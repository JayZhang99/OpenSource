commit_msg,labels
[FLINK-18528][table] Update UNNEST to new type systemThis closes #12862.,5
KAFKA-675 Allow the user to override the host that we bind to. Patch from Matan Amir<matan.amir@voxer.com> with slight changesto improve error messages for a bad host or port.,0
"MINOR: Update jmh to 1.27 for async profiler support (#9129)Also updated the jmh readme to make it easier for new people to knowwhat's possible and best practices.There were some changes in the generated benchmarking code thatrequired adjusting `spotbugs-exclude.xml` and for a `javac` warningto be suppressed for the benchmarking module. I took the chanceto make the spotbugs exclusion mode maintainable via a regexpattern.Tested the commands on Linux and macOS with zsh.JMH highlights:* async-profiler integration. Can be used with -prof async,pass -prof async:help to look for the accepted options.* perf c2c [2] integration. Can be used with -prof perfc2c,if available.* JFR profiler integration. Can be used with -prof jfr, pass-prof jfr:help to look for the accepted options.Full details:* 1.24: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-August/002982.html* 1.25: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-August/002987.html* 1.26: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-October/003024.html* 1.27: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-December/003096.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Lucas Bradstreet <lucasbradstreet@gmail.com>",4
[FLINK-7262][blob] remove the unused FallbackLibraryCacheManagerThis class was basically only used in unit tests and not really needed thereeither. The code path inside TaskManager was also dead.This closes #4403.,3
[FLINK-13090][hive] Test Hive connector with hive runnerThis PR uses hive runner in our hive connector tests.This closes #8987.,3
"Removed some old, outdated code",5
[hotfix] Fix incorrect output type in StreamExecTableSourceScan & BatchExecTableSourceScan,0
[FLINK-22624][runtime] Utilize the remain resource of new pending task managers to fulfill requirement in DefaultResourceAllocationStrategyThis closes #15888,1
Added missing files,2
[FLINK-25072][streaming] Introduce description on Transformation and StreamGraphThis closes #17924.,2
"[FLINK-5800] [checkpointing] Create CheckpointSteamFactory only once per operatorPreviously, the factory was created once per checkpoint, and its repeated initialization logic(like ensuring existence of base paths) caused heavy load on some filesystems at very large scale.This closes #3312",5
[FLINK-27398][scala] Move completeness test to flink-scala,2
[FLINK-22124][python] Fix the bug that errors are not thrown in custom python functionThis closes #15590.,1
"fix getAttachment, return default value (#10008)",1
[FLINK-20937][table-api] Fix exception when DROP a table with illegal watermark definitionThis closes #14640Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>,5
"[FLINK-5652] [asyncIO] Cancel timers when completing a StreamRecordQueueEntryWhenever a StreamRecordQueueEntry has been completed we no longer need the registered timeout.Therefore, we have to cancel the corresponding ScheduledFuture so that the system knows thatit can remove the associated TriggerTask. This is important since the TriggerTask contains areference on the StreamRecordQueueEntry. Consequently, such a task will prevent theStreamRecordQueueEntry from being garbage collected.This closes #3264.",1
[FLINK-21985][table][sql-client] Support EXPLAIN syntax in SQL Client and Table APIThis closes #15402,1
[FLINK-6290] [CEP] Fix SharedBuffer release when having multiple edges between entriesThis closes #3706,5
[hotfix][travis] Install jars in parallel,0
[FLINK-24417] Update MigrationVersion with 1.14,5
"[FLINK-27205][docs-zh] Translate ""Concepts -> Glossary"" page into Chinese.",2
MINOR: Fix side-effecting nullary methods warning in JsonValueTest (#5493)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-99 Enforce a max request size in socket server to avoid running out of memory with very large requests.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159837 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Small cleanups in TopicCommand describe handling (#7136)This patch contains a few small cleanups to make topic describe logic a little clearer. It also fixes a minor inconsistency in the output between the --zookeeper and --bootstrap-server behavior when the leader is unknown. Previously we printed -1 when --zookeeper was used, and now we print ""none."" The patch consolidates the output logic for describing topics and partitions in order to avoid inconsistencies like this in the future.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
[hotfix] Remove redundant job status logging,2
"[FLINK-994] Added test cases for AbstractPagedInputView, fixed problem with hbase.This closes #53",0
"[FLINK-10511][Cluster Management] Reuse the port selection and RPC service creation in JM and TMThis commit adds an overload method to create RPC service for specificport range in AkkaRpcServiceUtils and get rid of the port selectionlogic in TaskManagerRunner. Meanwhile, the AkkaRpcServiceUtils passthe work of akka config generation to BootstrapTools.This closes #6845.",5
"KAFKA-3108: custom StreamParitioner for Windowed keyguozhangwangWhen ```WindowedSerializer``` is specified in ```to(...)``` or ```through(...)``` for a key, we use ```WindowedStreamPartitioner```.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #779 from ymatsuda/partitioner",5
Implemented streaming input and output listeners,5
修改benchmark,5
[FLINK-17938] Move YarnTestBase.findFile and YarnTestBase.RootDirFilenameFilter to o.a.f.y.u.TestUtilsMoving findFile and RootDirFilenameFilter to o.a.f.y.u.TestUtils allows to run the UtilsTest suite withoutrequiring that yarn.classpath has been generated. The latter is required whenever one uses the YarnTestBaseclass because it reads this file when the class is being loaded.This closes #12341.,2
[FLINK-6078] Remove CuratorFramework#close calls from ZooKeeper based HA servicesRemove client less factory methods from ZooKeeperUtilsIntroduce default job idThis closes #3781.,4
KAFKA-1863; Add docs for possible thrown exception in Callback; reviewed by Jiangjie Qin,2
[FLINK-19406][table-planner-blink] Casting row time to timestamp loses nullability infoThis closes #13477,5
"Fix hessian2 serialized short, byte is converted to int bug (#1232)* Fix hessian2 serialized short, byte is converted to int bug* Fix hessian2 serialized short, byte is converted to int bug* adapt jdk1.5+",0
[FLINK-11753] [tests] Refactor SchemaCompatibilityTestingSerializerThis closes #7845.,3
[hotfix] Add missing space to log message in ZooKeeperLeaderElectionService,2
[hotfix] fix checkstyle,0
"KAFKA-12575: Eliminate Log.isLogDirOffline boolean attribute (#10430)This PR is a precursor to the recovery logic refactor work (KAFKA-12553).I have made a change to eliminate Log.isLogDirOffline attribute. This boolean also comes in the way of refactoring the recovery logic. This attribute was added in #9676. But it is redundant and can be eliminated in favor of looking up LogDirFailureChannel to check if the logDir is offline. The performance/latency implication of such a ConcurrentHashMap lookup inside LogDirFailureChannel should be very low given that ConcurrentHashMap reads are usually lock free.Tests:Relying on existing unit/integration tests.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
First piece of the Hybrid Hash Join: Partitions and partition spilling.,5
[FLINK-9007] [kinesis] [e2e] Build Kinesis test under include-kinesis profile,2
[hotfix] [cluster management] Remove scala dependencies from MiniCluster.java,5
修改multicast和zookeeper注册中心健状性git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@192 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Reflection free implementation of `defaultKerberosRealm` (#6978)The existing implementation triggers warnings in Java 9+ and relieson internal classes that vary depending on the JDK provider. The proposedimplementation fixes these issues and it's more concise.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Guozhang Wang <wangguoz@gmail.com>",5
unify registry_cluster key,1
"MINOR: Fixes version lookup exception.Given a schema with 2 versions (0 and 1), if you pass in a version of `2` you will get an `OutOfBoundsException` instead of an `IllegalArgumentException`.This fixes the problem by changing the check from `>` to `>=`, which will now return true in the given scenario.Author: Micah Zoltu <micah@zoltu.net>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #748 from Zoltu/patch-1",5
fix #9832 (#9839)Co-authored-by: 呈铭 <beck.wcm@antgroup.com>,0
"KAFKA-3060: Refactor MeteredStore and RockDBStore ImplChanges include:1) Move logging logic from MeteredXXXStore to internal stores, and leave WindowedStore API clean by removed all internalPut/Get functions.2) Wrap common logging behavior of InMemory and LRUCache stores into one class.3) Fix a bug for StoreChangeLogger where byte arrays are not comparable in HashSet by using a specified RawStoreChangeLogger.4) Add a caching layer on top of RocksDBStore with object caching, it relies on the object's equals and hashCode function to be consistent with serdes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #826 from guozhangwang/K3060",5
[FLINK-15834][hotfix][build scripts] Properly set return code before check,1
[minor] Fix warnings in AbstractFetcher(Test),3
修改zookeeper实现git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@70 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-7141; Consumer group describe should include groups with no committed offsets (#5356)Currently, if a consumer group never commits offsets, ConsumerGroupCommand will not include it in the describe output even if the member assignment is valid. Instead, the tool should be able to describe the group information showing empty current_offset and LAG.Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",5
Fixed bug in var-len integer deserialization.,0
"KAFKA-7833: Add missing test (#8847)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
[FLINK-3682] [cep] Assign processing timestamp in CEP operatorsThis PR fixes the problem that the CEP operators did not assign the wall clock timeas the timestamp to incoming in StreamRecords if the TimeCharacteristic was set toProcessingTime. Processing element with a Long.MIN_VALUE timestamp can lead to underflowsin the NFA if a positive window length is subtracted from the timestamp. For thisunderflow a sanity check has been added to notify the user with an exception about it.This closes #1841.,1
[FLINK-24228][connectors/firehose] Added documentation (&.zh docs) for the new Firehose sink.,1
Extended user API to set the number of execution retries per vertex,1
[FLINK-6639][docs] fix code tabs in CEP docsThis closes #3952.,2
"MINOR: Update test to wait for final value to reduce flakiness updated test method for multiple keys (#5517)Updated two integration tests to use IntegrationTestUtils#waitUntilFinalKeyValueRecordsReceived to eliminate flaky test results.Also, I updated IntegrationTestUtils#waitUntilFinalKeyValueRecordsReceived method to support having results with the same key present with different values.For testing, I ran the current suite of streams tests.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-14044] [datastream] Incorporating FLINK-13635 by adding tests for proper timeout handling,3
[hotfix][metrics][docs] Add missing space,1
[FLINK-12742][table-planner] Add insert into partition grammar as hive dialect,1
[hotfix][docs] replace references to MemoryStateBackend with HashMapStateBackend,2
[hotfix][runtime] Extract SlotManager interfaceRename SlotManager -> SlotManagerImpl and let it implement the SlotManager interface,4
[FLINK-8657][documentation] Fix incorrect description for configuration of async snapshot for heap based backendThis closes #5490.,5
[FLINK-1954] [FLINK-1958] [runtime] Cancel transfers of failed receiver tasks,0
KAFKA-1438 Migrate client tools out of perf; reviewed by Neha Narkhede,1
"KAFKA-5215; Small Javadoc fixes for AdminClient#describeTopicsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Roger Hoover <roger.hoover@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3013 from cmccabe/KAFKA-5215",5
[hotfix][network] Fix SingleCheckpointBarrierHandler#cancelSubsumedCheckpoint log.,2
"KAFKA-8637: WriteBatch objects leak off-heap memory (#7050)Should be cherry-picked back to 2.3 (picked from 2.2 to 2.1 in 7077 )Reviewers: pkleindl <44436474+pkleindl@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
Removed sequence number checking from incoming connection class,4
"kafka-1091; full topic list can be read from metadata cache in the broker instead of ZK; patched by Jun Rao; reviewed by Joel Koshy, Guozhang Wang, Swapnil Ghike, and Neha Narkhede",5
[FLINK-13289][table-planner-blink] Blink planner should setKeyFields to upsert table sinkThis closes #9195,1
broker needs to know the replication factor per partition; patched by Yang Ye; reviewed by Jun Rao; kafka-510git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396673 13f79535-47bb-0310-9956-ffa450edef68,2
Optimize code1. 判断字符串为空改为使用StringUtils (#4860)2. 将过多嵌套层次的if，循环改为使用卫语句3. 增加使用lambda表达式和Optional代替for循环和判空,5
[FLINK-13978][build system] Add experimental support for building on Azure PipelinesThis closes #10976,1
[FLINK-24405][tests] Harden kafka tests based on KafkaTestBase,3
[FLINK-9436][state] Remove generic parameter namespace from InternalTimeServiceManager.This closes #6077.,2
"[FLINK-16579][table] Upgrade Calcite version to 1.26 for Flink SQL (#13577)* Update Calcite version of pom and NOTICE fileAs a dependency, the Guava version upgrade to 29.0-jre, janino version upgrade to 3.0.11* Upgrade SQL parser Calcite version to 1.26.0* Fix the API change for plannerSqlParser, SqlValidator and SqlToRelConverter now have a Config bean for configurationSince CALCITE-2082, all the UDF needs a SqlOperandMetadata for operand type inference (before the change, it is SqlOperandTypeChecker)Since CALCITE-4215, Statistic default collations change from empty list to null* Replace the rule instance with new one since CALCITE-3923The core rules are changed to support new way of parameterization, and moved to CoreRules.* Since CALCITE-3877, the default over window bounds does not print out in the plan digest* Since CALCITE-3877, the default over window bounds does not print out in the plan digest* Since CALCITE-4220, the aggregate is promoted automatically after sql to rel conversion* The NDV algorithm has been tweaked since CALCITE-4132* All kinds of left plan changesThe predicate normalization now only happens during planning, that means it does not change in the digest anymoreThe HOP and SESSION window names changes to $HOP and $SESSION, both are deprecatedIS NOT DISTINCT FROM is expanded in the plan nowMany sort aggregate changes to hash aggregate which are more efficient",4
[hotfix][docs] Fix broken link in metrics.md.,2
[hotfix] Improve readability in SPV2#convertToOperatorStateSavepointV2,1
Adapt RPC to support primitive types as parameters and return values.,2
[hotfix] reallocate commons-codec in flink planner & blink planner,2
[FLINK-16337][python][table-planner-blink] Add support of vectorized Python UDF in blink planner,2
"KAFKA-10391: Overwrite checkpoint in task corruption to remove corrupted partitions (#9170)In order to do this, I also removed the optimization such that once enforced checkpoint is set to true, we always checkpoint unless the state stores are not initialized at all (i.e. the snapshot is null).Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@gmail.com>",5
Add base utility for serializer tests.Add string array serializer with test.,3
[FLINK-10958] [table] Add UDF's eval method parameters support subclass matching.This closes #7152,1
"[FLINK-4299] show loss of job manager in ClientThis prints a message when the leading JobManager changes after firstconnecting to a JobManager. Further, it prints a message when a connectionto a JobManager has been established.This closes #2322.",4
DUBBO-532 修复心跳不兼容问题,5
MINOR: use new method to get number of topics in DeleteTopicsRequest (#10351)Reviewers: David Jacot <djacot@confluent.io>,5
[FLINK-20239][docs] Confusing pages: Hive Read & Write and Hive Streaming,5
[FLINK-22854][docs-zh] Translate 'Apache Flink Documentation' index page to Chinese. (#16062),2
[hotfix][sql-gateway]Add default timeout for AbstractSqlGatewayRestHandler,0
"KAFKA-7149 : Reducing streams assignment data size  (#7185)* Leader instance uses dictionary encoding on the wire to send topic partitions* Topic names (most expensive component) are mapped to an integer using the dictionary* Follower instances receive the dictionary, decode topic names back* Purely an on-the-wire optimization, no in-memory structures changed* Test case added for version 5 AssignmentInfoReviewers: Guozhang Wang <wangguoz@gmail.com>",5
embedded controller; patched by Yang Ye; reviewed by Jun Rao; KAFKA-335git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350291 13f79535-47bb-0310-9956-ffa450edef68,2
kafka-1797; add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Neha Narkhede,1
[FLINK-2422] [web client] Added explicit link in case browser is not redirecting properlyThis closes #946,2
"[FLINK-12938][docs-zh] Translate ""Streaming Connectors"" page into ChineseThis closes #8837",1
[FLINK-4139][yarn] adjust task slots to parallelism correctly- user specifies no parallelism  -> parallelism is adjusted to #taskSlots * #nodes.- user specifies parallelism but no #taskSlots or too few slots  -> #taskSlots are set such that they meet the parallelism,1
Added missing files,2
Fix instance update failed (#9040),0
MINOR: Increase security test timeouts for transient failures (#6760)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
[FLINK-23453][refactor] Made a safe method for getting the number of buffers in the queue visible in the interface.,1
Rename multiple Scala classes: - DataStream to DataSet - DataSourceFormat -> *InputFormat - DataSinkFormat -> *OutputFormatClean up imports in scala examples,2
[FLINK-17268][connector/common] Fix the shutdown sequence in SplitFetcher to avoid blocking on shutdown.Fix flaky SourceReaderTestBase#testAvailableOnEmptyQueue().,3
[FLINK-14452][runtime] Keep only one execution topology in schedulerThis closes #9954.,2
[hotfix] Simplify computation in KeyGroupRangeAssignment::computeKeyGroupRangeForOperatorIndex,1
[FLINK-15464][hive] Fix HiveTableSourceTest::testPartitionFilterDateTimestamp for 1.xcloses #10757.,5
"[FLINK-4853] [rm] Clean up job manager registration at the resource managerIntroduce the JobLeaderIdService which automatically retrieves the current job leader id.This job leader id is used to validate job manager registartion attempts. Additionally, itis used to disconnect old job leaders from the resource manager.Add commentsThis closes #2657.",1
[hotfix][tests] Improve error message in GenericTypeInfoTest,5
Solved compilation errors in sopremo-common,0
[FLINK-9083][cassandra] Restructure CassandraSinkBase,2
[hotfix] Rename some methods of NetworkBufferPool and add more comments for better readabilityThis closes #18173.,1
[FLINK-15554][azure] Bump jetty-util to 3.1.2,2
fix string formatting; write data to stdout in ConsumerShellgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1164353 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix] Make GC test more strict in WindowOperatorContractTest,3
"[FLINK-7520][network] let our Buffer class extend from netty's buffer classFor this, use a common (flink) Buffer interface and an implementation(NetworkBuffer) that implements netty's buffer methods as well. In the future,with this, we are able to avoid unnecessary buffer copies when handing buffersover to netty while keeping our MemorySegment logic and configuration.For the netty-specific part, the NetworkBuffer also requires a ByteBuf allocatorwhich is otherwise not needed in our use cases, so if the buffer is handed overto netty, it requires a byte buffer allocator to be set.",1
修改Demogit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@853 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-12384: stabilize ListOffsetsRequestTest#testResponseIncludesLeaderEpoch (#10389)Reviewers: Luke Chen <showuon@gmail.com>, dengziming <swzmdeng@163.com>, Ismael Juma <ismael@juma.me.uk>",3
[FLINK-9394] [e2e] Test rescaling when resuming from externalized checkpointsThis closes #6038.,3
"[FLINK-28121][docs-zh]Translate ""Extension Points"" and ""Full Stack Example"" in ""User-defined Sources & Sinks"" page",1
"KAFKA-12375: don't reuse thread.id until a thread has fully shut down (#10215)Always grab a new thread.id and verify that a thread has fully shut down to DEAD before removing from the `threads` list and making that id available againReviewers: Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",5
[FLINK-14762][client] Implement JobClient#stopWithSavepoint,2
[FLINK-7845][runtime] Make NettyMessage publicThis a walkaround strange javaassist bug. The issue should go awayonce we upgrade netty dependency.Please check the ticket for more information.This closes #5007.,5
[FLINK-15179] Introduce generic ExecutorCLI,2
[FLINK-17857][e2e] Fix Kubernetes e2e tests on Mac OSThis closes #12451,3
[FLINK-23467][e2e] Remove usage of the sql-client YAML file in pyflink.sh This closes #16574,2
"KAFKA-13676: Commit successfully processed tasks on error (#11791)When we hit an exception when processing tasks we should save the work we have done so far.This will only be relevant with ALOS and EOS-v1, not EOS-v2. It will actually reduce the number of duplicated record in ALOS because we will not be successfully processing tasks successfully more than once in many cases.This is currently enabled only for named topologies.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-4209] Change hostname resolution from IP to nameThis solves issues when a host has multiple IPs,0
"KAFKA-6082; Fence zookeeper updates with controller epoch zkVersionThis PR aims to enforce that the controller can only update zookeeper states after checking the controller epoch zkVersion. The check and zookeeper state updates are wrapped in the zookeeper multi() operations to ensure that they are done atomically. This PR is necessary to resolve issues related to multiple controllers (i.e. old controller updates zookeeper states before resignation, which is possible during controller failover based on the single threaded event queue model we have)This PR includes the following changes:- Add MultiOp request and response in ZookeeperClient- Ensure all zookeeper updates done by controller are protected by checking the current controller epoch zkVersion- Modify test cases in KafkaZkClientTest to test mismatch controller epoch zkVersionTests Done:- Unit tests (with updated tests to test mismatch controller epoch zkVersion)- Existing integration testsAuthor: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Dong Lin <lindong28@gmail.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>Closes #5101 from hzxa21/KAFKA-6082",3
KAFKA-5994; Log ClusterAuthorizationException for all ClusterAction requestsAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #5021 from omkreddy/KAFKA-5994-CLUSTER-AUTH,5
"[streaming] add disk dump sink, prepare to support multiple output stream",1
kafka-1397; delete topic is not working; patched by Timothy Chen; reviewed by Neha Narkhede and Jun Rao,1
[FLINK-28152][sql-gateway] Simplify SessionHandle and OperationHandle,0
refresh only once,5
[FLINK-1242] Fix streaming-examples and scala-examples POMs to work properly with Eclipse,1
"[FLINK-24703][connectors][format] Add CSV File System encoding format based on BulkWriter.'flink-connector-file' introduced new interfaces for interacting with thefile system. This commit contributes to the goal of migrating all formatsused for writing files to this API, in particular, BulkWriter used byFileSink. It also makes use of the generic Converter interface to map typesbetween the types used by Flink (in particular by Table/SQL API) and thenative format types of the format encoder. This commit also adds teststhat use the reader added and the previous commit and the writer added inthis commit together.",1
"[hotfix] [build] Remove outdated and obsolete plugin config in flink-runtime    This removes an outdates plugin configuration for surefire, excluding    certain test data files which were way back conflicting with the test    naming pattern.",3
[FLINK-701] Change KeySelector to a SAM interfaceThis closes #85,4
"[FLINK-7056][tests][hotfix] make sure the client and a created InputStream are closedIf not and the server has not yet sent all data packets, it may still occupy theread lock and block any writing operations (also see FLINK-7467).This closes #4558.",2
[FLINK-16566][mesos] Change the log level of the launching command and dynamic properties from DEBUG to INFO in Mesos,5
fix qos configuration cannot work after added 'qos-enable' style support (#4378)fixes #4377,0
Remove redundant comparison (#1969),4
[FLINK-7905] [build] Update encrypted Travis S3 access keys,5
[FLINK-7414] Pin scala quickstart to 2.11Pinning it to the latest version means the order in which we deploy tomaven doesn't matter anymore.,3
[FLINK-27208][docs] Add scalafmt docs,2
[FLINK-18907][hotfix] Rename headOperator to mainOperator in the MultipleInputStreamTaskTest,3
"KAFKA-5604: Remove the redundant TODO marker on the Streams side (#8313)The issue itself has been fixed a while ago on the producer side, so we can just remove this TODO marker now (we've removed the isZombie flag already anyways).Reviewers: John Roesler <vvcephei@apache.org>",4
[hotfix] Correct equals & hashCode implementation of KryoSerializer,0
"KAFKA-9505: Only loop over topics-to-validate in retries (#8039)Found this bug from the repeated flaky runs of system tests, it seems to be long lurking but also would only happen if there are frequent rebalances / topic creation within a short time, which is exactly the case in some of our smoke system tests.Also added a unit test.Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6605: Fix NPE in Flatten when optional Struct is null (#5705)Correct the Flatten SMT to properly handle null key or value `Struct` instances.Author: Michal Borowiecki <michal.borowiecki@openbet.com>Reviewers: Arjun Satish <arjun@confluent.io>, Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
Finalized sparation of pact driver and control flow logic.,2
iterative mapreduce is working,1
[hotfix] [tests] Let MarshallingTestBases read the value from String value,3
KAFKA-707 Improve error message in the producer when sending data to a partition without an active leader; reviewed by Jun Rao,5
"[FLINK-8668] Remove ""hadoop classpath"" from config.shThis also removes usage of ""hdfs classpath"".",4
"KAFKA-13461: Don't re-initialize ZK client session after auth failure if connection still alive (#11563)If JAAS configuration does not contain a Client section for ZK clients, an auth failure event is generated. If this occurs after the connection is setup in the controller, we schedule reinitialize(), which causes controller to resign. In the case where SASL is not mandatory and the connection is alive, controller maintains the current session and doesn't register its watchers, leaving it in a bad state.Reviewers: Jun Rao <junrao@gmail.com>",5
Added plan assembler,1
[FLINK-26319][table-planner] Fix expected exception in CastFunctionITCase,1
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1391 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-10524] Retry MemoryManager#release if NoSuchElementExceptionThe MemoryManager#release method retries in case of ConcurrentModificationExceptions becausememory can be released concurrently. In case of concurrent releases we can also see aNoSuchElementException if we are in the ArrayList.Itr#next call past the concurrent modificationcheck and try to access, for example, an index which is exceeding the ArrayList's size. Thus,we should also retry on seeing a NoSuchElementException because it indicates a concurrentmodification.",1
"KAFKA-12905: Replace EasyMock and PowerMock with Mockito for NamedCacheMetricsTest (#10835)* Development of EasyMock and PowerMock has stagnated while Mockito continues to be actively developed. With the new Java cadence, it's a problem to depend on libraries that do bytecode generation and are not actively maintained. In addition, Mockito is also easier to use.KAFKA-7438Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
[FLINK-13986][doc] Update docs for managed memory configuration.,5
[FLINK-8600] Allow disabling truncate() check in BucketingSinkThe test was failing when using PrestoS3FileSystem because it doesn'tuse an absolute/qualified path.,1
"KAFKA-3073: Add topic regex support for Connect sinksThere are more methods that had to be touched than I anticipated when writing [the KIP](https://cwiki.apache.org/confluence/display/KAFKA/KIP-215%3A+Add+topic+regex+support+for+Connect+sinks).The implementation here is now complete and includes a test that verifies that there's a call to `consumer.subscribe(Pattern, RebalanceHandler)` when `topics.regex` is provided.Author: Jeff Klukas <jeff@klukas.net>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4151 from jklukas/connect-topics.regex",5
Job Graph Generator and Optimizer logic for generalized iterations.,2
DUBBO-153telnet增加--no-prompt参数，用于nc获取信息时不显示提示符git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@711 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-4920] Introduce Scala Function GaugeThis closes #3080.,1
[FLINK-21181][runtime] Wait for Invokable cancellation before releasing network resources,1
[FLINK-19833] Rename Sink API Writer interface to SinkWriterThis makes it more consistent with SourceReader.This closes #13887.,1
Remove redundant array creation.,1
"MINOR: Upgrade Gradle to 4.8 and bug fix updates for other deps (#5148)In addition to Gradle, updated snappy, owasp-dependency-check,apache directory service api.Gradle 4.8 fixes a fatal issue when building with Java 11, butfull support is coming in 4.9 or later.",1
MINOR: Small cleanups in the AclAuthorizer (#11921)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
KAFKA-3273; MessageFormatter and MessageReader interfaces should be resilient to changes* Change `MessageFormat.writeTo` to take a `ConsumerRecord`* Change `MessageReader.readMessage()` to use `ProducerRecord`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #972 from ijuma/kafka-3273-message-formatter-and-reader-resilient,1
Implemented propagation of buffer latencies to job manager component of the Nephele streaming plugin,2
[FLINK-17679][python] Replace strlen with the Python len for cython bytes encoding (#12142),2
[FLINK-5022] Suppress RejectedExecutionExceptions if the ExecutorService has been shut downThis PR suppresses occurring RejectedExecutionExceptions if an ExecutorService has been shutdown. This only works for ExecutorServices at the moment. All other exceptions are logged.This closes #2757,2
"[FLINK-17080][java,table] Fix possible NPE in Utils#CollectHelper This closes #11688",0
"KAFKA-10847: Delete Time-ordered duplicated records using deleteRange() internally (#10537)This PR changes the TimeOrderedKeySchema composite key from time-seq-key -> time-key-seq to allow deletion of duplicated time-key records using the RocksDB deleteRange API. It also removes all duplicates when put(key, null) is called. Currently, the put(key, null) was a no-op, which was causing problems because there was no way to delete any keys when duplicates are allowed.The RocksDB deleteRange(keyFrom, keyTo) deletes a range of keys from keyFrom (inclusive) to keyTo (exclusive). To make keyTo inclusive, I incremented the end key by one when calling the RocksDBAccessor.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-15482][table][hive] Fix calling Hive functions with returning decimal type failed (#10775),0
MINOR: Remove implicit return statement (#6629)Reviewers: Jason Gustafson <jason@confluent.io>,5
"fixed serialization error, still issues in restarting",0
"[FLINK-3184] [timeouts] Set default cluster side timeout to 10 s and the client side timeout to 60 sAdd missing param descriptions to FlinkYarnCluster, remove implicit timeout from ApplicationClientThis closes #1468",4
Merge branch 'stage1' into version02Conflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/io/TextInputFormat.java,5
[FLINK-7749][network] Refactor ResultPartitionWriter into an interfaceThis closes #5127.,4
"[FLINK-11679][table] Create Blink SQL planner and runtime modulesThis commit adds flink-table-planner-blink and flink-table-runtime-blinkmodules. Those modules are work-in-progress and are not connected to theAPI yet. This happens at a later stage (see FLINK-11452). We aim to makethe runtime module Scala-free.Initial dependencies have been added. Optimization with Calcite, codegeneration, and translation to operators are performed in the plannermodule.Actual execution classes and code compilation are performed in the runtimemodule.This closes #7790.",1
"KAFKA-7492 : Updated javadocs for aggregate and reduce methods returning null behavior. (#6285)This is an update to the existing javadocs for KGroupedStream class.Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
Added missing files,2
[FLINK-7599][table] Refactored AggregateUtil#transformToAggregateFunctions,1
[FLINK-22650][python][table-planner-blink] Support StreamExecPythonCorrelate json serialization/deserializationThis closes #15922.,5
[FLINK-4025] RMQ Streaming: Possibility to customize queueThis patch adds the possibilty for th user of the RabbitMQStreaming Connector to customize the queue which is used. Thereare use-cases in which you want to set custom parameters for thequeue (i.e. TTL of the messages if Flink reboots) or thepossibility to bind the queue to an exchange afterwards.The commit doesn't change the actual behaviour but makes itpossible for users to override the newly create `setupQueue`method and cutomize their implementation. This was not possiblebefore.This closes #2073,1
"KAFKA-13749: CreateTopics in KRaft must return configs (#11941)Previously, when in KRaft mode, CreateTopics did not return the active configurations for thetopic(s) it had just created. This PR addresses that gap. We will now return these topicconfiguration(s) when the user has DESCRIBE_CONFIGS permission. (In the case where the user doesnot have this permission, we will omit the configurations and set TopicErrorCode. We will also omitthe number of partitions and replication factor data as well.)For historical reasons, we use different names to refer to each topic configuration when it is setin the broker context, as opposed to the topic context. For example, the topic configuration""segment.ms"" corresponds to the broker configuration ""log.roll.ms"". Additionally, some brokerconfigurations have synonyms. For example, the broker configuration ""log.roll.hours"" can be used toset the log roll time instead of ""log.roll.ms"". In order to track all of this, this PR adds atable in LogConfig.scala which maps each topic configuration to an ordered list of ConfigSynonymclasses. (This table is then passed to KafkaConfigSchema as a constructor argument.)Some synonyms require transformations. For example, in order to convert from ""log.roll.hours"" to""segment.ms"", we must convert hours to milliseconds. (Note that our assumption right now is thattopic configurations do not have synonyms, only broker configurations. If this changes, we willneed to add some logic to handle it.)This PR makes the 8-argument constructor for ConfigEntry public. We need this in order to make fulluse of ConfigEntry outside of the admin namespace. This change is probably inevitable in generalsince otherwise we cannot easily test the output from various admin APIs in junit tests outside theadmin package.Testing:This PR adds PlaintextAdminIntegrationTest#testCreateTopicsReturnsConfigs. This test validatessome of the configurations that it gets back from the call to CreateTopics, rather than just checkingif it got back a non-empty map like some of the existing tests. In order to test theconfiguration override logic, testCreateDeleteTopics now sets up some custom static and dynamicconfigurations.In QuorumTestHarness, we now allow tests to configure what the ID of the controller should be. Thisallows us to set dynamic configurations for the controller in testCreateDeleteTopics. We will havea more complete fix for setting dynamic configuations on the controller later.This PR changes ConfigurationControlManager so that it is created via a Builder. This will make iteasier to add more parameters to its constructor without having to update every piece of test codethat uses it. It will also make the test code easier to read.Reviewers: David Arthur <mumrah@gmail.com>",3
[FLINK-17687][tests] Collect log files before tearing down Mesos,2
"KAFKA-3590; Handle not-enough-replicas errors when writing to offsets topicAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #1859 from hachikuji/KAFKA-3590",5
[FLINK-13008] fix findbugs warning in AggregationsFunction,1
MINOR: Improve log message in `ReplicaManager.becomeLeaderOrFollower`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1789 from ijuma/improve-log-message-in-replica-manager,2
[FLINK-25404] Let blob.storage.directory default to <WORKING_DIR>/blobs,1
[FLINK-3731] make embedded SQL outer joins fail during translationThis closes #1869,0
[FLINK-6593] [table] Fix Bug in ProctimeAttribute or RowtimeAttribute with CodeGeneratorThis closes #3918.,0
[FLINK-20275][python] Fix the delimiter of the dependencies of Python DataStream APIThis closes #14159.,5
[streaming] tuple test,3
KAFKA-2862: Fix MirrorMaker's message.handler.args descriptionAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang WangCloses #561 from SinghAsDev/KAFKA-2862,0
[FLINK-1201] [gelly] SSSP with runVertexCentricIteration,1
KAFKA-2848; Use client SSL/SASL config utilities in Kafka Connect to avoid duplication of configs.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #539 from ewencp/kafka-2848-reuse-ssl-sasl-client-configs,5
KAFKA-8098: Fix Flaky Test testConsumerGroups- The flaky failure is caused by the fact that the main thread sometimes issues DescribeConsumerGroup request before the consumer assignment takes effect. Added a latch to make sure such situation is not going to happen.Author: huxihx <huxi_2b@hotmail.com>Author: huxi <huxi_2b@hotmail.com>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6441 from huxihx/KAFKA-8098,1
"[FLINK-3347] [akka] Add QuarantineMonitor which shuts a quarantined actor system and JVM downThe QuarantineMonitor subscribes to the actor system's event bus and listens toAssociationErrorEvents. These are the events which are generated when the actor systemhas quarantined another actor system or if it has been quarantined by another actorsystem. In case of the quarantined state, the actor system will be shutdown killingall actors and then the JVM is terminated.Disable the quarantine monitor per defaultThis closes #2696.",5
"[FLINK-11889] Remove ""stop"" signal and related interfaces.",4
- Fixed check for partitioning (field numbers are now checked)- Couple of small bug fixes,0
merge 0.8 to trunk and resolve conflicts,5
[FLINK-19669][coordination] PipelinedRegionSchedulingStrategy#init ResultPartitionType blocking check use isBlocking method,1
DUBBO-251 增加API覆盖dubbo.properties的测试，以及旧版本配置项测试。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1213 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][yarn] Remove unused dependency,1
"KAFKA-5097; Add testFetchAfterPartitionWithFetchedRecordsIsUnassignedI verified that the test would trigger an `IllegalStateException` if the`position` call was added back.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2887 from ijuma/kafka-5097-unit-test",3
"[FLINK-3107] [runtime] Start checkpoint ID counter with periodic schedulerProblem: The job manager enables checkpoints during submission of streamingprograms. This can lead to call to a call to `ZooKeeperCheckpointIDCounter.start()`,which communicates with ZooKeeper. This can block the job manager actor.Solution: Start the counter in the `CheckpointCoordinatorDeActivator`.This closes #1610.",0
MINOR: Cache metrics were missingAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3262 from enothereska/minor-missing-metric,5
"[FLINK-16831][e2e] Support plugin directory as JarLocationAdds the plugins directory to the set of supported jar locations.Every plugin must be contained in a sub-directory within the plugins directory, so for simplicity we always create a parent directory regardless of what the target location is.",1
增加NOTICEgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1554 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-23722][fs] Downgrade shaded hadoop to 3.2.2 to avoid HADOOP-17771.,2
"[hotfix][docs,metrics] Fix typo in the input pool usage metrics",2
修改jetty依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@525 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[streaming] Removed unused StreamReduceRefactored corresponding tests, some minor cleanups.",4
[hotfix][mesos] Remove the useless env variable in MesosTaskExecutorRunner,1
"MINOR: Remove deprecated KTable#writeAs, print, foreach, to, through (#4910)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-22198][connector/kafka] Disable log retention on Kafka broker in KafkaTableTestBase (#16897),3
[FLINK-4062] Update Windowing Documentation,2
[FLINK-12075] Update RestOptions#PORT descriptionThis commit updates the description of RestOPtions#PORT to better reflect howit is used.,1
"MINOR: Update dependencies.gradle, Dockerfile, version.py, and bash.sh for 2.4.1 upgrade (#8387)These files were missed in the 2.4.1 releaseReviewers: Ismael Juma <ismael@confluent.io>",5
[FLINK-3901] [table] Create a RowCsvInputFormat to use as default CSV IF in Table API,1
Updated jar for end-to-end testing of packaged programs.,3
设置忽略文件 git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@417 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-19972][serialization] add more hints in case of incompatbilities,1
Passing parameters down directly from Protocol to Remoting components. (#9453)fixes #9440,0
[FLINK-3677] Remove Guava dependency from flink-core,2
"KAFKA-1108 When controlled shutdown attempt fails, the reason is not always logged; reviewed by Neha Narkhede",2
[FLINK-4316] [core] [hadoop compatibility] Make flink-core independent of HadoopThis commit moves all 'Writable' related code to the 'flink-hadoop-compatibility' projectand uses reflection in 'flink-core' to instantiate WritableTypeInfo when needed.This closes #2338,5
修改版本为2.4.0-SNAPSHOT,5
[hotfix][test] Do not hide original exception in the tests,3
KAFKA-10502: Use Threadlocal.remote to avoid leak on TimestampRouter (#9304)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-12208: Rename AdminManager to ZkAdminManager (#9900)Rename AdminManager to ZkAdminManager to emphasize the fact that it is not used by the KIP-500 code paths.Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
[hotfix][tests] Add SchedulerImplTest#testAllocateSlot to test the basic slot allocation function of SchedulerImpl,1
[refactor] Change if-else conditions to switch-case statements.This closes #1485,4
[hotfix][tests] Fix TestingShuffleMaster usage,3
"Separating Pact Drivers and Control-Flow drivers, first part.",5
KAFKA-1746 System tests don't handle errors well; reviewed by Neha Narkhede,0
"kafka-1864; Revisit defaults for the internal offsets topic; patched by Jun Rao; reviewed by Jeol Koshy, Neha Narkhede, and Gwen Shapira",1
[FLINK-1535] [tests] Add custom acumulators and custom type collect() to classloading testsConsolidate class loading tests into one cluster execution to validate repeated different class loaders,5
[hotfix] Remove RpcTimeout annotation from SlotPool,4
"KAFKA-1686; Implement SASL/KerberosThis PR implements SASL/Kerberos which was originally submitted by harshach as https://github.com/apache/kafka/pull/191.I've been submitting PRs to Harsha's branch with fixes and improvements and he has integrated all, but the most recent one. I'm creating this PR so that the Jenkins can run the tests on the branch (they pass locally).Author: Ismael Juma <ismael@juma.me.uk>Author: Sriharsha Chintalapani <harsha@hortonworks.com>Author: Harsha <harshach@users.noreply.github.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Parth Brahmbhatt <brahmbhatt.parth@gmail.com>, Jun Rao <junrao@gmail.com>Closes #334 from ijuma/KAFKA-1686-V1",5
DUBBO-372 Provider与Consumer version的默认值导致如果应用中没有配置version会出现服务匹配问题git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1700 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][task] Generalizing MailboxExecutor#execute to ThrowingRunnable.,1
add provider configuration override disable option (#8314),5
[FLINK-6830] [DataStream] Port window operator migration tests for Flink 1.3This commit also consolidates all Flink 1.1 and 1.2 window operatormigration tests to a single WindowOperatorMigrationTest class.Parameterization is used to test restoring from different previous Flinkversion snapshots.,2
DUBBO-68 修改测试用例中的host断言git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1534 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-16033][table-api] Parse identifiers in FunctionLookup.This change effectively enables querying catalogs for catalog functionswith qualified names.,1
[streaming] Started implementing basic type serialization with Long instead of String,2
"MINOR: Fix error message in exception when records have schemas in Connect's Flatten transformation (#3982)In case of an error while flattening a record with schema, the Flatten transformation was reporting an error about a record without schema, as follows: ```org.apache.kafka.connect.errors.DataException: Flatten transformation does not support ARRAY for record without schemas (for field ...)```The expected behaviour would be an error message specifying ""with schemas"". This looks like a simple copy/paste typo from the schemaless equivalent methods, in the same file Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Konstantine Karantasis <konstantine@confluent.io>",5
[FLINK-9011] Changed some verbose YarnResourceManager logging from INFO to DEBUG levelThis closes #5712.,0
Temporarily removed automatic flushing of output buffers,4
"[FLINK-7343][Kafka] Use NetworkFailureProxy in kafka testsWe shouldn't fail KafkaServers directly, because they might not be ableto flush the data. Since we don't want to test how well Kafka implementsat-least-once/exactly-once semantic, we just simulate network failurebetween Flink and Kafka in our at-least-once tests.",3
[FLINK-25080][tests] Move ManuallyTriggeredScheduledExecutor to flink-core,2
[FLINK-14936][runtime] Introduce MemoryManager#computeMemorySize to calculate managed memory size from a fraction,2
Finished rewrite of JobGraph by Nephele streaming plugin,5
"[FLINK-25387][FLINK-25388][FLINK-25389][table-planner] Introduce ExecNodeMetadata- Introduce a new annotation `ExecNodeMetadata` on `ExecNode`s which is used toimprove the serialization/deserialization to/from JSON plan of `ExecNode`s andfacilitate the upgrade of the pipeline, since every ExecNode has now also a versionattached.- List all the JSON plan eligible `ExecNode`s in `ExecNodeMetadataUtil` and use a static list to register them in Jackson.- Annotate all those eligible `ExecNode`s with the new annotation and provide aname constructed by the class name using `-` separators. All versions are set nowto 1.- Use an `ExecNodeContext` POJO which uses the uniqueId, name and version toserialize/deserialize them in a JSON plan in the form of `<id>_<exec-node-name>_<version>`.- Fix issues with `@JsonIgnoreProperties` and `@JsonIgnore`, and opt for the classbased annotation instead of the per field annotation of `@JsonIgnore`.- Update the test plans with the new JSON scheme derived by the changes.This closes #18479.",4
MINOR: Update test classes to use KafkaZkClient/AdminZkClient methods (#4353),1
"[build] Move licenses for shaded dependencies into the NOTICE fileIn accordance with the Apache Software License 2.0, the NOTICEfile is the dedicated/prefered place for any additional licenseinformation that affects redistribution, because the NOTICEfile is required to be included in any redistribution.The only project still having shaded dependencies that requireextra license statements is flink-table. Changing the licensesto be in the NOTICE file also allows removing the maven-resourceplugin from the root pom.xml",5
[FLINK-1767] [streaming] Make StreamExecutionEnvironment return JobExecutionResult instead of void.Conflicts:flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/LocalStreamEnvironment.javaflink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/util/ClusterUtil.javaThis closes #516,5
HOTFIX: Handle Connector version returning 'null' during plugin loading.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3321 from kkonstantine/HOTFIX-Handle-null-version-returned-from-Connector-interface-during-plugin-loading,0
[hotfix][coordination] Add log for slot allocation in FineGrainedSlotManagerThis closes #15748,2
[FLINK-14380][ScalaAPI] Passing inferred outputType directly to map and flatMap functionThis closes #9999,1
Added optional parameter to always write into directories even in case of DOP = 1.Extended FileOutputFormatTest.Some code beautifications.,3
[hotfix][core] InstantiationUtil#serializeObject creates ObjectOutputStream only when necessary.,1
[FLINK-19789][hive] Migrate Hive connector to new table source sink interfaceThis closes #13771,1
"KAFKA-2998: log warnings when client is disconnected from bootstrap brokersAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke, Guozhang WangCloses #769 from hachikuji/KAFKA-2998",5
[FLINK-22535][runtime] CleanUp is invoked despite of fail inside of cancelTask,0
[FLINK-18483][kinesis] Test coverage improvements for FlinkKinesisConsumer/ShardConsumerThis closes #12850.,2
"MINOR: Use `hiResClockMs` in `testRequestExpiry` to fix transient test failureWe recently switched `SystemTimer` to use `hiResClockMs` (based on `nanoTime`), but wewere still using `System.currentTimeMillis` in the test. That would sometimes meanthat we would measure elapsed time as lower than expected.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>Closes #1890 from ijuma/fix-test-request-satisfaction-transient-failure",3
"KAFKA-4420; Group StopReplicaRequests for partitions on the same broker into one StopReplicaRequestAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2148 from lindong28/KAFKA-4420",2
[FLINK-7878] Hide GpuResource in ResourceSpec,2
"[FLINK-6064][flip6] fix BlobServer connection in TaskExecutorThe hostname used for the BlobServer was set to the akka address which isinvalid for this use. Instead, this adds the hostname to the RpcGateway /AkkaInvocationHandler so that this information is available to the TaskExecutor.This closes #3551.",5
Fixed potential race condition in TaskManager failed task checking.,0
DUBBO-407 callback集成测试用例WARN日志找不到方法git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1840 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-23402][streaming-java] Refactor GlobalDataExchangeMode to GlobalStreamExchangeMode,4
[hotfix][build] Remove various unused test dependencies,3
[FLINK-28880][docs][cep] Fix wrong result of strict contiguity of looping patternsThis closes #20508.,0
"MINOR: Fix zk client session state metric names and various async zk clean-ups- Fix zk session state and session change rate metric names: typeshould be SessionExpireListener instead of KafkaHealthCheck. Testverifying the fix was included.- Handle missing controller in controlled shutdown in the same way as ifthe broker is not registered (i.e. retry after backoff).- Restructure BrokerInfo to reduce duplication. It now contains aBroker instance and the JSON serde is done in BrokerIdZNodesince `Broker` does not contain all the fields.- Remove dead code from `ZooKeeperClient.initialize` and removeredundant `close` calls.- Move ACL handling and persistent paths definition from ZkUtils toZkData (and call ZkData from ZkUtils).- Remove ZooKeeperClientWrapper and ZooKeeperClientMetrics fromZkUtils (avoids metrics clash if third party users create a ZkUtilsinstance in the same process as the broker).- Introduce factory method in KafkaZkClient that createsZooKeeperClient and remove metric name defaults fromZooKeeperClient.- Fix a few instances where ZooKeeperClient was not closed in tests.- Update a few TestUtils methods to use KafkaZkClient instead ofZkUtils.- Add test verifying SessionState metric.- Various clean-ups.Testing: mostly relying on existing tests, but added a coupleof new tests as mentioned above.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>Closes #4359 from ijuma/kafka-6320-kafka-health-zk-metrics-follow-up",3
KAFKA-10592: Fix vagrant for a system tests with python3Fix vagrant for a system tests with a python3.Author: Nikolay Izhikov <nizhikov@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9480 from nizhikov/KAFKA-10592,3
Added setter for FileBasedStatistics,2
"KAFKA-3799: Enable SSL endpoint validation in system testsGenerate certificates with hostname in SubjectAlternativeName and enable hostname validation.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1483 from rajinisivaram/KAFKA-3799",5
[hotfix][tests] Remove unused argument from db/flink-db.,5
[FLINK-14145] Fix getLatestCheckpoint(true) returns wrong checkpointCloses #9727,0
[FLINK-8053] [checkpoints] Default to asynchronous snapshots for FsStateBackend and MemoryStateBackend.This closes #5005.,2
"KAFKA-13599: Upgrade RocksDB to 6.27.3 (#11690)RocksDB v6.27.3 has been released and it is the first release to support s390x. RocksDB is currently the only dependency in gradle/dependencies.gradle without s390x support.RocksDB v6.27.3 has added some new options that require an update to streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBGenericOptionsToDbOptionsColumnFamilyOptionsAdapter.java but no other changes are needed to upgrade.I have run the unit/integration tests locally on s390x and also the :streams tests on x86_64 and they pass.Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
[FLINK-2432] Custom serializer supportThis closes #962,1
[hotfix] Add FutureUtils.completedVoidFuture,1
multicast fix + support for penalties,1
[FLINK-26039][table-runtime] Fix the incorrect value getter in map unnest table functionThis closes #18679.,1
[FLINK-1774] Remove the redundant code in try{} block.This closes #522,1
KAFKA-8415: Interface ConnectorClientConfigOverridePolicy needs to be excluded from class loading isolation (#6796)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
Adjust the modifier of DynamicParamTable#init method (#8332)* Adjust the modifier of DynamicParamTable#init method* Put the call to the getParameters() method outside the loop,2
"[FLINK-20883][table-planner-blink] Introduce BatchPhysicalPythonOverAggregate, and make BatchExecPythonOverAggregate only extended from ExecNodeThis closes #14605",1
"[FLINK-12284][Network,Metrics]Fix the incorrect inputBufferUsage metric in credit-based network mode",1
[FLINK-8994] [tests] Let general purpose DataStream job include Avro as stateThis closes #6435.,5
[FLINK-25079][table-common] Add some initial assertj assertions for table data and types apis,5
Merge branch 'version02_wo_dm' into version02Conflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/TPCHQuery3.java,5
[FLINK-20295][table][fs-connector] Table File Source lost data when reading from directories with JSON formatThis closes #14192,5
"MINOR: Fix failing ConsumeBenchTest:test_multiple_consumers_specified_group_partitions_should_raise (#6015)This is the error message we're after:""You may not specify an explicit partition assignment when using multiple consumers in the same group.""We apparently changed it midway through #5810 and forgot to update the test.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-24046][state] Refactor the EmbeddedRocksDBStateBackend configuration logicThis closes #17874.,2
"[FLINK-15632][kubernetes] Update the cluster id and high-availability jobmanager port when HA enabledWhen HA enabled, the config option HighAvailabilityOptions.HA_CLUSTER_ID will be set to the user specified cluster id. And if the config option HighAvailabilityOptions.HA_JOB_MANAGER_PORT_RANGE is not set or with value 0, it will be updated to the value of JobManagerOptions.PORT.",5
DUBBO-218 对空属性也要检查-D参数git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1032 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-3558; Add compression_type parameter to benchmarks in benchmark_test.py* Use a fixed `Random` seed in `EndToEndLatency.scala` for determinism* Add `compression_type` to and remove `consumer_fetch_max_wait` from `end_to_end_latency.py`. The latter was never used.* Tweak logging of `end_to_end_latency.py` to be similar to `consumer_performance.py`.* Add `compression_type` to `benchmark_test.py` methods and add `snappy` to `matrix` annotation* Use randomly generated bytes from a restricted range for `ProducerPerformance` payload. This is a simple fix for now. It can be improved in the PR for KAFKA-3554.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1225 from ijuma/kafka-3558-add-compression_type-benchmark_test.py,3
"[FLINK-23532] Pass a flag for draining along with EndOfDataFor the sake of unification, we want to emit EndOfData in case of stop-with-savepoint both with and without drain. This is a preparation so that we can enclose the flag inside of EndOfData.",5
[FLINK4429] Remove redis connector (now in Apache Bahir),4
DUBBO-970 消空overridegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1546 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-21466][sql-client] Make ""embedded"" parameter optional when start sql-client.shThis closes #15255",2
[FLINK-23659][metrics][prometheus] Cleanup code,4
current changes from dima repository,4
Fix concurrent bean creation error (#8883),0
"Service callback throws ""Not found exported service"" when 'bind.port' is set (#6223)",1
KAFKA-9821: consolidate Streams rebalance triggering mechanisms (#8596)Persist followup rebalance in assignment and consolidate rebalance triggering mechanismsReviewers: John Roesler <vvcephei@apache.org>,5
[hotfix] Bump japicmp reference version to Flink 1.6.0,2
"KAFKA-2555: Fix infinite recursive ensurePartitionAssignment in callback's commitSynchachikuji ewencp I found this problem when adding new consumer to mirror maker which commits offset in the rebalance callback. It is not clear to me why we are triggering rebalance for commitSync() and fetchCommittedOffset(). Can you help review to see if I miss something?Regarding commitSync, After each poll() the partitions will be either assigned to a consumer or it will be already revoked. As long as user is using internal offset map, the offset map will always be valid. i.e. the offset map will always only contain the assigned partitions when commitSync is called. Hence there is no need to trigger a rebalance in commitSync().The same guarantee also apply to fetchCommittedOffset(), isn't the only requirement is to ensure we know the coordinator?Another related issue is that today the IllegalGenerationIdException is a bit confusing. When we receive an IllegalGenerationIdException from heartbeat, we need to use that same generation Id to commit offset and the coordinator will take it. So the generation ID was not really illegal. I will file a ticket for this issue.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jason Gustafson, Guozhang WangCloses #221 from becketqin/KAFKA-2555",0
[FLINK-23742][python] Ignore test_keyed_co_process for the time being,3
- extended pact-tests TestBase- Added DeltaComparator to KMeansIterationITCase,1
"Implemented equals/hashCode for FileInputSplit, removed unnecessary locking in input split provider",1
[FLINK-20551][docs] Make SQL documentation Blink onlyThis closes #14594,2
- extended OptimizerNodes to hold new StubAnnotations- PactCompiler reads StubAnnotations and adds them to OptimizerNodes,1
[hotfix][javadocs] Fix name of the element in the createFieldGetter method of RowData. This closes #18261,5
[FLINK-7418][build] Integrate flink-shaded-jackson2This closes #4923.,2
"[FLINK-20856][table-planner-blink] Introduce StreamPhysicalGroupWindowAggregate & StreamPhysicalGroupWindowTableAggregate, and make StreamExecGroupWindowAggregate only extended from ExecNodeThis closes #14569",1
Finished changes to the compression interfaces,4
[FLINK-23652][core/metrics] Extract Operator(IO)MetricGroup interfaces and expose them in RuntimeContext,1
"[streaming] add stream join and stream window join example, refactor window state",4
[FLINK-13599][e2e tests] Harden test_streaming_kinesis with kinesalite docker image download/run retries,1
[FLINK-14349][docs] Add documentation for HBase descriptor API,2
[hotfix][table-planner-blink] revert commons-codec exclusion.,4
"KAFKA-12394; Return `TOPIC_AUTHORIZATION_FAILED` in delete topic response if no describe permission (#10223)We now accept topicIds in the `DeleteTopic` request. If the client principal does not have `Describe` permission, then we return `TOPIC_AUTHORIZATION_FAILED`. This is justified because the topicId is not considered sensitive. However, in this case, we should not return the name of the topic in the response since we do consider it sensitive.Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>, Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
MINOR: Fix compilation error in PlaintextConsumerTest under scala 2.12 (#5674),3
[FLINK-18750][table] SqlValidatorException thrown when select from a view which contains a UDTF call,5
[FLINK-4924] Simplify Operator Test Harness Constructors,3
"[docs] Clarify restart strategy defaults set by checkpointing- Added info about checkpointing changing the default restartstrategy in places where it was missing: the config page and thesection about the fixed-delay strategy- Replaced no-restart with ""no restart"" so people don't think we're referring to a config value- Replaced invalid <it> html tag with <code>- Fixed bad link to restart strategies page from state.md",2
[hotfix] Rename flag in CheckpointFailureReason to preFlight,0
"KAFKA-14195: Fix KRaft AlterConfig policy usage for Legacy/Full case (#12578)#12374 adjusted the invocation of the alter configs policy check in KRaft to match the behavior in ZooKeeper, which is to only provide the configs that were explicitly sent in the request. While the code was correct for the incremental alter configs case, the code actually included the implicit deletions for the legacy/non-incremental alter configs case, and those implicit deletions are not included in the ZooKeeper-based invocation. This patch adds a test to check for this and adjusts ConfigurationControlManager code so that the test passes -- the adjusted test is confirmed to fail locally otherwise. We also add a log statement to emit any unexpected stack traces in the alter config code path.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",5
Refactor Injvm invoke (#8926)* Refactor Injvm invoke* Add ut* Fix import* Remove deprecated method & fix ut* Fix Cluster join,0
[FLINK-4022] [kafka] Partition / topic discovery for FlinkKafkaConsumerThis closes #3746.,2
"[FLINK-10328] Release all locks when stopping the ZooKeeperSubmittedJobGraphStoreWhen stopping the ZooKeeperSubmittedJobGraphStore, it will release all currently heldlocks such that other instances can remove entries from the store. This is necessaryif we don't immediately close the used CuratorFramework/ZooKeeper client.This closes #6686.",1
[hotfix][core] Fix warnings in TypeSerializerUpgradeTestBase,3
Add unit test for ChannelBuffers and ChannelBufferFactory (#9031),3
[FLINK-1226] Add API support for passing Configurations to InputFormatsThis closes #196,5
[FLINK-21396][table-common] Add ResolvedCatalog(View/Table) and Catalog(View/Table).ofThis introduces ResolvedCatalogTable and ResolvedCatalogView. ResolvedCatalogTable usesa new CatalogPropertiesUtil for serialization into properties. We introduce aCatalogTable.of and CatalogView.of for creating instances easily and forceimplementers to not check against CatalogTableImpl which is actually an internalclass.This closes #15098.,2
[FLINK-7008] [cep] Update NFA state only when the NFA changesThis closes #4195.,4
DUBBO-200 测试用例中DubboProtocol采用new导致存在多个dubboprotocol实例进而导致获取invoker失败git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@895 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FILNK-11597][test] Remove legacy JobManagerActorTestUtils (#7700),3
"[FLINK-10325] [State TTL] Refactor TtlListState to use only loops, no java stream API for performanceThis closes #6683.",1
Php Client support for compression attribute; patched by AaronR; KAFKA-159git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1185774 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-705 Shutting down brokers should not receive stop replica requests if controlled shutdown status is incomplete; reviewed by Neha Narkhede,5
[FLINK-5014] [RocksDB backend] Add toString for RocksDBStateBackendThis closes #2760,5
KAFKA-13785: add processor metadata to be committed with offset (#11829)Part of KIP-825Reviewers: Matthias J. Sax <matthias@confluent.io>,5
Maven requirements [ci skip],1
删除无用类git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@822 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-26121][runtime] Adds clearUnhandledEvents() methodWe experienced some ZK connection issue which resulted in aSUSPEND and a RECONNECT event which were not handled and,therefore, stayed in the queue blocking a thread for thesecond event (because the capacity of the internally usedArrayBlockingQueue is set to 1). Shutting down the driverinitiates a shutdown of the ExecutorService which is usedfor the listeners internally (seeZooKeeperLeaderRetrievalDriver.close()). The blocking threadwill cause a fatal error through an InterruptedException.The test will fail due to the fatal error in the end.Cleaning unhandled events at the end of the test run fix the issue. Additionally, the tests were aligned by moving genericcode into a helper method.",4
"MINOR: Fix RecordContext Javadoc (#12130)A prior commit accidentally changed the javadoc for RecordContext.In reality, it is not reachable from api.Processor, only Processor.Reviewers: Guozhang Wang <guozhang@apache.org>",2
[FLINK-21818][table] Refactor SlicingWindowAggOperatorBuilder to accept serializer instead of LogicalTypeThis closes #15236,2
[FLINK-17442][docs] Make example URL Flink version dependent,2
"message size not checked at the server; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-469git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1376943 13f79535-47bb-0310-9956-ffa450edef68",1
Merge branch 'dev-metadata' of https://github.com/apache/incubator-dubbo into dev-metadata,5
[FLINK-23283][table-planner] Fix unstable case GroupWindowITCase#testWindowAggregateOnUpsertSourceThis closes #16408,3
[FLINK-23453][runtime] Message for notification about new buffer size(NewBufferSize) was added,1
[FLINK-4460] Add documentation for side outputs,2
[FLINK-10295] Add support of passing jar arguments as list of separate strings in REST API,4
added test case with multiple probers,3
增加常量git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1341 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][test][formats] Detach TableCsvFormatITCase from JsonPlanTestBase,5
"fixes #10079, address notification issue with service discovery multi subscription (#10080)",0
[FLINK-2386] [kafka connector] Remove copied Kafka code again. Implemented our own topic metadata retrieval.This closes #1039,5
KAFKA-2648: enforce non-empty group-ids in join-group requestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #362 from hachikuji/KAFKA-2648,5
[FLINK-25589][docs][connectors] Update Chinese version of Elasticsearch connector docs,2
[FLINK-25239][connector/jdbc] delete useless variables,1
[FLINK-21338][test] Relax ITCase naming constraints,3
[FLINK-11596][tests] Add ResourceManagerTaskExecutorTest#testDisconnectTaskExecutor,3
[FLINK-9256] [network] Fix NPE in SingleInputGate#updateInputChannel() for non-credit based flow controlThis closes #5914,2
"[hotfix] [build] Small improvements to the flink-mesos build  - The newer akka versions have no protobuf dependency and need no exclusion any more  - The transitive dependency promotion is ineffective here, disabling it makes    it more robust against accidentally pulling in more dependencies in the future  - Properly specifying the shaded dependencies is safer",1
[FLINK-16476] [table-planner-blink] Remove PowerMockito to avoid LinkageError in SelectivityEstimatorTest,3
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1370 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][hive] adapt HiveFunctionDefinitionFactory.createFunctionDefinition to latest APPI,3
Adjust the logic of Deployer to handle concurrent initialization (#9381)* Adjust the logic of Deployer to handle concurrent initialization* Fix the error of setting the initialized attribute under abnormal conditions of ConfigCenterConfig* Adjust the logic of Deployer to handle concurrent initialization* FIX UT* Restore the initialization of the module and replace some AtomicBoolean types with Boolean* Remove unused import* FIX* Update ConfigCenterConfigTest.java,5
Fixed AbstractObjectNode's #copyValueFrom(...).,0
[FLINK-2138] [streaming] Added docs and tests for partitioningCloses #872,3
"[FLINK-19084] Remove deprecated methods from ExecutionConfigThis commit removes deprecated, ineffective methods: - set/isFailTaskOnCheckpointError - disable/enableSysoutLogging - isLatencyTrackingEnabled",0
KAFKA-3435: Remove `Unstable` annotation from new Java ConsumerAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1113 from granthenke/remove-unstable,4
"解决如果多个类拥有相同的方法以及方法签名和返回值的情况下,会造成方法覆盖的问题感谢https://github.com/jessyZu 提出这个issue",0
[FLINK-16438][yarn] Introduce WorkerSpecContainerResourceAdapter for converting between Flink WorkerResourceSpec and Yarn container Resource in YarnResourceManager.,1
[FLINK-5488] Close YarnClient on error in AbstractYarnClusterDescriptorThis closes #4022.,0
MINOR: replace deprecated remove with delete (#5565)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"[FLINK-13766][task] Refactor the implementation of StreamInputProcessor based on PushingAsyncDataInput#emitNextThe current data processing in task input processor is based on the way of NullableAsyncDataInput#pollNext. In order tounify the processing stack for new source operator, we introduce the new PushingAsyncDataInput#emitNext(Output) instead.Then we need to adjust the existing implementations of StreamOneInputProcessor/StreamTwoInputProcessor based on this newway. To do so, we could integrate all the task inputs from network/source in a unified processor on runtime side.",1
"KAFKA-4223; RocksDBStore should close all open iterators on closeKeep track of open Rocks DB iterators. When a store is closed, close all open iterators.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1917 from dguy/kafka-4223",5
fix: invoker deactivation should be destroyed (#5858),0
[hotfix][docs-zh] Add known issues with Pulsar client under Java 11 to Chinese documentation.,2
Clean up Key generics and checkstyle errors.Fix various warnings.,2
[FLINK-14501] Make YarnClusterDescriptor initialization self-contained,5
[ml] Makes StandardScalers state package private and reduce redundant code. Adjusts flink-ml readme.,2
add license header for LogUtils file (#5272),2
support native image (#8234)* support native image* add annotations regarding native image,1
[FLINK-17027] Introduce a new Elasticsearch 7 connector with new property keys,5
"MINOR: refactor how ConfigurationControl checks for resource existence (#11835)ConfigurationControl methods should take a boolean indicating whether the resource is newlycreated, rather than taking an existence checker object. The boolean is easier to understand. Alsoadd a unit test of existing checking failing (and succeeding).Reviewers: Kirk True <kirk@mustardgrain.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"[FLINK-27121][docs-zh] Translate ""Configuration#overview"" paragraph and the code example in ""Application Development > Table API & SQL"" to Chinese. This closes #19435",5
[FLINK-24399][table-common] Improved DataType#getChildren javadocSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix] [Scala API] Simplify generics in EitherSerializer,0
"KAFKA-4935; Deprecate client checksum API and compute lazy partial checksum for magic v2Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3123 from hachikuji/KAFKA-4935",5
[FLINK-15274][docs]Added separate plugin page.Plugin page will be expanded in the future for connectors and other types.Central page to point someone who asks: what are plugins?,2
[FLINK-14157][e2e] Undo jaxb rellocations for java 8 in s3.,2
[FLINK-6809] [docs] Correct variable name in java side-output exampleThis closes #4047,2
[hotfix] Fix Scala 2.12 build,0
[FLINK-12834][table-planner-blink] Support CharType and BinaryTypeThis closes #8730,2
[hotfix][runtime] Remove redundant suppression,4
[FLINK-14834] Re-activate kerberized YARN on Docker tests,3
[FLINK-5093] Add proper shutdown of scheduled executor service in TimerService,1
"[FLINK-2306] Add support for named streams in Storm compatibility layer - enabled .declareStream() and connect via stream name - enabled multiplt output streams - added .split() / .select() / strip pattern - added helpers in new package utils - adapted and extended JUnit tests - adapted examplessome minor improvements (FlinkClient, integration of Tuple0)This closes #1011",2
"MINOR: release.py: fix some compatibility problems.Rather than using sed, use built-in Python regular expressions to stripthe SNAPSHOT expression from the pom.xml files.  Sed has different flagson different platforms, such as Linux.  Using Python directly here ismore compatible, as well as being more efficient, and not requiring anrm command afterwards.When running release_notes.py, use the current Python interpreter.This is needed to prevent attempting to run release_notes.py withPython 3 on some systems.  release_notes.py will not (yet) work withPython 3.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Magnus Edenhill <magnus@edenhill.se>, David Arthur <mumrah@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6198 from cmccabe/release_py",5
Removed outdated references to IOReadableWritable interface,5
"Turn Documentation into standalone website, add Overview PageThis can now be built standalone and then copied into the correct docsfolder of the website SVN.The index page now has a short overview and a table of contents.",2
"MINOR: add window verification to sliding-window co-group test (#10745)Reviewers: Luke Chen <showuon@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
[minor] Fix the test name of SourceReaderBaseTest.testPollNextReturnMoreAvailableWhenAllSplitFetcherCloseWithLeftoverElementInQueue.,3
[FLINK-26540][hive] Support handle join involving complex types in on conditionThis closes #19012,0
[FLINK-25940][python] Fix the unstable test test_keyed_process_function_with_state in PyFlinkThis closes #18742.,2
[FLINK-22881] Revert toggling IDLE/ACTIVE on records in IDLE stateThis closes #16095,4
Fix a typo in delegation.token.expiry.time.ms docs (#5449)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>,2
Reworked Nephele Mini Cluster to start more reliably.Fixed Local Executor.Fixed Bug in Delimited Input Formats.Reworked KMeans tests (both single step and iterative).Removed Pact Testing Framework for now.,1
[FLINK-21353][state/changelog] Implement batching,4
[hotfix][docs] Regenerate options,2
"KAFKA-12219: Add 'synchronized' keyword to InMemoryKeyValueStore#[reverseRange, reverseAll] (#9923)Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
Merge branch 'master' of https://www.stratosphere.eu/stratosphereConflicts:test,5
[FLINK-18907][test] Move MultipleInputStreamTaskChainedSourcesTest to MultipleInputStreamTaskTest,3
"[FLINK-18989][task] Remove non-sequental ChannelStateReader and the related code- ChannelStateReader and supporting classes- methods for channel state recovery in inputChannels, subpartitions, etc.- tests for reading channel state non-sequentially",3
DUBBO-382 修改测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1733 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[streaming] StreamRecord getters refactor,4
[FLINK-12490][network] Implement NetworkInput and use it in StreamInputProcessor,1
"[FLINK:27808][ha] Allow ""kubernetes"" as HA_MODE",1
DUBBO-616 javassist class loader 问题,5
[FLINK-6548] Fix AvroOutputFormatTest#testCompression on Windows,3
[FLINK-17303][python] Support Python TableResultThis closes #12009.,1
"KAFKA-5253: Fixed TopologyTestDriver to handle streams created with patterns (#4793)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-16921][e2e] Enable K8s tests,3
[FLINK-14762][client] Handle clients close gracefully,0
[FLINK-11362][tests] Port TaskManagerComponentsStartupShutdownTest to new code baseThis closes #7632.,1
"HOTFIX: Decrease commit intervalThe original commit interval of 30 seconds might be too large in some cases, e.g., when the verifier finishes before those 30 seconds have elapsed.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #1899 from enothereska/hotfix-smoke-test-commit-interval",3
"kafka-1318; waiting for producer to stop is not reliable in system tests; patched by Jun Rao; reviewed by Guozhang Wang, Timothy Chen and Neha Narkhede",3
[hotfix][rest] Remove the stale items in rest_v1_dispatcher,4
added processing of task latency back in,1
[FLINK-13511][kafka][build] Add test jaxb dependency,3
"[Dubbo-2678][For Master] Add ability to turn off SPI auto injection, special support for Object type.  (#2682)* Add ability to turn off SPI auto injection, special support for generic Object type injection.* Change Inject to AutoInject since it's main purpose is to turn off auto-injection.* disable is redundant in DisableInject annotation",4
[FLINK-1110] Add Collection-Based execution for Reduce OperatorsAlso fix some bugs resulting from moving stuff between packages,4
[FLINK-3524] [kafka] Add JSONDeserializationSchemaThis closes #1834,5
DUBBO-533 还原线程池缺省类型为fixed,0
fix #2619: is there a problem in NettyBackedChannelBuffer.setBytes(...)? (#3448),1
[FLINK-25159][tests] Disable broken E2E tests,3
"[FLINK-28060][Connector/Kafka] Updated Kafka Clients to 3.1.1 to resolve the issue where Flink is unable to commit its offset back to Kafka in case of Kafka Broker becoming unavailable. This should be resolved when the broker comes back up, but due to KAFKA-13563 that doesn't work. Since that fix has only become available with Kafka Clients 3.1.1, this commit updates the Kafka Clients dependency from 2.8.4 to 3.1.1.No interfaces needed to be adjusted.It was necessary to change some of our Bash e2e tests since they still relied on the Zookeeper parameter which has been removed in this version.The other necessary change was adjusting the KafkaConsumerTestBase class since the level of exception is changed in the new Kafka Clients so exception.getCause().getMessage()  throws an NPE in the test case.",3
[hotfix][docs][release] Update the building branch in workflowThis closes #20748.,1
[feature] publish ThreadPoolExhaustedEvent when thread pool exhausted (#5958)fix #5957,0
"Fix Javadoc links in documentationPreviously, it was pointing to release-1.7-SNAPSHOT where we don'tactually serve javadocs.Now we always point to master and have a dedicated variable for this soit can easily changed on release branches.",4
[FLINK-9743][client] Use correct zip path separator for nested jarsThis closes #6263.,1
[hotfix] [tests] Reduce visibility of helper class methodsThere is no need to make the helper methods public. No other classshould even use this inner test helper invokable.,3
"MINOR; Preserve ThrottlingQuotaExceededException when request timeouts after being retried due to a quota violation (KIP-599) (#9344)This PR adds the logic to preserve the ThrottlingQuotaExceededException when topics are retried. The throttleTimeMs is also adjusted accordingly as the request could remain pending or in-flight for quite a long time.Have run various tests on clusters with enabled quotas and I, indeed, find it better to preserve the exception. Otherwise, the caller does not really understand what is going on. This allows the caller to take the appropriate measure and also to take the throttleTimeMs into consideration.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: retry when deleting offsets for named topologies (#11604)When this was made I didn't expect deleteOffsetsResult to be set if an exception was thrown. But it is and to retry we need to reset it to null. Changing the KafkaStreamsNamedTopologyWrapper for remove topology when resetting offsets to retry upon GroupSubscribedToTopicException and swallow/complete upon GroupIdNotFoundExceptionReviewers: Anna Sophie Blee-Goldman <ableegoldman@ache.>,1
先不抛异常，避免Test代码里有多个dubbo.properties导致测试失败的问题。 参见 DUBBO-133 mvn eclipse:eclipse插件加强，排除依赖工程的Test目录的依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@656 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Avoid trace logging computation in `checkEnoughReplicasReachOffset``numAcks` is only used in the `trace` logging statement so it should be a `def` instead of a `val`. Also took the chance to improve the code and documentation a little.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1449 from ijuma/minor-avoid-trace-logging-computation-in-partition",2
"[hotfix][table-common] Add java docs to LogicalTypeMergingAdd more explanation in `LogicalTypeMerging#adjustPrecisionScale()` methodregarding the decision to not follow 100% the Microsoft's SQL Server rulesbut instead the Hive/Spark behaviour, when calculating the resulting precisionof a decimal operation.",2
[FLINK-10632][e2e] Running general purpose testing job with failure inper-job mode,0
[FLINK-26547][coordination] No requirement adjustments for unmatched slots,1
[FLINK-19733][python] Refactor fast_operation and slow_operation to make the produce functions consistentThis closes #13713.,1
[FLINK-19273][sql-parser] Support METADATA syntax in SQL parserUpdates the parser to accept METADATA syntax for columns and inthe LIKE clause. Reworks the class hierarchy of table columns.Introduces new keywords and grammar.This closes #13452.,1
2.7.6 Refactor + Enhancement (#5772)* Polish /apache/dubbo#5745 : Increasing the stack size in the start.sh* Polish /apache/dubbo#5297 : Only one of the multiple registration centers using nacos can register* Polish /apache/dubbo#5442 : VERSION_KEY和GROUP_KEY为空时，注册到NACOS的服务名与alibaba实现不一致，导致无法消费* Polish /apache/dubbo#5442 : Merge upstream/master* Polish /apache/dubbo##5239 : Mock字段注入异常* Polish /apache/dubbo##5239 : Mock字段注入异常* Polish /apache/dubbo#5770 : Removing the interinal JDK API from FileSystemDynamicConfiguration* Polish /apache/dubbo#5771 : [Enhancement] Refactor the APT test-cases implementation of dubbo-metadata-processor in Java 9+* Bugfix for the test-cases,3
[FLINK-1687] [streaming] [api-extending] Synchronizing streaming source API to batch source APICloses #521,2
修改FastJson对异常的处理git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@627 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix] [tests] Simplify JobMasterTest,3
"[FLINK-2429] [streaming] Deprecate the ""enableCheckpointing()"" method with no interval argument.This closes #1382",0
[MINOR] Update upgrade documentation for 3.2 (#12055)Reviewer: Bruno Cadonna <cadonna@apache.org>,1
[FLINK-19637][coordination][tests] Remove AllocationIdsExposingRMGateway,4
[streaming] StreamCollector added,1
"KAFKA-8066; Always close the sensors in Selector.close() (#6402)When shutting down the ReplicaFetcher thread, we may fail to unregister sensors in selector.close(). When that happened, we will fail to start up the ReplicaFetcherThread with the same fetch id again because of the IllegalArgumentException in sensor registration. This issue will cause constant URPs in the cluster because the ReplicaFetchterThread is gone.This patch addresses this issue by introducing a try-finally block in selector.close() so that we will always unregister the sensors in shutting down ReplicaFetcherThreads.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-8219: add doc changes for static membership release (#6790)* add doc changes for static membership release* address comments* address comments for a separate page* address Matthias' comment,1
[FLINK-13159] Fix incorrect subclass serializer reconfiguration in PojoSerializer,5
"HOTFIX: Task#dirtyClose should not throw (#8258)We need to swallow exceptions from StateManagerUtil#close in dirtyClose for both active and standby tasks.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
HOTFIX: Add missing template ref in upgrade section,1
"MINOR: Upgrade jetty to 9.4.27.v20200227 and jersey to 2.31 (#8859)Upgrade jetty to 9.4.27.v20200227 and jersey to 2.31Also remove the workaround used on previous versions from Connect's SSLUtils. (Reverts KAFKA-9771 - commit ee832d7d)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
Added missing files,2
[FLINK-25769][table] Introduce internal and versioned built-in functions,1
"KAFKA-13630: Reduce amount of time that producer network thread holds batch queue lock (#11722)Hold the `deque` lock for only as long as is required to collect and make a decision in`ready()` and `drain()` loops. Once this is done, remaining work can be done without lock,so release it. This allows producers to continue appending.For an application with with a single producer thread and a high send() rate, this changereduces spinlock CPU cycles from 14.6% to 2.5% of the send() path, or moreclearly a 12.1% improvement in efficiency for the send() path by reducing the duration ofcontention events with the network thread. Note that this application was executed withJava 8, which has a slower crc32c implementation.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Artem Livshits <84364232+artemlivshits@users.noreply.github.com>",1
[FLINK-9131][travis] Disable spotbugs plugin,0
"[hotfix][task,test] Add missing test coverage for pretty mailbox exceptions",3
KAFKA-10776: Add version attribute in RequestsPerSec metrics documentation (#9661)See https://cwiki.apache.org/confluence/display/KAFKA/KIP-272%3A+Add+API+version+tag+to+broker%27s+RequestsPerSec+metricReviewers: Ismael Juma <ismael@juma.me.uk>,5
"[FLINK-18930][docs-zh] Translate ""Hive Dialect"" page of ""Hive Integration"" into ChineseThis closes #13176",1
Fixed #691 本地伪装在provider为空的情况下无法执行,1
[hotfix][runtime] Rename SchedulerTestingUtils#createScheduler(...) to createSchedulerBuilder(...) because it returns a builder,1
Simple fix to respect return value return by File APIs.,2
[streaming] Licensing added,1
[FLINK-10899] Remove explicit version tag from flink-metrics-availability-test and flink-metrics-reporter-prometheus-test,3
[FLINK-20250][table-runtime] Fix NPE when invoking AsyncLookupJoinRunner#close methodThis closes #14207,1
[FLINK-17393][connectors] Wakeup the SplitFetchers more elegantly.This closes #13366,2
[FLINK-18194][walkthroughs] Document new table walkthroughThis closes #12592,1
"MINOR: Increase Throttle lower bound assertion in throttling_testImproves the reliability of this test by decreasing the lower bound (this is to be expected as throttling  takes the first fetch to stabilise and will ""over-fetch"" for this first request)Author: Ben Stopford <benstopford@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2698 from benstopford/throttling-test-fix",3
[hotfix] Fix JUnit 5 mini cluster arch unit rules,5
implemented annotaions for tasks,5
[hotfix][yarn][test] Avoid using Mockito for AMRMClientAsync in YarnResourceManagerTest.,3
[FLINK-13219][hive] Disable tests for hadoop 2.4 profile,2
[FLINK-10631] Set number of slots per TM to 3 for Jepsen tests,3
[FLINK-21088][runtime][checkpoint] Assign a finished snapshot to task if operators are all finished on restore,5
[FLINK-10935][kubernetes] Add fabric8 kubeClient implementation and decorators.The Fabric8FlinkKubeClient will be used to interact with Kubernetes API server to create/delete resources and get the status. The decorators will be used to build the complete Kubernetes resource description.This closes #9965 .,1
[storm-compat] Added tests for Storm compatibility API,3
[FLINK-7603] [docs] Update documentation with WITHIN clause for MATCH_RECOGNIZEThis closes #7187.,1
Fixed erroneous propagation of messages for Spargel.,0
[FLINK-20928] Fix flaky test by retrying notifyCheckpointComplete until either commit success or timeout,1
"[FLINK-25227][table-planner] Fix LEAST/GREATEST to return primitivesPreviously, `LEAST` and `GREATEST` functions would return primitivetypes in the generated code implementing their logic, producing issuesfor operators applied on top of them, and most importantly comparisonoperators, i.e.:```f0 INT, f1 INTSELECT GREATEST(f0, f1) = GREATEST(f0, f1)```would return `FALSE`, since the generated code would return `Integer`instead of `int`, as the result of `GREATEST`, and the `=` operatoron `Integer` objects would return false, even if the actual integervalue of them was the same.",1
[FLINK-19924][config] Disallow Unaligned Checkpoints for iterative jobs by default,1
Changed API of of local buffer pool owner,4
Added graph utility class for DAG rewriting,2
fix #2600 add javadoc-plugin to dubbo-all module (#2604),2
code format (#2730)* NullPointerException* code rule* code rule,5
[FLINK-14210][metrics][influxdb] Make timeouts configurable,5
"KAFKA-8407: Fix validation of class and list configs in connector client overrides (#6789)Because of how config values are converted into strings in the `AbstractHerder.validateClientOverrides()` method after being validated by the client override policy, an exception is thrown if the value returned by the policy isn't already parsed as the type expected by the client `ConfigDef`. The fix here involves parsing client override properties before passing them to the override policy.A unit test is added to ensure that several different types of configs are validated properly by the herder.Author: Chris Egerton <chrise@confluent.io>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
[hotfix] Fix loading of wrong TaskManager class,0
[hotfix] [tests] Increase timeout for AkkaRpcActorTest to mitigate occasional CI test timeouts,3
[FLINK-16832][metrics] Refactor ReporterSetupIntroduce methods for better readibility.,1
"[FLINK-16169][tests] Harden BlobServerRangeTestThe test is unreliable since there is no guarantee that the ""availablePort"" is still available then the blob server starts.",3
"KAFKA-10027: Implement read path for feature versioning system (KIP-584) (#8680)In this PR, I have implemented various classes and integration for the read path of the feature versioning system (KIP-584). The ultimate plan is that the cluster-wide finalized features information is going to be stored in ZK under the node /feature. The read path implemented in this PR is centered around reading this finalized features information from ZK, and, processing it inside the Broker.Here is a summary of what's in this PR (a lot of it is new classes):A facility is provided in the broker to declare its supported features, and advertise its supported features via its own BrokerIdZNode under a features key.A facility is provided in the broker to listen to and propagate cluster-wide finalized feature changes from ZK.When new finalized features are read from ZK, feature incompatibilities are detected by comparing against the broker's own supported features.ApiVersionsResponse is now served containing supported and finalized feature information (using the newly added tagged fields).Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-829 Mirror maker needs to share the migration tool request channel; reviewed by Jun Rao,1
[hotfix][python] Use StreamExecutionEnvironment.getConfiguration to access configuration,5
[FLINK-17050][runtime] Remove methods getVertex() and getResultPartition()Remove methods- SchedulingTopology#getVertex(ExecutionVertexID);- SchedulingTopology#getResultPartition(IntermediateResultPartitionID);,2
Fixed test plan for tests without expected values,3
[FLINK-11843] Add test case for FLINK-11843DispatcherRunnerImplTest#testJobRecoveryUnderLeaderChange fails onlyoccasionally.,0
[FLINK-28163][sql-gateway]Introduce the statement related API for REST endpointThis closes #20451,2
"[FLINK-10772][release] Fix create_binary_release.shRemove the unnecessary call to change_scala_version.sh and remove the-Dmaven.test.skip=true property. The latter is necessary because thisproperty suppresses the compilation and packaging of test classes. It,however, does not suppress the resolution of test dependencies whichwill then fail to compile because test dependencies have not been built.This commit also removes the redundant call to buildflink-shaded/hadoop/flink-shaded-hadoop2-uber which is a dependencyof flink-dist anyway.",2
Fixed POM files and removed some unused imports,2
[hotfix][doc] update document since ParquetAvroWriters has been deprecated and replaced by AvroParquetWriters.,2
Temp.,5
[FLINK-25601][state][config] Update the 'state.backend' option,5
[FLINK-21482][table-planner-blink] Support grouping set syntax for Window TVF based aggregationThis closes #15003,1
add some files list exclude license check (#4318)Signed-off-by: jimin.jm <slievrly@163.com>,2
kafka-1320; Change compression.codec to compression.type in new producer configs of system tests; patched by Guozhang Wang; reviewed by Jun Rao,3
[hotfix] Clean up ExecutionGraph- Remove unnecessary throws clause.- Format whitespace.,1
[FLINK-13972] Remove PackagedProgram#getPreviewPlan(),1
[FLINK-2919] Port FieldAccessMinibenchmark to JMH.This closes #1300,5
[FLINK-3597][tableAPI] Set relational expressions as DataSet operator names.,1
[hotfix][tests] Fix tests for jepsen.flink.generator/inc-by-factor,2
[FLINK-5168] Scaladoc annotation link use [[]] instead of {@link}This closes #2875,2
[FLINK-11693] Add KafkaSerializationSchema that uses ProducerRecord,1
"KAFKA-10793: move handling of FindCoordinatorFuture to fix race condition (#9671)Fixes a tricky race condition between the consumer and hb thread can lead to a failed but non-null findCoordinatorFuture, causing the AbstractCoordinator to wait endlessly on the request which it thinks is still in flight. We should move the handling of this future out of the listener callbacks and into the ensureCoordinatorReady() method where we can check the exception and clear the future all in one place.Reviewers: Guozhang Wang <guozhang@confluent.io>",5
Converted input formats for tpch tests,3
"[FLINK-23911][table-planner] Apply metadata spec even if no metadata were usedInitially a table source is instantiated and #applyReadableMetadata iscalled with all metadata declared in the table's schema. During theprojection pushdown we copy the table source and call #applyReadableMetadatawith only those metadata that are actually used, allowing the source toonly produce metadata which are actually required.If we skip this step if no metadata columns are used, the source continuesto believe that all (declared) metadata are required. This producesunnecessary work.This closes #16956.",1
Simplified naming scheme of file buffers,2
Fix for quickstart versions,0
Bump version to 2.6.2-SNAPSHOT,5
"[FLINK-3824] ResourceManager may repeatedly connect to outdated JobManagerWhen the ResourceManager receives a new leading JobManager via theLeaderRetrievalService it tries to register with this JobManager untilconnected. If during registration a new leader gets elected, theResourceManager may still repeatedly try to register with the oldone. This doesn't affect the registration with the new JobManager butleaves error messages in the log file and may process unnecessarymessages.",2
删除无用包git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1136 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[hotfix] Minor cleanup of warnings, comments, and code style in the Java API Utils",2
DUBBO-402 开源http协议支持timeout和client属性配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1978 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-7714][flip6] Implement JarPlanHandlerThis closes #5533.,0
[FLINK-21078] Add DeclarativeSlotPoolService which encapsulates a DeclarativeSlotPoolThis commit adds the DeclarativeSlotPoolService which makes a DeclarativeSlotPool usablewith the JobMaster.,1
[FLINK-12143] PluginLoader: use system level always parents first patterns in class loading,5
[FLINK-1296] [runtime] Fix bug when large record handling results in empty spill files,2
[FLINK-14134][table-common] Introduce LimitableTableSource for optimizing limit,2
more coerce refactoring,4
KAFKA-1251 Missed one per-node metric.,5
[FLINK-22774][sql-connector-kinesis] Update Kinesis SQL connector's Guava to 27.0-jreAvoids that security tools complain about an outdated Guava version in the KinesisSQL connector.This closes #16005.,5
[streaming] performance test scripts updated,5
[hotfix] Rename JobManagerProcessUtils#processSpecFromConfigWithFallbackForLegacyHeap to processSpecFromConfigAndFallbackToNewOptIfLegacyHeapSet,5
"KAFKA-4432; Added support to supply custom message payloads to perf-producer script.Current implementation of ProducerPerformance creates static payload. This is not very useful in testing compression or when you want to test with production/custom payloads. So, we decided to add support for providing payload file as an input to producer perf test script.We made the following changes:1. Added support to provide a payload file which can have the list of payloads that you actually want to send.2. Moved payload generation inside the send loop for cases when payload file is provided.Following are the changes to how the producer-performance is evoked:1. You must provide ""--record-size"" or ""--payload-file"" but not both. This is because, record size cannot be guaranteed when you are using custom events.  e.g. ./kafka-producer-perf-test.sh --topic test_topic --num-records 100000 --producer-props bootstrap.servers=127.0.0.1:9092 acks=0 buffer.memory=33554432 compression.type=gzip batch.size=10240 linger.ms=10 --throughput -1 --payload-file ./test_payloads --payload-delimiter ,2. Earlier ""--record-size"" was a required config, now you must provide exactly one of ""--record-size"" or ""--payload-file"". Providing both will result in an error.3. Support for an additional parameter ""--payload-delimiter"" has been added which defaults to ""\n""Author: Sandesh K <sandesh.karkera@flipkart.com>Reviewers: dan norwood <norwood@confluent.io>, Jun Rao <junrao@gmail.com>Closes #2158 from SandeshKarkera/PerfProducerChanges",4
"KAFKA-7824; Require member.id for initial join group request [KIP-394] (#6058)This patch implements KIP-394 as documented in https://cwiki.apache.org/confluence/display/KAFKA/KIP-394%3A+Require+member.id+for+initial+join+group+request.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-5558] [gelly] Replace TriangleCount with a Count analyticTriangleCount can be replaced by a generic Count analytic for DataSet.The analytics currently using TriangleCount can simply useTriangleListing and Count.Gelly includes both directed and undirected versions of TriangleListingand therefore two versions of TriangleCount which will be replaced by asingle Count analytic which can be reused elsewhere.This closes #3169,1
[FLINK-19933][DataStream] Execute and collect with limit fails on bounded datastream jobsThis closes #13893,5
remove some magic value (#4752)* fixed typo of variable* remove magic value,4
- Fixed JavaDocs in pact-common/../type/base/PactDouble.java,2
[FLINK-16440][core] Introduce multiplication for Resource.,2
[FLINK-15635][table] Propagate ClassLoader whenever is appropriateSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix] Refactors PackagedProgram.extractContainedLibraries(),4
KAFKA-622 Create mbeans per client; patched by Swapnil; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415021 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-5745] [runtime] Extract ExecutorThreadFactory#FatalExitExceptionHandlerMake it a top-level class so that it can be re-used.,1
"MINOR: Remove redundant `if` condition. (#5697)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
add config for travis ci fail when test case fail (#1264)* add config for travis ci fail when test case fail,0
fix a potential NPE in CallbackServiceCodec.java. (#5768),0
[FLINK-4144] Yarn properties file: replace hostname/port with Yarn application idThis closes #2191,2
"[hotfix][docs] Fix link to latency granularity in ""Metrics"" page (#10751)",2
"KAFKA-5646; Use KafkaZkClient in DynamicConfigManager and AdminManager* Add AdminZkClient class* Use KafkaZkClient, AdminZkClient  in ConfigCommand, TopicCommand* All the existing tests should workAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #4194 from omkreddy/KAFKA-5646-ZK-ADMIN-UTILS-DYNAMIC-MANAGER",1
[FLINK-27968][e2e] Fix PlannerScalaFreeITCase- only run the test in e2e profile- remove unnecessary dependencies,4
KAFKA-2313: javadoc fix for KafkaConsumer deserialization; reviewed by Guozhang Wang,0
"[FLINK-20461][tests] Check replication factor before asking for JobResultThis commit hardens the YARNFileReplicationITCase by checking the replication factor beforeasking for the JobResult. If done in the reverse order, then it can happen that the Flink applicationhas already terminated before doing the file replication check because the per-job mode has alreadydelivered the JobResult.This closes #16917.",1
[FLINK-26440][connector/filesystem] Make CompactorOperatorStateHandler supporting unaligned checkpoint.This closes #18955.,1
override router chain builder,5
[FLINK-22107][hive] Include antlr into hive connector uber jars (#15492),2
"[FLINK-19660][docs-zh][python] Translate page ""table_environment.zh.md"" into ChineseThis closes #13672.",1
refactored assertion in JsonNodeWrapperParameterizedTest >> shouldCreateDifferentNormalizedKeys() to be more readable,1
more hacking and cleaning,4
[FLINK-1652] fixes superstep increment in CollectionExecutorThis closes #464,0
[FLINK-8575][runtime] Add missing synchronization in BackPressureStatsTrackerMake triggerStackTraceSampleInternal private again and add locking totriggerStackTraceSample.This closes #5422.,1
"[FLINK-5020] Make the GenericWriteAheadSink rescalable.Integrates the new state abstractions with the GenericWriteAheadSinkso that the latter can change its parallelism when resuming executionfrom a savepoint, without geopardizing the provided guarantees.This closes #2759",1
[FLINK-6163] Document per-window state in ProcessWindowFunction,1
updated CONTRIBUTORS file,2
Fix nacos group inviable in consumer side (#8533)* Fix nacos group inviable in consumer side* remove getGroup method,1
"[FLINK-10342] [kafka] Filter restored partitions in FlinkKafkaConsumer with topics descriptorThis commit lets the FlinkKafkaConsumer filter out restoreed partition'soffsets that are no longer associated with the current list of specifictopics / topic pattern to subscribe to.This changes the previous default behaviour of the FlinkKafkaConsumer,which always respected the complete list of restored partitions,regardless of the specified topics to subscribe to.As a fallback, a setter configuration method is added to allow disablingthe filter behavior.",1
Fixed instantiation of utility combine node to use the correct properties.,1
MINOR: Use port 0 in ResetIntegrationWithSslTestI found this by running the tests while I happened tohave a kafka broker running.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4065 from tombentley/MINOR-random-port,1
[FLINK-6462] [table] Add requiresOver method to AggregateFunction.This closes #3851.,1
[3.0] Improve compressed URL param performance (#10125),2
"KAFKA-4801: don't verify assignment during broker up and down in testConsumptionWithBrokerFailures (#11949)In this test, we have another thread to let broker down and up, to test if consumer can still work as expected. During the broker down and up, we tried to verify the assignment is as what we expected. But the rebalance will keep triggering while broker down and up. It doesn't make sense to verify the assignment here. Remove it to make the test reliable.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
Adjusted sopremo base to last changes in sopremo common,4
"Merge pull request #3626, remove author.",4
- added missing Apache Headers,1
merge issue 1401 to 2.5.x (#1460)* merge issue 1401 to 2.5.x* modify* sync test case from master,3
[FLINK-4776] [distributed coordination] Move ExecutionGraph initialization into the dedicated class ExecutionGraphBuilder,5
修改注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@802 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Reworked examples.Implemented custom aggregators (runtime misses iteration head task),1
Minor improvements on GroupReduceITCase (tests for group sorting),3
[Bugfix] Resolve the issues about the demos using DubboBootstrap (#5314)* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5309 : [ISSURE] The beans of Dubbo's Config can't be found on the ReferenceBean's initialization* Polish apache/dubbo#5312 : Resolve the demos' issues of zookeeper and nacos* Polish apache/dubbo#5313 : [Migration] migrate the code in common module from cloud-native branch to master,1
[FLINK-9464] Remove version and scope from flink-test-utils-junit and maven-shade-plugin in flink-swift-fs-hadoop pom.xml,5
Include payload size in DumpLogSegments; patched by Chris Burroughs; reviewed by Jun Rao; KAFKA-152git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1181329 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-917] Rename netty IO thread count parameters,2
[hotfix] Harden TaskExecutorTest#testSyncSlotsWithJobMasterByHeartbeatThe problem was that we don't wait until the JobMaster has sent its response backto the TaskExecutor when it receives the offered slots and before we send theheartbeat response with the AllocatedSlotReport. This commit fixes the problemby instrumenting the TaskSlotTable to notify the test when all slots are markedas active.,3
"KAFKA-10636; Bypass log validation and offset assignment for writes from the raft leader (#9739)Since the Raft leader is already doing the work of assigning offsets and the leader epoch, we can skip the same logic in `Log.appendAsLeader`. This lets us avoid an unnecessary round of decompression.Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-2453] [docs] Update README and setup docs to reflect requirement for Java 7+,1
"KAFKA-10362: When resuming Streams active task with EOS, the checkpoint file is deleted (#9247)Deleted the checkpoint file before the transition from SUSPENDED state to RESTORING stateReviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-4044; log actual socket send/receive buffer size after connecting in SelectorAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1750 from omkreddy/KAFKA-4044-LOG,2
Create UnionNode in optimized plan when contract has more than onepredecessor per input,1
added html as cobertura output,1
only process context event of current context (#9637),5
[hotfix] [streaming api] Add proper deprecation JavaDocsAlso includes minor style cleanup of a test.,3
"[FLINK-2473] [core] Add a timeout to akka actorsystem shutdown.This works around a bug in akka where the ""awaitTermination()"" call freezes indefinitely.",5
[FLINK-9467][metrics][WebUI] Fix watermark displayThis closes #6152.,0
Added logging for multicast experiments,2
[FLINK-20053][table][doc] Add document for file compactionThis closes #13990,2
"more objectschema implementation, fixed tests",3
[FLINK-22016][table-planner-blink] RexNodeExtractor#visitLiteral should deal with NULL literals correctly (#15570),4
[streaming] pom refactor,4
MINOR: Remove unnecessary semicolon in NetworkClient (#9853)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
Fixing the perf subproject that broker after the sbt upgrade,0
Verify local reference for the creation of a local invoker process (#8592)* verify create local invoker* fix* fix* fix injvm protocol,0
[FLINK-13450][table api] Use StrictMath instead of Math for some expressionsThis ensures cross architecture compatibility of results.This closes #9681,1
feat: add triple demo (#7540),1
changed restarting. added new test with annotations,3
[FLINK-2418] [streaming] Add an end-to-end exactly-once test for Checkpointed functions.,1
"KAFKA-14107: Upgrade Jetty version for CVE fixes (#12440)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Aaron Freeland <afreeland@gmail.com>",0
KAFKA-644 https://svn.apache.org/repos/asf/kafka/branches/0.8; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418545 13f79535-47bb-0310-9956-ffa450edef68,2
[FLINK-9601][state] Make sure that the copied array in `CopyOnWriteStateTable#snapshotTableArrays()` is big enough to hold all (flattened) entriesThis closes #6174.,3
"KAFKA-3459: Returning zero task configurations from a connector does not properly clean up existing taskshachikuji ewencp Can you take a look when you have time?Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1248 from Ishiihara/kafka-3459",5
[FLINK-26758][container] Migrate tests to JUnit 5,3
"KAFKA-12933: Flaky test ReassignPartitionsIntegrationTest.testReassignmentWithAlterIsrDisabled (#11244)Removes assertion added in #10471. It's unsafe to assert thatthere are partition movements ongoing for some of the tests inthe suite because partitions in some of the tests have 0 data,which may complete reassignment before `verify` can run.Tests pass locally.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
[tests] Improve Kafka concurrent produce/consumer test by allowing retries when connecting to non-leader broker.,1
"[FLINK-3009] Add dockerized jekyll environmentThis is not to fulfill what FLINK-3009 is originally asking,but I'm piggybacking to contribute a docker environment with jekyllso that users won't have to deal with environment versions.Author: Jun Aoki <jaoki@apache.org>Author: jaoki <jaoki@apache.org>Closes #1363 from jaoki/dockerized-docgen and squashes the following commits:7bf3661 [Jun Aoki] Added apache label36869e7 [jaoki] [FLINK-3009] Add dockerized jekyll environment",2
"[hotfix][build] Add safeguards against rebranded jaxb-api/javax.activation-api dependenciesWith jakarta EE having made their first releases projects may start transitioning to the re-branded versions.The package names are identical (for now?), so we should be fine as long as we ensure that at least one version is on the classpath.For the time being we stay on the ""original"" dependencies, but we may have to switch eventually.",1
No explicit caching when hash table is cachedAdd tests for explicit cache removal when hash table is cached,4
removed test-jar from sopremo pom,3
"KAFKA-7324: NPE due to lack of SASLExtensions in SASL/OAUTHBEARER (#5552)Set empty extensions if null is passed in.Reviewers: Satish Duggana <sduggana@hortonworks.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-1371] [runtime] Fix KryoSerializer to not swallow EOFExceptions,1
[streaming] [scala] Revert removing getJavaStream() from DataStream,5
Simplified and fixed estimate computation.,0
[hotfix] Move YarnTestBase#waitUntilCondition into runtime.CommonTestUtils,3
Only read the sysctl that is used on Mac OS X,1
"KAFKA-7979 - Clean up threads and increase timeout in PartitionTest (#6378)Stack trace generated from the test failure shows that test failed even though threads were runnable and making progress, indicating that the timeout may be too small when test machine is slow. Increasing timeout from 10 to 15 seconds, consistent with the default wait in other tests. Thread dump also showed a lot of left over threads from other tests, so added clean up of those as well.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
Refactored meteor grammer; now without backtracking,4
Replaced the JobClient by an actor.,5
[FLINK-18936][docs] Update documentation around aggregate functionsThis closes #13143.,1
[FLINK-19193] Recommend stop-with-savepoint in upgrade guidelines,2
[FLINK-18667][docs] Data types documentation misunderstand usersThis closes #12976,1
DUBBO-521 调用SpringApplicationContext的refresh时出错,5
"[FLINK-20694][coordination] Extend slot pool logging- log total acquired resources when declaring requirements, or after accepting new / releasing idle slots- log if an offer could not be matched to any requirement",1
[FLINK-20978] Implement HeapSavepointRestoreOperationThis commit implements the logic of restoring a heap keyed state backendfrom a savepoint in a unified binary format. It eagerly deserializes allstates and populates the in memory structures.,2
"KAFKA-14078; Do leader/epoch validation in Fetch before checking for valid replica (#12411)After the fix for https://github.com/apache/kafka/pull/12150, if a follower receives a request from another replica, it will return UNKNOWN_LEADER_EPOCH even if the leader epoch matches. We need to do epoch leader/epoch validation first before we check whether we have a valid replica.Reviewers: David Jacot <djacot@confluent.io>",5
[FLINK-2214] [ml] Fixes prediction join operation and empirical risk join operation of ALS by giving join hintThis closes #844.,0
"[hotfix][coordination] Add getters of AllocationID, JobID and SlotState in TaskManagerSlotInformation",5
"[FLINK-6608] [security, config] Relax Kerberos login contexts parsingThis closes #3928.",2
"Improve JavaDoc (#9594)In the JavaDoc, the implemented interface was described inaccurately.Also, the ordered list was formatted as plain text, not as html ""ol"".Reviewers: Boyang Chen <boyang@confluent.io>",5
Destroy ServiceInstancesChangedListener (#9161),4
[Dubbo-936]fix The nc command is unstable in the dubbo startup script #936 (#3375)* fix dubbo启动脚本中nc命令不稳定 #936* modify,0
[hotfix] [doc] Incorrect example CLI command for Flink on Mesos,2
DUBBO-71 Graceful shutdown-半关闭状态git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@335 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-20647][python] Use yield to generate output data in ProcessFunction of Python DataStream APIThis closes #14414.,5
upgrade grpc gen version (#8101),5
"[hotfix][DataStream API] Fix style and warnings for CollectSinkOperatorFactoryIn particular, avoid raw types and do not generate compiler warnings, as per the Flinkcodeing style guide.",2
[FLINK-12346][travis][build] Account for timestamps in scala-suffix check,0
"KAFKA-3088; Make client-id a nullable string and fix handling of invalid requests.""…ent ID- Adds  NULLABLE_STRING Type to the protocol- Changes client_id in the REQUEST_HEADER to NULLABLE_STRING with a default of """"- Fixes server handling of invalid ApiKey request and other invalid requestsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>Closes #866 from granthenke/null-clientid",0
"Add log message in release.py (#8461)When building a release candidate with release.py, if it's not the first RC, we need to drop the previous RC's artifacts from the staging repository before closing the new ones. This adds a log message to remind the release manager of this",2
[FLINK-22475][table-common] Document usage of '#' placeholder in option keys,2
"KAFKA-5671: Add StreamsBuilder and Deprecate KStreamBuilderAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3602 from mjsax/kafka-5671-add-streamsbuilder",1
MINOR: Update Jackson to 2.9.5 (#4776),5
[FLINK-18759][tests] Add readme.md for TPC-DS tools (#13283)[FLINK-18759][tests] Add readme.md for TPC-DS tools,2
"Revert ""KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede""This reverts commit de432a09e632f78df9e580b51277f81582c3f026.",4
[FLINK-28105][Tests] test the copied object in GlobFilePathFilterTest#testGlobFilterSerializable,3
[FLINK-14074][mesos] Forward configuration to Mesos TaskExecutorThis commit forwards the Flink configuration to a Mesos TaskExecutor bycreating the ContainerSpecification with it. This will forward all optionswhich are dynamically configured until the ResourceManager has been startedto the Mesos TaskExecutor.This closes #10002.,5
修改注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1201 1a56cb94-b969-4eaa-88fa-be21384802f2,1
add openjdk to travis (#3300)* add openjdk to travis* add openjdk to travis,1
[FLINK-17854][core] Let SourceReader use InputStatus directly,1
added some testcases for reusage of target nodes in BatchAggregationExpressionTest and ObjectCreationTest;exceptions while reuse target nodes are now handled in SopremoUtil.reuseTarget;PrimitiveNodes are now only cleared with .clear() if SopremoUtil.DEBUG is set to true;,1
[hotfix][k8s] Use constant logging variable to replace constant strings,2
[FLINK-14745] Add dependencies of job as list of URLs in config,5
[FLINK-1415] [runtime] Clean up archiving of ExecutionGraphs,4
KAFKA-7347; Return not leader error for OffsetsForLeaderEpoch requests to non-replicas (#5576)The broker should return NOT_LEADER_FOR_PARTITION for OffsetsForLeaderEpoch requests against non-replicas instead of UNKNOWN_TOPIC_OR_PARTITION. This patch also fixes a minor bug in the handling of ListOffsets request using the DEBUG replica id. We should return UNKNOWN_TOPIC_OR_PARTITION if the topic doesn't exist.Reviewers: Jun Rao <junrao@gmail.com>,0
Minor format changes,4
[tools] Update copy files function in release script- people.apache.org has moved to home.apache.org- rsync currently not supported,1
[hotfix][table] Refactor DataGen source to use LogicalTypeVisitor pattern,2
"MINOR: Update JavaDoc for DSL PAPI-APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2413 from mjsax/javaDocImprovements6",2
[FLINK-8676] Ensure key stream is closed after backend#applyToAllKeys().This closes #5513.,2
DUBBO-202 修改override一起的ci问题主要原因：RegistryProtocol export如果providerUrl一样即使registryUrl不同，也处理为不再重新注册git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1024 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Improvements on Streams log4j1. add thread id as prefix in state directory classes; also added logs for lock activities.2. add logging for task creation / suspension.3. add more information in rebalance listener logging.4. add restored number of records into changlog reader.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Damian Guy, Ewen Cheslack-PostavaCloses #2702 from guozhangwang/KMinor-streams-task-creation-log4j-improvements",2
"[hotfix] Harden TaskExecutorTest#testSlotAcceptanceThe test did not properly wait for the registration of the TaskExecutor at theResourceManager. Therefore, it could come to a race condition between sendingan initial SlotReport and a separate message for the newly added slots.",1
[3.0-tri-compiler] dubbo compiler support stream (#8566),1
"KAFKA-13296: warn if previous assignment has duplicate partitions (#11347)Reviewers: Matthias J. Sax <matthias@confluent.io>, Luke Chen <showuon@gmail.com>",5
Fixed compilation error on jenkins,0
修改zookeeper异常信息git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@523 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-10803: Fix improper removal of bad dynamic config (#9682)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
KAFKA-1910; missed follow-up changes,4
DUBBO-589 在设置Router之前先对Router排序,5
[FLINK-9360][tests] Reduce sleep to 30 seconds,3
[hotfix][table-common] Fix InternalDataUtils for MapData tests,3
Added global event sequence number,1
[hotfix] [clients] Replace test IP with reserved address,1
KAFKA-1147 Consumer socket timeout should be greater than fetch max wait; reviewed by Neha Narkhede and Jun Rao,5
[FLINK-9236] [build] upgrade the version of apache parent pom from 18 to 20This closes #6378.,2
KAFKA-307 Refactor server code to reduce interdependencies; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1304473 13f79535-47bb-0310-9956-ffa450edef68,4
enhance configuration api (#5774),5
[FLINK-6865] Update checkstyle documentation,2
[hotfix][TE] Remove redundant HeartbeatManager calls,4
Upgrade webx version to fix dubbo-admin incompatible problem when running with jdk1.8,1
"[FLINK-26092][table-runtime] Fix `JSON_OBJECTAGG` when emitting `NULL`Previously, when the Json aggregation is taking place, and idJsonOnNull.NULL is selected, which means that we still want to emita `null` JSON node, .i.e `{.... ""myField"" : null ... }` when no valuesget accumulated, we used a null `StringData` object. When`state.backend.changelog.enabled` is enabled, the contents of the mapaccumulating the aggregated records, gets serialized leading to NPE,since `null` is not supported by `StringDataSerilizer`.To solve this, we instead create a StringData with an empty `byte[]`,which denotes the null, and when the aggregation ends and we createthe final JSON result, we check for a `byte[]` of `length` `0` inorder to write the JSON `null` node.",5
KAFKA-974 can't use public release maven repo because of failure of downloaded dependency,0
"KAFKA-8456: Stabilize flaky StoreUpgradeIntegrationTest (#6941)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
kafka-1301; system testcase_0206 fails using the new producer; patched by Jun Rao; reviewed by Jay Kreps,1
[FLINK-10565][tests] Refactor SchedulerTestBase to remove legacy code pathsThis closes #6856.,4
修改测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@719 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-17375] Move azure_controller into azure-pipelines folder,4
PreferredReplicaLeaderElectionCommand has command line error; patched by Jun Rao; reviewed by Maxime Brugidou; kafka-743,0
Update Hessian Lite Version (#9326),5
[FLINK-25372] Add thread dump feature for jobmanager on Web UIThis closes #18148,1
DUBBO-292 修改monitorfilter提供者判断逻辑git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1291 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fixed problem with FQDN in instance connection info,5
OutputFormat unit test discard existing temp files by default.,2
Fix: Filter GP and LP when DoP changes over a connection,4
[FLINK-14086][core] Add OperatingArchitecture Enum,1
Add Netty to License files[ci skip],2
[hotfix] Fix time-micros and timestamp-micros handling,0
[hotfix][runtime] Fix typo in IOManagerAsync,2
KAFKA-1812 Allow IpV6 in configuration with parseCsvMap patch by Jeff Holoman reviewed by Gwen Shapira and Joe Stein,5
[FLINK-19098][json][csv] Make RowData CSV and JSON converters publicThis closes #13303Co-authored-by: Jark Wu <jark@apache.org>,5
Records are now copied among different mappers,5
"[FLINK-20705][table-planner-blink] Introduce BatchPhysicalValues, and make BatchExecValues only extended from ExecNodeThis closes #14454",1
"[FLINK-4987] Add RpcTaskManagerGateway implementation; Port AllocatedSlotsTest, AvailableSlotsTest and SlotPoolTestThe RpcTaskManagerGateway is the TaskManagerGateway of Flink's new RPC abstraction. It basically forwards all calls to the underlying TaskExecutorGateway.Moreover, this PR enables the disabled tests AllocatedSlotsTest, AvailableSlotsTest and SlotPoolTest.Add license header to RpcTaskManagerGatewayFix ExecutionGraphMetricsTest",3
"MINOR: adjust logging levels in Stream tests (#12255)Now that we've turned off logging in the brokers/zookeeper/config classes we can finally see at least some of the logs where Streams is actually doing something when trying to debug tests from a failed PR build. But I've noticed we still have some flooding of warnings from the NetworkClient and info-level junk from Metadata, so to maximize the visible useful logs we should filter out everything bu the producer/consumer client themselves (in addition to Streams) fine-grained loggingReviewers: Luke Chen <showuon@gmail.com>, Kvicii Y",2
"[FLINK-7972] [core] Move SerializationSchema to 'flink-core'Moves the SerializationSchema and its related fromflink-streaming-java to flink-core.That helps API level projects that depend on those classesto not pull in a dependency on runtime classes, and tonot be Scala version dependent.",1
[FLINK-1635] remove Apache Thrift and Google Protobuf dependencies- remove Maven dependencies- add docs to show how to register your own serializer with KryoThis closes #794.,2
[FLINK-25892][elasticsearch6][test] add ArchUnit tests for test code,3
fix bigDecimal scientific notation (#9692)fix #9562,0
"MINOR: FetchRequest.Builder maxBytes for version <3The maxBytes field should be set to DEFAULT_RESPONSE_MAX_BYTES,the same way as the constructor using the Struct does.codeveloped with mimaisonAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2694 from edoardocomar/MINOR-FetchRequest",2
"[FLINK-8530] [flip6] Enable detached job mode submission to session clusterThis commit makes the RestClusterClient aware whether the user wishes to submita job in detached or non-detached mode. If it is detached, then the RestClusterClientwon't poll for the execution result.This closes #5466.",1
"[FLINK-20383][runtime] Fix race condition in notification.Notification happens outside of lock, so between non-null check and actual notification, readView could have been released.",0
[FLINK-7220] [checkpoints] Update RocksDB dependency to 5.5.5,5
"[FLINK-16383] Add debug logging to internal Kafka ProducerFor debugging FLINK-16383 we need to see who closes a Producer to tryand match the ""already closed"" exceptions.",1
修改demo,5
"KAFKA-6398: Return value getter based on KTable materialization statusThis is a bug fix that is composed of two parts:1. The major part is, for all operators that is generating a KTable, we should construct its value getter based on whether the KTable itself is materialized.1.a If yes, then query the materialized store directly for value getter.1.b If not, then hand over to its parents value getter (recursively) and apply the computation to return.2. The minor part is, in KStreamImpl, when joining with a table, we should connect with table's `valueGetterSupplier().storeNames()`, not the `internalStoreName()` as the latter always assume that the KTable is materialized, but that is not always true.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>Closes #4421 from guozhangwang/K6398-KTableValueGetter",1
KAFKA 218 Upgrade to zookeeper 3.3.4; patched by pyritschard; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1229784 13f79535-47bb-0310-9956-ffa450edef68,1
[travis] remove javadoc skip- skip was only necessary because Java 8 couldn't build the java docs,2
"[hotfix][tests] Restructure AbstractHaJobRunITCaseRefactors the test to make use of a static MiniClusterExtension, in preperation FLINK-26252.",2
[hotfix] remove isSystemFunction from DropCatalogFunctionOperation as it's never used,1
Polish /apache/dubbo#5721 : [Enhancement] Setting the default IDs for Dubbo's Config Beans (#5725),5
MINOR: Upgrade ducktape to 0.7.6Author: Brian Bushree <bbushree@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #7138 from brianbushree/update-ducktape,5
Expose JMX operation to set logger level dynamically (0.8 branch); patched by Jun Rao; reviewed by Jay Kreps; KAFKA-429git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377175 13f79535-47bb-0310-9956-ffa450edef68,2
"MINOR: Format AdminUtils::assignReplicasToBrokers java documentation (#7173)The assignReplicasToBrokers method has helpful but a large unformattedjavadoc comment that results in a big blob in generated html. Thischange formats the comment so that generated javadoc is nice.Reviewers: Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-28904][python][docs] Add missing connector/format documentationThis closes #20535.,2
[FLINK-3778] [shell] Forward configuration from FlinkILoop to ScalaShellRemoteStreamEnvironmentWith this PR the configuration of the FlinkILoop is properly forwarded to theScalaShellRemoteStreamEnvironment.This closes #1906.,3
[FLINK-16136][yarn][tests] Increase disk space limit for all YARN tests,3
"KAFKA-7790: Fix Bugs in Trogdor Task Expiration (#6103)The Trogdor Coordinator now overwrites a task's startMs to the time it received it if startMs is in the past.The Trogdor Agent now correctly expires a task after the expiry time (startMs + durationMs) passes. Previously, it would ignore startMs and expire after durationMs milliseconds of local start of the task.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",4
"[FLINK-13883] Deprecate unused AkkaOptions related to Akka's death watchWe no longer use Akka's death watch. Hence, this commit deprecates the deathwatch related configuration options AkkaOptions#WATCH_HEARTBEAT_INTERVAL,AkkaOptions#WATCH_THRESHOLD and AkkaOptions#WATCH_HEARTBEAT_PAUSE. Moreover,it removes the death watch verification logic in AkkaUtils.This closes #9638.",2
[hotfix][dist][config] Update the comments of TM process memory size in default flink-conf.yaml.- Correct the description of process memory size.- Provide the alternative flink memory size.,2
[FLINK-28876][python][format/orc] Support Orc formatThis closes #20505.,1
[FLINK-22239][jdbc] Pool connections in JDBC XA sinkSome databases like PostgreSQL and MySql allow at mostone XA transaction per connection. Using new connectionfor each transaction (and pooling) allows to overcomethis limitation.,1
[FLINK-6090] [table] Add RetractionRules for annotating AccMode to DataStreamRel nodes.,5
"[FLINK-23162][docs] Update column used in expression for creating table in ""Time Attribute"" pageThis closes #16301",1
[FLINK-10992][tests] Revise Hadoop configuration. (#7164)Do not use /tmp directory to place log files or the HDFS data directory.Reconfigure dfs.replication to 1 because file availability is irrelevant intests.Increase heap size of HDFS DataNodes and NameNode.Change find-files! function to not fail if directory does not exist.,0
[FLINK-28194][python] Remove avro sql jar workaround (#20045),1
[3.0] Fix shutdown hang when use port unification handler (#9852)* Fix shutdown hang when use port unification handler* Fix ut* Fix sync,0
"MINOR: Configure owasp.dependencycheck gradle pluginIt seems to output a few false positives, but stillworth verifying.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4117 from ijuma/dependency-check",5
"KAFKA-12863: Configure controller snapshot generation (#10812)Add the ability for KRaft controllers to generate snapshots based on the number of new record bytes that have been applied since the last snapshot. Add a new configuration key to control this parameter. For now, itdefaults to being off, although we will change that in a follow-on PR. Also, fix LocalLogManager so thatsnapshot loading is only triggered when the listener is not the leader.Reviewers: Colin P. McCabe <cmccabe@apache.org>",2
[FLINK-27790][table] Revert changes to AddJarOperation,1
"[FLINK-14894][core][mem] Do not explicitly release unsafe memory when managed segment is freedThe conclusion at the moment is that releasing unsafe memory, while potentially having a link to it in Java code, is dangerous. We revert this to rely only on GC when there are no links in Java code. The problem can happen e.g. if task thread exits w/o joining with IO threads (e.g. spilling in batch job) then the unsafe memory is released but it can be written w/o segfault by IO thread. At the same time, other task can allocate interleaving memory which can be spoiled by that IO thread. We still keep it unsafe to allocate it outside of JVM direct memory limit to not interfere with direct allocations, also it does not make sense for RocksDB native memory (also accounted in MemoryManager) to be part of direct memory limit.The potential downside can be that over-allocating of unsafe memory will not hit the direct limit and will not cause GC immediately which will be the only way to release it. In this case, it can cause out-of-memory failures w/o triggering GC to release a lot of potentially already unused memory.If we see the delayed release as a problem then we can investigate further optimisations, like:- directly monitoring phantom reference queue of the cleaner (if JVM detects quickly that there are no more reference to the memory) and explicitly release memory ready for GC asap, e.g. after Task exit- monitor allocated memory amount and block allocation until GC releases occupied memory instead of failing with out-of-memory immediatelyThis closes #10940.",0
[hotfix] Drop compatibility with Flink <= 1.5This commits lets us clear some codepaths. It should still be possibleto migrate from Flink 1.5 <= through any newer version.,1
- fixed JavaDoc warnings,2
"KAFKA-5876: KIP-216 Part 4, Apply InvalidStateStorePartitionException for Interactive Queries (#10657)KIP-216, part 4 - apply InvalidStateStorePartitionExceptionReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",3
[FLINK-24310][doc]Use >= instead of == to cover the downscaling scenario,2
清理demo,5
[hotfix] Introduce SlotPoolResource and TestingRpcServiceResource,3
"MINOR: Producers should set delivery timeout instead of retries  (#5425)Use delivery timeout instead of retries when possible and remove various TODOs associated with completion of KIP-91.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2
[FLINK-8801][yarn/s3] Retry if remote file not found and use remote modification time,1
"[FLINK-17847][table-planner-blink] Fix runtime ArrayIndexOutOfBoundsException when accessing out-of-bounds elements of ARRAY dataThis changes the behavior of ARRAY element accessing:- if the accessing index is a literal which is less than 1, then an error will be thrown before job is submitted with readable exception message- if the accessing index is out-of-bound during runtime, then return null instead of throwing exceptionThis closes #12436",1
[FLINK-22038][table-planner-blink] Update TopN to be without rowNumber if rowNumber field is never used by the successor CalcThis closes #16024,1
KAFKA-9662: Wait for consumer offset reset in throttle test to avoid losing early messages (#8227),3
[FLINK-11741] Remove ensureCompatibility implementation from dummy serializers,4
[FLINK-14154][ml] Add the class for multivariate Gaussian Distribution.This closes #9733.,1
KAFKA-12165: Include org.apache.kafka.common.quota in javadoc (#9846)Reviewers: David Jacot <djacot@confluent.io>,5
[FLINK-3560] [examples] Remove unchecked output of usage statement in examplesThis closes #1752.,4
[FLINK-24331][tests] Forbid to finish the TestEventSource if it has not sent at least one value,3
"MINOR: Fix warn logging in RecordCollectorImplFix warn log message in RecordCollectorImpl so it prints the exception message rather than `{}`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, GuozhangWang <wangguoz@gmail.com>Closes #4318 from dguy/minor-logging-record-collector",2
[FLINK-16727][table-planner-blink] Fix cast exception when having time point literal as parametersThis closes #11550,2
[FLINK-25402] Introduce ClusterOptions.PROCESS_WORKING_DIR_BASE for configuring a process directoryThis commit introduces the configuration option to configure a working directory for the JobManagerand TaskManager process. The resulting working directory will be <WORKING_DIR_BASE>/jm_<RESOURCE_ID>and <WORKING_DIR_BASE>/tm_<RESOURCE_ID> respectively.,1
[FLINK-16744][task] Split finish() in ChannelStateWriterSplit finish() in ChannelStateWriter into finishIn and finishOut to ease client usage,5
[FLINK-16806][operators] Add support for InputSelection to MultipleInputStreamOperator,1
[hotfix][docs] Add missing AggregatingStateDescriptor in State page (#15208),1
"[FLINK-17780][checkpointing] Add task name to log statements of ChannelStateWriter.Add task name to the executor thread and to all method of ChannelStateWriter (as they can be called from any other thread), such that log statements can be connected to the respective task.",2
Backported ID Methods from 0.2.1,5
[FLINK-18087][yarn] Fix uploading user artifact for Yarn job clusterThis closes #12463.,1
introduce AvroParquetWriters to support writing generic records to parquet file in Python DataStream APIThis closes #20403.,5
"KAFKA-3514, Documentations: Add out of ordering in concepts. (#5458)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-24928][ui] Prevent runaway recursion on NaN value,1
[hotfix] [docs] Fix broken downloads page urlThis closes #4912,0
[FLINK-1224] [streaming] getExecutionEnvironment method fixed to work properly for StreamExecutionEnvironment,1
added (failing) unit-test for task chaining,5
[hotfix] Introduce MetricFetcher interfaceRename MetricFetcher into MetricFetcherImpl and introduce MetricFetcher interface.This allows for better testing and hides the type parameter of MetricFetcherImpl.,2
[FLINK-15128][hive][doc] Document support for Hive timestamp typethis closes #10543.,1
"[FLINK-1165] [java-api] Rename ""createCollectionEnvironment"" to not break existing APIs.",4
[FLINK-25433] Add retry logic to DefaultResourceCleaner,4
[hotfix][runtime] Remove unused SchedulerBase.checkpointRecoveryFactory,1
"[FLINK-4743] [table] Add support for power(DOUBLE, DECIMAL) function.This closes #2686.",1
"KAFKA-9480: Fix bug that prevented to measure task-level process-rate (#8018)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-4558; throttling_test fails if the producer starts too fastWith this change, the consumer will be considered initialized in theProduceConsumeValidate tests once its partitions have been assigned.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2347 from apurvam/KAFKA-4588-fix-race-between-producer-consumer-start",0
[FLINK-14415][table-common] ValueLiteralExpression#equals should take array value into account (#9915)This closes #9915,2
[FLINK-15247][Runtime] Wait for all slots to be free before task executor services shutdown upon stopping[FLINK-15247][Runtime] Improve test coverage for slot allocation and task submission in TaskSlotTable[hotfix][Runtime] Introduce TaskSlotTable interface[hotfix][Runtime][Tests] Introduce StubTaskSlotTable for tests to replace mockito mocks[hotfix][Runtime][Tests] Rework TaskExecutorTest#testTaskInterruptionAndTerminationOnShutdown to testTaskSlotTableTerminationOnShutdownThis closes #10682.,3
[FLINK-8704][tests] Port SlotCountExceedingParallelismTestThis closes #5694.,3
[FLINK-7528] Create DispatcherRestEndpoint and integrate with DispatcherThis commit creates the DispatcherRestEndpoint and integrates it with theDispatcher. The DispatcherRestEndpoint is created in the SessionClusterEntrypointand its address is passed to the Dispatcher such that it can answer therequestRestAddress RPC.This closes #4598.,1
"[FLINK-2793] [runtime-web] Rework JobManagerRetriever to avoid race conditionsThe JobManagerRetriever sets the new leaderGatewayPortFuture directly in the notifyLeaderAddressmethod instead of in one of the futures. This avoids race conditions between multiple futureswhich finish in a different order than they were started. Furthermore, this replaces promisesby futures where a promise is not needed.Add logging statementFix WebRuntimeMonitorITCase to use random port and proper state backendAdd ChannelHandler.Sharable to RuntimeMonitorHandlerRemove sanity check from WebInfoServer to let it work on Yarn",1
"KAFKA-5191: Autogenerate Consumer Fetcher metricsAutogenerate docs for the Consumer Fetcher's metrics. This is a smaller subset of the original PR https://github.com/apache/kafka/pull/1202.CC ijuma benstopford hachikujiAuthor: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2993 from wushujames/fetcher_metrics_docs",2
"[FLINK-7480] Set HADOOP_CONF_DIR to sane default if not setThis improves the out-of-box experience on GCE and AWS, both of whichdon't set HADOOP_CONF_DIR by default but use /etc/hadoop/conf",5
[hotfix] add some more buffer recycling checks in SpillableSubpartitionTest,3
"MINOR: DefaultMessageFormatter custom deserializer fixesThe ability to specify a deserializer for keys and values was added in a recent commit (845c6eae1f6c6bcf11), but it contained a few issues.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #987 from ijuma/console-consumer-cleanups",4
[FLINK-8162] [kinesis] Add unit test for Kinesis shard metrics reportingThis closes #5182.,3
[docs] Rename Guides->Concepts to API Concepts,2
[streaming] FaultTolerancyBuffer class added,1
[FLINK-7468][network] Implement sender backlog logic for credit-basedTHis closes #4559.,2
"[FLINK-3248] add constructor params and generic ConnectionFactoryThis adds more default constructor parameters to the RMQSource. In addition,users may override the setupConnectionFactory() method to return their onwnconfigured factory.This closes #1670.",5
[3.0] release CPU to run StreamObserver methods (#9226)* release CPU to run StreamObserver methods* release CPU to run StreamObserver methods of GrpcProtocolTest,3
KAFKA-14062: OAuth client token refresh fails with SASL extensions (#12398)- Different objects should be considered unique even with same content to support logout- Added comments for SaslExtension re: removal of equals and hashCode- Also swapped out the use of mocks in exchange for *real* SaslExtensions so that we exercise the use of default equals() and hashCode() methods.- Updates to implement equals and hashCode and add tests in SaslExtensionsTest to confirmCo-authored-by: Purshotam Chauhan <pchauhan@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
KAFKA-3407 - ErrorLoggingCallback trims helpful diagnostic information.This should help when diagnosing issues with the console producer. This allows the logger to use `exception` rather than `exception.getMessage()`.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1079 from jcustenborder/KAFKA-3407,5
"KAFKA-2675; SASL/Kerberos follow upAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #376 from ijuma/KAFKA-2675-sasl-kerberos-follow-up",1
[FLINK-28632][sql-gateway][hive] Allow to GetColumns/GetPrimaryKeys/GetTableTypes in the HiveServer2 EndpointThis closes #20493,1
[FLINK-24687][parquet] Copied DecimalDataUtils#is32BitDecimal and DecimalDataUtils#is32BitDecimal in ParquetSchemaConverter to remove the dependency on DecimalDataUtils (from planner)Signed-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24516][archetype] Update archetype documentationThis closes #17487,2
"MINOR: Add BrokerMetadataListener (#10111)This adds BrokerMetadataListener which is responsible for processing metadata records received by the broker when running in Raft mode.This also moves some classes that were added to the wrong folder in trunkReviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>",5
HOTFIX: typo in Streams DSL docs,2
[FLINK-16858][table] Expose partitioned by grammarThis closes #11559,2
[FLINK-3656] [table] Consolidate ITCasesMerge FilterIT/SelectIT to CalcITCasesMerge FromDataSet/ToTable to TableEnvironmentITCasesMerge aggregating ITCasesAll batch ITCases use TableProgramsTestBaseThis closes #2566.,3
[FLINK-6093] [table] Implement and turn on retraction for table sinks.,2
[FLINK-24796][ci] Reduce size of compile build artifact,2
[hotfix] Minor JavaDoc correction in StateTable,2
[hotfix] Add description to java.env.opts.*,1
Adapted scheduler to new locking concept and fixed bug in state model,0
[FLINK-13770][build] Bump netty to 4.1.39.Final,2
[FLINK-24334][k8s] Set FLINK_LOG_DIR environment for JobManager and TaskManager pod if configured via optionsThis closes #17503.,5
"[FLINK-2651] Add Netty to dependency managementHadoop 2.7.0 pulls in an older Netty version, which clashes with our version.This makes sure to only pull in our version.",1
Implemented method to adjust channel buffer size limits from job manager,5
simplifications to management graph structures due to multigraph-DAG problem (management graph and streaming plugin cannot deal with multigraph-DAGs currently),2
[FLINK-13464][build] Bump powermock to 2.0.2,2
DUBBO-251 去掉重复的-D参数覆盖逻辑git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1138 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-4994] Don't Clear Trigger State and Merging Window Set When PurgingBefore, when a Trigger returns TriggerResult.PURGE from any of theon*() methods the WindowOperator will clear all state of that window(window contents, merging window set) and call Trigger.clear() so that theTrigger can clean up its state/timers.This was problematic in some cases. For example, with merging windows (sessionwindows) this means that a late-arriving element will not be put into thesession that was previously built up but will be put into a completely newsession that only contains this one element.The new behaviour is this: * Only clean window contents on PURGE * Register cleanup timer for any window, don't delete this on PURGE * When the cleanup timer fires: clean window state, clean merging window set,call Trigger.clear() to allow it to clean state/timers",4
添加空格,5
去掉URL上不必要的信息git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1185 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-7739][tests] Properly close flink mini cluster,5
Made RPC.getProxy a generic method,1
[FLINK-18713][table-planner-blink] Change duration ConfigOption to duration typeThis closes #13392,5
[FLINK-1201] [gelly] Updated the Graph constructor,5
KAFKA-8531: Change default replication factor config (#10532)Implements KIP-733Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
[streaming] updated streamrecord getrecord method,1
ConsumerIterator throws a IllegalStateException after a ConsumerTimeout occurs; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-241git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1233501 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-25883][python] Set the default value of DEFAULT_BUNDLE_PROCESSOR_CACHE_SHUTDOWN_THRESHOLD_S to 30 days,1
[FLINK-24859][doc][formats] Make new formats name coherent: introduce previous names classes to indicate deprecation to the users,1
"[FLINK-15597][runtime] Compromise JVM Overhead fraction to Total Flink / Process Memory sizes, wrt JVM Overhead min/max.This closes #10862.",2
KAFKA-141 Check and make sure that the files that have been donated have been updated to reflect the new ASF copyright;patched by nehanarkhede; reviewd by jjkoshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180185 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix][docs] Minor improvements of glossary.This closes #9694.,1
consumer sometimes don't release partition ownership properly in ZK during rebalance; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-286git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1294302 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-13809: Propagate full connector configuration to tasks in FileStream connectors (#12450)Reviewers: Chris Egerton <fearthecellos@gmail.com>,2
[docs-sync] Synchronize the latest documentation changes into Chinese documents,2
KAFKA-12539; Refactor KafkaRaftCllient handleVoteRequest to reduce cyclomatic complexity (#10393)1. Add `canGrantVote` to `EpochState`2. Move the if-else in `KafkaRaftCllient.handleVoteRequest` to `EpochState`3. Add unit tests for `canGrantVote`Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-15042][python] Fix python compatibility by excluding executeAsync,0
[FLINK-9781][build] Fix scala-maven-plugin for Java 9https://github.com/scala/scala/releases/tag/v2.11.12,0
- fixed memory requirements checks in PACT tasks,1
[FLINK-21434][python] Fix encoding error when using the fast coder to encode a row-type field containing more than 14 fieldsThis closes #15063.,5
"MINOR: update the comment for Utils.atomicMoveWithFallback (#11641)Reviewers: Luke Chen <showuon@gmail.com>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",4
"KAFKA-5844; add groupBy(selector, serialized) to Ktableadd `KTable#groupBy(KeyValueMapper, Serialized)` and deprecate the overload with `Serde` paramsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #3802 from dguy/kip-182-ktable-groupby",5
"KAFKA-8705: Remove parent node after leaving loop to prevent NPE (#7117)Fixes case where multiple children merged from a key-changing node causes an NPE.Reviewers:  Matthias J. Sax <mjsax@apache.org>, Boyang Chen <boyang@confluent.io>",5
[FLIN-12663]Implement HiveTableSource to read Hive tablesThis PR created HiveTableSource to read Hive tables.This closes #8809.,1
[hotfix][task] Rename triggerCheckpoint to better reflect a difference compared to other similarly named methods,1
Fix AbstractMetadataReportTest and AbstractMetadataReportFactoryTest (#8807)* Fix AbstractMetadataReportTest and AbstractMetadataReportFactoryTest* To trigger workflow* Fix test,3
"[FLINK-22233][table] Fix ""constant"" typo in PRIMARY KEY exception messagesThis closes #15656Co-authored-by: wuys <wuyongsheng@qtshe.com>",2
Added sopremo expressions,1
[FLINK-16373] Make JobManagerLeaderListener thread safeThe JobManagerLeaderListener used by the JobLeaderService was not thread safe. Stopping the listenerwhile notifying a new leader could lead to an IllegalStateException where the rpcConnection whichwas supposed to be started was concurrently closed by the stop call.This closes #11313.,1
[hotfix] Remove mocking from ExecutionGraphRestartTest,3
[FLINK-20352][docs] Updated CLI documentation to match the current state of the code.[FLINK-20352][docs] Added Savepoint link.[FLINK-20352][docs] Added -j info to dispose command.[FLINK-20352][docs] Added --allowNonRestoredState.[FLINK-20352][docs] Added more extensive details on the stop action which include the --drain parameter.[FLINK-20352][docs] Swapped stop and cancel subsections.[FLINK-20352][docs] Added $ prefix to commands and fixed formatting (linebreaks and indentation).[FLINK-20352][docs] Changed link label.[FLINK-20352][docs] Changed link target to point to Application Mode instead of the more general Deployment Modes.[FLINK-20352][docs] Updated Chinese CLI docs to align with the English version.[FLINK-20352][docs] Updated --target section[FLINK-20352][docs] Aligned English and Chinese version.This closes #14287.,2
[FLINK-11693] Support FlinkKafkaPartitioner functionality with new KafkaSerializationSchema,1
[FLINK-26931][Connector/pulsar] Make the producer name and consumer name unique for each instance.,1
Update path to stratosphere-dist folder in README.md,2
cloud manager working,1
[FLINK-11067][table] Port table source&sink classes into api-javaThis closes #8050,2
[hotfix] Remove unused TaskManagerConfiguration in TaskExecutorTest,3
"KAFKA-9460: Enable only TLSv1.2 by default and disable other TLS protocol versions (KIP-553) (#7998)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
[Spring Boot Project] Merge 3.0.x Spring-Boot project into Dubbo 3.0.x (#7441)* [Spring Boot Project] Merge 3.0.x Spring-Boot project into Dubbo 3.0.x* add junit5 dependency* ignore ut* change to junit5* reset ApplicationModel,1
[FLINK-14820][core] Migrate FutureUtils to Duration,2
MINOR: Use the correct processor id in the processor thread nameThis restores the behaviour before 1265d7cb7.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #294 from ijuma/fix-processor-thread-name,0
"MINOR: Enable deep-iteration to print data in DumpLogSegments (#4396)Enable deep-iteration option when print-data-log is enabled in DumpLogSegments. Otherwise data is not printed.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"[FLINK-21042][docs] Fix code example in ""Aggregate Functions"" section in Table UDF pageThis closes #14702",1
Merge pull request #630 from qinliujie:feat/netty4netty4 support,1
[hotfix][table] Converted static generateIterativeCondition & generateOneRowPerMatchExpression methods into inner methods,0
"KAFKA-3264; Deprecate the old Scala consumer (KIP-109)Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>This patch had conflicts when merged, resolved byCommitter: Ismael Juma <ismael@juma.me.uk>Closes #2328 from vahidhashemian/KAFKA-3264",0
[FLINK-9091][build] Dependency convergence run against dependency-reduced pomsThis closes #6102.,1
[hotfix][docs] Refactor ConfigOptionsDocGenerator,5
[hotfix] [core] Add a factory method to create Path from local fileThis makes it easier for users and contributors to figure out howto create local file paths in way that works cross operating systems.,5
MINOR: Improve introduction section in docs to better cover connect and streams. Make uses and ecosystem pages stand alone.,5
[FLINK-18073][avro] Fix AvroRowDataSerializationSchema is not serializableThis closes #12471,5
Fixed problem with character encoding in URL user info,5
[FLINK-11901][build] Update NOTICE files with year 2019This closes #7975.,2
[FLINK-18856][checkpointing] Synchronize access to CheckpointCoordinator.lastCheckpointCompletionRelativeTime,2
[FLINK-13287][table-api] Port ExistingField to api-java and use new Expression in FieldComputer,1
[FLINK-9126][cassandra] Finalize Pojo InputFormat,2
[hotfix][tests] Checkstyle and common style cleanups in CopyOnWriteStateMapTest,3
"Revert ""[FLINK-12143][e2e] Change end-to-end tests with file system to use plugins mechanism""This reverts commit 9e6ff81e22d6f5f04abb50ca1aea84fd2542bf9d.",4
Improve second replica assignment; patched by Jun Rao; reviewed by Guozhang Wang; kafka-762,1
"[FLINK-8324] [kafka, metrics] Make clear which metrics are legacy and should not be touchedThis commit consolidates all metrics related constant string names in aKafkaConsumerMetricConstants class, to give a better overview code-wisewhich metrics are exported.That makes it more clear in the code which metrics are kept forcompatibility reasons. It also additionally states that metric namesshould not be changed, otherwise metrics compatibility will be broken.This closes #5214.",4
[hotfix][metric] MetricRegistryImpl#LOG is private,2
[FLINK-20096][docs] Add PyFlink overview,2
"[FLINK-13985] Use unsafe memory for managed memoryMakes allocation of off-heap memory independent of direct buffers and limiting option -XX:MaxDirectMemorySize.This implementation uses sun.misc.Unsafe for that purpose. - Add allocate/release unsafe memory methods to MemoryUtils - Add a MemoryUtils#createMemoryGcCleaner to release memory in phantom reference queue   upon GC of the memory owning object (based on sun.misc.Cleaner similar to java.nio.DirectByteBuffer(int cap)). - Add MemoryUtils#wrapUnsafeMemoryWithByteBuffer which uses the private constructor java.nio.DirectByteBuffer(long address, int cap)   to wrap unsafe memory but w/o checking -XX:MaxDirectMemorySize. - Add an optional custom action to call in HybridMemorySegment#free for memory cleanup - Change MemorySegmentFactory#allocateUnpooledOffHeapMemory to   - allocate unsafe memory,   - wrap it with ByteBuffer with MemoryUtils#wrapUnsafeMemoryWithByteBuffer   - hook a phantom reference queue cleaner upon the buffer GC and   - create HybridMemorySegment with this buffer and its custom cleaner.",4
MINOR: Small cleanups/refactoring in kafka.controller- Updated logging to use string interpolation- Minor refactors- Fixed a few typosAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4231 from mimaison/controller_refactor,4
DUBBO-135 暂时注释掉Thrift中不通过的测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1820 1a56cb94-b969-4eaa-88fa-be21384802f2,1
renamed ArrayNode>>subList() to subArray(); implemeted more tests for ArrayNode interface and implementation,3
[FLINK-2972][java-api] remove Chill dependency from the test scopeThis closes #1535.,3
[FLINK-3373] [build] Revert HTTP Components versions because of incompatibility with Hadoop >= 2.6.0,1
[hotfix][table-common] Add ChangelogMode.toString(),4
[FLINK-23115][python] Expose Table#execute_insert and StatementSet#add_insert in Python Table APIThis closes #16516.,1
Reintegrated union code,5
[FLINK-24158][runtime] Remove useless collector in LimitOperatorSigned-off-by: TennyZhuang <zty0826@gmail.com>This closes #17148 .,1
[FLINK-14287] Decouple leader address from LeaderContenderChange LeaderElectionService#confirmLeadership to accept leader address so thatthe LeaderContender does not need to know the address of the potential leaderbefore gaining leadership. This allows to decouple the leader election from theactual leader component.This closes #9813.,1
fix UnsafeStringWriter constructor (#9353),0
[streaming] fault tolerance refactor,4
DUBBO-49 Injvm的端口总是置为0git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@236 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: removed obsolete classguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #843 from ymatsuda/remove_unused,4
[FLINK-7975][QS] Wait for QS client to shutdown.,2
[FLINK-9183] [docs] Add warning about idle partitions to Kafka connector docs.This closes #5858.,2
"Fix export provider error, change to catch throwable, handle NoClassDefFoundError (#6380)",0
optimize : optimize document specifications (#5587),2
[hotfix] [metrics] MetricRegistry threadNumber starts at 1,1
"MINOR: SuppressScenarioTest should set StreamsConfig.STATE_DIR_CONFIG (#5826)Set `StreamsConfig.STATED_DIR_CONFIG` in `SuppressScenarioTest`, aswith `StreamsTestUtils`. I have deliberately avoided using `StreamsTestUtils` asthis test sets bogus config parameters, but still fails if the default`STATE_DIR_CONFIG` does not exist.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, John Roesler <john@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"[FLINK-1672] [runtime] Unify Task and RuntimeEnvironment into one class. - This simplifies and hardens the failure handling during task startup - Guarantees that no actor system threads are blocked by task bootstrap, or task canceling - Corrects some previously erroneous corner case state transitions - Adds simple and robust tests",3
[FLINK-11678][runtime] Removes unnecessary obsolete method overwritingRestfulGateway provides the exact same method signature.DispatcherGateway.requestJob became obsolete with the changes made in ce49a904.,4
去掉RMI的类型转换不兼容git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@224 1a56cb94-b969-4eaa-88fa-be21384802f2,1
avoid logging stacktrace directly; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-231git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1226599 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-16989][table-planner-blink] Rename current TableSourceScan into LegacyTableSourceScanThis closes #11985,2
[FLINK-11718] Make RpcEndpoint#start method final to prevent changing its behaviourThis closes #7808.,4
"KAFKA-9179; Fix flaky test due to race condition when fetching reassignment state (#7786)This patch fixes a race condition on reassignment completion. The previous code fetched metadata first and then fetched the reassignment state. It is possible in between those times for the reassignment to complete, which leads to spurious URPs being reported. The fix here is to change the order of these checks and to explicitly check for reassignment completion. Note this patch fixes the flaky test `TopicCommandWithAdminClientTest.testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress`.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
[FLINK-12254][table-common] Add a logical type to data type converterThis closes #8453.,5
Merge branch 'master' into version02Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
[FLINK-7619] Improved abstraction of AbstractAsyncIOCallable to better fit the current usage pattern.,1
Fixed README and added clearer error message. (#10133)The script `test-raft-server-start.sh` requires the config to be specified with `--config`. I've included this in the README and added an error message for this specific case.Reviewers: Jason Gustafson <jason@confluent.io>,5
[hotfix][build] Add Aliyun FS dependency to flink-dist,2
[hotfix] Add BiConsumerWithException#unchecked to convert into BiConsumer,1
MINOR: fix docs of common per-broker metricsAuthor: lambdaliu <lambdaliu@tencent.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6212 from lambdaliu/fix_metrics_error,0
"[hotfix][runtime][tests] Migrate TaskManagerLocationTest, TaskExecutorToResourceManagerConnectionTest and TaskManagerRunnerConfigurationTest to JUnit5",3
"MINOR: Restore scanning for super types of Connect plugins (#4584)Enabling scans for super types in reflections is required in order to discover Connect plugins.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-12464: minor code cleanup and additional logging in constrained sticky assignment (#10645)This is the follow up PR to address the remaining comments in #10509.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
[hotfix][tests] Remove unused temp folder in CheckpointMetadataLoadingTest,5
[FLINK-10123] Use ExecutorThreadFactory instead of DefaultThreadFactory in RestServer/ClientUsing the ExecutorThreadFactory hardens the system because it uses the FatalExitExceptionHandleras UncaughtExceptionHandler which terminates the JVM in case of an exception.This closes #6539.,0
refactor override rule,4
[FLINK-20195][coordination] Deduplicate jobs for overview,2
kafka-1228; Socket Leak on ReplicaFetcherThread; patched by Ahmy Yulrizka; reviewed by Jun Rao,5
[hotfix][java-docs] Improve ResultSubpartition java doc,2
[FLINK-12453][table-planner-blink] Simplify constructor of AggsHandlerCodeGenerator to explicitly tell which methods need to be generatedThis closes #8378,0
"KAFKA-9130; KIP-518 Allow listing consumer groups per state (#8238)Implementation of KIP-518: https://cwiki.apache.org/confluence/display/KAFKA/KIP-518%3A+Allow+listing+consumer+groups+per+state. Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",5
"KAFKA-10546: Deprecate old PAPI (#10869)* Deprecate the old Processor API* Suppress warnings on all internal usages of the old API  (which will be migrated in other child tickets of KAFKA-8410)* Add new KStream#process methods, since KAFKA-10603 has not seen any action.",1
"[FLINK-9416] Make all RestClusterClient calls retriableThis commit changes the RestClusterClient calls such that they are all retriable wrtto connection errors and if the service is currently unavailable (return code 503).Moreover, it changes the retry behaviour for polling the JobResult such that it failsnow if the cluster returns a NOT_FOUND code.This closes #6069.",0
[FLINK-15334][table-api] Fix physical schema mapping in TableFormatFactoryBase to support define orderless computed column (#10693),1
KAFKA-371 Patch from Jonathan Creasy reviewed by me. Correctly handle the case of an empty string as topic name or invalid partition number.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1363022 13f79535-47bb-0310-9956-ffa450edef68,0
[hotfix][tests] Add easier way to chain operator in StreamTaskTestHarness,3
[runtime] [logging] Fix log messageThis closes #736.,1
[FLINK-22385][runtime] Fix type cast error in NetworkBufferPoolThis closes #15693.,1
Marked temporary code properly,5
DUBBO-528 修改兼容性判断,5
"[FLINK-14888][python] Move the Python SqlDialect to module tableThe java SqlDialect class exists in `table.api` module, so it's better to place the pythonSqlDialect into the `pyflink/table` module which is used to place table API classes.This closes #10279.",1
"[hotfix][runtime, test] Refactor StreamConfigChainer to support StreamOperatorFactory and honour pass down the bufferTimeout",4
[FLINK-19182][doc-zh] Update translation for intra-slot managed memory sharing.This closes #14079.,5
[hotfix][runtime] Refactor configuration preparations for resource managers.,5
[FLINK-28606][Runtime/Checkpointing] Refractor coordination tests with JUnit5 Assertions,3
[FLINK-7267][connectors/rabbitmq] Allow overriding RMQSource connection,1
KAFKA-2632: move fetchable check ahead in handleFetchResponseAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason GustafsonCloses #295 from guozhangwang/K2632,0
Fixed query error message,0
"[streaming] new tests, wordcount performance classes, commented examples",3
Better estimations for filter operator,1
"[FLINK-1318] [api-breaking] Simplified quoted string parsing, made it optional, and use a configurable quote characterThis closes #265",5
[FLINK-1353] [runtime] Loops through the JobManager's timeout to the Execution objects.This closes #325.,1
"[hotfix][table] Fix not-equals code generationThis was using != before, now uses !(a.equals(b))",1
"KAFKA-9235; Ensure transaction coordinator is stopped after replica deletion (#7963)During a reassignment, it can happen that the current leader of a partition is demoted and removed from the replica set at the same time. In this case, we rely on the StopReplica request in order to stop replica fetchers and to clear the group coordinator cache. This patch adds similar logic to ensure that the transaction coordinator state cache also gets cleared.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalHashAggregate, and make BatchExecHashAggregate only extended from ExecNodeThis closes #14562",1
[FLINK-3427] [webui] Rebuild web UIThis closes #3366.,2
[streaming] Licensing added to LogUtils,2
"MINOR: Update usage of deprecated API (#6146)Reviewers: Guozhang Wang <guozhang@confluent.io>, Ismael Juma <ismael@confluent.io>, Jorge Quilcate Otoya <quilcate.jorge@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"Minor: Fix ps command example in docsProcess grep command has been updated. Previous ""ps  | grep server-1.properties""  command is showing nothing.Author: Satendra Kumar <satendra@knoldus.com>Reviewers: Gwen ShapiraCloses #1386 from satendrakumar06/patch-1",5
[FLINK-13774][table-planner-blink] Modify filterable table source accept ResolvedExpression,0
[FLINK-11015] Remove deprecated code for format-specific Kafka table connectorsThis commit removes all classes and methods that have been deprecated inFlink 1.6 for separating Kafka connectors from Avro and JSON formats.This closes #7182.,5
[FLINK-2079] Add TaskManager deathwatch thread for YARN case,1
[FLINK-23621][core] Move MailboxExecutor to flink-core and org.apache.flink.streaming.api.operators,2
[FLINK-21851][table-runtime] Refactor BinaryRowDataKeySelector in testingThis closes #15256,3
[FLINK-27630][table-planner] Add maven-source-plugin for table planner testing connectors (#19746),3
DUBBO-469 调整Filter链顺序,5
修改错误的plugingit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1971 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-21080][runtime][checkpoint] The task reports whether it has called operators' finish method,5
"KAFKA-6751; Support dynamic configuration of max.connections.per.ip/max.connections.per.ip.overrides configs (KIP-308) (#5334)KIP-308 implementation. See https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=85474993.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-12883][runtime] Add getID() to ExecutionVertex,1
[FLINK-15101][connector/common] Add the SourceCoordinator implementation,1
DUBBO-309 补充单元测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1522 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Refactored sopremo common,4
Update the Java SE link to Java 8.,2
"MINOR: Move `ConsoleProducerTest` to the unit test directoryIncluded a couple of clean-ups: removed unused variable and the instantiated `KafkaProducer` is now closed.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #1470 from ijuma/move-console-producer-test-to-unit-folder",3
KAFKA-7762; Update KafkaConsumer Javadoc examples to use poll(Duration timeout) APIAuthor: Matthias Wessendorf <mwessend@redhat.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6052 from matzew/use_new_poll_api,1
Re-applied old patch from KAFKA-139Had to make some additional changes based on further mainline work. LeavingKafkaProject.scala in place as a reference for now.,1
[hotfix][runtime-web] replace loading icon with text to avoid spin animation bottleneck,0
[FLINK-12313][tests] Workaround for SynchronousCheckpointITCase to avoid race condition,1
[FLINK-11522][table] Deprecate ExternalCatalogTable.builder()This unblocks the porting and moving of ExternalCatalogTable toflink-table-common for FLINK-11067.This closes #7650,2
Adjusted test to new output format names.,1
[FLINK-22264][docs] Fix misleading statement about Flink Job Cluster Kubernetes Support in Flink Architecture page[FLINK-22264][docs] Add Chinese documentationThis closes #15602.,2
[FLINK-19924][config] Add an option to force Unaligned Checkpoints,1
[FLINK-21632][python] Add NamespacedStateView and PerWindowStateDataViewStoreThis closes #15130,5
MINOR: Fix error message in KafkaConfig validation (#4417),5
Add unit test for rpc-triple module (#9203)* Add unit test for rpc-triple module* Fix build* Fix and add unit testCo-authored-by: guohao <guohaoice@gmail.com>,3
[FLINK-785] Fixed ObjectReuseITCaseThis closes #370,1
[FLINK-20437][table-planner-blink] Port ExecNode to Java,2
[streaming] Minor pom fix,0
Added unsplittable behavior to input formats via marker interface UnsplittableInput.,1
MINOR: Propage version correctly in `FetchSnapshotRequest` constructor (#9804)Pass through the version to the super constructor in `FetchSnapshotRequest`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
[FLINK-25848][connectors/firehose] Separated unit style tests for the KDF Sink into KinesisFirehoseSinkTest,3
"MINOR: Create a new topic for each test for flaky RegexSourceIntegrationTest (#6853)The RegexSourceIntegrationTest has some flakiness as it deletes and re-creates the same output topic before each test. This PR reduces the chance for errors by creating a unique output topic for each test.Reviewers:  Matthias J. Sax <mjsax@apache.org>,  Boyang Chen <boyang@confluent.io>",5
[FLINK-21019][hbase] Bump Netty to 4.1.46,2
[FLINK-24635][examples] Fix deprecations in socket example,0
MINOR: Fix category in doap_Kafka.rdf (#11423)Reviewers: Mickael Maison <mickael.maison@gmail.com>,0
[FLINK-11304][docs][table] Fix typo in time attributes docThis closes #7477.,2
[FLINK-2488] [FLINK-2524] [FLINK-3124] Expose Attempt Number in RuntimeContext and add TaskInfo to hold all task related parameters.This closes #1386,2
"MINOR: Safer handling of requests prior to SASL authenticationThis implements two improvements for request handling prior to SASL authentication:1. Only parse request types that are allowed prior to authentication.2. Limit the maximum request size (the default is 100Mb).Author: Jason Gustafson <jason@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3558 from hachikuji/minor-restrict-presasl-request-parsing",5
"[Dubbo-4697] Fix PojoUtils support localdatetime,lcaldate,localtime (#5783)",5
[hotfix][FLINK-14716][table-planner-blink] Fix the order of fields projected into TableSourceThis fixes the failed HiveTableSourceTest#testProjectionPushDown.,3
[FLINK-4839] [cluster management] JobManager handle TaskManager's slot offeringThis closes #2647 #2643.,0
Added meteor,1
MINOR: Share BrokerMetadataPublisher code for coordinators (#11525)Leader election and resignation logic for the Group Coordinator and Transaction Coordinator is thesame. Share this logic by refactoring this code into a method.Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
[FLINK-4930] [client] [yarn] delete tmp file of job graph and refine finalizeCluster,2
[FLINK-2908] [web frontend] Redraw web plan when browser resizedRedraw the job plan visual graph when the browser width is increased.This closes #3251,1
[FLINK-25155] Support claim mode in rest api,1
"[hotfix][table-planner-blink] Rename WindowAggregateTest to GroupWindowTestWe are going to introduce the new window TVF based aggregates,in order to avoid confusing, we call the legacy window aggregate ""GroupWindow"",and the new window aggregate ""WindowAggregate"".",1
[FLINK-12066] [State Backends] Remove StateSerializerProvider field in keyed state backendThis closes #8078.,1
[FLINK-17040][tests] Fix SavepointWriterITCase failure because of UnsupportedOperationException,1
Clean up LICENSE and NOTICE files,2
"MINOR: Fix connect:mirror checkstyle (#7951)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-4322] [checkpointing] Ignore minimum delay for savepoints,5
[hotfix][docs] Reference file systems documentation from batch/connectors docs,2
"KAFKA-4709：Error message from Struct.validate() should include the name of the offending field.https://issues.apache.org/jira/browse/KAFKA-4709Author: Aegeaner <xihuke@gmail.com>Reviewers: Dong Lin, Guozhang WangCloses #2521 from Aegeaner/KAFKA-4709",0
[FLINK-1233] Fix flaky AggregateITCase,0
[FLINK-25744] Split CheckpointType for checkpoint & savepointCheckpoints & savepoints often contain a disjoint parts of typespecification. E.g. PostCheckpointAction apply only to savepoints.When adding new properties it becomes harder and harder to keep bothconfigurations in a single class.,5
[FLINK-16131] [docs] Translate /ops/filesystems/s3.zh.mdThis closes #11207.,5
[FLINK-26011][json][test] add ArchUnit tests for the test code,3
[FLINK-9275] [streaming] Add taskName to the output flusher thread's nameThis closes #5943,1
Remove concurrent access to process stdout,4
[FLINK-22159][docs][table] Add documentation for the new window TVF based operationsThis closes #15642,1
"[FLINK-7647] [flip6] Rename JobManagerConfigHandler to ClusterConfigHandlerThe original naming wouldn't make sense for the FLIP-6 redesign, sincewe would have multiple per-job JobManagers for each cluster, whichshares the same configuration.The REST path is still left untouched and not part of this commit, asthat would involve more changes in flink-runtime-web.",2
ProducerSendThread calls ListBuffer.size a whole bunch. That is a O(n) operation; patched by David Arthur; reviewed by Jun Rao; kafka-456git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1394164 13f79535-47bb-0310-9956-ffa450edef68,2
[hotfix][history] Read/Write MultipleJobsDetails instead of manual JSON,5
[streaming] Fixed StreamComponentTest,3
"[FLINK-22302][docs][table] Update ""Queries"" Chinese documentationsThis closes #15642",2
[FLINK-12897][python][docs] Improve the Python Table API docs by adding more examples.This closes #8916,1
[FLINK-11773] [core] Use LinkedOptionalMapSerializer in Kryo-/PojoSerializerSnapshotData,5
style in MulticastManager,5
[FLINK-3654] Disable Write-Ahead-Log in RocksDB State,5
"[FLINK-3121] Emit Final Watermark in Kafka SourceKafka sources that don't read from any partition never emit a watermark,thereby blocking the progress of event-time in downstream operations.This changes the Kafka Source to emit a Long.MAX_VALUE watermark if itknows that it will never receive data.This also changes the Timestamp Extraction operator to reacto to aLong.MAX_VALUE watermark by itself emitting a Long.MAX_VALUE watermark.",1
[hotfix][docker] Prevent docker-compose cachingThe caching is overly aggressive and potentially even ignores changes to the .yml files.,2
Fix DynamicConfiguration SPI config,5
HOTFIX: Avoid NPE in StreamsPartitionAssignorAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>Closes #1004 from guozhangwang/KStreamPANPE,5
[hotfix] Make test_sql_client independent of unzipSome platforms might not have installed the unzip command. Therefore it isbetter to use the jar command to extract jar files.,2
[FLINK-14347][test] Filter out expected exception string in YARN testsThis closes #9880.,3
"Wrap very long line in FlatMapOperator classAs previous discussions before, we do not restrict max chars per line for Java code, but this one just way too long compare to others that I just think make easier to read if we wrap it.Author: hsaputra <hsaputra@apache.org>Closes #683 from hsaputra/wrap_very_long_line_in_FlatMapOperator and squashes the following commits:37d2081 [hsaputra] Wrap very long line in FlatMapOperator class.",1
Fixed bug in AsynchronousPartialSorterCollector that causes undesired spawning of a reading thread.,1
[FLINK-13051][runtime] Rename TwoInputSelectableStreamTask and StreamTwoInputSelectableProcessor,2
"[hotfix][connectors/jdbc, table, tests] Fix types in schema ddl in tests",3
[FLINK-18348] RemoteInputChannel should checkError before checking partitionRequestClient,0
[FLINK-7293] [cep] Support custom order by in PatternStreamThis closes #4418.,1
[FLINK-17599][docs] Update documents due to FLIP-84,2
KAFKA-12260: Avoid hitting NPE for partitionsFor (#10017)Remove null pointer from the public partitionsFor API.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
[FLINK-21558][coordination] Skip check if slotreport indicates no change,4
修改simple-monitor页面git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@507 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-20021][docs] Cleanup misuses of Dispatcher/JobManagerThis closes #13959.,1
Fixed generics in FormatUtil,0
Reenabled FileInputSplitAssigner as default assigner for FileInputSplits,2
add logger to critical path (#6744),2
修改zookeeper实现git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@72 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-21072] Refactor the SnapshotStrategy hierarchy1. The refactoring simplifies the snapshot strategy hierarchy a bit.2. It extracts the synchronous/asynchronous execution out of the SnapshotStrategy to a separate SnapshotStrategyRunner. Prior to those changes the logic was duplicated in most of the strategies.3. It introduces the concept of SnapshotResources for the synchronous part which can be later on used for introducing a common SavepointSnapshotResources.This closes #14719,1
[FLINK-22528][docs] Document latency tracking metrics for state accesses,2
[FLINK-21368] Remove RpcService#getExecutor,1
[hotfix][mesos] Add more logging information to LaunchableMesosWorker,1
change codestyles and clean up,4
[streaming] Removed obsolete state objects from streaming-core,4
[FLINK-7856][flip6] Port JobVertexBackPressureHandler to REST endpointThis closes #5397.,0
MINOR: add process(Test)Messages to the README (#8480),3
[FLINK-18122][e2e] Make K8s test more resilient by retrying and failing docker image build (2nd try),1
fix netty server Option.SO_REUSEADDR config. (#5473),5
"Minor: add valueChangingOperation and mergeNode to StreamsGraphNode#toString (#5522)This PR adds valueChangingOperation and mergeNode to StreamsGraphNode#toStringReviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-18552][tests] Update migration tests of StatefulJobSavepointMigrationITCase to cover migration till release-1.11,3
[FLINK-5567] [table] Introduce and migrate current table statistics to FlinkStatistic.This closes #3197.,2
[FLINK-1073] Enables sorted group input for GroupReduce combiners.- GroupReduceCombineDriver uses separate comparators for sorting and grouping.- Adding support for multiple comparators for a single input driver required some refactoring.This closes #109,4
polishing,1
[FLINK-25583][connectors/filesystem] Add compaction support for FileSink.,2
[hotfix][docs][pyflink] Regenerate docs and adjust PyFlink tests fpr FLINK-21694,2
Compatible with nacos grouping via group (#8320)* Compatible with nacos grouping via group* move nacos.group to dubbo.registry.nacos module,1
[FLINK-22877][table] Remove outdated comments,5
[FLINK-25490][checkpoint] Complete the Chinese document regarding final checkpointThis closes #18766.,2
"KAFKA-3375; Suppress deprecated warnings where reasonable and tweak compiler settings* Fix and suppress number of unchecked warnings (except for Kafka Streams)* Add `SafeVarargs` annotation to fix warnings* Suppress unfixable deprecation warnings* Replace deprecated by non-deprecated usage where possible* Avoid reflective calls via structural types in Scala* Tweak compiler settings for scalac and javacOnce we drop Java 7 and Scala 2.10, we can tweak the compiler settings further so that they warn us about more things.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Gwen Shapira, Guozhang WangCloses #1042 from ijuma/kafka-3375-suppress-depreccated-tweak-compiler",1
- extended PACT CLI client- renamed pact-run.sh to pact-client.sh,1
[FLINK-2182] Add stateful Streaming Sequence SourceCloses #804,1
"KAFKA-8351; Cleaner should handle transactions spanning multiple segments (#6722)When cleaning transactional data, we need to keep track of which transactions still have data associated with them so that we do not remove the markers. We had logic to do this, but the state was not being carried over when beginning cleaning for a new set of segments. This could cause the cleaner to incorrectly believe a transaction marker was no longer needed. The fix here carries the transactional state between groups of segments to be cleaned.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
DUBBO-78JVM之间共享长连接 git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@436 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][k8s] Abstract get common labels to KubernetesUtils#getCommonLabels,1
[FLINK-3241] Fix SNAPSHOT deployment for Scala 2.11,0
[FLINK-9991] [table] Add regexp_replace function to TableAPI and SQLThis closes #6450.,1
[hotfix] Fix unchecked conversion in JobDetailsHandler,0
"enforce broker.id to be a non-negative integer; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-424git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374440 13f79535-47bb-0310-9956-ffa450edef68",1
HOTFIX: fix Kafka Streams upgrade note for broker backward compatibility (#7363)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
update README,5
enhance ConsistentHashLoadBalance ut (#2947)* enhance ConsistentHashLoadBalance ut* modify the consistent hash loadbalance unit test* rformate code,3
"[FLINK-21602] Make SlotAllocator.tryReserveSlots failableIn order to prepare the SlotAllocator to support failing SlotAllocator.tryReserveSlotscalls, this commit changes its return type to Optional<? extends ReservedSlots>.",4
[FLINK-24277][connector/kafka] Add OffsetsInitializerValidator interface for validating offset initializer in KafkaSourceBuilder,5
KAFKA-2009 Fix two minor bugs in mirror maker.,1
[FLINK-27692][changelog] Support local recovery for materialized part,1
"[readme] Synchronize tagline with intro, fix typos",2
[FLINK-25222][tests] Remove NetworkFailureProxy used in Kafka testsWe suspect that the NetworkFailureProxy is causing constant connectivityproblems to the brokers during testing resulting in either networktimeouts or corrupted results.Since the NetworkFailureProxy is only used for testing the deprecatedFlinkKafkaProducer/Consumer we can safely remove it because we will notadd new features to the connectors.,1
[FLINK-11466][tests] Add KafkaResource,1
[FLINK-16496][hbase][table] Improve default flush strategy for new HBase sink for better out-of-boxThe default flush strategy for old HBase sink is no flush interval and 2MB buffered size.The new default flush strategy for new HBase sink is '1s' flush interval and '1000' buffered rows and '2mb' buffered size.This closes #12536,1
[FLINK-16194][k8s] Introduce the internal and the external Service decorator,2
test,3
MINOR: NetworkClient#disconnect should not erase connection infoNetworkClient#disconnect should not erase the connection information.  This will allow exponentialbackoff to occur.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3309 from cmccabe/disc,5
[FLINK-17666][table-planner-blink] Insert into partitioned table can fail with select *This closes #12656,0
[streaming] wodcount cluster settings update,5
added proxy,1
[streaming] fix some conflicts,5
[FLINK-17074] Deprecate scala Datastream.keyBy methods that do not use KeySelector,1
Merge branch 'bugfix',0
[FLINK-11273][state] Fix shared InputView object between event processing and queryable state threadThis was introduced with FLINK-9702.,2
[FLINK-28630][sql-gateway][hive] Allow to GetSchemas in the HiveServer2 EndpointThis closes #20401,1
[FLINK-18811][network] Pick another tmpDir if an IOException occurs when creating spill file,2
"KAFKA-13919: expose log recovery metrics (#12347)Implementation for KIP-831.1. add remainingLogsToRecover metric for the number of remaining logs for each log.dir to be recovered2.  add remainingSegmentsToRecover metric for the number of remaining segments for the current log assigned to the recovery thread.3. remove these metrics after log loaded completely4. add tests Reviewers: Jun Rao <jun@confluent.io>, Tom Bentley <tbentley@redhat.com>",5
[FLINK-7882][build] Fixup FLINK-7810 by excluding remaining unused jaxb dependencies,1
去掉test错误的overridegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@104 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-5374; Set allow auto topic creation to false when requesting node information onlyIt avoids the need to handle protocol downgrades and it's safe (i.e. it will never causethe auto creation of topics).Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3220 from ijuma/kafka-5374-admin-client-metadata,5
Added sample Nephele job which exploits the new union record reader,1
"MINOR: Fix flaky shouldRejectNonExistentStoreName (#9426)Fix flaky test by making sure Streams isrunning before making assertions about IQ.Reviewers: Lee Dongjin <dongjin@apache.org>, Guozhang Wang <guozhang@apache.org>, Chia-Ping Tsai <chia7712@apache.org>",3
avoid potential shutdown race condition. (#5856),5
[FLINK-10789] [scala] ScalaEitherSerializerSnapshot should be a TypeSerializerSnapshotThis also adds a migration test for the Scala EitherSerializer.This closes #7028.,3
[FLINK-13760][hive] Fix hardcode Scala version dependency in hive connectorThis closes #9473.,0
[hotfix] Rename HsResultPartitionReadScheduler to HsFileDataManager Rename HsResultPartitionReadScheduler to HsFileDataManager as it plays the same role of FileDataManager mentioned in FLIP.,5
[3.0] ServiceDefinition usage refactor & distinguish serviceName and interfaceName (#9659),4
"KAFKA-3740: Enable configuration of RocksDBStoresAdd new config StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG to enable advancedRocksDB users to override default RocksDB configurationAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Roger Hoover, Dan Norwood, Eno Thereska, Guozhang WangCloses #1640 from dguy/kafka-3740-listener",5
"KAFKA-7992: Introduce start-time-ms metric (#6318)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
[FLINK-22786][sql-client] sql-client can not create history file when under soft link path (#16029),2
[FLINK-3259] [docs] Redirect programming guides to new layout,1
renamed jdbc package properly to the new 0.4 naming conventions,1
[FLINK-15416][network] Remove ignored PartitionRequestClientFactoryTest.testResourceReleaseAfterInterruptedConnectThe test was ignored for 5 years already.,3
Merge branch 'version02' into ring_v2Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JSONGenerator.java,5
[3.0-Triple] Fix  duplicate wrap executor (#10293)* fix wrap executor* fix* fix,0
[3.0] Add max entry limit for Profiler (#9703),2
[FLINK-944] Consolidated serialization logic between different classes. Fixes for warnings.,2
bugfix init reference dead lock  (#2053)* bugfix init reference dead lock* add test* bugfix init reference dead lock #2053* remove not reference package,4
"KAFKA-9838; Add log concurrency test and fix minor race condition (#8476)The patch adds a new test case for validating concurrent read/write behavior in the `Log` implementation. In the process of verifying this, we found a race condition in `read`. The previous logic checks whether the start offset is equal to the end offset before collecting the high watermark. It is possible that the log is truncated in between these two conditions which could cause the high watermark to be equal to the log end offset. When this happens, `LogSegment.read` fails because it is unable to find the starting position to read from.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"[3.0] Improve dubbo config beans and bootstrap initialization (#8168)* Improve dubbo bootstrap initialization* Initialize dubbo config beans before spring singleton beans* add RAT* Remove @PostConstruct method from AbstractConfig, register config beans in DubboConfigBeanInitializer* fix tests",3
[hotfix] Reduce code duplication in MetricUtils,0
Bug fix in Compiler.,0
"MINOR: Auth operations must be null when talking to a pre-KIP-430 broker (#6812)Authorized operations must be null when talking to a pre-KIP-430 broker.If we present this as the empty set instead, it is impossible for clientsto know if they have no permissions, or are talking to an old broker.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
[FLINK-21108][web] Add custom netty HTTP request inbound/outbound handlersCloses #16463,0
"KAFKA-13053; Bump kraft frame version for incompatible changes from 2.8 (#11010)This patch bumps the default frame version for kraft records from 0 to 1. At the same time, we reset allrecords versions back to 0 and we enable flexible version support for UnregisterBrokerRecord, which wasmissed previously. Note that the frame version bump also affects the KIP-405 records since they aresharing AbstractApiMessageSerde. Since these records were not part of any previous releases, this shouldnot cause an issue.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
[hotfix][yarn] Remove the useless static variable of flink.yarn.Utils#DEFAULT_KEYTAB_FILEThis closes #11992.,2
[FLINK-20773][json] Support to parse unescaped control chars in string nodeThis closes #14508,1
"[hotfix][metrics] remove an unnecessary check for non-nullThe metrics group given to a Task must always be non-null otherwise the codewould have crashed anyway. Similarly, the group returned by getIOMetricGroup()is always present.",1
[FLINK-24213][qs] Introduce factory for established connection,2
DUBBO-456 去掉不必要的参数,5
Finished global sorting.Implemented TeraSort Test Case.,3
"KAFKA-9863: replace the deprecated --zookeeper options in the documentation (#8482)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
[FLINK-15177][state-backend-rocksdb] Migrate RocksDB Configurable Options to new type safe config optionsThis also simplifies the validation logic.,2
"[FLINK-1984] Mesos ResourceManager - T1 milstone (3)- Fenzo usage fix - always call scheduleOnce after expireAllLeases.- increased aggressiveness of task scheduler- factored YarnJobManager and MesosJobManager to share base class`ContaineredJobManager`- improved supervision for task actors, unit tests- support for zombie tasks (i.e. non-strict slave registry)- improved javadocs- fix for style violations (e.g. line length)- completed the SchedulerProxy- final fields- improved preconditions- log lines to use {}- cleanup ZK state- serializable messages",4
[hotfix] Drop unnecessary PowerMockRunner from RMQSourceTest,3
cleanup + documentation,2
fix cache was deleted when startup (#7484),4
"[FLINK-24303][coordination] Failure when creating a source enumerator lead to full failover, not JobManager failure.Instead of letting exceptions during the creation of the Source Enumerator bubble up (and utimately failthe JobManager / Scheduler creation), we now catch those exceptions and trigger a full (global) failoverfor that case.This closes #17324",0
KAFKA-5481: ListOffsetResponse isn't logged in the right way with trace level enabledAdded toString() method to ListOffsetResponse for loggingAuthor: ppatierno <ppatierno@live.com>Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3383 from ppatierno/kafka-5481,5
"KAFKA-13394: Topic IDs should be removed from PartitionFetchState if they are no longer sent by the controller (#11459)With KAFKA-13102, we added topic IDs to the InitialFetchState and the PartitionFetchState in order to send fetch requests using topic IDs when IBP is 3.1. However, there are some cases where we could initially send topic IDs from the controller and then no longer to do so (controller changes to an IBP < 2.8). If we do not remove from the PartitionFetchState and one broker is still IBP 3.1, it will try to send a version 13 fetch request to brokers that no longer have topic IDs in the metadata cache. This could leave the cluster in a state unable to fetch from these partitions.This patch removes the topic IDs from the PartitionFetchState if the log contains a topic ID but the request does not. This means that we will always handle a leader and isr request if there is no ID in the request but an ID in the log. Such a state should be transient because we are either * upgrading the cluster and somehow switched between a new IBP controller and an old one --> and will eventually have all new IBP controllers/brokers.* downgrading the cluster --> will eventually have all old IBP controllers/brokers and will restart the broker/delete the partition metadata file for them.Reviewers: David Jacot <djacot@confluent.io>",5
"[FLINK-16661] Move the ClassPathPackagedProgramRetriever to flink-clientsThis is done because the ClassPathPackagedProgramRetriever is going to bealso used by other ApplicationEntrypoints in the future, including theYarnApplicationClusterEntryPoint.",1
[hotfix][config] Adjust AkkaOptions to new type-safe pattern,1
[hotfix] Disable broken savepoint tests tracked in FLINK-22067,2
KAFKA-842 Mirror maker can lose some messages during shutdown; reviewed by Jun Rao,1
[FLINK-9819] Add startup scripts for standalone job cluster entry pointThis closes #6316.,1
[FLINK-12641][coordination] Release partitions on every terminal job state,2
[FLINK-28107][python][connector/elasticsearch] Support id of document is nullThis closes #20002.,2
"[hotfix] [state backend, tests] Certain StateBackendMigrationTestBase tests should fail if exception isn't thrownThis commit strengthens tests in StateBackendMigrationTestBase thatdepend on a certain state operation (restoring state, accessing state,etc.) to be failing to assert correct behaviour. However, we previouslydo not really fail the test if no exception was thrown when there shouldbe.This also caught some bugs in the test itself which had the testsverifying incorrect behaviour.",3
[FLINK-14059][table] Blink batch executor disables allVerticesInSameSlotSharingGroupByDefaultSo that each logical pipelined region can be in a different slot sharing group by default.,2
[hotfix][tests] Remove Deadlines from CommonTestUtils added in new methods,1
"KAFKA-2757; Consolidate BrokerEndPoint and EndPointAuthor: zhuchen1018 <amandazhu19620701@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #911 from zhuchen1018/KAFKA-2757",5
ConsumerOffsetChecker now works with hostnames (in addition to IP) in the brokers/ids zk path; KAFKA-549; patched by Bob Cotton; reviewed by Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1395809 13f79535-47bb-0310-9956-ffa450edef68,1
DUBBO-970 修改本地路由git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1545 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-20607][docs] Fix example of FunctionHint in udfs pageThis closes #14388Co-authored-by: 002399 <shizhengchao@fcbox.com>,1
"KAFKA-6813: Remove deprecated APIs in KIP-182, Part I (#4919)I'm breaking KAFKA-6813 into a couple of ""smaller"" PRs and this is the first one. It focused on:Remove deprecated APIs in KStream, KTable, KGroupedStream, KGroupedTable, SessionWindowedKStream, TimeWindowedKStream.Also found a couple of overlooked bugs while working on them:2.a) In KTable.filter / mapValues without the additional parameter indicating the materialized stores, originally we will not materialize the store. After KIP-182 we mistakenly diverge the semantics: for KTable.mapValues it is still the case, for KTable.filter we will always materialize.2.b) In XXStream/Table.reduce/count, we used to try to reuse the serdes since their types are pre-known (for reduce it is the same types for both key / value, for count it is the same types for key, and Long for value). This was somehow lost in the past refactoring.2.c) We are enforcing to cast a Serde<V> to Serde<VR> for XXStream / Table.aggregate, for which the returned value type is NOT known, such the enforced casting should not be applied and we should require users to provide us the value serde if they believe the default ones are not applicable.2.d) Whenever we are creating a new MaterializedInternal we are effectively incrementing the suffix index for the store / processor-node names. However in some places this MaterializedInternal is only used for validation, so the resulted processor-node / store suffix is not monotonic.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-7192] [java] Activate checkstyle flink-java/test/operatorThis closes #4335.,3
[FLINK-25199][table-planner][test] Test fromValues() watermark propagationAdd a test in table-planner to validate the correct watermarkpropagation in case of `fromValues()`.Replace assertions in the class with assertj.It follows #18420.This closes #18439.,3
"KAFKA-10624: For FeatureZNodeStatus, use sealed trait instead of Enumeration (#9561)This is a follow-up to initial KIP-584 development. In this PR, I've switched the FeatureZNodeStatus enum to be a sealed trait. In Scala, we prefer sealed traits over Enumeration since the former gives you exhaustiveness checking. With Scala enumeration, you don't get a warning if you add a new value that is not handled in a given pattern match.Reviewers: Jun Rao <junrao@gmail.com>",0
"MINOR: Fix Partition::toString method (#6971)The AllReplicas was only printing remote replica ids. This change printsall ids, including local one.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix][python][docs] Fix python.archives docsThis closes #15783.,2
"KAFKA-5124: autocommit reset earliest fixes race conditionFixes `org.apache.kafka.streams.integration.utils.IntegrationTestUtils#readKeyValues` potentially starting to `poll` for stream output after the stream finished sending the test data and hence missing it when working with `latest` offsets.Author: Armin Braun <me@obrown.io>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2921 from original-brownbear/KAFKA-5124",1
Fixing sopremo test plans,3
[FLINK-7625] [docs] Fix metric nameThis closes #4676,0
"KAFKA-2558: ServerShutdownTest is failing intermittentlySee jira for a description.Author: fpj <fpj@apache.org>Reviewers: Onur Karaman, Ismael Juma, Guozhang WangCloses #224 from fpj/KAFKA-2558",0
"[FLINK-11718][rpc] Add onStart method to RpcEndpointAdd a dedicated onStart method to the RpcEndpoint which is called when the RpcEndpointis started via the start() method. Due to this change it is no longer necessary for theuser to override the start() method which is error prone because it always requires tocall super.start(). Now this contract is explicitly enforced. Moreover, it allows toexecute the setup logic in the RpcEndpoint's main thread.",2
[hotfix] Remove MetricGroup parameter from EG builder,2
[FLINK-14869][core] Introduce Resource#isZero,2
"[hotfix][tests] Added matcher that performs deep comparison with taking Tuples into accountThis commit introduced a matcher that performs a deepEquals comparisonsimilarly to Objects#deepEquals. The only difference is that it alsoperforms deep equality check for some flink specific classes such ase.g. Tuples, Rows.",2
[hotfix][docs] Fix and improve query configuration docs.* Fix: TableConfig is *not* passed back when a Table is translated.,4
[FLINK-15972][python][table-planner][table-planner-blink] Implement Physical Python Correlate Node,2
[hotfix][docs] Minor fixes in Network Memory Tuning Guide,1
added test for TPCHQuery4 and modified the other IT cases to remove the test data in case of assertion failures,0
extend DumpLogSegments to verify consistency btw data and index; patched by Yang Ye; reviewed by Jun Rao; KAFKA-577git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1406009 13f79535-47bb-0310-9956-ffa450edef68,5
[FLINK-10166] [table] Reduce dependencies by removing org.apache.commonsThis commit removes all dependencies to org.apache.commons libraries in flink-table. Inthe past we only used a couple of methods that were partially pulled in from Hadoopcausing the issues mentioned in the JIRA ticket.This closes #6966.,0
[FLINK-14481] Unify port range check in couple of missing places,2
[FLINK-15479][jdbc] Override explainSource method for JDBCTableSource to fix project pushdown (#10769),0
Removed PACT from log messages.,2
"[FLINK-16083][docs-zh] Translate ""Dynamic Table"" page of ""Streaming Concepts"" into ChineseThis closes #11423",1
[FLINK-27570][runtime] Count checkpoint finalization failures in CheckpointFailureManager,0
[FLINK-17489][core] Support any kind of array in StringUtils.arrayAwareToString()This closes #11969.,1
[hotfix] [build] Print cache infoPrint the size of the Maven cache copied for each TravisCI job.This closes #5279.,5
[FLINK-10190] Allow AWS_REGION to be supplied along with custom Kinesis endpoint URL for region-specific signingUpdate documentationThis closes #8444,2
"MINOR: Tag `RaftEventSimulationTest` as `integration` and tweak it (#9925)The test takes over 1 minute to run, so it should not be considered aunit test.Also:* Replace `test` prefix with `check` prefix for helper methods. A commonmistake is to forget to add the @Test annotation, so it's good to use adifferent naming convention for methods that should have the annotationversus methods that should not.* Replace `Action` functional interface with built-in `Runnable`.* Remove unnecessary `assumeTrue`.* Remove `@FunctionalInterface` from `Invariant` since it's not usedin that way.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-8179: Part I, Bump up consumer protocol to v2 (#6528)1. Add new fields of subscription / assignment and bump up consumer protocol to v2.2. Update tests to make sure old versioned protocol can be successfully deserialized, and new versioned protocol can be deserialized by old byte code.Reviewers: Boyang Chen <boyang@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
[FLINK-21026][flink-sql-parser] Align column list specification syntax with hive in INSERT statementThis closes #14726,2
KAFKA-6328: Sort node groups considering global stores in InternalTopologyBuilder#makeNodeGroupsAuthor: RichardYuSTUG <yohan.richard.yu2@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4339 from ConcurrencyPractitioner/kafka-6238Minor edits on description,2
[hotfix][tests] Extract class InfiniteIntegerSource,5
[FLINK-14546][formats] Support map type in JSON formatThis closes #10060,5
"[FLINK-10406] (Part 4) testSavepointRestoreSettingstestSavepointRestoreSettings is covered byJobMaster#testRestoringFromSavepointthe triggerSavepoint part is covered by JobMasterTriggerSavepointIT,and the submit failure part should be taken care of when portJobSubmitTest, which has a test testAnswerFailureWhenSavepointReadFails",3
[FLINK-1201] [gelly] First mockup of initial API functions,1
DUBBO-161用dubbo.properties作为最后一级缺省值git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@847 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Add NullPayloadGenerator to Trogdor (#4844),1
KAFKA-6130; Ensure VerifiableConsumer halts when --max-messages is reachedAuthor: Tom Bentley <tbentley@redhat.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4157 from tombentley/KAFKA-6130-verifiable-consumer-max-messages,5
[3.0] Add tests for reference tag attribute (#8113)* Add tests for reference tag attribute* Increase shutdown timeout* Improve ShutdownTelnetHandlerTest,3
KAFKA-1071; The random partition selected in DefaultEventHandler is not random across producer instances; reviewed by Neha Narkhede and Jun Rao,0
"[FLINK-11485] [tests] Adjust existing PojoSerializer upgrade testsThe following tests have been adjusted to new scope of functionalityrelated to upgrading the PojoSerializer: PojoSerializerTest andPojoSerializerUpgradeTest.In PojoSerializerTest, assertions that were supposed to check for""isCompatibleWithReconfiguredSerializer"" cases have been adjusted tocorrectly do so. Also, a test where changing field order was tested wasremoved, since the new PojoSerializerSnapshot always assumes that fieldshave been sorted already by the type extractor.In PojoSerializerUpgradeTest, tests which remove / add fields to POJOclasses were updated to no longer expect failures. They were expectingfailures because POJOs were not evolvable in the past.The updates to these tests also provide coverage for the POJO schemaevolution feature.This closes #7759.",3
Changes to input format configurator (builder) pattern.Added pattern for output formats.,1
"MINOR: Fix shouldNotResetEpochHistoryHeadIfUndefinedPassed (#9218)In LeaderEpochFileCacheTest.scala, code is identical for `shouldNotResetEpochHistoryHeadIfUndefinedPassed` and `shouldNotResetEpochHistoryTailIfUndefinedPassed`. Seems `truncateFromStart` should be invoked in `shouldNotResetEpochHistoryHeadIfUndefinedPassed` instead of `truncateFromEnd`.",1
[FLINK-7092] [mesos] Shutdown ResourceManager components properly (FLIP-6)This closes #4289.,2
[FLINK-9757] Fix typosThis closes #6258.,2
[hotfix] fix ResourceManagerGateway,0
[FLINK-8365] Relax List type in HeapListState and HeapKeyedStateBackendThis closes #5326.,2
[FLINK-13436][e2e] Add TPC-H queries as E2E testsThis closes #9312,3
[FLINK-7868][travis] Only run checkstyle during compilationThis closes #4886.,1
删除空模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1655 1a56cb94-b969-4eaa-88fa-be21384802f2,1
fix potential NPE before mock check.,0
[FLINK-20536][tests] Update migration tests of StatefulJobWBroadcastStateMigrationITCase (Java version) to cover migration from 1.12,3
MINOR: Improve description of `max.poll.records` config (#10506)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-10748: Add IP connection rate throttling metric (KIP-612) (#9685)This PR adds the IP throttling metric as described in KIP-612.Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",5
[FLINK-28142][runtime] Enrich TaskManagerLocation with node information,5
"[FLINK-16316][operators] Remove chaining strategy methods from the StreamOperator interfaceThose methods do not have any reason to be on the StreamOperator level since we introducedStreamOperatorFactory concept, so they should be moved to SetupableStreamOperator",1
Checking in KEYS file to be used to verify Kafka releasesgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179887 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-23306][table] Reduce usages of legacy TableSchemaThis closes #16425.,2
"KAFKA-12168; Move envelope request parsing out of SocketServer (#9850)Prior to this patch, envelope handling was a shared responsibility between `SocketServer` and `KafkaApis`.  The former was responsible for parsing and validation, while the latter was responsible for authorization. This patch consolidates logic in `KafkaApis` so that envelope requests follow the normal request flow.Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
[FLINK-7222] [kafka] Fix invalid symbol * when create directory on windowsThis closes #4361.,1
[FLINK-22477][tests] Remove TestingSlotPoolImpl,3
[FLINK-9753] [formats] Add a Parquet BulkWriter,1
[hotfix][javadoc] Fix typo in StreamElement javadocThis closes #5152.,2
[FLINK-1179] [jobmanager] Add button to JobManager web interface to request stack trace of a TaskManagerThis closes #374,1
"[FLINK-3073] Replace Streaming Mode by Memory Allocation ModeBefore, streaming mode (either batch or streaming) would specify howmemory is allocated on task managers.This introduces a new configuration value taskmanager.memory.allocationthat can take values ""lazy"" or ""eager"". This controls how memory isallocated.",5
optimize of ZookeeperDynamicConfigurationTest (#9215),5
[hotfix][testutil] Fix inconsistent condition checking result in waitUntil,0
[FLINK-27027][ci] Prevent creation of empty log files,2
"KAFKA-5867: Log Kafka Connect worker info during startupAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3932 from kkonstantine/KAFKA-5867-Kafka-Connect-applications-should-log-info-message-when-starting-up",5
"KAFKA-8286; Generalized Leader Election Admin RPC (KIP-460) (#6686)Implements KIP-460: https://cwiki.apache.org/confluence/display/KAFKA/KIP-460%3A+Admin+Leader+Election+RPC.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
DUBBO-305 消费者地址注册失败不抛错，在后台重试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1470 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-12342: Remove MetaLogShim and use RaftClient directly (#10705)This patch removes the temporary shim layer we added to bridge the interfacedifferences between MetaLogManager and RaftClient. Instead, we now use theRaftClient directly from the metadata module.  This also means that themetadata gradle module now depends on raft, rather than the other way around.Finally, this PR also consolidates the handleResign and handleNewLeader APIsinto a single handleLeaderChange API.Co-authored-by: Jason Gustafson <jason@confluent.io>",5
[FLINK-22477] Remove SlotPoolImpl reference from SingleLogicalSlot,2
[FLINK-11119][docs] Correct Scala example for Table Function in User-defined Functions docs.This closes #7379.,2
[FLINK-16607][python] Update flink-fn-execution.proto adding more schema information,5
Adjusted unit tests to expression refactorings,4
[hotfix][core] Remove ResourceSpec#isValidIt is not used in production.(those setResources entries are not open to users yet)It’s not necessary given that we will guarantee to only create valid ResourceSpecs.,1
- forward exception in PactRecord.updateBinaryRepresentation(),5
[hotfix] [docs][metrics] Small typo fix in the scope section,0
Add co-location-constraints as a special case of slot-shared scheduling,1
[hotfix][docs] Improve wording in documentation README,2
[hotfix] Refactor PlannerMocks be used as holder of different mocksSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-12774][build] Pin build-helper-maven-plugin version to 1.7,2
[docs] fix loading of style sheet with protocol relative base URL,0
[FLINK-9679] Add (Confluent)(Registry)AvroSerializationSchema,5
[hotfix][tests] Remove mocks from RestClusterClientTest,3
KAFKA-2945; CreateTopic - protocol and server side implementationAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1489 from granthenke/create-wire-new,1
Improved code style,1
[FLINK-18971][kubernetes] Support to mount kerberos conf as ConfigMap and Keytab as Secrete in Kubernetes,5
[FLINK-18607][build] Give the maven module a human readable nameThis closes #12907,2
[Enhancement] Replace explicit resource management with try-with-resource (#3281),1
[FLINK-11008][state] Parallelize file upload for RocksDB incremental snapshots.Summary:This patch add the ability about uploading state files using multithread when snapshoting.Differential Revision: https://aone.alibaba-inc.com/code/D818724This closes #7351.,1
[FLINK-27806][table] Support binary & varbinary types for datagen connectorThis closes #19827.,5
KAFKA-10432; LeaderEpochCache is incorrectly recovered for leader epoch 0 (#9219)The leader epoch cache is incorrectly recovered for epoch 0 as theassignment is skipped when epoch == 0. This check was likely intended toprevent negative epochs from being applied or there was an assumptionthat epochs started at 1.A test has been added to LogSegmentTest to show the LogSegmentrecovery path works for the epoch cache. This was a test gap as none of the recover calls supply a leader epoch cache to recover.Reviewers: Jason Gustafson <jason@confluent.io>,5
[hotfix][docs] Fix typo in Windows documentation,2
"KAFKA-6526: Enable unclean leader election without controller change (#4920)Enable dynamic update of default unclean leader election config of brokers. A new controller event has been added to process unclean leader election when the config is enabled dynamically.Reviewers: Dong Lin <lindong28@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",0
[hotfix][util] Added suppressExceptions for lambda functions,1
KAFKA-14111 Fix sensitive dynamic broker configs in KRaft (#12455)Enable some of the dynamic broker reconfiguration tests in KRaft mode,3
[FLINK-22620][orc] Drop BatchTableSource OrcTableSource and related classesThis removes the OrcTableSource and related classes including OrcInputFormat. Usethe filesystem connector with a ORC format as a replacement. It is possible toread via Table & SQL API snd convert the Table to DataStream API if necessary.DataSet API is not supported anymore.This closes #15891.,1
[FLINK-3425] FileOutputFormat closes outStream in case of failureThis closes #1652.,0
system test to validate consistency of replicas; patched by John Fung; reviewed by Jun Rao; KAFKA-341git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350316 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-9040; Add --all option to config command (#7607)Implement --all option for describing all configs (both dynamic and static) as documented in KIP-524 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-524%3A+Allow+users+to+choose+config+source+when+describing+configs.Reviewers: Brian Byrne <bbyrne@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3291; DumpLogSegment tool should also provide an option to only…… verify index sanity.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Sriharsha Chintalapani <mail@harsha.io>Closes #975 from Parth-Brahmbhatt/KAFKA-3291",1
[FLINK-2113][gelly] removed env.execute() after print()This closes #749.,4
set module started at applicationDeployer checkStarted() (#9013),1
[3.0] Multi Instances - Refactor ServiceRepository (#8684)* Introduce ServiceMetadata for Triple Health check* Reintroduce some method* Refactor ServiceRepository* Support Consumer Param override* Support multi consumer* Fix ut* Fix ut* Fix ut* Fix ut* Fix ut* Fix ut* Support Multi ClassLoader* Add Multi ClassLoader Test* change zk time* change timeout* Fix compatible module support* Refactor consumer param override in ServiceDiscovery,2
[FLINK-24055][connectors/kafka] Deprecate FlinkKafkaConsumer,2
Part refactoring of abstract task as generic non-iterative control flow task.,4
[FLINK-8709] [tests] Harden SlotPoolRpcTest.testCancelSlotAllocationWithoutResourceManager #2,3
kafka-1555; provide strong consistency with reasonable availability; patched by Gwen Shapira; reviewed by Joel Koshy and Jun Rao,1
Simplified Java quickstart skeleton.,5
MINOR: Update `TransactionalMessageCopier` to use the latest transaction pattern (#11265)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-27027][ci] Add default log file suffix,0
[FLINK-22884][hive] HiveCatalog should mark views as generic and store schema in propertiesThis closes #16149,2
Fix typo of resteasy version in dubbo-maven,2
[bin] Remove MaxPermSize parameter for JVM 1.8This closes #200.,2
"[FLINK-13037][docs-zh] Translate ""Concepts -> Glossary"" page into ChineseThis closes #9763",1
"Updated TypeExtractor and TupleTpyeInfo to work on subclasses of Tuple1, Tuple2, ...",1
[hotfix] [docs] Method name for PatternFlatSelectFunction should be flatSelectThis closes #4687.,1
[FLINK-14156][runtime] Refactoring: move ProcessingTimeService access request at operator level,1
[FLINK-4831][metrics] Implement slf4j metric reporterThis closes #4661.,2
KAFKA-12620 Allocate Producer IDs in KRaft controller (#10752)This is part 2 of KIP-730. Part 1 was in #10504.This PR adds QuorumController support for handling AllocateProducerIDs requestsand managing the state of the latest producer ID block in the controller by committingthis state to the metadata log.Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
[hotfix] Fix incorrect license headers,0
"[FLINK-17725][tests] Disable OkHttpClient timeouts for FileUploadHandlerTestIn order to harden the test case FileUploadHandlerTest, this commit disables the timeoutsof the used OkHttpClient.This closes #12248.",1
[FLINK-13524][es][docs] Fix typo,2
Comparators for Value types,5
Tasks submissions are now bundled in groups to reduce deployment latency,5
[scala] Reactivate DeltaIterationSanityCheckTest,3
[FLINK-6512] [docs] improved code formatting in some examplesThis closes #3857,1
[FLINK-10689] [table] Port UDF interfaces to flink-table-commonThis commit ports all UDF extension points to Java and relocates themto flink-table-common. Projects that just want to provide functionsdon't need to import flink-table and thus Scala anymore.This closes #7059.,2
[streaming] RMQ source for multiple types,5
"KAFKA-3583: Add documentation for Connect status control APIsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Roger Hoover <roger.hoover@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1358 from hachikuji/KAFKA-3583",5
MINOR: Upgrade ducktape to 0.7.5 (#6197)Reviewed-by: Colin P. McCabe <cmccabe@apache.org>,2
[FLINK-17520] [doc] Use new resolveOuterSchemaCompatibility in custom serialization docsThis closes #12209.,2
remove testfile,3
[FLINK-7836][Client] specifying node label for flink job to run on yarn[FLINK-7836] refactor the code and added some test code[FLINK-7836][Client] mark field : nodeLabelExpressionMethod @NullableThis closes #5593.,2
"KAFKA-6795; Added unit tests for ReplicaAlterLogDirsThreadAdded unit tests for ReplicaAlterLogDirsThread. Mostly focused on unit tests for truncating logic.Fixed  ReplicaAlterLogDirsThread.buildLeaderEpochRequest() to use future replica's latest epoch (not the latest epoch of replica it is fetching from). This follows the logic that offset for leader epoch request should be based on leader epoch of the follower (in this case it's the future local replica).Also fixed PartitionFetchState constructor that takes offset and delay. The code ignored the delay parameter and used 0 for the delay. This constructor is used only by another constructor which passes delay = 0, which luckily works.Author: Anna Povzner <anna@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #4918 from apovzner/kafka-6795",5
"[FLINK-1204] [streaming] Individual, self-contained packaging for streaming examples",2
"KAFKA-5086: Update topic expiry time in Metadata every time the topic metadata is requestedUpdate topic expiry time after every metadata update to handle max.block.ms greater than 5 minutesAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #2869 from lindong28/KAFKA-5086",5
"[FLINK-4306] [storm compatibility] Fix dependencies in flink-storm and flink-storm-examples  - Flink dependencies are now 'provided'  - flink-storm-examples has no direct storm-core dependency, but only depends through flink-storm",2
[FLINK-6175] Harden HistoryServerTest#testFullArchiveLifecycleThis closes #3655.,3
"[Dubbo-3653] etcd as config center (#3663)* Minor refactor, no functinoal change.* Separate ConnectionStateListener* Simplify code* Fix typo* Support get external config from etcd config center* Polish diamond operator* Initial etcd support as config center* Add a put interface for JEtcdClient* Enhanced Etcd config center support with the ability to watch and cancel watch* Polish code* Distinguish modification event and delete event* Add etcd registry and configcenter to dubbo-all* Watch again when connection is re-established",5
KAFKA-5180; Fix transient failure in ControllerIntegrationTest.testControllerMoveIncrementsControllerEpochThe tests previously ignored the fact that the controller does not atomicallycreate the /controller znode and create/increment the /controller_epoch znode.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3038 from onurkaraman/KAFKA-5180,2
"[hotfix][runtime, test] Unify formatting in StreamConfigChainer",5
[FLINK-16837][build] Disable trimStackTrace in surefire-plugin,2
[FLINK-24543][runtime] Avoid possible inconsistencies of ZookeeperStateHandleStore in case of unstable connection.This closes #17607.,0
MINOR: Fix typo in leader epoch change log message (#4476),2
[tests] Make timeout discarding checks in CheckpointCoordinatorTest more robust.,3
[hotfix][runtime] Remove unnecessary method.,4
kafka-1280; exclude kafka-clients jar from dependant-libs dir; patched by Jun Rao; reviewed by Neha Narkhede,5
[FLINK-12766][runtime] Fix bug in merging and converting UNKNOWN ResourceSpecs.,0
[FLINK-27068][python][tests] Fix the unstable tests test_keyed_min_and_max and test_keyed_min_by_and_max_by (#19369),3
[FLINK-11048] Mark new RemoteStreamEnvironment constructor PublicEvolving,3
"KAFKA-7459: Use thread-safe Pool for RequestMetrics.requestRateInternal (#5717)As part of KAFKA-6514, the `apiVersion` tag was added to the `RequestsPerSec`metric. A thread unsafe `HashMap` was used in the implementation even thoughit can be accessed by multiple threads. Fix it by replacing it with the thread-safe`Pool`.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"Move plan checking from PactProgram to ClientClient would invoke PactProgram.checkPlan(), but this is the only placewhere this was done, so I moved it.This is in preparation of further cleanups and a slight refactoring ofPactProgram.",4
[FLINK-11334] Add good TypeSerializerSchemaCompatibility.toString()This makes it easier to read messages of failing tests.,3
"Refactor TupleTypeInfo and add GenericPairComparatorNow we have TupleTypeInfoBase, TupleSerializerBase, and TupleComparatorBase. Theyare now super classes of TupleTypeInfo and the others.Also rename compare on DataInputView to compareSerialized because Scalacannot distinguish between the to compare methods for some reason.This change is necessary for allowing the Scala API to reuse most of thefunctionality.The GenericPairComparator uses the new extractKeys method ofTypeComparator to compare values of any type. This replacesTuplePairComparator and some other special-case pair comparators. Thisis preparatory work for enabling support for Scala Tuples and POJOcomparators.",1
[FLINK-1462][gelly][docs] added gelly guide,1
[FLINK-16914][python] Support ArrayType in vectorized Python UDF,1
[FLINK-20086][python][docs] Add documentation about how to override open() in UserDefinedFunction to load resourcesThis closes #15795.,1
[FLINK-3371] [api-breaking] Move TriggerResult and TriggerContext to dedicated classesThis closes #1603,4
"KAFKA-9274: Handle TimeoutException on commit (#9570)- part of KIP-572 - when KafkaStreams commits a task, a TimeoutException should not kill   the thread but `task.timeout.ms` should be triggered and the commit   should be retried in the next loopReviewer: John Roesler <john@confluent.io>",5
[storm-compat] Added README files to Storm compatibility modules,2
[FLINK-15118] Make flink-scala-shell use Executors,1
[FLINK-26055][table] Use FlinkVersion rather than version string from core in persisted planThis closes #18755.,2
"MINOR: Respect the default value of partition argument in SimpleConsumerShellThe `partition` argument is not marked as required, and has a default of `0`, according to the tool's help message. However, if `partition` is not provided the command returns with `Missing required argument ""[partition]""`. This patch is to fix the required arguments of the tool by removing `partition` from them.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1495 from vahidhashemian/minor/simple_consumer_shell_update_required_args",5
changed basis array test case and ignored failing test from LazyArrayNode,3
[FLINK-3046] Integrate the Either Java type with the TypeExtractorThis closes #1393.,4
[hotfix][docs] Fix typo,2
Polish README,1
Added some debug output,0
"KAFKA-2146: Fix adding partition did not find the correct startIndex.TopicCommand provide a tool to add partitions for existing topics. It try to find the startIndex from existing partitions. There's a minor flaw in this process, it try to use the first partition fetched from zookeeper as the start partition, and use the first replica id in this partition as the startIndex.One thing, the first partition fetched from zookeeper is not necessary to be the start partition. As partition id begin from zero, we should use partition with id zero as the start partition.The other, broker id does not necessary begin from 0, so the startIndex is not necessary to be the first replica id in the start partition.Author: chenshangan <chenshangan@meituan.com>Reviewers: Guozhang WangCloses #329 from shangan/trunk-KAFKA-2146",1
[streaming] Implemented basic record acknowledgment,5
[hotfix][docs] Fix typo for 'exactly-once' in docs,2
KAFKA-13444: Fix OAuthCompatibilityTool help and add SSL options (#11486)Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-9441: Cleanup Streams metrics for removed task commit latency metrics (#8356)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
[FLINK-11384][mesos] Remove legacy MesosTaskManager,4
Renaming part 7 (tests),3
[streaming] Performance removed,4
[hotfix][docs] fix tab syncronization in documentationFixes the synchronization of tabs so that if a tab group on thepage does not contain the selection it will remain in a validstate of its existing selected tab.,2
"[FLINK-13066][hive] append hive-site.xml to path of Hive conf dirThis PR fixes a bug that we previously only pass Hive conf dir to HiveConf but we really should pass path of hive-site.xml. Thus, the change is to append hive-site.xml to the Hive conf dir and pass into HiveConf if Hive conf dir is not null.This closes #8955.",5
[hotfix] Fix checkstyle violations,0
[FLINK-25183][table] Optimize changelog normalize for the managed table upsert modeThis closes #18199,4
JDK17 Support for Dubbo (#9062)* Add JDK17 Support for Javaassist* compact javaassist* compact javaassist* opt code* fix compile* fix classpath* add ant* tmp fix* fix ut* change name* Refactor get class* remove reflect get stackTrace* Fix support jdk 17* Add jdk 17 to ut* Add jdk 17 to ut* update mockito version* update jacoco* ignore java compile* add open* fix ut* fix ut* fix jupiter api* fix pom* disable zk 3.4* disable script router in jdk 17* remove curator5* fix ut* fix ut* fix ut* fix ut* fix ut* fix ut* fix ut* fix ut* fix zk* remove test scope* fix ut* add open* fix ut* add curator* fix pom* fix pom* enable debug* remove add open* add open profile* auto activate open* disable test in zk* refactor zk dependency* remove curator test* add zookeeper dependency* fix compile* change zk default wait time* change zk default wait time* fix ut* set throwable message by constructor* Add unit prepare jdk 17 support* fix zk dependency* remove jackson-databind,5
"[hotfix] [avro] Define Avro version through variableAvro version is used multiple times (dependendies and plugins),having a variable makes sure we use those in sync.",1
[FLINK-8978] Stateful generic stream job upgrade e2e testThis closes #5947.,3
Extracted OS detection into separate class.Reworked hardware configuration factory.,5
[FLINK-12479][operators] Integrate StreamInputProcessor with mailbox,2
[FLINK-27933][coordination] OperationResult is serializable,2
[FLINK-10213] Task managers cache a negative DNS lookup of the blob server indefinitely* Added a test case for unresolved InetSocketAddresses that fails before the fix* Updated BlobClient to create the socket using the hostname and portAdded a check in the BlobClientTest.testUnresolvedInetSocketAddress() that the client is connected.This closes #6862.,3
[FLINK-13738][blink-table-planner] Fix NegativeArraySizeException in LongHybridHashTableThis closes #9462,0
[FLINK-24253][jdbc] Cleanup JavaDoc of newly public interfaces,1
add Registry protocol listener (#5581)add Registry protocol listener,1
修改页面git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@400 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][tests] Fix compiler warning in MetricFetcherTest,3
DUBBO-970 修改lookupgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1608 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-7903] [tests] Add flip6 build profileThe flip6 build profile only runs the Flip-6 related test cases. Moreover,all Flip-6 related test cases are excluded when not running the flip6 buildprofile. This should reduce testing time when adding more and more Flip-6test cases.Include flink-test-utils-junit in all submodules to make the Category marker interfaces Flip6 and OldAndFlip6 availableThis closes #4889.",1
"MINOR: Improve the org.apache.kafka.common.protocol code (#7344)Add UUID to the list of types documented in Type#toHtml.Type, Protocol, ArrayOf: use Type#isArray and Type#arrayElementType rather than typecasting to handle arrays.  This is cleaner.  It will also make it easier for us to add compact arrays (as specified by KIP-482) as a new array type distinct from the old array type.Add MessageUtil#byteBufferToArray, as well as a test for it.  We will need this for handling tagged fields of type ""bytes"".Schema#Visitor: we don't need a separate function overload for visiting arrays. We can just call ""visit(Type field)"".TestUUID.json: reformat the JSON file to match the others.ProtocolSerializationTest: improve the error messages on failure.  Check that each type has the name we expect it to have.Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, Vikas Singh <soondenana@users.noreply.github.com>",1
"[FLINK-1323] Refactor I/O Manager Readers and Writers to interfaces, add implementation that uses callbacks on completed write requests. - This change also allows for a very simple way of plugging in a synchronous version of the I/O manager.This closes #193.",1
Adapted Sopremo code to compensate the missing IOReadableWritable interface,2
[hotfix] [core] Minor cleanup in SignalHandler.This makes the signal handler registration atomic and does not fail (but ignore) re-registration.,0
[hotfix][tests] Remove magic number,4
KAFKA-10079: improve thread-level stickiness (#8775)Uses a similar (but slightly different) algorithm as in KAFKA-9987 to produce a maximally sticky -- and perfectly balanced -- assignment of tasks to threads within a single client. This is important for in-memory stores which get wiped out when transferred between threads.Reviewers: John Roesler <vvcephei@apache.org>,1
"KAFKA-6566: Improve Connect Resource CleanupThis is a change to improve resource cleanup for sink tasks and source tasks.  Now `Task.stop()` is called from both `WorkerSinkTask.close()` and `WorkerSourceTask.close()`.It is called from `WorkerXXXTask.close()` since this method is called in the `finally` block of `WorkerTask.run()`, and Connect developers use `stop()` to clean up resources.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5020 from rayokota/K6566-improve-connect-resource-cleanup",4
[FLINK-1201] [gelly] empty test todos for implemented operations,2
[FLINK-9925][tests] Harden ClientTest by making handler shareableThis commit makes the handler that is used for the testConcurrentQueries shareable sothat Netty won't fail if another pipeline is created.,1
[hotfix] Fix checkstyle violations in HighAvailabilityServices,0
"KAFKA-10259: KIP-554 Broker-side SCRAM Config API (#9032)Implement the KIP-554 API to create, describe, and alter SCRAM user configurations via the AdminClient.  Add ducktape tests, and modify JUnit tests to test and use the new API where appropriate.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
DUBBO-537 configserver注册中心地址可以不配,5
[FLINK-17562][rest] Use correct headers for POST JobPlanHandler,0
Added temp vertex to avoid blocking when using range partitioner,1
[hotfix] Refactor test_yarn_kerberos_docker.sh by moving common functions to common_yarn_docker.sh.,2
[FLINK-23454][runtime] Added the support of changing the max capacity to BufferBuilder,4
Merge branch 'master-merged-performance-cloudnative'# Conflicts:#dubbo-bootstrap/dubbo-bootstrap-spring/src/main/java/org/apache/dubbo/config/spring/beans/factory/annotation/ReferenceAnnotationBeanPostProcessor.java#dubbo-bootstrap/dubbo-bootstrap-spring/src/main/java/org/apache/dubbo/config/spring/util/ClassUtils.java#dubbo-cluster/src/main/java/org/apache/dubbo/rpc/cluster/router/tag/TagRouter.java#dubbo-common/pom.xml#dubbo-common/src/main/java/org/apache/dubbo/common/URL.java#dubbo-common/src/main/java/org/apache/dubbo/common/config/configcenter/Constants.java#dubbo-common/src/main/java/org/apache/dubbo/common/constants/CommonConstants.java#dubbo-common/src/main/java/org/apache/dubbo/common/utils/ReflectUtils.java#dubbo-common/src/main/java/org/apache/dubbo/common/utils/StringUtils.java#dubbo-common/src/main/java/org/apache/dubbo/common/utils/UrlUtils.java#dubbo-common/src/main/java/org/apache/dubbo/config/AbstractConfig.java#dubbo-common/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-common/src/main/java/org/apache/dubbo/config/AbstractReferenceConfig.java#dubbo-common/src/main/java/org/apache/dubbo/config/AbstractServiceConfig.java#dubbo-common/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-common/src/main/java/org/apache/dubbo/config/Constants.java#dubbo-common/src/main/java/org/apache/dubbo/rpc/support/ProtocolUtils.java#dubbo-compatible/src/main/java/com/alibaba/dubbo/common/Constants.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/AbstractConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/AbstractReferenceConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/AbstractServiceConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ConfigCenterConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/builders/AbstractReferenceBuilderTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/builders/AbstractServiceBuilderTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/url/UrlTestBase.java#dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/ServiceBean.java#dubbo-configcenter/dubbo-configcenter-apollo/src/main/java/org/apache/dubbo/configcenter/support/apollo/ApolloDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/main/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-dependencies-bom/pom.xml#dubbo-dependencies/dubbo-dependencies-zookeeper/pom.xml#dubbo-metadata-report/dubbo-metadata-report-api/src/main/java/org/apache/dubbo/metadata/integration/MetadataReportService.java#dubbo-metadata-report/dubbo-metadata-report-api/src/test/java/org/apache/dubbo/metadata/integration/MetadataReportServiceTest.java#dubbo-metadata-report/dubbo-metadata-report-etcd/src/test/java/org/apache/dubbo/metadata/store/etcd/EtcdMetadataReportTest.java#dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/Constants.java#dubbo-remoting/dubbo-remoting-netty4/src/main/java/org/apache/dubbo/remoting/transport/netty4/NettyClientHandler.java#dubbo-remoting/dubbo-remoting-netty4/src/main/java/org/apache/dubbo/remoting/transport/netty4/NettyServerHandler.java#dubbo-remoting/dubbo-remoting-zookeeper/src/main/java/org/apache/dubbo/remoting/zookeeper/curator/CuratorZookeeperClient.java#dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/Constants.java#dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/ContextFilter.java#dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/GenericFilter.java#dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/interceptors/ConsumerContextClusterInterceptor.java#dubbo-rpc/dubbo-rpc-dubbo/src/test/java/org/apache/dubbo/rpc/service/GenericServiceTest.java#dubbo-rpc/dubbo-rpc-dubbo/src/test/java/org/apache/dubbo/rpc/validation/ValidationTest.java#dubbo-rpc/dubbo-rpc-rest/src/main/java/org/apache/dubbo/rpc/protocol/rest/RpcContextFilter.java#dubbo-rpc/dubbo-rpc-rest/src/test/java/org/apache/dubbo/rpc/protocol/rest/RestProtocolTest.java#pom.xml,5
[FLINK-9567][yarn] Before requesting new containers always check if it is requiredBy comparing the number of pending slot requests and the number of pending container allocationsit is possible to say whether we should allocate more containers or not.This closes #6669.,5
"Revert ""[FLINK-17303][python] Support Python TableResult""This reverts commit 381131a785700a7d07b822d6db4eaa72d2daab61.",5
"[FLINK-18136][checkpointing] Don't start channel state writer for savepointChannelStateWriter#start should be only called for unaligned checkpoint. While source triggeringsavepoint, SubtaskCheckpointCoordinator#initCheckpoint is introduced to judge the conditionwhether to start the internal writer or not. And this new method is also used in other places likeCheckpointBarrierUnaligner.This closes #12489.",1
"MINOR: log 2min processing summary of StreamThread loop (#9941)Remove all INFO-level logging from the main StreamThread loop in favor of a summary with a 2min intervalReviewers: Walker Carlson <carlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: internal config objects should not be logged (#5389)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"[streaming] [examples] Refactor and packaging for windowing examplesThe current examples show-case the API, more meaningful examples are coming for the 0.9 release.",4
"[FLINK-3667] refactor client communication classes- ClusterDescriptor: base interface for cluster deployment descriptors- ClusterDescriptor: YarnClusterDescriptor- ClusterClient: base class for ClusterClients, handles lifecycle of cluster- ClusterClient: shares configuration with the implementations- ClusterClient: StandaloneClusterClient, YarnClusterClient- ClusterClient: remove run methods and enable detached mode via flag- CliFrontend: remove all Yarn specific logic- CliFrontend: remove all cluster setup logic- CustomCommandLine: interface for other cluster implementations- Customcommandline: enables creation of new cluster or resuming from existing- Yarn: move Yarn classes and functionality to the yarn module (yarn  properties, yarn interfaces)- Yarn: improve reliability of cluster startup- Yarn Tests: only disable parallel execution of ITCasesThis closes #1978",3
[FLINK-18905][hotfix][task] Move output and collector helper classes out of OperatorChain,1
[hotfix][test] Converting fraction to double to improve the precision,1
"[FLINK-5699] [savepoints] Check target dir when cancelling with savepointProblem: when cancelling a job with a savepoint and no savepoint directoryis configured, triggering the savepoint fails with an NPE. This is thenreturned to the user as the root cause.Solution: Instead of simply forwarding the argument (which is possiblynull), we check it for null and return a IllegalStateException witha meaningful message.This closes #3263.",1
[hotfix] Move addJars() from ClientUtils to JobGraph,1
[FLINK-16744][task][test][hotfix] Fix formattingRemove extra newline in TestTaskStateManager,3
Reduced logging during task recovery,2
[hotfix][table-common] Fix invalid conversion class in data type transformer,5
"KAFKA-5146: remove Connect dependency from Streams module (#10131)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Ismael Juma <ismael@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Adopted optimizer test classes to new datamodel.,5
"[FLINK-23070][table-api-java] Introduce TableEnvironment#createTableThis behaves much like the previously introduced #createTemporaryTable,but actually permanently stores the table in a catalog.This closes #16285.",2
KAFKA-13590:rename InternalTopologyBuilder#topicGroups (#11704)Renamed the often confusing and opaque #topicGroups API to #subtopologyToTopicsInfoReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
Reformatted ChannelCheckpoint.java according to code style rules,5
KAFKA-6210; IllegalArgumentException if 1.0.0 is used for inter.broker.protocol.version or log.message.format.versionAdded unit test for ApiVersion and testApiVersions fromScala to Java.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4220 from ijuma/kafka-6210-iae-if-1.0.0-inter-broker-protocol-version,5
[FLINK-2123] Fix log4j warnings on CliFrontend startupThis closes #783,2
[FLINK-4737] [core] Ensure that Flink and its Hadoop dependency pull the same version of 'commons-compress',2
"KAFKA-404 When using chroot path, create chroot on startup if it doesn't exist; reviewed by Neha Narkhede",1
[FLINK-10076][table-planner-blink] Upgrade Calcite dependency to 1.18,2
"[FLINK-16573] Ensure Kinesis RecordFetcher threads shutdown on cancelThe threads may not shut down correctly because they do not check for therunning flag in the inner loops. The threads also do not get interrupted becausethey are not connected to the main task thread.These threads keep lingering around after the job has shut down:```Thread 23168: (state = BLOCKED) - java.lang.Object.wait(long) @bci=0 (Compiled frame; information may be imprecise) - org.apache.flink.streaming.connectors.kinesis.util.RecordEmitter.emitRecords() @bci=140, line=209 (Compiled frame) - org.apache.flink.streaming.connectors.kinesis.util.RecordEmitter.run() @bci=18, line=177 (Interpreted frame) - java.lang.Thread.run() @bci=11, line=748 (Compiled frame)```",1
[FLINK-28178][runtime-web] Show the delegated StateBackend and whether changelog is enabled in the UI,0
[hotfix][core] Fix broken JavaDoc link in FileUtils,2
[FLINK-8404] [tests] Mark Flip-6 tests with Flip6 category annotationMarks all existing Flip-6 test cases with the Flip6 category annotation. Thatway they are only run if the Flip-6 test profile is active.This closes #5278.,2
"MINOR: Add ConfigRepository, use in Partition and KafkaApis (#10005)`Partition` objects are able to retrieve topic configs when creating their log, and currently they do so with an implementation of `trait TopicConfigFetcher` that uses ZooKeeper.  ZooKeeper is not available when using a Raft-based metadata log, so we need to abstract the retrieval of configs so it can work either with or without ZooKeeper.  This PR introduces `trait ConfigRepository` with `ZkConfigRepository` and `CachedConfigRepository` implementations.  `Partition` objects now use a provided `ConfigRepository` to retrieve topic configs, and we eliminate `TopicConfigFetcher` as it is no longer needed.`ReplicaManager` now contains an instance of `ConfigRepository` so it can provide it when creating `Partition` instances.`KafkaApis` needs to be able to handle describe-config requests; it currently delegates that to `ZkAdminManager`, which of course queries ZooKeeper.  To make this work with or without ZooKeeper we move the logic from `ZkAdminManager` into a new `ConfigHelper` class that goes through a `ConfigRepository` instance.  We provide `KafkaApis` with such an instance, and it creates an instance of the helper so it can use that instead of going through `ZkAdminManager`.Existing tests are sufficient to identify bugs and regressions in `Partition`, `ReplicaManager`, `KafkaApis`, and `ConfigHelper`.  The `ConfigRepository` implementations have their own unit tests.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-5956; use serdes from materialized in table and globalTableThe new overloads `StreamBuilder.table(String, Materialized)` and `StreamsBuilder.globalTable(String, Materialized)` need to set the serdes from `Materialized` on the internal `Consumed` instance that is created, otherwise the defaults will be used and may result in serialization errorsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3936 from dguy/table-materialized",5
[FLINK-11545] [container] Pass job ID to ClassPathJobGraphRetriever,4
[FLINK-16871][runtime] Make more build time information available at runtime,1
KAFKA-10519; Add missing unit test for `VotedState` (#9337)Add a simple unit test for `VotedState`. Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
[FLINK-1679] use a consistent name for parallelism* rename occurrences of degree of parallelism to parallelism* [Dd]egree[ -]of[ -]parallelism -> [pP]arallelism* (DOP|dop) -> [pP]arallelism* paraDegree -> parallelism* degree-of-parallelism -> parallelism* DEGREE_OF_PARALLELISM -> PARALLELISM,1
[FLINK-19479] Add Javadocs to IntervalJoin.in(Processing|Event)Time,2
"KAFKA-8943: Move SecurityProviderCreator to org.apache.kafka.common.security.auth package (#7564)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-4200; Fix throttle argument in kafka-reassign-partitions.shSimple jira which alters two things:1. kafka-reassign-partitions --verify prints Throttle was removed regardless of whether a throttle was applied. It should only print this if the value was actually changed.2. --verify should exception if the —throttle argument. (check generate too)To test this I extracted all validation logic into a separate method and added a test which covers the majority of combinations. The validation logic was retained as is, other than implementing (2) and adding validation to the --broker-list option which you can currently apply to any of hte main actions (where it is ignored). Requirement 1 was tested manually (as it's just println).Testing:- Build passes locally.- System test reassign_partitions_test.py also passes.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1896 from benstopford/KAFKA-4200",4
"KAFKA-6018: Make KafkaFuture.Future an interface (KIP-218)Changing KafkaFuture.Future and KafkaFuture.BiConsumer into an interface makesthem a functional interface.  This makes them Java 8 lambda compatible.Author: Colin P. Mccabe <cmccabe@confluent.io>Author: Steven Aerts <steven.aerts@gmail.com>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Xavier Léauté <xl+github@xvrl.net>, Tom Bentley <tbentley@redhat.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4033 from steven-aerts/KAFKA-6018",5
Implements the ascending flag for basic type comparators.,5
[hotfix][table-planner] Make sure the iterator is always closed when reading results in BuiltInFunctionTestBaseSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
MINOR: Fix log message error of loadTransactionMetadata (#6571)Reviewers: Jason Gustafson <jason@confluent.io>,5
[hotfix] Close ResourceManager LeaderRetrievalService in TaskExecutor,0
[hotfix][network] Fix useless backlog value in BufferAndAvailability returned by RemoteInputChannel#getNextBuffer,1
[FLINK-11289][examples] Rework examples to account for licensing,1
[FLINK-16657] Allow the (Stream)ContenxtEnv to enforce single job execution,1
[FLINK-13082][table-planner-blink] Support MatchRecognize in blink plannerThis closes #8974,2
[FLINK-3405] [nifi] Extend NiFiSource with interface StoppableFunctionThis closes #2047,1
[FLINK-15510] Pretty Print StreamGraph JSON Plan,5
"[hotfix][runtime] If not specified, set Total Flink Memory according to JVM free heap memory for MiniCluster.",5
[FLINK-6964] [checkpoint] Fix externalized incremental checkpoints for StandaloneCompletedCheckpointStore,0
Fix checkstyle warning for Writable,2
"[FLINK-27292][docs-zh] Translate the ""Data Type Extraction"" section of ""Data Types"" to Chinese. This closes #20316* [FLINK-27292][docs-zh] Translate the ""Data Type Extraction"" section of ""Data Types"" to Chinese",5
[FLINK-17026][kafka] Introduce a new Kafka connect or with new property keysThis close #12150,5
"[FLINK-5810] [flip-6] Introduce a hardened slot managerHarden the slot manager so that it better deals with lost and out of order messagesfrom the TaskManager. The basic idea is that the TaskManager are considered the groundtruth and the SlotManager tries to maintain a consistent view of what is reported to itby the TaskManagers. This has the assumption that the TaskManagers regularly report theirslot status to the SlotManager piggy backed on the heartbeat signals to the ResourceManager.That way it is possible to handle lost and out of order messages because the SlotManagerwill eventually converge on a consistent view of the actual slot allocation.Additionally, the hardened SlotManager registers for idle TaskManagers and pending slotrequests a timeout. If the timoeut expires, then the TaskManagers are released and theslot request is failed. This prevents resource leaks and wasteful resource allocation.This closes #3394.",0
[FLINK-20223][runtime] (part 2) Set user code classloader as context class loader for SplitEnumerator creation and threadCo-authored-by: Jiangjie (Becket) Qin <jiangjie.qj@alibaba-inc.com>  - This moves the instantiation of the SplitEnumerator out of the constructor to prevent double-instantiation  - Add context class loaders to creation and coordinator thread  - Class-loading and SplitEnumerator instantiation is purely handled in the SourceCoordinator and does not leak    into RecreateOnResetOperatorCoordinator.,1
[FLINK-1871] [gelly] [docs] added a link to the migration guide in the Spargel guide;moved the migration guide section to the end of Gelly guide;made a few corrections in the migration guide textThis closes #600,4
"MINOR: fix quoted boolean in FetchRequest.json (#10998)Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",5
Change variable name,4
trivial change to catch all throwables in ProducerSendThreadgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1211747 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-26093][tests] Adjust SavepointFormatITCase for ChangelogStateBackend,4
Remove wait flag from CLI client. Wait is now the default.,4
"[hotfix][table-common] Introduce ObjectIdentifier.ofAnonymous to allow storing anonymous, but still uniquely identified, namesThis closes #18370.",1
ignore instance when metadataInfo is null (#8180),5
[hotfix][checkstyle] fix comments in SingleInputGate,0
"KAFKA-5759; Allow user to specify relative path as log directoryAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin<becket.qin@gmail.com>Closes #3709 from lindong28/KAFKA-5759",2
[hotfix][docs][conf] Setup logging for generator,2
[FLINK-21135][coord] Adds Precondition to AdaptiveSchedulerThis check is necessary since AdaptiveScheduler.calculateDesiredResourcesexpects the parallelism to be set for each JobVertex.,1
[FLINK-5904] Make jobmanager.heap.mb and taskmanager.heap.mb work in YARN modeThis closes #3414.,1
[FLINK-11583][configuration] Support deprecated and fallback keys at once,1
support method sync timeout (#4436)fixes #4435,0
[FLINK-9003][hotfix] Code cleanup.,4
changed write set and output schema computation,1
add visual-studio-code ignore (#6221),1
[FLINK-20552][jdbc] JdbcDynamicTableSink doesn't sink buffered data on checkpointThis closes #14387,5
Merge branch '2.5.x'# Conflicts:#all/pom.xml#dubbo-admin/pom.xml#dubbo-admin/src/main/java/com/alibaba/dubbo/governance/web/governance/module/screen/Providers.java#dubbo-cluster/pom.xml#dubbo-common/pom.xml#dubbo-config/dubbo-config-api/pom.xml#dubbo-config/dubbo-config-spring/pom.xml#dubbo-config/dubbo-config-spring/src/main/java/com/alibaba/dubbo/config/spring/ServiceBean.java#dubbo-config/pom.xml#dubbo-container/dubbo-container-api/pom.xml#dubbo-container/dubbo-container-jetty/pom.xml#dubbo-container/dubbo-container-log4j/pom.xml#dubbo-container/dubbo-container-logback/pom.xml#dubbo-container/dubbo-container-spring/pom.xml#dubbo-container/pom.xml#dubbo-demo/dubbo-demo-api/pom.xml#dubbo-demo/dubbo-demo-consumer/pom.xml#dubbo-demo/dubbo-demo-provider/pom.xml#dubbo-demo/pom.xml#dubbo-filter/dubbo-filter-cache/pom.xml#dubbo-filter/dubbo-filter-validation/pom.xml#dubbo-filter/pom.xml#dubbo-maven/pom.xml#dubbo-monitor/dubbo-monitor-api/pom.xml#dubbo-monitor/dubbo-monitor-default/pom.xml#dubbo-monitor/pom.xml#dubbo-plugin/dubbo-qos/pom.xml#dubbo-plugin/pom.xml#dubbo-registry/dubbo-registry-api/pom.xml#dubbo-registry/dubbo-registry-default/pom.xml#dubbo-registry/dubbo-registry-multicast/pom.xml#dubbo-registry/dubbo-registry-redis/pom.xml#dubbo-registry/dubbo-registry-zookeeper/pom.xml#dubbo-registry/pom.xml#dubbo-remoting/dubbo-remoting-api/pom.xml#dubbo-remoting/dubbo-remoting-grizzly/pom.xml#dubbo-remoting/dubbo-remoting-http/pom.xml#dubbo-remoting/dubbo-remoting-mina/pom.xml#dubbo-remoting/dubbo-remoting-netty/pom.xml#dubbo-remoting/dubbo-remoting-netty4/pom.xml#dubbo-remoting/dubbo-remoting-p2p/pom.xml#dubbo-remoting/dubbo-remoting-zookeeper/pom.xml#dubbo-remoting/pom.xml#dubbo-rpc/dubbo-rpc-api/pom.xml#dubbo-rpc/dubbo-rpc-default/pom.xml#dubbo-rpc/dubbo-rpc-default/src/main/java/com/alibaba/dubbo/rpc/protocol/dubbo/DubboProtocol.java#dubbo-rpc/dubbo-rpc-hessian/pom.xml#dubbo-rpc/dubbo-rpc-http/pom.xml#dubbo-rpc/dubbo-rpc-injvm/pom.xml#dubbo-rpc/dubbo-rpc-memcached/pom.xml#dubbo-rpc/dubbo-rpc-redis/pom.xml#dubbo-rpc/dubbo-rpc-rmi/pom.xml#dubbo-rpc/dubbo-rpc-thrift/pom.xml#dubbo-rpc/dubbo-rpc-webservice/pom.xml#dubbo-rpc/pom.xml#dubbo-simple/dubbo-monitor-simple/pom.xml#dubbo-simple/dubbo-registry-simple/pom.xml#dubbo-simple/pom.xml#dubbo-test/dubbo-test-benchmark/pom.xml#dubbo-test/dubbo-test-compatibility/dubbo-test-spring3/pom.xml#dubbo-test/dubbo-test-compatibility/pom.xml#dubbo-test/dubbo-test-examples/pom.xml#dubbo-test/dubbo-test-integration/pom.xml#dubbo-test/pom.xml#hessian-lite/pom.xml#pom.xml,5
[FLINK-11382][metrics] Disable MetricFetcher if interval is configured to 0,5
[FLINK-14924][connectorsi] Add treat empty field as null option to CsvTableSourceThis closes #10289,1
"[FLINK-8001] [kafka] Prevent PeriodicWatermarkEmitter from violating IDLE statusPrior to this commit, a bug exists such that if a Kafka consumer subtaskinitially marks itself as idle because it didn't have any partitions tosubscribe to, that idleness status will be violated when thePeriodicWatermarkEmitter is fired.The problem is that the PeriodicWatermarkEmitter incorrecty yields aLong.MAX_VALUE watermark even when there are no partitions to subscribeto. This commit fixes this by additionally ensuring that the aggregatedwatermark in the PeriodicWatermarkEmitterr is an effective one (i.e., isreally aggregated from some partition).",1
[FLINK-21272][checkpointing] Report incomplete metrics when aborted,2
"[QA] store messages in file instead of in the environmentBash can run out of environment memory if environment variables storetoo much data. When the memory is exceeded, bash can't run systemcommands anymore and, from then on, cryptically fails every command with""Argument list too long"".This closes #670.",0
调整单元测试包结构git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@172 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-14253][table-planner-blink] Add hash distribution and sort grouping only when dynamic partition insertThis closes #9796,1
[hotfix] [docs] Update file path of Gelly examples,2
[FLINK-28589][runtime-web] enable expanded rows of other concurrent attempts for subtasksThis closes #20380.,0
[hotfix][tests] Remove unused method CommonTestUtils#isProcessAlive(Process),3
"[FLINK-11154][network] Bump Netty to 4.1.32Notable changes since 4.1.24:- big improvements (performance, feature set) for using openSSL based  SSL engine (useful for FLINK-9816)- allow multiple shaded versions of the same netty artifact (as long  as the shaded prefix is different)- Ensure ByteToMessageDecoder.Cumulator implementations always release- Don't re-arm timerfd each epoll_wait- Use a non-volatile read for ensureAccessible() whenever possible to  reduce overhead and allow better inlining.- Do not fail on runtime when an older version of Log4J2 is on the  classpath- Fix leak and corruption bugs in CompositeByteBuf- Add support for TLSv1.3- Harden ref-counting concurrency semantics- bug fixes- Java 9-12 related fixes- no license changes- no changes in Netty's NOTICE file",2
[FLINK-4592] [table] Fix flaky test ScalarFunctionsTest.testCurrentTimePoint,3
KAFKA-14200: kafka-features.sh must exit with non-zero error code on error (#12586)kafka-features.sh must exit with a non-zero error code on error. We must do this in order to catchregressions like KAFKA-13990.Reviewers: David Arthur <mumrah@gmail.com>,0
[FLINK-27908] Extends onResultPartitionClosed to HsSpillingStrategy.,2
"KAFKA-8584: The RPC code generator should support ByteBuffer. (#7342)The RPC code generator should support using the ByteBuffer class in addition to byte arrays. By using the ByteBuffer class, we can avoid performing a copy in many situations. Also modify TestByteBufferDataTest to test the new feature.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
[tests] Add comments and to recovery tests,3
"KAFKA-3188: Compatibility test for old and new clients with 0.10 brokerapovzner becketqin please have a look if you can. Thanks.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Anna Povzner, Gwen ShapiraCloses #1059 from enothereska/kafka-3188-compatibility",1
[refactor][checkpoint] Change always true if block to checkState in SingleCheckpointBarrierHandler,0
[FLINK-22822][connector-jdbc] Clean up flink-connector-jdbc's pom.xmlThis closes #16039.,5
"[FLINK-3981] don't log duplicate TaskManager registrationsDuplicate TaskManager registrations shouldn't be logged with Exceptionsin the ResourceManager. Duplicate registrations can happen if theTaskManager sends out registration messages too fast when the actualreply is not lost but still in transit.The ResourceManager should simply acknowledge the duplicateregistrations, leaving it up to the JobManager to decide how to treatthe duplicate registrations (currently it will send an AlreadyRegisteredto the TaskManager).This closes #2045",2
[FLINK-17227][metrics][datadog] Remove relocations,4
KAFKA-1001; Handle follower transition in batch; patched by Guozhang Wang; reviewed by Jun Rao,0
"[FLINK-11772] [DataStream] Remove ""config"" from all serializer snapshot field / method names in InternalTimersSnapshotThis renaming corresponds to the fact that TypeSerializerConfigSnapshotis now deprecated, and is fully replaced by TypeSerializerSnapshot.",5
"KAFKA-3894; log cleaner can partially clean a segmentAs discussed in https://issues.apache.org/jira/browse/KAFKA-3894, this PR makes the log cleaner do a ""partial"" clean on a segment, whereby it builds a partial offset map up to a particular offset in a segment. Once cleaning resumes again, we will continue from the next dirty offset, which can now be located in the middle of a segment.Prior to this PR, segments with overly numerous keys could crash the log cleaner thread, as it was required that the log cleaner had to fit at least a single segment in the offset map.Author: Tom Crayford <tcrayford@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1725 from tcrayford/dont_crash_log_cleaner_thread_if_segment_overflows_buffer",4
HOTFIX: fix streams tutorial code example,0
"[FLINK-13767][task] Refactor StreamInputProcessor#processInput based on InputStatusStreamInputProcessor#processInput could return InputStatus instead of current boolean value to keep consistent withPushingAsyncDataInput#emitNext.For the implementation of StreamTwoInputProcessor#processInput, we could maintain and judge the two input status togetherwith the next selected input index to determine the final precise status. To do so we could avoid invalid processInput callexcept for the first call.In addition, AvailabilityProvider#isFinished has the duplicated semantic with InputStatus#END_OF_INPUT for PushingAsyncDataInput,and it is only meaningful for PullingAsyncDataInput now. So we migrate the #isFinished method from AvailabilityProvider toPullingAsyncDataInput.",5
"[FLINK-4246] Allow Specifying Multiple Metrics ReportersThis also updates documentation and tests.Reporters can now be specified like this:metrics.reporters: foo,barmetrics.reporter.foo.class: JMXReporter.classmetrics.reporter.foo.port: 10metrics.reporter.bar.class: GangliaReporter.classmetrics.reporter.bar.port: 11metrics.reporter.bar.something: 42",3
temporarily ignore UT RegistryDataConfigTest,5
"KAFKA-9645: Fallback to unsubscribe during Task Migrated (#8220)After #7312, we could still return data during the rebalance phase, which means it could be possible to find records without corresponding tasks. We have to fallback to the unsubscribe mode during task migrated as the assignment should be cleared out to keep sync with task manager state.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4144: Allow per stream/table timestamp extractorAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Damian Guy, Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2466 from jeyhunkarimov/KAFKA-4144",4
[FLINK-27470][state][tests] Migrate test to JUnit5,3
"KAFKA-5745; makeLeader should invoke `convertHWToLocalOffsetMetadata` before marking it as leaderAuthor: huxihx <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3682 from huxihx/KAFKA-5745",5
kafka-1375; Formatting for in README.md is broken; patched by Stevo Slavic; reviewed by Jun Rao,2
[FLINK-11786][travis] Setup notifications,1
KAFKA-1251: Add metrics to the producer.,1
"KAFKA-4774; Inner classes which don't need a reference to the outer c……lass should be staticAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2558 from cmccabe/KAFKA-4774",5
[hotfix][core] Do not set parallelism without checking whether the parallelism is set when translating Sink.,1
"MINOR: Fix flaky ControllerMutationQuotaTest.testQuotaMetric (#9417)`ClientQuotaManager.updateQuota` updates the in-memory quota before updating the configuration of the metric. Therefore, `quotaLimit` can return the updated value while the metric's configuration still returns the previous one. This patch updates the test to be resilient to this case.Reviewers: David Jacot <djacot@confluent.io>",5
修改group特殊符检查git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@983 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-21890][table-planner-blink] Rename DAGProcessor to ExecNodeGraphProcessorThis closes #15305,2
fixed issues in recovery,0
[streaming] minor fixes[streaming] minor example refactor,4
[FLINK-8465] [flip6] Retrieve correct leader component address in ClusterClientRename ClusterClient#getJobManagerAddress into #getClusterConnectionInfo. Thereturned LeaderConnectionInfo contains the address of the leading clustercomponent. In the old code this is the JobManager whereas in Flip-6 it is theDispatcher.This closes #5321.,1
Move the UnfinishedCoGroupOperation class into its own Scala file.The UnfinishedCoGroupOperation does not relate closely to CoGroupOperationvia sealed modifier so per Scala style guide [1] I propose to move it toseparate file.[1] http://docs.scala-lang.org/style/files.htmlThis closes #324.,2
"kafka-879; In system test, read the new leader from zookeeper instead of broker log on completion of become-leader state transition; patched by John Fung; reviewed by Jun Rao",2
[FLINK-21764][metrics][dropwizard] Remove flink-runtime dependency,2
"KAFKA-4461: Added support to ProcessorTopologyTestDriver for internal topicsThis resolves an issue in driving tests using the ProcessorTopologyTestDriver when `groupBy()` is invoked downstream of a processor that flags repartitioning.Ticket: https://issues.apache.org/jira/browse/KAFKA-4461Discussion: http://search-hadoop.com/m/Kafka/uyzND1wbKeY1Q8nH1dguy guozhangwangThe contribution is my original work and I license the work to the project under the project's open source license.Author: Adrian McCague <amccague@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2499 from amccague/KAFKA-4461_ProcessorTopologyTestDriver_map_groupbykey",3
[hotfix][core][config] Change default value of TaskManagerOptions#MEMORY_OFF_HEAP from false to true.,4
DUBBO-183 Multicast注册中心通过监控中心定时清理宕机提供者git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1461 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Fix chunked down-conversion behavior when no valid batch exists after conversion (#5173)We might decide to drop certain message batches during down-conversion because older clients might not be able to interpret them. One such example is control batches which are typically removed by the broker if down-conversion to V0 or V1 is required. This patch makes sure the chunked down-conversion implementation is able to handle such cases.,0
MINOR: Simplify SensorAccess usageI was investigating an exception in this code and found a fewopportunities for making it clearer.I also added the `out` folder to `.gitignore` as IntelliJ sometimesuses that as the build folder.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3552 from ijuma/minor-quota-improvements,1
[hotfix][runtime] Wrap arguments of ResourceManagerGateway#registerTaskExecutor into TaskExecutorRegistration.,0
[streaming] streamcomponent cleanup,4
Refactored record (de)serializer tests,3
Inefficient Usages of Java Collections (#8784)* Transform two LinkedHashMap objs to HashMap objs* Transform a LinkedHashMap obj to HashMap objThe map object is actually not used.* Transform a LinkedHashMap obj to HashMap obj* Transform a LinkedHashMap obj to HashMap obj* Transform a LinkedHashSet obj to HashSet obj* Transform a LinkedHashSet obj to HashSet obj* Transform a LinkedList obj to ArrayList obj* Transform an ArrayList obj to HashSet obj* Transform two ArrayList objs to LinkedList objs* Transform an ArrayList obj to LinkedList obj* Fix a compile error* Update FileSystemDynamicConfiguration.java* Update FileSystemDynamicConfiguration.java,5
KAFKA-10036: Improve handling and documentation of Suppliers (#9000)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
[docs] fix search form on subpages,0
Commented additional plugin repositories to speed up compile process,1
[FLINK-28519][network] Fix the bug that SortMergeResultPartitionReadScheduler may not read data sequentiallyThis closes #20320.,5
[streaming] streamcollector refactor,4
[FLINK-28644][datastream] Add DataStream#collectAsync,5
[FLINK-12720][python][docs] Add the Python Table API Sphinx docsThis closes #8774,2
[hotfix][build] Introduce property for common surefire arg line,5
[FLINK-25821][python][doc] Add the doc of execution mode in PyFlinkThis closes #18748.,2
[FLINK-20926][maxwell][json] Allow to read metadata for maxwell-json formatThis closes #16040,5
[FLINK-24603][e2e] Allow arbitrary jars to be added to the distributionRequired for adding a user-provided Scala library to lib.,1
[python][docs] Update the documentation of introduction of table api,2
Removed old files,2
[FLINK-15872][javadoc] Remove unnessary javadocs in InputFormat,2
[FLINK-14532][coordination] Split PartitionTracker,2
remove unused imports,2
[FLINK-5366] Add Initial version of SavepointUtilThis will serve as the basis for end-to-end tests of savepoint restorefrom Flink 1.1.,2
[streaming] Removed assembly execution on maven package for connectors,4
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1369 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-19590] Fix the compile issue of flink-streaming-java module,2
Guava shading issue fix for Eclipse,0
[FLINK-22678][state][changelog] Configurations and user APIs for ChangelogStateBackendThis fix #16153.,0
service discovery,5
"MINOR: Fix trace/debug logs in RequestChannelAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #192 from SinghAsDev/KAFKA-2461-2",2
"MINOR: add retry to system test curl commands (#8961)Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Boyang Chen <boyang@confluent.io>",5
[FLINK-22857][table-planner] Simplify DefaultSqlExprToRexConverterFactory to RexFactory,2
[FLINK-10260] Clean up log messages for TaskExecutor registrationsChange log level to debug for messages about TaskExecutor re-registeration inResourceManager and SlotManager in case of mupltiple attempts of the TaskExecutorto connect to the ResourceManagerThis closes #6720.,0
[FLINK-11073] [core] Let ListViewSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
"[FLINK-20736][table-planner-blink] Introduce BatchPhysicalLimit, and make BatchExecLimit only extended from ExecNodeThis closes #14472",1
[FLINK-12896][rest] Use JobID parameter for archiving,2
[FLINK-22673][docs] Add docs for JAR related commands and remove the usage of the YAML fileThis closes #16779,2
"[FLINK-1994] [ml] Add different learning rate calculation schemes to SGDAdded SGD gain calculation schemesfixed optimal SGD calculation schemeFLINK-1994: Added 4 new effective learning rates[FLINK-1994] [ml] Add different gain calculation schemes to SGDfixed long lines in GradientDescent.scala[FLINK-1994][ml]Add different gain calculation schemes to SGD[FLINK-1994][ml] Add different gain calculation schemes to SGD[FLINK-1994][ml] Add different gain calculation schemes to SGDAdded SGD gain calculation schemesfixed optimal SGD calculation scheme[FLINK-1994] [ml] Add different gain calculation schemes to SGDFLINK-1994: Added 3 new effective learning ratesAdded SGD gain calculation schemesfixed optimal SGD calculation scheme[FLINK-1994] [ml] Add different gain calculation schemes to SGDfixed long lines in GradientDescent.scala[FLINK-1994][ml] Add different gain calculation schemes to SGD[Flink-1994][ml] Add different gain calculation schemes to SGD[FLINK-1994][ml] Updated docs, refactored optimizationMethod from Int to String[FLINK-1994][ml] Added test and example to docs[FLINK-1994][ml] Fixed Int Artifacts in LinearRegression.scalaAdded LearningRateMethod to IterativeSolverThe learning rate method defines how the effective learning step is calculated foreach iteration step of the IterativeSolver.Fixed docs, merged enumeration from Till, fixed typo in Wus method[FLINK-1994][ml] Added 4 new effective learning rate methods[FLINK-1994][ml] Add different gain calulation schemes to SGDThis closes #1397.",1
"MINOR: capture result timestamps in Kafka Streams DSL tests (#6447)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[hotfix] Remove old sysout debug message in UdfAnalyzerTest,3
"[hotfix] Move SimpleSlotContext to test scope.This class is for the legacy code, and there's no usage of this class in production codes.",3
[FLINK-13368][python] Add Configuration Class for Python Table API to Align with Java.This closes #9199,5
[hotfix] [tests] Speed up streaming state tests by skipping default retry delay.,1
[FLINK-10291] Generate JobGraph with fixed/configurable JobID in StandaloneJobClusterEntrypointThis closes #6733.,1
"KAFKA-6473: Add MockProcessorContext to public test-utils (#4736)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-9018: Throw clearer exceptions on serialisation errors (#7496)Improved the exception messages that are thrown to indicate whether it was a key or value conversion problem.Author: Mario Molina <mmolimar@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,0
[FLINK-15688][streaming] Define DataStream API for MultipleInputStreamOperatorThis interface is still not complete - it's missing for example watermark andlatency markers support.,1
[FLINK-14813][metrics] Provide `isBackPressured` Task metric (#10359),1
Update readme links.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156166 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Correct KafkaProducer Javadoc spelling of property 'max.in.flight.requests.per.connection'Currently, in branches _trunk_, _0.11.0_, and _1.0_ the property **max.in.flight.requests.per.connection** is incorrectly misspelled as _max.inflight.requests.per.connection_harshach ijuma guozhangwang can you please review. Thank you.Author: Hugo Louro <hmclouro@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4094 from hmcl/trunk_MINOR_Doc_InflightProp",5
add more detail log,2
[hotfix][docs] Move note about partial checkstyle enforcement,1
[FLINK-7807] [REST] Log exceptions in HandlerUtils methodsThis closes #7807.,0
"KAFKA-7476: Fix Date-based types in SchemaProjectorVarious converters (AvroConverter and JsonConverter) produce aSchemaAndValue consisting of a logical schema type and a java.util.Date.This is a fix for SchemaProjector to properly handle the Date.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5736 from rayokota/KAFKA-7476",5
"KAFKA-8927: Deprecate PartitionGrouper interface (#7376)Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-935: Fix shutdown tool to work with new controlled shutdown API; reviewed by Neha Narkhede,1
"[FLINK-14505][e2e, table] Update expected results after format change introduced in FLINK-11935",2
[FLINK-6245] Fix late side output documentation in Window documents.,2
"[FLINK-2268] Don't include Hadoop deps in flink-core/flink-javaThis also makes them optional in flink-runtime, which is enabled by theprevious changes to only use Hadoop dependencies if they are available.This also requires adding a few explicit dependencies in other modulesbecause they were using transitive dependencies of the Hadoop deps. Themost common dependency there is, ha!, commons-io.",1
[hotfix][table-planner] Migrate PushProjectIntoTableSourceScanRuleTest to test harness,3
[FLINK-2136] [streaming] Added parallelism tests to DataStream,5
[FLINK-16346][runtime][tests] Use BlockingNoOpInvokable,1
Change Readme dubbo-sample hyperlink (#2927),2
KAFKA-5768; Upgrade to ducktape 0.7.1Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3721 from cmccabe/KAFKA-5768,5
[FLINK-14522] Revert FLINK-13985 (sun.misc.Cleaner is not available in Java 9+),4
DUBBO-285 当服务接口中有方法重载时，telnet 无法正确调用所有方法git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1294 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[tests] Various stability fixes to tests,3
[hotfix][checkpoint] Extract CheckpointPlan to be an interface,4
Removed automatic spilling in SpillingQueue,4
[FLINK-25461][python] Update net.sf.py4j:py4j dependency to 0.10.8.1This closes #18209.,5
[hotfix] [tests] Fix minor test instability in ConnectionUtilsTest,3
HOTFIX: removed extra footnote (#6996)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"[FLINK-23528][connectors/kinesis] Use proper mock of ExecutorService in KinesisDataFetcherTest.Mockito makes it so much harder to debug tests. Here, we replace Mockito with a small test class that emulates the previously dispersed functionality in a simpler way.",1
[FLINK-1924] minor refactoring of the Python API- code formatting- simpler python process initialization- renaming of the python connection following the switch to TCPThis closes #616.,5
"[FLINK-22574] Adaptive Scheduler: Fix cancellation while in Restarting state.The Canceling state of Adaptive Scheduler was expecting the ExecutionGraph to be in state RUNNING when entering the state.However, the Restarting state is cancelling the ExecutionGraph already, thus the ExectionGraph can be in state CANCELING or CANCELED when entering the Canceling state.Calling the ExecutionGraph.cancel() method in the Canceling state while being in ExecutionGraph.state = CANCELED || CANCELLED is not a problem.The change is guarded by a new ITCase, as this issue affects the interplay between different AS states.This closes #15882",0
Fix various JavaDoc errors,0
MINOR: small code optimizations in streamsguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1176 from ymatsuda/optimize,5
KAFKA-4403; Update KafkaBasedLog to use new endOffsets consumer APIewencp plz reviewAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2176 from baluchicken/KAFKA-4403,5
[FLINK-23196][tests] use MiniClusterResource,5
[FLINK-1696] [ml] Adds web documentation for multiple linear regression. Changes website links from relative to absolute.,2
"KAFKA-9524: increase retention time for window and grace periods longer than one day (#10091)Reviewers: Victoria Xia <victoria.xia@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"[FLINK-441] [optimizer] Rename ""o.a.flink.compiler"" to ""o.a.flink.optimizer""",2
[FLINK-17030][table-planner-blink] Add primary key syntax for ALTER TABLEThis closes #11950,1
[3.0] Upgrade nacos version (#10024)* upgrade nacos version* fix build errorCo-authored-by: 呈铭 <beck.wcm@antgroup.com>,0
Point quickstart scripts to 0.6.1-incubating,5
Simplify dubbo-common transitive dependencies (#5107),5
[FLINK-2590] fixing DataSetUtils.zipWithUniqueId() and DataSetUtils.zipWithIndex()* modified algorithm as explained in the issue* updated method documentation[FLINK-2590] reducing required bit shift size* maximum bit size is changed to getNumberOfParallelSubTasks() - 1This closes #1075.,1
"[FLINK-15076][task] Fix SourceStreamTask cancellationSource thread should be interrupted more or less the same way how task thread isbeing interrupted. This is important for example as in the scenario presented in theSourceStreamTaskTest#testCancellationWithSourceBlockedOnLock(). SourceFunction isblocked while holding checkpointLock, which might prevent task thread fromcancelling properly if the SourceFunction is not interrupted.",1
[FLINK-17942][table-planner-blink] Fix WindowOperator not call StateMapView.cleanup when destroying windowsThis closes #12358,4
[FLINK-20184][doc] update hive streaming read and temporal table documentThis closes #14182,2
[FLINK-27768][sql-gateway] Allow executing sql for the SqlGatewayService (#19846),1
[FLINK-12903][py] Remove old Python APIs,4
Merge pull request #16 from mhuelfen/masterFixed #16 Hiding extra Iteration Elements in Pact Plan Visualization,0
[FLINK-13824][travis] Refactoring travis_watchdog.sh: remove code duplication,4
HOTFIX: Avoid ambiguity error of Properties#putAll in Java 11 and scala 2.12 (#8599)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
add unit test,3
Fixes race condition in ExecutionGraph which allowed a job to go into the finished state without all job vertices having properly processed the finalizeOnMaster method.,5
KAFKA-3529: Fix transient failure in testCommitAsyncAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1234 from hachikuji/KAFKA-3529,5
[FLINK-7321] [futures] Replace Flink's futures with Java 8's CompletableFuture in HeartbeatManagerAddress PR commentsThis closes #4434.,1
[hotfix][python] Aligns with Java Table API by removing methods exec_env and query_configThis closes #8910,5
"[FLINK-13637][docs] Fix problems of anchors in document(building.md, common.md, queryable_state.md)This closes #9384",2
[FLINK-28855][hive] Fix 'Table.INDEX_TABLE' not found in the Hive3 (#20514),0
[FLINK-22356][hive][filesystem] Fix partition-time commit failure when watermark is applied defined TIMESTAMP_LTZ columnThis closes #15709,0
[FLINK-13269][table] Copy RelDecorrelator & FlinkFilterJoinRule to flink planner to fix CALCITE-3169 & CALCITE-3170This closes #9122,0
[FLINK-19717][connectors/common] Fix spurious InputStatus.END_OF_INPUT from SourceReaderBase.pollNext caused by split reader exception (#13776),1
Simply TagRouter (#2924),5
[FLINK-21974][table] Support to match quoted values for SET option statementThis closes #15372,1
Maven POM file cleanups.Added missing primitive type wrappers.Adjusted API for ozone-scala.,4
[FLINK-8331][core] FieldParser do not correctly set EMPT_COLUMN error state.This closes #5218,0
implemented reusage of target node in ArrayMerger; added some testcases for ArrayMerger; restructured target reusage in ArrayCreation,1
修改测试用例 git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1132 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix] Add Scala binary version suffix to flink-sql-client dependency in flink-dist/pom.xml,5
rename module name from governance to configcenter,5
"[hotfix] Fix AbstractKeyedCEPPatternOperator.restoreState()Before, this was trying to cast the StreamTaskState directly to aStateHandle<DataInputView> while it should take the operator state, i.e:StateHandle<DataInputView> stateHandle =  (StateHandle<DataInputView>) state.getOperatorState();",1
implement pull request #3412 on master branch (#3418),5
"KAFKA-12749: Changelog topic config on suppressed KTable lost (#10664)Refactored logConfig to be passed appropriately when using shutDownWhenFull or emitEarlyWhenFull. Removed the constructor that doesn't accept a logConfig parameter so you're forced to specify it explicitly, whether it's empty/unspecified or not.Co-authored-by: Bruno Cadonna <cadonna@apache.org>Reviewers: Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@apache.org>",1
DUBBO-44 修改订阅时与1.0 url无path时的兼容。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@222 1a56cb94-b969-4eaa-88fa-be21384802f2,1
DUBBO-533 统一使用threads参数,5
[FLINK-13495][table-planner-blink] Introduce isAssignable to use soft check in TableSourceUtil,1
[FLINK-20314][table-planner] Add rule to remove empty FlinkLogicalCalc,2
Made timeout configurable per stub.,5
Fix UT failure.,0
"[quickstarts] Remove redundant old fat jar assembly file.Adjusts the comments inside the POM file to encourage use ov ""mvn clean package"",rather than ""mvn clean install"".",4
Checkpoints are now written asynchronously,5
"MINOR: Fix typo in ReplicaVerificationTool outputAuthor: Andrew Otto <acotto@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #101 from ottomata/trunk and squashes the following commits:10b76f3 [Andrew Otto] MINOR - Fix typo in ReplicaVerificationTool output",2
[hotfix] Fix checkstyle violations in ExecutionVertex,0
"Added tests for JAQL operators filter, group, transform, and join",1
[FLINK-5748] [jobmanager] Make the 'future executor' a ScheduledExecutorServiceThis closes #3289,1
marked all expressions which dont reuse the target node during evaluation with   TODO Reuse target,1
Fix: Wrong output of shipping strategy in JSONGenerator,5
"KAFKA-3607: Close KStreamTestDriver upon completing; follow-up fixes to be tracked in KAFKA-3623Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Michael G. Noll, Ismael JumaCloses #1258 from guozhangwang/K3607",0
[FLINK-16501][table] Support IS JSON predicate in Table APIThis closes #16805.,5
增加README说明git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@706 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-3037: Test number of alive brokers known after single node cluster startup…ter startupAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #875 from granthenke/self-aware,5
Fixed problems with cache invalidation in the recovery logic,2
KAFKA-10044 Deprecate ConsumerConfig#addDeserializerToConfig and Prod… (#9013)deprecate ConsumerConfig#addDeserializerToConfig and ProducerConfig#addSerializerToConfig.Create internal use cases instead: appendDeserializerToConfig and appendSerializerToConfigReviewers: Boyang Chen <boyang@confluent.io>,5
"[FLINK-15790][k8s] Make some interfaces in FlinkKubeClient asynchronous which potentially blocks the execution of RpcEndpoint's main threadThe interfaces in FlinkKubeClient will be called both in Client and ResourceManager. To avoid potentially blocking the execution of RpcEndpoint's main thread, these interfaces #createTaskManagerPod, #stopPod should be implemented asynchronously.This closes #11427.",1
Merge branch 'mem-manager'Conflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/sort/TestBufferSortable.java,5
[FLINK-15862][kafka] Remove deprecated KafkaPartitioner,4
[FLINK-14998][fs] Remove FileUtils#deletePathIfEmptythis closes #19330.,4
polishing iterative mapreduce,1
MINOR: ChangelogReader should poll for duration 0 for standby restore (#8773)Co-authored-by: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
[hotfix][metrics] Remove legacy/unused code,1
Introduced ConstantFieldsExcept annotation,5
[FLINK-29184][sql-gateway] Close resource manager when closing Session,2
"KAFKA-8768: DeleteRecords request/response automated protocol (#7957)Also add version 2 to make use of flexible versions, per KIP-482.Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
[hotfix][runtime] Code clean-up in ResourceProfile.,2
[FLINK-11360] [test] Check and remove LocalFlinkMiniClusterITCaseThis closes #7516.,5
DUBBO-105 fix ReflectUtils 缓存失效。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@470 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-27459][tests] Reset context environment,1
"[Dubbo-3226] guarantee interoperability with 2.6.x and lower versions (#3229)* guarantee interoperability with 2.6.x and lower versions* fix unit test, also adjust comments to fit with the code style* change condition in isFramework270OrHigher() to 'version >= 2.7.0.0'",1
[hotfix] Add logging statement when the ExecutionGraph creation failed in the WaitingForResources state,0
[FLINK-2924] [streaming] Out-of-core state backend for JDBC databases,5
[FLINK-10934][e2e] Add e2e tests for Kubernetes application mode,3
[minor] Rework Javadoc in Sink interface,2
"[FLINK-8890] Compare checkpoints with order in CompletedCheckpoint.checkpointsMatch()This method is used, among other things, to check if a list of restoredcheckpoints is stable after several restore attempts in the ZooKeepercheckpoint store. The order of checkpoints is somewhat important becausewe want the latest checkpoint to stay the latest checkpoint.",3
[FLINK-9688] [table] Add ATAN2 SQL function supportThis closes #6223.,1
"[hotfix][runtime, tests] Remove ComponentMainThreadExecutor interface from ManuallyTriggeredScheduledExecutor",4
"KAFKA-6474: remove KStreamTestDriver (#6732)The implementation of KIP-258 broke the state store methods in KStreamTestDriver.These methods were unused in this project, so the breakage was not detected.Since this is an internal testing utility, and it was deprecated and partially removed infavor of TopologyTestDriver, I opted to just complete the removal of the class.Reviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Avoid logging connector configuration in Connect framework (#5868)Some connector configs may be sensitive, so we should avoid logging them.Reviewers: Alex Diachenko, Dustin Cote <dustin@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[FLINK-4658] [rpc] Allow RpcService to execute Runnables and Callables in its executorThis closes #2531.,1
Created Debian Package for Ozone install(Pull request by Christian Richter),1
[FLINK-26159][doc] add description for MAX_FETCH_RECORD related questionUpdate docs/content/docs/connectors/datastream/pulsar.mdCo-authored-by: MartijnVisser <martijn@2symbols.com>Update docs/content/docs/connectors/datastream/pulsar.mdCo-authored-by: MartijnVisser <martijn@2symbols.com>add Chinese documentation,2
"MINOR: allocate 2MB to offset map in connect EmbeddedKafkaCluster (#11619)EmbeddedKafkaCluster in other projects use 2MB for their offset map to reducememory consumption in test runs. Generally we allocate multiple of these offset maps,one for each broker.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Support KRaft in ReplicaFetchTest (#12345)Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix][tests] Remove Tasks#Sender and #Receiver,4
[FLINK-12001][tests] fix the external jar path config error for AvroExternalJarProgramITCase.This closes #8047,0
[FLINK-6655] Add validateAndNormalizeUri method to MemoryArchivistThis closes #4156.,5
[FLINK-1201] [gelly] added create methods from set of edges,1
"Changed for updatedTasks, avoids stopping and starting of unnecessary tasks (#7097)Corrected the `KafkaConfigBackingStore` logic to notify of only the changed tasks, rather than all tasks. This was not noticed before because Connect always stopped and restarted all tasks during a rebalanced, but since 2.3 the incremental rebalance logic exposed this bug.Author: Luying Liu <lyliu@lyliu-mac.freewheelmedia.net>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
[FLINK-26495][table-planner] Prohibit hints(dynamic table options) on viewThis closes #19007,2
"MINOR: Fix small typo in main README (#7779)Fixed a small typo in the main README file (""They are also are printed"" --> ""They are also printed"").Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2
MINOR: Fix broken standalone ReplicationQuotasTestRig test (#5773)* Fix `ZkUtils.getReassignmentJson` to pass Java map to `Json.encodeAsString`* Allow new file creation in ReplicationQuotasTestRig testReviewers: Ismael Juma <ismael@juma.me.uk>,3
Refactored expressions and functions,1
"prepare for next release, change version to 2.7.7-SNAPSHOT",4
Rename SPI config file of governance module,2
Minor fix to improve robustness of byte-buffered channel manager,1
[hotfix][tests] Fix compile error,0
[FLINK-4273] adapt JobRetrievalITCase to lazy classloader reconstruction,2
[hotfix][network] Maintain MemorySegmentProvider from InputChannel to SingleInputGate,1
[docs] clarify default restart behavior when checkpointing is enabled,0
"KAFKA-7801: TopicCommand should not be able to alter transaction topic partition countTo keep align with the way it handles the offset topic, TopicCommand should not be able to alter transaction topic partition count.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6109 from huxihx/KAFKA-7801",1
"KAFKA-3514: Remove min timestamp tracker (#5382)1. Remove MinTimestampTracker and its TimestampTracker interface.2. In RecordQueue, keep track of the head record (deserialized) while put the rest raw bytes records in the fifo queue, the head record as well as the partition timestamp will be updated accordingly.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"[KAFKA-8522] Streamline tombstone and transaction marker removal (#10914)This PR aims to remove tombstones that persist indefinitely due to low throughput. Previously, deleteHorizon was calculated from the segment's last modified time.In this PR, the deleteHorizon will now be tracked in the baseTimestamp of RecordBatches. After the first cleaning pass that finds a record batch with tombstones, the record batch is recopied with deleteHorizon flag and a new baseTimestamp that is the deleteHorizonMs. The records in the batch are rebuilt with relative timestamps based on the deleteHorizonMs that is recorded. Later cleaning passes will be able to remove tombstones more accurately on their deleteHorizon due to the individual time tracking on record batches.KIP 534: https://cwiki.apache.org/confluence/display/KAFKA/KIP-534%3A+Retain+tombstones+and+transaction+markers+for+approximately+delete.retention.ms+millisecondsCo-authored-by: Ted Yu <yuzhihong@gmail.com>Co-authored-by: Richard Yu <yohan.richard.yu@gmail.com>",5
"[FLINK-20783][table-planner-blink] Introduce BatchPhysicalNestedLoopJoin, and make BatchExecNestedLoopJoin only extended from ExecNodeThis closes #14516",1
[docs] Fix broken images in quickstarts,0
MINOR: Fix replica_verification_tool.py to handle slight change in output formatThe string representation of TopicPartition was changed to be{topic}-{partitition} consistently in the following commit:f6f56a645bb1c5ec6810c024ba517e43bf77056cAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3890 from ijuma/fix-replica-verification-test,3
"KAFKA-12648: avoid modifying state until NamedTopology has passed validation (#11750)Previously we were only verifying the new query could be added after we had already inserted it into the TopologyMetadata, so we need to move the validation upfront.Also adds a test case for this and improves handling of NPE in case of future or undiscovered bugs.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-12738: address minor followup and consolidate integration tests of PR #11787 (#11812)This PR addresses the remaining nits from the final review of #11787It also deletes two integration test classes which had only one test in them, and moves the tests to another test class file to save on the time to bring up an entire embedded kafka cluster just for a single runReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
Fixed incorrectly passes key positions.,4
Merge branch '2.7.0-release'# Conflicts:#dubbo-cluster/src/main/java/org/apache/dubbo/rpc/cluster/router/AbstractRouter.java#dubbo-cluster/src/test/java/org/apache/dubbo/rpc/cluster/router/ConfigConditionRouterTest.java#dubbo-cluster/src/test/java/org/apache/dubbo/rpc/cluster/router/TagRouterTest.java#dubbo-common/src/main/java/org/apache/dubbo/common/Constants.java#dubbo-common/src/test/java/org/apache/dubbo/common/URLTest.java#dubbo-compatible/src/test/java/org/apache/dubbo/config/ConfigTest.java#dubbo-compatible/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-compatible/src/test/java/org/apache/dubbo/rpc/cluster/RouterTest.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractServiceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/AbstractInterfaceConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ServiceConfigTest.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/cache/CacheTest.java#dubbo-config/dubbo-config-spring/pom.xml#dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/AnnotationBean.java#dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/ConfigCenterBean.java#dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/ServiceBean.java#dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/beans/factory/annotation/ReferenceAnnotationBeanPostProcessor.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/ConfigTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/ServiceBeanTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/beans/factory/annotation/AnnotationPropertyValuesAdapterTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/beans/factory/annotation/DubboConfigBindingBeanPostProcessorTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/beans/factory/annotation/ReferenceAnnotationBeanPostProcessorTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/beans/factory/annotation/ServiceAnnotationBeanPostProcessorTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/annotation/DubboComponentScanRegistrarTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/annotation/DubboConfigBindingRegistrarTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/annotation/DubboConfigBindingsRegistrarTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/annotation/DubboConfigConfigurationTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/annotation/EnableDubboConfigTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/annotation/EnableDubboTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/context/annotation/provider/HelloServiceImpl.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/context/properties/DefaultDubboConfigBinderTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/extension/SpringExtensionFactoryTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/schema/DubboNamespaceHandlerTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/status/DataSourceStatusCheckerTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/status/SpringStatusCheckerTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/util/PropertySourcesUtilsTest.java#dubbo-metadata-report/dubbo-metadata-report-zookeeper/src/test/java/org/apache/dubbo/metadata/store/zookeeper/ZookeeperMetadataReportTest.java#dubbo-remoting/dubbo-remoting-zookeeper/src/test/java/org/apache/dubbo/remoting/zookeeper/curator/CuratorZookeeperTransporterTest.java#dubbo-rpc/dubbo-rpc-api/src/test/java/org/apache/dubbo/rpc/RpcContextTest.java#dubbo-rpc/dubbo-rpc-dubbo/src/test/java/org/apache/dubbo/rpc/validation/ValidationTest.java#dubbo-rpc/dubbo-rpc-hessian/pom.xml#dubbo-rpc/dubbo-rpc-http/src/main/java/org/apache/dubbo/rpc/protocol/http/HttpProtocol.java,5
MINOR: Fix typo in SMT doc: s/RegexpRouter/RegexRouterAuthor: Robin Moffatt <robin@rmoff.net>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3576 from rmoff/patch-1,5
[FLINK-17547][task][hotfix] Improve error handling1 catch one more invalid input in DataOutputSerializer.write2 more informative error messages,0
[streaming] Renamed test cases for window and grouped window invokable to be consistent with the invokable names,3
[FLINK-4737] [core] Add support for bz2 and xy compression in flink-core.Adds a dependency on 'commons-compression'.This closes #2002,2
Optimize code: remove unnecessary judgment code. (#3196),4
[hotfix][table-api] Expose NOT for Table API,0
[hotfix][table-common] Add missing TIME type familyThis closes #8913.,1
[FLINK-27159][table] Support firstValue/lastValue in the Table APIThis closes #19958.,1
[FLINK-1677][gelly] Suppresed Sysout Printing for the Degrees with exception test suiteThis closes #475,3
[FLINK-13455][build] Move jdk.tools exclusions out of dependency management,4
fix GenericServiceTest failing on Travis (#5177),0
Fixed zombie tasks in test plans when exceptions are thrown,3
补充修改：cluster中对destroy的判断也不够严格 DUBBO-2git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@93 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-18537][table] Remove ExecutionConfig for internal serializers,5
[FLINK-28307][doc] Update history server docs w.r.t. FLIP-241.This closes #20297,2
[FLINK-28664][python] Support FileSink using Avro GenericRecord bulk writerThis closes #20383.,1
[FLINK-1381] Allow multiple output splitters for single stream operatorCloses #332Conflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/StreamConfig.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/StreamGraph.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/collector/DirectedStreamCollector.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/SingleOutputStreamOperator.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/SplitDataStream.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/streamvertex/OutputHandler.java,5
Added fix in pact compiler to fall back to a default parallelism when nothing else is specified.,0
[dist] Link plan visualizer to project website,2
[hotfix][docs] Move out the time zone page from streaming concepts sectionThis closes #17377,4
[tests] Speed up DataSinkTaskTest,5
[FLINK-8249] [kinesis] Fix setting region on KinesisProducerConfigurationThis closes #5160.,5
[FLINK-5076] Shutting down TM when shutting down mini cluster.This closes #2817.,5
[FLINK-17467][task][hotfix] Remove cast in CheckpointedInputGate,4
Adjusted dist pom.xml,5
MINOR: Bump js template to 2.2 (#6086)Bump js template to 2.2; update gradle.propertiesReviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-7184] Activate checkstyle flink-java/hadoopThis closes #4341.,2
KAFKA-10562: Properly invoke new StateStoreContext init (#9388)* all wrapping stores should pass StateStoreContext init through to the same  method on the wrapped store and not translate it to ProcessorContext init* base-level stores should handle StateStoreContext init so that callers passing  a non-InternalProcessorContext implementation will be able to initialize the store* extra tests are added to verify the desired behaviorReviewers: Guozhang Wang <guozhang@apache.org>,1
[FLINK-17593][Connectors/FileSystem] Turn BucketStateSerializerTest into an upgrade test,3
[FLINK-13078][table-common] Add a logical type parserThis adds a parser for all logical types defined in FLIP-37.This closes #9061.,2
修改pomgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@778 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-8134][REST][docs] Add MessageHeaders#getDescription()This closes #5967.,1
"Merge pull request #1331, add optional parameter to support hessian protocol method overload and request protocol version.",1
[streaming] Package and Java Dependency rename,5
[FLINK-7416][network] Implement Netty receiver outgoing pipeline for credit-based,2
"[hotfix] In flink-end-to-end-tests-common-kafka, execute dependency plugin in different phaseWe do this to fix this error message:[ERROR] Failed to execute goalorg.apache.maven.plugins:maven-dependency-plugin:3.1.1:copy (copy) onproject flink-end-to-end-tests-common-kafka: Artifact has not beenpackaged yet. When used on reactor artifact, copy should be executedafter packaging: see MDEP-187. -> [Help 1]",1
"KAFKA-12612: Remove `checksum` from ConsumerRecord/RecordMetadata for 3.0 (#10470)The methods have been deprecated since 0.11 without replacement sincemessage format 2 moved the checksum to the record batch (instead of therecord).Unfortunately, we did not deprecate the constructors that take a checksum(even though we intended to) so we cannot remove them. I have deprecatedthem for removal in 4.0 and added a single non deprecated constructor to`ConsumerRecord` and `RecordMetadata` that take all remaining parameters.`ConsumerRecord` could do with one additional convenience constructor, butthat requires a KIP and hence should be done separately.Also:* Removed `ChecksumMessageFormatter`, which is technically not publicAPI, but may have been used with the console consumer.* Updated all usages of `ConsumerRecord`/`RecordMetadata` constructorsto use the non deprecated ones.* Added tests for deprecated `ConsumerRecord/`RecordMetadata`constructors.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-13748: Do not include file stream connectors in Connect's CLASSPATH and plugin.path by default (#11908)With this change we stop including the non-production grade connectors that are meant to be used for demos and quick starts by default in the CLASSPATH and plugin.path of Connect deployments. The package of these connector will still be shipped with the Apache Kafka distribution and will be available for explicit inclusion. The changes have been tested through the system tests and the existing unit and integration tests. Reviewers: Mickael Maison <mickael.maison@gmail.com>, Randall Hauch <rhauch@gmail.com>",3
[FLINK-22814][metrics] Calculate checkpointStartDelay for FLIP-27 sources,2
Defensive check to solve issue #3923 (#3931),0
KAFKA-5250: Do fetch down conversion after throttlingPerform down conversion after throttling to avoid retainingmessages in memory during throttling since this could resultin OOM. Also update bytesOut metrics after throttling.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3068 from rajinisivaram/KAFKA-5250,5
[FLINK-12317][runtime] Ensure maximum size is larger than core size,2
[FLINK-19801][checkpoint] Recover data with virtual channels.This commit adds virtual channel support to SequentialChannelStateReader. The reader now replicates data on input and output side according to the InflightDataRescalingDescriptor and adds VirtualChannelSelector events before buffers.,1
DUBBO-970 修改dynamic=falsegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1494 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-20328][tests] Fixed buffer calculation in UnalignedCheckpointITCase.Ultimately, it was one buffer missing.",0
[FLINK-11356][tests] Port JobManagerStartupTest to new code base- Moved JobManagerStartupTest#testStartupWithPortInUse toBootstrapToolsTest#testActorSystemInstantiationFailureWhenPortOccupied- Moved JobManagerStartupTest#testJobManagerStartupFails toBlobServerTest#testFailureIfStorageDirectoryCannotBeCreatedThis closes #7541.,3
修改异常信息单词错误git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@838 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][test] Refactor TestingContender and TestingListener to abstract some common methods,3
"[FLINK-4821] [kinesis] General improvements to rescalable FlinkKinesisConsumerThis commit adds some general improvements to the rescalableimplementation of FlinkKinesisConsumer, including:- Refactor setup procedures in KinesisDataFetcher so that duplicate work  isn't done on a restored run- Strengthen corner cases where fetcher was not fully seeded with  initial state when snapshot is takenThis closes #3001.",5
"[FLINK-18071][coordination] (part 2) OperatorCoordinatorHolder does not implement OperatorCoordinator interface any moreOriginally it was designed that the OperatorCoordinatorHolder has the same interface as the OperatorCoordinator and simplyadds some hooks around the checkpoint triggering procedure.However, the OperatorCoordinatorHolder is becoming the glue between the scheduler threads and the scheduler's view ontasks and their status, and the OperatorCoordinator threads and their simplified view on the execution state. Thismeans they do require different interfaces.",1
Fixed Test for DataSinkTask.,5
Update CHANGES.md (#2978),4
"[FLINK-6803] [tests] Enhancements to PojoSerializerUpgradeTest1. Allow tests to ignore missing fields.2. Add equivalent tests which use POJOs as managed operator state.For 2, all tests have to be ignored for now until FLINK-6804 is fixed.",0
Reduced logging and fixed possible NullPointerException in FileBufferManager,2
"MINOR. implement --expose-ports option in ducker-ak (#7269)This change adds a command line option to the `ducker-ak up' command to enable exposing ports from docker containers. The exposed ports will be mapped to the ephemeral ports on the host. The option is called `expose-ports' and can take either a single value (like 5005) or a range (like 5005-5009). This port will then exposed from each docker container that ducker-ak sets up.Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
DUBBO-627 添加单元测试，覆盖 export 时是否能把 generic 的配置发布到 registry 上,1
[FLINK-3265][tests] adapt RMQSource checkpointing test to runtime behaviorThe methods snapshotState and notifyCheckpointComplete are alwaysmutually exclusive. The RMQSource relies on this but the test makes afalse assumption when it calls those two methods at the same time.This closes #1569.,1
[FLINK-3028] [runtime-web] Show cancel button for restarting jobsThis closes #1369,1
[FLINK-19939][table-planner-blink] Remove redundant union from multiple input node,4
[hotfix][flink-core] fix typo in error message,0
Introduced extended job status modell to deal with task failures,0
add system ignore,5
[streaming] Serializable no longer needed for examplesDue to the recent serialization changes.,4
[FLINK-13941][fs-connector] Do not delete partial part files from S3 upon restore.,2
"KAFKA-4457; Add BrokerApiVersionsCommandAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2184 from cmccabe/KAFKA-4457",5
[FLINK-1201] [gelly] cleared VertexKeyWith one class definintion,5
"KAFKA-7460: Fix Connect Values converter date format patternSwitches to normal year format instead of week date years and day of month instead of day of year.This is directly from #4820, but separated into a different JIRA/PR to keep the fixes independent. Original authorship should be maintained in the commit.Author: Amit Sela <amitsela33@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5718 from ewencp/fix-header-converter-date-format",5
[hotfix] Add whitespace to log statement in SourceCoordinatorProvider,1
"MINOR: Warning instead of error if TGT cannot be renewed beyond the next expiry dateAuthor: Sriharsha Chintalapani <harsha@hortonworks.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1510 from harshach/KerberosLogin-Log",2
[FLINK-18726][table-planner-blink] Support INSERT INTO specific columns in blink planner (#14977),2
"[FLINK-16641][network] (Part#3) Support to announce the upstream backlog to the downstream tasksThis batch introduce the ability of announcing upstream backlog to the downstream tasks through the BacklogAnnouncement message when the exclusive credit is 0. This gives the upstream tasks the ability to actively allocate credits from the downstream tasks, which is needed by FLINK-16641.",2
"[FLINK-14974][runtime] Calculate managed memory fractions with BigDecimalThis is necessary otherwise fractions can be summed up to be more than 1.0 due to the double precision issue, and the last operator may fail to allocate managed memory it is supposed to be able to acquire. The fraction scale is 16 which is large enough to make little managed memory unusable.",1
"[FLINK-11334] Create proper restore serializer in ScalaEnumSerializerSnapshotBefore, this was trying to create an Enumeration and cast it to aTypeSerializer. Creating the enumeration would fail because it is aScala Object, i.e. a singleton. The cast would also fail.This now uses inspection to create an instance of the Enumeration andthen uses that to create an EnumValueSerializer.",1
[FLINK-11884][table] Ported calculated table validation on top of Expressions,5
use interface name as path (#6212)* use interface name as path (#6212),1
[FLINK-23453][core] Renaming configuration automatic-buffer-adjustment -> buffer-debloat,5
"[FLINK-9099] Assign Execution to LogicalSlot when slot is assigned to ExecutionIn order to fail fast if an allocated slot is released by the SlotPool, we assign theExecution as payload to a LogicalSlot when the slot is assigned to the Execution.This closes #5775.",2
[FLINK-20114][connector/kafka] Add IT cases for KafkaSource by migrating IT cases from FlinkKafkaConsumer.,2
[FLINK-10390][metrics][datadog] Close responseBody,5
[FLINK-16684] Fix StreamingFileSink builder compilation for ScalaThis commit introduces a new type name for the row and bulk formatStreamingFileSink builders in order to solve the compilation problemof Scala when using generic types with the self-type idiom.This closes #11454.,1
[FLINK-15409][table-planner-blink] Fix code generation in windowed join function (#10714),1
[FLINK-5328] [logging] Add Thread name to FileSystem disposeFileSystemCloseableRegistryForTaskAdding this to the FileSystem dispose call in order to help debugging FLINK-5328when it occurs again. After the initial skim over the logs it looks like thestreams are closed to early for the failed task.,0
"[FLINK-7778] [build] Shade ZooKeeper dependency (part 1)Shading the ZooKeeper dependency makes sure that this specific version ofZooKeeper is used by the Flink runtime module. The ZooKeeper version issensitive, because we depend on bug fixes in later ZooKeeper versionsfor Flink's high availability.This prevents situations where for example a set of added dependencies (forexample transtive dependencies of Hadoop) cause a different ZooKeeper versionto be in the classpath and be loaded.This commit also removes the 'flink-shaded-curator' module, which was originallycreated to shade guava within curator, but is now obsolete, because newerversions of curator shade guava already.",1
[FLINK-18082][jdbc] Fix UnsignedTypeConversionITCase stalls in ch.vorburger.mariadb4j.DB.stopThis closes #12465,5
DumpLogSegments outputs wrong offsets; kafka-128 patched by junrao; reviewed by Joelgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1163929 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix][docs] Fix Kinesis consumer example,0
"KAFKA-7862 & KIP-345 part-one: Add static membership logic to JoinGroup protocol (#6177)This is the first diff for the implementation of JoinGroup logic for static membership. The goal of this diff contains:* Add group.instance.id to be unique identifier for consumer instances, provided by end user;Modify group coordinator to accept JoinGroupRequest with/without static membership, refactor the logic for readability and code reusability.* Add client side support for incorporating static membership changes, including new config for group.instance.id, apply stream thread client id by default, and new join group exception handling.* Increase max session timeout to 30 min for more user flexibility if they are inclined to tolerate partial unavailability than burdening rebalance.* Unit tests for each module changes, especially on the group coordinator logic. Crossing the possibilities like:6.1 Dynamic/Static member6.2 Known/Unknown member id6.3 Group stable/unstable6.4 Leader/FollowerThe rest of the 345 change will be broken down to 4 separate diffs:* Avoid kicking out members through rebalance.timeout, only do the kick out through session timeout.* Changes around LeaveGroup logic, including version bumping, broker logic, client logic, etc.* Admin client changes to add ability to batch remove static members* Deprecate group.initial.rebalance.delayReviewers: Liquan Pei <liquanpei@gmail.com>, Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-8912][WebUI] Rebuild UI,2
[FLINK-22355][docs] Fix simple task manager memory model imageThis closes #15862,1
[FLINK-7662] [build] Remove now obsolete packaged licenses for previously shaded ASM,4
"[FLINK-8765] [quickstarts] Simplify quickstart propertiesThis does not pull out the slf4j and log4j version into properties any more,making the quickstarts a bit simpler.Given that both versions are used only once, and only for the feature to haveconvenience logging in the IDE, the versions might as well be defined directlyin the dependencies.",2
[hotfix][docs] Fix wrong heading in user-defined function docs,2
"KAFKA-6008: Sanitize the app id before creating app id metricAuthor: Jakub Scholz <www@scholzj.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4012 from scholzj/KAFKA-6008",5
KAFKA-7096 : Clear buffered data for partitions that are explicitly unassigned by userAuthor: mgharat <gharatmayuresh15@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5289 from MayureshGharat/KAFKA-7096,1
Fixed hash join tests with after salting hashes.,3
coercer refactoring,4
[FLINK-19810][CI] Automatically run a basic NOTICE file check on CI,2
[hotfix][docs] Unified indentation,2
KAFKA-2743: Make forwarded task reconfiguration requests asynchronous on backoff on retrying.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #422 from ewencp/task-reconfiguration-async-with-backoff,5
[FLINK-19142][runtime] Use LocationPreferenceSlotSelectionStrategy for batch jobs even if local recovery is enabled,0
"KAFKA-7612: Fix javac warnings and enable warnings as errors (#5900)- Use Xlint:all with 3 exclusions (filed KAFKA-7613 to remove the exclusions)- Use the same javac options when compiling tests (seems accidental thatwe didn't do this before)- Replaced several deprecated method calls with non-deprecated ones:  - `KafkaConsumer.poll(long)` and `KafkaConsumer.close(long)`  - `Class.newInstance` and `new Integer/Long` (deprecated since Java 9)  - `scala.Console` (deprecated in Scala 2.11)  - `PartitionData` taking a timestamp (one of them seemingly a bug)  - `JsonMappingException` single parameter constructor- Fix unnecessary usage of raw types in several places.- Add @SuppressWarnings for deprecations, unchecked and switch fallthrough inseveral places.- Scala clean-ups (var -> val, ETA expansion warnings, avoid reflective calls)- Use lambdas to simplify code in a few places- Add @SafeVarargs, fix varargs usage and remove unnecessary `Utils.mkList` methodReviewers: Matthias J. Sax <mjsax@apache.org>, Manikumar Reddy <manikumar.reddy@gmail.com>, Randall Hauch <rhauch@gmail.com>, Bill Bejeck <bill@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
[FLINK-28708][table-planner] Introduce planner rules to optimize DPP patternThis closes,2
[FLINK-9285][REST][docs] Update REST API docsThis closes #5946.,2
Fix config append lost ApplicationConfig (#5434),5
"[hotfix][runtime,tests] Add test coverage for BlockingCallMonitoringThreadPool",3
修改URLgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@755 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Moved ContractUtilTest to test package,3
[FLINK-21331] Optimize calculating tasks to restart in RestartPipelinedRegionFailoverStrategyThis closes #15312,0
[FLINK-25931][format] Add projection pushdown support for CsvFormatFactoryThis closes #19286,1
[FLINK-1201] [gelly] simple graph metrics example,2
[hotfix][tests] Extract AcknowledgeStreamMockEnvironment,4
Add spargel compiler test.,3
[FLINK-17648][yarn] Make YarnApplicationClusterEntryPoint use the yarn.application-master.portThis closes #12109.,1
[hotfix] Introduce ContainerSpecification#createDynamicProperty,5
[FLINK-24058][coordination][tests] Add test for TimerService#isValid,3
"MINOR: Update ""Java Version"" sectionUse the latest information from LinkedIn and mention that the latestreleased version is recommended from a security perspective.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant HenkeCloses #603 from ijuma/java-version-recommendation",5
[hotfix][table-api-java] Fix JavaDocs for TableEnvironment.fromValues,2
[FLINK-10339][network] Use off-heap memory for SpillReadBufferPool,5
[hotfix] [runtime] Disable restart suppression on cancelAndClearEverythingThis temporary disables 28c57c3 (\cc @tillrohrmann),1
"[hotfix][network] Fix InputGate#isAvailable not completed while InputGate#isFinished is trueFinished InputGates should be available for reading, otherwise reader can deadlock waiting ona future that won't be completed ever.",5
"- extended compiler hints for local strategies SORT_BOTH_MERGE, SORT_FIRST_MERGE; SORT_SECOND_MERGE, MERGE, and COMBININGSORT- improved deadlock resolving: temp placement and data source duplication",5
"[yarn] deploy new yarn.tgz with travis, fix file permission in binary",2
[FLINK-23027] Move chill dependency to flink-scala,2
[FLINK-23770][runtime][checkpoint] Retrieve the state with both uidHash and generated ID on checking finished state consistency This closes #16825.,5
"[FLINK-3689] do not shutdown test ActorSystemInstead of shutting down the ActorSystem created in the test, we simply send amessage upon executing the shutdown method of the JobManager, TaskManager, andResourceManager. This ensures we can check for shutdown code execution withoutinterfering with the test.This closes #1852.",3
[FLINK-20114][connector/kafka] PartitionOffsetsRetrieverImpl.committedOffsets() should handle the case without committed offsets.,1
"[FLINK-24439][source] Introduce CoordinatorStoreIn order to allow SourceCoordinatorss from different Sources (for example twodifferent Kafka sources, or Kafka and Kinesis) to align watermarks, they haveto be able to exchange information/aggregate watermarks from those differentSources. To enable this, we need to provide some CoordinatorStore concept,that would be a thread safe singleton.",1
[FLINK-24300] SourceOperator#getAvailableFuture reuses futureCallers of SourceOperator#getAvailableFuture might call the methodmultiple times even if the returned future does not complete. Before thecommit each we were creating a new combined future from theSourceReader#isAvailable and the forcedStop one. If the underlyingSourceReader#isAvailable has not changed this operation is unnecessary.What is even worse each such operation adds another entry onto thesource reader's availability future stack which caused performanceregression.The commit reuses the combined future if the underlyingSourceReader#isAvailable future has not changed.This closes #17303,4
"make produce-sync flush (#8925)Call Producer#flush to make sure all records are indeed sent ""synchronously"" when EOS is not enabled in the OptimizedKTableIntegrationTest#shouldApplyUpdatesToStandbyStore.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
[FLINK-24733][connector/pulsar] Data loss in pulsar source when using shared mode,1
* fix a bug when the provider write a throwable into aysnc context (#1946)* sth doc* simple code,2
"KAFKA-13553: add PAPI KV store tests for IQv2 (#11624)During some recent reviews, @mjsax pointed out that StateStore layersare constructed differently the stores are added via the PAPI vs. the DSL.This PR adds KeyValueStore PAPI construction to theIQv2StoreIntegrationTest so that we can ensure IQv2 works on everypossible state store.Reviewers: Patrick Stuedi <pstuedi@apache.org>, Guozhang Wang <guozhang@apache.org>",1
"MINOR: Remove SubscriptionState.Listener and replace with assignmentId tracking (#6559)We have not had great experience with listeners. They make the code harder to understand because they result in indirectly maintained circular dependencies. Often this leads to tricky deadlocks when we try to introduce locking. We were able to remove the Metadata listener in KAFKA-7831. Here we do the same for the listener in SubscriptionState.Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"some small changes: comment, protobuf, etc.",4
[FLINK-4626] Add missing break in MEtricStore#add(),1
"MINOR: Make PushHttpMetricsReporter API compatible with releases back to 0.8.2.2This is follow up to #4072 which added the PushHttpMetricsReporter and converted some services to use it. We somehow missed some compatibility issues that made the ProducerPerformance tool fail when using a newer tools jar with older common/clients jar, which we do with some system tests so we have all the features we need in the tool but can build compatibility tests for older releases.This just adjusts some API usage to make the tool compatible with all previous releases.I have a full run of the tests starting [here](https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1122/)Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4214 from ewencp/fix-compatibility-sanity-check-tests",3
Worked on locking during recovery,1
[FLINK-4546] [table] Remove STREAM keyword in Stream SQLThis closes #2454.,4
[hotfix][tests] Make RpcEndpointTest more informative,5
"KAFKA-2892 Consumer Docs Use Wrong MethodThe KafkaConsumer docs use a non-existent method for assigning partitions (consumer.assign).The JavaDocs show as:```String topic = ""foo"";TopicPartition partition0 = new TopicPartition(topic, 0);TopicPartition partition1 = new TopicPartition(topic, 1);consumer.assign(partition0);consumer.assign(partition1);```Should be:```String topic = ""foo"";TopicPartition partition0 = new TopicPartition(topic, 0);TopicPartition partition1 = new TopicPartition(topic, 1);consumer.assign(Arrays.asList(partition0, partition1));```Author: Jesse Anderson <eljefe6a@gmail.com>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #592 from eljefe6a/trunk",1
[FLINK-6341] [jm] Add test case to guard against RM registration loop,3
"[FLINK-5021] Make the ContinuousFileReaderOperator rescalable.This is the last commit that completes the refactoring of theContinuousFileReaderOperator so that it can be rescalable.With this, the reader can restart from a savepoint with adifferent parallelism without compromising the providedexactly-once guarantees.",1
[hotfix] [core] Fix checkstyle workaround in FileSystem,5
Cleaned up BroadcastBranchingITCase (added Apache header),1
[FLINK-15194] Support registering directory as cache file in Yarn per-job modeThis closes #10550.,2
"KAFKA-2792: Don't wait for a response to the leave group message when closing the new consumer.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Onur Karaman, Gwen ShapiraCloses #480 from ewencp/kafka-2792-fix-blocking-consumer-close",0
[hotfix] [docs] Improve description of keyBy().,1
"[FLINK-971] Configure PooledByteBufAllocator in NettyConnectionManager instead of using the default allocatorConfiguration:    - 0 heap arenas,    - n direct arenas (where n = num incoming + num outgoing network IO threads), and    - bufferSize << 1 bytes page size.Additionally, OutboundEnvelopeEncoder directly implements ChannelOutboundHandlerAdapter instead of theMessageToByteEncoder<Envelope> wrapper to have tighter control of memory allocations.This closes #38.",1
"Revert ""[FLINK-14894][core][mem] Do not explicitly release unsafe memory when managed segment is freed""This reverts commit 6dcaae0e403a8d7322d5c63e82b01ed24340d984 because it causes Travis to fail.The reasons seems to be too much memory pressure because GC seems to happen too rarely.",1
[FLINK-2837][storm] various improvements for the compatibility layer- refactor to use Storm's topology builder- remove FlinkTopologyBuilder- instantiate context-based StreamExecutionEnvironment (local or remote)- remove some of the Flink and Storm behavior replicating classes- modify FlinkTopology to parse Storm topology directly- replace StormTestBase with StreamingTestBase- add print example- FlinkTopologyBuilder changes (check if all inputs are available before processing)- correct package typo- two input support- add join example- update docsThis closes #1398.,2
[FLINK-21328] Optimize the initialization of DefaultExecutionTopologyThis closes #15088,2
MINOR: Replaced unnecessary map and getOrElse with existsAuthor: himani1 <1himani.arora@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2035 from himani1/code_refactored,4
[FLINK-11905][table-runtime-blink] Fix BlockCompressionTest does not compile with Java 9 (#7981),3
[FLINK-29014][streaming-java][table] Improve end-to-end story about PipelinesOptions.JARSThis closes #20633.,1
"[FLINK-3887] improve dependency management for building docsThe Flink documentation build process is currently quite messy. Thesechanges move us to a new build process with proper dependencyhandling. It assures that we all use the same dependency versions forconsistent build output. Also, it eases the automated building processon other systems (like the ASF Buildbot). The goal was to make thedocumentation build process easier and self-contained.- use Ruby's Bundler Gem to install dependencies- update README- adapt Dockerfile- add additional rules to .gitignore- change default doc output path from /target to /content(default path of the flink-web repository)This closes #2033",2
[FLINK-11428][tests] Prevent file leak,2
"KAFKA-13861; Fix the validateOnly behavior for CreatePartitions requests in KRaft mode (#12106)The KRaft implementation of the `CreatePartitions` ignores the `validateOnly` flag in therequest and creates the partitions if the validations are successful. Fixed the behaviornot to create partitions upon validation if the `validateOnly` flag is true.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"[FLINK-14942][docs] remove the ""shallow copy"" note in ""Modifying savepoints"" section, fix exampleThis closes #13309",0
"MINOR: remove unused code from InternalTopicManagerRemove isValidCleanupPolicy and related fields as they are never used.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1888 from dguy/minor-remove-unused",4
[FLINK-1325] [Java API] Add Java ClosureCleanerThis closes #269,4
[FLINK-12933][sql client] support 'use catalog' and 'use database' in SQL CLIThis PR adds USE CATALOG and USE DATABASE commands to SQL CLI.This closes #8830.,5
"KAFKA-3994: Fix deadlock in Watchers by calling tryComplete without any locksAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Jun Rao, Jiangjie Qin, Guozhang WangCloses #2195 from hachikuji/KAFKA-3994-linked-queue",2
"Dubbo cloud native (#4896)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4807 : Add sort implementation* Refactor* Refactor* Polish apache/dubbo#4845 : [Feature] Enhance the Event-Publishing feature to original ServiceDiscovery* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Polish apache/dubbo#4854 : [Feature] MetadataService supports the Dubbo protocol under auto-increased port* Polish apache/dubbo#4857 : [Enhancement] Sync the Metadata storage type into ApplicationConfig* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4873 : [Feature] Add a conditional EventListener into Event Module* Polish apache/dubbo#4875 : [Feature] Refactor ServiceInstancesChangedListener",4
[FLINK-21402] Introduce SlotPoolServiceSchedulerFactory to bundle SlotPoolService and Scheduler factoriesThe SlotPoolServiceSchedulerFactory bundles the SlotPoolServiceFactory and SchedulerNGFactory to make sure thatwe only instantiate valid SlotPoolService and SchedulerNG combinations.This closes #14969.,1
[FLINK-17606][table] Introduce DataGenerator connector in tableThis closes #12074,5
[hotfix] properly encapsulate the original exception in JobClientThis closes #2890,0
[refactor] Call nextSelection after each emitNext,4
[FLINK-19243][elasticsearch] Bump snakeyaml to 1.27,2
[FLINK-3333] [docs] Improve documentation of DataSet object-reuse modes.This closes #1721,1
[FLINK-8562] [tests] Fix YARNSessionFIFOSecuredITCaseBefore the YARNSessionFIFOSecuredITCase also passed without Kerberos being active.This closes #5416.,4
commit follow #4148,5
[FLINK-1670] [streaming] Collect function for DataStreamStreams back the results from the job to the client via a TCP socket,5
MINOR: Fix a typo in a comment in config/server.properties (#4373),5
"[FLINK-3226] implement GroupReduce translation; enable tests for supported operationsSquashes the following commits:- Compute average as sum and count for byte, short and int type to avoid rounding errors- Move aggregation functions to org.apache.flink.table.runtime- Remove join-related changes- Change integer average aggregations to maintain sum and count- Long average uses a BigInteger sum",1
issue#2516: Remove getSpringContext() from org.apache.dubbo.config.spring.ServiceBean (#2517),5
extended plan-dump test for KMeans,3
[FLINK-6539] Run end-to-end tests on travis,3
"KAFKA-9700: Fix negative estimatedCompressionRatio (#8285)There are cases where `currentEstimation` is less than`COMPRESSION_RATIO_IMPROVING_STEP` causing`estimatedCompressionRatio` to be negative. This, in turn,may result in `MESSAGE_TOO_LARGE`.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: Handle nulls in NonEmptyListValidatorAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3045 from ewencp/minor-non-empty-list-validator-nulls,5
[FLINK-3823] Fix travis log upload & upload logs to transfer.sh (14 days),2
"MINOR: fix record collector to stick with streams partitioner behavior if it is specifiedIf `partition==null` and `partitioner!=null` we should not fall back to default partitioner (as we do before the patch if `producer.partitionsFor(...)` returns empty list. Falling back to default partitioner might corrupt hash partitioning.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Damian Guy, Guozhang WangCloses #2868 from mjsax/minor-fix-RecordCollector",0
[docs] Document metrics visualization in web-frontend,2
"KAFKA-5816; [FOLLOW UP] create ProducedInternal classCreate `ProducedInternal` and remove getters from `Produced`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3810 from dguy/kafka-5816-follow-up",5
"KAFKA-12815: Preserve context for KTable.transformValues when getting value from upstream state store (#10720)Reviewers: Victoria Xia <victoria.xia@confluent.io>, John Roesler <john@confluent.io>",5
Slight improvement of Wordcount Code style.,1
2.0.8 先忽略 BUG DUBBO-63git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@266 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-23399][state] Add a benchmark for rescaling,1
[FLINK-13407][tests][coordination] Harden StandaloneResourceManagerTestGet SlotManager.failUnfulfillableRequest in main thread of StandaloneResourceManagerfor verification in StandaloneResourceManagerTestThis closes #9126.,3
DUBBO-216 增加dubbo-transaction模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@959 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR; Update upgrade documentation for 3.3 (#12550),2
"[hotfix][test] Fix measuring alignmentDurationNanosMaxPreviously the expected alignmentDurationNanosMax was calculated before checkingthe actual alignmentDurationNanos. This meant that during a pending checkpointthe time for alignmentDurationNanos was still ticking, and the actual valuecould exceed the incorrectly calucated expected alignmentDurationNanosMax.",0
[FLINK-19000] Forward initialization timestamp from Dispatcher to ExecutionGraphThis closes #13368,5
recommit kafka-1112 since it's inadvently reverted in the commit of kafka-1135,4
"[FLINK-20266][runtime] Replace dedicated thread pool in ComponentClosingUtils with use of 'FutureUtils.orTimeout()'This removes extra (non-daemon) threads, which were previously keeping the threads alive.",4
"KAFKA-12457; Add sentinel ID to metadata topic (#10492)KIP-516 introduces topic IDs to topics, but there is a small issue with how the KIP-500 metadata topic will interact with topic IDs. For example, https://github.com/apache/kafka/pull/9944 aims to replace topic names in the Fetch request with topic IDs. In order to get these IDs, brokers must fetch from the metadata topic. This leads to a sort of ""chicken and the egg"" problem concerning how we find out the metadata topic's topic ID. This PR adds the a special sentinel topic ID for the metadata topic, which gets around this problem.More information can be found in the [JIRA](https://issues.apache.org/jira/browse/KAFKA-12457) and in [KIP-516](https://cwiki.apache.org/confluence/display/KAFKA/KIP-516%3A+Topic+Identifiers).Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-5746; Document new broker metrics added for health checksAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4026 from rajinisivaram/MINOR-KIP-188-metrics-docs,5
"[FLINK-11185] Fix StreamSourceOperatorWatermarksTest instability.The cause of the instability seems to be that due to a not-so-rare timing,the thread that calls the `interrupt()` on the main thread, runs stillafter its original test finishes and calls `interrupt()` during executionof the next test. This causes the normal execution (or `sleep()` in this case)to be interrupted.This closes #7842.",1
add log in ZkclientZookeeperClient.java (#3109),2
[hotfix][tests] Improve condition readability,1
[hotfix][build] Add japicmp exclusion for getSideOutput incompatibilityChange is source-compatible.,4
[FLINK-8814] [file system sinks] Control over the extension of part files created by BucketingSink.,1
"[FLINK-13977] Replace HighAvailabilityServices#getWebMonitorLeaderElectionService with #getClusterRestEndpointLeaderElectionServiceThis commit deprecates HighAvailabilityServices#getWebMonitorLeaderElectionService and addsa default implementation which throws an UnsupportedOperationException. Moreover, it introducesHighAvailabilityServices#getClusterRestEndpointLeaderElectionService which replaces the formermethod. The default implementation of this method calls getWebMonitorLeaderElectionService inorder to ensure backwards compatibility.",1
"KAFKA-3602; Rename RecordAccumulator dequeFor() and fix usageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ashish Singh <asingh@cloudera.com>, Ismael Juma <ismael@juma.me.uk>Closes #1254 from hachikuji/KAFKA-3602",5
[FLINK-7440] [kinesis] Eagerly check that provided schema and partitioner is serializable in FlinkKinesisProducerThis commit also adds a test to verify that the FlinkKinesisProducer isserializable.This closes #4537.,2
fix doc typo in CacheFilter.java (#5042),2
"[FLINK-24217][docs-zh] Translate ""LOAD Statements"" page of ""SQL"" into Chinese (#17221)",2
[FLINK-19737][table] Introduce TableOperatorWrapperGenerator to translate transformation DAG in a multiple-input node to TableOperatorWrapper DAG (#13707),2
[hotfix][cep] Introduced nfa test harness,3
DUBBO-234 redis注册中心健状性处理git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1217 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Upgrade rest integration,5
"KAFKA-8736: Streams performance improvement, use isEmpty() rather than size() == 0 (#7164)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[streaming] Updated connector type handling to suport generic classes by GenericSourceFunction interface,1
[docs] update version to 0.10,5
minor fix for KAFKA-1152; ReplicaManager's handling of the leaderAndIsrRequest should gracefully handle leader == -1; patched by Swapnil Ghike; reviewed by Jun Rao,0
MINOR: Clean `Metrics.defaultRegistry` to avoid transient failures in `testSessionExpireListenerMetrics`The failure could manifest itself if the default metrics registry had some entries from other tests:`java.lang.AssertionError: Unexpected meter count expected:<0> but was:<3>`I also removed an unused variable and improved the error message to include the metric name.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1544 from ijuma/fix-transient-session-expire-listener-metrics-failure,0
[FLINK-24165][datastream] Fix typo in javadoc of KeyContext classThis closes #17157,2
[FLINK-25528][state-processor-api] Support native savepointthis closes #18840,1
[FLINK-6431] [metrics] Activate strict checkstyle in flink-metricsThis closes #3968.,2
[FLINK-25033][runtime] DefaultExecutionTopology supports update.,5
Forgot license header (which causes apache-rat to fail the build),0
[3.0] fix #9346 use CopyOnWriteArrayList (#9348)fixes #9346,0
[FLINK-25094][test] Correct the LatencyTrackingMapStateTest#verifyIteratorThis closes #18111.,3
修改zookeepergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@215 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Update docs to say 2.2 (#6315)Update docs to say 2.2Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-10193: Add preemption for controller events that have callbacksJIRA: https://issues.apache.org/jira/browse/KAFKA-10193* add `preempt(): Unit` method for all `ControllerEvent` so that all events (and future events) must implement it* for events that have callbacks, move the preemption from individual methods to `preempt()`* add preemption for `ApiPartitionReassignment` and `ListPartitionReassignments`* add integration tests:1. test whether `preempt()` is called when controller shuts down2. test whether the events with callbacks have the correct error response (`NOT_CONTROLLER`)* explicit typing for `ControllerEvent` methodsAuthor: jeff kim <jeff.kim@confluent.io>Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,Stanislav Kozlovski <stanislav@confluent.io>, David Arthur <mumrah@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9050 from jeffkbkim/KAFKA-10193-controller-events-add-preemption",1
"KAFKA-7278; replaceSegments() should not call asyncDeleteSegment() for segments which have been removed from segments list (#5491)Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5505: Incremental cooperative rebalancing in Connect (KIP-415) (#6363)Added the incremental cooperative rebalancing in Connect to avoid global rebalances on all connectors and tasks with each new/changed/removed connector. This new protocol is backward compatible and will work with heterogeneous clusters that exist during a rolling upgrade, but once the clusters consist of new workers only some affected connectors and tasks will be rebalanced: connectors and tasks on existing nodes still in the cluster and not added/changed/removed will continue running while the affected connectors and tasks are rebalanced.This commit attempted to minimize the changes to the existing V0 protocol logic, though that was not entirely possible.This commit adds extensive unit and integration tests for both the old V0 protocol and the new v1 protocol. Soak testing has been performed multiple times to verify behavior while connectors and added, changed, and removed and while workers are added and removed from the cluster.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Robert Yokota <rayokota@gmail.com>, David Arthur <mumrah@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",5
Fix DubboTestChecker NPE (#9081),3
prepare for the next release 3.0.7-SNAPSHOT,5
[FLINK-6891] [table] Add LOG support in SQLThis closes #4122.,1
copyright 2018-2020,5
[hotfix] [streaming api] Improve JavaDocs of the user-fcing checkpointing and state interfaces,1
Refactored grouping,4
[FLINK-28142][runtime] Enrich TaskExecutorRegistration with node informationThis closes #20056.,5
[FLINK-7695] [flip6] Add JobConfigHandler for new RestServerEndpointThis closes #4737.,1
[FLINK-15020][hive] Support timestamp type in hiveThis closes #10401,1
[FLINK-7761] [examples] Include shaded guava dependency in Twitter example jarThis closes #4773.,2
[FLINK-16435][python] Replace since decorator with versionadd to mark the version an API was introducedThis closes #11318.,1
"[FLINK-3779] [streaming-java, streaming-scala] Add QueryableStateStream to KeyedStream[runtime, test-utils, tests]- Exposes queryable state on the API via KeyedStream#asQueryableState(String, StateDescriptor).  This creates and operator, which consumes the keyed stream and exposes the stream  as queryable state.This closes #2051.",1
"[FLINK-16219][runtime] Made AsyncWaitOperator chainable to non-sources.AsyncWaitOperator is not thread-safe when chained to legacy sources, but works well in a chained fashion in all other cases.Moved test case to StreamingJobGraphGenerator.",3
[FLINK-2498] [tests] Clean up GroupReduceITCase and make it more robust by avoiding temp files,2
[FLINK-1974] Fix getNetRuntime() of JobExecutionResult and add documentation- Fix JobInfo to report milliseconds- Added documentation to indicate that the return type is in milliseconds- Added an getNetRuntime method which accepts a desired time unit for easy conversionThis closes #652,1
[FLINK-18461][table-planner-blink] Fix Changelog source can't be insert into upsert sink,4
"MINOR: Reduce the log level when the peer isn't authenticated but is using SSLThe commit here changes the log level of a log message from WARN to DEBUG.As noted in the mail discussion here https://www.mail-archive.com/devkafka.apache.org/msg56035.html,in a pretty straightforward/typical and valid setup, the broker logs getflooded with the following message:[2016-09-02 08:07:13,773] WARN SSL peer is not authenticated, returning ANONYMOUS instead (org.apache.kafka.common.network.SslTransportLayer)Author: Jaikiran Pai <jaikiran.pai@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1825 from jaikiran/ssl-log-level",2
[hotfix][table-common] Reduce number of public extraction classes,4
Refactored execution graph listeners,4
Merge branch 'dev-metadata-spring-environment' into dev-metadata,5
[hotfix][runtime-test] Rename BufferTest to NetworkBufferTestBufferTest was not testing a Buffer interface but NetworkBuffer class.,1
"[FLINK-10493] Migrate all subclasses of TupleSerializerBase to use new serialization compatibility abstractionsThis includes the following serializers:- org.apache.flink.api.java.typeutils.runtime.Tuple0Serializer- org.apache.flink.api.java.typeutils.runtime.TupleSerializer- org.apache.flink.api.scala.Tuple2CaseClassSerializer- org.apache.flink.api.scala.typeutils.CaseClassSerializerAll of these serializers now have their own independent serializersnapshot class. They all implement the SelfResolvingTypeSerializer,allowing us to remove the ensureCompatibility(...) method from theTupleSerializerBase class.",4
[FLINK-18319][notice] Lack LICENSE.protobuf in flink-sql-orcThis closes #12675,2
[FLINK-18616][table] Add SHOW CURRENT DDLsThis closes #12934,1
refactor governance to configcenter,5
"make snakeyaml transitive, governance rule relies on this dependency to work. (#3659)",1
Remove semicolon in Scala files. Fix java doc alignment in AggregatorsITCase.java,2
[FLINK-17646][python] Reduce the package size of PyFlink. (#12106),2
[FLINK-9156][REST][CLI] Update --jobmanager option logic for REST clientThis closes #5838.,2
[hotfix] Correct typo in ExecutionConfigInfo#isObjectReuse,5
Continued to work on handling of InterruptedException from new RPC service,1
DUBBO-304 增加模块信息的配置xsdgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1476 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-14374][runtime,tests] Run RegionFailoverITCase also with DefaultScheduler enabledThis closes #10134.",0
"KAFKA-13522: add position tracking and bounding to IQv2 (#11581)* Fill in the Position response in the IQv2 result.* Enforce PositionBound in IQv2 queries.* Update integration testing approach to leverage consistent queries.Reviewers: Patrick Stuedi <pstuedi@apache.org>, Vicky Papavasileiou <vpapavasileiou@confluent.io>, Guozhang Wang <guozhang@apache.org>",5
"[hotfix] [docs] Fix broken link for time.htm, changed to event_time.htmlThis closes #1816.",4
"KAFKA-5636: Add Sliding Windows documentation (#9264)Add necessary documentation for KIP-450, adding sliding window aggregations to KStreamsReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"[streaming] My stream refactored, JobGraphbuilder update",5
DUBBO-168 ExtensionLoader可以从Spring等其它容器中注入对象git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1069 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Clean-up MemoryRecords variables and APIsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jun RaoCloses #348 from guozhangwang/MemoryRecordsCapacity,4
[FLINK-21480][core] Introduce ExternalResource to represent all the user-defined external resource,1
Add javadoc for dubbo-serialization module(#3002). (#3004)Add javadoc for dubbo-serialization module(#3002).,2
additional csv input format test,3
"KAFKA-4055; System tests for secure quotasFix existing client-id quota test which currently don't configure quota overrides correctly. Add new tests for user and (user, client-id) quota overrides and default quotas.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1860 from rajinisivaram/KAFKA-4055",5
[hotfix][docs] Update IDE Setup guideThis closes #16892.,1
[FLINK-2467] Example WordCountStorm.jar is not packaged correctly - fixed assembly xml fileThis closes #974,2
[FLINK-15913][python] Add Python TableFunction Runner and Operator in old planner (#11020),1
Add KryoSerializer and simple test,3
"KAFKA-3594; After calling MemoryRecords.close() method, hasRoomFor() method should return falseThis exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRoomFor() method. After calling MemoryRecords.close() method, hasRoomFor() method should return false.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma, Grant Henke, Guozhang WangCloses #1249 from omkreddy/KAFKA-3594",0
[FLINK-25145][build] Drop ZK 3.4 / Support ZK 3.6,1
[FLINK-7181] Activate checkstyle flink-java/operators/*This closes #4342.,2
KAFKA-4814; Enable ZK ACLs only when zookeeper.set.acl is setAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2845 from rajinisivaram/KAFKA-4814,5
"MINOR: Fix standby streamTime (#5288)#5253 broke standby restoration for windowed stores.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-15377] Add ResourceManager connecting error to white list,0
[FLINK-26018][connector/common] Create per-split output on split addition in SourceOperatorThis change could avoid watermark being pushed forward by records from the first split in the first fetch when multiple splits are assigned to the source operator.,1
[hotfix] [core] Pre-compile regex pattern in Path class,0
[FLINK-20665][connector-fs][table] FileNotFoundException when restore from latest Checkpoint in Sink CompactionThis closes #14438,3
"[hotfix][tests] Add TestingFatalErrorHandlerResourceThe TestingFatalErrorHandlerResource provides a TestingFatalErrorHandler instance and checks when the reource is beingclosed whether an exception has been caught. If this is the case, then the exception will be rethrown.",3
Adjusted TypeExtractorTest for updates CoGroup combiner signatures.,5
[FLINK-1406] [documentation] update compatibility notice with link to further documentationThis closes #314,2
[FLINK-15847][ml] Include flink-ml-api and flink-ml-lib in opt,2
[FLINK-20188][Connectors][Docs][FileSystem] Added documentation for File SourceCo-authored-by: shihong90 <2572805166@qq.com>Co-authored-by: Alexander Fedulov <1492164+afedulov@users.noreply.github.com>,1
DUBBO-50 迁移配置文件git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@237 1a56cb94-b969-4eaa-88fa-be21384802f2,1
add gpg signing plugin for protobuf compiler,1
[hotfix][checkstyle] Remove suppression for runtime/test.runtime.testutils,3
[FLINK-2458] [FLINK-2449] [runtime] Access distributed cache entries from Iteration contexts & use of distributed cache from Collection EnvironmentsThis closes #970,1
KAFKA-13763: Improve unit testing coverage and flexibility for IncrementalCooperativeAssignor (#11974)Reviewers: Mickael Maison <mickael.maison@gmail.com>,3
"MINOR: Update docs about ZooKeeper upgrade issue from 3.4.X to 3.5.6ZK upgrade from 3.4.X to 3.5.6 fails with ""java.io.IOException: No snapshot found"" if there are no snapshot files. This was discussed in https://issues.apache.org/jira/browse/ZOOKEEPER-3056Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #7625 from omkreddy/zk-upgrade",0
"[FLINK-7668] Add ExecutionGraphCache for ExecutionGraph based REST handlersThe ExecutionGraphCache replaces the ExecutionGraphHolder. Unlike the latter, the formerdoes not expect the AccessExecutionGraph to be the true ExecutionGraph. Instead it assumesit to be the ArchivedExecutionGraph. Therefore, it invalidates the cache entries aftera given time to live period. This will trigger requesting the AccessExecutionGraph againand, thus, updating the ExecutionGraph information for the ExecutionGraph based RESThandlers.In order to avoid memory leaks, the WebRuntimeMonitor starts now a periodic cleanup taskwhich triggers ExecutionGraphCache.cleanup. This methods releases all cache entries whichhave exceeded their time to live. Currently it is set to 20 * refreshInterval of theweb gui.This closes #4728.",1
KAFKA-8333; Load high watermark checkpoint lazily when initializing replicas (#6800)Currently we load the high watermark checkpoint separately for every replica that we load. This patch makes this loading logic lazy and caches the loaded map while a LeaderAndIsr request is being handled.Reviewers: Jun Rao <junrao@gmail.com>,0
[FLINK-11884][table] CalculatedTableOperation construction &transformation to RelNodes,2
support using multi registries/protocols in config center.,5
[hotfix] Remove auto-boxing in ContinuousEventTimeTrigger,1
KAFKA-2502; Documentation for quotasFollowed the approach specified here: https://issues.apache.org/jira/browse/KAFKA-2502I also made a minor fix to ConfigCommand to expose the right options on add-config.Author: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Gwen ShapiraCloses #381 from auradkar/K-2502,2
[FLINK-24018][build] Remove Scala dependencies from Java APIs,4
[FLINK-16986][coordination][refactor] Reduce dependencies of OperatorCoordinatorHolder and OperatorCoordinatorCheckpointContextThis simplifies both testing and future refactoring.,4
MINOR: Fix record conversion time in metrics (#4671)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
Revert [FLINK-19027][tests] Decrease checkpoint timeout to avoid livelocking in UnalignedCheckpointITCase.The failing test actually revealed an edge case during recovery with local channels.,3
[FLINK-5619] Add numStateEntries() method for all keyed backendsThis also adds a test for this in StateBackendTestBase,3
[hotfix][table-api] Remove deprecated table function code in insertInto,1
[FLINK-14113][client] Remove class JobWithJarsThis closes #9726.,4
added murmurHash implementation,1
"KAFKA-10134 Follow-up: Set the re-join flag in heartbeat failure (#9354)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
Fix ReduceDriver for mutable objects and arbitrary return types.,0
"KAFKA-10321: fix infinite blocking for global stream thread startup (#9095)The start() function for global stream thread only checks whether the thread is not running, as it needs to block until it finishes the initialization. This PR fixes this behavior by adding a check whether the thread is already in error state as well.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",0
[3.0] mapping report log optimization. (#9828)fixes #9742,0
Polling for jobmanager webinterface,5
[FLINK-5918] [runtime] port range support for taskmanager.rpc.portThis closes #3416.,1
"KAFKA-4532: StateStores can be connected to the wrong source topic resulting in incorrect metadata returned from Interactive QueriesWhen building a topology with tables and StateStores, the StateStores are mapped to the source topic names. This map is retrieved via TopologyBuilder.stateStoreNameToSourceTopics() and is used in Interactive Queries to find the source topics and partitions when resolving the partitions that particular keys will be in.There is an issue where by this mapping for a table that is originally created with builder.table(""topic"", ""table"");, and then is subsequently used in a join, is changed to the internal repartition topic. This is because the mapping is updated during the call to topology.connectProcessorAndStateStores(..).In the case that the stateStoreNameToSourceTopics Map already has a value for the state store name it should not update the Map.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2250 from dguy/kafka-4532",5
[FLINK-14080][table-planner-blink] Introduce SqlTimestamp as internal representation of TIMESTAMP_WITHOUT_TIME_ZONEThis closes #10035,2
[FLINK-25753][tests] Fix KafkaTableITCase.testStartFromGroupOffsetsLatest,3
"KAFKA-13488: Producer fails to recover if topic gets deleted midway (#11552)Allow the leader epoch to be re-assigned to the new value from the Metadata response if `oldTopicId` is not present in the cache. This is needed because `oldTopicId` is removed from the cache if the topic gets deleted but the leader epoch is not removed. Hence, metadata for the newly recreated topic won't be accepted unless we allow `oldTopicId` to be null.Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",5
update 3.0.2-SNAPSHOT version,5
[FLINK-18850][table-runtime-blink] Add late records dropped metric for row time over windowsThis closes #13519,4
Removed duplicate and broken test for BC variables,3
[hotfix][travis] Add missing jdk11 classifier,1
[streaming] wordcount cluster testing,3
[FLINK-14645][table] Support to keep nullability and precision when converting DataTypes to properties,5
[FLINK-5358] [types] Add support to extract RowTypeInfo from Row instance.This closes #3027.,5
[FLINK-15868] Bump flink-table-planner jackson dependencies to 2.10.1,2
[FLINK-14408][table-planner] Fix open() is not called if UDF is reduced during optimizationThis closes #9916,0
"KAFKA-9098: When users name repartition topic, use the name for the repartition filter, source and sink node. (#7598)When users specify a name for a repartition topic, we should use the same name for the repartition filter, source, and sink nodes. With the addition of KIP-307 if users go to the effort of naming every node in the topology having processor nodes with generated names is inconsistent behavior.Updated tests in the streams test suite.Reviewers: John Roesler <john@confluent.io>, Christopher Pettitt <cpettitt@confluent.io>",5
"KAFKA-7223: document suppression buffer metrics (#6024)Document the new metrics added in #5795Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"[FLINK-11772] [DataStream] Let InternalTimerServiceImpl use new serialization compatibility APIs for key / namespace serializer checksThis commit lets the InternalTimerServiceImpl properly useTypeSerializerSchemaCompatibility /TypeSerializerSnapshot#resolveSchemaCompatibility when attempting tocheck the compatibility of new key and namespace serializers.This also fixes the fact that this check was previously broken, in thatthe key / namespace serializer was not reassigned to be reconfiguredones.",5
[streaming] StreamRecord documentation update1,5
[hotfix][dist] Rename local variables in GlobalConfiguration,5
[FLINK-10591][table] Introduced functions to return time attributes from  MATCH_RECOGNIZE,1
MINOR: Update docs to reflect the ZK 3.5.5 upgrade (#7149)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"[FLINK-4710] [build] Remove Guice Dependency from Hadoop2This dependency is transitively pulled, but not necessary for the parts of theHadoop libraries used by Flink.",2
DUBBO-94 增加AOP和Autowire场景的单元测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@567 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-7708] [flip6] Add CheckpointConfigHandler for new REST endpointThis commit implements the CheckpointConfigHandler which now returns aCheckpointConfigInfo object if checkpointing is enabled. In case thatcheckpointing is disabled for a job, it will return a 404 response.This closes #4744.",0
[streaming] Proper hash join added for window joins,1
"Merge pull request #1761, add Locale serialize & deserialize support.Fixed #906",0
"KAFKA-3774: Make 'time' an optional argument of GetOffsetShellSince the 'time' argument has a default value of -1, it makes sense to make it an optional argument.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1457 from vahidhashemian/KAFKA-3774",5
KAFKA-12794: Fix trailing json tokens in `DescribeProducersRequest.json` (#10709)Reviewers: David Jacot <djacot@confluent.io>,5
"[github] change tab size to 4 spacesThe default tab size on GitHub is 8 spaces. This change decreases thetab size to 4. I think this will make reviewing of code on GitHubmuch easier.This commit also introduces sensible defaults for editors which respectthe "".editorconfig"" file standard.This closes #1404.",2
"Merge pull request #1839, remove validation key from provider url registered to registry.Fixes #1386.",0
[FLINK-17959][python] Fix the 'call already cancelled' exception when executing Python UDFThis closes #12459.,0
[FLINK-4237] [runtime] Cancel savepoints on declined snapshots,1
[FLINK-23649][rocksdb] Add FRocksDB packages to parent-first classloading patterns,5
[hotfix] Declare env and insertStatement transient in DbStateBackend,5
[hotfix][sql] Add name for exector,1
"MINOR: add unit test for StateStoreSerdesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4064 from mjsax/minor-add-state-serdes-test",3
[hotfix] Extract JobLeaderService interface + rename impl into DefaultJobLeaderServiceThis commit allows to provide different JobLeaderService implementations to the TaskExecutor.,1
"Simplify Pojo/Tuple/CaseClass comparator extractKeys() methodAlso fixes a bug with Java/Scala interop: TupleTypeComparator was only checkingfor nested Java Tuples and Pojos, not Scala Case classes.",0
[FLINK-1119] Make sure test mini cluster has started properly before submitting the test job.,3
kafka-883; System Test - update migration tool testsuite after 0.7 ProducerPerformance sends seq MessageID; patched by John Fung; reviewed by Jun Rao,3
"[FLINK-24091][tests] Harden TaskManagerProcessFailureBatchRecoveryITCaseThis commit hardens the TaskManagerProcessFailureBatchRecoveryITCase.testTaskManagerProcessFailure by decreasingthe heartbeat interval and the number of failed heartbeat RPCs. Moreover, it increases the delay between job restartsso that there is enough time for the heartbeat rpc to fail.This closes #17107.",0
"KAFKA-10479; Throw exception if users try to update non-reconfigurable configs of existing listeners (#9284)The previous dynamic configuration validation did not actually compare new configs to original configs as intended, so the expected exception was not thrown.Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9025: Add a option for path existence check in ZkSecurityMigratorhttps://issues.apache.org/jira/browse/KAFKA-9025If a chroot is configured, ZkSecurityMigrator should prompt a confirm to user to ensure whether chroot is specified correctly.Author: huxihx <huxi_2b@hotmail.com>Author: huxi <huxi_2b@hotmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7618 from huxihx/KAFKA-9025",1
[streaming] Incremental OLS fix,0
[FLINK-12350] [State Backends] RocksDBStateBackendTest doesn't cover the incremental checkpoint code pathThis closes #8297.,5
[FLINK-5118] [metrics] Fix inconsistent numBytesIn/Out metrics for network channelsThis closes #3106,1
DUBBO-408 Spring2.0兼容问题git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1830 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-6429] [table] Fix build and simplifications,0
"KAFKA-12523: handle TaskCorruption and TimeoutException during handleCorruption  and handleRevocation (#10407)Need to handle TaskCorruptedException and TimeoutException that can be thrown from offset commit during handleRevocation or handleCorruptionReviewers: Matthias J. Sax <mjsax@confluent.org>, Guozhang Wang <guozhang@confluent.io>",5
migration optimization (#6665),5
"MINOR: Tolerate limited data loss for upgrade tests with old message format (#7102)To avoid transient system test failures, tolerate a small amount of data loss due to truncation in upgrade system tests using older message format prior to KIP-101, where data loss was possible.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
[FLINK-11026][kafka][SQL] Rework kafka sql-client jar creation,1
[hotfix] Allow AllocationID to be built from hexString representation,1
加速测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@115 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-4838] [docs] Remove STREAM keyword in StreamSQLExampleThis closes #2645,4
DUBBO-451 decode失败时打印warn log,2
[FLINK-5451] Extend JMX reporter section,2
"KAFKA-12955: Fix LogLoader to pass materialized view of segments for deletion (#10888)Within LogLoader.removeAndDeleteSegmentsAsync(), we should force materialization of the segmentsToDelete iterable, to make sure the results of the iteration remain valid and deterministic. We should also pass only the materialized view to the logic that deletes the segments, as otherwise we could end up deleting the wrong segments.Reviewers: Jun Rao <junrao@gmail.com>",0
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1390 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fix hessian4 (#9981),0
add Endpoint default constructor. (#8277)Co-authored-by: sypeng <sypeng@iflytek.com>,1
MINOR: Add test for ConsumerNetworkClient.trySend (#6739)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-15599][table] SQL client requires both legacy and blink planner to be on the classpathThis closes #10878,2
KAFKA-9573: Fix VerifiableProducer and VerifiableConsumer to work with older Kafka versions (#8197)These classes are used by `upgrade_test.py` with old Kafka versions so they canonly use functionality that exists in all Kafka versions. This change fixes the testfor Kafka versions older than 0.11.0.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-10257 system test kafkatest.tests.core.security_rolling_upgrade_test fails (#9021)security_rolling_upgrade_test may change the security listener and then restart Kafka servers. has_sasl and has_ssl get out-of-date due to cached _security_config. This PR offers a simple fix that we always check the changes of port mapping and then update the sasl/ssl flag.Reviewers:  Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
[Enhancement] Adding the overriding rule for ExtensionLoader (#6068),1
[hotfix] Fix potential test concurrency instability in BulkSlotProviderImplTest,3
Modified implementation of ExecutionGraph to fix compilation error,0
"KAFKA-5790, KAFKA-5607; Improve error handling in SocketServer to avoid issues laterChanges:  1. When an exception is encountered in any of the methods in `Processor` while processing a channel, log the exception and close the connection. Continue to process other channels.  2. Fixes KAFKA-5790: SocketServer.processNewResponses should not skip a response if exception is thrown.  3. For `IllegalStateException` and `IOException` in `poll()`, don't close the `Selector`. Log the exception and continue.  4. Close channel on any failed send in `Selector`.  5. When closing channel fails or is closed, leave channel state as-is, indicating the state in which the channel was moved to closing.  6. Add tests for various failure scenarios.  7. Fix timing issue in `SocketServerTest.testConnectionIdReuse` by waiting for new connections to be processed by the server.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3548 from rajinisivaram/KAFKA-5607",5
Improved code style,1
[FLINK-6584] [table] Add SQL group window functions to retrieve time attributes.This closes #4199.,1
[FLINK-17096][table-blink] Mini-batch group aggregation doesn't expire state even if state ttl is enabledThis closes #11830,0
[FLINK-17092][python] Add retry when pip install dependencies (#12024),1
[hotfix] remove IntelliJ '//noinspection ...' directives from MemoryManager,4
[FLINK-13894][web] Add TE log link to subtask view,2
"KAFKA-8091; Use commitSync to check connection failure in listener update test (#6450)The use of consumer.poll() made the test flaky since in some cases, it doesn't wait for coordinator connection.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",3
[hotfix][table] REGEXP_EXTRACT return type should always be nullableThis closes #17242.,4
[FLINK-25917][tests] Share RpcSystem,5
Fixed minor bug in method to cancel job,0
[FLINK-15771][tests] Harden SQLClientKafkaITCase,3
[FLINK-8494][config] Migrate CC#DEFAULT_PARALLELISM_KEYThis closes #5377.,5
[FLINK-23369][connector-hive] Use enums for connector optionsThis also replaces ConsumeOrder with the (new) PartitionOrder as theyrepresent the same thing.,1
"[FLINK-12219] Log uncaught exceptions and terminate in case Dispatcher#jobReachedGloballyTerminalState failsFutureUtils#assertNoException will assert that the given future has not been completedexceptionally. If it has been completed exceptionally, then it will call theFatalExitExceptionHandler.This commit uses assertNoException to assert that the Dispatcher#jobReachedGloballyTerminalStatemethod has not failed.This closes #8334.",0
[FLINK-4960] Add AbstractStreamOperatorTestHarness.repackageState()The new method allows testing operator scale-in by combining severalOperatorStateHandles (that result from TestHarness.snapshot()) into oneto allow restoring an operator with a lower parallelism.,1
[hotfix] Make it possible to force MockSourceReader to wait for initial splits assignment,5
[hotfix][runtime] Minor style warning cleanups in SourceCoordinatorContext,4
[FLINK-2278] [ml] Fixes wrong Breeze sparse vector to Flink sparse vector conversion,2
[hotfix][table-api-scala] Unwrap Expression args for jsonObject and jsonArray,5
Continued refactoring,4
"KAFKA-12552: Introduce LogSegments class abstracting the segments map (#10401)This PR is a precursor to the recovery logic refactor work (KAFKA-12553).In this PR, I've extracted the behavior surrounding segments map access within kafka.log.Log class into a new class: kafka.log.LogSegments. This class encapsulates a thread-safe navigable map of kafka.log.LogSegment instances and provides the required read and write behavior on the map. The Log class now encapsulates an instance of the LogSegments class.Couple advantages of this PR:Makes the Log class a bit more modular as it moves out certain private behavior thats otherwise within the Log class.This is a precursor to refactoring the recovery logic (KAFKA-12553). In the future, the logic for recovery and loading of segments from disk (during Log) init will reside outside the Log class. Such logic would need to instantiate and access an instance of the newly added LogSegments class.Tests:Added a new test suite: kafka.log.LogSegmentsTest covering the APIs of the newly introduced class.Reviewers: Satish Duggana <satishd@apache.org>, Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
[FLINK-25573][kafka] Migrate KafkaSink to SinkV2,2
[FLINK-27692][changelog] Refactor ChangelogSnapshotState,4
[hotfix] Refactor TM Metric instantiation-formatting-don't use implicit conversions-fixed ObjectName for mapped bufferpool,0
"[FLINK-21011][table-planner-blink] Fix missed renaming for BatchExecJoinRuleBase, BatchExecNestedLoopJoinRuleBase and BatchExecSingleRowJoinRuleThis closes #14699",0
[hotfix] Add setupFlinkConfig to KubernetesTestBase to make sure flinkConfig is always setup before used,1
[FLINK-5375] [doc] Fix Watermark SemanticsThis closes #3185.,0
[FLINK-9045][REST] Make createLocalEnvironmentWithWebUI more user-friendly logging message for web UI address-add back known logging mesages about webUI address-do not set random port in local stream environmentThis closes #5814.,1
"KAFKA-6023 ThreadCache#sizeBytes() should check overflow    long sizeBytes() {        long sizeInBytes = 0;        for (final NamedCache namedCache : caches.values()) {            sizeInBytes += namedCache.sizeInBytes();        }        return sizeInBytes;    }The summation w.r.t. sizeInBytes may overflow.Check similar to what is done in size() should be performed.Author: siva santhalingam <siva.santhalingam@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4041 from shivsantham/kafka-6023",5
"MINOR; DeleteTopics version tests (#12141)Add a DeleteTopics test for all supported versions. Convert theDeleteTopicsRequestTest to run against both ZK and KRaft mode.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",1
[FLINK-15270][python][docs] Add documentation about how to specify third-party dependencies via API for Python UDFsThis closes #10597.,2
"[FLINK-19384][core] Add common permissive exception signatures to all methods of Source.This makes the exception signatures consistent within the class and with the exception philisophyin other API classes, like transformation functions: Allow users to simply throw or forward anytype of checked exceptions.",1
[FLINK-13562][table-planner-blink] Fix incorrect input type for local stream group aggregate in FlinkRelMdColumnIntervalThis closes #9346,2
[FLINK-23044][docs] Fix typos,2
Cleaned up and  adjusted BulkIterationWithAllReducerITCase,4
"[FLINK-16712][task] Refactor StreamTask to construct final fieldsAt the moment there are four fields initialized in the method of StreamTask#beforeInvoke, such as `stateBackend`, `checkpointStorage`, `timerService`, `asyncOperationsThreadPool`.In general it is suggested to use final fields to get known benefits. So we can refactor the StreamTask to initialize these fields in the constructor instead.This closes #11486",5
[hotfix] Remove redirects for pages which were simply removed,4
[hotfix][runtime] Move shared static test methods of slot allocator into ExecutionSlotAllocatorTestUtils,3
[FLINK-22719][table-planner-blink] Fall back to regular join instead of thrown exception if a join does not satisfy conditions to translate into WindowJoinThis closes #15963,2
"KAFKA-12648: Pt. 1 - Add NamedTopology to protocol and state directory structure (#10609)This PR includes adding the NamedTopology to the Subscription/AssignmentInfo, and to the StateDirectory so it can place NamedTopology tasks within the hierarchical structure with task directories under the NamedTopology parent dir.Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3765; Kafka Code style correctionsRemoved explicit returns, not needed parentheses, corrected variables, removed unused importsUsing isEmpty/nonEmpty  instead of size check, using head, flatmap instead of map-flattenAuthor: Joshi <rekhajoshm@gmail.com>Author: Rekha Joshi <rekhajoshm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1442 from rekhajoshm/KAFKA-3765",1
[hotfix][core][config] Use the new type definition for config options of primitive types in TaskManagerOptions.,5
KAFKA-1046 Added support for Scala 2.10 builds while maintaining compatibility with 2.8.x; reviewed by Neha and Jun,5
"Make code strong, version check compatibility. Fix https://github.com/apache/dubbo/pull/4488 (#4490)",0
[hotfix][client] PackagedProgram#userCodeClassLoader is final,1
"MINOR: Support ExponentialBackoff without jitter (#10455)It is useful to allow ExponentialBackoff to be configured to workwithout jitter, in order to make unit tests more repeatable.Reviewers: David Arthur <mumrah@gmail.com>",3
[hotfix][travis] Fix caching of misc jobAdding the e2e-pre-commit profile activation only to the misc profile broke the caching,2
DUBBO-243 修改ExtensionLoader条件错误git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1135 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-202 Make request processing in kafka asynchronous; patched by jaykreps; reviewed by junrao and nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1230845 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-18034][runtime] Introduce PreferredLocationsRetriever,2
KAFKA-12931: KIP-746: Revise KRaft Metadata Records (#10867)Implement the metadata records changes described in KIP-746. Fix unittests as needed.Reviewers: David Arthur <mumrah@gmail.com>,3
修改测试依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@107 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix] [core] Fix checkstyle in org.apache.flink.api.common.typeinfo,5
[FLINK-13371][coordination] Prevent leaks of blocking partitions,2
"[FLINK-24875][ci] Eagerly create cache directoriesThe cache task fails if the cache directory does not exist, which can happen if you get a cache miss and no test creates said directory.",1
修改方法的访问修饰符git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1515 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Add delay export  test case (#3447),3
Added missing interface implementation,1
KAFKA-1237 mirror maker using 08 consumer and 09 producer; reviewed by Jay Kreps and Joel Koshy,1
[FLINK-14381][table-planner-blink] Get partition keys from catalog table for PartitionableTableSource,2
"KAFKA-5502; read current brokers from zookeeper upon processing broker changeDong Lin's testing of the 0.11.0 release revealed a controller-side performance regression in clusters with many brokers and many partitions when bringing up many brokers simultaneously.The regression is caused by KAFKA-5028: a Watcher receives WatchedEvent notifications from the raw ZooKeeper client EventThread. A WatchedEvent only contains the following information:- KeeperState- EventType- pathNote that it does not actually contain the current data or current set of children associated with the data/child change notification. It is up to the user to do this lookup to see the current data or set of children.ZkClient is itself a Watcher. When it receives a WatchedEvent, it puts a ZkEvent into its own queue which its own ZkEventThread processes. Users of ZkClient interact with these notifications through listeners (IZkDataListener, IZkChildListener). IZkDataListener actually expects as input the current data of the watched znode, and likewise IZkChildListener actually expects as input the current set of children of the watched znode. In order to provide this information to the listeners, the ZkEventThread, when processing the ZkEvent in its queue, looks up the information (either the current data or current set of children) simultaneously sets up the next watch, and passes the result to the listener.The regression introduced in KAFKA-5028 is the time at which we lookup the information needed for the event processing.In the past, the lookup from the ZkEventThread during ZkEvent processing would be passed into the listener which is processed immediately after. For instance in ZkClient.fireChildChangedEvents:```List<String> children = getChildren(path);listener.handleChildChange(path, children);```Now, however, there are multiple listeners that pass information looked up by the ZkEventThread into a ControllerEvent which gets processed potentially much later. For instance in BrokerChangeListener:```class BrokerChangeListener(controller: KafkaController) extends IZkChildListener with Logging {  override def handleChildChange(parentPath: String, currentChilds: java.util.List[String]): Unit = {    import JavaConverters._    controller.addToControllerEventQueue(controller.BrokerChange(currentChilds.asScala))  }}```In terms of impact, this:- increases the odds of working with stale information by the time the ControllerEvent gets processed.- can cause the cluster to take a long time to stabilize if you bring up many brokers simultaneously.In terms of how to solve it:- (short term) just ignore the ZkClient's information lookup and repeat the lookup at the start of the ControllerEvent. This is the approach taken in this ticket.- (long term) try to remove a queue. This basically means getting rid of ZkClient. This is likely the approach that will be taken in KAFKA-5501.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3413 from onurkaraman/KAFKA-5502",2
[FLINK-20427] Remove configuration option to prefer checkpoints over newer savepoints,1
[FLINK-21628][python] Support Python UDAF in Tumbling WindowThis closes #15212,1
trivial follow-up patch for kafka-1073 to fix unit tests; patched by Jun Rao,3
DUBBO-366 修改工程结构，折叠子模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1665 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-20433][tests] Stabilizing UnalignedCheckpointITCase.Improves UnalignedCheckpointITCase in the following ways to avoid running into rare issues or better deal with them:- Reduce load on test machine: Executing a test with p=10 may spawn up to 70 tasks that until backpressured can potentially lead to a full load on 70 cores. This may causes larger GC pauses and other JVM freezes that will trigger the rare PartitionNotFound exception. Now, sources are throttled until the sink backpressures.- Keep track of restart attempts in split enumerator and sink with source instances. Only finish sources if the desired numbers of failures occurred to avoid finishing too quickly.- Avoid relying completely on notifyCheckpointComplete to finish test: notifyCheckpointComplete is not guaranteed to be called but the test completely relied on it. This may lead to indefinite test runs: Some sources are finished while others are still running, but new checkpoints are canceled because of the finished sources. Thus, too many aborted checkpoints will also lead to a completed test.- Readding splits to enumerator (after FLINK-20290 has been fixed). Any unexpected failure may have caused all splits to be dropped, which causes indefinite running tests.- Removing test-class level timeout - AZP has its own timeout that also provides thread dumps - something that would require a tremendous effort in JUnit4.",3
[hotfix][network] use ConcurrentMap#putIfAbsent and Lambdas for partition request handlers,0
[FLINK-7811] Add scala.Enumeration to ignore list for Scala SerialVersionUIDIt seems that the SerialVersionUID of this changed between 2.11 and2.12. We need to ignore it so that we can restore savepoints taken on a2.11 build with a 2.12 build.,4
KAFKA-3104: add windowed aggregation to KStreamAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MastudaCloses #781 from guozhangwang/K3104,1
[hotfix][testing] Remove the unused import from CheckpointBarrierUnalignerTest,3
[Dubbo-5140] Make sure the address element properly populated with 3.0.14 or higher version of cxf #5140 (#5154)* 改为使用soapTransferFactory* 改为使用soapTransferFactory作为destinationFactory* 使用soapTransferFactory替代原来的HttpTransforFactory* 修复codestyle检查错误* 增加SoapAction配置的处理，使wsdl文件可以正常显示operation对应的soapAction值* 修改SoapAction配置类的名称Co-authored-by: sthe9 <he_junjun@163.com>Co-authored-by: Ian Luo <ian.luo@gmail.com>,1
add AbstractServiceDiscovery,1
[hotfix][runtime] Fix checkstyle violations in FailoverStrategyLoader,0
[hotfix][es][tests] Remove unused variableSubsumed by #getUserConfig(),5
[FLINK-14062][runtime] Calculate managed memory fraction based on slot sharing groups,2
Fixed dependencies of pact compiler tests.,3
[FLINK-7097] [scripts] Enable Flip-6 TaskExecutor to be started with taskmanager.shThe taskmanager.sh script now supports to start a TaskExecutor by providing flip6 asa second argument to the script.This closes #4253.,1
[FLINK-10274][conf][docs] Document env.pid.dir,2
fix #2557 Update ConfigUtils.java (#2562),5
"[FLINK-17467][task][e2e] Modify existing upgrade test to verify aligned savepointsNew upgrade job, upon upgrade modifies the job graph and type of processed record.This ensures that savepoints are executed always as aligned, with no in-flight data.",5
added test coverage for nephele.configuration,5
[hotfix][checkpointing] Use practical ChannelStateReader instead of NO_OP,1
[FLINK-27779][connectors/kafka] Remove `flink-table-planner` in favor of `flink-table-test-utils`,3
"[hotfix] Fix broken copy in OperatorChainBefore, the StreamRecords was not copied, now it is.",1
- added Asterix TPCH query example and integration test,3
MINOR: Add actual state directory to related exceptions (#11751)For debugging it is useful to see the actual state directory whenan exception regarding the state directory is thrown.Reviewer: Bill Bejeck <bbejeck@apache.org>,1
[FLINK-22643][network] Reuse tpc connections between taskmanagersThis closes #18365.,1
DUBBO-54 修改泛型git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1195 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-8120] [flip6] Register Yarn application with correct tracking URLThe cluster entrypoints start the ResourceManager with the web interface URL.This URL is used to set the correct tracking URL in Yarn when registering theYarn application.This closes #5128.,1
[hotfix] [table-api-java] correct the logic of `truncateString` method in PrintUtils,3
[FLINK-1945][py] Python Tests less verboseThis closes #1376,1
[FLINK-7762] [connector-wikiedits] Make WikipediaEditsSourceTest proper testThe WikipediaEditsSourceTest unnecessarily implements an integrationtest that starts a FlinkMiniCluster and executes a small Flink program.This simply creates a source and executes run in a separate thread untila single WikipediaEditEvent is received.This closes #5102.,2
[FLINK-6138] [table] Create the ListStateDescriptor with the aggregationStateType instead of a serializer.this closes #3581,1
"KAFKA-7551: Refactor to create producer & consumer in the workerThis is minor refactoring that brings in the creation of producer and consumer to the Worker. Currently, the consumer is created in the WorkerSinkTask. This should not affect any functionality and it just makes the code structure easier to understand.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Randall Hauch <rhauch@gmail.com>, Robert Yokota <rayokota@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5842 from mageshn/KAFKA-7551",5
Reverse url of python (#4162)reverse url of python,5
upgrade curator version to 5.1.0. (#8464),5
[FLINK-7572] [table] Improve TableSchema and FlinkTable validation exception messages.This closes #4640.,5
[FLINK-17206][table] refactor function catalog to support delayed UDF initialization.This closes #11785,5
[FLINK-984] Compiler tests for distinct(). Adopted the old code from @markus-hThe code originates from https://github.com/apache/incubator-flink/pull/61.The pull request also contained code to add POJO support to the distinct() operator. This has already been implemented in earlier work,1
Upgrade version to 2.6.1,5
[FLNK-5354] [docs] Restructured Table API / SQL docs,2
Fix 3.0 followup 9784 (#9793),0
Introduced isBroadcastChannel method in AbstractOutputChannel,5
"[FLINK-3242] Also Set User-specified StateBackend without CheckpointingBefore, the user-specified StateBackedn would not be set when generating theJobGraph if checkpointing was disabled.This closes #1516",1
"KAFKA-5055: Fix Kafka Streams skipped-records-rate sensor bugFix as described in the [KAFKA-5055 Jira comment](https://issues.apache.org/jira/browse/KAFKA-5055?focusedCommentId=15990086&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15990086).mjsax guozhangwang take a lookAuthor: dpoldrugo <dpoldrugo@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2949 from dpoldrugo/KAFKA-5055-skipped-records-rate-sensor-bug",0
DUBBO-256 注册和订阅的URL上带上timestamp，用于标识提供者和消费者的启动时间git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1180 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-18972][runtime] BulkSlotProviderImpl disables batch slot request timeout check only when its slot allocation interface is really in use,1
update leaderAndISR in ZK conditionally; patched by Yang Ye; reviewed by Jun Rao; KAFKA-428git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377157 13f79535-47bb-0310-9956-ffa450edef68,5
[streaming] Proper exception propagation for udf exception + collector bugfix,0
"[FLINK-22048] Remove akka.transport.* config optionsSince Flink uses TCP connections for Akka, we don't need to configure thetransport failure detector and the exposed configuration options are meaningless.Consequently, this commit removes them.This closes #15433.",4
Should close filter in RocksDBStoreTest as well (#6676)Forgot to also close the filter in RocksDBStoreTest in time.Reviewers: Bill Bejeck <bbejeck@gmail.com>,5
[FLINK-2649] [scala shell] Fix unclosed stream in case of an error in JarHelper#unjar()This closes #1151,0
[FLINK-17375] Delete unused files in tools/- tools/qa-check.sh: not in use anymore- tools/merge_flink_pr.py: last commit created with script in 2016- tools/test_deploy_to_maven.sh: trivial,3
Introduced new enumeration for the checkpoint state and integrated it into the management classes,1
Removed debugging output from DiscoveryService,0
MINOR: Pass RecordingLevel to MetricConfig in the brokerThis is a KIP-104/105 follow-up. Thanks to ijuma for pointing out.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2350 from enothereska/minor-broker-level-config,5
"[FLINK-4829] snapshot accumulators on a best-effort basisHeartbeats should not fail when accumulators could not be snapshotted. Instead,we should simply skip the reporting of the failed accumulator. Eventually, theaccumulator will be reported; at the latest, when the job finishes.This closes #2649",5
"[FLINK-12603][network] Remove getOwningTaskName method from InputGateIn order to make abstract InputGate simple for extending new implementations in shuffle service architecture, we could remove unnecessary methods from it.InputGate#getOwningTaskName is only used for debugging log in BarrierBuffer and StreamInputProcessor. This task name could also be generated in StreamTaskvia Environment#getTaskInfo and Environment#getExecutionId. Then it could be passed into the constructors of BarrierBuffer/StreamInputProcessor for use.This closes #8529.",1
[FLINK-6563] [table] Add builders with time attribute support for KafkaTableSources.This closes #4638.,1
Update version to 1.8-SNAPSHOT,5
Added support for availability zones on Amazon EC2,1
[FLINK-25958][runtime] Report failed statistic if adding of completed checkpoint to checkpoint store fails,0
[FLINK-5454] [docs] Add documentation how to tune streaming applications for large state,2
kafka-2266; Client Selector can drop idle connections without notifying NetworkClient; patched by Jason Gustafson; reviewed by Jun Rao,1
[FLINK-4842] Introduce test to enforce order of operator / udf lifecycles,1
add unit test for netty4 remoting (#1509),3
[FLINK-22627][runtime] Remove PendingSlotRequest,4
[FLINK-5917] [statebackends] Remove size() method from MapStateThis closes #3462,4
KAFKA-6277: Ensure loadClass for plugin class loaders is thread-safe.`loadClass` needs to be synchronized to protect subsequent calls to `defineClass`.Details in the javadoc of this PR as well as here too: https://docs.oracle.com/javase/7/docs/technotes/guides/lang/cl-mt.html/cc ewencp rhauchAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4428 from kkonstantine/KAFKA-6277-Make-loadClass-thread-safe-for-class-loaders-of-Connect-plugins,1
"KAFKA-5351: Reset pending state when returning an error in appendTransactionToLogWithout this patch, future client retries would get the `CONCURRENT_TRANSACTIONS` error code indefinitely, since the pending state wouldn't be cleared when the append to the log failed.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3184 from apurvam/KAFKA-5351-clear-pending-state-on-retriable-error",0
[FLINK-6669] set inputEncoding to UTF-8 in scalastyle-maven-plugin,1
[FLINK-19462][checkpointing] Extend PendingCheckpointStats by FailedCheckpointStatsInherit mutation semantics from PendingCheckpointStatsto allow updates even after checkpoint failed.,0
"MINOR: Remove redundant fields in dump log record output (#11101)In 2.8, the dump log output regressed to print batch level information for each record, which makes the output much noisier. This patch changes the output to what it was in 2.7 and previous versions. We only print batch metadata at the batch level.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-17652][config] Legacy JM heap options should fallback to new JVM_HEAP_MEMORY in standaloneThis closes #12110.,1
MINOR: Change log level for group member failure from debug to infoAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3523 from guozhangwang/KMinor-group-coordinator-member-failure-info-log4j,5
DUBBO-301 RPC的error log太多git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1359 1a56cb94-b969-4eaa-88fa-be21384802f2,1
kafka-1078; Update System Test to handle controller data returned by ZK; patched by John Fung; reviewed by Jun Rao,5
- fixed bug #65,0
"Adjusted smoe examples and fixed some tests.Temporarily disabled tests for global sorting, which is disabled for the time being.",3
[hotfix][python] Align the signature of type utility methods with JavaThis closes #8893,0
"KAFKA-12339: Add retry to admin client's listOffsets (#10152)`KafkaAdmin.listOffsets` did not handle topic-level errors, hence the UnknownTopicOrPartitionException on topic-level can obstruct a Connect worker from running when the new internal topic is NOT synced to all brokers. The method did handle partition-level retriable errors by retrying, so this changes to handle topic-level retriable errors in the same way.This allows a Connect worker to start up and have the admin client retry when the worker is trying to read to the end of the newly-created internal topics until the internal topic metadata is synced to all brokers.Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-4427: Skip topic groups with no tasksAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2171 from enothereska/KAFKA-4427-topicgroups-with-no-tasks",5
"[hotfix][docs] Fix broken code block in ""Alter Statement"" pagesThis closes #16235",0
metadata read & write,5
"KAFKA-3853; Extend OffsetFetch API to allow fetching all offsets for a consumer group (KIP-88)Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2074 from vahidhashemian/KAFKA-3853",5
[FLINK-20145][task] Don't expose modifiable PrioritizedDeque.iterator,2
[FLINK-24832][tests][testinfrastructure] Update JUnit5 to v5.8.1,3
[hotfix] Fix typos in ExecutionGraph,2
"MINOR: Code cleanup, subject: log statements.I'm doing this in my spare time, so don't let reviewing this PR take away actual work time. This is just me going over the code with the Intellij analyzer and implementing the most easily implementable fixes.This PR is focused only on seemingly erronous log statements.1: A log statement that has 4 arguments supplied but only 3 `{}` statements2: A log statement that checks is debug is enabled, but then logs on `info` level.Author: coscale_kdegroot <koen.degroote@coscale.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3886 from KoenDG/loggingErrors",2
KAFKA-13479: Implement range and scan queries (#11598)Implement the RangeQuery as proposed in KIP-805Reviewers: John Roesler <vvcephei@apache.org>,2
DUBBO-849 2.0调1.0的float类型转换不兼容git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@694 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-10684; Avoid additional envelope copies during network transmission (#9563)This patch creates a new `SendBuilder` class which allows us to avoid copying ""zero copy"" types when transmitting an api message over the network. This generalizes the pattern that was previously used only for `FetchResponse`. Initially we only apply this optimization to the `Envelope` types and `FetchResponse`, but in the future, it can be the default implementation for `toSend`.The patch also contains a few minor cleanups such as moving envelope parsing logic into `RequestContext`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
[FLINK-17774][table] Supports all kinds of changes for select resultThis closes #12199,4
[hotfix][rest] Rename ClusterConfigurationInfo to ConfigurationInfo,5
"KAFKA-5654; add materialized count, reduce, aggregate to KGroupedStreamAdd overloads of `count`, `reduce`, and `aggregate` that are `Materialized` to `KGroupedStream`.Refactor common parts between `KGroupedStream` and `WindowedKStream`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3827 from dguy/kafka-5654",5
[FLINK-1944] [gelly] Added GSA-PageRank exampleThis closes #626,1
"KAFKA-7063; Remove references to old producers and consumers in docs (#5240)Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
unit-test -> more useful logging level,2
[FLINK-3365] [taskmanager] Properly shut down cleanup timer thread,4
add side key to MetadataService,5
"[hotfix][runtime] Refactor IOManager#close and remove #isProperlyShutDownIOManager#close would ignore any exceptions internally in order not to interrupt other close operations,then IOManager#isProperlyShutDown is used for checking any exceptions during close process. We could useIOUtils#closeAll for handling all the close operations and finally throwing the suppressed exceptions toget the same effect, then isProperlyShutDown method could be removed completely.",4
"Improved input type inference, bug fixing, code simplificationThis closes #176",0
[docs] Replace broken download linkThis variable was removed in dc5062557a55,4
"KAFKA-10024: Add dynamic configuration and enforce quota for per-IP connection rate limits (KIP-612, part 2) (#9386)This PR implements the part of KIP-612 for adding IP throttling enforcement, and a ZK entity for configuring dynamic IP throttles.Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",5
Support static tag group in TagRouter,1
Hotfixing version detectionAdd renaming utility to master branch,1
"[FLINK-21452][connector/common] Stop snapshotting registered readers in source coordinator.Sources used to store their registered readers into the snapshot. However, when downscaling, they have unmatched readers that violate a couple of invariants.The solution is to not store registered readers - they are re-registered on restart anyways.To keep it backward compatible, the best option is to always store an empty list of readers while writing the snapshot and discard any recovered readers from the snapshot.",1
[FLINK-13489][e2e] Fix akka timeout problem of the heavy deployment e2e testThis closes #9391.,3
[hotfix][table-planner] Avoid rawtypes warning in StreamExecDeduplicate,2
"KAFKA-13619: Remove zookeeper.sync.time.ms (#11717)`zookeeper.sync.time.ms` was previously used with the old Scala consumer, whichwas removed in Apache Kafka 2.0.0. Remove the config definition from `KafkaConfig`and documentation.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
[hotfix] Fixed typo in docsThis closes #6219.,2
"KAFKA-4205; KafkaApis: fix NPE caused by conversion to arrayNPE was caused by `log.logSegments.toArray` resulting in array containing `null` values. The exact reason still remains somewhat a mystery to me, but it seems that the culprit is `JavaConverters` in combination with concurrent data structure access.Here's a simple code example to prove that:```scalaimport java.util.concurrent.ConcurrentSkipListMap// Same as `JavaConversions`, but allows explicit conversions via `asScala`/`asJava` methods.import scala.collection.JavaConverters._case object Valueval m = new ConcurrentSkipListMap[Int, Value.type]new Thread { override def run() = { while (true) m.put(9000, Value) } }.start()new Thread { override def run() = { while (true) m.remove(9000) } }.start()new Thread { override def run() = { while (true) { println(m.values.asScala.toArray.headOption) } } }.start()```Running the example will occasionally print `Some(null)` indicating that there's something shady going on during `toArray` conversion.`null`s magically disappear by making the following change:```diff- println(m.values.asScala.toArray.headOption)+ println(m.values.asScala.toSeq.headOption)```Author: Anton Karamanov <ataraxer@yandex-team.ru>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2204 from ataraxer/KAFKA-4205",4
[FLINK-28094][kinesis] Removing references to Regions enum and instead using RegionUtils so that we include future AWS Regions as well,1
[FLINK-11651][tests] Upgrade jepsen dependency to 0.1.11,3
[FLINK-17715][sql-client] Align function DDL support with TableEnvironment in SQL clientThis closes #12171,1
[FLINK-9584][connector] Properly close output streams in Bucketing-/RollingSinkThis closes #6164.,2
"MINOR: Fix import for streams broker compatibility test to use new DEV_BRANCH constantAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2508 from ewencp/minor-streams-compatibility-trunk-dev-branch",1
[hotfix][runtime] move ContinuousFileReaderOperator unit test to theappropriate class and module,3
"Refactor dynamic config,1. Extract common method to AbstractDynamicConfiguration2. Unify strategy when config server cannot be reached at startup: start using local snapshot and try to connect in background.",1
[FLINK-3251] [runtime] Return empty stats for unknown operator,1
"KafkaController NPE in SessionExpireListener; patched by Yang Ye; reviewed by Jun Rao, Neha Narkhede; KAFKA-464git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374467 13f79535-47bb-0310-9956-ffa450edef68",2
[FLINK-17632][yarn] Support to specify a remote path for job jarThis closes #12143.,1
[FLINK-2932] Examples in docs now download shell script using https instead of httpThis closes #1309,1
[3.0] Fix timeout cal in Profiler exceed int range (#9503),2
修改注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1741 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-22902][connectors/kafka] Port KafkaSink to FLIP-143This commit introduces a new KafkaSink which is based onFLIP-143.,1
[FLINK-22919] Remove support for Hadoop1.x in HadoopInputFormatCommonBase.getCredentialsFromUGIThis closes #16107,1
[FLINK-23704][task] Extract LatencyMarkerEmitter class,4
Moved allocatedResourcesDied into AbstractScheduler,4
KAFKA-93 | Change and add ASF source header to follow standard ASF source header (http://www.apache.org/legal/src-headers.html).git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156232 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9742: Fix broken StandbyTaskEOSIntegrationTest (#8330)Relax the requirement that tasks' reported offsetSum is less than the endOffsetSum for thosetasks. This was surfaced by a test for corrupted tasks, but it can happen with real corruptedtasks. Rather than throw an exception on the leader, we now de-prioritize the corrupted task.Ideally, that instance will not get assigned the task and the stateDirCleaner will makethe problem ""go away"". If it does get assigned the task, then it will detect the corruption anddelete the task directory before recovering the entire changelog. Thus, the estimate we provideaccurately reflects the amount of lag such a corrupted task would have to recover (the whole log).Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
[FLINK-11334] Initialize EnumSerializer in constructorWe also don't check the state on every call anymore.,5
[FLINK-14338][table-planner-blink] Update files due to CALCITE-1824* GROUP_ID translation was fixed,0
"[doc] Switch parser to kramdown, normalize HeadingsThe switch to kramdown is necessary because I want to add tabs in thedocumentation for code examples and Redcarpet does not allow markupinside divs.Before, some doc pages had ""#"" headings as toplevel headings whileothers had ""##"" (which is the same as --- underlined headings). Now weuser level 2 everywhere. The page title is still a h1 heading.",1
refactor: inspect code of ZookeeperRegistry classes. (#10284),1
[FLINK-16070] [table-planner-blink] Stream planner supports remove constant keys from an aggregateThis closes #11158,4
"KAFKA-9027, KAFKA-9028: Convert create/delete acls requests/response to use generated protocol (#7725)Also add support for flexible versions to both protocol types.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Colin Patrick McCabe <cmccabe@apache.org>Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>Co-authored-by: Jason Gustafson <jason@confluent.io>",5
Improved robustness and logging of byte-buffered channel manager,2
[Documentation] Add documentation on accessing Microsoft Azure Storage Tables[ci skip]This closes #100,2
[FLINK-3247] Remove * exclude from quickstartsThis closes #1573,4
to process a scenario when service type is not available and service invocation is not generic eitherto process a scenario when service type is not available and service invocation is not generic either,5
Change for demo and test logic,2
[FLINK-10243][metrics] Make latency metrics granularity configurable,5
[FLINK-5877] [docs] Fix Async I/O Scala snippetThis closes #3383,0
[FLINK-3283] Improve Kafka test stability,3
merge and reinit,5
[hotfix] Fix checkstyle violations in ExecutionGraphTestUtils,3
[hotfix][tests] Deduplicate code in SlotManagerImplTest,3
"[FLINK-9908][scheduling] Do not cancel individual scheduling futureSince the individual scheduling futures contain logic to release the slot if it cannotbe assigned to the Execution, we must not cancel them. Otherwise we might risk thatslots are not returned to the SlotPool leaving it in an inconsistent state.This closes #6383.",2
[hotfix][table-common] Add validateExcept() to FactoryUtil,5
KAFKA-1747 TestcaseEnv improperly shares state between instances; reviewed by Neha Narkhede,3
[FLINK-16194][k8s] Introduce Java command decorator for the main Container of the JobManager and the TaskManger Pod,2
Added test for serialization of transfer envelopes,3
[3.0] Fix async context cannot work properly for embedded call. (#9567),1
fixed travis-ci failed because of test cases. (#1370),3
[FLINK-25600][docs] Update doc about new statement set syntaxThis closes #18363,1
[FLINK-24717][table-planner] Push down partitions before filters in table sourcesThis closes #17652.,2
[FLINK-14449][tests] Use dedicated deadline for each test,3
code rule (#3651),5
MINOR: improve flaky Streams system testHandle TimeoutException in Producer callback and retry sending input dataAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #4244 from mjsax/improve-flaky-system-test,5
[FLINK-15063][metric]fix input group and output group of the task metric are reversed,2
[FLINK-13632] Port JavaSerializer upgrade test to TypeSerializerUpgradeTestBase,3
KAFKA-714: ConsoleConsumer throws SocketTimeoutException when fetching topic metadata; reviewed by Neha Narkhede,5
"KAFKA-4725; Stop leaking messages in produce request body when requests are delayedThis change is in response to [KAFKA-4725](https://issues.apache.org/jira/browse/KAFKA-4725).When a produce request is received, if the user/client is exceeding their produce quota, the response will be delayed until the quota is refilled appropriately.Unfortunately, the request body is still referenced in the callback which in turn leaks the messages contained within the request.This change allows the `KafkaApis` method to take ownership of the request body from the `RequestChannel.Request` object.I am not sure whether this breaks other invariants which are assumed within other parts of Kafka.Author: Tim Carey-Smith <tim@spork.in>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2496 from halorgium/fix-throttled-response-leak",0
KAFKA-709 change in default blocking tripped test checking queue is full so updated test in case someone changes the new default to something else,1
"[FLINK-7811] Add ""override"" in Scala code to support Scala 2.12Some places in the code didn't have override, this wasn't a problem forScala 2.11 but Scala 2.12 seems to be more strict.",0
[hotfix][table-common] Update DataTypeUtils.transform for structured types,5
[FLINK-8222] [build] Update Scala versionThis is an incremental upgrade to the Scala security release 2.11.12.This closes #5136,5
Minor modification to output message,5
[FLINK-14490][table-api] Rework insertInto method,1
[FLINK-18720][k8s] Switch kubernetes deployment to the new active resource manager implementation.This closes #13186.,1
[FLINK-13263] [python] Supports explain DAG plan in flink-pythonThis closes #9114,2
"KAFKA-3158; ConsumerGroupCommand should tell whether group is actually deadThis patch fix differentiates between when a consumer group is rebalancing or dead and reports the appropriate error message.Author: Ishita Mandhan <imandha@us.ibm.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1429 from imandhan/KAFKA-3158",5
fix minor build issue: deploy uber-jar only if yarn version is build,0
[FLINK-18694][web] Add unaligned checkpoint config to web uiThis closes #12962.,5
"[FLINK-14341][python] Support pip versions of 7.1.x for gen_protos.pyPreviously, only pip versions of >=8.0.0 are supported for gen_protos.py, thiscommit also add support for pip versions of 7.1.x.This closes #9851.",1
[FLINK-8208][network-tests] Reduce mockito usage in RecordWriterTest,3
KAFKA-4775; Fix findbugs warnings in kafka-toolsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2559 from cmccabe/KAFKA-4775,5
[FLINK-4733] Port Task IO metrics,2
"KAFKA-9133; Cleaner should handle log start offset larger than active segment base offset (#7662)This was a regression in 2.3.1. In the case of a DeleteRecords call, the log start offset may be higher than the active segment base offset. The cleaner should allow for this case gracefully.Reviewers: Jun Rao <junrao@gmail.com>Co-Authored-By: Tim Van Laer <timvlaer@users.noreply.github.com>",1
"[FLINK-1984] Mesos ResourceManager - T1 milestoneImplemented Mesos AppMaster including:- runners for AppMaster and TaskManager- MesosFlinkResourceManager as a Mesos framework- ZK persistent storage for Mesos tasks- reusable scheduler actors for:  - offer handling using Netflix Fenzo (LaunchCoordinator)  - reconciliation (ReconciliationCoordinator)  - task monitoring (TaskMonitor)  - connection monitoring (ConnectionMonitor)- lightweight HTTP server to serve artifacts to the Mesos fetcher (ArtifactServer)- scenario-based logging for:  - connectivity issues  - offer handling (receive, process, decline, rescind, accept)- incorporated FLINK-4152, FLINK-3904, FLINK-4141, FLINK-3675, FLINK-4166",2
[FLINK-8787][flip6] Do not copy flinkConfiguration in AbstractYarnClusterDescriptorThis closes #5591.,5
"[FLINK-7910] [tests] Generalize Test(Stream)Environment to use JobExecutorThis commit introduces the JobExecutor interface which abstracts the actual mini clusterfrom the Test(Stream)Environment. By letting the Flip-6 MiniCluster as well as theFlinkMiniCluster implement this interface, we can run all test base jobs either on theFlip-6 mini cluster or on the current mini cluster.This closes #4897.",5
[hotfix] Harden SlotManagerImplTest#testSlotReportWhileActiveSlotRequestThe SlotManagerImplTest#testSlotReportWhileActiveSlotRequest contained a race condition sincewe were checking the internal state of the SlotManagerImpl's state. The test has been hardenedby removing this check.,4
MINOR: Remove unnecessary batch iteration in FileRecords.downConvertAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4192 from ijuma/avoid-unnecessary-batch-iteration-in-down-convert,5
[hotfix][tests] Remove ProgrammedSlotProviderRemoving the ProgrammedSlotProvider since it is no longer used.,1
[storm-compat] Added ITCases to Storm compatibility examples,1
MINOR: Remove a couple of redundant `CoreUtils.rm` methodsAlso:* Rename remaining `CoreUtils.rm` to `delete` for consistency* Use `try with resources` in `Utils` to simplify code* Silence compiler warning due to exception catch clause in `TestUtils`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1153 from ijuma/remove-redundant-core-utils-rm,4
Added missing Stratosphere headers in Nephele packages,1
[FLINK-21479][coordination] Introduce TaskManagerResourceInfoProvider as the read-only interface of TaskManagerTracker,5
Merge branch 'arvid'Conflicts:sopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/EmitMatrix.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/GenerateMatrix.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/Phase1.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/Phase2.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/Phase3.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/TransitiveClosure.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/SopremoModule.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/AggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/MaterializingAggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/TransitiveAggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/io/JsonParser.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonCollector.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonNodeWrapper.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoMap.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoUtil.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/DirectSchema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/GeneralSchema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyHeadArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/Schema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IJsonNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IntNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/JavaToJsonMapper.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ObjectNode.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/LazyObjectNodeTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNodeTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/type/ObjectNodeTest.java,5
[FLINK-26049][checkpoint] initialize CheckpointLocation after create PendingCheckpoint,1
[FLINK-11380][tests] Finish mocking of resourceManagerClient before using itThe problem was that we started the ResourceManager before we finished the mocking of theresourceManagerClient. This lead then to concurrent modifications of the mock which madethe test fail.,0
fix username & password config in dubbo:registry (#5075),1
[FLINK-26134][docs] Added documentation page with Checkpoint/Savepoint guarantees,2
Fixed deserialization problem in AbstractDeserializer,0
[3.0] Enhance ls command (#10126),5
MINOR: Remove APIs deprecated in 0.11.0 for core and clients (#5158)Not included: old consumers and checksum methodsReviewers: Dong Lin <lindong28@gmail.com>,4
[hotfix] [docs] [tableAPI] Fix typos in Table API documentation.This closes #2776.,2
[FLINK-10163] [sql-client] Support views in SQL ClientAdds initial support for views in SQL Client. It adds the following statements:CREATE VIEW: Creates a virtual table from a SQL query.SHOW VIEW: Describes a previously created virtual table.DROP VIEW: Deletes a previously created virtual table.It also adds the section 'views' to environment files.This closes #6606.,2
[FLINK-1040] Make types() call in projections optionalThis closes #194,1
"MINOR: Build modules in parallel (#9975)- According to https://docs.gradle.org/current/userguide/performance.html#parallel_execution,gradle executes builds serially by default.- With this change, the build performance is significantly better (~2x) on multi-core machinesThe time to run the following command went from 7m20s to 3m34s on one machine:`clean install assemble spotlessScalaCheck checkstyleMain checkstyleTest spotbugsMain`Reviewers: Ismael Juma <ismael@juma.me.uk>",0
[FLINK-18521][release] Add script for creating snapshot branch,1
[hotfix][test] Deduplicate TaskStateStatsTest code,3
[FLINK-26011][compress][test] add ArchUnit tests for the test code,3
"[FLINK-20608][table-planner-blink] Introduce StreamPhysicalLegacyTableSourceScan, and make StreamExecLegacyTableSourceScan only extended from ExecNodeThis closes #14427",1
Remove duplicate code in AbstractConfig (#4492),5
[FLINK-28487][connectors] Introduce configurable RateLimitingStrategy for AsyncSinkWriter,5
修改container页面git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@364 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-24246][connector/pulsar] Bump PulsarClient version to latest 2.9.11. Bump the pulsar-client-all version in pom file.2. Exclude useless dependencies for pulsar-client-all.3. Bump the Pulsar docker version.4. Change the dependencies to pass the tests.5. Drop PulsarTransactionUtils and fix compile issues in tests.6. Add bouncycastle to Pulsar e2e tests.,3
[FLINK-12798][table-planner][table-api-java] Port TableEnvironment to table-api-java moduleThis commit makes the TableEnvironments an API class. It looks upPlanner (for optimizing relation queries and converting them to aStreamTransformations) and Executor which enables to apply and runcreated transformations. This way we can decouple the unified TableEnvironmentfrom a StreamExecutionEnvironment.This closes #8764,1
[FLINK-24631][k8s] Use a stable subset of labels to select jobManager and taskManager podsThis closes #17685.,1
[hotfix] Removed execute() that followed print() in quickstart wordcount jobs,4
[hotfix][table-planner] Remove unused field from PlannerBase,1
Merge branch 'dima'Conflicts:pom.xml,5
[FLINK-12492][cep] Minor optimize the cep operator by avoiding unnecessary copy,1
[FLINK-19435][connectors/jdbc] Fix deadlock when loading different sql driver classes concurrently using Class.forNameThis closes #14361,1
[FLINK-5473] Limit max parallelism to 1 for non-parallel operators[FLINK-5473] Better default behaviours for unspecified maximum parallelismThis closes #3182.,1
"[FLINK-19154] ApplicationDispatcherBootstrap cleans up HA data only on FAILED, CANCELLED, SUCCEEDEDDepending on the status with which a job got terminated, we maywant to shutdown the cluster and clean up all HA data, or not. Tobe able to differentiate between the different termination reasonswe add the ApplicationFailureException.In addition, to be able to shutdown the cluster without cleaning upthe HA data, we need to be able to terminate the dispatcher's shutdown futurewith an exception. This is what the new error handler pass in theApplicationDispatcherBootstrap does. We chose to pass the FatalErrorHandleras a constructor argument because this allows for more robust code.This closes #13699",1
Remove duplicate ut classes,4
[FLINK-28772][hive] Supports ADD JAR command in Hive dialectThis closes #20413,1
"[Refactor] Dubbo cloud native  (#4953)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4807 : Add sort implementation* Refactor* Refactor* Polish apache/dubbo#4845 : [Feature] Enhance the Event-Publishing feature to original ServiceDiscovery* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Polish apache/dubbo#4854 : [Feature] MetadataService supports the Dubbo protocol under auto-increased port* Polish apache/dubbo#4857 : [Enhancement] Sync the Metadata storage type into ApplicationConfig* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4873 : [Feature] Add a conditional EventListener into Event Module* Polish apache/dubbo#4875 : [Feature] Refactor ServiceInstancesChangedListener* Remove the cycle dependencies* Remove the cycle dependencies* Polish apache/dubbo#4903 : [Feature] Set source into the BeanDefinition of Dubbo Config* Polish apache/dubbo#4902 : [Feature] Dubbo Cloud Native to Spring XML scenario* Polish apache/dubbo#4713 : Initial the new module and dependencies* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4910 : [Feature] To suppoort DubboLifecycleComponentApplicationListener in Spring XML scenario* Polish apache/dubbo#4713 : Add Service discovery implementation for Eureka #4713* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4920 : [Refactor] Extract the common implementation for URLs' revision* Refactor* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Remove useless classes* Bugfix & Refactor ServiceDiscoveryRegistry* Polish apache/dubbo#4937 : The calculation of Revision should add the parameters of URL* Polish apache/dubbo#4940 : NacosDynamicConfiguration supports getConfigKeys method* Polish apache/dubbo#4942 : Dubbo Cloud Native supports multiple protcols* Polish apache/dubbo#4944 : [Feature] Simplify The metadata of URL for MetadataService* Polish apache/dubbo#4947 : [Feature] Dubbo Cloud-Native supports the REST call to Non-Dubbo* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/metadata/ServiceInstanceMetadataUtils.java* Refactor",4
[docs] move FAQ to the website's repository,4
[FLINK-21105][table-planner-blink] Rename ExecEdge to InputProperty and rename RequiredShuffle to RequiredDistributionThis closes #14757,1
Excluded nephele EC2 project.Cleaned up POM files.,2
"MINOR: Test the new KIP-500 quorum mode in ducktape (#10105)Add the necessary test annotations to test the new KIP-500 quorum broker modein many of our ducktape tests. This mode is tested in addition to the classicApache ZooKeeper mode.This PR also adds a new sanity_checks/bounce_test.py system test that runsthrough a simple produce/bounce/produce series of events.Finally, this PR adds @cluster annotations to dozens of system tests that weremissing them. The lack of this annotation was causing these tests to grab theentire cluster of nodes.  Adding the @cluster annotation dramatically reducedthe time needed to run these tests.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",3
"[FLINK-18385][docs-zh] Translate ""DataGen SQL Connector"" page into ChineseThis closes #12730",1
[hotfix] [docs] Fix typo in ConfigGroups,5
"MINOR: remove unused fields from KTableImplRemove `keySerde`, `valSerde`, `OUTERTHIS_NAME`, `OUTEROTHER_NAME`, `LEFTTHIS_NAME`, `LEFTOTHER_NAME` from `KTableImpl` as they are all unused fieldsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2119 from dguy/minor-ktable-unused",1
[FLINK-21538][tests] Set default parallelism to 4 for Elasticsearch6DynamicSinkITCase.testWritingDocumentsThis commit sets the default parallelism of Elasticsearch6DynamicSinkITCase.testWritingDocuments to 4 in orderto reduce the load for our CI infrastructure.This closes #16918.,5
[hotfix][tests] Use ConfigOptions instead of hard-coded keys,5
[FLINK-12457][table-planner-blink] Remove char support in blink plannerThis closes #8379,2
[FLINK-20439][runtime] Rename `scheduleOrUpdateConsumers` to `notifyPartitionDataAvailable` to avoid confusion,5
[streaming] Updated Streaming function interfaces to match main project,1
Extended Projection.types() functions up to 22 type parameters.,2
kafka-1168; OfflinePartitionCount in JMX can be incorrect during controlled shutdown; patched by Jun Rao; reviewed by Swapnil Ghike,5
Bug in the collate logic of the DefaultEventHandler dispatches empty list of messages using the producer KAFKA-110; patched by Neha; reviewed by Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159465 13f79535-47bb-0310-9956-ffa450edef68,1
[streaming] javadoc added to api,1
[FLINK-20944][k8s] Do not resolve the rest endpoint address when the service exposed type is ClusterIPThis closes #14692.,1
"KAFKA-13510: Connect APIs to list all connector plugins and retrieve their configs (#11572)Implements KIP-769: https://cwiki.apache.org/confluence/display/KAFKA/KIP-769%3A+Connect+APIs+to+list+all+connector+plugins+and+retrieve+their+configuration+definitionsReviewers: Tom Bentley <tbentley@redhat.com>, Chris Egerton <fearthecellos@gmail.com>",5
"KAFKA-9183; Remove redundant admin client integration testing (#7690)This patch creates a `BaseAdminIntegrationTest` to be the root for all integration test extensions. Most of the existing tests will only be tested in `PlaintextAdminIntegrationTest`, which extends from `BaseAdminIntegrationTest`. This should cut off about 30 minutes from the overall build time.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-11505][runtime] Remove legacy JobManagerRegistrationTest,3
"[FLINK-5521] [runtime] remove unused KvStateRequestSerializer#serializeListAlso make sure that the serialization via the state backends' list statesmatches the deserialization of the KvStateRequestSerializer#deserializeListmethod.So far, it was used this way but not made sure via tests.This closes #3135",3
"KAFKA-6677: Fixed StreamsConfig producer's max-in-flight allowed when EOS enabled. (#4868)Reviewers: Matthias J Sax <matthias@confluentio>, Bill Bejeck <bill@confluent.io>",5
"[FLINK-4715] Fail TaskManager with fatal error if task cancellation is stuck- Splits the cancellation up into two threads:  * The `TaskCanceler` calls `cancel` on the invokable and `interrupt`    on the executing Thread. It then exists.  * The `TaskCancellationWatchDog` kicks in after the task cancellation    timeout (current default: 30 secs) and periodically calls `interrupt`    on the executing Thread. If the Thread does not terminate within    the task cancellation timeout (new config value, default 3 mins), the task    manager is notified about a fatal error, leading to termination of the JVM.- The new configuration is exposed via `ConfigConstants.TASK_CANCELLATION_TIMEOUT_MILLIS`(default: 3 mins) and the `ExecutionConfig` (similar to the cancellation interval).This closes #2652.",5
"Merge pull request #2114, enable configuration of Consumer thread pool.Fixes #2013",0
Added functionality to re-initialize file format defaults for use with local executor.,1
"[hotfix][FLINK-12348][table-api] Remove setConf(String, String) method in TableConfig",5
Implement toString of CsvOutputFormat,5
KAFKA-5443; Consumer should use last offset from batch to set next fetch offsetAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3331 from hachikuji/KAFKA-5443,5
"KAFKA-4658; Improve test coverage InMemoryKeyValueLoggedStoreAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3293 from jeyhunkarimov/KAFKA-4658",4
"KAFKA-2874; shutdown ZK process reliablyAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Flavio Junqueira <fpj@apache.org>, Jun Rao <junrao@gmail.com>Closes #573 from miguno/KAFKA-2874",5
KAFKA-1308 Publish jar of test utilities to Maven,3
KAFKA-7110: Add windowed changelog serde (#5307)Currently the TimeWindowedSerde does not deserialize the windowed keys from a changelog topic properly. There are a few assumptions made in the TimeWindowedDeserializer that prevents the changelog windowed keys from being correctly deserialized. This PR will introduce a new WindowSerde to allow proper deserialization of changelog windowed keys. Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
[hotfix] Various code cleanup in serializers,4
"[FLINK-5485] [webfrontend] Mark compiled web frontend files as binary when processed by git diffParticularly beneficial now that javascript is minified, we can markcompiled web frontend files as binary when processed by git diff.  https://linux.die.net/man/5/gitattributesThis does not affect how files are displayed by github.This closes #3122",2
optimize: replace literal string value with Constant Variable (#5352),5
KAFKA-2740: Convert Windows bin scripts from CRLF to LF line encodingsThere are no functional changes to the modified scripts.Author: Michael G. Noll <michael@confluent.io>Reviewers: Guozhang WangCloses #419 from miguno/KAFKA-2740,5
[hotfix] Correct typo in StreamExecutionEnvironmentThis closes #2393.,2
"Support for reading from "".deflate"" filesImplement clear distinction between unsplittable and serial inputsMade Avro input formats unsplittable",2
[hotfix][tests] Add TestingLibraryCacheManagerThis commit adds a testing implementation of the LibraryCacheManager interface. This makes testing of components which interact with the LibraryCacheManager easier.,3
"KAFKA-13846: Use the new addMetricsIfAbsent API (#12287)Use the newly added function to replace the old addMetric function that may throw illegal argument exceptions.Although in some cases concurrency should not be possible they do not necessarily remain always true in the future, so it's better to use the new API just to be less error-prone.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
KAFKA-1914; follow-up to fix SimpleFetchTest; reviewed by Joel Koshy,3
[FLINK-21976] Remove all files under flink-ml-parentThis closes #15405.,2
Added test case for sequential input/output format,3
[FLINK-8576][QS] Reduce verbosity when classes can't be foundThis closes #5420.,2
"KAFKA-8991: Enable scalac optimizer (#7452)The scalac optimizer is able to inline methods to avoid lambda allocations, eliminatingthe runtime cost of higher order functions in many cases. The compilation parameterswe are using here were introduced in 2.12.x, so we don't enable them for Scala 2.11.Also, we enable a more aggressive inlining policy for the `core` project since it'snot meant to be used as a library.See https://www.lightbend.com/blog/scala-inliner-optimizer for more information aboutthe optimizer.I verified that the lambda allocation in the code below (from LogCleaner.scala) went awayafter this change with Scala 2.12 and 2.13.```scalaprivate def consumeAbortedTxnsUpTo(offset: Long): Unit = {  while (abortedTransactions.headOption.exists(_.firstOffset <= offset)) {    val abortedTxn = abortedTransactions.dequeue()    ongoingAbortedTxns.getOrElseUpdate(abortedTxn.producerId, new AbortedTransactionMetadata(abortedTxn))  }}```The relevant part of the bytecode when compiled with Scala 2.13 looks like:```textprivate void consumeAbortedTxnsUpTo(long);    Code:       0: aload_0       1: invokespecial #54                 // Method abortedTransactions:()Lscala/collection/mutable/PriorityQueue;       4: invokevirtual #175                // Method scala/collection/mutable/PriorityQueue.headOption:()Lscala/Option;       7: dup       8: ifnonnull     13      11: aconst_null      12: athrow      13: astore        4      15: aload         4      17: invokevirtual #145                // Method scala/Option.isEmpty:()Z      20: ifne          48      23: aload         4      25: invokevirtual #148                // Method scala/Option.get:()Ljava/lang/Object;      28: checkcast     #177                // class kafka/log/AbortedTxn```The increased inlining causes some spurious spotBugs warnings, I added a few suppressionsand fixed one warning by avoiding unnecessary boxing.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
Data Source and Sink with INput / Output Format refactoring...,4
[FLINK-15270][python][docs] Corrects docs for method `set_python_executable` in TableConfig,5
Change MessageSet.sizeInBytes to Int; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-556git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401760 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-13429: ignore bin on new modules (#11415)Reviewers: John Roesler <vvcephei@apache.org>,1
[FLINK-21182] Make HeapPriorityQueueStateSnapshot iterableIn order to implement an iterator for a unified savepoint we need a wayto iterate over all entries in a priority queue snapshot.,1
"KAFKA-6119: Bump epoch when expiring transactions in the TransactionCoordinatorA description of the problem is in the JIRA. I have added an integration test which reproduces the original scenario, and also added unit test cases.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4137 from apurvam/KAFKA-6119-bump-epoch-when-expiring-transactions",5
[FLINK-19422] Upgrade Kafka and schema registry versions in the avro registry e2e test,3
[FLINK-3580] [table] Add QUARTER function,1
merge from 0.8 and resolve conflicts,5
"KAFKA-12191 SslTransportTls12Tls13Test can replace 'assumeTrue' by (junit 5) conditional test (#9899)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
"[FLINK-19427][FLINK-19489][tests] Fix test conditions for 'SplitFetcherTest.testNotifiesWhenGoingIdleConcurrent()'The changed logic also fixes flaky thread shutdown logic as a side effect, because it no longer relieson thread interrupting.This closes #13593",1
Added missing utility class,1
[FLINK-9951][build] Update scm developerConnection,5
KAFKA-1865 Add a flush() method to the producer.,1
修改注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1000 1a56cb94-b969-4eaa-88fa-be21384802f2,1
#190 fix class DubboMonitorFactory  name spelling (#987),0
[FLINK-15603][web] Expose checkpointStartDelayNanos metric in the WebUI,2
"[FLINK-25388][table-planner] Add consumedOptions to ExecNodeMetadataScanned all annotated StreamExecNodes and added the `consumedOptions` paramto their `@ExecNodeMetadata` annotation, denoting which configuration optionseach ExecNode is using that might influence the topology and thus statefulrestores.This closes #18624.",2
[FLINK-22469][runtime-web] Fix NoSuchFileException in HistoryServer,2
"Merge pull request #3520, fix #538 polish the process of deciding the ip to bind.",1
"MINOR: use 'mapKey' to avoid unnecessary grouped data (#10082)1. add 'mapKey=true' to DescribeLogDirsRequest2. rename PartitionIndex to Partitions for DescribeLogDirsRequest3. add 'mapKey=true' to ElectLeadersRequest4. rename PartitionId to Partitions for ElectLeadersRequest5. add 'mapKey=true' to ConsumerProtocolAssignmentReviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
should not skipTests (#2958),3
[FLINK-12253][table-common] Add a CHAR type,1
Adopted Tasks and Tests (prefinal version),3
compact with some registry without address (#8496),1
[hotfix] Move JarListInfoTest to correct package,5
"[FLINK-14396][network] Implement rudimentary non-blocking network outputConsidering the mailbox model and unaligned checkpoints requirements in future, task network output should be non-blocking. In other words, as long as output is available,it should never block for a subsequent/future single record write.In the first version, we only implement the non-blocking output for the most regular case, and do not solve the following cases which still keep the previous behavior.1. Big record which might span multiple buffers2. Flatmap-like operators which might emit multiple records in every process3. Broadcast watermark which might request multiple buffers at a timeThe solution is to provide the RecordWriter#isAvailable method and respective LocalBufferPool#isAvailable for judging the output beforehand. As long as there is at-least oneavailable buffer in LocalBufferPool, the RecordWriter is available for network output in most cases. This PR doesn’t include runtime handling of this non-blocking andavailability behavior in StreamInputProcessor.Note: It requires the minimum number of buffers in output LocalBufferPool adjusting to (numberOfSubpartitions + 1) and also adjusting the monitor of backpressure future.",5
[FLINK-13757][doc] Fix description error for the built-in 'is not true' logical functionThis closes #9469,1
"Revert ""[FLINK-13850] refactor part file configurations into a single method""This reverts commit 22b2a8856307c310b4c75b32eeed33ba66c0206e.",4
Introduced priorities for execution listeners,5
[FLINK-23249][runtime] Introduce ShuffleMasterContext to ShuffleMaster,2
[FLINK-14572][test] Print the root cause if job fails in BlobsCleanupITCase,4
[hotfix][python][docs] Add state API in PyDocs,2
[FLINK-3878] Fix support multiple identical temp directories in FileCacheThis closes #1965,2
"MINOR: Close timing window in SimpleAclAuthorizer startup (#5318)ZooKeeper listener for change notifications should be created before loading the ACL cache to avoid timing window if acls are modified when broker is starting up.Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@confluent.io>",5
Fixed some bugs in the Pact compiler,0
Add example that shows off secondary sort,1
[FLINK-20930][runtime] Remove AbstractExecutionSlotAllocatorThis closes #14615.,4
"[FLINK-5929] [tests] Fix SavepointITCase instabilityWhen shutting down the testing cluster it can happen that checkpointfiles lingered around (checkpoints independent of the savepoint).This commit deactives checkpointing for the test and uses count downlatches to track progress, which also reduces the test time.This closes #3427",3
kafka-896; merge 0.8 (988d4d8e65a14390abd748318a64e281e4a37c19) to trunk; patched by Jun Rao; reviewed by Jay Kreps,1
[gelly] made the number of vertices an optional parameter of PageRank; added the edge weight initialization to the library methods,5
[FLINK-22820] Allow storing SUSPENDED jobs in FileExecutionGraphInfoStore,5
TRIVIAL: provide clearer error in describe group when group is inactiveAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #502 from hachikuji/trivial-consumer-groups-fix,0
"KAFKA-13892: Fix bug where multiple remove records are generated for one ACLFix a bug where multiple remove records could be generated for a single ACL. Previously, this happenedif the user submitted multiple filters to deleteAcls, and more than one matched.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
[hotfix][runtime] Remove unused local variable in ExecutionGraph,1
[FLINK-24131][connectors/kafka] Improve debuggability of KafkaWriter.This also aligns the transaction ids with checkpoint ids starting at 1.,0
"KAFKA-9866: Avoid election for topics where preferred leader is not in ISR (#8524)In this commit we made sure that the auto leader election only happens after the newly starter broker is in the isr.No accompany tests are added due to the fact that:this is a change to the private method and no public facing change is madeit is hard to create tests for this change without considerable effortReviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",4
[FLINK-20717][metrics] Provide new backPressuredTimeMsPerSecond metric,1
fix bug: Rest Protocol can't work when use Tomcat as WebContainer (#6402)Co-authored-by: 01376420 <1qaz!QAZ>,1
"KAFKA-4042: Contain connector & task start/stop failures within the WorkerInvoke the statusListener.onFailure() callback on start failures so that the statusBackingStore is updated. This involved a fix to the putSafe() functionality which prevented any update that was not preceded by a (non-safe) put() from completing, so here when a connector or task is transitioning directly to FAILED.Worker start methods can still throw if the same connector name or task ID is already registered with the worker, as this condition should not happen.Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1778 from shikhar/distherder-stayup-take4",5
[FLINK-4381] Refactor State to Prepare For Key-Group State Backends,4
"KAFKA-8058: Fix ConnectClusterStateImpl.connectors() method (#6384)Fixed the ConnectClusterStateImpl.connectors() method and throw an exception on timeout. Added unit test.Author: Chris Egerton <chrise@confluent.io>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Robert Yokota <rayokota@gmail.com>, Arjun Satish <wicknicks@users.noreply.github.com>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #6384 from C0urante:kafka-8058",5
"KAFKA-2312: use atomic long for thread id reference; reviewed by Ewen Cheslack-Postava, Jason Gustafson, Ismael Juma and Guozhang Wang",1
[utils] Missing getters for ParameterToolCloses #1168,2
[FLINK-2463] [web dashboard] Shows job configuration in new dashboardThis closes #953,1
[FLINK-6711] Activate strict checkstyle for flink-jdbc,5
[FLINK-19542][k8s] Introduce data structures and common operations for KubernetesConfigMap,5
Try to move export & refer action out from ServiceConfig & ReferenceConfig.,5
Correct typos in Table API docs; update enumeration of supported table sources,1
"KAFKA-6796; Fix surprising UNKNOWN_TOPIC error from requests to non-replicas (#4883)Currently if the client sends a produce request or a fetch request to a broker which isn't a replica,we return UNKNOWN_TOPIC_OR_PARTITION. This is a bit surprising to see when the topic actuallyexists. It would be better to return NOT_LEADER to avoid confusion. Clients typically handle both errors by refreshing metadata and retrying, so changing this should not cause any change in behavior on the client. This case can be hit following a partition reassignment after the leader is moved and the local replica is deleted.To validate the current behavior and the fix, I've added integration tests for the fetch and produce APIs.",3
MINOR: changes to the production broker configuration docs.Author: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2519 from alexlod/production-config-docs,5
[scala] Add missing operator IT Cases,1
[FLINK-22966][runtime] StateAssignmentOperation returns only not null state handles,0
[FLINK-26658][docs] Migrate documentation build to Github Actions,2
[FLINK-12179][coordination] Remove legacy class Instance,4
[FLINK-22523][table-planner-blink] Window TVF should throw helpful exception when specifying offset parameter (#15803),2
"KAFKA-5567: Connect sink worker should commit offsets of original topic partitionsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3499 from kkonstantine/KAFKA-5567-With-transformations-that-mutate-the-topic-partition-committing-offsets-should-to-refer-to-the-original-topic-partition",1
"KAFKA-8590; Use automated TxnOffsetCommit type and add tests for OffsetCommit  (#6994)This PR changes the TxnOffsetCommit protocol to auto-generated types, and add more unit test coverage to the plain OffsetCommit protocol.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-13714: Fix cache flush position (#11926)The caching store layers were passing down writes into lower store layers upon eviction, but not setting the context to the evicted records' context. Instead, the context was from whatever unrelated record was being processed at the time.Reviewers: Matthias J. Sax <mjsax@apache.org>",1
KAFKA-2691: Improve handling of authorization failure during metadata refreshAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun RaoCloses #394 from hachikuji/KAFKA-2691,5
[hotfix][runtime] Remove unused ResourceManagerServicesThis closes #18959.,1
[FLINK-18315][table-planner-blink] Fix INSERT INTO partitioned table with VALUES doesn't work correctlyThe VALUES would be patched up with partition fields.This closes #12677,1
Ignore Generic Invoke for Injvm invocation copy (#8986),5
[FLINK-19218][core] Remove inconsistent/misleading locality information from Local File Splits.,2
[FLINK-7635] Add side-output test in WindowOperatorContractTest,3
KAFKA-4296; Fix LogCleaner statistics rollingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2016 from hachikuji/KAFKA-4296,5
[FLINK-25600][sql-client] Support new statement set syntax in sql clientThis closes #18363,1
Remove unnecessary null check.,4
"Refactoring, coverage",3
[FLINK-14800][hive] Introduce parallelism inference for HiveTableSourceThis closes #10210,5
[FLINK-22702][tests] Add test data supplier which provide null timestamp field to kafka connector tests,3
[FLINK-15341][client] Reset context classload in PackagedProgramUtils#createJobGraph,1
"Changes on demo, for test purpose.",3
"Revert ""[FLINK-26079][state/changelog] Disallow recovery from non-changelog checkpoints""This reverts commit 6fc4bad2",4
Fix for FLINK-708 (Hadoop 2.4 compatibility) and FLINK-887 (YARN Jobmanager heapspace calc),2
[FLINK-23511][docs] Fix display of system metrics,5
[FLINK-25230][table-planner] Harden type serialization for LogicalType and DataType,5
"[FLINK-19320][task] Remove RecordWriter#clearBuffersPreviously, RecordWriter#clearBuffers was used to recycle the partially filled buffer in the serializer. However, currently the serializer does not contain any network buffer any more. The method now is used to finish the current BufferBuilders and only some tests and BatchTask use it. Actually, these usage should be replaced by RecordWriter#close which dose the same thing. So this patch removes RecordWriter#clearBuffers and the corresponding test cases.",3
MINOR: support KRaft in TransactionsExpirationTest (#11633)Reviewers: José Armando García Sancio <jsancio@gmail.com>,3
[hotfix] Fix checkstyle violations in KeyGroupRangeAssignment,0
[FLINK-14566][core] Enable to get/set managed memory weight in Transformation,1
"DUBBO-202 override-provider:多条override一起下发,测试override覆盖，并测试多个override同时覆盖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@943 1a56cb94-b969-4eaa-88fa-be21384802f2",1
[FLINK-19849] Fix NOTICE files for 1.12 releaseThis closes #13796,1
KAFKA-1725 Configuration file bugs in system tests add noise to output and break a few tests; reviewed by Neha Narkhede,3
Implemented convenience method to detect last envelope transfered through a channel,5
[FLINK-25771][connectors][Cassandra][test] Add a test that raiseCassandraRequestsTimeouts indeed changes the configuration inside the container.,5
[FLINK-13055][runtime] Leverage PartitionTracker for checking partition availability,2
KAFKA-13080: Direct fetch snapshot request to kraft controller (#11041)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"KAFKA-3008: Parallel start and stop of connectors and tasks in ConnectAuthor: Konstantine Karantasis <konstantine@confluent.io>Author: Konstantine Karantasis <k.karantasis@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1788 from kkonstantine/KAFKA-3008-Parallel-start-and-stop-of-connectors-and-tasks",5
[FLINK-24635][examples] Fix deprecations in side output example,0
[FLINK-18242][state-backend-rocksdb] Remove the deprecated OptionsFactory and related classesThis closes #12683.,4
fix quick start path problem,0
[FLINK-2874] Fix recognition of Scala default setters,1
[FLINK-4209] Simplify docker-compose script (volumes are now local),2
"Changed members of Costs to double, cumulative cost is now the node cost plus the costs of the children divided by their out degree",4
Reintroduced set for recently removed channel ID in order to make cancelling of tasks more robust,1
[FLINK-9801][build] Add missing example dependencies to flink-distThis closes #6304.,2
[FLINK-15174][security] (follow-up) Add a test for exceptions on invalid / malformed fingerprint and refine docs.,2
MINOR: fix JavaDoc (#9217)Reviewer: John Roesler <john@confluent.io>,5
"MINOR: fix grammatical errors in DataException messageWas just reading kafka source code, my favourite Friday afternoon activity, when I found these small grammatical errors in some `DataException` messages.Could someone please review? ewencp dguyAuthor: Laurier Mantel <laurier.mantel@shopify.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1551 from LaurierMantel/maps-typos",2
[FLINK-11922][metrics] Support MetricReporter factories,1
KAFKA-7341 Migrate core module to JUnit 5 (#9855)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
- Fixed All-2-All Shortest Path example PACT program- Added JavaDocs to All-2-All Shortest Path example PACT program- Fixed All2AllSPITCase- Removed exclude for All2AllSPITCase,4
[hotfix][shuffle] Rename ShuffleEnvironment#releasePartitions to ShuffleEnvironment#releasePartitionsLocally,0
[hotfix][build] Remove hard-coded scala version,4
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1414 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-16485][python] Support vectorized Python UDF in batch mode of old planner (#11859),1
"[FLINK-23427][chinese-translation] Translate the page of ""Blocking Shuffle"" into ChineseThis closes #16627.",1
"MINOR: WorkerUtils#topicDescriptions must unwrap exceptions properly (#6937)Reviewers: Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",1
"KAFKA-1464; Add a throttling option to the Kafka replicationThis applies to Replication Quotasbased on KIP-73 [(link)](https://cwiki.apache.org/confluence/display/KAFKA/KIP-73+Replication+Quotas) originally motivated by KAFKA-1464.System Tests Run: https://jenkins.confluent.io/job/system-test-kafka-branch-builder/544/**This first PR demonstrates the approach**.**_Overview of Change_**The guts of this change are relatively small. Throttling occurs on both leader and follower sides. A single class tracks the throttled throughput in and out of each broker (**_ReplicationQuotaManager_**).On the follower side, the Follower Throttled Rate is calculated as fetch responses arrive. Then, before the next fetch request is sent, we check to see if the quota is violated, removing throttled partitions from the request if it is. This is all encapsulated in a few lines of code in the **_ReplicaFetcherThread_**. There is existing code to handle temporal back off, if the request ends up being empty.On the leader side it's a little more complex. When a fetch request arrives in the leader, it is built, partition by partition, in **_ReplicaManager.readFromLocalLog_**. As we put each partition into the fetch response, we check if the total size fits in the current quota. If the quota is exceeded, the partition will not be added to the fetch response. Importantly, we don't increase the quota at this point, we just check to see if the bytes will fit.Now, if there aren't enough bytes to send the response immediately, which is common if we're catching up and throttled, then the request will be put in purgatory. I've added some simple code to **_DelayedFetch_** to handle throttled partitions (throttled partitions are checked against the quota, rather than the messages available in the log).When the delayed fetch completes, and exits purgatory, _**ReplicaManager.readFromLocalLog**_ will be called again. This is why _**ReplicaManager.readFromLocalLog**_ does not actually increase the quota, it just checks whether enough bytes are available for a partition.Finally, when there are enough bytes to be sent, or the delayed fetch times out, the response will be sent. Before it is sent the throttled-outbound-rate is increased, based on the size of throttled partitions being sent. This is at the end of _**KafkaApis.handleFetchRequest**_, exactly where client quotas are recorded.There is an acceptance test which asserts the whole throttling process stabilises on the desired value. This covers a number of use cases including many-to-many replication. See **_ReplicationQuotaTest_**.Note:It should be noted that this protocol can over-request. The request is built, based on the quota at time t1 (_ReplicaManager.readFromLocalLog_). The bytes in the response are recorded at time t2 (end of _KafkaApis.handleFetchRequest_), where t2 > t1. For this reason I originally included an OverRequestedRate as a JMX metric, but testing has not seen revealed any obvious issue. Over-requesting is quickly compensated by subsequent requests, stabilising close to the quota value._**Main stuff left to do:**_- The fetch size is currently unbounded. This will be addressed in KIP-74, but we need to ensure this ensures requests don’t go beyond the throttle window.- There are two failures showing up in the system tests on this branch:  StreamsSmokeTest.test_streams (which looks like it fails regularly) and OffsetValidationTest.test_broker_rolling_bounce (which I need to look into)_**Stuff left to do that could be deferred:**_- Add the extra metrics specified in the KIP.- There are no system tests.- There is no validation for the cluster size / throttle combination that could lead to ISR dropoutsAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>Closes #1776 from benstopford/rep-quotas-v2",5
KAFKA-13261: Add support for custom partitioners in foreign key joins (#11368)Implements KIP-775.Co-authored-by: Tomas Forsman <tomas-forsman@users.noreply.github.com>,1
[FLINK-27116][hive] Support read Hive table partitioned by decimal typeThis closes #19388,1
[FLINK-18905][task] Allow SourceOperator chaining with MultipleInputStreamTask,5
Check config instance in ConfigManager before create a new one.,1
Fixed #188,0
[hotfix][table-common] Add default precision temporal data types,5
[FLINK-12348][table-planner-blink] Use TableConfig in api module to replace TableConfig in blink-planner module.This closes #8294,2
[FLINK-19043][docs-zh] Translate the 'Logging' page of 'Debugging & Monitoring' into ChineseThis closes #13271,1
[FLINK-17254][python][docs] Improve the PyFlink documentation and examples to use SQL DDL for source/sink definition.This closes #11945.,5
[hotfix] [tableAPI] Adapt tests to changed null-value support default,1
1. remove getExecutorService method cexecutor local variables (#4319),1
"MINOR: Extend release.py with a subcommand for staging docs into the kafka-site repoAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>Closes #3917 from ewencp/stage-docs",2
[FLINK-6463] [cep] Throw exception when NOT-NEXT is after OPTIONAL.,2
perf: Ignore unnecessary exception stack trace in testcase (#8420)1. Ignore of printing exception stack trace in ConfigCenterConfigTest#testOverrideConfig2. Ignore of printing exception stack trace in MethodConfigTest#testVerifyMethodConfigOfService3. Ignore of printing exception stack trace in ReferenceConfigTest#test1ReferenceRetry,5
"[FLINK-17436][python] Fix the IllegalAccessError caused by package-private access control when submitting Python job via ""flink run"". (#11930)",1
[FLINK-23252][changelog] Support recovery from checkpoint after disabling changelog backend,4
[FLINK-14370][kafka][test-stability] Fix the cascading test failure in KafkaProducerTestBase.,3
[FLINK-17027][hotfix] Rename back-off infix to backoff in new Elasticsearch properties,1
DynamicConfiguration: return default value if not implemented. (#6086)fixes #5916,0
"KAFKA-4704; Coordinator cache loading fails if groupId is reused for offset storage after group is removedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2455 from hachikuji/KAFKA-4704",5
[FLINK-8421] [core] Introduce PostVersionedIOReadableWritable,2
Fix isShutdown() always return true (#1426),0
[FLINK-23617][datastream] Translate sink into the new SinkOperatorFactory and CommitterOperatorFactory.This commit converts existing sink operators into SinkWriterStateHandler and CommitterHandler and composes them into the new operators.Further all test cases are adjusted to test the new combinations.,1
[FLINK-22289] Update JDBC XA sink docs,2
"Polish, remove call of deprecated method",4
[FLINK-9785][network] add remote address information to LocalTransportException instancesThis closes #6291,5
[FLINK-23854][connectors/kafka] Reliably abort lingering transactions in Kafka.The new approach depends on successively aborting transactions until an unused transaction is ensured. This approach covers all edge cases including failures before first checkpoint and downscaling without checkpoints.,0
Extended UniformPactRecordGenerator to produce keys and values starting at an offset,1
MINOR: KIP-161 upgrade docs changeAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #4036 from guozhangwang/KMinor-kip-161-docs,2
[FLINK-21833][table-runtime-blink] Fix state of TemporalRowTimeJoinOperator increase unlimitedly even state ttl is enabledThis closes #15247,0
[FLINK-24596][kafka] Make passed lambdas of UpsertKafka serializable,4
[FLINK-20663][core] Forbid calling HybridMemorySegment#wrap on unsafe segments.,2
"MINOR: Fix topology builder debug log message (#8005)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[hotfix] Remove unused method from SlotPool,1
included examples source code into assembly,5
"test: verify the process of exported provider in single registry center (#8501)1. Check if the exporter exported by RegistryProtocolListener, ServiceListener and ExporterListener2. Check if the provider works well by Filter",1
[FLINK-13626] Update StatefulJobSavepointMigrationITCase to restore from 1.9 savepointThis closes #9658.,5
"kafka-1984; java producer may miss an available partition; patched by Jun Rao; reviewed by Ewen Cheslack-Postava, Jay Kreps, and Guozhang Wang",5
[FLINK-5164] Disable some Hadoop-compat tests on WindowsThis closes #2889.,3
KAFKA-6247; Install Kibosh on Vagrant and fix release downloads in DockerFix an omission where Kibosh was not getting installed on Vagrantinstances running in AWS.Fix an issue where the Dockerfile was unable to download old ApacheKafka releases.  See the discussion on KAFKA-6233.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4240 from cmccabe/KAFKA-6247,5
[FLINK-25034][runtime] Let InputGateDeploymentDescriptor supports subpartition range.This closes #18050.,1
[FLINK-17458] Stop TaskSubmissionTestEnvironment.testingRpcService when closing the environmentThis closes #13569.,3
"[FLINK-6708] [yarn] Harden FlinkYarnSessionCli to handle GetClusterStatusResponse exceptionsThis PR hardens the FlinkYarnSessionCli by handling exceptions which occur whenretrieving the GetClusterStatusResponse. If no such response is retrieved and insteadan exception is thrown, the Cli won't fail but retry it the next time.",1
[FLINK-21922][python] Fix partition_by in Over doesn't work with expression DSLThis closes #15338.,1
"MINOR: Remove sleep calls and ignore annotation from streams upgrade test (#6046)The StreamsUpgradeTest::test_upgrade_downgrade_brokers used sleep calls in the test which led to flaky test performance and as a result, we placed an @ignore annotation on the test. This PR uses log events instead of the sleep calls hence we can now remove the @ignore setting.Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-348 merge trunk to branch 1239902:1310937 patch by Joe Stein reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1344526 13f79535-47bb-0310-9956-ffa450edef68,1
Added missing Stratosphere headers,1
"KAFKA-6790: Fix Streams processor node broken link (#4874)The page here https://kafka.apache.org/11/documentation/streams/developer-guide/memory-mgmt.html talks about processor nodes and refers to non existing links.Broken link (appears twice in the same document):https://kafka.apache.org/11/documentation/streams/concepts.html#streams-concepts-processorTo find this search for the word ""processor node"" on the page memory-management , the ones which are links are broken.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
[FLINK-16366] [table] Introduce executeSql method in TableEnvironmentSupported statement:CREATE TABLE / DROP TABLE / ALTER TABLE /CREATE DATABASE / DROP DATABASE / ALTER DATABASE /CREATE FUNCTION / DROP FUNCTION / ALTER FUNCTION /CREATE CATALOG / USE CATALOG / USE [CATALOG.]DATABASE /SHOW CATALOGS / SHOW DATABASES / SHOW TABLES / SHOW FUNCTIONSThis closes #11700,1
[FLINK-11508][tests] Remove invalid test AkkaJobManagerRetrieverTestThis closes #7633.,3
[hotfix] [table] Change scala.Boolean to java.lang.Boolean in UpsertStreamTableSink interface.,4
HOTFIX: RegexSourceIntegrationTest needs to cleanup shared output topic (#5008)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"[FLINK-23732][tests] Increase logger-startup-timeout to 50sIn order to harden tests on slow CI, this commit increases the logger-startup-timeout from 30s to 50s.This closes #16814.",2
[FLINK-17667][table-planner-blink][hive] Support INSERT statement for hive dialectThis closes #12129,1
[FLINK-9771][rest] Fix plan JSON responseThis closes #6274.,1
[doc] Fix javadoc building.The java8 Xdoclint:none fix was not correctly transferred when movingthe javadoc building to a jekyll plugin.,2
[FLINK-28018][core] correct the start index for creating empty splits in BinaryInputFormat#createInputSplits,1
[Dubbo-#2162]Correct the reference retries default value 0 to 2 (#2183)* Correct the reference retries default value 0 to 2* fix the unit test error,0
[FLINK-4734] [gelly] Remove use of Tuple setField for fixed positionThis closes #2590,0
[hotfix] [kinesis] Properly add serialVersionUIDs to FlinkKinesisProducer classes,2
[FLINK-18552][tests] Update migration tests of StatefulJobSavepointMigrationITCase (Java version) to cover migration from 1.10,3
"[FLINK-13561][table-planner-blink] Fix NOW() should return TIMESTAMP instead of BIGINT.This aligns the behavior to other systems (MySQL, Spark). Because NOW() is Synonyms for CURRENT_TIMESTAMP.",1
[FLINK-22592][runtime] numBuffersInLocal is always zero when using unaligned checkpointsThis closes #15915,1
Put dependencies in pact-scala in the right places,5
HOTFIX: Temporarily ignoring this test until fixedAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1838 from enothereska/hotfix-ignore-smoke-test,3
Merge branch 'annotation+newOptimizer' ofhttps://stratosphere.eu/fhueske into version02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/OptimizerNode.java,5
[FLINK-13774][table-planner-blink] Remove unresolved expression in RexNodeConverter,0
Leverage new ConfigSetter#close method to properly open/close filter (#6730)Uses the close method added in KIP-453 to properly init & close RocksObjects in RocksDBStoreTestReviewers: Bill Bejeck <bbejeck@gmail.com>,5
[FLINK-9629][metrics] Include dependencies in datadog reporter jarThis closes #6191.,5
Ignore flatten related files. (#3885),2
"[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIREDBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,if the failure of checkpointing is detected after checkpoint times out, the failure gets ignored sincethe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theoryunless something else fails.This PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`.",0
Log flush should complete upon broker shutdown; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-126git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1175966 13f79535-47bb-0310-9956-ffa450edef68,1
Add onlyExtensionClassLoaderPackages support for ExtensionLoader (#9061)* Add onlyExtensionClassLoaderPackages support for ExtensionLoader* revert temp,4
"KAFKA-13104: Controller should notify raft client when it resigns #11082When the active controller encounters an event exception it attempts to renounce leadership.Unfortunately, this doesn't tell the RaftClient that it should attempt to give up leadership. Thiswill result in inconsistent state with the RaftClient as leader but with the controller asinactive.  This PR changes the implementation so that the active controller asks the RaftClientto resign.Reviewers: Jose Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",4
Improved code style,1
Rename Sequential In/Out Formats to Serialized*Format,5
[FLINK-16166][build] Append additional javadoc options,2
"KAFKA-6656; Config tool should return non-zero status code on failure (#4711)Prior to this patch, we caught some exceptions when executing the command, which meant that it would return with status code zero. This patch fixes this and makes the expected exit behavior explicit. Test cases have been added to verify the change.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"[FLINK-12944][docs-zh] Translate ""Streaming File Sink"" page into ChineseThis closes #8918",1
[FLINK-10819] Replace with the Flink's Deadline implementationRemove Scala's Deadline and replace it with Flink's own version.This closes #10950.,2
[FLINK-4094] [core] Add a warning to only use off heap memory with pre-allocation=trueThis closes #2336,1
[FLINK-24352] [table-planner] Add null check for temporal table check on SqlSnapshotThis closes #17845,1
[FLINK-8797] Port AbstractOperatorRestoreTestBase to MiniClusterResource,5
[streaming] Streaming API grouping rework to use batch api Keys,1
"KAFKA-3097: Update docs to mention PrincipalType ""User"" is case sensitive (#5734)Reviewers: Jun Rao <junrao@gmail.com>",1
[FLINK-25888][coordination][metrics] Capture deploymentTime,2
[examples] Add toString() method to accumulator,1
[FLINK-24408][table-planner] Enable code splitting for large number of VALUES clauseThis closes #17586,1
[FLINK-17622][connectors/jdbc] Remove useless switch for decimal in PostgresCatalogThis closes #12090,2
[FLINK-16317][operators] Provide support for watermarks in  MultipleInputStreamOperator,1
"[FLINK-2025] add support for booleans in csv parserThe following values are parsed as booleans:""true"" or ""1"" -> true""false"" or ""0"" -> falseAll checks are performed case-insensitive.This closes #685.",1
DUBBO-970 修改本地路由git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1596 1a56cb94-b969-4eaa-88fa-be21384802f2,1
kafka-1616; Purgatory Size and Num.Delayed.Request metrics are incorrect; patched by Guozhang Wang; reviewed by Jun Rao,5
Fix get the wrong merger type in MergeableClusterInvoker.java (#5371)fixes #5370,0
[hotfix][streaming][test] Allow AbstractStreamOperatorTestHarness to use managed memory for operator use case,1
[hotfix][runtime] Add missing generics in RecordWriterBuilder for avoiding unchecked warning,2
[FLINK-18622][python] Add Table.limit method in the Python Table API (#13364),1
"KAFKA-10811: Correct the MirrorConnectorsIntegrationTest to correctly mask the exit procedures (#9698)Normally the `EmbeddedConnectCluster` class masks the `Exit` procedures using within the Connect worker. This normally works great when a single instance of the embedded cluster is used. However, the `MirrorConnectorsIntegrationTest` uses two `EmbeddedConnectCluster` instances, and when the first one is stopped it would reset the (static) exit procedures, and any problems during shutdown of the second embedded Connect cluster would cause the worker to shut down the JVM running the tests.Instead, the `MirrorConnectorsIntegrationTest` class should mask the `Exit` procedures and instruct the `EmbeddedConnectClusters` instances (via the existing builder method) to not mask the procedures.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",3
change mesh rule group to config default value (#8330),5
[FLINK-4573] [web dashboard] Fix potential resource leak due to unclosed RandomAccessFile in TaskManagerLogHandlerThis closes #2556,2
"[FLINK-18742][cli] Respect all config args when creating packaged program at clientBefore this, options like the classloader order was not respected if specified inthe command like because the packaged program was created before we create theeffective configuration at the client. This commit changes the order of events.This closes #13024.",4
MINOR: Remove `toStruct` and `fromStruct` methods from generated protocol classes (#9960)Update few classes that were still using the removed methods (includingtests that are no longer required).Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
KAFKA-1253 Compression in the new producer; reviewed by Jay Kreps and Jun Rao,1
Implemented piggybacking of lookup information,5
"[FLINK-13123] [cli] rename ""-s"" parameter of stop command",2
"KAFKA-7944: Improve Suppress test coverage (#6382)* add a normal windowed suppress with short windows and a short graceperiod* improve the smoke test so that it actually verifies the intendedconditionsSee https://issues.apache.org/jira/browse/KAFKA-7944Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-739 Handle null message payloads in messages and in the log cleaner. Reviewed by Jun and Neha.,4
"[FLINK-14899] [table-planner-blink] Fix unexpected plan when PROCTIME() is defined in querye.g. `SELECT * (SELECT *, ROW_NUMBER() OVER (ORDER BY PROCTIME() ASC) as rowNum FROM MyTable) WHERE rowNum = 1` should be translated to StreamExecDeduplicate instead of StreamExecRankThis closes #10291",0
"[hotfix][network] Make prune auto clear the bufferIt makes it more consistent and explicit. Previously it was assumed thatbuffer is clear before pruning and it was used that way, but thereticallyprune that's not proceeded/followed by clear would result in incosistent stateand position that points to non existing data.",5
"[FLINK-20348][kafka] Make ""schema-registry.subject"" optional for avro-confluent format when used with kafkaThis closes #14530Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>",1
fix UTs,0
"[FLINK-10918][state backends] Change o.a.f.core.fs.Path to java.nio.file.Path in RocksDB incremental checkpointsThis solves the bug that Paths are handled wrong on Windows, breaking incremental checkpoints.This closs #11095",4
Added check concerning illegal arguments to EC2 client factory,1
[FLINK-3927][yarn] make container id consistent across Hadoop versions- introduce a unique container id independent of the Hadoop version- improve printing of exceptions during registration- minor improvements to the Yarn ResourceManager codeThis closes #2013,1
Generate source attachments for each subproject,5
[FLINK-2425] [runtime] Cleanup code for forwarding config and hostname into TaskManager's RuntimeEnvironment,1
把 src/main/java 添加到资源目录中git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1013 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Add codestyle,1
[FLINK-22121][table-planner-blink] The field names in Rank and Over should be uniqueThis closes #15498,2
"[FLINK-18395][FLINK-18388][docs-zh] Translate ""ORC Format"" and ""CSV Format"" page into ChineseThis closes #12774",1
Fixed bug in replay logic,2
Changed calculation of meta data file size to enable faster recovery,0
[FLINK-3882] [docs] Fix errors in sample Java code for the Elasticsearch2 sinkThis closes #1971,0
[FLINK-13245][network] Remove redundant bookkeeping for already canceled input channel IDs,4
MINOR: update README with how to run code coverage on module. add reportCoverage at subProject levelAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2527 from dguy/code-coverage,3
"在配置阶段处理register=""false""和subscribe=""false""git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1486 1a56cb94-b969-4eaa-88fa-be21384802f2",1
[FLINK-9026] [flip6] Close the TaskManagerMetricGroup when the TaskExecutor is shut downThis closes #5734.,2
"[FLINK-15999][doc] Remove distinction between managed and raw state from state.mdUsers should not be using raw state, except in rare edge cases. We canjust refer to managed keyed state ad keyed state and managed operatorstate as operator state from now on.",1
"[FLINK-26320][docs] Update the default value from ""1m"" to ""1min"" in Hive pageThis closes #18768",1
DUBBO-483 ReferceConfig添加Finalizer Guardian,5
[FLINK-20978] Implement SavepointKeyedStateHandleIntroduce a marker SavepointKeyedStateHandle interface for state handles that describe savepoints. Based on the interface we can later decide which strategy to use when restoring from the handle.,0
[FLINK-11485] [core] Implement new PojoSerializerSnapshot class,1
[streaming] test update,5
Modified TeraSort example to use PACT global order option,1
[FLINK-29217][tests] Guarantee checkpoint order in OC testThis closes #20781.,3
KAFKA-7052 Avoiding NPE in ExtractField SMT in case of non-existent fields (#8059)Author: Gunnar Morling <gunnar.morling@googlemail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,4
"KAFKA-4510: StreamThread must finish rebalance in state PENDING_SHUTDOWNAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Guozhang WangCloses #2227 from mjsax/kafka-4510-finish-rebalance-on-shutdown",5
KAFKA-9780: Deprecate commit records without record metadata (#8379)Author: Mario Molina <mmolimar@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"Removed check that executionResourcesExhausted call must be from environment thread to enable chained tasks.Check is overly restrictive, since the only condition is that the output gate is always accessed by the same thread.",0
MINOR: equals() should compare all fields for generated classes (#8539)Reviewers: Jason Gustafson <jason@confluent.io>,5
Merge branch 'trunk' of https://git-wip-us.apache.org/repos/asf/kafka into trunk,1
[FLINK-2357] [web dashboard] New node organization,1
[FLINK-28193][runtime] Enable to identify whether a job vertex contains source/sink operatorsThis closes #20043.,1
package cleanup,4
[Dubbo-900] Fix 通过 override 修改 hessian协议的提供者的配置 不生效 #900 (#3363)* reExport fail fix#900* modify* use Objects.equals* compare URL for all proxy protocol,1
[hotfix][docs] Fix typo,2
[FLINK-11730] [State Backends] Make HeapKeyedStateBackend follow the builder patternThis closes #7866.,1
[FLINK-10945] Mark InputDependencyConstraint as PublicEvolving,2
[FLINK-19013][state-backends] Add start/end logs for state restoration,2
Fix checkstyle and warnings in EnumSerializer,2
[FLINK-28868][connector/hbase] Migrate HBase table connector to the new LookupFunction interfaceThis closes #20495,1
Adjusted Avro Input Format for new Java API.Adjusted test case for externally packaged avro program.,3
[hotfix][travis] Move flink-python to misc,2
"MINOR: Add 'task container' class to KafkaStreams TaskManager (#9835)Kafka Streams' TaskManager is a central class that grew quite big. ThisPR breaks out a new 'task container' class to descope what TaskManagerdoes. In follow up PRs, we plan to move more methods from TaskManagerto the new 'Tasks.java' class and also improve task-type type safety.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-1279 Socket server should close all connections when it is shutdown.,5
DUBBO-76 增加通过host 获取ip的方法git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@346 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Added implementation for serializable hash set,1
[FLINK-6747] [docs] Add documentation for QueryConfig.This closes #4256.,5
[FLINK-18935] Reject CompletedOperationCache.registerOngoingOperation if cache is shutting downThis commit changes the CompletedOperationCache so that it rejects registerOngoingOperation callswith an IllegalStateException if the cache is already shutting down. This ensures that now newoperation will be enqueued while waiting for the previous operations to complete.This closes #13139.,1
[FLINK-4143][metrics] Configurable delimiterThis closes #2219,5
"KAFKA-8334 Make sure the thread which tries to complete delayed reque… (#8657)The main changes of this PR are shown below.1. replace tryLock by lock for DelayedOperation#maybeTryComplete2. complete the delayed requests without holding group lockReviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",1
[FLINK-28586][runtime] Improve SourceCoordinator and SourceCoordinatorContext to support execution attempt level split requests and eventsThis closes #20299.,1
"MINOR: Fix typo in Utils#toPositive (#9943)Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2
[Bugfix] rename the dubbo-metadata-report-api to dubbo-metadata-api (#5357)* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5309 : [ISSURE] The beans of Dubbo's Config can't be found on the ReferenceBean's initialization* Polish apache/dubbo#5312 : Resolve the demos' issues of zookeeper and nacos* Polish apache/dubbo#5313 : [Migration] migrate the code in common module from cloud-native branch to master* Polish apache/dubbo#5316 : [Refactor] Replace @EnableDubboConfigBinding Using spring-context-support* Polish apache/dubbo#5317 : [Refactor] Refactor ReferenceAnnotationBeanPostProcessor using Alibaba spring-context-suuport API* Polish apache/dubbo#5321 : Remove BeanFactoryUtils* Polish apache/dubbo#5321 : Remove AnnotatedBeanDefinitionRegistryUtils* Polish apache/dubbo#5321 : Remove AnnotationUtils* Polish apache/dubbo#5321 : Remove ClassUtils* Polish apache/dubbo#5321 : Remove BeanRegistrar* Polish apache/dubbo#5321 : Remove ObjectUtils* Polish apache/dubbo#5321 : Remove PropertySourcesUtils* Polish apache/dubbo#5325 : [Migration] To migrate dubbo-metadata-api from cloud-native branch* Polish apache/dubbo#5326 : [Migration] To migrate dubbo-metadata-processor from cloud-native branch* Polish apache/dubbo#5329 : [Feature] To add the default metadata into ServiceInstance* Polish apache/dubbo#5339 : [Refactor] Refactor the DynamicConfiguration interface* Polish bugfix* Fixes test cases* Merge remote-tracking branch 'upstream/master' into cloud-native-2.7.5# Conflicts:#dubbo-configcenter/dubbo-configcenter-zookeeper/src/test/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfigurationTest.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/DynamicConfigurationServiceNameMappingTest.java* Merge remote-tracking branch 'upstream/master' into cloud-native-2.7.5# Conflicts:#dubbo-configcenter/dubbo-configcenter-zookeeper/src/test/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfigurationTest.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/DynamicConfigurationServiceNameMappingTest.java* Fix test-cases* Polish rename module dubbo-metadata-api,5
"KAFKA-13037: ""Thread state is already PENDING_SHUTDOWN"" log spamDemote this from INFO to debug since it's absolutely spamming the logsReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2
"MINOR: rework JavaDoc for windowing related public API - also some code refactoring and bug fixesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2337 from mjsax/javaDocImprovements4",2
"KAFKA-696 Fix toString() API for all requests to make logging easier to read; reviewed by Neha Narkhede, Jun Rao",2
Set up parameters for composite operators.,1
"KAFKA-3989; Initial support for adding a JMH benchmarking moduleAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1712 from bbejeck/KAFKA-3989_create_jmh_benchmarking_module",1
[hotfix] Enable killing mesos job manager in e2e clean up function,1
"KAFKA-8199: Implement ValueGetter for Suppress (#6781)See also #6684KTable processors must be supplied with a KTableProcessorSupplier, which in turn requires implementing a ValueGetter, for use with joins and groupings.For suppression, a correct view only includes the previously emitted values (not the currently buffered ones), so this change also involves pushing the Change value type into the suppression buffer's interface, so that it can get the prior value upon first buffering (which is also the previously emitted value).Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-10465][tests] Do not stop sshd if it is supervised by runit.,1
"[FLINK-6546] [build] Fix dependencies of flink-mesos  - This makes all flink-related dependencies 'provided' to not have the    transitive dependencies promoted  - Drops the unnecessary dependency on the Hadoop artifact  - Adds directly referenced libraries, like jackson  - Deactivates default logging of tests",3
"fixed properties propagation: instead of using a property blindly in the union case, it is droppedTODO: figure out when properties can be keept in the union case",4
"MINOR: fix HTML (#9127)Reviewers: Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"MINOR: Controller should process events without rate metrics (#7732)Fixes #7717, which did not actually achieve its intended effect. The event manager failed to process the new event because we disabled the rate metric, which it expected to be present.Reviewers: Ismael Juma <ismael@juma.me.uk",1
DUBBO-358 修改xsdgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1633 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-10917][metrics] Bump dropwizard to 3.2.6,4
"MINOR: Add logging when commitSync fails in StreamTaskWhen `consumer.commitSync` fails in `StreamTask`, the `CommitFailedException` bubbles up to [here](https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L780) and swallowed.  It'd be great if we knew which offsets failed to commit so that we may rewind our consumer.Author: J$ <jmonette@homeaway.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2514 from jmoney8080/jsm.addCommitLogLogging",2
"KAFKA-13946; Add missing parameter to kraft test kit `ControllerNode.setMetadataDirectory()` (#12225)Added parameter `metadataDirectory` to `setMetadataDirectory()` so that `this.metadataDirectory` would not be set to itself.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-9269][state] Fix concurrency problem when performing checkpoint in HeapKeyedStateBackend.This closes #5934.,0
[FLINK-21571][build] Fix japicmp referenceVersion,0
- removed union handling from compiler- replaced key arrays by fieldlists / fieldsets in most places- added several todo flags for release,2
"fix #10202, use getRemoteAddress (#10203)Co-authored-by: 呈铭 <beck.wcm@antgroup.com>",1
[FLINK-5329] Fix metric list being cut offThis closes #3109.,0
[hotfix][csv][javadoc] Fix reference,0
"MINOR: Use new version of ducktapeducktape diff: https://github.com/confluentinc/ducktape/compare/v0.7.8...v0.7.9- bcrypt (a dependency of ducktape) dropped Python2.7 support.ducktape-0.7.9 now pins bcrypt to a Python2.7-supported version.Author: Andrew Egelhofer <aegelhofer@confluent.io>Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9192 from andrewegel/trunk",1
[hotfix] [doc] Fixed doc typo in DataStream APIThis closes #5283.This closes #5191.,5
[FLINK-16541][doc] Fix document of table.exec.shuffle-modeThis closed #11386,2
[hotfix][javadocs] Fix metric handler example javadocs,2
"MINOR: make the constructor of InMemoryKeyValueStore public so that it can be re-used by custom (in-memory) stores (#5310)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-18656][tests] Rename MultipleInputStreamTaskTestHarnessBuilder to StreamTaskMailboxTestHarnessBuilderThe orignal concept MultipleInputStreamTaskTestHarnessBuilder proved much moreversatile then initially expected and it can easily handle all of the uses cases:- MultipleInputStreamTask- OneInputStreamTask- SourceStreamTaskHence there is no need for the abstraction and no need to provide specialized versions ofMultipleInputStreamTaskTestHarnessBuilder for the other types of tasks.,3
"KAFKA-12979; Implement command to find hanging transactions (#10974)This patch implements the `find-hanging` command described in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions#KIP664:Providetoolingtodetectandaborthangingtransactions-FindingHangingTransactions.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
[docs] Removed unnecessary Serializable from ExecutionEnvironment JavaDocsAlso did for StreamExecutionEnvironment,2
Cleanup and simplification in the taskmanager and the local instances and mini cluster.,5
[hotfix] [cep] Remove unused keySelector in operator.,1
[hotfix][hive] Add an ITCase that checks partition-time commit pretty wellThis closes #15754,1
Synced pact-tests between optimizer reworking and runtime reworking.,1
"[FLINK-18090][core][table] Update Row#toString and provide legacy utilThis updates the Row.toString method to provide a good summary string.In particular it fixes the following issues:Changeflag: According to FLIP-95, a row describes an entry in achangelog. Therefore, it should visible whether a row is an insert,delete, or update change. Now indicated with +I, -D, +U, -U.Nested rows: In the old implementation it was not visible whether nestedrows exist or not due to missing start/end boundaries. Now indicated with[...] or {...}.Positioned rows vs. named rows: According to FLIP-136, it should be visiblewhether a row operates in name-based or position-based field mode. Nowindicated with [...] or {...}.Nested arrays in maps and lists: In the old implementation arrays in mapsor lists could not be represented.Wrong formatting: Most programming languages use a space after a comma.This is an incompatible change. If the legacy representation is stillrequired for tests, the old behavior can be restored via the flagRowUtils.USE_LEGACY_TO_STRING for the local JVM. However, relying onthe row's string representation for tests is not a good idea in general asfield data types are not verified.",5
"KAFKA-8816: Make offsets immutable to users of RecordCollector.offsets (#7223)Make offsets immutable to users of RecordCollector.offsets. Fix up anexisting case where offsets could be modified in this way. Add a simpletest to verify offsets cannot be changed externally.Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"[FLINK-13708][table-planner-blink] Transformations should be cleared after execution in blink plannerTransformations should be cleared after execute() otherwise it will be executed multiple times.And tEnv.explain() shouldn't affect the transformation tree, otherwise it will be executed multiple times too.This closes #9433",2
[test-utils] cleanup and improve method to set the environment- introduced parameter to update or overwrite the environment- make Windows-specific code explicit- avoid duplicate update of environment map,5
fix typo (#6644),2
KAFKA-8618: Replace Txn marker with automated protocol (#7039)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
[FLINK-16769][table] Use new type inference in Table.flatMap()This closes #16850.,5
[FLINK-7221] [jdbc] Throw exception if execution of last JDBC batch fails.This closes #4459.,0
[FLINK-17222][table-common] Ensure deterministic field order in FieldsDataTypeNew method DataType.getChildren() provides better guarantees.This closes #12121.,1
[FLINK-14913][table] refactor CatalogFunction to remove propertiesthis closes #10294.,4
[FLINK-24113] Add option to disable automatic shutdown in application mode,1
"[FLINK-7019] [gelly] Rework parallelism in Gelly algorithms and examplesFlink job parallelism is set with ExecutionConfig#setParallelism or with-p on the command-line. The Gelly algorithms JaccardIndex, AdamicAdar,TriangleListing, and ClusteringCoefficient have intermediate operatorswhich generate output quadratic in the size of input. These algorithmsmay need to be run with a high parallelism but doing so for alloperations is wasteful. Thus was introduced ""little parallelism"".This can be simplified by moving the parallelism parameter to the newcommon base class with the rule-of-thumb to use the algorithmparallelism for all normal (small output) operators. The asymptoticallylarge operators will default to the job parallelism, as will the defaultalgorithm parallelism.This closes #4282",1
"KAFKA-5362: Add EOS system tests for Streams APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3201 from mjsax/kafka-5362-add-eos-system-tests-for-streams-api",5
"MINOR: Ensure in-memory metadata is removed before physical deletion of segment (#7106)Minor refactoring of the places where we delete log segments, to ensure we always remove the in-memory metadata of the segment before performing physical deletion.Reviewers: Ismael Juma <ismael@juma.me.uk>, NIkhil Bhatia <rite2nikhil@gmail.com>, Jun Rao <junrao@gmail.com>",4
[FLINK-7] Prevent range partitioning inside iterations.,2
[FLINK-6247] [table] Put flink-table.jar with all dependencies into ./opt folder.This closes #3666.,2
"[FLINK-22227][clients] Log submitted job name, id and receiving jobmanager",2
KAFKA-2340: Improve KafkaConsumer Fetcher test coverageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #112 from hachikuji/KAFKA-2340 and squashes the following commits:cc49ca2 [Jason Gustafson] KAFKA-2340; improve KafkaConsumer Fetcher test coverage,3
"KAFKA-9439: add KafkaProducer API unit tests (#8174)Add unit tests for KafkaProducer.close(), KafkaProducer.abortTransaction(), and KafkaProducer.flush() in the KafkaProducerTest.Increase KafkaProducer test code coverage from 82% methods, 82% lines to 86% methods, 87% lines when being merged.Reviewers: Boyang Chen <boyang@confluent.io>",5
[streaming] improved threadsafe publishing,1
[FLINK-13028][table-api-java] Remove planner expression from ExpressionResolver,0
"KAFKA-6323: punctuate with WALL_CLOCK_TIME triggered immediately (#4301)This PR avoids unnecessary punctuation calls if punctuations are missed due to large time advances. It also aligns punctuation schedules to the epoch.Author: Frederic ArnoReviewers: Michal Borowiecki <michal.borowiecki@openbet.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
修改demogit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1049 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-8729][streaming] Refactor JSONGenerator to use jacksonThis closes #5554.,1
[FLINK-3005] [core] Bump commons-collections version to fix object deserialization remote command execution vulnerabilityThis closes #1381,0
Fix Dubbo-3990 #3990 (#5247),0
[hotfix][docs] Allow manual trigger for docs build,2
[scala] [streaming] Added scala window helpers + timestamp rework for lambda support,1
"kafka-1992; checkEnoughReplicasReachOffset doesn't need to get requiredAcks; patched by Gwen Shapira; reviewed by Jeff Holoman, Jiangjie Qin and Jun Rao",1
"[FLINK-8105] Remove ""unnecessary 'null' check before 'instanceof' expression""This closes #5034",4
[hotfix][tests] Simplify and harden CoordinatorEventsExactlyOnceITCase,3
[FLINK-14395] Refactor ES 7 connectors to make them keep consistency with es 6 connectors,1
[FLINK-17407] Introduce ExternalResourceDriver and ExternalResourceInfo interface.,5
"[FLINK-12250] Rewrite assembleNewPartPath to let it return a new PartPathWhile debugging some code, I've noticed assembleNewPartPath doesnot really return a new path. Also rewrote the code a bit so themutable inProgressPart is changed in a single place.",4
[FLINK-18700][debezium] Debezium-json format throws NPE when PG table's IDENTITY config is not FULLThis commit add documentation for this case and throws a guide message in the exception.This closes #13019,2
[FLINK-25289][tests] Introduce sink test suite in connector test frameworkThis closes #18496.,1
Make first 10 calls notify not delay (#8337),1
[FLINK-3750] [jdbcConnector] Refactor JdbcInputFormat and JdbcOutputFormat.- New Input- and OutputFormat use Row instead of Tuple types to support null values.- JdbcInputFormat supports parallel input due to PreparedStatement and binding values for parameters.This closes #1941,2
Triple support (#7087),1
[FLINK-14762][client] Implement JobClient#cancel,2
[hotfix][table-planner-blink] Fix aggregate test,3
"KAFKA-8677: Simplify the best-effort network client poll to never throw exception (#7613)Within KafkaConsumer.poll, we have an optimization to try to send the next fetch request before returning the data in order to pipelining the fetch requests; however, this pollNoWakeup should NOT throw any exceptions, since at this point the fetch position has been updated. If an exception is thrown and the callers decide to capture and continue, those records would never be returned again, causing data loss.Also fix the flaky test itself.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-4410] [runtime-web] Add detailed checkpoint stats handlers,0
KAFKA-9516; Increase timeout in testNonBlockingProducer to make it more reliable (#9181)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"[FLINK-2777] [docs] Fix Scala API description in programming_guide.htmldef createLocalEnvironment(parallelism: Int = Runtime.getRuntime.availableProcessors()))//issue1: In the end, there is a extra "")""def createRemoteEnvironment(host: String, port: String, jarFiles: String*)def createRemoteEnvironment(host: String, port: String, parallelism: Int, jarFiles: String*)//issue2: the parameter of port should be ""Int"", not ""String""This closes #1193",2
[FLINK-8332] [flip6] Move savepoint dispose into ClusterClientMove the savepoint disposal logic from the CliFrontend into the ClusterClient. This givesa better separation of concerns and allows the CliFrontend to be used with differentClusterClient implementations.This closes #5219.,1
[FLINK-15585][table-planner] Update plan testsThis closes #18352.,3
[FLINK-14733][runtime] Introduce a builder for flexible ResourceProfile building,2
[FLINK-25613][build] Sync surefire versions,2
"MINOR: Add DuplicateBrokerRegistrationException (#10029)Add DuplicateBrokerRegistrationException, as specified in KIP-631.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Merge branch 'compiler02' of https://dev.stratosphere.eu/git/fhueskeinto version02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/PactCompiler.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MatchNode.java,5
[FLINK-11843] Port DispatcherResourceCleanupTestPorts the DispatcherResourceCleanupTest to work with the new Dispatcher contract,1
Fix for loop reference test pass on protostuff (#3252),4
[hotfix][k8s] Add log4j1 configuration to JobManager and TaskManager start command,5
[FLINK-6811] [table] Add TIMESTAMPADD support in SQLThis closes #4076.,1
[FLINK-377] Generic Interface,2
"enhance bundled examples  (#3115)* move dubbo xml demo into delegated dir* add demo for annotation usage, and rename dubbo-demo-api to dubbo-demo-interface* add pure api demo* enhance examples* remove useless imports* add readme for dubbo-demo",1
[FLINK-18710] Make ResourceProfileInfo serializableThis closes #12991.,5
[FLINK-27317][build] Bump maven-source-plugin to 3.2.1,2
[hotfix] Make fields transient in TwoPhaseCommitSinkFunction,1
"MINOR: Switch to use AWS spot instancesPricing for m3.xlarge: On-Demand is at $0.266. Reserved is at about $0.16 (40% discount). And Spot is at $0.0627 (76% discount relative to On-Demand, or 60% discount relative to Reserved). Insignificant fluctuation in the past 3 months.Ran on branch builder and works as expected -- each worker is created using spot instances (https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1982/console)This can be safely backported to 0.10.2 (tested using https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1983/)Author: Max Zheng <maxzheng.os@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5707 from maxzheng/minor-switch@trunk",1
[FLINK-9730][refactor] Fix static accesses via instance referenceThis closes #6247.,0
"[FLINK-12918][table][hive] unify GenericCatalogTable, HiveCatalogTable and AbstractCatalogTable into CatalogTableImplThis PR unifies implementations of CatalogTable by combining GenericCatalogTable, HiveCatalogTable and AbstractCatalogTable into CatalogTableImpl.This closes #8815.",2
[hotfix][runtime] Adjust signatures of ComponentClosingUtils to use Duration rather than long milliseconds.This makes it more consistent with the effort to introduce type safe types and signatures for time.,1
[FLINK-9815][yarn][tests] Harden tests against slow job shutdownsThis closes #6352.,3
[hotfix][python] Remove unused classes RunnerInputType and RunnerOutputType,1
[hotfix] [tests] Tests in flink-tests suppress log output by default,2
changed recovery to recover from completed checkpoints,4
[hotfix][filesystems] Also mirroring s3.path-style-access.,5
[hotfix][checkstyle] Remove suppression for runtime/io.disk,1
[FLINK-10545] Remove JobManagerLeaderSessionIDITCase,4
"[FLINK-10537][network] Fix network small performance degradation after merging [FLINK-9913]Checks removed by this commit were performed once per every record, whileBefore [FLINK-9913] those checks were executed only once per""continue writing with new buffer"". Apparently those checks have some overheadonce per record while are helping to avoid the need to commit the data very rarelly.",5
[hotfix] remove useless code in PlannerBase,1
[hotfix][QS] Disable RocksDB ITCases.,5
[FLINK-13528][kafka] Disable sql tests failing on Java 11,0
[FLINK-11699] Use isEmpty() for address comparison in AbstractDispatcherResourceManagerComponentFactoryThis closes #7783.,1
[FLINK-6213] [yarn] terminate resource manager itself when shutting down applicationThis closes #3640.,2
[hotfix] [jobmanager] Cleanups in the ExecutionGraph  - Making fields final where possible  - Making fields volatile where needed or advisable  - Remove some dead code/functionality,1
"[FLINK-19388][coordination] Do not remove logical slots from SharedSlot if it is releasing`SharedSlot#release` releases all logical slots in a loop over their collection.The logical slot releases lead to their execution failures.This can cause cancellation of other executions sharing same slot.The execution failure can cause cancelation of other sharing executions by `Scheduler`.The canceled executions subsequently call `SharedSlot#returnLogicalSlot`which modifies the logical slot collection while it is being iterated in `SharedSlot#release`,if the canceled executions share the same slot. This leads to `ConcurrentModificationException`.To avoid the `ConcurrentModificationException`, the logical slot collection can be copied before iterating it.This closes #13511.",2
Mailing list link in README,2
[FLINK-17019][runtime] Fulfill slot requests in request orderThis is to avoid slot competitions between slot allocation bulks which can lead to resource deadlocks.,2
"MINOR: Fix --enable-autocommit flag in verifiable consumer (#7743)The --enable-autocommit argument is a flag. It does not take a parameter. This was broken in #7724.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
"KAFKA-3141: Add checks to catch invalid authorizer porpertiesSkip misformed properties instead of throwing ArrayIndexOutOfBoundsExceptionAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #806 from SinghAsDev/KAFKA-3141",1
Artificial commit to close pull requests.This closes #5This closes #6This closes #10This closes #12This closes #14,5
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 intodatamodelConflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/graph/EnumTriangles.java,5
metadata refactor,4
[hotfix] Fix minor IDE warnings in MemoryUtils,2
fixed wrong Schema used in LazyHeadArrayNodeTest,3
DUBBO-456 确保所有注册中心订阅RegistryService能返回注册中心本身的URL地址列表,1
MINOR: ignore wakeups when committing offsets on consumer closeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #306 from hachikuji/handle-wakeup-in-consumer-close,0
"KAFKA-7454: Use lazy allocation for SslTransportLayer buffers and null them on close (#5713)Lazy allocation helps when there are a large number of connectionsthat have been accepted, but where no data has been received fromthe clients. Each buffer is often around 16k (max TLS record size).Nulling the buffers should not make a difference in the currentimplementation since we release the reference to the channeland transport layer after we close them, but it's a good practiceto release medium/large buffers after `close` is called.Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"[FLINK-2753] [streaming] [api breaking] Add first parts of new window API for key grouped windowsThis follows the API design outlined in https://cwiki.apache.org/confluence/display/FLINK/Streams+and+Operations+on+StreamsThis is API breaking because it adds new generic type parameters to Java and Scala classes, breaking binary compatibility.",4
[hotfix][docs] Updata max parallelism behavior for Reactive Mode,5
kafka-1400; transient unit test failure in SocketServerTest; patched by Neha Narkhede; reviewed by Guozhang and Jun Rao,3
[FLINK-10136] [table] Add REPEAT function in Table API and SQLThis closes #6597.,1
[streaming] Added Flume connector and updated connectors,5
[FLINK-14854][client] Add executeAsync() method to execution environments,1
[FLINK-25631][table] Support enhanced `show tables` syntax (#18361),1
[hotfix][tests] Avoid hard-coded class name,3
KAFKA-4272; Add missing 'connect' Windows batch scriptsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2146 from vahidhashemian/KAFKA-4272,5
Next steps in optimizer refactoring.,4
[FLINK-9061] [s3] Make base S3 file system entropy injecting,5
[FLINK-9751] [filesystem] Add PersistentResumableWriter interface.,1
"KAFKA-7185: Allow empty resource name when matching ACLs (#5400)Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
Merge branch 'ringwald02' into annotation+newOptimizer,1
[FLINK-21410][docs] Document checkpoint interval trade-offsThis closes #14964,2
"MINOR: upgrade system test should check for ISR rejoin on each roll (#7827)The upgrade system test correctly rolls by upgrading the broker and leaving the IBP, and then rolling again with the latest IBP version.Unfortunately, this is not sufficient to pick up many problems in our IBPgating as we charge through the rolls and after the second roll all ofthe brokers will rejoin the ISR and the test will be treated as asuccess.This test adds two new checks:1. We wait for the ISR to stabilize for all partitions. This is bestpractice during rolls, and is enough to tell us if a broker hasn'trejoined after each roll.2. We check the broker logs for some common protocol errors. This is afail safe as it's possible for the test to be successful even if someprotocols are incompatible and the ISR is rejoined.Reviewers: Nikhil Bhatia <nikhil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[FLINK-7396] Fix don't put multiple directories in HADOOP_CONF_DIR in config.sh,5
[FLINK-15548][table-blink] Use KeyedCoProcessOperator instead of LegacyKeyedCoProcessOperator in blink plannerLegacyKeyedCoProcessOperator is deprected and should use KeyedCoProcessOperator instead.This closes #10827,1
"[hotfix] [tests] Harden JobManagerRegistrationTestThe problem is that we don't wait until the JobManager becomes the leader. Due to this,the sent RegisterTaskManager messages might get dropped.This PR fixes the problem by waiting on the completion of the NotifyWhenLeader message.",0
remove author (#10112),4
[FLINK-10780][tests] Update Java / Scala StatefulJobWBroadcastStateMigrationITCase for 1.7,5
Interface and compiler portion of range partitioning for data sinks.,5
删除空模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1659 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-8885] [TaskManager] DispatcherThreadFactory registers a fatal error exception handlerIn case dispatcher threads let an exception bubble out (do not handle the exception), theexception handler terminates the process, to ensure we don't leave broken processes.",0
"[FLINK-11449][table-common] Introduce a new expression stack and visitor interfaceThis commit adds a new expression stack that is:- located in flink-table-common- implemented in Java- decoupled from Calcite and other planner specifics- reduced to a minimum/basic set of functionalityFor now, conflicting class names are prefixes with ""Common"". Classes suchas ""CommonExpression"" will become ""Expression"" for backwards-compatibilityin later commits.",0
[FLINK-23735][connectors/kafka] Migrate BufferedUpsertSinkFunction to FLIP-143 Sink API,1
[streaming] using Sets for testing parallelism,3
"KAFKA-8985; Add flexible version support to inter-broker APIs (#7453)This patch adds flexible version support for the following inter-broker APIs: ControlledShutdown, LeaderAndIsr, UpdateMetadata, and StopReplica. Version checks have been removed from `getErrorResponse` methods since they were redundant given the checks in `AbstractRequest` and the respective`*Data` types.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
MINOR: Make TopicDescription's other constructor public (#7405)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
[FLINK-17232][k8s] Disable the implicit behavior to use the Service externalIP as the address of the Endpoint,1
Optimize Service related issues (#8122),0
"KAFKA-6292; Improve FileLogInputStream batch position checks to avoid type overflow (#4928)Switch from sum operations to subtraction to avoid type casting in checks and type overflow during `FlieLogInputStream` work, especially in cases where property `log.segment.bytes` was set close to the `Integer.MAX_VALUE` and used as a `position` inside `nextBatch()` function.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
add some AvailableClusterInvoker unit test (#8934),3
[FLINK-9517][docs] Fix broken links in CLI and Upgrade docsThis closes #6113.,2
[FLINK-9866] Allow passing command line arguments to standalone jobThis closes #6344,4
[client] Work around limitations of JDK 1.6 in InetSocketAddress,1
modify metadata node path in zookeeper (#3166)* modify metadata node path in zookeeper* add licence,1
[FLINK-13430][build] Configure sending travis build notifications to builds@flink.apache.orgThis closes #9230,2
"[FLINK-25282][table-planner][table-runtime] Move runtime code from table-planner to table-runtime- Removes the dependency on SqlFunctions from Calcite- Move DefaultWatermarkGeneratorSupplier to runtime and rename to GeneratedWatermarkGeneratorSupplier- Remove dependency on BuiltInMethod from Calcite for floor, ceil and abs- Copy from Calcite json functions in SqlJsonUtils. Now jackson and jsonpath are shipped by runtime.- Move various Flink functionsThis closes #18108.",1
[hotfix][table-api] Add literal conversions between all numeric types.,1
[FLINK-4090] Close of OutputStream should be in finally clauseThis closes #2132,1
fix bug of read config,5
Fix bug in tuple comparator (state)Rename UnilateralSortmerger -> ExternalSorter (part 1)Fix checkstyle warning.,2
[FLINK-8143][flip6] Migrate SubtaskMetricsHandler to new RestServerEndpointMigrate logic fromorg.apache.flink.runtime.rest.handler.legacy.metrics.SubtaskMetricsHandler tonew handler. Add new handler to DispatcherRestEndpoint.[FLINK-8143][flip6] Assert that SubtaskIndexPathParameter is mandatory[FLINK-8143][flip6] Use path parameter constants in SubtaskMetricsHandlerTestThis closes #5082.,3
"MINOR: bug fixes to ducktape servicesHere's a (mostly successful) run with these changes:http://testing.confluent.io/confluent-kafka-branch-builder-system-test-results/?prefix=2016-06-27--001.1467080884--alexlod--ducktape-fixes--ad85493/At least one of the failed tests is failing in trunk, too:http://testing.confluent.io/confluent-kafka-branch-builder-system-test-results/?prefix=2016-06-28--001.1467090978--alexlod--ducktape-fixes--ad85493/The contribution is my original work and I license the work to the project under the project's open source license.Author: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1566 from alexlod/ducktape-fixes",0
[FLINK-12253][table-common] Add a BOOLEAN type,1
[FLINK-24615][table] Add infrastructure to support metadata for filesystemSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17544.,2
[hotfix] Add missing TestLogger to Kinesis tests,3
"Dubbo cloud native (#4943)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4807 : Add sort implementation* Refactor* Refactor* Polish apache/dubbo#4845 : [Feature] Enhance the Event-Publishing feature to original ServiceDiscovery* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Polish apache/dubbo#4854 : [Feature] MetadataService supports the Dubbo protocol under auto-increased port* Polish apache/dubbo#4857 : [Enhancement] Sync the Metadata storage type into ApplicationConfig* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4873 : [Feature] Add a conditional EventListener into Event Module* Polish apache/dubbo#4875 : [Feature] Refactor ServiceInstancesChangedListener* Remove the cycle dependencies* Remove the cycle dependencies* Polish apache/dubbo#4903 : [Feature] Set source into the BeanDefinition of Dubbo Config* Polish apache/dubbo#4902 : [Feature] Dubbo Cloud Native to Spring XML scenario* Polish apache/dubbo#4713 : Initial the new module and dependencies* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4910 : [Feature] To suppoort DubboLifecycleComponentApplicationListener in Spring XML scenario* Polish apache/dubbo#4713 : Add Service discovery implementation for Eureka #4713* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4920 : [Refactor] Extract the common implementation for URLs' revision* Refactor* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Remove useless classes* Bugfix & Refactor ServiceDiscoveryRegistry* Polish apache/dubbo#4937 : The calculation of Revision should add the parameters of URL* Polish apache/dubbo#4940 : NacosDynamicConfiguration supports getConfigKeys method* Polish apache/dubbo#4942 : Dubbo Cloud Native supports multiple protcols",1
"[FLINK-6600] Add key serializer config snapshot to keyed backend checkpointsThis commit adds the config snapshot of the key serializer of keyedbackends to its checkpoints. This allows the oppurtunity to upgrade keyserializers, as well as state migration in the future in the case ofincompatible old and new key serializers.This closes #3925.",1
[hotfix][docs] Fix html tags in Batch API overview,0
[hotfix] Fix typo in comment of PojoTypeInfo,5
[streaming] Examples updated with CoFunctions,1
rename default to simplegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@274 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Temporarily made config keys public to make not adopted examples compile.,1
[3.0-Triple] use promise catch server send big header exception (#8774)* use promise catch server send big header exception* remove duplicate set server stream key,1
[FLINK-16102][docs-zh] Translate /dev/table/hive/scala_shell_hive.zh.md into ChineseThis closes #11590,1
[FLINK-3552] [examples] Add a properly windowed word count reading from a socket (Java + Scala),1
[FLINK-22560][build] Add dedicated name to flink-dist shade-plugin execution,2
KAFKA-229 Patch from Joe Stein. Log full exception stack trace instead of just message.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1226549 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-2071] [java api] Fix serializability issue with projectsion function.Improve type safety.Minor cleanups in ProjectOperator.,1
Added new histogram stub files,2
"KAFKA-5663; Pass non-null logDirFailureChannel to Log.applyAlso:- Improve logging- Remove dangerous default arguments in Log.apply- Improve naming of methods and fields in LogDirFailureChannel- Some clean-upsAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3594 from lindong28/KAFKA-5663",5
修改测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1954 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][tests] Reorder ConfigOptions in DataStreamAllroundTestJobFactoryReorder so that checkpoint-related ConfigOptions appear consecutively.,5
[FLINK-23621] Add InterruptedException to ProcessingTimeService#onProcessingTime,1
[FLINK-10431] Extract scheduling-related code from SlotPoolThis closes #7662.,4
[FLINK-10543][table] Leverage efficient timer deletion in relational operatorsThis closes #6918,1
"MINOR: Remove unused MessageWriter and CompressionFactoryAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2543 from hachikuji/remove-message-writer",4
"MINOR: Add Replication Quotas Test RigThis test rig lives in the other.kafka package so isn't part of our standard tests. It provides a convenient mechanism for measuring throttling performance over time. Measurements for each experiment are charted and presented to the user in an html file. The output looks like this:**Experiment4**- BrokerCount: 25- PartitionCount: 100- Throttle: 4,000,000 B/s- MsgCount: 1,000- MsgSize: 100,000- TargetBytesPerBrokerMB: 400![image](https://cloud.githubusercontent.com/assets/1297498/19070450/3251bc52-8a23-11e6-88fe-94de6b9147c2.png)![image](https://cloud.githubusercontent.com/assets/1297498/19070467/4c19f38e-8a23-11e6-986a-ba19d16819ca.png)Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1957 from benstopford/throttling-test-rig",3
Clean up for file line reader,2
Re-enabled extraction of nested jar files in PACT jobs,2
"[FLINK-5454] [docs] Add stub for docs on ""Tuning for large state""",2
[streaming] Major internal renaming and restructureCloses #594,5
Made the default location of jars configurable,5
fix meta service definition (#9540),5
"[docs] update ""build from source"" page",5
[hotfix][build] Remove reference to scala-2.11 profile,2
Rename some variables to avoid possible confusion between Result and AppResponse. (#3889)Clear that the `Result` of the call back is actually an `AppResponse`.,5
[hotfix] Introduce NewClusterClient interfaceThe NewClusterClient interface contains asynchronous submitJob and requestJobResultmethods which will replace the ClusterClient#submitJob method.,1
[FLINK-16995][table-common] Add new data structure interfaces in table-commonThis closes #11651,5
[FLINK-28793][sql-gateway][hive] Allow to GetInfo in the HiveServer2 EndpointThis closes #20444,5
"KAFKA-10006: Don't create internal topics when LeaderNotAvailableException (#8712)1. return the topicsNotReady to makeReady including tempUnknownTopics, and not create topic to wait for next retry2. tempUnknownTopics will be created each retry since we count the tempUnknownTopics as part of topicsNotReady3. add 2 more tests to total test 3 cases:  3.1 shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound  3.2 shouldCompleteValidateWhenTopicLeaderNotAvailableAndThenDescribeSuccess  3.3 shouldThrowExceptionWhenKeepsTopicLeaderNotAvailableReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
[FLINK-19603][network] Introduce shuffle data compression to sort-merge based blocking shuffleData will be compressed before spilled to disk and depressed at consumer side which can reducethe storage overhead and improve the disk/network IO performance.This closes #13595,1
[FLINK-1941] [gelly] [docs] added documentation for the Gather-Sum-Apply iterations in Gellyadded SSSP example for vertex-centric; added a comparison section for vertex-centric and GSAThis closes #722,1
3.0 serviceinfo equals (#7539),5
[Enhancement]: language level migration (#3485)* use java7 diamond operator* replace Collections.sort with List.sort* extract duplicated code blocks* use StandardCharsets.UTF_8* use try-with-resources* use java7 diamond operator* enhance log message* fix unit tests failures,0
KAFKA-5031; Follow-up with small cleanups/improvementsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3363 from hachikuji/KAFKA-5031-FOLLOWUP,5
[FLINK-17339][table-planner] Update test cases due to default planner change.,4
[FLINK-18912][python][docs] Add Python api tutorial under Python GettingStart (#13192),1
KAFKA-4161: KIP-89: Allow sink connectors to decouple flush and offset commitAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2139 from shikhar/kafka-4161-deux,5
[FLINK-10052][docs] Update ZooKeeper HA services documentation to include support for tolerating suspended connectionsThis closes #16801.,1
KAFKA-5355; DelayedFetch should propagate isolation level to log readTests will be added in a subsequent commit.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3221 from hachikuji/KAFKA-5355,5
KAFKA-12246: Remove redundant suppression in KafkaAdminClient (#9989)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
pull request#131: 修复isInvalidPort方法的逻辑问题,5
[FLINK-5207] [logging] Decrease HadoopFileSystem logging,2
[FLINK-2935] [scala-shell] Allow Scala shell to connect Flink cluster on YARN  - Remove duplicated parseHostPortAddress method (Move it to ClientUtils class)  - Refactor FlinkShell classThis closes #1500.,2
fix typo (#3110),2
MINOR: Updating comment that fell out of sync with codeAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #681 from gwenshap/minor-herder-comment,5
[FLINK-4848] [ssl] Throw meaningful exception when SSL is misconfiguredThis closes #3677.,5
curator client support multi address. (#7679),1
Implemented a workaround for nonfunctional Pact union,1
[FLINK-12618][build] Rework jdk.tools exclusionReplicate jdk.tools exclusion in every module that requires them.Remove exclusion from root pom to prevent side-effects.,4
[refactor][checkpoint] Use Clock instead of directly calling System.nanoTime around checkpoint barriers,5
[FLINK-9579][CEP]Remove unneeded clear on elementQueueStateThis closes #6162,4
modify ignore file,2
[FLINK-6228] [table] Add support for OVER windows to streaming Table API.This closes #3743.,1
[FLINK-14784][table] CsvTableSink miss delimiter when row start with null member.This closes #10199,2
"[FLINK-12509] [table-planner-blink] Introduce planner rules about non semi/anti join, which includes: 1. `JoinConditionEqualityTransferRule` that converts conditions to the left or right table's own independent filter as much as possible.2. `JoinConditionTypeCoerceRule` to that coerces the both sides of EQUALS(`=`) operator in Join condition to the same type while sans nullability.3. `JoinDependentConditionDerivationRule` that extracts some sub-conditions in the Join OR condition which can be pushed into join's inputs further by FlinkFilterJoinRule.4. `JoinDeriveNullFilterRule` that filters null values before join if the count of null value exceeds some threshold. This closes #8440",2
[FLINK-15085][hs] Simplify dashboard config generation,5
"KAFKA-13785: [8/N][emit final] time-ordered session store (#12127)Time ordered session store implementation. I introduced AbstractRocksDBTimeOrderedSegmentedBytesStore to make it generic for RocksDBTimeOrderedSessionSegmentedBytesStore and RocksDBTimeOrderedSegmentedBytesStore.A few minor follow-up changes:1. Avoid extra byte array allocation for fixed upper/lower range serialization.2. Rename some class names to be more consistent.Authored-by: Hao Li <1127478+lihaosky@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com.com>, John Roesler <vvcephei@apache.org>",1
[hotfix] [tests] Remove sysout logging in LargeRecordHandlerITCase,0
[FLINK-9241][metrics][docs] Fix ScalaGauge usage example,0
[hotfix][table] Move UnresolvedCallExpression & TableReferenceExpression to table-api-java module,0
[FLINK-9031] [optimizer] Fix DataSet Union operator translation bug.- Adds a pass over the pre-optimized plan that fixes the output strategy of union nodes to FORWARD.This closes #5742,0
DUBBO-970 增加category参数分类通知git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1490 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-13112][table-planner-blink] Support LocalZonedTimestampType in blink plannerThis closes #9036,2
[FLINK-6702] put the CEP tests' harness.close() calls into a finally blockThis closes #3978.,3
[FLINK-22477] Remove SlotPoolImpl,4
MINOR: KStreams SuppressionDurabilityIntegrationTest should set StreamsConfig.STATE_CONFIG_DIR. (#5870),5
"[FLINK-3201] Enhance Partitioned State Interface with State TypesAdd new state types ValueState, ListState and ReducingState, whereListState and ReducingState derive from interface MergingState.ValueState behaves exactly the same as OperatorState. MergingState is astateful list to which elements can be added and for which the elementsthat it contains can be obtained. If using a ListState the list ofelements is actually kept, for a ReducingState a reduce function is usedto combine all added elements into one. To create a ValueState the userpasses a ValueStateIdentifier toStreamingRuntimeContext.getPartitionedState() while they would pass aListStateIdentifier or ReducingStateIdentifier for the other statetypes.This change is necessary to give the system more information about thenature of the operator state. We want this to be able to do incrementalsnapshots. This would not be possible, for example, if the user had aList as a state. Inside OperatorState this list would be opaque andFlink could not create good incremental snapshots.This also refactors the StateBackend. Before, the logic for partitionedstate was spread out over StreamingRuntimeContext,AbstractStreamOperator and StateBackend. Now it is consolidated inStateBackend.This also adds support for partitioned state in two-input operators.",1
"[runtime] Fix scheduleOrUpdateConsumers logic for blocking resultsFor tasks producing mixed pipelined and blocking results, the scheduling ofreceivers could lead to deadlocks, because of missing notifications.This problem was discovered in the ALSITCase, where the iteration head isproducing pipelined results for the step function and blocking results forthe final results. The receivers of the final blocking result never gotnotified.This commit adds a separate test case to test the correct behaviour and revertsthe changes introduced in dafcd4e to force pipelining in ALSITCase.",5
"KAFKA-9972: Only commit tasks with valid states (#8632)We spotted a case in the soak test where a standby task could be in CREATED state during commit, which causes an illegal state exception. To prevent this from happening, the solution is to always enforce a state check.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-13063: Make DescribeConsumerGroupsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11022)This patch improve the error handling in `DescribeConsumerGroupsHandler` and ensure that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.Reviewers: David Jacot <djacot@confluent.io>,5
"[FLINK-9809] [DataSteam API] Allow setting co-location constraints on StreamTransformations.This feature is currently only exposed on StreamTransformations (internal API) ratherthan in the public API, because it is a hidden expert feature.This closes #6309",1
"MINOR: Document endpoints for connector topic tracking (KIP-558)Update the site documentation to include the endpoints introduced with KIP-558 and a short paragraph on how this feature is used in Connect.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Toby Drake <tobydrake7@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #8148 from kkonstantine/kip-558-docs",2
[FLINK-1586] [streaming] Add support for iterative streaming graphs on JSON generationCloses #432,5
"MINOR: Clean up AlterIsrManager code (#11832)Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[hotfix] [tests] Remove redundant test assertionsThese seem to be remainders of a copy/paste error.,0
kafka-1673; potential java.lang.IllegalStateException in BufferPool.allocate(); patched by Jun Rao; reviewed by Jay Kreps,5
MINOR: Exclude junit 3 transitive dependency from jfreechart (#9928)This was causing IntelliJ to choose the Vintage runner when running `core` testswhich would then fail during the discovery phase.Verified that `core` tests work in IntelliJ again after this change.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
[FLINK-14195] Add jaxb dependency and do relocation for java 11 in s3.,1
Added signatures and factories for custom deserializers.,1
[3.0] Fix CountDownLatch not being released(#8845) (#8878),0
[hotfix][docs] Fix typosThis closes #5406.,2
[FLINK-21697][table-planner-blink] Support StreamExecMiniBatchAssigner json serialization/deserializationThis closes #15164,5
[FLINK-24562][yarn][test] YarnResourceManagerDriverTest should not use ContainerStatusPBImpl.newInstanceThis closes #17496,1
[FLINK-12357][table-api-java] Remove useless code in TableConfigThis closes #8301.,5
[hotfix][streaming-java] Allow .returns() on window functions,1
[hotfix] [streaming] Remove unused code fragment from DataStream.union() function.,1
[FLINK-14601] [client] CLI documentation for list is missing '-a',2
"[FLINK-2371] improve AccumulatorLiveITCaseInstead of using Thread.sleep() to synchronize the checks of theaccumulator values, we rely on message passing here to synchronize thetask process.Therefore, we let the task process signal to the task manager that ithas updated its accumulator values. The task manager lets the jobmanager know and sends out the heartbeat which contains theaccumulators. When the job manager receives the accumulators and hasbeen notified previously, it sends a message to the subscribed test casewith the current accumulators.This assures that all processes are always synchronized correctly and wecan verify the live accumulator results correctly.In the course of rewriting the test, I had to change two things in theimplementation:a) User accumulators are now immediately serialized as well. Otherwise,Akka does not serialize in local one VM setups and passes the liveaccumulator map through.b) The asynchronous update of the accumulators is disabled fortests (via the dispatcher flag of the TestingCluster). This wasnecessary because we cannot guarantee when the Future for updating theaccumulators is executed. In real setups this is neglectable.This closes #925.",1
KAFKA-4140: Upgrade to ducktape 0.6.0 and make system tests parallel friendlyUpdates to take advantage of soon-to-be-released ducktape features.Author: Geoff Anderson <geoff@confluent.io>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1834 from granders/systest-parallel-friendly,5
[hotfix][test] Clean up unnecessary type argument declarations in ClassLoaderITCase,4
"Revert ""[FLINK-16276][tests] Introduce a builder and factory methods to create DefaultScheduler for testing""This reverts commit bd757cb2a29cc2d9046d39aee9684d5b2e5ec036.",4
Fixed some bugs in nephele-common as reported by FindBugs,5
MINOR: Add documentation for KAFKA-6086 (ProductionExceptionHandler) (#4395)* Update streams documentation to describe production exception handler* Add a mention of the ProductionExceptionHandler in the upgrade guide,0
DUBBO-91 修改启动脚本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@397 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-23617][datastream] Clarify Sink usage and allow Sink to explicitly list compatible states.Currently, FileSink is able to read state from StreamingFileSink for a drop-in replacement but it's hard-coded in SinkTransformTranslator. In fact, all sinks effectively claim that they can read old StreamingFileSink state.This abstraction will be used in later commits by the newly introduced SinkWriterStateHandler during recovery.",0
DUBBO-211 读取jvalidation参数git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1175 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][doc] remove two obsolete Hive doc files,2
"MINOR: Reduce required occurrance from 100 to 10 (#5048)Due to #4644 the consumer connector logs will be much more clean with fewer ""broker may not be available"" entries. We need to reduce the required frequency from 100 to a smaller number.I've thought about reducing to just 1, but it may still be transient (i.e. even if broker is starting up you may see a few entries) so I reduced it to 10.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-14711][table] add alter and show function ddlthis closes #10231.,1
[hotfix] Add relativePath to flink-tpch-tests module,3
[FLINK-27125][tests] Fix ExecutorService leaks,0
[FLINK-16606][python] Throw exceptions for the data types which are not currently supported,1
[FLINK-13952][table-planner][hive] PartitionableTableSink can not work with OverwritableTableSinkTo support insert overwrite partition.This closes #9615.,1
"KAFKA-13498: track position in remaining state stores (#11541)Reviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, John Roesler<vvcephei@apache.org>",5
[FLINK-4795] [py] Fix CsvStringify for nested tuples,0
[FLINK-18286] Fix type inference for GET & AT Calcite functionsThis commit fixes how Calcite infers/derives types for accessing nested columns of a ROW type.,5
[build tools] Improve release scripts,1
Merge branch 'stage1_version02' into streamingConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/execution/Environment.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/InputGate.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/Task.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/AbstractPactTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSourceTask.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/TaskTestBase.java,5
"[FLINK-4326] [scripts] Flink foreground servicesAdd a ""start-foreground"" option to the Flink service scripts which doesnot daemonize the service nor redirect output.This closes #3492.This closes #3351.",2
KAFKA-6049: Add session window support for cogroup (#7782)Follow up to PR #7538 (KIP-150)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Add log entry for KafkaException in StreamThread#runLoop (#6144)I've observed several reports of sudden unexpected streamthread shutdown with the log entry like:State transition from PENDING_SHUTDOWN to DEADbut there is no related error logs before this line at all. I suspect this is because we intentionally do not log for KafkaException and there's some edge cases where we miss internally and hence caused this. I'm adding the ERROR level log entry here in order to reveal more information in case I saw this again in the future.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[hotfix] UNKNOWN ResourceSpec should not be numerically compared.,0
[FLINK-28941][Runtime/Checkpointing] Add concurrent checkpoint support in Operator CoordinatorThis closes #20752.,1
[FLINK-13973][runtime][checkpoint] Fix the state assignments if uidHash is setThis closes #16836.,1
[FLINK-9885] [tests] Add Elasticsearch 6.x end-to-end test,3
"MINOR: Logging improvements in consumer internalsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar reddy O <manikumar.reddy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2469 from hachikuji/improve-consumer-logging",2
Add integration testcase for testing RegistryProtocol and ServiceDiscoveryRegistry (#8278)Checks if ServiceDiscoveryRegistry works well using reflection,1
"[FLINK-4728] [core,optimizer] Replace reference equality with object equalitySome cases of testing Integer equality using == rather thanInteger.equals(Integer), and some additional cleanup.This closes #2582",4
"MINOR: system test clean up (#7552)Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>,",5
"MINOR: Update Connect error message to point to the correct config validation REST endpoint (#7991)When incorrect connector configuration is detected, the returned exception message suggests to check the connector's configuration against the `{connectorType}/config/validate` endpoint. Changing the error message to refer to the exact REST endpoint which is `/connector-plugins/{connectorType}/config/validate` This aligns the exception message with the documentation at: https://kafka.apache.org/documentation/#connect_rest Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
[FLINK-17004] Document the LIKE clause of CREATE TABLE statement.This closes #12075,1
"Merge pull request #3143 from beiwei30:prefix, fix prefix, use hypher case instead of camel case.",1
[FLINK-11653][DataStream] Add configuration to enforce custom UIDs on datastream,5
Added test case for bulk iteration with static input and delta iteration with static input,3
"MINOR: KIP-211 Follow-up (#5272)Updates the description of `offsets.retention.minutes` config, and fixes an upgrade note.",0
[hotfix] [gelly] Explicit type can be replaced with <>In Java 8 the diamond operator can be used in cases which would resultin an error in Java 7. In Gelly we have often desired to use the diamondoperator and only discovered an issue when running tests on TravisCI.This closes #4457.,3
[FLINK-1677] [gelly] Simple improvements to DegreesWithExceptionITCase.,1
[hotfix][table-planner] Add FlinkContext.getClassLoader,2
"[FLINK-19358][runtime] Make the job id distinct in application mode when HA is enabled.Previously, the job id will be set to zero in application mode when HA is enabled and the job id is not configured by user.This commit makes the job id distinct across different jobs in such case, which allows HistoryServer to distinguish it.This closes #20042.",1
[hotfix][docs][connectors] Improve SQL connectors documentation,2
[hotfix][testutil] Add test utilization for listening metric registration,3
"[FLINK-14346] [serialization] faster implementation of StringValue writeString and readString (#10358)This PR implements a set of performance optimizations for String serialization and de-serialization. While running a set of state-heavy streaming jobs, we noticed that Flink spends quite a lot of CPU time (~30-40%) doing String encoding and decoding in two places: while transferring messages between the nodes, and while loading and writing objects into the state store.this PR:Benchmark                                 (lengthStr)   (type)   Mode  Cnt    Score     Error   UnitsStringSerializationBenchmark.stringRead          1024    ascii  thrpt   30  769.067 ±   9.803  ops/msStringSerializationBenchmark.stringRead          1024  chinese  thrpt   30  260.280 ±   0.768  ops/msStringSerializationBenchmark.stringRead         16384    ascii  thrpt   30   53.418 ±   0.589  ops/msStringSerializationBenchmark.stringRead         16384  chinese  thrpt   30   17.313 ±   0.126  ops/msStringSerializationBenchmark.stringWrite         1024    ascii  thrpt   30  771.981 ± 160.013  ops/msStringSerializationBenchmark.stringWrite         1024  chinese  thrpt   30  250.321 ±   0.953  ops/msStringSerializationBenchmark.stringWrite        16384    ascii  thrpt   30   26.593 ±   0.099  ops/msStringSerializationBenchmark.stringWrite        16384  chinese  thrpt   30   13.487 ±   1.534  ops/msmaster:Benchmark                                 (lengthStr)   (type)   Mode  Cnt    Score   Error   UnitsStringSerializationBenchmark.stringRead          1024    ascii  thrpt   30   70.249 ± 0.458  ops/msStringSerializationBenchmark.stringRead          1024  chinese  thrpt   30   24.181 ± 0.094  ops/msStringSerializationBenchmark.stringRead         16384    ascii  thrpt   30    4.382 ± 0.024  ops/msStringSerializationBenchmark.stringRead         16384  chinese  thrpt   30    1.515 ± 0.007  ops/msStringSerializationBenchmark.stringWrite         1024    ascii  thrpt   30  175.745 ± 1.416  ops/msStringSerializationBenchmark.stringWrite         1024  chinese  thrpt   30   45.952 ± 5.209  ops/msStringSerializationBenchmark.stringWrite        16384    ascii  thrpt   30    7.062 ± 0.042  ops/msStringSerializationBenchmark.stringWrite        16384  chinese  thrpt   30    2.527 ± 0.015  ops/ms",0
[tests] Fix hostname escaping for older akka versions.,0
Extended debugging output in ByteBufferedChannelManager,0
[FLINK-1056] Use maven-assembly to build fat-jar in quickstartsAlso update documentation accordingly.,2
"MINOR: Remove checking on original joined subscription within handleAssignmentMismatch (#6782)When consumer coordinator realize the subscription may have changed, today we check again against the joinedSubscription within handleAssignmentMismatch. This checking however is a bit fishy and over-kill as well. It's better just simplifying it to always request re-join.The joinedSubscription object itself however still need to be maintained for potential augment to avoid extra re-joining the group.Since testOutdatedCoordinatorAssignment already cover the normal case we also remove the other invalidAssignment test case.Reviewers: Jason Gustafson <jason@confluent.io>",5
[FLINK-11328] [core] Upgrade parameterless / singleton serializers to use new serialization compatibility APIs,1
Replication properties are not pushed down.,5
"[FLINK-15121] Add public constructors for execution environments that take ConfigurationThis makes useful constructors on ExecutionEnvironment public and addsJavadoc.This makes the useless zero-argument constructor ofStreamExecutionEnvironment protected and adds Javadoc toStreamExecutionEnvironment constructors.This allows creating execution environments with arbitrary executorconfigurations, i.e. one can now create an execution environment thatuses a YARN executor.",1
"MINOR: Follow-up Streams doc changes to break into sub-pagesAlso fixed a bunch of broken links (details can be found in https://github.com/apache/kafka-site/commit/34f8ecea0db15523ce4b81e6b6bc4c5c2fabd603)Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3473 from guozhangwang/KMinor-streams-doc-breakdown",4
[hotfix] Remove unused JobMasterGateway#requestClassloadingProps,1
KAFKA-6729: Follow up; disable logging for source KTable. (#5038)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-5895: Gradle 3.0+ is needed on the build (#3861)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
[FLINK-18809][table-planner-blink] Update ListAggFunctions,1
[hotfix] [docs] Add a rouch description about internal types of states and state backends,1
"[hotfix][network] ensure deserialization buffer capacity for the whole record lengthOnce we know the record length and if we are not spilling, we should size thebuffer immediately to the expected record size, and not incrementally for eachreceived buffer chunk.",0
增加测试模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1641 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-6435] [async] React to exceptionally completed StreamElementQueueEntryThe AsyncWaitOperator should not only react to orderly completedStreamElementQueueEntries but also to those completed with a user exceptionor those which timed out.This PR fixes the problem by calling the onComplete function passed toStreamElementQueueEntry#onComplete also in the exceptional case.This closes #3814.,1
Added README,1
"KAFKA-9559 add docs for changing default serde to null (#10988)#10813 changed the default serde from ByteArraySerde as discussed in KIP-741. This adds proper documentation so users know to set a serde through the configs or explicitly pass one in.Reviewers: Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
KAFKA-6145: KIP 441 remove balance factor (#8597)Reviewers: John Roesler <vvcephei@apache.org>,4
remove not used import (#3309),2
"[hotfix] Reduce logging verbosity from the checkpoint-related REST handlersBefore the change, everytime the REST UI tried to access the checkpointing statistics, an ERROR message was logged.When using a BATCH job, this leads to log files looking like this:2020-11-13 15:27:38,785 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,788 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,788 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.2020-11-13 15:27:38,793 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.2020-11-13 15:27:38,793 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,797 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.2020-11-13 15:27:38,797 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,802 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.With this change, these log messages are surpressed.",2
"KAFKA-3587; LogCleaner fails due to incorrect offset map computationRemoved the over pessimistic require and instead attempt to fill the dedup buffer. Use the (only) map until full;this may allow to process all dirty segment (optimism) or may happen in the middle of a dirt segment.In either case, do compaction using the map loaded that way.This patch was developed with edoardocomarAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1332 from mimaison/KAFKA-3587",2
DUBBO-300 修改Activate注解git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1683 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][core] Extend JavaDocs for ExternallyInducedSourceReader.,2
MINOR: fix indention in <pre> tagsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2553 from mjsax/hotfixDocs2,2
[hotfix] Encapsulate async exception handling into StreamTask#StreamTaskAsyncExceptionHandler,0
Removing RpcContext after test finishes. (#6314),5
[hotfix] Refactor NeverCompleteFuture into a reusable utility,4
[FLINK-21203][table-planner-blink] Prevent emission of identical update records in LastRowFunctionThis closes #14863,1
Add profile for distribution module,2
Fix bug for tuple size greater than 22,0
[hotfix][runtime] Narrow down the access scope of SlotExecutionVertexAssignment,0
[FLINK-27611][Connector/pulsar] Fix ConcurrentModificationException during checkpoint on Pulsar unordered reader.,0
"MINOR: fix ClusterControlManager log message (#11358)Fix a ClusterControlManager log message that should have distinguished betweennewly registered and re-registered brokers, but did not due to a bug.Reviewers: Ismael Juma <ismael@juma.me.uk>, José Armando García Sancio <jsancio@gmail.com>",0
[FLINK-24199][python] Expose StreamExecutionEnvironment#configure in Python APIThis closes #17206.,5
"Fix perf regression on LISR requests by asynchronously flushing the partition.metadata file (#11056)After noticing increased LISR times, we discovered a lot of time was spent synchronously flushing the partition metadata file. This PR changes the code so we asynchronously flush the files.We ensure files are flushed before appending, renaming or closing the log to ensure we have the partition metadata information on disk. Three new tests have been added to address these cases.Reviewers:  Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",5
[FLINK-11744][core]Provide stable/final toHexString-method in AbstractIDThis closes #7825.,2
Improve exception messages for file output format when target file cannot be created.,1
"[DUBBO-2489] MockClusterInvoker provides local forced mock，I tested it locally, but it doesn't work (#2742)",1
[FLINK-13225][table-planner-blink] Fix type inference for hive udaf,5
Fix Triple Classloader & Add backward of ServiceMetadata (#8800),5
[FLINK-10419] Using DeclineCheckpoint message class when invoking RPC declineCheckpoint,1
DUBBO-73 shutdownnow 需要循环关闭，确定线程能够确保退出git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@511 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-4127] Check API compatbility for 1.1 in flink-coreThis closes #2177,2
[hotfix][runtime] MockStreamTask gracefully stops mailbox processor.MockStreamTask cannot call close on mailbox processor as we cannotassume that #cleanup is called from mailbox thread. Using a gracefultermination allows the stream task and any using test harness to beclosed from another thread for failure simulation.,0
"[FLINK-9373][statebackend] Introduce RocksIteratorWrapper to wrap `Seek(), Next(), SeekToFirst(), SeekToLast(), SeekForPrev(), and Prev()` to check the iterator status.This closes #6020.",2
Merge nephel2 v2 changes with pact changes.Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
[FLINK-22534][runtime][yarn] Set delegation token's service name as credential aliasThis closes #15810,1
[docs] Update readme with current feature list and streaming example,5
[hotfix] Pass in Rest address to Dispatcher as nullable String,1
[FLINK-14701][runtime] Fix MultiTaskSlot to not remove slots which are not its childrenThis closes #10867.,4
[FLINK-10169] [table] Fix error in RowtimeValidator when getting custom TimestampExtractorThis closes #6575.,4
[minor] Add debug logging if aws cli command failsThe motivation is to help debugging FLINK-15772.,2
KAFKA-3431: Remove `o.a.k.common.BrokerEndPoint` in favour of `Node`Also included a minor efficiency improvement in kafka.cluster.EndPoint.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1105 from ijuma/kafka-3431-replace-broker-end-point-with-node,1
[FLINK-5452] [table] Fix SortITCase which fails under cluster mode.This closes #3095.,0
[FLINK-13904][checkpointing] Remove trigger lock of CheckpointCoordinatorNow the checkpoint and savepoint triggering are executed in the one thread without any competition.So the triggerLock is no longer needed.,4
MINOR: Remove `InvalidReceiveException` catch in `SocketServer``Selector.poll` no longer throws it.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #506 from ijuma/poll-no-longer-throws-invalid-receive-exception,4
[FLINK-24635][examples] Fix deprecations in changelog socket example,4
[FLINK-23504][tests] Isolate TestingRpcService from Akka,3
[streaming] IterateTest refactor,4
[FLINK-7445] [GitHub] Remove FLINK-1234 reference from PR templateThis closes #4542.,2
[hotfix][docs] Improve Kafka exactly-once docs,2
Merge pull request #874 from vasia/fix_min_aggr_tostringFixes toString return value of MinAggregationFunction,1
[FLINK-17432][docs-training] Rename Tutorials to Training for better SEO (#11931)[FLINK-17432][docs-training] Rename Tutorials to Training for better SEO,1
"KAFKA-8122: Fix Kafka Streams EOS integration test (#7470)Reviewers: Guozhang Wang <guozhang@confluent.io>, Chris Pettitt <cpettitt@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-12248][table-planner-blink] Support e2e over window in blink batch (#8206),2
"KAFKA-5747; Producer snapshot loading should cover schema errorsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3688 from hachikuji/KAFKA-5747",5
MINOR: Fix inconsistency in StopReplica/LeaderAndIsr error countsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4147 from hachikuji/fix-error-inconsistencies,0
[FLINK-17342][checkpointing][hotfix] Synchronize access to CheckpointCoordinator.pendingCheckpoints,2
[streaming] Fixed BatchTest,3
[hotfix] Introduces public constants for file extension,2
"Merge pull request #1236, fix typo in FailbackRegistry.",0
"[FLINK-12642][network][metrics] Fix In/OutputBufferPoolUsageGauge failure with NPEThe result partition metrics are initialised before `ResultPartitiion#setup` was called. If a reporter tries to access a In/OutputBufferPoolUsageGauge in between it will fail with an `NullPointerException` since the `BufferPool` of the partition is still `null`. Currently, the quick fix is to return zero metrics until the `BufferPool` is initialised. When we have a single-threaded access from `Task#run`, we can merge partition/gate create and setup then it should not be the case anymore.",1
[FLINK-10397] Remove CoreOptions#MODERemoves the MODE option used to switch between the new and legacy mode.This closes #6752.,1
[FLINK-3899] [docs] Add examples for incremental window computation.This closes #2368,1
[FLINK-13322][table-runtime-blink] Fix serializer snapshot recovery in BaseArray and BaseMap serializers,0
[FLINK-1201] [gelly] reduceOnNeighbors with vertex value,2
[FLINK-25430][runtime] Renames JobGraphStoreFactory into JobPersistenceComponentFactorySeparate commit to prepare the further JobResultStoreintegration. JobGraphStoreFactory becomesJobPersistenceComponentFactory because we want tointegrate the initialization analogously to how theJobGraphStore initialization is integrated.,5
"KAFKA-4602; KIP-72 - Allow putting a bound on memory consumed by Incoming requeststhis is the initial implementation.Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>Closes #2330 from radai-rosenblatt/broker-memory-pool-with-muting",5
[FLINK-13121][table-planner-blink] Set properties to StreamGraph in blink executorThis closes #9057,2
[FLINK-3341] Make 'auto.offset.reset' compatible with Kafka 0.8 and 0.9This closes #1597,1
"KAFKA-8995: delete all topics before recreating (#8208)I think the root cause of KAFKA-8893, KAFKA-8894, KAFKA-8895 and KSTREAMS-3779 are the same: some intermediate topics are not deleted in the setup logic before recreating the user topics, which could cause the waitForDeletion (that check exact match of all existing topics) to fail, and also could cause more records to be returned because of the intermediate topics that are not deleted from the previous test case.Also inspired by https://github.com/apache/kafka/pull/5418/files I used a longer timeout (120 secs) for deleting all topics.Reviewers: John Roesler <vvcephei@apache.org>",4
[FLINK-23561][yarn]Detail the container completed messageUpdate flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManagerDriver.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>Update flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManagerDriver.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>Update flink-yarn/src/test/java/org/apache/flink/yarn/YarnResourceManagerDriverTest.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>[FLINK-23561][yarn]Detail the container completed message[FLINK-23561][yarn]Detail the container completed messageUpdate flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManagerDriver.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>[FLINK-23561][tests] Fix word spell error[FLINK-23561][yarn] Detail the container completed message,2
[hotfix][docs] Skip QA plugins for scala docs,2
Add provided-by paramater for DubboReference (#7190),2
KAFKA-9707: Fix InsertField.Key should apply to keys of tombstone records (#8280)* KAFKA-9707: Fix InsertField.Key not applying to tombstone events* Fix typo that hardcoded .value() instead of abstract operatingValue* Add test for Key transform that was previously not testedSigned-off-by: Greg Harris <gregh@confluent.io>* Add null value assertion to tombstone test* Remove mis-named function and add test for passing-through a null-keyed record.Signed-off-by: Greg Harris <gregh@confluent.io>* Simplify unchanged record assertionSigned-off-by: Greg Harris <gregh@confluent.io>* Replace assertEquals with assertSameSigned-off-by: Greg Harris <gregh@confluent.io>* Fix checkstyleTest indent issueSigned-off-by: Greg Harris <gregh@confluent.io>,5
"KAFKA-8729, pt 2: Add error_records and error_message to PartitionResponse (#7150)As noted in the KIP-467, the updated ProduceResponse is```Produce Response (Version: 8) => [responses] throttle_time_ms  responses => topic [partition_responses]    topic => STRING    partition_responses => partition error_code base_offset log_append_time log_start_offset      partition => INT32      error_code => INT16      base_offset => INT64      log_append_time => INT64      log_start_offset => INT64      error_records => [INT32]         // new field, encodes the relative offset of the records that caused error      error_message => STRING          // new field, encodes the error message that client can use to log itself    throttle_time_ms => INT32with a new error code:```INVALID_RECORD(86, ""Some record has failed the validation on broker and hence be rejected."", InvalidRecordException::new);Reviewers: Jason Gustafson <jason@confluent.io>, Magnus Edenhill <magnus@edenhill.se>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2332; Add quota metrics to old producer and consumerAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #176 from lindong28/KAFKA-2332",2
KAFKA-8030: Fix flaky tests in TopicCommandWithAdminClientTestThis change adds waits for metadata updates after killing the broker in order to make the tests more stable.Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6505 from viktorsomogyi/flaky-min-isr-test,3
[hotfix] [tests] Fix failing Scala StatefulJobSavepointMigrationITCase,0
"[FLINK-16921][e2e] Set service exposed type to NodePort explicitlyIn FLINK-16598, we change the behavior about how to get the rest port, it will make the e2e test failed when setting service exposed type to LoadBalancer.",5
[FLINK-27122] Remove FutureUtils#retryWithDelay variants without RetryStrategy,1
"[hotfix][doc] Fix default format in document for temporal function FROM_UNIXTIME(numeric, format)This closes #14617",1
Remove unused imports (#4443),2
[hotfix][tests] Remove mocking from ResourceManagerJobMasterTest,3
[FLINK-25313][connector-elasticsearch] Remove legacy Elasticseach connectorUse the new connector via option 'connector' = 'elasticsearch-7'.,1
"[FLINK-12201][network,metrics] Introduce InputGateWithMetrics in Task to increment numBytesIn metricIncrementing of numBytesIn metric in SingleInputGate does not depend on shuffle service and can be moved out of networkinternals into Task. Task could wrap InputGate provided by ShuffleService with InputGateWithMetrics which would incrementnumBytesIn metric.",1
[refactor][runtime] Extend AkkaRpcServiceUtils to support instantiating custom AkkaRpcServices.,1
[FLINK-24887][rest] Add CompletedOperationCache#containsOperation,1
Switched order of parameters in ReduceContract,2
[FLINK-18658][tests] Forward RpcServiceSharing setting,1
"MINOR: Added to .gitignore Kafka server logs directoryWhen running Kafka server from sources, logs directory gets created in root of repository, and kafka server logs end up there. Currently that directory is not ignored by git.This change adds root logs directory to .gitignore so that Kafka server logs are ignored and do not get tracked by git.Author: Stevo Slavić <sslavic@gmail.com>Reviewers: Ismael JumaCloses #94 from sslavic/patch-7 and squashes the following commits:c7b62a7 [Stevo Slavić] MINOR: Added to .gitignore Kafka server logs",2
"KAFKA-10272: Add IBM i support to ""stop"" scripts (#9023)Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
[FLINK-5066] [network] Add EventSerializer.isEventThis allows PartitionRequestQueue to peak into event buffers instead of de-serializing the full event class.This closes #2806.,1
"KAFKA-5179; Log connection termination during authenticationAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma, Jun RaoCloses #2980 from rajinisivaram/KAFKA-5179",5
[FLINK-12664][hive] Implement TableSink to write Hive tablesThis PR creates HiveTableSink to write Hive tables.This closes #8766.,1
[FLINK-1207] Context environments are realized through factories  - local execution blocking is reset after each run,1
Removed old dependencies.,4
"KAFKA-6936: Implicit materialized for aggregate, count and reduce (#5066)In #4919 we propagate the SerDes for each of these aggregation operators.As @guozhangwang mentioned in that PR:```reduce: inherit the key and value serdes from the parent XXImpl class.count: inherit the key serdes, enforce setting the Serdes.Long() for value serdes.aggregate: inherit the key serdes, do not set for value serdes internally.```Although it's all good for reduce and count, it is quiet unsafe to have aggregate without Materialized given. In fact I don't see why we would not give a Materialized for the aggregate since the result type will always be different (otherwise use reduce) and also the value Serde is simply not propagated.This has been discussed previously in a broader PR before but I believe for aggregate we could pass implicitly a Materialized the same way we pass a Joined, just to avoid the stupid case. Then if the user wants to specialize, he can give his own Materialized.Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-8475][config][docs] Integrate akka optionsThis closes #5384.,5
[hotfix][travis] Move docker wordcount to nightly tests,3
Minor consistency cleanups in CsvOutputFormat,4
[hotfix][docs] Fix JavaDocs typos in Task class.This closes #8025.,2
DUBBO-97  事件(例如heartbeat)运行在业务线程池git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@426 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Added menu to visualization and removed automatic logging of buffer utilization,2
DUBBO-192 修改JSONgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@871 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"Merge pull request #2130, enable checkstyle and rat plugin in travis.Fixes #2129",0
[FLINK-18045] Fix Kerberos credentials checkingThis closes #12462.,0
[FLINK-23150][table-planner] Remove the old code split implementationThis closes #16460,4
[FLINK-1201] [gelly] key and value types shouldn't be static fields; fixed #42,0
[FLINK-18492][python] Extract the Beam specific operation classes into a separate Python moduleThis closes #12903.,4
[hotfix][sqlclient][docs] Improved sql client docs (#18855),2
[streaming] StateHandleProvider added for configurable state backend,5
[FLINK-14588][hive] Support Hive version 1.0.0 and 1.0.1To support Hive 1.0.0 and 1.0.1.This closes #10062.,1
"KAFKA-7051: Improve the efficiency of ReplicaManager (#5206)Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>",1
"Completed, updated, and improved JavaDocs of Java API",2
[FLINK-4115] Skip filesystem checks for filesystems with no built-in support,1
[FLINK-1168] Add support for multi-char field delimiters in CSVInputFormats.This commit includes parts of Cbro's pull request and subsumes PR #247This closes #247This closes #264,1
MINOR: Use static imports in KafkaLog4jAppenderInstead of redefining the constants.Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3349 from Kamal15/log4j2,2
"MINOR: Remove spammy, unhelpful log message in the controller (#7879)This patch removes a spammy log message in the controller which is printed every time the leader imbalance ratio is checked. It is unhelpful because preferred leaders are generally deterministic and is spammy because it includes _every_ partition in the cluster.Reviewers: Jonathan Santilli <jonathansantilli@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
"Dubbo cloud native (#4922)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4807 : Add sort implementation* Refactor* Refactor* Polish apache/dubbo#4845 : [Feature] Enhance the Event-Publishing feature to original ServiceDiscovery* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Polish apache/dubbo#4854 : [Feature] MetadataService supports the Dubbo protocol under auto-increased port* Polish apache/dubbo#4857 : [Enhancement] Sync the Metadata storage type into ApplicationConfig* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4873 : [Feature] Add a conditional EventListener into Event Module* Polish apache/dubbo#4875 : [Feature] Refactor ServiceInstancesChangedListener* Remove the cycle dependencies* Remove the cycle dependencies* Polish apache/dubbo#4903 : [Feature] Set source into the BeanDefinition of Dubbo Config* Polish apache/dubbo#4902 : [Feature] Dubbo Cloud Native to Spring XML scenario* Polish apache/dubbo#4713 : Initial the new module and dependencies* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4910 : [Feature] To suppoort DubboLifecycleComponentApplicationListener in Spring XML scenario* Polish apache/dubbo#4713 : Add Service discovery implementation for Eureka #4713* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka",1
issue#570: 修复 client timeout 没设置的问题,0
[FLINK-8640][build] Add japicmp-plugin Java EE dependencies,1
DUBBO-204 修改应用名常量git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1738 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-17935] Move set yarn.log-config-file to YarnClusterClientFactory.createClusterDescriptor()This closes #12455.,1
Merge remote-tracking branch 'origin/cloud-native' into cloud-native# Conflicts:#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscovery.java,5
[FLINK-17236][docs] Add Tutorials section overviewThis closes #11826.,1
[FLINK-9418] Separated pruning and element processing pathsThis closes #6059,1
Fix NPE in Ordering toString method: Keytypes may be null,0
"[FLINK-19547][Runtime] Add the partialRecordLength when creating a BufferConsumerPartial records happen if a record can not fit into one buffer, then the remaining part of the same recordis put into the next buffer. Hence partial records only exist at the beginning of a buffer.Partial record clean-up is needed in the mode of approximate local recovery.If a record is spanning over multiple buffers, and the first (several) buffers have got lost due to the failureof the receiver task, the remaining data belonging to the same record in transition should be cleaned up.`partialRecordLength` is the length of bytes to skip in order to start with a complete record,from position index 0 of the underlying MemorySegment. `partialRecordLength` is used in approximatelocal recovery to find the start position of a complete record on a BufferConsumer, so-called`partial record clean-up`.This commit includes1). API change to add `partialRecordLength` when creating a BufferConsumer2). Add `partialRecordLength` in `BufferWritingResultPartition` when emitRecord and `broadcastRecord`",1
[FLINK-23954][e2e] Add debug logging to KvStateSerializerThis closes #16986.,2
DUBBO-212 在有非daemon线程时服务注册失败容器没有退出，改为用System.exit(1)强制退出。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@957 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR Removed unused ConfigProvider from raft resources module. (#10829)Reviewers: Jun Rao <junrao@gmail.com>,5
[hotfix][table] Remove unused geometry dependency,1
"MINOR: Filter out quota configs for ConfigCommand using --bootstrap-server (#9030)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, David Jacot <djacot@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",5
"fix 9735, concurrent modification of stated urls (#9777)",0
[FLINK-17257][yarn][test] Fix AbstractYarnClusterTest not compiling with hadoop 2.10.,3
[FLINK-16200][table] Support JSON_EXISTS in SQL & Table APIThis is partially based on the work done by @XuQianJin-Stars inhttps://github.com/apache/flink/pull/11186.supersedes #11186,2
[FLINK-13567][e2e] Enable schema registry testsThis closes #10544.,3
"DOCS - clarify transactionalID and idempotent behavior (#7821)If transactional.id is set without setting enable.idempotence, the producer will set enable.idempotence to true implicitly. The docs should reflect this.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
[maven-release-plugin] prepare release dubbo-2.7.0,2
[hotfix] moved files to correct folder to match package statementsThis closes #1510,2
[FLINK-11297][docs] Minor amendmends to the changeThis closes #7457,4
[FLINK-4826] add keytab support to mesos containerThis closes #2734.This closes #2900.,1
[FLINK-4115] Remove filesystem initialisation from FsStateBackend constructor,5
"KAFKA-14144:; Compare AlterPartition LeaderAndIsr before fencing partition epoch (#12489)This PR fixes an AlterPartition regression introduced in https://github.com/apache/kafka/pull/12032When an AlterPartition request succeeds, the partition epoch gets bumped. In Zk controller mode the sender also relies on the AlterPartition response to be informed of the new partition epoch.If the sender times out the request before a response is sent, the sender will have a stale partition epoch compared to the ZK controller state and will be fenced on subsequent AlterPartition request attempts. The sender will not receive an updated partition epoch until it receives a LeaderAndIsr request for controller-initiated ISR changes.Reviewers: Jason Gustafson <jason@confluent.io>",5
[FLINK-13548][Deployment/YARN]Support priority of the Flink YARN application.,2
[3.0-Triple]Fix compressor flag = 1 when compressor is none and format (#9021)* Fix compressor flag = 1 when compressor is none and format* Fix compressor flag = 1 when compressor is none and format* Fix server compressor,0
[FLINK-2827] Close FileInputStream through try-with-resources to avoid unused open stream.This closes #1276,1
MINOR: update java doc for deprecated methods (#10722)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[FLINK-16178][refactor] Remove redundant (duplicate) check on version availability.,4
DUBBO-254 增加Compiler扩展点git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1171 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-10029][DataStream API] Refactoring the StreamingFileSink code.,2
- Added JavaDoc to new classes,1
KAFKA-8601: Add UniformStickyPartitioner and tests (#7199)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
[FLINK-11741] [core] Add getNestedSerializerSnapshots utility method in CompositeTypeSerializerConfigSnapshotWe often want to get only the restored serializer snapshots from alegacy CompostieTypeSerializerConfigSnapshot when attempting to redirectcompatibility checks to new snapshots. This commit adds agetNestedSerializerSnapshots utility method for that purpose.,1
[FLINK-5237] Consolidate and harmonize Window Translation Tests,3
[FLINK-2165] [TableAPI] Renamed table conversion functions in TableEnvironmentThis closes #793,1
Implemented propagation of path latency information from task manager to job manager,5
[FLINK-11645][tests] Move TestingJobManagerMessages#NotifyWhenJobRemoved to TestingTaskManagerMessages,3
Remove .orig file and update gitigonre.,5
Fixes a bug in the Java 6 JVM where primitive arrays have a wrong type.,0
[FLINK-15629][runtime] Remove the unused param ‘restartStrategyFactory’ from SchedulerNGFactoryFactory#createSchedulerNGFactory(…),1
[FLINK-1032] Rework support for POJO types in the Java API,1
[FLINK-28782][python][connector/filesystem] FileSink supports compactionThis closes #20428.,1
KAFKA-2196; Remove identical topic constraint in round-robin assignor; reviewed by Guozhang Wang,4
Add ApplicationModel destroy support and ut support (#8673)* Add ApplicationModel destroy support and ut support* Fix ut* Fix ut,0
"[FLINK-2878] [webmonitor] Fix unexpected leader address patternThe HandlerRedirectUtils.getRedirectAddress decides whether the retrieved leader address is equal to the local job manager address. The local job manager address is, however, in the form akka.tcp://flink@url/user/jobmanager whereas the leader address can be akka://flink/user/jobmanager if the local job manager is the current leader. Such a case produced a warning which is not correct. This PR checks for the local job manager address and signals that no redirection has to be done if it receives akka://flink/user/jobmanager.Add test for HandlerRedirectUtilsThis closes #1280.",0
Fixed bug in output channel context,0
Add tests for TupleLeadingFieldComparator,3
"Fix #1411 Java Locale use '_' split language, country, variant. (#1413)",1
MINOR: Cleanup NetworkReceive constructors (#12511)There was unnecessary duplication and one of the overloadsdid not set the size field for no good reason.Reviewers: Luke Chen <showuon@gmail.com>,1
[FLINK-8298][tests] Properly shutdown MockEnvironment to release resourcesThis closes #5193.,3
[FLINK-8006] [Startup Shell Scripts] - Fixing $pidThis closes #4968.,0
[FLINK-22699][table-common] Declare ConstantArgumentCount as @PublicEvolving,2
[hotfix][docs][examples] Add missing semicolons,1
修改版本为2.4.0-SNAPSHOTgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@2011 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-10215]Add configuration of java option  for historyserverThis closes #6612.,5
"[3.0] Refactor State Router (#9228)* Refactor StateRouter, remove router cache* Remove unused class* refactor builtin routers to state routers* add log* remove unused method* move order* Add generics support",1
[FLINK-25220][test] ITCase ArchUnit test for HBase-2.2 connector,3
[FLINK-18326][legal] Updated kubernetes NOTICE,5
[FLINK-20651] Add Spotless plugin with Google AOSP style,1
"[FLINK-19319] Deprecate setStreamTimeCharacteristic() and TimeCharacteristicAfter FLINK-19317 and FLINK-19318 we don't need this setting anymore.Using (explicit) processing-time windows and processing-time timers workfine in a program that has EventTime set as a time characteristic andonce we deprecate timeWindow() there are not other operations thatchange behaviour depending on the time characteristic so there's no needto ever change from the new default of event-time. Similarly, theIngestionTime setting can be achieved in the future by providing aningestion-time WatermarkStrategy.",1
[FLINK-9243][tests] fix flaky SuccessAfterNetworkBuffersFailureITCaseThis closes #5915.,0
[hotfix][javadocs] Fix typos in RuntimeContextThis closes #4864.,1
[FLINK-10596][cep][docs] Updated cep docs with PatternProcessFunction,1
[hotfix][runtime] Set root cause to pending request released exception,1
MINOR: Fix documentation of compactionRemoved a duplicate line and also cleaned up some of the language around compaction guarantees.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Gwen ShapiraCloses #2089 from apurvam/fix-documentation-of-compaction and squashes the following commits:03c5bdd [Apurva Mehta] Fix line length to be consistent with the rest of the file0af1a86 [Apurva Mehta] MINOR: fix duplicate line in docs for compaction.,2
[hotfix][network] Fix field visibility.,0
Merge remote-tracking branch 'origin/master'# Conflicts:#dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/ServiceBean.java,5
DUBBO-581 codec encode后检查数据是否超过payload的限制,5
[hotfix][docs] Fix wrong JavaDoc link in SavepointSerializerThis closes #9588,2
"Extension: Eager Thread Pool (#1568)* Extension: Enhanced Thread PoolA thread pool that can provide faster processing speeds when there are more tasks (of course it consumes more resources)* When the number of tasks exceeds the core size, a new thread is first started to execute the task instead of putting it into the queue.* When the number of tasks is lower than the core size for a long time, the core size threads are maintained and redundant threads are recycled.* Compared to the fixed pool：When there are more tasks, provide more workers to handle the tasks.* Compared to the cached pool：The task queue in the cached pool is actually a SynchronousQueue and does not have the ability to cache tasks.* Whether to fail fail or put into a queue when a thread runs out：Both are feasible and need to consider which way should be applied according to the business scenario. Delayed scenarios are not allowed. Failfast is more reasonable than queues. However, if there is a certain tolerance for delays, queues are more reasonable than failfast.* remove * in import* add license to fix ci failure* rename the thread pool to EagerThreadPoolmodify sth with the code reviewformat the code file* remove '*' in import statement* throw NullPointerException if the param is null.* throw NullPointerException if the param is null.* catch throwable and decrease submitted task count anyway",2
[FLINK-21337] ComparableInputTypeStrategyTests is not running,1
"[FLINK-10995][runtime] Copy intermediate serialization results only once for broadcast modeThe behavior of current channel selector is either for one channel or all the channels for broadcast mode.In broadcast mode, the intermediate serialization results would be copied into every BufferBuilder requestedfor every sub partition, so this would affect the performance seriously especially in large scale jobs.We can copy to only one target BufferBuilder and the corresponding BufferConsumer would be shared by all thesub partitions to improve the performance. For mixed operations with broadcast and non-broadcast, we shouldfinish the previous BufferBuilder first before transforming from broadcast to non-broadcast, vice versa.",5
DUBBO-524 内嵌jetty服务器没有绑定anyhost,5
[hotfix] Remove some unecessary null checks in RocksDBKeyedStateBackend,5
[FLINK-20846] Move CompletedCheckpointStore creation out of ExecutionGraphBuilder.buildGraph,1
Renaming part 10 (fix error in clients pom file),2
[streaming] jobgraphbuilder setnumberoftasksperinstance update,5
[FLINK-21938][docs] Add how to unit test python udfsThis closes #15360.,3
"[FLINK-26453][clients] Prevent program configurations also when executeAsync is calledWith FLINK-25206 it is possible to disallow configuration changes insidethe user program. Before this commit the validation only happened whena job was executed synchronously and asynchronous submissions stillsucceeded. Now, the asynchronous submission also fails.",0
"[FLINK-23277][state/changelog] Store and recover TTL metadata using changelogUpon recovery, changelog backend creates underlying states to apply changes.TTL config is not available at that moment, so states are currently createdregardless of job TTL settings.This change stores TTL config along with metadata (in changelog); anduses it on recovery.Note: values are already serialized as TTL values and serializers as TTL seralizersNote: upgrading TTL settings is not possible (see FLINK-23143)",2
[hotfix][checkstyle] Forbidding to import org.testcontainers.shaded,3
[FLINK-2924] [streaming] Improve compacting logic,2
DUBBO-340 heartbeat 兼容老版本，server 端不开启 heartbeat，因为 server 端暂时无法判断 client 端是否支持 heartbeat，client 端只在发现 server 端的 dubbo 版本为 2.1.0 及以上版本时才开启git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1567 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KIP-835: metadata.max.idle.interval.ms shoud be much bigger than broker.heartbeat.interval.ms (#12238)The active quorum controller will append NoOpRecord periodically to increase metadata LEO, however, when a broker startup, we will wait until its metadata LEO catches up with the controller LEO, we generate NoOpRecord every 500ms and send heartbeat request every 2000ms.It's almost impossible for a broker to catch up with the controller LEO if the broker sends a query request every 2000ms but the controller LEO increases every 500ms, so the tests in KRaftClusterTest will fail.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, showuon <43372967+showuon@users.noreply.github.com>, Colin Patrick McCabe <cmccabe@confluent.io>",5
[hotfix][configuration] Match enums case insensitively in configuration,5
MINOR: Fix typo in documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang WangCloses #707 from vahidhashemian/typo04/fix_documentation_typos,2
pagerank works with caching,1
"Fixed mixed keys for CoGroup, adapted test cases, code clean up",4
[FLINK-20971][table-api-java] Support calling SQL expressions in Table APIThis closes #14660.,1
Prevent operator chaining directly after iteration nodes.,5
[streaming] FTBuffer fix,0
"KAFKA-12334: Add the KIP-500 metadata shellThe Kafka Metadata shell is a new command which allows users tointeractively examine the metadata stored in a KIP-500 cluster.It can examine snapshot files that are specified via --snapshot.The metadata tool works by replaying the log and storing the state intoin-memory nodes.  These nodes are presented in a fashion similar tofilesystem directories.Reviewers: Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>, Igor Soarez <soarez@apple.com>",5
[hotfix] Move testing sender and receiver invokables to TestingAbstractInvokablesMoves the testing Sender and Receiver class from JobExecutionITCase to TestingAbstractInvokablesfor easier reusability.,3
[FLINK-15700][python][doc] Improves the Python API Tutorial doc,2
MINOR: Implement toString() in config validator classes (#5401),5
修改配置KEYgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@133 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-5981] [security] Make SSL pick up configured protocols and cipher suitesThis closes #3486,3
"[FLINK-25179] Add document for array,map,row types support for parquet row writer",1
[streaming] initiate windowing,5
"[FLINK-4921] Upgrade to Mesos 1.0.1- Shading fix for Guava, Fenzo, Mesos lib",0
auto-discovery of topics for mirroring; patched by Joel; reviewed by Jun; KAFKA-74git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156393 13f79535-47bb-0310-9956-ffa450edef68,1
Improved shutdown behavior of RPC server,1
[FLINK-23452][runtime] Added extra classes for the ability to calculate throughput,1
"KAFKA-8233: TopologyTestDriver test input and output usability improvements (#7378)Implements KIP-470Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Some code cleanups on Scala Shell,4
Add default entry (commeted) for program JVM options,1
[FLINK-22341][hive] Fix describe table for hive dialectThis closes #15660,0
[FLINK-23401][python] Refactor the construction of transformation into getTransformsThis closes #16541.,1
DUBBO-303 各变量的线程安全性检查git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1440 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][checkstyle] Remove suppression for runtime/network.partition,1
[FLINK-12978][table] Support LookupableTableSource for CsvTableSource,1
Added unit test for ticket #198,3
[FLINK-2336][DataStream API] Fix ArrayIndexOufOBoundsException in TypeExtractor for type erased lambdasThis closes #11234,4
[FLINK-24746][ci] Use local Nexus cacheEach machine now has their own Nexus instance.,1
"[FLINK-17880][table] Use new inference for table/scalar function in catalogsThis updates catalog related operations (e.g. function DDL, SQL Client) tothe new type inference for scalar and table functions. Hive functions andlegacy planner still work with the old inference. With this commit we cantell an easier story about how to implement functions, because all mainentrypoints support the new inference.This closes #12336.",5
[hotfix][cep] Close nfa in CepOperator only if not null,1
- removed System.out.print statement from EnumTriangles example job,5
"KAFKA-14020: Performance regression in Producer (#12365)As part of KAFKA-10888 work, there were a couple regressions introduced:A call to time.milliseconds() got moved under the queue lock, moving it back outside the lock. The call may be expensive and cause lock contention. Now the call is moved back outside of the lock.The reference to ProducerRecord was held in the batch completion callback, so it was kept alive as long as the batch was alive, which may increase the amount of memory in certain scenario and cause excessive GC work. Now the reference is reset early, so the ProducerRecord lifetime isn't bound to the batch lifetime.Tested via manually crafted benchmark, lock profile shows ~15% lock contention on the ArrayQueue lock without the fix and ~5% lock contention with the fix (which is also consistent with pre-KAFKA-10888 profile).Alloc profile shows ~10% spent in ProducerBatch.completeFutureAndFireCallbacks without the fix vs. ~0.25% with the fix (which is also consistent with pre-KAFKA-10888 profile).Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2
"MINOR: Remove version in the uses pageThis is contributed by Hao Chen.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3366 from guozhangwang/KMinor-fix-streams-link-in-uses",2
[hotfix][table-common] Move specific type strategies out of TypeStrategies,4
[FLINK-16352][table-common] Changing HashMap to LinkedHashMap for deterministic iterations in ExpressionTest (#11269),3
[FLINK-10137][YARN] Log completed containers.,2
"KAFKA-12578: Remove deprecated security classes/methods for 3.0 (#10435)More specifically, remove deprecated:- Constants in SslConfigs- Constants in SaslConfigs- AclBinding constructor- AclBindingFilter constructor- PrincipalBuilder and DefaultPrincipalBuilder classes- ResourceFilterAlso simplify tests and code that no longer have to handle the removed `PrincipalBuilder`.These removals seem non controversial. There is a straightforward alternative. Thedeprecations happened in 1.0.0 and 2.0.0.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",4
"KAFKA-6826 avoid range scans when forwarding values during aggregation (#4927)Reviewers: Matthias J Sax <matthias@confluentio>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"Added exception check to combiner closing, to catch late exceptions.",1
zookeeper可使用group区分不同注册中心git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@168 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Small changes and tests for the newly introduced EnumTypeThis closes #230.,1
[FLINK-1949] Fix issue detecting stopped detached YARN session,0
[hotfix][avro] Fix TINYINT/SMALLINT types not work in Avro format,1
resolve idea warning no beans of type found (#8396),2
[hotfix][runtim] Minor clean-ups in FineGrainedSlotManager,4
[FLINK-10913] Harden ExecutionGraphRestartTest#testRestartAutomaticallyWait until all Executions reach the state DEPLOYING instead of having a resource assigned.,3
Add test to verify that distinct probers are used in the case of performing multiple concurrent hash joins with teh same hash table.,1
[FLINK-16273][python] Set io.netty.tryReflectionSetAccessible to true by default (#11341),1
[FLINK-22138][table] Allow casting between row and structured typeThis closes #15516.,1
"KAFKA-12577; Remove deprecated `ConfigEntry` constructor for 3.0 (#10436)ConfigEntry's public constructor was deprecated in 1.1.0. This patch removes it in AK 3.0.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
[FLINK-23614][table-planner] The resulting scale of TRUNCATE(DECIMAL) is not correctThis closes #16740,1
"[FLINK-12454][python] Add -l(list) -i(include) and -e(exclude) option for lint-python.sh.Brief change log:- Add -l(list) option, will list all checks supported.- Add -e(exclude) option, exclude checks which split by comma(,) e.g. -e tox,flake8- Add -i(include) option, include checks which split by comma(,) to exec e.g. -i flake8.This closes #8383",1
"KAFKA-2517; Performance Regression post SSL implementation (zero copy)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>Closes #273 from ijuma/kafka-2517-ssl-zero-copy-regression",1
[FLINK-12257][table-api][table-planner] Instantiate TableSource from CatalogTableThis closes #8634,2
[FLINK-4586] [core] Broken AverageAccumulatorThis closes #2639,2
[hotfix][table-api] Uncouple case classes from other API tests,3
"[FLINK-5590] [runtime] Add proper internal state hierarchyThis introduces an internal state hierarchy that mirrors the external state hierarchy,but gives the runtime access to methods that should not be part of the user facing API,such as:  - setting namespaces  - accessing raw values  - merging namespaces",1
"MINOR: Collect metadata log dir in kraft system tests (#12215)It is useful to collect the directory for `__cluster_metadata` in system tests. We use a separate directory from user partitions, so it must be configured separately. Reviewers: David Arthur <mumrah@gmail.com>",5
"[FLINK-15834][hotfix] Fix queryable state e2e testProblem: The logging pattern recently changed, that's why the extaction of port / ip failedThis closes #11222",0
Fix compile issue from last commit. Oops. :-(,0
Adjust tests LocalDistributedExecutor for low memory settings on build servers.,1
- fixed bug in InputFormat- revisited DataSourceTask cancel code,5
"KAFKA-13837; Return an error from Fetch if follower is not a valid replica (#12150)When a partition leader receives a `Fetch` request from a replica which is not in the current replica set, the behavior today is to return a successful fetch response, but with empty data. This causes the follower to retry until metadata converges without updating any state on the leader side. It is clearer in this case to return an error, so that the metadata inconsistency is visible in logging and so that the follower backs off before retrying. In this patch, we use `UNKNOWN_LEADER_EPOCH` when the `Fetch` request includes the current leader epoch. The way we see this is that the leader is validating the (replicaId, leaderEpoch) tuple. When the leader returns `UNKNOWN_LEADER_EPOCH`, it means that the leader does not expect the given leaderEpoch from that replica. If the request does not include a leader epoch, then we use `NOT_LEADER_OR_FOLLOWER`. We can take a similar interpretation for this case: the leader is rejecting the request because it does not think it should be the leader for that replica. But mainly these errors ensure that the follower will retry the request.As a part of this patch, I have refactored the way that the leader updates follower fetch state. Previously, the process is a little convoluted. We send the fetch from `ReplicaManager` down to `Partition.readRecords`, then we iterate over the results and call `Partition.updateFollowerFetchState`. It is more straightforward to update state directly as a part of `readRecords`. All we need to do is pass through the `FetchParams`. This also prevents an unnecessary copy of the read results.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: fix flaky Streams EOS system test (#4728)Reviewer: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-14557][python] Clean up the py4j package by removing the unused directory __MACOSX.This closes #10047.,1
[FLINK-16225] Add JVM Metaspace Error assumption test,3
[hotfix][travis] Use echo instead of printfAzure exhibits some problems when using printf.,1
Merge accumulators and minor cleanups.,4
[FLINK-11892] [docs] Refine README of end-to-end tests to make it more clearThis closes #7972,1
[FLINK-7880][QS] Fix QS test instabilities.,3
[FLINK-18809][table-planner-blink] Update First/LastValueAggFunction,1
"[hotfix] Remove leftover KeyedTimePanesRecently, the aligned window operators were removes, these classes whereleftover after that removal.",4
"KAFKA-702 Deadlock between request handler/processor threads; reviewed by Neha Narkhede, Jun Rao",0
[streaming] api refactor,4
"[docs, setup] Add missing parenthesis",1
"[FLINK-12] Clean up configuration object  - Remove class loader (was inconsistently used and set)  - Objects are stored in their type, rather than as a string",1
[FLINK-6695] Activate strict checkstyle for flink-connector-wikiedits,2
[FLINK-11067][table] Convert TableEnvironments to interfaces,2
"KAFKA-13987: Isolate REST request timeout changes in Connect integration tests (#12291)This causes the artificial reductions in the Connect REST request timeout to be more isolated. Specifically, they now only take place in the tests that need them (instead of any tests that happen to be running after the reduction has taken place and before it has been reset), and they are only performed for the requests that are expected to time out, before being immediately reset. This should help reduce spurious test failures (especially in slow environments like Jenkins) for all Connect integration tests that interact with the REST API, not just the BlockingConnectorTest test suite.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
MINOR: Ensure same version of scala library is used for compile and at runtime (#9168)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
Fixed JSON Bug for some plans.Signed-off-by: Robert Metzger <metzgerr@web.de>This closes #23.,0
[FLINK-23452][core] Added specific configuration for the calculation of the throughput,5
[FLINK-13386][web]: Add all operators watermark,1
Changed Nephele job client to reflect proper execution time in milliseconds,4
[FLINK-4905] [kafka 08 consumer] Suppress offset committing failures when fetcher is shutting downThis closes #3035,0
[FLINK-10149][mesos] Make returned port keys set immutable.,1
[FLINK-17903][core] WatermarkOutputMultiplexer supports String IDs and de-registration of outputs,1
FutureAdapter depends on AsyncRpcResult (#4471)#4471,5
[FLINK-7420] [avro] Move all Avro code to flink-avro,2
"KAFKA-8164: Add support for retrying failed (#8019)Disabled by default, but enabled for Jenkins PR builds (maximum of 1 retry pertest with up to 5 retries for the test run).Reviewers: Ismael Juma <ismael@juma.me.uk>",1
DUBBO-202 override 修复Directory.getUrl方法问题 增加测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1252 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[builds] Print Java process stack traces of stalled builds,5
"[FLINK-2415] [web dashboard] Provide more data in the job overview responsesRather than only listing job ids, this now includes all information necessary to describe the job.This reduces the number of requests for the job overview page to a single request.",5
[FLINK-11773] [tests] Add unit tests for KryoSerializerSnapshotThis closes #7852.,3
[FLINK-21072][hotfix] Clear resources in HeapSnapshotStrategy,2
Improved behavior of NIO threads when connection is idle,1
"[FLINK-16093][docs-zh] Translate ""System Functions"" page of ""Functions"" into Chinese (#16348)",1
Fix scope for scalatest dependency,3
修改启动脚本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@462 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[Dubbo-5871][Dubbo-5885][Dubbo-5899] Fix nacos registry not work bug since 2.7.6 (#5902)* TO FIX bug with https://github.com/apache/dubbo/issues/5885* Avoid instances overwriting problem with different service name* Avoid duplicated service name which will lead duplicated subscribe* Resolve Conflicts* Resolve conflicts* Use ConcurrentHashMap instead of HashMap* Resolve conflicts* Resolve conflicts* Resolve conflicts* Format codes,5
MINOR: Update shell scripts to support z/OS system (#7913)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"[streaming] Added CoBatchGroupReduceInvokable, CoWindowGroupReduceInvokable and grouped variants",1
[FLINK-11703][table-planner-blink] Introduce TableEnvironments and support registerDataStream and sqlQueryThis closes #7923,5
[hotfix][streaming] Improve Input class javadoc,2
Implemented output estimation for UnionNode,5
[FLINK-23452][refactor] Extracted PeriodTimer interface for the abstraction of idle/backpressure time management,4
[FLINK-21338][test] Disable broken tests,3
"Remove duplicate code which is invoked twice (#5039)Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",4
"Update KafkaConfig.scala (#7113)Better clarify the auto leader rebalance config documentation to reflect additional leader.imbalance.per.broker.percentage config description.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",5
[hotfix][tests] Remove the dead codes of StreamTestSingleInputGate and TestInputChannel,3
MINOR: Add Rolling Upgrade Notes to Security DocsAnd added info about the krb5.conf file as we don't appear to mention that in the current docsAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael JumaCloses #625 from benstopford/security_docs,2
[FLINK-8233][flip6] Add JobExecutionResultHandler    - Allow retrieval of the JobResult cached in Dispatcher.    - Implement serializer and deserializer for JobResult.[FLINK-8233][flip6] Improve JobResultDeserializer and add tests[FLINK-8233][flip6] Exclude null jobExecutionResult from serialization[FLINK-8233][flip6] Add TestLogger to JobResultDeserializerTestThis closes #5194.,3
KAFKA-5235: GetOffsetShell: Support for multiple topics and consumer configuration override (KIP-635) (#9430)This patch implements KIP-635 which mainly adds support for querying offsets of multiple topics/partitions.Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: Fixed misleading reference to HTTPS instead of SSL support in the docAuthor: ppatierno <ppatierno@live.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3487 from ppatierno/ssl-doc-https,2
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1409 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-11524][tests] Make JobResultUtils#assertIncomplete implementation more comprehensiveThis closes #10553.,3
[FLINK-333] [apis] Forward crossWithSmall and crossWithLarge hints to optimizer.,2
"[FLINK-17520] [core] Extend CompositeTypeSerializerSnapshot to allow migration based on outer snapshotThis commit deprecates isOuterSnapshotCompatible, which only allowssignaling if the outer config is either compatible or not compatible, infavor of a new resolveOuterSchemaCompatibility method which additionallyallows the user to signal migration.The change is backwards compatible, and allows subclasses that stillonly implement isOuterSnapshotCompatible to work as is.",1
[FLINK-1876] [streaming] StreamGraph refactor,4
"KAFKA-1119 Kafka 0.8.1 overwrites previous per topic config changes; reviewed by Joel Koshy, Guozhang Wang, Swapnil Ghike, Jay Kreps",4
[FLINK-17012][runtime] 'RUNNING' state split into 'RUNNING' and 'RECOVERING' in order to distinguish when the task is really runningThis closes #15221,1
[FLINK-27669][tests] Migrate flink-file-sink-common to JUnit5,3
[hotfix] Remove use of StringUtils.stringifyException() where used is counterindicated,1
Added missing classes to wordcount jar,1
[FLINK-19569][table] Upgrade ICU4J to 67.1 (#13805),2
[hotfix][docs] Allow formatting in SQL functions docs,2
[FLINK-21489][docs] Hugo docs add two anchor links to headers,2
[hotfix] [checkpoints] Cleanups in PendingCheckpoint,4
[FLINK-13382][table-planner-blink] Port DecimalITCase to unit tests DecimalTypeTestThis closes #9669,3
DUBBO-627 扩展泛化调用和实现,5
"[FLINK-15068][rocksdb] stop writing to RocksDB logs by defaultThis commit changes the default RocksDB configuration for all PredefinedOptionsso that they use log level HEADER_LEVEL and disable periodic statistics dumpsto the LOG file.Please note that there is no need to also changeDefaultConfigurableOptionsFactory since this is only applied after anyPredefinedOptions, and there is always one - at least PredefinedOptions#DEFAULT.The problem with this file is that is will grow indefinitely until it is deletedwhen the job is cancelled/restarted since it lives in RocksDB's local directory.Therefore, it cannot be used for troubleshooting errors. For looking intoperformance, metrics are probably better in the first place.Note: Theoretically, we could even set the log level to NUM_INFO_LOG_LEVELSwhich even removes (most of) the headers, but although that is working, it ispractically an invalid value for the log level and would be a bit hacky.This closes #10437",2
MINOR: Increase timeout in log4j system test to avoid transient failures (#5658)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"KAFKA-8972 (2.4 blocker): bug fix for restoring task (#7617)This is a typo bug which is due to calling a wrong map.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-1126][docs] Best practice: named TupleX typesThis closes #786,2
[FLINK-8065][QS] Improve error message when client already shut down.,0
"KAFKA-13823 Feature flag changes from KIP-778 (#12036)This PR includes the changes to feature flags that were outlined in KIP-778.  Specifically, itchanges UpdateFeatures and FeatureLevelRecord to remove the maximum version level. It also addsdry-run to the RPC so the controller can actually attempt the upgrade (rather than the client). Itintroduces an upgrade type enum, which supersedes the allowDowngrade boolean. BecauseFeatureLevelRecord was unused previously, we do not need to introduce a new version.The kafka-features.sh tool was overhauled in KIP-778 and now includes the describe, upgrade,downgrade, and disable sub-commands.  Refer to[KIP-778](https://cwiki.apache.org/confluence/display/KAFKA/KIP-778%3A+KRaft+Upgrades) for moredetails on the new command structure.Reviewers: Colin P. McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",1
MINOR: AbstractCoordinatorTest should close coordinator explicitly (#10001)Reviewers: Jason Gustafson <jason@confluent.io>,5
"[streaming] Code cleanup, added licenses",1
Minor logging improvement,1
[FLINK-13739][table-blink] JDK String to bytes should specify UTF-8 encodingThis closes #9455,2
"[FLINK-6630] [FLINK-6631] Implement FLIP-6 Mesos cluster entrypoints + MesosTaskExecutorRunner- bin: new entrypoints scripts for flip-6- ClusterEntrypoint: Refactor the shutdown method- ClusterEntrypoint: Install default FileSystem (for parity with legacy entrypoints)- ClusterEntrypoint: new MesosJobClusterEntrypoint, MesosSessionClusterEntrypoint, MesosEntrypointUtils, MesosTaskExecutorRunner- MesosServices: enhanced with artifactServer, localActorSystem- MesosResourceManager: Fallback to old TM params when UNKNOWN resource profile is provided- MesosResourceManager: config setting for taskmanager startup script (mesos.resourcemanager.tasks.taskmanager-cmd)- test: added a 'noop' job graph for testing purposesThis closes #4555.",3
[docs] Add import statements to DataStream example programs (Java/Scala)New users sometimes struggle with the imports (especially for Scala API).,2
[streaming] Streaming packages added to flink-dist lib,2
[FLINK-11618][state] Refactor operator state repartition mechanismThis closes #7711.,1
[hotfix] Further clarify side-output error message for same id and type,0
[FLINK-10079] [table] Look up sink tables in external catalogs.This closes #6508.,2
Input formats can tell their types to the java data set (no need for double manual configuration)Collections on tuples need no manual type informationAdditional sanity checks,5
[hotfix][table-api] Rename TableOperation to QueryTableOperation,0
[hotfix][tests] Avoid to add vertices to TestingSchedulingTopology when building edges using ProducerConsumerConnectionBuilder,1
KAFKA-3452 Follow-up: Refactoring StateStore hierarchiesThis is a follow up of https://github.com/apache/kafka/pull/2166 - refactoring the store hierarchies as requestedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2360 from dguy/state-store-refactor,4
[FLINK-18312][rest] Move savepoint operation state into Dispatcherdispatcher,4
fix memory leak of waitForRemove attribute (#7119)fix #7118,0
[streaming] package refactor,4
"MINOR: refactor replica last sent HW updates due to performance regression (#7671)This change fixes a performance regression due to follower last seen highwatermarkhandling introduced in 23beeea. maybeUpdateHwAndSendResponse is expensive forbrokers with high partition counts, as it requires a partition and a replica lookup for everypartition being fetched. This refactor moves the last seen watermark update into the followerfetch state update where we have already looked up the partition and replica.I've seen cases where maybeUpdateHwAndSendResponse is responsible 8% of CPU usage, not including the responseCallback call that is part of it.I have benchmarked this change with `UpdateFollowerFetchStateBenchmark` and it adds 5nsof overhead to Partition.updateFollowerFetchState, which is a rounding error compared to thecurrent overhead of maybeUpdateHwAndSendResponse.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"[FLINK-25414][metrics] Split backPressuredTime metric into soft and hardThis will allow user to differentiate between hard (blocked) back pressuretime and soft, and also it will allow us to present the maxSoft/HardBlockedTimesseparately for sort and hard case.",5
[FLINK-8050] [rest] REST server reports netty exceptions on shutdown.,2
DUBBO-334git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1539 1a56cb94-b969-4eaa-88fa-be21384802f2,1
修改demogit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1711 1a56cb94-b969-4eaa-88fa-be21384802f2,1
HOTFIX: add the hyper link for storageAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3617 from guozhangwang/KHotfix-introduction-hyperlink,2
MINOR: Optimize assertions in unit tests (#9955)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Updating files with release 2.6.1 (#9844)Reviewers: Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2
KAFKA-12427: Don't update connection idle time for muted connections (#10267)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
[FLINK-26995][build] Enable fork-reuse for all unit tests,3
[FLINK-5705] [WebMonitor] WebMonitor request/response use UTF-8 explicitlyThis closes #3257,1
DUBBO-344 log4j优先，保证测试用例通过git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1586 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-3163; Minor follow up for (KIP-33)junrao Could you take a look when get a chance? Thanks.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1769 from becketqin/KAFKA-3163-follow-up,1
[streaming] Moved WindowingOptimizer to its own class + several minor fixes,0
"[FLINK-10942][network,test] Deduplicate common codes in OutputEmitterTest (#7146)This is a pure refactoring commit - no functional changes.",4
"MINOR: Correct typo in test name `TimetampedSegmentsTest` (#7210)Reviewers: Sophie Blee-Goldman <sophie@confluent.io>, Stanislav Kozlovski <stanislav@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
[FLINK-15292] Rename Executor to PipelineExecutor,2
"MINOR: add IQ docs to streams documentationAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3484 from dguy/iq-doc",2
KAFKA-7938: Fix test flakiness in DeleteConsumerGroupsTest (#6312),3
心跳缺省不开启git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@645 1a56cb94-b969-4eaa-88fa-be21384802f2,1
memory optimization for upcoming reusage of pactrecords and objectnodesstarted arrayschema,5
"[hotfix][runtime] Adds debug logs for FinalRequestProcessor to CI runorg.apache.zookeeper.server.FinalRequestProcessor provides debug logs for actualoperations being performed on the server, which might be interesting to seewhen investigating test instabilities.The following logs are part of the debug logs:Processing request:: sessionid:0x1003757ccd40000 type:getData cxid:0x11 zxid:0xfffffffffffffffe txntype:unknown reqpath:/flink/default/checkpoint_id_counter...contains the type of request (e.g. 'getData') and path (e.g. '/flink/default/checkpoint_id_counter').",2
"Revert ""[FLINK-4177] Harden CassandraConnectorITCase""This reverts commit 62523acbe175cf159fe1b4ab6cf5c0412fc4d232.",4
Corrected source code comment,5
"KAFKA-6397: Consumer should not block setting positions of unavailable partitions (#4557)Prior to this patch, the consumer always blocks in poll() if there are any partitions which are awaiting their initial positions. This behavior was inconsistent with normal fetch behavior since we allow fetching on available partitions even if one or more of the assigned partitions becomes unavailable _after_ initial offset lookup. With this patch, the consumer will do offset resets asynchronously, which allows other partitions to make progress even if the initial positions for some partitions cannot be found.I have added several new unit tests in `FetcherTest` and `KafkaConsumerTest` to verify the new behavior. One minor compatibility implication worth mentioning is apparent from the change I made in `DynamicBrokerReconfigurationTest`. Previously it was possible to assume that all partitions had a fetch position after `poll()` completed with a non-empty assignment. This assumption is no longer generally true, but you can force the positions to be updated using the `position()` API which still blocks indefinitely until a position is available.Note that this this patch also removes the logic to cache committed offsets in `SubscriptionState` since it was no longer needed (the consumer's `committed()` API always does an offset lookup anyway). In addition to avoiding the complexity of maintaining the cache, this avoids wasteful offset lookups to refresh the cache when `commitAsync()` is used.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-1126 Remove the DISCLAIMER it is left over from incubation reviewed by Neha,4
"fix, add dynamic config at the first place",5
"[FLINK-18353] Make enabling of the JVM Direct Memory limit configurable for JMThe JVM Direct Memory leak is unlikely in JM. Therefore, we coulddisable its limit by default. This way it could span into e.g. JVMOverhead w/o failure to improve the user experience as before FLIP-116.If user needs the limit, e.g. to investigate container OOMs, the limit can be enabled bysetting the 'jobmanager.memory.enable-jvm-direct-memory-limit' option.This closes #12745.",0
[FLINK-9563][cep][tests] Migrate CEPITCase to collect()This closes #6170.,3
[hotfix][formats][parquet] Fix argument references,0
follow up commit of #5682,5
[3.0] Make Profiler work in Injvm invoke (#9619),1
[FLINK-17974][docs] Extend docker documentationThis closes #12490,2
"Really add POJO support and nested keys for Scala APIThis also adds more integration tests, but not all tests of the Java APIhave been ported to Scala yet.",3
[hotfix][streaming] Remove redundant word in javadocs,2
[FLINK-1608] [taskmanager] Hostname/address for TaskManager can be specified in the configuration,5
"[FLINK-28924][docs-zh] Translate ""LIMIT clause"" page into Chinese.This closes #20552",1
[FLINK-17017][runtime] Enable to get whether a physical slot will be occupied indefinitely,5
[FLINK-21098][coordination] Add SlotAllocator,1
[FLINK-15629][runtime] Remove SchedulerBase#getExecutionGraph() which is not needed any more,1
[FLINK-1559] [akka] Normalize all akka URLs to use IP addresses rather than hostnames,1
[hotfix] Fix checkstyle violations in FlinkDistributionOverlay,2
"MINOR: Fix some streams web doc nits (#4411)Reviewers: Derrick Or <derrickor@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2
Added default implementation for environment wrapper,1
[FLINK-27272][table-planner] Fix the incorrect plan for query with local sort is incorrect if adaptive batch scheduler is enabledThis closes #19497,0
"KAFKA-10355: Throw error when source topic was deleted (#9191)Before this commit, Kafka Streams would gracefully shut down the whole application when a source topic is deleted. The graceful shutdown does not give the user the possibility to react on the deletion of the source topic in the uncaught exception handler.This commit changes this behavior and throws an error when a source topic is deleted.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",5
Minor: added description for lag in consumer group commandAuthor: Kaufman Ng <kaufman@confluent.io>Reviewers: Gwen ShapiraCloses #1320 from coughman/trunk,1
[hotfix][docs] Update docs regarding externalized checkpointThis closes #5928.,2
[FLINK-2976] [runtime] Add setCount(long newCount) to CheckpointIDCounter,1
"MINOR: single Jackson serde for PageViewTypedDemo (#5590)Previously, we depicted creating a Jackson serde for every pojo class, which becomes a burden in practice. There are many ways to avoid this and just have a single serde, so we've decided to model this design choice instead.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-5576] [queryable state] Add tests to for KvStateRequestSerializerTestThese tests ensure that some special cases not properly tested before arehandled correctly in future.This closes #3174.This closes #3139 (left over).,0
[FLINK-18629] Add type to ConnectedStreams#keyByAdding a generic type to the method makes it possible to pass the typefrom a lambda function. Otherwise a wildcard type '?' is derived asObject and thus TypeExtractor extract a GenericTypeInfo<Object> for thekey.,5
KAFKA-6145: Add unit tests to verify fix of bug KAFKA-9173 (#8689)Ensure that the assignor will always assign tasks to new instances.Reviewers: John Roesler <vvcephei@apache.org>,1
HOTFIX: remove unsued StreamsConfig from StreamsPartitionAssignor,5
MINOR: Remove redundant apostrophe in doc (#9976)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
[FLINK-16205][table-planner] Test base for aggregation functions,1
Fixed #212,0
[3.0] Clear up env when destroy (#10193)* [3.0] Clear up env when destroy* fix import* fix clean* update clean up,4
"[taskmanager] do not process message if not connected to job managerThis commit makes sure that task messages are only processed whenconnected to a job manager. Otherwise, they are dropped. Before, themessage were processed in any case.This closes #914.",4
[FLINK-7667] [flip6] Use ArchivedExecutionGraph as serializable AccessExecutionGraphThis commit removes AccessExecutionGraph#getCheckpointCoordinator and changes theAccessExecutionGraph#getJobCheckpointSettings into #getJobCheckpointConfiguration.The JobCheckpointConfiguration only contains the CheckpointCoordinator relevantconfiguration settings and excludes the serialized state backend and theserialized master hooks. That way we don't send unnecessary information whenthe ArchivedExecutionGraph is requested.This closes #4727.,5
"Refactor, put overrides related to Config Center inside ConfigurationListeners",5
[FLINK-2298] Add option to pass a custom name for Flink on YARNThis closes #876,2
整理重复逻辑。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@207 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Align the constructor of KafkaConsumer to KafkaProducer (#8605)1. Move KafkaProducer#propsToMap to Utils#propsToMap2. Apply Utils#propsToMap to constructor of KafkaConsumerReviewers: Noa Resare <noa@resare.com>, Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-6710: Remove Thread.sleep from LogManager.deleteLogs (#4771)`Thread.sleep` in `LogManager.deleteLogs` potentially blocks a scheduler thread for up to `log.segment.delete.delay.ms` with a default value of a minute. To avoid this, `deleteLogs` now deletes the logs for which `currentDefaultConfig.fileDeleteDelayMs` has elapsed after the delete was scheduled. Logs for which this interval has not yet elapsed are considered for deletion in the next iteration of `deleteLogs`, which is scheduled sooner if required.Reviewers: Jun Rao <junrao@gmail.com>, Dong Lin <lindong28@gmail.com>, Ted Yu <yuzhihong@gmail.com>",1
"KAFKA-8069; Fix early expiration of offsets due to invalid loading of expire timestamp (#6401)After the 2.1 release, if the broker hasn't been upgrade to the latest inter-broker protocol version, the committed offsets stored in the __consumer_offset topic will get cleaned up way earlier than it should be when the offsets are loaded back from the __consumer_offset topic in GroupCoordinator, which will happen during leadership transition or after broker bounce. This patch fixes the bug by setting expireTimestamp to None if it is the default value after loading v1 offset records from __consumer_offsets.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
[FLINK-9464] Remove version and scope from flink-test-utils-junit in flink-json pom.xml,5
"MINOR: Suppress ProducerConfig warning in MirrorMakerThough MirrorMaker uses the `producer.type` value of theproducer properties, ProducerConfig show the warning:`The configuration 'producer.type' was supplied butisn't a known config.`Author: Shun Takebayashi <shun@takebayashi.asia>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2676 from takebayashi/suppress-mirrormaker-warning",2
"MINOR: Should cleanup the tasks after dirty close (#8433)Some tasks get closed inside HandleAssignment and did not remove from the task manager bookkeep list. The next time they would be re-closed which is illegal state.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"[FLINK-12530][network] Move Task.inputGatesById to NetworkEnvironmentTask.inputGatesById indexes SingleInputGates by id. The end user of this indexing is NetworkEnvironment for two cases:- SingleInputGate triggers producer partition readiness check and  then the successful result of check is dispatched back to this SingleInputGate by id.  We can just return a future from TaskActions.triggerPartitionProducerStateCheck.  SingleInputGate could use the future to react with re-triggering of the  partition request if the producer is ready. Then inputGatesById is not needed for dispatching.- TaskExecutor.updatePartitions uses inputGatesById to dispatch PartitionInfo update to the right SingleInputGate.  If inputGatesById is moved to NetworkEnvironment, which should be a better place for gate management,  and NetworkEnvironment.updatePartitionInfo is added then  TaskExecutor.updatePartitions could directly call NetworkEnvironment.updatePartitionInfo.Additional refactoring:- TaskActions.triggerPartitionProducerStateCheck is  separated into another interface PartitionProducerStateProvider.  TaskActions is too broad interface used also for other purposes.  Shuffle API needs only PartitionProducerStateProvider.- PartitionProducerStateProvider returns future with the ResponseHandle  which contains the producer state and accepts callbacks to cancel or fail consumption as a result of state check.- Task.triggerPartitionProducerStateCheck is also refactored into a RemoteChannelStateChecker  which becomes internal detail of NetworkEnvironment. RemoteChannelStateChecker accepts ResponseHandle,  checks whether producer is ready for consumption or aborts consumption  using ResponseHandle.cancelConsumption or ResponseHandle.failConsumption.",0
[FLINK-1993] [ml] Replaces custom SGD logic with optimization framework's SGD in MultipleLinearRegressionFixes PipelineITSuite because of change MLR loss functionThis closes #760.,1
Removed superfluous imports,2
[FLINK-18720][runtime] Initialize ResourceManagerDriver with ScheduledExecutor rather than Executor.ScheduledExecutor will be used for scheduling events in the rpc main thread in subsequent commits.,1
[FLINK-16096][docs-zh] Translate dev/table/catalog.zh.md into ChineseThis closes #11390,1
[hotfix] Remove Mockito from SlotManagerImplTest,3
[FLINK-23064][connector-jdbc] Create PublicEvolving JdbcOptions,5
[FLINK-5258] [docs] Reorganize the docs to improve navigation and reduce duplicationThis closes #2940,1
[hotfix] Use 'ExecutorThreadFactory' for Source Coordinator worker threads.This deduplicates some code.,1
"KAFKA-8319: Make KafkaStreamsTest a non-integration test class (#7382)Previous KafkaStreamsTest takes 2min20s on my local laptop, because lots of its integration test which is producing / consuming records, and checking state directory file system takes lots of time. On the other hand, these tests should be well simplified with mocks.This test reduces the test from a clumsy integration test class into a unit tests with mocks of its internal modules. And some other test functions should not be in KafkaStreamsTest actually and have been moved to other modular test classes. Now it takes 2s.Also it helps removing the potential flakiness of the following (some of them are claimed resolved only because we have not seen them recently, but after looking at the test code I can verify they are still flaky):* KAFKA-5818 (the original JIRA ticket indeed exposed a real issue that has been fixed, but the test itself remains flaky)* KAFKA-6215* KAFKA-7921* KAFKA-7990* KAFKA-8319* KAFKA-8427Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-3319: improve session timeout broker/client config documentationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke, Ismael Juma, Guozhang WangCloses #1106 from hachikuji/KAFKA-3319",5
[hotfix][docs]fix flink sql Cascading Window TVF Aggregation exception (#18414),2
[FLINK-12057] Refactor MemoryLogger to accept termination future instead of ActorSystem,5
KAFKA-4098: NetworkClient should not intercept user metdata requests on disconnectAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1798 from hachikuji/KAFKA-4098,5
[FLINK-949] Properly report GlobalBufferPool OutOfMemoryError to TaskManagerThis closes #28.,0
KAFKA-667 Change the .highwatermark file name.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1420356 13f79535-47bb-0310-9956-ffa450edef68,2
[hotfix] Fix typo multiple word mistakes,2
"MINOR: fix flakiness in testDeleteAclsThis call to isCompletedExceptionally introduced a race conditionbecause the future might not have been completed.  assertFutureErrorchecks that the exception is present and of the correct type in anycase, so the call was not necessary.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3139 from cmccabe/fix-test-deleteacls",3
"KAFKA-7068: Handle null config values during transform (KIP-297)Fix NPE when processing null config values during transform.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5241 from rayokota/KIP-297-null-config-values",5
[FLINK-3523] [Storm-Compatibility] Added SplitStreamMapper to program to get rid of SplitStreamType wrapper - additionally reworked split ITCases   * unified to single test   * make Windows compatible (using tmp files)   * added test case for embedded splittingThis closes #1844,3
[FLINK-2475] Rename Flink Client log fileThis closes #1074,2
Add dedicated factories for stateful and stateless serializers.,1
Added Nephele speed test to examples package,3
[FLINK-23222][docs-zh] Translate page 'Application Profiling & Debugging' into Chinese (#16359),0
KAFKA-2407: Only create log directory when it will be usedAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #115 from granthenke/log-fix and squashes the following commits:de36138 [Grant Henke] Small comment fix49a8dd4 [Grant Henke] KAFKA-2407: Only create log directory when it will be used,1
"Add avro to stratosphere-dist, thus adding it to the lib/ folder",1
"KAFKA-6748: double check before scheduling a new task after the punctuate call (#4827)After the punctuate() call, we would like to double check on the scheduled flag since the call itself may cancel it.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",5
[FLINK-12122] Introduce ClusterOptions#EVENLY_SPREAD_OUT_SLOTS_STRATEGYAdd config option to enable to evenly spread out slots across all availableTaskExecutors.,0
MINOR: Improve JavaDoc for some public classes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Mastuda <yasuhiro.mastuda@gmail.com>Closes #999 from guozhangwang/KJavaDoc,2
[hotfix][javadocs] Fix typo,2
[FLINK-27901][python] Support TableEnvironment.create(configuration)This closes #19883.,5
[FLINK-13967][licensing] Fully generate binary licensing,2
[hotfix] Fix typos in Trigger.java,2
[FLINK-11593][tests] Port TaskManagerTest to new code base,1
[FLINK-22947][docs] Move DataSet to bottom of Applciation Development,5
"KAFKA-5986; Streams State Restoration never completes when logging is disabledWhen logging is disabled and there are state stores the task never transitions from restoring to running. This is because we only ever check if the task has state stores and return false on initialization if it does. The check should be if we have changelog partitions, i.e., we need to restore.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, tedyu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3983 from dguy/restore-test",3
ut修改git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@655 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-26850][metrics] Add Metric#getMetricType,1
[build] Manage version of joda-time to prevent conflicts between dependencies.,5
Added types and serializers/comparators for dangling pagerank.,1
fixed wrong calculation of lazyArrayNode size,0
Added KMeans with additional point tagging as test case for branching broadcast variables.,3
[FLINK-21086][runtime][checkpoint] Add EndOfUserRecordsEvent,1
[fix] Field renaming in BroadcastConnectedStream,0
"KAFKA-2801; Process any remaining data in SSL network read buffer after handshakeProcess any remaining data in the network read buffer in `SslTransportLayer` when `read()` is invoked. On handshake completion, there could be application data ready to be processed that was read into `netReadBuffer` during handshake processing. `read()` is already invoked from `Selector` after handshake completion, but data already read into the `netReadBuffer` was not being processed. This PR adds a check for remaining data and continues with processing data if data is available.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #493 from rajinisivaram/KAFKA-2801",5
[hotfix] Add JavaDoc to RegisteredRpcConnection#tryReconnect,1
[FLINK-28429][python] Optimize PyFlink testsThis closes #20685.,3
Fixed concurrency bug in both local and queue scheduler,0
"MINOR: Fix common struct `JsonConverter` and `Schema` generation (#9279)This patch fixes a couple problems with the use of the `StructRegistry`. First, it fixes registration so that it is consistently based on the typename of the struct. Previously structs were registered under the field name which meant that fields which referred to common structs resulted in multiple entries. Second, the patch fixes `SchemaGenerator` so that common structs are considered first.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
"KAFKA-10005: Decouple RestoreListener from RestoreCallback (#8676)And remove bulk loading mechanism inside RocksDB.Reviewers: John Roesler <vvcephei@apache.org>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
Implemented scheduling of failure events,0
KAFKA-6672; ConfigCommand should create config change parent path if needed (#4727)Change `KafkaZkClient.createConfigChangeNotification` to ensure creation of the change directory. This fixes failing system tests which depend on setting SCRAM credentials prior to broker startup. Existing test case has been modified for new expected usage.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-10545: Create topic IDs and propagate to brokers (#9626)This change propagates topic ids to brokers in LeaderAndIsr Request. It also removes the topic name from the LeaderAndIsr Response, reorganizes the response to be sorted by topic, and includes the topic ID.In addition, the topic ID is persisted to each replica in Log as well as in a file on disk. This file is read on startup and if the topic ID exists, it will be reloaded.Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>, Nikhil Bhatia <rite2nikhil@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-26349][AvroParquet][test] add test for reading reflect records from parquet file created with generic record schema.,1
"KAFKA-4828: ProcessorTopologyTestDriver does not work when using throughThis resolves the following issues in the ProcessorTopologyTestDriver:- It should not create an internal changelog topic when using `through()` and `table()`- It should forward the produced record back into the topology if it is to a source topicJira ticket: https://issues.apache.org/jira/browse/KAFKA-4828The contribution is my original work and I license the work to the project under the project's open source license.Author: Hamidreza Afzali <hrafzali@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2629 from hrafzali/KAFKA-4828_ProcessorTopologyTestDriver_through",3
[hotfix][e2e] Enable kinesis profile,2
[FLINK-7643] [core] Rework FileSystem loading to use factoriesThis makes sure that configurations are loaded once and file system instances areproperly reused by scheme and authority.This also factors out a lot of the special treatment of Hadoop file systems and simplymakes the Hadoop File System factory the default fallback factory.,5
[FLINK-9152] Fix error message on BroadcastConnectedStream,0
[FLINK-1328] [docs] Updated documentation of semantic properties.Improved documentation of key specification and data type.,5
KAFKA-4166; Fix transient MM failure caused by slow old consumer shutdownAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2279 from hachikuji/KAFKA-4166,5
Prepared tracking of assigned vertices in class AllocatedResource,5
"KAFKA-13595: Allow producing records with null fields in ConsoleProducer (#11695)Implements KIP-810: https://cwiki.apache.org/confluence/display/KAFKA/KIP-810%3A+Allow+producing+records+with+null+values+in+Kafka+Console+ProducerConsoleProducer accepts a new setting, `null.marker`, that allows settings the record key, value or headers to null. This can be used to produce ""tombstone"" records.Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Israel Ekpo <israelekpo@gmail.com>",5
KMeansIterationITCase: fixed problem with decimal representation,0
[hotfix][runtime] Remove try-catch blocks,1
[FLINK-15618][runtime] Remove unused JobTimeoutException,1
"[FLINK-7093] [tm] Send SlotReport as part of the heartbeat payload to the ResourceManagerThe TaskManager sends the SlotReport as part of the heartbeat payload to the ResourceManager.That way, the ResourceManager can sync its internal view on the slot allocation with the actualallocation state.This closes #4251.",2
[FLINK-1177] [docs] Mark HDFS setup instructions as option in cluster setup docs,2
MINOR: code cleanup for `VOut` inconsistent naming (#8907)Consistently using VOut instead of Vout for Streams group API.Reviewers: Boyang Chen <boyang@confluent.io>,5
[FLINK-5041] Savepoint Backwards Compatibility 1.1 -> 1.2,2
"KAFKA-12906; Added RecordDeserializationException containing partition and offset  (#10836)As documented in KIP-334 (https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=87297793), we should add a new RecordDeserializationException, which is raised by the consumer when failing to parse a record. This allows the consumer to decide to take an action such as to shut down or skip past the record. Reviewers: Jason Gustafson <jason@confluent.io>",5
"[FLINK-3187] [restart] Introduce RestartStrategy to ExecutionGraphA RestartStrategy defines how the ExecutionGraph reacts in case of a restart. Different strategiesare conceivable. For example, no restart, fixed delay restart, exponential backoff restart, scalingin/out restart, etc.Expose RestartStrategy to user APIThis removes the setNumberExecutionRetries and the setDelayBetweenRetries on the ExecutionEnvironment andthe ExecutionConfig. Instead the more general RestartStrategy can be set. In order to maintain theseparation between the runtime and api module, one sets a RestartStrategyConfiguration which is transformedinto a RestartStrategy on the JobManager.Replace old execution-retries configuration parameters by restart-strategy.Add FixedDelayRestartStrategy test caseReintroduce old configuration values and API calls for the deprecated restart mechanismThe old configuration values and API calls will be respected if no explicitRestartStrategy has been set. The values, if correct, are used to instantiatea FixedDelayRestartStrategy.Add deprecation comments to the JavaDocsAdd logging statement for job recoveryFix JobManagerProcessFailureBatchRecoveryITCase by introducing a job recovery timeoutAdd proper annotations to RestartStrategiesLet ExecutionGraphRestartTest extend TestLoggerThis closes #1470.",3
[FLINK-9028] [yarn] Improve failure message if cluster cannot be started,0
[FLINK-19970] State leak in CEP OperatorsThis commit fixing cleaning up timed out state that were otherwise heldback by newer states that were not timed out.Instead of keeping reference counter just for shared buffer nodes wekeep reference counters for edges as well. This lets us clean up nodesbased when we time out all compatible paths instead of waiting for all successors from different paths to time out.This closes #14979,4
"KAFKA-5003; StreamThread should catch InvalidTopicExceptionWe should catch `InvalidTopicException` and not just`NoOffsetForPartitionException`. Also, we need to step throughall partitions that might be affected and reset those.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2747 from mjsax/minor-fix-reset",0
[FLINK-23023][table-planner] Support offset in window TVFThis closes #16215,1
"KAFKA-12952: Remove deprecated LogConfig.Compact (#10451)Deprecated since 1.0.0 for misleading name. Not a public API technically,but we were conservative originally.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-12648: minor followup from Pt. 2 and some new tests (#11146)Addresses the handful of remaining feedback from Pt. 2, plus adds two new tests: one verifying a multi-topology application with a FKJ and its internal topics, another to make sure IQ works with named topologies (though note that there is a bit more work left for IQ to be fully supported, will be tackled after Pt. 3Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
[FLINK-10204] Fix serialization/copy of LatencyMarkers,0
"Revert ""[FLINK-20551][docs] Remove legacy planner from index and common concepts""This reverts commit 69dc0a297726adb1bc2eb49bd2f52e9d490e53f9.",5
"[FLINK-16641][network] (Part#6) Enable to set network buffers per channel to 0This PR enables to set the number of network buffer per channel (taskmanager.network.memory.buffers-per-channel) to 0. Previously, the value can not be set to 0 because of dead lock, FLINK-16641 solves the problem and we can set it to 0 now.",1
[hotfix][security] Make the credential variable names to be more descriptive,1
[runtime] Add docs to BufferPool classes,2
[hotfix][streaming] Deduplicate code in StreamGraph,0
First steps towards TeraSort PACT example,5
[hotfix][docs] fix typos (#16300),2
"[hotfix][kubernetes] Use stable api apps/v1 instead of extensions/v1beta1The extensions/v1beta1 has been removed since v1.16. For better compatibility, we should use the stable api apps/v1 instead. The apps/v1 is introduced from v1.9.0.",1
"Revert ""[FLINK-23434][table-planner] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg function""This reverts commit a26887e1e257c6e9e14ad09d9aebe6416e69a4e1.",4
[FLINK-4385] [table] Union on Timestamp fields does not workThis closes #2362.,1
KAFKA-432 allow consumer to read from followers; patched by Yang Ye; reviewed by Neha and Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397422 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-1110] Fix IndexOutOfBoundsException in ListKeyGroupedIteratorOccured when calling nextKey() and iterator not consumed with *last* key group.,2
"KAFKA-5819; Add Joined class and relevant KStream join overloadsAdd the `Joined` class and the overloads to `KStream` that use it.Deprecate existing methods that have `Serde` paramsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3776 from dguy/kip-182-stream-join",5
[FLINK-28334][table-planner] Fix PushProjectIntoTableSourceScanRule: covers the case when table source SupportsReadingMetadata and not SupportsProjectionPushDownThis closes #20118,1
[3.0-Triple] Avoid listener npe  on rst (#9916)* Avoid OnReset npe* format & Add stream closed judgment* format* fix judgment,0
[FLINK-8584] handle read-only buffers in deserializer,0
[FLINK-17295][runtime] Introduce ExecutionGraphID,2
[FLINK-3207] [gelly] add pregel iteration abstraction to gelly,1
"MINOR: Use debug level logging for noisy log messages in Connect (#8918)Author: Cyrus Vafadari <cyrus@confluent.io>Reviewers: Chris Egerton <chrise@confluent.io>, Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"[FLINK-22307][network] Increase the default value of data writing cache size (not configurable) for sort-merge blocking shuffleCurrently, the data writing cache of sort-merge blocking shuffle is 8M, which can be not enough if data compression is enabled. This patch increases the cache size to 16M which can improve the performance for high compression ratio scenarios.This closes #15651.",1
Support Multi Subscribe for Service Discovery (#8908)* Support Multi Subscribe for Service Discovery* fix import,2
Cancelling correctly removes partial temporary files.,2
"[FLINK-5300] Add more gentle file deletion procedureBefore deleting a parent directory always check the directory whether it contains somefiles. If not, then try to delete the parent directory.This will give a more gentle behaviour wrt storage systems which are not instructed todelete a non-empty directory.Add test case for more gentle file deletionThis closes #2970.",4
[FLINK-7210] Implement TwoPhaseCommitSinkFunctionThis is a recommended base class for implementing exactly-once sinks in FlinkThis closes #4368.,2
"KAFKA-4914: Partition reassignment tool should check types before persisting state in ZooKeeper (#2708)Prior to this, there have been instances where invalid data was allowed to be persisted inZooKeeper, which causes ClassCastExceptions when a broker is restarted and reads thistype-unsafe data.Adds basic structural and type validation for the reassignment JSON viaintroduction of Scala case classes that map to the expected JSONstructure. Also use the Scala case classes to deserialize the JSONto avoid duplication.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-14296][sql-parser] Improve handling of parameters nullabillity in parser module1. Add @Nullable annotation to nullable fields2. Use Optional instead of nullable as return value3. Add requrieNonNull check in constructor for non-null fields4. List fields do not need to check against nullThis closes #9843,1
[FLINK-14503][coordination] Add partition report to heartbeat,1
"KAFKA-6120: RecordCollector should not retry sendingAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4148 from mjsax/kafka-6120-recordCollector",5
[hotfix] Remove mocking from RestServerEndpointITCase,4
[FLINK-2529] [runtime] Remove some unused code in ExecutionThis closes #1022,1
"I18N effort for dubbo-common, translate the missing content",5
"Multiple registry  (#4066)fixes #3932, #3599, #3084",0
[hotfix][test] Guarantee order of CloseableRegistry,1
KAFAK-4058: Failure in org.apache.kafka.streams.integration.ResetIntegrationTest.testReprocessingFromScratchAfterReset - fixed consumer group dead condition - disabled state store cacheAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2056 from mjsax/KAFKA-4058-instableResetToolTest,3
"KAFKA-3729: Revert adding Serde auto-config (#6630)* Revert ""MINOR: Add unit test for SerDe auto-configuration (#6610)""This reverts commit 172fbb2dd55144e2e44777174f970b56768e1777.* Revert ""[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)""This reverts commit e56ebbffca57741d398283e46073ed4170f8f927.The two merged PRs introduce a breaking change. Reverting to preserve backward compatibility. Jira ticket reopened.Reviewers: Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-1202] Remove incomplete file outputs on failureThis closes #175,0
[FLINK-19410][rest] API stability covers enum value changes,4
[FLINK-12996][table-common] Offer unified exception for type inference classes,5
[FLINK-18985][python][doc] Update the Sphinx doc for Python DataStream API. (#13191),5
MINOR: Kafka Streams Scala API cleanup (#7852)Reviewers: Bill Bejeck <bill@confluent.io>,5
Create a deep-copy of the record when changing timestamps.,4
[FLINK-13632] Port NFASerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-3323] [docs] Add documentation for NiFi connector.This closes #2099,2
[FLINk-10362] [s3] S3 config loading does not search Hadoop classpath,5
"KAFKA-4948; Wait for offset commit in test to fix transient failure`DescribeConsumerGroupTest#testDescribeExistingGroupWithNoMembersWithNewConsumer` shuts down the consumer executor thread and then checks that the assignments returned by `describeGroup` contain the consume group with no members. But if the executor thread is shut down before any offsets are committed, the assignments returned by `describeGroup` doesn't contain the group at all. This PR waits for an offset commit by waiting for the group to appear in `describeGroup` assignments prior to shutting down the executor.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3246 from rajinisivaram/KAFKA-4948",5
[hotfix][license] Add missing licensesThis close #4794.,1
[FLINK-9311] [pubsub] Add PubSubSource and PubSubSink connectorsThis closes #6594,1
[FLINK-8196] [build] Remove 'javax.servlet' dependency exclusion.,4
[streaming] WindowJoin Example refactored,4
[FLINK-1344] [streaming] [scala] Added implicits from scala seq to datastream and static StreamExecutionEnvironment initialization,5
[FLINK-21735][coordination] Harden JobMaster#updateTaskExecutionState()This closes #15196.,5
KAFKA-5690; Add support to list ACLs for a given principal (KIP-357)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5633 from omkreddy/KAFKA-5690-LIST-PER-PRICIPAL,1
"[FLINK-16662] Let PackagedProgramUtils create JobGraph under the user classloaderCurrently, in web submission JobGraph creation happens using the system classloader.This can lead to failures when, for example, the JobGraph creation uses code generationand needs the user code. This PR fixes it by doing the Jobgraph generation under theuser classloader.",1
[FLINK-27209][build] Half the memory and double forkCount for running unit testsAdditionally mark TaskExecutorRecoveryTest as an ITCase due to memory consumption and starting up TaskManagers,3
Added Java equivalent of Scala RelationalQuery example program,1
- fixed java doc in FileInputFormat.java,2
[FLINK-2088] [streaming] [scala] DataStream.name() returns a typed DataStreamCloses #739,5
[FLINK-14377] Parse the ProgramOptions to a Configuration.,5
"[FLINK-10415] Fail requests with empty Netty pipeline in RestClientSometimes it can happen that Netty does not properly initialize the channelpipeline when sending a request from the RestClient. In this situation, weneed to fail the response so that the caller will be notified about the un-successful call.This closes #6763.",0
[hotfix] [tests] Small simplification in 'CheckedThread'.,3
test dependency (#9542),3
[hotfix] Use List instead of ArrayList in TypeExtractor,4
[hotfix] Log architecture on startup,2
[FLINK-28606][Runtime/Checkpointing] Preserve consistency of OperatorEvent from OperatorCoordinator to subtasks,1
update alibaba_spring_context_support_version to 1.0.5 (#5395),1
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 into datamodel,5
[FLINK-23907] Use primitive functional interfaces,1
check destroyed of bean factory and extension (#9165),5
[hotfix][avro] Fix AvroRowSerializationSchema doesn't support TIMESTAMP type,1
[hotfix] Fix checkstyle violations in JobEdge,0
[hotfix] Add self rpc gateway registration to TestingSerialRpcService,3
Merge pull request #59 from aalexandrov/fix_dropin_libsFixed bad assembly of dropin libs in the stratosphere-bin shell scripts.,4
[hotfix][docs][sql] Fix typo,2
KAFKA-5563: Standardize validation and substitution of connector names in REST API connector configs…from config to own function and added check to create connector call.Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4230 from soenkeliebau/KAFKA-5563,5
[FLINK-15026][sql clientSupport create/drop/alter database in sql clientThis closes #10419,5
"KAFKA-8744: Update Scala API to give names to processors (#9738)As it's only API extension to match the java API with Named object with lots of duplication, I only tested the logic once.Reviewers: Bill Bejeck <bbejeck@apache.org>",2
"[FLINK-27394][Documentation] Document how you can add externally hosted documentation in a virtual filemounted system that's only known to Hugo, using Hugo Modules.",1
[hotfix] correct typo in method name,2
[FLINK-6058] Don't read DEFAULT_PARALLELISM from GlobalConfiguration,5
"KAFKA-7568; Return leader epoch in ListOffsets response (#5855)As part of KIP-320, the ListOffsets API should return the leader epoch of any fetched offset. We either get this epoch from the log itself for a timestamp query or from the epoch cache if we are searching the earliest or latest offset in the log. When handling queries for the latest offset, we have elected to choose the current leader epoch, which is consistent with other handling (e.g. OffsetsForTimes).Reviewers: Jun Rao <junrao@gmail.com>",1
"MINOR: Add method to Herder to control logging of connector configs during validation (#8263)* The Herder interface is extended with a default method that allows choosing whether to log all the connector configurations during connector validation or not. * The `PUT /connector-plugins/{connector-type}/config/validate` is modified to stop logging the connector's configurations when a validation request is hitting this endpoint. Validations during creation or reconfiguration of a connector are still logging all the connector configurations at the INFO level, which is useful in general and during troubleshooting in particular. Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <github@juma.me.uk>",5
"KAFKA-8817: Remove timeout for the whole test (#7313)I bumped into this flaky test while working on another PR. It's a bit different from the reported PR, where it actually timed out at parsing localhost:port already. I think what we should really test is that the closing call can complete, so I removed the whole test timeout and add the timeout for the shutdown latch instead.Reviewers: Jason Gustafson <jason@confluent.io>, cpettitt-confluent <53191309+cpettitt-confluent@users.noreply.github.com>",5
[FLINK-6410] [build] Fix Gelly Example packaging to support different Scala versions,1
[FLINK-10602] Use metric's ActorSystem in MetricFetcherUse the metric system's ActorSystem in the MetricFetcher. This makes the fetchingof metrics run in a separate ActorSystem from the one used in the RpcService. Thisshould decouple Flink from the metric system further and allows to individuallyconfigure both systems.,5
Minor code clean upThis closes #221.,4
change pom versiongit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@32 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-3849] [table] Add FilterableTableSource interface and rules for pushing it (2)This closes #3520.fix compilation failurefix compilation failure again.1. Deep copy TableSource when we copy TableSourceScan2. unify push project into scan rule for both batch and streamaddress comments.expand project list before creating new RexProgramupdate tests,3
"MINOR: Remove zkclient dependency (#7036)ZkUtils was removed so we don't need this anymore.Also:* Fix ZkSecurityMigrator and ReplicaManagerTest not toreference ZkClient classes.* Remove references to zkclient in various `log4j.properties`and `import-control.xml`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
[hotfix][coordination] Introduce AbstractHaServices for common logics and wire ZookeeperHaServices to new interface,1
KAFKA-8463: Fix redundant reassignment of tasks when leader worker leaves (#6859)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
Modify MetadataReportRetry ThreadName (#3550)* fix: rename the thread name from DubboRegistryFailedRetryTimer to DubboMetadataReportRetryTimer in MetadataReportRetry,5
upgrade netty for dubbo-all (#2123),5
Fix group reduce compilation test,3
[hotfix][docs][conf] Add query service port to port section,1
[hotfix][network] Fix raw type usages,0
Resolved problems after merging,0
[FLINK-27733][python] Rework on_timer output behind watermark bug fixThis closes #19788.,0
[FLINK-13352][docs] Using hive connector with hive-1.2.1 needs libfb303 jarThis closes #9223,1
"[FLINK-7811] Make IterateExample.Bound final so it can be used in withinBound()With Scala 2.12, the ClosureCleaner will complain that the filterfunction that uses withinBound() is not serializable. The reason is thatwhen ""Bound"" is not final it will serialize it with the closure, wichincludes IterateExample.",1
[FLINK-22406][coordination][tests] Stabilize ReactiveModeITCase,3
Continue to work on deploy/cancel race problem,0
[FLINK-6720] Activate strict checkstyle in flink-java8,2
[hotfix][docs] Fix image links,2
[FLINK-5141] [streaming api] Implement LocalStreamEnvironment for new mini cluster.This closes #2877,5
[streaming] fault tolerance tests,3
[hotfix][table-planner] Convert JSON enums more explicitly,5
Started to implemented distributed checkpoints,5
[FLINK-8989] [e2e] Cleanup / improve Elasticsearch e2e tests- Rework e2e test job modules to have correct Maven POM- Parameterize num of records to write to Elasticsearch- Parameterize Elasticsearch download URL and version in test script- Improve robustness of test- Move more Elasticsearch functionality to elasticsearch-common.shThis closes #5761.,1
[FLINK-12749][docs] Add operations playground.This closes #9543.[ci skip],1
"replace lastOption with exists (#11605)Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
[FLINK-8690] [table] Add DISTINCT aggregates for group windows on streaming tables.This closes #3764.This closes #3765. // Has been resolved by another PR.,0
[hotfix] [yarn] Remove unnecessary TaskManager configuration generation,5
Remove unnecessary final modifier in PlanExecutor.loadExecutorClass methodRemove unnecessary final modifier in PlanExecutor.loadExecutorClass private static method because private means you can not override this method.Author: Henry Saputra <henry.saputra@gmail.com>Closes #163 from hsaputra/remove_unneeded_final_privatetatsic_planexecutor and squashes the following commits:fe7afc7 [Henry Saputra] Remove unnecessary final modifier in PlanExecutor's private static method.,4
Merge branch 'stratosphere'Resolved conflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/client/nephele/api/Client.javapact/pact-clients/src/main/java/eu/stratosphere/pact/client/nephele/api/PactProgram.java,5
[hotfix][coordination] Improve JavaDocs for OperatorCoordinator and OperatorCoordinatorHolder,1
Fixed and renamed delimited input format test.,3
replace namespace suffix '.properties' with '-properties',0
[hotfix] [docs] Fix typo in Joining documentationThis closes #7270.,2
"[FLINK-19855][network] Specify channel AND gate in resume/block consumption()Given channelIndex only, UnionInputGate has to guess which wrapped inputgate this channel belongs to. For that, UnionInputGate expects channelindex with an inputGate offset. This contradicts with the contract ofother resumeConsumption() implementations.UnionInputGate.resumeConsumption isn't used currently but is planned tobe used in FLINK-19856.",2
[FLINK-17659] Add common watermark strategies and WatermarkStrategies helper,1
[FLINK-20500][upsert-kafka] Fix unstable UpsertKafkaTableITCase.testTemporalJoinThis closes #14330,3
"[FLINK-8732] [flip6] Cancel ongoing scheduling operationKeeps track of ongoing scheduling operations in the ExecutionGraph and cancelsthem in case of a concurrent cancel, suspend or fail call. This makes sure thatthe original cause for termination is maintained.This closes #5548.",1
[FLINK-16121][python] Introduce ArrowReader and ArrowWriter for reading and writing Arrow format dataThis closes #11112.,5
[FLINK-13237][table-planner-blink] Fix sqrt conversion in RexNodeConverter,0
[FLINK-14422][runtime] Added memory-related getter methods.,1
"KAFKA-3989; MINOR: follow-up: update script to run from kafka root…h-benchmarks/jmh.shAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2654 from bbejeck/KAFKA-3989_follow_up",1
[FLINK-15493][test] Add retry rule for all tests based on KafkaTestBase,3
#1067: I18N effort for dubbo code base - dubbo-rpc (part5),5
[FLINK-1432] [runtime] Make memory segment release robust against concurrent modifications of the collection,1
[FLINK-11442] Upgrade OSS SDK versionThis closes #7599.,2
[FLINK-6111] [py] Remove unnecessary sleeps,4
improve:speed up application start up time (#10109),1
"KAFKA-13100: Create KRaft controller snapshot during promotion (#11084)The leader assumes that there is always an in-memory snapshot at the lastcommitted offset. This means that the controller needs to generate an in-memorysnapshot when getting promoted from inactive to active.  This PR adds thatcode. This fixes a bug where sometimes we would try to look for that in-memorysnapshot and not find it.The controller always starts inactive, and there is no requirement that thereexists an in-memory snapshot at the last committed offset when the controlleris inactive. Therefore we can remove the initial snapshot at offset -1.We should also optimize when a snapshot is cancelled or completes, by deletingall in-memory snapshots less that the last committed offset.SnapshotRegistry's createSnapshot should allow the creating of a snapshot ifthe last snapshot's offset is the given offset. This allows for simpler clientcode. Finally, this PR renames createSnapshot to getOrCreateSnapshot.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
[FLINK-25266][tests] Disable StreamingKafkaITCase,3
"Fix when qos is disable,log will print every time. (#3397)* fix when qos is disable,log will print every time.* change qos server boos thread number 1",4
[hotfix] Remove unused TOTAL_FLINK_MEMORY_MB field,2
[FLINK-2550] [streaming] Allow multiple key/value states per operator on top of the new state backend,1
MINOR: Serialize state change logs for handling LeaderAndIsr and StopReplica requests (#8493)This patch moves the state change logger logs for handling a LeaderAndIsr/StopReplica request inside the replicaStateChangeLock in order to serialize the logs. This helps to tell apart per-partition actions of concurrent LAIR/StopReplica requests in cases where requests pile up waiting on the lock.Reviewer: Jun Rao <junrao@gmail.com>,2
DUBBO-582 decode时即使payload超出限制也要把当前message读完,5
MINOR: putting back kstream stateful transform methodsguozhangwang* added back type safe stateful transform methods (kstream.transform() and kstream.transformValues())* changed kstream.process() to voidAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #292 from ymatsuda/transform_method,5
The Hadoop Compatibility has been refactored and extended to support the new Java API.,1
[FLINK-3491] [tests] Prevent URIException in HDFSCopyTest and disable HDFSCopyUtilitiesTest on WindowsThis closes #1703,3
[hotfix] Clean up warnings in Serializers util class,2
[hotfix] [runtime] Fix a debug statement in StreamTask,0
"KAFKA-6166: Streams configuration requires consumer. and producer. in order to be read (#4434)* Implement method to get custom properties* Add custom properties to getConsumerConfigs and getProducerConfigs* Add testsReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-6930] [table] Forbid selecting window start/end on row-based Tumble/Slide windowsThis closes #4133,2
[FLINK-19653][hive] Reduce our dependency on hive runner for testsThis closes #14123,3
KAFKA-521 Missing files on last commit.git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1416254 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Fix JavaDoc warning (#7546)Reviewers: Bill Bejeck<bbejeck@gmail.com>,2
automatically append env parameters. (#4407),2
"KAFKA-9410; Make groupId Optional in KafkaConsumer (#7943)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Support long maxMessages in Trogdor consume/produce bench workers (#5957)Reivewers: Colin McCabe <cmccabe@apache.org>,1
[hotfix][core] Introduce divide operation to MemorySize,0
#992 add codecov component (#993),1
"MINOR: Fixed ConsumerRecord constructor javadocRefactoring of ConsumerRecord made in https://github.com/apache/kafka/commit/0699ff2ce60abb466cab5315977a224f1a70a4da#diff-fafe8d3a3942f3c6394927881a9389b2 left ConsumerRecord constructor javadoc inconsistent with implementation.This patch fixes ConsumerRecord constructor javadoc to be inline with implementation.Author: Stevo Slavić <sslavic@gmail.com>Reviewers: Ismael, GuozhangCloses #85 from sslavic/patch-3 and squashes the following commits:c289c4f [Stevo Slavić] MINOR: Fixed ConsumerRecord constructor javadoc",2
[FLINK-13404][table-api] Port csv descriptors & factories to flink-table-api-java-bridgeThis closes #9219,2
[FLINK-12800] Harden Tests when availableProcessors is 1This closes #8716.,3
KAFKA-4364: Remove secrets from DEBUG loggingleverage fix from KAFKA-2690 to remove secrets from task loggingAuthor: rnpridgeon <ryan.n.pridgeon@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2115 from rnpridgeon/KAFKA-4364,5
create basic project structure,1
[FLINK-7994][mesos] Remove effectively unused curator dependencyThis closes #4954.,1
MINOR: Fix JavaDocs markup (#8459)Reviewers: Bill Bejeck <bbejeck@gmail.com>,2
[hotfix] [table] Fix the misuse of assertEqualsThis closes #7190.,3
KAFKA-13287: Upgrade RocksDB to 6.22.1.1 (#11317)This commit upgrades RocksDB from 6.19.3 to 6.22.1.1Reviewer: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
[hotfix][runtime][test] Add missing checks in TaskExecutorProcessUtils.,1
"KAFKA-12663: Update FindCoordinator to support batch lookups (KIP-699) (#10743)This implements KIP-699: https://cwiki.apache.org/confluence/display/KAFKA/KIP-699%3A+Update+FindCoordinator+to+resolve+multiple+Coordinators+at+a+timeIt updates FindCoordinator request and response to support resolving multiple coordinators at a time. If a broker does not support the new FindCoordinator version, clients can revert to the previous behaviour and use a request for each coordinator.Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Sanjana Kaundinya <skaundinya@gmail.com>",5
Added basic memory views.O,1
Added broadcast variables to the PostPass and JobGraph generator.,4
[FLINK-20187][table-common] Fix factory discovering is failed when source and sink factories are not implemented in one classThis closes #14105,0
[FLINK-15065][docs] Correct default value of RocksDB options in documentationThis refer to https://github.com/facebook/rocksdb/pull/6123 which correctis RocksDB javadoc,2
[hotfix][table] Promote JoinedRowData to flink-table-common,2
"[FLINK-16537][network] Implement ResultPartition state recovery for unaligned checkpointDuring state recovery for unaligned checkpoint, the partition state should also be recovered besides with existing operator states.The ResultPartition would request buffer from local pool and then interact with ChannelStateReader to fill in the state data.The filled buffer would be inserted into respective ResultSubpartition queue in normal way.It should guarantee that op can not process any inputs before finishing all the output recovery to avoid mis-order issue.",0
[FLINK-1615] [java api] SimpleTweetInputFormatThis closes #621This closes #442,2
"Sorter with normalized keys, part 1",5
"MINOR: Added more basic concepts to the documentationAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Michael G. Noll, Matthias J. Sax, Guozhang WangCloses #2030 from enothereska/minor-kip63-docs",2
[FLINK-18866][python] Support filter() operation for Python DataStream API. (#13098),5
[FLINK-27428][core] Deduplicate #toDuration(Time),2
"MINOR: Fix wrong debug log message (#7137)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-13388][web][docs] Updated screenshots to ones taken from the new UI,1
MINOR: Word count should account for extra whitespaces between words (#10044)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[FLINK-953] Remove fake tail from iterationsThis closes #124,4
[FLINK-23055][docs][table] Add documentation for window tvf offset. (#17015),1
[FLINK-12408][python] Allow to define the data types in PythonThis closes #8420,5
Update commons-io artifact to same version as everywhere else.Use the new cooridnates for it.Fix a warning in pact-hbase/pom.xml.,5
kafka-1271; controller logs exceptions during ZK session expiration; patched by Jun Rao; reviewed by Guozhang Wang and Jay kreps,2
removed unnecessary config option,5
resolve conflicts,5
修改测试依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@106 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-25941][streaming] Only emit committables with Long.MAX_VALUE as checkpoint id in batch modeBefore this commit the SinkWriter and Committer operators emittedcommittables on endInput. This was troublesome because by doing so thecheckpointId was set to effectively Long.MAX_VALUE becausethe emission was not part of any checkpoint. With the completion ofFLIP-143 all jobs in streaming mode have a final checkpoint when theytransition to finish so we can rely on the normal checkpoint mechanismand only need endInput for the batch execution.,5
Adds new test classes and improves java doc,2
"Iteration head tasks are not merged with first operator in superstep, if there is a local strategy that needs to be executed directly prior to the first superstep.",1
[FLINK-16236][yarn][hotfix] fix YARNSessionFIFOSecuredITCase not loading the right security context factory,2
[FLINK-23999][table-planner] Support evaluating individual window table-valued function in planner (#17684),1
[FLINK-12414][runtime] Implement SchedulingTopology adapter,2
MINOR: Enable KRaft in transactions_test.py #11121Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
"[FLINK-20706][table-planner-blink] Introduce BatchPhysicalUnion, and make BatchExecUnion only extended from ExecNodeThis closes #14455",1
[hotfix][tests] Add missing import,2
[hotfix][tests] Simplify TaskManagerServices creation,1
[hotfix][yarn][test] Avoid using Mockito for NMClientAsync in YarnResourceManagerTest.,3
"[FLINK-16749][k8s] Support to set node selector for jobmanager and taskmanager podThe node-selector is a collection of key/value pairs to constrain a pod to only be able to run on particular node(s). Since affinity and anti-affinity are uncommon use case for Flink, so we leave the support in pod template.This closes #11500 .",1
Made support for spanning records configurable,5
[FLINK-2788] [apis] Add TypeHint class to allow type-safe generic type parsingThis closes #1744,1
[hotfix] Refactor JobArchiveFetcherTask#run,1
[FLINK-14734][runtime] Add a ResourceSpec in slot sharing group to describe the resources it needs overallIt’s updated automatically when vertices are added into or removed from the group.,4
[FLINK-2136] [streaming] Added test for scala DataStream,5
DUBBO-470 zookeeper注册中心添加empty协议条件错误,5
Refactored failure event table,0
[FLINK-14817][doc] Fix misleading documentation using method chaining of Configuration (#10323),5
DUBBO-489 修改owner逗号,5
[hotfix][table-planner] Fixed creating number literals in ExpressionParser,1
[docs] trivial typo in docker-flink/README.mdThis closes #1463.,2
[FLINK-27932][python] Introduce WatermarkStrategy.no_watermarks and WatermarkStrategy.no_watermarks to align with Java APIThis closes #19896.,2
Replace RpcStatus to count (#2984) (#3636),5
"KAFKA-7560; PushHttpMetricsReporter should not convert metric value to doubleCurrently PushHttpMetricsReporter will convert value from KafkaMetric.metricValue() to double. This will not work for non-numerical metrics such as version in AppInfoParser whose value can be string. This has caused issue for PushHttpMetricsReporter which in turn caused system test kafkatest.tests.client.quota_test.QuotaTest.test_quota to fail.Since we allow metric value to be object, PushHttpMetricsReporter should also read metric value as object and pass it to the http server.Author: Dong Lin <lindong28@gmail.com>Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5886 from lindong28/KAFKA-7560",5
[hotfix][scripts] Fix zookeeper quorum regex,0
"KAFKA-8500; Static member rejoin should always update member.id (#6899)This PR fixes a bug in static group membership. Previously we limit the `member.id` replacement in JoinGroup to only cases when the group is in Stable. This is error-prone and could potentially allow duplicate consumers reading from the same topic. For example, imagine a case where two unknown members join in the `PrepareRebalance` stage at the same time. The PR fixes the following things:1. Replace `member.id` at any time we see a known static member rejoins group with unknown member.id2. Immediately fence any ongoing join/sync group callback to early terminate the duplicate member.3. Clearly handle Dead/Empty cases as exceptional.4. Return old leader id upon static member leader rejoin to avoid trivial member assignment being triggered.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix] Fix confusing error message in TableSourceValidationThis closes #10263 .,5
"KAFKA-13228; Ensure ApiVersionRequest is properly handled KRaft co-resident mode (#11784)When brokers are co-resident with controllers using kraft, we incorrectly determine the supported API versions on the controller using `NodeApiVersions.create()`. The patch fixes the problem by using the versions from the sent `ApiVersions` request even when connecting to the local node.The patch also improves integration tests by adding support for co-resident mode.Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[hotfix][yarn][tests] Whitelist non-critical debug messages,0
[hotfix] Remove RPC timeouts from JobMasterService lifecycle methodsThe lifecycle methods should not have a RPC timeout. Instead the implementationsnow use the RpcUtils#INF_TIMEOUT as the timeout.,5
Code review (#3094)* movde compareTo into Configurator as a default method* adjust javado* optimize diamond* polish the code,1
[FLINK-13003][table-planner-blink] Support Temporal TableFunction Join in processing time and event timeThis closes #8901,1
MINOR: remove unneccessary `public` keyword from `Partitioner` interface (#10708)Reviewers: David Jacot <djacot@confluent.io>,5
[FLINK-26371][hive] Support variable substitution for sql statement while using Hive dialect (#19656),1
KAFKA-143 Fixing source code files to have the Apache license header ;patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1183191 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-8255] Throw meaningful exception when using string keys on row types,1
[FLINK-8915] CheckpointingStatisticsHandler fails to return PendingCheckpointStatsThis closes #5703.,0
KAFKA-2306: add another metric for buffer exhausted; reviewed by Guozhang Wang,1
[FLINK-1201] [gelly] use vertex/edge instead of tuples in the testfixed a few warnings in pagerank example,2
[3.0] revert AbstractConfiguratorListener#genConfiguratorsFromRawRule (#9248)* ignore event content parse failure* support single ip* revert genConfiguratorsFromRawRule,5
MINOR: Improve verification in flaky testPartitionReassignmentDuringDeleteTopic (#6460)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
[FLINK-13904][checkpointing] Encapsule and optimize the time relevant operation of CheckpointCoordinator,2
[FLINK-25432][runtime] Adds JobManagerRunnerRegistry and integrates it into the Dispatcher,1
[FLINK-3446] [runtime-web] Don't trigger back pressure sample for archived jobThis closes #1673.,1
Qos enhancement (#2153)* Not to accept foreign ip by default.* Log if fail to start qos server. #2046* Fix typo. No functional change.* Remove redundant declaration.* Sync dubbo.xsd to compact dubbo.xsd.* Simplify code and add comments.* Add log message if qos is not enabled.* Fix UT failure.,0
LogManager test fails on linux; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-220git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1298426 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-2268] Remove Writable support from Scala TypeInformation Macro,5
Remove obsolete Broadcast Variable Join example.,4
fixup! fixup! [FLINK-26762][docs] Document overdraft buffers,2
"[FLINK-19151][yarn] Update container resource normalization algorithm, with respect to Yarn FairScheduler.This closes #13347.",5
"KAFKA-3698; Update the message format section.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1375 from becketqin/KAFKA-3698",5
修改telnet的help信息git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@572 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"fixed computation of phase1, changed BinarySparseMatrix to a subclass of JsonNode",5
[FLINK-20031] Keep the UID of SinkWriter same as the SinkTransformationIn case we want to migrate the StreamingFileSink to the new Sink API wemight need to let user set the SinkWriter's uid same as theStreamingFileSink's. So that SinkWriter operator has the opportunity toreuse the old state. (This is just to keep the option open for now.)For this we need to let SinkWriter operator's uid is the same as theSinkTransformation.,1
"KAFKA-8774: Regex can be found anywhere in config value (#7197)Corrected the AbstractHerder to correctly identify task configs that contain variables for externalized secrets. The original method incorrectly used `matcher.matches()` instead of `matcher.find()`. The former method expects the entire string to match the regex, whereas the second one can find a pattern anywhere within the input string (which fits this use case more correctly).Added unit tests to cover various cases of a config with externalized secrets, and updated system tests to cover case where config value contains additional characters besides secret that requires regex pattern to be found anywhere in the string (as opposed to complete match).Author: Arjun Satish <arjun@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
[FLINK-12765][coordinator] Change the default resource spec to UNKNOWN,4
[hotfix][python] Rename the parameter from key_type_info to key_type for key_by,5
[FLINK-28993][table-planner] Fix adjusting join cost for dpp query pattern errorThis closes #20596,0
[FLINK-27735][testinfrastructure] Update testcontainers dependency to v1.17.2,3
[FLINK-22656] Fix typos,2
[hotfix] Simplify the lambda expression in TaskManagerRunner,1
KAFKA-2121; add missing file,2
[3.0] Statement lambda can be replaced with expression lambda (#8667)* Statement lambda can be replaced with expression lambda* format code,5
[hotfix][docs] fix formatting of release notes,0
[FLINK-28804][formats] Use proper stand-ins for missing metric groups,1
Fixed #192,0
[hotfix][docs] Fix code snippet with incorrect scala syntaxThis closes #16391,0
"[FLINK-12649][hive] Add a shim layer to support multiple versions of Hive MetastoreTo add shim layer for HMS client, in order to support different versions of HMS.This closes #8564.",1
"[FLINK-4379] [checkpoints] Introduce rescalable operator stateThis introduces the Operator State Backend, which stores state that is not partitionedby a key. It replaces the 'Checkpointed' interface.Additionally, this introduces CheckpointStateHandles as container for all checkpoint related state handlesThis closes #2512",0
"KAFKA-4750: Bypass null value and treat it as deletes (#4508)Here is the new rule for handling nulls:* in the interface store, put(key, null) are handled normally and value serde will still be applied to null, hence needs to handle null values* in the inner bytes store, null bytes after serialization will be treated as deletes.* in the interface store, if null bytes get returned in get(key), it indicate the key is not available; and hence serde will be avoided and null object will be returned.More changes:* Update javadocs, add unit tests accordingly; augment MockContext to set serdes for the newly added tests.* Fixed a discovered bug which is exposed by the newly added tests.* Use the new API to remove all old APIs in the existing state store tests.* Remove SerializedKeyValueIterator since it is not used any more.This is originally contributed by @evis.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian@confluent.io>",5
"MINOR: Remove unnecessary null checks (#4708)Remove unnecessary null check in StringDeserializer, MockProducerInterceptor and KStreamImpl.Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-11843] Remove unused dispatcher runner accessor from DispatcherResourceManagerComponent,1
[FLINK-21553][table-runtime-blink] Copy record if needed when flush window buffer records to stateThis closes #15081,2
[FLINK-1214] Prevent partitionings on subsets of fields from being pushed down,1
[FLINK-23052][ci] Improve stability of maven snapshot deployment,1
[FLINK-4490] [distributed coordination] (part 3) Rename methods on 'Instance' to have more intuitive namesgetResourceID() --> getTaskManagerID()getInstanceConnectionInfo() --> getTaskManagerLocation(),1
MINOR: Fix typos in docsAuthor: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Gwen ShapiraCloses #1003 from sasakitoa/Fix_typo_in_docs,2
[FLINK-3596] DataSet RelNode refactoring- remove the intermediate flink relnode layer and the dataset rules- move code generation from rules to DataSet nodes- remove unused DataSete nodes- move code generation from join rule to DataSetJoin node- merge DataSetMap and DataSetReduce into  DataSetAggregate,5
fix #6306.  support TypeBuilder sort (#6365)* fix #6306. support TypeBuilder sort* fix #6306. support TypeBuilder sort* fix #6306. support TypeBuilder sort* remove unused import* add license for test file,2
[hotfix][docs] do not include build scripts in content generation,2
[FLINK-14261] Add PermanentlyFencedRpcEndpointThis closes #9790.,1
[FLINK-15428][e2e] Skip Avro Confluent Schema Registry case when running with JDK11,1
"KAFKA-2389: remove commit type from new consumer.A shot to remove commit type from new consumer. The coordinator constructor takes a default offset commit callback mainly for testing purpose.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Guohang WangCloses #134 from becketqin/KAFKA-2389",3
"fix re-register can not work when curator session expires. (#5135)* fix re-register can not work when curator session expires.* Enhance zookeeper registry client recovery mechanism:1. Ignore connection event in children watcher.2. Fetch latest urls after connection recovery.* add same delete&create logic to createEphemeral(path, data)* remoting config from RegistryConfig and ConfigCenter both can take effect.",5
[FLINK-3580] [table] Implement FLOOR/CEIL for time pointsThis closes #2391.,2
"[FLINk-941] Place pipeline breakers for SingleInput nodes with broadcast variables, if needed.",4
Implemented first dummy version of lazy split assignment (must be replaced by more sophisticated version),5
[streaming] datastream added,1
"KAFKA-5849; Add process stop, round trip workload, partitioned test* Implement process stop faults via SIGSTOP / SIGCONT* Implement RoundTripWorkload, which both sends messages, and confirms that they are received at least once.* Allow Trogdor tasks to block until other Trogdor tasks are complete.* Add CreateTopicsWorker, which can be a building block for a lot of tests.* Simplify how TaskSpec subclasses in ducktape serialize themselves to JSON.* Implement some fault injection tests in round_trip_workload_test.pyAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4323 from cmccabe/KAFKA-5849",5
"KAFKA-7192: Wipe out if EOS is turned on and checkpoint file does not exist (#5421)1. As titled and as described in comments.2. Modified unit test slightly to insert for new keys in committed data to expose this issue.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-9737] [table] Make function validation optional,5
KAFKA-7880:Naming worker thread by task id (#6275)KAFKA-7880: Name worker thread to include task idChange Connect's `WorkerTask` to name the thread using the `task-thread-<connectorTaskId>` pattern.Reviewers: Randall Hauch <rhauch@gmail.com>,1
[FLINK-16857][table-planner-blink] Support partition prune by getPartitions of sourceThis closes #11560,1
[FLINK-1307] Excluded directories that match the file-filter from recursive descent.,2
[FLINK-8754][flip6] Make TaskManagerInfo implement SerializableThis closes #5566.,5
[FLINK-8101] [elasticsearch] Elasticsearch 6.X REST support,1
[FLINK-12526][runtime] Remove STATE_UPDATER in ExecutionGraphThis closes #10014.,5
[FLINK-3416] [py] Support for spaces in flink pathThis closes #1674.,2
"KAFKA-13767; Fetch from consumers should return immediately when preferred read replica is defined by the leader (#11942)When a replica selector is configured, the partition leader computes a preferred read replica for any fetch from the consumers. When the preferred read replica is not the leader, the leader returns the preferred read replica with `FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY)` to the `ReplicaManager`. This causes the fetch to go into in the fetch purgatory because the exit conditions are not met. In turns out that the delayed fetch is not completed until the timeout is reached because the delayed fetch ignores partition with an unknown offset (-1). If the fetch contains only one partition, the fetch is unnecessarily delayed by the timeout time (500ms by default) to only inform the consumer that it has to read from a follower.This patch fixes the issue by completing the fetch request immediately when a preferred read replica is defined.Reviewers: David Jacot <djacot@confluent.io>",5
[streaming] [scala] Restructured streaming scala project and examplesThis closes #275,5
[refactor] [tests] Generalize test handler generation,0
fix:#558 com.alibaba.dubbo.common.serialize.support.dubbo.Builder#newObjectBuilder 存在死循环的风险 (#589),1
[FLINK-17027] Introduce a new Elasticsearch 6 connector with new property keysThis closes #12184,5
coordinate spring and dubbo shutdown hook. (#5504),1
"KAFKA-8724; Improve range checking when computing cleanable partitions (#7264)This patch contains a few improvements on the offset range handling when computing the cleanable range of offsets.1. It adds bounds checking to ensure the dirty offset cannot be larger than the log end offset. If it is, we reset to the log start offset.2. It adds a method to get the non-active segments in the log while holding the lock. This ensures that a truncation cannot lead to an invalid segment range.3. It improves exception messages in the case that an inconsistent segment range is provided so that we have more information to find the root cause.The patch also fixes a few problems in `LogCleanerManagerTest` due to unintended reuse of the underlying log directory.Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jun Rao <junrao@gmail.com>",1
[FLINK-24051][connectors/kafka] Make groupId optional when constructing a KafkaSourceSetting a groupdId for the KafkaSource is often not necessary andcomplicates the setup for users that do not rely on specificsemantics which are implied by the groupId.,1
KAFKA-2944: Replaced the NPE with a nicer error and clean exit and added debug message to assist with figuring this out.…ssage to assist with figuring this out.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #993 from gwenshap/KAFKA-2944,5
[FLINK-3936] [tableAPI] Add MIN/MAX aggregation for Boolean.This closes #2035,1
[FLINK-2502] [storm compatibility] Fix FiniteStormSpout documenation rendering - added missing empty lines - additional minor improvementsThis closes #1002,1
[FLINK-25817] Add LocalRecoveryITCaseAdds an integration test for local recovery under process faults using the newlyintroduce working directory feature to persist state locally.,1
[hotfix] Harden JarDeleteHandlerTest test,3
[FLINK-9672] Fail fatally if job submission fails on added JobGraph signalThis closes #6213.,1
[FLINK-24186][table-planner] Allow multiple rowtime attributes for collect() and print()This closes #17217.,1
[FLINK-5618] [docs] Add intial queryable state page,1
Started work on tree creation,1
[FLINK-4589] [DataStream API] Fix Merging of Covering Window in MergingWindowSetThis also adds two new test cases for that problem.This closes #2476,0
[FLINK-7568] Change role of ProcessWindowFunction and WindowFunction in doc,2
"Merge pull request #3246 from cvictory:2.7.0-release remove gson from dubbo.jar in shading mode , and change to dependency way.* just for modify comments and imports* remove gson from dubbo.jar in shading mode, add dependency",1
[FLINK-23767][connectors] Add WatermarkOutput#markActive.The new method allows to quickly disable automatic watermark advancement when a partition becomes active but actually reading the data and extracting watermarks will be delayed.,4
"MINOR: Convert `ReassignPartitionsIntegrationTest` to KRaft (#12258)Updates relevant tests in `ReassignPartitionsIntegrationTest` for KRaft. We skip JBOD tests since it is not supported and we skip `AlterPartition` upgrade tests since they are not relevant.Reviewers: Kvicii <Karonazaba@gmail.com>, David Arthur <mumrah@gmail.com>",3
[FLINK-9697] Rename KafkaTableSource to KafkaTableSourceBase,2
MINOR: replace remove() with delete() after 5.0.1 RocksDB upgradeAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2380 from guozhangwang/KMinor-remove-deprecated-rocksDB,5
Fixed default configuration for Nephele cloud mode,5
[FLINK-23864][connector/pulsar] Release Pulsar Message if user enable poolMessage option.,0
[FLINK-24113] Refactor ApplicationDispatcherBootstrap#clusterShutdownFuture- rename to bootstrapShutdownFuture- simplify logic,2
DUBBO-163 没有dubbo.properties时不要打印WARN日志git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@791 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-5563] [gelly] Add density to vertex metricsThis closes #3167,1
[FLINK-20745][table] Clean useless codes: Never push calcProgram to correlateThis closes #14474,1
DUBBO-530 ExtensionLoader加载失败后，之后调用抛的异常没有当时调用的栈,5
[FLINK-4052] [runtime] Improve test stability for ConnectionUtilsTest,3
[FLINK-14494][docs] Regenerated config options documentation with type information,5
KAFKA-4145; Avoid redundant integration testing in ProducerSendTestsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1842 from vahidhashemian/KAFKA-4145,3
[FLINK-15868] Pin jackson-dataformat-yaml dependency to 2.10.1,5
move getExporterMap() to the abstract class,1
[streaming] Stratosphere version set to 0.6-SNAPSHOT,1
[hotfix] [tests] Add unit tests for ChildFirstClassLoader,3
[FLINK-3140] [table] NULL value data layout in Row Serializer/ComparatorThis closes #1465.,5
[FLINK-8772] [kafka] Fix missing log parameterThis closes #5574.,2
[FLINK-21519] Temporarily disable SQLClientHBaseITCase,2
[hotfix] Remove redundant keyword conversion when validating CLI args,5
[FLINK-14169][history-server] Refactor HistoryServerTest for reusability,3
[hotfix] Update release notes with changes to StreamStatusThis closes #17447,4
"KAFKA-2273; Sticky partition assignment strategy (KIP-54)This PR implements a new partition assignment strategy called ""sticky"", and it's purpose is to balance partitions across consumers in a way that minimizes moving partitions around, or, in other words, preserves existing partition assignments as much as possible.This patch is co-authored with rajinisivaram and edoardocomar.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1020 from vahidhashemian/KAFKA-2273",5
[FLINK-25696][datastream] Introduce metadataConsumer to InitContext in SinkThis closes #18412,5
"MINOR: Cleanup admin creation logic in integration tests (#11790)There seemed to be a little sloppiness in the integration tests in regard to admin client creation. Not only was there duplicated logic, but it wasn't always clear which listener the admin client was targeting. This made it difficult to tell in the context of authorization tests whether we were indeed testing with the right principal. As an example, we had a method in TestUtils which was using the inter-broker listener implicitly. This meant that the test was using the broker principal which had super user privilege. This was intentional, but I think it would be clearer to make the dependence on this listener explicit. This patch attempts to clean this up a bit by consolidating some of the admin creation logic and making the reliance on the listener clearer.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
[FLINK-3602] Fix TypeExtractor and add support for recursive typesThis closes #1787,1
- fixed minor typos in inline documentation,2
DUBBO-465 增加单元测试,5
kafka-937; delta patch; ConsumerFetcherThread can deadlock; patched by Jun Rao; reviewed by Joel Koshy,5
KAFKA-14160: Streamline clusterId retrieval in Connect (#12536)Cache the Kafka cluster Id once it has been retrieved to avoid creating many Admin clients at startup.Reviewers: Chris Egerton <fearthecellos@gmail.com>,1
"[FLINK-16383][task] Do not relay notifyCheckpointComplete to closed operators.Through StreamOperatorWrapper an operator may already be closed while the StreamTask is still running. Notification might be relayed in that time from the task to the closed operator causing issues on operators reacting on completed checkpoints, such as two phase commit sinks.This commit adds the information of the closing to the wrapper and avoids relaying notifications to closed operators.Also fixes a potential related issue in SubtaskCheckpointCoordinatorImpl#takeSnapshotSync.",0
[hotfix] [streaming] Fix type extraction for joined streams.This closes #2755.,4
[FLINK-28250][Connector/Kafka] Fix exactly-once Kafka Sink out of memory,0
[FLINK-6711] Activate strict checkstyle for flink-connector-kafka*,2
KAFKA-901 follow up changes to fix update metadata response handling and request logging,2
"[FLINK-9402] [kinesis] Kinesis consumer configuration requires either region or endpoint.Fix validation logic to allow either region or endpoint, but not both.This closes #6045.",1
[streaming] CoRecordReader and iterator added + ConnectedDataStream refactor,4
[hotfix] Outdated comment in FileInputFormat.javaThis closes #7882,2
Merge branch 'master' of https://git-wip-us.apache.org/repos/asf/flink into asf_master,2
[FLINK-16961][cassandra] Bump Netty to 4.1.44,2
"KAFKA-8341. Retry Consumer group operation for NOT_COORDINATOR error (#6723)An API call for consumer groups must send a FindCoordinatorRequest to find the consumer group coordinator, and then send a follow-up request to that node.  But the coordinator might move after the FindCoordinatorRequest but before the follow-up request is sent.  In that case we currently fail.This change fixes that by detecting this error and then retrying.  This fixes listConsumerGroupOffsets, deleteConsumerGroups, and describeConsumerGroups.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Boyang Chen <bchen11@outlook.com>",4
Remove incubator (#4161),4
[FLINK-19394][docs-zh] Translate the 'Monitoring Checkpointing' page of 'Debugging & Monitoring' into Chinese,0
"KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs (#8812)1. Don't advance recovery point in `recoverLog` unless there was a cleanshutdown.2. Ensure the recovery point is not ahead of the log end offset.3. Clean and flush leader epoch cache and truncate produce state managerif deleting segments due to log end offset being smaller than log startoffset.4. If we are unable to delete clean shutdown file that exists, mark thedirectory as offline (this was the intent, but the code was wrong).Updated one test that was failing after this change to verify the new behavior.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-19630][hive][doc] Make bundled hive jar the recommended way to add dependenciesThis closes #14131,1
[FLINK-6779] [scala] Activate strict checkstyleThis closes #4030,2
"KAFKA-7793: Improve the Trogdor command line. (#6133)* Allow the Trogdor agent to be started in ""exec mode"", where it simplyruns a single task and exits after it is complete.* For AgentClient and CoordinatorClient, allow the user to pass the pathto a file containing JSON, instead of specifying the JSON object in thecommand-line text itself.  This means that we can get rid of the bashscripts whose only function was to load task specs into a bash stringand run a Trogdor command.* Print dates and times in a human-readable way, rather than as numbersof milliseconds.* When listing tasks or workers, output human-readable tables ofinformation.* Allow the user to filter on task ID name, task ID pattern, or taskstate.* Support a --json flag to provide raw JSON output if desired.Reviewed-by: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
[hotfix] Let S3EntropyFsFactoryTest extend from TestLogger,3
[FLINK-27287][tests] Use random ports,1
[FLINK-11363][tests] Port TaskManagerConfigurationTest to new code base.,1
[FLINK-2846] [streaming] Emit downstream checkpoint barriers at beginning of the checkpoint scope,2
[FLINK-3667] delay connection to JobManager until job execution- lazily initialize ActorSystem- make sure it is not created before job execution- print connection information on the CLIThis closes #2189,5
[FLINK-19777][table-runtime-blink] Fix NullPointException for WindowOperator.close()This closes #13768,1
Fixed boolean coercion; made boolean constants immutable,0
"[FLINK-25792][connectors] Changed repeated yielding in write to non blocking flush after complete request, changed tests so that the mailbox thread is cleared before each write().",3
MINOR; Synchronize access to snapshots' TreeMap (#12464)Read and write access to the TreeMap in snapshots needs to be synchronized.Reviewers: David Arthur <mumrah@gmail.com>,5
[docs] Add FAQ entry about scala implicits error when missing imports,2
[FLINK-8475][config][docs] Integrate HA optionsThis closes #5467.,5
"MINOR: Modify Connect service's startup timeout to be passed via the init (#5882)Currently, the startup timeout is hardcoded to be 60 seconds in Connect's test service. Modifying it to be passable via init. This can safely be backported as well.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[storm-compat] Added Storm compatibility word count examples,1
"[FLINK-13402][table] Copy RelOptCluster to flink planner to fix ""RelOptCluster's constructor can not be accessed when connector depends on both planners""This closes #9215",0
[hotfix] Fix checkstyle violations in Execution,0
[FLINK-5756] [rocksdb] Add mini benchmarks to reproduce 'merge' performance problems,0
"[FLINK-16641][network] (Part#4) Release all allocated floating buffers of RemoteInputChannel on receiving any channel blocking event if the exclusive credit is 0This patch tries to release all allocated floating buffers of RemoteInputChannel on receiving any channel blocking event if the exclusive credit is 0 because a blocked channel does not need any credit and after that, these released credits can be used by other active channels. This can avoid the deadlock where credits are assigned to channels which do need them and those channels who need credits can not get any when the exclusive credit is 0.",2
fix register config not take effect because of url simplified (#4397),1
[FLINK-24670][docs] Restructure unaligned checkpoints docs to checkpointing under backpressure,2
[FLINK-10869] [build] Remove outdated secrets from travis buildThe secrets are replaced with build server environment variables.,5
Fixed bug where null parameter arrays are passed to the user code.,1
"KAFKA-13449: Comment optimization for parameter log.cleaner.delete.retention.ms (#11505)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
[FLINK-25714][runtime-web] upgrade ng-zorro-antd and remove unnecessary dependency,4
[FLINK-16608][python] Support TimeType in vectorized Python UDF,1
[FLINK-15411][hive] Fix listPartitions in HiveCatalog & Add time prune partition tests,3
"fix #3179. Make registry, configcenter, matadata-report share a zooke… (#3182)* fix #3179. Make registry, configcenter, matadata-report share a zookeeper connection* fix #3179. optimize registry, configcenter, matadata-report share a zookeeper connection* fix #3179. add licence* fix some review issue: just optimize constuctor order and refactor some code* modify HashMap to ConcurrentHashMap* add some comments* remove ZookeeperClientData and originalURLs* remove ZookeeperClientData and originalURLs* fix #3205 . add group into MetadataReport* remove SOURCE_URL_KEY from Constants* fix #3179 , #3205, #3218.  modify review issue; when sharing zookeeper connection, it should judge zookeeperClient.isConnected()",0
[hotfix][doc] fix typo in java doc.,2
DUBBO-515 Parser类类型判断条件错误,5
"[3.0] New service repository support for multi instance (#8669)* Add ExtensionDirector and Models* Fix access static getter method of ApplicationModel* Replace ExtensionFactory with ExtensionInjector* specify scope of some SPIs* Support scoped injection for extension* improve create extension loader logic* Add ScopeModel and ScopeBeanFactory, fix extension initialization of XxxConfig* polish doc of scope model* Extract FrameworkStatusReportService from FrameworkStatusReporter* Fix application model of default bootstrap instance* Pass scope model through URL* Fix scope model of registry, metadata, cluster and so on* exact ServiceModel from ProviderModel and ConsumerModel* Add ASF license header for ScopeBeanFactoryInitializer* Remove unused import* Remove unused import* Fix ut in ConfigManagerTest* Change default Scope Behave* Resolve recursive creation of Scope Model* Fix inject default model when scope is parent* Fix inject default model when scope is parent* Compact with url without ScopeModel* Change HttpBinder Scope* Change some SPIs' scope* Fix setApplicationModel override issue of MetadataServiceNameMapping* Default inject ScopeModel in ConfigManager* Add default Scope for AbstractConfig when init* Fix field override & Fix ut env* Fix zk not startup in DubboBootstrapMultiInstanceTest* Fix ExtensionAccessor not inject in UT of MetricsFilterTest* Compact old style getName* Fix UT in DNSServiceDiscoveryTest* Compact old style ApplicationModel* Fix UT in DNSServiceDiscoveryTest* Fix repository changed after ApplicationModel destroyed* Fix SpringExtensionInjector pollution in UT* Pass ApplicationModel in ServiceInstance* reintroduce metadata delay key* Add Transient on ApplicationModel getter of DefaultServiceInstance* Fix Configurator Listener in Singleton mode override issue* Fix Configurator Listener in Singleton mode override issue* Compact old style getApplication* Invocation pass ServiceModel* Compact old style registerConsumer* Fix NPE in RpcInvocation* Add ServiceModel pass when init* Fix ServiceModel cast error* Add ServiceModel pass when invoke* Fix NPE when simplify registry url* Revert ""Resolve recursive creation of Scope Model""This reverts commit 37a99957* Improve scope model aware* polish scope model* Cleanup ApplicationModel.defaultModel usage* Fix ut* Compatible with 2.6 Registry* Fix ut* Add Callback Service build ProviderModel* improve scope model of config bean* Fix scope model of reference/service model* Revert CallbackServiceCodec for dev* Fix scope model NPE* Fix consumer url NPE* Add Callback Service build ProviderModel* Fix NPE when destroy* Fix ut* pick from Add Callback Service build ProviderModel (b47b2777f9125cd7a0084cd211d4afa282e226b4)* add failback logic for ut* Fix ut* Add Scope Model check* Fix adaptive spi extension loading* update adaptive classes* Split ServiceRepository* Fix apache license* Fix UT* Fix uts* Fix DubboCodec* Fix ut in DubboBootstrapTest* Fix ut in DubboBootstrapTest* Suspend register duplicate providers error* Improve get unwrapped extension* Fix GenericServiceTest* Destroy all protocols in DubboBootstrap.reset()* Add --no-snapshot-updates and -fae for test fail safe* Fix uts* Reset ApplicationModel Before Test* Improve scope model initialization* Support instantiating spi/bean constructor with scope model parameters* change to fail never mode (-fn)* get unwrapped instance of DubboProtocol* Change referenced config's scope model after scope model changed* Change referenced config's scope model after scope model changed* Fix NPE of setScopeMode* change to fail-at-end (-fae) mode* Fix change scope model error* Avoid duplicate destroy model* Fix LocalCallMultipleReferenceAnnotationsTest* Avoid injection bean type of java.lang.Object* change to fail fast modeCo-authored-by: Albumen Kevin <jhq0812@gmail.com>",0
dubbo-maven指定javadoc-plugin版本,2
KAFKA-1326 Refactor Sender to support consumer.,1
[FLINK-20629][kinesis] Migrate from DescribeStream to DescribeStreamSummaryThis closes #14406.,2
"changed method signature of EvaluationExpression>>evaluate(), this method is now able to take a target node which will be reused if possible",1
"MINOR: Use new consumer API timeout in test (#5217)The old timeout configs no longer take effect, as of53ca52f855e903907378188d29224b3f9cefa6cb. They are replacedby the new one.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-25908][runtime][security] Add HadoopFSDelegationTokenProvider,1
[FLINK-1286] [APIs] [runtime] Fix serialization in CollectionInputFormat and generate meaningful error messages,0
"[hotfix] Add a production factory method for MemoryManager, use builder in tests",3
[FLINK-24781][table-planner] Refactor cast of literals to use CastExecutorSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17800.,2
[FLINK-2479] Refactor runtime.operators.* testsThis closes #1160,3
"MINOR: Use Java 11 for generating aggregated javadoc in release.py (#10399)Java 11 generates html5 pages with search support, which provides a better user experience.Fixed `get_jdk` bugs found during testing and updated `release.py` blurb to indicate thatboth JDK 8 and JDK 11 are required to perform a release.Tested by running `python2 release.py stage-docs`, which triggers the `aggregateJavadoc`path without some of the undesired (for testing) release steps.Reviewers: John Roesler <vvcephei@apache.org>",3
[FLINK-28609][Connector/Pulsar] PulsarSchema didn't get properly serialized. (#20698),1
MINOR: Improve log warning to include the log nameAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3562 from ijuma/tweak-log-warning,2
[streaming] explicit output flushing readded + need fix,0
"MINOR: fix package name in integration test (#10400)Change package name of IntegrationTestUtils ,TransactionsWithMaxInFlightOneTest, ControllerContextTest and DefaultMessageFormatterTest to kafka.server since we set the package name to kafka.xxx in all other classes.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
[FLINK-2209] [docs] Document linking with jars not in the binary dist,2
cloud manager amazon API (EXPERIMENTAL),5
[FLINK-26295][table-planner] Parse strategies should allow spaces between operation and semicolonThis closes #18874.,1
"KAFKA-6871: KStreams Scala API: incorrect Javadocs and misleading parameter name (#4971)Reviewer: Matthias J. Sax <matthias@confluent.io>, Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[hotfix][ci] Update libssl download link,2
"Improve kafka client sensor registration performance by lazily calculating JMX attributesWhen any metric (e.g. per-partition metric) is created or deleted,registerMBean() is called which in turn calls getMBeanInfo().getClassName().However, KafkaMbean.getMBeanInfo() instantiates an array of all sensors eventhough we only need the class name. This costs a lot of CPU to registersensors when consumer with large partition assignment starts. For example, ittakes 5 minutes to start a consumer with 35k partitions. This patch reduces theconsumer startup time seconds.Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Satish Duggana <satish.duggana@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5011 from radai-rosenblatt/fun-with-jmx",5
[FLINK-6466] [build] Build Hadoop 2.8.0 convenience binariesUpdate Hadoop versions and replace Hadoop 2.3 with 2.8 in build andcontinuous integration scripts. flink-yarn-tests can now be enabled forall supported Hadoop versions and is made non-optional.This closes #3832,1
[FLINK-942] Fix bug in config.sh to correctly set user-specified JVM argsThis closes #22,1
[hotfix][task] Log when AsyncCheckpointRunnalbe starts executing (with the execution delay),1
[FLINK-22329][hive] Inject current ugi credentials into jobconf when in hive connectorThis closes #15653,5
MINOR: Initialize ConnectorConfig constructor with emptyMap and avoid instantiating a new Map (#9603)The map passed as an argument remains read-only and therefore can be initialized using Collections#emptyMap instead of being passed a new Map instance. Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
"Merge pull request #3099, polish code, avoid dup code.",1
remove author,4
[FLINK-16015][filesystems]Throw an error when a plugin for a known scheme is missing.The error also avoid Hadoop fallback being used for s3 or other directly supported schemes.Also added a config to allow overridden this check for specific schemes.,1
[FLINK-8961][tests] Add MiniClusterResource#getClientConfiguration,5
[streaming] default signature added to operators,1
[FLINK-8349] [flip6] Remove Yarn specific commands from YarnClusterDescriptorRemove Yarn specific commands from YarnClusterDescriptor. This is a preparationalstep to make the FlinkYarnSessionCli work with the Flip-6 RestClusterClient.This closes #5229.,1
KAFKA-13868: Replace YouTube embedded video with links on streams page (#12438)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
[FLINK-6703][docs] Document how to take a savepoint on YARNThis closes #4721.,2
[hotfix] Extract common logic of getting CheckpointingMode as StreamingJobGraphGenerator#getCheckpointingMode,1
Fix ContentTypeId conflict (#3967)* fix ContentTypeId conflict* modify* modify avro id,5
[FLINK-14762][client] Implement JobClient#triggerSavepoint,2
MINOR: Temporarily disable testLogStartOffsetCheckpointIt's failing often and it seems like there are multiplereasons. PR #4238 will re-enable it.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4262 from ijuma/temporarily-disable-test-log-start-offset-checkpoint,3
Fixed bug in PactRecord (case columns % 8 == 0),0
[FLINK-7831] Make last received heartbeat retrievableThis commit adds functionality to retrieve the last received heartbeat fromthe HeartbeatManager.This closes #4817.,1
MINOR: Test SASL authorization idAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3766 from rajinisivaram/MINOR-sasl,5
MINOR: Next release will be 1.0.0Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3580 from ijuma/bump-to-1.0.0-SNAPSHOT,5
HOTFIX: Check JoinWindow boundariesguozhangwangAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1575 from mjsax/hotfix2,0
[FLINK-28388][docs][tests] Fix documentation buildThis closes #20189.,2
[FLINK-20278][Python] Throw a meaningful exception if the Python DataStream API job executes in batch modeThis closes #14164.,5
[hotfix][docs] Fix overlapping text,0
[hotfix][streaming] Fix and simplify PrintSinkFunctionTestPreviously PrintSinkFunctionTest was testing incorrectly for System.err. setTargetToStandardErr was beingcalled after opening PrintSink so it didn't have any effect.This commit also reduce code duplication and get rids of mockito usage in this test.,3
[hotfix][legal] Fix kinesis-data-streams licensing,5
[hotfix] Clean broadcast functions when translating.This closes #5477.,1
[hotfix][typo]Fix typo in task_lifecycle docsThis closes #12068,2
[streaming] Removed record fail from invoke,0
[FLINK-26520][table] Implement SEARCH operator in codegenImplements the SEARCH operator in the codegen and removesthe scalar implementation of IN and NOT_IN. Now every scalarIN/NOT_IN using a constant set is implemented through SEARCH(following Calcite's development on the topic CALCITE-4173)and plans will only have SEARCH.This closes #19001.,1
[FLINK-6879] [runtime] Activate checkstyle for runtime/memoryThis closes #4097,1
[streaming] Implemented AckEvent and FailEvent serialization,0
DUBBO-261 SimpleMonitor增加Unregister和Unsubscribe按钮git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1218 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"- removed example job launchers, use pact-clients instead",1
Fix curator5 compatibility (#9749)fixes #9738,0
"fix: StringUtils.split(String, char) not correct for input ""d,1,2,4"", 'a' (#5460)",0
"start to use ClusterConstants, MonitorConstants (#4045)",1
[hotfix] Fix processing time triggering on Window OperatorBefore it would only trigger if expectedTime < time. Now it isexpectedTime <= time.,1
[FLINK-16293] Document using plugins in Docker and KubernetesThis closes #11228.,3
"KAFKA-9432:(follow-up) Set `configKeys` to null in `describeConfigs()` to make it backward compatible with older Kafka versions.- After #8312, older brokers are returning empty configs,  with latest `adminClient.describeConfigs`.  Old brokers  are receiving empty configNames in `AdminManageer.describeConfigs()` method. Older brokers does not handle empty configKeys. Due to this old brokers are filtering all the configs.- Update ClientCompatibilityTest to verify describe configs- Add test case to test describe configs with empty configuration KeysAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #9046 from omkreddy/KAFKA-9432",5
[FLINK-20262] Building flink-dist docker image does not work without python2,1
[FLINK-21488][connectors/jdbc] Use JobID in XA global transaction ID,1
removed tail from ArraySchema,4
- disabled failing test case and opened ticket for fix,0
Started to refactored routing layer,4
Cleaned up Imports and warnings.,2
"KAFKA-7798: Expose embedded clientIds (#6107)Reviewers: Damian Guy <damian@confluent.io>, John Roesler <john@confluent.io>, Boyang Chen <bchen11@outlook.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
Added new Nodetypes,1
fix monitor filter: consumer side elapsed time is negative (#5705),0
[hotfix][yarn-tests] Fixes path definition for local YARN-test working directory artifact collection,1
[FLINK-6337][network] Remove the buffer provider from PartitionRequestServerHandlerThe buffer provider is not needed and most likely a left over from priorrefactorings.This closes #3785.,4
[streaming] WindowedWordCount Refactor,4
[FLINK-15689][table] Configure ExecutionEnvironment from BatchTableEnvironment,5
[FLINK-9807][tests] Parameterize EventTimeWindowCheckpointITCase & LocalRecoveryITCaseThis closes #6305.,1
"[Dubbo-2423] Multicast demo fails with message ""Can't assign requested address"". (#3317)* Fix #2423, Multicast demo fails with message ""Can't assign requested address""* temporarily disable ipv6 test",3
[FLINK-19616][tests][parquet] avoid re-generate the protobuf files due to time inconsistency,2
[FLINK-12732] [state-processing-api] Document reader for the State Processing API,2
Improved robustness of network transfers when receiver has already died,1
[FLINK-893] Inconsistent Iteration Step Function gives nonesense error messageI adjusted the error message.Author: Markus Holzemer <markus.holzemer@gmx.de>Closes #50 from markus-h/iteration_translation_exception and squashes the following commits:34a6f87 [Markus Holzemer] adjusted error message when encountering a translation failure for iterations,0
"MINOR: Fix ProcessorTopologyTestDriver to support multiple source topicsThere's a minor bug in ProcessorTopologyTestDriver that prevents it from working with a topology that contains multiple sources.  The bug is that ```consumer.assign()``` is called while looping through all the source topics, but, consumer.assign resets the state of the MockConsumer to only consume from the topics passed in.  This patch fixes the issue by calling consumer.assign once with all the TopicPartition instances.  Unit test (testDrivingSimpleMultiSourceTopology) included.This contribution is my original work and I license the work to the project under the project's open source license.Author: Mathieu Fenniak <mathieu.fenniak@replicon.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1782 from mfenniak/ProcessorTopologyTestDriver-multiple-source-bugfix",3
[FLINK-4354] [heartbeat] Add heartbeats between the ResourceManager and TaskExecutor,1
make telnet config work again (#2925),1
check-in due to branch switch,5
[FLINK-19331][state-processor-api] Native resource leak when working with RocksDBThis closes #13445,5
[FLINK-12253][table-common] Add a FLOAT type,1
[FLINK-19124][datastream] Remove ClassLoader parameter from JobClient methods,2
[FLINK-17878][fs-connector] Transient watermark attribute should be initial at runtime in streaming file operatorsThis closes #12293,1
"KAFKA-6738: Implement error handling for source and sink tasks (KIP-298)This PR implements the features described in this KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-298%3A+Error+Handling+in+ConnectThis PR changes the Connect framework to allow it to automatically deal with errors encountered while processing records in a Connector. The following behavior changes are introduced here:**Retry on Failure**: Retry the failed operation a configurable number of times, with backoff between each retry.**Task Tolerance Limits**: Tolerate a configurable number of failures in a task.We also add the following ways to report errors, along with sufficient context to simplify the debugging process:**Log Error Context**: The error information along with processing context is logged along with standard application logs.**Dead Letter Queue**: Produce the original message into a Kafka topic (applicable only to sink connectors).New **metrics** which will monitor the number of failures, and the behavior of the response handler are added.The changes proposed here **are backward compatible**. The current behavior in Connect is to kill the task on the first error in any stage. This will remain the default behavior if the connector does not override any of the new configurations which are provided as part of this feature.Testing: added multiple unit tests to test the retry and tolerance logic.Author: Arjun Satish <arjun@confluent.io>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5065 from wicknicks/KAFKA-6378",5
[hotfix] [tests] Speed up queryable state IT tests by removing sleep,4
[FLINK-14958][table] ProgramTargetDescriptor#jobID can be of type JobIDThis closes #10505 .,1
KAFKA-3916; Check for disconnects properly before sending from the controllerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1734 from hachikuji/KAFKA-3916,5
[docs] Fixes broken link in FlinkML docs,2
"KAFKA-10199: Further refactor task lifecycle management (#12439)1. Consolidate the task recycle procedure into a single function within the task. The current procedure now becomes: a) task.recycleStateAndConvert, at end of it the task is in closed while its stateManager is retained, and the manager type has been converted; 2) create the new task with old task's fields and the stateManager inside the creators.2. Move the task execution related metadata into the corresponding TaskExecutionMetadata class, including the task idle related metadata (e.g. successfully processed tasks); reduce the number of params needed for TaskExecutor as well as Tasks.3. Move the task execution related fields (embedded producer and consumer) and task creators out of Tasks and migrated into TaskManager. Now the Tasks is only a bookkeeping place without any task mutation logic.4. When adding tests, I realized that we should not add task to state updater right after creation, since it was not initialized yet, while state updater would validate that the task's state is already restoring / running. So I updated that logic while adding unit tests.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
[FLINK-20130][core] Add ZStandard to FileInputFormat,2
[hotfix][table] Code cleanup: use new methods introduced in FLIP-84 instead of deprecated methods,1
"KAFKA-13598: enable idempotence producer by default and validate the configs (#11691)In v3.0, we changed the default value for `enable.idempotence` to true, but we didn't adjust the validator and the `idempotence` enabled check method. So if a user didn't explicitly enable idempotence, this feature won't be turned on. This patch addresses the problem, cleans up associated logic, and fixes tests that broke as a result of properly applying the new default. Specifically it does the following:1. fix the `ProducerConfig#idempotenceEnabled` method, to make it correctly detect if `idempotence` is enabled or not2. remove some unnecessary config overridden and checks due to we already default `acks`, `retries` and `enable.idempotence` configs.3. move the config validator for the idempotent producer from `KafkaProducer` into `ProducerConfig`. The config validation should be the responsibility of `ProducerConfig` class.4. add an `AbstractConfig#hasKeyInOriginals` method, to avoid `originals` configs get copied and only want to check the existence of the key. 5. fix many broken tests. As mentioned, we didn't actually enable idempotence in v3.0. After this PR, there are some tests broken due to some different behavior between idempotent and non-idempotent producer.6. add additional tests to validate configuration behaviorReviewers: Kirk True <kirk@mustardgrain.com>, Ismael Juma <ismael@juma.me.uk>, Mickael Maison <mimaison@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix][table-api-java][javadoc]fix and unified the example JavaDoc for most DSL methods of Table class,2
[FLINK-16344][table-planner-blink] Preserve nullability for nested typesAvoids errors due to incompatible types during planning by preservingthe nullability attributes of nested types.This closes #11260.,0
"KAFKA-13083: Fix KRaft ISR in createPartitions, createTopicsWhen creating a new topic or partition via a manual partition assignment, wemust check if the nodes are unfenced before adding them to the new ISR.We also need to reject attempts to create a new partition with all fencednodes.Reviewers: David Arthur <mumrah@gmail.com>",1
[FLINK-22726][hive] Support grouping__id in hive prior to 2.3.0This closes #15983,1
"Added HBase table formats (patch by Marcus, slightly adjusted).",1
Added bulk copy methods to memory segment.,1
"[FLINK-3681] [cep, typeextractor] Generalize TypeExtractor to support more lambdasThe TypeExtractor.getUnaryOperatorReturnType and TypeExtractor.getBinaryOperatorReturnTypemethods have been extended to support positional arguments for the input types. This allowsto support parameterized types as Java 8 lambda arguments where the input type is not specifiedby the first type argument (e.g. Map<String, T>). This also solves the problem that the CEPlibrary did not support Java 8 lambdas as select functions.This closes #1840.",1
"[FLINK-16694] Run test_resume_externalized_checkpoints.sh with 15 min test timeoutIn order to harden test_resume_externalized_checkpoints.sh, it is now run with a 15 min test timeoutwhich will make the logs accessible in case of a stalling test.This closes #12530.",3
[FLINK-8547][network] Implement CheckpointBarrierHandler not to spill data for exactly-onceThis closes #5400.,5
[FLINK-1201] [gelly] cloned spargel classes,2
"KAFKA-13414: Replace Powermock/EasyMock by Mockito in connect.storage (#11450)I've skipped the following classes as they use powermock to stub/access private and static fields/methods:- KafkaConfigBackingStoreTest- KafkaOffsetBackingStoreTestThose will require some refactoring and will be updated in a separate PR.Reviewers: Tom Bentley <tbentley@redhat.com>, dengziming <dengziming1993@gmail.com>",5
Fixed #477 修复dubbo-admin添加动态配置后启用后不能删除,0
"KAFKA-4902; Utils#delete should correctly handle I/O errors and symlinksAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2691 from cmccabe/KAFKA-4902",5
"KAFKA-12945: Remove port, host.name and related configs in 3.0 (#10872)They have been deprecated since 0.10.0. Full list of removes configs:* port* host.name* advertised.port* advertised.host.nameAlso adjust tests to take the removals into account. Some tests wereno longer relevant and have been removed.Finally, took the chance to:* Clean up unnecessary usage of `KafkaConfig$.MODULE$` inrelated files.* Add missing `Test` annotations to `AdvertiseBrokerTest` andmake necessary changes for the tests to pass.Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-5949; User Callback Exceptions need to be handled properly - catch user exception in user callback (TimestampExtractor, DeserializationHandler, StateRestoreListener) and wrap with StreamsExceptionAdditional cleanup: - rename globalRestoreListener to userRestoreListener - remove unnecessary interface -> collapse SourceNodeRecordDeserializer and RecordDeserializer - removed unused parameter loggingEnabled from ProcessorContext#registerAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3939 from mjsax/kafka-5949-exceptions-user-callbacks",1
Implement superstep abstraction on Nephele readers/writers.Cleanup Nephele readers/writers.,4
[hotfix][python] Fix the module name of the entrypoint in pyflink-udf-runner.bat (#13848),2
DUBBO-277 Nonda和Dubbo配置集成git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1609 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][runtime] Code style clean-up for TaskExecutorResourceUtilsTest,3
java8 compat,5
[FLINK-22345][coordination] Catch pre-mature state restore for Operator Coordinators,1
"KAFKA-2640; Add tests for ZK authenticationI've added a couple of initial tests to verify the functionality. I've tested that the JAAS config file loads properly and SASL with DIGEST-MD5 works with ZooKeeper.Author: Flavio Junqueira <fpj@apache.org>Author: flavio junqueira <fpj@apache.org>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #324 from fpj/KAFKA-2640",1
DUBBO-458 空集合时处理group=*和version=*,5
[FLINK-15686][sql-client] Use old type system in CollectStreamTableSink,5
"[FLINK-2314] Make Streaming File Sources PersistentThis commit is a combination of several commits/changes. It combineschanges to the file input formats and the streaming file read operatorand integrates them into the API.These are the messages of the other two commits:[FLINK-3717] Make FileInputFormat checkpointableThis adds a new interface called CheckpointableInputFormatwhich describes input formats whose state is queryable,i.e. getCurrentState() returns where the reader isin the underlying source, and they can resume reading froma user-specified position.This functionality is not yet leveraged by current readers.[FLINK-3889] Refactor File Monitoring SourceThis is meant to replace the different filereading sources in Flink streaming. Now there isone monitoring source with DOP 1 monitoring adirectory and assigning input split to downstreamreaders.In addition, it makes the new features added byFLINK-3717 work together with the aforementioned entities(the monitor and the readers) in order to havefault tolerant file sources and exactly once guarantees.This does not replace the old API calls. Thiswill be done in a future commit.",2
[docs] Add description and illustration of checkpointing mechanism.,1
DUBBO-365 修改Validation测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1721 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-5368: Add test for skipped-records metric (#4365)* KAFKA-5368: Add test for skipped-records metricReviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-12233: Align the length passed to FileChannel by `FileRecords.writeTo` (#9970)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"MINOR: Fix system test StreamsCooperativeRebalanceUpgradeTest.test_upgrade_to_cooperative_rebalance (#11532)Log messages were changed in the AssignorConfiguration (#11490) that arealso used for verification in system testStreamsCooperativeRebalanceUpgradeTest.test_upgrade_to_cooperative_rebalance.This commit fixes the test and adds comments to the log messagesthat point to the test that needs to be updated in case ofchanges to the log messages.Reviewers: John Roesler <vvcephei@apache.org>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
[FLINK-7356] [config] misleading s3 file uri in configuration fileThis closes #4466.,2
"[FLINK-9917][JM] Remove superfluous lock from SlotSharingManagerThe SlotSharingManager is designed to be used by a single thread. Therefore,it is the responsibility of the caller to make sure that there is only a singlethread at any given time accesssing this component. Consequently, the componentdoes not need to be synchronized.This closes #6389.",1
"KAFKA-13587; Implement leader recovery for KIP-704 (#11733)Implementation of the protocol for starting and stopping leader recovery after an unclean leader election. This includes the management of state in the controllers (legacy and KRaft) and propagating this information to the brokers. This change doesn't implement log recovery after an unclean leader election.Protocol Changes================For the topic partition state znode, the new field ""leader_recovery_state"" was added. If the field is missing the value is assumed to be RECOVERED.ALTER_PARTITION was renamed from ALTER_ISR. The CurrentIsrVersion field was renamed to PartitionEpoch. The new field LeaderRecoveryState was added.The new field LeaderRecoverState was added to the LEADER_AND_ISR request. The inter broker protocol version is used to determine which version to send to the brokers.A new tagged field for LeaderRecoveryState was added to both the PartitionRecord and PartitionChangeRecord.Controller==========For both the KRaft and legacy controller the LeaderRecoveryState is set to RECOVERING, if the leader was elected out of the ISR, also known as unclean leader election. The controller sets the state back to RECOVERED after receiving an ALTER_PARTITION request with version 0, or with version 1 and with the LeaderRecoveryState set to RECOVERED.Both controllers preserve the leader recovery state even if the unclean leader goes offline and comes back online before an RECOVERED ALTER_PARTITION is sent.The controllers reply with INVALID_REQUEST if the ALTER_PARTITION either:    1. Attempts to increase the ISR while the partition is still RECOVERING    2. Attempts to change the leader recovery state to RECOVERING from a RECOVERED state.Topic Partition Leader======================The topic partition leader doesn't implement any log recovery in this change. The topic partition leader immediately marks the partition as RECOVERED and sends that state in the next ALTER_PARTITION request.Reviewers: Jason Gustafson <jason@confluent.io>",5
"Cleaned up pact-examples: 1) Removed PigMix package, removed Manifest files, removed CoGroupSecondarySort job, renamed ReduceSecondarySort job",4
Adopted Runtime tests to new runtime.,1
[Dubbo-808] Support etcd registry (#3605)* Merge https://github.com/dubbo/dubbo-registry-etcd into incubator-dubbo* Add UT to ConfigurationUtilsTest,5
[hotfix][tests] Enable building uberjar.,0
[FLINK-1587][gelly] Added additional check for edge src/trg id validityThis closes #440,1
"Revert ""KAFKA-13542: add rebalance reason in Kafka Streams (#11804)"" (#11873)This reverts commit 2ccc834faa3fffcd5d15d2463aeef3ee6f5cea13.This reverts commit 2ccc834. We were seeing serious regressions in our state heavy benchmarks. We saw that our state heavy benchmarks were experiencing a really bad regression. The State heavy benchmarks runs with rolling bounces with 10 nodes.We regularly saw this exception:  java.lang.OutOfMemoryError: Java heap space                                                                                                                                                                                              I ran through a git bisect and found this commit. We verified that the commit right before did not have the same issues as this one did. I then reverted the problematic commit and ran the benchmarks again on this commit and did not see any more issues. We are still looking into the root cause, but for now since this isn't a critical improvement so we can remove it temporarily.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, David Jacot <djacot@confluent.io>, Ismael Juma <ismael@confluent.io>",5
support destroy scope bean and spi extension instance (#9155),1
[hotfix] Remove unnecessary surefire plugin version in flink-connector-elasticsearch5,2
[FLINK-15119] Remove unused Plan/RemoteExecutor,1
Revert [FLINK-15670]This reverts commit 78b7c71d83d631c689fa5a3bace9fb40fb669f52 ff1695d92869fa4103d7d93828e048fa3fbf5a03 9fd02fe24d1ad68693f7f88f58929369f8b8022b e929c3c5fa631f9b35c73fd8e1e0db1f5a70b6df 03f5d54b99d5178f9268616a3ebf6cc30a403eda,5
[hotfix] [tests] Fix minor JavaDoc warnings,2
[FLINK-12957][docs] fix Thrift and Protobuf dependency examplesThese require newer versions nowadays.This closes #8848.,1
DUBBO-245 将Invocation的getUrl改成getInvokergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1115 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[streaming] Several minor cleanups,4
[FLINK-2357] [web dashboard] Update Node.js installation instructionsThis closes #1006,5
[FLINK-14049] [coordination] Add task name to error message for failed partition updates.This closes #9670,5
[streaming] DataStream type refactor for easier future extensions,4
"KAFKA-9080: Revert the check added to validate non-compressed record batch does have continuous incremental offsets#7167 added a check for non-incremental offsets in `assignOffsetsNonCompressed`, which is not applicable for message format V0 and V1. Therefore, I added a condition to disable the check if the record version precedes V2.Author: Tu Tran <tu@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7628 from tuvtran/KAFKA-9080",5
"Default mode for output formats is not to overwrite existing files.Globally configurable default modes for overwrite / output directory behavior.Configurable behavior for FileOutputFormat through regular parameters, rather than configuration.",5
"[tests] Remove redundant copies of the JUnit RetryRulesThe classes were noved to 'flink-test-utils-junit', but apparently copies remained in 'flink-core'.",2
"MINOR: Replace BrokerStates.scala with BrokerState.java (#10028)Replace BrokerStates.scala with BrokerState.java, to make it easier to use from Java code if needed.  This also makes it easier to go from a numeric type to an enum.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
Fixed filterByNodesConstantSet in LocalProperties,1
Fixed bug in restart logic of ReplayThread,2
[FLINK-1201] [gelly] fromCollection(edges) implemented abd tested,3
Checkpoint decision is now made by the task thread itself,5
refactor: Improve and perfect StringUtils (#9521),1
add @SPI annotation (#6436),1
[FLINK-23165][python] Add StreamExecutionEnvironment#registerSlotSharingGroup to PyFlink and ScalaThis closes #16405.,2
"MINOR: fix compatibility-breaking bug in RequestHeader (#7479)Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
DUBBO-371 NoNodeException检测git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1748 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-15348][hive] Fix orc optimization for version less than 2.3 by introducing orc shimadd shim to support hive orc version less than 2.3this closes #10618.,1
"KAFKA-2768: AdminClient ignore member list for non-stable groups…stabilizingAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma, Jason Gustafson, Guozhang WangCloses #447 from SinghAsDev/KAFKA-2768",2
[FLINK-8360][checkpointing] Implement file-based local recovery for FsStateBackendThis reverts commit 8925b7c,4
[FLINK-2797][cli] Add support for running jobs in detached mode from CLIThis closes #1214.,1
[FLINK-20211][doc] Use <ClusterId>-rest to get the external ip addressThis closes #14130.,1
DUBBO-389 ValidationFilter在有@Pattern标注时出错git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1751 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-7908][QS] Restructure the queryable state module.The QS module is split into core and client. The core shouldbe put in the lib folder to enable queryable state, while theclient is the one that the user will program against. Thereason for the restructuring in mainly to remove the dependencyon the flink-runtime from the user's program.",1
"[FLINK-21490][tests] Harden UnalignedCheckpointITCase.The source readers currently inferred the number of checkpoints individually potentially causing a drift. Number of checkpoint and restarts is now calculated in the coordinator and propagated to the readers keeping them in sync. The mechanism to infer the number of restarts has been improved by directly notifying enumerator when a source reader is created (RuntimeContext is unavailable in source).Further, if the payload of the test passes MAX_INT, then checkHeader fails as it uses the upper 4 bytes of the long to check for magic bytes. A checkstate ensures that no overflow happens and aborts the test with a meaningful message. checkHeader further prints the expected and actual value.This commit includes some refactorings for the upcoming UnalignedCheckpointRescaleITCase which eases the maintenance of the test in 1.12 and master branch.",3
[FLINK-7715][flip6] Implement JarRunHandlerThis closes #5509.,0
[hotfix] Fix formatting in windowing documentation,2
[streaming] Aggregation rework to support field expression based aggregations for Pojo data streams,5
[FLINK-13589] Fixing DelimitedInputFormat for whole file input splits.The DelimitedInputFormat drops bytes when using whole file input splits.This commit replicates the logic of regular input splits also for wholefile input splits.,2
[hotfix][network][tests] add readView.nextBufferIsEvent to assertNextBufferOrEvent(),3
DUBBO-89 Log4jContainer没有修改所有Appender的路径git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@491 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-8435: replace delete groups request/response with automated protocol (#6860)Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
[FLINK-5402] [tests] Increase JUnit timeouts in AkkaRpcServiceTestThis closes #3430.,3
[hotfix] [zk] Add logging for connection state changes in ZooKeeperLeaderElection/RetrievalService,4
[FLINK-8148][yarn/s3] fix test instability in YarnFileStageTestS3ITCaseRemove a check for a deleted directory since we may not see our own delete yetwith S3.This closes #5066.,4
Adjusted cygwin path conversion for path lists.,5
[3.0] close client immediately when destroy unused invoker (#8755)* close client immediately when destroy unused invoker* fix condition statement* call invoke.destroyAll() when destroy all invokers* format code,0
"[FLINK-11059][runtime] Add slot reconciliation between JM and TEWith this commit we introduce an AllocatedSlotReport which is periodically sent from theJM to the TE. This report is then used to reconcile the JM's and the TE's view on the stateof allocated slots.Furthermore, with this commit we drop slots which could not be freed viaTaskExecutorGateway#freeSlot and instead rely on the heartbeat reconciliation logic.This closes #7227.",2
"KAFKA-7808: AdminClient#describeTopics should not throw InvalidTopic if topic name is not found (#6124)* Update KafkaAdminClient#describeTopics to throw UnknownTopicOrPartitionException.* Remove unused method: WorkerUtils#getMatchingTopicPartitions.* Add some JavaDoc.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>, Ryanne Dolan <ryannedolan@gmail.com>",2
"[FLINK-6612] Allow ZooKeeperStateHandleStore to lock created ZNodesIn order to guard against deletions of ZooKeeper nodes which are still being usedby a different ZooKeeperStateHandleStore, we have to introduce a locking mechanism.Only after all ZooKeeperStateHandleStores have released their lock, the ZNode isallowed to be deleted.THe locking mechanism is implemented via ephemeral child nodes of the respectiveZooKeeper node. Whenever a ZooKeeperStateHandleStore wants to lock a ZNode, thus,protecting it from being deleted, it creates an ephemeral child node. The node'sname is unique to the ZooKeeperStateHandleStore instance. The delete operationswill then only delete the node if it does not have any children associated.In order to guard against oprhaned lock nodes, they are created as ephemeral nodes.This means that they will be deleted by ZooKeeper once the connection of theZooKeeper client which created the node timed out.",1
"DUBBO-91 修改simple,multicast,zookeeper支持admingit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@406 1a56cb94-b969-4eaa-88fa-be21384802f2",1
增加telnet防御git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@668 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-1317 KafkaServer 0.8.1 not responding to .shutdown() cleanly, possibly related to TopicDeletionManager or MetricsMeter state; reviewed by Neha Narkhede",4
Collecting registration and consumption status inside process (#7714),2
[FLINK-20580][rpc] Separate wire value class from user values,1
Small improvements to sopremo-common,1
DUBBO-71 Graceful shutdown-半关闭状态git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@337 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-979] Fix NetworkThroughput test input and output task config- Set DummyInputFormat and DummyOutputFormat via TaskConfig to respect task  hierarchy refactoring.- Run test via main method instead of JUnit test runner (this was originally  a test in order to use RecordAPITestBase for JobGraph submission).This closes #41.,3
[3.0] Do not release ByteBuf manually in port unification handler (#9869)* Do not release manually,0
[FLINK-12883][runtime] Extract computation of pipelined regions.,4
[FLINK-11071][core] add support for dynamic proxy classes resolution in job definationThis closes #7436,1
[hotfix] Refactor the registerJobManager to registerJobMasterThis closes #17428.,4
"KAFKA-12675: improve the sticky general assignor scalability and performance (#10552)I did code refactor/optimization, keep the same algorithm in this PR.Originally, With this setting:topicCount = 50;partitionCount = 800;consumerCount = 800;We complete in 10 seconds, after my code refactor, the time down to 100~200 msWith the 1 million partitions setting:topicCount = 500;partitionCount = 2000;consumerCount = 2000;No OutOfMemory will be thrown anymore. The time will take 4~5 seconds.Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
[FLINK-9581] [docs] Remove white spaces to align COLLECT code example.This closes #6161,4
[FLINK-4733] Port TaskManager metrics,2
[FLINK-5743] Mark WindowedStream.aggregate() methods as PublicEvolving,2
[FLINK-28745][python] Support DataStream PythonCoProcessOperator and PythonKeyedCoProcessOperator in Thread ModeThis closes #20396.,1
fix wrong context reference,0
[FLINK-12253][table-common] Add an ANY type,1
"[hotfix][javadoc] Add missing ""the""",1
"KAFKA-6100: Down-grade RocksDB to 5.7.3Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #4136 from guozhangwang/K6100-rocksdb-580-regression",5
"MINOR: Add RandomComponentPayloadGenerator and update Trogdor documentation (#7103)Add a new RandomComponentPayloadGenerator that gives a payload based on random selection of another PayloadGenerator.  Additionally, add an example that uses a non-default PayloadGenerator configuration to TROGDOR.md.Reviewers: Colin P. McCabe <cmccabe@apache.org>",5
[FLINK-18719][runtime] Introduce interfaces ResourceManagerDriver and ResourceEventHandler.,0
[FLINK-23024][rest] Make TaskManagerInfoWithSlots serializableThis closes #16188.,5
"MINOR: unpin ducktape dependency to always use the newest version (py3 edition) (#11884)Ensures we always have the latest published ducktape version.This way whenever we release a new one, we won't have to cherry pick a bunch of commits across a bunch of branches.",1
[hotfix][docs] Fix incorrect example in cep doc,2
enhance unit test (#2898)* enhance unit test* enhance unit test* enhance,3
Removed redundant WordCount examples.,4
[FLINK-11329][core] Migrate CRowSerializerConfigSnapshot to new TypeSerializerSnapshot interface,1
KAFKA-9078: Fix Connect system test after adding MM2 connector classesMM2 added a few connector classes in Connect's classpath and given that the assertion in the Connect REST system tests need to be adjusted to account for these additions.This fix makes sure that the loaded Connect plugins are a superset of the expected by the test connectors.Testing: The change is straightforward. The fix was tested with local system test runs.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7578 from kkonstantine/minor-fix-connect-test-after-mm2-classes,3
"KAFKA-4607: Validate the names of auto-generated internal topicsI considered catching errors to add further information about naming internal state stores. However, Topic.validate() will throw an error that prints the offending name, so I decided not to add too much complexity.Author: Nikki Thean <nthean@etsy.com>Reviewers: Matthias J. Sax, Guozhang Wang, Eno Thereska, Damian Guy, Ismael JumaCloses #2331 from nixsticks/internal-topics",1
Moved SerializerTestBase to s-core and resolved Maven dependencies,0
[FLINK-3134][yarn] asynchronous YarnJobManager heartbeats- use AMRMClientAsync instead of AMRMClient- handle allocation and startup of containers in callbacks- remove YarnHeartbeat messageThe AMRMClientAsync uses one thread to communicate with the resourcemanager and an additional thread to execute the callbacks.This closes #1450.,1
[FLINK-8014] [table] Add Kafka010JsonTableSink.- Refactor KafkaTableSink tests.,3
Add recordMetadata() to StateStoreContext (#11498)Implements KIP-791Reviewers: John Roesler <vvcephei@apache.org>,3
[streaming] Version set to 0.3-SNAPSHOT,1
[FLINK-26287][table] Add convenience method TableConfig.set,5
[FLINK-21819][filesystems] Remove Swift filesystem,5
[FLINK-3532] [gelly] Fix artifact ID of flink-gelly-examples moduleThe current flink-gelly-examples artifact id wrongly used an underscore to separateexamples from flink-gelly. This commit replaces the underscore with an hyphen.This closes #1731.,2
Support caching of dynamic property  (#7760),5
Update Gradle to 6.4.1 (#8678)This fixes critical bugs in Gradle 6.4:* Regression: Different daemons are used between IDE and CLI builds for the same project* Regression: Main-Class attribute always added to jar manifest when using application plugin* Fix potential NPE if code is executed concurrentlyMore details: https://github.com/gradle/gradle/releases/tag/v6.4.1Reviewers: Manikumar Reddy <manikumar@confluent.io>,5
KAFKA-6707: The default value for config of Type.LONG should be *L (#4762)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"[FLINK-7251] [types] Remove the flink-java8 module and improve lambda type extractionThis commit removes the flink-java8 module and merges some tests into flink-core/flink-runtime. It ensures to have the possibility for passing explicit type information in DataStream API as a fallback. Since the tycho compiler approach was very hacky and seems not to work anymore, this commit also removes all references in the docs and quickstarts.This closes #6120.",2
Pact Record fixes.Hash Join adoption complete.,0
[FLINK-15050][table-planner-blink] DataFormatConverters should support any TIMESTAMP WITHOUT TIME ZONE typesThis closes #10418,1
"KAFKA-9180: Introduce BrokerMetadataCheckpointTest (#7700)While investigating KAFKA-9180, I noticed that we had nounit test coverage. It turns out that the behavior wascorrect, so we just fix the test coverage issue.Also updated .gitignore with jmh-benchmarks/generated.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
[FLINK-20621][python] Improve the TypeInformation implementation in Python DataStream APIThis closes #14401.,5
Don't create empty splits in BinaryInputFormat#createInputSplits on one input file.,2
[3.0] router add getter method (#8139),1
test protection of master branch,3
KAFKA-5093; Avoid loading full batch data when possible when iterating FileRecordsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3160 from hachikuji/KAFKA-5093,5
"Unify the bean name convention of ServiceBean and ReferenceBean (#4135)fixes #4071, #3709",0
[FLINK-20626][runtime] Fix issue concurrent of concurrent failing and canceling of an ExecutionGraphUpdate ExecutionGraphRestartTest to be based on the new scheduler to verify it.,1
[FLINK-5412] Enable RocksDB tests on Windows OSThis closes #3067.,3
[FLINK-21277] Bump testcontainers version,3
[hotfix] Fix checkstyle violations in LibraryCacheManager,0
add comment,1
changed pom,4
Added stubs for count function and counting reducerAdded word count example using the counting of group elements.,1
[FLINK-11884][table] Ported alias validation on top of Expressions,5
[FLINK-1086] Replace JCL with SLF4J and Log4j with LOGBack- Excluded Kafka's transitive dependencies: jmxtools and jmxri- Corrected encoder pattern in logback.xml- Removed explicit logging access. Loggers are now configured by  configuration files. Fixed Yarn issue with multiple logging  bindings.This closes #111.,2
Fixes bugs where the TypeExtractor throws an NPE instead of the operators,1
Changed examples to use aggregators.,1
"[FLINK-12963] [state-processor] Allow providing user defined SavepointWriterOperatorFactory when creating keyed BootstrapTransformationsThis was exposed for non-partitioned BootstrapTransformations, but notfor keyed ones. This commit makes the functionality on-par for bothsides.",1
[FLINK-21445][clients] Refactors ClassPathPackagedProgramRetrieverClassPathPackagedProgramRetriever is replaced by DefaultPackagedProgramRetriever.A new interface EntryClassInformationProvider is introduced encapsulating theextraction of the actual jar/job class information. This enables us to test thethe functionality in a more fine-grained way. Improvements like fail-early werenot added as part of this refactoring to limit the scope of the change.,4
[streaming] remove java.nio from TestDataUtilTest,5
Print warn log instead of throw exception. (#8142),2
[FLINK-22776][connector-jdbc] Delete unuseful casting to byte[] in AbstractJdbcRowConverter classThis closes #16058,5
implementation of LazyTailArrayNode and added Test,3
[hotfix][streaming] Refactor TwoPhaseCommitSinkFunctionTest,3
Fix pom configuration,5
[FLINK-15114][sql client] Print execute result info for alter/create/drop database in sql-clientThis closes #10471,5
"[FLINK-16082][docs-zh][table] Translate ""Streaming Concepts Overview"" page into Chinese (#11128)",2
"[hotfix][connector-hive] Avoid serializing TableConfigUse and pass around only `threadNum` which is the only option read,instead of the whole `TableConfig`, to prevent the relevant classesthat are serialized from trying to serialize also the `TableConfig`.",5
"[FLINK-7638] [flip6] Port CurrentJobsOverviewHandler to new REST endpointPorts the CurrentJobsOverviewHandler to the new REST endpoint by letting it implementthe LegacyRestHandler interface. This commit changes the JobDetails JSON such that itnow contains the number of tasks for each ExecutionState, including SCHEDULED,DEPLOYING, CREATED and RECONCILING. These state will now also be displayed in theweb frontend.Change MultipleJobsDetails to store a Collection<JobDetails> instead of JobDetails[]Use MultipleJobsDetails#FIELD_NAME_ for serialization in CurrentJobsOverviewHandlerThis closes #4688.",0
[FLINK-13078][table-common] Simplify serializable string representation for parsers,2
[FLINK-21700][security] Add an option to disable credential retrieval on a secure cluster (#15131),1
[FLINK-15694][docs] Remove HDFS Section of Configuration PageThis close #15694,1
"[FLINK-12987][metrics] fix DescriptiveStatisticsHistogram#getCount() not returning the number of elements seenDescriptiveStatisticsHistogram#getCount() only returned the number of currentlystored elements, not the total number seen.Also add a unit test for verifying any Histogram implementation (based onthe previous test from DropwizardFlinkHistogramWrapperTest) and run this withDescriptiveStatisticsHistogram.",1
"[FLINK-5492] [log] Log unresolved address when starting an ActorSystemWith the Flakka changes we no longer resolve the given hostname into an IP. Thus,we should henceforth log the unresolved hostname as the address to which theActorSystem binds to.This closes #3161.",5
[FLINK-15744] Log erroneous Task state changes at warn level,4
Merge pull request #365 from fhueske/updateCliClientHelp#360: updated CLI client help text after renaming,5
[FLINK-18890][table] Update LookupTableSource to the new type systemThis closes #14329.,5
"[FLINK-8472] [fs, test] Extend BucketingSinkMigrationTest for Flink 1.4",2
[FLINK-22730][table-planner] Add per record code when generating table function collector code for lookup joinsThis closes #16104,1
修改启动脚本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@488 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Rephrase Javadoc summary for ConsumerRecordThe original Javadoc description for `ConsumerRecord` is slightly confusing in that it can be read in a way such that an object is a key value pair received from Kafka, but (only) consists of the metadata associated with the record. This PR makes it clearer that the metadata is _included_ with the record, and moves the comma so that the phrase ""topic name and partition number"" in the sentence is more closely associated with the phrase ""from which the record is being received"".Author: LoneRifle <LoneRifle@users.noreply.github.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2290 from LoneRifle/patch-1",5
MINOR: Add 2.2.0 upgrade instructions (#6501)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-19092][sql-parser] Support to parse comment on computed columnThis closes #13352,1
[FLINK-17315][tests] Increased timeouts of UnalignedCheckpointITCase.,1
MINOR: Fix transient test failure in SslTransportLayerTest (#5396)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-2774: Rename Copycat to Kafka ConnectAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #456 from ewencp/kafka-2774-rename-copycat,2
[FLINK-12253][table-common] Add a SMALLINT type,1
"KAFKA-12655 Update Jetty: 9.4.38.v20210224 → 9.4.39.v20210325 (#10526)Reviewers: Edwin <edwinhobor@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Luke Chen, xjin-Confluent, Chia-Ping Tsai <chia7712@gmail.com>",5
[hotfix][docs][rest] Update rest_v1_dispatcher.html,5
"Merge #1740 manually, fix typo.",2
MINOR: Replaced unnecessary isDefined and get on option values with foldAuthor: himani1 <1himani.arora@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2050 from himani1/refactored_code,4
[hotfix][travis] Move QS to connectors,4
[FLINK-4104] [docs] Restructure Gelly docsSplit the Gelly documentation into five sub-pages.This closes #2258.,2
[FLINK-26228][dropwizard] Migrate tests to JUnit5,3
[hotfix][tests] Introduce MockEnvironmentBuilder to deduplicate MockEnvironment constructors,3
[streaming] fix several bugs in in the examples. Window operator runnable,1
Replica.hw should be initialized to the smaller of checkedpointed HW and log end offset; patched by Yang Ye; reviewed by Jun Rao; KAFKA-539git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1395861 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-6585] [table] Fix execution of Table examples in IDE.This closes #3905.,0
"MINOR: Make kafka-run-class.sh work under Cygwinkafka-run-class.sh now runs under Cygwin; paths and classpath are set up properly.**WARNING:**  The script was not tested on a Linux machine, only under Cygwin.  Prior to merge it into trunk, if accepted, please run a quick test to ensure nothing broke.  From my own code review, there should not be any problem, but we can never be too sure.I do not have the environment to test it under Linux at this moment.Author: deragon <32nx9812masakjds>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1487 from deragon/trunk",1
HOTFIX: fix active task process ratio metric recording,0
[gelly] [docs] Change the return type of groupReduceOnNeighbors exampleThis closes #650,4
event of response fix#3244 (#3247),0
Merge pull request #777 from chickenlj:bugfix#672_MonitorFactory_blockFixed #672: Monitor blocks when registry is unreachable (#777),1
[FLINK-27228][ci] Redistributed modules across CI profiles-> runtime* gelly* statebackends* dstl* queryable-state-> connectors -> connectors_1* remaining filesystems/formats* hbase-> kafka/gelly -> connectors_2* pubsub* pulsar* rabitmq* aws-> misc* architecture-tests,3
[FLINK-26474][hive] Fold exprNode to fix the issue of failing to call some hive udf required constant parameters with implicit constant passedThis closes #18975,4
[FLINK-20304] Create base AbstractTwoInputTransformationTranslator.This base class factors out the common code between theTwoInputTransformationTranslator annd theBroadcastStateTransformationTranslator.,1
[FLINK-24336][python] Fix the issue that jar url list may contain empty string.This closes #17322.,0
Explored nonsymmetric matrix,5
MINOR: Upgrade Gradle to 6.6 (#9160)A couple of important bug fixes affecting Scala compilation are the main driver:* https://github.com/gradle/gradle/issues/13224* https://github.com/gradle/gradle/issues/13392Full release notes for the other improvements:* https://docs.gradle.org/6.6/release-notes.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
[FLINK-3901] [table] Convert Java implementation to Scala and fix bugsThis closes #2283.,0
[FLINK-6393] [gelly] Add Circulant and Echo graph generatorsThis closes #3802,1
"[FLINK-7876] Register TaskManagerMetricGroup under ResourceIDThis commit changes that TaskManagerMetricGroups are now registered under theTaskManager's ResourceID instead of the InstanceID. This allows to create theTaskManagerMetricGroup at startup of the TaskManager.Moreover, it pulls the MetricRegistry out of JobManager and TaskManager. Thisallows to reuse the same MetricRegistry across multiple instances (e.g. in theFlinkMiniCluster case). Moreover, it ensures proper cleanup of a potentiallystarted MetricyQueryServiceActor.Change TaskManagersHandler to work with ResourceID instead of InstanceIDAdapt MetricFetcher to use ResourceID instead of InstanceIDThis closes #4872.",1
[hotfix][tests] Remove unused method and field in ExecutionGraphTestUtils,3
KAFKA-5014; NetworkClient.leastLoadedNode should check if channel is readyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2813 from ijuma/kafka-5014-least-loaded-node-should-check-if-channel-is-ready,5
[FLINK-17739][network][tests] Fix unstable ResultPartitionTest#testInitializeMoreStateThanBuffer,5
KAFKA-6057: Users forget `--execute` in the offset reset tool (#4069)Add a small warning note when the user does not use the --execute flag.,1
[FLINK-7657] [table] Add all basic types to RexProgramExtractor,4
[hotfix][docs] Fix typos in config option descriptionsThis closes #12191,5
[FLINK-14188][runtime][yarn/mesos] Set container cpu cores into TaskExecutorResourceSpec when launching TaskExecutors on Yarn/Mesos.,1
[FLINK-13632] Port ScalaCaseClassSerializer upgrade test to TypeSerializerUpgradeTestBase,3
MINOR: Use match instead of if/else in KafkaZkClientAlso use ZkVersion.NoVersion instead of -1.Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4196 from mimaison/zkclient_refactor,4
"[FLINK-5021] Remove the special EOS TimestampedFileInputSplit.Without this special split signaling that no more splits areto arrive, the ContinuousFileReaderOperator now closes bysetting a flag that marks it as closed and exiting when theflag is set to true and the pending split queue is empty.",1
KAFKA-3691; Confusing logging during metadata update timeoutAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1509 from granthenke/timeout-logging,2
"KAFKA-13023: make ""range, cooperative-sticky"" as the default assignor in V3.0 (#10903)Set the default assignor to [""range"", ""cooperative-sticky""] to make it easier for users to switch over to cooperative rebalancing by using only a single rolling bounce.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
[FLINK-25907][runtime][security] Add pluggable delegation token manager,1
"MINOR: Follow-up improvements for KIP-266 (#5084)This patch contains a few follow-up improvements/cleanup for KIP-266:- Add upgrade notes- Add missing `commitSync(Duration)` API- Improve timeout messages and fix some naming inconsistencies- Various small cleanupsReviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-23450][avro-confluent-registry] Set properties map for DebeziumAvroFormatThis closes #16565.,1
[hotfix][docs] Fix typo,2
[FLINK-18905][hotfix][task] Extract OperatorChain#createChainOutputs method,1
Added nephele-s3 to stratosphere distribution,1
[FLINK-22706][legal] Update NOTICE regarding docs/ contents,2
Merge pull request #3 from wangchangbing/masteradmin项目订阅zk时当interface包含内部类$字符时出现问题,4
KAFKA-1739 Remove testComplexCompressDecompress in MessageCompressionTest; reviewed by Neha Narkhede,3
[FLINK-514] Fixed javadoc problems,0
"KAFKA-13511: Add support for different unix precisions in TimestampConverter SMT (#11575)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Tom Bentley <tbentley@redhat.com>",1
[FLINK-12670][runtime] Implement FailureRateRestartBackoffTimeStrategy* use ManualClock in unit test and add configuration descriptionThis closes #8573.,5
[FLINK-4269] [webfrontend] Decrease log level in RuntimeMonitorHandlerThis closes #2307.,0
KAFKA:212 IllegalThreadStateException in kafka mirroring;patched by nehanarkhede; reviewed by junrao and jaykrepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1208919 13f79535-47bb-0310-9956-ffa450edef68,1
"[FLINK-23862][runtime] Extract interfaces from AbstractInvokableThe previous commits introduced a contractbetween Task and StreamTask about cleaning up resources.To make this contract more explicit,the relevant methods (cleanUp, invoke, restore, plus related)are moved to a separate interface TaskInvokable.Furthermore, to allow Task to explicitly reference the new interfacecheckpointing and coordination interfaces are extracted.The requirement to extend AbstractInvokable is removed from its javadoc.",2
[FLINK-4283] Use new InfiniteDelayRestartStrategy instead of FixedDelayRestartStrategy to avoid blocking threadsThis closes #2661.,0
"KAFKA-4544: Add system tests for delegation token based authenticationThis change adds some basic system tests for delegation token based authentication:- basic delegation token creation- producing with a delegation token- consuming with a delegation token- expiring a delegation token- producing with an expired delegation tokenNew files:- delegation_tokens.py: a wrapper around kafka-delegation-tokens.sh  - executed in container where a secure Broker is running (taking advantage of automatic cleanup)- delegation_tokens_test.py: basic test to validate the lifecycle of a delegation tokenChanges were made in the following file to extend their functionality:- config_property was updated to be able to configure Kafka brokers with delegation token related settings- jaas.conf template because a broker needs to support multiple login modules when delegation tokens are used- consule-consumer and verifiable_producer to override KAFKA_OPTS (to specify custom jaas.conf) and the client properties (to authenticate with delegation token).Author: Attila Sasvari <asasvari@apache.org>Reviewers: Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Andras Katona <41361962+akatona84@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5660 from asasvari/KAFKA-4544",1
[FLINK-16350][e2e] Run half of streaming HA tests against ZK 3.5,3
[FLINK-13312][hive] move tests for data type mappings between Flink and Hive into its own test classThis PR moves UT for data type mapping between Flink and Hive to its own test class.This closes #9151.,3
"[FLINK-25362][docs] allow SQL maven artifact listIf a connector needs more than one maven dependency, these can instead bedefined as a list/array now. The old syntax with a single string is also stillpossible.",1
[FLINK-17599][docs] Add documents for USE statement,1
[FLINK-14119][table-planner-blink] Fix idle state is not cleaned for RetractableTopNFunctionThis closes #9741,1
修改READMEgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@2043 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-6825: Make StreamsConfig#DEFAULT_PRODUCTION_EXCEPTION_HANDLER_CLASS_CONFIG public (#4929)Reviewers: Matthias J Sax <matthias@confluentio>,5
[FLINK-4047] [docs] Fix documentation about determinism of KeySelectorsThis closes #4659.,5
"MINOR: Propagate LogContext to channel builders and SASL authenticator (#7867)The log context is useful when debugging applications which have multiple clients. This patch propagates the context to the channel builders and the SASL authenticator.Reviewers: Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
修改测试依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@118 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-23736][docs] Delete test line,3
[FLINK-24208][rest] Support user-supplied Savepoint triggerId,1
"MINOR: Fixed Non-Final Close Method + its DuplicationAuthor: Armin Braun <me@obrown.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2582 from original-brownbear/cleanup-nonfinal-close",4
CLI Client prints progress messages.,5
Fix for branching merging logic in BulkIterationPlanNode,2
Merge branch 'version02' of https://stratosphere.eu/git/stage1Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/fs/file/LocalFileSystem.java,5
[hotfix][network-tests] Simplify TestPooledBufferProvider,5
[FLINK-6751] [docs] Add documentation for user-defined AggregateFunction.This closes #4546.,1
Added Operator test cases,3
Fixed bug in PactRecord serialization.,0
ConsoleProducer does not exit correctly; kafka-701; patched by Maxime Brugidou; reviewed by Jun Rao,5
[hotfix][test] Remove unused code in AlternatingCheckpointBarrierHandlerTest,3
修改注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@999 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-22670][FLIP-150][connector/common] Hybrid source baseline,2
Fixed bug in serialization method of RemoteReceiver,0
[hotfix][docs] Mention new StreamTableEnvironment.fromDataStream in Chinese release notes,5
Reduced test logging verbosity.,2
[FLINK-1046] Made sure that Client uses correct user-code class loaders.,1
[FLINK-18065][docs] Document FLIP-65 table and scalar functionsThis closes #12660.,1
Move TypeInformation to stratosphere-core,5
Use max of the inputs for distinct value cardinality estimation inUnionNode,1
[FLINK-25578][core] Graduate and deprecate unified Sink API V1,2
[hotfix] Add debug logging in MiniDispatcher,5
Simplified buffer provider API,1
Fixed Runtime TestsFixed Common Delimited Input Format testsPulled Array-Model classes (POC) into separate project.Adopted JobGraphGenerator,3
"KAFKA-4743; [KIP-122] Add Reset Consumer Group Offsets toolingAuthor: Jorge Quilcate <quilcate.jorge@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2624 from jeqo/feature/rewind-consumer-group-offset",1
[hotfix][build] Remove unused akka-testkit dependencies,3
"KAFKA-3629; KStreamImpl.to(...) throws NPE when the value SerDe is nullguozhangwangAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #1272 from dguy/kstreamimpl-to-npe and squashes the following commits:49d48fb [Damian Guy] actually commit the fix07ce589 [Damian Guy] fix npe in KStreamImpl.to(..)74d396d [Damian Guy] fix npe in KStreamImpl.to(..)",0
MINOR: Mention in configuration of broker setting log.retention.ms that -1 disables retention by time (#6464)Includes an update to the relevant configuration doc.,2
"Kafka-2587:  Only notification handler will update the cache and all verifications will use waitUntilTrue.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #277 from Parth-Brahmbhatt/KAFKA-2587",1
"[FLINK-26025][connector/pulsar] Replace MockPulsar with new Pulsar test tools based on PulsarStandalone.1. Drop some unused fields in test classes.2. Fix the checkstyle issues for source test.3. Fix violations for Pulsar connector according to the flink-architecture-tests.4. Create a standalone Pulsar for test.5. Add new methods to PulsarRuntimeOperator.6. Fix the bug in PulsarContainerRuntime, support running tests in E2E environment.7. Create PulsarContainerTestEnvironment for supporting E2E tests.8. Add a lot of comments for Pulsar testing tools.9. Drop mocked Pulsar service, use standalone Pulsar instead.",1
[FLINK-27155][changelog] Reduce multiple reads to the same Changelog file in the same taskmanager during restore,2
[FLINK-12122] Add LeastUtilizationSlotMatchingStrategy for spreading slot allocations outThe LeastUtilizationSlotMatchingStrategy picks the matching slots which belongs to aTaskExecutor with the least utilization value. That way the SlotManager will spread outslot allocations across all available/registered TaskExecutors.,1
"KAFKA-4158; Reset quota to default value if quota override is deletedAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #1851 from lindong28/KAFKA-4158",4
"MINOR: increase number of unique keys for Streams EOS system test (#5640)Increasing the number of unique keys, to increase likelihood that the test exposes KAFKA-7192.Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
Code optimization and fix typo (#9840)* Code Adjust* Fix typo* FIX UT* FIX UT* Adjust the order of the two if judgments,0
"[FLINK-7810] Add more excludes in end-to-end testsWith the switch to Akka 2.4 this message can crop up in the logs, it'sonly a warning, though.",2
"[DUBBO-3137]: step2 - seperate constants for config, remoting, rpc (#4021)* constants step2* change interface",4
[FLINK-23198][docs] Fix the demo of ConfigurableRocksDBOptionsFactorythis fix #16371.,0
[FLINK-8975] [test] Add Kafka events generator job for StateMachineExample,1
[hotfix][yarn] Remove unused argument workingDirectory for YarnEntrypointUtils#installSecurityContext.,1
KAFKA-6694: The Trogdor Coordinator should support filtering task responses (#4741),1
#1915: java.net.BindException happens when delay-expose-service is enabled (#1916),0
URL参数排序git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@112 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-28934][Connector/pulsar] Fix split assignment in different Pulsar subscriptions.,0
[FLINK-8401] [cassandra] Add callback methods for failed and successful writes to CassandraOutputFormatBase.This closes #5274.,0
[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.,1
MINOR: Remove `zipWithIndex` to avoid tuple allocation in hot path in `LogValidator` (#9206)- improvement: +17%- garbage allocation: -12 %**Parameters**1. bufferSupplierStr = NO_CACHING1. bytes = RANDOM1. compressionType = NONE1. maxBatchSize = 5001. messageSize = 1000001. messageVersion = 2**BEFORE**```Benchmark                                                                                                  (bufferSupplierStr)  (bytes)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score       Error   UnitsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed                                        NO_CACHING   RANDOM             500         100000                 2  thrpt   15  2315566.901 ± 35760.064   ops/sUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate                         NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4004.046 ±    61.825  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate.norm                    NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1904.000 ±     0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4007.442 ±    80.422  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1905.678 ±    29.493    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.007 ±     0.001  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.003 ±     0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.count                              NO_CACHING   RANDOM             500         100000                 2  thrpt   15      516.000              countsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.time                               NO_CACHING   RANDOM             500         100000                 2  thrpt   15      491.000                  ms```**AFTER**```Benchmark                                                                                                  (bufferSupplierStr)  (bytes)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   UnitsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed                                        NO_CACHING   RANDOM             500         100000                 2  thrpt   15  2715876.329 ± 4288.625   ops/sUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate                         NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4163.501 ±    6.553  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate.norm                    NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1688.000 ±    0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4164.497 ±   56.694  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1688.397 ±   22.173    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.008 ±    0.002  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.003 ±    0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.count                              NO_CACHING   RANDOM             500         100000                 2  thrpt   15      536.000             countsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.time                               NO_CACHING   RANDOM             500         100000                 2  thrpt   15      518.000                 ms```Reviewers: Ismael Juma <ismael@juma.me.uk>,5
Manually configured JAVA_HOME is preferred over system configuration. No default JAVA_HOME is used. Instead an error message is shown. Adresses #207Added use of default java command as third option (after stratosphere-conf.yaml and JAVA_HOME).,5
Minor fix for delete topic,4
"MINOR: Remove unused ShutdownableThread class and ineffective ThreadedTest class (#12410)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Christo Lolov <christo_lolov@yahoo.com>",3
KAFKA-6489; Fetcher.retrieveOffsetsByTimes() should batch the metadata fetch.Currently if users call KafkaConsumer.offsetsForTimes() with a large set of partitions. The consumer will add one topic at a time for the metadata refresh. We should add all the topics to the metadata topics and just do one metadata refresh instead.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4478 from becketqin/KAFKA-6849,5
[hotfix][table-common] Add logical type root/family argument strategies,2
Disabled receiver-side spilling,5
"[FLINK-7243][connector] Add ParquetInputFormats for Row, Map, and POJO.This closes #6483.",1
"KAFKA-2988; Change default configuration of the log cleanerAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #686 from granthenke/compaction",4
[FLINK-3292]Fix for Bug in flink-jdbc. Not all JDBC drivers supportedThis closes #1551,1
[streaming] Updated logging to utilize SLF4J,2
"[FLINK-5798] [rpc] Let the RpcService provide a ScheduledExecutorServiceThis PR adds the getScheduledExecutorService method to the RpcService interface. Sohenceforth all RpcService implementations have to provide a ScheduledExecutorServiceimplementation.Currently, we only support the AkkaRpcService. The AkkaRpcService returns aScheduledExecutorService proxy which forwards the schedule calls to the ActorSystem'sinternal scheduler.Introduce ScheduledExecutor interface to hide service methods from the ScheduledExecutorServiceThis closes #3310.",5
[FLINK-29051][quickstarts] Do not create dependency-reduced-pom,1
"MINOR: remove ""auto.commit.interval.ms"" from ""Manual Offset Control"" exampleAuthor: xuwei-k <6b656e6a69@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1578 from xuwei-k/Manual-Offset-Control-example",1
[FLINK-12161][table-planner-blink] Supports partial-final optimization for stream group aggregate (#8148),1
"[hotfix] Make end-to-end test scripts more robustThis uses traps to ensure that we properly do cleanups, remove configvalues and shutdown things.",5
[FLINK-25230][table-planner] Replace RelDataType with LogicalType serialization,2
MINOR: Set `replicaId` for OffsetsForLeaderEpoch from followers (#6775)Reviewers: Jason Gustafson <jason@confluent.io>,5
"[hotfix] [build] Fix curator deps, Exclude Curator deps in TestsTests would fail because of version conflicts because the tests includethe original curator dependencies even though we shade them away in thefinal build result.This also fixes dependency management entries for curator dependencies.We shade it, therefore it cannot be in the dependency managementsection in the root pom.",0
KAFKA-3477: extended KStream/KTable API to specify custom partitioner for sinksAuthor: mjsax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1180 from mjsax/kafka-3477-streamPartitioner-DSL,5
Added class stubs for high level iteration constructs.,1
DUBBO-366 修改工程结构，折叠子模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1667 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-3825] [cep, doc] Documentation for CEP Scala API.[FLINK-3825] Documentation for CEP Scala API. Minor beautification on (flat-)select function code example.This closes #1960.",1
[tests] Add 'CheckedThread' as a common test utility,3
Filter UDFs always considers all fields as constants,5
"KAFKA-2946; MINOR: Follow up. Add Delete to AclCommandTestAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1730 from granthenke/test-delete",3
"[FLINK-25781][network] Adjust the maximum number of buffers can be used per result partition for data read of sort-shuffleCurrently, for sort-shuffle, the maximum number of buffers can be used per result partition for shuffle data read is 32M. However, for large parallelism jobs, 32M is not enough and for small parallelism jobs, 32M may waste buffers. This patch tries to solve the problem by adjusting the maximum number of buffers can be used per result partition for shuffle data read from 32M to Math.max(16M, numSubpartitions).This closes #18473.",5
KAFKA-2538: Fixing a compilation error in trunk.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Guozhang WangCloses #208 from Parth-Brahmbhatt/KAFKA-2538,1
"MINOR: Supplement the description of `Valid Values` in the documentation of `compression.type` (#11985)Because a validator is added to ProducerConfig.COMPRESSION_TYPE_CONFIG and KafkaConfig.CompressionTypeProp, the corresponding testCase is improved to verify whether the wrong value of compression.type will throw a ConfigException.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-3995] [build] flink-test-utils also contains the streaming test utilities.Test utilities include the StreamingMultipleProgramsTestBase and StreamingTestEnvironment.This moves the ITCases for streaming into 'flink-tests' to achieve that.This closes #2092,3
[FLINK-11768] Update TypeSerializerSnapshotMigrationITCase for Flink 1.8,2
Merge branch 'dev-metadata' of https://github.com/apache/incubator-dubbo into dev-metadata,5
more cleanup,4
"KAFKA-4656; Improve test coverage of CompositeReadOnlyKeyValueStoreAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3292 from jeyhunkarimov/KAFKA-4656",4
[FLINK-2793] [runtime-web] Redirect to leader in non-standalone modeSquashes:5a88d5e [tests] Add HttpTestClient for testing HTTP responses656d6d6 Split WebMonitor and LeaderRetrievalService start upa7e8da8 Move generated /web files to src/main/resourcesAdd comment to webMonitorPort attribute and make line breaks more ScalaesqueDon't block on leader retrieval and only resolve associated job manager onceMake JobManagerRetriever independent of redirecting logicThis closes #1202.,2
[FLINK-13959] Remove usages of the DetachedEnvironment and the class itself.,4
[hotfix] Change shutdown order in WebMonitorEndpoint to avoid illegal state,4
"[FLINK-4201] [runtime] Forward suspend to checkpoint coordinatorSuspended jobs were leading to shutdown of the checkpoint coordinatorand hence removal of checkpoint state. For standalone recovery modethis is OK as no state can be recovered anyways (unchanged in this PR).For HA though this lead to removal of checkpoint state, which weactually want to keep for recovery.We have the following behaviour now:-----------+------------+-------------------           | Standalone | High Availability-----------+------------+------------------- SUSPENDED |  Discard   |       Keep-----------+------------+------------------- FINISHED/ |  Discard   |     Discard FAILED/   |            | CANCELED  |            |-----------+------------+-------------------This closes #2276.",0
[FLINK-26619][python][docs] Add document for the window assigners in Python DataStream APIThis closes #19122.,5
[FLINK-19824][table-api] Refactor and merge SupportsComputedColumnPushDown and SupportsWatermarkPushDown interfacesThis closes #13806,1
[FLINK-11755] [core] Drop no longer used class CompatibilityResult,1
KAFKA-995 Ensure that replica fetch size is > max message size on server.,5
"MINOR: Remove unused TopicAndPartition and remove unused symbols (#7119)With the removal of ZkUtils and AdminUtils, TopicAndPartition is finallyunused.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-9887 fix failed task or connector count on startup failure (#8844)Moved the responsibility for recording task and connector startup and failure metrics from the invocation codeinto the status listener. The reason behind this is that the WorkerTasks (and subclasses) were either not propagating exceptions upwards, or were unable to do so easily because they were running on completely different threads.Also split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make surethe Data Abstraction Count checkStyle rule was not violated.Author: Michael Carter <michael.carter@instaclustr.com>Reviewers: Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
Fix missing IOException import in JobManager,2
DUBBO-396 Spring配置时，filter属性配置上default值时出异常git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1882 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-16437][runtime] SlotManager allocate resource from ResourceManager with WorkerRequest instead of ResourceProfile.This marks ResourceManager is no longer aware of slot ResourceProfiles.This closes #11320.,2
[hotfix] Remove unused OneSlotPerExecutionSlotAllocator,1
[FLINK-7116] [rpc] Add getPort to RpcServiceThe RpcService should expose its port it is bound to. That way it is easier to connect to aremote RpcService.This closes #4275.,1
[FLINK-17512] Add notification settings to .asf.yaml,1
[FLINK-25092][tests][elasticsearch] Refactor test to use artifact cacher,1
[FLINK-4301] [docs] Make the quickstart's Flink version configurableThis closes #6204.,5
MINOR: install Exit.exit handler in BrokerMetadataPublisherTest (#12142)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-19244][csv] Fix CSV format can't deserialize null ROW fieldThis closes #13426,0
KAFKA-1560 Make arguments to jira-python API more explicit in kafka-patch-review's get_jira(); reviewed by Neha Narkhede,1
[hotfix] Remove @Experimental from DataStream.forward(),5
KAFKA-8988; Replace CreatePartitions Request/Response with automated protocol (#7493)This change updates the CreatePartitions request and response api objectsto use the generated protocol classes.Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-23290][table-runtime] Fix NullPointerException when filter contains casting to booleanThis closes #16420,0
[FLINK-14477][coordination] Move shuffle service access into TEPartitionTracker,4
"Refactored iterators, adopted sort merging logic.",2
"MINOR: Fix setting of ACLs and ZK shutdown in test harnessesI found both issues while investigating the issue described in PR #1425.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #1455 from ijuma/fix-integration-test-harness-and-zk-test-harness",3
Simplified exception stack traces when file is not found.,2
[FLINK-7311][tests] refrain from using fail(Exception#getMessage())This closes #4446.,0
"[FLINK-4310] [build] Selectively run API compatibility checks in API projects.This moves the API compatibility checks into the API projects that use stability annotations.Previously, every project ran the tests, regardless of whether it contained public API classes or not.This closes #2334",3
fix some xsd error (#2470)* fix some xsd error* remove version info from imported spring-beans.xsd (though I do believeincluding a version is a better practice).,1
[FLINK-9871] Use Description class for ConfigOptions with rich formattingThis closes #6371,5
[FLINK-28807] Honor schema lifecycle,2
"[FLINK-6646] [yarn] Let YarnJobManager delete Yarn application filesBefore the YarnClusterClient decided when to delete the Yarn application files.This is problematic because the client does not know whether a Yarn applicationis being restarted or terminated. Due to this the files where always deleted. Thisprevents Yarn from restarting a failed ApplicationMaster, effectively thwartingFlink's HA capabilities.The PR changes the behaviour such that the YarnJobManager deletes the Yarn filesif it receives a StopCluster message. That way, we can be sure that the yarn filesare deleted only iff the cluster is intended to be shut down.",4
BoundedByteBufferReceive hides OutOfMemoryError; patched by Chris Burroughs; reviewed by Neha Narkhede; KAFKA-204git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205663 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-27145][table] Support code gen for aggregate function with empty parameterThis closes #19418,2
[FLINK-9463][runtime] Fix support for epoll transport type in nettyFor more information please check https://github.com/apache/flink-shaded/issues/30,2
[hotfix] Fix ArchivedExecutionGraphTest,3
Changed visibility of SIZE_LENGTH member,4
[FLINK-17795][example] Add MatrixVectorMul exampleThis closes #12398.,1
[hotfix] Fixed import order in RocksDBKeyedStateBackend.,5
[FLINK-8659] Add migration itcases for broadcast state.This closes #5955.,1
"KAFKA-13425:  Optimization of KafkaConsumer#pause semantics (#11460)* 1. Enhance the annotation of KafkaConsumer#pause(...) method2. Add log output when clearing the paused mark of topicPartitions.Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"Revert ""[FLINK-20033] Make JobManagerJobStatusListener call back run directly""This reverts commit 03047a78b6ad8017eb240548a009424d68ffc971.This closes #14037.",4
[DUBBO-3137]: step4 - remove ClusterConstants (#4065),4
"MINOR: Do not wait for first line of console consumer output since we now have a more reliable test using JMXWaiting for the first line of output was added in KAFKA-2527 when JmxMixin was originally added as a heuristic todetermine when the process was ready. We've since determined this is not good enough given JmxTool's limitationsand now include a separate, more reliable check before starting JmxTool. This check is also dangerous since aconsumer that is started before data is available in the topic, it won't output anything to stdout and only logserrors to a separate log file. This means we may have a long delay between starting the process and starting JMXmonitoring.Since we have a more reliable check for liveness via JMX now (and in cases that need it, partition assignmentmetrics via JMX), we should no longer need to wait for the first line of output.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>Closes #3447 from ewencp/dont-wait-first-line-console-consumer",5
[FLINK-7811] Make Scala savepoint migration tests Scala-version-independent,3
MINOR: Fix Embedded ConfigDef Validator toString issue (#6339)`ConfigDef.embeddedValidator` should return an Anonymous Object instead of lambda so that we can have a useful `toString()` for methods such as `toRst`.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-8859: Refactor cache-level metrics (#7367)Cache-level metrics are refactor according to KIP-444:tag client-id changed to thread-idname hitRatio changed to hit-ratiomade backward compatible by using streams config built.in.metrics.versionReviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",5
[FLINK-11086] Clean up profiles and dependency exclusionsThis closes #11983,2
fix typo (#5834),2
Renamed packages in stratosphere-core.,5
[hotfix] Remove legacy DummyActorGateway,4
[FLINK-4506] [DataSet] Fix documentation of CsvOutputFormat about incorrect default of allowNullValues- Add test case for CsvOutputFormatThis closes #2477This closes #2631,3
[hotfix][kafka-tests] Do not hide original exception in FlinkKafkaProducer011ITCaseThis closes #5383.,2
[FLINK-18904][task] Rename NumberOfInputs to NumberOfNetworkInputs in StreamConfigThis is a preparation for adding more generic Inputs field/accessor.,1
revert #5072 by logging error msg. (#5084),0
[FLINK-19607][table-runtime-blink] Implement streaming window TopN operatorThis closes #15291,1
[hotfix] Fix checkstyle violations in TaskTest,3
HOTFIX: remove deprecated calls,4
"KAFKA-3257: disable bootstrap-test-env.sh --colour optionbecketqin, when you get a chance, could you take a look at the patch?Author: zhuchen1018 <amandazhu19620701@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #969 from zhuchen1018/KAFKA-3257",5
submitAndWait (JobClient) now returns the job duration in milliseconds,5
[release] Add 1.15 docs link to the list of previous versions,2
backup,5
added testcases for LazyArrayNode and IArrayNode,3
[FLINK-14862][runtime] Fuse initializeState and open in StreamTaskThis commit fuses the two separate passes - one for initializeState andone for open into a single initalizeStateAndOpen pass. This allowsoperators chained together to emit down stream already on initalizeState.,5
KAFKA-1960; .gitignore does not exclude test generated files and folders; reviewed by Joel Koshy and Gwen Shapira,2
"MINOR: Do not require request timeout be larger than session timeout (#5246)This check was left over from the old consumer logic in which the join group was bound by the session timeout. Since we use a custom timeout for JoinGroup, this restriction no longer makes sense.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-12429: Added serdes for the default implementation of RLMM based on an internal topic as storage. (#10271)KAFKA-12429: Added serdes for the default implementation of RLMM based on an internal topic as storage. This topic will receive events of RemoteLogSegmentMetadata, RemoteLogSegmentUpdate, and RemotePartitionDeleteMetadata. These events are serialized into Kafka protocol message format.Added tests for all the event types for that topic.This is part of the tiered storaqe implementation KIP-405.Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
拆分模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@60 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-23532] Unify stop-with-savepoint without and with drainWe unify the stop-with-savepoint with and without drain. Both of thoseoptions follow a similar codepath.1. First of all we always emit EndOfData in case of a clean shutdown, but with a flag which determines if we should call StreamOperator#finish and flush all records.2. Secondly, we stop sources once we receive a trigger for synchronous checkpoint instead of shutting them down after the checkpoint completes.3. Lastly, we no longer wait in a synchronous mailbox loop, but instead we wait on a future in the StreamTask#afterInvoke.",5
"Fixed #1186, change the default ZK client from `zkclient` to `curator`",4
[hotfix][test] Extract common variables,4
[FLINK-23478][k8s] Guarantee the event handling order in KubernetesSharedInformerThis closes #16583.,5
[FLINK-7454] [docs] Uupdate 'Monitoring Current Event Time' sectionThis closes #4547.,5
[FLINK-25785][Connectors][JDBC] Upgrade com.h2database:h2 to 2.1.210,5
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1422 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fixed several bugs in new kryo-based RPC service,1
[FLINK-23969][connector/pulsar] Create e2e tests for pulsar connector.,3
"KAFKA-3330; Truncate log cleaner offset checkpoint if the log is truncatedbecketqin Can you take a look?Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1009 from lindong28/KAFKA-3330",5
Fix reconnect bug (#7329),0
"KAFKA-3835; Streams is creating two ProducerRecords for each send via RecordCollectorAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2417 from jeyhunkarimov/KAFKA-3835",4
[hotfix] Rework ZooKeeperLeaderElectionITCase to not rely on DispatcherResourceManagerComponent internals,1
[streaming] RMQSink and Test,3
"[FLINK-16653][network][tests] Implement MockResultPartitionWriter base for simplifying testsAt the moment there are at-least four implementations of `ResultPartitionWriter` interface used in unit tests.And there are about ten methods to be implemented for `ResultPartitionWriter` and most of them are dummy in tests.When we want to extend the methods for `ResultPartitionWriter`, the above four dummy implementations in tests have to be adjusted as well, to waste a bit efforts.Therefore the MockResultPartitionWriter is proposed to implement the basic dummy methods for `ResultPartitionWriter`,and the previous four instances can all extend it to only implement one or two methods based on specific requirements in tests.It will probably only need to adjust the MockResultPartitionWriter when extending the `ResultPartitionWriter` interface.This closes #11441.",3
"KAFKA-8715; Fix buggy reliance on state timestamp in static member.id generation (#7116)The bug is that we accidentally used the current state timestamp for the group instead of the real current time. When a group is first loaded, this timestamp is not initialized, so this resulted in a `NoSuchElementException`. Additionally this violated the intended uniqueness of the memberId, which could have broken the group instance fencing. Fix is made and unit test to make sure the timestamp is properly encoded within the returned member.id.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Fixed plan web display.,0
[hotfix][connectors/jdbc] Rename JdbcOutputFormat to JdbcRowOutputFormatCurrent JdbcOutputFormat works only with Rows which makes the namemisleading and doesn't allow to use it for more abstract version(which will be introduce in the subsequent commit).,1
[hotfix] [table] Fix typos in Table javadoc.This closes #7388.,2
[FLINK-12857][table-common] move FilterableTableSource into flink-table-commonThis closes #8748,2
增加void方法的单元测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@825 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][coordination] Fix MiniCluster#closeAsync to correctly close all components and services,5
[FLINK-16331][legal] Remove source licenses for old WebUI,4
[FLINK-10267][state] Fix arbitrary iterator access on RocksDBMapIteratorThis closes #6638.,5
modify apache license,5
"remove unnecessary semicolon (#9207)Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@apache.com>",5
[FLINK-16674][python][docs] Add documentation about how to use user-defined metrics for Python UDF (#11576),1
"[hotfix] Disable WAL in RocksDB state ""clear""",5
[FLINK-29182][table] fix redundant computations in SumAggFunction. (#20738),1
[FLINK-4173][metrics] Replace assembly-plugin usage,2
Improved robustness of clean-up procedure when task is canceled,4
[FLINK-27618][sql] Flink SQL supports CUME_DIST function (#19727),1
[streaming] StreamWindow abstraction added with typeinfo and tests,3
[FLINK-20536][tests] Update migration tests of AbstractNonKeyedOperatorRestoreTestBase to cover migration from 1.12,3
KAFKA-350 Enable message replication in the presence of failures; patched by Neha Narkhede; reviewed by Jun Rao and Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1365199 13f79535-47bb-0310-9956-ffa450edef68,0
KAFKA-7106: remove deprecated Windows APIs (#10378)1. Remove all deprecated APIs in KIP-328.2. Remove deprecated APIs in Windows in KIP-358.Reviewers: John Roesler <vvcephei@apache.org>,4
"[FLINK-14067] Refactor ExecutionEnvironment.getExecutionPlan() to be in root classBefore, each subclass had a slightly different way of getting theexecution plan (as JSON). Now, we factor that part out into a utilityand use that in the ExecutionEnvironment root class. This does mean,that we don't take into account special information that a clusterclient or some other environment might have for plan generation.Also, we can't remove the throws Exception from getExecutionPlan()because it is a @Public method.",1
[FLINK-25391][format-csv] Forward catalog table options,2
MINOR: Allow for asynchronous start of producer consumer in validation testAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1909 from kkonstantine/MINOR-Async-start-in-produce-consume-validate,5
[FLINK-16587][checkpointing] Introduce BufferReceivedListener for notifying of received buffers and barriers from network channel.,1
Reworked stub annotations to ConstantFields only,1
"MINOR: Rename TopicCommandTest (#8398)Rename the test suite to later add unit tests that don't depend onZK or the AdminClient TopiCommand types.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
[FLINK-1110] Fix Reduce and GroupReduce Test Failures,0
[FLINK-16217][sql-client] Fix exception catching to avoid SQL client crashesThis closes #11397.,0
[FLINK-7623][tests] Add tests verifying isRestored flag,3
feat: remove the unnecessary class of SaveProperties and loadding Properties use try-resource (#10276),1
[FLINK-12164][runtime] Harden JobMasterTest against timeoutsThis closes #8388.,3
Add warning in nephele-config.sh that the values are only defaultsI added this because several people already mistook this for the actualplace to change config values.,5
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalSortAggregate, and make BatchExecSortAggregate only extended from ExecNodeThis closes #14562",1
[Distributed runtime] Fail task if execution state update is unsuccessful,5
[FLINK-14019][python] Add necessary changes on shell script and boot.py to support pip installation and changing working directory.,1
[FLINK-3664] Create DataSetUtils method to easily summarize a DataSet of TuplesThis closes #1859,5
fix number type is lost in yaml config file (#1401)* #1399 fi* update test,3
"[FLINK-21132][runtime] Don't end input on stop with savepointEndOfInput was used to handle any stopping of the job. Whenstopping with savepoint the input is not actually ended.This causes issues with some sinks (e.g. Iceberg).With this change, endInput is not call for stop-with-savepoint.To differentiate stop-with-savepoint from other casesonly checkpoint (RPC/barriers) are considered and not network EOP.That's enough because EOP is only injected after the CP completion(i.e. when the downstream is also notified by sync savepoint by CPbarriers).",1
KAFKA-1443 Add delete topic option to topic commands; reviewed by Neha Narkhede,4
"[FLINK-12122] Calculate TaskExecutorUtilization when listing available slotsWhen listing available slots stored in the SlotPool and the SlotSharingManager, the systemwill now also calculate the utilization of the owning TaskExecutor wrt the job.",5
fix tomcat9 support. #5711 (#6066),1
[FLINK-27794][connectors/jdbc] Fix the wrong primary key for MysqlCatalog when there are tables with same name in different databasesThis closes ##20025.,5
[FLINK-20309][network] Add NetworkActionsLogger for easier debugging,0
update pom.xml,5
DUBBO-568 - 配置项dispather单词拼写错误。,5
还原page包名git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@438 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-149: Current perf directory has buggy perf tests; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179791 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix][tests] StreamTaskTestHarness: use Preconditions.checkState instead of explicit throw IllegalStateException,1
MINOR: Small logging fixes in AbstractCoordinator (#7230)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-25487][core][table-planner-loader] Improve verbosity of classloading errorsThis closes #18283.,0
[FLINK-24407][doc-zh] Fix the broken links in Chinese document of Pulsar connectorThis closes #17622.,2
DUBBO-173monitor和registry增加parameter子标签git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@814 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-2357] [web dashboard] Auto-update overview page,5
修改依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@76 1a56cb94-b969-4eaa-88fa-be21384802f2,1
- added WordCountTest based on WordCount example job- updated pact program tests- removed old wordcount tests,3
[hotfix][table] Simplify FlinkCalciteSqlValidatorThis closes #10981.,5
DUBBO-354 增加异步示例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1672 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-10000: Exactly-once source tasks (#11780)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Tom Bentley <tbentley@redhat.com>",5
"KAFKA-10017: fix flaky EOS-beta upgrade test (#9688)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"[FLINK-15254][sql cli][module] modules in SQL CLI yaml should preserve ordercurrently the module map is a hash map in sql cli, which doesn't preserve module loading order from yaml.fix it by always using a linked hash mapthis closes #10578.",2
[FLINK-2694] [test-stability] Hardens the JobManagerProcessReapingTest.testReapProcessOnFailure test case by letting the JobManager choose its port instead of predetermining it via the NetUtils.getAvailablePort.This closes #1145.,1
[hotfix] Migrates ApplicationStatusTest to JUnit5 and AssertJ,3
[FLINK-1201] [gelly] return arbitrary type instead of Tuple2 for the neighbor methods,2
fixbug: Unit test often time out (#8439)1. Make sure zookeeper is shutdown after all testcases finished2. Remove unused import3. Update unnecessary multiple zookeeper instances to single zookeeper instance4. Define SingleRegistryCenter and MultipleRegistryCenter,1
Plans do not reuse provided collections.,1
[FLINK-22773][coordination] Make DefaultLogicalPipelinedRegion inherit from LogicalPipelinedRegion,2
[FLINK-22694][e2e] Use SQL file in TPCH end to end tests (#15944),3
[FLINK-22619][python] Drop Python UDF serializers for old plannerThis closes #16008.,4
[FLINK-7576] [futures] Add FutureUtils.retryWithDelayFutureUtils.retryWithDelay executes the given operation of typeCallable<CompletableFuture<T>> n times and waits in between retries the givendelay. This allows to retry an operation with a specified delay.Make retry and retry with delay future properly cancellableThis closes #4637.,1
KAFKA-5486: org.apache.kafka logging should go to server.logThe current config sends org.apache.kafka and any unspecified logger tostdout. They should go to `server.log` instead.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3402 from ijuma/kafka-5486-org.apache.kafka-logging-server.log,2
[3.0-Triple] Refactor transport state and other code (#9057)* refactor(tri): refactor transport state and other code* fix rat* remove unused code* refactor stream call* fix style* refactor client stream obServer* fix ut* finish client refactor* refactor client construct the stream* fix ut* fix comment* avoid block* avoid block* fix ut* remove response error in util* Abstract client and server transport* fix comment* fix ut* Optimize interface* Optimize promise* Fix ut* remove unused code* Start call only when the channel creation is successful* start call switch user threadsCo-authored-by: guohao <guohaoice@gmail.com>,1
"MINOR: Rework NewPartitionReassignment public API (#7638)This patch removes the NewPartitionReassignment#of() method in favor of a simple constructor. Said method was confusing due to breaking two conventions - always returning a non-empty Optional and thus not being used as a static factory method.Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",1
[FLINK-11189] Deprecated documentation for readSequenceFile function,1
[FLINK-16300][tests] Introduce ExecutionGraphTestUtils#getExecutions(…) to replace SchedulerTestUtils#getTestVertex(…),3
Create issue templates,0
"KAFKA-7245: Deprecate WindowStore#put(key, value) (#7105)Implements KIP-474.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-7296; Handle coordinator loading error in TxnOffsetCommit (#5514)We should check TxnOffsetCommit responses for the COORDINATOR_LOADING_IN_PROGRESS error code and retry if we see it. Additionally, if we encounter an abortable error, we need to ensure that pending transaction offset commits are cleared.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
Upgrade to metrics jar to 3.x to pick up csv reporter fixes; KAFKA-542; patched by Joel Koshy; reviewed by Neha Narkhede.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396336 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-4688; Kafka 0.10.1.1 should be available in system testsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2424 from cmccabe/KAFKA-4688",5
[FLINK-8633] [flip6] Expose rescaling of jobs via the DispatcherThis commit exposes the JobMaster#rescaleJob via the Dispatcher. This willallow it to call this functionality from a REST handler.This closes #5452.,0
"fix offlineApp does not work as expected, because of empty revision check stops the de-registration. (#10009)fixes #9986",0
"Revert ""Reduce memory allocation during address change notification. (#5613)"" (#6119)This reverts commit 6491ed01b7ba7cdcf2c26934ca806df3a89cf2a9.",4
Removed warnings,2
DUBBO-424,5
[hotfix][docs] List FileSystem also as a source,5
"KAFKA-10763: Fix incomplete cooperative rebalances preventing connector/task revocations (#9765)When two cooperative rebalances take place soon after one another, a prior rebalance may not complete before the next rebalance is started.Under Eager rebalancing, no tasks would have been started, so the subsequent onRevoked call is intentionally skipped whenever rebalanceResolved was false.Under Incremental Cooperative rebalancing, the same logic causes the DistributedHerder to skip stopping all of the connector/task revocations which occur in the second rebalance.The DistributedHerder still removes the revoked connectors/tasks from its assignment, so that the DistributedHerder and Worker have different knowledge of running connectors/tasks.This causes the connector/task instances that would have been stopped to disappear from the rebalance protocol, and left running until their workers are halted, or they fail.Connectors/Tasks which were then reassigned to other workers by the rebalance protocol would be duplicated, and run concurrently with zombie connectors/tasks.Connectors/Tasks which were reassigned back to the same worker would encounter exceptions in Worker, indicating that the connector/task existed and was already running.* Added test for revoking and then reassigning a connector under normal circumstances* Added test for revoking and then reassigning a connector following an incomplete cooperative rebalance* Changed expectRebalance to make assignment fields mutable before passing them into the DistributedHerder* Only skip revocation for the Eager protocol, and never skip revocation for incremental cooperative protocolsReviewers: Konstantine Karantasis <k.karantasis@gmail.com>",4
[FLINK-25331][tests] FlinkImageBuilder checks for Java 17,2
[hotfix] [docs] Fix typosThis closes #5289.,2
KAFKA-5817: [FOLLOW-UP] add SerializedInternalAdd `SerializedInternal` class and remove getters from `Serialized`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3825 from dguy/kafka-5817-follow-up,1
"MINOR: Fix Streams EOS system tests (#4572)Avoid loosing log/stdout/stderr files on restartReenables testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
DUBBO-77 ExceptionFilter在抛出RpcException时应在服务提供方打印出错日志git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@347 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[streaming] wordcount moved out from testbase,3
[hotfix][docs] Add back-to-top button to connector page,1
KAFKA-3430: Allow users to set key in KTable.toStream and in KStream.… With KStream the method selectKey was added to enable getting a key from values before perfoming aggregation-by-key operations on original streams that have null keys.Author: bbejeck <bbejeck@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1222 from bbejeck/KAFKA-3430_allow_users_to_set_key_KTable_toStream,1
Added generic type comparators and adjusted type accessors.,1
Update Netty dependency to 4.0.21.Final,5
Fix typo in StreamExecutionEnvironment (#7854),2
[hotfix][docs-zh] Fix the formatting of Chinese documents.,2
[FLINK-9524] [table] Check for expired clean-up timers to prevent NPE in ProcTimeBoundedRangeOver.This closes #6180.,4
[FLINK-21377][coordination][tests] Move JobMaster QS tests to separate file,2
"[FLINK-13266][table-common] Improve comment for FilterableTableTableSourceFlink planner planner will push down PlannerExpressions (which are defined in flink-table-planner module), while Blink planner will push down Expressions. So the implementation for Flink planner and Blink planner should be different and incompatible.",2
[FLINK-4460] Add WindowOperatorContractTest tests for late data emission,5
[FLINK-28486][docs-zh] Flink FileSystem SQL Connector Doc is not rightThis closes #20255,2
MINOR: Set log level for producer internals to trace for transactions testWe need this to debug most issues with the transactions system test.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3261 from apurvam/MINOR-set-log-level-for-producer-to-trace-for-transactions-test,3
[FLINK-18417][table] Support List as a conversion class for ARRAYThis closes #12765.,1
[hotfix][coordination] Adjust TaskExecutor resource to reasonably large value for local executionThis fix is to avoid arithmetic overflow in calculating the resource overview of the minicluster.,5
[FLINK-16655][FLINK-16657] Introduce embedded executor and use it in Web SubmissionThis closes #11460.,1
"KAFKA-12471: Implement createPartitions in KIP-500 mode (#10343)Implement the createPartitions RPC which adds more partitions to a topicin the KIP-500 controller.  Factor out some of the logic for validatingmanual partition assignments, so that it can be shared betweencreateTopics and createPartitions.  Add a startPartition argument to thereplica placer.Reviewers: Jason Gustafson <jason@confluent.io>",5
"Extended compiler tests for K-Means.Fixed Cost formulas to properly distinguish between sorted, hashed, and arbitrary materialization.",0
[hotfix][runtime] Fixes parameter order in trace log messages,2
[hotfix][typo] fix typo in ContaineredTaskManagerParameters,2
[hotfix] [docs] add missing YARN options in CLI docs,2
"KAFKA-10611: Merge log error to avoid double error (#9407)When using an error tracking system, two error log messages result into two different alerts.It's best to group the logs and have one error with all the information.For example when using with Sentry, this double line of log.error will create 2 different Issues. One can merge the issues but it will be simpler to have a single error log line.Signed-off-by: Benoit Maggi <benoit.maggi@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Konstantine Karantasis <k.karantasis@gmail.com>",2
[FLINK-9293] [runtime] SlotPool should check slot id when accepting a slot offer with existing allocation idThis closes #5951,1
Removed System.out.println statements for checkpointing decisions.,5
[streaming] replaced synchronized methods with concurrent collections,5
[FLINK-13643][hive][docs] Document the workaround for users with a different minor Hive versionDocument the workaround for users with a different minor Hive versionThis closes #9447.,1
KAFKA-2308: make MemoryRecords idempotent; reviewed by Guozhang Wang,1
[FLINK-5681] [runtime] Make ReaperThread for SafetyNetCloseableRegistry a singletonThis closes #3230,1
#1067: I18N effort for dubbo code base - dubbo-rpc (part8),5
[hotfix] Fix loop in FailingSource,0
[FLINK-25032][runtime] Allow parallelism of ExecutionJobVertex to be decided lazily.,1
[FLINK-26573][test] Do not resolve the metadata file which is in progress,2
"KAFKA-9848: Avoid triggering scheduled rebalance delay when task assignment fails but Connect workers remain in the group (#8805)In the first version of the incremental cooperative protocol, in the presence of a failed sync request by the leader, the assignor was designed to treat the unapplied assignments as lost and trigger a rebalance delay. This commit applies optimizations in these cases to avoid the unnecessary activation of the rebalancing delay. First, if the worker that loses the sync group request or response is the leader, then it detects this failure by checking the what is the expected generation when it performs task assignments. If it's not the expected one, it resets its view of the previous assignment because it wasn't successfully applied and it doesn't represent a correct state. Furthermore, if the worker that has missed the assignment sync is an ordinary worker, then the leader is able to detect that there are lost assignments and instead of triggering a rebalance delay among the same members of the group, it treats the lost tasks as new tasks and reassigns them immediately. If the lost assignment included revocations that were not applied, the leader reapplies these revocations again. Existing unit tests and integration tests are adapted to test the proposed optimizations. Reviewers: Randall Hauch <rhauch@gmail.com>",3
"[FLINK-1285] Various cleanup of object reusing and non-reusing code. - The map driver now also supports this - In the merge iterator (merges sorted runs from external sort), we now always use the non-reusing code path,   because the reusing codepath here implies in all cases additional instances to be held concurrently, and copy   between elements, which voids the benefits of reusing elements. - For many utility iterators (in test cases), consolidates the logic between the two variants of the ""next()""   functions (one calls the other, where possible) - Eliminates a few copies between elements in the non-reusing parts (where possible) - Removes unused variables in the non-reusing variants (mainly serializers previously used to create instance   or copy between instances) - Remove some unused types -  Improves generic type safety (fewer raw types)",1
[hotfix] [tests] Harden YarnSessionFIFOITCase#testDetachedModeWait for the completion of the submitted job in order to avoid that we killthe JM while the TM tries to down load blobs from it.,3
[FLINK-25432][runtime] Makes JobManagerMetricGroup implement LocallyCleanableResource and GloballyCleanableResource,4
GRPC is compiled in default order (#8200)Co-authored-by: tiangua <tiangua@gaoding.com>,5
kafka-1041; Number of file handles increases indefinitely in producer if broker host is unresolvable; patched by Rajasekar Elango; reviewed by Jun Rao,5
"KAFKA-6214: enable use of in-memory store for standby tasksRemove the flag in `ProcessorStateManager` that checks if a store is persistent when registering it as a standby task.Updated the smoke test to use an in-memory store.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #4239 from dguy/kafka-6214",5
"KAFKA-14201; Consumer should not send group instance ID if committing with empty member ID (server side) (#12598)The consumer group instance ID is used to support a notion of ""static"" consumer groups. The idea is to be able to identify the same group instance across restarts so that a rebalance is not needed. However, if the user sets `group.instance.id` in the consumer configuration, but uses ""simple"" assignment with `assign()`, then the instance ID nevertheless is sent in the OffsetCommit request to the coordinator. This may result in a surprising UNKNOWN_MEMBER_ID error.This PR attempts to fix this issue for existing consumers by relaxing the validation in this case. One way is to simply ignore the member id and the static id when the generation id is -1. -1 signals that the request comes from either the admin client or a consumer which does not use the group management. This does not apply to transactional offsets commit.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Fix JAAS configuration numbering (#7601)7.3.1.1 JAAS configuration for Kafka brokers was followed by7.3.1.4 JAAS configuration for Kafka clients instead of 7.3.1.2.Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
[FLINK-2268] Dynamically load Hadoop security module when available,2
Switched to cached thread pool in task manager to speed up cancelling of tasks,5
"KAFKA-5767; Kafka server should halt if IBP < 1.0.0 and there is log directory failureAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3718 from lindong28/KAFKA-5767",0
[FLINK-9677][rest] Cleanup encoder after request has been processedThis closes #6217.,4
"KAFKA-7704: MaxLag.Replica metric is reported incorrectly (#5998)On the follower side, for the empty `LogAppendInfo` retrieved from the leader, fetcherLagStats set the wrong lag for fetcherLagStats due to `nextOffset` is zero.",1
Added required library to jobmanager and taskmanager start scripts,1
"MINOR: Stabilize flaky smoke system tests before KIP-91This is a workaround until KIP-91 is merged. We tried increasing the timeout multiple times already but tests are still flaky.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4329 from mjsax/hotfix-system-tests",5
kafka-1815; ServerShutdownTest fails in trunk; patched by Chris Cope; reviewed by Jun Rao,1
"KAFKA-9126: KIP-689: StreamJoined changelog configuration (#9708)Add withLoggingEnabled and withLoggingDisabled for StreamJoinedto give StreamJoined the same flexibility as MaterializedReviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
remove duplicate .flattened-pom.xml from .gitignore (#5897),5
kafka-1940; Initial checkout and build failing; patched by Martin Lemanski; reviewed by Jun Rao,0
performance tuning: avoid address resolve (#4220),0
"KAFKA-5694; Add AlterReplicaDirRequest and DescribeReplicaDirRequest (KIP-113 part-1)Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Colin P. Mccabe <cmccabe@confluent.io>Closes #3621 from lindong28/KAFKA-5694",5
[FLINK-28336][python][format] Support parquet-avro format DataStream APIThis closes #20124.,5
[FLINK-18879][python] Support Row Serialization and Deserialization schemas for Python DataStream API. (#13150),5
Revised fuzzy matching of test recordsMerge branch 'master' of https://stratosphere.eu/git/hpiConflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.java,5
"[FLINK-6136] Separate EmbeddedHaServices and StandaloneHaServicesThis PR introduces a standalone high availability services implementation which can be usedin a distributed setting with no HA guarantees. Additionally, it introduces a common baseclass which is also used by the EmbeddedHaServices. This base class instantiates thestandalone variants of the checkpoint recovery factory, submitted job graphs store, runningjobs registry and blob store.The StandaloneHaServices are instantiated with a fixed address for the Job- andResourceManager. This address and the HighAvailability.DEFAULT_LEADER_ID is returned bythe corresponding LeaderRetrievalServices when being started.This closes #3622.",1
[FLINK-20024][docs][docker] Add link to flink-docker repositoryThis closes #13962.,2
[streaming] FaultTolerance test update,5
"[hotfix] Cleanup unused methods / appropriate method renames in StateMetaInfoSnapshotThis commit removes the `restoreTypeSerializer(...)` method.That method is no longer used after the series of changes inFLINK-11094. This also corresponds to the new principle that the restoreserializer is only accessed, when the state backends attempt request itfrom their state meta infos. We do not create restore serializerseagerly when creating meta infos from a StateMetaInfoSnapshot.It also removes ""config"" from names of methods and fieldsrelated to serializer snapshotting.This corresponds to the abstraction rework of retiringTypeSerializerConfigSnapshot to be replaced by TypeSerializerSnapshot.The related fields / methods should not mention ""config"" anymore.",5
"[FLINK-16992][table-common] Add all ability interfaces for table sourcs and sinksThis adds all ability interfaces that are either supported already or mentionedin FLIP-95. This commit makes sure that all interfaces follow a common naming schemelike ""SupportsXXX"", ""applyXXX()"" and good documentation with consistent terminology.This closes #11692.",2
[FLINK-9593][cep] Unified After Match semantics with SQL MATCH_RECOGNIZEThis closes #6171,2
KAFKA-4644: Improve test coverage of StreamsPartitionAssignorSome exception paths not previously covered. Extracted `ensureCopartitioning` into a static class.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2448 from dguy/KAFKA-4644,4
DUBBO-396 Spring配置时，filter属性配置上default值时出异常git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1883 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-8336; Enable dynamic reconfiguration of broker's client-side certs (#6721)Enable reconfiguration of SSL keystores and truststores in client-side channel builders used by brokers for controller, transaction coordinator and replica fetchers. This enables brokers using TLS mutual authentication for inter-broker listener to use short-lived certs that may be updated before expiry without restarting brokers.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
[hotfix][connectors] Add RequestSplitEvent to 'flink-connector-base',2
"KAFKA-664 RequestPurgatory should clean up satisfied requests from watchers map. Also, simplify the purge logic - purge based on an incoming request interval.",2
"KAFKA-9490: Fix generics for Grouped (#8028)Reviewers: Andrew Choi <andchoi@linkedin.com>, John Roesler <john@confluent.io>",5
feat: 增加maven-wrapper，用户可以使用自己的maven，应用工程构建时将会使用工程的maven版本,5
DUBBO-303 RegistryDirectory线程栈内的ConcurrentHashMap改成HashMapgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1356 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-3430] Remove ""no POJO"" warning in TypeAnalyzerThis closes #1655",2
[FLINK-14045][runtime] Use SlotProviderStrategy in DefaultExecutionSlotAllocatorThis closes #9896.,1
[FLINK-11821] Fix package declaration and location of internal Kafka schema wrappers,0
"Fixed #665, redis registry support password auth",4
[FLINK-8776][flip6] Use correct port for job submission from Web UI.Use address of local WebMonitorEndpoint for the job submission from the Web UI.Rename TestingLeaderRetrievalService to SettableLeaderRetrievalService and moveclass out of test directory.This closes #5577.,3
"MINOR: Update zstd to 1.4.5 (#8766)It improves decompression speed:>For x64 cpus, expect a speed bump of at least +5%, and up to +10% in favorable cases.>ARM cpus receive more benefit, with speed improvements ranging from +15% vicinity,>and up to +50% for certain SoCs and scenarios (ARM‘s situation is more complex due>to larger differences in SoC designs).See https://github.com/facebook/zstd/releases/tag/v1.4.5 for more details.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
Fixed PACT unit test,3
"KAFKA-5294: PlainSaslServerFactory should allow a null MapIf props is null, use POLICY_NOPLAINTEXT default value: falseAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3105 from mimaison/KAFKA-5294",5
"[FLINK-14299] Introduce ProcessMetricGroupThe ProcessMetricGroup encapsulates the Status and system metrics of the ClusterEntrypoint.These have been factored out of the JobManagerMetricGroup. In order to maintain backwardscompatibility, the same scope as the JobManagerMetricGroup is being used.",1
Improved performance of BinaryOutputFormat and SequentialOutputFormat,1
"Refactor, revert ReferenceConfigCache package change",4
"[hotfix][docs] Temporarily disable liveserve./build_docs.sh -i previously did not only enable incremental documentationbuilding while serving the docs, it also enabled a 'liveserve' mode thatautomatically reloaded pages in the browser when they changed. This is basedon the 'hawkins' module which is not (yet) compatible with jekyll 4.0 which weneed to (significantly) improve build times.This disables the liveserve mode and remove the hawkins module until a newversion is available.",1
[FLINK-21127][runtime][checkpoint] Stores finished status for fully finished operators in checkpointThis closes #14754,1
"KAFKA-8229; Reset WorkerSinkTask offset commit interval after task commit (#6579)Prior to this change, the next commit time advances_each_ time a commit happens -- including when a commit happensbecause it was requested by the `Task`. When a `Task` requests acommit several times, the clock advances far into the futurewhich prevents expected periodic commits from happening.This commit changes the behavior, we reset `nextCommit` relativeto the time of the commit.Reviewers: Jason Gustafson <jason@confluent.io>",5
[FLINK-15115][kafka] Drop Kafka 0.9 SQL jar,4
[FLINK-11549][tests] Remove obsolete ResourceManagerITCase,4
KAFKA-5620: Expose the ClassCastException as the cause for the SerializationException in KafkaProducerExpose the ClassCastException as the cause for the SerializationException.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3556 from jcustenborder/KAFKA-5620,1
[hotfix][coordination] Add sanity checks to ClusterPartitionReportEntry,1
Bump compiler version to 0.0.3  release (#8687)* Bump compiler version to 0.0.3  release* Bump compiler version to 0.0.3  release,5
"MINOR: Refactor admin client helpers for checking leader and ISR (#7074)Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3652; Return error response for unsupported version of ApiVersionsRequestHandle unsupported version of ApiVersionsRequest during SASL auth as well as normal operation by returning an error response.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1310 from rajinisivaram/KAFKA-3652",5
[FLINK-14971][checkpointing] Introduce main thread executor in CheckpointCoordinator to execute all non-IO operations instead of the timer thread,2
Improve error message when scheduler cannot find a slot for immediate scheduling.,0
"[FLINK-9911][JM] Use SlotPoolGateway to call failAllocationSince the SlotPool is an actor, we must use the SlotPoolGateway to interact withthe SlotPool. Otherwise, we might risk an inconsistent state since there aremultiple threads modifying the component.This closes #6386.",1
Added junit dependency,3
The ConsumerStats MBean name should include the groupid; patched by Michael Tamm; reviewed by Jun Rao; kafka-547git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1396085 13f79535-47bb-0310-9956-ffa450edef68,1
"[FLINK-4696] [core] Limit number of Akka threads in local minicluster setupsSince Flink uses a rather small number of actors, not too many actor dispatcher threads are needed.To prevent mini cluster setups on multi-core CPUs (32 or 64 cores) to spawn too many threads,this limits the number of dispatcher threads for mini clusters.For proper Flink deployments, the threads are not limited by this change.",4
[FLINK-15803][table-common] Integrate data views into data type extractor,4
[FLINK-12165][table-planner] Added resolution rule that checks all unresolved expressions are resolvedAll resolutions should possible happen in a single place. To ensure thisis always true we added a safety rule that verifies no unresolvedexpressions are part of the output from the ExpressionResolver.This closes #8149,0
"KAFKA-10761; Kafka Raft update log start offset (#9816)Adds support for nonzero log start offsets.Changes to `Log`:1. Add a new ""reason"" for increasing the log start offset. This is used by `KafkaMetadataLog` when a snapshot is generated.2. `LogAppendInfo` should return if it was rolled because of an records append. A log is rolled when a new segment is created. This is used by `KafkaMetadataLog` to in some cases delete the created segment based on the log start offset.Changes to `KafkaMetadataLog`:1. Update both append functions to delete old segments based on the log start offset whenever the log is rolled.2. Update `lastFetchedEpoch` to return the epoch of the latest snapshot whenever the log is empty.3. Add a function that empties the log whenever the latest snapshot is greater than the replicated log. This is used when first loading the `KafkaMetadataLog` and whenever the `KafkaRaftClient` downloads a snapshot from the leader.Changes to `KafkaRaftClient`:1. Improve `validateFetchOffsetAndEpoch` so that it can handle fetch offset and last fetched epoch that are smaller than the log start offset. This is in addition to the existing code that check for a diverging log. This is used by the raft client to determine if the Fetch response should include a diverging epoch or a snapshot id. 2. When a follower finishes fetching a snapshot from the leader fully truncate the local log.3. When polling the current state the raft client should check if the state machine has generated a new snapshot and update the log start offset accordingly.Reviewers: Jason Gustafson <jason@confluent.io>",5
"[FLINK-8827] [scripts] When FLINK_CONF_DIR contains spaces, ZooKeeper related scripts failThis closes #5614",0
DUBBO-330 泛化调用时，方法是int、long类型调用失败git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1518 1a56cb94-b969-4eaa-88fa-be21384802f2,1
use composition to replace CompletableStage interface,1
[FLINK-1058] [streaming] Streaming initial documentation,2
"[FLINK-16572][e2e][pubsub] Acknowledge message in previous testThe test running before the failing test did not properly acknowledge thereception of the message.That's also the reason why this test always logged a timeout exception.With this change, the test will fail with timeout exceptions, and maybe thisimproves the overall test stability.",3
[hotfix] Add logging to the DefaultAllocatedSlotPool,2
"KAFKA-2770: Catch and ignore WakeupException for commit upon closingAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen Shapira, Geoff Anderson, Jason GustafsonCloses #470 from guozhangwang/K2770",5
"MINOR: Fix visibility of Log.{unflushedMessages, addSegment} methods (#9966)Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
[FLINK-13971][rest] Add TaskManager ID o.a.f.runtime.rest.messages.JobVertexTaskManagersInfo.TaskManagersInfoThis closes #9724.,5
[FLINK-9409] [formats] Remove flink-avro and flink-json from /optThis closes #6070.,5
[hotfix][tests] Adds log message to MiniClusterWithClientResource shutdown,5
[hotfix] Move Bucketer interface to file sink base packageThis brings it in line with RollingPolicy.,1
Adjust tests to new JobGraphModel,1
Add support for retrieving the physical memory size on FreeBSD,1
[FLINK-4129] [gelly] HITSAlgorithm should test for element-wise convergenceRemoves the example HITSAlgorithm. The Gelly library includes the moreperformant HITS algorithm.This closes #2663,4
MINOR: Doc of 'retries' config should mention max.in.flight.requests.per.connection to avoid confusionAuthor: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1607 from kawamuray/MINOR-retries-doc,2
[FLINK-19433] [docs][table] Correct example of FROM_UNIXTIME function in documentThis closes #13493Co-authored-by: zhangqike <death_note0539>,2
Avoid creating a new topic by the consumer; patched by Taylor Gautier; reviewed by Jun Rao; KAFKA-101git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1204764 13f79535-47bb-0310-9956-ffa450edef68,1
Cleaned up warnings in pact-common.,2
[FLINK-14992][client] Add job listener to execution environments,1
"KAFKA-10301: Do not clear Partition#remoteReplicasMap during partition assignment updates (#9065)We would previously update the map by adding the new replicas to the map and then removing the old ones.During a recent refactoring, we changed the logic to first clear the map and then add all the replicas to it.While this is done in a write lock, not all callers that access the map structure use a lock. It is safer to revert tothe previous behavior of showing the intermediate state of the map with extra replicas, rather than anintermediate state of the map with no replicas.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
[hotfix][flink-runtime] Fix broken CheckpointStatistics.equalsSee https://github.com/apache/flink/pull/14390 for more details.,2
"KAFKA-8215: Upgrade Rocks to v5.18.3 (#6743)This upgrade exposes a number of new options, including the WriteBufferManager which -- along with existing TableConfig options -- allows users to limit the total memory used by RocksDB across instances. This can alleviate some cascading OOM potential when, for example, a large number of stateful tasks are suddenly migrated to the same host.The RocksDB docs guarantee backwards format compatibility across versionsReviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>,",2
[FLINK-16626][runtime] Prevent REST handler from being closed more than once,0
MINOR: disable round_trip_fault_test system tests for Raft quorums (#10249)The KIP-500 early access release will not support creating a partition with a manualpartition assignment that includes a broker that is not currently online. This patch disablessystem tests for Raft-based metadata quorums where the test depends on this functionalityto pass.Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
[hotfix][tests] do not use a mocked BufferRecycler for unpooled memory segmentsThe mock will actually keep references to the segments instead of freeing them.,1
"Revert ""[hotfix] Make the checkpoint resuming e2e case pass by increasing the retained checkpoints number""This reverts commit dd9f9bf040cb82ed7e18c9fdf7c7e1ca6f43f896.",4
[3.0]Nacos notify `ServiceInstancesChangedEvent` (#8345)* Nacos notify ServiceInstancesChangedEvent* use log println error,0
DUBBO-970 修改dynamic=falsegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1495 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Remove unused import for unit test (#4976)* clear unused import,2
"[hotfix][tests] Setup closable resources in BeforeClassHaving static final resources that are closed in an @AfterClass method prevents the test from being run in a loop within the IDE, since the static fields aren't re-initialized.",5
修改RMI的ClassLoader问题，使测试通过git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@99 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix] Invert activation of new and legacy code by introducing -DlegacyCode flag,1
Support ip&port config per protocol separately,5
[hotfix][connector/common] Fix typo of variable in SourceOperator,1
Fixed RPC problem in EC2 cloud manager,0
"[FLINK-4861] [build] Package optional project artifactsPackage the Flink connectors, metrics, and libraries into subdirectoriesof a new opt directory in the release/snapshot tarballs.This closes #3014",1
Added required S3 libraries to classpath,1
[FLINK-17369][tests] Rename RestartPipelinedRegionFailoverStrategyBuildingTest to PipelinedRegionComputeUtilTest,3
"KAFKA-13890: Improve documentation of `ssl.keystore.type` and `ssl.truststore.type` (#12226)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , David Jacot <djacot@confluent.io>, Kvicii <kvicii.yu@gmail.com>",5
READMEgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@879 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-15564][yarn] Factor max vcores retrieval out of YarnClusterDescriptorFor better testability this commit introduces the YarnClusterInformationRetriever whichis responsible for retrieving the maximum number of vcores.This closes #10852.,5
[FLINK-23771][runtime][checkpoint] Fix the issue of getAllReceivedFuture if all channels are finishedThis closes #16827.,5
[FLINK-4229] Do not start any Metrics Reporter by default,2
adjust onResponse method for compatibility purpose.,5
[FLINK-29074][Connectors/JDBC] Fix ClassNotFound exception when using jdbc connector by add jar syntaxThis closes #20707,1
"[FLINK-8371][network] always recycle Buffers when releasing SpillableSubpartitionThere were places where Buffer instances were not released uponSpillableSubpartition#release() with a view attached to a non-spilledsubpartition:1) SpillableSubpartition#buffer:  SpillableSubpartition#release() delegates the recycling to the view, but  SpillableSubpartitionView does not clean up the 'buffers' queue (the  recycling was only done by the subpartition if there was no view).2) SpillableSubpartitionView#nextBuffer:  If this field is populated when the subpartition is released, it will neither  be given out in subsequent SpillableSubpartitionView#getNextBuffer() calls  (there was a short path returning 'null' here), nor was it recycled-> similarly to the PipelinesSubpartition implementation, make   SpillableSubpartition#release() always clean up and recycle the buffers-> recycle SpillableSubpartitionView#nextBuffer in   SpillableSubpartitionView#releaseAllResources()This closes #5261.",4
[FLINK-20723][cassandra][tests] Retry on NoHostAvailableException,1
"[FLINK-14504][rest] Rename AbstractTaskManagerHandlerThe name was misleading since the handler only interacts with the ResourceManager, and just happened to only be used by TaskExecutor-related handlers.",0
"MINOR: Set session timeout back to 10s for Streams system tests (#11236)We increased the default session timeout to 30s in KIP-735:https://cwiki.apache.org/confluence/display/KAFKA/KIP-735%3A+Increase+default+consumer+session+timeoutSince then, we are observing sporadic system test failuresdue to rebalances taking longer than the test timeout.Rather than increase the test wait times, we can just overridethe session timeout to a value more appropriate in the testingdomain.Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",3
Fix unit test: add runtime=true key to url,1
Implemented filebuffer to memory copy,2
"KAFKA-12938: Fix and reenable testChrootExistsAndRootIsLocked test (#10916)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Igor Soarez <soarez@apple.com>",3
[FLINK-20619][runtime] Remove unused InputDependencyConstraintThis work is part of FLINK-20589This closes #14579,2
"MINOR: Use method references instead of anonymus classes in Errors (#5525)Remove `ApiExceptionBuilder` in favour of `Function<String, ApiException>`.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
- yet another PactRecord fix (indexOutOfBounds if serializer.memory too small for direct copy),0
"KAFKA-7223: Make suppression buffer durable (#5724)This is Part 4 of suppression (durability)Part 1 was #5567 (the API)Part 2 was #5687 (the tests)Part 3 was #5693 (in-memory buffering)Implement a changelog for the suppression buffer so that the buffer state may be recovered on restart or recovery.As of this PR, suppression is suitable for general usage.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[docs] Fixes broken links on the setup_quickstart.html site,1
"[FLINK-15268][build] Correctly set Multi-Release in manifest.FLINK-14905 introduced a multi-release approach to bundle librariesfor different JDK versions. However, the multi-release flag was notcorrectly set, which effectively disabled the mechanism and lead toincomplete dependencies on Java 11. This commit fixes the setup, suchthat the Java 11 libraries are correctly loaded.",1
Fix issue with git-commit-id-plugin on Travis,0
