commit_msg,labels
test,3
test,3
more test,3
t,5
Merge branch 'master' of https://www.stratosphere.eu/stratosphereConflicts:test,5
test,3
new test,3
new test,3
new test,3
new test,3
test,3
test,3
test,3
test,3
Initial checkin.,5
- remove stratosphere/src folder,4
- Added .gitignore file,2
- Fixed webfrontend preview bug,0
Cleanup and clustermanager bug fix.,0
- pact modules are builed with tests- removed println statements from test- improved pact examples (K-Means and WordCount),1
- Added support for local filesystems to test setup- Refactored contract tests- Updated contract test configurations,5
- moved filesystem classes into designated package,5
Removed compiler error check in PactConnection#setShipStrategy,1
- updated contract tests- moved pact program tests- fixed tpch-3 program test- fixed LocalFSProvider,1
- added WordCountTest based on WordCount example job- updated pact program tests- removed old wordcount tests,3
- cleaned-up maven plugins in pom-files- added source distribution assembly- added javadocs to distributions- renamed binary distribution assembly,2
- continued maven pom-file clean-up and assembly configuration,5
- fixed PACT Webfrontend start bug,0
- fixed JavaDoc warnings,2
Mering Again,5
Initial checkin.,5
- remove stratosphere/src folder,4
- Added .gitignore file,2
- Fixed webfrontend preview bug,0
- pact modules are builed with tests- removed println statements from test- improved pact examples (K-Means and WordCount),1
Removed compiler error check in PactConnection#setShipStrategy,1
"Added javadoc comments and changed the thresholds for the doc, rank and visit filter",2
Improved java doc,2
Improved java doc,2
Improved java doc,2
added ignore,1
refactored misspelled method name getminumum,1
Fixed bug in split assignment for unspecified number of subtasks,0
Improved style and robustness of job manager end-to-end test,3
"Cleanup in FileLineReader, removed HDFSProvider.java",1
Removed superfluous files,2
Removed System.out.println commands from the Nephele code,5
Improved shut down of task manager,1
Removed unnecessary sleep times from execution graph test,3
Removed System.out.println from ByteBufferedChannelManager,5
Refactored *Notifiable to *Listener,4
Implemented check for cycles in the instance sharing dependency chain,2
Improved handling of I/O errors and javadoc for outgoing network connections,1
Removed sequence number checking from incoming connection class,4
Unified API for incoming data from the network and recovery checkpoints,1
Improved shutdown behavior of RPC server,1
Added debug message for job manager shutdown,0
Files of 0 bytes size now result in one input split,2
Restructured Nephele end-to-end test,3
Clean up for job manager test,3
Clean up for channel lookup protocol,4
Clean up for file line reader,2
Clean up for deserialization buffer,4
Added test for serialization of transfer envelopes,3
- fixed pact-test/pom.xml- removed unused imports in contract tests- updated TestBase.java,3
- deleted old code from pact-tests,3
- Minor fix,0
Reformatted ChannelCheckpoint.java according to code style rules,5
- Decreased memory requirement for check in TestBase.java to 192 MB,3
- Added JavaDocs to PACT base types in pact-common,2
Merge branch 'fhueske'Conflicts:nephele/nephele-common/pom.xmlpact/pact-common/src/main/java/eu/stratosphere/pact/common/io/OutputFormat.javapact/pact-tests/src/test/java/eu/stratosphere/pact/test/jobs/WordCount.javapact/pact-tests/src/test/java/eu/stratosphere/pact/test/jobs/WordCountMapReducePactMassiveTest.java,5
- Improved JavaDoc in pact-common,2
Fixes startup problem with bash 4.1 in cluster mode,0
Fixes package name of default instance manager in cluster mode,0
Fixes several broken javadoc references in the Nephele server module,2
Added JavaDoc for example TPCHQuery3.java,2
Updated JavaDoc for TPCH3 Query to new filter constraints,1
Fixes broken javadoc references in the Nephele management module,2
Reduces memory allocation of memory manager during Nephele end-to-end tests,3
- Added JavaDoc to pact-common contracts- Improve JavaDoc in pact-common,2
Adds support for hardware descriptions,1
Refactores instance type as a preparation for the new instance description interface,1
Adds method to query the available instance types to the management interface,1
Finishes implementation of instance hardware description,5
Removes deprecated assignment of file names for file channels,2
Removes Google collections from the build dependencies,4
Removes Google collections and modifies tests accordingly,3
Changed ByteBufferedManager to use more smaller buffers.,1
Fixes bugs in the cluster manager and improves unit tests,3
Adds new test classes and improves java doc,2
Changes behavior of local instance manager according to interface description and adds unit test,3
Added instance awareness in the compiler.,1
Merge branch 'warneke'Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/configuration/ConfigConstants.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/instance/local/LocalInstanceManager.java,5
Fixed WebLogAnalysis (including WebLogGenerator) example and added missing Javadoc tags.,2
Changed javadoc generation from compile to install phase,2
"Changed javadoc plugin execution phase to ""site""",2
Adds style checks according to code guidelines and fixes respective maven plugin configuration,5
Removed magic number and hidden field check from code style check,4
"added PowerMock,Mockito in pom.xml, new Tests",3
Fixed some bugs in nephele-common as reported by FindBugs,5
Fixed bugs as reported by FindBugs in nephele-management,5
Removed DesignedForExtension check from checkstyle template,4
Improved javadoc and style of nephele-management component,2
added some tests and the hamcrest dependancy,3
Compiler handles plans with multiple outputs.,0
renamed some tests and added missing plugin configrations,5
Improved javadoc and code style of nephele-management module,2
Fixed bug in equals method of SingleInstanceProfilingEvent,0
Fixed bug in equals method of ThreadProfilingEvent,0
Wrote unit tests for management module,3
- Added execution mode to bin/pact-start.sh,1
- Refactored test names in pact-common/../type/base,3
- Fixed JavaDocs in pact-common/../type/base/PactDouble.java,2
added failsafe plugin and hamcrest as dependancy to stratosphere/pom.xml,5
Fixed non deterministic behavior of management graph serialization,5
Fixed bug in management graph iterator implementation,0
Improved javadoc for management attachment,2
Added unit tests for the management graph and its components,3
- Adapted CrossTest.java and MatchTest.java to test for objects which are changed in the user code,1
- minor fix on debug statements in MapTest.java,3
Fixed minor flaw in source code format of Environment.java,0
Added several unit tests for the execution package,3
Improved javadoc and renamed name of test class,3
Added unit tests for event.task package in nephele-common module,3
Removed superfluous event list implementation and modified code that still used it,1
Added unit tests for event.job package in nephele-common module,3
Merge branch 'stratosphere'Conflicts:pom.xml,5
- Removed println statement in TestBase.java,3
- Added unit test for IntTupleDataInFormat.java- Added unit test for Tuple.java- Added JavaDocs to Tuple.java- Fixed bugs in Tuple.java,0
- Move time and memory intensive tests to integration tests in pact modules- Removed log level fixing from pact sort tests- Changed info logs to debug logs in pact-runtime tests- Removed invalid character from WebLogGenerator.java,2
Sorting operates directly on memory managers backing arrays.,1
Slight modification to sorting test to measure sort time.,3
current changes from dima repository,4
Completed commenst for memory manager and partly for sorting code.,5
Merge branch 'mem-manager'Conflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/sort/TestBufferSortable.java,5
Merge branch 'dima'Conflicts:pom.xml,5
Removed attached test jar again to avoid build problems,0
Added files missing from last commit,2
Merge branch 'dima'Conflicts:pom.xml,5
Commented additional plugin repositories to speed up compile process,1
Removed working directory for queue manager's test configuration,5
Changed job client interface to throw an exception in case of a job error or abort,0
- Added clean up for WordCount integration test,3
Description of task errors are now propagated to the job client,0
Removed old code,4
Added comments to all public and protected functions,1
fixed the regexp in InstanceProfile; fixed #19,0
The local and the queue scheduler now checks resource availability before accepting a job,5
Fixed network channel problem for vertices with different channel types,0
Minor improvements in the local and the queue scheduler,1
Fixed bug in SerializableHashMap.java,0
Fixed getType method in PACT compiler,1
- Fixed triangle enumeration pact program EnumTriangles.java- Added JavaDocs to EnumTriangles.java- Fixed EnumTriangleITCase.java- Removed exclude for EnumTriangleITCase from pact-tests/pom.xml,5
Cleaned up execution graph unit tests,3
"RPC server now deserializes to actual type of a call parameter, no longer the type given in the signature",2
Checkpoints created by file channels are now deleted after successful job execution,4
Fixed start scripts in cluster mode,0
- Improved EnumTriangles example- Improved EnumTrianglesITCase,1
- Fixed All-2-All Shortest Path example PACT program- Added JavaDocs to All-2-All Shortest Path example PACT program- Fixed All2AllSPITCase- Removed exclude for All2AllSPITCase,4
more generic detection of tenured space + Mac OS support,1
added tests for nepehle.configurations,5
added test coverage for nephele.configuration,5
pom.xml merge needed manual fix,0
Minor test modifications and changes to the code style/java doc,2
Added first unit tests for Nephele client package,3
- Unified Pact example program parameter handling- Remove Triangle data set generator,1
- added packaging for All2All Shortest Path example program- cleaned up pact-examples/pom.xml,5
- fixed clean up after Pact graph example jobs,4
- fixed WebLogAnalysis Pact example program- improved JavaDoc in  WebLogAnalysis Pact example program- fixed WebLogAnalysis integration test- removed exclude for WebLogAnalysis integration test,3
Transformed JobManagerTest into an integration test,3
Fixed some bugs as reported by FindBugs in Nephele's server module,5
Fixed some bugs as reported by FindBugs in Nephele's visualization module,5
Merge branch 'hu' into unittests,3
Added unit test for ChannelCheckpoint,3
Added unit test for EphemeralCheckpoint class,3
Added TODO for IO and memory manager clean up,4
"changed TextInputFormat to use any String as delimiter, Testcase also created; Ticket #20",1
Merged unittests branch to master branch,3
Added unit tests for nephele.fs,3
Added unit test for direct channel manager,3
"- removed example job launchers, use pact-clients instead",1
- Renamed TestNepheleMiniCluster to NepheleMiniClusterITCase,5
Changed ChannelSelector interface to avoid memory allocation for every record sent,4
- Renamed class in NepheleMiniClusterITCase,5
- removed old SpillingResettableIteratorTest,3
- added lastReturned() method to ResettableIterator interface- adapted interface implementations,1
- renamed SpillingResettableIteratorTest2 to SpillingResettableIteratorTest- extended SpillingResettableIteratorTest,3
Minor changes to LocalFileSystemTest,5
Added unit tests for basic Nephele types,3
- Split up ResettableIterator interface- Fixed multi input bug for CrossTask,0
- Added SerializationCopier- Adapted CrossTask to use SerializationCopier,1
"- Fixed value multi input bug for MatchTask- Moved run() method from MatchStub to MatchTask and renamed to crossValues()- added ValueDeserializer- TODO: Fix MatchStubTest, clean up MatchTask, comment ValueDeserializer, create KeyDeserializer",1
removed changes.tgz,4
added tests for QueueScheduler classes,3
"Added json, sequential, and splitting input and output formatAdded Format utilitiesAdded PactJsonObject",5
Added test harness,3
Added jackson dependency,1
little changes for robustness,4
little changes for robustness,4
- Added JavaDoc to new classes,1
added proxy,1
added buffersortable with memory guarantees,1
- extended OutputCollector to send out deep-copies for marked RecordWriters- added Unit test for OutputCollector (must be extended)- Adapted task classes to specify which RecordReaders must be fed with deep-copies,3
Added negative tests for TestPlan,3
Fixed negative tests,3
deep clone performanc test added,1
...,5
...,5
Added junit dependency,3
Fixed maven poms,0
- moved run() methods from MapStub and ReduceStub to MapTask and ReduceTask- changed map() method in MapStub from private to public- adapted MapStub implementation in examples to change in MapStub- move iterator interfaces from pact-common to pact-runtime- adapted runtime classes to iterator refactoring- move stub tests from pact-common to pact-runtime,1
"FileChannel, FileLineReadWriter Tests and changed Test for QueueScheduler",3
Nephele now also starts without configuration in local mode,5
- Smaller modifications to the PACT examples,5
added one test InstanceProfiler,2
Merge branch 'dima'Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/services/memorymanager/spi/DefaultMemorySegment.javapact/pact-runtime/pom.xmlpom.xml,5
added html as cobertura output,1
fixed bug in InstanceProfilerTest,3
Tasks release memory segments - part 1,5
Merge branch 'fhueske'Conflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/ReduceTask.java,5
"- added framework for standalone tests on tasks (TaskTestBase.java and MockEnvironment.java). Framework must be extended, e.g. IOManager & MemoryManager- added test draft for MapTask-",3
"Combine, Reduce, Match and CoGroup correctly deallocate their memory.",5
OuputEmitter reuses arrays.,1
Reverted changes to ChannelSelector interface,4
Fixed critical bug in QueueScheduler (ticket #55),0
Fixed possible NullPointerException during JobManager startup (ticket #56),0
Minor correction to log message,2
Changed path to visualization resources,4
Fixed profiling bug which led to NullPointerException in the visualization component (ticket #53),0
Fixed Bug in OutputEmitter,0
minor test change,4
added a test to reproduce the NegativeArraySizeException in ticket #62,3
added jvm params for surefire to execute pact-test/unit tests in a hudson environment,3
fixed typo,2
Add support for retrieving the physical memory size on FreeBSD,1
Only read the sysctl that is used on Mac OS X,1
- added TaskTests,3
- Added UnitTests and IntegrationTests for PACT Tasks,3
- follow-up on previous commit,5
- Removed output of tests or set it to debug level,0
- removed test tmp files,2
"- added framework for standalone tests on tasks (TaskTestBase.java and MockEnvironment.java). Framework must be extended, e.g. IOManager & MemoryManager- added test draft for MapTask-",3
- added TaskTests,3
- Added UnitTests and IntegrationTests for PACT Tasks,3
- follow-up on previous commit,5
- improved task tests,3
Merge branch 'stratosphere'Conflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CoGroupTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CoGroupTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CombineTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CombineTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CrossTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CrossTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MapTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MatchTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MatchTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/ReduceTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/ReduceTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/TempTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/TempTaskTest.java,5
TPC-H Q9 initially created.,1
Add copyright statement,1
Add a note that the output's ordering is still missing.,1
Test coverage for direct channels and gates,3
flushing for direct channels,5
Add dummy test case for the TPC-H query 9. Doesn't work yet.,1
Copy & Paste error: This is TPC-H Q9,0
"Test configuration for TPC-H Q3,Q9 was missing",5
Moved compilation logic from pact program to client.,2
"Locking Bug fixed in MemoryManager, Match Hash Strategies currently not selected by optimizer, Client Test adapted to changes.",4
JobManager/TaskManager stdout/stderr now goes to a file (ticket #58),2
- fixed bug #65,0
- fixed bug #63,0
- temp files of minicluster are written to system's temp dir,5
Fixes Nephele freeze-up when exception occurs in registerInputOutput (ticket #60),0
- fixed bug #67- improved MatchTask by reducing the number of object instanciations in crossValues() method,1
Deactivated Integration Tests for hash-match strategies.,3
- fixed bug in OutputCollector- extended OutputCollectorTest,3
Fixed issues described in tickets #57 and #71,0
Missing file from last commit,2
Fixes bug #72,0
Memory manager can release memory allocated to a task (first part),5
- added finally-clause to release memory in crossValues() method,1
- set temp dir in NepheleMiniClusterITCase to system's tmp dir- removed println statements in NepheleMiniClusterITCase,5
- solved bug #50,0
"Memory Manager allows to deallocate memory by task (part 2), Enhancement of tests to check more thoroughly for memory leaks.",3
- fixed memory release bugs for Cross and Combine in case task failure because of stub exceptions,1
Added VertexAssignmentEvent and corresponding unit test,3
Fixed bug #42,0
Removed obsolete files,2
"Forgot to change references to TPCHQuery3 to TPCHQuery9, reducedparallelism until further problems are resolved.",0
Ignore pact-tests' tmp directory contents,3
Improved style and java doc,2
Fix TPCHQuery9 so that it is working.,1
Update copyright,5
Forgot to add the TPC-H Q9 output formatter,1
Fixed Integration Tests fort Sort-Modules,3
- NepheleMiniClusterITCase brings down Nephele and MiniDFS after test- Removed clearFS() method for security reasons- Removed deprecated numTaskTrackers argument from NepheleMiniCluster,5
- fixed PowerMock-Log4J issue in pact-runtime TaskTests,3
- removed enforced debug logger configuration,5
Changed IO Manager to more report exceptions back to the readers/writers and to do proper threadsafe shutdown.,4
Added files required by the Apache License,1
- removed obsolete files in stratosphere-distribution,2
Fixed IO Manager exception reporting (part 2),0
MemoryManager.release is now called after task has finished,5
IO manager and sort code bug fixed.,0
"Fixed #64, #73 and #75",0
Fixed #36,0
Removed obsolete dependencies from nephele-profiling,4
- Fixed copy-and-paste mistake in exception statement,0
- replaced constant value by already defined final static field in SpillingResettableIteratorTest,3
- fixed CrossTaskExternalITCase to actually go to disk,0
- fixed double close of SpillingResettableIterator in CrossTask- fixed unneccessary reset of SpillingResettableIterator in CrossTask,1
"Merge branch 'warneke' (Conflicts: pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/PactCompiler.java)Fixed bug in IOManager, added extended test for IO manager.",3
SpillingResettableIterator deletes its file after operation.Added apache header to RequestQueue.,1
Integrated Sortable Buffers with space guarantees.,2
Introduced TaskManager specific construction of Java classpath,5
added TPCH Query 10,1
Fixed #59,0
Fixed #62,0
Visualization component now ignores the client's job and vertex events,5
Java heap size can now be additionally assigned through an environment variable,1
- fix #90- set jvm heap space fix to 512MB for pact-tests unit and integration tests- a separate JVM is forked for each test case in pact-tests integration tests,3
QueueSchedulerTest fixed,0
- set heap space for all tests (unit and integration tests) globally to 512MB,3
Modifications to DiscoveryService,5
removed exception printing in tests,3
"Worked on IO manager tests, fixed performance bug in match/co-group",0
TPCH Q10,5
TPCH Q10,5
TPCH Q 10,5
Inproved I/O Manager performance.,5
removed printStackTrace()n calls,4
changes in StringRecordTest,3
Fixed error in QueueSchedulerTest,3
KMeansIterationITCase: fixed problem with decimal representation,0
Merge branch 'ricos-changes',4
Fixed I/O manager implications on runtime.,1
Fixed bug in match it case.,0
DiscoveryService now works if JobManager and TaskManager are in different subnets,1
First step towards multicast channel implementation,5
- extended DefaultMemoryManagerTest,3
Exception consolidation in SortMerging components.,5
- set log config for PACT CLI client in pact-run.sh script,1
- PACT CLI client output goes to std-out,5
- fixed java heap size setting bug for local mode in nephele jobmanager script nephele-jobmanager.sh,0
Fixed potential source for deadlocks in case of task errors,0
Minor modification to generation of random filenames,2
- workaround fix for bug #96,0
- JobManager is shutdown if initialization of TaskManager fails in local execution mode- Improved logging of errors during TaskManager initialization,5
Fixed bug in equals method of IncomingConnectionID,0
Removed debugging output from DiscoveryService,0
OutgoingConnections are no longer closed immediately but after being idle for 3 sec.,5
Simplified state model of file buffer manager,2
"Renames TPCH Query 9 to be not match the integration name pattern, because it is broken.",1
Removed warnings,2
Merge branch 'marrus'Conflicts:nephele/nephele-queuescheduler/src/test/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueSchedulerTest.java,5
Improved behavior of NIO threads when connection is idle,1
- Added tests for handling of failing programs- Added TPCHQuery9ITCase to exclusions of pact/pact-tests/pom.xml,5
- follow up on last commit,5
Introduced cancel method to safely shut down user code,1
Changed spelling of execution states to American English,4
added segment cache / conditional materialization,1
Improved shut down behavior when task was canceled,1
- removed dependency of EnumTriangles example to pact-compiler- changed pact/pact-examples/pom.xml and remove maven dependency to pact-compiler- added maven dependency of pact-examples to pact-runtime with test scope,3
Changed job status names to correct American English spelling,4
- Added exclusions for failing unit tests in nephele-server- Added catch clause to LocalInstanceManagerTest to test whether the LocalInstanceManager was started correctly,3
Introduced extended job status modell to deal with task failures,0
Reformatting and removed obsolete includes,4
Introduced broadcast record writer,5
added test for TPCHQuery4 and modified the other IT cases to remove the test data in case of assertion failures,0
Added auxiliary class to create jar files,2
Added broadcast example job,1
Refactored input/output gates,4
Modified QueueSchedulerTest to match new state model,1
Introduced isBroadcastChannel method in AbstractOutputChannel,5
Added simple and sopremo packages,1
Finished implementation of optimized broadcast in output gate,5
finalized cache logic,2
beautified code,5
- added fine-grained logging- fixed caching bug,0
- fixed in-cache sort path bug (missed sentinel)- found potential memory leak,0
addes SortMerger.close() invocations to unit-test,3
unit-test -> more useful logging level,2
Refactored byte buffered channel manager,4
Added buffer provider,1
Refactored byte buffered channel manager,4
Merge branch 'warneke'Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/OutgoingConnectionThread.javasolved by taking warneke's version.,5
Started implementation of multi-receiver transport layer,5
- added tests to MapTaskTest for task cancelling- added cancel handling to MapTask- added util classes for task cancel tests,3
- excluded failing unit test ClusterManagerTest in nephele/nephele-clustermanager/pom.xml,5
Added method to Client to submit jobs and wait.,1
Merge branch 'fhueske'Conflicts:pact/pact-examples/pom.xml,5
Work on Range partitioner,1
Added new histogram stub files,2
"Added clean shutdown to Reduce Task, Match Task and CoGroup task.",4
test commit.. experimental,3
Cleaned up Simple + Sompremo,4
Added simple files,2
Fixed PactNull Serialization.,0
- Added tests for ReduceTask canceling- Added cancel() method to all tasks,1
Fixed #94,0
Removed superfluous imports,2
Fixed problem with InterruptedException in direct channels when task is canceled,0
Removed invalid test for incorrectly canceled map task.,3
Fixed task abortion for jobs with more than one stage,0
Merge branch 'stratosphere'Resolved conflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/client/nephele/api/Client.javapact/pact-clients/src/main/java/eu/stratosphere/pact/client/nephele/api/PactProgram.java,5
"- added unit tests for correct cancel behavior of Map, Reduce, Cross, Match, CoGroup, and Combine tasks- fixed cancel behavior of Map, Reduce, Cross, Match, CoGroup, and Combine tasks",0
Merged Pair und KeyValuePair in pact-common (Ticke #4).Pair is not referenced anymore directly in the project and can be deleted later.,4
"- fixed canceling behavior of TempTask, DataSourceTask, and DataSinkTask",5
Fixed #99- Removed potential null pointer access- Don't show cause message for ErrorInPlanAssemblerException as it gets already included when EIPA exception is thrown.,1
Forgot unsaved changes in the last commit,4
Fixed #48 - Replaced used hadoop classes by compatible ones provided by nephele,1
initial multicast implementation,5
Continued multicast implementation,5
Implemented event processing in output channels,5
- added job manager host and port to default nephele-user.xml- added task manager port to default nephele-user.xml- fixes #103,0
Fixed issue #101,0
Merge branch 'fhueske'Conflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MapTaskTest.java,5
Fixed possible deadlock in OutgoingConnectionThread,0
Added logging output for different transfer envelope receivers,2
Fixed bug in regular expression used to parse network topology,2
Temporarily disabled spilling,5
Changed configuration of broadcast test job,3
Fixed bug in environment,0
Merge branch 'casp_exp' into experimentalConflicts:nephele/nephele-examples/src/main/java/eu/stratosphere/nephele/example/broadcast/BroadcastJob.java,5
Added logging output,2
Reduced size of broadcast buffer,5
Continued implementation towards broadcast channels,5
Fixed concurrent modification of hash map in OutgoingConnectionThread,0
Fixed bug concerning varying degrees of parallelism and local forwarding strategies.,0
Added Unit test for Bug concerning local forward strategy and changing degree of parallelism.,4
Fixed problem with concurrent incoming connections,0
Implemented log methods for buffer utilization,2
Added test case for PactNull datatype,5
Added missing interface implementation,1
Protected state model against asynchronous changes,4
"Merge with Warneke, excluded IO Manager Perfomance Tests from Integration tests",3
Fixed issue #111,0
- fixed double-closing-SpillingResettableIterator bug in MatchTask,0
- removed obsolete code from EnumTriangle example pact program,4
"- fixed bug #113, PACT integration tests produce failures if exceptions occur during compilation and execution",0
- fixed bug #112,0
- renamed RuntimeExceptionFailureITCase to TaskFailureITCase,0
fixed multicast tree implementation,0
manual merge for SpillingResettableIteratorTest,3
- fixed ticket #116,0
Removed old code,4
- fixed canceling behavior of DataSinkTask and DataSourceTask,5
Removed GPL files from tree,2
Fixed #102,0
"1) Memory assignement from compiler and job-graph generator is a single value, which is split into I/O and sort memory by the tasks and the sortcomponents individually.2) All sort and spilling/resettable components use the new memory allocation method, which can return multiple smaller buffers in the presence of fragmentation.3) Memory access speed test is no longer an integration test.4) Configuration supports long numbers.5) Hash strategies are removed from the repository for the time being, as they are not used.",1
Suppressed type warnings in Environment.java,2
Changed file split API to better integrate lazy assignment in the future,1
Merge branch 'stratosphere'Conflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSourceTask.java,5
Adopted Tests for resettable iterators to new memory requirements.,1
Style improvements for file channel tests,3
Added unit test for #115,3
Adapted code in combining unilateral sort-merger and associated test case.,3
- Added NepheleReaderIterator to wrap Nephele Readers by an Iterator,1
- Added missing licence headers to source files in pact/pact-runtime,1
- added missing licence headers to source files in pact/pact-tests,3
- added missing licence header to files in pact/pact-compiler,2
- commented out incomplete tests from ContextCheckerTest,3
TPCH Q 9 again,5
Fixed #119,0
Added unit test for job with two connections between tasks,3
"Fixed bug in PactConnection, Reengineered BlockResettableIterator for correct shutdown.",1
Fixed double connection bug,0
- performance fix in CrossTask- removed ContextCheckerTest,3
"- added local sort-merge strategies SORT_BOTH_MERGE, SORT_FIRST_MERGE, SORT_SECOND_MERGE, MERGE to reuse existing orders in Match and CoGroup- adapted PactCompiler to set new sort-merge strategies- extended cost estimators for new sort-merge strategies- extended JSONGenerator and JobGraphGenerator for new sort-merge strategies- adapted MatchTask and SortMergeMatchTaskIterator to support new sort-merge strategies- extended SortMergeMatchIteratorITCase to test new sort-merge strategies- adapted CoGroupTask and SortMergeCoGroupTaskIterator to support new sort-merge strategies- added CoGroupTaskExternalITCase- renamed method in Pact compiler",1
added TPCH Q9 again,1
Merge branch 'sewen'Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/PactConnection.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/MatchTask.java,5
- extended TempTask rules for LocalStrategies SORT_FIRST_MERGE and SORT_SECOND_MERGE- added inline documentation for LocalStrategies,2
Finished implementation of buffer utilization log,2
Fixed #109,0
Added basic throtteling mechanism,1
Improved style and performance of queue scheduler,1
Fixed #105,0
Fixed problem with forwarding strategy and changing number of used instances.Cross selects non-blocked strategies only in the presence of estimates.,1
Removed final modifier from QueueScheduler class,4
Fixed #115,0
Removed obsolete code,4
Minor format changes,4
Modified unit test after having removed dead code,4
"- edited Nephele visualizer color scheme: Finishing tasks changed from orange to light blue, Canceled tasks changed from red to orange.",4
- fixed NullPointerException in cancel behavior of SpillingResettableIterator,1
- fixed NullPointerException bug in shutdown of TempTask,0
"- TempTask handling in compiler: correct placement, consideration of Nephele's network spilling, memory allocation- Compiler's memory assignment sensitive for number of memory consumers of local strategy",1
Added memory allocation strategy that works in pace of fragmentation across multiple chunks.,1
"- extended compiler hints are used for Reduce, Match, and CoGroup",1
"- extended compiler hints for local strategies SORT_BOTH_MERGE, SORT_FIRST_MERGE; SORT_SECOND_MERGE, MERGE, and COMBININGSORT- improved deadlock resolving: temp placement and data source duplication",5
- adapted compiler hints in CoGroup and Match integration tests,3
- fixed exception message,0
- fixed comments in MapTask and ReduceTask,0
Fixed possible deadlock in OutgoingConnectionThread (possible fix for #95),0
- improved task cancel behavior,1
- extended PACT task unit tests,3
- added SelfMatchTask- added unit test for SelfMatchTest,3
Fixed position integer overflow bug in Memory Segments and their Views.Channel Readers and Writers tollerate asynchronously released memory segments.,0
"- added local strategies for self match: SORT_SELF_NESTEDLOOPS, SELF_NESTEDLOOPS- extended JSONGenerator to handle new local strategies- extended JobGraphGenerator to handle new local strategies",1
Fixed #95,0
Added missing file,2
- applied new local strategies to SelfMatchTask,1
- fixed bug in JobGraphGenerator,0
- added new local strategies to compiler hints,1
- added cost estimations for new local strategies SORT_SELF_NESTEDLOOP and SELF_NESTEDLOOP,1
- adapted plan enumeration for new local strategies SORT_SELF_NESTEDLOOP and SELF_NESTEDLOOP for self match tasks,1
- improved cancel behavior of DataSourceTask and DataSinkTask: files are now closed in case of task canceling,2
- fixed bug in InputFormat- revisited DataSourceTask cancel code,5
Fixed #134,0
- added DataSourceTaskTest and DataSinkTaskTest- adapted task test utils for DataSourceTaskTest and DataSinkTaskTest- renamed configs of DataSourceTask and DataSinkTask,5
- removed unused imports in DataSourceTaskTest and DataSinkTaskTest,5
Fixed illegal monitor state exception,0
Fixed #131,0
- fixed bug in SelfMatchTaskTest- improved SelfMatchTask with value buffer,1
Removed final modifier from FileBufferManager class,2
Fixed #132,0
- fixed bug in SpillingResettableIterator hasNext() method- added constructor for SpillingResettableIterator to support Iterator as well,1
- improved SelfMatchTask- adapted SelfMatchTaskTest,3
- replaced Reduce Pact in EnumTriangles with Match,5
Fixed internal state of FileBufferManagerEntry,2
Increased idle time until TCP connection is closed to 10 sec.,1
- reduced classpath of PACT webfrontend in start script,5
- refined classpath in PACT CLI client script (pact-run.sh),1
Sorter closing is synchronized.,5
- improved SelfMatchTask,1
- fixed bug in SortMergeMatchIterator: calling hasNext() twice without next() caused lost tuples,1
- added buffer to MatchTask for n-n matches,1
- improved MatchTask with BlockResettableIterator crossing instead of streaming,1
Removed API for direct access to input channels,4
Fixed #38,0
Fixed #95,0
Merge branch 'stratosphere'Conflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/MatchTask.java,5
Fixed merge conflicts,5
Bug fix in Compiler.,0
Improved style and javadoc,2
Fixed #85,0
- fixed bug in pact-run.sh script,1
- moved PACT testing code and tests from pact-test to pact-client- adapted pom.xml files in pact-client and pact-test,3
- fixed memory requirements checks in PACT tasks,1
- adapted Pact task tests to new minimum memory requirements,1
Fixed #120 and improved clean-up in case of errors or cancel operations,0
Changed IO manager to allow block writers.,1
- fixed #137,0
Added menu to visualization and removed automatic logging of buffer utilization,2
First piece of the Hybrid Hash Join: Partitions and partition spilling.,5
- restructured value crossing code,5
- fixed bug in CrossTask (streaming strategy was not correctly used)- refactored crossing code in CrossTask,4
- fixed bug in MatchTask,0
- generalized NepheleReaderIterator- added IteratorNepheleReader,1
- refactored MatchTask code,4
Fixed #124,0
Moved abstract compression classes to server module,4
Removed nephele-compression from nephele pom file,2
Hash join incremental development.,5
Split compression module into separate modules,5
Removed files which are not under the Apache license from the LZMA compression module,2
Added README,1
Removed files which are not under the Apache license from the bzip2 compression module,2
Added README,1
Removed superfluous files from zlib compression library,2
Modified zlib Makefile,2
Removed files which are not under the Apache license from the zlib compression module,2
Added README,1
Merge branch 'master' into stratosphereConflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/util/NepheleReaderIterator.java,5
"Removed some old, outdated code",5
"Removed some old, outdated code",5
"Removed some old, outdated code",5
Changed default settings for compression libraries,1
Improved debugging for compression problems,0
- added replication factor to PactConnection- adapted cost estimators to consider replication factor,1
"- replaced compiler hint ""Selectivity"" by ""AvgRecordsEmittedPerStubCall""- adapted size estimations to new compiler hint- adapted JSONGenerator to new compiler hint- Adapted examples to new compiler hint",1
"Added parsing for selection, projection, (join)",1
Added missing files,2
- extended PACT CLI client- renamed pact-run.sh to pact-client.sh,1
- improved PACT CLI client output,1
- improved argument error handling in PACT CLI client,0
- added suppressWarning annotation in PACT CLI client,2
- extended pact-tests TestBase- Added DeltaComparator to KMeansIterationITCase,1
Small fix to CompressionLoader,0
Improved clean-up behavior for compression,4
- fixed JSON plan bug in PACT CLI client- improved PACT CLI client,1
Added Apache header to bzip2 compression library,1
Added Apache header to native zlib compression library files,2
Added Apache header to native files LZMA compression library wrapper,2
Added menu item to cancel job to visualization,1
Fixed #139,0
- added wait flag for program execution in PACT CLI client,1
Removed incomplete hashjoin code,4
Hash Join bucket array structure,5
Hash Join Test V0.1,3
Task interfaces changes to support a spilling threshold.,1
Added two auxiliary classes to improve shut down behavior,1
Improved javadoc,2
Improved javadoc,2
Buffer implementation is now robust against multiple calls of the recycling method,2
Fixed #139,0
Removed final keyword from class Buffer to fix unit test,3
Reduced logging and fixed possible NullPointerException in FileBufferManager,2
Removed semicolon,4
Fixed logging of state transitions in the profiling component,2
Corrected code style of OutgoingConnection.java,5
Fixed channel target lookup mechanism,1
Fixed #140,0
multicast cluster implementation continued,5
Fixed problem with outdated management graph information after visualization has been shut down,5
Improved robustness of user API,1
Added unit test for #141,3
- fixed compiler hint in TPCHQuery3,0
Fixed #141,0
Removed final identifier from AbstractInvokable.getEnvironment(),1
- fixed list action in PACT CLI Client,0
Typo fix in IOManager,0
added sortmerger cache to latest code-base,3
- fixed bug in PACT CLI client,0
Fixed #77,0
Fixed #146,0
Removed buggy clean-up optimization,4
Fixed bug in file buffers which caused IOExceptions when task is canceled,1
- added Asterix TPCH query example and integration test,3
- fixed invalid compiler hint in WebLogAnalysis example query,2
Constructor fix in sort-merger testcase.,3
Data Source Task robustness to canceling improved.,1
- improved TPCHQuery4 by removing unnecessary object instanciations and static objects- moved TPCHQuery4 classes to a single file,2
Reworked and improved Sort buffers and comparators.,1
In-memory sorts where possible with fine grained threshold definable.,5
Fixed spurious error message for buffer recycling,0
Combine Task now operates only in-memory and pushes out results early.,1
Fixed erroneous test case assertion.,3
Added tests for Jaql parsing,3
- removed empty class  TPCHQuery4Launcher- updated Asterix TPC-H example query,5
- replaced HDFS's API classes by Nephele's API,5
Fixed close bug for broadcast channels,0
Added test for multilevel hash function,1
Fixed #117,0
Fixed typo in JavaDoc,2
Fixed #149,0
Minor modification to output message,5
Modified JavaDoc,2
Fixed #144,0
Fixed Cost estimation Bug for Cross and Removed FallbackCostEstimator,3
- moved TPCH-Queries to pact-tests,3
- Updated pact-example/pom.xml- Renamed All2AllSP to PairwiseSP,5
- added stub configuration to TPCHQuery3 example,5
- added missing Apache Headers,1
- Moved SequentialInput/OutputFormat and JSONInput/OutputFormat to pact-client/testing,3
- Adapted WebLogGenerator,2
- added reference to Apache Hadoop licence to code that originated from Hadoop,1
- excluded source build from Maven- added JavaDoc build to Maven,2
"Added tests for JAQL operators filter, group, transform, and join",1
- pom.xml: moved javaDoc building to site target,1
- Added licencing headers,1
Reworked block resettable iterator to exclude asynchronous thread.,1
Merge branch 'master' into hashjoinConflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/hash/HashJoin.java,5
Merge branch 'master' into rangeConflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/util/OutputEmitter.java,5
Working prototyp for SOPREMO projection,1
Added sopremo expressions,1
- Adapted Stratosphere start scripts for MacOS compatibility,5
add a testfile,3
remove test file,2
testfile,3
remove testfile,3
"Added sopremo operators & tests for selection, projection, aggregation, and joins",3
Added some more scenarios to MultiLevelHashTest,3
Added a tolerance setting for differences in PactDouble values for the TestPlan class.,3
Hash Join Next step,5
MultiLevelHashTest is now integration test,3
Fixed basic operators and added function registry,1
Fixed Serialization Bug in PactString,0
Fixed bug #154 and #155Generalized fuzzy double matching problem by allowing users to specify a custom matcher and similarity measure for key value pairs.Merge branch 'master' of https://stratosphere.eu/stratosphereConflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/testing/TestPlan.java,5
- moved TPCH-Queries to pact-tests,3
- Updated pact-example/pom.xml- Renamed All2AllSP to PairwiseSP,5
- added stub configuration to TPCHQuery3 example,5
- added missing Apache Headers,1
- Moved SequentialInput/OutputFormat and JSONInput/OutputFormat to pact-client/testing,3
- Adapted WebLogGenerator,2
- added reference to Apache Hadoop licence to code that originated from Hadoop,1
- excluded source build from Maven- added JavaDoc build to Maven,2
- pom.xml: moved javaDoc building to site target,1
- Added licencing headers,1
- Adapted Stratosphere start scripts for MacOS compatibility,5
Added evaluation context to employ registered functions,1
Added missing files,2
Hash Join In-Memory functionality,1
"Fixed Hash Join Buck consering overflock buckets, extended test",3
Refactoring,4
Refactoring: removed unnecessary reflection in TypeSpecificHandler,0
Adapted Hash Function Test and included HashJoin probing for spilled partitions.,3
Cancelling correctly removes partial temporary files.,2
Refactored eu.stratosphere.dag package,2
Reworked IO Manager to correctly abstract IO requests for buffers and Memory Segments,1
Added new iterator for mutable objects.,1
Cleaning and commenting I/O Manager + Hashjoin incremental progress.,4
Added union operator and refactored,4
Refactoring and documentation,2
Fixed JavaFunction bug,0
Refactoring,4
Moved all json types from pact to sopremo,5
Added set operators,1
Fixed test cases in pact.testing,3
Added missing files,2
Cleaning and commenting I/O Manager + Hashjoin incremental progress.,4
Hash Join Cleanup,4
"Refactored PactModule, added SopremoModule and shared base class",1
Added n-way join and test case for equi join,3
"Support for recursions, still fixed number of buckets.",0
"Finished Hash Join, Adopted Match Task Iterators, ensured SortMatch will stay in-memory for N:M, if possible, cleaned iterator interfaces.",4
Allow sort iterators to take AbstractInvokables instead ofAbstractTasks.,1
Implement local sorting for data sink task,5
Initial work on job status display,1
Initial work on job status web interface part 2,1
Initial implementation of range partitioner,5
Merge branch 'hashjoin' of https://stratosphere.eu/sewen into hashjoinConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/services/iomanager/BlockChannelAccess.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/services/iomanager/BlockChannelWriter.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/services/iomanager/IOManager.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/hash/HashJoin.java,5
Propely integrated range partitioning into memory calculation,5
Removed hack used to set the partition borders,1
-Properly forward order information,5
Partitioning obeys order,5
Added HashMatchIterators and extended Tests. Full HashMatch support.,1
Memory Manager Strict allocation for small page collections.,5
Modified LibraryCacheManager to work on Windows,1
Added Exception to mutable object iterator interface.,1
Added CheckpointProfilingdata. Changes in Checkpointing,4
Added detection of physical memory for Windows,1
Support for nested jar files in pact jars.,2
Fixed possible NullPointerException in DiscoveryService,0
Minor reformat,5
Increased code coverage of expressions,3
Changed Input Split Logic so it can be overridden.,2
First steps towards Amazon S3 binding,5
Intermediate commit (does not compile and breaks tests!),3
Initial stubbing of api classes for new datamodel in extra packages.,5
Nested Jars contained in subdirectories are now supported.,1
Nephele rework to make input splits more generic and user definable.,1
Removed pull based scheduler model to reduce deployment latency,4
Minor reformatting,5
Added javadoc,2
"Removed static split assignment, prepared code for lazy split assignment",4
Implemented first dummy version of lazy split assignment (must be replaced by more sophisticated version),5
Improved documentation of <code>mkdirs/<code> method,2
Worked on S3 file system implementation,5
Added integration test for global sorting / partitioning.Fixed DataSinkTask if no order is set,1
Added generic input task.,1
Worked on getFileStatus method for S3 file system,5
Merge branch 'sewen'Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/template/AbstractFileInputTask.javanephele/nephele-common/src/test/java/eu/stratosphere/nephele/execution/EnvironmentTest.javanephele/nephele-common/src/test/java/eu/stratosphere/nephele/io/library/FileLineReadWriteTest.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/FileInputSplitAssigner.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/TestPlan.java,5
Adapted PACT runtime test to new lazy split assignment,1
Changed signature of computeSplits method,4
Temporarily disabled TestPlanTest to avoid build problem on Jenkins,0
Even more refactoring,4
Replaced dummy split assignment code with final input split manager,5
Temporarily removed file input split assigner from default configuration,5
Implemented S3DataOutputStream featuring HTTP multi part upload,5
Added implementation for S3 input streams plus tests and javadoc improvements,1
Initial draft of New Datamodel API.,5
Finished implementation of S3 file system support,1
S3 tests now finish successfully if no AWS keys are found,5
Fixed two warnings in nephele-common,2
Reenabled FileInputSplitAssigner as default assigner for FileInputSplits,2
Implemented distance computation between network nodes and added respective unit tests,3
Finished implementation for topology-aware file input split assignment,2
First steps towards TeraSort PACT example,5
Fixed QueueSchedulerTest,3
Fixed misleading log statement in FileInputSplitAssigner,2
Worked on TeraSort PACT job,1
Finished implementation of TeraSort PACT example,5
Fixed concurrency bug in both local and queue scheduler,0
Fixed potential concurrency problem,0
Added composite operators,1
Temporarily disabled CrossITCase since it seems to lock up in an infinite loop,5
Improved error handling when compression library is not on classpath,0
Rewrote compression resource management,5
Reorganized class hierarchy,2
Fixed possible memory leak in JNI resources,0
Fixed bug in compressor/decompressor cache,0
"Adapted bzip2, lzma, and zlib wrapper to new compression resource management",1
Initial stub for snappy wrapper,5
Worked on snappy compression wrapper,1
Minor modification,5
Modified Makefile to match snappy directory structure,2
Increased coverage of sopremo.common.base,3
Corrected calculation of buffer size,5
Changed visibility of SIZE_LENGTH member,4
Several fixes to JNI code and Makefiles,2
Increased coverage of sopremo package,3
Increased coverage of sopremo package,3
Fixed TempTask sharing #171,0
Fix: PARTITION_LOCAL_HASH is now also accepted by JobGraphGenerator + Test (ticket #170),3
Workarounds for OOM,1
Fixed memory leaks caused by TestPairs#iterator,3
"Refactoring, coverage",3
Modified TeraSort example to use PACT global order option,1
"Nested JAR file feature of PACT layer causes problems, disabled the feature temporarily",0
Fixed critical bugs in graph iterator classes,0
Fixed bug in PartitionTask distribution pattern,0
"Trying to reproduce bug #158, not yet possible",0
Used correct shipping strategy for reading data in partitioner,5
Added temp vertex to avoid blocking when using range partitioner,1
Sampling finishes after 100 KV pairs,5
Fixed problem with character encoding in URL user info,5
Added nephele-s3 to stratosphere distribution,1
Added support for S3 Reduced Redundancy Storage,1
Reworked input formats and source/sink tasks to be - more generic - support non-file inputs - allow user defined splits - allow user defined statistics gathering,1
Added the option to set a user defined data distribution on the receiver side for partitioning. This than skips sampling,5
Fixed bug that sink tasks did not use the correct degree of parallelism to decide whether to create the target directory.,1
"Only nested libraries contained in the ""lib/"" directory in the pact jar are added.",1
Forgot to include several files in last commit -.-,2
Fixed Bug that cross with empty inner input hangs.,0
Merge branch 'mkaufmann' into s3Conflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/PartitionTask.java,5
Reformatting PartitionTask,5
Reverted changes to sample task,4
Merge branch 'compressionfix' into s3,0
Fixed warning in execution graph,2
Reformatting ExecutionGraph,5
Added Test Case for empty cross task,3
Fixed bug that nested jar files in subdirectories are not supported.,1
cloud manager amazon API (EXPERIMENTAL),5
Added user-defined data distribution to TeraSort,5
Added required S3 libraries to classpath,1
Added commons-codec to classpath,1
Modified data distribution for TeraSort,5
Refactored and restructured,4
Fixed bug in Path implementation,0
"Replaced ""/"" with Path.SEPARATOR",5
Moved ContractUtilTest to test package,3
Changed LZMA wrapper to reflect new package structure,1
Fixed bug in LZMA compressor,0
Fixed Typo in comment.,2
Fixed assignment bug in ClusterManager,0
Merge branch 'master' into datamodel,5
Added remaining contract classes for new data model.Adopted KMeansIteration to new Data Model.,5
"Existing files output files removed before program execution starts, to prevent overwrite errors",0
Added key columns for new datamodel contracts.,5
Merge branch 'datamodel' into staging_datamodel,5
Removed getDecompressor test since compression is not enabled in standard setup anyway,1
Added Operator test cases,3
Merge branch 'master' of https://stratosphere.eu/warnekeConflicts:nephele/nephele-clustermanager/src/main/java/eu/stratosphere/nephele/instance/cluster/ClusterManager.java,5
Tasks submissions are now bundled in groups to reduce deployment latency,5
Increased version number from 0.1 to 0.1.1,1
Took care of warnings in various PACT classes,2
Addition of TPCH Q3 with new datamodel interfaces and smaller refinements on utility classes.,5
Merge branch 'datamodel' into staging_datamodel,5
cloudmanager EC2 implementation continued,5
removed old typica library,4
Fixed shutdownHook bug in Nephele JobClient,0
Merge branch 'stage1'Resolved Conflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/DataSinkContract.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.java,5
Merge branch 'bugfixes',0
Fixed test casesFixed temp task (didn't work if preceding task was input task),1
Merge branch 'experimental'Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/execution/Environment.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/Gate.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/InputGate.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/OutputGate.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/RecordWriter.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/AbstractInputChannel.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/AbstractOutputChannel.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/AbstractByteBufferedOutputChannel.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/ByteBufferedInputChannelBroker.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/ByteBufferedOutputChannelBroker.javanephele/nephele-common/src/test/java/eu/stratosphere/nephele/io/channels/bytebuffered/FileInputChannelTest.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/io/channels/FileBufferManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/protocols/ChannelLookupProtocol.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedInputChannelWrapper.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedOutputChannelGroup.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedOutputChannelWrapper.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/IncomingConnection.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/IncomingConnectionThread.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/OutgoingConnection.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/OutgoingConnectionThread.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/checkpointing/ChannelCheckpoint.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/checkpointing/EphemeralCheckpoint.javanephele/nephele-server/src/test/java/eu/stratosphere/nephele/taskmanager/checkpointing/ChannelCheckpointTest.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/util/OutputEmitter.java,5
Fixed compilation problems in nephele-common,0
cloudmgr continued,5
Started to integrated new buffer concept,1
cloudmgr fix (still experimental),0
"cloudmgr continue (fixed QueueScheduler call, floating instances)",0
Removed direct channels,4
Some bug fixes,0
cloud manager working,1
Implemented partitioning of global buffer pool,5
Worked on new checkpointing implementation,1
Implemented serializing in-memory channels,5
cloudmgr blacklist/exception handling,5
Reintegrated multicast transmissions,5
example fix,0
Changed version from 0.1.1 to 0.2,4
Progress on Data Model Evolution,5
Fixed multicast bug,0
Improved performance of receiver list lookup,1
Added implementation for serializable hash set,1
Worked on lazy deployment,1
Modified some tests to match new internal components,1
Worked on new instance manager interface,1
Added InstanceRequestMap to make specification of required instances for a job more elastic,1
Fixed bugs in byte buffered channel manager,0
Fixed bug in output channel context,0
Integrated new event to activate output channels,1
Added batch aggregationAdded record linkage implementation and unit tests,3
Merge branch 'master' of https://stratosphere.eu/arvidConflicts:sopremo/sopremo-relational/src/test/java/eu/stratosphere/sopremo/base/JoinTest.javasopremo/sopremo-relational/src/test/java/eu/stratosphere/sopremo/base/SelectionTest.java,5
Implemented delayed replay of a channel's data,5
Implemented additional consistency checks for buffers,1
Implemented filebuffer to memory copy,2
Simplified Nephele's internal state model,5
Adapted schedulers to new state model,1
"Removed two final modifiers, so PowerMock does not complain anymore",4
Introduced state STARTING to know when a task is currently deployed,5
Refactored class hierarchy for scheduler related classes,4
Added check for instance type when instances are reused outside of the same task group,1
Fixed minor bug in task manager logging,2
Modified instance assignment in cluster manager according to new request concept,1
Relocated activation of input channels to user code thread,1
Added additional check for execution state of vertices,1
New Datamodel runtime integration - adopted hash join,1
Adapted file resource layer to support buffer duplication,1
Fixed bug in copyBuffer method of FileBuffer and adapted FileBufferManager accordingly,2
Fixed bug in FileBuffer,2
Fixed bugs in FileBufferManager,2
Temporarily disabled lazy task deployment,5
support for orphaned instances,1
Re-enabled lazy task deployment,0
ReadableSpillingFile does not block anymore when the file is already locked,2
Merge branch 'version011' into version02Conflicts:nephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/cloud/CloudManager.java,5
Changed interface to handle callbacks of allocated resources,0
Pact Record fixes.Hash Join adoption complete.,0
Fixed bugs in buffer implementations,0
Merge branch 'warneke' into stagingConflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/DataSinkContract.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/terasort/TeraSort.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/TaskTestBase.java,5
- Unified and improved output estimates of PACT compiler,1
- added compiler hints to WebLogAnalysis PACT example job,2
Added global enumeration,1
Merge remote branch 'warneke/master'Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/terasort/TeraSort.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/PartitionTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/SampleTask.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/TaskTestBase.java,5
Implemented MutableRecordReader,2
Replaced synchronized HashMap by ConcurrentHashMap to improve performance,1
"cloudmanager cleaned, refactored",4
Hash Iterator AdoptionFirst Adoption of sorting code,5
Worked on diagnosis method logBufferUtilization,2
Fixed possible deadlock problems which occurred with new buffering concept,1
Minor changes to the EC2 cloud manager,4
Fixed RPC problem in EC2 cloud manager,0
- excluded performance test from build tests,3
Added method to estimate HardwareDescription of different cloud instance types,1
Added missing Stratosphere header,1
Removed old code to handle canceled channels,0
- Added PACT PlanConfiguration- PlanConfig can be used to delegate Nephele JobGraph Parameters,2
Cleaned up Nephele Grep example,4
Minor corrections in EC2 cloud manager,5
"Adoption of sort components to new data model, part 1.",5
Added missing Stratosphere headers,1
Added missing Stratosphere headers,1
Fixed bug #181,0
Updated status message,5
Corrected code style,5
Fixed default configuration for Nephele cloud mode,5
Re-enabled CrossITCase,0
Fixed bug in byte buffered input channel with prevented unconsumed channel from closing,0
Corrected message in getLogString of various PACT tasks,2
Minor correction to previous input channel bugfix,0
- Added UnitTest for DefaultDataInputView and DefaultDataOutputView- Fixed Bug in DefaultDataOutputView,5
- renamed method in PlanConfiguration,5
Merge branch 'master' into version02Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
Added missing import,2
- renamed access method in PlanConfiguration,5
started scrubbing operations,5
Merge branch 'master' of https://stratosphere.eu/arvidConflicts:sopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/DisjunctPratitioningRecordLinkageInterSourceTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/DisjunctPratitioningRecordLinkageIntraSourceTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/InterSourceRecordLinkageTestBase.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/IntraSourceRecordLinkageTestBase.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/NaiveRecordLinkageInterSourceTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/NaiveRecordLinkageIntraSourceTest.java,5
Redirected output of input split assigner from stdout to standard logging,2
Added scrubbing operations,1
Improved error logging in task manager,2
Improved logging of buffer utilization,2
Sort Runtime classes (except sort-merge-match) adopted to new data model.,5
Reduced visibility of task context methods,5
Started to implement blocking in-memory channels,5
Backported EC2 cloud manager from Stratosphere 0.2 to 0.1.1,5
Adopted Sort Matching and Sort Co-Grouping,5
"Added transitive closure, enhanced schema mapping",1
- Fixed bug in JobGraphGenerator for TempTask inserts,0
"Refactored iterators, adopted sort merging logic.",2
Increased robustness of initial execution graph creation,1
Re-enabled extraction of nested jar files in PACT jobs,2
Tried other mutable iterator model,2
Changed toString method of InstanceType,4
Renamed cloud manager to reflect dependence on Amazon EC2,5
Removed old files,2
Unified configuration of EC2 cloud manager with the one of the cluster manager,5
Removed superfluous library from classpath,4
Added Amazon EC2 standard instance types to default configuration,5
Improved robustness of EC2 cloud manager,1
Improved logging in EC2 cloud manager,2
Added required parameters to TPCHQuery3 to run on Amazon EC2,1
Added check concerning illegal arguments to EC2 client factory,1
Improved robustness of EC2 cloud manager,1
Improved logging for input split generation,2
Corrected logging in EC2 cloud manager,2
Improved log message in EC2 cloud manager,2
Added quick workaround to ensure correct calculation of intra-node-parallelism in PACT compiler,1
Added support for availability zones on Amazon EC2,1
Added additional check for Amazon image ID in the job configuration,5
Added support to pass an SSH key pair argument to TPCH query 3,4
Fixed possible NullPointerException when cloud instances are reused,1
Adoptes Hash and Sort components to new iterator model.,1
Fixed NullPointerException due to missing topology information,5
Added support for user-defined lease periods,1
"Finalized Sorting, Hashing and Resettable logic. Baseline performance passed.",4
Removed deprecated code,4
Adopted first set of task classes to new data model and mutable objects.,5
still problems with correct writing/reading of chekcpoints,0
Created AbstractPactTask with common control flowAdopted Map Task to new Data Model.Adopted Reduce Task to new Data Model.,5
Merge branch 'datamodel' into staging_datamodel,5
Added fusion operator,1
Adopted Task config and Match task for new data model.,5
Merge branch 'datamodel' into staging_datamodel,5
Merge branch 'stage1'Conflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/testing/MockTaskManager.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/SplitInputIterator.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/TestPairs.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/TestPlan.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/ioformats/JsonInputFormatTest.javapact/pact-clients/src/test/java/eu/stratosphere/pact/testing/TestPlanTest.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonInputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonOutputFormat.java,5
Fixed character error,0
Deleted bug reproduction file,2
Testing cobertura ignore,3
Added union record reader to support union operations on higher layers,1
Added sample Nephele job which exploits the new union record reader,1
Added test for catching NullPointerException which occurs when tasks have no name,3
Fixed #188,0
Adopted runtime tests and partly runtime classes to new data model,5
Implemented SpillingResettableMutableObjectsIterator,1
Fixed #186,0
Refactored job vertex class hierarchy,4
Improved code style and javadoc,2
Improved code style,1
Fixed transitive closure,0
Improved code style,1
Fixed code style,0
Fixed queue scheduler test,3
Improved code style,1
Improved code style,1
Improved code style,1
Improved code style,1
Renamed class to reflect abstract character,5
Improved code style,1
Merge branch 'master' into version02Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/AbstractID.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/DefaultChannelSelector.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/DeserializationBuffer.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/InMemoryOutputChannel.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/jobgraph/JobID.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/jobgraph/JobStatus.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/util/SerializableHashMap.javanephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/cloud/CloudManager.javanephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/cloud/FloatingInstance.javanephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/ec2/EC2ClientFactory.javanephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/ec2/EC2CloudInstance.javanephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/ec2/EC2CloudInstanceNotifier.javanephele/nephele-ec2cloudmanager/src/main/java/eu/stratosphere/nephele/instance/ec2/JobToInstancesMapping.javanephele/nephele-ec2cloudmanager/src/test/java/eu/stratosphere/nephele/instance/ec2/EC2CloudInstanceTest.javanephele/nephele-ec2cloudmanager/src/test/java/eu/stratosphere/nephele/instance/ec2/EC2CloudManagerTest.javanephele/nephele-ec2cloudmanager/src/test/java/eu/stratosphere/nephele/instance/ec2/FloatingInstanceTest.javanephele/nephele-ec2cloudmanager/src/test/java/eu/stratosphere/nephele/instance/ec2/JobToInstancesMappingTest.javanephele/nephele-queuescheduler/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/AbstractScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/local/LocalScheduler.java,5
Renamed ID to AbstractID,5
- Fixed bug in CrossTask: Ensured all channels are fully consumed,0
Added missing file,2
Merge branch 'master' into version02Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/AbstractID.javanephele/nephele-server/src/test/java/eu/stratosphere/nephele/taskmanager/bytebuffered/TransferEnvelopeSerializerTest.java,5
Manually repaired some merge problems,0
Updated from powermock dependency from 1.4.7 to 1.4.9,5
Appled Arvid's patch to prevent deadlocks for short-running tasks,1
Improved code style,1
Added testcases for OR-Expression.,3
added Test for OrExpression.java,3
- Fixed #156 for now- deadlock resolving strategy should be refined in a future release,0
- Added and modified  task names for data source and data sinks in Pact example programs,5
added new Test for ComparativeExpression,3
"Formatted OrExpressionTest, Added test for And-Expression and ElementInSetExpression, added hashCode and equals methode in ElementInSetExpression",1
Improved hash code calculation of StringRecord,1
Started to implement sender-side spilling,5
Temporarily removed automatic flushing of output buffers,4
made ComparativeExpressionTest to a parametrisized Test to include more TestCases,3
refactored record linkage,2
"Added Tests for NumberCastingExpression, added hash and equals methode in NumberCastingExpression",1
Enhanced record linkage,2
extended ComparativeExpression Test,3
"Added hash and equals methode in CoerceExpression, added testcases for CoerceExpression, added new testcase for NumberCastingExpression",3
Merge branch 'master' into hpiConflicts:sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/BooleanExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/OrExpressionTest.java,5
Generalized concept for ownership of file buffers,2
Merge branch 'master' of https://stratosphere.eu/stage1Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/local/LocalScheduler.java,5
Added testcase for PathExpression,3
Fixed possible capacity exceeding of file buffers,2
- Added FixedLengthInputFormat for efficient input of fixed length records- Added Test for FixedLengthInputFormat- Extracted FileBaseStatistics from TextInputFormat and adapted test accordingly- Updated JavaDoc of FileInputFormat,2
Implemented equals and hashCode for TransferEnvelope class,5
Event lists are now instantiated in a lazy fashion,2
Implemented and tested intra source RL,3
Modified transfer envelope serializer/deserializer to handle with non-existing event lists properly,0
Added new assignment strategy for arriving instances which works better with lazy task assignment,1
Removed debug output from AbstractScheduler,0
Fixed bug in computation of the initial active channel set,1
Added new type of queue which capable of spilling,1
Fixed bug in profiling which occurred together with lazy task deployment,1
Implemented and tested inter source record linkage,2
Renamed sopremo relational to sopremo base,5
Started with GovWild integration project,5
Reduced sleep interval to poll for closed output channels,5
Added testcases. Modified ObjectCreation constructor.,1
Removed superfluous import,2
Removed automatic spilling in SpillingQueue,4
Working on GovWild usecase,1
Added execution callback when task has initially run out of execution resources,1
Modified implementation of ExecutionGraph to fix compilation error,0
Added missing method to match new EnvironmentListener interface,1
Implemented tracking of channel utilization,5
Added implementation of resource utilization snapshots which capture the channel utilization at a specific point in time,1
Govwild usecase,1
"Added testcases for ErroneousExpression and TernaryExpression, hash and equal methode added in TernaryExpression, additional testcases for BuiltinFunctions",5
Notification about initial resource exhaustion is now propagated to the JobManager,5
- Added new InputFormats that read from stdout of external processes- Moved input and output formats into separate packages (many files affected by this)- Renamed GenericDataSource and GenericDataSink into GenericDataSourceContract and GenericDataSinkContract- Fixed bug in Compiler to handle GenericDataSourceContracts and GenericDataSinkContracts- Fixed bug in FixedLengthFileInputFormat,2
"- Added FifoInputSplitAssigner which serves splits in original order (first request receives first split, and so on)",1
- Fixed bug in ExternalProcessFixedLengthInputFormatTest,3
- added SkewRecordCount job,1
"added simple possibility for csv input, which gets transformed to jsonjust strings supported; more than 1 line or delimiter in string not supported yet",1
More GovWild usecase,1
"modified csvinput, included libary for reading csv files",2
Changed spilling queue to report amount of reclaimed main memory,4
Implemented support for asynchronous events in buffer management,1
remodified csv Inputformat to remove BOM symbol in front of the first character,4
deleted files used for testing csv to json parser,5
fix for BOM symbol in headers of csv-reader,0
added csv to json paring for gov experiment,5
Implemented task manager's response to initial exhaustion of execution resources,5
Modified Nephele job client to show overall job duration after job has successfully finished,5
Introduced additional execution state to enable lazy task deployment,0
Corrected source code comment,5
Implemented lazy task deployment,5
"Removed Key from CoGroupStub, adapted last tests for runtime to newdatamodel",5
Merge branch 'warneke/version02' into loadBalancingConflicts:nephele/nephele-queuescheduler/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/local/LocalScheduler.java,5
Several issues with cluster,0
Fixed #192,0
Finished integration of US Spending,5
GovWild,5
Changed local buffer distribution model to prevent deadlocks,4
Simplified buffer provider API,1
Changed debugging statement in ByteBufferedChannelManager,0
Improved performance of zipf-distributed random number generator,1
Nesed Jar Files are also added to class path for assembler instantiation.,1
Merge branch 'master' of https://stratosphere.eu/stage1 into stagingConflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.java,5
Fixed bug in selfmatch task after adapting to new datamodel,5
Fixed canceling behavior,0
Increased memory for BlockResettableIterators due to higherMinBufferSize,1
Removed library check code to improve latency behaviour,1
Fixed bug concerning missing close ack for in-memory channels,0
Prepared task deployment for routing hints,5
Removed old debugging output,0
Added routing hints for in-memory channels to reduce latency,1
Changed Nephele job client to reflect proper execution time in milliseconds,4
Fixed bug concerning file channel implementation,2
Simplified naming scheme of file buffers,2
Worked on Nephele fault tolerance,1
Worked on Nephele's fault tolerance mechanisms,1
Worked on Nephele's fault tolerance features,1
Fixed bug in resource deallocation,0
Improved robustness of lookup protocol,1
Unified deserializer with serializer interface,5
Worked on checkpointing implementation,1
"fixed serialization error, still issues in restarting",0
fixed missing method,0
fixed checkpoint tests,3
Worked on fault tolerance,1
Fixed GovWild use case,1
Fixed test cases,3
Removed csv converter hack,4
Introduced new enumeration for the checkpoint state and integrated it into the management classes,1
Integrated checkpoint state change event in visualization,4
Merged new datamodel with version02,5
Checked in files with merge conflicts,5
Implemented listener mechanism for checkpoint state changes,4
added AggregateExpressionTest and FunctionCallExpressionTest->therefore moved BuiltinFunction.java from sopremo-base to sopremo-common,5
added ErroneousExpressionTest and BatchAggregationExpressionTest,3
Refactored Environment class,4
Added missing files,2
Removed superfluous class,4
Improved thread safety of environment/invokable classes,1
Adapted junit test to new serialization format,1
Fixed bug in refactored state concept and adapted unit test accordingly,3
Removed final modifier for the sake of the PACT tests,3
Merge branch 'hpi'Conflicts:sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/ErroneousExpressionTest.java,5
Implemented propagation of checkpoint state changes,4
Completed propagation of checkpoint state changes,4
Redesigned locking concept for execution graph,5
Adapted scheduler to new locking concept and fixed bug in state model,0
Fixed instance leak bug in case of canceled jobs,0
Fixed possible NullPointerException in Environment,0
Improved java doc of EventCollector,2
Added unit test for ticket #198,3
Minor fix to instance sharing unit test,3
Additional modifications to instance sharing unit test,3
"new DuplicateDetection with Sopremorefacetored SopremoTest, moved some functions to JsonUtil-> reorganized Imports",2
Merge branch 'hpi'Conflicts:sopremo/sopremo-base/src/test/java/eu/stratosphere/sopremo/base/BuiltinFunctionsTest.java,5
moved Test for BuiltinFunctions,5
Fixed #194,0
Fixed Runtime Bugs for new DataModel Runtime,1
Created Nephele Version of Word Count with new runtime classes.,1
implemented base nodes for json data model,5
Worked on propagation of checkpointing decision,1
Implemented coordinated checkpoint decision,5
Completed propagation of checkpoint state to the visualization,5
New Datamodel Dummy Optimizer,5
"Sorter with normalized keys, part 1",5
Fixed minor formatting flaw in stratosphere-dist xml file,2
fixed some errors caused by merging,1
Implemented method to remotely kill task managers,5
Fixed PACT unit test,3
Moved JVM shutdown to timer thread and improved logging,2
Added new Nodetypes,1
serialization methodes implemented for all node types,5
added teststubs,3
added Tests for some JsonNode types + generic JsonNode  tests,3
"added testcases for serialize methodes, added canonicalize methode",1
Parsed first small jaql scripts,5
Added example scripts,1
Adopted optimizer test classes to new datamodel.,5
Manual forward of waneke v2 into datamodel.,5
initial refactoring for replacing jackson lib,4
continued refactoring,4
more refactoring...,4
more refactoring,4
Merge branch 'datamodel' into normalkey_sort,5
refactoring...,4
more refactoring,4
more refactoring,4
Unified Mutable Object IteratorsFirst Part of Normalized Key Sorter,2
Refactored sopremo; enhanced simple jaql parser,4
Small serialization improvment for PactRecord.,5
Added code for comparison of records in binary buffers.,1
Fix in BufferSortableGuaranteed and more modular tests for it.,3
Normalized-Key-Sorter sort finished and test added.,1
still problems in recovery,0
Continued refactoring,4
More refactoring,4
coercer refactoring,4
more coerce refactoring,4
for now last coerce refactoring,4
added additional getters in numeric node,1
Merge branch 'michael'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/jsondatamodel/BigIntegerNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/jsondatamodel/IntNode.java,5
fixed ec2 floating instance request bug,0
"before testing, final numeric node refactoring finished",5
New Datamodel API adoptions for compilation.,5
Refactoring...,4
ObjectMapper implemented,5
stubs for JsonParser and JsonGenerator added,1
Finished refactoring,4
Replaced Output with JsonStream in inputs and outputs of an Operator,1
started implementation of JsonParser,5
Added Stratosphere Header to PlanConfiguration,5
Added correct usage of plan-wide default parallelism.,1
Temporarily removed non-compiling classes from testing package.,3
Fixed User Type serialization bug.,0
Improved normalized key logic.,2
Improved WordCount to operate completely on mutable objects only.,1
Added normalized key generation to PactString.,1
Bug fix in PactString constructors and minor adaptions in Normlized Key based sorter.,0
Disabled Checkpointing by default.,5
added primitive paser into jsonparser,5
Removed Test for no longer preset ProbeSideIterator,1
Slight adaption of PactStringModified TestData to use new PactString,1
Made PactLong a normalizable key.,5
parser now parses arrays and primitives,5
refactored parser with handler,0
Fixed Bug that looses Memory Buffer in HashJoin.,0
Bug Fix in NormalizedKeySorter.,0
In-memory sort operational with normal-key-sort.,5
"finished parser, but not working for all cases",1
Cleaned up sort-merger test.,3
first working version of jsonparser.checkEnd does not work yet,1
Enhanced simple,5
Added file-backed DataInputView and DataOutputView.,5
First version of sort-merger cannel fixes.,0
Added MathUtility function,1
Finished UnilateralSortMerger to work block block-channel backed views to allow arbitraily sized records.,1
Added Nephele Version of WordCount,1
Minor cleanup.,4
Merge branch 'datamodel' into staging_datamodel,5
removed PactJson,5
fixed some problems,0
fixed JsonInputFormat Testcase,3
Unified dynamic method and ctor resolution,5
introduced JsonNodeWrapper for serialization,5
submitAndWait (JobClient) now returns the job duration in milliseconds,5
configurable multicast,5
Enhanced parser,5
Fixed zombie tasks in test plans when exceptions are thrown,3
commit,5
solved deserialization problem. still some error in recovery.,0
finished refactoring for package sopremo-base and sopremo-common,4
Worked on broadcast example job,1
"finished refactoring for sopremo-cleansing, ignored InterSourceRecordLinkageTest>>shouldAddSingleClusters and IntraSourceRecordLinkageTest>>shouldAddSingleClusters",3
Fixed broadcast evaluation job,0
Added java code generator for sopremo trees that have been parsed with SimpleParser (should ease test development),3
Fixed bug in checkpoint (de)serializer,0
Temporarily disabled checkpoints,5
Merge branch 'master' of https://stratosphere.eu/hpiConflicts:sopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Grouping.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Intersection.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Join.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Projection.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Replace.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Selection.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Union.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/UnionAll.javasopremo/sopremo-base/src/test/java/eu/stratosphere/sopremo/base/NormalizationTest.javasopremo/sopremo-base/src/test/java/eu/stratosphere/sopremo/base/ProjectionTest.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/ClosureMode.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/DisjunctPartitioning.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/Naive.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/RecordLinkageInput.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/TransitiveClosure.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/ValueSplitter.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/scrubbing/BlackListRule.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/scrubbing/DefaultValueCorrection.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/scrubbing/Scrubbing.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/scrubbing/WhiteListRule.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/similarity/MongeElkanSimilarity.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/similarity/SimilarityCondition.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/usecase/cleansing/CleansFunctions.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/usecase/cleansing/GovWild.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/DisjunctPratitioningRecordLinkageIntraSourceTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/InterSourceRecordLinkageTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/NaiveRecordLinkageInterSourceTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/TransitiveClosureTest.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/usecase/cleansing/AggExpressionTest.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/BuiltinFunctions.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/Evaluable.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/JsonUtil.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/NumberCoercer.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/Operator.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/Sink.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/SopremoModule.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/Source.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/StreamArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/ArrayAccess.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/ArrayCreation.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/ArrayProjection.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/CoerceExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/ComparativeExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/ElementInSetExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/EvaluationExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/FunctionCall.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/NumberCastingExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/ObjectCreation.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/SopremoExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/TernaryExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/WritableEvaluable.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/function/FunctionRegistry.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/function/JavaFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/CsvInputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonInputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonNodeComparator.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonOutputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/PactJsonObject.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoCoGroup.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoCross.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoMap.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoMatch.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoReduce.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoUtil.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-common/src/main/java/eu/stratosphere/util/CollectionUtil.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/SopremoTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/AndExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/ArrayCreationTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/ComparativeExpressionParameterizedTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/ConstantExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/OrExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/PathExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/testing/SopremoTestPlanTest.java,5
Temporarily removed testing package classes.,3
Changed IOManager to use multiple directories for the reading thread.,1
Fixed Bug in PactRecord.,0
Added code to correctly carry key positions and types forward to the runtime for MATCH.,1
Fixed calculation of throughput and added output for job duration,1
Fixed ObjectNode.compareTo and RL test cases,3
Removed deprecated optimization interface and introduced advanced plugin architecture,4
Implemented parser for plugin configuration,5
Added hooks for plugins in the job manager,1
Added hooks for task manager plugins,1
Removed superfluous import,2
Added sample plugin implementation for SCORE,1
Merge branch 'marrus' into version02Conflicts:nephele/nephele-clustermanager/src/main/java/eu/stratosphere/nephele/instance/cluster/ClusterManager.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/execution/Environment.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/DeserializationBuffer.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/InternalBuffer.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/AbstractByteBufferedInputChannel.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/InMemoryOutputChannel.javanephele/nephele-profiling/src/main/java/eu/stratosphere/nephele/profiling/impl/JobProfilingData.javanephele/nephele-queuescheduler/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueExecutionListener.javanephele/nephele-queuescheduler/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/executiongraph/ExecutionGraph.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/executiongraph/ExecutionVertex.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/instance/AbstractInstance.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/io/channels/CheckpointFileBuffer.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/io/channels/FileBuffer.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/io/channels/FileBufferManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/io/channels/MemoryBuffer.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/local/LocalScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/protocols/JobManagerProtocol.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/protocols/TaskOperationProtocol.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/TaskManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedOutputChannelGroup.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ChannelContext.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/IncomingConnection.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/IncomingConnectionThread.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/OutgoingConnection.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/checkpointing/ChannelCheckpoint.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/checkpointing/CheckpointManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/checkpointing/EphemeralCheckpoint.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/transferenvelope/AbstractSerializer.javanephele/nephele-server/src/test/java/eu/stratosphere/nephele/taskmanager/checkpointing/ChannelCheckpointTest.javanephele/nephele-server/src/test/java/eu/stratosphere/nephele/taskmanager/checkpointing/EphemeralCheckpointTest.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/MockTaskManager.java,5
Resolved merge conflicts,5
Fixed some merge problems,0
Refactored test cases,3
Removed JsonNodeComparator,5
Enabled checkpoints by default,0
Wrote integration test to check Nephele's fault tolerance mechanisms,3
starting recovery for failed tasks,0
changes TaskManager methods to IORadWritable parameters,2
removed unregistration of failed task and some debug-output,0
"Revert ""changes TaskManager methods to IORadWritable parameters""This reverts commit a7a85e66ffb30154cf1b0c602b4b43f030425aad",4
started implementation of an alternative parallel transitive closure,5
Added auto-boxing support for java functions,1
Merge branch 'warneke_v2' into pact v2 branchConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/checkpointing/CheckpointDecisionCoordinator.java,5
fixed issues in recovery,0
Added Trinagle Enumeration Program for IBM dataset.,5
Fixed problem with mutable records in input channels,0
Removed redundant version of nephele wordcount version,4
Fixed Wordcount IT Case,0
Merge branch 'warneke_v2' into datamodel,5
"Refactored resources for transitive closure, added methode to add nodes to specific positions into ArrayNodes",1
Fixed comments and combiner in wordcount example.,0
Merge branch 'datamodel' into staging_datamodel,5
Input channels now ignore envelopes which are sent more than once,5
Added more thorough test for primitive DataTypes (Fixed #205),0
Merge branch 'datamodel' of https://stratosphere.eu/sewen into datamodel,5
changed restarts to predecessors without checkpoints. changedrecovery to one call of checkpoint replay per instance.,4
fixed taskmanager mock,0
Increased robustness of envelope routing in presence of execution failures,0
Replay task now ignores partial checkpoint files which are still written at the same time,2
Fixed bug in sequence number check,0
Fixed bug with sign-bit in NormalizableKey for PactLong and PactInteger,0
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 into datamodel,5
Increased logging interval for latency measurement,2
Fixed #210,0
added User CPU to Utilization snapshot an checkpoint decision,1
Added two more integration tests for the fault tolerance features,3
Added another integration test to check Nephele's fault tolerance capabilities,3
Implemented support for Hadoop-style elasticity in ClusterManager,1
Improved javadoc and code style of ClusterManager,2
Added unit test for new pending requests data structure,5
changed recovery to recover from completed checkpoints,4
Merge branch 'warneke_v2' into datamodelConflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/testing/MockInstanceManager.javastratosphere-dist/src/main/assemblies/bin.xml,5
commit due to branch switch,5
fixed and refactored some queue related tests,3
fixed recovery for successively failing tasks,0
"further implementation of parallel transitiv closure computing, bug: Projection dont uses specified key/value transformations",1
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 into new_datamodel,5
check-in due to branch switch,5
Adapted ITCases for contracts to new datamodel,5
Deactive sorting tests for data sink,5
branch switch,5
- Finished RecordOutputFormat- MovedBinaryIntInputFormat- Minor Cleanup in other formats,4
Added Method STubs to PactRecord,1
Added substring methods to PactString,1
Added Pigmix queries and ported L2 query.,1
Merge branch 'datamodel' into staging_datamodel,5
branch switch,5
included Daniel Warnekes UnionRecordReader,5
Removed OutputCollector test,3
Converted input formats for tpch tests,3
"Converted tpch1 program (currently not run in tests, so not tested)",3
Adapted IntTupleDataInFormatTest to the new api,1
Fixed WebLogAnalysis example to work with the new datamodel,5
Merge branch 'datamodel' into triangles,5
Converted graph examples,5
Converted TPCHQuery4,5
Converted TPCH Query4,5
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 into new_datamodel,5
Merge branch 'datamodel' of https://stratosphere.eu/ringwald into new_datamodelConflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/type/base/PactString.java,5
Merge branch 'new_datamodel' of https://stratosphere.eu/cbruecke into new_datamodel,5
Adapted TaskFailureITCase to new datamodel,5
Added corrent toString and JSON output for Data Sinks.,5
implemented Phase1 of parallel transitive closure,5
Fixed incorrectly passes key positions.,4
Fixed bug related to push-based transfer model,0
Fixed deserialization bug in PactRecord accessors.,0
Fixed bug in PactRecord serialization.,0
Reworked Triangle Enumeration.,1
"Fixed EnumTriangles example, works now with local test case",3
"Converted TeraSort to new API -- ATTENTION: Will probably not work, not tested!",3
Removed unused and deprecated file formats,2
Finnished porting TPCHQUery3 and replaced the deprecated class by the new one -- untested,3
Merge branch 'new_datamodel' of ../repo into datamodel,5
"Adapted TPCH9+10+Asterix to new datamodel. Everything is compiling, butnot yet tested",3
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 intodatamodelConflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/graph/EnumTriangles.java,5
Switched order of parameters in ReduceContract,2
Fixed inputformat,0
fixed recovery for a  repeatedly failing vertex,0
Merge remote branch 'remotes/cbruecke/new_datamodel' into release0-2,5
Fused cleanse rules with expressions,4
Fixed some tests and some bugs after adapting to new datamodel,5
Merge branch 'new_datamodel' of https://stratosphere.eu/cbruecke into datamodel,5
Fixed bug in Outputformat for WebLogAnalysis,2
Fixed Outputformat for KMeans,0
Enhanced parser for cleansing tasks,4
Fixed string parsing error,0
Ignored cleanse tests for the time being,3
implemented removing of checkpoints,4
Merge branch 'michael'Conflicts:sopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/TransitiveClosure.java,5
Fixes in fault tolerance test,3
UnitTest for UnionRecordReader (bug #212),0
"fixed computation of phase1, changed BinarySparseMatrix to a subclass of JsonNode",5
Fixed test cases and Boolean/NullNode deserialization,3
branch switch,5
Added the concept of execution pipelines to simplify scheduling,1
Implemented construction of execution pipelines,5
Implemented pipeline based deployment,5
Class ExecutionVertex is now thread-safe.,5
Concurrency fixes for ExecutionVertex class,0
Class ExecutionGroupVertex is now thread-safe,5
Class ExecutionStage is now thread-safe,5
Class ExecutionPipeline is now thread-safe,5
Class ExecutionGroupEdge is now thread-safe,5
Class ExecutionGraph is now thread-safe,5
JobConfiguration is now a final property of ExecutionGraph,5
Switched back to more fine-grained locking in JobManager,5
Switched schedulers back to more fine-grained locking scheme,5
Removed coarse-grained locking from CheckpointDecisionCoordinator,4
Switched abstract scheduler to more fine-grained locking model,5
Minor fix,0
Switched to more fine-grained locking model in class AbstractionExecutionListener,5
commit to push,5
added basic networkchannel test,3
added Phase 2 of parallel Warshall and replaced mapstubs with SopremoMaps,1
Fixed bug in ExecutionGroupVertex,0
branch switch,5
finished Phase2 (testcase is missing),3
Moved allocatedResourcesDied into AbstractScheduler,4
implemented annotaions for tasks,5
Improved performance of execution graph compilation,1
Removed some debug output,0
Removed debug output in ExecutionGroupVertex,0
Prepared tracking of assigned vertices in class AllocatedResource,5
union integration phase finished,5
bug fix for eu.stratosphere.pact.test.pactPrograms.EnumTrianglesITCase,3
Parses all cleansing scripts now,4
clean up,4
More precise exception message during deserialization error.,0
Fixed Exception Forwarding in AsynchronousPartialSorter,0
Temporarily disabled test for failing tasks.,0
Fixed TPCH Query 3 and Test case.,3
bug fix,0
Fixed read val len logic in PactRecord for values > 0x7f,2
Fixed KMeans example,0
Fixed TPCHQuery 10,0
Commented out GlobalSortingITCase as long as it is not supported,1
Reverted graph examples to previous version,4
Merge branch 'datamodel' of https://stratosphere.eu/ringwald into datamodel,5
Commented out WordCountNephele due to problems with dependencies,0
QueueSchduler tests now work without mocking,1
Improved JavaDoc,2
Merge branch 'version02' into stage1_version02Conflicts:nephele/nephele-queuescheduler/src/test/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueExecutionListenerTest.javanephele/nephele-queuescheduler/src/test/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueSchedulerTest.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/checkpointing/CheckpointDecisionCoordinator.java,5
Fixed #204,0
Fixed spurious error message for state transition from CREATED to ASSIGNED,1
"Fixed Pact Web Servlet to produce plan description output, even when no plan preview can be created.",1
branch switch,5
Implemented first version of chaining for combiner and mapper.,5
fixed too early closevent for large records,0
changed restarting. added new test with annotations,3
Added configurable number of input splits to FileInputFormat,2
Added logging for multicast experiments,2
Added hostname of remote receiver to log output,2
Changed compiler and parameters to enable handling of default degree of parallelism.,0
Temporarily reduced verbosity of System.out logging,2
Added parameters to conif for ease of adoption.,2
Introduced config variable to control merging of spilled buffers,5
Explored nonsymmetric matrix,5
"phase 2 of parallel transitive closure now working, some testcases missing",3
Added rule rewriter for cleansing expression,4
Added comments to PactString.Added startsWith() methods to PactString.,1
Fixed PactCompiler to re-enable plan preview.,0
Removed unused legacy class.,1
Fixed data race problem in FileInputFormat.,2
"Changed NepheleMinicluster to work localhost loopback interface.That way, the tests work also if the system as no external IP Adress assigned.",5
Fixed typo and inconsistent naming in TaskConfig.,5
Fixed bug in AsynchronousPartialSorterCollector that causes undesired spawning of a reading thread.,1
Fixed bugs in ChainedCombineTask.,0
Enabled general chaining logic in AbstractPactTask. Chaining now works for - any Mapper - any combinerthat is attached to its predecessor via a forward connection and has the same degree of parallelism.,1
Improved some error messages in teh case of null key fields.,0
Slight improvement of Wordcount Code style.,1
Added fix in pact compiler to fall back to a default parallelism when nothing else is specified.,0
Bugfixing in ported Pact Programs,0
Fixing expression rewriter,0
Fixed Scrubbing and some test cases,3
cleanup,4
fixed .setCosts() in Single- and TwoInputNode,1
"started phase3, nothing done yet",5
branch switch,5
Improved robustness of spilling queue implementation,1
Merge branch 'version02_wo_dm' into multicastConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
multicast topology-awareness + output for visualization,2
Extended debugging output in ByteBufferedChannelManager,0
added new methods for backwards compatibility and convenience,1
"fixed properties propagation: instead of using a property blindly in the union case, it is droppedTODO: figure out when properties can be keept in the union case",4
SpillingQueue implementation is now thread-safe,5
Added methods to register and unregister spilling queues with a network connection,1
Switched to TransferEnvelopeQueue for network queue management,1
Changed close mechanism of output gate to improve performance of lazy deployment,1
Changed implementation of LocalBufferPool not to response to asyncronous events for non-blocking operations,4
Moved connection check in class OutgoingConnection to separate method,4
Implemented method to copy file buffers in spilling queue back to main memory,2
Implemented asynchronous transfer of file buffers back to main memory in spilling queues,2
Added size limitations for spilling queue elements and fixed bug related to file -> memory transfer,2
Improved thread-safety of spilling queue,1
Removed superfluous methods to unregister spiling queues,4
Minor performance improvement for transfer envelope queue,1
Added new unit test for ticket #212,3
Fixed #212,0
Re-enabled integration test,3
Merge branch 'union' of https://stratosphere.eu/warneke into union2Daniel's fix for UnionRecordReaderConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/InputGate.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/RecordReader.java,5
Added byte-counting for ByteBufferedInputChannel,1
Switched back to old structure of OutputChannelContext,5
Implemented debugging function for spilling state of queues,1
Temporary fix to transfer end of queues to hard disk,0
branch clean up,4
Refined locking granularity and improved memory consumption of spilling queue,1
Integrated task annotation from Mareike's branch,5
Added convenience class to check a set of task class properties,1
Minor correction to previous commit,5
Fixed errors in ported PACT examples,0
Fixed bug in KMeans concerning object reusage,0
Extracted SJaql tests,3
Merge branch 'score' into streamingConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.java,5
Introduced Nephele streaming plugin,2
Added JobManager and TaskManager components of streaming plugin,1
Added taggable record type,1
Extended plugin interfaces,2
Implemented streaming input and output listeners,5
added javanature and builder to streaming project,1
Fixing Simple test cases,3
Started to implement communication infrastructure for Nephele plugins,5
Finished implementation of the job manager part of the plugin communication infrastructure,5
Implemented thread to asynchronously handle communication between the streaming plugin's components,0
Improved javadoc,2
Implemented streaming tag and integrated it,5
Moved instantiation of plugins to early point during the job manager instantion to prevent problems in local mode,0
Revised multi output functions to operator,1
Improved javadoc,2
Implemented propagation of path latency information from task manager to job manager,5
Extended abstract instance to support plugin communication,1
Finished implementation of plugin communication from job manager to task maangers,5
some extensions to the nephele management api (untested),3
first sketch of the latency graph structures (untested),3
Refactored environment class to support encapsulation of tasks by monitor tasks,1
added .project that define a java-nature for the projects,1
Refactored input/output gates,4
Changed calculation of path latencies,4
Merge branch 'streaming' into streaming_test,3
Finished refactoring of input and output gates,4
integration between latency model and jobmanager plugin (untested),3
"* fixed some bugs (endless recursion in latency path construction, some NPEs)* added some toString() functions",1
simplifications to management graph structures due to multigraph-DAG problem (management graph and streaming plugin cannot deal with multigraph-DAGs currently),2
latency values from task managers are now written into latency model,5
Refactored input and output gates to support plugins,1
Added computation of task latency and propagation thereof to the job manager,1
Fixed several POM file-related warnings reported by the eclipse maven plugin,2
Added default wrapper for input and output gates,1
Added default implementation for environment wrapper,1
Removed deprecated methods from input and output gate listener interfaces,4
Improved javadoc,2
Cleaned up ChannelSelector interface,4
Both task and job configuration are now accessible at the task managers at runtime,1
Added new wrapper classes for Nephele streaming plugin,1
Worked on streaming plugin,1
Merge branch 'streaming_test' into streamingConflicts:nephele/nephele-streaming/src/main/java/eu/stratosphere/nephele/streaming/StreamingJobManagerPlugin.java,5
Fixed problem with inconsistent view on input/output gates,0
Removed superfluous import,2
Finished rewrite of JobGraph by Nephele streaming plugin,5
Worked on task manager implementation of Nephele streaming plugin,1
Finished implementation of channel throughput measurements,5
Made optimizer able to handle subclass contracts.,0
Fixed stream listener implementation,0
Simplified stream listener logic,2
"Phase 3 implemented but not tested yet, fixed Tests with old BSM",3
Added graph utility class for DAG rewriting,2
Fixed Instance Profiler to exclude local host interface.,2
Fixed #218,0
Reset file permissions,2
Merge nephel2 v2 changes with pact changes.Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
Combiner thread in chained combiner registers at profiling component.,5
refactored ManagementEdge identification scheme,4
addendum to last commit,1
Implemented mapping from receiver vertex to source channel IDs,5
"added value statistics (median, min, max, avg) to stream profiling data model",5
added processing of task latency back in,1
Implemented method to adjust channel buffer size limits from job manager,5
Refactored actions the Nephele streaming plugin can take to achieve latency and throughput goals,4
Fixed deserialization problems with the plugin ID,0
Implemented queue for pending actions inside the task manager component of the Nephele streaming plugin,2
Fixed serialization problem with the buffer size limit action,0
Finished implementation to adapt buffer limits during runtime,1
Fixed Late Memory Release in chained Combiner.,0
Bug fix in Sort Input data Collector,5
Implemented callback to calculate the latency introduced by the output buffers,5
Introduced new type for output buffer latency,1
Implemented propagation of buffer latencies to job manager component of the Nephele streaming plugin,2
* refactored most of the LatencyXYZ to ProfilingXYZ classes* implemented logging of profiling values* profiling paths (formerly known as LatencyPaths) can now start and end at edges,2
renamed streaming.latency package to streaming.profiling,5
* log entries now contain proper edge numbering* log entries now contain timestamp,2
Implemented belief resolution and other fusion features,5
Removed .project files from repository,2
fixed RuntimeException due to bug that caused violation of Comparable vs equals contract,1
Added log message in task manager component of Nephele streaming plugin,2
Added Nephele streaming plugin to distribution,1
"* fix for edge id lookup problem* workarounds to deal with broken profiling data (identical source and channel ids, NaNs)",5
Implemented custom read logic in StreamingInputGate,2
Redesigned implementation to calculate buffer latencies,5
Added entity extraction parsing,4
Fixed bug in custom streaming read logic,2
included output buffer latency in profiling data,5
Decreased NIO sleep time from 500 to 50 ms,5
Introduced mapper class to facilitate dynamic task chaining,5
Introduced API to construct stream chains,2
Added latex slide generator,1
"Removed check that executionResourcesExhausted call must be from environment thread to enable chained tasks.Check is overly restrictive, since the only condition is that the output gate is always accessed by the same thread.",0
Finished implementation of stream chaining,5
Temporarily disabled thread-safety check,5
Integrated statistics collection in stream chaining,5
Added code to trigger chaining event,5
implemented and tested first sketch of buffer size optimization,3
fix for excess buffer size increase bug,0
Reduced NIO timed waiting interval to 10 ms,5
Added custom equals to rules,1
Extended job manager plugin interface to expose possible profiling dependency,2
JobManager now considers profiling dependencies of plugins,2
Plugins can now return custom profiling listeners,2
Fixed extraction tests,3
"fixed issue in phase 2, mirrored matrix computed by warshall was nor emitted correctlycollecting matrizes in phase 3 in AMatch changed (not sure if it works for all cases)",1
Extended SelfMatchTask with triangle crosses and added testcases for these,3
"Added lost commit 5103eedb36483f14eb72b40615eeb0b8eeb1044e again: ""Fixed #156 for now""",0
"added lost commit ca2bb244e477bbc03253de6292ec04f0f989fc7d again: ""Added and modified  task names for data source and data sinks in Pact example programs""",5
- added additional tests for empty inputs of CrossTask- cleaned up inline comments of CrossTask,4
- added input format to start and read from external processes- added unit tests for external process input formats- fixed comment in FixedLengthInputFormat,0
Made HashJoinTest an integration testcase,3
Renamed class as well...,5
removed System.out.println statements from unit tests.,3
Records are now copied among different mappers,5
- Added unit test for FixedLengthInputFormat- Fixed bugs in FixedLengthInputFormat,0
extracted decision method,4
- fixed java doc in FileInputFormat.java,2
removed Amazon EC2 parameters from TPCHQuery3 example program,2
Merge branch 'union' into version02_wo_dmConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/InputGate.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/RecordReader.java,5
Minor modifications to the union record reader and related classes,5
Added mutable union record reader implementation,1
Removed final modifier again to fix problem with PowerMock testsRemoved final modifier again to fix problem with PowerMock tests,3
- added FixedLengthInputFormat and Test- extracted FileBaseStatistic inline class from TextInputFormat,2
sequel to previous commit...,5
multicast fix + support for penalties,1
Fixed #196,0
Fixed problems with event inlinening,0
Fixed #222 error with running indices,1
- added patch to fix #222,0
Merge branch 'stratosphere' into version02_wo_dmConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/AbstractByteBufferedOutputChannel.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/InputChannelContext.javapact/pact-common/src/main/java/eu/stratosphere/pact/common/io/input/TextInputFormat.java,5
Merge branch 'version02_wo_dm' into version02Conflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/TPCHQuery3.java,5
Fixed testCheckExitCode to work on MacOS too,1
Merge branch 'bugfix',0
Reworked output estimates for new data model,5
Merge branch 'version02' of https://stratosphere.eu/git/stage1 into unionNewDMConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/RecordReader.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/direct/AbstractDirectInputChannel.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/InputOutputAdder.javapact/pact-clients/src/main/java/eu/stratosphere/pact/testing/TestPlan.javapact/pact-clients/src/test/java/eu/stratosphere/pact/testing/TestPlanTest.javapact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/DualInputContract.javapact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/GenericDataSink.javapact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/SingleInputContract.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/PactCompiler.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JSONGenerator.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/CoGroupNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/CrossNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/DataSinkNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/DataSourceNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MapNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MatchNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/OptimizerNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/ReduceNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/SingleInputNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/SinkJoiner.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/TwoInputNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/contextcheck/ContextChecker.javapact/pact-compiler/src/test/java/eu/stratosphere/pact/compiler/HardPlansCompilationTest.javapact/pact-compiler/src/test/java/eu/stratosphere/pact/compiler/PartitionLocalHashCompilerTest.javapact/pact-compiler/src/test/java/eu/stratosphere/pact/compiler/PropertiesPropagationTest.javapact/pact-compiler/src/test/java/eu/stratosphere/pact/compiler/TempTaskSharingTest.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/datamining/KMeansIteration.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/TPCHQuery3.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/WebLogAnalysis.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/wordcount/WordCount.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/CoGroupTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/CrossTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/HistogramTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/MapTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/MatchTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/ReduceTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/util/TaskConfig.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CoGroupTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CoGroupTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CombineTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CombineTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CrossTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/CrossTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/DataSinkTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/DataSourceTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MapTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MatchTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/MatchTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/ReduceTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/ReduceTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/SelfMatchTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/TempTaskExternalITCase.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/TempTaskTest.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/TaskTestBase.javapact/pact-tests/src/test/java/eu/stratosphere/pact/test/failingPrograms/TaskFailureITCase.javapact/pact-tests/src/test/java/eu/stratosphere/pact/test/pactPrograms/GlobalSortingITCase.java,5
Merge branch 'version02_wo_dm' into checkpointingConflicts:nephele/nephele-queuescheduler/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/checkpointing/CheckpointDecisionCoordinator.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/executiongraph/ExecutionGraph.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/executiongraph/ExecutionVertex.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
First steps towards implementation of scripted job failure patterns,0
compilation error fix. added missing file.,2
"Revert ""compilation error fix. added missing file.""This reverts commit 9f4543e07e56ff17cdfd764169000acdd61b9bdc.",4
compilation error fix: added missing filebug fix (error after merging),0
bug fix for union case,0
Merge branch 'version02' of https://stratosphere.eu/git/stage1 into unionNewDM,1
Worked on job failure pattern manager,0
"new aproach for fixing Phase3, therfore more preprocessing steps-> empty blocks are filled-up with empty BinarySparseMatrix",0
Changed version number in pom files from 0.1.1 to 0.1.2,2
added profile for nightly builds,2
changed pom,4
fixed column bug in phase 2added selection in phase 3 and after computation unionadded method to transpose BinarySparseMatrix,1
3 BSP-Warshall should work now-> Phase 3 is working now,1
"- stub configuration enriched with parallel task count and id, and task name",5
- minor fix of exception string,0
- added RecordInputFormat + UnitTest- added FieldParser interface- added DecimalTextIntParser + UnitTest,3
- added DecimalTextDoubleParser + UnitTest- added negative values to DecimalTextIntParser,1
- added DecimalTextLongParser + UnitTest,3
- added Fixed and Variable Length String Parsers + UnitTests,3
- adapted StringFieldParser Unittests,3
- added check for too short input in RecordInputFormat and adapted unittest,3
refactored transitiveClosure.java -> source preprocessing and emitting out,4
Added missing classes to wordcount jar,1
Worked on GUI extension to simulate execution failures,0
Merge branch 'stage1_version02' into streamingConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/execution/Environment.javanephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/InputGate.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/Task.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/AbstractPactTask.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSourceTask.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/TaskTestBase.java,5
Reintegrated union code,5
Added stacktrace to the errorlog,2
First compilable version of the old pact-compiler ported to the new datamodel,5
Implemented a combo box with auto-completion features in SWT,5
Fixed problem with auto-completion combo box,0
Added possibility to add key listener to combo box with auto-completion,1
Implemented dialog to create new failure pattern,0
Ported testing framework to new data model,5
Removed merge files,2
Excluded sopremo from build,5
Worked on failure patten manager,0
Fixed #233,0
Fixed logging problem in visualization component,0
- updated to new StubAnnotations (former OutputContracts)- adapted some example queries (more work needed here),1
- changed method name in StubAnnotationConfigurable,5
- fixed #230,0
- fixed #230,0
Fixed #200 und #201,0
Fixed #200 und #201 for version 0.2,0
- ported fix for #197 from version 0.2 code base to 0.1.1,0
Fix #200 & #201 (followup),0
inserted partitioning for transitiveClosure and bug fixingtherefore an id in each node is needed->modified test resources,3
fixed test failure,0
Started to implement failure event editor,2
- extended OptimizerNodes to hold new StubAnnotations- PactCompiler reads StubAnnotations and adds them to OptimizerNodes,1
Merge branch 'bugfix' of https://stratosphere.eu/git/cbruecke into bugfix_v02,0
Finished implementation of failure event editor,2
Implemented sorting for failure event table,0
Refactored failure patterns editor,2
Improved robustness of failure manager,0
Implemented keyboard control,5
- inverted StubAnnotation UpdateSet to ConstantSet,1
- updated JavaDocs of StubAnnotation,2
- added OutputSchemaProvider interface for input formats to specify the schema of records they produce- implemented OutputSchemaProvider interface for RecordInputFormat and extended unit test- extended PactOptimizer to derive output schema for optimizer nodes,3
Added first Set of PactRecord Tests (written by Christoph Bruecke)Minor cleanup and fix in Pact Record.,0
- added getOutputSchema method to OptimizerNode- added keysets to SingleInputNode and TwoInputNode,1
Refactored failure event table,0
Updated year in about dialog,2
Added icons to failure event table,0
Finished I/O operations of failure patterns manager,0
Minor corrections and bug fixes,0
Implemented name suggestions,5
Implemented scheduling of failure events,0
Merge branch 'master' into version02Conflicts:build-tools/pom.xmlnephele/nephele-clustermanager/pom.xmlnephele/nephele-common/pom.xmlnephele/nephele-compression-bzip2/pom.xmlnephele/nephele-compression-lzma/pom.xmlnephele/nephele-compression-snappy/pom.xmlnephele/nephele-compression-zlib/pom.xmlnephele/nephele-ec2cloudmanager/pom.xmlnephele/nephele-examples/pom.xmlnephele/nephele-hdfs/pom.xmlnephele/nephele-management/pom.xmlnephele/nephele-profiling/pom.xmlnephele/nephele-queuescheduler/pom.xmlnephele/nephele-s3/pom.xmlnephele/nephele-server/pom.xmlnephele/nephele-visualization/pom.xmlnephele/pom.xmlpact/pact-clients/pom.xmlpact/pact-common/pom.xmlpact/pact-compiler/pom.xmlpact/pact-examples/pom.xmlpact/pact-runtime/pom.xmlpact/pact-tests/pom.xmlpact/pom.xmlpom.xmlstratosphere-dist/pom.xml,5
Merge branch 'stage1_version02' into version02Conflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/hash/HashJoinITCase.java,5
Merge branch 'version02' into checkpointingConflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/testing/MockTaskManager.java,5
Fixed pom file,2
Merge branch 'marrus_checkpointing' into checkpointingConflicts:nephele/nephele-queuescheduler/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/queue/QueueScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/checkpointing/CheckpointDecisionCoordinator.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/executiongraph/ExecutionVertex.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.java,5
Finished implementation to support task failures programmatically,0
Reintroduced set for recently removed channel ID in order to make cancelling of tasks more robust,1
Minor fix to improve robustness of byte-buffered channel manager,1
Fixed problem with job lock-up as a result of user cancel request,1
Removed cancel job from callback to ensure proper interaction with recovery mechanisms,4
Improved robustness of checkpoint replay manager,1
Added names for recovery threads,1
"ticket 209, 219",5
added asyn partial sorter it test,3
"ticket 209, 219",5
"Revert ""ticket 209, 219""This reverts commit 2f754556846f322386cac34c126a78ff761e3c72.",4
added (failing) unit-test for task chaining,5
added forced group vertex checkpoint,1
Merge old compiler with union with new compiler for new data modelConflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/GenericDataSink.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JSONGenerator.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/CoGroupNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/CrossNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/DataSinkNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/DataSourceNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MapNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MatchNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/OptimizerNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/ReduceNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/SingleInputNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/TwoInputNode.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/TPCHQuery3.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/TPCHQueryAsterix.java,5
- added setDifference method to FieldSetOperations and extended unit test,3
"- improved handling of stub annotations in optimizer nodes (copy in clone constructor, constant set mode, etc.)",1
- removed unnecessary TODO flag in CombinerNode,2
- disabled failing test case and opened ticket for fix,0
- fixed MatchTaskExternalITCase- disabled failing tests and added TRAC ticket for fixes,0
- added check for null names in pact tasks,1
Better comparison between outputs.,1
- reduce memory for AsynchonousPartialSorterITCase,5
- fixed TPCHQuery3,0
- fixed PactRecord.updateBinaryRepresentation for tailing null fields- added test case,3
Merge branch 'bugfix',0
Finished restructuring of parallel transitive closure algorithm.,5
see last commit,5
- fixed TPCHQ3 for reorder feature,0
- forward exception in PactRecord.updateBinaryRepresentation(),5
- extended RecordOutputFormat for record position definition and added unit test,3
- extended JavaDoc of RecordOutputFormat,2
- added Ignore annotation to AsynchonousPartialSorterITCase since it does not terminate on Jenkins- added Trac Ticket to enable and fix test,3
broadcast added hard-coded tree...,1
- Fixed check for partitioning (field numbers are now checked)- Couple of small bug fixes,0
- updated stub annotation set handling in optimizer nodes,1
Fixed small bugs in optimizer,0
Merge branch 'version02' of https://stratosphere.eu/stage1 intoversion02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/SingleInputNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/TwoInputNode.java,5
Added record iterator wrapper,1
Check constantsets as well as updatesets for checking which keys remainunchanged,4
"Fixed small bugs in Compiler (NPE, Maximal Costs of IP, Cloning of IPs)",0
Started port of sopremo-common,5
Fixed Pact Record and adopted tests.,3
Fixed wrong initial costs for interesting properties in reduce node,5
Some refactoring in OptimizerNode,4
Fixed filterByNodesConstantSet in LocalProperties,1
Minor Bugfix in PactRecord.,0
Fixed Test for DataSinkTask.,5
Cleaned up Imports and warnings.,2
Corrected typo in checkpointing annotations,2
"Fixed TPCH-Query 10 (adopted to new datamodel, plus beautified)Fixed TPCH-Query 10 (erroneous test)",3
Fixed Bug #236 (applied Arvid's Patch),0
Removed superfluous execution state RESTARTING,4
Fixed bug in PactRecord (case columns % 8 == 0),0
- yet another PactRecord fix (indexOutOfBounds if serializer.memory too small for direct copy),0
- annotation sets are available from all optimizer nodes,1
Solved compilation errors in sopremo-common,0
Merge branch 'hpi'Conflicts:sopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/record_linkage/TransitiveClosure.javasopremo/sopremo-cleansing/src/test/java/eu/stratosphere/sopremo/cleansing/record_linkage/TransitiveClosureTest.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/DefaultFunctions.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/EvaluationExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonNodeWrapper.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoUtil.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ObjectNode.java,5
merge fixes,0
Introduced priorities for execution listeners,5
Improved javadoc of execution listener interface,2
Removed old obsolete Array Util,4
Minor cleanup for Warnings,2
Added massive blackbox tests to PactRecordTestImplemented unionFields Method in PactRecord.,3
Removes Mockito dependencies from compile scope in PactClient.,4
first implementation of ObjectSchema,5
Introduced new method to keep track if execution retries in a thread-safe manner,1
Moved content of class RecoveryThread to class RecoveryLogic,2
- fixed job graph generator: Reducer gets key columns and classes for local strategy NONE,1
Moved code to handle dead hosts from queue scheduler to abstract base class,0
Fixed minor bug in method to cancel job,0
Fixed flaw in execution state listener of the execution graph,0
Marked restartTask method as deprecated,5
Minor fix to recovery logic,2
uncommented sequenznumber error log,2
fixed PactProgram constructor,0
Check if the existing partitioning is on only a subset of the key,1
Fixed filtering by constant sets,1
Fix: Partitioned fields are now ordered list and not a set,1
Set partitioning for other side of dual input contracts to the same asthe other if there exists one,1
Fixed duplicate registration of execution vertex listener,0
- applied Mareike's patch to fix #238,0
Fixed problem with instance assignment update event in event collector,5
Added Stratosphere header to DefaultDeserializer.java,1
Improved robustness of network transfers when receiver has already died,1
- OutputEmitter throws specific exceptions in case of problems to read the key- moved OutputEmitterTest to correct package and extended it- changed PartitionFunction interface and HistogramPartitionFunction,1
- added serialization test to OutputEmitterTest,3
Merge branch 'master' into annotation+newOptimizer,1
Use constant sets for output estimation.,1
Merge branch 'ringwald02' into annotation+newOptimizerConflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/DataSinkNode.java,5
Fixed wrong compiler hints in JSONGenerator,5
Adapted JSONGenerator to new data model,5
Fixed union bug in self-match,0
Improved robustness of buffer implementation,1
Refactored code for recovery,4
Decoupled task execution from network failures,0
Improved robustness and logging of byte-buffered channel manager,2
Removed deprecated restartTask method,4
Introduced task manager RPC method to invalidate entries from the receiver lookup cache,5
Added method to invalidate lookup cache entries to recovery logic,2
Fix: Second input is now partitioned on the same fields as the firstinput if this one is already paritioned,0
"Fix: Wrong estimates for num records if avgRecordsEmittedPerStubCall isknown, but not the number of stub calls",0
Improved logging of errors at the task manager,0
Unified event delivery model across input and output channels,5
Added event type to report transfer envelopes with unexpected sequence numbers,1
Simplified hand-over of transfer envelopes from tasks to the byte-buffered channel manager,5
Introduced unknown receiver events to signalize delivery failures to the sender,0
Fixed problems with cache invalidation in the recovery logic,2
Merge branch 'streaming' into checkpointingConflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/annotations/Stateless.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/instance/AbstractInstance.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/AbstractScheduler.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/Task.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/TaskManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/OutputChannelContext.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/util/OutputEmitter.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/io/OutputEmitterTest.java,5
Continued to work on integration of streaming branch into checkpointing branch,1
Merge branch 'ringwald02' into annotation+newOptimizer,1
Continued to work on integration of streaming branch into checkpointing branch,1
- reworked stub annotations- added read and write set computation to optimizer nodes- adapted example programs,1
Refactored context class hierarchie used by the byte-buffered channel manager,1
- added methods to compute output schema and write sets,1
changed write set and output schema computation,1
Merge branch 'master' of https://stratosphere.eu/git/hpiConflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/Operator.java,5
- fixed reading of copy and projection stub annotations,0
cleaned MC manager,4
- extended optimzer nodes with input schema check,5
- fixed valid input schema check for optimizer nodes,0
Cleaned up task manager operation protocol,4
- added java docs and comments for stub annotation methods,2
Added testcases for ObjectSchema,3
renamed mapping method,5
- fixed PactRecord.union(),0
Merge branch 'master' into annotation+newOptimizer,1
"more objectschema implementation, fixed tests",3
import fix,0
package cleanup,4
refactoring using interfaces for all Node Types,1
Added schema to SopremoTestPlans,3
- renamed compiler hints and added java docs,2
Worked on proper event dispatching in case a replay task runs concurrently with the original task,1
- renamed write annotation to modification annotation\n- added java docs to stub annotations,2
- renamed annotation another time,5
- renamed compiler hints,5
- removed output schema computation,4
- cleaned up pact-examples- ported triangle enumeration to new data model- removed some unused code- moved some pact-examples code to pact-tests,3
Merge branch 'examples02' into annotation+newOptimizerConflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/relational/TPCHQuery3.java,5
- fixed stub call estimation of MatchNode,0
- fixed compiler hints in TPCH Query 3,0
Fixed resource leaks during task clean-up,4
Improved robustness of recovery phase,1
changed cpu usage intervall,4
Worked on replay task implementation,1
Implemented ReplayOutputChannelContext,5
Improved robustness of forwarding barrier,1
Implemented execution state update for ReplayTask,5
Improved robustness of task manager profiling,1
Finished implementation of ReplayTask,5
Fixed bug related to detection of failed tasks,0
Implemented visual feedback for execution state REPLAYING,5
Modified ExecutionStateTransition to reflect new state changes during task replay,4
Fixed possible resource leak during task recovery,0
implementation auf pigMix1,5
Extended lookup protocol to reflect new state REPLAYING,1
Changed verbosity of RuntimeOutputChannelBroker,1
Fixed bug in ReplayThread close logic,2
Implemented logic to restart canceled tasks as part of recovery,2
Introduced sequence numbers for input split requests to handle recovery of input tasks,0
Revised fuzzy matching of test recordsMerge branch 'master' of https://stratosphere.eu/git/hpiConflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.java,5
Resolved issues with close logic of replay tasks,2
Fixed problem with lookup cache invalidation during recovery,5
Minor fix to debug message,0
Extended return code enumeration for IPC calls,5
Improved logging of state transitions,2
Fixed misleading log messages in compareAndUpdateExecutionState method of ExecutionVertex,5
Improved logging in utility class ExecutionStateTransition,2
Introduced new return value for routing lookups to reflect finished tasks during recovery,5
Unexpected envelope event is not sent outside of the queue synchronization block,5
Added convenience method to RuntimeEnvironment,1
Temporarily disabled SpillingBarrier,5
Fixed bug in Task Manager,0
Worked on locking during recovery,1
Fixed javadoc,2
Fixed bug in channel close logic when receiving task has already finished,5
Implemented input split tracker to make replay of input tasks deterministic,5
Fixed bug related to channel lookup service,0
Improved performance during job setup phase,1
First implementation of unique fields in optimizer,5
Merge branch 'version02' into checkpointingConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/executiongraph/ExecutionStage.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/scheduler/AbstractScheduler.java,5
"Removed uniqueness property from Global and LocalProperties, as it isnow tracked within the optimizer node itself",5
Merge branch 'annotation+newOptimizer' ofhttps://stratosphere.eu/fhueske into version02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/OptimizerNode.java,5
Minor performance improvement,1
Fixed problem with memory leaks,0
Fixed bug in local buffer pool,0
Fixed minor bugs in OptimizerNode (handling of output estimates whenunique key is available),0
Fixed bug in uniqueness determination in optimizer node,0
Improved robustness of channel close procedure in presence of execution failures,0
Added missing implementation in ReplayTaskContext,1
Added compiler hints for uniqueness,1
Fix: Distinguish correctly between uniqueness properties in input andoutput,0
continued implementation of LazyObjectNode,5
"little fixed for LazyObjectNode, TODO inserted",2
- used FieldSet instead of int[] for field sets in optimizer,1
- optimizer nodes hold key fields in FieldList to preserve order,5
Fix: Check for correct subset of key in partitioning,1
Fixed unit tests,3
Merge branch 'ringwald02' into annotation+newOptimizer,1
Improved logging of buffer utilization,2
Improved logging,2
Fixed incomplete cancellation of pact test plan,3
Fixing sopremo test plans,3
Implemented envelope consumption tracker to guarantee replay of envelopes in the correct order,5
Reduced verbosity of EnvelopeConsumptionLog,2
Fixed some bugs in the envelope consumption log,2
Quick workaround for buffer deadlock problem,0
Clean up of code,4
Fixed problem with unnecessary buffer copy attempt during recovery,0
Fixed bug in class ReplayOutputChannelContext,0
Fixed problem with ClosedByInterrupedException during finish,5
Temporarily switched ephemeral checkpoints to use one file per channel,2
ReplayThread now reads back data to memory before emitting it,5
Temporarily enabled receiver side spilling to prevent channel deadlocks,0
minor changes in decision components,4
Integrated Stephan's new file buffer manager,2
changed some logging for parsing,2
Temporarily added code to measure data input/output of PACT first-order function on byte level,1
Improved logging,2
Fix to make checkpoint deserializer work with new file buffer manager,2
Improved robustness of buffer implementation,1
Small fix to avoid deadlocks after recovery,0
Fixed minor bug in JobManager,0
Modified recovery logic to also handle node failures,0
changes in DecisionCoordinator,4
Clean-up of code,4
changes in decision logic an locality,2
- fixed bug in TextInputFormat (input size estimation),0
somewhat dirty fix for checkpoint annotation from pact layer,0
made lower and upper bound configurable,5
removed some debugg syso,5
added some checkpoint configuration,5
Fixed problem with data collection in PACT runtime,1
Marked temporary code properly,5
changed configuration of checkpoints,5
added always checkpointing flag,1
introduced MissingNode,5
implemented arrayschema stub,5
Refactored code for checkpoint decision logic,2
bugfix in iteratormore testcases,3
Checkpoint decision is now made by the task thread itself,5
- fixed nullpointer bug in GlobalProperites with Matthias Sax's patch,0
fixed CPdecision,0
Added some debug output,0
Merge branch 'marrus_checkpointing' into checkpointingConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/checkpointing/CheckpointDecision.java,5
memory optimization for upcoming reusage of pactrecords and objectnodesstarted arrayschema,5
Refined configuration of checkpoints,5
Fixed two bugs related to checkpoint configuration,5
Fixed wrong return value of getChannelType method in AbstractGate on task managers,1
removed tail from ArraySchema,4
"fixed bug/test, size of ObjectSchema was too small",3
"continued Implementation of ArraySchema, ArrayNode returns now MissingNode instead of IndexOutOfBoundsException",2
fixed code ownership and added some javadoc,2
Fixed bug in collection of PACT data statistics,5
- fixed bug in order property propagation of Pact compiler,5
Added sequential input and output format,1
Started to implemented distributed checkpoints,5
Extended file system API to support renaming of files,2
Continued to work on implementation of distributed checkpoints,1
Modified ReplayThread so it can handle distributed checkpoints,0
Fixed some bugs related to writing checkpoints to a distributed file system,5
removed getPactRecord() from LazyObjectNode (reason: getJavaValue() serves the same purpose),1
Finished implementation of recovery from distributed checkpoints,5
"implemented base structure for testing arraynodes, interface tests for arraynodes implemented",3
renamed ArrayNode>>subList() to subArray(); implemeted more tests for ArrayNode interface and implementation,3
some more tests for interface and implementation of arraynode,3
Fixed bug in ReplayInputChannelContext,0
Disabled receiver-side spilling,5
"changed return type of ArrayNode>>add(int,IJsonNode) from void to IArrayNode to be more consistent with ArrayNode>>add(IJsonNode); started to document all JsonNode-Interfaces",5
Changed calculation of meta data file size to enable faster recovery,0
Fixed problem with default block size in HDFS binding,0
Improved strategy to read checkpoints as part of recovery,1
Increased size of envelope consumption log,2
Checkpoints are now written asynchronously,5
Fixed problem with shut down of checkpoint's asynchronous write thread,0
Fixed problem with FQDN in instance connection info,5
- fixed PactProgram constructor (bug reported by Thomas Bodner),0
Improved robustness of checkpoint utility class,1
added ArraySchemaTeststarted implementation of recordToJsonfound bug in ObjectSchema -> test written,3
Added tests for ArraySchemaFixed NullPointer Exceptions,0
Merge branch 'stage1' into version02Conflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/io/TextInputFormat.java,5
Improved robustness of clean-up procedure when task is canceled,4
Fixed bug in method to cancel/kill task,0
"implemented LazyArrayNode,changed return type of IArrayNode>>toArray from Object[] to IJsonNode[],refactored LazyObjectNode>>getOtherField() so less type-casts are needed",1
Introduced new checkpoint state undecided,1
"JsonNodeWrapper now implements IJsonNode,added additional testcases for IArrayNode,added LazyArrayNodeTestfixed bug in LazyArrayNode>>remove",4
added testcases for LazyArrayNode and IArrayNode,3
Added method to trigger checkpoint decision asynchronously,1
Added method call to make checkpoint decision as a response to an asynchronous event,1
Improved performance of BinaryOutputFormat and SequentialOutputFormat,1
Added getNumInputs to ContractUtil,1
Revised and documented Iterator and Iterable classes,2
Adding key expressions to operators for schema inference,5
added some additional javadoc comments,2
Enabled lazy deployment by default,0
added some new javadoc comments,2
Added binary and sequential input/output formats for efficient storage of PactRecords in a native format,1
Added test case for sequential input/output format,3
Added setter for FileBasedStatistics,2
Moved sequential and binary formats from this branch to stage1/version02,4
Increased level of detail in BinaryInputFormat in case of exception during statistics gathering,1
"Implemented basic version of open(path, bufferSize)",5
Merge branch 'version02' of https://stratosphere.eu/git/stage1Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/fs/file/LocalFileSystem.java,5
File Input of TestPlan properly deserialized with configuration parameters,2
More details in Binary Input Format in case of error during statistic gathering,0
Fixed last remaining test cases for SOPREMO core port on version 02,3
Removed temporary class,4
Refactored envelope forwarding API,4
Added missing Stratosphere headers,1
Added missing Stratosphere headers,1
Fixed unit test,3
Fixed various bugs related to file channels,2
Fix several bugs related to recovery from file channels,2
documented interfaces of serialization package,2
started implementation for ArraySchema with tail,5
implemented tail functionality in recordToJson,5
Fixed bugs related to task recovery,0
started tail implementation in LazyArrayNodeiterator should work alreadyrefactored Iterator,4
Extended user API to set the number of execution retries per vertex,1
splitted ArraySchema/LazyArrayNode up to head and tail types,5
Finished java doc of all node types,2
Improved computation of initial checkpoint state,5
Clean-up,4
Made local checkpoints the default again,5
Fixed restart bug in class ReplayThread,0
Fixed problem with wrong initial checkpoint state,5
Fixed problem with missing thread interruption in class ReplayThread,0
Integrated stage1/version02 PACT layer,5
Merge branch 'casp_multicast' into version02Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/ByteBufferedChannelManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/NetworkConnectionManager.java,5
usage of broadcastrecordwriter implemented..,5
Fixed compilation problem,0
Fixed problem in replay thread,0
Multicast Test Case + MulticastManager readyness criteria,3
Fixed POM files and removed some unused imports,2
Code clean up,4
multicast auto deploy + test,3
Minor fix in MulticastManager,0
BroadcastChannel Test fixed,0
Fixed problem in replay thread in improved integration tests,3
Fixed bug in multicast manager,0
First implementation of a general Schema. Extended the signature of Schema>>jsonToRecord with an EvaluationContext; added simple testcases for GeneralSchema,3
GeneralSchema is now return by the NaiveSchemaFactory if no better Schema found,1
documented GeneralSchema; added some testcases for GeneralSchema,3
NaiveSchemaFactory now supports both ArraySchemas (HeadAS and TailAS),1
GeneralSchema.recordToJson now uses the provided target node correctly if the kind of this target is Array or Object,1
"added testcases for NaiveSchemaFactory; fixed ""IndexOutOfBounds""-bug in NaiveSchemaFactory",0
2 new testcases for GeneralSchema,3
more tests for GeneralSchema,3
Added interfaces for new memory manager views.Removed defunct mem-manager service provider.,1
Added global event sequence number,1
fixed minor style errors,0
style in MulticastManager,5
Removed unnecessary bit operation from MemorySegmentRenamed MemorySegmentTestRemoved redundant OutOfMemoryException,3
Added abstract paged input and output views,1
Added methods for waiting for returned segments to the block readers and writers.,1
Added new paged channel viewsAdopted TypeAccessorsAdded memory segment source,1
Adopted PactRecord and its accessors to new accessor api.,1
Added strict binary logarithm computation to math utils,2
Fix for memory views,0
Added basic memory views.O,1
Adopted NormalizedKeySorter to paged memory layout.,5
Added new PagedMemoryViews,1
Added Hash Partition Class with new paged memory manager classes,1
"changed method signature of EvaluationExpression>>evaluate(), this method is now able to take a target node which will be reused if possible",1
Added test utility classes for plugable types.,3
Added generic type comparators and adjusted type accessors.,1
Added test data generator.,5
Removed Obsolete BufferSortableGuaranteed,4
Removed warnings,2
Minor test cleanup and renaming,4
Added hash join adopted for paged memory model and plugable types.,1
Fixed bug in replay logic,2
"Added exception check to combiner closing, to catch late exceptions.",1
Fixed bug in Channel Views,0
Code clean-up,4
Removed deprecated input/output gate listeners,4
Reduced verbosity of logging output,2
Fixed bug in restart logic of ReplayThread,2
Fixed integration test for checkpoints,3
Fixed bug in FailingJobITCase,0
Improved clean-up of checkpoints after job has finished,5
Fixed problem with undetected missing envelopes in RuntimeInputChannelContext,1
Removed deprecated code,4
Fixed problem in POM file for pact-examples,2
Fixed possible resource leak in EphemeralCheckpointForwarder,0
Reduced verbosity of ForwardingBarrier,5
Properly closed RPC stub objects in the various shutdown procedures now,5
Fixed signature of methods destroying RPC proxies,0
Implemented missing close call to job client in IT cases of nephele-server module,5
Fixed possible resource leak in checkpoint's write thread,0
Adapted MockEnvironment to match new internal structure of RuntimeEnvironments,1
Fixed possible deadlock in AbstractByteBufferedInputChannel,0
Reduced debug output,0
Fixed bugs in ClusterManager and the corresponding unit test,3
implemeted reuse of target node in ArrayAccess; not working if result is a PrimitiveNode; implemented sometestcases for reusage,3
implemeted reusage of target node in ArrayCreation; added some testcases for ArrayCreation,1
implemented reusage of target node in ArrayMerger; added some testcases for ArrayMerger; restructured target reusage in ArrayCreation,1
implemented reusage of target node in GroupingExpression; added testcases for GroupingExpression,3
implemented reusage of target node in GenerateExpression; PrimitiveNode's (except BooleanNode) now have a setValue Method to allow reusage of that nodetype,1
refactored desition of target reusage -> moved to SopremoUtil,4
removed 'null' as target from evaluate-calls inside an evaluate-method,1
Merge branch major changes from warneke into memmanager branchConflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/util/OutputEmitterTest.java,5
multicast is by default topology-aware now,2
JsonNodes now have a clear method: allows node reset before reusageall EvaluationExpressions now have an field 'expectedTarget' which stores the type of an JsonNode: used to determine if a target node can be reused or not,1
added some testcases for reusage of target nodes in BatchAggregationExpressionTest and ObjectCreationTest;exceptions while reuse target nodes are now handled in SopremoUtil.reuseTarget;PrimitiveNodes are now only cleared with .clear() if SopremoUtil.DEBUG is set to true;,1
removed senseless testcases from AndExpressionTest,3
started to comment expressions,5
- removed verbose system.out.print statement,5
Merge branch 'version02' of https://stratosphere.eu/git/stage1Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/InputGate.java,5
Adjusted testing framework to checkpoint-aware nephele,1
- removed System.out.print statement from EnumTriangles example job,5
cleaned up MulticastManager. topologyawareness is on by default.,2
- added stacktrace output for failed pact tests,3
- removed union handling from compiler- replaced key arrays by fieldlists / fieldsets in most places- added several todo flags for release,2
Fixed #247,0
Moved Distribution Pattern out of User Code,1
dist pattern fix,0
Started to adapt PACT layer to new distribution pattern API,1
Some minor fixes,0
Backported patches for ephemeral checkpoints from version02 branch,5
Fixed problems with removal of checkpoints,4
added some additional class comments,1
naive way to reuse primitives in GeneralSchema; further commenting,1
further commenting,5
Included TestPlanTest cases,3
Added Nephele speed test to examples package,3
Added some new java-doc comments.,2
initial commit,5
Started work on clustering operator,1
First test running for Annotator,1
Added GeneratorInputFormat (input from config values),5
Added GeneratorInputFormat (input from config values),5
implemented TailArraySchema,5
fixed wrong Schema used in LazyHeadArrayNodeTest,3
Worked on non-file solution for adhoc sources.,2
Changed PACT's JobGraphGenerator to use new Nephele channel API,1
"implemented initial clustering, one test not working by now though",1
Removing old files.,2
implementation of LazyTailArrayNode and added Test,3
changed basis array test case and ignored failing test from LazyArrayNode,3
implementing creation of cluster tree,1
Minor changes to logging in job manager,2
Introduced enumeration for Nephele's possible execution modes,5
Started work on tree creation,1
Code cleanup,4
Finished java doc commenting of all expressions,2
removed nephele streming plugin from default configuration,5
Added HeaderlessChannelReaderViewFixed HashJoin for recursive spilling,0
Adopted I/O manager to multiple write threads for I/O spreading.Adopted interfaces for page read/write request combining.,5
Generification of Sorting logic (part 1) (does not compile!),2
Fixed NPE for TestRecords sorting,3
Created JUnit Test for Ticket #250,3
Improved style of junit test,3
Extended getClass signature to accept a user-defined class loader,1
Fixed #250,0
marked all expressions which dont reuse the target node during evaluation with   TODO Reuse target,1
Updated sopremo pacts,5
Updated sopremo common to 02,5
Updated most base operators to 02,1
Updated simple replace to 02,5
Updated library version,5
"Json serialization for cluster trees, some Json serialization functionality",1
"Added parameters to composite operators, some clean-up",4
refactored SopremoUtil.reusePrimitiv: the parameter <targetClass> was redundant,1
Merge branch 'version02' of https://stratosphere.eu/git/stage1Conflicts:pact/pact-clients/pom.xml,5
Fixed junit test,3
Merge branch 'master' of https://stratosphere.eu/git/hpiConflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/EvaluationExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonCollector.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/HeadArraySchema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyHeadArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/ObjectSchema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/Schema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IntNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/MissingNode.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/ArrayCreationTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/BatchAggregationExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/ObjectCreationTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/ObjectSchemaTest.java,5
Added byte array reusing to delimited input format.,1
Adjusted some calls to some parameter adaptions,2
Work on main clustering in progress,1
Fixed project path,0
Fixed project path,0
"Added atomic enumerator, to enumerate through multiple temp directories in a thread safe way.Adjusted code for envelope consumption log to work with multiple temp directories.",1
Adjusted LocalInstanceManager to work with multiple temp directories.,1
Fixed bug in execution pipeline assignment,0
Adopted Sorter IT Case,5
Fixed in basic sorterAdopted partial sorters,0
"impemented NormalizableKey interface for all JsonNodes, extended JsonNodeTest to automatically test the normalization of the tested node",3
"implemented NormaliableKey interface in JsonNodeWrapper, extended JsonNodeWrapperTest to test the new functionality",1
Created generic stubs and made pact record stubs special cases of them.,1
Fixed Asynchronous Partial Sorter TestsRenamed serializer,3
refactored copyNormalizedKey & getMaxNormalizedKeyLen -> JsonNode implements a standard behavior which can be overriden if another behavior is necessary,5
Adopted hash-match strategiesAdopted key-grouped-iterators,5
Adopted KeyGroupedIterator TestAdopted Combining SorterFirst part of CoGroup Strategy refactoring,4
- fixed dependency of WordCount example on AsciiUtils,0
Adjusted CoGroupIterator,5
Adjusted test programs to generic signatures.,3
"Relocated some tests, working on cluster representations",1
Further work on representation updates,5
Putting some clustering operators together,1
Extended  KeyGroupedIteratorTestAdopted BlockResettableIterator to paged memory model.,1
Minimal HashPartition tuning,5
Added spillable output view for record caching.,1
Removed old obsolete classes.,4
further work on clustering,1
Adopted spilling resettable iterators to pages memory model and I/O views.Various minor one-line additions / cleanups.,4
Cleaned and consolidates I/O Manager code.,5
MemoryManager changes to page memory manager.,4
Removed old input view files.First step to adopting runtime task classes.,1
Moved serializer classes to pact-common,4
First portion of task adoption to generic runtime.,1
Data Source and Sink with INput / Output Format refactoring...,4
initial commit,5
Next part of task adoption,5
Adopted remaining tasks (except Self-Match),5
initial clean up,4
fixed wrong calculation of lazyArrayNode size,0
fixed lazyTailArrayNode iterator,0
implemented set method of lazyTailArrayNode,1
Fixed bug that classloading fails in configuration with null class loader.,5
Removed System.out.println statementsFixed RecordINput/Output Format tests,3
added parameterized test for lazyTailArrayNode and fixed bugs when tail is small,0
finished lazyTailArrayNode,5
SopremoUtil can now use a custom class loader for deserialization (currently used by SopremoMap to load debugging objects),0
Fixed output size bug; added simple plan assembler; clean up,4
Applied new deserialization function to other sopremo operators,1
put some docs into lazyTailArrayNode,2
a little more cleanup,4
Extended data structures to handle multiple connections between a pair of TaskManagers,0
Added wrapper that turns mutable object iterator into a regular iterator with shared object.,1
Adopted Tasks and Tests (prefinal version),3
more cleanups,4
added stuff from Moritz' branch,1
Fixed bug in DataSourceTask,5
Temporarily changed Enumeration of Triangles job to use Reduce for first self-join.,1
Temporarily made match with self-join predicate fall back to regular match instead of using specialized self-match operation. (Self Match currently not adopted),1
and more cleanup,4
resolved conflict in SelfMatchTask,5
fighting through the code,5
Removed accidentally added marker file.,2
more cleanup,4
more cleanup,4
more cleanup,4
Adjusted nephele utils to new runtime code.,1
First part of iteration contract.,5
conflicts,5
Added class stubs for high level iteration constructs.,1
more hacking and cleaning,4
fixed a typo in new iteration contracts,1
Replaced synchronized block in lookup structure by java concurrent data structure,5
"removed algorithm implementations, will be restored later",4
"implemented copyNormalizedKey() in DoubleNode, new testcases for JsonNodeWrapper, refactored method to fill the target with zero bytes in copyNormalizedKey()",1
refactored assertion in JsonNodeWrapperParameterizedTest >> shouldCreateDifferentNormalizedKeys() to be more readable,1
crouching forward,5
crouching and crouching,5
Fixed clean-up problem in recovery code,0
Fixed bug in serialization method of RemoteReceiver,0
Implemented algorithm to compute connectionIDs,5
Fixed problem in network stack to handle multiple TCP connections between a pair of TaskManagers,0
Merge branch 'networkfix' into version02Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/NetworkConnectionManager.java,5
Resolved problems after merging,0
Fixed configuration problem with distributed checkpoints,0
Fixed #243,0
Fixed problem with read event subscription,0
it compiles...,5
started to add javadoc comments to all classes in sopremo-common,2
Fixed bugs in testing framework (reported by Thomas Bodner),1
Fixed refitting of PactRecords for ObjectSchemas,0
Added plan assembler,1
"Added some toString methods, fixed conf bug, added point generator",1
Set up parameters for composite operators.,1
Ran a clean-up on sopremo-sdaa11.,4
Refactored key expressions,4
further documentation with java-doc,2
further documentation with java-doc,2
"Implemented post processing, need to merge before testing.",3
Removed superfluent file.,2
Fixed schema inference bugs in composite operators,1
Extended post-processing. Ran clean-up.,4
Connected clustering parameters to suboperators.,1
Removed an unused test.,3
Added some missing operator annotations and constructors. Added two point test files.,2
Ran clean-up.,4
Added integration test to test scheduling overhead for jobs with large DoPs,3
Added missing Stratosphere header,1
Improved efficiency of AbstractID class,1
Improved code style,1
Transition to new internal execution graph representation (not yet complete),1
Fixed Long.SIZE bug,0
Working on SON algorithm.,1
Counting all candidate occurrences in SON algorithm.,5
SON is now working.,1
Merge branch 'compiler02' of https://dev.stratosphere.eu/git/fhueskeinto version02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/PactCompiler.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MatchNode.java,5
Continued to work on transition to new internal execution graph representation (not yet complete),1
Compatibility to OpenJDK 1.7.0,5
Finished transition to new internal execution graph structure,1
Fixed problem with uninitialized channel and compression settings,1
Removed IOReadableWritable interface from channels,4
Refactored cardinalities and adhoc sources,4
Completed test on scheduling graphs with larger DoPs,3
Reduced DoP for graph scheduling test (previous version caused OutOfMemoryError),0
Added signatures and factories for custom deserializers.,1
Improved robustness of RuntimeEnvironment,1
Merge branch 'stage1_version02' into version02Conflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/TaskTestBase.java,5
it compiles and starts,5
Renamed Serialization Buffer,5
Post-Merge fix of MockEnvironment,0
mutig,5
Post-Merge fix of ExecutionGraph,0
Reworked stub annotations to ConstantFields only,1
Fixed problem in MockEnvironment,0
Further java-doc commenting in SopremoTestPlan; deleted unnessesary file Schema.java.orig,2
Fixed cancellation of pacts in testing framework,1
Fixed bug when translating nested composite operators into elementary modules,1
Merged with branch including custom deserializer for nephele.Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/io/channels/bytebuffered/AbstractByteBufferedInputChannel.javanephele/nephele-common/src/test/java/eu/stratosphere/nephele/io/channels/bytebuffered/FileInputChannelTest.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/io/RuntimeInputGate.javapact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/test/util/MockEnvironment.java,5
finished java-doc commenting in SopremoTestPlan,3
Merge branch 'arvid'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoMap.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoUtil.java,5
Merge branch 'arvid'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/SopremoModule.java,5
SopremoTestPlanTest -> trying to find bug in 2 testcases,3
Changed member variable visibility as in Ticket #228,4
Typo fix.,0
Fixed Tests for nephele record serialization/deserialization and added tests for serialization logic spanning buffers.,2
Adjusted signature of DelimitedInputFormat to deserialize from byte array subsequence.,5
Changed DelimitedInputFormat to save byte copying to extra buffer and deserialize out of the read buffer directly.,4
Refactored grouping,4
Added missing files,2
Fixed Bug in adopted Test Input Formats,3
Merged branch 'arvid'. Kept SONTest,3
Added cardinality annotations to clustering operators.,1
Fixed minor inconsistencies in log messages,2
Added recursive expression rules,1
"Refactored join, grouping, and other base operators",1
Fixed some bugs in clustering algorithm. Added PrintAndForward operator. Clustering still suffers from point duplication.,1
Fixed point duplication defect.,0
Ran clean-up.,4
Changed envelope dispatcher interface so every InterruptedException and IOException is now propagated back to the task,4
Reduced verbosity of RuntimeInputChannelContext log messages,2
Refactored join,4
First part of Job Canceling Tests,3
restarting from pact-runtime,1
cleanup debug code,0
fixing...,0
fucked up,5
"xRevert ""Post-Merge fix of ExecutionGraph""This reverts commit f5220d64b71a4e1468e6e045b06896f47e91fb02.",4
more comments,5
"Separating Pact Drivers and Control-Flow drivers, first part.",5
Part refactoring of abstract task as generic non-iterative control flow task.,4
Finalized sparation of pact driver and control flow logic.,2
Removed obsolete iteration packages.,4
comments + headers,5
Skeleton for the new job cancellation tests,3
Changed broker interface for new compression API,1
Continued modifications of compression API,5
Modified and extended system cancelling tests,3
Switched to cached thread pool in task manager to speed up cancelling of tasks,5
Continued to work on new compression API,1
Made Cancelling Tests IT CasesRe-enabled testing of task failures.,0
"Extended notice that the project uses Apache Code, to be compliant with Apache Guidelines.",1
- removed HDFS dependency in pact-tests- removed MiniDFSCluster from pact-tests,3
"Fixed bug in JSONGenerator, inputs have not been comma separated",5
Fixed bug where null parameter arrays are passed to the user code.,1
Changed logic of cancelling thread to join with executing thread.,2
"Pact Tests now run with disabled fault tolerance, for immediate visibility of failures.",0
Improved cancelling for file output tasks to better handle HDFS write abortions.,0
Introduced ConstantFieldsExcept annotation,5
Added output cardinanlity bounds to annotation,1
Added outboundcards to TPCH Query 3,1
Small bug fix for outboundcards,0
Merge branch 'version02' of https://dev.stratosphere.eu/git/stage1 intoversion02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MatchNode.java,5
Re-enabled task failure it case.,0
"fixed 2 testcases for TernaryExpression, started to comment TransitiveClosure",3
Small fixes in optimizer,0
Added uniqueness hints to k-means iteration example.,1
Temporarily disabled one cancelling test to allow version02 branch to build.,1
Refactored sopremo types,4
Added accessors to sources of Testplans,3
Refactored sopremo common,4
Finished revision of sopremo base,5
"Fixed file input and output stream handling for more robust cleanup.Existing files are not attempted to be overwritten, but explicitly deleted first (does the same, but HDFS handles it better)",1
Task driver thread handels all throwables and not only exceptions.,5
Fixed cancelling bug for chained tasks.,0
Removed System.out.println statements for checkpointing decisions.,5
Correct handling of NullPointerException in I/O requests when memory has been asynchronously released by canceling or failing the task.,0
Reworked WebLogAnalysis to new RecordInputFormat,1
Added singleton annotation for operators that shall run as a single instance. Added operator for finding frequent items.,1
Changed Singleton annotation to more flexible DegreeOfParallelism annotation. Avoiding test plan DOP synchronization for explicitly set DOPs.,1
adjusted test plans to stage1,3
adjusted sopremo to stage1,5
removed simple; will be recommited as meteor,4
Fixed bug NullPointerException on branching PACTs,0
Added grouping operator of DAP algorithm.,1
Added grouping operator of DAP algorithm.,1
Ran clean-up.,4
Fixed estimates for DataSource,5
Added basket shrinking operator for the DAP algorithm.,1
Fixed memory leak in FileInputSplitAssigner,2
Fixed memory leaks in TestPlan,3
Removed sopremo cleansing and sdaa11 packages; they will later be added in a separate branch,1
Added sopremo query package,1
Sopremo util -> sopremo query,5
WIP on Create Frequent Itemset Candidates Operator,1
Finished Create Frequent Itemset Candidate Operator.,1
Added uniqueness properties to inputs of KMeans example,1
Add PartitionProperty for unique fields,5
Temporarily added more outputs to find test plan deadlocks,3
Fixed sporaduous state transition from job graph FINISHED back to RUNNING and subsequent dead lock,1
Increased timeout time for cancelling tasks.,1
unified some expressions,5
Migrating Thomas's Range partitioner changes.,4
Interface and compiler portion of range partitioning for data sinks.,5
Added Range Partitioning with istribution to the JobGraph Generator.Added basic test case for TeraSort with Distribution.,3
Added ascii terasort input and re-added runtime range partitioning code.,1
Finished global sorting.Implemented TeraSort Test Case.,3
Fixed #255,0
Simple first attempt to resolve the deploy/cancel race problem,0
Fixed NPE in pact testing,3
Continue to work on deploy/cancel race problem,0
Package reorganization in pact runtime.,1
Made TempDir Separator the system's path separator (not hardcoded ':'),5
Fixed potential race condition in TaskManager failed task checking.,0
Fixed timing race in ExternalProcessInputFormats with waiting for process termination.,0
Fixed compile bug with generic signatures in input format.,0
Improved compatibility with Windows,1
Fixed test plan for tests without expected values,3
Fixed overly restrictive range check in pact record user type deserialization.,1
first halfworking version of bulk iterations,1
output,5
Refactored sopremo schema,4
added contextual projection,1
Added approximate double matching for sopremo test plans,3
removed test-jar from sopremo pom,3
added an intermediate job to the simple testing pipeline,3
updated gitignore,5
Adjusted pom.xml for test dependencies to latest documentation,2
Added meteor,1
Adjusted dist pom.xml,5
first shoot at channel reading for iterations,5
"Adds secondary sort capabilitySecondary sort capability is added for Reduce and CoGroup PACTs. Thechanges touch three parts of the code:1. User facing classes: AbstractPact and child classes2. Plumbing: Storing the secondary sort keys in the config, this is done   in PactRecordComparatorFactory. Adding methods to create comparators   take the secondary sort keys into account, this is done in   TypeComparatorFactory PactRecordComparatorFactory.3. Runtime support: This touches AbstractPactTask, CoGroupTask, and   ReduceTask, Also SortMergeCoGroupIterator is changed.",4
Add example that shows off secondary sort,1
Improved compatibility of JobManagerITCase test with Windows,3
Continued to improve robustness of cancelling logic,2
Merge branch 'stage1_version02' into version02Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/TaskManager.javanephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/runtime/EnvelopeConsumptionLog.javanephele/nephele-server/src/test/java/eu/stratosphere/nephele/util/ServerTestUtils.java,5
added superstep barrier + synchronization,1
Fixed bug in charset decoding logic.,2
Fixed race in TackManager's checking for failed tasks.,0
"Change user interface regarding SecondarySort stuffAll the AbstractPact descendents now have setters for the secondary sortkey classes and positions. Remove secondary sort stuff from allconstructors that was added in the first secondary sort commit.Also split example into two, one for Reduce and one for CoGroup.",1
"Modify where secondary sort keys are storedEarlier the fields and methods were in AbstractPact andSingle/DualInputContract. Now they are directly in ReduceContractrespectively CoGroupContract. The user interface does not change,however. The methods are just in another place.Also removed secondary sort code fromJobGraphGenerator.connectJobVertices that was mistakenly added thereearlier.",1
Fixed NPE in OperatorFactory,1
Adjusted interfaces for secondary sort to Orderings.,5
Cleaned POM fiel for pact examples.,4
Fixed cancel bug and bug in unregisterExecutionListener method of ExecutionVertex,0
Merge branch 'version02' of https://dev.stratosphere.eu/git/stage1 intoversion02Conflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/datamining/KMeansIteration.java,5
Added compiler testcase for branching plans,3
Create UnionNode in optimized plan when contract has more than onepredecessor per input,1
Adapted JobGraphGenerator to explicit UnionNode in optimized plan,5
Fix: add information about input groups to correct task,5
Temporary fix: Adapt dop for union from descendant,0
First draft of UnionNode,5
Removed unnecessary method from Unionnode,4
Added logging for a special error case in data sink tasks.,5
Removed orphaned getConstantSet method from OptimizerNode,1
Implemented output estimation for UnionNode,5
Adjusted CostEstimator for Union handling,3
Implemented property handling for union node,5
Adapted interesting properties generation for UnionNode,5
Implemented branch handling in UnionNode,5
Fixed NPE when determining global properties in UnionNode,5
Refactored coercing,4
Fixed package importer for .jar,2
Refactored NULL expression,4
Fix: Add instances per machine for UnionNode,1
Fix: Do not chain tasks which have Union as input,0
Fix: Branch handling for incoming connections in UnionNode,0
Add union to BranchingPlans testcase,3
Added ITCase for Union with in TPCH Q3,1
Added comments to UnionNode,1
Implemented log file rotation,2
Fixed minor bug in ChannelDeploymentDescriptor and added unit test,3
Forwarded changes concerning separation of task and driver logic from the iterations branch.,2
Added unit test for GateDeploymentDescriptor class,3
More robust startup behavior of nephele mini cluster for testing.,3
Robustness of cancelling improved.,1
Fixed flaw in unit test for GateDeploymentDescriptor class,3
Refactored expressions and functions,1
Implemented a workaround for nonfunctional Pact union,1
Fix NPE in Ordering toString method: Keytypes may be null,0
Do not display UnionNode in WebInterface,5
Added unit test for the default transfer envelope deserializer,3
Safety commit.,5
Corrected exception message in PactIntegerRemoved unimplemented method from PactString,4
First draft of test case for partitioning property when dop changes,4
Merging...,5
Merging Pt. II...,5
Change all pact contracts to use Builder patternThe contract-remove-constructors branch will remove the old telescopeconstructors which will lead to significantly simplified contractclasses and more readable user code. The Builder pattern is takenstraight from Joshua Bloch's Effective Java (2nd edition).,2
"Update ContextChecker and incorporate into plan compilationUpdate the ContextChecker to check the file paths of FileDataSource andFileDataSink. Also add checks for Plans with no children but that codeis commented out for now since I'm not sure whether such a situation canever occur because a PACT Plan is generated starting from the datasinks.Also update MissingChildException and PlanException with a constructorthat allows to specifying a proper error message.The checkPlan() method is invoked from Client.getOptimizedPlan(), thisway it will always be called when a program is run and the web-clientpreview will still work because it circumvents getOptimizedPlan().",1
Fix PACT Builders to only have one constructorThe contructor with arrays for key fields is gone now. TheadditionalKeyField() method is used to add several key fields now.,1
Finished changes to the compression interfaces,4
Added guava dependency to nephele job and taskmanager startup scripts,1
Fix: Wrong output of shipping strategy in JSONGenerator,5
added event-handling for bulk synchronization task,1
Fix: Filter GP and LP when DoP changes over a connection,4
Finished compiler test: different dop for pre-partitioned match inputs,3
Added diagnostic code for deserialization error tracing.,0
Adapted Arvid's mock classes to reflect changes if internal Nephele API,4
Fix in OptimizerNode: remember which branches have already been closed,0
Added test for property propagation through UnionNode,5
Changed remaining compression libraries to the new compression interface,1
"fixed wiring, cleaned up logging",2
Compression now also works in combination with recovery,1
iterative mapreduce is working,1
removed unnecessary config option,5
Use max of the inputs for distinct value cardinality estimation inUnionNode,1
Removed .idea folder,4
Fixed bug in LZMA decompressor,0
polishing iterative mapreduce,1
Removed accidenally checked in dep.txtAdded ignore patterns for idea ide.,5
Added event subscription / publication methods to mutable reader interface and implementations.,1
Removed unfinished checkpointing features for OS release,5
Reduced logging during task recovery,2
fixed iterative mapreduce,0
Improved logging in case a vertex cannot be canceled,2
Fixed bug in method checkCancelRequestFlag of class ExecutionVertex,0
Merge branch 'arvid'Conflicts:sopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/EmitMatrix.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/GenerateMatrix.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/Phase1.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/Phase2.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/Phase3.javasopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/TransitiveClosure.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/SopremoModule.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/AggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/MaterializingAggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/TransitiveAggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/io/JsonParser.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonCollector.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonNodeWrapper.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoMap.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/SopremoUtil.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/DirectSchema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/GeneralSchema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyHeadArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/Schema.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IJsonNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IntNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/JavaToJsonMapper.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/ObjectNode.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/LazyObjectNodeTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNodeTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/type/ObjectNodeTest.java,5
Fixed resource leak in library cache manager,0
"added testcases for MissingNode, Object- and ArrayNode",3
Fixed minor bug in TaskDeploymentDescriptor and added unit test,3
Added ITCase for Union (including empty inputs),1
Fixed bug in checkpoint removal method,4
added some testcases for NullNode and changed NullNode>>equals() method,4
Fixed possible race in recovery logic,2
Minor improvements,1
minor formatting of LazyTailArrayNode,5
Merge branch 'michael'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNode.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNodeTest.java,5
polishing iteration examples,1
multicast receiver: connection ID from executiongraph,5
Merge branch 'hpi'Conflicts:nephele/nephele-common/src/test/java/eu/stratosphere/nephele/io/channels/serialization/SerializationTestType.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/ElementaryOperator.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/Annotator.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/Clustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/Point.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/SimpleClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/initial/InitialClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/initial/SequentialClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/json/ClusterNodes.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/ClusterDisassemble.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/MainClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/PointMapper.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/RepresentationUpdate.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/PointSelection.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/PostProcess.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/RepresentationSelection.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/RepresentationSwitch.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/Split.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/tree/ClusterTree.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/ClusterToTreePreparation.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/TreeAssembler.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/TreeCreator.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/json/AnnotatorNodes.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/util/JsonUtil2.javasopremo/sopremo-sdaa11/src/main/java/temp/GeneratePoints.javasopremo/sopremo-sdaa11/src/test/java/eu/stratosphere/sopremo/sdaa11/clustering/ClusteringTest.javasopremo/sopremo-sdaa11/src/test/java/eu/stratosphere/sopremo/sdaa11/clustering/InitialClusteringAndTreeCreationTest.javasopremo/sopremo-sdaa11/src/test/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/TreeAssemblerTest.java,5
EC2 AMI ID can also be set in global configuration now,5
Fixed #258,0
Fixed miscellaneous minor bugs in compiler.,0
EC2 AWS ID and KEY can also be configured globally,5
"executed project cleanup fpr sopremo-common, added some new testcases for JsonNodeWrapper, further java doc commenting",2
further javadoc commenting,2
Merge branch 'version02' into ring_v2Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JSONGenerator.java,5
next shot at pagerank,5
"futher java doc commenting, removed method getInputName() from Source -> duplicate to getInputPath()",1
further java doc commenting,2
Minor improvement of code style,1
Minor style changes,4
Fixes problem with ambiguity of Hadoop hostnames,0
Re-enabled generation of zip and tar.gz files in distribution pom file,2
first shot at iterations with intermediate dual input tasks,5
Refactored TestRecords,3
Refactored and Reorganized sopremo-common,4
Moved query related sopremo implementation to this package,4
Added meteor,1
Refactored base,4
Removed files that are superfluous after previous refactorings,4
Added base layout for sopremo packages,1
Added tooltips for jobs and improved consistency of GUI,1
Fixed #185,0
Fixed unit test,3
drastically simplified event handling,5
Continued refactoring of sopremo-query,4
"Add  ReduceContract.Builder ctor without keyFor global aggregation, not sure whether this is implemented in the""backend"" yet, though...",1
"Add key-field-less ctor to Builder patternReduce, CoGroup, and Match Builders can now be created withoutspecifying any key fields. For CoGroup and Match the build() method nowthrows an IllegalStateException if now key fields have been set.Also, rename additionalKeyField() to keyField() because the key field isnot necessarily additional anymore (it might be the only key field.The changes are mostly due to sopremo, which uses the key less ctor andthen later adds all the keys.",1
Added required library to jobmanager and taskmanager start scripts,1
fighting with pagerank,5
Added connectNetwork() methodAdjusted PageRank Implementation to use network channel for broadcast.,1
Fixed Bug in Broadcast In-Memory Channel Closing.,0
first draft of sync as sink,5
merged with nephele fix and changed sync to be an output,4
Fixed bug in var-len integer deserialization.,0
Modified Data Sources to reset PactRecord objects before handover to input format.,1
Fixed Bug in Random Access Input view for small data fractions.,5
pagerank works with caching,1
"Cleaned up pact-examples: 1) Removed PigMix package, removed Manifest files, removed CoGroupSecondarySort job, renamed ReduceSecondarySort job",4
Renamed SecondarySort into GroupSort,5
"Improved pact-example jobs: 1) updated JavaDoc and inline comments, 2) added constant field and output cardinality annotations, 3) improved some implementations, 4) minor fixes",0
polishing and commenting of bulk iterations,1
- moved groupsort and terasort into an example.sort package,4
- completed refactoring of SecondaryOrder to GroupOrder in pact-compiler,4
Change Builder patter as per Fabians feedbackThe input() method is now variadic on the builders.,5
Merge branch 'arvid'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/AbstractSopremoType.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/DefaultFunctions.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/AggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/EvaluationExpression.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/function/MethodRegistry.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/io/Source.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/operator/SopremoModule.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/operator/SopremoPlan.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/CsvInputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/IOConstants.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonInputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/pact/JsonOutputFormat.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/IJsonNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/util/Equals.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/GroupingExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/packages/MethodRegistryTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/pact/JsonInputFormatTest.javasopremo/sopremo-query/src/main/java/eu/stratosphere/sopremo/query/InfoBase.java,5
fixed import warnings + further commenting,2
"further commenting, added classcomments to json node types",5
commented missing schemas,5
Fixed a bug in the scrambling field handling of the PactCompiler,0
Adapted the expected result of the WebLogAnalysis integration test,3
Fixed some bugs in the Pact compiler,0
Fixed the PairwiseSP example program and adapted the corresponding test case,3
Merge branch 'master' into version02Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/CoGroupNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/MatchNode.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/PactConnection.java,5
Fixed Pairwise Shortest Path example program and test case,3
added csv test resource,3
Refactored registries and aggregation methods,4
Merge branch 'arvid'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/DefaultFunctions.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/aggregation/TransitiveAggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/expressions/MethodCall.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/function/Aggregation.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/function/MaterializingAggregationFunction.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/io/JsonParser.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/AbstractArrayNode.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/JavaToJsonMapper.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/type/JsonUtil.javasopremo/sopremo-common/src/main/java/eu/stratosphere/util/reflect/ReflectUtil.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/BuiltinFunctionsTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/BatchAggregationExpressionTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/expressions/FunctionCallTest.java,5
fixed bug in ArrayNode.fillArray(result),0
Changed ShipStrategy from Enum to Classes. Partitioning Strategies hold partition keys as member variables,4
Reactivated GlobalSortingITCase,5
Added or unified Apache license header in pact modules,1
"Updated pom file of pact-examples, removed double import of guava in JM and TM start scripts",2
Remove empty source jars from distribution,4
Fixed function registry test cases,3
Fixed meteor tests,3
Excluded meteor server/client for now,5
partial refactoring to have sync check iteration termination,4
Fixed function call tests,3
Refactored meteor grammer; now without backtracking,4
Merge branch 'version02' of https://dev.stratosphere.eu/git/stage1 into version02Conflicts:pact/pact-examples/src/main/java/eu/stratosphere/pact/example/secondarysort/CoGroupSecondarySort.javapact/pact-examples/src/main/java/eu/stratosphere/pact/example/secondarysort/ReduceSecondarySort.javaAlso fix bug in CoGroupContract and ReduceContract that appeared due torenaming of setSecondarySortOrder... to setGroupOrder...,1
Added dop getter/setter to SopremoTestPlan.,3
Added build of pact-tests jar to pact-tests pom.xml,5
removed expression tags; added explicit preserve property for join,5
Fixed AbstractObjectNode's #copyValueFrom(...).,0
Introduced hybrid event model,5
completed refactoring termination decisions into the sync,4
polishing AbstractIterativePactTask,1
Added sopremo server/client with IT tests,3
fixed bug in broker key generation,0
polishing and commenting,1
Fixed outer joins,0
Fixed sopremo server/client test cases,3
added meteor client,1
Added meteor/sopremo scripts; adjusted nephele scripts,1
Removed java warnings,2
Simple input format for N3 files (e.g. for DBpedia).,5
Removed superfluent import.,2
Fixed dop issue in SopremoTestPlan.,3
Added sanity check to N3InputFormat.,1
Added main to Sopremo server,1
convergence checking via sync is now working,1
Replaced slow implementation of ID-to-vertex lookup,5
Changed executor service in JobManager to support larger clusters,1
Optimized Terasort Data Types as mutable objects.,5
Added normalized key direction inversion to normalized key sorter.,1
Added direction for comparison on PactRecordComparator.,1
Improved efficiency of mechanism to release instances,1
Removed deprecated class,4
Added diagnostic trace for input split opener timeout.,1
Fixed minor issues with sopremo server,0
Added minor robustness changes for input split opening.,4
Removing N3InputFormat: It now can be found in sopremo-datamining.,5
Made fs stream opening timeout configurable.,5
Made timeout configurable per stub.,5
Added sort directions for comparators to runtime and job compilation.,1
Fixed NullPointer Bug in PactRecordComparator.,0
Remove all public contructors from PACTSFrom now on only the Builder is to be used. Change all the existingcode to use the Builder instead of public constructors.The only constructor left is the private constructor that is invoked bythe Builder.Also fix the sopremo code to use the Builders.,1
Made RPC.getProxy a generic method,1
Minor adjustment of builder pattern code.,5
FIxed bug in default deserializer.,0
Fixed bug in DefaultDeserializer,0
Fixed overrestrictive null-pointer check in Ordering.,0
Fixed sort direction configuration writing/reading.,5
Fixed and extended tests for global ordering.,3
Added package transfer mechanism for sopremo,1
Fixed pom.xml in sopremo server,5
Fixed query error message,0
Prototyped first version of input format configuration builder.,5
Temporarily made config keys public to make not adopted examples compile.,1
Forward fitted changes to Sopremo Packages.,4
Disabled activation of input channels,5
Implemented piggybacking of lookup information,5
Fixed compilation error on jenkins,0
Simplified thread model for updates to the execution graph,5
Implemented optimization to speed up resource assignment in large-scale setups,1
Changed test layout of queue scheduler to get it working on slow machines,1
Implemented resource check during task deployment,5
Fixed bug in JobManager shutdown method,0
Added missing methods to MockEnvironment,1
Fixed IT of sopremo server,0
Fixed sopremo client IT,0
removed deprecated compiler hint,4
Test plan releases vertices properly now,3
Changes to input format configurator (builder) pattern.Added pattern for output formats.,1
Forward fitted changes to Sopremo Packages.,4
Reworking of FieldSet/List and properties.,1
First part of optimizer reworking.,1
Merge branch 'version02' of https://dev.stratosphere.eu/git/stage1 into version02Conflicts:sopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Projection.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/UnionAll.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/operator/ElementaryOperator.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/pact/CsvInputFormatTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/pact/JsonInputFormatTest.java,5
Cleaned up accidental HDFS dependencies.Added commons-codec as dependency to nephele-common,1
Extended Configuration for binary data.Fixed de/encoding problem in TaskConfig.,5
Fixed builder pattern port,0
Forward fit new config API to all examples,5
Forward fit new config API to plans in pact-tests,3
Prototyped first version of input format configuration builder.,5
Temporarily made config keys public to make not adopted examples compile.,1
Changes to input format configurator (builder) pattern.Added pattern for output formats.,1
Forward fit new config API to all examples,5
Forward fit new config API to plans in pact-tests,3
Post rebase cleanup.,4
Merged version02 into optimizer reworking.,1
Merge branch 'acb' into v2cbmConflicts:sopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/Projection.javasopremo/sopremo-base/src/main/java/eu/stratosphere/sopremo/base/UnionAll.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/pact/CsvInputFormatTest.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/pact/JsonInputFormatTest.java,5
Fixed and renamed delimited input format test.,3
Next steps in optimizer reworking,1
first working version of incremental iterations,1
Reworking of cost estimation.Reworking of data properties.,5
Plans do not reuse provided collections.,1
"finished configuration options for workset iterations, polished code",1
Removed Jackson dependency from taskmanager classpath.,4
polishing,1
polished code,1
brute force method to fix cp issue of missing commons classes,0
made JSON plan output more detailed.,5
reactivated deadlock resolver in PactCompiler,0
Fixed bug #269. Adapted RecordInputFormat to forward configuration to FieldParsers and extended test case.,3
fixed broken BrokerTest,3
Improved code style,1
Temporarily disabled debug message due to problems with log4j configuration in tests,3
Improved robustness of default configuration,5
Removed dead code,4
Fixed unit test,3
Optimizer Refactoring continued.WARNING: Broken,2
Next steps in optimizer refactoring.,4
Fixed #202,0
Strategy RefactoringPact Record Post Pass (1st part),4
Started to integrate new RPC service,1
Continued to work on integration of new RPC service,1
Continued to work on new RPC service integration,1
Changed RPC object serialization to Kryo,4
Started to implement support for data fragmentation,5
PactRecordPostPass,4
Fixed bug in multi packet output stream and added unit tests,3
Fixed bugs in serialization methods of Path and JobGraph,0
Fixed several bugs in new kryo-based RPC service,1
Fixed bugs related to new RPC service,1
Added support for multi-threaded RPC handlers,0
iterative examples run on cluster now,1
Optimizer Property Handling straightened.,5
Improved serialization efficiency for basic RPC messages.,1
specialized logging for execution visualization,2
Made a series of performance improvements to the RPC service and started to add java doc,2
Fixed unit test,3
Simplified serialization of job graph,5
Fixed bug in RPC service and improved thread-safety of some data types,5
Fixed unit test,3
PageRank reuses PactRecords,1
underflow due to int constant for MEGABYTE,5
- Ported UnionITCase to contract builder pattern,5
- fixed minor typos in inline documentation,2
- updated version and documentation wiki URL in README files,2
polishing,1
towards repeatable hashjoins on constant data path,5
Modified Nephele start scripts to include dependencies of new RPC service,1
Added generic versions of contracts.,1
Updated AWS dependencies,5
Fixed problem with unit tests,3
Changed instantiation of the RPC service,4
Removed SenderHintEvent mechanism in favor of new faster RPC service,1
Adapted other usages of RPC services to new interface,1
Added missing types to list of RPC types,1
Added more missing types to list of RPC types,1
Modified profiling to work with new RPC service,1
Modified visualization to work with new RPC service,1
disabled BroadcastRecordWriter,5
fixed PageRank implementation,0
Fixed error in calculation of buffer size for RPC requests,0
Fixed various bugs related to new RPC service,1
Intermediate result size optimized version of WordCount.,5
Added pointer (truncated long) method to mem segments.Normalized Key sorter has config parameter to set norm key len.,1
both pagerank versions working,1
Fixed Window Size Bug in Partial Sorter.,0
Fixed Window Size Bug in Partial Sorter.,0
Refactored Comments and Optimizer for Generic Versions of the Contracts,4
Fixed NullPointer in LocalProperties.,0
Generic Plan Entry point into Optimizer.First portion of adopting two input nodes.,1
third version of PageRank,5
Fixed default jar path in sopremo package manager,0
Changed command line syntax,4
Made the default location of jars configurable,5
Fixed formatting,0
Enhanced ArrayNodes,5
Enhanced type coercion,5
Composite operators now return SopremoModule instead of ElementarySopremoModule to help optimization and remove duplicate code,4
Generalized signature of setInputs in GenericDataSink,5
Fixed boolean coercion; made boolean constants immutable,0
Fixed resource warning of eclipse 4.2,2
Changed signatures of modules from arrays to lists,4
Added predicates utility class,1
Refactored GlobalEnumeration,4
Added temp variable factory,1
Removed superflous open in Selection#Implementation,4
Removed generic return value from CoreFunctions#filter,1
Added CachingArrayNode for more efficient string tokenization,1
Added input cardinality to global enum; improved difference,1
Added additional setter and ctors for Sink and SopremoTestPlan,3
Fixed meteor import,2
Refactored toString in Sopremo types,4
Added add methods for container expressions,1
Speeded up some CoreFunctions,1
Added option to switch between one time arrays and materialized arrays in reduce and cogroups,1
Made ExecutionGraph executor spawn only daemon threads as there is no cleanup mechanism yet,4
Made PactStrings appendable,5
Renamed TestPlanTest#Join to TestJoin to remove it from content assistent when you want a Join,4
Fixed global enumeration,0
Fixed memory leak through anonymous thread factory in ExecutionGraph,0
Fixed memory leak through anonymous thread factory in ExecutionGraph,0
Fixed PactString#append,0
Made ExecutionExceptionHandler in TestPlans static to make the code more robust against resource leakage,1
Added (I)StreamArrayNode for reduces and cogroups; removed MultipassValues annotations -> user must copy the values manually to ArrayNodes,1
Added StreamArrayNodes,1
Refit base operators to IStreamArrayNodes,1
Mocked local channels acquire buffers in a blocked fashion now,5
Fixed #273,0
Fixed CsvInputFormat for multi-part input files,2
Refactored exception handling in dynamic method invocations,4
Fixed CachingList#clear,0
SopremoServer checks request for formal validity,5
Continued refactoring of exception handling in reflective invocations,4
Added naive sampling data source,5
Fixed ctor of ArrayNode thus tracing of Reduce and CoGroups,0
Fixed RegexTokenizer,0
Added null check to Defaultclient#submit,1
Enhanced deserialization methods of SopremoUtil,5
Added guava to sopremo-server script,1
Moved bytebuffered channels to nephele-server package,4
Changed RecordSerializer interface,4
Worked on new record serialization,1
Implemented methods to efficiently serialize strings in default record serializer,5
Fixed javadoc,2
Started to refactor Nephele channels,4
Continued to work on Nephele channel refactoring,4
Made support for spanning records configurable,5
Continued to work on channel refactoring,4
Continued to work on channel refactoring,4
Continued to work on channel refactoring,4
Worked on refactoring of Nephele channels,4
Merge branch 'newrpc' into version021,1
Merge branch 'serializer' into version021Conflicts:nephele/nephele-common/src/main/java/eu/stratosphere/nephele/jobgraph/AbstractJobVertex.java,5
Changed generation of IDs to improve thread-safety and save calls to random number generation,1
Continued to adapt code to new serialization scheme,1
Continued to work on new serialization scheme,1
Continued to work on new serialization scheme,1
Continued to work on new serialization scheme,1
Moved serialization related unit tests to server package,3
Added method to construct job ID from byte array,1
Fixed serialization bug in AbstractJobVertex.java,0
Fixed bug in RuntimeEnvironment.java,1
Fixed bug in new ObjectSerializer,1
Fixed DefaultSerializerTest unit test,3
Removed deprecated unit tests,3
Changed interface of AllocationID,4
Changed interfaces of GateID and SpillingQueueID and modified unit tests accordingly,3
Removed unnecessary System.out.println in unit test,3
Added missing type to ServerTypeUtils,1
Adoption of MatchNode to new optimizer.,1
Fixed deserialization problem in AbstractDeserializer,0
Fixed serialization bug in JobGraph.java,0
Adapted AbstractJobResult and child classes to new kryo serialization,1
Changed record serializer back to old version to maintain compatibility with old unit tests,3
Adapted PACT code to compensate missing IOReadableWritable interface,2
Adapted Sopremo code to compensate the missing IOReadableWritable interface,2
Removed IntegerRecord from RPC protocols,4
Formatted POM files and changed version to 0.2.1,4
Fixed problems with POM files,2
Updated log4j dependency,2
Cleaned up nephele-profiling project,4
Fixed problem with nephele-profiling POM file,2
Removed duplicate Apache license notice,4
Introduced group state to reduce computational complexity on execution state changes,4
Implemented UTF8 string encoding/decoding,5
reworked convergence detection,1
Fixed bug in DefaultRecordDeserializer,0
Refactored record (de)serializer tests,3
Fixed shutdown problem in job client,0
Removed superfluous imports,2
Updated references to documentation on website,2
Added missing Stratosphere headers in Nephele packages,1
Fixed some minor problems discovered by FindBugs,5
Declared setBytes and getBytes of Configuration deprecated,5
Removed outdated references to IOReadableWritable interface,5
Fixed some minor style problems,0
Removed superfluous imports,2
Improved robustness of object serializer/deserializer,1
Changed mechanism for connection retries,4
Updated plugins in master POM file to work with Maven 3 and get rid of warnings,2
Fixed various small style problems and potential bugs,0
Removed deprecated class IOUtils,4
Fixed small style problems and potential bugs,0
Fixed potential race condition and memory leak in EventCollector,0
Improved code quality,1
Simplified multicast manager,5
Added missing kryo jars to pact start scripts,1
Refactored class names,4
efficient workset iteration convergence,1
Improved coverage of transfer envelope deserializer test,3
Updated dates in file headers,2
Started to integrate statistics module into new RPC service,1
Fixed potential race condition in RPC service,0
Runtime adoption to new operator model.,1
Extended RPCServiceTest to detect duplicate calls on the application level,3
Performance optimization of the RPC service,5
Further adoption of pact runtime.,1
Worked on statistics collection for RPC service,1
Added additional sanity check to RPC calls,1
Changed fractionID from short to int to avoid collisions,4
Added missing utility class,1
"Add LocalPlanExecutor for quickly executing plans locallyFor this move the NepheleMiniCluster from pact-tests to pact-clients.Also add a ""public static main"" to wordcount that demonstrates use ofthe LocalPlanExecutor.Add pact-clients as dependency in pact-testa and pact-examples becausethey use the LocalPlanExecutor and the NepheleMiniCluster.",5
incremental iterations work now,1
Fixed critical bug which has caused duplicate calls of RPC method,1
Added explicit signature check of RPC protocol interfaces,1
Worked on handling of new InterruptedException for RPC calls,1
Continued to work on handling of InterruptedException from new RPC service,1
More modifications to RPC protocols,5
Continued to incorperate RPC interface changes,4
Changed ProfilerImplProtocol interface to throw an InterruptedException,2
"big refactoring, removed custom caching, nicer repeatable hashjoins",4
"Added PactString#setValue(CharSequence, offset, len)",1
Changed error message for uri file schemes to make it clearer,1
Added CharSequenceUtil,1
Changed TextNode signatures to CharSequence,4
Major refactoring of composite expressions: each expression must provide an iterator over its structure,1
Adjusted base operators to the expression refactoring,4
Tokenizer now work on CharSequences,1
Adjusted unit tests to expression refactorings,4
Meteor parser now gives more detailed descriptions and solutions to some syntax/semantic errors,0
Finished PactTask rewriting for new task model.,1
convergence criterion finally working,1
convergence criterion finally working,1
Minor code style improvement,1
Added missing types to ManagementTypeUtils,1
Refactored aggregations; enhanced expression transformations; Added rewrite of grouping expressions to batch aggregation,1
Small improvements to sopremo-common,1
Adjusted sopremo base to last changes in sopremo common,4
Improved error specification of meteor scripts,0
Fixed test cases and pom.xml,5
Increased timeout and reduced logging of RPC service,2
Made SpanningRecordSerializer the default choice again until bug in non-spanning serializer is fixed,0
fixed bug in event deserialization,0
Fixed SopremoUtil#assertPlanEquals,3
Fixed MeteorTest#assertPlanEquals,3
Incorporated rico's patch for lazy array projections,5
Adopted Runtime tests to new runtime.,1
Set nephele-server logging level to WARN,2
"Implemented equals/hashCode for FileInputSplit, removed unnecessary locking in input split provider",1
towards compensations,5
Fixed deserialization bug of Join,0
Fixed channel inversion for TwoSourceJoin,0
Added missing node check for batch aggregation,1
Fixed deserialization bug of Boolean Nodes,0
first compensations possible,5
cleanup,4
Fixed FileLineReadWriteTest unit test,3
Fixed problem in management graph test utilities,3
Fixed #290,0
Fixed bug in recovery logic,2
Fixed problem in state transition logic,2
Changed configuration implementation to use java concurrency classes instead of synchronized statement,1
Fixed critical bug in RuntimeEnvironment,1
Started to refactored routing layer,4
Continued to work on refactoring of network layer,1
Started to refactor routing layer,4
Refactored TransferEnvelopeReceiverList,4
Continued to refactor routing layer,4
Added file missing from last commit,2
Continued refactoring,4
fixed errors if no convergence criterion is used,1
Implemented convenience method to detect last envelope transfered through a channel,5
Fixed bug in EC2CloudManager,0
TaskManager profiler now sends instance profiling data even if no task is currently running,1
Reduced visibility of methods in profiling component,5
Fixes possible deadlock in recovery logic,2
Fixed problem with code style,0
Removed deprecated class JobSubmissionException,4
Refactored execution graph listeners,4
Changed Nephele setup in test cases,3
Made NetworkLayer and DefaultRoutingLayer regular objects again to avoid problems during unit tests,3
Fixed QueueScheduler unit test,3
Fixed minor javadoc problems,0
Fixed bug in EC2CloudManager,0
Fixed problem with S3 file system test,3
Fixed minor problems with unit tests,3
Merge branch 'stage1' into version021Conflicts:meteor/meteor-meteor/pom.xml,5
Increased allowed cancelling time in PACT cancelling tests necessary due to slight changes in Nephele's event delivery order,4
Fixed problems with integration of new RPC service in Sopremo,1
Cleaned up source code,4
Reactivated reference tracking in kryo to avoid problems when serializing exceptions,0
"Renamed NetworkLayer and RoutingLayer to NetworkService and RoutingService, respectively",1
Changed API of of local buffer pool owner,4
changed nightly build profile,2
server settings for auto deployment,1
Fixed problem exception serialization problems,0
Minor code reformat,5
Added missing methods to DelegatingConfig.,5
"Merged with Aljoscha, added LocalExecutor",1
Fixed Runtime TestsFixed Common Delimited Input Format testsPulled Array-Model classes (POC) into separate project.Adopted JobGraphGenerator,3
driver property handling,5
version of pagerank that can handle dangling nodes,0
compensatable pagerank that handles dangling nodes,0
compensatable pagerank,2
Added two input node candidate enumeration.,5
Fixed enumeration / pruning for two-input contracts.,1
Implemented Plan Dump as JSON for optimizer plans and Candidate plans.,5
Implemened array data model.,5
Fixed Bug with incorrect output directory preparation.,0
Fixed serialization for array data model.,5
Fixed Optimizer DOP changes.Added test cases for optimizer DOP changes.Fixed Optimizer Branch Handling.Added Test Cases for Branch Handling.,3
Added union operator.Added handling of multiple sinks.Fixed branch handling.Added pipeline breaker insertion to prevent deadlocks.,4
Picked Nephele Fix from ssc-iterations branch.,0
Synced pact-common and pact-compiler between iterations optimizer reworking and iterations runtime reworking.,1
Synced pact examples and pact clients.,5
Synced pact-tests between optimizer reworking and runtime reworking.,1
Synced array-datamodel project between optimizer and runtime reworkings.,1
Merge iterations runtime code with iterations compiler code (1st part),1
Extended possible TEMP modes for channels.,5
"Compiler Iteration Support (Plan Creation, Static/Dynamic Paths, Interesting Properties).",1
Finished compiler phase for bulk iterations (modulo post pass for PactRecord and the array data model)Fixed Bug in SingleInputNode data-property handling.,5
Implemented Compiler Post Pass for Bulk Iterations With Pact Record.,4
First part of adjusting runtime to compiler.,1
Merged with ssc runtime for bulk iterations.,1
Temporarily moved the iterative playing files to another project to make the setup compilable.,1
Fixed compiler error in maven for TaskConfig.java,5
Moved iterative examples to a separatre project.,4
Temporarily disabled archive packaging.,5
Added stub and contract for reducer with key.,1
Bulk Iterations finished.,5
Fixed error during closing of delimited input format.,0
Fixed Bug concerning incorrect filtering of GlobalProperties.,0
"Added / extended tests for clustering, including iterative variant.",3
Enabled proper canceling of iterative tasks.Merged Iteration Head now supported.,1
Add DeNormalizableKey interface and fixed-length sorter,0
"Workset Iteration Compiler, part 1",1
Included resettable driver strategiesAdopted ssc variant of dangling pagerank,1
Fixed memory leak in temp barrier.,0
Added types and serializers/comparators for dangling pagerank.,1
Applied ssc patch to improve stubs and input formats.,1
Implemented dangling pagerank with generic data types.,5
Included fix-length record in-place sorter.,0
Warning to indicate that in-place-sorter is not spilling ready.,2
Enabled spilling for fix-length in-place sorter.,0
Enabled synchronous combiner.Added combiner to custom dangling page rank.,1
Fixed inefficiency and congestion in input channels.,0
Changed interrupted checking in output channels from per-record to per-buffer.,4
Changed PactProgram to not instantiate plan multiple times.Removed obsolete reflection visitor.Cleaned up context checker.,4
Combiner filled with global and local properties.,5
Fixed bugs in JSON dump generator.Added tests for JSON dump generator.,5
Fixed plan web display.,0
Adjusted cost heuristics / comparisons.,5
Changed type serializers / comparators from interfaces to abstract classed (faster virtual method lookups),4
Reworked Input formats for correct handling of cached statistics.,1
Reworked commons IO testing and added sampling test for the delimited input format.,3
Extended tests for delimited input format.,3
Added extensive optimizer tests.,3
Temp.,5
Extended and reworked optimizer tests.,3
"Extended compiler tests for K-Means.Fixed Cost formulas to properly distinguish between sorted, hashed, and arbitrary materialization.",0
Stripped down stratosphere for ease of internal feature prototyping. - Excluded Sopremo / Meteor for now. - Excluded build-tools and EC2 scripts - Excluded buggy checkpointing tests in Nephele.Cleaned up some warnings in Maven POM Files.,2
Cleaned up pom.xmlSmall fix for pact runtime tests.,3
Dropped SelfMatchTasks (currently not working and of low priority to fix).Fixed ChainedTaskTests in pact runtime.Repaired root pom.xml,5
Refactored Job Manager Execution Modes.Reworked Nephele Mini Cluster.Added Local Executor.,1
Reworked Nephele Mini Cluster to start more reliably.Fixed Local Executor.Fixed Bug in Delimited Input Formats.Reworked KMeans tests (both single step and iterative).Removed Pact Testing Framework for now.,1
Extended JSON Dumps for iterations.,5
Reworked UDF annotations.Enumeration of incremental iteration plans complete.,1
Excluded nephele EC2 project.Cleaned up POM files.,2
Introduced RuntimeContext for UDFs.,1
Initial commit,5
Fixed Test for Delimited Input Format.,3
"Adjusted smoe examples and fixed some tests.Temporarily disabled tests for global sorting, which is disabled for the time being.",3
Added tuple data type (experimental).,5
Fixed Union in Optimizer Plan Enumeration.Fixed Cancelling tests.Adjusted example programs to use runtime context for subtask information.,5
Minor consistency fix in the pom files.,2
fixes #11 : nephele-ec2cloudmanager dependency still in stratosphere-dist pom.xml,5
Implemented generic aggregators for iterations in the API and configuration.,5
Added PactBoolean type.,1
Fixed aggregator registration for iteration tasks.,0
Reworked examples.Implemented custom aggregators (runtime misses iteration head task),1
Finished customizable aggregator implementation.Added DanglingPageRank example.Reworked iterative tests.Reduced logging verbosity for iterations (temporarily commented out monitoring facility for time tracing),2
Fixed Union Plan Enumeration.Fixed Branching Plan tests.,3
Added json verification to json generator tests.,3
Implemented pact plan visualization for bulk iterations.,5
Made sure that correct hash join strategy is used for operators joining with the solution set.,1
Implemented optimizer plan post pass for workset iterations.,1
Fixed erroneous cluster mode instantiation.,0
Dropped erroneous test for faulty multicast channels.,3
Hided not wanted elements in visualizatin of iteration pact plans,5
Temporarily accellerated external-sorter tests.,3
unified white spacerenamed variables for gateIndexes,5
added CHANGELOGwrote first entry in CHANGELOG,4
Merge pull request #16 from mhuelfen/masterFixed #16 Hiding extra Iteration Elements in Pact Plan Visualization,0
Maven POM file cleanups.Added missing primitive type wrappers.Adjusted API for ozone-scala.,4
Fixed various tests.,3
Implemented runntime for workset iterations.,1
Fixed shutdown logic in task unit tests.,3
Fixed port conflicts between unit tests and running nephele instantces.,1
Implemented JobGraph generation for Workset Iterations.,1
Reworked compiler post pass to be generic for all flat record models.,4
Update pom.xmlThe configured dependency version for pact-array-datamodel should be the same as the one of the enclosing project.,5
Merge pull request #29 from aalexandrov/patch-1Update pom.xml,5
Implemented reopenable hash join.,0
Fixed startup scripts to include extended hadoop dependencies in the classpath.,0
Extended comments in nephele config file.,2
Minor cleanup and corrections in API classes.,4
Fixed webfrontend plan display for workset iterations.,1
Split pact-compiler project between compiler and its unit tests and the compiler end-to-end tests with example programs.,3
Fixed hash join tests with after salting hashes.,3
Fixed dependencies of pact compiler tests.,3
KMeans example point input format parses negative numbers.,5
Disabled recovery by default.,5
New kmeans data generator.,5
Made sure user code class loaders are used for cloading user code classes.,1
Implemented CoGroup join with solution set.,1
Cleaned up connected components example and tests.,3
Fixed bug in pact-record-output-emitter partitioner.,0
Fixed class loading during transmission of user-defined aggregators through the iteration events.,1
Minor cleanup in examples.,4
Fixed WorksetCoGroup Tests.,3
Cloudera distribution of hadoop added as default dependency.Separated classpaths for cluster and clients.,1
added travis yml,5
Merge pull request #52 from rmetzger/gith_ozone_travis_integrationTravis-CI configuration,5
Ensured proper setup of logging framework in system integration tests.,3
Fixed bug where test temp files were not cleaned up.,4
"Iteration head tasks are not merged with first operator in superstep, if there is a local strategy that needs to be executed directly prior to the first superstep.",1
Updated Maven artifacts version to 0.2-ozone.Allows deploying Ozone to a local repository next to a vanilla Stratosphere distribution.,1
fixed: ArrayIndexOutOfBoundsException when reading test input > 32KB,3
fixed: multiplexing deadlock,0
re-openable hashjoin integration test,3
"Changed memory segment to use ""unsafe"" (native) memory accesses.",1
Mapped normalized key comparisons and record swapping in sorters to memory segment operations.,5
Fixed erroneous normalized key generation in PactCharacter.,0
Removed obsolete denormalizable key types.,4
Added bulk copy methods to memory segment.,1
Updated bulk get/put methods in memory segment in support of unified nephele/pact memory buffers.,1
Fix config and start scripts to work on Windows/cygwinAlso fix WebInterfaceServer.java to properly check whether pathis absolute on Windows.Default directory entries in nephele-user.xml and pact-user.xmlare now commented out because java code will load proper default.,1
Adjusted cygwin path conversion for path lists.,5
Fixed bad assembly of dropin libs in the stratosphere-bin shell scripts.,4
"Revert ""Adjusted cygwin path conversion for path lists.""This reverts commit 63d30a05fa290661e59d324384c3f0279e97c51e.",4
"Revert ""Fix config and start scripts to work on Windows/cygwin""This reverts commit a452fd48e971fa17423785398015aac887dbb6c0.",5
Fix config and start scripts to work on Windows/cygwinAlso fix WebInterfaceServer.java to properly check whether pathis absolute on Windows.Default directory entries in nephele-user.xml and pact-user.xmlare now commented out because java code will load proper default.,1
Merge pull request #60 from aljoscha/masterCygwin Fix Again,0
Merge pull request #59 from aalexandrov/fix_dropin_libsFixed bad assembly of dropin libs in the stratosphere-bin shell scripts.,4
added test case to verify input format bug,0
Fixed failing TextInputFormatTestSigned-off-by: Robert Metzger <metzgerr@web.de>,3
Backported ID Methods from 0.2.1,5
Generified binary and sequential i/o formats,5
Generalized methods in format utils,5
Fixed incorrect handling of generic formats in data sink tasks,5
Fixed local instance manager live lock during shutdown,0
Generified generic data sink ctor,5
Fixed generics in FormatUtil,0
Decreased waiting times in IPC Client to speed up LocalExecutor,5
Made PactString appendable,5
Added contract util for generic contract manipulation,1
Fixed bug in PactString append.,0
Merge pull request #62 from rmetzger/gith_input_format_bugMinor bugfix for TextInputFormat + Testcase,3
added test case (without fix) for a pact compiler bug with ALL_GROUP-reducer.,0
Implemented AllReduce.,5
Cleaned up warnings in pact-common.,2
Created Debian Package for Ozone install(Pull request by Christian Richter),1
Changed to snapshot version; added maven repository for deployment,1
Added automatic deployment to sonatype repo with travis,1
"Added HBase table formats (patch by Marcus, slightly adjusted).",1
Updated Contributors list.,5
"removed the FileBuffer from Nephele, and everything that uses it (Checkpointing, FileChannels)Changed Nephele MemoryBuffer to wrap PACT MemorySegment instead of java.nio.ByteBufferAddressed Stephans commentsnew memory segments methodsRemove checkpointing and envelope consumption logicSigned-off-by: Robert Metzger <metzgerr@web.de>Removed compression from nepheleRe-added tests.Re-enabled JobManagerITCase with reduced logging verbosity.",2
Reduced test logging verbosity to only print warn messages.,2
Fixed classloader delegation of task conf,5
Added maven-profiles to enable switching between yarn and non-yarn hadoop,0
"Remove pact-examples dependency in pact-clients.pact-clients was dependent on pact-examples in order to runLocalExecuterTest. The problem with that was, that this prevented theuse of the LocalExecuter within the pact-examples module (circulardependency). Hence the LocalExecuterTest was moved to the pact-testmodule and the pact-examples depedency was removed from pact-clients.",4
First part of fix to exclude pact-hbase when hadoop v1 is used,1
Added extra profile entries in the pom.xml files in order to fix the hadoop_v1 compilation problems.,0
"Merge pull request #1 from aalexandrov/hadoop-maven-profilesFix from Alexander, so that pact-hbase is only included if yarn is used (because it is not compatible with hadoop v1)",1
Made the hadoop_v1 profile active by default.,2
Moved hadoop.version property to the profiles.,2
Update README.md,2
Update Readme.md with project overview and a little tutorial.,2
Merge pull request #85 from rmetzger/gith_readmeUpdate Readme.md with project overview and a little tutorial.,2
Update README.md,2
Update README.md,2
"Rename SetId() to setId()Hopefully fixed a bug in the pact compiler for branching plans:- added a test case provided by Anja Kunkel from HU Berlin- my understanding of the bug is the following: During a check if additional pipeline breakers are necessary,the compiler checks for the LocalStrategy of a SinkJoinerPlan. The SinkJoinerPlan is a ""fake"" plan element to group multiple output sinks into one sink (the compiler assumes one root node, this is why a ""fake"" plan node is required).The local strategy of SinkJoinerPlan is initialized as NONE, which means that we just pass through the elements (which makes sence since we are talking about a sink) The initialization of a NONE-local strategy assumes only one input, not two.I replaced the LocalStrategy with BINARY_NO_OP, which is a NONE for two input.The compiler is now able to do its pipline breaker checks.",4
Merge pull request #2 from aalexandrov/hadoop-maven-profilesMade the hadoop_v1 maven profile active by default (hadoop version 1.2.1),2
Update README.md,2
Fix for a null pointer exception in new memory buffer,1
Merge pull request #70 from carabolic/masterRemove pact-examples dependency in pact-clients.,4
Travis build matrix for different profilesupdated contributersadded comment for eclipse users,1
Merge branch 'andrehacker-hadoop-maven-profiles',2
1) Fixed problem where commons-io jar file was missing in the lib directory 2) Fixed wrong maven group definition of commons-io (changed from org.apache.commons to commons-io) and updated to a more recent version (same as hadoop),5
Use wildcards to exclude all jetty artifacts,1
Merge pull request #92 from andrehacker/ozone_lib_fixFixed commons-io missing in lib directory + fixed wrong groupId of commons-io,0
Fixed nephele-config.sh substr command calls on OS X (closes #88),5
Fixed bug. stub.open() was not called for COMBININGSORT local strategy.,5
Merge pull request #97 from fhueske/masterFixed bug. stub.open() was not called for COMBININGSORT local strategy.,5
"Links to documentation, typos in README",2
Merge pull request #96 from uce/fix/nephele_config_script_os_xFixed nephele-config.sh substr command calls on OS X (closes #88),5
Added ALL_GROUP strategy to PlanJSONDumpGenerator. Before this fix the pact web could not show the plan.,0
Merge pull request #105 from andrehacker/fix_web_all_groupAdded ALL_GROUP strategy to PlanJSONDumpGenerator.,5
FileInputFormat.acceptFile() to filter out files and directories while creating input splits (like _log or _SUCCESS),2
1) Changed profile activation to properties (like hbase) 2) moved all properties to top of pom 3) moved module list to top of pom,4
"Remove unused exclude-statements in assembly-descriptor (exclude elements can only define artifacts, not paths)",1
Added hbase inspired script to generate poms for hadoop1 and hadoop2 (yarn),1
Added relative path to all poms,1
"Travis support for new profiles, readme, comments in script",2
Removed TeraSort from example jars when packaging,4
Merge pull request #102 from uce/remove_terasort_from_buildRemove TeraSort from examples,4
Merge pull request #111 from rmetzger/gith_andre_new_profilesSupport for different Hadoop versions (yarn!) using activation by properties,1
Mailing list link in README,2
Improved readmeWith help from @uce,1
Merge pull request #89 from rmetzger/gith_compiler_bug2Pact Compiler fix+testcase for SinkJoinerPlanNode,3
Make PartialSolutionHolder non-final in BulkIterationThis is needed because the scala frontend will create a customPartialSolutionHolder to allow it's magic to happen.,1
Make the placeholders in WorksetIteration non-finalThis is needed for the magic that happens in the scala frontend.,1
"Add support for passing objects to PACT contractsWhole stack is changed so that input/output formats and PACT contracts,respectively their builders, accept objects in addition to classes foruser code stubs.So now one can do:MapContract.builder(new CountWords())in addition to:MapContract.builder(CountWords.class)Objects passed in this way need to be serializable. The advantage isthat one can now pass arguments in the constructor of the stub, storethem in the stub, and they will be available when the stub is run. Thisis less cumbersome than using the Configuration to pass parameters.This change was originally  necessary to allow the scala frontend to generateusercode objects to pass to PACT contracts.",4
Merge pull request #73 from aljoscha/masterSwitch to using objects instead of classes for usercode,1
Merge branch 'master' of github.com:AHeise/ozone into AHeise-masterConflicts:.travis.ymlnephele/nephele-clustermanager/pom.xmlnephele/nephele-common/pom.xmlnephele/nephele-compression-bzip2/pom.xmlnephele/nephele-compression-lzma/pom.xmlnephele/nephele-compression-snappy/pom.xmlnephele/nephele-compression-zlib/pom.xmlnephele/nephele-examples/pom.xmlnephele/nephele-hdfs/pom.xmlnephele/nephele-management/pom.xmlnephele/nephele-profiling/pom.xmlnephele/nephele-queuescheduler/pom.xmlnephele/nephele-s3/pom.xmlnephele/nephele-server/pom.xmlnephele/nephele-visualization/pom.xmlnephele/pom.xmlpact/pact-array-datamodel/pom.xmlpact/pact-clients/pom.xmlpact/pact-common/pom.xmlpact/pact-compiler-tests/pom.xmlpact/pact-compiler/pom.xmlpact/pact-examples/pom.xmlpact/pact-runtime/pom.xmlpact/pact-tests/pom.xmlpact/pom.xmlstratosphere-dist/pom.xml,5
travis fix,0
Add an example of using LocalExecutor in WordCount example,1
Merge pull request #121 from aljoscha/masterAdd an example of using LocalExecutor in WordCount example.,1
travis: add script to deploy both versions of ozone to sonatype,1
typo in travis config,5
Merge pull request #108 from rmetzger/gith_input_format_filterIgnore system files when using FileInputFormat,2
Generate source attachments for each subproject,5
Add methods to get optimized plan from LocalExecutor,1
Merge pull request #129 from uce/add_plan_dump_to_local_executorAdd methods to get optimized plan from LocalExecutor,1
remove maven source plugin from 'nephele.pom',4
Add scala code to mainline,1
Merge pull request #135 from aljoscha/add-scala-frontendAdd scala code to mainline,1
Update path to stratosphere-dist folder in README.md,2
Fixed translation bug where solution set was first input to the join.,1
Fixed concurrent modification in memory release.,0
Removed Nephele plugins,4
Fixed erroneous execution graph test.,3
Updated maven surefire plugin version.,5
Added first version of Scala example jobs for triangle enumeration,1
Fix bug with user-code wrappersThe problem was that the user code wrapper was not deserialized from theconfig using the user-code class loader. Now we jave a customObjectInputStream that uses the user-code class loader to resolveclasses.,0
Merge pull request #155 from aljoscha/user-code-loader-bugfixFix bug with user-code wrappers,1
Don't create empty splits in BinaryInputFormat#createInputSplits on one input file.,2
BinaryInputFormat#createInputSplits on one input file test added.,1
Avoid invalid ranges in BinaryInputFormat#createInputSplits while creating empty splits.(HDFS doesn't like invalid ranges and returns an empty array in this case),1
Update README.md* new link to mailing list* fixed #149* Added dima irc channel,1
Update project name in maven poms and readme,5
Fix bug in UDTAnalyzerIterator of analysed list types was not correctly generated when arraysare used.,1
Fix bug in Scala serialization code generation,0
Added test cases for Java triangle enumeration example jobs,3
Scala triangle enumeration examples behave like their Java counterparts,5
Merge pull request #161 from aljoscha/serializer-fixesSerializer fixes,0
added tests for Scala triangle enumeration examples,3
Scala triangle enumeration examples follow the implementation of their Java counterparts.,5
Changed triangle enumeration scala jobs to scala class instead of object,4
Integration tests for triangle enumeration scala examples working,1
added getUserCodeClass to UserCodeWrapper,1
Merge pull request #167 from mleich/usercodewrapperAdded getUserCodeClass to UserCodeWrapper,1
Put dependencies in pact-scala in the right places,5
Fixup the rest off the scala examples and add Integration TestsSome examples do not work due to bugs in the runtime (iterations). Forthose tests that don't work we don't yet have an integration test sothat mvn verify will not fail.,0
Merge pull request #166 from aljoscha/fixup-scala-examplesFixup scala examples,0
Update README.md,2
Added local strategy SORT to DataSinkTask and extended DataSinkTaskTest correspondingly,5
Update commons-io artifact to same version as everywhere else.Use the new cooridnates for it.Fix a warning in pact-hbase/pom.xml.,5
"Unified config and added YAML (syntax) support (#113)- Unified config to stratosphere-conf.yaml, which replaces the old  nephele-user.xml and pact-user.xml and is also read by  bin/nephele-config.sh- Removed some settings from config:    * instance configuration    * multicast for broadcast    * profiler impl classes    * jobclient.polling.interval (adjusted default from 5 to 2)    * pact.runtime.fs_timeout",1
Improve pom-tooling scriptsPom-generate script now allows to specifiy a filename for the pomnew script to rename poms,1
Added early checks against invalid null inputs to contracts.,1
"Reqorked branch handling method in sink joiner to report when a disjoint data flow graph is found.Added test case for catching simple disjoint cases.Added test case for a more complex case of a branching but disjoint data flow graph (deactivated now, as it is not yet caught by the compiler).",5
Add filter on Join and Cross in scala frontend,1
Merge pull request #174 from aljoscha/filter-on-match-and-crossAdd filter on Join and Cross in scala frontend,1
Updated Readme to specify that Maven 3 is required.[ci skip],1
Update README.md with required plugins for eclipse 3.7,1
Change name in base pom and versionEnd the version name craziness and go back to have 0.4-SNAPSHOT asversion number. Also change the name of the toplevel pom back tostratosphere.,4
"Changed branch handling logic to correctly recognize disjoint data flow graphs, rather then erroring out.",0
Fixed erroneous costs handling in sink joiner.,0
Fixed wrong URL of quickstart script in README file.[ci skip],2
"Fix stratosphere-dist to include the scala jarsAlso fix an annoying bug that made tests fail because a dependency onscala-reflect was wrongly in the ""test"" scope.Also make alle the examples that work implement PlanAssembler and outputgenerated example jars for these examples to examples/pact-scala in thedistribution.",1
Remove ozone from readme [ci skip],4
Merge pull request #179 from aljoscha/fix-scala-jarsFix stratosphere-dist to include the scala jars,0
Rename hadoopReduce -> groupReduceAlso rename combinableReduce -> combinableGroupReduce,5
Fixed problems with scripts and default config- added missing environment variables in scripts- changed default port of web frontend back to 8080- replaced bc command with 'expr +' for adding heap sizes,1
Added toString() methods to configuration and task classed to ease debugging.,0
prevent chained tasks in the iteration tail for now.,5
Fixed Stratosphere Website link (relative relative to absolute link)[ci skip],2
Change scala KMeans now that map as last op in interation works,1
Reworked input channels with respect to returning events and buffers. Simplified logic and fixed bugs and reduced number of status polls.Reworked record readers to properly support unions and events.,1
Fixed Nephele Visualization job selection not working on Mac OS X[ci skip],1
Fixed and extended comments in WorksetConnectedComponents example.[ci skip],1
fixed: PactRecord allocating too few memory when writing UTF encoded strings,0
Upload builds as tgz and as directory to DOPA server,5
Fix stratosphere-dist: Some really outdated README's removed. The README and LICENCE were not copied to the build.,4
Fixed overly restrictive condition to identify disjoint plans.,0
"Rename groupReduce -> reduceGroup, add reduce/reduceAll on DataStream",5
Moved pact-compiler-tests from individual project into pact-tests.,3
"Move plan checking from PactProgram to ClientClient would invoke PactProgram.checkPlan(), but this is the only placewhere this was done, so I moved it.This is in preparation of further cleanups and a slight refactoring ofPactProgram.",4
Change Client to accept new PlanWithJars instead of PactProgramPlanWithJars is a simple wrapper around a Plan and a list of jars thathave to be submitted with the plan. This is necessary to enable theRemoteExecutor that simple accepts a Plan and a list of jars without thewhole PlanAssembler and jar extraction business of PactProgram.PactProgram now has a getPlanWithJars() method that does the old jarextraction and simply creates the PlanWithJars wrapper with the planthat it created from the PlanAssembler in the jar. Client no longercares about the jar extraction logic and does also no longer calldeleteExtractedLibraries (since it does not have a reference to thePactProgram anymore). The code that creates the PactProgram is notresponsible for calling deleteExtractedLibraries after the job issubmitted.,4
Change Client to return job runtime if called with wait=true,1
Add PlanExecutor interface and RemoteExecutorLocalExecutor now implements PlanExecutor and RemoteExecutor can be usedto submit jobs to a cluster.Example usage added to the WordCount example.,1
Remove comment from TransitiveClosureNaive scala exampleThe comment said that it didn't work because of the bug with unions initerations. That works now.,1
updated CONTRIBUTORS file,2
Merge pull request #200 from fhueske/updateContribFileUpdated CONTRIBUTORS file,2
Added weblog analysis Scala example and corresponding integration test.,3
Merge pull request #204 from fhueske/weblogScalaExampleAdded weblog analysis Scala example and corresponding integration test.,3
Add union input test (issue #192),0
Add warning in nephele-config.sh that the values are only defaultsI added this because several people already mistook this for the actualplace to change config values.,5
Prevent operator chaining directly after iteration nodes.,5
"Fix NepheleJobGraphGenerator bug with iterationsWhen traversing it is not checked whether iterations where alreadyvisited, this led to a bug when you used the output of an iterationtwice.",1
Use JAVA_RUN in all start scripts[ci skip],1
Added test case to check compiler with plans branching directly after a loop.,3
Implemented ordering within groups in optimizer.Added tests.Cleaned up property matching/reasoning for dual input operators.,1
Remove IPv4 Stack Hint[ci skip],4
Maven requirements [ci skip],1
Cleaned up wordcount examples.,4
Re added accidentally lost WordCountArrayTuples example.,1
"Improved handling of probelm causes and better error messages when connecting to HDFS for hdfs resident files.Added HDFS as dependency to pact-client, to allow local-executor to access hdfs files.",2
Fix1: Combiner gets same DOP and SubtasksPerInstance as its input to be chainableFix2: Local strategy of stand-alone (non-chained) combine driver      Adapted CombineTask tests to new local strategy,1
Fixed instantiation of utility combine node to use the correct properties.,1
Fix for Issue #93: slaves file requires blank line at end (otherwise last slave won't be started),1
change deploy tool to detect current stratosphere version and dynamically generate the yarn build,4
Fixed typo in method name,2
Removed unnecessary import from RequestedLocalProperties.,2
Small fix in PactRecordComparator,0
Reenabled range partitioning with manually specified data distributions.- Added Generics to DataDistribution- Added range partitioning to output emitter- Adapted output emitter tests- Added PactRecordDataDistribution and corresponding test- Reactivated pact tests with range distribution.- Reincluded TeraSort Pact Java example into example jobs.,3
Merge pull request #223 from rmetzger/fix_deploy_toolchange deploy tool to detect current stratosphere version,4
Hotfixing version detectionAdd renaming utility to master branch,1
"Simplified DataDistribution. For now, compatibility of DataDistribution and global sort order is not checked. The DataDistribution must be correctly specified on ALL keys of the sort order.Checks will be added later.",1
Show version and git revision on JobManager startup (in log)Place .version.property file into root directory of the build.,2
"Dump pact plan as json, using the local executor",1
Added extra versions of the Cross contract that determine which side should be broadcastet and how to pisk the local strategies.,1
Information Webfrontend for JobManager,5
Eliminated redundant copies in log file streaming.Minor cleanups.,4
Added constants for true and false to PactBoolean[ci skip],1
Runtime client prints original description without HTML preprocessing.,1
Removed defunct program description HTML preprocessing code.,4
Used intrincis opertations for primitives construction in pact record.,1
Fixed web frontend startup script to properly redirect standard streams.,0
Added redirection to job manager info frontend int the pact compiler web frontend.,5
Reworked text parser to propery work with quoted strings.,1
Cleanup of test logging and some comments.,2
"Cleaned parsers and reworked double parser to go through Java's parsing logic (which is object heavy, but precise) until we have a precise parser.",2
Added small introductory text about stratosphere to the readme.,1
move logVersionInformation() method to main() method,5
exclude jruby-complete from hbase.,5
Cleanup of main pom; generate javadocs,2
Merge branch 'version_information' of https://github.com/rmetzger/stratosphere into version,5
Added version properties file to be ignored by git,2
Added default logging to job manager (when started from within IDE).Failure to start web info server does not terminate job manager.,5
Fixed initialization of runtime context in combiners.,1
Change how DataSourceFormat is handled internally,0
Add implicit generation of UDT[T]This helps when implementing custom scala data input formats.,5
Change DataSinkFormat to also allow easy implemention of custom formats,1
Change scala version to 2.10.3,4
disable uploading 'stratosphere-dist' to dopa server,5
"Maven and build changes- use ""build"" profile of maven, to avoid any download progress information- Reduce logging verbosity of javadoc-plugin- instruct maven-eclipse-plugin to download sources (so that users can debug through our code without actively downloading the code)- Remove warnings in eclipse from the new git-commit-id maven plugin",1
hopefully fix bug with version detection using maven for yarn deployment to sonatype,1
Improve deployment on travis,1
CSV Parsers fail on inputs that cannot be parsed instead of silently ignoring the lines.,0
Changed default testing log verbosity for TestBase.,3
"Fixes #242. Excludes nephele-examples, pact-examples, and pact-scala-examples from distribution lib folder",0
Fix and spell correct version change script.[ci skip],4
Add support for using arbitrary Pact Value classes in scala frontendAlso add checks in key selector extraction to check whether the selectedfields can actually be part of a key.,4
Add link to starter jobs[ci skip],2
"LocalDistributedExecutor: Execute Nephele in CLUSTER-mode mode, with multipleTaskManagers in one JVM. The datatransfer happens over the OS network stack, notthrough memory channels",1
Rename multiple Scala classes: - DataStream to DataSet - DataSourceFormat -> *InputFormat - DataSinkFormat -> *OutputFormatClean up imports in scala examples,2
Manually configured JAVA_HOME is preferred over system configuration. No default JAVA_HOME is used. Instead an error message is shown. Adresses #207Added use of default java command as third option (after stratosphere-conf.yaml and JAVA_HOME).,5
PactProgram and PlanWithJar create proper user code class loaders.,1
"Resolve issue with hardcoded ""file://"" URIs under windowsRelocation of constructTestPath and constructTestURI methods to Path",3
Fixed check for local file scheme in TestBase2.,3
Added stubs for count function and counting reducerAdded word count example using the counting of group elements.,1
Added IT Case for count() agrgegation function.,1
Minor changes in RemoteExecutor.java and LocalExecutor.java. Removed obsolete null-value check in the finally clauses in LocalExecutor.java. Returning proper exit code in RemoteExecutor.java.,1
Rename Record*Format to Csv*Format in scala frontend,5
Adjusted test to new output format names.,1
Name escaping for jobmanager webfrontend,5
throw exception instead of return max dop of 1 one IOException (from file system/hdfs),5
Extracted OS detection into separate class.Reworked hardware configuration factory.,5
Updated Readme.,5
Simplified Java quickstart skeleton.,5
Move TPCH3 IT case from TestBase to TestBase2,3
"Fix global/local schema stuff and workset iterationsThis fixes workset iterations, for nowRevert global schema generation stuff to original state but simplydon't use it.We used the globalPos to create WorksetIteration, these are notavailable before the post pass has run, therefore use the localPos fornow.Properly set key positions in join,cogroup, and reduce from thelocal positions.Also add maxIterations parameter to iterateWithWorkset",1
CsvFormat configurable via regular parameters.CsvFormat generic (independent of PactRecord)Additional parsers.Examples partially ported to configuration via parameters (rather than confog strings).,5
"New maven project ""stratosphere-addons"".It contains code maintained by the project. (Most of them have a lot of dependencies and are not required by most users)Move pact-array-datamodel to stratosphere-addonsMove pact-hbase to stratosphere-addons",1
Move hbase example to hbase-addon project,1
Moved array datamodel dependencies.,5
Change assigning of fields in CsvInputFormat to correctly omit,4
"Fix GlobalSchemaGeneratorDid not correctly generate for key-less reducers.Threw exception when a copy operator was needed, ignore this for now.",1
"Re-add combinable reduce in scala, consolidate implementations",5
Rename all the custom DataStreamS to DataSet,5
Extends Java csv input format to accept field indices,5
Add indices support in scala csv input format,1
Fix some log/debugging outputMake the scala schema printers use log4jFix the additional syserr appender in LocalExecutor: add a threshold sothat it does only output error messagesMake JobClient use log4j for the event output that was annoying me,2
Refactor Scala data input/output formats,5
fixed TableInputFormat returns no records when re-opened with a new split,1
Added static utility serialization and deserialization methods to PactString for custom data types.,5
Added unsplittable behavior to input formats via marker interface UnsplittableInput.,1
Proper open/close handling of combine stubs in combining sorter.Combine stubs are lazily initialized upon spilling.Adjusted combining sorter test cases.,3
Updated contributors.,5
Added cobertura Maven plugin for test coverage report generation,3
Added JDBC Input Formant and tests.,3
Fixed serialization warnings.Marked transient fields.Minor formattings.,2
Adjusted JDBC example to use internal derby DB for better debugging support.,1
Added DefaultInputSplitAssigner as default fallback for GenericInputSplit.,1
Fixed handling of unsplittable inputs and added sanity checks.,1
Removed redundant split generation in JDBC format after fixing unsplittabel input behavior.,0
FileInputFormat builder accepts GenericDataSources.,5
Extended UniformPactRecordGenerator to produce keys and values starting at an offset,1
Extended DataSinkTask to support union input and added corresponding test case and integration test.,3
Fix typo in serialization method name.,2
Add Pregelsphere,1
Executor services use daemon threads which prevents lingering threads at job end.,1
Make 'closed' status in hash join atomic to prevent multiple concurrent closing.,1
Added missing googleapi,1
Fix concurrent memory release in HashJoin cancel case.Minor formattings.,0
"Add ""stratosphere-yarn"" sub-projectbased on https://github.com/hortonworks/simple-yarn-appBuild debian package only with special profile for that (to speed up the build)Build uber-jar of stratosphere (for super-handy yarn deployment)Old commit messages (from rebase:)advanced configuration file handling (maven and jar magic)Command line arguments for client (not yet done)Change JobManager startup to allow external controlUse environment variables to pass variables to ApplicationMasterUse contstants for settingsFix CLI optionsminor refinemens (pact-hbase dependencies)Yarn runs with HDFSjar files and configs are now shared using hdfsmany many deployment bug fixesuberjar is automatically uploaded to dopa server",0
generate debian package for dopa; new configuration parameter for yarn client to create default yaml,1
move yarn to separate profile to disable it individuallyThis is a combination of 5 commits:extended submission clientminor yarn refinementssome minor fixesmoved print usage,4
Implement superstep abstraction on Nephele readers/writers.Cleanup Nephele readers/writers.,4
Relieve 1. travis worker by deploying only one version to sonatype,1
Rename Pregelsphere to Spargel,5
"Make all scala rich stubs have apply method instead of specific nameBefore, MapStub required the user to specify a map() method, now theyspecify an apply() method. This is more in line with how Function1[] andso one works and also the same across all operators.",1
Add deferred updates to workset iterations (issue #21) and fix chaining of iteration state updates (issue #123),0
Formatting and minor cleanups in iteration code.,4
remove discoveryManager,4
"Updated Nephele task names.- Names have prefix of Pact contract (Map, Red, Cmb, Mat, Crs, CGp, ...)- All chained tasks are added to name of chain parent",1
yarn now also starts the web interfaceextended pact-client to nicely support remote execution.,1
unified 'run' and 'remote' in pact-client,1
Fix issue of selecting wrong class loader in combiners.,0
fix minor build issue: deploy uber-jar only if yarn version is build,0
Allow empty paths in FileInputFormat to fix a problem with the job preview,0
Optimizer handles deferred solution set updates.,5
Clean hash join shutdown on cancel case.,4
Reduced test logging verbosity.,2
Fixed accidentally committed log level change in local executor.,4
Job Graph Generator and Optimizer logic for generalized iterations.,2
Adapted iteration tests to modified parameters.,2
Fixed all JavaDoc warnings in pact-common. Added and updated some documentation on the way.,2
Simple batch scripts to run stratosphere under windows,1
Extended task names,5
Merge branch 'taskNames' of https://github.com/fhueske/stratosphere into fabianConflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/WorksetIterationNode.java,5
Added integration test case for AllReducer and iterations,3
Adjusted DataDistribution for key[] based bucket boundaries.,5
Add ClosureCleanerThe cleaner removes non-serializale fields from scala user code.UserCodeObjectWrapper is changed to check whether all fields areserializable.,4
Implemented accumulators,5
Merge accumulators and minor cleanups.,4
Added stubs for reorganized projects.,1
Reorganized basic project structures. No renamings yet.,2
Fix ASM library version conflict.,5
Fix assembly to correctly package webserver docs.,2
Removed old dependencies.,4
Renamed packages in stratosphere-core.,5
Fix JobManager IPC class instantiation.,0
Fix clustermanager test.,3
"Renaming on projects -clients, -compiler, -examples.Minor cleanups.",4
Renamed scripts in stratosphere_home/bin,5
Added delta page rank example.,1
Correctly extract the workset flag from the configuration.,5
Minor cleanups related to delta pagerank example.,4
Renamed programs & plans.,5
Cleaned up test packages.,3
Remove non-javadoc comments,2
Added and unified Apache License headers in all files.,2
Adjust deb package to new names and scripts,1
Cleaned up sysouts and apache headers in shell scripts,5
Cleaned up configuration parameters.,2
Update README.md,2
Job remains Plan for easier migration.,2
Renamed functions and operators in the Scala API.Cleaned up some examples.,4
Fixed example jar assembly.,0
Rename former PactRecord and Pact* core types to Record and *Value,5
Cleaned up delta page rank example and added test case.,3
Change namespace for scala api.,4
Rename Sequential In/Out Formats to Serialized*Format,5
Name cleanups on core api.,4
Unify java and record project. Removed api suffix from projects.,0
Java pi and record api namespace unified.WorksetIteration changed to DeltaIteration.,4
fix hdfs for hadoop 2.2fix yarn copyrightadopted hadoop configuration for hadoop 2.2.0Add accumulators to web interfaceConflicts:stratosphere-core/src/main/java/eu/stratosphere/configuration/ConfigConstants.javaREADME.md,5
fixed stratosphere-client's classpath,0
"added debugging msgs to yarn, changed ajax requests to relative paths",4
Change version to release candidate 1 (rc1),5
Fix ScalaPostPassFixed doc warnings for MemorySegment,2
Removed PACT from log messages.,2
Remove obsolete broadcast job.,4
Remove all '@author' tags (apache style),4
prepare release to maven central:release profilefake javadocs for scala examplestravis: deploy only SNAPSHOT to sonatype,2
Fix warning in scala-examples pomUpdate NOTICE.txt,5
Replaced ozone by stratosphere in contributers file,2
Fixed name in contributors file,2
#339: JDBC tests do not create derby.log file,2
Merge pull request #358 from fhueske/updateContribsUpdate contribs,5
Merge pull request #357 from fhueske/avoidDerbyLog#339: JDBC tests do not create derby.log file,2
Remove term PACT from CLI messages,4
Config directory is read correctly in CLI client.,5
Update documentation reference in the README.md,2
CLI Client prints progress messages.,5
Fixed distributed filesystem instantiation.,5
Corrected error messages for PackagedProgram,0
Improvements on hdfs initialization error messages.,0
Update README.md,2
Excluded sources jar from the examples assembly.,5
Fixed Connected Components Scala Example.,0
Deactivated closure cleaner due to class loading problems.,0
#360: updated CLI client help text after renaming,5
Merge pull request #365 from fhueske/updateCliClientHelp#360: updated CLI client help text after renaming,5
Deploy snapshots and release binaries to amazon s3,5
Fixed typo in EventCollector to correctly remove failed jobs from recentJobs list,0
Merge pull request #375 from markus-h/webinterface_failed_jobs-prBugfix for webinterface: Failed jobs don't disappear,0
Changed version to 0.4,4
Changed version to 0.5-SNAPSHOT,4
Applied version changes to all pom files.,2
Renamed 'match' in functions to 'join'.,1
Fixed bug in web-client.,0
Rename FilterStub to FilterFunction,1
Clean up bytes to memory pages computations. Fix number overflow errors for very large memory sizes.,0
Clean up destriptions and log/web display names.,2
Polling for jobmanager webinterface,5
Created 'avro' addons subprojectAdded 'AvroInputFormat' with test.,3
"Avro complex types (array, map, enum) implemented",5
Undo eclipse formatting in avro ifdisable javadocs gen when java6 is being used.,1
Add shutdown method to LocalDistributedExecutor and remove failing CustomDataTypeTest=> the removed test functionality will be included in an upcoming test by @aljoscha,3
Fix bug in scala cogroup.flatMapDid fail with null pointer exception when one of the inputs is empty.,0
Set LocalExecutor logging to INFO; print runtime. reduce logging verbosity of IPC server,2
implemented jdbcoutputformat,5
"moved jdbc into new project, adjusted for 0.5Conflicts:stratosphere-addons/jdbc/pom.xmlstratosphere-addons/jdbc/src/main/java/eu/stratosphere/api/io/jdbc/JDBCInputFormat.javastratosphere-addons/jdbc/src/test/java/eu/stratosphere/api/io/jdbc/JDBCInputFormatTest.javaConflicts handled by @rmetzger",0
renamed jdbc package properly to the new 0.4 naming conventions,1
added batch interval to jdbc; fixed issue with jdbc test cases,3
Polling for jobmanager webinterface,5
Paths in windows scripts enclosed in double quotes,5
Merge branch 'webinterface_autoupdate_newrelease-pr' of https://github.com/markus-h/stratosphere into webfix,0
Fix bug that incorrectly marked iterative tasks.,0
Added standalone plan visualizer tool.,1
Add LineRank as test case.,3
Add Scala Page Rank examples,1
Fixed ExecutionGraphTest. Test output files are removed. Reduced log level to WARN.,2
Add constructors with degree of parallelism argument to Plan (issue #426),0
Improve error message when no match is found in solution set join (issue #429),0
Add check whether group is empty in scala reduce operatorThis fixes #434,0
Reenable ClosureCleaner and add new Test case for everythingClosure cleaner did not work before because the user code class loaderwas not used when it was trying to load inner anonymous classes.The new test checks whether the ClosureCleaner works together with theuser code class loader.It also used the local distributed executor and remote executor.,1
removeField method in Record class,4
Adding comments to removeField and uncommenting its test method,3
create basic project structure,1
Initial Raw test impelementation of Hadoop Input Formats capability,3
Code restructure,5
"Some refinements on the hadoop input formatThis is a combination of commits:* make hadoop-compat compatible to hadoop yarn and remove org.apache.hadoop code* Extended usercode wrapper, fixed IF serialization* introduce pluggable type converter* make the converter interface more generic; (hopefully) improved fetching logic",2
Added convenience constructor to RemoteExecutor,1
Reorganized .gitignore.,2
quick fix for build error,0
Added code for reflective avro types.,1
Introduced CREATE and OVERWRITE file output write modes. OVERWRITE is default (as before).Rewrote code for file output path preparation.Fixed distributed writing to local filesystem #286,5
Added test for write modes on local file system,5
Updated configuration keys to new naming,1
Added optional parameter to always write into directories even in case of DOP = 1.Extended FileOutputFormatTest.Some code beautifications.,3
Adapted KMeans example such that also points with assigned cluster IDs are written as result.Adapted KMeans TestCases.,3
extend and expose KMeansDataGenerator,5
Fixed broken build,0
User compiler hints take precedence over crossWithSmall or CrossWithLarge hints.,1
Add generated avro classes to simplify build and plugins.,1
Add upper bound for dynamic path cost weight to prevent cost overflow.,1
Set default locale to US in offending Scala Test CasesThis fixes #416,0
Fix avro serialization and add tests.,3
Correctly handle cases where iteration operators do not consume all input data.Allow cases where in-iteration DOP is lowered.,5
Fix erroneous test case for AllReduce in iterations.,3
Merge pull request #461 from StephanEwen/itersFixed several bugs related to AllReduce and Iterations.,0
stratosphere debian package fixes,0
deploy spargel with dist,5
MatchNode UnsupportedOperationException fix,0
Add WordCount example with anonymous classes (for discussion),1
Provide Iterable instead of Iterator to updateVertex method of Spargel API (issue #425),0
Remove non-sensical comment from SpargelConnectedComponents (issue #428),0
Add SpargelConnectedComponentsITCase to Spargel module,1
Extend ConnectedComponentsITCase instead of code duplication for SpargelConnectedComponentsITCase,2
provide MessageIterator instead of Iterable,1
Changed CsvOutputFormat constructor to support additional arguments,1
removed some empty lines,4
create parallel collections and add java value to stratosphere value interface,1
add Unit-test to check format and change some code styles,4
some minor cleanups,4
fix CsvOutputFormatTest (and re-introduced a flag for constructor-based instantiation,3
add classloader to thread-global variable; introduce compiletime-typesafety for Hadoop Wrapper Types,1
"rename hadoop-compatibility,more generics",5
Extended avro serialization test.,3
Clean up several scala examples,4
Fix bug in avro serialization for empty collections.Add additional test for avro.,3
fix minor bug that prevents the webinterface from working correctly with YARN,1
Added API for broadcast variables.,1
Added KMeans Java examples using the broadcast variables API.,1
Added support for extra inputs to RegularPactTask and TaskConfig.,5
Added integrated test case for broadcast variables.,3
Adjusted kmeans examples.,5
Merge broadcast variable runtime.Extend runtime for iterative algorithms.Add iterative kmeans test for runtime code.,1
Fix bug in bc variables.Adjusted test that now use bc var programs.Miscellaneous test cleanups.,4
Minor readme fix.System.exit() is no longer required after the LocalExecutor,1
Add serial version UIDs to newly serializable function classes,1
Added support for broadcast variables to the optimizer IR structures.,1
Integrated broadcast inputs into getAlternativePlans enumeration logic.,2
Added broadcast variables to the PostPass and JobGraph generator.,4
Added integration test for the KMeansSingleStepBroadcast Java example.,3
Added compiler test for kmeans single step.Various examples cleaned up.,4
Add compiler test for iteration with broadcast variable.First parts of handling BC variables in iterations in compiler.Miscellaneous test cleanups.,4
Support for BC Variables in Iterations.,1
Removed duplicate and broken test for BC variables,3
Added demo KMeans example.,1
Changed default stddev in kmeans sample data generator.,5
Fixed WordCountUnionReduceITCase to not break the hep with too large test strings.,3
fix invalid nightly stratosphere build for hadoop1,0
"[travis] Fix some ruby dependencies for travis, seehttps://github.com/travis-ci/travis-artifacts/issues/23",0
Replication properties are not pushed down.,5
[yarn] use unique appId in to store jar in hdfs,1
[dist] deploy yarn in a separate compressed file,2
[yarn] fixed yarn binary; implemented a simple but effective shutdown mechanism for the yarn-session,0
"[yarn] deploy new yarn.tgz with travis, fix file permission in binary",2
Log rotation for start-local.bat,2
add failed node list to web interface,0
Correctly handle transient variables during serializability check,0
Correctly marked text input format members as transient,5
Add avro input format for generic objects.Add end to end test for avro with external jar and external test data.,5
Removed redundant object cloning in usercode wrapper to fix class loading issue.,0
Fixed logging in avro tets case,2
Serialization tags in ScalaInputFormat,5
Handle serialization / lazy initialization of UDF types in scala input formats,5
Fix bug in CsvInputFormat resulting from changing UserCodeWrapperconfigure() is called twice on input formats because of statisticsgeneration. CsvInputFormat did not handle this gracefully.Also change TPCHQuery3WithUnionITCase to TestBase2.,3
Added example program test jar,3
Simplified and fixed estimate computation.,0
Fix estimate computation and add (enable) additional tests.,3
Minor renaming of compiler hint,5
Adjusted file URIs in some tests for Windows compatibility,3
Made TextInputFormatTest platform agnostic.,3
Moved single-step kmeans program from examples to test project. Single step program is subsumed by iterative program.,3
Moved end-to-ent test from 'test' phase to 'verify' phase.,3
Updated some comments and minor example cleanup.,4
"Operators use UDF class name as default name, when no other is specified.",1
Enabled plan visualization for broadcast variables (quick fix visualized broadcast inputs like regular inputs),0
fix examples in GitHub readme page to 0.5 version usage,0
Cleaned up global sorting test cases and fixed latent bug in testing logic.,2
Fixed execution graph state checking to accept canceling -> failing transitions,0
Add branching logic for broadcast variables.,2
Added KMeans with additional point tagging as test case for branching broadcast variables.,3
Csv leniently accepts bad lines also when skipping fields,5
File data source fails fast on null inputs.File paths used as default names.,1
CsvInputFormat can optionally skip an initial header line.,5
"Default mode for output formats is not to overwrite existing files.Globally configurable default modes for overwrite / output directory behavior.Configurable behavior for FileOutputFormat through regular parameters, rather than configuration.",5
OutputFormat unit test discard existing temp files by default.,2
Additional test case for broadcast variables in branching data flows.,5
"Added options to configure the default behavior of the LocalExecutor (ports, overwrite, hdfs config)",5
Cleaned up BroadcastBranchingITCase (added Apache header),1
Compiler deadlock detection,5
fix NullPointException in web interface when inspecting a job immediately after it finished,5
delay the display of job history with 8 sec instead of using a high network overhead method,1
Fixed file output configuration and logging for various test cases.,3
Added functionality to re-initialize file format defaults for use with local executor.,1
Issue #519 Add setValue methods to Value types,1
Termination Criterion for Bulk Iterations,5
Fix bug in data source cost accounting.,5
Cleanup of termination criterion for bulk iterations.,4
fix s3 deployment for stratosphere YARN version,0
"[yarn] Major YARN-Client improvements- HDFS security token support- ""ship/"" directory to transfer files to all TaskManagers (user-files)- Log4j-based logging (YARN now respects the logging configuration)- the YARN-client deletes all ""temp"" files from HDFS.- The JVMs started by YARN now respect the configured JVM opts in the yaml-file- the JobManager webinterface shows the log file (e.g it is aware of the YARN-specific log-directory)- The YARN-client now creates a hidden "".yarn-jobmanager"" with the address of the JobManager in YARN. users do not have to specify the -m argument anymore.- Fix a little bug with the JobManager's ""cloud"" model for taskManager with less that 1GB memory.- Tested on Cloudera Hadoop 5 Beta 2- Tested on Cloduera Hadoop 5 Beta 2 WITH CDH5-B2 Maven Dependencies.- Tested on Hadoop 2.2.0- Tested on Amazon EMR",3
"Fix the external packaged program test after merge with the new java apiRelax generic bound in tuple type infor to work around bug in Java 6 compiler type inference.Local file system is used by default when URI is missingRemoved final declaration from Tuple classes to allow inheritance (Fabian Hueske)Fix in TupleType comparator generation (Fabian Hueske)Cogroup Implementation (Markus Holzemer)Added missing Apache license header (Fabian Hueske)Initial commit for join operator for new Java API (Fabian Hueske)Added cross operator to new Java API (Fabian Hueske)First part of CoGroup (Markus Holzemer)Added join example prog and fix in join operator (Fabian Hueske)Unified operator translation (Fabian Hueske)Add Cross Prog for API implementation (Fabian Hueske)Implement CsvInputFormat for new Java API, including tests.Fix logging messages in data source and sink tasks.Fix error in data source task with new InputFormat siignaturesAdd group reduce to new java api.Finaliz Key Extractors for new Java APIFix bug in intitialization of broadcast serializers.Added first set of comparators.Added generic type serialization via avroAdd first stab at KeyExtractor implementation (Aljoscha Krettek)Add trivial parts of serialization (Aljoscha Krettek)Connected serializers to the typeutils.Fix tests to run with the NEW-API changes (Aljoscha Krettek)Scala Post pass got confused because of ReduceNode renaming. (Aljoscha Krettek)Some input format mishaps. (Aljoscha Krettek)First set of new simple type serializers.Connect first paths of new Java API to optimizer.Add name() to Operator plus some other stuff (Aljoscha Krettek)Clean up moved annotationsAdd CoGroup, Cross, and Union operators (Aljoscha Krettek)Make reduce operators children of UdfOperator (Aljoscha Krettek)Adjust input formats to new signatureAdjusted, extended, and tested parsers for new java api compatibility.First draft of new java api.Removing dependency to Combinable annotation. (Jesus Camacho Rodriguez)Moving all annotations to Java API. (Jesus Camacho Rodriguez)Moving all annotations from the core to the Java API package. Created SemanticProperties in the core to store properties inferred currently from Java annotations. (Jesus Camacho Rodriguez)Moving all annotations to Java API (Jesus Camacho Rodriguez)",4
Add RAT plugin in the MAVEN build. Also add licenses where-ever needed.,1
Fixes a bug when using Double types as sorting key,1
Fixes a NullPointerException in PlanUnwrappingReduceGroupOperator,1
included double quotes around scalars to handle paths with spaces,0
[yarn] set the same user for the services running in the YARN containers.Fix #584Fix #568,0
Adjustments for java8,5
Local environment has console logging deactivated by default.,2
LocalEnvironment used the number of processor cores as the default DOP.,1
Change MutableObjectIterator to allow immutable objectsThis makes it possible to remove the Reference<T> hack.,4
Remove Reference<T> hack (plus some other clean-up)Also remove Serializer<T> and only use TypeSerializer<T> which is nowSerializable.,1
Reset AsciiUtils to original behavior (do not implement MutableOjectIterator any more)Minor cleanups.,4
"Renamed AsciiUtils to SimpleStringUtils, because they actually work on more than ascii strings (all strings without surrogate chars)",1
Removed array datamodel and Scala Grabbag,5
Small step towards semi join. Added semi join functions.TODO: Special exec strategy (runtime + optimizer) based on hash join required.      Either no duplicates of filtering side in HT or filtered tuples removed from HT after first match.,4
"Updated TypeExtractor and TupleTpyeInfo to work on subclasses of Tuple1, Tuple2, ...",1
Merge Fix,0
includeFields support for new Java API's CsvReader,1
Removed ReferenceWrappingReducer. Cleaned imports in PlanOperators. Fixes in ReduceFunction.,1
Rework command line client and added support for new Java API interactive mode. - Mixing generic and specific options is supported - Help is action specific - No -a is necessary for program arguments - New Java API programs with main(String[]) method as entry point work - The 'Main-Class' manifest entry is also considered when looking for Program entry points (easier export).,1
Add getArity() method to Tuple,1
Fix TypeExtractor to work with plain Tuple and derived Tuple,1
Add CsvOutputFormat for new Java API,1
Minor consistency cleanups in CsvOutputFormat,4
Add convenience method to set local environments to overwrite files by default.,2
Clean up LICENSE and NOTICE files,2
Updated NOTICE file,2
"Fixed compiler so that it reuses already generated OptimizerNodes within the recursive descent step of the GraphCreatingVisitor by passing down the current con2node state. This implies that one has to consider the root of the step function for computing the unclosed branch stack and for merging the branch plan maps. The method hasDamOnPathDownTo had also been adjusted for the step function, otherwise the ""Tracing dams for deadlock detection is broken"" compiler exception is thrown.",1
Added test case for bulk iteration with static input and delta iteration with static input,3
TextOutputFormat adds newline.,1
Added test base for new java api programs,1
Added test for WordCount in new Java API.,1
Implementation of the remaining BasicTypes for new Java API,1
Fix dependencies for java test base,3
Added first set of built-in aggregation functions for the new Java API.,1
Remove duplicate InvalidProgramException,4
Implement aggregation operator,1
Changed examples to use aggregators.,1
Change some generic signatures to work around Java 6 generic type inference,5
Fix erroneous test job.,3
Add ignoreFirstLine to CsvReader (new Java API),1
Add Bulk Iterations for new Java API,1
Fix client and webclient for interactive mode of new java api.,1
Remove resources from swt visualization,4
Added small test for packaged program,3
Initial support for Group Sorting (only key positions and Reduce operators).,1
Fixes in TupleComparator and BasicTypeComparator,0
Removed unneeded code from example,4
Triangle enumeration examples,5
Added integration tests for TriangleEnumeration examples on new Java API,1
Fix stratosphere pom.The compiler plugin was configured under the wrong section. It used tobe a child of reporting but is now a child of build. Changing the sourceand target properties in the old pom were without any effect.,1
"Changes in the TupleGenerator:    - For Tuple Fields:        - start with index 0        - are public (no getters and setters anymore)        - can be accessed via f0,f1, etc. instead of a method T1(), T2(), etc.        - setFields() allows for setting all fields at once    - For CsvReader, ProjectOperator, TupleTypeInfo:        - TupleGenerator generates code for classes which depend on the tuple arity.        - A special String indicates where to put Tuple dependent code",5
Added integration test for Filter operator.,1
Made internal methods protected to clean up user API,1
Added ReduceITCase for Java API reduce operator,1
Adjust names and messages for file write modes (NO_OVERWRITE and OVERWRITE),2
"Fixed NullPointerException in BulkIterationNode.mergeLists, fixed faulty chaining of root of termination criterion and root of step function, added static dynamic path detection for the termination criterion, fixed bug where the BulkIterationNode tries to generate alternative plans for the termination criterion even though there aren't any left for the step function",1
Extended scala api by introducing termination criterion,5
Added scala example for termination criterion,1
Added license header to example file,2
"Fix issue #505 removing trailing \r from lines in Windows text filesWindow uses \r\n to split lines. so, for text files from Windows, when\n is used as delimiter, \r is still appear at the end of lines.The code checks to see if \n is used as delimiter and end of a line is\r, then \r is removed from the line",4
Add TypeConfigurable interface for output formats.Minor cleanups.,4
Input formats can tell their types to the java data set (no need for double manual configuration)Collections on tuples need no manual type informationAdditional sanity checks,5
Renamed type configurable/queryable interfaces to more intuitive names,5
Avro input format provides type for the produced data set.Additional fail fast checks for new java api.,1
Adjusted Avro Input Format for new Java API.Adjusted test case for externally packaged avro program.,3
added util tests,3
included examples source code into assembly,5
Integrated Bootstrap in the User Interface and made some improvements and code clean ups.,4
Added kmeans as an example for the new java api.,1
HadoopDataSink works both for hadoop 1.2.1 and 2.2.0,1
add license headers,1
add ContextCheck to LocalExecutor; check in HadoopDataSink for output path,5
automatically generate a javadocs page,2
ported CompactingHashTable + unit tests to current master,3
Add project operator to Java API,1
Added tests for project operator,1
Extended Projection.types() functions up to 22 type parameters.,2
Moved parameter checks from DataSet to Projection. Handing object instance instead of serializer to MapProjector.,5
CsvOutputFormat checks that only tuple types are used.Add comments to CsvOutputFormat.,1
Added JavaDocs for transformation methods in DataSet. Commented out not supported transformation methods.,1
First version of Spargel for the new Java API.Equality/hashing for some type infos.Comments on iteration runtime context.,1
Renamed spargel iteration classes (more intuitive names) and added all java docs.,2
Made edge iterators iterable.,5
Added page rank example to spargel,1
First part of integrating delta iterations with new java api's optimizer post pass.,4
Delta Iterations for new Java API; SimpleDeltaPageRank + testcase,3
Fixed bug in splitting logic of number sequence iterator.,2
Fixed erroneous propagation of messages for Spargel.,0
SpargelConnectedComponentsITCase properly verifies results.,5
"Changed members of Costs to double, cumulative cost is now the node cost plus the costs of the children divided by their out degree",4
Refactor and Add Comments to Broadcast Variable Example,1
fix sonatype deploy,0
Add LocalCollectionOutputFormat for local executor,1
JDBC InputFormat and OutputFormat for new Java API,1
"Created TupleBuilder for every Tuple, via TupleGenerator",1
integrated CompactingHashTable in iterations code,2
Added JavaDocs for DataSet and Grouping,5
cleanup + documentation,2
Allow .yml file extension for config files (fixes #645),0
Make delta iterations use Keys.FieldPositionKeys,1
Speed up execution by having an early heartbeat,5
Add support for serializing null strings.Fix bug in binary copying of long strings.,0
Add tests for string serialization.,3
Add base utility for serializer tests.Add string array serializer with test.,3
intermediate (new hashtable and broken joinwithsolutionset*driver),1
cogroup fixed,0
match fixed but ConnectedComponentsWithDeferredUpdateITCase still fails,0
"Added Grouping unit test, extended Reduce integration test, added JavaDocs to ReduceFunction",1
Preliminary support for String arrays in new Java API,1
Improve error messages for instantiation errors on arrays and for programs without data sinks.,5
Add write mode to data set write function.,1
map operator test,3
flatMap operator test,3
Testcases for the CoGroup operator in the new Java API,1
Change return type of the CoGroup combine functions to a single value.Add default empty method stub for combiners in CoGroup functions.Add semantic property fields to single- and two-input udf operators.Lots of comments.,1
"Union implementation for new java api, with simple UnionIT testcase",3
Rewrite TypeExtractor to support more types and complex type structures. Possible Exceptions are now more user-friendly.,1
Fix of JVM 6 related bug and enhancement of 2 other corner cases.,0
Adjusted TypeExtractorTest for updates CoGroup combiner signatures.,5
Added comments and checks to the StringUtils,1
Added comments to the Tuple classes.,1
"Add specialized type serializer for long[], including test.Minor cleanups in Java API tests.",3
Minor cleanups in type extractor for new Java API.,1
ConnectedComponentsWithDeferredUpdateITCase green,5
added test case with multiple probers,3
Java 6 compliance,5
Simplified Java API by removing unnecessary project methods,4
Removed group sorting for pair-wise Reduce function,1
added license headers,1
Added aggregators and convergence criterion to new Java API.Better generics support for AggregatorsLots of comments.,1
Added convenience convergence criterion classes.,1
Added comments to parsers and improved error handling.,0
Added static parse methods to parse utility classes.,1
Added Java 8 to README.md,2
Moved SerializerTestBase to s-core and resolved Maven dependencies,0
GroupReduce testcases for the new java api,1
Minor improvements on GroupReduceITCase (tests for group sorting),3
Testcases for cross operator in new java API,1
Minor improvements of CrossITCase + some clean-up,4
Mixed key types for cogroup,5
"Fixed mixed keys for CoGroup, adapted test cases, code clean up",4
Implements the ascending flag for basic type comparators.,5
Fix instantiation of remote executor.,0
Minor example cleanups.,4
Add/rework utility iterators.,1
"Minor cleanup in local collection output format, csv reader, program description.",4
Removed redundant WordCount examples.,4
Fix various serialization warnings.,2
Add new java api based delta iteration example.Reorganize ConectedComponents example based tests.,3
Updated jar for end-to-end testing of packaged programs.,3
Cleanup among HashTable tests.,3
Added unit and integration tests for join,3
Testcase for filter with broadcast variable,3
Add test for StringSerializer for #589,3
Mixed key types for join,5
Minor error checks and message cleanups,4
Old Java Api now also uses the binary Union Operator and cleaned the common.api/optimizer level from input operator lists. Also added PropertyPropagationTest for new java api union,1
Comments and cleanup for (delta) iterations.,4
Clean up common api operators and marked var arg inputs as implicit unions as deprecated.Record API builder pattern suppoerts the model still. The common api uses an explicit union model.,1
Post merge cleanup of Union operator.,1
Unify delta iteration methods on DataSet.,5
Fix documentation errors.,0
Add support for multiple joins with the solution set.,1
Add test to verify that distinct probers are used in the case of performing multiple concurrent hash joins with teh same hash table.,1
Various minor fixes:- better exceptions for faulty temporary directories- better exception if client can not connect to JobManager,1
Add distributed cache to stratosphere,1
change codestyles and clean up,4
add test for delete process of tmp file and tested in cluster,3
Cleanup and simplification in the taskmanager and the local instances and mini cluster.,5
"Fixed log levels, code cleanups and restore the thread interruption states for JobManager and TaskManager",4
Fixed heartbeat thread and startup/shutdown races in TaskManager,0
Fix concurrency bugs in cluster manager and cluster manager tests.Simplifications of instance loading at startup.,3
Clean up comments and fix doc errors,0
Adjust iteration low level tests for reduced memory footprint,3
Improve error logging on RPC server.,2
Adjust tests LocalDistributedExecutor for low memory settings on build servers.,1
Post-merge fixes.,0
connected components test case with 2 joins with the solution set,1
Migrated tests to TestBase2 (for stabilty),3
"Added Int, Short, Float, Double, and Long Serializer Tests",3
"(Re)add TransitiveClosureNaive, fix join, add ITCaseScala Join took left key selector for both sides of join. Re-enableunion. TransitiveClosureNaive uses union, this is tested in the ITCase.Properly disable GlobalSchemaGenerator, the information it created hasnot been used, only local field positions have been used.",1
Add tupleType() method to CsvReader that allows to read directly into subclasses of Tuple,1
Fix CSV reader tests and added comments to CSV reader.,1
Display Exceptions in the JobManager webinterface,5
Removed faulty constructor,4
Remove obsolete Broadcast Variable Join example.,4
Simplified translation of new Java API,1
added support for setting the DOP of individual operators,1
Minor deprecation cleanup and comments.,4
Add semantic properties to spargel plan.,1
fix issues #736 and #733,0
Suggested fix for #739,0
Allow both comma and double-colon as path separator (for MR compat.); better error messages; delete address file,2
"Adds join projection, comments for join classes, removes unsupported methods for join.",1
Added unit test for join projection,3
Extended Join integration test for join projection,3
All sink methods in DataSet return the DataSink object to allow setting parameters.,2
Improved error message in PackagedProgram for preview plans.Fixed pre-packaged end-to-end test.,3
Add projection cross,1
Minor fixes in JavaDocs and parameter checks,2
Unit tests to check for valid parameters of cogroup,2
Activated unit test for CoGroupOperator,1
Default cross operator,1
Combinable GroupReduce for new Java API,1
Changed key handling for key-selector combiners,4
"Added Boolean, Byte, Char Serializer Tests",3
Implements a parse() method to parse TypeInformation in string representation.,5
Parser can now be tested with a JUnit test and supports Tuple arrays. Some minor bug fixes are also included.,0
Adapted test class for maven,3
Add annotation support for new java api,1
Removed obsolete array record utilities,4
Introduced notion of immutable types and stateful/stateless serializers.,2
Switched runtime task code from TypeSerializer to TypeSerializerFactory to support non thread-safe type serializers.,1
Add dedicated factories for stateful and stateless serializers.,1
Fix serializer equality checks and add tests.,3
add checkstyle to project,1
refactored given checkstyle.xml,5
minor cleanups for checkstyle,4
Fix maven problems with checkstyle in eclipse[ci skip],0
use Kryo for object copy in AvroSerializer.Enable more tests in CrossITCase and JoinITCase for JAPI,5
Lazy initialization of the kryo and avro serializers.,5
Add default entry (commeted) for program JVM options,1
Add object copying code to AvroSerializer,1
Add KryoSerializer and simple test,3
Adjusted generic serializer tests,3
Add modifications to hadoop compatibility package as required for parquet testing.,3
Move testing utils and data to package stratosphere-test-utilsWhen trying to use packages that use stratosphere-tests instratosphere-examples you used to get a circular dependency. Nowpackages can use the testing utilities without pulling in all thetransitive dependencies of stratosphere-tests.,3
Remove bin/ directory from tests and test-utils,3
"Remove old TestBase, rename TestBase2 -> RecordAPITestBase",3
Remove deprecated testing stuff,3
Increase visibility of temp file handling in test utils.,3
Removed unnecessary and unstable shutdown hooks for JobManager and TaskManager,1
Fix checkstyle in the test data,5
Changed Key to Key<T>,4
Adapt scala code to change in Key -> Key<T>,4
Clean up Key generics and checkstyle errors.Fix various warnings.,2
Improved TPC-H 10 example.,1
Example is now runnable without any parameters by default.,2
"The maven pom.xml file has been adapted to build a separate jar file coontaining the TPC-H query. The jar also contains the testdata, so that it can be executed without any further parameters.",2
Removed TPC-H test data due to unclear license state,5
TPCH Q10 example cleanup,4
Removed obsolete and broken RelQuery example,4
Add WebLogAnalysis example,2
Add TPCH Query 3 example,1
Renaming and minor cleanup of TPCH Q3 example,4
"Termination Criterion and PageRank for the new Java APIOptimization of SimplePagerank, setting of a correct serializer for the termination criterion, empty implementation of combiners for cogroup",1
Add utility result verification method for K/V pairs with double value and delta threshold.,1
Allow bulk iteration termination criterion with different data type than partial solution,5
Cleaned up page rank example and adjusted tests,3
getAggregators() for SpargleIteration,1
Tests for aggregate operator,1
Cache: exists() called / rel. path support,1
Fix aggregation testsFix error message for unsupported averaging data type,5
Generalised the name of the expected InputSplit class in HadoopDataSource.,5
"Add avro to stratosphere-dist, thus adding it to the lib/ folder",1
Better estimations for filter operator,1
Corrected minor errors in the optimizer filter operator.,1
"Add getSolutionSet() and .getWorkset() for delta iterationsBefore, the result of dataset.iterateDelta() would be the workset andthe solution set could be obtained via iteration.getSolutionSet().This is confusing since you are not told what the result of.iterateDelta() is supposed to be. Now, when using the result anexception is thrown during pre-flight that advises the user to usethe two methods to get the correct dataset (work, solution).",1
"Rename DeltaIterativeDataSet -> DeltaIteration, is no DataSet anymoreNow a user cannot mistakenly use it as a data set but is forced to usethe .getSolutionSet() and .getWorkset() methods.",1
added ExEnv.registerCachedFile(),2
StringComparators uses static StringValue.readString(),1
Fix generic compiler problem with Java 6,0
Test case for showing the still existing BulkIteration bug.,0
Added comments to iterative data set.,1
Cleaned up and  adjusted BulkIterationWithAllReducerITCase,4
Fix bug where a non-iterative data set is not fully consumed.,1
more detailed error messages for CompactingHashTable,0
Comparators for Value types,5
Straightened out ValueSerializer and ValueComparator,5
Remove obsolete ReflectKeyExtractorGenerator,4
Adjust ValueTypeInfo Generics for Java 6 compatibility.,5
Extension of the TypeExtractor to validate input type information and recognizing input mismatches.,5
More generated Tuples up to 25.,5
Introduced a checkstyle exception to also support TupleGeneration of more than 25 Tuples.,1
"Support for reading from "".deflate"" filesImplement clear distinction between unsplittable and serial inputsMade Avro input formats unsplittable",2
Boolean compare ordering switched,5
Added support for local distributed execution environments.Conflicts:stratosphere-tests/src/main/java/eu/stratosphere/test/util/AbstractTestBase.java,5
Fixed free memory calculation bug in case where multiple task manager run on the same jvm.,1
Removed local distributed executor environment from user api. Now only used for testing,3
Added setter and getter for numTaskManager in NepheleMiniCluster. Updated WordCountITCase and PackagedProgramEndToEndITCase accordingly.,5
WordCount examples are documented with many comments in order to be very user-friendly.,1
divided reduce and group-reduce,5
Add a dedicated reduce operator to be used with key extractors,4
Add comments to initial solution and -workset of delta iteration,1
"Execution environment data source methods return a DataSource, to allow the setting of parameters.",2
Add equals and hashCode to type information.,5
Add test for reduce operator translation,1
Add test for runtime reduce drivers and fist set of fixes for stable mutable object behavior.,0
"Remove unsafe getFieldFast() method from Tuple, because it turned out to be not faster than the switch-based getField() method.",1
Fix GroupReduceDriver test.,3
Fix ReduceDriver for mutable objects and arbitrary return types.,0
Fix and test reduce and Group Reduce translation for new Java API,1
Move PageRankITCase to proper package,4
Fix null pointer in ValueComparator,0
Add ReduceCombineDriver.Rename CombineDriver to GroupReduceCombineDriver,1
Minor cleanup and fix warnings,2
Reduce combiner deactivated when reduce uses a broadcast variable.,1
Update external Avro Test Program for updated data set signatures.,1
Small fix to get test to run under windows,1
additional csv input format test,3
Fix bug for tuple size greater than 22,0
add test for deflate input,3
Test for exclusion of ignored files (with underscore prefix),0
Print stratosphere version also in YARN-mode in the JM log filedisable the MatchJoinCancelingITCase test to speed up travis builds,3
Add javadocs documentation to user-facing classes.,1
Add Writable interface to allow seamless support for Hadoop types,1
Reduce minimum memory threshold for sorter,5
Added direct array serializers for all primitives,1
Fix deep copy code in GenericArraySerializer,0
TupleComparator fixeduses values of passed keyscan skip parts of the tuple if necessary,4
Add test for generic array serializer,3
Avoid unnecessary exception wrapping in PackagedProgram invokation.,5
Add TupleSerializer tests.,3
Improve TupleComparators.Add a compare method to teh comparators that works directly on objects.,1
Fix bug in tuple comparator (state)Rename UnilateralSortmerger -> ExternalSorter (part 1)Fix checkstyle warning.,2
"Add utility test to check string and tuple sorting (not active by default, time consuming and Linux OS dependent)",3
Fix checkstyle warning for Writable,2
Adjusted TupleTypeInfo for updated comparator,5
Tests for tuple and base type comparators,3
Add serializer for primitive char array,1
Primitive type arrays have dedicated serializers now.,5
Adjusted TupleComparatorTests,3
Fix javadocs in CsvReader,2
Deactivated outdated canceling tests,3
Fix hashing incompatibility between TupleLeadingFieldComparator and TupleComparator,0
Fix instantiation of tuple comparators.,0
Disable LocalExecutor when using Client,1
Set the disableLocalExecution() in ExecutionEnvironment to protected,1
Add comments to execution environments,1
Adjusted JVM garbage collection options to enable class unloading.,0
Disable also local environment in client submission settings.,1
TuplePairComparatorTests,3
Add tests for TupleLeadingFieldComparator,3
Fix for branching merging logic in BulkIterationPlanNode,2
Moved record API example jobs to stratosphere-tests,3
Remove some of the redundant Record examples  - some KMeans Variants  - some WordCount variants,4
"Add javaDoc comments to ExecutionEnvironment (final), DataSet (parts), InputTypeConfigurable, and ResultTypeQueryable.",5
Expose WriteMode in JAPI. #781Pass Configuration parameters to runtime operators in JAPI (+test),3
Refactored and unifid Java API example jobs,4
Updated JAR packaging of Java example programs,5
small corrections in refactored examples,4
"ValueComparator uses ascending flag, tests",3
Add GenericTypeComparator,1
Created new SortedGrouping to move the group order from the Grouping,4
Minor changes for SortedGrouping,4
Updated JavaDocs of ReduceFunction,1
Minor improvements in comparator tests,3
Introduction of a Writable type and tests,3
Improved exception message in WritableTypeInfo.,5
Fix combiner for group reduce.,0
implemented infrastructure for string style annotations,5
added semanticpropertyutilities,5
implemented parsing of the strings in SemanticPropUtil,5
"implemented semanticPropUtils class, added compatibility to operators",1
"Added Support for Wildcards. The following is now possible ""*"" for all fields constant and ""1->*"" when the first field is forwarded to all output fields.",1
Filter UDFs always considers all fields as constants,5
Fix group reduce compilation test,3
Removed combine methods from CoGroup function and some minor improvements.,1
Improved Java examples,1
"Completed, updated, and improved JavaDocs of Java API",2
Added UnsortedGrouping to separate Grouping methods from SortedGrouping methods,1
various fixes,0
"Substract only 15% from TM heap for yarn, capped at 500MB",5
Fix NullPointer exceptions in SemanticPropsUtil,0
Improved error messages and exceptions on non-serializable objects.,0
Add workset iteration translation tests.Add check that solution set is joined with on correct keys.,1
Improved comments in Java example jobs,1
Fix binary distribution: add LICENSE and NOTICEsource should now build without the presence of a .git directoryincluded the quickstart-archetypes into the main project.,1
Added links to programming guide / examplesremove reading from files from WC,2
Refactor type string parser into own class TypeInfoParser,5
Move TypeInformation to stratosphere-core,5
"Introduce TypeInformation at lowest Operator levelOperator now has an OperatorInformation that holds TypeInformationS foroutput types (and input types for unary and binary operators).This touches a LOT of stuff but will allow the removal of the separateJavaAPI plan operators and other redundant code.There is a new RecordTypeInfo that operators create behind the scenes.The *Source and *Sink operators are now Record specific as to not breakexisting programs. There are agnostic base classes with the *Basesuffix. Same is true for the iteration operators. Those operators andsources/sinks are now in stratosphere-java, only the agnostic ones arein stratosphere-core.This was done by Stephan, I squashed it into one commit to make iteasier to see the changes in one place:Clean up merge with ""type information on common operators"" branch  - re-added semantic annotations (API specific)  - Correct mixup in imports  - Improve generic typesafety  - Fix a lot of warnings  - Add docs / fix doc errors  - Improve iterator usage in unwrapping cogroup",1
Fix scala warnings,2
Add comments to function classes.,1
Made Scala and Java examples more consistent,5
Added Java equivalent of Scala RelationalQuery example program,1
Rework CLI client  - Add degree of parallelism option (run and info)  - Simplify options (-j and -a not needed any more)  - Fix corner cases with YARN  - Many tests,3
Remove wait flag from CLI client. Wait is now the default.,4
added improved syntax for annotations. Lists now possible within one String,1
Add additional test for semantic properties and translation. Fix some bugs.,0
Fixes an issue with wrong ClassLoader when submitting JobJars.,0
Improve error handling for Job Submission.,0
Removed System.exit() from Java example programs,5
removed System.exit() calls in Scala example programs,5
Consolidated and exteded Cli frontend  - all actions evaluate the target JobManager option  - all actions evaluate YARN files pointing to the job manager  - tests cover more cases,3
Getting OptimizedPlans from the Client evaluates the parallelism defined on the environment.,1
Make aggregations combinable and remove AVG aggregation,4
Fix hash partitioning for new java api,1
Fixed RecordOutputEmitter and extended OutputEmitterTest for hash corner cases,3
fixes toString return value of min aggregation,0
Merge pull request #874 from vasia/fix_min_aggr_tostringFixes toString return value of MinAggregationFunction,1
Improved error handling when fetching optimized plan of programs.,0
Improve ConnectedComponentsExample with constantfields annotation,1
Aggregate Operator sets its semantic properties.,1
added murmurHash implementation,1
Minor cleanups for hash partitioner,4
Fixes an issue when generating a type erasure exception in TypeExtractor.,4
Set version to 0.6-SNAPSHOT,1
Make sure progress bar label is visible by making the minimum width to 20%.Fixes #853.,0
Improve exception for nonexistent local files,2
Simplified exception stack traces when file is not found.,2
"Exception added to open() and fixed \r\nThe DelimitedInputFormat.open() method did not check if it has parsersregistered. Added throwing an exception when no parser is registeredwhen calling open. CsvInputFormat does now accept windows line endingswith standards settings. The |\r\n"" will be replaced by ""\n_""( _ is aspace)... To prevent from errors the returned length is set to thespace. So that this byte is known as parsed and will not get interpretedanymore.",1
Functions can now implement ResultTypeQueryable to supply TypeInformation manually.,5
Extend Delta iteration parametersRework SpargelAdd Broadcast variabel support to spargelAdd translation tests for delta iterationsAdd translation tests for spargel,3
Add spargel compiler test.,3
Fix restrictions with branches in broadcast variables and iteration closures,0
Fix potential bug due to unnecessary cast from long to int in FSDataInputStreamWrapper,5
Implement toString of CsvOutputFormat,5
"Rework stratosphere-clients tests to not expect a binary blob in the test resources (build the jar file using maven)add a test for ensuring the presense of a custom classloader in the CliFrontendAdd missing ClassLoader for the ""info"" command in the CliFrontend",5
Remove setUserCodeClassLoader() from PackagedProgram and use partial mock in respective test case,3
Fixes bugs where the TypeExtractor throws an NPE instead of the operators,1
Fix maven enforcer plugin warnings in Eclipse,2
Fix dependency exclusion for examples in yarn-uberjar,0
"Offer buffer-oriented API for I/O (#25)https://github.com/stratosphere/stratosphere/issues/25The runtime offered a record-oriented API for data transfers, which* resulted in unnecessary data (de)serialization,* complicated the upcoming fault tolerance implementation, and* blocked more efficient implementations of higher-level operators.With this commit, the runtime offers a buffer-oriented API for theoutput side (sending), which is oblivious to records. The bufferoriented input side (receiving) is still to be implemented.",1
Replace custom Java NIO TCP/IP code with Netty 4 library,5
Add debug log messages to Netty stack,2
Check number of designated buffers before returning buffer to BufferAvailabilityListener,5
Rename BufferAvailabilityRegistration constants and add initial LocalBufferPoolTest,3
Remove @Test from NettyConnectionManagerTest and run tests via main method,3
Merge cleanups,4
Fix for FLINK-708 (Hadoop 2.4 compatibility) and FLINK-887 (YARN Jobmanager heapspace calc),2
"Add to distributed cache executable flag, directory support",1
"Distributed Cache general purpose copy method, thread safety",5
Enable additional spargel compiler test,3
added own instantiate method to CoGroupDescriptorWithSolutionSetFirst; added Test,3
FS.get(): Add URI causing exception to message.,1
Allow multiple successive programs on the same execution environment.,1
Renamed Network Speed test to exclude the long benachmark from regular test cycles,3
quick and dirty fix for FLINK-927 and added more diagnostics information,5
Fix DelegatingConfiguration + Test,3
Fix generic warning in Plan,2
Fixes a bug in the Java 6 JVM where primitive arrays have a wrong type.,0
[FLINK-898] Clean up distribution default config,5
Pipeline breakers are placed correctly direct after iterations if needed.,4
Fix number formatting in JSON plans,5
Add LinearRegression example (Java API),1
Minor fixes for LinearRegression example,0
[FLINK-917] Rename netty IO thread count parameters,2
[FLINK-934] Remove default values for JobManager and TaskManager JVM heap sizes in startup scripts,4
Implement AvroOutputFormat,5
Add method to pass a schema for AvroOutputFormat,4
Aggregators and convergence criteria as objects instead of classes,2
[YARN] Improved the check for resource availability within the cluster,1
Minor fix for displayed estimates.,0
[FLINK-935] Fix compiler logic that pushed work out of the iteration loop.,1
Made FieldSet and FieldList immutable collections to prevent bugs to to side effect mutations,0
Made LocalProperties Immutable (avoid side effect mutation bugs)Change several Iterators to Iterables in the compiler (simpler code),4
[FLINK-935] (continued) Correct feedback property check for iterative algorithms.,5
[FLINK-942] Fix bug in config.sh to correctly set user-specified JVM argsThis closes #22,1
[FLINK-930] Netty Initialization is sometimes very slowThis closes #19,5
Artificial commit to close pull requests.This closes #5This closes #6This closes #10This closes #12This closes #14,5
Do not limit the client's heap space (See FLINK-934)[ci skip]This closes #18,2
Added Zihong Cao to CONTRIBUTORS list[ci skip]This closes #21,1
Added configuration subsection in webinterfaceCloses #16 (GitHub pull request)Also closes FLINK-919,2
New WebclientThis closes #15and FLINK-711,2
Fixed error messages in web client,0
extended plan-dump test for KMeans,3
Fixed JSON Bug for some plans.Signed-off-by: Robert Metzger <metzgerr@web.de>This closes #23.,0
"Add log info message with memory usage after TaskManager startup finished.This commit also introduces a logging thread, which repeatedly logs thememory usage. It can be configured via:    - 'taskmanager.debug.memory.startLogThread' (default: false)    - 'taskmanager.debug.memory.logIntervalMs' (default: 5000)",2
Remove Parameterized test runner annotation from NettyConnectionManagerTest,3
[FLINK-940] Added additional test for cogroup with delta iteration solution set on second input.,1
"[FLINk-941] Place pipeline breakers for SingleInput nodes with broadcast variables, if needed.",4
[FLINK-950] Fix spurious file deletion failures.,0
Projection constructor adjusts to max tuple sizeThis closes #27,5
[FLINK-943] Remove leading and ending double quotes from 'env.java.opts' config value in startup scriptsThis closes #26,5
Transitive closure example in Java APIThis closes #24,5
[FLINK-944] CollectionInputFormat now uses the TypeSerializer to serialize the collection entries. This allows to use objects not implementing the Serializable interface as collection elements.This closes #25,1
[FLINK-944] Consolidated serialization logic between different classes. Fixes for warnings.,2
Re-encrypt the credentials for various services with the new apache/incubator-flink travis keys,2
"Syntactic sugar for sum, min, and max aggregationsThis closes #7",5
[FLINK-957] Throw meaningful warnings and exceptions upon incorrect use of delta iterations.,1
Added Version and Revision of Stratosphere in Webinterfacehttps://issues.apache.org/jira/browse/FLINK-946![bildschirmfoto 2014-06-20 um 14 43 26](https://cloud.githubusercontent.com/assets/5738978/3340103/82d0485e-f878-11e3-9d15-617102ea40a3.png)Author: Jonathan <Jonathan@Hasenburg.de>Closes #30 from JonathanH5/wi_version and squashes the following commits:f29180a [Jonathan] Added Version and Revision of Stratosphere in Webinterface,1
The Hadoop Compatibility has been refactored and extended to support the new Java API.,1
Hadoop Compat pull request clean-upThis closes #32.,4
Fixes a bug where Thread.currentThread().getContextClassLoader() does not return the user code class loader within object deserialization.,1
"Rework the Taskmanager to a slot based model and remove legacy cloud codeSquashed commit of the following:  - Post merge cleanup  - Renamed fractionMemory into memoryFraction.  - Removed Local and QueueScheduler and replaced it instead with an unified DefaultScheduler.  - Removed Local and ClusterManager and inserted instead an unified DefaultInstanceManager.  - Removed connection IDs from execution edges  - Removed InstanceType, InstanceRequestMap, InstanceTypeDescription, InstanceTypeDescriptionTypeFactory, PendingRequestsMap  - Fixed problems with test cases.  - introduced simple slot system for scheduling.  - Removed subtasks per instance  - Added registerTaskManager to the JobManager RPC calls. RegisterTaskManager is called only once where the hardware description information is sent.Add: Merging cloudmodel remove with new network stack",1
Removed RuntimeEnvironment instantiation from execution graph construction. Removed legacy job vertex classes and input/output tasks.,4
Added failing behavior to JobManager if it is still in scheduled or created stateNew test case: Exception during ExecutionGraph construction in the JobManagerRemoved checkConfiguration method from AbstractJobVertex because it is not needed anymore,1
"Replaced Tarjan's algorithm with a simpler depth-first traversal cycle detection algorithm. By doing so, one gets rid off a possible linear time check whether a node is contained in the stack.",1
Streamlined job graph algorithms to get rid off linear contains operations.,1
Standardized creation of input and output channels in InputGate and OutputGate. Removed linear contains check in InputGate for channels.,4
Merge fix to omit input/output registering on JobManagerRework Invokable Task Hierarchy,1
Add some options for slot-based scheduling and changed default parallelism to one.,4
[FLINK-962] Initial import of documentation from website into source code (closes #34),2
Show version information including commit date in TaskMgr log,2
Add garbage collector stats to output of TaskManager memory usage debug thread,0
Revert unintentional change in 1357ea3a40f747e4e51b5b52612323fe55747da7,4
[FLINK-979] Fix NetworkThroughput test input and output task config- Set DummyInputFormat and DummyOutputFormat via TaskConfig to respect task  hierarchy refactoring.- Run test via main method instead of JUnit test runner (this was originally  a test in order to use RecordAPITestBase for JobGraph submission).This closes #41.,3
[FLINK-980] Fix buffer leak in OutputChannel,0
Changed default number of task slots per machine to one.Add logging for task slots.,2
LocalExecutor automatically picks up the maximum DOP for plans as its number of slots.,5
"[FLINK-973] [FLINK-969] Unify, clean up, and extend all environment logging at JobManager/TaskManager startupThis closes #40.",2
"[FLINK-926] Add shallow copy, deep equality, and hashCode to Tuple classesThis closes #17.",1
[FLINK-949] Properly report GlobalBufferPool OutOfMemoryError to TaskManagerThis closes #28.,0
[FLINK-960] Fix CollectionDataSource bugThis closes #33.,0
"Update Quickstarts Java API, Run Example, and Setup QuickstartThis closes #39.",1
"[FLINK-971] Configure PooledByteBufAllocator in NettyConnectionManager instead of using the default allocatorConfiguration:    - 0 heap arenas,    - n direct arenas (where n = num incoming + num outgoing network IO threads), and    - bufferSize << 1 bytes page size.Additionally, OutboundEnvelopeEncoder directly implements ChannelOutboundHandlerAdapter instead of theMessageToByteEncoder<Envelope> wrapper to have tighter control of memory allocations.This closes #38.",1
[FLINK-760] Add distinct operator,1
"Speed up ""getOptimizedPlan"" by not starting the local embedded runtime.",1
Change string construction to work around a known JVM performance bug still present in some older JVM versions.,0
InputVertices do not require an input format.,1
Fix generic type warnings in generated tuples,2
Remove debug LOG message of TaskManager heartbeats,2
[FLINK-985] Update the config.md to properly describe the configuration settings.[ci skip],1
Fixed Bug Flink-978https://issues.apache.org/jira/browse/FLINK-978Author: Jonathan <Jonathan@Hasenburg.de>Closes #46 from JonathanH5/fixWebI and squashes the following commits:13a7d41 [Jonathan] Fixed Bug Flink-978,2
Reeenable tryLocalExecution() test in ClientTest,3
Change TypeExtractor to have non-static methods that do the actual workThis is required because we need state to detect recursive data types.This will become necessary when introducing Pojo Types.,5
"Add support for POJO objectsThis adds support in the TypeExtractor and also one can now use fieldexpressions for grouping, join, and co-group.",1
Removed redundant config constants value.,5
Fix buggy computation of TaskManager free memory size- In NepheleMiniCluster the memory size was divided twice by the number of TaskManagers- In HardwareDescriptionFactory the memory fraction config value was multiplied too early,5
Fix the managed memory planning after patch 9ce6293075d1a2326df8a2e99c032445a555b28b,0
Fix checkstyle errors and various warnings.,2
"Add ""How to contribute"" and ""coding guidelines"" to the project.[ci skip]",1
Add first files for system internals documentation[ci skip],2
Add various figures for internals.Update text on internals overview.[ci skip],5
Fix simple error in local execution memory estimation,0
"Add ""how to add an operator"" section to internals.Add stubs for other internals pages[ci skip]",1
Mention that Oracle JDK 6 library will fail to buildSo people won't encounter and ask the same question as I did just now ;)Author: Raymond Liu <raymond.liu@intel.com>Closes #49 from colorant/doc and squashes the following commits:90bf2aa [Raymond Liu] Mention that Oracle JDK 6 library will fail to build,0
Minor changes in Java POJO WordCount example,4
add gh_link jekyll plugin to docs,2
Finished Flink-928Taskmanagers are now displayed in the web interface @rmetzgerAuthor: Jonathan <Jonathan@Hasenburg.de>Closes #43 from JonathanH5/webclient and squashes the following commits:5cc5f72 [Jonathan] Finished Flink-928 and simplified how new pages to the WebInterface are added,1
[FLINK-888] Add swap() to Tuple2,1
[FLINK-893] Inconsistent Iteration Step Function gives nonesense error messageI adjusted the error message.Author: Markus Holzemer <markus.holzemer@gmx.de>Closes #50 from markus-h/iteration_translation_exception and squashes the following commits:34a6f87 [Markus Holzemer] adjusted error message when encountering a translation failure for iterations,0
[FLINK-932] Introduce automatic generation of semantic props for projectionsThis closes #29,2
Fix various error messages and invalid JavaDocs.,2
[FLINK-996] Fix for bug in union replacementThis closes #56,0
[FLINK-990] Added constant fields and combinable annotations forwarding to Scala APIThis closes #51,1
[documentation] modified gh_link to support naming,1
[documentation] fix internals linking,2
"[documentation] fixed a lot of links, better gh_link pluginThis closes #54",2
"First cleanup attempt, mostly on Scala code, to follow guidelines from http://docs.scala-lang.org/style:1. Remove return statement from Scala code where it is not necessary (end of method definition)2. Remove extra ; from Scala and Java code3. First drop to abide to 100 chars per line for Scala code.   Will send another PR for other files as I have encountered.4. Remove parentheses for empty argument methods that do not have side effect   (see http://www.artima.com/pins1ed/composition-and-inheritance.html#i1343251059-1)5. Remove unused import statements in Scala code as I have encountered them.This is first drop to refactor and clean up Scala code to see comment/ response from community.More PRs for follow up code will come.Close #64",4
[FLINK-994] Replaced DataInput and DataOutput with DataInputView and DataOutputView,5
"[FLINK-994] Added test cases for AbstractPagedInputView, fixed problem with hbase.This closes #53",0
[FLINK-836] Integration of the CachedBuildSideMatchDriver into the optimizer,5
[FLINK-795] Tests for the integration of the cached match driver into the optimizer,3
[FLINK-836] Rework of the cached match driver,1
Fix various JavaDoc errors,0
Clean up exception logging in JobManagerITCase.,2
[FLINK-701] Rework of TypeExtractor for SAM supportThis closes #52,1
Add dedicated test for the type extraction on input formats.Fix various JavaDoc errors.,0
Fix cost formulas for cached hash joinsFix estimation bug in channelsAdd tests for isolated cost formulasAdd tests for channel class in plan candidates,5
Fix missing strategy constants in JSON dump generator,5
No explicit caching when hash table is cachedAdd tests for explicit cache removal when hash table is cached,4
Clean up checkstyle and JavaDoc errors in core project,0
Fix optimizer error in channel instantiation (wrong parameterization),2
Renaming part 1 (scala sources only),5
Renaming part 2 (core and java api),5
Renaming part 3 (runtime),1
Refactoring part 4 (compiler and clients),4
Renaming part 5 (java examples and test utils),3
Refactoring part 6 (finalize scala api and scala examples),4
Renaming part 7 (tests),3
Renaming part 8 (addons),1
Renaming part 9 (first part of distribution project),5
Renaming part 10 (fix error in clients pom file),2
"Rename POMs, scripts, quickstarts and other minor renames",5
Add compiler test for solution sets depending on the delta set.,1
Adjust LICENSE file to remove LGPL section (library not used any more)Adjust NOTICE file for years,2
"Minor fixes for POM files : Inherited versions where possible, suppress unnecessary warnings",2
Set version to 0.6-incubating-SNAPSHOT and update Readme,5
"Update license header for java, sh and xml files",2
Rename documentation,2
prefix all projects in addons and quickstarts with flink-,2
Change cluster shutdown order to avoid heartbeat exceptions during shutdown on large clusters,4
Fix issue with git-commit-id-plugin on Travis,0
[FLINK-1004] Add the maven repositories for all vendors + documentationThis closes #62,2
Improve error messages for data sinks inside iterations.,5
[FLINK-1018] Add tests to verify correct placement of pipeline breakers with broadcast variables,4
[FLINK-1018] Fix cross pipelining/daming info to resolve cross-related streaming deadlocks.,0
[FLINK-828] Implement accumulator example- shows how to build a custom accumulator (for vectors)- employ that accumulator for obtaining filter statisticsThis closes #55.,5
Reconfigure Apache Rat to enforce the correct ASF license header,1
Fix Quickstart example (by using the latest 0.5.2 Stratosphere release),3
Fix scope for scalatest dependency,3
Improve exception messages for file output format when target file cannot be created.,1
"[FLINK-955] ResizingHashTable: automatic resizing, IndexOutOfBoundsException fixed, pointersThis closes #57",0
"[FLINK-1026] Fix PojoComparatorWas not using the user code class loader and therefore could not clonethe serializer that is internally used.Also modify KMeansForTest to make use of the PojoComparator to preventsuch bugs in the future.Also fix PackagedProgramEndToEndITCase, AvroExternalJarProgramITCase andthe external jar file class loader tests in flink-clients. The pom wasnot configured to remove the code that should only be in the externaljar from the test-classes directory.",3
[FLINK-1031] Fix POM files to support Eclipse,1
Update LICENSE and NOTICE files[ci skip],2
"Consolidate some third-party license entries, update readme in binary distribution[ci skip]",5
Add Netty to License files[ci skip],2
[FLINK-1024] Enable automated snapshot deployment through Apache's Maven infrastructure,5
Add ASM to LICENSE file[ci skip],2
Add ScalaTest to LICENSE file[ci skip],2
Add notice to ClosureCleaner[ci skip],4
"[Documentation] Move ""How to contrib""; ""coding guidelines"" out of the code repo (part of FLINK-1012)Improve build instructions with respect to Hadoop 1 and Hadoop 2 dependencies.[ci skip]",2
"Fix License and Notice entries and headers for all web frontend files (css, js, fonts)",2
[FLINK-386] Fix and clean up dependencies- Upgraded to junit 4.11 and fixed code that used deprecated- Changed scala dependency from 2.10.3 to 2.10.4 to avoid conflicts with scalatest dependency- Upgraded log4j and commons-logging dependency- Removed superfluous dependency on commons-codec- Upgraded dependency versions in the base module- Ensured consistency of avro versions across submodules- Upgraded AWS dependency to version 1.8.1- Unified configuration of jetty dependencyThis closes #80.,5
"[FLINK-998] Close network connections when idle1. Close idle TCP connectionsTasks enqueue envelopes to be dispatched via NettyConnectionManager. Thefirst task to enqueue an envelope triggers the establishment of a newTCP connection to the target task manager. Usually, there are multipleconnections between the same task managers in order to avoid deadlocks.This commit addresses the following problem: idle connections were neverclosed. This meant that the number of TCP connections was monotonicallyincreasing over time. Idling connections are now closed after aconfigured amount of time, see 'taskmanager.net.closeAfterIdleForMs'.2. Enqueue envelopes directlyTCP connections are handled by Netty's IO loop. Every enqueue operationneeds to ensure that the envelope to be enqueued is handed over to therespective IO thread in a thread-safe manner. Previously, this was donevia Netty's user events.This commit addresses the following problem: every enqueue operationresulted in the creation of an IO event loop task to hand over theenvelope. Envelopes are now directly added to a ConcurrentLinkedQueue,which drastically improves the throughput of enqueue operations. Theuser event is now only fired to trigger the processing if the queue wasempty.3. Added unit tests for OutboundConnectionQueue and adapted existingtests to test concurrent enqueue and close4. Removed unused arguments to NettyConnectionManager (low and highwater mark)This closes #76.",1
Update Netty dependency to 4.0.21.Final,5
Add type parameters in OutboundConnectionQueueTestThe use of PowerMock's Whitebox without type parameters led to compileproblems with Java 6.,0
Remove unused import from OutboundEnvelopeEncoderTest,3
[FLINK-1039] Fix pojo expression keys for group reduce,0
"[Docs] Limit nesting of generated TOCsThe jekyll tocify plugin generates an HTML TOC based on the headingsof the markdown files. This commit limits the nesting of the TOC to 2,which means that only h1 and h2 element will be taken into account.Previously, all heading elements were used, which resulted in a verycluttered TOC.",1
[Docs] Adjust Java API documentation to be in sync with latest changes[ci skip],4
[FLINK-701] Refactor Java API to use SAM interfaces. Introduce RichFunction stubs for all UDFs.,1
[FLINK-701] Several cleanups after SAM refactoring.  - Lambda detection compiles on earlier java versions  - Add lambda detection test.  - Fix JavaDocs,2
[FLINK-701] Change KeySelector to a SAM interfaceThis closes #85,4
[FLINK-1023] Switch group-at-a-time function to java.lang.Iterable (from java.util.Iterator)Iterables over transient data throw an TraversableOnceException when iterated over again.This closes #84,5
[doku] fix broken image urls,0
"Create release scripts, add support for ""cdh4"" build.",1
Reflect recent changes to Java API documentationchange text to StringThis closes #87.,4
[FLINK-909]  Remove additional empty (and non empty for iterative broadcast variables) superstep.[FLINK-945]  Fix early memory release in iterations,0
[FLINK-909] Adjust aggregators test case,3
"Disable POJO typesThere are various issues when working with POJOs in the Java API, forexample [1].This commit squashes the following commmits:1. Disable tests, which depend on POJO types2. Replace expression keys with key selector in test3. PackagedProgramEndToEndITCase used a KMeans variant, which relies onexpression keys to select the field to group on. This commit replacesthis with a key selector.4. Disable WordCountPOJO test case and package5. Disables WordCountPOJOITCase, which executes the WordCountPOJO example.The example code is still included with the source code (with noticethat it is currently not working), but will *not* be packaged as a JARanymore.6. Disable tests, which depend on POJO types (continued)[1] https://mail-archives.apache.org/mod_mbox/incubator-flink-dev/201407.mbox/%3C53D96049.1060509%40cse.uta.edu%3EThis closes #93.",2
Remove expression key methods,4
Fix broken history due to misplaced google load js,0
"Extended release script, update nightly build script",5
Maven now tests if files generated by the archetypes do actually build,2
[FLINK-1042] Changed ClassLoader field to be transient.Serialization of the `RuntimeStatefulSerializerFactory` fails because the field `ClassLoader loader` is not serializable. The fix makes the field `transient`.Author: Fabian Hueske <fhueske@apache.org>Closes #92 from fhueske/StatefulSerializerFactoryFix and squashes the following commits:c01cc27 [Fabian Hueske] [FLINK-1042] Changed ClassLoader field to be transient.,4
"Remove field0 from CoGroup and Join OperatorThese were added before to force the user to specify at least one keyfield. Now, the user is also forced to specify at least one key becauseotherwise the call would be ambiguous because of tuple key fields andexpression keys.",1
Change python2.7 to python in KMeans Quickstart,4
[FLINK-966] java examples included in packaged example directoryThis closes #90,2
Fix problems with missing files/dependencies with cdh-4 distribution.,2
Fix legacy names in static webclient contents,0
"Fixes on CDH4 build / Maven improvements:- remove usages of commons-lang (we use only commons-lang3, as defined in flink-runtime/pom.xml)- Upgrade maven failsafe to 2.17 so that tests also fail if the test errors (exceptions during execution)- added new build profile ""docs-and-source"" that creates javadocs and source attachments. These are usually only needed when releasing (--> speed up the build)",2
[FLINK-1046] Made sure that Client uses correct user-code class loaders.,1
Add Sanity Checks for Join/CoGroup with SolutionSet in Record APIWe now check whether the key fields specified for the delta iterationsmatch those specified when joining/coGrouping with the solution set.This code is more or less copied from the new Java API.The Scala API uses the Record API underneath so it is also covered.,1
[FLINK-1047] Fixes main class for start-local.bat,0
[FLINK-1048] Swallow output of SET statements in ./bin/flink.bat,2
[FLINK-1051] ./bin/start-local.bat prints error message if java.exe cannot be found,0
Another fix for CDH4 compliance,0
Adjusted examples packaging to only create jars for fully self-contained examples.,1
"[FLINK-1053] Add ""mapPartition"" operator.",1
[FLINK-1053] Cleanup implementation of mapPartition functionThis closes #42,1
Small bug fixes for running hadoop output formatsThis closes #75,1
[FLINK-1054] Fix job history view in web frontend,0
[FLINK-1006] Added support for the MapR file system,5
make CI build fasterThis closes #97,1
"Run tests in parallelThis uses the forkCount parameter of surefire/failsafe. This alsochanges the JVM memory size for the testing VMs so that more can fitinto memory.For this to work, NepheleMiniCluster must recognize when it is run ina parallel testing environment and change ports accordingly. AlsoAbstractTestBase and TaskTestBase must prefix temp files with the classname to prevent name clashes.This closes #96",2
[FLINK-977] Improve error reporting for failed TM connection.This closes #98,0
[streaming] Initial commit,5
[streaming] updated README,5
[streaming] Initial source commit,5
[streaming] JobGraphBuilder refactor,4
[streaming] Begin implementing StreamSource object,5
[streaming] Source and Task interface updated,5
[streaming] StringRecord to Record migrate,5
"[streaming] Ordered imports, migrated StringValues to IntValues and LongValues",2
"[streaming] My stream refactored, JobGraphbuilder update",5
[streaming] UserTaskInvokable usage added to JobGraphBuilder,1
[streaming] Added UserSinkInvokable,1
[streaming] UserSinkInvokable fixed,0
[streaming] Automatically getting the number of input components in StreamTask,1
[streaming] Refactored the NumberOfInputs setting in JobGraphBuilder,1
[streaming] Refactor 2 of the NumberOfInputs setting in JobGraphBuilder,1
[streaming] Jobgraphbuilder connect update with partitioning,5
[streaming] Package naming refactor,4
[streaming] Added DefaultInvokable functionality,1
[streaming] StreamSource and Task updated to support connection level partitioning,1
[streaming] Apache Licensing added,1
[streaming] Stream classes refactor,4
"[streaming] StreamInvokable class added, updated UserInvokables",1
[streaming] test case update,5
[streaming] ShufflePartitioner Concept added,1
[streaming] Started implementing FlatStreamTask,5
[streaming] Partitioner classes added,1
[streaming] JobGraphBuilder api update with partitioning,5
[streaming] JobGraphBuilder method name refactor,4
[streaming] FlatStreamRecored fixed,0
[streaming] StreamSource and Task updated to support new grouping api + refactored,4
[streaming] Basic WordCount added,1
[streaming] WordCount Refactor,4
[streaming] WordCount object reuse,1
[streaming] WordCount updated,5
[streaming] Added StreamRecordProvider instead of FlatStreamRecord,1
[streaming] Added UUID generation to StreamRecordProvider,1
[streaming] StreamRecord created,1
[streaming] Added AckEvent,1
[streaming] UUID used to identify StreamRecord,1
[streaming] Implemented basic record acknowledgment,5
[streaming] StreamTask getClass TODO resolved,0
[streaming] Record copying in StreamRecord removed,4
[streaming] Created StreamComponentFactory for the common methods of StreamSource and StreamTask,1
[streaming] Making a copy of Record in StreamRecord,1
[streaming] emit update,5
[streaming] solve issue #3,0
[streaming] FieldsPartitioner fix,0
[streaming] StreamComponent additional refactor,4
[streaming] UserFunction setter move to StreamComponent,4
[streaming] FaultTolerancyBuffer class added,1
[streaming] ack update,5
[streaming] updated streamrecord getrecord method,1
[streaming] Fail event added,1
[streaming] emit update,5
[streaming] FTBuffer fix,0
[streaming] remove duplicate maven plugins. Added travis config,5
[streaming] StreamComponentHelper refactor to Generics,4
[streaming] StreamComponentFactory rename to StreamComponentHelper,5
[streaming] SerializableStreamRecord added,1
[streaming] FaultTolerance update with timekeeping + concurrent publishing bugfix,0
[streaming] Implemented thread safe event publishing,5
[streaming] initiate windowing,5
[streaming] Started using Serializable StreamRecord,1
[streaming] StreamRecord toString quickfix,0
[streaming] add timestamp field,1
[streaming] improved threadsafe publishing,1
[streaming] uuid update,5
[streaming] methods added for fault tolerance testing,3
[streaming] initialize tuple batch processing,5
[streaming] tests written for FaultTolerancyBuffer,3
[streaming] enable batch sending,0
[streaming] remove input files,2
"[streaming] Fixed FaultTolerancyBufferTest error caused by batchable StreamRecord, cleaned some imports",2
[streaming] StreamComponentException added,1
[streaming] batch StreamRecord Refactored,4
[streaming] Renamed batch simple test (StreamSink and StreamSource),3
[streaming] StreamComponentException usage,5
[streaming] hamlet.txt added to testdata,5
[streaming] new streamrecord constructor added,1
[streaming] javadoc added to fault tolerance buffer,1
[streaming] CellInfo refactor,4
[streaming] BatchForward Refactor,4
[streaming] FaultToleranceBuffer rename,5
[streaming] javadoc added to api elements,1
[streaming] WordCount Refactor,4
[streaming] javadoc added to api,1
[streaming] wordcount moved out from testbase,3
[streaming] WindowedWordCount Refactor,4
[streaming] CellInfo Refactor,4
[streaming] Added FTBuffer,1
[streaming] Added WordCountDummySource for simpler testing,3
[streaming] WordCount Refactor,4
[streaming] Test Refactor,4
[streaming] Added .gitignore,1
[streaming] Added StreamRecord setter,1
[streaming] Added logging for API,2
"[streaming] Updated StreamRecord, removed AtomRecord",4
[streaming] Logging intermediate stage,2
[streaming] Added new getters and setters to StreamRecord,1
[streaming] StreamRecord copy quickfix,0
[streaming] fault tolerance update,5
[streaming] Logging & WordCount bug,0
[streaming] wordcount bugfix,0
[streaming] Added NoSuchRecordException and StreamRecord tests,3
[streaming] Added Apache Licenses to sourcefiles,2
[streaming] updated fault tolerance buffer and jobgraphbuilder to properly handle broadcast partitioning,0
[streaming] wordcount cluster test,3
[streaming] Cluster trial & error,0
[streaming] wordcount cluster testing,3
[streaming] Logging updated,5
[streaming] StreamRecord package created,1
[streaming] StreamInvokableComponent rename,5
[streaming] Added test package for Partitioners,3
[streaming] Added testing for Partitioners,3
[streaming] wordcount cluster settings updated,5
[streaming] cellinfo and wordcount update for cluster testing,3
[streaming] wodcount cluster settings update,5
[streaming] Logging update,5
[streaming] Sink results added,1
[streaming] cluster testing,3
[streaming] minor bug fix,0
[streaming] Added Source & Sink parallelism,1
[streaming] Eliminated Testbase2,3
[streaming] StreamRecord javadoc fixed,0
[streaming] fault tolerance improvement and bugfix,0
"[streaming] Logger updated, only streaming is logged",2
[streaming] Encapsulated log setup,1
[streaming] LogUtils updated,5
[streaming] StreamComponentTest added,1
[streaming] Shorter log messages,2
[streaming] Components and faulttolerance buffer updated to support exactly once processing,1
[streaming] Repository change to dms.sztaki.hu/maven-public,4
[streaming] Adjust pom.xml to match new repo,1
[streaming] Refactor: added interfaces to abstract invokable classes,1
"[streaming] Code cleanup, added licenses",1
[streaming] faulttolerance update,5
[streaming] Rat plugin skeleton added,1
[streaming] streamrecord bugfix,0
[streaming] taskinstance id update,5
[streaming] FaultTolerance test updated,5
[streaming] Licensing added to LogUtils,2
"[streaming] Added apache lang3 dependency, pom refactor",4
[streaming] Refactored JobGraphBuilder and StreamComponents,4
[streaming] Pom warnings resolve,0
[streaming] UserInvokable Licensing,1
[streaming] fault tolerance refactor,4
[streaming] RandIS rename to DummyIS,5
[streaming] fault tolerance tests,3
[streaming] ExactlyOnceBufferTest added,1
[streaming] ExactlOnceBuffer bugfix,0
[streaming] fault tolerance refactor,4
[streaming] enabled exactly once processing for fault tolerance,0
[streaming] fault tolerance buffer updated to support directed emits,1
[streaming] Readme update,5
[streaming] Examples moved to example package,4
[streaming] Readme update,5
[streaming] Strated implementing StreamRecord with Tuple,5
[streaming] TupleTest passing,4
[streaming] Tuple serialization added,1
[streaming] StreamRecord refactor,4
[streaming] tuple test,3
[streaming] StreamRecordTest fixed,0
[streaming] set/get methods written for some basic types,1
[streaming] wordcountlocal updatet for tuple,5
[streaming] pom refactor,4
[streaming] Partitioner tests updated with Tuple,5
[streaming] BatchForwardLocal updated with Tuple,5
[streaming] batchwordcount updated for tuple,5
[streaming] batch and window wordcount updated for tuple,5
[streaming] CellInfo updated with Tuple,5
[streaming] TupleTest removed,4
[streaming] updated fields partitioning api,5
[streaming] copyTuple method added to streamrecord,1
[streaming] StreamRecord documentation update1,5
[streaming] JobGraphBuilder documentation update,5
[streaming] StreamRecord documentation update2,5
[streaming] StreamRecord getters refactor,4
[streaming] StreamRecord setters refactor,4
[streaming] StreamRecord copy updated,5
[streaming] getFieldSpeedTest,3
[streaming] streamrecord add/set tuple updated,5
[streaming] removeTuple method added to streamrecord,1
[streaming] streamrecord add method and tests updated,5
[streaming] speedtest for tuple20 added,1
[streaming] StreamRecord basicTypes update,5
[streaming] minor refactor,4
[streaming] Removed record fail from invoke,0
[streaming] Started implementing basic type serialization with Long instead of String,2
[streaming] jobgraphbuilder setnumberoftasksperinstance update,5
[streaming] streamrecord tupleBasicTypesFromLong update,5
[streaming] jobgraphbuilder update,5
[streaming] Updated type serialization,5
[streaming] Implemented AckEvent and FailEvent serialization,0
[streaming] ack and fail event updated + WordCountRemote modified for debugging,0
[streaming] Implemented getResult() for performance stats in WordCountRemote,1
[streaming] performance tracker class added,1
[streaming] Updated input checking for next record at invoke,5
[streaming] initiate internal state for stateful operators,1
[streaming] user-defined window operator,1
[streaming] timer added to performance tracker,1
[streaming] performance util refactor,4
[streaming] add licence,1
[streaming] python script added for performance visualization,1
[streaming] performance tracker update and counter added to wordcount example,1
[streaming] wordcount example modified for cluster testing,3
[streaming] Added performance test data copying script,5
[streaming] Changed String UID to byte array,4
[streaming] WordCount updated for testing,3
[streaming] Started implementing Storm WordCount for performance test,3
[streaming] Performance test scripts added,1
[streaming] WordCount updated for cluster testing,3
[streaming] performance test scripts updated,5
[streaming] WordCount update for testing,3
[streaming] Added test runner script,1
[streaming] replaced synchronized methods with concurrent collections,5
[streaming] performance tracker update,5
[streaming] WordCount performance,5
[streaming] perf util update,5
[streaming] WordCount performance testing,3
[streaming] update internal state abstraction,5
[streaming] add license,1
"[streaming] update internal state abstraction, add index.",1
[streaming] refactor,4
[streaming] jobgraphbuilder update,5
[streaming] WordCount example refactor + performanceTracker update,5
[streaming] performance tracker fix,0
[streaming] Upgrade to 0.5-rc1,5
[streaming] basic topology example added,1
[streaming] incremental machine learning skeleton added,1
[streaming] StreamRecord serialization updated to support basic array types,1
[streaming] Updated Tuple type serialization,5
[streaming] StreamRecord update with faster serialization and removed copy when adding/setting tuples,1
[streaming] StreamRecord serialization improvement,1
[streaming] fix some conflicts,5
[streaming] fix several bugs in in the examples. Window operator runnable,1
[streaming] IncrementalLearning skeleton updated,5
[streaming] Javadoc fix,0
[streaming] Minor pom fix,0
[streaming] StreamRecord iterable and new constructor added,1
"[streaming] IncrementalOLS implementation added, IncrementalLearning renamed to IncrementalLearningSkeleton",1
[streaming] Update to 0.5-rc2,5
[streaming] IncrementalLearning skeleton updated,5
[streaming] Javadoc fix,0
[streaming] Minor pom fix,0
[streaming] StreamRecord iterable and new constructor added,1
"[streaming] IncrementalOLS implementation added, IncrementalLearning renamed to IncrementalLearningSkeleton",1
[streaming] Update to 0.5-rc2,5
[streaming] perf util refactor and update,5
[streaming] add window sum example,1
[streaming] Incremental OLS fix,0
[streaming] finished windowing sum and windowing wordcount example,5
[streaming] minor bug fixed,0
[streaming] basic RabbitMQ tolopolgy add to test future support for RabbitMQ,1
[streaming] FaultTolerance set via JobGraphBuilder config,5
[streaming] Merged RMQTopology,2
[streaming] added support for udf objects in jobgraphbuilder,1
[streaming] JavaDoc and api update,5
"[streaming] Fixed double logging, added FieldTypeMismatchException",1
[streaming] api refactor,4
"[streaming] add clear function for StreamRecord, add framework of checkpointer.",1
[streaming] License fix,0
[streaming] Version set to 0.5,1
[streaming] api cleanup,4
[streaming] add frameworks for iterative computation.,1
"[streaming] add stream join and stream window join example, refactor window state",4
[streaming] add license & implement iterative processing,1
[streaming] Version set to 0.5,1
[streaming] add kafka topology,2
[streaming] Replaced List<RecordReader> with UnionRecordReader,5
[streaming] Refactored StreamComponentHelper and StreamComponentTest,3
[streaming] Refactored logging to avoid expensive String concatenation,2
[streaming] branch added for new api,1
[streaming] StreamCollector added,1
[streaming] streamrecord reworked,1
[streaming] datastream added,1
[streaming] Project version set to 0.1,1
[streaming] Project version set to 0.2-SNAPSHOT,1
[streaming] array based streamrecord added,1
[streaming] license added,1
"[streaming] Standard and Union StreamRecordReader added for improved serialization, not yet added to StreamTask and Sink",1
[streaming] created abstract streamrecord class + added StreamRecordReader and UnionStreamRecordReader to streamcomponenthelper,1
[streaming] ListStreamRecord test added,1
[streaming] StreamComponentHelper updated,5
[streaming] Fixed StreamComponentTest,3
[streaming] Stratosphere dependency upgraded to 0.5.1,5
[streaming] Refactored API to use new StreamRecord,1
[streaming] add CF job,1
[streaming] update iterative jobs,5
[streaming] Implemented dummy flatMap,5
[streaming] Added JobGraphBuilder getter to StreamExecEnv,1
[streaming] TypeExtraction test works,1
[streaming] Added FlatMapInvokable,1
[streaming] new api test,3
[streaming] new api refactor,4
[streaming] MapFunction support added,1
[streaming] new api refactor,4
[streaming] Deleted StreamOperator,1
[streaming] Deleted SingleStreamInputOperator,1
[streaming] connectWith and partitioning added to newapi,1
[streaming] addSink added to newapi,1
[streaming] Source skeleton added,1
[streaming] addSource fix + added missing licensing,1
[streaming] connectWith fix for different connection types,0
[streaming] added todos,2
[streaming] Added BatchReduce deserialization at stream components,1
[streaming] WordCount Counter & Splitter update,5
[streaming] Added FileSourceFunction,2
[streaming] Tested BatchReduce,3
[streaming] TypeExtract test added,1
[streaming] WordCount updated,5
[streaming] package refactor,4
"[streaming] Added FilterInvokable, eliminated code repetition at adding a function to DataStream",5
[streaming] Updated CellInfo and BasicTopology examples,2
[streaming] Updated Kafka and RMQ sources to new api,1
[streaming] Updated StreamComponentTest,3
[streaming] stream-join modified for new api,1
[streaming] minor update for partitioning setting with connectWith,1
[streaming] FaultTolerance test update,5
"[streaming] deleted obsolete examples, renamed addFileSource -> readTextFile to match batch api",2
[streaming] window join modified for new api,1
[streaming] Added batch setting to components,1
[streaming] Added batch timeout,1
[streaming] .batch operator added to datastream,5
[streaming] connectWith fix,0
[streaming] iterative example deleted due to lack of relevant content,4
[streaming] Incremental OLS update,5
[streaming] IML Skeleton update,5
[streaming] adapt to new APIs,1
[streaming] Minor WordCount Refactor,4
[streaming] adapt to new APIs and modify iterative algorithms,1
[streaming] TestDataUtil added,1
[streaming] added support for batch partitioning to jobgraphbuilder,1
[streaming] Added StreamCollector2,1
[streaming] Checksum check added to TestDataUtil,5
[streaming] Added DataStream copying,5
[streaming] TestDataUtil update with Logging,2
[streaming] minor fixes[streaming] minor example refactor,4
[streaming] refactor and jbuilder update for StreamRecord2,5
[streaming] StreamCollector2 added to streamcomponenthelper with fix,0
[streaming] Commenting out tunfinished iterative jobs,5
[streaming] Licensing added,1
[streaming] Iterative datafiles cleaned,4
[streaming] Fixed AtLeastOnceBufferTest,3
[streaming] Refactored BatchReduceTest,3
[streaming] in the wordcount example the download function is platform independent,1
[streaming] parallelism parameter added to operators,1
[streaming] Fixed java 1.6 error,0
[streaming] Map and FlatMapTest implemented,3
[streaming] Added MockRecordWriter for testing,3
[streaming] Updated StreamCollector2Test,3
[streaming] Added MockRecordWriterFactory,1
[streaming] Moved tuple copying to StreamCollector2,4
[streaming] new tests in MapTest,3
[streaming] Test updates,5
[streaming] license add,1
[streaming] more test in MapTest,3
"[streaming] test in MapTest, addSink with paralelism argument",1
[streaming] TestDataUtilTest added to test the download function of TestDataUtil,5
[streaming] test build fix,0
[streaming] download function of TestDataUtil was rewitten without using package nio,1
[streaming] comment remove,4
[streaming] StreamExecutionEnvironment javadoc update,5
[streaming] hamlet md5sum change,4
[streaming] remove java.nio from TestDataUtilTest,5
[streaming] .print() added as a sink to datastream,5
[streaming] example fix,0
"[streaming] new tests, wordcount performance classes, commented examples",3
[streaming] conflict solved,5
[streaming] license add,1
[streaming] examples update,5
[streaming] added some comment,1
[streaming] comments on examples,5
[streaming] javadoc for DataStream,5
[streaming] StreamExecutionEnvironment javadoc update,5
[streaming] examples refactor,4
[streaming] clustersize setting added to streamexecution environment,1
[streaming] streamcollector2 bugfix,0
[streaming] Fixed BatchTest,3
[streaming] using Sets for testing parallelism,3
[streaming] fromElements and fromCollection source added + refactor,4
[streaming] generateSequence source added,1
"[streaming] fromCollection, fromElements test",3
[streaming] jobgraphbuilder refactor and javadoc,2
[streaming] generateSequence test,3
[streaming] Stratosphere version set to 0.6-SNAPSHOT,1
[streaming] refactored dummysources,4
[streaming] datastream and streamexecution environment javadoc update,5
[streaming] streamcollector refactor,4
[streaming] connectwith function with multiple streams in the argumentum list,1
[streaming] Strato dependency to 0.5.1,5
[streaming] StreamComponentHelper refactor,4
[streaming] Strato version to 0.6-SNAPSHOT,5
[streaming] test for connect with,3
[streaming] Test refactor,4
[streaming] PreformacneSplitter update,5
[streaming] RMQSink and Test,3
[streaming] Decomposing project mv,5
[streaming] Started moving to 0.6,4
[streaming] refactor window operator and internal state management,1
[streaming] update state manager,5
[streaming] 0.6 build fix,0
[streaming] First succesful decomposed build,5
[streaming] DataStream id update,5
[streaming] pom update,5
[streaming] Remove dms repo from pom,4
[streaming] RMQ test removed,4
[streaming] javadoc update,5
[streaming] default signature added to operators,1
[streaming] fix kafka producer bug,0
[streaming] flatmaptest refactored,4
[streaming] MapTest refactored,4
[streaming] streamcomponent cleanup,4
[streaming] BatchTest refactored,4
[streaming] test cleanup,4
[streaming] StreamExecutionEnvironment restructure to match main project,5
"[streaming] KafkaSink, added shutdown to KafkaSource",1
"[streaming] add disk dump sink, prepare to support multiple output stream",1
[streaming] Removed unused StreamInvokableComponent,1
[streaming] Replaced StreamComponentHelper with AbstractStreamComponent,5
[streaming] Added RemoteStreamEnvironment,3
[streaming] RMQ Sink for other types,5
[streaming] test update,5
[streaming] streamcollector test fix,0
[streaming] javadoc fix,0
[streaming] package restructure,5
[streaming] Version set to 0.3-SNAPSHOT,1
[streaming] RMQ source for multiple types,5
[streaming] Rat fixes,0
[streaming] Performance removed,4
[streaming] rmq source refactored,4
[streaming] javadoc update,5
[streaming] kafka sink and source for multiple types,5
[streaming] setParallelism added for datastream operators to match main project,1
[streaming] jobgraphbuilder bugfix,0
[streaming] Javadoc fix,0
[streaming] addons rename to connectors,1
[streaming] remove legacy source folder,4
[streaming] explicit output flushing removed from streamcollector,4
[streaming] addon packages rename to connector,1
[streaming] explicit output flushing readded + need fix,0
[streaming] Package restructure,5
[streaming] Updated RemoteStreamEnvironment,3
[streaming] IterativeDataStream Prototype,5
[streaming] Fixed JavaDoc of RemoteStreamEnvironment,3
[streaming] IterateTest refactor,4
[streaming] simple iteration added with BlockingQueues,1
[streaming] iteration source/sink refactor,4
[streaming] Licenses,5
[streaming] Implemented and tested naming a component,3
[streaming] Iterative prototype,5
[streaming] Imports organized,2
[streaming] Test minor refactor,4
[streaming] Minor fixes,0
[streaming] ZeroMQ package,5
[streaming] Multiple iteration 1,5
[streaming] Added directed emit,1
[streaming] test minor refactor,4
[streaming] Updated OutputSelector,5
[streaming] Refactored collectors[streaming] streamcollector manager refactor1[streaming] streamcollector refactor,4
[streaming] jobgraphbuilder refactor,4
[streaming] Package and Java Dependency rename,5
[streaming] Module rename,5
[streaming] Dependency update,5
[streaming] Data{In/Out}putView QuickFix,0
[streaming] snapshot repo to pom,5
[streaming] pom fix,0
[streaming] Src licenses updated,5
[streaming] Readme trim,5
[streaming] Output-flush testing,3
[streaming] jobgraphbuilder remake to build graph at execution,1
[streaming] OutputFlush moved to a separate branch,4
[streaming] jobgraphbuilder remake,1
[streaming] Output-flushing,5
[streaming] iteration test fix,0
[streaming] iteration sink automatically named to 'iterate' for directed emits,5
[streaming] streamrecord remake + cleanup,4
[streaming] cleanup,4
[streaming] streamrecord cleanup,4
[streaming] partitioner performance improvements,1
[streaming] package refactor,4
[streaming] License fix,0
[streaming] Flink version update,5
[streaming] License update,5
[streaming] JobGraphBuilder minor refactor,4
[streaming] Enforced Flink coding style,2
[streaming] Removed legacy performace tester utils,3
[streaming] Legal issues of dependencies addressed,1
[streaming] Fixed generics and added SuppressWarnings,2
[streaming] Eliminated writing to standard output,5
[streaming] Test restructure + added tests for streamrecord and collectors,3
"[streaming] Fixes enabling build (mainly Licensing, Codestyle, Poms)",0
[streaming] Merged conflicts,5
[streaming] Build clean up & Removal of streaming.index package,4
[streaming] Removed profiles from pom.xml and made partitioners generic,5
[streaming] Corrected POM changes,4
[streaming] Forward connection type added to DataStream to support inmemory forwarding of tuples,1
[streaming] Iteration update to use proper partitioning and forward connection + DataStream refactor and Javadoc update,5
[streaming] Enforced the ASF2 license in POMs,1
[streaming] added writeAsText and Csv,1
[streaming] Package refactor & cleanup,4
[streaming] Added support for same outputname for multiple tasks + proper iteration edge naming,1
[streaming] Added exceptions,1
[streaming] Javadoc update for some core classes,5
[streaming] Fixed filter,0
[streaming] Serialization rework to reuse objects,1
[streaming] Added mutability switch for operators + cleanup,4
[streaming] Fixed StreamCollectorTest,3
[streaming] API javadoc + StreamRecordSerializer update,5
[streaming] windowReduce added + BatchReduceInvokable reworked,1
[streaming] Added CoFunctions for two type inputs,1
[streaming] Fixed multiple input CoFunction,1
[streaming] Distributed partitioner added,1
[streaming] Automerge error + License fix,0
[streaming] CoMapTest update,5
[streaming] Updated operators for better mutability handling,1
[streaming] Replaced connection types with StreamPartitioner in DataStream,5
[streaming] Operator invokable refactor,4
[streaming] StreamRecordWriter added for automatic output flushing settings,1
[streaming] Moved task configurations to StreamConfig,5
[streaming] Refactored StreamComponents,4
[streaming] Added twitter-hbc dependency to connectors and upgraded slf4j accordingly,1
[streaming] Added Flume connector and updated connectors,5
[streaming] connectors logging and error handling fixed,0
[streaming] Javadocs for connectors,2
[streaming] Wrapped serializers to make component construction simpler,1
[streaming] JSONParseFlatMap added to examples,1
[streaming] Twitter connector prototype,5
[streaming] Added support for simple types instead of Tuple1 in the API,1
[streaming] Removed unnecessary files from streaming project root,2
[streaming] Updated API to use RichFunctions,1
[streaming] Directed emit API updated to use split and select,1
[streaming] DataStream type refactor,4
[streaming] Added new DataStream types for operators,1
[streaming] Updated Streaming function interfaces to match main project,1
[streaming] API update with more differentiated DataStream types and javadoc + several fixes,0
[streaming] DataStream output naming reworked from vertex to edge based model,1
[streaming] Iterative DataStreams updated with buffer timout and max wait time,5
[streaming] DataStream fix to return DataStreamSink on closing operators,1
[streaming] GroupReduce operator added + StreamCollector bugfix,0
[streaming] Implemented sliding window and batchReduce,5
[streaming] Added groupBy operator to DataStream + name refactor,4
[streaming] Updated operator test to avoid environment execution,3
[streaming] Several minor bugfixes,0
[streaming] Exception handling update & minor refactor,4
[streaming] Fix LICENSE file for streaming project. Minor merge fixes.This closes #72,0
[streaming] Fixes for tests to support parallel builds,1
Update LICENSE and add license headers to CSS and JS in flink clients,2
Split between source distribution license/notice and binary distribution license/notice.Add a DEPENDENCIES file to list all maven dependencies with licenses and notices.[ci skip],2
Add new DEPENDENCIES file to apache-rat's exclude list [ci skip],2
[YARN] properly set diagnostics messages on failures,0
[FLINK-968] Add slot parameter to YARN client,2
"[FLINK-1050] Windows local setup documentation: added note for java being in %PATH% variable, headers, and missing link labelThis closes #95",2
[Documentation] Add documentation on accessing Microsoft Azure Storage Tables[ci skip]This closes #100,2
[FLINK-1053] Add documentation for mapPartition() function[ci skip],1
[FLINK-954] Improved WebClient  - display temp_mode at edge  - simplified function loadJsonToDagre(data);  - removed small grey borders below colored borders  - mirrored node into iteration if the origin is outside to draw an edge  - added zoom buttons in planVisualizer.htmlThis closes #82,1
[Documentation] Fix broken links,2
updated CONTRIBUTORS file,2
[FLINK-834] Added DataSet.writeAsFormattedText(),5
Update release script (its the exact setup for creating the 0.6-incubating release),1
Set version of poms to 0.7-incubating-SNAPSHOT ; 0.6-incubating release tasks:- update _config.yaml of integrated documentation- quick check on the quickstarts / build instructions to match the latest release- quickstart.sh scrips now point to the correct versions.,3
[FLINK-993] Release builds and nightly builds now have the same names,2
Forgot license header (which causes apache-rat to fail the build),0
[FLINK-1067] Replaced Stratosphere by Flink in FAQ,2
[FLINK-1068] Remove cdh4 specific build profile.Users using CDH4 can now build Flink against Hadoop 2.0.0-alpha.,2
[FLINK-1074] Fix for NULL input tuples in ProjectJoin,0
[FLINK-1071] Add Map Partition to Plan dump JSON generator,5
[streaming] CoFlatMap & CoGroupReduce functionality,1
[streaming] Added database-backed state,5
"[streaming] Memcached, MySQl and SQLite support for state management.",1
[streaming] Refactored db state connectors and added their licenseConflicts:flink-addons/flink-streaming/flink-streaming-connectors/pom.xml,5
[streaming] Refactored stream components with InputHandler & OutputHandler,0
[streaming] Minor bug and license header fixes,0
[streaming] Updated DBStates,5
[streaming] DataStream merge fix + example clean-up,4
[streaming] CoRecordReader and iterator added + ConnectedDataStream refactor,4
[streaming] Examples updated with CoFunctions,1
[streaming] Added JSONParser and updated Twitter connector,5
[streaming] WindowJoin Example refactored,4
[streaming] connectors logging and deploy update,5
[streaming] reduce operator added to DataStream and ConnectedDataStream + grouped batch and windowReduce operators reworked,1
[streaming] Moved dependencies to enforce correct policy,1
[streaming] Mutable and Immutable invoke in CoInvokable,2
"[streaming] Added MockCoInvokable, replaced environments with it in CoFunction tests",3
"[streaming] Tests added for Reduce, GroupReduce and BatchGroupReduce invokables",1
[streaming] Removed assembly execution on maven package for connectors,4
[FLINK-1065] [streaming] Explicitly adding commons-math dependency,1
[streaming] StreamInvokable refactor and javadoc update + StreamRecordSerializer update,5
[streaming] GroupReduceInvokable update,5
[streaming] Added exceptions for wrong usage of StreamExecutionEnvironment,0
[streaming] Added customizable timestamps to window operations,1
[streaming] Add redis dependency notices to binary distribution NOTICE file and DEPENDENCIES fileThis closes #102,2
"[FLINK-1070] Change return type of ""getBroadcastVariable()"" to List.This closes #105",1
[FLINK-1075] Removed the AsynchronousPartialSorter.This closes #104,4
[FLINK-1079] Fix inconsistent parameter naming,2
[FLINK-1078] PrintingOutputFormat uses same partition indexing as FileOutputFormat.,2
"[FLINK-1084] Fix broken links in ""How to add an operator""",1
Add Pi approximation Java exampleThis closes #78,1
Some simplifications to the PiEstimation example,5
[FLINK-1020] Introduce minBy and maxByThis closes #101,2
[FLINK-610] Added KryoSerializerThis closes #74,1
Default generic serializer is Avro. Minor improvements in KryoSerializer. Add mini benchmark for Avro/Kryo.,5
Disable merging of Iteration Aux TasksThis will become obsolete once we have buffer oriented execution.Disable it for now because it is causing a bug: FLINK-1087,2
Fix DeltaIteration Bug with Immutable TypesThe CompactingHashTable did not obey the new serialization contract thatallows for immutable objects. We must always use the return value of thedeserialization methods and cannot assume that the data was put into thereuse object.,1
[FLINK-1086] Replace JCL with SLF4J and Log4j with LOGBack- Excluded Kafka's transitive dependencies: jmxtools and jmxri- Corrected encoder pattern in logback.xml- Removed explicit logging access. Loggers are now configured by  configuration files. Fixed Yarn issue with multiple logging  bindings.This closes #111.,2
[FLINK-1017] Add documentation for execution parallelismThis closes #114,2
Updated documentation figure: FlinkOnYarn.svgThis closes #110,2
[FLINK-629] getFieldNotNull added to Tuple and updated Aggregators and Comparators to use that where appropriate,1
[FLINK-629] Updated getFieldNotNull usage and added it to TupleSerializersThis closes #73,1
"[FLINK-1063] Revert race introducing commitThis reverts ""[FLINK-998] Close network connections when idle"" [1] asit introduced a race condition into the network stack, which mightresult in a re-ordering of network envelopes.[1] 52512636444902497e47ccbfb1cabaffb3e23343",1
[FLINK-925] Support KeySelector function returning Tuple types,1
[FLINK-925] Extended for distinct operator and added test casesThis closes #59,3
Fix typo in package LICENSE,2
"[Tools] Minor fixes in release script- Introduced required RELEASE_BRANCH environment variable- Some hardcoded binary calls (gpg, sha512sum, md5sum) have been  replaced by environment variables (GPG, SHASUM, MD5SUM) and added  """" argument for 'sed -i' calls for compatability with OS X- Removed unused environment variables- Directly call ssh/scp instead of going through sshpass",4
"Fix typo in CONTRIBUTORSFixes a typo in CONTRIBUTORS, replaces tabs by whitespaces for alignment,and updates email adresses of Apache committers to @apache.org.",5
Update CONTRIBUTORS fileUpdates CONTRIBUTORS file with contributors from 0.6-incubating releaseannouncement and sorts by first name.,2
"[FLINK-1097] Fixed multiple slf4j bindings when using Hadoop2I excluded all slf4j-log4j12 transitive dependencies to get rid off the warning that slf4j finds multiple slf4j bindings in the classpath. Additionally, I added log4j-over-slf4j and excluded all log4j transitive dependencies so that slf4j handles also legacy log4j logging messages from dependencies.Author: Till Rohrmann <trohrmann@apache.org>Closes #121 from tillrohrmann/FLINK-1097 and squashes the following commits:b9f76d5 [Till Rohrmann] Excluded slf4j-log4j12 as transitive dependency in order to not have multiple slf4j bindings in the class path. Added log4j-overslf4j and excluded log4j transitive dependencies to collect log4j outputs.",2
Remove naive verification of tuple sizeThis verification will not work.Think of spaces or escaped ?I think it's easier for users to parse the SQLExceptionAuthor: Moritz Schubotz <github@ckurs.de>Closes #116 from physikerwelt/patch-1 and squashes the following commits:69a3d2a [Moritz Schubotz] Remove associated test as wellb51b4f0 [Moritz Schubotz] Remove naive verification of tuple size,4
Remove space after comma for TupleXX.toString()It is better to save some bytes when writing the output. Users can always overwrite to `toString()` if they want.Author: Robert Metzger <rmetzger@apache.org>Closes #118 from rmetzger/benchFixes and squashes the following commits:cb8a251 [Robert Metzger] Remove space after comma for TupleXX.toString(),4
"Remove CONTRIBUTORS file to prefer dynamically generate itPer discussion in the dev@ list, maintaining the CONTRIBUTORS file manually is hard to do.Most ASF projects defer this to team page or retrieveing it from JIRA or git commit listfor every release if needed.This PR proposes to remove it and defer to dynamically created per release.Author: Henry Saputra <henry.saputra@gmail.com>Closes #123 from hsaputra/remove_contributors_file and squashes the following commits:e235cbc [Henry Saputra] Per discussion in the dev@ list maintaining the CONTRIBUTORS file manually is hard. Most ASF projects defer this to team page or retrieveing it from JIRA or git commit list for every release.",2
[streaming] Fixed SlidingWindowStateIterator,0
[streaming] Reduce operator added to ConnectedDataStream + test,3
[streaming] Updated directed emit to not use output names when all outputs are selected,1
[FLINK-1080] [streaming] Streaming aggregation addedConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.java,5
[streaming] Added TypeInfo to DataStream,5
[FLINK-1080] [streaming] Streaming aggregation update and refactor,4
[FLINK-1058] [streaming] Streaming initial documentation,2
[streaming] DataStream type refactor for easier future extensions,4
[streaming] Invokables and tests added for fast batch/window reduce operations and aggregations,1
[streaming] window and batch operator added to DataStream + Documentation updated accordingly,5
[streaming] Updated logging to utilize SLF4J,2
"[streaming] Added CoBatchGroupReduceInvokable, CoWindowGroupReduceInvokable and grouped variants",1
[streaming] Added counter aggregation,1
[streaming] Added checked exception to execution,1
"[streaming] GroupedBatchReduce modified to batch by key, updated WindowReduce + Batch/Window reduce refactor",4
"[streaming] Minor bug fixes in Connectors, StreamCollector & docsThis closes #115",2
[FLINK-989] Improve error message when not finding enough task slots.,0
[FLINK-1030] Refactor and clean up instance managers.,4
"[FLINK-1094] Reworked, improved, and testes split assigners",3
Redesign Scheduler from pre-assignment to more flexible schedule-on-demand model,5
Adapt RPC to support primitive types as parameters and return values.,2
Redesign Scheduler part 2,5
Unify all job vertices to one type (rather than dedicated input/output types),5
Make IDs immutable and serializable.,1
Stubs for intermediate data set and related classes,1
Refactor job graph construction to incremental attachment based,4
Remove management graph and simplify historic job status,4
Introduce execution attempts at execution vertex.Add tests for job event classes,3
Finalize ExecutionGraph state machine and calls,5
Adjust ExecutionGraph state machine to TaskManager's failing model (direct transitions to canceled),0
Adjusted job graph generator to new job graph classes,1
Adjust test logging for new execution graph tests to logback framework,1
Add proper locality of scheduling tracking to scheduler. Add local scheduling to slot sharing groups.,1
Add options strict co-location constraints to scheduler,1
More graceful failing/errors/logging when canceling in early job stages,2
Fix buffer leak in TaskManager / test tasks,3
Fix logging in EventCollectorFix comparisons (null pointer safe) in JobManagerITCase,0
Better error messages at TaskManager startup and registration,0
Fix race at TaskManager registration during startup,0
Fix serializability for SlotSharingGroup,0
Adjust tests to new JobGraphModel,1
Add co-location-constraints as a special case of slot-shared scheduling,1
Fix bug in topological sort,2
Port streaming package to new JobGraph API and adjust all runtime-level tests,3
Improved distribution of IDs. Previous implementation lost bits due to double-to-long multiplication and rounding.,1
Fix failure exception message report back to client,0
Make Co-Location constraints resilient aginst out of order scheduling and depply integrate them with slot sharingFix miscellaneous checkstyle errors/warnings,2
"Fix Java6 errors in AbstractID, pull JobManager changes into YARN app master",4
Fix test to be backwards compatible with Java 6,3
Fix TaskDeploymentDescriptor serialization,0
Adjust the web frontend display of the jobsTolerate concurrent scheduling attempts,5
Update web frontend javascript to new statesSmall fix in integration test,3
Improve shutdown of JobManager (graceful exit of runing jobs and RPC service),1
"JobManager checks for empty job graphsTemporarily disabled streaming tests that validate jobgraphs that used to be illegal, but are now legal.",1
[FLINK-953] Remove fake tail from iterationsThis closes #124,4
[FLINK-1077] Improved error message if test failsThis closes #120,0
[FLINK-1096] Correction to histogram accumulatorThis closes #117* each key is associated with the number of times it was inserted into the accumulator* backed histogram with a tree map to present the entries sorted by key,2
[FLINK-1038] added RemoteCollectorOutputFormatThis closes #94,1
"Refactor TupleTypeInfo and add GenericPairComparatorNow we have TupleTypeInfoBase, TupleSerializerBase, and TupleComparatorBase. Theyare now super classes of TupleTypeInfo and the others.Also rename compare on DataInputView to compareSerialized because Scalacannot distinguish between the to compare methods for some reason.This change is necessary for allowing the Scala API to reuse most of thefunctionality.The GenericPairComparator uses the new extractKeys method ofTypeComparator to compare values of any type. This replacesTuplePairComparator and some other special-case pair comparators. Thisis preparatory work for enabling support for Scala Tuples and POJOcomparators.",1
"Perform TypeExtraction outside of Java OperatorsBefore, FlatMapOperator, GroupReduceOperator, MapOperator, and MapPartitionOperatorperformed the Type extraction themselves while the other Operators had TypeInformationparameters. Now the are all unified, which makes it possible to use them from theScala API.Also Key extraction for selector functions is moved outside of Keys.java",4
"Move the Iteration ""Operators"" to the operators packageI'm doing this in preparation for the Scala API rework, since then I can just copy overthe operators package and use them for Scala.",1
Make DistinctOperator and Keys use TupleComparatorBaseWas TupleComparator before which does not work when used from the Scala API.,1
Change ObjectArrayTypeInfo.getInfoFor to use componentInfo.isTupleType()This is necessary because the previous test didn't work for Scala tuples.,1
"Refactor Tuple wrapping/unwrapping in Join and CoGroupPreviously both sides were always wrapped/unwrapped, even if one sidewas a tuple type. This was not compatible with the Scala tuples and isalso not necessary anymore because of the GenericPairComparator.",1
"Move RichFunctions to api.common packageThey were in api.java before but they can be used from Scala,just like the regular functions.",1
"Rewrite the Scala API as (somewhat) thin Layer on Java APIDon't bother looking at the diff, this is almost a complete rewrite ofthe previous Scala API. This uses all the work put into the Java API,such as TypeInformation, the serializers and comparators and theoperators.The Scala DataSet and ExecutionEnvironment wrap their respective Javaequivalents. TypeInformation is generated by a macro that usesTypeInformationGen and other macro support classes. The JavaTypeExtractor is completely bypassed but the TypeInformation andsub-classes are created by the Scala type analyzer. There is specialsupport for Scala Tuples in the form of ScalaTupleTypeInfo,ScalaTupleSerializer, and ScalaTupleComparator.This also adds tests to flink-scala that are ports of the tests inflink-java.There are not yet any Scala specific tests in flink-tests. All thescala example ITCases are commented out, as well as the examplesthemselves. Those will be uncommented once the examples are ported. Thiswill happen in separate commits.",3
Connected Components example Scala API rewrite,5
WebLog Analysis example,2
Transitive closure Scala example,5
Added TriangleEnumeration examples for reworked Scala API.,1
Add logback-test.xml to java8-tests and logback.xml to java-examples,5
Adds PageRankBasic Scala example. Removes old Scala examples,4
Pi estimation example job in Scala,5
[scala] Add Field Name Key Support for Scala Case ClassesThis does not change the runtime behavious. The key field names aremapped to tuple indices at pre-flight time.Also extends tests to cover the new feature.,1
"Add SemanticPropertiesTranslationTest for Scala APIFix join operator to user proper EquiJoin constructor so that semanticproperties are actually retrieved.Fix typo, getSematicProperties -> getSemanticProperties",1
"Add Scala API completeness TestThis is very naive right now, just checks whether a function of the samename is available. There are lists and regex patterns of excludedfunctions since not all functions in the Java API need to be availablein the Scala API.",1
Added LinearRegression scala example. Removed old BGD example.,4
Renamed java examples package,5
"Fix rename of java example package to examplesSome occurences in comments and POMs where not updated.Also change signature of join and coGroup to always return a value, notan Option.",4
[scala] Fix Formatting in Examples and add ITCasesAlso actually use termination criterion in TransitivelClosureNaiveJava example.Add ConnectedComponentsITCase for Scala ExampleAlso fix some formatting in the example codeAdd WebLogAnalysisITCase for Scala ExampleSome minor reformatting of example code and scaladoc.Add ITCases for TriangleEnumeration Scala ExamplesAlso fix some formatting and make TriangleEnumerationOpt Scala produce thesame output as the Java version.Add PageRankITCase for Scala ExampleAlso fix formatting in PageRank Scala Example.Fix formatting in EnumTriangles Scala ExamplesRemove Old/Deprecated Scala Examples and ITCasesFix formatting in EnumTrianglesBasic.scalaFix formatting in LinearRegression Scala ExampleRemove old Scala LineRank Code and RelQuery Example[scala] Fix typo in scaladoc in GroupedDataSet[scala] Fix Scaladoc of Join and CoGroup OperationWas still referring to the type of join/coGroup function that returns anOption.Fix tab vs. spaces in flink-scala and flink-scala-examples,2
[scala] Reactivate DeltaIterationSanityCheckTest,3
"[scala] Add Scalastyle, use scalastyle-config.xml from Spark",5
"Rename ScalaTupleTypeInfo to CaseClassTypeInfoThis better reflects what it is actually for. It is still derivedfrom TupleTypeInfoBase, though.",5
"[doc] Switch parser to kramdown, normalize HeadingsThe switch to kramdown is necessary because I want to add tabs in thedocumentation for code examples and Redcarpet does not allow markupinside divs.Before, some doc pages had ""#"" headings as toplevel headings whileothers had ""##"" (which is the same as --- underlined headings). Now weuser level 2 everywhere. The page title is still a h1 heading.",1
Add ExecutionEnvironment to ScalaAPICompletessTest,3
Rewrite Java API Guide as Unified Programming GuideThis now covers both Java and Scala.,5
[doc] Unify Examples PageNow contains Java and Scala examples with tabs to switch between thetwo.,2
Bump doc version to 0.7-incubating,2
"Turn Documentation into standalone website, add Overview PageThis can now be built standalone and then copied into the correct docsfolder of the website SVN.The index page now has a short overview and a table of contents.",2
"[scala] Add and* methods to AggregateDateSetAnd create AggregateDataSet in the first place, to add the methods to.",1
"[doc] Unify ""DataSet Transformations"" page",5
[doc] Add automatic generation of Scaladoc,2
[scala] Add package documentation for package api.scala,2
[doc] Fix typo in docs/index.mdWas programming_guide.htmls,2
[doc] Re-add streaming guide that was lost in rebaseAlso convert to kramdown syntax,1
"Wait for slots instead of TaskManagers in test environmentInstead of waiting for the number of connected task managers, the localmini cluster used for tests now waits for the total number of availableslots. Waiting for the number of connected task managers instead of theavailable slots might result in races in rare situations.In addition, rename task tracker (sic) to task manager in test classes.",3
"[FLINK-1111] Move Basic and Array Type Information into ""flink-core"" Project",2
Fixes for LICENSE and DEPENDENCIES files,2
Add a FAQ entry about serializability errors,0
Improved robustness of ExecutionGraphDeploymentTest,3
[FLINK-1111] Adjust Java-8-tests for type information refactoring,4
Changed scala copyright header.,4
Updated license notices in in java files to be written in block comments instead of javadoc comments.,2
"[FLINK-1114] Move scala-style checks to scala projects, change paths to style conifg, to allow isolated building of individual projects.",1
[FLINK-1115] Local file streams retry file creation on FileNotFoundException to increase resilience against spurious failures in tests,3
Improve error message when scheduler cannot find a slot for immediate scheduling.,0
Improve robustness of task manager test,3
Remove error message in execution graph for concurrent state changes that are fully acceptable.,4
"Tasks are marked correctly as failed (not canceled), when the taskmanager kills then during shutdown or reset.",1
Limit number of RPC worker threads in TaskManager to prevent OutOfMemory (thread space) errors,0
[FLINK-1077] Fix unstable test CliFrontendPackageProgramTest,3
[FLINK-1119] Make sure test mini cluster has started properly before submitting the test job.,3
[FLINK-1060] Added methods to DataSet to explicitly hash-partition or rebalance the input of Map-based operators.This closes #108,1
Exclude DataSet.rebalance() and DataSet.partitionByHash() methods from ScalaAPICompletenessTest,3
Added documentation for rebalance() and partitionByHash(),2
[FLINK-1073] Added test case to reproduce error,0
[FLINK-1073] Enables sorted group input for GroupReduce combiners.- GroupReduceCombineDriver uses separate comparators for sorting and grouping.- Adding support for multiple comparators for a single input driver required some refactoring.This closes #109,4
"[FLINK-970] Adds first() operation on DataSet, UnsortedGrouping, and SortedGroupingThis closes #88",5
"Added parameter checks and tests for first-n operator.Excluded DataSet.first(), UnsortedGrouping.first(), and SortedGrouping.first() methods from ScalaAPICompletenessTest.",3
Added documentation for first-n operator.,1
[FLINK-1104] [streaming] Eliminated Tuple1 from connectors,2
[streaming] Streaming jobgraph and vertex refactor to match recent runtime changes,4
"[streaming] added batchReduceGroup, windowReduceGroup functionality to ConnectedDataStream and GroupedConnectedDataStream",5
[FLINK-1102] [streaming] Projection operator added to DataStreamConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.javaConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/JobGraphBuilder.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/StreamConfig.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/ConnectedDataStream.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.java,5
[streaming] Fixed InternalStateTest to avoid printouts + minor StreamVertexTest fix,0
[doc] [streaming] Added Twitter connector & Projection operator to docs,2
[FLINK-1103] [streaming] Updated WordCount example to become self-contained and removed old TestDataUtil,5
[FLINK-1121] [streaming] minBy and maxBy operators added to streaming api,1
[FLINK-1122] [streaming] Job Execution with user specified name,1
[streaming] Streaming packages added to flink-dist lib,2
Add *.log files to .gitignore,2
Set default log level to info in examples,5
[FLINK-1056] Use maven-assembly to build fat-jar in quickstartsAlso update documentation accordingly.,2
Fix Bug with forced repartitioning in DOP changes.,4
Fix error with invalid config values for degree of parallelism.,5
"Fix race condition leading to erroneous ""NoResourceAvailableException"".",0
"[FLINK-1062] Type Extraction for LambdasChecking for Java supportSmall changes and meaningful exception for unsupported compilerspom.xml modified to use JDT compilerProject structure refactored, examples addedDocumentation addedQuickstart adapted",1
Disable Checkstyle in java8 packageCheckstyle doesn't seem to support Java 8 yet.,1
Make Java 8 Doc fit into new doc schemeThis closes #113,2
[doc] Fix missing Scala Version in index.md,0
Cleanup LOG.debug to make sure no extra toString and unnecessary String concatenationRemove unnecessary type check and cast for FileInputSPlit.Update LOG.debug to user SLF4J parameterized logging or protected by LOG.isDebugEnabled to save toString and String concat.Remove unnecessary semicolons.This closes #127,4
Remove leftover logback-test.xml in flink-java8.tests,3
Point quickstart scripts to 0.6.1-incubating,5
Change logging backend of SLF4j from Logback to Log4j for better compatibiltiy with YARN.We'll still ship the Logback configuration file and pass them their path to the JVM so thatusers can use Flink with Logback as well.This closes #125,2
Removed slf4j-simple dependency from streaming component.,4
Fix Bug in ScalaAggregate Operator and add ITCase,1
Change Partition Operator to actual general-purpose OperatorIt is no longer a special-case operator that can only be used in frontof map-style operations.,1
[FLINK-1123] Add first-n to Scala API,1
[FLINK-1120] Add Explicit Partition/Rebalance Operator for Scala API,1
Update doc with Scala First-N and Partition/Rebalance,2
Added TPCH query examples for Scala APIImproved Java TPCH query examplesRemoved RelationalQuery Java API example,4
[FLINK-1005] Extend TypeSerializer interface to handle non-mutable object deserialization more efficiently.,0
[FLINK-1005] Add non-object reusing variants of key-grouped iterator.Clean minor javadoc errors.,0
[FLINK-1005] Make GroupReduce configurable to use either mutable or immutable object mode,1
"RAT plugin not inhertited, to prevent redundant checks.",2
[FLINK-1072] improved build matrix,1
add shading for guava,1
"Major depedendency cleanups  - add ""flink-shading"" for shaded libraries (currently guava only)  - relocate guava in all projects and exclude it from the lib and exported dependencies  - Exlude unnecessary transitive dependencies from hadoop 1",2
Deactivate shade plugin for quickstart projects,2
"[FLINK-1117] Clean up flink-avro project: remove deprecated AvroRecord format, migrate tests to new java api.",1
- Allow dependencies to retain guava- Clean dependencies in flink-streaming connectors,2
[FLINK-1118] Exclude log (and crash) files from rat checks.,2
[scala] Simplify Operation Classes: No more Impl Classes,5
Fix guava dependency in flink-streaming-core to allow IDE local testing.,3
[FLINK-514] Fixed javadoc problems,0
[FLINK-514] Fix additional javadoc problems and add suppressions for certain compiler warnings.,2
"[streaming] Added CoBatchReduceInvokable, CoWindowReduceInvokable, CoGroupedBatchReduceInvokable, CoGroupedWindowReduceInvokable",5
[streaming] Reduce and GroupReduce invokable refactor and performance tweak,4
[streaming] ConnectedDataStream API  and operator cleanup + modified windowReduceGroup functionality,1
[streaming] Improved tests for CoReduceInvokables,3
Guava shading issue fix for Eclipse,0
[FLINK-1124] Remove redundant HTML close tag,4
Repair guava dependencies,5
Guava shading fixes for eclipse and IntelliJ,0
[FLINK-1133] TypeExtractor resolves also variables inside Tuple-input,0
[FLINK-1133] TypeExtractor now also supports nested Tuple-input derivationThis closes #137,1
Move DeltaIteration Sanity Check to Base OperatorsIs now in JoinOperator and CoGroupOperator. We don't needthe special Scala API sanity check anymore now since theyuse java operators that now correctly check in the baseclass.,1
Add an object-based variant of the solution set,1
"[FLINK-12] Clean up configuration object  - Remove class loader (was inconsistently used and set)  - Objects are stored in their type, rather than as a string",1
Add flag for unmanaged solution set to spargel,1
[FLINK-1110] Framework for collection-based execution,1
[FLINK-1110] Fix MapOperator execution and added simple test,3
[FLINK-1110] Implement collection-based Cross,2
[FLINK-1110] Implement broadcast variables for collection-based execution,2
[FLINK-1110] Add execution on collections for flatMap,1
[FLINK-1110] Add Collection-Based execution for Reduce OperatorsAlso fix some bugs resulting from moving stuff between packages,4
"[FLINK-1110] Implement collection-based execution for mapPartition.Make groupReduce code compliant with pre-java-8 versions, fix java8 tests with moved type information classes.Fix Various warnings.",2
[FLINK-1110] Implement collection-based execution for bulk iterations,2
[FLINK-1110] Started implementing the JoinOperatorBase.Implemented JoinOperatorBase and test cases.,3
[FLINK-1110] Add createCollectionEnvironment for Scala,1
[FLINK-1110] Implement collection-based execution for coGroup,2
[FLINK-1110] Adjusted test base to run programs both with local executor and collection executor,1
[FLINK-1110] Implement Collection-Based Execution for Delta Iterations,2
"[FLINK-1110] By default, collection-based execution behaves mutable-object safe.",2
[FLINK-1110] Adjust tests and fix various issues in the collection-based execution.,0
[FLINK-1110] Fix IndexOutOfBoundsException in ListKeyGroupedIteratorOccured when calling nextKey() and iterator not consumed with *last* key group.,2
[FLINK-1110] Fix Reduce and GroupReduce Test Failures,0
[FLINK-1110] Fix mutable object safe mode for data sources in collection-based execution,5
[FLINK-1110] Add iteration aggregators to collection based execution,1
[FLINK-1110] Fix HadoopInputFormat to work without prior serialization.,1
[FLINK-1110] Adjust collection based runtime and tests for classloaders in runtime context,1
[FLINK-1134] tried to fix issue with not terminating JVM when using RemoteCollectorOutputFormatThis closes #138,1
[streaming] Excluded unused recursively pulled dependenciesConflicts:flink-addons/flink-streaming/flink-streaming-connectors/pom.xml[streaming] Connectors POM formatting fix,0
Integration of new BLOB service.Looped through the user code class loader from the envrionment to the tasks.Added timed cleanup task to LibraryCacheManager to remove automatically unreferenced jar files. Moved registration logic out of the IOReadableWritable serialization logic. Updated logger.Made the LibraryCacheManager an object instead of a Singleton.Added proper shutdown of task manager and job manager.Removed nio import to support Java 6 compilation.Removed lock map from BlobLibraryCacheManager. Using global lock for synchronization. Marked StackOverflow code. Removed JavaDocs copyright message. Added getUserCodeClassLoader to AbstractInvokable class.This closes #126 and closes #107.,1
[FLINK-1106] Deprecate Record API,2
"Updated run-example quickstart (commands, screenshots)This closes #136",2
[streaming] Several bugfixes and doc updates,5
[FLINK-1103] [streaming] Added Twitter streaming example and default inputs for examples,1
[streaming] CoWindow operator rework + stream iteration example added,1
[FLINK-1032] Rework support for POJO types in the Java API,1
Added expression keys to distinct and partition operator and addressed some of the comments,1
Add Pojo support to Scala API,1
"Various fixes- improved error messages- the composite vs atomic bug aljoscha found- Comparator test for Pojo Comparator enabled- TODO removed- string-based key expression for group sorting fields definition- support for specifying ""select all"" using * and now also _ (for scala fans)- Exception if user is having multiple fields with the same name in the class",1
Documentation and fixes,0
"Really add POJO support and nested keys for Scala APIThis also adds more integration tests, but not all tests of the Java APIhave been ported to Scala yet.",3
"Added wrappers for Hadoop functionsTests and documentation included. Also tested on cluster.I hijacked @twalthr's PR #131 to build the documentation of the Hadoop function wrappers on top.Author: Fabian Hueske <fhueske@apache.org>Author: Artem Tsikiridis <artem.tsikiridis@cern.ch>Author: twalthr <info@twalthr.com>Closes #143 from fhueske/hadoopFunctions and squashes the following commits:f1b3f21 [Fabian Hueske] [FLINK-1076] Extended Hadoop Compatibility documentation to cover Hadoop functionsf4be4a0 [twalthr] [FLINK-1107] Hadoop Compatibility Layer documented4a62bdb [Fabian Hueske] [FLINK-1076] Return type determined via type extraction. Added test cases. Minor improvements and clean-ups.df947d9 [Artem Tsikiridis] [FLINK-1076] Extend Hadoop compatibility. Added wrappers for stand-alone Map, Reduce, and CombinableReduce functions.",1
"Revert ""Added wrappers for Hadoop functions""This reverts commit 74dded1c2cb87c459be3444d1c7387bbc510e154.",4
"[FLINK-1076] Extend Hadoop compatibility. Added wrappers for stand-alone Map, Reduce, and CombinableReduce functions.",1
[FLINK-1076] Return type determined via type extraction.Added test cases.Minor improvements and clean-ups.,4
[FLINK-1107] Hadoop Compatibility Layer documentedThis closes #131,2
[FLINK-1076] Extended Hadoop Compatibility documentation to cover Hadoop functions,1
[FLINK-1136] Replaced Flink logo in web submission clientAdded Flink logo to JobManager web interface.Updated Run Example Quickstart screenshotsRemoved old gradients and unused image files from submission client.This closes #145.,2
[FLINK-1145] Fix incorrect getter / setter detection,1
Fixed missing logo in offline plan visualizer,2
[FLINK-1149] DataSource sets DOP to 1 for NonParallelInputs.,1
[FLINK-1150] Fix size estimate for FilterNode. Data size changes proportional to cardinality.This closes #146,4
"Simplify Pojo/Tuple/CaseClass comparator extractKeys() methodAlso fixes a bug with Java/Scala interop: TupleTypeComparator was only checkingfor nested Java Tuples and Pojos, not Scala Case classes.",0
[scala] Add missing operator IT Cases,1
[YARN] Fix issue with port-offsetting.,1
[doc] Fix javadoc building.The java8 Xdoclint:none fix was not correctly transferred when movingthe javadoc building to a jekyll plugin.,2
[doc] Update programming guide for scala expression keys,5
"Fix bug in Blob Manager, Cleanup Timer was not cancelled on Shutdown                                          -",4
Remove Guava dependecy from streaming-connectors (void shading otherwise),4
Enable forgotten JoinITCase (for POJOs) for Scala and Java API,5
Set the cleanup timer thread of the BlobLibraryCacheManager to be a daemon.,4
Fix class loader when extracting lambdas,4
Fix various deprecation warnings in tests,3
[FLINK-1143] Allow delta iterations that do not join with the solution set,1
"[FLINK-1148] Create a writeAsCsv(path, writemode) variant",1
[FLINK-1152] More robust resource release when tasks are canceled during deployment,2
Better test error messages when canceling tests fail,0
JoinHints are passed to the optimizer,4
Optimizer evaluates join hints from high level apis.,5
Fix incorrect scheduler test that sometimes produces a deadlock,3
"[scala] Change input of grouped ops from TraversableOnce to IteratorIterator is a subclass of TraversableOnce, so it doesn't break existingcode. We can have an Iterator anyways and it provides more functions forthe user.",1
[streaming] CoGroupedWindowReduceInvokable refactor[streaming] Grouped window reduce bugfix,0
[streaming] Added a TypeWrapper which combines two TypeInformations into a Tuple2 TypeWrapper.,5
[streaming] Added CoBatchedDataStream and CoWindowDataStream with reduce functionality + CoBatchReduce bugfix[streaming] RAT & Checkstyle fix,0
[FLINK-1160] Method added to RecordReaders to allow publishing events to specific inputs,1
Fix the Javadoc link in DataStream classFix the Javadoc link for org.apache.flink.api.common.functions.RichFunction and missing method reference in DataStream class.Author: Henry Saputra <henry.saputra@gmail.com>Closes #154 from hsaputra/fix_comments_streaming and squashes the following commits:127e47a [Henry Saputra] Fix the Javadoc link for org.apache.flink.api.common.functions.RichFunction and missing method reference.,2
[FLINK-1170] Fix faulty input split localizationPass hostname to split assignerAvoid clashes by only using the first component of the fully qualified hostname,1
[FLINK-1170] address pull request review commentsThis closes #158,1
Prevent RPC service from blocking on exceptions during task cleanup on canceling.,4
[FLINK-1171] Move Scala API tests to flink-tests projectThis closes #159,3
[FLINK-1164] Gracefully handle empty (identity) iterations,0
[FLINK-1167] Handle unions at the root of the iterationThis closes #160,0
[scala] Change CaseClassSerializer/Comparator to not use For-Loop,1
[build tools] update release sciprts,5
Set version to 0.8-incubating-SNAPSHOT,1
[FLINK-1189] [streaming] Added cross operatorConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/ConnectedDataStream.java,5
[FLINK-1189] [streaming] Temporal cross refactorConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/ConnectedDataStream.java,5
[FLINK-1175] [streaming] GroupBy updated to allow multiple field and keyselector groupings,1
[FLINK-1188] [streaming] Updated aggregations to work also on arrays by default,1
[streaming] Removed obsolete state objects from streaming-core,4
[FLINK-1185] [streaming] OperatorState and StateCheckpoint classes and implementations added for state checkpointing and rebalancing,1
[FLINK-1187] [streaming] StreamingRuntimeContext added with API support for registering fault tolerant state objects for the operators,1
"[FLINK-1178] Changed type preference to ValueType, WritableType, CaseClassTypeThis closes #162",4
Remove unnecessary final modifier in PlanExecutor.loadExecutorClass methodRemove unnecessary final modifier in PlanExecutor.loadExecutorClass private static method because private means you can not override this method.Author: Henry Saputra <henry.saputra@gmail.com>Closes #163 from hsaputra/remove_unneeded_final_privatetatsic_planexecutor and squashes the following commits:fe7afc7 [Henry Saputra] Remove unnecessary final modifier in PlanExecutor's private static method.,4
[FLINK-1194] Fix Java quickstart archetype POM fileThis closes #165,2
Add DeltaPageRank example,1
[FLINK-1182] Improve error messages for POJO type mismatches,0
[FLINK-1181] Fix IOReadableWritable checks in RPC serviceThis closes #167,0
Fix version and download paths in docs config,5
[docs] Various fixes in docs  - corrected links to download page  - corrected download urls  - corrected wget shortcut for yarn setup  - corrected links to faq in yarn setup  - corrected guide for manual yarn build  - FAQ layout,1
Another round to remove final modifier to private methods because it is not neededRemove final modifier to private methods because it is not needed.Those methods are final by default.Author: Henry Saputra <henry.saputra@gmail.com>Closes #168 from hsaputra/remove_final_privatemethods_1 and squashes the following commits:860b512 [Henry Saputra] Remove final modifier to private methods because it is not needed. It is final by default.,1
[FLINK-1203] Deactivate fork reuse in tests (workaround for potential surefire bug)This closes #174,0
[FLINK-1202] Remove incomplete file outputs on failureThis closes #175,0
Remove obsolete collection execution example.Correct remote collector format example.,4
Implement coarse-grained fault tolerance,5
Introduce a delay before restarts to make sure that taskmanager failures are detected before restart.,0
Improve error messages in case of invalid file paths or URIsThis closes #170,2
Make sure TaskManager does not accept task deployments when shutting down,1
[FLINK-1205] Fix library cache manager to track references to tasks and revent accidental duplicate registration/deregistration,0
"[FLINK-1203] Use forked execution in all tests, except in the end-to-end integration tests in flink-tests",3
[FLINK-1198] Broadcast variables are shared between tasks in the same TaskManager,2
"[FLINK-1198] Make Broadcast variables shared per taskmanager, rather than a shared singleton per JVM             (supports multiple TaskManagers in the same JVM)",1
[FLINK-1198] Broadcast variables can share initialization via broadcast variable initializers,5
[FLINK-1198] Fix nullpointer exception in broadcast variable materialization,0
Make sure that operator names are properly escaped for display in the web client,1
Temporarily disable fork reuse in flink-tests Unit tests (workaround for FLINK-1207),2
[doc] Fix programming guide link in iterations.md,2
[FLINK-1210] Improve error message in delta iterations when the next workset does not depend on the workset,1
[FLINK-1174] [streaming] Added window join operator,1
[streaming] Enhanced BufferTimeout functionality for StreamRecordWriter,1
"Change TypeExtractor to support interfaces within classesBefore, the pojo analyzer would try to analyze a field of type Listor Map and fail. Now we catch the exception and create a GenericTypeInfofor the enclosing class because the avro serializer can in factserialize objects that have fields of interface type.",1
[scala] Add macroparadise to enable Quasiquotes,0
"[FLINK-1191] Add support for Scala Collections and Special Types""The special types"" are Option and Either. This should work for allScala collections except SortedSet and SortedMap, for which the typechecker prints an error message.",0
[scala] Make getType public in Scala DataSet,5
[scala] Add union operation to Scala ExecutionEnvironment,1
"[FLINK-1005] By default, new objects are created for each element in group operations",1
[FLINK-1214] Prevent partitionings on subsets of fields from being pushed down,1
"Add test case for TaskManager connection loss, leading to task failure.",0
[FLINK-1220] Promote various log statements to INFO level. Add log statements for assignment locations,2
[FLINK-1222] Tasks send close acknowledgements early.,2
"[runtime] In local mode, make sure taskmanagers have completed registration before starting a job.",1
[FLINK-1215] Fix spurious failures when creating output directories due to I/O races,1
[streaming] Updated streaming groupBy operators to allow grouping on field expressions,1
[streaming] Aggregation rework to support field expression based aggregations for Pojo data streams,5
[streaming] Pojo wordcount example added to streaming,1
[FLINK-1224] [streaming] getExecutionEnvironment method fixed to work properly for StreamExecutionEnvironment,1
[Flink-1113] clean up JQuery dependenciesThis closes #178,4
[FLINK-1212] Fixed shell script interpreter directiveThis closes #180,0
[FLINK-1213] Added .gitattributes to normalize EOL[FLINK-1211] Fixed EOL character of Windows Batch filesThis closes #181This closes #179,2
[FLINK-1215] Increase robustness to spurious failures when creating output directories,1
Make sure S3 directory paths are suffixed with '/' on creation,1
[FLINK-1186] Fix wrong flat key position when using expression key for nested tuplesThis closes #169,1
"[FLINK-1323] Refactor I/O Manager Readers and Writers to interfaces, add implementation that uses callbacks on completed write requests. - This change also allows for a very simple way of plugging in a synchronous version of the I/O manager.This closes #193.",1
[FLINK-983] Fix WebClient truncated function namesThis closes #190.,1
"[FLINK-1223] Allow value escaping in CSV files- Strings can now contain "" quoted characters- Skip trailing whitespace after quoteThis closes #187.",2
[FLINK-1233] Improve error message when not enough slots are available to schedule a task.             Add additional test case for concurrency on the scheduler.,3
"Improved input type inference, bug fixing, code simplificationThis closes #176",0
[FLINK-1235] Compiler accepts iterations referenced from the static path of other iterations - Fix NepheleJobGraphGenerator to support iterations referenced on the static path of another iteration - Catch nested iterations on dynamic path properly in optimizer (and give a good error message),0
[FLINK-1226] Add API support for passing Configurations to InputFormatsThis closes #196,5
[FLINK-1230] Add documentation and an example for collection-based executionThis closes #195,2
[FLINK-1221] Use the source line as the default operator nameThis closes #197.,1
[streaming] Removed obsolete Join example,4
"[FLINK-1204] [streaming] Individual, self-contained packaging for streaming examples",2
[streaming] StreamExecutionEnvironment rework + user class loader fix for cluster deployment,0
[streaming] Example cleanup + windowJoin fix,0
[streaming] Examples refactor and packaging update,5
Fix caching of receivers,0
[scala] Self-contained build for scala examplesThis closes #199.,5
[FLINK-1218] Replace new Integer with Integer.valueOf in testsThis closes #183.,3
[FLINK-1239] [streaming] IterateExample fix and parallelism setting in StreamExecutionEnvironment made publicConflicts:flink-addons/flink-streaming/flink-streaming-examples/src/main/java/org/apache/flink/streaming/examples/iteration/IterateExample.java,5
[FLINK-1233] Fix flaky AggregateITCase,0
[docs] Add description of Quasiquotes compiler plugin in Eclipse to FAQ,1
[FLINK-1242] Fix streaming-examples and scala-examples POMs to work properly with Eclipse,1
"[FLINK-1008] Fix createProgramPlan() throws exceptionProblem was, that ExecutionEnvironment#getExecutionPlan clears the datasinks, i.e. a following ExecutionEnvironment#execute will throw an errorbecause there are no data sinks.This introduces a new flag for ExecutionEnvironment#createProgramPlan toindicate, that the the sinks shall not be cleared.This does not break any existing code.This closes #184",4
[FLINK-890] [docs] Adjust examples to show reader methods and correct class-vs.-interface errors.,0
[FLINK-1244] setCombinable() returns operatorThis closes #205,1
[FLINK-1172] [docs] Fix broken links in documentationThis closes #206,2
Fix flaky test SumMinMaxITCase,3
[FLINK-1246] Add additional debug output to flaky recovery test,3
[tests] Various stability fixes to tests,3
[build] Manage version of joda-time to prevent conflicts between dependencies.,5
[FLINK-1207] Context environments are realized through factories  - local execution blocking is reset after each run,1
"[FLINK-1237] Add support for custom partitioners  - Functions: GroupReduce, Reduce, Aggregate on UnsortedGrouping, SortedGrouping,               Join (Java API & Scala API)  - Manual partition on DataSet (Java API & Scala API)  - Distinct operations provide semantic properties for preservation of distinctified fields  - Tests for pushown (or not pushdown) of custom partitionings and forced rebalancing  - Tests for GlobalProperties matching of partitionings  - Caching of generated requested data properties for unary operatorsThis closes #207",1
[bin] Remove MaxPermSize parameter for JVM 1.8This closes #200.,2
[FLINK-1209] [compiler] Improve error messages when forgetting to close an iteration,1
[FLINK-1250] [config] [docs] Correct and document config keys for heartbeat intervals and timeoutsThis closes #212,5
[FLINK-1247] [docs] Fix broken links in documentationThis closes #213.,2
Minor code clean up to get rid of IntelliJ IDEA warningsThis closes #214.,2
Add byte array serialization to InstantiationUtil,1
Added getExecutionEnvironment to the DataSet of the Scala API.,5
[FLINK-1254] [compiler] Fix compiler bug for pipeline breaker placementThis closes #216,4
[FLINK-1253] [tests] Make sure tests do not die with garbage collection overhead exceededThis closes #217,3
[FLINK-933] Add primitive input format to read a sequence of primitivesThis closes #47,1
[FLINK-993] Primitive input format fails for invalid input. Adapted documentation.,2
[streaming] Source parallelism API updateThe new preferred way is calling setParallelism() after adding the SourceFounction. This solution works any other operator.,1
[streaming] Fixed async buffer sending at end of AbstractInvokable,0
[FLINK-1142] Log information about I/O manager temp dirsThis closes #219.,5
Minor code clean upThis closes #221.,4
[FLINK-1252] Add support for serializing Date and Enums in the Java API,5
[FLINK-1251] Enums are now handled properly by the collection input format,0
[FLINK-1252] address pull request commentsThis closes #215,1
Added binary input and output format which uses the objects' TypeSerializer to serialize them.Added InputTypeConfigurable to TypeSerializerOutputFormat to support a more seamless integration.This closes #218.,1
[FLINK-1265] Fix user classloader bug for registerInputOutput() method,0
[Flink-1262] inconsistency between CsvReader.java and TupleGenerator.javaThis closes #222,2
[FLINK-1264] [compiler] Properly forward custom partitioners to the runtime,1
[FLINK-820] [compiler] Support for disconnected data flows,5
Removed object reusage in GenericArraySerializer's deserialize method.,4
Log memory usage stats at INFO level instead of DEBUG,0
[APIs] Enhance test coverage for CollectionInputFormat and add tests for failed serializations of user code objects,1
[FLINK-1263] [optimizer] Implement compatibility checks for binary operators and custom partitioningThis closes #223,1
Minor code cleanups - left from previous patchesThis closes #225,4
[FLINK-1173] [streaming] Add socket text stream as a data source for the streaming API,5
[FLINK-1173] [streaming] SocketTextStream minor fixes + documentationThis closes #204,2
Fixes FLINK-1276Closes #229,2
[FLINK-1249] [APIs] [compiler] Add custom partitioner for CoGroupThis closes #228.,1
[FLINK-1221] Use only method name and location as default operator names,1
[FLINK-1221] Use StackTraceElement methods instead of String parsingThis closes #231.,1
Small changes and tests for the newly introduced EnumTypeThis closes #230.,1
[Java API] Fix various warnings,2
[FLINK-658] [APIs] Add group sorting to CoGroupThis closes #234,1
[runtime] Quick fix for error with unsupported ship strategy,1
[FLINK-1282] [docs] Update layout of docsThis closes #235.,2
[FLINK-1286] [APIs] [runtime] Fix serialization in CollectionInputFormat and generate meaningful error messages,0
[FLINK-1278] [runtime] (part 1) Remove special code paths for the Record data type in the input readers and the source task.,5
[Scala API] Case Class serializer can work with classes that cannot be instantiated empty,1
[FLINK-1282] [docs] Added {{ site.baseurl }} to css and image paths,1
[FLINK-1282] [docs] Make Flink logo link back to frontpageThis closes #237.,1
[FLINK-1234] Activate hadoop2 profile by defaultThis closes #232,2
[scala] Add ClosureCleaner for Scala Lambdas,4
[docs] Fix paths to work with local buildsLocal builds of the docs without a web server (e.g. ./build_docs.sh -p)were not working. This commit fixes this.,0
[runtime] CaseClassSerializer correctly treated as stateful,1
[scala] Fix slow building of adjacency list in Scala PageRank,0
Rewrite TPC-H Q3 to use Long instead of IntegerBoth Java and Scala version fixed.,0
[scala] Add equals() to TraversableTypeInfo,5
Removed TypeSerializerFactory from ScalaCsvInputFormat. The TypeSerializer is now serialized directly.,4
[FLINK-1270] [APIs] FS.get() supports relative pathsThis closes #224,1
[FLINK-1095] [clients] Remove '-d' option in info from CliFrontendThis closes #238,5
[FLINK-1273] [runtime] Add Void type to basic typesAdd optional test for external sorting of case classes.Fix various warnings.,2
Upgraded HBase addon to HBase 0.98.x and new Tuple APIs,1
[FLINK-1290] Fix Optimizer to create plans when encountering incompatible partitionings.,1
[scala] [runtime] Add extra tests for sorting of case classes,3
[Docs] Just a typo in docs/index.mdThis closes #242,2
[FLINK-1291] Remove default GC options from the shell scriptsThis closes #240.,4
[FLINK-1154] Quickfix to kill TaskManagers in YARN mode.This closes #233,0
[FLINK-984] Compiler tests for distinct(). Adopted the old code from @markus-hThe code originates from https://github.com/apache/incubator-flink/pull/61.The pull request also contained code to add POJO support to the distinct() operator. This has already been implemented in earlier work,1
[Docs] Fix rendering issue and typo,2
[FLINK-1292] Allow for longer normalized keys when using composite keysThis closes #241,1
[Java API] [docs] Rephrase Javadoc of minBy/maxBy and link from min/maxThis closes #244.,2
"[FLINK-1157] Document TaskManager slots and minor fixes.- Move some background on the most important configuration values into the configuration guide- Remove the term ""UDF"" because it is often being confused with UDFs in SQL- Fixe some typos",2
[streaming] Introduced a new invokable to allow flexible windowing based on trigger and eviction policies. Additionally created all required policy interfaces.,1
[streaming] Added interface for policy helpers. Such helpers will allow to use policy based windowing through a simpler API.,1
[streaming] Created trigger and eviction policies based on element counters. Included respective policy helper and test cases.,3
[streaming] Introduced extractor interface to enable flexible handling of arbitrary input data types.,5
[streaming] Created active trigger and eviction policies based on time. Included respective policy helper and test cases.,3
[streaming] Added extractor implementations for various extractions and conversions. (incl. test cases),3
[streaming] Created trigger and eviction policies based on data punctuation. (incl. test cases),3
[streaming] Created tumbling eviction policy. This policy evicts always all tuples after a trigger occurred. It can be used to prevent doubled computation between trigger and eviction policies whenever tumbling windows are used. (includes test case),3
[streaming] Created trigger and eviction policies which calculate a delta between two data points using a given delta function. The policies evict/trigger in case the delta is higher than a specified threshold. (incl. test case and the interface for delta functions),1
[streaming] Added abstract class ExtractionAwareDeltaFunction to enable easy extraction of data in pre-defined delta functions.,1
[streaming] Added cosine distance and Euclidean distance as examples for possible delta function implementations. Test cases are included as well.[streaming] Added policy helper for delta policies to provide a simpler API for such policies.[streaming] Created ActiveEvictionPolicyWrapper. This eviction policy wrappes around a non-active policy and makes it active by forwarding notification on fake elements to the regular notification method.,1
[streaming] Integrated the policy based windowing into DataStream and introduced WindowedDataStream to handle windowing helper.,0
[streaming] Added test cases for the policy based windowing invokable.,3
[streaming] Created several examples for the usage of policy based windowing.[streaming] Fixed windowing examples by removing manual setting of source parallelism[streaming] Extended streaming guide with a section about the new policy based windowing.,1
"[streaming] Introduced grouped windowing invokable, added required cloneable policy interfaces, and adjusted existing windowing invokable to make it usable together with the new grouped windowing invokable.",1
[streaming] Make all predefined policies cloneable and introduce an activating wrapper for cloneable eviction policies,1
[streaming] Adding unit tests for the grouped windowing invokable.,3
[streaming] New windowing API merge and cleanup + several minor fixes,0
[streaming] Extractor requirement removed for custom timestamp windowing,4
[streaming] Windowing API update + package refactor,4
[streaming] Window join api rework to support functional style,1
[streaming] Changed time based windowing policies to make lower boundary excluded and upper boundary included in the windows and adjusted policy test cases respectively.,3
[streaming] Windowing helper API cleanup,4
[streaming] Window cross API rework,1
[FLINK-1279] [streaming] Forward partitioning changed to use round-robin method,1
[streaming] Renamed test cases for window and grouped window invokable to be consistent with the invokable names,3
[streaming] Introduced central eviction policies in the grouped window invokable[streaming] Extended test cases for grouped window invokable to cover usage of central eviction policies,3
[streaming] Central trigger/eviction API integration + invokable refactor,4
[streaming] Updated javadocs for new windowing semantics[streaming] Updated streaming-guide to match recent api changes,4
[streaming] Changed GroupedWindowInvokable to always delete groups in case they have an empty element buffer,4
[docs] [streaming] Windowing rework documentation update,5
"[scala] Fix non-reuse copy in CaseClassSerializerBefore, it was not doing a proper deep copy of the fields.",1
[scala] Fix TupleSerializerTest for corrected CaseClassSerializer,3
"[FLINK-1301] Added Apache license headers to Markdown, HTML, SVG, Python files.Made exceptions for license check plugin more fine-granular.This closes #250",2
[FLINK-1139] Added FinalizeOnMaster hook to run code after the last task of an OutputFormat completed,1
[FLINK-1139] Fixed HadoopOutputFormat to run with DOP > 1This closes #173,1
[FLINK-1139] Updated Hadoop Compatibility documentation,2
[FLINK-1311] [optimizer] Correctly tag static/dynamic path for auxiliary nodes in iterations.,2
[FLINK-1161] [streaming] Streaming API type handling rework to support java 8 lambdas,1
[FLINK-1312] [streaming] OutputSelector changed to SAM-type to allow java 8 lambdas for splitting,1
[streaming] Java 8 WordCount example added for streaming[streaming] Documentation added for streaming java 8 support,1
Updated java 8 package to match flink-examples standardsRenamed org.apache.flink.example package to org.apache.flink.examplesDefault data is provided from flink-java examples,2
[FLINK-1315] [optimizer] Extra test reproducing the IllegalStateException bug in bulk iterations.,0
[FLINK-1315] [optimizer] Fix bug in branch tracking logic.,2
[FLINK-1316] [web client] Fix plan display for nodes referenced from multiple closures.,0
[java8] Fix pom.xml to properly work with Eclipse m2e,1
[FLINK-1040] Make types() call in projections optionalThis closes #194,1
[FLINK-1040] Updated JavaDocs and removed deprecated types() calls from examples and tests,3
Fixed java quickstart examplejava complains about not expecting an interface here. Needs to be `implements` instead of `extends`.This closes #257,0
[scala] Add withParameters() support for sinks/sourcesThis closes #261.,1
[FLINK-1310] Change ClosureCleaner Logging to DEBUGThis closes #262.,0
Enable flink-hbase module for hadoop1 build as well.This commit is based on a diff by @fpompermaier (see https://github.com/apache/incubator-flink/pull/220).This closes #220,2
[FLINK-1302] Make JDBCInputFormat implement the NonParallelInput interface,5
"[FLINK-998] Close TCP connections after destroying logical channels- This commit introduces reference-counting to keep track of the  InputChannel and OutputChannel instances, which share the same  physical TCP connection.- When the logical channels are released, the reference count will  reach 0 and the respective TCP connection can safely be closed.- Furthermore, the debug thread in the OutboundConnectionQueue is  properly shut down and all queued buffers are freed when the  channel is closed or an Exception occurs.This closes #255.",0
Exclude docs/_site/** from License Check,2
[FLINK-1287] LocalizableSplitAssigner prefers splits with less degrees of freedomThis closes #258,2
[FLINK-1208] Enable CsvInputFormats to ignore invalid lines and lines starting with commentsThis closes #201,0
[FLINK-1324] [runtime] Trailing data is cached before the local input strategies are closed.,5
[FLINK-1322] Make Scala API respect WriteMode set in ConfigThis closes #266,5
[scala] Change ScalaAggregateOperator to use TypeSerializerThis closes #263,1
[misc] Fix/suppress various compiler warnings.,2
[FLINK-1305] [FLINK-1304] Test for HadoopInputWrapper and NullWritable supportThis closes #252,1
[FLINK-1307] Allow file input from nested directory structureThis closes #260,2
[FLINK-1307] Excluded directories that match the file-filter from recursive descent.,2
Fixes broken code highlighting in documentation,2
[FLINK-1327] [core] Fix wrapping of MemorySegments in ByteBuffers,0
[streaming] Basic support reading from local and distributed file systems in readTextFile methodsConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/JobGraphBuilder.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java,5
[streaming] ReadTextFile re-implemented as RichFunction and cleanupConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java,5
[Runtime] [Tests] Remove flaky check in LocalInstanceManagerTest,3
[Distributed runtime] Fail task if execution state update is unsuccessful,5
[Java API] Fix equality checks on PojoTypeInfo,5
[APIs] Add ExecutionConfig,5
[FLINK-1325] [Java API] Add Java ClosureCleanerThis closes #269,4
[FLINK-1325] [Java API] Minor cleanups on the ClosureCleaner,4
Bump version to 0.9-incubating-SNAPSHOT,5
[streaming] DataStream print functionality updatePrintSinkFunction now explicitly states threads in outputAdded printToErr functionality,1
"[streaming] [examples] Refactor and packaging for windowing examplesThe current examples show-case the API, more meaningful examples are coming for the 0.9 release.",4
[streaming] Updated deprecated iterative functionality and docs,2
[FLINK-1325] [streaming] Added clousure cleaning to streamingThis closes #273,4
Fix invalid type hierarchy creation by Pojo logic,2
[FLINK-610] Replace Avro by Kryo as the GenericType serializerThe performance of data-intensive jobs using Kryo is probably going to be slow.Set correct classloadertry to use Kryo.copy() with fallback to serialization copy,1
[FLINK-1333] Fixed getter/setter recognition for POJOsThis closes #271,1
Fixes race condition in ExecutionGraph which allowed a job to go into the finished state without all job vertices having properly processed the finalizeOnMaster method.,5
[FLINK-1336] [core] Fix bug in StringValue binary copy method,0
Added configuration constants for akka's actor system.,5
Reworked the NepheleMiniCluster logicadded further communication logic to jobmanager and taskmanager.,2
Reworked the EventCollector and the ArchiveListener as actors.Replacing the EventCollector and the MemoryArchivist.Finished EventCollector and adjusted ExecutionGraph and ExecutionVertex to register actors as listeners.,5
Reworked the TaskManager.Changed RuntimeEnvironment and TaskInputSplitProvider to work with ActorRefs.,1
Implemented JobManagerProfiler and TaskManagerProfiler as actors.Renamed NepheleMiniCluster to FlinkMiniCluster.,5
Removed proxis from JobClient and CliFrontend.,4
Removed old RPC service.,4
Ported the JobManagerITCase to actor implementation.,5
Updated all JobManager and TaskManager relevant test cases to work with actors.,1
Removed legacy protocol classes.,4
Updated license headers of scala files to conform to scala-checkstyle.,5
Removed execution service from execution graph and replaced by akka's futures.,4
Replaced the JobClient by an actor.,5
"Removed old java implementations of the JobManager, TaskManager, JobClient, EventCollector, TaskOperationResult and MemoryArchivist.",4
Adapted Webserver to work with actors.,1
Added the webserver to the job manager.,1
Removed old events. Adapted webserver communication so that it can now talk to the actor implementations.,4
Added AKKA_LOG_LEVEL config constant.,5
Added scala docs to actor messages.,2
Removed listen parameter from SubmitJobDetached message.,2
Reworked Yarn client: Actor based communication.,1
Moved WebInfoServer and WebInterfaceServer resources into resource folders of respective projects. Jetty uses the jar as base directory.,1
Implemented proper shutdown of yarn containers if the system is shutdown via the yarn client.,5
Resolved scala checkstyle issues.,0
"Updated DEPENDENCIES, NOTICE and LICENSE files.",2
Adding timefactor to make up for slow travis tests.,3
Removed blocking call in Execution.deploySlot,4
Removed submitTask and cancelTask from Instance. Replaced unnecessary blocking calls.Fixed ExecutionVertexCancelTest after removing submitTask and cancelTask.,4
Reworked local cluster start. TaskManager watches JobManager and tries reregistration in case of disconnect. Introduced akka.ask.timeout config parameter to configure akka timeouts.,5
Adapted test cases to actor model after rebasing.,3
Fixed JobManagerITCase to properly wait for task managers to deregister their tasks. Replaced the scheduler's execution service with akka's futures. Introduced TestStreamEnvironment to use ForkableFlinkMiniCluster for test execution.,3
Removed JobStatusListener and ExecutionListener. Fixed LocalExecutor output for maven verify.,0
Removed dead instance cleanup from InstanceManager so that Akka's watch mechanism is the current mean to detect dead instances.,4
"Made ExecutionGraph, Execution, ExecutionJobVertex, ExecutionVertex, AllocatedSlot, Instance, CoLocationConstraint, SharedSlot and SlotSharingGroupAssignment serializable. Integrated Kryo to be used to serialize Akka messages.",1
Add debug guardians to suppress string generation which caused a significant performance loss.,1
Add startup timeout config parameter. Increase akka ask timeouts for integration tests. Increase akka logger startup timeout.,2
Use container based builds in travis. Enable caching for travis. Set travis fork count to 2.,1
Change integration tests to reuse cluster in order to save startup and shutdown time.,1
Add option to use single actor system for local execution. Use local connection manager if a single task manager is used for local execution. Remove synchronized blcok in getReceiverList of ChannelManager which effectively serialized the connection lookup calls of a single task manager.Fix Java6 problem that File has no method toPath,2
Execute lookupConnectionInformation and UpdateTaskExecutionState concurrently within futures,5
Exclude netty and protobuf dependency from hadoop-commons-2.0.0-alpha,5
Use Akka version 2.2.1 for hadoop version 2.0.0-alpha to resolve dependency conflicts. Adjust code to comply to respective Akka API. Remove obsolete TODO.,2
Exclude netty dependency from hadoop-mapreduce-client-core to resolve dependency conflict,5
Remove experimental KryoSerialization for Akka,4
Fix race condition in ExecutionGraph which made the job finish before all vertices have called the finalizeOnMaster method.,5
Add proper task resource removal in case that a task submission fails,0
Let the submitJobAndWait method check continuously whether the job manager is still alive. Terminate waiting for a response in case of a job manager outage.,5
[streaming] StreamInvokable rework for simpler logic and easier use,1
[dist] Updated the assembly of the examples subdirectoryExcluded the scala example jarsExcluded the example source code subdirectoriesThis closes #274,5
[streaming] Added immutability for window and filter operators,1
[streaming] Make windowed data stream aware of time based trigger/eviction in tumbling window situations.[streaming] Changed TimeEvictionPolicy to keep timestamps in the buffer instead of data-items,5
[streaming] Streaming local execution fix to create proper jobclient for minicluster,5
[FLINK-1338] Updates necessary due to Apache graduationRemoved Disclaimer fileEliminated unnecessary incubating substringsBumped version to 0.9-SNAPSHOT,2
[streaming] Time trigger preNotify fix,0
[scala] [streaming] Base functionality added for streaming scala api,1
[scala] [streaming] Extended scala data stream functionality to include simple operators,1
[scala] [streaming] Finished scala StreamExecutionEnvrionment functionality + DataStream sinks + docs,2
[scala] [streaming] Windowing functionality added to scala api,1
[scala] [streaming] Added SplitDataStream functionalityConflicts:flink-scala/src/main/scala/org/apache/flink/api/scala/streaming/DataStream.scala,5
[scala] [streaming] Added support for iterative streams for scala api,1
[streaming] Temporal join and cross rework for consistence and extended features,1
[scala] [streaming] Temporal join operator added,1
[scala] [streaming] Temporal cross operator added,1
[scala] [streaming] Modified aggregations to work on scala tuples,1
[scala] [streaming] Fixed scala formatting,0
[scala] [streaming] Added groupBy support for case class fields,1
[scala] [streaming] WindowJoin scala example added,1
[streaming] Streaming API grouping rework to use batch api Keys,1
[scala] [streaming] Added scala window helpers + timestamp rework for lambda support,1
[scala] [streaming] Added implicit conversions from java to scala streams,1
[scala] [streaming] added group windowing example with different policy types[scala] [streaming] updated example with scala delta helper usage,5
"[scala] [streaming] added initial ConnectedDataStream support (no windowing,batching) for the scala api",1
[scala] [streaming] Added connect op to DataStream and implicit conversion for ConnectedDataStreams[scala] [streaming] Changed return types to implicits,4
[streaming] Source parallelism + connector rework,1
[streaming] Updated connector type handling to suport generic classes by GenericSourceFunction interface,1
[streaming] [scala] Restructured streaming scala project and examplesThis closes #275,5
[docs] Trivial typo in example code: o -> out.This closes #280,2
[FLINK-1338] [docs] Remove incubator footer from docs,2
[docs] Remove files from obolete and unused figures,1
[FLINK-1346] [docs] Add stubs for Akka documentation,2
[FLINK-1335] [docs] Update internals with brief description about JobManager data structures and scheduling.This closes #281,5
Remove full package name for FlatMapOperatorBaseSimple code cleanup to remove full package name for FlatMapOperatorBase for FlatMapOperator#translateToDataFlow methodAuthor: Henry Saputra <hsaputra@apache.org>Closes #272 from hsaputra/remove_packagepath_flatmapoperatorbase and squashes the following commits:8ce5abd [Henry Saputra] Remove full package name for FlatMapOperatorBase for FlatMapOperator#translateToDataFlow method.,5
"[FLINK-1349] [runtime] Various fixes concerning Akka - Remove obsolete code from old IPC net utils - Smaller Writable/IOReadableWritable serialzation buffer start size (most messages are rather small) - For message logging, make system calls (timestamps) only in debug mode - Clean up warnings / code simplifications",2
[FLINK-1349] [runtime] Various cleanups to make scala runtime code interact smoother with java,1
"[FLINK-1335] [docs] Add guide how to set up Eclipse, and bring README.md up to speed.",2
[FLINK-1335] [docs] Minor fix to README file,2
[FLINK-1357] [compiler] Add union between static and dynamic path,1
[FLINK-1027] [cli] Added support for '--' and '-' prefixed tokens in CLI program arguments.This closes #278,0
[FLINK-1236] [hadoop compatibility] Add local split assignment support for HadoopInputFormatsThis closes #267,1
[streaming] Temporal operator windowing syntax update,5
[streaming] Deleted obsolete parts of the connected stream api,4
[streaming] Updated streaming guide for recent connector and data source changes,4
[scala] [streaming] Added package file for streaming scala api typeinfo implicits and conversions,5
[scala] [streaming] added scala streams as sources in streaming-api scala examples,1
[FLINK-1300] [core] Remove unused and redundant files DataInputViewStream and DataOutputViewStream.,5
[FLINK-1259] [apis] Added comments to interface and docs that filters must not mutate date elements.,5
[FLINK-1169] [apis] Add documentation for join hints.,2
[FLINK-1363] [runtime tests] Fix race condition in ExecutionVertexCancelTest.testSendCancelAndReceiveFailThis closes #288,3
[FLINK-1365] Fix ValueTypeInfo,5
[FLINK-1366] Enable FastPath in TextValueInputFormat again,0
[FLINK-1361] change jobManager log file name back to old valueThis closes #286,2
[FLINK-1354] Made test graph for TransitiveClosureITCase smallerThis closes #285,3
[FLINK-1137] Enhance MutableObjectIterator with non-reuse next()This is in preparation for configurable object-reuse mode. We previouslyreferred to this as mutable object vs. mutable object safe mode or somesuch thing.,1
[FLINK-1285] Make execution mode configurable,5
[FLINK-1285] Make Merge-Join aware of object-reuse settingThis closes #259,1
"[FLINK-1285] Various cleanup of object reusing and non-reusing code. - The map driver now also supports this - In the merge iterator (merges sorted runs from external sort), we now always use the non-reusing code path,   because the reusing codepath here implies in all cases additional instances to be held concurrently, and copy   between elements, which voids the benefits of reusing elements. - For many utility iterators (in test cases), consolidates the logic between the two variants of the ""next()""   functions (one calls the other, where possible) - Eliminates a few copies between elements in the non-reusing parts (where possible) - Removes unused variables in the non-reusing variants (mainly serializers previously used to create instance   or copy between instances) - Remove some unused types -  Improves generic type safety (fewer raw types)",1
[runtime] Release additional broadcast variable references early,1
[FLINK-1371] [runtime] Fix KryoSerializer to not swallow EOFExceptions,1
[streaming] [scala] scala SocketTextStream added and minor fixesOrganized imports for streaming scala examplesAdded template parameter for scala streaming iterateMinor fixes in streaming examples,0
[streaming] Replaced partitionBy with groupBy + re-added global partitioning,1
[FLINK-1367] [scala] [streaming] Field aggregations added to streaming scala api,1
[FLINK-1245] [Java API] Introduce TypeHints for Java API operatorsAlso contains fixes by sewen@apache.org - Make MissingTypeInfo optional in TypeExtractor (by default still throws exception) - Simplified deferred evaluation of type dependend code by making evaluations lazy - Add call location function names to MissingTypeInfo error messages. - Improvements on other error messages.This closes #270,0
"[FLINK-1266] Generalize DistributedFileSystem implementationto HadoopFileSystem wrapper, which supports all subclasses of org.apache.hadoop.fs.FileSystem.This allows us to let users use all file systems with support for HDFS.The change has been tested with Tachyon, Google Cloud Storage Hadoop Adapter and HDFS.The change also cleans up the Hadoop dependency exclusions.",4
[FLINK-1266] Update mongodb link and address pull request comments,1
[FLINK-1266] Properly pass the fs.defaulFS setting when initializing filesystems,5
[FLINK-1266] More dependency exclusions & fixed image in web clientThis closes #268,0
[FLINK-333] [apis] Forward crossWithSmall and crossWithLarge hints to optimizer.,2
[docs] Update README and internals (scheduling) for graduation and fix broken links,2
Fix typo in README.md,2
[FLINK-1197] [docs] Add information about types and type extraction,4
[FLINK-1225] Fix for quickstart packagingThis closes #279,0
[FLINK-1358] [streaming] Streaming added to the quickstarts,1
[FLINK-1386] [quickstart] Fix pom in java quickstart archetype,0
"[FLINK-1378] [scala] Fix type extraction for nested type parametersBefore, something like:def f[T: TypeInformation](data: DataSet[T]) = {  val tpe = createTypeInformation[(T, Seq[T])]  println(""Type: "" + tpe)}f(Seq(1.0f, 2.0f)would fail because the type extractor could not re-use existingTypeInformation for nested types.",5
[FLINK-1378] Add support for Throwables in KryoSerializer,1
[FLINK-1378] [scala] Add support for Try[A] (Success/Failure)This closes #293,0
[FLINK-986] [FLINK-25] [Distributed runtime] Add initial support for intermediate resultsThis closes #254.,1
[FLINK-1380] [streaming] Updated SplitDataStream to extend DataStream to get rid of selectAll method for splits,1
Undo erroneous commit 86f87537,5
[scala] Disable Warning Message in TypeAnalyzerThis would print a warning if a type could not be analyzed by the ScalaTypeAnalyzer. In such a case analysis is done using the JavaTypeExtractor but the warning seems to confuse people.,5
[FLINK-1397] Fix logfile access from JobManager web interface,2
Remove dup code fromRemoteExecutor#executePlan methodRemove dup code by delegating call from RemoteExecutor#executePlan to RemoteExecutor#executePlanWithJars.Author: Henry Saputra <henry.saputra@gmail.com>Closes #307 from hsaputra/reduce_dup_code_in_executePlan and squashes the following commits:a98f3b6 [Henry Saputra] Remove dup code by delegating call from RemoteExecutor#executePlan to RemoteExecutor#executePlanWithJars.,4
"[FLINK-1405] [windows] Fix Windows scripts (flink.bat and start-local.bat)- Fix for paths with blank characters- Fix for single entry wildcard classpaths (http://bugs.java.com, bugID: 7146578)",0
[hotfix] Also use java closure cleaner on grouped operations,4
[FLINK-1271] [hadoop] Remove Writable limitation from Hadoop format and function wrappersThis closes #287,1
[FLINK-1112] Add KeySelector group sorting on KeySelector groupingThis closes #209,1
[FLINK-1112] Additional checks for KeySelector group sorting and minor fixes,0
[FLINK-1183] Generate gentle notification message when Flink is started with Java 6This closes #296.,2
[runtime tests] Fixes TaskManagerTest.testRunJobWithForwardChannel which caused spurious errors. Doubles the timeout for tests.,3
[FLINK-1375] [assembly] Remove incubator DISCLAIMER file from binary distribution,2
[docs] Clean up documentation figures - Remove old unused figure image files - Add a file clarifying that figures are licensed under ASL 2.0,2
[docs] Add FAQ entry about scala implicits error when missing imports,2
[FLINK-1384] [webfrontend] Remove unused JS libraries,1
Minor dependencies cleanup:  - Move sling JSON dependency to streaming connectors (prev streaming core)  - Exclude YARN API from transitive mapreduce-core dependencies we use the dependency    only for .mapred and .mapreduce interfaces  - Remove some unnecessary dependencies (junit in java8)  - Manage Kryo dependency  - Cleanup minor POM warnings.,2
[tachyon] Minor fix in codestyle and warnings,2
"[LICENSE] Update LICENSE and NOTICE files - Add missing entries for dependencies - Remove entries for removed dependencies - Change DEPENDENCIES file to point to src and bin LICENSE and NOTICE file - Add comments in some files to clarify whether the are Flink original,   or from which third party file they are adapted - Change some links from incubator to TLP",2
[docs] Prepare documentation for 0.8 release,2
[dist] Updated mailing list info in binary distribution,5
Fix for quickstart versions,0
[build tools] Release script updateDefault hadoop version is now hadoop2Generate specific pom avoids version collisions with dependenciesUpdated poms for new release scriptsConflicts:flink-addons/flink-avro/pom.xmlflink-addons/flink-hadoop-compatibility/pom.xmlflink-addons/flink-hbase/pom.xmlflink-addons/flink-jdbc/pom.xmlflink-addons/flink-spargel/pom.xmlflink-addons/flink-tachyon/pom.xmlflink-quickstart/flink-quickstart-java/pom.xmlflink-quickstart/flink-quickstart-scala/pom.xml,5
Commit for year 2015Updated NOTICE filesUpdated inceptionYear in pom,5
[maven] Fix project name and inception year,0
[FLINK-1382][java] Adds the new basic types Void and Date to the TypeInfoParserThis closes #299,5
[FLINK-1229][FLINK-1206] [web frontend] Synchronize webclient arguments with command line and add default parallelism.This closes #291,1
[FLINK-1399] Add support for registering Serializers with KryoThis closes #305,1
[FLINK-1399] Fix kryo registration of types and make sure that tags are assigned for registered types.,1
[tests] Make dates in test data agnostic to time zones,5
[FLINK-1416] Fix dependency versions in quickstart archetypes,0
[FLINK-1395] Add tests for custom serializers with JodaTime.,5
[tests] Minor cleanup of compiler warnings.,2
[Distributed runtime] Refactor data availability listener of UnionBufferReader to increase readability,1
[Distributed runtime] Allow recursive union of buffer readers,1
[Distributed runtime] Rename read method of BufferReader to indicate blocking behaviour,1
[FLINK-1409] Let CoRecordReader subscribe to buffer reader notifications,2
FLINK-1420 Small cleanup on code after branch for 0.8 releaseSmall cleanup on code after branch for 0.8 release:-) Remove semicolons in Scala code for consistencies.-) Wrap some code in Java that is too long for easy read.-) Fix constant typo (from GENRAL_OPTIONS to GENERAL_OPTIONS)-) Remove some unused imports in Scala and Java code.Author: Henry Saputra <henry.saputra@gmail.com>Closes #302 from hsaputra/cleanup_code_simple_1 and squashes the following commits:f98431e [Henry Saputra] Remove not needed semicolons from Scala code for consistency.73fa587 [Henry Saputra] Move full class name to import for Serializable interface as import in InputSplitSource interface.a403136 [Henry Saputra] Move full package name to import statement for consistency.387e0c8 [Henry Saputra] Remove unnecessary parentheses for consistency.47b6b4c [Henry Saputra] Small cleanup on code after branch for 0.8 release: Remove semicolons in Scala code. Remove some unused imports in Scala and Java code.,2
[FLINK-1372] [runtime] Fixes logging settings. The logging is now exclusively controlled by the logging properties provided to the system. Removes akka.loglevel config parameter.,2
Adopts the logger level for the akka log level,2
[FLINK-1372] Re-add logging of temp directories at task manager startup,2
[FLINK-1372] Log memory usage at start up and fix log level mismatch for scheduled memory log messageThis closes #321.,1
Fix missing IOException import in JobManager,2
[Docs] Fix typo in programming guideThis closes #327.,2
[FLINK-1296] [runtime] Add better paged disk I/O readers / writers,1
[FLINK-1296] [runtime] Add sorter support for very large records,1
[FLINK-1326] [runtime] Make sure that serializers release their very large intermediate buffers early,1
[runtime] Add spillable input deserializer,1
[FLINK-1296] [runtime] Fix bug that first record in buffer is not correctly recognized as large record,0
[FLINK-1296] [runtime] Fix bug when large record handling results in empty spill files,2
Fix conflicts after rebase of PR #249This closes #249.,5
[FLINK-1403] [streaming] Distributed filesystem support for streaming filesinksNow streaming filesinks support the same filesystems as the batch ones,5
[streaming] Streaming runtime collector rework for increased flexibility with directed outputs and operator chains,1
[FLINK-1345] [streaming] Basic operator chaining added,1
[FLINK-1345] [streaming] Chaining refactor + ChainingStrategy exposed through the API for operators,1
[FLINK-1345] [streaming] Advanced task chaining added,1
[streaming] JobGraphbuilder separated to StreamGraph and StreamingJobGraphGenerator,5
[FLINK-1345] [streaming] Added support for chaining operators with directed outputs,1
[FLINK-1372] [runtime] Adds EnvironmentInformation.logEnvironmentInfo method calls to JobManager's and TaskManager's main methods.This closes #329.,5
[Runtime] Fix unnecessary object creation for large record sorterThis addresses comments made in https://github.com/apache/flink/commit/7df6a3d7266b0f934b76722732176dbf5469bdb4,5
Cleanup missing space =),4
Merge branch 'master' of https://git-wip-us.apache.org/repos/asf/flink into asf_master,2
"Rename coGroupDataSet.scala to CoGroupDataSet.scala, and crossDataSet.scala to CrossDataSet.scala",5
Move the UnfinishedCoGroupOperation class into its own Scala file.The UnfinishedCoGroupOperation does not relate closely to CoGroupOperationvia sealed modifier so per Scala style guide [1] I propose to move it toseparate file.[1] http://docs.scala-lang.org/style/files.htmlThis closes #324.,2
[FLINK-1353] [runtime] Loops through the JobManager's timeout to the Execution objects.This closes #325.,1
[tests] Fix missing task parallelism in JobManagerITCase bipartite job support test,3
[quickstart] Set quickstart.sh version to latest release (0.8.0),3
"[FLINK-1295][FLINK-883] Allow to deploy 'job only' YARN cluster. Add tests to YARN- users can now also deploy Flink on YARN for executing a single job.- The flink-yarn project has been moved out of the flink-addons module- the MiniYARNCluster is used for testing Flink on YARN- There is now a (undocumented) Java interface Flink's YARN client, allowing users to manually control the Yarn session.- ALL ports used by Flink when running on YARN are automatically determined. In the past users reported problems with blocked ports (YARN is telling the client the RPC address of the application master)- The checks before deployment have been improved to give better error messages if the user is requesting too many resources for a YARN session",1
[FLINK-1295] Address pull request review comments,1
[FLINK-1385] Make resource avilability checks optional (warn instead of fail),0
[FLINK-1406] [documentation] update compatibility notice with link to further documentationThis closes #314,2
[FLINK-1440] [docs] Fix missing plan visualizer image.,0
[FLINK-1381] Allow multiple output splitters for single stream operatorCloses #332Conflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/StreamConfig.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/StreamGraph.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/collector/DirectedStreamCollector.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/SingleOutputStreamOperator.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/SplitDataStream.javaflink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/streamvertex/OutputHandler.java,5
[FLINK-1081] Add getPos() method into FSDataInputStream class,5
[FLINK-1081] Add HDFS file-stream source for streamingConflicts:flink-addons/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java,5
[FLINK-1081] FileMonitoringFunction fix for proper handling of modification timesCloses #226,0
[streaming] Fix bug with operators inheriting lower parallelism,1
[FLINK-1425] [streaming] Add scheduling of all tasks at onceThis closes #330.,1
[FLINK-1389] Allow changing the filenames of the files created when writing to a directoryThis closes #301,1
[FLINK-1428] [docs] Fix typos in Java code example for RichGroupReduceFunction [ci skip]This closes #340.,1
[FLINK-1168] Add support for multi-char field delimiters in CSVInputFormats.This commit includes parts of Cbro's pull request and subsumes PR #247This closes #247This closes #264,1
"[FLINK-1453] Fix failing flink-yarn-tests on OS XThe actual issue was that the web server of the job manager was using the default HTTP port (8081) instead of automatic port assignment by the operating system.It seems that there are other services running on 8081 on OS X. So the fix is not only for OS X, it applies to all platforms.",0
[FLINK-1446] Fix Kryo createInstance() methodThis closes #336,1
[FLINK-1147][Java API] TypeInference on POJOsThis closes #315.,5
[FLINK-1433] Add HADOOP_CLASSPATH to start scriptsThis closes #337,1
[FLINK-1352] [runtime] Fix buggy registration of TaskManager to JobManager by introducing dedicated RefusedRegistration messagesAdds exponential backoff strategy for TaskManager registration. Introduces AlreadyRegistered and RefuseRegistration messages.This closes #328.,1
[runtime tests] Fix buggy recover a task manager failure integration test case[runtime tests] Fix TaskManagerFailsITCase and TaskManagerFailsWithSlotSharingITCase,0
[streaming] Refactor iterative datastream for clear self-contained functionality,1
[FLINK-1434] [FLINK-1401] Streaming support added for webclientCloses #334,1
[FLINK-1328] Integrated forwarded Fields into the optimizer (incomplete)This closes #83,2
"[FLINK-1328] [api-breaking][java-api][scala-api][optimizer] Reworked semantic annotations for functions.- Renamed constantField annotations to forwardedFields annotation- Forwarded fields can be defined for (nested) tuples, Pojos, case classes- Added semantic function information to example programsThis closes #311",5
[FLINK-1328] [docs] Updated documentation of semantic properties.Improved documentation of key specification and data type.,5
[FLINK-1328] Added previously failing semantic annotations to examples and fixed them by enabling partitioning on AtomicTypes.,0
[Typo] Delete DiscardingOuputFormatThis closes #343,4
[FLINK-1457] [build] Exclude avro test file from RAT checkThis closes #345,2
[FLINK-1344] [streaming] [scala] Added implicits from scala seq to datastream and static StreamExecutionEnvironment initialization,5
[FLINK-1344] [streaming] Quickfix for the recent  webclient supportCloses #341,1
Remove semicolon in Scala files. Fix java doc alignment in AggregatorsITCase.java,2
[FLINK-1460] fix typosFix some typos. Also fix some inconsistent uses of **partition operator** and **partitioning operator** in the codebase.Author: Shuo Xiang <shuoxiangpub@gmail.com>Author: Shuo Xiang <sxiang@pinterest.com>Closes #346 from coderxiang/typo and squashes the following commits:acf5274 [Shuo Xiang] change partitioningoperator to partitionoperator89b460a [Shuo Xiang] fix typos,2
[FLINK-1425] [streaming] Non-lazy scheduling set for streaming programs,1
[Typo] Typo fixes in code comments.This closes #352,0
[FLINK-1419] [runtime] Fix: distributed cache properly synchronizedThis closes #339,0
[FLINK-1452] Rename 'flink-addons' to 'flink-staging',2
[FLINK-1452] Add 'flink-contrib' moduleThis closes #355,2
[FLINK-1105] [api-extending] Add support for local sorting on data sinks.This closes #347,5
[FLINK-1105] [docs] Added documentation for locally sorted output,2
[FLINK-1437][Java API] Fixes copy() methods in PojoSerializer for null valuesThis closes #342,0
[misc] Code cleanups and fixes for various compiler warnings,2
Improved exception for missing type of InputFormatThis closes #351,1
[FLINK-1193][java-api][scala-api] Complete support for multidimensional arraysThis closes #348,1
[FLINK-1193][java-api][scala-api] Fix copy method for ObjectArraySerializer,0
[FLINK-1464] [java-api] Added ResultTypeQueryable interface implementation to TypeSerializerInputFormat.This closes #349,1
"[FLINK-1165] [java-api] Add createCollectionsEnvironment to Java APIThis commit adds a new method to ExecutionEnvironment to create aCollectionEnvironment, and applies the method to cases where aCollectionEnvironment() may be neededThis closes #320",1
"[FLINK-1165] [java-api] Rename ""createCollectionEnvironment"" to not break existing APIs.",4
[java api] Fix various compiler warnings through code cleanups,4
[FLINK-1330] [build] Build creates a link in the root directory to the build target directoryThis closes #333,1
[scripts] Fix job manager heap size configuration key,5
[FLINK-1468] [scripts] Add integer check for job/task manager heap size config valuesPrint a warning message if misconfigured.,5
[FLINK-1468] [scripts] Cancel job/task manager startup when misconfigured heap sizesAddresses comments here: https://github.com/apache/flink/commit/2bea79341eb0f2fafd1537b15ca212eb5792f950,2
[streaming] Task chaining bugfix for partitioner settings,1
[FLINK-1473] Simplify SplittableIterator interface,2
[FLINK-592] Add support for Kerberos secured YARN setups to Flink.,2
"[FLINK-592] Address pull request comments: fail early on missing auth,load log4j-cli.properties and do not set 'default' as default queueThis closes #358",1
[FLINK-1477] Respect HADOOP_HOME when starting Flink,2
"[FLINK-1318] [api-breaking] Simplified quoted string parsing, made it optional, and use a configurable quote characterThis closes #265",5
[FLINK-1318] [docs] Added documentation for CSV parsing options.,2
[FLINK-1443 [api-breaking] Extended split assigner interface by parallel task id.,4
[FLINK-1443] Added support for replicated data sources.Introduced new PartitioningProperty for any distribution (random partitioning or full replication).,5
Ensure blob manager storage directory creation is successful,1
Log blob cache and server storage directories at startup,2
Fix typo in task manager startup temp directory check log message,2
"[FLINK-1458] Allow Interfaces and abstract types in TypeExtractorKryo already supports them, so it was just a question of theTypeExtractor allowing them.",1
[FLINK-1442] [runtime] Reduce memory consumption of archived execution graphThis closes #344,1
[FLINK-1376] [runtime] Add proper shared slot release in case of a fatal TaskManager failure.Fixes concurrent modification exception of SharedSlot's subSlots field by synchronizing all state changing operations through the associated assignment group. Fixes deadlock where Instance.markDead first acquires InstanceLock and then by releasing the associated slots the assignment group lockcan block with a direct releaseSlot call on a SharedSlot which first acquires the assignment group lock and then the instance lock in order to return the slot to the instance.Fixes colocation shared slot releasing. A colocation constraint is now realized as a SharedSlot in a SharedSlot where the colocated tasks allocate sub slots.This cloes #317,0
[FLINK-1415] [runtime] Clean up archiving of ExecutionGraphs,4
[FLINK-1442] [runtime] Minor code cleanups in MemoryArchivist,4
[scala api] Minor code cleanup for compiler warnings,2
[docs] add documentation for FLink GCE setup using bdutilThis closes #361,1
[FLINK-1479] [runtime] Spawned threads in sorter get the same context class loader as the parent thread,1
"[FLINK-1415] [runtime] Akka cleanupsReplace akka.jobmanager.url by non exposed mechanism. Add heuristics to calculate different timeouts based on a single value.Harmonize scala coding style: Remove redundant braces and parentheses, remove meaningless code statements, standardize access patterns, name boolean parameters, unnecessary semicolons, unnecessary braces in import sectionAdds death watch test cases: Test if JobManager detects failing TaskManager. Test if the TaskManager detects failing JobManager and tries to reconnect to the JobManager.Refactors notifyExecutionStateChange method to avoid access of the TaskManagers internal state from outsideThis closes #319.",4
[FLINK-1471][java-api] Fixes wrong input validation if function has no genericsThis closes #359,1
[FLINK-1480] Set Hadoop version to 2.6.0 for travis tests,3
[runtime] Enables remote communication for local standalone cluster mode which is required by the JobClient.,1
[FLINK-1481] Fixes flakey JobManagerITCase which relied on non-deterministic behaviour.This closes #365.,5
[FLINK-1482] Add shutdown hooks to delete blob storage directories,4
[FLINK-1482] Log error instead of rethrowing it during shutdown hook,1
[runtime] Remove obsolete line reader test classes,3
"[runtime] Increase timeout in pipeline queue tests, to increase test robustness on CI servers",3
[FLINK-1478] [jobmanager] Stubs to support eager input split assignment on task creation,1
[FLINK-1478] [jobmanager] Scheduler support for external location constraints,1
[streaming] Critical bugfix for streaming keyselectors,0
[FLINK-1488][yarn] Fix broken log file access,2
[FLINK-1490][fix][java-api] Fix incorrect local output sorting of nested types with field position keys.,0
[FLINK-1485][documentation] Fix typo in Java join function example.This closes #369,1
[docs] Updated legacy references containing 'incubator' substringAlso dumped the stable release version in the docs config,5
Remove 'incubator-' prefix from README.md.This closes #371,2
[FLINK-1166] Add qa-check.sh toolThe ./tools/qa-check.sh tool allows developers to check for common errors before opening a pull request.The qa-checks are designed to be easily extensible by further checks.This closes #366,0
[FLINK-1438] [jobmanager] Fix class loading issue for messages with custom input splits,0
[streaming] Proper hash join added for window joins,1
[FLINK-1475] Decrease log level for yarn tests,3
[FLINK-1396][FLINK-1303] Hadoop Input/Output directly in APIThis adds methods on ExecutionEnvironment for reading with HadoopInput/OutputFormat.This also adds support in the Scala API for Hadoop Input/OutputFormats.,1
[FLINK-1478] [jobmanager] Add deterministic strictly local split assignment (part 1),5
[FLINK-1478] [jobmanager] Add deterministic strictly local split assignment (part 2)This closes #375,5
[FLINK-1478] [jobmanager] (addendum) Add eager check for null as input split host name,1
[hotfix] Fix missing guava dependency of flink-testsWhen building in hadoop 2 profile everything is fine since we get guavaas a transitive dependency. For hadoop 1 we need to manually add theguava dependency. This was erroneously removed earlier.,4
[FLINK-1498] [tests] Set a minimal JVM size to prevent NIO memory problems,0
[FLINK-1498] [tests] Better error messages in external sort tests,3
[FLINK-1495][yarn] Make Akka timeout configurable in YARN client.This closes #377,5
Remove unused enum values from Aggregations enum.SImple cleanup to remove unused enum values from Aggregations enum.Author: Henry Saputra <henry.saputra@gmail.com>Closes #373 from hsaputra/remove_unused_enumvalues_from_aggregations and squashes the following commits:a831e44 [Henry Saputra] Remove unused enum values from Aggregations enum.,1
[streaming] Stock streaming example added,1
[streaming] Java Stock streaming example added,1
[streaming] Windowing examples cleanupRemoved obsolete examplesUpdated StockPrices exampleUpdated build,5
"[FLINK-1369] [types] Add support for Subclasses, Interfaces, Abstract Classes.- Abstract classes with fields are handled as POJO types.- Interfaces and abstract classes without fields are handled as generic types.This closes #236This closes #316",0
[FLINK-1492] Fix exceptions on blob store shutdownThis closes #376,0
[FLINK-1496] [distributed runtime] Fix loss of events at uninitialized input channelsThis closes #380.,5
[FLINK-1201] [gelly] First mockup of initial API functions,1
[FLINK-1201] [gelly] Initial package,5
[FLINK-1201] [gelly] Stubs for basic classes,2
[FLINK-1201] [gelly] fix project setup,1
[FLINK-1201] [gelly] get undirected graph,1
[FLINK-1201] [gelly] edge and value extend tuple types,2
[FLINK-1201] [gelly] reverse and graph input methods,2
"[FLINK-1201] [gelly] Added Push-Gather-Apply, mapVertices, subgraph, outDegreesAdded:mapVertices + Testsubgraph (Unfinished)outDegreesPush-Gather-Apply Neighborhood ModelJunit DependencyEverything is untested as we are blocked on graph creation",1
"[FLINK-1201] [gelly] Reverted to using Tuples, added tests.",3
[FLINK-1201] [gelly] Added Kostas' functions from the hackathon; added ExecutionEnvironment member to Graph,1
[FLINK-1201] [gelly] type information in Graph and in getUndirected method,1
[FLINK-1201] [gelly] typeinfo in reverse and getOutdegrees,1
"[FLINK-1201] [gelly] test for undirected, reverse and outDegreesremove unused imports",2
"[FLINK-1201] [gelly] made functions for getUndirected, outDegrees and reverse static inner",1
[FLINK-1201] [gelly] test mapVertices,3
[FLINK-1201] [gelly] remove unecessary type from mapVertices,4
[FLINK-1201] [gelly] fixed subGraph() and added test,3
[FLINK-1201] [gelly] mapVertices allows changing the value type,4
[FLINK-1201] [gelly] remove old hackathon test file,2
[FLINK-1201] [gelly] added execution environment to create calls in test,3
[FLINK-1201] [gelly] separate test for mapVertices,3
[FLINK-1201] [gelly] Added mapEdges,1
[FLINK-1201] [gelly] Added mapEdges tests,3
[FLINK-1201] [gelly] Removed unnecessary edgeKeyType field,4
[FLINK-1201] [gelly] empty test todos for implemented operations,2
"[FLINK-1201] [gelly] fix count to work with Datasets of tuples, added test for numberOfVertices, numberOfEdges",3
"[FLINK-1201] [gelly] static inner classes for getVertexIds, getEdgeIds, isWeaklyConnected, tests for former 2",3
[FLINK-1201] [gelly] isWeakly connected corrections and test,3
[FLINK-1201] [gelly] Updated the Graph constructor,5
"[FLINK-1201] [gelly] Added tests for addVertex, removeVertex, addEdge and union",1
"[FLINK-1201] [gelly] fromCollection(vertices, edges) implemented and tested",3
[FLINK-1201] [gelly] added create methods from set of edges,1
"[FLINK-1201] [gelly] Added removeEdge, added more tests",3
"[FLINK-1201] [gelly] Fixed/added tests, based on Vasia's feedback",5
[FLINK-1201] [gelly] fromCollection(edges) implemented abd tested,3
"[FLINK-1201] [gelly] Fixed distinct vertex issues, changed removal filters",4
[FLINK-1201] [gelly] added descriptions for add/remove methods,4
[FLINK-1201] [gelly] reorganized tests and readme,3
"[FLINK-1201] [gelly] added vertex-centric iteration, removed pga",4
[FLINK-1201] [gelly] inDegrees and getDegrees implemented and tested,3
[FLINK-1201] [gelly] subgraph(vertexFilter) and subgraph(edgeFilter) implemented and tested,3
[FLINK-1201] [gelly] outDegrees with coGroup,2
[FLINK-1201] [gelly] filterOnVertices and filterOnEdges implemented and tested,3
"[FLINK-1201] [gelly] inDegree, outDegree, getDegrees implemented and tested",3
[FLINK-1201] [gelly] cleared VertexKeyWith one class definintion,5
[FLINK-1201] [gelly] replace fromCollection with fromElements; remove unused import,2
[FLINK-1201] [gelly] replaces tuples with vertex and edge classes,2
[FLINK-1201] [gelly] count to use Graph's execution environment,1
[FLINK-1201] [gelly] simple graph metrics example,2
[FLINK-1201] [gelly] validate vertex ids implemented and tested,3
[FLINK-1201] [gelly] integrated inline suggestions,2
[FLINK-1201] [gelly] Added PageRank example,1
[FLINK-1201] [gelly] Added PageRank as a library method and example,1
[FLINK-1201] [gelly] PageRank example implementing GraphAlgorithm,2
[FLINK-1201] [gelly] first take on neighborhood methods: OutEdges,2
[FLINK-1201] [gelly] fixed type info for the outEdgesFunction,1
[FLINK-1201] [gelly] use vertex/edge instead of tuples in the testfixed a few warnings in pagerank example,2
[FLINK-1201] [gelly] some refactoring and cleanup,4
[FLINK-1201] [gelly] reduceOnEdges method for in-/out- and all edges,2
[FLINK-1201] [gelly] added simplified reduceOnEdges without the vertex value,1
[FLINK-1201] [gelly] SingleSourceShortestPaths example,3
[FLINK-1201] [gelly] SSSP with runVertexCentricIteration,1
[FLINK-1201] [gelly] changed mapVertices to return a Graph and simplified SSSP,4
[FLINK-1201] [gelly] changed mapEdges to also return a Graph,4
[FLINK-1201] [gelly] reduceOnNeighbors with vertex value,2
[FLINK-1201] [gelly] return arbitrary type instead of Tuple2 for the neighbor methods,2
[FLINK-1201] [gelly] reduceOnNeighbors without vertex value,2
[FLINK-1201] [gelly] correct graph execution environment in InvalidVertexIdsValidator,5
[FLINK-1201] [gelly] joinWithVertices implemented and tested,3
[FLINK-1201] [gelly] [sssp example] only update the vertex value if new distance is smaller,1
[FLINK-1201] [gelly] get rid of Vertex to Tuple2 and Edge to Tuple3 conversions in runVertexCentricIteration,1
[FLINK-1201] [gelly] key and value types shouldn't be static fields; fixed #42,0
[FLINK-1201] [gelly] fix ClassCastException and Type errors in mapVertices; fixes #41 and #46,0
[FLINK-1201] [gelly] Fix bug in TestReduceOnNeighborMethods caused by object reuse,1
[FLINK-1201] [gelly] joinWithEdges implemented and tested,3
[FLINK-1201] [gelly] changed pageRank example to use joinWithEdgesOnSource,1
[FLINK-1201] [gelly] added description in GraphMetrics example,1
[FLINK-1201] [gelly] Expose the full Vertex and Edge object in filter functionsExpose the full Vertex and Edge object in filter functions to allow filteringby key value:- subgraph()- filterOnVertices()- filterOnEdges()fixes #56,0
"[FLINK-1201] [gelly] use type hints for mapVertices, mapEdges and create",1
[FLINK-1201] [gelly] Updated JavaDoc for Graph class,2
[FLINK-1201] [gelly] cloned spargel classes,2
[FLINK-1201] [gelly] changed spargel classes to work with Vertex and Edge types,1
[FLINK-1201] [gelly] removed 2-arg Edge constructor,4
"[FLINK-1201] [gelly] refactored methods for Graph creation- constructors are now private- create() methods have been renamed and refactored to fromDataSet()- fromCollection() methods have been refactored- overall consistency in creating new Graph objects, using the constructor now in all placesfixes #53",0
[FLINK-1201] [gelly] created fromTupleDataSet() methodsissue #53,0
[FLINK-1201] [gelly] remove isUndirected flag; methods will always consider the graph as directed,4
[FLINK-1201] [gelly] filtering bad records and top track per user,1
[FLINK-1201] [gelly] create similar users graph,1
[FLINK-1201] [gelly] added label propagation in library,1
[FLINK-1201] [gelly] label propagation example,2
[FLINK-1201] [gelly] added label propagation step in MusicProfiles,2
"[FLINK-1201] [gelly] LP example update: nodes get their id as initial label; if 2 labels have the same freq, select the one with the highest value",5
[FLINK-1201] [gelly] updated music profiles example,2
[FLINK-1201] [gelly] replaced create with fromDataSet,5
[FLINK-1201] [gelly] use fromTupleDataset method instead of Tuple3ToEdgeMap,5
[FLINK-1201] [gelly] added licence headers; added gelly to addons pom file; fixed checkstyle errors,0
[FLINK-1201] [gelly] added missing javadocs,2
[FLINK-1201] [gelly] use MultipleProgramsTestBase for the tests,3
[FLINK-1201] [gelly] Renamed tests from TestXyz to XyzITCase,3
[FLINK-1201] [gelly] changed ConstantFields to ForwardedFieldsThis closes #335,4
[FLINK-1473] Make abstract methods public in SplittableIterator,1
[runtime] Corrects messages sent to the JobManager by the JobManagerInfoServlet,5
[FLINK-1455] [runtime] Improve robustness of external sorting test errors,0
[FLINK-1489] Replaces blocking scheduleOrUpdateConsumers message calls with asynchronous futures. Buffers PartitionInfos at the JobManager in case that the respective consumer has not been scheduled.Conflicts:flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scalaAdds TaskUpdate message aggregation before sending the messages to the TaskManagersThis closes #378,5
[FLINK-1504] support for secure HDFS access using kerberosThis closes #383,1
[FLINK-1491] [runtime] Fixes logging output by setting Akka's stdout logger to log level WARNING.,2
[tests fix] Fix runtime exceptions for large record sorter by properly mocking the environment.,1
[FLINK-1530] Cache deserialized ExecutionConfig in the AbstractInvokable,5
[FLINK-1492] [FLINK-1513] Fix BLOB service shutdown message and avoid global configuration,5
[webclient] Remove obsolete arrow images,4
[FLINK-1411] Fix standalone plan visualizer,0
[FLINK-1504] Fix YARN tests,3
[FLINK-1432] [runtime] Make memory segment release robust against concurrent modifications of the collection,1
[runtime] Fixes re-submission of a job by JobClient,0
[FLINK-1510] Make AvroInputFormat splittableThis closes #387,1
"[FLINK-1436] usability improvements to the CliFrontend- more meaningful error messages- remove verbose flag and default to verbose output- rework error messages logic using checked exceptionsin particular, error messages are printed after usage information whichprovides information about the error immediately (no more scrolling)- catch MissingArgumentException- adapt tests for the new error handling of CliFrontend- improve help messages (FLINK-1424)- remove general options (they are really just confusing and don't add  additional functionality- change info to print the plan by default- change cancel to accept the job id as a parameter instead of an option- change list to print scheduled and running jobs by default- only print help message when -h is providedThis closes #331",1
[FLINK-1436] adapt all CliFrontend test cases,3
[FLINK-1531] [runtime] Adds proper EOFException forwarding to KryoSerializer.This closes #391.,1
[FLINK-1533] [runtime] Fixes NPE in the scheduler where the allocated shared slots are not properly checked.This closes #388.,0
[build tools] Improve release scripts,1
[FLINK-1436] fix missing checks in CliFrontendInfoTest,5
[FLINK-1517] [streaming] Added indexed input iterator for streaming,1
[streaming] Added ITCase for streaming classloading,1
[FLINK-1529] [jobmanager] Improve error handling on JobManager startupThis closes #385,0
[FLINK-1532] [tests] Fix spurious failure in AggregatorsITCase (plus minor cleanups),4
"Small cleanups to add space between if-else keyword and parentheses to be consistentas I found them.Also fix some comments typos.""",2
Merge branch 'master' of https://git-wip-us.apache.org/repos/asf/flink into asf_master,2
[FLINK-1508] [runtime] Removes AkkaUtil.ask and replaces respective calls with explicit future handling.Removes blocking calls for ActorRef retrieval in actors.This closes #384.,4
[FLINK-1543] [runtime] Adds try and catch blocks around all method calls from an actor's receive method which can throw an exception. Sets the StoppingSupervisorStrategy as default for all guardians.This closes #394.,1
[FLINK-1179] [jobmanager] Add button to JobManager web interface to request stack trace of a TaskManagerThis closes #374,1
[FLINK-1545] [runtime][tests] Fixes AsynchronousFileIOChannelsTest.testExceptionForwardsToClose by introducing additional error check in AsynchronousFileIOChannel.close methodThis closes #399,2
[FLINK-1487] [runtime][tests] Fixes SchedulerIsolatedTasksTest.testScheduleQueueing by waiting for the released resources to registered at the Scheduler again.This closes #398,3
[FLINK-1551] [runtime] Fix wrong class cast in JobManagerInfoServlet,5
[FLINK-1231] [streaming] More sophisticated streaming classloader ITCaseThis closes #303,1
[streaming] StreamWindow abstraction added with typeinfo and tests,3
[FLINK-1176] [streaming] Added invokables for modular windowing tranformations,1
[FLINK-1176] [streaming] WindowedDataStream rework for new windowing runtime,1
[streaming] StreamDiscretizer rework to support only 1 eviction and trigger for robustness + test cleanup,4
[streaming] Integration test added for windowed operations,1
[streaming] Streaming scala api fix for window changes + example cleanup,4
[streaming] GroupedTimeDiscretizer added for lighter time policy thread management,1
[streaming] WindowBuffer interface added for preaggregator logic + simple tumbling prereducer,2
[streaming] Reimplemented StreamWindow.split to avoid dependency issues,0
[streaming] TumblingGroupedPreReducer added + new tests for windowing,3
[streaming] WindowMapFunction added + Streaming package structure cleanup,4
[FLINK-1539] [streaming] Remove calls to uninitalized runtimecontexts,1
[streaming] Documentations updated to match the reworked windowing semantics,1
[streaming] Test cases added for all new windowing invokables,1
[docs] [streaming] Documentation updates for stream windowingThis closes #395,5
[FLINK-1454] [job client] Improve error handling for failed connections between JobClient and JobManager,0
[FLINK-1559] [akka] Normalize all akka URLs to use IP addresses rather than hostnames,1
[core] [java api] Various code cleanup and fixed for warnings.,2
"[FLINK-1542] Test case at BlobUtilsTest should not assume user could not create new item in root directorySometimes, user that run tests could have write access to root dir such as creating /cannot-create-thisis possible, hence to exception thrown.Need to construct a Flink test directory under directory specified under ""java.io.tmpdir"" and change the permission to not allow create newdirectory.This closes #396",1
[tests] Fix hostname escaping for older akka versions.,0
[FLINK-1557] Move JobManager web frontend server out of JobManager actor,4
[FLINK-1549] [yarn] Adds proper exception handling to YarnJobManagerThis closes #397.,1
[FLINK-1554] [runtime] Allows the LocalFlinkMiniCluster to start multiple TaskManager in the same ActorSystem.This closes #403.,5
[FLINK-1556] [runtime] Corrects faulty JobClient behaviour in case of a submission failureFixes unhandled FailsIntermediateResultPartitions message. Changes JobResultFailed and JobResultCanceled to send the cause as a throwable instead of a string.Fixes NullPointerException if an execution has already been prepared for archiving and sendPartitionInfos is called asynchronouslyThis closes #406.,5
[FLINK-1566] [streaming] Made WindowIntegrationTests thread-safe,3
[FLINK-1574] Fix null RuntimeContext when opening combiner UDF in CombiningUnilateralSortMerger.Move RuntimeContext initialization to begin of RegularPactTask.invoke().,5
[FLINK-1561] [build system] Use a fresh fork for each integration test runThis closes #412,1
[FLINK-1578] [BLOB manager] Improve failure handling and add more failure tests.,3
[FLINK-1391] Add support for using Avro-POJOs and Avro types with KryoConflicts:flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.javaflink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/KryoSerializer.java,5
[FLINK-1392] Add Kryo serializer for ProtobufConflicts:flink-java/pom.xmlflink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/KryoSerializer.java,5
[FLINK-1395] Add support for JodaTime in KryoSerializerAlso fix tests for JodaTime.Conflicts:flink-dist/src/main/flink-bin/LICENSEflink-java/pom.xmlflink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/KryoSerializer.javaflink-tests/src/test/scala/org/apache/flink/api/scala/runtime/KryoGenericTypeSerializerTest.scalaflink-tests/src/test/scala/org/apache/flink/api/scala/runtime/TupleSerializerTest.scala,5
[FLINK-1417] Automatically register types with Kryo,2
[FLINK-1567] Add option to switch between Avro and Kryo serializationThis closes #393,1
[blob manager] Fix flakey test.,3
Remove extra space after open parenthesis in InstanceConnectionInfo#toString.This closes #416,5
[FLINK-1483] IOManager puts temp files in dedicated directory and removes that on shutdownThis closes #417,4
[FLINK-1560] [streaming] StreamExecutionEnvironment enhancement for ITCases,2
[FLINK-1560][streaming] streaming WordCount ITCases,2
[builds] Print Java process stack traces of stalled builds,5
[builds] Add logger layout to prefix log output with Maven fork number,2
[builds] Allow to upload build artifacts to S3This closes #407.,1
[streaming] WindowBuffer separated from Discretizer for operator sharing + equality checks added for windowing objects,1
[streaming] Discretizer sharing added with further window optimzations for better chaining,5
"[streaming] Add MultiTriggerPolicy: It wraps around multiple triggers and allows to use them at the same time. It supports both, active and not active policies at the same time.",1
"[streaming] Add MultiEvictionPolicy: It wraps around multiple eviction policies and allows to use them at the same time. It supports both, active and not active policies at the same time. Additionally it introduces different eviction strategies the user can choose from.",1
[streaming] Added cloneable versions of MultiEvictionPolicy and MultiTriggerPolicy,1
[streaming] Moved WindowingOptimizer to its own class + several minor fixes,0
[FLINK-1585] [tests] Fix mini clusters to respect memory and buffer configurations and improve relative memory computation.,1
[tests] Add integration test for restart recovery,3
[web frontend] Small UI css class fixHeight of information bullets was not equal due to text break.This closes #425,4
[FLINK-1584] [runtime][tests] Fixes TaskManagerFailsITCase by replacing the TestingCluster with a ForkableFlinkMiniClusterThis closes #419,5
[FLINK-1584] [tests] Move logic for failure detection test cluster into test classes,3
[FLINK-1556] [runtime] Fails jobs properly in case of a job submission exceptionThis closes #422,0
[Flink-1484] [runtime] JobManager sends an explicit disconnect message to the registered TaskManagers in case of a graceful shutdown.,1
[FLINK-1499] [runtime] TaskManager sends explicit disconnect message to JobManager in case of shutdownThis closes #423,1
[tests] Cleanup style and timeouts in recovery restart tests,3
Update references in master to 0.8.1 release,5
[tests] Flix flakey SimpleRecoveryITCase,3
[FLINK-1451] [streaming] Parallel file source fix + minor windowing fix,0
[FLINK-1444][api-extending] Add support for attaching data properties to data sourcesThis closes #379,5
[FLINK-1461][api-extending] Add SortPartition operator to Java and Scala APIs.This closes #381,1
[FLINK-1466] Adds HCatInputFormats to read from HCatalog tables.,2
[FLINK-1466] Add support for complex types in Flink tuples for HCatInputFormats.This closes #411,2
[FLINK-1592] [streaming] StreamGraph refactor to store vertex IDs as Integers,4
[FLINK-1505] [distributed runtime] Separate reader API from result consumptionThis closes #428.,1
"Change translateToDataflow to return OperatorBefore, translateToDataflow of SingleInputOperator could only returna single input operator of the lower layer, same for TwoInputOperator.This change allows translateToDataflow to return more kinds ofoperators.",1
Add methods to CompositeType for querying field types and names,1
[FLINK-947] Add a declarative Expression API,1
[FLINK-1255] Add FAQ entry about Scala API TypeInformation,5
Add link to Type Extraction Doc in FAQ entry about Scala Extraction,4
[tests] Disables JobManagerFailsITCase and SimpleRecoveryITCase until they are fixed,0
[FLINK-1515] [gelly] Splitted runVertexCentricIteration into createVertexIteration and runVertexIteration to make VertexCentricIteration object accessible to developers.,1
[FLINK-1515] [gelly] Changed PageRank to use broadcast set provided by numberOfVertices() to read the number of vertices instead of passing it to the constructor.This closes #402,4
[FLINK-1596] [runtime] Remove space in temp filenameThis closes #431,2
[FLINK-1598] [runtime] Better error message when network serialization of records exceeds java heap space.,1
[runtime] Improve error handling when submitting a job to the JobManager,0
[jobmanager] Add a process reaper to kill the JobManager process when the main actor dies.Also adds various tests for failure behavior during job submission.,0
[tests] Speed up DataSinkTaskTest,5
"[tests] Add process reaping test for TaskManager, improves process reaping test for JobManager.",3
Small cleanup to truncate some lines that are too long for easy read of the code.,1
[FLINK-1580] [FLINK-1590] [runtime] Various cleanups and improvements in the TaskManager initialization - Better checks during TaskManager startup - More robust initialization of TaskManager actor system and actor - Fix memory accounting during TaskManager startup - Better logging for TaskManagers started through YARN - Remove command line parameter hacking fro YARN TaskManagers,2
fixed package statementpackage statement was not updated after class movementalso added a missing importAuthor: mjsax <mjsax@informatik.hu-berlin.de>Closes #437 from mjsax/bug_fix_package_statement and squashes the following commits:1470b0f [mjsax] fixed package statement,0
Fix typo in exception message from assiged to assigned in ExecutionJobVertex.,2
[FLINK-1606] [tests] Fixes JobManagerFailsITCase for Akka 2.2.1 by setting gate-invalid-address-for = 5s and quarantine-systems-for = off,5
[FLINK-1607] [tests] Fixes SimpleRecoveryITCase by rebalancing the data sources so that all mappers receive at least one element,5
[FLINK-1604] [runtime] Fixes livelock in PartitionRequestClientFactory.createPartitionRequestClientReplaces recursive concurrent modification resolution by while loopTurns off stdout-logging of Akka. Sends proper exceptions in ErrorResponse.Proper stream closing,0
[FLINK-1604] [FLINK-1568] Add initial connect failure test,3
[FLINK-1607] [runtime] Moves PartialPartitionInfo from ExecutionVertex to Execution to automatically clear them in case of restartThis closes #436.,5
Remove unnecessary log level checksThis addresses PR comments: https://github.com/apache/flink/pull/436/,2
[FLINK-1609] FileSystem.getHomeDirectory()This closes #438.,5
[FLINK-1519] Added canceling state to web interface.This closes #435.,1
[FLINK-1582][streaming]Allow SocketStream to reconnect when socket closes.,2
[FLINK-1582][streaming] SocketStream minor enhancementsThis closes #424,2
"[tests] Remove timeout in PipelinedPartitionQueueTestThe PipelinedPartitionQueueTest spuriously fails with a timeout. It is unclearwhether this is due to a deadlock or a test environment hickup. Since buildartifacts like stack traces for stalled builds are uploaded to S3, we can letthis test deadlock (if it is one) and then start debugging. ;-)",0
[web client] Fix webclient config forwarding,5
[tests] Improve debuggability of ProcessReapingTests,3
[docs] Fixes jekyll's config to bind to localhost,5
[streaming] Streaming examples dependency fix,0
[FLINK-1462][gelly][docs] added gelly guide,1
[FLINK-1462][gelly][docs] improvements and fixed typosThis closes #430,2
[core] move AbstractID from runtime to core,1
[java-api][scala-api] convenience methods count/collect to transfer a DataSet to the client- this implements two convenience methods on DataSet for the Java and Scala API- appropriate tests have been addedcount(): returns the number of elements in a DataSetcollect(): returns a List<T> with the actual elements of a DataSet<T>- both methods use accumulators to get the results back to the client- both methods force an execution of the job to generate the resultsThis closes #210,1
[FLINK-1586] [streaming] Add support for iterative streaming graphs on JSON generationCloses #432,5
[FLINK-1553] [streaming] Reworked Kafka connectorsCloses #433,1
[streaming] Add a clean in WindowedDataStream,5
[streaming] Several minor cleanups,4
[scala api] Moves TraversableType behind the CaseClassType in the TypeAnalyzer priority,4
[hotfix] Fix Scala type analysis for classes that extend Collections,0
[FLINK-1569] Disable object-reuse for collection execution,1
"Fix typos in iterations.md file-) Remove extra ""solution"" word.-) Change propagete to propagate.Author: Henry Saputra <henry.saputra@gmail.com>Closes #443 from hsaputra/fix_typo_in_iterations_md and squashes the following commits:fd781cc [Henry Saputra] Fix typos in iterations.md file: -) Remove extra solution word. -) Change propagete to propagate.",1
[FLINK-1608] [taskmanager] Hostname/address for TaskManager can be specified in the configuration,5
[FLINK-1608] [taskmanager] Network address selection makes multiple attempts before switching to heuristics.,1
[runtime] Extend environment logging on startup,2
[FLINK-1626] [tests] Fix spurious failure in MatchTaskTest,3
[streaming] Proper exception propagation for udf exception + collector bugfix,0
[distributed runtime] [tests] Add helper setters for NettyConfig,5
[distributed runtime] Notify about error when handing in channel,0
[distributed runtime] Throw interrupted exception during partition request client creation,1
[docs] adjust GCE setup instructions to point to the latest bdutil git version,3
[hotfix] Fix issue with nested Avro types,0
"[FLINK-1577] Remove misleading error log when failing task externallyTask thread Exceptions were always logged, even if the task was cancelled orfailed externally. In certain scenarios this lead to misleading error messagesand made it hard to figure out the root exception.When an exception is thrown w/o the task being canceled or failed, the erroris still handled via Task#markFailed(Throwable).",0
[FLINK-1555] Add serializer hierarchy debug utilThis closes #415,0
[hotfix] Fix loading of wrong TaskManager class,0
[config] Remove unused config constants,5
[FLINK-1631] [jobmanager] Deactivate web frontend in parallel tests (prevent port collisions),3
[flink-yarn-tests] Add check for exceptions in the flink logs.,2
[scala-api] Corrects type cast in Scala API's DataSet.collect method and adds test cases for that,3
"[FLINK-1627] [runtime] Fix race between remote receive and task releaseThe fixed race condition could lead to an infinite loop, in which the networkI/O thread is continuously trying to request a buffer from an already destroyedbuffer provider.The problem was noticed in certain builds during recovery test cases, where theblocked network I/O thread prevented restarted tasks from connecting to remotetask managers.",1
[FLINK-1631] [client] Overhaul of the client. - Fix bugs with non-serializable messages - Separate parser and action logic - Clean up tests - Vastly improve logging in CLI client - Additional tests for parsing / config setup in the command line client,1
[jobmanager] Improve error message in case task deployment times out.,0
[FLINK-1646] [runtime] Improve 'insufficient number of network buffers' error msgAdd a hint about how to configure the number of network buffers.,1
[tests] Simple code format in CountCollectITCase and suppresses sysout output for test.,3
[FLINK-1648] Add auto-parallelism to select all available task slots,1
[FLINK-1522][gelly] Added test for SSSP Example,3
[FLINK-1522][gelly] Fixed faulty split into create/runVertexCentricIterationThis closes #429,1
[FLINK-1522][FLINK-1576] Updated LabelPropagationExample and test,3
[FLINK-1522][FLINK-1576][gelly] Added more test cases for Label PropagationThis closes #441,3
[gelly] refactored tests; removed duplicate data from TestGraphUtils,3
[FLINK-1625] [streaming] Refactored StreamVertex and subclasses to clean up after invoke and properly log and propagate exceptions,2
[FLINK-1625] [streaming] [api-breaking] Added proper cancellation to StreamInvokables + Sink- and SourceFunction interfaces extended with cancel method,1
[FLINK-1625] [streaming] Streaming cancellation minor fix and documentationThis closes #449,2
[docs] reintroduce link from documentation to Flink website,2
[FLINK-1649] [runtime] Give a good error message when a user emits an unsupported null valueThis closes #456,1
[FLINK-1650] [logging] Suppress wrong netty warnings on akka shutdownThis closes #455,2
[FLINK-1640] Remove tailing slash from paths. Add tests for Path and FileOutputFormat.This closes #453,2
Some simple cleanups and doc updates while looking at (mostly) runtime packageThis PR consists of:1. Remove unnecessary brackets in ExecutionVertex#getPreferredLocations2. Throw illegal argument with proper message for consistencies of not nullable argument.3. Add final modifier to RecordWriter#serializers since the content being used as lock.4. Wrap too long of lines in some of the Java code for readibility.5. Add missing JavaDoc parameter.6. Remove final modifier in the OutputEmitter's private methods because it is redundant.Author: Henry Saputra <henry.saputra@gmail.com>Closes #457 from hsaputra/cleanup_javadoc_and_longlines_1 and squashes the following commits:8815302 [Henry Saputra] Some cleanups and doc updates while looking at runtime package: 1. Remove unnecessary brackets in ExecutionVertex#getPreferredLocations 2. Throw illegal argument with proper message for consistencies of not nullable argument. 3. Add final modifier to RecordWriter#serializers since the content being used as lock. 4. Wrap too long of lines in some of the Java code for readibility. 5. Add missing JavaDoc parameter. 6. Remove final modifier in the OutputEmitter's private methods because it is redundant.,1
Simple fix to respect return value return by File APIs.,2
[FLINK-1587][gelly] Added additional check for edge src/trg id validityThis closes #440,1
[FLINK-1429] [streaming] Scala documentation and minor Scala API features,2
Fixed simple typos,2
"[FLINK-1429] [streaming] Scala programming guide update: intro & operators, minor fixesThis closes #463",0
[FLINK-1637] Reduce number of files in uberjar for java 6This closes #450,2
"[FLINK-1651] Fix test case at JobManagerStartupTest to avoid hang on certain usersJobManagerStartupTest should not assume user could not create /does-not-exist-no-sir dir.Sometimes, user that run tests could have write access to root directory so creating /does-not-exist-no-sir is possible,hence no exception thrown.Need to construct a Flink test directory under directory specified under ""java.io.tmpdir"" and change the permissionto not allow create new directory.Author: Henry Saputra <henry.saputra@gmail.com>Closes #460 from hsaputra/FLINK-1651_fix_jobmanager_fail_test and squashes the following commits:5d46716 [Henry Saputra] [FLINK-1651] Fix test case at JobManagerStartupTest should not assume user could not create /does-not-exist-no-sir dir.",1
"Fix checking null for ternary operator check on Exception#getMessage callsAdd parentheses on Exception#getMessage calls from pattern of:""Initializing the input processing failed"" + e.getMessage() == null ? ""."" : "": "" + e.getMessage()to:""Initializing the input processing failed"" + (e.getMessage() == null ? ""."" : "": "" + e.getMessage())Extra parentheses needed to make sure ternary operator check on e.getMessage scope call.Author: Henry Saputra <henry.saputra@gmail.com>Closes #461 from hsaputra/fix_parentheses_exception_getmessage and squashes the following commits:1345cbf [Henry Saputra] Fix checking null for Exception#getMessage call from pattern of:",1
[tests] Add comments and to recovery tests,3
[FLINK-1667] [runtime] Add test for recovery after TaskManager process failure,0
[FLINK-1668] [core] Add a config option to specify delays between restarts,5
[hotfix] Fix erroneous testing log4j configuration for flink-runtime,2
[FLINK-1628] [optimizer] Fix partitioning properties for Joins and CoGroups.This closes #458,0
"[docs] fix anchor positions of headlines, reduce size of nav bar",0
[FLINK-1638] [streaming] Vertex level fault tolerance and state monitor,2
[FLINK-1638] [streaming] Fault tolerance logic in JM and TM,2
[FLINK-1638] [streaming] Operator state checkpointing and injection prototype,1
[FLINK-1638] [streaming] Added connector for low level Kafka Consumer API,1
[FLINK-1638] [streaming] Added Kafka topic creator and custom offset consumer,1
[FLINK-1638] [streaming] Added persistent Kafka sourceExposed state registering in the public API,1
[FLINK-1638] [streaming] State interface cleanup,4
[FLINK-1638] [streaming] Seperated AbstractRecordReader for streaming and batch,2
"[FLINK-1638] [streaming] Barrier sync added to CoRecordReader, barrier tests",3
"[FLINK-1638] [streaming] Kafka low level API example, documentation and fixes",0
[FLINK-1638] [streaming] At-Least once monitoring semantics added and bug fixesFault Tolerance monitor suicide on ExecutionGraph terminal stateForwarding messages to StreamCheckpointCoordinator,0
[FLINK-1638] [streaming] RegisterState removed from datastream + CoRecordReader barrier test added,1
[FLINK-1638] [streaming] Add StateHandle and include javadocThis closes #459,2
[FLINK-1638] [jobmanager] Cleanups in the ExecutionGraph for streaming fault tolerance,4
[FLINK-1660] [streaming] Increased timeout for MultiTriggerPolicyTest and introduced a constant representing it.,3
[FLINK-1657] [streaming] Count window parallel discretization,2
[FLINK-1619] [FLINK-1620] Basic sliding prereducers added for Time and Count,1
[FLINK-1643] [streaming] Auto detection of tumbling policies added + WindowedDataStream refactor,4
[FLINK-1619] [FLINK-1620] Grouped sliding prereducers added for Time and CountCloses #465,1
[FLINK-1605] Bundle all hadoop dependencies and shade guava awayThis closes #454,2
[FLINK-1654] [docs] Fix scala example in programming guideThis closes #478,0
"[FLINK-1629][FLINK-1630][FLINK-1547] Add option to start Flink on YARN in a detached mode. YARN container reallocation.This commit is changing:[FLINK-1629]: users can now ""fire and forget"" jobs to YARN or YARN sessions to there. (Detached mode)[FLINK-1630]: YARN is now reallocating failed YARN containers during the lifetime of a YARN session.[FLINK-1547]: Users can now specify if they want the ApplicationMaster (= the JobManager = the entire YARN session) to restart on failure, and how often. After the first restart, the session will behave like a detached session. There is now backup of state between the old and the new AM.The whole resource negotiation process between the RM and the AM has been reworked.Flink is now much more flexible when requesting new containers and also giving back uneeded containers.A new test case is testing the container restart. It is also verifying that the web frontend is proplery started,that the logfile access is possible andthat the configuration values the user specifies when starting the YARN session are visible in the web frontend.This closes #468",1
[docs] Adds documentation on setup of intelliJ[docs] Links internal_setup_intellij.html from internal_howto.htmlThis closes #480,1
Remove unused imports from RichMapPartitionFunction. Wrap way too long statements in NetworkBufferPool.,1
[tests] Increase timeout for ProcessFailureBatchRecoveryITCase to compensate for slow Travis runs,1
[FLINK-1683] [jobmanager]Fix scheduling preference choice for non-unary execution tasks.This closes #476,0
[maven] Remove flink-streaming-examples from flink-dist,2
[FLINK-1450] Added fold operator for the Streaming API,1
[FLINK-1450] Added GroupFoldFunction and GroupedFoldInvokable with a test. Integrated them into DataStream,5
[FLINK-1450] Integrated fold into WindowedDataStream and added a WindowFolder test[FLINK-1450] Fixed StreamFoldInvokable and GroupedStreamFoldInvokable by implementing accumulator copying to prevent mutations and removed GroupFoldFunction.Conflicts:flink-staging/flink-streaming/flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/DataStream.scala[FLINK-1450] Fixed foldWindow on WindowedDataStreams so it doesn't fail on extracting type information from scala types[FLINK-1450] Fix foldWindow so now user doesn't have to supply output TypeInformation while using it from Java API,1
[FLINK-1450] Several minor stream fold fixesCloses #481,0
[FLINK-1677][gelly] Suppresed Sysout Printing for the Degrees with exception test suiteThis closes #475,3
[FLINK-1677] [gelly] Simple improvements to DegreesWithExceptionITCase.,1
[project] Added additional IntelliJ file ignoresThis closes #483,2
[FLINK-1705] [taskmanager] Fix hostname lookup.,0
[FLINK-1691] [tests] Fix and cleanup CountCollectITCase,4
[gelly-tests] Fixes DegreesWithExceptionITCase to check expected exceptions,0
[yarn-tests] Fix potential NullPointerException,0
[optimizer] Remove obsolete and unused fields from OptimizerNode,1
[FLINK-1671] [jobmanager] Rename JobManager's ExecutionMode to JobManagerModeThis is done to avoid name conflicts with the overloaded type name ExecutionMode.,5
"[FLINK-1671] [tests] Rename ""ExecutionMode"" in MultiProgramTestBase to ""TestExecutionMode""... to avoid name clashes with the program execution mode.",3
[FLINK-1671] [core] Add execution mode to execution config,5
[FLINK-1671] [optimizer] Add data exchange mode to optimizer classesThis closes #487,4
"[FLINK-1576] [gelly] improvements to the gelly examples.Updated GraphMetrics, MusicProfiles and PageRank to run with and without parameters.Added input descriptions to LabelPropagation and SSSP.Fixed some minor issues in the SSSP example.Fixed a bug in MusicProfiles that wasn't generating the user-user graph properly.Changed the PageRank library method to initialize the vertex ranks.This closes #470",5
[FLINK-1652] fixes superstep increment in CollectionExecutorThis closes #464,0
[FLINK-1632][gelly] Deleted GraphUtils and made Gelly methods use DS.count(),1
[FLINK-1632][gelly] Removed bcast var in GraphMetrics and PageRankThis closes #462,4
Link to IntelliJ setup guide from README [ci skip],1
[FLINK-1714] Fix logger of the class SecurityUtilsThis closes #490,2
[FLINK-1414] Move quickstarts to website,4
[FLINK-1342] Use maven-shade-plugin in quickstarts to build fat-jarThis closes #486,1
[docs] Remove -j and -a parameters which seemed no longer valid in the doc example for submit job to Flink run in YARN.From:./bin/flink run -j ./examples/flink-java-examples-{{site.FLINK_VERSION_SHORT }}-WordCount.jar \      -a 1 hdfs:///..../apache-license-v2.txt hdfs:///.../wordcount-result.txtTo:./bin/flink run ./examples/flink-java-examples-{{site.FLINK_VERSION_SHORT }}-WordCount.jar \       hdfs:///..../apache-license-v2.txt hdfs:///.../wordcount-result.txt,5
[FLINK-1695] [ml] Initial commit to establish module structure. Adds simple Vector and Matrix types.,1
[FLINK-1696] [ml] Adds batch gradient descent linear regression with l2 norm[ml] Adds batch gradient descent linear regression with convergence criterion as relative change in sum of squared residuals[ml] Adds comments to MultipleLinearRegression,1
[FLINK-1697] [ml] Adds alternating least squares (ALS) implementation with test case[ml] Adds comments to ALS,1
[ml] Introduces FlinkTools containing persist methods.[ml] Changes comments into proper ScalaDoc in MultipleLinearRegression,2
[FLINK-1698] [ml] Adds polynomial base feature mapper and test cases[ml] Adds comments to PolynomialBase,1
[FLINK-1696] [ml] Adds web documentation for multiple linear regression. Changes website links from relative to absolute.,2
[FLINK-1697] [ml] Adds web documentation for alternating least squares. Adds web documentation for polynomial base feature mapper.[ml] Adds comments[ml] Set degree of parallelism of test suites to 2[ml] Replaces FlatSpec tests with JUnit integration test cases in order to suppress the sysout output.[ml] Adds missing clients-test jar[docs] Sets jekyll's baseurl to http://ci.apache.org/projects/flink/flink-docs-master[ml] Replaces JBlas by java netlib to avoid license issues of included fortran libraries[ml] Adds com.github.fommil.netlib:core to license file[ml] Adds Scala docs to FlinkTools[ml] Adds comments to LabeledVector and the math package objectThis closes #479.,1
[docs] Fixes typo in cluster_setup.md and links in sidenav.html and navbar.html,2
[docs] make the nav bar scroll instead of fixing it at the top- we gain some precious space which helps people reading the docs,2
"[docs] Fixes broken ""Build Flink"" link in sidenav.html",2
[FLINK-1641] Make projection operator chainable.Closes #489,1
"[FLINK-1350] [runtime] Add blocking result partition variant- Renames runtime intermediate result classes:  a) Removes ""Intermediate"" prefix  b) Queue => Subpartition  c) Iterator => View- [FLINK-1350] Adds a spillable result subpartition variant for BLOCKING  results, which writes data to memory first and starts to spill  (asynchronously) if not enough memory is available to produce the  result in-memory only.  Receiving tasks of BLOCKING results are only deployed after *all*  partitions have been fully produced. PIPELINED and BLOCKING results can not  be mixed.- [FLINK-1359] Adds simple state tracking to result partitions with  notifications after partitions/subpartitions have been consumed. Each  partition has to be consumed at least once before it can be released.  Currently there is no notion of historic intermediate results, i.e. results  are released as soon as they are consumed.",1
[FLINK-1350] [runtime] Set result type to BLOCKING if data exchange mode is BATCH,4
[runtime] [tests] Run ProcessFailureBatchRecoveryITCase in BATCH and PIPELINED execution mode,0
[FLINK-1671] [optimizer] Fix comment typos,2
[FLINK-1622][java-api][scala-api] add a GroupCombine operatorThe GroupCombine operator acts like a the optional combine step in theGroupReduceFunction. It is more general because it combines from aninput to an arbitrary output type. Combining is performed on thepartitions with as much data in memory as possible. This may lead topartial results.The operator can be used to pre-combine elements into an intermediateoutput format before applying a proper groupReduce to produce the finaloutput format.* make Combine and FlatCombine generic by adding an output type* add documentation* Reuse GroupReduceCombineDriver and SynchronousChainedCombineDriver for GroupCombine operator** make them more generic by specifying input and output type** implement AllCombineDriver* add Java tests* add Scala testThis closes #466,3
Quick fix to fix compile error due to change class name of MultipleProgramsTestBase.TextExecutionMode in GroupCombineITCase.,3
Fix indentation for JobManager ScheduleOrUpdateConsumers and space for if-else.,5
[docs] [streaming] Quick fix for batch lexers in streaming guide,0
[ml] [tests] Force pipelined execution of ALSITCaseThis a temporary workaround to force pipelined execution of this test. Thedefault execution mode currently leads to a deadlock.,3
[FLINK-1436] [docs] update command line documentation,2
[FLINK-1739] [runtime] Fix the bug of the jobManager and TaskManager IPC Port Check.This closes #499,0
[yarn] Add final modifier to PollingThread#lock object to make sure immutability.This closes #494,1
[FLINK-1720] Integrate ScalaDoc into JavaDocThis closes #497,2
[FLINK-1724] [tests] Respect number of task managers in TestingClusterStarting a task manager via TestingUtils does not respect the number ofconfigured task managers and mis-configures the task managers to use localnetwork communication (LocalConnectionManager instead ofNettyConnectionManager).,1
[FLINK-1709] Add initial SlotCountExceedingParallelismTestThis commit squashes:- [jobmanager] Add subtask index to state transition debug msg- [jobmanager] Fix typo in ResultPartition deployment descriptor- [jobmanager] Fix missing queue scheduling modeThis closes #498.,0
[FLINK-1752][streaming] Rework and improve Kafka connectors,1
[FLINK-1752][streaming] Add KafkaITCase and various bugfixesThis closes #500,0
[FLINK-1706] Spilling BarrierBuffer added + basic tests,3
[FLINK-1706] Resource cleanup added streaming readers with BarrierBuffers,1
[FLINK-1706] IOTest added for BarrierBuffersCloses #493,1
[FLINK-1721] [yarn] Temporarily disable search for exceptions in the YARN log due to akka bug,0
"[FLINK-441] [optimizer] Rename ""o.a.flink.compiler"" to ""o.a.flink.optimizer""",2
[FLINK-441] [optimizer] Removed obsolete plan validator,5
[FLINK-441] [optimizer] Remove obsolete and unused utility classes,1
[FLINK-441] [optimizer] Rename Pact* and Nephele* classesAlso clean up and improve various comments and method names.,1
[optimizer] Migrate first set of tests (branching plans) to new API,1
[optimizer] Moved optimizer graph traversals to dedicated classes to simplify Optimizer class.,4
"[optimizer] Rename optimizer project to ""flink-optimizer"" (previously flink-compiler)",2
[streaming] Added thread-safe list to tests,3
[FLINK-1594] [streaming] Added StreamGraphEdges,1
[FLINK-1594] [streaming] Embedded StreamEdges,2
[FLINK-1594] [streaming] Fixed co-tasks input handling,0
[FLINK-1594] [streaming] Added OutputSelector wrapping,1
[streaming] Added Reader and Writer factories & minor cleanup,4
[FLINK-1594] [streaming] Self connect tests and fixesCloses #472,0
[FLINK-1618] [streaming] Parallel time reduceCloses #485,2
[FLINK-1715] [streaming] Removed unnecessary print messages,4
test refactoring fix,0
[streaming] [FLINK-1740] Pass config param for numberOfExecutionRetries to the JobGraph for streaming jobsCloses #501,2
[FLINK-1757] [streaming] Fixed type cast bug in SumFunction,1
"[runtime] Fix scheduleOrUpdateConsumers logic for blocking resultsFor tasks producing mixed pipelined and blocking results, the scheduling ofreceivers could lead to deadlocks, because of missing notifications.This problem was discovered in the ALSITCase, where the iteration head isproducing pipelined results for the step function and blocking results forthe final results. The receivers of the final blocking result never gotnotified.This commit adds a separate test case to test the correct behaviour and revertsthe changes introduced in dafcd4e to force pipelining in ALSITCase.",5
[FLINK-1760] [maven] Added Scala version profiles to support building with Scala 2.11,1
[FLINK-1760] Add travis profiles for scala-2.11 builds.This closes #477,2
[runtime] Slight improvements and tests in the Buffer class,3
[streaming] StreamExecutionEnvironment methods for streaming fault tolerance,5
Small changes to make code more consistent.Change System.err to System.out calls for regular flow messages in FlinkYarnSessionCli.Code style add spaces between if-else and open parentheses and curly braces.Wrap very long lines in some classes.Remove unnecessary return statement at the end of a method.,4
[FLINK-1765] [streaming] GroupedReduceInvokable chaining fix + minor FilterInvokable fix,0
[streaming] ChainableInvokable refactor,4
[FLINK-1761] Fix IndexOutOfBoundsException when receiving empty bufferThis closes #504,0
[FLINK-1761] [runtime] Fix sequence number mismatch on empty buffer drop.,4
[streaming] Improve comments for source functions. Minor cleanups.,4
[streaming] Add test that runs streaming with fault tolerance,1
[FLINK-1688] [streaming] Socket client sink added,1
[FLINK-1688] [streaming] [api-extending] Socket Client Sink added to the DataStream APIMoved Serialization Schemas from connectors to coreMinor cleanups for Socket Client SinkThis closes #484,4
[FLINK-1756] [streaming] Rename Stream Monitoring to Stream CheckpointingAlso set the default checkpoint interval to 5 secs instead of 10.This closes #506,1
[FLINK-1763] [streaming] Remove cancel from SinkFunctionThis closes #513,1
[FLINK-1679] deprecate API methods to set the parallelism,1
[FLINK-1679] use a consistent name for parallelism* rename occurrences of degree of parallelism to parallelism* [Dd]egree[ -]of[ -]parallelism -> [pP]arallelism* (DOP|dop) -> [pP]arallelism* paraDegree -> parallelism* degree-of-parallelism -> parallelism* DEGREE_OF_PARALLELISM -> PARALLELISM,1
[FLINK-1679] deprecate old parallelism config entryold config parameter can still be usedOLDparallelization.degree.defaultNEWparallelism.default,1
[FLINK-1679] extend faq and programming guide to clarify parallelism,2
[Travis] Set checkout depth to 100 to avoid failed builds due to long build queues at travis,0
[FLINK-1767] [streaming] Make StreamExecutionEnvironment return JobExecutionResult instead of void.Conflicts:flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/LocalStreamEnvironment.javaflink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/util/ClusterUtil.javaThis closes #516,5
[docs] Fixes Java broadcast variable example,0
[logging] use correct class name for logging BlobServerConnectionThis closes #514,2
"[runtime] Return null at input gate after all end-of-partition eventsPreviously, the input gate user needed to be aware whether it is safe to querythe input gate for more data or not. If a user mistakenly queried an input gatefor data, the blocking call never returned.",5
[docs] Adds akka configuration descriptionThis closes #527.,5
Update Javadoc from Nephele task manager to Task Manager; add missing Javadoc params in RegularPactTask#getOutputCollector.,1
[FLINK-1770]Rename the variable 'contentAdressable' to 'contentAddressable'Rename the variable 'contentAdressable' to 'contentAddressable' in order to better understanding.Author: hongsibao <hongsibao@huawei.com>Closes #515 from matadorhong/RenameVariableMoreReasonable and squashes the following commits:40c7312 [hongsibao] Rename the variable 'contentAdressable' to 'contentAddressable',1
[FLINK-1544] [streaming] POJO types added to AggregationFunctionTestThis closes #517,3
[FLINK-1756] [streaming] Rename Stream Monitoring to Checkpointing in JobGraph.This is improves #506This closes #531,1
[Flink-1780] Rename FlatCombineFunction to GroupCombineFunctionThis closes #530,1
[FLINK-1512] [java api] Add CsvReader for reading into POJOs,1
[FLINK-1512] [scala api] Add CsvReader for reading into POJOs,1
[FLINK-1512] [tests] Add integration tests for CsvReaderThis closes #426,3
[FLINK-1512] [documentation] Added CSV to POJO feature to documenation.,2
[hotfix] [doc] Fix DataSet type in readCsvFile example,2
"[runtime] Refactor partition consumable notificationMoves the partition consumable notification out of ResultPartition. This makesit easier to setup unit tests, where no job manager is available to notify.",3
"[runtime] Fix possible resource leak in RemoteInputChannelIt was possible that a concurrent release and enqueue operation from thenetwork I/O thread leave a buffer queued at a released channel, resulting in aresource leak.This commit fixes this and adds a test, which successfully provoked the racecondition before the fix.The visibility of input channel operations is reduced to package private.",0
[FLINK-1755] Fix possible NullPointerException in LocalInputChannelThis commit squashes: - [runtime] Rename create read view methods to be consistent - [runtime] Fix spillable subpartition view read offset after spilling - [tests] Add comment to ScheduleOrUpdateConsumersTest,5
[streaming] Kafka documentation update,5
[FLINK-1773] [streaming] Introduced CentralActiveTrigger with GroupedActiveDiscretizerCloses #523,2
[FLINK-1775] BarrierBuffer fix to avoid end of stream deadlockCloses #534,0
[FLINK-1769] Fix deploy bug caused by ScalaDoc aggregation,2
[FLINK-1785] [test] Master tests in flink-tachyon fail with java.lang.NoSuchFieldError: IBM_JAVA.Move the hadoop-hdfs and hadoop-common test jars dependency before Tachyon.Looks like Maven respect the ordering of dependencies and first declarations win.Seemed like Tachyon brings transitive dependencies of older hadoop versions.Author: Henry Saputra <hsaputra@apache.org>Closes #536 from hsaputra/FLINK-1785_add_hadoop_deps_to_test_scope and squashes the following commits:f266a6c [Henry Saputra] [FLINK-1785] [test] Master tests in flink-tachyon fail with java.lang.NoSuchFieldError: IBM_JAVA.,0
[FLINK-1686] [streaming] Use different slot identifier per iteration,1
[FLINK-1686] [streaming] add parallel iteration test,3
[FLINK-1726][gelly] Added Community Detection Library and ExampleThis closes #505,1
[gelly] corrected community detection usage description and moved it from the library method to the example;removed unnecessary @SuppressWarnings(serial) from SSSP,2
[Flink-contrib] Flink dev cluster on Docker with Docker Compose deploymentThis closes #533,2
[FLINK-1501] Add metrics library for monitoring TaskManagersThis closes #421,1
[FLINK-1650] Set akka version to 2.3.9,1
[FLINK-1650] Let Netty(Akka) use Slf4jThis closes #518,1
[FLINK-1790]Remove the redundant import codeRemove the redundant import code in TaskManagerAuthor: hongsibao <hongsibao@huawei.com>Closes #538 from matadorhong/RemoveRedundantImport and squashes the following commits:1f80c0d [hongsibao] Remove the redunant import code,2
[FLINK-1781] [quickstarts] Fix exclusions for different Scala versions.Also exclude more large transitive dependencies.,0
"[quickstarts] Remove redundant old fat jar assembly file.Adjusts the comments inside the POM file to encourage use ov ""mvn clean package"",rather than ""mvn clean install"".",4
[FLINK-1783] [quickstarts] Quickstarts create no dependency-reduced POM.,1
Add missing import.,2
[FLINK-947] Add parser to Expression API for exposing it to Java,1
[FLINK-1623] Rename Expression API to Table APIPackage name is now flink-table. ExpressionOperation is renamed toTable.This also adds more JavaDoc and ScalDoc.,2
[maven] Fix maven snapshot deployment for Hadoop2 profile.,2
[FLINK-1795] [runtime] Add test for duplicate elimination in the solution set.,1
[tests] Remove incomplete and unused LineRankITCase.,1
"[FLINK-1796] [jobmanager] In local mode, the embedded TaskManager is watched by a process reaper as well.",2
[tests] Add template log4j.properties files for testsAlso clean up some unused imports.,2
[FLINK-1669] [streaming] Test for streaming recovery from process failureThis closes #496,0
[FLINK-1669] [streaming] Clean up and fix test for streaming fault tolerance with proess failures,0
[FLINK-1633] [gelly] Added getTriplets() method and test,3
[FLINK-1633] [gelly] some cosmetic changes to getTriplets and EuclideanGraphExampleThis closes #452,1
[runtime] Improve error messages and add tests for failed library downloads on TaskManagers,0
[tests] Improvements in timeouts for test stability on quirky Travis VMs,3
[FLINK-1779] [runtime] Rename the function name from getCurrentyActiveConnections to getCurrentActiveConnections in org.apache.flink.runtime.blobThis closes #529,2
[FLINK-1774] Remove the redundant code in try{} block.This closes #522,1
"[FLINK-1801] [FLINK-1465] Network environment can start prior to TaskManager in ""disassociated"" mode.NetworkEnvironment allocates heavy network buffer pool on startup and supportsmultiple associations / disassociations with the TaskManager actor.Fix negative memory report by replacing overflowing ints with longs.",0
Small clenaup to wrap very long lines in flink-runtime package.,2
"[FLINK-1771] Add support for submitting single jobs to a detached YARN sessionWith this change, users can submit a Flink job to a YARN cluster without having a local client monitoring the Application Master or job. You can basically fire and forget a Flink job to YARN.For supporting this, the ApplicationMaster can now monitor the status of a job and shutdown itself once it is in a terminal state.The change also verifies that various ways of setting the parallelism on YARN are passed through the system correctly (per job, session).There was a bug in YARN container creation which made the configuration values for the heap offset useless. This change fixes this error.All mentioned features and bugs are covered by the flink-yarn-tests.This closes #542",3
[FLINK-1806] Improve error message when no S3 access/secret key configured,5
[FLINK-1794] [test-utils] Adds test base for scala tests and adapts existing flink-ml tests[FLINK-1794] [test-utils] Adds scala docs to FlinkTestBaseThis closes #540.,3
"[FLINK-1805]The class IOManagerAsync should use its own Log instanceAlthough class 'IOManagerAsync' is extended from 'IOManager' in package 'org.apache.flink.runtime.io.disk.iomanager', but I think it should has its own Log instance.Author: hongsibao <hongsibao@huawei.com>Closes #546 from matadorhong/FLINK-1805 and squashes the following commits:89c0dd7 [hongsibao] Use private instead of protected56b9dab [hongsibao] The class IOManagerAsync(in org.apache.flink.runtime.io.disk.iomanager) should use its own Log instance",2
"[FLINK-1766]Fix the bug of equals function of FSKeyThe equals function in org.apache.flink.core.fs.FileSystem.FSKey should first confirm whether obj == this, if obj is the same object.It should return trueAuthor: hongsibao <hongsibao@huawei.com>Closes #511 from matadorhong/Bug_Flink_1776 and squashes the following commits:1ad06d7 [hongsibao] Fix the code format problem431fc4b [hongsibao] Fix the code format problemab0ae5e [hongsibao] [FLINK-1766]Fix the bug of equals function of FSKey",1
[FLINK-1662] [streaming] Triggering on fake element bugfix,0
[FLINK-1797] Add jumping pre-reducer for Count and Time windowsCloses #549,1
[FLINK-1718] [ml] Adds sparse matrix and sparse vector types,1
[ml] Adds convenience functions for Breeze matrix/vector conversion[ml] Adds breeze to flink-dist LICENSE file[ml] Optimizes sanity checks in vector/matrix accessors[ml] Fixes scala check style error with missing whitespaces before and after +[ml] Fixes DenseMatrixTest,3
[FLINK-1718] [ml] Unifies existing test casesThis closes #539.,3
[travis] Fix YARN container log upload to s3 on Travis,2
[streaming] Streaming program cancellation bugfix,0
[tools] Add --abbrev-ref to get the right branch name of HEADAdd --abbrev-ref to get the right branch name of HEAD rather than checksum to return back to original branch.Without it will make merge tool to go to unnamed branch.Somehow old PR #548 could not be reopen so submit new one. SorryAuthor: Henry Saputra <henry.saputra@gmail.com>Closes #552 from hsaputra/fix_merge_tools_to_get_original_head and squashes the following commits:98d2d97 [Henry Saputra] [tools] Add --abbrev-ref to get the right branch name of HEAD rather than checksum to return back to original branch.,1
[FLINK-1717] [ml] Adds support to directly read libSVM and SVMLight filesThis closes #543.,2
[FLINK-1811] Allow passing custom buffer sizes and timeouts to PersistentKafkaSourceThis closes #558,4
[FLINK-1589] Add option to pass configuration to LocalExecutorThis closes #427,5
[FLINK-1753] [streaming] Added test for Kafka connector with tuple typeThis closes #557,3
[FLINK-1777][Documentation] Improved documentation for Java 8 Lambdas in EclipseThis closes #528,1
[FLINK-1716] [ml] Adds CoCoA algorithm[ml] Adds web documentation and code comments to CoCoA[ml] Adds commentsThis closes #545.,1
[FLINK-1816] [gelly tests] Fixes wrongly introduced exception checks in DegreesWithExceptionITCase,0
[yarn][streaming] Add support for streaming fire and forget yarn job submissions.,1
Added support for Apache Tez as an execution environmentThis closes #189,1
[FLINK-1788] [table] Make logical plans transformable,2
[FLINK-1803] [streaming] returns(..) method added to Stream operatorsThis closes #556,1
[release scripts] Update scripts for 0.9.0-milestone1,5
[FLINK-1656] Filter ForwardedField properties for group-at-a-time operators in Optimizer.This closes #525,1
[FLINK-1776] Add offsets to field indexes of semantic properties for operators with key selectorsThis closes #532,1
[FLINK-1664] Adds check if a selected sort key is sortableThis closes #541,1
Fix the constructor comments with correct parameter in DefaultMemoryManagerCloses #568,2
[FLINK-1824] [streaming] Support added for missing types in DataStream apiCloses #567,5
[FLINK-1808] [streaming] Send barrier requests only when the execution graph is runningCloses #551,1
[FLINK-1580] [taskmanager] Improve TaskManager startup robustness     - Initialize network buffer pool and memory manager before the       asynchronous actor start     - Split messages into more topic-related groups     - Split message handling logic on TaskManager into topic-related functions     - Simplify registration logic     - Add a lot of tests that validate       - task manager configuration checking       - task manager registration       - task manager re-registration on failures/disconnects,0
[runtime] Simplify TaskExecutionState by removing obsolete manual serialization code.,4
[runtime] Fix bug that deploys to wrong target TaskManager slot,1
[runtime] Remove old redundant classes  - StringRecord -> StringValue  - IntegerRecord -> IntValue  - FileRecord -> obsolete,2
[streaming] WindowWordCount example added,1
[runtime] Add docs to BufferPool classes,2
[TaskManager] Add test for failure behavior on TaskManager startup,0
[runtime] Improve robustness of test TaskManagerRegistrationTest.Also rename jobmanager.TaskManagerRegistrationTest to avoid name conflicts.,5
Fix issue where Windows paths were not recognized as absoluteAdded Windows test cases to Path testsThis closes #491,3
Additional tests for Path.isAbsolute(),3
[FLINK-1817] Fix ClassLoaderObjectInputStream to support primitive type classesThis closes #565,1
[FLINK-1560] [streaming] Streaming examples rework,1
[FLINK-1560] [streaming] Added ITCases to streaming examples,1
[FLINK-1560] [streaming] Streaming example ITCases cleanupThis closes #519,4
[FLINK-1837] [streaming] Throw Exception for checkpointed iterative programsCheckpointing currently does not support this special case,1
"[maven] [quickfix] Don't exclude Zookeeper in flink-streaming-connectorsRunning package locally resulted in the following error:[ERROR] Failed to execute goal ... on project flink-streaming-connectors: Compilation failure[ERROR] .../KafkaTopicUtils.java:[57,25] cannot access org.apache.zookeeper.Watcher[ERROR] class file for org.apache.zookeeper.Watcher not foundMysteriously, this does not happen on Travis.",2
[runtime] Remove old unused classes,1
[runtime] Fix TaskManager's BLOB service host lookup when connecting to the JobManager,0
Remove 'executable' permission from various non-executable source files,2
[contrib] Remove redundant LICENSE file in 'flink-contrib/docker-flink',2
"[licences] Updated LICENSE and NOTICE file of the binary distribution to contain dependencies of 'flink-dist'.This means that the LICENSE and NOTICE files reflect all dependencies that we includein the binary distribution, but not those of artifacts pulled only through maven.",2
[FLINK-1832] [scripts] fix conversion to Windows path with spaces,0
[FLINK-1832] [scripts] fix start scripts for Cygwin and paths with spaces.This closes #575,0
[FLINK-1840] Fix BLOB manager on WindowsThis closes #578,0
[FLINK-1839] Reworked TwitterStreamITCase for testabilityThe job is now commutative and associative and thus testable in parallel.,3
[dist] Excludes the empty *-tests.jar from being copied to the flink-dist/../examples directory,2
[FLINK-1841] [streaming] More permissive WindowJoinITCaseInstead of a checking against a concrete output it only determines well-formedness.,5
[doc] Fix typos and formatting in Flink on Tez doc,2
[FLINK-1813] Avoid illegalstate exception when trying to broadcast on finished operatorsCloses #577,1
[quickstart] Error msg in streaming quickstarts when run with wrong number of arguments,0
[runtime] Fix erroneous import of shaded dependency,2
[hotfix] Fix scaladoc in Table.scala Examples,2
[hotfix] Fix scaladoc in Table.scala Examples (second try),1
[FLINK-1793] [streaming] Fix file source isRunning check for proper cancelling,1
[FLINK-1823] Remove linq from Table API documentation,2
[FLINK-1800] [docs] Add beta tag to components in flink-stagingThis closes #555.,2
[tests] SumMinMaxITCase to use collect() rather than flakey temp files,2
[FLINK-1847] [Scala API] Changes the return type of Scala API's collect method to Seq[T] and adds parentheses to collect and count methods. - Updates existing test cases using Scala API's collect/count method.This closes #583,1
[FLINK-1694] [gelly] added IterationConfiguration as a way to configure a VertexCentricIteration,5
[FLINK-1694] [gelly] fixed typo and a small code simplificationThis closes #547,2
[FLINK-1741] [gelly] Adds Jaccard Similarity Metric ExampleThis closes #544,1
[gelly] minor javadoc correction: the Graph is always directed.,2
[quickstarts] Set different default groupid for quickstarts to avoid exclusion by the assembly plugin,1
[docs] Add custom searchThis closes #563.,1
[docs] Add clickable stack figure on overview pageThis commit adds a figure giving an overview of Flink's stack. Users can clickon components to go to the respective component docs.This closes #585.,2
"[runtime] Accumulators are reported through the RuntimeEnvironment, not directly sent as an actor message",1
[FLINK-1535] [core] Rework accumulators  - Accumulators rely consistently on java serialization  - Fix accumulator transport to support custom classes  - Fix collect() accumulator to use correct class loader,1
[FLINK-1535] [tests] Add custom acumulators and custom type collect() to classloading testsConsolidate class loading tests into one cluster execution to validate repeated different class loaders,5
[tests] Revert accidentally committed log level change for tests,3
[FLINK-1850] Fix version on startpage,0
[runtime] [tests] Remove RemoteInputChannelTest timeout,3
[FLINK-1835] Stabilize YARN tests,3
[FLINK-1862] [apis] Add support for non-serializable types for collect() by switching from Java serialization to Flink serialization,2
[tests] Increase robustness of SimpleRecoveryITCase,1
[streaming] ITCase for WindowWordCount,5
[FLINK-1838] [doc] Streaming programming guide update,5
[streaming] Removed unnecessary BatchIterator class,4
[streaming] Cancellation update in connectors,5
[flink-yarn-tests] Make error messages verbose for debugging,0
"[docs] Remove skeleton page from navigation, add links to ML pages",2
[FLINK-1710] [table] Switch compile backend to JaninoThis greatly reduces compile time while still supporting the samefeature set.,1
[FLINK-1879] [client] Simplify JobClient. Hide actorRefs behind method calls where possible. - Drop redundant routing actor - Consistently set the flag to subscribe to updates or not. - Scala style cleanups: Drop default values for some method parameters.,2
[FLINK-1868] [tests] Fix corner case of EnvironmentInformationTest,5
[FLINK-1878] [APIs] Environments accept a flag that controls sysout logging during execution.,2
[tests] Cleanup sysout logging in tests,3
[docs][yarn] Use SNAPSHOT flink version in SNAPSHOT documentation,2
[runtime] Avoid IllegalStateException when TaskManager is killed during startupThis closes #587,1
[build system] Exclude log4j.properties files from uberjar and module jarsThis closes #586,2
[FLINK-1866] [streaming] StreamConfig key bugfix,0
[FLINK-1660] [streaming] [tests] Fix MultiTriggerPolicyTest raceCloses #590,3
[FLINK-1753] [streaming] Added Kafka broker failure testThis closes #589,3
[scripts] Update error message for missing commands of the jobmanager.sh script,0
[hotfix] Fix invalid timeout in JobClient,0
[FLINK-1876] [streaming] StreamGraph refactor,4
[streaming] Major internal renaming and restructureCloses #594,5
[FLINK-1753] Extend KafkaITCase with large messages test + rework PersistentKafkaSource.This closes #603,1
[FLINK-1900] Fix Scala Table API Example in doc,2
[FLINK-1856][doc] Add notice about implicit TypeInformation,5
[streaming][connectors] Add more configuration options to PersistentKafkaSourceThis closes #607,5
[docs] Corrects combineGroup documentation example,2
[FLINK-1902] Show jobmanager address/port in configuration,5
[FLINK-1900] add missing ',1
Fix the message in runtime exceptionThis closes #599,1
[docs] fixed a few typos in internal_general_arch.mdThis closes #602,2
[streaming] Parallel time reduce logic refactor to force prereducers,1
[FLINK-1906] [docs] Add tip to work around plain Tuple return type of project operatorThis closes #611,1
[FLINK-1809] Add Preprocessing package and Standardizer to ML-library[FLINK-1809] Add documentation for Standard Scaler[FLINK-1809] [ml] Integrates standard scaler documentation into the web siteThis closes #579.,2
[streaming] Fixes kafka test logging,2
[FLINK-377] Generic Interface,2
[FLINK-671] Python API,2
"Added examples of TPCH Query 3 and Query 10, WebLogAnalysis",2
[Flink-671] Python API additionsFixes several minor issuesRequesting non-available data throws ExceptionPython process shutodwn more reliableSynchronization done via TCP,5
[FLINK-703] [java api] Use complete element as join key,1
[FLINK-703] [scala api] Use complete element as join keyThis closes #572,1
[FLINK-1891] Add check for empty storageDirectory pathThis closes #601,1
"[FLINK-1486] add additional print method for prefixing a user-defined string- extend API to include a print(String sinkIdentifier) method- change PrintingOutputformat to include the sink identifier- if appropriate, print sink identifier and task id- update documentationThis closes #372",2
[FLINK-1878] [streaming] Stream environments accept a flag that controls sysout logging during execution.,2
[FLINK-1918] [client] Fix misleading NullPointerException in case of unresolvable host names,0
[client] Work around limitations of JDK 1.6 in InetSocketAddress,1
[docs][typo] Replace reduceGroup() with reduce() in the GroupReduceFunction interface,1
[FLINK-1875] Add figure explaining slots and parallelismThis closes #604,5
[build system][travis] avoid hanging builds when downloading cache archives,5
[FLINK-1909] [streaming] Type handling refactor for sources + scala api,4
[docs] Change doc layout- Changed layout (simple as possible)- Fix broken version references in docs- Update README- Removed dead resources- Reorganized content[docs] Address PR comments[docs] Address @ktzoumas comments[docs] Fix download link[docs] Fix front page stack link to TezThis closes #606.,2
[FLINK-1422] [docs] Add function parametrization docsThis closes #350.,2
[streaming] Small fixes for StreamConfigThis prevents toString() throwing null pointer exceptions.,5
[streaming] FullStream window helper added + partitioner bugfixCloses #614,0
[FLINK-1799][scala] Fix handling of generic arrays,0
[FLINK-1930] [runtime] Improve exception when bufferpools have been shut down.,1
[hotfix] Bump asm version to 5.0.3,0
[streaming] StreamConfig now uses InstantiationUtils for serialization,1
[streaming] Stream operators robustness improved for serilizationThis closes #620,1
[FLINK-1867/1880] Raise test timeouts in hope of fixing Travis fails,0
[FLINK-1514] [gelly] Add a Gather-Sum-Apply iteration method,1
"[FLINK-1514] [gelly] Removed GGC example, added Connected Components instead",1
[FLINK-1514] [gelly] Unified create and run for GSA iterations,1
[FLINK-1514] [gelly] improvements to the GSA SSSP example;improvements to the GSA Connected Components example,1
[FLINK-1514] [gelly] suppressed warnings in several places; adjusted tests,3
[FLINK-1514] [gelly] renamed fields in Neighbor class; added forwarded fields hint in GSAIteration,1
[FLINK-1514] [gelly] Simplified GatherUdf; added forwarded fields annotations,1
[FLINK-1514] [gelly] Removed edge value type from ApplyFunction; Reuse the output vertexThis closes #408,1
[FLINK-1758] [gelly] Neighborhood Methods Extensions,2
[FLINK-1758] [gelly] Replaced groupReduce with reduce,2
[FLINK-1758][gelly] Made reduce methods operate on values,1
"[FLINK-1758] [gelly] made reduceOnEdges and reduceOnNeighbors only have accees to edge/vertex values, not IDs",2
[FLINK-1758] [gelly] [docs] reworked neighborhood methods docsThis closes #576,2
[streaming] Serializable no longer needed for examplesDue to the recent serialization changes.,4
[streaming] Timestamp comparison bugfix,0
"[FLINK-1930] Separate output buffer pool and result partition life cycleThe problem: when a pipelined result is only consumed partially, the buffer poolassociated with the result partition will be destroyed too early. If there is apipelined producer online, which is still producing data for this partition, itwill run into an IllegalStateException.The solution: by separating the life-cycle of the result partition and theassociated buffer pool this cannot happen anymore. The result buffer pool isonly destroyed after the producing task is finished, which is independent ofthe state of the result partition.Furthermore, this commit squashes the following commits:- [FLINK-1930] [tests] Add test for FLINK-1930- [tests] Move iterative tests to correct packageThis closes #624.Close the following unrelated PRs:This closes #112.This closes #134.",1
[hotfix] Raise Akka test timeouts some more,3
[runtime] Bump Netty version to 4.27.Final and add javassistThis closes #617.,1
[FLINK-1924] minor refactoring of the Python API- code formatting- simpler python process initialization- renaming of the python connection following the switch to TCPThis closes #616.,5
FLINK-1693 Add DEPRECATED annotations in Spargel APIs and update the doc to refer to Gelly for Flink graph processing.Mark all user-facing from the Spargel API as deprecated and add a comment in the docs and point people to Gelly.This should help migration to Gelly in the next release.Author: hsaputra <hsaputra@apache.org>Closes #618 from hsaputra/FLINK-1693_deprecate_spargel_apis and squashes the following commits:4652805 [hsaputra] FLINK-1693 Add DEPRECATED annotations in Spargel APIs and update the doc to refer to Gelly for Flink graph processing.,2
[FLINK-1828] [hadoop] Fixed missing call to configure() for Configurable HadoopOutputFormats.This closes #632This closes #571,5
[FLINK-924] Add automatic dependency retrieval for JarFileCreator,2
[FLINK-924] Add JarFileCreator tests for anonymous classes and Java 8 lambdasThis closes #35,3
[docs] [ml] Fixes wrong ALS example code,0
[FLINK-1950] Change safety margin computation for YARN containersThis closes #637,4
[docs] Moves slots_parallelism.svg to correct directory,4
"[yarn] [python] Adds -Xms start option for yarn, fixes python test case to overwrite files, fixes python docsFixes failing yarn test cases",3
[FLINK-1922] [runtime] Fixes NPE when TM receives a null input splitThis closes #631,0
[FLINK-1923] [runtime] Replaces asynchronous logging with synchronous logging using grizzled-slf4j wrapper for Scala.This closes #628,1
[FLINK-1925] [runtime] Splits the processing of the SubmitTask message into two phases:  1. TDD reception with eager acknowledgement and  2. TDD instantiation with a subsequent state update message.This closes #622,5
[runtime] Remove redundant JobType property from JobGraph.,5
[streaming] Change 'getParallelism()' signature to return a primitive to avoid failed equality checks.,0
[runtime] Process reaper gives log time to reach disk before killing the process,2
[runtime] Miscellaneous style cleanups,4
"[FLINK-1953] [runtime] Implement robust and flexible checkpoint coordinator with tests. - Checkpoints can be configured to have different sets of tasks   that triggering the checkpoint barriers, that acknowledging the checkpoint,   and that require checkpoint confirmations. - A configurable number of successful chckpoints can be retained - Checkpoints time out after a certain time, if not acknowledged (prevent resource leaks) - Checkpoints are robust to lost messages and out of order acknowledging.",5
[FLINK-1948] [streaming] Manual task slot sharing settings added for stream operatorsCloses #634,1
[FLINK-1911] [streaming] Projection without specifying types,2
[streaming] Cleanup for projection updateCloses #630,5
[FLINK-1615] [java api] SimpleTweetInputFormatThis closes #621This closes #442,2
[FLINK-1843][jobmanager] remove SoftReferences on archived ExecutionGraphsThe previously introduced SoftReferences to store archivedExecutionGraphs cleared old graphs in a non-transparent order.This closes #639.,4
[hotfix] Remove asm dependency from root pom,4
[docs] fix search form on subpages,0
[FLINK-1883] [gelly] Connected Components exampleThis is a squash of the following commits:[FLINK-1883][gelly] Added Min Vertex Id Propagation library and example[FLINK-1883][gelly] Renamed algorithm to Connected Components[FLINK-1883][gelly] Made the CC library method match Spargel[FLINK-1883][gelly] Polished the CC with Randomised Edges testCloses #596,3
[streaming] Duplicate userfunction eliminated from StreamMap,1
[FLINK-1670] [streaming] Collect function for DataStreamStreams back the results from the job to the client via a TCP socket,5
[FLINK-1670] [streaming] Cleanup for DataStream collectMoved corresponding test to flink-contribRemoved unnecessary printCloses #581,4
[FLINK-1855] [streaming] Add WordCount class into WindowWordCount and SocketTextStreamWordCount example jarsCloses #644,1
[FLINK-1956] [streaming] Proper opening of rich windowfunctions,1
[ml] Adds proper log properties file setting for scalatest plugin,3
[FLINK-1944] [gelly] Added GSA-PageRank exampleThis closes #626,1
[gelly] [docs] Change the return type of groupReduceOnNeighbors exampleThis closes #650,4
[FLINK-1871] [gelly] Added Spargel to Gelly migration guide,1
[FLINK-1871] [gelly] [docs] added a link to the migration guide in the Spargel guide;moved the migration guide section to the end of Gelly guide;made a few corrections in the migration guide textThis closes #600,4
[FLINK-1951] Fix NullPointerException in delta iteration due to missing tempThis closes #641,0
[FLINK-1682] Ported optimizer unit tests from Record API to Java APIThis closes #627,3
[streaming] Added naming for streaming operatorsThis improves tracking of jobs.Closes #654,1
Removed legally questionable tweet data,5
"[runtime] Fix Netty watermark configurationThe watermarks of the NettyServer, which is responsible for data transfers, werenot configured correctly. Instead they were configured for the NettyClient, whichdoes need this fine-grained control as it does not transfer a lot of data.Previously, the default watermarks matched our desired watermarks of 64k (for ourdefault page size) by chance.",5
[FLINK-1978] Fix POJO deserialization for reuse objects with NULL fieldsThis closes #655,1
[streaming] [api-breaking] Changed returntype of WindowedDataStream's mapWindowFor a more consistent behaviour.,5
[FLINK-1937] [ml] Fixes sparse vector/matrix creation fromCOO with a single elementThis closes #636.,1
[FLINK-1933] [ml] Adds distance metrics and documentation to machine learning library[ml] [docs] Add a overview documentation for Distance Metrics[FLINK-1933] [ml] Moves metrics.distances package to org.apache.flink.mlThis closes #629.,2
[gelly] removes generic type constraintsThis closes #657,4
[ml] [docs] Adds distance formulas to documentation. Automatically include latex_commands.html with mathjax markdown files.,2
[scala] Introduces trait type to TypeAnalyzer which avoids compiler warnings due to misclassification as a pojo type,2
"[FLINK-1807] [ml] Adds optimization framework and SGD solver.Added Stochastic Gradient Descent initial version and some tests.Added L1, L2 regularization.Added tests for regularization, fixed parameter setting.Added documentation.Added option to provide UDF for the prediction function, moved SGD regularization to update step.Added prediction function class to allow non-linear optimization in the future.Small refactoring to allow calculation of regularized loss separatly fromregularized gradient.This closes #613.",1
[FLINK-1997][table] Add <> and != for un-equal in expressions,1
"[FLINK-1998][table] Fix equals expressionThe code that was generated for this used ""=="", now it uses .equals()",1
"[FLINK-1792] Add processCPULoad in metricsRegistry, add button toshow/hide graphs, add summary for metricsThis closes #553(Also close the mesos pull request)This closes #251",1
[streaming] Made constructor of GroupedDataStream public,5
[FLINK-1974] Fix getNetRuntime() of JobExecutionResult and add documentation- Fix JobInfo to report milliseconds- Added documentation to indicate that the return type is in milliseconds- Added an getNetRuntime method which accepts a desired time unit for easy conversionThis closes #652,1
[docs] Fix broken links in documentation,2
[streaming] New Source and state checkpointing interfaces that allow operations to interact with the state checkpointing in a more precise manner.,1
"[FLINK-1968] [runtime] Clean up and improve the distributed cache. - Gives a proper exception when a non-cached file is accessed - Forwards I/O exceptions that happen during file transfer, rather than only returning null when transfer failed - Consistently keeps reference counts and copies only when needed - Properly removes all files when shutdown - Uses a shutdown hook to remove files when process is killed",2
[runtime] Fix TaskExecutionState against non-serializable exceptions.,0
"[FLINK-1672] [runtime] Unify Task and RuntimeEnvironment into one class. - This simplifies and hardens the failure handling during task startup - Guarantees that no actor system threads are blocked by task bootstrap, or task canceling - Corrects some previously erroneous corner case state transitions - Adds simple and robust tests",3
Update build target path in README.md,2
[FLINK-1969] [runtime] Remove deprecated profiler code,2
[readme] Update links to IDE setup guide,1
[FLINK-1676] Rework ExecutionConfig.enableForceKryo()This closes #473,5
"[QA] store messages in file instead of in the environmentBash can run out of environment memory if environment variables storetoo much data. When the memory is exceeded, bash can't run systemcommands anymore and, from then on, cryptically fails every command with""Argument list too long"".This closes #670.",0
[FLINK-2001] [ml] Fix DistanceMetric serialization errorThis closes #668,0
[FLINK-1987][docs] Fixed broken linksThis closes #662,2
[FLINK-1928] [hbase] Added HBase write example,1
[FLINK-1928] [hbase] Fix license header for HBase tests,3
[runtime] Improve error messages on Task deploymentThis closes #615,0
[FLINK-785] ChainedAllReduce,2
[FLINK-785] Fixed ObjectReuseITCaseThis closes #370,1
[QA] display max 100 lines of compiler warningshide warning if output file does not exist,2
[streaming] Discretizer reuse bugfixes,0
[FLINK-1953] [runtime] Integrate new snapshot checkpoint coordinator with jobgraph and execution graphThis closes #651,1
"[FLINK-1973] [jobmanager] Task execution state messages are logged on INFO level, rather than on DEBUG level",0
"[streaming] Integrate new checkpointed interface with StreamTask, StreamOperator, and PersistentKafkaSource",1
[FLINK-1935] Reimplement PersistentKafkaSource using high level Kafka API,1
[streaming] StreamTask updated to handle chained states,0
[tests] Fix ProcessFailureRecovery tests by aligning restart delay parameter with heartbeat pause.,1
[tests] Add test that checkes canceling against a failed TaskManager process,0
"[tests] Adapted CoGroupITCase to use ""collect()"" rather than writing temp files (increases robustness)",1
[tests] Consolidate miscellaneous tests into one IntegrationTestCase to reuse minicluster and speed up tests,3
[FLINK-1959] [runtime] Support accumulators in chained functions after a non-UDF operation,1
[FLINK-1595] [streaming] Added complex streaming integration test,3
[streaming] Added proper StreamingMultipleProgramsBaseAlso minor fixes for streaming complex integration testCloses #520,3
[FLINK-2006] [runtime] Fix testing TaskManager task status request to stabilize tests.,3
[FLINK-2011] [runtime] Improve error message when user-defined serialization logic is erroneous,2
[FLINK-1949] Fix issue detecting stopped detached YARN session,0
[FLINK-2008] Fix broker failure test caseThis closes #675,1
[FLINK-1976][gelly] Added ForwardedFields annotations for Gelly functions.This closes #663,1
[FLINK-1525] Implement a tool for parsing input parameters and provide facilities to use them in the system.This closes #664,5
"[FLINK-1711] Converted all usages of commons validate to guava checks(for Java classes), scala predef require(for scala classes)This closes #673",1
[hotfix] Add missing import,2
[FLINK-1975][gelly] Graph getUndirected improvementThis closes #653,1
[FLINK-2019] Use a properly instantiated Kryo in the GenericTypeComparatorThis closes #679,1
[FLINK-1990] Support upper case of `as` for expressionThis closes #667,1
[FLINK-1942] [gelly] GSA Iteration ConfigurationThis squashes the following commits:Split Iteration Configuration into VertexCentric/GSAConfFixed checkstyle errorsThis closes #635,0
[hotfix] Fix link to coding guidelines,2
"[FLINK-2006] [tests] Fix ""TaskManagerTest.testRunJobWithForwardChannel()"" by properly deploying receiver only after sender is running.",1
"Wrap very long line in FlatMapOperator classAs previous discussions before, we do not restrict max chars per line for Java code, but this one just way too long compare to others that I just think make easier to read if we wrap it.Author: hsaputra <hsaputra@apache.org>Closes #683 from hsaputra/wrap_very_long_line_in_FlatMapOperator and squashes the following commits:37d2081 [hsaputra] Wrap very long line in FlatMapOperator class.",1
[FLINK-2022] Put default log4j.properties into quickstart projects,2
[core] Miscellaneous cleanups in the FileInputFormat,2
[FLINK-2041] [optimizer] Remove pipeline breakers where they are subsumed by batch data exchanges.,4
[streaming] Deleted obsolete database connectors,5
[FLINK-1820] Consistent behavior of numeric value parsers.This closes #566,2
[FLINK-1820] Consistent behavior of numeric value parsers.,2
[FLINK-2040] [runtime] Tolerate out-of-order CANCELING and CANCELED messages.,1
[FLINK-1952] [tests] Add a test that runs an iterative job after a failure in another iterative job.This test validates that task slots in co-location constraints are properly freed in the presence of failures.,0
[runtime] Fix for task canceling the order of (1) resource deregistration (2) completeness notification,0
[FLINK-1977] Rework Stream Operators to always be push based,1
"[FLINK-2009] Force chaining for System OperatorsThe system operators are, for example, the StreamDiscretizer andWindowBuffer",1
Disable Test in ComplexIntegrationTest,3
[streaming] ByteStream and File state handle added,1
[streaming] Discard method added to state handle,0
[streaming] StateHandleProvider added for configurable state backend,5
[streaming] Added HDFS test for FileStateHandle,2
[FLINK-1986] [streaming] Iterative stream creation bugfix,0
[streaming] State backend configurable from flink-conf.yamlCloses #676,5
[gelly] [refactoring] Removed Example end string from all gelly examplesAdded Algorithm end string to the library methodsThis closes #625,1
[FLINK-1523] [gelly] Vertex centric iteration extensionsRemoved trailing splits into vertex key and valueMade the extensions optional and separateRemoved overhead when the options are not used,1
[FLINK-1523] [gelly] Added Vertex Centric Configuration TestsThis commit squashes the following:Pratially addressed inline commentsAdded test for removal of a non-SP-edge,4
[FLINK-1523] [gelly] Added VertexWithDegrees as a subclass of Vertex,1
"[FLINK-1523] [gelly] added getIn/Out degrees methods in update and messaging functions;    deleted VertexWithValue type;    deleted InaccessibleMethodException; if the options are not set, -1 is returned;    added missing javadocs;    added tests;    renamed type parameters VertexKey -> K, VertexValue -> VV, EdgeValue -> EV.",2
[FLINK-1523] [gelly] [docs] updated vertex-centric docs accordinglyThis closes #680,2
[gelly] renamed IncrementalSSSPExample -> IncrementalSSSP to match the new examples naming scheme,1
"[FLINK-2025] add support for booleans in csv parserThe following values are parsed as booleans:""true"" or ""1"" -> true""false"" or ""0"" -> falseAll checks are performed case-insensitive.This closes #685.",1
[FLINK-2026][api] add a flag to indicate previous executionsThis closes #686.,1
[runtime] Improve error message for failed network connections due to limited number of file handles,0
[FLINK-2059] Changed flink-compiler to flink-optimizer in the pom.xmlThis closes #701,5
[FLINK-1980] [api] Allow users to decorate input streams* add a decorateInputStream() method as hook in FileInputFormat* provide a InputStreamFSInputWrapper to conveniently wrap InputStreams* base existing .deflate file support on these changes* add a test to verify the decorationThis closes #658,3
[FLINK-2057] [FLINK-2058] [core] Fix hadoop input split class loading and remove IOReadableWritable from InputSplits,4
[streaming] Fixed error logging in streaming tasks.,2
[FLINK-2063] [streaming] Configure checkpoint coordinator to treat all vertices as stateful.,5
"[FLINK-2063] [streaming] Add a streaming exactly once processing test with stateful operators.The counts are off by 1 in some cases, so the test is not activated.I commit it to allow others to use it as a base of investigation.",1
"[FLINK-2062] [core] Fix names of memory size config parameterThis still evaluates the old parameter, if the old one is set and the new one is not set.This closes #703",1
[FLINK-1418] [apis] Change print() to print on the client and to eagerly execute the program.print() now uses collect() internally,1
"[FLINK-1418] [apis] Fix eager print() and adjust all tests and examples to not fail due to ""eager"" print method - Add lastJobExecutionResult for getting the result of the last execution, when executing ""eager"" execution methodsThis closes #699",1
[FLINK-1418] [apis] Minor cleanups for eager on-client print() statement.,4
[FLINK-2071] [java api] Fix serializability issue with projectsion function.Improve type safety.Minor cleanups in ProjectOperator.,1
[examples] Fix remaining examples to properly handle eager print() execution.,0
[FLINK-2023] [scala] Improve type analysis - Exclude static fields in Scala Pojo analysis - Recognize Java Tuples - Clean up legacy code(And also make one of the field type retrieval methods nicer)This closes #669,1
[FLINK-1985] [streaming] Add ExecutionConfig serialization for streaming jobsThis closes #682,5
[FLINK-2052] Fix Serialization warnings in Stream OperatorsThis closes #698,1
[runtime] Extend memory and GC monitor logging.,2
[FLINK-1992] [ml] Adds convergence criterion to Flink's SGD algorithmAdded test case for convergenceThis closes #692.,3
"[FLINK-2034] [ml] [docs] Adds FlinkML web documentation (introduction, vision, roadmap)Also added attribution for some of the Latex in optimization framework.This closes #688.",1
[FLINK-2050] [ml] Introduces new pipelining mechanism using implicit classes to wrap the algorithm logicThis closes #704.,2
[FLINK-2050] [ml] Ports existing ML algorithms to new pipeline mechanismAdds pipeline commentsAdds pipeline IT case,1
"[FLINK-1954] [FLINK-1636] [runtime] Improve partition not found error handlingProblem: cancelling of tasks sometimes leads to misleading error messages about""not found partitions"". This is an artifact of task cancelling. If a task(consumer) consumes data from another remote task (producer), its sends apartition request over the network. If the producer fails concurrently with thisrequest, the request returns with a PartitioNotFoundException to the consumer.If this error message is received *before* the consumer is cancelled (as aresult of the failing producer), you see the misleading error being attributedto the consumer. This makes it hard to trace the root cause of the problem (thefailing producer).Solution: when a consumer receives a remote PartitionNotFoundException, it asksthe central job manager whether the producer is still running or has failed.If the producer is still running, the partition request is send again (using anexponential back off). If the following requests fail again, the consumer failswith a PartitionNotFoundException.If the producer has failed, the consumer is cancelled.If the producer is not running and has not failed, there is a bug either in theconsumer task setup (e.g. requesting a non-existing result) or in the networkstack (e.g. unsafe publication of produced results), in which case the error isattributed to the consumer.---The new Akka messages introduced with this change are only exchanged in errorcases and don't affect normal operation.Normal operation (not affected by this change):- TM1=>TM2: request result- TM2=>TM1: resultError case:- TM1=>TM2: request result- TM2=>TM1: PartitionNotFoundException- TM1=>JM: check partition state- JM=>TM1: retrigger request -OR- cancel consumerThis closes #705.",0
[streaming] Minor bugfix in the BarrierBuffer input finishing logic,2
"[hotfix][table] Fix not-equals code generationThis was using != before, now uses !(a.equals(b))",1
[FLINK-2007] [streaming] Proper Delta policy serializationCloses #697,2
[FLINK-2082] [streaming] Create own context for chained streaming operators,1
[streaming] Fix bug with iteration sink/source syncing,0
"[FLINK-1954] [FLINK-1957] [runtime] Improve error handling of transport failuresProblem: Failures in the network stack were not properly handled and correctlyattributed.Solution: Failures are always attributeed to the client (consumer). This changeintroduces TransportException, which indicates whether the problem ocurredlocally or remotely. This makes it easy to reason about the source of a problem.This closes #713.",0
[streaming] Fix iteration colocation + enable chaining for iterative jobs,5
"[FLINK-2074] Fix erroneous emission of Sliding Time PreReducerBefore this, a sliding time window would keep emitting the last resultbecause the number of elements per pre-aggregation result was notcorrectly reset on eviction.",1
Fix moved comment in StreamTask,4
[runtime] Fix possible IndexOutOfBoundsException when scheduling or updating consumers,5
[FLINK-2056] [ml] [docs] Addes docs for ML pipelinesThis closes #714.,2
[FLINK-1957] Fix NPE during cancelling of partition request,0
[FLINK-2053] [ml] Adds automatic type registration of flink-ml types. Adds de-duplication of registered types at ExecutionConfig. Fixes bug in Breeze SparseVector to Flink SparseVector conversion.This closes #723.,2
[runtime] [tests] Fix possible NPE and add Netty serialization test,3
[FLINK-1920] Properly pass command line arguments with spaces to FlinkThis closes #689,2
[runtime] Fix possible NPE during cancelling,0
[FLINK-2085] [runtime] Add an option to let the MemoryManager allocate and release memory as needed.This is an alternative mode to the current mode that pre-allocates all memory.The default remains to pre-allocate all memory.,1
[FLINK-2084] [core] Add an option to start Flink in streaming mode - Streaming mode sets the memory manager to lazy memory allocation to ensure   heap is not blocked by batch memory manager,1
[tests] Adjust tests for dedicated streaming mode and clean up test bases.This closes #718,3
[tez] Fix Flink-on-Tez use of pre-allocating MemoryManager,1
[quickfix] Made recursive enumeration parameter flag public in FileInputFormat,2
[bugfix] fix FileInputFormat for exclusively two level deep nested files,2
[scripts] Check if execution/streaming mode is set,1
Change FlinkMiniCluster#HOSTNAME to FlinkMiniCluster#hostname to match naming convention.The FlinkMiniCluster contain member variable called HOSTNAME which all caps. The naming of al caps usually reserved for constants and static variable.The PR is changing the name of the variable and the usages.Author: hsaputra <hsaputra@apache.org>Closes #711 from hsaputra/update_hostname_to_match_conventions and squashes the following commits:2a2f3bd [hsaputra] Change FlinkMiniCluster#HOSTNAME to FlinkMiniCluster#hostname to match naming convention.,5
[FLINK-2083] [ml] [docs] Improves FlinkML documentationAdded tables for parameter valuesAdds links to optimization parameter values in the descriptionThis closes #715.,2
[docs] Fix broken images in quickstarts,0
[tez] Fix initialization of MemoryManager.This closes #728,5
[FLINK-2012] [gelly] Added methods to remove/add multiple edges/verticesThis squashes the following commits:[gelly] Removed trailing comment[gelly] Made remove methods use a coGroup fun,1
[FLINK-2012] [gelly] Changed addVertices to operate on vertices onlyThis closes #678,1
[FLINK-1941] [gelly] [docs] added documentation for the Gather-Sum-Apply iterations in Gellyadded SSSP example for vertex-centric; added a comparison section for vertex-centric and GSAThis closes #722,1
[FLINK-1848] Fix for file paths with Windows drive lettersThis closes #712,2
[FLINK-2043] Change the KMeansDataGenerator to allow passing a custom pathThis closes #721,4
[jobmanager] Fix potential null pointer exception in jobmanager webfrontend,0
[FLINK-2079] Add TaskManager deathwatch thread for YARN case,1
[yarn] Adjust default values for YARN heap memory cutoffThis closes #717,5
[scripts] Start JM in batch mode in start-cluster.sh,5
[core] cleanup & tests for FileInputFormatfollowup of f2891ab857e00bc70eb025bb430f46f4f58355a5This closes #732.,2
[examples] Add toString() method to accumulator,1
[FLINK-2073] [ml] [docs] Adds contribution guide. Adds links to FlinkML main site.Adds html titles. Adds explicit operation section to all operators.This closes #727.,1
"[stream] Remove unused StreamSource.javaThis was a remnant, StreamFunction is exactly the same code now.",1
[FLINK-1952] [jobmanager] Rework and fix slot sharing scheduler,0
[tests] Fix AvroExternalJarProgramITCase logging,2
"[tests] Add a ""not-so-mini-cluster"" test to validate scheduler for iterative jobs on many TaskManagersThis closes #731",5
[tests] Consolidate manually triggered tests into a dedicated package,3
[tests] Minor warning cleanups,4
[ml] [docs] Fixes broken back links,2
[streaming] Fix streamrecordwriter behaviour with buffer timeout set to 0,1
[runtime] [tests] Add TaskCancelTest,3
[FLINK-1636] [runtime] Add partition request backoff logic to LocalInputChannel,2
"[FLINK-2089] Fix possible duplicate buffer releaseProblem: RecordWriter instances have stateful serializers, which include thebuffer that they currently work with. If the serializer state is not clearedcorrectly by the writers after writing a buffer to the respective resultpartition, it is possible that buffers are recycled multiple times in failurecases. This results in an IllegalStateException.Solution: After writing a buffer to a ResultPartition, the RecordWriter makessure that the serializer clears the reference to the respective buffer. Therecycling of the buffer is then the responsibility of the result partition.",1
[runtime] [logging] Fix log messageThis closes #736.,1
"[FLINK-2096] Remove implicit conversion from Window Stream to StreamThis causes unexpected behaviour, for example in:ds.window(...).map(..)The user would expect some kind of windowing to take place. Thewindowing, however, cancels out with the implicitly inserted flatten()call.",1
[streaming] [hotfix] Flatten called explicitly on windowing examples,0
[FLINK-1874] [streaming] Connectors separated into individual projects,2
[docs] [streaming] Flume connector temporarily removed from docsAs the Flume source is not working currently.Closes #719,1
[FLINK-2088] [streaming] [scala] DataStream.name() returns a typed DataStreamCloses #739,5
[FLINK-1907] Add Flink Scala ShellThis can either be used to connect to a Flink cluster or in local modewith a cluster in the same JVM.This only works for Scala 2.10 for now because the Scala REPL wasmodified in 2.11.,1
Some code cleanups on Scala Shell,4
Properly include Scala Shell in DocumentationThis closes #672,2
[FLINK-2047] [ml] Renaming CoCoA to SVMThis closes #733.,2
[ml] [docs] Replaces remaining CoCoA names by SVM,5
[FLINK-2104] [ml] Fixes problem with type inference for fallback implicits where Nothing is not correctly treated (see SI-1570)This closes #741.,5
[2104] [ml] Hotfix for wrong class name after renaming,0
[docs] let the squirrel logo point to the homepage,2
[FLINK-2109] [runtime] Fix CancelTaskException handlingThis closes #745.,0
[runtime] Clear serializer state when clearing RecordWriter,1
[hotfix][scala-shell] fix location of classes according to package nameJavadoc was throwing an error because it expected the class files to beorganized in hierarchical directories.,2
[FLINK-1687] [streaming] [api-extending] Synchronizing streaming source API to batch source APICloses #521,2
[FLINK-1687] [streaming] [api-breaking] fromCollection and generateSequence rework,1
[docs] Removed unnecessary Serializable from ExecutionEnvironment JavaDocsAlso did for StreamExecutionEnvironment,2
[streaming] [scala] [api-breaking] StreamExecutionEnvironment API updateCloses #738,5
[FLINK-2112] [streaming] Proper package for kafka tests,3
[streaming] Build warnings eliminated from streaming-core,2
[FLINK-2113][gelly] removed env.execute() after print()This closes #749.,4
[FLINK-2061] [java api] Fix GenericCsvInputFormat skipping fields error with quoted stringThis closes #734,0
[FLINK-2114] [streaming] Fix null check in PunctuationPolicy.toString()Closes #748,0
[FLINK-1954] [FLINK-1958] [runtime] Cancel transfers of failed receiver tasks,0
[FLINK-1954] [FLINK-1955] [runtime] Set task failure cause for produced result partitions,1
[runtime] Fix uncaught exception in Netty server pipeline,0
[runtime] Rename internal field of Netty error messageThis closes #746.,1
[FLINK-2037] Provide flink-python.jar in lib/This closes #691,2
[streaming] Test added for iteration sink-source CoLocation + non-chained windowing,1
[FLINK-2004] Fix memory leak in presence of failed checkpoints in Kafka sourceThis closes #674,0
[FLINK-2121] Fix the recursive summation in FileInputFormat.addFilesInDirThis closes #752,2
[docs][hotfix] fix <p> tag issue by removing <br> tag,4
[FLINK-2132] [scripts] Fix java version extraction,4
[FLINK-1430] [streaming] Scala API completeness for streamingCloses #753,2
"[FLINK-2102] [ml] Add predict function for labeled data for SVM and MLR.These functions return for each example in the input DataSet[LabeledVector] a pair (truth, prediction)Added documentation for new predict functionsThis closes #744.",1
[ml] Adds syntactic sugar for map with single broadcast element. Rewrites the optimization framework to to consolidate the loss function.Adds closure cleaner to convenience functions on RichDataSetRemoving regularization from LossFunction and making it part of the optimizer.This closes #758.,1
[ml] Replaces RichMapFunctions with mapWithBcVariable in FlinkML,2
[ml] Fixes implicit issue with BreezeVectorConverter,0
[streaming] Fixing some javadoc typos,2
Implemented TwitterSourceFilter and adapted TwitterSourcerenamed TwitterFilterSourceTest to TwitterFilterSourceExample and addedJavaDoc comments.Added a dummy twitter.properties to the resource filefixed TwitterSource.javaThis closes #695,2
[FLINK-2103] [streaming] [api-extending] Expose partitionBy to userConflicts:flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/datastream/DataStream.javaCloses #743,5
"[FLINK-2103] [streaming] [api-extending] PartitionBy for connected streams, scala & docs",2
[streaming] [api-breaking] Consolidate DataStream method namesTo better match the names of the DataSet API the following renamings were made:- DataStream.merge -> DataStream.union- DataStream.distribute -> DataStream.rebalance- DataStream.partitionBy -> DataStream.partitionByHashCloses #743,5
[FLINK-2130] [streaming] RMQ Source properly propagates exceptionsCloses #767,2
[FLINK-2069] Fix Scala CSV Output FormatCloses #759,0
[hotfix] Remove execute() after print() in Table API examplesThis closes #735,4
"[FLINK-2070] [core] Deprecate ""print(prefix)"" methods and add ""printOnTaskManager(prefix)"" method.",0
[FLINK-2134] Close Netty channel via CloseRequest msgThis closes #773.,2
[FLINK-2135] Fix faulty cast to GroupReduceFunctionThis closes #769,1
"[FLINK-2126] [scala shell] All tests now dont check for ""Job execution switched to status FINISHED."", which sometimes did not show up.Fixed typo in add numbers testThis closes #768",3
[core] Remove extra li HTML tags in TypeInformation JavaDoc class header.Rhis closes #766,2
[docs/javadoc][hotfix] Corrected Join hint and misleadling pointer to SpargelThis closes #763,2
[FLINK-2076] [runtime] Fix memory leakage in MutableHashTableThis closes #751,0
[FLINK-1993] [ml] Replaces custom SGD logic with optimization framework's SGD in MultipleLinearRegressionFixes PipelineITSuite because of change MLR loss functionThis closes #760.,1
[scala-shell] [docs] Fixes wrong scala shell command in online documentation,2
[hbase] Add a stream data sink for HBaseThis closes #706,1
[streaming] Minor cleanups on data stream.,5
[streaming] [scala] ITCases for streaming scala examples,5
[streaming] Removed StockPrices exampleThe purpose of this was to serve as an example for a blogpost.Moved it to another branch and removed it from the master.Closes #777,4
"[FLINK-2098] Ensure checkpoints and element emission are in orderBefore, it could happen that a streaming source would keep emittingelements while a checkpoint is being performed. This can lead toinconsistencies in the checkpoints with other operators.This also adds a test that checks whether only one checkpoint isexecuted at a time and the serial behaviour of checkpointing andemission.This changes the SourceFunction interface to have run()/cancel() methodswhere the run() method takes a lock object on which it needs tosynchronize updates to state and emission of elements.",5
[FLINK-2098] Improvements on checkpoint-aligned sources,1
[FLINK-1229][docs] Updated web client documentation - WebClient assembler class flag is '-c' (not 'assembler') - doc-building script is named 'build_docs.sh' (not '_build_docs.sh'),2
[FLINK-2123] Fix log4j warnings on CliFrontend startupThis closes #783,2
[javadoc] fix link not found errors on jdk8,0
[FLINK-1892] [tez] Bump Tez dependency to 0.6.1 from 0.6.0 to include tez bugfixes,0
[tests] Increase timeouts for process failure tests in order to compensate for volatile CI environments (Travis),3
"[FLINK-2160] Change Streaming Source Interface to run(Context)/cancel()The context can be used to emit elements and retrieve the checkpointinglock object.In the future, the context can be extended to provide support forelement emission with timestamps and dealing with the watermark system.",5
[FLINK-2165] [TableAPI] Renamed table conversion functions in TableEnvironmentThis closes #793,1
[FLINK-2002] [streaming] Test for iterations being gracefully shut downThe fix was done by gyfora in fdac963.,0
[FLINK-1126][docs] Best practice: named TupleX typesThis closes #786,2
[FLINK-1565][FLINK-2078] Document ExecutionConfig and object reuse behaviorThis closes #781,1
[FLINK-2133] [jobmanager] Fix possible deadlock when vertices transition to final state.,0
[FLINK-2139] [streaming] Streaming outputformat tests,3
[streaming] Socket Client Sink propagates exceptionsCloses #789,5
[FLINK-2136] [streaming] Added test for scala DataStream,5
[FLINK-2136] [streaming] Added parallelism tests to DataStream,5
[streaming] Added throwing exceptions to streaming functions,1
[FLINK-2136] [streaming] Added operator tests to DataStreamCloses #771,5
[hotfix][doc] Fix typo in Scala Shell doc,2
[docs] fix rendering glitch by separating html from markdown text,0
[FLINK-2164] Document streaming and batch modeThis closes #795,2
[flink-core] Added the member currentSplit to FileInputFormat. This member contains the split that this parallel instance must consume.This closes #791,2
[FLINK-1061] Document how to run an exampleThis closes #784,1
[FLINK-2092] Adjust documentation for print()/collect() semantics updateThis closes #774,5
[FLINK-2087] Add streaming mode switch to YARNThis closes #788,1
"[FLINK-2177] [runtime] Fix possible NPE when closing Netty channel, before it is active",0
[FLINK-1319] [core] Add static code analysis for user codeThis closes #729.,1
[FLINK-1981] add support for GZIP files* register decompression algorithms with file extensions for extensibility* fit deflate decompression into this scheme* add support for GZIP files* test support for deflate and GZIP files with the CsvInputFormat* replace Apache Commons' Validate with Guava's Preconditions* add documentation on reading compressed filesThis closes #762.,2
[FLINK-2153] Exclude Hbase annotationsThis is a temporal workaround for a bug in hbase.Closes #800,0
Add CONTRIBUTING.md file with pointers to our guidesCloses #778,2
[FLINK-2080] Document how to use Flink with sbtCloses #787,2
[FLINK-1635] remove Apache Thrift and Google Protobuf dependencies- remove Maven dependencies- add docs to show how to register your own serializer with KryoThis closes #794.,2
[FLINK-2000][table] Add SQL-style Aggregation Support,1
[FLINK-2054] Add object-reuse switch for streamingThe switch was already there: enableObjectReuse() in ExecutionConfig.This was simply not considered by the streaming runtime. This change nowdraws a copy before forwarding an element to a chained operator whenobject reuse is disabled.,1
[hotfix] correct Maven dependency for streaming examples,0
[docs] Fix some typos and grammar in the Streaming Programming Guide.Closes #806,2
[docs] [streaming] Added states and fold to the streaming docs,2
[FLINK-2174] allow comments in 'slaves' fileThis closes #796.,2
"[FLINK-1844] [ml] Add MinMaxScaler implementation in the proprocessing package, test for the for the corresponding functionality and documentation.This closes #798.",2
[ml] Makes StandardScalers state package private and reduce redundant code. Adjusts flink-ml readme.,2
"[hotfix] Fix YARNSessionFIFOITCaseWhen comparing the hostname, it was comparing capitalised vs.all-lowercase hostname from the yarn config.",5
[FLINK-2182] Add stateful Streaming Sequence SourceCloses #804,1
[streaming] Optional iteration feedback partitioning addedCloses #810,1
[FLINK-2194] [type extractor] Excludes Writable type from WritableTypeInformation to be treated as an interfaceThis closes #814.,5
"Fixed a few trivial issues:- The description of the input format for the graph examples  showed an example input as having a newline at the end  of the last line, but CsvInputFormat doesn't allow that  (it says ""Row too short"" for the empty line).- Fixed a link to local_execution.html in a javadoc.- ConcatenatedExtract had a typo in its name.- The creation of the jar for the SessionWindowing example was missing  from the pom.Closes #809",1
[hotfix] Bring KMeansDataGenerator and KMeans quickstart in sync,5
[FLINK-2196] [javaAPI] Moved misplaced SortPartitionOperator classThis closes #817,1
[streaming] Allow force-enabling checkpoints for iterative jobs,0
[FLINK-2191] Fix inconsistent use of closure cleaner in Scala StreamingThe closure cleaner still cannot be disabled for the Timestamp extractorin Time and for the delta function in Delta (windowing helpers).Closes #813,1
[streaming] Fixed streaming example jars packaging and terminationCloses #816,0
[FLINK-2072] [ml] Adds quickstart guideThis closes #792.,1
[FLINK-2199] Escape UTF characters in Scala Shell welcome squirrel.This closes #821,2
[scripts] remove quickstart scripts- we already decided to host them on the website- not really useful and they need maintenance- having the snapshot quickstart in the source is against Apache rulesThis closes #822.,1
[FLINK-2183][runtime] fix deadlock for concurrent slot releaseThis closes #824.,1
[streaming] Logging update for checkpointed streaming topologiesAlso adding a log message when delaying the retry of the execution graph.Closes #819,1
[build] [streaming] Streaming parents dependencies pushed to childrenCloses #820,5
[streaming] [api-breaking] Minor DataStream cleanups- Removed unused constructor parameter.- Updated outdated and wrong connection javadocs.Closes #825,2
[FLINK-2195] Configure Configurable Hadoop InputFormatsThis closes #827.,5
"[FLINK-2206] Fix incorrect counts of finished, canceled, and failed jobs in webinterfaceThis closes #826",0
[docs] remove obsolete YARN link and cleanup download links,2
[FLINK-2207] Fix TableAPI conversion documenation and further renamings for consistency.This closes #829,2
[FLINK-2203] handling null values for RowSerializerThis closes #831,2
[storm-compat] Introduced Storm wrappers to Flink,2
[strom-compat] Added Storm API compatibility classes,1
[storm-compat] Added tests for Storm compatibility API,3
[storm-compat] Added tests for Storm compatibility wrappers,3
[storm-compat] Added abstract base to Storm compatibility examples,1
[storm-compat] Added Storm compatibility word count examples,1
[storm-compat] Added ITCases to Storm compatibility examples,1
[storm-compat] Added README files to Storm compatibility modules,2
[storm-compat] Storm compatibility code cleanup,4
[storm-compat] Simple examples added,1
"[storm-compat] adapted layer to new streaming API  - re-introduced possibility to specify output type for addSource()  - split StormCollector into Abstract-, Bolt-, and Spout-Collectoradditional minor changes:  - removed unnecessary ""unused"" tags  - fixed comment typos  - added missing license header in SingleJoin example files",2
[storm-compat] Moved Storm-compatibility to flink-contrib and split flink-contrib into small sub-projectsCloses #573,2
[contrib] Added log properties files to contrib & minor clean ups,4
"[readme] Synchronize tagline with intro, fix typos",2
[FLINK-2216] Exclude javadoc jar from examples,2
[FLINK-2224] Log error cause in JobStatusChange,4
"[FLINK-2219] [webfrontend] Fix IllegalArgumentException and decrease log level- Pressing the state button in the job history view (like SCHEDULED, FINISHED)  sends a ""null"" (String) as group vertex ID, which results in an  IllegalArgumentException. Fixed by check and early return.- The JM log is flooded by INFO-level messages when no GlobalJobParameters are  set (common case). Fixed by decreasing the log level of these message to  DEBUG.",0
[hotfix] Some small fixups in README.mdThis closes #841.,2
[FLINK-2221] [docs] Docs for not using local filesystem on the cluster as state backupThis is just a clear documentation of the problem for the 0.9 release.Closes #839,0
[FLINK-2209] [docs] Document linking with jars not in the binary dist,2
[docs] Update obsolate cluster execution guideCloses #835,5
[FLINK-2120][runtime] rename AbstractJobVertex to JobVertexThis closes #840.,2
"[FLINK-2226][YARN] fail application on failed single-job cluster jobFailing jobs executed in the YARN cluster mode leave the applicationcontainer in the ""SUCCEEDED"" final state. While for long-running FlinkYARN clusters where multiple jobs are run, this is fine, for single jobsit is appropriate to mark the application as failed.This closes #838.",0
[FLINK-2210] Table API support for aggregation on columns with null values,1
[hotfix] Removed execute() that followed print() in quickstart wordcount jobs,4
[FLINK-2225] [scheduler] Excludes static code paths from co-location constraint to avoid scheduling problemsThis closes #843.,0
[legal] Updates LICENSE/NOTICE file of source and binary distributionThis closes #830.,2
[build] merge transitive notice files to shaded noticesThis closes #837.,2
[streaming] Fix out-of-sync class-level docs of SourceFunction,1
[core] Fix typo in DataSinkTask error message,0
[FLINK-2232] [storm-compat] Increased sleeping time for IT-CasesTo make tests more stable as a temporal fixadditional bug fix: isRunning was not volatile in AbstractStormSpoutWrapperCloses #845,1
Version bumped to 0.10-SNAPSHOTCloses #851,5
[FLINK-2149][gelly] Simplified Jaccard ExampleThis PR simplifies Gelly's Jaccard example by using the more efficient reduceOnNeighbors rather than groupReduceOnNeighbors.Author: andralungu <lungu.andra@gmail.com>Closes #770 from andralungu/jaccardImprovement and squashes the following commits:6e77f8d [andralungu] [FLINK-2149][gelly] Simplified Jaccard Example,2
"[streaming] Refactor the accessing of the user specified field by sum, min, etc.SumAggregator and ComparableAggregator had some code duplication foraccessing the specified field for different kinds of types (Tuple, Pojo,Array, simple).",1
"[FLINK-2140][gelly] Allowed access to the number of vertices in the GSA functionsSimilar to the vertex-centric approach, this PR enables users to access the total number of vertices from within the gather, sum and/or apply functions of a GSA iteration.Author: andralungu <lungu.andra@gmail.com>Closes #779 from andralungu/numVerticesGSA and squashes the following commits:cffd944 [andralungu] [FLINK-2140][gelly] Allowed access to the number of vertices in the GSA functions",1
"[FLINK-2178][gelly] Fixed groupReduceOnNeighbors bugThis PR adds an iterator.hasNext() check in the groupReduceOnNeighbors method, fixing the NoSuchElementException bug reported in FLINK-2178.@vasia , @StephanEwen, maybe we can merge this before the upcoming 0.9 release :)Thanks!Author: andralungu <lungu.andra@gmail.com>Closes #799 from andralungu/groupReduceOnBug and squashes the following commits:0a09e85 [andralungu] [FLINK-2178][gelly] Fixed groupReduceOnNeighbors bug",0
"[core] Use consistent equality check in Value typesThis closes #849, #850.",1
[FLINK-2229] Add equals() and hashCode() to ObjectArrayTypeInfoThis closes #842.,5
[FLINK-2155] Enforce import restriction on usage of Flink shaded package and Commons ValidateThis closes #790.,5
[core] Use instanceof for equality check in Value typesThis closes #850.,1
[scripts] cleanup release script and make it more robust- fail on command error / unset variable- make Mac OS X compatible- fix uberjar file limit detection- remove obsolete yarn part- cleanupThis closes #811.,4
[scala-shell] [tests] Remove unnecessary output checkhttps://s3.amazonaws.com/archive.travis-ci.org/jobs/67848150/log.txt,5
"[FLINK-1877] [FLINK-2204] Ignore frequently failing Flink-On-Tez testsThe Flink-On-Tez tests are failing frequently due to deadlocks in Tez 0.6.1.Since this is outside of the scope of Flink and Flink-On-Tez is not a corefeature of Flink, it is OK to ignore these tests until a new Tez version isreleased, which we can try.",1
[FLINK-2262][utils] rename method for default integer value in ParameterTool,2
[docs] correct yarn command-line example,2
[docs] update version to 0.10,5
[FLINK-2257] [streaming] Properly forward rich window function calls to wrapped functionsCloses #855,1
[FLINK-2255] [streaming] Fixed a bug in TopSpeedWindowing examplesCloses #857,0
[docs] fix broken links in FAQ,2
[streaming] Initial rework of the operator state interfaces,1
[streaming] Allow multiple operator states + stateful function test rework,1
[streaming] Add stateHandle to checkpointed message,0
[streaming] Return null for empty state instead of empty hashmap,2
[streaming] fix for null state in ConfirmCheckpoint messages,5
[streaming] KafkaSource checkpointing rework for new interfaces,1
[streaming] Fix shallow discard + proper checkpoint commit,1
[streaming] [docs] Updated streaming guide for new state interfaces,1
[streaming] Allow using both partitioned and non-partitioned state in an operator + refactor,4
[streaming] Re-enable Checkpointed interface for drawing snapshots,0
[streaming] Add KeyedDataStream abstraction and integrate it with the rest of the refactoringCloses #747,4
[FLINK-2271] [FLINK-1522] [gelly] changed PageRank example to expect an unweighted edge listadded PageRank and MusicProfiles testsgot rid of unused suppress warning annotations in Graph and JaccardSimilarityMeasurechanged GSAPageRank example to expect an unweighted edge listThis closes #865,4
[FLINK-2264] [gelly] changed the tests to use collect instead of temp filesThis closes #863,2
[FLINK-2264] [gelly] moved utility comparison methods to TestBaseUtils,3
[FLINK-2093] [gelly] Added difference Methodchanged difference method tests to use collect()This closes #818,1
[FLINK-2214] [ml] Fixes prediction join operation and empirical risk join operation of ALS by giving join hintThis closes #844.,0
"[FLINK-2116] [ml] Adds evaluate method to Predictor. Adds PredictOperation which can be reused by evaluate if the input data is of the format (TestingType, LabelType) where the second tuple field represents the true label.This closes #772.Moves PolynomialFeaturesITSuite in right package",4
[FLINK-2278] [ml] Fixes wrong Breeze sparse vector to Flink sparse vector conversion,2
[FLINK-2279] [streaming] Add Connected IterationCloses #870,1
[FLINK-2261] [streaming] Remove reduce/fold/aggregations from DataStream,5
[streaming] Created scala GroupedDataStreamCloses #860,5
[FLINK-2152] [java api] [scala api] Add zipWithIndex[FLINK-2152] zipWithIndex implementation[FLINK-2152] Added zipWithIndex utility method[FLINK-2152] Fixed minor documentation bug[FLINK-2152] Addressed Java suggestions[FLINK-2152] Scala zipWithIndex; first attempt[FLINK-2152] Scala zipWithIndex; second attempt[FLINK-2152] Scala zipWithIndex - finalised[FLINK-2152] Fixed checkstyle violation[FLINK-2152] Fixed minor Scala checkstyle suggestions,0
[FLINK-2294] [streaming] Fix partitioned state next-input setting for copying chained collectors,1
[runtime] Properly set cause of ProducerFailedException,0
[docs] move FAQ to the website's repository,4
"[FLINK-2175] added UI support for multiple ""assembler class"" entries in jar files  - program-class can contain multiple comma seperated entry classes  - Main-Class can contain multiple comma seperated entry classes  - WebClient shows checkbox for each entry class and can display plan for it",1
[FLINK-2175] extending WebClient and CLI to show ProgramDescriptionadded WordCountMeta example (used ProgramDescription interface to display meta data by clients)extended WebClient documenationThis closes #707,2
[FLINK-2298] Add option to pass a custom name for Flink on YARNThis closes #876,2
[tests] Remove subsumes low-level API tests for broadcast variabes - BroadcastVarsNepheleITCase is subsumed by BroadcastBranchingITCase - KMeansIterativeNepheleITCase is subsumed by the Java/Scala API KMeans example programs,3
[FLINK-2308] [runtime] Give proper error messages in case user-defined serialization is broken and detected in the network stack.,1
[FLINK-2158] Add support for null to the DateSerializerThis closes #780,5
[FLINK-2275] [tests] Aigrated test from execute() to collect() -> for package 'org.apache.flink.test.javaApiOperators' Seactivated unstable test (see comment section https://issues.apache.org/jira/browse/FLINK-2275)This closes #866,2
"[FLINK-2272] [ml] Removed roadmap and vision from docs, added link to them in the wiki.This closes #864.",2
"[FLINK-2297] [ml] Adds threshold setting for SVM binary predictions.Added Threshold option for SVM, to determine which predictions are positive/negative.Added parameter to determine output of prediction function.Determines whether we output raw distances to the boundaryor binary class labels.Documentation fixesThis closes #874.",0
"[FLINK-2150] Added zipWithUniqueIdsThis PR adds a library method that assigns unique labels to vertices.The following facts are used: * a map function generates an n-bit(n - number of parallel tasks) ID based on its own index * with each record, a counter c is increased * the unique label is then produced by shifting the counter c by the n-bit mapper IDAuthor: andralungu <lungu.andra@gmail.com>Closes #801 from andralungu/generateUniqueIds and squashes the following commits:5a3837b [andralungu] [FLINK-2150][gelly] Added library method for assigning unique labels to vertcies",1
[FLINK-2285] [streaming] Removed duplicate call in close from GroupedActiveDiscretizer,4
[streaming] Minor streaming code cleanupsCloses #873,4
[docs] improve setup guide for google compute engine,1
[docs] Add description and illustration of checkpointing mechanism.,1
[docs] Fix formatting error in description of stream checkpointing,0
[docs] small fix to the description of the checkpointing mechanism,0
[FLINK-2323] [api-breaking] Rename OperatorState interface methods to value() and update(..)Closes #890,5
[FLINK-2293] [runtime] Fix estimation for the number of hash buckets on recursive builds,0
[FLINK-2242] [api] Deprecate RemoteCollector interface and implementationThis closes #852,2
[FLINK-2000] [table api] Add sql style aggregation supportThis commit exists only to trigger closing the pull request.This closes #782,1
[tools] Make release script a bit more flexibleThis closes #868,1
[FLINK-2208] [runtime] Fix reflective access to CPU load to support IBM Java,1
"[FLINK-2288] [FLINK-2302] Setup ZooKeeper for distributed coordination- FLINK-2288: Setup ZooKeeper for distributed coordination  * Add FlinkZooKeeperQuorumPeer to wrap ZooKeeper's quorum peers with    utilities to write required config values (default datadir, myid)  * Add default conf/zoo.cfg config for ZooKeeper  * Add startup scripts for ZooKeeper quorum  * Add conf/masters file for HA masters- FLINK-2302: Allow multiple instances to run on single host  * Multiple TaskManager and JobManager instances can run on a single    host.",1
[FLINK-2288] [docs] Add docs for HA/ZooKeeper setupThis closes #886,1
[FLINK-2288] [runtime] Cleanups and comments for ZooKeeper based initialization,5
[FLINK-2327] [runtime] Log the limit of open file handles at TaskManager startup,0
[FLINK-2331] Whitelist the 'akka.remote.RemoteTransportExceptionNoStackTrace' to be acceptable in YARN logs,2
[FLINK-2124] [streaming] Fix behavior of FromElementsFunction when T isn't SerializableThis change rewrites the FromElementsFunction to work with arbitrary types. The elementsare serialized to a byte array (using a TypeSerializer) when the FromElementsFunction isconstructed and deserialized when run is called.This closes #848,1
"[FLINK-2124] [streaming] Handle 'fromElements()' for non-serializable elements. Cleanup code, and add proper tests.",3
[FLINK-2330] [streaming] Make FromElementsFunction checkpointable,1
[FLINK-2327] [hotfix] Properly print file handle limit on TaskManager startup,0
[FLINK-2280] GenericTypeComparator.compare() respects ascending flagThis closes #894,2
[hotfix] Fix wrong unit (secs vs msecs) in TaskManager logging statement.,2
[hotfix] [tests] Increase registration timeout for TaskManagers in ProcessFailureCancelingITCase to compensate for sloggy CI environments,2
[hotfix] [taskmanager] Fix line wrapping to please scala checkstyle,0
[FLINK-2339] Prevent asynchronous checkpoint calls from overtaking each other,2
[docs] Fix wordcount example in YARN setupFix wrong wget callThis closes #897,1
[FLINK-2138] [streaming] Added custom partitioning to DataStream,5
[FLINK-2138] [streaming] Added custom partitioning to scala DataStream,5
[FLINK-2138] [streaming] Added docs and tests for partitioningCloses #872,3
[FLINK-2305] Add documenation about Storm compatibility layeradditional improvements- added RawOutputFormatter- bug fix in SimpleOutputFormatter- enable default output formatter for StormBoltFileSinkCloses #884,2
[FLINK-2335] [streaming] Lazy iteration construction in StreamGraphCloses #900,2
"[FLINK-2141][gelly] Allow GSA's Gather to perform this operation in IN, OUT or ALL directions[FLINK-2141][gelly] Added Test cases for GSAConfiguration setDirection. Made changes in coding style[FLINK-2141][gelly]Removed Example[FLINK-2141][gelly] Corrected Annotation and Gelly guideMinor Changes in Gelly GuideThis closes #877",4
[FLINK-2348] [taskmanager] Make async call dispatching robust against concurrent finishing.,5
[docs] fix loading of style sheet with protocol relative base URL,0
[core] Removed redundant common.io.FormatUtil,4
[core] Minor cleanups in FileInputFormat and DelimitedInputFormat,2
[core] Add tests for DelimitedInputFormat's handling of records across split boundaries,3
"[hotfix] Add sshd line in Cluster Setup DocumentationBefore, it said to call /etc/init.d/ssh restart. This does not work onsome systems. There you might need /etc/init.d/sshd restart.",5
"[FLINK-1085] [runtime] Combiner forwards oversized records, rather than failing on them.This closes #854",0
[FLINK-1085] [tests] Make the combiner tests generic. Add more coverage for oversized records.,3
[FLINK-2337] [storm compat] Excluded 'logback' from Storm dependenciesThis closes #903,2
[FLINK-2008] [FLINK-2296] Fix checkpoint committing & KafkaITCaseThis closes #895,1
[FLINK-2329] [runtime] Introduces InstanceGateway as an abstraction to communicate with the TaskManager.Replaces AkkaUtils.globalExecutionContext with instance dependent ExecutionContext.This closes #893,1
"[FLINK-2235] fix calculation of free memory for local executionThe Java runtime may return Long.MAX_VALUE for a call to the maxMemory()method of the Runtime class. In these cases, we can get hold of thephysical memory size of the operating system by using a proprietaryOracle JDK method. Otherwise, we fail with an explanatory exception.The Oracle JVM defines the max memory to be 1/4 of the physical memoryif the user has more than 192 Megabytes which is assumed here.This closes #859",1
[FLINK-2235] Fix tests to allow exception in 'EnvironmentInformationTest.getSizeOfFreeHeapMemory()' if Xmx is not set.,1
[hotfix] Fix error messages in EnvironmentInformation when accessing user information,5
[FLINK-2353] Respect JobConfigurable interface in Hadoop mapred wrappersThis closes #908,5
[FLINK-2343] [scripts] Make CMS the default GC for streaming setupsThis closes #901,1
[hotfix] Commit to close lingering pull requestsThis closes #633,0
[docs] Add new figure of architecture/process model to docs overview page,2
[docs] Move stream checkpointing docs to scalable vector graphics.,2
"[taskmanager] do not process message if not connected to job managerThis commit makes sure that task messages are only processed whenconnected to a job manager. Otherwise, they are dropped. Before, themessage were processed in any case.This closes #914.",4
"[FLINK-2292][FLINK-1573] add live per-task accumulatorsThis refactors the accumulators to accumulate per task execution. Theaccumulators are reported from the task managers periodically to the jobmanager via the Heartbeat message. If the execution contains chainedtasks, the accumulators are chained as well. The final accumulatorresults are reported via the UpdateTaskExecutionState message.The accumulators are now saved in the Execution within theExecutionGraph. This makes the AccumulatorManager obsolete. It has beenremoved for now. In the future, we might introduce some caching for theweb frontend visualization.Two types of accumulators are available:- external (user-defined via the RuntimeContext)- internal (flink metrics defined in the invocables)The internal (built-in) metrics are targeted at users who want tomonitor their programs, e.g. through the job manager's web frontend.This closes #896.",1
[tests] relax timing assumptions in live accumulator test,3
[docs] Fix Javadocs of RuntimeContext parallel subtask index,1
[FLINK-1963] Improve distinct() transformationThis closes #905,1
[FLINK-2359] [java api] Add factory methods to the Java TupleX typesThis closes #911,1
"[FLINK-1967] Introduce (Event)time in StreamingThis introduces an additional timestamp field in StreamRecord. When using aSourceFunction and an auto-timestamp interval is set using theExecutionConfig, the timestamp is automatically set to System.currentTimeMillis()upon element emission. The timestamp can be manually set using anEventTimeSourceFunction.This also changes the signature of the StreamOperators. They now geta StreamRecord instead of the unwrapped value. This is necessary forthem to access the timestamp. Before, the StreamTask would unwrap thevalue from the StreamRecord, now this is moved one layer higher.This also introduces watermarks to keep track of processing. Ata configurable interval the sources will emit watermarks that signifythat no records with a lower timestamp will be emitted in the future bythis source. The timestamps are broadcast, stream inputs wait for watermarkevents on all input channels and forward the watermark to theStreamOperator once the watermark advances on all inputs. Operators areresponsible for forwarding the watermark once they know that no elementswith a previous timestamp will be emitted (this is mostly relevant forbuffering operations such as windows). Right now, all operators simplyforward the watermark they receive.When using an EventTimeSourceFunction the system does notautomatically emit timestamps, the user is required to manually emitwatermarks using the SourceContext.No watermarks will be emitted unlessExecutionConfig.setAutoWatermarkInterval is used to set a watermarkinterval.Per default timestamps and watermarks are completely disabled, there isa switch in ExecutionConfig (enableTimstamps()) to enable them. Thismeans that, out-of-box, the performance is not changed by adding thisnew feature. If it is not used.This commit contains fixes for other stuff that was discovered whileimplementing the feature. See Jira issue numbers and descriptions below.[FLINK-2290/2295] Fix CoReader Event Handling and CheckpointingThis changes CoReader (now CoStreamingRecordReader) to reuseUnionGate for the input multiplexing. This way it will not lock in onone specific input side and read events from both input sides.This also enables an event listener for checkpoint barriers so that theTwoInputTask now reacts to those and correctly forwards them.Then, this adds CoStreamCheckpointintITCase to verify that checkpointingworks in topologies with TwoInputStreamTasks.This also adds tests for OneInputStreamTask and TwoInputStreamTaskthat check whether: - whether open()/close() of RichFunctions are correctly   called - Watermarks are correctly forwarded - Supersteps/checkpoint barriers are correctly forwarded and the   blocking of inputs works correctlyAdd proper tests for Stream OperatorsThese test whether: - open()/close() on RichFunctions are called - Timestamps of emitted elements match the timestamp of the input   element - Watermarks are correctly forwarded[FLINK-2301] Fix Behaviour of BarrierBuffer and add TestsBefore, a CheckpointBarrier from a more recent Checkpoint would alsotrigger unblocking while waiting on an older CheckpointBarrier. Now,a CheckpointBarrier from a newer checkpoint will unblock all channelsand start a new wait on the new Checkpoint.The tests for OneInputStreamTask and TwoInputStreamTask check whetherthe buffer behaves correctly when receiving CheckpointBarriers from morerecent checkpoints while still waiting on an older CheckpointBarrier.",3
[tests] add flag for synchronous execution of futures in TestingClusterThis adds a flag to TestingCluster to disabled asynchronous execution offutures via the CallingThreadDispatcher.,1
"[FLINK-2371] improve AccumulatorLiveITCaseInstead of using Thread.sleep() to synchronize the checks of theaccumulator values, we rely on message passing here to synchronize thetask process.Therefore, we let the task process signal to the task manager that ithas updated its accumulator values. The task manager lets the jobmanager know and sends out the heartbeat which contains theaccumulators. When the job manager receives the accumulators and hasbeen notified previously, it sends a message to the subscribed test casewith the current accumulators.This assures that all processes are always synchronized correctly and wecan verify the live accumulator results correctly.In the course of rewriting the test, I had to change two things in theimplementation:a) User accumulators are now immediately serialized as well. Otherwise,Akka does not serialize in local one VM setups and passes the liveaccumulator map through.b) The asynchronous update of the accumulators is disabled fortests (via the dispatcher flag of the TestingCluster). This wasnecessary because we cannot guarantee when the Future for updating theaccumulators is executed. In real setups this is neglectable.This closes #925.",1
[FLINK-2382] fix Flink live accumulators for TwoInputStreamTask,2
[core] Remove obsolete OperatorUtil,1
"[FLINK-2358] [dashboard] First part dashboard server backend - Adds a separate Maven project for easier maintenance. Also allows users to refer to runtime without web libraries. - Simple HTTP server based on Netty HTTP (slim dependency, since we use netty anyways) - REST URL parsing via Netty Router - Abstract stubs for handlers that deal with errors and request/response - First set of URL request handlers that produce JSON responsesThis closes #677This closes #623This closes #297",5
"[FLINK-2358] [dashboard] Add server for static dashboard files (HTML, JS, CSS, ...)",2
[FLINK-2358] [dashboard] Add first stub of angular.js based dashboard.Add README.md that outlines build instructions.,2
"[FLINK-2358] [dashboard] Adding comments to web dashboard files, add LICENSE file entries",2
[FLINK-2377] [tests] Add reader.close() to readAllResultLines in TestBaseUtilsThis closes #924,3
[FLINK-2377] [tests] Make buffer closing logic robust to I/O failures.,0
[FLINK-2362] [docs] Add Scala and Java documentation for the 'distinct()' transformationThis closes #922,2
[FLINK-2376] Raise the time limit in testFindConnectableAddress under WindowsThis closes #920,3
[FLINK-1943] [gelly] Added GSA compiler and translation testsThis closes #916,3
[docs] Document some missing configuration parametersThis closes #915,2
[docs] Clean up completeness checker for configuration docs.,2
"[FLINK-2198] [tests] Under Windows, skip tests that use setWritableThis closes #919",1
[FLINK-2018] [core] Add ParameterUtil.fromGenericOptionsParser()This closes #720,2
[FLINK-2304] Add named attribute access to Storm compatibility layer  - extended FlinkTuple to enable named attribute access  - extended BoltWrapper for user defined input schema  - extended FlinkTopologyBuilder to handle declared output schemas  - adapted JUnit tests  - added new examples and ITCases  - updated READMEs  - updated documentationCloses #878,2
[FLINK-1658] Rename AbstractEvent to AbstractTaskEvent and AbstractJobEventDelete AbstractEvent in org.apache.flink.runtime.event.job    (see comment section in https://issues.apache.org/jira/browse/FLINK-1658)This closes #929,2
[FLINK-2218] Web client cannot distinguesh between Flink options and program arguments- added new input fields 'options' to WebClient- adapted WebClient-to-JobManager job submission logic- removed reduncand code and re-used CliFrontend- updated documentation (including new screenshots)- (some additional minor cleanup in launch.html and program.js)This closes #904.,4
[FLINK-2388] forward message to archivist in case accumulators can't be found- return AccumulatorsNotFound in case the archive cannot find them eitherThis closes #930.,2
[FLINK-1818] add cancel method to ClientThis closes #642.,1
[docs] Fixes broken links on the setup_quickstart.html site,1
[FLINK-2357] [web dashboard] New dashboard backend server supports requests from old web server as well.Also moves TestRunner to test scope.,3
[FLINK-2400] [tests] Improve error message on unexpected TaskTest message,3
"[FLINK-2332] [runtime] Adds leader session IDs and registration session IDs to JobManager and TaskManager messages.Refactors Flink's actor traits to support stackable traitsRefactored Flink's actors to use a factory method to generate messagesReplaced ActorRef with InstanceGateway in Task, RuntimeEnvironment and ExecutionGraphAdd commentsAdd test cases for registration session ID and leader session IDAdds IT case to check that a CancelMessage with the wrong leader session ID is discardedCorrected order of visibility and abstract modifiers. Removed lazy log member from FlinkActor. Made RequiresLeaderSessionID a Java interface.This closes #917.",1
[FLINK-2385] [scala api] Add parenthesis to 'distinct' transformation.This closes #933,1
[streaming] Copy default state values for partitioned states,5
[FLINK-2381] Stringify cause of ProducerFailedExceptions,0
"[FLINK-2384] [runtime] Move blocking I/O call outside of synchronized blockProblem: Waiting on asynchronous write requests with the partition lock canresult in a deadlock, because all other operations on the same partition areblocked. It is possible that the I/O writer itself needs to access thepartition, in which cases the whole program blocks.Solution: Move the wait outside the synchronized block. This was not necessarybefore, because no operation assumes the spilling to be finished when thefinish call has returned.",5
[hotfix] Fix warnings introduced by recent Watermark Commit,2
[FLINK-2405] [streaming] Added stateful functions to Scala DataStreams,5
[FLINK-2405] [streaming] Simplifies the way the partitioned field is set in StatefulFunctionCloses #936,1
[FLINK-2419] [hotfix] addSink now uses transform + remove double checkpoint commit at head operator,1
[FLINK-2404] add support for primitives to simple accumulator countersThis closes #942.,1
[FLINK-2418] [streaming] Add an end-to-end exactly-once test for Checkpointed functions.,1
[FLINK-2420] [streaming] StreamRecordWriter properly reports exceptions on flush.,2
[hotfix] Fix generics for stream record and watermark multiplexing.,0
[FLINK-2421] [streaming] Add tests for basic utility behavior of StreamRecordSerializer (fixed in previous commit).,0
[tests] Add a manual test to evaluate impact of checkpointing on latency,3
"[FLINK-2406] [streaming] Abstract and improve stream alignment via the BarrierBuffer - Add an interface for the functionaliy of the barrier buffer (for later addition of other implementatiions) - Add broader tests for the BarrierBuffer, inluding trailing data and barrier races. - Checkpoint barriers are handled by the buffer directly, rather than being returned and re-injected. - Simplify logic in the BarrierBuffer and fix certain corner cases. - Give access to spill directories properly via I/O manager, rather than via GlobalConfiguration singleton. - Rename the ""BarrierBufferIOTest"" to ""BarrierBufferMassiveRandomTest"" - A lot of code style/robustness fixes (proplery define constants, visibility, exception signatures)",0
"[FLINK-2402] [streaming] Add a stream checkpoint barrier tracker.The BarrierTracker is non-blocking and only counts barriers.That way, it does not increase latency of records in the stream, but can only beused to obtain ""at least once"" processing guarantees.",1
Fix [FLINK-2391] Storm-compatibility:method FlinkTopologyBuilder.createTopology() throws java.lang.NullPointerException bugThis closes #940,0
[docs] Updated method documentation. Changed .isEqualTo(..) to .equalsTo(..)This close #909,4
[FLINK-2231] Create Serializer and Comparator for Scala Enumerations.This closes #935,1
[FLINK-2424] [core] Close output stream in serialization utility,2
[hotfix] Code cleanups in the StreamConfig,5
"[FLINK-2407] [streaming] Add an API switch to choose between ""exactly once"" and ""at least once"".",1
[FLINK-2419] Add test for sinks after keyBy and groupByCloses #947,3
[cascading] add getJobConf() to HadoopInputSplit,5
[cascading] load user classloader when configuring InputFormatThis closes #950.,5
[client] send cancel message via the job manager's ActorGateway,2
[FLINK-2324] [streaming] Partitioned state checkpointing rework + test update,5
[FLINK-2324] [streaming] ITCase added for partitioned states,1
[FLINK-2324] [streaming] Added test for different StateHandle wrappersCloses #937,0
[cleanup] move updateAccumulators method to a more sensible location,5
"[FLINK-1927][FLINK-2173][py] Operator distribution rework, fix file pathsPython operators are no longer serialized and shipped across thecluster. Instead the plan file is executed on each node, followed byusage of the respective operator object.- removed dill library- filepaths are always explicitly passed to python- fix error reportingThis closes #931.",0
[FLINK-2238][api] Generalized fromCollection(Seq) to fromCollection(Iterable)This closes #956,2
[FLINK-2412] [runtime] Check if parent released before querying in-memory buffer in SpillableSubpartitionView,1
[FLINK-2248] add flag to disable sysout logging from cliThis closes #957.,2
[FLINK-2446] [streaming] Fix SocketTextStreamFunction memory leak on reconnectCloses #965,1
[hotfix] Fix SourceStreamTaskTest to switch source to running before checkpointing,1
[FLINK-2461] [tests] Guard tests that rely on unresolvable host names with the appropriate assumption.,3
"[FLINK-2427] [streaming] Make the BarrierBuffer more robust against lost/missing checkpoint barriers.Checkpoint barriers are now tolerated to be lost (as may happen if the checkpoint triggering actormessages are lost). This is realized by allowing the BarrierBuffer to maintain multiple queues of blocked inputs.The patch also reworks the buffer spilling logic, to increase I/O efficiency, and reduce the main memoryfootprint in cases where the buffers have little contents (low flush timeouts).",1
[runtime] Cleanup channel events. Add comments and move some classes to test scope.,3
"[FLINK-2438] [runtime] Improve channel event serialization performance.Because channel events may become very frequent now (frequent at-least-once checkpointing), their serialization perfomance starts to matter.",1
[hotfix] [streaming] Fix race in stream tasks when canceling tasks early.,0
[FLINK-2459] [cli] Cli API and doc fixes.1. Remove CliFrontendLoggingTest. Test directly that the logging flag is interpreted correctly.2. Doc fix for cli api3. Info command shouldn't print logging option for help.This closes #971,2
[FLINK-2463] [web dashboard] Shows job configuration in new dashboardThis closes #953,1
[FLINK-2434] [pom] Fix pattern for exclusion of org.apache.hadoop:hadoop-yarn-common:jersey-test-framework-grizzly2This closes #955,3
[FLINK-2436] [streaming] Make ByteStreamStateHandles more robustCloses #958,3
[FLINK-2464][tests] Add logging to BufferSpillerTest to help debug spurious failures.,0
[FLINK-2433] [docs] Add script to build local documentation on windowsThis closes #954,2
[FLINK-2409] [webserver] Replaces ActorRefs with ActorGateways in the web server to automatically decorate messages with a leader session ID.Refactored MiniCluster to also store a reference to the web server to stop it. Adds support for the new web interface for yarnFix web server start conditionThis closes #959.,0
[FLINK-2322] [streaming] Close file streams to release resources early.This closes #928,2
[FLINK-2465] [streaming] SocketClientSink closes connection earlyThis closes #972,2
[hotfix] Remove unused (and broken) TraversableOnceIterable.,1
[FLINK-2425] [FLINK-2426] [runtime] Add an unmodifiable config and provide access to task manager configuration and hostname inside RuntimeEnvironment,1
[FLINK-2426] [core] Cleanup/improve unmodifiable configuration.,5
[FLINK-2425] [runtime] Cleanup code for forwarding config and hostname into TaskManager's RuntimeEnvironment,1
"[FLINK-2473] [core] Add a timeout to akka actorsystem shutdown.This works around a bug in akka where the ""awaitTermination()"" call freezes indefinitely.",5
"[FLINK-2464] [tests] Change log level of BufferSpillerTest to ""info"" to let statements occur in CI logs.",2
[FLINK-2456] [hbase] Add a repository ID for hadoop2 in flink-hbase moduleThis closes #969,2
[FLINK-2095][docs] Added missing screenshots to webclient documentationThis closes #976,2
[FLINK-2422] [web client] Added explicit link in case browser is not redirecting properlyThis closes #946,2
[docs] Fixes broken link in FlinkML docs,2
Remove unwanted check null of input1 in ConnectedDataStreamCloses #978,5
[FLINK-2005] Remove Record API from jdbc moduleThis closes #982,5
"[FLINK-2205] Fix confusing entries in JobManager WebUI JobConfig section.Default display for 'Number of execution retries' is now 'deactivated'and for 'Job parallelism' is 'auto', as suggested in JIRA.This closes #927",5
[FLINK-2442] [fix] FieldPositionKeys support Pojo fieldsThis closes #963,1
"[FLINK-2105] Extract abstract superclass, interface from MergeMatchIterators, KeyGroupedIterators",2
[FLINK-2105] Add support for sorted but sparse test data generation,5
[FLINK-2105] [tests] Move duplicate utility classes to testutil package,3
[FLINK-2447] [java api] TypeExtractor returns wrong type info when a Tuple has two fields of the same POJO typeThis closes #986,5
[FLINK-1882] Removed RemotedCollector classesThis closes #985,4
[FLINK-2467] Example WordCountStorm.jar is not packaged correctly - fixed assembly xml fileThis closes #974,2
"[FLINK-1680] Remove Tachyon test and rename Maven module to ""flink-fs-tests""This closes #987",3
[FLINK-2484] [streaming] BarrierBuffer releases temp files properly.,2
[FLINK-2464] [tests] Make buffer spilling test robust to Java 6.,3
[hotfix] Remove unused and outdated HashFunctionCollisionBenchmark,1
[FLINK-1916] [FLINK-2361] [runtime] Fix EOFException and entry loss in CompactingHashTableAlso a lot of code cleanups in CompactingHashTable,4
[FLINK-2454] [buikd] Update Travis to drop JDK6 for tests,3
[FLINK-2453] [pom] Move Java source and target version to 1.7,1
[hotfix] Increase timeout for YARN tests to 180 seconds to prevent occasional CI failures.,0
[FLINK-2492] [runtime] Rename former 'match' classes to 'join' to reflect consistent naming scheme.,1
[FLINK-2240] Add bloom filter to filter probe records during hash join.,1
"[FLINK-2240] [runtime] Pass flag to configure use of bloom filters through runtime configuration.Also make sure that most tests run with enabled bloom filters, to increase test coverage.",3
[hotfix] Fix TEZ task contect to reflect updated interface.,5
[FLINK-2452] [Gelly] adds a playcount threshold to the MusicProfiles exampleThis closes #968,2
[FLINK-2243] [storm-compat] Added finite spout functionality to Storm compatibility layer,1
[FLINK-2243] [storm-compat] Demonstrating finite Storm spout functionality on exclamation example-minor renaming-improving JavaDocsCloses #853,2
[FLINK-2387] add streaming test case for live accumulatorsThis closes #926.,3
[FLINK-705] [license] Add license reference for TPC-H sample data in tests.,3
[FLINK-2453] [docs] Update README and setup docs to reflect requirement for Java 7+,1
[FLINK-1177] [docs] Mark HDFS setup instructions as option in cluster setup docs,2
[hotfix] Fix repository language statistics by adjusting .gitattributes,0
[FLINK-2498] [tests] Clean up GroupReduceITCase and make it more robust by avoiding temp files,2
[FLINK-2483] [runtime] Add default branch of switch(scheduleMode) in scheduleForExecution functionThis closes #984,1
[travis tools] Adds $HOME/bin/artifacts to $PATH of watchdog script,1
[FLINK-2357] [web dashboard] Update Node.js installation instructionsThis closes #1006,5
[FLINK-2502] [storm compatibility] Fix FiniteStormSpout documenation rendering - added missing empty lines - additional minor improvementsThis closes #1002,1
[FLINK-2500] [streaming] Code cleanup in DataStreamThis closes #1001,5
[FLINK-2277] [scala api] Add flag to set delta iteration solution set to unmanagedThis closes #1005,1
[streaming] [tests] Checkpointing tests refactor & cleanup,4
[FLINK-2423] [streaming] ITCase for checkpoint notificationsCloses #980,2
[FLINK-2511] [runtime] Make sure to close FileInputStream in FlinkZooKeeperQuorumPeer,2
[FLINK-2509] [runtime] Add class loader info into the exception message when user code classes are not found.This closes #1008,1
[FLINK-2507] [storm-compat] Rename the function tansformAndEmitCloses #1007,1
"[FLINK-2437] handle the case of a non-public default ctor in TypeExtractor.analyzePojoAlso changed some prints which printed the word ""class"" twice,because class.toString also prepends it to the class name.This closes #960.",1
[hotfix] read from old and new parallelism config keyregression of c6358024454cd8225cf27a91db7f64ffa13189ee,5
"[CLEANUP] Add space between quotes and plus sign in String concat for readability in flink-yarn moduleWhile working on Flink on YARN, do some simple nit cleanups to add space between quote and plus sign for readability in yarn module for readability.Use StringBuilder instad of StringBuffer in FlinkYarnClient since the String materializes immediately, so no need synchronize protection.Author: hsaputra <hsaputra@apache.org>Closes #1010 from hsaputra/cleanup_yarn_branch and squashes the following commits:a6fc9e1 [hsaputra] Add space between quote and plus sign for readability in flink-yarn module.",2
[FLINK-1819][core] allow access to RuntimeContext from Input and OutputFormats1. Allow access to Runtime Context from I/O formats.2. Make all existing I/O formats context aware.This closes #966.,1
"[FLINK-2509] [hotfix] Address pull request comments for ClassLoaderUtilsCorrecting commit, because the wrong commit was pushed earlier.",0
[FLINK-2515] [job manager] Checkpoint coordinator triggers checkpoints only when tasks are running.,1
[FLINK-2519] [streaming] Make checkpoint alignment aware of finished partitions.,5
[FLINK-2517] [docs] Minor fix to streaming guideThis closes #1013,0
[FLINK-2393] [docs] Updates docs to describe switch between exactly-once and at-least-once,2
[FLINK-2523] [taskmanager] Increase interrupt timeout in TaskManager task.,1
[FLINK-2457] [core] Integrate Tuple0 - extended TupleType helper classes to handle Tuple0 - extended TupleSerializer to handle Tuple0 - included Tuple0 into JUnit tests - simplified Receiver.createTuple(int)This closes #983,1
[FLINK-2457] [core] Slight adjustedments to Tuple0 singleton names to match naming scheme.,2
"[FLINK-2431] [python] Refactor PlanBinder/OperationInfoPlanBinder methods were restructured to make the class more readable.Keys are now stored as strings to simplify string-key-expression support.Parameter retrieval was moved from PB to OI constructor, similiar to PythonOperationInfo.This change reduces the clutter in Planbinder and allows code reusage for operations with similar parameters.This closes #961",2
[FLINK-2512] [storm compatibility] Make sure client is properly closed in FlinkSubmitterThis closes #1009,2
[docs] Fix some errors in programming_guide.md,0
"[FLINK-2487] [ml] In cosine distance, check that datapoints are of same cardinalityThis closes #1021",5
[FLINK-2458] [FLINK-2449] [runtime] Access distributed cache entries from Iteration contexts & use of distributed cache from Collection EnvironmentsThis closes #970,1
[tests] Make timeout discarding checks in CheckpointCoordinatorTest more robust.,3
[FLINK-2527] [gelly] Ensure that VertexUpdateFunction.setNewVertexValue is called at most once per updateVertexThis closes #1027,5
[docs] Minor addition to the cluster execution docs.This closes #1018,2
[FLINK-2534] [runtime] Some improvements in CompactingHashTableThis closes #1029,1
"[FLINK-2462] [streaming] Major cleanup of operator structure for exception handling and code simplication  - The exceptions are no longer logged by the operators themselves.    Operators perform only cleanup in reaction to exceptions.    Exceptions are reported only the the root Task object, which knows whether this is the first    failure-causing exception (root cause), or is a subsequent exception, or whether the task was    actually canceled already. In the later case, exceptions are ignored, because many    cancellations lead to meaningless exceptions.  - more exception in signatures, less wrapping where not needed  - Core resource acquisition/release logic is in one streaming task, reducing code duplication  - Guaranteed cleanup of output buffer and input buffer resources (formerly missed when other exceptions where encountered)  - Fix mixup in instantiation of source contexts in the stream source task  - Auto watermark generators correctly shut down their interval scheduler  - Improve use of generics, got rid of many raw typesThis closes #1017",1
[tests] Reinforce StateCheckpoinedITCase to make sure actual checkpointing has happened before a failure.,0
[FLINK-2521] [tests] Adds TestLogger class which automatically logs the currently executed test names and the reasons for a failure.Makes test bases extend TestLogger to add automatic test name loggingFrames test logging statements to make them more prominentThis closes #1015.,1
[FLINK-2286] [streaming] Wrapped ParallelMerge into stream operatorCloses #994,1
[flink-2532] [streaming] fix variable name in StreamWindowCloses #1025,0
[tests] Hardens TaskManagerRegistrationTest.testTaskManagerResumesConnectAfterJobManagerFailure test case by checking testing actor's complete mailbox for a Terminated message,3
[tests] Rename 'compiler' tests to 'optimizer' tests for consistent naming,3
[FLINK-2477] [streaming] Add tests for SocketClientSinkThis closes #977,3
[FLINK-1962] Add Gelly Scala APIThis closes #1004,1
[FLINK-2529] [runtime] Remove some unused code in ExecutionThis closes #1022,1
[tests] Minor cleanup removing duplicate mock invokables in various tests.,3
[tests] Replaces Scala mixins for the Job/TaskManager with classes which extend the respective classes. Adds proper logger registration for sub-classes of FlinkUntypedActor.,2
"[FLINK-2398][api-breaking] Introduce StreamGraphGeneratorThis decouples the building of the StreamGraph from the API methods.Before the methods would build the StreamGraph as they go. Now the APImethods build a hierachy of StreamTransformation nodes. From these aStreamGraph is generated upon execution.This also introduces some API breaking changes: - The result of methods that create sinks is now DataStreamSink instead   of DataStream - Iterations cannot have feedback edges with differing parallelism - ""Preserve partitioning"" is not the default for feedback edges. The   previous option for this is removed. - You can close an iteration several times, no need for a union. - Strict checking of whether partitioning and parallelism work   together. I.e. if upstream and downstream parallelism don't match it   is not legal to have Forward partitioning anymore. This was not very   transparent: When you went from low parallelism to high dop some   downstream  operators would never get any input. When you went from high   parallelism to low dop you would get skew in the downstream operators   because all elements that would be forwarded to an operator that is not   ""there"" go to another operator. This requires insertion of global()   or rebalance() in some places. For example with most sources which   have parallelism one.This also makes StreamExecutionEnvironment.execute() behave consistentlyacross different execution environments (local, remote ...): The list ofoperators to be executed are cleared after execute is called.",1
[hotfix] Some Java 7 cleanups in InstantiationUtil,4
"[FLINK-2540] [optimizer] [runtime] Propagate union batch exchanges to union inputsThe DataExchangeMode of union nodes was not respected when translating an OptimizedPlanto a JobGraph. This could result in deadlocks, when a branched data flow was closed.Union nodes with a batch exchange will propagate their exchange mode to all inputs oftheir inputs when the JobGraph is generated.This closes #1036",4
[FLINK-1901] [core] Create sample operator for Dataset.[FLINK-1901] [core] enable sample with fixed size on the whole dataset.[FLINK-1901] [core] add more comments for RandomSamplerTest.[FLINK-1901] [core] refactor PoissonSampler output Iterator.[FLINK-1901] [core] move sample/sampleWithSize operator to DataSetUtils.Adds notes for commons-math3 to LICENSE and NOTICE fileThis closes #949.,2
[tests] Move UnionClosedBranchingTest to optimizer tests,3
"[FLINK-2306] Add support for named streams in Storm compatibility layer - enabled .declareStream() and connect via stream name - enabled multiplt output streams - added .split() / .select() / strip pattern - added helpers in new package utils - adapted and extended JUnit tests - adapted examplessome minor improvements (FlinkClient, integration of Tuple0)This closes #1011",2
[FLINK-2451] [gelly] removed redundant examples; added comments describing which gelly method each example illustrates.,1
[FLINK-2451] [gelly] library methods cleanup,4
[FLINK-2451] [gelly] re-organized tests; compare with collect() instead of temp files where possibleThis closes #1000,2
[gelly] made the number of vertices an optional parameter of PageRank; added the edge weight initialization to the library methods,5
[FLINK-2560] Flink-Avro Plugin cannot be handled by Eclipse  - disabled avro-maven-plugin within Eclipse via <pluginManagement> ... <lifecyleMappingMetaData>This closes #1041,5
[FLINK-2468] [tests] Make sure StateCheckpoinedITCase tolerates errors before first checkpoint,0
[FLINK-2558] Add Streaming Connector for Elasticsearch,1
[FLINK-2563] [gelly] extended the run() method of GraphAlgorithm interface to return an arbitrary typeThis closes #1042,1
[FLINK-2564] [core] Improve stability of RandomSamplerTest  - Expand the verification boundary for random sampler test  - Increase the number of times we sampleThis closes #1047,1
[FLINK-2528] [tests] Increase robustness and error reporting of MatchTaskTest,3
[FLINK-2089] [runtime] Fix illegal state in RecordWriter after partition write failure- Address PR commentsThis closes #1050.,1
[FLINK-2538] Close created JarFile in ClassLoaderUtil,2
[FLINK-2270] [docs] Fix typo in docs (enableMonitoring => enableCheckpointing),0
[FLINK-2460] [runtime] Check parent state in isReleased() check of partition view- Address PR commentsThis closes #1051.,1
[hotfix] Fixes auto type registration settings in ExecutionConfig,5
[hotfix] Allow setting FLINK_CONF_DIR by hand,5
[hotfix] Add notice about using FLINK_CONF_DIR in Yarn Setup,1
[FLINK-2394] HadoopOutputFormats use correct OutputCommitters.This closes #1056.,1
"[FLINK-2555] Properly pass security credentials in the Hadoop Input/Output format wrappersThis is needed because the Hadoop IF/OF's are using Hadoop's FileSystem stack, which is usingthe security credentials passed in the JobConf / Job class in the getSplits() method.Note that access to secured Hadoop 1.x using Hadoop IF/OF's is not possible with this change.This limitation is due to missing methods in the old APIs.- Add some comments & change dependency scope to test",3
[scripts] resolve base path of symlinked executable- also adapt config.sh to use the same cross-platform compatible mechanismThis closes #1049.,1
[FLINK-2575] [runtime] Deactivate join bloom filters by default,1
[FLINK-2189] [runtime] Fix various issues in hash table  - check for memory availability before probing  - correctly compute memory required for recursive build fast path  - remove all temp files properly,2
[FLINK-2356] Add shutdown hook to CheckpointCoordinator to prevent resource leaksThis closes #1063.,1
[FLINK-2480][test] add test for PrintSinkFunctionThis closes #991.,1
[FLINK-2578] [tests] Fix stability of TaskAsyncCallTest,3
[FLINK-2276] [tests] Fix stability of TaskTest,3
[FLINK-2386] [kafka connector] Add new Kafka Consumer for FlinkThis closes #996,2
"[streaming] Cleanup de-/serialization schema, add TypeInformationSerializationSchema prominent, add tests.",3
[FLINK-2386] [kafka connector] Add comments to all backported kafka sources and move them to 'org.apache.flink.kafka_backport',2
"[FLINK-2386] [kafka connector] Refactor, cleanup, and fix kafka consumers",0
[FLINK-2386] [kafka connector] Remove copied Kafka code again. Implemented our own topic metadata retrieval.This closes #1039,5
[FLINK-2386] [kafka connector] Move Kafka connector classes to 'org.apache.flink.streaming.connectors.kafka',2
[hotfix] Determing native byte order via ByteOrder.nativeOrder()This closes #1065,0
[FLINK-2569] [core] Add CsvReader support for Value types  - Extend ValueTypeInfo to check whether the type is basic value or not  - Extend TupleTypeInfo to support Value types  - Add three unit tests and an integration test  - Rename CsvReaderWithPOJOITCase to CsvReaderITCase  - Refactor CsvReaderITCase to use collect methodThis closes #1053,1
[FLINK-2553] Example Jars not build correctly  - reworked package structure of utils and wordcount.stormoperators package  - reword class hierarchy of *FileSpout and *InMemorySpout  - fixed pom.xml to assembly jars correctly  - simplified example jar file names  - replace maven-assembly-plugin with maven-shade-plugin (removed assembly.xml file)  - extended README and documenation to building and using correct jarsAdditional minor changes: - comment typo in FlinkSubmitter - removed version number in hardcoded jar file nameThis closes #1037,2
[tests] Move manual test 'RecordsAndWidthsCombinationCheck' to proper tests scope,3
"[FLINK-2584] [java api] Downgrade version of javakaffee kryo serializers, for compatibility with kryo 2.4",2
[FLINK-2587] [streaming] Make sure that close() is not called while checkpoint methods are in progress.,1
[FLINK-2326] [yarn] Write yarn properties file to temp directoryThis closes #1062,2
[FLINK-2582] [docs] Add documentation how to build Flink against different Scala versionsThis closes #1070,2
[FLINK-2556] [core] Refactor/fix pre-flight key validationThis closes #1044,5
[FLINK-2565] Support primitive arrays as keysThis closes #1043,1
[FLINK-2499] [scripts] Warning message for hosts starting multiple daemonsCloses #1071,2
[hotfix] fix missing decorations for accumulator messages,0
[hotfix] disable object reuse in merging of accumulators,1
[scripts] Fixes path for taskmanager.sh in the start-cluster.sh script,0
[FLINK-2594][client] implement a method to retrieve the accumulators of a job- move SerializedValue from runtime to core- unified code to deserialize accumulatorsThis closes #1072.,1
[hotfix] Include Hadoop version into EnvironmentInformation,5
"[FLINK-2543] [core] Fix user object deserialization for file-based state handles.Send exceptions from JM --> JC in serialized form.Exceptions send from the JobManager to the JobClient were relying onAkka's JavaSerialization, which does not have access to the user code classloader.This closes #1048",1
[FLINK-2543] [core] Make exception communication and result/failure notifications consistent with respect to serialization of exceptions,0
[FLINK-1681] [tests] Remove outdated 'nephele' iteration tests.,3
"[tests] Improve and combine iteration tests with aggregators (less static sharing, collect(), parallel execution)",3
"[FLINK-2291] [runtime] Add ZooKeeper support to elect a leader from a set of JobManager. The leader will then be retrieved from ZooKeeper by the TaskManagers.Refactors FlinkMiniCluster to support multiple JobManagerAdds proper remote address resolution for actorsClean up of LeaderElection and LeaderRetrievalService. Removes synchronization to avoid deadlock.Adds ZooKeeper start option to TestBaseUtils.startClusterRemoves registration session IDs, using the leader session IDs instead. Sets the leader session ID directly in the grantLeadership method. Let the LeaderElectionService select the leader session ID. Return leader session ID to LeaderRetrievalListeners.Removes direct ActorRef interactionIntroduces LeaderRetrievalService for the Client and the CliFrontend.Make ApplicationClient to use the LeaderRetrievalService for JobManager resolutionAdds LeaderElection/Retrieval testsAdded test for exception forwarding from the CuratorFramework to a ContenderAdds test job submission with changing leadersAdds new test cases for job cleanup after leader election changeAdds new LeaderChangeStateCleanup test caseAdds LeaderElectionRetrievalTestingClusterIntroduces ListeningBehaviour for job submissionsRelocation of org.apache.curator in flink-shaded-hadoop jarAdds Apache ZooKeeper and Apache Curator to LICENSE and NOTICE filesIncreases zookeeper connection timeout to 20000 ms for the KafkaITCase to fix failing tests on TravisIncreased timeouts of ZooKeeperLeaderElectionTest for TravisMakes the WebInfoServer and the WebRuntimeMonitor to use the LeaderRetrievalService to retrieve the current leading JobManagerAdds proper synchronization to ZooKeeperLeaderElectionService. Fixes StateCheckpointedITCase and PartitionedStateCheckpointingITCaseAdds configuration description for new ZooKeeper configuration valuesFixed port selection of JobManager at startupImproves logging outputExtends masters file to also specify the webui portsAdds proper network interface resolution by retrieving the current leader addressMakes the ZooKeeperLeaderElectionService write the leader information in ephemeral nodes so that the information is deleted once the leader has terminated. Fixes a bug in the TaskManager due to call by name semantics of scheduler.scheduleOnce.Adds jobManagerURL to TriggerTaskManagerRegistration messageEnables findConnectingAddress to use the ZooKeeperLeaderRetrievalService. This allows to test the connection to a possibly changing master node.Changes startup scripts to respect the recovery mode instead of the ZK_QUORUMAdjust travis log file to only log zookeeper errorsUpdates high availability setup guideAdds TestLogger to leader election testsThis closes #1016.",3
"[jobmanager] fix warning about non-exhaustive case matching- fixed warning by adding a catch all case- corrected indention of code blockhint: use -w to ignore the whitespace in the diff,      e.g. git log -u -w",2
[FLINK-2599] [test-stability] Fix possible NPE in SlotCountExceedingParallelismTest,3
[core][runtime] move SerializedValueTest from runtime to core- move createCopySerializable to core's CommonTestUtils- rename CommonTestUtils createCopy to createCopyWritable- adapt the tests to use core's CommonTestUtils where applicableThis closes #1081.,3
[scripts] Fixes correct Flink bin path usage in scripts,2
[scripts] Adds example settings for zookeeper ha to default flink-conf.yaml,5
[FLINK-2596] Remove non-transitive comparator in random sampler test.This closes #1080,3
[FLINK-2584] Check for unshaded classes in fat jar and shade curatorThis closes #1076,2
[FLINK-2590] fixing DataSetUtils.zipWithUniqueId() and DataSetUtils.zipWithIndex()* modified algorithm as explained in the issue* updated method documentation[FLINK-2590] reducing required bit shift size* maximum bit size is changed to getNumberOfParallelSubTasks() - 1This closes #1075.,1
[FLINK-2590] Fixes Scala's DataSetUtilsITCase,5
[FLINK-2604] [runtime] Adds synchronization to stop method of ZooKeeperLeaderElectionService,1
[FLINK-2601] [runtime] Install shutdown hook at the end of I/O manager initializationThis prevents possible null pointers when the JVM shuts down before the I/O manager was fully started.,5
[FLINK-2545] add bucket member verification while build bloom filter.This closes #1067,1
[FLINK-2448] [tests] Create new Test Environments on every call to getExecutionEnvironment and allow sharing of job execution results,1
[hotfix] [gelly] Remove unintended calls to getExecutionEnvironment in VertexCentricIteration and GatherSumApplyIterationThis closes #1031,1
[hotfix][docs] Update Kafka section in streaming guide to match the renamed class names,5
[FLINK-2607][quickstart] ignore signature files when creating fat jarThis closes #1085.,1
[FLINK-2614][scala-shell] scala shell's default execution mode is broken- call new start() method of FlinkMiniCluster,5
[FLINK-2475] Rename Flink Client log fileThis closes #1074,2
[FLINK-2161] [scala shell] Modify start script to take additional argument (-a <path/to/class> or --addclasspath <path/to/class>) for external librariesThis closes #805,1
[FLINK-2605] [runtime] Unclosed RandomAccessFile may leak resource in StaticFileServerHandlerThis closes #1089.,2
[FLINK-2625] Pass configuration properly to JobGraphGeneratorLocalExecutor and Client now pass Configuration to JobGraphGenerator.This closes #1095,5
[FLINK-2628] [tests] CoStreamCheckpointingITCase prints a warning when test is inconclusiveThe test is inconclusive when the test failure happens before the first checkpoint.,0
[hotfix] [tests] Increase zookeeper session timeouts in tests them more robust,3
[FLINK-2626] [core] Add an average accumulatorThis closes #1096,1
[FLINK-2626] [core] Minor cleanups in AverageAccumulator and AverageAccumulatorTest,3
[FLINK-2372] Add new FlinkKafkaProducer bases on the new producer APIThis closes #1082,1
"[FLINK-2567] [core] Allow quoted strings in CSV fields to contain quotation character inside of the field, as long as its escaped Ex: 'Hi my name is \'Flink\''This closes #1059",2
[FLINK-2570] [gelly] Added a Triangle Count Library Method[FLINK-2570] [gelly] Added a description of the I/OThis closes #1054,1
[FLINK-2480][test] add a prefix test for PrintSinkFunction- improve test layoutThis closes #1073.,3
[FLINK-2106] [runtime] Add Outer Join drivers and Outer Merge strategies to Runtime,1
[FLINK-2616] [tests] Increases timeout of ZooKeeperLeaderElectionTest to 60s,3
[FLINK-2490][streaming] fix retryForever check in SocketStreamFunctionThis closes #992.,1
[FLINK-1320] [core] Add an off-heap variant of the managed memoryThis closes #1093,1
[FLINK-2636] [streaming] Create common type StreamElement for StreamRecord and Watermark,1
[FLINK-2635] [streaming] Make input processors independent of batch reader interface.,1
[FLINK-2580] [runtime] Expose more methods form Hadoop output streams and exposes wrapped input and output streams.,1
[FLINK-2392] Improve YARN test stability,3
[FLINK-2321] [ml] Set seed for SVM to be randomThis closes #889.,1
[FLINK-2600] Enable test rerun for Elasticsearch TestsThis also bumps surefire/failsafe version to 2.8.1,0
[FLINK-1674] Modified test cases for nested avro typeThis closes #1091,3
[FLINK-2493] Simplify names of example program JARsThis closes #1094,2
"[FLINK-1297] add accumulator called OperatorStatsAccumulator..capable of tracking min, max and estimates for count distinct andheavy hitters.The count distinct algorithms are Linear Counting and HyperLogLog, bothfrom an imported library from clearspring.The heavy hitters algorithms are Lossy counting (Manku et.al 2002) andone based on Count Min Sketch (Cormode 2005).The heavy hitters algorithms are implemented in the statistics packagein the flink-operator-stats submodule of flink-contrib.Include tests verifying if merged skecthes have the same guarantees aslocal sketches.Added conditional to every collect variable, to make stats moreconfigurable. Made print operator stats more informative. Addedarguments to yarn pom to enable buildingImplemented deep cloning for class OperatorStatistics. Added additionaltests in OperatorStatsAccumulatorTest to check if the accumulator workswhen only one statistic is being tracked, rather than all.This closes #605.",1
[FLINK-2619] [tests] Fix for some unexecuted Scala testsThis closes #1103,3
[FLINK-2619] [tests] Fix failing ExecutionGraphRestartTest and JobManagerRegistrationTest,3
"[FLINK-2638] [core] Add @SafeVarargs to the ExecutionEnvironment's ""fromElements(...)"" method.This closes #1109",1
[FLINK-2003] [docs] Added instructions for encrypted filesystemsThis closes #1100,5
[FLINK-2648] [tests] Fix flaky CombineTaskTest and improve cancelling in GroupReduceCombineDriver,1
[FLINK-2650] Fix broken Links in Table API doc,2
"[FLINK-2631] [streaming] Fixes the StreamFold operator and adds OutputTypeConfigurable interface to support type injection at StreamGraph creation.Adds test for non serializable fold type. Adds test to verify proper output type forwarding for OutputTypeConfigurable implementations.Makes OutputTypeConfigurable typed, tests that TwoInputStreamOperator is output type configurableThis closes #1101",5
"[FLINK-2617] [hadoop-compat] Added static mutexes for configure, open, close HadoopFormatsThis closes #1111",5
[FLINK-2408] Define all maven properties outside build profilesThis closes #941,2
[FLINK-2632] [client] Fix web client to respect the class loader of submitted jobsThis closes #1114,0
"[FLINK-2577] [streaming] Fix Stalling Watermarks when Sources CloseBefore, when one source closes early it will not emit watermarksanymore. Downstream operations don't know about this and expectwatermarks to keep on coming. This leads to watermarks not beingforwarded anymore.Now, when a source closes it will emit a final watermark with timestampLong.MAX_VALUE. This will have the effect of allowing the watermarksfrom the other operations to propagate though because the watermark isdefined as the minimum over all inputs.The Long.MAX_VALUE watermark has the added benefit of notifyingoperations that no more elements will arrive in the future.This closes #1060",1
[FLINK-2639] Add repository for hdp specific jetty to 'vendor-repos'This closes #1113-----Closing unresponsive PR:This closes #862,1
"[FLINK-2647] [streaming core] Distinguish between ""close"" (flushing buffered data) and ""dispose"" (cleanup resources) in streaming operators.",1
[hotfix] [tests] Fix warnings and casts in AbstractGenericArraySerializerTest,3
[FLINK-2656] Fix behavior of FlinkKafkaConsumer for out of range offsetsThis closes #1117,1
[FLINK-2654] Add JavaDoc to ParameterTool classThis closes #1116,2
[streaming] Appropriate Exception message in WriteSinkFunctionCloses #1119,1
[FLINK-2658] fieldsGrouping for multiple output streams fails - added SplitStreamTypeKeySelector and JUnit testsThis closes #1122,3
[FLINK-2664] [streaming] Allow partitioned state removalCloses #1126,4
[FLINK-2373] Add configuration parameter to createRemoteEnvironment methodThis closes #1066,1
[FLINK-2533] [java-api] Gap based random sample optimization.This closes #1110,2
[FLINK-2665] [api] [runtime] Makes ExecutionConfig serializable by forcing Kryo serializers to be SerializableThis closes #1128-----Closing PR:This closes #867,1
[FLINK-2670] [tests] Add tests that validate memory release under concurrent modification exceptions,5
[FLINK-1851] [tableAPI] Add support for casting in Table Expression Parser- Also fix code generation for casting between primitives.- Extends documentation for TableAPI expressionsThis closes #592,2
[TableAPI] [tests] Disambiguate result of test programs to DataSetThis closes #1131,5
[FLINK-2641] integrate off-heap memory configuration- add offheap configuration parameter taskmanager.memory.off-heap- remove offheap ratio parameter and reuse memory fraction parameter- set JVM -XX:MaxDirectMemorySize parameter correctlyThis closes #1129,2
[FLINK-2595] [tests] Fixed unclosed JarFile in ClassLoaderUtilsTestThis closes #1137,3
[FLINK-2637] [api-breaking] [types] Adds equals and hashCode method to TypeInformations and TypeSerializers- Fixes ObjectArrayTypeInfo- Makes CompositeTypes serializable- Adds test for equality relation's symmetric property- Adds test for PojoTypeInfo serializabilityThis closes #1134,5
[FLINK-2640] [yarn] integrate off-heap configurationThis closes #1132,5
[FLINK-2689] [runtime] Fix reuse of null object for solution set Joins and CoGroups.This closes #1136,1
[FLINK-2659] [runtime] Fix object reuse in UnionWithTempOperatorThis closes #1130,1
[FLINK-2691] [documentation] Fix broken links to Python script on QuickStart docsThis closes #1140,2
[hotfix] [tests] Increase resilience of ProcessFailureRecoveryTests,3
[hotfix] [kafka] Make tests robust against broker port conflicts.,5
[FLINK-2547] [web dashboard] Improved timeline view,1
[FLINK-2415] [optimizer] Create and attach proper JobGraph describing JSON plans to JobGraph for batch jobs.,5
[FLINK-2547] [web dashboard] Updated web dashboard after request/response changes,4
[FLINK-2547] [web dashboard] Add handlers for cluster status and web dashboard configuration,5
[FLINK-2357] [web dashboard] Added the 'Scheduled' mark to timeline,1
[FLINK-2357] [web dashboard] Added tooltips to timeline,1
"[FLINK-2415] [web dashboard] Provide more data in the job overview responsesRather than only listing job ids, this now includes all information necessary to describe the job.This reduces the number of requests for the job overview page to a single request.",5
[FLINK-2357] [web dashboard] Changed overview and timeline,4
[FLINK-2554] [web dashboard] Add request hander that lists exceptions encountered during execution,1
"[FLINK-2415] [monitoring api] Add vertex details request handler, unify IDs between vertices and plan",0
[FLINK-2357] [web dashboard] Auto-update overview page,5
[FLINK-2357] [web dashboard] Add view for exceptions,1
[FLINK-2687] [monitoring API] Extend vertex requests with subtask data and accumulators,5
[FLINK-2357] [web dashboard] Extend exceptions view,2
[FLINK-2357] [web dashboard] Added status counts for a job,1
[FLINK-2357] [web dashboard] Timeline for running tasks,1
[FLINK-2357] [web dashboard] New node organization,1
[FLINK-2357] [web dashboard] Show plan (and optimizer properties) as a dedicated view,2
[FLINK-2357] [web dashboard] Adjust view for details of a job,2
[FLINK-2357] [web dashboard] Add auto-refresh to dashboard,1
[FLINK-2687] [monitoring api] Add handlers for subtask details and accumulators,0
[FLINK-2357] [web dashboard] Add subtasks to vertex display,1
[FLINK-2688] [monitoring api] Add docs for monitoring REST API.,2
[FLINK-2688] [monitoring api] Integrate monitoring request handler with HA leader handling,0
"Revert ""[FLINK-2605] [runtime] Unclosed RandomAccessFile may leak resource in StaticFileServerHandler""The change breaks the functionality by returning incorrect HTTP responses (length / contents mismatch).",1
[FLINK-2698] Add trailing newline to flink-conf.yamlThis closes #1142,5
[FLINK-2701] [streaming] Add getter for wrapped Java environment to Scala ExecutionEnvironmentThis closes #1120,1
[FLINK-2557] [core] TypeExtractor properly returns MissingTypeInfoThis closes #1045,5
[FLINK-2627] [scala api] Makes scala data set utils easier to access.The import required is now org.apache.flink.api.scala.utils._Also adds a method to create case class type information for scala tuplesThis closes #1099,5
[FLINK-2702] [examples] Add a distributed copy utility exampleThis closes #1090,1
"[FLINK-2702] [examples] Add JAR packaging for DistCp example, plus minor cleanups.",4
[FLINK-2704] [streaming] Clean up naming of State/Checkpoint InterfacesThis closes #671The interfaces are used on StreamTask (for now) but were called*Operator.,1
[FLINK-2583] [hdfs connector] Add Stream Sink For Rolling HDFS FilesThis is also integrated with Checkpointing to provide exactly-once semantics.,1
"[hotfix] [build] Fix curator deps, Exclude Curator deps in TestsTests would fail because of version conflicts because the tests includethe original curator dependencies even though we shade them away in thefinal build result.This also fixes dependency management entries for curator dependencies.We shade it, therefore it cannot be in the dependency managementsection in the root pom.",0
[FLINK-2643] [build] Change Travis Build Matrix to Include Recent Hadoop VersionsThis removes 2.0.0-alpha. There are currently bugs that prevent 2.3.0and 2.7.0 from being used.This closes #1084,1
[FLINK-2707] [streaming] Set StateCheckpointer before default state value,1
[tempfix] [streaming] Disable fork reuse in streaming testsThe streaming tests violate the UnitTest / IntegrationTest patterns and hence cannot reuseJVMs for Unit Tests.,3
[test-stability] Hardens TaskManagerRegistrationTest by increasing the timeouts,1
[tests] [runtime] Disable for reuse for runtime unit tests,3
[hotfix] [tests] Remove sysout logging in LargeRecordHandlerITCase,0
[hotfix] [taskmanager] Add chain failure cause to exception when updating task execution state on JobManager,5
[FLINK-2711] [tests] Increase timeout for TaskManager tests upon partition lookups,3
[FLINK-2357] [web dashboard] Fixed broken plan on second entryThis closes #1148,1
[FLINK2392] Increase memory for TaskManager,1
[build system] Update secret keys for travis log delivery,2
[FLINK-2536] [streaming] Add a re-connect attempty to socket sinkThis closes #1030,1
[FLINK-2536] [streaming] Cleanups and improvements on SocketClientSink,1
[FLINK-2713] [streaming] Set state restore to lazy to avoid StateCheckpointer issues and reduce checkpoint overheadCloses #1154,0
[FLINK-2710] [streaming] Fix and improve SocketTextStreamFunction and SocketTextStreamFunctionTest,3
[FLINK-2648] [FLINK-2717] [runtime] Harden memory release in sorters against asynchronous canceling,1
[FLINK-2724] [runtime] Fix object reuse in GroupReduceCombineDriver and ReduceCombineDriver,1
[FLINK-2649] [scala shell] Fix unclosed stream in case of an error in JarHelper#unjar()This closes #1151,0
[FLINK-2392][yarn tests] Use log event which is guaranteed to show upto test whether the job was successful,3
[test-stability] Sets the number of ZooKeeper servers of TestingCluster in ForkableFlinkMiniCluster to 1 in order to avoid test failures when two servers try to bind to the same port.,1
[FLINK-2392][yarn tests] Produce more log output on travis for the flink-yarn-tests to avoid running into the 300s limit,1
[FLINK-2675] [streaming] Add utilities for scheduled triggers.,1
[FLINK-2683] [FLINK-2682] [runtime] Add dedicated operator for aligned processing time windows.Also add utilities for heap-backed keyed state in panes (dedicated tailored hash table),1
[FLINK-2643] [build] Update Travis build matrix and change snapshot deploy profilesThis closes #1146,2
[FLINK-2722] Use InetAddress.getLocalHost() as first approach when detecting the TMs own ip/hostnameThis closes #1159,1
[FLINK-2392][yarn tests] Address concurrent modification exception,1
"[Maven] fix order of parent module informationAn order other than ""groupId, artifactId, version"" can cause problemswith the release scripts.This needs to be properly fixed in tools/generate_specific_pom.sh",0
"[FLINK-2097][core] implement a job session managementSessions make sure that the JobManager does not immediately discard aJobGraph after execution, but keeps it around for further operations tobe attached to the graph. That is the basis for interactive sessions.This pull request implements a rudimentary session management. Togetherwith the backtracking #640, this will enable users to submit jobs to thecluster and access intermediate results. Session handling ensures thatthe results are cleared eventually.ExecutionGraphs are kept as long as  - no timeout occurred or  - the session has not been explicitly endedThe following changes have also been made in this pull request:- The Job ID is created through the ExecutionEnvironment and passed through- Sessions can be termined by the ExecutionEnvironment or directly  through the executor- The environments use reapers (local) and shutdown hooks (remote) to  ensure session termination when the environment runs out of scope- The Client manages only connections to the JobManager, it is not job  specificThis closes #858.",1
[FLINK-2097] temporarily disable session management API,2
[test-stability] Replaces Curator's TestingCluster with TestingServer in ZooKeeperElection/RetrievalTests. Increased the timeout to 200s in ZooKeeperLeaderElectionTest.Adds logging statements to ZooKeeperLeaderElection/RetrievalServiceAdds more debug logging and enabled debug logging for ZooKeeperLeaderElection/RetrievalService,2
[FLINK-2729] [web-dashboard] Add TaskManager overview[FLINK-2729] [web-dashboard] Rename 'task-managers' => 'taskmanagers'This closes #1164,2
[tests] Add RetryOnFailure annotationRemove TestRetryThis closes #1167,3
[FLINK-2696] [test-stability] Hardens ZookeeperOffsetHandlerTest by letting Curator's TestingServer select the port to bind to instead of using NetUtils.getAvailablePort.This closes #1144.,1
[FLINK-2694] [test-stability] Hardens the JobManagerProcessReapingTest.testReapProcessOnFailure test case by letting the JobManager choose its port instead of predetermining it via the NetUtils.getAvailablePort.This closes #1145.,1
[FLINK-2705] [yarn] Excludes commons-codec:1.3 from aws-java-jdk dependency to resolve dependency ambiguityThis closes #1162.,0
[FLINK-2746] [tests] Add RetryOnException annotation for tests,3
[FLINK-2744] [kafka connector] Reduce number of concurrent test forks to improce test stability on CI environment.,3
[tests] Improve Kafka concurrent produce/consumer test by allowing retries when connecting to non-leader broker.,1
[FLINK-2734] [streaming] Fix ArrayKeySelectorThis closes #1166,0
[hotfix] [streaming] Improve error message for key operations on non-composite typesAlso clean up KeySelectorUtil.,4
"[tests] Harden SocketClientSinkTestDepending on the OS, noticing the closed server socket requires more payload.(I tried to rewrite a test before noticing this and just kept it as is.)",3
"[FLINK-2651] Add Netty to dependency managementHadoop 2.7.0 pulls in an older Netty version, which clashes with our version.This makes sure to only pull in our version.",1
Bump Netty version to 4.0.31.FinalThis closes #1174,5
[FLINK-2675] [streaming] Integrate Timer Service with StreamTaskThis integrates the timer as a service in StreamTask thatStreamOperators can use by calling a method on theStreamingRuntimeContext.This also ensures that the timer callbacks can not be calledconcurrently with other methods on the StreamOperator. This behaviour isensured by an ITCase.This closes #1165,1
[jobmanager] Fix indentation,0
Adjust Netty version in flink-dist/LICENSE,2
[FLINK-1520] [gelly] Read edges and vertices from CSV filesThis squashes the following commit:[FLINK-1520] [gelly]Changed the methods for specifying types.Created a new file for tests. Made appropriate changes in gelly_guide.md,4
"[FLINK-1520] [gelly] add types methods and make formatting changes to the graph csv readerThis squashes the following commits:[FLINK-1520] [gelly] add named types methods for reading a Graph from CSV input,with and without vertex/edge values. Change the examples and the tests accordingly.[FLINK-1520] [gelly] corrections in Javadocs; updated documentationThis closes #1149",2
"[FLINK-2751] [docs] Add quickstart menu to the navigation bar of documentation  - Improve conditional ""active"" class for dropdown menu  - Fix unclosed A tagThis closes #1176.",0
[FLINK-2616] [test-stability] Fixes ZooKeeperLeaderElectionTest.testMultipleLeaders by introducing a second retrieval service to retrieve the leader address after the faulty address has been written.This closes #1173.,1
[FLINK-2200] [build system] Add scala version suffix to artifact id for Scala 2.11,0
[FLINK-2200] [build system] Deploy Flink 2.11 with every build (nightly)This closes #885,2
[docs] fix typo of the RabbitMQ Java example (added braces)Closes #1179,1
[utils] Missing getters for ParameterToolCloses #1168,2
[scripts] Exclude .git in source release,5
[FLINK-2690] [api-breaking] [scala api] [java api] Adds functionality to the CsvInputFormat to find fields defined in a super class of a Pojo. Refactors CsvInputFormat to share code between this format and ScalaCsvInputFormat.This closes #1141.,4
"[FLINK-2753] [streaming] [api breaking] Add first parts of new window API for key grouped windowsThis follows the API design outlined in https://cwiki.apache.org/confluence/display/FLINK/Streams+and+Operations+on+StreamsThis is API breaking because it adds new generic type parameters to Java and Scala classes, breaking binary compatibility.",4
Fix some typos and naming inconsistencies in new Windowing Code,1
"Move window operators and tests to windowing packageThe api package is also called windowing, this harmonizes the packagenames.",1
Harmonize generic parameter names in Stream API classes,2
Add Count and Delta  WindowPolicy,1
"Add Window parameter to KeyedWindowFunction, move to package windowing",4
Move delta window functions to package functions.windowing.delta,1
[FLINK-2677] Add a general-purpose keyed-window operator,1
[hotfix][streaming] correct return type of execute(..) method,0
"[FLINK-2561] [gelly] add missing methods to Graph:add-remove edges/vertices, difference, graph creation methods,validate, getTriplets. Add missing utility mappers.",1
[FLINK-2561] [gelly] convert existing tests to use collect instead of files;add tests for newly added operations.Add completeness test: fromCsvReader method is missing.,3
[FLINK-2561] [gelly] add GraphMetrics Scala exampleThis closes #1183,1
[FLINK-2768] [docs] Fix wrong java version requirement in quickstart (1.6 -> 1.7 and 6.x -> 7.x)This closes #1188,1
[FLINK-2769] [dashboard] Remove hard coded job server URLThis closes #1185,4
[FLINK-2756] [scripts] Fix start/stop scripts for paths with spacesThis closes #1182,0
[FLINK-2723] [core] CopyableValue method to copy into new instanceThis closes #1169,1
[FLINK-2754] Fixed FixedLengthRecordSorter write to multi memory pages issue and add more unit tests.This closes #1178,3
[FLINK-2761] [scala-shell] Prevent creation of new environment in Scala ShellThis closes #1180,1
[FLINK-2763] [runtime] Fix hash table spilling partition selection.,0
"[FLINK-2777] [docs] Fix Scala API description in programming_guide.htmldef createLocalEnvironment(parallelism: Int = Runtime.getRuntime.availableProcessors()))//issue1: In the end, there is a extra "")""def createRemoteEnvironment(host: String, port: String, jarFiles: String*)def createRemoteEnvironment(host: String, port: String, parallelism: Int, jarFiles: String*)//issue2: the parameter of port should be ""Int"", not ""String""This closes #1193",2
[FLINK-2754] Add a new module for micro benchmark.This closes #1177,1
"[FLINK-2775] [CLEANUP] Cleanup code as part of theme to be more consistent on Utils classesAs part of continuing theme and effort to help make the code more consistent, adding cleanup to Utils classes:-) Add final class modifier to the XXXUtils and XXXUtil classes to make sure can not be extended.-) Add missing Javadoc header classs to some public classes.-) Add private constructor to Utils classes to avoid instantiation.-) Remove unused test/java/org/apache/flink/test/recordJobs/util/ConfigUtils.java classAuthor: hsaputra <hsaputra@apache.org>Closes #1189 from hsaputra/add_missing_javadocs_class and squashes the following commits:0dfba19 [hsaputra] Cleanup code as part of theme to be more consistent: -) Add final class modifier to the XXXUtils and XXXUtil classes to make sure could not be extended. -) Add missing Javadoc header classs to some public classes. -) Add private constructor to Utils classes to avoid instantiation. -) Remove unused test/java/org/apache/flink/test/recordJobs/util/ConfigUtils.java class",5
[FLINK-2764] [WebClient] WebClient cannot display multiple JobsThis closes #1181,2
[FLINK-2703] Prepare Flink for being used with Logback.This closes #1194,2
[FLINK-2773] remove strict upper direct memory limitSetting a strict upper limit for the direct memory size can causeproblems with the direct memory allocation of the Netty network stackleading to OutOfMemoryExceptions.This closes #1203.,1
[FLINK-2097] fix finalize() method of ExecutorReaper,0
[FLINK-2781] [core] Cleanup NetUtils.  - The NetUtils class (in flink-core) contains all methods usable without runtime dependency  - The runtime NetUtils class (to find connectiong addresses) is now called ConnectionUtil.,1
[FLINK-2766] [core] Add proper handling of IPv6 address literals in URLs,1
"[hotfix] [build] Add joda-convert as a non-optional dependency, to fix Scala interoperability",0
[FLINK-2787] [core] Prevent instantiation of RemoteEnvironment when running a program through the command line.This also cleans up the use of context environments.,1
[streaming] [storm] Clean up instantiation of mini clusters and test environments.,3
"[FLINK-2783] Remove ""degreeOfParallelism"" API callsThis closes #1200",4
[FLINK-2561] [gelly] add Scala Gelly docsThis closes #1204,2
"[hotfix] Simplify new windowing APIBefore, there would be three different window() methods onKeyedDataStream: one that takes two policies, one that takes one policyand one that takes a window assigner.Now, there is only one window() method that takes a window assigner andcreates a KeyedWindowDataStream.For conveniece, there are two methods timeWindows() that take either oneargument (tumbling windows) or two arguments (sliding windows). Thesecreate a KeyedWindowDataStream with either a SlidingWindows orTumblingWindows assigner.When the window operator is created we pick the optimized aligned timewindows operator if the combination of window assigner/trigger/evictorallows it.All of this behaviour is verified in tests.This closes #1195",3
[FLINK-2778] Add API for non-parallel non-keyed WindowsThis adds two new operators for non-keyed windows: Regular triggeroperator and evicting trigger operator.This also adds the API calls nonParallelWindow(...) on DataStream andthe API class NonParallelWindowDataStream for representing theseoperations.This also adds tests for both the operators and the translation from APIto operators.,1
[hotfix] [tests] Run IPv6HostnamesITCase with parallel data exchange and less verbose output,4
"[doc] fixed typos in ""Internals -> Fault Tolerance for Data Streaming""",5
[FLINK-2663] [gelly] Updated Gelly library methods to use generic key typesThis squashes the following commits:[gelly] Added missing Javadocs to GSA classes[FLINK-2663] [gelly] Updated Gelly library methods to also use generic vertex/edge values where possibleThis closes #1152,1
[FLINK-2525] Add configuration support in Storm-compatibilityThis closes #1046,1
[FLINK-2748][jobmanager] accumulator fetch failure leads to duplicate job result responseThis closes #1206.,1
[FLINK-2776][cli] print job id when submitting a job,2
[FLINK-2762][cli] print execution result only if available,2
[FLINK-1599][docs] TypeComperator with no keys and comparators matches some elements- update JavaDoc to clarify the usage of the extractKey(..) and  getFlatComparators() methodThis closes #1207.,1
[FLINK-2796][cli] fix -q flag to suppress log output,2
[FLINK-2727] [streaming] Add a base class for Message Queue Sources that acknowledge messages by ID.This closes #1163,1
[hotfix] [streaming] Apply closure cleaner to KeyedWindowFunction,1
[hotfix] [streaming] Handle rich functions properly in aligned time windows,1
[FLINK-2802] [streaming] Remove cyclic watermark dependencies for iterationsCloses #1216,4
"[FLINK-2666] Add timestamp extraction operatorThis adds a user function TimestampExtractor and an operatorExtractTimestampsOperator that can be used to extract timestamps andattach them to elements to do event-time windowing.Users can either use an AscendingTimestampExtractor that assumes thattimestamps are monotonically increasing. (This allows it to derive thewatermark very easily.) Or they use a TimestampExtractor, where theyalso have to provide the watermark.The ExtractTimestampOperator periodically (on the auto watermarkinterval) calls the extractor to get the current watermark and forwardsit.This also adds an ITCase for this behaviour.",1
[FLINK-2740] Adding flink-connector-nifi module with NiFiSource and NiFiSinkThis closes #1198,2
[hotfix] Execute YARN integration tests only upon request (by activating the 'include-yarn-tests' profile)The default Hadoop version set in Flink (2.3.0) is causing the MiniYarnCluster to fail on some machines with some ip/hostname resolution issues.The YARN tests are all executed in travis profiles with Hadoop versions above 2.3.0This closes #1210,2
[FLINK-2550] Simplify Stream Java API Class NamesKeyedDataStream -> KeyedStreamKeyedWindowDataStream -> WindowedStreamNonParallelWindowDataStream -> AllWindowedStreamKeyedWindowFunction -> WindowFunctionWindowFunction -> AllWindowFunction(along with rich functions and reduce function wrappers)WindowedStream.mapWindow -> WindowedStream.applyAllWindowedStream.mapWindow -> AllWindowedStream.applyAlso renamed the tests to match the new names.,1
"[FLINK-2550] Rename ConnectedDataStream to ConnectedStreams, Remove some operationsThe removed operations are tricky and some of them are not workingcorrectly. For now, co-reduce, stream-cross and stream-join areremoved.I'm planning to add a new join implementation based on tagged unionthat uses the new windowing code.",1
[FLINK-2550] Remove groupBy and GroupedDataStreamTheir functionality is subsumed by keyBy and KeyedStream,1
Add Scala API for new WindowingThis adds window/timeWindow to KeyedStream along with windowAll/timeWindowAllon DataStream.The added API classes are AllWindowedStream and WindowedStream.This also adds Translations tests similar to those for the Java API: - AllWindowTranslationTest.scala - WindowTranslationTest.scala,3
Disable tests because operators are not implemented yet,1
[FLINK-2550] Change Window API constructs to use Time instead of longThis covers assigners/triggers/evictors.,1
[FLINK-2807] Add Javadocs for new windowing semantics/internals,1
[hotfix] Use closure cleaner for reduce window,4
[FLINK-2550] Rename IterativeDataStream to IterativeStream,5
[FLINK-2550] Rename SplitDataStream to SplitStream,5
[FLINK-1610] fix building of java doc for Java 8This closes #1225.,2
[FLINK-2813] document parameter for off-heap memoryThis closes #1226.,2
[FLINK-2810] Warn user if bc not installedThis closes #1228.,1
[FLINK-2811] [web-dashboard] Add job manager configuration overviewThis closes #1219,5
[FLINK-2741] Use single log statement in TestLoggerThis closes #1221,3
[FLINK-2786] Remove Spargel code and docs; Port Spargel tests to Gelly; Remove Beta badge from GellyThis closes #1229,4
[FLINK-2566] FlinkTopologyContext not populated completely  - extended FlinkTopologyContext to be populted with all supportable attributes  - added JUnit test  - updated README.mdadditionally: module restructuring to get cleaner package structureThis closes #1135,4
"[Storm Compatibility] Maven module restucturing and cleanup  - removed storm-parent; renamed storm-core and storm-examples  - updated internal Java package structure    * renamed package ""stormcompatibility"" to ""storm""    * unified *SpoutWrapper* to single SpoutWrapper.java class    * moved classes to appropriate packages    * shortened class names by stripping ""Storm""  - some more minor fixes, cleanups, and test improvements  - updated READMEs and web documentation  - updated examples pom.xml to assembly WordCount jars correctly",5
[FLINK-2822] [streaming] Remove scala.Serializable imports,2
[FLINK-2642] [table] Scala Table API crashes when executing word count exampleThis closes #1209.,2
"[streaming] Removed unused StreamReduceRefactored corresponding tests, some minor cleanups.",4
[FLINK-2283] [streaming] grouped reduce and fold operators checkpoint state,1
[FLINK-2283] [streaming] Test for checkpointing in internal operators,1
[FLINK-2283] [streaming] Proper serialization of state in StreamGroupedFold and Reduce,2
[FLINK-2812] [streaming] KeySelectorUtil interacts well with type extractionThe interaction is tested in the AggregationFunctionTest and the scala DataStreamTest amongst others.Closes #1155,5
"[FLINK-2815] [REFACTOR] Remove Pact from class and file names since it is no longer valid referenceRemove Pact word from class and file names in Apache Flink.Pact was the name used in Stratosphere time to refer to concept of distributed datasets (similar to Flink Dataset). It was used when Pact and Nephele still separate concept.As part of 0.10.0 release cleanup effort, let's remove the Pact names to avoid confusion.The PR also contains small cleanups (sorry):1. Small refactor DataSinkTask and DataSourceTask to follow Java7 generic convention creation new collection. Remove LOG.isDebugEnabled check.2. Simple cleanup to update MapValue and TypeInformation with Java7 generic convention creation new collection.3. Combine several exceptions that have same catch operation.Apologize for the extra changes with PR. But I separated them into different commits for easier review.Author: hsaputra <hsaputra@apache.org>Closes #1218 from hsaputra/remove_pact_name and squashes the following commits:b3c55b4 [hsaputra] Rename RegularTask to BatchTask per review.e278fac [hsaputra] Address review comments from chiwanpark (good catch).9f92f33 [hsaputra] Remove Pact from the file names of teh flink-runtime and flink-clients modules.dbb2175 [hsaputra] Simple cleanup to update MapValue with Java7 generic for new collection. Remove unused imports in CollectionsDataTypeTest.df2f553 [hsaputra] Use Java7 style of type resolution for new collection.6403d44 [hsaputra] Remove the word Pact from the Javadoc for ChainedDriver.0c562f4 [hsaputra] Small refactor on DataSinkTask and DataSourceTask classes to keep up with modern Java practice.",5
"Revert ""[FLINK-2210] Table API support for aggregation on columns with null values""This reverts commit b59c81bc41f0fc4ade5359dfdf42549a76d412fa.The commit had to be reverted because the RowSerializer is not in syncwith other comparators and serializers. See FLINK-2236.",2
"Revert ""[FLINK-2203] handling null values for RowSerializer""This reverts commit f8e12b20d925c3f6f24769327d1da5d98affa679.The commit had to be reverted because the RowSerializer is not in syncwith other comperators and serializers. See FLINK-2236.",2
Create a deep-copy of the record when changing timestamps.,4
[FLINK-2825] FlinkClient.killTopology fails due to missing leader session ID,0
[FLINK-2066][core] Add configuration of delay between execution retries at job levelThis closes #1223,5
[FLINK-2767] [scala shell] Add Scala 2.11 support to Scala shell.Update Scala 2.11 version and jline dependency.This closes #1197,5
[FLINK-2806] [scala-api] Add a TypeInformation[Nothing]This closes #1212.,5
[FLINK-2785] [gelly] implement fromCsvReader for gelly-scala; add tests and docsThis closes #1205,2
"[FLINK-2819] Add Windowed Join/CoGroup Operator Based on Tagged UnionRight now, this does everything in memory, so the JVM will blow if datafor one key becomes too large.",5
"[FLINK-2550] Rename reduceWindow to reduce on *WindowedStream, add Lambda ReduceLambda Reduce is the reduce method that takes a Scala Lambda function.",1
[FLINK-2550] Add Window Aggregations to new Windowing API,1
[FLINK-2550] Rework interplay of Window Assigners and TimeCharacteristic,1
Move CoGroupJoinITCase to windowing package,5
[FLINK-2674] Add Fold Window Operation for new Windowing API,1
"[FLINK-2561] [gelly] add gelly-scala examples: vertex-centric SSSP, GSA SSSPand how to use a library method (connected components).This closes #1211",1
[hotfix] Add ResultTypeQueryable to Keys in Stream CoGroup/Join,1
[FLINK-2381] [Storm Compatibility] Failing Test: WrapperSetupHelperTest,3
"[FLINK-2790] [yarn] [ha] Add high availability support for YarnThis squashes the following commits:- Refactor JobManager's start actors method to be reusable- Yarn refactoring to introduce yarn testing functionality- Add support for testing yarn cluster. Extracted JobManager's and TaskManager's testing messages into stackable traits.- Implement YarnHighAvailabilityITCase using Akka messages for synchronization.- Logging statements- Fix registration at JobManager when the leader address is null- Fix curator dependency conflict- Shades Flink's curator dependency in flink-runtime so that it cannot be overriden by external dependencies in the class path. This solves the problem with Hadoop 2.6.0 which adds Curator 2.6.0 to the class path. The curator version of this Hadoop version is not compatible to Flink's Curator version 2.8.0. Furthermore, Flink's Guava version is forced to be included in flink-shaded-curator jar to avoid to many different Guava version in the resulting dist jar.- Unify two shade executions of flink-runtime into one- Exclude log4j and slf4j-log4j12 dependency from flink-shaded-curator- Set default number of application attempts to 1 in standalone caseThis closes #1213",1
[FLINK-1789][core][runtime] Allow adding of URLs to the usercode class loaderThis closes #593.,1
[hotfix] Change result of WindowedStream ops to SingleOutputStreamOperator,1
[FLINK-2780] Remove Old Windowing Logic and APIThis rewrites the few examples and tests that are remaining using thenew Windowing API.,1
[FLINK-2550] Rename extractTimestmp() to assignTimestamps()This also changed TimestampExtractor.emitWatermark() toTimestampExtractor.extractWatermark().,4
[FLINK-2779] Update documentation to reflect new Stream/Window API,1
[FLINK-2831] [Storm Compatibility] Failing Test: WrapperSetupHelperTest,3
[hotfix] Fix wrong reference to WindowedDataStream in Doc,2
[FLINK-2576] Add outer join base operator.,1
"[FLINK-2576] [javaAPI] [scalaAPI] [optimizer] Add outerJoin to DataSet API (Java, Scala) and optimizer.This closes #1138",5
[FLINK-2576] [javaAPI] [scalaAPI] Restored binary compatibility for DataSet (inner) join.,5
[FLINK-2818] [docs] Correct javadocs of *ReduceDriver classes and some methods in the API.This closes #1224.,2
[FLINK-2613] [scala shell] Print usage information for Scala Shell  - Change startup code of scala shell  - User has to specify local or remote mode explicitly now.This closes #1106.,1
[FLINK-2156] [tests] Fix bug that some tests of Scala module cannot create log fileThis closes #1234.,2
[FLINK-2833] [gelly] create a flink-libraries module and move gelly thereThis closes #1241,4
[FLINK-2784] Remove deprecated configuration keys and updated documentationThis closes #1244,2
[FLINK-2730][webfrontend] Add cpu and memory usage graphsThis closes #1236.,1
Small update to Javadoc in IterativeDataset.closeWith to add missing param.,2
[hotfix] Add countWindow and countWindowAll shortcut,1
[docs] fix typo in Scala functions type descriptorsCloses #1253,1
[FLINK-2817] [streaming] FileMonitoring function logs on empty locationInstead of throwing NPE when location is emptyCloses #1251,2
[hotfix] Add default Trigger for GlobalWindowsThis also adds notes about possible non-parallelism for windowAllwindows.,1
"Change ""it's"" contraction to possession ""its""This closes #1256",4
[FLINK-2843] Add documentation for DataSet outer joins.This closes #1248,5
[FLINK-2479] Refactor runtime.operators.* testsThis closes #1160,3
[FLINK-2774] [scala shell] Extended default imports for ScalaShellThis closes #1247-- PRs closed due to inactivityThis closes #1077,2
[FLINK-2856] Introduce flink.version property into quickstart archetype,5
[hotfix] Correct name of HDFS tests from 'org.apache.flink.tachyon' to 'org.apache.flink.hdfstests',3
[hotfix] Remove remaning classes for old window triggers,4
[FLINK-2808] [streaming] Refactor and extend state backend abstraction,4
[FLINK-2550] [streaming] Make fast-path processing time windows fault tolerant,1
[FLINK-2550] [streaming] Rework JoinStreams and CoGroupStreams to properly implement operator builder syntax,1
[hotfix] [streaming] Initialize StreamingRuntimeContext to rich functions early,1
[hotfix] StreamTask and OperatorChain properly clean up partially initialized resources upon failures during initialization,5
[hotfix] [core] TypeExtractor correctly handles non-public types as generic types (rather than failing with an exception),0
[hotfix] Proper exception chaining in key/value state access of StreamingRuntimeContext,1
[FLINK-2846] [streaming] Emit downstream checkpoint barriers at beginning of the checkpoint scope,2
[FLINK-2550] [tests] Add an end-to-end failure/recovery test for fast path processing time windows,3
[hotfix] [tests] Make StreamTaskTimerTest more robust,3
[hotfix] [streaming scala] Expose key type information for key selectors on connected data streams,5
[FLINK-2550] [streaming] Allow multiple key/value states per operator on top of the new state backend,1
[hotfix] [streaming] Remove obsolete internal state handle classes,0
"[hotfix] [storm compatibility] Deactivate tests for split stream field grouping, which do not work in teh runtime and are now caught earlier",1
[FLINK-2855] [gelly] Add documentation for the Gelly library algorithms and improved javadocs for the library constructors.This closes #1258,2
[hotfix] Fix DataSet API programming guide,5
[FLINK-2863] [kafka connector] Kafka connector propagates async producer exceptions,2
[FLINK-2844] [web frontend] Remove old web interface- make new web one the default- adapt tests- make web directory a resource to be included in the fat jar- serve static files of web interface dynamic through the class loader- run on YARN- remove Jetty dependencies from poms,4
[FLINK-2844] [web frontend] Make web frontend URLs relative for YARN supportThis closes #1246,1
[hotfix] Removed broken dependency to flink-spargel.This closes #1259,2
[FLINK-2841] [docs] Correcting ML roadmap link to point to confluence.This closes #1254,5
[FLINK-2714] [gelly] Copy triangle counting logic from EnumTrianglesOpt.java to Gelly library.Also reorganizing classes to use Gelly's Graph APIs.,1
[FLINK-2714] [gelly] add the algorithm description in the gelly docs;update test to get the directed graph as inputThis closes #1250,1
[hotfix] Add debug output to (rarely) failing TimestampITCaseI'm adding this so that we have a bit more context when it fails nexttime.,0
"[FLINK-2611][yarn] do not fail application in shutdown hookThe application status is set to failed for jobs which did not completesuccessfully. If the client shuts down the YARN cluster, theapplications should be reported as SUCCESSFUL.",0
[FLINK-2731][web-dashboard] add access to JobManager stdout and logsThis closes #1233.,2
[FLINK-2844] remove old config entry from flink-conf.yaml,5
[FLINK-2809] [scala-api] Added UnitTypeInfo and UnitSerializer.This closes #1217,5
[FLINK-2725] Add Max/Min/Sum aggregation for mutable types.This closes #1191,1
[FLINK-2857] [gelly] Improve Gelly API and documentation.- Improve javadocs of Graph creation methods- Add fromTuple2 creation methods- Rename mapper parameters to vertexInitializer.- Improve javadocs and parameter names of joinWith* methods- Improve javadocs of neighborhood methods- Update docs to reflect api changesThis closes #1263,4
"[FLINK-2842] [documentation] Remove Flink S3FileSystem, extend documentation to use Hadoop S3FileSystem.This closes #1245",5
[FLINK-2107] Add hash-based strategies for left and right outer joins.This closes #1262,1
[FLINK-2652] [tests] Temporary ignore flakey PartitionRequestClientFactoryTest,3
"[FLINK-2792] [jobmanager, logging] Set actor message log level to TRACE",2
[FLINK-2354] [runtime] Add job graph and checkpoint recoveryThis closes #1153.,1
[FLINK-2354] [runtime] Remove state changing futures in JobManagerInternal actor states must only be modified within the actor thread.This avoids all the well-known issues coming with concurrency.Fix RemoveCachedJob by introducing RemoveJobFix JobManagerITCaseAdd removeJob which maintains the job in the SubmittedJobGraphStoreMake revokeLeadership not remove the jobs from the state backendFix shading problem with curator by hiding CuratorFramework in ChaosMonkeyITCase,1
[FLINK-2805] [blobmanager] Write JARs to file state backend for recoveryMove StateBackend enum to top level and org.apache.flink.runtime.stateAbstract blob store in blob server for recoveryThis closes #1227.,2
"[FLINK-2804] [runtime] Add blocking job submission support for HAThe JobClientActor is now repsonsible for receiving the JobStatus updates froma newly elected leader. It uses the LeaderRetrievalService to be notified aboutnew leaders. The actor can only be used to submit a single job to the JM. Onceit received a job from the Client it tries to send it to the current leader.If no leader is available, a connection timeout is triggered. If the job couldbe sent to the JM, a submission timeout is triggered if the JobClientActor doesnot receive a JobSubmitSuccess message within the timeout interval. If theconnection to the leader is lost after having submitted a job, a connectiontimeout is triggered if the JobClientActor cannot reconnect to another JM withinthe timeout interval. The JobClient simply awaits on the completion of thereturned future to the SubmitJobAndWait message.Added test cases for JobClientActor exceptionsThis closes #1249.",3
[FLINK-2793] [runtime-web] Redirect to leader in non-standalone modeSquashes:5a88d5e [tests] Add HttpTestClient for testing HTTP responses656d6d6 Split WebMonitor and LeaderRetrievalService start upa7e8da8 Move generated /web files to src/main/resourcesAdd comment to webMonitorPort attribute and make line breaks more ScalaesqueDon't block on leader retrieval and only resolve associated job manager onceMake JobManagerRetriever independent of redirecting logicThis closes #1202.,2
"[FLINK-2793] [runtime-web] Rework JobManagerRetriever to avoid race conditionsThe JobManagerRetriever sets the new leaderGatewayPortFuture directly in the notifyLeaderAddressmethod instead of in one of the futures. This avoids race conditions between multiple futureswhich finish in a different order than they were started. Furthermore, this replaces promisesby futures where a promise is not needed.Add logging statementFix WebRuntimeMonitorITCase to use random port and proper state backendAdd ChannelHandler.Sharable to RuntimeMonitorHandlerRemove sanity check from WebInfoServer to let it work on Yarn",1
"[FLINK-2852] [test-stability] Fix ScalaShellITSuite and ScalaShellLocalStartupITCaseChanges test program to use an int accumulator which is checked at the end of the program.This avoids to look for the ""Job status changed to FINISHED."" string in the stdout output,which can sometimes not be printed if the JobExecutionResult arrives earlier than theJobStatusChanged message at the JobClientActor.",4
"[FLINK-2354] [runtime] Replace old StateHandleProvider by StateStorageHelper in ZooKeeperStateHandleStoreThe old StateHandleProvider used in ZooKeeperStateHandleStore had to be replaced because the state backend implementation has changed. Since the new state backend could not be used anymore, a new StateStorageHelper interface has been created. The default implementation FileSystemStateStorageHelper stores the given state onto the specified file system and returns a FileSerializableStateHandle.Various fixes due to rebasing.",0
"[FLINK-2865] remove upper direct memory size bound- set the upper bound to Long.MAX_VALUEFor YARN, we set it to the calculated maximum container size (no need to fix).",0
[FLINK-2873] detect & serve the job manager log files correctly,2
"[FLINK-2864] Make State of General-Purpose Window Operators Fault-TolerantThis adds method state() on Trigger context that should be used tocreate an OperatorState to deal with fault-tolerant state.WindowAssigner now has a method getWindowSerializer() that is used toget a TypeSerializer for the Windows that it assigns. The Serializer forthe Key is retrieved from the input KeyedStream and the serializer forthe input elements is already available.During checkpointing all currently in-flight windows (per key, perwindow) are serialized using the TypeSerializers. The state that isaccessible in Triggers using state() is kept in aHashMap<String, Serializable>, this is serialized using javaserialization.",1
Replace Trigger.onTime by Trigger.onProcessingTime/onEventTimeThis also renames WatermarkTrigger to EventTimeTrigger andContinuousWatermarkTrigger to ContinuousEventTimeTrigger.,1
[FLINK-2872] [Documentation] Update the documentation for Scala part to add ExecutionEnvironment.readFileOfPrimitives.Add the missing Scala part for ExecutionEnvironment.readFileOfPrimitives API doc in theprogramming guide.Author: Henry Saputra <hsaputra@apache.org>Closes #1268 from hsaputra/add_readFileOfPrimitives_scala_guide and squashes the following commits:f543436 [Henry Saputra] Add variant of ExecutionEnvironment.readFileOfPrimitives in Java with additional delimiter.1209019 [Henry Saputra] [FLINK-2872] [Documentation] Update the documentation for Scala part to add readFileOfPrimitives.,2
[FLINK-2885][python] fix path building of Python resources,0
[FLINK-2877] Move Streaming API out of Staging package,4
"[hotfix] Add shortcuts for creating Time objectsThis adds Time.milliseconds(), Time.seconds(), and so on.",1
[FLINK-2743] Add XORShfitRandom and use it in RandomSamplers.This closes #1170,1
[docs] Fix documentation for building Flink with Scala 2.11 or 2.10This closes #1260,2
"[FLINK-2834] Global round-robin for temporary directoriesMultiple TaskManager filesystems can be used by configuring multiple temporary directories.This patch changes the process of spilling files from a per-operator round-robin to a globalround-robin such that each directory is written to in turn across all operators, reducingunbalanced I/O due to bunching.This closes #1272",1
[FLINK-2880] [streaming] Allow DeserializationSchema to forward exceptions.This closes #1275,1
[FLINK-2876] MinutiaeA collection of small documentation and grammar updates.This closes #1277,5
[FLINK-2820] Configuration not passed to JobGraphGeneratorThis was previously reported as FLINK-2625 (commit 8a84937215ea575fa94a00d11c2517902d252756).The Client class was concurrently refactored with FLINK-2097 (commit 71bf2f570861daae53b24bfcf1d06aedb85311b9).This closes #1278,5
[FLINK-2886] [runtime] Fix config key for number of threads in NettyClient,5
"[FLINK-2878] [webmonitor] Fix unexpected leader address patternThe HandlerRedirectUtils.getRedirectAddress decides whether the retrieved leader address is equal to the local job manager address. The local job manager address is, however, in the form akka.tcp://flink@url/user/jobmanager whereas the leader address can be akka://flink/user/jobmanager if the local job manager is the current leader. Such a case produced a warning which is not correct. This PR checks for the local job manager address and signals that no redirection has to be done if it receives akka://flink/user/jobmanager.Add test for HandlerRedirectUtilsThis closes #1280.",0
"[contrib, tests] Disable sys out logging in operator stats tests",3
[hotfix] Fix shaky EventTimeAllWindowCheckpointITCaseIn very rare cases it could happen that a checkpoint would be performedafter the ValidatingSink signaled that it had seen all expectedelements. If this happened the job would be restarted with the alreadycomplete state and we would never finish since no more elements wouldarrive.This adds a check in open() of ValidatingSink that signals success if wealready have the final state.,5
[tools] update release script- create Scala 2.11 binaries- remove Java 6 specific checks- cleanupTested for 0.10.0-rc0,3
[FLINK-2887] [gelly] make sendMessageToAllNeighbors respect the EdgeDirection if set in the configurationThis closes #1281,5
"[FLINK-2891] Set KV-State key upon Window Evaluation in General WindowsBefore, this was not set, leading to incorrect results if KV-State wasused in the WindowFunction.This also adds a test.",3
"[FLINK-2206] [webui] Fix incorrect counts of finished, canceled, and failed jobs in new web dashboardThis closes #1287",1
[FLINK-2668] [DataSet] [api-breaking] Chained Projections are no longer appendedThis closes #1279,4
[FLINK-2874] Fix Avro getter/setter recognitionThis closes #1252,1
[FLINK-2874] Fix recognition of Scala default setters,1
[hotfix] Fix processing time triggering on Window OperatorBefore it would only trigger if expectedTime < time. Now it isexpectedTime <= time.,1
[release] update version to 1.0-SNAPSHOT0.10-SNAPSHOT continues on branch release-0.10,5
[release] change quickstart and docs version to 1.0-SNAPSHOT,2
[FLINK-1982] [record-api] Remove dependencies on Record API from flink-runtime testsRename Match*Test to Join*Test and MapTaskTest to FlatMapTaskTestThis closes #1294,3
[FLINK-2893] [runtime] Consistent naming of recovery config parametersRename config key prefix from 'ha.zookeeper' to 'recovery.zookeeper'Rename config key from 'state.backend.fs.dir.recovery' => 'state.backend.fs.recoverydir'Move ZooKeeper file system state backend configuration keysThis closes #1286,5
[FLINK-2898] [build] Invert Travis CI build orderThis closes #1290,2
[FLINK-2895] Duplicate immutable object creationOperators defer object creation when object reuse is disabled.This closes #1288,1
Add copy() to Tuple base class.,1
"[hotfix] Fix broken copy in OperatorChainBefore, the StreamRecords was not copied, now it is.",1
[hotfix] Fix Mutable Object window aggregator/Disable Object CopyThis fixes the aggregators to make copies of the objects so that itworks with window operators that are not mutable-object safe.This also disables object copy in WindowOperator andNonKeyedWindowOperator.,1
[hotfix] Add Window Parameter in Trigger.onEventTime/onProcessingTimeBefore these trigger methods had no information about the window thatthey are responsible for. This information might be required forimplementing more advanced trigger behaviour.,1
[docs] add information on how to use Kerberos,1
[FLINK-2862] [Storm Compatibility] FlinkTopologyBuilder should use proper generic typesThis closes #1274,1
[FLINK-2866] [runtime] Eagerly close FSDataInputStream in file state handleThis closes #1282,0
[FLINK-2888] [streaming] State backends return copies of the default values,2
[FLINK-2891] [streaming] Set keys for key/value state in window evaluation of fast-path windows.,1
[FLINK-2411] [gelly] Add Summarization Algorithm* implemented algorithm* implemented integration tests* updated gelly guideThis closes #1269,5
[FLINK-2890] Port StringSerializationSpeedBenchmark to JMH.[FLINK-2889] Port LongSerializationSpeedBenchmark to JMH.This closes #1284This closes #1283,5
[FLINK-2853] Port MutableHashTablePerformanceBenchmark to JMH.This closes #1267,2
[FLINK-2919] Port FieldAccessMinibenchmark to JMH.This closes #1300,5
[FLINK-2827] Close FileInputStream through try-with-resources to avoid unused open stream.This closes #1276,1
[hotfix] Fix issue with spaces in Path in start-*-streaming.sh,0
[release] fix remaining and recently introduced old version artifacts,5
[release][scripts] replace quickstart archetype version,5
"Add org.apache.httpcomponents:(httpcore, httpclient) to dependency managementThis closes #1301.",1
[FLINK-2927] [runtime] Provide default required configuration keys in flink-conf of binary distributionThis closes #1303.,5
[release][scripts] automate changing of docs version,2
[release][scripts] use perl instead of sed for portability,1
[scala-shell][docs] add scala sources in earlier phaseOtherwise the javadoc fails to generate..,0
[FLINK-1610][docs] fix javadoc building for aggregate-scaladoc profile,2
"[FLINK-2800] [kryo] Fix Kryo serialization to clear buffered dataThe Kryo serializer uses Kryo's Output class to buffer individual write operations beforeit is written to the underlying output stream. This Output class is flushed by Flink'sKryoSerializer upon finishing its serialize call. However, in case of an exception whenflushing the Output, the buffered data is kept in the buffer. Since Flink uses EOFExceptionsto mark that an underlying buffer is full and has to be spilled, for example, it can happenthat the record triggering the spilling is written twice after it is rewritten. The reasonis that Kryo's Output buffer still contains the serialization data of the failed attempt whichis also flushed to the emptied output stream.This duplication of records can lead to corrupted data which eventually let's the Flink programcrash. The problem is solved by clearing Kryo's Output when the flush operation was not successful.This closes #1308",0
[FLINK-2869] [tests] Port IOManagerPerformanceBenchmark to JMH.This closes #1270.,3
[FLINK-2920] [tests] Port KryoVersusAvroMinibenchmark to JMH.This closes #1302,5
[FLINK-2900] [hadoop-compat] Remove Record API code from Hadoop Compat moduleThis closes #1293,4
[FLINK-2932] Examples in docs now download shell script using https instead of httpThis closes #1309,1
"[FLINK-2559] Clean up JavaDocs- Remove broken HTML tags like <br/>, <p/>, ...- close unclosed HTML tags- replaces special chars by HTML escaping, e.g., '<' by &lt;- wrap code examples by {@code}- fix incorrect @see and @link references- fix incorrect @throws- fix typosThis closes #1298",2
"[FLINK-2934] Remove placeholder pages for job.statistics, taskmanager.log and taskmanager.stdoutThis closes #1307",2
"[FLINK-2902][web-dashboard] Sort finished jobs by their end time, running jobs by start timeThis closes #1296",1
[release][scripts] shade away curator correctly with different Scala versions,5
[streaming] delegate JobGraph generation to Client class,5
"[checkstyle] link suppressions file in checkstyle file- This ensures Checkstyle works properly, e.g. in IDEs",1
[tez] remove unused hash variable- Prevents crashing of IntelliJ Checkstyle plugin,1
[travis] remove javadoc skip- skip was only necessary because Java 8 couldn't build the java docs,2
[FLINK-2912] [web-runtime-web] Add comment to StaticFileServerHandler,2
remove flink-benchmark due to licensing issues,0
[hotfix] remove Special LICENSE/NOTICE for binary releaseThis closes #1316.,1
[FLINK-2953] fix chaining of sortPartition() calls in Scala DataSet API- Added tests for Scala DataSet sortPartitionThis closes #1317.,5
[FLINK-2939] add cancel button to web frontendThis closes #1313.,1
[web-frontend] Fix README to to reflect the latest changes,4
[hotfix] Add list_deps.py toolThe tool can be used to list the set of dependencies to make a diffof dependencies between releases.,1
"[hotfix,doc] Fix link to coding guidelines, again",2
[release][scripts] deploy Scala 2.11 version to Maven,5
[docker] move the #!bash to first lineThis closes #1314.,4
[FLINK-2930] Respect ExecutionConfig execution retry delay- fix hard-coded defaultsThis closes #1304.,0
[FLINK-2958] Remove hard coded number of execution retries,4
[FLINK-2918] [api-extending] Add methods to read Hadoop SequenceFiles.This closes #1299,2
"[FLINK-2964] [runtime] Fix broken spilling of MutableHashTableThe HashPartition did not count properly the number of occupied memorysegments, because it excluded the memory segments of theBuildSideBuffer. That caused the MutableHashTable to fail when trying tospill a partition which did not have any overflow segments. This PRfixes the problem by also counting the memory segments of theBuildSideBuffer.This closes #1324.",0
[FLINK-2943][web-dashboard] Rename bytes/records read/written to received/sent.[hotfix][web-dashboard] Fix taskmanager charts legend.This closes #1323,2
[FLINK-2903][web-dashboard] Format numeric values of received/sent counters.This closes #1326,2
[FLINK-2898] Adopt deploy to maven script to new build order,1
"[FLINK-2968] [streaming] Let AbstractUdfStreamOperator forward output type information to WindowFunctionThe fold operation needs the output type information to serialize theinitial value of it. Therefore, the OutputTypeConfigurable interface wasdefined. It is called by the StreamGraph upon adding a StreamOperator tothe StreamGraph. Since some stream operators, such as the window streamoperator, don't work directly on the data, but instead call aWindowFunction for the actual logic, the output type information has tobe forwarded to this function to set output type information at theright place.Thus, the AbstractUdfStreamOperator checks whether its udf functionsupports the OutputTypeConfigurable interface. If this is the case, thenit forwards the output type information to the udf.This closes #1328.",5
[release][scripts] fix typo in release script,2
[FLINK-2957][web-dashboard] Improve the appearance of cancel buttonThis closes #1319.,1
[FLINK-2938] [docs] Update docs for key/value state,2
[doc] fix spelling mistakes in the transformations guideThis closes #1333,0
[FLINK-2951] [Table API] add union operator to Table API.This closes #1315.,1
[FLINK-2981] [docs] update requirements in docs/README* added libraries and versionsThis closes #1335.,1
[docs] Fix typos in streaming documentation,2
"[FLINK-2979] Fix RollingSink truncate for Hadoop 2.7The problem was, that truncate is asynchronous and the RollingSink wasnot taking this into account.Now it has a loop after the truncate call that waits until the file isactually truncated.This also changes the Hadoop 2.6 travis build to 2.7, instead.",4
[FLINK-2986] Fix typo in KvState interface snapshot method,2
[FLINK-2752] Documentation is not easily differentiable from the Flink homepage - added auto-redirect for coding_guidelines and how_to_contribute pages (to keep external links working) - updated menu links to point directly to coding_guidelines and how_to_contribute on Flink project page(only improvement on FLINK-2752; does not resolve it)This closes #1320,0
[FLINK-2905] [gelly] Add Graph Intersection methodThis closes #1329,1
[FLINK-2730] remove Apache License incompatible chart library,2
[FLINK-2982][cli] Fix to show streaming plans via info option.This closes #1334.,5
[FLINK-2990] Fix Flink on YARN for Scala 2.11,2
[FLINK-2987] Remove jersey-core and jersey-client dependency exclusion to make Flink on Hadoop 2.6.0+ workThis closes #1340,1
[hotfix] Check for null in StreamSource.cancel(),0
[FLINK-2992] Remove use of SerializationUtilsThis closes #1343,1
[FLINK-2966][web-dashboard] Improve the way job duration is reportedThis closes #1327.,1
[hotfix] [tests] Fix manual tests to properly start testing cluster.,3
[hotfix] [tests] Tests in flink-tests suppress log output by default,2
"[hotfix] Remove DEPENDENCIES file.Previously, this fiel pointed to the different versions of the LICENSEand NOTICE files (source version, bin version). Since we dropped theconvenience binary distribution LICENSE and NOTICE files and only ship thesource release related ones, this is no longer necessary.",2
[dist] Bring LICENSE file up to speed,2
[misc] Minor fixed to config docs and minor code cleanups in Client,4
"[FLINK-2994] [client] Report error cause when jobs switch to failing.For jobs that do not switch to FAILED, but rather RESTARTING, this now prints the error causeas well. Also minor improvement to exception printing in CliFrontend.",1
[FLINK-2826] [runtime] Fix race condition and locking in BroadcastVariableMaterialization#decrementReferenceInternalThis closes #1339,0
"[license] remove flink-benchmark due to licensing issuesIn addition to dd66e61ecc5da5b15a610f04b98c8386d141f910,removes the left-over source files.",2
[FLINK-2901] Move PythonAPI to flink-librariesThis closes #1257,2
[Documanation] Fix constructor name of WordWithCount example.This closes #1325,0
[docs] Update HA docs with YARN and state backend configuration,5
[FLINK-2432] Custom serializer supportThis closes #962,1
[FLINK-2797][cli] Add support for running jobs in detached mode from CLIThis closes #1214.,1
"[FLINK-2850] Limit the types of jobs which can run in detached modeThis disallows the following types of interactive programs in detachedmode:1. More than one call to execute2. Accessing job execution results likeaccumulators, net runtime, etc. This effectively disables eagerexecution functions such as count, print, collect, etc. too",1
[FLINK-2994] minor correction for newlines,1
[FLINK-3017] [Docu] Fix broken 'Slots' link on Streaming Guide.This closes #1357,2
[FLINK-2977] Using reflection to load HBase Kerberos tokensThis closes #1342,1
FLINK-3022: Broken link 'Working With State' in Fault Tolerance Section of Stream Programming Guide,1
[FLINK-3024] Fix TimestampExtractor.getCurrentWatermark() BehaviourPreviously the internal currentWatermark would be updated even if thevalue returned from getCurrentWatermark was lower than the currentwatermark.This can lead to problems with chaining because the watermark isdirectly forwarded without going through the watermark logic thatensures correct behaviour (monotonically increasing).This adds a test that verifies that the timestamp extractor does notemit decreasing watermarks.,4
[FLINK-3025] [kafka consumer] Bump transitive ZkClient dependency to 0.7 for bugfixesThis closes #1365,0
"[hotfix] [utils] Change the parameter 'numSample' in DataSetUtils.sampleWithSize() to 'numSamples', remove redundant Java 6 codeThis closes #1362",4
[hotfix] [runtime] Minor javadoc fix in JobManagerThis closes #1358JobExecutionVertices should be ExecutionJobVertices?I found it while I have been drawing a Flink local execution diagram.It is still a half way but let me know if you have any feedback.https://docs.google.com/drawings/d/1lZg8LkhAlI5lMc2EGCPlYArBmv7cCj-By-phuG6rGE8/edit,5
[FLINK-2914] [runtime] Add missing break Statement in ZKJobGraphStoreThis closes #1359,4
[FLINK-2879] [docs] Fixed broken links on the architecture pageThis closes #1348,1
"[FLINK-2967] Increase timeout for LOCAL_HOST address detection strategy, give the local host address a higher priorityThis closes #1391",1
[hotfix][docs] Replace Count.of() with appropriate Count(Trigger|Evictor).of(),2
[FLINK-2441] Introduce Python OperationInfoThis closes #1352.,5
[FLINK-3013] [gelly] Incorrect package declaration in GellyScalaAPICompletenessTest.scalaThis closes #1356.,3
"[FLINK-3036] [gelly] Fix Graph.fromCsvReader method in Gelly's Scala APIThe Graph.fromCsvReader in Gelly's Scala API returns a wrongly typed Graph instance becausethe implementation contains code paths with return types which are not compatible. Thislead to a bad user experience.This commit fixes this. However, it also introduces a slightly different behaviour and isthus API breaking. Before there were parameters hasEdgeValues and readVertices whichcontrolled whether edge values and vertices shall be read. This is now implicitly controlledby the types of the vertex and edge value. If the type is NullValue for the edge values thenthe edge value won't be read from the given csv file. If the vertex value type is NullValue,then all vertices will have a value of a NullValue instance. If the pathVertices is notspecified and the vertex value type is unequal to NullValue, then the vertexValueInitializeris used for the initialization.Add documentation for Gelly's Scala API method Graph.fromCsvReaderThis closes #1370.",2
[doc] Fix JavaDoc of ElasticsearchSinkThis closes #1367.,2
[FLINK-2233] Update InputF nextRecord javadocsThis closes #2233.,2
[FLINK-2937] Fix Typo in Scala Quickstart Guide (SBT)This closes #1373,2
"[FLINK-2989] job cancel button doesn't work on YARNIn addition to the REST-compliant ""DELETE /jobs/<jobid>"", allowscancellation also via a special GET request of the form""GET /jobs/<jobid>/yarn-cancel"".That enables us to cancel jobs from the web frontend on YARN whilekeeping a REST-compliant DELETE alternative.This closes #1344.",4
[FLINK-2942] [web dashboard] Fix dangling operators in dataflow visualizationThis closes #1346,5
[FLINK-2692] Untangle CsvInputFormatThis closes #1266,2
[travis] use new artifacts tool to upload snapshot binaries- replace deprecated tool which prevents uploading of snapshot binaries- remove Java 6 jar check,4
[FLINK-2955] [Documentation] Add operators description in Table API page.,1
[hotfix] [streaming] Fix instantiation of state backends from state backend factory.,0
[FLINK-3040] [docs] Add docs for State Backends,2
[hotfix] Fix concurrent processing-time Trigger in WindowOperatorThis fixes a problem that would occur if a Trigger registers a newprocessing-time trigger in the onProcessingTime method. The problem isthat onProcessingTime() is called while traversing the set of activetriggers. If onProcessingTime() tries to register a new processing-timetrigger this leads to a concurrent modification exception.,1
[docs] Add note about Znode root config for HA setups,1
[FLINK-1945][py] Python Tests less verboseThis closes #1376,1
FLINK-3041: Twitter Streaming Description section of Streaming Programming guide refers to an incorrect example 'TwitterLocal'This closes #1379.,2
[docs] remove snapshot information from front page,5
[travis] correct target path of uploaded snapshot artifact,1
"[FLINK-3002] Add Either type, EitherTypeInfo, and EitherSerializer to the Java APIThis closes #1371",5
[FLINK-3005] [core] Bump commons-collections version to fix object deserialization remote command execution vulnerabilityThis closes #1381,0
[FLINK-3043] [docs] Fix description of Kafka Consumer and Producer.This also adds to the deprecated classes pointers forward to the designated classes.This closes #1380,1
[FLINK-2913] [runtime] Ensure file streams are properly closes in FsStateBackendThis closes #1353,2
[FLINK-3048] [tests] Increase stability of DataSinkTaskTest,5
"[FLINK-3032] Fix jackson-core dependency conflict with Hadoop 2.7.1.This commit is also changing how we build the ""flink-shaded-hadoop"" artifact.In the past, we were including all Hadoop dependencies into a fat jar, without relocating all of them.Maven was not able to see Hadoop's dependencies and classes ended up in the classpath multiple times.With this change, only shaded Hadoop dependencies are included into the jar. The shade plugin will alsoremove only the shaded dependencies from the pom file.",2
[FLINK-3011] [runtime] Disallow ExecutionGraph state transition from FAILED to RESTARTINGRemoves the possibility to go from FAILED state back to RESTARTING. This was only used in a testcase. It was a breaking the terminal state semantics of the FAILED state.,0
"[FLINK-3011] [runtime, tests] Translate ExecutionGraphRestartTest to Java",3
[FLINK-3011] [runtime] Fix cancel during restart,0
[FLINK-3019] [client] List restarting jobs with scheduled jobs,2
[FLINK-3028] [runtime-web] Show cancel button for restarting jobsThis closes #1369,1
[hotfix] [core] Fix assignment of strictly local splits to host instancesThis closes #1345,0
[hotfix] [docs] Fix errors in streaming docs for fold(),2
"[FLINK-3021] Fix class loading issue for streaming sourcesStreaming sources were directly assigned their InputFormat in the StreamingJobGraphGenerator. As a consequence, the input formats were directly serialized/deserialized by Akka when the JobGraph was sent to the JobManager. In cases where the user provided a custom input format or an input format with custom types, this could lead to a ClassDefNotFoundException, because the system class loader instead of the user code class loader is used by Akka for the deserialization.The problem was fixed by wrapping the InputFormat into a UserCodeObjectWrapper which is shipped ot the JobManager via the JobVertex's configuration. By instantiating stream sources as InputFormatVertices, the corresponding InputFormat is retrieved from the Configuration in the initializeOnMaster method call.This closes #1368.",5
"[FLINK-3052] [optimizer] Fix instantiation of bulk iteration candidatesWhen a candidate for a bulk iteration is instantiated, then the optimizer creates candidatesfor the step function. It is then checked that there exists a candidate solution for the stepfunction whose properties met the properties of the input to the bulk iteration. Sometimesit is necessary to add a no-op plan node to the end of the step function to generate thecorrect properties. These new candidates have to be added to the final set of the acceptedcandidates.This commit adds that these new candidates are properly added to the set of accepted candidates.Fix test and add new iteration testsAdd predecessor operator and dynamic path information to no op operator in bulk iterationsThis closes #1388.",1
[FLINK-2974] Add periodic offset committer for Kafka when checkpointing is disabledThis closes #1341,1
[doc] Fix Documentation formatting for recently added ExecutionEnvironment.readSequenceFile()This closes #1389.,2
[FLINK-2860] [ml] [docs] Remove an undefined argument in FlinkML documentationThis closes #1310.,2
"[FLINK-3009] Add dockerized jekyll environmentThis is not to fulfill what FLINK-3009 is originally asking,but I'm piggybacking to contribute a docker environment with jekyllso that users won't have to deal with environment versions.Author: Jun Aoki <jaoki@apache.org>Author: jaoki <jaoki@apache.org>Closes #1363 from jaoki/dockerized-docgen and squashes the following commits:7bf3661 [Jun Aoki] Added apache label36869e7 [jaoki] [FLINK-3009] Add dockerized jekyll environment",2
"[hotfix][docs] Fix default config value, highlight detail in config",5
"[FLINK-2429] [streaming] Deprecate the ""enableCheckpointing()"" method with no interval argument.This closes #1382",0
[FLINK-2947] [scala shell] Add color support to Scala Shell,1
"[FLINK-2017] Add predefined required parameters to ParameterTool- Add RequiredParameters class to handle required parameters in UDFs which can be checked  and validated against the parameters extracted in ParameterTool- A required parameter is represented by an Option which has by default only a name and can  be extended to include possible values, a type, a default value- Any validation failure will throw a RequiredParametersExceptionThis closes #1097",2
[FLINK-3020][streaming] set number of task slots to maximum parallelism in local executionThis closes #1360.,1
[FLINK-2916] [streaming] Expose operator and task information to StateBackend,5
[FLINK-2924] [streaming] Out-of-core state backend for JDBC databases,5
[FLINK-2924] [streaming] Improved sharding logic,2
[FLINK-2924] [streaming] Use timestamps to store checkpoints so it supports job shutdown/restart,1
[FLINK-2924] [streaming] Improve compacting logic,2
[FLINK-2924] [streaming] Use short job id for table names,1
[FLINK-2924] [streaming] Execute compactions in background thread + keep connections alive on empty snapshotsCloses #1305,2
[FLINK-2956] [tests] Migrate integration tests for Table API,3
[FLINK-3045] Properly expose the key of a Kafka messageThis closes #1385,1
[FLINK-2861] Fields grouping on split streams failsThis closes #1387,0
"[docs, setup] Add note about (task|job)manager scripts",1
[FLINK-3070] Add AsynchronousStateHandleThis extends StateHandle with a materialize() method. The asynchronoushandle represents state and can materialize it when required.,1
[hotfix] fix shaded reference,0
"[docs, setup] Add missing parenthesis",1
"[streaming] [ml] Code cleanup: unused imports, fix javadocsThis closes #1391.",2
[FLINK-3064] [core] Add size check in GroupReduceOperatorBaseThis closes #1396.,1
[FLINK-2996] Introduce configuration parameter for BlobServer portThis closes #1394,2
Remove Record API program tests,3
Remove ITCases for Record API operators,1
Move operator ITCases into correct package,1
Remove Record API dependencies from CC iteration tests,3
Remove Record API dependencies from WordCount compiler test,3
Remove deprecation warning suppressions,2
[FLINK-2901] Remove Record API dependencies from flink-tests #1,3
[FLINK-2901] Remove Record API dependencies from flink-tests #2This closes #1306,3
[FLINK-2686] Show exchange mode in JSON planThis closes #1378,5
[FLINK-2318] Union can be used as BroadcastVariableThis closes #1390,1
[FLINK-3072] [streaming] Ensure Derby server starts before running any testsCloses #1401,3
[FLINK-3000] Adds shutdown hook to clean up lingering yarn sessionsThis closes #1354,4
[hotfix] Register signal handler for JobManager and TaskManagerThis closes #1400,0
[FLINK-3067] Enforce zkclient 0.7 for KafkaThis closes #1399,1
"[github] change tab size to 4 spacesThe default tab size on GitHub is 8 spaces. This change decreases thetab size to 4. I think this will make reviewing of code on GitHubmuch easier.This commit also introduces sensible defaults for editors which respectthe "".editorconfig"" file standard.This closes #1404.",2
"[docs][streaming] fix code examples which use 'implements'- replace ""implements"" with ""extends"" where applicable",1
[FLINK-2906] Remove Record APIThis closes #1403,4
"[FLINK-3059] Improve JavaDocs for DataSet.writeAsText()Currently the JavaDocs of writeAsText() state it simply generates a file,but this is not always true and it depends on the environment configuration.This commit improves the JavaDocs of writeAsText().This closes #1392",2
[typo-fix] Fix typo in DelimitedInputFormat.javaThis closes #1405,2
[docs][hotfix] Fix wrong window definitions in the docsThis closes #1407,2
[hotfix] Java-7-ify the ExecutionConfig class,5
[FLINK-3051] [streaming] Add mechanisms to control the maximum number of concurrent checkpointsThis closes #1408,1
[FLINK-3082] Fixed confusing error about an interface that no longer existsThis closes #1411,0
"[FLINK-3085] [runtime] Initialize state backends as part of ""invoke()""",5
[hofix] Properly set state backend from execution environment to stream graph,1
[FLINK-3046] Integrate the Either Java type with the TypeExtractorThis closes #1393.,4
[tools] add more defaults to .editorconfigThe tab default also applied to Scala files which could lead to editingproblems in IntelliJ.,2
[FLINK-3054] Remove R (return) type variable from SerializationSchemaThis closes #1406,4
[hotfix] Fix SimpleStringSchema serialization issue,0
[FLINK-3081] Properly stop periodic Kafka committerThis closes #1410,2
[FLINK-2961] [table] Add support for basic type Date in Table APIFix nullCheck enabledFix testTableConfig introducedImprovements and bug fixingThis closes #1322.,0
[FLINK-3075] Change Either creation method names and expose Right/Left classesCloses #1402,1
[FLINK-3061] Properly fail Kafka Consumer if broker is not availableThis closes #1395,0
"[FLINK-3088] [serialization] Fix copy method of TypeSerializer which use KryoSome TypeSerializer, WritableSerializer, ValueSerializer, and AvroSerializer, andcomparators, WritableComparator and ValueComparator, use Kryo to copy records.In case where the Kryo serializer cannot copy the record, the copy method fails.This is however not necessary, because one can copy the element by serializingthe record to a byte array and deserializing it from this array. This PR addsthis behaviour to the respective classes.Adds KryoUtils tool with copy method to avoid code duplicationThis closes #1415.Adds comments to KryoUtils functions",1
[tests] Activate ChaosMonkeyITCase,3
[FLINK-3083] [docs] Add docs on how to configure streaming fault tolerance.This closes #1413,5
[FLINK-2904] [web-dashboard] Fix truncation of task counts when the number is large.This closes #1321,1
[FLINK-2351] [core] Remove IOFormat ConfigBuildersThis closes #1420,5
"[FLINK-3056] [web-dashboard] Represent bytes in more readable form.Bytes are now displayed in the following fashion:  1. For [0, 1000) units, display three significant digits.  2. For [1000,1024) units, display 2 decimal points for the next higher unit.For example, 1010 KB is displayed as 0.99 MB, 10 MB is displayed as 10.0 MB and 230 MB is displayed as such.This closes #1419",2
[FLINK-2950] [ml] [docs] Fix markdown rendering problem in SVM documentation  - Remove unnecessary indentation of table  - Fix wrong `strong` end tag  - Simplify lambda expression in map operationThis closes #1312,0
[FLINK-2972] [JavaAPI] Remove Chill dependency from flink-java.This closes #1331,2
[FLINK-3084] [streaming] FsStateBackend backs up very small state directly with the metadata.This closes #1423,5
[hotfix] Declare env and insertStatement transient in DbStateBackend,5
[FLINK-3092] [docs] Fix Scala API quick start word count exampleThis closes #1424.,0
[tests] Decrease verbosity of ChaosMonkeyITCase,3
[FLINK-2624] RabbitMQSource uses MessageAcknowledgingSourceBase,1
[FLINK-2624] improvements to the RabbitMQ sourceThe RabbitMQ source may operate in three different modes:1) Exactly-once (when checkpointed) with RabbitMQ transactions and messages with   unique correlation IDs.2) At-least-once (when checkpointed) with RabbitMQ transactions but no   deduplication mechanism (correlation id is not set).3) No strong delivery guarantees (without checkpointing) with RabbitMQ   auto-commit mode.- add base class which can handle both session ids and unique ids  - session ids are used for acknowledgment  - unique ids are used for de-duplication- add unit test- add documentationThis closes #1243.,2
[FLINK-3087] [Table API] support multi count in aggregation.,1
[FLINK-2837][storm] various improvements for the compatibility layer- refactor to use Storm's topology builder- remove FlinkTopologyBuilder- instantiate context-based StreamExecutionEnvironment (local or remote)- remove some of the Flink and Storm behavior replicating classes- modify FlinkTopology to parse Storm topology directly- replace StormTestBase with StreamingTestBase- add print example- FlinkTopologyBuilder changes (check if all inputs are available before processing)- correct package typo- two input support- add join example- update docsThis closes #1398.,2
[FLINK-2115] [Table API] support no aggregation after groupBy.,1
"[FLINK-3080] Relax restrictions of DataStream.union()Before, it would not allow unioning with predecessors (also transitive)and streams of differing parallelism.",1
[FLINK-3071] Add asynchronous state materialization threadThis also adds a test for asynchronous state handles.,0
[FLINK-2440][py] Expand Environment feature coverageThis closes #1383,3
[FLINK-3100] signal handler prints error on normal shutdown of cluster,0
[hotfix] [tests] Temporarily ignore ChaosMonkeyITCase,3
[FLINK-3096] Retry cleaned checkpoint directory check,4
[FLINK-3098] [Table API] Cast Data to Long throw compile error.This closes #1431.,0
[FLINK-2954] Add config parameter for passing environment variables to YARNThis closes #1409,4
[docs] Add import statements to DataStream example programs (Java/Scala)New users sometimes struggle with the imports (especially for Scala API).,2
"[docs] Fix TumblingTimeWindows.of(AbstractTime) examplesAdded Time.of(Time), because there is no TumblingTimeWindows.of(int, TimeUnit).",1
[FLINK-3125] [web dashboard] Web server starts also when JobManager log files cannot be accessed.,2
"[FLINK-3055] [runtime] Remove redundant version of ""Executionvertex.getSubTaskIndex()""This closes #1438",1
[hotfix] Minor JobManager doc fixThis closes #1430It seems AbstractJobVertex class no longer exists but the doc's link still points to it.,2
[docker-flink] Bumped the docker container to the latest version.This closes #1366,3
[FLINK-2488] [FLINK-2524] [FLINK-3124] Expose Attempt Number in RuntimeContext and add TaskInfo to hold all task related parameters.This closes #1386,2
[FLINK-2963] Forbid commons lang 3 SerializationUtils as well,2
[FLINK-2897] [runtime] Use distinct initial indices for OutputEmitter round-robinThis closes #1292,5
[FLINK-1278] [runtime] Remove record emitter special code paths for deprecated Record API,4
[FLINK-3112] Remove unused RecordModelPostPass and replace JavaPlan by Plan.This closes #1436,4
[FLINK-3113] Remove unused and unsupported global-order methods from GenericDataSinkBaseThis closes #1435,5
[FLINK-3108] [java] JoinOperator's with() calls the wrong TypeExtractor methodThis closes #1440,4
[FLINK-3102] Allow reading from multiple topics with one FlinkKafkaConsumer instanceThis closes #1437,2
[FLINK-3136] Fix shaded imports in ClosureCleaner.scala,4
"[FLINK-3073] Replace Streaming Mode by Memory Allocation ModeBefore, streaming mode (either batch or streaming) would specify howmemory is allocated on task managers.This introduces a new configuration value taskmanager.memory.allocationthat can take values ""lazy"" or ""eager"". This controls how memory isallocated.",5
[FLINK-3155][docker] update Flink version to 0.10.1This closes #1443.,2
[FLINK-3143] update Closure Cleaner's ASM references to ASM5- This solves errors with reflectasm using Scala 2.11 and Java 8This closes #1445.,1
[FLINK-3145][storm] pin Kryo version of transitive dependenciesThis closes #1441.,2
[Storm Compatibility] Updated README.md and documenation,2
[FLINK-3074] Add config option to start YARN AM on port rangeThis closes #1416,1
[FLINK-3156] Fix NPE in KafkaConsumer when reading from SOME empty topics/partitions,0
"[FLINK-2936] Fix ClassCastException for Event-Time sourceBefore, would throw a ClassCastException when emitting watermarks withtimestamp/watermark multiplexing disabled.",0
"[FLINK-3121] Emit Final Watermark in Kafka SourceKafka sources that don't read from any partition never emit a watermark,thereby blocking the progress of event-time in downstream operations.This changes the Kafka Source to emit a Long.MAX_VALUE watermark if itknows that it will never receive data.This also changes the Timestamp Extraction operator to reacto to aLong.MAX_VALUE watermark by itself emitting a Long.MAX_VALUE watermark.",1
[FLINK-3023][web-dashboard] Display version and commit information on Overview Page.This closes #1422,5
"[FLINK-3077][cli] Add version option(-v, --version) to Cli.This closes #1418",1
[FLINK-2769] [runtime-web] Set allow-origin headerMany browsers don't allow cross-origin HTTP requests if the respectiveHTTP header is not set by the server.Because of this it was not possible to test changes to the web frontendwith the local proxy server and a running job manager.See here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS,2
"[FLINK-2769] [runtime-web] Add configurable job manager address to HTTP requestsThis was removed in 3b8b4f0f8c0600dc851d676ce1bd7f5ab81cb64f. Theissue was fixed by this, but it disabled local testing as well.This change re-introduces the variable and sets it to the emptystring by default. This way, we can still use the proxy server forlocal testing.This closes #1449",3
"[hotfix] Minor cleanups in classes FileSystem, OperatingSystem, CopyableValue, GenericCsvInputFormat",5
[hotfix] Add comments to BroadcastVariableInitializer and SplittableIterator,5
[hotfix] Add missing Override annotations to RichFoldFunction and RichReduceFunction,1
[hotfix] Remove unused FileDataSourceBase and FileDataSinkBase,5
[hotfix] Remove unused ValueUtil,1
[FLINK-3169] Move Record Type Utils from flink-java to flink-runtime/test,3
[FLINK-3171] [misc] Consolidate zoo of wrapper classes for input/output-stream to data-input/output-view.,5
"[hotfix] Fix Long.MAX_VALUE watermark emitBefore, when the Kafka Source would emit a final Long.MAX_VALUEwatermark to signal the end of elements (i.e. no partition assigned).This would trip up the AutomaticWatermarkContext and theNonWatermarkContext.Now, a Long.MAX_VALUE watermark is allowed through.",1
[hotfix] respect default local number of task managers,0
[FLINK-2882] [core] Improve performance of string conversions- Memoize string representations of AbstractID.- Use lookup table for byte-to-hex conversion in StringUtils.This closes #1455,1
[FLINK-3147] Expose HadoopOutputFormatBase fields as protectedThis closes #1442,2
"[contrib, connector-wikiedits] Add WikipediaEditsSourceThis closes #1439",2
[fix] Resolve code warnings in JobManager and TaskManager,2
[docs] trivial typo in docker-flink/README.mdThis closes #1463.,2
[FLINK-3134][yarn] asynchronous YarnJobManager heartbeats- use AMRMClientAsync instead of AMRMClient- handle allocation and startup of containers in callbacks- remove YarnHeartbeat messageThe AMRMClientAsync uses one thread to communicate with the resourcemanager and an additional thread to execute the callbacks.This closes #1450.,1
[CLI] Set current class loader to user-class loader and disable class initialization.Enalbes submission of Flink programs written in Clojure.This closes #1457,2
[FLINK-7] Add range partitioning with automatic sampling of key distributionThis closes #1255,1
[FLINK-7] Prevent range partitioning inside iterations.,2
[FLINK-3116] Remove RecordOperatorThis closes #1444,1
[FLINK-3180] [runtime] Log direct memory usage in MemoryLogger- The off-heap stats reported by the memory logger didn't include direct memory.This closes #1466,2
[FLINK-2622] [streaming] Align Scala streaming writeAsCsv API call with Java APIThis closes #1473This closes #1098This closes #1459,2
[FLINK-3103] [runtime] Remove unnecessary synchronization in FsStateBackend.FsCheckpointStateOutputStreamThis closes 1474,4
[hotfix] Trivial WriteMode comment fixWriteMode has 2 values NO_OVERWRITE and OVERWRITE but it refers CREATE in the javadoc.Probably old code.This closes #1475,2
[FLINK-3185] [tests] Don't swallow test failure Exception,0
"[FLINK-3185] [runtime, tests] Log error on failure during recoveryThis closes #1472",0
"[FLINK-3166] [runtime] The first program in ObjectReuseITCase has the wrong expected result, and it succeeds- TestEnvironment now honors configuration of object reuse- Fixed reduce transformations to allow the user to modify and return either inputThis closes #1464",1
[hotfix] [tests] Clean up and simplify ObjectReuseITCase,1
[FLINK-3173] Bump httpclient and httpcore to version 4.2.6 to solve bug in http clientThis closes #1456,0
[FLINK-2837] [Storm Compatibility] FlinkTopologyBuilder cannot handle multiple input streams- removed BoltWrapperTwoInputs- add generic multi-input stream bolt wrapper- updated FlinkTopology to translate multi-input bolts correctly- added multi-input union test wrapper- updated FlinkTopology to translate multi-input bolts correctly- added multi-input union test,3
[FLINK-3181] [gelly] avoid unnecessary messages in SSSP examples and library methodThis closes #1467,2
"[FLINK-3131] [contrib, runtime, streaming-java] Add long getStateSize() to StateHandle and KvStateSnapshotIn order to report the state sizes, we need to expose them. All state backendscurrently available backends know the state size. Only the LazyDbKvState doesnot expose it at the moment, because it serializes the data lazily. This can bechanged in a follow-up fix.",0
"[FLINK-3131] [core, runtime] Add checkpoint statistics trackerAdds a simple tracker of checkpoint statistics.",1
[FLINK-3131] [runtime-web] Add checkpoint statistics handlers,0
[FLINK-3131] [runtime-web] Add checkpoint statistics to web frontendThis closes #1453,1
[FLINK-3067] [kafka connector] Use curator for committing offsets to ZK from KafkaThis closes #1451,1
[FLINK-2978] [web-dashboard] Integrate web client into Web FrontendThis closes #1338,2
[hotfix] [web-dashboard] Various dashboard code cleanups,4
[FLINK-3157] [web dashboard] Remove author tag to be compliant with Apache code style,4
[hotfix] [core] Remove environment checks for Java 6,4
[hotfix] [core] Minor cleanup in SignalHandler.This makes the signal handler registration atomic and does not fail (but ignore) re-registration.,0
[FLINK-3186] [core] Deprecate DataSink.sortLocalOutput() methodsThis closes #1478,5
[FLINK-3194] [web client] Remove standalone web clientThe JAR upload and submit functionality is now integrated into the JobManager web interface.This closes #1481,1
[FLINK-3194] Remove obsolete web client config keys,5
[FLINK-3188] Pass deletes to KeyedDeserializationSchemaThis closes #1484,4
[FLINK-3093] Introduce annotations for interface stability in flink-coreThis closes #1427,2
[refactor] Change if-else conditions to switch-case statements.This closes #1485,4
[codestyle] Improve code style of PoissonSamplerThis closes #1476,1
[FLINK-3176] Improve documentation for window applyThis closes #1488,2
[javaDocs] Fix JavaDoc examples in tumbling and sliding time windowsThis closes #1490,2
"[docs] Add ""Iterator Data Sink"" section to DataStream guide.This closes #1487",5
"[FLINK-1737] [ml] Add outer product to Vector classOuter/Kronecker product take two vectors v, w and compute a matrixsuch that each matrix entry (i,j) is the product of v(i) * w(j).Depending on the vector types the result is either a DenseMatrixor a SparseMatrix. If one of the operands is sparse, then the resultis sparse as well.Implementation of outer product for sparse vectors.Test cases for outer product computation. For dense as well as sparse vectors, More tests are to come.Replaced implementation of  `outer' method in order to avoid call to `SparseVector.apply` (which involves binary search).Reduced warning by three: Removed unnecessary `val` keyword from case class fields.Incorporated suggestion from Till Rohrmann's code review (""avoid binary search by using zipWithIndex"").This closes #1078.",1
[FLINK-3050] [runtime] Add UnrecoverableException to suppress job restartsThis closes #1461.,1
[FLINK-2976] [docs] Add docs about savepoints,2
"[FLINK-2976] [streaming-java, streaming-scala] Set JobVertexID based on stream node hash[comments] Remove unused argument to method[comments] Add more comments to stream node hashingAdd name to hash in order to detect swapped nodes when they have namesImprove error message on non-unique user-specified IDs[comments] Add comment to stream node hashing",1
[FLINK-2976] [runtime] Add StateStore<T>,3
"[FLINK-2976] [core, runtime, streaming-java] Add ApplicationID to ExecutionGraph",1
[FLINK-2976] [runtime] Add setCount(long newCount) to CheckpointIDCounter,1
"[FLINK-2976] [runtime, tests] Add SavepointCoordinator[comments] Rename config keys[comments] Fix docs and don't overload savepoint backend configuration with checkpoint backend configuration[comments] Use ConcurrentMap in HeapStateStore[comments] Fix typo and add missing serialVersionUID[comments] Fix Scala style[comments] Fix Scala style[docs] Emphasize dangers and recommended approachesAdd test to show inf restart loop on submission with unknown savepoint path[comments] Suppress resart of savepoint recovery failureThis closes #1434.",0
[FLINK-2976] [clients] Add savepoint commands to CliFrontend[comments] Use handleError(Throwable),0
[FLINK-2976] [streaming-contrib] Use ApplicationID in DbStateBackend instead of JobID[comments] Set larger timeout for future when triggering savepoint,1
[FLINK-3212] [tests] Add RetryOnFailure rule to JobManagerCheckpointRecoveryITCase,0
[Docs] Fixed code example in streaming docsThis closes #1498.,2
[FLINK-3189] Fix argument parsing of CLI client INFO actionThis closes #1493,5
[FLINK-3218] Fix overriding of user parameters when merging Hadoop configurationsThis closes #1496,5
[FLINK-3224] [DataStream] Call setInputType() on output formats that implement InputTypeConfigurableThis closes #1497,5
[FLINK-3192] [TableAPI] Add explain support to print the sql-execution plan.This closes #1477,1
[FLINK-3118] [Gelly] Consider ResultTypeQueryable in MessageFunction and GatherFunctionThis closes #1471,1
"[hotfix, runtime] Downgrade to Netty version 4.0.27.FinalNetty versions >= 4.0.28.Final contain an improvement by Netty, which slicesa Netty buffer instead of doing a memory copy (https://github.com/netty/netty/issues/3704)in the LengthFieldBasedFrameDecoder. In some situations, this interacts badlywith our Netty pipeline leading to OutOfMemory error.To reproduce, run batch WordCount with a range partitioner and reasonably largedata.",5
[FLINK-2342] [ml] Add a new fit operation for Vector with Double value to StandardScaler  - Add more tests to `StandardScalerITSuite`  - Refactor `StandardScalerITSuite`This closes #899.,4
"[FLINK-3195] [examples] Consolidate batch examples into one project, unify batch and streaming examples under on parent project",5
[FLINK-3195] Rework quickstart example & some cleanups on the new examples,1
"[FLINK-1712] Remove ""flink-staging"" moduleThis closes #1492This closes #1482",2
[FLINK-2962] Cluster startup script refers to unused variable,1
"[FLINK-2586] Unstable Storm Compatibility Tests - added BLOCKING flag to FlinkLocalCluster - added NullTerminatingSpout and SpoutOutputCollectorObserver plus tests - reworked test accordingly   - set BLOCKING flag for ITCases   - make infinite spouts finite using NullTerminatingSpout   - removed sleep time to get stable - fixed bug in BoltSplitITCase and SpoutSplitITCase   - exception in VerifyAndEnrichBolt is swallowed and test would not fail (replaced by errorFlag) - reduced sleep-time in BoltSplitITCase and SpoutSplitITCase to reduce testing time - fixed WrapperSetupHelperTest   - reworked to origianl version with more than two inputs     (was limite to two inputs because more the two inputs per bolt was not supported in between, which is now fixed)minor code cleanup (removed unused imports, indenting, etc.)fixed small error in documenationThis closes #1502.",2
[Storm-Compatibility] Forward Storm Kryo registrations to FlinkThis closes #1495.,2
[FLINK-2984] [ml] Extend libSVM file format supportThis closes #1504.,1
[hotfix] moved files to correct folder to match package statementsThis closes #1510,2
[hotfix] Remove unnecessary dependencies in flink-runtime.  - Removes Apache Commons HTTP Client  - Removes Apache Commons IO  - Removes Jettison JSONparser and consolidates tests to use Jackson instead (which is included anyways),1
"[FLINK-3236] [runtime] Flink user code classloader as parent classloader from Flink core classesOriginally, the user code classloader delegates to the system classloader as parent.That works in Flink standalone settings, but not when the Flink core classes themselves are not loaded with the system classloader (certain embedded setups).This patch uses as parent the classloader that was used to load the Flink core classes, specificly""org.apache.flink.runtime.execution.librarycache.BlobLibraryCacheManager.FlinkUserCodeClassLoader.class.getClassLoader()"".This closes #1506This closes #1507This closes #1508",2
[hotfix] Remove docs for the now removed web client.,4
[hotfix] Remove outdated README for the quickstart projects.The README was describing non-existing bash scripts removed several versions ago.,4
[FLINK-3235] Remove Flink on Tez code,2
"[FLINK-3232] [runtime] Add option to eagerly deploy channelsAdds a flag to the ExecutionGraph's IntermediateResult class indicating whetherthe result consumers should be deployed eagerly. If true, the consumers aredeployed as soon as the partition is registered at the ResultPartitionManager ofthe task manager. In practice, the deployment boils down to updating unknowninput channels of the consumers (because the actual tasks are actually deployedall at once).This behaviour is configured in the JobGraph generator and only activated forstreaming programs (StreamingJobGraphGenerator). It only makes sense forpipelined results.The motivation is to get down the latency of the first records passing apipeline. The initial update of the input channels causes a higher latency.You can see this effect in the StreamingScalabilityAndLatency class (manualtest).At the moment, this results in duplicate Akka messages when the first recordis produced (the message travels from the task to the job manager and from thejob manager to task manager, which then will be ignored at the InputGate).This closes #1503",3
[FLINK-3219] [java scala] Implement DataSet.count and DataSet.collect using a single operator,1
"[hotfix] Minor cleanup of warnings, comments, and code style in the Java API Utils",2
[FLINK-3197] [core] Close InputStream in BinaryInputFormat#createStatistics reliablyThis closes #1494,3
[hotfix] Use AccumulatorSnapshot's class loader for deserializing accumulatorsThis closes #1511,1
[FLINK-3074] [yarn] Fix port range retry termination condition,1
[FLINK-3073] [dist] Fix JobManager command line argumentRemoved streaming mode lead to wrong arguments being passed.,4
"[FLINK-3172] [core, runtime, yarn] Allow port range for job manager with high availabilityThis closes #1458.",1
[FLINK-3132] [docs] Initial docs restructure[pr-comments] Decrease font size[pr-comments] Remove docker connector sectionThis closes #1499.,2
[hotfix] Fix missing license in new doc files,2
[FLINK-2716] [gelly] [apis] New checksum method on DataSet and GraphThis closes #1462,5
[FLINK-2671] [tests] Fix unstable StreamCheckpointNotifierITCase,0
[hotfix] Clean up CliFrontend after removing web client,4
[hotfix] Fix reference to batch Java examples in flink-java8,2
"[FLINK-3184] [timeouts] Set default cluster side timeout to 10 s and the client side timeout to 60 sAdd missing param descriptions to FlinkYarnCluster, remove implicit timeout from ApplicationClientThis closes #1468",4
[hotfix] [docs] Remove copy-paste and author comments,4
[FLINK-3251] [runtime] Return empty stats for unknown operator,1
[FLINK-3253] [runtime-web] Properly display checkpoint stats,1
[FLINK-3250] [runtime] Remove too strict parallelism check in SavepointCoordinator,4
[FLINK-3244] [runtime] Add debug log messages to SavepointCoordinator,2
[hotfix] Exclude 'flink-annotations' from fat jars in quickstart poms.,2
[Refactor] [DataSet] Refactor key selector translation in DataSet API.Clean up several compiler warnings.This closes #1509,2
[FLINK-3241] Fix SNAPSHOT deployment for Scala 2.11,0
[FLINK-3220] Remove javax.servlet exclusions from hadoop2 fat jar to fix Flink on HDP,2
[FLINK-2831] [Storm Compatibility Tests] Fixed instable testThis closes #1519.,3
[FLINK-3241] Fix Scala 2.11 build by moving some flink-table classes into the right directory,2
[FLINK-3165] [py] Windows OS supportThis closes #1454,1
[FLINK-3057] Bidrectional plan connection,2
[FLINK-3014] Replace InStr.read() calls with DataInStr.readFully()This closes #1432,5
[FLINK-3063][py] Remove combiner,4
"[FLINK-2501] [py] Remove the need to specify types for transformationsFull changelog:Major changes===============- Users no longer have to supply information about types- Values are now stored as byte arrays on the Java side in* a plain byte[] most of the time,* a T2<b[],b[]> within a join/cross* a T2<TX<b[]...b[]>, b[]> within keyed operations.- Every value contains information about its type at the beginning ofeach byte array.- Implemented KeySelectorsMinor===============- improved error messages in several places- defaultable operations now use a ""usesUDF"" flag- reshuffled type ID's; tuple type encoded as 1-25- broadcast variables are now sent via the tcp socket- ProjectJoin/-Cross now executes projection on python sideJava---------------- Sort field now stored as String, continuation of FLINK-2431- object->byte[] serializer code moved into separate utility classPython---------------- Fixed NullSerializer not taking a read method argument- Serializer/Deserializer interface added- Refactored DataSet structure* Set and ReduceSet merged into DataSet- configure() now takes an OperationInfo argument- Simplified GroupReduce tests- removed unused Function._open()- simplified chaining setup- most functions now use super.configure()",5
[FLINK-2439] [py] Expand DataSet feature coverage,3
"[hotfix] [webserver] Add sanity check to avoid NPE in case the web server could not be instantiatedThe method WebMonitorUtils.startWebRuntimeMonitor instantiates the WebMonitor. However, in case of a failure null is returned. This failure case has to be handled in the method FlinkMiniCluster.startWebServer in order to avoid a possible NullPointerException.",5
"[FLINK-3058] Add support for Kafka 0.9.0.0For adding Kafka 0.9.0.0 support, this commit changes the following:- Split up of the kafka connector into a flink-connector-kafka-(base|0.9|0.8) with different dependencies- The base package contains common test cases, classes and implementations (the producer for 0.9 and 0.8 relies on exactly the same code)- the 0.8 package contains a kafka connector implementation against the SimpleConsumer (low level) API of Kafka 0.8. There are some additional tests for the ZK offset committing- The 0.9 package relies on the new Consumer API of Kafka 0.9.0.0- Support for metrics for all producers and the 0.9 consumer through Flink's accumulators.This closes #1489",2
[FLINK-3122] [Gelly] Generic vertex value in label propagation* updated algorithm and tests* updated / corrected algorithm documentationThis closes #1521,2
[hotfix] [test] Add a test case for Filter.,3
[FLINK-3269] [py] Replace DataInStr.read() with DataInStr.readFully(),5
test protection of master branch,3
[hotfix] remove temporary file,2
[hotfix] [ml] Fix SVM documentation,2
[FLINK-2972][java-api] remove Chill dependency from the test scopeThis closes #1535.,3
[FLINK-3206] fix heap size for non-pre-allocated off-heap memory,0
[docs] add disclaimer for Kerberos concerning the Hadoop version,1
"[FLINK-1994] [ml] Add different learning rate calculation schemes to SGDAdded SGD gain calculation schemesfixed optimal SGD calculation schemeFLINK-1994: Added 4 new effective learning rates[FLINK-1994] [ml] Add different gain calculation schemes to SGDfixed long lines in GradientDescent.scala[FLINK-1994][ml]Add different gain calculation schemes to SGD[FLINK-1994][ml] Add different gain calculation schemes to SGD[FLINK-1994][ml] Add different gain calculation schemes to SGDAdded SGD gain calculation schemesfixed optimal SGD calculation scheme[FLINK-1994] [ml] Add different gain calculation schemes to SGDFLINK-1994: Added 3 new effective learning ratesAdded SGD gain calculation schemesfixed optimal SGD calculation scheme[FLINK-1994] [ml] Add different gain calculation schemes to SGDfixed long lines in GradientDescent.scala[FLINK-1994][ml] Add different gain calculation schemes to SGD[Flink-1994][ml] Add different gain calculation schemes to SGD[FLINK-1994][ml] Updated docs, refactored optimizationMethod from Int to String[FLINK-1994][ml] Added test and example to docs[FLINK-1994][ml] Fixed Int Artifacts in LinearRegression.scalaAdded LearningRateMethod to IterativeSolverThe learning rate method defines how the effective learning step is calculated foreach iteration step of the IterativeSolver.Fixed docs, merged enumeration from Till, fixed typo in Wus method[FLINK-1994][ml] Added 4 new effective learning rate methods[FLINK-1994][ml] Add different gain calulation schemes to SGDThis closes #1397.",1
"[FLINK-1994] [ml] Remove decay parameter from IterativeSolverOnly some of the LearningRateMethodTrait implementations use the decay value.Thus, it should only be part of these methods. This commit makes the learningrate methods which need additional parameters a case class which has to beinstantiated with the respective parameter values.Corrects some of the learning rate formulas and the example in the documentation.",2
[FLINK-3259] [docs] Redirect programming guides to new layout,1
"[FLINK-3261] Allow Task to decline checkpoint request if not readyBefore, it could happen that a StreamingTask receives a CheckpointTrigger message while internally not being ready. The checkpointcoordinator would then wait the specified timeout interval beforecontinuing. Now, tasks can signal that they are not ready and thecheckpoint coordinator will dicard a checkpoint for which is this thecase and trigger new checkpoints if necessary.The newly triggered checkpoints will also release alignment locks instreaming tasks that are still waiting for barriers from failedcheckpoints.",0
[hotfix] [docs] Add missing licenses to programming guide redirects.This closes #1545,1
[hotfix] Remove use of StringUtils.stringifyException() where used is counterindicated,1
[tests] Add test for a program with very fast failure rates.,0
[FLINK-3255] [streaming] Disable parallelism-dependent chaining optimizationThis closes #1518,5
[FLINK-3246] Remove unnecessary '-parent' suffix from projects 'flink-contrib' and 'flink-streaming-connectors'.This closes #1515,2
[hotfix] Undo DEBUG log setting for Blob Server in runtime tests,3
"[FLINK-3267] Disable reference tracking in Kryo fallback serializerBefore this commit, Kryo runs extra logic to track and resolve repeated references tothe same object (similar as JavaSerialization)This disables reference tracking because  - reference tracking is costly  - it is virtually always unnecessary in the datatypes used in Flink  - it is inconsistent with Flink's own serialization (which does not do reference tracking)  - it may have problems if elements are read in a different order than they are written.This closes #1528",0
[FLINK-3256] Fix colocation group re-instantiationThis closes #1526,0
"[FLINK-3284, hotfix] [docs] Fix various broken links",2
[FLINK-3135] Add chainable driver for UNARY_NO_OP strategyThis closes #1530,1
[hotfix] [docs] Tidy up documentation. Fix some non-idiomatic usage of return in scala code.This closes #1531,0
[FLINK-3285][maven] Skip deployment of flink-java8 moduleThis closes #1547,2
"[FLINK-3209] Remove Unused ProcessingTime, EventTime and AbstractTimeOnly keep Time for specifying time durations/intervals.This closes #1512",1
[FLINK-3274] Make accumulator names of Kafka connector uniqueThis closes #1541,1
[FLINK-3280] Change Boolean.getBoolean to Boolean.valueOf,1
[cleanup] Remove spark repl detection code from closure cleanerThis closes #1549.,4
[FLINK-1666][FLINK-1903][FLINK-3233] Refactor expression keys.- Unify usage of expression keys: FLINK-1666- Unify supported key expressions (incl. support for partitioning on atomic types: FLINK-3233)- Remove removal of duplicate keys: FLINK-1903- Unify checks for sort keys- Add more tests for SelectorFunctionKeys and ExpressionKeysThis closes #1520,1
[FLINK-1045][dataSet] Remove Combinable annotation.This closes #1522,4
[FLINK-3198][dataSet] Renames and documents better the use of the getDataSet() in Grouping.This closes #1548,5
[hotfix] Remove references to deprecated junit.framework.Assert from testsThis closes #1539.,3
[FLINK-2871] support outer join for hash on build side.this commit support full outer join includes:    1. left outer join with REPARTITION_HASH_FIRST.    2. right outer join with REPARTITION_HASH_SECOND.    3. fullouter join with REPARTITION_HASH_FIRST and REPARTITION_HASH_SECOND.this close #1469,1
[FLINK-2933][maven] add suffix to Scala dependent modules- add suffixes- adapt change-scala-version scriptThis closes #1529.,4
[maven] add script to verify Scala suffixes,0
[docs] add Scala suffix for Maven artifact names,0
[docs] Add warning about artifact name changes,4
[docs] Fix broken links and remove duplicate page,4
"[hotfix] Fix interaction of Async calls/checkpointing/cancelingBefore, it could happen that a Task is canceled during snapshotting.Some State Backends would silently swallow exceptions resulting fromthis and the Task would get stuck until the cleanup logic gets to it.Now, we rethrow a CancelTaskException if isRunning is false inStreamTask after performing snapshots.This also moves the logic that swallows exceptions in case a task is notrunning anymore from StreamTask to the async caller in Task.",1
[FLINK-3258] [runtime] Don't request partition on channel update if no requests yet,5
"[FLINK-3258] [runtime, streaming-java, tests] Move registerInputOutput code to invoke and remove registerInputOutputThis closes #1538",4
[FLINK-3290] [py] Generalize OperationInfo transfer-identifier saved in java OpInfo-changed default values to prevent null exceptions-all operations use the same routine to transfer parameters-PyPlRcv can handle Tuple0-labeled py OpInfo fields as transferred/internal-fixed broadcast OpInfo not having correct identifier-removed unused projection code,1
[FLINK-3140] [table] NULL value data layout in Row Serializer/ComparatorThis closes #1465.,5
"[FLINK-3275] [py] Support for DataSet.setParallelism()-parallelism is stored Value object within the OperationInfo, so it can be passed as a reference to multiple operations (in cases where a set is internally executed as multiple operations)-setParallelism is called for every DataSet with either a user-set value or env.getParallelism-added a DataSink set, providing access to name() and setParallelism() for sinks",1
[FLINK-3262] [web-dashboard] Remove fuzzy versioning from Bower dependenciesSeveral packages had been updated locally by users when compiling the templateswithout changing the version in bower.json. The following packages have beenexplicitly updated. jquery              2.1.4     2.2.0 angular            1.3.15     1.4.8 angular-moment      0.9.2    0.10.3 angular-ui-router  0.2.13    0.2.15 bootstrap           3.3.5     3.3.6 d3                  3.5.5    3.5.12 dagre-d3           0.4.10    0.4.11 font-awesome        4.3.0     4.5.0This closes #1525,2
[hotfix] [kafka connector] Replace funky loop with simple division in FixedPartitioner,0
[hotfix] [streaming] Processing timer errors are not logged unless the task is actually running.This keeps the log cleaner in case of failed timers while canceling tasks.,0
[FLINK-3178] Don't Emit In-Flight Windows When Closing Window OperatorThis closes #1542,1
[FLINK-3196] InputStream should be closed in EnvironmentInformation#getRevisionInformation()This closes #1552,5
"[FLINK-3242] Also Set User-specified StateBackend without CheckpointingBefore, the user-specified StateBackedn would not be set when generating theJobGraph if checkpointing was disabled.This closes #1516",1
[FLINK-3292]Fix for Bug in flink-jdbc. Not all JDBC drivers supportedThis closes #1551,1
[FLINK-3265] [rabbitmq] Fix concurrency bug in RabbitMQThis closes #1534,0
"[docs] Harmonizes watermark terminology between docs and java docsHenceforth, we shall only use the term lower in the context of timestampsto denote that an event has occurred before another event.",1
"[streaming] [scala] Exposed environment from DataStreamThis is needed for streaming library features, is identical to the batch API.Closes #1480",5
[FLINK-3300] fix concurrency bug in YarnJobManagerAdds message passing between Hadoop's async resource manager client andthe YarnJobManager actor.This closes #1561.,4
[hotfix] fix non-exhaustive match warning,2
[hotfix] [streaming] Tasks print subtask in log statements,2
[hotfix] Clean up warnings in Serializers util class,2
[FLINK-3306] [core] Fix auto-type registry util,1
[FLINK-3305] [core] Remove limited and inconsistent auto-magic for Joda TimeThe auto-magic for Joda Time was limited to very few classes. It was intransparent whatcases would be handled.,0
[hotfix] Add deprecation message to old Key interface,1
"Revert ""[FLINK-3265] [rabbitmq] Fix concurrency bug in RabbitMQ""This reverts commit 6b01a89020f2de3f7710cf72336291b1e8ca8562. Theintroduced locks are not necessary. The checkpointing test case onlyneeds to be adapted to the checkpointing runtime behavior.",1
[FLINK-3265][tests] adapt RMQSource checkpointing test to runtime behaviorThe methods snapshotState and notifyCheckpointComplete are alwaysmutually exclusive. The RMQSource relies on this but the test makes afalse assumption when it calls those two methods at the same time.This closes #1569.,1
[hotfix] Remove 'ByteArrayInputView' and replace deserialization in TypeInformationSerializationSchema with more efficient reusable buffers.,5
[fix] [docs] Fix typo in savepoints documentation,2
[FLINK-3281] IndexOutOfBoundsException when range partition on empty DataSet,5
[FLINK-3208] [gelly] rename vertex-centric iteration model to scatter-gatherThis closes #1514,2
[FLINK-3175][Kafka 0.8] Relax test condition,3
[FLINK-3216] [FLINK-3217] [cep] Adds CEP operator for pattern recognitionImplements NFA using the SharedBufferImplements NFACompiler to compile a Pattern into a NFAAdd CEP operatorMakes NFA and SharedBuffer serializableAdd serializability support to SharedBuffer and NFAAdd keyed cep pattern operatorAdds CEP documentationAdds online documentation for the CEP libraryCopies sequence events before giving them to the UDFFix correct scala type suffixesThis closes #1557.,0
[FLINK-3287] Shade Curator dependency into flink-connector-kafka-0.8,2
[FLINK-3247] Remove * exclude from quickstartsThis closes #1573,4
[FLINK-3049] [api breaking] Move 'Either' type to 'flink-core / org.apache.flink.types',2
[FLINK-3303] [core] Move Tuple classes to flink-core,2
[FLINK-3303] [core] Move all type utilities to flink-core,2
[hotfix] Reduce the heavy sysout verbosity for certain tests,3
"[FLINK-2348] Fix unstable IterateExampleITCase.This deactivates the validation of results, which is not reliably possible under the current model (timeout on feedback).This test for now only checks that the job executes properly.Also adds proper logging property files for the examples projects.",2
[hotfix] [streaming] Various cleanups in StreamTask  - Clean up generics  - Clean and safe disposal of initialized resources  - Add names to asynchronous materialization threads  - Fix concurrent modification of  materialization threads set,1
[hotfix] Remove old sysout debug message in UdfAnalyzerTest,3
"[hotfix] Fix warnings concerning joda-time in ""flink-tests""",3
[FLINK-3314] [streaming] Fix case where early cancel messages do not properly cancel a stream operator.,1
[hotfix] Fix typos in Trigger.java,2
[FLINK-3313] [kafka] Fix TypeInformationSerializationSchema usage in LegacyFetcherThe LegacyFetcher used the given KeyedDeserializationSchema across multiple threads even thoughit is not thread-safe. This commit fixes the problem by cloning the KeyedDeserializationSchemabefore giving it to the SimpleConsumerThread.Add clone method for Java serializable objects to InstantiationUtilThis closes #1577.,1
[streaming] remove dummy FlumeSource,4
[FLINK-3325] [cep] Close input stream in CEPPatternOperator.restoreState,1
[docs] Move libraries to batch and streaming guidesOld guides are redirected to the new pages.,1
"[hotfix, yarn] Exit JVM after YARN actor system shut downThis closes #1582, #1576.",5
"[FLINK-3201] Enhance Partitioned State Interface with State TypesAdd new state types ValueState, ListState and ReducingState, whereListState and ReducingState derive from interface MergingState.ValueState behaves exactly the same as OperatorState. MergingState is astateful list to which elements can be added and for which the elementsthat it contains can be obtained. If using a ListState the list ofelements is actually kept, for a ReducingState a reduce function is usedto combine all added elements into one. To create a ValueState the userpasses a ValueStateIdentifier toStreamingRuntimeContext.getPartitionedState() while they would pass aListStateIdentifier or ReducingStateIdentifier for the other statetypes.This change is necessary to give the system more information about thenature of the operator state. We want this to be able to do incrementalsnapshots. This would not be possible, for example, if the user had aList as a state. Inside OperatorState this list would be opaque andFlink could not create good incremental snapshots.This also refactors the StateBackend. Before, the logic for partitionedstate was spread out over StreamingRuntimeContext,AbstractStreamOperator and StateBackend. Now it is consolidated inStateBackend.This also adds support for partitioned state in two-input operators.",1
"[FLINK-3200] Use Partitioned State in WindowOperatorThis changes window operator to use the new partitioned stateabstraction for keeping window contents instead of custom internalstate and the checkpointed interface.For now, timers are still kept as custom checkpointed state, however.WindowOperator now expects a StateIdentifier for MergingState, this caneither be for ReducingState or ListState but WindowOperator is agnosticto the type of State. Also the signature of WindowFunction is changed toinclude the type of intermediate input. For example, if a ReducingStateis used the input of the WindowFunction is T (where T is the inputtype). If using a ListState the input of the WindowFunction would be oftype Iterable[T].",1
[FLINK-3278] Add Partitioned State Backend Based on RocksDB,5
[FLINK-3201] Add operator state to make change backwards compatible,4
[FLINK-3312] Add accessors for various state types to RuntimeContext,1
[FLINK-3200] Fix Triggers by introducing clear() method to clean up state/triggers,4
[FLINK-3312] Add simple constructors for State Descriptors,1
[FLINK-3201] Adjust CEP code for changes state interfaces,4
"[FLINK-3293] [yarn] Respect custom CLI Yarn name in JobManager modeAdded a method to set a default application name for the Flink Yarn session CLI.Switched the order, such that this name can now be overwritten by the command line.This closes #1558",2
[FLINK-3161] [dist] Externalize cluster start-up and tear-down when availableParallelizes cluster start-up and tear-down when pdsh is availableThis closes #1523,2
[FLINK-3254] [dataSet] Adding functionality to support the CombineFunction contract.This closes #1568,1
[FLINK-3328] Incorrectly shaded dependencies in flink-runtimeThis closes #1584,2
[FLINK-3268] [tests] Enhance stability of ZooKeeperTestEnvironment.deleteAll(),3
[FLINK-2845] Fix TimestampITCase.testWatermarkPropagation(),3
[streaming] [scala] Revert removing getJavaStream() from DataStream,5
[streaming] [scala] Scala wrapper for DataStreamUtilsThis closes #1574,5
[FLINK-3329] Auto-Close BackupEngine in AbstractRocksDBState,5
[hotfix] [docs] Fixed typo in process model illustrationThis closes #1592.,2
[FLINK-3342] [runtime] Fix checkpoint statistics state size overflow,0
[FLINK-3330] [ml] Fix SparseVector support in GradientDescentThe GradientDescent implementation did not work with sparse input databecause it requires the gradient to be dense. This patch makes sure thatthe gradient sum is always dense.This closes #1587.,1
[FLINK-3338] [kafka] Use proper classloader when cloning the deserialization schema.This closes #1590,1
[FLINK-3093] Introduce annotations for interface stability in remaining modulesThis closes #1428,5
[hotfix] Relax test condition in ExternalProcessRunnerTest,3
"[FLINK-3120] [runtime] Manually configure Netty's ByteBufAllocatortl;dr Change default Netty configuration to be relative to number of slots,i.e. configure one memory arena (in PooledByteBufAllocator) per slot and use oneevent loop thread per slot. Behaviour can still be manually overwritten. Withthis change, we can expect 16 MB of direct memory allocated per task slot byNetty.Problem: We were using Netty's default PooledByteBufAllocator instance, whichis subject to changing behaviour between Netty versions (happened betweenversions 4.0.27.Final and 4.0.28.Final resulting in increased memoryconsumption) and whose default memory consumption depends on the number ofavailable cores in the system. This can be problematic for example in YARNsetups where users run one slot per task manager on machines with many cores,resulting in a relatively high number of allocated memory.Solution: We instantiate a PooledByteBufAllocator instance manually and wrapit as a NettyBufferPool. Our instance configures one arena per task slot asdefault. It's desirable to have the number of arenas match the number of eventloop threads to minimize lock contention (Netty's default tried to ensure thisas well), hence the number of threads is changed as well to match the numberof slots as default. Both number of threads and arenas can still be manuallyconfigured.This closes #1593.",5
[FLINK-2721] [Storm Compatibility] Add Tuple meta informationThis closes #1591,5
[FLINK-3286] [build] Remove not maintained JDEB profile from flink-dist,2
[FLINK-3362] [runtime] Fix possible overflow in multiplication,0
"[FLINK-3339] Make ValueState.update(null) act as ValueState.clear()This was causing problems with TypeSerializers that choke on nullvalues, especially in the Scala KeyedStream.*WithState() family offunctions.",1
"[FLINK-3336] Add Rescale Data Shipping for DataStreamThis is the Javadoc of DataStream.rescale() that describes thebehaviour:Sets the partitioning of the {@link DataStream} so that the output elementsare distributed evenly to a subset of instances of the next operation in a round-robinfashion.The subset of downstream operations to which the upstream operation sendselements depends on the degree of parallelism of both the upstream and downstream operation.For example, if the upstream operation has parallelism 2 and the downstream operationhas parallelism 4, then one upstream operation would distribute elements to twodownstream operations while the other upstream operation would distribute to the othertwo downstream operations. If, on the other hand, the downstream operation has parallelism2 while the upstream operation has parallelism 4 then two upstream operations willdistribute to one downstream operation while the other two upstream operations willdistribute to the other downstream operations.In cases where the different parallelisms are not multiples of each other one or severaldownstream operations will have a differing number of inputs from upstream operations.",1
[hotfix] Remove @Experimental from DataStream.forward(),5
[FLINK-3348][scripts] remove bc dependency in startup script,4
[FLINK-3353] CSV-related tests may fail depending on localeThis closes #1598.,0
[hotfix] [runtime] Create TestingJobManager in TestingUtils,3
[hotfix] [docs] Add config docs about checkpoint stats,2
[FLINK-3310] [runtime-web] Add back pressure statistics to web monitor (backend),1
[FLINK-3310] [runtime-web] Add back pressure statistics to web dashboard (frontend)This closes #1578.,1
[hotfix][doc] Add note on how to use custom loggers with a per-job-yarn cluster,2
[FLINK-3337] [runtime] mvn test fails on flink-runtime because curator classes not foundRemoves curator dependency exclusions from flink-runtime. This resolvesNoClassDefFoundError exceptions when running `mvn test`.This partialy reverts e31a4d8.This closes #1596,4
[FLINK-3361] [jobmanager] Fix error messages about execution delay and max heartbeat pause,1
[FLINK-3363] [jobmanager] Properly shut down executor thread pool when JobManager shuts down,2
[FLINK-3365] [taskmanager] Properly shut down cleanup timer thread,4
[FLINK-3334] [conf] Include year-month-day in the log output,2
[hotfix] typo IllegalArgumentExceptionThis closes #1602,2
[FLINK-3357] [core] Drop AbstractID#toShortString()This closes #1601,4
[hotfix] Update comments in 'ChainingStrategy' and remove outdated 'FORCE_ALWAYS' constant,1
[hotfix] Cleanup routing of records in OperatorChain,1
[FLINK-3355] [rocksdb backend] Allow passing options to the RocksDB backend.This also cleans up the generics in the RocksDB state classes.This closes #1608,5
[FLINK-3286] Remove the files from the debian packaging as well,2
[FLINK-3373] [build] Bump version of transitine HTTP Components dependency to 4.4.4 (core) / 4.5.1 (client),2
[hotfix] Add missing entries to condif reference doc and removed outdated webclient entries,5
[FLINK-3373] [build] Revert HTTP Components versions because of incompatibility with Hadoop >= 2.6.0,1
[build system] Skip javadoc generation for java8 and snapshot deployments,2
[FLINK-3366] Rename @Experimental annotation to @PublicEvolvingThis closes #1599,2
[FLINK-3234] [dataSet] Add KeySelector support to sortPartition operation.This closes #1585,1
[docs] Fixed typo in Storm Compatibility pageThis closes #1618,1
[FLINK-3373] [build] Shade away Hadoop's HTTP Components dependencyThis closes #1615,2
[FLINK-3341] Make 'auto.offset.reset' compatible with Kafka 0.8 and 0.9This closes #1597,1
[FLINK-3350] [tests] Increase default test Akka ask and ZooKeeper timeouts,3
[hotfix] [tests] Ignore ZooKeeper logs in process tests,3
[hotfix] [tests] Log retry rule failures on warn level,0
[hotfix] [tests] Reset state to allow retry on failureThis closes #1611,0
"[FLINK-3260] [runtime] Enforce terminal state of ExecutionsThis commit fixes the problem that Executions could leave their terminal stateFINISHED to transition to FAILED. Such a transition will be propagated to theExecutionGraph where it entails JobStatus changes. Since the Execution alreadyreached a terminal state, it should not again affect the ExecutionGraph. Thiscan lead to an inconsistent state in case of a restart where the old Executionsget disassociated from the ExecutionGraph.This closes #1613",1
"[FLINK-3107] [runtime] Start checkpoint ID counter with periodic schedulerProblem: The job manager enables checkpoints during submission of streamingprograms. This can lead to call to a call to `ZooKeeperCheckpointIDCounter.start()`,which communicates with ZooKeeper. This can block the job manager actor.Solution: Start the counter in the `CheckpointCoordinatorDeActivator`.This closes #1610.",0
[FLINK-3371] [api-breaking] Move TriggerResult and TriggerContext to dedicated classesThis closes #1603,4
[FLINK-3384] [kafka] Add ClosableQueue for message exchanges between Kafka Threads,4
"[FLINK-3369] [runtime] Make RemoteTransportException instance of CancelTaskExceptionProblem: RemoteTransportException (RTE) is thrown on data transfer failureswhen the remote data producer fails. Because RTE is an instance of IOException,it can happen that the RTE is reported as the root job failure cause.Solution: Make RTE instance of CancelTaskException, leading to cancellation ofthe task and not failure.Squashes the following commit:[pr-comments] Add remote address to RemoteTransportExceptionThis closes #1621.",1
[FLINK-3391] [tests] Fix typo in test config,5
"[FLINK-3364] [runtime, yarn] Move SavepointStore initialization out of JobManager constructorThis closes #1622.",5
[FLINK-3271] [build] Don't exclude jetty-util dependency from the Hadoop dependenciesThis closes #1543,2
[FLINK-3389] [rocksdb] Add pre-defined option profiles.,2
"[FLINK-3358] [FLINK-3351] [rocksdb] Add simple constructors and automatic temp path configurationThis adds constructors that only take a backup dir URI and use it to initializeboth the RocksDB file backups and the FileSystem state backend for non-partitionedstate.Also, the RocksDBStateBackend now automatically picks up the TaskManager's temp directories,if no local storage directories are explicitly configured.",5
[hotfix][travis] deploy snapshots only for master branch,0
[FLINK-3270] Add Kafka exampleThis closes #1533,1
[hotfix] Minor code cleanups in AbstractStateBackend,4
"[FLINK-2991] Add Folding State and use in WindowOperatorThis enables efficient incremental aggregation of fold window.This also adds:- WindowedStream.apply(initVal, foldFunction, windowFunction)- AllWindowedStream.apply(initVal, foldFunction, windowFunction)This closes #1605",1
[FLINK-2991] Adjust RocksDB Folding State to latest RocksDBStateBackend,5
[FLINK-3392] [kafka] Fix unsynchronized access in ClosableBlockingQueue,0
[FLINK-3359] Make RocksDB File Copies Asynchronous,2
[FLINK-3352] Use HDFS Config in RocksDB Copy UtilitiesThis also moves the utilities (HDFSCopyFromLocal and HDFSCopyToLocal) tothe RocksDB package because we would need a HDFS dependency inflink-core otherwise.,5
[hotfix] Fix field names in RocksDBStateBackend,5
[FLINK-3393] [core] ExternalProcessRunner wait to finish copying error stream,0
[FLINK-3107] [runtime] Defer start of checkpoint ID counter,1
[FLINK-3367] Add PublicEvolving and Internal annotations to flink-java and flink-scala,2
[FLINK-3367] Add PublicEvolving and Internal annotations to flink-core,2
[FLINK-3367] Add PublicEvolving and Internal annotations to flink-streaming-java and flink-streaming-scalaThis closes #1606,2
"Revert ""[FLINK-3369] [runtime] Make RemoteTransportException instance of CancelTaskException""This reverts commit cf3ae88b73e30a2d69ac1cc6009a8304ea3f53cc.The reason is that we cannot be sure that a failing sender will always be the rootcause why the receiver cannot read the data. A TM can also fail after a sender isfinished leading to a loss of the intermediate result partitions. Then the receiverwill no longer be able to read the data.",5
[hotfix] [web-dashboard] Make build idempotent,1
[FLINK-3160] [web-dashboard] Aggregate operator statistics by TaskManagerAdds a new per-job tab displaying subtask statistics aggregated by TaskManager.This closes #1564.,1
[FLINK-3354] Determine correct size for RocksDB snapshotsCloses #1638,5
"[FLINK-3187] [restart] Introduce RestartStrategy to ExecutionGraphA RestartStrategy defines how the ExecutionGraph reacts in case of a restart. Different strategiesare conceivable. For example, no restart, fixed delay restart, exponential backoff restart, scalingin/out restart, etc.Expose RestartStrategy to user APIThis removes the setNumberExecutionRetries and the setDelayBetweenRetries on the ExecutionEnvironment andthe ExecutionConfig. Instead the more general RestartStrategy can be set. In order to maintain theseparation between the runtime and api module, one sets a RestartStrategyConfiguration which is transformedinto a RestartStrategy on the JobManager.Replace old execution-retries configuration parameters by restart-strategy.Add FixedDelayRestartStrategy test caseReintroduce old configuration values and API calls for the deprecated restart mechanismThe old configuration values and API calls will be respected if no explicitRestartStrategy has been set. The values, if correct, are used to instantiatea FixedDelayRestartStrategy.Add deprecation comments to the JavaDocsAdd logging statement for job recoveryFix JobManagerProcessFailureBatchRecoveryITCase by introducing a job recovery timeoutAdd proper annotations to RestartStrategiesLet ExecutionGraphRestartTest extend TestLoggerThis closes #1470.",3
"[FLINK-2111] Add ""stop"" signal to cleanly shutdown streaming jobs- added JobType to JobGraph and ExecutionGraph- added interface Stoppable, applied to SourceStreamTask- added STOP signal logic to JobManager, TaskManager, ExecutionGraph- extended Client to support stop- extended Cli frontend, JobManager frontend- updated documenationFix JobManagerTest.testStopSignal and testStopSignalFailThe StoppableInvokable could not be instantiated by Task because it was declared as a privateclass. Adds additional checks to verify that the stop signal behaves correctly.Auto-detect if job is stoppableA job is stoppable iff all sources are stoppable- Replace JobType by stoppable flag- Add StoppableFunction and StoppableInvokable to support the optional stop operation- added REST get/delete test (no extra YARN test -- think not required as get/delete is both tested)- bug fix: job got canceld instead of stopped in web interface- Add StoppingException- Allow to stop jobs when they are not in state RUNNINGSecond round of Till's comments",1
[FLINK-2111] Make stoppable stream task and stoppable stream source operator type safeUpdate index.js and reset vendor.css and vendor.js to master versionUpdate web-dashboardRemove duplicate flink-runtime-web dependency from flink-testsRemove not used ProgramStopExceptionChange stopping behaviour to only work in job status RUNNINGThis closes #750.,1
[hotfix] Add better error reporting in case of wrongly specified retry delay,1
[hotfix] Annotate StoppableFunction as PublicEvolving,1
[FLINK-3158] Enforce maven version to be < 3.3 when building a release,1
[FLINK-3304] Making the Avro Schema serializable.This closes #1635,1
FLINK-2380: allow the specification of a default filesystem scheme in the flink configuration file.This closes #1524,2
[hotfix] Add Scala version suffix to flink-cep module,2
[FLINK-3296] Remove 'flushing' behavior of the OutputFormat support of the DataStream APIThis closes #1563,5
[hotfix] [docs] Complete sentences in cluster_execution.md,2
[hotfix] [streaming] Remove unused code fragment from DataStream.union() function.,1
[hotfix] [rocksdb] Update predefined RocksDB option profiles.,2
[hotfix] [streaming] Remove some unused internal classes,1
"[FLINK-3413] [streaming] Remove implicit Seq -> DataStream conversionBecause the implicit conversion creates a new ExecutionEnvironment, it leads tostrange errors when used withing programs with more than one source.",1
[hotfix] [streaming] Add check in StreamRecord for reserved timestamp values,1
[FLINK-3308] [py] Remove debug mode,0
"[FLINK-3420] [api-breaking] Remove utility functions 'readTextFileWithValue' and 'readFileOfPrimitives' from StreamExecutionEnvironmentThese methods are highly specific for very niche cases of bounded data stream processing.As such, the disadvantages (bloat and lock the API, lock the development into support) outweigh the benefit.This closes #1648",1
"[FLINK-3243] Fix Interplay of TimeCharacteristic and Time WindowsThis adds dedicated WindowAssigners for processing time and event time.timeWindow() and timeWindowAll() respect the TimeCharacteristic seton the StreamExecutionEnvironment.This will make the easy stuff easy, i.e. using time windows and quicklyswitching the time characteristic. Users will then have the flexibilityto mix different kinds of window assigners in their job.This also expands the translation tests to verify that the correctwindow operators are instantiated.",1
"[FLINK-3403] Create Section ""Working with Time"" in Streaming Guide",1
[FLINK-3402] Refactor Common Parts of Stream/Batch Documentation,2
Add (basic) RocksDB State Backend Documentation,2
[FLINK-3379] [FLINK-3415] [streaming] Refactor TimestampExtractor into two separate classes - one class handled periodic watermarks - the other class handled watermarks triggered by elementsThis also makes sure that any timestamp assigner / watermark generators cannot generatenegative watermarksThis closes #1646,1
"[FLINK-3401] [streaming] [api breaking] AscendingTimestampExtractor only logs violations of ascending timestamp order.The user can also explicitly set an 'IgnoringHandler' or a 'FailingHandler', which do nothing on violations,respectively fail hard.",0
[FLINK-3299] Remove ApplicationID from EnvironmentThis closes #1642.,4
[hotfix] Fixes to flink-annotations JavaDocs,2
[hotfix] Properly declare ComplexIntegrationTest as an Integration Test Case,3
[FLINK-3413] [streaming] Make implicit conversions from Java DataStream to Scala DataStream explicitThis also clean up a lot of JavaDocs in various Scala DataStream API classes.,5
[FLINK-3421] [streaming scala] Remove unneeded ClassTag context bounds,4
"[FLINK-3419] [streaming] Drop 'partitionByHash' function, subsumed by 'keyBy()'",1
[hotfix] Auto-select actor system port in TestingCluster to prevent port collisions,3
"[FLINK-3430] Remove ""no POJO"" warning in TypeAnalyzerThis closes #1655",2
"[FLINK-3400] Move RocksDB Copy Utils to flink-streaming-javaThey are not specific to RocksDB, just utilities for copying localfolders to/from HDFS. Moving them to flink-streaming-java means thatthey are always in the classpath of the TaskManager, not only in theuser-code jar when using RocksDB. If they are only in the user-code jarthe external process runner cannot find the class files, leading toClassNotFoundExceptions.",2
[FLINK-3436] Remove ComplexIntegrationITCase,4
[FLINK-3423] [tests] Fixed ExternalProcessRunnerTest on WindowsThis closes #1650,3
[FLINK-3424] [tests] Close InputStream in FileStateBackendTest#validateBytesInStreamThis closes #1653,5
[hotfix] [tests] Increase timeouts in WebFrontendITCase for stability on CI infrastructure,5
[docs] fix typos in quickstart and CEP docsThis closes #1663,2
[FLINK-3368][Kafka 0.8] Handle leader changes in Kafka Consumer.,4
[FLINK-3386] Ensure Flink Kafka 0.8 is correctly using 'auto.offset.reset',1
[FLINK-3368][Kafka 0.8] Some improvements to the Legacy Fetcher,1
[FLINK-3386][FLINK-3368][Kafka 0.8] Cleanup Kafka Connector- Remove Guava dependency- Remove unused methods- Move ZKString Serializer- Add user-friendly error messages when parsing argumentsThis closes #1623 and closes #1672,0
[FLINK-3381] [runtime] Handle ConnectionLoss in ZooKeeper test util,3
[tests] Try to improve CI test stabilitySquashes the following commits:- [tests] Wait for task managers in JobManagerFailsITCase  Possible fix for: https://s3.amazonaws.com/archive.travis-ci.org/jobs/110235128/log.txt- [tests] Move ITCase from runtime to tests- [tests] Merge abstract and sub type class- [tests] Determine JobManagerProcess ports from logsThis closes #1676.,2
[FLINK-3446] [runtime-web] Don't trigger back pressure sample for archived jobThis closes #1673.,1
[hotfox] Fix javadoc of getState to comply with constructor changes,4
"[FLINK-3453] [runtime, runtime-web] Report partial stack trace sample for cleared tasksThis closes #1678.",1
"[FLINK-3248] add constructor params and generic ConnectionFactoryThis adds more default constructor parameters to the RMQSource. In addition,users may override the setupConnectionFactory() method to return their onwnconfigured factory.This closes #1670.",5
[cleanup] remove RMQTopology file,2
[FLINK-3453] [runtime] Fix TaskManagerTest stability,3
[FLINK-3439] Remove final Long.MAX_VALUE Watermark in StreamSource,4
"[FLINK-3450] Duplicate TypeSerializer in StateDescriptor.writeObjectThe StateDescriptor can be serializer asynchronously in case ofasynchronous checkpoints. In that case two threads would try toconcurrently use the TypeSerializer: The normal state updating and thecheckpoint serialization. If the TypeSerializer is a KryoSerializer thiscan lead to problems. Therefore the need to duplicate it before using in""writeObject"".",1
[FLINK-3455] Bump Kafka to 0.9.0.1 and 0.8.2.2This closes #1684,2
[hotfix] [runtime] Fix processing unmatched build-side when all buckets spilled,0
[FLINK-3385] [runtime] Fix outer join skipping unprobed partitionsThis closes #1680,0
FLINK-2213: Makes the number of vcores per YARN container configurable.This closes #1588,5
[FLINK-3440][Kafka 0.8] Commit also offsets retrieved from Kafka into the OffsetStore (ZK)This closes #1692,1
[tests] Add log statements to JobManagerHAJobGraphRecoveryITCaseAdds further log statements in order to improve debuggability ofJobManagerHAJobGraphRecoveryITCase.Hope to help for debugging:- hpick://s3.amazonaws.com/archive.travis-ci.org/jobs/110095304/log.txt- https://s3.amazonaws.com/archive.travis-ci.org/jobs/110085371/log.txt,5
[runtime] Log restart strategy on job submission,2
[FLINK-3416] [py] Support for spaces in flink pathThis closes #1674.,2
"[FLINK-3458] [build] Disable shade-flink execution in flink-shaded-hadoopThe shade-flink execution of the parent pom caused the problem that the guavadependencies were relocated twice in the flink-shaded-hadoop jar. In order toavoid this, this patch disables the shade-flink execution.This closes #1681.",2
"[FLINK-3459] [build] Fix conflicting dependencies commons-collections, commons-beanutils and commons-beanutils-coreThe Hadoop dependencies have a dependency on commons-configuration which pulls in transitively the commons-collection, commons-beanutils and common-beanutils-core depedencies. Commons-beanutils and commons-collection contain classes which live in the same namespace. They are also binary compatible but not binary identical. This is a problem for the sbt assembly plugin which checks for binary identity. In order to solve the problem, we bump the commons-configuration version to 1.7 so that only commons-beanutils is pulled in. This is necessary, because the transitive promotion of dependencies of the shade plugin only excludes the commons-beanutils dependency only from the directly depending dependency. All parent dependencies won't have the exclusion. This is a problem for SBT which will pull the dependency as part of one of the parents, then. Moreover, we replace commons-beanutils by commons-beanutils-bean-collections which contains only the non-conflicting classes wrt commons-collections.This closes #1682.",5
"[FLINK-3460] [build] Set Flink dependencies in flink-streaming-connectors, flink-batch-connectors, cep, gelly and flink-ml modules to providedThe flink-streaming-connectors all depend on flink-streaming-java in compile scope.This entails that this dependency is always pulled in, when you build a fat jar. Bysetting this dependency to provided, this will be avoided. Furthermore, the connectorsare always used in conjunction with flink-streaming-java. This means that you willalways have an explicit dependency import of flink-streaming-java in your build script.This allows you to run your program locally but it is also easy to exclude the dependencyfrom being included in the fat jar by setting it to provided, as well.This closes #1683.",1
"[FLINK-3438] ExternalProcessRunner fails to detect ClassNotFound exception because of locale settings[FLINK-3438] Improved solution, no workaround[FLINK-3438] Change: a faulty process now causes a RuntimeException to be thrownThis closes #1665.",1
[FLINK-3433] AvroOutputFormat#readObject uses readFully()This closes #1666,1
[FLINK-3410] [restart] Choose NoRestart strategy if the number of retries is set to 0Add test caseThis closes #1643.,1
[FLINK-3464] [docs] Add SBT template documentation to the quickstart documentationThis closes #1688.,2
[FLINK-3425] FileOutputFormat closes outStream in case of failureThis closes #1652.,0
[docs] Fix typos in jobmanager HA documentation,2
[hotfix][release script] make sure the quickstart depends on scala 2.10,1
"[FLINK-3418] Don't run RocksDB copy utils in external processThis was causing to many problems with security tokens and yarn. Now,let the RocksDB backup run in a thread butdon't interrupt these Threads anymore on closing. The Threads will closethemselves because the copy operation will fail because of aFileNotFoundException when the state directories are being cleaned up.This also removes the ExternalProcessRunner because it is not neededanymore and using it causes too many headaches.This closes #1687.",1
[FLINK-3426] Fix JobManagerLeader[Re]ElectionTest.testleaderElection on Windowsremoved unused importuse new Path().toUri()added missing bracesThis closes #1651.,1
"[FLINK-3315] Fix Slot Sharing in Streaming APIThis changes slot sharing settings to single methodslotSharingGroup(String) on DataStream.Operations inherit the slot sharing group of the input if all inputoperations are in the same slot sharing group.The default slot sharing group is ""default"" this can also be explicitlyset using slotSharingGroup(""default""). This overrides the inheritingbehaviour.This closes #1641.",1
[FLINK-2021] Rework examples to use ParameterToolThis closes #1581,2
[dist] Link plan visualizer to project website,2
[FLINK-3478] [runtime-web] Don't serve files outside of web folderThis closes #1697,2
[FLINK-3483] [runtime-web] Bump dagre-d3 version to 0.4.17,2
[FLINK-3490] Bump Chill version to 0.7.4This closes #1701,2
[hotfix] Add logging for RocksDB backup durations,5
[FLINK-3499] [runtime] Clear ZooKeeper references on recoveryThis closes #1707.,1
"[docs] Move state and windows guide to separate pages- Move ""Windowing"" to separate page  - Make ""Working with Time"" sub page of ""Windowing""  - Fix link in ""Working with Time"" page- Move ""Working with State"" page to ""Fault Tolerance""  - Add Table of Contents to State Backends page  - Hierarchical restart strategies sections- CEP => Event Processing (CEP)This closes #1705.",1
"[FLINK-3435] [streaming] Proparly separate IngestionTime and EventTime  - IngestionTime now only auto-generates watermarks  - EventTime does not auto-generate ingestion watermarksThis also removes the ""ExecutionConfig.areTimestampsEnabled()"" flag.This closes #1699",5
[hotfix] Expose current watermark to TriggersThis closes #1706,0
"[FLINK-3500] [test] Fix possible instability in ExecutionGraphRestartTestAfter restart of the execution graph, the test driver waits for thegraph to assign the new executions in a loop. If switchToRunning()is called multiple times in this loop, the job is canceled. Thiscould happen, if one execution had its resource assigned and calledswitchToRunning(), but the other didn't. In this case, the completeloop was retried and switchToRunning() was called again.This closes #1708.",1
[hotfix][build scripts] Ensure that the hadoop1 version is set properly everywhere,1
"[hotfix] [cep] Fix serialization problem and single state NFAsThe start computation states have a null event associated. When serializing these statesone has to check whether the event is null or not, because not all serializer can handlenull values.A single state NFA failed to compute a matching pattern because it was regarded as aterminal state in the pattern extraction algorithm. By letting the first states startwith a two level dewey number this problem is fixed.",0
[FLINK-3513] [runtime] Fix interplay of automatic Operator UID and Changing name of WindowOperator,1
[FLINK-3512] [runtime] Savepoint backend should not revert to 'jobmanager'This closes #1712.,4
[FLINK-3510] [cep] Fix typo in Pattern class level comment,2
[FLINK-3485][core] implement toString for SerializedListAccumulatorThe change improves the display of SerializedListAccumulators in the webinterface by displaying the number of elements contained in theaccumulator instead of the hash code of the object.This closes #1717.,1
[FLINK-3437] [web-dashboard] Fix UI router state for job planTransitive dependency EvEmitter updated to 1.0.2This closes #1661,5
[FLINK-3340] [runtime] Fix object juggling in driversA second attempt at object swapping in reduce drivers.This closes #1626,0
[FLINK-3509] Update Hadoop minor versions to latest & sync travis and release scriptsThis closes #1713,3
[FLINK-3434] Prevent NPE in ClientFrontend#getClient()This closes #1695,1
[FLINK-3449] createInput() no longer swallows exceptionThis closes #1675,1
"[FLINK-3520] [streaming] Periodic watermark operator emits current watermark in close()This makes sure that for bounded data sets with watermarks, the final elements get properly reflected in window results.",1
[hotfix][deploy script] Deploy 'release-*' branches as well,0
[FLINK-3518] Stale docs for quickstart setup* Explicitly state to stop the local environmentThis closes #1718,1
[hotfix] fix PageRank example to run with no args; some doc fixesThis closes #1714,0
"[FLINK-3390] [runtime, tests] Restore savepoint path on ExecutionGraph restartTemporary work around to restore initial state on failure during recovery asrequired by a user. Will be superseded by FLINK-3397 with better handling ofcheckpoint and savepoint restoring.A failure during recovery resulted in restarting a job without its savepointstate. This temporary work around makes sure that if the savepoint coordinatorever restored a savepoint and there was no checkpoint after the savepoint,the savepoint state will be restored again.This closes #1720.",1
[hotfix] Make DataStream property methods properly ScalaeskThis also includes some minor cleanupsThis closes #1689,4
[FLINK-3522] [storm compat] PrintSampleStream prints a proper message when involked without arguments,2
[FLINK-3525] [runtime] Fix call to super.close() in TimestampsAndPeriodicWatermarksOperator,1
[hotfix] Remove remaining unused files from the old standalone web client,2
[license] Update LICENSE file for the latest version,3
[hotfix] [build] Disable exclusion rules when using build-jar maven profile.This closes #1719,2
"[FLINK-3511] [gelly] Introduce flink-gelly-examples moduleThe new flink-gelly-examples module contains all Java and Scala Gelly examples. The modulecontains compile scope dependencies on flink-java, flink-scala and flink-clients so thatthe examples can be conveniently run from within the IDE.",1
[FLINK-3511] [avro] Move avro examples to test scope,3
[FLINK-3511] [hadoop-compatibility] Move hadoop-compatibility examples to test scope,3
[FLINK-3511] [jdbc] Move jdbc examples to test scope and add flink-clients dependency,2
"[FLINK-3511] [nifi, elasticsearch] Move nifi and elasticsearch examples to test scope",3
[FLINK-3511] [twitter] Move twitter examples to test scopeThis closes #1725,3
[FLINK-3526] [streaming] Fix Processing Time Window Assigner and TriggerThis closes #1727,0
[FLINK-3521] Make Iterable part of method signature for WindowFunctionThis closes #1723,1
"[FLINK-3528] Add FoldingWindowBuffer for Non-Keyed WindowsThis makes AllWindowedStream.fold() take constant space, just like thekeyed WindowOperator.Also this adds a new test case in EventTimeAllWindowCheckpointingITCaseto verify that the FoldingWindowBuffer works.This also renames the preexisting window buffers to ReducingWindowBufferand ListWindowBuffer to make the naming scheme consistent.",1
[FLINK-3527] Add Scala DataStream.transform()This implicitly adds KeyedStream.transform() and also explicitlyConnectedStreams.transform().This also removes the transform exclusions from the API completenesstests.,3
[docs] fix typos in Basic Concepts documentationCloses #1730,2
[FLINK-3461] [runtime] Remove redundant check in ZooKeeperLeaderElectionServiceThis closes #1700.,4
[FLINK-3461] [runtime] Fix space indentation in ZooKeeperLeaderElectionService,0
[FLINK-3517] [dist] Only count active PIDs in start scriptThis closes #1716.,2
Bump version to 1.1-SNAPSHOT,5
[FLINK-3532] [gelly] Fix artifact ID of flink-gelly-examples moduleThe current flink-gelly-examples artifact id wrongly used an underscore to separateexamples from flink-gelly. This commit replaces the underscore with an hyphen.This closes #1731.,2
[hotfix] Properly copy stream record in ReducingWindowBuffer and FoldingWindowBuffer,0
[docs] Update readme with current feature list and streaming example,5
[FLINK-3534] [runtime] Prevent canceling Execution from failingThis closes #1735.,0
[FLINK-3535] [runtime-web] Decrease log verbosity of StackTraceSampleCoordinatorThis closes #1732.,2
[FLINK-3538] [api-breaking] Streamline Scala DataStream.join/coGroupThis enforces that the user always has to specify keys for both inputsbefore .window() can be called.,1
"[FLINK-3536] Make clearer distinction between event time and processing timeThis brings it more in line with *ProcessingTimeWindows and makes itclear what type of window assigner it is.The old name, i.e. SlidingTimeWindows and TumblingTimeWindows is stillavailable but deprecated.",1
[FLINK-3540] Shade org.htrace in flink-shaded-hadoop to get rid of its Guava dependencyThis closes #1737,1
[FLINK-3548] [api-breaking] Remove unnecessary generic parameter from SingleOutputStreamOperator,1
[docs] fix readme typos; use the same scala style in the examplesThis closes #1743,1
[FLINK-3556] [runtime] Remove false check in HA blob store configurationThis closes #1749.,5
[FLINK-3559] [dist] Don't print INFO if no active processThis closes #1751.,5
"[FLINK-3557] [stream, scala] Introduce secondary parameter list for fold functionThe fold API call takes an initial value as well as a fold function. In Scala it is possibleto provide an anonymous function. In order to easily support multi line anonymous functionsas well as being consistent with Scala's collection API, this PR adds another parameter listto the fold API call, which contains the fold function parameter.Insert spaces between first parameter list and curly braces of anonymous functionThis closes #1748.",1
[FLINK-3554] [streaming] Emit a MAX Watermark after finite sources finishedThis closes #1750,5
[hotfix] Removed deprecated and commented code in SourceFunctionTest,3
[FLINK-2788] [apis] Add TypeHint class to allow type-safe generic type parsingThis closes #1744,1
[hotfix] [docs] Remove Java example code from Scala docs,2
[FLINK-3422][streaming][api-breaking] Scramble HashPartitioner hashes.,4
[FLINK-3422][streaming] Update tests reliant on hashingCloses #1685,3
"[maven] add module to force execution of Shade pluginThis ensures that all properties of the root pom are properlyresolved by running the Shade plugin. Thus, our root pom does not haveto depend on a Scala version just because it holds the Scala versionproperties.This closes #1755",1
[hotfix] Fix JavaDocs for SourceFunction,1
[FLINK-3496] Fix ML test discovery on WindowsThis closes #1710.,3
[FLINK-3432] Fixed ZookeeperOffsethandlerTest on WindowsThis closes #1664.,3
[FLINK-3484] Add setSlotSharingGroup documentation,2
"[FLINK-3570] [runtime] Use InetAddress.getLocalHost() as heuristic to find local addressThe ConnectionUtils.findAddressUsingStrategy method tries to find out the local address which isaccessible by other machines of the cluster. It tries to connect to a specified address to do so.In case that the no connection could be established, it uses an heuristic. Before it randomlypicked a NetworkInterface which is bound to an Inet4Address, not a loop back address and not alink local address. In most cases it makes more sense to default to theInetAddress.getLocalHost() address instead. This PR replaces the old heuristic with simplyreturning the InetAddress.getLocalHost(). This of course requires that the system on which Flinkis running, is properly configured.This closes #1758.",5
[hotfix] Make 'force-shading' deployable,1
[FLINK-3569] [build] Adjust test cases due to shading plugin base directory changes,4
[FLINK-3578] [streaming scala] Support RichFunctions for Scala WindowFunction and AllWindowFunctionThis also consolidates the various wrapper classes for fold() and reduce() functions.This closes #1765,1
[docs] Active tab caption is now displaying blueThis closes #1763,2
[docs] Fix javascript exception caused by disqus and fix typos in cluster execution.This closes #1756,2
[FLINK-3575] [docs] Update 'Working With State' section in docsThis closes #1760,2
"[docs] Add documentation about Event Time, Timestamp Assigners, Watermark Generation",2
[FLINK-3491] [tests] Prevent URIException in HDFSCopyTest and disable HDFSCopyUtilitiesTest on WindowsThis closes #1703,3
[FLINK-3495] [tests] Disable RocksDB tests on WindowsThis closes #1711,3
[FLINK-3566] [FLINK-3563] [core] TypeExtraction input type validation fixesThis closes #1759,0
[FLINK-3550] [examples] Rework WindowJoin to properly demonstrate continuous window joins (Java + Scala),1
[FLINK-3552] [examples] Add a properly windowed word count reading from a socket (Java + Scala),1
[FLINK-3533] [docs] fix broken links to examples and cluster execution in Gelly guide,2
"[docs] update ""build from source"" page",5
[docs] Move connectors page to batch guide,4
"[FLINK-3383] move snapshot deployment from Travis CI to ASF JenkinsDeployment will be handled by ASF's Jenkins instances which triggerthe deployment of snapshot versions every night. This way, we have notonly separated deployment from CI testing, but also improved thereliability of the test and deployment infrastructure.- remove Travis dependency from Maven deploy script- set force-dependency version to Flink versionThis assures deployment works when only credentials for the snapshotdeployment are available. Previously, we deployed snapshots with releasecredentials. These credentials would be over-privileged.- remove old credentials from Travis config fileThis closes #1619.",2
[FLINK-3585][tools] let deploy scripts work with spaces in paths,1
[FLINK-3309] [py] Resolve Maven warnings,2
[FLINK-3321] TupleSerializer.getLength() can return fixed-length sizeThis closes #1654.,0
[FLINK-3169] Remove Key classThis closes #1667.,4
[hotfix] Improve exception message in TaskManagerTest#testRemotePartitionNotFoundThis closes #1658,3
[FLINK-3883] fail immediately on deploy errors,0
[FLINK-3591] Replace Quickstart K-Means Example by Streaming Example,2
[FLINK-3592] [docs] Update setup quickstart,1
[docs] Update stack figure on docs start page,2
[docs] Add first steps to docs start page,2
"[tests] Add TestLogger to StreamCheckpointNotifierITCaseSaw this one failing, but it's impossible to get any insightfrom the logs, because you can't tell what is what.",1
[hotfix] Rename UnrecoverableException to SuppressRestartsException,0
"[FLINK-3396] [runtime] Suppress job restart if adding to job graph store failsA failure to add the job graph to the submitted job graphs in ZooKeepercould lead to a job restart w/o the job graph ever being added to thesubmitted graphs store. Although the job submission was not ACK'd inthis case before, it received job status messages. Now the job willnot be ACK'd as before, but the job will be failed.This closes #1657.",0
[docs] Add description and illustration about Watermarks in streams,1
[docs] Remove 'Working with Time' pageSuperseded by new 'Event Time' section.,1
[FLINK-3561] remove unused timestampsEnabled flag,0
[FLINK-3577] [docs] Display anchor links when hovering over headers.This closes #1762,2
[quickstart] fix links to documentation,2
[build] Consolidate scala checkstyle usage and update version to 0.8.0Consolidation is done via plugin management.Closes #1753,5
"[FLINK-3594] [runtime] Make sure exceptions during checkpoints are handled properly  - For the asynchronous trigger, exceptions are suppressed if the task is no longer running  - The task cannot go to ""not running"" while a checkpoint is still in progress.",1
"[hotfix] [runtime] Guard async recovery operation in try-catchIf something fails during a RecoverJobGraph, the logs don'tshow anything.",2
[hotfix] [tests] Remove verbose logging in SavepointITCase,2
"[FLINK-2671] [tests] Fix test instability in StreamCheckpointNotifierITCaseAlso add more logging, to help future test debugging",0
[docs] Fix netcat arguments in Setup quickstartThis closes #1781.,1
[FLINK-3327] ExecutionConfig to JobGraphThis closes #1583,5
[tests] Fix unstable test WebFrontendITCase,3
[FLINK-3590] [jdbc] Hide derby log in JDBC testsThis closes #1773,3
[FLINK-3472] [jdbc] Give a better exception if jdbc column has a null valueThis closes #1772,5
[FLINK-3467] [runtime] Remove superfluous objects from DataSourceTask.invokeThis closes #1691,5
[hotfix] [docs] Remove unnecessary whitespace in start-local.sh command,4
[FLINK-3333] [docs] Improve documentation of DataSet object-reuse modes.This closes #1721,1
[FLINK-3583] User configuration visible in webdashboard when job is runnnig,1
[FLINK-2523] Make the task cancellation interval configurableThis closes #1662,5
[FLINK-3272] [Gelly] Generic value in Connected Components* Updated scather-gather and GSA implementation * tests* updated documentationThis closes #1785,2
[FLINK-3621] [docs] Improve documentation of memory configuration parametersThis closes #1801,2
[FLINK-3620] [streaming] Remove DbStateBackendCloses #1800,5
[FLINK-1964] Reimplement TwitterSourceThis closes #1796This closes #666,2
[hotfix][docs] fs.hdfs.hadoopconf typo,2
[hotfix][examples] Add zookeeper.connect to usage line,1
"[FLINK-3629] Fix quick start description for the "".timeWindow()"" function call",1
[hotfix] [docs] Fix typo 'seperate'This closes #1810.,2
[hotfix] Fix typo 'JobManger'This closes #1812.,2
"[hotfix] [docs] Fix broken link for time.htm, changed to event_time.htmlThis closes #1816.",4
[FLINK-3223] Translate Table API calls to Calcite RelNodes.This is an intermediate step to port the Table API on top of Calcite (FLINK-3221).This commit:- Adds Calcite as dependency to flink-table.- Translates Table API calls directly into Calcite RelNodes.- Modifies tests to check only the translation into logical plans but not the execution of Table API queries.- Deactivates a few tests that are not supported yet.- Removes a lot of the former Table API translation code.- Removes bitwise operators from the Table API.,1
Renamed Table.scala to table.scala,2
[FLINK-3282] add FlinkRelNode interface.,2
[FLINK-3225] Implemented optimization of Table API queries via Calcite- added logical Flink nodes and translation rules- added stubs for DataSet translation rules- ported DataSetNodes to Scala- reactivated tests and added expected NotImplementedError,0
[FLINK-3225] Enforce translation to DataSetNodes,5
[FLINK-3226] Add DataSet scan and  conversion to DataSet[Row]This closes #1579.,5
[FLINK-3226] Implement a CodeGenerator for an efficient translation to DataSet programsThis closes #1595,5
[Flink-3226] Translate logical plan FlinkRels into physical plan DataSetRels.,5
"[FLINK-3226] implement GroupReduce translation; enable tests for supported operationsSquashes the following commits:- Compute average as sum and count for byte, short and int type to avoid rounding errors- Move aggregation functions to org.apache.flink.table.runtime- Remove join-related changes- Change integer average aggregations to maintain sum and count- Long average uses a BigInteger sum",1
[FLINK-3226] implement getUniqueName method in TranslationContextThis closes #1600 and #1567,1
[FLINK-3226] Translate logical joins to physicalThis closes #1632,2
[FLINK-3226] Translation from and to POJOs for CodeGeneratorThis closes #1624,2
[FLINK-3226] Casting support for arithmetic operators,1
[FLINK-3226] Translation of explicit casting,2
[FLINK-3226] Translation of scalar function substring(),1
[FLINK-3508] Add more test cases to verify the rules of logical plan optimization.,2
"[FLINK-3463] implement calc translation- remove FlinkFilter, FlinkProject and associated rules- deactivate FilterReduceExpressionsRule and ProjectReduceExpressionsRule  (covered by CalcReduceExpressions)This closes #1696",2
[FLINK-3226] Improvements for expected typesThis closes #1709,1
[FLINK-3482] implement union translation- implement custom JoinUnionTransposeRulesbecause Calcite's only match with LogicalUnionThis closes #1715,2
[FLINK-3502] Add test case. Bug was resolved by a previous commit.,0
[FLINK-3537] Fix code gen for disjunctions.This closes #1733,0
[FLINK-3504] Fix join translation. Equality predicates may only reference fields.Catch Calcite planner exception and rethrow with additional error messageThis closes #1734,1
[FLINK-3486] [tableAPI] Fix broken renaming of all fields.,0
"[FLINK-3498] Implement TRIM, SUBSTRING as reference design for Table API",2
[FLINK-3567] Fix selection on grouping. Only grouping keys or aggregates allowed.This closes #1761,1
[FLINK-3564] [table] Implement distinct() for Table APIThis closes #1754,2
[FLINK-3474]: Enable partial aggregate in Table API-- add new Aggregate interface which support partial aggregate-- implement SUM/COUNT/AVG/MIN/MAX aggregate functions implementation-- sorted-based runtime supportthis closes #1746,1
[FLINK-3573] [table] Implement more String functions for Table API,1
[FLINK-3593][tableAPI] Fix failing DistinctITCase,0
[FLINK-3596] DataSet RelNode refactoring- remove the intermediate flink relnode layer and the dataset rules- move code generation from rules to DataSet nodes- remove unused DataSete nodes- move code generation from join rule to DataSetJoin node- merge DataSetMap and DataSetReduce into  DataSetAggregate,5
[FLINK-3596] Finalized DataSet RelNode refactoring,4
[FLINK-3604][tableAPI] Enable and fix ignored tests.This closes #1782.,3
[FLINK-3597][tableAPI] Set relational expressions as DataSet operator names.,1
[FLINK-3603][tableAPI] Enable and fix Table API explain.This closes #1783,0
[FLINK-3574] Implement math functions for Table APIThis closes #1775.,1
[FLINK-3489] TableAPI refactoring and cleanupThis closes #1789,4
[FLINK-3612] remove PageRank Table exampleadd a type conversion mapper after aggregations if the expected type is not a RowThis closes #1793,1
[FLINK-3609] [tableAPI] Reorganize selection of optimization rulesThis closes #1797,2
[hotFix] [tableAPI] Improve naming of DataSetRelNodesThis closes #1799,5
[FLINK-3503] [tableAPI] Add cost model for DataSet RelNodes to improve plan selection.This closes #1798,1
[docs][tableAPI] update TableAPI docs,2
[tableAPI] Cleaned up tests,3
[FLINK-3622] [tableAPI] Improve execeptions for invalid joins,1
[tableAPI] fix JoinITCase non-equality tests,3
[FLINK-3636] Add ThrottledIterator to WindowJoin jar,2
[hotfix] Fix ContinuousProcessingTimeTrigger,0
[hotfix][Kafka 0.9] Avoid committing offsets to closed consumer,1
[FLINK-3207] [gelly] add pregel iteration abstraction to gelly,1
[FLINK-3207] [gelly] add a pregel SSSP example with combiner,1
[FLINK-3207] [gelly] add compiler and translation testsAdd the vertex-centric abstraction to the gelly guideand a comparison among all iteration models.,3
[FLINK-3207] [gelly] add pregel methods to gelly-scalaThis closes #1575,1
[hotfix] [docs] Update python.mdThis closes #1814.,5
Add JavaDoc to StreamTask.checkTimerException to clarify what it does,2
[FLINK-3645] [tests] Force HDFSCopyUtilitiesTest to use local file systemThis closes #1825.,5
[FLINK-3611] [docs] Correct link in CONTRIBUTING.mdThis closes #1786,2
[FLINK-3602] Fix TypeExtractor and add support for recursive typesThis closes #1787,1
[FLINK-3631] [tableAPI] Check type compatibility for comparison expressions in CodeGeneratorThis closes #1823,2
[FLINK-3179] [dataSet][optimizer] Log a WARN message if combiner is not added in front of PartitionOperatorThis closes #1822This closes #1553,1
FLINK-3115: Update ElasticSearch connector to 2.xThis closes #1792,5
[FLINK-2445] Add tests for HadoopOutputFormatsThis closes #1486,3
[FLINK-2445] Improve HadoopOutputFormatTestsThis closes #1628,3
[FLINK-2444] Add tests for HadoopInputFormatsThis closes #1628,3
[FLINK-2997] [dataSet] Add support for range partitioning with custom data distribution.This closes #1776,5
[FLINK-3653] [docs] Add recovery.zookeeper.storageDir docs to config pageThis closes #1828.,1
[FLINK-3663] [kafka] Fix logPartitionInfo log statementThis closes #1835.,2
[FLINK-3658][Kafka] Allow producing into multiple topicsThis closes #1832,1
[FLINK-2935] [scala-shell] Allow Scala shell to connect Flink cluster on YARN  - Remove duplicated parseHostPortAddress method (Move it to ClientUtils class)  - Refactor FlinkShell classThis closes #1500.,2
[FLINK-3639] add methods for registering datasets and tables in the TableEnvironmentThis closes #1827,5
[hotfix] [docs] Fix a couple of typos in YARN documentationThis closes #1836.,2
[FLINK-3544][runtime] introduce ResourceManager componentThis closes #1741.,2
[FLINK-3545][yarn] integrate ResourceManager support,1
[FLINK-3547] add support for DataStreamTable- add Java and Scala stream translators- add DataStream rules for calc and scan- add tests and streaming test utils- add support for streaming union- move code generation from the calc rule to the calc nodeand remove unnecessary rules- refactoring to reuse code between dataset and datastream translationThis closes #1820,5
[FLINK-3676][docs] sync docs with the WebClient removal,4
"[FLINK-3651] Fix faulty RollingSink RestoreOn restore the sink for subtask index i has to cleanup leftover filesfor subtask i. The pattern used for checking this was not properlyterminated so the sink for subtask 1 would, for example, delete somefiles for sink i=11. This would lead to data loss.This closes #1830",5
[hotfix] [cep] Add sanity check for erroneously pruned elements,1
"[FLINK-3681] [cep, typeextractor] Generalize TypeExtractor to support more lambdasThe TypeExtractor.getUnaryOperatorReturnType and TypeExtractor.getBinaryOperatorReturnTypemethods have been extended to support positional arguments for the input types. This allowsto support parameterized types as Java 8 lambda arguments where the input type is not specifiedby the first type argument (e.g. Map<String, T>). This also solves the problem that the CEPlibrary did not support Java 8 lambdas as select functions.This closes #1840.",1
[FLINK-3682] [cep] Assign processing timestamp in CEP operatorsThis PR fixes the problem that the CEP operators did not assign the wall clock timeas the timestamp to incoming in StreamRecords if the TimeCharacteristic was set toProcessingTime. Processing element with a Long.MIN_VALUE timestamp can lead to underflowsin the NFA if a positive window length is subtracted from the timestamp. For thisunderflow a sanity check has been added to notify the user with an exception about it.This closes #1841.,1
[FLINK-3684] [cep] Add proper watermark emission to CEP operatorsThis closes #1842.,1
[hotfix] [docs] Update CEP documentation,2
"[FLINK-3678] [dist, docs] Make Flink logs directory configurable* Edit config.sh* Document the newly defined log directory configuration keyThis closes #1837",5
"[FLINK-3633] Fix user code de/serialization in ExecutionConfigFLINK-3327 moved the ExecutionConfig directly to the JobGraph so that it was serializedand deserialized using the system class loader when sending a SubmitJob message to theJobManager. This is problematic since the ExecutionConfig can contain user code classwhich require a user code class loader for deserialization. In order to circumvent theproblem, a UserCodeValue class was introduced which automatically sends the wrapped valueas a byte array. On the receiving side, the wrapped value has to be explicitly deserializedproviding a class loader.To test the feature the ScalaShellITCase.testSubmissionOfExternalLibrary was adaptedto register org.apache.flink.ml.math.Vector at the ExecutionConfig.This commit also re-introduces the removed ExecutionConfig.CONFIG_KEY key, so thatversion 1.1 does not break the API.Updating documentation to include new task.cancellation-interval parameterMake globalJobParameters a UserCodeValue, fix wrong exception message, fix formatting regressionRework serialization of user code object in ExecutionConfigDue to the tight coupling of the ExecutionConfig and multiple Flink components(e.g. PojoSerializer) the automatic serialization and manual deserialization ofuser code objects via the UserCodeValue class caused problems. In order to minimizethe impact of the changes, I changed the serialization strategy to an explicit one.One has to call serializeUserCode to store the user code objects in a SerializeValueobject and nulling corresponding member fields. If that is not done, then it isassumed that the object is deserialized using a user code class loader.Add test case for user code types in ExecutionConfigThis closes #1818.",5
"[docs] Add ""concepts"" documentation page",2
[FLINK-3689] fix shutdown of JM when RM is not availableThis closes #1847.,0
[docs] Add top links and sub headings to Concepts,2
[docs] Add top-nav link to concepts,2
[docs] Rename Guides->Concepts to API Concepts,2
"[docs] Move quickstart top nav link- User reported too wide page with quickstart and concepts- Moved setup, Scala, Java quickstarts to setup section- Moved wikiedits example to streaming guide- Quickstarts are linked as before from the project page",2
[FLINK-3635] [connectors] Potential null deference in TwitterExample#SelectEnglishAndTokenizeFlatMap#flatMapThis closes #1845,2
[FLINK-3638][docs] fix default task manager port,0
[hotfix][examples] Remove System.exit() from Kafka example,5
[FLINK-3524] [kafka] Add JSONDeserializationSchemaThis closes #1834,5
"[FLINK-3571] [tests] Add debug output to SavepointITCase- If savepoint triggering fails, we only get a ClassCastException,  which is not helpful for debugging (see [1])- Adds more output in case of unexpected responses[1] https://issues.apache.org/jira/browse/FLINK-3571",2
[FLINK-3693] [tests] Wait for task manager to register before submitting job- This test could fail when the job was submitted before the task manager  connects to the leading job manager (see [1])[1] https://s3.amazonaws.com/archive.travis-ci.org/jobs/120072682/log.txt,5
"[hotfix] Fix some typos in ""concepts"" doc",2
[FLINK-3619] [runtime] Increase timeout in SavepointCoordinatorTest- Timeout of 5s seems to be too aggressive for some Travis runs [1][1] https://s3.amazonaws.com/archive.travis-ci.org/jobs/120105003/log.txt,5
[docs] Remove JS from concepts page,4
[FLINK-3595] [runtime] Eagerly destroy buffer pools on cancellingThis closes #1780.,1
[FLINK-1159] [Scala API] Add API extension to support case-style anonymous functionsThis closes #1704,1
[hotfix] Updates the AssignerWithPunctuatedWatermarks and the AssignerWithPeriodicWatermarks javadocsThis closes #1811,2
"[FLINK-3623] [runtime] Adjust MurmurHash AlgorithmFix ""hash *= n"" to be ""hash = hash * m + n"".This closes #1806",0
[hotfix] [core] Improve error messages of the Java Closure Cleaner,4
[FLINK-3614] Remove Non-Keyed Window OperatorInstead we use a dummy KeySelector and the regular WindowOperator now.,1
"[FLINK-3174] Add MergingWindowAssigner and SessionWindowsThis introduces MergingWindowAssigner, an extension of WindowAssignerthat can merge windows. When using a MergingWindowAssigner theWindowOperator eagerly merges windows when processing elements.For keeping track of in-flight windows and for merging windows this addsMergingWindowSet, this keeps track of windows per key.Only when using a MergingWindowAssigners is the more costly merginglogic used in the WindowOperator.For triggers there is a new method Trigger.onMerge() that notifies thetrigger of the new merged window. This allows the trigger to set a timerfor the newly merged window. Only triggers that return truefrom Trigger.canMerge() can be used with MergingWindowAssigner. Triggerhas default implementations for canMerge() and onMerge(), we returnfalse and onMerge() throws an Exception.This also adds AbstractStateBackend.mergePartitionedStates for mergingstate of several source namespaces into a target namespace. This is onlypossible for the newly introduced MergingState which is an extension ofAppendingState. Only ReducingState and ListState are MergingState whileFoldingState is now an AppendingState.This enables proper support for session windows.This also adds the EventTimeSessionWindows and ProcessingTimeSessionWindowswindow assigners and adapts an existing session example and adds test cases.",3
[FLINK-3283] Improve Kafka test stability,3
[docs] Add separate AWS setup page,1
[docs] Remove obsolete Flink on Tez figures,2
[docs] Fix broken links in Concepts,2
[docs] Add missing license to new page,1
"[FLINK-3689] do not shutdown test ActorSystemInstead of shutting down the ActorSystem created in the test, we simply send amessage upon executing the shutdown method of the JobManager, TaskManager, andResourceManager. This ensures we can check for shutdown code execution withoutinterfering with the test.This closes #1852.",3
FLINK-3529 Add template for pull requests- link from CONTRIBUTING.md to PR template- add it to excluded file of rat pluginThis closes #1729.,2
"[FLINK-3637] Refactored output stream handling from RollingSink.The Writer interface now deals directly with filesystem and path, ratherthan the raw output stream.Since the RollingSink no longer has access to the raw output stream, itcannot directly determine the current size of the file. A getPos()method has been added to the Writer interface, so the RollingSink can.retrieve the current file size.Finally, flush() has been extended to return the offset that the filemust be truncated to at recovery.",1
[docs] Add back pressure monitoring page,1
[FLINK-2522] Streaming support for Flink-Scala-Shell,2
[FLINK-2522] improve welcome message of Scala shell for streamingThis closes #1412.,1
[FLINK-3523] [Storm-Compatibility] Added SplitStreamMapper to program to get rid of SplitStreamType wrapper - additionally reworked split ITCases   * unified to single test   * make Windows compatible (using tmp files)   * added test case for embedded splittingThis closes #1844,3
[hotfix] Fix EvictingWindowOperator to work with MergingWindowAssigner,1
[FLINK-3711][docs] Documentation of Scala fold()() uses correct syntaxCloses #1860,1
[FLINK-3654] Disable Write-Ahead-Log in RocksDB State,5
[FLINK-3697] Properly access type information for nested POJO key selectionThis closes #1851,5
[FLINK-3688] WindowOperator.trigger() does not emit Watermark anymoreConflicts:flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,5
[FLINK-3712] Make all dynamic properties available to the CLI frontendThis closes #1863,1
"[FLINK-3640] Add support for SQL in DataSet programs- add EnumerableToLogicalScan rule- in order to be able to mix TableAPI and SQL, we need our own copy of PlannerImpl- create a dummy RelNode in the reset() method, in order to retrieve the RelOptPlannerThis closes #1862",1
[FLINK-3634] [docs] Fix documentation for DataSetUtils.zipWithUniqueId()This closes #1817.,5
[FLINK-3469] [docs] Improve documentation for grouping keysThis closes #1858.,2
[FLINK-3579] Improve String concatenation in the Table APIThis closes #1821,1
[FLINK-3640] [docs] extend the Table API docs and add a section about embedded SQL modeThis closes #1867,1
[FLINK-3492] Configurable interval between Checkpoints,5
[FLINK-3731] make embedded SQL outer joins fail during translationThis closes #1869,0
[hotfix] Minor edits to comments in code,2
[FLINK-3736] [tableAPI] Move toRexNode logic into each expression's implementation.This closes #1870,2
"[FLINK-3721] Min and max accumulatorsFlink already contains DoubleCounter, IntCounter, and LongCounter foradding numbers. This adds equivalent accumulators for storing theminimum and maximum double, int, and long values.This closes #1866",5
[FLINK-3700] [build] Add 'findbugs' (javax.annotation) annotations as a core dependency.,5
[FLINK-3700] [core] Add 'Preconditions' utility class.,1
[FLINK-3375] [kafka connector] Add per-Kafka-partition watermark generation to the FlinkKafkaConsumerThis closes #1839,2
[FLINK-3375] [kafka connector] Rework/simplify Kafka Connector and have a WatermarkExtractor object per partition,4
[FLINK-3716] [kafka consumer] Decreasing socket timeout so testFailOnNoBroker() will pass before JUnit timeoutThis closes #1864,3
[hotfix] [kafka consumer] Increase Kafka test stability by validating written data before consuming,5
[FLINK-3541] [Kafka Connector] Clean up workaround in FlinkKafkaConsumer09This closes #1846,2
[FLINK-3444] [APIs] Add fromElements method with based class type to avoid the exception.This closes #1857,1
[FLINK-3644] [web monitor] Add new config option to set web monitor tmp dirThis closes #1824,1
[FLINK-3737] [tests] Adding comment about SOCKS proxy server for WikipediaEditsSourceTestThis closes #1872,3
"[FLINK-3126] [core] Remove accumulator type from ""value"" in web frontendThis closes #1868",4
[FLINK-3730] Fix RocksDB Local Directory Initialization,5
[FLINK-3735] Make DataSetUnionRule match only for union-allThis closes #1874,5
[hotfix] [storm] Add proper exception forwarding to FlinkTopology.copyObject,2
[hotfix] [tests] Add cross transformation to OverwriteObjects manual test,3
[FLINK-3589] Allow setting Operator parallelism to default valueAdds the public field ExecutionConfig.PARALLELISM_DEFAULT as a flagvalue to indicate that the default parallelism should be used.Adds the public field ExecutionConfig.PARALLELISM_UNKNOWN as a flagvalue to indicate that the parallelism should remain unchanged.This closes #1778,4
[FLINK-2909] [gelly] Graph GeneratorsInitial set of scale-free graph generators:- Complete graph- Cycle graph- Empty graph- Grid graph- Hypercube graph- Path graph- RMat graph- Singleton edge graph- Star graphThis closes #1807,1
[hotfix] [kafka consumer] Increase Kafka test stability,3
[FLINK-3745] [runtime] Fix early stopping of stream sources,0
[FLINK-3747] Consolidate TimestampAssigner Methods in Kafka ConsumerThis closes #1877,4
[FLINK-3375] [Kafka Connector] Add tests for per-kafka-partition watermarks.,3
[FLINK-3743] upgrading breeze from 0.11.2 to 0.12This closes #1876,2
[FLINK-3760] Fix StateDescriptor.readObject,0
[FLINK-3739] [table] Add a null literal to Table APIThis closes #1880.,1
[hotfix] Make initial currentWatermark==Long.MIN_VALUE everywhere,5
"[FLINK-3700] [core] Remove Guava dependency from flink-coreAlmost all Guava functionality used within flink-core has correspondingutils in Flink's codebase, or the JDK library.This replaces the Guava code as follows  - Preconditions calls by Flink's Preconditions class  - Collection utils by simple Java Collection calls  - Iterator's by Flink's Union Iterator  - Files by simple util methods arount java.nio.Files  - InetAddresses IPv6 encoding code has been adapted into Flink's NetUtils (with attribution comments)Some util classes where moved from flink-runtime to flink-core.This closes #1854",2
"[FLINK-3738] [table] Refactor TableEnvironments. Remove Translators and TranslationContext.- Removes Translators (JavaBatchTranslator, ScalaBatchTranslator, JavaStreamTranslator, ScalaStreamTranslator)- Removes TranslationContext- Creates TableEnvironments for Java/Scala DataSet/DataStream APIs- Functionality of translators and translation context is moved to table environments- Tables are bound to a TableEnvironment- Simplifies table translation from and to DataSet / DataStream.- Updates documentation and cleaned up ScalaDocsThis closes #1887",2
[FLINK-3759] [table] Throw exception if NULL literal is encountered in non-null mode.This closes #1892,2
[FLINK-3732] [core] Fix potential null deference in ExecutionConfig#equals()This closes #1871,5
[FLINK-3762] [core] Enable Kryo reference trackingThis closes #1891,0
[FLINK-2544] [docs] Add Java 8 version for building PowerMock tests to docsJava 8 update 11 introduced a stricter bytecode verifier that leadsto failures in unit tests that use the PowerMock runner. The testsrun correctly in Java 8u51 or above.This closes #1882,3
[FLINK-3657] [dataSet] Change access of DataSetUtils.countElements() to 'public'This closes #1829,5
[FLINK-2732] Display TM logs in DashboardThis closes #1790,2
[FLINK-3773] Scanners are left unclosed in SqlExplainTestThis closes #1902,3
[FLINK-3664] Create DataSetUtils method to easily summarize a DataSet of TuplesThis closes #1859,5
[FLINK-3587] Bump Calcite version to 1.7.0- Add DataSetValues and DataStreamValues due to changed Calcite RelNode generation.- Pass TableEnvironment instead of TableConfig for DataSet and DataStream translation.- Add methods to create new DataSources to BatchTableEnvironment and StreamTableEnvironment.- Remove copied Calcite rule that got fixed.This closes #1897,0
[FLINK-3770] [gelly] Fix TriangleEnumerator performanceImplement optimization of ordering edges by degree and a JoinHint forthe joining of edges and vertices.This closes #1899,5
[FLINK-3748] [table] Add CASE function to Table APIThis closes #1893.,1
[FLINK-3764] [tests] Improve LeaderChangeStateCleanupTest stabilityThe LeaderElectionRetrievalTestingCluster now also waits for the Flinkresource manager to be properly started before trying to send leaderchange notification messages to the LeaderRetrievalServices.This closes #1894,4
"[hotfix] [cep] Make cep window border treatment consistentThe NFA and the SharedBuffer treated window borders differently. Therefore, it waspossible that events were pruned even though the NFA still contained references tothese events. Now CEP windows are left inclusive and right exclusive.",1
[FLINK-3230] Add producer for Amazon Kinesis Streams into FlinkThis closes #1910,2
[docs] Update AWS S3 docs,2
"[FLINK-3718] Add Option For Completely Async Backup in RocksDB State BackendThis also refactors the RocksDB backend to keep one RocksDB data base inthe backend where all key/value state is stored. Individual namedkey/value states get a reference to the db and store their state in acolumn family. This way, we only have to backup one RocksDB data baseand can centrally decide how to do backups.",5
[FLINK-3665] [dataSet] Add support for sort orders in range partitioning.This closes #1848,1
[FLINK-2998] [dataSet] Add support for explicit range partitioning for joins and coGroup.This closes #1838,1
[FLINK-3781] Ensure BlobClient is closed.This closes #1908,2
[FLINK-3798] [streaming] Clean up RocksDB backend field/method accessCloses #1918,5
[FLINK-3790] [streaming] Use proper hadoop config in rolling sinkCloses #1919,5
[hotfix] [FLINK-3798] Make RocksDB state classes also public,5
"[FLINK-3727] Add support for embedded streaming SQL (projection, filter, union)- add methods to register DataStreams- add sql translation method in StreamTableEnvironment- add a custom rule to convert to streamable table- add docs for streaming table and sqlThis closes #1917",2
[FLINK-3794] Add checks for unsupported operations in streaming table APIThis closes #1921,1
[hotfix] [zk] Add logging for connection state changes in ZooKeeperLeaderElection/RetrievalService,4
"[hotfix] [core] Standardize min and max accumulatorsUpdates counting, min, and max accumulators to all include primitiveconstructors and accessors.",5
[hotfix] [java] Allow setting DataSink parallelism to default valueThis was missed in FLINK-3589.,2
[FLINK-3740] Make Session Window State Checkpointed,1
[FLINK-3560] [examples] Remove unchecked output of usage statement in examplesThis closes #1752.,4
This closes #1925,5
"[FLINK-3774] [shell] Forwards Flink configuration to PlanExecutorThe ScalaShellRemoteEnvironment did not properly forward the given Flink configurationto the PlanExecutor. Consequently, it was not possible to configure the Client to connectto an HA cluster. This PR corrects the forwarding.Fix failing FlinkILoopTest with Scala 2.11This closes #1904.",3
[FLINK-3778] [shell] Forward configuration from FlinkILoop to ScalaShellRemoteStreamEnvironmentWith this PR the configuration of the FlinkILoop is properly forwarded to theScalaShellRemoteStreamEnvironment.This closes #1906.,3
"[hotfix] [tableAPI] Fix DataStreamScanRule, fix indention, improve class names.",1
"[FLINK-3803] [runtime] Pass CheckpointStatsTracker to ExecutionGraph`CheckpointStatsTracker` was instantiated in `ExecutionGraph#enableSnapshotCheckpointing`,where the Flink configuration is not available to parse the configuration.Instead of instantiating the `CheckpointStatsTracker` in the `ExecutionGraph`method, we directly pass it to it.This closes #1927.",4
"[FLINK-3775] [shell] Load Flink configuration before forwarding itThis commit makes sure that the GlobalConfiguration is loaded before the FlinkShellis started.Add configDir option to FlinkShellThis allows to configure a configuration directory for the FlinkShell. If theCLI option is not set, then the system tries to find the configuration directoryusing first the FLINK_CONF_DIR environment variable and then the standard directories.Add Apache license header to dummy flink-conf.yaml fileThis closes #1914.",2
"[FLINK-3756] [state] Add state hierarchy to CheckpointCoordinatorThis commit introduces a state hierarchy for the StateForTask objects keptat the CheckpointCoordinator. Task states are now grouped together if theybelong to the same ExecutionJobVertex. The StateForTask objects are nowstored in so called StateForTaskGroup objects. The StateForTaskGroup objectcan also store the key group state handles associated to a ExecutionJobVertex.Adapt restore methods of CheckpointCoordinator and SavepointCoordinatorAdd state size computationAdd comments to createKeyGroupPartitions; Add more information to StateForTask.toStringRename StateForTaskGroup -> TaskState, StateForTask -> SubtaskState, KvStateForTasks -> KeyGroupStateThis closes #1883.",5
[FLINK-3811] [tableAPI] Use only Java ExecutionEnvironments in TableEnvironmentsThis closes #1930,1
[FLINK-3810] Add missing breaks in ZKElectionService,4
[FLINK-3809] Add missing breaks in ZKRetrievalServiceThis closes #1935.,4
[Doc] added note to fix Eclipse build,0
[FLINK-3799] [gelly] Graph checksum should execute single jobThis closes #1922,2
"[hotfix] Disable WAL in RocksDB state ""clear""",5
[FLINK-3777] Add openIF/closeIF methods to IF lifecycleThis closes #1903,1
[FLINK-3804][docs] Fix YARN and Kafka docs,2
[hotfix] OptionSerializer.duplicate to respect stateful element serializer,0
[hotfix] [build] Replace maven-scala-plugin with newer scala-maven-plugin,1
[FLINK-3708] [cep] Add Scala CEP APIAdded missing test dependency to pom.Pattern in Scala API now uses Option to shield users against null values from the Java APIAdded test-jar for build phase to pom.Removed necessary dependency entry and an overlooked comment.Added missing comments on FollowedByPattern.CEPIT test update.Replace CEP test with a simple test for Scala <-> Java interoperability.This closes #1905.,3
"[FLINK-3800] [jobmanager] Terminate ExecutionGraphs properlyThis PR terminates the ExecutionGraphs properly without restarts when the JobManager callscancelAndClearEverything. It is achieved by allowing the method to be only called with anSuppressRestartsException. The SuppressRestartsException will disable the restart strategy ofthe respective ExecutionGraph. This is important because the root cause could be a differentexception. In order to avoid race conditions, the restart strategy has to be checked twicewhether it allwos to restart the job: Once before and once after the job has transitioned tothe state RESTARTING. This avoids that ExecutionGraphs can become an orphan.Furhtermore, this PR fixes the problem that the default restart strategy is shared by multiplejobs. The problem is solved by introducing a RestartStrategyFactory which creates for everyjob its own instance of a RestartStrategy.Fix LeaderChangeJobRecoveryTest caseThis closes #1923.",1
[hotfix] [scala-cep] Remove unnecessary testing dependency,3
[FLINK-3817] Remove unused guava dependency from RocksDb backendThis closes #1934,5
[FLINK-3819] Replace Guava Preconditions usage in flink-gelly-scalaThis closes #1937,2
[FLINK-3818] Remove Guava dependency from flink-gelly-examplesThis closes #1936,2
[FLINK-3815] Replace Guava Preconditions usage in flink-gellyThis closes #1932,2
[FLINK-3815] Replace Guava Preconditions usage in flink-clientsThis closes #1933,2
[FLINK-3086] [table] ExpressionParser does not support concatenation of suffix operationsThis closes #1912.,0
[hotfix] minor: make type explicit to allow Scala test to compile in Eclipse,3
"[FLINK-3824] ResourceManager may repeatedly connect to outdated JobManagerWhen the ResourceManager receives a new leading JobManager via theLeaderRetrievalService it tries to register with this JobManager untilconnected. If during registration a new leader gets elected, theResourceManager may still repeatedly try to register with the oldone. This doesn't affect the registration with the new JobManager butleaves error messages in the log file and may process unnecessarymessages.",2
[FLINK-3601] increase timeout for JobManagerTest methods,3
[FLINK-3835] [optimizer] Add input id to JSON plan to resolve ambiguous input names.,0
[FLINK-2828] [tableAPI] Add TableSource interfaces for external tables.- Add CsvTableSource as a reference implementation for TableSources.This closes #1939,1
[FLINK-3840] Remove Testing Files in RocksDB BackendWe create random files on initialization to check whether we can writeto the data directory. These files are also removed now.,4
[FLINK-3428] Adds a fixed time trailing watermark extractor.This closes #1764,4
[FLINK-3428] Minor fixes,0
[FLINK-2946] Add support for orderBy() to batch Table API and SQL.This closes #1926.Closed because CsvTableSource has been implemented.This closes #939.,1
[FLINK-3846] [gelly] Graph.removeEdges also removes duplicate edgesAll original edges are now emitted when no matching edge is found in theedge removal set.This closes #1948,1
[FLINK-3853] [gelly] Reduce object creation in Gelly utility mappersThis closes #1951,1
[FLINK-3847] Restructure flink-table test packages.This closes #1950,3
[FLINK-3786] [core] [api-extending] Add BigDecimal and BigInteger as Basic typesThis closes #1928.,1
[docs] Replace Markdown in HTML with HTML,2
[FLINK-3837] [table] Create FLOOR/CEIL functionThis closes #1943,1
"[FLINK-3771] [gelly] Methods for translating GraphsMethods for translation of the type or value of graph IDs, vertexvalues, and edge values.This closes #1900",2
[FLINK-3845] [gelly] Gelly allows duplicate vertices in Graph.addVerticesVertex sets are now merged with a cogroup so that a new Vertex is onlyadded to the Graph when no existing Vertex exists with the same label.This closes #1949,1
[FLINK-3793][docs] re-organize table API and SQL docsThis closes #1955,2
[FLINK-3669] Timer coalescing across keys and cleanup of unused trigger tasksPer timestamp only one TriggerTask is registered atthe runtime context. When the first timer is registered a new TriggerTaskis sheduled. When no timer is registered anymore for a specific timestampthe corresponding trigger task is canceled and hence removed.The ScheduledFutures to cancel trigger tasks are not checkpointed. Socleanup of trigger tasks will not work after a failure.,0
[FLINK-3860] [connector-wikiedits] Add retry loop to WikipediaEditsSourceTestThis closes #1964.,3
"[FLINK-3825] [cep, doc] Documentation for CEP Scala API.[FLINK-3825] Documentation for CEP Scala API. Minor beautification on (flat-)select function code example.This closes #1960.",1
"[FLINK-3825] [cep, doc] Make Scala code examples less verbose",1
[FLINK-3876] improve documentation of Scala Shell- restructure sections- improve readability,1
[FLINK-1996] [tableApi] Add TableSink interface to emit tables to external storage.- Add a CsvTableSinkThis closes #1961,1
[FLINK-3519] [core] Add warning about subclasses to Tuple JavaDocs.- Bring TupleGenerator up to date with the Tuple classes.This closes #1724,5
[FLINK-1827] [tests] Move test classes in test folders and fix scope of test dependencies.This closes #1915,3
[FLINK-3691] [avro] Extend AvroInputFormat to support Avro GenericRecordThis closes #1920,1
[docs] Document difference between 'stop' and 'cancel',2
[docs] Add note about S3AFileSystem 'buffer.dir' property,5
[FLINK-3881] [docs] Java 8 Documetation Sample CorrectionThis closes #1970.,2
[docs] Adjust network buffer config for slots and add tl;dr,1
"[FLINK-3772] [gelly] Graph algorithms for vertex and edge degreeGraph algorithms for annotating  vertex degree for undirected graphs  vertex out-, in-, and out- and in-degree for directed graphs  edge source, target, and source and target degree for undirected graphs",1
[FLINK-3877] [gelly] Create TranslateFunction interface for Graph translatorsThe TranslateFunction interface is similar to MapFunction but may becalled multiple times before serialization.This closes #1968,1
[FLINK-3880] remove mutex for user accumulators hash mapThis cloes #1976,1
[FLINK-3155] Update Flink Dockerfile* ubuntu trusty->xenial* jdk 7u51 -> 8u91* flink 0.10.1 -> 1.0.2This closes #1969,2
[FLINK-3821] [dataSet] Remove Guava usage in flink-java non-test files.- replaced CharSets with StandardCharsets- added checkElementIndex to Flink Preconditions- replaced Guava Preconditions with Flink Preconditions- removed single usages Ints.max() and Joiner()This closes #1938,4
[hotfix] [tableAPI] Fix SQL queries on TableSources.,0
[FLINK-3842] [tableApi] Fix handling null record/row in generated codeThis closes #1974,0
[FLINK-3882] [docs] Fix errors in sample Java code for the Elasticsearch2 sinkThis closes #1971,0
[FLINK-3856] [core] [api-extending] Create types for java.sql.Date/Time/TimestampThis closes #1959,5
[FLINK-3855] Upgrade and unify to Jackson 2.7.4This closes #1952,2
[FLINK-3878] Fix support multiple identical temp directories in FileCacheThis closes #1965,2
[FLINK-3776] Flink Scala shell does not allow to set configuration for local executionThis closes #1945,5
"[FLINK-3701] enable reuse of ExecutionConfigDepending on the context, the ExecutionConfig's type fields may eitherbe deserialized using a custom class loader or the default classloader. It may be explicitly serialized for the Task or shipped insidethe PojoSerializer where it is serialized or directly passed in localmode. An ExecutionConfig may be reused and thus its fields can't be setto null after it has been shipped once.The entire ExecutionConfig is now serialized upon setting it on theJobGraph. It is not passed through the JobGraph's constructor but setexplicitly on the JobGraph. If no ExecutionConfig has been set, thedefault is used. Unlike before, no code may modify the ExecutionConfigafter it has been set on the JobGraph.This closes #1913",1
[FLINK-3856] adapt test assertion to type stack changesAddition to bbd02d24bc7547e2c9384d713b20f86682cac08c.The java.lang.Date type shouldn't be an automatically Kryo registeredanymore.,5
"[FLINK-3912] [docs] Fix errors in Batch Scala API Documentation, Join sectionThis closes #1991",2
[FLINK-3768] [gelly] Local Clustering CoefficientThe local clustering coefficient measures the connectedness of eachvertex's neighborhood. Scores range from 0.0 (no edges betweenneighbors) to 1.0 (neighborhood is a clique).This closes #1896,2
[FLINK-3488] [tests] Fix flakey test Kafka08ITCase.testBigRecordJobThis closes #1998,3
[FLINK-3782] [tests] Properly close streams in CollectionInputFormatTestThis closes #1995,3
[FLINK-3852] [quickstart] Add skeleton StreamingJob  - move Job to BatchJob  - comment out transformers for the mainClass setting  - tidy up SocketTextStreamWordCount  - update docsThis closes #1982,2
[FLINK-3826] [tests] Fix test condition in StreamCheckpointingITCaseThis closes #1977,1
[hotfix] [kafka tests] Build a flink-connector-kafka-0.9 test-jarBuild a test-jar including KafkaTestEnvironmentImpl so that Flink users can write end to end integration tests of their Flink jobs.This closes #1972,2
[FLINK-3913] [docs] Clean up spelling mistakes.This closes #1992,4
[FLINK-3900] [tableAPI] Set nullCheck=true as default in TableConfig.This closes #1994,5
[FLINK-3754] [tableAPI] Add validation phase to Table API before construction of RelNodes.This closes #1958,5
[FLINK-3229] Initial working version for FlinkKinesisConsumer.This closes #1911,2
[FLINK-3229] Shade Google Protobuf into Kinesis connector to avoid runtime version conflict,5
[FLINK-3926] [core] Fix NumberFormatException in TupleTypeInfo.getFieldIndex()This closes #2004,5
[FLINK-3914] [runtime] Fix race when attempting to create temp dir in BlobUtils.This closes #2000,1
[FLINK-3750] [jdbcConnector] Refactor JdbcInputFormat and JdbcOutputFormat.- New Input- and OutputFormat use Row instead of Tuple types to support null values.- JdbcInputFormat supports parallel input due to PreparedStatement and binding values for parameters.This closes #1941,2
[hotfix] [tableAPI] Adapt tests to changed null-value support default,1
[FLINK-3934] [tableAPI] Check for equi-join predicates before translation.,2
[FLINK-3935] [optimizer] Fix check of key fields and ordering in PartitionNode.,0
[hotfix] [docs] Remove misleading sentence from DataSet.union() description.,5
[script] Simple fix of typo from JobManager to TaskManager in taskmanager.sh fileVery simple fix for typo on comment in the task manager.sh file.From `JobManager` to `TaskManager`.Author: Henry Saputra <hsaputra@apache.org>Closes #2001 from hsaputra/simple_text_fix_taskmanager and squashes the following commits:861cbb4 [Henry Saputra] Simple fix of typo from JobManager to TaskManager in taskmanager.sh file.,2
[FLINK-3933] [streaming API] Add AbstractDeserializationSchema that handles produced type extraction.The AbstractDeserializationSchema creates the produced type information automatically from thegeneric parameters.This closes #2010,2
[FLINK-3892] ConnectionUtils may die with NullPointerExceptionThis fixes a NullPointerException that would occur if the host namecould not be resolved.This closes #2008,0
[FLINK-3893] improve LeaderChangeStateCleanupTest stability- increase timeout for task managers to be registered- don't fail if leader retrieval service has not been started yetThis closes #2009,0
[FLINK-3909] replace Maven Failsafe with SurefireFailures during execution of the integration tests with the MavenFailsafe plugin were silently ignored on Travis with Maven version3.2.5. The problem is that failures are not passed on correctly from the'integration-test' phase (where failures are recorded and tolerated) tothe 'verify' phase.The cause of the error is most likely SUREFIRE-1127. An exception in the'integration-test' is sometimes not flushed back to disk where it isevaluated in the 'verify' phase. Bumping the version of the Failsafeplugin from 2.18.1 to 2.19.1 fixes the issue but introduces classpathrelated problems.We don't have to rely on Failsafe for running integrationtests. Surefire offers the same feature set we use from the Failsafeplugin.- replace Failsafe with Surefire- update to latest Surefire version- get rid of duplicate property declarationThis closes #2003,5
"[FLINK-3938] re-enable Yarn testsAs of 70978f560fa5cab6d84ec27d58faa2627babd362, the Yarn tests were notexecuted anymore. They were moved to the test directory but there wasstill a Maven configuration in place to change the test directorylocation.This closes #2012",3
[FLINK-3928] [gelly] Potential overflow due to 32-bit int arithmeticThis closes #2006,2
[FLINK-3780] [gelly] Jaccard IndexThe Jaccard Index measures the similarity between vertex neighborhoods.Scores range from 0.0 (no shared neighbors) to 1.0 (all neighbors areshared).This closes #1980,2
[FLINK-1502] [core] Add basic metric system,5
[FLINK-1502] [core] Various improvements to the metrics infrastructure code  - Metric groups are generally thread-safe  - Metric groups are closable. Closed groups do not register metric objects and more.  - TaskManager's JobMetricsGroup auto disposes when all TaskMetricGroups are closed  - Maven project with metric reporters renamed to 'flink-metric-reporters'  - Various code style cleanups,4
[FLINK-3927][yarn] make container id consistent across Hadoop versions- introduce a unique container id independent of the Hadoop version- improve printing of exceptions during registration- minor improvements to the Yarn ResourceManager codeThis closes #2013,1
"[FLINK-3953][maven] rename unit-tests execution to default-testAfter 38698c0b101cbb48f8c10adf4060983ac07e2f4b, there are now twoexecutions defined for the Surefire plugin: unit-tests andintegration-tests. In addition, there is an implicit default executioncalled default-test. This leads to the unit tests to be executedtwice. This renames unit-tests to default-test to prevent duplicateexecution.This closes #2019",3
[FLINK-3939] [tableAPI] Prevent translation of unsupported distinct aggregates and grouping sets.This closes #2014,1
[hotfix] [tableAPI] Throw helpful exception for unsupported ORDER BY features.,1
[hotfix] [tableAPI] Throw helpful exception for unsupported outer joins.,1
[FLINK-3632] [tableAPI] Clean up TableAPI exceptions.This closes #2015,4
[docs] Fix outdated default value for akka.ask.timeout,5
[hotfix] [tableAPI] Moved tests to correct package.,3
[FLINK-3955] [tableAPI] Rename Table.toSink() to Table.writeToSink().This closes #2023,2
[FLINK-3728] [tableAPI] Improve error message and documentation for unsupported SQL features.This closes #2018,1
"[FLINK-3960] ignore EventTimeWindowCheckpointingITCase for nowUntil FLINK-3960 is fixed, we need to disable this test to allow othertests to execute properly.This closes #2022",3
[FLINK-3963] Removed shaded importThis closes #2026,2
"[FLINK-3963] AbstractReporter uses wrong ConcurrentHashMapWe should use java.util.concurrent.ConcurrentHashMap because Netty'sConcurrentHashMap is not available for Hadoop 1. Also, Netty's ConcurrentHashMapis merely a copy of Java's to support Java versions prior 1.5.",1
[FLINK-3586] Fix potential overflow of Long AVG aggregation.- Add unit tests for Aggretates.This closes #2024,3
[FLINK-2044] [gelly] Implementation of HITS algorithm.This closes #1956,2
[FLINK-3936] [tableAPI] Add MIN/MAX aggregation for Boolean.This closes #2035,1
[FLINK-3941] [tableAPI] Add support for UNION to Table API.- Fix FLINK-3696 (type issues of DataSetUnion by forwarding expected types to input operators).This closes #2025,1
[hotfix] Remove leftover config key constant from ExecutionConfig,5
[hotfix] Fix access to temp file directories in SpillingAdaptiveSpanningRecordDeserializer,2
[FLINK-3962] [core] Properly initialize I/O Metric Group,5
[Flink-2971] [tableAPI] Add outer joins to the Table API and SQL.This closes #1981,1
[FLINK-3129] Bring infrastructure for ensuring interface stability in placeThis closes #2042,5
[FLINK-3129] Fix breaking changes in flink-core,2
[FLINK-3129] Fix ES2 issue,0
"[FLINK-3972] subclasses of ResourceID may not to be serializableWorkerTypes are currently subclasses of ResourceID. ResourceIDimplements Serializable but not necessarily its subclasses. This maylead to problems when these subclasses are used as ResourceIDs,i.e. serialization may fail with NotSerializableExceptions. Currently,subclasses are never send over the wire but they might be in the future.Instead of relying on subclasses of ResourceID for the WorkerTypes, welet them implement an interface to retrieve the ResourceID of aWorkerType.This closes #2037",1
[FLINK-3923] [connector-kinesis] Unify configuration conventions of the Kinesis producer to the same as the consumer,5
[FLINK-3923] Minor cleanups and enhancementsThis closes #2016,4
"[hotfix] Fix doc link to ""Working with Time""",1
"[FLINK-3981] don't log duplicate TaskManager registrationsDuplicate TaskManager registrations shouldn't be logged with Exceptionsin the ResourceManager. Duplicate registrations can happen if theTaskManager sends out registration messages too fast when the actualreply is not lost but still in transit.The ResourceManager should simply acknowledge the duplicateregistrations, leaving it up to the JobManager to decide how to treatthe duplicate registrations (currently it will send an AlreadyRegisteredto the TaskManager).This closes #2045",2
"[FLINK-3982] let only ResourceManager of leading JobManager registerIn HA mode, multiple ResourceManagers may register at the leadingJobManager. They register one after another at the JobManager. The lastregistering ResourceManager stays registered with the JobManager. Thisonly applies to Standalone mode and doesn't affect functionality.To prevent duplicate registration for the standalone ResourceManager,the easiest solution is to only start registration when the leadingJobManager runs in the same ActorSystem as theResourceManager. OtherResourceManager implementations may also run independently of theJobManager.This closes #2046",1
[FLINK-1745] [ml] Add exact k-nearest-neighbor join,1
[FLINK-1745] [ml] Use QuadTree to speed up exact k-nearest-neighbor join,1
[FLINK-1745] [ml] Adjust k-nearest-neighbor-join code formattingThis closes #1220.,2
[FLINK-2829] [runtime] Clarify error message when Flink cannot deploy task to slotThis closes #1993,2
[hotfix] [contrib] Fix robustness of DataStreamUtils stream collecting,5
"[FLINK-1502] [core] Cleanups, robustness, and performance improvements in the metrics system",5
[FLINK-1502] [core] Temporarily set no default metrics reporter (instead of JMX),1
"[hotfix] [yarn tests] Fix deadlock between YARN Session CLI tests and SurefireThe Surefire Plugin uses stdin to communicate with forked JVMs for tests.The YARN Session CLI tests also try to read the stdin stream. The tests deadlock sinceSurefire never releases the stdin locks during the lifetime of a test.This change adds a parameter whether the YARN Session CLI should try to readuser console input, and sets this to false in the integration tests.",3
[FLINK-2673] [core] Add a comparator for Scala Option typeThis closes #2017.,1
"[FLINK-3887] improve dependency management for building docsThe Flink documentation build process is currently quite messy. Thesechanges move us to a new build process with proper dependencyhandling. It assures that we all use the same dependency versions forconsistent build output. Also, it eases the automated building processon other systems (like the ASF Buildbot). The goal was to make thedocumentation build process easier and self-contained.- use Ruby's Bundler Gem to install dependencies- update README- adapt Dockerfile- add additional rules to .gitignore- change default doc output path from /target to /content(default path of the flink-web repository)This closes #2033",2
[docs] Add notes about shipped log4j properties files,2
[FLINK-3975] [docs] Override baseurl when serving docs locallyThis closes #2040,2
[FLINK-3887] fix quoting issue with bundler command,0
"[FLINK-3607] decrease default forkCount for testsThis makes running test locally a more pleasant experience. It stilluses all exposed CPU cores (virtual or real). A custom forkCount can beset using the flink.forkCount property, e.g. -Dflink.forkCount=4.",2
[FLINK-3886] [clients] Give a better error when the application Main class is not public.This closes #2043,0
[FLINK-3978] [core] Add hasBroadcastVariable method to RuntimeContextNew method RuntimeContext.hasBroadcastVariable(String).,1
[FLINK-3979] [docs] Add import statements for last code sample in the quickstart docs.This closes #2038,2
[hotfix] [tests] Minor style fix in FlinkTestBase,3
"[FLINK-3994] [ml, tests] Fix flaky KNN integration testsThis closes #2056.",3
[hotfix] [runtime] Disable restart suppression on cancelAndClearEverythingThis temporary disables 28c57c3 (\cc @tillrohrmann),1
[FLINK-3993] [py] Add Environment.generateSequence()This closes #2055,1
[FLINK-3806] [gelly] Revert use of DataSet.count()This closes #2036,5
[FLINK-3945] [gelly] Degree annotation for directed graphsThis closes #2021,2
[hotfix] [core] Fix scope format keys for metricsThis closes #2068,0
"Revert ""[FLINK-3960] ignore EventTimeWindowCheckpointingITCase for now""This reverts commit 98a939552e12fc699ff39111bbe877e112460ceb.",4
"[FLINK-3948] Protect RocksDB cleanup by cleanup lockBefore, it could happen that an asynchronous checkpoint was going onwhen trying to do cleanup. Now we protect cleanup and asynchronouscheckpointing by a lock.",4
"[FLINK-4026] Fix code, grammar, and link issues in the Streaming documentation",2
[FLINK-3980] [core] Remove ExecutionConfig.PARALLELISM_UNKNOWNThis closes #2064,5
[FLINK-3925] [gelly] GraphAlgorithm to filter by maximum degreeThis closes #2005,2
[FLINK-4013] [gelly] GraphAlgorithms to simplify directed and undirected graphsThis closes #2067,2
[FLINK-3906] [gelly] Global Clustering CoefficientThe global clustering coefficient measures the connectedness of a graph.Scores range from 0.0 (no triangles) to 1.0 (complete graph).This closes #1997,2
[FLINK-4003] [core] Use intrinsics for MathUtils logarithmsThis closes #2059,2
[FLINK-4025] RMQ Streaming: Possibility to customize queueThis patch adds the possibilty for th user of the RabbitMQStreaming Connector to customize the queue which is used. Thereare use-cases in which you want to set custom parameters for thequeue (i.e. TTL of the messages if Flink reboots) or thepossibility to bind the queue to an exchange afterwards.The commit doesn't change the actual behaviour but makes itpossible for users to override the newly create `setupQueue`method and cutomize their implementation. This was not possiblebefore.This closes #2073,1
[FLINK-4011] Keep UserCodeClassLoader in archived ExecutionGraphsThis closes #2065,1
"[FLINK-4000] [RabbitMQ] Fix for checkpoint state restore at MessageAcknowledgingSourceBaseAs says documentation for MessageAcknowledgingSourceBase.restoreState()This method is invoked when a function is executed as part of a recovery run. Note that restoreState() is called before open().So current implementation1. Fails on restoreState with NullPointerException, jobs fail to restart.2. Does not restore anything because following open erases all checkpoint data immediately.3. As consequence, violates exactly once rule because processed but not acknowledged list erased.Proposed change fixes that.This closes #2062",0
[FLINK-4000] [RabbitMQ] Style cleanups in MessageAcknowledgingSourceBase,4
[FLINK-3405] [nifi] Extend NiFiSource with interface StoppableFunctionThis closes #2047,1
[hotfix] [nifi] Minor style cleanups in NiFi source,4
[FLINK-3922] [core] Fix case of infinite recursion in TypeExtractorThis closes #2011,4
[FLINK-2832] [tests] Hardens RandomSamplerTestIncrease the level of significance from p=0.01 to p=0.001 and add retry annotationsto random sampler tests. This should decrease the probability of failing randomsampler tests.This closes #2076,3
[FLINK-4031] include sources in Maven snapshot deploymentThis closes #2082,2
[hotfix] Fix JSONDeserializationSchema for Kafka,5
[hotfix] Improve ParameterTool exceptionThis closes #2057,2
[FLINK-3854] Support Avro key-value rolling sink writerThis closes #1953,1
"[hotfix] [streaming-java] Harden IterateTestAdds retries and timeout scaling to all iteration tests, which relyon iteration timeouts. The way the tests rely on these timoeuts isprone to races. If the failures occur again, I vote to ignore thetests until iteration termination is fixed properly.Example test failures:- https://s3.amazonaws.com/archive.travis-ci.org/jobs/134215892/log.txt- https://s3.amazonaws.com/archive.travis-ci.org/jobs/134215975/log.txtThis closes #2087.",5
[FLINK-3763] RabbitMQ Source/Sink standardize connection parameters,2
[FLINK-3763] Some RMQ cleanupsThis closes #2054,4
[FLINK-3530] Fix Kafka08 instability: Avoid restarts from SuccessExceptionThis closes #2080,0
"[hotfix] [core] Re-enable JMX metrics as the default.This also does some minor code cleanups, logging fixes, and smoother concurrency handling.",0
[FLINK-4052] [runtime] Improve test stability for ConnectionUtilsTest,3
[hotfix] [py] Fix PythonPlanBinder not copying additional files,2
[FLINK-4002] [py] Improve testing infrastructureThis closes #2063,5
[FLINK-4049] Mark (open/close)IF() @PublicEvolving,2
"[hotfix] [core] Make sure Dropwizard reporters do not block operator creation/teardown while reportingThe ""report()"" method used to hold the same lock that was needed to create and shutdown metrics.Holding that lock too long could delay operator creation and teardown.This also removes the no longer needed dependency on dropwizard in flink-core.",2
[FLINK-3944] [tableAPI] Add rewrite rules to reorder Cartesian products and joins.These rules are necessary to resolve join orders that initially contain Cartesian productsdue to the order in which base relations are added in the FROM clause (SQL) or joined (Table API).This closes #2044,1
"[revert] [FLINK-3944] [tableAPI] Reverts ""Add rewrite rules to reorder Cartesian products and joins.""This reverts commit 85793a25a78ba5be96fabc2a26569318c6b53853.Added rewrite rules blow up search space which cannot be effectively pruned without cardinality estimates.This closes #2098",1
[FLINK-3971] [tableAPI] Fix handling of null values in aggregations.This closes #2049,0
"[FLINK-3896] Allow a StreamTask to be Externally CancelledIt adds a method failExternally() to the StreamTask, so that custom Operatorscan make their containing task fail when needed.",0
"[FLINK-2314] Make Streaming File Sources PersistentThis commit is a combination of several commits/changes. It combineschanges to the file input formats and the streaming file read operatorand integrates them into the API.These are the messages of the other two commits:[FLINK-3717] Make FileInputFormat checkpointableThis adds a new interface called CheckpointableInputFormatwhich describes input formats whose state is queryable,i.e. getCurrentState() returns where the reader isin the underlying source, and they can resume reading froma user-specified position.This functionality is not yet leveraged by current readers.[FLINK-3889] Refactor File Monitoring SourceThis is meant to replace the different filereading sources in Flink streaming. Now there isone monitoring source with DOP 1 monitoring adirectory and assigning input split to downstreamreaders.In addition, it makes the new features added byFLINK-3717 work together with the aforementioned entities(the monitor and the readers) in order to havefault tolerant file sources and exactly once guarantees.This does not replace the old API calls. Thiswill be done in a future commit.",2
[FLINK-3323] [docs] Add documentation for NiFi connector.This closes #2099,2
[FLINK-4030] Revert Surefire version to 2.18.1The ScalaShellITCase sometimes gets stuck before test execution with no outputin the logs. We ran about a hundred builds against Surefire 2.18.1 whichconfirmed that the failures don't occur with this version.Waiting for an upstream fix until this can be reverted.This closes #2101,4
[FLINK-3969] Log Exceptions by InvokableThis closes #2091,2
[FLINK-4032] Replace all usage of Guava PreconditionsThis closes #2084,2
[FLINK-4028] Create correct TimeWindow in AbstractAlignedProcessingTimeWindowOperator,1
[FLINK-3908] [core] Fix resetting of FieldParser error state.This closes #2007,0
[FLINK-4024] [streaming] Fix InputFormat lifecycle in FileSourceFunction.This closes #2100,2
[FLINK-4063] Add Metrics Support for Triggers,1
[FLINK-3949] Collect Metrics in Runtime OperatorscurrentLowWatermarklastCheckpointSizenumBytes(In/Out)(Local/Remote)numRecords(In/Out)numSplitsProcessed (Batch only)This closes #2090,1
[FLINK-3317] [cep] Introduce timeout handler to CEP operatorIntroduce timeout handling flag for the NFACompilerExpose timeout handling via Java APIUpdate documentation of PatternStream and CEPIntroduce timeout select function to CEP Scala APIAdd select and flatSelect with timeout support to CEP Scala APIAdd test cases for timeout handlingUpdate documentationFix CEP Scala API completeness testThis closes #2041.,3
[FLINK-3332] Add Exactly-Once Cassandra connector,1
[FLINK-3311] Add At-Least-Once Cassandra connector,1
[FLINK-3332] Address pull request review commentsThis closes #1771,1
[FLINK-3650] [dataSet] Add maxBy/minBy to Scala DataSet APIThis closes #1856,5
[FLINK-3649] [docs] Add documentation for DataSet minBy / maxBy.This closes #2104,5
[FLINK-4077] [tableAPI] Register Pojo DataSet/DataStream as Table with field references.This closes #2107,5
"[FLINK-3667] refactor client communication classes- ClusterDescriptor: base interface for cluster deployment descriptors- ClusterDescriptor: YarnClusterDescriptor- ClusterClient: base class for ClusterClients, handles lifecycle of cluster- ClusterClient: shares configuration with the implementations- ClusterClient: StandaloneClusterClient, YarnClusterClient- ClusterClient: remove run methods and enable detached mode via flag- CliFrontend: remove all Yarn specific logic- CliFrontend: remove all cluster setup logic- CustomCommandLine: interface for other cluster implementations- Customcommandline: enables creation of new cluster or resuming from existing- Yarn: move Yarn classes and functionality to the yarn module (yarn  properties, yarn interfaces)- Yarn: improve reliability of cluster startup- Yarn Tests: only disable parallel execution of ITCasesThis closes #1978",3
[FLINK-3863] Yarn Cluster shutdown may fail if leader changed recently,4
"[FLINK-3937] implement -yid option to Flink CLI- enables to use list, savepoint, cancel and stop subcommands- adapt FlinkYarnSessionCli to also accept YARN application Id to attach to- update documentationThis closes #2034",2
[FLINK-3937] programmatic resuming of clusters- integrates with and extends the refactoring of FLINK-3667- enables to resume from Yarn properties or Yarn application id- introduces additional StandaloneClusterDescriptor- introduces DefaultCLI to get rid of standalone mode switches in CliFrontend- various fixes and improvements- remove legacy code from CliFrontend- change activation code of CustomCommandLine interface- use checked exceptions to signal supported operations- remove all checked exceptions of type Exception- fix logging and reduce verbosity of per-job clusters- print 'id' argument in YarnSessionCli- minor renaming of methods names- improve documentation- deprecate streaming option- extend CliFrontendYarnAddressConfigurationTest- move loading of custom CLIs to CliFrontendThis closes #2085,4
[FLINK-4079] YARN properties file used for per-job cluster,1
[FLINK-4075] ContinuousFileProcessingCheckpointITCase failed on Travis,0
[FLINK-4056] [tests] Harden SavepointITCaseTrying to prevent failures like [1] from happening again. I could notexplain who deleted the savepoint file concurrently with the existscheck. The savepoint is triggered and retrieved successfully. Shuttingdown the cluster does not remove any savepoints.[1] https://s3.amazonaws.com/archive.travis-ci.org/jobs/136396433/log.txt,5
[FLINK-4009][tests] fix Scala Shell external library tests for IntelliJ,3
"[FLINK-2733] [tests] Harden ZooKeeperLeaderElectionTestHardens ZooKeeperElectionTest by allowing the testing listener to returnout-dated leader information. This can happen if the ZooKeeper connectionwas suspended and the new leader information has not been sent to thetesting listener. In this case, the testing listener will be queried againto return the actual leader information.Add debug statements to ZooKeeperLeaderElectionTest.testZooKeeperReelectionThis closes #2103.",3
"[FLINK-2259] [ml] Add Splitter for train, validation and test data set generationThis closes #1898.",1
[FLINK-3977] [dataStream] InternalWindowFunctions implement OutputTypeConfigurable.- setOutputType calls are forwarded to wrapped functions.- test added for InternalWindowFucntions.This closes #2118,1
[FLINK-3949] [metrics] Add numSplitsProcessed counter metric.This closes #2119,1
[FLINK-3641] Add documentation for DataSet distributed cache.This closes #2122,5
[FLINK-4083] [dataSet] Introduce closure cleaning in Join.where() and equaltTo()This closes #2117.,4
[FLINK-4078] [dataSet] Introduce closure cleaning in CoGroup.where() and equaltTo()This closes #2116.,4
[FLINK-4089][yarn] fix null check in Yarn client,0
[FLINK-4090] Close of OutputStream should be in finally clauseThis closes #2132,1
"[FLINK-3714] Add Support for ""Allowed Lateness""Handle late elements and take careof cleaning the window state.",4
"[FLINK-3714] Remove Unneccesary Timer in EventTimeTriggerIn onElement() we registered a timer for the case where the watermark isalready past the end of the window and we're firing anyways. Now, onlyadd a timer if the watermark is not already past the end of the window.",1
[FLINK-3714] Rename getCleanupTimeForWindow to cleanupTime in WindowOperator,1
[FLINK-3714] Extend comments in WindowOperatorTestThese will make it easier to read the tests for our future selves andothers.,3
"[hotfix] Remove ""initialTime"" in WindowOperatorTestI added this once with the though of varying the start time for windowtests but it just makes stuff harder to parse for now.",1
[FLINK-4012] [docs] Fix link to Iterations in Basic Concepts page,2
[hotfix] [docs] Fix link to ResultTypeQueryable,2
[FLINK-3973] [docs] Emphasize Table/SQL links,2
[FLINK-4038] [dist] Escape JVM arguments in TaskManager startup script,2
[FLINK-4082] Add Setting for enabling/disabling LargeRecordHandlerBy default this is set to disabled because there are known issues whenusers specify a custom TypeInformation.,5
[FLINK-4091] Fix Guava shading in Cassandra connectorThis closes #2133,0
[FLINK-4092] [py] Fix Stringify function's implicit string type conversion problemThis closes #2130,0
"[FLINK-3626] [py] Add zipWithIndex()This closes #2136Create a task_id message in PythonStreamer that is passed throughto the underlying process and included in the RuntimeContext, whereit is accessible to the user and to functions.",1
[FLINK-4076] BoltWrapper calls super.dispose()This closes #2111,2
[FLINK-4097] Fix NullPointerException on CassandraSinkBase and CassandraTupleWriteAheadSink's close()This closes #2144,0
[FLINK-3752] Add Per-Kafka-Partition Watermark Generation to the docsThis closes #2142,2
"[FLINK-3868] [core] Specialized CopyableValue serializers and comparatorsUpdate ValueTypeInfo to use specialized serializers and comparators,many of which were already present.This closes #1983",1
[FLINK-3919] [ml] Implement DistributedRowMatrixThis closes #1996.,2
"[FLINK-3872] [table, connector-kafka] Add JsonRowDeserializationSchema- Adds a deserialization schema from byte[] to Row to be used in conjunction  with the Table API.",1
"[FLINK-3872] [table, connector-kafka] Add KafkaTableSourceThis closes #2069.",1
"[FLINK-4040] [dist] Allow JobManager/TaskManager-specific JVM args- Adds two new config keys for the start up scripts:    * env.java.opts.jobmanager    * env.java.opts.taskmanager- These are used in addition to the regular env.java.opts for the JobManager  and TaskManager, respectively.- Current behaviour is not changed. This does not address the JMX port  setting, because that is handled differently.This closes #2143.",0
[FLINK-3859] [table] Add BigDecimal/BigInteger support to Table APIThis closes #2088.,1
"[FLINK-4046] [runtime] Add direct state transition from RESTARTING to FAILEDA job can get stuck in FAILING if fail is called on a restarting job which hasnot yet reset its ExecutionJobVertices, because these vertices would not calljobVertexInFinalState. This method, however, must be called in order to transitionfrom FAILING to FAILED.Accept state FAILED when calling ExecutionGraph.restartThis closes #2095.",0
"[FLINK-3800] [runtime] Introduce SUSPENDED job statusThe SUSPENDED job status is a new ExecutionGraph state which can be reached from allnon-terminal states when calling suspend on the ExecutionGraph. Unlike the FAILED,FINISHED and CANCELED state, the SUSPENDED state does not trigger the deletion of thejob from the HA storage. Therefore, this state can be used to handle the loss ofleadership or the shutdown of a JobManager so that the ExecutionGraph is stopped butcan still be recovered. SUSPENDED is also a terminal state but it can be differentiated asa locally terminal state from FAILED, CANCELED and FINISHED which are globallyterminal states.Add test case for suspend signalAdd test case for suspending restarting jobAdd test case for HA job recovery when losing leadershipAdd online documentation for the job statusAdd ASF license header to job_status.svgNot throw exception when calling ExecutionGraph.restart and job is in state SUSPENDEDThis closes #2096.",1
"[FLINK-3667] additional cleanups in YarnClusterClient- remove ActorRunner thread, print status in finalizeCluster instead- prevent premature shutdown of actor system in shutdown method- prevent timeout exceptions due to poisoning the ApplicationClient",5
[FLINK-1946] reduce verbosity of Yarn cluster setupThis removes repeated printing of messages retrieved from the Yarncluster. Only new messages are printed.- reduce waiting time between subsequent cluster queriesThis closes #2147,1
"[FLINK-3838] upgrade commons-cli to fix parsing of jar argsJar arguments with a single '-' were not parsed correctly if options werepresent. For example, in `./flink run <options> file.jar -arg value` thejar arguments would be parsed as ""arg"" and ""value"". Interestingly, this onlyhappened when <options> were present.The issue has been fixed in commons-cli 1.3.1.A test case was added to test for regressions.This closes #2139",3
[FLINK-3757] clarify JavaDoc for addAccumulator methodThis closes #2138,1
[FLINK-4041] reduce log level for JobManager->ResourceManager timeoutsThese timeouts can be recovered and don't have to be logged as errorwith an Exception.This closes #2137,0
[FLINK-3864][yarn] check for prohibited strings in log output- enables actual checking of output which didn't work until now- uses regexp to check for prohibited stringsThis closes #2125,1
[FLINK-3907] [gelly] Directed Clustering CoefficientThis closes #2079,2
[FLINK-4121] Add timeunit (ms) to docs for timestamps and watermarksThis closes #2165,2
[hotfix][docs] Add warning to Cassandra documentation,2
[FLINK-4119] Refactor null checks in Cassandra IOFThis closes #2163,4
[FLINK-4074] Make metric reporters less blockingThis closes #2105,1
[hotfix] [metrics] Prevent registration exceptions,0
[FLINK-4087] [metrics] Improved JMX port handlingThis closes #2145,1
[FLINK-4093] Expose metric interfacesThis closes #2134,2
[FLINK-3951] Add Histogram metric typeThis closes #2112,1
"[FLINK-3974] Fix object reuse with multi-chainingBefore, a job would fail if object reuse was enabled and multipleoperators were chained to one upstream operator. Now, we create shallowcopies in BroadcastingOutputCollector and DirectedOutput if object reuseis enabled.",0
"[FLINK-3464] Use Processing-Time Clock in Window Assigners/TriggersIntroduces a custom TimeServiceProvider to the StreamTask.This is responsible for defining and updating the currentprocessingtime for a task and handling all related action,such as registering timers for actions to be executed inthe future.",5
[FLINK-3647] Change StreamSource to use Processing-Time Clock Service,1
Fixing typos in the javadocs.,2
Fix test formatting and move WindowAssignerContext to WindowAssigner,4
[FLINK-3898] [gelly] Adamic-Adar SimilarityThis closes #2160,2
[FLINK-4113] [runtime] Always copy first value in ChainedAllReduceDriverGuard test for ChainedAllReduceDriverThis closes #2156.,3
[FLINK-4099] Fix CliFrontendYarnAddressConfigurationTest failuresThis closes #2166,0
[hotfix] Remove JavaConversions from TaskManager,4
[cli] print correct help for savepoint command,5
[gelly-doc] Correct Scala code example,2
[FLINK-3277] [gelly] Use Value types in Gelly APIThis closes #1671,1
[FLINK-3879] [gelly] Native implementation of HITS algorithmThis closes #1967,2
[FLINK-3580] [table] Reintroduce Date/Time and implement scalar functions for itThis closes #2150.,1
[FLINK-4126] [tests] Increase timeout for ZooKeeperLeaderElectionTest.testZooKeeperReelectionThe test case failed because it exceeded the deadline. Increasing the deadline and decreasingthe number of reelection should harden the test case.,3
[FLINK-4080] Guarantee exactly-once for Kinesis consumer for failures in the middle of aggregated recordsThis closes #2180,0
[FLINK-4033] Polish up Kinesis connector documentationIncludes:1. Scala examples for consumer and producer2. Add information about AWS Kinesis service usage3. Add Kinesis connecter to the fault tolerance guarantees table4. Minor typo fix in Kafka documentationThis closes #2181,2
[FLINK-4085][Kinesis] Set Flink-specific user agentThis closes #2175,1
[hotfix][metrics] Harden JMXAvailability test,3
[docs] Add transition between Canceling and Failing to job_status.svg,0
[FLINK-4075] Fix unstable ContinuousFileProcessingCheckpointITCase,2
"Revert recent change to WrapperSetupHelperTest@PowerMockIgnore({""javax.management.*"", ""com.sun.jndi.*""}) was changedto @PowerMockIgnore(""javax.*""). This broke builds on Travis.",4
"Remove polluting log message in ContinuousFileReaderOperatorBefore, when snapshotting, we printed a log message about the fileinput format not being checkpointable when the current split was""null"". Now, we only print the message when when appropriate.This closes #2174",2
"[FLINK-3618] [gelly] Rename abstract UDF classes in Scatter-Gather implementationRename MessageFunction to ScatterFunctionand VertexUpdateFunction to GatherFunction.Change the parameter order in  Graph.runScatterGatherIteration(VertexUpdateFunction, MessagingFunction)to  Graph.runScatterGatherIteration(ScatterFunction, GatherFunction)This closes #2184",1
[FLINK-4132] [gelly] Fix boxed comparison in CommunityDetection algorithmThis closes #2185,0
[FLINK-4128] [build system] Fix directory for git-commit-id-pluginThis closes #2179,0
[FLINK-4062] Update Windowing Documentation,2
[FLINK-456] Basic JM Metric InfrastructureThis closes #2146,5
[FLINK-1550] JM JVM Metrics,2
[FLINK-4057] Slots/regTaskManagers/numJobs,2
[FLINK-4057] Checkpoint Metrics,2
[hotfix] Refactor TM Metric instantiation-formatting-don't use implicit conversions-fixed ObjectName for mapped bufferpool,0
[FLINK-4122] Disable root shading in Cassandra jar,2
[FLINK-4139][yarn] adjust task slots to parallelism correctly- user specifies no parallelism  -> parallelism is adjusted to #taskSlots * #nodes.- user specifies parallelism but no #taskSlots or too few slots  -> #taskSlots are set such that they meet the parallelism,1
[FLINK-3667] print JobID on submission,2
[FLINK-3667] change log level for JobNotFound to debug,0
[FLINK-3937] allow -yid without -m yarn-cluster,1
[FLINK-3667] delay connection to JobManager until job execution- lazily initialize ActorSystem- make sure it is not created before job execution- print connection information on the CLIThis closes #2189,5
[FLINK-3964] add hint to job submission timeout exception messageThis closes #2168,1
[FLINK-3675][yarn] improvements to library shipping- always ship the lib folder- properly setup the classpath from the supplied ship files- cleanup deploy() method of YarnClusterDescriptor- add test caseThis closes #2187,1
[hotfix] Fx TestingyYarnJobManager constructor,3
[FLINK-3675][yarn] use classpath paths relative to the application homeThis fixes a regression of 0483ba583c7790d13b8035c2916318a2b58c67d6where the classpath would start off with the application master's homedir.,0
"[FLINK-4141] remove leaderUpdated() method from ResourceManagerThis removes the leaderUpdated method from the framework. Further itlets the RM client thread communicate directly with theResourceManager actor. This is fine since the two are always spawnedtogether. Failures of the ResourceManager actor will lead to droppedmessages of the RM client thread. Failures of the RM client thread willinform the JobManager.The leaderUpdated() method was used to signal the ResourceManagerframework that a new leader was elected. However, the method was notalways called when the leader changed, only when a new leader waselected. This dropped all messages from the async Yarn RM clientthread (YarnResourceManagerCallbackHandler) for the time that the oldleader had failed and no new leader had been elected. The Yarn RM clientthread used leader tagged messages to communicate with the main FlinkResourceManager actor.This closes #2190",2
[FLINK-4144] Yarn properties file: replace hostname/port with Yarn application idThis closes #2191,2
[FLINK-3965] [gelly] Delegating GraphAlgorithmA delegating GraphAlgorithm wraps a GraphAlgorithm result with adelegating proxy object. The delegated object can be replaced when thesame algorithm is run on the same input with a mergeable configuration.This allows algorithms to be composed of implicitly reusable algorithmswithout publicly sharing intermediate DataSets.This closes #2032,5
[FLINK-4135] [gelly] Replace ChecksumHashCode as GraphAnalyticAdds a GraphAnalytic to replace the checksumHashCode Java and Scalautility functions.This closes #2188,1
[hotfix] [runtime] Fix tests for JobManager metrics,3
[hotfix] [clients] Replace test IP with reserved address,1
"[FLINK-4118] Update docker image to 1.0.3 and remove unneeded depsSome of the changes include:- Remove unneeded dependencies (nano, wget)- Remove apt lists to reduce image size- Reduce number of layers on the docker image (best docker practice)- Remove useless variables and base the code in generic ones e.g.FLINK_HOME- Change the default JDK from oracle to openjdk-8-jre-headless, based ontwo reasons:1. You cannot legally repackage the oracle jdk in docker images2. The open-jdk headless is more appropriate for a server image (no GUI stuff)- Return port assignation to the standard FLINK one:Variable: docker-flink -> flinktaskmanager.rpc.port: 6121 -> 6122taskmanager.data.port: 6122 -> 6121jobmanager.web.port: 8080 -> 8081This closes #2176",5
[FLINK-4027] Flush FlinkKafkaProducer on checkpointsThis closes #2108This closes #2058 because its an invalid pull request.,1
[hotfix] Fix NPE in NetworkStackThroughputITCase,1
"[hotfix] Fix AbstractKeyedCEPPatternOperator.restoreState()Before, this was trying to cast the StreamTaskState directly to aStateHandle<DataInputView> while it should take the operator state, i.e:StateHandle<DataInputView> stateHandle =  (StateHandle<DataInputView>) state.getOperatorState();",1
[FLINK-4109] [tableAPI] Change the name of ternary condition operator 'eval' to '?'This closes #2173.,1
"[FLINK-4134] Retire Late Windows/Elements in WindowOperatorBefore, when processing an element that would end up in a late window(when using a MergingWindowAssigner), the element would be added to theMergingWindowSet. After determining that the window is late it would notbe removed from the MergingWindowSet. This can lead to problems withother elements being merged into these ""phantom"" windows and causingtriggers to be added for empty windows.This also fixes the same code in EvictingWindowOperator.",1
[FLINK-4086] [tableAPI] Hide internal methods of Expressions from Table API.This closes #2126.,2
Merge branch 'FLINK-4086',2
[FLINK-4145] Harden JMX testsUse distinct non-default port ranges for all tests.,3
[FLINK-4115] Skip filesystem checks for filesystems with no built-in support,1
[FLINK-4115] Remove filesystem initialisation from FsStateBackend constructor,5
"Change Validation Exception to LOG.warn() in FsStateBackendBefore, job would fail with an exception if the checkpoint filesystemwas not accessible from the client. This is preventing some correct jobsfrom running.Now, only print a warning.This closes #2157",2
"[FLINK-3995] [build] Properly structure test scopes and dependenciesMakes the JUnit test utils (TestLogger, retry rules, ...) properly available toother projects without the 'flink-core' test-jar, via the 'flink-test-utils-junit' project.Makes the ForkableMiniCluster, TestEnvironment,  and other test utilities available in the 'main'scope of the 'flink-test-utils' project.Creates a 'flink-test-utils-parent' project that holds the 'flink-test-utils-junit' and'flink-test-utils' project.Also moves some tests between projects and inlines some very simple utility functions inorder to simplify some test jar dependencies.",3
[FLINK-3995] [build] flink-test-utils also contains the streaming test utilities.Test utilities include the StreamingMultipleProgramsTestBase and StreamingTestEnvironment.This moves the ITCases for streaming into 'flink-tests' to achieve that.This closes #2092,3
[FLINK-3995] [build] Fix failing tests and add missing dependenciesThis closes #2148,1
[FLINK-4133] Reflect streaming file source changes in documentationThis closes #2198,2
[FLINK-4146] Fix YARN test failureThis closes #2200,0
[FLINK-3231] FlinkKinesisConsumer rework to handle Kinesis reshardingThis also fixes FLINK-4020: remove shard list querying from Kinesis consumer constructorThis closes #2131,4
[hotfix] [core][gelly] Fix license formatting,0
Add proper web monitor shutdown to standalone modeBefore the WebRuntimeMonitor was not properly stopped after the ActorSystem hasbeen terminated.,5
[FLINK-4151] Split test execution on travis into two groups(The groups being tests starting from A-N and N-Z)This closes #2201,3
Correct typos in Table API docs; update enumeration of supported table sources,1
[FLINK-4137] Tell Akka to shut down the JVM on fatal errorsThis closes #2205,0
[FLINK-4158] Fix Scala QS StreamingJob importThis closes #2204,2
[hotfix] Quickstart docs respect artifactIdThis closes #2203,2
[FLINK-4160][yarn] Show input validation errorsThis closes #2207,0
[tools] Update copy files function in release script- people.apache.org has moved to home.apache.org- rsync currently not supported,1
[FLINK-3034] Redis Sink ConnectorThis closes #1813,2
[hotfix] [streaming-connectors] Fix Kinesis connector test-utils dependency,3
[hotfix] [build] Include Kinesis tests in CI builds,3
[FLINK-3648] Introduce Trigger Test Harness,3
[FLINK-4176][kinesis-connector] Remove Java8-specific `Long.hashCode()` method from Kinesis connectorThis closes #2215,4
[hotfix][metrics] Declare all used dependencies,1
[hotfix][metrics] Fix typos,2
[FLINK-3942] [tableAPI] Add support for INTERSECT and update documentThis closes #2159.,2
"[FLINK-4171] [metrics] Replace : chars in StatsD metric namesThe StatsD server rejects metrics whose names contain the : character. Therefore,metric names which contain : chars will be altered so that : is replaced by -.This closes #2212.",2
[FLINK-4172] [gelly] Don't proxy a ProxiedObjectRetrieve the proxied object and wrap in a new proxy.This closes #2213,1
[FLINK-4019][kinesis-connector] Use Kinesis records' approximateArrivalTimestampUsed in the following:1) Exposed through the KinesisDeserializationSchema for users to obtain2) Attatched to records as the default event timeThis closes #2214,1
[FLINK-4116] Metrics documentation,2
[FLINK-4116][metrics] Move config keys to ConfigConstantsThis closes #2158,5
[FLINK-4096] Ensure JarOutputStream is always closedThis closes #2172,2
[hotfix][metrics] Remove leftover comment Registry,1
[hotfix] fix errors and formatting in NiFi documentationThis closes #2224,2
[FLINK-4185] Reflecting rename from Tachyon to Alluxio.This closes #2222,2
[FLINK-3943] [table] Add support for EXCEPT operatorThis closes #2169.,1
[FLINK-4157] Catch Kafka metrics serialization exceptionsThis closes #2206,2
"[FLINK-4154] [core] Correction of murmur hash breaks backwards compatibilityRevert ""[FLINK-3623] [runtime] Adjust MurmurHash Algorithm""This reverts commit 641a0d436c9b7a34ff33ceb370cf29962cac4dee.This closes #2223",4
[FLINK-3190] failure rate restart strategyAdd toString method to TimeReintroduce org.apache.flink.streaming.api.windowing.time.Time for backwards compatibilityRemove Duration from FailureRateRestarStrategyThis closes #1954.,0
[FLINK-4191] Expose shard information in kinesis deserialization schemaThis closes #2225,5
[FLINK-4018][kinesis-connector] Add configuration for idle time between get requests to Kinesis shardsThis closes #2071,1
[hotfix][docs] Add note about Kinesis producer limitationsThis closes #2229,1
[FLINK-3916] [table] Allow generic types passing the Table APIThis closes #2197.,4
[hotfix] [execution graph] Null restart strategy field in ExecutionGraph when archiving,0
[FLINK-4111] [table] Flink Table & SQL doesn't work in very simple exampleThis closes #2209.,1
[FLINK-4123] Cassandra sink checks for exceptions in ack phaseadd serialVersionUIDswitch to AtomicReferencewait-notifydisable loggingadd test case for leaving ackPhaseLoopOnExceptionprevent infinite loop in testThis closes #2183.,3
"[FLINK-4123] [cassandra] Fix concurrency issue in CassandraTupleWriteAheadSinkThe updatesCount variable in the CassandraTupleWriteAheadSink.sendValues did not haveguaranteed visibility. Thus, it was possible that the callback thread would read anoutdated value for updatesCount, resulting in a deadlock. Replacing IntValue updatesCountwith AtomicInteger updatesCount fixes this issue.Furthermore, the PR hardens the CassandraTupleWriteAheadSinkTest which could have failedwith a NPE if the callback runnable was not set in time.",1
[FLINK-4127] Check API compatbility for 1.1 in flink-coreThis closes #2177,2
[FLINK-4200] [Kafka Connector] Kafka consumers logs the offset from which they restoreThis closes #2230,1
[FLINK-4159] Remove Quickstart exclusions for unused dependenciesThis closes #2217,1
[FLINK-4143][metrics] Configurable delimiterThis closes #2219,5
[hotfix] [documentation] Add missing GemInclude 'json' as a required dependency for building the documentation.,2
[hotfix] Reuse getMaxJvmHeapMemory() in EnvironmentInformation#getSizeOfFreeHeapMemory()This closes #2235,5
[FLINK-4167] [metrics] Make IOMetricGroup register its metrics at the parent metric groupIntroduce ProxyMetricGroup which forwards metric registration calls to its parent.The IOMetricGroup then extends ProxyMetricGroup so that all metric registrationsare executed on the parent of IOMetricGroup.This closes #2210.,1
[hotfix] [network] Add DEBUG log messages to intermediate resultsThis adds log messages about created result partition consumers andspilling.,1
[FLINK-4197] Allow Kinesis endpoint to be overridden via configThis closes #2227,5
[hotfix][kinesis-connector] Remove duplicate info in KinesisDeserializationSchemaThis closes #2234,5
[FLINK-3477] [runtime] Add hash-based combine strategy for ReduceFunctionThis closes #1517 (1/2),1
[FLINK-2246] [runtime] Add ChainedReduceCombineDriverThis closes #1517 (2/2),1
[FLINK-4206][metrics] Remove alphanumeric name restrictionThis closes #2237,4
[FLINK-4170] Simplify Kinesis connecter config keys to be less overly verboseThis closes #2228,1
[doc] [hotfix] Fix Gelly readCsvFile example,2
[hotfix] [kafka connector] Minor code cleanups in the Kafka Producer,4
[hotfix] [runtim] Minor code cleanups.,4
"[FLINK-4196] [runtime] Remove the 'recoveryTimestamp' from checkpoint restores.The 'recoveryTimestamp' was an unsafe wall clock timestamp attached by the masterupon recovery. This this timestamp cannot be relied upon in distributed setups,it is removed.",4
[FLINK-4214] [web dashboard] Properly increment the exceptions counterThis closes #2242,2
[FLINK-4216] [docs] Fixed example.This closes #2246This closes #2247,0
[FLINK-3666] Remove all remaining Nephele references,5
[FLINK-3630] [docs] Little mistake in documentationThis closes #2254,2
[hotfix] [metrics] Prevent log flooding from collisionsThis closes #2135,2
[FLINK-4142][docs] Add warning about YARN HA bugThis closes #2255,0
"[licenses] Remove not included dependency from LICENSEThis closes #2186Flink does not include the anchor.js file but loads it dynamically when displayingthe documentation. Therefore, we don't have to include anchor.js in the LICENSE file.",2
[FLINK-4053] Add tests for RMQ sink and check connection for nullThis closes #2128,3
[FLINK-4017] [py] Add Aggregation support to Python APIAssembles and applies a GroupReduceFunction using pre-definedAggregationOperations in Python. References to aggregations inPythonOperationInfo and other Java classes in the Python APIremoved since aggregations are now handled by Python.This closes #2115,0
"[FLINK-4184] [metrics] Replace invalid characters in ScheduledDropwizardReporterThe GraphiteReporter and GangliaReporter report metric names which can contain invalidcharacters. These characters include quotes and dots. In order to properly report metricsto these systems, the afore-mentioned characters have to be replaced in metric names.The PR also removes quotes from the garbage collector metric name.The PR sets the default value for TTL in the GangliaReporter to 1, because -1 causes thereporter to fail.Introduce CharacterFilter to filter invalid characters from the metric name outThe character filter is applied to all components of the fully qualified metric name.The ScheduledDropwizardReporter and AbstractReporter implement this interface to generatecompatible metric names.Correct AbstractMetricGroup.getMetricIdentifier; Add test cases to check that reporters filter out invalid charactersThis closes #2220.",3
[FLINK-4186] Use Flink metrics to report Kafka metricsThis commit also adds monitoring for the current and committed offsetThis closes #2236,1
[FLINK-3466] [tests] Add serialization validation for state handles,0
"[FLINK-3466] [runtime] Make state handles cancelable.State handles are cancelable, to make sure long running checkpoint restore operations dofinish early on cancallation, even if the code does not properly react to interrupts.This is especially important since HDFS client code is so buggy that it deadlocks wheninterrupted without closing.",0
Replace StreamEvent by StreamRecord in CEP Tests,3
[FLINK-4149] Fix Serialization of NFA in AbstractKeyedCEPPatternOperatorNFA is Serializable and has readObject()/writeObject() methods. InAbstractKeyedCEPPatternOperator a KryoSerializer was used as theTypeSerializer for the ValueState that holds NFA instances. Kryo doesnot call readObject()/writeObject() therefore the state of the NFA wasinvalid after deserialization.This change adds a new TypeSerializer for NFA that usesJava Serialization. In the long run it will be better to get rid of thereadObject()/writeObject() methods and instead efficiently serializeusing a specialized TypeSerializer.,1
"[FLINK-4162] Fix Event Queue Serialization in Abstract(Keyed)CEPPatternOperatorBefore, these were using StreamRecordSerializer, which does not serializetimestamps. Now it uses MultiplexingStreamRecordSerializer.This also extends the tests in CEPOperatorTest to test that timestampsare correctly checkpointed/restored.",3
Fix Displayed CEP Operator Names,1
[FLINK-4165] Add warning about equals/hashCode to CEP doc,2
Allow Setting StateBackend in OneInputStreamOperatorTestHarness,3
"[FLINK-4169] Fix State Handling in CEPBefore, ValueState.update() was not called after changing the NFA or thepriority queue in CEP operators. This means that the operators don'twork with state backends such as RocksDB that strictly require thatupdate() be called when state changes.This changes the operators to always call update() and also introduces atest that verifies the changes.",4
[FLINK-4209] Change hostname resolution from IP to nameThis solves issues when a host has multiple IPs,0
[FLINK-4209] Separate build dependencies in the docker image and remove them once it is ready,4
[FLINK-4209] Add debug information of the build steps,5
[FLINK-4209] Simplify docker-compose script (volumes are now local),2
[FLINK-4209] Remove supervisord dependency for the docker image,2
"[FLINK-3713] [clients, runtime] Use user code class loader when disposing savepointDisposing savepoints via the JobManager fails for state handles or descriptors,which contain user classes (for example custom folding state or RocksDB handles).With this change, the user can provide the job JAR when disposing a savepoint inorder to use the user code class loader of that job. The JAR is optional, hencenot breaking the CLI API.This closes #2083.",4
[hotfix] correct typo in method name,2
[hotfix] fix warning b/c of unspecified exception type,2
[FLINK-4232] Make sure ./bin/flink returns correct pidThis closes #2268,2
[FLINK-2985] [table] Allow different field names for unionAll() in Table APIThis closes #2078.,1
[FLINK-4130] [table] CallGenerator could generate illegal code when taking no operandsThis closes #2182.,2
[FLINK-4183] [table] Move checking for StreamTableEnvironment into validation layerThis closes #2221.,5
[FLINK-4199] fix misleading CLI messages during job submission- change CLI message upon cluster retrieval- save JobExecutionResult for interactive executions- only print Collection size in accumulator results- remove unused helper methodThis closes #2264,1
[FLINK-4166] [Distributed Coordination] zookeeper namespaces (cli parameter -z)This closes #2249,2
[hotfix] Fixes broken TopSpeedWindowing scala exampleIntegrated PR commentsThis closes #2259.,0
[FLINK-4070] [table] Support literals on left side of binary expressionsThis closes #2120.,1
[FLINK-3729] [table] Several SQL tests fail on Windows OSThis closes #2238.,0
[FLINK-3956] Make FileInputFormats independent from ConfigurationParameters of some input formats that was only possible to beset through the Configuration object now have setter methodsthat allow the user to do so.Values set by the setters cannot be reset by the configurationobject.,5
[FLINK-4229] Do not start any Metrics Reporter by default,2
[FLINK-4230] [DataStreamAPI] Add Session Windowing ITCase,1
[FLINK-4230] [DataStreamAPI] PR feedback on Session Windowing ITCase,5
[FLINK-4237] [runtime] Cancel savepoints on declined snapshots,1
[FLINK-4238] Only allow/require query for Tuple Stream in CassandraSink,1
"[FLINK-4202] Add restarting time JM metricThis PR adds a JM metric which shows the time it took to restart a job. The time ismeasured between entering the JobStatus.RESTARTING and reaching the JobStatus.RUNNINGstate. During this time, the restarting time is continuously updated. The metric onlyshows the time for the last restart attempt. The metric is published in the job metricgroup under the name of ""restartingTime"".This closes #2271.",5
[FLINK-4229] [metrics] Only start JMX server when port is specifiedThis closes #2279,2
[FLINK-4202] [metrics] Update restarting time metric documentationThis closes #2284.,2
"[FLINK-4201] [runtime] Forward suspend to checkpoint coordinatorSuspended jobs were leading to shutdown of the checkpoint coordinatorand hence removal of checkpoint state. For standalone recovery modethis is OK as no state can be recovered anyways (unchanged in this PR).For HA though this lead to removal of checkpoint state, which weactually want to keep for recovery.We have the following behaviour now:-----------+------------+-------------------           | Standalone | High Availability-----------+------------+------------------- SUSPENDED |  Discard   |       Keep-----------+------------+------------------- FINISHED/ |  Discard   |     Discard FAILED/   |            | CANCELED  |            |-----------+------------+-------------------This closes #2276.",0
[FLINK-4213] [gelly] Provide CombineHint in Gelly algorithmsThis closes #2248,1
"[FLINK-4217] [gelly] Gelly drivers should read CSV values as stringsThe user must now specify the ID type as ""integer"" or ""string"" whenreading a graph from a CSV file.This closes #2250",2
"[hotfix] Prevent CheckpointCommitter from failing jobPrevents the CheckpointCommitter from failing a job, if eithercommitCheckpoint() or isCheckpointCommitter() failed. Instead, we willtry again on the next notify().This closes #2287",1
"[FLINK-4150] [runtime] Don't clean up BlobStore on BlobServer shut downThe `BlobServer` acts as a local cache for uploaded BLOBs. The life-cycle ofeach BLOB is bound to the life-cycle of the `BlobServer`. If the BlobServershuts down (on JobManager shut down), all local files will be removed.With HA, BLOBs are persisted to another file system (e.g. HDFS) via the`BlobStore` in order to have BLOBs available after a JobManager failure (orshut down). These BLOBs are only allowed to be removed when the job thatrequires them enters a globally terminal state (`FINISHED`, `CANCELLED`,`FAILED`).This commit removes the `BlobStore` clean up call from the `BlobServer`shutdown. The `BlobStore` files will only be cleaned up via the`BlobLibraryCacheManager`'s' clean up task (periodically or onBlobLibraryCacheManager shutdown). This means that there is a chance thatBLOBs will linger around after the job has terminated, if the job managerfails before the clean up.This closes #2256.",4
[FLINK-3901] [table] Create a RowCsvInputFormat to use as default CSV IF in Table API,1
[FLINK-3901] [table] Convert Java implementation to Scala and fix bugsThis closes #2283.,0
[FLINK-3891] [table] Add a class containing all supported Table API typesThis closes #2292.,1
[FLINK-4244] [docs] Field names for union operator do not have to be equalThis closes #2280.,1
[FLINK-2125][streaming] Delimiter change from char to stringThis closes #2233,4
[hotfix] [gelly] Reduce maximum number of generator blocksThe default maximum akka transfer size is 10 MB. This commit reduces thenumber of generator blocks from 2^20 to 2^15 which removes the limit ongraph size. The original limit of one millions blocks was intended tofuture-proof scalability.This is a temporary fix as graph generation will be reworked in FLINK-3997.,2
[FLINK-4103] [table] Modify CsvTableSource to implement StreamTableSourceThis closes #2162.,2
[FLINK-4103] [table] Add CsvTableSource docs and Java accessibility,2
"[FLINK-4067] [runtime] Add savepoint headersSavepoints were previously persisted without any meta data using defaultJava serialization of `CompletedCheckpoint`. This commit introduces asavepoint interface with version-specific serializers and storessavepoints with meta data.Savepoints expose a version number and a Collection<TaskState> forsavepoint restore.Currently, there is only one savepoint version:SavepointV0 (Flink 1.1): This is the current savepoint version, whichholds a reference to the Checkpoint task state collection, but isserialized with a custom serializater not relying on default Javaserialization. Therefore, it should not happen again that we need tostick to certain classes in future Flink versions.The savepoints are stored in `FsSavepointStore` with the followingformat:MagicNumber SavepointVersion Savepoint  - MagicNumber => int  - SavepointVersion => int (returned by Savepoint#getVersion())  - Savepoint => bytes (serialized via version-specific SavepointSerializer)The header is minimal (magic number, version). All savepoint-specificmeta data can be moved to the savepoint itself. This is also were wewould have to add new meta data in future versions, allowing us todifferentiate between different savepoint versions when we change theserialization stack.All savepoint related classes have been moved from checkpoint to a newsub package `checkpoint.savepoint`.This closes #2194.",1
[FLINK-4239] Set Default Allowed Lateness to Zero and Make Triggers Non-PurgingThis closes #2278.,1
[FLINK-4210][metrics] Move close()/isClosed() out of MetricGroupThis closes #2286,4
[FLINK-4192] [metrics] Move metrics classes out of 'flink-core'- moved user-facing API to 'flink-metrics/flink-metrics-core'- moved JMXReporter to 'flink-metrics/flink-metrics-jmx'- moved remaining metric classes to 'flink-runtime'This closes #2226,2
[travis] remove outdated comment regarding snapshots,5
"[FLINK-4152] Allow re-registration of TMs at resource manager- Add YarnFlinkResourceManager test to reaccept task manager registrations from a re-elected job manager- Remove unnecessary sync logic between JobManager and ResourceManager- Avoid duplicate reigstration attempts in case of a refused registration- Add test case to check that not an excessive amount of RegisterTaskManager messages are sent- Remove containersLaunched from YarnFlinkResourceManager and instead not clearing registeredWorkers when JobManager loses leadership- Let YarnFlinkResourceManagerTest extend TestLogger- Harden YarnFlinkResourceManager.getContainersFromPreviousAttempts- Add FatalErrorOccurred message handler to FlinkResourceManager;  Increase timeout for YarnFlinkResourceManagerTest;  Add additional constructor to TestingYarnFlinkResourceManager for tests- Rename registeredWorkers field into startedWorkersAdditionally, the RegisterResource message is renamed into NotifyResourceStarted whichtells the RM that a resource has been started. This reflects the current semantics ofthe startedWorkers map in the resource manager.- Fix concurrency issues in TestingLeaderRetrievalServiceThis closes #2257",3
"[FLINK-4261][tools] retry in case of failed snapshot deploymentUnfortunately, we can't deploy snapshots atomically using the Nexusrepository. The staged process which leads to an atomic deployment isonly designed to work for releases. Best we can do is to retrydeploying artifacts in case of failures.- introduce retry in case of failure of snapshot deployment- simplify deployment scriptThis closes #2296",0
"[FLINK-4246] Allow Specifying Multiple Metrics ReportersThis also updates documentation and tests.Reporters can now be specified like this:metrics.reporters: foo,barmetrics.reporter.foo.class: JMXReporter.classmetrics.reporter.foo.port: 10metrics.reporter.bar.class: GangliaReporter.classmetrics.reporter.bar.port: 11metrics.reporter.bar.something: 42",3
[FLINK-4258] fix potential NPE in SavepointCoordinator,0
[FLINK-4207] WindowOperator becomes very slow with allowed lateness,1
[FLINK-3904] enhancements to GlobalConfiguration- fail if config couldn't be loaded- remove duplicate api methods- remove undocumented XML loading feature- generate yaml conf in tests instead of xml conf- only load one config file instead of all xml or yaml files (flink-conf.yaml)- make globalconfiguration non-global and remove static SINGLETON- fix test cases- add test casesThis closes #2123,3
[FLINK-4179] [table] Update TPCHQuery3Table exampleThis closes #2232.,5
[FLINK-4179] [table] Additional TPCHQuery3Table example improvements,1
[FLINK-4259] Added statement in FileCache to close the FSDataOutputStream objectCloses #2299,5
[hotfix] [docu] Add missing tick,1
[hotfix] [docu] Fix System Metrics table,5
[FLINK-4269] [webfrontend] Decrease log level in RuntimeMonitorHandlerThis closes #2307.,0
[docs] require at least Ruby 1.9.0 for buildingThe json module is bundled with Ruby from 1.9.0 and upwards. Thiscures dependency problems with different versions of Ruby.,0
[FLINK-4279] [py] Set flink dependencies to providedThis closes #2308,1
[FLINK-4277] Fix TaskManagerConfigurationTest#testDefaultFsParameterLoadingThis closes #2310,5
"[FLINK-4289] Unset -x flag for .java filesSome source files had the -x flag set:Before this change:```$ find . -perm +111 -type f | grep ""\.java""./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/places/Attributes.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/places/BoundingBox.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/places/Places.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/Contributors.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/Coordinates.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/CurrentUserRetweet.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Entities.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/HashTags.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Media.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Size.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Symbol.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/URL.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/UserMention.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/Tweet.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/User/Users.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/Graph.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/ApplyFunction.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/GatherFunction.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/GatherSumApplyIteration.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/Neighbor.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/SumFunction.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/GSAConnectedComponents.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/GSASingleSourceShortestPaths.java./flink-libraries/flink-gelly-examples/src/main/java/org/apache/flink/graph/examples/GSASingleSourceShortestPaths.java./flink-libraries/flink-gelly-examples/src/test/java/org/apache/flink/graph/test/GatherSumApplyITCase.java./flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java```After this change:```$ find . -perm +111 -type f | grep ""\.java""```",4
[FLINK-4284] [docu] Fix broken linksThis closes #2311,2
"Revert ""[FLINK-4154] [core] Correction of murmur hash breaks backwards compatibility""This reverts commit 81cf2296683a473db4061dd3bed0aeb249e05058.We had an incorrent implementation of Murmur hash in Flink 1.0. Thiswas fixed in 641a0d4 for Flink 1.1. Then we thought that we need torevert this in order to ensure backwards compatability between Flink1.0 and 1.1 savepoints (81cf22). Turns out, savepoint backwardscompatability is broken for other reasons, too. Therefore, we revert81cf22 here, ending up with a correct implementation of Murmur hashagain.",4
"[FLINK-4296] Fixes failure reporting of consumer task scheduling when producer has already finishedThis PR changes the failure behaviour such that the consumer task is failed instead of theproducer task. The latter is problematic, since a finsihed producer task will simply swallowscheduling exception originating from scheduling the consumer task.This closes #2321.",1
"[FLINK-4299] show loss of job manager in ClientThis prints a message when the leading JobManager changes after firstconnecting to a JobManager. Further, it prints a message when a connectionto a JobManager has been established.This closes #2322.",4
[hotfix] [docs] Remove obsolete file 'plotPoints.py',2
[FLINK-4285] [docs] Update the setup quickstart guide with the new SocketWindowWordCount example,1
[FLINK-4292] [batch connectors] Fix setup of HCatalog project by adding Scala SDK dependency,1
[FLINK-4251] [Rabbit MQ] Allow users to override queue setup in order to customize queue configThis closes #2281,5
[hotfix] Remove various '.hidden' files that seem to have been accidentally committed,2
[hotfix] [build] Update LICENSE file with new URL of simplejmx dependency,1
[FLINK-4298] [storm compatibility] Clean up unnecessary dependencies in 'flink-storm',2
[FLINK-4290] [Cassandra Connector] Skip CassandraConnectorTest on Java 7 buildsCassandra needs Java 8 to run reliably.,1
[cleanup] remove unused code- remove unused utility testing function- remove leftover FLINK_CONF_DIR jvm propertyThis closes #2325,5
[FLINK-4298] [storm compatibility] Add proper repository for Closure dependencies.Adds further dependency exlcusions for unneeded (and potentially conflicting) storm dependencies.,5
[FLINK-4180] [FLINK-4181] [table] add Batch SQL and Stream SQL and Stream Table API examplesThis closes #2274.,1
[FLINK-4180] [FLINK-4181] [table] Ensure examples consistency,2
[FLINK-4203] [table] [docs] Improve Table API documentationThis closes #2293.,2
[hotfix] Fix exception message,0
"[FLINK-4306] [storm compatibility] Fix dependencies in flink-storm and flink-storm-examples  - Flink dependencies are now 'provided'  - flink-storm-examples has no direct storm-core dependency, but only depends through flink-storm",2
[hotfix] [tests] Fix minor test instability in ConnectionUtilsTest,3
[hotfix] Fix failing Table API test and checkstyle violation,3
[FLINK-4307] [streaming API] Restore ListState behavior for user-facing ListStates,1
[build] Bump version to 1.2-SNAPSHOTThis closes #2324,5
[build] Bump docs and tools to version 1.2-SNAPSHOT,2
[FLINK-4161] [build] Add Quickstart exclusion for flink-dist dependenciesThis closes #2309,2
"[build] Move GitHub specific files to '.github', update release script",5
[FLINK-4219] [scripts] Quote PDSH opts in start-cluster.shThis prevents word splitting if the user configures multiple SSHoptions.This closes #2253.,5
"[FLINK-4314] [tests] Fix test instability in JobManagerHAJobGraphRecoveryITCaseThe test was relying on the JobManager shutting down before theTaskManager, which is not necessarily the case. If the TaskManagershuts down before the JobManager, the JobGraph could reach the finalstate FAILED, in which case all HA state is removed.To circumvent this, we add a restart strategy.",1
[FLINK-4308] [web frontend] Add optional config parameter 'jobmanager.web.uploaddir' to specifiy job jar locationThis allows users for example to prepackage jars in docker imagesThis closes #2335,2
[FLINK-4094] [core] Add a warning to only use off heap memory with pre-allocation=trueThis closes #2336,1
"[FLINK-4310] [build] Selectively run API compatibility checks in API projects.This moves the API compatibility checks into the API projects that use stability annotations.Previously, every project ran the tests, regardless of whether it contained public API classes or not.This closes #2334",3
[FLINK-4297] [yarn] Decode URL encoded fat jar pathThis solves problems with spaces and special characters in theautomatically determined fat jar path which is returned URL encoded.This closes #2320,0
[hotfix] [tests] Fix minor JavaDoc warnings,2
[FLINK-4256] [distributed runtime] Clean up serializability of ExecutionGraph,4
[FLINK-4304] [runtime-web] Jar names that contain whitespace cause problems in web clientThis closes #2327.,0
[FLINK-3138] [types] Method References are not supported as lambda expressionsThis closes #2329.,1
[hotfix] Add try-catch around test tearDownhttps://s3.amazonaws.com/archive.travis-ci.org/jobs/150069581/log.txt,5
[hotfix][kinesis] Fix build instructions,0
[FLINK-4226] Typo: Define Keys using Field Expressions example should use window and not reduce,1
[FLINK-4276] Fix TextInputFormatTest#testNestedFileReadThis closes #2312,3
[FLINK-4291] [metrics] Add log entry for scheduled reportersThis closes #2318,1
[hotfix] [distributed runtime] Add overflow check for ZooKeeper checkpoint ID counter.,1
[FLINK-4329] [distributed runtime] Clean up ScheduleModeRemove unsopported 'backtracking' option.Pick better names for 'all' and 'from sources' options.,1
[FLINK-4332] [checkpoints] Fix SavepointV1Serializer read() / readFully(),0
[FLINK-4333] [checkpoints] Clean up naming mixups for SavepointV0 / SavepointV1 / SavepointV01,4
[hotfix][build] Fix release script,0
[build] disable travis cache,5
[FLINK-4212] [scripts] Lock PID file when starting daemons,2
[FLINK-2090] [core] Truncate 'toString()' of CollectionInputFormat when the collection is hugeThis closes #2323,1
"[FLINK-3779] [runtime] Add getSerializedValue(byte[]) to KvState[statebackend-rocksdb, core, streaming-java]- Adds the getSerializedValue(byte[]) to KvState, which is used to query single  KvState instances. The serialization business is left to the KvState in order  to not burden the accessor -- e.g. the querying network thread -- with setting  up/accessing the serializers.- Adds quaryable flag to the StateDescriptor. State, which sets a queryable state  name will be published for queries to the KvStateRegistry.- Prohibts null namespace and enforces VoidNamespace instead. This makes stuff  more explicit. Furthermore, the concurrent map used for queryable memroy state  does not allow working with null keys.",1
"[FLINK-3779] [runtime] Add KvStateRegistry for queryable KvState[streaming-java]- Adds a KvStateRegistry per TaskManager at which created KvState instances are  registered/unregistered.- Registered KvState instances are reported to the JobManager, whcih can be  queried for KvStateLocation.",1
"[FLINK-3779] [runtime] Add KvState network client and server- Adds a Netty-based server and client to query KvState instances, which have  been published to the KvStateRegistry.",1
[FLINK-3779] [runtime] Add KvStateLocation lookup service- Adds an Akka-based KvStateLocation lookup service to be used by the client  to look up location information.,5
"[FLINK-3779] [runtime] Add QueryableStateClient- Adds a client, which works with the network client and location lookup service  to query KvState instances.- Furthermore, location information is cached.",5
"[FLINK-3779] [streaming-java, streaming-scala] Add QueryableStateStream to KeyedStream[runtime, test-utils, tests]- Exposes queryable state on the API via KeyedStream#asQueryableState(String, StateDescriptor).  This creates and operator, which consumes the keyed stream and exposes the stream  as queryable state.This closes #2051.",1
[FLINK-4337] [build] Remove unnecessary Scala Suffix from Hadoop 1 shaded artifactThis closes #2343,0
[build] [hadoop compatibility] Remove unneeded dependency to 'flink-clients'Also includes minor code cleanups for warnings and more explicit serialization behavior.,2
[FLINK-4316] [core] [hadoop compatibility] Make flink-core independent of HadoopThis commit moves all 'Writable' related code to the 'flink-hadoop-compatibility' projectand uses reflection in 'flink-core' to instantiate WritableTypeInfo when needed.This closes #2338,5
[FLINK-4342] [build] Fix dependencies of flink-connector-filesystem  - Remove unneeded Guava dependency  - Set hadoop-shaded-artifact dependency to 'provided'This closes #2346,1
[hotfix] [runtime] Remove unneeded check in KvStateClientTestThe removed condition check was wrong and lead to unnecessarily longwait times before the test could succeed.,3
[docs] Remove deprecated variables,4
[FLINK-3940] [table] Add support for ORDER BY OFFSET FETCHThis closes #2282.,1
[FLINK-3940] [table] Additional improvements- Improve overflow handling (support for more records than Int.MAX)- SQL LIMIT support- Bug fixing and improved docs,2
[hotfix][docs] Fix RMQ Sink code example,0
[FLINK-4270] [table] 'as' in front of join does not workThis closes #2306.,1
[FLINK-4242] [table] Improve validation exception messagesThis closes #2290.,5
[maven] fix snapshot deployment of hadoop1 version,0
[FLINK-4359] [table] Add INTERVAL typeThis closes #2348.,1
[FLINK-4236] fix error handling for jar files with no main methodThis change shows only entry classes with a valid main method. Itignores classes which contain no main method.This closes #2347,1
[FLINK-4387] [runtime] Ignore test in KvStateClientTestInstable test on TravisCI. Most likely caused by a Netty issue (#4357).,0
[FLINK-4385] [table] Union on Timestamp fields does not workThis closes #2362.,1
[FLINK-3097] [table] Add support for custom functions in Table APIThis closes #2265.,1
[FLINK-4394] RMQSource: QueueName accessible for subclassesThe queueName is needed if the subclasses override `setupQueue`.This closes #2373,1
[FLINK-4309] Fix potential NPE in DelegatingConfigurationThis closes #2371.,5
[FLINK-4388] [core] Make MemorySegmentFactory check and initialization atomic.This prevents rare race conditions when starting multiple TaskManagers in the same JVM.,5
[FLINK-4366] Add 'forceNonParallel()' to stream transformations and enforce parallelism=1 for AllWindowedStreamThis closes #2354,1
[hotfix] [tests] Let SlotCountExceedingParallelismTest use the TestLogger,3
[FLINK-4293] Fix malformatted license headersThis closes #2364,0
[FLINK-4104] [docs] Restructure Gelly docsSplit the Gelly documentation into five sub-pages.This closes #2258.,2
[FLINK-4411] [py] Properly propagate chained dual input children,2
[FLINK-4412] [py] Chaining properly handles broadcast variables,0
"[hotfix] [metrics] Refactor constructors and tests- removed constructors taking a specific ScopeFormat as argument, asthey were only used by tests and serve no real purpose- refactored tests accordingly- made sure that the registry is shutdown in every testThis closes #2302.",3
[FLINK-4302] [metrics] Add documentation to MetricConfig,5
[FLINK-4409] [build] Exclude JSR 305 from Hadoop dependencies,2
"[FLINK-3155] Update docker flink container to the latest release[FLINK-3155] Make docker image execute as non-root user (l:flink)[FLINK-3155] Change default FLINK_HOME from /usr/local/flink to /opt/flink[FLINK-3155] Make install path configuragle, simplify mirror based download[FLINK-3155] Upgrade default docker version to 1.1.1This closes #2340",2
[FLINK-4287] Ensure the yarn-session.sh classpath contains all Hadoop related pathsThis closes #2317,2
[FLINK-4281] [table] Wrap all Calcite Exceptions in Flink ExceptionsThis closes #2372.,2
[FLINK-4387] [runtime] Don't wait on termination future on KvStateServer shutdownDue to a bug in Netty that was only fixed in 4.0.33.Final it canhappen that waiting on the termination future never succeeds.Netty issue: https://github.com/netty/netty/issues/4357,0
[FLINK-4322] [checkpointing] Unify CheckpointCoordinator and SavepointCoordinatorThe CheckpointCoordinator now also takes over the role of the SavepointCoordinator.Savepoints are just like other checkpoints - they only store the metadata in addition.Restoring from a savepoint means loading it into the CheckpointStore at startup.,1
[FLINK-4322] [checkpointing] Add and fix tests for unified Checkpoint/Savepoint CoordinatorThis closes #2366,3
[hotfix] Fix Redis Sink to fail at opening if Redis is not initialized.This closes #2245,5
[FLINK-4189] [table] Introduce symbols for internal useThis closes #2380.,1
[hotfix] Minutiae,0
[FLINK-4322] [checkpointing] Ignore minimum delay for savepoints,5
[FLINK-4322] [checkpointing] Extend CheckpointCoordinatorTestThe added tests check that savepoints ignore the maximum numberof concurrent checkpoints and minimum delay between checkpoints.This closes #2385.,5
"[FLINK-4021] [network] Consume staged buffers on shutdownIf we have staged buffers and one consuming channel is closed,all others will be skipped and auto read will not be set backto true.This is currently not a problem, because failures bring down thewhole job, but it would become an issue with partial recovery.",0
[FLINK-4021] [network] Add test for staged buffers auto read behaviourThis closes #2141.,3
[FLINK-3319] [cep] Add or function to CEP's pattern apiThis closes #2171.,1
[FLINK-3319] [cep] Add documentation for or function,1
Add ManualWindowSpeedITCase For Assessing State PerformanceThis should be used to test whether there are any obvious performanceregressions between releases. Somewhat similar to the other manual teststhat have @Ignore set these have to be run manually. (for now),1
[FLINK-4402] Changed the documentation for the metrics in the System Scope SectionThis closes #2382,5
[FLINK-4282] Add Offset Parameter to WindowAssigners,2
[FLINK-4282] Add doc for WindowAssigner offset parameterThis closes #2333This closes #2355,2
"[FLINK-4431] [core] Introduce a ""VisibleForTesting"" annotation.This annotation documents methods/fields that are not private because tests need them,but should not be called by any non-testing code.This closes #2390",3
[FLINK-4245] Expose all defined variablesThis closes #2300.,2
[hotfix] [metrics] Rename host format constant,0
[hotfix] Correct typo in StreamExecutionEnvironmentThis closes #2393.,2
[hotfix] [metrics] Fix AbstractMetricGroupTest#testGetAllVariables,3
"[FLINK-4222] Support automatic AWS Credentials discovery.When called without credentials, the AmazonKinesisClient tries to configure itself automatically, searching for credentials from environment variables, java system properties, and finally from instance profile credentials delivered through the Amazon EC2 metadata service.Add the AWSConfigConstant ""AUTO"", which supports creating an AmazonKinesisClient without any AWSCredentials, which allows for this auto-discovery mechanism to take place and supports getting kinesis credentials from the AWS EC2 metadata service.This closes #2260",5
[FLINK-3866] StringArraySerializer does not treat type as immutable.This closes #2289,2
[hotfix] Remove unused legacy code,1
[FLINK-4435] Replace Guava's VisibleForTesting annotation with Flink's annotationThis closes #2404,2
[FLINK-4441] Make RocksDB backend return null on empty state + add test for all backendsCloses #2399,3
"[FLINK-4317, FLIP-3] [docs] Restructure docs- Add redirect layout- Remove Maven artifact name warning- Add info box if stable, but not latest- Add font-awesome 4.6.3- Add sidenav layoutThis closes #2387.",1
[FLINK-4454] always display JobManager address using LeaderRetrievalServiceThis closes #2406,1
[FLINK-4253] [config] Rename 'recovery.mode' key to 'high-availability',5
[FLINK-4253] [config] Clean up renaming of 'recovery.mode'- Renamed config keys and default values to be consistent- Updated default flink-conf.yaml- Cleaned up code occurrences of recovery modeThis closes #2342.,4
[FLINK-4452] [metrics] TaskManager network buffer gaugesAdds gauges for the number of total and available TaskManager networkmemory segments.This closes #2408,1
[FLINK-4231] [java] Switch DistinctOperator from GroupReduce to ReduceRewrite the DistinctOperator using Reduce to support both the sort-basedcombine and the recently added hash-based combine. This is configured bythe new method DistinctOperator.setCombineHint(CombineHint).The tests for combineability are removed as Reduce is inherentlycombineable.This closes #2272,4
"[FLINK-4264] [gelly] New GraphMetrics driverUpdates VertexMetrics analytic, adds directed and undirectedEdgeMetric analytics, and includes a new GraphMetrics driver.This closes #2295",1
[FLINK-4453] [docs] Scala code example in Window documentation shows JavaThis closes #2411,2
[hotfix] Reduce string concatenations in ExecutionVertex,0
[FLINK-4437] [checkpoints] Properly lock the triggerCheckpoint() methodThis introduces a trigger-lock that makes sure checkpoint trigger attemps to not overtakeeach other (as may otherwise be the case for periodic checkpoints and manual savepoints).This also fixes the evaluation of the min-delay-between-checkpoints,0
"[FLINK-4417] [checkpoints] Checkpoints are subsumed by CheckpointID not, by timestampThis closes #2407",2
[FLINK-4457] Make ExecutionGraph independent of actors.This introduced types JobStatusListener and ExecutionStatusListener interfacesthat replace the ActorRefs and ActorGateway for listeners,1
[hotfix] [tests] Fix mini cluster usage and logging/printing in CustomDistributionITCase,2
[FLINK-3899] [docs] Add examples for incremental window computation.This closes #2368,1
[FLINK-3823] Fix travis log upload & upload logs to transfer.sh (14 days),2
"[FLINK-4273] Modify JobClient to attach to running jobsThese changes are required for FLINK-4272 (introduce a JobClient classfor job control). Essentially, we want to be able to re-attach to arunning job and monitor it. It shouldn't make any difference whether wejust submitted the job or we recover it from an existing JobID.This PR modifies the JobClientActor to support two different operationmodes: a) submitJob and monitor b) re-attach to job and monitorThe JobClient class has been updated with methods to access thisfunctionality. Before the class just had `submitJobAndWait` and`submitJobDetached`. Now, it has the additional methods `submitJob`,`attachToRunningJob`, and `awaitJobResult`.The job submission has been split up in two phases:1a. submitJob(..)Submit job and return a future which can be completed toget the result with `awaitJobResult`1b. attachToRunningJob(..)Re-attach to a runnning job, reconstruct its class loader, and return afuture which can be completed with `awaitJobResult`2. awaitJobResult(..)Blocks until the returned future from either `submitJob` or`attachToRunningJob` has been completed- split up JobClientActor into a base class and two implementations- JobClient: on waiting check JobClientActor liveness- lazily reconstruct user class loader- add additional tests for JobClientActor- add test case to test resuming of jobsThis closes #2313",3
[FLINK-3677] FileInputFormat: Allow to specify include/exclude file name patternsThis closes #2109,2
[FLINK-3874] [tableApi] Add KafkaJsonTableSinkThis closes #2244,5
[FLINK-4273] adapt JobRetrievalITCase to lazy classloader reconstruction,2
[FLINK-3580] [table] Implement FLOOR/CEIL for time pointsThis closes #2391.,2
"[FLINK-4418] [client] Improve resilience when InetAddress.getLocalHost() throws UnknownHostException- If InetAddress.getLocalHost() throws UnknownHostException when  attempting to connect with LOCAL_HOST strategy, the code will move on  to try the other strategies instead of immediately failing.- Also made minor code style improvements for trying the different strategies.This closes #2383",1
[FLINK-4480] [elasticsearch connector] Fix link to elastic.co in documentationThis also includes minor code and test cleanups.This closes #2416,4
[FLINK-3677] Remove Guava dependency from flink-core,2
[FLINK-4341] Let idle consumer subtasks emit max value watermarks and fail on reshardingThis no longer allows the Kinesis consumer to transparently handle resharding.This is a short-term workaround until we have a min-watermark notification service available in the JobManager.This closes #2414,1
[hotfix][quickstarts] Remove Jodatime exclusion,5
[FLINK-4420] [table] Introduce star(*) to select all of the columns in the tableThis closes #2384.,2
[hotfix][docs] fixed timestamp extractor documentation Java exampleThis closes #2433,2
[FLINK-4525] [core] Drop special cases for 'StrictlyLocalAssignment' and 'PredeterminedAssignment',4
"[FLINK-1984] Mesos ResourceManager - T1 milestoneImplemented Mesos AppMaster including:- runners for AppMaster and TaskManager- MesosFlinkResourceManager as a Mesos framework- ZK persistent storage for Mesos tasks- reusable scheduler actors for:  - offer handling using Netflix Fenzo (LaunchCoordinator)  - reconciliation (ReconciliationCoordinator)  - task monitoring (TaskMonitor)  - connection monitoring (ConnectionMonitor)- lightweight HTTP server to serve artifacts to the Mesos fetcher (ArtifactServer)- scenario-based logging for:  - connectivity issues  - offer handling (receive, process, decline, rescind, accept)- incorporated FLINK-4152, FLINK-3904, FLINK-4141, FLINK-3675, FLINK-4166",2
[FLINK-1984] Mesos ResourceManager - T1 milestone (2)Add license information,5
"[FLINK-1984] Mesos ResourceManager - T1 milstone (3)- Fenzo usage fix - always call scheduleOnce after expireAllLeases.- increased aggressiveness of task scheduler- factored YarnJobManager and MesosJobManager to share base class`ContaineredJobManager`- improved supervision for task actors, unit tests- support for zombie tasks (i.e. non-strict slave registry)- improved javadocs- fix for style violations (e.g. line length)- completed the SchedulerProxy- final fields- improved preconditions- log lines to use {}- cleanup ZK state- serializable messages",4
[FLINK-1984] Mesos ResourceManager - T1 milestone (4)- adjust pom.xml per feedback,5
[FLINK-1984] port Mesos code to latest master- move Scala code to /scala dir- remove merge commits- update versionThis closes #2315,5
[FLINK-4488][yarn] only automatically shutdown clusters for detached jobs- add check to yarn tests to verify cluster hasn't been shutdown prematurelyThis closes #2419,3
[FLINK-4486] detached YarnSession: wait until cluster startup is completeThis closes #2423,2
[FLINK-4526][yarn] remove redundant proxy messagesThis closes #2437,4
[hotfix] fix Checkstyle error,0
[FLINK-3950] Add Meter interfaceThis closes #2374,1
[FLINK-4190] Generalise RollingSink to work with arbitrary buckets,1
[hotfix] remove Guava dependency from flink-mesos,2
[maven] update checkstyle plugins- update checkstyle plugin to 2.17- update scalastyle plugin to 0.8.0,5
[FLINK-4271] [DataStream API] Enable CoGroupedStreams and JoinedStreams to set parallelism.This closes #2305,1
[FLINK-4271] [DataStream API] Extends JavaDocs for 'apply(...)' and 'with(...)' functions.,1
[FLINK-4514][kinesis-connector] Handle unexpected ExpiredIteratorExceptionsThis closes #2432,2
[hotfix] [table] Add docs about SQL's lexical policy,2
[FLINK-4539] [runtime] Reuse functionality for Physical Memory size in 'Hardware' and 'EnvironmentInformation'.,5
"[hotfix] [cassandra connector] Fix minor issues in CassandraConnectorTest.The test now properly uses and reuses a mini cluster, rather than spawning a local environment for each test.This also properly renames the CassandraConnectorTest to CassandraConnectorITCase",3
[FLINK-4380] Introduce KeyGroupAssigner and Max-Parallelism ParameterThis introduces a new KeySelector that assigns keys to key groups andalso adds the max parallelism parameter throughout all API levels.This also adds tests for the newly introduced features.,1
[FLINK-4381] Refactor State to Prepare For Key-Group State Backends,4
[FLINK-4380] Add tests for new Key-Group/Max-ParallelismThis tests the rescaling features in CheckpointCoordinator andSavepointCoordinator.,3
"[FLINK-3761] Refactor State Backends/Make Keyed State Key-Group AwareThe biggest change in this is that functionality that used to be inAbstractStateBackend is now moved to CheckpointStreamFactory andKeyedStateBackend. The former is responsible for providing streams thatcan be used to checkpoint data while the latter is responsible forkeeping keyed state. A keyed backend can checkpoint the state that itkeeps by using a CheckpointStreamFactory.This also refactors how asynchronous keyed state snapshots work. Theyare not implemented using a Future/RunnableFuture.Also, this changes the keyed state backends to be key-group aware and tosnapshot the state in key-groups with an index for restoring.",4
[FLINK-3761] Refactor RocksDB Backend/Make Key-Group AwareThis change makes the RocksDB backend key-group aware by building on thechanges in the previous commit.,4
[FLINK-3755] Ignore QueryableStateITCaseThis doesn't work yet because the state query machinery is not yetproperly aware of key-grouped state.,1
[FLINK-4380] Remove KeyGroupAssigner in favor of static method/Have default max. parallelism at 128,4
[FLINK-3755] Fix variety of test problems cause by Keyed-State Refactoring,4
[FLINK-3755] Extended EventTimeWindowCheckpointITCase to test the boundaries of maxParallelism.,3
"[hotfix] Improve Logging in CheckpointCoordinator, StreamTask, State Code",2
[hotfix] Fixes unstable ContinuousFileMonitoringTest.This closes #2446,3
[hotfix] [test-stability] Properly fail if ZooKeeperTestEnvironment cannot delete ZNodes,4
[hotfix] [tests] Fix CassandraConnectorITCase on Java 7 profiles,2
[FLINK-4570] revert Scalastyle version to 0.5.0This closes #2462,4
"[FLINK-4455] [FLINK-4424] [networkenv] Make NetworkEnvironment independent of ActorGateway and JobManager associationMakes the NetworkEnvironment independent of the JobManager association. This means that theNetworkEnvironment and with it the ConnectionManager is started before the TaskManager actoris executed. Furthermore, the ConnectionManager keeps running even in case of a JobManagerdisassocation. In the wake of the remodelling this behaviour, the PartitionStateChecker andthe ResultPartitionConsumableNotifier which depend on the JobManager association were movedout of the NetworkEnvironment. They are now contained in the SlotEnvironment which will beset up when the TaskManager connects to a JobManager. The SlotEnvironment contains allinformation related to the associated JobManager. Since all slots are implicitly associatedwith the JobManager which is the leader, we only create one SlotEnvironment which is sharedby all Tasks.Introduce SlotEnvironment to accommodate the PartitionStateChecker and ResultPartitionConsumableNotifierRemove the PartitionStateChecker and the ResultPartitionConsumableNotifier from theNetworkEnvironment. Start the NetworkEnvironment when the TaskManager components arecreated. Keep the NetworkEnvironment running also when the JobManager is disassociated.Fix CassandraConnectorITCaseRemove ExecutionContext from TaskManager; Rename SlotEnvironment into JobManagerConnectionIntroduce JobManagerCommunicationFactory to generate job manager specific communication componentsThis closes #2449.",4
[FLINK-3497] [table] Add IS (NOT) TRUE/IS (NOT) FALSE functions,1
[FLINK-4570] disable Scalastyle for flink-mesos Utils fileThe version change didn't cause the Scalastyle errors. Seems like theonly viable solution to prevent random failures of the Scalastyleplugin is to disable Scalastyle checks for the affected source file.,2
[FLINK-4567] [runtime] Enhance SerializedThrowable to properly mimic Exception causes,1
[FLINK-4566] [network runtime] Properly preserve exception causes for ProducerFailedException,0
[FLINK-4490] [distributed coordination] (part 1) Change InstanceConnectionInfo to TaskManagerLocationThis adds the ResourceId to the TaskManagerLocation,1
"[FLINK-4490] [distributed coordination] (part 2) Make slots independent of 'Instance'.To allow for a future dynamic slot allocation and release model, the slots should not depend on 'Instance'.In this change, the Slots hold most of the necessary information directly (location, gateway) andthe interact with the Instance only via a 'SlotOwner' interface.",5
[FLINK-4490] [distributed coordination] (part 3) Rename methods on 'Instance' to have more intuitive namesgetResourceID() --> getTaskManagerID()getInstanceConnectionInfo() --> getTaskManagerLocation(),1
[FLINK-4525] [core] (followup) Remove remaining redundant code for pre-defined strictly local assignments.,5
[FLINK-3580] [table] Add current time point functionsThis closes #2441.,1
"[FLINK-4570] remove conflicting Unicode characterThis caused Scalastyle to fail, presumably depending on the localeused. After a bit of debugging on the Scalastyle plugin I found out thatthe number in the error is the byte position.""Expected identifier, but got Token(COMMA,,,1772,,)""head -c 1772 flink-mesos/src/test/scala/org/apache/flink/mesos/Utils.scalapointed to the Unicode character '' which causes Scalastyle to fail incertain environments.This closes #2466",0
[FLINK-4459] [distributed runtime] Introduce SlotProvider for SchedulerThis closes #2424,1
[hotfix] Delete leftover (superseded) StreamTaskAsyncCheckpointTestThere is RocksDBAsyncSnapshotTest which tests async snapshots for theRocksDB state backend. Operators themselves cannot do asynchronouscheckpoints right now.,1
[FLINK-4073] fix stability of TaskManagerFailure test,3
"[FLINK-4073] remove unstable testing code in TaskManagerFailure testYarn reports null or (1, maxVcores) depending on its internal logic. Thetest only worked in the past because it summed up the used vcores of theRM and the TM containers. We have checks in place to ensure the vcoresconfig value is passed on to the Flink ResourceManager.",2
"[FLINK-4559][kinesis-connector] Fix AWSUtil.getCredentialsProvider() to not return nullReturn a DefaultAWSCredentialsProviderChain instead of null whenAWS_CREDENTIALS_PROVIDER config is set to ""AUTO""This closes #2470",1
[FLINK-4265] [dataset api] Add a NoOpOperatorAdds a NoOpOperator which is unwound in OperatorTranslation.translate.This will be first used by Gelly as a placeholder to support implicitoperator reuse.This closes #2294,1
[FLINK-4436] Unclosed DataOutputBuffer in Utils#setTokensFor()This closes #2402,1
[FLINK-4595] Close FileOutputStream in ParameterToolThis closes #2478,2
"[FLINK-4458] Replace ForkableFlinkMiniCluster by LocalFlinkMiniClusterRename _configuration to originalConfigurationRemove testing classes from main scope in flink-runtimePreviously, the ForkableFlinkMiniCluster which resided in flink-test-utils requiredthese files to be in the main scope of flink-runtime. With the removal of theForkableFlinkMiniCluster, these classes are now no longer needed and can be movedback to the test scope.This closes #2450.",3
[FLINK-4456] Replace Akka specific types by interfaces in TaskIntroduce TaskExecutionStateListener for TaskReplace JobManagerGateway in Task by InputSplitProvider and CheckpointNotifierReplace the TaskManager ActorGateway by TaskManagerConnection in TaskRename taskmanager.CheckpointNotifier into CheckpointResponder; rename TaskExecutionStateListener.notifyTaskExecutionState into notifyTaskExecutionStateChangedRemove InputSplitProvider.start; add ClassLoader parameter to InputSplitProvider.getNextInputSplitRemoves the unused class InputSplitIterator.Update InputSplitProvider JavaDocsThis closes #2456.,2
[FLINK-4522] [docs] Gelly link broken in homepageThe Gelly documentation was recently split into multiple pages inFLINK-4104 but was missing a redirect. This commit updates the Gellyredirect to point to the old page.This closes #2464,5
[FLINK-4257] [gelly] Handle delegating algorithm change of classReplaces Delegate with NoOpOperator.This closes #2474,1
[FLINK-4571] [gelly] Configurable little parallelism in Gelly driversThis closes #2475,5
[FLINK-3497] [table] Add POSITION/OVERLAY functions,1
[FLINK-4601] [java] Check for empty string properlyThis closes #2483.,2
[FLINK-4592] [table] Fix flaky test ScalarFunctionsTest.testCurrentTimePoint,3
[FLINK-3580] [table] Add QUARTER function,1
[FLINK-3497] [table] Add SQRT function,1
[FLINK-4599] [table] Add 'explain()' also to StreamTableEnvironmentThis closes #2485.,1
[FLINK-4389] Expose metrics to WebFrontendThis closes #2363,2
[hotfix] [metrics] Add missing @Internal annotations,1
[FLINK-4589] [DataStream API] Fix Merging of Covering Window in MergingWindowSetThis also adds two new test cases for that problem.This closes #2476,0
[FLINK-4626] Add missing break in MEtricStore#add(),1
[FLINK-4612] Close FileWriter using try with resourcesThis closes #2492.,1
[FLINK-4608] Use short-circuit AND in Max/Min AggregationFunctionThis closes #2489.,1
[FLINK-4607] Close FileInputStream in ParameterTool and otherThis closes #2488.,2
[FLINK-4622] Include 'savepoint' in the CLI help messageThis closes #2501.,1
[FLINK-4081] [core] [table] FieldParsers should support empty stringsThis closes #2297.,1
[FLINK-4625] [core] Add a safety net to forcibly terminate JVM is clean shutdown freezed.,4
[FLINK-4610] [core] Replace keySet/getValue with entrySet in UdfAnalyzerUtilsThis closes #2491,1
[FLINK-4247] [table] CsvTableSource.getDataSet() expects Java ExecutionEnvironmentThis closes #2298.,5
[FLINK-4638] [core] Fix exception message for MemorySegmentThis closes #2515,0
[FLINK-4609] [java-api] Remove redundant check for null in CrossOperatorThis closes #2490,1
[FLINK-4594] [core] Validate lower bound in MathUtils.checkedDownCastThis closes #2481,5
"[FLINK-4572] [gelly] Convert to negative in LongValueToIntValueThe Gelly drivers expect that scale 32 edges, represented by the lower32 bits of long values, can be converted to int values. Values between2^31 and 2^32 - 1 should be converted to negative integers.Creates separate signed and unsigned translators for long to int. Thisprevents ambiguous conversion since each translator only works on a32-bit range of values.This closes #2469",1
[FLINK-4268] [core] Add a parsers for BigDecimal/BigIntegerThis closes #2304.,1
[FLINK-2662] [dataSet] [optimizer] Fix merging of unions with multiple outputs.Translate union with N outputs into N unions with single output.This closes #2508.,0
"[FLINK-3929] Added Keytab based Kerberos support to enable secure Flink cluster deployment(addresses HDHS, Kafka and ZK services)FLINK-3929 Added MiniKDC support for Kafka, Zookeeper, RollingFS and Yarn integration test modules",3
"[FLINK-3929] conditionally skip RollingSinkSecuredITCase- for now, we skip this test class until Hadoop version 3.x.x.",3
[FLINK-3929] additional fixes for keytab security- load flink-jaas.conf from classpath- avoid using undocumented flink base dir config entry- enable test cases to run on MacOS- unify suffix of secure test cases- fix error logging and reportingThis closes #2275,2
[FLINK-3042] [FLINK-3060] [types] Define a way to let types create their own TypeInformationThis closes #2337.,5
[FLINK-4654] [docs] Small improvements to the docs.This closes #2525,2
[hotfix] [docs] Parametrized version of quickstart script and artifacts in the quickstart docsThis closes #2522,2
[hotfix] [streaming api] Add proper deprecation JavaDocsAlso includes minor style cleanup of a test.,3
[FLINK-4645] [core] Adjust signatures of 'registerTypeWithKryoSerializer(...)' methods to allow simpler passing ofclasses without generic casting.This is not API breaking due to generic type erasure in Java. The changes method still has the samebinary signature.,4
[FLINK-4640] [streaming api] Ensure that the state descriptors properly initialize the serializers.,5
[hotfix] [tests] Fix race condition in RescalingITCase that could make the test stuck in a blocking call until timeoutThis closes #2513,3
"[docs] Update docs on data types and serialization, to include type hints, type registration, and serializer registration.",5
[FLINK-4248] [core] [table] CsvTableSource does not support reading SqlTimeTypeInfo typesThis closes #2303.,5
[FLINK-3580] [table] Add OVERLAPS functionThis closes #2468.,1
[FLINK-4603] [checkpoints] Fix user code classloading in KeyedStateBackendThis closes #2533,1
"[FLINK-4628] [core] Provide user class loader during input split assignmentIn analogy to the configure() method, this also sets a context classloader during input split assignment.This closes #2505",1
[hotfix] Minor code cleanup in StreamTask,4
[FLINK-4556] [distributed runtime] Make Queryable State Key-Group AwareThis closes #2523,1
[FLINK-4663] [jdbc] Fix JDBCOutputFormat log messageThis closes #2534,1
[FLINK-4665] [misc] Remove unnecessary boxing/unboxing of primitive types in various placesThis closes #2537,4
[FLINK-4666] [core] Declare constants as final in ParameterToolThis closes #2538,2
[FLINK-4496] Refactor the TimeServiceProvider to take a Trigerable instead of a Runnable.,1
[FLINK-4494] Expose the TimeServiceProvider from the Task to each Operator.,1
[hotfix] Replace registerTimer/getTime by TimeServiceProvider in Context,1
[FLINK-4550] [table] Clearly define SQL operator tableThis closes #2502.,1
[FLINK-4549] [table] Test and document implicitly supported SQL functionsThis closes #2500.,1
[FLINK-4482] [checkpoints] Make numUnsuccessfulCheckpointsTriggers an atomic integerThis closes #2421,1
"[FLINK-4664] [gelly] Add translator to NullValueThis translator is appropriate for translating vertex and edge values toNullValue when the values are not used by an algorithm. Also, addedtests and moved translators into a subpackage.This closes #2536",4
[FLINK-4668] [clients] Fix positive random int generationThis closes #2539,0
[FLINK-4555] wait for ResourceManager to cleanly unregister applicationThis ensures that the ResourceManager has enough time to unregister theapplication before shutting down.This closes #2514,4
"[FLINK-4485] close and remove user class loader after job completionKeeping the user class loader around after job completion may lead toexcessive temp space usage because all user jars are kept until theclass loader is garbage collected. Tests showed that garbage collectioncan be delayed for a long time after the class loader is not referencedanymore. Note that for the class loader to not be referenced anymore,its job has to be removed from the archive.The fastest way to minimize temp space usage is to close and remove theURLClassloader after job completion. This requires us to keep aserializable copy of all data which needs the user class loader afterjob completion, e.g. to display data on the web interface.This closes #2499",5
[FLINK-4485] close classloader in absence of reference holders,2
[hotfix] Fix restart strategy class loading by using not lower cased class name,1
[FLINK-4672] [taskmanager] Do not decorate Actor Kill messages,2
"[FLINK-4218] [checkpoints] Do not rely on FileSystem to determing state sizesThis prevents failures on eventually consistent S3, where the operations forkeys (=entries in the parent directory/bucket) are not guaranteed to be immediately consistent (visible) after a blob was written.",0
[FLINK-4662] Bump Calcite version up to 1.9This closes #2535.,2
[FLINK-4684] [checkpoints] Remove redundant class loader from CheckpointCoordinator,4
[FLINK-4590] [table] Some Table API tests are failing when debug lvl is set to DEBUGThis closes #2504.,0
[FLINK-4252] [table] Validate input and output classes of Table APIThis closes #2507.,5
[FLINK-4241] [table] Cryptic expression parser exceptionsThis closes #2529.,2
[FLINK-4671] [table] Table API can not be builtThis closes #2549.,2
"[FLINK-4696] [core] Limit number of Akka threads in local minicluster setupsSince Flink uses a rather small number of actors, not too many actor dispatcher threads are needed.To prevent mini cluster setups on multi-core CPUs (32 or 64 cores) to spawn too many threads,this limits the number of dispatcher threads for mini clusters.For proper Flink deployments, the threads are not limited by this change.",4
[FLINK-4685] [checkpoints] Gather sync/async duration and alignment information for task checkpointsThis adds to each 'acknowledge checkpoint' message  - number of bytes buffered during alignment  - duration of alignment phase  - duration of synchronous part of the operator checkpoint  - duration of asynchronous part of the operator checkpoint,1
[hotfix] [tests] Speed up streaming state tests by skipping default retry delay.,1
"[FLINK-4361] Introduce Flink's own future abstractionFlink's future abstraction whose API is similar to Java 8's CompletableFuture.That's in order to ease a future transition to this class once we ditch Java 7.The current set of operations comprises:- isDone to check the completion of the future- get/getNow to obtain the future's value- cancel to cancel the future (best effort basis)- thenApplyAsync to transform the future's value into another value- thenAcceptAsync to register a callback for a successful completion of the future- exceptionallyAsync to register a callback for an exception completion of the future- thenComposeAsync to transform the future's value and flatten the returned future- handleAsync to register a callback which is called either with the regular resultor the exceptional resultAdditionally, Flink offers a CompletableFuture which can be completed with a regularvalue or an exception:- complete/completeExceptionallyComplete FlinkCompletableFuture exceptionally with a CanellationException upon cancelAdd convenience functions for FlinkCompletableFuturesThis closes #2554.",2
[FLINK-4690] Replace SlotAllocationFuture with flink's own futureThis closes #2552.,2
[FLINK-4690] Use direct executor to run slot allocation future handler,0
"[FLINK-4695] Introduce MetricRegistryConfiguration to encapsulate MetricRegistry parametersIn order to decouple the MetricRegistry object instantiation from the global configurationthe MetricRegistryConfiguration class has been introduced. This class encapsulates allrequired information to create a MetricRegistry object. Furthermore, it encapsulates theconfiguration parsing logic by offering a static method fromConfiguration, which constructsa MetricRegistryConfiguration object from a Configuration.This closes #2555.",5
[FLINK-4560] [build] Enforcer Java version >= 1.7 via Maven enforcer pluginThis closes #2458,1
"[FLINK-4543] [network] Fix potential deadlock in SpilledSubpartitionViewAsyncIO.The deadlock could occur in cases where the SpilledSubpartitionViewAsyncIO would simultaneously try torelease a buffer and encounter an error in another thread.The field of congestion was the listener, which is now replaced by an AtomicReference, removing thenecessity to lock in the case of reporting the error.This closes #2444",0
[FLINK-3656] [table] Reduce number of ITCasesThis closes #2563.,2
"[FLINK-4710] [build] Remove Guice Dependency from Hadoop2This dependency is transitively pulled, but not necessary for the parts of theHadoop libraries used by Flink.",2
[FLINK-4708] [build] Properly scope Kerberos Test Cluster dependency for tests,3
[FLINK-3656] [table] Consolidate ITCasesMerge FilterIT/SelectIT to CalcITCasesMerge FromDataSet/ToTable to TableEnvironmentITCasesMerge aggregating ITCasesAll batch ITCases use TableProgramsTestBaseThis closes #2566.,3
"[FLINK-4711] Let the Task trigger partition state requests and handle their responsesThis PR makes changes the partition state check in a way that the Task is now responsiblefor triggering the state check instead of the SingleInputGate. Furthermore, the operationreturns a future containing the JobManager's answer. That way we don't have to route theresponse through the TaskManager and can add automatic retries in case of a timeout.The PR removes the JobManagerCommunicationFactory and gets rid of the excessivePartitionStateChecker and ResultPartitionConsumableNotifier creation. Instead of creatingfor each SingleInputGate one PartitionStateChecker we create one for the TaskManager whichis reused across all SingleInputGates. The same applies to theResultPartitionConsumableNotifier.This closes #2569.",1
[FLINK-4573] [web dashboard] Fix potential resource leak due to unclosed RandomAccessFile in TaskManagerLogHandlerThis closes #2556,2
"[FLINK-4379] [checkpoints] Introduce rescalable operator stateThis introduces the Operator State Backend, which stores state that is not partitionedby a key. It replaces the 'Checkpointed' interface.Additionally, this introduces CheckpointStateHandles as container for all checkpoint related state handlesThis closes #2512",0
[FLINK-4379] [checkpoints] Fix minor bug and improve debug logging,2
[FLINK-4702] [kafka connector] Commit offsets to Kafka asynchronously and don't block on pollsLetting the Kafka commit block on polls means that 'notifyCheckpointComplete()' may takevery long. This is mostly relevant for low-throughput Kafka topics.,1
[FLINK-4618] [kafka-connector] Incremented the commited offset by one to avoid duplicate read message.,1
[FLINK-4618] [kafka-connector] Minor improvements to comment and variable namingThis closes #2579,1
"[FLINK-4624] [gelly] Support null values in Graph Summarization* Bug was caused by serializers that cannot handle null values (e.g. Long)* VertexGroupItem now uses Either<NullValue, VV> instead of VV* Generalized test cases* Added tests for vertex/edge values of type Long* Replaced Guava Lists.newArrayList() with new ArrayList<>()This closes #2527",1
[FLINK-4643] [gelly] Average Clustering CoefficientDirected and undirected analytics computing the average clusteringcoefficient over vertices in a graph and an updated driver.This closes #2528,5
[FLINK-3656] [table] Convert expression tests to unit testsThis closes #2567.,3
[FLINK-4068] [table] Move constant computations out of code-generatedThis closes #2560.,4
[FLINK-4068] [table] Reduce expression also for filter/project,2
[FLINK-4546] [table] Remove STREAM keyword in Stream SQLThis closes #2454.,4
[hotfix] [kafka] Fix NPE in Kafka09Fetcher,0
"[FLINK-4732] remove maven junction pluginOn Windows, the plugin downloads and executes code from the author'sweb site. The downloaded file is not signed in the same way as Mavenartifacts from Maven central which have to be signed with thedeveloper's key. This could be a potential target for attackers.This closes #2586",1
[hotfix] [kafka] Committed offset value set in KafkaTopicPartitionState should also be incremented by 1.The broken behaviour was introduced in the last hotfix commit eece0dd0.,0
[FLINK-3874] Rewrite Kafka JSON Table sink testsThis closes #2430.,3
[FLINK-4677] fail if user jar contains no executionsThis closes #2548.,1
"[FLINK-4729] [gelly] Use optional VertexCentric CombineFunctionPasses through the CombineFunction to VertexCentricIteration, and othercode cleanup discovered via IntelliJ's code analyzer.This closes #2587",4
[FLINK-4734] [gelly] Remove use of Tuple setField for fixed positionThis closes #2590,0
[FLINK-4740] [tests] Upgrade testing librariesUpgrades  JUnit from 4.11 to 4.12  Mockito from 1.9.5 to 1.10.19  PowerMock from 1.5.5 to 1.6.5This closes #2597,3
[FLINK-4744] [streaming api] Introduce usercode class loader to deserialize partitionable operator stateThis closes #2598,1
"[FLINK-4744] [streaming api] Followup: Unify names for operator state access methods and comments.Also make JavaSerializer package private, as it is not intended for user as a proper TypeSerializer",1
"[FLINK-4728] [core,optimizer] Replace reference equality with object equalitySome cases of testing Integer equality using == rather thanInteger.equals(Integer), and some additional cleanup.This closes #2582",4
[FLINK-4709] [core] Fix resource leak in InputStreamFSInputWrapperThis closes #2581,0
[hotfix] [core] Minor code cleanup and correction of javadocs for filesystem input stream classes.,5
[FLINK-4329] [streaming api] Fix Streaming File Source Timestamps/Watermarks HandlingThis closes #2546,2
[hotfix] Various code cleanups around time service and asynchronous exceptions  - DefaultTimeServiceProvider now owns scheduled executor  - Enforce that an asynchronous exception handler is always set,1
[FLINK-4737] [core] Add support for bz2 and xy compression in flink-core.Adds a dependency on 'commons-compression'.This closes #2002,2
[FLINK-4737] [core] Ensure that Flink and its Hadoop dependency pull the same version of 'commons-compress',2
[FLINK-4718] [docs] Fix figure about parallel watermarks.This closes #2578,0
"[FLINK-4739] [elasticsearch connector] Adding packaging details for the Elasticsearch connectorWhen an uber-jar containing an Elasticsearch sink is executed, anIllegalArgumentException may occur, which is caused by conflicting files ofElasticsearch and it's dependencies in META-INF/services.This commit adds further clarification to the documentation on how to build aporper uber-jar that can be properly executed by adapting the pom file.This closes #2591",2
[FLINK-4748] [streaming api] Make timers in Ingestion Time source context properly cancelable.,1
[hotfix] [streaming api] Cleanup watermark initialization in window operator,1
[FLINK-4749] [streaming api] Remove redundant processing time timer sets from window operator,1
[hotfix] [streaming api] Remove obsolete and unused InputTypeSerializer from WindowOperator,1
[FLINK-4750] [runtime] Cleanly await end of all currently executing processing time timers when finite streams finish.,5
[FLINK-4700] [tests] Expand and harden TimeServiceProvider test,3
[hotfix] [tests] Remove leftover sysout logging code,2
[FLINK-4751] [futures] Add thenCombineAsync function to Flink's futuresThe thenCombineAsync method allows to combine two futures and apply a BiFunction onthe results of both futures. The BiFunction is only applied after both futures havecompleted.Add ThrowableWrapperException to properly handle throwablesThis closes #2600.,0
[hotfix] Make KeyGroupsStateHandle implement StreamStateHandle,0
[hotfix] Minor cleanup in FlinkKafkaConsumerBase and Test,3
[FLINK-4730] Introducing CheckpointMetaDataThis closes #2583.,5
"[FLINK-4736] [core] Don't duplicate fields in OrderingDuplicate fields should not be appended to an ordering. In an orderingeach subsequent field is only used as a comparison when all prior fieldstest equal; therefore, a repeated field cannot contribute to theordering.This closes #2601",3
[hotfix] [streaming api] Re-register timers in open() instead of restore()This makes sure timers cannot fire prior to the operator being opened.This closes #2602,1
[FLINK-4731] Fix HeapKeyedStateBackend Scale-InAdds additional tests in RescalingITCase for scale-inThis closes #2584.,3
[FLINK-4318][docs] change default version in config,5
"[FLINK-4777] catch IOException in ContinuousFileMonitoringFunctionFileSystem.listStatus(path) may throw an IOException when it lists filesand then retrieves their file status. This is quite common, e.g. editorswhich create temporary files and move them. TheContinuousFileMonitoringFunction can only apply a file path filterafterwards.The solution is to defer file checks until no exception is caught anymore.This closes #2610.",2
[FLINK-4745] [table] Convert KafkaTableSource test to unit testsThis closes #2603.,3
[FLINK-4776] [distributed coordination] Move ExecutionGraph initialization into the dedicated class ExecutionGraphBuilder,5
[hotfix] [tests] Increase robustness of Fast Time Window Operator Tests,3
[FLINK-4786] [tests] Fix BarrierBufferTest validation of alignment time computation,5
[hotfix] [tests] Remove leftover sysout logging from AccumulatingAlignedProcessingTimeWindowOperatorTest,3
[hotfix] [tests] Fix PowerMock warnings concerning log4j,2
"[FLINK-4764] [core] Introduce Config OptionsThis is a more concise and maintainable way to define configuration keys, default values,deprecated keys, etc.This closes #2605",5
[FLINK-4768] [core] Migrate high-availability configuration parameters to ConfigOptionsThis closes #2607,5
[FLINK-4439] Validate 'bootstrap.servers' config in flink kafka consumer 0.8This closes #2397,2
[FLINK-4788] [streaming api] Fix state backend classloading from configuration,5
[FLINK-4311] [hbase] Fix TableInputFormat to correctly process multiple input splits.This closes #2330,0
[FLINK-2765] [hbase] Bump HBase versions and fix tests.- HBase version for Hadoop 1 bumped to HBase 0.98.22-hadoop1- HBase version for Hadoop 2 bumped to HBase 1.2.3- Excluded tests from hadoop1 profile.,2
[FLINK-3656] [table] Add test base for logical unit testing.This closes #2595,3
"[FLINK-4778] [docs] Fix WordCount parameters in CLI examples.Due to the change in https://github.com/apache/flink/commit/0629e25602eefdc239e8e72d9e3c9c1a5164448e, we need to specify a prefix for `input` and `output` files.This closes #2611",2
[FLINK-4035] Add support for Kafka 0.10.x.This closes #2231,1
[FLINK-4035] Refactor the Kafka 0.10 connector to be based upon the 0.9 connectorAdd a test case for Kafka's new timestamp functionality and update the documentation.This closes #2369,2
[FLINK-4793] [types] Improve lambda constructor reference handlingThis closes #2621.,1
"[FLINK-3706] Fix YARN test instabilityThe most important change in this commit is that the `YarnTestBase.Runner` doesn't do ""try {} catch (Throwable t) { fail(t); }"" anymore, which doesn't lead to a test failure, because its called outside the main thread.With the change, all throwables are reported back to the main thread and fail the test there properly (many YARN tests benefit from this change).This closes #2622",4
[FLINK-4799] re-add 'build-target' symlink on Unix systemsThis adds back the link 'build-target' which points to the final buildassembly in 'flink-dist/target/'.This closes #2620,2
[hotfix][kafka] Undo DataGenerators changes (use inline kafka producer again,1
[hotfix][kafka] Backport Kafka09FetcherTest for Kafka010This closes #2627,3
[FLINK-4791] [table] Fix issues caused by expression reduction,1
[FLINK-4512] [FLIP-10] Add option to persist periodic checkpoints[FLINK-4509] [FLIP-10] Specify savepoint directory per savepoint[FLINK-4507] [FLIP-10] Deprecate savepoint backend configThis closes #2608.,5
"[FLINK-4717] Add CancelJobWithSavepoint- Adds CancelJobWithSavepoint message, which triggers a savepoint  before cancelling the respective job.- Adds -s [targetDirectory] option to CLI cancel command:    * bin/flink cancel <jobID> (regular cancelling)    * bin/flink cancel -s <jobID> (cancel with savepoint to default dir)    * bin/flink cancel -s <targetDir> <jobID> (cancel with savepoint to targetDir)This closes #2609.",1
"[FLINK-4373] [cluster management] Introduce AllocationID, ResourceProfile, and AllocatedSlotThese classes are introduced as part of the cluster management rework.This closes #2630",1
[FLINK-4720] Implement archived ExecutionGraphThis closes #2577.,2
[FLINK-4774] [metrics] Fix scope concatenation in QueryScopeInfoThis closes #2613.,5
[FLINK-4827] [docs] Fix scala Streaming Table exampleThis closes #2632.,0
"[FLINK-3660] Measure latency and exposes them via a metricThis commit adds the initial runtime support for measuring latency of records going through the system.I therefore introduced a new StreamElement, called a LatencyMarker.Similar to Watermarks, LatencyMarkers are emitted from the sources at an configured interval. The default value for the interval is 2000 ms. The emission of markers can be disabled by setting the interval to 0. LatencyMarkers can not ""overtake"" regular elements. This ensures that the measured latency approximates the end-to-end latency of regular stream elements.Regular operators (excluding those participating in iterations) forward latency markers if they are not a sink.Operators with many outputs randomly select one to forward the maker to. This ensures that every marker exists only once in the system, and that repartition steps are not causing an explosion in the number of transferred markers.If an operator is a sink, it will maintain the last 512 latencies from each known source instance.The min/max/mean/p50/p95/p99 of each known source is reported using a special LatencyGauge from the sink (every operator can be a sink, if it doesn't have any outputs).This commit does not visualize the latency in the web interface.Also, there is currently no mechanism to ensure that the system clocks are in-sync, so the latency measurements will be inaccurate if the hardware clocks are not correct.This closes #2386",5
[hotfix] Fix ArchivedExecutionGraphTest,3
[FLINK-3660][hotfix] Add missing default value in ConfigConstants,5
[FLINK-4564] [metrics] Configurable delimiter per reporterThis closes #2517.,5
[FLINK-3932] Added ZK ACL configuration for secure cluster setupThis closes #2589.,1
[FLINK-4667] Fix for using correct ZK namespace in Yarn deployment,1
[FLINK-4667] add import for config entry,1
[FLINK-4506] [DataSet] Fix documentation of CsvOutputFormat about incorrect default of allowNullValues- Add test case for CsvOutputFormatThis closes #2477This closes #2631,3
[FLINK-4108] [scala] Respect ResultTypeQueryable for InputFormats.This closes #2619,2
[FLINK-4771] [avro] Add support for compression to AvroOutputFormat.This closes #2612,1
"[FLINK-3931] Implement Transport Encryption (SSL/TLS)Enabled SSL support for the different network transport within flink.This feature is documented as task T3 in the ""Secure Data Access in Flink"" design doc - https://docs.google.com/document/d/1-GQB6uVOyoaXGwtqwqLV8BHDxWiMO2WnVzBoJ8oPaAsThis commit addresses subtasks - FLINK-4324, FLINK-4325, FLINK-4404 and FLINK-4405For details about how to use this feature, refer to security-ssl.md and the new config values added to config.mdThis closes #2518",5
[FLINK-4723] [kafka] Unify committed offsets to Kafka to be next record to processThis closes #2580,1
[FLINK-4829] protect user accumulators against concurrent updates,5
"[FLINK-4829] snapshot accumulators on a best-effort basisHeartbeats should not fail when accumulators could not be snapshotted. Instead,we should simply skip the reporting of the failed accumulator. Eventually, theaccumulator will be reported; at the latest, when the job finishes.This closes #2649",5
"[FLINK-4727] [kafka] Set missing initial offset states with starting KafkaConsumer positionWith this change, on a clean startup of FlinkKafkaConsumer09, the auto retrieved offsets (either earliest, latest, or an actualcommitted offset) from Kafka will also be checkpointed and committed, even if no records are read after the startup.This closes #2585",1
[FLINK-4619] Answer with JobResultFailure if savepoint restore fails during submissionThis closes #2498.,0
[FLINK-4510] [checkpoint] Always create CheckpointCoordinatorThis closes #2453.,1
[hotfix] Fix JobSubmitTest,3
[FLINK-4792] [docs] Update ML quickstart importThis closes #2641,2
[FLINK-4652] [streaming connectors] Automatically refresh AWS credentialsBy using the credentials explicitly we are responsible for checking andrefreshing credentials before they expire. If no refreshment is done wewill encounter AmazonServiceException: 'The security token included inthe request is expired'. Utilize automatic refreshment of credentialsby passing the AWSCredentialsProvider directly to AmazonClient by removingthe getCredentials() call.This closes #2635,1
[FLINK-4586] [core] Broken AverageAccumulatorThis closes #2639,2
[FLINK-4844] Partitionable Raw Keyed/Operator State,1
[FLINK-4842] Introduce test to enforce order of operator / udf lifecycles,1
[FLINK-4857] Remove throws clause from ZooKeeperUtils functionsRemove the unnecessary throws clauses from all ZooKeeperUtils' functions which don'tthrow an actual exception.This closes #2659.,1
[FLINK-4795] [py] Fix CsvStringify for nested tuples,0
[FLINK-4805] [py] Fix implicit type conversion in CsvStringify,0
[FLINK-4794] [py] Fix partition_by_hash() implicit key usage,0
[FLINK-4804] [py] Fix first() failing when applied to groupings,0
[FLINK-4784] Unique MetricQueryService actor namesThis closes #2636.,2
[FLINK-3888] allow registering a custom convergence criterion in delta iterations- cleanups in iterations and aggregators code- add delta convergence criterion in the CollectionExecutor- add ITCases for delta custom convergenceThis closes #2606,1
[FLINK-4129] [gelly] HITSAlgorithm should test for element-wise convergenceRemoves the example HITSAlgorithm. The Gelly library includes the moreperformant HITS algorithm.This closes #2663,4
[FLINK-4780] Make GraphiteReporter protocol configurableThis closes #2677.,5
[FLINK-4772] [metrics] Store metrics as strings in MetricStore,2
[FLINK-4775] [metrics] Simplify MetricStore access,2
[FLINK-4833] properly log exceptions in CountMinHeavyHitterThis closes #2660,2
"[FLINK-4881][docker] remove shared volume for configurationREADME.md                  -    Description of the bluemix specific stepsbuild.sh                   -    modify permissions to make script executable by defaultdocker-compose-bluemix.yml -    allow to specify image names with path to private BM registrydocker-compose.sh          -    find out path to docker registry, extend build time to 120 secs, then call docker-composedocker-compose.yml         -    make use of container linking instead of shared volumesdocker-entrypoint.sh       -    use 'jobmanager' entry in /etc/hosts arising from container linking so that taskmanager can register itself with jobmanagerdocker-compose.sh -> bluemix-docker-compose.sh    - renamed on requestdocker-entrypoint.sh    - made sure the taskmanager's slots correlate to the number of CPUsThis closes #2667",2
[FLINK-4878][tests] Log test failure cause on INFO level,5
[FLINK-4852] Remove Non-Multiplexing StreamRecordSerializerThis also renames MultiplexingStreamRecordSerializer toStreamElementSerializer.,4
"[FLINK-4877] Rename TimeServiceProvider to ProcessingTimeServiceThe name is clashing with the soon-to-be-addedTimerService/InternalTimerService which is meant as an interface fordealing with both processing time and event time.TimeServiceProvider is renamed to ProcessingTimeService to reflect thefact that it is a low-level utility that only deals with ""physical""processing-time trigger tasks.",1
"[FLINK-4877] Refactor OperatorTestHarness to always use TestProcessingTimeServiceBefore, this would allow handing in a custom ProcessingTimeService butthis was in reality always TestProcessingTimeService.",3
[FLINK-4877] Use OperatorTestHarness and TestProcessingTimeService in Kafka Tests,3
[FLINK-4877] Refactor Operator TestHarnesses to use Common Base ClassThis also introduces KeyedTwoInputStreamOperatorTestHarness whichis similar to KeyedOneInputStreamOperatorTestHarness,3
"[FLINK-3674] Add an interface for Time aware User FunctionsThis moves the event-time/processing-time trigger code fromWindowOperator behind a well defined interface that can be used byoperators (and user functions).InternalTimerService is the new interface that has the samefunctionality that WindowOperator used to have. TimerService is the userfacing interface that does not allow dealing with namespaces/payloadsand also does not allow deleting timers. There is a defaultimplementation in HeapInternalTimerService that can checkpoint timers toa stream and also restore from a stream. Right now, this is managed inAbstractStreamOperator and operators can ask for anInternalTimerService.This also adds tests for HeapInternalTimerService.This adds two new user functions: - TimelyFlatMapFunction: an extension of FlatMapFunction that also   allows querying time and setting timers - TimelyCoFlatMapFunction: the same, but for CoFlatMapFunctionThere are two new StreamOperator implementations for these that use theInternalTimerService interface.This also adds tests for the two new operators.This also adds the new interface KeyContext that is used forsetting/querying the current key context for state and timers. Timersare always scoped to a key, for now.Also, this moves the handling of watermarks for both one-input andtwo-input operators to AbstractStreamOperators so that we have a centralground-truth.",1
[FLINK-4877] Rename Triggerable to ProcessingTimeCallbackThis more accurately describes what the interface is for.,2
[FLINK-4877] Rename ProcessingTimeCallback.trigger() to onProcessingTime(),2
"[FLINK-4581] [table] Fix Table API throwing ""No suitable driver found for jdbc:calcite""This closes #2506This closes #1491 // closing stale PRThis closes #997  // closing stale PR",5
[FLINK-4838] [docs] Remove STREAM keyword in StreamSQLExampleThis closes #2645,4
[FLINK-4875] [metrics] Use correct operator nameThis closes #2676.,1
[FLINK-4866] [streaming] Make Trigger.clear() Abstract to Enforce Implementation,1
[hotfix] Force Non-Parallel for Non-Keyed CEP Operators,1
[FLINK-4891] Remove flink-contrib/flink-operator-stats module,2
[FLINK-4843] Test for FsCheckpointStateOutputStream::getPos()This closes #2646.,1
[FLINK-4879] Make KafkaTableSource publicThis closes #2678,1
[FLINK-4862] fix Timer register in ContinuousEventTimeTriggerThis closes #2671,1
[FLINK-4824] [client] CliFrontend shows misleading error messageWhen a command-line program is run but no Flink job is executed themessage to the user is now displayed without the stacktrace.When a Flink program throws ProgramParametrizationException theoptional message is printed to stderr without a stacktrace.This closes #2662,2
[FLINK-4204] [gelly] Clean up gelly-examplesMoves drivers into separate package. Adds default main class to printusage listing included classes. Includes documentation for runningGelly examples.This closes #2670,1
[FLINK-4773] [metrics] [refactor] Rename IOMetricGroup to TaskIOMetricGroup,4
[FLINK-4773] [metrics] [refactor] Introduce OperatorIOMetricGroup,1
[FLINK-4639] [table] Introduce CalciteConfig to make Calcite features more pluggable.This closes #2521This closes #1617 // closing PR after discussion,1
[FLINK-4762] [table] Use plural in time interval unitsThis closes #2688,1
[hotfix] [kafka] Fix RackAwareMode instantiation in Kafka 0.10 testsThis closes #2654,3
[FLINK-3950] Implement MeterViewThis closes #2443.,2
[hotfix] Fix unnecessary stream wrapping for Netty Error Message Frames,0
"[hotfix] [kafka consumer] Improve logging For Kafka Consumer 0.8 shutdownThis does not log InterruptedExceptions on shutdown any more, because those always comeper the Task's cancelation strategy.This also slightly improves the behavior of joining on the spawned simple consumer threads on shutdown.",5
[hotfix] [gelly] Driver usage and configurationFixes driver usages to print error messages.Registers user command-line parameters for web UI configuration.,5
[FLINK-4691] [table] Add group-windows for streaming tables to Table API.This closes #2562.,1
[FLINK-4691] [table] Rework window property extraction.- Deduplicate aggregations and window properties in Table API,4
[FLINK-4924] Simplify Operator Test Harness Constructors,3
[FLINK-4892] Change TestHarness.snapshot() to return OperatorStateHandlesThis makes it symmetric with initializeState(),5
[FLINK-4892] Snapshot TimerService using Key-Grouped StateThis also removes StreamCheckpointedOperator from AbstractStreamOperatorwhich was added as an interim solution for snapshotting the timers.,1
[FLINK-4892] Re-enable RescalingITCaseWith AbstractStreamOperator no longer implementingStreamCheckpointedOperator the test passes again.,4
[FLINK-4892] Parameterize HeapInternalTimerServiceTestThis now tests multiple interesting key-group cases.,3
[FLINK-4892] Add Key-Group Ranges Test in HeapInternalTimerServiceTestThis checks whether key groups are correctly checkpointed and wether wecan correctly restore reassigned key-group ranges.,3
[FLINK-4907] Add Num-Subtasks/Subtask-Index Parameter to Operator Test Harnesses,3
[FLINK-4907] Add State Reshuffling in Operator Test Harness,3
[FLINK-4907] Add Test for Timers/State Provided by AbstractStreamOperator,1
[FLINK-4283] Use new InfiniteDelayRestartStrategy instead of FixedDelayRestartStrategy to avoid blocking threadsThis closes #2661.,0
[FLINK-4579] [RocksDB backend] Add StateBackendFactory and config shortcut for the RocksDB BackendThis also now packages the RocksDB state backend into the Flink distributionThis closes #2482,2
"[FLINK-4913][yarn] include user jars in system class loaderWhen deploying a Yarn cluster for a single job, this changepre-configures the cluster to include the user jar(s) on all nodes.This eliminates the need to upload jar files through theBlobClient. More importantly, it loads the user classes only once andnot on every instantiation of a Task. This also reduces the JobManagerclass loading upon recovery of a failed job.This closes #2692.",0
"[FLINK-4800] Introduce the TimestampedFileInputSplit for Continuous File ProcessingThis commit mainly introduces the TimestampedFileInputSplit,which extends the class FileInputSplit and also contains:i) the modification time of the file it belongs to and also, andii) when checkpointing, the point the reader is currently reading    from in the split the reader.This will be useful for rescaling. With this addition, theContinuousFileMonitoringFunction sends TimestampedFileInputSplitto the Readers, and the Readers' state now contain onlyTimestampedFileInputSplit.In addition, it refactors the code of the ContinuousFileMonitoringFunctionand that of the ContinuousFileReaderOperator along with the relatedtests.This closes #2618.",3
[FLINK-4903] [futures] Introduce synchronous future operationsThe synchronous future operations are executed by the thread which adds the operationif the future is already completed or by the thread executing the last operation.Increase FlinkFutureTest timeouts to 10sThis closes #2689.,3
"[FLINK-4894] [network] Don't request buffer after writing to partitionAfter emitting a record via the RecordWriter, we eagerly requesteda new buffer for the next emit on that channel (although it's not clearthat we will immediately need it). With this change, we request thatbuffer lazily when an emit call requires it.This closes #2690.",1
[FLINK-4715] Remove superfluous test,3
"[FLINK-4715] Fail TaskManager with fatal error if task cancellation is stuck- Splits the cancellation up into two threads:  * The `TaskCanceler` calls `cancel` on the invokable and `interrupt`    on the executing Thread. It then exists.  * The `TaskCancellationWatchDog` kicks in after the task cancellation    timeout (current default: 30 secs) and periodically calls `interrupt`    on the executing Thread. If the Thread does not terminate within    the task cancellation timeout (new config value, default 3 mins), the task    manager is notified about a fatal error, leading to termination of the JVM.- The new configuration is exposed via `ConfigConstants.TASK_CANCELLATION_TIMEOUT_MILLIS`(default: 3 mins) and the `ExecutionConfig` (similar to the cancellation interval).This closes #2652.",5
"[FLINK-4889] [InstanceManager] Remove ActorRef dependency from InstanceManagerThe instance manager should not know about the underlying RPC abstraction, namely Akka.Therefore, the PR removes the dependency on ActorRef from the InstanceManager.This closes #2698.",4
"Revert ""[FLINK-4894] [network] Don't request buffer after writing to partition""This reverts commit cbdb784dc24abba50674d054bb21c94dd7a559a5.",5
[FLINK-4378] Allow Setting Custom Configuration in RollingSink,5
[FLINK-4378] Allow Setting Custom Configuration in BucketingSink,5
"[FLINK-4787] [runtime-web] Return generic HttpResponse in RequestHandler- Let RequestHandler return a generic HttpResponse instead of a String. This  enables handlers to return custom reponses (differnt http codes, etc.)- Introduce AbstractJsonRequestHandler for default JSON responses",5
[FLINK-4787] [runtime-web] Add JobCancellationWithSavepointHandlers- Add handlers for triggering and monitoring job cancellation with  savepoints.This closes #2626.,0
[FLINK-4925] [metrics] Integrate meters into IOMetricGroupsThis closes #2694.,2
[hotfix] [docs] Add documentation for TaskManager's registration configuration parameters,2
[FLINK-4631] Prevent NPE in OneInputStreamTaskThis closes #2709.,2
[FLINK-4544[ Refactor JM/TM metrics,4
[FLINK-4923] [metrics] Expose Task's input/output buffer queue lengths and bufferPool usage as a metricsThis closes #2693,2
[FLINK-4245] JMXReporter exposes all defined variablesThis closes #2418.,2
[hotfix] [metrics] Make JmxMeter class static,1
[hotfix] Improved test stability of RescalingITCaseThis closes #2728.,1
[FLINK-4972] Fix CoordinatorShutdownTest,3
[FLINK-4733] Reuse operator IO metrics for task,1
[FLINK-4733] Port TaskManager metrics,2
[FLINK-4733] Port Task IO metrics,2
[hotfix] Fixes the TimestampedInputSplit.EOS comparison.This closes #2718,0
"[FLINK-4932] [distributed coordination] Failing in state RESTARTING only fails terminally if no more restarts are possibleIf in state RESTARTING a failure occurs, then a new restart attempt is started. Only if therestart strategy no longer allows further restarts or if the thrown exception is of typeSuppressRestartsException a job can go from RESTARTING into FAILED.This closes #2710",0
"[FLINK-4894] [network] Don't request buffer after writing to partitionAfter emitting a record via the RecordWriter, we eagerly requesteda new buffer for the next emit on that channel (although it's not clearthat we will immediately need it). With this change, we request thatbuffer lazily when an emit call requires it.This closes #2716.",1
[FLINK-4659] [core] Closed the jassConfStream object to prevent resource leaksThis closes #2665,5
"[FLINK-4933] [exec graph] Don't let the EG fail in case of a failing scheduleOrUpdateConsumers callInstead of failing the complete ExecutionGraph, a failing scheduleOrUpdateConsumers callwill be reported back to the caller. The caller can then decide what to do. Per default,it will fail the calling task.This closes #2700",0
"[FLINK-4887] [execution graph] Introduce TaskManagerGateway to encapsulate communcation logicAll task manager related logic is now encapsulated in the TaskManagerGateway. Consequently,there is no direct use of the ActorGateway in the ExecutionGraph anymore.Add PartitionInfo[FLINK-4887] Add FutureUtils#retry to automatically retry failed future operationsAdapt job manager[FLINK-4887] Refactor StackTraceSampleCoordinator to work with TaskManagerGateway and Flink futures[FLINK-4887] Refactor CheckpointCoordinator to work with TaskManagerGateway[FLINK-4887] Fix test cases to work with the newly introduce TaskManagerGateway[FLINK-4887] Update FlinkFuture#handlyAsync to avoid second future operation[FLINK-4887] Remove TaskOpeartionResult messageMake StackTrace and StackTraceSampleResponse serializableIncrease timeout of TaskStopTestThis closes #2699.",3
[FLINK-4884] Eagerly Store MergingWindowSet in State in WindowOperator,1
[FLINK-4447] [docs] Include NettyConfig options on Configurations pageThis closes #2465,1
"[FLINK-4445] [client] Add allowNonRestoredState flag to CLIAllow to specify whether a checkpoint restore should allowcheckpoint state that it cannot map to the program. This isexposed via the CLI in the run command:bin/flink run -s <savepointPath> -n ...Furthermore, the savepoint restore settings are moved out ofthe snapshotting settings.",1
[FLINK-4445] [checkpointing] Add option to allow non restored checkpoint stateAllows to skip checkpoint state that cannot be mapped to a job vertex whenrestoring.This closes #2712.,1
[FLINK-4935] [webfrontend] Submit job with savepointThis closes #2714.,2
[FLINK-4923] [metrics] Initializes all task's gauges in TaskIOMetricGroup and extract the used buffers interface for BufferPoolThis closes #2727.,1
[FLINK-4845] [runtime-web] Fix Job Exception pageThis closes #2722.,1
[FLINK-4398] [query] Improve logging and error message in failing KvStateServerHandlerTest,3
[FLINK-4398] [query] Fix race in KvStateServerHandlerTestSuccessful request are reported asynchronously after the Netty channelwrite has succeeded. The test checked the number of successful requeststoo early.,3
[FLINK-4945] FlinkKafkaConsumer logs wrong warning about confirmation for unknown checkpointThis closes #2706,5
[FLINK-4991] [taskmanager] Fix too aggressive timeout and improve logging in TaskTestThis closes #2738.,3
[FLINK-4850] [ml] FlinkML - SVM predict Operation for Vector and not LaveledVectorThis closes #2658.,2
[FLINK-4996] [core] Make CrossHint @PublicThis closes #2743.,1
[FLINK-4943] Fix typo ConfigConstants JavaDocs: YYARN -> YARNThis closes #2704.,2
[FLINK-4623] [table] Add physical execution plan to StreamTableEnvironment explain().This closes #2720.,1
"[FLINK-4743] [table] Add support for power(DOUBLE, DECIMAL) function.This closes #2686.",1
[FLINK-4315] [dataSet] [hadoopCompat] Annotate Hadoop-related methods in ExecutionEnvironment as @Deprecated.- Preparation to remove Hadoop dependency from flink-java- Alternatives for deprecated functionality is provided in flink-hadoop-compatibility via HadoopInputsThis closes #2637.,2
[yarn] fix debug string displayed for failed applicationsThis closes #2745.,0
[hotfix] [checkpointing] Fix error message in SavepointLoaderThe message referred to parallelism although max parallelism ischecked.,0
[FLINK-4960] Add AbstractStreamOperatorTestHarness.repackageState()The new method allows testing operator scale-in by combining severalOperatorStateHandles (that result from TestHarness.snapshot()) into oneto allow restoring an operator with a lower parallelism.,1
[hotfix] Don't Swallow Exception in RocksDBAsyncSnapshotTest,5
[hotfix] [tests] Simplify mocking of the ResultPartitionWriter,3
[FLINK-4977] [core] Fix enum serializer to use proper access to enum constants,1
[FLINK-4596] Fallback restart strategy config to let jobs choose restart configuration set at cluster levelAdded java doc for fallback restart strategyThis closes #2592.,2
[FLINK-4998][yarn] fail if too many task slots are configuredThis fails the deployment of the Yarn application if the number of taskslots are configured to be larger than the maximum virtual cores of theYarn cluster.This closes #2741.,5
[FLINK-3813][yarn] wait for CLI to complete before checking outputThis closes #2749.,2
[FLINK-4221] Show metrics in WebFrontend + general improvementsOther included changes:- Removed Properties tab- Renamed plan to overview- Added parallelism to task listThis closes #2724,1
"[FLINK-5004] [runtime] Add option to disable queryable state- By default, the queryable state server is enabled- Via config option `query.server.start` it can be disabled- In tests, we disable it by default- Not part of the TaskManagerOptions as there are also client  options availableThis closes #2748.",3
[hotfix] Remove unnecessary ConfigOptions#key() calls,5
[hotfix] Remove noisy log message in TaskCancelerWatchDog,2
"[FLINK-4876] [webfrontend] Allow to bind to a specific interface- Adds config key 'jobmanager.web.address' to configure listening address- Default is Netty's default, picking anyLocalAddress()This closes #2680.",1
[hotfix] Add Check for Keyed Operator in getInternalTimerService(),1
[FLINK-4951] Fix Javadoc of KeyedStream.flatMap(TimelyFlatMapFunction),1
[FLINK-4952] [scala] Add KeyedStream.flatMap(TimelyFlatMapFunction),1
[FLINK-4955] Add Translations Tests for KeyedStream.flatMap(TimelyFlatMapFunction),1
[FLINK-4957] Remove Key Serializer Parameter getInternalTimerService()It's not needed because we can get the key serializer from the keyedstate backend.,1
[FLINK-4957] Provide API for TimelyCoFlatMapFunction,1
[FLINK-5028] [streaming] StreamTask skips clean shutdown logic upon cancellation,2
[FLINK-5032] Fix CsvOutputFormatTest on Windows OSThis closes #2769.,3
[FLINK-5022] Suppress RejectedExecutionExceptions if the ExecutorService has been shut downThis PR suppresses occurring RejectedExecutionExceptions if an ExecutorService has been shutdown. This only works for ExecutorServices at the moment. All other exceptions are logged.This closes #2757,2
[FLINK-5014] [RocksDB backend] Add toString for RocksDBStateBackendThis closes #2760,5
[hotfix] [RocksDB backend] Minor cleanups to constructors and comments in RocksDBStateBackend,5
"[hotfix] [tests] Clean up (mostly redundant) PowerMock runners, preparations, and exclusions",1
[FLINK-4963] [gelly] Tabulate edge direction for directed VertexMetricsThe current implementation simply counts edges. We can do one better andtabulate unidirectional (u:v but no v:u) and bidirectional edges (u:vand v:u).This is effectively the 'dyadic census'.This commit also makes edge metrics distinct from vertex metrics.Previously EdgeMetrics has always been a superset of VertexMetrics.This closes #2725,1
[FLINK-4984] [checkpointing] Add Cancellation Barriers as a way to signal aborted checkpoints,1
[FLINK-4985] [checkpointing] Report canceled / declined checkpoints to the Checkpoint Coordinator,2
"[FLINK-4975] [checkpointing] Add a limit for how much data may be buffered in alignment.If more data than the defined amount is buffered, the alignment is aborted and the checkpoint canceled.",5
[FLINK-5019] Proper isRestored result for tasks that did not write state,2
[hotfix] Properly Await Termination in SavepointITCase,0
[hotfix] Move logging of JobStatus changes into the ExecutionGraphPrior the JobManager was responsible for logging the JobStatus changes. This introducedout of order logging since the JM was a mere job status listener which was notified byan asynchronous message.,2
[FLINK-5037] Fixed instability in AbstractUdfStreamOperatorLifecycleTest,3
"[FLINK-5038] [streaming runtime] Make sure Canceleables are canceled even them ""cancelTask"" throws an exception",1
"[FLINK-5033] [cep] Advance time with incoming watermarks at CEP operatorBefore the time was only advanced if the CEP had some events buffered. If the priority queuewas empty, then an incoming watermark did not advance the time. This led to missing timeoutsand pruning possibilities. The PR fixes this problem.This closes #2771.",0
[FLINK-5027] FileSource finishes successfully with a wrong pathIntegrated commentsThis closes #2765.,0
"[hotfix] Fix duplicate ""ms"" time unit in RestartStrategy.For example: ""Restart with fixed delay (10000 ms ms).""-> org.apache.flink.api.common.time.Time already prints the time unit.This closes #2778.",2
[hotfix] [tests] Fix boxed Integer comparison with != in PartitionerITCase.This closes #2774.,0
[hotfix] [tests] Fix wrong argument order of assertNotNull in ClassLoaderITCase.This closes #2775.,3
[hotfix] [docs] [tableAPI] Fix typos in Table API documentation.This closes #2776.,2
[FLINK-4946] [scripts] Load jar files from subdirectories of libThe Flink classpath is a concatenation of jar files in lib/. This commitincludes files from subdirectories of lib/ in the classpath.This closes #2708,2
[FLINK-4970] [gelly] Parameterize vertex value for SSSPThe input vertex values for SingleSourceShortestPaths andGSASingleSourceShortestPaths are unused and replaced with aparameterized type.This closes #2730,2
[hotfix] [gelly] Flip ordering of TriangleListing bitmaskEncode directed triangle bitmask using forward=10 and reverse=01 as doneby Batagelj and Mrvar in their Triadic Census table.,1
[FLINK-4934] [gelly] Triadic CensusA triad is any three vertices in a graph. The triadic census producescounts for each of the 4 undirected and 16 directed triad types.This closes #2731,2
"[FLINK-5046] [tdd] Preserialize TaskDeploymentDescriptor informationIn order to speed up the serialization of the TaskDeploymentDescriptor we can pre serializeall information which stays the same for all TaskDeploymentDescriptors. The information whichis static for a TDD is the job related information contained in the ExecutionGraph and theoperator/task related information stored in the ExecutionJobVertex.In order to pre serialize this information, this PR introduces the JobInformation classand the TaskInformration class which are stored in serialized form in the ExecutionGraphand the ExecutionJobVertex, respectively.This closes #2779.",5
"Revert ""[FLINK-3232] [runtime] Add option to eagerly deploy channels""The reverted commit did not really fix anything, but hid the problem bybrute force, sending many more schedule or update consumers messages.",5
[FLINK-5040] [jobmanager] Set correct input channel types with eager scheduling,1
"[FLINK-5040] [taskmanager] Adjust partition request backoffsThe back offs were hard coded before, which would have made itimpossible to react to any potential problems with them.This closes #2784.",0
"[FLINK-5012] Expose Timestamp in Timely FlatMap FunctionsThis also adds a Context parameter that holds the timestamp, time domainand TimerService to declutter the parameter list of the functions.",1
"[FLINK-5021] Remove the special EOS TimestampedFileInputSplit.Without this special split signaling that no more splits areto arrive, the ContinuousFileReaderOperator now closes bysetting a flag that marks it as closed and exiting when theflag is set to true and the pending split queue is empty.",1
[FLINK-5021] Guarantee PROCESS_ONCE works correctly after recovering.,1
"[FLINK-5021] Make the ContinuousFileReaderOperator rescalable.This is the last commit that completes the refactoring of theContinuousFileReaderOperator so that it can be rescalable.With this, the reader can restart from a savepoint with adifferent parallelism without compromising the providedexactly-once guarantees.",1
"[FLINK-4939] WriteAheadSink: Decouple creation and commit of a pending checkpointSo far the GenericWriteAheadSink expected thatthe subtask that wrote a temporary buffer to thestate backend, will be also the one to commit it tothe third-party storage system.This commit removes this assumption. To do thisit changes the CheckpointCommitter to dynamicallytake the subtaskIdx as a parameter when askingif a checkpoint was committed and also changes thestate kept by the GenericWriteAheadSink to alsoinclude that subtask index of the subtask that wrotethe pending buffer.This closes #2707.",4
[FLINK-4177] Harden CassandraConnectorITCaseThis closes #2484.,1
[hotfix] [cassandra] Fix CassandraSinkBase serialization issue,0
[hotfix] [metrics] Supply name to view/reporter thread,0
[hotfix] [metrics] Prevent concurrency issues in MeterView,0
[FLINK-4174] Enhance evictor functionality,1
[hotfix] [cassandra] [tests] Show error log messages,2
[FLINK-4174] Add accessor for current watermark in Evictor Context,1
[FLINK-4801] [types] Input type inference is faulty with custom Tuples and RichFunctionsThis closes #2625.,1
[hotfix] Remove unused ProcessingTimeService from Evictor,1
[FLINK-5013] [kinesis] Shade AWS dependencies to work with older EMR versionsThis closes #2787.,1
[hotfix] [metrics] MetricRegistry threadNumber starts at 1,1
[hotfix] [Kafka Consumer] Clean up some code confusion and style in the Fetchers for Kafka 0.9/0.10,5
"[FLINK-5048] [kafka consumer] Change thread model of FlinkKafkaConsumer to better handel shutdown/interrupt situationsPrior to this commit, the FlinkKafkaConsumer (0.9 / 0.10) spawns a separate thread that operates Kafka's consumer.That thread ws shielded from interrupts, because the Kafka Consumer has not been handling thread interrupts well.Since that thread was also the thread that emitted records, it would block in the network stack (backpressure) or in chained operators.The later case lead to situations where cancellations got very slow unless that thread would be interrupted (which it could not be).This commit changes the thread model:  - A spawned consumer thread polls a batch or records from the KafkaConsumer and pushes the    batch of records into a blocking queue (size one)  - The main thread of the task will pull the record batches from the blocking queue and    emit the records.",4
"Revert ""[hotfix] [cassandra] [tests] Show error log messages""This reverts commit 1adefee2eff9c9b4267f5b5e10022255cfcaf47a.",4
"Revert ""[hotfix] [cassandra] Fix CassandraSinkBase serialization issue""This reverts commit 5fa389014a3ce40534703c8a5731c8a9a955058a.",4
"Revert ""[FLINK-4177] Harden CassandraConnectorITCase""This reverts commit 62523acbe175cf159fe1b4ab6cf5c0412fc4d232.",4
[hotfix] [tests] Corrected log4j files.This closes #2814,2
[FLINK-5057] [taskmanager] Read cancellation timeout from task manager configThis closes #2793,5
"[FLINK-5063] [checkpointing] Discard state handles of declined or expired state handlesWhenever the checkpoint coordinator receives an acknowledge checkpoint message which belongsto the job maintained by the checkpoint coordinator, it should either record the state handlesfor later processing or discard to free the resources. The latter case can happen if acheckpoint has been expired and late acknowledge checkpoint messages arrive. Furthremore, itcan happen if a Task sent a decline checkpoint message while other Tasks where still drawinga checkpoint. This PR changes the behaviour such that state handles belonging to the job ofthe checkpoint coordinator are discarded if they could not be added to the PendingCheckpoint.This closes #2812",1
[FLINK-5006] [streaming] Remove assumption of order in SystemProcessingTimeServiceTestThis closes #2785,5
[FLINK-4263] [table] SQL's VALUES does not work properlyThis closes #2818.,1
[hotfix] [checkpoints] Enhance debug logging in exactly-once and at-least-once checkpoint stream aligners,2
[hotfix] [docs] Fix incorrect URL.This closes #2821.,0
[FLINK-5058] [scala-shell] Set correct value for TaskManager memory parameter.This closes #2799.,2
"[FLINK-5054] [FLINK-5056] Make the BucketingSink rescalable.Refactors the BucketingSink to be able to changeparallelism after restoring from a savepoint. Todo so, this commit changes the following:1) the sink does not clean up lingering files upon   restoring2) the previous snapshot/restore cycle is replaced   by the new initializeState/snapshotState one.This closes #2797.",5
[FLINK-5071][yarn] adjust vcore validation checkThe check didn't take the virtual core settings configured in the Flinkconfiguration into account.- improve error reporting- add test caseThis closes #2839.,1
[hotfix] [streamExamples] Fix typo in comment.This closes #2841.,2
"[hotfix] [docs] Fix broken links, figures, and code examples.This closes #2834.",2
[FLINK-4294] [table] Allow access of composite type fieldsThis closes #2319.,1
[FLINK-5123] [docs] Add description how to build a properly shaded build with different Maven versions,1
"[FLINK-4155] [kafka] Move partition list fetching  to open() for Kafka producersThe fetched partition list from Kafka in open() is sorted by partition idso that subtasks will have the same list across failures. To compensate the originaluse of the KafkaProducer instantiation in the constructor to eagerlyensure that required producer configs are provided, we check that at leastthe bootstrap servers are set.This change also includes refactoring of AtLeastOnceProducerTest for a morecomplete suite of tests on FlinkKafkaProducerBase.This closes #2681.",2
"[FLINK-3869] Replace WindowedStream.apply() by reduce()/fold()Before, there where these overloads for apply(): - appply(ReduceFunction, WindowFunction) - apply(T initial, FoldFunction, WindowFunction)These are now called reduce() and fold(). We keep the old methods anddeprecate them for compatibility.This also fixes a problem with apply(T initial, FoldFunction,WindowFunction) being to restrictive.",1
"[FLINK-5082] Pull ExecutorService lifecycle management out of the JobManagerThe provided ExecutorService will no longer be closed by the JobManager. Instead thelifecycle is managed outside of it where it was created. This will give a nicer behaviour,because it better seperates responsibilities.This closes #2820.",1
[FLINK-5073] Use Executor to run ZooKeeper callbacks in ZooKeeperStateHandleStoreUse dedicated Executor to run ZooKeeper callbacks in ZooKeeperStateHandleStore insteadof running it in the ZooKeeper client's thread. The callback can be blocking because itdiscards state which might entail deleting files from disk.Introduce dedicated Executor for blocking io operationsThis closes #2815.,2
[FLINK-5085] Execute CheckpointCoordinator's state discard calls asynchronouslyThe CheckpointCoordinator is now given an Executor which is used to execute the state discardcalls asynchronously. This will prevent blocking operations to be executed from within thecalling thread.Shut down ExecutorServices gracefullyThis closes #2825.,1
[FLINK-4910] Introduce safety net for closing file system streamsThis closes #2691.,5
[FLINK-5107] Introduced limit for prior execution attempt historyThis closes #2837.,2
"[FLINK-5107] Handle evicted execution attempts in request handlersIf a prior execution attempt cannot be retrieved because it has been evicted before,the request handler will now throw a meaningful exception to notify the requesterabout the evicted execution attempt.",0
[FLINK-5124] [table] Support more temporal arithmeticThis closes #2851.,1
[FLINK-2608] Updated Twitter Chill version.[FLINK-2608] Updated test with Java collections.[FLINK-2608] Updated Chill and Kryo dependencies.[FLINK-2608] Added collections serialization test.This closes #2623.,3
"[FLINK-5010] [akka] Introduce default configuration values for Akka's deathwatchSet the akka deathwatch interval to 10s, the akka deathwatch pause to 60s and the tcpconnection timeout to 20s per default.This closes #2831.",1
"[FLINK-5000] Rename Methods in ManagedInitializationContextThis removes ""managed"" from the OperatorStateStore and KeyedStateStoreaccess methods. There is no ""un-managed"" state and users might bewondering what ""managed"" means here.",1
[FLINK-4900] flink-master: Allow to deploy TM with containerAllows via a setting to deploy a base image on that a task managerruns.This closes #2703.,1
[FLINK-2662] [optimizer] Fix computation of global properties of union operator.- Fixes invalid shipping strategy between consecutive unions.This closes #2848.,0
[FLINK-5143] [table] Add EXISTS to list of supported SQL operators.This closes #2853.,1
[FLINK-4937] [table] Add incremental group window aggregation for streaming Table API.This closes #2792.,1
[hotfix][docs] Stream joins don't support tuple position keys,1
[hotfix] [streaming] Fix type extraction for joined streams.This closes #2755.,4
[FLINK-5149] let ContinuousEventTimeTrigger fire at the end of the windowThis changes the ContinuousEventTimeTrigger to behave like theEventTimeTrigger in the sense that it also triggers at the end of thewindow.This prevents the trigger from not firing at all in case the firsttrigger interval is after the window end.This closes #2860.[typo] fix toString() of ContinuousEventTimeTriggerThis closes #2854.,1
[FLINK-5075] [kinesis] Make connector fail-proof to incorrect Kinesalite API behaviourThis closes #2822.,0
[FLINK-2608] remove expensive integration tests previously introducedThis is a followup to 0d3ff88b369fbb1b0a8fb0e8263c9ce0a9da1583This closes #2856.,3
[FLINK-3702] Make FieldAccessors support nested field expressions.,1
[FLINK-3702] FieldAccessor refactor to static factoryCloses #2094,4
"[FLINK-5055][security] skip Hadoop UGI login if unsecuredThe new Kerberos authentication code in Flink assumed that it's runningagainst vanilla Hadoop. Original Hadoop's behavior is to skip a securelogin if security is not configured. This is different for otherdistributions, e.g. the MapR Hadoop distribution of Hadoop.Thus, we need to make sure we don't perform any login action if securityis not configured.This also performs minor code cleanup.This closes #2864.",4
"[FLINK-5112] [ExecutionGraph] Remove unused accumulator aggregation code from ArchivedExecutionJobVertexThe ArchivedExecutionJobVertex calculated for its ExecutionVertices the aggregated accumulatorvalue. However, the result was nowhere stored. This indicates that this code is no longer usedand can be removed.This closes #2846.",4
[hotfix] Fix condition in CoGroupRawDescriptorThis closes #2852.,0
[FLINK-4741] Proper shutdown the ServerBootstrap WebRuntimeMonitorThis closes #2862.,1
[FLINK-5096] Make the RollingSink rescalable.Integrates the RollingSink with the new state abstractions sothat its parallelism can change after resuming execution froma savepoint.This closes #2845.,4
[FLINK-4993] Don't Allow Trigger.onMerge() to return TriggerResultAllowing Trigger.onMerge() to return a TriggerResult is not necessarysince an onMerge() call will always be followed by an onElement() callwhen adding the element that caused the merging to the merged window.Having this complicates the internal logic of the WindowOperator andmakes writing Triggers more confusing than it has to be.,5
[FLINK-4993] Remove Unused Import in TriggerResult,2
[FLINK-5050] [build] Remove transitive JSON.org dependencyThis transitive dependency has an incompatible license.This closes #2824,5
[hotfix] [tests] Harden timeout logic for TaskManager registration in AbstractTaskManagerProcessFailureRecoveryTest,3
"[hotfix] Flush in CsvOutputFormat before closing, to increase CI stability",1
[FLINK-5168] Scaladoc annotation link use [[]] instead of {@link}This closes #2875,2
[hotfix] [docs] Add a rouch description about internal types of states and state backends,1
[FLINK-5181] Add Tests in StateBackendTestBase that verify Default-Value Behaviour,3
[FLINK-4872] [types] Type erasure problem exclusively on cluster executionThis closes #2823.,0
[FLINK-5026] Rename TimelyFlatMap to Process,2
[FLINK-4825] [table] Implement a RexExecutor that uses Flink's code generation.This closes #2884This closes #2874 (closing PR with Public API breaking changes),4
[FLINK-5184] [table] Fix compareSerialized() of RowComparator.This closes #2894,0
[FLINK-4832] [table] Fix global aggregation of empty tables (Count/Sum = 0).- Fix injects a union with a null record before the global aggregation.This closes #2840,0
[FLINK-4260] [table] Allow SQL's LIKE ESCAPEThis closes #2758.,1
"[FLINK-4921] Upgrade to Mesos 1.0.1Updated the Mesos dependency, to unlock some new features (notably theability to fetch into sandbox sub-directories).Shaded the protobuf dependency because the new Mesos library depends ona newer version than does akka-remoting.This closes #2827.",1
"[FLINK-5197] [jm] Ignore outdated JobStatusChanged messagesOutdated JobStatusChanged messages no longer trigger a RemoveJob message but arelogged and ignored. This has the advantage, that an outdated JobStatusChanged messagecannot interfere with a recovered job which can have the same job id.",4
[FLINK-4895] Drop Hadoop1 support and remove related build infrastructureThis closes #2850,5
[FLINK-5123] [task] Add missing @Override to Task#failExternally,0
[FLINK-4826] add keytab support to mesos containerThis closes #2734.This closes #2900.,1
[FLINK-4918] add SSL handler to artifact serverThis closes #2734.This closes #2900.,0
[hotfix] [webfrontend] Rebuild,0
"[FLINK-3680] [web frontend] Remove ""(not set)"" text in the Job Plan UIThis closes #2457",1
[FLINK-3719][web frontend] Moving the barrier between graph and statsThis closes #2467,4
[hotfix] [webfrontend] Organize job pane tabs,0
[FLINK-5194] [logging] Log heartbeats on TRACE level,2
[FLINK-5201] [logging] Log loaded config properties on INFO level,5
[FLINK-5196] [logging] Don't log InputChannelDeploymentDescriptor,2
[FLINK-5198] [logging] Improve TaskState toString,1
[FLINK-5199] [logging] Improve logging in ZooKeeperSubmittedJobGraphStore,2
[FLINK-5207] [logging] Decrease HadoopFileSystem logging,2
[FLINK-5192] [logging] Improve log config templatesThis closes #2899.,3
[FLINK-5216] [checkpoints] 'Min Time Between Checkpoints' references timestamp after checkpoint,2
"[FLINK-5159] [table] Add single-row broadcast nested-loop join.- Support for arbitrary joins (cross, theta, equi) if one input has exactly one row.This closes #2811.",1
[FLINK-5169] [network] Make consumption of InputChannels fair,1
[FLINK-5169] [network] Adjust tests to new consumer logic,2
[FLINK-5169] [network] Add tests for channel consumptionThis closes #2882.,3
[FLINK-5169] [network] Fix spillable subpartition buffer count,0
[hotfix] IOUtils.closeQuietly() closes absolutely quietly.,0
[hotfix] Fix test instability in AbstractTaskManagerProcessFailureRecoveryTest,3
[FLINK-5218] [state backends] Add test that validates that Checkpoint Streams are eagerly closed on cancellation.This is important for some stream implementations (such as HDFS) that do not properlyhandle thread interruption.,0
"[FLINK-5158] [table] Refactor BatchScan, DataSetScan, and BatchTableSourceScan.This closes #2921.",5
[hotfix] [jdbc] Set flink-table dependency to optional to avoid pulling in Calcite if not needed.,2
[FLINK-5228] [network] Fix LocalInputChannel re-trigger request and release deadlock,0
[FLINK-5128] [kafka] Get Kafka partitions in FlinkKafkaProducer only if a partitioner is setThis closes #2893.,1
[FLINK-5209] [webfrontend] Fix TaskManager metricsFixes a capitalization incompatibility when providing memory metrics tothe webfrontend. Numeric metrics now returned as numbers in the JSONAPI. Non-byte numbers now localized in the webfrontend.This closes #2902,5
[FLINK-5173] Upgrade RocksDB dependency,5
[FLINK-5146] Improved resource cleanup in RocksDB keyed state backend,5
[FLINK-5109] [webfrontend] Fix invalid content-encodingThis closes #2898,0
[docs] Replace broken download linkThis variable was removed in dc5062557a55,4
[FLINK-2844] [docs] Remove obsolete 'new-web-frontend' optionThis closes #2927.,1
[FLINK-5016] [checkpointing] Split EventTimeWindowCheckpointingITCaseSplit this EventTimeWindowCheckpointingITCase up into multiple testsin order to not run into the no output to stdout CI limit (currentlyset to 5 minutes).This closes #2933.,1
"[FLINK-5248] [tests] Catch restore failures in SavepointITCase- Minor test clean up- The test did not catch a task restore failure since only the  TDDs were tested. Now, we test that restore is actually called  and some checkpoints complete after restoring from a savepoint.",3
"[FLINK-5262][docs] Introduce Gemfile.lock to avoid dependency range conflictsThe Gemfile for specifying the Ruby dependencies of our documentationhas fixed dependency versions to avoid incompatible changes withdifferent versions of the dependencies. However, Ruby's dependencymanagement allows artifacts to specify ranges for dependencies. This canbe problematic.For instance, we use 'jekyll' version 2.5.3 which depends on'jekyll-gist' ~> 1.0 which means 1.0 >= version < 2.0. This may resolve'jekyll-gist' 1.4.0 which depends on 'octokit' ~> 4.2 which may be 4.2>= versions < 5.0. Too bad, 'octokit' starting with 4.4 depends on Rubyversion >= 2.0 which is not available on our build servers.Since we already use the improved version of Rubys build system called'bundler', we can mitigate this problem by checking in a Gemfile.lockfile which specifies the exact versions of all dependencies required tobuild the docs.This closes #2945.",2
"[FLINK-5091] Formalize the Mesos AppMaster environment for docker compatibility- introduced ContainerSpecification.- reworked how the TM container environment is constructed; eliminated- special-case environment variables, file layout.- added dynamic configuration support to GlobalConfiguration.- integrated the SecurityContext into AM/TM runners.- added config setting for Mesos framework user.- support DCOS side-channel authentication.- set the FS default scheme.- made the artifact server more generic (no assumption about existence- of dispatcher, Path-based).- moved some test code related to overriding the JVMs env.- moved the Mesos containerizer config code to the MesosTaskManagerParameters.This closes #2915.",2
[test-utils] cleanup and improve method to set the environment- introduced parameter to update or overwrite the environment- make Windows-specific code explicit- avoid duplicate update of environment map,5
[hotfix] Check for null in OperatorSnapshotResult#cancelThis closes #2950,1
[FLINK-5249] [docs] Fix description of datastream rescaling to match the figure.This closes #2932.,5
[FLINK-5259] [docs] Fix wrong execution environment in batch retry delays example.This closes #2943.,1
[FLINK-5257] [table] Include optimized logical plan in explain().This closes #2949.,2
[FLINK-5251] [table] Decouple StreamTableSourceScan from TableSourceTable.This closes #2934.,2
[FLINK-5179] [metrics] Close TaskManagerMetricGroup on JobManager dissociationThis closes #2886.,2
[FLINK-5261] [metrics] Clean up meters in ScheduledDropwizardReporterThis closes #2944.,4
[FLINK-4983] [webfrontend] Add faviconThis closes #2737,1
"[FLINK-4921] Upgrade to Mesos 1.0.1- Shading fix for Guava, Fenzo, Mesos lib",0
[hotfix][webfrontend] Added non-binary image assets to license check exceptions,1
"[FLINK-5041] Savepoint backwards compatibility 1.1 -> 1.2This addresses Savepoint, TaskState, StateHandels, KeyedStateBackends.This closes #2781.",1
[docs] clarify default restart behavior when checkpointing is enabled,0
[docs] Note that numberOfExecutionRetries and executionRetryDelay are deprecated.And some other minor fixes and deduplication.,0
[FLINK-4469] [table] Add support for user defined table function in Table API & SQL,1
[FLINK-4469] [table] Minor improvements- Fixed typos- Removed implicit conversion with TableCallBuilder- Fixed bugs about expression parser alias and static eval methods- Refactored testsThis closes #2653.,3
[FLINK-5274] [network] Handle reader release in LocalInputChannel,0
[FLINK-5275] [execgraph] Give more detailed error message if InputChannel deployment fails,0
[FLINK-4631] Prevent NPE in TwoInputStreamTaskCheck that the input processor has been created before cleaning it up.,4
[FLINK-4554] [table] Add support for array typesThis closes #2919.,1
[FLINK-5164] Disable some Hadoop-compat tests on WindowsThis closes #2889.,3
[FLINK-4563] [metrics] scope caching not adjusted for multiple reportersThis closes #2650.,2
"[FLINK-5020] Make the GenericWriteAheadSink rescalable.Integrates the new state abstractions with the GenericWriteAheadSinkso that the latter can change its parallelism when resuming executionfrom a savepoint, without geopardizing the provided guarantees.This closes #2759",1
[FLINK-5169] [network] Fix String formats in spillable partitionThis closes #2967.,0
[FLINK-5226] [table] Use correct DataSetCostFactory and improve DataSetCalc costs.- Improved DataSetCalc costs make projections cheap and help to push them down.This closes #2926.,1
[FLINK-5039] Bump Avro version to 1.7.7.This closes #2953.,2
[FLINK-3921] Add support to set encoding in CsvReader and StringParser.This closes #2060.,1
[FLINK-3921] Add support to set encoding in CsvReader and StringParser.- extends first commit.This closes #2901.,1
[FLINK-5285] Abort checkpoint only once in BarrierTrackerPrevent an interleaved sequence of cancellation markers for two consecutive checkpointsto trigger a flood of cancellation markers for down stream operators. This is done byaborting each checkpoint only once and don't re-create checkpoint barrier counts for alreadyaborted checkpoints.Add test caseThis closes #2963.,1
[FLINK-5278] Improve task and checkpoint related loggingAdd more loggingThis closes #2959.,2
"[FLINK-5193] [jm] Harden job recovery in case of recovery failuresWhen recovering multiple jobs a single recovery failure caused all jobs to be not recovered.This PR changes this behaviour to make the recovery of jobs independent so that a singlefailure won't stall the complete recovery. Furthermore, this PR improves the error reportingfor failures originating in the ZooKeeperSubmittedJobGraphStore.Add test caseFix failing JobManagerHACheckpointRecoveryITCaseThis closes #2909.",1
"[FLINK-5158] [ckPtCoord] Handle exceptions from CompletedCheckpointStore in CheckpointCoordinatorHandle exceptions from the CompletedCheckpointStore properly in the CheckpointCoordinator. Thismeans that in case of an exception, the completed checkpoint will be properly cleaned up and alsothe triggering of subsequent checkpoints will be started.This closes #2872.",4
[hotfix] properly encapsulate the original exception in JobClientThis closes #2890,0
[FLINK-4646] [gelly] Add BipartiateGraphThis closes #2564,1
[FLINK-5211] [metrics] [docs] Include example reporter configurationThis closes #2972.,5
[FLINK-5206] [py] Use random file names in testsThis closes #2973.,3
[FLINK-4906] [metrics] Introduce constants for IO metricsThis closes #2980.,2
[FLINK-5147] Prevent NPE in LocalFS#delete()This closes #2859.,4
[FLINK-5114] [network] Handle partition producer state check for unregistered executionsThis closes #2912.,0
[FLINK-5310] [RocksDB] Harden the JNI library loading,5
[hotfix] [tests] Add re-tries to the result verification via files.,2
[FLINK-5007] [checkpointing] Retain externalized checkpoint on suspensionHandles graceful cluster shut down (non-HA) like cancellation.,0
"[FLINK-5326] [network] Check release flag of parent in readerIn PipelinedSubpartitionView, there is a possible race withreleasing the parent subpartition and querying for a bufferin the view.The parent partition release clears all buffers in lockedscope and releases the view outside of the lock. If concurrentlythe view is queried for a buffer it might get null, whichis only allowed if the view was released.Because the release is only forwarded out of the lock scope,this can happen before the release has propagated.As a solution, we check the parent release status as well in theview. This is how it is handled in the spilled views, too.This surfaced with the recent refactorings, because the previousconsumption model required multiple rounds of get, registerListener,isReleased calls, which hid this problem.",0
[docs] Add docs about externalized checkpoints,2
[FLINK-5163] Port the ContinuousFileMonitoringFunction to the new state abstractions.,1
[FLINK-5163] Port the FromElementsFunction to the new state abstractions.,1
[FLINK-5163] Port the MessageAcknowledgingSourceBase to the new state abstractions.,1
[FLINK-5163] Port the StatefulSequenceSource to the new state abstractions.,1
[FLINK-5328] [logging] Add Thread name to FileSystem disposeFileSystemCloseableRegistryForTaskAdding this to the FileSystem dispose call in order to help debugging FLINK-5328when it occurs again. After the initial skim over the logs it looks like thestreams are closed to early for the failed task.,0
[FLINK-5145] WebInterface only polls selected metricsThis closes #2867.,2
[FLINK-5326] [network] Log errors in sending Netty handler,0
[FLINK-5304] [table] Rename crossApply/outerApply to join/leftOuterJoin in Table API.This closes #2978.,2
[FLINK-5223] [doc] Add documentation of UDTF in Table API & SQLThis closes #2956.,2
[FLINK-3848] [table] Add ProjectableTableSource and push projections into BatchTableSourceScan.This closes #2923.,1
"[FLINK-5300] Add more gentle file deletion procedureBefore deleting a parent directory always check the directory whether it contains somefiles. If not, then try to delete the parent directory.This will give a more gentle behaviour wrt storage systems which are not instructed todelete a non-empty directory.Add test case for more gentle file deletionThis closes #2970.",4
[FLINK-5290] Ensure backwards compatibility of the hashes used to generate JobVertexIds,1
[hotfix] [tests] Improve exception message for file-based result verification in 'TestBaseUtils',3
[FLINK-5327] Remove IOException from StateObject::getStateSizeThis closes #2993,1
"[hotfix] Clean up structure and comments in 'FileSystem'This commit aims to improve the readability of the FileSystem class.The commit does not introduce new/different code, but introduces sections in the class, moves nestedclasses and methods between these sections.The commit also improves comments for the class and nested classes.",1
[hotfix] [core] Minor code cleanups in 'LocalFileSystem'.This makes members final where possible and avoids repeated access to the system properties.This commit also brings the formatting style closer to the style of the other Flink classes.,2
[tests] Add 'CheckedThread' as a common test utility,3
[FLINK-5332] [core] Synchronize FileSystem::initOutPathLocalFS() to prevent lost files when called concurrently.,2
[FLINK-5289] [streaming] Give meaningful exceptions when using value state on non-keyed streamThis closes #2969,1
"[tests] Remove redundant copies of the JUnit RetryRulesThe classes were noved to 'flink-test-utils-junit', but apparently copies remained in 'flink-core'.",2
[FLINK-5307] [metrics] Log reporter configurationThis closes #2979,5
[FLINK-5002] [network] Renamed getNumberOfUsedBuffers() method to bestEffortGetNumOfUsedBuffers()This closes #2865,5
"[FLINK-5330] [tests] Harden KafkaConsumer08Test to fail reliably with unknown host exceptionUsing static mocking to reliably fail the InetAddress.getByName call with an UnknowHostException.Furthermore, the PR decreases the connection timeouts which speeds the test execution up.This closes #2998",3
[hotfix] [core] Fix typo in variable nameThis closes #3002,2
[FLINK-5258] [docs] Reorganize the docs to improve navigation and reduce duplicationThis closes #2940,1
[FLINK4429] Remove redis connector (now in Apache Bahir),4
[FLINK-5240][tests] ensure state backends are properly closedThis adds additional test cases to verify the state backends are closedproperly upon the end of a task. The state backends should always beclosed regardless of the final state of the task.This closes #2997.,3
[FLINK-5283] Fix closing streams when restoring old savepoint in keyed backends,0
[FLINK-5282] Fix closing streams on exception in SavepointV0Serializer,0
[FLINK-5041] Savepoint Backwards Compatibility 1.1 -> 1.2,2
[FLINK-5051] Add Serde Proxies for Serializers and State Backend Data,5
[FLINK-4936] [gelly] Operator names for Gelly inputsProvide descriptive operator names for Graph and GraphCsvReader.Condense multiple type conversion maps into a single mapper.Reuse objects in operations wrapping user-defined-functions.This closes #2832,1
[FLINK-5335] Allow ListCheckpointed user functions to return null,1
[FLINK-5266] [table] Inject projection of unused fields before aggregations.This closes #2961.,1
[FLINK-5187] [core] Port Row and related type utils to Java and move them to flink-core.This closes #2968.,2
[FLINK-5189] [table] Delete Row and its related classes from flink-table.This closes #3004.,2
[FLINK-5188] [table] [connectors] [core] Adjust imports and method calls to new Row type.- Port RowCsvInputFormat to Java and move it to flink-core.This closes #3003.,2
[FLINK-4446] Remove Flume connector (now in Bahir),4
"[FLINK-4611] [kinesis] Make ""AUTO"" credential provider as default for Kinesis ConnectorThis closes #2914.",1
"[FLINK-5097][gelly] Add missing input type information to TypeExtractorin MapVertices, mapEdges, fromDataSet, and groupReduceOnEdgesThis closes #2842",5
[FLINK-5311] [gelly] [docs] Add user documentation for bipartite graphThis closes #2984,2
[hotfix] Fix Table API doc typo,2
[FLINK-5011] [types] TraversableSerializer does not perform a deep copy of the elements it is traversingThis closes #2952.,2
[FLINK-4704] [table] Refactor package structure of flink-table.This closes #2958.,2
[FLINK-5343] [table] Add support to overwrite files with CsvTableSink.This closes #3011.,2
[FLINK-5255] [table] Generalize detection of single row inputs for DataSetSingleRowJoinRule.- Add support for projections and filters following a global aggregation.This closes #3009.,1
[FLINK-3848] [table] Add projection push down for StreamTableSource.- Add plan tests for projection push down.- Implement ProjectableTableSource in CsvTableSource.- Refactored RowCsvInputFormatThis closes #2810.,4
[FLINK-3848] [table] follow-up: Refactor TableSource tests.,3
[FLINK-5008] [docs] Update IDE setup and quickstart documentation.This closes #2764.,2
[docker] improve Dockerfile host configuration- configure job manager address for both operation modes- introduce argument to specify the external job manager address- replace ARG with ENV for backwards-compatibility- EXPOSE web port and RPC portThis closes #2981.,1
[FLINK-4922][docs] document how to use Flink on MesosThis closes #3007.,2
[FLINK-5091] cleanup unused Mesos configuration entries,5
[FLINK-5350] don't overwrite an existing JAAS configUsers may want to use SASL/PLAIN https://tools.ietf.org/html/rfc4616without Kerberos enabled.Skip security configuration if no Kerberos credentials are available.This closes #3017.,5
"[maven] properly attach the CEP Scala source codeTwo options, either change the default Maven source directory from'src/main/java' to 'src/main/scala' or use the build-helper-maven-pluginto attach the Scala sources. Opting for both here to be in lines withMaven standards and support Eclipse.This closes #2908.",1
"[FLINK-2821] use custom Akka build to listen on all interfacesThis uses Flakka (a custom Akka 2.3 build) to resolve the issue thatthe bind address needs to be matching the external address of theJobManager. With the changes applied, we can now bind to allinterfaces, e.g. via 0.0.0.0 (IPv4) or :: (IPv6).For this to work properly, the configuration entryJOB_MANAGER_IPC_ADDRESS now represents the external address of theJobManager. Consequently, it should not be resolved to an IP addressanymore because it may not be resolvable from within containeredenvironments. Akka treats this address as the logical address. Anymessages which are not tagged with this address will be received bythe Actor System (because we listen on all interfaces) but will bedropped subsequently. In addition, we need the external address forthe JobManager to be able to publish it to Zookeeper for HA setups.Flakka: https://github.com/mxm/flakkaPatch applied: https://github.com/akka/akka/pull/15610- convert host to lower case- use consistent format for IPv6 address- adapt config and test cases- adapt documentation to clarify the address config entry- TaskManager: resolve the initial hostname of the StandaloneLeaderRetrievalServiceThis closes #2917.",5
"[FLINK-5344] Fixed the dockerized doc build, which has been broken for a while. Fixed the -p option. Reverted the main Gemfile back to ruby 1.9 to make the build bot happy, and created a new Gemfile in ruby2/Gemfile to keep the incremental build option available.This closes #3016.",2
"[FLINK-4391] Add asynchronous I/O operations1. add an example job 2. fix a bug in state serialization in async wait operator; 3. move broadcast barrier after snapshot operator statesupdate IT caseadjust the whitespace in IT1. use final for member variable; 2. initialize resouce in open() 3. use ioexception instead of runtimeexception to propagate errorsmake sure head operator comes first while doing shapshot for chained operators[FLINK-4391] 1. adjust the order of snapshot for operators in one chain, so that head operator can do snapshot first. it is for the chained operator with async wait operator, which will keep emitting data in the internal buffer to its children if stream task perform checkpoint from tail to the head, getting incorrect result. 2. support LatencyMarker in async wait operator[FLINK-4391] use checkpoint lock in async wait operator; remove emitter thread[FLINK-4391] use checkpoint lock in async wait operator; remove emitter thread[FLINK-4391] 1. Re-add emitter thread. Without this thread, if there is no input coming, and we just use main thread to emit result, the finished async collectors may have to wait uncertained period of time to be emitted. The emitter thread can help output them as soos as possible; 2. In UNORDERED mode, only emits results prior to the oldest Watermark in the buffer; 3. Use the latest OperatorStateStore to keep partitionable operator state.[FLINK-4391] remove change to StreamTask.java[FLINK-4391] Optimize inner data structure for AsyncWaitOperator, add extra test cases.[FLINK-4391] Fix UT failure[FLINK-4391] Fix format problem[FLINK-4391] Add a RuntimeContext wrapper for RichAsyncFunction to disable getting state from RuntimeContext.This closes #2629.",1
[FLINK-4391] Polish asynchronous I/O operationsPolish AsyncFunctionMove AsyncCollectorBuffer to operators packageRework AsyncWaitOperator and AsyncStreamElementQueue implementationRename AsyncCollectorQueue into StreamElementQueueReworked StreamingOperatorsITCase and RichAsyncFunctionTestRefactor AsyncWaitOperatorTestAdd StreamElementQueueTestsAdd EmitterTest caseAdd comments,1
"[FLINK-4391] Add timeout parameter for asynchronous I/OThe timeout defines how long an asynchronous I/O operation can take. If the operationtakes longer than the timeout, then it is failed with an TimeoutException.Annotate classes with internal Annotation",0
[FLINK-4391] Add Scala API for asynchronous I/O operationsThis commit also adds a small example for asynchronous I/O with Scala.,1
[FLINK-5292] Add CheckpointedRestoringOperator interface.This breaks the StreamCheckpointedOperator interface into thecheckpointing and restoring part. The restoring part is meant foroperators that need to restore from legacy snapshots done using Flink1.1,2
[FLINK-5292] Expose some SavepointV0Serializer methods for use in tests,3
"[FLINK-5292] Add ""restoreFromLegacySnapshot"" in AbstractStreamOperatorTestHarness.For unit testing the code in operators that restores from Flink 1.1snapshots.",2
[FLINK-5294] Make WindowOperator backwards compatible with 1.1 snapshots,1
[FLINK-5295] Migrate the AlignedWindowOperators to the WindowOperator.This adds code that lets WindowOperator restore from the Flink 1.1fast aligned processing-time windows operator.,1
[FLINK-5294] Add tests for WindowOperator restore from 1.1 snapshot,1
[FLINK-5294] Test aggregating aligned window op restore from 1.1,3
[FLINK-5294] Test accumulating aligned window op restore from 1.1,3
[FLINK-5293] Make Kafka consumer backwards compatible with 1.1 snapshots,1
[FLINK-5293] Add test for Kafka backwards compatibility,3
[FLINK-5366] Add Initial version of SavepointUtilThis will serve as the basis for end-to-end tests of savepoint restorefrom Flink 1.1.,2
[hotfix] Fix compatibility check in RegisteredBackendStateMetaInfoThis was to strict. RocksDB initializes with null namespace Serializerand when we have the actual namespace serializer the check fails.,0
[hotfix] Add null checks in StateAssignmentOperation,1
[FLINK-5366] SavepointUtil into SavepointMigrationTestBase/Add TestThis also changes how the savepoint is being performed and now we'rewaiting on accumulators to signal that a job is ready for savepointing.,4
[FLINK-5317] Make the continuous file processing backwards compatible w/ unit tests.This includes both the ContinuousFileMonitoringFunction and theContinuousFileReaderOperator.,2
[FLINK-5367] [docs] Restored changes that were lost when merging the recent doc refactoring.This closes #3028,4
[FLINK-4669] [apis] Add createLocalEnvironment() utility method that starts the web UIThis closes #2541,1
[FLINK-4669] [apis] Harmonize the instantiations of local environments between Java/Scala Batch/Streaming,2
"[FLINK-5369] [build] Rework jsr305 and logging dependencies.Currently, every project in Flink has a hard (compile scope) dependency on the jsr305, slf4j, and log4jartifacts. That way they are pulled into every fat jar, including user fat jars as soon as they refer toa connector or library.This commit changes the behavior in two ways:  1. It removes the concrete logger dependencies from the root pom file. Instead, it adds them to the     'flink-core' project. That way, all modules that refer to 'flink-core' will have those dependencies     as well, but the projects that have 'flink-core' as provided (connectors, libraries, user programs,     etc) will have those dependencies transitively as provided as well.  2. The commit overrides the slf4j and jsr305 dependencies in the parents of 'flink-connectors',     'flink-libraries', and 'flink-metrics' and sets the to 'provided'. That way all core projects     pull the logger classes, but all projects that are not part of flink-dist (and rather bundled     in fat jars) will not bundle these dependencies again.The flink-dist puts the dependencies into the fat jar (slf4j, jsr305) or the lib folder (log4j).",2
"[FLINK-4861] [build] Package optional project artifactsPackage the Flink connectors, metrics, and libraries into subdirectoriesof a new opt directory in the release/snapshot tarballs.This closes #3014",1
[FLINK-4861] [build] Make sure 'opt' artifacts are not in the 'flink-dist' uber jarThis also removes gelly-examples from 'opt' assembly,4
[hotfix] [tests] Clean up some warnings,2
[hotfix] [tests] Fix instability in TimestampITCase,0
[hotfix] [tests] Speed up CoStreamCheckpointingITCase,3
[FLINK-4973] Let LatencyMarksEmitter use StreamTask's ProcessingTimeServiceThe LatencyMarksEmitter class uses now the StreamTask's ProcessingTimeService to schedulelatency mark emission. For that the ProcessingTimeService was extended to have the methodscheduleAtFixedRate to schedule repeated tasks. The latency mark emission is such a repeatedtask.This closes #3008.,0
[build system] Update version to 1.3-SNAPSHOT,5
[FLINK-5385] [core] Add a helper method to create Row object.This closes #3038,1
[FLINK-5348] [core] Add support for custom field names to RowTypeInfo.This closes #3020,5
[hotfix] Minutiae,0
[FLINK-4346] [rpc] Add new RPC abstraction,1
[FLINK-4368] [distributed runtime] Eagerly initialize the RPC endpoint membersThis closes #2351,5
[FLINK-4362] [rpc] Auto generate rpc gateways via Java proxiesThis PR introduces a generic AkkaRpcActor which receives rpc calls as aRpcInvocation message. The RpcInvocation message is generated by theAkkaInvocationHandler which gets them from automatically generated Java Proxies.Add documentation for proxy based akka rpc serviceLog unknown message type in AkkaRpcActor but do not fail actorUse ReflectionUtil to extract RpcGateway type from RpcEndpointThis closes #2357.,4
"[FLINK-4384] [rpc] Add ""scheduleRunAsync()"" to the RpcEndpointThis closes #2360",1
[FLINK-4392] [rpc] Make RPC Service thread-safe,1
[FLINK-4386] [rpc] Add a utility to verify calls happen in the Rpc Endpoint's main thread,1
"[FLINK-4383] [rpc] Eagerly serialize remote rpc invocation messagesThis PR introduces an eager serialization for remote rpc invocation messages.That way it is possible to check whether the message is serializable andwhether it exceeds the maximum allowed akka frame size. If either of theseconstraints is violated, a proper exception is thrown instead of simplyswallowing the exception as Akka does it.Address PR commentsThis closes #2365.",1
"[FLINK-4373] [cluster management] Introduce SlotID, improve and test ResourceProfileThis closes #2370.",2
"[FLINK-4382] [rpc] Buffer rpc calls until the RpcEndpoint has been startedThis PR allows the AkkaRpcActor to stash messages until the corresponding RcpEndpointhas been started. When receiving a Processing.START message, the AkkaRpcActorunstashes all messages and starts processing rpcs. When receiving a Processing.STOPmessage, it will stop processing messages and stash incoming messages again.Add test case for message stashingThis closes #2358.",3
[FLINK-4355] [cluster management] Implement TaskManager side of registration at ResourceManager.This closes #2353,2
"[FLINK-4403] [rpc] Use relative classloader for proxies, rather than system class loader.",5
[FLINK-4414] [cluster] Add getAddress method to RpcGatewayThe RpcGateway.getAddress method allows to retrieve the fully qualified address of theassociated RpcEndpoint.This closes #2392.,1
[FLINK-4434] [rpc] Add a testing RPC service.This closes #2394.,3
[FLINK-4355] [cluster management] Add tests for the TaskManager -> ResourceManager registration.This closes #2395.,3
[FLINK-4400] [cluster mngmt] Implement leadership election among JobMastersAdapt related components to the changes in HighAvailabilityServicesAdd comments for getJobMasterElectionService in HighAvailabilityServicesThis closes #2377.,1
[FLINK-4443] [rpc] Add support for rpc gateway and rpc endpoint inheritanceThis commit extends the RpcCompletenessTest such that it can now check for inheritedremote procedure calls. All methods defined at the RpcGateway are considered native.This means that they need no RpcEndpoint counterpart because they are implemented bythe RpcGateway implementation.This closes #2401.update commentsremove native method annotationadd line break,4
[hotfix] Remove RecoveryMode from JobMasterThe recovery mode is not used any more by the latest CheckpointCoordinator.All difference in recovery logic between high-availability and non-high-availabilityis encapsulated in the HighAvailabilityServices.,2
[hotfix] [clustermgnt] Set pending registration properly in TaskExecutorToResourceManagerConnection,1
[FLINK-4363] Implement TaskManager basic startup of all components in javaThis closes #2400,2
[FLINK-4347][cluster management] Implement SlotManager coreThis closes #2388,2
"[FLINK-4516] leader election of resourcemanager- add serial rpc service- add a special rpcService implementation which directly executes the asynchronous calls serially one by one, it is just for testcase- Change ResourceManagerLeaderContender code and TestingSerialRpcService code- override shutdown logic to stop leadershipService- use a mocked RpcService rather than TestingSerialRpcService for resourceManager HA testThis closes #2427",3
"[FLINK-4529] [flip-6] Move TaskExecutor, JobMaster and ResourceManager out of the rpc packageThe TaskExecutor, the JobMaster and the ResourceManager were still contained in the rpcpackage. With this commit, they will be moved out of this package. Now they are containedin dedicated packages on the o.a.f.runtime level.This closes #2438.",1
[FLINK-4528] [rpc] Marks main thread execution methods in RpcEndpoint as protectedGive main thread execution context into the TaskExecutorToResourceManagerConnection,2
[hotfix] Add self rpc gateway registration to TestingSerialRpcService,3
[FLINK-4451] [rpc] Throw RpcConnectionException when rpc endpoint is not reachableThis PR introduces a RpcConnectionException which is thrown if the rpc endpointis not reachable when calling RpcService.connect.This closes #2405.,2
[hotfix] [taskmanager] Fixes TaskManager component creation at startup,1
[FLINK-4538][FLINK-4348] ResourceManager slot allocation protcol- associates JobMasters with JobID instead of InstanceID- adds TaskExecutorGateway to slot- adds SlotManager as RM constructor parameter- adds LeaderRetrievalListener to SlotManager to keep track of the leader id- tests the interaction JM->RM requestSlot- tests the interaction RM->TM requestSlotThis closes #2463,3
[hotfix] Remove unused imports from SlotRequestRegistered/Rejected and ResourceSlot,2
[hotfix] Add methods defined in the gateway to the ResourceManager and TaskExecutor,1
[FLINK-4656] [rpc] Port the existing code to Flink's own future abstractionThis closes #2530.,2
[FLINK-4658] [rpc] Allow RpcService to execute Runnables and Callables in its executorThis closes #2531.,1
[FLINK-4537] [cluster management] ResourceManager registration with JobManager,2
[FLINK-4537] rebase and refine,2
[FLINK-4535] [cluster management] resourceManager process the registration from TaskExecutor,2
[FLINK-4535] rebase and refine,2
[hotfix] fix ResourceManagerGateway,0
[hotfix] [rpc] Add RpcConnectionTest to validate that connection buildup fails fast when endpoint is unreachable.,0
[FLINK-4408] [JobManager] Introduce JobMasterRunner and implement job submission & setting up the ExecutionGraphThis closes #2480,1
[FLINK-4580] [rpc] Report rpc invocation exceptions to the callerThis closes #2526.,2
[FLINK-4687] [rpc] Add getAddress to RpcServiceThis closes #2551.,1
[FLINK-4530] [rpc] Generalize TaskExecutorToResourceManagerConnection to be reusableThis closes #2520,2
[FLINK-4505] [cluster mngt] Implement TaskManager component's startupThe TaskManagerRunner now contains the startup logic for the TaskManager's components.,2
[FLINK-4505] [cluster mngt] Separate TaskManager service configuration from TaskManagerConfiguration; Implement TaskManagerRunnerRefactors the startup logic so that is easier to reuse.This closes #2461.,1
[FLINK-4606]  Integrate the new ResourceManager with the existed FlinkResourceManager,2
[FLINK-4703] RpcCompletenessTest: Add support for type arguments and subclassesThis closes #2561,1
[FLINK-4606] integrate features of old ResourceManagerThis closes #2540,2
[hotfix] Replace TaskManager.createTaskManagerComponents by TaskManagerServices,1
[FLINK-4406] [cluster management] Implement job master registration at resource manager[FLINK-4406] [cluster management] Skip new connection if new resource manager's address and leader id are both not changing[FLINK-4406] [cluster management] Verify registration response with leader idThis closes #2565.,4
[FLINK-4657] Implement HighAvailabilityServices based on ZooKeeper[FLINK-4657] Implement a few rpc calls for JobMaster[FLINK-4657][cluster management] Address review comments[FLINK-4657][cluster management] Throw exception when error occurred when request input split,0
"[FLINK-4478] [flip-6] Add HeartbeatManagerAdd a heartbeat manager abstraction which can monitor heartbeat targets. Wheneverno heartbeat signal has been received for a heartbeat timeout interval, theheartbeat manager will issue a heartbeat timeout notification.Add resourceID to HeartbeatListener.reportPayloadReplace scala future by Flink's futuresAdd unmonitoring testThis closes #2435.",3
[hotfix] Fix failing JobManagerRunnerMockTest,3
"[FLINK-4347][FLINK-4348] simplify SlotManager and integrate it with ResourceManagerInstead of relying on a full synchronization of all slots information onevery heartbeat, the SlotManager is now responsible for updating itsstate. It initially syncs all slots upon registration of theTaskExecutor. After that, it only receives notifications from theTaskExecutor when slots become available again. This simplifies thelogic of the SlotManager and makes the slot allocation more predictablein case of message loss.Additional changes:- Move the slot registration and allocation report to the registration  of the TaskExecutor- Let the TaskExecutor immediately notify the ResourceManager once a  slot becomes free. The ResourceManager has to confirm this  notification. Otherwise, the slot will be blocked because the  ResourceManager's state is not in sync.- Integrate with handleSlotRequestFailedAtTaskManager and introduce  fencing to protect against TaskExecutors which are not registered  anymore.- introduce RPC call to notify ResourceManager about free slots- ignore out-of-date slot requests from ResourceManager at TaskExecutor- let the ResourceManager update its state instead of relying on heartbeats- provide ResourceManagerServices to SlotManager- introduce factory for SlotManager- keep task gateways and worker information in ResourceManager and  inform SlotManager- add TaskExecutor test to ensure that a free slot which hasn't been  confirmed by the task executor is correctly blacklisted as long as the  ResourceManager has not confirmed the allocation removal.- adapt tests- update javadocsThis closes #2571.",2
[FLINK-4694] [rpc] Add termination futures to RpcEndpoint and RpcServiceThe termination futures can be used to wait for the termination of the respective component.This closes #2558.,1
"[FLINK-4738] [TaskManager] Port TaskManager logic to new Flip-6 TaskManagerThe ported logic contains the task lifecycle management methods, JobManager association andsetup of TaskManager components.Introduce Rpc implementations for TaskManager componentsImplement metrics setupMove more TaskManager components out of the constructor to make TaskExecutor more testableAdd RpcMethod annotation to TaskExecutor#confirmCheckpointThis closes #2594.",5
[FLINK-4746] Make TaskManagerRuntimeInfo an interfaceLet the TaskManagerConfiguration implement the TaskManagerRuntimeInformation to make some ofthe TaskManager's configuration values accessible from different components.This closes #2599.,5
[FLINK-4516] update leadership information in ResourceManagerThe leadership information remained static for connectedJobMasters. This updates it to remove stale JobMasters when they loseleadership status.This closes #2624,4
[FLINK-4735] [cluster management] Implements some job execution related RPC calls on the JobManager,2
"[FLINK-4375] [distributed coordination] Implement new JobManager creation, initialization, and basic RPC methods",5
[FLINK-4339] [cluster management] Implement Slot Pool core on JobManager side,2
[FLINK-4489] [tm] Add TaskSlotTable to manage slot allocations for multiple job managersAdd TimerService for slot timeoutsAdd task and task slot access methodsAdd comments to newly introduced classesThis closes #2638.,1
"[FLINK-4360] [tm] Implement TM -> JM registration logicUpon requesting a slot for a new job, the TaskManager registers this job at theJobLeaderService. The job leader service is responsible to monitor job leader changesfor all registered jobs. In case of a new job leader, the service will try to establisha connection to the new job leader. Upon establishing the connection the task manageris informed about it. The task manager will then offer all allocated but not yet activeslots to the new job leader.Implement JobLeaderServiceThe JobLeaderService is responsible for establishing a connection to the JM leader of a givenjob.Disable TaskExecutorTest#testRejectAllocationRequestsForOutOfSyncSlotsAdd simple task submission testAdd job leader detection test caseAdd task slot acceptance testFix RpcCompletenessTestAdd commentsThis closes #2640.",3
[hotfix] [tests] Migrate some test tasks to Java,3
[FLINK-4835] [cluster management] Add embedded version of the high-availability servicesThis includes the addition of the EmbeddedLeaderServiceand a clean shutdown hook for all high availability services.,1
"[FLINK-4836] [cluster management] Add flink mini cluster (part 1)This implements  - mini cluster configuration  - startup / shutdown of common services (rpc, ha)  - startup / shutdown of JobManager and Dispatcher",5
[FLINK-4689] [cluster management] Implement a simple slot provider for the new job manager,1
[FLINK-4351] [cluster management] JobManager handle TaskManager's registration,0
[hotfix] Treat taskManager's rpc address and location separately,1
[FLINK-4839] [cluster management] JobManager handle TaskManager's slot offeringThis closes #2647 #2643.,0
[hotfix] [cluster management] Remove scala dependencies from MiniCluster.java,5
[hotfix] Add a DefaultSlotManager similar to the TestingSlotManager,3
[FLINK-4836] [cluster management] Start ResourceManager and TaskManager services in MiniCluster,5
[FLINK-4836] [cluster management] Start ResourceManager in MiniCluster,5
Rebasing fixes on latest master,3
[FLINK-4882] [flip-6] Remove exceptions from HighAvailabilityServices where not necessaryCleanup of the interface HighAvailabilityServices so that only methods which really throw anexception have an exception clause defined.This closes #2679.,1
[FLINK-4847] Let RpcEndpoint.start/shutDown throw exceptionsAllowing the RpcEndpoint.start/shutDown to throw exceptions will help to let rpc endpointsto quickly fail without having to use a callback like the FatalErrorHandler.This closes #2651.,0
"[FLINK-4851] [rm] Introduce FatalErrorHandler and MetricRegistry to RMThis PR introduces a FatalErrorHandler and the MetricRegistry to the RM. The FatalErrorHandler is used to handle fatal errors. Additionally, the PR adds the MetricRegistry to the RM which can be usedto register metrics.Apart from these changes the PR restructures the code of the RM a little bit and fixes someblocking operations.The PR also moves the TestingFatalErrorHandler into the util package of flink-runtime test. Thatit is usable across multiple tests.Introduce ResourceManagerRunner to handle errors in the ResourceManagerThis closes #2655.",0
"[FLINK-4853] [rm] Clean up job manager registration at the resource managerIntroduce the JobLeaderIdService which automatically retrieves the current job leader id.This job leader id is used to validate job manager registartion attempts. Additionally, itis used to disconnect old job leaders from the resource manager.Add commentsThis closes #2657.",1
"[FLINK-4871] [mini cluster] Add memory calculation for TaskManagers to MiniClusterIf the managed memory size for the task manager has not been set in the Configuration, thenit is automatically calculated by dividing the available memory by the number of distributedcomponents. Additionally this PR allows to provide a MetricRegistry to the TaskManagerRunner.That way it is possible to use the MiniCluster's MetricRegistry.Add memory calculation for task managersThis closes #2669.",1
Rebase fixes,0
[FLINK-4958] [tm] Send slot report to RM when registeringFix failing test cases,3
[FLINK-4834] [cluster management] Add LeaderIdMismatchException at a common way to report RPC calls rejected due to outdated leader status.,5
[FLINK-4986] Improvements to the JobMaster,1
[FLINK-4987] Harden SlotPool on JobMaster,2
"[FLINK-4987] Add RpcTaskManagerGateway implementation; Port AllocatedSlotsTest, AvailableSlotsTest and SlotPoolTestThe RpcTaskManagerGateway is the TaskManagerGateway of Flink's new RPC abstraction. It basically forwards all calls to the underlying TaskExecutorGateway.Moreover, this PR enables the disabled tests AllocatedSlotsTest, AvailableSlotsTest and SlotPoolTest.Add license header to RpcTaskManagerGatewayFix ExecutionGraphMetricsTest",3
[FLINK-4954] [rpc] Discard messages when AkkaRpcActor is in state Processing.STOPWhen the AkkaRpcActor receives a message while being in state Processing.STOP it will discardit and send an AkkaRpcException back to the caller. This replaces the old stashing behaviourwhich had the problem that it was just a best effort approach to keep all received messages.Distributed components should not rely on this behaviour. That's why it was replaced with discardingmessages.,0
[FLINK-5171] [runtime] fix wrong use of Preconditions.checkState in TaskManagerRunnerThis closes #2880.,1
[FLINK-5170] [akka] Fix hostname usage in AkkaUtils.getConfigThis closes #2879.,5
[FLINK-5170] [akka] Extend AkkaUtils.getAkkaConfig methods to properly work with Java,1
[FLINK-5076] Shutting down TM when shutting down mini cluster.This closes #2817.,5
[FLINK-5093] Fix bug about throwing ConcurrentModificationException when stopping TimerService.[FLINK-5093] Remove useless import.This closes #2828.,2
[FLINK-5093] Add proper shutdown of scheduled executor service in TimerService,1
[FLINK-5141] [streaming api] Implement LocalStreamEnvironment for new mini cluster.This closes #2877,5
[FLINK-5141] [runtime] Add 'waitUntilTaskManagerRegistrationsComplete()' to MiniCluster,5
"[FLINK-5140] [JobManager] SlotPool accepts allocation requests while ResourceManager is not connectedThe requests are kept for a certain time and fulfilled once the ResourceManager is connected.If no ResourceManager is connected in time, the allocation requests are failed.",0
[FLINK-5238] [minicluster] MiniCluster starts local communication if only one TaskManager is used,1
[hotfix] Improve logging and thread characteristics for 'EmbeddedNonHaServices',2
[FLINK-5239] [distributed coordination] RPC service properly unpacks 'InvocationTargetExceptions',1
[FLINK-5190] [runtime] fix ZooKeeperLeaderRetrievalService close the zk client when stopping bug,0
[FLINK-4928] [yarn] Implement FLIP-6 YARN Application Master Runner,1
[FLINK-4928] [yarn] Implement FLIP-6 YARN Application Master Runner,1
[FLINK-4929] [yarn] Implement FLIP-6 YARN TaskExecutor RunnerSummary: Implement FLIP-6 YARN TaskExecutor RunnerTest Plan: NAReviewers: biao.liubDifferential Revision: http://phabricator.taobao.net/D6564,3
[FLINK-4927] [yarn] refine YARN Resource manager according to till's comments,2
[FLINK-5254] [yarn] Implement YARN High-Availability Services,2
"[FLINK-4930] [client, yarn] Implement FLIP-6 YARN clientSummary: Implement FLIP-6 YARN clientTest Plan: NAReviewers: biao.liubDifferential Revision: http://phabricator.taobao.net/D6563",3
[FLINK-4930] [client] [yarn] delete tmp file of job graph and refine finalizeCluster,2
[hotfix] [tests] Clean up lots of warnings,2
[tests] Harden TaskExecutorTest,3
[hotfix] RAT - Exclude test snapshots,3
[FLINK-4861][hotfix] Fix change-scala-version script for opt assembly,4
[FLINK-5382][web-frontend] Fix problems with downloading TM logs on Yarn,2
[FLINK-5408] [RocksDB backend] Uniquify RocksDB JNI library path to avoid multiple classloader problem,0
[FLINK-5349] [docs] Fix typos in Twitter connector exampleThis closes #3015.,2
[FLINK-5323] [docs] Replace CheckpointNotifier with CheckpointListenerTHis closes #3006.,2
[FLINK-4870] Fix path handling in ContinuousFileMonitoringFunctionThis closes #2887.,2
[FLINK-4255] Unstable test WebRuntimeMonitorITCase.testNoEscapeThis closes #3019.,3
[FLINK-5160] Fix SecurityContextTest#testCreateInsecureHadoopContext on WindowsThis closes #2888.,3
[FLINK-4288] [table] Make it possible to unregister tablesThis closes #2511.,1
[FLINK-4686] [table] Add possibility to get column namesThis closes #2553.,1
[FLINK-4890] [core] Make GlobFilePathFilter work on Windows,1
"[FLINK-5397] [runtime] Do not replace ObjectStreamClass on deserialization of migration package classes, override resolveClass(...) insteadThis closes #3050",0
[hotfix] Set default test logger back to 'OFF' in 'flink-tests',3
"[FLINK-5390] [yarn] Fix for proper closing input and output streams, in case of errorsThis closes #3045",0
[FLINK-5399] [checkpoints] Add more information about checkpoint to TriggerSavepointSuccessThis closes #3051,5
[FLINK-5400] [core] Add accessor to folding states in RuntimeContextThis closes #3053,1
[hotfix] [table] Remove unnused import and warnings in RexProgramProjectExtractorTest,3
[FLINK-5160] SecurityUtils use OperatingSystem.getCurrentOperatingSystem()This closes #3066.,5
[FLINK-5412] Enable RocksDB tests on Windows OSThis closes #3067.,3
[FLINK-4148] Fix min distance calculation in QuadTreeThis closes #2442.,0
[FLINK-5119][web-frontend] Fix problems in displaying TM heartbeat and path.This closes #3070.,0
[FLINK-5381][web-frontend] Fix scrolling issuesThis closes #3069.,0
"[docs] Clarify restart strategy defaults set by checkpointing- Added info about checkpointing changing the default restartstrategy in places where it was missing: the config page and thesection about the fixed-delay strategy- Replaced no-restart with ""no restart"" so people don't think we're referring to a config value- Replaced invalid <it> html tag with <code>- Fixed bad link to restart strategies page from state.md",2
[docs] Add TOC to restart strategies pageThis closes #3059.,1
"[javadocs, network] Add javadocs to SpanningRecordSerializer and RecordSerializer",2
[network] Clear serializer only once in RecordWriter#flush()This closes #2829.,1
[FLINK-5066] [network] Add EventSerializer.isEventThis allows PartitionRequestQueue to peak into event buffers instead of de-serializing the full event class.This closes #2806.,1
[FLINK-5059] [network] Only serialise events once during RecordWriter#broadcastEventThis closes #2805.,1
[FLINK-4651] Ensure processing-time timers are set on restoreThis test ensures that we set a low-level processing time timer in casewe have processing-time timers set.,1
[FLINK-5360] Fix argument names in WindowedStream,0
"[FLINK-4410] [runtime, runtime-web] Remove old checkpoint stats tracker code",4
[FLINK-4410] [runtime] Rework checkpoint stats tracking,1
[FLINK-4410] [runtime-web] Add detailed checkpoint stats handlers,0
[FLINK-4410] [runtime-web] Add new layout for checkpoint stats,1
[FLINK-4410] [runtime-web] Rebuild JS/HTML filesThis closes #3042.,2
[FLINK-5357] [table] Fix dropped projectionsThis closes #3063.,4
[FLINK-5084] [table] Replace Java Table API integration tests by unit testsThis closes #2977.,3
[hotfix] [table] Enable all CalciteConfigBuilderTest testsThis closes #3065.,3
[FLINK-4673] [core] TypeInfoFactory for Either typeRemoves from TypeExtractor the explicit parsing for Either and adds anEitherTypeInfoFactory.This closes #2545.,5
[FLINK-5280] [table] Refactor TableSource interface.This closes #3039.,4
[FLINK-5358] [types] Add support to extract RowTypeInfo from Row instance.This closes #3027.,5
[FLINK-5320] Fix result TypeInformation in WindowedStream.fold,5
[FLINK-5237] Don't Fire Processing-Time Timer in registerTimer()Immediately firing the timer can lead to endless recursion if theonTimer() method sets a timer for the past.,1
[FLINK-5237] Consolidate and harmonize Window Translation Tests,3
[FLINK-5418] [table] Estimated row size does not support nested typesThis closes #3073.,1
[hotfix] [table] Remove typo,2
[FLINK-5388] Change private Graph constructor to protectedThis closes #3044,4
[hotfix] [core] Migrate ConnectionUtils from System.currentTimeMillis() to System.nanoTime()This change makes the code robust against concurrent clock adjustments.,1
[Flink-5378] [runtime] Bumped Scopt version to 3.5.0.This will also allow for using comma-separated values in the CLI.This closes #3072,1
[FLINK-5442] [streaming] Ensure order of enum elements in StateDescriptor.Type through a testThis closes #3091,3
[FLINK-5427] [docs] Fix code example in event_timestamps_watermarks.mdThis closes #3082,0
"[FLINK-5364] [security] Rework JAAS configuration to support user-supplied entriesFixes FLINK-5364, FLINK-5361, FLINK-5350, FLINK-5055This closes #3057",2
[FLINK-5364] [security] Fix documentation setup for Kerberos,1
[hotfix] [docs] Move 'dev/state_backends' to 'ops/state_backends',4
"[FLINK-5454] [docs] Add stub for docs on ""Tuning for large state""",2
[FLINK-5455] [docs] Add stub for Upgrading Jobs and Framework,1
[hotfix] [docs] Move section about internal snapshot implementation from 'state_backends.md' to 'stream_checkpointing.md',4
[FLINK-5456] [docs] Add stub for types of state and state interfaces,1
[FLINK-5457] [docs] Add stub for Async I/O docs,2
[FLINK-5458] [docs] Add a template for migration guide,1
[FLINK-5459] [docs] Add templates for debugging classloading and debugging event time issues,0
[FLINK-5460] [docs] Add placeholder for Docker setup guide,1
[FLINK-5421] Add explicit restore() method in Snapshotable,1
[FLINK-5421] Deduplicate code in StateHandle Iterators,0
[hotfix] [docs] Polish Table API / SQL UDTF documentation.,2
[FLINK-5466] [webfrontend] Set environment to production in gulpfile,2
[FLINK-5466] [webfrontend] Rebuild CSS/JS filesThis closes #3100.,2
[FLINK-5444] [webfrontend] Make UI links relative,2
[FLINK-5444] [webfrontend] Rebuild HTML/JS filesThis closes #3093.,2
[FLINK-5296] Expose the old AlignedWindowOperators through special assignersThe user can use the deprecated AccumulatingProcessingTimeWindowOperatorand AggregatingProcessingTimeWindowOperator by using theTumblingAlignedProcessingTimeWindows and theSlidingAlignedProcessingTimeWindows introduced by thiscommit. These operators are neither backwards compatibilitynor rescalable.,1
[FLINK-5407] Handle snapshoting null-operator in chain,1
[FLINK-5407] IT case for savepoint with iterative job,2
[hotfix] Remove deprecated method in HeapKeyedStateBackendThe method is not needed and was left there by mistake.,4
[FLINK-5467] Avoid legacy state for CheckpointedRestoring operatorsThis closes #3102.,1
[FLINK-5155] Deprecate ValueStateDescriptor constructors with default value,2
[FLINK-5318] Make the RollingSink backwards compatible.,1
"[FLINK-5443] Migrate from Rolling to Bucketing sink.To migrate from a RollingSink to a BucketingSink, auser can now take a savepoint, change his code touse a BuckeingSink with the same properties as theprevious RollingSink, and resume his program fromthat savepoint.",1
[hotfix] [docs] Improved Table API docs.,2
[docker] improve Dockerfile- Make build.sh executable- Fix Dockerfile using ARG instead of ENV- Prevent exit only for job-/taskmanger shortcutsThis closes #3086.,1
[FLINK-5265] Introduce state handle replication mode for CheckpointCoordinator,0
Hide broadcast state / remove from public API,4
[FLINK-5250] Unwrap WrappingFunction in AbstractStreamOperator.setOutputType()This makes InternalWindowFunction subclasses WrappingFunctions andcorrectly forwards calls to setOutputType() by unwrappingWrappingFunction in the newly added StreamingFunctionUtils.,1
[FLINK-5250] Make AbstractUdfStreamOperator aware of WrappingFunction,1
[FLINK-5489] maven release:prepare fails due to invalid JDOM comments in pom.xml.This closes #3123,5
[FLINK-5457] [docs] Add documentation for asynchronous I/O,2
[FLINK-4692] [table] Add tumbling group-windows for batch tablesThis closes #2938.,1
"[FLINK-5426] [ml] Clean up the Flink Machine Learning libraryRemoved duplicate tests, inproved scaladoc and naming, removed typo's in scaladoc, introduced and improved use of constants, improved test-case naming.This closes #3081.",3
[hotfix] [table] Test does not extend TableProgramsTestBase,3
[FLINK-5303] [table] Add CUBE/ROLLUP/GROUPING SETS operator in SQLThis closes #2976.,1
[FLINK-4450] [storm compat] Update storm version to 1.0This closes #3037,5
[FLINK-5448] [checkpoints] Fix typo in StateAssignmentOperation ExceptionThis closes #3097,2
[FLINK-5438] [streaming api] Typo in JobGraph generator ExceptionThis closes #3098,2
"[FLINK-5485] [webfrontend] Mark compiled web frontend files as binary when processed by git diffParticularly beneficial now that javascript is minified, we can markcompiled web frontend files as binary when processed by git diff.  https://linux.die.net/man/5/gitattributesThis does not affect how files are displayed by github.This closes #3122",2
[FLINK-5345] [core] Add a utility to delete directories without failing in the presence of concurrent deletes,4
[FLINK-5345] [core] Migrate various cleanup calls to concurrency-safe directory deletion,4
[FLINK-3617] [scala apis] Added null value check.,1
[FLINK-4959] [docs] Add documentation for ProcessFunction,1
[FLINK-5447] [table] Sync documentation of built-in functions for Table API with SQLThis closes #3126.,1
[FLINK-5394] [table] Fix row count estimationThis closes #3058.,0
[FLINK-5268] Split TableProgramsTestBase into TableProgramsCollectionTestBase and TableProgramsClusterTestBaseThis closes #3099.,3
[FLINK-5144] [table] Fix error while applying rule AggregateJoinTransposeRuleThis closes #3062.,0
[FLINK-5518] [hadoopCompat] Add null check to HadoopInputFormatBase.close().This closes #3133This closes #243 // closing stale PR,1
"[FLINK-5461] [gelly] Remove Superflous TypeInformation DeclarationFLINK-4624 updated Gelly's Summarization algorithm to useEither<NullValue, VV> in order to support types for which theserialization does not support null values. This required the use ofexplicit TypeInformation due to TypeExtractor. FLINK-4673 created aTypeInfoFactory for EitherType so the explicit TypeInformation can beremoved.This closes #3096",4
"[hotfix] [gelly] Improve generic type formattingAdd spacing between type parameters.For example, 'Vertex<K,VV>' has been updated to 'Vertex<K, VV>'.",5
"[hotfix] [gelly] Indent Java with tabs not spacesThis PR also applies IntelliJ's ""reformat code"" using the unofficialFlink-style configuration.",5
"[hotfix] [docs] Several fixes on ""Basic API Concepts"".- Fix a wrong function name `groupBy()` to `keyBy()`.- Add closing parentheses.- Fix an invalid return type of sample code.- Remove a duplicate ""their"".This closes #3145.This closes #3146.This closes #3147.This closes #3148.",4
[FLINK-3150] Make YARN container invocation configurableThis closes #3056,5
[FLINK-5484] [serialization] Add test for registered Kryo types,3
"Revert ""[FLINK-2608] Updated Twitter Chill version.""This reverts commit 0d3ff88b369fbb1b0a8fb0e8263c9ce0a9da1583.",4
[FLINK-5512] [doc] Improve RabbitMQ documentationThis closes #3136.,2
[FLINK-5377] [docs] Stress importance of UIDs for savepoints,2
"[FLINK-5423] [ml] Implement Stochastic Outlier Selection (SOS) algorithmImplemented the Stochastic Outlier Selection algorithm in the Machine Learning library, including the test code and scaladoc documentation. Furthermore extended the development documentation.This closes #3077.",2
[FLINK-5560] [webfrontend] Align table header columns with body,2
[hotfix] [webfrontend] Rename 'pending' subtask stat to 'pending_or_failed',0
[webfrontend] Rebuild web frontend,5
[FLINK-5574] [docs] Add checkpoint monitoring docs,2
[FLINK-5556] [checkpointing] Report correct buffered bytes during alignmentThis closes #3164.,2
[FLINK-5543] [client] Add a comment to the code about adding a customCommandLine to the CLIThis closes #3144,1
[FLINK-5531] [docs] Fix SSL code-block/list formattingThis closes #3140,0
"[FLINK-5521] [runtime] remove unused KvStateRequestSerializer#serializeListAlso make sure that the serialization via the state backends' list statesmatches the deserialization of the KvStateRequestSerializer#deserializeListmethod.So far, it was used this way but not made sure via tests.This closes #3135",3
[FLINK-5519] [build] scala-maven-plugin version all change to 3.2.2This closes #3132,4
[FLINK-5555] Document how to debug event time using watermarks (+ kafka metrics)This closes #3170,1
[FLINK-5557] [docs] Fix link in library methodsThis closes #3163,2
"[hotfix] [docs] Add closing parentheses on ""DataStream API Programming Guide"".This closes #3153.",5
[FLINK-5452] [table] Fix SortITCase which fails under cluster mode.This closes #3095.,0
[FLINK-5520] [table] Disable outer joins with non-equality predicates.This closes #3141.,2
[FLINK-5150] [webui] Store metrics in sessionStorageThis closes #3104.,1
[FLINK-5432] recursively scan nested files in ContinuousFileMonitoringFunctionThis closes #3090.,2
[FLINK-5380] Fix task metrics reuse for single-operator chainsThis closes #3068.,1
[FLINK-5329] Fix metric list being cut offThis closes #3109.,0
[FLINK-5434] Remove unsupported project() transformation from Scala DataStream docs.This closes #3121.,2
[FLINK-5419] Make full TM metrics available through REST APIThis closes #3092.,1
"[FLINK-5424] Improve Restart Strategy Logging- Added toString for FailureRateRestartStrategy (important forJobManager's ""Using restart strategy $restartStrategy"" log message)- Added explanation in log when the restart strategy is responsiblefor preventing job restartThis closes #3079.",2
[FLINK-5417] [docs] Fix config file name in slots_parallelism.svgThis closes #3071.,2
[FLINK-5321] [metrics] LocalFlinkMiniCluster starts JM MetricQSThis closes #2991.,5
[FLINK-4920] Introduce Scala Function GaugeThis closes #3080.,1
[FLINK-5113] Port functions in tests to new CheckpointedFunction IF.This closes #2939.,1
"[hotfix] [doc] Fix several broken ""Linking with Flink"" linksThis closes #3137.",2
[FLINK-5493] Fix String formats in FlinkDistributionOverlay and TaskThis closes #3010.,2
Rebuild web-dashboard,5
[FLINK-5482] [tests] Dedup code in QueryableStateITCase,3
"[FLINK-5482] [queryable state] Re-issue location lookup upon failureAny failing lookup, e.g. in case the job has not been started yet, previouslyremained in the lookup cache and thus future queries did not retry the lookupand failed. This commit changes the lookup caching code so that completedand failed futures are removed from the cache and replaced by new lookups.",1
"[FLINK-5507] [queryable state] Remove list variant of asQueryableStateThe queryable state ""sink"" using ListState stores all incoming dataforever and is never cleaned. Eventually, it will pile up too muchmemory and is thus of limited use.This closes #3129.This closes #3120 (left over).",1
[FLINK-5515] [queryable state] Remove unused getSerializedValue callThis closes #3131.,1
[FLINK-4693] [table] Add session group-windows for batch tablesThis closes #3150.,1
[hotfix] [table] Update documentation about limitations,2
[FLINK-5386] [table] Refactor window clause.- move window() before groupBy()- make window alias mandatory- groupBy() must include window aliasThis closes #3046.,5
"[FLINK-5549] [core] TypeExtractor fails with RuntimeException, but should use GenericTypeInfoThis closes #3154.",5
[FLINK-5561] [runtime] Fix DataInputDeserializer#available()This closes #3171.,5
[FLINK-5468] [savepoints] Improve error message for migrating semi async RocksDB snapshotThis closes #3119.,5
[FLINK-5355] [kinesis] Handle AmazonKinesisException gracefully in Kinesis Streaming ConnectorThis closes #3078.,0
[FLINK-5580] [security] Fix path setting of shipped Kerberos keytabs in YARN modeThis closes #3177.,1
[FLINK-5368] [kafka] Log msg if kafka topic doesn't have any partitionsThis closes #3036.,2
[FLINK-5528] [tests] Reduce query retry delay in QueryableStateITCaseUsing 100ms instead of the 1s previously used does not impose too muchadditional query load and reduces the test suite's duration from 16-20s to13-15s on my machine with the current set of unit tests. Further reductionsin the retry delay do not yield more improvements so far.,1
[FLINK-2662] [optimizer] Fix translation of broadcasted unions.This closes #3083.,0
[FLINK-5585] [jobmanager] Fix NullPointerException in JobManager.updateAccumulators,5
[FLINK-5459] [docs] Add troubleshooting guide for classloading issues,0
[hotfix] Fix type in ProcessFunction documentation,2
[FLINK-5530] [queryable state] Fix race condition in AbstractRocksDBState#getSerializedValueAbstractRocksDBState#getSerializedValue() uses the same key serialisationstream as the ordinary state access methods but is called in parallel duringstate queries thus violating the assumption of only one thread accessing it.This may lead to either wrong results in queries or corrupt data while queriesare executed.This closes #3143.,5
"[FLINK-5576] [queryable state] Check unconsumed bytes in deserializeValueKvStateRequestSerializer#deserializeValue deserializes a given byte array. Thisis used by clients and unit tests and it is fair to assume that these byte arraysrepresent a complete value since we do not offer a method to continue readingfrom the middle of the array anyway. Therefore, we can treat unconsumed bytesas errors, e.g. from a wrong serializer being used, and throw a IOExceptionwith an appropriate failure message.",0
"[FLINK-5576] [queryable state] Improve failure message deserializeListAs in FLINK-5559, wrap the original IOException into a new one with anappropriate error message to better diagnose it.",1
[FLINK-5576] [queryable state] Add tests to for KvStateRequestSerializerTestThese tests ensure that some special cases not properly tested before arehandled correctly in future.This closes #3174.This closes #3139 (left over).,0
"[FLINK-5559] [queryable state] Throw proper IOException deserializeKeyAndNamespaceThis adds the hint that a deserialisation failure probably results from a""mismatch in the key/namespace serializers used by the KvState instance and thisaccess"" to all thrown exceptions.This closes #3172.",1
[FLINK-5454] [docs] Add documentation how to tune streaming applications for large state,2
[hotfix] Cleanups of the AbstractKeyedStateBackend,4
[hotfix] Remove no longer used Generic State classes,1
[hotfix] [streaming api] Non-merging triggers throw UnsupportedOperationException instead of RuntimeException,1
"[FLINK-5590] [runtime] Add proper internal state hierarchyThis introduces an internal state hierarchy that mirrors the external state hierarchy,but gives the runtime access to methods that should not be part of the user facing API,such as:  - setting namespaces  - accessing raw values  - merging namespaces",1
[hotfix] [runtime] Various code cleanups and reductions of warnings in heap state restoring code,2
[hotfix] Remove sysout logging in SavepointMigrationTestBase and fix several warnings.,2
[FLINK-5582] [streaming] Add 'AggregateFunction' and 'AggregatingState'.The AggregateFunction implements a very flexible interface for distributive aggregations.,1
[FLINK-5495] [mesos] Provide executor to ZooKeeperMesosWorkerStoreThe ZooKeeperMesosWorkerStore instantiates a ZooKeeperStateHandleStore which requires anExecutor instance. This executor is now given to the ZooKeeperMesosWorkerStore.This closes #3155.,1
[FLINK-5496] [mesos] Relocate Mesos Protobuf dependency to avoid version conflictsOnly relocate Mesos Protobuf dependency in flink-mesos. This avoids problems with Mesosbecause Flink pulls in Protobuf 2.5.0 via Flakka.This closes #3156.,2
[FLINK-5508] [mesos] Introduce ZooKeeperUtilityFactory to create ZooKeeper utility classesThis commit adds utility classes to abstract the CuratorFramework dependency from ZooKeeperutility classes away. That way it is possible for modules outside of flink-runtime to usethese utility classes without facing the problem of a relocated curator dependency.Address PR commentsThis closes #3157.,1
[hotfix] Make MergingWindowSet resilient to misbehaving window assigners,1
[FLINK-5504] Create mesos-appmaster log file in log directoryThis PR prepends the FLINK_LOG_DIR env variable pointing to Flink's loggingdirectory to the logging file name.This closes #3159.,2
"[FLINK-5492] [log] Log unresolved address when starting an ActorSystemWith the Flakka changes we no longer resolve the given hostname into an IP. Thus,we should henceforth log the unresolved hostname as the address to which theActorSystem binds to.This closes #3161.",5
[FLINK-5503] [log] Print error message in case MesosApplicationMasterRunner failsThis PR adds an error message to the mesos-appmaster.sh script which is printed in casethat the MesosApplicationMasterRunner fails.This closes #3162.,0
[FLINK-5532] [streaming api] Make marker window assigners for aligned window ops non-extendableMakes the TumblingAlignedProcessingTimeWindows and theSlidingAlignedProcessingTimeWindows final so that users cannotextend them.This closes #3180,1
[FLINK-5532] [streaming api] Improve JavaDocs for assigners for Fast Aligned Windows to clarify role,2
[hotfix] [gelly] Fix TriangleListing EdgeOrderThe edge bitmask was swapped in ed09dba.,5
[hotfix] [build] Include flink-gelly-examples in opt/Adds the flink-gelly-examples jar to the opt/ directory of the binaryrelease artifacts. The examples jar is referenced in the online documentation.Corrects the file paths in the Gelly quickstart documentation.,2
[FLINK-5562] [gelly] Driver fixes: Improve parametrization and output formatting.This closes #3187This closes #3188,2
[FLINK-5118] [metrics] Fix inconsistent numBytesIn/Out metrics for network channelsThis closes #3106,1
[FLINK-5450] Fix restore from legacy log messageThis closes #3134,1
[FLINK-5480] [savepoints] Add setUidHash method to DataStream APIThis closes #3117.,5
"[hotfix] [ml] Use the FlinkTestBase ExecutionEnvironment in StochasticOutlierSelectionITSuiteThe FlinkTestBase instantiates a Flink cluster with the right setup (logging, parallelism).This cluster should be used by calling ExecutionEnvironment.getExecutionEnvironment fromwithin the test method. Calling this method in the constructor won't create the rightExecutionEnvironment, because the before method of FlinkTestBase has not been executed.",3
[FLINK-5365] Mesos AppMaster/TaskManager should obey sigterm- use exec in bash script to ensure that signals flow to the javaprocess.This closes #3025.,1
[FLINK-5214] Clean up checkpoint data in case of a failing checkpoint operationAdds exception handling to the stream operators for the snapshotState method. A failingsnapshot operation will trigger the clean up of all so far generated state resources.This will avoid that in case of a failing snapshot operation resources (e.g. files) areleft behind.Add test case for OperatorSnapshotResultAdd StateSnapshotContextSynchronousImplTestAdd AbstractStreamOperator failing snapshot testsThis closes #3178.,3
"[FLINK-5229] [state] Cleanup of operator snapshots if subsequent operator snapshots failThis PR adds operator state cleanup to the StreamTask class. If a stream task contains multiplestream operators, then every operator is checkpointed. In case that a snapshot operation failsall state handles and OperatorSnapshotResults belonging to previous operators have to be freed.Add test cases for failing checkpoint operations in StreamTaskAddress PR commentsThis closes #3179.",1
[FLINK-5618] [docs] Add intial queryable state page,1
[FLINK-5610] [docs] Rename 'Installation and Setup' to 'Project Setup',1
[docs] Group monitoring/debugging docs,2
[FLINK-5609] [docs] Add last built time,1
"[FLINK-5613][query] querying a non-existing key is inconsistent among state backendsQuerying for a non-existing key for a state that has a default value setcurrently results in an UnknownKeyOrNamespace exception when theMemoryStateBackend or FsStateBackend is used but results in the default valueif RocksDBStateBackend is set.This removes the special handling from the RocksDBStateBackend and makes itconsistent with the other two back-ends, i.e. returning null which resultsin the mentioned UnknownKeyOrNamespace exception.This closes #3193",1
[FLINK-5298] TM checks that log file existsThis closes #2974.,2
[hotfix] Remove unused variable in MetricDumpSerializerTest,3
[FLINK-5464] [metrics] Ignore metrics that are null,2
[FLINK-5464] [metrics] Improve MetricDumpSerialization exception handlingThis closes #3128.,1
[FLINK-4523] Allow Kinesis Consumer to start from specific timestamp / Date,5
[FLINK-4523] [kinesis] Add documentation for start position configurationThis closes #2916.,5
[FLINK-5395] [Build System] support locally build distribution by script create_release_files.shThis closes #3049,2
[hotfix] Use own SumReducer in WindowOperatorMigrationTest,3
[hotfix] Use correct ClassLoader in FlinkKafkaConsumerBaseMigrationTest,3
[hotfix] Use correct ClassLoader in ContinuousFileProcessingMigrationTest,3
[hotfix] Use correct ClassLoader in WindowOperatorMigrationTest,3
"[FLINK-4994] Don't Clear Trigger State and Merging Window Set When PurgingBefore, when a Trigger returns TriggerResult.PURGE from any of theon*() methods the WindowOperator will clear all state of that window(window contents, merging window set) and call Trigger.clear() so that theTrigger can clean up its state/timers.This was problematic in some cases. For example, with merging windows (sessionwindows) this means that a late-arriving element will not be put into thesession that was previously built up but will be put into a completely newsession that only contains this one element.The new behaviour is this: * Only clean window contents on PURGE * Register cleanup timer for any window, don't delete this on PURGE * When the cleanup timer fires: clean window state, clean merging window set,call Trigger.clear() to allow it to clean state/timers",4
"[FLINK-4552] Refactor WindowOperator/Trigger TestsBefore, tests for WindowOperator, WindowAssigner, Trigger andWindowFunction were all conflated in WindowOperatorTest. All of thesetest that a certain combination of a Trigger, WindowAssigner andWindowFunction produce the expected output.This change modularizes these tests and spreads them out across multiplefiles. For example, one per trigger/window assigner.The new WindowOperatorContractTest verifies that the interaction betweenWindowOperator and the various other parts works as expected, that thecorrect methods on Trigger and WindowFunction are called at the expectedtime and that snapshotting, timers, cleanup etc. work correctly. Thesetests also verify that the different state types and WindowFunctionswork correctly.For trigger tests this introduces TriggerTestHarness. This can be usedto inject elements into Triggers they fire at the correct times. Theactual output of the WindowFunction is not important for these tests.The new tests also make sure that triggers correctly clean up state andtimers.WindowAssigner tests verify the behaviour of window assigners inisolation.  They also test, for example, whether offset parameter oftime-based windows work correctly.We keep the old WindowOperatorTest because it still provides some levelof coverage and doesn't take long to run.",1
[FLINK-5375] [doc] Fix Watermark SemanticsThis closes #3185.,0
[docs] Document reporter plurality,2
[FLINK-5451] Extend JMX reporter section,2
[docs] Document metrics visualization in web-frontend,2
[FLINK-5446] [docs] Rework system-metrics section,5
[FLINK-4396] [docs] Document /opt reporter jarsThis closes #3116.,2
[FLINK-5404] [docs] Consolidate and update AWS setupThis closes #3054.,1
[FLINK-5617] Change reference version for API stability checks to 1.1.4,4
[FLINK-5617] Mark some methods as PublicEvolving or InternalThis closes #3195,2
"[FLINK-5615] [queryable state] Execute QueryableStateITCase for all backends[FLINK-5615][query] improve testQueryableStateWithTaskManagerFailure test durationThis is based on the following points:* slow down QueryableStateITCase#TestKeyRangeSource for the rest of the  program to make more progress (we do not need a full-speed source here!)* reduce the checkpointing interval* reduce the amount of progress before starting our own evaluation* reduce the number of checkpoints to wait for before killing a TM* reduce the thread waiting time when asking how many checkpoints existNote that by slowing down QueryableStateITCase#TestKeyRangeSource, the othertests should only be affected positively, too, since they also did not reallyneed a full-speed source and thus have more CPU cycles for their own tasks.[FLINK-5615][query] speed up some more tests in QueryableStateITCaseThis is based on reducing the number of keys the source generates. We do notreally need 1024 different keys for the tests - go with 256 now.[FLINK-5615][query] execute the QueryableStateITCase for all state back-ends[FLINK-5615][query] nicer test case abstractionThis closes #3194.",3
[FLINK-5395][release script] Fix version commit and maven upload,0
[FLINK-5473] Limit max parallelism to 1 for non-parallel operators[FLINK-5473] Better default behaviours for unspecified maximum parallelismThis closes #3182.,1
"[FLINK-5247] [streaming api] Fix checks for allowed lateness in windowed streamsAlso, fix outdated documentation.",2
[hotfix] [streaming api] Minor cleanup in WindowedStream and AllWindowedStream,4
[FLINK-4905] [kafka 08 consumer] Suppress offset committing failures when fetcher is shutting downThis closes #3035,0
"[FLINK-4917] [streaming api] Deprecate ""CheckpointedAsynchronously"" interfaceThis closes #3087",2
[hotfix] [streaming api] Improve JavaDocs of the user-fcing checkpointing and state interfaces,1
[FLINK-5577] [yarn] Fix application id growth by reusing Yarn ClientThis closes #3173,1
[FLINK-5620] Fix unstable ContinuousFileProcessingTest,3
[FLINK-5639] [rabbitmq connector] Add a note about MPL 1.1 license of Maven dependency,1
[license] Update license with 'angular-drag-and-drop-lists' dependency,4
[FLINK-5492] Fix TaskManager log entry,1
[FLINK-5643] Fix NPE in StateUtilIntroduces a null check to deal with state futures which have a null value.This closes #3212.,0
"[FLINK-5638] [asyncIO] Fix deadlock when closing two chained AsyncWaitOperatorsThis PR addresses the problem by changing the Emitter's behaviour to first output theelement before removing it from the StreamElementQueue. That way the close method waitsuntil also the Emitter has outputted the last completed element. Additionally, thestopResources method now frees the checkpoint lock in order to let the emitter threadreact to the interrupt signal.This closes #3209.",1
[FLINK-5626] Improved resource deallocation in RocksDBKeyedStateBackend,5
[FLINK-5602] Introduce artifical namespace serializer for migrationThis closes #3200.This closes #3198.,2
[FLINK-5637] Avoid warning while parsing YAML configuration files,2
[FLINK-5632] [streaming api] Fix typo in StreamGraph variable nameThis closes #3203,2
[FLINK-5630] [streaming api] Followups to the AggregateFunction  - Add a RichAggregateFunction  - Document generic type parameters  - Allowing different input/output types for the cases where an additional window apply function is specified  - Adding the aggregate() methods to the Scala API  - Adding the window translation tests,3
[hotfix] Fix testing setup of StreamingOperatorsITCase via ScalaStreamingMultipleProgramsTestBase,3
[FLINK-5224] [table] Improve UDTF: emit rows directly instead of buffering themThis closes #3118.,1
"[FLINK-5666] [tests] Add blob server clean up testsPreviously, deleting in HA mode was only tested with a local file system.This verifies that the delete still works on HDFS.This closes #3222.",1
"[FLINK-5049] [queryable state] Remove TM failure testThe test was flakey, because the expected behaviour is actuallynot possible with the current state of queryable state, whichallows uncommitted reads.",1
[FLINK-5529] [docs] Improve / extends windowing documentation,2
[FLINK-4752] [docs] Improve window assigner documentation.,2
[FLINK-5529] Update Window Documentation Figures,2
[FLINK-5529] Fix Trailing Whitespace in Window Documentation,2
[hotfix] [tests] Speed up StreamCheckpointNotifierITCase,3
[FLINK-5612] [code] Make GlobPathFilter serializable,1
"[FLINK-5660] [state] Fix state cleanup of PendingCheckpointWhen calling PendingCheckpoint.dispose, the state contained of a pending checkpointis discarded by an asynchronous task. Since this task accesses the taskStates fieldwe must not clear it in PendingCheckpoint.dispose. Instead we will clear it onceall state objects have been discarded from within the asynchronous task.This closes #3220.",4
"[FLINK-5670] Properly clean up local RocksDB directoriesWe have to change the instance path to not include too many nesteddirectories, otherwise the Keyed backend cannot properly clean up thewhole directory hierarchy.",4
[FLINK-5667] [state] Synchronize asynchronous checkpointing and close operationThis PR synchronizes asynchronous checkpointing and close operations of a StreamTask.The synchronization prevents that an acknowledged checkpoint gets discarded and thata discarded checkpoint gets acknowledged. It achieves this by introducing an atomicstate variable which guards against late close and acknowledge operations.This closes #3226.,1
[FLINK-5663] [runtime] Prevent leaking SafetyNetCloseableRegistry through InheritableThreadLocalThis closes #3229,1
[FLINK-5678] [table] Fix User-defined Functions do not support all types of parametersThis closes #3233.,2
[FLINK-5628] [webfrontend] Fix serializability of checkpoint stats trackerThis closes #3215.,0
[FLINK-5681] [runtime] Make ReaperThread for SafetyNetCloseableRegistry a singletonThis closes #3230,1
[FLINK-5456] Resurrect and update parts of the state intro documentation,2
[hotfix][docs] Fix broken redirect and liquid syntax problem,0
"[FLINK-5608] [webfrontend] Cancel button stays visible in narrow windows- Most importantly, the Cancel and Stop buttons have been changed tofloat right, and will only wrap downward if pushed out by the job name- Also combined the job name and job id into a single horizontalelement, reducing the overall horizontal space taken by the mainnavbar components in the job view, making the main navbar componentsless likely to wrap downward and be overlapped by the secondary navbar.- Moved global job status counts to be right-most so it wraps beforethe job-specific information, and it's now hidden on medium width(992px - 1900px) to save horizontal space- Compiled code has been rebuilt",5
[FLINK-5608] [webfrontend] Rebuild web frontendThis closes #3189.,2
[FLINK-4820] [core] Make Flink code independent of log4j 1.x,2
[FLINK-5684] [web frontend] Add MacOS section to README.mdThis closes #3234,2
[FLINK-5563] [gelly] Add density to vertex metricsThis closes #3167,1
[FLINK-5581] [doc] Improve user accessibility for Kerberos-related documentationThis closes #3181,2
[hotfix] [rat] Add exclusion for rolling-sink snapshotThis closes #3208,1
[FLINK-5644] [runtime] Remove metric: Task#lastCheckpointSizeThis closes #3214,4
[FLINK-5455] [docs] Add documentation for upgrading applications.This closes #3217.,2
[FLINK-5558] [gelly] Replace TriangleCount with a Count analyticTriangleCount can be replaced by a generic Count analytic for DataSet.The analytics currently using TriangleCount can simply useTriangleListing and Count.Gelly includes both directed and undirected versions of TriangleListingand therefore two versions of TriangleCount which will be replaced by asingle Count analytic which can be reused elsewhere.This closes #3169,1
[hotfix] [doc] Fix broken externalized checkpoint reference link,2
[FLINK-5502] [docs] Add migration guide in docs.,2
[FLINK-5474] [docs] Extend DC/OS documentationState where you can find out the job manager's address and how to install the DC/OS CLI.This closes #3237.,1
[FLINK-5494] [docs] Add more details to the  Mesos documentationThis closes #3236.,2
[FLINK-5700] [docs] Document akka.client.timeout configuration parameter,2
[docs] Fix Markdown code example in REST API,0
[docs] Update version to 1.3-SNAPSHOT,5
[FLINK-5499] [JobManager] Reuse the resource location of prior execution attempt in allocating slotThis closes #3125,1
[hotfix] Minor code cleanups in the ExecutionGraph's Execution,4
[hotfix] [jobmanager] Reduce complexits when archiving ExecutionVertexThis fixes the inefficiency where the archiving operation iterated over the entireevicted history of prior execution attempts when converting them toarchived executions.,0
[hotfix] [jobmanager] Cleanups in the ExecutionGraph  - Making fields final where possible  - Making fields volatile where needed or advisable  - Remove some dead code/functionality,1
[FLINK-5499] [JobManager] Make the location preferences combined by state and inputs.Reusing the prior location (for state locality) takes precedence over input locality.,1
[hotfix] [tests] Increase timeout for AkkaRpcActorTest to mitigate occasional CI test timeouts,3
[FLINK-5708] [docs] Remove duplicate configuration optionThis closes #3261,5
[FLINK-2211] [ml] Generalize ALS APIAllows the user and items to be of type LongThis closes #3265.,1
"[FLINK-5652] [asyncIO] Cancel timers when completing a StreamRecordQueueEntryWhenever a StreamRecordQueueEntry has been completed we no longer need the registered timeout.Therefore, we have to cancel the corresponding ScheduledFuture so that the system knows thatit can remove the associated TriggerTask. This is important since the TriggerTask contains areference on the StreamRecordQueueEntry. Consequently, such a task will prevent theStreamRecordQueueEntry from being garbage collected.This closes #3264.",1
[FLINK-5709] Add Max Parallelism to Parallel Execution Doc,2
[FLINK-5693] [gelly] ChecksumHashCode DataSetAnalyticAdds a DataSetAnalytic that checksums and counts elements from aDataSet. This allows DataSetUtils.checksumHashCode to be deprecated.This closes #3244,5
[FLINK-5694] [gelly] Collect DataSetAnalyticAdds a DataSetAnalytic that accumulates elements and returns elementsusing a List. This mirrors the implementation of DataSet.collect() butusing the analytic execution workflow.This closes #3245,1
[docs][state] add missing Java syntax highlighting to documentation,2
[FLINK-5618] [docs] Add queryable state (user) documentationThis closes #3275.,2
[docs] Add production readiness checklistThis closes #3259.,1
[docs] Add migration documentationThis closes #3258.,2
[docs] Fix typo in code snippet* fix typo in code snippet CheckpoingConfig -> CheckpointConfigThis closes #3254.,5
[FLINK-5721] Add FoldingState to State Documentation,2
[FLINK-5575] [docs] Rework outdated release warningThis closes #3242.,2
[FLINK-5618][docs] createSerializer must actually get a non-null ExecutionConfigThis closes #3279.,5
[FLINK-5680] [docs] Document env.ssh.optsDocument env.ssh.opts in setup/config.html.This closes #3247,5
[FLINK-2883] [docs] Add documentation to forbid key-modifying ReduceFunctionThis closes #3256,1
"[FLINK-5699] [savepoints] Check target dir when cancelling with savepointProblem: when cancelling a job with a savepoint and no savepoint directoryis configured, triggering the savepoint fails with an NPE. This is thenreturned to the user as the root cause.Solution: Instead of simply forwarding the argument (which is possiblynull), we check it for null and return a IllegalStateException witha meaningful message.This closes #3263.",1
[FLINK-4988] Elasticsearch 5.x support,1
[FLINK-4988] [elasticsearch] Restructure Elasticsearch connectorsThis closes #3112.,2
[FLINK-5702] [doc] At-least-once configuration info for FlinkKafkaProducerThis closes #3282.,2
[FLINK-5727] [table] Unify API of batch and stream TableEnvironments.This closes #3281.,2
[hotfix] [docs] Fix error in docs for zipping elements.This closes #3280.,2
"[FLINK-5153] Support YARN application tagsAdds a new config option `yarn.tags`, a comma-separated list of stringspassed to YARN as application tags.",4
[FLINK-5153] Add test for YARN application tags,3
[FLINK-5748] [jobmanager] Make the 'future executor' a ScheduledExecutorServiceThis closes #3289,1
[FLINK-4912] Introduce RECONCILIATING state in ExecutionGraph and Execution for JobManager failure recoveryThis closes #3113,0
[FLINK-5132] [core] Introduce the ResourceSpec to define required resource factors in APIThis closes #3114,1
[FLINK-5517] Upgrade hbase version to 1.3.0This closes #3235.,2
[hotfix] [doc] Fix broken Flink on Windows link,2
"[FLINK-5017] [streaming] Introduce StreamStatus to facilitate idle sourcesThis commit is the first part of making idle streaming sources in Flinkpossible. It introduces a new element, StreamStatus, that flows withother records in streams. StreamStatus elements are generated at thesources, and affect how operators advance their watermarks with thepresence of idle sources.Prior to this commit, when advancing watermarks at downstream operators,the new min watermark is found by simply determining if the minwatermark across all input channels has advanced. This resulted inwatermark-stalling downstream operators when there are idle sources.With this change, operators can now mark input channels to be idle, andignore them when advancing their watermark.This commit also includes refactoring of previous watermark forwardinglogic into a single class, StatusWatermarkValve. OneInputStreamTasks,TwoInputStreamTasks, and AbstractStreamOperator use valves to help themdetermine how watermarks and stream statuses are forwarded.",1
[FLINK-5759] [jobmanager] Set UncaughtExceptionHandlers for JobManager's Future and I/O thread poolsThis closes #3290,0
[FLINK-5766] [distributed coordination] Unify the handling of NoResourceAvailableException,2
[FLINK-5718] [core] TaskManagers exit the JVM on fatal exceptions.This closes #3276,2
[hotfix] [dist] Add notice about memory pre-allocation to default 'flink-conf.yaml',5
[FLINK-5415] Harden ContinuousFileProcessingTest- Use TemporaryFolder @ClassRule instead of manually managing HDFS basedir.- Place files for each test in own sub-directory- Harden completeness condition in testFunctionRestore(),3
[hotfix] [core] Add tests for Futures applying multiple functions,1
[hotfix] [core] Improve FlinkFuture synchronous actions by avoiding creation of ExecutionContext,1
[FLINK-5712] [config] update several deprecated configuration optionsThis closes #3267.,5
"[FLINK-1979] [ml] Add logistic loss, hinge loss and regularization penalties for optimizationUse parameter to set regularization penalty in gradient descent solverUpdate regularization penalty docsThis closes #1985.",2
"[hotfix] [tests] Correct EitherTypeInfoTest to respect equals-hashcode contractequality implies equal hash codes but not vice versa. Thus, if two objects are not equal,then we cannot assume that their hash codes differ as well.EitherTypeInfoTest#testEitherTypeInequality, however, did exactly that.",5
[FLINK-5662] [table] Rework internal type handling of Table APIThis closes #3271.,1
[FLINK-5729] [examples] Add hostname option to SocketWindowWordCount examplesThis closes #3283,1
[FLINK-5631] [yarn] Support downloading additional jars from non-HDFS paths.This closes #3202,1
[FLINK-5406] [table] Add normalization phase for predicate logical plan rewritingThis closes #3101.,2
[FLINK-5690][docs] Add note on shading to best practices guideThis closes #3300,1
[FLINK-5566] [table] Add containers for table and column statistics.This closes #3196.,1
[FLINK-5762] [runtime] Protect initializeState() and open() by the same lockThis closes #3291,5
"[FLINK-5553] [network] keep the original throwable in PartitionRequestClientHandlerThis way, when checking for a previous error in any input channel, we can throwa meaningful exception instead of the inspecificIllegalStateException(""There has been an error in the channel."") before.Note that the original throwable (from an existing channel) may or may not(!)have been printed by the InputGate yet. Any new input channel, however, did notget the Throwable and must fail through the (now enhanced) fallback mechanism.This closes #3299",0
[FLINK-5788] [docs] Improve documentation of FileSystem and specify the data persistence contract.This closes #3301,5
[FLINK-2908] [web frontend] Redraw web plan when browser resizedRedraw the job plan visual graph when the browser width is increased.This closes #3251,1
[FLINK-2168] Add HBaseTableSource for batch tables.This closes #3149.,1
[FLINK-2168] Refactor HBaseTableSource and extend tests.,3
[FLINK-5745] [runtime] Extract ExecutorThreadFactory#FatalExitExceptionHandlerMake it a top-level class so that it can be re-used.,1
[FLINK-5745] [network] Set uncaught exception handler for Netty threadsThis sets a JVM-terminating handler that logs errors from uncaught exceptionsand terminates the process so that critical exceptions are not accidentallylost and leave the system running in an inconsistent state.This closes #3293.,1
[FLINK-5796] [docs] Fix broken linksThis closes #3308.,2
[FLINK-5790] [core] Use list types when ListStateDescriptor extends StateDescriptorThis closes #3305,1
[FLINK-5790] [core] Followups and tests for the StateDescriptor changes,4
[FLINK-5807] [docs] Improved wording for home pageThis closes #3320.,1
[FLINK-5806] [runtime] Fix TaskExecutionState toStringThis closes #3319.,0
[hotfix] [streaming] Properly mark non-transported fields as transient in AbstractStreamOperator,1
"[FLINK-5800] [checkpointing] Create CheckpointSteamFactory only once per operatorPreviously, the factory was created once per checkpoint, and its repeated initialization logic(like ensuring existence of base paths) caused heavy load on some filesystems at very large scale.This closes #3312",5
[FLINK-5714] [table] Use a builder pattern for creating CsvTableSourceThis closes #3273.,1
[FLINK-4280] [kafka] Explicit start position configuration for FlinkKafkaConsumerThis closes #2509.,2
[FLINK-5793] [runtime] fix running slot may not be add to AllocatedMap in SlotPool bugThis closes #3306,0
[FLINK-5805] [docs] Improvements to docs for ProcessFunctionThis closes #3317,1
[FLINK-5771] [core] Fix multi-char delimiter detection in DelimitedInputFormat.- Add a test case to validate correct delimiter detection.- Remove a couple of try-catch blocks from existing tests.This closes #3316.,3
[FLINK-5567] [table] Introduce and migrate current table statistics to FlinkStatistic.This closes #3197.,2
[FLINK-5751] [docs] Fix some broken linksThis closes #3329.,2
"[hotfix] [tests] Stabilize FastFailuresITCaseThe test triggers 200 immediate failures and recoveries. The restart strategy allowed 200 restarts.It may happen that another failure occurs as during the execution, in which case the restart attempts are notsufficient.",0
"[FLINK-5814] [build] Fix packaging flink-dist in unclean source directoryIf ""<flink-dir>/build-target"" already existed, running 'mvn package' forflink-dist would create a symbolic link inside ""<flink-dir>/build-target""instead of replacing that symlink. This commit fixes this behaviour of 'ln -sf'by adding the --no-dereference parameter.This closes #3331",2
"[FLINK-5773] Use akka.actor.Status.Failure class to send failures via AskSupportAkka's AskSupport trait requires that failures are wrapped in a akka.actor.Status.Failureto be recognized. Internally the trait will unwrap the failure and wrap it in ascala.util.Failure instance. However, it does not recognize the scala Failure when givento the AskSupport trait. As a consequence it would wrap scala.util.Failure in ascala.util.Success instance.This closes #3321.",0
[FLINK-5811] [tests] Harden YarnClusterDescriptorTestAdd fail call after method which is supposed to fail. Remove stack trace printingto stdout.This closes #3326.,4
[FLINK-5705] [WebMonitor] WebMonitor request/response use UTF-8 explicitlyThis closes #3257,1
[FLINK-5624] [table] Add SQL support for tumbling windows on streaming tables.This closes #3252.,1
[FLINK-5751] [docs] Add link check scriptThis closes #3332.,2
"[FLINK-5616] [tests] Harden YarnIntraNonHaMasterServicesTest.testClosingReportsToLeaderPrevent the race condition between shutting down the leader election service and thecontender becoming the leader by waiting on a LeaderRetrievalListener. The problemwas that if the service has been shut down before the contender has become the leader,then the contender would not be notified about the shut down via the handleError method.At correct waiting behaviour using Mockito's verify statementThis closes #3327.",1
[FLINK-5825] [webui] Fix image loading in YARNA absolute URL to an image prevents this image in case ofrunning with a YARN proxy. This makes the URL relative.This closes #3337.,1
[FLINK-5825] [webui] Rebuild web frontend,2
[hotfix] Fix trailing whitespace in WindowedStream.java,0
[FLINK-4997] [streaming] Introduce ProcessWindowFunction,1
[FLINK-4997] [streaming] Add ProcessWindowFunction to Scala API,1
[FLINK-4997] Add doc for ProcessWindowFunction,1
[FLINK-4997] Add ProcessWindowFunction support for .aggregate(),1
[FLINK-5237] Consolidate and harmonize Window Translation Tests,3
[FLINK-5751] [docs] Fix tab in check_links script,2
[FLINK-5837][docs] improving readability of the queryable state docsThis closes #3350.,2
[FLINK-5828] [distributed runtime] Fix initialization of Blob storage directoriesFlip the logic (check existence and create directory) to resolve currency problemThis closes #3342,0
[hotfix] [docs] Updated DC/OS setup instructions.This closes #3349,1
[FLINK-5129] [distributed runtime] BlobCache to directly accesses Blobs from distrinbuted file system if possibleThis closes #3084,5
[FLINK-5497] [tests] Remove duplicated tests for hash tablesThis closes #3089,3
[FLINK-5522] [storm compatibility] Move Storm LocalCluster based test to a separate classThis fixes the problem that the Storm LocalCluster can't run with powermockThis closes #3138,1
[FLINK-5817] [tests] Use TemporaryFold to create temp files and folds for testThis closes #3341,3
"[FLINK-5817] [test] (followup) Fix temporary folder and temp file path generationThis makes sure the TemporaryFolder rule is already evaluated by the timethe temp files are generated.This also injects a random parent directory to ensure that even for fix directory/filenames, the absolute path is randomized.",2
[FLINK-5640] [build] Configure the explicit Unit Test file suffixThis closes #3211,0
"[FLINK-5669] [contrib] Change DataStreamUtils to use the loopback address (127.0.0.1) with local environments.Using loopback rather than the ""local address"" allows tests to run insituations where the local machine's hostname may not be resolvable in DNS(because DNS is unreacable or the hostname is not found) or the hostname doesresolve, but not to an IP address that is reachable.This closes #3223",1
[FLINK-5739] [client] Fix NullPointerException in CliFrontendThis closes #3292,0
[FLINK-5277] [tests] Add unit tests for ResultPartition#add() in case of failuresThis verifies that the given network buffer is recycled as expected and thatno notifiers are called upon failures to add a buffer.This closes #3309,1
"[FLINK-4813] [test-utils] Make the hadoop-minikdc dependency optionalWith this change, any project using flink-test-utils which also requiresSecureTestEnvironment must add a dependency to hadoop-minikdc itself, e.g. inpom.xml:   ...   <dependencies>     <dependency>       <groupId>org.apache.hadoop</groupId>       <artifactId>hadoop-minikdc</artifactId>       <version>${minikdc.version}</version>       <scope>compile</scope>     </dependency>   ...   </dependencies>   ...   <build>     <plugins>       <!--         https://issues.apache.org/jira/browse/DIRSHARED-134         Required to pull the Mini-KDC transitive dependency       -->       <plugin>       <groupId>org.apache.felix</groupId>       <artifactId>maven-bundle-plugin</artifactId>       <version>3.0.1</version>       <inherited>true</inherited>       <extensions>true</extensions>     </plugin>   ...This closes #3322",5
[hotfix] [core] Add missing @PublicEvolving annotations to classes in flink-core.,2
[hotfix] [core] Add missing @Internal annotations to classes in flink-core.,2
[hotfix] [tests] Use random actor names in JobManagerHARecoveryTest to avoid name collisions,3
[FLINK-5812] [core] Cleanups in FileSystem (round 1)  - This makes the FileSystem use the 'WriteMode' (otherwise it was an unused enumeration)  - Extends comments  - Deprecate the method that controls the replication factor and block size,1
[FLINK-5812] [core] Cleanups in FileSystem (round 2)Move the FileSystem safety net to a separate class.,5
"[FLINK-5747] [distributed coordination] Eager scheduling allocates slots and deploys tasks in bulkThat way, strictly topological deployment can be guaranteed.Also, many quick deploy/not-enough-resources/fail/recover cycles can beavoided in the cases where resources need some time to appear.This closes #3295",0
"[FLINK-5749] [build] Unset HADOOP_HOME and HADOOP_CONF_DIR variables for testsThis unsets the HADOOP_HOME and HADOOP_CONF_DIR envirobment variables for tests, to avoidthat the tests pick those variable up from build servers and produce unexpected testresults.This closes #3288",3
[FLINK-5723] [web frontend] Use 'Used' instead of 'Initial' in TaskManager memory consumption viewThis closes #3275,5
"[FLINK-5842] [docs] Fix ES5 ""since"" versionThis closes #3355.",0
[FLINK-5571] [table] add open and close methods for UserDefinedFunctionThis closes #3176.,1
[hotfix] [doc] Document that the `AsyncCollector` can only be completed once,2
"[hotfix] [jobmanager] Minor code cleanups in JobGraph and CheckpointCoordinatorThis makes the exception that can occur during serialization of the ExecutionConfig explicit,and adds some comments to JobGraph.",1
[hotfix] [core] Deprecate unused and redundant config parameter 'flink.base.dir.path',2
[FLINK-5074] [runtime] Add a ZooKeeper-based RunningJobRegistryThis closes #2903,1
"[FLINK-4770] [core] Introduce 'CoreOptions'The CoreOptions should hold all essential configuration values that are not specific toJobManager, TaskManager or any feature area, like HighAvailability or Security.Examples for that are  - default java options  - default parallelism  - default state backend",5
"[FLINK-5821] [state backends] Rename the 'StateBackend' to 'StateBinder' and create root StateBackend interfaceStateBinder more correctly reflects what the interface does and clears up the name 'StateBackend'The 'StateBackend' interface is now the root of the State Backend hierarchy (previously that was 'AbstractStateBackend')This also extends a lot the JavaDocs of the core state classes, like StateBackend and StateObject",2
[hotfix] [tests] Fix minor JavaDoc link errors,0
[FLINK-3163] [scripts] Configure Flink for NUMA systemsStart a TaskManager on each NUMA node on each worker when the newconfiguration option 'taskmanager.compute.numa' is enabled.This closes #3249,0
[FLINK-5795] [table] Improve UDF&UDTF to support constructor with parameterthis closes #3330,2
[FLINK-5877] [docs] Fix Async I/O Scala snippetThis closes #3383,0
[FLINK-5763] [checkpoints] Acknowledge with explicit ID and CheckpointMetricsInstead of acknowledging checkpoints with the CheckpointMetaData makethe acknowledgement explicit by ID and CheckpointMetrics. The rest isnot needed.,1
[FLINK-5763] [checkpoints] Move CheckpointMetrics out of CheckpointMetaData,5
[FLINK-5763] [checkpoints] Add isSavepoint() to CheckpointPropertiesThis closes #3345,1
[FLINK-5876] [docs] Mention Scala extensions in queryable state docs,2
[FLINK-5836] [flip6] Fix race condition between offer slot and submit taskStreamline test caseThis closes #3371.,1
[FLINK-5701] [kafka] FlinkKafkaProducer should check asyncException on checkpointsThis closes #3278.,2
[FLINK-5716] [streaming] Make StreamSourceContexts aware of source idlenessThis closes #3347.,1
FLINK-5731 Spilt up tests into three disjoint groupsThis closes #3344,3
[FLINK-5894] [docs] Fix misleading HA docsThis closes #3401.,2
[FLINK-5716] Add StreamStatusMaintainer mock in StreamSourceOperatorTest,3
[hotfix] [kafka] Indent Kafka010FetcherTest with tabs instead of spaces,3
[FLINK-4856] Add MapState for keyed state,1
[hotfix] [docs] Fix JavaDoc errors in 'flink-streaming-java',2
"[FLINK-5763] [checkpoints] Add CheckpointOptionsAdds `CheckpointOptions` to the triggered checkpoint messages (coordinatorto barrier injecting tasks) and barriers (flowing inline with the data:```javapublic class CheckpointOptions {  // Type of checkpoint  // => FULL_CHECKPOINT  // => SAVEPOINT  @NonNull  CheckpointType getCheckpointType();  // Custom target location. This is a String, because for future  // backends it can be a logical location like a DB table.  @Nullable  String getTargetLocation();}```This class would be the place to define more options for performing thecheckpoints (for example for incremental checkpoints).These options are forwarded via the `StreamTask` to the `StreamOperator`s and`Snapshotable` backends. The `AbstractStreamOperator` checks the options andeither i) forwards the shared per operator `CheckpointStreamFactory` (as ofFor this, the state backends provide the following new method:```CheckpointStreamFactory createSavepointStreamFactory(JobID, String, String);```The `MemoryStateBackend` returns the regular stream factory and the`FsStateBackend` returns a `FsSavepointStreamFactory`, which writes allcheckpoint streams to a single directory (instead of the regular sub foldersper checkpoint).We end up with the following directory layout for savepoints:```+---------------------------+| :root_savepoint_directory | (custom per savepoint or configured default via `state.savepoints.dir`)+---------------------------+  | +---------------------------------------+  +-| savepoint-:jobId(0, 6)-:random_suffix | (one directory per savepoint)    +---------------------------------------+       |       +- _metadata (one per savepoint)       +- :uuid (one data file per StreamTask)       +- ...       +- :uuid```",2
[FLINK-5763] [checkpoints] Followup on adding CheckpointOptions  - Add a test that validates the checkpoint type ordinals are not changed  - Change target location writing from 'writeUtf' to 'StringUtils.write'.  - Pull out the coding charset as a constant in 'EventSerializer'  - Simplify the directory creation in 'SavepointStore',1
[FLINK-5887] [checkpointing] Make CheckpointBarrier type immutable.,1
[hotfix] [checkpoints] Remove equals()/hashCode() from CompletedCheckpoint as semantic equality is not well defined.,4
[FLINK-5767] [table] Add interface for user-defined aggregate functions and built-in aggregate functions.This closes #3354.,1
"[FLINK-5845] [cep] Unify keyed and non-keyed operators.Now all cep operators are keyed, and for the non-keyedusecases, we key on a dummy key and use the keyed operator.",1
[FLINK-5895] [runtime] Decrease logging aggressiveness of FileSystemSafetyNet,5
[hotfix] [tests] Remove sysout logging in KvStateLocationTestThis helps keeping test log output free from clutter.,2
[FLINK-5854] [core] Add base Flink Exception classesThis closes #3368,2
[FLINK-5885] [docs] Fix Cassandra Scala snippetThis closes #3400,0
[FLINK-5743] Mark WindowedStream.aggregate() methods as PublicEvolving,2
"[FLINK-5798] [rpc] Let the RpcService provide a ScheduledExecutorServiceThis PR adds the getScheduledExecutorService method to the RpcService interface. Sohenceforth all RpcService implementations have to provide a ScheduledExecutorServiceimplementation.Currently, we only support the AkkaRpcService. The AkkaRpcService returns aScheduledExecutorService proxy which forwards the schedule calls to the ActorSystem'sinternal scheduler.Introduce ScheduledExecutor interface to hide service methods from the ScheduledExecutorServiceThis closes #3310.",5
"[FLINK-5799] [rpc] Let RpcService.scheduleRunnable return a ScheduledFutureThe returned ScheduledFuture instance allows to cancel a scheduled runnable and obtainthe delay until the runnable will be executed. Furthermore, it allows to wait on thecompletion of the runnable.This closes #3311.",1
"[FLINK-5122] [elasticsearch] Retry temporary Elasticsearch request errors.Covered exceptions are: Timeouts, No Master, UnavailableShardsException, bulk queue on node full",0
[FLINK-5353] [elasticsearch] User-provided failure handler for ElasticsearchSinkThis commit fixes both FLINK-5353 and FLINK-5122. It allows users to implement afailure handler to control how failed action requests are dealt with.The commit also includes general improvements to FLINK-5122:1. Use the built-in backoff functionality in the Elasticsearch BulkProcessor (notavailable for Elasticsearch 1.x)2. Migrate the `checkErrorAndRetryBulk` functionality to the new failure handler,0
[FLINK-5487] [elasticsearch] At-least-once Elasticsearch SinkThis closes #3358.,2
[hotfix] [core] Changing PublicEvolving anntoation of Archiveable to Internal.,4
[FLINK-5710] [table] Add proctime() function to indicate processing time in Stream SQL.This closes #3370.This closes #3302. // duplicate of #3370,1
[FLINK-5899] [table] Fix translation of batch event-time tumbling windows with non-partial aggregation functions.This closes #3405.,1
[FLINK-5896][docs] improve readability of event time docsThis closes #3403.,2
"[FLINK-5772] [elasticsearch] Allow Elasticsearch 1.x tests to rerun on failureThis is allowed because Elasticsearch 1.x has a potential deadlock whencreating indices. Since this flakiness rarely happens, this commitallows rerunning the Elasticsearch 1.x tests to try to mitigate thisproblem instead of just failing them.This closes #3410.",0
[FLINK-5849] [kafka] Move FlinkKafkaConsumer start offset determination to open()This closes #3378.,1
[hotfix] [kafka] Cleanup star / unused imports in all Flink Kafka tests,3
[FLINK-3475] [table] Add support for DISTINCT aggregates in SQL queries.This closes #3111.,1
[FLINK-5907] [java] Fix handling of trailing empty fields in CsvInputFormat.This closes #3417.,0
[FLINK-5871] [cep] Enforce uniqueness of pattern names in CEP.,1
[FLINK-3903] [docs] Add Homebrew installation docsThis closes #3393.,2
[FLINK-5157] [streaming] Introduce ProcessAllWindowFunction,1
"[FLINK-5420] [cep] Make the CEP operators rescalableIntroduces the KeyRegistry in the TimeServiceHandlerwhich allows to specify a callback and register keysfor which we want this callback to be invoked on eachwatermark.Given this service, now the CEP operator has onlykeyed state, and the non-keyed one (keys) arehandled by the KeyRegistry.",1
[hotfix] [runtime] Reduce the gazillion deprecation warnings from the backwards-compatible savepoint path,2
[FLINK-5501] [runtime] Extend RunningJobRegistry to job status created/running/doneThis closes #3385,1
[FLINK-5501] [runtime] Followups and improvements to RunningJobsRegistryThis commit changes the following:  - Remove the unsafe 'isJobRunning()' method.  - Exctract duplicate code into utility functions  - Simplify the NonHaRegistry by using a map rather than two sets  - Improve exception handling / error messages for the ZooKeeper-based registry  - Slight improvement of error handling in the JobManagerRunner  - Compare enums with '==' (better null-pointer safety)  - Correct 'expected' and 'actual' parameters in 'assertEquals'  - Forward tests also to the HDFS file based registry test,3
[FLINK-5501] [runtime] Make config key for ZooKeeper path for running registry consistent with other keys,1
"[FLINK-5929] [tests] Fix SavepointITCase instabilityWhen shutting down the testing cluster it can happen that checkpointfiles lingered around (checkpoints independent of the savepoint).This commit deactives checkpointing for the test and uses count downlatches to track progress, which also reduces the test time.This closes #3427",3
"[FLINK-5133] [core] Add new setResource API for DataStream and DataSetThis introduces the internals, but does not yet make it public in the API.This closes #3303",1
[FLINK-5133] [core] Followups for ResourceSpec on DataSet / DataStream API  - Correct some use of Preconditions.checkNotNull  - Make 'resources' plural in all cases  - Add comments to why the setters are commented out  - Add @PublicEvolving annotations  - Make the Scala API completeness test match Scala-esk versions of Java Getters,1
"[FLINK-5897] [checkpoints] Make checkpoint externalization not depend strictly on FileSystemsThat is the first step towards checkpoints that can be externalized to other stores as well,like k/v stores and databases, if supported by the state backend.",1
[FLINK-5822] [state backends] Make JobManager / Checkpoint Coordinator aware of the root state backendThis closes #3411,1
[FLINK-5928] [checkpoints] Add CheckpointCoordinatorExternalizedCheckpointsTestProblem: there were only unit tests for the checkpoint instances availablethat don't test the behaviour of the checkpoint coordinator with respectto externalized checkpoints.This closes #3424,3
[hotfix] [tests] Fix test instability in SavepointITCase,3
[FLINK-5921] [table] Add custom data types for rowtime and proctime.- proctime() and rowtime() are translated to constont zero timestamp.This closes #3425.,5
[FLINK-5389] [tests] Increate ask timeout in JobSubmitTest,3
[FLINK-5402] [tests] Increase JUnit timeouts in AkkaRpcServiceTestThis closes #3430.,3
"[FLINK-5794] [doc] Update the documentation about UDF/UDTF"" support have parameters constructor.This closes #3450",2
[FLINK-4422] [kafka] Convert all time interval measurements to System.nanoTime()This closes #3422.This closes #3421.This closes #3420.This closes #3419.,5
[FLINK-5870] Handlers define REST URLsThis closes #3376.,0
[FLINK-5852] Move handler JSON generation code into static methodsThis closes #3365.,5
"[FLINK-5938] Replace ExecutionContext by Executor in SchedulerIn order to remove the Scheduler's dependency on Scala's ExecutionContext andAkka's futures, this PR replaces the ExecutionContext by an Executor which isused to execute the concurrent handleNewSlot call.This closes #3435.",0
"[FLINK-5934] Set the Scheduler in the ExecutionGraph via its constructorBefore the scheduler was set when calling ExecutionGraph.scheduleForExecution(). Thishas the disadvantage that the ExecutionGraph has not scheduler set if something elsewent wrong before the scheduleForExecution call. Consequently, the job will be stuckin a restart loop because the recovery will fail if there is no Scheduler set. Inorder to solve the problem, the Scheduler is not passed to the ExecutionGraph whenit is created.This closes #3437.",1
[FLINK-5948] Fix error in Python zip_with_index documentationThis closes #3454.,2
[FLINK-5524] [table] Support early out for code generated AND/OR conditionsThis closes #3372.,1
[FLINK-5827] [table] Exception when do filter after join a udtf which returns a POJO typeThis closes #3357.,2
[FLINK-5945] [core] Close function in OuterJoinOperatorBase#executeOnCollectionsConclude OuterJoinOperatorBase#executeOnCollections with a call toFunctionUtils.closeFunction(function) in order to close rich userfunctions.This closes #3453,1
[FLINK-5941] Integrate Archiver pattern into handlersThis closes #3444.,0
[FLINK-5768] [table] Refactor DataSet and DataStream aggregations to use UDAGG interface.- DataStream aggregates use new WindowedStream.aggregate() operator.This closes #3423.,1
[FLINK-4896] [gelly] PageRank algorithm for directed graphsAdds a PageRank algorithm using Flink transformation that handles sourceand sink vertices (in- or out-degree of zero). The scatter-gather andgather-sum-apply PageRank implementations are moved to Gelly examples.This closes #2733,4
[FLINK-5597] [docs] Improve the LocalClusteringCoefficient documentationUpdate the documentation for Gelly's library methods with improvedalgorithm descriptions and explanation of algorithm results.This closes #3404,1
[FLINK-5937] [doc] Add documentation about the stream task lifecycle,2
[FLINK-5917] [statebackends] Remove size() method from MapStateThis closes #3462,4
"[FLINK-5864] [cep] Fix duplicate output patterns problemThe problem was that the Dewey numbers in theNFA::computeNextStates() were not updated correctlywhen branching, i.e. from the same state  we hadtwo new valid states.",1
[hotfix] [table] Fix initialization of accumulators for MIN and MAX aggregates.,5
[FLINK-5955] [table] Fix aggregations with ObjectReuse enabled by pairwise merging of accumulators.This closes #3465.,0
"[FLINK-5927] [table] Remove old Aggregate interface, built-in functions, and tests.This closes #3465.",3
[FLINK-5219] [table] Add non-grouped session windows for batch tables.This closes #3266.,1
[FLINK-5586] [table] Extend TableProgramsClusterTestBase for object reuse modeThis closes #3339.,1
[FLINK-5067] Java 8 build fixes- New type inference rules changed which overloaded methods are picked.- Renamed java.version property in maven to java.minor.version. This is due to the fact that overriding java.version is used by some third-party classes and they expect the version to be fully qualified.- Introduced Java 8 build for Travis CIThis closes #2804This closes #2767,1
[FLINK-5965] [docs] Fix minor typo on DropWizard wrappersThis closes #3475.,4
"[FLINK-4460] Make ProcessFunction abstract, add default onTime() methodThis is in preparation of allowing ProcessFunction on DataStream becausewe will use it to allow side outputs from the ProcessFunction Context.",1
[FLINK-4660] Allow ProcessFunction on DataStreamIntroduce new ProcessOperator for this. Rename the pre-existingProcessOperator to KeyedProcessOperator.,1
"[FLINK-4460] Make CoProcessFunction abstract, add default onTime() methodThis is in preparation of allowing CoProcessFunction on a non-keyedconnected stream.  we will use it to allow side outputs from theProcessFunction Context.",1
[FLINK-4660] Allow CoProcessFunction on non-keyed ConnectedStreamsIntroduce new CoProcessOperator for this. Rename the pre-existingCoProcessOperator to KeyedCoProcessOperator.,1
[FLINK-4460] Update doc: ProcessFunction now possible on DataStream,5
[FLINK-5645] Store accumulators/metrics for canceled/failed tasksThis closes #3377.,0
[FLINK-5956] [table] Add retract method for AggregateFunction.This closes #3470.,1
[FLINK-5803] [table] Add support for procTime partitioned OVER RANGE BETWEEN UNBOUNDED PRECEDING aggregation to SQL.This closes #3397.,1
[FLINK-5916] [yarn] make env.java.opts.jobmanager and env.java.opts.taskmanager working in YARN modeminor change and add test caseThis closes #3415.,1
"[FLINK-4326] [scripts] Flink foreground servicesAdd a ""start-foreground"" option to the Flink service scripts which doesnot daemonize the service nor redirect output.This closes #3492.This closes #3351.",2
[FLINK-5722] [table] Add dedicated DataSetDistinct operator.- Uses hash-combiner for more better combine rate.This closes #3471.,1
[FLINK-3427] [webui] Add watermark tracking,1
[FLINK-3427] [webui] Refactorings to watermark tracking,4
[FLINK-3427] [webui] Rebuild web UIThis closes #3366.,2
[FLINK-5414] [table] Bump up Calcite version to 1.11. (Jark Wu and Haohui Mai)This closes #3338.This closes #3426.,2
[FLINK-5047] [table] Add sliding group-windows for batch tablesThis closes #3364.,1
[FLINK-5983] [table] Convert FOR into WHILE loops for aggregation functions.This closes #3489.,1
[FLINK-3679] [kafka] Allow Kafka consumer to skip corrupted messages,1
"[FLINK-3679] [kafka] Improve null record handling for FlinkKafkaConsumerThis commit generally improves null record handling by: - also update the offset in state holders if record is null - move null record related tests to AbstractFetcherTest, so that   behaviour is tested for all fetcher implementations - let the docs be more informative of the behaviour of the consumer   when corrupted messages are encountered.This closes #3314.",5
"[hotfix] [FLINK-3679] Improve Javadocs of DeserializationSchemasJavadocs of the `deserialize(...)` method should inform that returningnull from the method is allowed, if the message cannot be deserialized.",1
[FLINK-6002] [docs] Quickstart download not rendered correctlyThis closes #3497.,2
[FLINK-5963] [table] Remove prepare mapper of DataSetAggregate.This closes #3472.,5
[FLINK-5984] [table] Add resetAccumulator method for AggregateFunctionThis closes #3496.,1
[hotfix] [checkpoints] Cleanups in PendingCheckpoint,4
[FLINK-5598] [web frontend] Return filename after jar uploadThis closes #3469,2
[FLINK-5824] Fix String/byte conversions without explicit encodingThis closes #3468,0
"[FLINK-5824] (followup) Minor code cleanups in CheckForbiddenMethodsUsage  - Move to maual tests package  - Adjust order of methods (ctor, instance, class)  - Replace Guava with Java Util  - Make charset in SimpleStringSchema configurable",5
[FLINK-4545] [network] remove fixed-size BufferPool instancesThis closes #3467,0
[FLINK-5830] [distributed coordination] Handle OutOfMemory and fatal errors during process async message in akka rpc actorThis closes #3360,0
[FLINK-5135] [runtime] Expand the fields in ResourceProfile based on ResourceSpecThis closes #3457,2
"[FLINK-5909] [gelly] Interface for GraphAlgorithm resultsCreate PrintableResult interface for library algorithms and analyticscontaining a toPrintableString method used by drivers to printhuman-readable results to stdout.Also create interfaces for UnaryResult, BinaryResult, and TertiaryResultimplementing methods to access the 0th, 1st, and 2nd vertices.This closes #3434",1
"[FLINK-5838] [scripts] Print shell script usageIf jobmanager.sh, taskmanager.sh, or zookeeper.sh are called withoutarguments then argument list for the call to flink-daemon.sh ismisaligned and the usage for flink-daemon displayed to the user.Adds a check to each script to check for a valid action and otherwisedisplays the proper usage string.This closes #3352",1
[FLINK-5804] [table] Add support for procTime non-partitioned OVER RANGE BETWEEN UNBOUNDED PRECEDING aggregation to SQL.This closes #3491.,1
[FLINK-6010] [docs] Correct IntelliJ IDEA Plugins path in 'Installing the Scala plugin' sectionThis closes #3504,2
[FLINK-6005] [misc] Fix some ArrayList initializations without initial sizeThis closes #3499,5
[FLINK-5980] [core] Expose max-parallelism value in RuntimeContext.This closes #3487,1
[FLINK-5976] [tests] Deduplicate Tokenizer in testsThis closes #3485,3
"[FLINK-4545] [network] Allow LocalBufferPool to limited the number of used buffersUse ""a * <number of channels> + b"" buffers for bounded pipelined partitions:Default: a = 2, b = 8* 1 buffer for in-flight data in the subpartition/input channel* 1 buffer for parallel serialization* + some extra buffers (8 seems a good default given bandwidth-delay products of current networks)This closes #3480",1
[FLINK-4545] [network] Small adjustments to LocalBufferPool with limited the number of used buffers,1
[FLINK-5890] [gelly] GatherSumApply broken when object reuse enabledGatherSumApplyIteration uses reduce and join for which extra care mustbe taken when object reuse is enabled. Adds a check for objects returnedby the user to prevent system objects from being overwritten.This closes #3402,5
"[FLINK-5910] [gelly] Framework for Gelly examplesDriver jobs are composed of an input, an algorithm driver, and anoutput. Create the interfaces for inputs, drivers, and outputs.This closes #3431",1
[FLINK-5874] Restrict key types in the DataStream API.Reject a type from being a key in keyBy() if it is:1. it is a POJO type but does not override the hashCode() and   relies on the Object.hashCode() implementation.2. it is an array of any type.,5
[FLINK-5954] [table] Always assign names to the windows in SQL queries on streams.This closes #3461.,2
[FLINK-6023] fix process function doc examplesThis closes #3510.,2
[FLINK-5881] [table] ScalarFunction(UDF) should support variable types and variable argumentsThis closes #3389.,1
[FLINK-5882] [table] TableFunction (UDTF) should support variable types and variable argumentsThis closes #3407.,1
"[FLINK-5971] [flip-6] Add timeout for registered jobs on the ResourceManagerThis PR introduces a timeout for inactive jobs on the ResourceManager. A job is inactiveif there is no active leader known for this job. In case that a job times out, it willbe removed from the ResourceManager. Additionally, this PR removes the dependency ofthe JobLeaderIdService on the RunningJobsRegistry.Fix YarnFlinkApplicationMasterRunner to use correct arguments for JobLeaderIdServiceFix race condition in JobLeaderIdListener#cancelTimeoutThis closes #3488.",0
"[FLINK-6025] [core] Add Flink's own JavaSerializer for Kryo serializationThis commit adds a reimplemented JavaSerializer to be registered withKryo. This is due to a know issue with Kryo's JavaSerializer that mayuse the wrong classloader for deserialzation.Instead of registering Kryo's JavaSerializer for Throwables, it is nowchanged to register the reimplemented JavaSerializer. Users who bumpinto ClassNotFoundExceptions if they are using Kryo's JavaSerializer fortheir own types are also recommended to change to Flink's JavaSerializer.This closes #3517.",2
[FLINK-3123] [kafka] Allow custom specific start offsets for FlinkKafkaConsumerThis closes #2687.,2
"[FLINK-6007] Allow key removal from within the watermark callback.When deleting a key from the InternalWatermarkCallbackService, thedeleted key is put into a separate set, and the actual deletionhappens after the iteration over all keys has finished. To avoidcheckpointing the deletion set, the actual cleanup also happensupon checkpointing.",4
"[FLINK-5942] [checkpoint] Harden ZooKeeperStateHandleStore to handle corrupt dataIf calling ZooKeeperStateHandleStore.getAll or getAllSortedByName as theZooKeeperCompletedCheckpointStore does in the recovery case, the operation will failif there exists a Znode with corrupted data. This will break Flink's recoverymechanism, because it will read this node over and over again. In order to solve thisproblem, this commit changes the behaviour such that it ignores corrupted Znodes itcannot read.This closes #3447.",4
[FLINK-5441] [table] Directly allow SQL queries on a TableThis closes #3107.,1
"[FLINK-5940] [checkpoint] Harden ZooKeeperCompletedCheckpointStore.recover methodThe ZooKeeperCompletedCheckpointStore only tries to recover the latest completedcheckpoint even though it might have read older checkpoint state handles fromZooKeeper. In order to deal with corrupted state handles, this commit changes thebehaviour such that the completed checkpoint store adds all read retrievablestate handles from ZooKeeper and upon request of the latest checkpoint it willreturn the latest completed checkpoint which could be retrieved from the statehandles. Broken state handles are removed from the completed checkpoint store andZooKeeper.This closes 3446.",4
[hotfix] [log] Log proper user defined state backend in StreamTask,1
[FLINK-5949] [yarn] Don't check Kerberos credentials for non-Kerberos authentication methodsThis closes #3528.,2
[FLINK-3398] [kafka] Allow disabling offset committing for FlinkKafkaConsumerThis closes #3527.,2
[FLINK-6040] [table] DataStreamUserDefinedFunctionITCase occasionally failsThis closes #3530.,0
[hotfix] [tests] Improve mocking in ZooKeeperCompletedCheckpointStore.testCheckpointRecovery,3
[FLINK-5635] [docker] Improvements for Docker on Flink experienceModifying Dockerfile to build from local flink-dist as well as release URLs.Logging to stdout.Adding scripts to deploy seamlessly on Docker Swarm.Updating Docker Compose scripts to work correctly.Parameterizing things so these Docker scripts are more generally useful.,1
"[FLINK-5635] [docker] Use start-foreground in Docker entrypointdocker-entrypoint.sh should error on invalid argsImprove docker build.sh cleanupDockerfile improvements per reviewRemove unnecessary Dockerfile build stepsNow that docker-entrypoint.sh uses 'start-foreground', mungingflink-daemon.sh and overwriting the log4j config are not longernecessary.Improve Dockerfile and docker-entrypoint.shClean up Dockerfile and improve docker-entrypoint.sh to support '--help'and pass through non-(jobmanager|taskmanager) commands.This closes #3205.This closes #3494.",4
[FLINK-6001] Fix ContinuousEventTimeTrigger firing without state,1
[FLINK-6061] [state backends] Throw IllegalStateException when using RocksDB keyed state with no key set,1
[FLINK-6044] Replace all unintentional calls to InputStream#read(...) with InputStream#readFully(...),2
[hotfix] [doc] Fix error in ProcessFunction example.,1
[FLINK-6051] [metrics] [docs] Fix scope keys on Configuration pageThis closes #3538.,1
[FLINK-6018] Properly initialise StateDescriptor in AbstractStateBackend.getPartitionedState(),1
"[FLINK-6064][flip6] fix BlobServer connection in TaskExecutorThe hostname used for the BlobServer was set to the akka address which isinvalid for this use. Instead, this adds the hostname to the RpcGateway /AkkaInvocationHandler so that this information is available to the TaskExecutor.This closes #3551.",5
"[FLINK-6032] [cep] Clean-up operator state when not needed.The CEP operator now cleans the registered state for akey. This happens:1) for the priority queue, when the queue is empty.2) for the NFA, when its shared buffer is empty.3) finally the key is removed from the watermark   callback service if both the above are empty.",4
[hotfix] Remove auto-boxing in ContinuousEventTimeTrigger,1
[FLINK-5756] [rocksdb] Add mini benchmarks to reproduce 'merge' performance problems,0
[FLINK-5692] [core] Add an Option to Deactivate Kryo Fallback for SerializersThis closes #3373,1
[FLINK-5692] [core] (followups) Add an Option to Deactivate Kryo Fallback for Serializers,1
[hotfix] [core] Fix/cleanup serialization test for ExecutionConfig,5
[FLINK-5962] [checkpoints] Remove scheduled cancel-task from timer queue to prevent memory leaksThis closes #3548,4
[FLINK-4422] [clients] Convert time interval measurements to System.nanoTime() in 'flink-clients'This closes #3384,2
[FLINK-4754] [checkpoints] Make number of retained checkpoints user configurableThis closes #3374,5
[FLINK-4754] [checkpoints] Small followups to the configuration of number of retained checkpoints.,5
[FLINK-5134] [runtime] Aggregate ResourceSpec for chained operators when generating job graphThis closes #3455,1
[FLINK-6009] [java api] Deprecate DataSetUtils#checksumHashCodeThis is likely only used by Gelly and we have a more featurefulimplementation allowing for multiple outputs and setting the job name.Deprecation will allow this to be removed in Flink 2.0.This closes #3516,2
[FLINK-6041] [streaming api] Move StreamingFunctionUtils to 'org.apache.flink.streaming.util'This close #3532,2
[FLINK-5650] [py] Continuously check PyProcess health while waiting for incoming connection,2
[refactor] [py] General code clean-up- added missing serialVersionUID- PythonPlan* classes no longer implement serializable- marked several fields as transient- replaced some fields by local variables- input/output files are now being deleted- remvoed some unnecessary casts- renamved several ignored exceptions- close socket in PythonPlanStreamer- simplified PyProcess health check- eliminated several uses of raw types- removed some unthrown exception declarations,4
[FLINK-5715] Asynchronous snapshots for heap-based keyed state backend,2
[FLINK-3849] [table] Add FilterableTableSource interface and rules for pushing it (1)fix filterable testrebase and trying fix rexnode parsingcreate wrapper and update rules,5
[FLINK-3849] [table] Add FilterableTableSource interface and rules for pushing it (2)This closes #3520.fix compilation failurefix compilation failure again.1. Deep copy TableSource when we copy TableSourceScan2. unify push project into scan rule for both batch and streamaddress comments.expand project list before creating new RexProgramupdate tests,3
[FLINK-5981] [security] Make SSL pick up configured protocols and cipher suitesThis closes #3486,3
[hotfix] Added missing documentation in StateTransformationFunction,1
[FLINK-6076] Refactor HeartbeatManager to extend HeartbeatTargetRemove start method from HeartbeatManagerThis closes #3555.,4
[FLINK-5932] initializeState() before legacy state restoring in operator,1
[FLINK-5846] [cep] Make the CEP operators backwards compatible with Flink 1.1,2
[FLINK-4364] [heartbeats] Implement TaskManager side of heartbeat from JobManagerThis closes #3151.,2
[FLINK-4364] Introduce HeartbeatServices for the HeartbeatManager instantiationThe HeartbeatServices are used to create all services relevant for heartbeating. Thisincludes at the moment the creation of HeartbeatManager implementations which activelysend heartbeats and those which only respond to heartbeat requests.Add comments,1
[FLINK-5985] Report no task states for stateless tasks on checkpointing,2
"[FLINK-5808] Move default parallelism to StreamingJobGraphGeneratorBefore, it was set on the ExecutionConfig for some stream executionenvironments and later for others. Now, we don't set the defaultparallelism on the ExecutionConfig but instead set it at the latestpossible point, in the StreamingJobGraphGenerator.This also adds tests that verify that we don't set the defaultparallelism on the ExecutionConfig.",5
[FLINK-5808] Move max keygroup constants to ExecutionConfigWe need to have them there if we want to properly test the arguments ofsetMaxParallelism() in the ExecutionConfig itself.,5
"[FLINK-5808] Add proper checks in setParallelism()/setMaxParallelism()Before, there where some checks inStreamExecutionEnvironment.set(Max)Parallelism() but a user wouldcircumvent these if using the ExecutionConfig directly. Now, all checksare moved to the ExecutionConfig.",5
[FLINK-4460] Add support for side outputsThis does not yet allow users to emit to side outputs in user functions.Only operators (StreamOperator) can emit to side outputs. A side outputcan be retrieved on a SingleOutputStreamOperator.,1
[FLINK-4460] Provide late-data output for window operationsWe use side outputs to emit dropped late data.,5
[FLINK-4460] Expose OutputTag constructor that takes TypeInformation,5
[FLINK-4460] Make chaining work with side outputs,1
[FLINK-4460] Add side outputs for ProcessFunction,1
[FLINK-4460] Add proper side output API for Scala APIThe Scala side output API uses context bounds to get a TypeInformationfor an OutputTag. This also adds a SideOutputITCase for the Scala API.,1
[FLINK-4460] Add documentation for side outputs,2
[FLINK-4460] Add WindowOperatorContractTest tests for late data emission,5
[FLINK-4460] Add ITCase to verify watermark forwarding for side outputs,1
[FLINK-4460] Add side output ITCase for multiple side out consumers,1
[FLINK-4460] Catch side output OutputTag id clashesThis also adds tests.,3
"[FLINK-5568] [table] Introduce ExternalCatalog interface, integrated with calcite and provide an in-memory implementation for testing.This closes #3406.",3
[FLINK-6068] [table] Support If() as a built-in function.This cloes #3553.,1
[FLINK-6111] [py] Remove unnecessary sleeps,4
[FLINK-5183] [py] Support mulitple jobs per plan fileThis closes #3232.,2
[FLINK-6122] Add Travis build status to READMEThis closes #3570.,1
[FLINK-5995] [checkpoints] Fix serializer initialization for Operator StateThis closes #3503,1
[FLINK-5995] [checkpoints] Harden test for state descriptor passing to OperatorState,1
[FLINK-5883] [core] Re-adding the Exception-thrown code for ListKeyGroupedIterator when the iterator is requested the second timeThis closes #3392,2
[FLINK-6027] [checkpoints] Suppress (and log)  exceptions thrown by the subsuming of completed checkppointsThis closes #3521,2
[docs] Document per-Kafka-partition watermarks,2
"[FLINK-5999] [resMgnr] Move JobLeaderIdService shut down into ResourceManagerRunnerThe JobLeaderIdService is being created by the ResourceManagerRunner and then given to aResourceManager. Before the ResourceManager stopped the service before being stoppeditself. This could lead to a concurrent modification exception by a state changing actionexecuted by the actor thread. In order to avoid this concurrent modification, the service'sshut down is now being executed after the ResourceManager has been shut down.This closes #3526.",4
"[hotfix] Harden TaskExecutorTest#testHeartbeatTimeoutWithJobManager by increasing timeoutIn order to check whether the heartbeat manager detects timeouts we wait on theJobMasterGateway.disconnectTaskManager call which happens asynchronously. In order to hardenthe test, we increase the timeout from 50 ms to 500 ms for the timeout call to happen.",1
"[FLINK-6050] [robustness] Register exception handler on thenAccept futuresWhen applying an AcceptFunction on a Future x, then we should register the exception handleron the returned thenAccept future instead of on x. This has the advantage that we also catchexceptions which are thrown inside of the AcceptFunction and not only those which originatefrom x. The PR adapts the code respectively.This closes #3537.",1
[FLINK-6037] [table] Metadata provider didn't work in SQLThis closes #3559.,1
[FLINK-6124] [table] support max/min aggregations for string typeThis closes #3579.,1
[FLINK-6138] [table] Create the ListStateDescriptor with the aggregationStateType instead of a serializer.this closes #3581,1
"Revert ""[FLINK-6122] Add Travis build status to README""This reverts commit 486f7249cb36a34af928c771b5d59052ebed9154.Removed after the ""[DISCUSS] TravisCI status on GitHub Page"" discussion onthe mailing list.This closes #3577.",4
[FLINK-6132] [cleanup] Remove redundant code in CliFrontendThis closes #3576.,4
[FLINK-6084][Cassandra] Promote transitive dependenciesThis closes #3556,2
[FLINK-6144] [config] Port JobManager configuration options to ConfigOptionThis PR ports the existing JobManager configuration options to the JobManagerOptions classusing the ConfigOption abstraction.,5
[hotfix] [config] Minor improvements to JobManagerOptions docs and harmonization of config parameters.,2
[hotfix] Clean up AbstractID and make it immutable.This removes the IOReadableWritable interface from AbstractID which is no longer used with IDs.,1
[hotfix] Clean up StringUtils and remove unused methods.,1
[FLINK-6056] [build] Add rat exclude for 'tools/flink*'This closes #3540,2
[FLINK-6000] [scripts] Fix starting HA cluster with start-cluster.shThis closes #3506,0
"[FLINK-6134] Set UUID(0L, 0L) as default leader session idBefore the default leader session id was null in the standalone case. However, in the ZooKeepercase null indicated that there was no active leader available. With this commit, the defaultleader id will be set to UUID(0L, 0L). This allows the uniform treatment of null denoting thatthere is no active leader across the standalone and the ZooKeeper case.With this change, the FlinkActors will now ignore all LeaderSessionMessages if the actors'sleader id field is null. This indicates that the FlinkActor does not know the current leader.This closes #3578.",2
[FLINK-6080] Unclosed ObjectOutputStream in NFA#serialize(),2
[FLINK-1579] [refactor] Add WebFrontendBootstrap for code reuseRefactors the web frontend's Netty code into a bootstrap helper classthat can be re-used by the history server.,1
[FLINK-1579] [webui] Implement History ServerArchives jobs to a file system directory and adds a history serverthat can display the archived jobs.,1
[FLINK-1579] [webui] Rebuild web frontendThis closes #3460.,2
"[FLINK-6139] [build] Add ""mapr"" build profileThis build profile is for building Flink to be compatible with MapR. Itadditionally excludes dependency clashes between MapR's Hadoop /Zookeeper distributions and Flink's dependencies.",2
[FLINK-6139] [doc] Add documentation for running Flink on MapRThis closes #3582.,2
[FLINK-5067][hotfix] Fix snapshot deployment,0
[FLINK-6170] [metrics] Don't rely on stats snapshot for checkpoint metricsThis closes #3597.,2
[FLINK-3318] Add support for quantifiers to CEP's pattern API,1
[FLINK-3318] Backward compatibility of CEP NFA,2
[FLINK-4354] [heartbeat] Implement heartbeat logic between TaskManager and ResourceManagerThis closes #3591.,2
[FLINK-4354] [heartbeat] Add heartbeats between the ResourceManager and TaskExecutor,1
[hotfix][scripts] Fix zookeeper quorum regex,0
[FLINK-6129] [metrics] Stop query actor of MetricRegistryThis PR properly shuts down the query actor of the MetricRegistry upon shut down.Add locking to the MetricRegistryThis closes #3573.,1
"[hotfix] Add EvictingWindowOperatorContractTestThe existing WindowOperatorContractTest is turned into a test base whileRegularWindowOperatorContract test tests WindowOperator andEvictingWindowOperatorTest tests EvictingWindowOperator. For this towork, the base tests now always use List windows and we have specifictests for reducing/folding windows in RegularWindowOperatorContractTest.This also patches in the missing side output support forEvictingWindowOperator.",1
[hotfix] Fix various small issues in WindowOperatorContractTest,3
[FLINK-5972] Don't allow shrinking merging windowsThis closes #3587.,1
[FLINK-6018] Add tests for KryoSerializer restore with registered typesThis commit also renames isCompatibleWith() to canRestoreFrom() to makethe method asymetric because in the case of KryoSerializer wecan restore from state that was stored using no registedtypes/serializers while the other way around is not possible.This closes #3534.This closes #3603.,1
"[hotfix] Remove validateRunsInMainThread from TaskExecutor to fix TaskExecutorTestCurrently, the TestingSerialRpcService does not play well together with theMainThreadValidatorUtil which assumes that rpc calls are dispatched to a mailboxfrom where they are picked up. In order to support the TestingSerialRpcServicewe will have to extend the MainThreadValidatorUtil to allow entering the main threadif the RpcEndpoint already runs in the context of the main thread.",1
[FLINK-6182] Fix possible NPE in SourceStreamTaskThis closes #3606.,0
"[FLINK-5890] [gelly] GatherSumApply broken when object reuse enabledThe initial fix for this ticket is not working on larger data sets.Reduce supports returning the left input, right input, a new object, ora locally reused object. The trouble with the initial fix was that thereturned local object was reusing fields from the input tuples.The problem is with ReduceDriver#run managing two values (reuse1 andreuse2) and with a third, local value returned byGatherSumApplyIteration.SumUDF. After the first grouping value.f1 ==reuse1.f1. Following UDF calls may swap value.f1 and reuse2.f1, whichcauses reuse1.f1 == reuse2.f1. With an odd number of swaps the nextgrouping will reduce with reuse1 and reuse2 sharing a field anddeserialization will overwrite stored values.The simple fix is to only use and return the provided inputs.This closes #3515",1
[FLINK-6128] [tests] Optimize JVM options to improve test performanceDecrease the time to run TravisCI builds and reduce OOM by- increasing the heap size- switching to Java's serial garbage collector- removing the UseGCOverheadLimit optionThis closes #3571,1
[FLINK-5570] [table] Register ExternalCatalogs in TableEnvironment.This closes #3409.,2
[hotfix] [table] Improved code documentation for external catalog.,2
[FLINK-6089] [table] Add decoration phase for stream queries to rewrite plans after the cost-based optimization.This closes #3564.,1
[FLINK-5990] [table] Add event-time OVER ROWS BETWEEN x PRECEDING aggregation to SQL.This closes #3585.,1
[FLINK-5658] [table] Add event-time OVER ROWS/RANGE UNBOUNDED PRECEDING aggregation to SQL.This closes #3386.,1
[hotfix] [table] Disable event-time OVER RANGE UNBOUNDED PRECEDING window.,0
[FLINK-5698] [table] Add NestedFieldsProjectableTableSource interface.This closes #3269.,1
[FLINK-5929] Allow Access to Per-Window State in ProcessWindowFunction,1
[hotfix] Make GC test more strict in WindowOperatorContractTest,3
[hotfix] [docs] Fix broken linksThis closes #3618.,2
"[FLINK-5911] [gelly] Command-line parametersCreate interface for parsing command-line parameters using ParameterTooland generic implementations for boolean, long, double, string, choice.This closes #3433",2
"[FLINK-6197] [cep] Add support for iterative conditions.So far, the where clause only supported simple FilterFunctionconditions. With this, we add support for conditions where anevent is accepted not only based on its own properties, e.g.name, as it was before, but also based on some statisticcomputed over previously accepted events in the pattern, e.g.if the price is higher than the average of the prices of thepreviously accepted events.",1
comments,5
[FLINK-6207] Duplicate TypeSerializers for async snapshots of CopyOnWriteStateTable,3
[FLINK-6034] [checkpoints] Introduce KeyedStateHandle abstraction for the snapshots in keyed streams,0
[FLINK-6211] [kinesis] Fix AT_TIMESTAMP config validation for FlinkKinesisConsumerThis closes #3636.This closes #3637.,2
[hotfix] [dist. coordination] Small code cleanups in ExecutionGraph and related classes,4
[hotfix] [dist. coordination] Add safety check for execution graph state transitions,1
[hotfix] [dist. coordination] Fix waiting for execution termination,0
"[hotfix] [dist. coordination] Move metrics out of the Execution GraphExecutionGraph-based metrics should be in their own package 'org.apache.flink.runtime.executiongraph.metrics'.They are instantiated by whoever builds the execution graph, but not by the execution graph itself.This separates concerns more elegantly.",2
[hotfix] [dist. coordination] Clean up exception signature of ExecutionGraph,4
[FLINK-5340] [metrics] Add an uptime and downtime metric to the Execution Graph.,1
[hotfix] [dist. coordination] Remove redundant method 'ExecutionVertex.getSimpleName()'Replace the method via identical method 'getTaskNameWithSubtaskIndex'.,1
[FLINK-5655] [table] Add event-time OVER RANGE BETWEEN x PRECEDING aggregation to SQL.This closes #3629.,1
"[FLINK-6165] [cep] Implement internal continuity for looping states.Allows looping states (oneOrMore, zeroOrMore, times) to specifyif they want their elements to be consecutive or allow non-matchingelements in-between.",1
[FLINK-6200] [table] Add support for unbounded event-time OVER RANGE window.This closes #3649.,1
[FLINK-5653] [table] Add processing-time OVER ROWS BETWEEN x PRECEDING aggregation to SQL.This closes #3653.This closes #3574.,1
[FLINK-5625] [kinesis] Configurable date format for timestamp-based start position in FlinkKinesisConsumerThis closes #3651.,2
[FLINK-4577] [kinesis] Transparent reshard handling for FlinkKinesisConsumerThis closes #3458.,2
"[FLINK-6205] [FLINK-6069] [cep] Correct watermark/late events in side output.With this, the CEP library assumes correctness of the watermarkand considers as late, events that arrive having a timestampsmaller than that of the last seen watermark. Late events are notsilently dropped, but the user can specify to send them to a sideoutput.",1
[FLINK-5915] [table] Forward the complete aggregate ArgList to aggregate runtime functions.This closes #3647.,1
[FLINK-5903] [yarn] Respect taskmanager.numberOfTaskSlots config value in Yarn modeThis closes #3408.,5
"[FLINK-2814] [optimizer] DualInputPlanNode cannot be cast to SingleInputPlanNodeWorksetIterationNode#instantiate loops over all solution and work setcandidates. Since the solution set reference is modified in place whenthe predecessor node can be used in its place, swith this variable tothe inner loop.This closes #3563",1
[FLINK-3695] [gelly] ValueArray typesProvide compact and efficiently serializable and comparable arrayimplementations for Flink mutable Value types and Java primitives.This cloeses #3382,2
[FLINK-5912] [gelly] Inputs for CSV and graph generatorsCreate Input classes for reading graphs from CSV as well as for each ofthe graph generators.This closes #3626,1
[FLINK-5913] [gelly] Example driversReplace existing and create new algorithm Driver implementations foreach of the library methods.This closes #3635,1
[FLINK-5654] [table] Add processing-time OVER RANGE BETWEEN x PRECEDING aggregation to SQL.This closes #3641.This closes #3590.This closes #3550.,1
[FLINK-4949] [gelly] Refactor Gelly driver inputsThe Gelly drivers started as simple wrappers around library algorithmsbut have grown to handle a matrix of input sources while often runningmultiple algorithms and analytics with custom parameterization.The monolithic drivers are replaced with separate inputs and algorithms.Command-line parameter parsers are shared and reusable across inputs andalgorithms. Algorithm results now implement a common AlgorithmResultinterface. Drivers are now tested with integration tests.This closes #3294,3
[FLINK-5829] [table] Bump Calcite version to 1.12.This closes #3613.,2
[FLINK-6124] [table] Add min/max string aggregation with retracionThis closes #3593.,1
[FLINK-6254] [cep] Same method name for late data outputs on PatternStream and WindowedStream,5
[FLINK-6259] Fix a small spelling error from har-with-dependencies to jar-with-dependenciesthis closes #3667,0
[FLINK-6267] [table] Remove unused imports in FlinkRelBuilder.This closes #3671.,2
"[FLINK-6011] [table] Support TUMBLE, HOP, SESSION group window functions in SQL queries on streams.This closes #3665.",1
[FLINK-6265] [cep] Fix consecutive() for times(),0
"[FLINK-6212] [docs] Add avro dependency referenceAdds the reference to the maven dependecy for flink-avroin the ""Avro support in Flink"" section.This closes #3638.",2
[FLINK-6201] [py] [dist] move python example files from resources to the examplesThis closes #3628.,2
[FLINK-6186] Remove unused import in StreamExecutionEnvironment.scalaThis closes #3612.,2
[FLINK-6127] [checkstyle] Add MissingDeprecation checkThis closes #3572.,1
[hotfix] Fix unchecked conversion in JobDetailsHandler,0
[FLINK-6246] Fix generic type of OutputTag in operator OutputThis closes #3662.,1
[FLINK-6086] [py] Clean up PythonSender/-Streamer generics,4
[hotfix] [py] Code cleanup - PythonStreamer#sendBroadCastVariables(),5
[hotfix] [py] Code cleanup - StreamPrinter- implements Runnable instead of extending Thread- use AtomicRefence<String> instead of StringBuilder- remove redundant wrapInException argument,4
[hotfix] [py] Code cleanup - PythonStreamer,4
[hotfix] Fix shading checks,0
[FLINK-6181][Start scripts] Fix regex in start scriptsThis closes #3605.,0
[FLINK-6183] [metrics] Prevent some cases of TaskMG not being closed,2
[FLINK-6203] [docs] [batch] Fix scala GroupReduce example,0
[FLINK-4848] [ssl] Throw meaningful exception when SSL is misconfiguredThis closes #3677.,5
[FLINK-6241] [table] Add codeGen for streaming OVER aggregations.This closes #3676.,1
[hotfix] [py] Fix PythonCoGroup useByteArray check,1
[FLINK-6223] [py] Rework PythonPlanBinder generics,1
[hotfix] [py] Code cleanup - PythonPlanBinder,4
[FLINK-6229] [py] Rework configuration of PythonPlanBinder/Operators- unify python2/python3 configuration- explicitly pass on a configuration to each operator- port all configuration options to ConfigOptions- [FLINK-5516] Make all paths explicitly configurable- [FLINK-6230] Make mmap size configurable,5
[FLINK-6229] [py] Rework setup of PythonPlanBinder- make file/argument split more readable- pass on Paths where applicable instead of recreating them every time- rename PPB#clearPath to more appropriate deleteIfExists- simplify PPB#copyFile- simplify PPB#startPython- use UUID#randomUUID() instead of Random.nextInt()- remove several invalid exception declarations,4
[FLINK-6257] [table] Consistent naming of ProcessFunction and methods for OVER windows.- Add check for sort order of OVER windows.This closes #3681.,1
[FLINK-5435] [table] Remove FlinkAggregateJoinTransposeRule and FlinkRelDecorrelator after bumping Calcite to v1.12.This closes #3689.,2
[FLINK-6268] [core] Object reuse for Either typeImplement object reuse for Flink's Either type by storing a reference toRight in Left and Left in Right. These references are private and remainnull until set by EitherSerializer when copying or deserializing withobject reuse.This closes #3680,1
[FLINK-5376] Fix log statement in UnorderedStreamElementQueue,2
[FLINK-6256] Fix outputTag variable name in Side Output docsThis closes #3684.,2
[FLINK-6079] [kafka] Provide meaningful error message if TopicPartitions are nullThis closes #3685.,0
[hotfix] [jdbc] Add generic parameter to ResultTypeQueryable,2
[FLINK-6269] Make UserCodeClassLoader finalThis closes #3682.,1
[FLINK-6270] extend Configuration with contains(configOption),5
[FLINK-6270] port some memory and network task manager options to ConfigOptionThis closes #3683.,5
"[FLINK-6261] [table] Support TUMBLE, HOP, SESSION group window functions for SQL queries on batch tables.- Drop support for group window translation of ""GROUP BY FLOOR/CEIL"".This closes #3675.",1
[FLINK-6012] [table] Support SQL WindowStart and WindowEnd functions.This closes #3693.,1
[FLINK-5545] [table] Remove FlinkAggregateExpandDistinctAggregatesRule after bumping Calcite to v1.12.This closes #3695.,2
[FLINK-6279] [table] Fix toString() of TableSourceScan.- The digest of VolcanoRuleMatch matched different table sources with same field names as the same.This closes #3699.,0
[FLINK-6162] [core] Fix bug in ByteArrayOutputStreamWithPosFix off-by-one error in 'setPosition' and expand array when seekingoutside the original bounds.This closes #3595,1
[FLINK-6282] Fix some spelling mistakeThis closes #3702,0
[FLINK-5756] Replace RocksDB dependency with FRocksDBThis closes #3704,5
[hotfix] [gelly] Update test graph generationIn tests RMat graphs are now created by calling a function with thedesired scale and edge factor. Also updated the documentation forgenerating test graphs using Gelly examples.,1
[hotfix] [gelly] Add mutators to Result interfacesAdd mutators matching the existing accessors for vertex ID fields.,1
[FLINK-6298] [java api] Set context in RichOutputFormatThis closes #3716,1
[FLINK-6304] [table] Remove unused importsThis closes #3717,2
[FLINK-5629] [runtime-web] Close RAF in FileServerHandlers when exception occursThis closes #3678.,2
"[FLINK-6299] make all IT cases extend from TestLoggerThis way, currently executed tests and their failures are properly logged.This closes #3713.",2
"[hotfix] add the missing mvn.forkNumber to the commandline of flink-hbaseOtherwise, travis file logs end up in the wrong log file, i.e. "".log"".",2
"[hotfix] prepend ""mvn-"" to Travis log filesThis is just a safety precaution in case future tests forget to include themvn.forkNumber property in the argLine. In that case, the log file would havebeen "".log"" and omitted from the log files package that is uploaded for furtherinspection.",2
[FLINK-6292] fix transfer.sh upload by using httpsSeems the upload via http is not supported anymore.This closes #3708.,1
[FLINK-6271] [jdbc] Fix NPE when there's a single splitThis closes #3686.,0
[FLINK-6143] [clients] Fix unprotected access to this.flink in LocalExecutor#endSession.This closes #3710.,2
[FLINK-6240] [table] Add code generation for DataStream group window aggregations.This closes #3694.,5
[FLINK-6317] Fix wrong default directory for history serverThis closes #3731.,0
[FLINK-6313] [runtime] Fix typos; log exception in QSClient for ActorSystem shutdown failureThis closes #3728.,0
[FLINK-6104] Fix resource leak in ListViaRangeSpeedMiniBenchmarkThis closes #3725.,5
[FLINK-6286] [scripts] Print error for 'hbase not found'Previously if HBASE_CONF_DIR was set then `hbase classpath` was run andappended to INTERNAL_HADOOP_CLASSPATHS. Now when HBASE_CONF_DIR is setHBASE_HOME or PATH is checked for 'hbase' and if not found a warning isprinted and INTERNAL_HADOOP_CLASSPATHS is not updated.This closes #3711,5
[FLINK-6195] [build] Move gelly-examples jar from opt to examplesThe opt directory should be reserved for Flink JARs which users mayoptionally move to lib to be loaded by the runtime. flink-gelly-examplesis a user program so is moved to the examples folder.This closes #3691,4
[hotfix] [gelly] Don't print Null edge values,0
"[FLINK-6300] Use 'exec' in start-foreground callsTo avoid signal-handling issues in Docker, applications need to run asa single executable or use a process manager that forwards signalscorrectly, in either case running as PID 1.Since Flink uses a number of chained scripts before the ultimate callto `java`, we need to use `exec` so that the script executable isreplaced, ultimately resulting in a single `java` process as PID 1.There's no need to run a process manager since Flink only actuallyrequires a single process.This closes #3734",1
[FLINK-6294] Add close without input test for BucketingSinkAnd earlier version of the code was throwing an NPE if the sink wasclosed without ever seeing any input.,3
"Revert ""[FLINK-5808] Add proper checks in setParallelism()/setMaxParallelism()""This reverts commit f31a55e08ddb7b4bc9e47577a187bac31ad42f4b.The fixes around FLINK-5808 introduced follow-up issues.",0
"Revert ""[FLINK-5808] Move max keygroup constants to ExecutionConfig""This reverts commit e4fbae36207c563363eed39886c24eea51d7db01.The fixes around FLINK-5808 introduced follow-up issues.",0
"Revert ""[FLINK-5808] Move default parallelism to StreamingJobGraphGenerator""This reverts commit 9cfae899358e0694c3ecedae1fad20e428a1d359.The fixes around FLINK-5808 introduced follow-up issues.",0
"[FLINK-6324] [DataStream] Refine OperatorStateStore interfaceThis commit refines the OperatorStateStore interface by,- deprecating Java serialization shortcuts- rename getOperatorState to getListStateThe Java serialization shortcuts are deprecated because they werepreviously introduced to provide a smoother migration path from oldersavepoints. However, its usage should definitely be discouraged.Renaming to getListState is a preparation of making the names of stateaccess methods contain information about both its redistribution patternon restore and the shape of its datastructure, since the combination ofthese two is orthogonal. This convention will also provide a betternaming pattern for more state access methods in the future, for examplegetUnionListState. If the method name does not contain itsredistribution pattern (e.g., getListState), then it simply implies thedefault repartitioning scheme (SPLIT_DISTRIBUTE).",1
"[FLINK-5991] [DataStream] Expose Union ListState for operator stateThis commit exposes the union list state scheme for managed operator state.The actual functionality was already previously added to the`DefaultOperatorStateBackend`, so this change simply exposes the featurethrough the `OperatorStateStore` interface.This commit also updates the documentation for managed operator state sothat it covers the new union list state scheme. It strengthens thedifference between keyed and non-keyed state data structures byemphasizing the semantic differences in the state access method Javadocs.This closes #3508.",2
[FLINK-6149] [table] Add additional flink logical relation nodes and separate current optimization to logical and physical optimizeThis closes #3594.,2
"[FLINK-6307] [jdbc] Refactor JDBC testsJDBCFullTest:- split testJdbcInOut into 2 methods to avoid manul test-lifecycle callsJDBCTestBase:- remove all qualified static accesses- remove static Connection field- remove (now) unused prepareTestDB method- create RowTypeInfo directly instead of first allocating a separateTypeInfo[]- rename testData to TEST_DATA in-line with naming conventions- rework test data to not rely on Object arraysJDBCInputFormatTest:- call InputFormat#closeInputFormat() in tearDown()- simplify method exception declarations- remove unreachable branch when format returns null (this should failthe test)- replace loops over splits with for-each loops- rework comparisons; no longer ignore nulls, no longer check class,compare directly against expected valueJDBCOutputFormatTest:- directly create Row instead of first creating a tuple- simplify method exception declarationsGeneral:- do not catch exceptions if the catch block only calls Assert.fail()This closes #3723.",3
[FLINK-5904] Make jobmanager.heap.mb and taskmanager.heap.mb work in YARN modeThis closes #3414.,1
[FLINK-5904] Use proper ConfigOption syntax to retrieve config values,5
"[hotfix] [gelly] Driver updates- refactor SimpleDriver to call internal plan method- add CLI parameters for RMatGraph, AdamicAdar, JaccardIndex- remove unused data from VertexDegrees- JaccardIndex now filters on > rather than >=- handle null in ValueArrayTypeInfo- add NonForwardingIdentityMapper to GraphUtils",1
[FLINK-6327] [table] Bug in CommonCalc's estimateRowCount() methodThis closes #3740.,0
[hotfix] [tests] Stabilize SystemProcessingTimeServiceTest,5
[hotfix] [tests] Stabilize AsyncCallsTest by ensuring delayed messages are not executed before their time,3
[FLINK-5646] [docs] Document JAR upload with the REST APIThis closes #3722,2
[FLINK-5481] [core] Add utility method to easily generate RowTypeInfosThis closes #3127,5
"[FLINK-5481] [core] Followups to the typeinfo/Types utility  - Move new 'Types' class to 'common' scope, not 'java api'.  - Make the method names the same in Scala and Java",1
[hotfix] [streaming] Propagate 'CancelTaskException' in during checkpoint-on-barrier,0
[hotfix] [misc] Minor code cleanups,4
[hotfix] [checkpoints] Rename JobSnapshottingSettings to JobCheckpointingSettingsCleanup to consistently use  - checkpoint for the overall fault tolerance mechanism and procedure  - snapshot for an operators state snapshot that is part of a checkpoint,1
"[hotfix] [streaming api] Make it clear that StreamingJobGraphGenerator is single use.This reduces the public API of the StreamingJobGraphGenerator to a static createJobGraph() method,which internally instantiates a generator, creates the job, and drops the generator.",4
[FLINK-6339] [streaming api] Delete unused (and useless) class ConnectorSource,1
"[FLINK-6338] [core] Rename SimpleStringUtils to StringValueUtilsThis more intuitivce name clarifies the role of the class.This also marks the class as PublicEvolving, as it is not actually used as an internal class.",1
[FLINK-6311] [kinesis] NPE in FlinkKinesisConsumer if source was closed before runThis closes #3738.,1
[FLINK-6103] [core] Improve rename() on LocalFileSystemThis closes #3598,5
[FLINK-6103] [core] Fix conditions and add tests for rename() on LocalFileSystem,5
"[FLINK-5623] [runtime] Fix TempBarrier dam has been closedProperly reset the ""pipeline breaker"" upon closing.This closes #3747",4
[hotfix] [docs] Typo sick -> sinkThis closes #3749,2
[FLINK-6176] [scripts] [yarn] [mesos] Add JARs to CLASSPATH deterministicallySorts files read from Flink's lib directory and places the distributionJAR to the end of the CLASSPATH.This closes #3632,2
[FLINK-6117] [security] Make setting of 'zookeeper.sasl.disable' work correctlyThis closes #3600,1
[misc] Closing commit for outdated pull requestThis closes #3592,5
[FLINK-6210] [rocksdb] Close RocksDB in ListViaMergeSpeedMiniBenchmark && ListViaRangeSpeedMiniBenchmarkThis closes #3652,5
[hotfix] [rocksdb] Convert performance benchmarks to unit tests,3
[FLINK-6290] [CEP] Fix SharedBuffer release when having multiple edges between entriesThis closes #3706,5
[FLINK-4769] [metrics] Port metric config parameters to ConfigOptionsThis closes #3687,5
[FLINK-5962] [runtime-web] [tests] Replace deprecated usage og JsonNode#getValueAsTextThis closes #3679,5
[hotfix] [docs] Remove empty Docker docs pageThis will be re-added when we have a coherent plan for Docker supportand after the official Docker images are available.This closes #3658,2
[FLINK-6236] [docs] Mention that resume from savepoint is possible via the web UIThis closes #3657,2
"[FLINK-5672] [scripts] Add special cases for a local setup in cluster start/stop scriptsThis way, if all slaves refer to ""localhost"", we do not require ssh at all.This closes #3298",1
[FLINK-4562] [table] Move table examples into a dedicated module in flink-examples.This closes #2460.,2
[FLINK-6326] [table] Add ProjectMergeRule to logical optimization rule set.This closes #3739.,1
[FLINK-6242] [table] Add code generation for DataSet AggregatesThis closes #3735.,3
[hotfix] [table] Add missing semicolons to Table API Java examples.This closes #3754.,1
[FLINK-6014] [checkpoint] Allow the registration of state objects in checkpoints,1
[FLINK-6014] [checkpoint] Additional review changes,4
[FLINK-6280] [scripts] Allow logging with Java flagsEvaluate user-defined Java options immediately before starting servicesand rotate all log files.This closes #3701,2
[FLINK-6228] [table] Add support for OVER windows to streaming Table API.This closes #3743.,1
[FLINK-6361] [table] Refactor the AggregateFunction interface and built-in aggregates.This closes #3762.,1
[FLINK-6368] [table] Grouping keys in stream aggregations have wrong orderThis closes #3768.,0
"[hotfix] [tests] Harden JobManagerRegistrationTestThe problem was that the started JobManagers try to instantiate a MetricQueryServiceactor with a fixed name. Thus, if the previous JobManager was not shutdown properly,then there was still a MetricQueryServie actor around having the exact same namewith which you try to start a new actor.The problem is solved twofold:1. by properly stopping the instantiated actors2. by starting the JobManager without a MetricsRegistry",1
[FLINK-6155] Introduce an endpoint id for RpcEndpointsAn endpoint id allows to assign a unique name to a RpcEndpoint. This name can be usedto look up the rpc endpoint within the RpcService.Remove component endpoint name methods from the HighAvailabilityServicesRemove JobMaster endpoint idThis closes #3596.,4
[hotfix] Fix Scalastyle for broken build,0
[FLINK-6107] Custom checkstyle for flink-streaming-javaThis is based on the Apache Beam checkstyle with some custommodifications for making it fit the exisiting Flink code base. The mostnotable change is that Flink uses Tabs for indentation while Beam usesspaces.This adds a lot of checks that are commented out because they requirenon-trivial changes to the code base.There are some trivial code changes for good practices checkstyle rulesthat where only broken in very few places.,4
[FLINK-6107] Enable Javadoc checks in streaming checkstyle,2
[FLINK-6107] Enable newline at EOF check in streaming checkstyle,1
[FLINK-6107] Enable trailing whitespace check in streaming checkstyle,0
[FLINK-6107] Enable import order check in streaming checkstyle,2
[FLINK-6107] Enable WhitespaceAfter check in streaming checkstyle,0
[FLINK-6107] Enable WhitespaceAround check in streaming checkstyle,0
[FLINK-6107] Enable MemberNameCheck in streaming checkstyle,0
[FLINK-6107] Enable StaticVariableNameCheck in streaming checkstyle,0
[FLINK-6107] Enable LeftCurly check in streaming checkstyle,0
[FLINK-6107] Add checkstyle section to IDE Setup Guide,1
"[FLINK-6248] [cep] Make the optional() available to all offered patterns.Allow all patterns to be optional in a pattern sequence.Singleton becomes simply optional, times(X) transforms from""exactly X"" to ""0 or X"", and ""one or more"" becomes ""zero or more"".",1
"[FLINK-6356] [cep] Make times() eager by default and allow allowCombinations().By default, the times() quantifier operates in eager mode and theuser can disable eagerness by calling .allowCombinations().",1
[FLINK-6384] [py] Remove python binary check via additional processThe PythonStreamer used to check for the existence of the python binary bystarting a python process. This process was not closed afterwards. This causedthe PythonPlanBinderTest to fail locally.I think the check whether a python binary exists is not necessary since thesubsequent python command would fail anyway if there is no binary available onthe system. The system failure message is that there is no such file or directory.This error message should be descriptive enough in order to debug such a problem.This closes #3774.,0
[FLINK-3871] [table] Add Kafka TableSource with Avro serializationThis closes #3663.,1
[FLINK-3722] [runtime] Don't / and % when sortingReplace division and modulus with addition and subtraction.This closes #2628,1
[FLINK-6048] [checkpoint] Implement asynchronous snapshots for DefaultOperatorStateBackend,1
"[FLINK-6390] [checkpoints] Add API for checkpoints that are triggered via external systemsThis includes  - A interface for hooks that are called by the checkpoint coordinator to trigger/restore a checkpoint  - A source extension that triggers the operator checkpoints and barrier injection on certain eventsBecause this changes the checkpoint metadata format, the commit introduces a new metadata format version.This closes #3782",5
"[hotfix] [tests] Harden JobManagerRegistrationTestThe problem is that we don't wait until the JobManager becomes the leader. Due to this,the sent RegisterTaskManager messages might get dropped.This PR fixes the problem by waiting on the completion of the NotifyWhenLeader message.",0
[hotfix] Fix wrong comparator in WindowOperatorTestAnd also the same bug in WindowOperatorMigrationTest,3
"[FLINK-4953] Allow access to ""time"" in ProcessWindowFunction.Context",1
"[FLINK-5090] [network] Add metrics for details about inbound/outbound network queuesThese metrics are optimised go go through the channels only once in order togather all metrics, i.e. min, max, avg and sum. Whenever a request to eitherof those is made, all metrics are refreshed and cached. Requests to the othermetrics will be served from the cache. However, each value will be served onlyonce from the cache and a second call to retrieve the minimum, for example,will refresh the cache for all values.This setup may at first be a bit strange but ensures that the statistics belongtogether logically and originate from a common point in time. This is notnecessarily the point in time the metric was requested though.",2
"[hotfix][metrics] remove an unnecessary check for non-nullThe metrics group given to a Task must always be non-null otherwise the codewould have crashed anyway. Similarly, the group returned by getIOMetricGroup()is always present.",1
[hotfix][metrics] keep the non-null assumption and implement tests properlyPrevious commit in e908b62ab3 caused a regression leading to unit test failures.,0
"[FLINK-5090] Fixups for ""Add metrics for details about inbound/outbound network queues""This closes #3348.",1
[FLINK-6247] [table] Put flink-table.jar with all dependencies into ./opt folder.This closes #3666.,2
[FLINK-6392] [table] Improve group window API to make alias mandatory.This closes #3786.,5
[FLINK-6120] [heartbeat] Implement heartbeat logic between JobManager and ResourceManagerThis closes #3645.,2
[FLINK-6404] [FLINK-6400] Ensure PendingCheckpoint is registered when calling Checkpoint Hooks,1
"[FLINK-5975] Add volume support to flink-mesosWhen using containerization, specifically, docker, it is useful to beable to attach additional volumes, such as an NFS share.This adds support for volumes to be attached via specifying a new configvalues `mesos.resourcemanager.tasks.container.volumes`. This is commadelimited string of `[host_path:]container_path[:RO|RW]`.It is modeled after the spark mesos framework[FLINK-5975] Address code review, simplify handling of modes[FLINK-5975] Fix volume config key to match actual[FLINK-5975] make building volume info eager[FLINK-5975] add volume info before setting container info[FLINK-5975] Always set volumes even in no imageIn the event that no container is used, we should still be able to usevolumes with the mesos containerizer.This closes #3481.",1
"[FLINK-6336] [mesos] Add mesos placement constraintsThis adds a HostAttrValueConstraint evaluator for fenzo, allowing tasksto be placed on agents with matching attributes.Signed-off-by: Stephen Gran <stephen.gran@piksel.com>This closes #3744.",1
[FLINK-6398] RowSerializer's duplicate should always return a new instanceThis closes #3794.,1
[FLINK-6386] Missing bracket in 'Compiler Limitation' sectionThis closes #3775.,2
"[FLINK-3347] [akka] Add QuarantineMonitor which shuts a quarantined actor system and JVM downThe QuarantineMonitor subscribes to the actor system's event bus and listens toAssociationErrorEvents. These are the events which are generated when the actor systemhas quarantined another actor system or if it has been quarantined by another actorsystem. In case of the quarantined state, the actor system will be shutdown killingall actors and then the JVM is terminated.Disable the quarantine monitor per defaultThis closes #2696.",5
[FLINK-6410] [build] Fix Gelly Example packaging to support different Scala versions,1
"[hotfix] Change checkstyle/suppression file references to be absoluteThe relative path caused problems with ""mvn deploy"".",0
[FLINK-6208] [cep] Implement skip till next match strategy,2
[FLINK-6293] [tests] Harden JobManagerITCaseOne of the unit tests in JobManagerITCase starts a MiniCluster and sends aLeaderSessionMessage to the JobManager without waiting until the JobManagerhas gained leadership. This can lead to a dropped TriggerSavepoint messagewhich will cause the test to deadlock.This PR fixes the problem by explicitly waiting for the JobManager to becomethe leader.This closes #3796.,0
"[FLINK-5810] [flip-6] Introduce a hardened slot managerHarden the slot manager so that it better deals with lost and out of order messagesfrom the TaskManager. The basic idea is that the TaskManager are considered the groundtruth and the SlotManager tries to maintain a consistent view of what is reported to itby the TaskManagers. This has the assumption that the TaskManagers regularly report theirslot status to the SlotManager piggy backed on the heartbeat signals to the ResourceManager.That way it is possible to handle lost and out of order messages because the SlotManagerwill eventually converge on a consistent view of the actual slot allocation.Additionally, the hardened SlotManager registers for idle TaskManagers and pending slotrequests a timeout. If the timoeut expires, then the TaskManagers are released and theslot request is failed. This prevents resource leaks and wasteful resource allocation.This closes #3394.",0
[FLINK-5810] [flip-6] Multiple small cleanups across Resource Manager related code,4
[FLINK-5810] [flip-6] Make slot registration static,1
[FLINK-5810] [flip-6] Use single timeout task for SlotManager,1
[FLINK-6411] [flip-6] Remove job removal from RunningJobsRegistry in YarnFlinkApplicationMasterRunner.shutdownThe YarnFlinkApplicationMasterRunner should not be concerned with removing jobs fromthe RunningJobsRegistry. This is the responsibility of the JobManagerRunner.This PR removes the job removal from the RunningJobRegistry from theYarnFlinkApplicationMasterRunner.shutdown method.This closes #3797.,2
[FLINK-6341] [jm] Don't let JM fall into infinite loopThis closes #3745.,5
[FLINK-6341] [jm] Add test case to guard against RM registration loop,3
[FLINK-5892] Add new StateAssignmentOperationV2,1
[Flink-5892] Restore state on operator level,1
[FLINK-5892] Add tests for topology modificationsThis closes #3770.,2
[FLINK-6059] [table] Reject GenericType<Row> when converting DataSet or DataStream to Table.This closes #3546.,5
[FLINK-6406] [table] Remove unused importsThis closes #3795,2
[FLINK-6395] [tests] Mark test bases as abstractThis closes #3790,3
[FLINK-6112] [table] Support Calcite 1.12's new numerical functionsThis closes #3718.,1
"[FLINK-6112] [table] Improve documentation, consistency, and fix bugs",0
[FLINK-6377] [table] Support map types in the Table / SQL APIThis closes #3767.,1
[FLINK-6377] [table] Add additional map tests,3
"[FLINK-6382] [gelly] Support additional types for generated graphs in Gelly examplesThe Gelly examples current support IntValue, LongValue, and StringValuefor RMatGraph. Allow transformations and tests for all generated graphsfor ByteValue, Byte, ShortValue, Short, CharValue, Character, Integer,Long, and String.This closes #3779",3
[FLINK-6337][network] Remove the buffer provider from PartitionRequestServerHandlerThe buffer provider is not needed and most likely a left over from priorrefactorings.This closes #3785.,4
[FLINK-6409] [table] TUMBLE/HOP/SESSION_START/END do not resolve time field correctlyThis closes #3799.,0
[FLINK-6337] [network] Fix instability in SuccessAfterNetworkBuffersFailureITCaseThe reduced number of network buffers as part of this issue was too low andlead to instable tests.,3
[hotfix] [tests] Fix test log level in flink-runtime,2
[FLINK-6415] [build] Make sure core Flink artifacts have no specific logger dependency,2
[hotfix] [build] Remove unneeded logback-test.xml files,2
[hotfix] [security] Reduce logging verbosity for SSLUtils,2
[hotfix] [runtime] SerializedThrowable copy constructor preserves cause,1
[hotfix] [runtime] Minor improvement to logging in CheckpointCoordinator,2
[hotfix] [client] Unwrap SerializedThrowable in client log statements when possible,2
[FLINK-2067] [runtime] Unwrap the ExceptionInChainedOperatorException exceptions to clean up stack traces,4
[FLINK-6427] Ensure file length is flushed in StreamWriterBase,2
[FLINK-4604] [table] Add support for standard deviation/varianceThis closes #3260.Old PR: This closes #2762.,1
"[FLINK-4604] [table] Clean-ups, improved Sum0 aggregation, simplified tests and bug fixing",0
"[FLINK-6353] Fix legacy user-state restore from 1.2State that was checkpointed using Checkpointed (on a user function)could be restored using CheckpointedRestoring when the savepoint wasdone on Flink 1.2. The reason was an overzealous check inAbstractUdfStreamOperator that only restores from ""legacy"" operatorstate using CheckpointedRestoring when the stream is a Migration stream.This removes that check but we still need to make sure to read away thebyte that indicates whether there is legacy state, which is written whenwe're restoring from a Flink 1.1 savepoint.After this fix, the procedure for a user to migrate a user function awayfrom the Checkpointed interface is this: - Perform savepoint with user function still implementing Checkpointed,   shutdown job - Change user function to implement CheckpointedRestoring - Restore from previous savepoint, user function has to somehow move   the state that is restored using CheckpointedRestoring to another   type of state, .e.g operator state, using the OperatorStateStore. - Perform another savepoint, shutdown job - Remove CheckpointedRestoring interface from user function - Restore from the second savepoint - Done.If the CheckpointedRestoring interface is not removed as prescribed inthe last steps then a future restore of a new savepoint will failbecause Flink will try to read legacy operator state that is not thereanymore.  The above steps also apply to Flink 1.3, when a user want's tomove away from the Checkpointed interface.",4
"[FLINK-5969] Remove watermark callback serviceIn Flink 1.2 we only wrote timers to key-grouped state streams. With theaddition of the watermark callback service we started to also write thewatermark callbacks to the key-grouped streams. This breaks backwardscompatibility with saveoints taken on Flink 1.2This replaces usage of the watermark callback service by setting aregular timer for ""current watermark + 1"". These timers will fire assoon as the watermark advances, thus simulating the watermark callbackservice.",1
[FLINK-5969] Augment SavepointMigrationTestBase to catch failed jobs,0
[FLINK-5969] Add savepoint IT case that checks restore from 1.2The binary savepoints in this were created on the Flink 1.2.0 releasecommit.,2
"[FLINK-5969] Add OperatorSnapshotUtilThis has methods for storing/reading OperatorStateHandles, as returnedfrom stream operator test harnesses. This can be used to write binarysnapshots for use in state migration tests.",3
[FLINK-5969] Add ContinuousFileProcessingFrom12MigrationTestThe binary snapshots were created on the Flink 1.2 branch.,2
[FLINK-5969] Fix restore from empty state in KafkaConsumerBase,0
[FLINK-5969] Add KafkaConsumerBaseFrom12MigrationTestThe binary snapshots were created on the Flink 1.2 branch.,2
[FLINK-5969] Also snapshot legacy state in operator test harness,3
[FLINK-5969] Add WindowOperatorFrom12MigrationTestThe binary snapshots for this were created on the Flink 1.2 branch.,2
[FLINK-5969] Add BucketingSinkFrom12MigrationTestThe binary snapshots have been created on the Flink 1.2 branch.,2
[FLINK-5969] Add CEPFrom12MigrationTestThe binary snapshots have been created on the Flink 1.2 branch.,2
[FLINK-6312] [build] Update curator version to 2.12.0The updated curator version includes a bugfix for a potential block,0
[FLINK-6340] [flip-1] Add a termination future to the Execution,1
[FLINK-5869] [flip-1] Add basic abstraction for Failover Strategies to ExecutionGraph  - Rename 'ExecutionGraph.fail()' to 'ExecutionGraph.failGlobally()' to differentiate from fine grained failures/recovery  - Add base class for FailoverStrategy  - Add default implementation (restart all tasks)  - Add logic to load the failover strategy from the configuration,5
[FLINK-6334] [table] Refactor Table API TableFunction join methods.This closes #3791.,1
[hotfix] Add check for aligned assigner in AllWindowedStream.evictor()This check is present in WindowedStream but was missing onAllWindowedStream.,1
[FLINK-5933] Allow Evictor for merging windows,1
[FLINK-6274] Replaces usages of org.codehaus.jacksonThis closes #3780.,2
[FLINK-3709] Prevent caching of outdated suspended ExecutionGraphsThis closes #3709.,5
[FLINK-6367] support custom header settings of allow originThis closes #3769.,1
"[FLINK-6177] Add support for ""Distributed Cache"" in streaming applicationsThis closes #3741.",1
[hotfix] [py] Code cleanup - Functions,1
[hotfix] [py] Code cleanup - SerializationUtils,4
[hotfix] [py] Improve error reporting in Python*InputStreamer,0
[FLINK-6445] [cep] Fix NPE in no-condition patterns.,0
[FLINK-5906] [table] Add support to register UDAGGs for Table API and SQL.This closes #3809.,2
[FLINK-5998] Un-fat Hadoop from Flink fat jar.This closes #3604,2
"[FLINK-6136] Separate EmbeddedHaServices and StandaloneHaServicesThis PR introduces a standalone high availability services implementation which can be usedin a distributed setting with no HA guarantees. Additionally, it introduces a common baseclass which is also used by the EmbeddedHaServices. This base class instantiates thestandalone variants of the checkpoint recovery factory, submitted job graphs store, runningjobs registry and blob store.The StandaloneHaServices are instantiated with a fixed address for the Job- andResourceManager. This address and the HighAvailability.DEFAULT_LEADER_ID is returned bythe corresponding LeaderRetrievalServices when being started.This closes #3622.",1
[FLINK-6078] Remove CuratorFramework#close calls from ZooKeeper based HA servicesRemove client less factory methods from ZooKeeperUtilsIntroduce default job idThis closes #3781.,4
[FLINK-6435] [async] React to exceptionally completed StreamElementQueueEntryThe AsyncWaitOperator should not only react to orderly completedStreamElementQueueEntries but also to those completed with a user exceptionor those which timed out.This PR fixes the problem by calling the onComplete function passed toStreamElementQueueEntry#onComplete also in the exceptional case.This closes #3814.,1
[FLINK-6217] ContaineredTaskManagerParameters sets off-heap memory size incorrectly.This closes #3648.,1
[FLINK-6217] Fix ContaineredTaskManagerParametersTest to properly test off heap settings,1
[FLINK-5974] [mesos] Added configurations to support mesos-dns hostname resolutionThis closes #3692.,1
[FLINK-5974] [mesos] Make mesos service name configurable for dns lookups,5
"[FLINK-3320] Add NOT pattern support to CEP's pattern APINOT patterns are not yet supported when an OPTIONALpattern directly preceeds a NOT. In these cases, anexception is thrown that proposes an alternative(but not the most efficient) way to support thesepatterns.",1
[FLINK-6364] [checkpoint] Incremental checkpointing in RocksDBKeyedStateBackend,5
[FLINK-6364] [checkpoint] Additional minor review changes,4
[FLINK-6463] [cep] Throw exception when NOT-NEXT is after OPTIONAL.,2
[FLINK-5884] [table] Integrate time indicators for Table API & SQLThis closes #3808.,2
[FLINK-5884] [table] Integrate time indicators for Table API & SQL. Continued,2
[FLINK-6216] [table] Add non-windowed GroupBy aggregation for streams.This closes #3646.,1
[FLINK-6090] [table] Add RetractionRules for annotating AccMode to DataStreamRel nodes.,5
[FLINK-6091] [table] Implement and turn on retraction for non-windowed aggregates.,2
[FLINK-6093] [table] Implement and turn on retraction for table sinks.,2
[FLINK-6093] [table] Add stream TableSinks and DataStream conversion with support for retraction.,1
[hotfix] [build] Updated outdated config keys in default flink-conf.yaml,5
[FLINK-6401] [rocksdb] Harden RocksDB performance test,3
[hotfix] fix typo in error message,0
[hotfix] fix typo in taskmanager.sh usage string,2
"[FLINK-4545] [network] replace the network buffers parameterInstead, allow the configuration with the following three new (more flexible)parameters: * ""taskmanager.network.memory.fraction"": fraction of JVM memory to use for network buffers (default: 0.1) * ""taskmanager.network.memory.min"": minimum memory size for network buffers (default: 64 MB) * ""taskmanager.network.memory.max"": maximum memory size for network buffers (default: 1 GB)This closes #3721",1
[FLINK-4545] [network] (followup) Replace awk lshift by multiplication'lshift(...)' is not defined by default in some commonly used awk versions.,1
[hotfix] [runtime] Migrate NetworkEnvironmentConfiguration to Java,5
[hotfix] [config] Harmonize configuration keys for TaskManager network settings.This preserves old config keys as deprecated keys where the key was already presentin an earlier release.This also re-arranges config options to form logical sections in the fileand harmonized JavaDoc formatting style.,2
[FLINK-6470] [core] Add a utility to parse memory sizes,1
[FLINK-6447] [docs] Update aws/emr docsThis closes #3828,2
[FLINK-6443] [docs] Add more links to concepts docsThis closes #3822,2
[FLINK-5867] [flip-1] Support restarting only pipelined sub-regions of the ExecutionGraph on task failure,0
[FLINK-5867] [flip-1] Add tests for pipelined failover region construction,0
[FLINK-5867] [flip-1] Improve performance of Pipelined Failover Region constructionThis method exploits the fact that verties are already in topological order.This closes #3773,2
[hotfix] [runtime] Correct some JavaDocs for RestartIndividualStrategy,2
[hotfix] [core] Avoid Java 8 specific functions in MemorySize,1
[FLINK-4821] Implement rescalable non-partitioned state for Kinesis Connector,2
"[FLINK-4821] [kinesis] General improvements to rescalable FlinkKinesisConsumerThis commit adds some general improvements to the rescalableimplementation of FlinkKinesisConsumer, including:- Refactor setup procedures in KinesisDataFetcher so that duplicate work  isn't done on a restored run- Strengthen corner cases where fetcher was not fully seeded with  initial state when snapshot is takenThis closes #3001.",5
[FLINK-6257] [table] Refactor OVER window tests.This closes #3697.,3
[FLINK-6033] [table] Add support for SQL UNNEST.This closes #3793.,1
"[hotfix] [core] Catch InvalidClassException in TypeSerializerSerializationProxyPreviously, the TypeSerializerSerializationProxy only uses the dummyClassNotFoundDummyTypeSerializer as a placeholder in the case where theuser uses a completely new serializer and deletes the old one.There is also the case where the user changes the original serializer'simplementation and results in an InvalidClassException when trying todeserialize the serializer. We should also use theClassNotFoundDummyTypeSerializer as a temporary placeholder in thiscase.",1
"[FLINK-6178] [core] Allow serializer upgrades for managed stateThis commit adds the functionality of allowing serializer upgrades forFlink's managed state. It consists of 2 major changes: 1) newuser-facing API in `TypeSerializer`, and 2) activate serializer upgradesin state backends.For 1) new user-facing API for `TypeSerializer`, the following is added:- new class: TypeSerializerConfigSnapshot- new class: CompatibilityResult- new method: TypeSerializer#snapshotConfiguration()- new method:  TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)Generally speaking, configuration snapshots contains a point-in-timeview of a serializer's state / configuration, and is persisted alongwith checkpoints. On restore, the configuration is confronted with thenew serializer of the state to check for compatibility, which mayintroduce reconfiguration of the new serializer to be compatible.This compatibility check is integrated in the state backends' restoreflow in 2). Currently, if the check results in the need to perform statemigration, the restore simply fails as the state migration feature isn'tyet available.",0
"[FLINK-6178] [core] Introduce TypeDeserializer interface for CompatibilityResultPreviously, the CompatibilityResult class accepts a full-blownTypeSerializer for its convert deserializer, which will actually onlyever be used for deserialization.This commit narrows down the interface by introducing a newTypeDeserializer interface that contains only the read methods.This closes #3834.This closes #3804.",1
[FLINK-6471] [checkpoint] Fix RocksDBStateBackendTest#testCancelRunningSnapshot failing sporadically,0
[FLINK-6475] [checkpoint] Incremental snapshots in RocksDB should not hold lock during async file upload,2
FLINK-6474 Potential loss of precision in 32 bit integer multiplication,2
Update Flink version to 1.4-SNAPSHOT,2
[FLINK-6394] [runtime] Respect object reuse configuration when executing group combining functionThis closes #3803.,1
[FLINK-6506] [build] Tests in flink-tests exceed memory resources on containerized Travis,3
[FLINK-5742] [docs] allow sidenav to work for widths down to 992This closes #3821,1
"[FLINK-6438] [docs] Added a few links to the docs home page, and made some other small adjustments.This closes #3823",2
[FLINK-6479] [table] Fix IOOBE in DataStreamGroupWindowAggregate.This closes #3841.,5
[FLINK-6436] [table] Fix code-gen bug when using a scalar UDF in a UDTF join condition.This closes #3815.,1
[FLINK-6486] [table] Pass RowTypeInfo to CodeGenerator instead of CRowTypeInfo.This closes #3850.,5
[FLINK-6476] [table] Add support to convert DataSet[Row] and DataStream[Row] to Table.This closes #3849.,5
[FLINK-5070] [types] Unable to use Scala's BeanProperty with classesThis closes #3318,5
[FLINK-6157] [core] Make TypeInformation fully serializableThis closes #3619.,5
Close hanging GitHub PRsThis closes #1033This closes #1944This closes #1979This closes #2029This closes #2809This closes #3043This closes #3627,5
[FLINK-6164] Make ProcessWindowFunction a RichFunctionThis closes #3824.,1
[FLINK-5978] Move JM WebFrontend address ConfigOption to JMOptionsThis closes #3552.,5
[FLINK-6459] Move origin header ConfigOption to JMOptions,5
[FLINK-6461] Deprecate web config defaults in ConfigConstantsThis closes #3831.,5
[FLINK-6396] Fix FsSavepointStreamFactoryTest on WindowsThis closes #3789.,3
[FLINK-5720] Deprecate DataStream#fold()This closes #3816.,5
[FLINK-6013][metrics] Add Datadog HTTP metrics reporterThis closes #3736.,5
[FLINK-6509] [tests] Perform TestingListener#waitForNewLeader under lockPerformin TestingListener#waitForNewLeader under the lock which is also hold whenupdating the leader information makes sure that leader changes won't go unnoticed.This led before to failing test cases due to timeouts.This closes #3853.,3
[FLINK-5819] [webui] implements numeric option on metrics graphsThis closes #3367,2
"[FLINK-5831] [webui] order, search and filter metricsThis closes #3369",2
"[FLINK-6330] [docs] Add basic Docker, K8s docsThis closes #3751",2
[FLINK-6512] [docs] improved code formatting in some examplesThis closes #3857,1
[FLINK-6513] [docs] cleaned up some typos and grammatical flawsThis closes #3858,2
[hotfix] Use Flink's FileUtils in BlobUtils to have proper exception handling,2
[hotfix] [build] Move JSON dependency in flink-storm into proper section,2
[FLINK-6501] [build] Add NOTICE transformers to shadingThis makes sure that transitive NOTICE files are added to the shaded JAR files.,2
[FLINK-6515] [runtime] Fix classloading of JavaSerializer,0
[hotfix] [core] Minor code cleanups in JavaSerializer and SerializerTestBase,3
[hotfix] [tests] Add a lightweight test for classloading in the Kryo Serializer,3
[hotfix] [gelly] Support log output when running examples in the IDEThis adds the dependencies / config files necessary for log output,2
[FLINK-6508] [build] Include licenses of bundled/shaded dependencies where required,1
[FLINK-6414] [build] Use scala.binary.version in place of change-scala-version.shUse scala.binary.version as defined in the parent POM and remove thescript to swap scala version identifiers.This closes #3800,4
[hotfix] [tests] Share proper test mini cluster for tests in DistributedCacheTest,3
[FLINK-5679] [tests] Refactor PartitionedStateCheckpointingITCase  - Massively speeds up the test by using fewer test elements and better coordination    of source throttling and checkpointing.  - Makes the test compatible with Windows by using proper URI encoding  - Drops use of deprecated ValueState constructors,1
[FLINK-6531] [checkpoints] Ensure proper classloading for user-defined checkpoint hooksThis closes #3868,1
[hotfix] [build] Drop transitive jersey/jettison/servlet dependencies pulled via Hadoop,4
[hotfix] [docs] Update file path of Gelly examples,2
[hotfix] [gelly] Improve graph generator documentation,2
[FLINK-6393] [gelly] Add Circulant and Echo graph generatorsThis closes #3802,1
[hotfix] Refactor to use multi-catchThis closes #3866,1
[FLINK-6491] [table] Add QueryConfig and state clean up for non-windowed aggregates.,4
[FLINK-6491] [table] Add QueryConfig and state clean up for over-windowed aggregates.This closes #3863.,4
[FLINK-6483] [table] Add materialization of time indicators.This closes #3862.,1
[FLINK-6564] [build] Fix copying of license files.,2
[hotfix] Minutiae,0
[FLINK-6562] [table] Support implicit table references for nested fields in SQL.This closes #3879.,1
[FLINK-5256] [table] Extend DataSetSingleRowJoin to support Left and Right joins.This closes #3673.,1
[FLINK-5101] Track pending records in CassandraSinkBase,2
[FLINK-5101] Refactor CassandraConnectorITCaseThis closes #2866.,1
[FLINK-6548] Fix AvroOutputFormatTest#testCompression on Windows,3
[FLINK-6558] Disable yarn tests on Windows,3
[FLINK-6561] Disable glob test on Windows,3
[FLINK-6565] Fail memory-backed state restores with meaningful message if previous serializer is unavailableThis closes #3882.,0
"[FLINK-6566] [core] More restricted interface for VersionedIOReadableWritable hooksThis commit makes the method hooks for defining compatibileserialization versions of VersionedIOReadableWritables more restricted.Functionally everything remains the same, but with lesser space forerror-prone user implementations. It also allows for a better errormessage to indicate version mismatch.This closes #3883.",0
"[FLINK-6554] [core] Make CompatibilityResult options more explicitly definedPreviously, if a serializer determines that state migration needs to beperformed but could not provide a fallback convert deserializer, itwould use CompatibilityResult.requiresMigration(null).This commit makes this option more explicit by having aCompatibilityResult.requiresMigration() option that takes no parameters.This improves how the user perceives the API without having to rely onthe Javadoc that it is allowed to have no fallback convert deserializer.Consequently, when usingCompatibilityResult.requiresMigration(TypeDeserializer), the providedargument cannot be null.This closes #3886.",1
[FLINK-6397] [tests] Reset context environments after test executionThis closes #3810.,3
[FLINK-6518] Port blobserver config parameters to ConfigOptionsThis closes #3865.,5
[FLINK-6530] Close response in DatadogHttpClientThis closes #3892.,5
[hotfix] [table] Change scala.Boolean to java.lang.Boolean in UpsertStreamTableSink interface.,4
[FLINK-6537] [checkpoint] First set of fixes for (de)registration of shared state in incremental checkpoints,0
[FLINK-6504] [checkpoint] Fix synchronization on materializedSstFiles in RocksDBKeyedStateBackend,5
[FLINK-6527] [checkpoint] OperatorSubtaskState has empty implementations of (un)/registerSharedStates,1
[FLINK-6545] [checkpoint] Make incremental checkpoints externalizable,1
[FLINK-6534] [checkpoint] Use async IO to dispose state in SharedStateRegistry,1
[FLINK-6520] [kafka] Overwrite auto commit props for ON_CHECKPOINTS / DISABLED commit mode,2
"[FLINK-6546] [build] Fix dependencies of flink-mesos  - This makes all flink-related dependencies 'provided' to not have the    transitive dependencies promoted  - Drops the unnecessary dependency on the Hadoop artifact  - Adds directly referenced libraries, like jackson  - Deactivates default logging of tests",3
[build] Reduce flink-avro's compile dependency from 'flink-java' to 'flink-core',2
"[FLINK-6514] [build] Remove 'flink-shaded-hadoop2' from 'flink-dist' via exclusionsThis is more tedious/manual than setting it to 'provided' once, but itis also correct.For example, in the case of Hadoop 2.3, having 'flink-shaded-hadoop2' as 'provided'removes other needed dependencies as well, such as 'org.codehaus.jackson' from avro.",4
[FLINK-6514] [build] Create a proper separate Hadoop uber jar for 'flink-dist' assemblyThis closes #3876,2
[FLINK-6517] [table] Support multiple consecutive windowsThis closes #3897.,1
[FLINK-6579] [table] Add proper support for BasicArrayTypeInfoThis closes #3902.,5
[hotfix] Disable broken test in TableEnvironmentITCase,3
[FLINK-6580] Sync default heap sizes from code with config fileThis closes #3900,2
[FLINK-6552] Allow differing types for side outputs,1
[FLINK-5781][docs] Generate HTML from ConfigOptionsThis closes #3495.,5
[FLINK-6175] Harden HistoryServerTest#testFullArchiveLifecycleThis closes #3655.,3
[hotfix] Further clarify side-output error message for same id and type,0
[FLINK-6381] [connector] Unnecessary synchronizing object in BucketingSink.,2
[FLINK-6593] [table] Fix Bug in ProctimeAttribute or RowtimeAttribute with CodeGeneratorThis closes #3918.,0
[FLINK-6462] [table] Add requiresOver method to AggregateFunction.This closes #3851.,1
[FLINK-6597] [table] Clean up unused imports.This closes #3920.,2
"[FLINK-6581] [cli] Correct dynamic property parsing for YARN cliThe YARN cli will now split the dynamic propertie at the first occurrence ofthe = sign instead of splitting it at every = sign. That way we support dynamicproperties of the form -yDenv.java.opts=""-DappName=foobar"".Address PR commentsThis closes #3903.",1
[FLINK-6555] [futures] Generalize ConjunctFuture to return resultsThe ConjunctFuture now returns the set of future values once it is completed.Introduce WaitingConjunctFuture; Fix thread safety issue with ResultConjunctFutureThe WaitingConjunctFuture waits for the completion of its futures. The future valuesare discarded making it more efficient than the ResultConjunctFuture which returnsthe futures' values. The WaitingConjunctFuture is instantiated viaFutureUtils.waitForAll(Collection<Future>).This closes #3873.,1
"[FLINK-6284] Correct sorting of completed checkpoints in ZooKeeperStateHandleStoreIn order to store completed checkpoints in an increasing order in ZooKeeper,the paths for the completed checkpoint is no generated byString.format(""/%019d"", checkpointId) instead of String.format(""/%s"", checkpointId).This makes sure that the converted long will always have the same length withleading 0s.Fix failing ZooKeeperCompletedCheckpointStoreITCaseThis closes #3884.",1
"[FLINK-6519] Integrate BlobStore in lifecycle management of HighAvailabilityServicesThe HighAvailabilityService creates a single BlobStoreService instance which isshared by all BlobServer and BlobCache instances. The BlobStoreService's lifecycleis exclusively managed by the HighAvailabilityServices. This means that theBlobStore's content is only cleaned up if the HighAvailabilityService's HA datais cleaned up. Having this single point of control, makes it easier to decide whento discard HA data (e.g. in case of a successful job execution) and when to retainthe data (e.g. for recovery).Close and cleanup all data of BlobStore in HighAvailabilityServicesUse HighAvailabilityServices to create BlobStoreIntroduce BlobStoreService interface to hide close and closeAndCleanupAllData methodsThis closes #3864.",5
[FLINK-6020] Introduce BlobServer#readWriteLock to synchronize file creation and deletionThis commit introduces a BlobServer#readWriteLock in order to synchronize file creationand deletion operations in BlobServerConnection and BlobServer. This will preventthat multiple put and get operations interfere with each other and with get operations.The get operations are synchronized using the read lock in order to guarantee some kind ofparallelism.Add Get and Delete operation testsThis closes #3888.,3
[FLINK-6601] [table] Use time indicators in DataStreamLogicalWindowAggregateRuleThis closes #3924.,5
[FLINK-6587] [table] Simplification and bug fixing of the ExpressionParserThis closes #3923.,0
"[FLINK-6371] [cep] NFA return matched patterns as Map<String, List<T>>.",2
[FLINK-6536] [cep] Improve error message in SharedBuffer::put().,5
[FLINK-6255] [cep] Remove PatternStream.getSideOutput().,1
[FLINK-6578] [cep] Fix self-loop handling in SharedBuffer.,5
[hotfix] [cep] Remove unused keySelector in operator.,1
[FLINK-6604] [cep] Remove java serialization from the library.,4
[FLINK-6609] [cep] Fix wrong version assignment with multiple TAKEs.,0
[hotfix] Add configuration notice to HistryServer overview,1
[FLINK-6598] [table] Remove unused parameter from DataStreamGroupAggregate.This closes #3922.,5
[FLINK-6583] [table] Add state cleanup for counting GroupWindows.This closes #3919.,4
[FLINK-6589] [core] Deserialize ArrayList with capacity of size+1 to prevent growth.This closes #3912.,2
"[FLINK-6600] Add key serializer config snapshot to keyed backend checkpointsThis commit adds the config snapshot of the key serializer of keyedbackends to its checkpoints. This allows the oppurtunity to upgrade keyserializers, as well as state migration in the future in the case ofincompatible old and new key serializers.This closes #3925.",1
[FLINK-6570] QueryableStateClient docs with matching constructor signatureThis closes #3926.,2
[FLINK-6624] [cep] Fix SharedBuffer#hashCode().,5
[FLINK-6031][yarn] Add config parameter for user-jar inclusion in classpathThis closes #3931,1
[FLINK-6596][travis] Disable javadoc generation for jdk 7,2
[FLINK-6440][metrics] Downgrade fetching failure logging to DEBUG,0
[FLINK-6416] Fix divide-by-zero in InputGateMetrics,0
[FLINK-6618] [table] Fix translation of WindowProperties in Table API.This closes #3936.,0
[FLINK-6585] [table] Fix execution of Table examples in IDE.This closes #3905.,0
[FLINK-6543] [table] Deprecate toDataStream and add toAppendStream.This closes #3929.,1
"[FLINK-6614] [table] Fix translation of group auxiliary functions (e.g., TUMBLE_END).This closes #3930.",1
[hotfix] [docs] Fix link to docker-compose.ymlThis closes #3887,5
[FLINK-6616] [docs] Clarify provenance of official Docker imagesNote that the official Docker images for Flink are community supportedand not an official release of the Apache Flink PMC.This closes #3932,2
[hotfix] Restore KeySerializer only once,0
[hotfix] Remove some raw type usage in RocksDBKeyedStateBackendIntroduce more generic parameters,2
[hotfix] Remove unnecessary job id from RocksDBKeyedStateBackend,5
[hotfix] Correct equals & hashCode implementation of KryoSerializer,0
"[FLINK-6608] [security, config] Relax Kerberos login contexts parsingThis closes #3928.",2
[FLINK-6288] [kafka] New custom partitioner API that correctly handles multiple Kafka sink topics,0
"[FLINK-6288] [kafka] Cleanup and improvements to FlinkKafkaPartitioner custom partitioningThis commit wraps up some general improvements to the new Kafka sinkcustom partitioning API, most notably:1. remove deprecated constructors from base classes, as they are notuser-facing.2. modify producer IT test to test custom partitioning for dynamictopics.3. improve documentation and Javadocs of the new interfaces.This closes #3901.",1
[hotfix] [kafka] Remove unused operator state store field in FlinkKafkaProducerBase,2
"[FLINK-6612] Allow ZooKeeperStateHandleStore to lock created ZNodesIn order to guard against deletions of ZooKeeper nodes which are still being usedby a different ZooKeeperStateHandleStore, we have to introduce a locking mechanism.Only after all ZooKeeperStateHandleStores have released their lock, the ZNode isallowed to be deleted.THe locking mechanism is implemented via ephemeral child nodes of the respectiveZooKeeper node. Whenever a ZooKeeperStateHandleStore wants to lock a ZNode, thus,protecting it from being deleted, it creates an ephemeral child node. The node'sname is unique to the ZooKeeperStateHandleStore instance. The delete operationswill then only delete the node if it does not have any children associated.In order to guard against oprhaned lock nodes, they are created as ephemeral nodes.This means that they will be deleted by ZooKeeper once the connection of theZooKeeper client which created the node timed out.",1
[FLINK-6633] Register shared state before adding to CompletedCheckpointStore,1
[FLINK-6582] [docs] Project from maven archetype is not buildable by defaultThe pom.xml for flink-quickstart-java and flink-quickstart-scala mustspecify scala.version and scala.binary.version.This closes #3910,2
[FLINK-6574] [table] Support nested catalogs in ExternalCatalog.This closes #3913.,2
[FLINK-6606] Set UserCodeClassLoader as TCCL for MasterTriggerRestoreHook- wrap calls to MasterTriggerRestoreHook (and its factory) such that the user classloader is appliedThis closes #3933.,1
[FLINK-6606] Hide WrapperMasterHook by making it private,1
[FLINK-6634] [cep] NFASerializer serializes ComputationState counter.,2
[hotfix][rat] Add exclusion for all test snapshots/savepointsThis closes #3854.,3
[FLINK-5636][metrics] Measure numRecordsIn in StreamTwoInputProcessorThis closes #3950.,2
[FLINK-6639][docs] fix code tabs in CEP docsThis closes #3952.,2
[FLINK-6586] InputGateMetrics return 0 as min for local channelsThis closes #3907.,2
[FLINK-6439] Fix close OutputStream && InputStream in OperatorSnapshotUtilThis closes #3904.,1
[FLINK-6641] [ha] Don't let the ClusterClient clean up HA services data when being shut downThe ClusterClient should not call HighAvailabilityServices#closeAndCleanupAllData when being shut down.The reason is that this call will delete all HA data needed for a future recovery. Only the JobManagershould be allowed to decide when to discard HA data or not.,5
[FLINK-6640] Ensure registration of shared state happens before externalizing a checkpoint,2
[FLINK-6551] Reject empty OutputTag namesThis closes #3953.,2
[FLINK-6628] Fix start scripts on WindowsThis closes #3954.,0
[FLINK-6644] Don't register HUP signal handler on WindowsThis closes #3955.,0
[FLINK-6651] Add synchronization to SharedStateRegistry::clear,1
"[FLINK-6635] [test] Fix ClientConnectionTestThe ClientConnectionTest passed even though it was failing the test because wewere expecting an exception and checking a special word to contained in theexception's message. Unfortunately, we generated an AssertionError with the sameword if the actual logic we wanted to test failed. That cause the test to pass.",4
"[FLINK-6629] Use HAServices to find connecting address for ClusterClient's ActorSystemThe ClusterClient starts its ActorSystem lazily. In order to find out the addressto which to bind, the ClusterClient tries to connect to the JobManager. In orderto find out the JobManager's address it is important to use theHighAvailabilityServices instead of retrieving the address information from theconfiguration, because otherwise it conflicts with HA mode.This closes #3949.",5
[hotfix] [docs] Remove invalid REST path,4
[FLINK-6482] [core] Add nested serializers to config snapshots of composite serializersThis commit adds also the nested serializers themselves to theconfiguration snapshots of composite serializers. This opens up theoppurtunity to use the previous nested serializer as the convertdeserializer in the case that a nested serializer in the new serializerdetermines that state migration is required.This commit also consolidate all TypeSerializer-related serializationproxies into a single utility class.This closes #3937.,5
[FLINK-6632] [table] Improved the method BoolLiteral of ExpressionParser for case insensitive.This closes #3944.,1
[FLINK-6495] Migrate Akka configuration optionsThis closes #3935.,5
[FLINK-6610][web] Allow uploadDir to be null in WebFrontendBootstrapThis closes #3947.,5
[hotfix] Fix @deprecated javadoc in ConfigConstants,5
"[FLINK-6450][web] Rename ""TaskManagers"" tab to ""Subtasks by Taskmanager""",2
"[FLINK-6451][web] Rename ""Metrics"" tab to ""Task Metrics""",2
"[FLINK-6448][web] Rename ""Free Memory"" field to ""JVM Heap Size""",2
Rebuild webUI,5
[FLINK-6603] [streaming] Enable checkstyle on test sourcesUpdates / reverts the import order by sections:- org.apache.flink.*- all other imports- javax.*- java.*- static importsAdds EmptyLineSeparator to enforce an extra newline (not enforcedbetween field or local variable declarations).This closes #3941,5
"[FLINK-6328] [chkPts] Don't add savepoints to CompletedCheckpointStoreThe lifecycle of savepoints is not managed by the CheckpointCoordinator and fullyin the hand of the user. Therefore, the CheckpointCoordinator cannot rely on themwhen trying to recover from failures. E.g. a user moving a savepoint shortly beforea failure could completely break Flink's recovery mechanism because Flink cannotskip failed checkpoints when recovering.Therefore, until Flink is able to skip failed checkpoints when recovering, we shouldnot add savepoints to the CompletedCheckpointStore which is used to retrieve checkpointfor recovery. The distinction of a savepoint is done on the basis of theCheckpointProperties (CheckpointProperties.STANDARD_SAVEPOINT).This closes #3965.",1
"[FLINK-6656] [cep] Change element PriorityQueue to MapState.This is to leverage the fact that RocksDB already returns thekeys sorted. So now elements, instead of being stores in a PQand all of them being deserialized and serialized at each incomingelement, the are stored in a MapState with the key being thetimestamp and the value, a List of elements that refer to thesame timestamp.",5
[FLINK-6671] [tests] Make RocksDBStateBackendTest.testCancelRunningSnapshot stableLet first the snapshotting thread completely finish before checking the test condition.This prevents race conditions between the checkpointing thread and the verification.,3
[FLINK-6492] Fix unclosed DataOutputViewStream usageThis closes #3898.,1
[FLINK-6660] [docs] Expand the connectors overview pageThis closes #3964.,1
"[FLINK-6662] [errMsg] Improve error message if recovery from RetrievableStateHandles failsWhen recovering state from a ZooKeeperStateHandleStore it can happen that the deserializationfails, because one tries to recover state from an old Flink version which is not compatible.In this case we should output a better error message such that the user can easily spot theproblem.This closes #3972.",0
[FLINK-6685] Prevent that SafetyNetCloseableRegistry is closed prematurely in Task::triggerCheckpointBarrier,1
[FLINK-6690] Fix meta-data restore in RocksDBKeyedStateBackend under rescaling,5
[FLINK-6650] [table] Improve the error message for toAppendStreamThis closes #3958.,0
[FLINK-6431] [metrics] Activate strict checkstyle in flink-metricsThis closes #3968.,2
[FLINK-6432] [py] Activate strict checkstyle for flink-pythonThis closes #3969.,2
[FLINK-6675] Activate strict checkstyle for flink-annotationsThis closes #3970.,2
[FLINK-6659] fix RocksDBMergeIteratorTest leaving temporary data behind-> use a JUnit '@Rule' that does the cleanup,4
[FLINK-6659] fix SavepointITCase leaving temporary data behind-> use a JUnit '@Rule' that does the cleanupThis closes #3962.,4
[FLINK-6320] fix unit test failing sometimes when deleting a temp directoryThis closes #3966.,4
[FLINK-5376] Fix log statement in UnorderedStreamElementQueueThis closes #3948.,2
[FLINK-6669] set inputEncoding to UTF-8 in scalastyle-maven-plugin,1
[FLINK-6691][checkstyle] Add separate block for scala imports,2
[FLINK-6687] [web] Activate strict checkstyle for flink-runtime-web,2
[FLINK-6707] [examples] Activate strict checkstyle for flink-examples,2
[hotfix] Rename exampleJavaPrograms packageThis closes #3986.,1
"[FLINK-6706][tests] Remove outdated/unused ChaosMonkeyITCaseThis test was disabled in Dec 2015 due to its instability and never made itback again. It is probably outdated and may not even work anymore due to thechanges since then.Since it doesn't make sense to keep it in its current form, let's remove it.This closes #3980.",4
[FLINK-6699] Activate strict checkstyle for flink-yarn-testsThis closes #3985.,3
[FLINK-6715] Activate strict checkstyle for flink-mesosThis closes #3988.,2
[FLINK-6642] Return -1 in EnvInfo#getOpenFileHandlesLimitThis closes #3956.,5
[FLINK-4497] [cassandra] Scala Case Classes / Tuple supportThis closes #2633.,1
[FLINK-5892] Enable 1.2 keyed state testThis closes #3842.,3
[hotfix] Fix CassandraConnectorITCase,0
[hotfix] Really fix CassandraConnectorITCase,0
[FLINK-6716] Suppress load errors in checkstyle JavadocMethod,2
[FLINK-6719] Activate strict checkstyle for flink-clientsThis closes #3989.,2
[FLINK-6714] [runtime] Use user classloader for operator state copying on snapshotsThis closes #3987.,1
"[FLINK-6646] [yarn] Let YarnJobManager delete Yarn application filesBefore the YarnClusterClient decided when to delete the Yarn application files.This is problematic because the client does not know whether a Yarn applicationis being restarted or terminated. Due to this the files where always deleted. Thisprevents Yarn from restarting a failed ApplicationMaster, effectively thwartingFlink's HA capabilities.The PR changes the behaviour such that the YarnJobManager deletes the Yarn filesif it receives a StopCluster message. That way, we can be sure that the yarn filesare deleted only iff the cluster is intended to be shut down.",4
"[FLINK-6708] [yarn] Harden FlinkYarnSessionCli to handle GetClusterStatusResponse exceptionsThis PR hardens the FlinkYarnSessionCli by handling exceptions which occur whenretrieving the GetClusterStatusResponse. If no such response is retrieved and insteadan exception is thrown, the Cli won't fail but retry it the next time.",1
[FLINK-6708] [yarn] Minor improvements to YARN session HA fixesThis closes #3981.This closes #3982.,0
[FLINK-6704][yarn] Fix user-jars not being possible to exclude from system class pathThis closes #3979.,5
[FLINK-6653] Avoid directly serializing AWS's Shard class in Kinesis consumer's checkpoints,2
[FLINK-6653] [kinesis] Improvements to removal of AWS's Shard class in checkpointsThis closes #3994.,4
[FLINK-6688] Activate strict checkstyle for flink-test-utilsThis closes #3983.,3
[FLINK-6702] fix SIGABRT during GC in the CEP unit tests,3
[FLINK-6702] put the CEP tests' harness.close() calls into a finally blockThis closes #3978.,3
[FLINK-6658] [cep] Use scala Collections in scala CEP API.,1
[FLINK-6721] Activate strict checkstyle for flink-fs-testsThis closes #3991.,3
[FLINK-6728] Activate strict checkstyle for flink-quickstartThis closes #3996.,2
[FLINK-6709] [gelly] Activate strict checkstyle for flink-gelliesThis closes #3997.,2
[FLINK-6701] Activate strict checkstyle for flink-yarnThis closes #3990.,2
[FLINK-6720] Activate strict checkstyle in flink-java8,2
[FLINK-6720] Rename java8 javaApiOperators package to api.java.operatorsThis closes #3999.,1
[FLINK-6711] Activate strict checkstyle for flink-connector-twitter,2
[FLINK-6711] Activate strict checkstyle for flink-connector-nifi,2
[FLINK-6711] Activate strict checkstyle for flink-connector-rabbitmq,2
[FLINK-6711] Activate strict checkstyle for flink-jdbc,5
[FLINK-6711] Activate strict checkstyle for flink-hbase,2
[FLINK-6711] Activate strict checkstyle for flink-hcatalog,2
[FLINK-6711] Activate strict checkstyle for flink-elasticsearch*,2
[FLINK-6711] Activate strict checkstyle for flink-connector-kafka*,2
[FLINK-6711] Activate strict checkstyle for flink-connector-kinesis,2
[FLINK-6711] Activate strict checkstyle for flink-hadoop-compatibility,2
[FLINK-6711] Activate strict checkstyle for flink-connector-filesystem,5
[FLINK-6711] Activate strict checkstyle for flink-connector-cassandra,2
[FLINK-6711] Activate strict checkstyle for flink-avro,2
[FLINK-6711] Activate strict checkstyle for flink-connectorsThis closes #3992.,2
[FLINK-6137] Activate strict checkstyle for flink-cepThis closes #3976.,2
[FLINK-6699] Add checkstyle plugin to flink-yarn-tests pomThis closes #4005.,3
[FLINK-6760] [table] Fix OverWindowTest alias test errorThis closes #4007.,0
[FLINK-6736] [table] Fix UDTF field access with time attribute recordThis closes #4008.,0
[FLINK-6737] [table] Fix string reference variable errorThis closes #4000.,0
[hotfix] Update year in NOTICE file,2
[FLINK-6780] [table] ExternalTableSource should add time attributes in the row type.This closes #4023.,1
[FLINK-6753] [table] Fix flaky SqlITCase due to Janino bugThis closes #4010.,0
[FLINK-6766] [docs] Update documentation about async backends and incremental checkpointsThis closes #4011,2
[FLINK-6777] [shell] Activate strict checkstyleThis closes #4029,2
[FLINK-6779] [scala] Activate strict checkstyleThis closes #4030,2
[FLINK-6778] [dist] Activate strict checkstyleThis closes #4031,2
[FLINK-6560] [build] Restore maven parallelism in flink-testsConfigure a default value for Maven variable 'flink.forkCountTestPackage'.This closes #3875,3
[FLINK-6332] [build] Upgrade Scala versionsUpgrade to the last maintenance releases of Scala 2.10 and 2.11.This closes #3957,2
[FLINK-6038] [docs] Added deep links to Bahir connectorsThis closes #3975,2
[FLINK-6695] Activate strict checkstyle for flink-connector-wikiedits,2
[FLINK-6695] Activate strict checkstyle for flink-statebackend-rocksDB,5
[FLINK-6695] Activate strict checkstyle for flink-storm,2
[FLINK-6695] Activate strict checkstyle for flink-storm-examples,2
[FLINK-6695] Activate strict checkstyle for flink-streaming-contribThis closes #4004.,2
[FLINK-6722] [table] Activate strict checkstyleThis closes #4021.,2
[FLINK-6724] Include class name in UDFUtils#checkForInstantiation exceptionsThis closes #3995.,2
[FLINK-6729] Add checkstyle plugin to flink-runtime pomThis closes #4032.,2
[FLINK-6729] Activate checkstyle in runtime/accumulators,1
"[FLINK-6570] update queryable state documentation* adapt a left-over ""QueryableStateClient client = new QueryableStateClient(config);""* remove use of TestingUtils as it is only available to Flink testsThis closes #4028.",3
[FLINK-6478] [doc] Document how to upgrade state serializersThis closes #4006.,2
[hotfix] [doc] Incorrect example CLI command for Flink on Mesos,2
[FLINK-5340] Document job uptime/downtime/restartTime/fullRestarts metricsThis closes #3908.,2
[FLINK-6775] [state] Duplicate StateDescriptor's serializerDuplicate the TypeSerializer before returning it from the StateDescriptor. That waywe ensure that StateDescriptors can be shared by multiple threads.Add test case for AggregatingStateDescriptorFix OperatorStateBackendTest#testCorrectClassLoaderUsedOnSnapshotThis closes #4025.,3
[FLINK-6792] [mvn] Move maven-checkstyle-plugin before maven-shade-plugin definition in pom.xmlSomehow appending the maven-checkstyle-plugin at the end of the pom.xml changed the orderof the maven-assembly-plugin and the maven-shade-plugin in the package phase. This breaksthings since the shade plugin has to run before the assembly plugin to build the fat-jar.Specifying the checkstyle-plugin before the maven-shade-plugin resolves the issue.This closes #4042.,0
[FLINK-6466] [build] Build Hadoop 2.8.0 convenience binariesUpdate Hadoop versions and replace Hadoop 2.3 with 2.8 in build andcontinuous integration scripts. flink-yarn-tests can now be enabled forall supported Hadoop versions and is made non-optional.This closes #3832,1
[FLINK-6809] [docs] Correct variable name in java side-output exampleThis closes #4047,2
[FLINK-6793] Activate checkstyle for runtime/metricsThis closes #4037.,1
[FLINK-6794] Activate checkstyle for migration/**This closes #4038.,2
[FLINK-6795] Activate checkstyle for runtime/processThis closes #4040.,1
[FLINK-6781] Make statement fetch size configurable in JDBCInputFormat.This closes #4036.,5
[hotfix] Update DataSet docs concerning JDBCInputFormat.The way to provide type information was outdated.,5
[FLINK-6840] [ml] Correct documentation for multiple linear regression,2
[FLINK-6818] Activate checkstyle for runtime/historyThis closes #4051.,1
[FLINK-6819] Activate checkstyle for runtime/leaderretrievalThis closes #4053.,1
[FLINK-6824] Activate checkstyle for runtime/eventThis closes #4056.,1
[FLINK-6827] Activate checkstyle for runtime/webmonitorThis closes #4054.,1
[FLINK-6831] Activate checkstyle for runtime/*This closes #4057.,1
[FLINK-6797][docs] Docs do not build cleanly with new version of bundlerThis closes #4043.,1
"[FLINK-6837] [table] Fix a test case name error, a small error message bug, and improve some message info.This closes #4060",5
[FLINK-6816] [table] Fix wrong usage of Scala string interpolation in Table APIThis closes #4050.,0
[FLINK-6812] Enforce Java8 when creating a releaseThis closes #4048,1
"[FLINK-6845] [table] Cleanup ""println(StreamITCase.testResults)"" call in test casethis closes #4071",1
[FLINK-6723] Activate strict checkstyle for flink-librariesThis closes #4069.,2
[hotfix] [tests] Add serialVersionUID to InterruptLockingStateHandle in tests,3
[FLINK-6844] [scala] Implement compatibility methods for TraversableSerializerThis closes #4081.,2
[FLINK-6853] [DataStream] Let StreamRecordSerializer be compatible with MultiplexingStreamRecordSerializerThis commit lets StreamRecordSerializer.ensureCompatibility be tolerablefor config snapshots taken from the legacyMultiplexingStreamRecordSerializer. This is required for users whichoriginally used MultiplexingStreamRecordSerializer to serialize streamelements as part of their checkpointed state (e.g. FlinkCEP).This closes #4079.,2
[FLINK-6808] Implement snapshotConfiguration/ensureCompatibility for CoGroupedStreams.UnionSerializerThis closes #4052.,5
[FLINK-6830] [tests] Add StatefulJobSavepointFrom13MigrationITCase,1
[FLINK-6830] [tests] Port topology change migration ITCases for Flink 1.3,2
[FLINK-6830] [cep] Port CEPFrom12MigrationTest for Flink 1.3,2
[FLINK-6830] [fileSink] Port BucketingSinkFrom12MigrationTest for Flink 1.3,2
[FLINK-6830] [kafka] Port migration tests for FlinkKafkaConsumerBase to Flink 1.3This commit also consolidates all tests for migration from Flink 1.1 and1.2 for the FlinkKafkaConsumerBase to a single classFlinkKafkaConsumerBaseMigrationTest. Parameterization is used to testmigration from different Flink version savepoints.,2
[FLINK-6830] [DataStream] Port window operator migration tests for Flink 1.3This commit also consolidates all Flink 1.1 and 1.2 window operatormigration tests to a single WindowOperatorMigrationTest class.Parameterization is used to test restoring from different previous Flinkversion snapshots.,2
[FLINK-6830] [fileSource] Port continuous file reader migration tests for Flink 1.3This commit also consolidates all Flink 1.1 and 1.2 migration tests intoa single ContinuousFileProcessingMigrationTest class. Parameterizationis used to test restore from different previous Flink versions.This closes #4059.,2
[FLINK-6815] Fix javadocs by upgrading genjavadoc-plugin_2.10.6 to 0.10,2
[FLINK-6852] Fix misuse of GCDThis closes #4077.,1
[FLINK-6859][table] remove delete useless times for improve StateCleaningCountTriggerThis closes #4085.,4
[FLINK-6820] Activate checkstyle for runtime/filecacheThis closes #4062.,2
[FLINK-6834] [table] Support scalar functions on Over WindowThis closes #4070.,1
[FLINK-6783] Changed passing index of type argument while extracting return type.,4
[FLINK-6772] [cep] Fix ordering (by timestamp) of matched events.,0
[FLINK-6817] [table] Add OverWindowWithPreceding class to guide users apply preceding in over windowThis closes #4055,1
[FLINK-6876] [streaming] Correct the comments of DataStream#assignTimestampsAndWatermarksThis closes #4092,5
[FLINK-6198] [cep] [doc] Update CEP documentation.,2
[FLINK-6198] [cep] [doc] Update CEP documentation.,2
"[hotfix] [scala] Fix instantiation of Scala serializers' config snapshot classesPrior to this commit, the configuration snapshot classes of Scalaserializers did not have the proper default empty constructor that isused for deserializing the configuration snapshot.Since some Scala serializers' config snapshots extend the JavaCompositeTypeSerializerConfigSnapshot, their config snapshot classes arealso changed to be implemented in Java since in Scala we can only call asingle base class constructor from subclasses.",4
"[FLINK-6869] [scala] Specify serialVersionUID for all Scala serializersPreviously, Scala serializers did not specify the serialVersionUID, andtherefore prohibited restore from previous Flink version snapshotsbecause the serializers' implementations changed.The serialVersionUIDs added in this commit are identical to what theywere (as generated by Java) in Flink 1.2, so that we can at leastrestore state that were written with the Scala serializers as of 1.2.",2
"[FLINK-6869] [core] Tolerate serialVersionUID mismatches for Scala and anonymous serializersThis commit lets the TypeSerializerSerializationProxy be tolerable forserialVersionUID mismatches when reading anonymous classed serializersor our Scala serializers.Our Scala serializers require this since they use Scala macros to begenerated at compile time, and therefore is not possible to fix acertain serialVersionUID for them. For non-generated Scala serializers,we still also need this because their serialVersionUIDs pre-1.3 mayvary depending on the Scala version used.This can be seen as a workaround, and should be reverted once 1.2savepoint compatibility is no longer maintained.This commit also updates the streaming state docs to educate the user toavoid using anonymous classes for their state serializers.This closes #4090.",1
[hotfix] [cep] Fix incorrect CompatibilityResult.requiresMigration calls in CEP,1
"[FLINK-6883] [core] Refactor TypeSerializer to not implement TypeDeserializerThe separation of the TypeDeserializer interface from the TypeSerializerbase class is due to the fact that additionally implementing theTypeDeserializer interface alters the generation order of anonymosserializer classes for Scala case classes and collections.Instead, the TypeDeserializer is now used as a mixin on theTypeDeserializerAdapter utility, which now serves as a bridge forboth directions (i.e. TypeSerializer to TypeDeserializer, and viceversa). No user interfaces are broken due to this change.",4
"[FLINK-6883] [tests] Add migration tests for Scala jobsThis commit adds migration ITCases for jobs written using the Scala API.An extra concern for migration of Scala jobs is that Scala case classesand collections use anonymous generated serializers, which may affectstate restore.This closes #4103.",1
[FLINK-6796] [tests] Use Environment's class loader in AbstractStreamOperatorTestHarnessGeneralize KeyedOneInputStreamOperatorTestHarnessGeneralize AbstractStreamOperatorTestHarness,3
"[FLINK-6803] [tests] Add test for PojoSerializer state upgradeThe added PojoSerializerUpgradeTest tests the state migration behaviour when theunderlying pojo type changes and one tries to recover from old state. Currentlynot all tests could be activated, because there still some pending issues to befixed first. We should arm these tests once the issues have been fixed.",0
[hotfix] [tests] Fix failing tests in AsyncWaitOperatorTest and StateBackendTestBase,3
"[FLINK-6803] [tests] Enhancements to PojoSerializerUpgradeTest1. Allow tests to ignore missing fields.2. Add equivalent tests which use POJOs as managed operator state.For 2, all tests have to be ignored for now until FLINK-6804 is fixed.",0
"[FLINK-6801] [core] Relax missing fields check when reading PojoSerializerConfigSnapshotPrior to this commit, when reading the PojoSerializerConfigSnapshot, ifthe underlying POJO type has a missing field, then the read would fail.Failing the deserialization of the config snapshot is too severe,because that would leave no oppurtunity to restore the checkpoint atall, whereas we should be able to restore the config and provide it tothe new PojoSerializer for the change of getting a convert deserializer.This commit changes this by only restoring the field names when readingthe PojoSerializerConfigSnapshot. In PojoSerializer.ensureCompatibility,the field name is used to lookup the fields of the new PojoSerializer.This change does not change the serialization format of thePojoSerializerConfigSnapshot.",5
"[FLINK-6801] [core] Allow deserialized PojoSerializer to have removed fieldsPrior to this commit, deserializing the PojoSerializer would fail whenwe encounter a missing field that existed in the POJO type before. It isactually perfectly fine to have a missing field; the deserializedPojoSerializer should simply skip reading the removed field's previouslyserialized values, i.e. much like how Java Object Serialization works.This commit relaxes the deserialization of the PojoSerializer, so that anull will be used as a placeholder value to indicate a removed fieldthat previously existed. De-/serialization and copying methods on thePojoSerializer will respect null Fields and simply skip them.",4
"[FLINK-6804] [state] Consistent state migration behaviour across state backendsPrior to this commit, memory and non-memory state backends behaveddifferently w.r.t. state migration. For the memory backends, we didnot require the new serializer to be compatible in order for the job toproceed after restore, because all state have already been deserializedto objects and the new serializer can always just be used as is.Therefore, the compatibility checks were not performed for the memorybackends, resulting in different code paths between the different statebackends.However, this inconsistent behaviour across backends will be confusingfor users. This commit adds the code path to check the newly registeredserializer's compatibility in the memory backends (even though it isn'trequired), and deliberately fails the job if the new serializer isincompatible.Note that the compatibiilty code paths will be truly unified andrequired for all backends once we have eager state registration.This closes #4073.",1
"[FLINK-6803] [tests] Fully enable PojoSerializerUpgradeTests for all state backendsWith the fixes for the PojoSerializer in, this commit fully enables alltests for upgrading the PojoSerializer for all state backends, whichotherwise could not pass before.This closes #4044.",4
[FLINK-6848] [doc] Update managed state docs to include Scala snippetsAdd an example of how to work with managed state in Scala.This closes #4072.,1
[FLINK-6899] [state] Create correctly sized state array in NestedMapsStateTableThis closes #4107.,1
"[FLINK-6833] [task] Fail StreamTask only due to async exception if it is runningIn order to resolve a race condition between a properly terminated StreamTask whichcleans up its resources (stopping asynchronous operations, etc.) and a cancelledasynchronous operation (e.g. asynchronous checkpointing operation), we check whetherthe StreamTask is still running before failing it externally.This closes #4058.",0
[FLINK-6744] [tests] Harden ExecutionGraphSchedulingTest.testDeployPipelinedConnectedComponentsTogetherIncrease the timeout for the verification check that the TaskManagerGateway#submitTaskmethod has been called.,3
[FLINK-6685] Adjust scopes of SafetyNetCloseableRegistry usagesThis closes #4108.,1
[hotfix] [tests] Fix failing Scala StatefulJobSavepointMigrationITCase,0
[FLINK-6884] [table] Improve confused exception information.This closes #4100,5
[FLINK-6776] [runtime] Use skip instead of seek for small forward repositioning in DFS streams,1
[FLNK-5354] [docs] Restructured Table API / SQL docs,2
[FLINK-6747] [table] [docs] Time attributes section addedThis closes #4020.,1
[FLINK-6745] [table] [docs] Updated Table API / SQL docs: OverviewThis closes #4013.,2
[FLINK-6746] [table] [docs] Updated Table API / SQL docs: Common APIThis closes #4012.,2
[FLINK-6749] [table] [docs] Updated Table API / SQL docs: SQL,2
[FLINK-6748] [table] [docs] Reworked Table API PageThis closes #4093.,1
[FLINK-6750] [table] [docs] Rework Table Sources & Sinks PageThis closes #4094.,1
[hotfix] Additional tests for HadoopDataInputStream#skip vs #seek,5
[hotfix] Removed lamba indices for type extraction for abstract classes,4
[FLINK-6930] [table] Forbid selecting window start/end on row-based Tumble/Slide windowsThis closes #4133,2
[FLINK-6886] [table] Fix conversion of Row Table to POJO.This closes #4102.,0
[FLINK-6602] [table] Prevent TableSources with empty time attribute names.This closes #4135.,2
[FLINK-6941] [table] Validate that start and end window properties are not accessed on over windows.This closes #4137.,5
[FLINK-6904] [cep] Support for quantifier range to CEP's pattern APIThis closes #4121,1
[FLINK-6929] [table] Add documentation for Table API over windows.This closes #4141.,2
[FLINK-6881] [FLINK-6896] [table] Creating a table from a POJO and defining a time attribute failsThis closes #4144.This closes #4111.,0
"[FLINK-6921] [serializer] Allow EnumValueSerializer to deal with appended enum valuesThe problem was that we don't check the bounds of the array with the enum names containedin the ScalaEnumSerializerConfigSnapshot.This PR also adds an Enumeration upgrade test which makes sure that appended fields aresupported without migration. Moreover, it checks that a field removal and an order changeleads to a required migration.This closes #4126.",1
"[FLINK-6948] [serializer] Harden EnumValueSerializer to detect changed enum indicesThis PR changes the seriailization format of the ScalaEnumSerializerConfigSnapshot to also include theordinal value of an enum value when being deserialized. This allows to detect if the ordinal valueshave been changed and, thus, if migration is required.IMPORTANT: This PR changes the serialization format of ScalaEnumSerializerConfigSnapshot.Remove backwards compatibility path for 1.3.1This closes #4142.",5
[FLINK-6922] [serializer] Remove Java serialization from Enum(Value)SerializerConfigSnapshotThis commit removes the use of Java serialization for serializing theenum class and constants in the Java EnumSerializerConfigSnapshot andScala ScalaEnumSerializerConfigSnapshot.This closes #4147.,5
[FLINK-6652] [core] Fix handling of delimiters split by buffers in DelimitedInputFormatThis closes #4088.,0
"[FLINK-6836] [tests] Fix YARNSessionCapacitySchedulerITCase to work with Hadoop 2.6.5, 2.7.3 and 2.8.0Due to MNG-5899, maven cannot resolve dependency reduced poms in a multi project build. Therefore,flink-yarn-tests pulls in a wrong version of org.apache.httpcomponents.httpclient which does not workwith Hadoop's ServletUtils together. As a solution we have to move the dependency management for thehttpclient and httpcore version into the parent pom.xml.Another problem is the version of these libraries which has been recently bumped. In 4.4, httpclientchanged its behaviour such that URLEncodedUtils#parse(String, Charset) now throws a NPE if the firstparameter is null. In 4.2.6, an empty list was returned instead. Due to this incompatibility, we revertedthe change and set the version to its previous value.Bump httpclient to 4.5.3 and httpcore to 4.4.6This closes #4120.",1
"[FLINK-6918] [tests] Harden AbstractOperatorRestoreTestBase by retrying CancelWithSavepoint messagesThe problem is that a StreamTask can be in state RUNNING without internally being running.As a consequence checkpoint message will be discarded. This problem will be solved onceFLINK-4714 has been addressed. Until then, we harden the test case by retrying theCancelWithSavepoint message.This closes #4129.",1
"[FLINK-6945] Fix TaskCancelAsyncProducerConsumerITCase by removing race conditionThe TaskCacnelAsyncProducerConsumerITCase#testCancelAsyncProducerAndConsumer test casesometimes failed with a NPE because of a race condition. The problem was that someinvokables set static fields which are checked in the main thread. Since we checkedthe wrong field, the one for the consumer, after making sure that the produceris running, this could lead to a race condition if the consumer wasn't running yet.This closes #4139.",1
[FLINK-6874] [docs] Static and transient fields ignored for POJOsNote that static and transient fields are ignored when TypeExtratorvalidates a POJO.This closes #4091.,5
[FLINK-6806] [docs] Add RocksDB to listed state backends in docThis closes #4045.,2
[hotfix] [docs] Fix typo in docs (Souce -> Source)Includes such typos in:1. docs/fig/state_partitioning.svg2. docs/dev/table_api.mdThis closes #4119.,2
[FLINK-6932] [doc] Update inaccessible Dataflow Model paper linkThis closes #4131.,2
[FLINK-6937] [docs] Fix broken link in Production Readiness ChecklistThis closes #4134.,2
[FLINK-6952] [docs] Add link to Javadocs,2
"[FLINK-6985] [docs] Remove bugfix version from titleRemoves the bugfix version from title and other places where itcan potentially be confusing.For snapshot release, version and version_short should be thesame, e.g. 1.4-SNAPSHOT. For stable releases, version should bethe full version string (e.g. 1.2.1) whereas version_shortshould skip the bugfix version (e.g. 1.2):.This closes #4162.",0
"[FLINK-6952, FLINK-6985] [docs] Fix Javadocs linksThis is a follow up to e7c887c and 0287758. For snapshot versionswe need to differntiate between title version and javadocs version.In addition, this removes an unneded config variable and updatesthe release scripts.",5
[FLINK-6237] [table] support RAND and RAND_INTEGER on SQLThis closes #3660.,1
[FLINK-6237] [table] Performance improvements and code clean up,4
[hotfix] Improve readability in SPV2#convertToOperatorStateSavepointV2,1
[FLINK-6742] Improve savepoint migration failure error messageThis closes #4083.,1
[FLINK-6920] Remove minor guava usagesThis closes #4124.,4
"[FLINK-6769] Replace usage of deprecated FileSystem#create(Path, boolean)This closes #4116.",5
[FLINK-6863] Remove batch dependency from streaming-examplesThis closes #4115.,4
[FLINK-6868][build] Using `scala.binary.version` for `flink-streaming-scala` in `Cassandra Connector`This closes #4087.,2
[FLINK-6798][docs] update old network buffer noticesThis closes #4080.,1
[FLINK-6784][docs] update externalized checkpoints documentationThis closes #4033.,2
[FLINK-6788] Remove unsused GenericFlatTypePostPass/AbstractSchema classesThis closes #4118.,4
[hotfix][docs] update Checkpoint docs with correct code example,2
[FLINK-6782][docs] update snapshot documentation to reflect flink 1.3This closes #4024.,2
[FLINK-6541] Improve tmp dir setup in TM/WebMonitorThis closes #3894.,1
[FLINK-6682] [checkpoints] Improve error message in case parallelism exceeds maxParallelismThis closes #4125.,0
[FLINK-6488] [scripts] Deprecate 'start-local.sh' and 'stop-local.sh' scriptsThis closes #4074.,2
[hotfix] Fix typo in JobManager,2
[FLINK-6943] Improve exceptions within TypeExtractionUtils#getSingleAbstractMethodThis closes #4140.,4
[FLINK-6967] Remove batch-examples dependency from storm examplesThis closes #4159.,4
[FLINK-6956] Make table example POJO classes publicThis closes #4148.,1
[FLINK-6786] [metrics] Deduplicate QueryScopeIntoTestThis closes #4034.,3
[FLINK-6389] [connector] Upgrade hbase dependency to 1.3.1This closes #4151.,2
[FLINK-6774][build] set missing build-helper-maven-plugin versionThis closes #4017.,1
"[FLINK-6999] [build] Print TravisCI CPU, memory, and filesystem infoThis closes #4177",5
[FLINK-6960] [table] Support E() on SQL.This closes #4152,1
[FLINK-6942] [table] Add E() support in Table APIThis closes #4181.,1
[FLINK-6994] [docs] Wrong base url in master docsThis closes #4175.,2
[FLINK-6418][cep] Support for dynamic state changes in CEP patternsThis closes #4143.,4
"[hotfix] [docs] Fix description of ""following"" for Table API over windows.This closes #4161.",0
[FLINK-7005] [table] Optimization steps are missing for nested registered tablesThis closes #4186.,2
[FLINK-7004] Switch to Travis Trusty image- enable sudo for more memory- increase java heap size- replace usage of oraclejdk7 since it is no longer supporter- manually install maven 3.2.5This closes #4182.,1
[FLINK-7014] [table] Expose isDeterministic interface to UserDefinedFunctionThis closes #4200,1
[FLINK-6379] [mesos] Add Mesos ResourceManager (FLIP-6)- Make the RPC gateway of the ResourceManager extensible to allow for framework-specific RPC methods- Introduce FLIP-6 MesosResourceManager w/ tests- Introduce a Mesos-specific RPC gateway for callbacks from child actors and from the Mesos scheduler client- Enhance the persistent Mesos worker store to track the resource profile associated with a worker- Convert RegisteredMesosWorkerNode to Java- Decline TE registration if framework doesnt recognize the workerThis closes #3942.,1
[FLINK-6379] [tests] Fix race condition in MesosResourceManagerTestThe MesosResourceManagerTest#testAdapter tests the AkkaAdapter class. The testsare executed asynchronously and thus it is necessary to introduce timeouts forthe verify calls. This commit fixes the test instability by introducing timeouts.,3
"[FLINK-6379] Remove internal methods from MesosResourceManagerGatewaySome internal methods which are required for the interplay between the TaskMonitor,LaunchCoordinator and the MesosResourceManager were exposed as RPC methods. In orderto keep the RPC interface as lean as possible, these methods have been removed.Fix checkstyle violations",4
[FLINK-6989] [gelly] Refactor examples with Output interfaceThe current organization of the Gelly examples retains full flexibilityby handling the Graph input to the algorithm Driver and having theDriver overload interfaces for the various output types. The outputsmust be made independent in order to support Transforms which areapplied between the Driver and Output (and also between the Input andDriver).This closes #4179,1
[FLINK-7008] [cep] Update NFA state only when the NFA changesThis closes #4195.,4
[FLINK-3551] [examples] Sync Scala streaming examples with Java examples.- Move Java example tests into a single ITCase- Add ITCase for Scala examplesThis closes #2761.,1
[FLINK-7025] [table] Port non-partitioned unbounded proctime Over window to keyed state.This closes #4212.,2
[FLINK-6710] Remove Twitter-InputFormat,4
[FLINK-6075] [table] Add ORDER BY support for streaming table.This closes #3889.,1
[FLINK-4022] [kafka] Partition / topic discovery for FlinkKafkaConsumerThis closes #3746.,2
"[FLINK-7011] [kafka] Remove Kafka testStartFromKafkaCommitOffsets ITCasesThe testStartFromKafkaCommitOffsets ITCases are covering too much withinone single test. The case verifies that whatever offset was committed toKafka, Flink rreads it correctly and can uses that as the correctstarting point for exactly-once.This over-engineered test was instable that we needed to first read somerecords and wait until some records is committed. This wait is hard todefine.It is in fact sufficient to have 2 separate tests to cover the testedbehaviour:- test that committed Kafka offsets are correct (there is already a  ITCase for this, i.e. `runCommitOffsetsToKafka`)- test that committed offsets are correctly picked up and used correctly  (there is actually also a test for this, i.e.`runStartFromGroupOffsets`)Hence, this test can be removed without harming test coverage.This closes #4190.",3
"[FLINK-6867] [elasticsearch] Fix instable Elasticsearch 1.x ITCasesThe root cause for the instability in ES 1.x is that we're testing bothembedded client mode and transport client mode against the sameElasticsearch environment. This commit removes the embedded modetesting, as that method is generally discouraged anyways.This closes #4191.",3
[FLINK-6789] [optimizer] Remove duplicated test utility reducer in optimizerThis closes #4216.,3
[FLINK-6496] [security] Port SSL config parameters to ConfigOptionsThis closes #3855.,5
"[FLINK-6376] [yarn] Always upload HDFS delegation token for secured YARN deploymentsPreviously, YARN log aggregation fails because it depoends on the HDFSdelegation token, which we do not upload if Kerberos keytabs are used.We did not include HDFS delegation tokens when keytabs are used becausethe UGI would prioritize the delegation token (which expires) if bothare present.To address this, changes include:1. Change Flink YARN client to always upload delegation tokens whensecurity is enabled. This would then allow log aggregation.2. Filter out HDFS delegation token from the tokens fetched from HDFSwhen populating the UGI. This allows the UGI to always use Kerberostickets instead of the HDFS delegation token.",1
[FLINK-6376] [yarn] Improve inline code comments related to HDFS delegation token inclusionThis closes #3776.,1
[FLINK-6575] [tests] Disable tests on Windows that use HDFSThis closes #6575.,1
[FLINK-6674] [docs] Bootstrap API Migration docs update for 1.2 -> 1.3,5
"[FLINK-6680] [docs] Update ""Upgrading Applications and Flink Versions"" for 1.3This closes #4211.",2
[FLINK-6785] [metrics] Fix ineffective asserts in MetricRegistryTestThis closes #4035.,3
[FLINK-6898] [metrics] Limit size of operator component in metric nameThis closes #4109.,1
[FLINK-6461] Replace usages of deprecated web port keyThis closes #3951.,2
[FLINK-7000] Add custom configuration local environment in Scala StreamExecutionEnvironmentThis closes #4178.,5
[FLINK-5488] Close YarnClient on error in AbstractYarnClusterDescriptorThis closes #4022.,0
[FLINK-6498] Migrate Zookeeper configuration optionsThis closes #4123.,5
[FLINK-6638] Allow overriding default for primitive ConfigOptionThis closes #4016.,5
[FLINK-6742] Add eager checks for parallelism/chain-length changeThis closes #4185.,4
[FLINK-6221] Add PrometheusReporterThis closes #3833.,1
[FLINK-6987] Fix TextInputFormatTest for paths with spacesThis closes #4168.,3
[FLINK-5918] [runtime] port range support for taskmanager.rpc.portThis closes #3416.,1
[FLINK-6655] Add validateAndNormalizeUri method to MemoryArchivistThis closes #4156.,5
[FLINK-6908] Remove batch/streaming arg from start-cluster.shThis closes #4197.,4
[FLINK-7030] Build with scala-2.11 by defaultThis closes #4209.,2
[FLINK-7048] [travis] Define javadoc skipping in travis watchdog scriptThis closes #4227.,2
[FLINK-7046] [travis] Hide download logging messagesThis closes #4226.,2
[FLINK-5893] [RM] Fix the bug of race condition for removing previous JobManagerRegistration in ResourceManagerThis closes #3399.,4
[FLINK-6310] Use correct lock for synchronization in LocalExecutor,1
[FLINK-7066] [tests] Fix integration tests in airplane modeThis closes #4247.,3
[FLINK-7012] remove user-JAR upload when disposing a savepoint the old wayThis closes #4245.,1
"[FLINK-7032] [build] Overwrite inherited compiler versions from parent pomDefault values for compiler version are 1.6 and were causing Intellij toconstantly switch language level to 1.6, which in turn was causingcompilation errors. It worked fine for compiling from console usingmaven, because those values are separetly set in maven-compiler-pluginconfiguration.This closes #4213.",5
[FLINK-6773] [checkpoint] Introduce compression (snappy) for keyed state in full checkpoints and savepoints,2
[FLINK-6773] [documentation] Added documentation for compressed checkpoints,2
"[FLINK-7070] Use properly built custom jar in ScalaShellITCaseBefore, the external jar loading tests where using the flink-ml jarwithout the scala shell package actually declaring this as a dependency.Now we built our own jar and have no unlisted dependencies anymore.This closes #4249.",2
[FLINK-6880] [runtime] Activate checkstyle for runtime/iterativeThis closes #4098.,1
[FLINK-6877] [runtime] Activate checkstyle for runtime/securityThis closes #4095.,1
[FLINK-6821] [runtime] Activate checkstyle for runtime/fsThis closes #4063.,1
[FLINK-7039] [build] Increase forkCountTestPackage for sudo-enabled TravisCIThe switch from the container-based to sudo-enabled environment inTravisCI has increased available memory from 4 GB to 7.5 GB so use aforkCount of 2 in all packages including flink-test.This closes #4222.,3
[FLINK-6826] [runtime] Activate checkstyle for runtime/netThis closes #4065.,1
"[FLINK-6008] Collection of BlobServer improvements- [docs] update some config options to the new, non-deprecated ones- [docs] improvements in the BlobService docs- use Preconditions.checkArgument in BlobClient- refactor BlobCache#getURL()- do not fail the BlobServer if delete fails- fix concurrent job directory creation- do not guard a delete() call with a check for existence- cleanup javadocs in (Blob)LibraryCacheManager- cleanup tests for BlobLibraryCacheManagerThis closes #4146.",3
[hotfix] Fix typos in Task and JobManager,2
[FLINK-6043] [web] Display exception timestampThis closes #3583.,2
Rebuild web-frontend,5
[FLINK-7037] Remove scala suffic from flink-examples moduleThis closes  #4221.,2
[FLINK-6823] Activate checkstyle for runtime/broadcastThis closes #4068.,1
[FLINK-6927] [cep] Support pattern group in CEPThis closes #4153,1
[FLINK-7061] [cep] Fix quantifier range starting from 0This closes #4242,0
"[FLINK-7093] [tm] Send SlotReport as part of the heartbeat payload to the ResourceManagerThe TaskManager sends the SlotReport as part of the heartbeat payload to the ResourceManager.That way, the ResourceManager can sync its internal view on the slot allocation with the actualallocation state.This closes #4251.",2
"[FLINK-7074] [tm] Add entry point for the TaskManagerRunnerThe entry point can be used by the standalone mode to run a TaskManager. Moreover, theYarnTaskExecutorRunner now reuses some of the start up logic of the TaskManagerRunner.This closes #4252.",1
[FLINK-7097] [scripts] Enable Flip-6 TaskExecutor to be started with taskmanager.shThe taskmanager.sh script now supports to start a TaskExecutor by providing flip6 asa second argument to the script.This closes #4253.,1
[FLINK-6925] [table] Add CONCAT/CONCAT_WS supported in SQLThis closes #4138,1
[FLINK-7045] [tests] Reduce element count of UdfStreamOperatorCheckpointingITCaseThis closes #4230,1
[FLINK-6879] [runtime] Activate checkstyle for runtime/memoryThis closes #4097,1
[FLINK-7006] [gelly] Base class using POJOs for Gelly algorithmsGelly algorithms commonly have a Result class extending a Tuple type andimplementing one of the Unary/Binary/TertiaryResult interfaces.Add a Unary/Binary/TertiaryResultBase class implementing each interfaceand convert the Result classes to POJOs extending the base resultclasses.This closes #4201,1
[FLINK-7023] [gelly] Remaining types for Gelly ValueArraysAdd implementations of Byte/Char/Double/Float/ShortValueArray. Alongwith the existing implementations of Int/Long/Null/StringValueArray thiscovers all 10 CopyableValue types.This closes #4203,1
"[hotfix] [docs] Added missing ""more"" word to programming-model docs.This closes #4244.",2
[FLINK-7038] [docs] Correct misused term (KeyedDataStream -> KeyedStream),5
"[FLINK-7038] Correct misused terms (WindowedDataStream, JoinedDataStream)This closes #4229.",5
[FLINK-7041] Deserialize StateBackend from JobCheckpointingSettings with user classloaderThis closes #4232.,1
[FLINK-6499] [config] Migrate state configuration optionsThis closes #4173.,5
[FLINK-6996] [kafka] Fix at-least-once semantic for FlinkKafkaProducer010This closes #4206.,2
[FLINK-6422] [core] Unreachable code in FileInputFormat#createInputSplitsThis closes #4202.,2
[FLINK-7044] [qs] Allow to specify namespace and descriptor in query.,1
[FLINK-7109] [hadoop] Remove GlobalConfiguration.loadConfiguration from HadoopUtils#getHadoopConfigurationThe HadoopUtils#getHadoopConfiguration should not load the global configuration. Insteadwe pass it in as parameter.This closes #4265.,2
[FLINK-7116] [rpc] Add getPort to RpcServiceThe RpcService should expose its port it is bound to. That way it is easier to connect to aremote RpcService.This closes #4275.,1
"[FLINK-7117] [ha] Add HighAvailabilityServices.getJobManagerLeaderRetriever(jobId, defaultJobManagerAddress)The getJobManagerLeaderRetriever method with the defaultJobManagerAddress parameter is necessary forthe standalone HA services case. The TaskExecutor don't know at creation time of the HA services,where the JobManager will be executed. Therefore, we need this way to pass in the JobManageraddress at runtime.This closes #4276.",1
[FLINK-6842] [runtime] Uncomment and activate code in HadoopFileSystemThis closes #4219,5
[FLINK-7042] [yarn] Fix jar file discovery flink-yarn-testsAdd dependencies for batch and streaming WordCount programs and copiesthe jar files into a new target/programs directory. The integrationtests now directly references the program jar files rather than theprior brittle search.This removes the flink-yarn-tests build-time dependency on the examplesmodules (there remains a build-time dependency on flink-dist).This closes #4264,2
[FLINK-7069] [metrics] Granular exception catching in MetricRegistryThis closes #4248.,1
[FLINK-6828] Activate checkstyle for runtime/deploymentThis closes #4066.,1
[FLINK-6825] Activate checkstyle for runtime/heartbeatThis closes #4067.,1
[FLINK-6822] Activate checkstyle for runtime/plugableThis closes #4064.,1
[FLINK-6302] Documentation build error on ruby 2.4This closes #3720.,0
[FLINK-6878] [runtime] Activate checkstyle for runtime/queryThis closes #4096.,1
[FLINK-7099] Replace usages of deprecated JOB_MANAGER_IPC_PORT_KEY and JOB_MANAGER_IPC_ADDRESS_KEYThis closes #4278.,1
[FLINK-6747] [docs] Add documentation for QueryConfig.This closes #4256.,5
[FLINK-7063] [checkpoint] Call super.cancel(...) before closing streams in AsyncStoppableTaskWithCallback,2
[FLINK-7111] [scala-shell] Disable external jar testThis closes #4288.,3
[FLINK-6058] Don't read DEFAULT_PARALLELISM from GlobalConfiguration,5
[FLINK-6882] [runtime] Activate checkstyle for runtime/registrationThis closes #4099,1
[FLINK-6903] [runtime] Activate checkstyle for runtime/akkaThis closes #4114,1
[FLINK-6407] [build] Upgrade AVRO to 1.8.2This closes #4205,2
[FLINK-6357] [java] ParameterTool get unrequested parametersAdds ParameterTool#getUnrequestedParameters returning a Set<String> ofparameter arguments names not yet requested by ParameterTool#has or anyof the ParameterTool#get methods.This closes #4169,2
"[FLINK-6358] [gelly] Write job details for Gelly examplesAdd an option to write job details to a file in JSON format. Job detailsinclude: job ID, runtime, parameters with values, and accumulators withvalues.This closes #4170",2
"[FLINK-7019] [gelly] Rework parallelism in Gelly algorithms and examplesFlink job parallelism is set with ExecutionConfig#setParallelism or with-p on the command-line. The Gelly algorithms JaccardIndex, AdamicAdar,TriangleListing, and ClusteringCoefficient have intermediate operatorswhich generate output quadratic in the size of input. These algorithmsmay need to be run with a high parallelism but doing so for alloperations is wasteful. Thus was introduced ""little parallelism"".This can be simplified by moving the parallelism parameter to the newcommon base class with the rule-of-thumb to use the algorithmparallelism for all normal (small output) operators. The asymptoticallylarge operators will default to the job parallelism, as will the defaultalgorithm parallelism.This closes #4282",1
[FLINK-7133] Exclude optional asm deps from Elasticsearch base moduleThese ASM dependencies where shaded into the elasticsearch-base modulewhich where then clashing with our newer (also shaded) ASM dependency.,1
[FLINK-7052][blob] remove unused NAME_ADDRESSABLE modeThis closes #4158.,1
"[FLINK-7103] [dispatcher] Add skeletal structure of Dispatcher componentThe Dispatcher is responsible for receiving job submissions, persisting the JobGraphs,spawning JobManager to execute the jobs and recovering the jobs in case of a masterfailure. This commit adds the basic skeleton including the RPC call for job submission.Add cleanup logic for finished jobsPass BlobService to JobManagerRunnerThis closes #4260.",1
[FLINK-7017] Remove netty usages in flink-testsThis closes #4196.,3
[FLINK-6965] Include snappy-java in flink-distThis closes #4160.,2
[FLINK-7149] [connectors] Add checkpoint ID to 'sendValues()' in GenericWriteAheadSink,1
"[FLINK-7150] [elasticsearch connector] Various code cleanups in the ElasticSearch connector - Removes Serializable from the RequestIndexer, because they are neither required to be   serializable (they are created in open()) nor is the main implementation   (BulkProcessorIndexer) actually serializable. - Makes BulkFlushBackoffPolicy a static inner class, which avoids adding outer class during   serialization and clears various warnings about raw reference to outer classThis closes #4298",2
[hotfix] [docs] Fix Java typo in dataset transformations docThis closes #4300,2
[FLINK-7136] [docs] Improve search by adding facets and turning off adsThis closes #4291,1
[FLINK-7138] [storm] Include WordCountData in example jars,5
[FLINK-7131] [streaming] Include WordCountData in example jars,5
[FLINK-7047] [travis] Reorganize build profiles,2
[FLINK-7132] [java] Fix BulkIteration parallelismCopy the parallelism when translating a BulkIteration.This closes #4283,0
[FLINK-6731] [tests] Activate strict checkstyle for flink-testsThis closes #4295,3
[FLINK-6888] [table] Fix can't determine TypeInformation of ACC type of AggregateFunction when ACC is a Scala classThis closes #4105,1
[FLINK-7126] [table] Support Distinct for Stream SQL and Table APIThis closes #4279,1
[FLINK-7034] Bump Dropwizard Metrics version to 3.2.3,4
[FLINK-6902] Activate strict checkstyle for flink-streaming-scala,2
[FLINK-6901] Make strict-checkstyle the default,1
[FLINK-6865] Update checkstyle documentation,2
[FLINK-6934] [util] remove unused LRUCache class,1
[FLINK-7161] Fix misusage of Float.MIN_VALUE and Double.MIN_VALUEfix float overflow checksuse POSITIVE_INFINITY instead of MAX_VALUEchange float overflows and underflows checksThis closes #4305.,4
[FLINK-6617][table] Improve JAVA and SCALA logical plans consistent testThis closes #3943.,3
"[FLINK-6617] [table] Restructuring of tests- tests are named like the operator or feature that they are testing e.g. Calc, Distinct etc.- all tests have the same name everywhere (OverWindowTest, OverWindowValidationTest, OverWindowITCase, OverWindowStringExpressionTest)- no packages with one class- org.apache.flink.table.api contains all tests that test the translation from batch/stream/table/sql APIs- org.apache.flink.table.plan contains all tests that modify the plan- org.apache.flink.table.runtime contains all ITCases and runtime relevant tests- all other package contain unit tests for the classes of the same package",3
[hotfix] [docs] Fix broken links in 1.2 -> 1.3 API migration docs,2
[FLINK-7173] [doc] Change the illustration of tumbling window,4
[FLINK-7173] Also change the illustration of sliding-windows,4
[FLINK-6693] [table] Support DATE_FORMAT function in the Table / SQL API.This closes #4078.,1
[FLINK-6693] [table] Support dateFormat() function in Scala Table API.- Add dateFormat() to Table API documentation.,2
[hotfix] [table] Fix typo in DataStreamRel ScalaDocs.This closes #4303.,2
[FLINK-7154] [docs] Missing call to build CsvTableSource exampleThe Java and Scala example code for CsvTableSource create a builder butare missing the final call to build.This closes #4313.,1
[FLINK-6964] [checkpoint] Fix externalized incremental checkpoints for StandaloneCompletedCheckpointStore,0
[FLINK-6975] [table] Add CONCAT/CONCAT_WS supported in Table APIThis closes #4274.,1
[FLINK-6887] [table] Split up CodeGenerator into several specific CodeGeneratorThis closes #4171.,2
[FLINK-7101][table] add condition of !stateCleaningEnabled is avoided non-grouped window state to be cleaned up too earlyThis closes #4348.,4
[FLINK-6232] [table] Add support for processing time inner windowed stream join.,1
[FLINK-6232] [table] Add SQL documentation for time window join.- Add support for window join predicates in WHERE clause.- Refactoring of WindowJoinUtil.- Minor refactorings of join classes.This closes #4324.,4
[hotfix] [hadoopCompat] Fix tests to verify results new Hadoop input API.This closes #4325.,1
[FLINK-6811] [table] Add TIMESTAMPADD support in SQLThis closes #4076.,1
[hotfix] [tests] Workaround for WaitForAllVerticesToBeRunning not working in TestingCluster,3
[FLINK-6891] [table] Add LOG support in SQLThis closes #4122.,1
[FLINK-7178] [metrics] Do not create separate shaded jarsThis closes #4326.,1
"[FLINK-7212][tests] re-enable JobManagerLeaderSessionIDITCaseThis test was previously named JobManagerLeaderSessionIDITSuite and has notbeen executed for a while by maven because of it having the wrong namingscheme. After a renaming, it runs again but needed a minor change to besuccessful again which is included in this commit.This closes #4354.",4
[FLINK-7186] Activate checkstyle flink-java/samplingThis closes #4339.,2
[FLINK-7189] Activate checkstyle flink-java/utilsThis closes #4336.,2
[FLINK-7182] Activate checkstyle flink-java/functionsThis closes #4333.,2
"[FLINK-6550] Reject null OutputTags in Context#collect(OutputTag<X>, X)This closes #4312.",2
[FLINK-7183] Activate checkstyle flink-java/aggregationThis closes #4332.,2
[FLINK-7058] Fix scala-2.10 dependenciesThis closes #4240.,0
[FLINK-7184] Activate checkstyle flink-java/hadoopThis closes #4341.,2
[FLINK-7162] [test] Introduce TemporaryFolder in runtime testsThis closes #4311.,3
[FLINK-7102] improve ClassLoaderITCase* ClassLoaderITCase unnecessarily runs multiple tests in a single test case* ClassLoaderITCase#testDisposeSavepointWithCustomKvState() does not cancel its  job (thus the order of execution of test cases defines the outcome)* ClassLoaderITCase uses e.getCause().getCause() which may cause  {{NullPointerException}}s hiding the original errorThis closes #4255.,0
[FLINK-7222] [kafka] Fix invalid symbol * when create directory on windowsThis closes #4361.,1
[FLINK-7197] [gelly] Missing call to GraphAlgorithmWrappingBase#canMergeConfigurationWith()Fix for methods calling the incorrect super function.This closes #4345.,1
[FLINK-5541] Missing null check for localJar in FlinkSubmitter#submitTopologyThis closes #4315.,2
[FLINK-7204] [core] CombineHint.NONEAdd a new option to CombineHint which excludes the creation of acombiner for a reduce function.Gelly now excludes the combiner when simplifying graphs as used in mostalgorithm unit and integration tests.This closes #4350,3
[FLINK-7230] [travis] Disable snapshot updatesThis closes #4377.,5
[hotfix] Backwards compatible deserialization of RocksDB backend UUIDs,5
[FLINK-6654] [build] Let 'flink-dist' properly depend on 'flink-shaded-hadoop2-uber'This closes #3960,2
[FLINK-7233] [tests] Fix instable TaskManagerHeapSizeCalculationJavaBashTestThis fixes getRandomConfig() being prone to integer overflows and creatinginvalid configuration values.This closes #4378,5
[FLINK-7176] [travis] Improve error handlingThis closes #4330.,0
[FLINK-7232] [docs] Update checkstyle docs regarding test inclusionThis closes #4371.,3
[FLINK-7228] [history] Use free port in HistoryServerStaticFileServerHandlerTestThis closes #4366.,3
[FLINK-6747] [docs] Add documentation for dynamic tables.This closes #4365,2
[FLINK-7194] [table] Add default implementations for type hints to UDAGG interface.This closes #4379,2
"[FLINK-7105] [rpc] Make ActorSystems non daemonicIn order to not having to explicitly wait on the termination of an ActorSystemin the main thread, we now create the ActorSystems in non-daemonic mode. Thatway the process won't terminate if there is still an active actor.This closes #4259",5
"[FLINK-6665] [FLINK-6667] [distributed coordination] Use a callback and a ScheduledExecutor for ExecutionGraph restartsInitial work by zjureel@gmail.com , improved by sewen@apache.org.",1
[FLINK-7216] [distr. coordination] Guard against concurrent global failover,0
[FLINK-7231] [distr. coordination] Fix slot release affecting SlotSharingGroup cleanup,4
[hotfix] [tests] Code cleanups in ExecutionGraphRestartTest,3
[FLINK-7174] [kafka connector] Bump Kafka 0.10 dependency to 0.10.2.1This closes #4321,2
[FLINK-7225] [core] Fix exception message in StateDescriptor,0
"[FLINK-7224] [kafka, docs] Fix incorrect Javadoc / docs regarding Kafka partition metadata queryingSince Flink 1.3, partition metadata is no longer queried on the clientside. This commit corrects the statements of this legacy behaviour inthe Javadocs and documentation.This closes #4310.",2
"[hotfix] [kafka, tests] Commit read offsets in Kafka integration testsPreviously offsets were not commited so the same records could be read more then once.It was not a big issue, because so far this methods were used only for at-least-once tests.This closes #4310.",3
"[FLINK-7143] [kafka, tests] Stricter tests for deterministic partition assignmentPrevious test coverage for partition assignment was not strict enough.It did verify that partitions are assigned to the exact expectedsubtasks, which is crucial for verifying that partition to subtaskassignments are deterministic, and insensitive to the ordering of thefetched partition metadata.This close #4302.",5
"[FLINK-6365] [kinesis] Adapt default values of the Kinesis connectorThe previous GET_SHARDS_MAX and GET_SHARDS_INTERVAL_MILLIS did not workwell with AWS's service limitations, leading to poor Kinesis connectorperformace if used directly out-of-the-box. This commit adapats them tofollow the default values used by the AWS SDK.This closes #4375.",1
[FLINK-7211] [build] Exclude Gelly javadoc jar from release,2
[FLINK-6539] Add automated batch WordCount end-to-end test,3
[FLINK-6539] Combine ReadFromKafka/WriteIntoKafka into one Kafka010ExampleThis also updates the Kafka version we use in the examples module to0.10.x.,1
[FLINK-6539] Add automated Kafka end-to-end test,3
[FLINK-6539] Run end-to-end tests on travis,3
[FLINK-7137] [table] Fix nullability for nested types,0
[FLINK-7137] [table] Rework nullability handling,1
[FLINK-7137] [table] Add unit tests to verify composite type nullable and nested field nullable on aggregationsThis closes #4314.,3
[FLINK-7241] Rename namespace to cluster-id in HA docThis was renamed a while ago and namespace is now deprecated.,2
[FLINK-7241] Remove cluster-id from YARN HA setup template in docWhen running a YARN cluster the cluster-id is automatically derived.Acutally setting a cluster-id can lead to problems if you start multipleper-job YARN sessions with the same cluster-id by accident.,0
"[FLINK-7241] Reword description of cluster-id in HA docBefore, we were describing what happens if you manually specify acluster-id. Now, we say explicitly that you should not do this whenrunning Flink on a resource manager.",2
"[FLINK-7202] Split supressions for flink-core, flink-java, flink-optimizer per packageThis closes #4384.",1
[FLINK-7181] Activate checkstyle flink-java/operators/*This closes #4342.,2
[FLINK-7187] Activate checkstyle flink-java/scaThis closes #4337.,2
"[FLINK-7258] [network] Fix watermark configuration orderWhen configuring larger memory segment sizes, configuring thelow watermark before the high watermark may lead to anIllegalArgumentException, because the low watermark willtemporarily be higher than the high watermark. It's necessaryto configure the high watermark before the low watermark.For the queryable state server in KvStateServer I didn'tadd an extra test as the watermarks cannot be configured there.This closes #4391.",5
[FLINK-6940] [docs] Clarify the effect of configuring per-job state[skip ci]This closes #4136.,5
[FLINK-7141] [build] enable travis cache againThis adds some additional checks that should make sure the repository may notget corrupted or if it was than at least it is cleaned up again.This closes #4293.,4
[FLINK-5987] [build] Upgrade zookeeper dependency to 3.4.10This closes #4319.,2
[FLINK-7190] [java] Activate checkstyle flink-java/*This closes #4343.,2
[hotfix] [core] Fix null check in Plan#addDataSinkThis closes #4385.,5
[FLINK-7256] [travis] Only run end-to-end tests if no previous error occurredThis closes #4390.,0
[FLINK-7255] [docs] Remove default value from ListStateDescriptor constructorThis closes #4389.,4
[FLINK-7170] [cep] Fix until condition when the contiguity is strictThis closes #4318.,0
[FLINK-7257] [runtime] Enable checkstyle for test files in flink-runtimeThis closes #4394.,2
[FLINK-7264] [travis] Kill watchdog only after compilation&testsThis closes #4396.,3
[FLINK-7254] [java8] Properly activate checkstyle for flink-java8This closes #4393.,2
[FLINK-7247] [travis] Replace java 7 build profilesThis closes #4388.,2
[FLINK-7226] [webUI] Properly include UTF-8 in content-type headerThis closes #4392.,2
[FLINK-7263] [docs] Extend the PR templateThis closes #4395,2
[FLINK-6648] [gelly] Transforms for Gelly examplesReplaces GeneratedGraph class (which was extended by inputs) with theGraphKeyTypeTransform which can also transform the algorithm result toobtain consistent hash codes. This allows for the removal of the casestatements in the driver checksum tests.Float and double are now supported types.This closes #4304,1
[FLINK-7234] [docs] Fix CombineHint documentationThe CombineHint documentation applies to DataSet#reduce notDataSet#reduceGroup and should also be noted for DataSet#distinct. Alsocorrect the usage where the CombineHint is set with setCombineHintrather than alongside the user-defined function parameter.This closes #4372,2
"[hotfix] [gelly] Reduce time to run integration testsRemoves the ""large"" tests and increases the size of the ""small"" testsfrom scale=7 to scale=8.",3
"[FLINK-7110] [client] Add per-job cluster deployment interfaceRename deploySession to deploySessionCluster, deployJob to deployJobCluster; Add ClusterDeploymentDescription to deployJobCluster methodThis closes #4270.",1
[FLINK-7082] Add generic entry point for session and per-job clustersThis closes #4261.,1
[FLINK-7135] [flip-6] Pass in proper configuration to Dispatcher componentThis closes #4286.,5
"[FLINK-7113] Make ClusterDescriptor independent of cluster sizeThe deploySession method now is given a ClusterSpecification which specifies thesize of the cluster which it is supposed to deploy.Remove 2 line breaks, unnecessary parameters for YarnTestBase#Runner, add builder for ClusterSpecificationThis closes #4271.",1
[FLINK-7086] Add Flip-6 standalone session cluster entry pointThis closes #4272.,1
[FLINK-7098] Adapt startup scripts to start Flip-6 standalone session clusterThis closes #4262.,2
[FLINK-7125] [yarn] Remove Configuration loading from AbstractYarnClusterDescriptorInstead the AbstractYarnClusterDescriptor is passed in a Configuration instance whichis sent to the started application master.Pass in configuration directory manuallyRemove configurationDirectory resolution from AbstractYarnClusterDescriptorAddress PR commentsThis closes #4280.,1
[FLINK-7220] [checkpoints] Update RocksDB dependency to 5.5.5,5
Bump to 5.6.1,5
Stephan's feedback,5
"[FLINK-7108] [yarn] Add YARN entry points based on the generic entry pointAdd the YarnSesssionClusterEntrypoint and the YarnJobClusterEntrypoint which extendSessionClusterEntrypoint and JobClusterEntrypoint, respectively.Add new Yarn session and per-job cluster entry pointsRemove old Flip-6 Yarn per job entry pointThis closes #4281.",1
"[FLINK-7143] [kafka] Introduce KafkaTopicPartitionAssigner with stricter assignment contractsThis commit refactors the local partition assignment logic to be locatedin a strict contract-defining method, to make it explicit of theexpected partition to subtask assignment without relying solely onhashCode's of kafka partitions.",1
"[FLINK-7143] [kafka] Add test for Kafka Consumer rescalingThis verifies that the consumer always correctly knows whether it isrestored or not and is not affected by changes in the partitions asreported by Kafka.Previously, operator state reshuffling could lead to partitions beingsubscribed to multiple times.",1
[hotfix] [kafka] Make checkpoint methods final in KafkaConsumerBaseThis prevents concrete Kafka Source implementations from accidentallyoverriding the checkpointing methods. This would be problematic when notproviding tests. We test the checkpoint methods of the ConsumerBase butderived methods would not be tested.,3
"[FLINK-7248] [kafka, tests] Remove invalid checkRestoredNullCheckpointWhenFetcherNotReady testThis test is an invalid remnant from recent major Kafka consumerrefactorings. The actual behaviour is covered bycheckRestoredCheckpointWhenFetcherNotReady. When the fetcher is not yetready and exposed and a checkpoint happens, we fallback to using anyrestored state as the checkpoint.This closes #4387.",1
[FLINK-6998] [kafka] Add Kafka offset commit metrics to Flink Kafka Consumer,2
[FLINK-6998] [kafka] Remove unfruitful null checks on provided KafkaCommitCallbacksThis closes #4187.,1
"[FLINK-7287] [kafka, tests] Fix test instabilities in KafkaConsumerTestBaseThis closes #4414.",3
[FLINK-7092] [mesos] Shutdown ResourceManager components properly (FLIP-6)This closes #4289.,2
[FLINK-7118] [hadoop] Remove hadoop1.x code in HadoopUtilsThis closes #4285.,4
[FLINK-7134] Remove hadoop1.x code in mapreduce.utils.HadoopUtilsThis closes #4362.,4
[FLINK-7281] Remove old and misleading release scripts/README,4
[FLINK-7281] Make quickstart versions depend on project versions,1
[FLINK-7290] Add modular release scripts,1
[hotfix] Fix missing @ in quickstart poms,0
[FLINK-7080] [yarn] Add Yarn per job mode deploymentUpload user code jar from JobGraphThis closes #4284.,1
"[FLINK-7279] [minicluster] call fatal error handlers asynchronouslyThis fixes a deadlock between TM and cluster shutdown:The MiniCluster can deadlock if the fatal error handler is called while theMiniCluster shuts down. The reason is that the shut down happens under a lockwhich is required by the fatal error handler as well. If now the MiniClustertries to shut down the underlying RPC service which waits for all actors toterminate, it will never complete because one actor is still waiting for thelock.Solution: call fatal error handlers in TaskExecutor asynchronously so that theRPC service does not get blocked on this. This is more future proof than fixingthe locking problem itself which may eventually re-occur.This closes #4416.",0
"[FLINK-7295] [rpc] Add postStop callback for proper shutdown of RpcEndpointsIn order to execute a proper shutdown of RpcEndpoints it is necessary to havea callback which is executed in the main thread context directly before stoppingprocessing of messages. This PR introduces the postStop method which acts asthis callback. All endpoint specific cleanup should be executed in this method.The RpcEndpoint#shutDown method now only triggers the shut down of an RpcEndpoint.In order to wait on the completion of the shut down, one has to wait on thetermination future which can be retrieved via RpcEndpoint#getTerminationFuture.This PR also adapts the existing RpcEndpoints such that they execute their formershutDown logic in the postStop method.This closes #4420.",2
[FLINK-7192] [java] Activate checkstyle flink-java/test/operatorThis closes #4335.,3
[FLINK-7249] [build] Bump java.version property to 1.8This closes #4398.,5
[FLINK-7250] [build] Remove jdk8 profileThis closes #4399.,2
[FLINK-7253] [tests] Remove CommonTestUtils#assumeJava8This closes #4400.,3
"[hotfix] [tests] fix JobRetrievalITCase#testJobRetrieval() test job not runningAlthough this test should only verify that ClusterClient#retrieveJob() isworking, the inability to run the invokable given to the job does at least printan exception in the test output that may be confusing.This closes #4417.",5
[hotfix] [tests] fix NetworkStackThroughputITCase not working anymoreInvokable classes need to stay public in order to be successfully executed bythe TM.,1
[FLINK-7188] [java] Activate checkstyle flink-java/summarizeThis closes #4338.,2
"[hotfix] [tests] minor test improvements in TaskManagerConfigurationTest* use a proper JUnit temporary folder that ensures uniqueness* do not catch an exception just to fail with its message - if we let it throw,we do get more information out of the failure* also re-set the default file system scheme (a static member!) after finishingthe testThis closes #4401.",3
"[FLINK-7283][python] fix PythonPlanBinderTest issues with python paths* the path is not set correctly (only inside config, not the configuration that  is passed on to the PythonPlanBinder* linux distributions have become quite inventive regarding python binary names:  some offer python as Python 2, some as Python 3. Similarly, python3 and/or  python2 may not be available. If we really want to test both, we need to take  this into account.This closes #4409.",3
[FLINK-6213] [yarn] terminate resource manager itself when shutting down applicationThis closes #3640.,2
[hotfix] Add more prominent logging around end-to-end tests,3
[FLINK-7300] Increase timeout in Kafka end-to-end test,3
[FLINK-7185] Activate checkstyle flink-java/ioThis closes #4340.,2
[FLINK-7191] Activate checkstyle flink-java/operators/translationThis closes #4334.,2
[FLINK-6732] [java] Activate strict checkstyle for flink-java,2
[FLINK-7313] [futures] Add Flink future and Scala future to Java 8 CompletableFuture conversionAdd DirectExecutionContextAdd Scala Future to Java 8 CompletableFuture utility to FutureUtilsAdd Flink future to Java 8's CompletableFuture conversion utility to FutureUtilsAdd base class for Flink's unchecked future exceptionsThis closes #4429.,2
[FLINK-7314] [futures] Replace Flink's futures with CompletableFuture in TaskManagerLogHandlerThis closes #4430.,2
[FLINK-7318] [futures] Replace Flink's futures in StackTraceSampleCoordinator with Java 8 CompletableFutureThis closes #4431.,2
[FLINK-7319] [futures] Replace Flink's Futures with Java 8 CompletableFuture in MesosResourceManagerThis closes #4432.,2
[FLINK-7322] [futures] Replace Flink's futures with Java 8's CompletableFuture in CheckpointCoordinatorFix failing JobManagerITCaseThis closes #4436.,1
[FLINK-7326] [futures] Replace Flink's future with Java 8's CompletableFuture in RegisteredRpcConnectionAddress PR commentsThis closes #4440.,1
[FLINK-7327] [futures] Replace Flink's future with Java 8's CompletableFuture in StreamRecordQueueEntryThis closes #4442.,1
[hotfix] Fix snapshot deploymentThe snapshot deployment script still tried to use the jdk8 profile whichdoesn't exist anymore.,2
[hotfix] Fix maven-javadoc-plugin configurationBecause we're now using Java 8 we have to disable linting also when notusing the (now-removed) jdk8 profile or the release profile.Because of this problem snapshot deployments were not working.,1
[FLINK-7333] [futures] Replace Flink's futures with Java 8's CompletableFuture in TaskThis closes #4449.,2
[FLINK-7321] [futures] Replace Flink's futures with Java 8's CompletableFuture in HeartbeatManagerAddress PR commentsThis closes #4434.,1
[FLINK-7324] [futures] Replace Flink's future with Java 8's CompletableFuture in SlotPoolAddress PR commentsThis closes #4438.,1
[FLINK-7328] [futures] Replace Flink's futures with Java 8's CompletableFuture in SlotManagerThis closes #4443.,2
[FLINK-7332] [futures] Replace Flink's futures with Java 8's CompletableFuture in TaskExecutorThis closes #4448.,2
[FLINK-7317] [futures] Replace Flink's futures with Java 8's CompletableFuture in ExecutionGraphChange FutureUtils.retry to work with CompletableFuturesLet ConjunctFutures extends CompletableFutureRemove Flink's futures from ExecutionGraphThis closes #4433.,2
[FLINK-7331] [futures] Replace Flink's Future with Java 8's CompletableFuture in ResourceManagerAddress PR commentsThis closes #4444.,1
[FLINK-7325] [futures] Replace Flink's futures by Java 8's CompletableFuture in MiniClusterThis closes #4439.,5
[FLINK-7280] Wrong clearing SharedBuffer of Equal elements with same TimestampThis closes #4406,5
[hotfix] Add more logging in Kafka end-to-end test,3
[FLINK-7323] [futures] Replace Flink's futures with Java 8's CompletableFuture in MasterHooksThis closes #4437.,1
[FLINK-7320] [futures] Replace Flink's futures with Java 8's CompletableFuture in SchedulerAddress PR commentsThis closes #4435.,1
[FLINK-7303] [build] Build elasticsearch5 by defaultThis closes #4426.,2
[FLINK-7304] [scripts] Simplify taskmanager GC configurationThis closes #4427.,5
"[FLINK-7346] [tests] EventTimeWindowCheckpointingITCases print progress before each testTravis checks how long maven did not produce an output and we assume that atest hangs if no output is produces within 300s.IncrementalRocksDbBackendEventTimeWindowCheckpointingITCase executes severaltests but output is only generated at the end of the whole suite which may,under certain circumstances, already take longer than 300s. Therefore, simplyprovide some output in the form of progress messages regarding the executionof test cases.This closes #4419.",3
[FLINK-7311][tests] refrain from using fail(Exception#getMessage())This closes #4446.,0
[FLINK-7305] [checkstyle] Allow imports from org.apache.flink.shaded + add new import blockThis closes #4425.,2
"[FLINK-7166] [avro, tests] cleanup generated test classes in the cleanup phaseMaven neither cleaned up generated avro classes used by tests nor did it replacethem with new ones after the avro dependency change causing troubles to buildthe project. Although the target directory inside `src` is unusual, we keep itfor now but at least delete these files in the cleanup stage so that a`mvn clean install` always works.This closes #4309.This closes #4290.",1
[FLINK-7306] Function notFollowedBy in CEP don't return a Pattern objectThis closes #4428.,5
"[FLINK-7334] [futures] Replace Flink's futures with Java 8's CompletableFuture in RpcEndpoint, RpcGateways and RpcServiceRemove Futures from RpcGatewaysRemove Future usageFix failing AkkaRpcActorTestThis closes #4462.",3
[FLINK-7335] [futures] Remove Flink's own Future implementationThis closes #4463.,2
[FLINK-7356] [config] misleading s3 file uri in configuration fileThis closes #4466.,2
[FLINK-7127] [runtime] Add null check for state meta info snapshotting in heap backendThis closes #4349.,5
[FLINK-6493] Fix ineffective null check in RegisteredOperatorBackendStateMetaInfo#equals,5
[FLINK-6493] Fix ineffective null check in equality of RegisteredKeyedBackendStateMetaInfo snapshotsThis closes #4328.This closes #4408.,5
[FLINK-7369] [backend] Add more information for 'Key group index out of range of key group range' exception,5
[FLINK-4565] [table] Support for SQL IN operator,1
[FLINK-4565] [table] Full IN operator support for literals and sub-queriesThis closes #4404.This closes #3502.,1
"[hotfix][docs] add documentation for `taskmanager.exit-on-fatal-akka-error`When the quarantine monitor was added as of FLINK-3347, this documentation forenabling it only went into the backport for the 1.2 branch, not into master andtherefore not into the 1.3 release either. This adds it again.This closes #4478.",1
[FLINK-7210] Implement TwoPhaseCommitSinkFunctionThis is a recommended base class for implementing exactly-once sinks in FlinkThis closes #4368.,2
[hotfix][docs] Updated required Java version for standalone clusterThis closes #4469.,1
[FLINK-7053][blob] Improve code quality in BlobServer related testsThis lets BlobClientSslTest extend BlobClientTest as most of its implementationcame from there and was simply copied.[FLINK-7053][blob] verify some of the buffers returned by GET[FLINK-7053][blob] use TemporaryFolder for local BLOB dir in unit testsThis replaces the use of some temporary directory where it is not guaranteedthat it will be deleted after the test.This closes #4234.,3
[release-infra] Add releasing/update_branch_version.sh script,5
[FLINK-7349] [travis] Only execute checkstyle in misc profileThis closes #4460.,2
[FLINK-7350] [travis] Only execute japicmp in misc profileThis closes #4461.,2
[FLINK-7343][kafka] Increase Xmx for testsSometimes 1000m was not enough memory to run at-least-once tests with broker failures on TravisThis closes #4456.,0
[FLINK-6982] [guava] Reduce guava dependency usagesThis closes #4453.,2
[hotfix] [gelly] Explicit type can be replaced with <>In Java 8 the diamond operator can be used in cases which would resultin an error in Java 7. In Gelly we have often desired to use the diamondoperator and only discovered an issue when running tests on TravisCI.This closes #4457.,3
[FLINK-4499] [build] Add spotbugs pluginThis closes #4367.,0
[FLINK-7348] [checkstyle] Allow redundant modifiers on methods / revert removal of final modifierThis closes #4458.,4
[FLINK-7013] Introduce flink-shaded-netty-4This closes #4452.,2
[FLINK-7221] [jdbc] Throw exception if execution of last JDBC batch fails.This closes #4459.,0
[FLINK-7298] [table] Improve state clean-up of proctime window join.This closes #4421.,4
[FLINK-7293] [cep] Support custom order by in PatternStreamThis closes #4418.,1
[FLINK-7343][utils] Add network proxy utility to simulate network failures,0
[hotfix][Kafka] Refactor properties for KafkaTestEnvironment setup,1
"[FLINK-7343][Kafka] Use NetworkFailureProxy in kafka testsWe shouldn't fail KafkaServers directly, because they might not be ableto flush the data. Since we don't want to test how well Kafka implementsat-least-once/exactly-once semantic, we just simulate network failurebetween Flink and Kafka in our at-least-once tests.",3
[hotfix][Kafka] Clean up getKafkaServer method,1
"[hotfix] Clarify checkstyle setup instructions for IntelliJWe have to specifically set the Checkstyle Version to 6.19, otherwisewe'll get errors when trying to import the checkstyle file.",2
[FLINK-6429] [table] Bump Calcite version to 1.13.This closes #4373.,2
[FLINK-6429] [table] Fix build and simplifications,0
[FLINK-7385] Fix ArrayIndexOutOfBoundsException when object-reuse is enabledThis closes #4496.,0
[FLINK-7300] Fix unstable Kafka end-to-end testsInstead of specifying a timeout for the console consumer we now speciyan uppper message boundary that matches our expected number of messages.The timout was to unstable because it could sometimes return even thoughmessages were in fact available.,1
[hotfix] Fix newline printing in travis_mvn_watchdog.sh,1
"[FLINK-7300] Add new Kafka errors to ignored errors in end-to-end testsA new ERROR log message was added in FlinkKafkaConsumerBase that isemitted when asynchronous offset commit to the Kafka broker fails. Wealso ignore the accompanying exception, NoAvailableBrokersException.",0
[FLINK-7301] [docs] Rework state documentationThis closes #4441.,2
[FLINK-7382] [docs] Broken links in Apache Flink Documentation pageThis closes #4490.,1
"[FLINK-7054] [blob] Remove LibraryCacheManager#getFile()This was only used in tests where it is avoidable but if used anywhere else, itmay have caused cleanup issues.This closes #4235.",0
[hotfix] [docs] Fix missing menu item and improve other items,1
"[FLINK-7107] [flip6] Add option to start a Flip-6 Yarn session clusterThe Flip-6 Yarn session cluster can now be started with yarn-session.sh --flip6. Perdefault, the old Yarn application master will be started.This closes #4465.",1
[FLINK-7383] Remove ConfigurationUtilThis closes #4489.,5
"[FLINK-7370][docs] rework the operator documentation structure- create category `Streaming/Operators`- move `Streaming/Overview/DataStream Transformations` to `Streaming/Operators/Overview`- move `ProcessFunction`, `Windows`, and `Async IO` to `Streaming/Operators`- update previous links in the documentation- create any necessary redirects for old URLs",1
[FLINK-7370] [docs] Relocate files according to new structureThis closes #4477.,1
[FLINK-4565] [table] Support for SQL IN operator - move case of equal checkThis closes #4493.,4
[hotfix] Update create_binary_release.sh to newer Hadoop versionsThis brings it in line with the monolithic create_release_files.sh.,2
"[FLINK-7372] [JobGraph] Remove ActorGateway from JobGraphThe JobGraph has an unncessary dependency on the ActorGateway via itsJobGraph#uploadUserJars method. In order to get rid of this dependencyfor future Flip-6 changes, this commit retrieves the BlobServer'saddress beforehand and directly passes it to this method.This closes #4483.",4
"[FLINK-7375] Replace ActorGateway with JobManagerGateway in JobClientIn order to make the JobClient code independent of Akka, this PR replaces theActorGateway parameters by JobManagerGateway. AkkaJobManagerGateway is therespective implementation of the JobManagerGateway for Akka. Moreover, thisPR introduces useful ExceptionUtils method for handling of Future exceptions.Additionally, the SerializedThrowable has been moved to flink-core.This closes #4486.",2
[FLINK-7240] [tests] Stabilize ExternalizedCheckpointITCaseThe problem was that the TestingCluster did not wait properly after canceling thejob that the job was also completely removed from the cluster before submittingthe next job. This could lead to a NoResourceAvailableException which ultimatelymade the job fail.Add CountDownLatch to source of ExternalizedCheckpointITCase in order to wait for all sources to be running before triggering a checkpointThis closes #4497.,1
[FLINK-7352] [tests] Stabilize ExecutionGraphRestartTestIntroduce an explicit waiting for the deployment of tasks. This replaces the looseordering induced by Thread.sleep and fixes the race conditions caused by it.This closes #4501.,1
[FLINK-7026] [asm] Introduce flink-shaded-asm-5This closes #4494.,2
[FLINK-6494] [RM][Yarn][Mesos] Migrate ResourceManager/Yarn/Mesos configuration optionsThis closes #4075.,5
"[FLINK-7354][tests] ignore ""initialSeedUniquifierGenerator"" thread in thread listNetty may spawn a thread in its ThreadLocalRandom class because of some securerandom use which may be caught in our LocalFlinkMiniClusterITCase as not beingstopped. Let's tolerate this.Alternatively, we could solve this similarly tohttps://issues.apache.org/jira/browse/SOLR-10098 by settingThreadLocalRandom.setInitialSeedUniquifier(1L);but that may be less future proof or even remove some randomness.This closes #4464.",4
"[FLINK-7408] [conf] Create WebOptions for WebRuntimeMonitorThis commit moves the WebRuntimeMonitor related configuration options fromJobManagerOptions to WebOptions. Moreover, it removes the prefix jobmanager.This closes #4512.",0
[FLINK-7379] [qs] Remove HighAvailabilityServices from QS client constructor.,4
[FLINK-7300] Also ignore DisconnectException in end-to-end test logs,2
[FLINK-7381] [web] Decouple WebRuntimeMonitor from ActorGatewayThis PR decouples the WebRuntimeMonitor from the ActorGateway by introducingthe JobManagerGateway interface which can have multiple implementations. Thisis a preliminary step for the integration of the existing WebRuntimeMonitorwith the Flip-6 JobMaster.Add time unit for web.timeoutThis closes #4492.,1
"[FLINK-7387] [rpc] Require RpcEndpoints to directly implement RpcGatewaysThis commit changes the relation between RpcEndpoints and RpcGateways. From now on,the RpcEndpoints have to implement the RpcGateways they want to support instead ofcoupling it loosely via a type parameter. In order to obtain self gateway a newmethod RpcEndpoint#getSelfGateway(Class) has been introduced. This method can be usedto obtain the RpcGateway type at run time to talk to the RpcEndpoint asynchronously.All existing RpcEndpoints have been adapted to the new model. This basically meansthat they now return a CompletableFuture<X> instead of X.Add RpcEndpointTestThis closes #4498.",3
[FLINK-7396] Fix don't put multiple directories in HADOOP_CONF_DIR in config.sh,5
[FLINK-6281] [jdbc] Add JDBCAppendTableSink.This closes #3712.,5
[hotfix] [docs] Improve TableSink documentation.,2
"[FLINK-7055][blob] refactor getURL() to the more generic getFile()The fact that we always returned URL objects is a relic of the BlobServer's onlyuse for URLClassLoader. Since we'd like to extend its use, returning Fileobjects instead is more generic.This closes #4236.",2
"[FLINK-7056][blob] add API to allow job-related BLOBs to be stored[FLINK-7056][blob] refactor the new API for job-related BLOBsFor a cleaner API, instead of having a nullable jobId parameter, use two methods:one for job-related BLOBs, another for job-unrelated ones.This closes #4237.",1
"[FLINK-7434][doc] scafolding with ""sbt new""Since the generated project is an sbt project, it ismuch more straightfoward for the user to create it withthe new ""sbt new"" command than by using giter8 (whichrequires to install giter8 just for that purpose).This closes #4531.",1
"[FLINK-6180] [rpc] Remove TestingSerialRpcServiceThe TestingSerialRpcService produces thread interleavings which are not happeningwhen being executed with a proper RpcService implementation. Due to this the testcases can fail or succeed wrongly. In order to avoid this problem, this commitremoves the TestingSerialRpcService and adapts all existing tests which used itbefore.Remove TestingSerialRpcService from MesosResourceManagerTestRemove TestingSerialRpcService from ResourceManagerJobMasterTestRemove TestingSerialRpcService from ResourceManagerTaskExecutorTestRemove TestingSerialRpcService from ResourceManagerTestRemove SerialTestingRpcService from JobMasterTestRemove TestingSerialRpcService from TaskExecutorITCaseRemove TestingSerialRpcService from TaskExecutorTestRemove TestingSerialRpcService from SlotPoolTestDelete TestingSerialRpcServiceThis closes #4516.",3
[FLINK-7441] [table] Double quote string literals is not supported in Table API and SQLThis closes #4538.,1
[FLINK-7399] [checkstyle] Forbid imports from org.codehaus.jacksonThis closes #4505.,2
[FLINK-6982] [guava] Integrate flink-shaded-guava-18This closes #4503.,2
[hotfix] [docs][metrics] Small typo fix in the scope section,0
[FLINK-7445] [GitHub] Remove FLINK-1234 reference from PR templateThis closes #4542.,2
[FLINK-7443] [metrics] MetricFetcher store and deserializer fields now finalThis closes #4539.,2
[FLINK-7415] [cassandra] Add example instructions for creating keyspaceThis closes #4519.,1
"[hotfix][misc] Fix logging of local port in NetworkFailuresProxyPreviously if localPort was set 0, actually obtained/bind port was notlogged anywhere. Now we print local port after binding.",2
[hotfix][misc] More verbose logging in NetworkFailuresProxyThis closes #4515.,0
[FLINK-7405] [metrics] Reduce excessive warning logging from DatadogHttpReporterThis closes #4508.,5
[FLINK-7213] Introduce state management by OperatorID in TaskManager,1
[FLINK-7268] [checkpoints] Scope SharedStateRegistry objects per (re)start,1
"[FLINK-7268] Add delaying executor in *EventTimeWindowCheckpointingITCaseThis helps tease out races, for example the recently discovered one incleanup of incremental state handles at the SharedStateRegistry.(cherry picked from commit d7683cc)",1
[FLINK-7362] [checkpoints] Savepoint property is lost after de/serialization of CheckpointProperties,5
[FLINK-7462] [docs] Add very obvious warning about outdated docsThis closes #4553.,2
"[FLINK-7056][tests][hotfix] make sure the client and a created InputStream are closedIf not and the server has not yet sent all data packets, it may still occupy theread lock and block any writing operations (also see FLINK-7467).This closes #4558.",2
[hotfix] increase Scala checkstyle maxParameters to 20,2
"[FLINK-7057][blob] move ref-counting from the LibraryCacheManager to the BlobCacheAlso change from BlobKey-based ref-counting to job-based ref-counting which issimpler and the mode we want to use from now on. Deferred cleanup (as before)is currently not implemented yet (TODO).At the BlobServer, no ref-counting will be used but the cleanup will happenwhen the job enters a final state (TODO).[FLINK-7057][blob] change to a cleaner API for BlobService#registerJob()[FLINK-7057][blob] implement deferred cleanup at the BlobCacheWhenever a job is not referenced at the BlobCache anymore, we set a TTL and letthe cleanup task remove it when this is hit and the task is run. For now, thismeans that a BLOB will be retained at most(2 * ConfigConstants.LIBRARY_CACHE_MANAGER_CLEANUP_INTERVAL) seconds after notbeing referenced anymore. We do this so that a recovery still has the chance touse existing files rather than to download them again.[FLINK-7057][blob] integrate cleanup of job-related JARs from the BlobServerTODO: an integration test that verifies that this is actually done when desiredand not performed when not, e.g. if the job did not reach a final executionstate[FLINK-7057][tests] extract FailingBlockingInvokable from CoordinatorShutdownTest[FLINK-7057][blob] add an integration test for the BlobServer cleanupThis ensures that BLOB files are actually deleted when a job enters a finalstate.[FLINK-7057][tests] refrain from catching an exception just to fail the testremoves code like this in the BLOB store unit tests:catch (Exception e) {    e.printStackTrace();    fail(e.getMessage());}[FLINK-7057][blob] fix BlobServer#cleanupJob() being too eagerInstead of deleting the job's directory, it was deleting the parent storagedirectory.[FLINK-7057][blob] fix BlobServer cleanup integration* the test did not check the correct directories for cleanup* the test did not honour the test timeout[FLINK-7057][blob] test and fix BlobServer cleanup for a failed job submission[FLINK-7057][blob] rework the LibraryCacheManager APISince ref-counting has moved to the BlobCache, the BlobLibraryCacheManager isjust a thin wrapper to get a user class loader by retrieving BLOBs from theBlobCache/BlobServer. Therefore, move the job-registration/-release out of it,too, and restrict its use to the task manager where the BlobCache is used (onthe BlobServer, jobs do not need registration since they are only used once andwill be deleted when they enter a final state).This makes the BlobServer and BlobCache instances available at the JobManagerand TaskManager instances, respectively, also enabling future use cases outsideof the LibraryCacheManager.[FLINK-7057][blob] address PR comments[FLINK-7057][blob] fix JobManagerLeaderElectionTest[FLINK-7057][blob] re-introduce some ref-counting for BlobLibraryCacheManagerApparently, we do need to return the same ClassLoader for different (parallel)tasks of a job running on the same task manager. Therefore, keep the initialtask registration implementation that was removed with8331fbb208d975e0c1ec990344c14315ea08dd4a and only adapt it here. This alsorestores some tests and adds new combinations not tested before.[FLINK-7057][blob] address PR comments[FLINK-7057][tests] fix (manual/ignored) BlobCacheCleanupTest#testJobDeferredCleanup()[FLINK-7057][hotfix] fix a checkstyle error[FLINK-7057][blob] remove the extra lock object from BlobCacheWe can lock on jobRefCounters instead, which is what we are guarding anyway.[FLINK-7057][blob] minor improvements to the TTL in BlobCacheDo not use Long.MAX_VALUE as a code for ""keep forever"". Also add more comments.[FLINK-7057][blob] replace ""library-cache-manager.cleanup.interval"" with ""blob.service.cleanup.interval""Since we moved the cleanup to the BLOB service classes, this only makes sense.[FLINK-7057][hotfix] remove an unused import[FLINK-7057][docs] adapt javadocs of JobManager descendents[FLINK-7057][blob] increase JobManagerCleanupITCase timeoutThe previous value of 15s seems to be too low for some runs on Travis.[FLINK-7057][blob] providing more debug output in JobManagerCleanupITCaseIn case the BlobServer's directory is not cleaned within the remaining time,also print which files remain. This may help debugging the situation.This closes #4238.",0
"[FLINK-7347] Keep IDs for checkpoint in a set in MessageQueue SourcePreviously, they were kept in a List, which made removal from the Set ofunconfirmed IDs prohibitively expensive inMessageAcknowledgingSourceBase.notifyCheckpointComplete().",5
"[FLINK-6630] [FLINK-6631] Implement FLIP-6 Mesos cluster entrypoints + MesosTaskExecutorRunner- bin: new entrypoints scripts for flip-6- ClusterEntrypoint: Refactor the shutdown method- ClusterEntrypoint: Install default FileSystem (for parity with legacy entrypoints)- ClusterEntrypoint: new MesosJobClusterEntrypoint, MesosSessionClusterEntrypoint, MesosEntrypointUtils, MesosTaskExecutorRunner- MesosServices: enhanced with artifactServer, localActorSystem- MesosResourceManager: Fallback to old TM params when UNKNOWN resource profile is provided- MesosResourceManager: config setting for taskmanager startup script (mesos.resourcemanager.tasks.taskmanager-cmd)- test: added a 'noop' job graph for testing purposesThis closes #4555.",3
[FLINK-7077] [mesos] Implement task release to support dynamic scaling- SlotManager: fix for idleness tracking (`markIdle` shouldn't reset `idleSince` on every call)- ResourceManager: change `stopWorker` method to use `ResourceID`- ResourceManager: schedule callbacks from `ResourceManagerActions` onto main thread- MesosResourceManager: implement `stopWorker`- MesosResourceManager: fix for message routing from child actors to RMThis closes #4560.,0
[FLINK-7269] Refactor passing of dynamic propertiesThis closes #4415.,4
"[FLINK-7477] Use ""hadoop classpath"" to augment classpath when availableThis improves the out-of-box experience on GCE and AWS, both of whichdon't set a HADOOP_CLASSPATH but have ""hadoop"" available on the $PATH.",1
"[FLINK-7480] Set HADOOP_CONF_DIR to sane default if not setThis improves the out-of-box experience on GCE and AWS, both of whichdon't set HADOOP_CONF_DIR by default but use /etc/hadoop/conf",5
[FLINK-7300] Also ignore AskTimeoutException in end-to-end test logs,2
[FLINK-5851] [streaming API] Rename AsyncCollector into ResultFutureComplete renaming AsyncCollector -> ResultFutureThis closes #4243.,2
[FLINK-7123] [cep] Support timesOrMore in CEPThis closes #4523.,1
[FLINK-6244] [cep] Emit timeouted Patterns as Side OutputThis closes #4320,2
[FLINK-7337] [table] Refactor internal handling of time indicator attributes.- Expand phyiscal Row schema for time indicators.- Refactor computation of logical schema of tables to import.- Refactor operators to use time attribute in Row instead of StreamRecord timestamp.This closes #4488.,1
[FLINK-7337] [table] Efficient handling of rowtime timestampsUse Long instead of a SQL Timestamp to represent timestamps internallyThis closes #4532.,1
[hotifx][streaming] Simplify state of TwoPhaseCommitSinkFunction,1
[hotfix] [cep] Spelling corrections,0
[FLINK-7147] [cep] Support greedy quantifier in CEPThis closes #4296.,1
[hotfix][tests] Implement AutoCloseable in TestHarness,3
[hotfix][streaming] Refactor TwoPhaseCommitSinkFunctionTest,3
[FLINK-7460] [state backends] Close all ColumnFamilyHandles when restoring from rescaled incremental checkpoints,0
[FLINK-7505] Use lambdas in suppressed exception idiom,1
[FLINK-7461] Remove Backwards compatibility with <= Flink 1.1,2
[hotfix] Remove old Kinesis snapshots for Flink 1.1,2
[FLINK-7429] [kinesis] Add IT tests for migration from 1.3,3
[FLINK-7040] [rest] Add basics for REST communicationAdd better error message for get requests with a bodyConsistent error message for 404Rework resolve URL generationRework handler registrationSupport concurrent requestsRework client response receivalRework handler response (remove HandlerResponse class)tests: move client/server shutdown into finally blockClose connection in ClientHandlerProper shutdown of netty stacksimplify RestClientEndpoint lambda chainProvide handlers with access to MessageParametersThis closes #4569.,2
"[FLINK-7040] [rest] Introduce executor, shutdown timeouts and future completion in failure case to RestServerEndpointThis commit also moves the target address and target port specification to theRestClient#sendRequest call instead of passing the connection information to theconstructor of the RestClient.",5
[FLINK-7544] [REST] Make all path parameters mandatory,5
[FLINK-7543] [REST] Simplify handler access to path/query parametersThis closes #4611.,2
[FLINK-7454] [docs] Uupdate 'Monitoring Current Event Time' sectionThis closes #4547.,5
[FLINK-7498][streaming] Bind together state fields of TwoPhaseCommitSinkFunctionMake sure that state fields are coupled together between checkpoints.,1
[FLINK-7497][streaming] Introduce user context in TwoPhaseCommitSinkFunction,1
[hotfix][streaming] Allow to override methods from TwoPhaseCommitSinkFunctionThis allow for some custom user logic during handling checkpoints.,2
[hotfix][streaming] Fix logging in TwoPhaseCommitSinkFunction,1
[hotfix] [docs] Add section in docs about writing unit and integration testsThis closes #4454.,3
[hotfix] [docs] Fix typos and improve testing docs,2
[hotfix] [docs] Remove duplicate docs page,2
[FLINK-7206] [table] Add DataView to support direct state access in AggregateFunction accumulators.This closes #4355.,1
[FLINK-7245] [table] Add operators to hold back watermarks with static delays.This closes #4530.,1
[FLINK-7309] [table] Fix NullPointerException when selecting null fields.This closes #4479.,0
[FLINK-7398] [table] Add Logging trait to prevent serialization of Logger.This closes #4576.,2
FLINK-7366 Upgrade kinesis-producer-library in flink-connector-kinesis from 0.10.2 to 0.12.5This closes #4522,2
[FLINK-7559] [quickstart] fix Typo in flink-quickstart pomThis closes #4619.,2
"[FLINK-7556] Allow Integer.MIN_VALUE for fetch size in JDBCInputFormatAllow Integer.MIN_VALUE to be accepted as a parameter for setFetchSize for MySQL Driver.The combination of a forward-only, read-only result set, with a fetch size of Integer.MIN_VALUE serves as a signal to the driver to stream result sets row-by-row. After this, any result sets created with the statement will be retrieved row-by-row.This closes #4617.",1
[FLINK-7558][table]Improve SQL ValidationException message.This closes #4620,5
[FLINK-6787] Fix Job-/StoppableException extend FlinkException,2
[hotfix][table] Fix bug of testAggregateFunctionOperandTypeCheckThis closes #4629,3
[FLINK-7299][AVRO] Write GenericRecord using AvroOutputFormat,1
[FLINK-7422] Upgrade Kinesis Client Library (KCL) and AWS SDK in flink-connector-kinesis,2
[FLINK-7169][CEP] Support AFTER MATCH SKIP function in CEPThis closes #4331,1
[FLINK-7457] Make Dispatcher highly availableThis commit introduces a dispatcher leader election and retrieval service to theHighAvailabilityServices. Moreover it adds code such that the Dispatcher now takespart in the leader election process using the afore-mentioned services.Let Dispatcher participate in leader electionAdd test for Dispatcher leader electionThis closes #4548.,3
"[FLINK-7489] Remove startJobExecution and suspendExecution from JobMasterGatewayThe job lifecycle methods should not be exposed as RPCs. Therefore, this commitremoves them from the JobMasterGateway definition.This closes #4573.",5
[FLINK-7501] Generalize RegisteredRpcConnection to support generic leader idsThe RegisteredRpcConnection now supports generic leader ids/fencing tokens. Thiswill allow to introduce component specific leader ids/fencing tokens.This closes #4580.,1
[FLINK-7522] Add termination future to ClusterEntrypointThe termination future is completed when the ClusterEntrypoint shuts down. Thisallows for easier testing.This closes #4589.,3
[FLINK-7519] Add HttpResponseStatus to RestClientExceptionEnrich the RestClientException with the HttpResponseStatus in case of failures. Thismakes the exception handling on the client side easier.This closes #4588.,1
"[FLINK-7078] [rpc] Introduce FencedRpcEndpointIntroduce FencedRpcEndpoint which requires all RPC messages to have afencing token attached. Based on the received fencing token and theactual fencing token, the message will either be discarded if they arenot equal or it will be processed. That way we are able to filter outold messages or messages which originate from a split brain situationAdd support for callAsyncWithoutFencingIntroduce local and remote fenced messagesThis closes #4578.",1
[FLINK-7409] [web] Make WebRuntimeMonitor reactiveThis commit changes the behaviour of the WebRuntimeMonitor to not longer block servingthreads by waiting on the result of futures. Instead the RequestHandler now returns aCompletableFuture<FullHttpResponse> which is written out to the Netty channel uponcompletion. This will improve the performance of our WebRuntimeMonitor.This closes #4527.,1
[FLINK-7444] [rpc] Make external calls non-blockingMake all external calls from the RpcEndpoint's main thread non blocking byexecuting them as a runnable in an Executor.Make FatalErrorHandler calls non asynchronousThis closes #4540.,0
"[FLINK-7500] Set JobMaster leader session id in main threadThis commit changes the JobMaster such that it's leader session id is only setin the main thread. This is done by passing the leader session id to thestartJobExecution method. Moreover, this commit returns a future from thestart and suspend methods which can be used to wait on the completion of theseoperations.This closes #4579.",1
"[FLINK-7526] [TaskExecutor] Filter out duplicate JobManager gained leadership messagesThis commit filters out duplicate JobManager gained leadership messges coming fromthe JobLeaderService. This avoid opening multiple connections to the JobManagerwhich consumes resources. Moreover, this commit properly closes allJobManagerConnections in case of a shut down.This closes #4595.",2
[FLINK-7507] [dispatcher] Fence DispatcherLet the Dispatcher extend the FencedRpcEndpoint and introduce DispatcherId whichreplaces the UUID as leader id/fencing token.This closes #4584.,2
"[FLINK-7504] Fence the ResourceManagerProperly fences the ResourceManager by letting it extend the FencedRpcEndpoint.Moreover, this PR introduces a ResourceManagerId which replaces the UUID asleader id/fencing token. This will give us more type safety when defining rpcinterfaces.This closes #4582.",5
"[FLINK-7523] Add proper resource shutdown to ResourceManager/JobManagerRunnerThis commit waits for the completion of the shutdown of the ResourceManagerbefore shutting down the ResourceManagerRuntimeServices. The JobManagerServices arenow exclusively passed in to the JobManagerRunner which means that it is nolonger responsible for shutting the JobManagerServices down. Additionally,it waits until the JobMaster has been shut down before closing theLeaderElectionService as well as the JobManagerMetricGroup.The JobManagerServices are now managed by the caller of the JobManagerRunner. Thisallows to reuse them across multiple JobManagerRunners.The RpcEndpoint#postStop method is now called by the UntypedActor#postStop method,which ensures that the RpcEndpoint's method is also called if only the underlyingRpcService is shut down (without explicitly shutting down the RpcEndpoint).This closes #4596.",1
"[FLINK-7506] Fence JobMasterThis commit lets the JobMaster extend from FencedRpcEndpoint. This enablesautomatic fencing of all messages. Moreover, this PR introduces theJobMasterId which is the new leader id/fencing token replacing the UUID. Thisimproves type safety when passing multiple fencing tokens around.This closes #4583.",4
[FLINK-6751] [docs] Add documentation for user-defined AggregateFunction.This closes #4546.,1
[FLINK-7564] [table] Fix watermark semantics in rowtime unbounded OVER window.This closes #4633.,0
[FLINK-7572] [table] Improve TableSchema and FlinkTable validation exception messages.This closes #4640.,5
[FLINK-7404] [table] Generate code for non-equi join conditions only.This closes #4507.,2
[FLINK-7227] [table] Fix push-down of disjunctive predicates with more than two terms.This closes #4608.,0
[FLINK-7568] Change role of ProcessWindowFunction and WindowFunction in doc,2
[FLINK-7568] Update ProcessFunction.Context in window documentation,2
[FLINK-7568] Add note about 'key' parameter to window doc,2
[FLINK-7568] Add note about start/end timestamps in window doc,2
[FLINK-7568] Add section about consecutive windows to window doc,2
[FLINK-7576] [futures] Add FutureUtils.retryWithDelayFutureUtils.retryWithDelay executes the given operation of typeCallable<CompletableFuture<T>> n times and waits in between retries the givendelay. This allows to retry an operation with a specified delay.Make retry and retry with delay future properly cancellableThis closes #4637.,1
"[FLINK-7430] Set StreamTask.isRunning to false after closing StreamOperatorsClosing StreamOperators is still part of the StreamTask's running lifecycle,because operators which perform asynchronous operations usually finish theirwork when the StreamOperator is closed. Since this also entails that errorscan occur and that a checkpointing operation is triggered, we should only setthe StreamTask's isRunning to false after all StreamOperators have been closed.Furthermore, this commit introduces a while guard for the waiting condition inContinuousFileReaderOperator#close.This closes #4650.",2
[hotfix][kafka][docs] Add warning regarding data losses when writing to Kafka,5
"[FLINK-7407] [kafka] Adapt AbstractPartitionDiscoverer to handle non-contiguous partition metadataPreviously, the AbstractPartitionDiscoverer tracked discoveredpartitions by keeping only the largest discovered partition id. Allfetched partition metadata with ids smaller than this id would beconsidered as discovered. This assumption of contiguous partition ids istoo naive for corner cases where there may be undiscovered partitionsthat were temporariliy unavilable before and were shadowed bydiscoverered partitions with largerer partition ids.This commit changes to use a set to track seen partitions. This alsoremoves the need of pre-sorting fetched partitions.",4
[hotfix] [kafka] Remove unused shouldAssignToThisSubtask method in AbstractPartitionDiscovererThis closes #4526.,1
[FLINK-7440] [kinesis] Eagerly check serializability of deserialization schema in FlinkKinesisConsumerThis commit also adds tests for verifying that the FlinkKinesisConsumeritself is serializable.,2
[FLINK-7440] [kinesis] Eagerly check that provided schema and partitioner is serializable in FlinkKinesisProducerThis commit also adds a test to verify that the FlinkKinesisProducer isserializable.This closes #4537.,2
[FLINK-7367] [kinesis] Generalize configuration for FlinkKinesisProducer properties,2
[FLINK-7363] [kinesis] Clean up deprecation of ProducerConfigConstants- Improve deprecation message in Javadocs- Remove usage of ProducerConfigConstants in code wherever possible- Remove usage of ProducerConfigConstants in documentation code snippetsThis closes #4473.,2
[FLINK-7294] [mesos] Set mesos.resourcemanager.framework.role for resourcesThis closes #4622.,1
[FLINK-7617] [runtime] Remove string format in BitSet to improve the performance of BuildSideOuterjoinThis closes #4668.,1
[FLINK-7273] [gelly] Gelly tests with empty graphsThere exist some tests with empty graphs but the `EmptyGraph` in`AsmTestBase` contained vertices but no edges. Add a new `EmptyGraph`without vertices and test both empty graphs for each algorithm.EmptyGraph now generates the proper TypeInformation (for Edge<> notTuple3) which had prevented adding edges due to a union incompatibility.GraphGeneratorUtils#vertexSet now uses a hash-combine for distinct.`PageRank` optionally includes zero-degree vertices in the results(at a performance cost).This closes #4405,1
"[FLINK-7199] [gelly] Graph simplification does not set parallelismThe Simplify parameter should accept and set the parallelism whencalling the Simplify algorithms.The LocalClusteringCoefficient ""count triangles"" reduce now uses theassigned (""little"") parallelism as this computation is proportional tothe number of vertices (the combine computation is proportional to thepotentially much larger number of triangles).The ignored CombineHint on the HITS all-reduces have been removed.This closes #4346",4
[hotfix] [docs] Fix log file name in quick start guideProgram output is written to TaskManager logs.This closes #4641,2
[FLINK-7494] [build] Add license header to '.travis.yml' fileThis closes #4575,2
[FLINK-7625] [docs] Fix metric nameThis closes #4676,0
[FLINK-7402] [runtime] Fix null check in NettyMessage#writeThis closes #4562,0
[FLINK-7563] [cep] Fix watermark semantics in cep and related tests.This closes #4632,3
[hotfix] [cep] Fix afterMatchStrategy parameter missing issueThis closes #4673,0
[FLINK-7458] Generalize GatewayRetriever for WebRuntimeMonitorIntroduce a generalized GatewayRetriever replacing the JobManagerRetriever. TheGatewayRetriever fulfills the same purpose as the JobManagerRetriever with theability to retrieve the gateway for an arbitrary endpoint type.This closes #4549.,1
"[FLINK-7459] Generalize Flink's redirection logicIntroduce RedirectHandler which can be extended to add redirection functionality to allSimpleInboundChannelHandlers. This allows to share the same functionality across theStaticFileServerHandler and the RuntimeMonitorHandlerBase which could now be removed.In the future, the AbstractRestHandler will also extend the RedirectHandler.This closes #4551.",0
[FLINK-7533] Let LeaderGatewayRetriever retry failed gateway retrievalsAdd test caseOnly log LeaderGatewayRetriever exception on Debug log levelProperly fail outdated gateway retrieval operationsThis closes #4602.,5
"[FLINK-7580] Automatically retry failed gateway retrievalsThe LeaderGatewayRetriever implementations, AkkaJobManagerRetriever and theRpcGatewayRetriever, now automatically retry the gateway retrieval operationfor a fixed number of times with a retry delay before completing the gatewayfuture with an exception.Retry AkkaJobManagerRetrieverRetry RpcGatewayRetrieverAdd support for fenced componentsThis closes #4643.",1
[FLINK-7639] [tests] Harden TaskExecutorITCaseThe TaskExecutorITCase does not wait for the leader election to have finishedbefore sending remote messages to the ResourceManager. Waiting on the completionfixed the test instability.,3
[FLINK-7581] [REST] Name netty threadsThis closes #4644.,2
[FLINK-7583] [REST] Use static constant for CONTENT_TYPE headerThis closes #4646.,1
[FLINK-7598][travis] fix ineffective shaded artifacts checksThis fixes the netty check and makes all of them more robust against failures ofthe executed commands counting the number of dependencies.This closes #4653.,0
[FLINK-6549] [datastream] Improve error message for type mismatches with side outputsThis closes #4663.,0
[FLINK-7626] [docs][metrics] Add some checkpoints metric description in docsThis closes #4677.,2
[FLINK-7609][examples] Adjust WindowWordCount default window configuration valuesThis closes #4662.,5
[FLINK-7630] Allow passing a File or an InputStream to ParameterTool.fromPropertiesFile(),2
"[FLINK-7527] [rest] Let AbstractRestHandler extend RedirectHandlerBy letting the AbstractRestHandler extend the RedirectHandler, we add redirectioncapabilities to the AbstractRestHandler.This closes #4597.",0
[FLINK-7528] Create DispatcherRestEndpoint and integrate with DispatcherThis commit creates the DispatcherRestEndpoint and integrates it with theDispatcher. The DispatcherRestEndpoint is created in the SessionClusterEntrypointand its address is passed to the Dispatcher such that it can answer therequestRestAddress RPC.This closes #4598.,1
"[FLINK-7529] Retrieve complete REST address from gatewayWith this change, the complete REST address (protocol://hostname:port) is retrievedfrom the RestfulGateway. That way we decouple the RestHandlers from the underlyingRestServerEndpoint/WebRuntimeMonitor because they no longer have to know whetherHTTPs is enabled or not.This closes #4599.",0
[FLINK-7531] Move Flink legacy rest handler to flink-runtimeMove metrics handlers under o.a.f.runtime.webmonitor.handlersMove StaticFileServerHandler under o.a.f.runtime.webmonitor.filesThis closes #4600.,2
[hotfix] Test properly default JobMasterId in JobMaster#suspendExecution,3
[FLINK-6733] Remove commented out AvgAggregationFunction.javaThis closes #4630.,1
[FLINK-7357] [table] Fix translation of group window queries with window props and HAVING.This closes #4521.,0
[FLINK-6442] [table] Add registration for TableSinks and INSERT INTO support for SQL and Table API.This closes #3829.,1
"[FLINK-7532] Add web content handler to DispatcherRestEndpointAdds the StaticFileContentHandler to the DispatcherRestEndpoint if theflink-runtime-web dependency is in the classpath. In order to setup therespective channel handler, this commit introduces the setupChannelHandlersmethod to the RestServerEndpoint.Refactor RestServerEndpoint#initializeHandler to support StaticFileServerHandler registrationThis closes #4601.",2
"[FLINK-7534] Create LegacyRestHandlerAdapter for old REST handlersIntroduce LegacyRestHandler interface which the old REST handler have to implementin order to make them usable for the RestServerEndpoint in combination with theLegacyRestHandlerAdapter. The LegacyRestHandlerAdapter extends the AbstractRestHandlerand runs the LegacyRestHandler implementation.As an example, this commit ports the ClusterOverviewHandler to the new interface. TheDispatcher side still has to be properly implemented.This closes #4603.",1
"[FLINK-7535] Port DashboardConfigHandler to new REST endpointLets DashboardConfigHandler implement the LegacyRestHandler. Moreover, thiscommit defines the appropriate DashboardConfigurationHeaders.The DispatcherRestEndpoint registers the DashboardConfigHandler.This closes #4604.",5
[FLINK-7651] [flip-6] Delay RetryingRegistration in case of connection errorSimilar to a registration error we should also delay the retrying registration in case ofconnection error which could happen if the remote endpoint has not been started yet.This closes #4686.,0
[FLINK-7552] Extend SinkFunction interface with SinkContext,1
[FLINK-7553] Use new SinkFunction interface in FlinkKafkaProducer010,2
[FLINK-7644] [runtime] Remove double semicolon.This closes #4692.,4
[FLINK-7571] [table] Fix translation of TableSource with time indicators.This closes #4635.,0
[FLINK-7442] Add option for using a child-first classloader for loading user codeThis also adds an end-to-end test that verifies correct order for bothclasses and resources.,3
[FLINK-7655] [flip6] Set fencing token to null if not leaderThis commit changes the fencing behaviour such that a component which is not theleader will set its fencing token to null. This distinction allows to throw differentexceptions depending on whether it is a token mismatch or whether the receiver hasno fencing token set (== not being the leader).This closes #4689.,1
[FLINK-7567] [scala] Remove keepPartitioning parameter from DataStream.iterate(),5
"[FLINK-7508] [kinesis] Switch to POOLED ThreadingMode in FlinkKinesisProducerKinesisProducerLibrary (KPL) 0.10.x had been using aOne-New-Thread-Per-Request model for all requests sent to AWS Kinesis,which is very expensive.0.12.4 introduced a new ThreadingMode - Pooled, which will use a threadpool. This hugely improves KPL's performance and reduces consumedresources. By default, KPL still uses per-request mode. We shouldexplicitly switch FlinkKinesisProducer's KPL threading mode to 'Pooled'.This closes #4656.",2
[FLINK-7600] [kinesis] Shorten credential update delay to avoid updateCredentials ExceptionThe updateCredentials delay is an ignorable warning that occurs due tothe fact that the default credential update delay is longer than theawait termination timeout when shutting down KPL.See https://github.com/awslabs/amazon-kinesis-producer/issues/10 fordetails.This closes #4657.,0
[hotfix] Fix typo in Debugging Classloading documentationThis closes #4685.,2
[FLINK-7656] [runtime] Switch to user classloader before calling initializeOnMaster and finalizeOnMaster.This closes #4690.,5
[hotfix] Add ProcessOperator tests that verify side outputs work,1
[hotfix] Fix typos and other small things,2
"[hotfix] Remove leftover KeyedTimePanesRecently, the aligned window operators were removes, these classes whereleftover after that removal.",4
[FLINK-7635] Support side output in ProcessWindowFunction,1
[FLINK-7635] Add side-output test in WindowOperatorContractTest,3
[FLINK-7524] Remove potentially blocking behaviour from AbstractCloseableRegistry.,1
[FLINK-7619] Improved abstraction of AbstractAsyncIOCallable to better fit the current usage pattern.,1
[hotfix][runtime] Checkstyle changes in TaskStateSnapshot,4
"[FLINK-7541][runtime] Refactor StateAssignmentOperation and use OperatorIDThis is not complete refactor, some methods still relay on the order of thenew and old operators.",1
"[FLINK-7638] [flip6] Port CurrentJobsOverviewHandler to new REST endpointPorts the CurrentJobsOverviewHandler to the new REST endpoint by letting it implementthe LegacyRestHandler interface. This commit changes the JobDetails JSON such that itnow contains the number of tasks for each ExecutionState, including SCHEDULED,DEPLOYING, CREATED and RECONCILING. These state will now also be displayed in theweb frontend.Change MultipleJobsDetails to store a Collection<JobDetails> instead of JobDetails[]Use MultipleJobsDetails#FIELD_NAME_ for serialization in CurrentJobsOverviewHandlerThis closes #4688.",0
"Revert ""[FLINK-7541][runtime] Refactor StateAssignmentOperation and use OperatorID""This reverts commit f1b2b83d639658907bbc521f967e2673c4c866a1 because it makes theOperatorSubtaskState unserializable due to the usage of guava.Multimap.get. Thiseffectively breaks the master.",4
[FLINK-7439] [table] Support variable arguments for UDTF in SQLThis closes #4536.,1
[FLINK-7439] [table] Add possiblity to replace TypeExtractor call,4
"[FLINK-7664] Replace FlinkFutureException by java.util.concurrent.CompletionExceptionFlinkFutureException was introduced to fail a CompletableFuture callback. However, therewas already such a class which allows to better handle failures in different stages whichis the java.util.CompletionException. Therefore we replace FlinkFutureException byCompletionException and remove the former.This closes #4701.",4
[hotfix] [docs] Simplify and fix Table UDF docs,2
"[FLINK-7596] [table] Fix bug during Set Operation (Union, Minus ... ) with Any(GenericRelDataType)This closes #4658.",5
[FLINK-7596] [table] Restrict equality and improve tests,3
[hotfix] [docs] Method name for PatternFlatSelectFunction should be flatSelectThis closes #4687.,1
[FLINK-7393] [kinesis] Move unit tests of KinesisConfigUtil from FlinkKinesisConsumerTest to KinesisConfigUtilTestThis closes #4708.,5
[hotfix] [doc] Fix incorrect javaStream access on Scala DataStream API in docsThis closes #4704.,2
[FLINK-7647] [flip6] Port JobManagerConfigHandler to new REST endpointThis commit lets the JobManagerConfigHandler implement theLegacyRestHandler interface in order to be ported to the new RESTendpoint. This includes the introduction of ClusterConfigurationresponse body and ClusterConfigurationHeaders.The DispatcherRestEndpoint now also registers theJobManagerConfigHandler.,5
"[FLINK-7647] [flip6] Rename JobManagerConfigHandler to ClusterConfigHandlerThe original naming wouldn't make sense for the FLIP-6 redesign, sincewe would have multiple per-job JobManagers for each cluster, whichshares the same configuration.The REST path is still left untouched and not part of this commit, asthat would involve more changes in flink-runtime-web.",2
"[FLINK-7647] [flip6] Introduce test base for REST response marshallingIntroduces a common test base that for all REST responses, a subclassshould be implemented to verify that the response can be correctlymarshalled and unmarshalled.This closes #4691.This closes #4720.",3
[FLINK-7654] [rabbitmq] Update RabbitMQ Java client version to 4.2.0This closes #4694.,5
hotfix] [docs] Fix incorrect doc for s3a configuration for AWS deploymentThis closes #4679.,5
[FLINK-4047] [docs] Fix documentation about determinism of KeySelectorsThis closes #4659.,5
"[FLINK-4048] Remove Hadoop from DataSet APIThis removes all Hadoop-related methods from ExecutionEnvironment (thereare already equivalent methods in flink-hadoop-compatibility (seeHadoopUtils and HadoopInputs, etc.). This also removes Hadoop-specifictests from flink-tests because these are duplicated by tests inflink-hadoop-compatibility.This also removes Hadoop-specic example code from flink-examples: theDistCp example and related code.",2
[FLINK-4048] Remove Hadoop GenericOptionsParser from ParameterToolThere are methods for this in flink-hadoop-compatibility.,2
[FLINK-2268] Remove Hadoop-related Akka Serializers from runtime,1
[FLINK-2268] Remove unused HDFS copy-utils from flink-streaming-java,2
[FLINK-2268] Don't use Hadoop Writable in JoinOperatorTest,3
[FLINK-2268] Don't use commons-io ByteArrayOutputStream in NFATestcommons-io is only usable as a transitive dependency of the Hadoopdependencies. We can just use the Java ByteArrayOutputStream andget rid of that dependency.,1
[FLINK-2268] Don't use Hadoop FileSystem in RocksDB testsThis was in there because of legacy reasons but is not required by thetest.,3
"[FLINK-2268] Don't use jets3t in MesosArtifactServerThis was only used for the Enum for a specific http response type. Thejets3t dependency is only available as a transitive dependency of theHadoop dependencies, that's why we remove it.",4
[FLINK-2268] Only print Hadoop env info if Hadoop is in the classpath,5
[FLINK-2268] Close Hadoop FS reflectively in TestBaseUtilsThis removes the dependency on Hadoop and ensures that we only close ifHadoop is available.,4
[FLINK-2268] Remove Writable support from Scala TypeInformation Macro,5
[FLINK-2268] Dynamically load Hadoop security module when available,2
"[FLINK-2268] Don't include Hadoop deps in flink-core/flink-javaThis also makes them optional in flink-runtime, which is enabled by theprevious changes to only use Hadoop dependencies if they are available.This also requires adding a few explicit dependencies in other modulesbecause they were using transitive dependencies of the Hadoop deps. Themost common dependency there is, ha!, commons-io.",1
[FLINK-2268] Allow not including the Hadoop uber jar,1
[hotfix] Fix containerized.master.env.* config options,5
[hotfix] Make SecurityUtils.SecurityConfiguration a toplevel class,5
[hotfix] Java 8-ify HadoopSecurityContext,0
[FLINK-7663] [flip6] Return BAD_REQUEST if HandlerRequest cannot be createdThis commit changes the behaviour such that a failure in creating a HandlerRequest willresult in a BAD_REQUEST response by the AbstractRestHandler.This closes #4699.,0
[FLINK-7723] [tests] Harden DispatcherTestThe problem was that the DispatcherTest#testJobSubmission did not properly wait untilthe Dispatcher has been granted leadership.,3
"[FLINK-7650] [flip6] Port JobCancellationHandler to new REST endpointLet the JobCancellationHandler implement the LegacyRestHandler interface. Moreover,this commit adds the DELETE method to HttpMethodWrapper and theRestServerEndpoint#registerHandler method.Add PATCH methodThis closes #4697.",1
"[FLINK-7649] [flip6] Extend JobTerminationHandler to support stopRename the JobCancellationHandler into JobTerminationHandler which is now responsiblefor terminating jobs. Moreover, this commits adds two termination modes, cancel and stop,which are specified by providing a query parameter.This closes #4700.",2
[FLINK-7487][tests] fix ClassLoaderITCase#testDisposeSavepointWithCustomKvState not self-containedThe cancellation of the job started in #testDisposeSavepointWithCustomKvStatemay actually continue after the test method succeeds and may thus stop furtherjobs from being executed. This may result in a NoResourceAvailableException.[FLINK-7487][tests] address PR commentsThis closes #4571.,1
[FLINK-7513][tests] remove TestBufferFactory#MOCK_BUFFERThis static buffer did not allow proper reference counting and we should rathercreate test buffers in the tests which may also be released afterwards.[FLINK-7513][tests] address PR comments* inline buffer.retain() into the buffer use instead of having it on a separatelineThis closes #4590.,1
[FLINK-7514][tests] fix BackPressureStatsTrackerITCase releasing buffers twiceThis closes #4591.,0
[FLINK-7411][network] minor (performance) improvements in NettyMessage* use a switch rather than multiple if conditions* use static `readFrom` methods to create instances of the message sub typesThis closes #4517.,1
[FLINK-7724] [metrics] Add extra metrics to MetricStoreTest.setupStoreThis closes #4739.,3
[FLINK-7675] [metrics] LatestCompletedCheckpointExternalPathGauge should check if external path is existThis closes #4709.,3
[FLINK-7645] [docs][metrics] Add system-metrics subsections to ToCThis closes #4693.,5
[FLINK-7659] Fix unprotected access to inProgress in JobCancellationWithSavepointHandlers#handleNewRequestThis closes #4703.,0
[FLINK-4664] [webUI] Show uploaded-jars descending by upload timeThis closes #4664.,2
[hotfix] [REST] Add note about placement of FileServerHandler,2
[FLINK-7725] [REST] Add testbase for requests / allow exceptions,1
"[FLINK-7438] [scala] Remove unused importThese classes imported the org.apache.flink.util.OutputTag class, which was however not used sincea scala OutputTag class exists in the same package. This caused the compiler to throw warningsas the import was overshadowed by the package local class.This closes #4570.",2
[FLINK-7674] Fix NullPointerException in ContinuousFileMonitoringFunction#closeThis closes #4711.,2
"[FLINK-7541][runtime] Refactor StateAssignmentOperation and use OperatorIDThis is not complete refactor, some methods still relay on the order of thenew and old operators.This closes #4609.",1
[FLINK-7683][state backends] Introduce iterator for keys in KeyedStateBackend.This closes #4722.,2
[hotfix] Add checkstyle suppressions for StateBackendTestBaseThe commits after this one move consolidated tests to this file whichbreaks the 3000 lines limit.,4
[FLINK-5619] Add numStateEntries() method for all keyed backendsThis also adds a test for this in StateBackendTestBase,3
[FLINK-5619] Consolidate ListState Tests in StateBackendTestBase,3
[FLINK-5619] Consolidate ReducingState Tests in StateBackendTestBase,3
[FLINK-5619] Consolidate AggregatingState Tests in StateBackendTestBase,3
"[FLINK-7547] Make AsyncFunction.scala extends FunctionBefore, the Scala AsyncFunction was not Serializable. Function isderived from Serializable.",1
[FLINK-7734] [tests] Harden ResourceManagerTest#testHeartbeatTimeoutWithTaskExecutorThe problem was that we did not on the leader election to complete before sending anRPC message.,0
[FLINK-7667] [flip6] Use ArchivedExecutionGraph as serializable AccessExecutionGraphThis commit removes AccessExecutionGraph#getCheckpointCoordinator and changes theAccessExecutionGraph#getJobCheckpointSettings into #getJobCheckpointConfiguration.The JobCheckpointConfiguration only contains the CheckpointCoordinator relevantconfiguration settings and excludes the serialized state backend and theserialized master hooks. That way we don't send unnecessary information whenthe ArchivedExecutionGraph is requested.This closes #4727.,5
[hotfix] [REST] Extend empty request/parameters support[hotfix] [REST] Fix error message if empty request does not conform to RequestBody spec[hotfix] [REST] Add special handling for plain-text responsesThis closes #4730.,1
[FLINK-7662] [build] Remove now obsolete packaged licenses for previously shaded ASM,4
"[FLINK-7721] [DataStream] Only emit new min watermark iff it was aggregated from watermark-aligned inputsPrior to this commit, In the calculation of the new min watermark inStatusWatermarkValve#findAndOutputNewMinWatermarkAcrossAlignedChannels(),there is no verification that the calculated new min watermarkreally is aggregated from some aligned channel.In the corner case where all input channels are currently not alignedbut actually some are active, we would then incorrectly determine thatthe final aggregation is Long.MAX_VALUE and emit that.This commit fixes this by only emitting the aggregated watermark iff it wasreally calculated from some aligned input channel (as well as thealready existing constraint that it needs to be larger than the lastemitted watermark). This change should also safely cover the case that aLong.MAX_VALUE was genuinely aggregated from the input channels.",4
"[FLINK-7728] [DataStream] Simplify BufferedValveOutputHandler used in StatusWatermarkValveTestThe previous implementation was overly complicated. Having separatebuffers for the StreamStatus and Watermarks is not required for ourtests. Also, that design doesn't allow checking the order StreamStatus /Watermarks are emitted from a single input to the valve.This commit reworks it by buffering both StreamStatus and Watermarks ina shared queue.",1
"[FLINK-7728] [DataStream] Flush max watermark across all inputs once all become idlePrior to this commit, once all inputs of the StatusWatermarkValvebecomes idle, we only emit the StreamStatus.IDLE marker, and checknothing else. This makes the watermark advancement behaviourinconsistent in the case that all inputs become idle depending on theorder that they become idle.This commit fixes this by ""flushing"" the max watermark across allchannels once all inputs become idle. At a high-level, what this meansfor downstream operators is that all inputs have become idle and willtemporariliy cease to advance their watermarks, so they can safelyadvance their event time to whatever the largest watermark is.",1
"[FLINK-7728] [DataStream] Make StatusWatermarkValve unit tests more fine-grainedPreviously, the unit tests in StatusWatermarkValveTest were toocluttered and testing too many behaviours in a single test. This makesit hard to have a good overview of what test cases are covered.This commit is a rework of the previous tests, making them morefine-grained so that the scope of each test is small enough. Allpreviously tested behaviours are still covered.",3
[FLINK-7721] Verify StatusWatermarkValve only emits WM iff it has aligned inputs,2
"[FLINK-7668] Add ExecutionGraphCache for ExecutionGraph based REST handlersThe ExecutionGraphCache replaces the ExecutionGraphHolder. Unlike the latter, the formerdoes not expect the AccessExecutionGraph to be the true ExecutionGraph. Instead it assumesit to be the ArchivedExecutionGraph. Therefore, it invalidates the cache entries aftera given time to live period. This will trigger requesting the AccessExecutionGraph againand, thus, updating the ExecutionGraph information for the ExecutionGraph based RESThandlers.In order to avoid memory leaks, the WebRuntimeMonitor starts now a periodic cleanup taskwhich triggers ExecutionGraphCache.cleanup. This methods releases all cache entries whichhave exceeded their time to live. Currently it is set to 20 * refreshInterval of theweb gui.This closes #4728.",1
[FLINK-7695] [flip6] Add JobConfigHandler for new RestServerEndpointThis closes #4737.,1
"[FLINK-7708] [flip6] Add CheckpointConfigHandler for new REST endpointThis commit implements the CheckpointConfigHandler which now returns aCheckpointConfigInfo object if checkpointing is enabled. In case thatcheckpointing is disabled for a job, it will return a 404 response.This closes #4744.",0
[FLINK-7710] [flip6] Add CheckpointStatisticsHandler for the new REST endpointThis commit also makes the CheckpointStatsHistory object serializable by removing theCheckpointStatsHistoryIterable and replacing it with a static ArrayList.This closes #4750.,4
[hotfix] [dispatcher] Remove leftover javadoc from DispatcherGateway,2
[FLINK-7412][network] optimise NettyMessage.TaskEventRequest#readFrom() to read from netty buffers directlyThis closes #4518.,2
[FLINK-7752] [flip-6] RedirectHandler should execute on the IO threadThis closes #4766.,0
[hotfix] [hbase] Set root log level to OFF for flink-hbase tests.Log level is changed due to a buggy Calcite check that causes a NPE.The check is only performed if log level DEBUG is enabled.This closes #4771,0
[hotfix] Fix testing log level in flink-runtime,2
[hotfix] [core] Prevent potential null pointer in MemorySize.equals(...),0
[FLINK-7446] [table] Change DefinedRowtimeAttribute to work on existing field.This closes #4710.,1
[FLINK-7754] [rpc] Complete termination future after actor has been stoppedThis commit waits not only until the Actor has called postStop but also until the actorhas been completely shut down by the ActorSystem before completing the terminationfuture.This closes #4770.,5
"[FLINK-7483][blob] prevent cleanup of re-registered jobsWhen a job is registered, it may have been released before and we thus need toreset the cleanup timeout again.",4
"[FLINK-7057][tests][hotfix] fix test instability of JobManagerCleanupITCase#testBlobServerCleanupCancelledJobThis test expected two messages to arrice (job cancellation and job state changenotification) but did not take different receive orders into account. The fix:- removes state change listening for this test case so that only one message  arrives, and- adds message comparison by object, not just class (to improve debugging)",0
"[FLINK-7068][blob] change BlobService sub-classes for permanent and transient BLOBs[FLINK-7068][blob] start introducing a new BLOB storage abstractionThis is incomplete and may not compile and/or run tests successfully yet.[FLINK-7068][blob] remove BlobView from TransientBlobCacheThe transient BLOB cache is not supposed to work with the HA store since it onlyserves non-HA files.[FLINK-7068][blob] remove unnecessary use of BlobClient[FLINK-7068][blob] implement TransientBlobCache#put methods[FLINK-7068][blob] remove further unnecessary use of BlobClient and adapt to HA get/put methods[FLINK-7068][blob] fix BlobServer#getFileInternal not being guarded by locks[FLINK-7068][blob] add incoming file cleanup at BlobServer in cases of errors[FLINK-7068] fix missing BlobServer#putHA() jobId propagation[FLINK-7068][blob] remove BlobClient use from BlobServer{Get|Put}Test[FLINK-7068][blob] make helper methods work with any BlobService[FLINK-7068][blob] start adding a BlobCacheGetTest[FLINK-7068][blob] verify get contents in separate threadsThis allows (at a slight chance) that we may see an intermediate file.[FLINK-7068][blob] better locking granularity during file retrievalThis allows multiple parallel downloads from the HA store to the BlobServer'slocal store although only one of these downloaded staging files will actuallybe used. In practice, this happens only during recovery and not in parallelanyways.[FLINK-7068][blob] share more code among BlobServer and BlobServerConnectionThis also applies the better locking granularity of the previous commit toBlobServerConnection.[FLINK-7068][blob] properly cleanup temporary staging files in all cases[FLINK-7068][blob] make PermanentBlobCache and TransientBlobCache thread-safe[FLINK-7068][tests] improve various tests[FLINK-7068][blob] change the signature of the delete calls to return successWe will not throw exceptions in case of failures anymore and return whether theoperation was successful instead. Failure details will still be accessible inthe written logs.[FLINK-7068][tests] extend and adapt BlobServerDeleteTest[FLINK-7068][tests] adapt further BlobCache tests[FLINK-7068][tests] adapt BlobClientTest[FLINK-7068][blob] cleanup BlobClient methodsBlobClient is not supposed to be used by anyone else than theBlobServer/BlobCache classes. Most accessors were already package-private, nowremove the ones that just blow up the code.[FLINK-7068] add a TODO to fix the currently failing tests[FLINK-7068][tests] add a BlobCacheRecoveryTestThis currently fails due to TransientBlobCache#put also storing files in HAstore which it should not![FLINK-7068][tests] improve failure message[FLINK-7068][blob] add permanent/transient BLOB modes to BlobClientThis allows a better control of which should end up in HA store and which shouldnot. Also, during GET methods, we do not check the HA store unnecessarily.[FLINK-7068][tests] extend the Blob{Server|Cache}GetTestThis adds some failing GET operations and verifies that the files are cleanedup accordingly.[FLINK-7068][blob] remove ""final"" flag from BlobCache classThis re-enables mocking in various unit tests.[FLINK-7068][tests] fix test relying on order of folder contents[FLINK-7068][blob] some BlobServer cleanup[FLINK-7068][hotfix] fix checkstyle errors[FLINK-7068][tests] fix tests now requiring a more complete BlobCache mockA suitable BlobCache mock should at least return a mock for a permanent and atransient BLOB store, so mock(BlobCache.class) is not sufficient anymore.[FLINK-7068] final wrap up* remove a left-over TODO* remove useless tests for the concurrency of the GET operations (we cannot testthat the file write is guarded by a lock directly - rely on the concurrentchecks in the individual threads instead)* fix some log messages[FLINK-7068][blob] remove Thread#start() call from BlobServer constructorThis is bad design and limits extensibility, e.g. in tests like theBlobCacheRetriesTest where this caused a race condition with the sub-class.Instead, the user must now call BlobServer#start() explicitely.[FLINK-7068][tests] remove unused imports[FLINK-7068][tests] fix a typo[FLINK-7068][tests] add some tests that verify behaviour with corrupted filesAlso add corruption checks for HA-store downloads which was not implemented yet.[FLINK-7068][blob] ensure consistency in PermanentBlobCache even in cases of invalid useDuring cleanup, no write lock was taken but the storage directory of an(unused!) job was deleted. Normally, there should be no process left accessingits data and no new process can jump in since the registration is locked. Incase of invalid use cases, i.e. using a job's data outside a register() andrelease() block, this could lead to strange effects.By guarding the cleanup with the write lock as well, we circumvent that.[FLINK-7068][hotfix] remove an unused import",2
"[FLINK-7261][blob] extend BlobStore#get/put with boolean return valuesThis way, using code can distinguish non-HA cases, i.e. VoidBlobStore, fromHA cases, i.e. FileSystemBlobStore, in a general way and have better errorreporting.",0
"[FLINK-7068][blob] Introduce permanent and transient BLOB keys[FLINK-7068][blob] address PR review comments, part 1[FLINK-7068][blob] create a common base class for the BLOB caches[FLINK-7068][blob] update some comments[FLINK-7068][blob] integrate the BLOB type into the BlobKey[FLINK-7068][blob] rename a few methods for better consistency[FLINK-7068][blob] fix Blob*DeleteTest not working as documented in one test[FLINK-7068][blob] add checks for jobId being null in PermanentBlobCache[FLINK-7068][blob] implement get-and-delete logic for transient BLOBsTransient BLOB files are deleted on the BlobServer upon first access from acache. Therefore, we do not need the DELETE operations anymore, aside fromdeleting the file from the local cache (for now).[FLINK-7068][blob] address PR comments, part 2[FLINK-7068][blob] separate permanent and transient BLOB keys* create PermanentBlobKey and TransientBlobKey (inheriting from BlobKey) and  forbid using transient BLOBs with permanent caches and vice versa* make BlobKey package-private, similarly for the BlobType which is now  reflected by the two BlobKey sub-classes-> this gives a cleaner interface for the userThis closes #4358.",1
"[FLINK-7643] [core] Misc. cleanups in FileSystem  - Simplify access to local file system  - Use a fair lock for all FileSystem.get() operations  - Robust falback to local fs for default scheme (avoids URI parsing error on Windows)  - Deprecate 'getDefaultBlockSize()'  - Deprecate create(...) with block sizes and replication factor, which is not applicable to many FS",1
"[FLINK-7643] [core] Drop eager checks for file system support.Some places validate if the file URIs are resolvable on the client. This leads toproblems when file systems are not accessible from the client, when the full libraries forthe file systems are not present on the client (for example often the case in cloud setups),or when the configuration on the client is different from the nodes/containers that willexecute the application.",5
[FLINK-7643] [core] Rework FileSystem loading to use factoriesThis makes sure that configurations are loaded once and file system instances areproperly reused by scheme and authority.This also factors out a lot of the special treatment of Hadoop file systems and simplymakes the Hadoop File System factory the default fallback factory.,5
"[FLINK-7766] [file system sink] Drop obsolete reflective hflush callsThis was done reflectively before for Hadoop 1 compatibility.Since Hadoop 1 is no longer supported, this is obsolete now.",1
[FLINK-7767] [file system sinks] Avoid loading Hadoop conf dynamically at runtime,1
"[FLINK-7768] [core] Load File Systems via Java Service abstractionThis changes the discovery mechanism of file from static class name configurationsto a service mechanism (META-INF/services).As part of that, it factors HDFS and MapR FS implementations into separate modules.With this change, users can add new filesystem implementations and make them availableby simply adding them to the class path.",1
[hotfix] [build] Properly exclude flink-python artifact from fat dist jar,2
"[hotfix] [build] Remove incorrect and ineffective example exclusionsThe examples are not part of dist's dependencies, hence no need to exclude themfrom the fat jar.The exclusion did not work anyways, because it used wrong artifact names(not using scala suffixes).",0
"[hotfix] [build] Remove no longer needed explicit Hadoop exclusionsNow that Hadoop is an optinal dependency, all the explicit exclusionsduring shading are no longer needed.",4
[FLINK-7772][blob] fix test instability in BlobCacheDeleteTestBlobCacheDeleteTest did not account for the server executing the delete call ofa transient BLOB after acknowledging the request. This resulted in thetestDeleteTransientLocalFails* tests failing.This closes #4782,0
[FLINK-7739] [kafka connector] Fix test instabilities  - Set shorter heartbeats intervals. Default pause value of 60seconds is    too large (tests would timeout before akka react)  - Exclude netty dependency from zookeeper. Zookeeper was pulling in    conflicting Netty version. Conflict was extremly subtle - TaskManager in    Kafka tests was deadlocking in some rare corner cases.This closes #4775,3
[FLINK-7742] [java api] [runtime] Fix array index out of bounds exceptionsThis closes #4754,0
[hotfix] [docs] Fix broken linksThis closes #4755,2
[FLINK-7312] [checkstyle] Enable checkstyle for 'flink/core/memory/*'We deliberately ignore redundant modifiers for now since we want `final`modifiers on `final` classes for increased future-proofness.,1
"[FLINK-7310] [core] always use the HybridMemorySegmentSince we'd like to use our own off-heap buffers for network communication, wecannot use HeapMemorySegment anymore and need to rely on HybridMemorySegment.We thus drop any code that loads the HeapMemorySegment (it is still availableif needed) in favour of the HybridMemorySegment which is able to work on bothheap and off-heap memory.For the performance penalty of this change compared to using HeapMemorySegmentalone, see this interesting blob article (from 2015):https://flink.apache.org/news/2015/09/16/off-heap-memory.htmlThis closes #4445",2
"[FLINK-7575] [webui] Show ""Fetching"" instead of 0 when IO metrics are not yet retrievedThis closes #4647.",2
[FLINK-7761] [examples] Include shaded guava dependency in Twitter example jarThis closes #4773.,2
[hotfix] Don't use deprecated writeWithTimestamps in Kafka 0.10 tests,3
[FLINK-6988] Make TwoPhaseCommitSinkFunction work with Context,1
[FLINK-6988] Add Kafka 0.11 connector maven module,1
[FLINK-6988][kafka] Implement our own KafkaProducer class with transactions recovery,2
[FLINK-6988][kafka] Add flink-connector-kafka-0.11 with exactly-once semantic,2
[hotfix][streaming] Fix typo in parameter and unify naming in test harnesses,3
[FLINK-6988][kafka] Add test for failure before before checkpoint and scaling down,0
[FLINK-6988][kafka] Add Kafka 0.11 tests for scaling down and up again,3
[hotfix] [REST] Add utility HandlerRequest constructor,0
"[FLINK-7072] [REST] Define protocol for job submit/cancel/stop[FLINK-7072] [REST] Extend Dispatcher[FLINK-7072] [REST] Add handlers for job submit/cancel/stop[FLINK-7072] [REST] CLI integrationuse ExecutorThradFactory + rebase(blobKey fix)add ""Flink"" prefix to RestCC threadsshutdown client for cancel/shutdownRework CliFrontEnd Stop/Cancel testsThese tests verified that the CLI was sending the correct messages andparameters to the JM actor. This is now handled by the ClusterClient, sothe tests were adjusted to verify that the correct methods on theClusterClient are being called.Additional tests were added to the ClusterClientTest class to verifythat the correct messages and parameters are being sent.This closes #4742.",2
[FLINK-7744][docs] Add missing top links to documentationThis closes #4756.,2
[hotfix] [docs] Polish grammar and tone for consistency and clarityThis closes #4760.,1
[FLINK-7632] [docs] Overhaul Cassandra connector docsRefactor the current usage of on Cassandra Sink w/ more in-depth information.Provides examples for Pojo and Java Tuple data typesThis closes #4696.,5
"[hotfix] Remove exception stack trace from Emitter shutdown messageBefore, we were printing the exception (and stack trace) when the AsyncI/O Emitter was receving an interrupted exception. The interrupt,however is part of the normal shutdown process of the Emitter and thelog message was causing concern because a stack trace usually indicatessomething went wrong.",0
[FLINK-7378][core] Create a fix size (non rebalancing) buffer pool type for the floating buffersThis closes #4485.,0
[FLINK-7394][core] Manage exclusive buffers in RemoteInputChannelThis closes #4499.,2
[FLINK-7699][core] Define the BufferListener interface to replace EventlListener in BufferProviderThis closes #4735.,1
[FLINK-7790] [REST] Unresolved query params not added to request URLThis close s#4788.,1
[FLINK-7709] Add CheckpointStatisticDetailsHandler for new REST endpointDisable failing when not all creator properties are knownMove CheckpointStatsCache out of legacy package; Remove unused CheckpointingStatistics#generateCheckpointStatistics methodRemove JsonInclude.Include.NON_NULL from CheckpointStatistics; Pull null check out of CheckpointStatistics#generateCheckpointStatistics; Make CheckpointStatistics#checkpointStatisticcsPerTask non nullable; Add fail on missing creator propertyThis closes #4763.,5
[FLINK-7704] [flip6] Add JobPlanHandler for new RestServerEndpointThis closes #4768.,1
[FLINK-6233] [table] Add inner rowtime window join between two streams for SQL.This closes #4625.,1
[FLINK-6233] [table] Add more tests for rowtime window join + minor refactoring.,4
[FLINK-7776] [table] Prevent emission of identical update records in group aggregation.This closes #4785.,5
[FLINK-7491] [table] Add MultiSet type and COLLECT aggregation function to SQL.This closes #4585.,1
[FLINK-7410] [table] Use UserDefinedFunction.toString() to display operator names of UDFs.This closes #4624.,1
[FLINK-7792] [tests][client] Only suppress stdout for CLI testsThis closes #4792.,3
[refactor] [tests] Refactor CliFrontend mocking into utility class,4
[refactor] [tests] Generalize gateway mocking in ClusterClientTest,3
[refactor] [tests] Generalize test handler generation,0
[FLINK-7780] [Client] Move savepoint logic into ClusterClient,2
[FLINK-7780] [REST] Define savepoint trigger protocolThis closes #4789.,2
[hotfix] [rpc] Add more logging for endpoint shutdown,2
[FLINK-7707] [flip6] Add TaskCheckpointStatisticDetailsHandler for new REST endpointThis closes #4772.,1
[FLINK-7769][QS] Move queryable state outside the runtime.Creates a separate for the queryable state and  moves the clientcode outside the runtime. The Task Manager is now instantiatingthe KvStateServer using reflection.,1
"[FLINK-7770][QS] Hide the queryable state behind a proxy.Previously the QueryableStateClient could connect to the JMand the TMs directly to fetch the required state. Now, thereis a proxy running on each TM and the remote client connectsto one of these proxies in order to get its state. The proxyreceives the request from the client, performs all necessarymessage exchanges within the Flink cluster, receives the stateand forwards it back to the client.This architecture allows for more security features to beintegrated in the future, as the proxy is running in thecluster, it exposes less information about the cluster tothe outside world, and is more suitable for containerizedenvironments.",5
"[hotfix] Harden TaskExecutorTest#testSlotAcceptanceThe test did not properly wait for the registration of the TaskExecutor at theResourceManager. Therefore, it could come to a race condition between sendingan initial SlotReport and a separate message for the newly added slots.",1
[FLINK-7661][network] Add credit field in PartitionRequest messageThis closes #4698.,1
[FLINK-7808] [REST] JobDetails constructor checks size of tasksPerState argumentThis closes #4800.,2
[FLINK-7807] [REST] Log exceptions in HandlerUtils methodsThis closes #7807.,0
[hotfix][doc] Remove outdated best-practice suggestion to use .withParameters()This way of passing parameters does not work with the streaming API andis actually confusing for users.This closes #4797.,1
[hotfix] [Javadoc] Fix typo in Javadoc for class InputTypeConfigurable,5
[hotfix] [Javadoc] Fix typo in Javadoc for class FileSystemThis closes #4791.,5
[hotfix] Convert queryable state POMs to tabs,0
[FLINK-7660] Support sideOutput in ProcessAllWindowFunction,1
[doc] Add ProcessWindowFunction to side output doc,2
[FLINK-7818] Synchronize MetricStore access in TaskManagersHandlerThis closes #4811.,0
"[FLINK-7653] Properly implement Dispatcher#requestClusterOverviewThis commit implements the ClusterOverview generation on the Dispatcher. Inorder to do this, the Dispatcher requests the ResourceOverview from theResourceManager and the job status from all JobMasters. After receiving allinformation, it is compiled into the ClusterOverview.Note: StatusOverview has been renamed to ClusterOverviewThis closes #4793.",5
[FLINK-7763] [table] Fix testing RowSink for enabled object reuse.,1
[FLINK-7835][cep] Fix duplicate() in NFASerializer.,0
[FLINK-7414] Pin scala quickstart to 2.11Pinning it to the latest version means the order in which we deploy tomaven doesn't matter anymore.,3
[FLINK-7484] Perform proper deep copy in CaseClassSerializer.duplicate()This also adds a test that verifies the deep copy.,3
[FLINK-6615] [core] (followup) Add one more test for FileUtils,2
"[hotfix] [docs] Remove weasel words, fix passive voice, typos and formattingThis closes #4816",2
"[FLINK-5706] [file systems] Add S3 file systems without Hadoop dependenciesThis adds two implementations of a file system that write to S3.Both are not actual re-implementations but wrap other implementations and shade dependencies.(1) A wrapper around Hadoop's s3a file system. By pulling a smaller dependency tree and    shading all dependencies away, this keeps the appearance of Flink being Hadoop-free,    from a dependency perspective.(2) The second S3 file system is from the Presto Project.    Initial simple tests seem to indicate that it responds slightly faster    and in a bit more lightweight manner to write/read/list requests, compared    to the Hadoop s3a FS, but it has some semantical differences.This closes #4818",3
[hotfix] [tests] Move Kryo Registrations test to flink-runtime,2
"[hotfix] [scala api] Move tests to correct packageWe previously had all Scala API unit tests in the flink-testsproject, because Eclipse could not use macros in 'test' that weredeclared in 'main'.Because we do not support Eclipse for development of the system anymore (only for using Flink to develop Flink-based applications),we can now move the tests to their natural location and simplifysome of the dependency structures.",3
[hotfix] [scala api] Fix compiler warnings in Scala API,2
[FLINK-7809] Remove support for Scala 2.10,1
[FLINK-7810] [build] Switch from custom Flakka to Akka 2.4.xWe can do this now that we dropped support for Scala 2.10.This closes #4807,1
[FLINK-7810] [build] (follow-up) Exclude unneeded dependencies from bumped akka,2
[hotfix] [docs] Minor improvements to the 'building form source' guide.,1
[hotfix] [build] Filter out unnecessary maven JAR entries from 'force-shading',1
[FLINK-7842] [build] Shade org.codehouse.jackson in Hadoop,1
[FLINK-7419] [build] Shade jackson dependency in flink-avroThis closes #5424,2
[hotfix] [build] Exclude jline from ZooKeeper dependenciesjlnie is a command line shell used optionally for ZK'scommand line tool.,1
[FLINK-7774][network] fix not clearing deserializers on closing an inputThis closes #4783.,0
[FLINK-6703][docs] Document how to take a savepoint on YARNThis closes #4721.,2
[FLINK-6805] [cassandra] Shade indirect netty4 dependencyTo relocate various *indirect* netty4 dep of ver 4.0.33.Final toclasspath of Flink flavor using Maven shade plugin.This closes #4545.,1
[FLINK-7791] [Client] Move LIST logic into ClusterClient,2
[FLINK-7791] [REST][client] Integrate LIST command into RestClusterClientThis closes #4802.,2
"[build] Move licenses for shaded dependencies into the NOTICE fileIn accordance with the Apache Software License 2.0, the NOTICEfile is the dedicated/prefered place for any additional licenseinformation that affects redistribution, because the NOTICEfile is required to be included in any redistribution.The only project still having shaded dependencies that requireextra license statements is flink-table. Changing the licensesto be in the NOTICE file also allows removing the maven-resourceplugin from the root pom.xml",5
[hotfix] [build] Change akka-remote exclusion pattern to fix maven warnings,2
"[hotfix] [build] Small improvements to the flink-mesos build  - The newer akka versions have no protobuf dependency and need no exclusion any more  - The transitive dependency promotion is ineffective here, disabling it makes    it more robust against accidentally pulling in more dependencies in the future  - Properly specifying the shaded dependencies is safer",1
"[hotfix] [build] Remove outdated and obsolete plugin config in flink-runtime    This removes an outdates plugin configuration for surefire, excluding    certain test data files which were way back conflicting with the test    naming pattern.",3
[FLINK-7140][blob] add an additional random component into the BlobKeyThis should guard us from uploading (and deleting) the same file more thanonce and also from hash collisions.This closes #4359.,2
"[FLINK-7810] Add more excludes in end-to-end testsWith the switch to Akka 2.4 this message can crop up in the logs, it'sonly a warning, though.",2
[FLINK-7495] Call to AbstractUdfStreamOperator#initializeState() in the beginning,5
[hotfix] Change order of reduce and fold in window documentationIn the section about incremental aggregation with a window function theorder of fold and reduce was different from the order of fold and reducein the rest of the documentation.,2
[hotfix] Change WindowFunction to ProcessWindowFunction in window docThere were some places where the doc still referred to WindowFunctionwhere ProcessWindowFunction should be used instead now.,1
[FLINK-7371] [table] Add support for constant parameters in OVER aggregateThis closes #4736.,2
[FLINK-7798] [table] Add support for stream time-windowed inner join to Table APIThis closes #4825.,1
[FLINK-7426] [table] Support null values in keysThis closes #4732.,1
[FLINK-7785] [tests] Harden DispatcherTestStart dispatchers with different endpoint ids in order to avoid name clashes in casethat the previous Dispatcher has not been completely shut down. This is recommendedpractice by Akka.,1
"[FLINK-7788][QS] Allow specification of port range for queryable state proxy.The queryable state client proxy can now take a port range as argumentso that if multiple proxies run on one machine, they can all start withoutproblems.",0
[FLINK-5920][QS] Allow specification of port range for queryable state server.,1
[FLINK-7826][QS] Add support for all types of state to the QS Client.,1
[FLINK-7757] [checkpointing] Introduce resource guard for RocksDBKeyedStateBackend to reduce locking and avoid blocking behavior.This closes #4764.,5
[FLINK-7813] [metrics] Replace MetricRegistryThreadFactoryThis closes #4803.,1
[FLINK-7703] Port JobExceptionsHandler to new REST endpointThis closes #4834.,1
[hotfix] Fix typo in CassandraSink,2
[FLINK-6314] [cassandra] Support user-defined Mapper optionsThis closes #4831.,1
[FLINK-7853] [table] Reject table function outer joins with predicates in Table API.This closes #4842.,1
[hotfix] Add QueryableState module to Libraries travis build.,1
[hotfix] Rename QS ITCases to end in ITCase.,0
[FLINK-7021] [core] Handle Zookeeper leader retrieval error in TaskManager and throw RuntimeExceptionThis closes #4214.,1
"[FLINK-7021] Unregister ZooKeeperLeaderRetrievalService from CuratorFramework at shut downWhen stopping the ZooKeeperLeaderRetrievalService, then we also have to unregister thisfrom the CuratorFramework#getUnhandledErrorListenable.",0
[FLINK-7021] Add UnhandledErrorListener to ZooKeeperLeaderElectionService,0
[FLINK-7759] [table] Add support for field names with Boolean prefix.This closes #4829.,0
[FLINK-7802] [table] Fix projection of all fields in CsvTableSource.This closes #4815.,0
[FLINK-7854] [table] Reject lateral table outer joins with predicates in SQL.This closes #4846.,2
[FLINK-5372] [tests] Fix RocksDBAsyncSnapshotTest.testCancelFullyAsyncCheckpoints(),5
[hotfix][javadocs] Fix typos in RuntimeContextThis closes #4864.,1
"[hotfix][docs][javadocs] Remove double ""the""This closes #4865.",4
[FLINK-6907][core] Extend TupleGenerator javadocsThis closes #4850.,2
[FLINK-7831] Make last received heartbeat retrievableThis commit adds functionality to retrieve the last received heartbeat fromthe HeartbeatManager.This closes #4817.,1
[FLINK-7861] [flip6] Suppress ActorKilledException loggingIntroduce a StoppingSupervisorWithoutLoggingStrategy which only logs theActorKilledException on debug level and all other exceptions on error level.This closes #4845.,0
[FLINK-7874] Add logging to the ClusterEntrypointsThis closes #4860.,1
[FLINK-7875] [flip6] Start StaticFileServerHandler with random tmp dirThis closes #4861.,2
[FLINK-7855] [flip6] Port JobVertexAccumulatorsHandler to REST endpoint,0
[FLINK-7855] [flip6] Add JobVertexMessageParametersThis closes #4857.,2
[FLINK-7837] Extend AggregateFunction.add() to work with immutable types,1
[FLINK-5968] Add documentation for WindowedStream.aggregate(),2
[FLINK-7839] [doc] Add a note on possible maven failure for creating quickstart project.This only applies before project release; {%site.is_stable == false %}.Add an warning note on recent Maven change (3.0+) for -DarchetypeCatalog while creating quickstart project.,1
[FLINK-7832] [flip6] Extend SlotManager to report free slots per TMFail if slot belongs to a unregistered TaskManagerAdd more sanity checksMake the TaskManagerSlot state transitions clearerIntroduce proper TaskManagerSlot state enumRefactor SlotManager for better maintainabilityThis closes #4823.,1
"[FLINK-7196][blob] add a TTL to all transient BLOBsTransient BLOB files should not exist for long and are only deleted manuallyfrom the caches and after access on the server. This uses the BLOB storage'scleanup interval to set a TTL on all transient BLOB files as a backup cleanuppath. The cleanup task itself runs every cleanupInterval seconds and removes alltransient BLOBs for which the TTL is older than the current time. This way, atransient BLOB stays at most 2*cleanupInterval seconds before getting deletedautomatically.This closes #4381.",4
[FLINK-7262][blob] remove the unused FallbackLibraryCacheManagerThis class was basically only used in unit tests and not really needed thereeither. The code path inside TaskManager was also dead.This closes #4403.,3
[FLINK-7793] [flip6] Defer slot release to ResourceManagerThis commit changes the SlotManager behaviour such that upon a TaskManager timeoutthe ResourceManager is only notified about it without removing the slots. TheResourceManager can then decide whether it stops the TaskManager and removes the slotsfrom the SlotManager or to keep the TaskManager still around.Add test caseThis closes #4795.,1
[hotfix] Remove redundant job status logging,2
[hotfix] Harden SlotManagerTest#testTaskManagerTimeoutDoesNotRemoveSlots,3
"[hotfix] Ignore unstable Queryable State RocksDB integration testsThe tests are sometimes failing with:Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.353 sec - in org.apache.flink.queryablestate.itcases.NonHAQueryableStateRocksDBBackendITCasepure virtual method calledterminate called without an active exceptionTests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.722 sec - in org.apache.flink.queryablestate.itcases.HAQueryableStateRocksDBBackendITCaseAborted (core dumped)",5
[FLINK-7579] [Documentation] More accurate description of yarn.application-attempts.This closes #4642.,2
"[FLINK-7898] [flip6] Don't propagate CancellationExceptions in RegisteredRpcConnectionThe RegisteredRpcConnection should not call the exception handler when the RetryingRegistration futurefailed with a cancellation exception, because this is how the future is completed in case of stoppingthe RetryingRegistration.",1
[FLINK-7899] Harden SlotManagerTest#testTaskManagerTimeoutDoesNotRemoveSlots by increasing timeout,1
"[FLINK-7879][travis] Only execute RAT plugin in ""Misc"" profileThis closes #4867.",2
[hotfix] [tests] Reduce visibility of helper class methodsThere is no need to make the helper methods public. No other classshould even use this inner test helper invokable.,3
"[FLINK-7067] [jobmanager] Resume periodic checkpoints after failed cancel-job-with-savepointProblem: If a cancel-job-with-savepoint request fails, this has anunintended side effect on the respective job if it has periodiccheckpoints enabled. The periodic checkpoint scheduler is stoppedbefore triggering the savepoint, but not restarted if a savepointfails and the job is not cancelled.This commit makes sure that the periodic checkpoint scheduler isrestarted iff periodic checkpoints were enabled before.This closes #4254.",0
[FLINK-6245] Fix late side output documentation in Window documents.,2
[FLINK-7868][travis] Only run checkstyle during compilationThis closes #4886.,1
[hotfix] [tests] Increase stability of SavepointITCase,1
[FLINK-7905] [build] Update encrypted Travis S3 access keys,5
[hotfix] Fix code formatting in window doc,2
[FLINK-6861][metrics] Use OperatorID in metric systemThis closes #4849.,5
[FLINK-7864] Support side-outputs in CoProcessFunction,1
"[FLINK-7783] Don't remove checkpoints in ZooKeeperCompletedCheckpointStore#recover()Now, checkpoints are only discarded when they are subsumed. The earlierbehaviour was causing problems when the checkpoint store had transientoutages.",0
[hotfix][streaming] Fix formatting in OperatorChain,1
[hotfix][tests] Add easier way to chain operator in StreamTaskTestHarness,3
[hotfix][tests] Extract AcknowledgeStreamMockEnvironment,4
[FLINK-7623][tests] Add tests verifying isRestored flag,3
"[FLINK-7737][filesystem] Add syncOnFlush flag to StreamWriterBaseIt depends whether to call hsync or hflush on the underlying file systemand user preferences. Normally hflush is enough to protect against singlemachine HDFS failures and against TaskManagers failures. However if user isusing S3 like file system, or wants to protect againt whole HDFS rack powerloss hsync must be used instead.",1
"[FLINK-7738] Add note about non-firing triggers with empty windowsTimer callbacks on Trigger are not called if the window is empty, theyare silently ignored. This has led to some confusion.",5
[FLINK-7388] Don't set processing time as timestamp in ProcessFunction.onTimer(),1
[hotfix] [tests] Remove AbstractTestBase from CsvOutputFormatITCase and TextOutputFormatITCase,3
[hotfix] Suppress unchecked warnings in HeartbeatManagerTest,3
[hotfix] make BlobServer#serverSSLContext final,1
"[FLINK-6046] offload large data from the TaskDeploymentDescriptor to the BlobServerThis only includes potentially big parts, i.e. serializedJobInformation andserializedTaskInformation, which are both offloaded only once for all parallelinstances.- adds a configurable akka.rpc.offload.minsize threshold for large data- serialized task information is uploaded only once per task, irrespective of  the parallelism[FLINK-6046][tests] added an integration test with a job with big payloadThis verifies that uploading a job with a payload of 100MB is successful.NOTE: This only works after also implementing JobGraph offloading duringsubmission or akka.framesize will already limit it when sending it form theclient to the jobmanager.This closes #4412.Set min offloading size to 1 MiB",1
[FLINK-6046] Combine ExecutionGraph parameters into JobInformation,5
[FLINK-6046] Either store serialized value or permanent blob key in ExecutionGraph and ExecutionJobVertex,2
[FLINK-6046] Introduce BlobWriter interface to abstract BlobServer from ExecutionGraph,2
[hotfix] [docs] Fix typos in documentationThis closes #4885,2
[hotfix] [docs] Fix typo in monitoring REST API documentationThis closes #4854,2
[FLINK-7849] [hcatalog] Remove unnecessary/ineffective gauva shadingThis closes #4836,4
[FLINK-7755] [table] Fix NULL handling in batch joins.- Fixes also [FLINK-5498] Add support for non-equi join and local predicates to outer joinsThis closes #4858.This closes #3379 (stale PR for FLINK-5498).,2
[hotfix] [docs] Synchronize the Table API and SQL documentation of time-windowed joins.This closes #4874.,2
[FLINK-7821] [table] Deprecate Table.limit() and replace it by Table.offset() and Table.fetch().This closes #4813.,1
[FLINK-7882][build] Fixup FLINK-7810 by excluding remaining unused jaxb dependencies,1
[hotifx][docs][yarn] Add required option -yn to WordCount example commandThis closes #4856.,1
"[FLINK-7637] [kinesis] Fix at-least-once guarantee in FlinkKinesisProducerPrior to this commit, there is no flushing of KPL outstanding records oncheckpoints in the FlinkKinesisProducer. Likewise to the at-least-onceissue on the Flink Kafka producer before, this may lead to data loss ifthere are asynchronous failing records after a checkpoint which therecords was part of was completed.This closes #4871.",0
[hotfix] [kinesis] Fix inproper test name in FlinkKinesisProducerTest,3
[hotfix] [kinesis] Properly add serialVersionUIDs to FlinkKinesisProducer classes,2
[FLINK-7611][metrics] Measure number of dropped late elementsThis closes #4665.,4
"[FLINK-7669] Always load Flink classes via parent ClassLoaderBefore, when setting classloader.resolve-order Flink classes where alsoresolved via the child ClassLoader which could lead to problems if theuser-jar contains copies of Flink classes. This change introduces a newsetting classloader.parent-first-patterns. Classes that match thispattern will always be resolved by the parent first, even when using thechild-first ClassLoader.",1
[FLINK-7669] Add ClassLoader resolution order to classloader doc,2
[hotfix] Fix broken master by passing alwaysParentFirstPatterns in JobMasterTest,3
[FLINK-6584] [table] Add SQL group window functions to retrieve time attributes.This closes #4199.,1
[FLINK-6584] [docs] Add ROWTIME and PROCTIME group window functions to documentation.,2
"[FLINK-6697] [table] Add support for group window ROWTIME to batch SQL & Table API.- Fixes [FLINK-7542] ""AggregateITCase fails in different timezone.""This closes #4796.",0
"[FLINK-7666] Close TimeService after closing operators.This was revealed through the continuous file reader. Previouslythe StreamTask was calling the quiesceAndAwaitPending() of theTimerService before the close() of the operator. This meantthat with a periodic watermark emitter and a small file (e.g. onesplit), the timer service would be closed before even starting toread (as soon as the reader received the first split), and notimers would be registered to emit watermarks.",2
[FLINK-4831][metrics] Implement slf4j metric reporterThis closes #4661.,2
[FLINK-7502][metrics] Improve PrometheusReporter* Do not throw exception when same metric is added twice* Add possibility to configure port range* Bump prometheus.version 0.0.21 -> 0.0.26* Use simpleclient_httpserver instead of nanohttpd* guard gauge report against null* guard close() vs NPEThis closes #4586.,1
[FLINK-7540] Apply consistent hostname normalizationThe hostname normalization is now applied when generationg the remote akka config.That way it should be ensured that all ActorSystems are bound to a normalizedhostname.This closes #4812.,5
[FLINK-7920] Make MiniClusterConfiguration immutableThis closes #4905.,5
"[FLINK-7300] Demote ERROR to WARN on Commit Failure in KafkaConsumerCommitting the offset to Kafka can fail for various reasons, this is notalways an error because Flink will keep processing just fine.",2
[FLINK-5967] Add support for AggregatingState in user functionsThis also adds documentation for Aggregating state in user functions.,1
[hotfix] Reorder ProcessOperator methods so they conform to the order in the interface,5
[FLINK-7368][metrics] Make MetricStore ThreadSafe classRemove external synchronization on MetricStoreThis closes #4472.This closes #4840.,4
[FLINK-7846] [elasticsearch] Remove unnecessary guava shadingThis closes #4902.,4
[FLINK-7840] [build] Shade netty in akka,2
"[FLINK-7908][QS] Restructure the queryable state module.The QS module is split into core and client. The core shouldbe put in the lib folder to enable queryable state, while theclient is the one that the user will program against. Thereason for the restructuring in mainly to remove the dependencyon the flink-runtime from the user's program.",1
[FLINK-7824][QS] Put the QS modules in the opt folder.Now the user can find the jars in the opt/ folder andhe can activate QS by putting the core jar in the lib/folder and program against the client jar.,1
[FLINK-6173] [table] Clean-up flink-table jar and dependenciesThis closes #4837.,2
[FLINK-7051] [table] Bump Calcite version to 1.14.This closes #4873.,2
[hotfix] [table] Include commons-lang3 in flink-table artifact JAR.,2
[hotfix] [hdfs] Avoid reparsing URIs in Hadoop File Status conversion,2
[hotfix] [streaming] Move SerializedCheckpointData to proper scope for MessageAcknowledgingSourceBase,5
[hotfix] [runtime] Minor optimization in CheckpointMetrics,1
[hotfix] [checkpoints] fix warnings and make minor improvements to CheckpointCoordinatorTest and SharedStateRegistry,1
[hotfix] [core] Fix FileUtils.deletePathIfEmpty,4
[hotfix] [checkpoints] Remove incorrect 'Serializable' from StateBackendFactory,4
"[FLINK-7924] [checkpoints] Fix incorrect names of checkpoint optionsCheckpoint options are incorrectly always called 'FULL_CHECKPOINT' when actually,the checkpoints may always be incremental and only savepoints have to be fulland self contained.Initially, we planned to add options for multiple checkpoints, like checkpointsthat were foreced to be full, and checkpoints that were incremental. Thatis not necessary at this point.",1
[hotfix] [checkpoints] Remove unused and obsolete start()/stop() methods on CheckpointRecoveryFactory,1
[FLINK-7844] [ckPt] Fail unacknowledged pending checkpoints for fine grained recoveryThis commit will fail all pending checkpoints which have not been acknowledged bythe failed task in case of fine grained recovery. This is done in order to avoidlong checkpoint timeouts which might block the CheckpointCoordinator from triggeringnew checkpointsThis closes #4844.,1
[FLINK-7880][QS] Fix QS test instabilities.,3
[FLINK-7933][metrics] Improve PrometheusReporter testsThis closes #4908.,3
"[hotfix] Exclude Netty RejectedExecutionException from end-to-end testsNetty can throw a RejectedExecutionException when being shut down. This should not beconsidered a testing failure and, thus, the PR excludes the corresponding logstatement.",2
[FLINK-7548] [table] Refactor TableSource interface.- Improves the time attribute handling of table sources.This commit also resolves:- FLINK-6870: Unified handling of time attributes in batch and streaming- FLINK-7179: Support for projection push down and watermark assigners- FLINK-7696: Support for projection push down and time attributesThis closes #4894.,3
[FLINK-6495][config] Revert heartbeat pause back to 60sThis fixes an important bug introduced by FLINK-6495. Heartbeat pause MUST besignificantly larger then heartbeat interval.[hotfix][runtime] Fix exception message for restart delayPreviously default value didn't match with an exception message that was being thrown.[hotfix][core] Add convienient IllegalConfigurationException constructor[FLINK-6495][config] Validate heartbeats configuration on runtime[hotfix][docs] Fix and improve akka config options documentationThis closes #4774.,2
[FLINK-7739][kafka-tests] Shutdown NetworkFailureProxyThis closes #4749.,0
[FLINK-7739][tests] Properly close flink mini cluster,5
[FLINK-7739] [tests] Remove unnecessary FlinkMiniCluster#awaitTermination calls,5
[FLINK-7739][kafka-tests] Throttle down data producing threadThis closes #4751.,5
[hotfix] Remove redundant FutureUtils#getFailedFutureFutureUtils#completedExceptionally does exactly the same.,0
[FLINK-7940] Add FutureUtils.orTimeoutThis commit adds a convenience function which allows to easily add a timeout toa CompletableFuture.This closes #4918.,1
"[FLINK-7950][build] add flink-queryable-state-runtime as a dependency to flink-distSince FLINK-7824, flink-queryable-state-runtime's jar file was put into the opt/folder of flink-dist and is thus required to build as well.This closes #4925.",1
[hotfix][QS] Disable RocksDB ITCases.,5
[hotfix][javadocs] Fix metric handler example javadocs,2
[FLINK-7781][metrics][REST] Support on-demand aggregations,1
[FLINK-7912][metrics][docs] Document metrics REST APIThis closes #4901.,2
[hotfix][metrics] Remove MetricRegistryConfiguration#createScopeConfigThis method duplicates ScopeFormats#fromConfig,5
[hotfix][metrics] Remove unused ScopeFormats constructor,1
[hotfix][metrics] Remove unnecessary ScopeFormats constructor,4
[hotfix][metrics] Limit visibility of ScopeFormats constructor,0
[hotfix][metrics] Make ScopeFormats class finalThis closes #4922.,1
[FLINK-7418][build] Integrate flink-shaded-jackson2This closes #4923.,2
[hotfix][S3] Shade jackson 2.6,0
[FLINK-7939] [table] Fix Table conversion of DataStream of AtomicType.This closes #4917.,5
[FLINK-6563] [table] Add builders with time attribute support for KafkaTableSources.This closes #4638.,1
[hotfix] Make internal KafkaProducer11 details package private,1
[hotfix] Make fields transient in TwoPhaseCommitSinkFunction,1
"[FLINK-7902] Use TypeSerializer in TwoPhaseCommitSinkFunctionsWe use custom serializers to ensure that we have control over theserialization format, which allows us easier evolution of the format inthe future.This also implements custom serializers for KafkaProducer11, the onlyTwoPhaseCommitSinkFunction we currently have.",1
[FLINK-7400][cluster] fix cut-off memory not used for off-heap reserve as intended+ fix description of `containerized.heap-cutoff-ratio`[FLINK-7400][yarn] add an integration test for yarn container memory restrictions using off-heap memory[FLINK-7400] address PR commentsThis closes #4506.,1
[FLINK-6225] [cassandra] Add a CassandraAppendTableSink.This closes #3748.,1
[FLINK-7863] Generalize MetricFetcher to work with a RestfulGatewayAdd more logging to MetricFetcherThis closes #4852.,2
[FLINK-7867] Start MetricQueryService in TaskManagerRunnerThis closes #4853.,1
[hotfix] Let flink-yarn-tests UtilsTest extend TestLogger,3
[FLINK-7773] [tests] Fix unfinished stubbing in UtilsTestThe problem seemed to be that the TestingContainer dynamically stubbed theContainerId and the NodeId. I assume that this could happen concurrentlyto mocking the nodeManagerClient which would cause the unfinished stubbingexception.,5
"[FLINK-7876] Register TaskManagerMetricGroup under ResourceIDThis commit changes that TaskManagerMetricGroups are now registered under theTaskManager's ResourceID instead of the InstanceID. This allows to create theTaskManagerMetricGroup at startup of the TaskManager.Moreover, it pulls the MetricRegistry out of JobManager and TaskManager. Thisallows to reuse the same MetricRegistry across multiple instances (e.g. in theFlinkMiniCluster case). Moreover, it ensures proper cleanup of a potentiallystarted MetricyQueryServiceActor.Change TaskManagersHandler to work with ResourceID instead of InstanceIDAdapt MetricFetcher to use ResourceID instead of InstanceIDThis closes #4872.",1
[FLINK-7876] Properly start and shutdown MetricRegistry by ClusterEntrypointSuppress MetricRegistry#shutdown exceptions if the metric query service actor's actor system has already beenshut down.Address PR commentsPull out TaskManagerMetricGroup instantiation from TaskManagerServices,1
[FLINK-7876] Merge TaskExecutorMetricsInitializer and MetricUtilsThis commit removes the TaskExecutorMetricsInitializer and moves its methodsto MetricUtils.,4
"[FLINK-7784] [kafka011-producer] Make TwoPhaseCommitSinkFunction aware of transaction timeouts.TwoPhaseCommitSinkFunction allows to configure a transaction timeout. Thetimeout can be used to log warnings if the transaction's age is appraochingthe timeout, and it can be used to swallow exceptions that are likelyirrecoverable. This commit also integrates these changes to theFlinkKafkaProducer011.This closes #4910.",2
[hotfix] [kafka-tests] Clean up FlinkKafkaProducer011Tests,3
[FLINK-7732][kafka-consumer] Do not commit to kafka Flink's sentinel offsetsThis closes #4928.,1
[hotfix][kafka] Bump Kafka 0.11 dependencyThis might include some bugfixes,0
[FLINK-7838][kafka] Add missing synchronization in FlinkKafkaProducer,2
[hotfix][kafka] Fix FlinkKafkaProducer011 logger,2
[hotfix][kafka-tests] Fix test names so that they are not ignored by mvn build,3
"[hotfix][kafka] Move checkpointing enable checking to initializeStateinitializeState is called before open and since both of those functionsrelay on chosen semantic, that means checkpointing enable check shouldhappen in initializeState.",5
[hotfix][kafka] Remove unsued field in FlinkKafkaProducer011,2
"[hotfix][kafka] Do not return producers to a pool in abort for non EXACTLY_ONCE modesPreviously on abort(...) producers were returned to the pool. This was minor bug,probably without any negative side effect, however this patch fixes itand adds additional sanity checks to guard against similar bugsin the future.This closes #4915.",0
[hotfix] [kafka-tests] Rename FlinkKafkaProducerTest to *ITCaseThe affected tests are actually integration tests that spawn a Kafkabroker. Renaming it to *ITCase would be more appropriate.,3
[hotfix] [docs] Fix broken downloads page urlThis closes #4912,0
[hotfix] [javadoc] Fix typo in Javadoc of ManagedSnapshotContext#getCheckpointId()This closes #4913,1
[hotfix] [docs] Fix typos in types serialization documentationThis closes #4914,2
"[FLINK-7960] [tests] Fix race conditions in ExecutionGraphRestartTest#completeCancellingForAllVerticesOne race condition is between waitUntilJobStatus(eg, JobStatus.FAILING, 1000) and thesubsequent completeCancellingForAllVertices where not all execution are in stateCANCELLING.The other race condition is between completeCancellingForAllVertices and the fixeddelay restart without a delay. The problem is that the 10th task could have failed.In order to restart we would have to complete the cancel for the first 9 tasks. Thisis enough for the restart strategy to restart the job. If this happens beforecompleteCancellingForAllVertices has also cancelled the execution of the 10th task,it could happen that we cancel a fresh execution.[hotfix] Make WaitForTasks using an AtomicInteger[hotfix] Set optCancelCondition to Optional.empty() in SimpleAckingTaskManagerGatewayAdd assertion message to ExecutionGraphTestUtils#switchToRunningThis closes #4933.",3
[hotfix] Instantiate a HdfsConfiguration in HadoopUtils#getHadoopConfiguration()Instantiate a HdfsConfiguration as the base configuration when callingHadoopUtils#getHadoopConfiguration() to load the hdfs-site.xml andhdfs-default.xml from the classpath before trying to load an explicitlyspecified configuration.,5
"[FLINK-7764][kafka]FlinkKafkaProducer010 does not accept name, uid, or parallelism",2
"[FLINK-7778] [build] Shade ZooKeeper dependency (part 1)Shading the ZooKeeper dependency makes sure that this specific version ofZooKeeper is used by the Flink runtime module. The ZooKeeper version issensitive, because we depend on bug fixes in later ZooKeeper versionsfor Flink's high availability.This prevents situations where for example a set of added dependencies (forexample transtive dependencies of Hadoop) cause a different ZooKeeper versionto be in the classpath and be loaded.This commit also removes the 'flink-shaded-curator' module, which was originallycreated to shade guava within curator, but is now obsolete, because newerversions of curator shade guava already.",1
[FLINK-7778] [build] Shade ZooKeeper dependency (part 2)This closes #4927,2
"[FLINK-7778] [build] Shade ZooKeeper dependency (followups)  - Rename the 'flink-shaded-curator-recipes' module to 'flink-shaded-curator',    because it actually contains more curator code than just the recipes.  - Move the exception handling logic of 'ZooKeeperAccess' directly into the    ZooKeeperStateHandleStore",0
[FLINK-7153] Re-introduce preferred locations for scheduling,2
"[FLINK-7153] Introduce LocationPreferenceConstraint for schedulingThe LocationPreferenceConstraint defines whether all or any preferred locationshave to be taken into consideration when scheduling tasks. Especially for batchjobs where we do lazy scheduling not all input locations might be known for aconsumer task. Therefore, we set the location preference constraint to any whichmeans that only those location are taken into consideration which are known atscheduling time.[FLINK-7153] Add test casesReplace AtomicReference with AtomicReferenceUpdaterFixUse static imports Preconditions.checkNotNullInitialize ANY array with number of returned futuresRevert formatting changes in SchedulerSet flink-runtime log level in log4j-test.properties to OFFRevert changes to ExecutionVertex#getPreferredLocationsBasedOnInputsFix failing FailoverRegionTestThis closes #4916.",3
[hotfix] Make failover region topological sorted,2
[hotfix] [tests] Improve TypeInfoTestCoverageTest,5
"[hotfix] [build] Fix broken project references to 'flink-shaded-curator-recipes'.The project 'flink-shaded-curator-recipes' was renamed to 'flink-shaded-curator',but some references were not properly updated. This fixes the remaining references.",5
[FLINK-7968] [core] Move DataOutputSerializer and DataInputDeserializer to 'flink-core'These core flink utils are independent of any other runtime classes andare also used both in flink-runtime and in flink-queryable-state (which duplicatedthe code).,2
"[FLINK-6226] [table] Add tests for UDFs with Byte, Short, and Float arguments.",3
[FLINK-7421] [table] Fix serializability of AvroRowSerializationSchema + AvroRowDeserializationSchema.,0
[FLINK-7338] [table] Fix retrieval of OVER window lower bound.,0
"[FLINK-7972] [core] Move SerializationSchema to 'flink-core'Moves the SerializationSchema and its related fromflink-streaming-java to flink-core.That helps API level projects that depend on those classesto not pull in a dependency on runtime classes, and tonot be Scala version dependent.",1
[hotfix] [tests] Remove console poluting output in tests of flink-streaming-java,2
[FLINK-7420] [avro] Move all Avro code to flink-avro,2
"[FLINK-7420] [avro] (follow-up) Do not shade or exclude avro in HadoopExcluding Avro in Hadoop will make basic classes like sequence file writers failto load, even if Avro is not used.Shading Avro is not possible because it is part of the API for users thatuse Avro types.",1
[FLINK-7420] [avro] Replace GenericData.Array by dummy when reading TypeSerializersThis also adds a new test that verifies that we correctly registerAvro Serializers when they are present and modifies an existing test toverify that we correctly register dummy classes.,3
"[FLINK-7420] [avro] Abstract all Avro interaction behind AvroUtilsBefore, we would try and dynamicall load Avro-related classes in severalplaces. Now, we only reflectively instantiate the right AvroUtils andall other operations are methods on this.The default AvroUtils throw exceptions with a helpful message for mostoperations.",1
[FLINK-7847] [avro] Fix typo in jackson shading patternThis closes #4931,2
[hotfix] [avro] Minor XML formatting cleanup,4
[FLINK-7420] [avro] Make flink-avro Scala independentThis removes all dependencies on Scala-dependent projects.This commit introduces a hard wired test dependency to'flink-test-utils_2.11' to avoid introducing a Scala version dependencydue to a non-exported test utility.,3
[hotfix] [avro] Fix some serializability warnings and problems,0
"[hotfix] [avro] Simplify the FSDataInputStreamWrapperThe FSDataInputStreamWrapper comes from a time when Flink's FsDataInputStream was notposition aware. Not that it is, the FSDataInputStreamWrapper is not required to trackits own position, but can simply delegate these calls to the FsDataInputStream.This also adds missing @Override tags.",1
[hotfix] [avro] Remove incorrect serializability from DataOutputEncoder,5
[hotfix] [avro] Improve Avro type hierarchy checks in AvroKryoSerializerUtils,1
[hotfix] [avro] Improve AvroUtils to perform reflection lookups only once.This also fixes minor warnings (unchecked casts) and moves the constantsinto scopes that avoid bridge methods for access outside of the nested classes.,4
[hotfix] [avro] Add test that validates deserialization of Kryo Serializer in the absence of Avro,5
[FLINK-7973] [filesystems] Fix shading patterns for META-INF/services entries,5
[FLINK-7992][docs] extend the PR template asking for any S3 relationThis closes #4952.,2
[hotfix][build] Fix typo in parent pomThis closes #4947.,2
[hotfix][java] Add missing space to error messageThis closes #4944.,1
[FLINK-7843][metrics][docs] Add time unit and metric type to system metrics referenceThis closes #4869.,5
[FLINK-7994][mesos] Remove effectively unused curator dependencyThis closes #4954.,1
[FLINK-7993][kafka] Sync curator shading patternsThis closes #4953.,2
"[FLINK-7745][tests] add tests for ensuring NetworkBufferPool overprovisioning behaviour[FLINK-7745][tests] address PR comments, fix testThe testOverprovisioned() unit test wasn't really testing that a buffer returnedfrom lbp1 is available to lbp2 afterwards, which is also fixed in addition tothe improved comments in the tests.[FLINK-7745][network] address PR comments- rename occurences of `lbp` to more meaningful namesThis closes #4758.",1
"[FLINK-7515][network] allow actual 0-length content in NettyMessage#allocateBuffer()Previously, length ""0"" meant ""unknown content length"" but there are cases wherethe actual length is 0 and so we use -1 for tagging the special case now.[FLINK-7515][network] address PR commentsThis closes #4592.",1
[FLINK-7516][memory] do not allow copies into a read-only ByteBuffer[FLINK-7516][memory] address PR commentsThis closes #4593.,1
[FLINK-7701][network] really fix watermark configuration order this timeFLINK-7258 fixed this for large memory segment sizes but broke it for smallones. This should fix both.FYI: Newer Netty versions actually circumvent the problem by allowing to setboth watermarks at the same time.This closes #4733.,1
[FLINK-6022] [avro] Use Avro to serialize Avro in flight and in StateThis falls back to the original serializer (Pojo / Kryo) in cases wherean old snapshot is resumed.,1
"[hotfix] [avro] Define Avro version through variableAvro version is used multiple times (dependendies and plugins),having a variable makes sure we use those in sync.",1
"[FLINK-7997] [avro] Make Avro part of the user code spaceBy not setting Avro as 'provided', the build system will put itinto the user code fat jar, rather than assuming it will be partof Flink's 'lib' folder.That way Avro is loaded child-first through the user code classloader, giving it independent separate copies per load that avoidversion conflicts and caching problems.",0
Update version to 1.5-SNAPSHOT,5
[hotfix][metrics][docs] Add type for numLateRecordsDropped metricThis closes #4964.,4
[hotfix][rat] Add missing rat exclusionsAnother set of RAT exclusions to prevent errors on Windows.,0
[FLINK-7823][QS] Update Queryable State configuration parameters.,2
[FLINK-7822][QS][doc] Update Queryable State docs.,2
[FLINK-7914] Introduce AkkaOptions.RETRY_GATE_CLOSED_FORThe AkkaOptions.RETRY_GATE_CLOSED_FOR allows to configure how long a remoteActorSystem is gated in case of a connection loss. The default value is setto 50 ms.This closes #4903.,1
[hotfix] Speed up JobManagerFailsITCase by decreasing timeout,0
[FLINK-7872] Allow to pass in additional HTTP headersHandlerUtils#sendResponse now accepts a map of additional http response headersand their values. This allows to set additional headers such as theACCESS_CONTROL_ALLOW_ORIGIN header and its value.This closes #4859.,1
[FLINK-7648] [flip6] Add TaskManagersHandlerSend dataPort and HardwareDescription to RMInstantiate RM leader retriever,5
[FLINK-7648] [flip6] Write HardwareDescription in sub object of legacy.TaskManagersHandlerThis closes #4824.,0
[hotfix] Move TaskManagersHandler to rest.handler.taskmanager and messages to rest.messages.taskmanagerMove TaskManager messages to rest.messages.taskmanagerMove TaskManager message tests to rest.messages.taskmanager,3
[FLINK-7862] [flip6] Add TaskManagerDetailsHandlerPass MetricQueryServiceRetriever to DispatcherRestEndpointThis closes #4862.,4
[FLINK-7862] No longer send inidividual TaskManager information in an arrayFix failing WebFrontendITCase,0
[FLINK-7862] Change web ui to calculate total memory from heap and non-heap data,5
[FLINK-7705] Add JobDetailsHandlerAdd JobID(De)Serializer and JobVertexID(De)Serializer for jacksonThis closes #4884.,0
[FLINK-7706] [flip6] Add JobAccumulatorsHandler for new REST endpointThis closes #4898.,1
[FLINK-7806] [flip6] Register CurrentJobsOverviewHandler under /jobs/overviewRename CurrentJobsOverviewHandler to JobsOverviewHandlerChange pathsRemove joboverview/running and joboverview/completed from JobsOverviewHandlerAdapt web ui filesUpdate rest_api to reflect new REST call /jobsThis changes #4805.,4
[FLINK-7815] Remove grouping from MultipleJobsDetailsWith this commit the MultipleJobsDetails instance only contains a list of all jobswhich could be retrieved from the cluster. With this change it is the responsibilityof the web ui to group the jobs into running and finished jobs.Adapt jobs.svc.coffee script to group list of jobs into running and finished jobsThis closes #4806.,5
[FLINK-7941][flip6] Port SubtasksTimesHandler to new REST endpointThis closes #4930.,1
[FLINK-7941] Store timestamps indexed by ExecutionState in SubtasksTimesInfo,5
[FLINK-7870] [runtime] slot pool cancel slot request to resource manager if timeoutSummary: slot pool cancel slot request to resource manager if timeoutTest Plan: unit testReviewers: haitao.wDifferential Revision: https://aone.alibaba-inc.com/code/D320749This closes #4887.,3
[FLINK-7870] [tests] Add SlotPool test to verify cancellation of failed slot requestsAdds the SlotPoolTest#testSlotRequestCancellationUponFailingRequest.,3
[hotfix] Use correct commit id in GenericWriteAheadSink.notifyCheckpoint,1
[hotfix] [docs] Improve Supported Types section of Table API & SQL docs.,2
[hotfix] [docs] Fix UDTF join description in SQL docs.,2
"[FLINK-8001] [kafka] Prevent PeriodicWatermarkEmitter from violating IDLE statusPrior to this commit, a bug exists such that if a Kafka consumer subtaskinitially marks itself as idle because it didn't have any partitions tosubscribe to, that idleness status will be violated when thePeriodicWatermarkEmitter is fired.The problem is that the PeriodicWatermarkEmitter incorrecty yields aLong.MAX_VALUE watermark even when there are no partitions to subscribeto. This commit fixes this by additionally ensuring that the aggregatedwatermark in the PeriodicWatermarkEmitterr is an effective one (i.e., isreally aggregated from some partition).",1
[hotfix][kafka] Extract TransactionalIdsGenerator class from FlinkKafkaProducer011This is pure refactor without any functional changes.,4
"[FLINK-7978][kafka] Ensure that transactional ids will never clashPreviously transactional ids to use and to abort could clash betweensubtasks. This could lead to a race condition between initializationand writting the data, where one subtask is still initializing/abortingsome transactional id while different subtask is already trying to writethe data using the same transactional id.",1
[FLINK-8004][metrics][docs] Fix usage examplesThis closes #4965.,0
[FLINK-8010][build] Bump remaining flink-shaded versionsThis closes #4971.,2
[FLINK-8009][build][runtime] Remove transitive dependency promotionThis closes #4972.,4
"[FLINK-7773] [tests] Move all mocking before testing code in UtilsTest to avoid unfinished stubbingMove all mocking code before the actual testing code in UtilsTest#testYarnFlinkResourceManagerJobManagerLostLeadership.Hopefully, this will fix the unfinished stubbing exception which still occurs spuriously.This closes #4957.",5
[FLINK-7076] [yarn] Implement stopWorker logic for YarnResourceManagerThis closes #4729.,2
[FLINK-7076] [tests] Harden YarnResourcemanagerTest#testStopWorker to properly wait for concurrent operations,3
[FLINK-7971] [table] Fix potential NPE in non-windowed aggregation.This closes #4941.,0
[FLINK-7922] [table] Fix FlinkTypeFactory.leastRestrictive for composite types.This closes #4929.,2
[FLINK-7996] [table] Add support for (left.time = right.time) predicates to window join.This closes #4977.,1
[FLINK-8012] [table] Fix TableSink config for tables with time attributes.This closes #4974.,5
[FLINK-8002] [table] Fix join window boundary for LESS_THAN and GREATER_THAN predicates.This closes #4962.,0
[FLINK-7704] [hotfix] [flip6] Fix JobPlanInfoTest package pathThis closes #4978.,5
[FLINK-8000] Sort Rest handler URLS in RestServerEndpointIntroduce special RestHandlerUrlComparator to sort REST URLs such thatURLs with path parameters are sorted after those without or fewer.E.g. the following order would be established/jobs/jobs/overview/jobs/:jobid/jobs/:jobid/config/:*This closes #4958.,5
[FLINK-8024] Let ClusterOverviewHandler directly extend from AbstractRestHandlerThis closes #4982.,0
[FLINK-8025] Let DashboardConfigHandler directly extend AbstractRestHandlerThis closes #4983.,0
[FLINK-8026] Let ClusterConfigHandler directly extend AbstractRestHandlerThis closes #4984.,0
[FLINK-8017] Fix High availability cluster-id key in documentation,2
[hotfix] Fix formatting in windowing documentation,2
[hotfix][build] Deduplicate maven-enforcer version,1
[FLINK-7765][build] Enable dependency convergence by defaultDisable it in most modules.,0
"[FLINK-8005] Set user-code class loader as context loader before snapshotDuring checkpointing, user code may dynamically load classes from the user codejar. This is a problem if the thread invoking the snapshot callbacks does nothave the user code class loader set as its context class loader. This commitmakes sure that the correct class loader is set.",1
[FLINK-4500] CassandraSinkBase implements CheckpointedFunctionThis closes #4605.,1
"[FLINK-6434] cancel slot allocation if request timed out in ProviderAndOwnerSummary:This fix flink jira #64341. Let the ProviderAndOwner generate the allcation id before calling allocateSlot to slot pool.2. If the allocateSlot call timed out, ProviderAndOwner cancel the previos allocation to slot pool.Test Plan: UnitTestReviewers: haitao.wDifferential Revision: https://aone.alibaba-inc.com/code/D323990This closes #4937.",3
[FLINK-6434] [tests] Harden and speed up SlotPoolRpcTest,3
[FLINK-6434] [flip6] Introduce SlotRequestID for SlotPool#allocateSlotWe have to distinguish between the slot request and the slot allocation becauseslot allocations are reused across multiple slot requests. Therefore we cannot usethe AllocationID to identify individual slot requests which might be cancelled.Introducing a separate SlotRequestID solves the problem.,0
[hotfix][build] Disable dependency convergence in flink-distPreviously mvn javadoc:aggregate goal was failing,0
[FLINK-6163] Document per-window state in ProcessWindowFunction,1
[hotfix][docs] Change mailing list link in quickstart to flink-userPreviously it was pointing to flink-dev,2
[FLINK-7702] Remove Javadoc aggregation for Scala codegenjavadoc generated some Java code that was making Javadoc fail.,0
"[FLINK-7702] Add maven-bundle-plugin to root pomBefore, we had it in places that require it. This doesn't work whenrunning mvn javadoc:aggregate because this will only run for the rootpom and can then not find the ""bundle"" dependencies.",1
[FLINK-8040] [tests] Fix test instability in ResourceGuardTestThis closes #5004.,3
[FLINK-7657] [table] Add time types FilterableTableSource push downThis closes #4746.,1
[FLINK-7657] [table] Add all basic types to RexProgramExtractor,4
"[FLINK-7973] Fix shading and relocating Hadoop for the S3 filesystems- do not shade everything, especially not JDK classes!-> instead define include patterns explicitly- do not shade core Flink classes (only those imported from flink-hadoop-fs)- hack around Hadoop loading (unshaded/non-relocated) classes based on names in  the core-default.xml by overwriting the Configuration class (we may need to  extend this for the mapred-default.xml and hdfs-defaults.xml):-> provide a core-default-shaded.xml file with shaded class names and copy and  adapt the Configuration class of the respective Hadoop version to load this  file instead of core-default.xml.Add checkstyle suppression pattern for the Hadoop Configuration classesAlso fix the (integration) tests not working because they tried to load therelocated classes which are apparently not available thereRemove minimizeJar from shading of flink-s3-fs-presto because this wascausing ""java.lang.ClassNotFoundException:org.apache.flink.fs.s3presto.shaded.org.apache.commons.logging.impl.LogFactoryImpl""since these classes are not statically imported and thus removed whenminimizing.Fix s3-fs-presto not shading org.HdrHistogramFix log4j being relocated in the S3 fs implementationsAdd shading checks to travis",1
[FLINK-7973] Add shaded S3 FileSystem end-to-end tests,3
"[hotfix] Make end-to-end test scripts more robustThis uses traps to ensure that we properly do cleanups, remove configvalues and shutdown things.",5
[hotfix] fix presto end-to-end test not cleaning up,4
[hotfix] ignore a warning from the error check of the S3 e2e tests,3
[hotfix] let end-to-end tests check for empty .out files again,2
[FLINK-8053] [checkpoints] Default to asynchronous snapshots for FsStateBackend and MemoryStateBackend.This closes #5005.,2
[FLINK-7845][runtime] Make NettyMessage publicThis a walkaround strange javaassist bug. The issue should go awayonce we upgrade netty dependency.Please check the ticket for more information.This closes #5007.,5
"[hotfix][docs][javadocs] Remove double ""of""This closes #4999.",4
[hotfix][docs] Fix typos in deployment AWS documentationThis closes #5000.,2
[FLINK-4500][docs] Update cassandra documentation regarding data lossAs of FLINK-4500 the Cassandra connector will wait for pending updates to finish upon checkpoint.This closes #5002.,5
[hotfix][docs] Fix broken link to FLINK-7811This closes #4995.,2
[FLINK-8011][dist] Set flink-python to providedThis closes #4973.,1
[FLINK-8006] [Startup Shell Scripts] - Fixing $pidThis closes #4968.,0
[FLINK-8056][dist] Use 'web.port' instead of 'jobmanager.web.port'This closes #5010.,1
[FLINK-7998][examples] Fix TPCHQuery3 examplesThis closes #4959.,0
[FLINK-8071][build] Bump shade-plugin asm version to 5.1This closes #5014.,2
[FLINK-7419][build][avro] Shade jackson dependency in flink-distThis closes #4981.,2
[FLINK-7973] disable JNI bridge for relocated hadoop classes in s3-fs-*,2
[FLINK-7451] [table] Support non-ascii character literals in Table API and SQLThis closes #4544.,1
[FLINK-7451] [table] Disable testing of the charset in TableTestBase,3
[FLINK-8013] [table] Support aggregate functions with generic arraysThis closes #5011.,1
[FLINK-7678] [table] Support composite inputs for user-defined functionsThis closes #4726.,1
[FLINK-7490] [table] Use correct classloader to compile generated code that calls UDAGGs.This closes #5018.,2
[FLINK-7942] [table] Reduce aliasing in RexNodesThis closes #5019.,2
[FLINK-7962] Add built-in support for min/max aggregation for TimestampThis closes #4936,1
[FLINK-7698] [table] Tests joins with null literals,3
[FLINK-7003] [table] Fix 'SELECT *' for tables with nested schema.This closes #4989.,0
[FLINK-7389] [table] Remove Calcite PushProjectorThis closes #5022.,4
[FLINK-8014] [table] Add Kafka010JsonTableSink.- Refactor KafkaTableSink tests.,3
[FLINK-8016] [docs] Add documentation for KafkaJsonTableSinks.This closes #4990.,5
[FLINK-8069] [table] Add preserving WatermarkStrategy.This closes #5016.,1
[FLINK-7986] [table] Introduce FilterSetOpTransposeRuleThis closes #4956.,1
[FLINK-8063][QS] QS client does not retry when an UnknownKvStateLocation is thrown.,1
[FLINK-8062][QS] Make getKvState() with namespace private.,1
[FLINK-8065][QS] Improve error message when client already shut down.,0
[FLINK-8055][QS] Deduplicate logging messages about QS start.,2
[FLINK-8059][QS] QS client throws FlinkJobNotFoundException for queries with unknown jobIds,2
[FLINK-8057][QS] Change error message in KvStateRegistry.registerKvState(),1
[FLINK-8061][QS] Remove trailing * in QSClient javadocs.,2
[FLINK-7265] [core] Introduce FileSystemKind to differentiate between FileSystem and ObjectStore,5
[FLINK-7266] [core] Prevent attempt for parent directory deletion for object storesThis closes #4397,4
"[FLINK-4228][yarn/s3] fix for yarn staging with s3a defaultFs+ includes a new unit tests for recursive uploads to hfds:// targets+ add a unit test for recursive file uploads to s3:// via s3a[FLINK-4228][yarn/s3] turn the dependencies aroundInstead of having flink-s3-fs-hadoop depend on flink-yarn_<scala_version>,let flink-yarn depend on the s3 filesystem and implement the test there.This is safer with regards to the scala-independent flink-s3-fs-hadoop project.[FLINK-4228][yarn] change the S3 upload tests to use Hadoop's S3 implementationsThis is how YARN would use it and what should really be tested.[FLINK-4228][yarn] enable S3 tests for newer Hadoop versions- requires the 'include_hadoop_aws' build profile (or property) to be set- requires a newer aws-sdk version (than Hadoop pulls in) to work with our  httpcomponents version- we also add a check that at least one S3 implementation is tested to notsilently ignore all tests because of such a missing dependencyThis closes #4939.",1
[FLINK-7988][s3] fix HadoopS3FileSystemITCase leaving test directories behind in S3This closes #4950.,3
[FLINK-8096] [table] Fix time attribute materialization when writing to TableSinkThis closes #5025.,0
[FLINK-8095] [table] Introduce ProjectSetOpTransposeRuleThis closes #5026.,1
[FLINK-4809] [checkpoints] Operators should tolerate checkpoint failures.This closes #4883.,0
[hotfix][kafka] Improve logging in FlinkKafkaProducer011,2
"[FLINK-8086][kafka] Ignore ProducerFencedException during recoveryProducerFencedException can happen if we restore twice from the same checkpointor if we restore from an old savepoint. In both cases transactional.ids that wewant to recoverAndCommit have been already committed and reused. Reusing meanthat they will be known by Kafka's brokers under newer producerId/epochId,which will result in ProducerFencedException if we try to commit again someold (and already committed) transaction.Ignoring this exception might hide some bugs/issues, because instead of failingwe might have a semi silent (with a warning) data loss.",5
[FLINK-8099] Reduce default restart delay to 1 second,2
[FLINK-8108][py] Fix bounds check,0
[FLINK-8109][py] Check for existence of plan/additional files,2
[FLINK-8114][py] Fix forwarding of arguments,0
[FLINK-8110][dist] Relocate jackson services in flink-distThis closes #8110.,2
"[FLINK-7943] Make ParameterTool thread safeThis commit changes the serialization of the ParameterTool such that only thedata map is contained. The defaultData and the unrequestedParameters maps arenot serialized because they are only used on the client side. Additionally, thedefaultData and unrequestedParameters map are being made thread safe by usingConcurrentHashMaps.This closes #4921.",1
[hotfix][license] Add missing licensesThis close #4794.,1
[FLINK-8102][docs] Fixed formatting issues in Mesos documentation.This closes #5033.,2
[FLINK-8115] Fix Kafka download link in end-to-end test,3
[hotfix] Fix create_release_branch.sh to use correct branch name,1
"[hotfix] Always explicitly set hadoop.version in create_binary_releaseBefore, the ""hadoop2"" profile would create a binary release for whateverhappens to be the default hadoop.version.",1
[hotfix][docs] Fix some typos in the documentation.This closes #5039.,2
"[FLINK-8038] [table] Support map value constructor, cardinality, and itemThis closes #5015.",1
[FLINK-8038] [table] Clear maps and support cardinality,1
[FLINK-8097] [table] Add built-in support for min/max aggregation for Date/TimeThis closes #5027.,5
[FLINK-8123][py] Bundle python scripts in jar,2
[FLINK-8117] [runtime] Eliminate modulo operation from round-robin partitionersThis closes #5041,1
[FLINK-7841] [docs] Update AWS docs with respect to S3 file system changesThis closes #5029,4
[FLINK-8126] [build] Fix and update checkstyleUpdate to the latest checkstyle version and fix the errors notpreviously detected.This closes #5044.,0
[FLINK-8070][yarn][tests] Print errors found in log filesThis closes #5012.,2
[FLINK-8113][build] Bump maven-shade-plugin to 3.0.0This closes #5042.,2
[FLINK-8084][build] Remove unnecessary japicmp pom entriesThis closes #5020.,4
[FLINK-8131] Update to Kafka 0.11.0.2,5
[hotfix][docs] Fix typo in Trigger docThis closes #5051.,2
[hotfix] Make aws docs version agnostic,2
[FLINK-8136] [table] Fix code generation with JodaTime shadingThis closes #5054.,5
[FLINK-2170] [connectors] Add OrcRowInputFormat and OrcTableSource.This closes #4670.,1
[FLINK-2170] [connectors] Add OrcRowInputFormat and OrcTableSource.This closes #5043.,1
[FLIN-6505] Proactively cleanup local FS for RocksDBKeyedStateBackend on startup,5
[hotfix][kafka] Throw FlinkKafkaProducer011Exception with error codes instead of generic Exception,0
"[FLINK-8132][kafka] Re-initialize transactional KafkaProducer on each checkpointPreviously faulty scenario with producer pool of 2.1. started transaction 1 with producerA, written record 422. checkpoint 1 triggered, pre committing txn1, started txn2 with producerB, written record 433. checkpoint 1 completed, committing txn1, returning producerA to the pool4. checkpoint 2 triggered , committing txn2, started txn3 with producerA, written record 445. crash....6. recover to checkpoint 1, txn1 from producerA found to ""pendingCommitTransactions"", attempting to recoverAndCommit(txn1)7. unfortunately txn1 and txn3 from the same producers are identical from KafkaBroker perspective and thus txn3 is being committedresult is that both records 42 and 44 are committed.With this fix, after re-initialization txn3 will have different producerId/epoch counters compared to txn1.",5
[hotfix][kafka] Remove unused method in kafka tests,3
[FLINK-8118] [table] Allow to specify the offsets of KafkaTableSourcesThis closes #5056.,1
[FLINK-8118] [table] Fix documentation mistakes,2
[hotfix][docs] Improve Kafka exactly-once docs,2
[FLINK-5465] [streaming] Wait for pending timer threads to finish or to exceed a time limit in exceptional stream task shutdown.This closes #5058.,5
[hotfix] Exclude python-source.zip from checkstyleThis was causing the snapshot deployment to fail.,0
[FLINK-7316][network] Always use off-heap network buffers.This is another step at using or own (off-heap) buffers for networkcommunication that we pass through netty in order to avoid unnecessary buffercopies.This closes #4481.,4
[hotfix] [core] Fix lots of checkstyle errors in core.fs,0
[FLINK-8125] [core] Introduce limiting of outgoing file system connections,5
[FLINK-6294] Fix potential NPE in BucketingSink.close(),0
"[FLINK-7718] [flip6] Add JobVertexMetricsHandler to DispatcherRestEndpointMigrate logic inorg.apache.flink.runtime.rest.handler.legacy.metrics.JobVertexMetricsHandler tonew handler and add new handler to DispatcherRestEndpoint. Add common classesfor remaining implementations oforg.apache.flink.runtime.rest.handler.legacy.metrics.AbstractMetricsHandler,which require migration as well.[FLINK-7718] [flip6] Clean up JobVertexMetricsHandlerHeaders[FLINK-7718] [flip6] Assert that HTTP code is 404 if metric is unknown[FLINK-7718] [flip6] Minor fixes in Javadocs[FLINK-7718] [flip6] Add unit test for AbstractMetricsHandlerHeaders[FLINK-7718] [flip6] Let unit tests inherit from TestLogger[FLINK-7718] [flip6] Re-format Metric constructor[FLINK-7718] [flip6] Fix mistake in Javadoc of AbstractMetricsHandlerHeaders[FLINK-7718] [flip6] Rename AbstractMetricsHandlerHeaders to AbstractMetricsHeadersStrip the term Handler from the Header class. Also rename its subclasses.[FLINK-7718] [flip6] No longer return HTTP 404 if metric is unknown[FLINK-7718] [flip6] Make JobVertexMetricsHeaders class final[FLINK-7718] [flip6] Introduce MetricsHandlerTestBase for future MetricHandlers[FLINK-7718] [flip6] Always return same MessageParameter objects in JobVertexMetricsMessageParametersThis closes #5055.",2
[FLINK-8022][kafka] Bump at-least-once timeout in testsIncreasing timeout for reading the records from 30s to 60s seems to solve the issuefor failing at-least-one tests.,3
[FLINK-8081][metrics] Annotate 'MetricRegistry#getReporters' with '@VisibleForTesting'This closes #5049.,3
[hotfix][docs] Fix missing period package declarationThis closes #5077.,0
[hotfix] Ensure pristine release in tools/releasing/create_source_release.sh,1
"[hotfix] Remove ""Java 7"" from README.md",2
[hotfix] [docs] Update checkstyle version in documentationThis closes #5061,2
[FLINK-8142] [config] Cleanup references to deprecated constants in ConfigConstantsThis closes #5067,5
"[FLINK-8105] Remove ""unnecessary 'null' check before 'instanceof' expression""This closes #5034",4
[FLINK-7967] [config] Deprecate Hadoop specific Flink configuration optionsThis closes #4946,5
[hotfix] [tests] Use G1GC for testsThis closes #4748,3
"[FLINK-8161] [tests] Harden YARNSessionCapacitySchedulerITCaseAdd ""Remote connection to [null] failed with java.nio.channels.NotYetConnectedException""to the list of whitelisted log statements in YarnTestBase. This logging statementseems to appear since we moved from Flakka to Akka 2.4.0.This closes #5085.",4
"[hotfix] [optimizer] Normalize job plan operator formattingWhen printing the job plan the operator description is typicallyformatted as the operator name followed by the user given or generatedfunction name in parenthesis. For example, ""Reduce (My Function)"".This normalizes the node names to include a space between the operatorand function names.This closes #4383",1
"[FLINK-6864] [core] Fix confusing ""invalid POJO type"" messages from TypeExtractorThis closes #4574",4
[hotfix] Fail unacknowledged checkpoints before trying to restart the failed tasks,0
[FLINK-7300] Ignore more exceptions in end-to-end tests,3
[FLINK-8166] Create hadoop-free binary in release scripts,1
[FLINK-7679][build] Upgrade maven enforcer plugin to 3.0.0-M1This closes #5001.,1
"[FLINK-8150] [flip6] Expose TaskExecutor's ResourceID as TaskExecutor idBefore, the TaskExecutor's InstanceID was exposed as TaskExecutor id. This was wrongsince the InstanceID is bound the registration of a TaskExecutor whereas theResourceID is bound to the lifetime of the TaskExecutor. Thus, it is better to identifythe TaskExecutor by its ResourceID which does not change.This commit changes the behaviour accordingly on the ResourceManager and theTaskManagerDetailsHandler.This closes #5093.",0
[FLINK-8150] [flip6] Add TaskManagerIdPathParameterTest,3
"[FLINK-7717][flip6] Migrate TaskManagerMetricsHandler to new RestServerEndpointMigrate logic inorg.apache.flink.runtime.rest.handler.legacy.metrics.TaskManagerMetricsHandlerto new handler, and add new handler to DispatcherRestEndpoint.[FLINK-7717][flip6] Use taskmanagerid constant in TaskManagerMetricsHandlerTestThis closes #5081.",3
[FLIP-7716][flip6] Migrate JobManagerMetricsHandler to new RestServerEndpointMigrate logic inorg.apache.flink.runtime.rest.handler.legacy.metrics.JobManagerMetricsHandlerto new handler and add new handler to DispatcherRestEndpoint.[FLINK-7716][Javadoc] Deprecate method MetricStore#getJobManager().There is a semantically equivalent method in MetricStore.This closes #5083.,1
[hotfix][Javadoc] Fix typo in ConversionException,2
[FLINK-8143][flip6] Migrate SubtaskMetricsHandler to new RestServerEndpointMigrate logic fromorg.apache.flink.runtime.rest.handler.legacy.metrics.SubtaskMetricsHandler tonew handler. Add new handler to DispatcherRestEndpoint.[FLINK-8143][flip6] Assert that SubtaskIndexPathParameter is mandatory[FLINK-8143][flip6] Use path parameter constants in SubtaskMetricsHandlerTestThis closes #5082.,3
[hotfix][Javadoc] Remove wrong Javadoc from SubtaskMetricsHandler,0
[hotfix][flip6] Add unit tests JobVertexMetricsHeadersTest,3
"[FLINK-7694][flip6] Migrate JobMetricsHandler to new RestServerEndpointMigrate logic inorg.apache.flink.runtime.rest.handler.legacy.metrics.JobMetrisHandler to newhandler, and add new handler to DispatcherRestEndpoint.[FLINK-7694][flip6] Use jobid path parameter constant in JobMetricsHandlerTestThis closes #5084.",3
"[FLINK-7989][yarn] Do not upload the flink-dist jar twiceWe always add the dist.jar ourselves, but it could also be inside a shippedfolder such as the ""lib/"" folder and was then distributed multiple times.This closes #4951.",1
[FLINK-8165] ParameterTool serialization fixCloses #5096,0
[FLINK-7652] [flip6] Port CurrentJobIdsHandler to new REST endpointThis closes #4734.,1
"[FLINK-7652] [flip6] Introduce JobIdWithStatus type for JobIdsWithStatusOverviewInstead of storing the JobID and the JobStatus in a Tuple2 which is serializedas an array of values in JSON, this commit introduces the JobIdWithStatus whichis serialized as a proper JSON object with an id and a status field.",5
[hotfix] [docs] Fix typos in State Backends docThis closes #5075.,2
[FLINK-8076] [kinesis] Upgrade KinesisProducer to 0.10.6 to set properties approperiatelyThis closes #5017.,1
[FLINK-8149] [kinesis] Replace usages of deprecated SerializationSchemaThis closes #5069.,2
"[FLINK-8027] Generalize existing rest handlers to work with an arbitrary RestfulGatewayBy letting the existing REST handlers work with an arbitrary RestfulGateway,they can be used by the Dispatcher as well as the JobMaster, once it implementsthe RestfulGateway.This closes #4985.",1
[hotfix] Rename RestfulGateway#requestJobDetails into requestMultipleJobDetails to avoid name conflicts with JobMasterGateway,5
[hotfix] Pass in Rest address to Dispatcher as nullable String,1
[hotfix] [gelly] Fix Gelly CSV outputAlgorithm result types no longer extend Tuple but are now custom POJOs.This prevents the use of DataSet#writeAsCsv which accepts custom lineand field delimiters. Anticipating this lose the result types overrideThis patch uses DataSet#writeAsCsv for types extending Tuple andDataSet#writeAsText otherwise. Since most algorithm result types are nowcustom POJOs the custom delimiters are now largely ineffective.,5
[FLINK-8151] [table] Fix map type equalityThis closes #5070.,0
[FLINK-8173] [table] Fix input unboxing and support Avro Utf8This closes #5111.,1
[hotfix] [tests] Let MarshallingTestBases read the value from String value,3
[FLINK-8141] [flip6] Fix JsonPlan serialization in JobDetailsInfoThe JsonPlan in JobDetailInfo must be serialized as a raw valueto make it parsable for downstream applications.This closes #5109.,1
[FLINK-7851] [scheduling] Improve scheduling balance by round robin distributionMake sure that the value maps are of type LinkedHashMap in SlotSharingGroupAssignment#availableSlotsPerJidThis closes #4839.,4
"[FLINK-8028] Let JobMaster implement RestfulGatewayThis commit lets the JobMaster implement the RestfulGateway. That way,the JobMaster can be used in combination with the existing REST handlers.This closes #4986.",0
[FLINK-8148][yarn/s3] fix test instability in YarnFileStageTestS3ITCaseRemove a check for a deleted directory since we may not see our own delete yetwith S3.This closes #5066.,4
[FLINK-8104] [table] Add ROW value constructorThis closes #5040.,1
[hotfix][docs] Fix typo in checkpointing docThis closes #5110.,2
[FLINK-7907][docs][metrics] Add scala examplesThis closes #7907.,1
[FLINK-7595] [Savepoints] Allow removing stateless operatorsThis closes #4651.,1
"[FLINK-8167] [connector-wikiedits] Harden WikipediaEditsSource- Minor eager sanity checks- Use UUID suffix for nickname. As reported in FLINK-8167, the current  nickname suffix can result in nickname clashes which lead to test  failures.",0
[FLINK-7762] [connector-wikiedits] Make WikipediaEditsSourceTest proper testThe WikipediaEditsSourceTest unnecessarily implements an integrationtest that starts a FlinkMiniCluster and executes a small Flink program.This simply creates a source and executes run in a separate thread untila single WikipediaEditEvent is received.This closes #5102.,2
"[FLINK-8177] Replace TestingContainer by mock in YARN UtilsTestThe Container Interface was extended in Hadoop 2.9, meaning that thetest would not run when compiling with Hadoop 2.9. Using a mock fixesthis problem.",0
[FLINK-7395] [metrics] Count bytesIn/Out without synchronizationThis closes #4504.,2
[FLINK-8194] [akka] Suppress Java serializer used warnings from Akka,2
[hotfix] Remove empty line in UtilsTest,3
[FLINK-8190] [kafka] Add constructors to expose topic pattern-based subscriptionThis closes #5117.,1
[hotfix] [kafka] Fix outdated Javadoc reference to non-existing restoreState method,2
[FLINK-8196] [build] Remove 'javax.servlet' dependency exclusion.,4
[hotfix] [core] Fix remaining checkstyle issues for 'core.fs',0
[FLINK-8198] [core] Fix condition for parsing ConnectionLimitingSettings,1
[FLINK-8007][metrics] Move TestMeter into test scope,3
[hotfix][metrics] Cleanup reporter poms,4
[FLINK-8204] [tests] Harden JobManagerLeaderSessionIDITCaseReplace wait on lock with OneShotLatch to resolve race condition between taskstart up and unblocking of invokable.,0
"[FLINK-8186] Exclude flink-avro from flink-dist; fix AvroUtils loadingBefore, AvroUtils were loaded when the class was loaded which didn'ttake into account the user-code ClassLoader. Now, we try loading avroutils with the Thread context ClassLoader.",1
[hotfix] [tests] Speed up TaskManagerServicesTestThe TaskManagerServicesTest was extremely slow because it uses the PowerMockRunnerfor a single test case. Additionally some other tests test different settings ina loop which was quite slow because the PowerMockRunner instrumented all method calls.Moving the test which required the PowerMockRunner into a separate test class sped upthings by a factor of 50.,3
[FLINK-8193][quickstart] Cleanup quickstart pomsThis closes #5118.,4
[FLINK-8174] Mesos RM unable to accept offers for unreserved resources[FLINK-8174] Mesos RM unable to accept offers for unreserved resources- added test `OfferTest`[FLINK-8174] Mesos RM unable to accept offers for unreserved resources- fix `LaunchCoordinatorTest`[FLINK-8174] Mesos RM unable to accept offers for unreserved resources- improved javadocs[FLINK-8174] Mesos RM unable to accept offers for unreserved resources- rename `print` to `toString`- precalculate offer resource values- extend TestLoggerThis closes #5114.,3
[hotfix] Properly delete temp flink dir in create_source_release.sh,1
[FLINK-7975][QS] Wait for QS client to shutdown.,2
[FLINK-7974][QS] Wait for QS abstract server to shutdown.,2
[FLINK-7880][QS] Wait for proper resource cleanup after each ITCase.,4
[FLINK-8133][REST][docs] Generate REST API documentationThis closes #5052.,2
[hotfix][docs] Exclude flink-docs from maven deployment,2
[hotfix][javadoc] Fix typo in StreamElement javadocThis closes #5152.,2
[FLINK-8145][tests] fix various IOManagerAsync instances not being shut downThis closes #5064.,0
[FLINK-7692][metrics] Support user-defined variablesThis closes #5115.,1
[FLINK-8235][build] Spotbugs exclusion file path now absoluteThis closes #5146.,2
"[FLINK-8241][tests] Remove ResultPartitionWriter-related ""@PrepareForTest"" annotationsThis closes #5147.",3
"[FLINK-7748][network] Properly use the TaskEventDispatcher for subscribing to eventsPreviously, the ResultPartitionWriter implemented the EventListener interfaceand was used for event registration, although event publishing was alreadyhandled via the TaskEventDispatcher. Now, we use the TaskEventDispatcher forboth, event registration and publishing.It also adds the TaskEventDispatcher to the Environment information for a taskto be able to work with it (only IterationHeadTask so far).This closes #4761.",1
[FLINK-7749][network] Refactor ResultPartitionWriter into an interfaceThis closes #5127.,4
"[hotfix][tests] Remove Task-related ""@PrepareForTest"" annotations",3
[FLINK-8080][metrics] metrics.reporters now optional include listThis closes #5099.,2
[FLINK-8213][metrics] Improve fallback behaviorsThis closes #8213.,1
[hotfix][metrics] Refactor CheckpointStatsTrackerTest,3
[FLINK-8238][tests] Forbid multiple setups of StreamTaskTestHarness,3
[FLINK-8239][tests] StreamTaskTestHarness supports 2-input head operatorsThis closes #5153.,1
[hotfix] [docs] Consistent capitalization in Mesos documentation.This closes #5157.,2
[hotfix][javadocs] Clarify replacement for deprecated FoldingStateThis closes #5129.,2
[hotfix][tests] Extract SubmittedJobGraphStore implementation from JobManagerHARecoveryTest,3
[hotfix][Javadoc] Make first sentence in JobSubmissionException Javadoc end with period,2
"[FLINK-8176][flip6] Start SubmittedJobGraphStore in DispatcherImplement SubmittedJobGraphListener interface in DispatcherCall start() on SubmittedJobGraphStore with Dispatcher as listener. To enablethis, the dispatcher must implement the SubmittedJobGraphListener interface. Addsimple unit tests for the new methods. Refactor DispatcherTest to removeredundancy.[FLINK-8176][flip6] Make InMemorySubmittedJobGraphStore thread-safe[FLINK-8176][flip6] Add method isStarted() to TestingLeaderElectionService[FLINK-8176][flip6] Return same RunningJobsRegistry instance from TestingHighAvailabilityServices[FLINK-8176][flip6] Fix race conditions in Dispatcher and DispatcherTestCheck if jobManagerRunner exists before submitting job.Replace JobManagerRunner mock used in tests with real instance.Do not run job graph recovery in actor main thread when job graph is recoveredfrom SubmittedJobGraphListener#onAddedJobGraph(JobID).[FLINK-8176][flip6] Rename variables in DispatcherTest[FLINK-8176][flip6] Remove injectMocks in DispatcherTest[FLINK-8176][flip6] Update Dispatcher's SubmittedJobGraphListener callbacksAlways attempt the job submission if onAddedJobGraph or onRemovedJobGraph arecalled. The checks in submitJob and removeJob are sufficient.This closes #5107.",4
[hotfix][tests] Fix DispatcherTest compilation,3
[FLINK-8029] Create WebMonitorEndpointThe WebMonitorEndpoint is the common rest endpoint used for servingthe web frontend REST calls. It will be used by the Dispatcher andthe JobMaster to fuel the web frontend.This closes #4987.,1
[FLINK-8030] Instantiate JobMasterRestEndpoint in JobClusterEntrypointThis closes #4988.,1
"[FLINK-8078] Introduce LogicalSlot interfaceThe LogicalSlot interface decouples the task deployment from the actualslot implementation which at the moment is Slot, SimpleSlot and SharedSlot.This is a helpful step to introduce a different slot implementation forFlip-6.This closes #5086.",2
"[FLINK-8085] Thin out LogicalSlot interfaceRemove isCanceled, isReleased method and decouple logical slot from Execution byintroducing a Payload interface which is set for a LogicalSlot. The Payload interfaceis implemented by the Execution and allows to fail an implementation and obtaininga termination future.Introduce proper Execution#releaseFuture which is completed once the Execution'sassigned resource has been released.This closes #5087.",5
[FLINK-8261] [quickstarts] Fix typos in exclusion patterns.,2
"[hotfix] [quickstarts] Exclude not only slf4j api, but also bridges",0
[hotfix] [quickstarts] Fix indentation in Java Quickstart pom.xml,5
[FLINK-8263] [quickstarts] Correctly set 'flink-core' to provided in Scala Quickstart pom.xml,5
[FLINK-8262] [tests] Harden IndividualRestartsConcurrencyTest.testLocalFailureFailsPendingCheckpointsThe problem was a concurrent restart attempt which failed due to not enoughavailable slots. This failure would lead to the job failure and the discardingof all pending checkpoints.,0
[FLINK-8120] [flip6] Register Yarn application with correct tracking URLThe cluster entrypoints start the ResourceManager with the web interface URL.This URL is used to set the correct tracking URL in Yarn when registering theYarn application.This closes #5128.,1
[FLINK-8087] Decouple Slot from AllocatedSlotThis commit introduces the SlotContext which is an abstraction for the SimpleSlotto obtain the relevant slot information to do the communication with theTaskManager without relying on the AllocatedSlot which is now only used by theSlotPool.This closes #5088.,1
"[FLINK-8088] Associate logical slots with the slot request idBefore logical slots like the SimpleSlot and SharedSlot where associated to theactually allocated slot via the AllocationID. This, however, was sub-optimal becauseallocated slots can be re-used to fulfill also other slot requests (logical slots).Therefore, we should bind the logical slots to the right id with the right lifecyclewhich is the slot request id.This closes #5089.",2
[FLINK-8089] Also check for other pending slot requests in offerSlotNot only check for a slot request with the right allocation id but also checkwhether we can fulfill other pending slot requests with an unclaimed offeredslot before adding it to the list of available slots.This closes #5090.,1
[hotfix] Speed up RecoveryITCase,0
"[FLINK-7956] [flip6] Add support for queued scheduling with slot sharing to SlotPoolThis commit adds support for queued scheduling with slot sharing to theSlotPool. The idea of slot sharing is that multiple tasks can run in thesame slot. Moreover, queued scheduling means that a slot request must notbe completed right away but at a later point in time. This allows tostart new TaskExecutors in case that there are no more slots left.The main component responsible for the management of shared slots is theSlotSharingManager. The SlotSharingManager maintains internally a tree-likestructure which stores the SlotContext future of the underlyingAllocatedSlot. Whenever this future is completed potentially pendingLogicalSlot instantiations are executed and sent to the slot requester.A shared slot is represented by a MultiTaskSlot which can harbour multipleTaskSlots. A TaskSlot can either be a MultiTaskSlot or a SingleTaskSlot.In order to represent co-location constraints, we first obtain a rootMultiTaskSlot and then allocate a nested MultiTaskSlot in which theco-located tasks are allocated. The corresponding SlotRequestID is assignedto the CoLocationConstraint in order to make the TaskSlot retrievable forother tasks assigned to the same CoLocationConstraint.Port SchedulerSlotSharingTest, SchedulerIsolatedTasksTest andScheduleWithCoLocationHintTest to run with SlotPool.Restructure SlotPool components.Add SlotSharingManagerTest, SlotPoolSlotSharingTest andSlotPoolCoLocationTest.This closes #5091.",3
[hotfix] [tests] Speed up queryable state IT tests by removing sleep,4
"[FLINK-7878] [api] make resource type extendible in ResourceSpecSummary:Now, flink only support user define CPU and MEM,but some user need to specify the GPU, FPGA and so on resources.So it need to make the resouce type extendible in the ResourceSpec.Add a extend field for new resources.Test Plan: UnitTestReviewers: haitao.wDifferential Revision: https://aone.alibaba-inc.com/code/D327427make Resource abstract and add GPUResource FPGAResourceThis closes #4911.Add a resource spec builder and remove FPGAResource",4
[FLINK-7878] Hide GpuResource in ResourceSpec,2
[FLINK-7928] [runtime] extend the resources in ResourceProfile for precisely calculating the resource of task managerSummary:ResourceProfile denotes the resource requirements of a task. It should contains:1. The resource for the operators: the resources in ResourceSpec (please refer to jira-7878)2. The resource for the task to communicate with its upstreams.3. The resource for the task to communicate with its downstreams.Now the ResourceProfile only contains the first part. Adding the last two parts.Test Plan: UnitTestsReviewers: haitao.wDifferential Revision: https://aone.alibaba-inc.com/code/D330364This closes #4991.,3
[FLINK-7928] Move Resource out of ResourceSpec,4
[FLINK-8264] [core] Add 'scala.' to the 'parent-first' classloading patterns.This closes #5166,1
[hotfix][metrics][docs] Remove unclosed highlight,4
[hotfix] [javadoc] Fix typo in StreamExecutionEnvironment javadocThis closes #5164.,2
[FLINK-8249] [kinesis] Fix setting region on KinesisProducerConfigurationThis closes #5160.,5
[FLINK-8218] [kinesis] Move flink-connector-kinesis examples from /src to /testThis closes #5131.,3
[FLINK-8216] [kinesis] Unify test utils in flink-connector-kinesisThis closes #5130.,2
[hotfix] [doc] Fix typo in TaskManager and EnvironmentInformation docThis closes #5135.,2
[FLINK-7452] [types] Add helper methods for all built-in Flink types to TypesThis closes #4612.,2
[hotfix][docs] Update debugging classloading doc to Java 8Since Java 8 Metaspace has replaced PermGenThis closes #5158.,2
[FLINK-8215] [table] Support implicit type widening for array/map constructors in SQLThis closes #5148.,1
[FLINK-8295] [cassandra] [build] Properly shade netty for the datastax drivercom.datastax.driver.core.NettyUtil expects netty to be present either at itsoriginal package or relocated to com.datastax.shaded.netty. By relocating itto this package we make sure the driver follows its designated path.This closes #5183.,1
[FLINK-5506] [gelly] Fix CommunityDetection NullPointerExceptionDouble.MIN_VALUE != min(double)This closes #5126,0
[FLINK-8222] [build] Update Scala versionThis is an incremental upgrade to the Scala security release 2.11.12.This closes #5136,5
[FLINK-8223] [build] Update Hadoop versionsUpdate 2.7.3 to 2.7.5 and 2.8.0 to 2.8.3This closes #5137,5
[hotfix] [build] Always include Kafka 0.11 connectorNow that Flink only supports builds for Scala 2.11+ we canunconditionally enable the Kafka 0.11 connector.This closes #5195,0
[hotfix] [docs] Fix typos in MemorySegment classThis closes #5199,2
[FLINK-8301][table] Support Unicode in codegen for TableAPI && SQLThis closes #5203,1
[FLINK-8278] [docs] Fix Scala examples of metrics docs (var initialization).,5
[FLINK-8312][table] Fix ScalarFunction varargs length exceed 254This closes #5206,1
[FLINK-8227] Optimize the performance of SharedBufferSerializerThis closes #5142,5
[hotfix] Replace HighAvailabilityOptions#HA_ZOOKEEPER_NAMESPACE with HA_CLUSTER_ID,0
"[FLINK-8171] [flip6] Remove work arounds from Flip6LocalStreamEnvironmentIt is no longer needed to wait for the registration of task managers andto not use slot sharing when submitting jobs to the Flip-6 MiniCluster.Therefore, we can remove these work arounds from theFlip6LocalStreamEnvironment.Adapt comment in RestClusterClientThis closes #5101.",1
"[FLINK-8330] [flip6] Remove FlinkYarnCLIThe FlinkYarnCLI is not needed and is, thus, being removed.This closes #5217.",4
[FLINK-8330] [flip6] Remove YarnClusterClientV2The YarnClusterClientV2 is no longer needed since we have removed FlinkYarnCLI.,2
[FLINK-8226] [cep] Dangling reference generated after NFA clean up timed out SharedBufferEntryThis closes #5141,5
[FLINK-8257] [conf] Unify the value checks for setParallelism(),1
[FLINK-8326] CheckpointCoordinatorTest#testRestoreLatestCheckpointedStateScaleOut() didn't use the correct parameter to trigger test function,1
[FLINK-8258] [table] Enable query configuration for batch queriesThis closes #5169.,5
[FLINK-8258] [table] Add missing ScalaDocs,2
[hotfix] [docs] Remove duplicated 'program' in docs/dev/api_concepts.mdThis closes #5222.,2
"[hotfix] [docs] Fix Scala code snippets in docs.* remove unneeded semi-colons* add `()` to `print` method    * typically, methods with some side-effects are invoked with `()`* fix a few misc issuesThis closes #5221.",0
[FLINK-8323] [table] Fix modulo scalar function bugThis closes #5212.,0
[FLINK-8122] [table] Name all built-in table sinks and sourcesThis closes #5068.,2
[FLINK-7427][network] integrate PartitionRequestProtocol into NettyProtocol- removes one level of (unneeded) abstraction for clarityThis closes #4528.,4
[hotfix] add some more buffer recycling checks in SpillableSubpartitionTest,3
[hotfix] only update buffer statistics in SpillableSubpartition#add() if successful,1
"[FLINK-7499][io] also let AsynchronousBufferFileWriter#writeBlock() recycle the buffer in case of failuresThis fixes a double-recycle in SpillableSubpartitionView and also makes surethat even if adding the (asynchronous) write operation fails, the buffer isproperly freed in code that did not perform this cleanup. It avoids codeduplication of this cleanup and it is also more consistent to take overresponsibility of the given buffer even if an exception is thrown.[FLINK-7499][io] complete the idiom of ResultSubpartition#add() taking over ownership of the bufferThe buffer will now always be released once and at the right time and the callermust not worry about the buffer release if a called function threw an exception.This closes #4581.",1
"[FLINK-7517][network] let NettyBufferPool extend PooledByteBufAllocatorPreviously, NettyBufferPool only wrapped PooledByteBufAllocator but then, anyallocated buffer's alloc() method was returning the wrappedPooledByteBufAllocator which allowed heap buffers again. By extending thePooledByteBufAllocator, we prevent this loop hole.This also fixes the invariant that a copy of a buffer should have the sameallocator.This closes #4594.",0
[FLINK-8331][core] FieldParser do not correctly set EMPT_COLUMN error state.This closes #5218,0
[FLINK-8139] [table] Check for proper equals() and hashCode() for stateful operatorsThis closes #5065.,1
[FLINK-8139] [table] Check types for hashCode/equals only for stateful operations,2
[FLINK-8203] [FLINK-7681] [table] Make schema definition of DataStream/DataSet to Table conversion more flexibleThis closes #5132.,5
[hotfix] [core] Add comments for class loading config options in CoreOptions,5
"[FLINK-8374] [yarn,tests] Whitelist meaningless exception that may occur during Akka shutdown.",3
[hotfix] [doc] Fix typo in filesystems.mdThis closes #5237,5
"[hotfix] Fix many many typosFix typos from the IntelliJ ""Typos"" inspection.This closes #5242",2
[FLINK-8359] [docs] Update copyright date in NOTICEThis closes #5238,5
[hotfix] Fix typo in TestableKinesisDataFetcherThis closes #5178,5
[hotfix] [misc] Fix some typosThis closes #5204,2
[FLINK-8346][docs] add v4 signature workaround for manual S3 setupsThis closes #5231,1
"[FLINK-8373] [core, hdfs] Ensure consistent semantics of FileSystem.mkdirs() across file system implementations.",5
[hotfix] [tests] Remove unnecessary stack trace printing in StreamTaskTest,3
[hotfix] [core] Avoid redundant File path conversion in LocalFileSystem.getFileStatus(Path),5
"[hotfix] [checkpoints] Remove never used method 'close()' on CheckpointStreamFactoryThe fact that the method was never called (and never implemented) strongly suggeststhat it should be removed, otherwise someone might eventually end up implementingit for a new state backend and wonder why it is never called.",1
[hotfix] [core] Improve local fs exists() performanceThis avoids going though an exception in the case of non-existing files.,2
"[hotfix] [hdfs] Avoid re-parsing URIs for all Hadoop File System calls.Previously, this converted Flink paths (internally URIs) to strings andthen let the Hadoop Paths parse, validate, and normalize the strings toURIs again.Now we simply pass the URIs directly.",4
"[hotfix] [checkpoints] Improve performance of ByteStreamStateHandleThe input stream from ByteStreamStateHandle did not overwrite the 'read(byte[], int, int)' method,meaning that bulk byte reads resulted in many individual byte accesses.Additionally, this change avoids accessing the data array through an outer class, but instead addsa reference directly to the input stream class, avoiding one hop per access. That also allowsa more restricted access level on the fields, which may additionally help the jitter in some cases.",1
[hotfix] [core] Pre-compile regex pattern in Path class,0
[hotfix] [core] Add a factory method to create Path from local fileThis makes it easier for users and contributors to figure out howto create local file paths in way that works cross operating systems.,5
[FLINK-8265] Missing jackson dependency for flink-mesos,2
[FLINK-8116] [DataStream] Fix stale comments referring to Checkpointed interface,0
[FLINK-8116] [DataStream] Provide proper checkpointed source function example in JavadocsThis closes #5121.,2
[FLINK-8260] [kafka] Fix usage of deprecated instantiation methods in FlinkKafkaProducer docs,2
[FLINK-8287] [kafka] Improve Kafka producer Javadocs / doc to clarify partitioning behaviour,2
"[FLINK-8260] [kafka] Reorder deprecated / regular constructors of FlinkKafkaProducer010This commit moves deprecated factory methods of theFlinkKafkaProducer010 behind regular constructors, for better navigationand readability of the code.This closes #5179.",1
"[hotfix] [kafka] Properly deprecate FlinkKafkaProducer010ConfigurationFlinkKafkaProducer010Configuration is the return type of the deprecatedwriteToKafkaWithTimestamp factory methods. Therefore, the class shouldalso be deprecated as well.",5
[hotfix] [kafka] Fix stale Javadoc link in FlinkKafkaProducer09The previous link was referencing a non-existent constructor signature.,2
[hotfix] [kafka] Add serialVersionUID to FlinkKafkaProducer010,2
[FLINK-8268][streaming][tests] Improve TwoPhaseCommitSinkFunctionTest stability by using custom in memory storage,1
[FLINK-8298][tests] Properly shutdown MockEnvironment to release resourcesThis closes #5193.,3
"[FLINK-8283] [kafka] Stabalize FlinkKafkaConsumerBaseTest::testScaleUp()Previously, the testScaleUp() test was taking too much resources andcausing test resources to be terminated before the test could finish.This commit lowers the intensity of the test, while still retaining theverified behaviour (i.e., when restoring the Kafka consumer with higherparallelism and more Kafka partitions).This closes #5201.",5
[FLINK-7406][network] Implement Netty receiver incoming pipeline for credit-based,2
[FLINK-7416][network] Implement Netty receiver outgoing pipeline for credit-based,2
[hotfix][network] Drop redundant this reference usages,4
[FLINK-8207][network-tests] Unify TestInfiniteBufferProvider and TestPooledBufferProvider,5
[hotfix][network-tests] Simplify TestPooledBufferProvider,5
[FLINK-8208][network-tests] Reduce mockito usage in RecordWriterTest,3
[FLINK-8209][network-tests] Make LocalBufferPoolDestroyTest less implementation dependent,3
[hotfix][runtime] Remove unused methods,1
[FLINK-8210][network-tests] Collect results into proper mock in MockEnvironment,3
[FLINK-8214][streaming-tests] Collect results into proper mock in StreamMockEnvironment,3
"[FLINK-8178][network] Introduce not threadsafe write only BufferBuilderWhile Buffer class is used in multithreaded context it requires synchronisation.Previously it was miss-leading and unclear, suggesting that RecordSerializer shouldtake into account synchronisation of the Buffer that's holding. With NotThreadSafeBufferBuilder there is now clear separation between single-threaded writing/creatinga BufferBuilder and multithreaded Buffer handling/retaining/recycling.This increases throughput of network stack by factor of 2, because previouslymethod getMemorySegment() was called twice per record and it is a synchronizedmethod on recycleLock, while RecordSerializer is sole owner of the Buffer atthis point, so synchronisation is not needed.",1
[hotfix][test] Add timeout for joining with CheckedThread,5
[hotfix][util] Added suppressExceptions for lambda functions,1
[FLINK-8220][network-benchmarks] Define network benchmarks in Flink project,2
[FLINK-8221][network-benchmarks] Define latency network benchmarks in Flink projectThis closes #5255.,2
[FLINK-8383][mesos] Disable test-jar shadingThis closes #5258.,3
[FLINK-8292] Remove unnecessary force cast in DataStreamSourceThis closes #5180.,5
[FLINK-8280][checkstyle] enable and fix checkstyle in BlobServer and BlobUtilsThis closes #5175.,0
[FLINK-8250][runtime] Remove unused RecordSerializer#instantiateMetricsThis closes #5162.,1
[FLINK-8200][tests] Use TemporaryFolder in RocksDBAsyncSnapshotTestThis closes #5122.,5
[hotfix][docs] Fix DataStream iterations documentation* Fix a scala example which is using a wrong variable* Remove partitioning descriptions  * partitioning parameters are already removed from  IterativeStream#closeWith/DateStream#iterate  * https://github.com/apache/flink/pull/988  * https://github.com/apache/flink/pull/4655This closes #5249.,2
[hotfix][docs][metrics] Fix Threads.Count metric referenceThis closes #5213.,0
[FLINK-8320][docs] Clarify that only Java 8 is supported,1
[FLINK-8388][docs] Fix baseUrl for master branchThis closes #5263.,0
"[FLINK-7903] [tests] Add flip6 build profileThe flip6 build profile only runs the Flip-6 related test cases. Moreover,all Flip-6 related test cases are excluded when not running the flip6 buildprofile. This should reduce testing time when adding more and more Flip-6test cases.Include flink-test-utils-junit in all submodules to make the Category marker interfaces Flip6 and OldAndFlip6 availableThis closes #4889.",1
[hotfix] Remove unnecessary surefire plugin version in flink-connector-elasticsearch5,2
[FLINK-7904] Enable Flip6 build profile on TravisThis adds a new Travis build matrix entry which runs the Flip-6 build profileReuse caches and split core+test into core and tests Travis buildThis closes #4890.,3
"[FLINK-7909] Unify Flink test basesIntroduce a MiniClusterResource which is used by the AbstractTestBase to startand shut down a FlinkMiniCluster. Additionally, this resource registers the properStream- and ExecutionEnvironment which is now the only way for tests to startjobs. This change will thus allow to centrally control which FlinkCluster willbe started for all test bases.",3
"[FLINK-7909] Replace StreamingMultipleProgramsTestBase by AbstractTestBaseThe AbstractTestBase fully subsumes the functionality of theStreamingMultipleProgramsTestBase since it now is the most general test basefor streaming and batch jobs. As a consequence, we can safely remove theStreamingMultipleProgramsTestBase and let all corresponding tests extend fromAbstractTestBase.This closes #4896.",3
[hotfix] Remove unnecessary exception catching in StreamingProgramTestBase,3
[FLINK-6094] [table] Implement stream-stream proctime non-window inner joinThis closes #4471.,2
[FLINK-6094] [table] Add checks for hashCode/equals and little code cleanup,4
[FLINK-8381] [table] Document more flexible schema definitionThis closes #5257.,5
[FLINK-7797] [table] Add support for windowed outer joins for streaming tables.This closes #5140.,1
[hotfix] [docs] Update documentation about joins,2
[FLINK-8352] [web-dashboard] Report error on jar submission failureThis closes #5264.,0
[FLINK-8385] [checkpointing] Suppress logging of expected exception during snapshot cancellation.,2
[FLINK-8385] [checkpointing] Avoid RejectedExecutionException in SharedStateRegistry during disposal from async Zookeeper calls.This closes #5256.,1
[hotfix][checkstyle] only ignore checkstyle in existing packages under runtime.io.network- ignore runtime.io.(async|disk)- ignore runtime.io.network.(api|buffer|netty|partition|serialization|util)-> everything else will be checked against the ruleset- fix checkstyle errors in classes directly under runtime.io.network,1
"[FLINK-8252][benchmarks] convert network benchmarks to streaming benchmarksThis allows us to use the output flushing interval as a parameter to evaluate,too.This closes #5259.",2
[FLINK-7468][network] Implement sender backlog logic for credit-basedTHis closes #4559.,2
"[FLINK-8375][network] Remove unnecessary synchronizationSynchronized blocks in ResultPartition could affect only:1. totalNumberOfBuffers and totalNumberOfBytes counters2. subpartition add(), finish() and release() calls.However:1. counters were not used anywhere - they are removed by this commit2a. add(), finish() and release() methods for PipelinedSubpartition were already threads safe2b. add(), finish() and release() methods for SpillableSubpartition were made thread safe inthis commit, by basically pushing synchronized section down one level.This closes #5260.",5
[hotfix][tests] move assertions out of the finally blockThere was a potential for them to mask exceptions.,3
"[FLINK-8371][network] always recycle Buffers when releasing SpillableSubpartitionThere were places where Buffer instances were not released uponSpillableSubpartition#release() with a view attached to a non-spilledsubpartition:1) SpillableSubpartition#buffer:  SpillableSubpartition#release() delegates the recycling to the view, but  SpillableSubpartitionView does not clean up the 'buffers' queue (the  recycling was only done by the subpartition if there was no view).2) SpillableSubpartitionView#nextBuffer:  If this field is populated when the subpartition is released, it will neither  be given out in subsequent SpillableSubpartitionView#getNextBuffer() calls  (there was a short path returning 'null' here), nor was it recycled-> similarly to the PipelinesSubpartition implementation, make   SpillableSubpartition#release() always clean up and recycle the buffers-> recycle SpillableSubpartitionView#nextBuffer in   SpillableSubpartitionView#releaseAllResources()This closes #5261.",4
[FLINK-5982] [runtime] Refactor AbstractInvokable and StatefulTask to accept Environment and State in the constructor.This is the first steo towards implementing an RAII pattern for all task runtime classes.This closes #3633,1
[FLINK-8392] [rpc] Let termination future be completed by AkkaRpcActor#postStopRevert the changes introduced by FLINK-7754. An RpcEndpoint's termination future is nowcompleted from the AkkaRpcActor#postStop method.This closes #5266.,2
"[FLINK-7910] [tests] Generalize Test(Stream)Environment to use JobExecutorThis commit introduces the JobExecutor interface which abstracts the actual mini clusterfrom the Test(Stream)Environment. By letting the Flip-6 MiniCluster as well as theFlinkMiniCluster implement this interface, we can run all test base jobs either on theFlip-6 mini cluster or on the current mini cluster.This closes #4897.",5
[hotfix] Add retrieval of key sets to DualKeyMap,1
[FLINK-8389] [flip6] Release all slots upon closing of JobManagerThis closes #5265.,2
[hotfix] Enable checkpointing RPC calls,0
[hotfix] Add JavaDocs to OnCompletionActions,2
[hotfix] Refactor JobMasterTest to avoid using Mockito,1
"[FLINK-6926] [table] Add support for MD5, SHA1 and SHA256This closes #4810.",1
[FLINK-7475] [state] Introduce ListState#update()This closes #4963.,5
"[FLINK-8393] [flip6] Reconnect to last known JobMaster when connection is lostIn case of a heartbeat timeout or a disconnect call, the TaskExecutor tries toreconnect to the last known JobMaster location.This closes #5267.",2
[FLINK-7918] Run AbstractTestBase tests on Flip-6 MiniClusterThis closes #5095.,5
[hotfix] [tests] Refactor TypeHintITCase to extend AbstractTestBase,3
[hotfix] [tests] Fix JavaProgramTestBase to reset MiniClusterResource#TestEnvironment,5
"[hotfix] [tests] Fix PageRankITCase, AggregatorsITCase and DataSinkITCase to use fresh result path",1
[FLINK-6893] [table] Add BIN function supportThis closes #4128.,1
[FLINK-6893] [table] Add BIN function to Table API and fix bugs,0
[FLINK-6094] [table] Use the lexicographic smallest attribute as the common group idThis closes #5273.,1
[hotfix] [docs] Update latest stable version URL,3
[FLINK-8404] [tests] Mark Flip-6 tests with Flip6 category annotationMarks all existing Flip-6 test cases with the Flip6 category annotation. Thatway they are only run if the Flip-6 test profile is active.This closes #5278.,2
"[FLINK-8234][flip6] Cache JobExecutionResult in Dispatcher- Introduce new JobExecutionResult used by JobMaster to forward the information in  the already existing JobExecutionResult.- Always cache a JobExecutionResult. Even in case of job failures. In case of  job failures, the serialized exception is stored additionally.- Introduce new methods to RestfulGateway to allow retrieval of cached  JobExecutionResults[FLINK-8234][flip6] Rename JobExecutionResult -> JobResult[FLINK-8234][flip6] Update MiniClusterJobDispatcherDo not store job failure exception in a separate field because the JobResultalready contains the exception.[FLINK-8234][flip6] Make JobResult Serializable[FLINK-8234][flip6] Add Javadoc to JobResult builder[FLINK-8234][flip6] Add Javadoc to JobResult#serializedThrowable[FLINK-8234][flip6] Wrap JobResults in SoftReferencesWrap instances of JobResult stored in JobExecutionResultCache in SoftReferencesso that the GC can free them according to memory demand.[FLINK-8234][flip6] Fix checkstyle violations[FLINK-8234][flip6] Add Javadoc to JobResultThis closes #5184.",2
"[FLINK-7949] Make AsyncWaitOperator recoverable also when queue is fullStart emitter thread BEFORE filling up the queue of recovered elements.This guarantees that we won't deadlock inserting the recovered elements,because the emitter can already start processing elements.This closes #4924.",1
[FLINK-7949] Add unit test for AsyncWaitOperator recovery with full queue,1
[hotfix] [travis] Set distinct cache for Flip-6 build profiles,2
"[FLINK-8328] [flip6] Move Yarn ApplicationStatus polling out of YarnClusterClientIntroduce YarnApplicationStatusMonitor which does the Yarn ApplicationStatus polling inthe FlinkYarnSessionCli. This decouples the YarnClusterClient from the actual communicationwith Yarn and, thus, gives a better separation of concerns.This closes #5215.",1
[FLINK-8329] [flip6] Move YarnClient to AbstractYarnClusterDescriptorMoves the YarnClient from the YarnClusterClient to the AbstractYarnClusterDescriptor.This makes the latter responsible for the lifecycle management of the client and givesa better separation of concerns.This closes #5216.,1
[FLINK-8332] [flip6] Move savepoint dispose into ClusterClientMove the savepoint disposal logic from the CliFrontend into the ClusterClient. This givesa better separation of concerns and allows the CliFrontend to be used with differentClusterClient implementations.This closes #5219.,1
[FLINK-8233][flip6] Add JobExecutionResultHandler    - Allow retrieval of the JobResult cached in Dispatcher.    - Implement serializer and deserializer for JobResult.[FLINK-8233][flip6] Improve JobResultDeserializer and add tests[FLINK-8233][flip6] Exclude null jobExecutionResult from serialization[FLINK-8233][flip6] Add TestLogger to JobResultDeserializerTestThis closes #5194.,3
[hotfix] Clean up ExecutionGraph- Remove unnecessary throws clause.- Format whitespace.,1
"[FLINK-8333] [flip6] Separate deployment options from command optionsThis commit separates the parsing of command options and deployment options into twosteps. This makes it easier to make the CustomCommandLines non-static.Moreover, this commit moves the CliFrontend into the cli sub package.This closes #5220.",4
"[FLINK-8338] [flip6] Make CustomCommandLines non static in CliFrontendThis commit changes how CustomCommandLines are registered at the CliFrontend.Henceforth, the CliFrontend is initialized with the set of CustomCommandLinesinstead of registering them statically. This improves maintainability andtestability.This closes #5224.",3
"[FLINK-8339] [flip6] Let CustomCommandLine return ClusterDescriptorInstead of directly retrieving or deploying a Flink cluster, theCustomCommandLine now only returns a ClusterDescriptor which can be usedfor these operations. This disentangles the ClusterDescriptor and theCustomCommandLine a bit better supporting a proper lifecycle managementof the former.This closes #5225.",1
[FLINK-8299][flip6] Retrieve JobExecutionResult after job submission[FLINK-8299][flip6] Improve ExponentialWaitStrategyAdd additional argument validation. Add more unit tests.This closes #5207.,3
[FLINK-8271] [kinesis] Remove usage of deprecated Kinesis APIsThis closes #5171.,4
[FLINK-6951] [kinesis] Shade httpcomponents dependency for Kinesis connectorThis closes #4150.,2
[hotfix] [doc] Fixed doc typo in DataStream APIThis closes #5283.This closes #5191.,5
[hotfix] Fix typo in AbstractMetricGroup.javaThis closes #5280.,2
"[FLINK-8324] [kafka, metrics] Add new offsets metrics that can be scoped by topic and partition",1
"[FLINK-8324] [kafka, metrics] Make clear which metrics are legacy and should not be touchedThis commit consolidates all metrics related constant string names in aKafkaConsumerMetricConstants class, to give a better overview code-wisewhich metrics are exported.That makes it more clear in the code which metrics are kept forcompatibility reasons. It also additionally states that metric namesshould not be changed, otherwise metrics compatibility will be broken.This closes #5214.",4
"[FLINK-8162] [kinesis, metrics] Add Kinesis' millisBehindLatest metric",3
"[FLINK-8162] [kinesis] Move shard metric gauges registration to KinesisDataFetcherThis commit refactors the registration of shard metric gauges to theKinesisDataFetcher, instead of being handled by the ShardConsumer.Overall, this achieves better separation of concerns.This commit also consolidates all metrics related constant strings to aseparate KinesisConsumerMetricConstants class, with comments that themetric names should not be touched to maintain backwards compatibilityfor the consumer's shipped metrics.",5
[FLINK-8162] [kinesis] Add unit test for Kinesis shard metrics reportingThis closes #5182.,3
"[FLINK-8162, FLINK-8364] [metric, doc] Improve Kafka / Kinesis metrics doc- Add available user variables to table- Fix wordings to be more fluent- Fix incorrect metric type for Kinesis millisBehindLatest- Add description that Kafka commit failures do not affect Flink's  checkpoint integrity.",2
"[FLINK-8296] [kafka] Rework FlinkKafkaConsumerBaseTest to not rely on Java reflectionReflection was mainly used to inject mocks into private fields of theFlinkKafkaConsumerBase, without the need to fully execute all operatorlife cycle methods. This, however, caused the unit tests to be tooimplementation-specific.This commit reworks the FlinkKafkaConsumerBaseTest to remove testconsumer instantiation methods that rely on reflection for dependencyinjection. All tests now instantiate dummy test consumers normally, andlet all tests properly execute all operator life cycle methodsregardless of the tested logic.This closes #5188.",2
"[FLINK-8306] [kafka, tests] Fix mock verifications on final methodPreviously, offset commit behavioural tests relied on verifying onAbstractFetcher::commitInternalOffsetsToKafka(). That method is actuallyfinal, and could not be mocked.This commit fixes that by implementing a proper mock AbstractFetcher,which keeps track of the offset commits that go through.This closes #5284.",1
"[hotfix] [kafka] Remove stale comment on publishing procedures of AbstractFetcherThe previous comment mentioned ""only now will the fetcher return atleast the restored offsets when calling snapshotCurrentState()"". This isa remnant of the previous fetcher initialization behaviour, where in thepast the fetcher wasn't directly seeded with restored offsets oninstantiation.Since this is no longer true, this commit fixes the stale comment toavoid confusion.",5
[FLINK-8217] [kinesis] Properly annotate APIs of flink-connector-kinesisThis closes #5138.,2
[hotfix] [kinesis] Add serialVersionUID to KinesisPartitioner,1
[FLINK-8199] [elasticsearch] Properly annotate APIs of Elasticsearch connectorThis closes #5124.,2
[FLINK-8276] [kafka] Properly annotate APIs for Kafka connectorThis closes #5173.,2
[hotfix] [kafka] Add missing serialVersionUIDs to all Kafka connector Serializable classes,1
"[FLINK-8340] [flip6] Remove passing of Configuration to CustomCommandLineSince the Configuration does not change over the lifetime of a CustomCommandLine,we can safely pass it as a constructor argument instead of method argument.This closes #5226.",4
[FLINK-8341] [flip6] Remove not needed options from CommandLineOptionsThis closes #5227.,4
[FLINK-8342] [flip6] Remove generic type parameter from ClusterDescriptorThis closes #5228.,2
[FLINK-8349] [flip6] Remove Yarn specific commands from YarnClusterDescriptorRemove Yarn specific commands from YarnClusterDescriptor. This is a preparationalstep to make the FlinkYarnSessionCli work with the Flip-6 RestClusterClient.This closes #5229.,1
[hotfix] Add help command to FlinkYarnSessionCli,2
"[FLINK-8347] [flip6] Make cluster id used by ClusterDescriptor typesafeThe ClusterDescriptor uses a typed cluster id for the ClusterClient retrieval.Moreover, the ClusterClient and the CustomCommandLine are typed accordingly.This closes #5232.",1
[FLINK-8348] [flip6] Print help for DefaultCLIThis closes #5233.,2
"[FLINK-8119] [flip6] Wire correct Flip6 components in Flip6YarnClusterDescriptorLet the Flip6YarnClusterDescriptor create a RestClusterClient as ClusterClient.Moreover, this commit makes the YarnResourceManager register under the REST portat Yarn.This closes #5234.",1
[hotfix] Log failure message only if Yarn application truly failed,0
[FLINK-8201] [yarn] Delete temp configuration file after uploading it to HDFSThe Utils#createTaskExecutorContext method creates a temporary local configurationfile which it then uploads to HDFS. This fille should be removed after the uploadhas completed.This closes #5123.,4
[FLINK-8420] [flip6] Recognize TimeoutException in RetryingRegistrationA timeout exception will trigger an exponential backoff wrt the connection timeout.This will guarantee that we don't overload the network with connection requests butalso to quickly connect to a newly available target.This closes #5286.,1
[FLINK-8288] [runtime] register job master rest endpoint url to yarnThis closes #5186.,1
[FLINK-8317][flip6] Implement savepoints in RestClusterClientAllow triggering of savepoints through RestfulGateway. Implement REST handlersto trigger and query the status of savepoints. Implementsavepoint command in RestClusterClient.[FLINK-8317][flip6] Rename field QueueStatus#statusId to id[FLINK-8317][flip6] Simplify initialization of RpcUtils#INF_TIMEOUT[FLINK-8317][flip6] Add missing fail() to test in SavepointHandlersTest[FLINK-8317][flip6] Add TestLogger to unit tests[FLINK-8317][flip6] Replace anonymous with lambda[FLINK-8317][flip6] Extract string constants to variables in RestClusterClientTest[FLINK-8317][flip6] Move method RestClusterClient#waitForResource[FLINK-8317][flip6] Do not wait if resource is already completed[FLINK-8317][flip6] Only return savepoint location from triggerSavepointOnly return the savepoint's location from RestfulGateway#triggerSavepoint. Fixmistakes in Javadoc. Rename occurrences of checkpoint to savepoint inSavepointHandlers class.[FLINK-8317][flip6] Declare SavepointHandlers#defaultSavepointDir finalThis closes #5223.,0
[hotfix][javadoc] Fix typo in Watermark javadoc,2
[hotfix][tests] Add TestLogger to ExponentialWaitStrategyTest,3
[FLINK-8368] Migrate org.apache.flink.runtime.rest.handler.legacy.SubtaskExecutionAttemptDetailsHandler to new a REST handler that registered in WebMonitorEndpoint[FLINK-8368] Add attempts path info that is missing in SubtaskExecutionAttemptDetailsHeadersThis closes #5270.,5
[FLINK-8368] [rest] Simplify SubtaskExecutionAttemptDetailsHandlerTest#testHandleRequest,3
[FLINK-8369] Migrate SubtaskExecutionAttemptAccumulatorsHandler to Flip-6 REST endpointThis closes #5285.,0
[FLINK-8367] Migrate SubtaskCurrentAttemptDetailsHandler to new a REST handlerThis closes #5287.,0
[FLINK-8399] [runtime] use independent configurations for the different timeouts in slot managerThis closes #5271.,5
[FLINK-8082][build] Bump flink version for japicmp pluginThis closes #5262.,2
[hotfix][docs] Mention maven dependency for RocksDB state backendThis closes #5293.,5
[hotfix] [docs] Fix typosThis closes #5289.,2
"[hotfix][akka] Fix typo in AkkaUtils methodAlso, removed unused code:- `StandaloneHaServices#RESOURCE_MANAGER_RPC_ENDPOINT_NAME`, since `ResourceManager#RESOURCE_MANAGER_NAME` is used instead- AkkaRpcServiceUtils#createInetSocketAddressFromAkkaURL()This closes #5133.",1
[FLINK-8175] remove flink-streaming-contrib and migrate its classes to flink-streaming-java/scalaupdate docmove classes to /experimentalupdate license headerreorg scala class levelenforce stylecheck and change API annotationThis closes #5112.,4
[FLINK-8050] [rest] REST server reports netty exceptions on shutdown.,2
[FLINK-8049] [rest] REST client reports netty exceptions on shutdown.This closes #5057.,2
[FLINK-7777][build] Bump japicmp to 0.11.0This closes #5302.,2
"Revert ""[hotfix][docs] Mention maven dependency for RocksDB state backend""This reverts commit 5623ac66bd145d52f3488ac2fff9dbc762d0bda1.",5
"[FLINK-8279][blob] fall back to TaskManager temp directories firstInstead of falling back to java.io.tmpdir directly, the BLOB server and cacheprocesses fall back to the TaskManager temp directories (given byConfigConstants#TASK_MANAGER_TMP_DIR_KEY) directly, before falling backto ConfigConstants#DEFAULT_TASK_MANAGER_TMP_PATH (set to java.io.tmpdir).In a Mesos/YARN environment, this means that we will use the designated tempdirectories for our jobs instead of the system-wide java.io.tmpdir. Thesedirectories may also offer some more space.This closes #5176.",5
[hotfix] replace misuse of ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH as a temporary folder in unit tests-> use JUnit's TemporaryFolder instead.,3
"[FLINK-8350][config] replace ""taskmanager.tmp.dirs"" with ""io.tmp.dirs""This replaces ""taskmanager.tmp.dirs"" with the new ""io.tmp.dirs""configuration parameter to define temporary directories in (cluster)environments for all components, i.e. JobManager, JobMaster, Dispatcher,...Please note that this (kind of internal and thus undocumented) configurationparameter is set by our YARN and Mesos integrations.[FLINK-8350][cluster] initialise ""io.tmp.dirs"" for JobManager as wellIn a YARN and Mesos environment, this initialises Flink's temporary directoryconfiguration with YARN/Mesos application-specific paths for JobManager,JobMaster, Dispatcher, etc. components as well (Mesos integration actually stilllacks a proper integration of this, but once done, the new hooks fall in placejust fine).",1
[hotfix][tests] replace DiscardingRecycler with FreeingBufferRecycler,3
[hotfix][tests] do not use a mocked BufferRecycler for unpooled memory segmentsThe mock will actually keep references to the segments instead of freeing them.,1
[hotfix][tests] make SpillableSubpartitionTest use TestBufferFactory.createBuffer(this simplifies the test setups),1
[hotfix][tests] replace InputChannelTestUtils#createMockBuffer() with TestBufferFactory#createBuffer()This eliminates one more unnecessary buffer mock.,3
"[FLINK-7520][network] let our Buffer class extend from netty's buffer classFor this, use a common (flink) Buffer interface and an implementation(NetworkBuffer) that implements netty's buffer methods as well. In the future,with this, we are able to avoid unnecessary buffer copies when handing buffersover to netty while keeping our MemorySegment logic and configuration.For the netty-specific part, the NetworkBuffer also requires a ByteBuf allocatorwhich is otherwise not needed in our use cases, so if the buffer is handed overto netty, it requires a byte buffer allocator to be set.",1
[hotfix][io] remove duplicate code between SynchronousBufferFileReader and BufferReadRequest,2
"[hotfix][network] clarify BufferResponse#size() uses (by removing it)This field was only used by the code paths on the receiver and was inconsistentwith what was added on the sending side. We should use the contained buffer'sreadableBytes() instead, depending on the actual use case.This closes #4613.",1
"[hotfix][network] rename Buffer#retain() and #recycle in preparation for FLINK-8396 and FLINK-8395Since these two methods also exist in Netty's ByteBuf, we would otherwise getinto overloading conflicts.Also add Buffer#readableBytes() and Buffer#setAllocator().",1
[FLINK-8395][network] add a read-only sliced ByteBuf implementation based on NetworkBufferThis closes #5288.,1
"[hotfix][tests] separate tests inside SlotCountExceedingParallelismTestThis way, in case of failures, we may have better pointers on what test code iscurrently executed.",3
[hotfix][network][tests] remove Mockito mocks in RecordWriterTest,3
[FLINK-7518][network] pass our own NetworkBuffer to nettyThis is using a composite buffer to assemble header+content and avoids anunnecessary buffer copy from our (Network)Buffer class backed by a MemorySegmentto Netty's ByteBuf class.This closes #4615.,1
[FLINK-7925] [checkpoints] Add CheckpointingOptionsThe CheckpointingOptions consolidate all checkpointing and state backend-relatedsettings that were previously split across different classes.,1
[hotfix] [core] Fix broken JavaDoc links in ConfigConstants,5
[FLINK-5823] [checkpoints] Pass state backend to checkpoint coordinator,4
"[FLINK-5823] [checkpoints] State backends define checkpoint and savepoint directories, improved configuration",5
[hotfix] [rocksdb] Clean up RocksDB state backend code  - arrange variables to properly express configuration (client side) versus runtime (task manager side)  - make all runtime-only fields properly transient  - fix confusing variable name for local directories,5
[FLINK-5823] [checkpoints] Make RocksDB state backend configurable,5
[FLINK-5823] [checkpoints] State backends now also handle the checkpoint metadata,5
[hotfix] [core] Move 'ThrowingConsumer' and 'RunnableWithException' to proper package (.util.function)This also adds missing stability annotations to the functional interfaces in 'util.function'.,1
[hotfix] [core] Fix checkstyle for 'flink-core' : 'org.apache.flink.util',2
[hotfix] [core] Fix checkstyle for 'flink-core' : 'org.apache.flink.configuration',5
[FLINK-7938] Introduce addAll() to ListStateThis closes #5281.,1
[FLINK-8156] [build] Bump commons-beanutils version to 1.9.3This closes #5113,2
[hotfix] [tests] Add unit tests for ChildFirstClassLoader,3
"[FLINK-8455] [core] Make 'org.apache.hadoop.' a 'parent-first' classloading pattern.This change avoid duplication of Hadoop classes between the Flink runtime and the user code.Hadoop (and transitively its dependencies) should be part of the application class loader.The user code classloader is allowed to duplicate transitive dependencies, but not Hadoop'sclasses directly.This also adds tests to validate parent-first classloading patterns.",5
[FLINK-8461] [build] Adjust logger configurations for shaded Netty classnames,5
[FLINK-8355] [table] Remove DataSetAggregateWithNullValuesRule.This closes #5320.,5
[FLINK-6590][docs] Integrate configuration docs generatorThis closes #5119.,2
[FLINK-8325] [table] Fix COUNT(*) and COUNT(1).This closes #5241.,0
[hotfix] [REST] Fix WebMonitorEndpoint that missing parameters while initializing handlersThis closes #5322.,0
[hotfix][docs] Put HADOOP_CONF_DIR in <code> tagThis closes #5315,5
[FLINK-7719] [checkpoints] Send checkpoint id to task as part of deployment descriptor when resuming,2
[FLINK-7720] [checkpoints] Centralize creation of backends and state related resourcesThis closes #4745.,1
[FLINK-8463] [rest] Remove blocking of IO executor in RestClient#submitRequestInstead of waiting on the ChannelFuture we register a ChannelFutureListener whichis notified when the channel has been established. This unblocks IO executor threadsin the RestClient.This closes #5319.,4
[hotfix] Add not null check to message headers in AbstractRestHandler,0
[FLINK-8462] [flip6] Filter invalid heartbeat timeouts in TaskExecutorThis commit properly stops the heartbeating of disconnected RMs and additionallyignores outdated heartbeat timeouts for old RM connections out.This closes #5318.,5
[FLINK-7511] [cep] Remove dead code after dropping backward compatibility with <=1.2This closes #4587,4
[FLINK-8441] [State Backend] [RocksDB] change RocksDBListState to serialize values and separators in stream to avoid extra bytes copyingThis closes #5323.,5
[FLINK-8365] Relax List type in HeapListState and HeapKeyedStateBackendThis closes #5326.,2
[FLINK-8411] [State Backend] HeapListState#add(null) will wipe out entire list stateThis closes #5300.,1
[FLINK-8469] Unify RocksDB params in RocksDBPerformanceTestThis closes #5325.,5
[hotfix] [tests] Small simplification in 'CheckedThread'.,3
[FLINK-8499] [core] Force Kryo to be parent-first loaded.,1
"[hotfix] [build] Fix diverging snappy versions.This removes the snappy dependency from flink-core, which is no longer needed since we donot have an Avro dependency in flink-core any more.",2
[FLINK-6892] [table] Add L/RPAD support in SQLThis closes #4127.,1
[FLINK-6892] [table] Add LPAD/RPAD to Table API,1
[FLINK-8473][webUI] Improve error behavior of JarListHandlerThis closes #5331.,0
[FLINK-8079][tests] Stop end-to-end test execution after first failureThis closes #5156.,0
[FLINK-8433] [doc] Remove ununsed CheckpointedRestoring interfaceThis closes #5298.,4
[hotfix] [build] Print cache infoPrint the size of the Maven cache copied for each TravisCI job.This closes #5279.,5
[FLINK-8361] [build] Remove create_release_files.shThe monolithic create_release_files.sh does not support building withoutHadoop and has been superseded by the scripts in tools/releasing.This closes #5291.,1
"[hotfix] [build] Converge Kryo dependencyPreviously, the Kryo dependency was diverging between the flink-core dependencyand the chill dependency.[INFO] +- org.apache.flink:flink-java:jar:1.4.0:compile[INFO] |  +- org.apache.flink:flink-core:jar:1.4.0:compile[INFO] |  |  +- com.esotericsoftware.kryo:kryo:jar:2.24.0:compile....[INFO] +- org.apache.flink:flink-streaming-java_2.11:jar:1.4.0:compile[INFO] |  +- (org.apache.flink:flink-core:jar:1.4.0:compile - omitted forduplicate)[INFO] |  +- org.apache.flink:flink-runtime_2.11:jar:1.4.0:compile[INFO] |  |  +- com.twitter:chill_2.11:jar:0.7.4:compile[INFO] |  |  |  +- com.twitter:chill-java:jar:0.7.4:compile[INFO] |  |  |  |  \- (com.esotericsoftware.kryo:kryo:jar:2.21:compile -omitted for conflict with 2.24.0)[INFO] |  |  |  \- (com.esotericsoftware.kryo:kryo:jar:2.21:compile -omitted for conflict with 2.24.0)",5
"[FLINK-8466] [runtime] Make sure ErrorInfo references no user-defined classes.That way, holding on to the ErrorInfo does not prevent class unloading.However, this implies that the ErrorInfo must not hold strong references to any Exception classes.For that reason, the commit pull the ""ground truth"" exception into a separate fields, so that theExecutionGraph logic itself can always assume to have the proper ground-truth exception.This closes #5348",2
[FLINK-8406] [bucketing sink] Fix proper access of Hadoop File SystemsThis closes #5330,5
[FLINK-8146][py] Properly close ZipInputStreamThis closes #5349.,2
[FLINK-8485] [client] Unblock JobSubmissionClientActor#tryToSubmitJobThe JobSubmissionClientActor blocked a ActorSystem's dispatcher thread when requestingthe BlobServer port from the cluster. This fails when using the FlinkMiniCluster on asingle core machine because we set the number of threads to 1.This commit unblocks the JobSubmissionClientActor#tryToSubmitJob method and sets thelower limit of dispatcher threads to 2 when using the FlinkMiniCluster.This closes #5359.,5
[FLINK-8224] [flip6] Shutdown application when job terminated in job modeThis closes #5139.,2
[FLINK-8266] Add network memory to ResourceProfile for input/output memory of a taskThis closes #5170.,2
[hotfix] Reorder imports in ResourceProfile according to checkstyle,2
[hotfix] [qs] Combine logging statements in QueryableStateUtils#createKvStateServer,1
[FLINK-7858][flip6] Port JobVertexTaskManagersHandler to REST endpointThis closes #5149.,0
[FLINK-7858][flip6] Return with HTTP 404 if job or jobvertex are unknownAnnotate AccessExecutionGraph#getJobVertex(JobVertexID) with @Nullable.Throw NotFoundException in JobVertexTaskManagersHandler if jobvertexId is unknown.Throw NotFoundException in AbstractExecutionGraphHandler if jobId is unknown.Copy Javadoc from legacy JobVertexTaskManagersHandler.,0
[FLINK-7934] [table] Upgrade to Calcite 1.15This closes #5355.,2
[FLINK-7934] [table] Clean up and add more EXTRACT tests,3
[FLINK-8449] [flip6] Extend OnCompletionActions to accept an SerializableExecutionGraphThis commit changes the OnCompletionActions interface such that it accepts anArchivedExecutionGraph instead of a plain JobResult. This allows toarchive the completed ExecutionGraph for further usage in the containercomponent of the JobMasterRunner.This closes #5308.,1
[hotfix] [tests] Let BucketingSink extend TestLogger,3
"[FLINK-8450] [flip6] Make JobMaster/DispatcherGateway#requestJob type safeLet JobMasterGateway#requestJob and DispatcherGateway#requestJob return aCompletableFuture<ArchivedExecutionGraph> instead of aCompletableFuture<AccessExecutionGraph>. In order to support the old codeand the JobManagerGateway implementation we have to keep the return typein RestfulGateway. Once the old code has been removed, we should changethis as well.This closes #5309.",4
"[FLINK-8453] [flip6] Add ArchivedExecutionGraphStore to DispatcherThe ArchivedExecutionGraphStore is responsible for storing completed jobsfor historic job requests (e.g. from the web ui or from the client). The storeis populated by the Dispatcher once a job has terminated.The FileArchivedExecutionGraphStore implementation persists allArchivedExecutionGraphs on disk in order to avoid OOM problems. It only keepssome of the stored graphs in memory until it reaches a configurable size. Oncecoming close to this size, it will evict the elements and only reload them ifrequested again. Additionally, the FileArchivedExecutionGraphStore definesan expiration time after which the execution graphs will be removed from disk.This prevents excessive use of disk resources.This closes #5310.",1
"[FLINK-8454] [flip6] Remove JobExecutionResultCache from DispatcherWith the introduction of the ArchivedExecutionGraphStore to the Dispatcher,it is no longer necessary to store the JobResult separately. In order todecrease complexity and state duplication, this commit removes theJobExecutionResultCache and instead uses the ArchivedExecutionGraphStoreto serve completed job information. A side effect of this change is that theJobExecutionResult is now available as long as the completed Flink job is storedin the ArchivedExecutionGraphStore.This closes #5311.",2
[FLINK-8490] Allow custom docker parameters for docker tasks on MesosThis closes #5346.,2
[hotfix] Fix typo in AbstractCustomCommandLine Javadoc,2
[hotfix] Fix checkstyle violations in ZooKeeperUtils,0
[hotfix] Fix checkstyle violations in ZooKeeperLeaderElectionService,0
[hotfix] Simplify log message format,2
[hotfix] Unify argument validation in RestClusterClient,5
[hotfix] Fix wrong Javadoc in RestServerEndpointgetRestAddress() returns a String instead of a CompletableFuture,1
[hotfix] Do not schedule timeout when future is already  completed,0
[hotfix] Remove redundant variable,4
[FLINK-8344][flip6] Retrieve leading WebMonitor in RestClusterClientMake WebMonitorEndpoint instances participate in leader election.Use leading instance's base url to issue HTTP request from RestClusterClient.Make polling of JobExecutionResults and savepoints fault tolerant.[FLINK-8344][flip6] Add TestLogger to unit tests[FLINK-8344][flip6] Update RestOptionsDeclare timeouts and delays as long datatype.Add descriptions to ConfigOptions.[FLINK-8344][flip6] Rename methods in RestClusterClientRename waitForSavepointCompletion to pollSavepointAsync.Rename waitForResource to pollResourceAsync.This closes #5312.,5
[hotfix] Modify the classification of partitioner in StreamingJobGraphGenerator#connectThis closes #5358.,0
[hotfix] improve javadoc and logging of RocksDBKeyedStateBackendThis closes #5366.,5
[hotfix][docs] Fix Scala code example in Controlling Latency sectionThis closes #5299.,0
[FLINK-8465] [flip6] Retrieve correct leader component address in ClusterClientRename ClusterClient#getJobManagerAddress into #getClusterConnectionInfo. Thereturned LeaderConnectionInfo contains the address of the leading clustercomponent. In the old code this is the JobManager whereas in Flip-6 it is theDispatcher.This closes #5321.,1
[FLINK-8432] Add support for openstack's swift filesystemThis closes #5296.,5
"[FLINK-8505] [flip6] Prevent SlotManager from reaching an inconsistent stateThe SlotManager could reach an inconsistent state when a formerly free slot is reportedto be allocated by an incoming SlotReport. This state transition did not remove the slotfrom the set of free slots. As a consequence, a now allocated slot will be considered forfuture SlotRequests. This caused a failure with an IllegalStateException.The problem is solved by removing an updated slot which is now allocated from the set offree slots.This closes #5354.",1
"[FLINK-8488] [flip6] Fix Dispatcher job recovery bugInstead of only accepting job submissions if the RunningJobRegistry signalsthat the job's JobSchedulingStatus is PENDING, the Dispatcher now also acceptsif the job's JobSchedulingStatus is RUNNING. Only if the job is marked asDONE, it will be rejected.This closes #5363.",1
"[FLINK-8431] Allow to specify # GPUs for TaskManager in Mesos[FLINK-8431] Upgrade Fenzo dependency to 0.10.1[FLINK-8431] Simplify scalar aggregation[FLINK-8431] Offer::getScalarValues need not contain entries for cpus, mem, disk, and network[FLINK-8431] Floor # gpus to make sure whole numbersThis closes #5307.",1
[FLINK-7736] Fix some lgtm.com alertsThis closes #4784.,0
"[hotfix][config][docs] Rename ""Default Value"" column to ""Default""",5
[FLINK-8130][docs] Fix snapshot javadoc linkThis closes #5379.,2
"[FLINK-8524] Fix TypeExtractor.getBinaryReturnType JavaDocThe JavaDoc stated that the parameter `lambdaOutputTypeArgumentIndices` was atable of indices of the type argument specifying the input type, where itactually is a table of indices of the type argument specifying the outputtype. This is now fixed.This closes #5382.",0
[FLINK-6464][streaming] Stabilize default window operator namesThis closes #5332.,1
[FLINK-6623][Blob] BlobServer#putBuffer moves file after stream is closedThis closes #5351.,2
"[FLINK-5659] [core] Prevent concurrent FileUtils.deleteDirectory() under WindowsThis serializes these types of cleanup calls under Windows, to work around thefact that Windows exhibits unpredictable behavior under concurretn file/directorydelete operations. That in turn causes nasty exception stack traces on shutdownoperations where components like I/O manager and Blob Server concurrently cleanup their directories, which may overlap in some subdirectories.",4
[FLINK-8476][config][HA] Deprecate HA config constantsThis closes #5338.,5
[FLINK-8494][config] Migrate CC#DEFAULT_PARALLELISM_KEYThis closes #5377.,5
[hotfix] Rearrange TaskExecutor imports,2
[FLINK-8504] [flip6] Deregister jobs from the JobLeaderService when no more slots allocatedLet the TaskExecutor deregister jobs from the JobLeaderService once it has no more slotsfor this job allocated.This closes #5361.,2
[FLINK-8475][config][docs] Integrate akka optionsThis closes #5384.,5
[Flink-8407] [DataStream] Setting the parallelism after a partitioning operation should be forbidden,1
[FLINK-8240] [table] Create unified interfaces to configure and instatiate TableSourcesThis closes #5240.,5
[hotfix] [table] Fix IndexOOBE in DataStreamSortRule.This closes #5370.,5
[FLINK-8492] [table] Improve cost estimation for CalcsThis closes #5347.,1
[FLINK-8489][ES] Prevent side-effects when modifying user-configThis closes #5378.This closes #4847.This closes #5305.This closes #5208.This closes #2192.This closes #2422.This closes #3478.,5
[FLINK-8422] [core] Checkstyle for org.apache.flink.api.java.tupleUpdate TupleGenerator for Flink's checkstyle and rebuild Tuple andTupleBuilder classes.This closes #5292.,2
"[FLINK-8496][metrics] Create missing ""Network"" groupThis closes #5343.",1
"[FLINK-8230] [orc] Fix NPEs when reading nested columns.- fixes NPEs for null-valued structs, lists, and maps- fixes NPEs for repeating structs, lists, and maps- adds test for deeply nested data with nulls- adds test for columns with repeating valuesThis closes #5373.",3
[hotfix] [bin] Adjust the comments and inactive options in 'flink-conf.yaml' to reflect latest config options,5
[hotfix] [bin] Reorder sections in flink-conf.yaml to reflect common use of options.,1
[hotfix] [checkpointing] Cleanup: Fix Nullability and names in checkpoint stats.,0
[hotfix] [tests] Drop obsolete CheckpointExternalResumeTest.Because all checkpoints are now externalized (write their metadata) this is an obsolete test.,3
"[hotfix] [checkpoints] Clean up CompletedCheckpoint, grouping related methods together",1
[hotfix] [checkpoints] Drop ill-defined hashCode() and equals() from CompletedCheckpoint.,4
[hotfix] [tests] Clean up HeapKeyedStateBackendAsyncByDefaultTest,3
[FLINK-8531] [checkpoints] (part 1) Pull CheckpointType into its own class.,2
[FLINK-8531] [checkpoints] (part 2) Add CheckpointType to CheckpointProperties,1
[FLINK-8531] [checkpoints] (part 3) Rework ExternalizedCheckpointITCase,1
[FLINK-8531] [checkpoints] (part 4) rename forCheckpoint() to forCheckpointWithDefaultLocation(),2
[FLINK-8531] [checkpoints] (part 5) Introduce CheckpointStorageLocationReference instead of String to communicate the location,2
[FLINK-8531] [checkpoints] (part 6) Tasks resolve CheckpointStreamFactory from CheckpointStorage and Checkpoint Location Reference to persist checkpoint data.,5
[FLINK-8531] [checkpoints] (part 7) Move tests specific to Checkpoint Storage and Checkpoint Stream to separate tests suites,3
[FLINK-8531] [checkpoints] (part 8) Add tests for the FsCheckpointStorage and MemoryBackendCheckpointStorage.,3
[FLINK-8531] [checkpoints] (part 9) Introduce EXCLUSIVE and SHARED scope for states,2
[hotfix] [runtime] Fix checkstyle for 'runtime/io/network/api'.,1
"[FLINK-8539] [checkpointing] (part 1) Introduce CompletedCheckpointStorageLocation to properly handle disposal of checkpoints.That concept allows us to properly handle deletion of a checkpoint storage, for example deleting checkpointdirectories, or the dropping of a checkpoint specific table.This replaces the current workaround for file systems, where every file disposal checks if the parentdirectory is now empty, and deletes it if that is the case. That is not only inefficient, butprohibitively expensive on some systems, like Amazon S3.",5
[FLINK-8539] [checkpointing] (part 2) Modify all tests to use CompletedCheckpointStorageLocation.,1
[FLINK-8539] [checkpointing] (part 3) Rename FixFileFsStateOutputStream to FsCheckpointMetadataOutputStreamThe new name captures the proper use and meaning of the class in a better way.,1
"[FLINK-8540] [checkpointing] FileStateHandles no longer attempt to clean up their parent directory.Performing directory contents checks and cleaning up the parent directory in the state handle disposalhas previously led to excessive file system metadata requests, which especially on systems likeAmazon S3 is prohibitively expensive.",5
[hotfix] Fix some typos in flink-conf.yaml comments.,5
[hotfix][cep] Remove migration from 1.5 testThis closes #5398,3
[hotfix] Simplify computation in KeyGroupRangeAssignment::computeKeyGroupRangeForOperatorIndex,1
[FLINK-4812][metrics] Expose currentLowWatermark for all operators,1
[FLINK-8384] [streaming] Dynamic Gap Session Window Assigner,2
[FLINK-8243] [orc] OrcTableSource reads input path recursively by default.This closes #5344.,2
[FLINK-8242] [orc] Fix predicate translation if literal is not Serializable.This closes #5345.,0
[FLINK-8242] [table] RexProgramExtractor only translates literals of known types.,4
[hotfix] [cep] SharedBuffer refactoring.,4
[FLINK-8561] [cep] Fix SharedBuffer.removeEdges to use .equals().This closes #5414.,1
[FLINK-7923] [table] Support accessing fields of arrays of composite typesThis closes #5367.,1
[FLINK-8555] [table] Fix TableFunction varargs length exceed 254This closes #5409.,1
[FLINK-8555] [table] Simplify function operand checkers and inference,5
[FLINK-8471] [flip6] Introduce configuration switch for Flip-6Add 'mode' configuration parameter which enables and disables the Flip-6code paths. Per default this is set to the old code path.This closes #5334.,1
[FLINK-8493] [flip6] Integrate queryable state with Flip-6Adapt KvStateRegistry to accept multiple KvStateRegistryListeners. Introducethe KvStateLocationOracle to retrieve the KvStateLocation. Adapt the KvStateClientProxyto accept multiple KvStateLocationOracles to retrieve the KvStateLocations fordifferent jobs. Registered the KvStateRegistryListener and KvStateLocationOraclein TaskExecutor upon establishing a connection to the JobMaster.This closes #5339.,1
[FLINK-8495] [flip6] Enable main cluster component's log and stdout file retrievalThis commit enables the log and stdout file retrieval of the cluster's main componentvia the web ui. This happens via the StaticFileServerHandler which serves the logand stdout file.This closes #5341.,2
"[FLINK-8501] [flip6] Use single BlobCacheService per TaskExecutorInstead of creating for each new JobManagerConnection a dedicated BlobCacheServicethe TaskExecutor uses a single BlobCacheService which it shares between thedifferent JobManagerConnections. The initial BlobServer address is passed by theResourceManager when the TaskExecutor registers at it. In order to avoid the re-creation of BlobCacheServices, this commit changes the behaviour such that one canupdate the BlobServer address.This closes #5350.",1
"[hotfix] [tests] Remove JobManagerRunnerMockTestThe JobManagerRunnerMockTest is completely ignored. Moreover, it tests things withheavy usage of Mockito which is hard to maintain.",3
"[FLINK-8502] [flip6] Remove LibraryCacheManager from JobMasterThis commit removes the LibraryCacheManager from the JobMaster since it isno longer needed. The JobMaster is started with the correct user code classloader and, thus, does not need the LibraryCacheManager.This commit also corrects that the BlobServer is not closed by theJobManagerServices#shutdown method.This closes #5352.",1
"[FLINK-8503] [flip6] Display TaskExecutor logs and stdout files in web uiIntroduce the AbstractHandler which takes a typed request and returns an untypedresponse. The AbstractRestHandler extends the AbstractHandler to add typed reponses.Introduce AbstractTaskManagerFileHandler which encapsulates the file loading logic.Upon request of a TaskManager file, the handler will trigger the file upload viathe ResourceManager. The returned TransientBlobKey is then downloaded via theTransientBlobService. Once downloaded, the file is served to the client. Eachtransient blob key is cached for maximum duration after which it is purged and hasto be reuploaded by the TaskExecutor.This closes #5353.",2
[hotfix] Return NOT_FOUND in TaskManagerDetailsHandler  if TaskExecutor unknown,0
[FLINK-7856][flip6] Port JobVertexBackPressureHandler to REST endpoint,0
[FLINK-7856][flip6] Port JobVertexBackPressureHandler to REST endpointThis closes #5397.,0
[hotfix][tests] Add Javadocs to JobMasterTestAdd Javadocs to JobMasterTest.Remove debug print.,0
[hotfix] Log swallowed exception in JobMaster,1
"[FLINK-8398] [kinesis, tests] Cleanup confusing implementations in KinesisDataFetcherTest and related classesThe previous implementation of the TestableKinesisDataFetcher wasconfusing in various ways, causing it hard to be re-used for othertests. This commit contains the following various cleaups:- Remove confusing mocks of source context and checkpoint lock. We now  allow users of the TestableKinesisDataFetcher to provide a source  context, which should provide the checkpoint lock.- Remove override of emitRecordAndUpdateState(). Strictly speaking, that  method should be final. It was previously overriden to allow  verifying how many records were output by the fetcher. That  verification would be better implemented within a mock source context.- Properly parameterize the output type for the  TestableKinesisDataFetcher.- Remove use of PowerMockito in KinesisDataFetcherTest.- Use CheckedThreads to properly capture any exceptions in fetcher /  consumer threads in unit tests.- Use assertEquals / assertNull instead of assertTrue where-ever  appropriate.",3
"[FLINK-8398] [kinesis, tests] Stabilize flaky KinesisDataFetcherTestsPrior to this commit, several unit tests in KinesisDataFetcherTestrelied on sleeps to wait until a certain operation happens, in order forthe test to pass.This commit removes those sleeps and replaces the test behaviours withOneShotLatches.This closes #5268.",3
"[FLINK-6004] [kinesis] Allow FlinkKinesisConsumer to skip recordsThis commit acknowledges that null can be returned from thedeserialization schema, if the message cannot be deserialized. If nullis returned for a Kinesis record, no output is produced for that record,while the sequence number in the shard state is still advanced so thatthe record is effectively accounted as processed.This closes #5269.",2
[FLINK-8409] [kafka] Fix offset committing race condition in KafkaConsumerThreadThis closes #5329.,1
[hotfix] [kafka] Make AbortedReassignmentException a static class,1
"[FLINK-8419] [kafka] Move consumer metric group registration to FlinkKafkaConsumerBaseThis commit is a refactor to move the registration of the consumermetric group (user scope ""KafkaConsumer"") to FlinkKafkaConsumerBase.Previously, the registration was scattered around in Kafkaversion-specific subclasses.",2
[FLINK-8419] [kafka] Register metrics for dynamically discovered Kafka partitionsThis closes #5335.,2
[hotfix] [kafka] Fix inapproriate access modifiers in AbstractFetcher,0
[FLINK-8022][kafka-tests] Disable at-least-once tests for Kafka 0.9For some reasons this test is sometimes failing in Kafka09 while the same code works in Kafka010.Disabling this test because everything indicates those failures might be caused by unfixed bugsin Kafka 0.9 branchThis closes #5316.,0
[hotfix][connectors] Fix log format stringsFixes three occurrences of using '%s' instead of '{}' in loggingstatements.This closes #5380.,2
[FLINK-8484] [kinesis] Synchronize local shard metainfo's on restoreEnsure that a metainfo change in the StreamShardMetadata other than`StreamShardMetadata.shardId` or `StreamShardMetadata.streamName` doesnot result in the shard not being able to be restored. This handles thecorner case where a shard might have been closed (ending sequence numberset to not-null) since the last savepoint or checkpoint when a job isrestarted from a snapshot state.,1
"[hotfix] [kinesis, test] Use real test classes instead of Mockito in FlinkKinesisConsumerMigrationTest",3
[FLINK-8484] [kinesis] Use an equivalence wrapper around restored StreamShardMetadatas to bypass out-of-sync shard infosThis closes #5337.,5
"[hotfix] [kinesis] Use ArrayList for faster shard state updatesPreviously, the Kinesis Consumer uses LinkedLists as the underlyingimplementation for subscribedShardsState. This list is accessed on everyrecord, updating a shard's state using a shard state index (i.e., theorder of the shard state in the list). With LinkedLists, this access haslinear time complexity, and since this operation happens per record, canhave a big performance hit on executions with a huge number of Kinesisshards.This commit changes the list implementation to be an ArrayList forconstant-time shard state access. The downside is that when new shardsare discovered, there will be a costly array re-size. However, sinceresharding is not expected to happen so often, this is acceptable.",1
"[FLINK-8472] [DataStream, test] Extend WindowOperatorMigrationTest for Flink 1.4",2
"[FLINK-8472] [scala, test] Extend StatefulJobSavepointMigrationITCase for Flink 1.4",2
"[FLINK-8472] [DataStream, test] Refactor StatefulJobSavepointFrom*MigrationITCase to single ITCaseThis commit refactors the StatefulJobSavepointFrom12MigrationITCase andStatefulJobSavepointFrom13MigrationITCase to a single class,StatefulJobSavepointMigrationITCase. The new ITCase is parameterized toensure that all previous versions and state backend variants arecovered.",2
"[FLINK-8472] [DataStream, test] Extend StatefulJobSavepointMigrationITCase for Flink 1.4",2
"[FLINK-8472] [kinesis, test] Extend FlinkKinesisConsumerMigrationTest for Flink 1.4",2
"[FLINK-8472] [kafka, test] Extend FlinkKafkaConsumerBaseMigrationTest for Flink 1.4",2
"[FLINK-8472] [fs, test] Extend ContinuousFileProcessingMigrationTest for Flink 1.4",2
"[FLINK-8472] [fs, test] Extend BucketingSinkMigrationTest for Flink 1.4",2
[FLINK-8472] [tests] Extend AbstractOperatorRestoreTestBases for Flink 1.4This closes #5364.,2
"[hotfix] [test] Remove stale savepoint files no longer used by migration testsThis includes:- Removing MigrationVersion.v1_1, since compatilbity for 1.1 is no  longer supported (and no migration tests still test that)- Remove all 1.1 test savepoint files (which no migration tests still  use)- Remove all 1.2 test savepoint files that are no longer in use (e.g.,  CEPMigrationTest does not test 1.2 restores anymore)",3
"[FLINK-8421] [DataStream, tests] Add WindowOperator migration test for Kryo-serialized window keys",3
[FLINK-8421] [core] Allow InstantiationUtil.deserializeObject() to use FailureTolerantObjectInputStreamThis makes it possible to use the FailureTolerantObjectInputStream inInstantiationUtil.deserializeObject. This behaviour is controlled via aisFailureTolerant flag argument. All previous calls to the methodremains to have identical behaviour (the ClassloaderObjectInputStream).,0
[FLINK-8421] [core] Introduce PostVersionedIOReadableWritable,2
"[FLINK-8421] [DataStream] Make timer serializers reconfigurable on restorePreviously, the key and namespace serializers for theHeapInternalTimerService were not reconfigured on restore to be compatiblewith previously written serializers.This caused an immediate error to restore savepoints in Flink 1.4.0,since in Flink 1.4.0 we changed the base registrations in the Kryoserializer. That change requires serializer reconfiguration.This commit fixes this by writing also the serializer configurationsnapshots of the key and namespace serializer into savepoints, and usethem to reconfigure the new serializers on rrestore. This improvement alsocomes along with making the written data for timer service snapshotsversioned. Backwards compatibility with previous non-versioned formatsis not broken.",5
"[FLINK-8421] [test] Increase MAX_MEM_STATE_SIZE and Akka framesize in AbstractEventTimeWindowCheckpointingITCaseAfter adding the TypeSerializerConfigSnapshots of timer serializers tothe timers snapshots, the size of the timer snapshots have potentiallydoubled. This caused the AbstractEventTimeWindowCheckpointingITCase tobe failing, because the configured max memory state size and Akkaframesize were too small. This commit doubles those sizes.This closes #5362.",5
"[FLINK-8275] [security, yarn] Fix keytab local path in YarnTaskManagerRunner",1
"[FLINK-8275] [security, yarn] Remove test-specific code path in YarnTaskManagerRunnerPreviously, the YarnTaskManagerRunner contained a code path that existsfor the sole purpose of injecting mock runners. Having code paths justto utilize tests in production code is in general a bad idea.This commit fixes this be making YarnTaskManagerRunner a factory-likeclass, which creates a Runner that contains all the runners properties,such as configuration. Unit tests can than test against the containedconfiguration in the created Runner to validate that everything isconfigured properly.This closes #5172.",5
[hotfix][docs] Fix typosThis closes #5406.,2
[hotfix][build] Fix duplicate maven enforce plugin declarationThis closes #5407.,1
[hotfix][docs] Fix typos in window documentThis closes #5408.,2
[FLINK-8550][table] Iterate over entryset instead of keysThis closes #5404.,1
[FLINK-8559][RocksDB] Release resources if snapshot operation failsThis closes #5412.,0
[FLINK-7608][metrics] Rework latency metricThis closes #5161.,1
[FLINK-7803][docs] Add missing savepoint informationThis fixes FLINK-7803 by emphasizing the savepoint save location should be on a distributed file-system.This cloes #4809.,5
[FLINK-8565][tests] Ensure locationBytes.length > 0This closes #5417.,3
[hotfix][tests] Fix compiler warning in MetricFetcherTest,3
[hotfix][metrics] Restrict visiblity of testing methods in Slf4jReporter,3
[FLINK-8522] [checkpoint] Remove number of states from checkpoint.,4
[FLINK-4940] Add broadcast state to the OperatorStateBackend.,1
[FLINK-3659] Expose broadcast state on DataStream API.,5
[FLINK-8345] Add iterator of keyed state on broadcast side of connected streams.,1
[FLINK-8446] Support multiple broadcast states.,1
[hotfix] Create BroadcastITCase.,1
[FLINK-8595] [table] Include table source factory services in flink-table jar,2
"[FLINK-7760] Fix deserialization of NFA state in CEP libraryBefore, the condition was being read via in.read() and notin.readFully()",0
[FLINK-8575][runtime] Add missing synchronization in BackPressureStatsTrackerOperations in method getOperatorBackPressureStats must appear atomic otherwisethe stack trace can be sampled multiple times.,1
[FLINK-8575][runtime] Add missing synchronization in BackPressureStatsTrackerMake triggerStackTraceSampleInternal private again and add locking totriggerStackTraceSample.This closes #5422.,1
[FLINK-8362][elasticsearch] shade all dependencies,2
[FLINK-8362] [elasticsearch] Further improvements for Elasticsearch connector shading- Do not shade Elasticsearch dependencies- Do not shade Flink Elasticseach Connector classes- Also shade log4j-api dependency in Elasticsearch 5 connector. This is  required for the log4j-to-slf4j bridge adapter to work properly.- Add NOTICE files for license statements for all ES connectorsThis closes #5426.This closes #5243.,2
[FLINK-8456] Add Scala API for Connected Streams with Broadcast State.,1
[FLINK-8597] Add examples for Connected Streams with Broadcast State.This closes #5425.,1
[hotfix] Move DataStreamUtils to the datastream API package so that we can actually use it to expose package-private constructors or methods for experimental features.,1
[FLINK-8571] [DataStream] Introduce utility function that reinterprets a data stream as keyed streamThis closes #5424.,5
"[FLINK-7124] [flip6] Add test to verify rescaling JobGraphs works correctlyThis commit adds two tests to verify behaviours of rescaling JobGraphs:1. JobGraphs can be consecutively rescaled to arbitrary valid DOPs2. Rescaling beyond max parallelism would failThe second test, however, is temporarily disabled for now since itdoesn't properly fail.This closes #4510.",0
[FLINK-7124] [flip6] Introduce parallelism <= max parallelism check into ExecutionJobVertexCheck that the parallelism is smaller than the max parallelism when creating anExecutionJobVertex.,1
[hotfix] Refactor graph verification code in ExecutionGraphConstructionTestThe refactoring resuses utility methods in ExecutionGraphTestUtils toverify constructed ExecutionGraphs.,3
[FLINK-8617] [table] Fix code generation bug while accessing Map typeThis closes #5438.,0
[FLINK-8636] [flip6] Use TaskManagerServices to pass in services to TaskExecutorPass in the TaskExecutor services via the TaskManagerServices insteadof individually.This closes #5456.,4
[hotfix] Simplify TaskExecutorTest to avoid Mockito,3
[hotfix][kafka-tests] Do not hide original exception in FlinkKafkaProducer011ITCaseThis closes #5383.,2
[FLINK-7871] [flip6] SlotPool should release unused slots to RMThis closes #5048.,1
[FLINK-7871] [flip6] Add ManualClock for SlotPool slot release tests,3
[FLINK-8475][config][docs] Integrate Algorithm optionsThis closes #5460.,5
[FLINK-8475][config][docs] Integrate Mesos optionsThis closes #5461.,5
[FLINK-8475][config][docs] Integrate netty optionsThis closes #5386.,5
[FLINK-8475][config][docs] Integrate optimizer optionsThis closes #5387.,5
[FLINK-8475][config][docs] Integrate REST optionsThis closes #5389.,5
[FLINK-8475][config][docs] Integrate SlotManager optionsThis closes #5390.,5
[FLINK-8475][config][docs] Integrate BlobServer optionsThis closes #5391.,5
[FLINK-8475][config][docs] Integrate JM optionsThis closes #5392.,5
[FLINK-8475][config][docs] Integrate Checkpointing optionsThis closes #5464.,5
[FLINK-8475][config][docs] Integrate SSL optionsThis closes #5385.,5
[FLINK-8626] Introduce BackPressureStatsTracker interfaceRenames BackPressureStatsTracker into BackPressureStatsTrackerImpl and introducea BackPressureStatsTracker interface. This will make testing easier when we don'thave to set up all the different components.This closes #5443.,1
[FLINK-8637] [flip6] Use JobManagerSharedServices to pass in services to JobMasterPass a JobManagerSharedServices instance to the JobMaster instead of theeach service individually.This closes #5457.,4
[FLINK-8423] OperatorChain#pushToOperator catch block may fail with NPEThis closes #5447.,0
[FLINK-8475][config][docs] Integrate HA-ZK optionsThis closes #5462.,5
[FLINK-8475][config][docs] Integrate YARN optionsThis closes #5463.,5
[FLINK-8642] Initialize descriptors before use at getBroadcastState().,1
[hotfix] Clean broadcast functions when translating.This closes #5477.,1
[FLINK-8475][config][docs] Integrate FS optionsThis closes #5459.,5
[FLINK-8475][config][docs] Integrate HA optionsThis closes #5467.,5
[FLINK-8475][config][docs] Integrate Environment optionsThis closes #5468.,5
[FLINK-8475][config][docs] Integrate RM optionsThis closes #5470.,5
[FLINK-8475][config][docs] Integrate TM optionsThis closes #5471.,5
[FLINK-8475][config][docs] Integrate Core optionsThis closes #5469.,5
[FLINK-8576][QS] Reduce verbosity when classes can't be foundThis closes #5420.,2
[FLINK-8553][metrics][datadog] Switch to async modeThis closes #5418.,5
[hotfix] Remove costly checkState() statements from CEP SharedBuffer,5
[FLINK-7658] [table] Add Collect aggregate function to Table API.This closes #5472.,1
[FLINK-8652] [QS] Reduce log level in getKvState to DEBUG.This closes #5489.,0
[hotfix] Remove unused imports from SharedBuffer,5
[FLINK-8529] [flip6] Let Yarn entry points use APPLICATION_MASTER_PORTLet all Yarn entry points use the YarnConfigOptions.APPLICATION_MASTER_PORT optionto specify the valid port range for the common RpcService.This closes #5388.,5
[FLINK-8603] [flip6] Split submitJob into job submission and execution result retrievalSplit RestClusterClient#submitJob into submitJob and requestJobResult which canbe called individually.This closes #5428.,2
[hotfix] Change shutdown order in WebMonitorEndpoint to avoid illegal state,4
[FLINK-8604] [rest] Move JobTerminationHandler into WebMonitorEndpointRegister the JobTerminationHandler at the WebMonitorEndpoint to make it accessible toall REST endpoints.This closes #5429.,1
"[FLINK-8605] [rest] Enable job cancellation from the web UIIn order to support the job cancellation from the web UI, including when usingYarn, we have to register the JobTerminationHandler under /jobs/:jobid/yarn-canceland /jobs/:jobid/yarn-stop. This is just a temporary fix until we can sendarbitrary REST verbs through the Yarn proxy.This closes #5430.",0
"[FLINK-8608] [flip6] Implement MiniDispatcher for job modeThe MiniDispatcher is responsible for submitting the single job with whicha job mode cluster is started. Once the job has completed and if the clusterhas been started in detached mode, the MiniDispatcher will terminate.In order to reduce code duplication, the MiniDispatcher is a sub class of theDispatcher which is started with a single job submitted job graph store.This closes #5431.",5
"[FLINK-8609] [flip6] Enable Flip-6 job mode in CliFrontendThis commit allows to deploy detached job mode clusters via theCliFrontend. In order to do that, it first extracts the JobGraphfrom the PackagedProgram and then uses the ClusterDescriptor todeploy the job mode cluster.This closes #5432.",1
"[FLINK-8613] [flip6] [yarn] Return excess containersUpon notification of newly allocated containers, the YarnResourceManagerwill only accept as many containers as there are pending container requests.All excess containers will be returned.This closes #5436.",1
[FLINK-8212] [network] Pull EnvironmentInformation out of TaskManagerServicesThis closes #5458.,5
[FLINK-7713][flip6] Implement JarUploadHandlerThis closes #5442.,0
"[FLINK-8530] [flip6] Enable detached job mode submission to session clusterThis commit makes the RestClusterClient aware whether the user wishes to submita job in detached or non-detached mode. If it is detached, then the RestClusterClientwon't poll for the execution result.This closes #5466.",1
"[FLINK-8644] [flip6] Shut down AkkaRpcActors with PoisonPillShutting AkkaRpcActors down with Kill can result in uncompleted futures, ifthe mailbox contains requests which will be dropped. Therefore, it is betterto stop AkkaRpcActors with a PoisonPill which assures that all messages beforethe pill will be processed.This closes #5476.",1
"[FLINK-8643] [flip6] Use JobManagerOptions#SLOT_REQUEST_TIMEOUT in ExecutionGraphThis commit changes the initialization of the ExecutionGraph to use theJobManagerOptions#SLOT_REQUEST_TIMEOUT for the slot allocation. Furthermore,it changes the behaviour of the SlotPool#ProviderAndOwner implementation suchthat the timeout is given to it via the SlotProvider#allocateSlot call.This closes #5475.",1
[hotfix] [flip6] Remove unnecessary timeout from SlotPool,4
"[FLINK-8308] Remove explicit yajl-ruby dependency, update Jekyll to 3+",5
[FLINK-8303] Add hawkins back to Gemfile,2
[FLINK-8303] [docs] Allow to overwrite ruby/gem binaryThis closes #5395.,1
[FLINK-8397] [cassandra] Add CassandraRowOutputFormat.This closes #5272.,1
[FLINK-8401] [cassandra] Add callback methods for failed and successful writes to CassandraOutputFormatBase.This closes #5274.,0
[FLINK-8647] [flip6] Introduce JobMasterConfigurationThis commit introduces a JobMasterConfiguration which contains JobMaster specificconfiguration settings.This closes #5478.,1
"[FLINK-8610] [flip6] Remove RestfulGateway from JobMasterGatewayThe JobMaster no longer needs to implement the RestfulGateway. Therefore,it is removed by this commit.This closes #5433.",4
[hotfix] Fix checkstyle violations in JobExecutionResult,0
[FLINK-8611] [flip6] Add result future to JobManagerRunnerThis commit adds a CompletableFuture<ArchivedExecutionGraph> to theJobManagerRunner. This future will be completed once the job hasreached a globally terminal state.This closes #5434.,1
[FLINK-8516] [kinesis] Allow for custom hash function for shard to subtask mapping in Kinesis consumerThis closes #5393.,1
[FLINK-8630] [formats] Add proper support for JSON formatsThis closes #5491.,5
[FLINK-8520][cassandra] Fix race conditionThis closes #5474.,0
[FLINK-5728] [kafka] Let FlinkKafkaProducers flush on checkpoints by default,2
[FLINK-3655] [core] Add support for multiple file paths for FileInputFormat.,2
"[FLINK-3655] [core] Add support for multiple file paths for FileInputFormat.- Reverted API-breaking changes.- Enable multi-path support for the following InputFormats:  - AvroInputFormat,  - [Pojo,Row,Tuple]CsvInputFormat,  - OrcInputFormat,  - TextInputFormat,  - TextValueInputFormat",1
[FLINK-7456][network] Implement Netty sender incoming pipeline for credit-basedThis closes #4552.,2
[hotfix] Add the switch for keeping both the old mode and the new credit-based mode,2
[FLINK-8425][network] fix SpilledSubpartitionView not protected against concurrent release callsThis closes #5314.,0
[FLINK-8671][docs] Word-wrap default valuesThis closes #5506.,2
[FLINK-8475][config][docs] Integrate HeartbeatManager optionsThis closes #5507.,5
[FLINK-8676] Ensure key stream is closed after backend#applyToAllKeys().This closes #5513.,2
[hotfix][config][docs] Remove leading space from descriptions,4
[FLINK-8411] Don't allow null in ListState.add()/addAll(),1
[FLINK-8607] [table] Add a basic embedded SQL CLI clientThis closes #5441.,1
[FLINK-7711][flip6] Implement JarListHandlerThis closes #5209.This closes #5455.,0
[FLINK-8612] [flip6] Enable non-detached job modeThe non-detached job mode waits until has served the JobResult ofa completed job at least once before it terminates.This closes #5435.,0
[FLINK-7857][flip6] Port JobVertexDetailsHandler to REST endpoint,0
[FLINK-7857][flip6] Return status 404 if JobVertex is unknownThis closes #5493.This closes #5035.,2
[FLINK-8662] [tests] Harden FutureUtilsTest#testRetryWithDelayThis commit moves the start of the time measurement before the triggering ofthe retry with delay operation.This closes #5494.,1
[FLINK-5886][py] Add Python Streaming APIThis closes #3838.,1
[FLINK-5886][py] Various refactorings to Streaming APIThis closes #5333.Changelog:General:- rebase branch to current master- incremented version to 1.5-SNAPSHOT- removed kafka code- applied checkstyle- disabled method/parameter name rules for API classes- assigned flink-python-streaming to 'libraries' travis profile- copy streaming-python jar to /opt- change the name of the final jar to flink-streaming-python (previously flink-python)- replace maven-jar-plugin with maven-shade-pluginAPI:- PDS#map()/flat_map() now return PythonSingleOutputStreamOperator- renamed PDS#print() to PDS#output()- print is a keyword in python and thus not usable in native python APIs- added PythonSingleOutputStreamOperator#name()- removed env#execute methods that accepted local execution argument as they are redundant due to environment factory methods- narrow visibility of *DataStream constructorsMoved/Renamed:- made SerializerMap top-level class and renamed it to AdapterMap- Moved UtilityFunctions#adapt to AdapterMap class- renamed UtilityFunctions to InterpreterUtils- moved PythonobjectInputStream2 to SerializationUtils- renamed PythonObjectInputStream2 to SerialVersionOverridingPythonObjectInputStreamJython:- renamed InterpreterUtils#smartFunctionDeserialization to deserializeFunction- added generic return type to #deserializeFunction- #deserializeFunction uses static initialization flag to detect whether it has to load jython instead of waiting for exception to happen- removed file cleanup in #initAndExecPythonScript as it is the binders' responsibilityConnectors:- replaced usage of deprecated serialiation schema interfaces- P(S/D)Schema#(de)serialize now fails with RuntimeException if schema deserialization failsFunctions:- Introduced AbstractPythonUDF class for sharing RichRunction#open()/close() implementations- PythonOutputSelector now throws FlinkRuntimeException when failing during initialization- added generic return type to Serializationutils#deserializeObject- added new serializers for PyBoolean/-Float/-Integer/-Long/-String- PyObjectSerializer not properly fails when an exceptioin occurs- improved error printing- PythonCollector now typed to Object and properly converts non-PyObjects- jython functions that use a collector now have Object has output type- otherwise you would get ClassCastException if jython returns something that isn't a PyObjectPythonStreamBinder- adjusted to follow PythonPlanBinder structure- client-like main() exception handling- replaced Random usage with UUID.randomUIID()- now loads GlobalConfiguration- local/distributed tmp dir now configurable- introduced PythonOptions- no longer generate plan.py but instead import it directly via the PythonInterpreterEnvironment:- Reworked static environment factory methods from PythonStreamExecutionEnvironment into a PythonEnvironmentFactory- program main() method now accepts a PythonEnvironmentFactory- directories are now passed properly to the environment instead of using static fields- removed PythonEnvironmentConfig. #registerJythonSerializers now staticExamples:- move examples to flink-streaming-python- change examples location in dist to examples/python/streaming- replace ParameterTool usage with argparse- pass arguments via run instead of constructor- remove 'if __name__ == '__main__':' block- remove exception wrapping around source/sink creation- add WordCount exampleTests:- removed 'if __name__ == '__main__':' blocks from tests since the condition is never fulfilled- removed python TestBase class- removed print statements from tests- standardized test job names- cleaned up PythonStreamBinderTest / made it more consistent with PythonPlanBinderTest- run_all_tests improvements- stop after first failure- print stacktrace on failure- no longer relies on dirname() to get cwd but uses the module file location instead- added log4j properties file- added end-to-end test,3
"[FLINK-8673] [flip6] Use JobManagerRunner#resultFuture for success and failure communicationThis commit removes the OnCompletionActions and FatalErrorHandler from theJobManagerRunner. Instead it communicates a successful job execution of thefailure case through the JobManagerRunner#resultFuture.Furthermore, this commit no longer allows the JobManagerRunner to shut down itself.All shut down logic must be triggered by the owner of the JobManagerRunner.This closes #5510.",1
[hotfix] [yarn] Write number of slots to configuration,5
[hotfix] [yarn] Remove unnecessary TaskManager configuration generation,5
[hotfix] Only log retrying exception on debug in RetryingRegistration,1
"[FLINK-8614] [flip6] Activate Flip-6 mode per defaultThis commit enables the Flip-6 mode per default. Additionally, it disablessome of the Yarn tests which no longer apply to Flip-6 (tests which wait fora number of started TM container without a job submission).This closes #5437.",3
[hotfix] Initialize FileSystem in TaskManagerRunner#main,1
"[FLINK-8653] [flip6] Remove internal slot request timeout from SlotPoolInstead of using the internal slot request timeout to time out pending slot requests,we use the timeout passed to SlotPool#allocateSlot to time out pending slot requests.This closes #5483.",4
[hotfix] [tests] Simplify JobMasterTest,3
"[FLINK-8546] [flip6] Respect savepoints and restore from latest checkpointsLet the JobMaster respect checkpoints and savepoints. The JobMaster will alwaystry to restore the latest checkpoint if there is one available. Next it will checkwhether savepoint restore settings have been set. If so, then it will try to restorethe savepoint. Only if these settings are not set, the job will be started fromscratch.This closes #5444.",1
[FLINK-8693][py] Remove redundant Intepreter initialization,5
[FLINK-8692][docs] Remove extra parenthesis in scala code samples,4
[FLINK-8549] [config] Move TimerServiceOptions into TaskManagerOptionsThis closes #5402,4
[FLINK-8548] [examples] Add state machine exampleThis adds an example of using a state machine for pattern validation.The example illustrates the use of state and the kafka connector.This closes #5401,1
"[hotfix] [core] Remove Java 8 related reflection from TypeExtractionUtils.The class previously used reflection to check for the existence of certain classes thatare only available in Java >= 8.With the switch to having Java 8 as the minimal Java version, these reflection tricksare no longer necessary and the code can be simplified.",5
[hotfix] [core] Add old checkpoint directory config key back for compatibility.,5
[FLINK-8680] [data stream api] Assign meaningful names to the sinks that print to std. out and std. err.,5
[FLINK-8681] [build] Remove 'planVisualizer.html' has moved notice,4
[FLINK-8682] [shell scripts] Make shell scripts work without SSH for local-only HA setups.This allows users to set up HA testing on a local machine with multiple JobManagerswithout configuring SSH keys.,5
[hotfix] [shell scripts] Use SSH-less fast path for both 'localhost' and '127.0.0.1',1
"[FLINK-8668] Remove ""hadoop classpath"" from config.shThis also removes usage of ""hdfs classpath"".",4
[hotfix][network] Invert if check in SpanningRecordSerializer to improve readability,1
[hotfix][tests] Do not hide original exception in Serialization tests,3
[hotfix][runtime] Drop one of the two clear methods in RecordSerializerThis simplifies an API a little bit,4
[hotfix][tests] Deduplicate code in LargeRecordsTestDeduplicated code was identical.,3
"[hotfix][test] Deduplicate code in LargeRecordsTest and SpanningRecordSerializationTestDedupilcated code was effectively identical, but implemented in a slightly different way.",3
[FLINK-8582][runtime] Introduce BufferConsumerBufferConsumer will be used in the future for reading partially writtenMemorySegments. On flushes instead of requesting new MemorySegment BufferConsumercode will allow to continue writting to partially filled up MemmorySegment.,1
[hotfix][test] Simplify RecordWriterTest,3
[hotfix][runtime] Refactor ResultPartition for cleaner recycle path,4
[hotfix][runtime] Fix recycleBuffer in ResultPartitionTest,3
[hotfix][runtime] Deduplicate code in PipelinedSubpartition,0
[hotfix][runtime] Deduplicate buffersInBacklog code in Pipelined and Spillable subtartitions,2
[hotfix][runtime-tests] Immediatelly fail test when one of the futures fails,0
[hotfix][runtime-tests] Deduplicate CollectingResultPartitionWriters classes,3
[hotfix][tests] Reduce mockito usage in StreamTaskTest,3
[FLINK-8590][runtime] Drop addBufferConsumerToAllSubpartitions method,5
[FLINK-8584] handle read-only buffers in deserializer,0
[FLINK-8583] Pass BufferConsumer to subpartitions,4
[hotfix][runtime] Simplify RecordWriter code,0
[hotfix][java-docs] Improve ResultSubpartition java doc,2
[hotfix][runtime] Simplify PipelinedSubpartitionnotifyBuffersAvailable is a quick call that doesn't need to be executed outside of the lock,0
[hotfix][runtime] Drop unused throws IOException,1
[FLINK-8586][tests] Clean up hard to maintain testsSpilledSubpartitionViewTest duplicates a lot of production logic (TestSubpartitionConsumer is aduplicated logic of LocalInputChannel and mix of CreditBasedSequenceNumberingViewReader with PartitionRequestQueue.Also it seems like most of the logic is covered by SpillableSubpartitionTest.,3
[hotfix][tests] Properly close StreamRecordWriter in network benchmarks,1
[hotfix][tests] Correctly set moreAvailable flag in StreamTestSingleInputGate and handle redundant data notifications,5
[FLINK-8587][runtime] Drop unused AdaptiveSpanningRecordDeserializer,1
[FLINK-8588][runtime] Handle sliced buffers in RecordDeserializer,0
"[FLINK-8589][runtime] Add polling method to InputGateThis is a preparation for changes in data notifications, which will not bethat strict as they are now.",5
[FLINK-8591][runtime] Pass unfinished bufferConsumers to subpartitions,5
[hotfix][benchmarks] Add network stack benchmarks for LocalInputChannels,1
[hotfix][tests] Properly clean up RescalingITCase and allow it to run in the loop,1
[hotfix][tests] Remove masking original exception in StreamTaskTimerTest,3
[FLINK-8582][runtime] Optimize BufferBuilder writesBy introducing #commit() method on critical path we reduce number of volatile writes from 2 down to 1.This improves network throughput by 20% and restores the orignal performance for high latency cases.This closes #5423.,1
[hotfix][runtime] Rename setNextBufferBuilder to continueWritingWithNextBufferBuilder,1
[FLINK-8657][documentation] Fix incorrect description for configuration of async snapshot for heap based backendThis closes #5490.,5
"[FLINK-8669] Add completeAll and runAfterwards(Async) to FutureUtilsFutureUtils#completeAll(Collection) takes a collection of futures and returnsa future which is completed after all of the given futures are completed. Thisalso includes exceptional completions. Potentially occurring exceptions arerecorded and combined into a single exception with which the resulting futureis completed.FutureUtils#runAfterwards takes a future and runs a given action after thecompletion of the given future. This also includes an exceptional completion.In this case, a potentially occurring exception as the result of the providedaction will be combined with the future's exception.This closes #5503.",1
[FLINK-8675] Add non-blocking shut down method to RestServerEndpointMake shut down method of RestServerEndpoint non blocking.This closes #5511.,1
[hotfix] Remove unused code in JarActionHandler,0
[FLINK-7715][flip6] Implement JarRunHandlerThis closes #5509.,0
"[FLINK-7715] [flip6] Introduce WebSubmissionExtension for web submission handlersIntroduce a WebMonitorExtension interface which can be used to dynamically loadweb monitor extensions. Web monitor extension provide channel inbound handlerswhich are added to the WebMonitorEndpoint. Furthermore, they offer a close andcloseAsync method to close their resources. That way they can be integrated inthe lifecycle of the WebMonitorEndpoint.",1
[hotfix] Harden SlotPoolRcpTest#testCancelSlotAllocationWithoutResourceManager,3
[FLINK-8695] [rocksdb] Move flink-statebackend-rocksdb from 'flink-contrib' to 'flink-state-backends'.This closes #5523,2
[FLINK-8600] Allow disabling truncate() check in BucketingSinkThe test was failing when using PrestoS3FileSystem because it doesn'tuse an absolute/qualified path.,1
[FLINK-8698] [flip6] Use Flip6LocalStreamEnvironment instead of LocalStreamEnvironment,1
[FLINK-8698] [flip6] Let LocalExecutor use Flip-6 MiniClusterThis closes #5524.,5
[FLINK-8709] [tests] Harden SlotPoolRpcTest.testCancelSlotAllocationWithoutResourceManager,3
[FLINK-8574][travis] Add timestamp to logging messagesThis closes #5419.,2
[FLINK-8621][prometheus][tests] Remove endpointIsUnavailableAfterReporterIsClosed()The test is inherently unstable as it will always fail if any otherserver is started on the port between the closing of the reporter andthe polling of metrics.This closes #5473.,0
"[hotfix][prometheus] Document internal usage of CollectorRegistry.defaultRegistryIt appeared as if the HTTPServer wasn't actually doing anything, but itinternally accessed the singleton registry that we also access toregister metrics.",1
[hotfix][prometheus][tests] Add utility for generating port ranges,1
[hotfix][docs] Update configuration docs,2
[FLINK-8709] [tests] Harden SlotPoolRpcTest.testCancelSlotAllocationWithoutResourceManager #2,3
[FLINK-8668] Document how to set HADOOP_CLASSPATH for Flink,2
[FLINK-8723] Remove existing broadcast state examples.This closes #5540.,4
[FLINK-8703][tests] Migrate tests to MiniClusterResource (batch #1)This closes #5535.,5
[FLINK-8713][tests] Ensure outdated mod time is smaller than minimumThis closes #5534.,5
[hotfix][table][tests] Set @Ignore description for RowCsvInputFormatTest#testParserCorrectnessThis closes #5413.,3
[hotfix][build] Set flink-shaded-jackson to providedThis closes #5539.,1
[hotfix] Fix various typosThis closes #5497.,2
[FLINK-8738] [build] Converge dependency versions for 'scala-lang' and for 'com.typesafe:config',5
"[FLINK-6489] [shell scripts] Remove local mode from Windows start-local.batInstead, this uses 'start' to start JobManager and TaskManager background processes.",1
[FLINK-8696] [shell scripts] Remove JobManager local mode from shell scripts,4
[FLINK-6489] [FLINK-8696] [docs] Update docs to use 'start-cluster.sh' instead of 'start-local.sh'(and likewise for 'start-cluster.bat' vs. 'start-local.bat'),1
"[hotfix] [shell scripts] Remove hostname from Windows log and out filesThe host names are added in the UNIX scripts to support flink setups where all nodes puttheir log files in a shared NFS folder, and hostnames are needed to avoid name collisions.The windows setup scripts do not need that kind of functionality.",1
[hotfix] [tests] Update port of Travis end-to-end tests to match temporary Flip-6 web UI port,3
[hotfix] [tests] Decrease verbosity of ent-to-end test cluster start checks,3
[FLINK-8705] [flip6] Add Flip-6 support to Remote(Stream)EnvironmentThis commit enables the Remote(Stream)Environment to submit jobs to a Flip-6based cluster. It achieves this by instantiating a RestClusterClient insteadof a StandaloneClusterClient.,0
"[FLINK-8705] [flip6] Add DispatcherRestEndpoint to MiniClusterIn order to properly support the RemoteEnvironment, the Flip-6 MiniClusterneeds a REST endpoint to receive requests from the RestClusterClient.This closes #5527.",5
[FLINK-8710] [YARN] AbstractYarnClusterDescriptor doesn't use pre-defined configs in Hadoop's YarnConfigurationThis closes #5522.,5
[FLINK-7712][flip6] Implement JarDeleteHandlerThis closes #5529.,4
[hotfix] Rename JarUploadMessageHeaders to JarUploadHeaders,0
[hotfix] Move JarListInfoTest to correct package,5
[FLINK-7714][flip6] Implement JarPlanHandlerThis closes #5533.,0
"[FLINK-8711] [yarn] Remove code which auto-magically changes slots per TMThe FlinkYarnSessionCli auto-magically amends the number of slots with which theTMs are started. This was thought as a convenience function. However, it breaks theexecution of jobs where we have multiple slot sharing groups. Therefore, this commitremoves this code.As a consequence, the user has to make sure that he specifies enough slots andcontainers for the pre Flip-6 code such that the number of total slots is greateror equal than the parallelism of the job.Remove FlinkYarnSessionCliTest#testNotEnoughTaskSlots since we removed auto magical slot amendmentThis closes #5532.",4
"[FLINK-8631] [rest] Add support for generic types to the RestClientThis commit allows the Restclient to receive generic response types. In orderto do this, the MessageHeaders contain now information about the generictype parameters of the response type.This closes #5450.",2
"[FLINK-8632] [flip6] Introduce generalized asynchronous operation handlersThe asynchronous operation handlers are the generalization of the SavepointHandlers.They consist of a Trigger- and a StatusHandler. The TriggerHandler is used to triggeran asynchronous operation. The handler stores the operation future and returns atrigger id. The trigger id can be used to query the status of the operation via theStatusHandler. Once the operation has completed, the StatusHandler will return theresult.This closes #5451.",0
[FLINK-8547][network] Implement CheckpointBarrierHandler not to spill data for exactly-onceThis closes #5400.,5
"[FLINK-8674][runtime] Improve performance of flushAlways in StreamRecordWriterReduce the number of data notifications in case of flushAlways = true. Instead of notifying all ofthe channels/subpartitions, notify only the one that has just been written to.This closes #5526.",5
[FLINK-8735] Rename StatefulJobSavepointMigrationITCaseThis is preparation for modifying a new ITCase to use modern statefeatures.,1
[FLINK-8735] Add new StatefulJobSavepointMigrationITCaseThis new test does not pretend to use legacy state but now instead usesthe more modern operator state varieties.The binary savepoints for this were generated on the release-1.4 branch.,1
[FLINK-8639][State Backends] Fix always need to seek multiple times when iterator RocksDBMapStateThis closes #5465.,5
"[FLINK-8732] [flip6] Cancel ongoing scheduling operationKeeps track of ongoing scheduling operations in the ExecutionGraph and cancelsthem in case of a concurrent cancel, suspend or fail call. This makes sure thatthe original cause for termination is maintained.This closes #5548.",1
[hotfix] Fix checkstyle violations in ExecutionGraph,0
"[FLINK-8627] Introduce new JobStatus#SUSPENDING to ExecutionGraphThe new JobStatus#SUSPENDING says that an ExecutionGraph has been suspended but itsclean up has not been done yet. Only after all Executions have been canceled, theExecutionGraph will enter the SUSPENDED state and complete the termination futureaccordingly.This closes #5445.",4
"[FLINK-8629] [flip6] Allow JobMaster to rescale jobsThis commit adds the functionality to rescale a job or parts of it tothe JobMaster. In order to rescale a job, the JobMaster does the following:1. Take a savepoint2. Create a rescaled ExecutionGraph from the JobGraph3. Initialize it with the taken savepoint4. Suspend the old ExecutionGraph5. Restart the new ExecutionGraph once the old ExecutionGraph has been suspendedThis closes #5446.",1
[FLINK-8633] [flip6] Expose rescaling of jobs via the DispatcherThis commit exposes the JobMaster#rescaleJob via the Dispatcher. This willallow it to call this functionality from a REST handler.This closes #5452.,0
[FLINK-8634] [rest] Introduce job rescaling REST handlerAdd rescaling REST handler as a sub class of theAbstractAsynchronousOperationHandlers.This closes #5451.,0
[FLINK-8635] [rest] Register rescaling handlers at web endpointThis closes #5454.,0
"[FLINK-8656] [flip6] Add modify CLI command to rescale Flink jobsJobs can now be rescaled by calling flink modify <JOB_ID> -p <PARALLELISM>.Internally, the CliFrontend will send the corresponding REST call and pollfor status updates.This closes #5487.",5
[FLINK-8679][State Backends] Ensure that RocksDBKeyedBackend.getKeys() filters keys by namespaceThis closes #5518.,5
[FLINK-8648] [kinesis] Allow for customization of emitRecordAndUpdateState in Kinesis connector.This closes #5480.,5
[FLINK-8754][flip6] Make TaskManagerInfo implement SerializableThis closes #5566.,5
[hotfix] [formats] Dependency and code clean-up,4
[hotfix] [sql-client] Use hard-coded Scala version,1
"[FLINK-8678] [flip6] Make RpcService shut down non blockingChanges the RpcService#stopService method to be non blocking. Insteadof waiting until the RpcService has stopped, it returns the terminationfuture which is completed once the RpcService has been completelyshutdown.This closes #5517.",4
[FLINK-8664] [rest] Change RpcEndpoint#TerminationFuture value type to VoidThis closes #5496.,4
[hotfix] Remove unused method MiniCluster#waitUntilTaskManagerRegistrationsComplete,5
[hotfix] Don't fail LeaderContender and Listener when closing EmbeddedLeaderService,0
[hotfix] Fix checkstyle violations in RpcEndpoint,0
[FLINK-8665] [rest] Let RpcEndpoint#postStop return completion futureThe RpcEndpoint#postStop method returns a CompletableFuture<Void> which iscompleted once all post stop actions have completed. The termination futureof the respective RpcEndpoint is only completed afterwards.This closes #5498.,2
"[FLINK-8670] Make MetricRegistryImpl#shutdown non blockingThis commit makes the MetricRegistryImpl#shutdown method non blocking. Insteadof waiting for the completion of the shutdown procedure, the method returns afuture which is completed once the metric registry has completed the shut down.This closes #5504.",1
[FLINK-8666] [test] Use testDispatcherConfig in MiniClusterUsing the AkkaUtils#testDispatcherConfig reduces the number of started threads.This effectively decreases the resource foot print of the MiniCluster.This closes #5499.,5
[FLINK-8677] [flip6] Make ClusterEntrypoint shut down non-blockingMakes the ClusterEntrypoint shut down method non-blocking. This also removesthe need to run the Dispatcher#terminationFuture callback in the commonFork-Join pool.This closes #5512.,1
[hotfix] Workaround for shut down deadlock of Netty < 4.0.33,1
"[FLINK-8746] [flip6] Allow rescaling of partially running jobsThis commit enables the rescaling of Flink jobs which are currently not fullydeployed. In such a case, Flink will use the last internal rescaling savepoint.If there is no such savepoint, then it will use the provided savepoint when thejob was submitted. In case that there is no savepoint at all, then it will restartthe job with vanilla state.This closes #5560.",1
[hotfix] Register job status listener for rescaled job,0
[FLINK-8138] [tests] Fix TaskAsyncCallTest#testSetsUserCodeClassLoaderThe problem was a race condition between the triggerCheckpoint and the waitloop which had as termination condition the number of received trigger checkpointmessages.,0
[hotfix] Don't use tmp directory for rescaling savepoints,1
"[FLINK-8748] [flip6] Cancel slot allocations for alternatively completed slot requestsIf a slot request is fulfilled with a different AllocatedSlot in the SlotPool,then we cancel the slot request sent to the ResourceManager.This closes #5561.",2
[hotfix] Avoid redundant slot release operations,0
[hotfix] Cancel pending slot request when SlotPool is suspended,0
[FLINK-8749] [flip6] Release slots when scheduling operation is canceledRelease slots when the scheduling operation is canceled in the ExecutionGraph.This closes #5562.,2
[hotfix] Improve code structure of JobMaster#rescaleOperators,1
[FLINK-8773] [flip6] Make JobManagerRunner shut down non blockingThe Dispatcher no longer shuts down the JobManagerRunner in a blocking fashion.Instead it registers the termination futures and calls the shut down of theJobManagerSharedServices once all JobManagerRunners have terminated.This closes #5575.,1
[FLINK-8774] [flip6] Make shut down of ResourceManagerRunner non blocking,1
[FLINK-8775] [flip6] Non blocking MiniCluster shut downThis closes #5576.,5
[hotfix] Introduce ShutdownHookUtil to avoid code duplication(Un)registering shotdown hooks for cleanups is a very common concern in Flink.Many places in the code essentially duplicate all the code for doing this.This commit introduces a utils class and deduplicates the code.,2
[hotfix] Remove some unecessary null checks in RocksDBKeyedStateBackend,5
[hotfix] Do not track completed checkpoint ids without incremental checkpointing,0
[hotfix] Remove outdated class OperatorStateHandles and replace it with OperatorSubtaskState,1
[hotfix] Rename OperatorSnapshotResult to OperatorSnapshotFutures.,1
[FLINK-8360][checkpointing] Implement state storage for local recovery and integrate with task lifecycle,2
[FLINK-8360][checkpointing] Implement file-based local recovery for FsStateBackendThis reverts commit 8925b7c,4
[FLINK-8360][checkpointing] Implement file-based local recovery for RocksDBStateBackend,5
[FLINK-8360][checkpointing] Documentation for local recoveryThis closes #5239.,2
"[hotfix] Suppress emitting non-causal exceptions from closed checkpointing threadThis avoids that an exception that is caused by closing a running snapshot is reported.With this we avoid that users get confused by their logs or that this exception could bereported before its actual cause, thus hiding the real cause in logs.",2
[FLINK-8699][checkpointing] Create deep copy of state meta data to avoid concurrency problem with checkpoints,0
"[hotfix] RocksDB make default column family firstAccording to the documentation of RocksDB, the default column family should always be created first.",1
"[hotfix] RocksDB improve resource cleanup (disposal order, dispose all WriteOptions)This commit ensures that all WriteOption objects are closed and that we do not create unessesaryWriteOption objects for each state.",1
[hotfix] Replace use of deprecated remove calls to RocksDB with delete,4
[hotfix] Update RocksDB version to 5.7.5,5
"[hotfix] Clear interrupted flag in stream task cancellationWe clear the interrupted flag before the cleanup code block of task cancellation.Otherwise, code that would like to wait until services are properly shutdown willalways immediately return from calls that are supposed to be blocking waits.",4
[FLINK-8776][flip6] Use correct port for job submission from Web UI.Use address of local WebMonitorEndpoint for the job submission from the Web UI.Rename TestingLeaderRetrievalService to SettableLeaderRetrievalService and moveclass out of test directory.This closes #5577.,3
[hotfix] Initialize webSubmissionHandlers list in WebSubmissionExtension with correct size.,0
[FLINK-8762] [quickstarts] Make 'StreamingJob' the default main class and remove WordCount example from the quickstart.The packaged example jobs have been reported to not be terribly helpful andsimply create noise in the initial project setup.,1
[hotfix] [quickstarts] Fix header and package declaration order.,0
[FLINK-8763] [quickstarts] Remove obsolete Dummy.java classes from quickstart projects.,4
[hotfix] [quickstarts] Fix block comments in program stubs.,0
"[FLINK-8764] [quickstarts] Make quickstarts work out of the box for IDE and JAR packaging  - All Flink and Scala dependencies are properly set to provided  - That way, Maven JAR packaging behaves correctly by default  - Eclipse adds 'provided' dependencies to the classpath when running programs, so works out of the box  - There is a profile that automatically activates in IntelliJ that adds the necessary    dependencies in 'compile' scope to make it run out of the box.",1
"[FLINK-8765] [quickstarts] Simplify quickstart propertiesThis does not pull out the slf4j and log4j version into properties any more,making the quickstarts a bit simpler.Given that both versions are used only once, and only for the feature to haveconvenience logging in the IDE, the versions might as well be defined directlyin the dependencies.",2
"[FLINK-8766] [quickstarts] Pin scala runtime version for Java QuickstartFollowup to FLINK-7414, which pinned the scala version for the Scala Quickstart",2
"[FLINK-8767] [quickstarts] Set the maven.compiler.source and .target properties for Java QuickstartSetting these properties helps properly pinning the Java version in IntelliJ.Without these properties, Java version keeps switching back to 1.5 in some setups.",1
[FLINK-8764] [docs] Adjust quickstart documentation,2
[FLINK-8781][scheduler] Try to reschedule failed tasks to previous allocationThis closes #5403.,0
"[FLINK-8741] [kafka] Fix incorrect user code classloader in FlinkKafkaConsumerThis commit fixes incorrectly using the parent of the user code classloader. Since Kafka 010 / 011 versions directly reuse 09 code, this fixfixes the issue for all versions.This commit also extends the Kafka010Example, so that is uses a customwatermark assigner. This allows our end-to-end tests to have caught thisbug.",0
[hotfix] [test] Make test-streaming-kafka010.sh more flexible for local execution,3
"[hotfix] [test] Also trap INT signal in Kafka end-to-end testThis allows the test to perform the cleanup procedure (as well asprinting any error logs) if an interruption occurred while waiting forthe test data to be written to Kafka, therefore increasing visibility ofreasons to why the test was stalling.This closes #5568.",3
[FLINK-8772] [kafka] Fix missing log parameterThis closes #5574.,2
[FLINK-8703][tests] Migrate tests to MiniClusterResource (batch #2)This closes #5542.,5
[FLINK-8596][CLI] Also catch NoClassDefFoundErrorsThis closes #5543.,0
"[FLINK-8645][configuration] Split classloader.parent-first-patterns into ""base"" and ""appendThis closes #5544.",5
[FLINK-8593][metrics] Update latency metric docsThis closes #5484.,2
"[FLINK-8543] Don't call super.close() in AvroKeyValueSinkWriterThe call to keyValueWriter.close() in AvroKeyValueSinkWriter.close()will eventually call flush() on the wrapped stream which fails if weclose it before(). Now we call flush ourselves before closing theKeyValyeWriter, which internally closes the wrapped stream eventually.",0
[FLINK-8733][network] fix SpillableSubpartition#spillFinishedBufferConsumers() not counting spilled bytesThis closes #5549.,3
[FLINK-8734][network] fix partition bytes counting and re-enable in testsThis closes #5550.,3
[hotfix][network] remove PowerMockRunner from RecordWriterTest,3
[hotfix][network] various minor improvements,1
[hotfix][network] initialize SingleInputGate#enqueuedInputChannelsWithData with the right size,5
[FLINK-8736][network] fix memory segment offsets for slices of slices being wrongThis closes #5551.,0
[FLINK-8719] Add module description for flink-contrib to clarify its purposeThis closes #5537.,1
[hotfix][tests] Remove unused variable,1
Update version to 1.6-SNAPSHOT,5
[hotfix] Improved logging for task local recovery,2
[hotfix] [core] Suppress unused warning config options only used in shell scripts and doc generation.,2
[FLINK-8798] [core] Make force 'commons-logging' to be parent-first loaded.,2
[FLINK-8538][table]Add a Kafka table source factory with JSON format support,1
[FLINK-8538] [table] Improve unified table sourcesThis closes #5564.,1
[FLINK-8791] [docs] Fix documentation about configuring dependenciesThis closes #5586,5
[FLINK-8787][flip6] Do not copy flinkConfiguration in AbstractYarnClusterDescriptorThis closes #5591.,5
[FLINK-8730][REST] JSON serialize entire SerializedThrowableDo not only serialize the serialized exception but the entireSerializedThrowable object. This makes it possible to throw theSerializedThrowable itself without deserializing it.This closes #5546.,1
[FLINK-8792] [rest] Change MessageQueryParameter.convertStringToValue to convertValueToStringThis closes #5587.,2
[FLINK-8792] [rest] Change MessageQueryParameter#convertValueFromString to convertStringToValue,2
[FLINK-8451] [serializers] Make Scala tuple serializer deserialization more failure tolerantThis closes #5567.,0
[FLINK-8777][checkpointing] Cleanup local state more eagerly in recoveryThis closes #5578.,4
[hotfix] Enable FILESYTEM_DEFAULT_OVERRIDE in FLIP-6 MiniClusterResource,5
[FLINK-8557][checkpointing] Remove illegal characters from operator description text before using it to construct the instance directory in RocksDBThis closes #5598.,5
[hotfix][tests] Deduplicate code in SingleInputGateTest,3
[hotfix][runtime] Remove duplicated check,4
"[FLINK-8760][runtime] Correctly propagate moreAvailable flag through SingleInputGatePreviously if we SingleInputGate was re-eqnqueuing an input channel, isMoreAvailablemight incorrectly return false. This might caused some dead locks.",1
[hotfix][tests] Do not hide original exception in SuccessAfterNetworkBuffersFailureITCase,0
[FLINK-8694][runtime] Fix notifyDataAvailable race conditionBefore there was a race condition that might resulted in igonoring some notifyDataAvailable calls.This fixes the problem by moving buffersAvailable handling to Supartitions and adds stress testfor flushAlways (without this fix this test is dead locking).,3
"[FLINK-8805][runtime] Optimize EvenSerializer.isEvent methodFor example, previously if the method was used to check for EndOfPartitionEventand the Buffer contained huge custom event, the even had to be deserialized beforeperforming the actual check. Now we are quickly entering the correct if/else branchand doing full costly deserialization only if we have to.Other calls to isEvent() then checking against EndOfPartitionEvent were not used.",1
"[FLINK-8750][runtime] Improve detection of no remaining data after EndOfPartitionEventBecause of race condition between:  1. releasing inputChannelsWithData lock in this method and reaching this place  2. empty data notification that re-enqueues a channelwe can end up with moreAvailable flag set to true, while we expect no more data.This commit detects such situation, makes a correct assertion and turn off moreAvailable flag.This closes #5588.",3
[FLINK-8747][bugfix] The tag of waiting for floating buffers in RemoteInputChannel should be updated properlyThis closes #5558.,5
[hotfix] Fix package private and comments,0
[hotfix][network] minor improvements in UnionInputGate,1
"[FLINK-8737][network] disallow creating a union of UnionInputGate instancesRecently, the pollNextBufferOrEvent() was added but not implemented but this isused in getNextBufferOrEvent() and thus any UnionInputGate containing a UnionInputGatewould have failed already. There should be no use case for wiring up inputsthis way. Therefore, fail early when trying to construct this.This closes #5583.",1
"[hotfix] [tests] Fix SelfConnectionITCaseThe test previously did not fail on failed execution, and thus evaluated incomplete resultsfrom a failed execution with th expected results.This cleans up serialization warnings and uses lambdas where possible, to make the codemore readable.",1
[hotfix] Add missing space to log message in ZooKeeperLeaderElectionService,2
[hotfix][Javadoc] Fix typo in YARN Utils: teh -> the,2
[hotfix][Javadoc] Fix typo in YarnTestBase: teh -> the,3
[hotfix][tests] Fix wrong assertEquals in YARNSessionCapacitySchedulerITCaseTest swapped actual and expected arguments.Remove catching Throwable in test; instead propagate all exceptions.,3
[FLINK-7805][flip6] Recover YARN containers after AM restart.Recover previously running containers after a restart of the ApplicationMaster.This is a port of a feature that was already implemented prior to FLIP-6.Extract RegisterApplicationMasterResponseReflector class into separate file.This closes #5597.,2
"[FLINK-4387][QS] don't wait and process requests at Netty servers after shutdown requestThere is a race condition on an assertion in Netty's event loop that may causetests to fail when finished early.This was fixed in 4.0.33.Final, see https://github.com/netty/netty/issues/4357.This closes #5606.",0
[hotfix] [formats] Make ObjectMapper final in JsonNodeDeserializationSchema,5
"[hotfix][build] Add missing shade-plugin execution id's2 metric modules weren't setting the execution id to ""shade-flink"" causing them to not pick up the default shade-plugin configuration.",5
[FLINK-8814] [file system sinks] Control over the extension of part files created by BucketingSink.,1
[FLINK-8810] Move end-to-end test scripts to end-to-end moduleThis also makes the tests executable by calling$ flink-end-to-end-tests/run-pre-commit-tests.sh,3
[FLINK-6352] [kafka] Support to set offset of Kafka with specific date,5
[FLINK-6352] [kafka] Further improvements for timestamped-based startup mode1) Eagerly deterrmin startup offsets when startup mode is TIMESTAMP2) Remove usage of java Date in API to specify timestamp3) Make tests more robust and flexible4) Add documentation for the featureThis closes #5282.,2
[FLINK-8808] [flip6] Allow RestClusterClient to connect to local dispatcherThe RestClusterClient resolves a dispatcher address without an explicit hostto 'localhost'. That way we allow the RestClusterClient to talk to a Dispatcherwhich runs in a local ActorSystem.This closes #5599.,5
[FLINK-8811] [flip6] Add initial implementation of the MiniClusterClientThe MiniClusterClient directly talks to the MiniCluster avoiding pollinglatencies of th RestClusterClient.This closes #5600.,5
[FLINK-8811] [flip6] Implement MiniClusterClient#getJobStatus,5
[FLINK-8811] [flip6] Implement MiniClusterClient#cancel,5
[hotfix] Introduce null checks for SlotManager#suspend,0
[hotfix] Let ClusterClient only shut down own HaServices,0
[hotfix] Unregister job from JobManagerRunner before completing the result future,1
[hotfix] Close ResourceManager LeaderRetrievalService in TaskExecutor,0
[hotfix] Correct shutdown order of RestClusterClient,0
[hotfix] Let AbstractEventTimeWindowCheckpointingITCase shutdown ZooKeeper after MiniCluster,5
[hotfix] Let JobLeaderService terminate leader retrieval services,0
[hotfix] Improve logging in ZooKeeper services,2
[FLINK-8821] [table] Fix non-terminating decimal errorThis closes #5608.,0
[FLINK-8842] Change the Rest default port to 8081This closes #5626.,4
[hotfix] Enable standalone HA mode by choosing HA port range,0
"[FLINK-8840] [yarn] Pull YarnClient and YarnConfiguration instantiation out of AbstractYarnClusterClientFor better testability, this commit moves the YarnClient and YarnConfiguration out ofthe AbstractYarnClusterDescriptor.",5
"[hotfix] [flip6] Harden JobMaster#triggerSavepointCheck first whether the CheckpointCoordinator has been set before triggeringa savepoint. If it has not been set, then return a failure message.",0
[FLINK-8826] [flip6] Start Yarn TaskExecutor with proper slots and memoryRead the default TaskManager memory and number of slots from the configurationwhen the YarnResourceManager is started.This closes #5625.,5
[hotfix] Set default number of TaskManagers in FlinkYarnSessionCli for Flip6,2
[hotfix] Print correct web monitor URL in FlinkYarnSessionCli,2
[FLINK-8459][flip6] Implement RestClusterClient.cancelWithSavepointIntroduce cancelJob flag to existing triggerSavepoint methods in Dispatcher andJobMaster. Stop checkpoint scheduler before taking savepoint to make sure thatthe savepoint created by this command is the last one.This closes #5622.,1
[FLINK-8758] Make non-blocking ClusterClient.submitJob() public,1
[FLINK-8700] Add getters to JobDetailsInfo,5
[FLINK-8700] Add ClusterClient.getJobStatus(),1
"[FLINK-8818][yarn/s3][tests] harden YarnFileStageTest upload test for eventual consistent read-after-writeIn case the newly written object cannot be read (yet), we do 4 more retries toretrieve the value and wait 50ms each. While this does not solve all the casesit should make the (rare) case of the written object not being available forread even more unlikely.This closes #5601.",1
"[FLINK-8769][flip6] do not print error causing exceptions without debuggingIn DispatcherRestEndpoint and TaskExecutor, there were two places where withouterrors (running a job inside an IDE) exceptions were logged. While for debuggingthey may be useful, for normal operation it is enough to print the messagesthemselves, especially since some more details were already logged before.This closes #5611.",2
[FLINK-8458][config][docs] Add config of credit-based network buffersThis closes #5317.,1
[FLINK-8859][checkpointing] RocksDB backend should pass WriteOption to Rocks.put() when restoringThis closes #5635.,4
[FLINK-8517] Fix missing synchronization in TaskEventDispatcherThis closes #5621.,0
"[FLINK-8807] Fix ZookeeperCompleted checkpoint store can get stuck in infinite loopBefore, CompletedCheckpoint did not have proper equals()/hashCode(),which meant that the fixpoint condition inZooKeeperCompletedCheckpointStore would never hold if at least oncheckpoint became unreadable.We now compare the interesting fields of the checkpoints manually andextended the test to properly create new CompletedCheckpoints. Before,we were reusing the same CompletedCheckpoint instances, meaning thatObjects.equals()/hashCode() would make the test succeed.",3
Fix checkstyle in ZooKeeperCompletedCheckpointStoreTest,3
[hotfix] Fix javadoc link in ClusterClient#triggerSavepointThis closes #5592.,2
[hotfix][REST] Fix CONTENT_TYPE headerThis closes #5590.,0
[hotfix][docs] Drop the incorrect parallel remark in windowAllThis closes #5607.,4
[hotfix][docs] Remove reference to CheckpointedRestoringThis closes #5627.,4
[FLINK-8857][hbase] Remove redundant execute() call in hbase exampleThis closes #5633.,4
[FLINK-8849][docs] Fix links to chaining docsThis closes #5630.,2
[FLINK-8560] Add KeyedProcessFunction exposing key in onTimer().This closes #5481.,1
[FLINK-8667] Expose key in KeyedBroadcastProcessFunction#onTimer()This closes #5500.,5
"[FLINK-8890] Compare checkpoints with order in CompletedCheckpoint.checkpointsMatch()This method is used, among other things, to check if a list of restoredcheckpoints is stable after several restore attempts in the ZooKeepercheckpoint store. The order of checkpoints is somewhat important becausewe want the latest checkpoint to stay the latest checkpoint.",3
"[FLINK-8827] [scripts] When FLINK_CONF_DIR contains spaces, ZooKeeper related scripts failThis closes #5614",0
[FLINK-8824] [kafka connector] Replace Class.getCanonicalName() with Class.getName()This closes #5620,1
[hotfix] [javadoc] Minor javadoc fix in TimestampAssigner.javaThis closes #5646Also close unrelated lingering pull request:This closes #5643,4
[FLINK-8877] [core] Set Kryo trace if Flink log level is TRACE,2
[FLINK-8878] [tests] Add BlockerSync utilityThis helps to synchronize two threads of which one is expected to blockwhile holding a resource.,1
[FLINK-8878] [core] Add concurrency check Kryo Serializer on DEBUG level,0
[FLINK-8879] [avro] Add concurrency check Avro Serializer on DEBUG level.,0
"[hotfix] [build] Change REST port to 8081 for end-to-end testing scriptsNow that the FLIP-6 code uses 8081, we need to probe that port to checkFlink's status in the end-to-end tests.",3
[FLINK-8839] [sql-client] Fix table source factory discoveryThis closes #5640.,0
[hotfix] [taskmanager] Fix checkstyle in Task and TaskTest,3
"[FLINK-8856] [TaskManager] Move all cancellation interrupt calls to TaskCanceller threadThis cleans up the code and guards against a JVM bug where 'interrupt()' callsblock/deadlock if the thread is engaged in certain I/O operations.In addition, this makes sure that the process really goes away when the cancellationtimeout expires, rather than relying on the TaskManager to be able to properly handlethe fatal error notification.",0
[FLINK-8883] [core] Make ThreadDeath a fatal error in ExceptionUtils,0
"[FLINK-8885] [TaskManager] DispatcherThreadFactory registers a fatal error exception handlerIn case dispatcher threads let an exception bubble out (do not handle the exception), theexception handler terminates the process, to ensure we don't leave broken processes.",0
"[hotfix] [runtime] Harden FatalExitExceptionHandlerIn case the logging framework throws an exception when handling the exception,we still kill the process, as intended.",1
[FLINK-8887][tests] Add single retry in MiniClusterClientThis closes #5657.,5
[hotfix][tests] Do not use singleActorSystem in LocalFlinkMiniClusterUsing a singleActorSystem rendered the returned client unusable.This closes #5652.,5
[FLINK-8889][tests] Do not override cluster config valuesThis closes #5651.,5
[FLINK-8860][flip6] stop SlotManager spamming logs for every TM heartbeat at log level 'info'This closes #5637.,5
[FLINK-8729][streaming] Refactor JSONGenerator to use jacksonThis closes #5554.,1
[FLINK-8860] Change slot-report message to DEBUG,0
[FLINK-8896] [kafka08] remove all cancel MARKERs before trying to find partition leadersThis guards us against #cancel() being called multiple times and then trying tolook up an invalid topic/partition pair.This closes #5661,1
[FLINK-8091] [scripts] Support running historyserver in foregroundThis closes #5642,1
[FLINK-8854] [table] Fix schema mapping with time attributesThis closes #5662.,3
[hotfix] [network] Rename RecordWriter#closeBufferConsumer() to closeBufferBuilder(),1
[hotfix] [network] Various minor improvements,1
[hotfix] [network] [tests] Make AwaitableBufferAvailablityListener thread-safeThis is called asynchronously by the spill writer and thus may needsynchronization on incrementing the counter but definately had visibilityissues with the counter. Using an AtomicLong fixes that.,0
[FLINK-8755] [network] Fix SpilledSubpartitionView relying on the backlog for determining whether more data is availableFix SpilledSubpartitionView#getNextBuffer() to not only rely on the backlog:instead it is sufficient to also return true if the next buffer is an eventsince either there is a real buffer enqueued (reflected by the backlog) or atleast one event.,2
"[FLINK-8786] [network] Fix SpillableSubpartitionView#getNextBuffer returning wrong isMoreAvailable when processing last in-memory bufferWhen processing the last in-memory buffer inSpillableSubpartitionView#getNextBuffer while the rest of the buffers arespilled, need to rely on the spilled view's isAvailable instead of alwayssetting the isMoreAvailable flag of the returned BufferAndBacklog to false.",5
[FLINK-8755] [FLINK-8786] [network] Add and improve subpartition tests+ also improve the subpartition tests in general to reduce some duplicationThis closes #5581,3
[FLINK-8800][REST] Reduce logging of all requests to TRACEThis closes #5594.,2
[FLINK-8847][build] Always generate .class files for package-info.javaThis closes #5644.,5
[hotfix][build] Enable incremental compilation,0
Add our own Deadline implementation,1
[FLINK-8758] Add FutureUtils.retrySuccessfulWithDelay()This retries getting a result until it matches a given predicate oruntil we run out of retries.,1
[FLINK-8797] Port AbstractOperatorRestoreTestBase to MiniClusterResource,5
[FLINK-8778] Port queryable state ITCases to use MiniClusterResource,5
[FLINK-8911] Add separate script for nightly end-to-end tests,3
[FLINK-8487] Verify ZooKeeper checkpoint store behaviour with ITCase,2
[FLINK-8274] [table] Split generated methods for preventing compiler exceptionsThis closes #5613.This closes #5174.,2
"[FLINK-8922] Revert ""[FLINK-8859][checkpointing] RocksDB backend should pass WriteOption to Rocks.put() when restoring""We need to revert FLINK-8859 because it causes problems with RocksDB that make our automated tests fail on Travis.The change looks actually good and it is currently unclear why this can introduce such a problem. This might also be a Rocks in RocksDB.Nevertheless, for the sake of a proper release testing, we should revert the change for now.",4
[hotfix][RAT] Add serializer snapshot to exclusions,1
[hotfix][tests] Strip CompletionExceptions in MiniClusterClient#guardWithSingleRetry,5
[hotfix] Don't mark Table API & SQL as 'beta' anymore,0
[FLINK-8687] [sql-client] Make MaterializedCollectStreamResult#retrievePage to have resultLockThis closes #5647.,1
[hotfix] [yarn] Improve logging of container resources,2
[FLINK-8927][checkpointing] Eagerly release the checkpoint object in RocksDB incremental snapshotsThis closes #5682.,5
[FLINK-8783] [tests] Harden SlotPoolRpcTestWait for releasing of timed out pending slot requests before checking thenumber of pending slots requests.This closes #5684.,3
[FLINK-8934] [flip6] Properly cancel slot requests of otherwisely fulfilled requestsCancel slot requests at the ResourceManager if they have been completed with a differentallocation.This closes #5687.,2
[FLINK-7521] Add config option to set the content length limit of REST server and client,1
[FLINK-7521][flip6] Remove RestServerEndpoint#MAX_REQUEST_SIZE_BYTES,4
[FLINK-7521][flip6] Return HTTP 413 if request limit is exceeded.Remove unnecessary PipelineErrorHandler from RestClient.Rename config keys for configuring request and response limits.Set response headers for all error responses.This closes #5685.,0
[FLINK-8850] [sql-client] Add support for event-time in SQL ClientThis closes #5683.,1
[FLINK-8832] [sql-client] Create a SQL Client Kafka 0.11 fat-jarThis closes #5673.,1
[FLINK-8916][REST] Write/read checkpointing mode enum in lower caseThis closes #5679.,1
[hotfix][docs][py] Fix class name in exampleThis closes #5692.,0
[hotfix][cli][tests] let CliFrontendRunTest extend from TestLogger,3
[FLINK-8904][cli][tests] Restore previous sysoutThis closes #5670.,5
[hotfix][javadocs] Update javadoc of InternalTimerService.registerEventTimeTimer()This closes #5677.,2
[FLINK-8703][tests] Port KafkaShortRetentionTestBase to MiniClusterResourceThis closes #5666.,5
[FLINK-8703][tests] Port NotSoMiniClusterIterations to MiniClusterResourceThis closes #5667.,5
[FLINK-8703][tests] Port StreamingScalabilityAndLatency to MiniClusterResourceThis closes #5668.,5
[FLINK-4569][tests] Respect exceptions thrown in thread in JobRetrievalITCaseThis closes #5689.,1
[FLINK-8888] [Kinesis Connectors] Update the AWS SDK for flink kinesis connectorThis closes #5663,2
[FLINK-8945] [kinesis] Allow customization of KinesisProxyThis closes #5698,1
"Revert ""[FLINK-7851] [scheduling] Improve scheduling balance by round robin distribution""This reverts commit d9c669d4781f095806013651c1a579eae0ca2650.",4
[FLINK-9016] [flip6] Properly unregister jobs from JobMetricGroupThis commit properly removes jobs from the JobMetricGroup once a jobhas reached a terminal state.,4
"[FLINK-8812] [flip6] Set managed memory for TaskExecutor to 80 MB in MiniClusterIn order to avoid problems with OOM exceptions, this commit sets the managedmemory to 80 MB for TaskExecutors started by the MiniCluster.This closes #5713.",5
[FLINK-7804][flip6] Run AMRMClientAsync callbacks in main threadThis closes #5675.,1
[hotfix][flip6] Only create new terminationFuture if MiniCluster is running,1
[FLINK-8843][REST] Decouple bind REST address from advertised addressBy default bind REST server on wildcard address.Rename RestServerEndpoint#getRestAddress to getRestBaseUrl.This closes #5707.,1
[FLINK-8894][REST] Set object codec for JsonGenerator used by CurrentJobIdsHandlerThis closes #5711.,0
[FLINK-8915] CheckpointingStatisticsHandler fails to return PendingCheckpointStatsThis closes #5703.,0
[FLINK-8905][rest][client] fix RestClusterClient#getMaxSlots() returning 0,5
[FLINK-8906][flip6][tests] also test Flip6DefaultCLI in org.apache.flink.client.cli testsThis closes #5671.,3
[FLINK-8948][runtime] Fix IllegalStateException when closing StreamTaskThis closes #5710.,0
[hotfix][javadocs] Minor javadoc fixesThis close s5696,0
[FLINK-8935][tests] Implement MiniClusterClient#listJobs,5
[FLINK-8935][tests] Implement MiniClusterClient#getAccumulators,5
[FLINK-8935][tests] Implement MiniClusterClient#triggerSavepoint,5
[FLINK-8935][tests] Implement MiniClusterClient#stopThis closes #5690.,5
[FLINK-8830][YARN] YarnResourceManager throws NullPointerException,2
[FLINK-8830] [yarn] Log reading of Hadoop's token fileThis closes #5629.,2
[FLINK-8942][runtime] Pass heartbeat target ResourceIDreceived payload field now volatileAdd HeartbeatMonitor#getHeartbeatTargetIdThis closes #5699.,1
[FLINK-9019] Unclosed closeableRegistry in StreamTaskStateInitializerImpl#rawOperatorStateInputsThis closes #5723.,5
"[FLINK-8801][yarn/s3] fix Utils#setupLocalResource() relying on consistent read-after-write""Amazon S3 provides read-after-write consistency for PUTS of new objects in yourS3 bucket in all regions with one caveat. The caveat is that if you make a HEADor GET request to the key name (to find if the object exists) before creatingthe object, Amazon S3 provides eventual consistency for read-after-write.""https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModelSome S3 file system implementations may actually execute such a request for theabout-to-write object and thus the read-after-write is only eventuallyconsistent. org.apache.flink.yarn.Utils#setupLocalResource() currently relies ona consistent read-after-write since it accesses the remote resource to get filesize and modification timestamp. Since there we have access to the localresource, we can use this metadata directly instead and circumvent the problem.This closes #5602.",0
[FLINK-8881][runtime] Send accumulator updates via heartbeats,5
[FLINK-8703][tests] Port SavepointMigrationTestBase to MiniClusterResourceThis closes #5701.,5
[hotfix] [core] Add @FunctionalInterface to KeySelectorThat clarifies that this interface should always be a SAM interfaceto allow that users created lambdas for its use.,1
[FLINK-9028] [yarn] Perform parameters checking before Yarn starting clusterThis closes #5726.,2
[FLINK-9028] [yarn] Improve failure message if cluster cannot be started,0
[FLINK-9022][state] Fix resource release in StreamTaskStateInitializerImpl.streamOperatorStateContext()This closes #5716.,5
[hotfix] [core] Fix checkstyle in 'org.apache.flink.api.common.state',2
[FLINK-8756][Client] Support ClusterClient.getAccumulators() in RestClusterClientThis closes #5573.,1
[FLINK-8073][kafka-tests] Disable timeout in testsTo get stacktraces in case of deadlock do not timeout tests programatically.This closes #5718.,3
[hotfix][kafka-tests] Clean up and drop unused field in KafkaProducerTestBase,3
"[FLINK-7343][kafka-tests] Fix test at-least-once test instabilityPreviously we could set numElementsBeforeSnapshot to some value during checkpointingAFTER executing shutdown, while at the same time FlinkKafkaProducerXXX snapshot for thisvalue would fail. This lead to incorrectly cacluated expected set of values to be presentin the test kafka topic.Fix is to remember lastSnapshotedElementBeforeShutdown - last snapshot that we expectto succeed without failure.This closes #5729.",0
"[FLINK-8984][network] Drop taskmanager.exactly-once.blocking.data.enabled config optionPreviously there were twe options:taskmanager.network.credit-based-flow-control.enabledandtaskmanager.exactly-once.blocking.data.enabledIf we disabled first one, but keept default value for the second one deadlocks will occur.By dropping taskmanager.exactly-once.blocking.data.enabled we can always use: - blocking BarrierBuffer for credit based flow control - spilling BarrierBuffer for non credit based flow control.This closes #5708.",2
[FLINK-9020][E2ETests] Use separate modules per testcaseThis closes #5717.,3
[FLINK-8649] [scala api] Pass on TypeInfo in StreamExecutionEnvironment.createInputThis closes #5478.,1
"Revert ""[FLINK-8703][tests] Port AutoParallelismITCase to flip6""The test does not actually run on Flip6, see FLINK-8813.",2
[FLINK-8925][tests] Enable flip6 on travis,0
"[FLINK-8903] [table] Fix VAR_SAMP, VAR_POP, STDEV_SAMP, STDEV_POP functions on GROUP BY windows.This closes #5706.",1
[hotfix] [core] Add missing serialVersionUID to MapStateDescriptor,1
[hotfix] [core] Demockitofy state descriptor tests,3
[hotfix] [core] Make State Descriptors consistently use Preconditions instead of Objects.,1
"[FLINK-9034] [core] StateDescriptor does not throw away TypeInformation upon serialization.Throwing away TypeInformation upon serialization was previously done because the typeinformation was not serializable. Now that it is serializable, we can (and should) keepit to provide consistent user experience, where all serializers respect the ExecutionConfig.",5
[hotfix] [core] Consolidate serializer duplication tests in StateDescriptorTest where possible,3
[FLINK-9035] [core] Fix state descriptor equals() and hashCode() handling,0
[FLINK-8562] [tests] Fix YARNSessionFIFOSecuredITCaseBefore the YARNSessionFIFOSecuredITCase also passed without Kerberos being active.This closes #5416.,4
[FLINK-8562] [tests] Introduce private global configuration to YarnTestBase,3
[hotfix] Remove unnecessary transient modifiers in CheckpointStatsTracker,4
[hotfix] Add generics to FutureUtils.toJava calls in ClusterClient,1
[FLINK-8919] [table] Add KeyedProcessFunctionWithCleanupState.This closes #5680.,4
[FLINK-8931] TASK_KILLING is not covered by match in TaskMonitor#whenUnhandledThis closes #5744.,0
[hotfix] Improve Flip-6 component logging,2
[FLINK-9047] Fix slot recycling in case of failed releaseIn case that a slot cannot be released it will only recycled/reused if the owningTaskExecutor is still registered at the SlotPool. If this is not the case then wedrop the slot from the SlotPool.This closes #5739.,4
[hotfix] Remove unused method from SlotPool,1
[hotfix] Make RestServerEndpoint#uploadDir protected,1
"[FLINK-9027] [web] Clean up web UI resources by installing shut down hookThe ClusterEntrypoint creates temp directory for the RestServerEndpoint. Thisdirectory contains the web ui files and if not differently configured the webupload directory. In case of a hard shut down, as it happens with bin/stop-cluster.shthe ClusterEntrypoint will clean up this directory by installing a shut down hook.All future directory cleanup tasks should go into this methodClusterEntrypoin#cleanupDirectories.This closes #5740.",4
[hotfix] Log final status and exit code under lock,2
[hotfix] Add FutureUtils#composeAfterwards,1
[FLINK-8900] [yarn] Properly unregister application from Yarn RMThis closes #5741.,2
[FLINK-8956][tests] Port RescalingITCase to flip6This closes #5715.,3
[FLINK-8959][tests] Port AccumulatorLiveITCase to flip6This closes #5719.,3
[FLINK-8957][tests] Port JMXJobManagerMetricTest to flip6This closes #5720.,3
[FLINK-8958][tests] Port TaskCancelAsyncProducerConsumerITCase to flip6This closes #5722.,3
[hotfix][utils] Add ExceptionUtils#findThrowable with predicate,1
[FLINK-8964][tests] Port JobSubmissionFailsITCase to flip6This closes #5727.,0
[FLINK-8965][tests] Port TimestampITCase to flip6This closes #5728.,3
[hotfix] [table] Add Java deprecation annotation to TableEnvironment.sql().,1
[FLINK-8975] [test] Add Kafka events generator job for StateMachineExample,1
[FLINK-8975] [test] Add resume from savepoint end-to-end testThis closes #5733.,3
[FLINK-8976] [test] Add end-to-end tests for resuming savepoint with differrent parallelismThis closes #5745.,3
[hotfix][runtime] Remove unused method,1
[hotfix][tests] Do not hide original exception in the tests,3
[hotfix][tests] Allow to run SpillableSubpartitionTests in the loop,3
"[FLINK-8721][flip6] Handle archiving failures for accumulatorsDuring archivization, wrap errors thrown by users' Accumulators into a OptionalFailureand do not fail the job because of that.This closes #5737.",1
[FLINK-8852] [sql-client] Add support for FLIP-6 in SQL ClientThis closes #5704.,1
[FLINK-8972] [e2eTests] Add DataSetAllroundTestProgram and e2e test script.,3
[FLINK-8972] [e2eTests] Remove IDE warnings and simplify pom.xmlThis closes #5752.,5
[FLINK-8833] [sql-client] Create a SQL Client JSON format fat-jarThis closes #5700.,5
[hotfix] [sql-client] Add flink-sql-client as 'provided' to flink-dist,2
"[FLINK-8789] Throw IllegalStateException when calling Task#stopExecution on not running TaskBefore we threw an UnsupportedOperationException when calling Task#stopExecution on a Taskwhere we did not set the invokable yet. This can be a bit misleading and, thus, this committhrows an IllegalStateException with an respective message.This closes #5753.",1
"[FLINK-8901] [yarn] Set proper Yarn application nameWhen deploying a session cluster, Flink will register under ""Flink session cluster"".When deploying a per-job cluster, Flink will register under ""Flink per-job cluster"".This closes #5754.",2
[hotfix] Remove unused applicationName parameter from FlinkYarnSessionCli#createDescriptor,2
[FLINK-5411] [flip6] Fix JobLeaderIdService shut down in ResourceManagerThe JobLeaderIdService was formerly closed at two different locations. Once in theResourceManager and once in the ResourceManagerRuntimeServices. Since the JobLeaderIdServiceis a RM specific component. It should also be closed in the scope of the RM.This closes #5757.,1
[FLINK-8940] [flip6] Add support for dispose savepointAdds an AsynchronousOperationHandler for disposing savepoints. The handler is registeredunder '/savepoint-disposal' and requires a SavepointDisposalRequest JSON object containingthe path to the savepoint to be disposed. The RestClusterClient polls the status registeredunder '/savepoint-disposal/:triggerId' until the operation has been completed.This closes #5764.,5
[hotfix] Improve logging in AkkaRpcActors,2
[hotfix] Poll invariant variables out of polling loop in RestClusterClient#rescaleJob,0
[hotfix] Add Assert.fail to RestClusterClientTest,3
[hotfix] Set RescalingHandlers timeout to RpcUtils.INF_TIMEOUT,5
[FLINK-9067] [e2eTests] Add StreamSQLTestProgram and test run script.,1
[FLINK-9067] [e2eTests] Fix test and simplify codeThis closes #5759.,3
[FLINK-9093] [docs] Ship jQuery library without external providerThis closes #5770.,1
[hotfix] [docs] Fix missing license header,0
[hotfix][tests] add a name to the parameter of RescalingITCase,2
"[FLINK-9057][network] fix an NPE when cleaning up before requesting a subpartition viewIn PartitionRequestServerHandler, the view reader was created and immediatelyafterwards added to the PartitionRequestQueue which would attempt a cleanup ofthe view reader's subpartition view. This view, however, was currently onlycreated after adding the reader to the PartitionRequestQueue and may thus resultin a NullPointerException if the cleanup happens very early in theinitialization phase, e.g. due to failures.This closes #5747.",0
[FLINK-8941][tests] use TestLogger and TemporaryFolder in SpanningRecordSerializationTest,3
"[FLINK-8941][serialization] make sure we use unique spilling filesAlthough the spilling files were chosen with random names of 20 bytes, it couldrarely happen that these collide. In that case, have another try (at most 10) atselecting a unique file name.This closes #5709.",2
[FLINK-8415] Unprotected access to recordsToSend in LongRecordWriterThread#shutdown()This closes #5724.,2
[hotfix] [test] Move resuming from savepoint e2e tests to nightly tests,3
[FLINK-9026] [flip6] Close the TaskManagerMetricGroup when the TaskExecutor is shut downThis closes #5734.,2
[FLINK-8740] [metrics] Create new JobManagerJobMetricGroup when creating a new ExecutionGraphThis closes #5755.,1
"[hotfix] Create ExecutionGraph when JobMaster is startedThe ExecutionGraph is not a final resource in the JobMaster. For example, it is necessaryto create a new ExecutionGraph when rescaling the job or when the JobMaster loses andregains its leadership.",1
[hotfix] Remove unused fields in JobMaster,1
[hotfix] Fix race condition in JobMaster#requestJobDetailsDo not directly access executionGraph in another thread because it might bealtered.,1
[hotfix] Remove cluttering comments from JobMaster,4
"[FLINK-9099] Assign Execution to LogicalSlot when slot is assigned to ExecutionIn order to fail fast if an allocated slot is released by the SlotPool, we assign theExecution as payload to a LogicalSlot when the slot is assigned to the Execution.This closes #5775.",2
"[FLINK-8887] Wait for JobMaster leader election in DispatcherBefore sending requests from the Dispatcher to the JobMasters, the Dispatcher mustwait until the respective JobMaster has gained leadership. Otherwise we might riskthat the messages are ignored because no fencing token was set.This is solved by letting the JobManagerRunner expose a CompletableFuture<JobMasterGateway>which is only completed after the JobMaster has gained leadership. The future is clearedonce the leadership is revoked.This closes #5767.",1
[FLINK-9063] Fix SpillableSubpartitionTest testSpillFinishedBufferConsumerstestSpillFinishedBufferConsumers was incorrectly manually closing the BufferConsumerafter passing it's ownership to the ResultSubpartition. This was leading to a raceconditions with AsynchronousBufferFileWriter.This closes #5765.,2
[hotfix] Extend TestingFatalErrorHandler to return an error future,0
[hotfix] Add BiFunctionWithException,1
"[FLINK-8943] [ha] Fail Dispatcher if jobs cannot be recovered from HA storeIn HA mode, the Dispatcher should fail if it cannot recover the persisted jobs. The ideais that another Dispatcher will be brought up and tries it again. This is better thansimply dropping the not recovered jobs.This closes #5746.",4
[FLINK-9081] [tests] Harden ResourceManagerJobMasterTest and ResourceManagerTaskExecutorTestset heartbeatTimeout=1000 in ResourceManagerJobMasterTest and ResourceManagerTaskExecutorTest.This closes #5783.,3
[hotfix] Guard against clock changes when computing the net runtime of a job,1
[FLINK-9031] [optimizer] Fix DataSet Union operator translation bug.- Adds a pass over the pre-optimized plan that fixes the output strategy of union nodes to FORWARD.This closes #5742,0
[FLINK-8813][flip6] Disallow PARALLELISM_AUTO_MAX for flip6This deprecates `org.apache.flink.api.common.ExecutionConfig#PARALLELISM_AUTO_MAX`This closes #5756.,5
[FLINK-9060][state] Fix concurrent modification exception when iterating keys.This closes #5751.,0
[FLINK-8708] [examples] Unintended integer division in StandaloneThreadedGeneratorThis closes #5776,2
[FLINK-8908] Do not create copy when MapSerializer stateless.,1
[FLINK-8928] [QS] Improve server binding error message.,0
[FLINK-8926] [QS] Shutdown client proxy after test ends.,3
[FLINK-8802] [QS] Fix concurrent access to non-duplicated serializers.This closes #5691.,0
[hotfix] Add FutureUtils.supplyAsync with SupplierWithException,1
"[FLINK-9106] [rpc] Add UnfencedMainThreadExecutor to FencedRpcEndpointThe UnfencedMainThreadExecutor executed Runnables in the main thread context withoutchecking the fencing token. This is important to set a new fencing token, for example.This closes #5784.",1
[hotfix] Re-introduce FatalErrorHandler to JobManagerRunner,1
[hotfix] Correct JavaDocs in SubmittedJobGraphStore and add Nullable annotation,1
"[FLINK-9097] Fail fatally if job submission fails when recovering jobsIn order to not drop jobs, we have to fail fatally if a job submission fails whenrecovering jobs. In HA mode, this will restart the Dispatcher and let it retryto recover all jobs.This closes #5774.",1
[hotfix] Recover jobs before setting fencing token,1
[FLINK-9121] [flip6] Remove Flip6 prefixes and other referencesRemove Flip6 prefixes and references to make Flip-6 the proper default:Rename categories Flip6 -> New and OldAndFlip6 -> LegacyAndNewRemove Flip-6 from documentationRemove Flip-6 from start up scriptsThis closes #5801.,4
[hotfix] Invert activation of new and legacy code by introducing -DlegacyCode flag,1
[hotfix] Add scheme to output path of test_streaming_sql e2e testThis commit disambiguates the local output in case that one has Hadoop set up.,1
[FLINK-8979] [test] Refactor Kafka-related common end-to-end test scripts,3
[FLINK-8979] [test] Include shuffles in Kafka end-to-end testsThis closes #5778.,3
[FLINK-8973] [E2E] HA end-to-end test with StateMachineExample.Adds an end-to-end test that runs the StateMachineExample on a localcluster with HA enabled. There is a single JM which gets killed andre-created and we check if the new JM picks up the job execution andif at the end the StateMachine has no ALERTs printed.This closes #5750.,1
[hotfix] Introduce NewClusterClient interfaceThe NewClusterClient interface contains asynchronous submitJob and requestJobResultmethods which will replace the ClusterClient#submitJob method.,1
[FLINK-9094] [tests] Harden AccumulatorLiveITCaseThe problem was that we did not wait for the proper shut down of the job beforeresetting the latches. This could lead to a deadlock.This closes #5771.,1
[FLINK-6567] [tests] Harden ExecutionGraphMetricsTestThe problem was that in some cases the currentRestartingTime would not increasebecause the iteration in the loop were too fast.This closes #5782.,1
[FLINK-9042][tests] Port ResumeCheckpointManuallyITCase to flip6This closes #5736.,3
[hotfix][tests] Hide output from config.shThis closes #5763.,5
[FLINK-9069] Add checkstyle rule to detect multiple consecutive semicolonsThis closes #5769.,1
[FLINK-8963][tests] Port BigUserProgramJobSubmitITCase to MiniClusterResourceThis closes #5772.,5
[FLINK-8704][tests] Port SlotCountExceedingParallelismTestThis closes #5694.,3
[FLINK-8703][tests] Port CancelingTestBase to MiniClusterResourceThis closes #5664.,5
[hotfix][tests] Properly disable JoinCancelingITCase,3
[FLINK-8704][tests] Port ScheduleOrUpdateConsumersTestThis closes #5697.,5
[hotfix][docs][table] Minor fixesThis closes #5795.,0
[FLINK-8966][tests] Upload user-jars in MiniCluster,5
[FLINK-8966][tests] Port AvroExternalJarProgramITCase to flip6This closes #5766.,3
[FLINK-9104][docs] Update generator and regenerate REST API docsThis closes #5797.,2
[FLINK-8804][build] Bump flink-shaded-jackson version to 3.0This closes #5596.,2
[FLINK-8697] Rename DummyFlinkKafkaConsumer in Kinesis tests  This closes #5809.This closes #5785.,3
[FLINK-8771][build] Upgrade scalastyle to 1.0.0This closes #5702.,2
+ScheduleOrUpdateConsumersTest,5
[FLINK-9128] [flip6] Add support for scheduleRunAsync for FencedRpcEndpointsWrap self messages in the FencedRpcEndpoints in a LocalFencedMessage to not drop themdue to a missing fencing token.This closes #5812.,4
[hotfix] Suppress restarts if rescaling operation fails,0
[hotfix][docs] Update maven instructions for generating docs,2
[hotfix][docs] Stabilize generated hashcodes,2
[FLINK-8254][docs] Regenerate REST API,2
[FLINK-8507] [table] Upgrade Calcite dependency to 1.16This closes #5791.,2
[FLINK-8563] [table] Add test for consecutive DOT access of composite array element in SQLThis closes #5792.,3
[FLINK-9108][docs] Fix invalid link,2
[FLINK-8509] [table] Remove SqlGroupedWindowFunction class from Flink repoThis closes #5794.,2
[FLINK-8508] [table] Remove RexSimplify class from FlinkThis closes #5793.,2
[FLINK-9110] [docs] Fix local bundler installationThis closes #5788.,0
[FLINK-9131][travis] Disable spotbugs plugin,0
[FLINK-9107] [docs] Document timer coalescing for ProcessFunctionThis closes #5790.,1
[hotfix] [docs] Improve description of keyBy().,1
[hotfix] [docs] Update deprecated sql() to sqlQuery().This closes #5818.,5
[FLINK-9068] [docs] Fix for removing extra '</p>' tag.,4
[FLINK-8968][state] Pull the creation of readOptions out of loop to avoid native resource leak.,1
[FLINK-8699][state] Deep copy state info to avoid potential concurrency problem in full checkpoint.,0
[hotfix] Use try-with-resources to ensure RocksIterator is always closed in RocksDBMapState.This closes #5705.,5
"[FLINK-9059] [table] Replace ""sources"" with ""tables"" in environment fileThis closes #5758.",2
[hotfix][tests] Remove Kafka testFailOnDeploy test,3
[hotfix][tests] Remove unused methods in KafkaConsumerTestBase,3
[FLINK-8703][tests] Port KafkaTestBase to MiniClusterResourceThis closes #5669.,5
[FLINK-8837][annotations] Add @Experimental annotation and annotate some classesThis closes #5800.,1
[FLINK-8835] [taskmanager] Cleanup TaskManager config keysThis closes #5808.,5
[FLINK-8742][docs] Move docs generator annotations to flink-annotationsThis closes #5821.This closes #5787.,2
[hotfix][docs] Update maven version in building flink docsThis closes #5760.,2
[hotfix][tests] Fix job-cancellation check in ResumeCheckpointManuallyITCase,0
"[FLINK-8426][docs] fix java examples for ""Generating Timestamp/Watermakr"" documentation.This closes #5828.",2
[FLINK-9147] [metrics] Include shaded Prometheus dependencies in jar  The Prometheus metrics reporter does not include the shaded Prometheus dependencies in its jar. This commit changes this.This closes #5828.,4
[hotfix][docs] Fix typosThis closes #5827.,2
[FLINK-9140][build] Simplify scalastyle configurationThis closes #5819.,5
[FLINK-9087] [runtime] change the method signature of RecordWriter.broadcastEvent() from BufferConsumer to voidThis closes #5802.,4
[FLINK-8684][mesos] Make MESOS_RM_TASKS_SLOTS an alias,1
[hotfix][docs] Refactor ConfigOptionsDocGenerator,5
[FLINK-9160] Make subclasses of RuntimeContext internal that should be internal,1
[FLINK-9152] Harmonize BroadcastProcessFunction Context names,1
"[FLINK-9152] Use in-class Context objects in BroadcastProcessFunctionThis brings it in line with KeyedBroadcastProcessFunction, which usescontext objects defined in KeyedBroadcastProcessFunction. The contextobjects here have no added functionality but we still define them hereso that the methods don't refer to the base class implementations forconsistency.",1
[FLINK-9152] Fix error message on BroadcastConnectedStream,0
[FLINK-9152] Add simple ITCase for non-keyed Broadcast Connect translation,1
[hotfix][typo] fix some typos,2
[hotfix][tests] fix ineffective file existence check and remove duplicate code,4
"[FLINK-8872][flip6] fix yarn detached mode command parsingThe detached flag if given by ""-yd"" was not passed correctly into theCliFrontend and resulted in the CLI waiting for submitted jobs to finish insteadof detaching from the execution.[FLINK-8872][yarn] add tests for YARN detached mode command line parsing with CliFrontend- create a test-jar of flink-clients- create CliFrontendRunWithYarnTest based on CliFrontendRunTest that verifies  CliFrontend's parsing in conjunction with FlinkYarnSessionCli-> verify detached mode in this test (can be extended further in the future)This closes #5672.",3
[hotfix] Deprecate AbstractYarnClusterDescriptor#setDetachedMode and isDetachedMode,1
[hotfix] Replace nio.Path with File in RestHandlerConfiguration,5
[FLINK-9103] Using CanonicalHostName instead of IP for SSL coonection on NettyClientThis closes #5789.,1
[FLINK-9163] [e2e-tests] harden signal traps and config restorationThis closes #5841.,5
[FLINK-9145] [table] Clean up flink-table dependenciesThis closes #5853.,2
"[FLINK-9173][REST] Improve client error message for parsing failures- print parsing exception for expected type, not error- add toString implemented to JsonResponse",5
[FLINK-9156][REST][CLI] Update --jobmanager option logic for REST clientThis closes #5838.,2
[hotfix][tests] Add MCR constructor accepting configuration and type,5
[FLINK-8961][tests] Add MiniClusterResource#getClientConfiguration,5
[FLINK-8961][tests] Port JobRetrievalITCase to flip6This closes #5730.,3
[hotfix][metrics] Make MessageParameter constructor protected,2
[hotfix][metrics] Allow QueryParameter converters to throw ConversionExceptions,2
[FLINK-8370][REST] Port AggregatingMetricsHandler to flip6This closes #5805.,0
[FLINK-9177][docs] Update Mesos getting started linkThis closes #5850.,2
[FLINK-9045][REST] Make createLocalEnvironmentWithWebUI more user-friendly logging message for web UI address-add back known logging mesages about webUI address-do not set random port in local stream environmentThis closes #5814.,1
[FLINK-9089] [orc] Upgrade Orc dependency from 1.4.1 to 1.4.3.This closes #5826.This closes #1990. // closing old PR,2
[FLINK-9183] [docs] Add warning about idle partitions to Kafka connector docs.This closes #5858.,2
Clarify where DataStream.print() and printToErr() print to,5
[FLINK-8366] [table] Fix UpsertTableSink tests.This closes #5244.,3
[FLINK-6924] [table] Add Table API log() function.This closes #5638.,1
[FLINK-9186][build] Enable dependenvy convergence for flink-librariesThis closes #5859.,2
[FLINK-9011] Changed some verbose YarnResourceManager logging from INFO to DEBUG levelThis closes #5712.,0
[FLINK-9124] [kinesis] Allow customization of KinesisProxy.getRecords read timeout and retry.This closes #5803.,1
[FLINK-8990] [test] Test partition discovery in Kafka end-to-end testThis closes #5779.,3
[FLINK-9203] Deprecate non-well-defined SinkFunctions,1
Fix order of starting JobManager service in Kubernetes doc,2
[FLINK-9210][metrics] Only call Gauge#getValue once during serialization,1
[FLINK-9045][REST][addendum] Batch createLocalEnvironmentWithWebUI starts on 8081,1
[FLINK-9180] [conf] Remove REST_ prefix from rest optionsThis closes #5852.,0
[FLINK-8661] Replace Collections.EMPTY_MAP with Collections.emptyMap()This closes #5864.,2
[FLINK-9199][REST] Fix URLs and remove subtask index parameterThis closes #5865.,2
[FLINK-8703][tests] Expose WebUI port,3
[FLINK-8703][tests] Port WebFrontendITCase to MiniClusterResourceThis closes #5665.,5
[FLINK-8704][tests] Port ClassLoaderITCase to flip6This closes #5780.,3
[FLINK-8960][tests] Port SavepointITCase to flip6This closes #5806.,3
[FLINK-9206][checkpoints] add job IDs to CheckpointCoordinator log messages  This closes #5872.This closes #5873.,2
[FLINK-9208][tests] fix naming of StreamNetworkThroughputBenchmarkTestThis closes #5873.,3
[hotfix][checkstyle] fix warnings in LocalBufferPool,2
[hotfix][network] extend logging message in SpillableSubpartition,2
[hotfix][network] minor optimisation in LocalBufferPool,0
[FLINK-9144][network] fix SpillableSubpartition causing jobs to hang when spillingThis closes #5842.,1
[FLINK-9022][state] Backend disposal in StreamTaskStateInitializer should always be performed in cleanup.This step should be independent from the fact if the backend is still registered with the closeable registry.,1
[hotfix][checkpointing] Double check if local state directory exists to avoid problem with concurrent directory creation.,1
[hotfix] Generated OperatorSubtaskDescription string should start counting from 1 for index 0,1
[hotfix][statebackend] Removed use of rawtype access for generic collection,1
[FLINK-9113] [connectors] Use raw local file system for bucketing sink to prevent data lossThis change replaces Hadoop's LocalFileSystem (which is a checksumming filesystem) with the RawFileSystem implementation. For performing checksums the default filesystem only flushes in 512 byte intervals which might lead to data loss during checkpointing. In order to guarantee exact results we skip the checksum computation and perform a raw flush.Negative effect: Existing checksums are not maintained anymore and thus become invalid.This closes #5861.,5
[FLINK-8980] [e2e] Add a BucketingSink end-to-end testThis closes #5813.,3
[FLINK-9227] [test] Add Bucketing e2e test script to run-nightly-tests.shThis closes #5884.,3
[FLINK-8836] Fix duplicate method in KryoSerializer to perform deep copy of default/registered serializer instances.This method did create deep copies of registered or default serializer instances andas a result those serializer instances can accidentally be shared across different threads.This closes #5880.,1
[hotfix] [core] Small improvements to DataOutputSerializer,5
[hotfix] [core] Fix checkstyle in org.apache.flink.api.common.time,2
[hotfix] [core] Cleanup DeadlineGets rid of unnecessary boxing and multiplications/divisions that Duration does internally.,1
[hotfix] [core] Fix checkstyle in org.apache.flink.api.common.typeinfo,5
"[hotfix] [core] Cleanup TypeInformationSerializationSchemaPrevents the class from dropping the TypeInformation, adds a convenience constructor.",1
[FLINK-9197] [core] Improve error messages for TypeInformation and TypeHint with generic variables.,5
[hotfix] [core] Drop hijacking of TypeHint by OutputTag. Improve error message for OutputTag.,0
[hotfix] [core] Fix OutputTag serialization to not drop TypeInformation,5
[FLINK-9198] [core] Improve AbstractDeserializationSchema to eagerly extract generic types.This results in better error messages.,0
[FLINK-9223] [tests] bufferConsumers should be closed in SpillableSubpartitionTest#testConsumeSpilledPartitionSpilledBeforeAddThis closes #5882,5
[hotfix] [docs] Minor cleanup of Java example code for AsyncFunctionsThis closes #5848,1
"[FLINK-9053][runtime] only release outputs under the checkpoint lockReleasing an operator chain's outputs will call RecordWriter#clearBuffers() andthis may not be run in parallel with RecordWriter#broadcastEvent() which theasynchronous checkpoint barrier trigger inside Task may run viaStreamTask#triggerCheckpoint(). Now, during the cleanup of StreamTask#invoke(),StreamTask's asynchronous services are shut down but not those of the Task andalso, operatorChain.releaseOutputs() was not put under the checkpoint lock.This commit adds the checkpoint lock here and we should be safe to do so sincewe already closed all of StreamTask's asynchronous executors and also disposedthe operators and hence nothing should be blocking the cleanup by holding thecheckpoint lock.This closes #5748",4
[hotfix] [core] Make some fields final in LimitedConnectionsFileSystem,5
[FLINK-8402] [tests] Fix hadoop/presto S3 IT cases for eventually-consistent operationsAlso seehttps://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModelThis closes #5624,3
[FLINK-9076] [network] Reduce minimum number of floating buffers to 0This closes #5874,5
[FLINK-9158] [core] Set default FixedRestartDelayStrategy delay to 0s.This closes #5839,0
[FLINK-8335] [hbase] Upgrade hbase connector dependency to 1.4.3This closes #5488,2
[hotfix] Making arguments in BroadcastProcessFunction final.,1
[FLINK-9241][metrics][docs] Fix ScalaGauge usage example,0
[FLINK-8537] [table] Add a Kafka table source factory with Avro format supportThis closes #5610.,1
[FLINK-5372][tests] Fix RocksDBAsyncSnapshotTest.testCancelFullyAsyncCheckpoints(),5
[hotfix][config][docs] Allow word-break for semicolon lists,4
[FLINK-9240][tests] Harden WebFrontendITCase#testStopYarn()This closes #5886.,3
[FLINK-8967][tests] Port NetworkStackThroughputITCase to flip6This closes #5870.This closes #5247.This closes #5875.,1
[hotfix][tests] Properly close writer in NetworkStackThroughputITCase,1
[hotfix][tests] Enable NetworkStackThroughputITCase,1
[FLINK-9225][core] Minor code comments fix in RuntimeContextThis closes #5883.,1
[FLINK-9212][REST] Port SubtasksAllAccumulatorsHandler to new REST endpointThis closes #5893.,1
"[FLINK-8793][REST] Hide configured value for ""password""/""secret""",4
"[FLINK-9100][core] Hide configured value for ""password""/""secret""This closes #9100.",4
[FLINK-9033][config] Replace usages of deprecated TASK_MANAGER_NUM_TASK_SLOTSThis closes #5731.,5
[FLINK-8704][tests] Port PartialConsumerPipelinedResultTest,3
[FLINK-9229] [table] Fix literal handling in code generationThis closes #5898.,0
[FLINK-8686] [sql-client] Improve basic embedded SQL client- Fix invalid cached session properties- Sort given table source properties- Add logging for exceptions and cluster communication- Add valid page range- Fix highlighting during result refreshThis closes #5867.,0
[FLINK-9243][tests] fix flaky SuccessAfterNetworkBuffersFailureITCaseThis closes #5915.,0
[FLINK-8841] Remove HashMapSerializer and use MapSerializer instead.This closes #5910.,1
"[FLINK-8689] [table] Add support DISTINCT aggregates in OVER windows.- distinct values are stored in a MapView, either on the heap or in a StateBackend depending on the context.This closes #5555.This closes #3783 (PR was superseded by #5555)",1
[FLINK-8992] [e2e-tests] Initial commit for general purpose DataStream job,5
[FLINK-8992] [e2e-tests] Integrate general DataStream test job with project structureThis also includes minor cleanup of WIP code in the test job.This closes #5925.,3
"[FLINK-8715] Ensure use of reconfigured serializers in state backendsThis commit consists of the following changes:1. No longer use StateDescriptors in state handle classes. Instead,state handles always work with serializers directly.2. Refactor state registration paths to have better separation ofconcerns.This closes #5885.",1
"[FLINK-9214] [tests, yarn] YarnClient should be stopped in YARNSessionCapacitySchedulerITCase#testDetachedPerJobYarnClusterInternalThis closes #5892",3
[hotfix] Update README.md building prerequisitesThis closes #5924,3
[hotfix] Replace String concatenation with Slf4j placeholders.,0
[hotfix] Indent method parameters.,2
[hotfix] Remove unnecessary int cast.,4
[hotfix] Fix raw types warning.,2
[hotfix] [mesos] Delete unused class FlinkMesosSessionCli.,2
[hotfix] [yarn] Remove unused field appReport in YarnClusterClient.,1
[hotfix] [tests] Rename UtilsTest to YarnFlinkResourceManagerTest.Test was misnamed.,3
"[FLINK-9196] [flip6, yarn] Cleanup application files when deregistering YARN AMEnable graceful cluster shut down via HTTP.Remove Flink application files from remote file system when theYarnResourceManager deregisters the YARN ApplicationMaster.This closes #5938",5
[hotfix] [runtime] Fix a debug statement in StreamTask,0
[FLINK-9275] [streaming] Add taskName to the output flusher thread's nameThis closes #5943,1
[FLINK-9274] [kafka] Add thread name for partition discoveryThis closes #5942,1
[hotfix] [tests] Remove redundant rebalance in SuccessAfterNetworkBuffersFailureITCaseThis closes #5916,0
[FLINK-9256] [network] Fix NPE in SingleInputGate#updateInputChannel() for non-credit based flow controlThis closes #5914,2
[FLINK-6557] [rocksdb] Use File instead of Path for RocksDB local temp directories.,5
[FLINK-9263][state] Fix concurrency problem in DefaultOperatorStateBackend.This closes #5930.,1
[FLINK-9188] [kinesis] Generic mechanism to set ClientConfiguration properties.This closes #5889.,5
[FLINK-9266] [kinesis] Updates Kinesis connector to use newer version of kcl to limit describe streams callsThis closes #5932.,1
[FLINK-9213] Revert checkpoint details URL from '/jobs/:jobid/checkpoints/:checkpointid' to '/jobs/:jobid/checkpoints/details/:checkpointid' as it was in 1.5This closes #5906.,4
[FLINK-9216][Streaming] Fix comparator violationThis closes #5878.,0
[FLINK-9041][tests] Refactor StreamTaskTest to use java 8 CompletableFuture instead of scala/akka PromiseThis closes #5912.,1
[FLINK-9249][build] Add convenience profile for skipping non-essential pluginsThis closes #5904.,2
[FLINK-8743][docs] Allow overriding documented defaultThis closes #5822.,2
[FLINK-9211][REST] JarRunHandler submits job to Dispatcher via RPCThis closes #5903.,0
[FLINK-9154][REST][docs] Document WebSubmissionExtension handlersThis closes #5833.,0
[hotfix][docs] Fix typehint in state documentationThis closes #5919.,2
[FLINK-9119][table][docs] Fix example code error in Concepts & Common APIThis closes #5935.,0
[FLINK-9136][tests] Remove StreamingProgramTestBaseThis closes #5817.,3
[FLINK-9269][state] Fix concurrency problem when performing checkpoint in HeapKeyedStateBackend.This closes #5934.,0
[FLINK-8683][docs] Regenerate config docs,2
[FLINK-8683][docs] Add test for configuration docs completenessThis closes #5515.,2
[FLINK-9288] [docs] clarify the event time / watermark docsThis closes #5949,2
[hotfix] [tests] Update log4j-test.propertiesBrings the logging definition in sync with other projects.Updates the classname for the suppressed logger in Netty to account for the newshading model introduced in Flink 1.4.,2
[FLINK-8900] [yarn] Set correct application status when job is finishedThis closes #5944,5
[FLINK-8726][docs] Fix and normalize code-highlightingThis closes #5909.,0
[FLINK-9293] [runtime] SlotPool should check slot id when accepting a slot offer with existing allocation idThis closes #5951,1
[hotfix] [runtime] Minor code cleanup in SlotPool,4
[FLINK-6719] [docs] Add details about timers to ProcessFunction docs.This closes #5887.,2
[FLINK-8620] Enable shipping custom files to BlobStore and accessing them through DistributedCacheThis closes #5580,2
[FLINK-9254] Move NotSoMiniClusterIterations to be an end-to-end testThis closes #5921.,3
[FLINK-8978] Stateful generic stream job upgrade e2e testThis closes #5947.,3
"[hotfix] [runtime] Minor cleanups around JobMasterId, ResourceManagerId, DispatcherId.",4
[hotfix] [runtime] Add resourceId to TaskManager registration messages,1
[FLINK-9292] [core] Remove TypeInfoParser (part 1),5
[FLINK-9301][tests] Disable high-parallelism-iterations-test,3
"[FLINK-9169] [runtime] Always use dummy serializer instead of null when old state serializer cannot be readPrreviously, the behaviour of TypeSerializerSerializationUtil readmethods in the case when serializers cannot be read, is quite mixed up.For some exceptions (e.g. ClassNotFoundException,InvalidClassException), a dummy serializer will be used as areplacement. In other cases, null is used.This commit fixes this by always using dummy serializers if a'useDummyPlaceholder' flag is set to true. Otherwise, an IOException isthrown. This makes it clear that users should use dummy serializers ifthey want the deserialization to be tolerant to failures.Another benefit of this is that there will no longer be 'null'serializers after restore; they will either be an actual serializer, ora dummy if the old serializer cannot be restored.",0
"[FLINK-9169] [runtime] Allow specifiying serializer presence requirement in KeyedBackendSerializationProxyThis commit consolidates logic of whether old serializers are requiredto be present at restore time in the KeyedBackendSerializationProxy, viaa isSerializerPresenceRequired flag.Heap-based backends typically set this to true, while RocksDB statebackend will set this to false. If set to true, restored serializerscannot be the UnloadableDummyTypeSerializer, otherwise an IOExceptionwill be thrown to fail the restore.This closes #5950.",0
[FLINK-9287][kafka] Properly clean up resources in non EXACTLY_ONCE FlinkKafkaProducer011Previously FlinkKafkaProducer was not being closed for AT_LEAST_ONCE and NONE Semanticswhen closing FlinkKafkaProducer011. This was leading to resources leaking (for exampleincreasing number of active threads),1
[FLINK-9287][kafka] Ensure threads count do not grow in FlinkKafkaProducer011This closes #5952.,2
[hotfix ] Fix incorrect parallelism in the Javadoc of ListCheckpointedThis closes #5918.,2
[hotfix] Correct the javadoc of StandaloneCheckpointIDCounter#getLastThis closes #5956.,1
[hotfix][docs][QS] Minor cleanup of QS documentation- replace usage of deprecated ValueStateDescriptor constructor- fix artifact-id containing 2 underscores- remove final keyword from method reference- add missing space to note,1
[FLINK-8064][docs][QS] List flink-core as dependencyThis closes #5006.,2
[hotfix] Skip deployment of end-to-end test modules,3
[FLINK-8237] [bucketSink] BucketingSink returns error message if Writer.duplicate returns null.This closes #5927.,0
[FLINK-8690] [table] Add DISTINCT aggregates for group windows on streaming tables.This closes #3764.This closes #3765. // Has been resolved by another PR.,0
[FLINK-8690] [table] Add DISTINCT aggregates for group windows on streaming tables.This closes #5940.,1
Remove special-case krb5.conf code from YARN runners,1
"[FLINK-9306] Execute YARN ITCases in both legacy and new modeBefore, always setting mode to LEGACY_MODE when security settings arepresent caused the test never to run with the new code. Now we use thesystem property for determining whether to run in old or new mode.For this, we also need to actually execute an example. Otherwise, noTaskExecutors would be brought up.",1
[FLINK-8286] Fix Kerberos integration for FLIP-6 YarnTaskExecutorRunner,1
[FLINK-9093] [e2e-tests] Extend savepoint e2e tests for different state backendsThis closes #5926.,3
[FLINK-8533] [checkpointing] Support MasterTriggerRestoreHook state reinitialization- ensure that JobManager calls restoreLatestCheckpointedState unconditionally- add close method to hook interface- fix test failure in `JobManagerStartupTest` (Windows only)This closes #5427,3
[hotfix] [core] [runtime] Some code simplifications for MasterHooksThis introduces LambdaUtil.withContextClassLoader(...) to apply Runnables and Supplierswith a configured context class loader.,5
[FLINK-9310] [security] Update standard cipher suites for secure modeThis sets the cipher suits accepted by default to those recommended inIETF RFC 7525 : https://tools.ietf.org/html/rfc7525This closes #5965,5
[FLINK-9261] [security] Fix SSL support for REST API and Web UI.- Remove wrong reuse of SSLEngine instances. SSLEngine must be re-created for  every SocketChannel initialization.- Add ChunkedWriteHandler to REST server pipeline because StaticFileServerHandler  relies on it.- Add integration tests to verify that SSL can be enabled.,0
[hotfix] [docs] Use markdown hyperlink instead of writing out the URL.,2
[FLINK-9141][datastream] Fail early when using both split and side-outputsThis closes #5836.This closes #5479.This closes #4893.This closes #4809.This closes #4621.This closes #3915.,1
[FLINK-9179][REST] Deduplicate WebOptions.PORT and RestOptions.PORTThis closes #5856.,2
[FLINK-8912][WebUI] Update error handling for flip6This closes #5907.,0
[FLINK-8912][WebUI] Rebuild UI,2
[FLINK-8284][metrics][docs] Expand port description for JMX reporter,2
[FLINK-9125][tests] MiniClusterResource sets CoreOptions.TMP_DIRSThis closes #5933.,1
[FLINK-9282][docs] Update Quickstart page for 1.5This closes #5957.,5
[FLINK-9317][docs] Fix variable name in scala Async I/O API ExampleThis closes #5968.,0
[FLINK-9321][REST] Rename SubtasksAllAccumulatorsHandlersThis closes #5971.,0
[FLINK-9265][metrics] Upgrade Prometheus version to 0.3.0This closes #5936.,2
[hotfix][REST][docs] Regenerate REST documentation,2
[FLINK-8134][REST][docs] Add MessageHeaders#getDescription()This closes #5967.,1
[hotfix][docs] Add missing bracketThis closes #5981.,1
[FLINK-9323][build] Properly organize checkstyle-plugin configurationThis closes #5972.,5
[FLINK-9138][docs][tests] Make ConfigOptionsDocsCompletenessTest an IT caseThis closes #5975.,1
[FLINK-9309][docs] Recommend HA setup on Production Readiness ChecklistThis closes #5976.,1
"[FLINK-9190][flip6,yarn] Request new container if container completed unexpectedly.This closes #5931.",1
[hotfix][yarn] Reduce visibility of fields.,0
[hotfix] [tests] Harden YarnSessionFIFOITCase#testDetachedModeWait for the completion of the submitted job in order to avoid that we killthe JM while the TM tries to down load blobs from it.,3
"[FLINK-9324] Wait for slot release before completing release future in SingleLogicalSlotThis commit properly waits for the completion of the SingleLogicalSlot's release futureuntil the SlotOwner has acknowledged the release. That way the ExecutionGraph will onlyrecover after all of its slots have been returned to the SlotPool.As a side effect, the changes in this commit should reduce the number of redundant releasecalls sent to the SlotOwner which cluttered the debug logs.This closes #5980.",2
[hotfix] [runtime] Minor code cleanups and improved comments.  - Clarify the purposes of AllocationID versus SlotRequestId.  - Remove an unnecessary method indirection,4
[hotfix] [runtime] Add toString() methods to SlotSharingManager and contained slot classes.,1
[hotfix] [runtime] Add toString() and print methods to SlotPool classes for as debugging/diagnostic helpers,0
[FLINK-9330] [runtime] Add periodic logging of SlotPool statusOnly happens if log level for the SlotPool is set to DEBUG,0
"[FLINK-9331] [mesos] Let MesosResourceManager request new tasks for failed onesIn order to avoid the problem of not fulfilling allocation requests when a Mesostasks dies before it could register at the RM, this commit restarts all failedMesos tasks. The downside is that in some cases where the JM notices the failureof a TM and would fail the job, we request tasks which are not directly needed.This closes #5986.",0
[FLINK-9332] [table] Fix handling of null return values in CallGenerator.This closes #5988.,0
[FLINK-9138] [bucketSink] Support time-based rollover of part files in BucketingSink.This closes #5860.,2
[FLINK-9339][REST] Register subtask accumulator handler under correct URLThis closes #5997.,0
[hotfix] [network] Make time measurements with System.nanoTime(),5
[hotfix] [network] Minor code cleanup in NettyTestUtil,3
[FLINK-9348] [docs] Scalastyle documentatiom for IntelliJ IDE setupThis closes #5999,1
[hotfix][docs] Move note about partial checkstyle enforcement,1
[FLINK-9234] [table] Fix missing dependencies for external catalogsThis closes #5897.,2
[FLINK-9201] Add trigger tests for late-window mergingThis closes #5917,3
[hotfix] [runtime] Remove accidental reference to Hadoop StringUtils in CheckpointStorageLocationReference,4
[FLINK-9181] [docs] [sql-client] Add documentation for the SQL ClientThis closes #5913.,2
[FLINK-8780] [docs] Add Broadcast State documentation.This closes #5922.,2
[FLINK-9336] [state] Set the userKeyOffset in every MapEntry.Previously the userKeyOffset in RocksDB  was set when serializingthe key and namespace. This was prone to failure as different codepaths followed by queryable state were not setting it appropriately.This closes #5993.,1
[FLINK-9355][checkpointing] Simplify configuration of local recovery to a simple on/off switchThis closes #6006.,5
[hotfix][tests] Fix minor mocking issues in AbstractStreamOperatorTest,3
[FLINK-9246][HS] Adjust HistoryServer for job overview changes,4
[hotfix][history] Read/Write MultipleJobsDetails instead of manual JSON,5
[FLINK-9194][history] Add archiving routine to Dispatcher,1
[FLINK-9194][history] Add convenience ArchivedJson constructor,5
[FLINK-9194][history] Adjust handlers,0
[FLINK-9194][history] Rework and extend the HistoryServer test,3
[FLINK-9194] Add support for legacy history server formats,1
[hotfix] Add import for linked component in ArchivedJson,5
[FLINK-9194] Introduce HistoryServerArchivist interfaceThe HistoryServerArchivist interface encapsulates the archiving logic of anAccessExecutionGraph to the history server. Currently this means to generatethe JSON responses for all possible HTTP requests and writing them to atarget directory.This closes #5902.,1
[FLINK-9304] Timer service shutdown should not stop if interruptedThis closes #5962.,2
"[FLINK-9358] Avoid NPE when closing an unestablished ResourceManager connectionA NPE occurred when trying to disconnect an unestablished ResourceManager connection.In order to fix this problem, we now check whether the connection has been establishedor not.This closes #6011.",0
[hotfix] Make field JobMaster#resourceManagerLeaderRetriever final,1
[FLINK-9074] [e2e] Allow configuring externalized checkpoints for the general purpose DataStream job,5
[FLINK-9074] [e2e] Add e2e test for resuming jobs from retained checkpointsThis closes #5969.,3
[FLINK-9350] Parameter baseInterval has wrong check message in CheckpointCoordinator constructorThis closes #6002.,0
"[FLINK-6926] [table] Add support for SHA-224, SHA-384, SHA-512",1
[FLINK-6926] [table] Add support for SHA2 (Compatible with SQL vendors like MySQL)This closes #5324.,1
[hotfix] Add JobMasterTest#testSlotRequestTimeoutWhenNoSlotOfferingThe JobMasterTest#testSlotRequestTimeoutWhenNoSlotOffering verifies that the JMwill retry a job scheduling if one of its TMs does not properly offer a slot. Themechanism which triggers this behaviour is the slot request timeout which fails theongoing scheduling operation if the slot requests are not fulfilled.,0
[hotfix] Resolve compiler warnings in AkkaRpcService,2
[FLINK-9365] [rpc] Add handshake procedure to AkkaRpcService when connectingThe handshake procedure sends the source version and the target rpc gateway typeto the rpc endpoint. This information is used to validate whether the version iscompatible and whether the rpc endpoint supports the target gateway type.This closes #6017.,1
[FLINK-9361] [sql-client] Fix refresh interval in changelog modeThis closes #6012.,4
[FLINK-9174] Make type of state created in ProcessWindowFunction.process() consistent,1
[hotfix][test-scripts] Properly wait for cluster to be up in common.sh,3
[FLINK-9357][tests][yarn] Add margins to exception excerptsThis closes #6009.,1
[FLINK-9283][docs] Update port cluster execution docsThis closes #6022.,2
[FLINK-9284][docs] Update port in CLI docsThis closes #6013.,2
[FLINK-9359][docs] Update quickstart docs to only mention Java 8This closes #6010.,2
[FLINK-9176][tests] Remove category annotationsThis closes #5851.This closes #6005.,4
[FLINK-9360][tests] Reduce sleep to 30 seconds,3
[FLINK-9333][docs] Fix typos in quickstart docs,2
[FLINK-9333][docs] Add IntelliJ section for setting JVM optionsThis closes #5989.,1
[FLINK-9285][REST][docs] Update REST API docsThis closes #5946.,2
[hotfix][docs] Update docs regarding externalized checkpointThis closes #5928.,2
[FLINK-9354][travis] Print execution times for nightly E2E testsThis closes #6008.,3
[hotfix][conf] Add missing deprecation notes,1
[hotfix][docs] Update docs for simplified configuration of local recovery,5
[hotfix] Abort restore when the procedure failed through with a closed CloseableRegistryThis prevents that exceptions from cancellation through the CloseableRegistry will result inunnecessary recovery attemps with alternative state.,1
[hotfix] Change default for SLOT_IDLE_TIMEOUT to match HEARTBEAT_TIMEOUTThat preserves sticky slot allocation for local recovery for lost JVMsthat can take as long as the heartbeat timeout to be detected.,4
"[hotfix] Introduce NoOpTaskLocalStateStoreImpl that is used as store if local recovery is disabledThis implementation will no go through all the registration/lookup steps or a normal state store, beausethey are not required if local recovery is disabled.",1
[hotfix] Small improvements in logging for local recovery,2
[hotfix] Expose AllocationID as string through TaskInfo,5
[FLINK-8910][e2e] Automated test for local recovery (including sticky allocation)This closes #5676.,3
"[FLINK-8428] [table] Implement stream-stream non-window left outer joinTwo different CoProcessFunctions are used to implement left join for performance reasons. One for left join with non-equal predicates, the other for left join without non-equal predicates. The main difference between them is, for left join without non-equal predicates, left rows can always find matching right rows as long as join keys are same.- Left join with non-equal predicates: Use a mapState to keep how many rows(joinCnt) from right table can be matched by current left row. If joinCnt is 0, output NULL right with left row. If joinCnt is changed from 0 to 1, retract the previous NULL right output and output the matched result. If joinCnt is changed from 1 to 0 when received a right retract input, retract the previous mathched result and output NULL right with left row.- Left join without non-equal predicates: We don't need to count joinCnt any more, because joinCnt is same with right state size, so check state size is ok.Table Modes:Left join will generate retractions, so DataStreamRel node of left join will working under AccRetract mode. Also, the table mode of dynamic table produced by left join is Update Mode, even if the table does not include a key definition.This closes #5327.",5
"[FLINK-9381] Release blobs after job terminationProperly remove job blobs from BlobServer after the job terminates. If the job reaches a globally terminalstate, then the HA blob store files will also be cleared. In case of a suspension or that the job is notfinished (e.g. another process finsihes the job concurrently), we only remove the local blob server files.Additionally, we properly release the user code class loader registered in the JobManagerRunner when itcloses.This closes #6030.",1
"Revert ""[FLINK-9360][tests] Reduce sleep to 30 seconds""This reverts commit a709b74fd8b185ccd1a9df1dff51c93ef4fb3752.",4
[FLINK-9292] [core] Remove TypeInfoParser (part 2)This changes #5970,4
[FLINK-9299] [docs] Fix errors in ProcessWindowFunction documentation Java examplesThis closes #6001,2
[hotfix] [build] Force delete corrupt jar files from cache,2
"[FLINK-9373][statebackend] Introduce RocksIteratorWrapper to wrap `Seek(), Next(), SeekToFirst(), SeekToLast(), SeekForPrev(), and Prev()` to check the iterator status.This closes #6020.",2
[FLINK-9387] Several log message errors in queryable-state module.This closes #6029.,0
"[FLINK-6160] Add reconnection attempts in case of heartbeat timeouts to JobMaster and TaskExecutorIf a timeout with the RM occurs on on the JobMaster and TaskExecutor, then they will both try to reconnectto the last known RM address.Additionally, we now respect the TaskManagerOption#REGISTRATION_TIMEOUT on the TaskExecutor. This means thatif the TaskExecutor could not register at a RM within the given registration timeout, it will fail with afatal exception. This allows to fail the TaskExecutor process in case that it cannot establish a connectionand ultimately frees the occupied resources.The commit also changes the default value for TaskManagerOption#REGISTRATION_TIMEOUT from ""Inf"" to ""5 min"".This closes #6035.",5
[hotfix] Make TaskManagerRunner shutdown asynchronously,1
[hotfix] [docs] Add Release Notes for Flink 1.5.This closes #6039.,2
[hotfix] [docs] Add Release Notes for Flink 1.6.,2
[hotfix] [tests] Minor cleanup and lambda-ification for the StreamGraphGeneratorTest,3
[FLINK-9397] [DataStream API] Correctly propagate operator buffer timeout of 0This also improves some JavaDocs.,2
[hotfix] [core] Fix checkstyle in org.apache.flink.api.common.functions,2
[FLINK-9392] [core] Add @FunctionalInterface to all core functions to guard against breaking SAM mechanics,4
[FLINK-9070][state] Improve the performance of RocksDBMapState.clear() with WriteBatch.This closes #5979.,5
[FLINK-8659] Add migration itcases for broadcast state.This closes #5955.,1
[hotfix][docs][table] Fix link to registering external catalogThis closes #6052.,2
[FLINK-9403][docs] Remove obsolete documentationThis closes #6048.,2
[hotfix] [e2e-tests] Make SequenceGeneratorSource usable for 0-size key ranges,1
[FLINK-8971] [e2e-tests] Include broadcast / union state in general purpose DataStream jobThis closes #5941.,5
[FLINK-9322] [e2e] Add failure simulation to the general purpose DataStream job,5
[FLINK-9320] [e2e] Update test_ha e2e to use general purpose DataStream jobThis closes #5990.,5
[FLINK-8977] [e2e] Allow configuring restart strategy for general purpose DataStream job,5
[FLINK-8977] [e2e] Extend externalized checkpoint e2e to simulate job failuresThis closes #6004.,0
[FLINK-8989] [e2eTests] Elasticsearch1&2&5 end to end test,3
[FLINK-8989] [e2e] Cleanup / improve Elasticsearch e2e tests- Rework e2e test job modules to have correct Maven POM- Parameterize num of records to write to Elasticsearch- Parameterize Elasticsearch download URL and version in test script- Improve robustness of test- Move more Elasticsearch functionality to elasticsearch-common.shThis closes #5761.,1
[FLINK-9008] [e2e] Implements quickstarts end to end test,3
"[FLINK-9008] [e2e] Reuse flink-elasticsearch5-test job code as quickstart e2e test's modified jobPreviously, the modified job used in the `test_quickstarts.sh` testscript is maintained as a new Maven module. This is an overkill, since allwe are doing is replacing the quickstart's contained job with somethingmore complex and with additional dependencies.This commit changes this by simply reusing job code inflink-elasticsearch5-test as the modified job,which is copied to the quickstart project.This closes #5823.",5
[hotfix] [e2e] Properly backup Flink config in externalized checkpoint e2e test,3
[FLINK-9372] [elasticsearch] Typo on Elasticsearch website linkThis closes #6018.,2
[hotfix] [e2e] Properly use run_test utility for local recovery and quickstart tests,3
[hotfix][tests] Introduce MockEnvironmentBuilder to deduplicate MockEnvironment constructors,3
[hotfix][tests] Reduce mockito usage in tests,3
[FLINK-9316][streaming] Expose operator's unique ID in DataStream programsThis allows to uniquely and stably across multiple job submissions identify operators.Previously two different operators that were executed by tasks that had the same namewere indistinguishable.,1
"[FLINK-9295][kafka] Fix transactional.id collisions for FlinkKafkaProducer011Previously if there were two completely independent FlinkKafkaProducer011 data sinksin the job graph, their transactional.id would collide with one another. Fix is touse operator's unique ID as well along task name and subtask id.This change is backward compatible for recovering from older savepoints,since transactional.ids generated by the old generator still will be usedafter restoring from state.This closes #5977.",1
[hotfix][javadocs] Fix path example in DateTimeBucketerThis closes #6051.,5
[FLINK-8429] [table] Implement stream-stream non-window right outer joinThis closes #6046.,2
[FLINK-6909] [types] Add tests for Lombok POJOsThis closes #6033.,3
[FLINK-6909] [types] Fix error message in CsvReader for wrong type classThis closes #6037.,0
[hotfix] [types] Expose type extraction error for fromElements/Collection()This closes #6036.,0
[FLINK-8838] [table] Add support for UNNEST on MultiSet fieldsThis closes #5619.,1
"[FLINK-9402] [kinesis] Kinesis consumer configuration requires either region or endpoint.Fix validation logic to allow either region or endpoint, but not both.This closes #6045.",1
[FLINK-9408] Let JM try to reconnect to RMThis commit changes the behaviour of the JM to always try to reconnect to the latest known RM address.This closes #6056.,1
[FLINK-9406] Use equals in JobMaster#requestPartitionStateUse equals instead of referential equality in JobMaster#requestPartitionStatewhen comparing the producerExecution attempt id with the result partitionproducer id.This closes #6057.,1
"[FLINK-9414] Remove unnecessary jline-reader and jline-terminal entries from LICENSEThe jline-reader and jline-terminal are dependencies against which we link.They don't need to be included in LICENSE, because LICENSE only contains codewhich is contained in the source release of Flink.",2
[FLINK-9349] [kafka] Fix concurrent modification on partitions states list,0
"[FLINK-9349] [kafka, test] Strengthen testConcurrentPartitionsDiscoveryAndLoopFetching testThis commit improves the said test to fail consistently without fixingconcurrent modifications on the partition states list.This closes #6040.",0
"[hotfix] [kafka, test] Remove unnecessary Mockito usages in AbstractFetcherTest",3
[hotfix][cassandra] Add no-org constructor to example POJO,1
[FLINK-7814] [table] Add BETWEEN and NOT BETWEEN expression to Table APIThis closes #6027.,1
[FLINK-8845][state] Introduce RocksDBWriteBatchWrapper to improve batched write performance in RocksDB backend.This closes #5650.,5
[FLINK-9064][scaladocs] Add link to scaladocs to documentation sidebar.This closes #5773.,2
[FLINK-9337] Implemented AvroDeserializationSchema,2
[FLINK-9338] Implemented RegistryAvroDeserializationSchema & provided implementation for Confluent Schema RegistryThis closes #5995,1
[FLINK-9426][test] Remove flaky asserts from RocksDBWriteBatchPerformanceTest.benchMark().This closes #6063.,5
[hotfix] [runtime] Remove unused and unnecessary method from StreamTask,1
[hotfix] [runtime] Restore interruption flag in StreamRecordWriter.close(),1
[hotfix] [runtime] Remove dead code for handling no longer thrown InterruptedException,4
[hotfix] [tests] Cleanup and lambda-ify StreamOperatorChainingTest,5
"[hotfix] [runtime] Eagerly create AccumulatorMap in StreamTaskThis follows the RAII paradigm, simplifying testing setups and reasoning about initialization.",5
[FLINK-9415] Remove reference to StreamingMultipleProgramsTestBase in docs,2
"[FLINK-9415] [scala, test] Remove ScalaStreamingMultipleProgramsTestBaseThis closes #6058.",3
[FLINK-9428] [runtime] Add a 'pre-barrier-emit' checkpoint notification to stream operators.This allows operators with small transient unmanaged state (for example pre-aggregates) toflush the state prior to the checkpoint barrier.,1
[hotfix] [tests] Minor code cleanups in SavepointITCase,4
[FLINK-8511] [table] Remove legacy code for the TableType annotationThis closes #6055.,4
[FLINK-9425] Make release scripts compliant with ASF release policyRemove the generation of MD5 checksum files and create sha checksumfiles with a sha512 file ending.This closes #6061.,2
"[FLINK-9427] Fix registration and request slot race condition in TaskExecutorThis commit fixes a race condition between the TaskExecutor and the ResourceManager. Before,it could happen that the ResourceManager sends requestSlots message before the TaskExecutorregistration was completed. Due to this, the TaskExecutor did not have all information it neededto accept task submissions.The problem was that the TaskExecutor sent the SlotReport at registration time. Due to this, the SlotManager could already assign these slots to pending slot requests. With this commit, theregistration protocol changes such that the TaskExecutor first registers at the ResourceManagerand only after completing this step, it will announce the available slots to the SlotManager.This closes #6067.",4
[FLINK-9421] Remove job from RunningJobsRegistry when it reaches a terminal stateThis commit lets the Dispatcher remove the RunningJobsRegistry entry for a completed jobwhen it is removed from the Dispatcher.This closes #6068.,4
"[FLINK-9416] Make all RestClusterClient calls retriableThis commit changes the RestClusterClient calls such that they are all retriable wrtto connection errors and if the service is currently unavailable (return code 503).Moreover, it changes the retry behaviour for polling the JobResult such that it failsnow if the cluster returns a NOT_FOUND code.This closes #6069.",0
[FLINK-9420] [table] Add tests and docs for SQL IN sub-query operator in streamingThis closes #6065.,1
[FLINK-9088] [nifi-connector] Bump nifi-site-to-site-client to 1.6.0This closes #5891,2
[FLINK-9286] [docs] Update classloading docsThis closes #5948,2
[FLINK-9286] [docs] (addendum) Update classloading docs for inverted classloading,2
[hotfix] [docs] Fix flink-s3-fs-* README entry for the service file,2
[hotfix] [s3] Port config key forwarding test from hadoop S3 to presto,3
[FLINK-9305] [s3] Also register flink-s3-fs-hadoop's factory for the s3a:// schemeThis closes #5963,2
[hotfix][doc] Mention AggregationEnabled setting in kinesis docsThis closes #6072.,2
[FLINK-9384] [table] Fix KafkaAvroTableSource type mismatchThis closes #6026.,0
[FLINK-9409] [formats] Remove flink-avro and flink-json from /optThis closes #6070.,5
[hotfix] Don't swallow exception in CliFrontend#handleArgException,0
[hotfix] Bump japicmp reference version to Flink 1.5.0,2
[hotfix][docs] Add 1.5 to list of previous versions,1
[hotfix][tests] Report failure with error level instead of debug,0
"[FLINK-9386] Embed netty routerThis commit replaces netty-router dependency with our own version of it, which issimplified and adds guarantees about order of matching router patterns.This is a prerequisite for FLINK-3952. netty-router 1.10 is incompatible withNetty 4.1, while netty-router 2.2.0 brakes a compatibility in a way that wewere unable to use it.This closes #6031.",1
[hotfix] Removed unused scala imports.This closes #5820.,2
[FLINK-9153] TaskManagerRunner should support rpc port range.This closes #5834.,1
[FLINK-8655][cassandra] Support default keyspace for POJOsThis closes #5538.This closes #5964.,1
[FLINK-7850][build] Add activation property to maven profilesThis closes #5840.,2
[FLINK-9258][metrics] Thread-safe initialization of variables map,5
[FLINK-9326][streaming] TaskManagerOptions.NUM_TASK_SLOTS does not work for local/embedded modeThis closes #6041.,1
[FLINK-9383][runtime] Test directories in DistributedCache E2E test,3
[FLINK-9370][tests] Activate distributed cache end-to-end testThis closes #6023.,3
[FLINK-9356][qs] Improve error message when QS not ready / reachableThis closes #6028.,0
[FLINK-9472] fix archetype documentation typoThis closes #6098,2
[hotfix][docs] Update kubernetes.mdThis closes #5721,5
[FLINK-9215][resourcemanager] Simply print the exception message in the log in SlotPool#releaseSlot().This closes #5879,2
[FLINK-7836][Client] specifying node label for flink job to run on yarn[FLINK-7836] refactor the code and added some test code[FLINK-7836][Client] mark field : nodeLabelExpressionMethod @NullableThis closes #5593.,2
[FLINK-9423][state] Implement efficient deletes for heap-based timer service.This closes #6062.,4
[FLINK-9436][state] Remove generic parameter namespace from InternalTimeServiceManager.This closes #6077.,2
[hotfix][table] Remove a println statement,4
[FLINK-9464] Remove duplicate maven-jar-plugin entry in flink-clients pom.xml,5
[FLINK-9464] Remove version and scope from flink-test-utils-junit and maven-shade-plugin in flink-swift-fs-hadoop pom.xml,5
[FLINK-9464] Remove version and scope from flink-test-utils-junit dependency in flink-statebackend-rocksdb pom.xml,5
[FLINK-9464] Remove version and scope from flink-test-utils-junit in flink-json pom.xml,5
[hotfix] Use ConfigConstants.DEFAULT_CHARSET in KvStateRequestSpecify ConfigConstants.DEFAULT_CHARSET when converting a String into bytes and readinga String from a byte array.,5
[hotfix] Remove Category marker interface New from flink-test-utils-junit,3
[hotfix] Remove unnecessary flink-test-utils-junit dependency from flink-connector-filesystem,5
"[FLINK-9464] Remove version and scope from flink-test-utils-junit dependency in multiple modulesflink-connectors, flink-orc, flink-connector-wikiedits, flink-dist, flink-metrics-*, flink-queryable-state-*This closes #6093.",2
[FLINK-7789] Add handler for Async IO operator timeoutsThis closes #6091.,1
[FLINK-9468] [core] Set outputLimit in LimitedConnectionsFileSystem#createStream() correctly.This closes #6094,5
[hotfix] [docs] Remove unsupported SQL Client jars,1
[FLINK-9476][cep] Emit late elements in CEP as sideOutputThis closes #6104,2
[FLINK-7866][runtime] Order preferred locations by score for scheduling.This closes #4949.,2
[hotfix][docs] add comment for TestTableSourceFactory,3
[hotfix][cep] Fix checkstyle violation in CEPOperatorTestThis closes #6117.,3
[FLINK-9517][docs] Fix broken links in CLI and Upgrade docsThis closes #6113.,2
[FLINK-9518][docs] Adjust password in SSL setup config exampleThis closes #6114.,5
[FLINK-8518] [table] Support EXTRACT(DOW ...) and document supported extraction unitsThis closes #6007.,4
[FLINK-8790][State] Improve performance of rescaling an incremental checkpointThis closes #5582.,1
[FLINK-9440][streaming] Expose cancelation of timers through timer service interface.This closes #6096.,2
[FLINK-7917] The return of taskInformationOrBlobKey should be placed inside synchronized in ExecutionJobVertexThis closes #5798,5
[FLINK-8430] [table] Implement stream-stream non-window full outer joinThis closes #6079.,2
[hotfix] [tests] Skip annotation processing for compiling tests,3
[FLINK-9109] [doc] Update documentation for CLIMake flip6 mode the default modeThis closes #5786.,1
[hotfix] [docs] Fix Scala code examples for Table API and SQL.This closes #6131.,0
[FLINK-9482] [table] EXTRACT function argument validation whether it is applicable for TIME typeThis closes #6121.,5
[hotfix][javadocs] Update OptionsFactory javadocsThe javadocs were outdated since FLINK-3718 (v1.1.0).This closes #6144.,2
[FLINK-9549][cep][docs] Fix broken links and missing quotesThis closes #6137.,3
[hotfix][docs] Properly initialize scala variableThis closes #6143.,5
[FLINK-9539][build] Integrate flink-shaded 4.0This closes #6128.,2
[FLINK-9508][docs] Fix spelling/punctuation errorsThis closes #6112.,0
[FLINK-8861] [sql-client] Add support for batch queries in SQL ClientThis closes #5660.,1
[hotfix] [sql-client] Fix NPE when column is null,0
[FLINK-9564][tests] Expose flink-end-to-end module directory to testsThis closes #6145.,3
[FLINK-9451][tests] Add scala quickstart end-to-end testThis closes #6089.,3
[FLINK-9398][cli] Only list non-terminal jobs in running section,1
[FLINK-9566][cli] Support listing all jobsThis closes #6049.,1
[FLINK-8946][metrics] Do not close TM MetricGroup on JobManager failoverThis closes #6060.,0
[FLINK-9368][py][tests] Add Python API E2E testThis closes #6127.,3
[FLINK-8768][network] Let NettyMessageDecoder inherit from LengthFieldBasedFrameDecoderThis replaces one additional step from the pipeline and does not only removeoverhead there but also allows use to override the #extractFrame() method torestore the old Netty 4.0.27 behaviour for non-credit based code paths whichhad a bug with Netty >= 4.0.28 there (see FLINK-8759).This closes #5570.,2
[FLINK-8759][network] preparations for the update of netty to version 4.1This closes #5571.,5
[hotfix] Correct preconditions check in TypeExtractor#getBinaryOperatorReturnType,4
"[FLINK-9458] Ignore SharedSlot in CoLocationConstraint when not using legacy modeThe SharedSlot in CoLocationConstraint is only set when using the legacy mode. Thus,CoLocationConstraint#isAssignedAlive should only check the SharedSlot if it waspreviously set. This fixes the NPE when restarting a job with a co-location constraintwhen using the new mode.This closes #6119.",1
[FLINK-3952][runtine] Upgrade to Netty 4.1This commit includes possible bug fix to file uploading cleanup in FileUploadHandler andHttpRequestHandler. For mor information look here:https://github.com/netty/netty/issues/7611This closes #6071.,0
[FLINK-9463][runtime] Fix support for epoll transport type in nettyFor more information please check https://github.com/apache/flink-shaded/issues/30,2
[hotfix][runtime-test] Rename BufferTest to NetworkBufferTestBufferTest was not testing a Buffer interface but NetworkBuffer class.,1
"[hotfix] Remove Netty shutdown work around in RestServerEndpointWith upgrading Netty to 4.1.24, it is no longer necessary to have the timeout safe guardwhen shutting down the Netty server in RestServerEndpoint.",1
[FLINK-9570] [sql-client] Fix merging of environmentsThis closes #6157.,0
[FLINK-8725] Separate state from NFA in CEP libraryThis also changes the serialization of state to not include the staticNFA parts and to also not include any user code.,1
[FLINK-8725] Reverted backward compatibility with <=1.5This closes #5960,4
[FLINK-9418] Migrate SharedBuffer to use MapState,1
[FLINK-9418] Separated pruning and element processing pathsThis closes #6059,1
[FLINK-9538] Make KeyedStateFunction an interfaceThis closes #6134,1
[FLINK-9572] Extend InternalAppendingState with internal stored state accessThis closes #6156.,2
[hotfix] Remove Scala dependency from ZooKeeperLeaderElectionTest,3
[FLINK-9573] Extend LeaderElectionService#hasLeadership to take leader session idThe new LeaderElectionService#hasLeadership also takes the leader session id and verifies whetherthis is the correct leader session id associated with the leadership.This closes #6154.,1
[hotfix] Fix checkstyle violations in SingleLeaderElectionService,0
[hotfix] Make TestingDispatcher and TestingJobManagerRunnerFactory standalone testing classesRefactors the DispatcherTests and moves the TestingDispatcher and the TestingJobManagerRunnerFactoryto be top level classes. This makes it easier to reuse them.,1
"[FLINK-9494] Fix race condition in Dispatcher with granting and revoking leadershipThe race condition was caused by the fact that the job recovery is executed outsideof the main thread. Only after the recovery finishes, the Dispatcher will set the newfencing token and start the recovered jobs. The problem arose if in between these twooperations the Dispatcher gets its leadership revoked. Then it could happen that theDispatcher tries to run the recovered jobs even though it no longer holds the leadership.The race condition is solved by checking first whether we still hold the leadership whichis identified by the given leader session id.This closes #6155.",1
[FLINK-9530][metrics] Fix numRecords task metric for chainsThis closes #6126.,0
"[FLINK-9257][tests] Fix wrong ""All tests pass"" messageThis closes #6053.",1
[FLINK-8744][docs] Add CommonOption annotationThis closes #5843.,1
[FLINK-9589][py] Make PythonOperationInfo immutable,5
[FLINK-9590][metrics] Make HistogramDump immutable,1
[FLINK-9591][py] Remove remnants of distributed-cache logic,2
[hotfix] Remove duplicate lines,4
[FLINK-8573] Extend ProgramInvocationException message with Job ID where applicableThis closes #6169.This closes #5421.,2
[FLINK-9366] DistributedCache works with Distributed File SystemThis closes #6107,5
[FLINK-9579][CEP]Remove unneeded clear on elementQueueStateThis closes #6162,4
[FLINK-9551][DOCS]FlinkCEP Scala Combining Patterns table has a missing patternThis closes #6139,5
[FLINK-9487][state] Prepare InternalTimerHeap for asynchronous snapshotsThis closes #6159.,2
[hotfix][state] Introduce hard size limit for CopyOnWriteStateTable,3
[FLINK-9601][state] Make sure that the copied array in `CopyOnWriteStateTable#snapshotTableArrays()` is big enough to hold all (flattened) entriesThis closes #6174.,3
[FLINK-9571] Repace StateBinder with internal backend-specific state factoriesThis closes #6173.,2
[FLINK-8982][e2e tests] Add E2E Tests for queryable state.Adds one test for normal execution andone with a TM failure scenario.This closes #5807.,0
[hotfix][tests] JobGraphTest extends TestLogger,3
[FLINK-9623][runtime] Move zipping logic out of blobserviceThis closes #6187.,2
[FLINK-9467][metrics][WebUI] Fix watermark displayThis closes #6152.,0
[FLINK-9467][metrics] Rebuild UI,2
[FLINK-9599][rest] Implement generic mechanism to access uploaded filesThis closes #6178.,2
[FLINK-8944] [Kinesis Connector] Use listShards instead of DescribeStream for shard discovery as it offer higher rate limitsThis closes #5992,1
[FLINK-8795] Fixed local scala shell for Flip6This closes #6182.,0
[hotfix] [docs] Fix a typo in index.mdThis closes #6193.,2
[FLINK-9394] [e2e] Test rescaling when resuming from externalized checkpointsThis closes #6038.,3
[FLINK-9638][E2E Tests] Add helper script to run single testThis commit adds a helper script `run-single-test.sh` that allows you to runa single test in the context of the text runner.This provides you with* Setup of ENV variables* cleanup after test* Nicer outputUsage: ./run-single-test.sh <path-to-test-script> [<arg1> <arg2> ...]This closes #6197.,3
[FLINK-9594][E2E tests] Improve docs for new test runnerThis closes #6172.,1
[FLINK-9374] [kinesis] Enable FlinkKinesisProducer backpressuringThis closes #9374.,2
[FLINK-9599][rest] RestClient supports FileUploadsThis closes #6189.,2
"[FLINK-9595] [kinesis, docs] Add instructions to docs about ceased support of KPL version used in Kinesis connector",1
[FLINK-9550][DOC]FlinkCEP snippet example has some syntax errorsThis closes #6138,0
[hotfix] Introduce builder for MiniClusterResourceConfiguration,5
[hotfix] Pass CodebaseType via the MiniClusterResourceConfiguration,5
[hotfix] Only run MiniClusterResource if specified CodebaseType equals actual CodebaseType,1
[hotfix] Make ActorSystemLoader in ClusterClient configurable,5
[hotfix] Add DefaultActorSystemLoader which returns the given ActorSystem,5
[hotfix] Start always ClusterClient for MiniClusterResource,5
[FLINK-9493] Forward cause when releasing a TaskManager at the SlotPoolThis closes #6202.,1
[FLINK-9646] [tests] Harden ExecutionGraphCoLocationRestartTest.testConstraintsAfterRestartNot only wait for resource assingment but until all Executions have reachedthe state DEPLOYING. That way it is assured that no Execution is still in stateSCHEDULED and will directly transition into the state CANCELED when callingExecution.cancel.,3
[FLINK-9585] Logger in ZooKeeperStateHandleStore is public and non-finalThis closes #6175.,0
[FLINK-7897] Use nio.Files for file deletion in TransientBlobCleanupTaskThis closes #5777.,4
[FLINK-9557] [formats] Parse 'integer' type as BigDecimalThis closes #6153.,2
[hotfix] Introduce SlotPoolFactory to make SlotPool instantiation configurable,5
[hotfix] Remove SlotIdleTimeout from JobMasterConfiguration,5
"[FLINK-9634] Disable local recovery scheduling if local recovery is disabledIntroduce a SchedulingStrategy which is used by the SlotPool to schedule tasks.The default implementation is LocationPreferenceSchedulingStrategy which triesto schedule tasks to their preferred locations. In order to support local recoverythe PreviousAllocationSchedulingStrategy schedules tasks to their previousallocation.The scheduling strategy is selected based on the configuration optionstate.backend.local-recovery. If set to true, then PreviousAllocationSchedulingStrategyis selected. Otherwise LocationPreferenceSchedulingStrategy is selected.This closes #6208.",1
[hotfix] Introduce SlotPoolResource and TestingRpcServiceResource,3
"[FLINK-8468][RabbitMQ] Make RabbitMQ connector to take advantage of AMQP features (routing key, exchange and message properties)[FLINK-8468] Make the connector to take advantage of AMQP features (routing key, exchange and message properties) and Test[FLINK-8468] Make the connector to take advantage of AMQP features (routing key, exchange and message properties) and Test[FLINK-8468] Make the connector to take advantage of AMQP features (routing key, exchange and message properties) and Test[FLINK-8468] Make the connector to take advantage of AMQP features (routing key, exchange and message properties) and Test[FLINK-8468] Make the connector to take advantage of AMQP features (routing key, exchange and message properties) and Test[FLINK-8468] Make the connector to take advantage of AMQP features (routing key, exchange and message properties) and TestFix test assertions and importsModified according to code reviews.[FLINK-8468] Take advantage of AMQP features (routing key, exchange, flags, message properties and returnListener)Update README.mdUpdate Readme.md[FLINK-8468] Take advantage of AMQP features (routing key, exchange, flags, message properties and returnListener)[FLINK-8468] Take advantage of AMQP features (routing key, exchange, flags, message properties and returnListener)[FLINK-8468] Take advantage of AMQP features (routing key, exchange, flags, message properties and returnListener)[FLINK-8468] Take advantage of AMQP features (routing key, exchange, flags, message properties and returnListener)",4
[FLINK-8468][RabbitMQ] Improve RabbitMQ connectorRemove text from README.md because it is covered by Javadocs.[FLINK-8468][RabbitMQ] Introduce SerializableReturnListener interface.[FLINK-8468][RabbitMQ] Update RMQSinkPublishOptions.Improve Javadocs.Add default implementation for methods computeMandatory and computeImmediate.[FLINK-8468][RabbitMQ] Replace statements with Preconditions.checkStateThis closes #5410.,2
[FLINK-9524] [table] Check for expired clean-up timers to prevent NPE in ProcTimeBoundedRangeOver.This closes #6180.,4
[FLINK-9580][rest] Close streams in RestClient#readRawResponseThis closes #6166.,1
[FLINK-9629][metrics] Include dependencies in datadog reporter jarThis closes #6191.,5
[hotfix][docs] Remove duplicate lineThis closes #6179.,4
[hotfix][table] Fix misleading exception messageThis closes #6163.,1
[FLINK-9677][rest] Cleanup encoder after request has been processedThis closes #6217.,4
[FLINK-9677][rest] Simplify logging,2
[FLINK-9624][runtime] Move jar/artifact upload out of jobgraphThis closes #6199.,4
[FLINK-9666] Use short-circuit logic in boolean contextsThis closes #6212.,2
[FLINK-8983] End-to-end test: Confluent schema registryThis closes #6083.,1
[FLINK-8983] Integrate test_confluent_schema_registry.sh into run-nightly-tests.sh,3
"[FLINK-9217][kafka-tests] Ignore testTimestamps for Kafka 0.10This test was deadlocking someimtes and for some reasons it appears not failing in Kafka 0.11.Disabling it for now, since this probably indicates there was a bug in Kafka 0.10that was fixed later in Kafka 0.11.This closes #6215This closes #6149",0
"[FLINK-9514,FLINK-9515,FLINK-9516] Introduce wrapper to enhance state with ttlThis closes #6186.",2
[FLINK-8067] User code ClassLoader not set before calling ProcessingTimeCallbackThis closes #6081,1
[FLINK-7775] Remove unreferenced method PermanentBlobCache#getNumberOfCachedJobs,1
[FLINK-9627] [table] Extending KafkaJsonTableSource according to comments will result in NPE.This closes #6198.,5
[hotfix] Remove unnecessary logging in Dispatcher#listJobs,2
[FLINK-9672] Fail fatally if job submission fails on added JobGraph signalThis closes #6213.,1
[FLINK-9532] Flink Overview of Jobs Documentation IncorrectThis closes #6125.,2
[hotfix] Remove deprecated parameter high-availability.zookeeper.storageDir from docThis closes #6229.,2
[FLINK-9684][historyserver] HistoryServer should initialize FileSystem before using itThis closes #6225.,1
[hotfix] Fixed typo in docsThis closes #6219.,2
[FLINK-9660] Allow passing custom artifacts to Mesos workersThis closes #6207.,1
[hotfix] Harden YARNSessionCapacitySchedulerITCase#testTaskManagerFailure by removing timeoutWe should wait until the runner has completed fully. Otherwise we might risk that theYarn application has not been fully shut down.,1
[FLINK-9456] Let ResourceManager notify JobManager about failed/killed TaskManagers.This closes #6132.,0
[FLINK-9456] Reuse TestingResourceActions in SlotManagerTest#testNotifyFailedAllocationWhenTaskManagerTerminated,3
[FLINK-9655][tests] Add missing parallelism parametersThis closes #6209.,2
[FLINK-4301] [docs] Make the quickstart's Flink version configurableThis closes #6204.,5
[FLINK-8650] [table] Add documentation and tests for WINDOW clause.This closes #6226.,1
[FLINK-9567][yarn] Only restart containers if there are pending slot requestsThe YarnResourceManager should only restart containers if it still has some pendingslot requests left. This solves the problem that upon restart of the YarnResourceManagerit can happen that one recovers containers from a previous attempt which are just aboutto be completed (the completion was triggered by the previous attempt). These containersshould not be restarted because they are no longer needed.This closes #6237.[FLINK-9567][runtime][yarn] Fix the bug that Flink does not release Yarn container when onContainerCompleted callback method happened after full restart,2
[hotfix][yarn] Extract number of task slots once from configurationLet the YarnResourceManager only extract the number of task slots once from theprovided configuration.,5
[FLINK-9665][metrics] Unregister individual metrics in PrometheusReporterThis closes #6239.,2
[hotfix][tests] Reuse existing functions for cleaning logs,2
[hotfix][tests] Simplify jar paths to QS tests,3
[FLINK-9674][tests] Replace hard-coded sleeps in QS E2E testThis closes #6216.This closes #6025.This closes #5297.This closes #6211.This closes #5899.This closes #5888.This closes #5901.,3
[FLINK-8654][docs] Extend project quickstarts on how to submit jobsThis closes #6084.This closes #6047.,2
[FLINK-9578] [sql-client] Allow to define an auto watermark interval in SQL ClientThis closes #6160.,1
[FLINK-9444] [formats] Add full SQL support for Avro formatsThis PR adds full support of Apache Avro records for the Table API & SQL. It adds (de)serialization schemas to the row type for both specific and generic records. It converts all Avro types to Flink types and vice versa. It supports both physical and logical Avro types. Both an Avro class or a Avro schema string can be used for format initialization.This closes #6218.This closes #6082.,5
[hotfix][core] Introduce MAX_ARRAY_SIZE as general constant,0
[FLINK-9491][state] Generalization of timer queue (decoupled from timers) and second implementation based on RocksDBThis closes #6228.,5
[FLINK-8785][rest] Handle JobSubmissionExceptions,0
[FLINK-9301][tests] Enable high-parallellism-iterations testThis closes #6024.,3
[hotfix][tests] Use utility functions for setting config,5
[FLINK-9280][rest] Rework JobSubmitHandler to accept jar/artifact filesThis closes #6203.,2
"[FLINK-9686] [kinesis] Allow creating AWS credentials by assuming a roleConfig example:```aws.credentials.provider: ASSUME_ROLEaws.credentials.provider.role.arn: <arn>aws.credentials.provider.role.sessionName: session-nameaws.credentials.provider.role.provider: AUTO```[FLINK-9686] [kinesis] Housekeeping: Use early return instead of variable assignment and break[FLINK-9686] [kinesis] Add dependency on aws-java-sdk-stsImplicitly (via `Class.forName`) used by `STSProfileCredentialsServiceProvider`.Due to shading, it is not possible to treat this as a ""provided"" dependency, asMaven rewrites the class name with the shaded one, which would force clients toprovide aws-java-sdk-sts shaded in the same way.[FLINK-9686] [kinesis] Mention new config option in docs[FLINK-9686] [kinesis] Use `STSAssumeRoleSessionCredentialsProvider` instead[FLINK-9686] [kinesis] Add constants for new config optionsThis closes #6221.",5
[FLINK-9695] Added mesos.resourcemanager.tasks.container.docker.force-pull-image optionThis closes #6232.,2
[FLINK-9633] Use Savepoint path's file system to create checkpoint output streamThis commit changes Flink such that it uses the savepoint path's file system togenerate the output stream instead of the checkpoint path's file system.This closes #6194.,5
[hotfix][network] checkstyle,0
[hotfix][network] add a few more checks and tags,1
[FLINK-9708][network] fix inconsistency with failed buffer redistribution,0
[hotfix][network] always destroy buffer pool in NetworkBufferPoolTest#testRequestMemorySegmentsInterruptable(),3
[FLINK-9636][network] fix inconsistency with interrupted buffer pollingThis closes #6238.,0
[FLINK-9708] Clean up LocalBufferPool if NetworkBufferPool#createBufferPool fails,0
[hotfix] Let NetworkBufferPoolTest extend TestLogger and make TestIOException static class,3
[FLINK-9513][state] Implement TTL state wrappers factory and serializer for value with TTLThis closes #6196.This closes #5799. (forgotten),2
[hotfix] Let LocalBufferPoolTest extend TestLogger,3
[hotfix] Use currentPoolSize in releaseMemory expression instead of numBuffers,1
[FLINK-9654] Changed the way we check if a class is anonymous to avoid SI-2034.,4
[FLINK-9654] Add InstantiationUtilTests for Scala types to flink-scalaThis closes #6206.,2
[FLINK-9707] Support concurrent directory creations in LocalFileSystemSupport concurrent directory creations by accepting directories which have beencreated by a different thread/process in LocalFileSystem#mkdirs.This closes #6243.,5
[FLINK-9622] Do not swallow exceptions in FileUtils#copyThis closes #6244.,2
[hotfix] Let DistributedCacheDfsTest extend TestLogger and avoid stdout output,3
"[FLINK-9693] Set Execution#taskRestore to null after deploymentSetting the assigned Execution#taskRestore to null after the deployment allows theJobManagerTaskRestore instance to be garbage collected. Furthermore, it won't bearchived along with the Execution in the ExecutionVertex in case of a restart. Thisis especially important when setting state.backend.fs.memory-threshold to largervalues because every state below this threshold will be stored in the meta state filesand, thus, also the JobManagerTaskRestore instances.This closes #6251.",2
[FLINK-9554][scala-shell] Respect customCommandlinesThis closes #6140.,2
[FLINK-9734][docs][sql] Fix typoThis closes #6249.,2
[FLINK-9729][docs][sql] Remove duplicate row for %WThis closes #6246.,4
"[FLINK-9676][network] clarify contracts of BufferListener#notifyBufferAvailable() and fix a deadlockWhen recycling exclusive buffers of a RemoteInputChannel and recycling(other/floating) buffers to the buffer pool concurrently while theRemoteInputChannel is registered as a listener to the buffer pool and adding theexclusive buffer triggers a floating buffer to be recycled back to the samebuffer pool, a deadlock would occur holding locks onLocalBufferPool#availableMemorySegments and RemoteInputChannel#bufferQueue butacquiring them in reverse order.One such instance would be:Task canceler thread -> RemoteInputChannel1#releaseAllResources -> recycle floating buffers-> lock(LocalBufferPool#availableMemorySegments) -> RemoteInputChannel2#notifyBufferAvailable-> try to lock(RemoteInputChannel2#bufferQueue)Task thread -> RemoteInputChannel2#recycle-> lock(RemoteInputChannel2#bufferQueue) -> bufferQueue#addExclusiveBuffer -> floatingBuffer#recycleBuffer-> try to lock(LocalBufferPool#availableMemorySegments)Therefore, we decouple the listener callback from lock aroundLocalBufferPool#availableMemorySegments and implicitly enforce thatRemoteInputChannel2#bufferQueue takes precedence over this lock, i.e. mustbe acquired first and should never be taken after having locked onLocalBufferPool#availableMemorySegments.This closes #6257.",1
[hotfix][filesystem] Remove incorrect equals methods in StreamWritersThis closes #6262.,4
"[FLINK-8479] Add TimeBoundedStreamJoinOperator.Adds an implementation of an operator for interval joins.The timestamp of a joined pair for now is the max timestampof the elements in the pair. In addition, it contains thestate for outer joins in the future.This closes #5342.",1
[FLINK-9588][cep] Reused context with same computation state calculateThis cloes #6168,1
[FLINK-6469][core] Configure Memory Sizes with unitsThis closes #5448,5
[FLINK-9593][cep] Unified After Match semantics with SQL MATCH_RECOGNIZEThis closes #6171,2
[FLINK-9757] Fix typosThis closes #6258.,2
[FLINK-9681] [table] Enforce 5 minute difference between minRetentionTime and maxRetentionTime.This closes #6255.,1
[FLINK-9581] [docs] Remove white spaces to align COLLECT code example.This closes #6161,4
[FLINK-9742] [table] Add helper method to access private Expression.resultType.This closes #6252.,1
"[FLINK-8094] [table] Extend ExistingField rowtime extractor to support ISO date strings.This closes #6253.- This patch proposes improvement of ExistingField which handles ISO dateformatted  String type as well as Long and Timestamp types.- Add test code to cover ExistingField's new behavior.  The credit for test code should go to @xccui, since I copied the test method from below commit:  https://github.com/xccui/flink/commit/afcc5f1a0ad92db08294199e61be5df72c1514f8- Document new behavior of ExistingField to sourceSinks.md.",1
[FLINK-9770][rest] Fix jar listingThis closes #6269.,0
[FLINK-9769][rest] Clear FileUpload attribute after accessThis closes #6270.,2
"[FLINK-9659][tests] Replace hard-coded sleeps in bucketing end-to-end testThis PR replaces hard-coded sleeps in the bucketing sink end-to-end test.Instead we use utility functions to wait for specific events, in this case some progress in the job (measured by number of checkpoints) and the job finishing (by waiting for FINISHED state).This closes #6210.",5
"[FLINK-9352] Choose initial checkpoint delay randomly to reduce I/O pressureBy choosing the initial checkpoint delay randomly from[minPauseBetweenCheckpoints, baseInterval] we avoid that multiple restarting jobshave synchronized checkpoints. This can cause otherwise significant I/O pressure.This closes #6092.",1
[hotfix][RAT] Add generated avro java codes to RAT exclusion listThis closes #6256.,1
[FLINK-9772][docs] Update Hadoop compatibility docs regarding HadoopInputsThis closes #6278.,2
"[FLINK-9603] Fix part counter loop in BucketingSink to account for part suffix.1. all logic, that is responsible for path assembly moved into method;2. test logic of part file indexing, when in-progress/ pending/ final   part files already exists in bucket;3. test the same logic, when part file has suffixThis closes #6176.",0
[FLINK-9486][state] Introduce InternalPriorityQueue as state in keyed state backendsThis commit does not include the integration with checkpointing.This closes #6276.,2
[FLINK-8863] [sql-client] Add user-defined function support in SQL ClientThis closes #6090.,1
[FLINK-8863] [sql-client] Make user-defined functions more robust- Simplify code and fix various bugs- Add more tests- Refactor various names for descriptors and variables- Make 'from' property mandatory- Make LiteralValue public API,1
[FLINK-9691] [kinesis] Modify runloop to try to track a particular getRecords() frequency.This closes #6290,1
[FLINK-9776] [runtime] Stop sending periodic interrupts once executing thread leaves user function / operator code.This closes #6275,1
[FLINK-9470] Allow querying the key in KeyedProcessFunction,1
[FLINK-9743][client] Use correct zip path separator for nested jarsThis closes #6263.,1
[FLINK-9789][metrics] Ensure uniqueness of watermark metricsThis closes #6292.,2
[FLINK-9187][metrics] Add Prometheus PushGateway reporterThis closes #6184.,1
[FLINK-9730][refactor] Fix static accesses via instance referenceThis closes #6247.,0
[FLINK-9666][refactor] Use short-circuit logic in boolean contextsThis closes #6230.,2
[FLINK-9584][connector] Properly close output streams in Bucketing-/RollingSinkThis closes #6164.,2
[hotfix][rat] Add *.snapshot files to RAT exclusion listThis closes #6295.,2
[FLINK-9768][release] Speed up binary releaseThis closes #6285.,1
[FLINK-9754][release] Remove references to scala profilesThis closes #6286.,2
"[FLINK-5363] Fire timers when window state is currently emptyBefore, a window Trigger would not be invoked if the window is empty atthe time of the timer firing. Now the Trigger is always invoked.As a side effect, this resolves FLINK-9687.",2
[FLINK-5363] Clarify Trigger behaviour for empty windows,2
[FLINK-9511] Implement state TTL configurationThis closes #6277.,5
"[FLINK-9706] Properly wait for termination of JobManagerRunner before restarting jobsIn order to avoid race conditions between resource clean up, we now wait for the propertermination of a previously running JobMaster responsible for the same job (e.g. originatingfrom a job recovery or a re-submission).This closes #6279.",1
"[FLINK-9809] [DataSteam API] Allow setting co-location constraints on StreamTransformations.This feature is currently only exposed on StreamTransformations (internal API) ratherthan in the public API, because it is a hidden expert feature.This closes #6309",1
[FLINK-9785][network] add remote address information to LocalTransportException instancesThis closes #6291,5
[hotfix][checkstyle] fix checkstyle in PartitionRequestClientFactory,0
"[FLINK-9766][network][tests] fix cleanup in RemoteInputChannelTestIf an assertion in the test fails and as a result the cleanup fails, in mosttests the original assertion was swallowed making it hard to debug.Furthermore, #testConcurrentRecycleAndRelease2() does even not clean up at allif successful.This closes #6271",4
[FLINK-9784] Fix inconsistent use of 'static' in AsyncIOExample.javaThis closes #6298.,1
[FLINK-9799][state] Generalize and unify state meta infosThis closes #6308.,5
[FLINK-9804][state] Fix KeyedStateBackend.getKeys() for RocksDBMapState.This closes #6306.,5
[hotfix] Correct checkstyle violations in RestartStrategies,0
[FLINK-9701] Introduce TTL configuration in state descriptorsThis closes #6313.,5
"[FLINK-8480][DataStream] Add APIs for Interval Joins.This adds the Java and Scala API for performing an IntervalJoin.In jave this will look like:Example:```javakeyedStream.intervalJoin(otherKeyedStream)    .between(Time.milliseconds(-2), Time.milliseconds(2)) // lower and upper bound    .upperBoundExclusive(true) // optional    .lowerBoundExclusive(true) // optional    .process(new IntervalJoinFunction() {...});```This closes #5482.",5
[hotfix] Fixed import order in RocksDBKeyedStateBackend.,5
[FLINK-9563][cep][tests] Migrate CEPITCase to collect()This closes #6170.,3
[FLINK-9801][build] Add missing example dependencies to flink-distThis closes #6304.,2
[FLINK-9810][rest] Close jar file in JarListHandlerThis closes #6310.,0
[FLINK-9771][rest] Fix plan JSON responseThis closes #6274.,1
[FLINK-9091][build] Dependency convergence run against dependency-reduced pomsThis closes #6102.,1
"[FLINK-9424] [security] Set default cipher suite to a more compatible cipher suite.The upgraded ciphers are not yet supported on all platforms and JDK versions, makingthe getting-started process rough. Instead, we document our recommendation to set thesevalues in the configuration.This reverts ""[FLINK-9310] [security] Update standard cipher suites for secure mode""",5
[FLINK-9807][tests] Parameterize EventTimeWindowCheckpointITCase & LocalRecoveryITCaseThis closes #6305.,1
[FLINK-9503] Migrate integration tests for iterative aggregatorsThis closes #6129.,3
"[FLINK-9004][tests] Implement Jepsen tests to test job availability.Use the Jepsen framework (https://github.com/jepsen-io/jepsen) to implementtests that verify Flink's HA capabilities under real-world faults, such assudden TaskManager/JobManager termination, HDFS NameNode unavailability, networkpartitions, etc. The Flink cluster under test is automatically deployed on YARN(session & job mode) and Mesos.Provide Dockerfiles for local test development.This closes #6240.",3
"[FLINK-9703] Allow TM ports to be exposed through MesosMaintain a deterministic port ordering, so we can have expectations on which endpoint is behind which port index.This closes #6288.",5
"[hotfix] Make PackagedProgram(Class<?>, String...) constructor public",1
"[FLINK-9818] Add cluster component command line parserThe cluster component command line parser is responsible for parsing the common command linearguments with which the cluster components are started. These include the configDir, webui-portand dynamic properties.This closes #6314.",5
[FLINK-9488] Add container entry point StandaloneJobClusterEntryPointThe StandaloneJobClusterEntryPoint is the basic entry point for containers. It is started withthe user code jar in its classpath and the classname of the user program. The entrypoint willthen load this user program via the classname and execute its main method. This will generatea JobGraph which is then used to start the MiniDispatcher.This closes #6315.,5
[FLINK-9819] Add startup scripts for standalone job cluster entry pointThis closes #6316.,1
[FLINK-9820] Forward dynamic properties to Flink configuration in ClusterEntrypointWith this commit we can use dynamic properties to overwrite configuration values in theClusterEntrypoint.This closes #6317.,1
[FLINK-9821] Forward dynamic properties to configuration in TaskManagerRunnerWith this commit we can use dynamic properties to overwrite configuration values in theTaskManagerRunner.This closes #6318.,1
[FLINK-9822] Add Dockerfile for StandaloneJobClusterEntryPoint imageThis commit adds a Dockerfile for a standalone job cluster image. The imagecontains the Flink distribution and a specified user code jar. The entrypointwill start the StandaloneJobClusterEntryPoint with the provided job classname.This closes #6319.,1
"[FLINK-9823] Add Kubernetes deployment ymlsThe Kubernetes files contain a job-cluster service specification, a job specificationfor the StandaloneJobClusterEntryPoint and a deployment for TaskManagers.This closes #6320.",1
[hotfix] Support building a job image from a Flink archiveExtend the flink-container/docker/build.sh script to also accept a Flink archive to buildthe image from. This makes it easier to build an image from one of the convenience releases.,1
[FLINK-9619] Eagerly close the connection with task manager when the container is completed.This closes #6185.,2
[FLINK-9143] Use cluster strategy if none was set on client sideAdded NoOrFixedIfCheckpointingEnabledRestartStrategyThis closes #6283.,0
"[FLINK-9701] [state] (follow up) Use StateTtlConfiguration.DISABLED instead of null, make it Serializable and addconvenience methods to its builderThis closes #6331.",1
"[FLINK-8558] [table] Add unified format interfaces and separate formats from connectorsThis PR introduces a format discovery mechanism based on Java Service Providers. The general `TableFormatFactory` is similar to the existing table source discovery mechanism. However, it allows for arbirary format interfaces that might be introduced in the future. At the moment, a connector can request configured instances of `DeserializationSchema` and `SerializationSchema`. In the future we can add interfaces such as a `Writer` or `KeyedSerializationSchema` without breaking backwards compatibility.This PR deprecates the existing strong coupling of connector and format for the Kafa table sources and table source factories. It introduces descriptor-based alternatives.",4
[FLINK-8866] [table] Create unified interfaces to configure and instatiate TableSinksThis closes #6201.,5
[FLINK-8866] [table] Merge table source/sink/format factories- Rename to TableFactory and move it to org.apache.flink.table.factories package- Unify source/sink/format factories with same logic and exceptions,2
[FLINK-8866] [table] Move table type out of descriptorsThe declaration of a table type is SQL Client/context specific and should not be part of a descriptor.,4
[FLINK-8866] [table] Make source/sink factories environment-dependentUsually it is very uncommon to define both a batch and streaming source in the same factory. Separating by environment is a concept that can be find throughout the entire flink-table module because both sources and sinks behave quite different per environment.This closes #6323.,1
[FLINK-9404] [file sink] Bucketing sink uses target directory rather than home directory during reflectTruncateThis closes #6050,1
[FLINK-8544] Handle null message key and value in JSONKeyValueDeserializationSchemaThis closes #5516,5
[FLINK-9483] 'Building Flink' doc doesn't highlight quick build commandThis closes #6109,2
[FLINK-9758] Fix ContinuousFileProcessingTest failure due to not setting runtimeContextThis closes #6260,1
[FLINK-8858] [sql-client] Add support for INSERT INTO in SQL ClientThis closes #6332.,1
[hotfix] [core] Fix checkstyle in flink-core:'org.apache.flink.api.common.io.compression',2
[hotfix] [core] Fix checkstyle workaround in FileSystem,5
[hotfix] [core] Remove unused class AbstractMultiFSDataInputStream,5
[FLINK-9751] [filesystem] Add PersistentResumableWriter interface.,1
[FLINK-9751] [filesystem] Add fixes and tests for Persistent Resumable Writers,3
[FLINK-9751] [filesystem] Use FileChannel directly in LocalRecoverableFsDataOutputStream,5
"[FLINK-9313] [security] (part 1) Instantiate all SSLSocket and SSLServerSocket through factories.This removes hostname verification from SSL client sockets.With client authentication, this is no longer needed and it is not compatible withvarious container environments.",4
"[FLINK-9313] [security] (part 2) Split SSL configuration into internal (rpc, data transport, blob server) and external (REST)This also uses SSLEngineFactory for all SSLEngine creations.",1
[FLINK-9313] [security] (part 3) Activate mutual authentication for RPC/akka,2
[FLINK-9314] [security] (part 4) Add mutual authentication for internal Netty and Blob Server connectionsThis closes #6326.,1
[hotfix] Let SSLUtilsTest and NettyClientServerSslTest extend TestLogger,3
[hotfix] Fix typo in AkkaRpcService,2
[hotfix] Speed up RpcSSLAuthITCase by setting TCP timeout to 1s,1
[FLINK-8731] Replaced mockito with custom mock in TestInputChannelThis closes #6338,3
[FLINK-9380][tests] Do not delete logs on E2E test failureThis closes #6289.,0
[FLINK-9842][rest] Pass actual configuration to BlobClientThis closes #6340.,5
[FLINK-9839][tests] Add support for SSL to e2e-testsThis closes #6327.,3
[FLINK-9865] [build] Set Hadoop dependency to 'provided' in flink-hadoop-compatibility,2
[FLINK-9750] [DataStream API] Add new StreamingFileSink on top of the ResumableWriter.,2
[FLINK-9489] Checkpoint timers as part of managed keyed state instead of raw keyed stateOptimization for relaxed bulk pollsDeactivate optimization for now because it still contains a bugThis closes #6333.,0
[hotfix] Add EXCLUSIONS set to ConfigOptionsDocGenerator,5
[hotfix] Consolidate RocksDB configuration options in RocksDBOptionsRename from backend.rocksdb.priority_queue_state_type into state.backend.rocksdb.timer-service.impl,5
[hotfix] Rename PriorityQueueStateType.ROCKS into PriorityQueueStateType.ROCKSDB,5
"[hotfix] Use default value of RocksDBOptions#TIMER_SERVICE_IMPLIn order to fully enable the RocksDBOptions#TIMER_SERVICE_IMPL we should use the default valueof this config option instead of """".",5
[hotfix] Harden RocksDBAsyncSnapshotTest#testCancelFullyAsyncCheckpointsDepending on RocksDBOptions#TIMER_SERVICE_IMPL we have to adapt the testCancelFullyAsyncCheckpoints wrthow many checkpointing streams we skip.,3
Update version to 1.7-SNAPSHOT,5
[FLINK-9692] [kinesis] Adaptive reads from KinesisThis closes #6300,2
[FLINK-9692] [kinesis] Harmonize style of config variable names,5
[FLINK-9857] Delay firing of processing-time timers by 1 ms,2
[FLINK-9880] Fix order in BucketerContext#update.,5
[FLINK-9777] YARN: JM and TM Memory must be specified with UnitsThis closes #6297,2
"[hotfix] Harden JarUploadHandlerTest#testUploadJarUse lastIndexOf(""_"") instead of indexOf(""_"") in order to find the file name part",2
[hotfix][rest] Simplify dispatcher host retrievalAdjusted to work like the JobSubmitHandler.,0
[FLINK-9811][test] Add test for jar handler interactionsThis closes #6311.,0
[hotfix] Properly stop Flink Yarn application in YARNSessionFIFOITCase#testJavaAPICalls ClusterClient#shutDownCluster in order to stop the Flink Yarn application,2
[FLINK-9793][yarn] Fix flink-dist detection to prevent duplicate uploadThis closes #6296.,2
[FLINK-9866] Allow passing command line arguments to standalone jobThis closes #6344,4
[FLINK-9792] Added custom Description class for ConfigOptions to enable rich formatting.This closes #6312,0
[FLINK-9866][hotfix] Pass program arguments last to standalone-job.sh,4
[FLINK-9575] Remove job-related BLOBS only if the job was removed sucessfullyThis closes #6322.,4
"[FLINK-9575][tests] Simplify DispatcherTest#testBlobsAreRemovedOnlyIfJobIsRemovedProperlyMove DispatcherTest#testBlobsAreRemovedOnlyIfJobIsRemovedProperly into DispatcherResourceCleanupTestand split it up into a success and failure case.Moreover, this commit changes the logic of blob cleanup to also cleanup locally in case of a removalfailure of a job from a SubmittedJobGraphStore.",4
[FLINK-9872][tests] Properly cancel test jobThis closes #6349.,3
[FLINK-9815][yarn][tests] Harden tests against slow job shutdownsThis closes #6352.,3
[FLINK-9499][rest] Support JSON request in JarHandlersThis closes #6330.,0
[hotfix] [sql-client] Fix typo in SqlExecutionExceptionThis closes #6364.,2
[hotfix] [docs] Update docs about streaming joins,2
[FLINK-9881] [table] Fix a typo in table.scalaThis closes #6354.,2
[FLINK-9748][release] Use dedicated directory for release artifactsThis closes #6342.,1
[FLINK-9762][yarn] Use local default tmp directories on Yarn and MesosThis closes #6284.,1
[FLINK-9762] Consolidate configuration cloning in BootstrapTools,5
[hotfix] Fix checkstyle violations in BootstrapTool,0
[FLINK-9860][REST] fix buffer leak in FileUploadHandlerChange the parent's instance of SimpleChannelInboundHandler to auto-releaseobjects and make sure we retain them only when needed.-> This should be the safer approach to not leaking.Enable Netty resource leak detection for FileUploadHandlerTest and have the test fail on detection.This closes #6363.,0
[FLINK-9871] Use Description class for ConfigOptions with rich formattingThis closes #6371,5
[FLINK-9755][network] forward exceptions in RemoteInputChannel#notifyBufferAvailable() to the responsible threadThis mainly involves state checks but previously these have only been swallowedwithout re-registration or any other logging/handling. This may have lead tosome thread stalling while waiting for the notification that never came.This closes #6272.,2
[FLINK-9435][java] optimise ComparableKeySelector and ArrayKeySelector for more efficient Tuple creationBenchmark results (2 runs) by running the benchmarks fromhttps://github.com/dataArtisans/flink-benchmarks/pull/5:Benchmark                    Mode  Cnt     Score    Error   Units================= old =================KeyByBenchmarks.arrayKeyBy  thrpt   30  1151.305  21.096  ops/msKeyByBenchmarks.arrayKeyBy  thrpt   30  1117.486  43.508  ops/msKeyByBenchmarks.tupleKeyBy  thrpt   30  1659.634  28.627  ops/msKeyByBenchmarks.tupleKeyBy  thrpt   30  1554.265  82.604  ops/ms================= new =================KeyByBenchmarks.arrayKeyBy  thrpt   30  1150.552  51.185  ops/msKeyByBenchmarks.arrayKeyBy  thrpt   30  1195.777  10.621  ops/msKeyByBenchmarks.tupleKeyBy  thrpt   30  1743.633  27.109  ops/msKeyByBenchmarks.tupleKeyBy  thrpt   30  1697.885  22.101  ops/msThis closes #6115.,1
"[FLINK-7251] [types] Remove the flink-java8 module and improve lambda type extractionThis commit removes the flink-java8 module and merges some tests into flink-core/flink-runtime. It ensures to have the possibility for passing explicit type information in DataStream API as a fallback. Since the tycho compiler approach was very hacky and seems not to work anymore, this commit also removes all references in the docs and quickstarts.This closes #6120.",2
"[FLINK-9852] [table] Expose descriptor-based sink creation and introduce update modeThis commit exposes the new unified sink creation through the table environments and the external catalog table. It introduce a new update-mode property in order to distinguish between append, retract, and upsert table sources and sinks. This commit refactors the top-level API classes a last time and adds more documentation. This commit completes the unified table sources/sinks story from an API point of view.Brief change log:- Introduction of TableEnvironment.connect() and corresponding API builder classes- Introduction of property update-mode: and update of existing connectors- External catalog support with proper source/sink discovery and APIThis closes #6343.",1
[FLINK-9886] [sql-client] Build SQL jars with every buildThis closes #6366.,2
[FLINK-9858][tests] State TTL End-to-End TestThis closes #6361.,3
[FLINK-9902][tests] Improve and refactor window checkpointing IT casesThis closes #6376.,4
[FLINK-9903] [DataStream API] Refactor StreamingFileSink / add bulk encoders* Add supports for bulk encoders.* Expose more options in the rolling policy and* Allows to return any object as bucket id from the bucketer.,1
[FLINK-9753] [formats] Add a Parquet BulkWriter,1
[hotfix] [core] Align serialization methods in SimpleVersionedSerialization,0
[hotfix] Fix loop in FailingSource,0
[FLINK-9185] [runtime] Fix potential null dereference in PrioritizedOperatorSubtaskState#resolvePrioritizedAlternativesThis closes #5894.,0
[FLINK-9890][Distributed Coordination] Remove obsolete class ResourceManagerConfigurationThe configuration values are effectively not used. This commit removes the classand all its usages.This closes #6368.,4
[hotfix] [table] Deprecate SchemaValidator#deriveTableSinkSchemaThe method combines two separate concepts of table schema and fieldmapping. This should be split into two methods once we have supportfor the corresponding interfaces (see FLINK-9870).,2
[FLINK-9895][tests] Ensure error logging for NettyLeakDetectionResourceThis closes #6374.,2
[FLINK-9888][release] Remove unsafe defaults from release scriptsThis closes #6362.,4
[FLINK-9873][runtime] Log task state when aborting checkpointThis closes #6350.,2
[FLINK-9841][rest] Close log file channel after response was fully writtenThis closes #6329.,2
[FLINK-9805][rest] Catch JsonProcessingException in RestClientThis closes #6307.This closes #6116.This closes #6142.,5
[hotfix] [sql-client] Wrap exceptions thrown during environment instance creation,1
[FLINK-9921][DataStream API] Update RollingPolicy interface,5
"[FLINK-9846] [table] Add a Kafka table sink factoryAdds a Kafka table sink factory with format discovery. Currently, this enablesthe SQL Client to write Avro and JSON data to Kafka. The functionality islimited due to FLINK-9870. Therefore, it is currently not possibleto use time attributes in the output.Changes:- Decouple Kafka sink from formats and deprecate old classes- Add a Kafka table sink factory- Existing tests for the KafkaTableSourceFactory have been  generalized to support sinks as well.This closes #6387.",1
[FLINK-9838][logging] Don't log slot request failures on the ResourceManagerThis closes #6373.,0
[hotfix] Improve logging of SlotPool and SlotSharingManager,2
"[FLINK-9908][scheduling] Do not cancel individual scheduling futureSince the individual scheduling futures contain logic to release the slot if it cannotbe assigned to the Execution, we must not cancel them. Otherwise we might risk thatslots are not returned to the SlotPool leaving it in an inconsistent state.This closes #6383.",2
"[FLINK-9909][core] ConjunctFuture does not cancel input futuresIf a ConjunctFuture is cancelled, then it won't cancel all of its inputfutures automatically. If the users needs this behaviour then he has toimplement it explicitly. The reason for this change is that an implicitcancellation can have unwanted side effects, because all of the cancelledinput futures' producers won't be executed.This closes #6384.",1
[hotfix] Fix checkstyle violations in FutureUtils,0
"[hotfix] Replace check state condition in Execution#tryAssignResource with if checkInstead of risking an IllegalStateException it is better to check that thetaskManagerLocationFuture has not been completed yet. If, then we also rejectthe assignment of the LogicalSlot to the Execution. That way, we don't riskthat we don't release the slot in case of an exception inExecution#allocateAndAssignSlotForExecution.",2
[hotfix] Fix checkstyle violations in ExecutionVertex,0
[hotfix] Fix checkstyle violations in ExecutionJobVertex,0
[hotfix] Fix checkstyle violations in Execution,0
"[FLINK-9910][scheduling] Execution#scheduleForeExecution does not cancel slot futureIn order to properly give back an allocated slot to the SlotPool, one must not completethe result future of Execution#allocateAndAssignSlotForExecution. This commit changes thebehaviour in Execution#scheduleForExecution accordingly.This closes #6385.",4
"[FLINK-9911][JM] Use SlotPoolGateway to call failAllocationSince the SlotPool is an actor, we must use the SlotPoolGateway to interact withthe SlotPool. Otherwise, we might risk an inconsistent state since there aremultiple threads modifying the component.This closes #6386.",1
[FLINK-9892][tests] Disable local recovery in Jepsen tests.This closes #6369.,3
[FLINK-9862] [test] Extend general puropose DataStream test to have a tumbling windowThis closes #6351.,3
[FLINK-9765] [sql-client] Improve CLI responsiveness when cluster is not reachableMoves the job cancellation into the final phase of the refresh thread in order tokeep the CLI responsive.This closes #6265.,4
"[FLINK-5750] [table] Fix incorrect translation of n-ary Union.In certain cases, Calcite produces union operators with more than two input relations.However, Flink's translation rules only considered the first two relationsThis closes #6341.",2
[FLINK-9296] [table] Add support for non-windowed DISTINCT aggregates.This closes #6393.,1
[FLINK-9296] [table] Add documentation for DISTINCT aggregates,2
[FLINK-9923][tests] Harden OneInputStreamTaskTest#testWatermarkMetricsMake WatermarkGauge's currentWatermark field volatile because writesand reads can happen from different threads.This closes #6398.,1
"[FLINK-9934] [table] Fix invalid field mapping by Kafka table source factoryAccording to the DefinedFieldMapping interface the field mapping can also containthe input fields. However, the Kafka table source factory was callingSchemaValidator#deriveFieldMapping with its own schema instead of the input type.This closes #6403.This closes #3124.",5
[FLINK-9694][table] Fix NPE in CRowSerializerConfigSnapshot constructorThis closes #6392.,5
[FLINK-6222] Update config.sh to look for a Hadoop and/or YARN configuration directoriesThis just adds to the config.sh to allow setting YARN_CONF_DIR and HADOOP_CONF_DIRwith the Flink configuration file.This closes #6388,2
[FLINK-6222] Documented YARN and HADOOP conf dir options.This closes #6388,5
[hotfix][tests] Enrich timeout exception messageThis closes #6414.,1
[FLINK-9946][tests] Update quickstart E2E script for 1.7,5
[FLINK-9806][docs] Add canonical linkThis closes #6396.,2
[FLINK-9914][docs] Update Docker docs,2
[FLINK-9949][tests] Kill Flink processes in DB/teardown!This closes #6419.,5
[hotfix][tests] Fix checkstyle violations in BootstrapToolsTest.,3
[FLINK-9939][runtime] Add null check before setting tmp dirs in config.This closes #6418.,5
"[hotfix] [table] Remove wrong ISO references for timestamp extractionThe docs and timestamp extractors mention ISO timestamps, however, accordingto ISO 8601 timestamps have a different format.",4
[FLINK-5860] [tests] Replace java.io.tmpdir with JUnit TemporaryFolder in testsJUnit's TemporaryFolder is a better way to handle temporary foldersin tests as JUnit takes care of creation and cleanup of temporaryfolders automatically.This closes #6399.,4
[FLINK-9236] [build] upgrade the version of apache parent pom from 18 to 20This closes #6378.,2
"[hotfix][docs] Use Fedora for Docker docs buildThe docs require Ruby >= 2.1.0 which isn't shipped by CentOS 7. It isavailable in Fedora 28, however, and I don't see any harm in switchingto it.",1
[FLINK-9927][py][docs] Change .print() to .output(),4
[FLINK-9916] Add FROM_BASE64 function for table/sql APIThis closes #6397.,1
[FLINK-9353] Added end to end test for standalone embedded job run in docker,2
[FLINK-9353] Added end to end test for standalone embedded job in kubernetes,3
[FLINK-9928] Add LOG2 function for table/sql APIThis closes #6404.,1
[hotfix] Resolve symbolic links in test scripts,3
"[FLINK-8981] Add end-to-end test for running on YARN with KerberosThis adds a complete Docker container setup and Docker Compose file forstarting a kerberized Hadoop cluster on Docker.The test script does the following: * package ""build-target"" Flink dist into a tarball * build docker container * start cluster using docker compose * upload tarball and unpack * modify flink-conf.yaml to use Kerberos keytab for hadoop-user * Run Streaming WordCount Job * verify resultsWe set an exit trap before to ensure that we shut down the dockercompose cluster at the end.",2
[FLINK-9944][tests] Cleanup end-to-end test poms,3
[FLINK-9935] [table] Fix incorrect group field access in batch window combiner.,0
[FLINK-9951][build] Update scm developerConnection,5
[FLINK-9942][rest] Guard handlers against null fields,0
[FLINK-8439] Add Flink shading to AWS credential provider s3 hadoop config,5
[FLINK-9994][DataStream API] IntervalJoinOp Context#getTimestamp() returns max timestamp.This closes #6449.,1
[FLINK-9900][tests] Harden ZooKeeperHighAvailabilityITCase,3
[FLINK-8974] Run all-round DataSet job with failures in HA mode,0
[FLINK-8993] [tests] Let general purpose DataStream job uses KryoSerializer via type extractionThis closes #6413.,4
[FLINK-8994] [tests] Let general purpose DataStream job include Avro as stateThis closes #6435.,5
[FLINK-9987][tests] Harden ClassLoader E2E test,3
[FLINK-9976][streaming] Rework StreamingFileSink builders,2
[FLINK-9985][docs] Fix parameter order in windowing example,2
[hotfix][javadocs] Fix typo,2
[hotfix] Move Bucketer interface to file sink base packageThis brings it in line with RollingPolicy.,1
[hotfix] Rename rolling.policies to rollingpolicies in file sink packages,2
[FLINK-9996][fs] Wrap exceptions during FS creation,1
[FLINK-9790] [docs] Add documentation for UDFs in SQL ClientThis closes #6356.,2
[FLINK-9159][mesos] Set default value of mesos.failover-timeout to 1 week.,0
[FLINK-9159][runtime] Deprecate config key slotmanager.request-timeout- Replace config key slotmanager.request-timeout with slot.request.timeout becauseboth keys have effectively the same semantics.- Rename key slotmanager.taskmanager-timeout toresourcemanager.taskmanager-timeout.This closes #6406.,1
[hotfix][docs] Add -DskipTests flag to command that generates docs.,2
[FLINK-9978][release] Include relative path in source release sha fileThis closes #6436.,2
[FLINK-9972][flip6] Handle debug memory logging in flip6Debug memory logging was being ignored in flip6 code and wasonly supported in legacy code/mode.This closes #6431.,1
[FLINK-9986][build] Only include commit info in .version.properties file,2
[FLINK-9988][rest] Add deprecated keys for server bind address,1
[FLINK-9988][rest] Add RestOptionTest for deprecated BIND_ADDRESS keysThis closes #6441.,1
[FLINK-9877][docs] Add documentation page for different datastream joins,5
[FLINK-10005][DataStream API] StreamingFileSink: initPartCounter=maxUsed in new BucketsThis closes #6466.,1
"[FLINK-9874][E2E Tests] Fix set_ssl_conf for macOSThis fixes the set_ssl_conf utility function under macOS. The previousversion was using `hostname -I` regardless of the OS, but the -I optionis not available on the BSD version of hostname.This is now fixed by checking for all IPv4 addresses from ifconfig if theOS is macOS and formatting the output to be identical to `hostname -I`.Additionally the filtering of the output is removed so that now allip addresses are appended to the SANSTRING instead of just one.This closes #9874.",1
[FLINK-9946][tests] Expose Flink version to E2E tests,3
[FLINK-9897] Make adaptive reads depend on run loop time instead of fetch interval millisThis closes #6408.,1
[FLINK-9926][Kinesis Connector] Allow for ShardConsumer override in Kinesis consumer.This closes #6427.,1
[FLINK-7386] [elasticsearch] Evolve ES connector API to make it working with Elasticsearch 5.3+This closes #6043.,1
[FLINK-8101] [elasticsearch] Elasticsearch 6.X REST support,1
[FLINK-9885] [tests] Add Elasticsearch 6.x end-to-end test,3
[FLINK-9885] [elasticsearch] Major cleanup to finalize Elasticsearch 6.x connectorThis closes #6391.,4
"[FLINK-10016] Make YARN/Kerberos end-to-end test stricterThis change ensures that Flink containers are spread across the twoavailable NMs. Before, it could happen that all containers are scheduledon one NM, which wouldn't trigger FLINK-8286.This also extends logging output and reduces the slot wait time.",2
"[FLINK-9979] [table] Support a FlinkKafkaPartitioner for Kafka table sink factoryAdds the possibility to add a FlinkKafkaPartitioner to a Kafka table sinkfactory. It povides shortcuts for the built-in ""fixed"" and ""round-robin"" partitioning.This closes #6440.",0
[FLINK-10021][tests] Update operator name when querying metrics,1
[FLINK-9981][state] Testing and performance tuning for RocksDB-based priority queueThis closes #6438.,5
[FLINK-10028][core] Introduce reusable ByteArrayData[Input/Output]View as adapter between Data[Input/Output]View and byte-arrays,5
[FLINK-9688] [table] Add ATAN2 SQL function supportThis closes #6223.,1
"[FLINK-9833] [e2e] Add a SQL Client end-to-end test with unified source/sink/formatAdds a SQL Client end-to-end test with Kafka/Filesystem and Avro/JSON/CSV components.It reads JSON from Kafka, uses a UDF for transformation, writes to Kafka Avro, readsfrom Kafka Avro, and writes to Filesystem CSV again. It also tests the availableSQL jars for correctness.This closes #6422.",3
[hotfix] [e2e] Remove explicit Maven plugin version,4
[FLINK-9887][state] Integrate priority queue state with existing serializer upgrade mechanismThis closes #6467.,2
[hotfix] Minor cleanups in LongSerializer,4
[FLINK-6846] [table] Deprecate quarter() in Table API,2
[FLINK-10029][DataStream API] Refactoring the StreamingFileSink code.,2
[FLINK-10027][DataStream API] Add logging to StreamingFileSink.This closes #6477.,2
"[FLINK-9947] [docs] Document unified table sources/sinks/formatsAdds documentation for unified table sources, sinks, and formats bothfor Table API & SQL and SQL Client.- New connect page- Adapted SQL Client page- Adapted Sources & Sinks pageThis closes #6456.",1
"[FLINK-6846] [table] Add timestamp addition in Table APIIt adds all temporal intervals known to SQL to the Table APIfor timestamp/interval arithmetic.Replaces the deprecated ""quarter()"" function.This closes #6188.",1
[FLINK-9861][tests] Add StreamingFileSink E2E test,3
[hotfix][build] Remove unnecessary version,4
"[FLINK-10033] [runtime] Task releases reference to AbstractInvokableTo guard against memory leaks, the Task releases the reference to its AbstractInvokablewhen it shuts down or cancels.This closes #6480.",1
[hotfix] Let MemoryManager log start up values,2
[hotfix][tests] Remove unused variable.,1
[FLINK-9936][mesos] Wait for leadership before creating MesosResourceManager componentsThis closes #6464.,1
[hotfix] [test] Wait CompletableFuture complete,3
[FLINK-9995][tests] Improve tearing down Mesos.- Clean up logs and Mesos working directory.- Kill Mesos processes using grepkill! utility.,1
[FLINK-9915] [table] Add TO_BASE64 function for table/sql APIThis closes #6390.,1
[FLINK-9938][state] Clean up full snapshot from expired state with TTLThis closes #6460.,4
[FLINK-10064] [table] Fix a typo in ExternalCatalogTableThis closes #6497.,2
[FLINK-10051][tests][sql] Add missing dependencies for sql client E2E test,3
[FLINK-9562][optimizer] Fix typos/comments,2
[hotfix][metrics] Replace anonymous classes with lambdas,0
[FLINK-7812][metrics] Add system resources metricsThis closes #4801.,5
[hotfix][docs] Specify operators behaviour on processing watermarks,1
[hotfix][docs] Document event time behaviour for idle sourcesThis closes #6076.,2
[FLINK-9504][logging] Change the log-level of checkpoint duration to debugThis closes #6111.,0
[FLINK-10070][build] Downgrade git-commit-id-plugin,2
[FLINK-10071] [docs] Document usage of INSERT INTO in SQL ClientThis closes #6505.,2
- remove AggregateReduceFunctionsRule copy in Flink repo.- incoporate calcite change in DATETIME_PLUS operator.- fix unittests.- fix SqlToRelConverter in Flink repo.,2
[FLINK-10055][javadocs] Fix in-progress file suffix in BucketingSink,0
[FLINK-10095][state] Swap serialization order in TTL value: first timestamp then user valueThis closes #6510.,1
[FLINK-9576] Fixed documentation for contiguity within looping pattern. (#6268)[FLINK-9576] Fixed documentation for contiguity within looping pattern.,2
[FLINK-10073] [sql-client] Allow setting a restart strategy in SQL ClientAdds support for fine-grained restart strategies per job/query.This closes #6506.,1
[FLINK-9438] Add documentation for AvroDeserializationSchema (#6078),2
[FLINK-10094][tests] Always backup config before running test,3
"[FLINK-9446][docs] Update savepoint compatibility table for 1.4* [FLINK-9446][docs] Update savepoint compatibility table for 1.4* fix typo* clarify casecalss migration* fix ""Scala"" capitalization* rework CEP note",1
[FLINK-9933] Simplify taskmanager memory default values (#6444),2
[FLINK-10102][docs] Fix docs for EXECUTION_FAILOVER_STRATEGY,0
[FLINK-9446][docs] Update savepoint compatibility table for 1.5,5
[FLINK-9446][docs] Update savepoint compatibility table for 1.6,5
[FLINK-9867] Extend release notes for Flink 1.6Extend the release notes for Flink 1.6 which can be found in /docs/release-notes/flink-1.6.md,2
[FLINK-9867] Add release notes file for Flink 1.7,2
[hotfix] [security] Fix error message when RestClientConfiguration cannot be created due to wrong SSL config.,5
[FLINK-10069] [docs] Update SSL docs to reflect internal vs. external communicationThis closes #6507.,2
[FLINK-10105][hotfix][docs] Fixed documentation completeness test,3
[FLINK-10063][tests] Use runit to supervise mesos processes.,1
[FLINK-10063][tests] Set Marathon's maxLaunchDelaySeconds to 3.The default value for maxLaunchDelaySeconds is 3600 (1 hour). For testingpurposes this value is too high and can cause false positive test failures.This closes #6496.,0
[hotfix][tests] Remove unused argument from db/flink-db.,5
[hotfix] Bump japicmp reference version to Flink 1.6.0,2
[hotfix][docs] Add 1.6 to the list of previous versions,1
"[FLINK-10107] [e2e] Exclude conflicting SQL JARs from testThis is a temporary solution for fixing the SQL Client end-to-endtest for releases. For now, we do not include conflictingSQL JARs in library folder of the test.This closes #6528.",3
[FLINK-9637] [docs] Add public user documentation for state TTL featureThis closes #6379.,2
[FLINK-10099][test] Improve YarnResourceManagerTestIntroduce methods to mock a Yarn Container and ContainerStatus.Properly shutdown a started ResourceManager.This closes #6499.,3
[FLINK-9240] Avoid deprecated Akka methodsUse static importsUse the org.apache.flink.runtime.concurrent.Executors importThis closes #6446.,2
[hotfix][docs] Add missing space after end of sentence.,1
"[FLINK-9795][mesos, docs] Update Mesos documentation[FLINK-9795][mesos, docs] Remove unnecessary remark about task reconciliation.The config key high-availability.zookeeper.path.mesos-workers already has adefault value. Even without explicitly setting the key, the task reconciliationwill work. Moreover, if there would not be a default key, the code would throw an NPE. Soeither way, the remark is only confusing the reader.[FLINK-9795][mesos, docs] Remove configuration keys from Mesos Setup page.- Remove the Mesos specific configuration keys from the Mesos Setup page becausethey duplicate what is already on the configuration page.- Add missing descriptions for some of the keys that are under the Mesos section of the configurationpage.- Improve formatting of the descriptions.[FLINK-9795][mesos, docs] Document which config options are only used in legacy mode.[FLINK-9795][mesos, docs] Document that mesos.initial-tasks is only needed in legacy mode.[FLINK-9795][mesos, docs] Clarify necessity of Marathon in documentation.[FLINK-9795][mesos, docs] Rewrite ""Flink's JobManager and Web Interface"" section.[FLINK-9795][mesos, docs] Add missing period at the end of sentence.This closes #6533.",1
[hotfix] [docs] Fix ProcessWindowFunction code snippets.This closes #6527.,1
[FLINK-10041][state] Extract iterators from RocksDBKeyedStateBackend (inner or static inner classes) into full classesThis closes #6501.,5
[FLINK-10124][state] Use ByteArrayDataInput/OutputView instead of stream + wrapper,5
[hotfix][kubernetes] Fix broken hyperlink in README.md,2
[FLINK-9919][docs] Remove unit for fullRestarts metric,4
[hotfix][network] add task name to SingleInputGate logs,2
[hotfix][checkstyle] fix comments in SingleInputGate,0
[FLINK-10006][network] improve logging in BarrierBuffer: prepend owning task nameThis closes #6470.,2
[FLINK-10066] Keep only archived version of previous executionsThis closes #6500.,2
[FLINK-9977] [table] [docs] Refine the SQL/Table built-in function docs.This closes #6535.,2
[FLINK-8135][REST][docs] Add description to MessageParameter,2
[hotfix][REST][docs] Add missing spaces,1
[FLINK-10087][tests] Update BucketingSinkMigrationTest for 1.5,3
[FLINK-10089][tests] Update FlinkKafkaConsumerBaseMigrationTest for 1.5,3
[FLINK-10090][tests] Update ContinuousFileProcessingMigrationTest for 1.5,3
[FLINK-10091][tests] Update WindowOperatorMigrationTest for 1.5,3
[FLINK-10092][tests] Update StatefulJobSavepointMigrationITCase for 1.5,5
[FLINK-10085][tests] Update AbstractOperatorRestoreTestBase for 1.6,3
"Fix Javadoc links in documentationPreviously, it was pointing to release-1.7-SNAPSHOT where we don'tactually serve javadocs.Now we always point to master and have a dedicated variable for this soit can easily changed on release branches.",4
[FLINK-9853] [table] Add HEX support for Table API & SQLThis closes #6337.,1
[hotfix] [table] [docs] Improvements for the functions documentation,2
[FLINK-10109] Add documentation for StreamingFileSink,2
Fix typo in Streaming File Sink documentation,2
[FLINK-9664][ml][docs] Fix ML quick start docs,2
[hotfix][streaming] Fix and simplify PrintSinkFunctionTestPreviously PrintSinkFunctionTest was testing incorrectly for System.err. setTargetToStandardErr was beingcalled after opening PrintSink so it didn't have any effect.This commit also reduce code duplication and get rids of mockito usage in this test.,3
[FLINK-7205] [table] Add UUID() for Table API & SQLThis closes #6381.,1
[FLINK-10056] [test] Add JobMasterTest#testRequestNextInputSplitThis closes #6490.,3
[FLINK-9859] [runtime] More Akka configThis closes #6339.,5
[FLINK-5232] Add a Thread default uncaught exception handler to the ActorSystem,5
[FLINK-5232] Introduce RobustActorSystemThe RobustActorSystem has a configurable UncaughtExceptionHandler. Per default it is startedwith the FatalExitExceptionHandler. This handler terminates the JVM whenever it sees anuncaught exception.This closes #6334.,0
[FLINK-10123] Use ExecutorThreadFactory instead of DefaultThreadFactory in RestServer/ClientUsing the ExecutorThreadFactory hardens the system because it uses the FatalExitExceptionHandleras UncaughtExceptionHandler which terminates the JVM in case of an exception.This closes #6539.,0
[FLINK-10022][network][metrics] add metrics for input/output buffersThis closes #6551.,1
[hotfix] [docs] Fix typo in Elasticsearch example,2
[FLINK-9013] Allow formatting text as code in option description,1
[FLINK-9013] Document yarn.containers.vcores only being effective when adapting YARN config,5
[FLINK-8290] Allow setting clientId in flink-connector-kafka-0.8,2
[FLINK-9546] Fix checking of heartbeatTimeoutIntervalMs in HeartbeatMonitorThis closes #6135.,0
[FLINK-9289] [Dataset] Parallelism of generated operators should have the max parallelism of inputThis closes #6003.,1
[FLINK-10110][tests] Harden Kafka component shut down for E2E testsInstead of only calling kafka-server-stop.sh and zookeeper-server-stop.sh which can faildue to KAFKA-4931 we also use jps to kill the Kafka and ZooKeeper processes.This closes #6530.,1
[FLINK-10101][mesos] Announce web UI url at Mesos masterThis commit announces the cluster's web UI url at the Mesos master so that itis visible in the Mesos UI.This closes #6522.,2
[FLINK-10151][state] Fix false recursion call for state TTL in TransformingStateTableKeyGroupPartitioner.tryAddToSourceThis closes #6563.,1
[hotfix][state] Improve memory-friendliness of state assignment by allocating collections with correct sizes or improved size estimates where possible,1
[FLINK-10154][connectors] Make sure we always read at least one record in KinesisConnector.This closes #6564.,1
[FLINK-10116] [types] Fix getTotalFields() implementation of some TypeInfos.This closes #6569.,5
[FLINK-9899] Add more ShardConsumer metricsThis closes #6409.,1
[FLINK-10020] [kinesis] Support recoverable exceptions in listShards.This closes #6482.,1
[hotfix] Update Travis' Docker Compose version to 1.22.0,2
[hotfix][docs] Introduce Github branch variable in _config.ymlgithub_branch in docs/_config.yml points to the branch name of the current release.,5
[FLINK-10001][docs] Add documentation for job cluster deployment on Docker and K8s[FLINK-10001][docs] Add documentation for job cluster deployment on K8sThis closes #6561.,2
[hotfix][tests] Deduplicate code in ListCheckpointedTest,3
"[FLINK-10159][tests] Fail TestHarness.initializeState if harness has already been initializedThis is a change in tests only. Previously it was technically possible to call first `harness.open()`followed by `harness.initializeState(fooBar)`. However this was incorrect, since `open()` was alreadycalling `initializeState(null)`, which was leading to quirks. This commit adds a `checkState` whichmakes sure that `initializeState` is called only once.",5
[hotfix][tests] Deduplicate code in AbstractStreamOperatorTestHarness constructor,3
[hotfix][kafka] Add claryfiying comment in FlinkKafkaProducer011,2
[FLINK-9850][streaming] Add a string to the print method to identify output for DataStream (#6367),5
[FLINK-10169] [table] Fix error in RowtimeValidator when getting custom TimestampExtractorThis closes #6575.,4
[FLINK-10068][docs] Add documentation for RocksDB-based timers and stopping timersThis closes #6504.,5
[hotfix] Minor JavaDoc correction in StateTable,2
[FLINK-6670][tests] Remove CommonTestUtils#createTempDirectory,3
[FLINK-10139][tests] Update compatibility tests for 1.6,3
[FLINK-9900][tests] Include more information on timeout in Zookeeper HA ITCase,5
[FLINK-10082][metrics][slf4j] Provide initial size to StringBuilder,5
"[hotfix][streaming][docs] Remove ambiguous remark about KeyedBroadcastProcessFunction#onTimer()It is hard to tell whether ""This is aligned with the onTimer()method of the KeyedProcessFunction"" applies to ""the ReadOnlyContextin the processElement() method"" or either/both of the sub-items.Someone not deeply familiar with process functions would simplyassume that `KeyedBroadcastProcessFunction#onTimer` works exactlylike `KeyedProcessFunction#onTimer` anyway, so the removed statementwould be superfluous anyway.",4
[FLINK-10072][streaming][docs] Fix syntax/formatting issues in broadcast docs,2
[hotfix][python][tests] Activate remaining tests,3
[FLINK-10059] [table] Add LTRIM function in Table API and SQLThis closes #6494.,1
[FLINK-10060] [table] Add RTRIM function in Table API and SQLThis closes #6509.,1
[FLINK-10181][rest][docs] Add anchor links to rest requests,2
[FLINK-10042][state] (part 1) Extract snapshot algorithms from inner classes of RocksDBKeyedStateBackend into full classes,5
[FLINK-10042][state] (part 2) Refactoring of snapshot algorithms for better abstraction and cleaner resource managementThis closes #6556.,4
[FLINK-10127] [core] Add TypeInformation for java.time.Instant.This closes #6549.,5
[FLINK-10187] [table] Fix LogicalUnnestRule after upgrading to Calcite 1.17.* LogicalUnnestRule needs to match correlate->...->project->uncollect* Remove SqlToRelConverter which was copied from Calcite to workaround CALCITE-2440.This closes #6592.,1
[FLINK-10172] [table] Fix Table.orderBy(String) by adding asc & desc to ExpressionParser.* Add tests to ensure asc and desc won't be dropped in the future.This closes #6585.,4
[hotfix] [REST] Add logging to RouterHandler,0
[FLINK-10175][state] Fix concurrent access to shared buffer between RocksDBMapState and querable state,5
[FLINK-10176][state] Replace ByteArrayData[Input|Output]View with (enhanced) Data[Output|InputDe]SerializerThis closes #6583.,5
"[FLINK-10164] Add support for resuming from a savepoint to StandaloneJobClusterEntrypointThe StandaloneJobClusterEntrypoint accepts now CLI options to specify a savepoint path andwhether to allow non restored state or not. If the entrypoint is started with a savepointpath, then the job will try to resume from this savepoint.This closes #6572.",1
[hotfix] Update standalone-job.sh usage string,5
[hotfix] Improve StandaloneJobClusterEntrypoint command line helpProperly print the CLI help if the command line options could not be parsed.,1
[hotfix] Add support for savepoint options to docker-compose template,2
[hotfix][docs] Document how to resume from a savepoint with a job cluster on K8s,2
[hotfix][metrics][docs] Remove redundant <th> from metric table,4
[hotfix][docs] Add missing </td> to metrics pageThis closes #6609.,1
"[FLINK-10153] [docs] Add Tutorials section and rework structure.- Add a Tutorials section- Move tutorial & quickstart guides into Tutorial section- Add a ""Building & Developing Flink"" section for Flink contributors- Remove Project Setup section and move content to relevant sections- Update Examples section- Update links and add redirects for moved pages.- Fix a few broken links.This closes #6565.",2
[FLINK-10201] [table] [test] The batchTestUtil was mistakenly used in some stream sql testsThis closes #6605.,3
[FLINK-10136] [table] Add REPEAT function in Table API and SQLThis closes #6597.,1
[FLINK-10204] Fix serialization/copy of LatencyMarkers,0
[FLINK-10163] [sql-client] Support views in SQL ClientAdds initial support for views in SQL Client. It adds the following statements:CREATE VIEW: Creates a virtual table from a SQL query.SHOW VIEW: Describes a previously created virtual table.DROP VIEW: Deletes a previously created virtual table.It also adds the section 'views' to environment files.This closes #6606.,2
[FLINK-10192] [sql-client] Fix SQL Client table visualization modeFixes the wrong materialization for the debugging visualizationin table mode. Reworks the caching mechanism in MaterializedCollectStreamResult.This closes #6617.,1
[FLINK-9781][build] Fix scala-maven-plugin for Java 9https://github.com/scala/scala/releases/tag/v2.11.12,0
[FLINK-10233][core] Reverse deprecation of ConfigOption#withDescription(String),5
[FLINK-8686] [sql-client] Limit result size for prototyping modesThis makes the SQL Client more robust by limiting the result size forboth changelog and table result modes. In changelog mode theresponsiveness of the CLI is the limiting factor. This adds a hardlimit for changelog mode. In table mode only the main memory is thelimiting factor and the configurable maximum row count. This adds aconfigurable limit for table mode.This closes #6621.,5
[FLINK-10137][YARN] Log completed containers.,2
[FLINK-9962] allow users to specify TimeZone in DateTimeBucketerThis closes #6492.,5
[FLINK-9642][cep] Added caching layer to SharedBuffer(#6205),5
[FLINK-10189] Fix inefficient use of keySet iterators,1
[FLINK-10207][build] Bump checkstyle to 8.9,2
[FLINK-10207] Fix newly discovered checkstyle violations,1
[hotfix] [docs] Fix javadoc typos in FileStateHandle and SavepointV2,2
[hotfix] [docs] Fix typo in batch connectors,2
"[hotfix][network] simplify moreAvailable/wasEmpty logicIf we only need the status of a queue being empty or not, we do not need toacquire the size.",2
"[FLINK-10141][network] move notifications outside the bufferQueue and receivedBuffers locksThis means, notifyCreditAvailable() and notifyChannelNonEmpty() are calledwithout any locks being acquired. The change is safe since these callbacks dotheir own synchronization already (if needed).This closes #6553.",4
[FLINK-10142][network] reduce locking around credit notificationThis closes #6555.,2
[FLINK-10270][REST] Delete unused class LegacyRestHandlerAdapter.- Delete class LegacyRestHandlerAdapter.- Delete class LegacyRestHandler.,0
[hotfix][conf] Remove references to deprecated WebOptions,4
[hotfix][rest] Extend logging,2
[FLINK-10115][rest] Ignore content-length limit for FileUploads,2
[hotfix][rest] Update error handling in FileServerHandlers,2
[FLINK-7551][rest] Add versioning,1
[FLINK-10186][streaming] Use ThreadLocalRandom in BufferSpiller constructor,1
[FLINK-10150][metrics] Fix OperatorMetricGroup creation for Batch,1
[hotfix][metrics] Rename TaskMetricGroup#addOperator,1
[hotfix][docs] Fix html tags in Batch API overview,0
[hotfix][docs] Remove redundant td tag,4
[hotfix][checkstyle] Enable checkstyle for flink-core/test.util,3
[hotfix][checkstyle] Enable checkstyle for flink-core/migration,2
[hotfix][checkstyle] Enable checkstyle for flink-core/api.common.restartstrategy,2
[hotfix][checkstyle] Enable checkstyle for flink-core/api.java.functions,2
[hotfix][checkstyle] Remove suppression for runtime/test.runtime.zookeeper,3
[hotfix][checkstyle] Remove suppression for runtime/io.disk,1
[hotfix][checkstyle] Remove suppression for runtime/network.buffer,1
[hotfix][checkstyle] Remove suppression for runtime/minicluster,5
[hotfix][checkstyle] Remove suppression for runtime/test.runtime.testutils,3
[hotfix][checkstyle] Remove suppression for runtime/network.serialization,1
[hotfix][checkstyle] Remove suppression for runtime/concurrent,1
[hotfix][streaming] Remove redundant word in javadocs,2
[FLINK-10254][backend]Fix inappropriate checkNotNull in stateBackend,2
[FLINK-10283][runtime] Remove misleading logging in FileCache,2
[hotfix][flink-connector-filesystem] fix javadoc typo in BucketingSink,2
[hotfix][streaming] fix check for notNull jobName in StreamContextEnvironment,0
[FLINK-10261] [table] Fix INSERT INTO with ORDER BY clauseThis closes #6648.,1
[FLINK-10293][streaming] Properly forward REST port for remote environments,2
[hotfix][tests] Extend MockEnvironmentBuilder to support TaskManagerRuntimeInfo,5
[FLINK-10242][tests] Split StreamSourceOperatorTest,3
[FLINK-10242][metrics] Disable latency metrics by default,2
[hotfix] Remove @RpcTimeout from JobMaster.requestJobDetails.,4
[FLINK-10193][runtime] Add @RpcTimeout to JobMasterGateway.triggerSavepoint.This closes #6601.,1
[hotfix][tests] Fix checkstyle violations in JobMasterTest.,3
[hotfix][tests] Make JobMasterTest#EMPTY_TESTING_INPUT_SPLITS private.,3
"[FLINK-10174] [table] Define UTF-8 charset for HEX, TO_BASE64, FROM_BASE64This closes #6579.",1
[hotfix] Remove unused imports from MetricOptions,2
[FLINK-10243][metrics] Make latency metrics granularity configurable,5
[hotfix][metrics] Add missing import,2
[FLINK-10131][network] improve logging around subpartitions- add task name- add subpartition indexThis closes #6547.,1
[FLINK-9735][tests] Potential leak in RocksDBResourceThis closes #6660.,5
[FLINK-10267][state] Fix arbitrary iterator access on RocksDBMapIteratorThis closes #6638.,5
[hotfix][kubernetes] Correct exception typoThis closes #6677.,2
[hotfix][runtime] Remove unused exception classThis closes #6674.,1
[FLINK-10170] [table] Add string representation for all Table & SQL API typesSince 1.6 the recommended way of creating source/sink tables is usingconnector/format/schema descriptors. This commit adds string-basedrepresentation for all types supported by the Table & SQL API.We use a syntax similar to Hive and other SQL projects.This closes #6578.,1
"[FLINK-10281] [table] Fix string literal escaping throughout Table & SQL APIThis commit fixes the string literal escaping of the Table & SQL API. Properescaping of quotes was not possible in the past for Table API. SQL and SQL Clientwere not standard compliant.Due to FLINK-8301 backslashes were considered in SQL literals, however, theyshould only be used in SQL `U&'\1234'` literals. For the Table API, the newlogic relies on the Java/Scala escaping and uses duplicate quotes for escapingthe quotes in expression strings. For SQL, we rely on unicode string literalswith or without the UESCAPE clause. The SQL Client was using backslashes forescaping new lines. For the SQL Client, we allow unescaped new lines anduse ';' for statement finalization; similar to other SQL clients.This closes #6671.",1
[hotfix] Fix checkstyle violations in ZooKeeperStateHandleStore,0
[hotfix] Fix checkstyle violations in ZooKeeperCompletedCheckpointStore,0
"[FLINK-10185] Make ZooKeeperStateHandleStore#releaseAndTryRemove synchronousRemove the asynchronous callback from ZooKeeperStateHandleStore#releaseAndTryRemove.Instead we can execute the callback after having executed the releaseAndTryRemovemethod successfully. This separates concerns better because we don't mix storagewith business logic. Furthermore, we can still avoid blocking operations if we use aseparate thread to call into ZooKeeperStateHandleStore#releaseAndTryRemove.This closes #6586.",4
[hotfix] Fix checkstyle violations in ZooKeeperUtils,0
[FLINK-10011] Introduce SubmittedJobGraphStore#releaseJobGraphSubmitedJobGraphStore#releaseJobGraph removes a potentially existing lockfrom the specified JobGraph. This allows other SubmittedJobGraphStores toremove the JobGraph given that it is no longer locked.,4
"[FLINK-10011] Release JobGraph after losing leadership in JobManagerThe JobManager now releases its lock on all JobGraphs it has stored inthe SubmittedJobGraphStore if the JobManager loses leadership. This ensuresthat a different JobManager can delete these jobs after it has recoveredthem and reached a globally terminal state. This is especially importantwhen using stand-by JobManagers where a former leader might still beconnected to ZooKeeper and, thus, keeping all ephemeral nodes/locks.",1
[hotfix][tests] Ensure that JobManagerRunners are stopped when Dispatcher loses leadership,1
"[FLINK-10011] Release JobGraph from SubmittedJobGraphStore in DispatcherThe Dispatcher now releases all JobGraphs it has stored in the SubmittedJobGraphStoreif it loses leadership. This ensures that the newly elected leader after recoveringthe jobs can remove them from the SubmittedJobGraphStore. Before, the problem wasthat a former leader might still be connected to ZooKeeper which keeps its ephemerallock nodes alive. This could prevent the deletion of the JobGraph from ZooKeeper.The problem occurs in particular in multi stand-by Dispatcher scenarios.This closes #6587.",0
[hotfix][benchmarks] fix StreamNetworkThroughputBenchmark#setUp not forwarding localMode,1
[hotfix][benchmarks] add @Override,1
[FLINK-10301][network] extend StreamNetworkBenchmarkEnvironment to allow custom Configuration instancesThis closes #6670.,5
[FLINK-10269] [connectors] Fix Elasticsearch 6 UpdateRequest binary incompatibilityThis commit fixes the binary incompatibility for UpdateRequests in Elasticsearch. Thisis due to a binary compatibility issue between the base module (which is compiledagainst a very old ES version and the current Elasticsearch version).It lets the API call bridge also provide the RequestIndexer version-specific.This closes #6682.,1
[FLINK-10223][LOG]Logging with resourceId during taskmanager startupcentralize location & resourceId info at the master nodeThis closes #6679.,5
[FLINK-10223][logging] Add 'ResourceID' to log message.,2
[FLINK-5315] [table] Add support for DISTINCT aggregation to Table API.This closes #6521.,1
[FLINK-10321][network] Make the condition of broadcast partitioner simple (#6688),1
[hotfix] Add LeaderRetrievalUtils#retrieveLeaderConnectionInfo with Time timeout,5
[hotfix] Add FunctionUtils#uncheckedFunction to convert FunctionWithExcpetion into Function,1
"[FLINK-10255] Only react to onAddedJobGraph signal when being leaderThe Dispatcher should only react to the onAddedJobGraph signal if it is the leader.In all other cases the signal should be ignored since the jobs will be recovered oncethe Dispatcher becomes the leader.In order to still support non-blocking job recoveries, this commit serializes allrecovery operations by introducing a recoveryOperation future which first needs tocomplete before a subsequent operation is started. That way we can avoid race conditionsbetween granting and revoking leadership as well as the onAddedJobGraph signals. This isimportant since we can only lock each JobGraph once and, thus, need to make sure thatwe don't release a lock of a properly recovered job in a concurrent operation.This closes #6678.",1
[hotfix] Add BiConsumerWithException#unchecked to convert into BiConsumer,1
[hotfix] Add BiFunctionWithException#unchecked to convert into BiFunction,1
[hotfix] Add ThrowingRunnable#unchecked and FunctionUtils#uncheckedConsumerThrowingRunnable#unchecked converts a ThrowingRunnable into a Runnable which throws checkedexceptions as unchecked ones. FunctionUtils#uncheckedConsmer(ThrowingConsumer) converts aThrowingConsumer into a Consumer which throws checked exceptions as unchecked ones. This isnecessary because ThrowingConsumer is public and we cannot add new methods to the interface.,1
[hotfix] Add --host and --executionMode config option to ClusterEntrypointThis is necessary to support the command line syntax used by the multi masterstandalone start-up scripts.,1
[FLINK-10329] Fail ZooKeeperSubmittedJobGraphStore#removeJobGraph if job cannot be removedFail properly with an exception if we cannot remove the JobGraph in ZooKeeperSubmittedJobGraphStore#removeJobGraph. This is necessary in order to notify callers about the unsuccessful attempt.,4
"[FLINK-10328] Release all locks when stopping the ZooKeeperSubmittedJobGraphStoreWhen stopping the ZooKeeperSubmittedJobGraphStore, it will release all currently heldlocks such that other instances can remove entries from the store. This is necessaryif we don't immediately close the used CuratorFramework/ZooKeeper client.This closes #6686.",1
"[FLINK-10325] [State TTL] Refactor TtlListState to use only loops, no java stream API for performanceThis closes #6683.",1
[hotfix] Replace DispatcherResourceCleanupTest#TestingJobManagerRunnerFactory with TestingJobmanagerRunnerFactory,3
"[FLINK-10314] Making JobManagerRunner creation non-blocking in DispatcherThe JobManagerRunner creation can be a blocking operation, e.g. if the CheckpointCoordinatorneeds to access a FileSystem. Therefore, this operation should not be executed in the main threadof the Dispatcher in order to not block this component.This closes #6699.",5
[FLINK-9991] [table] Add regexp_replace function to TableAPI and SQLThis closes #6450.,1
[FLINK-10222] [table] Fix parsing of keywords.This closes #6622.,0
[FLINK-10215]Add configuration of java option  for historyserverThis closes #6612.,5
[hotfix] Add description to java.env.opts.*,1
[hotfix][docs] Fix comment error in ZooKeeperSubmittedJobGraphStore,0
[hotfix][benchmarks] Add network broadcast benchmark,1
[hotfix][benchmarks] Add network broadcast benchmark (#6697),1
"[FLINK-9917][JM] Remove superfluous lock from SlotSharingManagerThe SlotSharingManager is designed to be used by a single thread. Therefore,it is the responsibility of the caller to make sure that there is only a singlethread at any given time accesssing this component. Consequently, the componentdoes not need to be synchronized.This closes #6389.",1
"[FLINK-9912][JM] Release TaskExecutors if they have no slots registered at SlotPoolThis commit extends the SlotPools behaviour when failing an allocation by sending a notificationmessage to the TaskExecutor about the freed slot. Moreover, it checks whether the affectedTaskExecutor has more slots registered or not. In the latter case, the TaskExecutor's connectionwill be eagerly closed.This closes #6394.",0
[hotfix] Fix checkstyle violations in SlotManager,0
[FLINK-9884] [runtime] fix slot request may not be removed when it has already be assigned in slot managerThis closes #6360.,4
[hotfix] Fix checkstyle violations in SlotManagerTest,3
[FLINk-10362] [s3] S3 config loading does not search Hadoop classpath,5
"[FLINK-10363] [s3] Only log config keys in config loader, to avoid exposing secret values",5
[hotfix] [hdfs] Suppress some deprecation warnings,2
[hotfix] Move common dependencies into 'flink-filesystems',5
[FLINK-10259] [table] Fix identification of key attributes for GroupWindows.This closes #6641.,0
[FLINK-10079] [table] Look up sink tables in external catalogs.This closes #6508.,2
[hotfix][flink-streaming-java] Fix typo in variable name in StreamingJobGraphGenerator.This closes #6593.,2
[hotfix][flink-streaming-java] Fix typo in OperatorChain.This closes #6619.,1
[FLINK-10365] [s3] Factor out Hadoop FS classes into pre-shaded artifact and update to Hadoop 3,5
[FLINK-10366] [s3] Create an S3 base module as the common denominator of the S3 connectors,1
[FLINK-10366] [s3] Adjust Hadoop-based s3 connector to use common denominator module,1
[FLINK-10366] [s3] Adjust Presto-based S3 adapter to use common S3 base,1
[FLINK-10366] [s3] Consolidate shared classes for S3 in flink-s3-fs-baseSome classes were previously incorrectly in flink-hadoop-fs,2
[FLINK-10366] [s3] Update build script shading checks to new patterns.,1
[FLINK-10324] Replace ZooKeeperStateHandleStore#getAllSortedByNameAndLock by getAllAndLockIn order to reduce code duplication this commit replaces ZooKeeperStateHandleStore#getAllSortedByNameAndLock by getAllAndLock and do the sorting of the entries afterwards.The implication of this change is that we no longer try to release and remove corruptedentries and instead simply ignore them.This closes #6681.,4
[hotfix][checkstyle] Remove suppression for runtime/network.partition,1
"[hotfix][network] ensure deserialization buffer capacity for the whole record lengthOnce we know the record length and if we are not spilling, we should size thebuffer immediately to the expected record size, and not incrementally for eachreceived buffer chunk.",0
[hotfix][network] some minor improvements around the network stack,1
[hotfix][network] minor optimisations and clarifications around BufferBuilder and BufferConsumer,0
[hotfix][network] adapt InputGateConcurrentTest to really follow our guarantees- producers should flush after writing to make sure all data has been sent- we can only check bufferConsumer.isFinished() after building a Buffer- producer/consumer threads should be named,5
[hotfix][network][tests] add readView.nextBufferIsEvent to assertNextBufferOrEvent(),3
[hotfix][network][tests] use assertNextBuffer etc in PipelinedSubpartitionTest,3
[FLINK-10331][network] reduce unnecessary flushingDo not flush (again) if- a previous flush request has not been completely handled yet and/or is still enqueued or- the network stack is still polling from this subpartition and doesn't need a new notificationThis closes #6692.,1
"[hotfix][network][tests] split PipelinedSubpartitionTest for better initialization- add PipelinedSubpartitionWithReadViewTest which always creates a subpartition,an availability listener, and a read view before each test and cleans up aftereach test- remove mockito use from testBasicPipelinedProduceConsumeLogic()",3
[hotfix][network] use ConcurrentMap#putIfAbsent and Lambdas for partition request handlers,0
[FLINK-10332][network] move data notification out of the synchronized blockNone of the notifications actually rely on being under the lock and may thusonly cause lock contention.This closes #6693.,1
[FLINK-10355] [java] Use 1-based field indexes in RowCsvInputFormat exception messages.This closes #6713.,1
[FLINK-10358] fix NPE when running flink-kinesis connector against dynamodb streamsThis closes #6708.,5
[FLINK-8660][ha] Enable user to provide custom HAServices implementationCreate BlobStorage for any HA backendHighAvailabilityServicesFactory may throw exceptionsDocsUse ha mode config property to specify factory class FQNUpdate docs,2
"[FLINK-8660][ha] Add InstantiationUtil#instantiate to create instance from class nameInstantiationUtil#instantiate takes a class name, a target type and a class loader to loada class of the given class name and create an instance of it.",1
[hotfix] Add JavaDoc to HighAvailabilityServicesUtils#AddressResolution,1
[hotfix] Add ExceptionUtils#stripExceptionstripException strips a given throwable from a specified exception type. Thisis useful to unwrap exceptions.,1
"[hotfix] Unstrip UndeclaredThrowableExceptions from entrypointsIn order to better report errors while starting the cluster, we unstrip allUndeclaredThrowableExceptions from the entrypoints. This should give a betteruser experience.",1
[FLINK-10050][DataStream API] Support allowedLateness in CoGroupedStreams.This closes #6646.,1
[hotfix][doc] Fix curl example in upload jar exampleThis closes #6706.,0
[hotfix][docs] Regenerate docs to fix curl example for uploading jars.,0
[hotfix][tests] Add file sshd-run.The file that was previously missing is needed to build the docker images usedfor running the Jepsen tests locally.,3
[FLINK-10375] Added wrapped exception as causeThis closes #6719.,1
[hotfix] Fix checkstyle violations in ExceptionInChainedStubException,0
[FLINK-10260] Clean up log messages for TaskExecutor registrationsChange log level to debug for messages about TaskExecutor re-registeration inResourceManager and SlotManager in case of mupltiple attempts of the TaskExecutorto connect to the ResourceManagerThis closes #6720.,0
[FLINK-9567][yarn] Before requesting new containers always check if it is requiredBy comparing the number of pending slot requests and the number of pending container allocationsit is possible to say whether we should allocate more containers or not.This closes #6669.,5
[hotfix] Bump japicmp reference version to 1.6.1,0
"[FLINK-9913][network] Serialize records only once for multi channel writes in RecordWriter (#6417)This commit improves the output serialization, to serialize records only once for multi target channels in RecordWriter, rather than serializing record as many times as the number of selected channels.",1
[FLINK-9738][table] Provide a way to define Temporal Table Functions in Table API,1
[hotfix][table] Deduplicate optimize code between stream and batch table environment,0
[hotfix][table] Extract computeCost in FlinkLogicalJoin to base classThis commit can be squashed with a following commit after code review,2
[hotfix][table] Deduplicate RelTimeInidicatoConverter logic,2
"[hotfix][table,tests] Reduce mockito usage in TableTestUtil",3
[FLINK-9713][table][sql] Support versioned join in planning phase,1
[hotfix][table] Extract DataStreamJoinToCoProcessTranslator,5
[hotfix][table] Simplify NonWindowJoin class,0
[hotfix][table] Add convienient constructors for CRow,1
"[hotfix][table,tests] Add convienient verify methods to HarnessTestBase",3
[FLINK-9714][table] Support versioned joins with processing time,1
[FLINK-10157][State TTL] Allow `null` user values in map state with TTLThis closes #6707.,1
[FLINK-10369][tests] Enable YARNITCase to test per job mode deploymentThis closes #6717.,3
"[hotfix] Move TestingYarnClusterDescriptor#TestJarFinder into YarnTestUtilsIn order to reuse the TestJarFinder class, this commit moves it into the YarnTestUtilsclass.",3
[FLINK-10234][runtime] Fix ambiguous lambda usage,0
[FLINK-10376][runtime] Use Files#createDirectories in BlobUtils,2
[FLINK-10389][runtime] Remove unused field in TaskManagerServicesConfiguration,5
[hotfix] [docs] Improve S3 file system docs,2
[hotfix] [s3] Remove obsolete READMEs from hadoop- and presto- s3The Hadoop shading logic is not consolidated in the flink-fs-hadoop-shaded project.,2
"[FLINK-10383] [s3] Prevent Hadoop configs in the classpath to seep into S3 configurationThe S3 connectors are based on a self-contained shaded Hadoop and should not load implicitlyconfigs from the classpath, like Hadoop does it. Instead, they should only use config valuefrom the Flink configuration.",5
[hotfix] Add JavaDocs to CheckpointMetadataOutputStream,5
[FLINK-9061] [fs] Add entropy injector for file systems,5
[FLINK-9061] [checkpoints] FsStatebackend optionally injects entropy into state data file paths,2
[FLINK-9061] [s3] Make base S3 file system entropy injecting,5
[hotfix] [runtime] Clean up some checkstyle violations,4
[FLINK-10416] Added files generated by jepsen tests to rat excludes.,3
[FLINK-6847] [FLINK-6813] [table] Add support for TIMESTAMPDIFF in Table API & SQLThis closes #6282.,1
"[FLINK-10263] [sql-client] Fix classloader issues in SQL ClientFixes classloading issues when using a UDF with constant parameters. Everyoptimization might need to compile code (i.e. for constant folding), thus,needs access to the user-code classloader.This closes #6725.",1
[hotfix] [docs] Add double quotes to Kafka version YAML examplesThis closes #6639.,1
[FLINK-10010] Mark BaseAlignedWindowAssigner as deprecatedAnd also remove SlidingAlignedProcessingTimeWindows,4
[FLINK-9891] Added hook to shutdown cluster if a session was created in per-job mode.This closes #6540.,1
"[FLINK-9891] Make shutdown of started cluster in attached mode optional, add cli option 'schutdownOnAttachedExist'This closes #6718.",1
[FLINK-10444] [core] Make entropy injection work across FileSystem SafetyNet.,5
[FLINK-10145] [table] Add replace function in Table API and SQLThis closes #6576.,1
[FLINK-1960] Add comments and docs for withForwardedFields and related operators. (#6753),1
"[FLINK-10400] Fail JobResult if application finished in CANCELED or FAILED stateIn case of the CANCELED state, the client will throw an JobCancellationException.In case of the FAILED state, the client will throw an JobExecutionException.This closes #6742.",0
[FLINK-10390][metrics][datadog] Close responseBody,5
[FLINK-10378][github] Comment out contribution guide from PR template,2
[FLINK-10393] Remove legacy entrypoints from start up scriptsThis commit removes the legacy entrypoints from the startup scripts.,1
[FLINK-10394][build] Remove legacy mode from Travis build matrix,4
[FLINK-10395] Remove legacyCode profile from parent pom.xml,5
[hotfix] Make RestClient AutoCloseableAsync,1
"[FLINK-10415] Fail response future if connection closes in RestClientIf the RestClient detects that a connection was closed (channel became inactive), thenit now fails the json response future with a ConnectionClosedException.",5
"[FLINK-10415] Fail response future if RestClient connection becomes idleThis commit adds a IdleStateHandler to the Netty pipeline of the RestClient. TheIdleStateHandler sends an IdleStateEvent if it detects that the connection is idlefor too long. If we see an IdleStateEvent, then we close the connection and failthe json response future.",5
"[FLINK-10415] Fail requests with empty Netty pipeline in RestClientSometimes it can happen that Netty does not properly initialize the channelpipeline when sending a request from the RestClient. In this situation, weneed to fail the response so that the caller will be notified about the un-successful call.This closes #6763.",0
"[FLINK-9455][RM] Add support for multi task slot TaskExecutorsExtend ResourceActions interface to return a set of ResourceProfiles describingthe set of slots with which the new resource will be started. The SlotManagerstores them as PendingTaskManagerSlots which can be assigned to PendingSlotRequests.Only if there are no more TaskManagerSlots and PendingTaskManagerSlots, theSlotManager will request new resources from the ResourceManager.This closes #6734.",1
[hotfix] Cancel actual pending slot request in SlotManager#updateSlotState,5
[hotfix] Remove mocking from SlotManagerTest,3
[hotfix] Remove mocking from SlotProtocolTest,3
[hotfix] Start MesosWorkers with default ContaineredTaskManagerConfiguration,5
"[FLINK-10411] Make ClusterEntrypoint more compositionalIntroduce a ClusterComponent which encapsulates the logic for starting the clustercomponents, Dispatcher, RestServerEndpoint and the ResourceManager. The individualcomponents are created by using a factory instance. The ClusterEntrypoint is nowonly responsible for managing the required services needed by the ClusterComponent.This design should make the testing of these components easier, improve reusabilityand reduce code duplication.",1
[FLINK-10411] Move System.exit out of ClusterEntrypointMove the logic of when to exit the JVM process out of the ClusterEntrypointso that the caller is now responsible to make this call. This improves theusage of the ClusterEntrypoint for testing purposes.,3
[FLINK-10411] Rename ClusterComponent into DispatcherResourceManagerComponent,2
"[FLINK-10411] Introduce DispatcherResourceManagerComponentFactoryThis commit introduces the DispatcherResourceManagerComponentFactory which is usedto create a DispatcherResourceManagerComponent. That way, it is possible to eagerlyinitialize all fields of the DispatcherResourceManagerComponent making it possibleto make all fields final and remove the lock.This closes #6743.",4
[FLINK-10396] Remove CodebaseTypeCodebaseType was used to distinguish between the legacy and new mode.This commit removes the CodebaseType and the codebase switch in theMiniClusterResource.This closes #6748.,5
[hotfix] Remove StandaloneMiniCluster from ScalaShellITCase,5
[FLINK-10401] Port ProcessFailureCancelingITCase to new code baseThis closes #6749.,1
[FLINK-10402] Port AbstractTaskManagerProcessFailureRecoveryTest to new code baseThis closes #6750.,1
[hotfix] Remove TaskManagerProcess,4
[hotfix] Remove TaskManagerProcessEntryPoint,1
[hotfix] Let ClusterEntrypoint implement AutoCloseableAsync,1
[FLINK-10403] Port JobManagerHAProcessFailureBatchRecoveryITCase to new code baseThis closes #6751.,1
[hotfix] Remove DispatcherProcess#getJobManagerPort function,1
[FLINK-10397] Remove CoreOptions#MODERemoves the MODE option used to switch between the new and legacy mode.This closes #6752.,1
"[FLINK-10065] InstantiationUtil.deserializeObject(InputStream in, ClassLoader cl, boolean isFailureTolerant) will close the inputStream (#6498)* fix inputstream auto closable* delete useless file",2
"[FLINK-10311][tests] Test job cancellation with standby masters.This adds tests to verify that jobs can be cancelled properly when there arestandby masters. To enable this, we added tests to install Flink as astandalone cluster. The first two DB nodes will be running the masterprocesses, while the others are running the TaskManagers. All Flink processesare supervised by runit  this allows killing for Flink processes by thenemesis.The client now implements a cancel operation. The model used by the checkerhad to be rewritten to address the fact that the job can be canceled. Thecancel operation is ""reliable"", i.e., it either cancels the job successfully,or it fails the whole test fatally. This way we can be that the job shouldbe eventually not running if the cancel operation completes successfully.This closes #6712.",1
[hotfix][tests] Remove wrong -rest.port=8081 from mesos start arguments.Dynamic arguments hould be prefixed with -D. Despite that the config key is notneeded because it is set in the flink-conf.yaml already.,5
[hotfix][tests] Extract mesos appmaster command to separate function.,1
[hotfix][tests] Enable building uberjar.,0
"[hotfix][docs, tests] Fix formatting in jepsen README.md",2
[hotfix][tests] Update default Flink distribution to 1.6,2
[hotfix][tests] Reformat code in nemesis.clj,3
"[hotfix][tests] Enable Mesos Jepsen tests.Previously the Mesos tests were disabled due to FLINK-9936, which is resolvednow. There are currently no known issues with Mesos so it is justified to enablethe tests.",3
[hotfix][tests] Stop all services supervised by runit when tearing down.,1
[hotfix][tests] Assert there is only one applicationId in ZooKeeper.,3
[FLINK-10417][cep] Added option to throw exception on pattern variable miss during SKIP_TO_FIRST/LAST,1
[hotfix] [connectors] Remove unused BulkProcessorIndexer class,1
"[FLINK-3875] [connectors] Add an upsert table sink factory for ElasticsearchThis commit adds full support for Elasticsearch to be used with Table & SQL API as well as SQL Client.It includes:- Elasticsearch 6 upsert table sink (for append-only and updating queries)- Elasticsearch 6 table factory- Elasticsearch table descriptors & validators- Unit tests, SQL Client end-to-end test- Website documentationThis closes #6611.",2
[FLINK-10414][cep] Added skip to next strategy,1
[FLINK-10291] Generate JobGraph with fixed/configurable JobID in StandaloneJobClusterEntrypointThis closes #6733.,1
[hotfix][docs] Improve documentation of savepointsThis closes #6766.,2
[FLINK-10339][network] Use off-heap memory for SpillReadBufferPool,5
[hotfix][network] Add allocateUnpooledOffHeapMemory for the MemorySegmentFactory,1
[FLINK-10312][rest] Propagate exception from server to client in REST API,2
[FLINK-8033][build] Add java9 profile,2
[hotfix][build] Only consider Flink artifacts for japicmp,2
[FLINK-10209][build] Exclude jdk.tools dependency from hadoop,2
[hotfix] Fix quickstarts end-to-end testUpdate the common methods to the new testing harness.,3
[FLINK-10405][docs] Fix broken links,2
"Revert ""[hotfix][build] Only consider Flink artifacts for japicmp""This reverts commit 6b5787d5f3a1f279ff471db7d1ff6a9a21f81e4d.The change did not fix japicmp failing for not being able to resolve the hadoop dependency.",0
[FLINK-10451] [table] TableFunctionCollector should handle the life cycle of ScalarFunctionThis closes #6771.,1
[FLINK-8819][travis] Rework travis script to use stages,1
[FLINK-10371] Allow to enable SSL mutual authentication on REST endpoints by configuration[FLINK-10371][tests] Regenerate configuration docs[FLINK-10371] Adapt to code reviewThis closes #6727.,2
[hotfix][travis] Remove legacy references,4
"[FLINK-10354] Revert ""[FLINK-6328] [chkPts] Don't add savepoints to CompletedCheckpointStore""This reverts commit 6f570e7b6810e1645a4f7094f17ab9e8559fa139.This closes #6704",4
[FLINK-10345][docs] Added note with warning about removing savepoints,4
[hotfix][docs] Polish savepoint warning,2
[FLINK-10279] [documentation] Make jython limitations more obvious in documentation. This closes #6761.,2
[FLINK-10470] Add method to check if pattern can produce empty matches,1
[hotfix] Remove unused cluster parameter from flink-contrib/docker-flink/docker-entrypoint.sh,2
[FLINK-10427] [tests] Port JobSubmitTest to new code base,1
[FLINK-10427] [tests] Port JobSubmitTest#testFailureWhenJarBlobsMissing to new code basePort JobSubmitTest#testFailureWhenJarBlobsMissing to JobSubmissionFailureITCase#testMissingJarBlob.This closes #6768.,3
[FLINK-10454][tests] Start MiniCluster with rest port 0Start the MiniCluster used by ScheduleOrUpdateConsumersTest and SlotCountExceedingParallelismTestwith a rest port 0 in order to avoid port conflicts when these two tests are executed concurrently.,3
"[FLINK-10421][tests] Exclude FluentPropertyBeanIntrospector info message in common.shFluentPropertyBeanIntrospector logs an info message containing the word error. This can causeend-to-end tests to fail. In order to prevent this, the respective logging statement is excluded.",2
[FLINK-8532] Modify RebalancePartitioner to use a random partition as its first partitionThis closes #6544.,1
[hotfix] Cleanup PartitionerITCase,4
[docs] Update cluster setup docs to reflect the new syntax of jobmanager.sh script.jobmanager.sh script syntax changed in Flink 1.5 as documented here: https://ci.apache.org/projects/flink/flink-docs-stable/release-notes/flink-1.5.html#changed-syntax-of-jobmanagersh-script,4
"[FLINK-10406] Port JobManagerTest to new code base (Part 1)Directly remove testStopSignal and testStopSignalFail, which iscovered by ExecutionGraphStopTest, and the high level invocationat Dispatch and JobMaster is trivial.",3
"[FLINK-10406] Port JobManagerTest to new code base (Part 2)testNullHostnameGoesToLocalhost is ported toAkkaUtilsTest#""null hostname should go to localhost""",3
[FLINK-10406] Port JobManagerTest to new code base (Part 3)testRequestPartitionState* arecovered by1. JobMasterTest#testRequestPartitionState2. TaskTest#testTriggerPartitionStateUpdate3. TaskTest#testOnPartitionStateUpdate,5
"[FLINK-10406] (Part 4) testSavepointRestoreSettingstestSavepointRestoreSettings is covered byJobMaster#testRestoringFromSavepointthe triggerSavepoint part is covered by JobMasterTriggerSavepointIT,and the submit failure part should be taken care of when portJobSubmitTest, which has a test testAnswerFailureWhenSavepointReadFails",3
"[FLINK-10406] (Part 5) testCancelWithSavepointtestCancelWithSavepoint is covered byJobMasterTriggerSavepointIT#testStopJobAfterSavepointtestCancelWithSavepointNoDirectoriesConfigured is somehow covered byJobMasterTriggerSavepointIT#testDoNotCancelJobIfSavepointFails.Now we don't provide detail error message to dig out the cause whytrigger savepoint fails. testDoNotCancelJobIfSavepointFails testsif the savepoint path permission denied, but change it to a /not/exist/pathprovide the same process. The exception stringified asjava.util.concurrent.ExecutionException:java.util.concurrent.CompletionException:org.apache.flink.runtime.checkpoint.CheckpointTriggerException:Failed to trigger savepoint.Decline reason: An Exception occurred while triggering the checkpoint.testCancelJobWithSavepointFailurePeriodicCheckpoints is covered byJobMasterTriggerSavepointIT#testDoNotCancelJobIfSavepointFails.",3
"[FLINK-10406] (Part 6) testSavepointWithDeactivatedPeriodicCheckpointingtestSavepointWithDeactivatedPeriodicCheckpointing is ported toJobMasterTriggerSavepointIT#testStopJobAfterSavepointWithDeactivatedPeriodicCheckpointing, witha little refactor to enable the latter test class configurecheckpointInterval(to deactivated periodic checkpointing).",5
"[FLINK-10406] (Part 7) testResourceManagerConnectiontestResourceManagerConnection is not applicable to FLIP-6 new code base,FLIP-6 has its own reconnect logic between JM and RM and the mechanismshould be guarded byJobMasterTest#testReconnectionAfterDisconnectJobMasterTest#testResourceManagerConnectionAfterRegainingLeadershipJobMasterTest#testCloseUnestablishedResourceManagerConnection",5
[FLINK-10406] (Part 8) testKvStateMessagestestKvStateMessages is ported to 4 tests in JobMasterTest1. JobMasterTest#testRequestKvStateWithoutRegistration2. JobMasterTesttestRequestKvStateWithIrrelevantRegistration3. JobMasterTest#testRegisterAndUnregisterKvState4. JobMasterTest#testDuplicatedKvStateRegistrationsFailTask,3
[hotfix] Fix checkstyle violations in ExecutionGraphStopTest,3
[hotfix] Fix checkstyle violations in SavepointRestoreSettings,1
[FLINK-10406][tests] Port JobManagerTest#testSavepointRestoreSettingsPort JobManagerTest#testSavepointRestoreSettings to JobMasterTest#testRestoringModifiedJobFromSavepoint.,3
[FLINK-10406] Add meaningful message if no savepoint location for cancel with savepointThe JobMaster now returns a meaningful exception messages if a job is canceled with savepointand neither a savepoint directory has been given nor a default location has been configured.This closes #6765.,5
[hotfix][scripts] Fix typo in taskmanager.sh,2
[FLINK-10453][travis] Move hdp 2.4 tests to cron jobs,3
[hotfix][travis] Add maintenance note,1
[FLINK-10512][rest][docs] Remove legacy docs,2
[FLINK-10208][build] Bump mockito to 2.21.0 / powermock to 2.0.0-beta.5,2
[FLINK-10487] [docs] Fix table conversion example and add runnable SQL example for Java.This closes #6790.,1
"[FLINK-10289] Classify Exceptions into different categories to apply different failover strategiesWe need to classify exceptions and treat them with different strategies. To do this, we propose to introduce the following Throwable Types, and the corresponding exceptions:NonRecoverable  - We shouldnt retry if an exception was classified as NonRecoverable  - For example, NoResouceAvailiableException is a NonRecoverable Exception  - Introduce a new Exception UserCodeException to wrap all exceptions that throw from user codePartitionDataMissingError  - In certain scenarios producer data was transferred in blocking mode or data was saved in persistent store. If the partition was missing, we need to revoke/rerun the produce task to regenerate the data.  - Introduce a new exception PartitionDataMissingException to wrap all those kinds of issues.EnvironmentError  - It happened due to hardware, or software issues that were related to specific environments. The assumption is that a task will succeed if we run it in a different environment, and other task run in this bad environment will very likely fail. If multiple task failures in the same machine due to EnvironmentError, we need to consider adding the bad machine to blacklist, and avoiding schedule task on it.  - Introduce a new exception EnvironmentException to wrap all those kind of issues.Recoverable  - We assume other issues are recoverable.Change-Id: I35c72b4d5328457b4998bff411bf522a8f8f3a48This closes #6739.",4
[FLINK-9126][cassandra] Add Pojo InputFormat,1
[FLINK-9126][cassandra] Finalize Pojo InputFormat,2
[hotfix][cassandra][tests] Close sources/sinks in finally block,3
[FLINK-10386] [taskmanager] Remove legacy class TaskExecutionStateListener,4
[hotfix] Remove unused StreamTaskTest#waitUntilExecutionState,3
[FLINK-10386] Let TaskManagerActions#notifyFinalState send TaskExecutionStateInstead of only sending the ExecutionAttemptID TaskManagerActions#notifyFinalStatesends the TaskExecutionState. This allows to test the final states in TaskTest.This closes #6729.,3
[FLINK-10513] Replace TaskManagerActions#notifyFinalState with #updateTaskExecutionStateSimplify TaskManagerActions interface by replacing calls to notifyFinalState withupdateTaskExecutionState.This closes #6804.,5
[hotfix] Fix checkstyle violations in TaskManagerTest,3
[FLINK-10514][docs] change tachyon to alluxio in docChange-Id: I85df5e484d115c81440a056e41adcff260aaf9a8,4
[FLINK-10340] Add Cosh math function supported in Table API and SQL,1
[FLINK-10465][tests] Do not stop sshd if it is supervised by runit.,1
[FLINK-10310] Cassandra Sink - Handling failing requests.This closes #6732,0
[FLINK-10227] Remove javax.xml.bind.DatatypeConverter for java 9 compatibility,5
[FLINK-10295] Add support of passing jar arguments as list of separate strings in REST API,4
[FLINK-10465][tests] Do not fail if /etc/service does not exists.,0
[FLINK-10399] Refactor ParameterTool#fromArgsThis closes #6737.,2
[FLINK-10399] Use String#isEmpty() to check for empty string.,1
[FLINK-10399] Rely on exception propgation to fail tests.,3
[FLINK-10469][core] make sure to always write the whole buffer to FileChannel,2
[FLINK-5542][yarn] Use YarnCluster vcores setting to do MaxVCore validation.This closes #6775.,5
[FLINK-9990] [table] Add regex_extract function in TableAPI and SQLThis closes #6448.,1
"[FLINK-9377] [core] (part 1) Extend TypeSerializerConfigSnapshot as a factory for restoring serializersThis commit is the first step towards removing serializers fromcheckpointed state meta info and making Flink checkpoints Javaserialization free.Instead of writing serializers in checkpoints, and trying to read thatto obtain a restore serializer at restore time, we aim to only write theconfig snapshot as the single source of truth and use it as a factory tocreate a restore serializer.This commit adds the restoreSerializer() method and signatures to theTypeSerializerConfigSnapshot interface. Use of the method, as well asproperly implementing the method for all serializers, will beimplemented in follow-up commits.To allow for the codebase to still build, the restoreSerializer() methodcurrently returns the originating serializer directly. This implies thefact that the originating serializer has been injected to the configsnapshot appropriately.",5
"[FLINK-9377] [core] (part 2) Move responsibility of serializer compatibility resolution to TypeSerializerConfigSnapshotThis work towards letting TypeSerializers be immutable, moving away fromthe previous design where serializers had to reconfigure themselves.The TypeSerializerConfigSnapshot interface now has a newresolveSchemaCompatibility method, via which it gets the new serializerto check against. Currently, to allow for incremetal changes inFlink-shipped config snapshots, we have a dummy implementation whichforwards the call to the to-be-deprecatedTypeSerializer#ensureCompatibility(...) method",5
"[FLINK-9377] [core] (part 3) Deprecate TypeSerializerSerializationUtilThis commit deprecates all utility methods and classes related toserializing serializers. All methods that will still be in use, i.e.writing config snapshots, are now moved to a separate newTypeSerializerConfigSnapshotSerializationUtil class.",5
"[FLINK-9377] [core] (part 4) Introduce BackwardsCompatibleConfigSnapshotThe BackwardsCompatibleConfigSnapshot is a wrapper, dummy configsnapshot which wraps an actual config snapshot, as well as apre-existing serializer instance.In previous versions, since the config snapshot wasn't a serializerfactory but simply a container for serializer parameters, previousserializers didn't necessarily have config snapshots that are capable ofcorrectly creating a correct corresponding restore serializer.In this case, since previous serializers still have serializers writtenin the checkpoint, the backwards compatible solution would be to wrapthe written serializer and the config snapshot within theBackwardsCompatibleConfigSnapshot dummy. When attempting to restore theserializer, the wrapped serializer instance is returned instead ofactually calling the restoreSerializer method of the wrapped configsnapshot.",5
[FLINK-9377] [core] (part 5) Remove serializers from serialization proxiesThis commit officially uses the newTypeSerializerConfigSnapshot#restoreSerializer() factory method toremove serialization of state serializers into checkpoints.,4
"[FLINK-9377] [core] (part 6) Introduce TypeSerializerSnapshot for a smoother upgrade pathThis commit deprecates TypeSerializerConfigSnapshot, and introduces aTypeSerializerSnapshot interface which will eventually be the newreplacement.The now-deprecated TypeSerializerConfigSnapshot differentiates in thatwhen being written, it wil still write along with it the priorserializer and return that when attempting to restore the priorserializer. Implementations which are upgraded to directly implement thenew TypeSerializerSnapshot interface are strictly required to implementthe restoreSerializer() method. Therefore, once upgraded, the priorserializer is no longer written.",1
"[hotfix] [core] Do not initialize serializer snapshot class when loading itThis lets errors during static initialization happen not in thedeserialization stack, but upon use of the class later, which is often abit easier to understand.",1
[FLINK-10361] Harden instable elastic search end-to-end test caseThis closes #6789.,1
[FLINK-10316] [kinesis] bug was preventing FlinkKinesisProducer to connect to KinesaliteThis closes #6808.,2
"[hotfix][docs,table] Split Streaming Concepts page into multiple documents.",2
"[FLINK-9712][docs,table] Document processing time Temporal Table Joins",2
[hotfix] [docs] Improve table streaming docs section- Adds more explanation and guidance- Improves the temporal table / join sectionsThis closes #6741.,1
[hotfix][rest] Add test for RestServerEndpointConfiguration,5
[FLINK-10282][runtime] Add builder for ExecutorThreadFactory,1
[FLINK-10282][rest] Separate REST and Dispatcher RPC thread pools,2
"[FLINK-10379][docs,table] Fix TableFunction docsOld syntax of joining with Table Functions in Java Table API:```// Register the function.tableEnv.registerFunction(""split"", new Split(""#""));myTable.join(""split(a) as (word, length)"");```is no longer supported and this the reason why the documentation needed to be updated. Currently supported syntax is:```orders.join(new Table(tEnv, ""split(a)"");```This closes #6744.",1
[FLINK-10075][rest] Redirect non-ssl requests to https url if ssl is enabled,0
[hotfix] Generify FutureUtils#toJava,0
[hotfix] Add AkkaUtils#terminateActorSystem,5
"[FLINK-10247] Run MetricQueryService in separate ActorSystemIn order to avoid that the metric system interferes with Flink's cluster components,the MetricQueryService is now executed in a separate ActorSystem.[FLINK-10247][metric] Start new actor system in JobMananger and TaskManagerAn actor system dedicated for metric query service is started for each ClusterEntrypoint and TaskManager Runner. The actor system is a single thread executorwith lowest priority. The metric query service path will be passed to ResourceManager and Dispatcher via MetricRegistry. This commit start the MetricQueryService independent of main component Rpc Service and close it during shutdown.[FLINK-10247][metric]Pass the address of Metric Query Service actor system to TaskExecutor and fix upIn order to making JobManager's metric query service communicate with Task executor's, JobManager should beaware of the address of TaskExecutor's MetricQueryService actor. This commit changes the constructorof TaskExecutor by passing the path of MetricQueryService actor and save it in an instance variable. Meanwhile,it changes the TaskExecutorGateway interface to make the address available to JobManager.Besides changes mentioned above, this commit also add an option to configure the port range of metric queryservice in JobManager started in a Yarn cluster.[FLINK-10247] Remove AkkaActorSystemService[FLINK-10247] Replace """" with null metricy query service path for TaskExecutor initialization[FLINK-10247] Decouple AkkaUtils and AkkaExecutorMode[FLINK-10247] Correct AkkaUtils#getSingleThreadExecutorConfig[FLINK-10247] Refactor Bootstrap#createActorSystem with dispatcher executor[FLINK-10247] Simplify metrics ActorSystem instantiation in TaskManagerRunner",1
[FLINK-10247] Return TaskManager metricy query paths in non-blocking fashion,2
[FLINK-10247] Update MiniCluster to run MetricQueryService in separate ActorSystem,5
[FLINK-10247] Start metrics ActorSystem under metrics,5
[hotfix] Add MetricUtils#startMetricsActorSystemSingle place where the metrics ActorSystem is instantiated.,5
"[FLINK-10247] Introduce port range option for Flink's metrics query serviceIn order to make the port used for Flink's internal metrics query service configurable,this commits adds the metrics.internal.query-service.port config option. This optionspecifies a port range from which the metric query service picks a free one to bind to.Per default, a random port is picked.This closes #6759.",5
[hotfix] [tests] JobManager -> Dispatcher in DispatcherProcess,3
"[FLINK-10426] Port TaskTest to new code base[FLINK-10426] (Part 1) testRegularExecution[FLINK-10426] (Part 2) porting fails1. testCancelRightAway2. testFailExternallyRightAway3. testLibraryCacheRegistrationFailed4. testExecutionFailsInNetworkRegistration5. testInvokableInstantiationFailed6. testExecutionFailsInInvoke7. testFailWithWrappedException8. testCancelDuringInvoke9. testFailExternallyDuringInvoke10. testCanceledAfterExecutionFailedInInvoke11. testExecutionFailsAfterCanceling12. testExecutionFailsAfterTaskMarkedFailed13. testCancelTaskException14. testCancelTaskExceptionAfterTaskMarkedFailed[FLINK-10426] (Part 3) partition state update testsSee also FLINK-10319, some of these tests would be removed based on that.[FLINK-10426] (Part 4) watch dog[FLINK-10426] (Part 4) config",5
[FLINK-10426] Replace TaskManagerActions mocks in TaskTestThis closes #6778.,3
[hotfix] Fix checkstyle violations in TaskTest,3
[hotfix] Fix checkstyle violations in ExecutionGraphRestartTest,3
"[hotfix] [tests] Speed up ExecutionGraphRestartTest#testFailingExecutionAfterRestart, #testRestartAutomatically",3
[hotfix] Refactor ExecutionGraphRestartTest to reuse cancellation logic,2
[hotfix] Remove mocking from ExecutionGraphRestartTest,3
"[FLINK-9788] Fix ExecutionGraph inconsistency for global failures when restartingThe problem was that a concurrent global failure could start a concurrentrestart operation without terminating the previous operation. Terminatingthe previous restart operation means to cancel all current Executions andwait for cancellation completion. Due to the missing wait, it could happenthat previously reset Executions are being tried to reset again. This violatesa sanity check and would lead to a restart loop.The problem is fixed by not distinguishing between a fail which happens instate JobStatus.RESTARTING and in any other state. Due to this, we will alwayscancel all existing Executions and only trigger the restart after all Executionshave reached a terminal state.",0
[FLINK-9752][s3-fs-connector] Add s3 recoverable writer.Adds a recoverable writer for S3.The new recoverable writer is only available for Hadoop S3(not Presto) and uses the MultiPart feature to upload part files.,2
[FLINK-10529][build] Add flink-s3-fs-base to travis stage file.This closes #6795.,2
[hotfix] Fix typo in WindowedStream.This closes #6825.,2
[hotfix] Use semantically correct timeout in ExecutionGraph::scheduleEager.This closes #6831.,1
"[FLINK-10524] Retry MemoryManager#release if NoSuchElementExceptionThe MemoryManager#release method retries in case of ConcurrentModificationExceptions becausememory can be released concurrently. In case of concurrent releases we can also see aNoSuchElementException if we are in the ArrayList.Itr#next call past the concurrent modificationcheck and try to access, for example, an index which is exceeding the ArrayList's size. Thus,we should also retry on seeing a NoSuchElementException because it indicates a concurrentmodification.",1
[hotfix] S3 tests are ignored when no credentials provided.,1
[FLINK-10532] [docs] Fix broken links in documentation,2
[FLINK-10156][table] Deprecate Table.writeToSink().This closes #6805.,2
[FLINK-10528][table] Remove methods that were deprecated in Flink 1.4.0.- remove TableEnvironment.sql() deprecated with FLINK-6442- remove StreamTableEnvironment.toDataStream() and TableConversions.toDataStream() deprecated with FLINK-6543- remove Table.limit() deprecated with FLINK-7821This closes #6826.,2
[FLINK-10516] [yarn] fix YarnApplicationMasterRunner fail to initialize FileSystem with correct Flink Configuration during setupThis closes #6836.,1
[FLINK-10541][tests] Removed unused legacy methods in TestBaseUtils,3
[hotfix][javadocs] Remove repetition,4
[FLINK-10544][build] Do not use custom settings.xml for snapshots,5
[hotfix][build] Skip checkstyle for snapshot deployments,0
[hotfix][build] Remove reference to scala-2.11 profile,2
[FLINK-10135][metrics] Expose missing cluster-level metris again,2
[FLINK-10075][rest] Addnull check before KeepAliveWrite.flush,1
[hotfix][rest] Fix various javadoc references,2
[FLINK-10549][tests] Remove Legacy* tests,3
[FLINK-10545] Remove JobManagerLeaderSessionIDITCase,4
"[FLINK-10530][tests] Harden ProcessFailureCancelingITCase and AbstractTaskManagerProcessFailureRecoveryThe problem is that the Dispatcher actor is being started before it gains leadership. When using thestandalone high availability services, then we don't wait until the Dispatcher has confirmed itsleader session id. We only wait until the actor has become available. Due to that it can happen thatwe try to send a RPC message to the Dispatcher before it has actually set its leader session id.This commit changes the above mentioned tests to use HA mode based on ZooKeeper. With that, we willwait until the leader session id has been confirmed.This closes #6827.",5
[FLINK-10546] Remove StandaloneMiniCluster,5
[hotfix] Fix checkstyle violations in TaskExecutorTest,3
[hotfix] Introduce TestingJobMasterGatewayBuilder,3
"[FLINK-9932] Harden slot allocation protocolHarden slot allocation protocol by accepting task submissions for slots which are onlyallocated. Before, it was necessary that the slot was marked as active. This, however,required that task submissions come strictly after completing the slot offering whichis not the case. With this change, we mark all allocated and active slots as activeif the TaskExecutor receives a task submission.",4
[FLINK-9932] Add TaskExecutorTest#testOfferSlotToJobMasterAfterTimeoutThis closes #6780.,3
[FLINK-10554][build] Bump flink-shaded to 5.0,2
[FLINK-10551][rest] Remove legacy REST handlers,0
[FLINK-10474][table] Evaluate IN/NOT_IN with literals as local predicate.- Before IN/NOT_IN with many literals was executed as JOIN with VALUES input.This closes #6792.,2
[FLINK-8865] [sql-client] Add CLI query code completion in SQL ClientThis closes #6791.,1
[FLINK-8865] [sql-client] Finalize CLI query code completion in SQL Client- Allow code completion also for SQL Client specific statements- Fix invalid escaping/quoting- Remove invalid metadata table completion,5
[FLINK-10547][client] Remove LegacyCLI,4
[FLINK-10559][streaming] Remove LegacyLocalStreamEnvironment,4
[hotfix][javadocs] Update LocalFlinkMiniCluster references,5
[FLINK-10565][tests] Refactor SchedulerTestBase to remove legacy code pathsThis closes #6856.,4
[FLINK-4052] Use non-local unreachable ip:port in testReturnLocalHostAddressUsingHeuristicsThis closes #6853.Change-Id: If6dfbbde2190dead5e918dbdaf15b551975acd17,5
[FLINK-9697] Rename KafkaTableSource to KafkaTableSourceBase,2
[FLINK-9697] Rename KafkaTableSink to KafkaTableSinkBase,2
[FLINK-9697] Rename KafkaConsumerCallBridge to KafkaConsumerCallBridge09,2
[FLINK-9697] Upgrade slf4j from 1.7.7 to 1.7.15,2
[FLINK-9697] Remove usage of deprecated code in KafkaConsumerTestBaseThe method was unused and this was using code that is deprecated andremoved in Kafka 2.0,4
[FLINK-9697] Add connector version value for kafka 2.0,1
[FLINK-9697] Add new kafka connector module,1
[FLINK-9443][streaming] Remove unused parameter in StreamGraphHasherV2#generateNodeLocalHash,2
[FLINK-10405] [tests] Port JobManagerFailsITCase to new code base (#6841)* [FLINK-10405] [tests] Port JobManagerFailsITCase to new code base* revert redundant assertion,3
[FLINK-10440][cassandra] Add CassandraPojoOutputFormat,1
"[hotfix][network] Make prune auto clear the bufferIt makes it more consistent and explicit. Previously it was assumed thatbuffer is clear before pruning and it was used that way, but thereticallyprune that's not proceeded/followed by clear would result in incosistent stateand position that points to non existing data.",5
"[FLINK-10537][network] Fix network small performance degradation after merging [FLINK-9913]Checks removed by this commit were performed once per every record, whileBefore [FLINK-9913] those checks were executed only once per""continue writing with new buffer"". Apparently those checks have some overheadonce per record while are helping to avoid the need to commit the data very rarelly.",5
[FLINK-10253] Run MetricQueryService with lower priority,1
[FLINK-10253] Add ActorSystemExecutorConfiguration to configure ActorSystem's executorAdd MetricUtilsTest#testStartMetricActorSystemRespectsThreadPriorityThis closes #6839.,5
"[FLINK-10582][rest] Make REST executor's thread priority configurableIntroduce RestOptions#SERVER_THREAD_PRIORITY(""rest.server.thread-priority"") to configure thethread priority of the REST executor's threads.",5
[hotfix][rest] Simplify thread-priority description,0
[FLINK-10579][build] Remove unused deploysettings.xml,5
[hotfix][javadocs] Replace odd single quotes,2
"[FLINK-10511][Cluster Management] Reuse the port selection and RPC service creation in JM and TMThis commit adds an overload method to create RPC service for specificport range in AkkaRpcServiceUtils and get rid of the port selectionlogic in TaskManagerRunner. Meanwhile, the AkkaRpcServiceUtils passthe work of akka config generation to BootstrapTools.This closes #6845.",5
[FLINK-10567][state] Fix TtlStateSerializer doe not propagate all field serializer during duplicate()This closes #6860.,0
[FLINK-10580] Harden BootstrapTool#startActorSystemInstead of opening a socket to check whether a given port is free we simply start anActorSystem with it an check whether it can bind to this port. This also solves the problemthat a 0 port get resolved to a specific port which might get taken between closing thetest socket and starting the ActorSystem.,5
[FLINK-10057] Update FlinkYarnSessionCli.javaoptimalize org.apache.flink.yarn.cli.FlinkYarnSessionCli.isYarnPropertiesFileModeThis closes #6491.,2
"[hotfix][table,test] Deduplicate code in ExpressionTestBase",3
"[hotfix][table,test] Improve error message in ExpressionTestBase",3
[hotfix][table] Rewrite TemporalJoin from CoProcessFunction to TwoInputStreamOperator,1
[FLINK-9715][table] Support temporal join with event time,1
[FLINK-10398] Add Tanh math function supported in Table API and SQL,1
"[FLINK-10508] Port ""The JobManager actor must handle jobs when not enough slots"" to MiniClusterITCase#testHandleJobsWhenNotEnoughSlot",5
[hotfix] a bit refactor of MiniClusterITCase,5
[FLINK-10508] Port scheduling test1. JobManagerITCase.The JobManager actor must support immediate scheduling of a single vertex2. JobManagerITCase.The JobManager actor must support queued scheduling of a single vertexFLIP-6 always allow queued scheduling because we need to request slots fromthe ResourceManager.Thus adjust MiniClusterITCase#runJobWithSingleRpcService andMiniClusterITCase#runJobWithMultipleRpcServices to cover it.,5
[FLINK-10508] Port jobs casesAll of cases below are ported to MiniClusterITCase#... corresponding.1. JobManagerITCase.The JobManager actor must support forward jobs2. JobManagerITCase.The JobManager actor must support bipartite job3. JobManagerITCase.The JobManager actor must support two input job failing edge mismatch4. JobManagerITCase.The JobManager actor must support two input job5. JobManagerITCase.The JobManager actor must support scheduling all at once6. JobManagerITCase.The JobManager actor must handle job with a failing sender vertex7. JobManagerITCase.The JobManager actor must handle job with an occasionally failing sender vertex8. JobManagerITCase.The JobManager actor must handle job with a failing receiver vertex9. JobManagerITCase.The JobManager actor must handle job with all vertices failing during instantiation10. JobManagerITCase.The JobManager actor must handle job with some vertices failing during instantiation11. JobManagerITCase.The JobManager actor must check that all job vertices have completed the call to finalizeOnMaster before the job completes,0
"[FLINK-10508] Port Savepoint relevant tests1. ""JobManagerITCase.The JobManager actor must handle trigger savepoint response for non-existing job"" -> SavepointITCase#testTriggerSavepointForNonExistingJob2. ""JobManagerITCase.The JobManager actor must handle trigger savepoint response for job with disabled checkpointing"" -> SavepointITCase#testTriggerSavepointWithCheckpointingDisabled3. ""JobManagerITCase.The JobManager actor must handle trigger savepoint response after succeeded savepoint future"": removed.mechanism guarded by SavepointITCase and other savepoint tests; no need to check message since FLIP-6 is not directly based on Akka.",3
[FLINK-10508] Remove JobManagerITCaseThe session timeout test cases are obsolete with the Flip-6 code base.The savepoint failure message handling should be covered by tests inSavepointITCase.This closes #6834.,3
[hotfix] Speed up MiniClusterITCase,5
[FLINK-10384] Add Sinh math function supported in Table API and SQL,1
[FLINK-10602] Use metric's ActorSystem in MetricFetcherUse the metric system's ActorSystem in the MetricFetcher. This makes the fetchingof metrics run in a separate ActorSystem from the one used in the RpcService. Thisshould decouple Flink from the metric system further and allows to individuallyconfigure both systems.,5
[hotfix][runtime] Log stacktrace if checkpoint cannot be ack'ed.,2
[hotfix][tests] Remove invalid logger from log4j config.,5
"[FLINK-10309][rest] Before shutting down cluster, wait for asynchronous operations.Wait for the result of asynchronous operations to be served before shutting downthe cluster.  This is necessary for the ""cancel with savepoint"" operation. If wedo not wait for the result to be accessed by the client, we may shutdown thecluster, and the client gets a ConnectionException.Extract CompletedOperationCache from AbstractAsynchronousOperationHandlers toease unit testing.This closes #6785.",3
"[FLINK-10309][tests] Replace wait-notify with CountDownLatches.Replace the use of wait-notify with CountDownLatches inRestServerEndpointITCase. The wait() method can have spurious wakeups which waspreviously not considered. Also refactor the tests that use the TestHandler toavoid code duplication, and to separate concerns.",3
"[FLINK-10563] Expose shaded Presto S3 filesystem under ""s3p"" scheme",5
[FLINK-10423][rocksdb][metrics] Expose Rocksdb native metrics,5
[hotfix] Further speed up MiniClusterITCaseUse shared RpcService for most of the MiniClusterITCases.,5
[FLINK-10608][avro] Add exclusion for generated avro files,2
[FLINK-10412] toString field in AbstractID should be transient to avoid been serialized,2
[FLINK-10412] Add test to ensure that improved AbstractID can be deserializedThis closes #6755.,1
"[FLINK-10614] Let test_batch_allround.sh rely on test-runner-common.sh for clean upWith FLINK-9638, we introduced the test-runner-common.sh script which is responsible for stoppingFlink resources and reverting all changes a test might have applied. This commit updates test_batch_allround.sh accordingly.",3
[FLINK-10527] Cleanup constant isNewMode in YarnTestBase,3
[FLINK-10607][network][test] Unify to remove duplicated NoOpResultPartitionConsumableNotifier,4
[FLINK-7062][table][cep] Initial support for the basic functionality of MATCH_RECOGNIZE,1
[hotfix][cep] Throw exception when skipping to first element of a match,0
[hotfix][cep] Changed cep operator names to distinguish between global and keyed,1
[hotfix][cep] Added equals/hashcode to Pattern/SkipStrategies/Quantifier,1
[hotfix][table] Allowed using '|' and stripMargin with indenter,1
[FLINK-7062][table][cep] Improved support of basic functionality of MATCH RECOGNIZEThis closes #6815This closes #4502,1
[hotfix][docs] fix SSL docs headings and add a TOC,1
[hotfix][docs] add complete configuration options to SSL docs,2
[hotfix][webmonitor] add @Nullable to SSL engine factory,1
[FLINK-9878][network][ssl] add more low-level ssl optionsThis is mostly to tackle bugs like https://github.com/netty/netty/issues/832(JDK issue during garbage collection when the SSL session cache is not limited).We add the following low-level configuration options for the user to fine-tunetheir system:- SSL session cache size via 'security.ssl.internal.session-cache-size'- SSL session timeout via 'security.ssl.internal.session-timeout'- SSL handshake timeout via 'security.ssl.internal.handshake-timeout'- SSL close notify flush timeout via 'security.ssl.internal.close-notify-flush-timeout'This closes #6895.,5
[FLINK-10639][docs] Fix java syntax error in documentThis closes #6902,2
"[FLINK-9975][hadoop] also shade Hadoop's io.netty dependencyThis is to prevent user code from clashing on Netty which we did shade awayusing its old namespace: org.jboss.netty. Hadoop >= 2.7, however, upgradedNetty and rely on the new package: io.netty.",1
[FLINK-9737] [table] Add more auxiliary methods for descriptor properties,1
[FLINK-9737] [table] Make function validation optional,5
"[FLINK-9737] [FLINK-8880] [sql-client] Support defining temporal tables in environment filesThis commit introduces the definition of temporal tables also to the SQL Client. Similar totable views, temporal table definitions need to reference a different table source ortable view. Thus, the definition order is important which is why this code refactorsthe parsing of environment files. The recently introduced top-level section `views`has been integrated into `tables`; temporal tables are defined there as well. As aside effect of the refactoring, properties are also validated for data type andvalue bounds now.This closes #6897.",5
[FLINK-10606][network][test] Construct NetworkEnvironment simple for tests,3
[hotfix][test] Add tests for releasing memory by BufferPoolOwner with different ResultPartitionType,3
[FLINK-10491][network] Fix deadlock between LocalBufferPool and SpillableSubpartitionPreviously LocalBufferPool.setNumBuffers would call SpillableSubpartition.releaseMemory(synchronized on `buffers` lock) under the availableMemorySegments lock and this wasdeadlocking with another thread taking the same locks in oposite order (for examplefrom SpillableSubpartition.spillFinishedBufferConsumers).The solution is to pass BufferPoolOwner in the constructor of LocalBufferPooland to release memory in LocalBufferPool.setNumBuffers outside of the synchronizedsection.This closes #6809.,1
[FLINK-10425][runtime] Use TaskManagerOptions#HOST,1
[FLINK-10570][cep] Fixed clearing shared buffer nodes when using After match skip strategy,1
"[FLINK-10669][e2e] Fixed error & exception checking in logsPreviously the 'q' flag of grep make the last element of pipeline exitas soon as the condition was satisfied. This resulted that if there weremultiple log files and the condition was met for the first file,operations on subsequent files tried to write to closed pipe whichresulted in pipefail code and the if condition to be evaluatedincorrectly.",0
[FLINK-10220][e2e][table] Removing logs for streaming sql e2e test before validation,5
"[FLINK-10637] Use MiniClusterResource for tests in flink-runtimeRename MiniClusterResource into MiniClusterWithClientResource and move base functionalityin the form of MiniClusterResource into flink-runtime. The new base class simply starts aMiniCluster with random ports.Moreover, this commit lets almost all tests in flink-runtime use the MiniClusterResourceto guarantee that there are no port conflicts between concurrently executed tests.This closes #6899.",3
[FLINK-10621][runtime] Properly use ExecutorService in BootstrapToolsTest,3
[FLINK-10657][tests] Fix visibility issue in TPCHQuery3,0
[hotfix] [python] Set PythonPlanBinder logger to private,2
[FLINK-10663][streaming] Fix NPE when StreamingFileSink is closed without initialization. (#6915),5
[FLINK-10613][hbase][tests] Remove logger casts,2
[FLINK-10599][Documentation] Provide documentation for the universal (1.0.0+) Kafka connector (#6889),2
[hotfix][docs] Fix various typos,2
[FLINK-10692] Harden Confluent schema registry E2E testThis commit fails the Confluent schema registry E2E test test_confluent_schema_registry.shif it cannot start the Confluent schema registry. Before the test would simply deadlock insuch a situation.,3
[FLINK-10702][scala-shell] Yarn app is not killed when scala shell is terminated,2
"[FLINK-10695] ""Cannot load user class"" errors should set the underlying ClassNotFoundException as their causeThis closes #6945.",1
[hotfix][cep] fix typos in cep quantifier error message,0
"[FLINK-10675][sql-client][table] Fixed depdency issues in cep & table/sql-client integrationSql-client depends table api which results that table-api is included inthe classloader of sql-client. As table api extends some interfaces fromcep library for MATCH_RECOGNIZE it has to be in the same classloader ascep library, therefore we need to add dependency on cep to sql-client aswell.As cep library may be in user classloader, we should use thatclassloader for checking presence of cep library.",1
[FLINK-10623][e2e] Extended sql-client e2e test with MATCH_RECOGNIZE,3
[hotfix][table] Added default branches to pattern matching to supress warnings,2
[hotfix] [docs] Fix typo in ConfigGroups,5
"[FLINK-10687] [table] Introduce flink-table-commonBecause more and more table factories for connectors and formats areadded and external catalog support is also on the horizon, flink-tablebecomes a dependency for many Flink modules. Since flink-table isimplemented in Scala it requires other modules to be suffixes withScala prefixes. However, as we have learned in the past, Scala codeis hard to maintain which is why our long-term goal is to avoidScala/Scala dependencies.This commits adds a new module flink-table-common that containsinterfaces between flink-table and other modules. This module isimplemented in Java and should contain minimal (or better no)external dependencies.",1
[FLINK-10687] [table] Move TableException and ValidationException to flink-table-common,2
[FLINK-10687] [table] Move TableSchema to flink-table-common,2
[FLINK-10687] [table] Move TypeStringUtils to flink-table-common,2
[FLINK-10687] [table] Move DescriptorProperties to flink-table-common,2
[FLINK-10687] [table] Move format factories to flink-table-common,2
"[FLINK-10687] [table] Move format descriptors and validators to flink-table-commonThis commit makes the flink-formats module Scala free by introducing aflink-table-common module that is implemented in Java. This module containsall classes that are required across different Maven modules.Additionally, all classes in this module have been annotated with @Internaland @PublicEvolving accordingly.Since the methods in Descriptor were declared with private[flink] visibility,they have been migrated to a new toProperties() method that is public.This closes #6958.",1
[FLINK-8995][tests] Add keyed state that uses custom stateful serializer to allround test jobThis closes #6909.,3
[FLINK-10679] Rename TypeSerializerSnapshot read/write methodsThis is necessary to avoid clashes with the write() method ofIOReadableWritable/TypeSerializerConfigSnapshot.,5
[FLINK-10679] [core] Let TypeSerializerSnapshot.resolveSchemaCompatibility be the entry point for all compatibility checks,1
[FLINK-10679] [core] Factor out reusable read/write logic for serializer snapshots,2
[FLINK-10679] [state-backends] Remove usage of CompatibilityResult and CompatibilityUtil from state backends,4
"[FLINK-10679] [state-backends] Remove isSerializerPresenceRequired flag from KeyedBackendSerializationProxyInstead, state backends should not be accessing the restore serializerunless necessary.Towards this end, RocksDB should not be instantiatingRegisteredKeyValueStateInformation with state meta info snapshots.RegisteredKeyValueStateInformation should be immutable objects that areready to be used by runtime for state access (getting serializers, etc).It does not make sense to create them solely from info snapshots,because the serializer snapshots don't guarantee that a restoreserializer can be present.",1
[FLINK-10679] [tests] Adapt state backend / serializer tests to new behaviours,1
[hotfix] Various code cleanup in serializers,4
[FLINK-10710] [core] Implement new CompositeSerializerSnapshot and migrate EitherSerializer / GenericArraySerializer,1
[FLINK-10708] [tests] Introduce SerializerMigrationTestBase,3
[FLINK-9808] [state backends] Migrate state when necessary in state backends,2
[FLINK-10605] [avro] Upgrade AvroSerializer and snapshot for Avro schema evolutionThis closes #6881.,2
[FLINK-10709] [core] Remove NS generic from TypeSerializerSchemaCompatibility,4
[FLINK-10710] [core] CompositeSerializerSnapshot should be used composition,1
"[FLINK-10716] Upgrade ListSerializer / ArrayListSerializer for state evolutionThis upgrades their snapshot classes to implement the new interface, aswell as add their corresponding migration tests.",3
[FLINK-10717] [core] Introduce SimpleSerializerSnapshot as replacement for ParameterlessTypeSerializerConfig,5
[FLINK-10723] [core] Upgrade MapSerializer and snapshot for state evolution,2
"[FLINK-10357][tests] Improve StreamingFileSink E2E test stability. (#6907)[FLINK-10357][tests] Improve StreamingFileSink E2E test stability.Previously, we relied on checkpoint statistics to decide when to re-check thenumber of files written by the sink under test. However, side effects aretriggered asynchronously, i.e., it can happen that statistics are updated beforeside effects are triggered (rolling of files). This can lead to test failuresdue to hash mismatches. We now wait until the number of expected lines werewritten to the file system.",5
[FLINK-10726] [table] Include flink-table-common in flink-table jarThis closes #6964.,2
[FLINK-9635][scheduling] Avoid task spread-out in scheduling with local recoveryThis closes #6961.,2
[FLINK-10166] [table] Reduce dependencies by removing org.apache.commonsThis commit removes all dependencies to org.apache.commons libraries in flink-table. Inthe past we only used a couple of methods that were partially pulled in from Hadoopcausing the issues mentioned in the JIRA ticket.This closes #6966.,0
[FLINK-10690][tests] Fix Files.list resource leaks,2
[FLINK-7816] Support Scala 2.12 closures and Java 8 lambdas in ClosureCleanerThis updates the ClosureCleaner with recent changes from SPARK-14540.,4
"[FLINK-7811] Add ""override"" in Scala code to support Scala 2.12Some places in the code didn't have override, this wasn't a problem forScala 2.11 but Scala 2.12 seems to be more strict.",0
[FLINK-7811] Make Long literal explicit to support Scala 2.12,1
[FLINK-7811] Add implicit types to make Scala 2.12 happyThis wasn't a problem for Scala 2.11 but Scala 2.12 seems to be morestrict.,0
[FLINK-7811] Add use ForkJoinPool from Java package for Scala 2.12 supportScala 2.12 doesn't have ForkJoinPool there anymore.,1
[FLINK-7811] Fix recursion bug in TypeInformationGenIt seems this wasn't a problem with Scala 2.11 but with 2.12 we go intoinfinite recursion.The fix should still be good for 2.11.,0
[FLINK-7811] Update to grizzled 1.3.2 to support Scala 2.12Our previous grizzled dependency is too old for Scala 2.12,1
[FLINK-7811] Update scalatest to 3.0.0 for Scala 2.12 supportOur previous dependency was too old.,1
[FLINK-7811] Fix TestingJobManagerLike for Scala 2.12,3
[FLINK-7811] Disambiguate ZooKeeperHAJobManagerTest for Scala 2.12The new Scala 2.12 typechecker didn't like this.,1
[FLINK-7811] Disambiguate Graph.scala methods for Scala 2.12 support,1
[FLINK-7811] Disambiguate method calls for Scala 2.12 supportThese changes are required for 2.12 support and also work on Scala 2.11.,1
[FLINK-7811] Fix japicmp exclusion patternIt seems \$ doesn't work but $$ does. I noticed this when changingDataStream.scala.,5
"[FLINK-7811] Add DataStream.keyBy() that takes KeySelectorPreviously we only allowed a lambda here, which was an omission.This also adds support for KeySelector on other operations that need akey.",1
[FLINK-7811] Remove macro paradise plugin,4
[FLINK-7811] Update breeze dependency and add explicit types in FlinkMLThis is needed for Scala 2.12 compatibility,2
[FLINK-7811] Disambiguate Scala Example code to work with Scala 2.12,1
[FLINK-7811] Update Kafka version of Kafka connector base,5
"[FLINK-7811] Add ScalaKryoInstantiator from Chill 0.7.4 and update to 0.7.6We have to do this in order to be able to update our Chill dependencywithout changing the the Kryo serializers that are registered bydefault.The problem is that snapshots of our Kryo serializer only contain theuser-registered serializers, not the serializers that are registered bydefault by Chill. If we had that, we could probably get by without thischange.The reason we have to update is that there is no Chill 0.7.4 dependencyfor Scala 2.12.",5
[hotfix] Remove unused testing savepoints,3
[FLINK-7811] Make Scala savepoint migration tests Scala-version-independent,3
[FLINK-7811] Add SerialVersionUID to Scala test classes to make it work on Scala 2.12They didn't have a SerialVersionUID before and it seems Scala 2.12assigns different UIDs from Scala 2.11 so we have to fix them to thosethat Scala 2.11 assigned automatically.,1
[FLINK-7811] Add scala.Enumeration to ignore list for Scala SerialVersionUIDIt seems that the SerialVersionUID of this changed between 2.11 and2.12. We need to ignore it so that we can restore savepoints taken on a2.11 build with a 2.12 build.,4
"[FLINK-7811] Make IterateExample.Bound final so it can be used in withinBound()With Scala 2.12, the ClosureCleaner will complain that the filterfunction that uses withinBound() is not serializable. The reason is thatwhen ""Bound"" is not final it will serialize it with the closure, wichincludes IterateExample.",1
"[FLINK-7811] Add Scala 2.12 profileThis changes some modules that had a _2.11 dependency but didn't exposeit in their module name to instead depend on the ${scala.binary.version}dependency.The main reason for this is to make the build self contained, before,with the hard-dependency on 2.11, when buildig for 2.12 it would not beclear where the dependency would come from because it is not created aspart of the build. This could lead to inconsistencies. For example, whenadding a new class in flink-runtime but not recompiling on 2.11 but onlyon 2.12, the 2.12 tests would fail when using that new class becausethey would use 2.11 dependencies that weren't rebuilt with the newclass.We also don't build flink-scala-shell and flink-connector-kafka-0.8because they don't work with Scala 2.12.This also includes $PROFILE in dependency convergence check script. Thisis in preparation for building with ""-Dscala-212"", where we hace toexclude certain things.We also exclude Kafka 0.8 from stages when building for Scala 2.12And add Scala 2.12 to the release scripts",1
"[FLINK-10727][network] remove unnecessary synchronization in SingleInputGate#requestPartitions()In `SingleInputGate`, for every `getNextBufferOrEvent()`, `requestPartitions()`is called and this always synchronizes on the `requestLock` before checking the`requestedPartitionsFlag`.Since `requestPartitions()` is only called from the same thread (the task threadgetting the record), it is enough to check the `requestedPartitionsFlag` firstbefore synchronizing for the actual requests (if needed).`UnionInputGate` already goes the same way in its `requestPartitions()`.",1
"[FLINK-8987][e2e] Add state evolution/migration e2e test.Adds two e2e tests, one testing the avro evoluttion andone for general state migration from Flink-1.6. The latteris added to test that none of the changes related tostate evolution  broke state migration.",4
[hotfix] Add Scala binary version suffix to flink-sql-client dependency in flink-dist/pom.xml,5
[FLINK-10097][DataStream API] Additional tests for StreamingFileSink.,2
[hotfix] [Scala API] Simplify generics in EitherSerializer,0
[FLINK-10693] [Scala API] Fix incorrect duplication in EitherSerializerThis closes #6951.,0
[FLINK-10678][e2e] Introduced switch to disable log checking in e2e tests,3
[hotfix][docs] Fix errors in Elasticsearch6 exampleschanged variable names and added missing imports in Elasticsearch6 examples for both java and scala,2
[FLINK-10681] Harden ElasticsearchSinkITCase against wrong JNA librarySet the system property jna.nosys=true to avoid ElasticsearchSinkITCase test failuresdue a wrong JNA version.,0
[FLINK-10739][tests] Harden ProcessFailureCancelingITCase.testCancelingOnProcessFailure.This closes #6993.,3
[hotfix] Set number of Mesos agent CPUs to 8This commits sets the number of CPUs on a Mesos agent to 8 which is the sameas the number assigned vcores to a NodeManager in the Yarn case. This allowsto spawn 3 Mesos tasks on an agent if there is enough memory. This will giveus the same number of TMs possible as in the Yarn case.,1
[FLINK-10631] Set number of slots per TM to 3 for Jepsen tests,3
"[FLINK-10752][yarn] Use the validated cluster resources in AbstractYarnClusterDescriptor (#6991)* use the validated resources* removed unnecessary, effectively unused validation against hardcoded minimal limits for yarn containers",5
[FLINK-10632][e2e] Running general purpose testing job with failure inper-job mode,0
[FLINK-10754] Enable local recovery for Jepsen based tests,3
[FLINK-10581] Increased the threshold for memory verification in YarnConfigurationITCase.testFlinkContainerMemory,5
"Revert ""[FLINK-10727][network] remove unnecessary synchronization in SingleInputGate#requestPartitions()""This reverts commit 194603a89844af1f6613b88d6401d28a170494a6 because it caused thecreation of sub partitions to fail.",0
[hotfix] Let S3EntropyFsFactoryTest extend from TestLogger,3
[FLINK-10757] [tests] Avoid port conflicts in AbstractTaskManagerProcessFailureRecoveryTestThis closes #6998.,3
"[FLINK-10715] Suppress ConcurrnetModificationException in Slf4jReporterThis commit suppress the ConcurrentModificationException thrown by the Slf4jReporterreport method. This exception occurs when a metric is added/removed while this report is reporting.Suppressing this (somewhat expected exception) is needed by our e2e framework to reduce somefalse-positive e2e test failures. This does not solves the root issue, which is being tracked in a different issue FLINK-10035.This closes #7008.",2
Update version to 1.8-SNAPSHOT,5
[hotfix] Add release notes for Flink 1.8,2
[FLINK-10490][tests] OperatorSnapshotUtil should use SavepointV2SerializerPlease not that state written with OperatorSnapshotUtil before this commit was written in the V1 format.Now we are using the current V2.This closes #6910.,1
[FLINK-10368][e2e] Hardened kerberized yarn e2e test* wait for whole  bootstrapping script to execute on masternode before submitting job* retrying to start hadoop cluster. Failling test in case could not start hadoop cluster.* added check that all containers are up and running before submittingjob* reduced memory requirements for the kerberized yarn test,3
"[FLINK-10772][release] Fix create_binary_release.shRemove the unnecessary call to change_scala_version.sh and remove the-Dmaven.test.skip=true property. The latter is necessary because thisproperty suppresses the compilation and packaging of test classes. It,however, does not suppress the resolution of test dependencies whichwill then fail to compile because test dependencies have not been built.This commit also removes the redundant call to buildflink-shaded/hadoop/flink-shaded-hadoop2-uber which is a dependencyof flink-dist anyway.",2
[FLINK-10773] Harden resume externalized checkpoint end-to-end testIgnore the 'Artificial Failure' exceptions and renameExceptionThrowingFailureMapper into FailureMapper to avoid falsepositive exception matchings.,0
[FLINK-10364][tests] Fix instability in NonHAQueryableStateFsBackendITCase#testMapStateThis closes #6975.,3
"[FLINK-10638][table] Invalid table scan resolution for temporal join queriesPreviously there was a strict fixed order of applying LogicalCorrelateToTemporalTableJoinRuleand TableScanRule rules. This was causing problems, since either of them could create a newRelNodes that have to be subject of the other rule (imagine deeply nested TemporalTableFunctionthat references registered tables/views and other TemporalTableFunctions).Solution to this problem is to run both of those rules in one group/collection in HepPlaner.Instead of applying one rule to whole tree then the other rule, both rules are applied toa parent node, before going down/deeper.",1
[FLINK-10627][e2e] Test s3 output for streaming file sink.This closes #6957.,2
[FLINK-10793][ttl] Change visibility of TtlValue and TtlSerializer to public for external toolsThis closes #7021.,4
[FLINK-8897] [table] Reintroduce materialization of time attributes in filters,2
[hotfix] [table] Simplify time attribute handling for joins,0
[hotfix] [table] Move utility method down in JoinTest,3
[hotfix] [table] Refactor SqlToConverter configurationThis closes #6857.,5
[FLINK-10655][rpc] fix RemoteRpcInvocation not overwriting ObjectInputStream's ClassNotFoundException,0
[FLINK-10600] Provide End-to-end test cases for modern Kafka connectors,3
[FLINK-10633][prometheus] Add end-to-end test,3
[FLINK-10463][table] Null literal cannot be properly parsed in Java Table API function callThis closes #6888.,1
[FLINK-10720][tests] Add deployment end-to-end stress test with many inflated task deployment desciptorsThis closes #6994.,5
[FLINK-8985] [e2e] Add a Flink CLI end-to-end testThis closes #5863.,3
[FLINK-8985] [e2e] Add additional checks and error messages to CLI test,3
[hotfix][tests] Fix Files.walk resource leak,2
[hotfix] [e2e] Add missing Kubernetes test,3
[hotfix] [e2e] Categorize nightly tests,3
[FLINK-10800][network][test] Abstract StreamPartitionerTest for common codes,3
[FLINK-10353][kafka] Support change of transactional semantics in Kafka Producer with existing stateThis closes #7010.,4
[hotfix][tests] Deduplicate the default timeout constants in FlinkKafkaProducerITCase,2
[FLINK-10704][end-to-end] Fix sql client end to end test failure,0
[hotfix][metrics] Cleanup test-utilts-junit dependency,3
[hotfix][build] Remove outdated comment,5
"[FLINK-10711] [e2e] Allow basic error handling with bashThis commit modifies the test infrastructure to allow bash's basicerror handling mechanism with set -e. Many tests are notready for a globally defined strict error handling. For now, atleast newly developed tests should consider this flag. If a testcauses an error, a test fails with ""[FAIL] Test script contains errors"".See the end-to-end test README for more information about how to developtests in the future.This closes #7023.",3
[FLINK-10797][docs] Fix broken ide_setup links,2
[FLINK-10805] [e2e] Fix failing end-to-end testsFix test_confluent_schema_registry.sh and test_sql_client.sh end-to-end tests which failedbecause of missing arguments for kafka-common.sh and the newly introduce set -e flag.This closes #7034.,1
[FLINK-10750][tests] Harden SocketClientSinkTestThe tests attempts to re-bind a server to a specific port. If the port is taken the test will fail.The test is now skipped instead if this happens.This closes #7040.,3
[FLINK-10812][build] Skip javadoc plugin for e2e-test-utils,3
[hotfix] Add RocksDB config options to documentation,2
[FLINK-10676][table] Change the over window preceding clause from required to optional.This closes #6949,1
[FLINK-10811][hcatalog] Add scala suffix,0
[FLINK-10816][cep] Fix LockableTypeSerializer.duplicate() to consider deep duplication of element serializerThis closes #7049.,0
[FLINK-10799][yarn] YARN mode JobManager JVM memory args add -XmsXXXm,1
[FLINK-10770] [table] Ensure calling open/close of generated functionsThis closes #7014.,1
[FLINK-10765][test] Include s3p schema in S3 testThis closes #7032.,3
[FLINK-10361][tests][ES] Properly wait for ES to startThis closes #7057.,3
[FLINK-10803][docs] Update the filesystem documentation for S3 (s3p).,2
[FLINK-10803][docs] Update the StreamingFileSink documentation for S3.,2
[FLINK-10791] Provide end-to-end test for Kafka 0.11 connector (#7038)[FLINK-10791][e2e] Provide end-to-end test for Kafka 0.11 connector,3
[hotfix][tests] Remove hard-coded scala versions,4
[hotfix][docs] Clarify unit for network.request-backoff,1
[FLINK-10825][tests] Increase request-backoff for high-parallelism e2e test,3
[FLINK-10814][examples] Add scala suffix to Kafka example module,0
[FLINK-10691][e2e] Remove dependency on hadoop for StreamSQL E2E test,3
[FLINK-10823][jdbc] Add scala suffix,0
[FLINK-10823][metrics][prometheus] Add scala suffix,0
[FLINK-10823][metrics][jmx] Add scala suffix,0
[FLINK-10733][tests] Inline clean_log_files(),4
[FLINK-10813][travis][scala] Automatically check scala-suffixes,0
[FLINK-10801][e2e] Retry verify_result_hash in elastichsearch-common (#7060)Instead of looping the verification until the expected number of resultsloop until we get the correct output. This tries to solve the problemof some records (aggregated? updated?) arriving later.,5
[hotfix] Follow up FLINK-6046 to clean unused variable,1
[FLINK-10771] Replace hard code of job graph file path with config option for FileJobGraphRetrieverThis closes #7054.,2
"[FLINK-10835][network] Remove duplicated round-robin ChannelSelector implementation (#7069)RoundRobinChannelSelector exists for default selector in RecordWriter mainly for tests. Another similar RoundRobin implementation exists in RecordWriterTest, only because the difference in starting channel index for round-robin.We can adjust the test verify logic to keep the same behavior with RoundRobinChannelSelector, and then remove the duplicated RoundRobin.",4
[FLINK-10789] [cep] LockableTypeSerializerSnapshot should be a TypeSerializerSnapshotThis also adds a migration test for the LockableTypeSerializer.,3
[FLINK-10789] [table] ListViewSerializerSnapshot should be a TypeSerializerSnapshotThis also adds a migration test for the ListViewSerializer.,3
[FLINK-10789] [table] MapViewSerializerSnapshot should be a TypeSerializerSnapshotThis also adds a migration test for the MapViewSerializer.,3
[FLINK-10789] [scala] ScalaEitherSerializerSnapshot should be a TypeSerializerSnapshotThis also adds a migration test for the Scala EitherSerializer.This closes #7028.,3
[hotfix] [core] Add missing precondition null checks in List-/MapSerializerSnapshot,1
[hotfix] [cep] Remove duplicate getElementSerializer() method from LockableTypeSerializer,1
[hotfix] Make test_sql_client independent of unzipSome platforms might not have installed the unzip command. Therefore it isbetter to use the jar command to extract jar files.,2
[FLINK-10626] [docs] [table] Add documentation for temporal table joinsThis closes #7065.,2
[FLINK-10826] [e2e] Decrease deployment size of heavy deplyment e2e test for TravisThis closes #7066.,3
[FLINK-10826] [e2e] Increase network timeout,1
"[FLINK-10821] E2E now uses externalized checkpointThis commit fixes the test_resume_externalized_checkpoints.sh script,by providing the path to the externalized checkpoint taken.",1
[FLINK-10839][serializer] Fix implementation of PojoSerializer.duplicate() w.r.t. subclass serializer,0
[FLINK-10827][tests] Add test for duplicate() to SerializerTestBaseThis closes #7061.,3
[FLINK-10809][state] Include keyed state that is not from head operators in state assignmentThis closes #7048.Signed-off-by: Stefan Richter <s.richter@data-artisans.com>,5
[FLINK-10753] Improve propagation and logging of snapshot exceptionsThis closes #7064.,2
[FLINK-10826] [e2e] Further decrease heavy deployment sizeIn order to enable stable nightly Travis cron jobs.,0
[hotfix] CheckpointDeclineException should lead to pendingCheckpoint.abortDecline()We also avoid logging exceptions that are cause by instances of CheckpointDeclineException,1
[FLINK-10861]][e2e] Do not fail stop_kafka_cluster if a process terminates before we kill it,0
[FLINK-10863][tests] Assign UIDs to all operators in DataStreamAllroundTestProgramThis closes #7085.,5
[FLINK-10419] Using DeclineCheckpoint message class when invoking RPC declineCheckpoint,1
[FLINK-10419] Added IT test to check declineCheckpoint invocation,3
[FLINK-10455][Kafka Tx] Close transactional producers in case of failure and termination (#6989)This commit addresses the problem of potential leak of resources associated with unclosed Kafka transactional producers in case of commitment failure or task shutdown.1. always close producer even if commit fails in TwoPhaseCommitSinkFunction#notifyCheckpointComplete2. close pending transactions in close method of Kafka Flink function in case of task shutdown3. continue trying to commit other transactions in TwoPhaseCommitSinkFunction#notifyCheckpointComplete if any of them failed,0
"[FLINK-10856] Take latest checkpoint to resume from in resume from externalized checkpoint e2e testSince it can happen that some empty checkpoint directories are left, we have to take the latestcheckpoint directory in order to resume from an externalized checkpoint. This commit changes thetest_resume_externalized_checkpoint.sh to sort the checkpoint directories in descending order andthen takes the head checkpoint directory.",3
[FLINK-10419] Call JobMasterGateway through RpcCheckpointResponder in test,3
[FLINK-10628][E2E][SSL] Enable mutual REST SSL auth in e2e tests,3
[FLINK-10624] Extend SQL client end-to-end to test new KafkaTableSinkThis closes #6927.,1
[FLINK-10767] Updated savepoint compatibility matrix with 1.7,5
[FLINK-10764][tests] Add ITCase for checkpoint path entropy injection. (#7075)Add a test that verifies that checkpoint data on the file system has additionalentropy added to its path.Remove code duplication in SavepointITCase.,4
[FLINK-10634][metrics][rest] Add metrics availability e2e test,3
[hotfix][tests] Fix typo in FutureUtils#retrySuccessfulWithDelay,1
[FLINK-10857][metrics] Cache logical scopes separately for each reporter,2
[hotfix] fix javadoc typo in LocalFileSystem.java,5
[hotfix][javadocs] Fix reference in KeyedSerializationSchemaWrapper,0
[FLINK-10144][runtime] Remove unused import in TaskManagerMessages.scala,2
[FLINK-10899] Remove explicit version tag from flink-metrics-availability-test and flink-metrics-reporter-prometheus-test,3
[hotfix] Skip log verification for the heavy deployment e2e test,3
[hotfix] Log SlotReport in SlotManager#reportSlotStatus,2
[hotfix] Fix checkstyle violations in SlotReport and SlotStatus,0
[FLINK-10877] Cleanup flink-connector-kafka pom fileRemove duplicate flink-connector-kafka-base test dependencies and exclusions.,3
[FLINK-10856] Find latest completed checkpoint for resume from externalized checkpoint e2e test,3
[hotfix] Fix checkstyle violation in ExecutionGraph,0
"[FLINK-10883] Failing batch jobs with NoResourceAvailableException when slot request times outInstead of failing the ExecutionGraph with a generic TimeoutException if a slot request times out,this commit changes the exception to a more meaningful NoResourceAvailableException.",4
[FLINK-10642] [table] Fix CodeGen split errors when maxGeneratedCodeLength equals 1This closes #6900.,0
"[hotfix][kafka][docs] Split long lines in kafka.mdLong lines are not diff/conflict resolution friendly, while md ignores new lines,so this change has no visible effect for the user.",1
[hotfix][kafka][docs] Couple of minor fixes in Kafka 2.0 connector documentation,2
[FLINK-10900][kafka][docs] Mark universal Kafka connector as betaBecause of frequent deadlocks and other failures in tests the connector is marked as beta.Those errors are probably only test issues or Kafka bugs but as for now it's not confirmed.,5
[FLINK-10843] [connectors] Change Kafka table factory version '2.0' to 'universal'This closes #7087.,4
[FLINK-10872] [e2e] Extend SQL Client end-to-end to for Kafka 0.11 connectorThis closes #7100.,2
[FLINK-10891] Upgrade Kafka client version to 2.0.1,2
[FLINK-10869] [build] Remove outdated secrets from travis buildThe secrets are replaced with build server environment variables.,5
[FLINK-10869] [tests] Add S3Credentials to get access to S3 test credentials,3
[FLINK-10869] [tests] Update all S3 tests to use new test credentials,3
"[FLINK-10869] [tests] Remove Yarn staging test for deprecated Hadoop s3:// filesystem.That filesystem is no longer supported by Hadoop, is discouraged to use, and isunable to work with any non-overall-permissive permission setup.",1
[FLINK-10869] [tests] Adjust end-2-end tests to new S3 credentials,1
[hotfix] [e2e] Do not print S3 credentials in test scripts,3
[FLINK-10869] [tests] Fix test_streaming_file_sink to use proper and unique output directory,1
[hotfix] Add release note that Flink's Scala shell does not work with Scala 2.12,1
[FLINK-10531][e2e] Fix unstable TTL end-to-end test.This closes #7036.,3
[hotfix] [tests] Make S3 Recoverable Writer tests ITCases,3
[hotfix] [s3] Minor fixes/code simplifications in S3 recoverable writer,0
[hotfix] [tests] Make S3 config key forwarding a proper unit testThis avoids unnecessary and expensive connections to S3 just to validate whether configkeys of various formats are forwarded.,5
[hotfix] [tests] Check for s3a and s3 schemes in a unit testThis avoid duplicating the very expensive and time consuming execution of theS3 file system integration tests.The scheme is an artifact purely of the factory with no need to test it inan integration test of the actual file system.,5
"[hotfix] [tests] Simplify and speed up S3 filesystem testsRather then reinitializing the S3 file system in each test, use one file systemacross tests. This reduces code and speeds up the test.",3
[FLINK-10736] [tests] Use staticly hosted test data for S3 wordcount testsThis avoids issues with eventual consistency/visibility on S3.,0
[FLINK-10906][docker] Don't print configuration in docker-entrypoint.shIn order to not leak secrets we should not print the configuration in docker-entrypoint.sh.,2
[FLINK-10913] Harden ExecutionGraphRestartTest#testRestartAutomaticallyWait until all Executions reach the state DEPLOYING instead of having a resource assigned.,3
[FLINK-10880] Add Documentation.ExcludeFromDocumentation to exclude ConfigOptions from documentationThe annotation Documentation.ExcludeFromDocumentation can be used to annotate ConfigOptionswith in order to not include them in the documentation.,2
[FLINK-10880] Exclude JobManagerOptions#EXECUTION_FAILOVER_STRATEGY from documentationThis commit excludes the JobManagerOptions#EXECUTION_FAILOVER_STRATEGY from Flink'sconfiguration documentation.,2
[FLINK-10880] Add release notes warning to not use Flink's failover strategy,0
[FLINK-10625] [docs]  Documentation for MATCH_RECOGNIZE clause,1
[FLINK-10625] [docs] Improvements to the MATCH_RECOGNIZE documentation,2
[FLINK-10625] [docs] Polishing MATCH_RECOGNIZE document,2
[FLINK-10916][streaming] Include duplicated user-specified uid in error message,0
[hotfix][javadocs] Finish sentence in FlinkKafkaConsumerBase,2
[FLINK-10666] [tests] Port YarnClusterDescriptorTest to new codebase,1
[FLINK-10235][kafka] Explicitly cast custom partitioner classes,2
[FLINK-10925][py] Check for null when closing socket,2
[FLINK-10670] [table] Fix Correlate codegen errorThis closes #6923.,0
[FLINK-10481][e2e] Added retry logic for building docker image,2
[FLINK-8997] Added sliding window aggregation to datastream test job,3
[FLINK-10893] [tests] Export S3 credentials properly for test scripts,3
[FLINK-10922] Refactor the placement of the Flink Kafka connector end to end test module,3
"[FLINK-10922] Remove Scala Kafka010Example from flink-end-to-end-testsThis commit removes the Scala based Kafka010Example from flink-end-to-end-tests/flink-streaming-kafka010-test module. Moreover, it adds relative paths to theirparent pom's and cleans up the flink-streaming-kafka*/pom.xml.",5
[FLINK-10922] Exclude transitive kafka-clients dependency from base flink-connector-kafkaIn order to satisfy dependency convergence we need to exclude the kafka-clients from the baseflink-connector-kafka-x dependency in every flink-connector-kafka-y module.This closes #7140.,2
[FLINK-10763] [streaming] Fix interval join return type in ScalaThis commit fixes the wrong result type of interval joins inthe DataStream Scala API. The API did not call the Scala typeextraction stack but was using the default one offered by theDataStream Java API.This closes #7141.,5
"[FLINK-5697] [kinesis] Add periodic per-shard watermark supportAdds support for periodic per-shard watermarks to the Kinesis consumer. Thisfunctionality is off by default and can be enabled by setting an optionalwatermark assigner on the consumer. When enabled, the watermarking alsooptionally supports idle shard detection based on configurable interval ofinactivity.- Add watermark assigner to consumer- Modify data fetcher to track watermark state per shard- Modify emitRecordAndUpdateState to extract timestamp and update watermark- Timer driven periodic watermark emitThis closes #6980.",5
[FLINK-10980][docs] Fix CEP documentation error.This closes #7158,0
[FLINK-10983][queryable state] Increase port range for NonHAQueryableStateFsBackendITCaseThis closes #7159,1
[hotfix] [table] Refactor aggregation harness tests to be found,3
[hotfix] [table] Show deserialization error cause,1
"[FLINK-10674] [table] Fix handling of retractions after clean upBecause state clean up happens in processing time, it might bethe case that retractions are arriving after the state hasbeen cleaned up. Before these changes, a new accumulator wascreated and invalid retraction messages were emitted. Thischange drops retraction messages for which no accumulatorexists. It also refactors the tests and adds more testcases and explanations.This closes #7147.",3
[FLINK-10951][tests] Set yarn.nodemanager.vmem-check-enabled to false (#7149),0
[FLINK-10842] [e2e] Fix broken waiting loops in common.shThis closes #7073.,0
[FLINK-10946] Silence checkpoint exception logging in task executor if job is not running,1
[FLINK-10958] [table] Add UDF's eval method parameters support subclass matching.This closes #7152,1
"[FLINK-10942][network,test] Deduplicate common codes in OutputEmitterTest (#7146)This is a pure refactoring commit - no functional changes.",4
[FLINK-10009][table] Fix the casting problem for built-in TIMESTAMPADD.This closes #7155,1
[FLINK-10998][metrics][ganglia] Remove Ganglia reporter,4
"[FLINK-11005] Define flink-sql-client uber-jar dependencies via artifactSetInstead of including every dependency and then limiting the set of includedfiles via a filter condition of the maven-shade-pluging, this commit definesan artifact set of included dependencies. That way we will properly includeall files belonging to the listed dependencies (e.g. also the NOTICE file).This closes #7176.",2
[FLINK-10992][tests] Revise Hadoop configuration. (#7164)Do not use /tmp directory to place log files or the HDFS data directory.Reconfigure dfs.replication to 1 because file availability is irrelevant intests.Increase heap size of HDFS DataNodes and NameNode.Change find-files! function to not fail if directory does not exist.,0
[FLINK-4173][metrics] Replace assembly-plugin usage,2
"[FLINK-10367][network] Introduce NotificationResult for BufferListener to solve recursive stack overflow (#6829)Before this fix, during LocalBufferPool#recycle, the recycled buffer would be notified to a BufferListener. But this BufferListener may not need floating buffers any more currently, so this buffer is recycled again to the LocalBufferPool, then another BufferListener is selected to be notified of this available buffer.The above process may be repeatedly triggered in recursive way that will cause stack overflow error in extreme case. We ever encountered this error triggered by release all resources during task failover in large scale job, especially it will also result in buffer leak after stack overflow.This fix removes recursive calls and replace them with a loop and adds a `NotificationResult` as a result from BufferListener#notifyBufferAvailable to inform the caller whether the buffer was used or not.",1
[FLINK-10990][metrics] Enforce minimum timespan in MeterView,5
[FLINK-10924][javadoc] Fix character set in readTextFile* methods,2
[hotfix][table] Improve scalar function test case to UserDefinedScalarFunctionTestThis is a follow up of FLINK-10958.This closes #7179,2
[FLINK-9574] [doc]  Rework docuementation for custom state serializers and state evolutionThis closes #7124.,2
[FLINK-11004] [docs] correct ProcessWindowFunction.process argument in documentThis closes #7175,2
[FLINK-11003][docs] Fix type parameter in lambda docs,2
[hotfix] Unify to rename variables from numChannels to numberOfChannels,0
"[FLINK-10820][network] Simplify the RebalancePartitioner implementationThe current RebalancePartitioner implementation seems a little hacky for selecting a random number as the first channel index based on Integer.MAX_VALUE. For the corner case of numChannels = Integer.MAX_VALUE, it would trigger next random index once reaching the last channel index. Actually the random index should be selected only once at the first time.We propose the new setup method in ChannelSelector interface for initialization before selecting channels.This closes #7051.",5
"[FLINK-10991][docker] Updated Dockerfiles to fulfill requirements of RocksDB* added libc6-compat package to all alpine-based Flink images for RocksDB statebackend* switched from deprecated ""library/java"" to ""library/openjdk"" docker base image",2
[FLINK-8159] [cep] Pattern(Flat)SelectFunctions should support RichFunction interface[FLINK-6938] [cep] IterativeCondition should support RichFunction interfaceThis closes #7110,1
[FLINK-10955] Extend release notes for Apache Flink 1.7.0,2
[FLINK-10987] Deactive ApacheLicenseResourceTransformer to add vanilla LICENSE and NOTICE file to every module,2
[FLINK-10987] Exclude packaged LICENSEs from license check by the apache-rat-plugin,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-streaming-python,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-sql-client,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-table,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-mesos,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-runtime-web,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-runtime,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-test-utils,3
[FLINK-10987] Add LICENSE & NOTICE files for flink-shaded-hadoop2,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-shaded-hadoop2-uber,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-shaded-yarn-tests,3
[FLINK-10987] Add LICENSE & NOTICE files for flink-shaded-curator,2
[FLINK-10987] Do not deploy flink-yarn-tests module to repository,3
[FLINK-10987] Add LICENSE & NOTICE files for flink-connector-twitter,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-metrics-datadog,5
[FLINK-10987] Add LICENSE & NOTICE files for flink-metrics-graphite,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-metrics-prometheus,2
[FLINK-10987] Add license notices for flink-filesystems,5
[FLINK-10987] Add licenses and notice for flink-swift-fs-hadoop,2
[FLINK-10987] Add LICENSE & NOTICE files for flink-dist,2
[FLINK-10987] Add NOTICE & licenses for binary releaseAdds a NOTICE-binary file and a licenses-binary directory containing all bundled licensesfor the binary release. When creating the binary release the NOTICE-binary file and thelicenses-binary directory will be copied and renamed to NOTICE and the licenses in the binaryrelease.,2
[FLINK-10987] Update source LICENSE & NOTICE filesThe source LICENSE and NOTICE files now follow the same pattern that the LICENSE fileonly contains the ASL 2.0 license and the dependencies are now listed in the NOTICE file.This closes #7191.,2
[hotfix] Remove flink-metrics-ganglia from flink-dist/pom.xml,5
[hotfix] Let CoGroupGroupSortTranslationTest extend TestLogger and fix testGroupSortTuplesDefaultCoGroup,3
[hotfix] Add release notes 1.7 and 1.8 to documentation front page,2
[hotfix] Add 1.7 to previous docs in docs/_config.yml,5
[hotfix] Bump japicmp Flink reference version to 1.7.0,2
[hotfix][table] Check if expected exception was thrown,0
[FLINK-11017][table] Throw exception if constant with YEAR TO MONTH resolution was used for group windowsThis closes #7200.,1
[hotfix] [docs] Fix typos in MATCH_RECOGNIZE docsThis closes #7194.,2
[hotfix] [table] Fix the misuse of assertEqualsThis closes #7190.,3
[FLINK-11015] Remove deprecated code for format-specific Kafka table connectorsThis commit removes all classes and methods that have been deprecated inFlink 1.6 for separating Kafka connectors from Avro and JSON formats.This closes #7182.,5
[hotfix][cep] Enabled distributed cache for CEP functions,1
[FLINK-10597] Enabled UDFs support in MATCH_RECOGNIZE,1
[hotfix][docs] Fix typo in StreamTableSoureFactory,4
[FLINK-10798] Add the version number of Flink 1.7 to MigrationVersionThis closes #7026.,2
[FLINK-10149][mesos] Don't allocate extra mesos port for TM unless configured to do so.This closes #7203.,5
[FLINK-10149][mesos] Replace string concatenation with slf4j placeholders,2
[FLINK-10149][mesos] Make returned port keys set immutable.,1
[FLINK-10149][mesos] Simplify assertions in LaunchableMesosWorkerTestUse Set equality to simplify test assertions.Change type of field LaunchableMesosWorker#TM_PORT_KEYS to Set<String>.,1
[FLINK-11013] [table] Fix distinct aggregates for group window in Table APIThis closes #7181,0
[FLINK-10689] [table] Port UDF interfaces to flink-table-commonThis commit ports all UDF extension points to Java and relocates themto flink-table-common. Projects that just want to provide functionsdon't need to import flink-table and thus Scala anymore.This closes #7059.,2
[FLINK-10689] [table] Improve docs and fix bugs of ported classes,0
[FLINK-10874][kafka-docs] Document likely cause of UnknownTopicOrPartitionException,1
[FLINK-7603] [table] Support WITHIN clause in MATCH_RECOGNIZEIntroduces support for WITHIN clause in MATCH_RECOGNIZE thatallows adding a time constraint for a pattern. It reuses thewithin function of Pattern in the CEP library. The behavioris such that the difference between first row in a match andlast row in a match must be smaller than the given period. TheWITHIN clause accepts only a constant millisecond interval value.,1
[FLINK-7603] [docs] Update documentation with WITHIN clause for MATCH_RECOGNIZEThis closes #7187.,1
[FLINK-11047] Fix CoGroupGroupSortTranslationTest by specyfing typesAdding the parameter types is necessary to compile the CoGroupGroupSortTranslationTestwith Scala 2.12.,3
[FLINK-6756][DataStream API] Provide Rich AsyncFunction to Scala API suiteThis closes #7168,1
[FLINK-11044] [docs] Fix registerTableSink docsThis closes #7208.,2
[hotfix][fs-connector] Refactor PartFileWriter to take stream.,2
[hotfix][fs-connector] Refactor Bucket to statically import Preconditions.,2
[hotfix][s3-connector] Renamed S3MultiPartUploader to S3AccessHelper.,0
[hotfix] Consolidated all S3 accesses under the S3AccessHelper.,5
[hotfix] Method renaming in the RecoverableMultiPartUploadImpl.,0
"[FLINK-10963][fs-connector, s3] Cleanup tmp S3 objects uploaded as backups of in-progress files.This closes #7161.",2
[FLINK-11045][table] Set correct UserCodeClassLoader for RuntimeUDFContext in CollectionExecutorThis closes #7213,1
[FLINK-10522][fs-connector] Check if RecoverableWriter supportsResume() and act accordingly.This closes #7047.,1
"[hotfix] Fixing the broken code examplesThe code examples for Scala and Java are both broken,and set a bad example in terms of efficiency.This closes #7232.",1
[hotfix][docs] Fix typo in Windows documentation,2
[FLINK-9555][scala-shell] Support table api in scala shell.This closes #7121,1
[hotfix][docs] Fix invalid link in schema_evolution doc,2
[FLINK-10997][formats] Bundle kafka-scheme-registry-client,1
[FLINK-10987] Add LICENSE & NOTICE files for flink-avro-confluent-registry,5
[FLINK-11011][E2E][JM] Log error messages about null CheckpointCoordinator only if job is running (#7216),1
[FLINK-10482] Fix double counting of checkpoint stat,0
[hotfix][documentation] Mention limitation of local recovery with RocksDB in multi device setups.,1
[FLINK-10543][table] Leverage efficient timer deletion in relational operatorsThis closes #6918,1
[FLINK-10865] Add Aliyun OSS file systems without Hadoop dependenciesThis closes #7123.,5
[FLINK-10985][tests] Enable submission of multiple jobs. (#7166)This enables submission of multiple jobs in the Jepsen tests. The jobspecifications are in an .edn file that must be passed as command linearguments. The checker verifies that all jobs are running at the end of thetest. The job cancellation function now cancels all jobs at once.Delete script/run-tests.sh and move code to docker/run-tests.sh.,3
"[FLINK-10986][tests] Enable fine-grained configuration of required dbsThis enables toggling the setup of test dependencies, such as Hadooop, Mesos,and, ZooKeeper through the --test-spec edn file. The type of the Flink clustercan also be specified via: :flink-yarn-job :flink-yarn-session:flink-mesos-session, and :flink-standalone-session.Retryable operations that exhausted all attempts, now propagate the exception bydefault. This is to fail fast if during the db/setup!, an operation, such asFlink job submission, fails to complete.",0
[FLINK-10986][tests] Implement DB to setup Apache Kafka,1
[FLINK-10986][tests] Add example on how to run a Jepsen test with KafkaThis closes #7173.,3
[hotfix] Remove redundant keyword conversion when validating CLI args,5
[hotfix] Move code from nemesis to generator,4
[hotfix] Rename keys-as-allowed-values-help-text to keys->allowed-values-help-text,1
[hotfix][docs] Add and update description of local-recovery config optionsThis closes #7211.,5
[FLINK-9552][iterations] fix not syncing on checkpoint lock before emitting recordsWe need to make sure that concurrent access to the RecordWriter is protected bya lock. It seems that everything but the StreamIterationHead was synchronizingon the checkpoint lock and hence we sync here as well.,1
[FLINK-11123][docs] fix the import of the class is missing in ml quick start document.This closes #7269,2
[FLINK-10743] [runtime] Use 0 processExitCode for ApplicationStatus.CANCELEDThis closes #7004.,1
"[hotfix] [state backend, tests] Certain StateBackendMigrationTestBase tests should fail if exception isn't thrownThis commit strengthens tests in StateBackendMigrationTestBase thatdepend on a certain state operation (restoring state, accessing state,etc.) to be failing to assert correct behaviour. However, we previouslydo not really fail the test if no exception was thrown when there shouldbe.This also caught some bugs in the test itself which had the testsverifying incorrect behaviour.",3
"[hotfix] [state backends] New namespace serializer in HeapKeyedStateBackend should always be compatiblePreviously, we were only checking if the new namespace serializer isincompatible, while properly we should be checking that it is strictlycompatible.This doesn't affect any user expected behaviour, since the namespaceserializer is never exposed to users.",1
"[hotfix] [state backends, tests] Make StateBackendMigrationTestBase more understandableThe StateBackendMigrationTestBase previously mocked user behaviour ofupgrading serializers by using a single serializer class, that can beconfigured with different target compatibility results when they arechecked for compatibility.This is a bit hard to understand, also doesn't really reflect how a userwould actually approach the feature. Instead, instead of configuring asingle serializer class with different compatibility ""personalities"",this commit uses actual different classes, V1TestTypeSerializer,V2TestTypeSerializer, and IncompatibleTestTypeSerializer, to simulatethe compatibility cases in tests.This commit also refactors the serializer migration related testserializers / types / snapshots to the testutil package, so that it canbe shared by other state migration related tests in the future.",3
"[FLINK-11094] [rocksdb] Eagerly create meta infos for restored state in RocksDBKeyedStateBackendThis ensures that all restored state, even non-accessed ones after therestore, have a meta info available on future snapshots.",5
"[FLINK-11094] [state backends] Let meta infos always lazily access restore serializerThis commit introduces StateSerializerProvider thatwraps logic on how to obtain serializers for registered state,either with the previous schema of state in checkpoints orthe current schema of state.All state meta info subclasses useStateSerializerProviders to replace direct serializer instances. Thisallows meta infos that were instantiated with restored serializersnapshots to not eagerly access the restore serializer when restoringstate. This needs to be avoided since when restoring from 1.6, therestore serializer might not be available; for RocksDB, this should betolerable.",5
"[FLINK-11094] [state backends] State backends no longer need separate map for restored StateMetaInfoSnapshotsSince now all restored state meta info snapshots are handled so that wealways eagerly create the corresponding RegisteredStateMetaInfoBase forit, the information is already part of the registered state infos map.As can be seen in the changes, those maps are no longer queried and cantherefore be safely removed.This closes #7264.",4
[hotfix] [tests] Remove unused enum from StateBackendTestBase,3
"[hotfix] Cleanup unused methods / appropriate method renames in StateMetaInfoSnapshotThis commit removes the `restoreTypeSerializer(...)` method.That method is no longer used after the series of changes inFLINK-11094. This also corresponds to the new principle that the restoreserializer is only accessed, when the state backends attempt request itfrom their state meta infos. We do not create restore serializerseagerly when creating meta infos from a StateMetaInfoSnapshot.It also removes ""config"" from names of methods and fieldsrelated to serializer snapshotting.This corresponds to the abstraction rework of retiringTypeSerializerConfigSnapshot to be replaced by TypeSerializerSnapshot.The related fields / methods should not mention ""config"" anymore.",5
"[FLINK-11087] [state] Incorrect broadcast state K/V serializer snapshot association when restoring from 1.5.xWhen restoring a broadcast state's meta information from a 1.5.xsavepoint, theLegacyStateMetaInfoReaders.OperatorBackendStateMetaInfoReaderV2V3incorrectly associates the first restored serializer as the valueserializer, and the second restored serializer as the key serializer.The actual order of this should be the other way around.This bug prevents successful broadcast state restores from 1.5, both forFlink 1.6.x and 1.7.0.The commit also modifies the StatefulJobWBroadcastStateMigrationITCaseto have different key / value types for its tested broadcast tests,which otherwise would not have caught this bug.",0
[FLINK-11087] [docs] Amend compatibility table to notify issue with restoring 1.5.x braodcast state in later versions.This closes #7256.,0
[hotfix] [docs] Fix typo in Joining documentationThis closes #7270.,2
[hotfix] [docs] Fix tEnv in tableApi docsThis closes #7254.,2
[hotfix] [docs] Correct the parameter in Operators Overview docThis closes #7219.,2
[FLINK-11029] [docs] Fixed incorrect parameter in Working with state docThis closes #7198.,2
[FLINK-10359] [docs] Scala example in DataSet docs is brokenThis closes #7266.,2
[hotfix][test][streaming] Fix invalid testNotSideOutputXXX in WindowOperatorTest,3
[FLINK-11041][test] ReinterpretDataStreamAsKeyedStreamITCase source should hold checkpointing lock,5
[FLINK-11090][streaming api] Remove unused parameter in WindowedStream.aggregate(),2
[FLINK-10252][metrics] Pass akkaFrameSize to MetricQueryService,4
[FLINK-10252][metrics] Handle oversized metric messages,0
[hotfix][metrics][tests] Ensure ActorSystem is terminated,5
[hotfix][metrics][tests] Refactor MetricQueryServiceTest- use UnregisteredMetricGroups instead- simplify metrics- encapsulate TestActor fields,3
[hotfix][docs][table] Fix string concatenation in avro example,0
[hotfix][build] Add Aliyun FS dependency to flink-dist,2
[FLINK-11080][ES] Rework shade-plugin filters,1
[hotfix] [docs] Fix typo in dynamic tables documentationThis closes #7275.,2
[FLINK-11125] clean up useless importsThis closes #7272,2
[FLINK-11085][build] Fix inheritance of shading filters,0
[hotfix] [docs] Fix typos in Table and SQL docsThis closes #7297.,2
[hotfix] [docs] Improve DataSet.partitionCustom() documentation.This closes #7282.,2
[FLINK-11136] [table] Fix the merge logic of DISTINCT aggregates.This closes #7284.,2
[FLINK-11001] [table] Fix alias on window rowtime attribute in Java Table API.This closes 7289.,0
[hotfix] [docs] Add notice about buggy DATE_FORMAT function,1
[hotfix] [docs] Add notice about buggy dateFormat() function,1
[FLINK-11122][core] Change signature of WrappingProxyUtil#stripProxy(T)Changed signature so that the method expects a WrappingProxy<T>. This fixes atype inference ambiguity by the compiler.Make the method throw a runtime exception of it needs to strip more than 128proxies.Change AbstractCloseableRegistryTest so that no mocks are used.This closes #7273.,1
[hotfix][core] Fix typo in WrappingProxyUtil Javadoc,2
"[FLINK-11144][tests] Make tests runnable on Java 9This enables to run tests on Java 9. However, not all tests are passing atthe moment.This closes #7293.",4
[FLINK-11152][core] Use asm 6 in ClosureCleaner,4
[FLINK-11145] Fix Hadoop version handling in binary release script,0
[FLINK-11040][docs] fixed the Incorrect generic type of output in broadcast_state.md,0
[FLINK-10566] Fix exponential planning time of large programsThe traversal of the DAG is not efficient enough at some places which can leadto very long plan creation times.This introduces caching for the traversal to avoid traversing nodes multipletimes. Caching is performed at two places:- when registering Kryo types- when determining the maximum parallelism,5
[hotfix] [docs] Improve the correctness in Detecting Patterns docThis closes #7307.,2
[hotfix] [docs] Correct the field name in Connect to External Systems docThis closes #7311.,2
[FLINK-11074] [table][tests] Enable harness tests with RocksdbStateBackend and add harness tests for CollectAggFunctionThis closes #7253,1
[FLINK-7599][table] Refactored AggregateUtil#transformToAggregateFunctions,1
[hotfix][table] Move generate runner functions to MatchCodeGenerator companion object,1
"[FLINK-7599][table, cep] Support for aggregates in MATCH_RECOGNIZE",1
[FLINK-7599][docs] Updated MATCH_RECOGNIZE documentation with aggregations,2
[FLINK-7599][table] Throw exception on DISTINCT in aggregations in MATCH_RECOGNIZE,2
[hotfix][docs] Unified indentation,2
[FLINK-11083] [Table&SQL] CRowSerializerConfigSnapshot is not instantiableThis closes #7267.,5
[FLINK-10457][fs-connector] Add SequenceFile support to StreamingFileSink.,2
[FLINK-10457][fs-connector] Add SequenceFile support to StreamingFileSink.This closes #6774.,2
[FLINK-11100][s3][tests] Add FS type argument to s3_setup,1
[FLINK-11101][S3] Ban openjdk.jol dependencies,2
[FLINK-11151][rest] Create parent directories in FileUploadHandler,2
[FLINK-11168][tests] Relax time-constraints for LargePlanTestThe test completes in 500ms on my machine. On Travis the resources are muchmore limited and it fails occasionally.The following should ensure the test does not fail anymore:- Increase test timeout to 30 seconds- Reduce complexity of tests by decreasing branching factor,3
[FLINK-11026][ES6] Rework creation of fat sql-client jar,1
[FLINK-10784][tests] Update FlinkKafkaConsumerBaseMigrationTest for 1.7,3
[FLINK-10788][tests] Update ContinuousFileProcessingMigrationTest for 1.7,3
[FLINK-10782][tests] Update AbstractKeyedOperatorRestoreTestBase for 1.7,3
[FLINK-10787][tests] Update AbstractNonKeyedOperatorRestoreTestBase for 1.7,3
[FLINK-10786][tests][cep] Update CEPMigrationTest for 1.7,3
[hotfix][docs] Fix typos in documentation,2
[hotfix][docs][table] Fix various examples,0
[hotfix] Fix typo in AbstractStreamOperator,1
[FLINK-11180][tests] Use random port in ProcessFailureCancelingITCase,0
[hotfix][javadocs] Fix typo,2
[FLINK-9083][cassandra] Restructure CassandraSinkBase,2
"[FLINK-9083][cassandra] Refactor CassandraSinkBaseTest- ensure sinks are closed in failing tests (by introducing try-with-resource blocks)- introduce CountDownLatch in tests that wait for pending updates, o ensure that close/snapshot was actually executed- add utility methods for creating sinks",1
[FLINK-9083][cassandra] Add async backpressure support,1
[FLINK-10461][runtime] Refactor direct executor serviceCo-authored-by: Andrey Zagrebin <azagrebin@gmail.com>Co-authored-by: klion26 <qcx978132955@gmail.com>,4
[FLINK-10461][rocksdb] Support multiple threads for downloading restored state,1
[hotfix][docs][scala] Update comment about supported scala version,1
[FLINK-10748] Decouple RestServerEndpoint from Dispatcher (#7295)This commits decouples the RestServerEndpoint from the Dispatcher by converting theRedirectHandler into LeaderRetrievalHandler which only retrieves the gateway of thecurrent leader instead of redirecting the client. This is possible since the servingRestServerEndpoint no longer needs to be colocated with the Dispatcher and JobMasterafter all RPC requests are serializable (e.g. no direct access on the ExecutionGraphis needed).With this change every RestServerEndpoint will automatically proxy to the current leaderwithout needing to redirect the requesting client.,4
[FLINK-11201] Update release notes to contain changes for SBT projectsSBT projects which use the MiniClusterResource now have to explicitly add a test-jardependency on flink-runtime. The reason for this is that we moved the MiniClusterResourceto flink-runtime and sbt does not properly pull in transitive test-jar dependencies.,3
[FLINK-11048] Ability to programmatically execute streaming pipeline with savepoint restoreThis closes #7249.,2
[FLINK-4582] [kinesis] Consumer for DynamoDB streams via Kinesis API (#6968)Introduces a new Flink source to consume from DynamoDB streams. This new source is built on top of the existing Kinesis connector. It interacts with the DynamoDB streams via a dynamodb-streams-kinesis-adapter client.,5
[FLINK-11179][tests] fix testCancelSortMatchWhileDoingHeavySorting bugThis closes #7315,0
[hotfix] [docs] Fix broken links in State Schema Evolution docs,2
[hotfix] [docs] Correct word spelling errorsThis closes #7353,0
[hotfix] [docs]  Fix wrong window time unit for window join documentation.This closes #7349,2
[hotfix][docs][metrics] Update currentLowWatermark references,5
[hotfix][docs] Fix typos,2
[FLINK-11142][docs] Point out fields can be projected out for Position-based MappingThis closes #7352,2
[FLINK-7208][table] Optimize Min/MaxWithRetractAggFunction with DataViewThis closes #7201,5
[hotfix][cep] Fixed timestamp for timed out partial matches,0
[hotfix][cep] Fixed argument list code style,0
[hotfix][cep] Added test event builder,3
[hotfix][cep] Added test harness output asserter,3
[FLINK-10596][cep] Introduced PatternProcessFunction,1
[hotfix][cep] Fixed passing runtime context,1
[FLINK-10596][cep][docs] Updated cep docs with PatternProcessFunction,1
[hotfix][cep] Made PatternStream immutable & changed PatternStreamBuilder to a proper builder,4
[hotfix] [docs] fix typos,2
"[hotfix][docs] Fix incorrectly spelled ""the"" as ""teh""",0
[FLINK-11233][core] Fix typo in JobID Javadoc,2
[hotfix][runtime] Fix typo in FlinkUserCodeClassLoaders Javadoc,2
[hotfix][docs] Add back-to-top button to connector page,1
[FLINK-11246][table] Fix distinct AGG visibility issueThis closes #7394,0
[FLINK-11217][docs] Add missing back-to-top buttons,1
[FLINK-10779][tests] Update Java / Scala StatefulJobSavepointMigrationITCase for 1.7,5
Merge pull request #7242 from hequn8128/flink-10781[FLINK-10781][fs] Update BucketingSinkMigrationTest for Flink 1.7,2
[FLINK-10780][tests] Update Java / Scala StatefulJobWBroadcastStateMigrationITCase for 1.7,5
[FLINK-11235][es] Close transportclient if no connection could be established,2
[FLINK-11181][tests] Fix SimpleRecoveryFailureRateStrategyITBase test errorThis colses #7316,0
[FLINK-11163][tests] Use random port in RestClusterClientTest,3
[hotfix][tests] Remove mocks from RestClusterClientTest,3
[FLINK-11023] Add LICENSE & NOTICE files for flink-connector-cassandra,2
[FLINK-11023] Add LICENSE & NOTICE files for flink-connector-elasticsearch,2
[hotfix][ES2] Set findbugs to provided,1
[FLINK-11023] Add LICENSE & NOTICE files for flink-connector-elasticsearch2+es2,2
[FLINK-11023] Add LICENSE & NOTICE files for flink-connector-elasticsearch5+es5,2
[FLINK-11023] Add LICENSE & NOTICE files for flink-connector-kinesis,2
[FLINK-10761][metrics] Do not acquire lock for getAllVariables(),1
[FLINK-11079][storm] Skip deployment of storm-examples,2
[FLINK-11194][hbase] Use type instead of classifier,1
[FLINK-11023][ES] Add NOTICE file,2
[hotfix][docs][kafka] Fix typo,2
[FLINK-11234] [table] Fix ExternalTableCatalogBuilder unable to build a batch-only table- fix the logic in supportsBatch to properly declare a batch-only table- adjust CommonTestData to provide batch-only or streaming-only tablesThis closes #7386.,1
[hotfix][ES6][SQL] Remove unused version property,5
[FLINK-11026][kafka][SQL] Rework kafka sql-client jar creation,1
[hotfix] [table] Fix typos in Table javadoc.This closes #7388.,2
[hotfix][docs] Fix incorrect example in cep doc,2
[FLINK-11119][docs] Correct Scala example for Table Function in User-defined Functions docs.This closes #7379.,2
[FLINK-11227] [table] Fix bound checking errors in DescriptorPropertiesThis closes #7373.,0
[FLINK-11173][table] Fix the exception message of proctime attribute validation in TableSourceUtil#validateTableSourceThis closes #7374.,5
[FLINK-11001] [table] Update exception message for time attributes on aliases,5
[FLINK-11124][table] Add private[flink] to TemporalTableFunction.create()This closes #7271.,1
[hotfix] [docs] Update docs regarding missing 'sql-jar' suffix,0
[FLINK-10848][YARN] properly remove YARN ContainerRequest upon container allocation successThis closes #7078,4
[FLINK-10845] [table] Support multiple different DISTINCT aggregates for batchThis closes #7079.,1
[hotfix] Improve performance of GenericArraySerializer.copy(),1
[hotfix] Remove unused generic parameter from RocksDB states,5
[FLINK-9702] Improvement in (de)serialization of keys and values for RocksDB stateThis closes #7288.Co-authored-by: Stefan Richter <s.richter@data-artisans.com>Co-authored-by: klion26 <qcx978132955@gmail.com>,5
[FLINK-11265][docs] AvroSinkWriter  AvroKeyValueSinkWriter,2
[hotfix][runtime] Remove redundant suppression,4
[FLINK-11073] [core] Add COMPATIBLE_WITH_RECONFIGURED_SERIALIZER to TypeSerializerSchemaCompatibility,5
"[FLINK-11073] [state backends] Respect serializer reconfiguration in state backendsThis commit adapts the StateSerializerProvider to respect theCOMPATIBLE_WITH_RECONFIGURED_SERIALIZER case, which effectively lets allstate backends respect serializer reconfiguration because stateserializers are always obtained via StateSerializerProviders.It also makes StateSerializerProvider work for both eagerly / lazilyregistered serializers.This is required so that the StateSerializerProvider can be used for thekey serializer in AbstractKeyedStateBackend. For the key serializer,regardless of whether or not we're restoring old state, we always firstget the new key serializer, and then maybe get the previous keyserializer's snapshot in the restore phase.Therefore, after this commit, access the key serializer inAbstractKeyedStateBackend is also governed by a StateSerializerProvider.For a more fine-grained explaination of all the changes that build up tothis, please refer to #7329.This closes #7329.",4
"[hotfix] Rename keySerializerConfigSnapshot to keySerializerSnapshot in KeyedBackendSerializationProxyRemove ""config"" from the field names and getter name to reflect the newabstraction TypeSerializerSnapshot.",1
[hotfix] [doc] Fix an error in state_backendsThis closes #7401.,0
[hotfix] [doc] Fix incorrect http port in Elasticsearch 6.x Scala docThis closes #7361.,2
[FLINK-11165] Refine the task deploying log for easier finding of task locations,2
[FLINK-11189] Deprecated documentation for readSequenceFile function,1
[FLINK-11273][state] Fix shared InputView object between event processing and queryable state threadThis was introduced with FLINK-9702.,2
[FLINK-11161][scala-shell] Fix unable to import java packages in scala-shell.This closes #7370,2
[FLINK-11279] [table] Fix week interval parsing in ExpressionParserThis closes #7426.,0
[FLINK-11191] [table] Check for ambiguous columns in MATCH_RECOGNIZEAdded a validation that checks if no ambiguous columns are definedin MATCH_RECOGNIZE clause. Without the check there is a crypticmessage thrown from code generation stack.This closes #7328.,1
"Revert ""[FLINK-10848][YARN] properly remove YARN ContainerRequest upon container allocation success""This reverts commit e26d90fc86b266978b4bac84fe02ca34b62983fe.",4
"[FLINK-11280] [rocksdb] Lazily create RocksDBSerializedCompositeKeyBuilder only after restorePrior to this commit, the composite key builder was created in theconstructor of the RocksDBKeyedStateBackend. The creation of the builderrequires providing a key serializer.This is problematic, because the key serializer may be reconfiguredduring the restore phase, therefore invalidating the key serializer usedby the composite key builder.This commit resolves this by lazily creating the composite key builderonly after the restore phase, which would be the point-in-time when weare certain the key serializer will no longer be changed and is final.",4
[hotfix] [rocksdb] Only log snapshot restore message when state is actually restored,2
[hotfix] [rocksdb] Remove unused method in RocksDBSerializedCompositeKeyBuilder,5
"[FLINK-11280] [state backends, tests] Do not set current key before restore in TtlStateTestBase tests",3
"[FLINK-11073] [core] Introduce CompositeTypeSerializerSnapshotThe CompositeTypeSerializerSnapshot encapsulates logic for handlingwriting, reading, and deriving final compatibility results for compositeserializers that have multiple nested serializers as well as somestatic outer configuration (e.g. type class in theGenericArraySerializer).his base class has its own versioning for the format in which it writesthe outer snapshot and the nested serializer snapshots. The version ofthe serialization format of this based class is definedby getCurrentVersion(). This is independent of the version in whichsubclasses writes their outer snapshot, defined bygetCurrentOuterSnapshotVersion().This means that the outer snapshot's version can be maintained onlytaking into account changes in how the outer snapshot is written.Any changes in the base format does not require upticks in the outersnapshot's version",1
[FLINK-11079] [core] Let ListSerializerSnapshot extend CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Let MapViewSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Let ArrayListSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Let LockableTypeSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Let ListViewSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Let MapSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Let ScalaEitherSerializerSnapshot be a CompositeTypeSerializerSnapshot,2
[FLINK-11073] [core] Replace GenericArraySerializerConfigSnapshot with new GenericArraySerializerSnapshot,1
[FLINK-11073] [core] Replace EitherSerializerSnapshot with new JavaEitherSerializerSnapshot,1
"[hotfix] [core] Assert current serializer snapshot is expected snapshot class in TypeSerializerSnapshotMigrationTestBaseThis strengthens the test base to make use of the provided snapshotclass in the test specifications, to assert that serializers are reallyusing the expected classes for their current serializer snapshots.",1
"[FLINK-11073] [core] Rename CompositeSerializerSnapshot to NestedSerializersSnapshotDelegateAfter introducing CompositeTypeSerializerSnapshot, theCompositeSerializerSnapshot has been reworked to only deal with concernsof delegating reading and writing of the nested serializers' snapshots.It no longer deals with resolving the final compatibility result for theouter composite serializer.Therefore, it is renamed properly as NestedSerializersSnapshotDelegate,and also annotated as an internal class, since we want users to use themore powerful CompositeTypeSerializerSnapshot instead.This closes #7422.",1
"[FLINK-10555] [test] Port AkkaSslITCase to new code base[FLINK-10555] tests are all of BlobServer initialization, also remove already covered testsThis closes #6849.",3
[FLINK-10555] Clean-up BlobServerSSLTest,3
[FLINK-10700] [cluster managerment] Remove LegacyStandaloneClusterDescriptor (#6946),4
[FLINK-11232][rest] Fix subtask start-time field name,0
[FLINK-11251][metrics] Exclude variable values from logical scope of generic groups,2
[hotfix][cep] Change contract of cep TimerContext#timestamp to neverreturn null,4
[hotfix][cep] Introduced nfa test harness,3
[FLINK-10596][cep] Added access to timer service in IterativeCondition,1
[hotfix][cep] Renamed TimerContext to TimeContext,0
"[FLINK-10596][cep, docs] Added description of TimeContext to docs",2
[FLINK-11056] [mesos] Remove MesosApplicationMasterRunner,1
[hotfix][docs] Sync formatting for cli usage examples,2
[hotfix][test] Remove usage of deprecated method,4
[hotfix][test] Reduce test timeout to a reasonable value,3
[hotfix][test] Adjust suppressWarnings,2
[hotfix][docs] Update addShutdownHookThread javadocs,2
[hotfix][docs] Fix javadocs of RandomFibonacciSource,2
[FLINK-11140][fs-connector] Fix empty child path check in Buckets.This closes #7287.,0
[FLINK-11197][tests] Improve migration test comments about how to generate snapshots,3
[FLINK-11262][py] Bump jython-standalone to 2.7.1Bump the jython dependency because of a security issue.,0
[FLINK-10783][tests] Update WindowOperatorMigrationTest for 1.7,3
[FLINK-11207][build] Bump commons-compress to 1.18This addresses CVE-2018-11771.,1
[FLINK-10326] Simplify ZooKeeperSubmittedJobGraphStore#constructorMove initialization logic out of the ZooKeeperSubmittedJobGraphStore constructor.,2
[FLINK-10436] Add ConfigOption#withFallbackKeys (#6872)* [FLINK-10436] Add ConfigOption#withFallbackKeys* [hotfix] correct javadoc* [FLINK-10436] Code quality improvement,1
[FLINK-11287] [rocksdb] RocksDBListState should be using registered serializer in state meta infosThis closes #7434.,5
"[FLINK-11073] [state backends, tests] Activate ignored testKeyedListStateSerializerReconfiguration test in StateBackendMigrationTestBaseThis test was previously ignored due to 2 missing changes:- ListSerializerSnapshot was not respecting serializer reconfiguration  (fixed by FLINK-11073), and- RocksDBListState did not use the correct registered state serializer  in backend's state meta info (fixed by FLINK-11287)With those fixes in, the test can now be activated and expected to pass.",4
[hotfix][docs] Add missing config option descriptions,5
[FLINK-10571][storm] Remove topology support,1
[FLINK-11267][release] Only create hadoop-free binary by default,1
[FLINK-10583][table] Add base TwoInputStreamOperator with TTL operator.,1
[hotfix] Avoid redundant state access in TemporalProcessTimeJoin.,0
[FLINK-10584][table] Add State Retention support to TemporalRowtimeJoin.,1
[FLINK-10583][table] Add State Retention support to TemporalProcessTimeJoin.,1
[FLINK-11278] [docs] Add documentation for TableAPI&SQL in scala-shell.This closes #7437,2
"[hotfix][docs] Reverse paragraphs in cli.md to cli enumeration (#7443)The markdown treats the TOC as the last item in CLI use list, thus this list could not be shown properly. This PR revert the two paragraph to fix this issue.",0
[FLINK-10866] Only load queryable state when explicitly configuredChange-Id: Id79c8bf97002a387a80be563a43dce3210143dc2,5
[FLINK-11272][flink-yarn] Support for parsing multiple --yarnship parameters,2
[FLINK-11134][rest] Do not log stacktrace for handled exceptions,0
[hotfix][rest] Centralize REST error logging,2
[hotfix][rest] Remove unnecessary instanceof check,4
[FLINK-11268][release] Deploy multiple flink-shaded-hadoop2 artifacts,2
[FLINK-11253] Add shutdown hook for yarn session client,1
[FLINK-11253] Factor out application report loggingMove final application report logging out of the shutdownCluster method. This allowsto not log the final application report if the cluster is shut down via a shutdown hook.This closes #7414.,1
[FLINK-10509][storm] Remove flink-stormThis closes #7453.,2
Fix queryable-state nightly test,3
[FLINK-11084][datastream] Forbid using two consecutive split transformationsThis closes #7258,1
[FLINK-11224][scala-shell] Log is missing in scala-shellLogging configuration was set only for scala-shell in yarn mode. This commit sets the configuration for local and remote mode in start-scala-shell.sh script as well.,5
"[hotfix][docs] Fix NullPointerExceptionOffset is Long type, the default value is null, and executing offset+=1 in Java 1.8.x will throw a NullPointerException",1
"[FLINK-11306][jdcs] Bump derby from 10.10.1.1 to 10.14.2.0Derby has two CVE's:https://ossindex.sonatype.org/vuln/b01781a6-31db-4dbc-b091-d683aaeb98e6https://ossindex.sonatype.org/vuln/bbe6594a-c255-41a7-a397-d762d1aa8b00Although it is only a test dependency, updating would be nice.",5
"[FLINK-10848] Remove container requests after successful container allocationThis commit removes container requests after containers have been allocated. This prevents thatwe will request more and more containers from Yarn in case of a recovery.Since we cannot rely on the reported container Resource, we remove the container request byusing the requested Resource. This is due Yarn's DefaultResourceCalculator which neglects thenumber of vCores when allocating containers.This closes #7430.",1
[hotfix] [docs] Fix kafka doc mistake classname,2
[FLINK-11312][docs] Fix broken link to Zookeeper getting started,1
"[hotfix] Add dependency snippet for RocksDBStateBackend to state_backends.mdIn order to use the RocksDBStateBackend, the user has to add the flink-statebackend-rocksdbdependency to his project. This commit adds this information to the state_backends.md.This closes #7480.",5
[hotfix] Fix typo in restart strategies documenation (#7479),2
[hotfix][docs] Fix typo in classloading doc,2
[FLINK-11304][docs][table] Fix typo in time attributes docThis closes #7477.,2
[hotfix][docs][table] Fix more typos in time attributes doc,2
[hotfix] [docs] Fix typo in Table SQL docThis closes #7491.,2
[hotfix] [datastream] Remove irrelevant comments and fix typo in SourceStreamTaskThis closes #7485.,2
[hotfix] [fs] Add clock as an argument in JavadocsThe clock parameter is missing in the docstring.This closes #7484.,2
"[FLINK-11156][tests, runtime] Reconcile ZooKeeperCompletedCheckpointStoreMockitoTest with JDK 9",3
"[FLINK-11156][tests, runtime] Simplify ZooKeeperCompletedCheckpointStore constructor",1
Add link to KeyedProcessFunction to side output documentation,2
[FLINK-11331][table][docs] Fix errors in tableApi.md and functions.mdThis closes #7494,1
[hotfix][docs] fix some typos,2
[FLINK-9222][docs] add documentation for setting up Gradle projects,1
[hotfix][quickstart] make the note about IDE memory requirements non-specific to MacOS X users,1
[FLINK-11023][kafka] Add NOTICE files,2
"[FLINK-11187] [s3] Use file over stream for writesThis changes the S3AccessHelper API to take a file instead of an inputstream.This allows s3 client to properly reset a file instead of a file overstream for writes.This fixes an issue where the underlying s3 implementation has anintermittent failure, tries to reset the stream, fails to do so, andresults in hung requests with delayed errors.",0
[hotfix][build] Append shade-plugin transformers in child modules,0
[FLINK-11289][examples] Rework examples to account for licensing,1
[FLINK-11174][prometheus] Add option to not filter label values,1
[hotfix][docs] Update references to deprecated SinkFunction#invoke(Object),1
[hotfix] Fix parameter name KeyedCoProcessOperator constructor,1
[FLINK-11012][tests] Introduce abstract superclass for filesystem IT cases.This closes #7384.,5
"[FLINK-10945] Add an InputDependencyConstraint to avoid resource deadlocks for finite stream jobs when resources are limitedThis commit adds a job config InputDependencyConstraint, which helps to avoidresource deadlocks in LAZY_FROM_SOURCES scheduling when resources are limited.The InputDependencyConstraint controls across multiple inputs when consumers arescheduled. Currently it supports ANY and ALL. ANY means that any input intermediateresult partition must be consumable and ALL means that all input intermediate resultpartitions (from all inputs) need to be consumable in order to schedule the consumer task.This closes #7255.",1
[FLINK-10945] Mark InputDependencyConstraint as PublicEvolving,2
[FLINK-11295][conf] Rename configuration options of queryable-state from query.x to queryable-state.xChange-Id: Idb561da3982de07e77a05ffef9ad227094f527b0,5
[FLINK-11302][fs-connector] Correctly parse tmp dirs in FlinkS3FileSystem.This closes #7458.,5
[hotfix][docs] Remove stray character,4
[hotfix] Introduce MetricFetcher interfaceRename MetricFetcher into MetricFetcherImpl and introduce MetricFetcher interface.This allows for better testing and hides the type parameter of MetricFetcherImpl.,2
[FLINK-10822] Make MetricFetcher update interval configurableIntroduce WebOptions.METRIC_FETCHER_UPDATE_INTERVAL configuration option to configurethe update interval of the MetricFetcher.This closes #7459.,5
[hotfix] Remove Mockito from MetricFetcherTest,3
[hotfix][docs] Fix quick start project structure error in DataStream API TutorialThis closes #7502,5
[hotfix][docs] Fix typos,2
[FLINK-11359][test] LegacyAvroExternalJarProgramITCase,3
[hotfix][tests] Reduce metric fetcher interval for e2e tests,3
"[hotfix] [tests] Remove unfruitful MigrationTestUtil classThat utility class had a single helper method, restoreFromSnapshot,which accepts the target snapshot's Flink version. This was usefulbefore, because the way to restore snapshots was a bit different forFlink <= 1.1 and newer versions.Since we now no longer support compatibility for 1.1 versions andbelow, this helper method is simply forwarding the restore operationto the test harness.This commit refactors this have equivalent behaviour directly in theAbstractStreamOperatorTestHarness class.",3
[FLINK-10778] [tests] Move MigrationVersion to flink-core test utils,3
"[FLINK-10778] [tests] Make TypeSerializerSnapshotMigrationTestBase aware of snapshot versionBefore, the tests in TypeSerializerSnapshotMigrationTestBase alwaysassumed that the test serializer snapshotw were written with Flink 1.6.This commit makes this flexible, so that we can allow subclasses tospecify different snapshot versions for each TestSpecification.",3
"[FLINK-10778] [tests] Make new serializer compatibility tests more flexible in TypeSerializerSnapshotMigrationTestBaseBefore, the TypeSerializerSnapshotMigrationTestBase test base alwaysonly asserted that a new serializer is compatible as is with theprevious serializer's snapshot.This makes the test code not resusable for cases where the newserializer provided isn't compatible as is, but other compatibilitytypes, for example Kryo serializers that requires reconfiguration onrestore. This allows the test base to express those cases.",3
"[FLINK-10778] [tests] Remove serializerSnapshotRestoresCurrentSerializer test in TypeSerializerSnapshotMigrationTestBaseThe serializerSnapshotRestoresCurrentSerializer test asserts that therestored serializer instance from the snapshot is of the same type asthe current serializer. This isn't necessary true, as is not a contractof the TypeSerializerSnapshot abstraction.Therefore, this test is removed.",4
[FLINK-10778] [tests] Extend all TypeSerializerSnapshotMigrationTestBase subclasses to test restoring from 1.7This closes #7504.,3
[FLINK-11371] The AvroParquetReader is not being closed,2
[FLINK-11294][tests] Remove legacy JobInfo usage in valid tests,3
"[FLINK-11294][tests, runtime] Add new constructor to SubmittedJobGraphThe new constructor only expects a JobGraph. Deprecate the old constructor.",1
[hotfix][tests] Remove redundant null check,4
[hotfix][runtime] Fix checkstyle violation in SubmittedJobGraph,0
[FLINK-11341][doc] Correct javadoc of AkkaUtils#getAkkaConfig,5
[FLINK-10817] Upgrade presto dependency to support path-style access,1
"[FLINK-10558][Yarn tests] Port YARNHighAvailabilityITCase to new code baseThis commit ports the YARNHighAvailabilityITCase to the new code base. It now usesthe YarnClusterDescriptor and the RestClusterClient to directly interact with thedeployed Flink cluster.Since the test uses the pkill command to kill the application master, the test onlyruns on Linux, MacOS, FreeBSD and Solaris. On Windows this test won't be executed.This closes #7509.",3
[FLINK-11350][tests] Delete JobClientActorRecoveryITCaseThe JobClientActorRecoveryITCase is no longer needed since it only tests the legacycode path.,3
[FLINK-11349][tests] Port CoordinatorShutdownTest to new code baseThe relevant tests of the CoordinatorShutdownTest have been moved to theExecutionGraphCheckpointCoordinatorTest which executes the same test justwithout spawning an actual cluster.,3
[hotfix] Remove mocking from ExecutionGraphCheckpointCoordinatorTest,3
[FLINK-11360] [test] Check and remove LocalFlinkMiniClusterITCaseThis closes #7516.,5
[hotfix] [tests] Fix incorrect EitherSerializerSnapshot migration test files,2
[FLINK-11372] [core] Incorrect delegation of compatibility checks to new CompositeTypeSerializerSnapshotsThis closes #7521.,1
[FLINK-11383][blob] Clean up blobs of failed submissionsLet the dispatcher clean up blobs of failed submissions.,0
"[FLINK-11036] Fix test_streaming_classloader.sh end-to-end testBefore, this was relying on .version.properties being available in theflink-dist jar. This was not the case when building from a Flink sourcerelease.This is fixed by introducing a fake lib package that we place in thelib/ folder to test the classloader resolution order. Both the libpackage and the user package contain a parent-child-test.properties andwe check the resolution order in the test.Also change the test to not use TaskManager anymore.This test was relying on TaskManager being present in Flink, this mightnot be the case in the future. We change this test to place a fake classin the ""lib"" package and the ""user"" package to make it independent ofthe rest of Flink.",2
[hotfix][table] Converted static generateIterativeCondition & generateOneRowPerMatchExpression methods into inner methods,0
[hotfix][table] Switched from PatternSelectFunction to PatternProcessFunction,1
[FLINK-10591][table] Introduced functions to return time attributes from  MATCH_RECOGNIZE,1
[FLINK-10591][docs] Added description of MATCH_ROWTIME and MATCH_PROCTIME functions,1
[hotfix][docs] Formatted match_recognize.md to keep line length under 100 characters.,2
[FLINK-8739] [table] Optimize DISTINCE aggregates to use the same distinct accumulator if possibleThis closes #7286,1
[hotfix][tests] Fix checkstyle violation and extract NoDataSource,5
[FLINK-10665][tests] Remove legacy test YARNSessionFIFOITCase#testJavaAPIThis closes #6917.,3
[hotfix][docs] Remove reference to non-existent DataStream#mapPartitionWith,5
[FLINK-11256][Streaming] Improve StreamEdge to reduce the sizes of JobGraphThis closes #7403,1
[hotfix][docs] Fix broken links,2
[FLINK-11328] [core] Upgrade parameterless / singleton serializers to use new serialization compatibility APIs,1
[FLINK-11328] [cep] Snapshots of NFA-related serializers should be a CompositeTypeSerializerSnapshot,2
"[hotfix] [tests] Remove redundant outdated migration tests in StateBackendTestBaseThose tests were implemented before we had the state schema evolutionfeature in Flink 1.7, and were implemented using the old legacyserialization compatibility APIs. Moreoever, the behaviours that theytest are already more comprehensively covered inStateBackendMigrationTestBase.",3
[FLINK-11328] [e2e] Do not use deprecated ParameterlessTypeSerializerConfig in e2e tests,3
[FLINK-11328] [tests] Add serializer migration tests for all parameterless serializersThis closes #7553.,2
[FLINK-11351][tests] Port JobManagerCleanupITCase to new code baseThis commit renames JobManagerCleanupITCase into BlobsCleanupITCase and usesthe MiniCluster instead of the TestingCluster to execute the tests.This closes #7524.,3
[FLINK-11355][tests] Remove JobManagerProcessReapingTestThe JobManagerProcessReapingTest is no longer relevant since we don't start aProcessReaper as it used to be the case in the legacy mode.,1
[FLINK-11348][tests] Port testClientStartup to new codebasePort YARNSessionCapacitySchedulerITCase#testClientStartup to new flip6 codebase.Rename test to testStartYarnSessionClusterInQaTeamQueue.Remove -n command line parameter & argument.,2
fix typo in JobManagerRunnerThis closes #7569,1
[FLINK-11048] Mark new RemoteStreamEnvironment constructor PublicEvolving,3
[hotfix][tests] Fix checkstyle violations in AkkaRpcServiceTest,3
[FLINK-11356][tests] Port JobManagerStartupTest to new code base- Moved JobManagerStartupTest#testStartupWithPortInUse toBootstrapToolsTest#testActorSystemInstantiationFailureWhenPortOccupied- Moved JobManagerStartupTest#testJobManagerStartupFails toBlobServerTest#testFailureIfStorageDirectoryCannotBeCreatedThis closes #7541.,3
[FLINK-11353][tests] Port JobManagerHAJobGraphRecoveryITCase to new code baseRemoved testClientNonDetachedListeningBehaviour because the test was only relevant forthe JobClientActor. Moved testJobPersistencyWhenJobManagerShutdown toDispatcherHATest#testPersistedJobGraphWhenDispatcherIsShutDown.This closes #7526.,3
[FLINK-10251][rpc] Handle oversized response messages in AkkaRpcActor,0
[FLINK-10251][rpc] Refactor handling of over sized messagesThis commit slightly refactors and cleans up the handling of over sized messages.This closes #6876.,4
[hotfix] Fix checkstyle violations in AkkaRpcActorTest,3
[hotfix] Remove unused JobMasterGateway#requestClassloadingProps,1
[hotfix] Pass BlobWriter into JobMaster instead of BlobServer,4
[hotfix] Move BlobWriter into JobMangerSharedServices,4
[hotfix][tests] Remove BlobServer from JobManagerRunnerTest,3
[hotfix][tests] Add TestingHighAvailabilityServicesBuilderThe builder creates a TestingHighAvailabilityServices with the standaloneimplementation of the individual services.,3
[FLINK-11354][tests] Port JobManagerHARecoveryTest to new code base- Moved JobManagerHARecoveryTest#testJobRecoveryWhenLosingLeadership toDispatcherHATest#testJobRecoveryWhenChangingLeadership- Moved JobManagerHARecoveryTest#testFailingJobRecovery toDispatcherHATest#testFailingRecoveryIsAFatalErrorThis closes #7539.,3
[FLINK-11008][state] Parallelize file upload for RocksDB incremental snapshots.Summary:This patch add the ability about uploading state files using multithread when snapshoting.Differential Revision: https://aone.alibaba-inc.com/code/D818724This closes #7351.,1
[FLINK-11390][tests] Port testTaskManagerFailure to new codebase.Port YARNSessionCapacitySchedulerITCase#testTaskManagerFailure to flip6 codebase:* Remove assertions that rely on log messages only* Move part where TMs are killed to YARNHighAvailabilityITCase* Rename test to a proper name that describes what it does* Add Javadoc explaning what this test does[FLINK-11390][tests] Move comment to right position[FLINK-11390][tests] Reuse YarnClient from super classMove waitUntilCondition to YarnTestBase[FLINK-11390][tests] Extract method parse hostnameExtract method getOnlyApplicationReportExtract method submitJobExtract method getNumberOfSlotsPerTaskManagerExtract method getFlinkConfigFromRestApiDelete useless commentRename: runner -> yarnSessionClusterRunnerDelete useless sleep & refactorReorder methods and add static keyword where possibleThis closes #7546.,1
"[FLINK-11171] Avoid concurrent usage of StateSnapshotTransformerTest non concurrent access of StateSnapshotTransformerRefactor out testNonConcurrentSnapshotTransformerAccess to separte StateSnapshotTransformerTestuse element serializer from new meta info, duplicate it in rocksdb transformer factory, test concurrent access for element serializerThis closes #7320.",3
[FLINK-11316][tests] Drop JarFileCreator,2
[FLINK-11316][tests] Refactor ClassLoaderUtilsTests#createValidJar(File)This closes #7486.,3
[hotfix][tests] Fix checkstyle violations in ClassLoaderUtilsTest,3
[FLINK-11329][core] Migrate CRowSerializerConfigSnapshot to new TypeSerializerSnapshot interface,1
Enhance error message in BucketingSinkFaultToleranceITCaseWe add this with the hope of finding clues about FLINK-9920.,2
[FLINK-11366][tests] Delete obsolete TaskManagerMetricsTestThis closes #7544.,3
[hotfix][docs] Remove redundant word in BarrierBuffer comment,4
fix typo in JobMaster (#7572),2
"[FLINK-11414] Introduce JobMasterService interfaceFor a better separation of concerns in the JobManagerRunner, this commit introducesa JobMasterService which only exposes the JobMaster's lifecycle methods to theJobManagerRunner. This allows for an easier substitution when testing the JobManagerRunner.This closes #7563.",1
[hotfix] Remove RPC timeouts from JobMasterService lifecycle methodsThe lifecycle methods should not have a RPC timeout. Instead the implementationsnow use the RpcUtils#INF_TIMEOUT as the timeout.,5
[hotfix][docs] Fix typo,2
[FLINK-11411][runtime] Properly log number of failover regions,0
"[FLINK-11436] [avro] Manually Java-deserialize AvroSerializer for backwards compatibilityDuring the release of Flink 1.7, the value of serialVersionUID was uptick to 2L (was 1L before)And although the AvroSerializer (along with it's snapshot class) were migrated to the new serializationabstraction (hence free from Java serialization), there were composite serializers that were not migratedand were serialized with Java serialization.This commit manually Java-Deserializes the AvroSerializer to support backwards compatability.This closes #7580.",1
"[FLINK-11293][kafka, test] Added timeout to delete topic request.Logs from failures show that even though the request never finishes,kafka topics are actually deleted. Therefore this PR adds timeout ondelete request. If the request times out we check if the topic actuallyexists. If not then we continue as if the delete request succeeded.",4
[FLINK-10473][State TTL] TTL state incremental cleanup for heap backendThis closes #7188.,4
[FLINK-11071][core] add support for dynamic proxy classes resolution in job definationThis closes #7436,1
[FLINK-11071][core] Improved proxy class serialization testThis closes #7436,3
[FLINK-11270][build] Do not include hadoop in flink-dist by default,2
[hotfix][yarn][tests] Meaninful directory logging,2
[FLINK-11296][table] Support truncate in TableAPI and SQLThis closes #7450,1
[FLINK-11326] Allow negative offsets in window assigners,1
[FLINK-10910][e2e] Hardened Kubernetes e2e test.Added check if minikube is running. If it is not we try to start it couple of times. If we do not succeed we fail with a descriptive message.,0
[FLINK-11415] Introduce JobMasterServiceFactoryThe JobMasterServiceFactory controls how the JobMasterService is constructed bythe JobManagerRunner. This allows for an easier testing of this component.This closes #7564.,3
[FLINK-11400] Linearize leadership operations in JobManagerRunnerIntroduce a leadershipOperation future in the JobManagerRunner. This future is completed whenevera leadership operation (granting or revoking leadership) has been fully completed. All subsequentleadership operations wait for their predecessors to complete before they are processed. Thisguarantees that the JobMaster is properly shut down and there cannot be a race condition betweenrevoking and granting leadership.This closes #7565.,1
"[FLINK-10662][network] Refactor the ChannelSelector interface for single selected channel (#7199)[FLINK-10662][network] Refactor the ChannelSelector interface for single selected channelIn ChannelSelector#selectChannels, it would return an array for selected channels. But considering specific implementations, only BroadcastPartitioner would select all the channels, and other implementations will select one channel.So we can simple this interface to return single channel index for benefiting performance, and in the future we can specialize the BroadcastPartitioner in a more efficient way.",4
[FLINK-11469][docs] Update documentation for `Tuning Checkpoints and Large State`This closes #7603.,2
[hotfix][cep] Close nfa in CepOperator only if not null,1
[hotfix][cep] Split NFAStateSerializer methods into smaller ones.,0
[FLINK-11328][core] Migrate NFAStateSerializer to new TypeSerializer interfaceThis closes #7566.,1
[FLINK-11329] [DataStream] Migrating CompositeSerializer to use new compatibility API,1
[hotfix] [e2e] Add missing serialVersionUIDs to state TTL e2e test classes,3
[FLINK-11329] [core] Migrating the NullableSerializer to use new compatibility API,1
[FLINK-11329] [table] Migrating the RowSerializer to use new compatibility API,1
[FLINK-11329] [DataStream] Migrating the UnionSerializer to use new compatibility API,1
[FLINK-11329] [DataStream] Migrate BufferEntrySerializer to use new compatibility API,1
[FLINK-11329] [DataStream] Migrate StreamElementSerializer to use new compatibility API,1
[FLINK-11329] [scala] Migrating ScalaOptionSerializer to use new compatibility API,1
[FLINK-11329] [scala] Delegate compatibility check on old OptionSerializerConfigSnapshot to ScalaOptionSerializerSnapshotThis closes #7590.,5
[FLINK-11329] [DataStream] Migrate TwoPhaseCommitSinkFunction.StateSerializer to use new compatibility API,1
[FLINK-11329] [DataStream] Migrate TimerSerializer to use new compatibility API,1
[FLINK-11322] [kafka] Use try-with-resource for short-living connections in Kafka connectorsThis closes #7488.,1
[hotfix] [docs] Fix typo in best_practicesThis closes #7594.,2
[hotfix] [javadocs] Fix typo in RpcServiceThis closes #7585.,2
[hotfix] [rocksdb] Fix typo in RocksDB state migration exception messageThis closes #7558.,1
"[FLINK-11358][tests] Port LeaderChangeStateCleanupTest to new code baseThis commit pots the LeaderChangeStateCleanupTest to the new code base. The newtests test that revoking and granting of the leadership to the Dispatcher and theJobMaster will leave the system in a clean state.Moreover, this commit adds TaskExecutorTest#testDisconnectFromJobMasterWhenNewLeader whichensures that the TaskExecutor sends a disconnect message to the JobMaster if it is notifiedabout a leader change.Additionally, we test via DispatcherTest#testJobSuspensionWhenDispatcherLosesLeadership thata job is failed if the Dispatcher loses leadership.This closes #7567.",0
[FLINK-11357][test] Remove LeaderChangeJobRecoveryTest (#7554),3
[FLINK-11363][tests] Port TaskManagerConfigurationTest to new code base.,1
[FLINK-11363][tests] Shutdown RpcServices created in TaskManagerRunnerConfigurationTestShutdown RpcServices to avoid resource leak.Split testUsePreconfiguredRpcService into separate tests.Rename tests cases.,3
[hotfix][runtime] Refactor TaskManagerRunner#createRpcServiceExtract method determineTaskManagerHostname.,4
[FLINK-11460] [test] Remove the useless class AcknowledgeStreamMockEnvironmentThis closes #7611.,1
[FLINK-11461] [test] Remove the useless MockRecordReader classThis closes #7610.,1
"[FLINK-11064] [table] Setup a new flink-table module structureThis commit splits the flink-table module into multiple submodules inaccordance with FLIP-32 (step 1).The new module structure looks as follows:flink-table-common       ^       |flink-table-api-java <------- flink-table-api-scala       ^                                 ^       |                                 |flink-table-api-java-bridge    flink-table-api-scala-bridge       ^       |flink-table-plannerThe module structure assumes that the type system has been reworked suchthat only one table environment exists for both Java and Scala users.The module `flink-table-planner` contains the content of the old`flink-table` module. From there we can distribute ported classes totheir final module without breaking backwards compatibility orforce users to update their dependencies again.For example, if a user wants to implement a pure table program in Scala,`flink-table-api-scala` and `flink-table-planner` need to beadded to the project.Until we support pure table programs, `flink-table-api-scala/java-bridge`and `flink-table-planner` need to be added to the project.This closes #7587.",1
[FLINK-11423] Keep exception message thrown from the main classThis closes #7573.,2
[hotfix][docs] Add missing brackets,1
[FLINK-10774] Rework lifecycle management of partitionDiscoverer in FlinkKafkaConsumerBase,2
[FLINK-10774] [tests] Refactor Kafka tests to have consistent life cycle verifications,3
[FLINK-10774] [tests] Test that Kafka partition discoverer is wokeup before closed when concurrently accessed,3
[FLINK-10774][tests] Refactor FlinkKafkaConsumerBaseTest#testConsumerLifeCycleSplit #testConsumerLifeCycle into two methods which represent the two if-elsebranches.This closes #7606.,3
[FLINK-11412] [mesos] Remove legacy MesosFlinkResourceManager,2
[FLINK-10569][tests] Replace various Scheduler usages,3
[FLINK-11473][metrics][docs] Clarify documentation on Latency Tracking,2
[hotfix] [javadocs] Fix typo in TaskSlot,2
[FLINK-11384][mesos] Remove legacy MesosTaskManager,4
[FLINK-11369][tests] Remove legacy ZooKeeperHAJobManagerTest,3
[FLINK-11365][tests] Remove legacy TaskManagerFailureRecoveryITCase,0
[FLINK-11385][mesos] Remove legacy MesosJobManager,4
[FLINK-11380][tests] Finish mocking of resourceManagerClient before using itThe problem was that we started the ResourceManager before we finished the mocking of theresourceManagerClient. This lead then to concurrent modifications of the mock which madethe test fail.,0
[hotfix] [javadocs] Correct outdated doc for TaskSlotTable.start(),2
[FLINK-11389] Fix Incorrectly use job information when call getSerializedTaskInformation in class TaskDeploymentDescriptor,5
[FLINK-11389][tests] Refactor TaskDeploymentDescriptorTestThis closes #7532.,3
[FLINK-11422] Prefer testing class to mock StreamTask in AbstractStreamOperatorTestHarness,3
[FLINK-11106] [yarn] Remove legacy flink-yarn componentThis closes #7527.,2
"[FLINK-11106][tests] Port YarnTaskManagerRunnerFactoryTest to new code baseThe test YarnTaskManagerRunnerFactoryTest#testKerberosKeytabConfiguration is now covered byYarnTaskExecutorRunnerTest#testKerberosKeytabConfiguration. In order to test the behaviour,the YarnTaskExecutorRunner was slightly refactored to make it testable.",3
"[FLINK-11106] Remove Scala nature from flink-yarn moduleSince all Scala code has been removed from the flink-yarn module, we can now safelyremove the Scala nature from the flink-yarn module.",2
[FLINK-11382][metrics] Disable MetricFetcher if interval is configured to 0,5
[hotfix][docs] Remove redundant symbols,4
"[FLINK-11445][table] Deprecate static methods in TableEnvironmentIn order to separate API from actual implementation, the static methodsTableEnvironment.getTableEnvironment() are deprecated.Use Batch/StreamTableEnvionment.create() instead.This closes #7622.",1
[FLINK-11451][table] Port *QueryConfig and TableDescriptor to flink-table-api-javaThis is part of the effort to split flink-table into separate module toallow future improvements.This closes #7621,1
[FLINK-11450][table] Port and move TableSource and TableSink related classes to flink-table-commonThis closes #7626.,2
[FLINK-10395][build] Remove lefover 'codebase' references,4
[FLINK-11419][filesystem] Wait until lease is revoked before truncating file in Hadoop.,2
[FLINK-11419][filesystem] Wait for lease to be revoked when truncating file in Hadoop.This closes #7588.,2
[FLINK-11164] Check for sentinel values when creating new Kinesis ShardIterator,1
"[hotfix][kafka,tests] Do not start Flink MiniCluster when not neededPreviously MiniClusterResource was used even for tests that do not submitany job to it. Now there are two separate test bases one with and secondwithout MiniCluster.",5
[hotfix][test] Extract TestProcessBuilder utility class,3
"[FLINK-11042][kafka,tests] Drop invalid kafka producer testsMain point of testFlinkKafkaProducerFailTransactionCoordinatorBeforeNotify is to fail transaction coordinator(by using kafkaProducer.getTransactionCoordinatorId(); ) and we expect that this will cause failure of Flink job.However that's not always the case. Maybe because transaction coordinator can be re-elected before KafkaProducereven notices it or for whatever the reason, sometimes the failure is not happening.Because of a bug in the test, if failure hasn't happened, the test will not fail.Generally speaking this test is invalid and should be dropped.",4
[hotfix][docs] Updated vendor building documentation with library that existsThis closes #7648,2
"[FLINK-9920] Only check part files in BucketingSinkFaultToleranceITCaseBefore, it could happen that other files are in the same directory. Thenthe verification logic in the test would pick up those files and thetest would fail. Now we ignore all files that don't match our expectedpattern.",2
"[FLINK-11352][tests]Port JobManagerHACheckpointRecoveryITCase to new code base.The testCheckpointRecoveryFailure moved to JobManagerHAProcessFailureRecoveryITCase::testJobManagerRecoveryFailureLog,testCheckpointedStreamingProgramIncrementalRocksDB is already covered by KeyedStateCheckpointingITCase#{testWithRocksDbBackendFull, testWithRocksDbBackendIncremental}.This closes #7647.",5
[FLINK-11522][table] Deprecate ExternalCatalogTable.builder()This unblocks the porting and moving of ExternalCatalogTable toflink-table-common for FLINK-11067.This closes #7650,2
[FLINK-11521] Make RetryingRegistration configurableMake the timeouts of the RetryingRegistration configurable. This gives more controlover Flinks registration behaviour which is also beneficial for testing purposes.This closes #7645.,3
[hotfix] Move YarnTestBase#waitUntilCondition into runtime.CommonTestUtils,3
[FLINK-11370][test]Check and port ZooKeeperLeaderElectionITCase to new code base if necessaryThis closes #7613.,1
[FLINK-11370][tests] Refactor LeaderChangeClusterComponentsTest#testTaskExecutorsReconnectToClusterWithLeadershipChangeMake the test more responsive by using CommonTestUtils#waitUntilCondition.,3
[hotfix] Remove blocking call when retrieving the DispatcherGateway from MiniCluster,5
[hotfix] Simplify MiniCluster by using the DispatcherResourceManagerComponentThis commit simplifies the MiniCluster by using the DispatcherResourceManagerComponentto start a Dispatcher and a ResourceManager. Moreover it refactors the MiniCluster tosupport support for multiple DispatcherResourceManagerComponents.,1
"[hotfix] Let Dispatcher use GatewayRetriever for communication with the ResourceManagerBefore, the Dispatcher was only able to talk to a single ResourceManager with which it was started.Now, the Dispatcher gets a GatewayRetriever passed in which it uses to resolve the gateway forthe current leading ResourceManager. That way it is no longer forced to only talk to its co-locatedResourceManager.",1
[hotfix][tests] Extend TestingMiniCluster to support multiple Dispatchers and ResourceManagersThis commit adds funcationality to the TestingMiniCluster to start multiple Dispatchers andResourceManagers. This can be used to test HA scenarios.,3
[FLINK-11370] Port ZooKeeperLeaderElectionITCase#testJobExecutionOnClusterWithLeaderReelection to new code base,1
[FLINK-11417] Make access to ExecutionGraph single threaded from JobMaster main threadThis closes #7568.,1
[FLINK-11502][tests] Remove obsolete test FlinkActorTest (#7627),3
[FLINK-11497][tests] Remove obsolete test JobManagerLeaderElectionTest (#7624),3
"[FLINK-11447][table] Deprecate new Table(TableEnvironment, String)Deprecates the constructor usage of the Table class. This isnecessary for converting the class into a clean interface. Seealso FLIP-32 for more information.Use table.joinLateral() or table.leftOuterJoinLateral() instead.This closes #7651.",5
[FLINK-11362][tests] Port TaskManagerComponentsStartupShutdownTest to new code baseThis closes #7632.,1
[FLINK-11362][tests] Clean up TaskExecutorTest# testTaskManagerServicesShutdown* Use IOManagerAsync(String) constructor* Simplify TaskExecutorTest#testTaskManagerServicesShutdown() asserts* Explicitly create MemoryManager instance for assertions* Remove superfluous NetworkEnvironmentConfiguration instance* Rename test testTaskManagerServicesShutdown to testShouldShutDownTaskManagerServicesInPostStop* Move heartbeatServices declaration/definition closer to first usage,5
[hotfix][tests] Move field definitions before method definitions,5
[hotfix][table] Annotate QueryConfig classes,5
[FLINK-11535][table] Include table-api-java in SQL Client jarThis closes #7652.,2
[FLINK-10944] Enhance error message for slot allocation timeout,0
[FLINK-11505][runtime] Remove legacy JobManagerRegistrationTest,3
[FLINK-11504][runtime] Remove legacy JobManagerConnectionTest,3
[FLINK-11503][runtime] Remove legacy TaskManagerLossFailsTasksTest,3
[hotfix][yarn] Remove legacy descriptor methods,4
[FLINK-11513][client] Port CliFrontendSavepointTest,3
[FLINK-11512][client] Port CliFrontendModifyTest,3
[hotfix][javadocs] Fix typos and errors,0
[FLINK-11386][runtime] Remove legacy ContaineredJobManagerThis closes #7623.,4
[FLINK-11509][tests] Remove invalid test ClientConnectionTest (#7634),3
[FLINK-11367][tests] Port TaskManagerProcessReapingTestBase to new code baseThis closes #7653.,1
[hotfix][docs] Fix instructions to enable checkpointing for iterative jobs,0
[FLINK-11495][runtime] Remove legacy job archiving paths,4
[FLINK-11494][runtime] Remove WebRuntimeMonitor,1
[FLINK-11368][runtime] Port TaskManagerStartupTest,3
[FLINK-11382][docs] Update documentation,2
[hotfix] Log JobMasterId under which a job is being executed,2
[hotfix] Fix checkstyle violations in EmbeddedHaServicesTest,3
[hotfix] Correct logging statement in ResourceManager,2
"[FLINK-11524] Solve race condition in EmbeddedLeaderServiceUsing the EmbeddedHaServices it could happen that the EmbeddedLeaderService goes into aninvalid state if two grant leadership operations are executed concurrently.The problem was that the first operation when confirming the now outdated leader session idwould set the EmbeddedLeaderElectionService#isLeader field to false as part of the staleconfirmation message handling. Consequently, all subsequent calls toLeaderElectionService#hasLeadership(newLeaderSessionId) would return false even though thecontender would still have the leadership.The solution is to not set the EmbeddedLeaderElectionService#isLeader to false if theEmbeddedLeaderService encounters a stale confirmation message.This closes #7654.",5
[FLINK-11311][datastream] Fix StreamSource implements StreamOperator interface multiple timesThis closes #7492.,1
[Flink-11314] Use RocksDBWriteBatchWrapper instead of WriteBatch in the flush function of RocksDBMapStateThis closes #11314.,5
[Flink-11315] Make magic number in KvStateSerializer as a constant value to make more readable (#7482)This closes #11315,1
[FLINK-11483][tests] Simplify StreamOperatorSnapshotRestoreTest with ParameterizedThis closes #7612.,2
[FLINK-11515][client] Port ClientTest,3
[hotfix][tests] Remove unnecessary catch blocks,4
[hotfix][tests] Rename ClusterClient variable,3
[FLINK-11553][tests] Create empty fencing tokens queue instead of null in DispatcherHATest.testFailingRecoveryIsAFatalErrorThis closes #7669.,3
[FLINK-10422] [kinesis] Follow AWS specs in Kinesis ConsumerThis closes #6760.,2
[FLINK-11413][metrics] Fix reporter filtering on JDK 9,0
[FLINK-11550][kinesis] Port manual tests,3
[FLINK-11514][client] Port ClusterClientTest,3
[hotfix][tests] Fix failing logic in RestCusterClientTest,3
[FLINK-11570][tests] Rework savepoint trigget RestClusterClient tests,3
[FLINK-11288][build] Add flink-ml-uber module,2
[FLINK-11540][client] Remove StandaloneClusterClient,4
[FLINK-11571][runtime] Remove JobManagerProcess,4
[FLINK-11548][tests] Delete test ClusterShutdownITCase,3
"[FLINK-11548][tests, runtime] Add test for Dispatcher#shutDownClusterThis closes #7666.",3
[hotfix][runtime] Rename method closeAsyncInteral to closeAsyncInternal,0
[hotfix][runtime] Delete unused method DispatcherResourceManagerComponent#getTerminationFuture,1
[FLINK-11549][tests] Remove obsolete ResourceManagerITCase,4
[FLINK-11508][tests] Remove invalid test AkkaJobManagerRetrieverTestThis closes #7633.,3
[FLINK-11507][tests] Remove invalid test JobClientActorTestThis closes #7635.,3
[FLINK-11511][tests] Remove legacy class JobAttachmentClientActorThis closes #7637.,4
[FLINK-11046] [elasticsearch] Fix ElasticsearchSink deadlock when index failed with retry,1
"[FLINK-11046] [elasticsearch] Simplify failure handler indexer implementationSince we always use the original request indexer to re-index failedrequests, and that indexer already keeps track of the number of pendingactions, the ElasticsearchFailureHandlerIndexer does not need to keeptrack of the number of pending records by itself.",0
[FLINK-11046] [elasticsearch] Always re-index buffered failed requests on snapshotThis ensures that at-least-once semantics is not broken due to thechanges to the failure handle request indexer.This closes #7576.,0
[hotfix] [elasticsearch] Replace implementation of deprecated invoke method in ElasticsearchSinkBase,0
[hotfix][logging] Fix various logging issues,0
[hotfix][docs][kafka] Fix code formatting,0
[FLINK-11053][docs] Fix Bucketing Sink example,0
[hotfix][docs] Add space in self-closing linebreak tag,4
[FLINK-11584][docs][tests] Fix linebreak parsing,4
[hotfix] Fix checkstyle violations in MainThreadValidationTest,5
[hotfix] Refactor ResourceManagerTest to avoid mocking,3
[FLINK-11551][rpc] Allow RpcEndpoint to execute asynchronous stop operationsReplace RpcEndpoin#postStop with RpcEndpoint#onStop method which can execute asynchronousoperations in the main thread executor. onStop returns a future which will terminate theRpcEndpoint once it is completed.The new stop semantics allow to execute complex shut down logic which requires asynchronousoperations.This closes #7665.,1
[hotfix] Replace RpcEndpoint#shutDown with RpcEndpoint#closeAsync method,0
[hotfix] Fix checkstyle violations in MessageSerializationTest,3
[FLINK-11585][docs] Fix prefix matching,0
[hotfix][metrics][docs] Add missing space,1
[FLINK-11418][docs] Fix version of bundler to 1.16.1This closes #7575,0
[FLINK-11297][docs] Add a doc link of jobmanager ha details.,2
[FLINK-11297][docs] Minor amendmends to the changeThis closes #7457,4
[FLINK-7155][metrics] Add InfluxDB reporter,5
[FLINK-11583][configuration] Support deprecated and fallback keys at once,1
[hotfix][configuration] Add tests for deprecation flags of keys,3
[hotfix] Remove TaskExecutorITCaseTaskExecutorITCase is actually covered by TaskExecutorTest#testOfferSlotToJobMasterAfterTimeout.,3
[hotfix] Remove mocking from TaskExecutorTest#testJobLeaderDetection,3
[hotfix] Remove mocking from TaskExecutorTest#testHeartbeatSlotReporting,3
"[FLINK-11364][tests] Port TaskManagerFailsITCase to new code base- ""detect a failing task manager"" --> JobMaster#testHeartbeatTimeoutWithTaskManager- ""handle gracefully failing task manager"" --> JobMasterTest#testJobFailureWhenGracefulTaskExecutorTermination- ""handle hard failing task manager"" --> JobMasterTest#testJobFailureWhenTaskExecutorHeartbeatTimeout- ""go into a clean state in case of a TaskManager failure"" --> TaskExecutorITCase#testNewTaskExecutorJoinsClusterThis closes #7676.",3
"[FLINK-11586][tests] Remove legacy SlotSharingITCase- ""support slot sharing for forward job"" --> is covered by JobRecoveryITCase#testTaskFailureWithSlotSharingRecovery- ""support slot sharing for forward job"" --> covered by MiniClusterITCase#testSchedulingAllAtOnceThis closes #7689.",5
[FLINK-10493] [core] Add SelfResolvingTypeSerializerThis interface is useful for cases where differentTypeSerializers where using the same snapshot class.,1
"[FLINK-10493] Migrate all subclasses of TupleSerializerBase to use new serialization compatibility abstractionsThis includes the following serializers:- org.apache.flink.api.java.typeutils.runtime.Tuple0Serializer- org.apache.flink.api.java.typeutils.runtime.TupleSerializer- org.apache.flink.api.scala.Tuple2CaseClassSerializer- org.apache.flink.api.scala.typeutils.CaseClassSerializerAll of these serializers now have their own independent serializersnapshot class. They all implement the SelfResolvingTypeSerializer,allowing us to remove the ensureCompatibility(...) method from theTupleSerializerBase class.",4
[FLINK-10493] [scala] Rename SpecificCaseClassSerializer to ScalaCaseClassSerializerThis closes #7658.,2
[hotfix] [tests] Make case class definition in tests top level,3
[FLINK-11591] [core] Support transformation for serializer snapshots before 1.7This commit adds a mechanism for type serializers to transformpreviously checkpointed serializer snapshots (from pre 1.7) to adifferent serializer snapshot.,1
[FLINK-11591] [core] Allow injecting nested serializer snapshots via CompositeTypeSerializerUtil,1
"[FLINK-11591] [cep] Transform incorrect snapshots for LockableTypeSerializer before 1.7In Flink 1.6, LockableTypeSerializer was directly returningthe elementSerializer's snapshot instead of wrapping it ina LockableTypeSerializer(Config)Snapshot. This caused state information to bewritten as <LockableTypeSerializer, SomeArbitrarySerializerSnapshot>.This commit address that by transforming the legacy snapshot.This closes #7695.",1
[FLINK-11089] Log filecache directory removed messagesThis closes #7257.,4
[FLINK-11544] [rest] Extend JarRequestBody with job ID,2
[FLINK-11544] [rest] Set job ID from optional request body entry,1
[FLINK-11544] [rest] Add Nullable annotation to PackagedProgramUtils,1
[FLINK-11544] [rest] Regenerate rest-docs,2
"[hotfix][tests] Fix CommonTestUtils#waitUntilCondition(SupplierWithException, Deadline, long)Properly pass the retryIntervalMillis to the sleep call.",1
"[FLINK-11486][tests] Port RecoveryITCase to new code base- ""recover a task manager failure"" --> TaskExecutorITCase#testJobRecoveryWithFailingTaskExecutor- ""recover once failing forward job"" --> JobRecoveryITCase#testTaskFailureRecovery- ""recover once failing forward job with slot sharing"" --> JobRecoveryITCase#testTaskFailureWithSlotSharingRecoveryThis closes #7683.",3
[hotfix][tests] Harden tests using CommonTestUtils.waitUntilConditionIncrease the retry interval for TaskExecutorITCase and ZooKeeperLeaderElectionITCasesince they take so long that the low retry interval won't have a big effect apartfrom a higher CPU load.,1
"[FLINK-11587][tests] Port CoLocationConstraintITCase to new code base- ""support colocation constraints and slot sharing"" --> JobExecutionITCase#testCoLocationConstraintJobExecutionThis closes #7690.",3
[FLINK-11442] Upgrade OSS SDK versionThis closes #7599.,2
[FLINK-11602] Remove legacy AkkaJobManagerRetriever,4
[hotfix] [tests] Fix access to nested utility classes of TypeSerializerSnapshotMigrationTestBaseThe subclass ScalaCaseClassSerializerSnapshotMigrationTest was failingto build with Scala 2.12 because of this.,1
"[hotfix] [scala, tests] Fix failing ScalaCaseClassSerializerSnapshotMigrationTest in Scala 2.12The ScalaCaseClassSerializerSnapshotMigrationTest was failing becauseof a serial version UID mismatch for the test data type CustomCaseClass.Scala 2.12 generates different default serial version UIDs compared toScala 2.11.This commit explicitly sets the serial version UID for that test datatype, so that the migration test is agnostic to the Scala version beingused.",1
[FLINK-11568][kinesis] Don't obscure important Kinesis exceptions (#7672),2
[FLINK-10431] Extract scheduling-related code from SlotPoolThis closes #7662.,4
[FILNK-11597][test] Remove legacy JobManagerActorTestUtils (#7700),3
[FLINK-11081][rest] Support server port range,1
[hotfix][runtime] Fix mistake in RestfulGateway and JobMasterGateway JavadocMethod requestOperatorBackPressureStats never returns a future that completeswith null.,1
[FLINK-11578][runtime] Expose MiniCluster#getDispatcherGatewayFuture for testing,3
[FLINK-11578][tests] Port BackPressureStatsTrackerImplITCase to new code baseThis closes #7697.,1
[FLINK-11626][build] Bump flink-shaded to 6.0,2
[FLINK-11628][travis] Cache maven,2
[FLINK-11424][metrics] Properly remove string/failing gauges,0
[hotfix] Reorder StandaloneJobClusterEntryPoint class members,1
[hotfix] Improve error message in JobID.fromHexString,0
[FLINK-11545] [container] Add job ID to StandaloneJobClusterConfiguration[FLINK-11545] [container] Add null checks and reduce visibility in StandaloneJobClusterConfigurationFix line breaks in StandaloneJobClusterConfiguration,5
[FLINK-11545] [container] Parse job ID in StandaloneJobClusterConfigurationParserFactory[pr-review] Make getJobId static[pr-review] Add expected format and example to error messageFix checkstyleDon't wrap JobID.fromHexString error message in StandaloneJobClusterConfigurationParserFactory[pr-review] Add test for short options,3
[FLINK-11545] [container] Pass job ID to ClassPathJobGraphRetriever,4
[FLINK-11545] [container] Catch Exception before exiting with error,0
[FLINK-11545] [container] Add docs for job-id argument,2
[hotfix][tests] Remove mocking from ResourceManagerJobMasterTest,3
[hotfix][tests] Remove mocking from ResourceManagerTaskExecutorTest,3
[hotfix][tests] Refactor ResourceManagerTest to use Before and After methods,1
[FLINK-11596][test] Remove legacy ResourceManagerTest,3
[FLINK-11596][tests] Add ResourceManagerTaskExecutorTest#testDisconnectTaskExecutor,3
[FLINK-11596][tests] Add heartbeat timeout test to ResourceManagerTest- Add ResourceManagerTest#testHeartbeatTimeoutWithJobMaster- Add ResourceManagerTest#testHeartbeatTimeoutWithTaskExecutorThis closes #7698.,3
[hotfix][travis] Remove stray slash,4
[hotfix][build] Remove hard-coded scala version,4
"[FLINK-11154][network] Bump Netty to 4.1.32Notable changes since 4.1.24:- big improvements (performance, feature set) for using openSSL based  SSL engine (useful for FLINK-9816)- allow multiple shaded versions of the same netty artifact (as long  as the shaded prefix is different)- Ensure ByteToMessageDecoder.Cumulator implementations always release- Don't re-arm timerfd each epoll_wait- Use a non-volatile read for ensureAccessible() whenever possible to  reduce overhead and allow better inlining.- Do not fail on runtime when an older version of Log4J2 is on the  classpath- Fix leak and corruption bugs in CompositeByteBuf- Add support for TLSv1.3- Harden ref-counting concurrency semantics- bug fixes- Java 9-12 related fixes- no license changes- no changes in Netty's NOTICE file",2
"[FLINK-11577][tests, runtime] Improve test coverage of stack trace sampling in TM- Extract stack trace sampling logic to StackTraceSampleService- Add unit tests for StackTraceSampleService",3
[FLINK-11577][tests] Delete obsolete test StackTraceSampleCoordinatorITCase- Test could silently fail- Test had no assertions- Test is superseded by StackTraceSampleServiceTest,3
[FLINK-10887] [jobmaster] Add global aggregate tracking to the JobMaster (#7099)This adds a JobMaster RPC endpoint that is used to share information across source subtasks.This will be used implement things like event time source synchronization across sources.  This functionality can be accessed from user code via the StreamingRuntimeEnvironment.,1
[FLINK-11121][license] Check and update licensing notes for Aliyun FSThis closes #7692.,5
Refactor ScalaSerializersMigrationTest to be agnostic of serializer class,3
"[FLINK-11539] Add TypeSerializerSnapshot for TraversableSerializerThis changes the TraversableSerializer to not be abstract anymore, notdepend on a macro for generating a CanBuildFrom.We now store the CanBuildFrom type as a string and compile that atruntime to get a CanBuildFrom. This String is easily storable in the newTypeSerializerSnapshot.This also breaks compatibility of savepoints that contain aTraversableSerializer from Flink 1.2. A test is adapted to reflect that.",3
[hotfix] Move testing sender and receiver invokables to TestingAbstractInvokablesMoves the testing Sender and Receiver class from JobExecutionITCase to TestingAbstractInvokablesfor easier reusability.,3
"[FLINK-11592][tests] Port TaskManagerFailsWithSlotSharingITCase to new code base- ""handle gracefully failing task manager with slot sharing"" --> TaskExecutorITCase#testJobReExecutionAfterTaskExecutorTermination- ""handle hard failing task manager with slot sharing"" --> TaskExecutorITCase#testJobReExecutionAfterTaskExecutorTerminationThis commit changes the JobGraph of the TaskExecutorITCase such that it uses now slot sharing.This closes #7693.",1
[hotfix][tests] Remove Tasks#Sender and #Receiver,4
[FLINK-10540] Remove legacy FlinkMiniCluster and sub classesThis commit removes- FlinkMiniCluster- LocalFlinkMiniCluster- TestingClusterThis closes #7694.,3
[hotfix][runtime] Remove wrong references to ResourceManager in RetryingRegistration,1
[hotfix][runtime] Delete unused constructor in RetryingRegistration,1
"[hotfix][tests, runtime] Fix checkstyle violations in TestingGatewayBase",3
[hotfix][tests] Fix checkstyle violations in TestingRpcService,3
[FLINK-11594][tests] Extract method createTaskExecutorLocalStateStoresManager in TaskExecutorTest,3
[FLINK-11594][tests] Clean up TaskExecutorTest#testImmediatelyRegistersIfLeaderIsKnown,3
[FLINK-11594][tests] Add TaskExecutorToResourceManagerConnectionTest,3
[FLINK-11594][tests] Add assert to test that TM re-connects to JM,3
[FLINK-11594][tests] Remove TaskManagerRegistrationTestThis closes #7725.,3
[hotfix] Fix typo in comments of MemorySegmentThis closes #7744.,2
[FLINK-11629][rpc] Stop AkkaRpcActor immediately after onStop future has been completedThe AkkaRcpActor should stop itself immediately after the onStop future has been completed.Before we sent a Kill message which enqueues into the mailbox and does not overtake messages.Now we call Context.stop(ActorRef) which directly stops the AkkaRpcActor.This closes #7716.,2
[hotfix] Fix some typos in documentation and java-docThis closes #7748.,2
[FLINK-11645][tests] Remove TestingUtils#createJobManagerTestingUtils#createJobManager created a TestingJobManager for testing purposes which is no longer neededsince all legacy tests using the TestingJobManager are now ported.,3
[hotfix][tests] Remove TestingMemoryArchivist,3
[FLINK-11645][tests] Move TestingJobManagerMessages#NotifyWhenJobRemoved to TestingTaskManagerMessages,3
"[FLINK-11645][tests] Remove TestingJobManagerRemoves the TestingJobManager, TestingJobManagerLike and TestingJobManagerMessages.",3
[hotfix] Fix checkstyle violations in TriggerCheckpoint,0
[FLINK-11645] Remove legacy JobManagerThis commit removes the legacy JobManager and references in comments from the code.This closes #7731.,4
[FLINK-11648] Remove MemoryArchivistThis closes #7733.,4
[FLINK-11649] Remove legacy JobInfo classThis closes #7735.,5
[FLINK-11650][tests] Remove TestingUtils#removeResourceManager,3
[FLINK-11650][tests] Remove legacy TestingResourceManager,3
[FLINK-11650] Remove legacy StandaloneResourceManager,4
[FLINK-11650] Remove FlinkResourceManager- Replace FlinkResourceManager#RESOURCE_MANAGER_NAME with ResourceManager#RESOURCE_MANAGER_NAMEThis closes #7736.,2
[FLINK-11323] Add a generic type snapshot base,1
[FLINK-11588] Migrate CopyableValueSerializer to new serialization compatibility abstractions,1
[FLINK-10964][sql-client] SQL Client throws exception when paging through finished batch queryThis closes #7265.,5
[FLINK-10471][State TTL] State TTL cleanup using RocksDb compaction filterThis closes #7163.,5
[FLINK-11598] Remove legacy JobSubmissionClientActorThis closes #7738.,4
[FLINK-11600] Remove legacy JobListeningContextThis closes #7739.,4
[FLINK-11599] Remove legacy JobClientActorThis closes #7740.,4
[FLINK-11601] Remove legacy JobManagerGatewayThis closes #7741.,4
[FLINK-11652] Remove legacy JobClientThis closes #7743.,4
"[FLINK-9803] Drop canEqual() from TypeSerializerThis change removes TypeSerializer.canEqual() because it is not usefulon that class hierachy. Serializers can only equals() on an exactmatch, not with different serializers up and down the hierarchy.This adds a serialVersionUID to InstantSerializer, to ensure that itdoesn't change from removing the canEqual() method.Plus we also remove canEqual() from PojoField, where it is not needed.",4
[FLINK-11663] Remove control flow break point from Execution#releaseAssignedResourceSince LogicalSlot#releaseSlot returns a future which is always completed from the main threadit is no longer necessary to merge the future back into the main thread by using FutureUtils#whenCompleteAsyncIfNotDone. The advantage is that LogicalSlot#releaseSlot will atomically releasethe assigned Execution.This closes #7755.,1
[hotfix][tests] Fix reference in PackagedProgramTest,3
[hotfix][docs] Fix typo in sourceSinks.md.,2
[FLINK-10569][runtime] Remove Instance usage in ExecutionVertexSchedulingTest,3
[FLINK-11292] [doc] Update document about how to use new CompositeTypeSerializerSnapshot,1
"[FLINK-11292] [doc] Move predefined TypeSerializerSnapshot class docs to a top-level subsectionThis commit adds an independent, top-level subsection named ""Predefinedconvenient TypeSerializerSnapshot classes"" to the ""Custom Serializationfor Managed State"" page.This section covers details about using the SimpleTypeSerializerSnapshotand CompositeTypeSerializerSnapshot classes, what they do, and in whichcases they are suitable to be used by a serializer.This closes #7475.",1
"[hotfix] [doc] Add ""Avoid Java serialization"" to best practices section in ""Custom Serialization for Managed State"" doc",2
[hotfix] [core] GenericArraySerializerSnapshot should implement isOuterSnapshotCompatible,0
[FLINK-11655][rpc] Remove serializable interface from CallAsyncCallAsync is a message which should only send to the local actor. Hence it isnot necessary to be serializable.This closes #7760.,4
[FLINK-11677] Remove ResourceManagerRunnerThis closes #7699.,1
[hotfix][runtime] Fix typo in IOManagerAsync,2
[FLINK-11691] Introduce Classloader in the methods of StateBackendFactory and ConfigurableStateBackendThis closes #7779.,5
[hotfix] Use lambda for heartbeat timeout handler in ResourceManager,0
[hotfix] Null resourceManagerAddress when suspending JobMasterNulling the resourceManagerAddress when suspending the JobMaster prevents that theJobMaster tries to reconnect to the ResourceManager if it receives a disconnectResourceManagermessage.,1
[hotfix] Fix checkstyle violation in JobMaster,0
[hotfix] Fix checkstyle violations in ExecutionGraphSuspendTest,3
[hotfix] Remove unused methods from TaskManagerGateway,1
[hotfix][tests] Remove mocking from ExecutionGraphSuspendTest,3
[hotfix] Fix checkstyle violation in ExecutionGraph,0
[hotfix] Fix checkstyle violations in JobStatus,0
[hotfix] Fix checkstyle violations in ArchivedExecutionGraphTest,3
"[FLINK-11537] Make ExecutionGraph#suspend terminate ExecutionGraph atomicallyThis commit makes the suspend call transition the ExecutionGraph atomically into theSUSPENDED state without requiring a round-trip to cancel all task properly. Instead itsimply notifies the TaskExecutors about the suspension and then transitions the Executionsinto a terminal state. Moreover, this commit removes JobStatus#SUSPENDING.This closes #7756.",4
[hotfix][tests] Remove mocking from ExecutionGraphSchedulingTest,3
[FLINK-11678] Change RestfulGateway#requestJob return type to CompletableFuture<ArchivedExecutionGraph>,4
[FLINK-11678] Let ExecutionGraphCache store only ArchivedExecutionGraphsThe ExecutionGraphCache now only stores ArchivedExecutionGraphs since it will never receive anExecutionGraph from the RestfulGateway.- Remove ExecutionGraphTest#testCacheInvalidationIfSuspended- Remove ExecutionGraphTest#testCacheInvalidationIfSwitchToSuspendedThis closes #7769.,5
[FLINK-11334][core] Migrate enum serializers to use new serialization compatibility abstractionsThis commit touches EnumSerializer: - replace an EnumSerializerSnapshot when calling snapshotConfiguration. - add a test EnumSerializerSnapshotMigrationTest to varify the change. - remove function EnumSerializer#ensureCompatibility.,1
[FLINK-11334] Remove old deserialization logic from new EnumSerializer SnapshotThis code will never be used to deserialize from an oldSerializerConfigSnapshot.,5
"[FLINK-11334] Fix compatibility check in EnumSerializer Snapshot and do proper reconfigurationThis changes the new EnumSerializer Snapshot to hold Enums, instead oftheir String representation (we to the mapping from and to Enum in theread/write methods).This also changes the compatibility checks to detect changes in enumordering and then report that only reconfiguration is required.",1
"[FLINK-11334] Fix EnumSerializer.equals()Before, it wasn't comparing the ordering of enum values, i.e. themapping of indices to enum values.",0
[FLINK-11334] Add good EnumSerializer.toString()This makes it easier to understand failing tests where serializersare being compared.,3
[FLINK-11334] Add good TypeSerializerSchemaCompatibility.toString()This makes it easier to read messages of failing tests.,3
[FLINK-11334] Fix matcher in TypeSerializerSnapshotMigrationTestBase,3
[FLINK-11334] Allow setting a compatibility matcher in TypeSerializerSnapshotMigrationTestBase,3
[FLINK-11334] Fix EnumSerializerSnapshotMigrationTest to check reconfiguration,5
[FLINK-11334] Initialize EnumSerializer in constructorWe also don't check the state on every call anymore.,5
Fix checkstyle and warnings in EnumSerializer,2
[FLINK-11699] Use isEmpty() for address comparison in AbstractDispatcherResourceManagerComponentFactoryThis closes #7783.,1
[FLINK-11041][tests] Fix ReinterpretDataStreamAsKeyedStreamITCaseThis closes #7753.,5
[hotfix][docs] Fix typo in cep.md.,2
[hotfix] Remove extra symbols in StringComparator,4
[FLINK-11334][core] Migrate EnumValueSerializer to use new serialization compatibility abstractionsThis commit migrate EnumValueSerializer to use new serialization compatibilty abstractions  * add a new class `ScalaEnumSerializerSnapshot`  * return a `ScalaEnumSerializerConfigSnapshot ` with `ScalaEnumSerializerSnapshot` when calling `EnumValueSerializer#snapshotConfiguration`  * add a migration test `EnumValueSerializerSnapshotMigrationTest` to test the compatibility  * remove function `EnumValueSerializer#ensureCompatibility()`,1
"[FLINK-11334] Don't use IntSerializer in EnumValueSerializerUsing an IntSerialize technically makes EnumValueSerializer a compositeserializer, which it doesn't have to be. This decouplesEnumValueSerializer from any future changes to IntSerializer.",4
[FLINK-11334] Remove old deserialization logic from ScalaEnumSerializerSnapshotThis logic will never be used because the new snapshot will never beused to deserialize an old config snapshot.,5
"[FLINK-11334] Create proper restore serializer in ScalaEnumSerializerSnapshotBefore, this was trying to create an Enumeration and cast it to aTypeSerializer. Creating the enumeration would fail because it is aScala Object, i.e. a singleton. The cast would also fail.This now uses inspection to create an instance of the Enumeration andthen uses that to create an EnumValueSerializer.",1
"[FLINK-11334] Fix migration check in ScalaEnumSerializerSnapshotFirst, this inverts the if statements to make the code more readableand maintainable.Then, this changes the check to report *incompatible* when the orderof enums changes or when enums are removed because we currently don'tmaintain a map of enum ids to enum values ourselves and therefore cannotmigrate or reconfigure the serializer to read data that was serializedwith the old mapping.",5
[FLINK-11334] Add checkState calls in ScalaEnumSerializerSnapshot,1
[hotfix][runtime] Refactor SimpleAckingTaskManagerGateway to not use optional,1
[hotfix][runtime] Add convenience TestingLogicalSlot constructor,3
[FLINK-10569][runtime] Remove Instance usage in ExecutionGraphDeploymentTest,3
[FLINK-11684][checkstyle] Bump checkstyle to 8.12,2
[FLINK-11684][checkstyle] Enforce single empty line around static imports,2
[FLINK-11713][docs] Remove legacy mode from documentation,2
[FLINK-11686][checkstyle] Enforce whitespace around lambdas,1
[FLINK-11688][checkstyle] Enforce whitespace around TYPE_EXTENSION_AND,1
[hotfix] [tests] Fix EnumValueSerializerSnapshotMigrationTest for Scala 2.12 buildsThe test enum type written in test resource files has differentserialVersionUIDs generated between Scala 2.11 / 2.12. The test fails in2.12 because we wrote the test files with 2.11.This commit fixes that by explicitly setting a fixed serialVersionUIDfor the test enum type.,3
[FLINK-11323] Add OptionalMap to be used by KryoAn OptinalMap is a map that allows null values and null keys (as longas a name is assosicated with them. This would replace the usage ofDummyUnloadableClass and DummyUnloadableSerializer withinKryoSerializerSnapshot.,1
[FLINK-11323] [tests] Adjust serializer tests to respect new COMPATIBLE_WITH_RECONFIGURED_SERIALIZER optionAdjust serializer tests to use the reconfigured serializer if suchserializer was provided.,1
"[FLINK-11323] [core] Migrate KryoSerializer to use new serialization compatibility abstractionsThis commit adds a new KryoSerializerSnapshot class and uses thatinstead of the now deprecated KryoSerializerConfigSnapshot.It also adds migration tests for the new KryoSerializerSnapshot,extending the TypeSerializerSnapshotMigrationTestBase.",3
[FLINK-11323] [tests] Add more test cases to TypeSerializerSnapshotMigrationTestBaseThis commit adds two more tests to TypeSerializerSnapshotMigrationTestBasethat validates that the new serializer are able to read previously storeddata (perhaps after reconfiguration).,5
[FLINK-11323] Migrate WritableSerializer to use new serialization compatibility abstractions,1
[FLINK-11323] Migrate ValueSerializer to use new serialization compatibility abstractions,1
[FLINK-11323] Migrate TrySerializer to use new serialization compatibility abstractionsThis closes #7496.,1
[FLINK-11485] [core] Move OptionalMap to org.apache.flink.utilThis utility class may commonly be used by the KryoSerializer and thePojoSerializer. This commit moves the utility to a more suitable packageand adjusts usage access.,4
"[FLINK-11485] [core] Rename OptionalMap to LinkedOptionalMapHaving ""Linked"" in the name better reflects the fact that the mappreserves entry ordering.",1
[FLINK-11485] [core] Refactor multiple nested serializer compatibility resolution logic to CompositeTypeSerializerUtilThis commit refactors the logic of resolving overall compatibilityresults across multiple nested serializers of a composite serializer outof the CompositeTypeSerializerSnapshot class.This allows us to reuse this functionality when implementing thecompatibility check for the PojoSerializerSnapshot,1
[FLINK-11485] [core] Implement new PojoSerializerSnapshot class,1
[FLINK-11485] [core] Migrate PojoSerializer to use new serialization compatibility abstractions,1
"[FLINK-11485] [tests] Adjust existing PojoSerializer upgrade testsThe following tests have been adjusted to new scope of functionalityrelated to upgrading the PojoSerializer: PojoSerializerTest andPojoSerializerUpgradeTest.In PojoSerializerTest, assertions that were supposed to check for""isCompatibleWithReconfiguredSerializer"" cases have been adjusted tocorrectly do so. Also, a test where changing field order was tested wasremoved, since the new PojoSerializerSnapshot always assumes that fieldshave been sorted already by the type extractor.In PojoSerializerUpgradeTest, tests which remove / add fields to POJOclasses were updated to no longer expect failures. They were expectingfailures because POJOs were not evolvable in the past.The updates to these tests also provide coverage for the POJO schemaevolution feature.This closes #7759.",3
[hotfix] [core] LinkedOptionalMap should collect keys in LinkedHashSet to guarantee ordering,2
[FLINK-10897] [docs] Document POJO schema evolution in /dev/stream/state/schema_evolution.md,2
"[FLINK-6768] [core] More efficient field serializer lookups in PojoSerializerSnapshotIn the PojoSerializerSnapshot#resolveSchemaCompatibility method we callfor each field the findField(...) method in the PojoSerializer, whichperforms a linear scan of the array of fields. This effectively hasO(n^2) complexity.This is improved by this commit by building an index in theresolveSchemaCompatibility method for faster field serializer lookups.",0
"[hotfix] [core] Subclass serializer cache in PojoSerializer should be a MapIn this case, there is no specific need to let that cache bespecifically a HashMap. Changing this to the generic Map does not breakcontracts with how the PojoSerializer works. It also doesn't breakcompatibility w.r.t. Java serialization of the PojoSerializer.",4
[FLINK-11690][runtime] Use configured RPC timeout in MiniCluster,5
[FLINK-10569][runtime] Remove Instance usage in FailoverRegionTest,3
[FLINK-11651][tests] Upgrade jepsen dependency to 0.1.11,3
[hotfix][runtime] Consistent enum implementation,0
[hotfix] Fixing test instabilities in streaming.runtime.tasks.,1
[FLINK-8354] Refactor AUTO_COMMIT config in Kafka consumersThis moves the code to a method in the base class.,4
[FLINK-8354] Fix formatting in FlinkKafkaConsumerBase,2
"[FLINK-8354] Add KafkaDeserializationSchema that uses ConsumerRecordWe now directly use the ConsumerRecord from the Kafka API instead oftrying to forward what we need to the deserialization schema ourselves.This makes it more future-proof, if Kafka adds new fields to theConsumerRecord.The previously used KeyedDeserializationSchema now extendsKafkaDeserializationSchema and has a default method to bridge theinterface. This way existing uses of KeyedDeserializationSchema stillwork.",1
[FLINK-8354] Update Kafka doc for new KafkaDeserializationSchema,1
[FLINK-10569][runtime] Remove Instance usage in ExecutionVertexDeploymentTest,3
[FLINK-10569][runtime] Remove Instance usage in ExecutionVertexCancelTest,3
[FLINK-11656][hadoop] Remove redundant test path in WordCountMapredITCase,2
[FLINK-11657][hadoop] Remove redundant test path in WordCountMapreduceITCase,3
[hotfix][docs] Fix example code of readSequenceFile in dev/batch/index.html.mdThis closes #7806.,2
[FLINK-11704][tests] Improve AbstractCheckpointStateOutputStreamTestBase by using JUnit's ParameterizedThis closes #7784.,2
[FLINK-11541] Run submitTask call in future executorThis closes #7768.,1
[FLINK-9964][table] Add an initial CSV table format factoryThis closes #6541.,5
"[FLINK-9964][table] Add a full CSV table format factoryIt adds CsvRowSerializationSchema, CsvRowDeserializationSchema, a new CSV descriptor,CsvRowTableFormatFactory, documentation and testsThe format integrates nicely with most SQL types.It deprecates the ""old CSV"" descriptor stack and prepares also for FLINK-7050 (#4660).The old CSV descriptor is still available under as ""OldCsv"".This closes #7777.",2
[FLINK-11716] Add new config option for TaskManager automatic address binding[FLINK-11716] Add unit test to new config option[FLINK-11716] TaskManager: introduce new (default) automatic ip address bindingThis closes #7795.,1
[FLINK-10043] [State Backends] Refactor RocksDBKeyedStateBackend object construction/initialization/restore codeThis closes #7674.,5
[FLINK-11618][state] Refactor operator state repartition mechanismThis closes #7711.,1
[hotfix] Fix update_branch_version.sh to allow version suffixesThis is needed because the shaded hadoop uber jar now has the hadoopversion as a suffix to the flink version.,2
Update version to 1.9-SNAPSHOT,5
[hotfix][table] Remove unused geometry dependency,1
"[FLINK-11679][table] Create Blink SQL planner and runtime modulesThis commit adds flink-table-planner-blink and flink-table-runtime-blinkmodules. Those modules are work-in-progress and are not connected to theAPI yet. This happens at a later stage (see FLINK-11452). We aim to makethe runtime module Scala-free.Initial dependencies have been added. Optimization with Calcite, codegeneration, and translation to operators are performed in the plannermodule.Actual execution classes and code compilation are performed in the runtimemodule.This closes #7790.",1
"[hotfix] Repair ineffective LocalRecoveryITCaseThe test did not actually run since the class was refactored with JUnit's parameterized, because it was always running into a NPE and the NPE was then silently swallowed in a shutdown catch-block.",1
"[FLINK-7243][connector] Add ParquetInputFormats for Row, Map, and POJO.This closes #6483.",1
[FLINK-11343][tests] Force order that TaskExecutor shutdown after Task exit in TaskExecutorTest,3
[FLINK-11745][State TTL][E2E] Restore from the savepoint after the job cancellation.This closes #7824.,2
[hotfix] fix typos in description,2
[FLINK-11744][core]Provide stable/final toHexString-method in AbstractIDThis closes #7825.,2
[hotfix] Revert overriding toString-method in AllocationID,4
"[FLINK-11185] Fix StreamSourceOperatorWatermarksTest instability.The cause of the instability seems to be that due to a not-so-rare timing,the thread that calls the `interrupt()` on the main thread, runs stillafter its original test finishes and calls `interrupt()` during executionof the next test. This causes the normal execution (or `sleep()` in this case)to be interrupted.This closes #7842.",1
[FLINK-11728] [table] Deprecate CalciteConfig temporarilyThis closes #7840,5
[hotfix] Minor code cleanups in RocksDBKeyedStateBackendBuilder and RocksDBIncrementalRestoreOperation,5
[FLINK-11743] Fix problem with restoring incremental checkpoints from local stateThis corrects a problem that was introduced with the refactorings in FLINK-10043.This closes #7841.,2
[hotfix] Introduce common interface to all IncrementalKeyedStateHandles,0
[FLINK-10912][rocksdb] Configurable RocksDBStateBackend optionsThis closes #7586.,5
[hotfix] Allow leader assignment to TestingLeaderElectionService if it has not been started,3
"[FLINK-11718][rpc] Add onStart method to RpcEndpointAdd a dedicated onStart method to the RpcEndpoint which is called when the RpcEndpointis started via the start() method. Due to this change it is no longer necessary for theuser to override the start() method which is error prone because it always requires tocall super.start(). Now this contract is explicitly enforced. Moreover, it allows toexecute the setup logic in the RpcEndpoint's main thread.",2
[hotfix] Factor logic out of AkkaRpcActor#handleRpcInvocation to reduce size of method,0
[FLINK-11718] Add onStart to Dispatcher,1
[FLINK-11718] Remove start override from JobMaster,4
[FLINK-11718] Add onStart method to ResourceManager,1
[FLINK-11718] Add onStart method to TaskExecutor,1
[FLINK-11718] Make RpcEndpoint#start method final to prevent changing its behaviourThis closes #7808.,4
[hotfix] Fix checkstyle violations in CheckpointCoordinator,0
[FLINK-11752] [dist] Move flink-python to opt (#7843)* [FLINK-11752] [dist] Move flink-python to opt* [FLINK-11752] [dist] Point pyflink scripts to opt,2
[hotfix][runtime] Remove try-catch blocks,1
[FLINK-10569][runtime] Port CoLocationConstraintTest,3
[FLINK-11091][table] Clear the use of deprecated `process(ProcessFunction)` of KeyedStream in table operators.This closes #7837,1
Fix typo in TypeInformation,5
Fix typo in StreamExecutionEnvironment (#7854),2
[hotfix][docs] Add that LIMIT requires ORDER BY.This closes #7737,1
[hotfix][tests] Harden DispatcherTest#testJobSubmissionErrorAfterJobRecoveryWait until the Dispatcher has been started before adding new JobGraphs to the SubmittedJobGraphStore,1
[FLINK-11777][docs] Remove and update useless html anchor in hadoop_compatibility.md.This closes #7802,1
[FLINK-11714][table-planner-blink] Add cost model for both batch and streamingThis closes #7836,1
[FLINK-11702][table-planner-blink] Introduce a new blink table type system: InternalType.This closes #7817.,5
"[FLINK-11449][table-common] Introduce a new expression stack and visitor interfaceThis commit adds a new expression stack that is:- located in flink-table-common- implemented in Java- decoupled from Calcite and other planner specifics- reduced to a minimum/basic set of functionalityFor now, conflicting class names are prefixes with ""Common"". Classes suchas ""CommonExpression"" will become ""Expression"" for backwards-compatibilityin later commits.",0
"[FLINK-11740] [core] Clarify CompositeTypeSerializerSnapshot class signaturePrior to this commit, the CompositeTypeSerializerSnapshot classsignature was a bit confusing and contained raw types. Moreover, itrequired subclasses to always erase types and re-cast.This closes #7818.",1
[hotfix] [core] Fix TypeSerializerUtils#snapshotBackwardsCompatible method signature,0
"[FLINK-11772] [DataStream] Remove ""config"" from all serializer snapshot field / method names in InternalTimersSnapshotThis renaming corresponds to the fact that TypeSerializerConfigSnapshotis now deprecated, and is fully replaced by TypeSerializerSnapshot.",5
"[FLINK-11772] [DataStream] Let InternalTimerServiceImpl use new serialization compatibility APIs for key / namespace serializer checksThis commit lets the InternalTimerServiceImpl properly useTypeSerializerSchemaCompatibility /TypeSerializerSnapshot#resolveSchemaCompatibility when attempting tocheck the compatibility of new key and namespace serializers.This also fixes the fact that this check was previously broken, in thatthe key / namespace serializer was not reassigned to be reconfiguredones.",5
"[FLINK-11772] [DataStream] InternalTimerServiceSerializationProxy should not be serializing timers' key / namespace serializers anymoreAll of the changes done to managed state surrounding how we no longerJava-serialize serializers anymore, and only write the serializersnapshot, was not reflected to how we snapshot timers. This was mainlydue to the fact that timers were not handled by state backends (and weretherefore not managed state) in the past, and were handled in anisolated manner by the InternalTimerServiceSerializationProxy.This closes #7849.",0
[FLINK-11741] [core] Add getNestedSerializerSnapshots utility method in CompositeTypeSerializerConfigSnapshotWe often want to get only the restored serializer snapshots from alegacy CompostieTypeSerializerConfigSnapshot when attempting to redirectcompatibility checks to new snapshots. This commit adds agetNestedSerializerSnapshots utility method for that purpose.,1
[FLINK-11741] [runtime] Replace ArrayListSerializer's ensureCompatibility method with SelfResolvingTypeSerializer implementation,1
"[FLINK-11741] [core] Remove CompositeSerializer's ensureCompatibility method using SelfResolvingTypeSerializer interfaceOnly the TtlSerializer needs to implement theSelfResolvingTypeSerializer interface, because all other subclasses ofCompositeSerializer are test serializers.",3
"[FLINK-11741] [core] Remove Scala EitherSerializer's ensureCompatibility method using LegacySerializerSnapshotTransformer interfaceThe Scala EitherSerializer requires using theLegacySerializerSnapshotTransformer in order to remove theensureCompatibility method because in 1.6, the serializer was returningJava's EitherSerializerConfigSnapshot, which has different generic typesthan the expected ScalaEitherSerializerSnapshot.",5
"[FLINK-11741] [table] Remove table dataview serializers' ensureCompatibility method using LegacySerializerSnapshotTransformer interfaceFor the Table dataview serializers (i.e. ListViewSerializer andMapViewSerializer) we need to use theLegacySerializerSnapshotTransformer interface because these serializerswere incorrectly returning the snapshot of their nested serializer in1.6, likewise to what the LockableTypeSerializer was incorrectly doingalso in 1.6.",1
[FLINK-11741] [runtime] WritableSerializer's ensureCompatibility method should have been removed,4
[FLINK-11741] Remove ensureCompatibility implementation from dummy serializers,4
"[FLINK-11741] [tests] Remove ensureCompatibility implementation in all test-related serializersThis also fixes the snapshotConfiguration method of some test-relatedserializers, to return a proper snapshot of itself.",3
"[FLINK-11755] [tests] Remove TypeSerializerSnapshotTest#testBridgeCompatibilityCheck testThis test essentially tests that when a legacyTypeSerializerConfigSnapshot is restored, the compatibility check goesthrough the new serializer's `ensureCompatibility` method. Since we'renow removing the `ensureCompatibility` method from the TypeSerializerabstraction, this test is no longer relevant.",3
[FLINK-11741] [core] Remove TypeSerializerSingleton's ensureCompatibility implementation,4
"[FLINK-11741] [cep] Migrate legacy NFA serializers to use new serialization compatibility abstractionsAlthough these serializers were used for state that are no longer accessednow, they will still be snapshotted as part of the CEP state's metainfo, since they still are registered. This commit updates them to usethe new serialization compatibility abstractions, so that theserializers are no longer Java-serialized.",1
"[FLINK-11755] [core] Remove no longer used CompatibilityUtil classThe CompatibilityUtil class is no longer used after the series ofchanges for FLINK-11755 and FLINK-11741. This corresponds to the factthat ensureCompatibility is about to be removed from TypeSerializer, andtherefore no serializers should still require this util to convertTypeSerializerSchemaCompatibility to CompatibilityResult.",1
"[FLINK-11755] [core] Drop ensureCompatibility from TypeSerializerIf users are still using the TypeSerializerConfigSnapshot when upgradingto 1.8, they have to do the following:- Change the type serializer's config snapshot to implement  TypeSerializerSnapshot, rather than extending  TypeSerializerConfigSnapshot (as previously).- If the above step was completed, then the upgrade is done.- Otherwise, if changing to implement TypeSerializerSnapshot directly  in-place as the same class isn't possible (perhaps because the new  snapshot is intended to have completely different written contents or  intended to have a different class name),  retain the old serializer snapshot class (extending  TypeSerializerConfigSnapshot) under the same name and give the updated  serializer snapshot class (the one extending TypeSerializerSnapshot)  a new name.- Override the  TypeSerializerConfigSnapshot#resolveSchemaCompatibility(TypeSerializer)  method to perform the compatibility check based on configuration  written by the old serializer snapshot class.This closes #7821.",5
[FLINK-11755] [core] Drop no longer used class CompatibilityResult,1
[FLINK-11755] [core] Removed no longer used class TypeDeserializer,1
[FLINK-11406] [core] Return INCOMPATIBLE when nested serializers arity don't match in CompositeTypeSerializerSnapshotThis closes #7557.,2
[FLINK-11753] [tests] Add hamcrest matchers for TypeSerializerSchemaCompatibility,1
[FLINK-11753] [tests] Refactor SchemaCompatibilityTestingSerializerThis closes #7845.,3
[FLINK-11773] [core] Add LinkedOptionalMapSerializerThis adds a simplified serializer for LinkedOptionalMapsthat resiliently stores the keys and the values of the map.,2
[FLINK-11773] [core] Use LinkedOptionalMapSerializer in Kryo-/PojoSerializerSnapshotData,5
[FLINK-11773] [tests] Add unit tests for KryoSerializerSnapshotThis closes #7852.,3
"[FLINK-10342] [kafka] Filter restored partitions in FlinkKafkaConsumer with topics descriptorThis commit lets the FlinkKafkaConsumer filter out restoreed partition'soffsets that are no longer associated with the current list of specifictopics / topic pattern to subscribe to.This changes the previous default behaviour of the FlinkKafkaConsumer,which always respected the complete list of restored partitions,regardless of the specified topics to subscribe to.As a fallback, a setter configuration method is added to allow disablingthe filter behavior.",1
[FLINK-10342] [kafka] Improve Javadoc of new disableFilterRestoredPartitionsWithSubscribedTopics method in FlinkKafkaConsumerBaseThis closes #7726.,2
[hotfix] [tests]Fix typo in RollingSinkSecuredITCase.javaThis closes #7823.,2
[FLINK-11771] [core] Fix TypeSerializerSnapshot#readVersionedSnapshot for TypeSerializerSnapshots directly upgraded from TypeSerializerConfigSnapshot,5
[FLINK-10777] [tests] Update TypeSerializerSnapshotMigrationITCase to cover restoring from 1.7.x,5
[FLINK-10785] [tests] Upgrade FlinkKinesisConsumerMigrationTest to test restoring from 1.7.x,3
[FLINK-11449][table-planner] Represent built-in expressions as planner expressionsThis commit introduces `PlannerExpression extends Expression` and letsbuilt-in expressions extend it.,2
[hotfix][table-planner] Remove unnused Quarter case classThe API for this was already changed in FLINK-6846.,2
[FLINK-10881] Use cancelWithSavepoint in SavepointITCase test.This closes #7833.,3
[hotfix][docs] Fix missing joinLateral,0
[hotfix][docs] fix grammatical errors in descriptionThis closes #7863,0
[FLINK-11780] Change version scheme of Hadoop-based modules to conform to SNAPSHOT guidelinesThis also adadpts update_branch_version.sh to correctly update versionsthat have a prefix.,0
[hotfix][table-api] Discourage the usage of the Literal case class in API,0
"[FLINK-11785][table-api] Replace case class Null(type) by nullOf(type) expressionThis introduces `nullOf(type)` for representing typed nulls in Table API. It allowsto uncouple API from expression case classes and enables us to have `nullOf(type)` and`null` in the future, once we introduced a NULL type and proper type inference.Furthermore, it also integrates better in existing expressions that all startwith lower case characters.This closes #7864.",1
[hotfix][travis] Log commit ID ad cache directory,2
[FLINK-11379][core] Fix OutOfMemoryError caused by Files.readAllBytes() when TM loads a large size TDDThis closes #7797,2
"[FLINK-11724][core] Add copyToUnsafe, copyFromUnsafe and equalTo to MemorySegment.This closes #7847",1
[FLINK-11715][table-planner-blink] Add optimize program to organize optimization phases.This closes #7834,1
"[FLINK-10585][tests, ssl] Re-create testing keystore and truststoreCreate new key so that IPv6 loopback address is included in subject alternativenames section. Used the commands below to re-create the stores:keytool -genkeypair -alias flink.test -keystore test.keystore -keyalg RSA \-keysize 4096 -storetype PKCS12 -ext ""SAN=dns:localhost,ip:127.0.0.1,ip:::1"" \-dname ""CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown"" \-storepass passwordkeytool -exportcert -keystore test.keystore -alias flink.test -file test.cer \-storepass passwordkeytool -importcert -keystore test.truststore -alias ca -storepass password \-file test.cer --noprompt",3
"[FLINK-10585][tests] Explicitly bind testing RestServerEndpoint on loopback addressIf we do not bind on a loopback address, the wildcard address will be chosen.The downside of that is it can happen that the server will be only available viaeither IPv4 or IPv6 (but not both). This can happen, for example, if anotherapplication chose to bind on the same (random) port but only using the IPv4stack. In this case, the bind operation in the RestServerEndpoint will onlysucceed for IPv6 and silently fail for IPv4.",0
"[FLINK-10585][runtime] Use java.net.URL to build restBaseUrlIn URLs, IPv6 addresses have to be put inside ""["" and ""]"", which is handled bythe URL class.",0
[FLINK-10585][tests] Extract method getTestResource in RestServerEndpointITCaseThis closes #7839.,1
[FLINK-11533] [container] Add JarManifestParser[pr-review] Extend TestLogger in JarManifestParserTest[pr-review] Mark TemporaryFolder field final in JarManifestParserTest[pr-review] Improve Javadocs for TestJob.getTestJobJar[pr-review] Add JarManifestParser.findOnlyEntryClass(Iterable)[pr-review] Reduce visibility of helper[pr-review] Mark helper with @VisibleForTesting[pr-review] Remove remove-external-test-classes stage[pr-review] Address comments,1
[FLINK-11533] [container] Throw FlinkParseException in ParserResultFactory,2
[FLINK-11533] [container] Make jobClassName argument optional[pr-review] Address comments,1
[FLINK-11533] [container] Find job jar on classpath[pr-review] Address comments,1
[FLINK-11533] [container] Update kubernetes/README.md[pr-review] Fix typo[pr-review] Fix grammer,0
[hotfix][table-api] Uncouple case classes from math expressions,0
[hotfix][table-api] Introduce an alternative for if-then-else in prefix notationThis commit uncouples prefix if-then-else expressions from the `If` caseclass. The offically documented way is still using the `?` teneraryoperator. But this commit adds a nice alternative that is available inthe Scala DSL.,1
[hotfix][table-api] Uncouple case classes from other API tests,3
[hotfix][table-api] Relocate and document Over window offsets,1
[FLINK-9003][hotfix] Code cleanup.,4
"[FLINK-9003][E2E] Add operators with input going through custom, stateful serialization.This closes #7846.",1
[FLINK-11449][table-planner] Add a converter for PlannerExpressionsThis commit adds a converter for converting from the new expressionstack to the old expression stack which is extending PlannerExpression.,1
[FLINK-11701][table-runtime-blink] Introduce an abstract set of data formatsThis closes #7816,5
[FLINK-11617] [kinesis] Kinesis consumer getRecords() failure logging is misleading (#7706),2
[FLINK-11501] [kafka] Add ratelimiting to Kafka consumer (#7679),1
[FLINK-11790][table-planner-blink] Introduce FlinkRelNode interface and FlinkConventionsThis closes #7878,2
[FLINK-11795][table-planner-blink] Introduce DataStream nodes and converter rules for batch and streamThis closes #7881,5
[FLINK-11516][table-common] Port and move catalog transitive classes to flink-table-commonThis closes #7642.,2
Merge pull request #7879 from aljoscha/build-with-hadoop-guide[FLINK-11791] Describe how to build Flink with Hadoop in build guide,2
[FLINK-11802][table-runtime-blink] Create TypeInfo and TypeSerializer for blink data formatThis closes #7887,5
[hotfix] Fix typo in some API comments (#7867)* Fix typos in DataStream* merge other fixes into one PR,0
[FLINK-11653][DataStream] Add configuration to enforce custom UIDs on datastream,5
[FLINK-11801] [table-api] Port SqlParserException to flink-table-api-javaThis closes #7888,2
Update ops/upgrading.md for Flink 1.8,2
"[hotfix][core] Fix Tuple0Serializer handling of nullTuple0Serializer serialized null as just a proper Tuple0 instance, which if later deserialized resulted in a regular value rather than null. This commit changes it so that it is no longer possible to serialize null with Tuple0Serializer.",4
[hotfix][core] Added snapshot for TestListCompositeSerializer,3
[hotfix][core] Added snapshot for NothingSerializerSnapshot,1
[hotfix][core] Comparing whole collections rather than contents in KryoGenericTypeSerializerTest,3
[hotfix][tests] Call all methods from SerializerTestBase in SerializerTestInstance by reflection,3
[FLINK-11420][core] Fixed duplicate method of TraversableSerializerThe duplicate method of TypeSerializer used an equality check ratherthan reference check of the element serializer to decide if we need adeep copy. This commit uses proper reference comparison.,1
"[hotfix][tests] Added matcher that performs deep comparison with taking Tuples into accountThis commit introduced a matcher that performs a deepEquals comparisonsimilarly to Objects#deepEquals. The only difference is that it alsoperforms deep equality check for some flink specific classes such ase.g. Tuples, Rows.",2
"[FLINK-11804] [State Backends] Make sure the CloseableRegistry used in backend builder is registered with taskWe need to make sure each stream constructed in restore could also be closed in case of task cancel,for example the data input stream opened for serDe during restore.Also removed close of CloseableRegistry in RocksDBKeyedStateBackendBuilder.",5
[FLINK-11730] [State Backends] Make HeapKeyedStateBackend follow the builder patternThis closes #7866.,1
[hotfix][table-api] Remove deprecated table function codeThis commit removes the table constructor (deprecated inFLINK-11447) for lateral table function joins and simplifiesrelated code.,1
[hotfix][table-api] Remove deprecated table function code in insertInto,1
[hotfix][table-api] Add docs to over-windowed table's select(),2
"Fix create_release_branch.sh to accomodate Hadoop VersionsBefore, this would not correctly change version tags that have a versionprefix or suffix, like the shaded Hadoop modules.",0
"Fix version change expressions in releasing scriptsThe earlier version had ""\1${NEW_VERSION}"" in there, which would resolveto ""\11.8."", i.e. the backreference would now be \11.",0
[FLINK-11803][table-planner-blink] Improve FlinkTypeFactory for Blink (#7898),2
[FLINK-11731] [State Backends] Make DefaultOperatorStateBackend follow the builder patternThis closes #7899.,1
[FLINK-11796] [State Backends] Remove Snapshotable interface,4
[hotfix] Fix checkstyle violations in ZooKeeperHaServices,0
[hotfix] Fix checkstyle violations in ZooKeeperUtils,0
[hotfix] Fix checkstyle violations in ZooKeeperLeaderRetrievalTest,3
[hotfix][tests] Speed up ZooKeeperLeaderRetrievalTest#testTimeoutOfFindConnectingAddressDecrease the timeout from 10s to 1s in testTimeoutOfFindConnectingAddress to speed up the test.,3
"[FLINK-11336][zk] Delete ZNodes when ZooKeeperHaServices#closeAndCleanupAllDataWhen calling ZooKeeperHaServices#closeAndCleanupAllData we should delete theHA_CLUSTER_ID znode which is owned by the respective ZooKeeperHaServices.Moreover, the method tries to go up the chain of parent znodes and tries todelete all empty parent nodes. This should clean up otherwisely orphanedparent znodes.This closes #7880.",4
[FLINK-11826] Ignore flaky testRateLimitedConsumer,3
[FLINK-11827][table-runtime-blink] Introduce DataFormatConverters to convert between internal data format and java formatThis closes #7904,5
[hotfix][runtime] Remove unused local variable in ExecutionGraph,1
"[FLINK-11781][yarn] Remove ""DISABLED"" as possible value for yarn.per-job-cluster.include-user-jarRemove this feature because it is broken since Flink 1.5This closes #7883.",2
[FLINK-11833] [State Backends] Cleanup unnecessary createKeyedStateBackend methods in StateBackendThis closes #7909.,1
[FLINK-11830][table-planner-blink] Introduce CodeGeneratorContext to maintain reusable statementsThis closes #7906,2
[FLINK-11751] Extend release notes for Flink 1.8,2
[FLINK-11836] Sort concatenated NOTICE files for NOTICE-binaryThis will make for less changes in the future because the order in theNOTICE-binary file is deterministic.,5
[FLINK-11821] Fix package declaration and location of internal Kafka schema wrappers,0
[hotfix][flink-core] fix errors in MemorySegment descriptionThis closes #7916.,0
[FLINK-11829][checkpoint] Avoid FsCheckpointStateOutputStream to store state in files when size below fileStateThresholdThis closes #7907.,2
[hotfix][statebackend] Reduce and simplify code for column creation in RocksDB backendThis closes #7830.,5
"[FLINK-11834] [table-planner-blink] Introduce flink logical relational nodes (#7910)* [FLINK-11834] [table-planner-blink] Introduce flink logical relational nodesThis commit includes most flink logical relational nodes, the rest will be introduced by other commit.* add FlinkLogicalTableFunctionScan* add FlinkLogicalTableSourceScan* move RankRange into Rank.scala file",2
[FLINK-11542][config][docs] Extend memory configuration descriptions,5
[hotfix][docs] Fix the mismatch generic type in hadoop compatibility doc,2
"[FLINK-11826][tests] Harden Kafka09ITCase#testRateLimitedConsumerKafka tests seem to have the problem that writing to a newly created topiccan fail. In order to harden the test against this problem, we set thenumber of Kafka retries to 3.This closes #7900.",1
[FLINK-11687] Code clean for streamJobGraphGenerator.,4
[FLINK-11846] Don't delete HA job files in case of duplicate job submissionThis commit changes the cleanup logic of the Dispatcher to only clean up job HA filesif the job is not a duplicate (meaning that it is either running or has already beenexecuted by the same JobMaster).This closes #7918.,1
"[FLINK-11851] Introduce dedicated io executor for ClusterEntrypoint and MiniClusterThe io executor is responsible for running io operations like discarding checkpoints.By using the io executor, we don't risk that the RpcService is blocked by blockingio operations.This closes #7924.",1
"[FLINK-11850][zk] Tolerate concurrent child deletions when deleting owned zNodeWhen calling ZooKeeperHaServices#closeAndCleanupAllData it can happen that a child of the ownedzNode of the ZooKeeperHaServices is being concurrently deleted (e.g. a LeaderElectionService hasbeen shut down). In order to tolerate concurrent deletions, we use now ZKPaths#deleteChildren.This closes #7928.",4
[FLINK-11703][table-planner-blink] Introduce TableEnvironments and support registerDataStream and sqlQueryThis closes #7923,5
[FLINK-11837][table-runtime-blink] Improve blink internal data foramtThis closes #7913,5
[FLINK-11858][table-runtime-blink] Introduce block compression to batch table runtime.This closes #7941,1
[FLINK-11863][table-runtime-blink] Introduce channel to read and write compressed data (#7944),5
[FLINK-11857][table-runtime-blink] Introduce BinaryExternalSorter and BufferedKVExternalSorter to batch table runtime (#7945),1
[FLINK-11844][table-api] Simplify over window API classes and improve documentationThis closes #7920.,2
[FLINK-11854][table-planner-blink] Introduce batch physical nodes (#7931),2
[hotfix][table-api] Update wrong null literal hint,0
[FLINK-11867][datastream] Fixed preconditions for filePath's value,2
"[hotfix][test] Use ScalaCaseClassSerializerTest specific case classPreviously the ScalaCaseClassSerializerTest reused class defined in other test, even though it defined a separate one. Also extended the class so that it uses GenericSerializer.",1
[FLINK-11420][datastream] Fix duplicate and createInstance methods of CoGroupedStreams.UnionSerializerUnionSerializer did not perform a proper duplication of inner serializers. It also violated the assumption that createInstance never produces null.,1
[FLINK-11861][tests] Fix JobMasterTriggerSavepointIT not executedThis closes #7943.,0
[FLINK-11856][table-runtime-blink] Introduce BinaryHashTable to batch table runtime. (#7949),1
"[FLINK-11646][test] Remove not used MockRecordWriter (#7730)MockRecordWriter is not used any more, so remove it to make code clean.",4
[FLINK-11865] Extract compileCbf from TraversableSerializer,4
[FLINK-11865] Cache compiled CanBuildFrom values in TraversableSerializer,2
[hotfix][table] Fix Scala package object,0
"[FLINK-11449][table] Uncouple table expressions from CalciteThis commit uncouples table expressions from Calcite by switchingthe API to a new, simplified basic expression stack.Major changes:- Rename CommonExpression to Expression- Rework the function catalog to work with the newly introduced function definitions- Rework the Scala implicits and Java expression parser to return the new expression stack- Introduce an expression bridge on the edges of the API to convert to the old expression stack as a temporary solution until the old expression stack becomes obsolete- Cleanup of main API interfaces (i.e. Table.scala and expressionDsl.scala)- Ensure that SPI classes such as FilterableTableSource and TimestampExtractor still workThis closes #7664.This closes #7967.",1
[hotfix] [core] Avoid array copying in LinkedOptionalMapSerializer,2
[FLINK-10756][runtime][tests] Wait for TM processes to shutdown,3
[FLINK-11886][docs] Update CLI output,5
[FLINK-11866][py][docs] Fix method name,0
[FLINK-11892] [docs] Refine README of end-to-end tests to make it more clearThis closes #7972,1
[FLINK-11901][build] Add script for updating NOTICE year,5
[FLINK-11901][build] Update NOTICE files with year 2019This closes #7975.,2
[FLINK-11237][sql-client] Enhance LocalExecutor to wrap TableEnvironment w/ user classloaderUse the context classloader for all interactions with TableEnvironment.This closes #7389.,1
[hotfix][tests] Improve error message in GenericTypeInfoTest,5
[FLINK-11183][metrics] Move memory metrics creation into separate method,1
[FLINK-11183][metrics] Properly measure current memory usage,2
"[hotfix][rest] Remove ""Impl. error"" from log messageOriginal intent was to never reach this code path except on programmer errors, but it has turned into an accepted code path for unhandled exceptions.",0
[FLINK-11902][rest] Do not wrap all exceptions in RestHandlerException,0
[FLINK-11845][runtime] Drop legacy InfoMessage,5
[FLINK-11874][checkpoint] Split CheckpointStorage interface to distinguish JM and TM sideThis closes #7970.,2
[FLINK-11904][tests]Improve MemoryStateBackendTest by using JUnit's ParameterizedThis closes #7984.,2
[FLINK-11903][tests] Improve FileStateBackendTest by using JUnit's parameterizedThis closes #7973.,2
[FLINK-10076][table-planner] Upgrade Calcite dependency to 1.18This closes #7607.,2
[FLINK-10076][table-planner-blink] Upgrade Calcite dependency to 1.18,2
[FLINK-11881][table-planner-blink] Introduce code generated typed sorter to blink table (#7958),2
[FLINK-11905][table-runtime-blink] Fix BlockCompressionTest does not compile with Java 9 (#7981),3
[FLINK-11882][table-runtime-blink] Introduce BytesHashMap to batch hash agg (#7961),2
[FLINK-11918][table] Deprecated some Window APIs and Rename Window to GroupWindowThis closes #7985,2
"[FLINK-11788][table-planner-blink] Support Code Generation for RexNode1. Introduce ExprCodeGenerator to generate code for RexNodes2. Introduce SqlOperatorGens to generate code for SQL scalar operators3. Introduce GenerateUtils to generate code for general purpose, e.g. generateLiteral, generateFieldAccessThis closes #7982",1
[FLINK-11896] [table-planner-blink] Introduce stream physical nodes (#7969),2
"[hotfix][runtime,test] Deduplicate the common codes in RecordWriterTest (#7989)Extract a common method in tests for easy reuse and maintenance",1
[FLINK-9007] [kinesis] [e2e] Add Kinesis end-to-end test,3
[hotfix] [FLINK-9007] [kinesis] [e2e] Disable record aggregation,2
[FLINK-11932][table-planner-blink] Add support for generating optimized logical plan for 'select * from mytable' (#7993),2
[FLINK-11950][dist]Add missing dependencies in NOTICE file of flink-dist.This closes #8004,2
[FLINK-11908][table] Port window classes into flink-table-api-javaThis closes #7976.,2
[FLINK-9007] [kinesis] [e2e] Build Kinesis test under include-kinesis profile,2
"[hotfix] Remove rocksdbjni from flink-dist NOTICEWe currently use frocksdbjni, so rocksdbjni is not used anymore.",1
[FLINK-10755][table] Port external catalogs in Table API extension points to flink-table-commonThis closes #7848.,2
[FLINK-11871][table-runtime-blink] Introduce LongHybridHashTable to improve performance when join key fits in longThis closes #7996,1
[FLINK-11068][table] Convert the API classes of *Table to interfacesThis closes #8006,2
[FLINK-11946][table-planner-blink] Introduce ExecNode to blink planner (#8010),2
"[FLINK-11966][table-planner-blink] Add support for generating optimized logical plan for simple query(Project, Filter, Values and Union all) (#8009)",2
[FLINK-11949][table-planner-blink] Introduce DeclarativeAggregateFunction and AggsHandlerCodeGenerator to blink planner (#8001),2
[FLINK-11817][docs] Replace fold example in DataStream API Tutorial,5
[FLINK-11692][metrics] Add proxy support to datadog reporter,5
[hotfix][runtime] Delete unused methods from ExecutionGraphDelete methods:  - getRequiredClasspaths()  - getRequiredJarFiles(),2
[hotfix][runtime] Delete unused interface ExecutionStatusListenerThis closes #7977.,1
[hotfix] Fix inactive branch in TtlStateTestBase,3
"[FLINK-11980] Improve efficiency of iterating KeySelectionListener on notificationKeySelectionListener was introduced for incremental TTL state cleanup as a driver of the cleanup process. Listeners are notified whenever the current key in the backend is set (i.e. for every event). The current implementation of the collection that holds the listener is a HashSet, iterated via forEach on each key change. This method comes with the overhead of creating temporaray objects, e.g. iterators, on every invocation and even if there is no listener registered. We should rather use an ArrayList with for-loop iteration in this hot code path to i) minimize overhead and ii) minimize costs for the very likely case that there is no listener at all.This closes #8020.",5
[hotfix] Remove unused method in AbstractKeyedStateBackend,1
Minor example typo fix,0
"[FLINK-11825][StateBackends] Resolve name class of StateTTL TimeCharacteristic class.We can not remove the class StateTtlConfig#TimeCharacteristic and use org.apache.flink.streaming.api.TimeCharacteristic directly,because StateTtlConfig locates in module flink-core and org.apache.flink.streaming.api.TimeCharacteristic locates in flink-streaming-java,so we choice to rename StateTtlConfig#TimeCharacteristic.changes include:- Deprecated the StateTtlConfig#TimeCharacteristic class (for backward-compatibility).- Introduce a new class named StateTtlConfig#TtlTimeCharacteristic.",5
[hotfix][table] Move UnresolvedCallExpression & TableReferenceExpression to table-api-java module,0
[hotfix][table] Removed unnecessary casts in ApiExpressionUtils,4
[hotfix][table] Introduced UnresolvedFieldReferenceExpression &FieldReferenceExpression expressions,0
[FLINK-11786][travis] Simplify stage selection,2
[FLINK-11786][travis] Run main profile only on pr/push,2
[FLINK-11786][travis] Setup notifications,1
[hotfix][e2e] Enable kinesis profile,2
"[FLINK-11971] Fix kubernetes check in end-to-end testBefore, this was using string parsing but the output of minikube statusdepends on the minikube version and the system.This now simply uses the status code.This closes #8024.",1
[FLINK-11872][table-runtime-blink] update lz4 license file. (#7952),2
[FLINK-11972] [docs] Add necessary notes about running streaming bucketing end-to-end test in READMEThis closes #8027.,3
[FLINK-11853][rest] Support POST for /job/:jobid/plan,1
[FLINK-11989][travis][jdk9] Remove metric reporter exclusions,4
[hotfix][streaming] Fix BucketStateSerializerTest on Windows,3
[FLINK-11721][network] Remove IOMode from NetworkEnvironment,1
[FLINK-11676][network] Make ResultPartitionWriter extend AutoCloseable,1
[hotfix][travis] Fix directory references,0
[hotfix][docs] Replace tabs in dependency templade with spacesThe tabs were wrecking the formatting.,2
[hotfix][travis] Activate hadoop profile via property,5
[hotfix][travis] Fix typo in hadoop property,5
[FLINK-11994] [table-planner-blink] Introduce TableImpl and remove Table in flink-table-planner-blinkThis closes #8032,2
[FLINK-11887][metrics] Fix latency drift,0
[FLINK-11885][network] Introduce RecordWriterBuilder for creating RecordWriter instance,1
[hotfix] Outdated comment in FileInputFormat.javaThis closes #7882,2
[FLINK-11988][network] Remove legacy MockNetworkEnvironment,1
[hotfix][travis] Fix e2e setup issues,0
[FLINK-11981][table-planner-blink] Introduce ProjectionCodeGenerator and HashCodeGenerator for BaseRow (#8019),2
[FLINK-11984][docs] MPU timeout implications on StreamingFileSink.,2
[FLINK-11907][types] Normalize String/BigInteger in GenericTypeInfoTest,5
[hotfix] Increase startup timeout in end-to-end testsWe've seen quite some flakyness in the end-to-end tests on Travislately. On most tests it takes about 5-8 secs for the dispatcher to comeup so 10 secs might be to low.,3
"[FLINK-12012] [tests] BroadcastStateITCase properly inherits from AbstractTestBaseThe test previously used the default local environment (and thus embedded mini cluster),where the parallelism depends on the number of CPU cores.That makes the network buffer consumption non-deterministic.The test now extends AbstractTestBase which uses a test environment withwell-defined parallelism and memory footprint.",3
[FLINK-11975][table-planner-blink] Support running a simple select from values query (#8035),1
[hotfix] Increase timeout on streaming file sink e2e testIt seems Travis is getting slower and slower.,1
[FLINK-11153][dataset] Remove UdfAnalyzer,4
[FLINK-11153][travis] Remove flink-java tests Java 9 exclusion,3
[FLINK-12001][tests] fix the external jar path config error for AvroExternalJarProgramITCase.This closes #8047,0
[FLINK-12007][scala][docs] Clarify 2.12 build instructions,2
[hotfix][table] Fix visitor for TypeLiteralExpression,0
[hotfix][table] Changed ApiExpressionVisitor to abstract class,4
[FLINK-11707][network] InputGate extends AutoCloseable,2
[hotfix] Implement NoOpTaskActions to avoid mock in tests,3
[hotfix][table] Extracted UnresolvedCallResolver to table-java-api module,0
[hotfix][table] Rename UnresolvedCallExpression to LookupCallExpression,0
"[FLINK-11884][table] Ported splitting expressions into aggregates, projections, window properties and fieldReferences into Java",2
[FLINK-11884][table] Extract logic of creating LogicalNodes fromTableImpl,2
[FLINK-11146][clients] Remove legacy code code in ClusterClient,4
[FLINK-11996][scala][docs] Remove warning about max fields in case class,2
[FLINK-12055][clients] Remove legacy ActorSystemLoader,5
[FLINK-12013][table-planner-blink] Support calc and correlate in blink planner (#8056),2
[hotfix][docs] Fixed typo in docs tag,2
[FLINK-11723][network] Remove KvState related components from NetworkEnvironment,1
[FLINK-11855] Fix race condition in EmbeddedLeaderService#GrantLeadershipCallFix the race condition between executing EmbeddedLeaderService#GrantLeadershipCalland a concurrent shutdown of the leader service by making GrantLeadershipCall notaccessing mutable state outside of a lock.This closes #7935.,1
[hotfix] Fix checkstyle violations in ExecutionGraphDeploymentTest,3
"[FLINK-12021] Deploy execution in topological sorted orderDue to changes how the slot futures are completed and due to the fact that theResultConjunctFuture does not maintain the order in which the futures were specified,it could happen that executions were not deployed in topological order. This commitfixes this problem by changing the ResultConjunctFuture so that it maintains the orderof the specified futures in its result collection.This closes #8060.",4
"[FLINK-12006][tests] Wait for Curator background operation finishedIn order to wait for the NodeCache's background operation which generates theparent zNodes for the ZooKeeperLeaderRetrievalService, we wait for a new leaderin the ZooKeeperHaServicesTest.This closes #8046.",3
[FLINK-12057] Refactor MemoryLogger to accept termination future instead of ActorSystem,5
[FLINK-12051][runtime][tests] Wait for TaskExecutor to be started,3
[hotfix][network] Remove unused IOMode from NetworkEnvironmentConfiguration,5
[FLINK-11898] [table-planner-blink] Support code generation for all Blink built-in functions and operatorsThis closes #8029,1
[FLINK-11959][table-runtime-blink] Introduce window operator for blink streaming runtimeThis closes #8058.,1
"[FLINK-12015] Fix TaskManagerRunnerTest instabilityBefore, the was a race condition between the termination future inTaskManagerRunner completing and the asynchronous shutdown part here:https://github.com/apache/flink/blob/70107c4647ecac3df9b2b8c7920e7cb99ad550f1/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java#L258The test would go out of the block that was waiting on the future butthe shutdown code that is executed after the future completes isexecuted asynchronously, so is not guaranteed to have run at that point.This also refactors the code a bit to make it more obvious what ishappening and removes the SecurityManagerContext because it wasobscuring the problem.This was analyzed by Igal and me, and mostly fixed by Igal.",0
"[FLINK-12064] [core, State Backends] RocksDBKeyedStateBackend snapshots uses incorrect key serializer if reconfigure happens during restoreThis closes #8076.",5
[FLINK-12073][table-planner-blink] Support appropriate precision and scale processing of Decimal (#8088),1
[FLINK-12018][table-planner-blink] Add support for generating optimized logical plan for Sort and RankThis closes #8051,2
"[FLINK-12028][table] Add `addColumns`,`renameColumns`, `dropColumns` support.This closes #8057.",1
[FLINK-12079][table-planner-blink] Add support for generating optimized logical plan for join on batchThis closes #8094,2
[FLINK-12077][table-runtime-blink] Introduce HashJoinOperator and LongHashJoinGenerator to blink runtime (#8093),1
[FLINK-12056][coordination] Remove legacy methods in LeaderRetrievalUtils,4
"[FLINK-12076] [table-planner-blink] Add support for generating optimized logical plan for simple group aggregate on batch (#8092)* [FLINK-12076] [table-planner-blink] Add support for generating optimized logical plan for batch simple group aggregate* fix checkstyle error* remove Ignore from SingleRowJoinTest, and update based on comments* fix checkstyle error",0
[FLINK-12020] [docs] Add documentation for mesos-appmaster-job.sh1. Rename the section title from `standalone` to `Flink session cluster on Mesos`.2. Add one new section `Flink job cluster on Mesos` which describes the usage of mesos-appmaster-job.sh.This closes #8084.,2
"[FLINK-12014][Doc]Flink CEP Doc missing ""SkipToNextStrategy""",2
"[hotfix][runtime, docs] Fixed typo in SingleInputGate",2
[FLINK-12075] Update flink-conf.yaml to not specify rest.port per defaultThis commits updates the flink-conf.yaml to contain the new rest options and commentsout the rest.port per default.,1
[FLINK-12075] Update RestOptions#PORT descriptionThis commit updates the description of RestOPtions#PORT to better reflect howit is used.,1
"[FLINK-12075][yarn] Set RestOptions.BIND_PORT only to 0 if not specifiedThis commit changes the YarnEntrypointUtils#loadConfiguration so that it onlysets RestOptions.BIND_PORT to 0 if it has not been specified. This allows toexplicitly set a port range for Yarn applications which are running behind afirewall, for example.This closes #8096.",1
[FLINK-11240][table-common] Add an external catalog factory and descriptorThis closes #7390.,2
[FLINK-12041][table-runtime-blink] Introduce ResettableExternalBuffer to blink batch (#8066),2
[hotfix][table-planner-blink] Fix aggregate test,3
[FLINK-12062][table-runtime-blink] Introduce bundle operator to streaming table runtime.This closes #8086,1
[FLINK-11155][fs] Fix hadoop-free factory tests on Java 9,3
[FLINK-11929][runtime] Remove unused transientBlobCache in ClusterEntrypoint,1
[FLINK-12078][network] Abstract TaskEventPublisher interface for simplifying NetworkEnvironment,1
[hotfix][table] Correct test method name.,3
[hotfix][table]Improve column operations doc in tableAPI.This closes #8112.,2
[FLINK-10575][coordination] Remove deprecated ExecutionGraphBuilder.buildGraph method,4
[hotfix][runtime] Remove unused variable,1
[FLINK-11603][metrics] Port MetricQueryService to RpcEndpoint,2
[FLINK-11897][tests] Wait until all tasks are submitted,3
[FLINK-12112][tests] Properly print process output,3
[FLINK-10973] [table] Add support for map to table API.This closes #7167.,1
[FLINK-12050][tests] Fix process id retrieval on Java 9,0
[FLINK-12094][table-runtime-blink] Introduce sort merge join operator to blink batch runtimeThis closes #8107,1
[FLINK-12081][table-planner-blink] Introduce aggregation operator code generator to blink batchThis closes #8099,2
[hotfix][table] Renamed UnresolvedFieldReferenceExpression to UnresolvedReferenceExpression,0
[hotfix][table] Added getTableOperation method to Table,1
[hotfix][table] Replaced Table in TableReference with TableOperation,0
[hotfix][table-planner] Fixed creating number literals in ExpressionParser,1
[FLINK-12009][runtime] Fix wrong check message about heartbeat interval for HeartbeatServicesThis closes #8048.,0
[FLINK-11884][table] Implement expression resolution on top of newExpressions,1
[FLINK-12121] [State Backends] Use composition instead of inheritance for InternalKeyContext in backendsThis closes #8122.,1
[hotfix][table] Simplified aggregation & projection splitting,0
Add Flink 1.8 to list of previous docs,2
[FLINK-10205] Introduce fault tolerance for InputSplits in batch executionThis closes #8125.,2
[FLINK-11593][tests] Port TaskManagerTest to new code base,1
[FLINK-11884][table] Ported projection validation on top of Expressions,5
[hotfix][tests] Fix tests for jepsen.flink.generator/inc-by-factor,2
[FLINK-12123][tests] Upgrade Jepsen to 0.1.13Upgrade Jepsen dependency to get support for Debian Stretch (Jessie has reachedEOL):  * Adapt for new checker interface  * Install Marathon manually because there are no packages for Debian Stretch  * Upgrade Marathon to 1.7 because I cannot find the 1.6.322 binaries anywhere  * Update Dockerfiles to Debian StretchThis closes #8131.,2
"[hotfix][tests] Shut down HDFS and YARN cleanly.Use provided scripts to shut down HDFS and YARN instead of grepkill! function.Using grepkill! one can run situations where flink and hadoop processes arekilled concurrently, which results in an exception.",2
[FLINK-12087][table-runtime-blink] Introduce over window operators to blink batch (#8102),2
Update japicmp comparison version to latest Flink 1.8.0,2
[FLINK-12066] [State Backends] Remove StateSerializerProvider field in keyed state backendThis closes #8078.,1
[FLINK-12098][table-planner-blink] Add support for generating optimized logical plan for simple group aggregate on stream (#8110),2
[hotfix][docs] Update Yarn setup documentation with Flip-6,2
[FLINK-11920][scala] Reuse java classpath,1
[FLINK-11920][travis] Remove flink-scala exclusion,2
[FLINK-11757][tests] Add 1.8 to MigrationVersion,1
[FLINK-12155][coordination] Remove legacy TaskManager,4
[hotfix][travis] Allow scala-suffix check to download plugins,0
[FLINK-12151][es1] Remove Elasticsearch 1 connector,4
[FLINK-12100][kafka] Add jaxb-api dependency on Java 9,1
[FLINK-12156][coordination] Remove legacy FlinkActor,2
[FLINK-12140][table-planner-blink] Support e2e sort merge join operator in batch mode (#8127),1
[FLINK-12120][table-planner-blink] Support e2e aggregate operator run in batch mode (#8120),1
"[FLINK-12067][network] Refactor the constructor of NetworkEnvironment (#8090)[FLINK-12067][network] Refactor the constructor of NetworkEnvironmentThe constructor of NetworkEnvironment was refactored to only contain NetworkEnvironmentConfiguration. The other related components such as TaskEventDispatcher, ResultPartitionManager, NetworkBufferPool are created internally.We also refactor the process of generating NetworkEnvironmentConfiguration in TaskManagerServiceConfiguration to add numNetworkBuffers instead of previous networkBufFraction, networkBufMin, networkBufMax. This way seems more easy and direct to construct NetworkBufferPool later. isCreditBased field is also maintained in this component for considering the setting usage in tests.Further we introduce the NetworkEnvironmentConfigurationBuilder for creating NetworkEnvironmentConfiguration easily especially for tests.",3
[FLINK-10941][Network] Release partition after consumer end of reception confirmation,5
"[FLINK-10941][RM] Release task executor after all its result partitions are releasedThe task executor gateway can use NetworkEviroment.PartitionManager to check still registered and unreleased partitions because it is the central point to manage partitions. It would also simplify how it is queried now going through TaskSlot and lingering Tasks. Eventually, NetworkEviroment becomes ShuffleService which could decide whether producer can be released or not this way or another.We still make producer task executor depend on another consumer task executor, though, we do not see any problems with it now, I think it is still more safe to introduce an option as a feature flag. By default, task executor will wait for consumers, as this PR suggests, but users can always fallback to the previous behaviour using the option.",1
[FLINK-12169] [javadocs] improve javadoc of MessageAcknowledgingSourceBaseThis closes #8155.,1
[hotfix][docs] Fixed typo in metrics.md,2
[FLINK-12161][table-planner-blink] Supports partial-final optimization for stream group aggregate (#8148),1
[hotfix][travis] Remove leftover ES1 exclusion,4
"[FLINK-12168][table-planner-blink] Support e2e limit, sortLimit, rank, union in blink batch (#8156)",2
[FLINK-11884][table] Ported alias validation on top of Expressions,5
"[FLINK-12154][network] Remove legacy fields for SingleInputGate (#8136)This work is a preparation for FLINK-11726.In SingleInputGate#create, we could remove unused parameter ExecutionAttemptID.And for the constructor of SingleInputGate, we could remove unused parameter TaskIOMetricGroup.Then we introduce createSingleInputGate for reusing the process of creating SingleInputGate in related tests.",3
[FLINK-11884][table] Ported sort & limit validation on top of Expressions,5
[hotfix] Remove unused exception from FileSystem#initialize,5
[FLINK-11952][1/3] Make ChildFirstClassLoader a top-level class in flink-core,2
[FLINK-11952][2/4] Introduce basic plugin mechanism for FlinkThe mechanism uses child-first classloading and creates classloaders from jars that are discoveredfrom a directory hierarchy.,1
[FLINK-11952][3/4] Integrate plugin mechanism with FileSystem,5
"[FLINK-11952][4/4] Integrate plugin mechanism with FileSystem initialization in process entry pointsThis integration currently still does not provide a proper plugin root folder because thisrequires more changes, in particular FLINK-11952.This closes #8038.",2
[hotfix] Use TemporaryClassLoaderContext in other appropriate places in the codebase,1
[FLINK-11884][table] Ported calculated table validation on top of Expressions,5
[hotfix] Remove unused method ExecutionGraph#restoreLatestCheckpointedState,3
[hotfix] Delete empty TaskManager.scala file,2
[FLINK-12177][coordination] Remove legacy FlinkUntypedActor,2
[FLINK-12017][table-planner-blink] Introduce Rank and Deduplicate operators for blink streaming runtimeThis closes #8109,1
[hotfix] [typo] fix typo in debugging_event_time,0
[FLINK-12193][tests] Add option to disable failOnCheckpointingErrorsAdd option to disable failOnCheckpointingErrors in DataStreamAllroundTestJob.,5
[hotfix][tests] Split DataStreamAllroundTestJobFactory#setupEnvironment into smaller methods,5
[hotfix][tests] Reorder ConfigOptions in DataStreamAllroundTestJobFactoryReorder so that checkpoint-related ConfigOptions appear consecutively.,5
[hotfix][tests] Fix typo in exception message,2
[hotfix][docs] Fix JavaDocs typos in Task class.This closes #8025.,2
[FLINK-12204][jdbc] Improve JDBCOutputFormat ClassCastException.This closes #7965.,5
[hotfix][docs] Fix inconsistencies in SQL function documentation.This closes #7940.,2
[hotfix][filesystem] Remove redundant 'for example' in JavaDocs.This closes #8143.,2
[FLINK-12132][docs] Fix example in job submission for YARN setup.This closes #8129.,1
[FLINK-12137][docs] Use AWSConfigConstants instead of ConsumerConfigConstants in examples.This closes #8128.,5
[hotfix][docs] Update process function example to use KeyedProcessFunction.This closes #8101.,1
[hotfix][docs] add missing bracket for cli.mdThis closes #8178.,1
[FLINK-12185][table-planner-blink] Add support for generating optimized logical plan for join on stream (#8165),2
"[FLINK-12174][table] Introduce FlinkAggregateExtractProjectRule and remove extractFieldReferencesThis commit introduces calcite's rule that tries to extract Projection from Aggregation instead of doing it manually in Table API. This way we have a consistent behavior between Table API and SQL. It also works better as it incorporates more contextual information, rather than naively extracting all field references.",4
[FLINK-12217][table] OperationTreeBuilder.map() should perform ExpressionResolver.resolve(),0
[FLINK-12117][cassandra] Disable tests on Java 9,3
[FLINK-12102][tests] Fix FlinkILoopTest on Java 9,3
[FLINK-11923][metrics] Move reporter setup out of MetricRegistry,1
[hotfix][utils] Remove duplicate LeaderRetrievalUtils#getRecoverMode mode,1
[FLINK-10712] Support state restore for RestartPipelinedRegionStrategyThis closes #7813.,1
[FLINK-12170] [table-planner-blink] Add support for generating optimized logical plan for Over aggregate (#8157),2
[FLINK-12198][jdbc] Add support for setting auto-commit mode of JDBCInputFormat DB connection.This closes #8186.,5
[FLINK-12204][jdbc] Improve JDBCOutputFormat ClassCastException.This closes #8182.,5
[hotfix][yarn] Fix typo in comment of YarnConfigurationITCase.This closes #8161.,5
[hotfix][rockdb] Fix a swallowed exception cause in RocksDBListState.This closes #7983.,5
"[FLINK-11667][checkpointing] Add Synchronous Checkpoint handling in StreamTask.This is a necessary step towards implementing the ""stop with a savepoint"".Essentially, a synchronous savepoint is one that waits until also thenotifyOnCheckpointComplete is successfully executed, before releasing thecheckpoint lock (on the StreamTask side).",1
"[FLINK-11668][checkpointing] Allow sources to advance to MAX_WATERMARK.Allows the sources to inject a MAX_WATERMARK before processing asynchronous savepoint. This is needed for the ""drain"" functionality,as described in FLIP-34.",1
"[FLINK-11669][checkpointing] Wire the Suspend/Terminate to the JM/TM.Wires the functionality introduced in FLINK-11667 and FLINK-11668with Flink's distributed RPC mechanism. This is a pre-requisitein order to expose the ""suspend"" and ""terminate""/""drain"" functionalityto the user.",1
[FLINK-11670][FLINK-11671][rest][cli] Expose Suspend/Drain via REST and CLI.,2
"[FLINK-12119][build] Add owasp-dependency-check pluginRun via ""mvn org.owasp:dependency-check-maven:aggregate"".Prints a report to stdout and creates a report in the root /target directory.",1
[FLINK-12212][docs] Clarify that operator state is checkpointed asynchronouslyThis closes #8185.,1
"[FLINK-11474][table] Add ReadableCatalog, ReadableWritableCatalog, and other related interfaces.This closes #8007.",2
[FLINK-12211][table-planner-blink] Add more it cases to blink batch (#8184),2
[hotfix][docs] Fix typo,2
"[FLINK-11889] Remove ""stop"" signal and related interfaces.",4
[FLINK-11889][webui] Remove STOP related code.,4
[FLINK-11889][webui] Rebuilt UI.,2
[FLINK-11431][runtime] Upgrade akka to 2.5,2
[FLINK-12226][docs] Update CLI docs for SUSPEND/TERMINATE.,2
"[FLINK-12146][network] Remove unregisterTask from NetworkEnvironment to simplify the interface of ShuffleService NetworkEnvironment#unregisterTask is used for closing partition/gate and releasing partition from ResultPartitionManager. partition/gate close could be done in task which already maintains the arrays of them.Further we could release partition from ResultPartitionManager inside ResultPartition via introducing ResultPartition#fail(Throwable).To do so, the NetworkEnvironment#unregisterTask could be totally replaced to remove. The benefit is simplifying the method of NetworkEnvironment which would be regarded as default ShuffleService implementation.",1
[hotfix][travis] Enable multiple modules on Java 9,0
[FLINK-12248][table-planner-blink] Support e2e over window in blink batch (#8206),2
[FLINK-12192][table-planner-blink] Add support for generating optimized logical plan for grouping sets and distinct aggregateThis closes #8176,1
[FLINK-11530] [docs] Support multiple languages for the docs frameworkThis closes #7754,1
[FLINK-11530] [docs] Copy all the English markdown files to xx.zh.mdThis closes #7754,2
[FLINK-12026][table]Remove the `xxxInternal` method from TableImpl.This closes #8070.,4
[FLINK-12029][table] Add column operations for TableApiThis closes #8087.,1
[FLINK-10974][table] Add support for flatMap to table APIThis closes #7196.,1
[FLINK-12133] [table-runtime-blink] Support unbounded aggregate in streaming table runtimeThis closes #8202,1
[FLINK-11531] [docs-zh] Translate the Home Page of flink docs into ChineseThis closes #8231,1
[FLINK-12261][table-planner-blink] Support e2e group window in blink batchThis closes #8221,2
[hotfix] Remove some unused import statement,2
[Flink-12208] [table-runtime-blink] Introduce Sort & TemporalSort & SortLimit & Limit operators for blink streaming runtimeThis closes #8203,1
[FLINK-11910] [YARN] Add customizable yarn application typeThis closes #7978,1
[FLINK-10517][rest] Extract DocumentingDispatcherRestEndpoint,2
[hotfix][docs] Include exception in stacktrace,2
[FLINK-10517][rest] Add isStable field to RestAPIVersion,1
[FLINK-10517][rest] Add stability test,3
[FLINK-11067][table] Introduce PlannerConfig and port TableConfig into api-javaThis is part of the effort to decouple api specific classes from Plannermodule. It introduces the concept of PlannerConfig to enable passing acustom planner specific configuration.,5
[hotfix][table-api] Fixed calciteConfig extraction from PlannerConfig,5
[FLINK-11067][table-api-java] port AmbiguousTableFactoryException and NoMatchingTableFactoryException,2
[FLINK-12165][table-planner] Added resolution rule that checks all unresolved expressions are resolvedAll resolutions should possible happen in a single place. To ensure thisis always true we added a safety rule that verifies no unresolvedexpressions are part of the output from the ExpressionResolver.This closes #8149,0
[FLINK-11534] [container] Allow ExecutionMode configuration,5
[FLINK-11884][table] Ported aggregation validation on top of Expressions,5
[FLINK-11884][table] Ported filter validation on top of Expressions,5
"[FLINK-11884][table] Ported Minus, Intersect, Union validation on top of Expressions",5
[FLINK-11884][table] Ported join validation on top of Expressions,5
[FLINK-11884][table] Skeleton for transforming operations to RelNodes,2
[FLINK-11884][table] AggregateTableOperation construction &transformation to RelNodes,2
[FLINK-11884][table] DistinctTableOperation & FilterTableOperation construction &transformation to RelNodes,2
[FLINK-11884][table] SortTableOperation construction &transformation to RelNodes,2
[FLINK-11884][table] CalculatedTableOperation construction &transformation to RelNodes,2
[FLINK-11884][table] CatalogTableOperation construction &transformation to RelNodes,2
[FLINK-11884][table] PlannerTableOperation construction &transformation to RelNodes,2
[FLINK-11884][table] WindowAggregateTableOperation construction & tranformation to RelNodes,2
[FLINK-11884][table] JoinTableOperation construction & tranformation to RelNodesThis closes #8062,2
[FLINK-12288][table-planner-blink] Bump Calcite dependency to 1.19.0 in blink plannerThis closes #8234,2
[FLINK-11915][core] Fix miscalculation of DataInputViewStream.skip[FLINK-11915][core] Add the missed unit test case[FLINK-11915][core] Rich the test case to cover origin skipping functionThis closes #8195.,1
[FLINK-12247][rest] Fix NPE when writing the archive json file to FileSystemThis closes #8250.,5
[FLINK-12247] Add @Nullable annotation to AccessExecutionVertex#getPriorExecutionAttempt()This commit updates the AccessExecutionVertex#getPriorExecutionAttempt() interface to correctlydenote that it can return a null value.,1
[FLINK-12065][e2e] Ignore reflection access warnings,2
[hotfix][tests] Use ConfigOptions instead of hard-coded keys,5
[hotfix][rest][tests] Fix Preconditions placeholder,0
[FLINK-12322] Remove legacy ActorTaskManagerGatewayRemove ActorTaskManagerGateway from InstanceManagerTestRemove ActorTaskManagerGateway from ExecutionGraphRestartTestRemove ActorTaskManagerGateway from ExecutionVertexCancelTestRemove ActorTaskManagerGateway from InstanceTestRemove ActorTaskManagerGateway from SimpleSlotTestRemove ActorTaskManagerGatewayThis closes #8255.,3
[hotfix] Remove legacy DummyActorGateway,4
[FLINK-12323] Remove legacy ActorGateway based interface implementationsRemove ActorGatewayCheckpointResponderRemove ActorGatewayGlobalAggregateManagerRemove ActorGatewayKvStateLocationOracleRemove ActorGatewayKvStateRegistryListenerRemove ActorGatewayPartitionProducerStateCheckerRemove ActorGatewayResultPartitionConsumableNotifierRemove ActorGatewayTaskManagerActionsRemove TaskInputSplitProviderThis closes #8256.,1
[hotfix] Remove ActorUtils,4
[hotfix] Remove ScalaTestingUtils,3
[FLINK-12324] Remove legacy ActorGateway interfaceThis commit removes the legacy ActorGateway and all its implementations.This closes #8257.,4
[FLINK-11067][table-common] port AmbiguousTableFactoryException and NoMatchingTableFactoryException from api-java to table-common,2
"[FLINK-11067][table] port Schema, Rowtime, SchematicDescriptor, RegistrableDescriptor etc.",2
[FLINK-11067][table-common] port TableFactoryService into table-common,2
"[FLINK-11067][table] Convert TableFactoryUtil, Batch/StreamTableDescriptor, ConnectTableDescriptor into java",2
[FLINK-11067][table] Convert TableEnvironments to interfaces,2
[FLINK-11067][table] Port table source&sink classes into api-javaThis closes #8050,2
[FLINK-12024] Bump universal Kafka connector to Kafka dependency to 2.2.0 (#8055)This commit also removes useless arg:KAFKA_CONNECTOR_VERSION,1
[FLINK-10705][web]: Remove angularjs project,4
[FLINK-10858][web]: Create Angular Scaffold,1
[FLINK-10706][web]: Rework Flink Web DashboardThis closes #8016,2
[hotfix][tests] Simplify TaskExecutor creation,1
[hotfix][tests] Simplify TaskManagerServices creation,1
[hotfix][runtime] Move hostname retrieval logic into separate methods,2
[hotfix][network] Refactor NetworkEnvironmentConfigurationBuilder into NetworkEnvironmentBuilder,1
"[FLINK-12213][network] Move network metrics setup into NetworkEnvironmentAt the moment NetworkEnvironment#getNetworkBufferPool is called to add network related MetricGroup. In order to simplify the public API in NetworkEnvironment which is regarded as default ShuffleService implementation, we could pass the TaskManagerMetricGroup into constructor of NetworkEnvironment, then the related network MetricGroup could be added internally.",1
[FLINK-11518] [table] Add partition related catalog APIs and implement them in GenericInMemoryCatalogThis closes #8222,2
[FLINK-12321][table-planner-blink] Supports sub-plan reuse in blink plannerThis closes #8253,2
[hotfix][runtime] Log RPC failures on debug,0
[FLINK-12317][runtime] Ensure maximum size is larger than core size,2
[FLINK-12200][table-planner] Support UNNEST for MAP typesThis closes #8179,1
[FLINK-11519][table] Add function related catalog APIsThis closes #8275,2
[hotfix][yarn] userJarFiles can be a local variableThis closes #8264.,2
[FLINK-12316][jdbc] Relax assertions,3
[hotfix][webui] Add profile to skip WebUI build process,2
[hotfix][travis] Skip WebUI build process during tests,3
[FLINK-12040][build] Remove unused akka dependencies,1
[hotfix][travis] Extend cache info logging,2
[hotfix][travis] Speed up dependency convergenceRun dependency convergence in main compile run.Invoking maven once per modules requires significant time.Run convergence in install phase (i.e. after the shade plugin) to work against dependency-reduced poms.,1
[FLINK-12042] Fix RocksDBStateBackend mistaken usage of the default filesystem[FLINK-12042] Restrict only temporary snapshot directories to the local file system by changing the signature to accept files as parameterThis closes #8068.,2
[FLINK-12042][test] Refactor SnapshotDirectoryTest#existsTests in a separate test that SnapshotDirectory#temporary creates a local snapshot directory.,1
"[hotfix][travis] Cache documentation gems separatelyThe .rvm directory contains a bunch of travis-provided gems, which we don't need to cache. Additionally, these were cached in all profiles, not just the documentation ones.We now cache gems required for the documentation separately.",2
[FLINK-11776][coordination] Refactor to simplify the process of scheduleOrUpdateConsumersThis closes #7856.,5
[FLINK-12131] Adjust IntermediateResult/IntermediateResultPartition status properly on ExecutionVertex reset1. Add a test for exact running producer counter verification2. Add back IntermediateResult.resetForNewExecution for tests3. Refine commentsThis closes #8158.,3
[hotfix][travis] Fix convergence profile name,2
[hotfix][travis] Remove unnecessary faraday installation,4
[hotfix][travis] Install kubernetes/docker only in E2E profiles,2
[hotfix][travis] Speed up scala-suffix check- fix find -mindepth parameter- pass PROFILE to maven to prevent downloads of modules that weren't built beforehand- add -maxdepth parameter for pom.xml searches,5
[hotfix][travis] Exclude all jars from cacheJar caching is not required since they are rebuilt in the test profiles anyway.,2
[FLINK-12344][coordination] Remove legacy runtime messages,1
[hotfix][travis] Move docker wordcount to nightly tests,3
[hotfix][travis] Move several modules out of misc,4
[hotfix][tests] Remove mockito usage in ExecutionGraphTestUtils,3
[hotfix][tests] Remove unused method and field in ExecutionGraphTestUtils,3
[hotfix][tests] Shift down ERROR_MESSAGE to its only referred class,0
[hotfix][tests] Replace mock ConsumerRecords with ConsumerRecords.empty,3
[FLINK-12339][example] Fix variable name,0
[hotfix][travis] Update comment,5
[hotfix][travis] Cleanup cache logging,2
[FLINK-10441][rest] Log initial creation of uploadDir on INFO,5
[hotfix][travis] Run pre-commit e2e tests in compile stage,3
[FLINK-11822][table-planner-blink] Introduce Flink metadata handlersThis closes #7903,0
[hotfix][travis] Install jars in parallel,0
[hotfix][travis] Move flink-python to misc,2
[hotfix][travis] Move flink-ml to misc,2
[hotfix][travis] Move QS to connectors,4
[FLINK-12230][runtime] Remove method JobMaster#getExecutionGraph()This closes #8211.,1
"Revert ""[hotfix][travis] Install jars in parallel""This reverts commit faabf0a2af3f238ebbde836c13482a64c81d4f85.Building scala projects in parallel interacts badly with incremental compilation",4
[FLINK-12347][build][sql] Add scala suffix,0
[hotfix][travis] Add sleep before timestamp update,5
[FLINK-12346][travis][build] Account for timestamps in scala-suffix check,0
[FLINK-12307][table-planner-blink] Support translation from StreamExecWindowJoin to StreamTransformation.This closes #8261,1
[FLINK-12139][Mesos] Add disk space parameter.This closes #8224.,2
[hotfix][travis] Move gelly to tests,3
{hotfix][build][es6] Small shade-plugin cleanup,4
[FLINK-10724] Refactor failure handling in check point coordinatorThis closes #7571.,0
[FLINK-11167] Optimize RocksDBListState#put by removing the clear before every put operationThis closes #7421.Differential Revision: https://aone.alibaba-inc.com/code/D816268,4
[FLINK-12350] [State Backends] RocksDBStateBackendTest doesn't cover the incremental checkpoint code pathThis closes #8297.,5
"[hotfix][runtime,tests] Add test coverage for BlockingCallMonitoringThreadPool",3
[FLINK-12180][Tests] Port ExecutionVertexCancelTest to new codebaseThis closes #8227.,1
[hotfix] Fix checkstyle violations in ExecutionVertexCancelTest,3
[FLINK-8640][build] Add japicmp-plugin Java EE dependencies,1
[FLINK-8640][build] Rework hadoop jdk.tools exclusion,1
[FLINK-8640][travis] Enable japicmp on Java 9,0
[FLINK-12312][runtime] Remove CLI command for rescalingThis closes #8260.,4
"[FLINK-12296][StateBackend] Fix local state directory collision with state loss for chained keyed operators- ChangeWill change the local data path from`.../local_state_root/allocatio_id/job_id/jobvertext_id_subtask_id/chk_id/rocksdb`to`.../local_state_root/allocatio_id/job_id/jobvertext_id_subtask_id/chk_id/operator_id`When preparing the local directory Flink deletes the local directory for each subtask if it already exists,If more than one stateful operators chained in a single task, they'll share the same local directory path,then the local directory will be deleted unexpectedly, and the we'll get data loss.This closes #8263.",5
[FLINK-12306][Runtime] Change the name of log into LOG,2
[hotfix][metrics] Remove legacy/unused code,1
[hotfix][tests][runtime] Extract utilities for creating InputChannels,1
[FLINK-12199][metrics][network] Decouple network metrics from Task,1
[FLINK-12238][hive] Support database related operations in GenericHiveMetastoreCatalog and setup flink-connector-hive moduleThis closes #8205,2
"[FLINK-12187] Bug fixes, Use BufferedWriter in a loop instead of FileWriter",2
[hotfix] regenerate rest-docs to latest code,3
"[FLINK-12203] Refactor ResultPartitionManager to break tie with TaskAt the moment, we have ResultPartitionManager.releasePartitionsProducedBy which uses indexing by task in network environment. These methods are eventually used only by Task which already knows its partitions so Task can use ResultPartition.fail(cause) and TaskExecutor.failPartition could directly use NetworkEnviroment.releasePartitions(Collection<ResultPartitionID>). This also requires that JM Execution sends produced partition ids instead of just ExecutionAttemptID.This closes #8210.",1
[hotfix][travis] Fix scala 2.12 profile name,2
[hotfix] [table] Refactor GenericInMemoryCatalogTest to prepare for moving common tests to CatalogTestBase (#8325)* [hotfix] [table] Refactor GenericInMemoryCatalogTest to prepare for moving common tests to CatalogTestBase,3
[hotfix][mapr] Skip MaprFS on Java 9,0
"[FLINK-12049][runtime] Adjust ClassLoaderUtils to Java 9ClassLoaderUtil#getUserCodeClassLoaderInfo made an assumption that system classloaders were always URLClassLoaders, which no longer holds on Java9+. In this case it returned ""no user code ClassLoader"", but this would be confusing if it ever were printed at runtime.We're adding another branch to cover this case, which should only reachable on Java 9,",1
[hotfix][travis] Enable flink-runtime on Java 9,2
[FLINK-12184][hs] HistoryServerArchiveFetcher incompatible with old versionThis closes #8313.,2
[hotfix][tests] Prevent HistoryServerTest to print to STDOUT,3
[FLINK-12333][docs] Add documentation for all async operations through REST APIThis closes #8327.,2
[hotfix] [tests] Fix incomplete buffer reading in S3 test,3
[hotfix] [tests] Unimplemented mock methods in RecoverableMultiPartUploadImplTest throw UnsupportedOperationException,1
[FLINK-12359][metrics][tests] Harden SystemResourcesMetricsITCase,5
[FLINK-12391][travis] Limit transfer.sh upload to 1 minute,2
[hotfix][travis] Fix log4j configuration path,5
[hotfix][travis] Skip WebUI build process for e2e runs,1
[FLINK-12246][runtime] Read MAX_ATTEMPTS_HISTORY_SIZE from cluster configurationThis closes #8268.,5
[FLINK-12357][table-api-java] Remove useless code in TableConfigThis closes #8301.,5
[FLINK-12253][table-common] Introduce a logical type skeleton,2
[FLINK-12253][table-common] Add a CHAR type,1
[FLINK-12253][table-common] Add a VARCHAR type,1
[FLINK-12253][table-common] Add a BOOLEAN type,1
[FLINK-12253][table-common] Add a BINARY type,1
[FLINK-12253][table-common] Add a VARBINARY type,1
[FLINK-12253][table-common] Add a DECIMAL type,1
[FLINK-12253][table-common] Add a TINYINT type,1
[FLINK-12253][table-common] Add a SMALLINT type,1
[FLINK-12253][table-common] Add a INT type,1
[FLINK-12253][table-common] Add a BIGINT type,1
[FLINK-12253][table-common] Add a FLOAT type,1
[FLINK-12253][table-common] Add a DOUBLE type,1
[FLINK-12253][table-common] Add a DATE type,5
[FLINK-12253][table-common] Add a TIME type,1
[FLINK-12253][table-common] Add a TIMESTAMP type,1
[FLINK-12253][table-common] Add a TIMESTAMP WITH TIME ZONE type,1
[FLINK-12253][table-common] Add a TIMESTAMP WITH LOCAL TIME ZONE type,1
[FLINK-12390][build] Fully migrate to flink-shaded-asm-6,2
[FLINK-10977][table] Add  non-windowec streaming FlatAggregate to Table API.This closes #8230,1
"[FLINK-11614][docs-zh] Translate the ""Configuring Dependencies"" page into ChineseThis closes #8200",1
[FLINK-11732] [docs] Add a language switch to the sidebar for Flink documentsThis closes #8238add contribute translation link to English pages.,2
"[FLINK-12360][docs-zh] Translate ""Jobs and Scheduling"" Page into ChineseThis closes #8342",1
"[FLINK-11611][docs-zh] Translate the ""Batch Examples"" page into ChineseThis closes #8273",1
"[FLINK-12314][docs-zh] Translate the ""Type Serialization"" page into ChineseThis closes #8276",1
"[FLINK-11613][docs-zh] Translate the ""Project Template for Scala"" page into ChineseThis closes #7799",1
"[FLINK-12311][python] Add base python framework and Add Scan, Projection, and Filter operator supportThis closes #8267make travis tests greenfix documents, refine shell file name and optimize program logic.Adjust the code examples in python documents to be consistent with scala documents.Refactor flink-python project structure, remove java file from flink-python package.delete unnecessary dependency and plugins.",4
"[FLINK-11633][docs-zh] Translate ""Working with state"" page into ChineseThis closes #8341",1
[hotfix][runtime] Remove useless code in JSONGenerator,5
[FLINK-12253][table-common] Add an INTERVAL YEAR TO MONTH type,1
[FLINK-12271][table] Display input field name list when throw Cannot resolve field exception,0
[FLINK-12253][table-common] Add an INTERVAL DAY TO SECOND type,1
[FLINK-12253][table-common] Add an ARRAY type,1
[FLINK-12253][table-common] Add a MULTISET type,1
[FLINK-12253][table-common] Add a MAP type,1
[FLINK-12253][table-common] Add a ROW type,1
[FLINK-12253][table-common] Add user-defined types,1
[FLINK-12253][table-common] Add a NULL type,1
[FLINK-12253][table-common] Add an ANY type,1
[FLINK-12274] Fix documentation to enable Queryable State,0
"[FLINK-12404][docs-zh] Translate the ""Register a custom serializer for your Flink program"" page into ChineseThis closes #8348",1
"[FLINK-11636][docs-zh] Translate ""State Schema Evolution"" page into ChineseThis closes #8319",1
[FLINK-12366][table] Clean up catalog APIs to make them more consistent and coherentThis closes #8312,1
[FLINK-12368] [Kafka] Add subtask index to FlinkKafkaConsumerBase loggingThis closes #8315,2
"[hotfix] [docs] Fix typo in ""Window Operator"" documentationBefore: ... windows together if `their` are closer to eachAfter: ... windows together if `they` are closer to eachThis closes #8285",1
"[FLINK-12239][hive] Support table related operations in GenericHiveMetastoreCatalogThis PR enables GenericHiveMetastoreCatalog to operate Flink tables by using Hive metastore as a storage. Flink tables will be stored as Hive tables in metastore, and GenericHiveMetastoreCatalog can convert between Flink and Hive tables upon read and write.This closes #8329",2
[FLINK-12232][hive] Support database related operations in HiveCatalogThis PR creates HiveCatalog in flink-connector-hive module and implements database related APIs for HiveCatalog.This closes #8837,2
"[hotfix][kafka,test] Improve error messageIf expected or actual elements are small enough, print them directly instead of printing the elements count.",0
"[hotfix][kafka,test] Add missing shutdown call propagation",1
"[hotfix][kafka,test] Allow exceptions in KafkaTestEnvironment#prepare",3
"[hotfix][kafka,test] Make brokers list final and avoid potential null pointer exceptions",1
"[hotfix][kafka,test] Synchronize 0.11 KafkaTestEnvironmentImpl with universalThis is a pure refactor, that reorders the method so that those two KafkaTestEnvironmentImpl implementations are more inline",3
"[FLINK-11249][kafka,test] Add FlinkKafkaProducer(011) migration testsAdd migration test for 0.11 and universal connector to make surethat those sinks can be restarted from old save points.Note this doesn't test for migration from 0.11 to universal connector.It only checks that master version of 0.11 (or universal) connector iscompatible with state created by previous Flink versions.",2
"[hotfix][kafka,test] Handle shutdownCluster even if it wasn't initializedPreviously null pointer exception thrown from @AfterClass shutdown call could hideoriginal underlying issue if there was a failure that prevented kafkaServer from being constructed",0
[FLINK-10976] [table] Add support for aggregate to table APIThis closes #8311.,1
[FLINK-12330][python]Add integrated Tox for ensuring compatibility of multi-version of python.This closes #8355.,2
[FLINK-12345][table-planner-blink] Add support for generating optimized logical plan for stream window aggregateThis closes #8288,2
"[FLINK-12219] Log uncaught exceptions and terminate in case Dispatcher#jobReachedGloballyTerminalState failsFutureUtils#assertNoException will assert that the given future has not been completedexceptionally. If it has been completed exceptionally, then it will call theFatalExitExceptionHandler.This commit uses assertNoException to assert that the Dispatcher#jobReachedGloballyTerminalStatemethod has not failed.This closes #8334.",0
"[FLINK-12342][yarn] Add config option for heartbeat interval during container requestsFlink's YarnResourceManager sets a faster heartbeat interval when it is requesting containersfrom Yarn's ResourceManager. Since requests and responses are transported via heartbeats, thisspeeds up requests. However, it can also put additional load on Yarn due to excessive containerrequests. Therefore, this commit introduces a config option which allows to control this heartbeat.This closes #8306.",1
"[FLINK-12240][hive] Support view related operations in GenericHiveMetastoreCatalogThis PR added support for views in GenericHiveMetastoreCatalog, operations include create, drop, alter, rename, list.This closes #8339.",4
[FLINK-12326][python] Add basic test framework for python table api.This closes #8347,1
[FLINK-12365][table] Add stats related catalog APIsThis closes #8314,2
[FLINK-12227][runtime] Add interfaces for SchedulingTopologyThe SchedulingTopology contains the information which is provided to theSchedulingStrategy in order to decide which execution vertices should bescheduled next.,1
[FLINK-12227][runtime] Introduce SchedulingStrategy interfaceThis closes #8233.,2
[FLINK-12228][runtime] Implement Eager Scheduling StrategyThis closes #8296.,2
[hotfix][tests] Rename variables in EagerSchedulingStrategyTest,3
[hotfix][runtime] Add null check to RestartStrategyResolving,1
[hotfix][runtime] Remove unused field ARCHIVE_NAME from JobMaster,1
"[FLINK-12231][runtime] Introduce SchedulerNG interfaceIntroduce SchedulerNG interface with a LegacyScheduler implementation, whichhides direct calls to the ExecutionGraph from the JobMaster.The LegacyScheduler is only needed so that the existing scheduling code pathskeep functioning while work on the new scheduling abstractions is in progress.Remove JobMasterTest#testAutomaticRestartingWhenCheckpointing() because itrequires the JobMaster to expose internal state (RestartStrategy) - add unittests for JobGraph#isCheckpointingEnabled() to make up for the removed test.",3
[hotfix][tests] Avoid mock NetworkEnvironment in tests,3
"[FLINK-11726][network] Refactor the creations of ResultPartition and SingleInputGate into NetworkEnvironmentAt the moment ResultPartition and SingleInputGate are created in Task. Based on new pluggable ShuffleManager, they should be created via ShuffleService#createResultPartitionWriter/InputGate.The NetworkEnvironment would be refactored into NetworkShuffleService future. So we could migrate the process of creating ResultPartition and SingleInputGate into current NetworkEnvironment. The metrics registration of network and buffers can also be done along with the creations.",1
[FLINK-12417][table] Unify ReadableCatalog and ReadableWritableCatalog interfaces to Catalog interfaceThis PR unifies ReadableCatalog and ReadableWritableCatalog interfaces to Catalog interface to simplify the architecture and management of catalogs.This closes #8365.,2
[FLINK-12325][metrics] Refactor StatsD tests,3
[FLINK-12325][metrics] Add counter/gauge tests for StatsD,3
[FLINK-12325][metrics] Extend test metric implementations,3
[FLINK-12325][metrics] Migrate StatsD test to test metric implementations,3
[FLINK-12325][metrics] StatsDReporter properly handles negative values,0
[hotfix][docs] Fix typo,2
[hotfix][state] Add error message to precondition in HeapPriorityQueueSet,1
[FLINK-12460][docs] Replace taskmanager.tmp.dirs with io.tmp.dirs in documentation,2
[FLINK-12453][table-planner-blink] Simplify constructor of AggsHandlerCodeGenerator to explicitly tell which methods need to be generatedThis closes #8378,0
[FLINK-12392][table-planner-blink] Port FlinkRelMetadataQuery into Java to avoid compiling error with Scala 2.12This closes #8376,0
[FLINK-11974][runtime] Introduce StreamOperatorFactory and replace StreamOperator.setup with StreamOperatorFactory.create,1
[FLINK-11974][table-planner-blink] Use StreamOperatorFactory in Blink runtime,1
[hotfix][table-common] Make type parameter constants accessible,2
"[FLINK-12393][table-common] Add the user-facing classes of the new type systemIntroduces the DataType class and subclasses. Users are able to do a star importof DataTypes and declare types like: `MULTISET(MULTISET(INT())`. Close to SQL. Asmentioned in FLIP-37, data types allow to specify format hints to the plannerusing `TIMESTAMP(9).bridgedTo(java.sql.Timestamp)`.This closes #8360.",1
[hotfix][table-common] Add description to user-defined type attributes,1
[hotfix][table-common] Validate fields of row type,5
[hotfix][table-common] Allow boxed conversions when primitive types are allowed,1
[hotfix][table-common] Remove COLLECTION family from MAP type root,4
[FLINK-12417][table] part2 - remove ReadableCatalog,2
"[FLINK-12454][python] Add -l(list) -i(include) and -e(exclude) option for lint-python.sh.Brief change log:- Add -l(list) option, will list all checks supported.- Add -e(exclude) option, exclude checks which split by comma(,) e.g. -e tox,flake8- Add -i(include) option, include checks which split by comma(,) to exec e.g. -i flake8.This closes #8383",1
[hotfix][table] Fix typo for method name in FieldReferenceLookup.This closes #8393,2
[FLINK-12444][docs] Fix broken links,2
[FLINK-9445][scala] Scala-shell uses JAVA_RUN,1
[FLINK-12369][runtime] Add Failover interfaces,0
[FLINK-12369][runtime] Port RestartPipelinedRegionStrategy,2
[hotfix] Don't swallow exception in FromElementsFunction,1
"[FLINK-12459][yarn] YarnConfigOptions#CLASSPATH_INCLUDE_USER_JAR should affect the order of classpath between user jars and flink jarsPut user code jars behind the Flink distribution jar when settingYarnConfigOptions#CLASSPATH_INCLUDE_USER_JAR to ""LAST"".This closes #8395.",5
[FLINK-12445][yarn] Cancel application on failure,0
[hotfix][tests] Extend Tar wrapper to support strip argument,1
[hotfix][build] Remove unnecessary version tag,4
[hotfix][tests] Remove forced step logging in AutoClosableProcess,2
[hotfix][tests] Rework Process IO handling,1
[hotfix][tests] Add modified ExternalResource class,1
[hotfix][tests] Backup logs for failed tests,3
Merge pull request #8361 from pnowojski/f12434[FLINK-12434][network] Replace listeners with CompletableFuture in InputGates,2
"Revert ""Merge pull request #8361 from pnowojski/f12434""This reverts commit d3fd7a6794a8ffd16e00bb1867b6e62c3909a2d2.",4
[hotfix][network] Implement UnionInputGate#pollNextBufferOrEvent method,0
"[hotfix][network] Refactor and simplify InputGate#getNextBufferOrEventPreviously in case of more data available, re-enquing a channel or an inputGatewas done in a separate critical section, resulting with more complicated concurrencycontract (critical section split into two). Side effect of this changeis that now recursive getNextBuffer/pollNextBufferOrEvent are happening alsounder the lock, however they are non-blocking, so this shouldn't cause any issues.",0
[hotfix][test] Introduce InputGateTestBase and deduplicate test code,3
[hotfix][network] Replace inputGatesWithData and enqueuedInputGatesWithData fields with single LinkedHashSet,2
"[FLINK-12434][network] Replace listeners with CompletableFuture in InputGatesThis commit replaces listeners in InputGates with `CompletableFuture<?> isAvailable`.Such change makes the contract simpler, since it avoids problems with:- only one possible listener- race conditions between registering listeners and firing the notification- by design handles a situation when a notification is fired more then once- it will integrate better with a recently proposed `Input` and `SourceReader` interfaces",1
[hotfix][network] Refactor InputGates code,4
[hotfix][test] Drop mockito usage from TestSingleInputGate,3
"[hotfix][travis] Retain existing MAVEN_OPTS in Travis maven setupRemoves a potential sources of unexpected behavior for when we defined MAVEN_OPTS in .travis.yml, which until now would've been ignored by this script.",5
[FLINK-12378][docs] Consolidate FileSystem Documentation,2
[FLINK-8513][docs] Add documentation for connecting to non-AWS S3 endpoints,2
[FLINK-10249][docs] Document hadoop/presto s3 file system configuration forwarding,5
[hotfix][docs] Some fixes to FileSystem DocumentationThis closes #8326,2
[hotfix] [docs] Minor cleanup in filesystem docs,2
[FLINK-12388][docs] Update the production readiness checklistThis closes #8330,5
[hotfix] Expand JavaDoc of MemorySegment.wrap(),2
"[hotfix] [network] Release unpooled buffer for events.So far, these buffers never needed to be released, because they do not come from a buffer pool.They were simply garbage collected.When changing the blocking partitions to use memory mapped files, these buffer were referingfor a short time to an unmapped memory region (after the partition is released). Because the bufferswere not accessed any more by any code, it did not matter when regularly running Flink.But, it did segfault the JVM when attaching a debugger and exploring just that part of the code.This happens because the debugger calls toString() on the buffer object as part of its rendering of the currentstack frame. The toString() method access the buffer contents, which is an unmapped region of memory,and boom!",0
[hotfix] [tests] Remove unnecessary timeouts from SingleInputGate TestsThese tests very lightweight and no longer run with any concurrency or external interactionand hence do not require any timeouts.,1
[hotfix] [tests] Network and Partition Tests pass in Testing IOManager rather than dysfunctional mock,1
[hotfix] [tests] Consolidate mocking of ResultPartition in one utility classThis also removes the use of Mockito from these classes.,1
[hotfix] [tests] Remove redundant test assertionsThese seem to be remainders of a copy/paste error.,0
"[hotfix] [tests] Move utility methods into correct test class.The methods were intended to be generic for tests across partitions and hence placed in theSubpartitionTestBase.However, the SubpartitionTestBase can only really test common contract behavior, like behavior ondisposal, finishing, and buffer reycling contracts in those cases. Producer / consumer behavioris sufficiently different between both implementations that it does not make sense at this pointto try and share the tests.",3
"[FLINK-12070] [network] Change Bounded Blocking Subpartition Implementation to Memory Mapped FilesThis commit consists of multiple steps (originally individual commits) that are squashed intoone commit after review, to form a self-contained (compiling / test passing) commit.Part 1: Make tests that were specific to pipelined (and buffer storing) implementations into the    specific test classes.    Several assumptions are tied to specific implementations of the partitions, rather than testing    required behavior:      - The availability of statistics after disposing partitions is not necessary and requires extra        effort to guarantee in certain implementations      - The fact that the number of bytes in a partition only update on consumption seems wrong and        can only apply on ""consume once"" implementations. This should not be assumed in a test base.Part 2: Make ""release parent releases readers"" test specific to pipelined partitions.    For pipelined partitions, the release call on the SubPartition causes immedately releasing the reader (view).    For bounded partitions, this is not required or even desirable, because too eager release can segfault in case    of direct byte buffers and memory mapped files.Part 3: Remove old SpillableSubpartition and SpillableSubpartitionViewPart 4: Move code specific to pipelined subpartitions into PipelinedSubpartition class.Part 5: Implement new BoundedBlockingSubpartitionPart 6: Remove no longer applicable memory release test for blocking partitionsPart 7: Add tests for BoundedBlockingSubpartition",5
[FLINK-12371][table-planner-blink] Add support for converting (NOT) IN / (NOT) EXISTS to semi / anti join (#8317)This closes #8317,1
[FLINK-12457][table-planner-blink] Remove char support in blink plannerThis closes #8379,2
[FLINK-12269][table-blink] Support Temporal Table Join in blink planner and runtimeThis closes #8302,1
[FLINK-12421][docs-zh] Synchronize the latest documentation changes (commits to 754cd71d) into Chinese documentsThis closes #8354,2
[FLINK-12495][python][client] Move PythonGatewayServer into flink-clients.This closes #8423,2
[FLINK-12493] Add step to export Hadoop classpath to docsGithub PR #8422,2
[FLINK-12164][runtime] Harden JobMasterTest against timeoutsThis closes #8388.,3
[FLINK-12301] Fix ScalaCaseClassSerializer to support value typesWe now use Scala reflection because it correctly deals with Scalalanguage features.,1
[FLINK-12159]. Enable YarnMiniCluster integration test under non-secure modeRemove setting of yarn.minicluster.fixed.portscopy yarn-site.xml to target/test-classesThis commit closes #8144.,3
[hotfix][table-planner] Port TimeIndicatorTypeInfo to table-commonThis closes #8363.,5
[FLINK-12233][hive] Support table related operations in HiveCatalogThis PR introduced HiveCatalogTable and implemented table related catalog APIs in HiveCatalog.This closes #8353.,2
[FLINK-12374][table-planner-blink] Support translation from StreamExecTableSourceScan/BatchExecTableSourceScan to StreamTransformation. (#8407),1
[FLINK-12472][yarn] Support setting attemptFailuresValidityInterval of jobs on YarnThis closes #8400.,0
[FLINK-12468][yarn] Unregister application from the YARN Resource Manager with a valid appTrackingUrl,2
[FLINK-12468][yarn] Derive HistoryServer's URL from HistoryServerOptionsThis commit derives the HistoryServer's URL from the availabe HistoryServerOptions.This closes #8396.,2
"[FLINK-12260] Slot allocation failure by taskmanager registration timeout and raceTaskExecutor registration has asynchronous process, which allows a nextretry after timeout to be processed first ahead of earlier request. Suchdelayed timed-out request can accidently unregister a valid taskmanager, whose slots are permanently not reported to job manager. Thispatch introduces ongoing task executor futures to prevent such race.",1
[FLINK-12260][tests] Speed up ResourceManagerTaskExecutorTest#testDelayedRegisterTaskExecutorUse latches instead of timeouts/sleeps to test problematic thread interleaving.This closes #8415.,0
[FLINK-12507][table-runtime-blink] Fix AsyncLookupJoin doesn't close all generated ResultFuturesThis closes #8436,0
"[Flink-11610][docs-zh] Translate the ""Examples"" page into ChineseThis closes #8384",1
[hotfix][runtime] Remove executionCanceled() and executionFailed() from ExecutionVertexThis closes #8369.,0
"[hotfix][table-planner] Extracted creation & configuration ofFrameworkConfig & RelBuilder to separate classBoth those classes should be configured for a single planning session.They are constructed of static properties, that do not change in alifecycle of TableEnvironment(e.g. TypeSystem) & dynamic (e.g. defaultpath). The newly introduced PlanningConfigurationBuilder class helps to splitthose two sets of properties.",1
"[FLINK-12469][table] Clean up catalog API on default/current databaseThis PR separates concepts of ""current database of a user session"" and ""default database of a catalog"".This closes #8390.",2
"[FLINK-12505][hive] Unify database operations to HiveCatalogBase from its subclassesCurrently each subclass of HiveCatalogBase has its own impl for catalog related database APIs and its own util class to support such impl. However, they share many common code. This PR unifies their common parts to make the code cleaner and more readable.This closes #8433.",4
[FLINK-12234][hive] Support view related operations in HiveCatalogThis PR supports view related operations in HiveCatalog and creates HiveCatalogView.This closes #8434.,2
[FLINK-12370][python][travis] Integrated Travis for Python API.Brief change log: - Added python stage for Python API CI testing. - Integrated flink-python/dev/lint-python.sh for CI testing of the Python API.This closes #8392,3
[hotfix][metrics] Exit early if not reporters are configured,5
[FLINK-11922][metrics] Support MetricReporter factories,1
[FLINK-11922][metrics] Add utils for backwards compatibility,1
[FLINK-11922][metrics] Add JMXReporterFactory,1
[FLINK-12475][tests] Include timestamp in generated log4j config,5
[FLINK-12285][test] Shut down running jobs in MiniClusterResource#shutdown(),5
[FLINK-12290][runtime] Clarify exception message,2
[FLINK-12488][metrics] Pass Status group to NetworkEnvironment,1
[hotfix][travis] Always execute e2e testsNo longer skip e2e tests if a unit/integration test fails.,0
[FLINK-11159] Allow configuration whether to fall back to savepoints for restoreCloses #8410,5
[FLINK-12463][tests] Deduplicate empty .out log file checks,2
[hotfix][tests] Don't set process variable to nullPrevents the output from being written in case of failure,0
[hotfix][tests] Removed unused field,1
[FLINK-12111][tests] Wait until TM has shut downPrevents theoretical scenarios where the job can finish because the destroy() command takes a while to take effect.,1
"[FLINK-12111][tests] Allow multiple restartsFor some reason this test could fail multiple times, instead of just once.",0
"[FLINK-12510][network] Fix deadlock in InputGatesBecause recursive calls reading from SingleInputGate or InputChannel can potentially trigger somenotifications to happen, it's better to not execute those calls under the locks in SingleInputGateand UnionInputGate.",1
[hotfix][network] Extract getInputGate and getChannel methods,1
[FLINK-12485][python] Add completeness test for Table and TableEnvironment.This closes #8439,3
[FLINK-11710][tests] Refactor SimpleSlotProvider to TestingLogicalSlotProvider,3
"[FLINK-12436][hive] Differentiate Flink database properties from Hive database propertiesThis PR adds support to differentiate Flink database properties from Hive database properties by using a Flink specific prefix for each property key, similar to how we differentiate Flink table properties from Hive table properties.This closes #8456.",2
"[FLINK-12511][table][hive] make variable 'comment' in all catalog metadata classes finalThis PR removes the default value of ""comment"" and make it final that can only be assigned value upon construction, and ends the not-so-well-designed overloaded constructors for catalog metadata classes.This closes #8457.",5
[FLINK-11945][table-runtime-blink] Support over aggregation for blink streaming runtimeThis closes #8244,1
"[FLINK-12516][travis] Use Ubuntu 16.04 LTS (Xenial) and switch to OpenJDK8 This changes the test environment from trusty to xenial which is stillsupported until 2021-04 and provides more up-to-date system libraries.Since oraclejdk8 is not available in Travis' xenial image and we can't switchto oraclejdk9 yet, this also changes the JDK to openJDK8.",4
[hotfix][tests] Use TemporaryFolder in TextInputFormatTest,3
[hotfix][refactor] Cleanup TextInputFormatTest,3
[FLINK-12287][runtime] Correct javadoc,2
[hotfix][table-common] Add a data type visitor,5
[hotfix][table-common] Add a default data type visitor,5
[hotfix][table-common] Add a default logical type visitor,2
[hotfix][table-common] Remove depecated methods in TableSchema,4
[hotfix][table-common] Add the timestamp kind to summary strings,1
[hotfix][table-common] Summarize VARCHAR(Int.MAX) to STRING,0
[hotfix][table-common] Summarize VARBINARY(Int.MAX) to BYTES,0
[FLINK-12254][table-common] Add a class to data type converter,5
[FLINK-12254][table-common] Add a logical type to data type converterThis closes #8453.,5
[hotfix][table] Add missing generics to TableFunctionDefinition,5
[FLINK-10466][build] Add flink-dist dependency to yarn-test,3
"[hotfix][build] Remove shade-plugin configuration from flink-yarn-testsThe relocations are a no-op since no dependencies are bundled, nor are any classes that are relocated referenced in this module.The dependency-reduced-pom.xml is not used by anyone, since we neither deploy or nor any other module depends on it.As such the shade-plugin configuration is not necessary here.",5
[hotfix][hive] return early in alterTable() to improve readability,1
"[FLINK-12452][table][hive] alterTable() should ensure existing base table and the new one are of the same typeCurrently all catalogs doesn't check if existing base table and the new one are of the same type in alterTable(), e.g. existing table is a view but user tries to replace it with a table. This PR adds such checks to all catalogsThis closes #8458.",2
[hotfix][docs] Update POJO serialization documentation,2
[FLINK-12508] [docs] extend section on unit testing Flink operators,1
[FLINK-12508] [docs] add documentation about MiniClusterWithClientResource,5
[hotfix] move HiveTypeUtil to util package 'org.apache.flink.table.catalog.hive.util',2
"[FLINK-12512][table-planner] Create a new instance of CostFactory, FlinkTypeSystem & FlinkTypeFactory per TableEnvironment",2
[FLINK-12549][hive] include exceptions thrown by Hive metastore client in CatalogException in HiveCatalogBase,2
[FLINK-12424] [table-planner-blink] Supports query optimization with multiple sinksThis closes #8356,1
[FLINK-12519] [table-planner-blink] Introduce transpose rules about semi/anti joinThis closes #8450,2
[hotfix][table][docs] correct `distinct operator` doc for table API.this closes #8470,2
[FLINK-12534][travis][python] Reduce the test cost for Python APIThis is close #8465,3
"[FLINK-11051][table] Add flatAggregate api on WindowGroupedTableBrief change log:- Add flatAggregate API on WindowGroupedTable. Add java and scala API. In this commit, the implementation has not been implemented.- Resolve expression and build LogicalWindowTableAggregate. TableAggregate is added to make it different from Aggregate. The two kinds of RelNode contain different semantics. For Aggregate, it represents a relational operator that eliminates duplicates and computes totals while for TableAggregate, it can output 0 or more records for a group.- Add Plan support for window table aggregate. Logical&Physical nodes and rules are added in the commit.- Add runtime support for window table aggregate. This commit reuses the code of window aggregate and adds support for window table aggregate.- Add docs for window table aggregate. Also rename Table Aggregate to FlatAggregate as it is more consistent with the API for users.This closes #8359",1
"[FLINK-12407][python] Add all table operators for align Java Table API.Brief change log: - Add all the operators except the ones that involve UDFs, such as: map/flatmap/aggregate/flatAggregate - Add test case for all operators, such as: test_aggregate, test_column_operation, test_join, test_window, test_calc etc. - Add doc for all operators - Add table_completeness test for check whether the Python Table API is aligned with the Java Table API - Add environment_completeness test for check whether the Python Enviroment is aligned with the Java Enviroment APIThis is closes #8401",3
[hotfix][python] Fix the bug of test base class runs twice,1
[FLINK-12553][table-runtime-blink] Fix bug that SqlDateTimeUtils#parseToTimeMillis doesn't parse millisecond correctlyThis closes #8483,5
[FLINK-12560][docs] Documentation language build flagsThis closes #8489,2
[FLINK-12552][table]: Combine HiveCatalog and GenericHiveMetastoreCatalogThis PR is to combine GenericHiveMetastoreCatalog and HiveCatalog into one single class.This closes #8480.,2
[FLINK-12496][table-planner-blink] Support translation from StreamExecGroupWindowAggregate to StreamTransformationThis closes #8462,1
[hotfix][table] Reformat method signature of GenericInMemoryCatalog,2
"[FLINK-12580][hive] Rename GenericHiveMetastoreCatalogTest to HiveCatalogFlinkMetadataTest, and HiveCatalogTest to HiveCatalogHiveMetadataTestThis PR renames GenericHiveMetastoreCatalogTest to HiveCatalogGenericMetadataTest, and HiveCatalogTest to HiveCatalogHiveMetadataTest, since we unified GenericHiveMetastoreCatalog and HiveCatalog into a new HiveCatalog.This closes #8504.",2
[FLINK-12524] [table-planner-blink] Introduce CalcRankTransposeRule & RankNumberColumnRemoveRuleThis closes #8460,4
"[FLINK-12509] [table-planner-blink] Introduce planner rules about non semi/anti join, which includes: 1. `JoinConditionEqualityTransferRule` that converts conditions to the left or right table's own independent filter as much as possible.2. `JoinConditionTypeCoerceRule` to that coerces the both sides of EQUALS(`=`) operator in Join condition to the same type while sans nullability.3. `JoinDependentConditionDerivationRule` that extracts some sub-conditions in the Join OR condition which can be pushed into join's inputs further by FlinkFilterJoinRule.4. `JoinDeriveNullFilterRule` that filters null values before join if the count of null value exceeds some threshold. This closes #8440",2
[FLINK-12241][hive] Support Flink functions in catalog function APIs of HiveCatalogThis PR adds support for Flink functions in HiveCatalog.This closes #8503.,2
"[FLINK-12478, FLINK-12480][runtime] Introduce mailbox to StreamTask main-loop.This closes #8409.This closes #8431.This also decomposes monolithic run-loops in StreamTask implementations into step-wise calls.",1
[FLINK-12483][runtime] Support (legacy) SourceFunction as special case in the mailbox model for stream tasks.This closes #8442.,1
[FLINK-12578][build] Use https URL for Maven repositoriesMapR repositories are excluded from this change as there appears to be some certificate issue on the MapR side. The latest documentation (https://mapr.com/docs/61/DevelopmentGuide/MavenArtifacts.html) also recommends using the http url.,1
[FLINK-12439][python] Add FileSystem Connector with CSV format support in Python Table APIBrief change log: - Add all of the existing descriptor interfaces align Java Table API. - Add FileSystem connector and OldCsv format support. - The `schema(..)` of OldCsv will be added in FLINK-12588.This closes #8488,2
[hotfix][tests][network] Introduce SingleInputGateBuilder for creation of SingleInputGate in tests,3
[hotfix][tests][network] Introduce ResultPartitionBuilder for creation of ResultPartition in tests,3
[hotfix][tests][network] Introduce InputChannelBuilder for creation of InputChannels in tests,3
[hotfix][tests][network] Introduce NetworkEnvironment.create factory method,1
[hotfix][network] Introduce ResultPartitionFactory,0
[hotfix][network] Introduce SingleInputGateFactory,0
[hotfix][network] Introduce MemorySegmentProvider for RemoteInputChannel to assign exclusive segments,1
[hotfix][network] Move MemorySegmentProvider from SingleInputGate to RemoteInputChannel,1
[FLINK-12331][network] Refactor NetworkEnvironment#setupPartition() to ResultPartitionWriter#setup()Move partition setup from NetworkEnvironment to ResultPartition.This eliminates tie between Task and NetworkEnvironment.Task does not need depend on NetworkEnvironmentand can trigger setup from ResultPartitionWriter interface.,1
[FLINK-12331][network] Refactor NetworkEnvironment#setupInputGate() to InputGate#setup()Move input gate setup from NetworkEnvironment to InputGate.This eliminates tie between Task and NetworkEnvironment.Task does not need depend on NetworkEnvironmentand can trigger setup from InputGate directly.,1
[FLINK-12566][table] Remove row interval typeThis closes #8497.,4
[FLINK-12447][build] Set minimum maven version to 3.1.1,5
[FLINK-12539] [fs-connector] Make StreamingFileSink customizable (#8469),2
[hotfix][hive] unify instantiateHiveDatabase() in HiveCatalog,2
[FLINK-12335][table-runtime-blink] Improvement the code and performance of class SegmentsUtilThis closes #8278,1
"[FLINK-12582][table][hive] Alteration APIs in catalogs should check existing object and new object are of the same classThis PR supports alterations in catalogs to check existing object and new object are of the same class.Most of them currently don't, e.g. you can alter an existing generic table with a new hive table in GenericInMemoryCatalog.This closes #8514.",2
[FLINK-12559][table-planner-blink] Introduce metadata handlers on window aggregateThis closes #8487,0
[FLINK-12563][table-runtime-blink] Introduce vector data format in blinkThis closes #8492,2
[FLINK-12411][table-planner][tests] Workaround limited support of not nullable fields in window aggregationThis does not fix the problem. It just makes the e2e test pass. For aproper fix of the underlying problem see FLINK-12249.,2
[hotfix][table-common] Add default precision temporal data types,5
[hotfix][table-common] Add assumption about expressions and data types,5
[hotfix][table-common] Fix equality of data types with same conversion class,5
[hotfix][table-common] Add logical type check utilities,2
[hotfix][table-common] Fix invalid class to data type conversion,5
[FLINK-12254][table-common] Add a converter between old type information behavior and data type,5
[FLINK-12181][runtime] Port ExecutionGraphRestartTest to new codebase,1
[FLINK-12586][optimizer] Reverse stderr/stdout order,2
[hotfix][docs] Correct documentation of ExEnv#fromElements,2
[FLINK-12497][network] Move ConnectionManager#start arguments to constructor,4
[hotfix] fix typos.1. [flink-core] below -> above in TypeInformation methods2. [flink-streaming-java] CLusterUtil -> ClusterUtil in LocalStreamEnvironment methods,2
[FLINK-12254][table] Update TableSchema to new type system,5
[hotfix][connector-hive] Fix Hive type mapping to Table API type information,5
[hotfix][core] Delete unused config option jobmanager.resourcemanager.reconnect-interval,5
[hotfix][runtime] Fix checkstyle violations in RestartStrategyFactory,0
"[hotfix][runtime] Move scheduling-related classes to new packageMove SchedulerNG, SchedulerNGFactory, and its implementations to packageorg.apache.flink.runtime.scheduler.",2
"[FLINK-12432][runtime] Add SchedulerNG stub implementationAdd new SchedulerNG stub implementation, which will represents the futuredefault scheduler.Add feature toggle to switch between existing scheduler and stubimplementation.Add ThrowingRestartStrategy to validate that in new scheduling code paths, thelegacy restart strategies are not used.This closes #8452.",1
[FLINK-12127][network] Consolidate network options in NetworkEnvironmentOptions,1
"[hotfix][network,tests] Add new unit tests for ResultPartitionManager#createSubpartitionViewIt is necessary to make sure PartitionNotFoundException is thrown on producer side for flip1, so some new tests are added to cover the casesof creating subpartition view via ResultPartitionManager for registered/unregistered partitions.",1
"[hotfix][network,tests] Add new unit tests for PartitionRequestServerHandlerIt is necessary to make sure the network server would not transform or swallow the PartitionNotFoundException thrown by ResultPartitionManager, so a new unit testis added for PartitionReuqestServerHandler to cover this case.",0
"[hotfix][network,tests] Add new unit test for LocalInputChannel#requestSubpartitionIt is necessary for flip1 to make sure the PartitionNotFoundException would be thrown by LocalInputChannel#requestSubpartition if the partitionwas not registered in ResultPartitionManager before. So a new unit test is added to cover this case.",1
[hotfix][network] Introduce PartititonRequestClient interface for creating simple client instance in tests,3
"[hotfix][network,tests] Add new unit test for RemoteInputChannel#retriggerSubpartitionRequestIt is necessary for flip1 to make sure the PartitionNotFoundException would be setted on the RemoteInputChannel while retriggering partition request,so a new unit test is added to cover this case.",1
"[hotfix][coordination] Refactor PartitionException to PartitionUpdateExceptionThe current usage of PartitionException is only for describing the RPC of update parttitions failed, so the exception rename would not have any other effects.In flip1 PartitionException is used for presenting all the cases that indicate to restart the producer while the consumer failed.",0
"[FLINK-6227][network] Introduce PartitionException to indicate restarting producer on JM sideThe new proposed PartitionException would cover all the cases of consuming partition failure which causes consumer failed, then JM decides to restart the producer based on this exception.[FLINK-6227][network] (part 2)Make current PartitionNotFoundException extend PartitionExceptionThis closes #8242.",1
"[FLINK-12458][network] Introduce PartitionConnectionException for unreachable producerIf the consumer can not establish a connection to remote task executor while requesting remote subpartition, which might indicate the remote task executor is not reachable.We could wrap this connection exception into new proposed PartitionConnectionException which also extends PartitionException, then the job master would decide whether torestart the upstream region to re-producer partition data.This closes #8509.",5
[FLINK-12236][hive] Support Hive function in HiveCatalogThis PR creates HiveCatalogFunction class and adds support for Hive function operations in HiveCatalog.This closes #8507.,2
[FLINK-12235][hive] Support partition related operations in HiveCatalogThis PR adds support for Hive partitions in HiveCatalog.This closes #8449.,2
[FLINK-12592][python] Add `--force` for python install.This closes #8525,1
[FLINK-12299][streaming] Reject negative auto watermark interval,2
[FLINK-12570][network] Work against ResultPartitionWriter interfaceThis part of Shuffle API refactoring: make task not depend on theconcrete implementation of ResultPartitionWriter (ResultPartition).,1
[hotfix][travis] Run e2e tests in test stage,3
[hotfix][travis] Move 404 link check to test stage,3
[FLINK-12591][test] Fix synchronization issue in StatsDReporterTest,3
[hotfix][docs] fix config.zh.md file path errorThis is closes #8528,0
[FLINK-11476] [SQL/TABLE] Create CatalogManager to manage multiple catalogs and encapsulate Calcite schema,2
[FLINK-11476][table] Integrated CatalogManager with TableEnvironmentIn this commit both registration & tables lookup go through CatalogManager with respect to the current default  catalog & database. It is not decoupled from Calcite yet. The next step will be to register the CatalogTables built exclusively in the table api rather than converted already to the Calcite's Tables.This closes #8404,2
[FLINK-12408][python] Allow to define the data types in PythonThis closes #8420,5
[FLINK-12473][ml] Add ML pipeline and MLlib interfaceThis closes #8402,1
[FLINK-12416] Fix docker build scripts on Flink-1.8This closes #8391.,2
[FLINK-12575][table-planner-blink] Introduce planner rules to remove redundant shuffle and collationThis closes #8499i#refactor satisfyTraits method,4
[FLINK-12167] Reset context classloader in run and getOptimizedPlanThis closes #8154.,1
[FLINK-12152] Make the vcore that Application Master used configurable for Flink on YARNThis closes #8438.,2
[FLINK-11126][YARN][security] Filter out AMRMToken in the TaskManager credentialsThis closes #7895.,2
[FLINK-12414][runtime] Implement SchedulingTopology adapter,2
[FLINK-12267][runtime] Port SimpleSlotTest to new code base,1
[FLINK-12618][build] Rework jdk.tools exclusionReplicate jdk.tools exclusion in every module that requires them.Remove exclusion from root pom to prevent side-effects.,4
[FLINK-12254][table] Update cast() and TypeLiteralExpression to new type system,5
[FLINK-12254][table] Improve documentation about the deprecated type systemThis closes #8510.,5
[FLINK-11283] Accessing the key when processing connected keyed stream,2
[FLINK-12327][python] Adds support to submit Python Table API job in CliFrontendThis closes #8472,1
"[hotfix][python]fix command error for python API doc, and function call bug in table environment.",0
[FLINK-12068][runtime] Implement region backtracking for region failover strategy,0
[FLINK-12644][travis] Setup jdk9 sticky e2e tests,3
[FLINK-12644][travis] Setup jdk9 cp/ha e2e tests,3
"[FLINK-12600][table-planner-blink] Introduce various deterministic rewriting rule, which includes:1. FlinkLimit0RemoveRule, that rewrites `limit 0` to empty Values2. FlinkRewriteSubQueryRule, that rewrites a Filter with condition: `(select count from T) > 0` to a Filter with condition: `exists(select * from T)`3. ReplaceIntersectWithSemiJoinRule, that rewrites distinct Intersect to a distinct Aggregate on a SEMI Join4. ReplaceMinusWithAntiJoinRule, that rewrites distinct Minus to a distinct Aggregate on an ANTI JoinThis closes #8520",2
[hotfix] Correct redirect from /ops/deployment/oss.html to /ops/filesystems/oss.html,5
[FLINK-12115][fs] Add support for AzureFSCheck for http enabled storage accounts in AzureFS IT testsAdd AzureFS standalone E2E test,3
[FLINK-12115][fs] Decrease dependency footprint of flink-azure-fs-hadoop,2
[FLINK-12115][fs] Add NOTICE file for flink-azure-fs-hadoopThis closes #8537.This closes #8117.,2
[FLINK-12636][rest] Fail stability test on compatible modifications,3
[FLINK-12635][rest] Move stability test to runtime-web,1
"[FLINK-12418][hive] Add input/output format and SerDeLib information when creating Hive table in HiveCatalog and add 'hive-exec' as provided dependencyTo set input/output formats and SerDe lib when creating Hive tables in HiveCatalog, so that we can access these tables later. Also added 'hive-exec' as provided dependency.This closes #8553.",1
"[FLINK-9172][sql-client][tabe] Support catalogs in SQL-Client yaml config fileThis PR adds support for basic catalog entries in SQL-Client yaml config file, adds CatalogFactory and CatalogDescriptor, and hooks them up with SQL Client thru table factory discovery service.This closes #8541.",1
[hotfix][table-common] Update CHAR and BINARY in accordance with the SQL standard,5
[hotfix][table-common] Add missing getter to TimeType,1
[hotfix][table-common] Add more logical type check utilities,2
[hotfix][table-common] Add a value to data type converter,5
[hotfix][table-common] Fix invalid class to data type conversion,5
[FLINK-12413][runtime] Implement ExecutionFailureHandler* Implement ExecutionFailureHandler* Throws exception when getting tasks or restart delay from the failure handling result when the restarting is suppressed; Renames verticesToBeRestarted to verticesToRestart* Address the comments* make verticesToRestart in FailureHandlingResult unmodifiable* Support checking for nested unrecoverable throwable; address comments,1
[FLINK-10921] [kinesis] Shard watermark synchronization in Kinesis consumer,2
"[FLINK-12610][table-planner-blink] Introduce aggregate related planner rules, which includes:1. AggregateCalcMergeRule, that recognizes Aggregate on top of a Calc and if possible aggregate through the calc or removes the calc2. AggregateReduceGroupingRule, that reduces unless grouping columns3. PruneAggregateCallRule, that removes unreferenced AggregateCall from Aggregate4. FlinkAggregateRemoveRule, that is copied from Calcite's AggregateRemoveRule, and supports SUM, MIN, MAX, AUXILIARY_GROUP functions in non-empty group aggregate5. FlinkAggregateJoinTransposeRule, that is copied from Calcite's AggregateJoinTransposeRule, and supports Left/Right outer join and aggregate with AUXILIARY_GROUP",1
[hotfix] Fix the version number in NOTICE and pom in table-planner-blink,2
"[FLINK-12530][network] Move Task.inputGatesById to NetworkEnvironmentTask.inputGatesById indexes SingleInputGates by id. The end user of this indexing is NetworkEnvironment for two cases:- SingleInputGate triggers producer partition readiness check and  then the successful result of check is dispatched back to this SingleInputGate by id.  We can just return a future from TaskActions.triggerPartitionProducerStateCheck.  SingleInputGate could use the future to react with re-triggering of the  partition request if the producer is ready. Then inputGatesById is not needed for dispatching.- TaskExecutor.updatePartitions uses inputGatesById to dispatch PartitionInfo update to the right SingleInputGate.  If inputGatesById is moved to NetworkEnvironment, which should be a better place for gate management,  and NetworkEnvironment.updatePartitionInfo is added then  TaskExecutor.updatePartitions could directly call NetworkEnvironment.updatePartitionInfo.Additional refactoring:- TaskActions.triggerPartitionProducerStateCheck is  separated into another interface PartitionProducerStateProvider.  TaskActions is too broad interface used also for other purposes.  Shuffle API needs only PartitionProducerStateProvider.- PartitionProducerStateProvider returns future with the ResponseHandle  which contains the producer state and accepts callbacks to cancel or fail consumption as a result of state check.- Task.triggerPartitionProducerStateCheck is also refactored into a RemoteChannelStateChecker  which becomes internal detail of NetworkEnvironment. RemoteChannelStateChecker accepts ResponseHandle,  checks whether producer is ready for consumption or aborts consumption  using ResponseHandle.cancelConsumption or ResponseHandle.failConsumption.",0
[FLINK-12440][python] Add all connector support align Java Table API.This closes #8531,1
[FLINK-6962][table] Add sql parser module and support CREATE / DROP tableThis closes #8548,4
[FLINK-12431][table-api-java] Port utility methods for extracting fields information from TypeInformation,5
"[hotfix][table-planner] Removed TableOperationConverterSupplier.Rather than passing TableOperationConverterSupplier, we just createFlinkRelBuilder whenever we need to convert from TableOperation toRelNode.",2
"[FLINK-12571][network] Make NetworkEnvironment#start() return the binded data portNetworkEnvironment#getConnectionManager is currently used for getting binded data port from ConnectionManager. Considering the general shuffle service architecture,the internal ConnectionManager in NetworkEnvironment should not be exposed to outsides. We could make ShuffleService#start return the binded data port directly ifexists, then for other cases it could return a default int value which seems no harm.This closes #8496.",5
[hotfix][network] Remove legacy private TaskEventDispatcher from NetworkEnvironment,1
[FLINK-12679][sql-client] Support 'default-database' config for catalog entries in SQL CLI yaml file,2
[FLINK-12678][table] Add AbstractCatalog to manage the common catalog name and default database name for catalogs,2
"[FLINK-12676][table][sql-client] Add descriptor, validator, and factory of GenericInMemoryCatalog for table discovery serviceThis closes #8567.",2
"[FLINK-12649][hive] Add a shim layer to support multiple versions of Hive MetastoreTo add shim layer for HMS client, in order to support different versions of HMS.This closes #8564.",1
"[FLINK-12564][network] Remove ResultPartitionWriter#getBufferProvider()* [FLINK-12564][network] Refactor the method of getBufferProvider to getBufferBuilder in ResultPartitionWriterResultPartitionWriter#getBufferProvider seems not very general for all the writer implementations. The key point is to request a BufferBuilderfrom the BufferProvider, so this method is refactored into getBufferBuilder directly. Then the internal components of ResultPartitionWriter instancewould not be exposed to outside.* [fixup] Remove getBufferProvider from ResultPartition",1
"[FLINK-12642][network][metrics] Fix In/OutputBufferPoolUsageGauge failure with NPEThe result partition metrics are initialised before `ResultPartitiion#setup` was called. If a reporter tries to access a In/OutputBufferPoolUsageGauge in between it will fail with an `NullPointerException` since the `BufferPool` of the partition is still `null`. Currently, the quick fix is to return zero metrics until the `BufferPool` is initialised. When we have a single-threaded access from `Task#run`, we can merge partition/gate create and setup then it should not be the case anymore.",1
[hotfix][hive] make hive-metastore dependency scope to 'provided' as pre-requisite to support multiple hive versionsThis closes #8560.,1
[hotfix][hive] remove jdo-api dependency from profile hive-1.2.1 in flink-connector-hive,2
[hotfix][hive] move hive metastore client and shim related classes to package 'org.apache.flink.table.catalog.hive.client',2
[hotfix] remove extra spaces in project's pom.xml,5
[FLINK-12688] [state] Make serializer lazy initialization thread safe in StateDescriptorThis closes #8570.,5
[FLINK-12409][python] Adds from_elements in TableEnvironmentNote: Currently only flink planner is supported. The blink planner will be supported after the planner discovery is supported which is part of the work of FLIP32.This closes #8474,1
[FLINK-12689][dist] Add flink-azure-fs-hadoop dependency to flink-distThis closes #8590.,2
[hotfix][docs] Remove space in variable name,4
[FLINK-12687][table-runtime-blink] ByteHashSet is always in dense modeThis closes #8579,1
[FLINK-12229][runtime] Add LazyFromSourcesSchedulingStrategyThe LazyFromSourcesSchedulingStrategy encapsulates Flink's basic batch scheduling strategy.It starts scheduling the source vertices and schedules consumers as soon as their input resultpartitions become consumable. For pipelined result partitions this is the case once a recordhas been produced whereas for blocking result partitions all producers need to finish.This closes #8309.,5
[FLINK-12547][blob] Add connection and socket timeouts for the blob clientThis closes #8484.,1
[hotfix][hive] include jdo-api for hive-metastore to enable tests for profile hive-1.2.1,2
[FLINK-12568][hive] Implement OutputFormat to write Hive tablesThis closes #8536.,2
"[FLINK-12712][table] deprecate ExternalCatalog and its subclasses and implsThis PR deprecates `ExternalCatalog` and its subclasses, implementations, and related util classes.This closes #8600.",2
"[FLINK-12713][table] deprecate descriptor, validator, and factory of ExternalCatalogThis closes #8601.",2
[FLINK-12601][table] Wrapping DataStream & DataSet asTableOperations.We do not store the DataStream & DataSet as Calcite's Tables anymore. Wetreat them as inline operations. When converting from TableOperations toRelNodes we directly create a special kind of DataStream/SetScan thatdoes not access the catalog.This closes #8521,2
[hotfix][table-api] Port TableSource specific descriptors,0
[hotfix][table-planner] Fix getting external catalog,2
[FLINK-12604][table] Register a TableSource/Sink directly as CatalogTablesThis closes #8549,2
[hotfix][tests] Refactor the creation of InputGate for StreamNetworkBenchmarkEnvironment,1
"[FLINK-12201][network,metrics] Introduce InputGateWithMetrics in Task to increment numBytesIn metricIncrementing of numBytesIn metric in SingleInputGate does not depend on shuffle service and can be moved out of networkinternals into Task. Task could wrap InputGate provided by ShuffleService with InputGateWithMetrics which would incrementnumBytesIn metric.",1
"[hotfix][network] Drop redundant getSizeUnsafe from Buffer interfaceThe implementations of getSize and getSizeUnsafe are exactly the same now, which do not need the synchronized way.So We could remove the getSizeUnsafe to make it clean and clear.",4
[FLINK-11249][kafka] Use custom serializers for NextTransactionalIdHint in 0.11 and universal FlinkKafkaProducer,2
"[FLINK-11249][kafka,test] Update Kafka migration resources with new NextTransactionalIdHint serializer",1
"[FLINK-11249][kafka] Fix migration from FlinkKafkaProducer0.11 to universalAdd backward compatibile classes to the universal FlinkKafkaProducer, so that it can restore from 0.11 checkpoints.",2
"[FLINK-11403][network] Introduce ResultPartitionWithConsumableNotifier for simplifying creation of ResultPartitionWriterThe creation of ResultPartitionWriter from NetworkEnvironment relies on TaskAction, ResultPartitionConsumableNotifier. For breaking this tie, ResultPartitionWithConsumableNotifier is introduced for wrapping the logic of notification.In this way the later interface method ShuffleService#createResultPartitionWriter would be simple.This closes #7549.",1
[FLINK-12572][hive]Implement HiveInputFormat to read Hive tablesImplement HiveInputFormat to read data from Hive non-partition/partition tables.This closes #8522.,5
[hotfix][core] Add notice about TypeSerializerSnapshot serialization,1
[FLINK-12726][table-common] Fix ANY type serializationThis closes #8612.,0
[FLINK-12254][table] Update TableSource and related interfaces to new type system,5
[FLINK-12254][table] Update TableSink and related interfaces to new type systemThis closes #8596.,5
[hotfix][e2e] Refactor batch wordcount test to use different source types,1
[FLINK-12556][e2e] Add read-only test FileSystem for end-to-end tests,3
[hotfix][e2e] Refactor yarn kerberos test: setup Flink config by one command,5
[hotfix][e2e] Refactor yarn kerberos test: use retry_times to start hadoop cluster,1
[hotfix][e2e] Refactor yarn kerberos test: move Flink tarball creation to a later test step (just before when it's needed),3
[hotfix][e2e] Refactor yarn kerberos test: group and generalize expected result checks,3
[hotfix][e2e] Refactor yarn kerberos test: move logs copying and printing into a separate function,1
[hotfix][e2e] Refactor docker embedded job test: use pushd/popd instead of cd,1
[FLINK-12556][e2e] Add some end-to-end tests with custom (input) file system plugin,5
[FLINK-12650][docs] Redirect Users to Documentation Homepage if Requested Resource Does Not Exist,2
"[hotfix][chck] Remove Nullable annotation from method with primitive return typeZooKeeperStateHandleStore#releaseAndTryRemove returns a primitive boolean and, thus,does not need a @Nullable annotation.",4
[hotfix] Fix the typo issue,0
"[FLINK-12603][network] Remove getOwningTaskName method from InputGateIn order to make abstract InputGate simple for extending new implementations in shuffle service architecture, we could remove unnecessary methods from it.InputGate#getOwningTaskName is only used for debugging log in BarrierBuffer and StreamInputProcessor. This task name could also be generated in StreamTaskvia Environment#getTaskInfo and Environment#getExecutionId. Then it could be passed into the constructors of BarrierBuffer/StreamInputProcessor for use.This closes #8529.",1
[hotfix][network] Fix JavaDoc of the InputGate,2
"[hotfix][network] Simplify SingleInputGate#isFinishedPrevious implementation of #isFinished was not only checking whether the input gate is finished, but also if it wasclosed. This commit simplifies #isFinished to just check whether the input gate is finished. The only difference is thatthe following scenario:inputGate.close()inputGate.isFinished() (2)before this change (2) would return true, now it will return false. This potentially could berelevant, because TaskCanceller is calling InputGate#close, however it doesn't relay on #isFinished().Any InputGate's user after accessing InputGate#get/pollNextBufferOrEvent would still get anIllegalStateException(""Released"") both before and after this change, so changing/simplifying #isFinished()implementation from ""isFinishedOrClosed()"" as it was before to just ""isFinished()"" shouldn't matter.",5
[hotfix][network] Define AsyncDataInput interfaceThis is intendend as a common base for couple of classes in the following commits.,5
[hotfix][test] Do not hide original exception in BarrierTrackerTest,3
[hotfix][test] Deduplicate code in BarrerTrackerTest,3
[hotfix][test] Deduplicate code in BarrierBufferTestBase,3
[FLINK-12535][network] Make CheckpointBarrierHandler non-blocking,0
[FLINK-12535][test] Drop deprecated blocking CheckpointBarrierHandler#getNext method,0
[hotfix][network] Simplify UnionInputGate#isFinished,5
"[hotfix][network] Fix InputGate#isAvailable not completed while InputGate#isFinished is trueFinished InputGates should be available for reading, otherwise reader can deadlock waiting ona future that won't be completed ever.",5
[FLINK-12490][network] Introduce Input interface,2
[FLINK-12490][network] Implement NetworkInput and use it in StreamInputProcessor,1
[hotfix][operator] Reorder if conditions in StreamInputProcessorMake the most commonly expected condition the first one.,1
[hotfix][operator] Remove unused field in StreamInputProcessor,1
[FLINK-12254][table] Update value literals to new type system,5
[FLINK-12254][table] Port and deprecate old types listingThis closes #8581.,2
"[FLINK-12476] [State TTL] Consider setting a default background cleanup strategy in StateTtlConfigAt the moment we have two efficient background cleanup strategies: incremental for heap and compaction filter for RocksDB. StateTtlConfig has 2 methods to activate them: cleanupIncrementally and cleanupInRocksdbCompactFilter. Each is activated only for certain backend type and inactive for other. They have different tuning parameters.The idea is to add method cleanupInBackground which would activate default background cleanup. User does not need to think then about details or used backend if not needed. Depending on actually used backend, the corresponding cleanup will kick in. If original strategy is not set with cleanupIncrementally and cleanupInRocksdbCompactFilter then backends should check whether default background cleanup is activated and if so, use it with default parameters.We can also deprecate the parameterless cleanupInRocksdbCompactFilter() in favour of this new method.This closes #8459.",1
[FLINK-12734][table-planner-blink] remove getVolcanoPlanner method from FlinkOptimizeContext and make RelNodeBlock not depend on TableEnvironmentThis closes #8619,1
[hotfix][yarn][tests] Remove unused field,1
[FLINK-12445][yarn] Disable test timeout,3
[FLINK-12614][yarn] Refactor test to not do assertions in @After methods,3
[hotfix][network] Move partition release under registeredPartitions modification lock in ResultPartitionManager.onConsumedPartition,4
[FLINK-12673][network] Introduce NetworkEnvironment.getUnreleasedPartitions instead of using getResultPartitionManager,1
[FLINK-11391] Introduce shuffle master interfaceIntroduce PartitionLocation in NettyShuffleDescriptor and NettyShuffleDescriptorBuilder for testsAdd ShuffleDescriptor.getResultPartitionID and isUnknownUse NettyShuffleDescriptorBuilder in StreamNetworkBenchmarkEnvironmentIntroduce ShuffleUtils.applyWithShuffleTypeCheck to isolate inout channel shuffle descriptor 'known' check and castThis closes #8362.,1
[hotfix] Fix flink-sql-parser can't compile with scala 2.12,2
[FLINK-12683] Provide task manager location information for checkpoint coordinator specific log messages,2
[FLINK-12683][chkpt] Simplify task manager location info generation for logging statementsThis closes #8580.,2
[FLINK-12101] Race condition when concurrently running uploaded jars via REST,1
[FLINK-12101] Deduplicate code by introducing ExecutionEnvironment#resolveFactoryExecutionEnvironment#resolveFactory selects between the thread local and the global factory.This method is used by the ExecutionEnvironment as well as the StreamExecutionEnvironment.This closes #8543.,1
[FLINK-12715][hive] fix Hive-1.2.1 buildThis PR fixes hive-1.2.1 build. The build was broken because some util method used in FLINK-12568 is not compatible in Hive-2.3.4 and Hive-1.2.1.This closes #8610.,2
[FLINK-12756][hive] migrate HiveCatalog from TypeInformation-based old type system to DataType-based new type systemThis PR migrates HiveCatalog from TypeInformation-based old type system to DataType-based new type systemThis closes #8639.,5
[hotfix][hive] make HiveCatalog's HiveConf and client wrapper private,5
[FLINK-12737][table-api][table-planner] Port TemporalTableFunctionImpl to java-api module,1
[FLINK-12737][table-planner] Generate unique attributes for aggregationswithin a single operation rather than globally per TableEnvironment,2
[FLINK-12737][table-planner] Remove getRelNode from TableImpl.,1
[FLINK-12737][table-api][table-planner] Added insertInto method to TableEnvironment,1
[FLINK-12718][hive] allow users to specify hive-site.xml location to configure hive metastore client in HiveCatalogThis PR enables users to specify the path of hive-site.xml file as param to build a HiveCatalog. hive-site.xml is a standard way of configuring Hive client. Configs in hive-site is a superset of the config hive.metastore.uris which we currently use to config HiveCatalog.This closes #8616.,2
"[FLINK-12386][hive] Support mapping BinaryType, VarBinaryType, CharType, VarCharType, and DecimalType between Flink and Hive in HiveCatalogThis PR enables mapping BinaryType, VarBinaryType, CharType, VarCharType, and DecimalType between Flink and Hive in HiveCatalog, such that HiveCatalog can persist tables of these types in Hive metastore and later read them.This closes #8645.",2
[hotfix][hive] categorize primitive type conversions with AtomicDataType,5
[hotfix][tests] refactor StandaloneJobClusterConfigurationParserFactoryTest to use temporary folder for global Flink configuration,5
[FLINK-12617] [container] StandaloneJobClusterEntrypoint defaults to random JobID for non-HA setupsThis closes #8539.,1
[FLINK-12643][runtime] Implement ExecutionGraph to FailoverTopology Adapter,2
[FLINK-12775][build] Bump flink-shaded version to 7.0,2
"[hotfix][datastream, core] Move StreamTransformation to flink-core",2
[hotfix][table-api] Rename TableOperation to QueryTableOperation,0
[hotfix][table-api] Renamed methods of TableOperationsVisitor,0
"[FLINK-12690][table-api] Introduce a Planner interfaceThe Planner interface separates parsing, optimization & translating froma relational QueryTableOperation representation into a runnable graph ofStreamTransformations. This enables switching between differentimplementations of the planner in a TableEnvironment.",0
[FLINK-12769][table-common] Introduce a symbol type,2
[FLINK-12769][table-common] Simplify expression design for symbolsThis closes #8651.,2
[hotfix][table-common] Introduce an across-catalog object identifier,2
[FLINK-12254][table] Update field references to new type systemThis closes #8655.,5
[hotfix][table] Rename to ValueLiteralExpession.getOutputDataType,5
[hotfix][table] Rename to TypeLiteralExpession.getOutputDataType,5
[FLINK-12513][e2e] Delegate Flink lib folder clean up to the test runner,1
[FLINK-12513][e2e] Introduce on exit callback registry,1
[hotfix][e2e] Add retries for downloading Kafka distribution,1
[hotfix][e2e] Refactoring Flink config edits,2
[hotfix] Fix typo in javadoc of StateSnapshotContextSynchronousImplThis closes #8650.,2
"[FLINK-12677][hive][sql-client] Add descriptor, validator, and factory for HiveCatalogThis PR adds descriptor, validator, and factory for HiveCatalog, and tests in flink-sql-client.This closes #8589.",2
[FLINK-12685][table-planner-blink] Supports UNNEST query in blink plannerThis closes #8578,2
[FLINK-12588][python] Add TableSchema for Python Table API.This closes #8561,1
[FLINK-12757][python] Improves the word_count example to use the descriptor APIThis closes #8641,1
[FLINK-12789][table] Fix java docs in UserDefinedAggregateFunction.This closes #8674,2
[FLINK-12780][hive] use Flink's LogicalTypeRoot for type comparison in HiveTypeUtilThis PR changes type comparisons in HiveTypeUtil to use LogicalTypeRoot of Flink's DataType.This closes #8662.,5
"[FLINK-12772][hive] Support mapping ARRAY, MAP, ROW (STRUCT) between Flink and Hive in HiveCatalogThis PR added mapping of ARRAY, MAP, ROW (STRUCT) between Flink and Hive in HiveCatalog, such that HiveCatalog can persist tables of these types in Hive metastore and later read them.This closes #8657.",2
[hotfix][table-common] Add util method to logical RowType,2
[FLINK-12443][table-planner-blink] Replace InternalType with LogicalType in blink plannerThis closes #8435.,2
[FLINK-12787][python] Allow to specify directory in option -pyfsThis closes #8671,1
[FLINK-12402][table] Make validation error message in ResolveCallByArguments more user friendly,1
[FLINK-10455][Connectors/Kafka] Ensure all the KafkaProducers closed on an exceptionThe patch fixes the bugs reported in FLINK-10445 by making sure all the KafkaProducers are closed when FlinkKafkaProducer is closed. The same fix was applied to universal FlinkKafkaProducer and FlinkKafkaProducer011.,2
[FLINK-12795][table-planner-blink] Extracted creation & configuration of FrameworkConfig & RelBuilder to separate class in blink plannerThis closes #8677,2
"[hotfix][network] Add NetworkEnviroment.fromConfiguration factory methodMove <Flink configuration> -> NetworkEnvironmentConfiguration parsing from TaskManagerServicesConfigurationto NetworkEnviroment.fromConfiguration(flinkConfiguration) factory method anduse it to create NetworkEnviroment in TaskManagerServices.This way TaskManagerServices does not depend on network internals.Memory page size is additionally parsed for TaskManagerServicesConfigurationto decouple it from NetworkEnvironmentConfiguration becausethe page size is used also for memory manager outside of NetworkEnviroment.Theoretically shuffle implementations can have their own page size in future,different from TaskManagerOptions.MEMORY_SEGMENT_SIZE.",1
[FLINK-11392][network] Introduce ShuffleEnvironment interface,2
[FLINK-11392][network] Rename NetworkEnviroment to NettyShuffleEnviromentThis closes #8608.,1
[FLINK-12178] Remove legacy SchedulerThis closes #8676.,4
[FLINK-12646][runtime] Change the test IP of RestClientTest to 240.0.0.0This closes #8663.,3
[FLINK-12583][python] Add all format support align with the Java Table API.This closes #8575,1
[FLINK-12401][table] Support incremental emit under AccRetract mode for non-window streaming FlatAggregate on Table API.This closes #8550,1
"[FLINK-11876] Introduce new InputSelectable, BoundedOneInput and BoundedMultiInput interfaces for stream operators",1
[FLINK-11877][runtime] Introduce new BarrierDiscarder class,1
[FLINK-11877][runtime] Abstract AbstractTwoInputStreamTask from TwoInputStreamTask,2
[FLINK-11877][runtime] Implement the runtime handling of the InputSelectable interface,1
[FLINK-12636] Check if proper JAR file in JobWithJars#checkJarFileThis closes #8552.,2
[hotfix][py] Fix typo in Python examplesThis closes #8705.,2
[FLINK-12727][hive] Make HiveTableOutputFormat support writing partitioned tablesThis PR adds support for writing (both static and dynamic) partitioned table in HiveTableOutputFormat.This closes #8614.,1
[FLINK-12801][table-planner-blink] Set parallelism for batch SQLThis closes #8690,1
[FLINK-11107] [state] Avoid memory stateBackend to create arbitrary folders under HA path when no checkpoint path configuredThis closes #7281.,5
"[FLINK-12708][table] Introduce InputFormatTableSource and make blink&flink planner support it1. Add a isBounded() interface to StreamTableSource, default returns false2. Introduce InputFormatTableSource extends StreamTableSource and isBounded always returns true3. InputFormatTableSource only exposes getInputFormat() interface",1
"[FLINK-12708][table] Introduce OutputFormatTableSink and make blink&flink planner support it1. Introduce OutputFormatTableSink and extends StreamTableSink and only expose getOutputFormat interface2. Add a method consumeDataStream(DataStream) to StreamTableSink which returns DataStreamSink always, and make it mandatory in Blink planner",2
[FLINK-12708][table] Introduce LookupableTableSource and make blink planner support it,1
[FLINK-12708][table] Expose getTableStats() interface in TableSource,1
[hotfix][EG] Strip CompletionException before evaluation exception typeStrip CompletionException before evaluating the exception type in ExecutionGraph#scheduleForExecution.That way CancellationExceptions which are wrapped in a CompletionException won't fail theExecutionGraph globally.,0
[FLINK-12502] Harden JobMasterTest#testRequestNextInputSplitWithDataSourceFailover,5
[FLINK-12502] Refactor JobMasterTest#testRequestNextInputSplits tests* Rename JobMasterTest#testRequestNextInputSplitsWithTaskFailover into #testRequestNextInputSplitsWithLocalFailover* Rename JobMasterTest#testRequestNextInputSplits into #testRequestNextInputSplitsWithGlobalFailover* Reduce code duplication between tests by running the same test code with different configurations* Properly check that only the failed Execution's input splits are being reset in case of local task failoverThis closes #8667.,0
[hotfix] Use proper template format substitute for Preconditions,1
[hotfix][docs] Add missing ')',1
[hotfix] Remove outdated FLINK_JOB parameter from flink-container/kubernetes/README.md,2
[FLINK-12788][container] Add support for Python jobs in build scriptThis closes #8609.,1
[hotfix][dist] Rename FLINK_ROOT*_DIR to FLINK_HOMEThe same concept of Flink's root/home directory was named in different places differently.This commit unifies the naming convention to FLINK_HOME by renaming FLINK_ROOT_DIR and FLINK_HOME_DIR to FLINK_HOME.,2
"[hotfix][dist] Export variables in only one place (config.sh)Previously exporting of variables like FLINK_CONF_DIR, FLINK_BIN_DIR, FLINK_LIB_DIR, ...was scattered or even dupliacted in multiple places. Now it happens only in config.sh.",5
[hotfix][runtime] Deduplicate and simplify environment variables handling in FlinkDistributionOverlay,2
[hotfix][core] Deduplicate code and unify method names in GlobalConfiguration,5
[FLINK-12143] Distribute FLINK_PLUGINS_DIR the same way as FLINK_LIB_DIR is distributed,2
[FLINK-12143][dist] Ship plugins in the cluster the same way as lib jars,2
[hotfix][dist] Use proper flink-python jar match pattern in pyflink.bat for Windows (FLINK-12409),2
[FLINK-12143] PluginLoader: use system level always parents first patterns in class loading,5
[FLINK-12143][e2e] Introduce plugins helper function and test cleanup,4
[FLINK-12143][e2e] Change end-to-end tests with file system to use plugins mechanism,1
[hotfix][FLINK-12830][table-planner] Fix fragile TableSinkITCase#testBoundedTableSink test,3
[FLINK-12799][table] Improve expression based TableSchema extraction from DataStream/DataSet,5
[hotfix][runtime] Fix result partition redundantly added in TestingSchedulingTopologyThis closes #8725.,3
[FLINK-12163] User correct ClassLoader for Hadoop Writable TypeInfo,5
[FLINK-12088][table-runtime-blink] Introduce unbounded streaming inner/left/right/full join operatorThis closes #8629,1
[hotfix][docs] Minor clarification,2
[FLINK-12667][runtime] Add JobID to TaskExecutorGateway#releasePartitions,1
[FLINK-12822] Add explicit transformer from SerializableOptional to OptionalThis closes #8724.,1
[FLINK-12608][runtime] Add getVertexOrThrow and getResultPartitionOrThrow to SchedulingTopologyThis closes #8603.,2
[FLINK-12372] [runtime] implement ExecutionSlotAllocatorThis closes #8486.,1
[hotfix][tests] Upgrade zookeeper package to 3.4.9-3+deb9u2,3
[hotfix][tests] SynchronousCheckpointITCase: set test run timeout limit,1
[FLINK-12313][tests] Workaround for SynchronousCheckpointITCase to avoid race condition,1
[hotfix][tests] Simplify SynchronousCheckpointITCase,3
[FLINK-12800] Harden Tests when availableProcessors is 1This closes #8716.,3
[FLINK-12670][runtime] Implement FailureRateRestartBackoffTimeStrategy* use ManualClock in unit test and add configuration descriptionThis closes #8573.,5
[FLINK-12669][runtime] Implement FixedDelayRestartBackoffTimeStrategyThis closes #8698.,0
[FLINK-12835][tests] Fix wrong conversion of ManualClock bugThis closes #8733.,0
[FLINK-12827][table-planner] Extract Optimizer from TableEnvImplThis closes #8723,4
[FLINK-12798][table-planner] Extracted the logic of converting from a Row type info to expected typeThis closes #8726,5
[FLINK-12831][table-planner][table-api-java] Split FunctionCatalog into Flink & Calcite specific partsThis closes #8729,2
[FLINK-12803][python] Correct the package name for python APIThis closes #8710,2
"Revert ""[FLINK-12143][e2e] Change end-to-end tests with file system to use plugins mechanism""This reverts commit 9e6ff81e22d6f5f04abb50ca1aea84fd2542bf9d.",4
[FLINK-12774][build] Pin build-helper-maven-plugin version to 1.7,2
[hotfix][build] Document required plugin execution order,1
[FLINK-12716][python] Add an interactive shell for Python Table APIThis closes #8675,1
"[FLINK-11059][runtime] Add slot reconciliation between JM and TEWith this commit we introduce an AllocatedSlotReport which is periodically sent from theJM to the TE. This report is then used to reconcile the JM's and the TE's view on the stateof allocated slots.Furthermore, with this commit we drop slots which could not be freed viaTaskExecutorGateway#freeSlot and instead rely on the heartbeat reconciliation logic.This closes #7227.",2
[hotfix] Fix checkstyle violations in SlotPoolImplTest,3
[FLINK-12719][python] Add the Python catalog APIThis closes #8623,2
[FLINK-12851][travis] Move gelly/kafka to separate profile,2
"Revert ""[hotfix][travis] Run pre-commit e2e tests in compile stage""This reverts commit 2f7d47300cb51bc3eff13feb9386d4ce7ce50ce8.",4
"[FLINK-12647][network] Make partition release on consumption optionalResultPartitions being released on consumption is no longer a hard-coded behavior. This is a prerequisite for making partitions consumable multiple times, without knowing ahead-of-time how often that might be. To retain the existing behavior a configurable flag was introduced to force the consumption of all release partitions, but this will likely be removed in the future.",4
[FLINK-12705][hive] Allow user to specify the Hive version in useThis PR allows users to specify hive version in the yaml file.This closes #8694.,2
[FLINK-12297] Make Java ClosureCleaner recursive to handle nested functions,1
[FLINK-12405] [runtime] Introduce BLOCKING_PERSISTENT ResultPartition type,1
[hotfix] [runtime] Improve JavaDoc comments for ResultPartitionType,2
[FLINK-12405] [DataSet] Introduce a way to generate BLOCKING_PERSISTENT ResultPartition through DataSet API,5
[hotfix] Reduce some code duplication in JobGraphGeneratorTest,3
"[hotfix] Small code cleanups for Persistent Intermediate Results  - Make explicit that BlockingShuffleOutputFormat is only used for tagging, so its methods should never be invoked.  - Add serialVersionUid for consistency with other formats  - Move adjustment of JobGraph into separate helper method in JobGraphGenerator  - Fix use of generics in JobGraphGeneratorTest  - Make test more targeted, i.e., remove checks/assertions that are unrelated.",3
[hotfix][tests] remove rogue comment in common_ssl.sh,4
"[hotfix][docs] make LineBreakElement also implement InlineElementThis allows line breaks in text block elements and may be useful, for example,in starting a new line inside a list description element.",1
[FLINK-12838][network] netty-fy SSL configurationRefactor the SSL configuration done for Netty to have it more like the wayNetty intends it to be: using its SslContextBuilder. This will make it mucheasier to set a different Netty SSL engine provider.[hotfix][network] extract key and trust manager factory creation,1
"[FLINK-9816][network] allow configuring the SSL engine provider[FLINK-9816][network][tests] add openSSL-based SSL tests if available[FLINK-9816][network] use OpenSslX509KeyManagerFactory for openSSL back-endAccording to https://netty.io/news/2018/07/10/4-1-26-Final.html, this willvastly reduce handshake latency and CPU use.[FLINK-9816][network][tests] allow forcing openSSL tests to runFor forcing openSSL tests to run (or fail if not available), specify thefollowing system property: '-D flink.tests.force-openssl'",3
"[FLINK-12839][dist] package flink-shaded-netty-tcnative-dynamic into opt/Please note that there is also a static version of netty-tcnative but wecurrently do not distribute it due to licensing issues. Once openSSL completesits switch to Apache License v2, we can provide this as well and maybe evenmake that one default (by putting it into lib/). Since there are to many thingswhich may go wrong with the dynamically-linked library (based on the system yourun on), we provide this only in opt/.",1
[FLINK-12517][tests] enable openSSL tests via openSSL-enhanced flink-shaded versionThis uses the dynamically-linked openSSL for the unit tests since this is theartifact that we distribute.TODO: e2e tests for dynamically and statically linked openSSL,2
"[FLINK-12518][tests][e2e] enable openSSL for test_streaming_file_sinkThis test (run nightly) will use a dynamically or statically linked openSSLlibrary at random during runtime, in order to eventually verify both.",1
[hotfix][docs] correctly escape ampersands,2
"[FLINK-12446][docs] update openSSL option documentationMention all steps necessary  to get openSSL-based SSL running, based onflink-shaded 7.0.",2
[FLINK-12857][table-common] move FilterableTableSource into flink-table-commonThis closes #8748,2
[FLINK-12742][table-planner] Add insert into partition grammar as hive dialect,1
FLINK-1722][datastream] Enable the InitializeOnMaster and FinalizeOnMaster interfaces on datastream,5
[FLINK-12823][datastream] Add ShuffleMode property to PartitionTransformationThis also wires the property all the way through to the JobGraph.,5
[hotfix][akka] Replace deprecated ExtensionKeyThis closes #8752.,0
[FLINK-12824][table-planner-blink] Set parallelism for stream SQLThis closes #8718,1
[FLINK-12806] Remove beta feature remark from the Universal Kafka connector,4
[hotfix][table-common] Move function definitions to functions package,1
[FLINK-12871][docs] fix separate keypass not compatible with PKCS12 stores,4
[FLINK-12711][table] Refactor function lookup,1
[FLINK-12853][table-api][table-planner] TableSourceUtils#validateTableSource method to common moduleThis closes #8739,5
[FLINK-12657][hive] Integrate Flink with Hive UDFThis PR integrates Flink with Hive UDF.This closes #8700.,2
[FLINK-12779][table] Avoid field conflicts when generate field names for non-composite TypeinformationThis closes #8664,5
[FLINK-12864][python][tests] Improves the Python Table API test cases performanceThis closes #8755,3
[hotfix][python][test] fix IDE test problems and unified assertion usageThis closes #8777,1
[FLINK-12867][sql-parser] Add insert overwrite grammar as HIVE dialectThis closes #8758,1
[FLINK-12686][datastream] Remove StreamExecutionEnvironment from StreamNode,4
[FLINK-12686][datastream] Remove StreamExecutionEnvironment from StreamGraph,4
[FLINK-12686][datastream] Remove StreamExecutionEnvironment from StreamGraphGenerator,4
[FLINK-12686][datastream] Add StreamExecutionEnvironment.getStreamGraph(name),1
[FLINK-12686][datastream] Configure co-location group of iteration nodes in StreamGraph instread of in StreamingJobGraphGenerator,5
[FLINK-12832][datastream] Make slot sharing configurable in StreamGraphGenerator,5
[FLINK-12832][datastream] Make ScheduleMode configurable in StreamGraphGenerator,5
[FLINK-12832][datastream] Use new StreamGraphGenerator configurability in Blink Table Runner,1
[FLINK-12711][table] Separate function implementation and definitionThis closes #8661.,5
"[FLINK-12875][hive] support converting input args of char, varchar, bytes, timestamp, date for Hive functionsThis PR adds support for converting input args of char, varchar, bytes, timestamp, date for Hive functions.This closes #8769.",1
[FLINK-12892][table][hive] serialize catalog table to properties for table discovery serviceThis PR enables serialization of catalog table to properties for table discovery service and table factory to initiate source/sink from those properties.This closes #8784.,5
[FLINK-12874][table-common] Improve the semantics of zero length stringsThis closes #8781.,1
[FLINK-12878][travis] Move flink-table-planner-blink & flink-table-runtime-blink to separate profileThis closes #8772,2
[FLINK-12364] Introduce CheckpointFailureManager for centralized checkpoint failure handling,0
[FLINK-12720][python][docs] Add the Python Table API Sphinx docsThis closes #8774,2
[hotfix][table] Replace constructor of expressions with util calls,0
[hotfix][table] Refactor expression visitors to common naming scheme,4
[FLINK-12710][table] Rename CallExpression to UnresolvedCallExpression,0
[FLINK-12710][table] Rename ApiExpressionUtils.call() to unresolvedCall(),0
[hotfix][table] Add a summary method to expressions,1
[FLINK-12862][coordination] Remove legacy QuarantineHandler/-Monitor,0
[FLINK-12861][coordination] Remove legacy ListeningBehaviour,4
[FLINK-12143][runtime] Workaround for dynamic class loading in FS creation: set thread context class loader to plugin's class loader,1
"Revert ""Revert ""[FLINK-12143][e2e] Change end-to-end tests with file system to use plugins mechanism""""This reverts commit 24246b8ddb53ddd6062cef36c391b6c377419840.",5
[FLINK-10984][build] Remove flink-shaded-hadoop(-uber) modules,2
[FLINK-12257][table-api][table-planner] Instantiate TableSource from CatalogTableThis closes #8634,2
[hotfix][streaming] Report correct value of currentProcessingTime in the exceptionPreviously the actual and reported values were always of by small margin.,0
"[hotfix][network][tests] Add new unit tests for ReleaseOnConsumptionResultPartitionThe process of ReleaseOnConsumptionResultPartition#onConsumedSubpartition was not covered by unit tests before, so adding a new test for it.",3
"[FLINK-12843][network] Refactor the pin logic in ReleaseOnConsumptionResultPartitionThe pin logic is for adding the reference counter based on number of subpartitions for ReleaseOnConsumptionResultPartition. It seemsnot necessary to do it in while loop as now, because the atomic counter would not be accessed by other threads during pin. If theReleaseOnConsumptionResultPartition was not created yet, the createSubpartitionView would not be called actually resulting inPartitionNotFoundException. So we could simple increase the reference counter in ReleaseOnConsumptionResultPartition constructor directly.",1
[FLINK-12264][runtime] Remove unused methods in ExecutionGraphTestUtils,3
[FLINK-12268][runtime] Port SharedSlotsTest to new code base,1
[hotfix] Fix error message in BatchTableSourceScan & StreamTableSourceScan,0
"[FLINK-12877][table][hive] Unify catalog database implementationsThis PR unifies catalog database implementations, and remove is_generic flag.This closes #8786.",4
[FLINK-12658][hive] Integrate Flink with Hive GenericUDFThis PR integrates Flink with Hive GenericUDF.This closes #8770.,2
[hotfix] fix imports of CatalogDatabaseImpl,5
[hotfix] use CatalogDatabaseImpl in CatalogStructureBuilder,2
[hotfix][FLINK-12907][table-planner-blink] Adds override modifier to methods of MockTableSink to make scala 2.12 compiler pass,4
[FLINK-11869] Make buffer size in checkpoint stream factory configurableThis closes #8686.,5
[FLINK-11869] Improve description and variable naming for filesystem checkpoints stream write buffer size config,5
"[FLINK-11947] Support MapState value schema evolution for RocksDBCurrently, we do not attempt to perform state schema evolution if the key or value's schema of a user MapStatehas changed when using RocksDB, with this commit we support value's schema evolution for RocksDBMapState.This closes #8565.",5
[FLINK-11947] Fix exposure leak of NestedSerializerSnapshotsDelegate,0
[FLINK-11947] Improve readability and fix raw type usage for RocksDBKeyedStateBackend#migrateStateValuesThis closes #8565.,5
[FLINK-12856][table-planner-blink] Introduce planner rule to push projection into TableSourceThis closes #8747,2
[hotfix][table] fix imports of RexNodeExtractor.,4
[FLINK-12896][rest] Use JobID parameter for archiving,2
[FLINK-12896][rest] Use JobID parameter for archiving,2
[FLINK-11761] Update FlinkKafkaConsumerBaseMigrationTest for 1.8,3
[FLINK-11762] Update WindowOperatorMigrationTest for 1.8,3
[FLINK-11765] Update Java / Scala StatefulJobWBroadcastStateMigrationITCase for 1.8,5
[FLINK-11766] Update Java / Scala StatefulJobSavepointMigrationITCase for 1.8,5
[FLINK-11763] Update AbstractKeyedOperatorRestoreTestBase for 1.8,3
[FLINK-11760] Update CEPMigrationTest for 1.8,3
[FLINK-11758] Update ContinuousFileProcessingMigrationTest for 1.8,3
[FLINK-11764] Update BucketingSinkMigrationTest for Flink 1.8,2
[FLINK-11768] Update TypeSerializerSnapshotMigrationITCase for Flink 1.8,2
[FLINK-11770] Update FlinkKinesisConsumerMigrationTest for 1.8,3
[FLINK-11759] Update AbstractNonKeyedOperatorRestoreTestBase for 1.8This closes #8168.,3
[FLINK-12815] [table-planner-blink] Do not register the intermediate optimization result as a table in batch and stream CommonSubGraphBasedOptimizer,2
[FLINK-12815] [table-planner-blink] TableImpl supports QueryOperation in blink planner,2
[FLINK-12815] [table-planner-blink] Support CatalogManager in blink plannerThis closes #8707,2
[FLINK-12910][hotfix][python][tests] Fix the Python catalog test failure caused by FLINK-12877This closes #8807,2
[hotfix][network] Rename taskExecutorLocation to taskExecutorResourceId and small fixes,0
[hotfix] Convert ClassNotFoundException to FlinkException if the type implementing class is not found in InstantiationUtil.instantiate,2
[FLINK-12706] Add the ShuffleMaster factory method to ShuffleService and its default Netty implementationThis closes #8680.,1
[FLINK-12659][hive] Integrate Flink with Hive GenericUDTFThis PR integrates Flink with Hive GenericUDTF.This closes #8798.,2
[FLINK-12664][hive] Implement TableSink to write Hive tablesThis PR creates HiveTableSink to write Hive tables.This closes #8766.,1
[hotfix][python] Exclude header check for python DocsThis closes #8816,2
[hotfix][TE] Remove redundant HeartbeatManager calls,4
[hotfix] Fix checkstyle violations in SlotPoolImpl,0
"[FLINK-12863][FLINK-12865] Remove concurrency from HeartbeatManager(Sender)ImplThis commit makes the HeartbeatManager implementations to use the RpcEndpoint'smain thread executor. Furthermore, this commit changes the HeartbeatListenerinterface to directly return a payload instead of returning a future whenHeartbeatListener#retrievePayload is called.Since the HeartbeatManager implementations now use the RpcEndpoint's main thread,we remove the splicing into the RpcEndpoint's main thread in the implementationsof the HeartbeatListeners in the TaskExecutor, JobMaster and ResourceManagercomponents.* Add test case for FLINK-12863The test case JobMasterTest#testAllocatedSlotReportDoesNotContainStaleInformation verifiesthat the AllocatedSlotReport does not contain stale information. The test case itself isprobabilistic and needs to be executed several times to produce a failure.* Add test case for FLINK-12865The test case TaskExecutorTest#testSlotReportDoesNotContainStaleInformation verifiesthat the SlotReport does not contain stale information. The test case itself isprobabilistic and needs to be executed several times to produce a failure.This closes #8783.",0
[hotfix] Refactor HeartbeatManagerTest to remove SimpleTestingHeartbeatListener,3
[hotfix] Harden TaskExecutorTest#testSyncSlotsWithJobMasterByHeartbeatThe problem was that we don't wait until the JobMaster has sent its response backto the TaskExecutor when it receives the offered slots and before we send theheartbeat response with the AllocatedSlotReport. This commit fixes the problemby instrumenting the TaskSlotTable to notify the test when all slots are markedas active.,3
[FLINK-12585][python] Add ExecutionEnvironment and StreamExecutionEnvironment with basic configuration APIs which do not depends on additional classes such as ExecutionConfig.This closes #8681,5
[FLINK-12778][table] Fix derive row type bug for table aggregateThis closes #8771,0
[FLINK-12899][table] Introduce a resolved expression with data typeThis separates calls to functions into resolved and unresolved callexpressions. Unresolved expressions are created in the API and aretranslated to resolved expression. Resolved expressions are validatedand contain a return type. Table operations and planner should workwith resolved expressions only.This closes #8822.,0
"[hotfix][yarn,test] Deduplicate YarnClusterDescriptor construction in YarnClusterDescriptorTest",3
[FLINK-12868][yarn] Fix yarn cluster can not be deployed if plugins dir does not existPlugins dir should be optional and cluster deployment should not fail if it doesn't exist.,0
[FLINK-12868][mesos] Fix mesos cluster can not be deployed if plugins dir does not existPlugins dir should be optional and cluster deployment should not fail if it doesn't exist.,0
[FLINK-12868][plugins] Log warnings if the plugins directory doesn't exist,2
[FLINK-12868][plugins] Create an empty plugins directory in flink-dist,2
[FLINK-11884][table-api-java][table-planner] Port TableImpl to java-apimodule,2
[hotfix][table-planner] Drop External catalog exceptions,2
[FLINK-12798][table-planner][table-api-java] Port TableEnvironment to table-api-java moduleThis commit makes the TableEnvironments an API class. It looks upPlanner (for optimizing relation queries and converting them to aStreamTransformations) and Executor which enables to apply and runcreated transformations. This way we can decouple the unified TableEnvironmentfrom a StreamExecutionEnvironment.This closes #8764,1
[hotfix][python] Using fully qualified function names in python tests.,3
[FLINK-12891][hive] remove hadoop/hive writable from boundaries of Hive functions and FlinkThis PR removes hadoop/hive writable from boundaries of Hive functions and Flink because Flink only deals with java objects rather than hadoop/hive writables. Data is passed from Flink to Hive functions and from Hive functions back to Flink will always be simple java objects.This closes #8813.,2
[docs-sync] Synchronize the latest documentation changes (commits to 318ce571) into Chinese documents,2
"[FLINK-11612][docs-zh] Translate the ""Project Template for Java"" page into ChineseThis closes #8799",1
[FLINK-12903][py] Remove old Python APIs,4
"[FLINK-12917][hive] support complex type of array, map, struct for Hive functions",1
[FLINK-12743][table-runtime-blink] Introduce unbounded streaming anti/semi join operatorThis closes #8792,1
"[FLINK-11606][docs-zh] Translate the ""Distributed Runtime Environment"" page into ChineseThis closes #8750",1
[FLINK-12834][table-planner-blink] Support CharType and BinaryTypeThis closes #8730,2
[FLINK-11878][runtime] Implement the runtime handling of BoundedOneInput and BoundedMultiInput,1
[FLINK-12923][runtime] Introduce Task termination future,2
"[FLINK-12842][network] Fix invalid check in ReleaseOnConsumptionResultPartition#createSubpartitionViewCurrently in ReleaseOnConsumptionResultPartition#createSubpartitionView it would check whether this partition is released before creating view.But this check is based on refCnt != -1 which seems invalid, because the reference counter would not always reflect the released state. In thecase of release/fail, the reference counter is not set to -1. Even if in the case of onConsumedSubpartition, the reference counter seems also nochance to be -1. So we could check the real isReleased state during creating view instead of reference counter.",1
[hotfix][network][tests] Refactor existing tests for reusing PartitionTestUtils,3
[FLINK-12555] Introduce an encapsulated metric group layout for shuffle API and deprecate old one,2
[hotfix][network] Introduce NettyShuffleMetricFactory to encapsulate metrics creation,1
[FLINK-11480][hive] Create HiveTableFactory that creates TableSource/Sink from a Hive tableThis PR creates HiveTableFactory that creates TableSource/Sink from a Hive tableThis closes #8785.,1
"[FLINK-12964][sql client] add commented-out defaults to sql client yaml file to make it easier for users to adoptThis PR adds commented-out defaults for catalogs to sql client yaml file, to make it easier for users to adopt. This is done similar to how existing defaults of tables and functions is written.This closes #8862.",1
[FLIN-12663]Implement HiveTableSource to read Hive tablesThis PR created HiveTableSource to read Hive tables.This closes #8809.,1
[FLINK-12931][python] Fix lint-python.sh cannot find flake8,0
[hotfix][python]Use of a variable like $X instead of ${X},0
[FLINK-12920][python] Drop support of register_table_sink with parameters field_names and field_typesThis closes #8817,2
[FLINK-12807][hive]Support Hive table columnstats related operations in HiveCatalogThis PR adds support for Hive table column stats related operations in HiveCatalogThis closes #8703.,2
[FLINK-12932][table][sql client] support 'show catalogs' and 'show databases' end-2-end in TableEnvironment and SQL CLIThis PR adds 'show catalogs' and 'show databases' end-2-end functionalities in TableEnvironment and SQL CLI.This closes #8829.,1
[FLINK-12904][table-api] Remove TableSource#getTableStats() interfaceThis reverts commit 147022cf7984b8e56d1e01e826d9640674837e68This closes #8793,4
"[FLINK-12890][coordination][shuffle] Introduce ShuffleDescriptor#hasLocalResourcesShuffleDescriptor.hasLocalResources() indicates that this partition occupies local resources on TM and requires TM running to consume the produced data (e.g. true for default NettyShuffleEnviroment and false for externally stored partitions). If a partition needs external lifecycle management and is not released after the first consumption is done (ResultPartitionDeploymentDescriptor.isReleasedOnConsumption()), then RM/JM should keep TMs, which produce these partitions, running until partition still needs to be consumed. The connection to these TMs should also to be kept to issue the RPC call TaskExecutorGateway.releasePartitions once partition is not needed any more, the RPC call triggers ShuffleEnvironment.releasePartitions.",0
[FLINK-12890][coordination][shuffle] Introduce ShuffleMaster#removePartitionExternallyJM should call this whenever the partition does not need to be consumed any more.This call releases partition resources possibly occupied externally outside of TM and does not depend on ShuffleDescriptor.hasLocalResources.,4
[hotfix][shuffle] Rename ShuffleEnvironment#releasePartitions to ShuffleEnvironment#releasePartitionsLocally,0
[hotfix][config][docs] Fiy typo for `taskmanager.memory.preallocate`,2
[hotfix] [end-to-end-tests] fix test_kubernetes_embedded_job.sh and test_docker_embedded_job.sh broken by FLINK-12788,2
[hotfix][python][docs] Fix python doc nav bar not showing and layout issue.This closes #8825,0
[FLINK-12967][runtime] Change the processing that the input reaches the end to comply with the InputSelectable contract,4
[hotfix][network] Fix raw type usages,0
[FLINK-12915][tests] Don't reuse minicluster in AbstractOperatorRestoreTestBase,3
[FLINK-12913][runtime] Remove legacy InstanceManager and InstanceManagerTest,3
"[hotfix][runtime, tests] Fix checkstyle violations in TestFailoverTopology",3
[hotfix][runtime] Add @Nullable to JobVertex#getSlotSharingGroup(),1
[hotfix][runtime] Add @Nullable to ExecutionJobVertex#getSlotSharingGroup(),1
"[hotfix][runtime, tests] Fix typos in parameter namesRename parameter of SimpleAckingTaskManagerGateway#setSubmitConsumer() frompredicate to submitConsumer.Rename parameter of SimpleAckingTaskManagerGateway#setCancelConsumer() frompredicate to cancelConsumer.",1
[hotfix][runtime] Remove wrong @Nullable annotationTaskDeploymentDescriptor#getSerializedJobInformation() andTaskDeploymentDescriptor#getSerializedTaskInformation() cannot return null.,5
"[hotfix][runtime, tests] Move TestRestartBackoffTimeStrategy to separate class",3
[hotfix][runtime] Add @VisibleForTesting to Execution#markFinished(),5
[hotfix][runtime] Use FutureUtils.assertNoException in ExecutionGraph#failGlobal()Fail fatally if exception is thrown in code that runs after all tasks arecancelled otherwise the exception will be swallowed.,1
[hotfix][runtime] Extract method cancelVerticesAsync() in ExecutionGraph,4
[FLINK-12969][table-planner-blink] Remove dependencies on RelNode from TableImpl in blink planner (#8866)This closes #8866,2
[FLINK-12888] [table-planner-blink] remove FunctionCatalog in blink planner and use FunctionCatalog in flink-table-api-java,2
[FLINK-12888] [table-planner-blink] Introduce planner rule to push filter into TableSourceThis closes #8782,2
[FLINK-12975][table-planner-blink] UserDefinedFunctionUtils should distinguish overload any parameters methodsThis closes #8869,2
[FLINK-12933][sql client] support 'use catalog' and 'use database' in SQL CLIThis PR adds USE CATALOG and USE DATABASE commands to SQL CLI.This closes #8830.,5
[FLINK-12760] [runtime] Implement ExecutionGraph to InputsLocationsRetriever AdapterThis closes #8688.,1
"[FLINK-12918][table][hive] unify GenericCatalogTable, HiveCatalogTable and AbstractCatalogTable into CatalogTableImplThis PR unifies implementations of CatalogTable by combining GenericCatalogTable, HiveCatalogTable and AbstractCatalogTable into CatalogTableImpl.This closes #8815.",2
[hotfix][tests] Move ResultPartitionTEst#createPDD,3
"[FLINK-12612][coordination] Track stored partitions on TMIntroduces partition tracking on the TaskExecutor.We start tracking partitions after a Task has been started. Partitionsare only tracked iff.a) they are not released on consumption (in this case the ShuffleEnvironment takes care of that automatically)b) they have local resources (as otherwise there's nothing to release)Partitions are tracked using a PartitionTable.If a task fails we stop tracking any partitions for this task. No release calls will be issued, asthe task will fail their partition, which will automatically release them.If task reaches the state FINISHED, no additional action is required. Partitions will continue to be trackeduntil they are released at a later point.The TaskExecutor is informed about the task termination via the tasks termination future, which also containsthe final execution state.Partitions for finished tasks are only released in 2 cases:a) An external call to TaskExecutor#releasePartitions is made.b) The connection to a JobManager terminates for whatever reason.For a) we stop tracking the given partitions and forward a release call to the ShuffleEnvironment.No sanity checks are made; we assume that the whoever issued the release call has a reason to do so.For b) we determine all partitions associated with the job corresponding to the terminated connection,stop tracking them and issue a release call to the ShuffleEnvironment.No additional cleanup is performed on shutdown, as the ShuffleEnvironment implicitly releases allpartitions requiring it.",1
"[FLINK-12612][coordination] Maintain JM connection until all partitions are releasedWhenever a slot is freed the TaskExecutor was checking whether any other slots were allocated for a given job,and if this isn't the case disconnects from the corresponding JobMaster.It now additionally takes into account whether we still have any tracked partitions for the given job.This check is also performed whenever an partition was released due to TaskExecutor#releasePartitions being called.",1
[FLINK-12972][table-planner-blink] Ensure calling open/close in join condition of generated functionsThis closes #8868,1
[hotfix] Expose StateAssignmentOperation#reDistributePartitionableStates as public,0
[hotfix] Expose AbstractFsCheckpointStorage#resolveCheckpointPointer as public,0
[FLINK-12729] [state-processing-api] Add state reader for consuming non-partitioned operator state,1
[FLINK-12729] [state-processing-api] Add missing serialVersionUids,1
[FLINK-12729] [state-processing-api] Build operator state index within OnDiskSavepointMetadataThis closes #8615.,5
[hotfix] Refactor NeverCompleteFuture into a reusable utility,4
[FLINK-12732] [state-processing-api] Implement shim SavepointEnvironment on top of user RuntimeContext,1
[FLINK-12732] [state-processing-api] Add savepoint reader for consuming partitioned operator state,1
[FLINK-12732] [state-processing-api] Document reader for the State Processing API,2
[FLINK-12732] [state-processing-api] Miscellaneous cleanup for read part of State Processing APIThis closes #8618.,4
[hotfix] [connectors] Fix shadowed NPE in elasticsearch sink connectorThis closes #8849.,0
"[hotfix][docs] ""data Artisans"" -> ""Ververica""",5
[hotfix][docs] update latency metric name to cover for latency granularity,5
[hotfix][docs] fix typo,2
[FLINK-12957][docs] fix Thrift and Protobuf dependency examplesThese require newer versions nowadays.This closes #8848.,1
[FLINK-12870][doc] Add missing warnings to schema evolution documentationThis closes #8806.,2
[hotfix] [docs] Fix typo in Checkpoints docThis closes #8797.,2
[hotfix] [docs] Fix the typos in process_function.md and process_function.zh.md.This closes #8709.,1
[FLINK-12741] [docs] Update Kafka producer fault tolerance guaranteesThis closes #8640.,5
[FLINK-12190] [tests] Fix IllegalArgumentException throwed by FlinkKinesisConsumerMigrationTest#writeSnapshotThis closes #8174.,3
"[FLINK-12911][table-api] Port AppendStreamTableSink, UpsertStreamTableSink, RetractStreamTableSink to flink-api-java-bridgeThis closes #8819",2
[FLINK-12971][table-planner-blink] Remove the constraint that lookup join needs a primary key or index keyThis closes #8878,4
[FLINK-12821][table-planner][cep] Fix the bug that fix time quantifier can not be the last element of a pattern,0
[FLINK-12924][table] Introduce basic type inference interfaces,5
[FLINK-12924][table] Add basic type inference logicThis closes #8865.,2
[hotfix][tests] ResultPartitionDeploymentDescriptorTest cleanup and test serialization of UnknownShuffleDescriptor without ResultPartitionDeploymentDescriptor,3
"[FLINK-12960][coordination][shuffle] Introduce ShuffleDescriptor#ReleaseType and ShuffleDescriptor#getSupportedReleaseTypes`ResultPartitionDeploymentDescriptor#releasedOnConsumption` shows the intention how the partition is going to be used by the shuffle user and released. The `ShuffleDescriptor` should provide a way to query which release type is supported by shuffle service for this partition. If the requested release type is not supported by the shuffle service for a certain type of partition, the job should fail fast.",0
[hotfix][python] Align the signature of type utility methods with JavaThis closes #8893,0
[FLINK-12914][runtime] Remove legacy InstanceListener,4
[hotfix][readme] Update how-to-contribute link,2
"[FLINK-12993][runtime] Refactor forceReleaseOnConsumption to JM conceptThe forceReleaseOnConsumption option/flag is now only evaluated on the JobMaster side and transparent to task managers,",1
[FLINK-12988][table] restore AbstractCatalogTable as parent for CatalogTableImpl and ConnectorCatalogTableThis PR adds back AbstractCatalogTable from FLINK-12918 to reflect the correct inheritance structure of CatalogTableImpl and ConnectorCatalogTable. But the unification of catalog table implementations remain untouchThis closes #8883.,2
[FLINK-12970][hive] Support writing Hive complex typesThis PR supports writing to Hive tables with complex data types.This closes #8875.,5
[hotfix][docs] Fix invalid link in migration docs,2
[FLINK-12990][python] Fix LocalTimeZone issue for Date type.This closes #8892,5
[FLINK-12609][python] Add LocalZonedTimestampType/ZonedTimestampType/DayTimeIntervalType/YearMonthIntervalTypeThis closes #8847,1
[FLINK-12722][docs] Adds Python Table API tutorialThis closes #8907,1
[FLINK-12611][table-planner-blink] Make time indicator nullable in blinkThis closes #8530,2
[FLINK-12784][metrics] Support retention policy for InfluxDB metrics reporter,5
[FLINK-11662] Disable task to fail on checkpoint errorsThis closes #8745.,0
"[FLINK-12639] [docs] add ""getting started"" section to documentation to expand in FLIP-42",2
[hotfix][docs] Fix FileSystem index link,2
[FLINK-12965][table][hive] unify catalog view implementationsThis PR unified implementations of CatalogView.This closes #8882.,2
"[FLINK-13006][hive] remove GenericUDTFReplicateRows from GenericUDTFTest because Hive 1.2.1 doesn't have itThis PR removes GenericUDTFReplicateRows from HiveGenericUDTFTest because Hive 1.2.1 doesn't have it and thus the build profile for Hive 1.2.1 would fail.I've added pretty a lot test coverage for HiveGenericUDTF, so removing just this one test should be fine.This closes #8905.",3
"[FLINK-12660][hive] Integrate Flink with Hive UDAFThis PR adds support for Hive UDAF in Flink.For Hive UDAF, there are mainly four interfaces: UDAF, GenericUDAFResolver, GenericUDAFResolver2, AbstractGenericUDAFResolverUDAF is kind of on its own, deprecated in Hive a long time ago. GenericUDAFResolver and AbstractGenericUDAFResolver are deprecated for GenericUDAFResolver2.This closes #8881.",0
[FLINK-12962][python] Allows pyflink to be pip installed.This closes #8863,2
[hotfix][table-common] Add implicit precision to predefined types,1
[hotfix][table-common] Add missing TIME type familyThis closes #8913.,1
[hotfix] Remove unused method from Kafka Test Environments,3
[FLINK-11693] Add KafkaSerializationSchema that uses ProducerRecord,1
[FLINK-11693] Support FlinkKafkaPartitioner functionality with new KafkaSerializationSchema,1
[FLINK-11693] Deprecate old constructors in modern KafkaProducer,2
[hotfix][tests] Rewrite StreamTaskTest without reflection based fields setting,1
[hotfix][tests] StreamTaskTestHarness: create StreamTask instance in the execution thread (task's thread)This would prepare some StreamTask tests to be compatible with a new invariant in the StreamTask that the mailbox loop should be running in the task's thread. The latter is decided by the thread that instantiates the task.,1
[hotfix][tests] Make SynchronousCheckpointTest create StreamTask instance in the main task's thread,1
[hotfix][tests] StreamTaskTestHarness: use Preconditions.checkState instead of explicit throw IllegalStateException,1
[FLINK-12968][table-common] Add a utility for logical type castsThis closes #8874.,2
[hotfix][table-common] Update LogicalTypeCastsTest to use logical types,2
[hotfix][table-common] Enrich the output type of InputTypeValidators#getExpectedSignature.,5
[hotfix][table-common] Fix argument count validation,5
[FLINK-12985][core][streaming] Rename StreamTransformation to org.apache.flink.api.dag.TransformationThis name better represent the fact that Transformation also supportsbatch cases. Moreover it makes the structure of the flink-core cleaner.,4
[FLINK-12954][table-api] Supports create(drop) view grammar for sql parserThis closes #8850,4
[hotfix][python] Aligns with Java Table API by removing methods exec_env and query_configThis closes #8910,5
[FLINK-12850][core] Introduce LocalDate/LocalTime/LocalDateTime TypeInfoThis closes #8757,5
[FLINK-13003][table-planner-blink] Support Temporal TableFunction Join in processing time and event timeThis closes #8901,1
[FLINK-12989][hive]: Generate HiveTableSink from from a Hive tableThis PR adds the generation of HiveTableSink from from a Hive table.This closes #8890.,1
"[FLINK-12882][network] Remove ExecutionAttemptID argument from ResultPartitionFactory#createThe ResultPartitionID could be got directly from ResultPartitionDeploymentDescriptor, so it is no need to passExecutionAttemptID to construct new ResultPartitionID during creating ResultPartition in factory.",1
"[hotfix][network,tests] Use the simple constructor of ResultPartitionID in tests",3
[hotfix][runtime] add checkNotNull for parameters in ResultPartitionID constructor,2
[FLINK-13004][table-runtime-blink] Correct the logic of needToCleanupState in KeyedProcessFunctionWithCleanupStateThis closes #8909,4
[FLINK-12615][coordination] Support generic key in PartitionTable,1
[FLINK-12615][coordination] Track partitions on JM,2
[FLINK-12641][coordination] Release partitions on job shutdown,2
[FLINK-12612][coordination] Maintain JM connection until all partitions are released,2
[FLINK-12641][coordination] Release partitions on every terminal job state,2
[hotfix][coordination] Remove outdated comment,5
[hotfix] Minor cleanups,4
[hotfix] [network] Rename BoundedBlockingSubpartitionReader 'memory' parameter,2
[FLINK-12986] [network] Add different implementations to store/serve the data from the BoundedBlockingSubpartitionThis PR encapsulates the following steps:  - introduce the BoundedData interface to abstract the way that buffers are stored / read as part of a bounded stream subpartition  - Change BufferToByteBuffer from reader/writer to encoder util that works across byte buffers and byte channels    so we can use it for both file-based implementations and memory-buffer based implementations  - Add FileChannelBoundedData which writes the buffers to a file and reads them back from the file  - Add FileChannelMemoryMappedBoundedData which writes the buffer to a file and maps that file into memory for reading  - Add common tests for all implementations of BoundedData  - Rename MemoryMappedBuffers to MemoryMappedBoundedData to be consistent with other names.  - Instantiate new bounded data store implementations from ResultPartition  - Use FILE_MMAP implementation on 64bit systems and FILE implementation on other systems,5
[hotfix] [tests] Remove usage of Assume in BoundedDataTests to avoid warnings during build/testing,3
"[FLINK-12881][ml] Add more functionalities for ML Params and ParamInfo classAdd more functionalities, including the support of aliases, the config of size/clear/isEmpty/contains/fromJason in ParamsThis closes #8776",2
"[FLINK-12947][docs-zh] Translate ""Twitter Connector"" page into ChineseThis closes #8842",1
[FLINK-12897][python][docs] Improve the Python Table API docs by adding more examples.This closes #8916,1
[FLINK-13022][table][hive] unify catalog function implementationsThis PR unifies catalog function implementations.This closes #8919.,1
[FLINK-12758][ml] Add flink-ml-lib moduleThis closes #8643,2
[FLINK-13001][tests] Add TestingExecutionGraphBuilder,3
[FLINK-12997][coordination] Release partitions on vertex reset,1
[hotfix][docs] Regenerate blob server configuration docs,2
[hotfix][docs] Update configuration page to list new netty shuffle options,1
[hotfix][network] Rename BufferBlocker to BufferStorage,0
[hotfix][network] Make toNotifyOnCheckpoint field final in ChekpointBarrierHandlers,0
[hotfix][network] Move queuedBuffered and currentBuffered fields to BufferStorageThis makes BufferStorage contract more complete. Now it takes care of the whole processof storing and returning the data with simpler interface (single #rollOver methodvs two different as it was before).,5
[hotfix][test] Drop unnecessary pageSize argument in BufferBarierTestBase#createBuffer,3
[hotfix][network] Do not abort the same checkpoint barrier twice when cancellation marker was lost,0
[hotfix][test] Drop mockito usage from BarrierTrackerTest,3
[FLINK-12777][network] Extract CheckpointBarrierAligner from BarrierBuffer,4
[FLIKN-12777][network] Refactor BarrierTracker to use the same code structure as BarrierBuffer,1
"[FLINK-12777][network] Rename existing classes to make them in sync with the refactor1. Rename BarrierBuffer to CheckpointedInputGateCheckpointedInputGate was an interface, while BarrierBuffer wasit's implementation. This rename means that we are dropping the interfaceand keeping only the concrete class.2. Rename BarrierBuffer and BarrierTracker tests to match this renameand previous refactorings.",4
[hotfix][network] Split InputProcessorUtil into smaller methods,0
[FLINK-12777][network] Introduce LinkedBufferStorage class,5
[hotfix][operator] Fix checkpointing lock in StreamTwoInputSelectableProcessor,0
[FLINK-12777][operator] Use CheckpointedInputGate StreamTwoInputSelectableProcessor,1
[hotfix][network] Drop unneccessary reference in the commentThis reference was introducing unwanted dependency between CachedBufferStorage and aclass that was using it.,1
[hotfix][network] Minor code simplification in CachedBufferStorage,5
[hotfix][network] Drop one testing constructor of CheckpointedInputGate,3
[FLINK-13023][hive] Generate HiveTableSource from a Hive table,2
[FLINK-13005][hive] HiveCatalog should not add 'flink.is_generic' key for Hive tableThis PR fixes a bug that 'flink.is_generic' key should not add for metadata for a non-generic catalog table (a.k.a a Hive table).This closes #8904.,2
[FLINK-12627][doc][sql client][hive] Document how to configure and use catalogs in SQL CLIThis PR adds English doc for configuring catalogs in SQL CLI.This closes #8800.,2
[FLINK-11147][table][docs] Add documentation for TableAggregate FunctionThis close #8669,1
[FLINK-12703][table-planner-blink] Introduce metadata handlers on SEMI/ANTI join and lookup joinThis closes #8588,0
[FLINK-12937][table-planner-blink] Introduce join reorder planner rules in blink plannerThis closes #8832,2
[FLINK-12805][table-api] Introduce PartitionableTableSource for partition pruning,1
[FLINK-12808][table-api] Introduce OverwritableTableSink for supporting insert overwrite,1
[FLINK-12809][table-api] Introduce PartitionableTableSink for supporting writing data into partitions,5
[FLINK-13028][table-api-java] Extract legacy type inference logic,2
[FLINK-13028][table-api-java] Remove planner expression from ExpressionResolver,0
[FLINK-13028][table-api-java] Refactor local over windows,4
[FLINK-13028][table] Refactor expression package structure,4
[FLINK-13029][table-planner] Ported GROUP BY expression to new type system,5
[FLINK-13029][table-planner] Removed usages of ExpressionBridge in QueryOperation's factoriesThis closes #8932,4
[hotfix][table-common] Enable finding multiple matching TableFactories from TableFactoryServiceThis commits adds methods TableFactoryService.findAll that return TableFactories even if they are ambiguous based on the requiredContext and supportedProperties. Additionally it fixes minor issues and improves type hanlding.,1
[FLINK-12798][table] Add a discovery mechanism for switching between Flink/Blink Planner/ExecutorThis closes #8852.,2
[hotfix][runtime] Cleanup IOManager code,4
[hotfix][runtime] IOManager implements AutoCloseable,0
"[hotfix][runtime] Refactor IOManager#close and remove #isProperlyShutDownIOManager#close would ignore any exceptions internally in order not to interrupt other close operations,then IOManager#isProperlyShutDown is used for checking any exceptions during close process. We could useIOUtils#closeAll for handling all the close operations and finally throwing the suppressed exceptions toget the same effect, then isProperlyShutDown method could be removed completely.",4
"[FLINK-12735][network] Refactor IOManager to introduce FileChannelManagerIOManager mainly has two roles. One is for managing file channels based on config temp dirs, and the other is for abstracting ways to read/writer files.We could define a FileChannelManager class for handing the file channels which could be reused for shuffle environment future. To do so the shuffleenvironment do not need to rely on the whole IOManager.",1
"[FLINK-12735][network] Make shuffle environment implementation independent with IOManagerThe current creation of NettyShuffleEnvironment relies on IOManager from TaskManagerServices. Actually the shuffle only needs thefile channel during creating partition, so it could internally create a light-weight FileChannelManager with its own prefix foldername instead of the heavy-weight IOManagerAsync.",0
[hotfix][runtime] Remove legacy NoOpIOManager class,4
[FLINK-12883][runtime] Extract computation of pipelined regions.,4
[hotfix][runtime] Use Set instead of IdentityHashMap where possibleReplace instances where we use an IdentityHashMap as a set withCollections.newSetFromMap() in RestartPipelinedRegionStrategy andPipelineRegionComputeUtil.,1
[hotfix][runtime] Remove obsolete comment from PipelinedRegionComputeUtil#uniqueRegions(),4
[FLINK-12883][runtime] Add getID() to ExecutionVertex,1
"[FLINK-12883][runtime] Introduce PartitionReleaseStrategy- Introduce interface PartitionReleaseStrategy.- Introduce RegionPartitionReleaseStrategy and  NotReleasingPartitionReleaseStrategy implementations, which can be configured  via a new config option.- Add unit tests for new classes.- Increase visibility of methods in TestingSchedulingTopology for unit tests  outside of its package.",3
[FLINK-13045][table] Move Scala expression DSL to flink-table-api-scalaThis move the Scala expression DSL to flink-table-api-scala.Users of pure table programs should define there imports like:import org.apache.flink.table.api._TableEnvironment.create(...)Users of the DataStream API should define their imports like:import org.apache.flink.table.api._import org.apache.flink.table.api.scala._StreamTableEnvironment.create(...)This commit did not split the package object org.apache.flink.table.api.scala._ intotwo parts yet because we want to give users the chance to update their imports.This closes #8945.,2
[hotfix][table-planner][table-api-java] Move QueryOperation factories to table-api-java,4
[FLINK-12906][table-planner][table-api-java] Ported OperationTreeBuilder to table-api-java module,2
[hotfix][table-api-java] Moved QueryOperation utilities to o.a.f.t.operations.utilsThis closes #8860,4
[FLINK-13047][table] Fix the Optional.orElse() usage issue in DatabaseCalciteSchemaThis PR fixes the Optional.orElse() usage issue in DatabaseCalciteSchem.This closes #8940.,5
[FLINK-13021][table][hive] unify catalog partition implementationsThis PR unifies catalog partition implementations.This closes #8926.,2
[FLINK-13046][hive] rename hive-site-path to hive-conf-dir to be consistent with standard name in HiveThis PR renames the SQL CLI config key for HiveCatalog from hive-site-path to hive-conf-dir which is consistent with standard Hive conf key name.This closes #8939.,5
[FLINK-13048][hive] support decimal in Flink's integration with Hive user defined functionsThis PR adds support for decimal in Flink's integration with Hive user defined functions.This closes #8941.,1
[hotfix][python] Remove the redundant 'python setup.py install' from tox.iniThis close #8947,5
"[FLINK-12945][docs-zh] Translate ""RabbitMQ Connector"" page into ChineseThis closes #8843",1
"[FLINK-12938][docs-zh] Translate ""Streaming Connectors"" page into ChineseThis closes #8837",1
"[FLINK-12946][docs-zh] Translate ""Apache NiFi Connector"" page into ChineseThis closes #8838",1
"[FLINK-12943][docs-zh] Translate ""HDFS Connector"" page into ChineseThis closes #8897",1
"[FLINK-12944][docs-zh] Translate ""Streaming File Sink"" page into ChineseThis closes #8918",1
[hotfix][docs] remove duplicate `to` in state doc,2
[FLINK-13049][table-planner-blink] Rename windowProperties and PlannerResolvedFieldReference to avoid name conflit,5
[FLINK-13049][table-planner-blink] Port planner expressions to blink-planner from flink-plannerThis closes #8942,2
[FLINK-13070][table-planner-blink] Remove TableImpl from blink planner and use api.internal.TableImpl insteadThis closes #8959,1
[FLINK-12977][table] Port CsvTableSource to api-java-bridgeThis closes #8872,1
[FLINK-12977][table] Port CsvTableSink to api-java-bridge,2
[FLINK-12978][table] Support LookupableTableSource for CsvTableSource,1
"[FLINK-12284][Network,Metrics]Fix the incorrect inputBufferUsage metric in credit-based network mode",1
"[FLINK-13077][python] Fix the failed test in CatalogPartitionAPICompletenessTests caused by the lack of ""getComment"" method. (#8968)This close #8968",1
[hotfix][43w5] Fix logging argument,2
"[hotfix][table] remove @PublicEvolving annotation from AbstractCatalog as it's not supported to be publicThis PR removes @PublicEvolving annotation from AbstractCatalog. @PublicEvolving should be on the Catalog interface (which it already is), and marking AbstractCatalog as @PublicEvolving brings us extra burden on maintaining its compatibility.This closes #8975.",5
[FLINK-12974] [build] Bump checkstyle to 8.14This closes #8870,2
[hotfix] [docs] Update IDE setup instructions for latest IntelliJ IDEAThis closes #8908,3
[FLINK-12840] [core] Fix network utils to work with ipv6 correctly  - Fixes problems around akka configuration parsing with some IPv6 literals  - Fixes an issue with address parsing and validation with some Ipv6 literalsThis closes #8734,5
[hotfix] [examples] Distinguish 'netcat' arguments for Linux and Windows in the SocketWIndowWordcount JavaDocsThis closes #8593.,2
[FLINK-13017] [docs] Do not mount local $HOME into docs docker environmentThis closes #8917,2
[FLINK-12820] [Connectors / Cassandra] Support ignoring writing nulls for tuple typesThis closes #8714,1
[FLINK-13043] [Library / CEP] Fix the bug of parsing Dewey number from stringThis closes #8936,0
[hotfix][runtime] Fix checkstyle violations in FailoverStrategyLoader,0
"[hotfix][runtime, tests] Remove ComponentMainThreadExecutor interface from ManuallyTriggeredScheduledExecutor",4
[hotfix][runtime] Make ComponentMainThreadExecutorServiceAdapter accept ScheduledExecutor,1
"[FLINK-12876][runtime] Adapt new RestartPipelinedRegionStrategy to legacy schedulingImplement adapter (AdaptedRestartPipelinedRegionStrategyNG) that adaptsorg.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategyto the legacy failover strategy interface(org.apache.flink.runtime.executiongraph.failover.FailoverStrategy).The new AdaptedRestartPipelinedRegionStrategyNG is chosen if config optionjobmanager.execution.failover-strategy is set to ""region"". The legacy behaviorcan be enabled by setting the config option to ""region-legacy"".This closes #8922.",5
[hotfix][table-planner-blink] Fix boolean hashCode codegen,0
[hotfix][table-planner-blink] Set shuffleMode to PartitionTransformation in BatchExecExchange,4
[FLINK-12959][table-planner-blink] Use BoundedInput and InputSelectable in blink,2
[FLINK-12959][table-planner-blink] Implement BatchExecHashJoin translateToPlanInternalThis closes #8854,2
"[FLINK-11638][docs-zh] Translate ""Savepoints"" page into ChinesThis closes #8300",2
[FLINK-11775][runtime] Introduce MemorySegmentWritable,2
[FLINK-11775][table-runtime-blink] Use MemorySegmentWritable to BinaryRowSerializerThis closes #8775,1
[FLINK-12963] [state-processor] Add savepoint writer for bootstrapping new savepoints,1
[FLINK-12963] [travis] Add state processor api to travis library module,1
[FLINK-12963] [docs] Document savepoint writer for bootstrapping new savepoints,1
[FLINK-12963] [state-processor] Refactor operator state access concerns into ModifiableSavepointMetadata,5
"[FLINK-12963] [state-processor] Introduce OperatorStateSpec wrapper classThis class is a simple container class to represent an operator statethat is either still defined by a BootstrapTransformation, i.e. newstate that has not been written out yet, or an existing OperatorState.Introducing this class improves readability of the code, instead ofusing Eithers and Tuples that would not have clear semantics for theuser.",1
"[FLINK-12963] [state-processor] Reduce dependency on SavepointMetadata in runtime componentsPreviously, we were passing around SavepointMetadata across differentruntime classes, such as MergeOperatorStates operator andBoostrapTransformation.write().This isn't necessary, as these runtime classes actually do not needfunctionality that the SavepointMetadata provides. The SavepointMetadatashould essentially just be a data structure that maintains what existingoperator states there are, and which operator states are added, in orderto build the job graph.This commit changes this by only passing in the necessary informationwrapped by SavepointMetadata to the runtime classes. By doing so, we canavoid making SavepointMetadata a Serializable, since it is now no longerpart of the built job graph.",5
"[FLINK-12963] [state-processor] Simplify SavepointMetadata hierarchyFrom the current state of its usage, the previous hierarchy(ModifiableSavepointMetada -> SavepointMetadata) is redundant. Thiscommit simplifies this to just be a single SavepointMetadata class.",5
[FLINK-12963] [state-processor] Add missing serialVersionUIDs,1
"[FLINK-12693] [state-processor] Improve Javadocs for user-facing APIsThis commit improves Javadocs for the State Processor API that areeither outdated, or not sufficiently informative.",5
"[FLINK-12963] [state-processor] Allow providing user defined SavepointWriterOperatorFactory when creating keyed BootstrapTransformationsThis was exposed for non-partitioned BootstrapTransformations, but notfor keyed ones. This commit makes the functionality on-par for bothsides.",1
[FLINK-12963] [state-processor] Make OperatorTransformation non-instantiableThe OperatorTransformation class is a simple entry point for creatingBootstrapTransformations via the #bootstrapWith static factory method.This commit solidifies this by making the class non-instantiable.This closes #8861.,1
"[hotfix][runtime] Make BufferStorage independent with InputGate#getPageSizeThe page size could be got directly from configuration during constructing BufferStorage instance instead of from InputGate,then we could remove abstract getPageSize method from InputGate later.",1
"[FLINK-12738][network] Remove abstract getPageSize method from InputGateCurrently InputGate#getPageSize is only used for testing purpose. In order to make abstract InputGate simple and clean,it is better to remove unnecessary abstract methods via refactoring relevant tests not to rely on it.",3
[hotfix][network] Remove getMemorySegmentSize method from BufferProvider interface,1
"[hotfix][network] Remove unnecessary getMemorySegmentSize method from NetworkBufferPoolSince LocalBufferPool is not relying on NetworkBufferPool#getMemorySegmentSize any more, and the current only usage for this methodis in tests which also seems unnecessary. So we could remove this method from NetworkBufferPool.",1
[FLINK-13073][table-blink-runtime] BinaryRow in Blink runtime has wrong FIRST_BYTE_ZERO maskThis closes #8961,0
[hotfix][test] Drop InputGateConcurrentTestThose tests are mostly superseded by StreamNetworkThroughputBenchmarkTest(except of mixed local/remote workload),1
[hotfix][test] Drop unused closedChannels field in MockInputGate,1
[FLINK-13016][network] Fix StreamTaskNetworkInput#isAvailableBefore this method was ignoring data/records buffered in the currentRecordDeserializer,5
[hotfix][operator] Deduplicate StreamTask code,0
[hotfix][operator] Rename StreamInputProcessor to StreamOneInputProcessorThis is done in order to free `StreamInputProcessor` name as a base interface ofall of the processors.,0
[hotfix][operator] Deduplicate code by introducing StreamInputProcessor interface,0
[FLINK-13019][coordination][tests] Add ITCase for fine-grained recoveryThe simplest IT test is to create a batch job with a sequence of non-parallel mappers.The each mapper writes to a blocking partition which means the next mapper starts when the previous is done.The mappers are not chained into one Task which makes them separate failover regions.,0
"[FLINK-11637][doc-zh] Translate ""Checkpoints"" page into ChineseThis closes #8943",1
[hotfix][yarn] Remove unused dependency,1
[FLINK-12902][hadoop] Remove flink-shaded-yarn-tests,3
[FLINK-13071][table-planner-blink] Support more functions in RexNodeConverter.,1
[FLINK-13071][table-planner-blink] QueryOperationConverter in Blink planner support add kinds of QueryOperations.,1
[FLINK-13071][table-planner-blink] Remove toRexNode methods from the PlannerExpressions in blink planner & add TableApi testcases.This closes #8977,3
[FLINK-12665][table-planner-blink] Introduce MiniBatchIntervalInferRule and watermark assigner operatorsThis closes #8562,1
"[FLINK-13066][hive] append hive-site.xml to path of Hive conf dirThis PR fixes a bug that we previously only pass Hive conf dir to HiveConf but we really should pass path of hive-site.xml. Thus, the change is to append hive-site.xml to the Hive conf dir and pass into HiveConf if Hive conf dir is not null.This closes #8955.",5
[FLINK-13087][table] Add group window Aggregate operator to Table APIThis closes #8979,1
[FLINK-12802][table-runtime-blink] Cleanup some interfaces of BinaryStringThis closes #8689,4
[FLINK-13089][table-planner-blink] Implement batch nested loop join and add some join itcasesThis closes #8978,1
[FLINK-12956][jdbc] Introduce upsert table sink for JDBCThis closes #8867,5
[hotfix][table-runtime-blink] Fix checkstyle of NestedLoopJoinCodeGenerator,0
[FLINK-13082][table-planner-blink] Support MatchRecognize in blink plannerThis closes #8974,2
[FLINK-12767][python] Support user defined connectors/formatThis closes #8719,1
[FLINK-13096][Deployment/YARN]Typo in Utils,2
[FLINK-12796][table-planner-blink] Introduce BaseArray and BaseMap to reduce conversion overheadThis closes #8682,2
[FLINK-12319][Library/CEP]Change the logic of releasing node from recursive to non-recursive,2
"[FLINK-12936][table-planner-blink] Support ""intersect all"" and ""minus all""This closes #8898",1
[FLINK-12597][ml] Remove the legacy flink-ml and flink-ml-uberRemove the legacy flink-libraries/flink-ml and flink-libraries/flink-ml-uberThis closes #8526,2
[FLINK-13060][coordination] Respect restart constraints in new RegionFailover strategy,0
[hotfix] Port TestingUncaughtExceptionHandler from Scala to Java,3
[hotfix][tests] Remove problematic mocking from StreamTaskTest#testAsyncCheckpointingConcurrentCloseBeforeAcknowledgeThe problem was the whenNew mocking which could lead to a StackOverflowException in theStreamTask#AsyncCheckpointRunnable.,1
[hotfix][tests] Remove PowerMocking from StreamTaskTest,3
"[FLINK-12889] Set FatalExitExceptionHandler for StreamTask#asyncOperationsThreadPoolIn order to avoid the swallowing of uncaught exceptions in asynchronous checkpoint operations,this commit sets the FatalExitExceptionHandler for the StreamTask#asyncOperationsThreadPool.For testing purposes the uncaught exception handler was made configurable in the StreamTask.This closes #8948.",5
[FLINK-12723][docs] setup IDE for Python (#8992)This closes #8992,1
[FLINK-12353][tools] Collect japicmp output under tools/japicmp-output,2
[FLINK-12817][docs] Fix imports in Processing function example,1
[FLINK-9311] [pubsub] Add PubSubSource and PubSubSink connectorsThis closes #6594,1
[FLINK-9311] [pubsub] Add unit and integration tests for PubSub connectors,3
[FLINK-9311] [pubsub] Add documentation of pubsub connectors,2
[FLINK-9311] [pubsub] Clean up / add documentation and style issues in the PubSub connector,0
[FLINK-9311] [pubsub] Improvements to builders + minor improvement to PubSubSink flush logic,2
[FLINK-13088][table-api] Support lazy query transformation & execution on TableEnvironment,1
[hotfix][table-api] Remove CompositePlannerConfig,5
[FLINK-13088][table-api] Support instantiating the unfied TableEnvironmentThis closes #8984,1
[FLINK-12744][ml] add shared params in ml packageThis closes #8632,1
[FLINK-13081][table-planner][table-api-java] Supports explain DAG planThis closes #8973,2
"[FLINK-12934][hive] add hadoop dependencies as 'flink-shaded-hadoop-2-uber' for flink-connector-hive to connect to remote hive metastore serviceNow, for all hadoop related dependencies, we just use the single jar of flink-shaded-hadoop-2-uber, instead of depending on individual hadoop jars. It's much more convenient for users to use now.This closes #8889.",1
[FLINK-12237][hive]Support Hive table stats related operations in HiveCatalogThis pull request makes HiveCatalog support Hive table stats related operations.This closes #8636.,1
[hotfix][runtime] Make TestingComponentMainThreadExecutor accept ComponentMainThreadExecutor,3
[hotfix][runtime] Fix main thread check in ComponentMainThreadExecutorServiceAdapter,0
[hotfix][runtime] Merge TestingComponentMainThreadExecutorServiceAdapter and ComponentMainThreadExecutorServiceAdapterMerge TestingComponentMainThreadExecutorServiceAdapter withComponentMainThreadExecutorServiceAdapter because it only adds static methods.Move ComponentMainThreadExecutorServiceAdapter to test sourcesThis closes #8989.,3
[FLINK-13040][table-planner-blink] Improve blink planner configurations.This closes #8980,5
[FLINK-13026][connector] Introduce JDBCLookupFunctionThis closes #8923,5
[FLINK-12961][datastream] Add internal StreamExecutionEnvironment.execute(StreamGraph),1
[FLINK-13125] Make PubSub stability warning more prominent,2
[FLINK-13137][py][docs] Remove legacy python docs,2
[FLINK-13114][table-planner-blink] adapt blink planner to new unified TableEnvironmentThis closes #9010,1
[hotfix] Revert annotation to Internal on DataStreamQueryOperation,5
[hotfix][table-planner-blink] Fix static variable name,0
[hotfix][table-planner-blink] Fix various checkstyle issues.,0
"[FLINK-11082][network] Fix the calculation of backlog in PipelinedSubpartitionThe backlog of subpartition should indicate how many buffers are consumable, then the consumer could feedback the corresponding credits for transporting these buffers. But in current PipelinedSubpartition implementation, the backlog is increased by 1 when a BufferConsumer is added into PipelinedSubpartition, and decreased by 1 when a BufferConsumer is removed from PipelinedSubpartition. So the backlog only reflects how many buffers are retained in PipelinedSubpartition, which is not always equivalent to the number of consumable buffers.The backlog inconsistency might result in floating buffers misdistribution on consumer side, because the consumer would request floating buffers based on backlog value, then one floating buffer might not be used in RemoteInputChannel long time after requesting.Considering the solution, the last buffer in PipelinedSubpartition could only be consumable in the case of flush triggered or partition finished. So we could calculate the backlog precisely based on partition flushed/finished conditions.",5
[FLINK-12968][table-common] Add an utility for finding a common type from a set of typesThis closes #8933.,1
[hotfix][runtime] Compare native memory in ResourceProfile#equals().,2
[FLINK-12812][runtime] Set resource profiles for task slots  - Add managed memory in ResourceSpec and ResourceProfile.  - Set resource profiles for task slots when starting TaskManagers.  - Set resource profiles for pending task manager slots.,2
"[hotfix] [runtime] Improve slot profile computation in TaskManagerServicesIn particular, this avoid repeatedly performing the computation, for each slot.",2
[hotfix] [runtime] Split heap/managed memory computation into smaller reusable methods,1
[FLINK-12812] [runtime] (follow-up) Fix bytes/megabytes mixup in managed memory for slot resource profile,2
[FLINK-12812] [runtime] (follow-up) Deduplicate managed memory configuration logic between ResourceManager and TaskManagerServices,2
[FLINK-12812] [runtime] (follow-up) Consolidate profile/memory configuration logic in ResourceManagers.,2
"[FLINK-12812] [runtime] (follow-up) Test refers to slot profile computed in ResourceManager.This helps catch a previous bug in which the test re-computed the managed memory, passing a test valuein MEGABYTES. The original call in the ResourceManager passed a value in BYTES.",4
[hotfix] [core] Simplify access to default values TM/JM memory sizes.,0
[hotfix] [yarn] Various minor code style fixes in YarnResourceManagerTest,3
[FLINK-12652] [documentation] add first version of a glossary to concepts section,1
[hotfix] Remove blink Types class,2
[FLINK-12844][table-planner-blink] Use default conversion class LocalDate/LocalTime/LocalDateTime for DateType/TimeType/TimestampTypeThis closes #8762,5
[FLINK-13110][hive] add shim of SimpleGenericUDAFParameterInfo for Hive 1.2.1 and 2.3.4This PR adds shim of SimpleGenericUDAFParameterInfo for Hive 1.2.1 and 2.3.4.This closes #9001.,5
"[FLINK-13135][hive] unify configs for meta-objects in HiveCatalogThis PR unifies configs for meta-objects in HiveCatalog, specifically unifies HiveDatabaseConfig, HiveTableConfig, HivePartitionConfig into HiveCatalogConfig.This closes #9012.",5
[FLINK-12973]Support reading Hive complex types like array and mapThis PR adds support reading Hive complex types like array and map.This closes #8935.,1
"[FLINK-13134][hive] override default hadoop version from 2.4.1 to 2.7.5 in flink-connector-hiveHive 2.3.4 relies on Hadoop 2.7.2 or later version. The default hadoop version in Flink globally is 2.4.1 which misses some classes in 2.7.2 and thus doesn't meet the requirement.For hadoop 2.7, the minor version supported in flink-shaded-hadoop-2-uber is 2.7.5.This closes #9011.",2
[hotfix][hive] disable unit test HiveInputFormatTest.testReadComplextDataTypeFromHiveInputFormat(),5
[FLINK-12991][python] Correct the implementation of Catalog.get_table_factory (#8956),2
[hotfix][python]Fix the install failure of pyflink used previous version of python 2.7 (#9016)Fix for python 2.7.10.,0
[hotfix][python][docs]Fix wrong example code in Python REPL and wrong table plan in table/common page (#9018),0
[FLINK-12693][state] Store state per key-group in CopyOnWriteStateTableThis closes #8611.,3
[FLINK-13098][datastream] Add a new type UNDEFINED of shuffle mode,1
[FLINK-13101][datastream] Introduce blockingConnectionsBetweenChains property of StreamGraph,5
[FLINK-12730][runtime] Unify BitSet implementations in flink-runtimeThis closes #8613.,2
[FLINK-13063] Temporary fix for AsyncWaitOperator consistency problemsThe current implementation of AsyncWaitOperator can violate exactly-once and at-least once guarantees in some common scenarios. This commit provides a temporary fix by preventing the operator to be chained after other operators.This closes #9034.,1
"[FLINK-12736][coordination] Release TaskExecutor in SlotManager only if there were no slot allocations after the partition checkThe ResourceManager looks out for TaskManagers that have not had any slots allocated on them for a while, as these could be released to safe resources.If such a TM is found, the RM checks via an RPC call whether the TM still holds any partitions. If no partition is held then the TM is released.However, in the RPC callback no check is made whether the TM is actually still idle. In the meantime a slot could have been allocated on the TM.Even if the slot has been freed, there can be newly allocated partitions not included in check result.To make sure there was no resource allocation in between, we can mark the taskManagerRegistration.getIdleSince() time before starting the async 'no partition' check.The TM can be released only if the idle time after the check matches the previously marked one. Otherwise we discard the release and start over after the next timeout.This closes #8988.",1
[hotfix][tests][coordination] Move idle task manager release tests into a separate suite,3
[hotfix][test] Guarantee order of CloseableRegistry,1
[hotfix][test] Move CloseableRegistry as field in InputBuffersMetricsTest,3
[hotfix][test] Deduplicate NettyShuffleEnvironmentTest code,3
"[FLINK-13013][network] Request partitions during InputGate#setupBefore partitions were being requested on first polling/getting next bufferwhich was causing a couple of issues:- it was a little bit confusing- after first requestPartitions call, this was causing unnecessary synchronisation overhead- this was preventing data notifications to come through and isAvailable() future was always not  completed before the first attempt to read the data from the input gateThis commit moves requesting partitions to InputGate#setup solving those issues.",0
[hotfix][network] Make InputGate#requestPartitions a private method,1
[FLINK-12951][table-planner] Add logic to bridge DDL with table source/sinkThis closes #8844,2
[FLINK-13090][hive] Test Hive connector with hive runnerThis PR uses hive runner in our hive connector tests.This closes #8987.,3
"[FLINK-13068][hive] HiveTableSink should implement PartitionableTableSinkThis PR makes HiveTableSink implement PartitionableTableSink, so that HiveTableSink supports static partitioning.This closes #8965.",1
[hotfix][hive] resolve bad merge in HiveTableSinkTestResolve bad merge between #8965 and #8987 though they passed CI separately.,4
[FLINK-12955][hbase] Support LookupableTableSource for HBaseThis closes #9045,1
[hotfix][python] Fix the documentation issue,0
[hotfix][test] Clean up NettyShuffleEnvironmentTest,3
[hotfix][checkpointing] Extract MINIMAL_CHECKPOINT_TIME magic constant,5
[FLINK-13175][tests] Fix ExecutionContextTest test failure.This closes #9052,0
[hotfix][python] Update the package name from pyflink to apache-flink (#9028),2
[FLINK-13067][docs] Fix broken links to contributing docsThis closes #8964,2
[hotfix][runtime] Remove unused DependencyVisitorThis closes #8970,1
[FLINK-13057][state] Correct comments in ListState classThis closes #8994,2
[hotfix] Remove incorrect doc comments from RocksDBMapStateThis closes #8999,5
[hotfix][runtime] Fix test cases that use unknown resource profiles in slot offers.The test cases should not user ResourceProfile#UNKNOWN in slot offers.  - ResourceProfile#UNKNOWN is used for slot requests whose resource needs are not specified.  - ResourceProfile#ANY is used for task manager slots whose can match any slot request.These cases haven't been failing because so far slot requests always have unknown resource profiles.,2
[FLINK-12763][runtime] Requests slots with ResourceProfiles that are converted from ResourceSpecs.,2
[FLINK-12763][runtime] SlotManager fails unfulfillable slot requests if it is set to do so.,1
[FLINK-12763][runtime] Yarn/MesosResourceManager do not start new worker when requested resource profile cannot be satisfied.,2
[FLINK-12763][runtime] Yarn/MesosResourceManager set SlotManager to fail unfulfillable requests on started.,0
[FLINK-12763][runtime] Introduce a start-up period to standalone cluster that after this period StandaloneResourceManager set SlotManager to fail unfulfillable requests.,0
[hotfix] [runtime] Remove obsolete Exception from JobLeaderIdService signature,4
[hotfix] [tests] Factor out MockResourceManagerRuntimeServices to make them reusable in different tests,3
[FLINK-12763][runtime] Use a timeout of zero to indicate no startup periodThis allows users to configure a behavior similar to previous versions.,5
[FLINK-12763][runtime] Factor out SlotManager tests for eager failing of unfulfillable requestsTurning the one monolithic test into multile targeted tests makes it easier to test specificscenarios and makes the tests easier readable.,3
[FLINK-12763][runtime] Remove eagerly rejected pending slot requests from SlotManager,4
[hotfix][runtime] Minor cleanup in SlotManagerAvoid checking whether slots would be fulfillable unless necessary,4
[hotfix][python] Align with Java Table API to remove QueryConfig (#9063),5
[FLINK-12929] Pass TypeInformation in addSourceCo-authored-by: Georg Rollinger <georg.rollinger@posteo.net>,1
"[FLINK-13173][tests] only run openSSL-based tests with flink.tests.with-opensslRename `flink.tests.force-openssl` (introduced for Flink 1.9) to`flink.tests.with-openssl` and only run openSSL-based unit tests if this is set.This way, we avoid systems where the bundled dynamic libraries do not work.Travis seems to run fine and will have this property set.For examples of such scenarios and why (for now) we cannot rely on automaticopenSSL detection, please refer tohttps://issues.apache.org/jira/browse/FLINK-13172.",2
"FLINK-13106][doc-zh] Translate ""Parallel Execution"" page into ChineseThis closes #8995",1
[FLINK-7244][parquet] Add ParquetTableSource.This closes #8064.,1
[FLINK-13160]HiveTaleSource should implment PartitionableTableSourceThis PR implements PartitionableTableSource for HiveTaleSource to support partition pruning.This closes #9032.,1
[FLINK-13157]reeanble unit test read complext type of HiveInputFormatTestThis closes #9037.,3
[FLINK-13128][hive] make HiveGenericUDAF expose accumulator type in order to create its corresponding AggregateFunctionDefinition,5
[FLINK-13155][e2e] fix SQL client end-to-end testThis closes #9051,3
[FLINK-13076] [table-planner-blink] Bump Calcite dependency to 1.20.0 in blink planner,2
[FLINK-13076] [table-planner-blink] Support true condition on lookup join conditionThis closes #8962,1
[hotfix][table-planner-blink] revert commons-codec exclusion.,4
[FLINK-12348][table-planner-blink] Use TableConfig in api module to replace TableConfig in blink-planner module.This closes #8294,2
"[FLINK-12852][network] Timeout to avoid the deadlock when requesting exclusive buffers (#8925)This commit tries to replace the deadlock problem during requesting exclusive buffers with a timeout. Since currently the number of maximum buffers and the number of required buffers are not the same for local buffer pools, there may be cases that the local buffer pools of the upstream tasks occupy all the buffers while the downstream tasks fail to acquire exclusive buffers to make progress. Although this problem can be fixed by increasing the number of total buffers, the deadlock may not be acceptable. Therefore, this commit tries to failover the current execution when the timeout occurs and tips users to increase the number of buffers in the exception message.",1
"[FLINK-13141][network] Remove getBufferSize method from BufferPoolFactoryBufferPoolFactory#getBufferSize is only used for creating subpartitions in ResultPartitionFactory. We could pass the networkbuffer size from NettyShuffleEnvironmentConfiguration while constructing the ResultPartitionFactory, then the interface methodgetBufferSize could be removed form BufferPoolFactory.",4
[hotfix][network] Fix checkstyle violations,0
[FLINK-13185][sql-parser][table-planner] Bump Calcite dependency to 1.20.0 in sql parser & flink plannerThis closes #9056,2
[FLINK-13214][hive] Add jdk.tools exclusion for Java 9,1
[FLINK-13107][table-planner-blink] Introduce fieldNames to TypedFlinkTableFunction to using fieldNames which is specified.,1
[FLINK-13107][table-planner-blink] Fix Bug when convert DataType which has primitiveClass as convensionClass to TypeInformation.,5
"[FLINK-13107][table-planner-blink] Derive sum, avg, div return type in planner expressions using behavior of blink",2
[FLINK-13107][table-planner-blink] Fix Bug to check whether OverCall is RowMode or RangeMode.,0
[FLINK-13107][table-planner-blink] Copy TableApi IT and UT to Blink planner.This closes #9006,2
[hotfix] [docs] add missing YARN options in CLI docs,2
"[FLINK-13123] [cli] add deperecation warning to ""cancel -s""",2
"[FLINK-13123] [cli] rename ""-s"" parameter of stop command",2
"[FLINK-13123] [rest] align terminology of ""stop"" endpoint with cli",2
[hotfix] [docs] fix typo in docs/README.md,2
[FLINK-13198][core] Add a utility to parse String to Duration,1
[FLINK-13198][table-api] Add a utility to validate and parse duration in DescriptorProperties,5
[hotfix][travis] Remove ES1 from nightly split,4
[FLINK-13209][table-api] Revert TableEnvironment#sql and move ddl support to sqlUpdateThis closes #9081,5
[hotfix] reallocate commons-codec in flink planner & blink planner,2
[FLINK-13208][table-planner][table-planner-blink] Update Notice files after adding commons-codec to table package.This closes #13208,1
[FLINK-13112][table-planner-blink] Support LocalZonedTimestampType in blink plannerThis closes #9036,2
"[hotfix][FLINK-12348][table-api] Remove setConf(String, String) method in TableConfig",5
[hotfix][python] Use the TableEnvironment.execute() method instead of ExecutionEnvironment.execute()/StreamExecutionEnvironment.execute(). (#9087),1
[FLINK-10245][hbase] Add an upsert table sink factory for HBaseThis commit adds full support for HBase to be used with Table & SQL API.It includes:- HBase upsert table sink (for append-only and updating queries)- HBase table factory- HBase table descriptors & validators- Unit testsThis closes #9075,3
[FLINK-13118][jdbc] Introduce JDBC table factory and bridge JDBC table source with streaming table source (#9029),5
[hotfix] Remove RpcTimeout annotation from SlotPool,4
"[FLINK-13165] Complete slot requests in request orderThis commit makes sure that slot requests enqueued at the SlotPoolImpl will get completedin the order in which they were requested. This makes sure that the original request orderwill be respected, hence preventing deadlock situations where dependent requests get completedfirst.This closes #9043.",1
[hotfix] Introduce SlotPoolPendingRequestFailureTest suiteMove testFailingAllocationFailsPendingSlotRequests from SlotPoolImplTest toSlotPoolPendingRequestFailureTest.,3
[hotfix] Move SlotPoolImplTest#testSlotRequestCancellationUponFailingRequest to SlotPoolPendingRequestFailureTest,3
[hotfix] Add SlotPoolPendingRequestFailureTest#testPendingSlotRequestTimeout,3
"[FLINK-13166] Add support for batch slot requests to SlotPoolImplThis commit adds a new type of slot request which can be issued to the SlotPoolImpl.The batch slot request is intended for batch jobs which can be executed with a singleslot (having at least one slot for every requested resource profile equivalence class).Usually, a job which fulfills this criterion must not contain a pipelined shuffle.The new batch slot request behaves in the following aspects differently than the normalslot request:* Batch slot request don't time out if the SlotPool contains at least one allocated slotwhich can fulfill the pending slot request* Batch slot request don't react to the failAllocation signal from the ResourceManager* Batch slot request don't fail if the slot request to the resource manager failsIn order to time out batch slot request which cannot be fulfilled with an allocated slot,the SlotPoolImpl schedules a periodic task which checks for this condition. If a slot cannotbe fulfilled, it is marked as unfulfillable and the current timestamp is recorded. If theslot cannot be marked as fulfillable until the batch slot timeout has been exceeded, theslot request will be timed out.The batch slot request will be requested by calling SlotPool#requestNewAllocatedBatchSlot.Add SlotPool#requestNewAllocatedBatchSlotThis closes #9058.",5
"[hotfix] Introduce TestingSlotPoolImpl to expose trigger timeout methodsIn order to not clutter the production implementation with testing methods, thiscommit introduces the TestingSlotPoolImpl and moves the trigger timeout methodsand the convenience constructor to this class.",4
[hotfix] Move schedule mode decision to SchedulingUtils#schedule,4
[hotfix] Make ExecutionGraph#scheduleMode and #allowQueuedScheduling finalRemoves the lazy setting of the scheduleMode and the allowQueuedScheduling from theExecutionGraph.,1
[hotfix] Remove unused code paths in ExecutionJobVertex,1
[hotfix] Make SlotPoolBuilder a top level class,1
[hotfix] Introduce SlotPoolUtils to share common testing utilities for the SlotPoolImpl,3
"[FLINK-13187] Introduce ScheduleMode#LAZY_FROM_SOURCES_WITH_BATCH_SLOT_REQUESTThe new ScheduleMode#LAZY_FROM_SOURCES_WITH_BATCH_SLOT_REQUEST works similar to theold ScheduleMode#LAZY_FROM_SOURCES just with the difference that the slot requestscall the SlotPool#requestNewAllocatedBatchSlot which requests batch slots. Theidea of batch slots is that the requests won't time out as long as there is anallocated slot registered at the SlotPool which can fulfill the slot request(being equal or larger than the requested ResourceProfile).Hence, this ScheduleMode allows for batch job execution with fewer slots than requested.The user, however, has to make sure that every pipelined region of the submitted job requiresonly one slot to be executed!The different types of slot requests are encapsulated in the newly introducedSlotProviderStrategy. Depending on the ScheduleMode, the strategy will either callSlotProvider#allocateSlot or SlotProvider#allocateBatchSlot.This closes #9073.",1
"[hotfix] Remove unused parameters from Execution#allocateAndAssignSlotForExecutionDue to the introduction of the SlotProviderStrategy which encapsulats the SlotProvider,the allowQueuedScheduling property and potentially the allocation timeout, some of theparameters of the allocateAndAssignSlotForExecution were no longer needed. This commitremoves these parameters.",2
[FLINK-12602][travis] Correct the flink pom `artifactId` config and s (#8563) Brief change log:  - remove the scala version suffix for connector-hive and queryable-state-client-java  - add the scala dependencies for table-api-scala and flink-sql-connectors  - correct the scala-free check logic in `verify_scala_suffixes.sh`,0
[FLINK-13121][table-planner-blink] Set properties to StreamGraph in blink executorThis closes #9057,2
[FLINK-13115] [table-planner-blink] Move SQL_OPTIMIZER_CNF_NODES_LIMIT from SelectivityEstimator into FlinkRexUtil,2
[FLINK-13115] [table-planner-blink] fix codegen error for udf in ExpressionReducer,0
[FLINK-13115] [table-planner-blink] Introduce planner rule to support partition pruning for PartitionableTableSourceThis closes #9080,1
[FLINK-13211][table-planner] Add drop table support for flink planner,2
[FLINK-13220][table-planner-blink] Add DDL support for blink plannerThis closes #9093,2
"[hotfix][network] Move private NoOpResultSubpartitionView class out of PartitionRequestQueueTestNoOpResultSubpartitionView is defined as a private class in PartitionRequestQueueTest. It could be used widelyin other places future, so it is reasonable to refactor it as a separate public class.",4
"[hotfix][network] Make BoundedBlockingSubpartitionType configurableThe current BoundedBlockingSubpartitionType is internally selected based on memory architecture, so it is difficult to coverall the type implementations in ITCases/tests. The config option ""taskmanager.network.bounded-blocking-subpartition-type"" isadded into NettyShuffleEnvironmentOptions only for ITCases/tests at the moment. And we make BoundedBlockingSubpartitionTypeaslo configurable in ResultPartitionBuilder.",5
"[FLINK-13100][network] Fix the bug of throwing IOException while FileChannelBoundedData#nextBufferThe implementation of FileChannelBoundedData#nextBuffer assumes that there is always an available buffer, otherwise an IOException is thrownand it always assumes that pool of two buffers is enough (before using the 3rd buffer, first one was expected to be recycled already). But inthe case of pending flush operation (when the socket channel is not writable while netty thread is calling writeAndFlush method), the firstfetched buffer from FileChannelBoundedData has not been recycled while fetching the second buffer to trigger next read ahead, which breaks theabove assumption.In order to fix this problem, we make read ahead is not always available for FileChannelBoundedData. If there are no available buffers to readthe next data, we retrigger the read ahead while recycling buffer via ResultSubpartitionView#notifyDataAvailable.",5
[FLINK-13232][table-planner-blink] Fix CURRENT_DATE test to avoid timezone errorThis closes #9095,0
Update version to 1.10-SNAPSHOT,5
[FLINK-13219][hive] Disable tests for hadoop 2.4 profile,2
[FLINK-13133] [pubsub] Fix small error in PubSub documentation relating to PubSubSink serializer and emulator settings,1
[hotfix] Remove dangerous waiting methods from mailbox,4
[FLINK-12804] Introduce mailbox-based ExecutorService,2
[FLINK-12804] Change mailbox implementation from bounded to unboundedThis closes #8692.,4
[FLINK-12766][runtime] Introduce merge and subtract calculations and tests for ResourceProfile.,2
[FLINK-12765][coordinator] Change the default resource spec to UNKNOWN,4
[hotfix] [tests] Checkstyle fixes and minor code cleanup in ResourceProfileTest and ResourceSpecTest,3
[FLINK-12766][runtime] Fix bug in merging and converting UNKNOWN ResourceSpecs.,0
[hotfix][runtime] Preserve singleton property of UNKNOWN ResourceSpec and ResourceProfile,2
"[hotfix][core] Minor cleanups to the ResourceSpec class  - Some JavaDoc comments  - Make the class final, because several methods are not designed to handle inheritence well.  - Avoid repeated string concatenation/building",0
"[FLINK-12765][coordinator] Disable jobs where some, but nor all, vertices have configured resource profiles",2
[FLINK-12765][jobmanager] Keep track of the resources used in the task slot hierarchy,1
[FLINK-12765][jobmanager] Let some slot reqests fail if the sharing slot is oversubscribed,0
[FLINK-13250][blink runner] Make sure that all nodes have a concrete resource profileThis change is covered by various existing integration tests that failed prior to this fix.,0
"[FLINK-13109][docs-zh] Translate ""Restart Strategies"" page into ChineseThis closes #9047",1
[hotfix][doc] Remove invalid endunless tag in cli.md,4
[FLINK-13229][table-planner-blink] ExpressionReducer with udf bug in blink (#9091),2
[FLINK-13236][table-runtime-blink] Fix bug and improve performance in TopNBuffer (#9098),1
[FLINK-13217][table-planner-blink] Fix FlinkLogicalRelFactories to make it compile with Scala 2.12,1
[FLINK-13253][jdbc] Deadlock may occur in JDBCUpsertOutputFormat (#9107),5
[FLINK-13243][tests] Simplify exception matching,3
[hotfix][tests] Remove legacy case,4
[FLINK-13154][docs] Fix broken links,2
[FLINK-12995][hive] Add Hive-1.2.1 build to Travis,1
don't need a separate stage,5
move clean to get_test_modules_for_stage,3
move to cron job,4
address comments,1
address comment,1
"[FLINK-13124] Don't forward exceptions when finishing SourceStreamTaskBefore, exceptions that occurred after cancelling a source (as theKafkaConsumer did, for example) would make a job fail when attempting a""stop-with-savepoint"". Now we ignore those exceptions.",0
[FLINK-13205][runtime] Make stop-with-savepoint non-blocking on SourceStreamTask checkpoint injecting thread,1
[FLINK-13205][runtime] Make checkpoints injection ordered again (partial revert of FLINK-11458): use single threaded Task's dispatcher thread pool,1
[hotfix] Fix IOUtils.closeAll exceptions aggregation,0
[hotfix][runtime] SynchronousSavepointLatch: check completion condition in the blocking method in case of spurious wakeups,0
[FLINK-11727][formats] Fixed JSON format issues after serializationThis commit reworks JSON format to use a runtime converter created basedon given TypeInformation. Pre this commit conversion logic was based onreference comparison of TypeInformation which was not working afterserialization of the format.This also introduces a builder pattern for ensuring future immutabilityof schemas.This closes #7932.,1
[FLINK-13264][table] Let the planner supply its type inference utilThis closes #9116.,5
[FLINK-13069][hive] HiveTableSink should implement OverwritableTableSinkThis PR makes HiveTableSink implements OverwritableTableSink.This closes #9067.,1
[FLINK-13170][table-planner] Planner should get table factory from catalog when creating sink for CatalogTablePlanner should first try getting table factory from catalog when creating table sinks for CatalogTable.This closes #9039.,2
[FLINK-12277][table/hive/doc] Add documentation for catalogsThis PR adds comprehensive documentation for unified catalog APIs and catalogs.The ticket for corresponding Chinese documentation is FLINK-13086.This closes #8976.,2
[FLINK-13024][table] integrate FunctionCatalog with CatalogManagerThis PR integrates FunctionCatalog with Catalog APIs.This closes #8920.,2
[FLINK-13263] [python] Supports explain DAG plan in flink-pythonThis closes #9114,2
[FLINK-13176][SQL CLI] remember current catalog and database in SQL CLI SessionContextThis PR supports remembering current catalog and database that users set in SQL CLI SessionContext.This closes #9049.,1
[FLINK-13268][table-planner-blink] Revert SqlSplittableAggFunction to support making two planners available in one jarThis closes #9119,1
"[FLINK-13216][FLINK-13153][table-planner-blink] Fix Max_Retract and Min_Retract may produce incorrect resultThe reason is we didn't set null to acc.max/min which may have an old value when we need to get a new max/min from an empty MapView.And the old value will be output to downstream instead of a null value. This influences the final result.This causes many unstable cases, including:- AggregateITCase.testNestedGroupByAgg- SplitAggregateITCase.testMinMaxWithRetractionThis closes #9120",3
[FLINK-13193][tests] Enable custom flink cluster config per testEnable users to set a cluster configuration in the test spec which will haveprecedence over the default configuration.Remove --ha-storage-dir parameter because the user can set this value in thetest spec cluster configuration now.This closes #9070.,5
"Revert ""[FLINK-8801][yarn/s3] fix Utils#setupLocalResource() relying on consistent read-after-write""This reverts commit c90a757b29f168144b1bae99df532911ae682e63.",4
[FLINK-8801][yarn/s3] Retry if remote file not found and use remote modification time,1
[FLINK-13215][hive] Simplify copying of classpath,2
[FLINK-13223][dist] Enable fine-grained recovery by default in distribution,0
[FLINK-13104][metrics][datadog] Log all failed requests,0
[FLINK-11860][config] Update usages of deprecated (job-/taskmanager).heap.mb,5
[FLINK-11428][tests] Prevent file leak,2
[FLINK-13294][sql client] disable LocalExecutorITCase.testUseCatalogAndUseDatabase,5
[FLINK-13307][tests] Fix SourceStreamTaskTest test instability.,3
[FLINK-13168][table] Clarify isBatch/isStreaming/isBounded flag in flink planner and blink planner,2
[FLINK-13275] Fix race condition in finishTask().,5
[FLINK-13299][travis][python] fix flink-python failed on Travis because of incompatible virtualenv (#9140),1
"[FLINK-13296][table] FunctionCatalog.lookupFunction() should check in memory functions if the target function doesn't exist in catalogCurrently the logic to lookup a function is check either the catalog or the in memory function. But the correct logic is to 1st check the catalog, and if the function doesn't exist there, check in memory functions. There should be a resolution order.This closes #9135.",1
"[FLINK-13280][table-planner-blink] Revert blink changes in DateTimeUtils, and keep it same as flink versionThis closes #9124",2
[FLINK-13161][table-blink-runtime] Fix calculation of numBuckets in BinaryHashBucketAreaThe original calcucation may lead to some requested segments are wasted.This closes #9027,0
[hotfix][kafka] Fix typo in filter property in pom.xmlThis closes #9142,5
[FLINK-13256] Ensure periodical checkpointing continues when regional failover aborts pending checkpointsThis closes #9128.,0
"[FLINK-13316][legal] Update binary licensingThis commit includes the deterministic ordering of NOTICE entries (FLINK-11836), resulting in an abnormally large diff.It is recommended to view the actual diff via ""git diff release-1.8.0..<branch> --patience"".licenses-binary changes and their cause:flink-ml removal:- arpack- machnist- spire- jtransforms- coreflink-shaded-hadoop removal:- jsch- paranamer- xmlenc- cddlv1.0- cddlv1.1flink-shaded update:- asminfluxdb-reporter:- influxThe remaining changes are due to the WebUI update.NOTICE-binary changes:It is hard to tell which changes this commit specifically does (due to the re-ordering).Hence, here's a changelog compared to 1.8.0:add flink-azure-fs-hadoopupdate akkaupdate scala-parser-combinatorsupdate flink-shaded-jacksonadd new WebUIremove flink-shaded-asm (switched fully to flink-shaded-asm-6)remove flink-ml-uberremove flink-mlremove apache camel (previous flink-yarn dependency)replace flink-pythonadd flink-shaded-netty-openssl-staticupdate calciteupdate janino",5
[FLINK-13249][runtime] Fix handling of partition producer responses b (#9138)* [FLINK-13249][runtime] Fix handling of partition producer responses by running them with the task's executor* Review comments,1
[FLINK-13281][tests] Improve test for aborting pending checkpoints on failover,0
[FLINK-13320][catalog][docs] Remove broken link,2
[FLINK-13319][catalog][docs] Add chinese version,1
[FLINK-12578][build] Use secure MapR repository by default,1
[FLINK-12578][build] Add fallback unsafe MapR repository,1
[FLINK-13287][table-planner] Support STREAM_RECORD_TIMESTAMP call in table planner,1
[FLINK-13287][table-planner] Support Reinterpret cast call in blink planner,2
[FLINK-13287][table-api] Port ExistingField to api-java and use new Expression in FieldComputer,1
[FLINK-13287][table-api] Port StreamRecordTimestamp to api-javaThis closes #9129.,2
[FLINK-13315][api-java] Port wmstrategies to api-java-bridgeThis closes #9153.,1
[hotfix][table-common] Fix minor typos in ObjectIdentifier,2
[hotfix][table-common] Update list of synonyms for logical types,2
[hotfix][table-common] Link timestamp precisions,2
[FLINK-13078][table-common] Simplify serializable string representation for parsers,2
[FLINK-13078][table-common] Add an unresolved user-defined logical type,2
[FLINK-13078][table-common] Add a logical type parserThis adds a parser for all logical types defined in FLIP-37.This closes #9061.,2
[FLINK-13312][hive] move tests for data type mappings between Flink and Hive into its own test classThis PR moves UT for data type mapping between Flink and Hive to its own test class.This closes #9151.,3
[FLINK-13327][table-planner-blink] Fixed scala 2.12 compilation,0
[FLINK-13269][table] Copy RelDecorrelator & FlinkFilterJoinRule to flink planner to fix CALCITE-3169 & CALCITE-3170This closes #9122,0
[FLINK-13302][table-planner] Fix CEIL(date) returns the same value with FLOOR(date)This is a bug that DateTimeUtils.unixDateCeil returns the same value as unixDateFloor does.This closes #9160,5
[FLINK-12578][build] Use fallback unsafe MapR repository,1
[hotfix][docs] Fix loop redirection in /dev/projectsetup/dependencies.html (#9177),1
[FLINK-13186][clients] Remove unused fields,1
[FLINK-12916][tests] Retry cancelWithSavepoint on cancellation barrier,1
[FLINK-12916][tests] Rework regex,1
[FLINK-13310][hive][build] Remove shade-plugin configuration,5
[hotfix] Add directory link-python/apache_flink.egg-info to gitignore,5
[FLINK-13308][python] Drop the classifier of the flink-python jar,2
[FLINK-13255][hive] Skip tests on Java 9,3
[FLINK-13286][table-api] Port RowtimeValidator and SchemaValidator to api-java-bridgeThis closes #9168,1
[FLINK-13286][table-common] Port FileSystem and FileSystemValidator to common,5
[FLINK-13321][table-planner-blink] Fix lateral join udtf with constant parameters doesn't work in blink plannerThis closes #9162,2
[FLINK-13274]Refactor HiveTableSourceTest using HiveRunnerRefactor HiveTableSourceTest to use HiveRunner.This closes #9130.,1
[FLINK-13293] [state-processor-api] [build] Add state processor api to opt/ directory in flink-distThis closes #9133.,2
[FLINK-13094][state-processor-api] Support iterating over registered timers in the internal timer serviceCertain operations require querying the registered timers for a key buttimers are stored TIMESTAMP -> KEY[] which would only support O(n)reads. Because the timer service sits in the per-record code path we optto add forEach*RegisteredTimer methods so consumers can copy data into amore appropriate data structure to avoid any accidental performancedegredations.,5
[FLINK-13094][state-processor-api] Add registered*TimeTimers methods to KeyedStateReaderFunction#Context for querying the registered timers for a given keyThis closes #9094.,1
[FLINK-13284][table-planner-blink] Correct some builtin functions' return type inference in Blink plannerThis closes #9146,2
[FLINK-13304][table-runtime-blink] Fix implementation of getString and getBinary method in NestedRowThis closes #9139,1
[FLINK-13322][table-runtime-blink] Fix serializer snapshot recovery in BaseArray and BaseMap serializers,0
[FLINK-13323][table-runtime-blink] Add tests for complex data formats,5
[FLINK-13326] Add closeInterruptibly(),1
"[FLINK-13326] Use ResourceGuard in NonClosingCheckpointStreamThis commit adds the ability for users to indicate to Flink that theKeyedStateCheckpointOutputStream / OperatorStateCheckpointOutputStream should be closedat some point later in time. Previously it was expected to be closed within the synchrounspart of AbstractStreamOperator#snapshotState.Users might call KeyedStateCheckpointOutputStream#acquireLease(), and at some pointin the future might release the least. Once the number of leases reaches 0, the streamwould be closed.",1
"[FLINK-13326] Support async rawState checkpointingThis commit adds the ability for users to obtain a lease for therawOperator/rawKeyed output streams, during the synchronous partof a snapshot, thus preventing these streaming to close.",1
[FLINK-13266] [table] move ExpressionParserException & UnresolvedException to table-common module,0
[FLINK-13266] [table] remove definedTimeAttributes file in blink plannerthose classes are already in table-common module,2
[FLINK-13266][table-runtime-blink] remove Order class from table-runtime-blink,2
"[FLINK-13266][table-common] Improve comment for FilterableTableTableSourceFlink planner planner will push down PlannerExpressions (which are defined in flink-table-planner module), while Blink planner will push down Expressions. So the implementation for Flink planner and Blink planner should be different and incompatible.",2
[FLINK-13313][table] create CatalogTableBuilder to support building CatalogTable from descriptorsThis PR adds CatalogTableBuilder as a replacement of ExternalCatalogTableBuilder to help users convert table source/sink descriptors to CatalogTable. The gap was mainly discovered when I was writing tests for HiveCatalog to make sure it works as expected to persist Flink generic tablesThis closes #9172.,2
[FLINK-13276][hive] write documentation and quickstart for Flink-Hive compatibilityThis PR adds documentation and quickstart for Flink-Hive integration.This closes #13276.,2
[FLINK-13206]replace 'use database' with 'use' in sql client parserReplace use database xxx with use xxx in sql client parser.This closes #9118.,1
"[FLINK-12595][kinesis] Interrupt thread at right time to avoid deadlock- Inside testOriginalExceptionIsPreservedWhenInterruptedDuringShutdown,consumerThread.interrupt() was getting absorbed insideKinesisDataFetcher's while(running) loop, thereforeTestableKinesisDataFetcherForShardConsumerException's awaitTermination()wasn't getting interrupted by it. This led to deadlock, withKinesisDataFetcher waiting on the test code to send the interrupt, andthe test code waiting for KinesisDataFetcher to throw the expectedexception.- Now, the test code waits until KinesisDataFetcher is insideawaitTermination() before producing the interrupt, so it can be surethat the interrupt it produces will be received/handled insideawaitTermination().",0
[FLINK-13221][table-planner-blink] Blink planner should set ScheduleMode to LAZY_FROM_SOURCES_WITH_BATCH_SLOT_REQUEST for batch jobsThis closes #9101,1
"[FLINK-13227][docs-zh] Translate ""asyncio"" page into ChineseThis closes #9150",1
[FLINK-13075][table-planner-blink] Project pushdown rule shouldn't require the TableSource return a modified schema in blink plannerThis closes #9197,2
[FLINK-13262][docs] Add documentation for the new Table & SQL API type systemThis closes #9161.,5
[FLINK-13368][python] Add Configuration Class for Python Table API to Align with Java.This closes #9199,5
[FLINK-13117][table-planner-blink] Do not need to backup and restore streamEnv config in BatchExecutorThis closes #9179,5
[FLINK-13314][table-planner-blink] Correct resultType of some PlannerExpression when operands contains DecimalTypeInfo or BigDecimalTypeInfo in Blink plannerThis also fix some minor bugs:- Fix minor bug in RexNodeConverter when convert between and not between to RexNode.- Fix minor bug in PlannerExpressionConverter when convert DataType to TypeInformation.This closes #9152,5
"[FLINK-13318][table-planner-blink] Fix Blink planner tests failing on Scala 2.12 by setting SerialVersionUID to Scala UDFsThis is because:1. we print the udf's md5 into the node explanation2. blink planner uses XML to verify plan, the XML content is immutable between different Scala versions3. the serialization behavior is different between Scala 2.11 and 2.12 when version id is not defined.That's why we add version id to all existing scala udfs. But this doesn't mean we force users to set this. This is just a workaround for the plan test for different Scala versions. Users can still use a Scala udf without version id in blink planner and flink planner.This closes #9193",2
[FLINK-13369] Track references of already visited object in ClosureCleaner,4
[FLINK-13074][table-planner] Fix PartitionableTableSink doesn't work for flink and blink plannerThis closes #8966,2
[hotfix] fix checkstyle,0
[FLINK-13266][table] Port DataView related classes to flink-table-common,2
[FLINK-13266][table] Port function-related descriptors to flink-table-commonFileSystem/OldCsv/RowtimeValidator/SchemaValidator will be ported in other commits,5
[hotfix][tests] Declare variables in start_taskmanagers() local,3
[hotfix][tests] Improve wait_job_terminal_state() functionAlways terminate script if job is in globally terminal state. Assert thatexpected terminal state matches actual state.,3
"[FLINK-13145][runtime, tests] Enable fine grained failover in E2E HA data set test- Introduce new test job (DataSetFineGrainedRecoveryTestProgram), which waits  for an  external file to be created before finishing.- Introduce killing of TMs to HA data set test.- Reduce JM kills to 2.- Reduce heartbeat interval and timeout to speed up TM loss detection.This closes #9060.",3
[FLINK-13345][tests] Dump jstack output for Flink JVMsDump the jstack output for all Flink JVMs at the end of each Jepsen test in thelog aggregation phase. This can be helpful for debugging deadlocks.This closes #9194.,0
[FLINK-13266][table] Move OptimizerConfigOptions & ExecutionConfigOptions to table-api-java module,5
[FLINK-13266][table] Relocate blink runtime classes to avoid class clashes,1
[FLINK-13266][table] Relocate blink planner classes to avoid class clashes,2
[FLINK-13394][travis] Use fallback unsafe MapR repository,1
[FLINK-13341][table][connectors] StreamTableSink#consumeDataStream returns DataStreamSink when using blink planner.This closes #9186,2
[FLINK-13351][table-blink-planner] Clean up duplicate case clause for ROW in FlinkTypeFactory.toLogicalTypeThis closes #9196,2
"[FLINK-13398][hive][build] Exclude jdk.toolsSpecify a direct exclusion for jdk.tools on the root dependencies, since dependencyManagement entries for transitive are ignored by the shade-plugin artifact resolution.",2
"[FLINK-13169][tests][coordination] Test TaskExecutor failures in fine-grained recovery IT caseThe BatchFineGrainedRecoveryITCase can be extended with an additional test failure strategy which abruptly shuts down the task executor. This leads to the loss of all previously completed and the in-progress mapper result partitions. The fail-over strategy should restart the current in-progress mapper which will get the PartitionNotFoundException because the previous result becomes unavailable and the previous mapper has to be restarted as well. The same should happen subsequently with all previous mappers. When the source is recomputed, all mappers has to be restarted again to recalculate their lost results.",1
[FLINK-13055][runtime] Leverage PartitionTracker for checking partition availability,2
[hotfix][tests] Delete tmp directory after cluster has shut down,4
[FLINK-13378][table-planner-blink] Fix SINGLE_VALUE is not correctly supported in blink plannerThis closes #9208,2
[FLINK-13257][table-planner-blink] Avoid stream operator implementing BoundedOneInput in blink runnerThis closes #9109,1
"[FLINK-13402][table] Copy RelOptCluster to flink planner to fix ""RelOptCluster's constructor can not be accessed when connector depends on both planners""This closes #9215",0
[FLINK-13403][table-planner-blink] Fix some classes' package name is not updated after class relocationThis closes #9216,5
[FLINK-12901][docs] Update Hadoop build instructions,5
[FLINK-13409][python] Supported java UDFs in python API.This closes #9222,1
[FLINK-13210][hive] Hive connector test should dependent on blink planner instead of legacy plannerThis closes #9181,2
[FLINK-13353][table-planner] Remove 2 args constructor in REPLACE expressionThis closes #9218,4
[FLINK-13116][table-planner-blink] Fix Catalog statistics is not bridged to blink plannerThis closes #9083,2
[FLINK-13116][table-planner-blink] Exclude RAT for explain and digest resource files,2
[FLINK-13397] Remove RollingSink,4
[FLINK-12765][coordinator] Add the remaining resources to the slot selection strategy,5
[FLINK-13367] Recognize writeReplace in ClosureCleanerThis closes #9201,4
[FLINK-13222][docs] Add documentation for failover strategy optionAdd detailed failover strategies documentation to doc pagePoint links in ZH docs to ZH pagesUse a relative path in docs link to flink pagesThis closes #9113.,2
[FLINK-13289][table-planner-blink] Blink planner should setKeyFields to upsert table sinkThis closes #9195,1
[hotfix][tests] StandaloneResourceManagerTest extends TestLogger,3
[FLINK-13407][tests][coordination] Harden StandaloneResourceManagerTestGet SlotManager.failUnfulfillableRequest in main thread of StandaloneResourceManagerfor verification in StandaloneResourceManagerTestThis closes #9126.,3
"[FLINK-13393][table-planner-blink] Fix generic TableSource doesn't work in blink plannerThe reason is that blink-planner use TypeExtractor to extract class from TableSource, and use this class to DataFormatConverter. However, blink should use conversion class of DataType in TableSource#getProducedDataType.This closes #9211",5
[FLINK-13391][table] Fix InputFormatTableSource#getDataStream should not call getReturnType.,1
[FLINK-12179][coordination] Remove legacy class Instance,4
[FLINK-13158][rest] Remove WebMonitor interface,4
[hotfix][build] Use HTTPS URL in qa-check.sh,1
[hotfix][py] Use HTTPS URLs in package information,5
[hotfix][build] Use HTTPS URLs,1
[FLINK-12590][docs] Use HTTPS for all Flink links,2
[hotfix][tests] Pull TestTaskBuilder out of TaskTest,3
[hotfix][tests] Make NoOpPartitionProducerStateChecker a public reusable test implementation.,3
[hotfix][tests] Reduce some mocking in TestTaskBuilder,3
[FLINK-13325][test] Add test for FLINK-13249FLINK-13249 was a bug where a deadlock occurred when the network thread got blocked on a lockwhile requesting partitions to be read by remote channels. The test mimicks that situationto guard the fix applied in an earlier commit.,0
[FLINK-13352][docs] Using hive connector with hive-1.2.1 needs libfb303 jarThis closes #9223,1
[FLINK-13012][hive] Handle default partition name of Hive tableThis closes #9088,0
"[FLINK-13451][tests] Remove use of Unsafe.defineClass() from CommonTestUtilsThe method Unsafe.defineClass() is removed in Java 11. To support Java 11, we rework the method""CommonTestUtils.createClassNotInClassPath()"" to use a different mechanism.This commit now writes the class byte code out to a temporary file and create a new URLClassLoader thatloads the class from that file.  That solution is not a complete drop-in replacement, because it cannotadd the class to an existing class loader, but can only create a new pair of (classloader & new-class-in-that-classloader).Because of that, the commit also adjusts the existing tests to work with that new mechanism.This closes #9251",1
[FLINK-13429][table-common] Fix BoundedOutOfOrderTimestamps watermark strategyThis closes #9241.,0
[FLINK-13387][WebUI] Fix log download for old UI,2
"[FLINK-13245][network] Fix the bug of file resource leak while canceling partition requestOn producer side the netty handler receives the CancelPartitionRequest for releasing the SubpartitionView resource.In previous implementation we try to find the corresponding view via available queue in PartitionRequestQueue. Butin reality the view is not always available to stay in this queue, then the view would never be released.Furthermore the release of ResultPartition/ResultSubpartitions is based on the reference counter in ReleaseOnConsumptionResultPartition,but while handling the CancelPartitionRequest in PartitionRequestQueue, the ReleaseOnConsumptionResultPartition is nevernotified of consumed subpartition. That means the reference counter would never decrease to 0 to trigger partition release,which would bring file resource leak in the case of BoundedBlockingSubpartition.In order to fix above two issues, the corresponding view is released via all reader queue instead, and then it would callReleaseOnConsumptionResultPartition#onConsumedSubpartition meanwhile to solve this bug.",0
[FLINK-13245][network] Make subpartition consumption notification independant,1
[FLINK-13245][network] Remove redundant bookkeeping for already canceled input channel IDs,4
[hotfix] Fix typo in api_concepts.md,2
[FLINK-13458][table] ThreadLocalCache clashes for Blink plannerThis closes #9257.,2
[FLINK-13228][tests][filesystems] Harden HadoopRecoverableWriterTestCurrently test cases will fail when trying to close the output stream if all data writtenbut ClosedByInterruptException occurs at the ending phase. This commit fixes it.This closes #9235,0
[FLINK-13447][table] Change default planner to legacy planner instead of any oneThis closes #9249,4
[FLINK-9526][e2e] Fix unstable BucketingSink end-to-end test,3
[FLINK-12747][docs] Getting Started - Table Api Walkthrough,1
[FLINK-13347][table-planner] should handle SEMI/ANTI JoinRelType in switch caseThis closes #9227.,1
[FLINK-13375][table] Improve config names in ExecutionConfigOptions and OptimizerConfigOptionsThis closes #9203,5
"[hotfix][python] Change ""flink-python-"" to ""flink-python"" for the change  of artifact of flink-python module (#9270)",2
[hotfix][table-api-java] Improve documentation of withBuiltinCatalogName & withBuiltinDatabaseName,5
[hotfix][table] Unify default catalog & builtin catalog naming,2
[FLINK-13350][table-api-java] Annotate useCatalog & useDatabase with experimental annotation,5
[hotfix][table-common] Fix logging in the table source validation procedure,5
[FLINK-13279][table-sql-client] Fully qualify sink name in sql-clientThis closes #9229.,2
[hotfix][sql-client] Add USE CATALOG/USE to CLI help,2
[hotfix][test] Extract common variables,4
[FLINK-12171][Network] Do not limit the network buffer memory by heap size on the TM side,1
[hotfix][test] Converting fraction to double to improve the precision,1
[hotfix][Network] Rename the terminology,2
[FLINK-12038][tests] Harden YARNITCaseOnly kill Yarn application if it does not properly terminate.This closes #9175.,3
"[FLINK-13241][yarn/mesos] Fix Yarn/MesosResourceManager setting managed memory size into wrong configuration instance.[FLINK-13241][yarn][test] Update YarnResourceManagerTest#testCreateSlotsPerWorker to compute tmCalculatedResourceProfile based on the RM altered configuration.[FLINK-13241][yarn][test] Update YarnConfigurationITCase to verify that TMs are started with correct managed memory size.[FLINK-13241][runtime] Calculating and set managed memory size outside of ResourceManager.[FLINK-13241][rumtime/yarn][test] Move YarnResourceManagerTest#testCreateSlotsPerWorker to ResourceManagerTest#testCreateWorkerSlotProfiles, and update to verify slot profile calculation with determinate managed memory size.[FLINK-13241][runtime] Move getResourceManagerConfiguration from ResourceManagerFactory to ResourceManagerUtil.This closes #9246.",5
[FLINK-12249][table] Fix type equivalence check problems for Window AggregatesThis closes #9141,3
[FLINK-13488][Python] Remove python 3.3/3.4 support (#9278),1
[FLINK-13399][table] Create two separate table uber jars for old and blink planners,2
[FLINK-13399][table][docs] Updated the required dependencies section of Table API documentation,2
[FLINK-13399][legal] Update NOTICE-binary for new table uber jarsThis closes #9261.,1
[hotfix] Fix checkstyle violations in StandaloneResourceManagerTest,3
[hotfix][runtime] Extract SlotManager interfaceRename SlotManager -> SlotManagerImpl and let it implement the SlotManager interface,4
"[FLINK-13408][runtime] Let StandaloneResourceManager start startup period upon granting leadershipDuring the startup period, the StandaloneResourceManager won't fail slot requests if it cannot allocate newcontainers.[FLINK-13408][runtime][test] Add StandaloneResourceManagerTest#testStartUpPeriodAfterLeadershipSwitch validates that StandaloneResourceManager applies a startup period whenever the leadership is acquired.[FLINK-13408][runtime] StandaloneResourceManager#startStartupPeriod uses RpcEndpoint#scheduleRunAsync.This closes #9242.",1
[hotfix] Make TestingSlotManager#setFailUnfulfillableRequestConsumer non-nullable,3
[hotfix] Remove polling loops from StandaloneResourceManagerTest,3
[hotfix] Rename TestingSlotManagerFactory into TestingSlotManagerBuilder,3
[hotfix] [travis] Fix the python travis failure (#9286),0
[FLINK-13431][hive] Fix nameNode HA configuration was not loaded when running HiveConnector on YarnThis closes #9237,1
[hotfix][tests] Refactor MapR FS Tests,3
[FLINK-13499][maprfs] Handle MapR dependency purely through reflectionThis allows us to remove the MapR dependency from the module.The MapR maven dependency has frequently caused issues.,0
[hotfix][tests] TimestampITCase: use explicit CheckpointFailureReason to ignore exception,0
[FLINK-12858][checkpointing] Fail whole job when in-flight sync savepoint is discarded by a task,0
[FLINK-12858] Change the CHECKPOINT_COORDINATOR_SHUTDOWN to be not pre-flight.,4
[hotfix] Rename flag in CheckpointFailureReason to preFlight,0
[FLINK-13440] Report reason when failing job due to checkpoint failure.,0
[FLINK-13440] Move checkpoint failure logic from scheduler to failure manager,0
[FLINK-13440] Add test for FLINK-12858,2
[FLINK-13396] Deprecate the BucketingSink,2
[FLINK-13487][tests] Wait until TE has registerd at JM,3
[FLINK-10725][build] Initialize JDK 11 profile,2
[table-api-java] Postpone check for Blink planner in StreamTableEnvironment,2
[FLINK-13273][table-planner-blink] Allow retrieving StreamGraph from Blink executor,2
[hotfix][table-planner-blink] Update Blink's auto-complete hints,2
[hotfix][table-planner-blink] Update Blink's ExpressionReducer classloading to Flink's behavior,2
[FLINK-13273][sql-client] Allow switching planners in SQL ClientThis closes #9266.,1
[hotfix][table] Add missing annotations to factories,1
[FLINK-13456][build] Bump lombok to 1.16.22,2
[FLINK-13453][build] Bump shade plugin to 3.2.1,2
[FLINK-13455][build] Move jdk.tools exclusions out of dependency management,4
[FLINK-13423][hive] Unable to find function in hive 1This closes #9279,1
"[FLINK-13226][connector/kafka] Fix deadlock between producer closure and transaction commit in Kafka connector 0.11This patch fixes a race condition between the checkpointing thread and main thread.The sequence causing the deadlock is the following:    1. In FlinkKafkaProducer, the main thread encounters a problem and closes all the producer       to start failover.    2. The previous checkpoint has completed, so the checkpointing thread grabs the checkpoint       lock and tries to commit the transaction on the producer that has been closed in step 1.       This commit will never succeed due to KAFKA-6635. So the checkpoint thread blocks forever.    3. In StreamTask, the main thread will eventually try to release all the record writer.       To do that, it attempts to grab the checkpoint lock which is hold by checkpoint thread in       step 2 and will never be released. So the main thread also blocks forever.KAFKA-6635 has been fixed in Kafka 2.3.0. But Flink 1.9 does not rely on that yet, and we alsosupport Kafka 0.11. So we are just going to fix on the Flink side first. The solution is to makesure that in FlinkKafkaProducer any operation relying on the underlying sender thread to finishthrows an exception if the producer is closed.",5
"[FLINK-13226][connector/kafka] Fix deadlock between producer closure and transaction commit in the universal Kafka connector.This patch fixes a race condition between the checkpointing thread and main thread.The sequence causing the deadlock is the following:    1. In FlinkKafkaProducer, the main thread encounters a problem and closes all the producer       to start failover.    2. The previous checkpoint has completed, so the checkpointing thread grabs the checkpoint       lock and tries to commit the transaction on the producer that has been closed in step 1.       This commit will never succeed due to KAFKA-6635. So the checkpoint thread blocks forever.    3. In StreamTask, the main thread will eventually try to release all the record writer.       To do that, it attempts to grab the checkpoint lock which is hold by checkpoint thread in       step 2 and will never be released. So the main thread also blocks forever.KAFKA-6635 has been fixed in Kafka 2.3.0. But Flink 1.9 does not rely on that yet, So we are justgoing to fix on the Flink side first. The solution is to make sure that in FlinkKafkaProducer anyoperation relying on the underlying sender thread to finish throws an exception if the produceris closed.",5
[hotfix] Fix static inner class name collision in KafkaConsumerTestBase.,3
"[FLINK-11321] Clarify NPE on fetching nonexistent topic (#7487)[FLINK-11321][connector/kafka] Throw explicit exception on fetching nonexistent topic.Before the fix, NPE will be thrown if a consumer is trying to fetch from a nonexistent topic. The fix throws a RuntimeException with a clear message.",1
[FLINK-13464][build] Bump powermock to 2.0.2,2
[FLINK-13465][build] Bump javassist to 3.24.0-GA,2
[FLINK-13511][kafka][build] Add test jaxb dependency,3
[hotfix][docs] Reference file systems documentation from batch/connectors docs,2
[FLINK-12998][docs] Document optional file systems libs to use plugins loading mechanism,1
[FLINK-12998][docs] Extend debugging_classloading documentation with plugins loading case,2
[FLINK-13434][e2e] Change the test_resume_savepoint to use stop-with-savepoint.,1
[FLINK-13434][e2e] Change test_stateful_stream_job_upgrade to use stop-with-savepoint.,1
[hotfix][e2e] Harden test_resume_savepoint e2e test.,3
[hotfix][e2e] Harden test_stateful_stream_job_upgrade e2e test.,3
[FLINK-13376][datastream] ContinuousFileReaderOperator should respect semantics of BoundedOneInput,2
[FLINK-13376][datastream] Unify all no operation sinks with DiscardingSink,5
[FLINK-13491][datastream] correctly support endInput in AsyncWaitOperatorBefore completing endInput operator has to make sure that all of the records were emitted.,1
[hotfix][tests] Remove setting the default value of force-release-on-consumption,1
[FLINK-13435] Remove ShuffleDescriptor.ReleaseType and make release semantics fixed per partition typeIn a long term we do not need auto-release semantics for blocking (persistent) partition. We expect them always to be released externally by JM and assume they can be consumed multiple times.The pipelined partitions have always only one consumer and one consumption attempt. Afterwards they can be always released automatically.ShuffleDescriptor.ReleaseType was introduced to make release semantics more flexible but it is not needed in a long term.FORCE_PARTITION_RELEASE_ON_CONSUMPTION was introduced as a safety net to be able to fallback to 1.8 behaviour without the partition tracker and JM taking care about blocking partition release. We can make this option specific for NettyShuffleEnvironment which was the only existing shuffle service before. If it is activated then the blocking partition is also auto-released on a consumption attempt as it was before. The fine-grained recovery will just not find the partition after the job restart in this case and will restart the producer.,1
[hotfix][network] fix codestyle issues in ResultPartitionFactory,0
[hotfix][network] Annotate NettyShuffleDescriptor#PartitionConnectionInfo with @FunctionalInterface,1
[hotfix][network] fix codestyle issues in NettyShuffleMaster,0
[hotfix] fix codestyle issues in ShuffleDescriptor,0
[hotfix][tests] Make PartitionTestUtils enum singleton and fix codestyle,0
[hotfix][tests] fix codestyle issues in ResultPartitionBuilder,0
[hotfix][tests] fix codestyle issues in ResultPartitionFactoryTest,3
[hotfix][tests] fix codestyle issues in NettyShuffleEnvironmentBuilder,0
[hotfix][tests] fix codestyle issues in NettyShuffleDescriptorBuilder,0
[hotfix][tests] fix codestyle issues in NettyShuffleEnvironmentConfiguration,5
[hotfix][network] Simplify ResultPartitionFactory.createSubpartitions based on ResultPartitionType.isBlocking,1
[FLINK-13454][build] Bump japicmp jaxb dependencies,2
[FLINK-13374][scala][build] Set -Xss2m when compiling scala,1
[FLINK-12704][python] Enable the configuration of using blink planner.This closes #9314,2
[FLINK-9900][tests] Fix unstable ZooKeeperHighAvailabilityITCaseThis closes #9900.,1
[FLINK-12966][hive] finalize package name of Hive table source/sinkfinalize package name of Hive table source/sink from org.apache.flink.batch.connector to org.apache.flink.connector.This closes #9290.,2
[FLINK-13424][hive] HiveCatalog should add hive version in confTo avoid overriding the hive version users specify in the yaml file.This closes #9232.,2
"[FLINK-13290][table-api] Add method to check LogicalType compatibleAdd a areTypesCompatible() method to LogicalTypeChecks. This will compare two LogicalTypes without field names and other logical attributes (e.g. description, isFinal).",2
[FLINK-13290][table-planner-blink] SinkCodeGenerator should not compare row type field names,2
[FLINK-13290][hbase] Enable blink planner for integration tests of HBaseThis commit combines HBaseTableSourceITCase and HBaseLookupFunctionITCase and HBaseConnectorITCase into one class.This can save much cluster initialization time for us.This closes #9275,5
[table-api-java] Change the default value of table.exec.sort.default-limit to -1,4
[FLINK-13436][e2e] Add TPC-H queries as E2E testsThis closes #9312,3
[FLINK-13427][hive] HiveCatalog's createFunction fails when function name has upper-case charactersThis closes #9254,1
[hotfix][coordination] Check whether partition set to track is empty,1
[FLINK-13371][coordination] Prevent leaks of blocking partitions,2
[FLINK-13494][table-planner-blink] Remove source and sink parallelism configurationsThis closes #9277,5
[FLINK-13421] Exclude releasing root slots from slot allocationMake MultiTaskSlot not available for allocation when its releasing childrento avoid ConcurrentModificationException.This closes #9288.,1
[FLINK-13543][table-planner-blink] Enable reuse forks for integration tests in blink plannerThis closes #9326,2
[FLINK-13338][table] Make SQL dialect configurableThis closes #9212.,5
[FLINK-13546][travis] Add TPC-H E2E test in travis cron jobThis closes #9330,3
[FLINK-13544][connectors] Set parallelism of table sink operator to input transformation parallelismThis closes #9332,1
[hotfix][table-sql-parser] Removed unnecessary dependency on guava.,4
[hotfix][table-planner] Added joda.convert to planner jar,1
[FLINK-13504][table] Fixed shading issues in table modules.Properly include the flink-sql-parser into flink-planner* modules shadedjars. Removed the flink-sql-parser module from flink-table-uber* jars asit is already included in the flink-planner* modules.This closes #9313.,2
"[FLINK-13335][sql-parser] Bring the SQL CREATE TABLE DDL closer to FLIP-37This brings the SQL DDL closer to FLIP-37. However, there are a couple ofknown limitations.Currently unsupported features:- INTERVAL- ROW with comments- ANY- NULL- NOT NULL/NULL for top-level types- ignoring collation/charset- VARCHAR without length (=VARCHAR(1))- TIMESTAMP WITH TIME ZONE- user-defined types- data types in non-DDL parts (e.g. CAST(f AS STRING))This closes #9243.",5
"[FLINK-13535][connector/Kafka] do not abort transactions twice during KafkaProducer startupDuring startup of a transactional Kafka producer from previous state, we recoverin two steps:1) in TwoPhaseCommitSinkFunction, we commit pending commit-transactions and   abort pending transactions and then call into finishRecoveringContext()2) in FlinkKafkaProducer#finishRecoveringContext() we iterate over all recovered   transaction IDs and abort them.This may lead to some transactions being worked on twice. To avoid the overheadassociated with it (creating a KafkaProducer for each of these transactions isexpensive), we provide finishRecoveringContext() with a collection of alltransactions that TwoPhaseCommitSinkFunction already covered and that do notneed to be aborted again. The FlinkKafkaProducer instances then ignoretransactional IDs from that set.",1
[FLINK-13541][state-processor-api] State Processor Api sets the wrong key selector when writing savepointsThis closes #9324,0
[FLINK-12768][tests] Fix FlinkKinesisConsumerTest.testSourceSynchronization race conditionThis closes #9183.,3
[hotfix] Let FlinkKinesisConsumerTest extend TestLogger,3
[hotfix] Introduce TestingLogicalSlotBuilder,3
[FLINK-13334][coordination] Remove legacy slot implementationThis closes #9245.,4
[FLINK-13385]Align Hive data type mapping with FLIP-37Align Hive data type mapping with FLIP-37.This closes #9239.,5
[hotfix][python] Fix the package name of PythonGatewayServer (#9351),0
[FLINK-13476][coordination] Release pipelined partitions on vertex restart / job failure,0
[FLINK-13190][hive] Add tests to verify partition pruning for HiveTableSourceThis closes #9310,1
[FLINK-13518][hive] Disable tests on Java 11,3
[FLINK-13532][docs] Fix broken links of zh docsThis closes #9344,2
[FLINK-10257][table-common] Generalize variable strings for varying lengthsThe Blink planner generalizes multiple CHAR literals into VARCHAR. It seemslikely that we will adopt this behavior in the future to prevent unwantedside-effects for users. This PR updates the existing type generalization classes.,5
[FLINK-13463][table-planner-blink] Add test case for VALUES with char literal,3
[hotfix][table-common] Add utilities for modifying (nested) types,1
[FLINK-13463][table-common] Relax legacy type info conversion for VARCHAR literalsThis closes #9334.,5
[hotfix][tests] Remove unused method CommonTestUtils#isProcessAlive(Process),3
[hotfix][tests] Remove unused method CommonTestUtils#sleepUninterruptibly(long),3
[hotfix][tests] Fix typo in method CommonTestUtils#isSteamContentEqual()Rename method isSteamContentEqual() to isStreamContentEqual().,3
[FLINK-13508][tests] Prevent waitUntilCondition() from sleeping negative timeThis fixes that CommonTestUtils#waitUntilCondition() may invoke Thread.sleep()with a negative argument.,3
[hotfix][tests] Extract class InfiniteIntegerSource,5
[hotfix][tests] Fix that InvokableBlockingInInvoke can finish from spurious wakeups,5
[FLINK-13384][runtime] Set context class loader before instantiating AbstractInvokableSet the user code class loader as the executing thread's context class loaderbefore instantiating the AbstractInvokable so that the constructor of theAbstractInvokable implementation has access to the user code class loader.,1
[FLINK-13384][runtime] Fix back pressure sampling for SourceStreamTask,0
"[FLINK-12576][Network, Metrics] Take LocalInputChannel into account when compute inputQueueLength (#8559)* [FLINK-12576]Take localInputChannel into account when complute inputQueueLength* remove default method* fix comments* fix up* fix up* u",0
[FLINK-13237][table-planner-blink] Fix regexpReplace and regexpExtract to same of flink-planner,2
[FLINK-13237][table-planner-blink] TypeInfoDataTypeConverter should support convert from DayTimeIntervalType,1
[FLINK-13237][table-planner-blink] Fix sqrt conversion in RexNodeConverter,0
[FLINK-13237][table-planner-blink] Add LocalTime and LocalDateTime support to planner expressions,1
[FLINK-13237][table-planner-blink] Add expression table api tests in blink plannerThis closes #9099,2
[FLINK-13119][docs] Add Blink table config to documentationThis closes #9024.,2
[FLINK-13579] Only set managed memory when starting an active RMIntroduce ActiveResourceManagerFactory which encapsulates the logic to set relevantconfiguration values for the active ResourceManager implementations (e.g. managedmemory).Let existing active ResourceManager factory implementations extend ActiveResourceManagerFactory.Add ActiveResourceManagerFactoryTest to ensure that active ResourceManager relevantconfiguration values are set.Add StandaloneResourceManagerFactoryTest to ensure that a standalone ResourceManager can bestarted if the memory size is configured to be less than the containered min cutoff size.This closes #9357.,5
[FLINK-13192][hive] Add tests for different Hive table formatsThis closes #9264,3
[FLINK_13475][hive] Reduce dependency on third-party maven repositoriesThis closes #9337,2
[FLINK-13584][table-planner-blink] RankLikeAggFunctionBase should take type into account when generate literal expressionThis closes #9360,1
[hotfix][runtime] Fix checkstyles in SlotManagerImpl class.,0
[FLINK-13555][runtime] Fail slot requests immediately at the SlotPool if unfulfillableRemove the SlotManagerException as extension of ResourceManagerException.[FLINK-13555][runtime][test] Add cases in SlotPoolBatchSlotRequestTest validates that pending batch slot requests fail on UnfulfillableSlotRequestException.[FLINK-13555][runtime] Add the information which slot request failed in stack trace of exception in SlotManager#registerSlotRequest.[FLINK-13555][runtime][test] Update SlotManagerFailUnfulfillableTest to validate that slot manager throws UnfulfillableSlotRequestException for failing unfulfillable requests.This closes #9339.,0
[FLINK-13439] Run Streaming SQL e2e test with blink plannerThis closes #9276,2
[hotifx][table] Improve documentation around table configThis closes #9369.,5
[FLINK-12781][REST] Include the whole stack trace in error response payloadThis closes #8665,0
[FLINK-12928][docs] Remove old Flink ML docsThis closes #8827,2
[hotfix][e2e] Include dependency tests in travis splits,3
[FLINK-13404][table-api] Port csv descriptors & factories to flink-table-api-java-bridgeThis closes #9219,2
[FLINK-13486][tests] Harden AsyncDataStreamITCase to alleviate race condition,5
"[FLINK-13540][table-api] Fix DDL parser doesn't support number or minus character in properties keyIn this commit, we parse DDL table properties key as string literals instead of identifiers, so that all the properties key should be quoted by single-quote.This closes #9361",1
[hotfix][tests] fix topic name in FlinkKafkaProducerITCase#testScaleUpAfterScalingDown(),3
"[FLINK-13498][kafka] abort transactions in parallelThis makes FlinkKafkaProducer abort transactions, e.g. during a first startup,in parallel making use of lingering CPU resources (using at mostkafkaProducersPoolSize producers at once each, just like during runtime).Especially during that first startup (and thus also in tests), a lot ofproducers (5*poolSize) are being created at each sink instance to abortpotentially existing previous transactions (in most cases, they don't exist).",1
"[FLINK-10368] Harden Dockerized Kerberos tests by waiting for NM to be upBefore, we didn't wait for Yarn NodeManagers to be up. This meant thatsometimes the Flink Job would not have enough resources to run.",1
[hotfix] Print Flink logs from YARN in test_yarn_kerberos_docker.sh,3
"[FLINK-10368] Increase slot request timeout to harden YARN/Kerberos testBefore, the tests were sometimes failing withNoResourceAvailableException. In the logs it was visible that therequested TaskExecutors (TMs) were connecting after the exception wasthrown. Increasing the timeout therefore fixes the instability.",0
[FLINK-9782][e2e] Harden bucketing sink e2e test.,3
[FLINK-13592][e2e] Fix hardcoded flink version in tpch end-to-end test.This closes #9368.,3
"[hotfix] Change the parallelism of tpch end-to-end test to 2.This can help to cover the situation that parallelism is higher than the slot number, since the testing cluster only have one task manager and contains only one slot.",3
[hotfix] Add relativePath to flink-tpch-tests module,3
"[FLINK-13044][s3][fs] Fix handling of relocated amazon classesTo provide credentials to S3 users may configure a credentials provider. For providers from amazon (which are relocated) we allow users to configure the original class name, and relocate it manually in the S3 filesystem factories.The factories however- used the wrong shading pattern- could not correctly detect providers with a ""com.amazon*"" prefix, as the String constant containing this prefix was also being relocated.This commit obfuscates the constant to prevent relocations, fixes the shading patterns, and sets up e2e tests to cover this case.",3
[FLINK-13433][table-planner-blink] Do not fetch data from LookupableTableSource if the JoinKey in left side of LookupJoin contains null valueThis closes #9285,5
[FLINK-13509][table-planner-blink] Forbidden `IS NOT DISTINCT FROM `(or an expanded version) in LookupJoin.,2
"[FLINK-13529][table-planner-blink] Rename CONCAT_AGG to LISTAGG and fix the behavior according to the ANSI-SQLAccording to the ANSI-SQL, the LISTAGG function is used to transform values from a group of rows into a list of values that are delimited by a configurable separator.This closes #9316",5
"[FLINK-13529][table-planner-blink] Remove the second parameter of FIRST_VALUE and LAST_VALUEAccording to ANSI-SQL, FIRST_VALUE and LAST_VALUE are ordered set function which require the within group clause to specify an order instead of pass the order field as a parameter.This closes #9316",2
[FLINK-13529][table-planner-blink] Remove APPROX_COUNT_DISTINCT and INCR_SUM in blink planner- Remove APPROX_COUNT_DISTINCT for now because we still don't support it yet.- Remove INCR_SUM because it is not a standard aggregate function.This closes #9316,1
[FLINK-13428][fs-connector] Make part file name configurableThis closes #9228,5
[FLINK-13452][runtime] Fail the job globally when exception happens during reseting tasks of a region,1
[hotfix][tests] Move SettableLeaderRetrievalService to test scope,3
[FLINK-13605][tests] Fix unstable case AsyncDataStreamITCase#testUnorderedWaitThis closes #9378,5
[FLINK-13495][table-api] Use DataType in ConnectorCatalogTable instead of TypeInformation,5
[FLINK-13495][table-planner-blink] Deal with InputFormatTableSource in planner to use planner type convertion to keep precision,1
[FLINK-13495][table-planner-blink] Introduce isAssignable to use soft check in TableSourceUtil,1
[FLINK-13495][table-planner-blink] source/sink code should use planner type conversion to keep precision,1
[FLINK-13495][table-planner-blink] Add table source and table sink it case using varchar/char/decimal precision,1
[FLINK-12749] [docs] Add operations Docker playground.* Add new Docker Playgrounds section to Getting Started documenation section* Add new count click events example jobsThis closes #9192.,1
[FLINK-13225][table-planner-blink] Fix type inference for hive udf,5
[FLINK-13225][table-planner-blink] Fix type inference for hive udtf,5
[FLINK-13225][table-planner-blink] Fix type inference for hive udaf,5
[FLINK-13225][hive] Fix getAccumulatorType of HiveGenericUDAF,1
[FLINK-13225][hive] Add hive function it case using blink-plannerThis closes #9089,2
[FLINK-13521][sql-client] Allow setting configurations in SQL CLIThis closes #9328.,5
[FLINK-13471][table] Add stream FlatAggregate support for blink planner.This closes #9322,2
[FLINK-13610][hive]Refactor HiveTableSource Test use sql query and remove HiveInputFormatTestRefactor HiveTableSourceTest use sql query and remove HiveInputFormatTestThis closes #9379,3
[FLINK-13159] Fix the NPE when PojoSerializer restored,0
[FLINK-13159] [tests] Add subclass serialization cases to PojoSerializerSnapshotMigrationTestThis closes #9375.,3
[FLINK-13159] Fix incorrect subclass serializer reconfiguration in PojoSerializer,5
[FLINK-13594][python] Improve the 'from_element' method of flink python api to apply to blink planner.This closes #9370,2
[FLINK-12479][operators] Integrate StreamInputProcessor with mailbox,2
"[hotfix][task,test] Do not override performDefaultAction in StreamTaskTest",3
[hotfix][examples] Changed collection execution environment to regular environment in WordCountTable example,4
[FLINK-13558][examples][table] Added table examples to distThis closes #9367,1
"[FLINK-13581][coordination][tests] Harden BatchFineGrainedRecoveryITCaseIf counting of mapper restarts in BatchFineGrainedRecoveryITCase is based on the open method of user function,the fact of the restart depends on internal implementation of the local Task and whether the open method is eventually called.If execution attempt numbers are used instead, the test behaviour is more stable because it depends only on coordination.The execution attempt numbers can be queried from the REST client of the testing mini cluster.This closes #9374.",5
[FLINK-13441][e2e] Add e2e test for SQL batch jobThis closes #9359.,3
[FLINK-13630][table-api-bridge] Use values retention configuration from TableConfig if not specified explicitlyIf methods that do not specify QueryConfig explicitly are used inStreamTableEnvironment than the values from TableConfig will be used.If methods that accept QueryConfig are used than those values will beused to overwrite the TableConfig.,5
"[FLINK-13561][table-planner-blink] Remove some builtin datetime functions which can be covered by existing functionsRemoves DATE_FORMAT_TZ, DATE_ADD,DATE_SUB, DATEDIFF, FROM_TIMESTAMP, TO_TIMESTAMP_TZ builtin functions which can be covered by existing functions.",1
"[FLINK-13561][table-planner-blink] Drop DATE_FORMAT(timestamp, from_format, to_format) function supportThis commit drops DATE_FORMAT(timestamp, from_format, to_format) function support in blink planner to align with other systems. We only support DATE_FORMAT(timestamp, to_format) and DATE_FORMAT(string, to_format) in this version.",5
"[FLINK-13561][table-planner-blink] Drop CONVERT_TZ(timestamp, format, from_tz, to_tz) function supportThis commit drops CONVERT_TZ(timestamp, format, from_tz, to_tz) function support in blink planner to align with other systems. We only support CONVERT_TZ(timestamp, from_tz, to_tz) in this version.",1
"[FLINK-13561][table-planner-blink] Drop TO_TIMESTAMP(bigint) function supportThis commit drops TO_TIMESTAMP(bigint) function support in blink planner to align with other systems. We only support TO_TIMESTAMP(string [,format]) in this version.",1
"[FLINK-13561][table-planner-blink] Drop TO_DATE(int) function supportThis commit drops TO_DATE(int) function support in blink planner to align with other systems. We only support TO_DATE(string [,format]) in this version.",5
"[FLINK-13561][table-planner-blink] Fix FROM_UNIXTIME(bigint [,format]) should work in session time zoneThis aligns the behavior to other systems (MySQL, Spark).",5
"[FLINK-13561][table-planner-blink] Fix UNIX_TIMESTAMP(string [,format]) should work in session time zoneThis aligns the behavior to other systems (MySQL, Spark). UNIX_TIMESTAMP(string [,format]) is an inverse of FROM_UNIXTIME(bigint [,format]). We also remove the support of UNIX_TIMESTAMP(timestamp) in this commit.",1
"[FLINK-13561][table-planner-blink] Fix NOW() should return TIMESTAMP instead of BIGINT.This aligns the behavior to other systems (MySQL, Spark). Because NOW() is Synonyms for CURRENT_TIMESTAMP.",1
"[FLINK-13561][table-planner-blink] Fix wrong result of TIMESTAMPADD(HOUR, interval, DATE)TIMESTAMPADD(HOUR, -1, DATE '2016-06-15') will get a wrong result of ""2016-06-15"", which should be ""2016-06-14 23:00:00.000"".This is a cherry-pick of FLINK-10009 to blink planner.",2
[FLINK-13545] [table-planner-blink] JoinToMultiJoinRule should not match SEMI/ANTI LogicalJoinThis closes #9329,2
[FLINK-13608] [docs] Update upgrade compatibility table in operations doc for 1.9.0,2
[FLINK-13608] [docs] Move 1.2.x compatibility limitations to correct location in compatibility tableThis closes #9381.,4
StringWriter support custom row delimiter,1
fixup! StringWriter support custom row delimiter,1
[FLINK-13600][table] Rework TableEnvironment.connect() class hierarchyThis closes #9382.,1
[FLINK-13523][table-planner-blink] Refactor DIVIDE function to keep it compatible with old plannerThe behavior of DIVIDE function in blink planner always return double/decimal type which is not standard.,2
"[FLINK-13523][table-planner-blink] Remove non-standard bitwise scalar function and DIV(), DIV_INT() function from blink plannerThis commit remove BITAND, BITOR, BITNOT, BITXOR scalar functions because they are not standard.This commit also removes DIV(), DIV_INT() because we already have ""/"" and ""/INT"" operators.",1
[FLINK-13523][table-planner-blink] Refactor AVG aggregate function to keep it compatible with old plannerThe behavior of AVG aggregate function in blink planner always return double/decimal type which is not standard.,2
"[FLINK-13587][table-planner-blink] Introduces a framework to reuse code of ""explainTerms"" to generate operator names",1
[FLINK-13587][table-planner-blink] Fix some operator names are not set in blink plannerThis closes #9363,2
[FLINK-13645][table-planner-blink] Fix Error in code-gen when using blink planner in scala shellThis closes #9389,2
[hotfix] Fix the style check failure of flink-sql-parser when enabling docs-and-source profile,2
[FLINK-13593][checkpointing] Prevent failing the wrong job in CheckpointFailureManagerThis closes #9364.,0
[hotfix][tests] Add NoOpJobFailCall singleton,0
"[FLINK-13547][table-planner-blink] Refactor CONCAT() and CONCAT_WS() to keep it compatible with old plannerCONCAT(string1, string2, ...) should returns NULL if any argument is NULL.CONCAT_WS(sep, string1, string2,...) should returns NULL if sep is NULL and automatically skips NULL arguments.",4
[FLINK-13547][table-planner-blink] Fix FROM_BASE64() should return STRING type instead of BINARYThis fix the behavior of FROM_BASE64() to align with old planner.,0
[FLINK-13547][table-planner-blink] Align the implementation of TRUNCATE() function with old planner,1
"[FLINK-13547][table-planner-blink] Remove LENGTH(), JSONVALUE(), KEYVALUE(), SUBSTR() builtin functions which are not standard.LENGTH, SUBSTR, KEYVALUE can be covered by existing functions, e.g. CHAR_LENGTH, SUBSTRING, STR_TO_MAP(str)[key].",1
"[FLINK-13637][docs] Fix problems of anchors in document(building.md, common.md, queryable_state.md)This closes #9384",2
[hotfix][table] Rename TableAggFunctionCallVisitor to TableAggFunctionCallResolver for class name more meaningful.This closes #9281,0
[docs-sync] Synchronize the latest documentation changes (commits to 56c6b487) into Chinese documents,2
"[FLINK-13505][docs-zh] Translate ""Java Lambda Expressions"" page into ChineseThis closes #9348",1
[FLINK-13562][table-planner-blink] Fix incorrect input type for local stream group aggregate in FlinkRelMdColumnIntervalThis closes #9346,2
[FLINK-13563][table-planner-blink] TumblingGroupWindow should implement toString method to explain more infoThis closes #9347,5
[FLINK-13473][table-blink] Add stream Windowed FlatAggregate support for blink plannerThis close #9396,2
[FLINK-13526][sql-client] Switching to a non existing catalog or database crashes sql-clientAvoid crashing sql-client when switching to non-existing catalog or database.This closes #9399.,5
"[FLINK-13517][docs][hive] Restructure Hive Catalog documentationHive documentation is currently spread across a number of pages and fragmented. In particular:- An example was added to getting-started/examples, however, this section is being removed- There is a dedicated page on hive integration but also a lot of hive specific information is on the catalog pageThis closes #9308.",1
[FLINK-13490][jdbc] Fix return null in JDBCUtils::getFieldFromResultSet,5
[FLINK-13489][e2e] Fix akka timeout problem of the heavy deployment e2e testThis closes #9391.,3
[FLINK-13534][hive] Unable to query Hive table with decimal columnFix the issue that Flink cannot access Hive table with decimal columns.This closes #9390.,2
[hotfix][doc] remove two obsolete Hive doc files,2
[FLINK-13704][table-planner-blink] Revert removing SUBSTR() function in blink planner to fix TPC-H e2e test failedThis closes #9427,0
[FLINK-13488][tests] Harden ConnectedComponents E2E testBy default the tests starts 25 TMs with a single slot each. This is notsustainable on Travis CI. This commit changes the test so that it only starts 2TMs that each offer 13 slots by default.Run 'set -Eexuo pipefail' at the beginning of the test as recommended by theREADME.md.,2
[FLINK-13663][e2e] Double curl retries count and total time for Kafka downloadsThis closes #9429.,2
[FLINK-13585][tests] Harden TaskAsyncCallTest by fixing race conditionThis closes #9436.,0
[hotfix][tests] Fix code style error of TaskAsyncCallTest,3
[FLINK-13501][doc] Fixes a few issues in documentation for Hive integrationThis closes #9437.,2
[docs] Broken links in Hive documentationThis closes #9435.,2
[hotfix][doc] remove obsolete catalog.md in favor of new catalogs.md,2
[FLINK-13530][qs][tests] Increase port range size,1
[FLINK-13415][docs] Document how to use hive connector in scala shellThe purpose of this PR is to add docs about how to use hive connector in scala shell via table api.This closes #9233.,1
[FLINK-13127][yarn] Add support for resource classloading for resources shipped using --yarnship.This closes #9022.,1
"[FLINK-12987][metrics] fix DescriptiveStatisticsHistogram#getCount() not returning the number of elements seenDescriptiveStatisticsHistogram#getCount() only returned the number of currentlystored elements, not the total number seen.Also add a unit test for verifying any Histogram implementation (based onthe previous test from DropwizardFlinkHistogramWrapperTest) and run this withDescriptiveStatisticsHistogram.",1
"[FLINK-12984][metrics] only call Histogram#getStatistics() once where possibleIn some occasions, Histogram#getStatistics() was called multiple times toretrieve different statistics. However, at least the dropwizard implementationhas some constant overhead per call and we should maybe rather interpret thismethod as returning a point-in-time snapshot of the histogram in order to getconsistent values when querying them.",1
[hotfix][tests] let MeterViewTest extend from TestLogger,3
[FLINK-13706][hive] add documentation of how to use Hive functions in FlinkAdd documentations of how to use Hive functions in Flink.This closes #9445.,2
[FLINK-13688][hive] Limit the parallelism/memory of HiveCatalogUseBlinkITCaseThis closes #9417,2
[FLINK-13460][tests] Rework SerializedThrowableTest to not use Unsafe#defineClass(),1
[FLINK-9900][tests] Harden ZooKeeperHighAvailabilityITCaseWaiting checkpoint id increasing to 5 can not guarantee there must bestate data included. An empty checkpoint would fail the restorationchecking.This closes #9461.,0
[FLINK-12529][runtime] Release record-deserializer buffers timely to improve the usage efficiency of heap on taskmanager (#8471)This pull request releases the buffer of the corresponding record deserializer after receiving EndOfPartitionEvent from the input channel to improve the efficiency of heap memory usage on taskmanager.,1
[FLINK-13737][flink-dist] Added examples-table to flink-dist dependencies,2
[hotfix][hive] refine Hive related documentations,2
"[hotfix][hive][doc] update document of TIMESTAMP, TIMESTAMP_WITHOUT_TIME_ZONE data mapping",5
[FLINK-13277][hive][doc] add documentation of Hive source/sinkTo add documentation for hive source and sink.This closes #9217.,2
[FLINK-13747][hive] Remove some TODOs in Hive connectorThis PR is to fix some obsolete TODOs.This closes #9460.,2
[FLINK-13738][blink-table-planner] Fix NegativeArraySizeException in LongHybridHashTableThis closes #9462,0
[FLINK-13739][table-blink] JDK String to bytes should specify UTF-8 encodingThis closes #9455,2
[FLINK-13759][builds] Fix builds for master branch are failed during compile stageThis closes #9472.,1
[FLINK-13760][hive] Fix hardcode Scala version dependency in hive connectorThis closes #9473.,0
[FLINK-11630] Triggers the termination of all running Tasks when shutting down TaskExecutorThis closes #9072.This closes #7757.,1
[hotfix] Introduce TaskDeploymentDescriptorBuilder in tests,3
[FLINK-13742][table-planner-blink] Fix wrong result when aggregation contains both distinct aggs with and without filterThis closes #9459,0
[FLINK-13752] Only references necessary variables when bookkeeping result partitions on TMThis closes #9480.,2
[FLINK-13599][e2e tests] Harden test_streaming_kinesis with kinesalite docker image download/run retries,1
[FLINK-11879][runtime] Add getStreamOperatorClass() to the StreamOperatorFactory interface,1
[hotfix][test] Separate some shared inner classes from test classes into the separate files,2
[FLINK-11879][runtime] Add validators for the uses of InputSelectable,1
[FLINK-13231] [pubsub] Replace Max outstanding acknowledgement ids limit with a FlinkConnectorRateLimiter,2
"[FLINK-13699][table-api] Fix TableFactory doesn't work with DDL when containing TIMESTAMP/DATE/TIME typesThe solution is encode DataTypes.TIMESTAMP() as ""TIMESTAMP"" when translating to properties.And will be converted back to the old TypeInformation: Types.SQL_TIMESTAMP.This would fix all factories at once.",0
[FLINK-13699][hbase] Add integration test for HBase to verify DDL with TIMESTAMP types,3
"[FLINK-12745][ml] Add sparse vector, dense vector classes and dense matrix class with basic operations",1
[FLINK-13643][hive][docs] Document the workaround for users with a different minor Hive versionDocument the workaround for users with a different minor Hive versionThis closes #9447.,1
[FLINK-13380][docs] Improve docs on how to use Flink with Kuberneteslist several ways to access flink web UIThis closes #9470.,2
[FLINK-13588] Report exception message when failing StreamTask#handleAsyncExceptionDon't throw away exception info in logging as it make diagnosis extremely hardThis closes #9456.,1
[hotfix] Extend MockEnvironment to provide better testing tools,3
[hotfix] Encapsulate async exception handling into StreamTask#StreamTaskAsyncExceptionHandler,0
[FLINK-13718][hbase] Disable tests on Java 11,3
"[FLINK-13644][docs-zh] Translate ""State Backends"" page into ChineseThis closes #9454",1
[FLINK-13650][tests] Consolidate CommonTestUtils and ClassLoaderUtils,3
[FLINK-13650][tests] Use ClassLoaderUtils#compileAndLoadJava,1
[FLINK-13697][table-api] Removed deprecated ExternalCatalog APIThis closes #9422,2
[FLINK-13697][table-api] Unified catalog manager operationsAfter the ExternalCatalog API was dropped all catalog paths consists of3 parts. Based on that assumption some internal calls can be simplified.,2
[FLINK-13800][State Backends] Add maven module for spillable heap backendThis closes #9500.,1
[FLINK-13512][kinesis][build] Add jaxb-api dependency on Java 11,1
"[FLINK-12981][metrics] ignore NaNs in percentile implementationHistrogram metrics use ""long"" values anyway and therefore, there is no NaNin the DescriptiveStatistics' data.",5
"[FLINK-12982][metrics] improve DescriptiveStatisticsHistogramStatistics performanceInstead of redirecting DescriptiveStatisticsHistogramStatistics calls toDescriptiveStatistics, it takes a point-in-time snapshot using an ownUnivariateStatistic implementation thata) calculates min, max, mean, and standard deviation in one go (as opposed to   four iterations over the values array!)b) caches pivots for the percentile calculation to speed up retrieval of   multiple percentiles/quartilesAs a result, this roughly increases value retrieval performance by 120% whenaccessing typical statistics in a metrics reporter, e.g. the InfluxDB reporter:count, min, max, mean, stddev, p50, p75, p95, p98, p99, p999.",5
"[FLINK-12983][metrics] replace descriptive histogram's storage back-endInstead of using `DescriptiveStatistics` and its `ResizableDoubleArray` storageback-end, implement an own circular array based on a fixed-size double arraythat wraps around. This significantly improves the time needed to add newvalues. It also ensures that access is synchronized which `ResizableDoubleArray`does not guarantee.",1
[hotfix][build] Remove scala suffix,0
[FLINK-13711][sql-client] Hive array values not properly displayed in SQL CLIFix the issue that SQL CLI doesn't display arrays properly.This closes #9450.,0
[FLINK-13741][table] 'SHOW FUNCTIONS' should include Flink built-in functions' namesThis closes #9457.,1
[FLINK-13757][doc] Fix description error for the built-in 'is not true' logical functionThis closes #9469,1
[FLINK-13712] [docs] Add release notes for Flink 1.9.0,2
[FLINK-13564][table-planner-blink] throw exception if constant with YEAR TO MONTH resolution was used for group windowsThis is a same fix with FLINK-11017 in blink planner.This closes #9349,2
[hotfix] [docs] Add 1.9 to list of previous docs,2
[FLINK-13797] Fix log formats,2
[hotfix][python] Add System.exit() at the end of PythonGatewayServer to ensure the JVM will exit if its parent process dies.This closes #9490,5
[FLINK-13806][metrics] Log all errors on DEBUG,0
[FLINK-13714] Remove Program-related code,4
[FLINK-13715][docs] Remove Program-related english documentation,2
[FLINK-13716][docs] Remove Program-related chinese documentation,2
[FLINK-13761][scala] Deprecate Scala SplitStreamDeprecate Scala SplitStream which has been superseded by side outputs.This closes #9474.,2
[hotfix][table-blink] Ignore tests in GroupWindowTableAggregateITCase and TableAggregateITCaseIgnore the tests for the time being and recover it when bug is fixed in blink-planner,2
[FLINK-13354][docs] Add documentation for how to use blink plannerThis closes #9362,2
[FLINK-13105][doc] Add documentation for blink planner's built-in functionsThis closes #9002,1
[FLINK-13825][e2e] Restore original plugins dir in flink distribution after test run,1
[FLINK-13762][task] Add the exception throwable in the interface methods of ValveOutputHandlerIt is only for simplifying the implementations of specific methods to not wrap the exception into RuntimeException.,1
[FLINK-13831] Correct Free Slots / All Slots display errorThis closes #9521.,0
[FLINK-13430][build] Configure sending travis build notifications to builds@flink.apache.orgThis closes #9230,2
"[FLINK-13764][task,metrics] Pass the counter of numRecordsIn into the constructor of StreamInputProcessorCurrently the counter of numRecordsIn is setup while processing input in processor. In order to integrate the processing logic based on StreamTaskInput#emitNext(Output) later, we need to pass the counter into output functions then. So there are three reasons to do this:It is the precondition of following integration work.We could make the counter as final fields in StreamOneInputProcessor and StreamTwoInputSelectableProcessor.We could reuse the counter setup logic for all the input processors.There should be no side effects if we make the counter setup a bit earlier than the previous way.",1
[hotfix][task] Adjust the code format of OneInputStreamTask,0
"[FLINK-13442][network] Remove unnecessary notifySubpartitionConsumed method from view readerCurrently the methods of NetworkSequenceViewReader#notifySubpartitionConsumed and NetworkSequenceViewReader#releaseAllResourceswould be called meanwhile in netty stack during releasing resources.As confirmed in FLINK-13245, in order to make this release logic simple and clean, we could remove the redundant notifySubpartitionConsumedfrom NetworkSequenceViewReader side, and also remove it from ResultSubpartitionView side. In the implementation of ResultSubpartitionView#releaseAllResourcesit would further notify the parent subpartition of consumed state via ResultSubpartition#notifySubpartitionConsumed which further feedback to parent ResultPartitionlayer via onConsumedSubpartition. Finally ResultPartition could decide whether to release itself or not.E.g. for the case of ReleaseOnConsumptionResultPartition which is mainly used for pipelined partition, it would release partition after reference counter decreased to0. For the case of ResultPartition which would be generated for blocking partition by default, it would never be released after notifying consumed. And the JM/schedulerwould decide when to release partition properly.In addition, InputChannel#notifySubpartitionConsumed could also be removed as a result of above.",4
[FLINK-13824][travis] Refactoring travis_watchdog.sh: remove code duplication,4
[hotfix][travis] Remove duplicate mvn logging options for mvn verify,2
[hotfix][docs] Correct method name in KeyedStateReaderFunction exampleThis closes #9520,1
[hotfix][JavaDocs] Correct comment in KeyedStreamThis closes #9395,2
[hotfix][table api] Fix logger arguments in CatalogManagerThis closes #9401,2
[FLINK-13728][docs] Fix wrong closing tag order in sidenavThis closes #9439,0
"[FLINK-13724][docs] Remove unnecessary whitespace from the generated pagesStarting command tags with ""{%-"" will drop all whitespace to the left and endingwith ""-%}"" will drop all whitespace to the right (including newlines!).Code like the following would otherwise create quite some unnecessarywhitespace:  {% if parent_id %}    {% assign parent_id = current[0].nav-parent_id %}  {% else %}    {% break %}  {% endif %}This closes #9440",4
[FLINK-13723][docs] Use liquid-c for faster doc generationJekyll requires liquid and only optionally uses liquid-c if available. Thelatter uses natively-compiled code and reduces generation time by ~5% for me.This closes #9441,1
[FLINK-13729][docs] Update website generation dependenciesThis seems to come with a much nicer code highlighting.This closes #9442,5
"[FLINK-13725][docs] use sassc for faster doc generationJekyll requires sass but can optionally also use a C-based implementationprovided by sassc. Although we do not use sass directly, there may be someindirect use inside jekyll. It doesn't seem to hurt to upgrade here.This closes #9443",1
"[hotfix][docs] Temporarily disable liveserve./build_docs.sh -i previously did not only enable incremental documentationbuilding while serving the docs, it also enabled a 'liveserve' mode thatautomatically reloaded pages in the browser when they changed. This is basedon the 'hawkins' module which is not (yet) compatible with jekyll 4.0 which weneed to (significantly) improve build times.This disables the liveserve mode and remove the hawkins module until a newversion is available.",1
"[FLINK-13726][docs] Build docs with jekyll 4.0.0.pre.beta1This significantly reduces the build times, on my machine from 140s to 47s!This closes #9444",2
[FLINK-13359][docs] Add documentation for DDL introductionThis closes #9366,2
"[FLINK-13362][docs] Add DDL documentation for Kafka, ElasticSearch, FileSystem and formats",5
[hotfix][docs] Add documentation regarding path style access for s3This closes #9479,2
"[FLINK-13791][docs] Speed up sidenav by using group_by_includes/sidenav.html parses through pages_by_language over and over againtrying to find children when building the (recursive) side navigation. By doingthis once with a group_by, we can gain considerable savings in building thedocs via `./build_docs.sh` without any change to the generated HTML pages:This closes #9487",4
[hotfix][docs] Update local setup tutorials to fit new log messagesThis closes #9488[ci skip],2
"[FLINK-13853][e2e] Update common_ha.sh test expression to count recoveriesWith FLINK-13573 we removed the SubmittedJobGraph and replaced it with the JobGraph.Consequently, we no longer see the log statement ""Recovered SubmittedJobGraph"" whichwas used by the common_ha.sh script to count the number of job recoveries. Now we needto look for ""Recovered JobGraph"" instead.This closes #9534.",1
"[FLINK-13765][task] Introduce the TwoInputSelectionHandler for selecting input in StreamTwoInputSelectableProcessorIn StreamTwoInputSelectableProcessor there are three fields {InputSelectable, InputSelection, availableInputsMask} tobe used together for the function of selecting next available input index.From design aspect, these fields can be abstracted into a separate component called TwoInputSelectionHandler, which ispassed into the constructor of StreamTwoInputSelectableProcessor as a final field. So the internal implementation detailsof TwoInputSelectionHandler is hidden from processor view which only needs to interact with exposed methods from selection handler.Another tiny benefit is that we make the StreamTwoInputSelectableProcessor a bit because two methods are removed from it.",4
[FLINK-13011][build] Add the Build logic for Python API release packageThis closes #9496,1
[FLINK-13832] Rename DefaultRollingPolicy create to builderCloses #9527,1
"[FLINK-13405][docs-zh] Translate ""Basic API Concepts"" page into ChineseThis closes #9299",1
[FLINK-13794][client] Remove unused logic of printStatusDuringExecution,2
[FLINK-13614][Tests] Add MigrationVersion.v1_9This closes #9526.,1
[FLINK-13841][hive] Extend Hive version support to all 1.2 and 2.3 versionsSupport all 1.2 and 2.3 minor Hive versions instead of currently 1.2.1 and 2.3.4 only.This closes #9524.,1
[hotfix][kinesis] Update emit record javadoc and don't count max watermark as timeout,2
[FLINK-13823][table-planner-blink] Fix incorrect debug log in CompileUtilsThis closes #9518,2
[FLINK-13745][travis] Retain cache of most recent build,2
[FLINK-13531][runtime] Check size when handling over-allocated slots,2
[FLINK-13807][tests] Use UTF-8 charset in TestBaseUtils.getResultReader,3
[FLINK-13875][docs] Add missing redirects to the documentation.This closes #9544.[ci skip],2
[hotifix][docs] Uniform capitalization for tools,2
[FLINK-13817][rest] Expose whether web submissions are enabled,0
[FLINK-13789][kafka] Simplify transactional ID generationRemove String.format usage to prevent unexpected behaviors if the configured prefix contains format specifiers.,0
[FLINK-13751][ml] Add TypeInformation of built-in vector types,5
[hotfix][docs] Add missing double-quote to redirect.,1
[FLINK-13826][table-planner][hive] Support INSERT OVERWRITE for Hive connectorSupport INSERT OVERWRITE Hive tables.This closes #9519.,1
[hotfix][doc] fix mvn config example for hive,5
[hotfix][doc] fix catalog registration example,2
[FLINK-13774][table-planner-blink] Blink extended expressions should implement ResolvedExpression,0
[FLINK-13774][table-planner-blink] Fix Reinterpret bug of PlannerExpressionConverter,0
[FLINK-13774][table-planner-blink] Supports decimal with different precision for IF PlannerExpression,1
[FLINK-13774][table-planner-blink] Modify filterable table source accept ResolvedExpression,0
[FLINK-13774][table] FieldComputer should return ResolvedExpression,0
[FLINK-13774][table-planner-blink] Expressions of DeclarativeAggregateFunction should be resolved,0
[FLINK-13774][table-planner-blink] Remove unresolved expression in RexNodeConverter,0
[FLINK-13774][table-planner-blink] Use LocalReferenceExpression and RexNodeExpression instead of blink expressionsThis closes #9484,2
"[FLINK-13819][coordination] Introduce isRunning state for RpcEndpointTo better reflect the lifecycle of RpcEndpoint, we suggest to introduce its running state.We can use the non-running state e.g. to make decision about how to react on APIcalls if it is already known that the RpcEndpoint is terminating.",1
[FLINK-13769][Coordination] Close RM connection in TaskExecutor.onStop and do not reconnectThis prevents JM from acquiring slots which belong to the stopped TM.,2
"[FLINK-13882] Remove ProcessReaperThe ProcessReaper is a utility for the legacy distributed components. Hence,we should remove it.This closes #9551.",4
[hotfix][travis] Clarify profile names- add missing jdk9 qualifier to misc- add e2e qualifier to e2e profiles,2
[hotfix][travis] Hide maven download progress,0
[hotfix] Rename SlotManagerTest into SlotManagerImplTest,3
[hotfix][tests] Add CoreMatchers#containsCauseAdd Hamcrest matcher which checks for a given Throwable whether it containsa specified failure cause.,1
[hotfix] Make ResourceManagerException a subclass of FlinkException,2
[hotfix] Introduce SlotManagerExceptionSlotManagerException is the base class for all exceptions generated by theSlotManager implementations.,0
[hotfix] Remove Mockito from SlotManagerImplTest,3
[hotfix] Harden SlotManagerImplTest#testSlotReportWhileActiveSlotRequestThe SlotManagerImplTest#testSlotReportWhileActiveSlotRequest contained a race condition sincewe were checking the internal state of the SlotManagerImpl's state. The test has been hardenedby removing this check.,4
[hotfix] Remove unnecessary SuppressWarnings annotations from SlotManagerImplTest,3
[FLINK-13805] Properly forward cause for slot removal in SlotManagerForwarding the slot removal cause to the ResourceActions allows to notify the JobMasterabout the allocation failure cause. This improves debuggability and understanding of thesystem.This closes #9550.,5
"[hotfix][javadoc] Add missing ""the""",1
[FLINK-13147][hive] Deduplicate conditions,2
[hotfix][docs] Fix minor typo,2
[FLINK-13240][qs] Correct error messages and javadocs,2
[FLINK-13877][hive] Support Hive version 2.1.0 and 2.1.1Support Hive 2.1.x versions (2.1.0 and 2.1.1).This closes #9547.,1
[hotfix] [runtime] Replacing mockito in AsyncWaitOperatorTest,3
"[FLINK-13248][runtime] Implement per operator priorities for mailbox actions and yieldToDownstream conceptThis commit introduces separate mailboxes per operator each handling enqueuing actions/letters and yielding with different priorities. Yielding execution, yields only for down stream actions, which in principle allows for having yielding operators in the middle of an operator chain (and not only as a head).",1
[FLINK-13248] [runtime] Adding and using YieldableOperatorFactory to pass MailboxExecutor view to operator,1
"[FLINK-13248] [datastream/streaming] Enabling custom factories for one input stream operators to be passed in DataStreamAlso enabled StreamOperatorTestHarness and InputStreamTaskTestHarness to work with factories. In the future, instead of passing operators directly in the DataStream API, factories should be used instead.",1
[FLINK-9787] Let ExecutionConfig#getGlobalJobParameters always return a non null valueThis closes #8175.,5
"[FLINK-13514] Fix instability in StreamTaskTest.testAsyncCheckpointingConcurrentCloseAfterAcknowledgeBefore, thread pool shutdown would interrupt our waiting method.Production code cannot throw an InterruptedException here and would alsonot be correct if one is thrown.We now swallow interrupted exceptions and wait until we successfullyreturn from await().",1
[FLINK-13548][Deployment/YARN]Support priority of the Flink YARN application.,2
[hotfix] Create YarnTestUtils in flink-yarnMove isHadoopVersionGreaterThanOrEquals from RegisterApplicationMasterResponseReflectorTest toYarnTestUtils to make it shareable.,1
[FLINK-13548][tests] Add dedicated test case for priority schedulingAdded YarnPrioritySchedulingITCase which is only executed if the underlyingHadoop version supports priority scheduling (>= 2.8.0).This closes #9336.,1
"Revert ""[FLINK-13791][docs] Speed up sidenav by using group_by""This reverts commit c64e167b8003b7379545c1b83e54d9491164b7a8.",4
"Revert ""[FLINK-13726][docs] Build docs with jekyll 4.0.0.pre.beta1""This reverts commit ac1b8dbf15c405d0646671a138a53c9953153165.",5
"Revert ""[hotfix][docs] Temporarily disable liveserve""This reverts commit f802e16b06b0c3a3682af7f9017f9c0a69e5d4de.",4
"Revert ""[FLINK-13725][docs] use sassc for faster doc generation""This reverts commit 065de4b573a05b0c3436ff2d3af3e0c16589a1a7.",4
"Revert ""[FLINK-13729][docs] Update website generation dependencies""This reverts commit ef74a61f54f190926a8388f46db7919e0e94420b.",5
[FLINK-13828][configuration] Deprecate ConfigConstants.LOCAL_START_WEBSERVER,5
[hotfix][test] Prefer propogate exceptions,3
[FLINK-13051][runtime] Replace the non-selectable stream task with the input-selectable one,2
[hotfix][runtime] Remove the unused StreamOperatorFactory#isOperatorSelectiveReading method,1
[hotfix][runtime] Clean up unnecessary type argument declarations in TwoInputStreamTaskTest and TwoInputStreamTaskTestHarness,3
[hotfix][runtime] Clean up unused member variables in StreamTwoInputSelectableProcessor,1
[FLINK-13051][runtime] Drop the non-selectable StreamTask and InputProcessor,4
[FLINK-13051][runtime] Rename TwoInputSelectableStreamTask and StreamTwoInputSelectableProcessor,2
[hotfix] Correct broken link in sql.zh.md,2
[FLINK-13814][hive] HiveTableSink should strip quotes from partition valuesStrip quotes from partition value in order to get proper string values.This closes #9502.,1
[FLINK-12847][kinesis] update flink-connector-kinesis to use Apache 2.0 license codeThe Kinesis Connector will now be able to be built and included in the build artefacts as it no longer pulls in any Amazon licensed code.This closes #9494.,1
"[FLINK-13903][hive] Support Hive version 2.3.6Support Hive 2.3.6, which was released a few days ago.This closes #9584.",1
[FLINK-13891][build] Increment flink-shaded version,2
[FLINK-13467][build] Bump ASM to 7.1,2
[FLINK-13770][build] Bump netty to 4.1.39.Final,2
[hotfix][datadog] Log report and series size,2
[FLINK-13935][tests] Only stop YarnTestBase#yarnCluster if non null,3
[FLINK-10725][tests] Add tooling for disabling specific tests on Java 11,3
[FLINK-13533][cassandra] Disable tests on Java 11,3
[FLINK-13906][core] Implement hashCode() method in class `GlobalJobParameters`This closes #9593,2
[FLINK-13568][sql-parser] Fix DDL CREATE TABLE statement doesn't allow STRING data typeThis closes #9354,5
[FLINK-13618] Update FlinkKafkaConsumerBaseMigrationTest to restore from 1.9 savepointThis closes #9594.,3
[FLINK-13617] Update FlinkKafkaProducer011MigrationTest to restore from 1.9 savepointThis closes #9592.,3
[FLINK-13615][Tests] Update CEPMigrationTest to restore from 1.9 savepointThis closes #9589.,3
[FLINK-13616][Tests] Update BucketingSinkMigrationTest to restore from 1.9 savepointThis closes #9590.,3
[Flink-12164][runtime] Introduce factory pattern for HeartbeatMonitor,2
[Flink-12164][tests] Enrich TestingHeartbeatServices by supporting manually triggering timeout,1
[Flink-12164][tests] Harden JobMasterTest#testJobFailureWhenTaskExecutorHeartbeatTimeoutThis closes #9568.,3
[hotfix][tests] Fix code style problem of JobMasterTest,3
[FLINK-13897][oss] Move NOTICE file into META-INF directory,5
[FLINK-13887][core] Ensure ExConfig#defaultInputDependencyConstraint is non-null,5
[FLINK-13059][cassandra] Release semaphore on exception in send(),2
[FLINK-13355][docs] Add documentation for Temporal Table Join in blink plannerThis closes #9545,2
[FLINK-13356][table][docs] Add documentation for TopN and Deduplication in blink plannerThis closes #9511,2
[FLINK-13912][client] Remove ClusterClient#getClusterConnectionInfoThis closes #9575.,5
[FLINK-13363][docs] Add documentation for streaming aggregate performance tuningThis closes #9525,2
[FLINK-13941][fs-connector] Do not delete partial part files from S3 upon restore.,2
[FLINK-13775][table-planner-blink] Correct time field index of window agg,2
[FLINK-13775][table-planner-blink] Rename RexNodeConverter to ExpressionConverter,2
[FLINK-13775][table-planner-blink] Refactor ExpressionConverterThis closes #9485,4
[FLINK-13922][docs] Translate headings of task_failure_recovery.zh.md into EnglishTranslate headings of task_failure_recovery.zh.md into English in order to supportanchors in the English and Chinese documentation to subsections of this page.This closes #9571.,2
"[FLNK-13885] Deprecate HighAvailabilityOptions#HA_JOB_DELAYThe HighAvailabilityOptions#HA_JOB_DELAY is no longer used. Hence, this commit deprecatesthe old code and updates the configuration documentation.This closes #9554.",2
[FLINK-13779][metrics][prometheus] Support groupingKey configuration,5
[FLINK-13750][client][coordination] Separate HA services between client-side and server-sideThis closes #9609.,2
[FLINK-13892][hs] Harden HistoryServerTest,3
[FLINK-13927][docs] Add note about adding Hadoop dependencies to run/debug Flink locally in mini cluster,5
[FLINK-13528][kafka] Disable tests failing on Java 11,0
[FLINK-13515][tests] Disable test on Java 11,3
[FLINK-13516][tests] Disable test on Java 11,3
[FLINK-13893][s3] Add jaxb-api dependency on Java 11,1
[FLINK-13457][travis] Setup JDK 11 builds,1
[FLINK-13457][build][travis] Remove JDK 9 support,1
[FLINK-13936][licensing] Update NOTICE-binary,5
[FLINK-13842][docs] Improve Javadocs and web documentation of the StreamingFileSinkCloses #9530,2
[FLINK-13966][licensing] Pin locale for deterministic sort order,5
"[FLINK-13930][hive] Support Hive version 3.1.xSupport Hive 3.1.x versions, including 3.1.0, 3.1.1, and 3.1.2. Those are latest and newest versions from Hive community.This closes #9580.",1
[FLINK-13937][docs] Fix the error of the hive connector dependency versionFix the error of the hive connector dependency version in doc.This closes #9591.,2
[FLINK-13952][table-planner][hive] PartitionableTableSink can not work with OverwritableTableSinkTo support insert overwrite partition.This closes #9615.,1
[FLINK-13591][web] fix job list display when job name is very longThis closes #9621,0
[hotfix] Fix checkstyle violations in HighAvailabilityServices,0
[FLINK-13960] Add throwing HighAvailabilityServices#getWebMonitorLeaderRetriever default implDefault impl HighAvailabilitySerivces.getWebMonitorLeaderRetriever throws exceptionin order to refer to implementing the CLientHighAvailabilityServices instead.This closes #9629.,1
[FLINK-13964] Let HighAvailabilityServices create cluster and client side HA servicesLet HighAvailabilityServices extend ClientHighAvailabilityServices. This ensures thatthe HighAvailabilityServices can create cluster and client side HA services. This againis useful for components which need to create both types of services such as the MiniCluster.,5
[hotfix] Remove code duplication in HighAvailabilityServicesUtilsIntroduce HighAvailabilityServicesUtils#loadCustomHighAvailabilityServicesFactory toremove duplicated code in createCustomHAServices and createCustomClientHAServices.,1
[FLINK-13964] Replace #getWebMonitorLeaderRetriever implementations with #getClusterRestEndpointLeaderRetrieverThis commit changes all HighAvailabilityServices implementation to implementThis closes #9630.,4
"[FLINK-13977] Replace HighAvailabilityServices#getWebMonitorLeaderElectionService with #getClusterRestEndpointLeaderElectionServiceThis commit deprecates HighAvailabilityServices#getWebMonitorLeaderElectionService and addsa default implementation which throws an UnsupportedOperationException. Moreover, it introducesHighAvailabilityServices#getClusterRestEndpointLeaderElectionService which replaces the formermethod. The default implementation of this method calls getWebMonitorLeaderElectionService inorder to ensure backwards compatibility.",1
[FLINK-13977] Let HighAvailabilityServices implementations implement getClusterRestEndpointLeaderElectionServiceInstead of implementing HighAvailabilityServices#getWebMonitorLeaderElectionService allHighAvailabilityServices implementation now implement getClusterRestEndpointLeaderElectionService.This closes #9631.,1
[FLINK-13868][rest] Job vertex add taskmanager id in rest apiThis closes #9555.,1
[FLINK-13970][coordinate] Remove LifoSetQueue and SetQueueThis closes #9633.,1
[FLINK-13967][licensing] Fully generate binary licensing,2
[FLINK-13963][docs] Consolidate Hadoop file systems usage and Hadoop integration docs,2
[FLINK-13892][hs] Harden HistoryServerTest,3
"[FLINK-12501] Use SpecificRecord.getSchema in AvroFactoryBefore, we were using SpecificData.getSchema(type) which was not workingfor types that were generated using Avrohugger (for Scala) becausethe SCHEMA was generated in the companion object. Now we use a methodthat must be available on all SpecificRecord(s).We still use the old method as a fallback if we cannot instantiate orcall getSchema() on the instance.",1
[FLINK-13968][travis] Check correctness of binary licensing,2
[FLINK-12749][docs] Revert commit f695a76b10b0cb5f074bbb874fe374cd11e6eff3,4
[FLINK-12749][docs] Add operations playground.This closes #9543.[ci skip],1
"[FLINK-13942][docs] Add ""Getting Started"" overview page.This closes #9603.[ci skip]",1
[hotfix] Update NOTICE-binary file.,2
[FLINK-13388][web][docs] Updated screenshots to ones taken from the new UI,1
[hotfix][travis] Add detailed instructions for update binary licensing,5
[FLINK-13989][coordination] Remove legacy ClassloadingProps,4
[FLINK-13988][coordination] Remove legacy JobManagerCliOptions,4
[FLINK-13990][coordination] Remove legacy exceptions,4
[FLINK-13946] Remove session-related code from execution env,4
[FLINK-13946] Remove session-related code from the PlanExecutors,4
[FLINK-13946] Refactor executor code to ban resource sharing between plan executions.,4
[FLINK-13946] Remove unused constructors from RemoteExecutor,1
[FLINK-13946] Make the ClusterClient autocloseable,1
[FLINK-13946] Remove taskManagerNumSlots and defaultOverwriteFiles from LocalExecutor,2
[hotfix] Undo removal of ClusterClient#shutdown() for backwards compatibility.,4
[FLINK-13621][Tests] Update ContinuousFileProcessingMigrationTest to restore from 1.9 savepointThis closes #9600.,3
[FLINK-13623][Tests] Update StatefulJobSavepointMigrationITCase to restore from 1.9 savepointThis closes #9614.,5
[FLINK-13624][Tests] Update StatefulJobWBroadcastStateMigrationITCase to restore from 1.9 savepointThis closes #9626.,5
[FLINK-13625][Tests] Update StatefulJobSavepointMigrationITCase to restore from 1.9 savepointThis closes #9627.,5
[FLINK-13934][rest] Use hamcrest for checking String contents,1
[hotfix] Fix NOTICE-binary.,0
[FLINK-13978] Add azure-pipelines.yml,5
[FLINK-13620][Tests] Update FlinkKafkaProducerMigrationTest to restore from 1.9 savepointThis closes #9599.,3
[FLINK-13622][Tests] Update WindowOperatorMigrationTest to restore from 1.9 savepointThis closes #9612.,3
[hotfix][runtime] Rename StreamTask's performDefaultAction method to processInput,0
[docs-sync] Synchronize the latest documentation changes (commits to b61290fc) into Chinese documents,2
[FLINK-13994][docs-zh] Translate 'Getting Started' overview page into Chinese (#9649),1
[FLINK-14009][build] Ignore license file check for Scala version different than 2.11This closes #9651.,2
"[FLINK-13921] Simplify cluster level RestartStrategy configuration* If the config option `restart-strategy` is configured, then Flink uses this `RestartStrategy`* If the config option `restart-strategy` is not configured, then** If checkpointing is disabled, then choose `NoRestartStrategy`** If checkpointing is enabled, then choose `FixedDelayRestartStrategy(Integer.MAX_VALUE, ""0 s"")`This closes #9636.",0
[FLINK-13898] Migrate restart stratey config constants to ConfigOptionsMigrate existing config constants for restart strategies to ConfigOptions byintroducing a RestartStrategyOptions class with the corresponding ConfigOptions.,5
[FLINK-13898] Replace deprecated ConfigConstants with RestartStrategyOptionsThis closes #9562.,5
[FLINK-14005][hive] Support Hive version 2.2.0This closes #9647.,1
"[FLINK-13677][docs-zh] Translate ""Monitoring Back Pressure"" page into ChineseThis closes #9606",1
"[FLINK-13444][docs-zh] Translate BucketingSink deprecation note into ChineseBucketingSink has been deprecated in FLINK-13396, which added English note.The pull request attempting to translate that note to Chinese.This closes #9420",1
[FLINK-13997][coordination] Remove legacy LeaderAddressAndIdThis closes #9654.,1
[FLINK-13957] Log dynamic properties on job submissionCloses #9616,2
[FLINK-14000][runtime] Remove legacy ProcessShutDownThreadThis closes #9657.,4
[hotfix] Fix checkstyle violations in FailureRateRestartStrategy,0
[hotfix] Set restart delay for SimpleRecoveryFailureRateStrategyITBase to 0 sThis speeds up the SimpleRecoveryFailureRateStrategyITBase.,3
[FLINK-13884] Set default delay for restart strategies to 1sThis commit sets the default delay for all restart strategies to 1s in orderto prevent restart storms from happening.This closes #9637.,1
"[FLINK-13883] Deprecate unused AkkaOptions related to Akka's death watchWe no longer use Akka's death watch. Hence, this commit deprecates the deathwatch related configuration options AkkaOptions#WATCH_HEARTBEAT_INTERVAL,AkkaOptions#WATCH_THRESHOLD and AkkaOptions#WATCH_HEARTBEAT_PAUSE. Moreover,it removes the death watch verification logic in AkkaUtils.This closes #9638.",2
[FLINK-13626] Update StatefulJobSavepointMigrationITCase to restore from 1.9 savepointThis closes #9658.,5
[FLINK-13627] Update TypeSerializerSnapshotMigrationITCase to restore from 1.9 savepointThis closes #9659.,5
[FLINK-13336][docs] Remove deprecated batch fault tolerance pageRemove batch fault tolerance page and add redirect to task failure recoverypage.This closes #9365.,0
[FLINK-13628] Update AbstractKeyedOperatorRestoreTestBase to restore from 1.9 savepointThis closes #9660.,3
[FLINK-13629] Update AbstractNonKeyedOperatorRestoreTestBase to restore from 1.9 savepointThis closes #9661.,3
[hotfix] Remove .toDelete from flink-connector-cassandraThe .toDelete file seems to be accidentally committed to the Flinkrepository.,2
[FLINK-13631] Update FlinkKinesisConsumerMigrationTest to restore from 1.9 savepointThis closes #9662.,3
"[FLINK-14043] Speed up SavepointMigrationTestBase sub classesSince all SavepointMigrationTestBase sub classes rely on theMigrationTestUtils.AccumulatorCountingSink which uses user code accumulatorsin order to communicate with the test driver, we set the heartbeat intervalto 300ms in order to speed the test execution up. The reason this works isthat Flink transports user code accumulators from the TM to the JM viathe heartbeats. Hence, the heartbeat interval represents the lower boundaryfor the test completion.This closes #9664.",3
[FLINK-13959] Consolidate the code of Context and DetachedEnvironment,5
[FLINK-13959] Remove unnecessary method in DetachedEnvironment,4
[FLINK-13959] Remove usages of the DetachedEnvironment and the class itself.,4
"[FLINK-13653][sql-client] ResultStore should avoid using RowTypeInfo when creating a resultFix the issue that types with parameters, e.g. decimal, cannot be accessed via SQL client.This closes #9432.",2
[FLINK-13931][hive] Support Hive version 2.0.xThis closes #9644.,1
"[FLINK-11696][checkpoint] Avoid to send mkdir requests to DFS from task side (#7942)Previously, not only checkpoint coordinator but also tasks would always send those mkdir requests out when initialization. This would actually put a lot of pressure to master of distributed file system.This commit avoids to call file system's mkdir when creating CheckpointStorage, but call it only once by the CheckpointCoordinator.",1
[FLINK-14047] Add ConfigurationUtils.hideSensitiveValues to filter out sensitive values,5
[FLINK-14047][rest] Let JobConfigHandler replace sensitive values from user configurationThis commit replaces sensitive values from the user configuration by replacing them withGlobalConfiguration.HIDDEN_CONTENT.,5
[FLINK-14047] Use ConfigurationUtils.hideSensitiveValues in ClusterConfigurationInfoThis closes #9672.,5
[hotfix] Correct typo in ExecutionConfigInfo#isObjectReuse,5
[FLINK-13619] Update FlinkKafkaProducerMigrationOperatorTest to restore from 1.9 savepointThis closes #9667.,3
[FLINK-14049] [coordination] Add task name to error message for failed partition updates.This closes #9670,5
[FLINK-13981][runtime] Introduce config switch for enabling the new FLIP-49 task executor memory configurationsThis closes #9676.,5
[hotfix][docs] Fix typos in API concepts docsThis closes #9538.This closes #9619.,2
[hotfix][docs] Fix few typos in the java docsThis closes #9671.,2
[FLINK-13136][docs] Fix documentation error about stopping job with restful apiThis closes #9013.,0
[FLINK-14065] Log metric name when the metric fails on registration/unregistrationThis closes #9680.,0
[FLINK-12362] Remove legacy container number config option for Flink on yarnThis closes #9678.,2
[hotfix] Add disk and network resource and offer logging for flink-mesos,2
[FLINK-14029] Update Mesos scheduling behavior to reject all expired offersThis closes #9652.,5
[hotfix][runtime] Change return type for methods Execution#processFail(...)Change return types for processFail(...) methods from boolean to void becausethe returned value is not used anywhere.,1
[FLINK-13972] Remove PackagedProgram#getPreviewPlan(),1
[FLINK-13972] Remove preview field from PreviewPlanEnv,4
[FLINK-13972] Remove all production usages of the PreviewPlanEnv,4
[FLINK-13972] Move PreviewPlanEnv to flink-tests,3
[FLINK-13972] Rename the PreviewPlanEnv,2
[hotfix] Removed unused ClusterClient#run(),1
[hotfix][tests] Add tests timeouts,3
[hotfix][tests] AsyncWaitOperatorTest refactoring: use test harness' default mock environment,3
[hotfix][tests] AsyncWaitOperatorTest refactoring: move common test harness creation to a dedicated method,1
[hotfix][tests] Adjust code formatting,3
[hotfix][runtime] Streaming runtime: open mailbox early in constructor,1
[hotfix][runtime] Add main mailbox executor to MailboxProcessor,1
[hotfix][runtime] Drain mailbox on StreamTask shutdown,0
[hotfix][tests] Make StreamTaskTerminationTest non-blocking on main task's thread,3
"[hotfix][tests] Add thread invariants test for StreamTaskTests that some StreamTask methods are called only in the main task's thread.Currently, the main task's thread is the thread that creates the task.",1
[hotfix][tests] StreamTaskTimerTest refactoring,4
[FLINK-12481][runtime] Move checkpoint lock outside of SystemProcessingTimeService,5
[FLINK-12482][runtime] Move decline checkpoint handling into StreamTask,4
"[FLINK-12482][runtime] Move CheckpointListener.notifyCheckpointComplete call into StreamTaskThis should allow to not wait for StreamTask.notifyCheckpointComplete() call, once the latter is asynchronous.",1
"[FLINK-12482][runtime] Make StreamTask.triggerCheckpoint asynchronous, delegating execution to the task's thread",1
"[FLINK-12482][runtime] Make StreamTask.notifyCheckpointComplete asynchronous, delegating execution to the task's thread",1
"[FLINK-12482][runtime] Cleanup: remove not needed anymore FileSystemSafetyNet usage in Task.triggerCheckpointBarrierAfter delegating the actual call to the StreamTask's mailbox, the dispatcher thread is not calling user or filesystem operations. hence, we can remove the FileSystemSafetyNet guard.",5
[FLINK-12482][runtime] Task cleanup: remove dispatcher executor service; submit directly asynchronous checkpoint triggers to StreamTask,4
[FLINK-12481][runtime] Use StreamTask mailbox for processing time triggered actions,1
[FLINK-12958][runtime] Adding processing of downstream messages in AsyncWaitOperator's wait loops,1
[FLINK-13633][coordination] Move submittedJobGraph and completedCheckpoint to cluster-id subdirectory of high-availability storage,4
[FLINK-13633] Add HighAvailabilityServiceUtils.getClusterHighAvailableStoragePathLet BlobUtils and ZooKeeperUtils call HighAvailabilityServiceUtils.getClusterHighAvailableStoragePathto obtain cluster wide high available storage path.This closes #9598.,1
[hotfix] Remove unused constructor from FileSystemStateStorageHelper,5
[hotfix][docs] Fix some typos in Hive docsThis closes #9687.,2
[FLINK-14069] [core] Enable TimeUtils for all time units labels supported by scala Duration,1
[FLINK-14069] Streamline TimeUtils.TimeUnit.getAllUnits to automatically generate descriptionThis closes #9686.,1
[FLINK-13949][rest] Replace duplicated JobVertexDetailsInfo.VertexTaskDetail with SubtaskExecutionAttemptDetailsInfoThis closes #9699.,5
"[hotfix] Fix whitespace, imports, and Javadoc formatting in Plan",2
[hotfix] Fix Javadoc formatting and import order in StreamingPlan,2
[hotfix] Remove unused dumpStreamingPlanAsJSON from StreamingPlan,5
[hotfix] Remove unused static methods from LocalExecutor,1
[FLINK-14067] Remove Exception from PlanExecutor.getOptimizerPlanAsJSON,5
"[FLINK-14067] Refactor ExecutionEnvironment.getExecutionPlan() to be in root classBefore, each subclass had a slightly different way of getting theexecution plan (as JSON). Now, we factor that part out into a utilityand use that in the ExecutionEnvironment root class. This does mean,that we don't take into account special information that a clusterclient or some other environment might have for plan generation.Also, we can't remove the throws Exception from getExecutionPlan()because it is a @Public method.",1
[FLINK-14067] Reflectively load JSON plan generator in ExecutionPlanUtilWe do this to get rid of the dependency on PlanExecutor for generatingthe JSON plan. The executor should not be concerned with printing JSONplans and this will simplify future executor work.,1
[FLINK-14067] Remove unused PlanExecutor.getOptimizerPlanAsJSON(),5
[FLINK-12746][docs] Add DataStream API WalkthroughThis closes #9201.,5
"[FLINK-12746] Add DataStream API Walkthrough* Remove old DataStream tutorial* Update links to new API walkthrough* Update order of menu entries in ""Getting Started"" section* Update index pages to reflect updated ""Getting Started"" section.",1
"[FLINK-13979][docs-zh] Translate new ""Streaming File Sink"" docs to chineseThis closes #9677",1
[FLINK-14014] Bump maven-shade-plugin to 3.2.1Bumps maven-shade-plugin to 3.2.1 as version below 3.1.0 could not workwell with ASM 6.0(MSHADE-258) which is dependent by Beam,1
"[FLINK-14014][python][table-common] Adds basic classes PythonFunction, PythonEnv, PythonFunctionInfoIntroduces basic classes such as PythonEnv, PythonFunction, PythonFunctionInfointo flink-table-common which hold the information such as the Python executionenvironment, the serialized Python functions, etc. These classes are located inflink-table-common because they will be used by the added RelNode which will beintroduced later.",1
[FLINK-14014][python] Introduce PythonScalarFunctionRunner to handle the communication with Python worker for Python ScalarFunction execution* Introduces a series of PythonFunctionRunners. They are responsible for using  Beam's portability framework for Python UDF execution.* Handle the license statements as it introduces a few third-part dependences  are introduced because of we depends on Beam.This closes #9653,1
[FLINK-13965] Keep hasDeprecatedKeys and deprecatedKeys methods in ConfigOption and mark it with @Deprecated annotationThis closes #9691.,5
[FLINK-14017][python] Support to start up Python worker in process mode.This closes #9655,1
[FLINK-14107][kinesis] Erroneous queue selection in record emitter may lead to deadlock,2
[hotfix][API/DataStream] Add missing assert for checkpoint lock checksThis closes #9713.,3
[FLINK-13896][build] Set Scala compile target version to the same as Java compile target versionThis closes #9692,1
[FLINK-11859][runtime] Small improvement to performance of SpanningRecordSerializerThis removes the length buffer of SpanningRecordSerializer and serializes the record length tothe data buffer directly.This closes #9710,5
[FLINK-13449][core] Add ARM architecture to MemoryArchitectureThis patch adds 'aarch64' for ARM64/AARCH64 to the known 64 bit memory architectures.This closes #9273,1
[FLINK-9941][ScalaAPI] Flush in ScalaCsvOutputFormat before closeThis closes #9467,1
[FLINK-13796][coordination] Remove unused variable from YarnResourceManagerThis closes #9492,1
[hotfix][docs] Fix wrong JavaDoc link in SavepointSerializerThis closes #9588,2
[FLINK-13845][javadocs] Drop references to removed 'Checkpointed' interfaceThis closes #9604,4
[hotfix][build] Use parent's maven-surefire-plugin version in elasticsearch6 connector,1
"[FLINK-13953][build, runtime] Facilitate enabling new Scheduler in MiniCluster TestsThis closes #9675.",3
[FLINK-14140][python] Fix the broken flink logo in flink python shell.This closes #9725,2
[FLINK-14150][python] Clean up the __pycache__ directories and other empty directories in flink-python source code folder before packaging.This closes #9729.,2
"[FLINK-13864][fs-connector] Make StreamingFileSink extensibleThis PR makes the StreamingFileSink protected and the buildersmutable so that they can be subclassed. In order for the userto subclass the StreamingFileSink, he has to override theforRowFormat/forBulkFormat depending on his needs and thecorresponding builder so its the build() method returns thesubclass and not the original StreamingFileSink.",2
[FLINK-14160][docs] Describe --backpressure option for Operations Playground.This closes #9739.,2
"[hotfix][task] Refactor the process of checking input index for StreamOneInputProcessor#processInputWe can check the input index inside StreamTaskNetworkInput while updating, so we could remove this logicin StreamOneInputProcessor#processInput for the preparation of processing input based on emitNext way.",2
[hotfix][task] Remove unncessary SuppressWarnings from StreamOneInputProcessor,2
[hotfix][task] Remove unused argument from constructor of StreamTaskNetworkInput,1
[hotfix][network] Refactor the class name AsyncDataInput to PullingAsyncDataInput,5
[hotfix][task] Refactor the constrcutor of StreamTwoInputProcessorMigrate the construction of local temporary fields into TwoInputStreamTask and initialize the non-final fieldsduring declaration in StreamTwoInputProcessor instead of inside construcotor. To do so we could make the constructorof StreamTwoInputProcessor short and fresh.,1
[hotfix][task] Refactor the constrcutor of StreamOneInputProcessor,4
"[FLINK-13766][task] Refactor the implementation of StreamInputProcessor based on PushingAsyncDataInput#emitNextThe current data processing in task input processor is based on the way of NullableAsyncDataInput#pollNext. In order tounify the processing stack for new source operator, we introduce the new PushingAsyncDataInput#emitNext(Output) instead.Then we need to adjust the existing implementations of StreamOneInputProcessor/StreamTwoInputProcessor based on this newway. To do so, we could integrate all the task inputs from network/source in a unified processor on runtime side.",1
[FLINK-14157][e2e] Undo jaxb rellocations for java 8 in s3.,2
[FLINK-14157][e2e] Disable Streaming File Sink s3 end-to-end test for java 11.The test was disabled temporarily until a proper fix is added for FLINK-13748.The problem is that the rellocation of jaxb in only relevant for Java 11 andnot Java 8. For Java 8 it actually makes Flink fail at runtime.,1
[FLINK-14015][python] Introduces PythonScalarFunctionOperator to execute Python user-defined functions- Introduces PythonScalarFunctionOperator to execute Python user-defined functions for flink planner.- Introduces BaseRowPythonScalarFunctionOperator to execute Python user-defined functions for blink planner.This closes #9707.,2
[FLINK-14113][client] Remove class JobWithJarsThis closes #9726.,4
[FLINK-14094][metrics] Avoid duplicate metrics registration in TaskMetricGroup.getOrAddOperatorThis closes #9697.,1
[FLINK-14119][table-planner-blink] Fix idle state is not cleaned for RetractableTopNFunctionThis closes #9741,1
[FLINK-14145] Fix getLatestCheckpoint(true) returns wrong checkpointCloses #9727,0
[FLINK-14182][core] Make TimeUtils able to parse duration string with plural form labelsThis closes #9754.,1
[FLINK-14168][runtime] Remove unused BootstrapTools#generateTaskManagerConfigurationThis closes #9755.,5
[FLINK-14167][python] Move python-related scripts from flink-dist to flink-python.This closes #9746.,2
[FLINK-14158] Update Mesos scheduler to make leaseOfferExpiration and declinedOfferRefuse duration configurableThis closes #9737.,5
[FLINK-13971][rest] Add TaskManager ID o.a.f.runtime.rest.messages.JobVertexTaskManagersInfo.TaskManagersInfoThis closes #9724.,5
[FLINK-13746][e2e] Whitelist [Terror] to avoid end to end test failure in es 2.3.5This closes #9738.,0
[FLINK-14076] Ensure CheckpointException can be deserialized on JobManagerThis closes #9742.,2
[FLINK-14010][coordination] YarnResourceManager#onShutdownRequest triggers fatal errorThis closes #9719.,0
[FLINK-14129][hive] HiveTableSource should implement ProjectableTableSourceImplement ProjectableTableSource for HiveTableSource.This closes #9721.,2
[hotfix][task] Refactor the class name AvailabilityListener to AvailabilityProvider,1
"[hotfix][task] Remove invalid condition in StreamTwoInputProcessor#isAnyInputAvailableWhen StreamTwoInputProcessor#processInput is called, that means at-least one input has not finished yet. Soin the process of StreamTwoInputProcessor#isAnyInputAvailable, when the input1 is finished it is no need tocheck whether the input2 is finished or not. We could return the status of input2 directly.",5
"[hotfix][task] Refactor to integrate the logics of TwoInputSelectionHandler#setAvailable/UnavailableIndexCurrently the logic of TwoInputSelectionHandler#setAvailableIndex is done before selectNextInputIndex, andthe logic of TwoInputSelectionHandler#setUnavailableIndex is done after selectNextInputIndex. Actually thesetwo logics are close with each other and can be done together, and it is helpful to trace the logics to avoidspreading anywhere.",2
"[FLINK-13767][task] Refactor StreamInputProcessor#processInput based on InputStatusStreamInputProcessor#processInput could return InputStatus instead of current boolean value to keep consistent withPushingAsyncDataInput#emitNext.For the implementation of StreamTwoInputProcessor#processInput, we could maintain and judge the two input status togetherwith the next selected input index to determine the final precise status. To do so we could avoid invalid processInput callexcept for the first call.In addition, AvailabilityProvider#isFinished has the duplicated semantic with InputStatus#END_OF_INPUT for PushingAsyncDataInput,and it is only meaningful for PullingAsyncDataInput now. So we migrate the #isFinished method from AvailabilityProvider toPullingAsyncDataInput.",5
[FLINK-14070] Use TimeUtils to parse duration configs (akka unrelated parts),5
[FLINK-14070] Use TimeUtils to parse duration configs (akka related parts)This closes #9745.,5
[hotfix] Convert Akka duration configs to valid Akka duration format,5
[hotfix][coordination] Fix MiniCluster#closeAsync to correctly close all components and services,5
[FLINK-14180] Enable config of maximum capacity of FileArchivedExecutionGraphStore.This closes #9753.,2
[FLINK-14031][examples] Add blink planner dependency and examples which use blink plannerThis closes #9761,2
"[FLINK-14128][runtime,docs] Remove the description of restart strategy customizationThis closes #9722.",4
[hotfix][runtime] Remove RestartBackoffTimeStrategyOptions and use RestartStrategyOptions instead,1
[FLINK-12709][runtime] Add NoRestartBackoffTimeStrategy which suppresses all task restarts,1
[FLINK-12709][runtime] Implement RestartBackoffTimeStrategyFactoryLoader which also respects legacy restart strategy configsThis closes #8912.,5
[FLINK-14139][rest] Fix potential memory leak problem of rest server.This closes #9750.,0
[FLINK-14183] Remove scala duration usages from FutureUtils and other related classes,4
"[FLINK-14183] Remove scala duration usages from LeaderRetrievalUtils, ConnectionUtils and other related classes",4
[FLINK-14183] Remove scala duration usages from TestingUtils,3
[FLINK-14183] Remove scala duration usages from MetricRegistryImplTestThis closes #9757.,3
[FLINK-14114][client] Shift down ClusterClient#timeout to RestClusterClientThis closes #9723.,2
[FLINK-14016][python][flink-table-planner] Introduce DataStreamPythonCalc for Python function execution* Introduces DataStreamPythonCalc for Python ScalarFunction execution* Introduces PythonScalarFunctionSplitRule which split multiple ScalarFunctions contained in the same node* Add a logical rewrite phase for Python related rulesThis closes #9748.,2
[FLINK-13143][checkpointing] Remove unnecessary CheckpointExceptionHandler class (#9777),0
[FLINK-14186][e2e] Skip Elastic Search 2.3.5 case when running with JDK11This closes #9775.,1
[FLINK-14195] Add jaxb dependency and do relocation for java 11 in s3.,1
[FLINK-14195] Add Streaming File Sink s3 end-to-end test back for java 11.,3
[hotfix][runtime] Make slotSharingGroupId nullable in TestingLogicalSlot,3
[hotfix][runtime] Set correct SlotSharingGroupId in LogicalSlot returned by SimpleSlotProviderSet SlotSharingGroupId to the Task's SlotSharingGroupId in TestingLogicalSlotreturned by SimpleSlotProvider,1
[hotfix][runtime] Add checkNotNull for slotOwner ctor parameter in TestingLogicalSlot,3
[FLINK-12433][runtime] Add NoOpFailoverStrategyIntroduce a NoOpFailoverStrategy that is exclusively configured if the newgeneration scheduler is used. This is because the new scheduler does not dependon the legacy FailoverStrategy interface.,0
"[FLINK-12433][runtime] Introduce SchedulerBaseIntroduce common super class SchedulerBase for DefaultScheduler andLegacyScheduler, which contains code that is shared between the schedulerimplementations. Previously, DefaultScheduler inherited from LegacyScheduler toavoid re-implementing features such as queryable state, taking savepoints, etc.",2
[FLINK-12433][runtime] Add additional implementation to DefaultSchedulerImplement DefaultScheduler to the point where streaming and batch WordCount canbe executed. Note that restoring state does not work yet. This will be fixed inlater commits.Add additional functionality to ExecutionGraph so that it can be used byDefaultScheduler. Some of the logic in ExecutionGraph must not be run whenDefaultScheduler is configured. We introduce a function isLegacyScheduling() tobe able to toggle off some of the legacy behavior when DefaultScheduler isconfigured.This closes #9663.,5
[FLINK-14120][API/Datastream] Fix SystemProcessingTimeServiceTest.testImmediateShutdownFix testImmediateShutdown test: delegated thread synchronization to completableFutureAdded more explicit timeout for awaiting future completionThis closes #9767.,1
[FLINK-14244][runtime] Initialize DefaultScheduler with correct RestartBackoffTimeStrategyThis closes #9785.,5
[hotfix][tests] Fix the invalid method reference in javadoc of unit tests,3
[hotfix][tests] Remove dead codes in PartitionTestUtils,3
[hotfix][tests] Adjust to use constant BUFFER_SIZE in PipelinedSubpartitionWithReadViewTest,3
"[FLINK-10995][runtime] Copy intermediate serialization results only once for broadcast modeThe behavior of current channel selector is either for one channel or all the channels for broadcast mode.In broadcast mode, the intermediate serialization results would be copied into every BufferBuilder requestedfor every sub partition, so this would affect the performance seriously especially in large scale jobs.We can copy to only one target BufferBuilder and the corresponding BufferConsumer would be shared by all thesub partitions to improve the performance. For mixed operations with broadcast and non-broadcast, we shouldfinish the previous BufferBuilder first before transforming from broadcast to non-broadcast, vice versa.",5
[FLINK-13386][web]: Fix job manager configuration sort,5
[FLINK-13386][web]: Fix job subtask sort,0
[FLINK-13386][web]: Fix operators/tasks metrics sort,1
[FLINK-13386][web]: Add numeric metrics in job,1
[FLINK-13386][web]: Add all operators watermark,1
[FLINK-13386][web]: Fix sort in Firefox,0
"[FLINK-13992][coordination] Refactor Optional parameter in InputGateWithMetrics#updateMetricsAs consensus from community code style discussion, in InputGateWithMetrics#updateMetrics we can refactor to reduce the usage of Optional parameter.This closes #9684.",2
"[FLINK-13656][sql-parser] Bump sql parser Calcite dependency to 1.21.0* Add ExtendedSqlRowTypeNameSpec to represent custom ROW type name* Add SqlMapTypeNameSpec to represent SQL MAP type name* Add ExtendedSqlBuiltinTypeNameSpec to represent extended builtin type like STRING and BYTES* Add ExtendedSqlCollectionTypeNameSpec to represent custom collection type name* Remove original temp SqlXXXType files* Remove temp FlinkSqlDataTypeSpec because CALCITE-3213 has been resolved* In FlinkDDLDataTypeTest, support parsing for user defined type, now if user does not register UDT, it would throws during sql node validation",5
[FLINK-13656][table-planner][table-planner-blink] Bump flink and blink planner pom and notice file Calcite version to 1.21.0,2
[FLINK-13656][table-planner][table-planner-blink] Update implementation about match_recognize because of match partition keys structure changeThis change was introduced by CALCITE-1935.,4
[FLINK-13656][table-planner] Update converter rule descriptionThis was introduced by CALCITE-3115.,5
[FLINK-13656][table-planner][table-planner-blink] Update plan change for agg call distinct removeThis was introduced by CALCITE-3159.,4
"[FLINK-13656][table-planner][table-planner-blink] Update file for Calcite API changeThis was introduce by CALCITE-3187, CALCITE-3122, CALCITE-3267.",4
[FLINK-13656][table-planner-blink] Update plan change because of collapsed IS NOT DISTINCT FROMThis was introduced by CALCITE-3174.,1
[FLINK-13656][table-planner][table-planner-blink] Update files for non equal join condition push down change after sql-to-rel conversionThis was introduced by CALCITE-3101.This closes #9712,4
[FLINK-14179][sql-client] Fix the description of 'SHOW FUNCTIONS' in SQL Client (#9752),1
"[hotfix][python] Use pyflink code with higher priority if it existsAdd directory flink-python/pyflink to PYTHONPATH if it exists, this is helpful duringdevelopment as this script is used to start up the Python worker and putting thedirectory of flink-python/pyflink to PYTHONPATH makes sure the Python source code willtake effect immediately after changed.",4
"[FLINK-14018][python] Add Python building blocks to make sure the basic functionality of Python ScalarFunction could workWith this commit, users can write end to end python Table Api jobs with python UDFs. This commit mainly includes theApi, rule optimization and python runtime changes.",4
[FLINK-14018][python] Package cloudpickle in flink for ease of use for Flink Python usersThis closes #9766.,1
[hotfix] Fix typo in table planner RuleSetsThis closes #9795,1
[FLINK-14288][legal] Add Py4J NOTICE for source releaseThis closes #9816.,1
[FLINK-14050][yarn] Refactor YarnClusterDescriptor inheritance,4
[FLINK-14050][yarn] Narrow method visibility in YarnClusterDescriptor,2
[FLINK-14050][yarn] Remove unused parameter from #createYarnClusterClient,1
"[FLINK-14205] Return DuplicateJobSubmissionException if submitted job is a duplicateDispatcher#submitJob now returns a DuplicateJobSubmissionException, which is a subclassof JobSubmissionException, if the submitted job is a duplicate. This allows to betterdistinguish duplicate job submissions from other job submission errors.This closes #9771.",0
[FLINK-14178][build] Downgrade maven-shade-plugin to 3.1.1This closes #9817.,2
[hotfix] Remove Exception from ZooKeeperUtils#createLeaderRetrievalService,1
[FLINK-14251] Add FutureUtils#forward utilityThe forward function completes the second future with the result of the firstfuture.This closes #9786.,1
[FLINK-14252] Encapsulate Dispatcher services in DispatcherServicesThe DispatcherServices container contains all required Dispatcher servicesexcept for the JobGraphStore which needs to passed in separately to make it workwith the MiniDispatcher.This closes #9787.,5
[FLINK-14259] Introduce JobManagerRunner interfaceThis commit extracts the JobManagerRunner interface and renames the implementationclass into JobManagerRunnerImpl.This closes #9788.,1
[hotfix][benchmarks] Expose RecordWriterBuilder from the benchmark environment,0
[hotfix][benchmarks] Remove unused field from benchmark environment,1
[FLINK-10995][benchmarks] Use BroadcastRecordWriter for network broadcast benchmarks,1
[FLINK-14260] Port MiniDispatcherTest to use new TestingJobManagerRunnerFactoryNG,3
[FLINK-14260] Port DispatcherHATest to use TetingJobManagerRunnerFactoryNG,1
[FLINK-14260] Port ZooKeeperHaDispatcherTest to use TestingJobManagerRunnerFactoryNG,3
[FLINK-14260] Replace TestingJobManagerRunnerFactory with TestingJobManagerRunnerFactoryNG in DispatcherTest,3
[FLINK-14260] Port DispatcherResourceCleanupTest to use TestingJobManagerRunnerFactoryNG,3
[FLINK-14260] Replace TestingJobManagerRunnerFactory with TestingJobManagerRunnerFactoryNGThis commit removes the old TestingJobManagerRunnerFactory and renamesthe TestingJobManagerRunnerFactoryNG into TestingJobManagerRunnerFactory.This closes #9789.,3
[FLINK-14261] Add PermanentlyFencedRpcEndpointThis closes #9790.,1
"[FLINK-14277][tests] Upgrade InMemoryJobGraphStore to TestingJobGraphStoreRenames InMemoryJobGraphStore into TestingJobGraphStore and adds settable testingfunctions for all JobGraphStore methods.This changes makes the FaultyJobGraphStore obsolete and, hence, removes it.This closes #9806.",4
[hotfix] Remove inheritance relationship between PartialDispatcherServices and DispatcherServices,4
[FLINK-13516][test] Bump MiniKdc to 3.2.0,5
[hotfix][docs] Fix placement of ticks,0
"[FLINK-14214][runtime] Shortcut isAvailable().isDone() anti-starvation check in StreamTwoInputProcessorThis probably doesn't speed up the code, but it's how the isAvailable() was intended to be used.",1
[FLINK-13827][script] shell variable should be escaped,2
[hotfix][docs] Do not point to release-1.8 docs,2
[FLINK-13515][test] Fix ClassLoaderITCase fails on Java 11,0
[hotfix][test] Clean up unnecessary type argument declarations in ClassLoaderITCase,4
"[hotfix][runtime,tests] Fix checkstyle violations in ThrowableClassifierTest",3
"[hotfix][runtime,tests] Move ThrowableClassifierTest to correct package",3
[hotfix][runtime] Cleanup NoResourceAvailableExceptionRemove unused methods and fix checkstyle violations.,0
"[hotifx][runtime] Remove NonRecoverableError annotation from NoResourceAvailableExceptionWith new generation scheduler, NonRecoverableError will suppress restarts andcause jobs to fail. Thus NoResourceAvailableException with NonRecoverableErrorannotation will lead jobs to be FAILED, which did not happen in the past. Thisshould not happen because most issues that causes NoResourceAvailableExceptioncan be recovered via retries/restarts. To suppress restarts by purpose, oneshould pass a SuppressRestartsException as the param when creating aNoResourceAvailableException.",1
[hotfix][runtime] Complete future returned by SimpleSlotProvider#allocateSlot with TimeoutException when the slot request cannot be fulfilled and queued scheduling is allowedThis is similar to what the production SlotProvider does and can be helpful toverify some related error handlings.,0
[FLINK-14247][runtime] Use NoResourceAvailableException to wrap TimeoutException on slot allocation timeoutThis closes #9794.,1
[hotfix] Reduce code duplication in MetricUtils,0
"[FLINK-14299] Introduce ProcessMetricGroupThe ProcessMetricGroup encapsulates the Status and system metrics of the ClusterEntrypoint.These have been factored out of the JobManagerMetricGroup. In order to maintain backwardscompatibility, the same scope as the JobManagerMetricGroup is being used.",1
[hotfix] Factor out AbstractImitatingJobManagerMetricGroup super classThe AbstractImitatingJobManagerMetricGroup imitates the reporting of theJobManagerMetricGroup and can be used for metrics which are factored outof the JobManagerMetricGroup without breaking backwards compatibility wrtthe reported metrics.,4
[FLINK-14303] Introduce ResourceManagerMetricGroupIntroduce a new metric group called ResourceManagerMetricGroup which can be usedto report ResourceManager specific metrics.,1
[hotfix] Remove unused MetricRegistry from ResourceManager,1
"[FLINK-14303][metrics] Replace JobManagerMetricGroup with ResourceManagerMetricGroup in ResourceManagerWith this commit, the ResourceManager uses the ResourceManagerMetricGroup to register itsmetrics.",1
[FLINK-14305] Transfer ownership of JobManagerMetricGroup to DispatcherWith this commit the Dispatcher is now responsible for managing the lifecycle ofthe JobManagerMetricGroup.,2
[FLINK-14276][quickstarts] Scala quickstart compiles on JDK 11,2
[FLINK-13065][datastream][docs] Clarify key selector example,5
[FLINK-14283][kinesis][docs] Update Kinesis consumer docs for recent feature additions,1
[FLINK-14117][docs-zh] Translate changes on index page to Chinese (#9815),4
"[FLINK-13037][docs-zh] Translate ""Concepts -> Glossary"" page into ChineseThis closes #9763",1
[FLINK-13382][table-planner-blink] Port DecimalITCase to unit tests DecimalTypeTestThis closes #9669,3
[hotfix] [runtime] Let TimestampedCollector implement Output,1
[hotfix] [runtime] Moving specification on how to properly implement StreamOperator#open from a comment in AsyncWaitOperator into the doc of open,2
[FLINK-14044] [runtime] Removing EmitterThread and reducing synchronization in AsyncWaitOperator,1
[FLINK-14044] [datastream] Incorporating FLINK-13635 by adding tests for proper timeout handling,3
[hotfix] [runtime] Removing pendingElements from AsyncWaitOperator as the synchronous part of checkpoints cannot happen while yielding anymore.,1
[hotfix][doc] Correct code highlighting in state processor api documentation,2
[FLINK-14310][runtime] Get ExecutionVertexID from ExecutionVertex rather than creating new instances,1
[FLINK-10437][rest] Mark WebOptions#ADDRESS as fallback key,1
[FLINK-13524][es][docs] Fix typo,2
[hotfix][table][docs] Add missing braces,1
[hotfix] Remove unnecessary generics from DispatcherResourceManagerComponent,4
"[FLINK-14280] Introduce DispatcherRunnerIn order to better separate concerns which are currently contained in theDispatcher, this commit introduces the DispatcherRunner abstraction. TheDispatcherRunner is used by the DispatcherResourceManagerComponent and encapsulateshow the Dispatcher is executed.This closes #9807.",1
[FLINK-14281] Add DispatcherRunner#getShutDownFutureThe DispatcherRunner#getShutDownFuture is completed if the DispatcherRunner implementationintends to be shut down by its owner.This closes #9808.,1
"[FLINK-14282] Simplify DispatcherResourceManagerComponent hierarchyRemove unnecessary subclasses of AbstractDispatcherResourceManagerComponentand rename this class into DefaultDispatcherResourceManagerComponent. Moreover,this commit removes the unnecessary generics from the DispatcherRunnerFactoryto further simplify the code base.This closes #9809.",1
"[FLINK-14284] Add shut down future to DispatcherThis commit adds the shutDownFuture to all Dispatcher implementations. Moreover,forwards this signal to the DispatcherResourceManagerComponent via theDispatcherRunnerImpl.This closes #9810.",1
[FLINK-14285] Remove generics from Dispatcher factoriesSimplify Dispatcher factories by removing generics from them.This closes #9811.,4
[FLINK-14286] Remove Akka specific parsing from LeaderConnectionInfoRemove unused Akka specific parsing from LeaderConnectionInfo.This closes #9812.,5
[FLINK-14118][benchmarks] Add network throughput benchmark for data skew scenario. (#9850),5
[FLINK-14271][runtime] Remove legacy RestartPipelinedRegionStrategy components,4
"[FLINK-14315] Make heartbeat manager fields non-nullableThis commit introduces the NoOpHeartbeatManager which can be used to initializean unset heartbeat manager field. This allows to make the heartbeat manager fieldsnon-nullable which in turn avoid NPE.Moreover, this commit makes the heartbeat manager fields of the TaskExecutorfinal.This closes #9837.",1
[FLINK-14210][metrics][influxdb] Make timeouts configurable,5
[FLINK-14335][docs] Fix ExampleIntegrationTest example- java version wasn't compiling due to missing ';'- java version was checking order of the elements which cannot be guaranteed- examples where checking for the wrong results,0
[hotfix] Update README- add Java 11 to list of supported Java versions- add WSL to list of unix-like environments- updated some links to use https,1
"[FLINK-14300][runtime] Cleanup operator threads in case StreamTask fails to allocate operatorChain (#9857)This commit fixes a thread leak on the task manager when the StreamTask class fails to deserialize an operator when instantiating the operatorChain property. The error handling code cleans up all operator threads if the OperatorChain class is instantiated, but fails to clean up threads created before the OperatorChain class is instantiated if the operatorChain property is null.An example of a deserialization exception thrown when instantiating the OperatorChain object is as follows:org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot instantiate user function.        at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperator(StreamConfig.java:239)        at org.apache.flink.streaming.runtime.tasks.OperatorChain.<init>(OperatorChain.java:104)        at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:267)        at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)        at java.lang.Thread.run(Thread.java:748)Caused by: java.io.InvalidClassException: (...)",1
"[FLINK-14306][python] Add the code-generated flink_fn_execution_pb2.py to the source codePreviously, we generate some python file during the building. However, it introduces python dependencieswhich makes the building complicated. This commit adds the generated file directly into the source codemanually so that there is no python dependencies during building.This closes #9855.",2
[FLINK-13360][docs] Add documentation for HBase connector for Table API & SQLThis closes #9799,2
[FLINK-13361][docs] Add documentation for JDBC connector for Table API & SQLThis closes #9802,5
[FLINK-14353][table] Enable fork reuse for tests,3
"[FLINK-14118][runtime] Reduce the unnecessary flushing when there is no data available for flush. (#9706)The purpose of this commit is to reduce unnecessary flushing when there is no data available for flush. More specifically, when there is exactly one BufferConsumer in the buffer queue of subpartition and no new data will be added for a while in the future (may because of just no input or the logic of the operator is to collect some data for processing and will not emit records immediately), the previous implementation will continuously notify data available (may wake up the netty thread), which is unnecessary, and eliminating these unnecessary flush can reduce CPU usage by 20% - 40% for some jobs.Benchmark results before the fix:Benchmark    Mode     Cnt     Score      Error   UnitsnetworkSkewedThroughput     thrpt    30   18240.197  1892.419 ops/msAfter the fix:networkSkewedThroughput     thrpt    30   24532.313  1118.312 ops/m",0
[FLINK-14334][es][docs] Use ExceptionUtils#findThrowableThis closes #9849.,1
[hotfix] Remove Scala Promise from LeaderRetrievalUtils,4
[FLINK-14287] Decouple leader address from LeaderContenderChange LeaderElectionService#confirmLeadership to accept leader address so thatthe LeaderContender does not need to know the address of the potential leaderbefore gaining leadership. This allows to decouple the leader election from theactual leader component.This closes #9813.,1
[FLINK-14309] [test-stability] Add retries and acks config in producer test (#9835)Add retries and acks config to reduce the risk of failure of flush() method.,0
"[FLINK-14341][python] Support pip versions of 7.1.x for gen_protos.pyPreviously, only pip versions of >=8.0.0 are supported for gen_protos.py, thiscommit also add support for pip versions of 7.1.x.This closes #9851.",1
"[FLINK-14289][runtime] Remove Optional fields from RecordWriter relevant classesBased on the code style guides for Jave Optional, it should not be used for class fields. So weremove the optional usages from RecordWriter, BroadcastRecordWriter and ChannelSelectorRecordWriter.",4
[hotfix][runtime] Add missing generics in RecordWriterBuilder for avoiding unchecked warning,2
[hotfix] Fix checkstyle violations in LeaderElectionService,0
[FLINK-14298] Replace LeaderContender#getAddress with #getDescriptionThis commit changes the LeaderContender to only require implementations toreport a description of the contender used for logging purposes instead ofthe actual leader address.This closes #9821.,1
[hotfix] Add FutureUtils.completedVoidFuture,1
[hotfix] Use simulated self-type idiom in TestingRestful/DispatcherGateway.Builder,3
[hotfix] Fix checkstyle violations in RpcEndpoint,0
[hotfix] Add JobGraphStoreFactory,4
[hotfix] Add TriFunctionWithException,1
[hotfix] Let AbstractMetricGroupTest extend TestLogger,3
[FLINK-14307] Extract JobGraphWriter from JobGraphStoreThis closes #9830.,4
[hotfix][e2e] Disable Avro Confluent schema registry e2e test until FLINK-13567 has been fixed,0
"[hotfix][runtime, test] Unify formatting in StreamConfigChainer",5
"[hotfix][runtime, test] Refactor StreamConfigChainer to support StreamOperatorFactory and honour pass down the bufferTimeout",4
"[FLINK-14300][runtime, test] Add test making sure that RecordWriter is properly closed in case of early StreamTask failureThis adds a missing test coverage for the 0d112f5bc61e6f8400e000e13add08abae1067a1 commit.",1
[FLINK-14347][test] Filter out expected exception string in YARN testsThis closes #9880.,3
[FLINK-14343][coordination] Remove uncompleted YARNHighAvailabilityServiceThis closes #9852.,4
[FLINK-14273][table-planner] Improve exception message when signature validation of UDAF is failedThis closes #9823,0
[FLINK-14273][table-planner-blink] Add UserDefinedFunctionValidationTest to verify operand type check,5
"[FLINK-14004][runtime] Define SourceReaderOperator to verify the integration with StreamOneInputProcessorWe already refactored the task input and output in runtime stack for considering the requirements of FLIP-27. In order tofurther verify that the new source could work well with the unified StreamOneInputProcessor in mailbox model, we define theSourceReaderOperator as task input and implement a unit test for passing through the whole process.",4
"[FLINK-14212][python] Support no-argument Python UDFs.Support Python UDFs with no arguments, e.g., tab.select(""one(), two()"").This closes #9865.",1
[FLINK-14208][python] Support Python UDFs with parameters of constant valuesSupport Python UDFs with parameters of constant values. The constant parameters are not neededto be transferred between the Java operator and the Python worker for each input record.This closes #9858.,1
[hotfix][runtime] Make SchedulerBase#getInputsLocationsRetriever() final,1
[hotfix][runtime] Make SchedulerBase#getFailoverTopology() final,2
[hotfix][runtime] Make SchedulerBase#getSchedulingTopology() final,2
[hotfix][tests] Remove unused methods from FailingExecutionVertexOperationsDecorator,0
"[FLINK-14291][runtime, tests] Add test coverage to DefaultScheduler- Remove SubmissionTrackingTaskManagerGateway, and introduce  TestExecutionVertexOperationsDecorator to track task deployments.- Introduce DefaultExecutionSlotAllocatorFactory- Introduce TestExecutionSlotAllocatorThis closes #9872.",3
"[FLINK-13339][ml] Add an implementation of Flink ML Pipeline api.- Add an abstract implemention of PipelineStage, Estimator, Transformer, Model.- Add MLEnvironment to hold the execution environment and others environment shared variable.- Add AlgoOperator for the implementation of algorithms.- Add BatchOperator and StreamOperator based on AlgoOperator.- Add TableSourceBatchOp and TableSourceStreamOp.",1
[hotfix][doc] fix typos in RichFunction,1
[hotfix][runtime] Pipelined partition consumers should not be scheduled in LazyFromSourcesSchedulingStrategy#onExecutionStateChangeThe pipelined partition consumers should be already scheduled inLazyFromSourcesSchedulingStrategy#onPartitionConsumable.,4
[FLINK-14331][runtime] Introduce TestSchedulingStrategy for flexible scheduler testing,3
[FLINK-14331][runtime] Cancel the ongoing slot request of a vertex when canceling the vertex,2
"[FLINK-14331][runtime] Reset vertices before asking the scheduling strategy to restart themWithout this change, the LazyFromSourcesSchedulingStrategy will fail to restarttasks. This is because the LazyFromSourcesSchedulingStrategy only schedulesvertices in CREATED state.",1
[FLINK-14331][runtime] Make DefaultScheduler only schedule vertices in CREATED stateAlso define SchedulerOperations#allocateSlotsAndDeploy to accept vertices inCREATED state only.  This rule helps to figure out invalid or duplicatedscheduling requests.This closes #9860.,1
[hotfix][runtime] DefaultExecutionSlotAllocator checks for duplicated slot allocationThis ensures that a restarted vertex is in a correct state to request a slot.It also ensures that DefaultExecutionSlotAllocator will not drop the referenceof an existing pending slot request.,4
[FLINK-13999][cep][docs] Correct the example in the section of Aggregations of MATCH_RECOGNIZE,2
[hotfix][docs] Fix the incorrect scala checkstyle configure file pathThis closes #9875,2
[FLINK-13025] Elasticsearch 7.x support,1
"[FLINK-13025] In ES7 SQL connector, update shading rules and NOTICE",5
[hotfix] Rename `TaskManagerOptions#MANAGED_MEMORY_SIZE` and `TaskManagerOptions#MANAGED_MEMORY_FRACTION` with prefix `LEGACY_`.This is to avoid naming conflict with the new config options.,5
[FLINK-13982][runtime] Introduce FLIP-49 task executor memory config options.,5
"[FLINK-13982][core] Introduce arithmetic operations (add, subtract, multiply) for MemorySize.",1
[FLINK-13982][runtime] Introduce 'TaskExecutorResourceSpec' to store memory / pool sizes of TaskExecutors.,2
[FLINK-13982][runtime] Introduce 'TaskExecutorResourceUtils' for calculating memory / pool sizes from configuration.,5
[FLINK-13982][runtime] Generate dynamic configurations and JVM parameters with TaskExecutorResourceUtils.This closes #9760.,2
"[FLINK-12576][docs,metrics] Document that input pool usage metrics ignore LocalInputChannels",2
"[hotfix][docs,metrics] Fix typo in the input pool usage metrics",2
[FLINK-14246][runtime] Annotate MiniClusterITCase with AlsoRunWithSchedulerNG and fix broken testsThe tests broke because the error messages of NoResourceAvailableExceptions fromLegacyScheduler and DefaultScheduler are different.,0
"[FLINK-14246][runtime] Annotate TaskExecutorITCase with AlsoRunWithSchedulerNG and fix broken testsThe test testJobRecoveryWithFailingTaskExecutor was to fail because terminatingone TM will cause 2 tasks to fail, leading to 2 failure recoveries when usingDefaultScheduler. And the restart strategy limited max failure count to 1.",0
[FLINK-14246][runtime] Annotate all other MiniCluster tests in flink-runtime with AlsoRunWithSchedulerNGThis closes #9901.,1
[FLINK-14215][docs] Add how to configure environment variables to documentationThis closes #9887.,2
"[FLINK-12628][Runtime / Coordination] Remove no consumers check in Execution.getPartitionMaxParallelismCurrently, we have a TODO for this case in Execution.getPartitionMaxParallelism because of tests:// TODO consumers.isEmpty() only exists for test, currently there has to be exactly one consumer in real jobs!though partition is supposed to have always at least one consumer at the moment.After having run the CI, there is no test failure, when we ignore the case for consumers.isEmpty() equals to true.This means we can remove the TODO and the check leaving only the precondition assertion.",3
[FLINK-14185][tests]Move unstable assertion statement out of close method of QS test server.,3
[FLINK-14349][hbase] Create a Connector Descriptor for HBase so that user can connect HBase by TableEnvironment#connectThis closes #9866,1
[FLINK-14349][docs] Add documentation for HBase descriptor API,2
[hotfix][kafka][es] Add missing @PublicEvolving annotation on Kafka and Elasticsearch descriptor class,1
[FLINK-14216][table] introduce temp system functions and temp functions to FunctionCatalogadapt existing APIs to the introduction of temporary system and temp functions according to FLIP-57.This closes #9822.,1
[hotfix][hbase] Put flush interval string to properties instead of parsing it in HBase descriptorThis fixes the broken HBase descriptor,0
[FLINK-14355][docs] Fix compile errors in State Processor API docs,2
[FLINK-14045][runtime] Make SlotProviderStrategy class public,1
[FLINK-14045][runtime] Use SlotProviderStrategy in DefaultExecutionSlotAllocatorThis closes #9896.,1
[hotfix][runtime] Replace Arrays.asList() with Collections.singletonList(),0
[FLINK-14365][tests] Annotate MiniCluster tests in core modules with AlsoRunWithSchedulerNGThis closes #9901.,1
"[FLINK-14290] Add Pipeline as a common base class of DataSet and DataStream plansFor now, only DataSet Plan implements this, as a follow-up, StreamGraphshould also implement this.",5
"[FLINK-14290] Add Pipeline translation utils for getting a JobGraph from a FlinkPipelineFor now, we can only translate DataSet Plans, in the future we also needthis for DataStream StreamGraps.",5
[FLINK-14290] Change DataSet PlanExecutors to use the new pipeline translation utilThis decouples JobGraph generation from the executors and environments.,1
[FLINK-14290] Add support for StreamGraph to pipeline translation util,1
[FLINK-14290] Use LocalExecutor in LocalStreamEnvironment,1
"[FLINK-14290] Add SavepointRestoreSettings to StreamGraph and GeneratorsWe need this to be able to set SavepointRestoreSettings on a StreamGraphthat we want to execute via an Executor (PlanExecutor). If we don't setthe settings on the StreamGraph we would have to pass them to theExecutor, as we now pass them to the ClusterClient.This can make the Executor/ClusterClient unaware of this streaming-onlysetting.",1
[FLINK-14290] Use RemoteExecutor in RemoteStreamEnvironment,3
[FLINK-14290] Use PipelineTranslationUtil and client.submitJob() in StreamContextEnvironment,1
[hotfix] Fix formatting/checkstyle in PlanExecutor,0
"[FLINK-14290] Move jars and classpath out of executors and add to execute() methodBefore, the executors were potentially storing the jar and classpathinternally while the jars and classpaths are really a property of thepipeline that should be executed. This change reflects that.",4
"[FLINK-14391] Factor out translator discovery in FlinkPipelineTranslationUtilThis way, we can reuse the discovery from different methods that we'lladd in follow-up commits.",1
[FLINK-14391] Add JobID setter in JobGraphThis allows setting the JobID after creation of the JobGraph.,1
[FLINK-14391] Add JSON execution graph generation to PipelineTranslationUtil,5
[FLINK-14391] Remove JobID parameter from exception in RemoteStreamEnvironmentCreating a JobGraph from a StreamGraph using this method creates arandom JobID that doesn't give any information.,5
[FLINK-14391] Remove FlinkPlan as common base class of OptimizerPlan and StreamGraphWe also need to change/simplify some translation logic because of this.,1
[hotfix][hs] Deduplicate variables,0
[hotfix][hs] Clarify write access to webJobDir,0
[FLINK-14337][hs] Prevent NPE on corrupt archives,2
[FLINK-14337][hs] Only mark archives as processed on success,2
[FLINK-13097] Make the cause for EOFException explicit (buffer depletion),1
[FLINK-13008] fix findbugs warning in AggregationsFunction,1
[FLINK-12979][formats] Allow empty line delimiter for CsvRowSerializationSchemaThis closes #9529.,1
[FLINK-14409][table] Fix MapType and MultisetType doesn't accept any subclass of java.util.Map for inputsThis closes #9913.,1
[hotfix][docs] Add MAP data type docs,2
[FLINK-14421][table] Add 'L' suffix to static long value (#9917),0
[FLINK-14296][sql-parser] Improve handling of parameters nullabillity in parser module1. Add @Nullable annotation to nullable fields2. Use Optional instead of nullable as return value3. Add requrieNonNull check in constructor for non-null fields4. List fields do not need to check against nullThis closes #9843,1
"[hotfix][docs-zh] Fix the incorrect links in ""Savepoints"" pageThis closes #9911",1
[docs-sync] Synchronize the latest documentation changes (commits to 86ae90ed) into Chinese documents,2
[FLINK-14176][web] Add log url for taskmanager of vertex (#9798),2
[FLINK-14413][build] Specify encoding for ApacheNoticeResourceTransformer,2
[hotfix][release] Use release version in path,1
[FLINK-14008][release] Generate binary licensing during release,2
[FLINK-14008][release] Remove redundant NOTICE-binary infrastructure,5
[FLINK-5490] Verify that ExecutionEnvironment#getExecutionPlan() does not clear sinks,1
[hotfix][javadocs] Fix typo,2
[FLINK-12399][table-planner] Check the table source digest changed after project/filter had been pushed down into it.Also fix table sources that incorrectly overrides explainSource without explaining pushdownThis closes #8468,5
[FLINK-14278] Extend DispatcherResourceManagerComponentFactory.create to take ioExecutorThis closes #9831.,1
[hotfix] Fix scheduler-ng profile to set system property jobmanager.scheduler=ng,5
[FLINK-14237][yarn] No need to rename shipped Flink jarThis closes #9861 .,2
[FLINK-14130][client] Remove ClusterClient.run() methods,1
[FLINK-14130][client] Shift down Logger from ClusterClient to RestClusterClient,2
[FLINK-13818][web] Check whether web submission are enabled,0
[FLINK-14445][python] Fix python module build failed when making sdist.This closes #9932.,1
[hotfix][test] Drop unused timeout parameter,2
"[FLINK-14004][runtime,test] Add test coverage for stateful SourceReaderOperator implementation",1
"[FLINK-13601][tests] Harden RegionFailoverITCaseUse CompletedCheckpointStore to record completed checkpoints, since it's reliable than notifications returned to the task.",0
[FLINK-7629] [scala] Fix RecursiveProductFieldAccessor.fieldType,0
[hotfix] Only use types defined in CaseClassFieldAccessorTest in the test,3
[FLINK-7629] [scala] Fix KeyedStream.aggregate for nested field expressions,0
[FLINK-12848][table] Fix invalid row type cachingThis closes #9930.,0
[FLINK-14272][python][table-planner-blink] Support Blink planner for Python UDF(Scalar Function)Ports python User-Defined Scalar Function from flink planner to blink planner.This closes #9890.,2
[FLINK-14366][tests] Enable TaskFailureITCase to pass with NG scheduler,4
[FLINK-14366][tests] Enable AccumulatorErrorITCase to pass with NG scheduler,4
[FLINK-14366][tests] Enable CustomSerializationITCase to pass with NG scheduler,4
[FLINK-14366][tests] Enable MiscellaneousIssuesITCase to pass with NG scheduler,4
[FLINK-14366][tests] Enable SuccessAfterNetworkBuffersFailureITCase to pass with NG scheduler,4
[FLINK-14366][tests] Enable TextOutputFormatITCase and CsvOutputFormatITCase to pass with NG scheduler,4
"[FLINK-14366][tests] Annotate MiniCluster tests in flink-tests with AlsoRunWithSchedulerNGAbstractTestBase in flink-test-utils is also annotated here to enabled tests based on it.7 failed tests are not included and will be fixed in separate PRs:* ClassLoaderITCase, EventTimeWindowCheckpointingITCase and WindowCheckpointingITCase in FLINK-14371* KeyedStateCheckpointingITCase in FLINK-14372* ZooKeeperHighAvailabilityITCase in FLINK-14373* RegionFailoverITCase in FLINK-14374* BatchFineGrainedRecoveryITCase in FLINK-14440This closes #9900.",2
[FLINK-14330][runtime] Introduce base topology interfaceThis closes #9934.,2
[FLINK-14401][table][hive] create DefaultFunctionDefinitionFactory to instantiate regular java class-based udfcreate FunctionDefinitionUtil to instantiate regular java class-based udf and add HiveFunctionDefinitionFactory to instantiate both flink and hive udfThis closes #9908.,2
[FLINK-14459][python] Fix python module build hang problemThe latest conda installer may hang in some circumstances. We should specify a stable version instead of the latest.This closes #9941.,3
[FLINK-14027][python][doc] Add documentation for Python User-Defined Scalar function.This closes #9886.,1
[hotfix][doc] fix typo in RuntimeContextThis closes #9945.,1
[hotfix][task] Fix the code formatting in StreamTask,0
[hotfix][runtime] Remove legacy NullableAsyncDataInput class,5
[hotfix][network] Remove optional class field from LocalBufferPool,4
"[FLINK-14394][network] Remove unnecessary interface method BufferProvider#requestBufferBlockingCurrently BufferProvider#requestBufferBlocking method is only used for unit tests, so we could refactor the related tests to usemethods of BufferProvider#requestBufferBuilderBlocking or BufferProvider#requestBuffer instead. Then we could remove this legacymethod completely to clean up the interface.",4
"[FLINK-13485][docs-zh] Translate ""Table API Example Walkthrough"" page into ChineseThisc closes #9784",1
"[FLINK-8822] In config.sh, don't use extended regex for rotationThe -E parameter is a FreeBSD/MacOS feature while -r is GNU. It's hardto know which of -E/-r to use.",1
"[FLINK-14441][table-api] Fix ValueLiteralExpression#getValueAs when value is PeriodWhen value is Period, getValueAs(Integer.class) returns a Long value.This closes #9931",1
[FLINK-14123][docs] Update release notes to contain warning about OOMThis closes #9949.,2
[FLINK-14461][configuration] Remove unused sessionTimeout from JobGraphThis closes #9942.,1
[FLINK-14456][client] Exclude lastJobExecutionResult from ClusterClient,2
[FLINK-14457][client] Shift down ClusterClient#configuration,5
[FLINK-14469][python] Drop Python 2 support for PyFlink- Remove the CI for Python 2.7- Throw an exception if Python below 3.5 is used(both for install and run on worker)- Clean up code specific for Python 2.xThis closes #9947.,4
[hotfix][runtime] Remove duplicated check from ExecutionGraph ctor,4
[FLINK-14206][runtime] Let fullRestart metric count both full restarts and fine grained restartsThis closes #9778.,2
[hotfix][tests] Remove legacy executor assumptions in ExecutionGraphRestartTest,3
[FLINK-14434][coordination] Dispatcher#createJobManagerRunner returns on creation succeedThis closes #9940.,1
[hotfix] Annotate MemoryManager methods used for testing with the @VisibleForTesting,3
[hotfix] Introduce MemoryManagerBuilder for tests,3
[hotfix] Remove unsed methods and fields in MemoryManager,4
[hotfix] Checkstyle fixes in MemoryManager,0
[hotfix] Refactor MemoryManager constructor,4
[hotfix] Remove and deprecate memory preallocation in MemoryManager,4
[FLINK-13984] Separate on-heap and off-heap managed memory poolsRefactor MemoryManager to support allocating from two memory pools ofdifferent types (heap/off-heap) at the same time.,1
"[FLINK-14399] Implement reservation of memory chunks in MemoryManagerMemoryManager allocates paged segments from the provided memory pools of different types (on-/off-heap).Additionally, it can manage reservation and release of arbitrarily sized chunks of memory from the same memory poolsrespecting their overall limit. The way, how the memory is allocated, used and freed, is then up to the memory user.MemoryManager is just a book-keeping and limit checking component.",1
[hotfix] Enable memory manager with zero memory or zero pages,0
[FLINK-14447] Network metrics doc table render confusion,5
"[hotfix][kafka,test] Drop unused field in FailingIdentityMapper",0
"[hotfix][kafka,test] Remove unused statement from testOneToOneAtLeastOnce",3
[hotfix][dist] Rename local variables in GlobalConfiguration,5
"[FLINK-14235][kafka,tests] Change source in at-least-once test from finite to infinitePreviously it was possible that the source would end before a first chcekpoint could complete.If that was the case, any exceptions thrown during checkpointing are swallowed, which could explainthe apparent data loss from FLINK-14235.",2
[hotfix] Use MemorySegmentFactory in tests instead of HybridMemorySegment constructors,3
[hotfix] Minor refactoring of OperationsOnFreedSegmentTest,3
"[FLINK-13985] Use unsafe memory for managed memoryMakes allocation of off-heap memory independent of direct buffers and limiting option -XX:MaxDirectMemorySize.This implementation uses sun.misc.Unsafe for that purpose. - Add allocate/release unsafe memory methods to MemoryUtils - Add a MemoryUtils#createMemoryGcCleaner to release memory in phantom reference queue   upon GC of the memory owning object (based on sun.misc.Cleaner similar to java.nio.DirectByteBuffer(int cap)). - Add MemoryUtils#wrapUnsafeMemoryWithByteBuffer which uses the private constructor java.nio.DirectByteBuffer(long address, int cap)   to wrap unsafe memory but w/o checking -XX:MaxDirectMemorySize. - Add an optional custom action to call in HybridMemorySegment#free for memory cleanup - Change MemorySegmentFactory#allocateUnpooledOffHeapMemory to   - allocate unsafe memory,   - wrap it with ByteBuffer with MemoryUtils#wrapUnsafeMemoryWithByteBuffer   - hook a phantom reference queue cleaner upon the buffer GC and   - create HybridMemorySegment with this buffer and its custom cleaner.",4
[hotfix] KeyedBudgetManagerTest extends TestLogger,3
[FLINK-13539][table-api] Improve CSV table factory doesn't need to require format.fieldsThis closes #9421,1
[FLINK-14202][table][python] Optimize the execution plan for Python Calc when there is a conditionOptimizes the Python UDF execution plan when there is a condition which containsPython UDFs by calculating the condition firstly and then check whether to callthe other UDFs. This can eliminate the Python UDF execution for the input rowswhich could be filtered by the condition.Brief changes:- Refactor PythonScalarFunctionSplitRule by splitting it into multi rules to  make it more understandable.- Handle cases where condition is not null in the SplitRule.This closes #9907.,0
[hotfix][typo] fix typo in YarnClusterDescriptor,2
[FLINK-14336][checkpointing] Log exceptions during async checkpoint,2
[hotfix][streaming] Fix/clarify side output comment,0
[FLINK-13519][es][docs] Correct scala Elasticsearch 6.x example,2
[hotfix][es][docs] Sync english/chinese docs,2
[FLINK-12622][scala][docs] Fix ProcessWindowFunction example,1
[hotfix][table] JoinedRow failed on toString as the default implementation invokes the unsupported hashCode.,1
[FLINK-14199] [runtime] Mailbox explicitly requires a description to ease debugging,0
[FLINK-14199] [runtime] Improving error-reporting when a Mailbox mail failed to executePromoting Mail to internal class and using it primarily in Mailbox API.Moving priority association entirely to MailboxExecutor.Removing priority views on TaskMailbox - the MailboxExecutor will now put and pull mails with its priority.Consolidating Mailbox hierarchy: Only the Mailbox interface for MailboxExecutor and the TaskMailbox interface for MailProcessor remain.,5
[FLINK-14199] [runtime] Improving the performance of named mails by adding overloaded submission methods to MailboxExecutor.java that do not create a new array for empty arguments.,1
[FLINK-14169][history-server] Refactor HistoryServerTest for reusability,3
[FLINK-14169][history-server] Cleanup expired jobs from history server- added logic for removing deleted job archives from history server,4
[FLINK-14416][table] Add Module interface and ModuleManagerAdd Module interface and ModuleManager to Flink SQL.This closes #9937.,2
[FLINK-13873][rocksdb][metrics] Optionally expose column_family as variable,5
[hotfix][runtime] Refactoring: remove ProcessingTimeService::shutdownAndAwaitPending method,4
[hotfix][runtime] Refactoring: move timer service lifecycle methods into a separate interface,4
[hotfix][tests] Reformat StreamSourceOperatorWatermarksTest according to code style (method argument on new lines),1
[FLINK-14156][runtime] Refactoring: move ProcessingTimeService access request at operator level,1
[FLINK-14156][runtime] Instantiate ProcessingTimeService per operator (with timer execution by operator precedence),1
[hotfix][tests] RocksDBAsyncSnapshotTest: use test harness helper method to wait until task is running,1
[FLINK-14156][tests] Rewrite StreamTaskOperatorTimerTest to observe flow via output (to avoid using mutable static fields),1
[hotfix][tests] Clean up ExecutionFailureHandlerTest,3
[FLINK-14232][runtime] Support global failure handling in DefaultScheduler- Enable ExecutionFailureHandler for global failure handling- Introduce handleGlobalFailure interface to SchedulerNG- Refactor InternalTaskFailuresListener to also support global failure listening- Notify the InternalFailuresListener about global failure for NG scheduler in ExecutionGraph#failGlobalThis closes #9904.,0
[FLINK-14265][table-planner-blink] Don't use ContinuousFileReaderOperator to support multiple paths in batch (#9803),1
[hotfix][coordination] Update field namePartitionTable was at some point only tracking per job but was later generalized to work with arbitrary keys. The field name was updated accordingly however.,5
[FLINK-14053][table-planner-blink] Fix DenseRankAggFunction first row bug.We should consider the possibility that first row's order by key is equal to the initial last value.This closes #9966,5
[FLINK-14408][table-planner] Fix open() is not called if UDF is reduced during optimizationThis closes #9916,0
"[FLINK-14524] [flink-jdbc] Fix syntax for PostgreSQL dialect ""upsert"" statement (#9990)",0
[FLINK-14321][sql-parser] Support to parse watermark statement in SQL DDLThis closes #9952,1
[FLINK-14342][table][python] Remove method FunctionDefinition#getLanguage.Do some cleanup in this commit. We don't need to add getLanguage() in FunctionDefinitionas we can use the interface PythonFunction directly to judge whether it is a Python ScalarFunction.This closes #9894.,1
[FLINK-14522] Revert FLINK-13985 (sun.misc.Cleaner is not available in Java 9+),4
[hotfix][table-planner] Remove unused import in CalcITCase,2
[FLINK-14381][table-planner] Remove dynamic partition shuffle support in legacy planner,1
[FLINK-14381][table-planner-blink] User table factory and catalog table to test partition source and sink,3
[FLINK-14381][table-planner-blink] Get partition keys from catalog table for PartitionableTableSink,2
[FLINK-14381][table-planner-blink] Get partition keys from catalog table for PartitionableTableSource,2
[FLINK-14381][table-planner-blink] Remove getPartitionFieldNames in PartitionableTableSource and PartitionableTableSinkThis closes #9909,1
[FLINK-14363][runtime] Prevent vertex from being affected by outdated deploymentThis closes #9902.,5
"[hotfix][tests] TestingLogicalSlot should only respect the first slot release requestOtherwise it may return itself to the slotOwner several times, which may lead toerrors or more available slots than expected.",0
"[hotfix][runtime] Remove the unnecessary slot release logic for outdated deploymentFor DefaultScheduler#assignResourceOrHandleError, a normally completed slotrequest can trigger it only if the vertex is not canceled after this scheduling,which means the deployment is not outdated. ForDefaultScheduler#deployOrHandleError, the slot should always be assigned orreleased.",0
[FLINK-14449][tests] Use dedicated deadline for each test,3
[FLINK-14497][python] Replace coder with typeserializer,2
[FLINK-14497][python] Support TinyIntType for Python UDF,1
[FLINK-14497][python] Support BooleanType for Python UDF,1
[FLINK-14497][python] Support SmallInt for Python UDF,1
[FLINK-14497][python] Support IntType for Python UDF,1
[FLINK-14497][python] Support FloatType for Python UDF,1
[FLINK-14497][python] Support DoubleType for Python UDF,1
[FLINK-14497][python] Support BinaryType/VarBinaryType for Python UDF,1
[FLINK-14497][python] Support CharType/VarCharType for Python UDF,2
[FLINK-14497][python] Support DateType for Python UDFThis closes #9977.,5
[FLINK-14509][python] Improve the README.md in flink-python to prepare for PyPI release.PyFlink will be released on PyPi from FLINK 1.10.0. This commit adds corresponding document for it.This closes #9982.,2
[hotfix] Enrich DispatcherRunnerFactory to pass in additional services,1
[hotfix] Introduce JobManagerMetricGroupFactory and use for DispatcherServices creationThe JobManagerMetricGroupFactory allows to create a fresh JobManagerMetricGroup wheneverwe create a new Dispatcher instance.,1
[hotfix] Stop DispatcherResourceManagerComponent if Dispatcher completes shutDownFuture in MiniCluster,5
[hotfix] Rework ZooKeeperLeaderElectionITCase to not rely on DispatcherResourceManagerComponent internals,1
[hotfix] Remove unused methods from MiniCluster,5
[hotfix] Improve logging in DispatcherResourceManagerComponent,2
[FLINK-11665] Add DispatcherRunnerImplTest for FLINK-11665,2
[FLINK-11843] Add test case for FLINK-11843DispatcherRunnerImplTest#testJobRecoveryUnderLeaderChange fails onlyoccasionally.,0
[FLINK-11843] Add DispatcherRunnerImplNG with DispatcherLeaderProcess abstraction,1
[FLINK-11843] Add DispatcherLeaderProcessImpl,1
[FLINK-11843] Add DispatcherRunnerImplNGFactory implementation,1
[FLINK-11843] Allow to pass JobGraphStore into Dispatcher via DispatcherServicesThis commit introduces DispatcherFactoryServices which is an extension ofPartialDispatcherFactoryServices. The extension allows to set a specificJobGraphStore which is being forwarded via the DispatcherServices to theDispatcher.,1
[FLINK-11843] Remove JobGraphListener from Dispatcher,4
[FLINK-11843] Allow passing collection of recovered jobs to Dispatcher,4
[FLINK-11843] Remove job recovery from Dispatcher,4
[FLINK-11843] Restrict Dispatcher to only use JobGraphWriter instead of JobGraphStore,1
[FLINK-11843] Make Dispatcher a PermanentlyFencedRpcEndpoint,1
[FLINK-11843] Enable DispatcherRunnerImplNG,1
[FLINK-11665] Port ZooKeeperDispatcherRunnerImplTest to use DispatcherRunnerImplNG,1
[FLINK-11843] Enable DispatcherRunnerImplTest for DispatcherRunnerImplNG,1
[FLINK-11843] Port MiniDispatcherTest to not do leader election for the MiniDispatcher,5
[FLINK-11843] Create AbstractDispatcherLeaderProcess,1
[FLINK-11843] Add proper per-job mode support for DispatcherRunnerImplNG,1
[hotfix] Remove explicit JobGraphWriter from Dispatcher constructor,4
[FLINK-11843] Port and remove DispatcherTest[FLINK-11843] Remove DispatcherTest#testLeaderElectionDispatcherTest#testLeaderElection is superseded byDispatcherRunnerImplNGTest#grantLeadership_validLeader_confirmsLeaderSession.[FLINK-11843] Port DispatcherTest#testJobSuspensionWhenDispatcherLosesLeadershipChanged DispatcherTest#testJobSuspensionWhenDispatcherLosesLeadership intoDispatcherRunnerImplNGTest#revokeLeadership_withExistingLeader_stopsLeaderProcess tocover test logic of #testJobSuspensionWhenDispatcherLosesLeadership.[FLINK-11843] Port DispatcherTest#testFatalErrorAfterJobRecoveryFailurePort DipsatcherTest#testFatalErrorAfterJobRecoveryFailure toDispatcherLeaderProcessImplTest#recoverJobs_withRecoveryFailure_failsFatally[FLINK-11843] Port DispatcherTest#testFatalErrorAfterJobIdRecoveryFailurePort DispatcherTest#testFatalErrorAfterJobIdRecoveryFailure toDispatcherLeaderProcessImplTest#recoverJobs_withRecoveryFailure_failsFatally.[FLINK-11843] Port DispatcherTest#testJobSubmissionErrorAfterJobRecoveryPort DispatcherTest#testJobSubmissionErrorAfterJobRecovery to[FLINK-11843] Port DispatcherTest#testJobRecoveryReplace DispatcherTest#testJobRecovery withDispatcherRunnerImplNGITCase#leaderChange_afterJobSubmission_recoversSubmittedJob.[FLINK-11843] Clean up DispatcherTest,3
[FLINK-11843] Port DispatcherResourceCleanupTestPorts the DispatcherResourceCleanupTest to work with the new Dispatcher contract,1
[hotfix] Pass in DispatcherServices into TestingDispatcher,3
[FLINK-11843] Pass in explicit JobGraphWriter in DispatcherTests,3
"[FLINK-11843] Port and remove ZooKeeperHADispatcherTest#testStandbyDispatcherJobExecutionZooKeeperHADispatcherTest#testStandbyDispatcherJobExecution has been replaced withDispatcherLeaderProcessImplTest#onAddedJobGraph_ifNotRunning_isBeingIgnored[FLINK-11843] Remove ZooKeeperHADispatcherTest#testJobGraphReleaseZooKeeperHADispatcherTest#testJobGraphRelease is already covered byDispatcherLeaderProcessImplTest#closeAsync_stopsJobGraphStoreAndDispatcher.[FLINK-11843] Delete ZooKeeperHADispatcherTest#testStandbyDispatcherJobRecoveryDelete ZooKeeperHADispatcherTest#testStandbyDispatcherJobRecovery because it should no longeradd test coverage. The test is superseded byDispatcherLeaderProcessImplTest#start_triggersJobGraphRecoveryAndDispatcherServiceCreation,DispatcherRunnerImplNGTest#grantLeadership_validLeader_confirmsLeaderSession andDispatcherTest#testPersistedJobGraphWhenDispatcherIsShutDown",3
[FLINK-11843] Port and remove DispatcherHATestRemove DispatcherTest#testFailingRecoveryIsFatalErrorDispatcherHATest#testFailingRecoveryIsFatalError has been superseded byDispatcherLeaderProcessImplTest#recoverJobs_withRecoveryFailure_failsFatally.[FLINK-11843] Port DispatcherHATest#testRevokeLeadershipTerminatesJobManagerRunnersDispatcherHATest#testRevokeLeadershipTerminatesJobManagerRunners has been replaced byDispatcherResourceCleanupTest#testDispatcherTerminationTerminatesRunningJobMasters.[FLINK-11843] Remove DispatcherHATest#testJobRecoveryWhenChangingLeadershipDispatcherHATest#testJobRecoveryWhenChangingLeadership has been replaced withDispatcherRunnerImplNGITCase#leaderChange_afterJobSubmission_recoversSubmittedJob[FLINK-11843] Remove DispatcherHATest#testGrantingRevokingLeadershipDispatcherHATest#testGrantingRevokingLeadership has been replaced withDispatcherLeaderProcessImplTest#closeAsync_duringJobRecovery_preventsDispatcherServiceCreation.[FLINK-11843] Delete DispatcherHATest,3
[FLINK-11843] Ignore duplicate job submission due to false positive onAddedJobGraph callbacks,1
"[FLINK-11843] Properly remove job graphs which have been removed from the JobGraphStoreInstead of cancelling job graphs, which have been removed from the JobGraphStore, this commitsimply stops and removes jobs. This has the advantage that the job does not go into a globallyterminal state.",4
[FLINK-11843] Forward shut down future from Dispatcher through to the DispatcherRunnerImplNG,1
[FLINK-11843] Move DispatcherService into AbstractDispatcherLeaderProcess,4
[FLINK-11843] Remove old DispatcherRunnerImpl and DispatcherRunnerFactoryImpl,1
[FLINK-11843] Rename DispatcherRunnerImplNG into DefaultDispatcherRunnerRename XImplNG implementations into DefaultX. Rename DispatcherLeaderProcessImpl intoSessionDispatcherLeaderProcess.,1
[FLINK-11843] Move DispatcherRunnerImplTest#testJobRecoveryUnderLeaderChange to DefaultDispatcherRunnerITCaseThe DispatcherRunnerImplTest#testJobRecoveryUnderLeaderChange has been moved to theDefaultDispatcherRunnerITCase#leaderChange_withBlockingJobManagerTermination_doesNotAffectNewLeader.,4
[FLINK-11843] Various cleanups for DefaultDispatcherRunner and tests,3
[FLINK-11843] Introduce DispatcherRunnerLeaderElectionLifecycleManagerThe DispatcherRunnerLeaderElectionLifecycleManager is responsible for stopping theLeaderElectionService.,1
[FLINK-11665] Various ZooKeeperDefaultDispatcherRunnerTest clean ups,4
[FLINK-11843] Remove unused dispatcher runner accessor from DispatcherResourceManagerComponent,1
[FLINK-11843] Remove unnecessary getDispatcherGateway method from DispatcherRunner,1
[FLINK-11843] Rename DispatcherLeaderProcess#getConfirmLeaderSessionFuture into getLeaderAddressFuture,1
[FLINK-11843] Various SessionDispatcherLeaderProcessTest clean ups,4
[hotfix] Remove Nonnull annotations from DispatcherFactory and sub classes,4
[FLINK-11843] Rename DispatcherService into DispatcherGatewayServiceThis closes #9832.,2
[hotfix] Remove exception suppression from Dispatcher#stopDispatcherServices,4
[hotfix][core] Introduce IterableUtilsIt supports a neater way to convert an Iterable to a Stream.,1
[FLINK-14450][runtime] Refactor SchedulingTopology to extend base topology[FLINK-14450][runtime] Refactor SchedulingTopology to extend base topology (for review - Part2: implementations)[FLINK-14450][runtime] Refactor SchedulingTopology to extend base topology (for review - Part3: usages)This closes #9936.,2
[hotfix][runtime] Remove FailoverVertex#getExecutionVertexName which is not necessary.This is to simplify the topology interface.,2
[FLINK-14451][runtime] Refactor FailoverTopology to extend base topology[FLINK-14451][runtime] Refactor FailoverTopology to extend base topology (for review - Part2: implementations)Also drops DefaultFailoverTopology and uses ExecutionGraphToSchedulingTopologyAdapter instead[FLINK-14451][runtime] Refactor FailoverTopology to extend base topology (for review - Part3: usages)This closes #9948.,2
[hotfix][runtime] Rename ExecutionGraphToSchedulingTopologyAdapter to DefaultExecutionTopologyExecutionGraphToSchedulingTopologyAdapter now is the default implementation of both SchedulingTopology and FailoverTopology.,2
[FLINK-14452][runtime] Keep only one execution topology in schedulerThis closes #9954.,2
[FLINK-14453][runtime] Support building pipelined regions from base topologyThis closes #9967.,2
[hotfix][runtime] Remove FailoverTopology dependency from PartitionReleaseStrategy,2
[FLINK-14518][coordination] Generalize TE->RM heartbeat payloadIntroduce an encapsulating class for the heartbeat payload to simplify future additions to the payload.,1
[hotfix][tests] Fix TestingShuffleMaster usage,3
[FLINK-14475][coordination] Adjust TaskExecutor interface to accept promotions,2
[FLINK-14417][table] Develop CoreModule to provide Flink built-in functionsDevelop CoreModule to provide Flink built-in functions.This closes #9979.,1
[FLINK-14153][ml] Add to BLAS a method that performs DenseMatrix and SparseVector multiplication.This closes #9732.,1
[FLINK-14478][python] Optimize current python test cases to reduce test time.This closes #9991.,3
[hotfix] fix java checkstyle exception,0
[FLINK-14040][travis] Enable NG scheduler testing in per-commit testsThis closes #9783.,3
"[FLINK-14227][docs-zh] Translate ""Checkpointing"" page to ChineseThis closes #9805",1
"[hotfix][runtime] Implement AvailabilityHelper for providing resetAvailable/Unavailble functions for InputGateIn existing abstract InputGate it covers some logics of switching between available and unavailable states, which couldbe extracted as a separate helpful implementation to be reused by other components future.",1
"[FLINK-14396][network] Implement rudimentary non-blocking network outputConsidering the mailbox model and unaligned checkpoints requirements in future, task network output should be non-blocking. In other words, as long as output is available,it should never block for a subsequent/future single record write.In the first version, we only implement the non-blocking output for the most regular case, and do not solve the following cases which still keep the previous behavior.1. Big record which might span multiple buffers2. Flatmap-like operators which might emit multiple records in every process3. Broadcast watermark which might request multiple buffers at a timeThe solution is to provide the RecordWriter#isAvailable method and respective LocalBufferPool#isAvailable for judging the output beforehand. As long as there is at-least oneavailable buffer in LocalBufferPool, the RecordWriter is available for network output in most cases. This PR doesnt include runtime handling of this non-blocking andavailability behavior in StreamInputProcessor.Note: It requires the minimum number of buffers in output LocalBufferPool adjusting to (numberOfSubpartitions + 1) and also adjusting the monitor of backpressure future.",5
[hotfix][tests] Fix the missing class reference in LocalInputChannelTest,3
[FLINK-14415][table-common] ValueLiteralExpression#equals should take array value into account (#9915)This closes #9915,2
"[FLINK-14230][task] Change the endInput call of the downstream operator to after the upstream operator closesThis change fixes the error of propagating ""endInput"" on the chain immediately after the input of the headoperator is finished. Correctly, ""endInput"" of the downstream operator should be invoked only after closingthe upstream operator.",1
"[FLINK-14230][datastream] Remove the BoundedOneInput implementation of AsyncWaitOperator and ContinuousFileReaderOperatorAfter ""endInput"" of the downstream operator on the chain is invoked correctly, we revertthe changes of PR#9298 and PR#9221.",4
"[hotfix][test] Clean up the test code in SourceStreamTaskTest and OneInputStreamTaskTestThese cleanups include removing unnecessary type parameter declarations and redundant suppression, etc.",2
[hotfix] Extract utils of CheckpointCoordinatorTest into a separate utils class and correct codestyle,3
[hotfix] Split too large file CheckpointCoordinatorTest.java into several small files,2
[hotfix] Correct code style of CheckpointCoordinator,0
[FLINK-13904][checkpointing] Make trigger thread of CheckpointCoordinator single-threaded,1
[FLINK-13904][tests] Support checkpoint consumer of SimpleAckingTaskManagerGateway,1
[FLINK-13904][checkpointing] Avoid competition between savepoint and periodic checkpoint triggering,2
[FLINK-13904][checkpointing] Remove trigger lock of CheckpointCoordinatorNow the checkpoint and savepoint triggering are executed in the one thread without any competition.So the triggerLock is no longer needed.,4
[FLINK-13904][checkpointing] Encapsule and optimize the time relevant operation of CheckpointCoordinator,2
[FLINK-14370][kafka][test-stability] Fix the cascading test failure in KafkaProducerTestBase.,3
[hotfix][kafka][test-stability] Accelerate the KafkaProducerTest by reducing the timeout values.,3
[FLINK-14397][hive] Failed to run Hive UDTF with array argumentsFix the issue that calling Hive UDTF with array arguments causes cast exception.This closes #9927.,1
[FLINK-14134][table-common] Introduce LimitableTableSource for optimizing limit,2
[FLINK-14134][table-planner-blink] Introduce PushLimitIntoTableSourceScanRule to apply LimitableTableSource,2
[FLINK-13513][ml] Add the Mapper and related classes for later algorithm implementations.,1
"[FLINK-14493][core] Introduce data types to ConfigOptions.NOTE: Starting from this commit getters in Configuration throw an exception when parsing of a value failed, instead of returning the default value.",0
[FLINK-14490] Use ObjectIdentifier in TableOperations,1
[FLINK-14490][table-planner] Extract CalciteParser from FlinkPlannerImpl,2
[FLINK-14490][table-api] Introduce UnresolvedIdentifier,0
[FLINK-14490][table-planner] Extract parsing logic from Planner interface,2
[FLINK-14490][table] Introduced temporary tables to CatalogManager,2
[FLINK-14490][table-api] Add createTemporaryView,1
[FLINK-14490][table-api] Add drop temporary tables,4
[FLINK-14490][table-api] Add from method,1
[FLINK-14490][table-api] Rework insertInto method,1
[FLINK-12223][Runtime]HeapMemorySegment.getArray should return null after being freed,2
[hotfix] Fix typos in MemorySegment java docs,2
[FLINK-12289][flink-runtime]Fix typos in Memory manager,2
[FLINK-14318][travis] Compile with a single threadMulti-threaded compilation can deadlock builds with later shade-plugin versions.,2
[FLINK-13756][table] Fix javadoc for findAndCreateTableSource method in TableFactoryUtil class,1
[FLINK-12492][cep] Minor optimize the cep operator by avoiding unnecessary copy,1
[FLINK-12092][docs] Clarify when onTimer(...) in ProcessFunction is called.,1
[FLINK-10435][yarn] Fix client sporadically hangs after Ctrl + CThis closes #10010,0
[FLINK-14061][runtime] Introduce managed memory fractions to StreamConfigThis closes #10024.,5
[FLINK-14526][hive] Support Hive version 1.1.0 and 1.1.1To support Hive 1.1.0 and 1.1.1.This closes #9995.,1
[FLINK-14218][table] support precise function reference in FunctionCatalogEnable referencing functions with fully qualified name in FunctionCatalog.This closes #9962.,2
[FLINK-14398][table-planner] Further split input unboxing code into separate methods (#10000),2
[FLINK-11405][rest] Add maxExceptions query parameter,2
"[FLINK-12147][metrics][influxdb] Bump influxdb-java to 2.16Solves issue with sending metrics with infinity values (e.g. from Kafka) which are unsupported by InfluxDB. New driver version silently drops unsupported value types (NaN, -Inf, +Inf).",5
[hotfix][docs] Fix REST label rotation in SSL figure,0
[FLINK-14403][coordination] Remove legacy NotifyCheckpointComplete and TriggerCheckpoint,4
[FLINK-14535][table-planner-blink] Fix cast exception when count distinct on decimal fieldsThe conversion class of DecimalType of distinct key should be Decimal instead of BigDecimal.This closes #10001,0
[FLINK-13869][table-planner-blink][hive] Fix Hive functions can not work in blink planner streaming mode (#10013),2
[FLINK-14253][table-planner-blink] Add hash distribution and sort grouping only when dynamic partition insertThis closes #9796,1
[FLINK-14532][coordination] Rename PartitionTracker,2
[FLINK-14532][coordination] Split PartitionTracker,2
[FLINK-14534][table] FunctionCatalog.getUserDefinedFunctions() should include temp functionsFunctionCatalog.getUserDefinedFunctions() should include temp functions.This closes #9998.,1
[hotfix][runtime] Fix checkstyle violations in ExecutionVertex,0
[hotfix][runtime] Add overloaded method CheckpointCoordinator#restoreLatestCheckpointedState- New method expects a task Set instead of a Map. This is possible because the  Map's key was not used.- Deprecate the old method.,1
[hotfix][tests] Introduce TestMasterHook,3
[FLINK-14389][runtime] Restore task state before restarting tasks in DefaultSchedulerThis closes #9920.,2
[FLINK-12526][runtime] Remove STATE_UPDATER in ExecutionGraphThis closes #10014.,5
[FLINK-14219][table] support ambiguous function referenceSupport ambiguous function reference.This closes #10052.,1
"[FLINK-14547][table-planner-blink] Fix UDF cannot in the join condition in blink planner for Table API.Currently, UDF can not be used in the join condition for Table API in blink planner(SQL is ok).This closes #10016.",2
"[FLINK-14556][python] Correct the package structure of cloudpickleCorrect the package structure of cloud pickle, otherwise ""ImportError: No module named cloudpickle""error will be thrown when running in a standalone cluster.This closes #10046.",1
[FLINK-14522] Introduce JavaGcCleanerWrapper to find Java GC Cleaner depending on JVM version,4
[FLINK-14302] [kafka] FlinkKafkaInternalProducer should not send `ADD_PARTITIONS_TO_TXN` request if `newPartitionsInTransaction` is empty when enable EoS,0
[FLINK-14059][core] Introduce option allVerticesInSameSlotSharingGroupByDefault in ExecutionConfig,5
[FLINK-14059][table] Blink batch executor disables allVerticesInSameSlotSharingGroupByDefaultSo that each logical pipelined region can be in a different slot sharing group by default.,2
[FLINK-14476] Extend PartitionTracker to support promotions,1
[hotfix] Remove unused TaskManagerConfiguration in TaskExecutorTest,3
[FLINK-14557][python] Clean up the py4j package by removing the unused directory __MACOSX.This closes #10047.,1
"[FLINK-14561] Don't write FLINK_PLUGINS_DIR env variable to ConfigurationThis commit reads the FLINK_PLUGINS_DIR env variable directly instead of firstwriting it first to the Flink Configuration and then reading it from there. Thishas the advantage that the plugins env variable which is intended for the localprocess only is not being leaked to other processes. The latter can happen ifwe start a new Flink process based on the read Flink Configuration (e.g. Yarn,Mesos TaskExecutor).This closes #10037.",5
[hotfix] Fix checkstyle violations in FlinkDistributionOverlayTest,3
[hotfix] Fix checkstyle violations in FlinkDistributionOverlay,2
[hotfix] Introduce ContainerSpecification#createDynamicProperty,5
[hotfix] Fix checkstyle violations in ContainerSpecification,0
[hotfix] Rename and move MesosEntrypointUtils to o.a.f.mesos.util.MesosUtils,1
[hotfix] Rename ContainerSpecification#dynamicConfiguration to flinkConfiguration,5
[hotfix] Remove clone method from ContainerSpecification,4
[hotfix][mesos] Remove dynamicProperties from ContainerSpecificationThe dynamic properties are already contained in the Flink configuration.,5
[FLINK-14074][mesos] Forward configuration to Mesos TaskExecutorThis commit forwards the Flink configuration to a Mesos TaskExecutor bycreating the ContainerSpecification with it. This will forward all optionswhich are dynamically configured until the ResourceManager has been startedto the Mesos TaskExecutor.This closes #10002.,5
[hotfix][mesos] Add more logging information to LaunchableMesosWorker,1
[FLINK-14558][python] Fix ClassNotFoundException of PythonScalarFunctionOperatorLoad the jar of flink-python with user classloader instead of the system classloader.This closes #10045.,5
"[FLINK-14544][runtime] Fixing race condition during task cancellationwhen closing mailbox / enqueuing poison letter.The race condition occurred because StreamTask#cancel will stopTaskMailboxProcessor#runMainLoop by sending a poison letter. That loop,however, can also be left by receiving EOI from upstream tasks, suchthat the normal cleanup in StreamTask#invoke will close themailbox(processor). Sending a (poison) letter with a closed mailbox willtrigger an MailboxStateException, which acts as a safety net and reportsillegal mailbox accesses in respect to its state.To avoid the situation, the enqueuing of the poison letter is more nowrobust. It checks for the mailbox being in the correct state (OPEN) orelse will not enqueue the poison letter, which would not have an effectanyways as the mailbox loop has already been terminated.Since the check and the enqueuing of the letter are non-atomic, another(much more unlikely) race condition would have been introduced. Hence,there is now a convenience method to TaskMailbox to run code under theinternal lock, such that MailboxProcessor can atomically check ifmailbox is still open and enqueuing poison letter.",1
[FLINK-14439][runtime] Enable RestartPipelinedRegionStrategy to leverage JM tracked partition availabilityThis enables better failover experience when using the DefaultSchedulerThis closes #10043.,1
[FLINK-14440][tests] Annotate BatchFineGrainedRecoveryITCase to enable scheduler NG testing for itThis closes #10044.,3
[FLINK-14502] Change CustomCommandLine cluster client methods to get a configuration,5
[FLINK-14501] Change the log config file discovery,2
[FLINK-14501] Add the DeploymentOptions.TARGET,1
[FLINK-14501] Add the ClusterClientFactory and make it discoverable,1
[FLINK-14501] Add Standalone and Yarn ClusterClientFactories,1
[FLINK-14501] Wired ClusterClientFactories to production code,2
[hotfix] Do not expose Yarn dynamic options,0
[FLINK-14501] Make YarnClusterDescriptor initialization self-contained,5
[FLINK-14377] Parse the ProgramOptions to a Configuration.,5
[hotfix] Rename T to ClusterID in CliFrontend and ExecutionContext,0
[FLINK-14502] Use the newly introduced list ConfigOption wherever possible.,5
[FLINK-14154][ml] Add the class for multivariate Gaussian Distribution.This closes #9733.,1
[FLINK-14496][client] Exclude detach flag from ClusterClientThis closes #9972 .,2
[hotfix][docs] Fix paragraph tags,0
[FLINK-14115][docs-zh] Translate DataStream Code Walkthrough into chinese (#9749),5
[FLINK-14322][table-api] Add watermark information in TableSchema (#9994),5
"[FLINK-12939][docs-zh] Translate ""Apache Kafka Connector"" page into ChineseThis closes #9764",1
[hotfix][runtime] Fix code style violations in JobVertexD and IntermediateDataSetID,5
[FLINK-14312][runtime] Introduce LogicalTopology,2
[FLINK-14312][runtime] Introduce LogicalPipelinedRegion,2
[FLINK-14312][runtime] Introduce DefaultLogicalTopologyIt is an adapter of JobGraph to LogicalTopology.With it we can get logical pipelined regions of the underlying JobGraph.This closes #10006.,2
[FLINK-14488][python] Update python table API with temporary tables & views methods,5
[FLINK-14488][python] Update python table API adding from_path method,1
[FLINK-14488][python] Update python table API with insert_into,5
[hotfix][python] Deprecate TableEnvironment.register_table_source and TableEnvironment.register_table_sink,0
[hotfix][python] Clean up test_environment_completeness by removing the legacy excluded methods which are already supported,1
[FLINK-14022][table-planner][table-planner-blink] Add python udf validation check in MatchRecognize,5
"[FLINK-14022][table-planner][table-planner-blink] Introduces SplitPythonConditionFromJoinRule which splits Python Functions from join conditionsCurrently, python udfs can not exist in join condition. In this commit, the SplitPythonConditionFromJoinRule isused to extract python udfs from (inner)join conditions.",4
[FLINK-14022][table-planner][table-planner-blink] Add python udf validation check in join conditionThis closes #9969.,5
"[FLINK-14464] Introduce the AbstractUserClassPathJobGraphRetrieverThis abstract class is for the JobGraphRetriever, which wants touse the user's classpath.",1
[FLINK-14464] Simplify file listing implementationThis closes #9950.,2
[FLINK-14221][table] support drop temp system functions and temp catalog functionsSupport dropping temp functions in FunctionCatalog.This closes #10054.,2
[FLINK-14588][hive] Support Hive version 1.0.0 and 1.0.1To support Hive 1.0.0 and 1.0.1.This closes #10062.,1
[FLINK-14562] Let RabbitMQ source close consumer and channel on closeClosing method of RabbitMQ source must close consumer and channel in order to prevent leaving idle consumerThis closes #10036.,2
[FLINK-14536][core] Sum the cpuCores when merging resource specsThis closes #10072.,2
[FLINK-14549][table-planner-blink] Improve exception message when schema is not matched between query and sinkThis closes #10027,1
"[FLINK-14498][runtime]Introduce NetworkBufferPool#isAvailable() for interacting with LocalBufferPool. (#9993)* [FLINK-14498][network] Introduce NetworkBufferPool#isAvailable() for non-blocking outputIn order to best-effort implement non-blocking output, we need to further improve the interaction between LocalBufferPool and NetworkBufferPool in non-blocking way as a supplementation of FLINK-14396.In detail, we provide the NetworkBufferPool#isAvailable to indicate the global pool state, then we could combine its state via LocalBufferPool#isAvailable method to avoid blocking in global request while task processing.Meanwhile we would refactor the process when LocalBufferPool requests global buffer. If there are no available buffers in NetworkBufferPool, the LocalBufferPool should monitor the global's available future instead of waiting 2 seconds currently in every loop retry. So we can solve the wait delay and cleanup the codes in a unified way.",4
[FLINK-14080][table-planner-blink] Introduce SqlTimestamp as internal representation of TIMESTAMP_WITHOUT_TIME_ZONEThis closes #10035,2
[FLINK-14462][coordination] Remove JobGraph#allowQueuedScheduling flag because it is always trueRewrite testRestartWithSlotSharingAndNotEnoughResources,3
[hotfix] Fix checkstyle violations in SchedulerIsolatedTasksTest,3
[hotfix] Fix checkstyle violation in SchedulerTestBase,3
[hotfix] Enable SchedulerTestBase to use different ComponentMainThreadExecutorsThe SchedulerTestBase has now an abstract supplier method for the ComponentMainThreadExecutor.That way subclasses can control which ComponentMainThreadExecutor is being used.,1
[FLINK-14462] Enable ScheduleIsolatedTasksTest#testScheduleWithDyingInstancesUse the ComponentMainThreadExecutorServiceAdapter.forSingleThreadExecutor to run the testin order to support timeout values.This closes #10048.,1
[FLINK-14372][tests] Add category AlsoRunWithSchedulerNG to KeyedStateCheckpointingITCaseThis closes #10065.,1
[FLINK-12527][runtime] Remove GLOBAL_VERSION_UPDATER in ExecutionGraphThis closes #10058.,5
[FLINK-14583][runtime] Remove progressLock from ExecutionGraphThis closes #10063.,4
[FLINK-14578][table] load/unloadModule() should throw RuntimeException rather than checked exceptionTo adhere to FLIP to make load/unloadModule() API throw RuntimeException rather than checked exceptions.This closes #10053.,1
[hotfix][tests] Refactor SchedulerTestBase for removing dead codeThis closes #10077 .,4
[hotfix][runtime] Remove StreamGraphGenerator#isSlotSharingEnabledThe field has been superseded by ExecutionConfig#allVerticesInSameSlotSharingGroupByDefault.This field was always true. So the removal does not affect anything in production.,4
[hotifx] Remove unused constructor of StreamingJobGraphGenerator,1
"[hotfix][table, tests] Increase slot count in blink batch tests to avoid resource deadlocks if a job has multiple logical regionsThis is needed before FLINK-13708 is fixed.Cases having too many queries are split as well.",0
[FLINK-14060] Set vertex slot sharing based on logical pipelined regionsThis closes #10007.,2
[hotfix][runtime] Propagate execution graph execution state update result to JobMasterAlso only perform scheduler internal update if the execution graph executionstate update succeeded.,5
[hotfix][runtime] Invoke sendCancelRpcCall for internally detected failures after notifying it to schedulerAlso fix the issue that sendCancelRpcCall and handlePartitionCleanup may happentwice when it is non-legacy scheduling.,4
[FLINK-14375][runtime] Avoid notifying ineffective state update to schedulerThis closes #10067.,5
[FLINK-14371][tests] Annotate WindowCheckpointingITCase with AlsoRunWithSchedulerNG category,1
[FLINK-14371][tests] Annotate EventTimeWindowCheckpointingITCase with AlsoRunWithSchedulerNG category,1
[FLINK-14371][tests] Enable ClassLoaderITCase to pass with NG schedulerAlso annotate it with AlsoRunWithSchedulerNG category.This closes #10071.,1
[FLINK-14418][hive] Create HiveModule to provide Hive built-in functions- Create HiveModule to provide Hive built-in functions as system functions to Flink- Unify creation of HiveShim and reuse a single HiveShim in the stack to avoid creating new instances repeatedlyThis closes #9988.,1
"[FLINK-14419][table] Add ModuleFactory, ModuleDescriptor, ModuleDescriptorValidator for factory discovery service, and add implementations for CoreModuleAdd ModuleFactory, ModuleDescriptor, ModuleValidator for factory discovery service, and add implementations for CoreModule.This closes #10070.",1
[FLINK-14546][formats] Support map type in JSON formatThis closes #10060,5
"[FLINK-14603][runtime] Notify the potential buffer consumer if the size of LocalBufferPool has been expanded.Currently, when the size of LocalBufferPool is expanded by LocalBufferPool#setNumBuffers and there are segmentsavailable in the global NetworkBufferPool, we may fail to notify the potential buffer consumer which is waitingfor the LocalBufferPool to be available. This commit fixes the problem by completing the previous uncompletedavailable future when the size of LocalBufferPool is expanded.",0
[FLINK-14600][runtime] Change type of field ExecutionGraph#verticesFinished to intThis closes #10080.,5
[FLINK-13894][web] Add TE log link to subtask view,2
"[FLINK-14580][hive] add HiveModuleFactory, HiveModuleDescriptor, and HiveModuleDescriptorValidatoradd HiveModuleFactory, HiveModuleDescriptor, and HiveModuleDescriptorValidator for HiveModule.This closes #10092.",5
[FLINK-13034][state backends] Add isEmpty method for MapStateThis closes #9255,1
[FLINK-13469][state] Ensure resource used by StateMapSnapshot will be released if snapshot failsThis closes #9301,0
[hotfix][tests] Replace mockito-based verification with property verification.,5
[hotfix][tests] Checkstyle and common style cleanups in CopyOnWriteStateMapTest,3
[FLINK-14586][tests] JobMasterBuilder as top-level class,3
[FLINK-14586][tests] Factor out utility createSingleVertexJobGraph(),1
[FLINK-14586][tests] Move JM partition tests into separate class,3
[FLINK-14586][tests] Refactor partition testsRework test setup to be re-usable across tests.,3
[FLINK-14586][coordination] JM issues promote calls on successful job,0
[FLINK-12342][yarn] Remove container requests in order to reduce excess containersThis commit changes the order in which the container requests are removed whenonContainersAllocated is being called. The idea is to remove the container requestsas fast as possible in order to avoid allocating excess containers as described inYARN-1902.This closes #10089.,4
"[FLINK-14589] Redundant slot requests with the same AllocationID leads to inconsistent slot tableWhen a slot request is redundantly made with the same AllocationID to aslot index other than the already allocated one, slot table becomesinconsistent having two slot indices allocated but one AllocationIDassigned to only the latest slot index. This can lead to slot leakage.This patch prevents such redundent slot request from renderinginconsistent slot allocation state by rejecting the request.This closes #10099.",3
[FLINK-14608][formats] Remove java stream from JsonRowDeserializationSchemaThis closes #10107,5
[FLINK-13702][flink-table-planner] Fix NullSerializer & NullAwareMapSerializer snapshotting,0
[FLINK-13702][flink-table-planner] Fix accumulator type of CollectAggFunction,1
[FLINK-13702][flink-table-planner] Fix digest of GenericRelDataType,5
[FLINK-13702][table-planner-blink] Fixed BinaryGeneric & BinaryString materialization,0
[FLINK-14639][metrics][docs] Fix methods signature,0
[hotfix][runtime] Replace all occurrences of letter to mail to unify wording of variables and documentation.,2
[hotfix][runtime] Replace MailboxStateException with IllegalStateException.MailboxStateException adds no information and makes using code throwing it more clunky then necessary. (Handling exception is limited to rethrowing since it indicates a programmatic error).,0
[hotfix][runtime] Added TaskMailbox#drain and using it to implement MailboxProcessor. Also changed return types of TaskMailbox#close to Mail for unification.,4
"[hotfix][runtime] Simplified and tweaked TaskMailboxImpl.In benchmarks, a separate count field or state imposed (small) additional costs.",1
"[FLINK-14304][runtime] Adding batch capabilities to TaskMailbox, movedmailbox thread ownership into mailbox to sharpen the threading model,and simplified hierarchy.A batch is a local copy of mails that avoid task starvation and alsoreduces the amount of synchronization (as batch is thread-local). Whilethe performance improvement is modest (5-10%), it allows a morepredictable interleaving of mails and input.Also clarified threading model in javadoc.",2
[hotfix][runtime/core] Cleaning up MailProcessor and adding utility method to WrappingRuntimeException.,1
[hotfix][runtime] Consolidating javadoc and package structure.,2
[hotfix][runtime] Moving interfaces closely related to mailboxdefault action into MailboxDefaultAction. Renaming DefaultActionContextto MailboxDefaultAction.Controller.,4
"[hotfix][metrics] Define the default time span for MeterView and add a constructor to use itCurrently in production, MeterView is always created with a 60 s time span.Rather than specify that number everywhere, its better to make 60 the defaulttime span value.",1
[hotfix][runtime] Remove the redundant handleGlobalFailure() definition from SchedulerBase,5
[FLINK-14164][runtime] Add a 'numberOfRestarts' metric to exhibit number of restarts,1
[FLINK-14164][runtime] Add docs for 'numberOfRestarts' metricThis closes #10082.,2
[FLINK-14373][tests] Fix ZooKeeperHighAvailabilityITCase to pass with NG schedulerAlso annotate it with category AlsoRunWithSchedulerNG.This closes #10085.,1
[FLINK-12697][state backends] Support on-disk state storage for spill-able heap backend,1
[FLINK-12697][state backends] (follow-up) Minor optimization that avoids extra memory segment wrapping.  - the SkipListKeySerializer offers methods to directly return a MemorySegment instead of a byte[]    to exploit implementations that thus avoid extra wrapping.,2
"[FLINK-12216][runtime] Respect the number of bytes from input parameters in HybridMemorySegmentThis also needs to move the condition for ""isReadOnly"" to keep giving consistent error messagesbetween all MemorySegment implementations.This closes #8194",0
[hotfix][core] Cleanups of compiler and inspection warnings for HybridMemorySegment and tests.,3
[FLINK-14605][hive] Use Hive-1.1.0 as the profile to test against 1.1.xUse Hive-1.1.0 as the profile to test against 1.1.x.This closes #10081.,3
[hotfix] Move TaskManagerSlot to o.a.f.runtime.resourcemanager.slotmanager,1
[hotfix] Introduce TaskManagerSlotInformationTaskManagerSlotInformation is a super interface of the TaskManagerSlot whichgives access to the basic information of a registered TaskManagerSlot.,5
[hotfix] Make SlotManagerImpl#findMatchingRequest and #findMatchingSlot private,1
[hotfix] Extend OptionalConsumer to accept ThrowingRunnable,1
[hotfix] Let SlotManagerImpl#findMatchingSlot return Optional<TaskManagerSlot>,0
"[FLINK-12122] Introduce SlotMatchingStrategy for SlotManagerThe SlotMatchingStrategy encapsulates how the SlotManager finds a matching slotfor a slot request. At the moment, the only implementation AnyMatchingSlotMatchingStrategypicks any matching slot.",2
[FLINK-12122] Add LeastUtilizationSlotMatchingStrategy for spreading slot allocations outThe LeastUtilizationSlotMatchingStrategy picks the matching slots which belongs to aTaskExecutor with the least utilization value. That way the SlotManager will spread outslot allocations across all available/registered TaskExecutors.,1
[FLINK-12122] Introduce ClusterOptions#EVENLY_SPREAD_OUT_SLOTS_STRATEGYAdd config option to enable to evenly spread out slots across all availableTaskExecutors.,0
[hotfix] Replace SlotInfoAndResource helper constructor with static factory method,5
"[FLINK-12122] Calculate TaskExecutorUtilization when listing available slotsWhen listing available slots stored in the SlotPool and the SlotSharingManager, the systemwill now also calculate the utilization of the owning TaskExecutor wrt the job.",5
[FLINK-12122] Add EvenlySpreadOutLocationPreferenceSlotSelectionStrategyThe EvenlySpreadOutLocationPreferenceSlotSelectionStrategy is a special implementation ofthe LocationPreferenceSlotSelectionStrategy which tries to evenly spread out the workloadacross all TaskExecutors by choosing the slot with the least utilization if there is a tiewrt the locality.,1
"[FLINK-12122] Choose SlotSelectionStrategy based on ClusterOptions#EVENLY_SPREAD_OUT_SLOTS_STRATEGYIf ClusterOptions#EVENLY_SPREAD_OUT_SLOTS_STRATEGY is enabled, then Flink will use the evenly spreadout location preference strategy to spread out the workload as much as possible.This closes #9928.",1
[hotfix] Fix checkstyle violations in SlotSharingManagerTest,3
"[FLINK-13969][Checkpointing] Do not allow trigger new checkpoitn after stop the coordinatorCurrently, we just check whether coordinator has been stopped in eager pre-check, if the coordinator stopped after eager pre-checkhas been done, we'll trigger a new checkpoint even if the coordinator has been stopped.In this commit we'll prevent triggering new checkpoint in such case.[hotfix] extract common logic for checkpoint trigger check[hotfix] Get rid of Mockito in testThis closes #10111.",3
[FLINK-14623][table-api] Add computed column information into TableSchemaThis closes #10096,5
[FLINK-14593][client] Port ClusterClient to asynchronous interface versionThis closes #10069 .,2
[FLINK-14262][table] FunctionCatalog should return empty when can not get the catalog from catalog nameThis closes #10039,2
[FLINK-14262][table-planner-blink] Add getCatalogManager to FlinkContextThis closes #10039,2
[FLINK-14262][table-planner-blink] support referencing function with fully/partially qualified names in blinkThis closes #10039,2
"[FLINK-14262][table] FunctionIdentifier shouldn't normalize function name and use un-escaped identifier as toStringThe display name of functions shouldn't be normalized and escaped, otherwise, a lot of planner tests will fail.However, FunctionIdentifier enforce to normalize names when construction. This makes it impossibleto get the original name. The normalization can happen out of FunctionIdentifier.",1
[hotfix][table] Avoid passing CatalogManager to FunctionCatalogOperatorTableThis also changes the parameter of FunctionLookup#lookupFunctionfrom FunctionIdentifier UnresolvedIdentifier. The qualifying happensin FunctionCatalog which holds CatalogManager.,2
[hotfix][table] Fix the comments of Operation,0
[FLINK-14380][ScalaAPI] Passing inferred outputType directly to map and flatMap functionThis closes #9999,1
[FLINK-14481][runtime] Change Flink's port check to 0 to 65535This closes #9992,2
[hotfix] remove unused method in YarnConfigUtils,5
[hotfix] Port the DYNAMIC_PROPERTIES config option to new options API,1
[FLINK-14630] Make the yarn APPLICATION_LOG_CONFIG_FILE an internal option,5
[FLINK-14630] Add test utility to create YarnClusterDescriptor with Logging,2
[FLINK-14630] Create separate util for setting the yarn log config option,5
[hotfix] Make logging flags explicit,2
[hotfix][table-planner-blink] Make sure TableSourceTable.catalogTable is not null,2
[FLINK-14324][table-planner-blink] Convert SqlCreateTable with SqlWatermark to CatalogTable,2
[FLINK-14326][table-planner-blink] Introduce WatermarkGenerator interface to generate watermark from current row,2
[FLINK-14326][table-planner-blink] Support code generate a WatermarkGenerator from RexNode,1
[FLINK-14326][table-planner-blink] Support to generate and apply watermark assigner in translateToPlan,1
[hotfix][table-planner-blink] Move SqlToOperationConverterTest from sqlexec package to operations packageSqlToOperationConverter is in org.apache.flink.table.planner.operations package.,2
[FLINK-14646] Add non-null checks to KeyGroupRangeAssignmentThis closes #10120.,1
[hotfix] Fix checkstyle violations in KeyGroupRangeAssignment,0
[FLINK-14530][coordination] Replace PartitionTable with PartitionTracker,2
[FLINK-15430][coordination] Store IntermediateDatasetID,5
[FLINK-14636][runtime] Enable scheduling for ScheduleMode.LAZY_FROM_SOURCES_WITH_BATCH_SLOT_REQUESTThis enables scheduling of jobs withScheduleMode.LAZY_FROM_SOURCES_WITH_BATCH_SLOT_REQUEST with DefaultScheduler.This closes #10132.,0
[FLINK-14611][runtime] Move allVerticesInSameSlotSharingGroupByDefault setting from ExecutionConfig to StreamGraph,5
[FLINK-14579][sql cli] enable SQL CLI to configure modules via yaml configenable SQL CLI to configure modules via yaml config.This closes #10093.,5
[FLINK-14673][hive] Shouldn't expect HMS client to throw NoSuchObjectException for non-existing functionAlways to check MetaException when getting function with HMS client.This closes #10133.,1
"[FLINK-14465] Let StandaloneJobClusterEntryPoint use the user code class loader[FLINK-14465] The PackageProgram's constructor does not throw excpetionany more when jarFile is null. Introducing this change is because theremay be no jarFile in perjob mode. All jars the user code depends on arein the classpaths.[FLINK-14465] ClassPathJobGraphRetriever creates PackagesProgram with userclass paths.[FLINK-14465] StandaloneJobClusterEntryPoint uses ""FLINK_HOME/usrlib""as the job's class path. The environment variable FLINK_HOME is setat Dockerfile. Link the FLINK_JOB_ARTIFACTS_DIR to the FLINK_HOME/job,which makes the FlinkUserClassloader load the user class in thestandalone perjob mode.This closes #10076.",1
[FLINK-14657] Generalize and move config utils from flink-yarn to flink-core,2
[FLINK-14395] Refactor ES 7 connectors to make them keep consistency with es 6 connectors,1
[hotfix] Update Javadoc in FlinkKafkaProducer.javafix number of options,2
Fixed word typo : environment and refactored load savepoint exception message,4
[hotfix] Rename TimeReaderFunction to TimerReaderFunction,1
[hotfix][JavaDocs] Correct docs in MemoryStateBackend,2
[FLINK-14665][table-planner-blink] Support computed column in blink-plannerThis closes #10123,2
[FLINK-14554] Correct the comment of ExistingSavepoint#readKeyedState to generate java doc,2
[FLINK-14601] [client] CLI documentation for list is missing '-a',2
[hotfix] Fix wrong Java doc comment of BroadcastStateBootstrapFunction.Context,1
[FLINK-14374][runtime] Expose scheduler type constants in SchedulerNGFactoryFactory,2
"[FLINK-14374][runtime,tests] Run RegionFailoverITCase also with DefaultScheduler enabledThis closes #10134.",0
[hotfix][docs] Fix broken table that describes 'numberOfRestarts' metric,0
[hotfix][runtime] Rename metric 'numberOfRestarts' to 'numRestarts',0
[FLINK-14164][runtime] Make metric 'fullRestarts' compatible with NG schedulerThis closes #10150.,1
[FLINK-14660][sql cli] add 'SHOW MODULES' to SQL CLIThis closes #10140.,1
[FLINK-14420][doc] Add documentation for pluggable modulethis closes #10121.,2
[FLINK-14656][table-planner-blink] blink planner should also fetch catalog statistics for permanent table (#10119),2
[FLINK-14468][docs] Update Kubernetes docs- use Deployment from apps/v1 instead of extensions/v1beta1- run as unprivileged user,1
[FLINK-14714][table-runtime-blink] BytesHashMap should not log the whole stack when start spilling (#10156),2
"[FLINK-14693][python] Fix Python tox checks failure on travisPreviously, we use conda to install tox. However, tox 3.14.0 depends on both0.19 and 0.23 of importlib_metadata at the same time and conda will try toinstall both these two versions and it will cause problems occasionlly.In this commit, use pip to install tox to avoid this problem.This closes #10148.",0
[hotfix] Introduce constants MemorySize#ZERO and MemorySize#MAX_VALUE.,0
"[hotfix] Move SimpleSlotContext to test scope.This class is for the legacy code, and there's no usage of this class in production codes.",3
"[hotfix] Fix misusage of UNKNOWN and ANY ResourceProfiles- UNKNOWN should be used for describing:  - A resource requirement (SlotRequest, SlotProfile, ExecutionJobVertex, etc.) that the exact amount of resource needed is not specified.  - Remaining resource of a multi task slot (SlotInfoAndResources) that contains tasks with unknown resource profiles.- UNKNOWN should not be used for describing total resource of a slot / task executor (TaskSlot, SlotOffer, SlotReport, etc.), which should always be specific with FLIP-49.- ANY should be used for describing a set of resource (SlotOffer, SlotReport, TaskSlot, etc.) that is large enough to match any request. It's for testability purpose only. With FLIP-49, task executors / slots should always have specific resource profiles in production.This commit fix misusages of the two constants.",0
[hotfix] Deduplicate setting operator resource / parallelism argument checks.,1
[hotfix] UNKNOWN ResourceSpec should not be numerically compared.,0
[hotfix] Make MemorySize comparable.,1
[FLINK-14405][runtime] Update ResourceSpec to align with FLIP-49 resource types,5
[FLINK-14405][runtime] Update ResourceProfile to align with FLIP-49 resource types,2
"[FLINK-14495][core] Limit ResourceSpec to always specify cpu cores and task heap memory size, unless it UNKNOWN.",2
[hotfix] Remove unused constructors and unnecessary javadocs for ResourceSpec.,2
"[hotfix] Remove unused constructors and unnecessary javadoces, and annotate constructors used only in testing codes as VisibleForTestting for ResourceProfile.",2
[hotfix] Preserve the singleton property for ResourceProfile#ANY.,2
"[FLINK-14344][checkpointing] PendingCheckpoint supports acknowledging master stateMasterState acknowledgements are now independent of task states acknowledgments.This is done as a preparation for asynchronous MasterHooks firing, where we will firstasynchronously fire MasterHooks, wait for their acknowledgements and only then startthe checkpoint.",1
[hotfix] Correct code style of MasterTriggerRestoreHook,1
[FLINK-14344][checkpointing] Emphasize that MasterTriggerRestoreHook#triggerCheckpoint should be non-blocking in java doc,2
"[FLINK-14344][checkpointing] MasterHooks class supports asynchronous triggeringThis commits add supports for asynchronous triggering `MasterHooks`.As for now, they are still being fired synchronously by the `CheckpointCoordinator`.",1
[hotfix] Correct the acknowledging method name of PendingCheckpoint,0
[FLINK-14499][metric] MetricRegistry#getMetricQueryServiceGatewayRpcAddress is NonnullThis closes #10074 .,1
[hotfix][metric] MetricRegistryImpl#LOG is private,2
"[FLINK-14704] Remove unused SynchronousSavepointLatchAfter FLINK-12482, SynchronousSavepointLatch has been useless and should be removed.This closes #10154 .",4
"[FLINK-14486][table-api, docs] Update documentation regarding Temporary ObjectsThis closes #10078",2
[FLINK-14715][hive] HiveModuleTest fails with Hive-3.1.1this closes #10159.,0
[FLINK-14689][table] Add catalog related commands support in sql parser.This closes #10149.,1
[FLINK-14612][runtime] Change Type of Field intermediateResults from ConcurrentHashMap to HashMapThis closes #10102.,4
[FLINK-14602][runtime] Change Type of Field tasks from ConcurrentHashMap to HashMapThis closes #10101.,4
[FLINK-14640][runtime] Change Type of Field currentExecutions from ConcurrentHashMap to HashMapThis closes #10112.,4
"[FLINK-14638][doc] move functions related docs to a new single, unified dir /dev/table/functions",1
[FLINK-14301][doc] add documentation for functions categories and new function resolution ordersthis closes #10110.,1
[hotfix][doc] fix titles in Hive doc,2
[FLINK-14731][table-planner-blink] LogicalWatermarkAssigner should use specified trait set when doing copy (#10167),1
[FLINK-14724][table-planner-blink] Join condition could be simplified in logical phase (#10163),2
[FLINK-12039] Remove ASSIGNED_SLOT_UPDATER in Execution.tryAssignResourceThis closes #10168 .,1
[hotfix][docs] clarify RocksDB thread options applicability per operator/TM,1
[hotfix][docs] clarify that a RocksDB dependency in pom.xml may not be needed,5
[FLINK-14627][tests] Refactor ExecutionGraph creation in tests as TestingExecutionGraphBuilderThis closes #10100 .,3
[FLINK-14706] Remove legacy KvStateMessageThis closes #10172 .,1
[FLINK-14723][table-planner-blink] Add tests for partial qualified UDF calls as computed columns,3
[FLINK-14723][table-planner-blink] Remove result assertion in test CatalogTableITCase#testInsertSinkTableWithUnmatchedFieldsThe test CatalogTableITCase#testInsertSinkTableWithUnmatchedFields shouldn't verify the expected results because the job will fail and will not be executed.,0
[FLINK-14723][table-planner-blink] Java(Scala)DataStreamQueryOperation should remember the registered object pathJava(Scala)DataStreamQueryOperation represent a registered DataStream from `registerDataStream` methodor a unregistered DataStream from `fromDataStream`. However the name under which the DataStreamis registered is missing when converting a Java(Scala)DataStreamQueryOperation to a RelNode.So add a `qualifiedName` member field in it to remember the original name.,1
[FLINK-14723][table-planner-blink] Use ObjectIdentifier in DataStreamQueryOperationsThis closes #10160,5
"[hotfix][docs, config] Exlcude ReadableConfig and WritableConfig from configuration docs generator",2
[FLINK-14494][docs] Add ConfigOption type to the documentation generator,2
[FLINK-14494][docs] Regenerated config options documentation with type information,5
[hotfix] Change the signature of the ConfigUtils.encodeCollectionToConfig(),5
[hotfix] Move addJars() from ClientUtils to JobGraph,1
[hotfix] Refactors PackagedProgram.extractContainedLibraries(),4
[hotfix] CliFrontend.buildProgram() uses only ProgramOptions,1
[FLINK-14745] Add dependencies of job as list of URLs in config,5
[FLINK-14745] Fix setting CoreOptions.DEFAULT_PARALLELISM in ExecutionConfigAccessor,5
[FLINK-14745] Wire the configuration to the ClientUtils.executeProgram,5
[FLINK-14477][coordination] Move shuffle service access into TEPartitionTracker,4
[FLINK-14477][coordination] Implement promotion logic on TaskExecutor,2
[hotfix][runtime] Remove unused import,2
[FLINK-13528][kafka] Disable sql tests failing on Java 11,0
[FLINK-14239] Fix the max watermark in StreamSource may arrive the downstream operator early,1
[hotfix][test] Fix some code styles in StreamSourceOperatorWatermarksTest and StreamSourceOperatorLatencyMetricsTest,3
[FLINK-13729][docs] Update website generation dependenciesThis seems to come with a much nicer code highlighting.This closes #9442,5
"[FLINK-13725][docs] use sassc for faster doc generationJekyll requires sass but can optionally also use a C-based implementationprovided by sassc. Although we do not use sass directly, there may be someindirect use inside jekyll. It doesn't seem to hurt to upgrade here.This closes #9443",1
"[hotfix][docs] Temporarily disable liveserve./build_docs.sh -i previously did not only enable incremental documentationbuilding while serving the docs, it also enabled a 'liveserve' mode thatautomatically reloaded pages in the browser when they changed. This is basedon the 'hawkins' module which is not (yet) compatible with jekyll 4.0 which weneed to (significantly) improve build times.This disables the liveserve mode and remove the hawkins module until a newversion is available.",1
"[FLINK-13726][docs] Build docs with jekyll 4.0.0.pre.beta1This significantly reduces the build times, on my machine from 140s to 47s!This closes #9444",2
"[FLINK-13791][docs] Speed up sidenav by using group_by_includes/sidenav.html parses through pages_by_language over and over againtrying to find children when building the (recursive) side navigation. By doingthis once with a group_by, we can gain considerable savings in building thedocs via `./build_docs.sh` without any change to the generated HTML pages:This closes #9487",4
[FLINK-14642] Add support for copying null values to the TupleSerializer and CaseClassSerializer,1
[FLINK-14758] Add Executor-related interfaces + wire their discovery to environments.,1
"[FLINK-14472][runtime] Implement back-pressure monitor with non-blocking outputsThe previous back pressure monitor relies on detecting task threads that are stuck in LocalBufferPool#requestBufferBuilderBlocking. After the implementation of non-blocking network output in FLINK-14396, the back pressure monitor should be adjusted accordingly.In detail, we reimplement the back pressure monitor based on the availability of output buffers. If there is at-least one available buffer in output's LocalBufferPool, then the task is not back pressured and vice versa. Furthermore this way can also solve the previous invalid monitor case if the buffer is not requested by task thread.This closes #10083",2
[FLINK-14708][runtime] Introduce RestartAllStrategy for NG scheduler,2
[FLINK-14131][runtime] Introduce FailoverStrategyFactoryLoader to load NG failover strategy factories,0
[FLINK-14131][runtime] DefaultSchedulerFactory uses FailoverStrategyFactoryLoader to load failover strategy factory,0
[FLINK-14682][tests] Enable AbstractTaskManagerProcessFailureRecoveryTest to pass with new DefaultSchedulerThis closes #10173.,1
"[FLINK-14680][runtime,tests] Enable KafkaConsumerTestBase#runFailOnNoBrokerTest to pass with DefaultSchedulerThis closes #10136.",4
[FLINK-14728][hive][doc] add reminder for users of potential thread safety issues of hive built-in functionthis closes #10166.,1
[FLINK-14727][hive][doc] update doc of supported Hive versionsthis closes #10165.,1
[FLINK-14687][sql] Add database related ddl support to SQL Parserthis closes #10201.,1
"[FLINK-14710][hive] Decide column nullability according to Hive constraintsWhen getting a Hive table, set column nullability according to Hive NOT NULL constraints.this closes #10157.",1
[hotfix][doc] update links to table functions,1
[FLINK-14759][coordination] Remove unused class TaskManagerCliOptionsThis closes #10186 .,1
[FLINK-14784][table] CsvTableSink miss delimiter when row start with null member.This closes #10199,2
"[FLINK-14382][java] Add MultipleParameterTool to support parsing multiple parameters of args. For example, --multi multiValue1 --multi multiValue2.",2
[FLINK-14382][examples] Adding multiple--inputsupport toWordCount,1
[FLINK-14382][e2e] Add another dummy fs for e2e test. It is same as dummy fs with different schema.,3
[hotfix] Refactor test_yarn_kerberos_docker.sh by moving common functions to common_yarn_docker.sh.,2
[FLINK-14382][e2e] Update e2e tests to support two inputs from two dummy FS.,1
[FLINK-14382][yarn] Fixes the Flink plugin mechanism on yarn cluster by shipping only the plugin directory instead of adding it to the classpath. And add class isolation check in dummy FS.,1
[FLINK-13747] Make Client respect classloading policy,1
[hotfix] Simplify tests in ClassLoaderITCaseThis also makes child-first classloading explicit in the test instead ofrelying on the default.,3
[FLINK-14808] set correct Classloader in the CLI,1
[FLINK-14794][runtime] Fixing KeyedStream#transform to properly relaytype information if invoked with factories.,5
[hotfix][tests] Introduce PartitionDescriptorBuilder,3
[FLINK-14679][shuffle] Store number of partitions in PartitionDescriptor,2
[FLINK-13850] refactor part file configurations into a single methodCloses #9533,5
"Revert ""[FLINK-13850] refactor part file configurations into a single method""This reverts commit 22b2a8856307c310b4c75b32eeed33ba66c0206e.",4
[FLINK-14699][type] Move ClosureCleaner to flink-core,2
[FLINK-14780][runtime] Register restart metrics only when start schedulingDefer registering restart metrics so that we avoid leaking an instance of thescheduler before the object is fully created.This closes #10192.,1
[FLINK-14782][table] CoreModule#getFunctionDefinition should return empty optional when function does not existCoreModule#getFunctionDefinition should return empty optional when function does not exist.this closes #14782.,1
[hotfix][kinesis] Eliminate compliler warnings and apply simple inspection-based automated cleanups,4
[FLINK-14635][e2e tests] Use non-relocated imports for AWS SDK Kinesis classes in tests  - Moving pubsub client testutil to main project's to test jar,3
[FLINK-14663[tests] Support starting individual Job-/TaskManagers,1
[FLINK-11463][tests] Support job submissions,1
[FLINK-11463][tests] Add utilities- FactoryUtils for simplified ServiceLoader access- TestUtils for simplified resource jar access- ParameterProperty for defining parameters- OperatingSystemRestriction to restrict tests to operating systems,5
[FLINK-11463][tests] Always run in a fresh copy of the distribution,1
[hotfix][tests] Remove optional usage,4
[hotfix][tests] Use TestUtils#copyDirectory,3
[FLINK-11465][tests] Add FlinkResource,2
[FLINK-11464][tests] Add DownloadCache,1
[FLINK-11466][tests] Add KafkaResource,1
[FLINK-11468][tests] Setup surefire execution,1
[FLINK-11467][kafka][tests] Port Kafka Streaming E2E test,3
[FLINK-11463][tests] Modify logging- log process output on debug by default- log created processes with their arguments,1
[FLINK-14801][sql-parser] Improve the local variable name in SqlCreateTable#unparser()Modify `withFrame` to `partitionedByFrame` to make the field name more specifically.This closes #10229,1
[docs-sync] Synchronize the latest documentation changes (commits to fdc2555c) into Chinese documents,2
"[hotfix][runtime] Refactor the method of AvailabilityProvider#isAvailableThere are two main changes for this refactor:1. Rename AvailabilityProvider#isAvailable() to AvailabilityProvider#getAvailableFuture() for more suitable with the return type of CompleteFuture.2. Provide default implementations of #isAvailable() and #isApproximatelyAvailable() for AvailabilityProvider based on two considerations:   - Concentrate on the concerns of performance and visibility in these two methods to provide proper usages and implementations.   - Avoid reimplementing these logics in existing/new usages, because it is not easy to handle them properly. And if we want to improve the way of     CompleteFuture in future, it is easy to only focus on these concentrated methods.",1
"[hotfix][network] Make ResultPartitionWriter extend AvailabilityProvider to avoid defining duplicate methodResultPartitionWriter#getAvailableFuture() was already defined by AvailabilityProvider interface, so we can makeResultPartitionWriter extend it to remove this duplicate method.",4
"[FLINK-14553][runtime] Respect non-blocking output in StreamTask#processInputThe non-blocking output was introduced in FLINK-14396 and FLINK-14498 to solve the problem of handling the checkpoint barrier in the case of backpressure.In order to make the whole process through, StreamInputProcessor should be allowed to process input elements if the output is also available.The default core size of LocalBufferPool for ResultPartition should also be increased by 1 in order not to cause stuck problem and impact the performance,and this tiny memory overhead could be ignored in practice.",0
[FLINK-13850] refactor part file configurations into a single methodCloses #10225,5
[hotfix][network] Reduce the synchronisation overhead in CreditBasedSequenceNumberingViewReaderPreviously CreditBasedSequenceNumberingViewReader#isAvailable() was synchronising twice on thelock subpartitionView if there are no credits: first in subpartitionView.isAvailable() andsecond in subpartitionView.nextBufferIsEvent(). The first one `subpartitionView.isAvailable()`check is redundant (always true) if `subpartitionView.nextBufferIsEvent()` is also true soit should be safe to simplify the code.,2
[FLINK-14830][docs-zh] Correct the links in stream_checkpointing.zh.md page (#10233)The links in Chinese version pages should link to Chinese pages.,2
[hotfix] Add shortcuts for getting jvm heap / direct memory size.,1
"[FLINK-14637][core][runtime] Introduce config option for framework off-heap memory.At the moment after FLINK-13982, when we do not account for adhoc direct memory allocations for Flink framework (except network buffers) or done by some libraries used in Flink. In general, we expect this allocations to stay under a certain reasonably low limit but we have to have some margin for them so that JVM direct memory limit is not exactly equal to network buffers and does not fail. We can address it by introducing framework off heap memory config option.",5
[FLINK-14750][configuration] Migrate duration and memory size ConfigOptions in RestartStrategyOptionsThis closes #10216,5
[FLINK-14750][documentation] Regenerated restart strategy documentation,2
[hotfix] Add String type in config docs for taskmanager.memory.framework.off-heap.size,1
[FLINK-14694] [table-planner-blink] Enabled all tests from package o.a.f.table.planner.functions.aggfunctions* enabled tests that were previously not run because they were defined in abstract classes* fixed assertions for BinaryGeneric in those tests,3
[FLINK-14789][table-comon] extends max/min type in ColumnStats from Number to Comparable This closes #10196,2
[hotfix] Add general options to cli options in SQL cli LocalExecutorWithout the general options the SQL cli deployment code does not forwardthe jobmanager/m setting to the execution configuration.,5
"[FLINK-14581][python] Let python UDF execution no longer rely on the flink directory structure to support running python UDFs on yarn.This commit adds pyflink-udf-runner.sh, pyflink.zip, py4j-0.10.8.1-src.zip andcloudpickle-1.2.2-src.zip as resources into flink-python-{VERSION}.jar and extractduring runtime. In this way, we don't need to care about the file path.This closes #10061.",2
"[hotfix][configuration] Add method for creating restart strategy from configurationThis commit adds method fromConfiguration that allows creating an instance of RestartStrategyConfiguration based on configuration parameters.It also adds equals/hashCode methods to org.apache.flink.api.common.time.Time class. The class had no implementation for those methods, but e.g. RestartStrategyConfiguration used it in their equals/hashCode implementation.",1
[FLINK-14786][configuration] Add configure method to ExecutionConfigThis closes #10217,5
[FLINK-14786][documentation] Regenerated documentation for ExecutionOptions & PipelineOptions,2
[FLINK-14806][table-runtime-blink] Add get and set interface for SqlTimestamp to BaseRow and VectorizedColumnBatchThis closes #10212,1
"[FLINK-14466][runtime] Let YarnJobClusterEntrypoint use user code class loaderFileJobGraphRetriever adds the user class path to JobGraph if the user classpathis not empty.The system class path does not include the user jars in yarn perjob mode whenuser set the yarn.per-job-cluster.include-user-jar to ""DISABLED"". The user jarsare loaded by FlinkUserCodeClassLoaders.Check if there is a ship directory, whose name is the same asDEFAULT_FLINK_USR_LIB_DIR. Throw a IllegalArgumentException if there is one whenuserJarInclusion == DISABLED.This closes #10152.",1
[hotfix] Refactor TaskExecutorTest.testTaskSubmission to not use mocking,1
[hotfix] Introduce TaskSlotUtils for tests,3
[hotfix] Refactor out slots creation from the TaskSlotTable constructor,1
"[FLINK-14400] Shrink the scope of MemoryManager from TaskExecutor to slotMemoryManager currently manages the memory bookkeeping for all slots/tasks inside one TaskExecutor.For better abstraction and isolation of slots, we can shrink its scope and make it per slot.The memory limits are fixed now per slot at the moment of slot creation. All operators, sharing the slot,will get their fixed fractional limits.In future, we might make it possible for operators to over-allocate beyond their fraction limitif there is some available free memory in the slot but it should be possible to reclaim the over-allocated memoryat any time if other operator decides to claim its fair share within its limit.",1
[hotfix] Remove unused number of slots in MemoryManager,1
"[hotfix] Remove unnecessary comments about memory size calculation before network initPreviously network and MemoryManager pre-allocated direct memory,so we wanted network to allocated before to make sure it gets the memory.Now MemoryManager does not pre-allocate anything andthere should be no conflicts mmeory-size-wiseotherwise it is a misconfiguration or bug.",0
[hotfix] Remove redundant timerService in TaskExecutorTest,3
[FLINK-14720] Bring down ExecutionVertex#deployToSlot access modifier and mark it with @VisibleForTesting annotation,3
[hotfix][docs] Fix broken links to table functionsthis closes #10244.,1
[FLINK-14842][table] add logging for loaded modules and functionsAdd logging to help users identify loaded modules and functionsthis closes #10241.,1
[FLINK-14711][table] add alter and show function ddlthis closes #10231.,1
[FLINK-14066][python] Support to install pyflink in windowsThis closes #10188.,2
[FLINK-13184][yarn] Use NMClientAsync instead of NMClient to avoid starting TaskExecutor blocking call. The start container requests will be executed in a thread pool of NMClientAsync.,1
[FLINK-13184][yarn] Use dynamic properties instead of uploading taskmanager-conf.yaml to hdfs. This will reduce the time cost of launching a TaskExecutor so that YarnResourceManager could start a large number of TaskExecutors timely.This closes #10143 .,5
"[FLINK-14858][table-planner] Wrong ""if"" statement in SqlToOperationConverterThis closes #10253",0
[FLINK-11935][table-planner][table-planner-blink] Remove DateTimeUtils from legacy planner and blink planner,2
[FLINK-11935][table-planner] Fix cast timestamp/date to string to avoid Gregorian cutover,5
[FLINK-11935][table-planner] Fix unixDateCeil in Flink since CALCITE-3199 is not fixed in avatica-1.15.0,0
[FLINK-11935][table-planner-blink] Fix cast timestamp to string and vice-versa to avoid Gregorian cutover,0
[FLINK-11935][table-planner-blink] Fix unixDateCeil in blink planner since CALCITE-3199 is not fixed in avatica-1.15.0This closes #10208,0
"[FLINK-14716][table-planner-blink] Refactor FlinkRelOptTable and FlinkTable and cooperate computed column with push down rules* Remove FlinkTable, add a new RelOptTable abstract implementation named FlinkPreparingTableBase and make all the Flink specific tables extend it.* Remove FlinkRelOptTable and use the sub-class of FlinkPreparingTableBase* Remove TableSinkTable and TableSourceSinkTable because they are all useless* Merge InlineTable into DataStreamTable because which is the only implementation* Postpone the Flink tables translation from DatabaseCalciteSchema to FlinkCalciteCatalogReader which happens during sql-to-rel conversion* In DatabaseCalciteSchema, introduce a new class named CatalogSchemaTable to bridge the schema table and catalog table* Add a new table named CatalogSourceTable used to translate CatalogSchemaTable to TableSourceTable during last phrase of sql-to-rel conversion* Refactor MetadataTestUtil to use mock FlinkPreparingBaseTable* Add test case for computed column with push down rules.This closes #10224",3
[hotfix][FLINK-14716][table-planner-blink] Fix the order of fields projected into TableSourceThis fixes the failed HiveTableSourceTest#testProjectionPushDown.,3
[hotfix] Fix confusing error message in TableSourceValidationThis closes #10263 .,5
[FLINK-14104][build] Pin jackson version to 2.10.1,2
[FLINK-14618][runtime] Provide the required akka framesize in the oversized message exceptionThis closes #10257,1
[FLINK-14104][build] User projects use shade-plugin 3.1.13.0.0 has problems when dealing with dependencies that make use Java9+ features.,1
[hotfix][runtime] Remove unused compareTo from ResourceProfileThe implementation is basically broken.One should use isMatching instead for resource checking.,1
[hotfix][core] Remove ResourceSpec#isValidIt is not used in production.(those setResources entries are not open to users yet)Its not necessary given that we will guarantee to only create valid ResourceSpecs.,1
[hotfix][core] Strengthen ResourceSpec#lessThanOrEqual param checkingAllow comparison of both UNKNOWN resources.,1
[hotfix][core] Remove ResourceAggregateTypeCurrently only AGGREGATE_TYPE_SUM is valid and used.AGGREGATE_TYPE_MAX is broken (#subtract() not implemented) and not used.,1
[hotfix][core] GPUResource hosts its own name,0
[FLINK-14594][core] Change Resource to use BigDecimal as its value,1
[FLINK-14594][core] Introduce CPUResourceIt will be used to represent cpu cores in ResourceSpec and ResourceProfile.,2
[FLINK-14594][core] Change ResourceSpec to use CPUResource for cpu cores,1
[FLINK-14594][runtime] Change ResourceProfile to use CPUResource for cpu cores,1
[hotfix][docs] fix 'optional' SQL Client function parameters stated as 'optimal',2
[FLINK-13727][docs] update jekyll to the final version 4.0.0,5
"[hotfix][docs] whitespace fixesWith these, Jekyll 4.0.0 renders the exact same HTML pages as 4.0.0.pre.beta1,except for some further improvements in the syntax highlighting.",1
[FLINK-14803][metrics][influx] Support consistency level,1
[hotfix][tests] Fix ResourceProfile instantiation,2
[hotfix][client] PackagedProgram#userCodeClassLoader is final,1
[FLINK-14861][Client/Job Submission] Fix parallelism.default propagation from flink-conf.yaml,5
[hotfix] Merge configuration args in CliFrontend.run() into one,1
[FLINK-14871][cep] Add space,1
[FLINK-14641][docs] Fix description of metric `fullRestarts` (#10128)Pointing out that this metric also includes fine grained restarts in 1.9.2 and later versions.,0
[FLINK-14642][metrics] Deprecate metric `fullRestarts`,2
[FLINK-14822][runtime] Increase number of restarts in StreamingFileSinkProgramThis closes #10267.,2
[FLINK-14826][tests] Increase number of restarts in BucketingSinkTestProgramThis closes #10266.,3
[FLINK-14821][tests] Enable E2E test to pass with new DefaultSchedulerEnable test_queryable_state_restart_tm ('Queryable state (rocksdb) with TMrestart') to pass with new DefaultScheduler.This closes #10226.,1
[FLINK-14433][DataStream] Move generated Jaas conf file from /tmp directory to Job specific directory,2
[FLINK-14362][runtime] Fix DefaultResultPartition to return true result partition stateThe result should be based on the partition state rather than the vertex state.Change possible values in ResultPartitionState enum to CREATED and CONSUMABLE.This closes #10237.,1
[hotfix][runtime] Log errors that happen in DefaultScheduler deployment,0
[hotfix][runtime] Fix code style violations in JobVertex,0
[hotfix][runtime] Fix code style violations in SlotSharingGroup and VertexSlotSharingTest,5
"[hotfix][runtime] Remove useless constructor of SlotSharingGroupWhen a vertex is assigned with a slot sharing group, the vertexId will be added to this group automatically.So the constructor with sharedVertices params does not make any sense and is causing confusions.",5
[FLINK-14734][runtime] Add a ResourceSpec in slot sharing group to describe the resources it needs overallIts updated automatically when vertices are added into or removed from the group.,4
[FLINK-14859][runtime] Avoid leaking unassigned slots when deployment is outdatedThis closes #10255.,5
[FLINK-14841][table] add create and drop function ddl in SQL parserthis closes #10240.,1
[FLINK-14735][scheduler] Improve scheduling of all-to-all partitions with ALL input constraint for new schedulerThis avoids the quadratic complexity in the legacy scheduler when checking the availability of the input oncethe successor task becomes ready for scheduling.,1
[FLINK-14862][runtime] Fuse initializeState and open in StreamTaskThis commit fuses the two separate passes - one for initializeState andone for open into a single initalizeStateAndOpen pass. This allowsoperators chained together to emit down stream already on initalizeState.,5
[hotfix][runtime] Check managed memory fraction range when setting it into StreamConfig,5
[FLINK-14062][runtime] Calculate managed memory fraction based on slot sharing groups,2
[FLINK-14746][web] Handle uncaught exceptions in HistoryServerArchiveFetcher.,0
[hotfix] Fix parallelism consolidation logic in the (Stream)ExecutionEnvironment.,2
[hotfix] Ignore empty yarn DYNAMIC_PROPERTIES when creating configuration,5
[hotfix] Make the DefaultExecutorServiceLoader a singleton,1
[hotfix] Annotate all the Executor-related interfaces as @Internal,0
[hotfix] Annotate all ClusterClientFactories as @Internal,0
[hotfix] Make ClusterClientFactory.isCompatibleWith case-insensitive,1
[hotfix] Simplify ContextEnvironment construction to use configuration,5
[FLINK-14850] Update the Executor interface and introduce minimal JobClient,5
[hotfix] Rename configuration param in constructor of (Stream)ExecutionEnv,2
[FLINK-14851] Add the Yarn/Standalone Executors and make ContextEnvironments use them,1
[FLINK-14851] Remove redundant CliFrontend.runProgram() method,1
[FLINK-14851] Re-enabled the -sae flag.,0
[FLINK-14851] Remove getJobSubmissionResult from JobClient,1
[hotfix] Remove @nonnull annotatation from all the Executor-related interfaces,4
[hotfix] Rename JobClientImpl to ClusterClientJobClientAdapter,0
[hotfix][runtime] Do state check before input check in LAZY_FROM_SOURCES scheduling for better performanceState check is much more lightweight than the input check.,1
[FLINK-14811][runtime] Replace Java Streams in input checking with for-loopsThis is performance critical code and we should avoid use Java Streams,1
[FLINK-14747][runtime] Reintroducing volatile flag in TaskMailboxImpl to    avoid locks in case of empty mail queue.,2
[hotfix][runtime] MockStreamTask gracefully stops mailbox processor.MockStreamTask cannot call close on mailbox processor as we cannotassume that #cleanup is called from mailbox thread. Using a gracefultermination allows the stream task and any using test harness to beclosed from another thread for failure simulation.,0
"[hotfix][runtime] Smaller cleanup of Mailbox and ensuring state changingoperation may only occur through the mailbox thread, such that statechecks do not any kind of synchronizations.",4
[hotfix][runtime] Avoid iteration creation inTaskMailboxImpl#tryTakeFromBatch.,1
[hotfix][runtime] Fixing TaskMailboxImpl #take and #tryTake not honoringrequested priority if a batch is open.,1
[FLINK-14735][scheduler] Improve scheduling of all-to-all partitions with ALL input constraint for legacy schedulerThis closes #10278,1
[hotfix][typo] fix typo in ContaineredTaskManagerParameters,2
Merge pull request #9989 from wangxlong/hotifx-annotation-NonWindowLeftRightJoinWithNonEquiPredicates[hotfix][docs] Delete useless annotation in NonWindowLeftRightJoinWithNonEquiPredicates,1
[Flink-14126][test]Disable Xpack.ml for elasticsearch 6.0+ on ARM,3
"[FLINK-14688][table] add show tables syntax support in parsreThe PR is only about parser related changes to support table-related commands and Hooking up with table env will come later. We add such parser support:showTablesStatement:SHOW TABLESdescTableStatement:DESCRIBE [ EXTENDED] [[catalogName.] dataBasesName].tableNamealterTableStatement:ALTER TABLE [[catalogName.] dataBasesName].tableNameRENAME TO newTableNameALTER TABLE [[catalogName.] dataBasesName].tableNameSET ( name=value [, name=value]*)this closes #10209.",5
[FLINK-14866][doc] fix a few broken doc linksthis closes #10273.,2
[FLINK-14788][configuration] Add configure method to CheckpointConfig,5
[FLINK-14788][documentation] Generated documentation for ExecutionCheckpointingOptionsThis closes #10222,2
"[FLINK-13708][table-planner-blink] Transformations should be cleared after execution in blink plannerTransformations should be cleared after execute() otherwise it will be executed multiple times.And tEnv.explain() shouldn't affect the transformation tree, otherwise it will be executed multiple times too.This closes #9433",2
[FLINK-13708][table-planner-blink] Revert changes in fb7beb88 which is a temporary fix,0
[FLINK-14481]Modify the Flink valid socket port check to 0 to 65535. (#10184),2
[FLINK-14481] Unify port range check in couple of missing places,2
[hotfix][configuration] Match enums case insensitively in configuration,5
[hotfix] Fix scaladocs links,2
[FLINK-14787][configuration] Add configure method to StreamExecutionEnvironment,5
"[FLINK-14787][documentation] Generate documentation for ExecutionOptions, PipelineOptions and StreamPipelineOptionsThis closes #10223",2
[FLINK-14722][hadoop] Optimize mapred.HadoopInputSplit to serialize conf only when necessaryThis closes #10170,5
[FLINK-14915][runtime] Remove unnecessary parameter JobGraph from SchedulingStrategyFactory#createInstanceThis closes #10287 .,1
[FLINK-14876]Putting xercesImpl related classes into alwaysParentFirstLoaderPatterns to avoid conflicts,5
[FLINK-14878][table] Add useCatalogOperation and support it both in flink/blink plannerSupport USE CATALOG catalogName through sqlUpdate() method in TableEnvironmentthis closes #10272.,5
[FLINK-14924][connectorsi] Add treat empty field as null option to CsvTableSourceThis closes #10289,1
[FLINK-14931][docs] Regenerated documentation,2
[hotfix][runtime] Adding back the missing blacklisting information when refining SotProfile in allocateCoLocatedMultiTaskSlot,2
"[hotfix][runtime] Fix code style violations in SlotProfile, SchedulerTestBase, PreviousAllocationSlotSelectionStrategyTest and ScheduleWithCoLocationHintTest",3
[hotfix][runtime] Cleanup the SlotProfile constructorsSpreading the usages of SlotProfile constructor directly makes it hard to track the intention of each argument.This hotfix makes the constructor private and forces SlotProfile to be built from the factory methods with clear semantics.@Nonnull annotation for arguments/fields are removed since arguments /fields should be non-null by default. Runtime non-check checking is added instead.,1
"[FLINK-14314][runtime] Introduce physical slot ResourceProfile in SlotProfilephysicalSlotResourceProfile can be used for allocating a physical slot for the task slot. If the task is not in a shared slot, it is the task resource profile. Otherwise it is the slot sharing group resource profile.The existing ResourceProfile in SlotProfile is renamed as taskResourceProfile for logical slot allocation.",2
"[FLINK-14314][runtime] Remove SharedSlotOversubscribedException handlingNow that a physical slot resources should always fulfill all possible children slots allocated in it.Therefore, slot oversubscribing only happens when there is a bug.Hence, there is no need to do partial releasing on oversubscribing or do retrying allocation for unfulfilled children slots.A simple sanity check is kept though.",1
[FLINK-14928][docs] Fix the broken links in documentation (#10292),2
[FLINK-14595][orc] Move flink-orc to flink-formats from flink-connectors (#10277),2
[FLINK-14873][client] Make PackagedProgram#savepointSettings final,1
[hotfix] Make parameter of PackagedProgram#<init> final,5
[hotfix] Extract loadJarFile from PackageProgram#<init>,5
[FLINK-14767] Mark TaskManagerOptions#EXIT_ON_FATAL_AKKA_ERROR with @Deprecated annotation,0
[hotfix] Don't set plan name after creation in SQL cli ExecutionContext,1
[hotfix] Add debug logging in MiniDispatcher,5
[hotfix] Fix checkstyle error in ExecutionContext.java,0
[FLINK-14838] Cleanup the description about container number config option in Scala and python shell doc,2
[FLINK-14874][table-planner-blink] add local aggregation to solve data skew for ROLLUP/CUBEThis closes #10271,5
[FLINK-14506][python][build] Improve the release script for Python API release packageUse python virtual environment to build the python package.This closes #10103.,1
[FLINK-14885][client] YarnClusterDescriptor should not know about detached option* [FLINK-14885][client] YarnClusterDescriptor should not know about detached option* [hotfix] Add back testCorrectSettingOfDetachedMode testing for configuration propagatedThis closes #10276 .,5
[FLINK-14865][python] fix unstable tests PyFlinkBlinkStreamUserDefinedFunctionTests#test_udf_in_join_condition_2This closes #10310.,3
[FLINK-14892][docs] Add documentation for checkpoint directory layout (#10305),2
[hotfix] Correct wrong log level in TaskLocalStateStoreImpl#storeLocalStateThis closes #10321 .,3
[FLINK-14846][doc] Correct the default writerbuffer size documentation of RocksDBCorrect the default write buffer size of RocksDB to '64MB',5
[hotfix][table] Move UnresolvedIdentifier to table-common and update UDT,5
"[FLINK-14903][table] Relax structured types constraintsIn order to allow type extraction of structured types that arenot registered in a catalog, we need to relax the structuredtype concept to ""inline or anonymous structured types"" that arenot identified by an object identifier in a catalog but thefully qualified implementation class.This closes #10307.",2
[FLINK-13995][legal] Properly exclude netty license directory,2
"[FLINK-14904][table] Rename ANY type to RAW typeNote: ""RAW"" is a reserved keyword now.This closes #10308.",2
[hotfix][examples-table] Update registerDataSet to createTemporaryView,1
[hotfix] Add more logging in YARN/docker test scripts,3
[hotfix][core] Make CoreMatchers.containsCause more flexible,1
[FLINK-12996][table-common] Require equals/hashCode for type inference classes,5
[FLINK-12996][table-common] Offer unified exception for type inference classes,5
[FLINK-12996][table-common] Add required input type validators for FLIP-65,5
[FLINK-12996][table-common] Add required type strategies for FLIP-65,1
[FLINK-12996][table-common] Simplify type validators structureThis closes #10312.,5
[FLINK-14817][doc] Fix misleading documentation using method chaining of Configuration (#10323),5
[FLINK-14913][table] refactor CatalogFunction to remove propertiesthis closes #10294.,4
[FLINK-14948][client] Implement shutDownCluster for MiniClusterClientThis closes #10320 .,5
[FLINK-10932][kubernetes] Initialize flink-kubernetes moduleThis closes #9957 .,2
[FLINK-11491][e2e] Add TPC-DS queries to end to end testsThis closes #10239,3
[minor] Fix error logging in common yarn/docker test scriptsWe also now print the list of YARN applications to aid in debugging.,0
[FLINK-14968] Disable flaky yarn_kerberos_docker (custom fs plugin) test,3
"[hotfix][runtime] Fix checkstyle violations in runtime classes which use ResourceProfileIncluding SlotSelectionStrategyTestBase, AvailableSlotsTest, SlotProtocolTest and TaskManagerReleaseInSlotManagerTest.",3
[FLINK-14733][runtime] Introduce a builder for flexible ResourceProfile building,2
"[FLINK-14930][fs][oss] Fix shading prefixThe OSS filesystem only supports OSS credential providers, which use the ""com.aliyun"" relocation and not the hadoop one.",1
[FLINK-14930][fs][oss] Document credential providers,1
[hotfix][coordination] Fix error message,0
[FLINK-11835][tests] Wait until job was recovered before unblocking task,3
[FLINK-14940][travis] Fix error code handling for maven calls,0
[FLINK-14939][e2e] Set distDir property,5
[FLINK-14901] Throw Error in MemoryUtils if there is problem with using system classes over reflection,5
[hotfix] Annotate interfaces in JavaGcCleanerWrapper with @FunctionalInterface,1
[FLINK-14505][tests] Temporarily disable SQL Client end-to-end tests for KafkaThis closes #10334.,3
[FLINK-14969][tests] Refactor CliFrontendRunWithYarnTest reflect to new execution codepath (#10331),1
"[FLINK-14709] Allow outputting elements in user defined close method, executed by chained driver.",1
[FLINK-14709] Remove unused GroupCombineChainedDriver.,1
[FLINK-14709] Dispose resources in ChainedDriver close method instead of closeTask.,1
"[FLINK-14813][metrics] Provide `isBackPressured` Task metricExpose the recently implement mechanism of detecting back pressure in FLINK-14472 as a ""isBackPressured"" metric",2
[FLINK-13634] Add compression format for use with StreamingFileSink,2
[FLINK-13634] Add CompressWriterFactory to documentation,2
[hotfix][tests] Avoid to add vertices to TestingSchedulingTopology when building edges using ProducerConsumerConnectionBuilder,1
"[FLINK-14909][runtime] Respect the scheduled vertex order from scheduling strategiesThis allows the topological ordering in default scheduling strategies to beeffective. And the desired order from other scheduling strategies can also berespected, no matter it's in topological or any other order. The schedulingprocess, including state transition, slot allocation/assignment and tasksdeployment are now conducted in the given order.",2
[FLINK-14909][runtime] Change default scheduling strategies to schedule vertices in topological orderVertices to deploy are orders before invoking #allocateSlotsAndDeploy on them.This would reduce #requestPartitionState RPCs to JobMaster since upstream tasksare more likely to get launched earlier than downstream tasks in this way. Italso makes logs more readable.,2
[FLINK-14909][runtime] Cleanup default scheduling strategiesExtracted possible utils into SchedulingStrategyUtils.This closes #10309.,4
"[FLINK-10377] Support checkpoint overtaking a savepoint in TwoPhaseCommitSinkThe precondition checkState(pendingTransactionIterator.hasNext(), ""checkpoint completed, but no transaction pending""); in TwoPhaseCommitSinkFunction.notifyCheckpointComplete() seems too strict, because checkpoints can overtake checkpoints and will fail the precondition. In this case the commit was already performed by the first notification and subsumes the late checkpoint. I think the check can be removed.This can happen in the following scenario:# savepoint is triggered# checkpoint is triggered# checkpoint completes (but it doesn't subsume the savepoint, because checkpoints subsume only other checkpoints).  # savepoint completes",1
"Revert ""[FLINK-14813][metrics] Provide `isBackPressured` Task metric""This reverts commit 2772cd02ed7fe611b9d04449cefd05d495db6ae0.",5
"[FLINK-14859][runtime] Remove wrong checkStateA slot that is assigned to an execution may be unreleased even if a deploymentis outdated. However, this is safe, because the execution is responsible forreleasing the slot.This closes #10351.",1
[FLINK-14957][yarn] Remove deprecated -yst option,4
[hotfix][docs] Update REST API docs,2
[FLINK-14834][tests] Disable flaky yarn_kerberos_docker (default input) test,3
[hotfix][tests] Expose full heartbeat payload,3
[FLINK-14503][coordination] Simplify method signature,2
[FLINK-14503][coordination] Capture number of partitions,2
[FLINK-14503][coordination] Add partition report to heartbeat,1
[FLINK-14762][client] Handle clients close gracefully,0
[FLINK-14762][client] ClusterClient#submitJob returns CompletableFuture of JobID,2
[FLINK-14762][tests] Introduce TestingJobClient,3
[FLINK-14762][client] Implement JobClient#cancel,2
[FLINK-14762][client] Implement JobClient#stopWithSavepoint,2
[FLINK-14762][client] Implement JobClient#triggerSavepoint,2
[FLINK-14762][client] Implement JobClient#getAccumulators,1
[FLINK-14762][api] Move JobStatus to flink-core,2
[FLINK-14762][client] Implement JobClient#getJobStatusThis closes #10311 .,1
[FLINK-14905][build] Unify Java8/11 packaging process,2
"[FLINK-14974][runtime] Calculate managed memory fractions with BigDecimalThis is necessary otherwise fractions can be summed up to be more than 1.0 due to the double precision issue, and the last operator may fail to allocate managed memory it is supposed to be able to acquire. The fraction scale is 16 which is large enough to make little managed memory unusable.",1
[FLINK-14976][cassandra] Release semaphore on all Throwable's in send(),2
[hotfix][table-planner-blink] Fix statistics extraction for temporary tablesA temporary table can be registered in a catalog that does not exist. In the DatabaseCalciteSchema table statistics logic was not accounting for that.,2
[hotfix][table-planner-blink] Safe casting FlinkContext using unwrapinstead of hard cast,1
[FLINK-12905][table-planner] Support CatalogView in legacy planner,2
[FLINK-12905][table-planner-blink] Support CatalogView in blink plannerThis closes #8859,2
[FLINK-14135][table-runtime-blink] Introduce DecimalColumnVector,2
[FLINK-14135][table-planner-blink] Fix source explain in PlanUtil.explainStreamGraph,0
[FLINK-14135][orc] Introduce OrcSplitReader to refactor orc input format,4
[FLINK-14135][orc] Introduce OrcColumnarRowSplitReader to orc,2
[FLINK-14135][hive] Introduce HiveVectorizedOrcSplitReader to hiveThis closes #10022,2
[FLINK-14599][table-planner-blink] Use SqlTimestamp as internal representation of Timestamp type,1
[FLINK-14599][table-planner-blink] Support precision of Timestamp type in blink plannerThis closes #10268,2
[FLINK-14021][table-planner][table-planner-blink] Add rules to push down the Python ScalarFunctions contained in the join condition of Correlate nodeThis closes #10033.,1
[FLINK-14467][mesos] Implement user code classloading in per-job clusterThe MesosJobClusterEntrypoint adds 'usrlib' directory to the containerspecification if the directory exists. Then jars under the directory are loadedby the FlinkUserCodeClassloader.This closes #10256.,2
[hotfix][docs] Remove trailing whitespaces from mesos.md,4
[hotfix][docs] Fix an error in mesos.zh.md,0
[FLINK-10190] Allow AWS_REGION to be supplied along with custom Kinesis endpoint URL for region-specific signingUpdate documentationThis closes #8444,2
"[FLINK-14888][python] Move the Python SqlDialect to module tableThe java SqlDialect class exists in `table.api` module, so it's better to place the pythonSqlDialect into the `pyflink/table` module which is used to place table API classes.This closes #10279.",1
"[FLINK-14967][table] Add a utility for creating data types via reflectionThis implements the data type extractor mentioned in FLIP-65. It is similar toFlink's core type information extractor but also adds a lot of SQL specific featuresand improves the overall user experience. In particular, it allows to annotatetypes, fields, and classes for parameterizing the extraction process. It is unifiedacross Java and Scala.This closes #10342.",4
[FLINK-14891][python] Set the default chaining strategy to ALWAYS for Python operatorsThis closes #10280.,1
[FLINK-14721][hive]HiveTableSource implement LimitableTableSource interfacethis closes #10318.,2
[FLINK-14914][table] refactor CatalogFunction interface and impls to add language fieldthis closes #10327,1
[FLINK-14651][runtime] Enable DefaultScheduler by defaultRun tests against legacy scheduler in separate Travis stagesThis closes #14651.,3
"[FLINK-14672][sql-client] Make Executor stateful in sql clientSimplify the executor backend state for each session: The SessionContext is only used for frontend user to open session, all the backend informations are maintained in ExecutionContext.This closes #10270",5
[FLINK-14254][table-runtime-blink] Introduce FileSystemOutputFormat for batchThis closes #9864,5
[FLINK-14254][hive] Integrate hive table sink with FileSystemOutputFormat,5
[FLINK-14662][table api][hive] Distinguish unknown CatalogTableStatistics and zeroThis closes #10380,2
[FLINK-14800][hive] Introduce parallelism inference for HiveTableSourceThis closes #10210,5
[FLINK-14962] Fix various inefficient use of keySet iterator instead of entrySet iteratorThis closes #10328,1
[hotfix][test] Drop mockito usage in CheckpointBarrierAlignerAlignmentLimitTest,3
[FLINK-14516][network] Remove non credit-based flow control code,2
[FLINK-14516][network] Simplify code after removing non credit-based flow control,2
[hotfix][network] Rename fields in CachedBufferStorage,5
[FLINK-14947] Introduce LocalExecutor and make LocalEnvironment use it,1
[FLINK-14947] Make LocalStreamEnvironment use LocalExecutor,1
[FLINK-14947] Remove unused LocalExecutor that extends PlanExecutor,1
[hotfix] remove unused code in RemoteStreamEnvironment.executeRemotely(),3
[hotfix] Create JarUtils with common jar file tools,2
[hotfix] Decouple ScalaShellRemoteEnvironment from RemoteEnvironment,0
[hotfix] Decouple ScalaShellRemoteStreamEnvironment from RemoteStreamEnvironment,3
[FLINK-14972] Implement RemoteExecutor + make RemoteEnvironment use it,1
[FLINK-15033] Remove unused RemoteStreamEnvironment.executeRemotely() (FLINK-11048),2
[FLINK-14972] Make RemoteStreamEnvironment use RemoteExecutor,1
[hotfix] Inverse comparison order in ExecutorFactory.isCompatibleWith to avoiod NPE,0
[FLINK-14854][client] Add executeAsync() method to execution environments,1
[FLINK-15014][state-processor-api] Refactor KeyedStateInputFormat to support multiple types of user functionsThis closes #10382,1
[hotfix][rocksdb] fix exception message upon failure to create directory,1
[FLINK-14033][yarn] upload user artifacts for yarn job cluster,1
[minor] Change YarnTestCacheJob to verify retrieved property,5
"[hotfix][task,test] Add missing test coverage for pretty mailbox exceptions",3
"[hotfix][task,runtime] Drop unused MailboxExecutor#asExecutor method",1
"[hotfix][task,runtime] Make MailboxProcessor implement Closeable",1
"[FLINK-14935][task,runtime] Use RunnableWithException in the MailboxThis allows mailbox action to throw an exception.",1
[FLINK-14943][Connector/Kafka] Expose callback and related fields to subclasses for override,2
[FLINK-14978][table-api] Introduce constraint class hierarchy required for primary keysThis closes #10340,1
[FLINK-15042][python] Fix python compatibility by excluding executeAsync,0
[hotfix][runtime] Map deprecated config option 'taskmanager.heap.size' and 'taskmanager.heap.mb' to total process memory.,5
"[hotfix][dist] Refactor 'TaskManagerHeapSizeCalculationJavaBashTest', abstract 'JavaBashTestBase' for executing testing bash scripts from java classes.",3
[hotfix][runtime] Remove heading/trailing/duplicated whitespaces from shell command generated by BootstrapTools.This is to eliminate the dependencies on white space counts from 'BootstrapToolsTest#testGetTaskManagerShellCommand'.,3
[hotfix][mesos] Fix missing junit annotation for MesosTaskManagerParametersTest#testForcePullImageTrue.,3
"[hotfix][runtime] Fix backwards compatibility of NettyShuffleEnvironmentOptions#NETWORK_NUM_BUFFERS.The legacy NettyShuffleEnvironmentOptions#NETWORK_NUM_BUFFERS should be used to decide shuffle memory size, when:- NettyShuffleEnvironmentOptions#NETWORK_NUM_BUFFERS is explicitly configured, and- None of TaskManagerOptions#SHUFFLE_MEMORY_MIN/MAX/FRACTION is configured.This was not respected when deriving internal memory sizes from total flink memory size in TaskExecutorResourceUtils.",2
"[hotfix][runtime] If not specified, set Total Flink Memory according to JVM free heap memory for MiniCluster.",5
[hotfix][runtime] Code style clean-up for TaskExecutorResourceUtilsTest,3
[hotfix][runtime] Throw IllegalConfigurationException instead of NumberFormatException for negative memory sizes in TaskExecutorResourceUtils.,5
[hotfix][runtime] Add backwards compatibility for setting task executor memory through environment variable.,1
[hotfix][core][config] Change default value of TaskManagerOptions#MEMORY_OFF_HEAP from false to true.,4
[hotfix][core][config] Change default value of managed memory fraction from 0.5 to 0.4.,4
[hotfix][core][config] Change default framework off-heap memory size from 64m to 128m.,1
[hotfix][core][config] Change default jvm metaspace size from 192m to 128m.,4
[FLINK-13983][runtime] Introduce 'BashJavaUtils' allowing bash scripts to call java codes for generating TM resource dynamic configurations and JVM parameters.,2
[FLINK-13983][runtime][yarn/mesos][dist] Launch task executor with new memory calculation logics    - TM startup scripts calls java code to set flip49 TM resource configs and JVM parameters    - Launches TaskExecutors on Yarn/Mesos with JVM parameters and dynamic configs generated from TaskExecutorResourceSpec    - Use TaskExecutorResourceSpec to calculate memory for ShuffleEnvironment and MemoryManager in TM,1
[FLINK-13986][dist] Remove codes for legacy memory calculations in task executor startup scripts.,4
[FLINK-13986][core][runtime] Remove java codes for legacy memory calculations.,4
[FLINK-13986][core][config] Remove legacy config option TaskManagerOptions#TASK_MANAGER_HEAP_MEMORY.,5
[FLINK-13986][core][config] Remove legacy config option TaskManagerOptions#LEGACY_MANAGED_MEMORY_FRACTION.,5
[FLINK-13986][core][config] Remove legacy config option TaskManagerOptions#LEGACY_MANAGED_MEMORY_SIZE.,5
[FLINK-13986][core][config] Remove unused ConfigConstants#TASK_MANAGER_MEMORY_OFF_HEAP_KEY.,5
[FLINK-13986][core][config] Remove usage of legacy NETWORK_BUFFERS_MEMORY_(MIN|MAX|FRACTION).,1
[FLINK-13986][doc] Update docs for managed memory configuration.,5
[FLINK-13986][core][config] Remove FLIP-49 feature option.,4
[FLINK-14936][runtime] Introduce MemoryManager#computeMemorySize to calculate managed memory size from a fraction,2
[FLINK-15016][build] Remove unused dependencyThis closes #10386 .,1
[FLINK-14691][table] Support create/drop/alter/use database in TableEnvironmentThis closes #10296,5
[hotfix] Fix the comment about dropping database in in-memory catalog,2
[FLINK-13502][table-planner-blink] Move CatalogTableStatisticsConverter & TreeNode to correct packageThis closes #9284,1
[FLINK-15039] Remove default close() implementation from ClusterClient,4
[FLINK-15041] Remove default close() implementation from JobClient,4
[hotfix][javadocs] Fix typo,2
[hotfix][table][docs] Fix link,2
[FLINK-14654][logging] Fix various placeholder issues,0
[FLINK-15025][python][build] Include resource directory in jar,2
[FLINK-14997][state-backends] Avoid unnecessary delete() calls in RocksDBState's mergeNamespaces implementationThis helps to improve the performance after the changed from FLINK-7700.This closes #10383,2
[FLINK-15044][e2e tests] Clean up TpcdsResultComparator  - This simlifies many comparisons  - Factors out and clarifies the extra rules for three queries  - Fixes the issue that a trailing expected line may be ignoredThis closes #10405,0
"[FLINK-15044][e2e tests] Remove trailing error message from TPC-DS query 46 answerThe trailing error message was originally ignored implicitly by a bug in the result validator.Now it needs to be cleaned up, because the validator detects the line now.",5
[hotfix][state-backends] Simple cleanups in RocksDBStateBackend,5
"[FLINK-15047][runtime] Fix format of setting managed memory size in ActiveResourceManagerFactory.This fixes YarnDistributedCacheITCase#testPerJobModeWithDistributedCache.The test case failed because value of dynamic properties in generated task executor starting command contains space, which blocks parsing of the subsequent properties.",1
[hotfix][runtime] Code clean-up in ResourceProfile.,2
[FLINK-15023][runtime] Remove on-heap managed memoryRemove on-heap managed memory from configuration and internal resource describing data structures.,5
[FLINK-14813][metrics] Provide `isBackPressured` Task metric (#10359),1
[FLINK-14910][datastream] Checking for auto generated uids only for PhysicalStreamTransformationsThis closes #10417,5
[FLINK-14960][e2e] Fix failed dependency shading test of table modules,3
[hotfix] wrap root exception when instantiating catalog functionsthis closes #10412.,1
[FLINK-15036][yarn] Container startup error should be handled inside of the YarnResourceManager's main threadThis closes #10407.,0
[hotfix] Correct log statements in YarnResourceManager,2
[hotfix] Let YarnResourceManagerTest run asynchronous tasks in main thread,1
"[FLINK-14663]Distinguish Unknown CatalogColumnStats and other valuesWhen converting from hive stats to Flink's column stats, we didn't check whether some columns stats is really set or just an initial value. This PR we aim to change the CatalogColumnStatisticsDataBase and its subclass's stats from primitive types to corresponding boxed-type.this closes #10394.",5
[FLINK-15051][state-backends] Fix typos in RocksDBStateBackend and RocksDBNativeMetricMonitor methods.This closes #10420,5
[FLINK-13450][table api] Use StrictMath instead of Math for some expressionsThis ensures cross architecture compatibility of results.This closes #9681,1
[FLINK-15034][state-backends] Bump FRocksDB version to support better control over used memory,1
[FLINK-14019][python] Add client API for Python environment and dependency management.,1
[FLINK-14019][python] Add PythonDependencyInfo for Python environment and dependency management.,5
[FLINK-14019][python] Refactor python runners and operators to add PythonEnvironmentManager and ProcessEnvironmentManager for Python environment and dependency management.,1
[FLINK-14019][python] Add necessary changes on shell script and boot.py to support pip installation and changing working directory.,1
[FLINK-14019][python] add ITCases for Python environment and dependency management.This closes #10017.,1
"[FLINK-10935][kubernetes] Add config options and cli options for kubernetes.All the basic and necessary config options has been added. Such as, image name, service account, taskmanager resources, etc.",1
"[FLINK-10935][kubernetes] Add FlinkKubeClient API and basic kubernetes resources.The basic resources for active Kubernetes integration include ConfigMap, Deployment, Service, Pod.",5
[FLINK-10935][kubernetes] Add fabric8 kubeClient implementation and decorators.The Fabric8FlinkKubeClient will be used to interact with Kubernetes API server to create/delete resources and get the status. The decorators will be used to build the complete Kubernetes resource description.This closes #9965 .,1
[FLINK-15060][e2e tests] Add aarch64 support for tpcds e2e test (#10424),3
[hotfix][yarn] Extract some common codes of TaskManagerRunner to public methods and simplify YarnTaskExecutorRunner,1
[FLINK-10968][kubernetes] Implement KubernetesTaskExecutorRunnerThe KubernetesTaskExecutorRunner will parse the dynamic properties and apply to the flink configuration. Then use the updated configuration to start a TaskExecutor.This closes #9985 .,5
[hotfix][yarn] Rename YarnTaskExecutorRunner#run to #runTaskManagerSecurely,1
[FLINK-14890] Add broadcast operators test harnesses,3
[FLINK-14890] Add utility class for initializing various process function test harnesses,3
[FLINK-14890] Add ProcessFunctionTestHarnesses tests,3
[FLINK-14809] Use StreamRecord matchers in ProcessFunctionTestHarnessTest,3
[minor] Move StreamRecordMatchers to util package,4
[minor] Rename StreamRecordMatchers.isStreamRecord() to streamRecord(),5
[FLINK-14781] [docs-zh] correct the state_backends.zh external link and some other things (#10206),2
[hotfix][build] Remove redundant shaded-jackson version,4
[FLINK-14104][build] Upgrade to flink-shaded 9.0,2
[FLINK-14795][tests] Rework TaskExecutorPartitionLifecycleTest,3
[FLINK-14573][python] Support TimeType for Python UDF,1
[FLINK-14573][python] Support TimestampType for Python UDFThis closes #10055.,1
[FLINK-14063][table-planner-blink] Operators use fractions to decide how many managed memory to allocateThis closes #10396,1
[FLINK-15062][formats] Orc reader should use java.sql.Timestamp to read for respecting time zone This closes #10426,1
[hotifx][runtime/task] Split StreamTask.invoke into several smaller methods,1
"[hotfix][runtime/task] remove MailboxExecutor#executeFirst and enqueue MailboxProcessor ""control"" mails directly in itThe only use of MailboxExecutor#executeFirst is in MailboxProcessor to send control messages to itself.These control messages don't require any special handling like synchronization with task state changing actions.",4
[FLINK-12484][runtime/task] introduce StreamTaskActionExecutor (no semantic changes),4
[hotfix][runtime] Allow TaskMailbox to be injected into MailboxProcessor and StreamTask to ease testing,3
[FLINK-12484][runtime/task] synchronize all mailbox actions,2
[hotfix] encapsulate Mail.runnable: do not expose Mail#runnable field,1
[FLINK-14984][web] Remove old WebUI,4
[FLINK-15059][table-common] Update ASM opcode to 7This closes #10439.,5
[hotfix][core] Transformation#setResources validates resources paramsCurrently resources is only validated in DataStream. But table planner may directly set resources to Transformation via Transformation#setResources which is a public interface.We must validate the resources params in Transformation#setResources.,1
[hotfix][runtime] Introduce ZERO ResourceSpec to represent zero amount of resources,0
[hotfix][runtime] Fix issue that iteration tail node has UNKNOWN resources when the head node has specified resources,0
[FLINK-14566][core] Enable to get/set managed memory weight in Transformation,1
[FLINK-14566][runtime] Set Transformation managed memory weight to corresponding StreamNode,1
[FLINK-14566][runtime] Adjust managed memory fraction calculation regarding managed memory weightsThis only applies to vertices with UNKNOWN resources.This closes #10427.,2
[hotfix] Let StreamGraphGeneratorTest extend TestLogger,3
"[FLINK-14590][python] Unify the working directory of Java process and Python process when submitting python jobs via ""flink run -py""This closes #10126.",1
"[FLINK-14965] [table-planner-blink] Correct the logic of convertToTableStats method in CatalogTableStatisticsConverterCorrect the following logic:1. CatalogTableStatistics and CatalogColumnStatistics do not override equals method, and the given parameters may be unknown but is not (CatalogTableStatistics/CatalogColumnStatistics) UNKNOWN instance. equals method should not be used here.2. Should only care about rowCount value of CatalogTableStatistics now3. Even if tableStatistics is null or tableStatistics is CatalogTableStatistics.UNKNOWN, the columnStatistics may be not UNKNOWN. It also needs to be convert to column stats.This closes #10429",2
[FLINK-15026][sql clientSupport create/drop/alter database in sql clientThis closes #10419,5
[FLINK-14692][table] Support rename/alter table in TableEnvironment for both flink/blink plannerThis closes #10410,2
[FLINK-14552][table-planner-blink] Enable partition level statistics in blink plannerThis closes #10315,2
[FLINK-13943][table-planner-blink] Provide utility method to convert table to Java ListThis closes #10306,1
[hotfix][task] Refactor StreamTask#disposed field,4
"[FLINK-14198][python] Add ""type"" and ""rtype"" options to flink python API docstrings of table.py and table_environment.pyThis closes #10389",2
[FLINK-15063][metric]fix input group and output group of the task metric are reversed,2
[FLINK-15045][runtime] Only log RestartStrategy in legacy scheduling mode,2
[hotfix][runtime] Fix typo in static factory method,2
[FLINK-15045][runtime] Log which RestartBackoffTimeStrategy is used for a job,1
[hotfix][runtime] Log start scheduling message on info level,5
[FLINK-14890] Add utility method to extract values from test harnesses and use in ProcessFunctionTestHarnessesTest,3
[FLINK-14857][runtime] Remove remaining checkpoint lock usages from AsyncWaitOperatorAfter 9b3a0b54e2eb2d29805365a3a6c2c9bd9330fd1c every Mail actionacquires checkpoint lock automatically and all state-modifying actionsin AsyncWaitOperator are already executed as mails.,1
[FLINK-14857][runtime/task] deprecate StreamTask.getCheckpointLock method (#10252),1
"[FLINK-15084][runtime] Add shared resources tracking to MemoryManagerThis allows the memory manager to track shared opaque resources form other components, like forexample block caches from RocksDB. The memory manager is responsible for allocating and releasing thoseresources, as well as for assigning the memory budget from of the managed memory budget.This closes #10447",1
[FLINK-14407][yarn] Retry S3 tests on failure,0
[FLINK-15054][docs] Add FAQ section to IntelliJ setup guide,1
[FLINK-13450][table api] Use StrictMath instead of Math for expThis ensures compatibility of results across processor architecturesThis closes #10432,1
[hotfix][rocksdb] Fix description of DefaultConfigurableOptionsFactory,5
"[FLINK-15068][rocksdb] stop writing to RocksDB logs by defaultThis commit changes the default RocksDB configuration for all PredefinedOptionsso that they use log level HEADER_LEVEL and disable periodic statistics dumpsto the LOG file.Please note that there is no need to also changeDefaultConfigurableOptionsFactory since this is only applied after anyPredefinedOptions, and there is always one - at least PredefinedOptions#DEFAULT.The problem with this file is that is will grow indefinitely until it is deletedwhen the job is cancelled/restarted since it lives in RocksDB's local directory.Therefore, it cannot be used for troubleshooting errors. For looking intoperformance, metrics are probably better in the first place.Note: Theoretically, we could even set the log level to NUM_INFO_LOG_LEVELSwhich even removes (most of) the headers, but although that is working, it ispractically an invalid value for the log level and would be a bit hacky.This closes #10437",2
[FLINK-15057][tests] Set JM and TM memory config in flink-conf.yamlThis closes #10422.,5
[FLINK-14847][hive] Support retrieving Hive PK constraintsThis closes #10249,1
"[FLINK-14949][Runtime/Task] Task cancellation can be stuck against out-of-thread error (#10387)This commit added an additional safety net against fatal error thrown from starting task cancellation by notifying the fatal error to taskmanager. Without it, if a fatal or out-of-memory error happens while initiating task cancellation, one or more critical threads that are responsible for cancellation either gracefully or forcefully may not be spawned, thereby job state machine being permanently stuck in a non-terminal state such as FAILING (by stuck task cancellation). The fatal error notification added by this patch can restart JVM cleaning up the state letting job state machine make progress.NOTE: Instead of catching fatal/OOM errors from each thread start, added a catch at a higher level by internalizing cancelOrFailAndCancelInvokable, as it would make sense to notify fatal error no matter where such error comes from during the function. In addition, doing so made unit testing easier by mocking.",3
[hotfix][metrics] Add missing Override annotations,1
"[FLINK-14983][table-common] Add interfaces for input type inferenceThis adds a similar class as Calcite's SqlOperandTypeInference toFlink's type inference. For FLIP-65, we will need to implement thoseinterfaces as the planner needs to infer the DataTypes out of logicaltypes that come from the logical query. This is also beneficial tosupport the NULL literal in the future.This closes #10368.",1
[hotfix][table-planner-blink] Fix the redundant line break in the plan XMLThis copied XmlOutput from Calcite which removes the redundant linefor each CDATA section. This file should be removed once bump toCalcite 1.22.,4
[FLINK-14624][table-blink] Support computed column as rowtime attributeThis also refactor WatermarkAssigner RelNodes to support a RexNode watermarkexpression and extract mini-batch logic from StreamExecWatermarkAssignerinto StreamExecMiniBatchAssigner. This makes mini-batch and watermarkindependent.,5
[FLINK-11524][tests] Print failure cause if job failed,0
"[hotfix][config] Improve error messagesIf the dynamic resource string contains unexpected contents we currently just get an IllegalArgumentException, with no way of actually figuring out what the problem is.",0
[FLINK-15079][tests][config] Run BashJavaUtils after packaging,1
[FLINK-13945][build][docs] Fix instructions for building against custom hadoop versions,0
[FLINK-14512][table] Introduce listPartitionsByFilter to CatalogThis closes #10325,2
[FLINK-15080][fs][oss] Enable deployment,0
[FLINK-15085][hs] Simplify dashboard config generation,5
[FLINK-13862][docs] Update execution plans docs,2
[hotfix][tests] Consolidate the instantiation of the RocksDBKEyesStateBackendBuilder for tests in a utility class.,3
[FLINK-14484][state-backend] Control memory usage of RocksDB via Cache and WriteBufferManagerThis closes #10416,5
[FLINK-14484][state-backend] Some refactorings for the RocksDB memory controlling codeThis closes #10449,5
[FLINK-15113][config] add fs.azure.account.key to list of sensitive configs,5
"[FLINK-14912][Table] register, drop, and alter catalog functions from DDL via catalogthis closes #10450.",2
[FLINK-15106][hive] Hive 3.x tests leave metastore_db folder under build directorythis closes #10463.,5
[hotfix][doc] update docs to replace content of external catalog with new catalog api,2
[FLINK-14959][table-planner-blink] Use SqlTimestamp as internal representation of LocalZonedTimestampType,1
[FLINK-14959][table-planner-blink] Support precision of LocalZonedTimestampType in blink plannerThis closes #10399,2
[FLINK-14584][python] Support ArrayType,1
[FLINK-14584][python] Support MapType,1
[FLINK-14584][python] Support DecimalType,1
[FLINK-14584][python] Fix impletation bug of TinyIntCoder and CharCoderThis closes #10086.,0
"[FLINK-15027][sql client] Support alter table in SQL CLIALTER TABLE [[catalogName.] dataBasesName].tableName RENAME TO newTableNameALTER TABLE [[catalogName.] dataBasesName].tableName SET ( name=value [, name=value]*)This closes #10464",1
[FLINK-15114][sql client] Print execute result info for alter/create/drop database in sql-clientThis closes #10471,5
[FLINK-14026][python] Manage the resource of Python worker properlyThis closes #10453.,1
[FLINK-14019][python][cli] Add commandline options for managing Python UDF environment and dependencies.This closes #10430.,1
"[FLINK-13195][sql client] Add create/drop table support in sql client* Keep state of catalogs when setting/resetting properties in SQL-CLI* In TableEnvironment implementation class, add method to get the CatalogManager;* Reuse the CatalogManager instance of previous table env when setting or resetting properties in SQL-CLI.This closes #10454",1
[FLINK-14845][runtime][table] Move block compression utils from table module to runtime module.,1
[FLINK-14845][runtime] Introduce data compression to reduce disk and network IO of shuffle.,1
[FLINK-15035][table-planner-blink] Use unknown managed memory in blink plannerThis closes #10452,2
[FLINK-15107][sql client] Fix sql cli can not execute statement with lower 'inert into'This closes #10469,0
[FLINK-14645][table-common] Support to parse LegacyTypeInformationTypeThis is required by serializing DataTypes in TableSchema using LogicalTypeParser. The DataType can be a LegacyTypeInformationType which is converted from Types.BIG_DEC to DataType.,5
[FLINK-14645][table] Support to keep nullability and precision when converting DataTypes to properties,5
[FLINK-14645][csv] Support LocalTimestamp/LocalDate/LocalTime for CSV format,5
[FLINK-14645][json] Support LocalTimestamp/LocalDate/LocalTime for JSON format,5
[FLINK-14645][connectors] Support new schema properties for SQL connectors,1
"[FLINK-14645][docs] Update documentation to use ""data-type"" instead of ""type"" to declare a data type",5
"[FLINK-14346] [serialization] faster implementation of StringValue writeString and readString (#10358)This PR implements a set of performance optimizations for String serialization and de-serialization. While running a set of state-heavy streaming jobs, we noticed that Flink spends quite a lot of CPU time (~30-40%) doing String encoding and decoding in two places: while transferring messages between the nodes, and while loading and writing objects into the state store.this PR:Benchmark                                 (lengthStr)   (type)   Mode  Cnt    Score     Error   UnitsStringSerializationBenchmark.stringRead          1024    ascii  thrpt   30  769.067    9.803  ops/msStringSerializationBenchmark.stringRead          1024  chinese  thrpt   30  260.280    0.768  ops/msStringSerializationBenchmark.stringRead         16384    ascii  thrpt   30   53.418    0.589  ops/msStringSerializationBenchmark.stringRead         16384  chinese  thrpt   30   17.313    0.126  ops/msStringSerializationBenchmark.stringWrite         1024    ascii  thrpt   30  771.981  160.013  ops/msStringSerializationBenchmark.stringWrite         1024  chinese  thrpt   30  250.321    0.953  ops/msStringSerializationBenchmark.stringWrite        16384    ascii  thrpt   30   26.593    0.099  ops/msStringSerializationBenchmark.stringWrite        16384  chinese  thrpt   30   13.487    1.534  ops/msmaster:Benchmark                                 (lengthStr)   (type)   Mode  Cnt    Score   Error   UnitsStringSerializationBenchmark.stringRead          1024    ascii  thrpt   30   70.249  0.458  ops/msStringSerializationBenchmark.stringRead          1024  chinese  thrpt   30   24.181  0.094  ops/msStringSerializationBenchmark.stringRead         16384    ascii  thrpt   30    4.382  0.024  ops/msStringSerializationBenchmark.stringRead         16384  chinese  thrpt   30    1.515  0.007  ops/msStringSerializationBenchmark.stringWrite         1024    ascii  thrpt   30  175.745  1.416  ops/msStringSerializationBenchmark.stringWrite         1024  chinese  thrpt   30   45.952  5.209  ops/msStringSerializationBenchmark.stringWrite        16384    ascii  thrpt   30    7.062  0.042  ops/msStringSerializationBenchmark.stringWrite        16384  chinese  thrpt   30    2.527  0.015  ops/ms",0
[hotfix][scala-shell] Minor license refactoring,4
[hotfix] Uniformize Executor names,0
[hotfix] Factor out YarnClusterDescriptor.setClusterEntrypointInfoToConfig() method,5
[hotfix] FlinkILoop: reset ContextEnvFactories also for StreamEnvironments,1
[FLINK-15120] YarnSessionCli.isActive & getApplicationId account conf APPLICATION_ID,5
[FLINK-15118] Make flink-scala-shell use Executors,1
[FLINK-15119] Remove unused Plan/RemoteExecutor,1
[minor] Refactor getJarFiles() out of ScalaShellEnvironments,2
"[hotfix] Remove Mockito from RemoteStreamExecutionEnvironmentTestThis also makes the test actually verify the argument forwarding.Before, the test was ineffectual.",3
"[FLINK-14872][runtime] Temporary fix for potential deadlock problem when tasks read from blocking ResultPartitions. (#10472)This commit implements a temporary fix for the potential deadlock problem reported in FLINK-14872. The problem itself is not solved completely, however the possibility of deadlock is largely reduced. We leave the proper fix of this problem to the future version.",0
[FLINK-11120][table] Fix timestampadd operation not returning correct result.,1
"[FLINK-11120][table] Fix timestampadd on non-zero, negative interaval that cross over day boundary, refine documentation.This closes #8746.",2
[FLINK-14911] [table] register and drop temp catalog functions from DDL to FunctionCatalogthis closes #10478.,2
"[FLINK-8949] Add dedicated watermarks metric retrieval endpoint (#10238)Without this, watermarks for jobs with a parallelism of >= 160 cannot bedisplayed correctly and will result in a ""/bad-request"" error message. Thereason is that the watermark for each subtask will be retrieved in a giantmetrics request like the following (abbreviated):```http://localhost:8081/jobs/32f2205231d280ad105b011198dd9e5f/vertices/8b69eb2c39b9caf941896fdafa7ca05f/metrics?get=0.currentInputWatermark,1.currentInputWatermark,2.currentInputWatermark,3.currentInputWatermark,...,160.currentInputWatermark```We debated raising the maximum header length or lifting the header lengthrestriction. Instead, we opted for a separate metrics endpoint which returns thewatermarks for the entire job vertex:```/jobs/:jobid/vertices/:vertexid/watermarks```",1
[FLINK-14840] Add unit tests for exception behaviour of SQL cli executor,3
"[FLINK-14840] Use Executor interface in SQL cliThis also does not print the cluster ID and web interface URL anymorewhen submitting because there is no portable way of retrieving these.Previously, even for YARN the printed cluster id was not usable becauseit was just the class name of the implementation class.",1
[hotfix][yarn] Move getDynamicProperties from yarn utils to BootstrapToolsThe getDynamicProperties could be reused by KubernetesResourceManager to generate taskmanager start command.,1
[hotfix][yarn] Fix typos in YarnResourceManager,2
"[hotfix][yarn] Add ActiveResourceManager containing some common codesThe common codes in ActiveResourceManager could be reused by other ResourceManager implementation, such as KubernetesResourceManager.",1
[FLINK-9495][kubernetes] Implement ResourceManager for KubernetesThe KubernetesResourceManager will dynamically allocate TaskManager Pods from Kubernetes on demand.,3
[hotfix][runtime] Checkstyle fixes in JobVertex,0
[FLINK-14454][tests] Re-enable SavepointSerializers.setFailWhenLegacyStateDetected after testsThis closes #9944,3
[FLINK-14907] [filesystems] Add EnvironmentVariableKeyProvider for Azure Blob StorageAlso updates the documentation on credential configuration for ABSThis closes #10376,5
[FLINK-14970][table] Remove useless pattern matching case for NaNThis closes #10333,1
"[FLINK-15096][python] Pass python configuration to the python operators instead of global job parameters.Previously, configurations are passed to python operators through GlobalJobParameters. However, GlobalJobParametersis a user only configuration that should not be used to ship system specific settings. In this commit, passes pythonconfigurations to the python operators directly when construct python operators.This closes #10477.",1
[FLINK-10933][kubernetes] Add Kubernetes session cluster entry point,1
[FLINK-15095][table-planner-blink] Bridge table schema's primary key to metadata handler in blink plannerThis closes #10480,2
[FLINK-15020][hive] Support timestamp type in hiveThis closes #10401,1
[hotfix][kubernetes] Let creating Flink master deployment and taskmanager pod respect user defined configBlobServerOptions.PORT and TaskManagerOptions.RPC_PORT need to be respected.,5
[FLINK-9955][kubernetes] Add Kubernetes ClusterDescriptor to support deploying session clusterThis closes #9973 .,1
[FLINK-14993][metrics] Reorganize reporter-scoped information,5
[FLINK-14993][metrics] Store delimiter in reporter settings,1
[hotfix][yarn] Add AbstractClusterClientFactory containing some common implementations,5
[hotfix][yarn] Move some common methods to AbstractCustomCommandLineThe common methods could be reused by Kubernetes custom cli.,1
[FLINK-10936][kubernetes] Implement Kubernetes command line tools to support session clusterThe FlinkKubernetesCustomCli will be added to customCommandLines of CliFrotend.This closes #10245 .,1
[FLINK-10937][dist] Add kubernetes-entry.sh and kubernetes-session.shkubernetes-entry.sh is used for JobManager and TaskManager container entrypoint.kubernetes-session.sh is used for starting session cluster.This closes #10246 .,1
[hotfix] Fix checkstyle violations in CliFrontend.java,0
[minor] Make RestClient logging less noisy,2
"[hotfix] Remove ""shutdown if attached"" option from ""all"" YARN optionsAdding this option here means that the check inisYarnPropertiesFileMode() will mistakenly think that ""shutown ifattached"" is a YARN option and therefore not execute an attached jobwith this option on an existing YARN session.",5
[minor] Add debug statements in Cli frontends,0
[FLINK-15116] Return a ClusterClientProvider from ClusterDescriptor methodsThis allows the consumer of the methods to create a new ClusterClientwith a separate lifecycle whenever necessary.,1
"[FLINK-15116] Make JobClient stateless, remove AutoCloseableWith this change, the JobClient acquires the required ClusterClient foreach method call. This means that the users no longer have the burden ofmanaging the JobClient lifecycle, i.e. they can freely ignore the resultof executeAsync().",1
"[FLINK-15116] Move attached shutdown hook to context environmentThis simplifies the per-job executor and moves the logic to where itactually belongs. The previous solution had some issues that this fixes: - the code that knows how and why we're submitting a job is the context environment because it is used for the Flink CLI - having the code in the one executor made that one more complicated for a CLI feature - the shutdown hook was not available for jobs submitted against an existing session. I think the expected behaviour is that an attached job that is submitted from the CLI shuts down no matter the execution mode.The ""shutdown on attached exit"" parameter now has the semantics: ""canceljob when the CLI shuts down"". For a per-job cluster this has the sameeffect as before: the cluster shuts down. For sesion clusters this hasthe effect that the job is canceled.For this to work we have to change the MiniDispatcher to shut down thecluster when a job is canceled.",5
[FLINK-14264][rest] Expose state backend name,2
"[FLINK-14264][runtime] Reduce surface area to EGThe stateBackendName is only relevant for the REST API, yet is spread out over multiple runtime classes.Until a better place for job meta data has been introduced we should restrain such necessary evils to the ExecutionGraph.",5
"[hotfix][e2e] Cleaning logs before executing single tests.Logs of successful tests are cleaned up automatically. However, logs offailing tests remain to ease debugging. However, if the developer doesnot clean them before executing a new test with exception checks, thenew test will fail independent of the actual result as the old logs willcause the checks to fail.With this fix, failing tests will not cause subsequent tests to failbecause of parsing old logs.",2
[hotfix][e2e] Removing unused s3 methods,1
[FLINK-14574][e2e] Replacing s3Util with dockerized aws cli enablingcustomized endpoints and other features that would needed to be manuallyimplemented.,0
[FLINK-14574][e2e] Providing minio based s3 setup allowing users withoutAWS secrets to test plugins.,3
"[FLINK-14574][core/e2e] Wrap FileSystem to use plugin context classloader.Filesystems loaded through PluginManager are wrapped inPluginFileSystem, which swaps the context classloader for all directmethods. Thus, lazily loaded classes (security, optimizations) areloaded with the expected classloader. In particular,java.util.ServiceLoader will use that context classloader to load newservices.This change will fix the s3-hadoop plugin while writing.Also added minio-based s3 batch tests that write to s3.Modified existing s3 batch tests to also write to s3.Modified existing s3 streaming test to checkpoint onto s3.",3
[hotfix][core] Removing deprecated methods in SafetyNetCloseableRegistry.,1
[FLINK-14906][table] create and drop temp system functions from DDL to FunctionCatalogthis closes #10484.,2
[hotfix][hive] adapt HiveFunctionDefinitionFactory.createFunctionDefinition to latest APPI,3
[FLINK-14898] Enable background cleanup of state with TTL by default,4
[hotfix][core] Introduce divide operation to Resource,0
[hotfix][core] Introduce divide operation to MemorySize,0
[hotfix][core] Introduce TaskExecutorResourceSpecBuilder for building TaskExecutorResourceSpec.,0
[FLINK-14188][runtime][yarn/mesos] Set container cpu cores into TaskExecutorResourceSpec when launching TaskExecutors on Yarn/Mesos.,1
[FLINK-14188][runtime] Derive and register TaskExecutor to ResourceManager with default slot resource profile.,2
[FLINK-14188][runtime] Use default slot resource profile derived from TaskExecutorResourceSpec on both RM and TM sides.,2
[hotfix][runtime] Wrap arguments of ResourceManagerGateway#registerTaskExecutor into TaskExecutorRegistration.,0
[FLINK-14189][runtime] TaskExecutor register to ResourceManager with total resource profile.,2
[FLINK-14189][runtime] Extend TaskExecutor to support dynamic slot allocation,1
[FLINK-14189][runtime] Do not store dynamic slots by index in TaskSlotTable,2
[FLINK-15110][metrics] Support variable exclusion,1
[FLINK-14824][table] Make derivation schema as a default option for CSV source and sink,1
[FLINK-14824][csv][json] Make derivation schema as default option for CSV and JSON formats,5
[FLINK-14824][docs] Improve schema derivation for formats,1
"[FLINK-15109][runtime] Null out restoredTimersSnapshot when it is no longer neededInternalTimerServiceImpl references restored state after use, taking up resources unnecessarily.This PR just nullifies its restoredTimersSnapshot field in startTimerService().",1
"[FLINK-15121] Add public constructors for execution environments that take ConfigurationThis makes useful constructors on ExecutionEnvironment public and addsJavadoc.This makes the useless zero-argument constructor ofStreamExecutionEnvironment protected and adds Javadoc toStreamExecutionEnvironment constructors.This allows creating execution environments with arbitrary executorconfigurations, i.e. one can now create an execution environment thatuses a YARN executor.",1
[FLINK-14513][hive] Implement listPartitionsByFilter to HiveCatalogThis closes #10381,2
[FLINK-14378][state-backends] Cleanup rocksDB lib folder if loading the library failsThis closes #10423,0
[FLINK-15130][core] Deprecate RequiredParameters and OptionThis prepares for removal in a future release.,4
[FLINK-15136][docs] Update the Chinese version of Working with State TTLWe enabled background cleanup of state with TTL by default inFLINK-14898. Here we update the Chinese version of the user documentationaccordingly.,2
[FLINK-14649][kafka][es] Flatten all the connector properties keys to make it easy to configure in DDL (#10468),5
[FLINK-13438][hive] Support date type in HiveThis closes #10494,5
[FLINK-15134][client] Delete temporary files created in YarnClusterDescriptor,1
[hotfix][configuration] Improve Configuration set method for a more fluent api,1
[FLINK-15067][table] Pass configuration to the underlying ExecutionEnvironment,5
[FLINK-15067][table-api] Add utility method to TableConfig that adds a new job parameter,2
Update version to 1.11-SNAPSHOT,5
[FLINK-15127][table] rename function operations to catalog function operationsthis closes #10488.,1
[hotfix] Fix typo in HiveShimV100,2
[FLINK-14953][formats] use table type to build parquet FilterPredicateThis closes #10371,1
[FLINK-15157] Make ScalaShell ensureYarnConfig() and fetchConnectionInfo() public,5
[FLINK-15129] Return JobClient instead of JobClient Future from executeAsync(),2
[FLINK-14992][client] Add job listener to execution environments,1
"[FLINK-14992] Extend test coverage of JobListenerITCaseThis changes the test to use a MiniClusterResource to be more efficient.This adds test coverage for the executeAsync() methods.This verifies that we call the job listeners from the main executionthread, which is important for some frameworks such as Zeppelin support.",1
"[FLINK-15166][runtime] Fix the bug of wrongly recycling uncompressed bufferFor blocking shuffle data compression, the compressed intermediate buffer is recycled after it is written out. However when the data can not be compressed, the returned buffer is the original buffer which should not be recycled.This commit fixes the bug of wrongly recycling uncompressed buffer by comparing the returned buffer with the original buffer.",0
[hotfix][test] Do not hide original exception in the SourceStreamTaskTest,3
"[FLINK-15076][task] Fix SourceStreamTask cancellationSource thread should be interrupted more or less the same way how task thread isbeing interrupted. This is important for example as in the scenario presented in theSourceStreamTaskTest#testCancellationWithSourceBlockedOnLock(). SourceFunction isblocked while holding checkpointLock, which might prevent task thread fromcancelling properly if the SourceFunction is not interrupted.",1
[hotfix][test] Rename and reformat testCancellationFailsWithBlockingLockNew name testCanceleablesCanceledOnCancelTaskError better reflects what the test is doingwhile CancelFailingTask closer to the test case makes reading the test easier.,3
[hotfix][task] Do not wrap Errors from SourceFunctionThread,1
[hotfix] Fix checkstyle violation in AbstractMetricGroup,0
"[FLINK-15093][streaming-java] StreamExecutionEnvironment#getStreamGraph should clear transformations* Add internal interface StreamExecutionEnvironment#getStreamGraph(String, boolean) with the ability to clean existing transformations;* Add tests for this new interface;* Keep StreamExecutionEnvironment#getExecutionPlan semantic unchanged",4
[FLINK-15052][sql-client] Test transformation.clear() in sqlClient* Add ITCase in SQL-CLI LocalExecutorITCase for re-execution of the same statement.,1
[hotfix][kubernetes] Remove per-job related config options,5
"[hotfix][kubernetes] Correct some description of cli optionsCurrently, some cli options descriptions could not show correctly. It is just because KubernetesConfigOptions.CONTAINER_IMAGE.description().toString() is used. The Description#toString() does not represent the real description content.",1
"[hotfix][kubernetes] Separate creating and retrieving flink cluster logsCurrently, when we create a flink cluster on kubernetes, two retrieving logs and one creating log will show up. It is so confusing. The logs of creating and retrieving a flink cluster should be separated.",2
"[FLINK-15153][kubernetes] Service selector needs to contain jobmanager component labelThe jobmanager label needs to be added to service selector. Otherwise, it may select the wrong backend pods(taskmanager).",0
[FLINK-14958][table] ProgramTargetDescriptor#jobID can be of type JobIDThis closes #10505 .,1
[FLINK-14006][python][docs] Add documentation for how to use Java UDFs with Python APIThis closes #10516.,1
[hotfix][doc] update Hive functions page with more info,5
[FLINK-14951][tests] Harden the thread safety of State TTL backend tests,3
[FLINK-15008][build] Bundle javax.activation-api for Java 11,2
[FLINK-15008][legal] Update licensing,5
[FLINK-14926][state-backend-rocksdb] Ensure that RocksObjects are always closed on backend disposalThis also ensures that the newly introduces shared resources (shared cache and write buffers)are properly closed when the RocksDB state backend is disposed.This closes #10300,5
[hotfix][tests] Remove unnecessary temp directory handlingRemove the use of a non-needed temp directory and relies on JUnit tool rather than manual cleanup.,4
[hotfix][tests Use assumptions rather than manual checks in RocksDBStateBackendConfigTest to report skipped tests properly,3
[hotfix][tests] Ensure RocksDB native library is loaded into temp directoryThis moves the loading code from one specific test method into a the initialization phase.That way the extraction happens into the target location also in cases where other test methods execute first.,3
[FLINK-15177][state-backend-rocksdb] Migrate RocksDB Configurable Options to new type safe config optionsThis also simplifies the validation logic.,2
[hotfix][state-backend-rocksdb] Some minor style cleanups in RocksDBResourceContainer  - Make visibility consistent package private (was mix of package private and public)  - remove unused method  - Adjust line spacing between fields  - Add some JavaDocs  - Make final (not designed for inheritance)  - Nullable annotations,1
[FLINK-14926][state-backend-rocksdb] (follow-up) Make RocksDBResourceContainer immutable,5
[FLINK-14926][state-backend-rocksdb] (follow-up) Simplify test to rely on RocksDBResourceContainer for cleanup of native handles,0
[FLINK-14926][state-backend-rocksdb] (follow-up) Avoid exposing handles that will not be closed from RocksDBStateBackendThat means that RocksDBStateBackend should not have accessors to gather created native handles.The native handles should only be created once the Resource Container is created.This implies removing tome test methods from RocksDBStateBackend and changing the tests to test against theRocksDBResourceContainer instead.,5
"[FLINK-14926][state-backend-rocksdb] (follow-up) Simplify collecton the option objects to close  - rather than letting each option factory method add the option to the list itself, add it in one place in the Resource Container.  - assume the list passed to the factory methods is always non-null",4
"[FLINK-14926][state-backend-rocksdb] (follow-up) Replace OptionsFactory for RocksDBOptionsFactoryOptionsFactory was breaking existing implementations by adding a method to the interface without default method.To solve this, we keep OptionsFactory but replace it in the RocksDB State Backend with the RocksDBOptionsFactory which hasthe evolved signature. The OptionsFactory is still accepted and wrapped into a RocksDBOptionsFactory, for compatibility.",5
"[FLINK-15069][benchmark] Supplement the pipelined shuffle compression case for benchmarkWhile reviewing the PR of introducing data compression for persistent storage and network shuffle, we think it is better to also cover this scenario in the benchmark for tracing the performance issues future.This PR would supplement the compression case for pipelined partition shuffle, and the compression cases for blocking partition would be added in FLINK-15070.",2
[FLINK-15199][rocksdb] Make RocksDBResourceContainer public for the benchmarksflink-benchmarks need to access this class in order to use RocksDBKeyedStateBackendBuilder,5
[hotfix][doc] update and remove limitations of Hive connector,4
[hotfix][doc] update Hive doc,2
[FLINK-15203][doc] rephrase Hive's data types docthis closes #10537.,2
[hotfix][doc] update catalog APIsthis closes #10525.,2
[FLINK-13577][ml] Add an util class to build result row and generate result schema.This closes #9355.,1
[FLINK-15061][table]create/alter and table/databases properties should be case sensitive stored in catalogthis closes #10493.,2
[FLINK-14007][python][docs] Add documentation for how to use Java user-defined source/sink in Python APIThis closes #10515.,1
"[FLINK-15073][sql client] Sql client falis to run same query multiple timesAfter we change the SQL-CLI to stateful in FLINK-14672, each query'stemporal table was left out so we can not re-registered the sameobject(from the same query).This closes #10523",2
[hotfix][docs] Add missing endhighlight,1
[FLINK-15185][hive] Shade flink-hadoop-fs to use hive connectors in standalone modeThis closes #10540,1
[FLINK-15195][kubernetes] Remove unused KubernetesConfigOptionsInternal.ENTRY_POINT_CLASS_ARGS,5
"[FLINK-15082] Respect new FLIP-49 taskmanager.memory.total-process.size in Mesos RMUsage of noew option is consistent with the legacy Mesos specific one 'mesos.resourcemanager.tasks.mem':- If taskmanager.memory.total-process.size and mesos.resourcemanager.tasks.mem are both set and differ in their values, an exception should be thrown- If only taskmanager.memory.total-process.size is set and mesos.resourcemanager.tasks.mem is not set, then the value configured by the former should be respected- If only mesos.resourcemanager.tasks.mem is set and taskmanager.memory.total-process.size is not set, then the value configured by the former should be respected",5
[FLINK-15082] Deprecate mesos.resourcemanager.tasks.mem in favour of taskmanager.memory.total-process.sizeThis closes #10513.,2
[FLINK-15139] [table/sql-client] parse dependecy jars in execution config,5
[FLINK-15001] [table-planner-blink] The digest of sub-plan reuse should contain retraction traits for stream physical nodesThis closes #10377.,1
[FLINK-15124][table] Fix types with precision defined in DDL can't be executed,0
[hotfix][table-runtime-blink] Fix the watermark assigner operator should emit max watermark in close,1
[FLINK-15161][table-common] Introduce TypeTransformation interface and basic transformations (#10500),2
[hotfix][build] Fix typo in maven property,5
[FLINK-15163][build] Set japicmp.referenceVersion to 1.9.1This closes #10509.,1
[FLINK-15196][Mesos] Using the mesos.resourcemanager.tasks.cpus to determine the cpus of Mesos worker.This closes #10531.,1
[hotfix][documentation] Generate the respective htmls because of previous configuration changes,4
"[FLINK-14952][network] Solve the issue of exceeding memory limits when using mmap blocking partitionAs reported by users in mail list, the container would be killed by yarn because of exceeding physical memory limits. It is mainly becausethe memory usage of mmap in BoundedBlockingSubpartition is not capped and not accounted by configured memory limits, but yarn would trackthis memory usage and kill the container once exceeding some threshold.To solve this issue, we adjust the default option of ""taskmanager.network.bounded-blocking-subpartition-type"" from `auto` to `file` for safety usage.And users can still enable mmap way via configuration if they make a proper adjustment in yarn configuration to avoid container killing.In order to make this option consistent with existing compression option, we also rename it to ""taskmanager.network.blocking-shuffle.type"".",1
[hotfix][streaming] Fix API incompatibility,0
[hotfix][doc] add missing tag in catalogs.zh.md,2
[FLINK-14941][hbase] Fix the same row appear twice if encountered any HBase exception when scanningThis closes #10314,0
"[FLINK-15140][runtime] Fix that data compression doesn't work with BroadcastRecordWriter for pipelined modeFor pipelined shuffle mode, the compressor copies the data back to the input buffer. However, the underlying buffer can be shared by multi channels when BroadcastRecordWriter is used, so coping data back can corrupt data of other channels. This commit fixes the problem by disabling data compression for operators which use broadcast partitioner in pipelined mode.",1
[hotfix][config] Document enhancement: reminding users that shuffle data compression is experimental currently,5
[FLINK-15167][sql client] Catalogs should be created and registered with user class loaderThis closes #10514,1
[FLINK-15058][runtime] Log required config options if TaskManager memory configuration is invalidThis closes #10549.,5
[FLINK-15222][state backends] Move state benchmark utils into core repository,4
[FLINK-15197][kubernetes] And resource dynamic properties into TM start command for kubernetes integration.This closes #10545.,2
[hotfix] Simplify SlotSharingManagerTest by introducing factory method,3
"[FLINK-15013] Mark root as resolved before completing MultiTaskSlotIn order to prevent a race condition where Executions are scheduled becausetheir inputs' locations have been assigned but the underlying root slot notbeing marked as resolved and, hence, not being available for location basedscheduling, this commit enforces that we first resolve the root slot beforecompleting the associated MultiTaskSlot.",0
[hotfix] Introduce SlotSharingManager#createAndRegisterRootSlot,1
[hotfix] Refactor LocationPreferenceSlotSelectionStrategyTest to use Hamcrest matchers,1
[hotfix] Add locality assertions to LocationPreferenceSlotSelectionStrategyTest tests,3
"[FLINK-15013] Fix selection of NON_LOCAL slots in LocationPreferenceSlotSelectionStrategyThe LocationPreferenceSlotSelectionStrategy ignored NON_LOCAL slots due to initializing the initialcandidate score to a positive value. As NON_LOCAL candidates have a value of 0, the initial candidatescore needs to be negative.This closes #10555.",5
[hotfix] Remove explicit capacity from HashMap creation in SlotSharingManager,1
[hotfix] Set initial bestCandidateScore in LocationPreferenceSlotSelectionStrategy to Double.NEGATIVE_INFINITY,5
[hotfix][hive][test] rename util method from createTableEnv to createTableEnvWithBlinkPlannerBatchMode,2
[hotfix][hive] rename HiveCatalogTestBase to HiveCatalogMetadataTestBase,5
[FLINK-15234][table][hive] hive table created from flink catalog table cannot have null properties in parameters,2
[FLINK-15240][hive] is_generic key is missing for Flink table stored in HiveCatalogthis closes #10575.,2
[hotfix] Leverage autoCloseable to simplify CliFrontend.runClusterAction(),1
[FLINK-15179] Introduce generic ExecutorCLI,2
[FLINK-15179] Remove StandaloneSessionClusterExecutor so ExecutorCLI supports list()/cancel(),1
[FLINK-15179] Make Kubernetes Session CLI use the ExecutorCLI,1
[FLINK-15179] Assume Deployment.target=kubernetes-session when in KubernetesSessionCli,1
[FLINK-15179] Annotate KubernetesSessionCli as internal,2
[FLINK-15260] Uniformize Kubernetes executor name with the rest,2
[hotfix][doc][hive] rename page from 'Hive' to 'Hive Integration',2
[FLINK-15159][docs] Update the mapping of  JSON schema string type to Flink SQL STRING type (#10582),2
[hotfix][doc][hive] add doc on what hive dependencies to put in /lib dir,2
[hotfix][hive][test] enhance HiveCatalog IT case with 'alter table' and 'drop table' statements,4
[FLINK-15190][doc]add documentation for DDL in FLIP-69this closes #10565.,2
[FLINK-15233][kafka] Improve Kafka connector properties to make append update-mode as defaultThis closes #10584,5
[FLINK-13589] Fixing DelimitedInputFormat for whole file input splits.The DelimitedInputFormat drops bytes when using whole file input splits.This commit replicates the logic of regular input splits also for wholefile input splits.,2
[FLINK-15228][docs] Drop vendor specific deployment documentation,2
[FLINK-15257][hive]convert HiveCatalogITCase.testCsvTableViaAPI() to use blink plannerthis closes #10589.,2
[FLINK-15128][hive][doc] Document support for Hive timestamp typethis closes #10543.,1
[FLINK-15263][hive][doc] add dedicated page for HiveCatalogthis closes #10581.,2
[hotfix][doc][hive] add Hive connector to SQL's connector page,1
"[FLINK-15254][sql cli][module] modules in SQL CLI yaml should preserve ordercurrently the module map is a hash map in sql cli, which doesn't preserve module loading order from yaml.fix it by always using a linked hash mapthis closes #10578.",2
[FLINK-15271][python][docs] Add documentation about the environment requirements for running Python UDF,1
[FLINK-15270][python][docs] Add documentation about how to specify third-party dependencies via API for Python UDFsThis closes #10597.,2
[FLINK-15270][python][docs] Corrects docs for method `set_python_executable` in TableConfig,5
[FLINK-15267][table-planner-blink] Fix NoSuchElementException if rowtime field is remapped in TableSource (#10596),0
[FLINK-15245][hive] Fix hive table source cannot write data to another hadoop clusterThis closes #10568,5
[FLINK-15286][state-backend-rocksdb] Read option whether to use managed memory from configurationThis closes #10600,5
[FLINK-14834] Re-activate kerberized YARN on Docker tests,3
[FLINK-15251][kubernetes] Use hostname to create end point when ip in load balancer is null,1
"[FLINK-15265] Remove ""-executor"" suffix from executor namesThe executor names always have ""-executor"" as a suffix, this isreduntant. Currently, the executor name is also used to retrieve aClusterClient, where it is unfortunate that the name has executor as asuffix. In the future we might provide something like a FlinkClient thatoffers a programmatic API for the functionality of bin/flink, here wewould also use the same names.In reality, the ""executor names"" are not names of executors butdeployment targets. That's why the current naming seems a bit unnatural.This is a simple search-and-replace job, no new functionality.",1
[FLINK-15072][client] Move printing stringified JobExecutionResult to ContextEnv,4
[FLINK-15072][client] Remove JobExecutionResult container from ClientUtils#executeProgram,4
[FLINK-15201][client] Remove verifications in ContextEnv for detached execution,4
[FLINK-15072][client] Hijack executeAsync instead of execute for create pipeline,1
[FLINK-14929][tests] Harden ContinuousFileProcessingCheckpointITCaseRemove limit on number of restarts.Throw SuppressRestartsException in TestingSinkFunction.,3
[hotfix][tests] Remove unnecessary try-catch usage,1
[hotfix][tests] Remove unnecessary try-catch usage,1
[hotfix][tests] Remove unnecessary override of close() method,4
"[FLINK-15250][docs] Update ""Connect to External Systems"" page to list the required formats in connectors definition sectionThis closes #10585",5
[FLINK-15191][table][connectors] Fix connector factories that CREATE TABLE DDL can't work if watermark or computed column is definedThis closes #10536,1
[FLINK-15191][kafka] Add Kafka IT cases for Table API & SQLThis closes #10536,1
"[FLINK-14899] [table-planner-blink] Fix unexpected plan when PROCTIME() is defined in querye.g. `SELECT * (SELECT *, ROW_NUMBER() OVER (ORDER BY PROCTIME() ASC) as rowNum FROM MyTable) WHERE rowNum = 1` should be translated to StreamExecDeduplicate instead of StreamExecRankThis closes #10291",0
[FLINK-15169][runtime] Set global failure cause to ExecutionGraphThis makes the failure cause retrievable via REST and WebUI.,1
[FLINK-15169][runtime] Hand task failures to ExecutionGraph so that the vertex state and failure cause are properly setProperly setting failure cause to Execution is needed to exhibit the taskfailure in WebUI.This closes #10541.,0
"[FLINK-15092][java, table] Remove the restriction that CsvInputFormat expects at least one parserCsvInputFormat (RowCsvInputFormat transitevely) had an artificial restriction that at least one parsermust have been provided. This is a limitation for a proper support ofprojection pushdown in flink-table, when no fields from the input arerequired. This lead to a safety condition check in PushProjectIntoTableSourceScanRule failing.As part of this commit a TableSourceTestBase class was introduced wherewe can check if table sourcec meet such requirements.",1
[FLINK-15105][test] Skipping exception checks for resuming checkpoint tests after terminal failureThis closes #10588.,0
[FLINK-13373][docs] Remove examples section from getting started,1
[FLINK-13373][docs] Move python tutorial to the walkthrough section,4
[hotfix][docs] Cleanup grammar in python table walkthrough,4
[FLINK-13373][docs] Merge bash and windows local setup and move todeployment,4
[FLINK-15256][hive] HiveModuleFactory should take hive-version as required supported propertyHiveModuleFactory should have hive-version as property. Currently it cannot pick up hive-version from service discoverythis closes #10577.,5
[FLINK-15205][hive][document] Update hive partition and orc for read_write_hivethis closes #10590.,5
[hotfix][doc] Add single quotes to csv format ddl propertyThis closes #10612,5
[FLINK-15049][table-planner-blink] Fix compile error when hash join with timestamp type key (#10415),0
[FLINK-15232][table] Improve message of NoMatchingTableFactoryException to tell users which part is not matched (#10563),1
[FLINK-15291][table-common] Rename WatermarkSepc#getWatermarkExpressionString to getWatermarkExpr (#10614),1
[hotfix][table] Rename UserFunctionsTypeHelper,1
"[FLINK-12283][table] Relax UDF constraints by using the ClosureCleanerThis relaxes the UDF constraints as much as possible by using theClosureCleaner. For Java users, this is very convenient. For Scala users, itimproves the current status but we still need to fix FLINK-15162.It ensures that the validation and cleaning happens at exactly 2 locations.Either during registration in the function catalog or during resolution ofinline, unregistered functions.This closes #10519.",1
[hotfix][table] Update function tests to use testing infrastructure,5
[hotfix][table] Use testing infrastacture in tests,3
[FLINK-14170][fs-connector] Support hadoop<2.7 in StreamFileSink when truncate() not used,1
[FLINK-14170][fs-connector] Add tests for hadoop<2.7 support in StreamFileSink,2
[FLINK-14944][python] Fix pip install ConnectionResetErrorAdd retry logic for pip install to fix the possible ConnectionResetErrorwhen downloading python packages on high-speed networks.This closes #10613.,1
[FLINK-13197][table-planner-blink] Fix Hive view row type mismatch when expanding in planner* Add `FlinkRelOptUtils#createCastRel` to add cast rel based on specific conditions;* Remove the type mismatch check in `FlinkPlannerImpl` for the planner.This closes #10595,2
[FLINK-13197][table-planner] Fix Hive view row type mismatch when expanding in planner* Remove the type mismatch check in `FlinkPlannerImpl` for the planner;* Add test cases for anonymous column and field type mismatch.,3
[FLINK-15244][FileSystems] Avoid following symbolic links in FileUtils#deleteDirectory(File)This closes #10567.,4
[hotfix][travis] Made shade.sh standard shell compliant.,0
"[hotfix][e2e] Added ""minio"" to test descriptions.",3
[hotfix][filesystems] Also mirroring s3.path-style-access.,5
[FLINK-11956][travis] Removed S3 shading checks from build script.,4
[FLINK-11956][filesystem] Remove relocations from s3 plugins.,4
[FLINK-15241] Revert the unexpected change of the configuration for Mesos CPU coresThis closes #10571.,5
[FLINK-15171] [serialization] fix performance regression caused by too many buffer allocations on string serialization,1
[FLINK-15312][tests] Remove PlanExposingEnvironment,4
[FLINK-13567][e2e] Support retry with cleanup,4
[FLINK-13567][e2e] Dump kafka logs in shutdown on error,0
[FLINK-13567][e2e] Retry kafka/registry start,1
[FLINK-13567][e2e] Enable schema registry testsThis closes #10544.,3
"[FLINK-15317][runtime] Handle closed input gates more gracefully during cancellation. (#10621)During task cancellation, input gates can be closed in the task cancellation thread, before the main invokable has been interrupted, which resulted in reads from a closed gate.This commit will handle this case in a more graceful manner such that the end-user is not seeing any additional exception.",1
[FLINK-15149][table-common] Merge InputTypeStrategy and InputTypeValidatorThis merges the concepts of InputTypeStrategy for inferring input data typesand enriching data types with conversion classes and InputTypeValidator forvalidating arguments. It enables implicit casting and simplifies the overalldesign.This closes #10546.,0
[FLINK-14683] Fix RemoteStreamEnvironment's constructor,3
[hotfix][table-common] Add utility method for checking if a type is a composite type,1
[hotfix][table-common] Add utility for expanding a composite type to a schema.,1
[hotfix][table-api] Add utility for extracting accessed fields from a given physical type.,4
[hotfix][table-common] Add utility for mapping logical fields to physical indices.,2
[hotfix][table] Remove duplicated code for physical to logical mapping,2
[FLINK-15168][table-planner] Fix physical indices computing.Starting from this commit we use the schema that comes from CatalogTable instead of schema that comes from TableSource.Computing physical indices is based on the new type hierarchy instead of TypeInformation.,5
"[hotfix][table-planner-blink, tests] Fix produced data type of TestCollectionTableSource.",3
[FLINK-15168][table-planner-blink] Compute physical indices based on new type hierarchy instead of TypeInformation,5
[hotfix][table-common] Deprecate TableSource#getSchema.,1
"[hotfix][connectors/jdbc, table, tests] Fix types in schema ddl in tests",3
"[hotfix][connectors/kafka, table, tests] Fix types in schema ddl in testsThis closes #10605",3
[FLINK-15050][table-planner-blink] DataFormatConverters should support any TIMESTAMP WITHOUT TIME ZONE typesThis closes #10418,1
[FLINK-15269][table] Fix INSERT OVERWRITE/PARTITION syntax shouldn't be limited to Hive dialect (#10587),0
[FLINK-15266][table-planner-blink] Fix NPE for code generated CASE WHEN operator in blink planner (#10594),2
[FLINK-11767] [tests] Introduce ClassRelocator,3
[FLINK-11767] [tests] Introduce new TypeSerializerUpgradeTestBase,3
[FLINK-11767] [test] Add new PojoSerializer upgrade test based on TypeSerializerUpgradeTestBase,3
[minor] Add more JavaDoc to ClassRelocator,2
[FLINK-11767] Allow multiple migrate versions in PojoSerializerUpgradeTest,3
[FLINK-11767] In PojoSerializerUpgradeTest also check against Flink 1.8,2
[minor] In TypeSerializerUpgradeTestBase add note about generating test data,5
[FLINK-13632] In PojoSerializerUpgradeTest also check against Flink 1.9,2
"[FLINK-11767] In TypeSerializerUpgradeTestBase move migration version to base classTests derived from this should use the list of migrations versions fromthe base class, to ensure that we always update all the tests inlockstep.",3
"[FLINK-11767] Deprecate TypeSerializerSnapshotMigrationTestBase in favour of TypeSerializerUpgradeTestBaseThere are still a lot of tests that need to be ported, but we should notadd new tests using the old test base.",3
"[hotfix] In ClassRelocator, use correct ASM7 dependency",1
"[FLINK-14505][e2e, table] Update expected results after format change introduced in FLINK-11935",2
"Revert ""[FLINK-14505][tests] Temporarily disable SQL Client end-to-end tests for Kafka""This reverts commit f38106582e69765677ef8ebddece3a92641f6f22.",4
[FLINK-15332][jepsen] Copy flink-s3-fs-hadoop* into /plugins directory instead of libWe can no longer copy the flink-s3-fs-hadoop* jars into lib as they contain un-relocatedHadoop 3.1.0 dependencies.This closes #10634.,2
[hotfix][yarn] Refactor YarnDistributedCacheITCase to avoid code duplication,4
[hotfix][yarn] Fix logs in YARNITCase could not show up,2
[FLINK-15194] Support registering directory as cache file in Yarn per-job modeThis closes #10550.,2
"[FLINK-15268][build] Correctly set Multi-Release in manifest.FLINK-14905 introduced a multi-release approach to bundle librariesfor different JDK versions. However, the multi-release flag was notcorrectly set, which effectively disabled the mechanism and lead toincomplete dependencies on Java 11. This commit fixes the setup, suchthat the Java 11 libraries are correctly loaded.",1
[FLINK-15065][docs] Correct default value of RocksDB options in documentationThis refer to https://github.com/facebook/rocksdb/pull/6123 which correctis RocksDB javadoc,2
"[FLINK-15311][runtime] Remove the shade of lz4 compression for using efficient native implementationCurrently, the lz4 java library is used by both runtime and table modules for data compression.To avoid potential conflict with user jars, the library was shaded before.    However this way would change the class name to prevent JVM from finding the moreefficient native implementation. To boost the performance, this commit removes the shadeof lz4 library.    Note that this change might increase the probability of potential class conflict which can be solved via plugin mechanism in the future.",5
"[FLINK-15308][runtime] Remove data compression for pipelined partitionCurrently the implementation of data compression for pipelined partition brings some special handling logics. Especially it needs to add an additional synchronization in network stack for solving the race condition of multiple netty threads while compressing the partition buffer. This way might bring potential risk and complexity in threading model.Considering the above concerns and no strong compression requirements for pipelined partition at the moment, we decide to drop it and might re-implement it via light-weight netty handler stack in future if needed.",0
[FLINK-15301] [kinesis] Exception propagation from record emitter to source thread,2
[FLINK-15287][hive] Pack flink-hadoop-compatibility and flink-orc into flink-hive,2
[hotfix][doc][hive] add information of hive connector jar,5
[FLINK-15322][hive] Parquet test fails with Hive versions prior to 1.2.0this closes #10626.,0
[FLINK-14796][hive][doc] Add document about limitations of different Hive versionsthis closes #10650.,2
[hotfix][e2e] Refactor test_kubernetes_embedded_job.sh by moving common functions to common_kubernetes.sh,1
[FLINK-10938][e2e] Add e2e test for natively running flink session cluster on kubernetesThis closes #10602.,3
[hotfix] Enable killing mesos job manager in e2e clean up function,1
[hotfix] Forcelly remove the useless log in e2e clean up function,1
[Flink-15135][e2e][Mesos] Adding Dockerfiles relevant to Mesos setup,1
[Flink-15135][e2e][Mesos] Adding common functions to setup Flink on Mesos cluster,2
[Flink-15135][e2e][Mesos] Adding WordCount e2e test for Flink on Mesos,2
[hotfix] Enable arg list for nightly.sh,0
[Flink-15135][e2e][Mesos] Enable Mesos e2e test in TravisThis closes #10538.,3
[hotfix] Adding Mesos e2e tests to run-nightly-test script,3
[hotfix] Using retry_times when building docker image,2
[FLINK-15360][e2e] Fix the issue of parameter with whitespace in retry_times shell functionYarn e2e test is broken with building docker image. It is because the shell function retry_times can not support the parameter with whitespace properly (E.g. `retry_times 5 0 docker build image`). We make the third parameter which might contain whitespace as a local variable and then pass it into the function to solve the issue.,0
[FLINK-15320][runtime] Increment versions of all vertices when failing/canceling/suspending a job,0
[FLINK-15320] Simplify DefaultSchedulerTest tests for incrementing vertex versionsThis closes #10646.,3
[FLINK-15272][table-planner-blink] Improve exception message when insert partition with values (#10591),1
"[FLINK-15361][parquet] ParquetTableSource should pass predicate in projectFieldsfix the problem, when after projectFields, ParquetTableSource will loose predicates.this closes #10660.",0
[FLINK-15348][hive] Fix orc optimization for version less than 2.3 by introducing orc shimadd shim to support hive orc version less than 2.3this closes #10618.,1
[FLINK-15193][table][docs] Move DDL to the first tab in table connector page,4
[FLINK-15243][table][docs] Fix documentation about how to set line feed as delimiter for csv formatThis closes #10661,1
[FLINK-15344][documentation] Update limitations in hive udf documentthis closes #10647.,2
[FLINK-15175][sql client] Fix SqlClient not support with..select statementThis closes #10619,1
[FLINK-15359][configuration] Remove unused YarnConfigOptionsIncluding- yarn.appmaster.rpc.address- yarn.appmaster.rpc.port- yarn.maximum-failed-containersalong with their document and dedicate tests.,3
[FLINK-13662][core] Add timeLeft variant that throws TimeoutException,1
[FLINK-13662][kinesis] Relax timing requirementsThis closes #10551.,1
"[FLINK-15248][FileSystems] Allow FileUtils#compressDirectory to process relative directories.FileUtils#compressDirectory behaves buggy when processing relative directory path. If the path of target directory is a relative path, the relative path inside the target zip file can not be constructed correctly. Convert the relative path to absolute path before compressing it.",2
[FLINK-11524][tests] Throw descriptive error if job terminates prematurely,0
[FLINK-11524][tests] Make JobResultUtils#assertIncomplete implementation more comprehensiveThis closes #10553.,3
[hotfix] Unmounted the data and log directory of Mesos docker,2
[FLINK-15377] Add ResourceManager connecting error to white list,0
[hotfix] Using docker detach execution mode to start flink cluster,2
[FLINK-15374][core][config] Update jvm overhead config descriptions regarding direct/native memory and jvm parameters.,2
[FLINK-15373][core][config] Update framework off-heap memory config description regarding direct/native memory and jvm parameters.,2
[FLINK-15373][core][config] Update task off-heap memory config description regarding direct/native memory and jvm parameters.,2
[hotfix] Update task heap/offheap config option descriptions for preciseness.,5
[hotfix][doc] add section for various optimizations of reading Hive tablesthis closes #10640.,1
[FLINK-15342][hive] add IT for querying Hive viewthis closes #10643.,1
[FLINK-15372][core][config] Remove 'total-' from total process memory config key.,5
[FLINK-15372][core][config] Remove 'total-' from total flink memory config key.,5
[hotfix][table-common] Add toNullable() and legacyDecimalToDefaultDecimal() TypeTransformations,1
[hotfix][table-api] Use new type system for CsvTableSink,5
"[hotfix][hive] Use TableUtils.collectToList(Table) to verify query result`HiveTestUtils#collectTable` doesn't use new type system, this will loseprecision information.",5
"[FLINK-15313][table-blink] Fix can't insert decimal data into sink using TypeInformationThe root problem is we use TypeInformation for sink code generation whichloses the precision of decimal type. This result in the illegal accessing tothe internal Decimal value. The fixing including:1. Add validation for query and sink field types should be compatible (including precision)2. If not compatible, an implicit cast is added (this makes sure that it is still correct  to access internal decimal data using sink field type, e.g. genToExternal)3. Checks logical schema (from DDL) and physical schema (from TableSink#getConsumedDataType)  are compatible.4. Use new type system for sink code generationThis closes #10667",5
[hotfix][hive] Use TableUtils.collectToList(Table) in TableEnvHiveConnectorTest,3
[FLINK-15382][docs] Exclude PythonConfig from configuration docs generatorThis closes #10688.,2
[hotfix][yarn] Move yarn Utils#calculateHeapSize to BootstrapToolsThe method BootstrapTools#calculateHeapSize will be used by Yarn and Kubernetes to calculate the heapsize of jobmanager. The heapsize will be set to JVM -Xmx and -Xms.,1
"[FLINK-15288][kubernetes] Starting jobmanager pod should respect containerized heap-cutoffThe cutoff is to leave some memory for jvm non-heap, for example meta space, thread native memory and etc.",2
[FLINK-15391][hive] DATE and TIMESTAMP partition columns don't workFix issues of read/write DATE and TIMESTAMP partition columns.this closes #10690.,5
[FLINK-15239][table-planner-blink] Fix CompileUtils:#COMPILED_CACHE leaks class loaders (#10620),0
[FLINK-15189][hive][doc] Add documentation for hive viewthis closes #10701.,2
[FLINK-14849][hive][doc] Fix documentation about Hive dependenciescloses #10681.,2
"[FLINK-15426][e2e] Fix TPC-DS end-to-end test (Blink planner) fails on travis (#10707)FLINK-15313 forbids to use TypeInformation defined in blink plannerinternally (`BigDecimalTypeInfo`) as the output type of TableSink (physical type and logicaltype not equal). However, the TPC-DS framework breaks this. The fixingis to use DataTypes which is the standard way.",5
[FLINK-15125][table-planner-blink] Fix PROCTIME() computed column defined in CREATE TABLE doesn't workThis closes #10680,1
[FLINK-13667][ml] Add the utility class for common Table operations.,1
[FLINK-13667][ml] Improve API and extend test coverage on all functions in TableUtils.This closes #9404.,1
[FLINK-15435][python] Fix unstable test for ExecutionConfigTests.test_equals_and_hashThe default parallelism used by local environments is calculated according to the availableprocessors. We should specify the parallelism explicitly to avoid test unstable.This closes #10715.,3
[FLINK-15389][jdbc] Improve JDBCUpsertOutputFormat to schedule flusher when flushMaxSize is not oneThis closes #10712,5
[FLINK-15418][table-planner-blink] Set FlinkRelDistribution in StreamExecMatchRuleThis closes #10706,2
[FLINK-15425][csv][docs] Improve docs that only old CSV format is supported in filesystem connector (#10718),5
"[FLINK-15192][table][docs] Restructure ""SQL"" page into multiple sub-pages and reorder pages under Table API & SQLThe new sub-pages of ""SQL"":- Overview- Queries- CREATE Statements- DROP Statements- ALTER StatementsThis closes #10669",4
[FLINK-14610][table][docs] Add documentation for how to define time attribute in DDLThis commit describes how to define processing time attribute and event time attributein CREATE TABLE DDL using the syntax of computed column and watermark statement.This closes #10669,1
"[FLINK-15439][table][docs] Fix incorrect description about unsupported DDL in ""Queries"" pageUpdate documentation because DDL is supported now.",1
[FLINK-15231][table-runtime-blink] Remove useless methods in AbstractHeapVectorThis closes #10562,1
[FLINK-15421][table-planner-blink] Fix cast exception for timestamp MAX/MIN retract aggregate functionsThis makes TimestampMaxAggFunction and TimestampMinAggFunction to accept SqlTimestamp values and also support high precision for timestamp types. This closes #10722,1
[FLINK-15428][e2e] Skip Avro Confluent Schema Registry case when running with JDK11,1
[FLINK-15428][e2e] Fix the error command for stopping kafka cluster,0
[FLINK-15409][table-planner-blink] Fix code generation in windowed join function (#10714),1
[FLINK-15290][streaming] Configure user defined function with global configurationLoad configurations in HiveTableInputFormat to decide whether vector orc reader should be used.this closes #10632.,1
[FLINK-15259][hive] HiveInspector.toInspectors() should convert Flink constant to Hive constantConvert constant Flink object to Hive object before creating Hive's constant object inspectors.this closes #10625.,1
[FLINK-15443][jdbc] Fix mismatch between Java float and JDBC float (#10731),5
[hotfix][table-planner-blink] Fix comparison of timestamp with local time zone,0
[FLINK-15411][table-planner-blink] Fix prune partition on DATE/TIME/TIMESTAMP columns,5
[FLINK-15411][hive] Fix listPartitions in HiveCatalog & Add time prune partition tests,3
[FLINK-15420][table-planner-blink] Fix precision is lost when casting string to timestamp (#10727),0
[FLINK-15383][table-planner] Use sink schema field name instead of query field name for UpsertStreamTableSink#setKeyFieldsThis closes #10700,1
[FLINK-15334][table-api] Fix physical schema mapping in TableFormatFactoryBase to support define orderless computed column (#10693),1
[FLINK-15381] [table-planner-blink] Fix collation derive logic on RelSubset in RelMdCollation (#10694),1
"[FLINK-15377][tests] Remove docker-engine install in Mesos docker imageSince we do not start additional docker containers from within docker, it isacceptable to remove the installation of the docker-engine dependency.This closes #10695.",2
[FLINK-14980][docs] add function ddl docsthis closes #10732.,2
"[FLINK-14613][table-planner-blink] Fix wrong result when lookup join equality condition contains function on lookup key.For the following SQL, the join condition `A.amount = cancat(B.amount, 'r')`` is ignored, and the only filter is `B.product = '1'`.SELECT *FROM A join B FOR SYSTEM_TIME AS OF A.proctimeon A.amount = cancat(B.amount, 'r') and B.product = '1'This closes #10144",5
"[hotfix][docs] Fix link to latency granularity in ""Metrics"" page (#10751)",2
[hotfix][csv][json] Deprecate schema methods for CSV and JSON formatsDeprecate schema methods for CSV and JSON formats because these formats canderive schema from table schema by default. It is no longer necessary toexplicitly declare format schema.,1
"[FLINK-15446][table][docs] Improve ""Connect to External Systems"" documentation page1. Remove documentation for format schema, which is not necessary any more and is deprecated.2. Add DDL documentation for ""Table Schema"" and ""Rowtime Attribute"" sections.3. Update the comments in DDL tab for better rendering (do not wrap line).This closes #10733",1
[hotfix][yarn] Write yarn properties file without YarnClusterDescriptor.,2
[hotfix][yarn] Remove unused argument workingDirectory for YarnEntrypointUtils#installSecurityContext.,1
[hotfix][yarn] Remove unused argument logger for YarnEntrypointUtils#loadConfiguration.,5
[FLINK-15437][yarn] Apply dynamic properties early on client side.This closes #10728 .,2
[FLINK-15429][hive] HiveObjectConversion implementations need to handle null valuesthis closes #10721.,0
[hotfix][runtime] Fix formatting in TaskExecutorResourceUtils and NetworkBufferPool,1
[FLINK-15403][task] Allow the CancelTaskException to be thrown from mailbox threadCancelTaskException can be thrown for example from LocalInputChannel#getNextBuffereven if the current (down stream) task hasn't YET been canceled. This restoresthe behaviour to before [FLINK-15317].StreamTask is able to correctly process/handle CancelTaskException.,0
[FLINK-15380][scala-shell] Unable to set number of TM and number of Slot for MiniCluster in Scala shellThis closes #10676 .,5
[hotfix][core][config] Use the new type definition for config options of primitive types in TaskManagerOptions.,5
[FLINK-15371][core][config] Use the new type definition for config options of memory types in TaskManagerOptions.This closes #10677.,5
[hotfix][core][config] Use the new type definition for config options of duration types in TaskManagerOptions.,5
[FLINK-15427][Statebackend][test] Check TTL test in test_stream_state_ttl.sh and skip the exception checkAdd some specific error message in TtlVerifyUpdateFunction and use it to verify the testThis closes #10726.,3
[FLINK-15279][doc] Document new executeAsync() method and the newly introduced JobClientThis closes #10684 .,1
[FLINK-15454][cluster] Remove redundant inherited ClusterEntrypoint#installSecurityContext,1
[FLINK-15341][client] Reset context classload in PackagedProgramUtils#createJobGraph,1
"[FLINK-15427][e2e] Harden test_stream_state_ttl.sh verification logicInstead of checking for a specific string in the *.out file, we simply check whetherthe out file is empty. If this is not the case, then this indicates a test failure.",0
[FLINK-9679] Add Schema Registry version as parameter + update version,5
[FLINK-9679] Add (Confluent)(Registry)AvroSerializationSchema,5
[minor] Simplify RegistryAvroSerializationSchema.serialize(),1
"[FLINK-9679] In Confluent Schema Registry e2e, also test write path",3
[FLINK-15297][yarn] Do not throw exception if YARN Application switched to FINISHED immediately after deployed in YarnClusterDescriptor#startAppMaster,5
[FLINK-15459] Drop vendor specific repos from parent pom.xmlWe no longer need builds for vendor specific repos as Flink no longerbundles Hadoop dependencies. Putting the dependencies on the classpathshould be good enough.,2
[FLINK-14765][runtime] Remove STATE_UPDATER in ExecutionThis closes #10288.,5
[FLINK-13596][ml] Add DataStream and DataSet to Table transformations.,5
[FLINK-13596][ml] Improve fallback conversion and test for Table transformation.This closes #9373.,3
[FLINK-13027][fs-connector] SFS bulk-encoded writer supports customized checkpoint policy,1
[FLINK-14766][coordination] Remove volatile keyword in executiongraph packageThis closes #10207 .,1
[hotfix][doc] Remove invalid comment from CheckpointedInputGateThis closes #10729 .,4
[hotfix][doc] Fix typo in asyncio.mdThis closes #10765 .,2
[FLINK-15468][sql-client] INSERT OVERWRITE not supported from SQL CLIcloses #10759.,1
[FLINK-15453][hive] Remove unneeded HiveShim methodscloses #10755,4
"[FLINK-15385][table][docs-zh] Translate ""SQL"" pages of Table API into ChineseThis closes #10738",1
[hotfix][runtime] Fix a comment typo in CheckpointBarrierAligner,2
"[hotfix][runtime] Remove unused IOManager parameter while constructing BufferStorageAfter removing the code path of noncredit-based flow control, the IOManager parameter would never be used forconstructing the BufferStorage, so we can remove it along with the related code path.",4
[FLINK-14655][runtime] Change type of field jobStatusListeners from CopyOnWriteArrayList to ArrayListThis closes #10116.,4
[FLINK-15430][table-planner-blink] Split generated methods for Calc to prevent compiler exceptions (#10737),2
[FLINK-14572][test] Print the root cause if job fails in BlobsCleanupITCase,4
"[FLINK-15481][python] Add `list[str]` to the type hint of parameter ""schema"" in `TableEnvironment#from_elements`.",2
[hotfix][table-api-java] Remove @Experimental from useCatalog/useDatabase,5
[hotfix][docs] Align the documentation of checkpoint directory to the actual implementation,2
"[hotfix] Remove default value of legacy 'taskmanager.heap.mb', in case of implicit usages.",4
[hotfix] Add the legacy config option 'taskmanager.heap.size' back.This makes it convenient for later decouple 'taskmanager.heap.size' from 'taskmanager.memory.process.size'.,1
[hotfix] Remove unused ClusterSpecification#fromConfiguration.,5
[hotfix] Rename AbstractClusterClientFactory to AbstractContainerizedClusterClientFactory.,0
[FLINK-15367][runtime] Map legacy 'taskmanager.heap.size' to new config options differently for standalone / active setups.This closes #10716.,1
[hotfix] Remove unnecessarily setting managed memory size for active resource manager configurations.,5
[FLINK-15369][runtime] Set MiniCluster to use fixed managed / shuffle memory size by default.This closes #10717.,0
[hotfix][network] Fix the import format of NettyConfig class,5
[hotfix][network] Remove unused method from NettyConfig class,5
"[FLINK-15021][network] Remove the setting of netty channel watermark in NettyServerThe high and low watermark setting in NetterServer before was mainly used for network flow control and limiting the maximum memoryoverhead caused by copying data inside netty stack. In detail, when the downstream side processes slowly and exhausted the availablebuffers finally, it would temporarily close the auto read switch in netty stack. Then the upstream side would finally reach the highwatermark of channel to become unwritable.But based on credit-based flow control and reusing flink network buffer inside netty stack, the watermark setting is not invalid now.So we can safely remove it to cleanup the codes.",4
[FLINK-14200][table] Fix NPE for Temporal Table Function Join when left side is a query instead of a source (#10763),1
[FLINK-15478][table-planner-blink] Fix FROM_BASE64 code generation exception because of the wrong result type (#10766),0
"[FLINK-15053][runtime] Escape all dynamic property values for taskmanagerFor unix-like OS(Linux, MacOS, FREE_BSD, etc.), each value will put in single quotes. This works for all chars except single quote itself. To escape the single quote, close the quoting before it, insert the escaped single quote, and then re-open the quoting. For example, the value is foo'bar and the escaped value is 'foo'\''bar'.For windows OS, each value will be surrounded with double quotes. The double quote itself needs to be escaped with back slash. Also the caret symbol need to be escaped with double carets since the window command uses it to escape characters.This closes #10532.",1
"[FLINK-15398][docs] Fix incorrect code example in ""Catalogs"" page (#10786)",2
[FLINK-15465][FLINK-11964][table-runtime-blink] Fix required memory calculation not accurate and hash collision bugs in hash table (#10756),0
[FLINK-15482][table][hive] Fix calling Hive functions with returning decimal type failed (#10775),0
[FLINK-15442] Harden the way to loop in retry_times_with_backoff_and_cleanup,4
[FLINK-15442] Retry to download the kafka and confluent distThis closes #10742.,5
[FLINK-15501] Remove the wrong doc of ExecutionVertexSchedulingRequirements#getExecutionVertexIdThis closes #10790.,1
[FLINK-15406][state-processor-api] RocksDB savepoints with heap timers cannot be restored by non-process functions,1
[hotfix][e2e] Normalize the way to get log file name in wait_num_of_occurence_in_logs function,1
[FLINK-15214][e2e] Enable waiting for job terminal state for all deployment modes,0
[FLINK-15214][e2e] Make CPU resources for mesos agent configurable per test,3
[FLINK-15214][e2e] Introduce multiple submissions e2e test for mesosThis closes #10666.,3
[FLINK-15370][state backends] Make sure sharedResources takes effect in RocksDBResourceContainer,5
[FLINK-14926][state-backend-rocksdb] (follow-up) Move additional setup with sharedResources into RocksDBResourceContainerThis closes #10670,5
[FLINK-11135][configuration] Reorder Hadoop config loading in HadoopUtilsThis closes #7314 .,5
[FLINK-15502][docs-zh] Fix hyperlink mistake in 'Queries' page (#10789),2
[FLINK-15499][yarn] Log TM host and resource at INFO level when starting new TMs.,1
[hotfix] Refactor memory range fraction parsing to throw IllegalConfigurationException,5
[hotfix] Fix TaskExecutorResourceUtilsTest#validateFail to catch only relevant exception and throw assert error,0
[hotfix] Simplify logic which duplicates TaskExecutorResourceUtils#deriveManagedMemoryAbsoluteOrWithFraction and calls it again,2
"[FLINK-15300][Runtime] Allow shuffle memory fraction mismatch if derived from other memory typesThe shuffle memory is used when there is no clue about its size.If the fraction is not wihtin min/max range of its abs value, it is capped to the closest min/max value.If the user configured ohter types of memory (total Flink, task heap and managed memory) then the derivedshuffle memory is the abs remaining value of total Flink memory basically as if it is explicitly configured.If the derived shuffle memory is within min/max range but it does not match the fraction,we can log this fact but there is no reason to fail.",0
[hotfix] Improve derived shuffle memory sanity check test coverage,3
[hotfix] Log if memory fraction is outside of its min/max range and has to be capped,2
[hofix] Improve failure message of shuffle memory sanity check,0
[hotfix] [python] Change the text of PyPI Author from `Flink Developers` to `Apache Software Foundation` (#10799),5
"[FLINK-15355][plugins] Added parent first patterns for plugins.Certain parent first entries do not work well with unrelocated pluginsand custom hadoop bundling. By using a reduced list that only consistsof SPI level interfaces and logging frameworks, plugins work withoutrelocations.",1
[FLINK-10939][doc] Add documents for running Flink cluster natively on Kubernetes,2
[FLINK-10939] Adjust spelling and ordering in Flink on Kubernetes doc,2
[hotfix] Fix typos in Flink on Kubernetes doc,2
[hotfix][doc] Add missing execution configuration in config.zh.md,5
[FLINK-15510] Pretty Print StreamGraph JSON Plan,5
[hotfix] Refactor OperatorID compartion in StreamGraph JSONGenerator,5
[hotfix][yarn] Move yarn/Utils#getEnvironmentVariables to BootstrapToolsThe method BootstrapTools#getEnvironmentVariables could be reused by Yarn and Kubernetes.,1
"[FLINK-15483][kubernetes] Starting jobmanager pod should respect environment config optionThe config option ""containerized.master.env."" could be used to set the environment variables. For example, containerized.master.env.LD_LIBRARY_PATH: ""/usr/lib/native"".This closes #10788.",1
[FLINK-8255] Throw meaningful exception when using string keys on row types,1
[FLINK-14825][state-processor-api][docs] Rework state processor api documentation,2
[FLINK-15338][python] Cherry-pick NETTY#8955 to fix the TM Metaspace memory leak problem in shaded netty when submitting PyFlink UDF jobs multiple times.,2
[FLINK-15338][python] Cherry-pick BEAM-9006#10462 to fix the TM Metaspace memory leak problem when submitting PyFlink UDF jobs multiple times.This closes #10772.,2
[hotfix][docs] Fix typo,2
[hotfix][javadocs] Fix class reference,0
[FLINK-15466][table-planner-blink] Fix the wrong plan when use distinct aggregations with filterThis closes #10760,1
[FLINK-15536][configuration] Revert removal of ConfigConstants.YARN_MAX_FAILED_CONTAINERS (#10808),5
[FLINK-15457][yarn] Remove outdated TODOThe referenced config option no longer exists.,5
[FLINK-15518][web] do not hide web frontend side pane automatically (#10803),2
"[FLINK-15306][network] Adjust the default netty transport option from nio to autoThe default option of `taskmanager.network.netty.transport` in NettyShuffleEnvironmentOptions is `nio` now.As we know, the `epoll` mode can get better performance, less GC and have more advanced features which are only available on linux.Therefore it is better to adjust the default option to `auto` instead, and then the framework would automatically choose the propermode based on the platform.",1
"[FLINK-12785][StateBackend] RocksDB savepoint recovery can use a lot of unmanaged memoryAdd size based flush policy for RocksDBWriteBatchWrapper, to prevent too much memory consumption during savepoint recovery.This closes #10329.",5
[FLINK-15009][table-common] Improve error message for common type mistakes,0
[FLINK-15009][table-common] Add a utility for creating type inference logic via reflectionThis implements the full annotation and extraction logic mentioned in FLIP-65. The utilitytakes any of the currently supported functions and returns a TypeInference instance. Seethe documentation of the FunctionHint annotation for more information about the semantics.This closes #10606.,5
[hotfix][table-common] Add utility methods to identifiers,1
[FLINK-15281][table-planner-blink] Map Flink's TypeInference to Calcite's interfacesThis connects Flink's new type inference to Calcite's type inference. It ensures thatboth Table API and SQL have exactly the same behavior and similar exception messages.This closes #10781.,5
"[FLINK-15355][plugins] Fixed parsing of plugin parent-first patterns.Previously, empty options would result in an empty pattern, whichmatches everything. Thus, we effectively got parent first for allclasses.",0
[FLINK-15542][legal] Move NOTICE entry for lz4-java,1
[FLINK-15543][legal] Remove Apache Camel NOTICE entries,4
[FLINK-15319][e2e] Support configurable download retries/timeout,5
[FLINK-15319][travis] Retry downloads,1
[FLINK-15520][prometheus][tests] Use DownloadCache,1
[FLINK-12004][core] Make Pojo types accept chainable settersThis closes #8045,1
[FLINK-15490][kafka][test-stability] Enable idempotence producing in KafkaITCase to avoid intermittent test failure.,0
[FLINK-15504] Allow output to stdout/stderr during execution of PackagedProgramWe suppress the output to stdout/stderr during plan extraction viaPackagedProgram. This has unintended consequences for users who are looking intodebugging their Flink programs during JobGraph creation.This change removes the suppression of output when we run the JARs. The planpreview still suppresses the output to avoid spaming the logs during planpreview.,2
"[FLINK-15387][rocksdb][metrics] Expose missing RocksDB properties out via RocksDBNativeMetricOptionsExpose more RocksDB metrics including block-cache-capacity, block-cache-pinned-usage, block-cache-usage and is-write-stoppedThis closes #10692.",5
[FLINK-15515][hive][doc] Document that Hive connector should be used with blink plannercloses #10813.,2
[FLINK-15464][hive] Fix HiveTableSourceTest::testPartitionFilterDateTimestamp for 1.xcloses #10757.,5
[FLINK-13465][legal] Update licensing,5
[FLINK-15523][conf] Revert removal of Public fields,4
[FLINK-15523][conf] Japicmp checks ConfigConstants,5
"[FLINK-15512][state backends] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)Due to the implementation of RocksDB write buffer manager and the existing issue of creating cache with strict capacity limit, we do some internal calculation of the cache capacity shared among RocksDB instances for memory control.This closes  #10820.",5
[FLINK-15485][table-planner] Reopen ignored tests whose related issues have been resolvedThis closes #10774,0
[FLINK-15548][table-blink] Use KeyedCoProcessOperator instead of LegacyKeyedCoProcessOperator in blink plannerLegacyKeyedCoProcessOperator is deprected and should use KeyedCoProcessOperator instead.This closes #10827,1
[FLINK-15522][runtime] JobResult takes ExecutionGraph failure cause as its failure cause only if job is FAILED,0
[hotfix][runtime] ExecutionGraph failure cause cannot be null if job is FAILED,0
[FLINK-15495][sql-cli] Set default planner to Blink planner for SQL Client (#10787),2
[hotfix][runtime] Fix variable name typos in TaskInformation,5
[FLINK-15488][runtime] Obtain JVM and TM params correctlyThis avoids that log messages to stdout intermingle with BashJavaUtils'computation result which is also printed to stdout.This closes #10804.,2
[FLINK-15174][security] Added certificate pinning for SSL mutual authThis helps to make sure only a single certificate can be used when certificates are issued by public CA.,0
[FLINK-15174][security] (follow-up) Add a test for exceptions on invalid / malformed fingerprint and refine docs.,2
[FLINK-15529] [docs] Update upgrade compatibility table in operations doc for 1.10.0This closes #10805.,2
[FLINK-15292] Rename Executor to PipelineExecutor,2
[FLINK-15292] Rename ExecutorFactory to PipelineExecutorFactory,2
[FLINK-15115][kafka] Reduce mockingReplace the mocked KafkaConsumer with a custom Consumer implementation. Migrate all users toward the Consumer interface instead of the concrete KafkaConsumer implementation.Using an actual implementation highlights API changes when migrating to later custom versions and prevents issues due to subtle mocking gotchas.,0
[FLINK-15115][kafka] Drop Kafka 0.8,4
[FLINK-15115][kafka] Drop Kafka 0.9 SQL jar,4
[hotfix][kafka][legal] Correct version in NOTICE,0
[FLINK-15115][kafka] Drop Kafka 0.9,4
[FLINK-15541] Fix unstable case FlinkKinesisConsumerTest,3
"[FLINK-15565][table-planner-blink] Fix error conversion of TINYINT, SMALLINT literals between Flink and Calcite (#10841)",2
[FLINK-15559][docs] Fix broken links due to missing baseurl (#10844),2
[FLINK-15567][table][docs] Add documentation for INSERT statements for Flink SQL (#10839),2
[hotfix][kubernetes] Remove the unnecessary clean up codes for Kubernetes embedded jobThe ${OUTPUT_VOLUME} is under ${TEST_DATA_DIR}. And ${TEST_DATA_DIR} will be cleaned up automatically when the e2e test finished. See test-runner-common.sh#cleanup.,3
"[hotfix][kubernetes] Use stable api apps/v1 instead of extensions/v1beta1The extensions/v1beta1 has been removed since v1.16. For better compatibility, we should use the stable api apps/v1 instead. The apps/v1 is introduced from v1.9.0.",1
[FLINK-15354][e2e] Start and stop minikube only in kubernetes related e2e testsThis closes #10665.,3
[FLINK-15533] Consolidate parallelism in Environment constructor,5
[FLINK-15533] Deprecate text sink facilitation methods in DataStream,5
[hotfix] remove isSystemFunction from DropCatalogFunctionOperation as it's never used,1
"[FLINK-15576] remove isTemporary property from CatalogFunction APIaccording to FLIP-79, CatalogFunction shouldn't have ""isTemporary"" property. Moving that from CatalogFunction to Create/AlterCatalogFunctionOperationcloses #10846.",2
[hotfix][docs] Fix typo in class doc of KafkaTopicPartitionStateWithPunctuatedWatermarksThis closes #10849 .,2
[FLINK-15431][CEP] Add numLateRecordsDropped metric in CepOperator,1
[FLINK-14091][coordination] Allow updates to connection state when ZKCheckpointIDCounter reconnects to ZK,5
[FLINK-14091][tests] Tests ZooKeeperCheckpointIDCounter can be recoverd from connection loss,3
[FLINK-14091][tests] Refactor ZooKeeperCheckpointIDCounter for a more testable codebase,3
[hotfix] Fix checkstyle violations in ZooKeeperCheckpointIDCounter,0
"[FLINK-14091] Harden ZKCheckpointIDCounterMultiServersTestIn order to avoid race conditions between notifying different listeners,this commit introduces the LastStateConnectionStateListener which is passedinto the ZooKeeperCheckpointIDCounter. This listener can be modified tofulfill the required testing purposes inZKCheckpointIDCounterMultiServersTest#testRecoveredAfterConnectionLoss.This closes #10754.",3
[FLINK-15434][tests] Harden JobMasterTestStop using fastHeartbeatServices in tests that do not require a fast heartbeattimeout. This avoids unexpected heartbeat timeouts.This closes #10814.,1
[FLINK-15278] Update the StreamingFileSink docs,2
[FLINK-15535][doc] Add ProcessFunctionTestHarnesses documentation,2
[FLINK-15554][azure] Bump jetty-util to 3.1.2,2
[FLINK-15327][runtime] No warning of InterruptedException during cancel.InterruptedException are previously only handled when wrapped inWrappingRuntimeException. This patch looks through the whole exceptionchain.,1
[hotfix][typo] Fix doc typo for the java doc of MultiStateKeyIteratorTest,3
[FLINK-15517][Runtime][Configuration][Network] Use back 'network' in 'shuffle' memory config option names,5
[FLINK-15589][doc] remove beta tag from catalog and hive doccloses #10856,2
[FLINK-15590][doc] add section for current catalog and current database,5
[FLINK-15307][runtime] Rename Subclasses of FailoverStrategyThis closes #10848.,0
[hotfix][dist][config] Update the comments of TM process memory size in default flink-conf.yaml.- Correct the description of process memory size.- Provide the alternative flink memory size.,2
[FLINK-15145][dist][config] Increase the TM process memory size in default flink-conf.yaml to 1568MB.,5
[FLINK-15145][core][config] Increase the TM JVM overhead min size default value to 192MB.,1
[FLINK-15145][core][config] Decrease the TM JVM metaspace size default value to 96MB.This closes #10860.,5
[FLINK-15521][e2e] Follow symbolic link when copying distribution,2
[hotfix][tests] Fix typo,2
[FLINK-15152][checkpointing] Restart CheckpointCoordinator if StopWithSavepoint failed (#10824),0
[FLINK-14843][e2e] Harden bucketing sink e2e test,3
[FLINK-15220][Table][Kafka] Add startup timestamp in KafkaTableSourceThis closes #10674,1
"[FLINK-15220][Table,Kafka,Python] Add startup timestamp in KafkaTableSource in python API",1
[FLINK-14853][core] Implemented Duration formatting,2
[FLINK-14853][core] Implemented MemorySize formatting,2
[FLINK-14853][docs] Updated documentation generator to print MemorySize andDuration in a nicer wayThis closes #10829,2
[hotfix][coordination][configuration] Fix docs: container cutoff options are only used for JM after FLIP-49,1
[FLINK-15489][web] Avoid caching of JM and TM logs in the web uiThis adds the 'Cache-Control: no-cache' HTTP header when requesting TM or TMlogs.This closes #10842.,2
[FLINK-15355][plugins]Classloader restricted to whitelisted system classes.No class/resource in the system class loader (everything in lib/) can be seen in the plugin except those starting with a whitelist prefix.,0
[hotfix][plugins]Hide classloader pattern options from documentation.,2
[FLINK-13595][connector/kafka][test] Close the KafkaAdminClient with a timeout. Print stacktrace if a long closure happens.,3
[FLINK-15558][Connector] Bump Elasticsearch version from 7.3.2 to 7.5.1 for es7 connector,2
"[FLINK-15597][runtime] Compromise JVM Overhead fraction to Total Flink / Process Memory sizes, wrt JVM Overhead min/max.This closes #10862.",2
[hotfix][javadoc] Add a missing param doc for JobExecutionException,2
"[hotfix][e2e] Compile walkthroughs for e2e testsThe partial compilation in nightly only compiles flind-end-to-end-testsfor performance reasons. However, that resulted in outdated walkthrougharchetypes among other issues.",0
[FLINK-15583][walkthrough] Use -nobootcp in maven-scala-plugin,1
[FLINK-15583][e2e] Add walkthroughs e2e tests to misc split,3
[hotfix][e2e] Force local archetype catalogPrevents subtle issues with archetypes accidentally being downloaded from the snapshot repository.,0
[FLINK-15605][State][TTL] Remove deprecated in 1.9 StateTtlConfig.TimeCharacteristic1.10 follow-up for FLINK-11825,2
[FLINK-15606][State][TTL] Deprecate enable default background cleanup of state with TTLFollow-up forFLINK-14898.Having an API method to enable TTL background cleanup does not make sense too much if it is already enabled by default so we can deprecate this method.,0
"[FLINK-15506][State][TTL] Enable State TTL Compaction Filter by default and deprecate the optionHaving the TTL compaction filter always enabled, currently results in that it runs for all Flink states independently from whether they are configured to have TTL or not. This theoretically increases compaction time and wastes some CPU cycles on calling the filter with the disabled TTL check. To test this, we have to try it by running a job with high compaction pressure which is difficult to generate. The common performance benchmark should be at least checked. In general, we do not expect any significant performance degradation as the calling of idle filter should be a negligible internal native C++ call w/o using JNI.This option can be also quite confusing for users. We can deprecate it but keep to fallback atm. Then see if there are any actual performance degradation reported by users. If none, we can remove it completely later.",4
[hotfix] Add space after period in TTL_COMPACT_FILTER_ENABLED description,0
[FLINK-15564][yarn][test] Fix that YarnClusterDescriptorTest#testFailIfTaskSlotsHigherThanMaxVcores and #testConfigOverwrite not validating the original intended behaviors.,5
[FLINK-15564][yarn] Factor max vcores retrieval out of YarnClusterDescriptorFor better testability this commit introduces the YarnClusterInformationRetriever whichis responsible for retrieving the maximum number of vcores.This closes #10852.,5
[hotfix][yarn] Remove yarn app master env keys that are not used.,1
"[hotfix][yarn][client] Remove invalid numberTaskManagers from ClusterSpecification.After FLIP-6, we can no longer specifiy number of task managers from client side on active deployment. Thus numberTaskManagers in ClusterSpecification is invalid.This also includes the following changes:- YarnClusterDescriptor#validateClusterResources no longer validate whether yarn have enough resource for the flink cluster, because the total resource requirements of the flink cluster is not known.- Remove parallelism from yarn properties file, because we can no longer infer the parallelism from numberTaskManagers * slotsPerTaskManager.",5
"[FLINK-15598][yarn] Remove unnecessary cluster specification validation in YarnClusterDescriptor#deployInternal.Currently, the only thing YarnClusterDescriptor#validateClusterSpecification does is to validate that ClusterSpecification#taskManagerMemoryMB and flinkConfiguration together are valid for creating TaskExecutorResourceSpec.However, such validation is already covered by AbstractContainerizedClusterClientFactory#getClusterSpecification.",1
"[FLINK-15598][yarn] Do not overwrite configuration with cluster specification in YarnClusterDescriptor#startAppMaster.ClusterSpecification is generated from configuration at the first place, in AbstractContainerizedClusterClientFactory. It does not make sense to write the values back.We are aware that ClusterSpecification#taskManagerMemoryMB might be updated in YarnClusterDescriptor#validateClusterResources, which is before reaching YarnClusterDescriptor#startAppMaster. However, this will only happen if the TM process memory is configured smaller than Yarn minimum allocation. While using the original process memory size may lead to waste, it should not cause any serious problems or failures. On the other hand, overwriting the process memory size may lead to failures due to memory configuration conflicts, of which the reason could be implict to the users. Thus, we believe throwing a warning on process memory less than Yarn minimum allocation but not overwriting it would be enough.This closes #10863.",5
[FLINK-15623][build][python] Exclude code style check of generation code in PyFlink.This closes #10876.,2
[hotfix][javadocs] Correct add() return type,1
[FLINK-15615][docs] Fix reported file sink consistency guarantees,2
[hotfix][build] Remove unused depMgmt entry,1
[FLINK-14163][runtime] Enforce synchronous registration of produced partitions,1
[FLINK-14703][e2e] Port the Kafka SQL related tests.,3
"[FLINK-15616][python] Move boot error messages from python-udf-boot.log to taskmanager's log filePreviously, the boot error messages are printed in the log file(python-udf-boot.log) which is very hardto locate. This commit prints the error messages into the taskmanager log file to make it more user-friendly.This closes #10870.",1
[FLINK-15638][release][python] Change version of pyflink to the release version when creating release branch,1
[hotfix][conf][tests] Introduce factory method,5
[FLINK-15458][conf][tests] Separate options discovery and well-definedness check,5
"[FLINK-15458][conf][docs] Introduce SuffixOption annotationThey key of a SuffixOption is only a suffix, with the prefix being determined at runtime.In the case of reporters the prefix is ""metrics.reporter."" with a user-provided infix.For these options it doesn't make sense to check whether they are clashing with other options;in practive this is entirely dependent on the prefix.",0
[FLINK-14831][metrics][docs] Generate InfluxDB config docs,2
[FLINK-15479][jdbc] Override explainSource method for JDBCTableSource to fix project pushdown (#10769),0
[FLINK-15650][python][doc] Improve the udfs documentation of the Python API,2
[FLINK-15537][table-planner-blink] Fix code generation to use BinaryRow instead of GenericRow for distinct keysCode generation should use BinaryRow instead of GenericRow for distinct keys to have a consistent behavior of equals and hashcode. Because the distinct key will be deseraizlied as BinaryRow from state when job recovery. This closes #10815,1
[FLINK-15630][python][doc] Improve the environment requirement documentation of the Python API. (#10884),2
[FLINK-15657][python][doc] Fix the python table api doc link,2
"[FLINK-15577][table-planner] Add Window specs to WindowAggregate nodes' digestsThe RelNode's digest is used by the Calcite HepPlanner to avoid addingduplicate vertices to the graph. If an equivalent vertex was alreadypresent in the graph, then that vertex is used in place of the newlygenerated one.This means that the digest needs to contain all the informationnecessary to identifying a vertex and distinguishing it from similar- but not equivalent - vertices.In the case of the `WindowAggregation` nodes, the window specs arecurrently not in the digest, meaning that two aggregations with the samesignatures and expressions but different windows are consideredequivalent by the planner, which is not correct and will lead to aninvalid Physical Plan.This commit fixes this issue and adds a test ensuring that the windowspecs are in the digest, as well as similar aggregations on twodifferent windows will not be considered equivalent.This closes #10854",3
"[FLINK-15577][table-planner-blink] Add different windows tests to blink plannerThe Blink planner doesn't seem to be subject to the bug described inFLINK-15577. For safety, we also add the tests to ensure no regressionis possible that would introduce the issue in the Blink planner.",2
[FLINK-15575] [filesystems] fix shading of azure filesystem,5
[FLINK-15675][python][docs] Add exception and documentation that Python UDF is not supported in old Planner under batch modeThis closes #10907,1
[FLINK-15599][table] SQL client requires both legacy and blink planner to be on the classpathThis closes #10878,2
[FLINK-15497][table-planner-blink] Reduce outputs when rank number is not required in Retractable TopN (#10823),1
[FLINK-15631][table-planner-blink] Fix equals code generation for RAW and TIMESTAMP typeThis fixes generic types can't be used as the result of an AggregateFunction in Blink planner.This closes #10896,2
[FLINK-15637][state backends] Make RocksDB the default store for timers when using RocksDBStateBackendThis closes #10893.,5
[FLINK-15700][python][doc] Improves the Python API Tutorial docThis closes #10911.,2
[FLINK-15700][python][doc] Improves the Python API Tutorial doc,2
[hotfix] Introduce builder for checkpoint coordinator to deduplicate test codes[hotfix] Normalize variable name of CheckpointCoordinatorTriggeringTest,3
[hotfix] Normalize variable name of CheckpointCoordinatorTriggeringTest,3
[FLINK-13905][checkpointing] Unify all error handlings of checkpoint failureThere are so many similar entrances for error handling of checkpoint failure.So here unified these methods into abortPendingCheckpoint(s).,0
"[FLINK-13905][checkpointing] Redefine the behavior if there are too many pending checkpointsThis is not just a pure renaming. The semantics has been changed a bit.If there are too many in-flight checkpoints, the current checkpointwill fail, and the periodic triggering will be suspended. This stays the sameas it used to be before.From now on, there will be no queued semantics. If an in-flight checkpointends its lifecycle, it will try to resume periodic triggering, but noqueued checkpoint will be resumed anymore, as it was in the past.",1
[hotfix] Fix broken test utils caused by FLINK-12039,2
[hotfix] Introduce helper method FutureUtils#getWithoutException,1
[FLINK-13905][checkpointing] Separate checkpoint triggering into severalasynchronous stages.,2
[FLINK-15549] Fix Integer overflow in ResettableIterator. (#10903)The ResettableIterator had a data overflow problem if the number of elements in a single input exceeded Integer.MAX_VALUE.,0
[FLINK-15278][docs-zh] Update Chinese version StreamingFileSink docThis closes #10868.,2
[hotfix][tests] Remove legany codes from CheckpointBarrierAlignerTestBase,3
"[FLINK-15444][runtime] Make the component AbstractInvokable in CheckpointBarrierHandler NonNullThe current component AbstractInvokable in CheckpointBarrierHandler is annotated as @Nullable. Actually in real code path it is passed via the constructor and never be null.The nullable annotation is only used for unit test purpose. But this way would mislead the real usage in practice and bring extra troubles, because you have to alway checkwhether it is null before usage in related processes.We can refactor the related unit tests to implement a dummy AbstractInvokable for tests and remove the @Nullable annotation from the related class constructors.",4
"[FLINK-15355][plugins] PluginLoader allows access to JDK9 modules.With Java9, classes that have moved to modules are not accessible through the bootstrap classloader anymore. The platform classloader is the equivalent to the Java8 bootstrap classloader and now used for plugins.",1
[FLINK-15355][s3]Plugins now use multi-release mechanism to ship jaxb for Java 9+.,1
[FLINK-15601] Remove unused constant field NUM_STOP_CALL_TRIES in Execution (#10906),1
[FLINK-15686][sql-client] Use old type system in CollectStreamTableSink,5
[hotfix] Clean up in TaskExecutorResourceUtilsTest.,3
[FLINK-15375][core] Introduce MemorySize#toHumanReadableString.,2
[FLINK-15375][core][runtime] Print MemorySize with human readable string in logs and error messages.This include changes in:- ResourceSpec- ResourceProfile- TaskExecutorResourceSpec- TaskExecutorResourceUtils,2
[FLINK-15375][core] Add factory method for creating MemorySize from mebibytes.This closes #10785.,1
"[FLINK-13758][client] Support to register DFS files as distributed cacheAll the Flink Standalone, Yarn, Mesos, Kubernetes session clusters are using RestClusterClient#submitJob to submit a job to an existing session. Before this commit, the Flink client will hang when trying to register DFS artifacts as distributed cache for session cluster.",1
[hotfix][kubernetes] Only check the expected env vars in Fabric8ClientTest#testCreateFlinkMasterDeployment,3
"[FLINK-15632][kubernetes] Make Flink client always uses Kubernetes service to contact with jobmanager via rest clientThe K8s service is designed for accessing the jobmanager out of K8s cluster. So Flink client will not use HA service to retrieve address of jobmanager. Instead, it always uses Kubernetes service to contact with jobmanager via rest client. So firstly, we will get the RestOptions#ADDRESS and RestOptions#PORT from the Kubernetes service and set the values to configuration. Then we will use the updated configuration to construct a StandaloneClientHAServices for RestClusterClient.",5
"[FLINK-15632][kubernetes] Set JobManagerOptions#ADDRESS to the pod ip address when HA mode enabledFor non-HA cluster, JobManagerOptions#ADDRESS has be set to Kubernetes service name on client side. See KubernetesClusterDescriptor#deployClusterInternal. So the TaskManager will use service address to contact with JobManager.For HA cluster, JobManagerOptions#ADDRESS will be set to the pod ip address. The TaskManager uses Zookeeper or other high-availability service to find the address of JobManager.",1
"[FLINK-15632][kubernetes] Update the cluster id and high-availability jobmanager port when HA enabledWhen HA enabled, the config option HighAvailabilityOptions.HA_CLUSTER_ID will be set to the user specified cluster id. And if the config option HighAvailabilityOptions.HA_JOB_MANAGER_PORT_RANGE is not set or with value 0, it will be updated to the value of JobManagerOptions.PORT.",5
[FLINK-15612][table] Refactor DataTypeLookup to DataTypeFactory,5
[FLINK-15612][table] Integrate data type factory into catalog manager,2
[FLINK-15612][table-planner-blink] Propagate the data type factory in the plannerThis closes #10917.,5
[FLINK-15636][python] Support Python UDF in old planner under batch modeThis closes #10913.,1
[FLINK-15519][configuration]Preserve logs from BashJavaUtils and make them part of TM logsWe build a separate jar for BashJavaUtils with bundled log4j classes anda configuration that logs to the stdout. Using this jar we run theutility to capture the output. Out of the last line we extract jvmparameters. The rest we pass as an environment variable (INHERITED_LOGS)to the TaskManager process.As part of the EnvironmentInformation printing we log whatever waspassed through the INHERITED_LOGS in the TM/JM process.This closes #10850,2
[FLINK-15684][docs] Add taskmanager.memory.flink.size to common optionsThis closes #10916,2
[FLINK-15684][docs] Regenerate documentation,2
[FLINK-15726] [Blink Planner] [hotfix] Fix error message inStreamExecTableSourceScan & BatchExecTableSourceScanThis closes #10914,0
"[FLINK-15150][tests] Prevent job from reaching terminal stateExplicitly enable restarts; this is necessary since the shutdown may result in the job failing and hence being removed from ZooKeeper.What happens to running jobs if the Dispatcher shuts down in an orderly fashion is undefined behavior.By allowing restarts we prevent the job from reaching a globally terminal state, causing it to be recovered by the next Dispatcher.",1
[hotfix][zookeeper] Log changes to SchedulingState,4
[hotfix] Correct logging statement in TaskExecutorResourceUtils,2
[minor] Remove outdated mention of getPlan() from CliFrontendParser,1
[FLINK-15276] Update executor CLI name and help message,5
"[FLINK-15276] Regenerate bin/flink output in docs/ops/cli.mdWe changed the executor help messages slightly and removed some outdatedmentions of getPlan() in previous commits. This also updates the outputof bin/flink to reflect some earlier changes, for example for the -saeflag.",4
[FLINK-15276] Add method for listing executors to PipelineExecutorServiceLoaderThe first use case for this is listing the available executors in the CLI.,1
[FLINK-15276] List available executors in ExecutorCLI,2
[FLINK-15276] Add introduction text about executors in cli.md,1
[FLINK-15276] Bring cli.zh.md in line with recent changes to cli.md,4
"[FLINK-15690][core] In environments, call configure() in constructors with passed ConfigurationThis change means it is possible to instantiate ExecutionEnvironment &StreamExecutionEnvironment and apply a Configuration. Effectively thisenables configuring ExecutionConfig, CheckpointConfig and parametersfrom environment via flink-conf.yaml.This closes #10925",5
[FLINK-15690][docs] Updated CACHED_FILES doc,2
[FLINK-15689][table] Configure ExecutionEnvironment from BatchTableEnvironment,5
"[FLINK-15552][table] Use thread context classloader to find factories in TableFactoryServiceThis fixes the problem that `--library` and `--jar` doesn't work for DDL in SQL CLI, because the user's classloader is not passed to the TableFactoryService. A long-term solution is not to use the context-classloader which is tracked by FLINK-15635.This closes #10874",2
"[FLINK-15487][table-common] Make TypeInference mandatory for function definitionsThis makes TypeInference mandatory for function definitions and updatesFunctionDefinition, UserDefinedFunction, and ScalarFunction to FLIP-65.This closes #10928.",1
[FLINK-15692][state] Enable limiting RocksDB memory consumption by defaultTurn on state.backend.rocksdb.memory.managed to enable memory limit on RocksDBThis closes #10921.,5
[hotfix] Fix checkstyle violation in TestingResourceManagerGateway,3
[FLINK-14742][test] Harden TaskExecutorTest#testSubmitTaskBeforeAcceptSlotRemove the access to TaskExecutor's internal state from the test thread. Instead we relyon the public API of the TaskExecutorGateway and its collaborators to verify the test.This closes #10927.,3
[FLINK-15602][table-planner-blink] Padding zeros for TIMESTAMP type to respect the precision when casting timestamp to varcharThis closes #10877,2
[FLINK-15368][e2e] Add end-to-end test for controlling RocksDB memory usageThis closes #10930,1
"[FLINK-15368][e2e] (follow-up) Minor improvements to the RocksDB Memory Control e2e testSome cleanups in RocksDBStateMemoryControlTestProgram  - skip "".returns"" when not necessary  - peel off command line parameter abstraction earlier (don't pass ParameterTool to functions).  - Add proper class-level JavaDoc.Remove script from 'run-nightly-tests.sh' (unused) and add to a different CRON split file instead.Some improvements to the test script  - Added comment explainig where the upper limit value comes from  - Added fixed managed memory size, so the test is not affected by changes in the managed memory fraction settings  - Always log measured cache size for information",5
"[hotfix][tests] Setup closable resources in BeforeClassHaving static final resources that are closed in an @AfterClass method prevents the test from being run in a loop within the IDE, since the static fields aren't re-initialized.",5
"[FLINK-15691][tests] Remove runInTaskExecutorThreadAndWait()The method did not achieve the desired effect of running the action in the TE main thread. Given that the test has not shown instabilities despite this we can conclude that these actions can just be executed in the tests main thread instead.Additionally, this test removes/replaces accesses to the JobManagerTable of the TaskExecutor.",4
[FLINK-15592][hive] Add black list for Hive built-in functionscloses #10894.,1
[FLINK-15603][metrics] Add checkpointStartDelayNanos metricThe time in nanoseconds that elapsed between the creation of the last checkpoint andthe time when the checkpointing process has started by this Task. This delay showshow long it takes for a first checkpoint barrier to reach the task. Back-pressure willincrease this value.,1
"[FLINK-15275] Deprecate ineffectual sysoutLogging CLI optionWe don't remove it completely, so as not to break existing tooling butwe don't print it in the CLI help anymore and don't show it in cli.md.",4
[FLINK-14701][runtime] Fix MultiTaskSlot to not remove slots which are not its childrenThis closes #10867.,4
[FLINK-15741][docs][TTL] Fix TTL docs after enabling RocksDB compaction filter by default,5
[hotfix] Remove 'null if not allocated' from TaskSlot comments,4
[hotfix] Segregate TaskSlotPayload interface from Task for TaskSlot and TaskSlotTable,0
[FLINK-15247][Runtime] Wait for all slots to be free before task executor services shutdown upon stopping[FLINK-15247][Runtime] Improve test coverage for slot allocation and task submission in TaskSlotTable[hotfix][Runtime] Introduce TaskSlotTable interface[hotfix][Runtime][Tests] Introduce StubTaskSlotTable for tests to replace mockito mocks[hotfix][Runtime][Tests] Rework TaskExecutorTest#testTaskInterruptionAndTerminationOnShutdown to testTaskSlotTableTerminationOnShutdownThis closes #10682.,3
"[FLINK-15751][tests] Ignore exceptions in RocksDB Memory Limiting e2e testThis test does not rely on job execution success, but verifies the correctness in the test scripts.The occastional exceptions are unrelated and result of the cancellation process, hence can be ignored.(Cleaning these log pollution exceptions up is a separate unrelated issue)",0
[hotfix] Align the parameter pattern of retry_times with retry_times_with_backoff_and_cleanupThis closes #10668.,4
"[FLINK-14894][core][mem] Do not explicitly release unsafe memory when managed segment is freedThe conclusion at the moment is that releasing unsafe memory, while potentially having a link to it in Java code, is dangerous. We revert this to rely only on GC when there are no links in Java code. The problem can happen e.g. if task thread exits w/o joining with IO threads (e.g. spilling in batch job) then the unsafe memory is released but it can be written w/o segfault by IO thread. At the same time, other task can allocate interleaving memory which can be spoiled by that IO thread. We still keep it unsafe to allocate it outside of JVM direct memory limit to not interfere with direct allocations, also it does not make sense for RocksDB native memory (also accounted in MemoryManager) to be part of direct memory limit.The potential downside can be that over-allocating of unsafe memory will not hit the direct limit and will not cause GC immediately which will be the only way to release it. In this case, it can cause out-of-memory failures w/o triggering GC to release a lot of potentially already unused memory.If we see the delayed release as a problem then we can investigate further optimisations, like:- directly monitoring phantom reference queue of the cleaner (if JVM detects quickly that there are no more reference to the memory) and explicitly release memory ready for GC asap, e.g. after Task exit- monitor allocated memory amount and block allocation until GC releases occupied memory instead of failing with out-of-memory immediatelyThis closes #10940.",0
[FLINK-15754][docs] Remove config options table.exec.resource.*memory from docs,2
[FLINK-10819] Replace with the Flink's Deadline implementationRemove Scala's Deadline and replace it with Flink's own version.This closes #10950.,2
[FLINK-15739] Fix TypeSerializerUpgradeTestBase on Java 12The problem was that some of the relocated classes inPojoSerializerUpgradeTest have enums in them. Java 12 introduced theEnumDesc class and enums will have an inner subclass of this definedthat does not have a ClassLoader. We now filter out classes that don'thave a classloader in the ClassRelocator because these classes don'thave bytecode that we could relocate.,1
"[FLINK-15751][task] Let all exceptions propagate from the StreamTask#runMailboxLoopIf the StreamTask is being cancelled, let the Task handle the exception.",0
[hotfix][minicl] Set default managed memory to 128mb for mini cluster,5
[hotfix] Rename TaskExecutorResourceSpec to TaskExecutorProcessSpec,0
"[FLINK-15763][Runtime] Running TM checks only necessary resource cofig, set to default for local executionFLIP-49 (FLINK-13980) calculates memory setup to start TM process. Atm, we reuse this logic to getnecessaryresource configuration optionsin running TM, although we do not need the fullTaskExecutorResourceSpec which can be renamed toTaskExecutorProcessSpec.In case of local execution in mini cluster, the TM process is started outside of Flink framework and nothing is pre-calculated. It means that any configured process or Flink memory size can make no sense and can be ignored then to make things simpler and more explicit. Also the result of FLIP-49 calculation can contradict to the default values and other derived FLIP-49 memory components are not used by TM internally anyways.If some necessary options are not set, we can set them to reasonable defaults.Theconfiguration optionsrequired for running TM, which are expected to be calculated and set before its start, are the following (with defaults for local execution):- cpu cores (potentially for FLIP-56,FLINK-14187, default: Double.MAX_VALUE- task heap memory (potentially for FLIP-56,FLINK-14187, default: MemorySize.MAX_VALUE)- task off-heap memory (potentially for FLIP-56,FLINK-14187, default: MemorySize.MAX_VALUE)- network memory (default: 64Mb)- managed memory (default: 128Mb)Additionally, we refactor TM runner to not reuse current FLIP-49 computation but just check that thenecessary options are set and createTaskExecutorResourceSpec which contains only them.This closes #10946.",1
[hotfix] Fix checkstyle violations in TaskExecutorResourceUtilsTest,3
"Revert ""[FLINK-14894][core][mem] Do not explicitly release unsafe memory when managed segment is freed""This reverts commit 6dcaae0e403a8d7322d5c63e82b01ed24340d984 because it causes Travis to fail.The reasons seems to be too much memory pressure because GC seems to happen too rarely.",1
[FLINK-15701][Travis] Retries when uploading to transfer.sh failsThis closes #10951.,0
[FLINK-15681] Remove legacy ExecutionAndAllocationFuture classThis closes #10949.,4
[FLINK-15617] Remove useless JobRetrievalExceptionThis closes #10948.,1
[FLINK-15274][docs]Added separate plugin page.Plugin page will be expanded in the future for connectors and other types.Central page to point someone who asks: what are plugins?,2
[hotfix][web] Rename Checkpoint metric fieldsNewer names are shorter and less abreviated while preserving or improving the readability.,1
[hotfix][rest] Introduce MinMaxAvgStatistics.valueOf helper method,0
[hotfix][rest] Remove redundant comments in TaskStateStats,3
[hotfix][rest] Remove redundant comments in SubtaskStateStats,3
[FLINK-15603][web] Expose checkpointStartDelayNanos metric in the WebUI,2
[hotfix][tests] Make JarHandlers re-usable,0
[FLINK-15651][tests] Refactor JarHandlerTest,3
[FLINK-15768] Consolidate executor-related classes in flink-client,2
[FLINK-15628][rest] Create webSumissionHandlers List with default capacityThis closes #10882.,0
[hotfix][javadocs] Fix OutputTag example,0
[hotfix][runtime] Add missing space to exception message,1
[FLINK-15743][docs] Add release notes for Flink 1.10,2
"[FLINK-15487][table] Allow registering FLIP-65 functions in TableEnvironmentUpdates all catalog related interfaces to FLIP-65. It also continues FLIP-64 byexposing new interfaces in table environment for registering functions oftemporary/system/catalog kind. Furthermore, it adds early class validationto the function catalog.The first functions will be fully functional once the code generator has beenupdated.This closes #10942.",5
[FLINK-15738][build] Bump powermock to 2.0.4,2
"[FLINK-9272][metrics][datadog] Rename counter type to countThe Datadog metric ""counter"" was renamed to ""count"". The ""counter""type still works, but support for it might be removed one day by Datadog.To align the implementation with their latest documentation the typeis renamed.",2
[FLINK-15623][checkstyle] Exclude target directory,1
[hotfix][checkstyle] Remove outdated checkstyle suppressions,5
[FLINK-13689] [Connectors/ElasticSearch] Fix thread leak in Elasticsearch connector when cluster is down,0
[FLINK-15627][cep] Correct the wrong naming of compareMaps in NFATestUtilities,3
[FLINK-15810] Add more description for FlinkKafkaProducerMigrationOperatorTest,3
[FLINK-15837] Add proper NOTICE file to flink-kubernetesThis closes #10986.,3
[FLINK-15840][table-planner-blink] Fix ClassCastException when use tEnv.from for temp/catalog table (#10989),2
[hotfix][k8s] Correct relocation patterns in flink-kubernetes,2
[FLINK-15806][yarn] Log recommended way how to stop a detached Yarn session clusterThe recommended way to shut down a detached Yarn session cluster is to reattach viathe yarn-session.sh script and to issue a stop command. This will ensure that alljob artifacts and temporary files are properly cleaned up.,4
[FLINK-15806][doc] Update yarn documentation to include proper way of stopping a detached Yarn sessionThis closes #10964.,2
[FLINK-15797][k8s] Reduce log noise of Fabric8FlinkKubeClientThis commit reduces the log noise of the Fabric8FlinkKubeClient by changing the log levelfrom info to debug.This closes #10965.,0
[FLINK-15789][kubernetes] Do not wrap the InterruptedException and throw a different one in ActionWatcher.awaitThis closes #10970.,2
[FLINK-15694][docs] Remove HDFS Section of Configuration PageThis close #15694,1
[FLINK-15697][docs] Move python options from general configuration page to table config options pageThis closes #10957,1
[FLINK-15824][docs] Generalize CommonOption,2
[hotfix][docs] Clean up deprecation/unused warnings in tests for ConfigOptionsDocGenerator,5
"[FLINK-15824][docs] (follow-up) Simple improvements/cleanups on @SectionOption  - Rename '@SectionOption' to '@Section' for brevity  - Rename '@Section.sections()' to '@Section.value()'    That way, the method name can be skipped when only sections (no positions) are specified,    which should is the common case after config documentation rework is complete.  - Adjust test for @Section annotation",3
"[FLINK-15698][docs] Restructure the Configuration docs  - Grouping options by semantics and functionality, rather than by defined class.  - Splitting between ""normal/common options"" and options that should only be necessary    for trouble-shooting.",1
[FLINK-15695][docs] Remove outdated background sections from configuration docs,2
[FLINK-14495][docs] Add documentation for memory control of RocksDB state backend,5
"[FLINK-14495][docs] Reorganize sections of RocksDB documentationThis moves most in-depth RocksDB contents to te State Backends docs.The ""tuning large state"" docs only refer to actual tuning and trouble-shooting.",2
[FLINK-14495][docs] Synchronize the Chinese document for state backend with the English version,2
"[FLINK-15010][network] Add shut down hook to ensure cleanup netty shuffle directoriesWhen the cluster is shut down in standalone mode, the task manager is shut down via SIG_TERM signal. In this case, the shuffle directories created by FileChannelManager would not be removed finally.To solve this issue, we register the shut down hook before creating directories in the constructor of FileChannelManagerImpl.This closes #10736",2
[hotfix][python] Remove unused variable from class AbstractPythonFunctionRunner,1
[FLINK-15494][table-planner-blink] Fix incorrect time field index in LogicalWindowAggregateRuleBaseThis closes #10784,2
[FLINK-15658][table-planner-blink] Fix duplicate field names exception when join on the same key multiple times (#11011),0
[hotfix] [javadoc] RocksFullSnapshotStrategy remark DESCRIPTION correctly,2
[FLINK-15864][k8s] Upgrade jackson-databind dependency to 2.10.1This closes #11000.,5
[FLINK-15807][docs] Add Java 11 to supported JDKsVersion is already declared in root pom.,1
[FLINK-15614][docs] Consolidate Hadoop documentation,2
[hotfix][docs] Fix missing double quotes in catalog docscloses #11008,2
[FLINK-15858][hive] Store generic table schema as propertiesThis closes #11012,2
[FLINK-15706][table-planner-blink] Fix LastValueAggFunctionWithOrderTest compilation error due to incompatible typesThis partially reverts the commit dcc1330375826b779e4902176bb2473704dabb11 and uses the initial approach from #10158 of using Enclosed annotation. The problem with the TestSpec approach was that the top level classes shouldn't use generics as they are stripped when instantiated by JUnit runner which may lead to generic signature mismatch.This closes #10915,1
[FLINK-15706][table-planner-blink] Reorder and split into sections classes in aggfunctions tests.,3
[FLINK-15872][javadoc] Remove unnessary javadocs in InputFormat,2
[FLINK-15335] Replace `add-dependencies-for-IDEA` profile,2
[hotfix][table-common] Fix invalid BYTES data type extraction,4
[hotfix][table] Fix various type inference issues,0
[hotfix][table-common] Add 'use argument' type strategy,1
[FLINK-15487][table] Update code generation for new type inferenceThis updates the code generation for the new type inference and thuscompletes FLINK-15487. Scalar function work with the types supportedby the planner. Tests added in this PR only test basic behavior. Wewill need more tests per data type. But this is a follow up issue.This closes #10960.,0
[FLINK-15863][docs] Fix docs stating that savepoints are relocatable,2
[FLINK-15905][runtime] Fix race condition between allocation and release of OpaqueMemoryResource,0
[FLINK-15916][docs] Remove outdated sections for Asnc Snapshots and Network buffers from Tuning Checkpoints and Large State,1
[FLINK-15868][kinesis] Resolve version conflict between jackson-core and jackson-dataformat-cbor,5
[FLINK-15868] Pin jackson-dataformat-smile dependency to 2.10.1,5
[FLINK-15868] Pin jackson-dataformat-yaml dependency to 2.10.1,5
[hotfix][es][tests] Remove unused variableSubsumed by #getUserConfig(),5
[hotfix][es][tests] Refactor utils,4
[FLINK-15868][es] Add tests for different formats,3
[FLINK-15868] Bump flink-table-planner jackson dependencies to 2.10.1,2
[FLINK-15868] Pin snakeyaml dependency in flink-connector-elasticsearch5 to 1.25This closes #11006.,2
[FLINK-15921] [python] Add version range of grpcio. (#11024),1
[FLINK-11373] Don't cut of error message in CliFrontend,0
[FLINK-15811][task] report CancelTaskException on SourceStreamTask cancellationThread interruption and InterruptedException are implementation detailsand shouldn't be exposed. Throw CancelTaskException instead which is a part of informal contract.,5
[hotfix][docs] Improve description of 'high-availability.jobmanager.port' config option.,5
"[hotfix][runtime] Clean up minor issues in TaskInformation  - Checkstyle violations in JavaDocs  - Remove use of 'checkNotNull' on primitive types, which looks like a confusion/oversight.    It is not checking anything and results in unnecessary boxing/unboxing.",5
[FLINK-15920][build] Show thread names in logs by defaultThis closes #11023,2
[hotfix][runtime] Small improvements in log messages for Task and RocksDB Backend,5
[hotfix][build] Move jaxb copy into executionThis allows us to specify multiple executions that copy different file sets without having to worry what side-effects it may have.,1
"[hotfix][tests] Add ""javax.management.*"" to PowerMock ignore listThe test otherwise logged a LinkageError since it tries to load the MBeanServer interface which was already loaded.",2
[hotfix][build] Add depMgmt entry for flink-shaded-hadoopSome noise reduction.,2
"[hotfix][build][sql] Remove slf4j/log4j dependenciesThe SQL client does not require explicit slf4j/log4j dependencies.slf4j-api is already defined in the root pom, whereas the log4j-related dependencies are just not necessary since the distribution provides them.",1
"[hotfix][build] Remove unnecessary log4j filesThese log4j.properties files could only be used when adding a main() method to production code,but this could be done through a test anyway.",3
[FLINK-15181][docs] Fix minor typos and mistakes in table documentationThis closes #10521,2
[FLINK-15929][python] Update the version limit of grpcio to 1.26.0This closes #11027,5
[FLINK-15937][python] Update the Development Status to 5 - Production/Stable (#11028),5
[hotfix][travis] Remove outdated activation properties,5
"[FLINK-15785][travis][e2e] Rework E2E test activations- consolidate travis activations in .travis.yml- introduce dedicated profile for each category to reduce verbosity- use gmavenplus-plugin to merge inclusion/exclusions across profiles- add java11 profile (i.e., don't rely on exclusion setup in root pom)- disable tests with Hadoop category by default- add Hadoop activations to e2e profiles",2
[FLINK-15685][e2e] Kafka SQL test requires Hadoop,1
[hotfix][documentation] Fix wrong time semantics description,0
[FLINK-15897][python] Defer the deserialization of the Python UDF execution results,2
[FLINK-15919][core][mem] MemoryManager shouldn't allow releasing more memory than reservedThis closes #11025.,1
"[hotfix][build][e2e] Invert Java 11 activation conditionIf we are not running on Java 11, then tests failing on Java 11 should still be run. Conversely, these tests should be excluded on Java 11.",3
[hotfix][build][e2e] Remove empty include/exclude propertyThey shadow the properties set by the groovy script.,1
[hotfix][build][e2e][addendum] Remove empty include/exclude property,5
[hotfix][e2e] Add retry timeout to kafka broker startup,1
[hotfix][build system] Improve logging in maven setup script,1
[hotfix][travis] Improve Maven dependency download stability,1
[hotfix][travis] Use echo instead of printfAzure exhibits some problems when using printf.,1
[hotfix][table] Convert FlinkCalciteSqlValidator to JavaConverts the SqlValidator extension to Java. This class is likelyto extend Calcite. So it makes sense to have it in Java to quicklycopy paste code.,1
[hotfix][table] Simplify FlinkCalciteSqlValidatorThis closes #10981.,5
[FLINK-15618][runtime] Remove unused JobTimeoutException,1
"[FLINK-15935][table] Fix watermark can't work when depending both on flink planner and blink planner in projectThe reason is that we didn't sync the fixing of org.apache.calcite.sql.validate.ParameterScope to flink-planner. When an application project depends flink-planner and blink-planner at the same time, the classloader may use the ParameterScope from Calcite instead of from blink planner, which leads to this exception.This closes #11030",2
[FLINK-15935][example] Add Streaming Window SQL example,1
[FLINK-14270][web] Support to display more metrics at once (#10689),1
[hotfix][travis] Fix caching of misc jobAdding the e2e-pre-commit profile activation only to the misc profile broke the caching,2
[FLINK-15902][python][docs] Improve the Python API documentation adding the version an API was introducedThis closes #11035,1
[hotfix][example] Add StreamWindowSQLExample.jar to dist (#11036),1
[FLINK-15942] Do not log huge/infinite cpu/memory resources in profiles,2
[hotfix] Let ResourceProfileTest extend TestLogger,3
[FLINK-15942][tests] Simplify ResourceProfileTest testsThis closes #11039.,3
[hotfix][docs]  Fix some typos in state_processor_api docs (#11033),2
[hotfix][travis] Add missing jdk11 classifier,1
[hotfix][travis] Reduce depth for walkthrough module detectionIf the module was built beforehand a pom.xml would be detected in the target directory.,1
[FLINK-15913][python] Add Python TableFunction Runner and Operator in old planner (#11020),1
[hotfix][docs] Fix Readme Description for the State Machine Example (#11046),0
[hotfix][e2e] Reduce e2e-hadoop to exclusionAlso having it work as an include is confusing.,5
[FLINK-15417][e2e] Change the access permission of files modified in mesos constainerThis closes #10746.,2
[FLINK-15741][docs-zh][TTL] Fix TTL docs after enabling RocksDB compaction filter by defaultThis closes #11022.,5
"[hotfix][runtime,test] refactor ContinuousFileProcessingRescalingTest to prepare for ContinuousFileReaderOperator migration to Mailbox Execution model",2
[FLINK-13955][runtime] use mailbox execution model in ContinuousFileReaderOperator.Motivation: allow to avoid explicit synchronization and eventually to remove StreamTask.getCheckpointLock().ContinuousFileReaderOperator was changed significantly to avoidthe currently necessary thread and extra synchronization between blocking and non-blocking code(e.g.  format.reachedEnd and nextRecord)Performance is lower by ~15% because of the overhead of enqueueing and processing each mail (instead of just loop).,1
[hotfix] Remove deadcode in ExecutionGraph#restart,4
"Revert ""[hotfix] Remove deadcode in ExecutionGraph#restart""This reverts commit 5f38f91a602201c4f52ac8febe13f9d72367a8c5.",4
[hotfix][example] Copy StreamWindowSQLExample.jar to dist/examples/table,0
[FLINK-15917][runtime] Fix that the root exception is not shown in Web UI,0
"[FLINK-15918][runtime] Fix that 'uptime' metric is not reset after restartThe 'uptime' metric is the time difference between 'now' and the timestamp whenthe job transitioned to state RUNNING. The new scheduler until now nevertransitioned out of status RUNNING when restarting tasks which had the effectthat the 'uptime' metric was not reset after a restart. This introduces newstate transitions to the job. We transition the job status to RESTARTING if atleast one ExecutionVertex is waiting to be restarted, and we transition fromRESTARTING immediately to RUNNING again after the restart.This closes #11032.",1
[FLINK-15143][docs] Add new memory configuration guide for FLIP-49,5
[FLINK-15143][docs] Add tuning and troubleshooting guides for memory configuration,5
[FLINK-15143][docs] Add migration guide from pre-FLIP-49 memory config,5
[FLINK-15875][python] Bump Beam to 2.19.0This closes #11050.,2
[FLINK-15875][python] Remove the ProcessManager which is copied from Beam 2.19,4
[FLINK-15546][table-planner-blink] Fix obscure error message from ScalarOperatorGens::generateCast (#11021),1
[FLINK-15933][catalog][doc] Update content of how generic table schema is stored in hive via HiveCatalogcloses #11029,2
"[FLINK-15561] Unify Kerberos credentials checkingBefore, we had duplicate code in HadoopModule and YarnClusterDescriptor,now we use the same code for both. That code is refactored to a util.",4
[hotfix][task] Fix the comment typo in TwoInputStreamTask class,2
"[FLINK-15914][checkpointing][metrics] Miss the checkpoint related metrics for the case of two inputsWhen the StreamTwoInputSelectableProcessor was introduced before, it forgot adding the checkpoint related metrics in the constructor.But it did not cause any problems, because only the StreamTwoInputProcessor actually worked before.After StreamTwoInputProcessor is replaced by StreamTwoInputSelectableProcessor as now, this bug is exposed and we will not see thecheckpoint related metrics for the case of two inputs.The solution is to add these metrics while constructing the CheckpointBarrierHandler.",0
[FLINK-12484][runtime] remove checkpoint lock *usage* from production codeAfter b4aa6e lock is acquired for every mailbox action if needed.,4
[FLINK-12484][runtime] remove checkpoint lock testsAfter a3b6be905f lock is not managed by operatorsso the test aren't relevant anymore.,3
[FLINK-12484][runtime] push checkpoint lock from StreamTask to SourceStreamIntermediate tasks (not source/sink) don't acquire lock anymore(as they use single-threaded model).SourceStreamTask still has to have the lock to conform to the public API.MockStreamTask has the lock for compatibility with the existing tests.,3
[FLINK-15914][tests] Fix the fragile tests caused by race condition of multiple threads,1
[FLINK-15743][docs] Extend Flink 1.10 release notesThis closes #10997.,3
[FLINK-15862][kafka] Remove deprecated KafkaPartitioner,4
[FLINK-15646][kubernetes] Make kubernetes context configurableThis closes #10956 .,5
[FLINK-15995][table-planner-blink] Change TO_BASE64 operand type checker from ANY to STRINGThis can make the exception message more readable which can be thrown by Calcite instead of code generator. This closes #11058,1
[FLINK-15941] [format-avro] Create schema coder only once in RegistryAvroSerializationSchema,1
[FLINK-15994][table-planner-blink]Support byte array argument for FROM_BASE64 function (#11060),1
"[FLINK-15445][jdbc] Support new type system and check unsupported data types for JDBC table sourceThis bridges the JDBC table source to new type system to support precisions of types. In the meanwhile, this also adds a validation to check unsupported types and precisions by various dialects to avoid surprising results.This closes #10745",1
[FLINK-15990][table][python] Remove register source and sink in ConnectTableDescriptorThis closes #11055,4
[FLINK-15992][kafka][es] Use thread context classloader when finding TableFormatFactory (#11064),1
[hotfix][docs] Add 1.10 to list of previous docs,2
"[hotfix][build] Add safeguards against rebranded jaxb-api/javax.activation-api dependenciesWith jakarta EE having made their first releases projects may start transitioning to the re-branded versions.The package names are identical (for now?), so we should be fine as long as we ensure that at least one version is on the classpath.For the time being we stay on the ""original"" dependencies, but we may have to switch eventually.",1
[FLINK-15949][build] Harden jackson dependency constraints,2
[hotfix][javadocs] Add missing asterisk,1
[FLINK-16026][python] Limit the version of avro-python3This closes #11078.,2
[FLINK-15970][python] Optimize the Python UDF execution to only serialize the value (#11059),2
[FLINK-15982][e2e] Pick the right Flink version to fix the java quickstart testThis closes #11067,3
[hotfix][build] Downgrade groovy to 2.5.8The google mirror for some reason does not contain 2.5.9.,0
[FLINK-16004][build] Use correct parent,1
[hotfix][docs] show usage if wrong option is given,0
"[FLINK-13793][docs] build each language in a separate subprocessWhen not serving docs and just building them, e.g. via `./build_docs.sh`, wespawn sub-processes for each language build instead of running themsingle-threaded (jekyll currently does not support parallel builds).",1
[hotfix][docs] do not include build scripts in content generation,2
"[FLINK-15993] Move 404 ""refresh"" redirect into noscript block, add timeoutApparently, search engines penalize META refresh links and this getsaround it",1
[FLINK-15997] Make documentation 404 page look like a documentation page,2
"[minor][docs] Fix missing ""page"" text in redirect.html layout",0
[FLINK-16037][build] Bump dependency-analyzer to 1.11.1,2
[hotfix][build] Remove unused flink-test-utils dependencies,3
[hotfix][build] Remove redundant flink-test-utils-junit version/scope,3
[FLINK-15802][table] Bring input/output types of table functions closerRefactors the code generation around table functions such that return data typeand argument data type are read from the function at the same location insteadof reading each in a separate code generator. This adds an additional runtimecollector that is only responsible for result conversion.,1
"[FLINK-15802][table] Support new type inference for table functionsFurther develops the stack based on BridgingSqlFunction and the newtype inference. Similar to FLINK-15487, we don't test every data typecombination yet.This closes #11034.",5
[hotfix][web][build] Cleanup dependencies,4
"[FLINK-15402][csv, table] Expose disable quote character option to CSVformatThis closes #10697",2
[hotfix][runtime][tests] Use javax annotation,1
[hotfix][core][tests] Mark SerializerTestInstance with @IgnoreSome runners may attempt to run this class as a test.,3
[hotfix][build] Remove unused shaded-asm7 dependencies,1
[hotfix][build] Remove unused akka-testkit dependencies,3
[FLINK-16040][python] Change local import to global import (#11084),2
[FLINK-15913][python] Add Python TableFunction Runner and Operator in Blink plannerThis closes #11044.,2
[hotfix][docs] Add note SSL not enabled by default,0
[hotfix][tests] Add a TestingSchedulerFactory to help instantiating the scheduler in tests,3
"[FLINK-15099][runtime] Add Operator Coordinators and EventsOperator Coordinators are instances that exist once per operator. While the operators run on the TaskManagers, thecoordinator runs on the JobManager. The coordinator communicates via events with the operators, typicalls toassign work.The first user for those coordinators would be the new source interface.Further users we envision are sinks (for coordinated commits of metadata), or iterations (gather progress andsteer supersteps) as well as simple approximate alignments between streams (event time alignment).",5
[FLINK-16046][es] Drop Elasticsearch 2 connector,4
[FLINK-16053][python] Remove redundant metrics in PyFlink (#11089),2
[FLINK-16059][rest][docs] Order properties alphabetically,2
[FLINK-16065][core] Unignore FileUtilsTest.testDeleteDirectoryConcurrently(),3
[hotfix][tests] Adjust FileUtilsTest.testDeleteSymbolicLinkDirectory() to handle unsupported situations in Windows,1
[hotfix][build] Remove various unused test dependencies,3
[FLINK-14802][orc][hive] Multi vectorized read version support for hive orc readsupport vectorized read for hive 1.x.closes #10730,1
[hotfix][docs][conf] Add query service port to port section,1
[hotfix][docs][conf] Add query service port to port section,1
[hotfix][docs][conf] Setup logging for generator,2
[hotfix][docs][conf] Log included packages / excluded classesEases discoverability,2
[docs-sync] Synchronize the latest documentation changes into Chinese documents,2
[FLINK-15702][sql-client] Respect CLASSLOADER_RESOLVE_ORDER in sql-clientThis closes #10910 .,0
[hotfix][build system] broader search for YARN logs,2
[hotfix][e2e] harden elasticsearch test,3
[hotfix][e2e] Fix docker invocation in mesos tests,3
[hotfix] Harden kubernetes test,3
[FLINK-13978][build system] Add experimental support for building on Azure PipelinesThis closes #10976,1
[hotfix][docs] Regenerate documentation,2
[FLINK-16109][python] Move the Python scalar operators and table operators to separate package,1
"[FLINK-16049] Remove outdated ""Best Practices"" section from Application Development Section",5
[FLINK-15708] Add MigrationVersion.v1_10,1
[FLINK-16071][python] Introduce FlattenRowCoder to solve the performance issue of __get_item__ in Row,1
[FLINK-16113][table-planner-blink] ExpressionReducer shouldn't escape the reduced string value (#11108),2
[FLINK-16118][table-planner-blink] Ignore order for FunctionITCase.testDynamicTableFunction,3
[FLINK-16068][table-planner-blink] Fix DDL fails when both computed column and keyword-escaped column exist (#11101),0
[FLINK-15988][json] Make JsonRowSerializationSchema's constructor private (#11080),5
"[FLINK-10918][state backends] Change o.a.f.core.fs.Path to java.nio.file.Path in RocksDB incremental checkpointsThis solves the bug that Paths are handled wrong on Windows, breaking incremental checkpoints.This closs #11095",4
[hotfix][core] Fix broken JavaDoc link in FileUtils,2
[hotfix][runtime] Small docs/comments cleanups in RPC code.,4
[FLINK-15966][runtime] Capture callstacks for RPC ask() calls to improve exceptions.,1
[hotfix][config] Adjust AkkaOptions to new type-safe pattern,1
[FLINK-16057][runtime] chain ContinuousFileReaderOperator by default (HEAD),2
[FLINK-15961][table-planner][table-planner-blink] Add physical Python Correlate rules and RelNodesThis closes #11051.,1
[FLINK-16056][runtime][tests] do fail ContinuousFileProcessingITCase on failure,0
[FLINK-16056][runtime][tests] create ContinuousFileReaderOperator using factory onlyAlso drop test constructor and make the class package-private.,1
[FLINK-16056][docs] update StreamExecutionEnvironment javadoc,2
[FLINK-16136][yarn][tests] Increase disk space limit for all YARN tests,3
[FLINK-14086][core] Add OperatingArchitecture Enum,1
[FLINK-14086][core] (follow-up) Clean-up / unify processor and memory architecture enumsThis closes #9768,4
[FLINK-15473][core] Add ppc64le to the list of known processor architectures.,1
[FLINK-16055][hive] Avoid catalog functions when listing Hive built-in functionscloses #11093,1
[FLINK-15744] Log erroneous Task state changes at warn level,4
[FLINK-15835][build][oss] Exclude hadoop-common,2
[hotfix][docs] Minor improvements of glossary.This closes #9694.,1
[FLINK-14533][flink-table-planner] Fix LOWER/UPPER not being pushed down to TableSource (#10005),0
"[FLINK-16135][core] Unify the TemporaryClassLoaderContext and AutoContextClassLoaderThese two classes did teh same thing, this commit unifies the use to a consolidated instance.This closes #11120",5
"[FLINK-15866] Make ClosureCleaner ""work"" for classes that have no super class or interfaces",1
[FLINK-16162][build] Bump flink-shaded to 10.0,2
[FLINK-16033][table-api] Construct expressions through factory methods (#11141)This commit is a preparation step for next commits. The only entry pointto constructing api expression are methods in ApiExpressionUtils. Thisway we can put additional logic in the factory methods without pollutingthe ctors.,2
[FLINK-16164][build] Disable maven-site-plugin,2
[FLINK-7727] [REST] Improve error logging in StaticFileServerHandlers,2
[hotfix][table-common] Remove deprecated DataTypes.ANY(...)This closes #11094.,5
"[FLINK-16169][tests] Harden BlobServerRangeTestThe test is unreliable since there is no guarantee that the ""availablePort"" is still available then the blob server starts.",3
[hotfix][table-api] Fixed ExpressionResolver rules modifiers.,0
[FLINK-16072][python] Optimize the performance of the write/read null mask of FlattenRowCoder,2
"[FLINK-15833] Fix 'Kerberized YARN on Docker' e2e test on Azure PipelinesMostly removed the ""-it"" argument from docker exec. -it is meant to be used for interactive shell sessions, not in scripts on a CI system.Because of the ""-it"" argument, the docker command printed ""the input device is not a TTY"" to the output. That's why some checks / assumptions in the scripts failed.",0
[FLINK-12343][yarn] Add YARN file replication optionThis closes #10980 .,2
[hotfix] Refactor YARNFileReplicationITCase to avoid inheritance,2
[FLINK-15904][connectors/kafka] Use explicit Serializer for KafkaConsumer unionOffsetStates,1
"[FLINK-16000] Move ""Project Build Setup"" to ""Getting Started"" in documentationWe also add redirects.",1
"[FLINK-16000] Add ""where to go"" to getting-started overview sectionThis also re-orders the overview sections to make the orderingconsistent between the overview and the actual sub-sections.",1
"[FLINK-16000] Remove icons from getting-started subsectionsThis makes the section more consistent with the rest of thedocumentation, where no sub-sections have icons.",2
"[FLINK-16041] Expand ""popular"" documentation sections by default",2
[FLINK-16182][table-api] Remove check against null types as a result of an input type inference when deriving output type based on surrounding info.,5
[FLINK-16191][state backends] Improve error message on Windows when RocksDB is give a too long path.,5
[hotfix][runtime] Fix checkstyle in org.apache.flink.runtime.checkpoint (main scope)Test scope is not included in this fix.,0
[hotfix][DataStream API] Minor JavaDoc / deprecation cleanup in CheckpointedFunction,1
[FLINK-16139][runtime] Reset colocation constraints when restarting tasks in DefaultScheduler,1
[FLINK-15652][kubernetes] Support for imagePullSecrets K8s optionThis closes #11054 .,1
[FLINK-15652][kubernetes] Change imagePullSecrets option to list ConfigOptionThis closes #11166 .,5
[FLINK-16019][runtime] fix ContinuousFileReaderOperator error handling,0
[FLINK-16019][runtime][test] Implement test coverage for FLINK-16019 bug,0
[FLINK-11589] Support security module and context discovery via ServiceLoader.,1
[FLINK-11589] Add tests for SecurityContext fallback behaviour,3
[FLINK-11589] Regenerate security configuration docs,2
[FLINK-14231][task] Add the quiesce() method to ProcessingTimeService and remove TimerService::awaitPendingAfterQuiesce method,4
[FLINK-14231][runtime] Introduce and use ProcessingTimeServiceAware to pass ProcessingTimeService to operator,1
"[FLINK-14231][task] Add StreamOperatorWrapper that handles the close, endInput and other related logic of an operatorFor each operator in the operator chain, its inputs must end completely before executing the ""endInput()"" method. Forthe operator chain in a task, such as ""OP1 - > OP2 - > ..."", after the (source/network) input of OP1 are finished,the operators on the chain are closed in the following order:1. quiesce ProcessingTimeService of OP1 to prevent the pending timers from firing, but wait the timers in running   to finish.2. call OP1#close()3. call OP2#endInput()4. quiesce ProcessingTimeService of OP2 to prevent the pending timers from firing, but wait the timers in running   to finish.5. call OP2#close()...",5
[FLINK-14231][task] Change StreamTask to close operators with StreamOperatorWrapper to make the endInput semantics on the chain strict,1
"[hotfix][test] Clean up the codes in StreamTaskTestHarness, StreamTaskTimerTest and TestProcessingTimeServiceTestThese cleanups include removing redundant initializer, unnecessary type parameter declarations and redundantsuppression, and so on.",2
"[hotfix] Revert ""[FLINK-15992][kafka][es] Use thread context classloader when finding TableFormatFactory (#11064)""This reverts commit c6158648",4
[FLINK-15999][doc] Add outline of new concepts section,1
[FLINK-15999][doc] Move explanation of DAGs/Dataflows from programming-model.md to stream-processing.md,5
[FLINK-15999][doc] Clean up DAG/parallel DAG section in concepts doc,2
[FLINK-15999][doc] Move state introduction from programming-model.md to stateful-stream-processing.md and clean up,4
[FLINK-15999][doc] Move checkpointing introduction from programming-model.md to stateful-stream-processing.md,4
[FLINK-15999][doc] Move batch-fault-tolerance from programming-model.md to stateful-stream-processing.md,4
"[FLINK-15999][doc] Remove distinction between managed and raw state from state.mdUsers should not be using raw state, except in rare edge cases. We canjust refer to managed keyed state ad keyed state and managed operatorstate as operator state from now on.",1
[FLINK-15999][doc] Move keyed state/operator state explanation from api doc to conceptsThis also reorders/massages the text a bit to make it fit in better.,1
[FLINK-15999][doc] Move broadcast state explanation from api doc to conceptsThis also reorders/massages the text a bit to make it fit in better.,1
[FLINK-15999][doc] Move checkpointing doc from internals to conceptsThis is a straight copy without any adjustments. Follow-up commits willmassage this and make sure it fits well within the concepts section.,1
[FLINK-15999][doc] Update newly moved checkpointing concepts sectionThis fixes links and merges the text with the previously existing text.We also completely remove the section about actual snapshotimplementations in operators.,1
[FLINK-15999][doc] Add TODOs to state concepts section,2
"[FLINK-15999][doc] Rename time concepts section to ""Timely Stream Processing""",2
[FLINK-15999][doc] Move time and windows section from programming-model.md to timely-stream-processing.md,4
[FLINK-15999][doc] Fix formatting and links in timely-stream-processing.md,2
[FLINK-15999][doc] Move relevant sections from event_time.md to timely-stream-processing.mdThis moves the conceptual parts from the development section to theconcepts section. massages them to fit in well and fixes formatting andlinks.,2
[FLINK-15999][doc] Add reference to windowing and ProcessFunction doc in event_time.mdAlso fix section formatting.,0
"[FLINK-15999][doc] Remove ""Low-level Operations"" from ProcessFunction documentation",2
[FLINK-15999][doc] Add TODOs in timely-stream-processing.md,2
[minor] Remove outdated components(.zh).md,5
[FLINK-15999][doc] Move state backend and savepoint doc from runtime.md to stateful-stream-processing.mdAlso reformat/fix links and add TODOs.,2
[FLINK-15999][doc] Move flink components doc from runtime.md to flink-architecture.mdAlso rename and reformat to get up-to-date with current naming.,5
[FLINK-15999][doc] Move remaining text from runtime.md to flink-architecture.mdAlso rename and reformat to get up-to-date with current naming.,5
"[FLINK-15999][doc] Remove ""Asynchronous State Snapshots"" section from concepts",4
"[FLINK-15999][doc] Remove ""ingestion time"" from concepts sectionIngestion time is a special ""flavour"" of event time and one that mightnot be too useful in practice because of inconsistencies that arise incase of failures/recovery. If users don't need event-time they can gostraight to processing time.",1
"[FLINK-15999][doc] Remove ""operator state"" from concepts sectionWe move it to the development section and mention that it is a specialtype of state that is normally not needed in user programs.",1
[FLINK-15999][doc] Remove programming-model section and incorporate into overviewThis also adds explanation about the concepts section,1
"[FLINK-15999][doc] Update/remove outdated information in concepts sectionThe content of the concepts section was gathered from pre-existingdocumentation texts. This commit cleans that up a bit, removes outdatedcontent that is not ""conceptual"" and updates some of the terms that weno longer use.",1
[FLINK-15977][docs] Update pull request template to include Kubernetes as deployment candidatesThis closes #11053 .,5
[FLINK-15672][build] Migrate to log4j2,2
[FLINK-15672][build] Migrate production log4j configuration to log4j2,2
[FLINK-15672][build][tests] Migrate test log4j configurations to log4j2,2
[FLINK-16163][build] Migrate to flink-shaded-zookeeper,2
[hotfix][build system] Do not trigger dependent jobs if predecessor fails,0
[FLINK-15967][examples] Use universal kafka connector in StateMachineExample,1
[hotfix][scripts] Fix comment for default GC configuration,5
[FLINK-14038][docs] Extend Application Profiling documentationThis commit adds explanations on how to analyze/debug out of memory problems andhow to analyze GC behaviour.This closes #11165.,0
[FLINK-16186][es][tests] Reduce connect timeout to 5 seconds,3
[FLINK-15912][table] Add Context to TableSourceFactory and TableSinkFactoryThis closes #11047,1
[FLINK-15912][table] Support create table source/sink by context in sql-cli,1
[FLINK-15912][table-planner-blink] Support create table source/sink by context in blink planner,2
[FLINK-15912][table-planner] Support create table source/sink by context in legacy planner,1
[FLINK-15912][table] Support create table source/sink by context in hive connector,1
[FLINK-15912][table] Clean TableFactoryUtil,4
"[FLINK-16082][docs-zh][table] Translate ""Streaming Concepts Overview"" page into Chinese (#11128)",2
[hotfix] Stabilize python tests,3
"[FLINK-16233][hive][build] Add additional log4j 1 exclusionsAdds several missing log4j1 exclusions, that are only necessary for certain hive versions.",2
[FLINK-16081][docs-zh][table] Translate /dev/table/index.zh.md (#11127),2
[FLINK-16243][docs] Update quickstarts to Log4j2,2
[hotfix][docs] Sync slf4j version,2
[FLINK-16188][e2e] AutoClosableProcess constructor now private,2
java8 compat,5
fix stream issueapparently you can literally only create 1 stream from a collection...,1
Remove concurrent access to process stdout,4
[FLINK-15172][table-blink] Introduce LazyMemorySegmentPool,2
[FLINK-15172][table-blink] Imporve BinaryExternalSorter to lazy allocate memory,2
[FLINK-15172][table-blink] Imporve BytesHashMap to lazy allocate memory,2
[FLINK-15172][table-blink] Improve ResettableExternalBuffer to lazy allocate memory,1
[FLINK-15172][table-blink] Improve Hash join tables to lazy allocate memoryThis closes #10797,1
[FLINK-16288][travis] Remove redundant double-quote,4
[FLINK-16237][build] Add Log4j2 configuration properties,5
[FLINK-16161][hive] Statistics zero should be unknown in HiveCatalogThis closes #11199,2
[FLINK-16121][python] Introduce ArrowReader and ArrowWriter for reading and writing Arrow format dataThis closes #11112.,5
"[FLINK-16183][table-api] Make identifier parsing in Table API morelenientIt improves the experience of Table API users as they do not need to escape SQL keywords. Some of the sql keywords might be a commonly used names in Table API (e.g. ""table"" for Table names). It also lets us support parsing identifiers coming from Java's ExpressionParser (e.g. for a string array(...) it produces a lookup call with an ""array"" identifier which should be parsed).",1
[FLINK-16183][table-api] Update documentation to reflect the more lenient sql identifier parsing.This closes #11156,2
[FLINK-16067][table] Forward Calcite exception when parsing a sql queryThis closes #11172,2
[FLINK-16033][table-api] Fix loosing function identifier in ExpressionResolver rules,0
[FLINK-16033][table-api] Parse identifiers in FunctionLookup.This change effectively enables querying catalogs for catalog functionswith qualified names.,1
[FLINK-16033][table-api] Expose catalog lookup function calls in Scala'sexpression dsl.,1
[FLINK-16242][table-runtime-blink] Duplicate field serializers in BaseRowSerializer (#11194),2
"[FLINK-16013][core] Make complex type config options could be parsed correctlyIf the config option value is complex type(e.g. Duration, List, Map), it need to be properly handled when converting to string. For List type, we need to convert it to a semicolon-separated string. For Map type, we need to convert it to comma-separated key:value pairs. For Duration type, we need to convert it to a nano seconds string. And if we want to write the configuration to a yaml file, Configuration#toMap should be used to get all the keys and values.",1
[hotfix] Minor clean-up in TaskExecutorProcessUtils.,4
[FLINK-16111][k8s] Fix Kubernetes deployment not respecting 'taskmanager.cpu.cores'.This closes #11110.,0
[hotfix][yarn][test] Add test cases for validating Yarn deployment respecting the cpu configuration fallback order.,5
[hotfix][mesos][test] Update test cases for validating Mesos deployment respecting the cpu configuration fallback order.,5
[FLINK-16263][python][tests] Set io.netty.tryReflectionSetAccessible to true for JDK9+,1
[hotfix] Fix minor IDE warnings in MemoryUtils,2
"[FLINK-15094] Use Unsafe to instantiate and construct DirectByteBufferIf we use reflection to create a DirectByteBuffer to wrap unsafe native memory allocations,it causes illegal access warnings in Java9+.This PR changes this to use Unsafe to instantiate a DirectByteBuffer.The address and capacity fields are set by direct unsafe memory operations.Other fields are set by calling ByteBuffer#clear at the end.Unsafe operations skips the illegal access verification and do not result in warnings.This solution still relies on Unsafe which is about to be removed in future Java releases.If it is removed and we still do not want to contribute to direct memory by allocating native managed memory,we will have to find alternartive solutions, like e.g. writing a custom native allocatorand use JNI API to instantiate the wrapping DirectByteBuffer (NewDirectByteBuffer in C).This closes #11160",1
[hotfix] fix typo in FlinkKafkaConsumerBase,2
[FLINK-16179][hive] Use configuration from TableFactory in hive connector (#11201),5
"[FLINK-16264][table] Fix ConnectTableDescriptor loose time attribute bug (#11204)In CatalogTableImpl.fromProperties, we can not remove all schema.* for TableSchema, because Schema (it is a descriptor) is not same to TableSchema. Schema contains time attribute, so we need keep them in properties.",1
[FLINK-16178][refactor] Avoid costly eager error message construction in OperatorState.,1
[FLINK-16178][refactor] Remove SavepointV1 class and move relevant code to test scopeThe class was a shell used for tests but confusing and cluttering the main scope.,5
[FLINK-16178][refactor] Remove redundant (duplicate) check on version availability.,4
[FLINK-16178][refactor] Make the versioned Checkpoint Metadata Serializers only responsible for deserialization.Serialization always happens with the latest version anyways.,3
"[FLINK-16192][checkpointing] Remove remaining bits of ""legacy state"" and Savepoint 1.2 compatibility""Legacy State"" Refers to the state originally created by the old ""Checkpointed"" interface, before state was re-scalable.Because some of the tests for 1.3 compatibility used checkpoints with that legacy state, some 1.3 migrationtests had to be removed as well.",4
"[FLINK-16247][checkpoints] Rename 'checkpoints.savepoint.' package and classes to 'checkpoint.metadata.'These classes describe the persistence of checkpoint metadata.Originally, savepoints where the only snapshots with persistent metadata, while checkpoints had themetadata only in memory or in ZooKeeper (Java Serialized).Nowadays, checkpoints and savepoints both persist metadata in the same way, and hence thepackage is not actually related to savepoints any more.",5
"[FLINK-16259][checkpoints] Drop interface/impl separation for checkpoint Metadata and rename MetadataV2 to CheckpointMetadataThe interface 'Metadata' (nee Savepoint) and its different implementations was misleading.There is only ever one real implementation: the latest version.All deserializers need to go to that version, to keep the complex versioninglogic out of other parts of the code.Further more, this is a simple ""data holder"" class, simply storing collections,there is no behavior to be abstracted behind an interface.Even if there were different versions (as in an earlier version of the code, where the SavepointV1 classfor tests was in the main scope), the interface was a union of all accessors to all different collectionsfrom different versions (with all accessors but the ones for the latest version deprecated).AS a result, the 'Metadata' interface was misleading and suggesting something that is notthere, namely that multiple versions of the metadata are handled in various places in thecode, and not just during deserialization.",0
[FLINK-15349] add 'create catalog' DDL to blink planneradd 'create catalog' DDL to blink plannercloses #11116.,2
[FLINK-16265][table][csv] CsvTableSourceFactoryBase should compare LogicalTypes instead of TableSchema (#11214)Filesystem OldCsv with timestamp type will fail in yaml.The root cause is we will convert the properties into CatalogTableImpl and then convert into properties again. The schema type properties will use new type systems then which is not equal to the legacy types due to conversion classes.,5
[FLINK-16251][python] Optimize the cost of function call in ScalarFunctionOpertation,1
"[FLINK-16248][python][ml] Add interfaces for MLEnvironment and MLEnvironmentFactory (#11198)Align interface for MLEnvironment and MLEnvironmentFactory from Java, so Python users can use Python MLEnvironmentFactory to maintain the execution environment and table environment.",1
[FLINK-16283][table-planner] Fix potential NullPointerException when invoking close() on generated function (#11217),1
[FLINK-16231][hive][build] Add missing jdk.tools exclusionFailed the build on Java 11 with Hive 2.x.y profiles.,2
[FLINK-16287][es][build] Remove Log4j2 relocation,2
[FLINK-16115][filesystem][oss] Relocate flink-hadoop-fs,2
[FLINK-15834] Set up nightly builds in Azure,1
[FLINK-15834][hotfix][build scripts] Properly set return code before check,1
[FLINK-15834][hotfix] Always run end to end tests,3
"[FLINK-15834][hotfix] Fix Kubernetes E2E testsProblem: Low disk space was causing K8s to mark the kubelet as ""full disk"", thus Flink did not schedule there.Problem: Low disk space let the kublet delete unused docker images, including images generated for the test.",3
[FLINK-15834][hotfix] Fix Kerberized YARN e2e testThe problem was that YARN was decommissioning NodeManagers because of low disk space.,1
"[FLINK-15834][hotfix] Fix queryable state e2e testProblem: The logging pattern recently changed, that's why the extaction of port / ip failedThis closes #11222",0
[FLINK-16265][table][csv] CsvTableSinkFactoryBase should compare LogicalTypes instead of TableSchema (#11229),2
[FLINK-16252][python] Optimize the output emit logic to remove unnecessary overhead,4
"[FLINK-14818][benchmark] Fix InputGate setup logic of StreamNetworkBenchmarkEnvironmentBefore this change, in network benchmark (for example 1000 channels benchmark with 4 record writers) StreamNetworkBenchmarkEnvironment#createInputGate was creating 1000 input gates with 4 input channels each, which doesn't make much sense. This commit is changing that to a single receiver with 4 input gates and each with 1000 channels.It is achieved by providing testing implementations of InputChannels, which are using channel index for requesting subpartitions from ResultPartition, instead of subpartition index. Thanks to that, we can map a single ResultPartition with N subpartitions, to a single instance of InputGate with N channels.The change also influences the benchmark results, overall, the performance goes down a bit because of the decrease of floating buffers and the followings are benchmark results before and after this change:------------------------------------------------------------------Before----------------------------------------------------------------------Benchmark                                                                     (channelsFlushTimeout)   Mode  Cnt      Score      Error   UnitsDataSkewStreamNetworkThroughputBenchmarkExecutor.networkSkewedThroughput                         N/A  thrpt   30  17079.534   830.532  ops/msStreamNetworkBroadcastThroughputBenchmarkExecutor.networkBroadcastThroughput                     N/A  thrpt   30    599.664    13.325  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                 100,100ms  thrpt   30  45629.898  1623.455  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                             100,100ms,SSL  thrpt   30   9817.421   216.075  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                  1000,1ms  thrpt   30  25442.152   968.340  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                1000,100ms  thrpt   30  27944.285   518.106  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                            1000,100ms,SSL  thrpt   30   7820.549   895.862  ops/msStreamNetworkLatencyBenchmarkExecutor.networkLatency1to1                                         N/A   avgt   30     13.184     0.093   ms/op------------------------------------------------------------------After-----------------------------------------------------------------------Benchmark                                                                     (channelsFlushTimeout)   Mode  Cnt      Score      Error   UnitsDataSkewStreamNetworkThroughputBenchmarkExecutor.networkSkewedThroughput                         N/A  thrpt   30  17345.574   370.647  ops/msStreamNetworkBroadcastThroughputBenchmarkExecutor.networkBroadcastThroughput                     N/A  thrpt   30    608.881    12.054  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                 100,100ms  thrpt   30  41732.518  1109.436  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                             100,100ms,SSL  thrpt   30   9689.525   202.895  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                  1000,1ms  thrpt   30  24106.705  2952.364  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                1000,100ms  thrpt   30  27509.665  3246.965  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                            1000,100ms,SSL  thrpt   30   7691.287   927.775  ops/msStreamNetworkLatencyBenchmarkExecutor.networkLatency1to1                                         N/A   avgt   30     12.758     0.147   ms/op",1
[FLINK-16234][tests] Fix unstable cases in StreamingJobGraphGeneratorTestThis closes #11187.,3
[FLINK-16196][hive] FlinkStandaloneHiveRunner leaks HMS process (#11169),2
[FLINK-16275][table-planner-blink] AggsHandlerCodeGenerator can fail with custom module (#11215),0
[FLINK-15972][python][table-planner][table-planner-blink] Implement Physical Python Correlate Node,2
[FLINK-15972][python] Add TableFunctionRowCoder,1
[FLINK-15972][python][table-planner][table-planner-blink] Add Python building blocks to make sure the basic functionality of Python TableFunction could workThis close #11130.,1
[hotfix][docs] Remove unnecessary indents and blank lines,4
[FLINK-15562][docs] Add example settings.xml for configuring snapshot repository,5
[FLINK-15198][Config][Mesos] Remove deprecated option 'mesos.resourcemanager.tasks.mem'The option was deprecated in 1.10 in favour of `taskmanager.memory.process.size`.This closes #10890.,4
[FLINK-15847][ml] Include flink-ml-api and flink-ml-lib in opt,2
"[FLINK-16257][network] Remove useless ResultPartitionID from AddCredit messageThe ResultPartitionID in AddCredit message is never used on upstream side, so we can remove it to cleanup the codes.There would have another two benefits to do so:1. Reduce the total message size from previous 52 bytes to 20 bytes.2. Decouple the dependency with InputChannel#getPartitionId.",1
"[hotfix][network] Cleanup the unused method from SingleInputGateThe method SingleInputGate#getConsumedResultId is never used, so remove it to cleanup the codes.",4
[FLINK-15948][yarn] Enrich the warning log for YARN minimum allocation memoryThe warning log should show up when the JobManager/TaskManager memory is not a multiple of YARN minimum allocation memory. Because YARN will always normalize the resource request by insuring that the requested memory is a multiple of minimum allocation. The minimum allocation could be configured in YARN ResourceManager via 'yarn.scheduler.minimum-allocation-mb'.This closes #11176.,5
[FLINK-16301][table-api] Improve logging message in ModuleManager (#11244),2
[FLINK-15688][streaming] Define DataStream API for MultipleInputStreamOperatorThis interface is still not complete - it's missing for example watermark andlatency markers support.,1
[hotfix][test] Rename getStreamEdges to getStreamEdgesOrThrow,1
[hotfix][streaming] Deduplicate code in StreamGraph,0
[FLINK-15688][streaming] Add support for MultipleInputStreamOperator in the StreamGraphGenerator,1
[hotfix][test] Deduplicate code in LinkedBufferStorageTest,5
[FLINK-16060][checkpointing] Generalize LinkedBufferStorage to support arbitrary number of linked buffer storages,2
[FLINK-16060][metrics] Generalize MinWatermarkGauge to accept an aribtrary number of input gauges,2
[hotfix][task] Extract InputSelection.NONE_AVAILABLE constant,4
[FLINK-16060][task] Implement InputSelection#fairSelectNextIndexThis is going to be used for runtime support of MultipleInputStreamOperator,1
[FLINK-16060][task] Generalize InputSelection#isAllMaskOf2 to multiple inputs,2
[hotfix][tests] Clean up exception lists of StreamTestSingleInputGate,3
[FLINK-16060][test] Provide a test harness for MultipleInputStreamTaskThis creates new hierarchy of task harnesses that could be used for other tasks as well.,1
"[FLINK-16060][task] Implemente working StreamMultipleInputProcessorThis doesn't fully support input selection, watermarks, latency markers and keyed contextes yet",1
[FLINK-16292][AZP] Simplify mechanism for choosing jdk version,2
[FLINK-16292][e2e] Improve debugging of schema registry test,3
[FLINK-16292][AZP] Add missing nightly testsThis closes #11241,3
[FLINK-16271][python] Introduce ArrowPythonScalarFunctionOperator for vectorized Python UDF execution,1
[hotfix] Fix checkstyle violations in ScheduledUnit,0
[hotfix][tests] Mock ExecutionVertex#getID() in ScheduelrTestUtils to avoid NPE issues,0
[FLINK-16180][runtime] Replace the nullable vertexExecution in ScheduledUnit with a non-null executionVertexId,2
[FLINK-16297][docs] Remove unnecessary indents and blank lines,4
[FLINK-16288] Document how to keep the task managers around longer in KubernetesThis closes #11226.,3
[FLINK-15329][runtime] Fix incorrect Javadoc in MemoryManagerFix incorrect Javadoc in MemoryManager#availableMemory(MemoryType),2
[FLINK-15975][tests] Ignore order in assertion,3
[FLINK-13934][rest] Throw RestHandlerException instead of sending inline response,0
[FLINK-13934][rest][tests] Fix and strengthen response assertions,3
[FLINK-16331][legal] Remove source licenses for old WebUI,4
[FLINK-16339][metrics][datadog] Log configuration,5
[FLINK-16307][e2e] Use start-cluster.sh instead of manually building cluster,1
[FLINK-16341][metrics][datadog] Unify DatadogHttpRequest and DSeries,5
[hotfix][tests] Make SchedulerTestingUtils constructor private,3
[hotfix][runtime] Remove slotProvider and slotRequestTimeout param from DefaultScheduler constructorThis makes it easier to understand that the slot allocation is conducted via ExecutionSlotAllocatorFactory but not those two legacy params.,2
[FLINK-16276][tests] Introduce a builder and factory methods to create DefaultScheduler for testing,3
Fixup! [FLINK-16276][tests] Introduce a builder and factory methods to create DefaultScheduler for testing,3
"Revert ""Fixup! [FLINK-16276][tests] Introduce a builder and factory methods to create DefaultScheduler for testing""This reverts commit 622bd31ab8e48afa120b9bb37e8fdc5fdb04f193.",5
"Revert ""[FLINK-16276][tests] Introduce a builder and factory methods to create DefaultScheduler for testing""This reverts commit bd757cb2a29cc2d9046d39aee9684d5b2e5ec036.",4
[FLINK-16276][tests] Introduce a builder and factory methods to create DefaultScheduler for testing,3
[FLINK-16342][metrics][datadog] Remove mocking- introduce timestamp factory instead of relying on static method- introduce static package-private non-final flag for skipping api validation,5
[FLINK-13417][build] Bundle Zookeeper 3.5 in opt,2
[FLINK-16033][table-api] Introduced Java Table API Expression DSL,2
"[FLINK-16033][table-api, test] Added test that check scala/java APIscompletenessThe test should check that methods are accessible from both JAVA andSCALA APIs or have equivalents. Checks are based on methods names.",3
[FLINK-16033][table-api] Updated a test to use java expression dsl,1
[FLINK-16033][table-api] Added test for expression resolution.The added test uses expressionDsl to create unresolved expressions that are later being resolved using ExpressionResolver. It covers constructing expected expressions as well as resolver rules.This closes #11081,0
"[FLINK-16285][network] Refactor SingleInputGate#setInputChannel to remove IntermediateResultPartitionID argumentThe IntermediateResultPartitionID info can be got directly from the respective InputChannel, so we can remove it fromthe arguments of SingleInputGate#setInputChannel to cleanup the codes.It is also helpful to simplify the unit tests and avoid passing the inconsistent IntermediateResultPartitionID with theinternal ResultPartitionID that the respective InputChannel maintains.",4
[hotfix][tests] Remove the dead codes of StreamTestSingleInputGate and TestInputChannel,3
[FLINK-16352][table-common] Changing HashMap to LinkedHashMap for deterministic iterations in ExpressionTest (#11269),3
[FLINK-16360][orc] Flink STRING data type should map to ORC STRING type (#11277)Hive 2.0 ORC not support schema evolution from STRING to VARCHAR.We need produce STRING in ORC for VarcharType(MAX_LENGHT) in Flink.,2
[FLINK-16007][table-planner][table-planner-blink][python] Add PythonCorrelateSplitRule to push down the Java Calls contained in Python Correlate nodeThis closes #11242.,1
[hotfix][hdfs] Fixed error message when using HadoopRecoverableWriter on non hdfs.,1
[FLINK-16015][filesystems]Throw an error when a plugin for a known scheme is missing.The error also avoid Hadoop fallback being used for s3 or other directly supported schemes.Also added a config to allow overridden this check for specific schemes.,1
[hotfix][runtime] Removed duplicate isChainable.,4
[hotfix][runtime] Unified variable names in StreamingJobGraphGenerator.Removed confusing headOperators in isChainable.,1
"[FLINK-16219][runtime] Disallow chaining of legacy source and yielding operator.This change allows yielding operators to be eagerly chained whenever possible, except after legacy sources.Yielding operators do not properly work when processInput is called from another thread, but are usually fine in any other chain.",1
"[FLINK-16219][runtime] Made AsyncWaitOperator chainable to non-sources.AsyncWaitOperator is not thread-safe when chained to legacy sources, but works well in a chained fashion in all other cases.Moved test case to StreamingJobGraphGenerator.",3
[hotfix][build] Remove redundant javadoc-plugin versions,2
[FLINK-15633][build] Bump javadoc-plugin to 3.1.1,2
[FLINK-2336][DataStream API] Fix ArrayIndexOufOBoundsException in TypeExtractor for type erased lambdasThis closes #11234,4
[hotfix][docs] Fix the mismatch between java and scala CEP examplesThis closes #11278,0
[hotfix][table] Remove unused import in DataStreamConversionsThis closes #11271,5
[FLINK-16380][AZP] Fix jdk11 switch,0
[FLINK-16281][jdbc] Parameter 'maxRetryTimes' can not work in AppendOnlyWriter (#11223),1
[FLINK-12814][sql-client] Support a traditional and scrolling view of result (tableau format)This closes #11273,1
"[FLINK-15081][docs-zh] Translate ""Concepts & Common API"" page of TableThis closes #10822",2
[FLINK-16370][build] Only bundle javax as Java11-exclusive dependency,2
"[FLINK-16359][table-runtime] Introduce WritableVectors for abstract writing (#11275)In FLINK-11899 , we need write vectors from parquet input streams.We need abstract vector writing, in future, we can provide OffHeapVectors.",1
[FLINK-16190][e2e] Migrate tests to FlinkResource,2
[FLINK-16190][e2e] Move FlinkDistribution into flink package,2
[FLINK-16348][WebUI] Add commas to numeric accumulators,1
[hotfix][dataset][javadoc] Fix typotypo in InputFormat.,2
[hotfix][table][docs] Fix typo,2
[hotfix][kinesis][build] Document why guava must not be relocated,2
"[FLINK-10885][e2e] Stabilize confluent schema registry testPotential problem:- the error message ""No supported Kafka endpoints are configured. Either kafkastore.bootstrap.servers must have at least one endpoint matching kafkastore.security.protocol or broker endpoints loaded from ZooKeeper must have at least one endpoint matching"" indicates that the one of the mentioned config parameters has to be set, or the brokers need to be listed in Zookeeper.- The source code of the ""KafkaStore"" in the schema registry supports this hypothesis: https://github.com/confluentinc/schema-registry/blob/3.2.0-post/core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaStore.java#L121- after starting the Kafka cluster, we wait until ""Node does not exist"" is not returned by the ZK Cli.- However, if ZK is not (yet) running, we'll also have outputs such as ""WARN Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)"", stopping the wait loop.Solution: Wait till we have a ZK Cli output indicating that the broker is registered.",0
[FLINK-15582][tests] Enable batch scheduling tests for both LegacyScheduler and DefaultScheduler,3
[FLINK-16140] [docs-zh] Translate Event Processing (CEP) page into Chinese (#11168),2
[FLINK-16362][table] Remove deprecated `emitDataStream` method in StreamTableSinkThis closes #11279,5
[FLINK-11193][State] Fix Rockdb timer service factory configuration option to be settable per jobThis closes #8479.,1
[hotfix] Fix chinese doc links to make master documentation build again,2
[hotfix][scaladoc] Add missing parameter in DataStreamConversions's scaladocThis closes #11272.,2
[FLINK-16131] [docs] Translate /ops/filesystems/s3.zh.mdThis closes #11207.,5
[hotfix] [docs] Fix typo in /ops/filesystems/s3.md,5
[FLINK-10917][build] Move&rename drowpizard propertyThis property is only relevant for metrics; hence there's no reason for this property to be defined in the root pom.The name was changed since it was inconsistent with current naming conventions (<library>.version).,4
[FLINK-10917][metrics] Bump dropwizard to 3.2.6,4
[FLINK-16280][doc] Fix sample code errors in the documentation about elasticsearch connector.This closes #11216.,2
[FLINK-15838] Dangling CountDownLatch.await(timeout)This closes #11005.,2
[FLINK-16393][kinesis] Skip record emitter thread creation w/o source sync,1
[hotfix] Fix checkstyle violations in ExecutionGraphTestUtils,3
[hotfix][tests] Change ExecutionGraphTestUtils#getExecutionVertex() to ExecutionGraphTestUtils#getExecutionJobVertex()These methods actually returns ExecutionJobVertex.,3
[FLINK-16300][tests] Introduce ExecutionGraphTestUtils#getExecutions() to replace SchedulerTestUtils#getTestVertex(),3
[hotfix] [k8s] Normalize name or package class of the test classes,3
[FLINK-16194][k8s] Remove the existing decorator patterns,4
[FLINK-16194][k8s] Refactor and simplify KubernetesTestBase- make KubernetesTestBase contains only the common logic of the client-side and cluster-side- remove some unnecessary methods of getting kube client and mocking Service's ADD event,1
[FLINK-16194][k8s] Remove Flink Configuration out of KubernetesResource,5
[FLINK-16194][k8s] Introduce Kubernetes parameters parsing/verifying/managing tool,2
[FLINK-16194][k8s] Introduce the monadic step decorator design and the InitJobManagerDecorator and the TaskManagerDecorator,5
[FLINK-16194][k8s] Introduce Java command decorator for the main Container of the JobManager and the TaskManger Pod,2
[FLINK-16194][k8s] Introduce the internal and the external Service decorator,2
"[FLINK-16194][k8s] Introduce decorator for mounting configuration files such as flink-conf.yaml, log4j.properties, and logback.xml",5
[FLINK-16194][k8s] Introduce Factories that chain the decorators together to construct all the client/cluster-side Kubernetes resources,1
[FLINK-16194][k8s] Rework FlinkKubeClient to use the new decorator patternThis closes #11233 .,1
[FLINK-16194][k8s] Make FlinkPod a value class,2
[FLINK-15584][table-planner] Give nested data type of ROWs in ValidationException,5
[FLINK-16414][table] Fix sql validation failed when using udaf/udtf has no getResultType (#11302),1
[FLINK-16133][docs-zh] Translate /ops/filesystems/azure.zh.mdThis closes #11232,5
[FLINK-16132][docs-zh] Translate /ops/filesystems/oss.zh.md into ChineseThis closes #11231,1
"[FLINK-16089][docs-zh] Translate ""Data Type"" page of Table API & SQL into ChineseThis closes #11190",1
[FLINK-16084][docs-zh] Translate /dev/table/streaming/time_attributes.zh.md (#11102),2
[FLINK-16418][hive] Hide hive version to avoid user confuse (#11304),5
[FLINK-16122][AZP] Upload artifacts fileThis closes #11306,2
[hotfix][AZP] Shorten cron build job names,0
[FLINK-16400][s3] Fixing YarnFileStageTestS3ITCase for direct Hadoop access.,3
[FLINK-16400][filesystem] Deprecating filesystem kind.Also removing invalid HdfsKindTest cases.,3
[FLINK-16269][FLINK-16108][table-planner-blink] Fix schema of query and sink do not match when generic or POJO type is requested (#11236)This also fixes failure of StreamSQLExample when running in blink planner.,2
[FLINK-16177][refactor][checkpointing] Remove unnecessary test constructor from PendingCheckpoint.The constructor is adding trivial benefit and is only used once.,1
[FLINK-16177][refactor][checkpointing] Introduce a new MetadataV3Serializer for the latest version,3
[FLINK-16177][refactor][checkpointing] Remove unused fields from Metadata Serializer version 3This also cleans up some code and names in the shared SubtaskState serialization code.,4
[hotfix][checkpointing] Minor code cleanups for 'checkpoint.metadata' test classes  - fix checkstyle  - Adjust names of tests with renamed main scope classes  - remove test util methods that are no longer used after Legacy State was dropped.,4
[hotfix][tests] Fix parameter error in CheckpointCoordinatorTestingUtils,3
[FLINK-16177][checkpointing] Integrate OperatorCoordinator with checkpoints (triggering and committing)Restoring state to OperatorCoordinators is not included in this commit.This closes #11274,1
[FLINK-16410][e2e][build] Add explicit flink-runtime dependency,2
[FLINK-16172][build] Add baseline set of allowed unused dependencies,1
[FLINK-16173][build] Reduce noise for used undeclared dependencies,1
"[FLINK-16189][e2e] Remove test logic from FlinkDistributionThe FlinkDistribution is now a simple wrapper, which makes it easier to use in ways that do not match the jUnit resource life-cycle.",3
[FLINK-16417][e2e] Slightly increase offheap memory for ConnectedComponents testThe calculated off-heap size was 130 MB.The test passes on JDK 11 when setting it to 270 MB.The test fails on JDK 11 when setting it to 135 MB.The test passes on JDK 11 when setting it to 160 MB.This commit sets the memory to 160MB.,1
[FLINK-16431][AZP] Pass build profile into end to end test script on Azure,3
[FLINK-16378][AZP] Disable Docker tests when running with JDK11,1
"[FLINK-16249][python][ml] Add interfaces for Params, ParamInfo and WithParamsThis closes #11220.",2
[FLINK-11899][parquet] Introduce parquet ColumnarRow split readerThis closes #10922,2
[FLINK-16129][docs-zh] Translate /ops/filesystems/index.zh.md into ChineseThis closes #11167,1
[FLINK-16130][docs-zh] Translate /opt/filesystems/common.zh.md into ChineseThis closes #11182,1
[FLINK-16337][python][table-planner-blink] Add support of vectorized Python UDF in blink planner,2
[FLINK-16337][python][table-planner] Add support of vectorized Python UDF in old plannerThis closes #11252.,1
[FLINK-16435][python] Replace since decorator with versionadd to mark the version an API was introducedThis closes #11318.,1
[FLINK-16313] Ignore unstable rocksdb state processing api test,3
"[hotfix] In flink-end-to-end-tests-common-kafka, execute dependency plugin in different phaseWe do this to fix this error message:[ERROR] Failed to execute goalorg.apache.maven.plugins:maven-dependency-plugin:3.1.1:copy (copy) onproject flink-end-to-end-tests-common-kafka: Artifact has not beenpackaged yet. When used on reactor artifact, copy should be executedafter packaging: see MDEP-187. -> [Help 1]",1
[FLINK-16445][build] Set property japicmp.referenceVersion to 1.10.0This closes #11324.,5
[FLINK-16313][state-processor-api] Properly dispose of native resources when closing input splitThis closes #11335.,2
[FLINK-16450][hive] Integrate parquet columnar row reader to hiveThis closes #11327,2
[FLINK-16463][table-planner-blink] Remove the redundant semicolon in the generated code in CodeGenUtilsThis closes #11339,4
[FLINK-16199][table] Support IS JSON predication for SQL in blink plannerThis closes #11174,2
[FLINK-16500][hive] Hive get primary key should not throw exception when Invalid method nameThis closes #11352,1
[FLINK-16467][core] Fix MemorySizeTest#testToHumanReadableString failure due to different string formats in different locales.,0
"[FLINK-16427][api] Don't throw ProgramInvocationException in RemoteStreamEnvironmentProgramInvocationException is in flink-clients and we want to eventuallyturn around the dependencies, that is flink-clients should depend onflink-streaming-java (or some streaming translation package) and not theother way round, as it currently is.",2
[FLINK-16273][python] Set io.netty.tryReflectionSetAccessible to true by default (#11341),1
[FLINK-15131][connector/source] Add the APIs for Source (FLIP-27).Boundedness - A enum indicating whether the input stream is Bounded or UnboundedSource - A factory style class that helps create SplitEnumerator and SourceReader at runtime.SourceSplit - An interface for all the split types.SplitEnumerator - Discover the splits and assign them to the SourceReadersSplitEnumeratorContext - Provide necessary information to the SplitEnumerator to assign splits and send custom events to the the SourceReaders.SplitAssignment - A container class holding the source split assignment for each subtask.SourceReader - Read the records from the splits assigned by the SplitEnumerator.ReaderInfo - A container class about reader information.SourceReaderContext - Provide necessary function to the SourceReader to communicate with SplitEnumerator.SourceOutput - A collector style interface to take the records and timestamps emit by the SourceReader.WatermarkOutput - An interface for emitting watermark and indicate idleness of the source.Watermark - A new Watermark class in the package org.apache.flink.api.common.eventtime to replace the existing Watermark class.,2
[FLINK-16167][python][doc] Improve python_shell documentThis closes #11142.,2
[FLINK-16483][python] Add Python building blocks to make sure the basic functionality of vectorized Python UDF could work (#11342),1
[FLINK-16371][fs-connector] Make CompressWriterFactory serializable,1
[FLINK-16371][fs-connector] Add ITCaseThis closes #11307.,1
[FLINK-15782][connectors/jdbc] rename package-private JDBC classesMotivation:Future classes for JDBC XA and JDBC DMLmake uppercase convention inconvenient,1
[FLINK-15782][connectors/jdbc] introduce parameter objectsMotivated partially by future use in public API,1
[FLINK-15782][connectors/jdbc] refactor JDBC connector impl.Motivation: use existing code oriented to Table API in DataStream APIChanges:1. make JDBC writers more general PreparedStatement executors (still operating on Rows)2. isolate Delete operation specific to Table API3. generalize JdbcUpsertOutputFormat and rename to JdbcBatchingOutputFormat,5
[FLINK-15782][connectors/jdbc] generalize jdbc statement executors (from Row to <T>)Motivation: use existing code oriented to Table API in DataStream API,5
[FLINK-15782][connectors/jdbc] generalize output formats and sinks (from Row to <T>)Motivation: use existing code oriented to Table API in DataStream API,5
[FLINK-15782][connectors/jdbc] rename Batch to Execution Options,5
"[FLINK-15782][connectors/jdbc] inject connection provider instead of optionsMotivation: manage connections outside of JDBCOutputFormat.In particular, this is required to manage transactions.",1
[FLINK-15782][connectors/jdbc] refactor JDBC sink testsChanges:1. extract DbMetadata to allow to use different databases2. extract test fixture from the base class3. use inheritance only for @Before/@After behaviour,1
[FLINK-15782][connectors/jdbc] add JDBC sink DataStream APIParameterSetter renamed to StatementBuilder:semantically it builds a statement from a user POJO by setting parameters.,2
[FLINK-15782][connectors/jdbc][pr-review] use SimpleBatchStatementExecutor for Upsert[pr-review] enforce use of Builder and Optional in JdbcOptions[pr-review] don't expose Row in DataStream API[pr-review] fix typo and remove redirects in docs; add some javadoc[pr-review] rename ExecutorCreator to StatementExecutorCreator and some vars/methods[pr-review] address formatting and some other minor issuesThis closes #11061.,0
[FLINK-16455][hive] Introduce flink-sql-connector-hive modules to provide hive uber jarsThis closes #11328,1
[FLINK-15396][json] Support to ignore parse errors for JSON formatThis closes #11119,5
[FLINK-16512][task] Unaligned checkpoints: API for persistence,2
[FLINK-16525][task] Increment subtask id by 1 to display subtask name,2
"[FLINK-16014][s3] Force usage of SAXParserFactory over XMLReaderFactoryThis avoids a ClassNotFound exception of the underlying XML reader class in plugin classloaders.Root cause is a bug in JDK8 (JDK-8015099). XMLReaderFactory caches the class name independent of the classloader. On EMR, xercesImpl is on classpath (because of HDFS) and will be loaded at some point in time.",1
"[FLINK-16363][table] Correct the execution behavior of TableEnvironment and StreamTableEnvironmentNote: In previous versions, TableEnvironment.execute() and StreamExecutionEnvironment.execute() can both trigger table and DataStream programs. Since 1.11.0, table programs can only be triggered by TableEnvironment.execute(). Once table program is convereted into DataStream program (through toAppendStream() or toRetractStream() method), it can only be triggered by StreamExecutionEnvironment.execute().This closes #11296",5
[FLINK-16519][checkpointing][tests] Remove PowerMock,4
[FLINK-14041][tests] Refactor LeaderRetrievalServiceHostnameResolutionTest- rename class and test cases for clarity- inline StandaloneUtils as it is just unnecessary,3
[FLINK-16477][hotfix][test] Add SerialVersionUID to the test Class to get stable functionIdentifier,1
[FLINK-16516][python] Avoid codegen user-defined function for Python UDF (#11358),1
"[FLINK-16530][docs] Add documentation about ""GROUPING SETS"" and ""CUBE"" support in streaming modeThis closes #11379",1
[FLINK-16374][AZP] Disable java e2e tests in misc profileBecause the java e2e tests are executed in the e2e profile,2
[FLINK-16456][e2e] Increase memory off heap of 'Heavy deployment end-to-end test'Increasing from default / calculated 134217728b to 200m.,3
[FLINK-16417][e2e] Increase offheap memory for high-parallel-iterations testThis closes #11364,3
[FLINK-15337][docs] Add vendor table to documentation,2
[FLINK-16546][yarn] Fix logging bug in YarnClusterDescriptor#startAppMaster,0
[hotfix] Fix some typos in flink-examples-streaming,2
[FLINK-16545][build] Remove Eclipse-specific plugins,4
[FLINK-11720][connectors] Bump ElasticSearch5 to 5.3.3The ES5 connector has caused numerous issues in end to end and integration tests (on CI and during release test).The NOTICE file has been updated according to this maven shade output:[INFO] --- maven-shade-plugin:3.1.1:shade (shade-flink) @ flink-connector-elasticsearch5_2.11 ---[INFO] Including org.apache.flink:flink-connector-elasticsearch-base_2.11:jar:1.11-SNAPSHOT in the shaded jar.[INFO] Including org.elasticsearch.client:transport:jar:5.3.3 in the shaded jar.[INFO] Including org.elasticsearch:elasticsearch:jar:5.3.3 in the shaded jar.[INFO] Including org.apache.lucene:lucene-core:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-analyzers-common:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-backward-codecs:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-grouping:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-highlighter:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-join:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-memory:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-misc:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-queries:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-queryparser:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-sandbox:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-spatial:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-spatial-extras:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-spatial3d:jar:6.4.2 in the shaded jar.[INFO] Including org.apache.lucene:lucene-suggest:jar:6.4.2 in the shaded jar.[INFO] Including org.elasticsearch:securesm:jar:1.1 in the shaded jar.[INFO] Including net.sf.jopt-simple:jopt-simple:jar:5.0.2 in the shaded jar.[INFO] Including com.carrotsearch:hppc:jar:0.7.1 in the shaded jar.[INFO] Including joda-time:joda-time:jar:2.5 in the shaded jar.[INFO] Including org.yaml:snakeyaml:jar:1.25 in the shaded jar.[INFO] Including com.fasterxml.jackson.core:jackson-core:jar:2.10.1 in the shaded jar.[INFO] Including com.fasterxml.jackson.dataformat:jackson-dataformat-smile:jar:2.10.1 in the shaded jar.[INFO] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.10.1 in the shaded jar.[INFO] Including com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.10.1 in the shaded jar.[INFO] Including com.tdunning:t-digest:jar:3.0 in the shaded jar.[INFO] Including org.hdrhistogram:HdrHistogram:jar:2.1.6 in the shaded jar.[INFO] Including net.java.dev.jna:jna:jar:4.2.2 in the shaded jar.[INFO] Including org.elasticsearch.plugin:transport-netty3-client:jar:5.3.3 in the shaded jar.[INFO] Including org.elasticsearch.plugin:transport-netty4-client:jar:5.3.3 in the shaded jar.[INFO] Including io.netty:netty-buffer:jar:4.1.7.Final in the shaded jar.[INFO] Including io.netty:netty-codec:jar:4.1.7.Final in the shaded jar.[INFO] Including io.netty:netty-codec-http:jar:4.1.7.Final in the shaded jar.[INFO] Including io.netty:netty-common:jar:4.1.7.Final in the shaded jar.[INFO] Including io.netty:netty-handler:jar:4.1.7.Final in the shaded jar.[INFO] Including io.netty:netty-resolver:jar:4.1.7.Final in the shaded jar.[INFO] Including io.netty:netty-transport:jar:4.1.7.Final in the shaded jar.[INFO] Including org.elasticsearch.plugin:reindex-client:jar:5.3.3 in the shaded jar.[INFO] Including org.elasticsearch.client:rest:jar:5.3.3 in the shaded jar.[INFO] Including org.apache.httpcomponents:httpclient:jar:4.5.3 in the shaded jar.[INFO] Including org.apache.httpcomponents:httpcore:jar:4.4.6 in the shaded jar.[INFO] Including org.apache.httpcomponents:httpasyncclient:jar:4.1.2 in the shaded jar.[INFO] Including org.apache.httpcomponents:httpcore-nio:jar:4.4.5 in the shaded jar.[INFO] Including commons-codec:commons-codec:jar:1.10 in the shaded jar.[INFO] Including commons-logging:commons-logging:jar:1.1.3 in the shaded jar.[INFO] Including org.elasticsearch.plugin:lang-mustache-client:jar:5.3.3 in the shaded jar.[INFO] Including com.github.spullara.mustache.java:compiler:jar:0.9.3 in the shaded jar.[INFO] Including org.elasticsearch.plugin:percolator-client:jar:5.3.3 in the shaded jar.[INFO] Including io.netty:netty:jar:3.10.6.Final in the shaded jar.[INFO] Including org.apache.flink:force-shading:jar:1.11-SNAPSHOT in the shaded jar.[WARNING] Discovered module-info.class. Shading will break its strong encapsulation.[WARNING] Discovered module-info.class. Shading will break its strong encapsulation.[WARNING] Discovered module-info.class. Shading will break its strong encapsulation.[WARNING] Discovered module-info.class. Shading will break its strong encapsulation.[INFO] Replacing original artifact with shaded artifact.[INFO] Replacing /Users/robert/Projects/flink/flink-connectors/flink-connector-elasticsearch5/target/flink-connector-elasticsearch5_2.11-1.11-SNAPSHOT.jar with /Users/robert/Projects/flink/flink-connectors/flink-connector-elasticsearch5/target/flink-connector-elasticsearch5_2.11-1.11-SNAPSHOT-shaded.jar[INFO] Dependency-reduced POM written at: /Users/robert/Projects/flink/flink-connectors/flink-connector-elasticsearch5/target/dependency-reduced-pom.xml[INFO][INFO] --- maven-surefire-plugin:2.22.1:test (integration-tests) @ flink-connector-elasticsearch5_2.11 ---,2
[FLINK-16526][table-planner-blink] Fix exception when computed column expression references a keyword column nameThis is a followup fix of FLINK-16018.This closes #11380,2
[FLINK-16493][k8s] Use enum type instead of string type for KubernetesConfigOptions.REST_SERVICE_EXPOSED_TYPEThis closes #11346 .,5
[FLINK-16406] Increase default value for JVM Metaspace to minimise its OutOfMemoryErrorThis closes #11300.,0
[FLINK-16304][python] Remove python packages bundled in the flink-python jar. (#11238),2
[FLINK-15727][scripts] Return dynamic configs and JVM parameters in one call,2
"[FLINK-16550][s3] Force namespace parsing in XmlResponsesSaxParser.This commit explicitly enables Sax' NAMESPACES_FEATURE (default true) in JAXP (default false), such that multi part uploads to S3 actually work.",1
[FLINK-16343][table-planner-blink] Improve exception message when reading an unbounded source in batch modeThis closes #11387,1
[FLINK-16350][e2e] Run half of streaming HA tests against ZK 3.5,3
[FLINK-16539][sql-client] Trim the value when calling set command in sql cli This closes #11392,1
[FLINK-15090][tests] Explicitly depend on flink-clients,2
[FLINK-15090][tests] Move streaming env tests to flink-tests+ GetOperatorUniqueIDTest+ RemoteStreamEnvironmentTest+ ReinterpretDataStreamAsKeyedStreamITCase+ LocalStreamEnvironmentITCase,5
[FLINK-15090][compiler] Extract JobGraphGenerator#addUserArtifactEntries to a flink-runtime utils,2
[FLINK-15090][api] Reverse the dependency from flink-streaming-java to flink-clientsThis closes #10526 .,2
[FLINK-16330][AZP] Enable tests requiring S3 credentialsThis closes #11332,1
[FLINK-16250][python][ml] Add interfaces for PipelineStage and Pipeline (#11344),1
[hotfix][network] Fix the comments error in NettyMessage,0
"[FLINK-10742][network] Let Netty use Flink's buffers directly on receiver sideFor credit-based flow control, we always have buffers available for data that issent to use. We could thus use them directly and not copy the network stream intoNetty buffers first and then into our buffers. This improvement can reduce the totalNetty memory overhead to aovid potential direct OutOfMemoryError in large scale jobs.",0
"[FLINK-16008][python][table-planner][table-planner-blink] Add rules to transpose the join condition as a Calc on top of the Python Correlate node (#11299)Since currently we don't support joining a Python UDTF with conditions,add a rule to transpose the condition as a Calc on top of the Python Correlate node.",1
"[FLINK-16538][python][docs] Restructure Python Table API documentation (#11375)Adds an item ""Python Table API"" under ""Table API & SQL"" and move the documentation about Python Table API under it.",2
[FLINK-16464][sql-client] Result-mode tableau may shift when content contains Chinese string in SQL CLI (#11334)* [FLINK-16464][sql-client]result-mode tableau may shift when content contains Chinese String in SQL CLI* [FLINK-16464][sql-client]result-mode tableau may shift when content contains Chinese String in SQL CLI* address comment* add license and unit tests* revert pom header format,4
[FLINK-16524][python] Optimize the Python UDF execution to use generator to eliminate unnecessary function calls (#11374),1
"[FLINK-16261][table] Use type compatibility consistently to avoid castingIn many cases, full type equality is not necessary. Especially when leavingthe table ecosystem to sinks or UDFs a clear definition of ""type compatibility""is important. This commit defines the type compatibility for all logicaltypes to avoid unnecessary casting and less type inequality exceptions.This closes #11225.",2
"[FLINK-16554][task][refactoring] split StreamTask1. Extract static CheckpointingOperation and AsyncCheckpointRunnablefrom StreamTask to separate files to reduce complexity.No changes in logic or structure, just a simple refactoring.2. Cleanup CheckpointingOperation and AsyncCheckpointRunnable:Don't pass StreamTask as an argument3. move registering AsyncCheckpointRunnable Closeable to its run() method",1
"[FLINK-11088] Allow YARN to discover pre-installed keytab filesThis is to change how keytab files are discovered,    * remove hard-coded keytab filenames    * extended YARNSessionFIFOITCase to accommodate different types of security setting test cases regenerate configuration documentations",2
[FLINK-11088] Refactor keytab resolution to Utils,4
[FLINK-11088] Regenerate YARN/kerberos config docs,2
[FLINK-11088] Add unit test for Kerberos parsing in YarnEntrypointUtilsTest,3
[FLINK-14121] Update commons-compress because of CVE-2019-12402This closes #11333.,1
[hotfix][docs] fix mistakes in Modules documentThis closes #11399,2
[FLINK-16508][k8s] Name the ports exposed by the main Container in PodThis closes #11360 .,2
[FLINK-16541][doc] Fix document of table.exec.shuffle-modeThis closed #11386,2
[FLINK-16336][table] Add new type inference for temporal table functionsThis closes #11253.,1
[FLINK-16613] make build trigger on azp more reliable,1
"[FLINK-16573] Ensure Kinesis RecordFetcher threads shutdown on cancelThe threads may not shut down correctly because they do not check for therunning flag in the inner loops. The threads also do not get interrupted becausethey are not connected to the main task thread.These threads keep lingering around after the job has shut down:```Thread 23168: (state = BLOCKED) - java.lang.Object.wait(long) @bci=0 (Compiled frame; information may be imprecise) - org.apache.flink.streaming.connectors.kinesis.util.RecordEmitter.emitRecords() @bci=140, line=209 (Compiled frame) - org.apache.flink.streaming.connectors.kinesis.util.RecordEmitter.run() @bci=18, line=177 (Interpreted frame) - java.lang.Thread.run() @bci=11, line=748 (Compiled frame)```",1
[FLINK-16096][docs-zh] Translate dev/table/catalog.zh.md into ChineseThis closes #11390,1
[FLINK-16454][build] Update the copyright with 2020 year in NOTICE files,2
[FLINK-16413][hive] Reduce hive source parallelism when limit push downThis closes #11405,2
[FLINK-16623][sql-client] Add the shorthand 'desc' for describe in sql clientThis closes #11422,1
[FLINK-16607][python] Update flink-fn-execution.proto adding more schema information,5
[FLINK-16047][table-planner-blink] Fix Blink planner produces wrong aggregate results with state clean upThis closes #11419,4
[FLINK-16551][WebUI][tests] Improve assertions,3
[FLINK-16494][k8s] Switch to enum type for config option KubernetesConfigOptions.CONTAINER_IMAGE_PULL_POLICYThis closes #11406 .,5
"[FLINK-16586][network] Build ResultSubpartitionInfo and InputChannelInfo in respective constructorsIn the constructors of ResultSubpartition and InputChannel, the respective ResultSubpartitionInfo and InputChannelInfo should be created as well.These infos would be used for interacting with ChannelStateReader and ChannelStateWriter future.This cloese #11400.",1
[hotfix][task][tests] Remove useless import from TaskTest classThis cloese #11400.,3
Fix typo,2
[FLINK-16433][table-api] TableEnvironmentImpl doesn't clear buffered operations when it failsThis closes #11317,0
[FLINK-16565][python][ml] Make Pipeline Json compitable between Java and Python if all PipelineStages are Java ones (#11420),5
[FLINK-16606][python] Throw exceptions for the data types which are not currently supported,1
[FLINK-16373] Make JobManagerLeaderListener thread safeThe JobManagerLeaderListener used by the JobLeaderService was not thread safe. Stopping the listenerwhile notifying a new leader could lead to an IllegalStateException where the rpcConnection whichwas supposed to be started was concurrently closed by the stop call.This closes #11313.,1
[hotfix] Minor cleanups in JobLeaderService,4
[hotfix] Add JavaDoc to RegisteredRpcConnection#tryReconnect,1
[FLINK-16635] Remove pinned dependency for okio and okhttp from flink-metrics-influxdbWith FLINK-12147 we bumped the influxdb-java version from 2.14 to 2.16. At the sametime we still have okio and okhttp fixed to an incompatible version. This commitremoves the dependency management entries for these dependencies so that theinfluxdb reporter bundles the correct dependencies.,5
[FLINK-16635] Bump influxdb-java version to 2.17This commit bumps influxdb-java version from 2.16 to 2.17. This resolves adependency convergence problem within the influxdb-java dependency.This closes #11428.,5
"[FLINK-16083][docs-zh] Translate ""Dynamic Table"" page of ""Streaming Concepts"" into ChineseThis closes #11423",1
[FLINK-16646][orc] Flink read orc file throw a NullPointerException after re-openThis closes #11434,2
[hotfix][doc] Fix typos and broken links in memory configuration docs.,2
"[FLINK-15991][docs-zh] Translate the index of ""Memory Configuration"" into Chinese.This closes #11401",5
"[FLINK-15991][docs-zh] Translate the ""Set up Task Executor Memory"" page into Chinese.This closes #11401",1
"[FLINK-15991][docs-zh] Translate the ""Detailed Memory Model"" page into Chinese.This closes #11401",2
"[FLINK-15991][docs-zh] Translate the ""Memory tuning guide"" page into Chinese.This closes #11401",2
"[FLINK-15991][docs-zh] Translate the ""Troubleshooting"" page into Chinese.This closes #11401",2
"[FLINK-15991][docs-zh] Translate the ""Migration Guide"" page into Chinese.This closes #11401",2
[FLINK-15953][web] Fix color of RESTARTING status in Web UIThis closes #11433.,0
"[FLINK-15958][table-common] Introduce unresolved data types in APIIntroduces unresolved data types for class-based extraction, name-basedresolution, and configuration-based RAW types. Unresolved types behavelike regular data types but only after they have been resolved. Usingunresolved data types in nested structures leads to further unresolvedtypes. Thus, the usage of unresolved types is type-safe in API.This closes #11153.",0
[FLINK-16344][table-planner-blink] Preserve nullability for nested typesAvoids errors due to incompatible types during planning by preservingthe nullability attributes of nested types.This closes #11260.,0
[FLINK-15771][tests] Harden SQLClientKafkaITCase,3
[hotfix][tests] Fix exception in AutoClosableProcess,0
[FLINK-16583][sql-client] Provide classloader during pipeline creationFixes a classloading bug that was introduced in the last release whileupdating the code for the new Pipeline abstractions.This closes #11438.,1
[FLINK-16664][stream] fix wrong check for DataStreamSource#setParallelism()This closes #11446.,5
[FLINK-16592][docs] The doc of Streaming File Sink has a mistake of grammarThis closes #11409.,2
[FLINK-16432][hive] Fix dependencies in Hive Connector buildThis closes #11316,0
[FLINK-16675][test] Fix TableEnvironmentITCase.testClearOperation failureThis closes #11451,0
[FLINK-16236][yarn][hotfix] fix YARNSessionFIFOSecuredITCase not loading the right security context factory,2
[FLINK-16236][yarn][runtime] Change security context factory initialization1. throws exception when isCompatible returns true but initialziation fails.2. SecurityUtils handles logging of exception and fallback strategy to the next context factory.This closes #11189.,2
[hotfix] Add log4j2 properties file to flink-yarn-tests,3
[FLINK-13000][tests] Remove unused JobID parametersThis closes #11404.,2
[FLINK-16676][python][test] Fix ValidationPipelineTest.test_pipeline_from_invalid_json failure in Azure,0
[hotfix][docs] Fix broken links,2
[FLINK-16293] Document using plugins in Docker and KubernetesThis closes #11228.,3
[FLINK-15852][cli] Prioritize ExecutorCLI over YarnSessionCLI for active CLIThis closes #11435.,2
[hotfix] Make TestBulkWriterFactory publicly available for other test modules,3
[FLINK-16684] Fix StreamingFileSink builder compilation for ScalaThis commit introduces a new type name for the row and bulk formatStreamingFileSink builders in order to solve the compilation problemof Scala when using generic types with the self-type idiom.This closes #11454.,1
[FLINK-16650][python] Support LocalZonedTimestampType for Python UDF in blink planner (#11439),2
[FLINK-16220][json] Fix cast exception in JsonRowSerializationSchema when serializing null fieldsThis closes #11180,5
"[FLINK-16653][network][tests] Implement MockResultPartitionWriter base for simplifying testsAt the moment there are at-least four implementations of `ResultPartitionWriter` interface used in unit tests.And there are about ten methods to be implemented for `ResultPartitionWriter` and most of them are dummy in tests.When we want to extend the methods for `ResultPartitionWriter`, the above four dummy implementations in tests have to be adjusted as well, to waste a bit efforts.Therefore the MockResultPartitionWriter is proposed to implement the basic dummy methods for `ResultPartitionWriter`,and the previous four instances can all extend it to only implement one or two methods based on specific requirements in tests.It will probably only need to adjust the MockResultPartitionWriter when extending the `ResultPartitionWriter` interface.This closes #11441.",3
[FLINK-15962][network] Reduce the default chunk size to 4M in netty stack,2
"[FLINK-16633][AZP] Fix builds without s3 credentialsProblem: Builds on Azure where failing if S3 credentails were not provided, because the syntax in the pipeline definition was incorrect.Solution: Use a way to access secret variables that leads to an empty value (instead of the variable name). Also, extend the check in the unit tests to ""variable empty"" instead of just ""variable not set"".",1
[FLINK-16011] fix the bug that with will not effect if not in the end of pattern,0
[FLINK-16011] Distinguish between no time window and 0 length time windwo in NFACompilerThis closes #11200.,2
[FLINK-16691][python][docs] Improve Python UDF documentation to remind users to install PyFlink on the clusterThis cloese #11462.,2
[FLINK-16471][jdbc] develop JDBCCatalog and PostgresCatalogcloses #11336,2
[FLINK-16472] support precision of timestamp and time data typescloses #11336,5
[hotfix][task] Remove unnecessary fields and methods from StreamTaskThis closes #11459,4
[hotfix][tests] Remove dead codes from SynchronousCheckpointTestThis closes #11459,3
[FLINK-16690][tests] Refactor StreamTaskTest to reuse TestTaskBuilder and MockStreamTaskBuilderThis closes #11459,3
[FLINK-16345][table-planner-blink] Fix computed column can not refer row time attribute columnThis closes #11424,0
[FLINK-16532][core] Shouldn't trim whitespaces in PathThis closes #11393,2
[FLINK-16711][parquet] Parquet columnar row reader read footer from wrong endThis closes #11484,0
[FLINK-16652][orc] BytesColumnVector should init buffer in Hive 3.xThis closes #11485,5
[FLINK-15667][k8s] Support to mount custom Hadoop ConfigurationsThis closes #11415 .,5
[FLINK-16547][yarn] Respect the config option of FileJobGraphRetriever#JOB_GRAPH_FILE_PATHThis closes #11472.,2
[FLINK-16718][tests] Fix ByteBuf leak in KvStateServerHandlerTestThis closes #11453.,3
[hotfix][doc] Document union list metadata gotchaThis closes #11475.,5
[FLINK-16302][rest] Enable retrieval of custom TaskManager log filesAdd log list handler which lists all files in TaskManager log directory. Enableretrieval of custom TaskManager log files by name.This closes #11250.,2
[FLINK-16302][rest] Add tests for (un)marshalling LogListInfo,5
[FLINK-14971][checkpointing] Handle ack/declined message of checkpointin timer thread,0
[FLINK-14971][checkpointing] Introduce main thread executor in CheckpointCoordinator to execute all non-IO operations instead of the timer thread,2
[hotfix] Harden ResumeCheckpointManuallyITCaseThe way of detecting external checkpoint is done or not is not strict.The finalization of checkpoint might be interrupted by the cancallation.,1
[FLINK-14971][checkpointing] Make CompletedCheckpointStore thread-safe to avoid synchronization outside,1
"[FLINK-14971][checkpointing] Remove coordinator-wide lock of CheckpointCoordinatorSince all non-IO operations are executed in main thread, thecoordinator-wide lock could be avoided now.",4
"[FLINK-14971][checkpointing] Remove lock of PendingCheckpoint and introduce IO lock for PendingCheckpointSince all non-IO operations are executed in main thread, the lock ofPendingCheckpoint could be avoided now.",4
[FLINK-16092][docs-zh] Translate dev/table/functions/index.zh.md into ChineseThis closes #11461,1
[FLINK-16567][table][doc] Update to TableConfig in query_configuration documentThis closes #11410,2
[FLINK-16608][python] Remove the method which derives the LogicalType from the Arrow ValueVector,2
[FLINK-16608][python] Support BooleanType in vectorized Python UDF,1
[FLINK-16608][python] Support FloatType in vectorized Python UDF,1
[FLINK-16608][python] Support DoubleType in vectorized Python UDF,1
[FLINK-16608][python] Support VarCharType in vectorized Python UDF,2
[FLINK-16608][python] Support VarBinaryType in vectorized Python UDF,1
[FLINK-16608][python] Support DecimalType in vectorized Python UDF,1
[FLINK-16608][python] Support DateType in vectorized Python UDF,5
[FLINK-16608][python] Support TimeType in vectorized Python UDF,1
"[FLINK-16225] Improve metaspace out-of-memory error handling thrown in user codeImprove error message, explaining the possible reasons and ways to resolve.In case of metaspace OOM error, try a graceful TM shutdown.This closes #11408.",1
[FLINK-16225] Add JVM Metaspace Error assumption test,3
[FLINK-15989] Improve direct out-of-memory error handling in MemorySegmentFactory,0
[FLINK-15989] Add JVM Direct Error assumption test,3
[FLINK-16740][orc] Orc logicalTypeToOrcType fails to create decimal type with precision < 10This closes #11492,1
[FLINK-16732][hive] Failed to call Hive UDF with constant return valueThis closes #11494,0
[hotfix][runtime] Minor code clean-ups.,4
[hotfix][e2e] Deduplicate codes for building docker image with custom jar.,2
"[FLINK-15911][runtime] Refactor to create AkkaRpsService with builder class, in order to reduce the number of nested creating methods.",1
[FLINK-15911][runtime] Support configure address/port and bind-address/bind-port separately for JM/TM RPC services.,1
[FLINK-15911][runtime] Support configure address/port and bind-address/bind-port separately for netty shuffle service.,1
[FLINK-15911][runtime] Support unresolveable external hostname.,0
[FLINK-15911][e2e] Add e2e test for Flink over NAT.This closes #11284.,2
[FLINK-15647][k8s] Support user-specified annotations for the JM/TM pods,1
[FLINK-15647][k8s] Return an empty Map instead of null when annotations is not setThis closes #10973.,1
[FLINK-16170][elasticsearch] Fix SearchTemplateRequest ClassNotFoundException when using flink-sql-connector-elasticsearch7 We shouldn't `exclude org.elasticsearch:elasticsearch-geo` and `org.elasticsearch.plugin:lang-mustache-client` when shading.This closes #11396,2
[FLINK-15579][table-planner-blink] UpsertStreamTableSink should work on batch mode,1
[FLINK-15579][table-planner-blink] Fix UpsertStreamTableSink support and add tests,3
"[FLINK-16712][task] Refactor StreamTask to construct final fieldsAt the moment there are four fields initialized in the method of StreamTask#beforeInvoke, such as `stateBackend`, `checkpointStorage`, `timerService`, `asyncOperationsThreadPool`.In general it is suggested to use final fields to get known benefits. So we can refactor the StreamTask to initialize these fields in the constructor instead.This closes #11486",5
[FLINK-15640][k8s] Support to set labels for jobmanager and taskmanager podThis closes #11489 .,1
[FLINK-16625][utils] Extract BootstrapTools#getEnvironmentVariables to ConfigurationUtils#getPrefixedKeyValuePairsThis closes #11458 .,5
[FLINK-16604][web] JM config key column has 30% width,5
[FLINK-16629] Ignore Streaming bucketing end-to-end test with Hadoop 2.4.1,3
[FLINK-16663][docs] Interpret versions as strings,2
[FLINK-16692] Register custom JobListeners throug config.This closes #11471.,5
[FLINK-16316][task] Remove StreamTask dependency from AbstractStreamOperator#snapshotState,1
"[FLINK-16316][operators] Remove chaining strategy methods from the StreamOperator interfaceThose methods do not have any reason to be on the StreamOperator level since we introducedStreamOperatorFactory concept, so they should be moved to SetupableStreamOperator",1
[FLINK-16316][operators] Pass StreamTaskStateInitializer to operators from outsideThis removes another dependency on the StreamTask from AbstractStreamOperator,1
[hotfix][test] Fix formatting in AbstractStreamOperatorTest,3
[hotfix][test] Remove no-op tests for AbstractStreamOperatorThose two tests were not performing any assertions since [FLINK-13326] (c75af84d44dfb9b883115bf4fd65b6a5989464e4),2
[FLINK-16316][operators] Extract state handling code from AbstractStreamOperatorIntroduce StreamOperatorStateHandler class for that purpose and move more logic intoIntrenalTimeServiceManager.This makes AbstractStreamOperator a simpler class and will allow to deduplicate code withnew replacement of AbstractStreamOperator that will come soon.,1
[FLINK-16316][operators] Cut dependency between StreamingRuntimeContext and AbstractStreamOperatorThis simplifies dependencies between those two classes and will allow for StreamingRuntimeContextto be re-used in new replacement for AbstractStreamOperator.,1
[FLINK-16316][operators] Move inner CountingClass class out from AbstractStreamOperator,1
"[FLINK-16316][operators] Introduce StreamOperatorParameters classNew POJO class will make Public and PublicEvolving interfaces more stableand easier to use. User will not have to pass n parameters, but just thisone POJO.",2
[FLINK-16316][operators] Implement new AbstractStreamOperatorV2 as a replacement for AbstractStreamOperatorThe new base class for operators tries to address couple of limitations in the AbstractStreamOperator like:- lack of support for multiple inputs- setup(...) method,1
[FLINK-16316][operators] Make StreamOperatorFactory Experimental,1
[FLINK-16166][build] Append additional javadoc options,2
[FLINK-16377][table] Support calls to inline functions in theexpressions DSL.,1
[FLINK-16480][AZP] fix log upload condition,2
"[FLINK-16480][e2e] On failure, add e2e logs into artifactThis closes #11501",2
[hotfix][tests] Remove dead code,4
[FLINK-16317][operators] Provide support for watermarks in  MultipleInputStreamOperator,1
"[FLINK-16317][operators] Refactor AbstractStreamOperatorTest classThis deduplicates code a little bit, fixes not closing issue and makes it ready for future extension that comes in next commit.",1
[FLINK-16317][operators] Implement AbstractStreamOperatorV2Test,3
[FLINK-16317][operators] Provide support for key selector and latency marker in MultipleInputStreamOperator,1
[FLINK-16317][operators] return this from (Keyed)MultipleInputTransformation#addInput,1
[FLINK-16778][e2e] Make sure all java e2e tests are running,1
[hotfix] Remove unused method in TaskExecutorProcessUtils,1
[hotfix] add int type to JOB_MANAGER_HEAP_MEMORY_MB option,1
[hotfix] change type of JOB_MANAGER_HEAP_MEMORY option from String to MemorySize,4
[FLINK-16615] Introduce data structures and utilities to calculate Job Manager memory componentsThis closes #11445.,5
[FLINK-15438][metrics][datadog] Report counter deltas and not totalsThe Flink semantics of a counter are not matching with the countersin DataDog. In Flink a counter counts the total of increment anddecrement calls. In DataDog a counter is the number of incrementand decrement calls during the reporting interval.,5
[FLINK-15438][metrics][datadog] Add DCounterTest,3
[FLINK-16795][AZP] Increase e2e test timeout by 40minThis closes #11522,3
[FLINK-16790][python][doc] Enables the interpretation of backslash escapes (#11526),0
[FLINK-16671][python] Support for defining scopes on Python metric group (#11470),5
[FLINK-16805][e2e] Remove pre-commit profile activation,2
[FLINK-16786][hotfix] Fix pyarrow version in setup.py (#11517),1
"[FLINK-16702] develop JDBCCatalogFactory, descriptor, and validator for service discoverycloses #16702",5
[hotfix][jdbc] rename PostgresCatalogITCase to PostgresCatalogTest,3
[FLINK-16498] connect PostgresCatalog to table planner,2
[FLINK-16411][AZP] Use google mvn mirror globallyThis closes #11314,1
[FLINK-16810][jdbc] add back PostgresCatalogITCaseadd back PostgresCatalogITCase which is supposed to be part of #11468,2
[hotfix][connector] Correct exception message (#11523),0
[hotfix][jdbc] add license header to PostgresCatalogITCase,2
"[FLINK-16127][docs-zh] Translate ""Fault Tolerance Guarantees"" page of connectors into ChineseThis closes #11129",1
"[FLINK-16128][docs-zh] Translate ""Google Cloud PubSub"" page into ChineseThis closes #11151",1
[hotfix][python] Improve the imports to use full path when importing a PyFlink module (#11525),2
[FLINK-16647][hadoop-compatibility] Refactor HadoopUtils to extract a possible Hadoop conf util methodThis closes #11440,5
[FLINK-16647][hive] Hive connector should read mapred-site.xmlThis closes #11440,5
[FLINK-16647][table-runtime-blink][hive] Miss file extension when inserting to hive table with compressionThis closes #11440,2
[FLINK-16821][e2e] Use constant minikube version instead of latest,3
[FLINK-11404][web] Add load more feature to exception pageThis closes #11436.,1
"[FLINK-16825][prometheus][tests] Use Path returned by DownloadCacheIf the test is ran multiple times, newly downloaded files will get numbered prefixes (e.g. file.tar.gz.1). This causes an error because the wrong bath is used. This commit fixes this issue.",0
[FLINK-16798][scripts] Properly forward BashJavaUtils logging output,2
"[FLINK-16826][e2e] Support copying of jarsJARs copying into multiple locations is required for testing plugins-loading mechanism. Currently only ""move"" operations is supported, this commit extends it to also support ""copy"" operations.",1
[FLINK-16828][prometheus][metrics] Support factories,1
[hotfix][coordination] Exit early for empty collection,0
[hotfix][tests] Rename variable,3
[FLINK-14792][coordination] Rework partition storage,1
[FLINK-14792][coordination] Implement TE cluster partition release,2
[hotfix][metrics] Do not log reporter config to prevent credentials leak,5
[FLINK-16594][runtime] Fix typo in GlobalAggregateManager JavadocThis closes #11548.,2
"[FLINK-16831][e2e] Support plugin directory as JarLocationAdds the plugins directory to the set of supported jar locations.Every plugin must be contained in a sub-directory within the plugins directory, so for simplicity we always create a parent directory regardless of what the target location is.",1
[hotfix][metrics][prometheus] Add missing import,2
[FLINK-16832][metrics] Refactor ReporterSetupIntroduce methods for better readibility.,1
[FLINK-16222][core] Relax Plugin bounded type parameter constraint,2
[FLINK-16222][runtime] Introduce PluginManager to ReporterSetup,1
[FLINK-16222][metrics] Support loading reporters as plugins,1
[FLINK-16222][metrics][prometheus] Add plugin e2e test,3
[FLINK-15100][connector/common] Add abstract implementation for SourceReader (FLIP-27).,1
[FLINK-16262][connectors/kafka] Set the context classloader for parallel stream in FlinkKafkaProducerThis closes #11247,2
[FLINK-15101][hotfix] Remove the BOUNDEDNESS option from SourceReaderOptions,4
[FLINK-16070] [table-planner-blink] Stream planner supports remove constant keys from an aggregateThis closes #11158,4
[FLINK-16727][table-planner-blink] Fix cast exception when having time point literal as parametersThis closes #11550,2
"[FLINK-16672][python] Support Counter, Gauge, Meter, Distribution metric type for Python UDF (#11543)",1
[FLINK-16862][quickstarts] Remove example url,4
[FLINK-13483] Retry delete when checking path existence in AbstractHadoopFileSystemITTestThis closes #11516.,5
[FLINK-16806][operators] Fix shouldSetAvailableForAnotherInput for MultipleInputStreamOperator,1
[FLINK-16806][operators] Add support for InputSelection to MultipleInputStreamOperator,1
[hotfix][operators] Rename InputSelectable inputSelector field to inputSelectable,0
[FLINK-16741][web] Add TM log list and TM log detail pageThis closes #11498.,1
[FLINK-16847][python] Support LocalZonedTimestampType in vectorized Python UDF,1
[FLINK-16847][python] Support TimestampType in vectorized Python UDF,1
[FLINK-14338][flink-table] Update flink table POM and NOTICE file Calcite dependency to 1.22.0This closes #11340,2
"[FLINK-14338][sql-parser] Bump sql parser Calcite dependency to 1.22.0* Add Junit5 supports for tests* Move classes under package calcite.sql to flink.sql.parser.type* Remove ExtendedSqlBasicTypeNameSpec, use SqlAlienSystemTypeNameSpec instead* In Parser.tdd, re-organize the imports order to alphabetical order, remove the useless tailing commas, extends nonReservedKeywordsToAdd* Fix the JavaCC compile warnings",2
[FLINK-14338][table-planner][table-planner-blink] Implements new RelMetadataQuery extension* This feature is introduced in CALCITE-3446,5
[FLINK-14338][table-planner][table-planner-blink] Remove usage of TableScanRule and use new TableScanFactory extension* This change was introduced in CALCITE-3769,4
[FLINK-14338][table-planner][table-planner-blink] Tweak implementations due to API change* Replace RelOptUtils.createCastRel with RelOptUtil.createCastRel* Implement RelOptTable#getKeys and Statistic#getKeys* Changes logical nodes constructor for hints* Implement RelShuttle.visit(LogicalTableModify),2
[FLINK-14338][table-planner][table-planner-blink] Remove redundant code copy because the bugs are already fixed in Calcite* SqlValidatorImpl.java was removed because of CALCITE-2707* ParameterScope.java was removed because of CALCITE-3476* SqlFunction.java was removed because of CALCITE-3360,1
"[FLINK-14338][table-planner-blink] Plan verify changes from DIGEST to EXPLAIN* Because of CALCITE-3713, the project names was removed from plan DIGEST, thus, the DIGEST plan has less info that EXPLAIN, we switch to EXPLAIN for plan verification;* The CALC window fields name was also changes with CALCITE-3713, which is acceptable because the old name was also un-readable, the new name was based on field index, not bad.",1
[FLINK-14338][table-planner-blink] Plan verify changes from DIGEST to EXPLAIN: change plan for expand node* The explain node does not show each projects names anymore,4
[FLINK-14338][table-planner-blink] Plan verify changes from DIGEST to EXPLAIN: change plan for values node* The values node does not print row type anymore,4
[FLINK-14338][table-planner][table-planner-blink] Update files due to builtin TUMBLE operator name changes to $Tumble* This change was introduced in CALCITE-3382,4
[FLINK-14338][table-planner][table-planner-blink] Update files due to CALCITE-3763* CALCITE-3763 prunes useless fields of input project,1
[FLINK-14338][table-planner-blink] Update files due to CALCITE-1824* GROUP_ID translation was fixed,0
"[FLINK-14338][table-planner][table-planner-blink] Update all kinds of left plan changes* Some join order changes for blink-planner due to the rule fire sequence changes, see https://github.com/apache/calcite/commit/35caa059a762094c7df0b30e9b51358a19b48ac2, they are still correct* The Correlate row count estimation has been fixed from a always 1 to join like estimation, thus, if the inputs of Join is a Correlate, the join algorithm would very probably changes, i.e. batch.sql.SubplanReuseTest* Due to CALCITE-3729, the filter condition was pushed down for some Join cases: batch.sql.join.JoinReorderTest* Due to CALCITE-2450 RexNode normalization, the predicates sequence of some test changes: logical.subquery.FlinkRewriteSubQueryRuleTest* The Decimal modulus precision inference has been fixed: planner.expressions.DecimalTypeTest",3
[FLINK-16796][python] Fix the bug of Python UDTF in SQL query (#11521),0
[FLINK-16673][python] Support metric for Python UDTF (#11566),1
[FLINK-16857][table-planner-blink] Support partition prune by getPartitions of sourceThis closes #11560,1
[FLINK-16767][hive] Failed to read Hive table with RegexSerDeThis closes #11504,0
[hotfix][runtime][tests] Rename/move ClassLoaderTestThe test is actually testing FlinkUserCodeClassLoaders.,2
[FLINK-16245][runtime] Decouple user from context classloaderAllows user classloader can be unloaded even if a reference on the context classloader outlives the user code.,1
[FLINK-16245][table] Close user classloader,1
"[FLINK-16245][tests] Adjust BatchFineGrainedRecoveryITCaseBecause the classloader is now closed when the task fails the UDF only has access to the bootstrap classloader, which doesn't contain our own test classes.",3
"[FLINK-16018] Increase default value of web.timeout to 10 minutesIn order to not fail the job submission with a TimeoutException ifit takes longer than 10 s, this commit increases the web.timeout to10 minutes.This closes #11565.",1
[hotfix][rpc] Add proper error reporting to AkkaRpcActor#handleControlMessage,0
"[FLINK-16703][rpc] Set AkkaRpcActor state to TERMINATING when terminatingThis commit fixes a bug where we did not update the state of the AkkaRpcActorin case of terminating it. Moreover, this commit fixes the problem that theonStop action could have been called multiple times. Last but not least, itchanges the enum names of the state implementations for better diagnostics.This closes #11549.",1
[FLINK-16836] Clear rpcConnection field in JobManagerLeaderListener when target loses leadershipClearing the rpcConnection field in the JobManagerLeaderListener when target loses leadershipprevents that we try to reconnect to the target in case JobLeaderService.reconnect(JobID) iscalled.This closes #11552.,1
[FLINK-16878][e2e][table] Fix dependency shading of table modules test failure after FLINK-14338This closes #11575,2
[FLINK-16849] [docs] Comment is not reasonable,2
[FLINK-16411][AZP] Cache maven artifacts for tests as well,3
[hotfix] Fix typo in org.apache.flink.sql.parser.ddl.SqlCreateTableThis closes #11580,2
[FLINK-16858][table] Expose partitioned by grammarThis closes #11559,2
[FLINK-16888][legal] Add jquery licensejquery is used for the documentation.,2
[FLINK-16807][e2e] Improve reporting for instantiation errors,0
[FLINK-16808][e2e] Consolidated logging,2
[FLINK-16837][build] Disable trimStackTrace in surefire-plugin,2
[FLINK-16877][table-runtime] SingleDirectoryWriter should not produce file when no input recordThis closes #11572,2
[FLINK-16834] Add flink-clients dependency to all example modulesThis commit adds a flink-clients dependency to all example modules. Thatway they become executable from the IDE again.,2
[hotfix] Add log4j2 and logback properties file to flink-examples-table,2
[FLINK-16834] Add flink-clients to flink-quickstarts pomsFlink quickstarts' poms need to include flink-clients as a dependency because it isno longer transitively pulled into the project.,1
"[FLINK-16834] Add flink-clients dependency to flink-walkthroughsWith inverting the dependency between flink-clients and flink-streaming-java,it is now necessary to explicitly add the flink-clients dependency in orderto execute the walkthrough jobs from within the IDE.This closes #11551.",2
[FLINK-16674][python][docs] Add documentation about how to use user-defined metrics for Python UDF (#11576),1
"[FLINK-14311] Relax restart checker to harden StreamingFileSink e2e testBefore, we were checking for an exact number of restarts, this is toostrict, because we could have more than the expected number of restarts.Now we check whether we have gte the number of expected restarts.",1
[minor] Add debug logging if aws cli command failsThe motivation is to help debugging FLINK-15772.,2
[FLINK-16035] Updated Stream/BatchTableEnvironment.java to use Java's Expression DSLThis PR introduces alternatives for methods that are using the String based expressions in TableEnvironments.This PR also removes all usages of the String based expressions methods. It is a preparation for deprecating and in result removing those methods in the future.,4
[FLINK-16036][table-api] Deprecate String based Expression DSL in TableEnvironmentsThis closes #11527,2
[hotfix][table] Fix scalastyle issue,0
[FLINK-16737][k8s] Remove KubernetesUtils#getContentFromFileThis closes  #11569 .,2
[FLINK-16535][table] BatchTableSink emitDataSet to consumeDataSetThis closes #11376,5
[FLINK-16860][orc] Distinguish empty filters from no pushed down in expainSourceThis closes #11594,2
"[FLINK-16560] Forward Configuration in PackagedProgramUtils#getPipelineFromProgramBefore, when using PackagedProgramUtils (for example in the standalonecluster entrypoint or the web ui) the Flink Configuration would not beapplied to the execution environment.This also adds a test that verifies that we forward configuration.",5
"[FLINK-14316] Properly manage rpcConnection in JobManagerLeaderListener under leader changeThis commit changes how the rpcConnection is managed in JobManagerLeaderListener under leader change.This component clears now the fields rpcConnection and currentJobMasterId if the leader loses leadership.Moreover, it only restarts a connection attempt if the leader session id is new.This closes #11603.",1
[FLINK-16944][tests] Fix compile errors,0
[FLINK-16917][runtime] Revert FLINK-16245,2
[FLINK-16939][rest] Declare field taskManagerIdParameter finalThis closes #11612.,2
[FLINK-16940][runtime] Create currentRegion HashSet with default capacityThis closes #11613.,1
[hotfix][coordination] Add sanity checks to ClusterPartitionReportEntry,1
[FLINK-14791][coordination] ResourceManager tracks ClusterPartitions,2
[FLINK-16916][serialization] Fix the logic of NullableSerializer#copy,2
[FLINK-16125][connecotr/kafka] Remove Kafka connector property zookeeper.connect and clear documentation because Kafka 0.8 connector has been removed.,4
[FLINK-16885][hive] Remove wilcard excludes that don't work on maven 3.1.XThis closes #11620,1
[FLINK-16476] [table-planner-blink] Remove PowerMockito to avoid LinkageError in SelectivityEstimatorTest,3
[FLINK-16476] [table-planner-blink] Remove PowerMockito to avoid LinkageError in AggCallSelectivityEstimatorTest,3
[FLINK-16389][kafka] Bump kafka version to 0.10.2.2,2
[FLINK-16942][es] Allow users to override http/transport type,1
"Revert ""[FLINK-16535][table] BatchTableSink emitDataSet to consumeDataSet""This reverts commit 9ffa85aaa1b9025e3d2becdc084a02aa8440d4d9.",4
[FLINK-16772][hive] Move derby dependency to test scope,3
[FLINK-16921][e2e] Do not start/stop minikube in non-linux environment for k8s e2e tests,3
[FLINK-16921][e2e] Print more information for debugging when Kubernetes e2e tests failed,0
[FLINK-16921][e2e] Wait for rest endpoint up and then submit Flink job to existing Kubernetes session,2
[FLINK-15305][tests] Make BoundedDataTestBase#testGetSizeMultipleRegions respect system page size to avoid potential failure,0
[hotfix][metrics] Extend MetricReporterFactory javadocs,2
"[FLINK-16705] Ensure MiniCluster shutdown does not interfere with JobResult retrievalThere is a race condition in `LocalExecutor` between (a) shutting down thecluster when the job has finished and (b) the client which retrieves the resultof the job execution.This was observed in Beam, running a large test suite with the Flink Runner.We should make sure the job result retrieval and the cluster shutdown do notinterfere. This adds a PerJobMiniClusterClient which guarantees that.Improve message for running flag state checks in MiniClusterAdditionally check for the JobID in PerJobMiniClusterClientIntroduce PerJobMiniCluster and a corresponding JobClientAdd TestLogger to testConvert shutdown methods to be asyncThis closes #11473.",3
[hotfix] Add resourceManagerGateway null check to SlotPoolImplSlotPoolImpl's resourceManagerGateway field can be null if JM hasnot connected to the ResourceManager yet. SlotPoolImpl's methodsshould respect this contract.,1
[FLINK-6258] Deprecate ListCheckpointed interfaceThis also updates the documentation and changes usage in our code toCheckpointedFunction.The Google PubSub source unfortunately also uses ListCheckpointed buthere we cannot migrate to CheckpointedFunction because of savepointcompatibility.,1
[FLINK-16044][doc] Extract libraries documentation to a top-level section,2
[FLINK-16045][doc] Extract connectors documentation to a top-level section,2
[FLINK-16710][runtime] Avoid blocking TaskExecutor Main ThreadAvoid blocking TaskExecutor main thread when uploading log files.This closes #11571.,2
"[FLINK-16921][e2e] Describe all resources and show pods logs before cleanup when failedThe pods may be pending because of not enough resources, disk pressure, or other problems. Then wait_rest_endpoint_up will timeout. Describing all resources will help to debug these problems.",0
[FLINK-16980][python] Fix Python UDF to work with protobuf 3.6.1 (#11631),1
"[FLINK-16098][docs-zh] Translate ""Overview"" page of ""Hive Integration"" into ChineseThis closes #11455",1
"[FLINK-16913] Migrate StateBackends to use ReadableConfig instead of ConfigurationStateBackendFactories do not need a full read and write access to theConfiguration object. It's sufficient to have read only access. Moreoverthe ReadableConfig is a lightweight interface that can be implemented inother ways, not just through the Configuration. Lastly we exposed thislightweight interface as a configuration entry point forExecutionEnvironments. This change will make it possible to pass theReadableConfig directly to the StateBackendFactories without fragileadapters.",5
[FLINK-16979][hive][build] Exclude jdk.tools,2
[hotfix] Make the checkpoint resuming e2e case pass by increasing the retained checkpoints number,1
[hotfix][metrics][javadocs] Fix typo,2
[FLINK-14126][e2e] Enforce elasticsearch version check,1
[FLINK-16981][tests] Add global PowerMock exclusions,1
[minor] Remove --quiet from aws file fetching to help debugging,0
[FLINK-15772] Add retry to test_batch_wordcount file fetchingThe suspicion is that test flakyness was caused by S3 flakyness/eventualconsistency.,1
"[FLINK-15998] In Glossary, clarify Application/Job cluster description",2
[FLINK-16921][e2e] Disable K8s tests until instability is resolved,0
[FLINK-16655][FLINK-16657] Introduce embedded executor and use it in Web SubmissionThis closes #11460.,1
[FLINK-16657] Allow the (Stream)ContenxtEnv to enforce single job execution,1
[FLINK-16657] Forbid blocking calls in JobClient when in Web Submission,2
[minor] Rename ExecutorUtils to PipelineExecutorUtils,5
[FLINK-16912][parquet] Introduce table row write support for parquet writerThis closes #11602,1
[FLINK-16830][table-api] Let users use Row/List/Map/Seq directly in Expression DSLThis PR implements conversion logic from Row/List/Map/Seq to a corresponding Expression. From now on users can use those types in the Expression DSL without the need to converting those types manually.It is also a prerequisite to use those type directly in TableEnvironment#fromValues.,1
[FLINK-16859][filesystem][table-runtime] Introduce file system table factoryThis closes #11574,5
[FLINK-14266][csv] Introduce RowCsvInputFormat to CSV moduleThis closes #9884,2
[hotfix][k8s] Remove the outdated comments and unused config option,5
"[FLINK-16749][k8s] Support to set node selector for jobmanager and taskmanager podThe node-selector is a collection of key/value pairs to constrain a pod to only be able to run on particular node(s). Since affinity and anti-affinity are uncommon use case for Flink, so we leave the support in pod template.This closes #11500 .",1
[FLINK-16914][table-runtime-blink] Introduce array column vector in blink,2
[FLINK-16914][python] Support ArrayType in vectorized Python UDF,1
[FLINK-16590] flink-oss-fs-hadoop: remove erroneous license referencesThis is updated based on the output of the maven-shade-plugin onflink-oss-fs-hadoop.,2
[FLINK-17007][docs] Add section 'Handling Application Parameters' in DataStream,5
[FLINK-16973][tests] Add tooling for collecting jvm crash files,2
"[FLINK-16537][network] Implement ResultPartition state recovery for unaligned checkpointDuring state recovery for unaligned checkpoint, the partition state should also be recovered besides with existing operator states.The ResultPartition would request buffer from local pool and then interact with ChannelStateReader to fill in the state data.The filled buffer would be inserted into respective ResultSubpartition queue in normal way.It should guarantee that op can not process any inputs before finishing all the output recovery to avoid mis-order issue.",0
"[FLINK-17010] Remove --quiet from s3 get operationThe reason this failed with --quiet is that the test redirects stdout toget the sorted results:get_complete_result > ""${TEST_DATA_DIR}/complete_result""5f2f7d637d8073b1034f8c1124f52604745936eb removed the --quiet parameterfrom the s3 fetch command, which changed what is printed to stdout. Thes3 command is printing which file it is downloading and this log messagealso ends up in the ""result"" output that is being sorted and checked.",2
[FLINK-16817][core] StringUtils.arrayToString() doesn't convert array of byte array correctly,2
[FLINK-16811][jdbc] introduce row converter API to JDBCDialectcloses #11652,5
"[FLINK-16535][table] rename BatchTableSink#emitDataSet to BatchTableSink#consumeDataSet, and return DataSink",5
"[FLINK-16632][table-planner-blink] Fix SqlDateTimeUtils#toSqlTimestamp(String, String) may yield incorrect resultThis closes #11654",5
[FLINK-17040][tests] Fix SavepointWriterITCase failure because of UnsupportedOperationException,1
"[FLINK-16864][metrics] Add IdleTime metric for taskThis pr adds an IdleTime metric which measures idle time of a task including the time cost for mail processor to wait for new mail and the time cost in record writer to waiting a new buffer.1. when a job can not catch up with the speed of data generating, the vertex which idle time is near to zero is the bottle neck of the job.2. when a job is not busy, idle time can be used to guide user how much he can scale down the job.",1
[FLINK-16856][scripts] Manually calculate lines of logging output'head' with a negative '-n' argument isn't standardized.,2
[FLINK-16602][k8s] Rework the internal & external Service1.The REST service serves REST traffic while the internal service serves internal requests from TMs to JM.2.The REST service is always created but the internal service is only created in non-high availability setup.Co-authored-by: felixzheng <felixzheng@tencent.com>This closes #11456 .,1
[FLINK-14162][runtime] SchedulerOperations#allocateSlotsAndDeploy always deploys tasks in a bulk,2
[FLINK-16945][checkpointing] Execute CheckpointFailureManager.FailJobCallback directly in main thread executor,0
"[FLINK-9429] run-single-test.sh: fix order of ""imports""Some e2e tests that rely on FLINK_VERSION being set, such astest_quickstarts.sh, didn't work with run-single-test.sh before.The reason the tests didn't work locally is that run-single-test.sh hasthe order of ""imports"" wrong. i.e. we have: source ""${END_TO_END_DIR}/test-scripts/test-runner-common.sh"" source ""${END_TO_END_DIR}/../tools/ci/maven-utils.sh""while run-nightly-tests.sh has: source ""${END_TO_END_DIR}/test-scripts/test-runner-common.sh"" source ""${END_TO_END_DIR}/../tools/ci/maven-utils.sh""This leads to this line failing in test-runner-common.sh because mvn_runis not available:  export FLINK_VERSION=$(MVN_RUN_VERBOSE=false run_mvn --file ${END_TO_END_DIR}/pom.xml org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate -Dexpression=project.version -q -DforceStdout)",1
"[FLINK-16555] Reject Enum as key typehashCode() of Enum type calls Object.hashCode(), therefore keyBy on Enumtype could lead to incorrect data routing.",5
[FLINK-17035][runtime] Add new methods to TestingSchedulingTopology- Enable adding single vertex to TestingSchedulingTopology.- Enable setting 'containsCoLocationConstraints' flag.,1
[FLINK-17035][runtime] Replace FailoverTopology with SchedulingTopology,2
[FLINK-17035][runtime] Rename method TestingSchedulingExecutionVertex#newVertex()Rename method to TestingSchedulingExecutionVertex#newExecutionVertex().This closes #11659.,3
[FLINK-16988][table] Add core table source/sink interfacesAdds the core set of interfaces described in FLIP-95.This closes #11646.,1
"[FLINK-16513][checkpointing] pre-requisite refactorings to add channel state to snapshot metadataMotivation:Currently, there is a lot of code duplication for different types of states (keyed/operator, managed/raw).With the upcoming addition of channel state it increases even further.This is mostly code in CheckpointCoordinator in JM; and also OperatorSnapshotFutures in TM.Changes:1. convert some ""procedures"" with multiple ""output"" parameters to functions called multiple times2. parameterize OperatorStateRepartitioner and related code so that it can be applied to collections of any type of state3. extract common code",4
[FLINK-16513][checkpointing] add task channel state for unaligned checkpointsChanges:1. add channel state metadata to OperatorSubtaskState2. adjust StateAssignmentOperation3. adjust metadata serialization4. adjust related classesThis closes #11491.,5
"Revert ""[FLINK-16864][metrics] Add IdleTime metric for task""This reverts commit 18787230ea0bb3b502a8002b9f4f0fa0afb85f63.",4
[hotfix][table-api] Change QueryOperations' factories scope to default,4
[hotfix] Fix logical type generalization for approximate types.,2
[hotfix][table-api] Add literal conversions between all numeric types.,1
"[hotfix][tabe, tests] Extract FunctionLookupMock to be reusable.",1
[FLINK-15812][runtime] Archive jobs asynchronously,2
[FLINK-16696][rest] Properly document async responses,2
[FLINK-16696][javadocs] Correct field name for operation result,2
[FLINK-17047][runtime] Change SchedulingStrategy#onPartitionConsumable() to take IntermediateResultPartitionID instead of ResultPartitionIDResultPartitionID is a composition of IntermediateResultPartitionID and ExecutionAttemptID.SchedulingStrategy is not aware of ExecutionAttemptID so there is no need to expose it.,4
[FLINK-17047][runtime] Remove the producerId param from SchedulingStrategy#onPartitionConsumable()Its redundancy since we can also retrieve it from the partition.,2
[FLINK-17036][metrics][datadog] Support EU data center,5
[FLINK-16666][table][python] Introduce Python dependency config optionsThis closes #11448.,5
[FLINK-17065][python][doc] Add documentation about the Python versions supported for PyFlink (#11685),2
[FLINK-17062][python] Fix the conversion from Java row type to Python row typeThis closes #11680.,0
"[FLINK-16864][metrics] Add IdleTime metric for taskThis pr adds an IdleTime metric which measures idle time of a task including the time cost for mail processor to wait for new mail and the time cost in record writer to waiting a new buffer.1. when a job can not catch up with the speed of data generating, the vertex which idle time is near to zero is the bottle neck of the job.2. when a job is not busy, idle time can be used to guide user how much he can scale down the job.",1
[FLINK-17063][table-api] Make null type be a possible result of a type inference.There are use cases that can benefit from making a null type a valid result of an input and output type inference.E.g We can use null type in VALUES clause for a temporary placeholder that will be later inferred based on types of other rows.,5
FLINK-16697][metrics][jmx] Disable rebinding,2
[FLINK-15817][k8s] Clean up residual resources when failed to deploy a new ClusterThis closes #11672.,1
[FLINK-16687][python] Support Python UDF in Java Correlate (#11650),1
[FLINK-16744][task][hotfix] Finalize StreamTask methods used during constructionMotivation: prevent access to uninitialized descendant state fromStreamTask constructor which otherwise leads to NPE,5
[FLINK-16744][task][refactor] Extract SubtaskCheckpointCoordinatorMotivation:1. move checkpoint-related responsibilities out of StreamTask2. ability to cache checkpoint storage locations for unaligned checkpoints,4
[FLINK-16744][task] Split finish() in ChannelStateWriterSplit finish() in ChannelStateWriter into finishIn and finishOut to ease client usage,5
[FLINK-16744][task] Implement channel state reading and writing for unaligned checkpoints,2
"[FLINK-16744][task] Send channel state handles to JM1. add channel state writer to SubtaskCheckpointCoordinator2. add handles to the reported snapshot3. cache checkpoint locations to prevent multiple streamsper checkpoint. With unaligned checkpoints, checkpointcan be initiated from several places which can result(without cache) in multiple streams/files for a singlecheckpoint",2
[FLINK-16744][task][test][hotfix] Fix formattingRemove extra newline in TestTaskStateManager,3
[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImplMinor refactoring of  SubtaskCheckpointCoordinatorImplto reduce its methods complexity,4
[FLINK-9656][scripts] Take also env.java.opts from flink-conf.yaml at the client side,5
[FLINK-9656][scripts] Add DEFAULT_ENV_JAVA_OPTS_CLI & KEY_ENV_JAVA_OPTS_CLI to read env.java.opts.client from flink-conf.yaml,5
[FLINK-9656][docs] Add env.java.opts.client to docs,2
[FLINK-9656] Add FLINK_CLI_JVM_OPTIONS with key env.java.opts.clientThis closes #11595.,2
[hotfix] Update CoreOptions JVM options to use stringType,1
[FLINK-16668][python] Improve PythonDriver to parse python dependency info from configurationThis closes #11682.,5
[FLINK-17081][table-planner-blink] Extend batch integration tests with TestLoggerThis closes #11689,3
[FLINK-16761][python] Return JobExecutionResult for Python execute method (#11670),2
[hotfix][doc] Typo fixups in the concepts part of the website. (#11703),0
[hotfix][docs] Correct english typo in streamfile sinksThis closes #11678,2
[FLINK-16949][test] Enhance AbstractStreamOperatorTestHarness to use customized TtlTimeProviderThis closes #11624,1
[FLINK-16626][runtime] Prevent REST handler from being closed more than once,0
[FLINK-16803][hive] Need to make sure partition inherit table spec when writingThis closes #11524,1
"[FLINK-15639][k8s] Support to set tolerations for jobmanager and taskmanger podTaints and tolerations work together to ensure that pods are not scheduled onto inappropriate nodes. One or more taints are applied to a node; this marks that the node should not accept any pods that do not tolerate the taints. Tolerations are applied to pods, and allow (but do not require) the pods to schedule onto nodes with matching taints.This closes #11606 .",1
[FLINK-17050][runtime] Replace usages of getResultPartition() with getResultPartitionOrThrow()Replace usages of method    SchedulingTopology#getResultPartition(IntermediateResultPartitionID)with    SchedulingTopology#getResultPartitionOrThrow(IntermediateResultPartitionID)in unit tests.,3
[FLINK-17050][runtime] Remove methods getVertex() and getResultPartition()Remove methods- SchedulingTopology#getVertex(ExecutionVertexID);- SchedulingTopology#getResultPartition(IntermediateResultPartitionID);,2
[FLINK-17050][runtime] Rename methods getVertexOrThrow() and getResultPartitionOrThrow()Rename methods- SchedulingTopology#getVertexOrThrow(ExecutionVertexID)- SchedulingTopology#getResultPartitionOrThrow(IntermediateResultPartitionID)to- SchedulingTopology#getVertex(ExecutionVertexID)- SchedulingTopology#getResultPartition(IntermediateResultPartitionID)respectively.This closes #11684.,2
[FLINK-17107][checkpointing] Make CheckpointCoordinatorConfiguration#isExactlyOnce() be consistent with StreamConfig#getCheckpointMode(),5
[hotfix] Extract common logic of getting CheckpointingMode as StreamingJobGraphGenerator#getCheckpointingMode,1
[FLINK-16303][rest] Enable retrieval of custom JobManager log filesThis closes #11542.,2
[FLINK-17098][table] CatalogManager#dropTemporaryTable and dropTemporaryView should use ObjectIdentifier as its argument,1
[FLINK-17067][table] CatalogManager#createTable and createTemporaryTable should provide consistent semantics,1
[FLINK-16951][parquet] Integrate parquet to file system connectorThis closes #11653,5
[FLINK-16771][table-planner-blink] NPE when filtering by decimal columnThis closes #11511,2
[FLINK-16961][es] Bump Netty to 4.1.44,2
[FLINK-16961][hbase] Bump Netty to 4.1.44,2
[FLINK-16961][cassandra] Bump Netty to 4.1.44,2
[FLINK-16961][python] Bump Netty to 4.1.44,2
[FLINK-16961][hive] Bump Netty to 4.1.44,2
"[FLINK-15936] Harden TaskExecutorTest#testSlotAcceptanceThe test called taskSlotTable.allocateSlot from the test main thread,concurrently with taskSlotTable.createSlotReport while trying to registerRM in the main TM thread. This silently failed the RM registration in TM.runAsync.As a result, RM.notifySlotAvailable was not called in TM.The commmit refactors the test to wait properly for RM registrationand allocate slots through gateway in TM thread.The commit also uses proper testing RM/JM instead of mocks.To verify, the test has been looped locally 30k times.This closes #11667.",3
[hotfix][coordination] Log if TaskExecutor#establishResourceManagerConnection fails,0
[hotifx][tests] Remove dead code in TaskExecutorTest,3
[FLINK-17114][python] Set the default value of 'python.executable' to the path of the python interpreter which launches the job when the job is executed by LocalExecutor.This closes #11714.,1
"[FLINK-14504][rest] Rename AbstractTaskManagerHandlerThe name was misleading since the handler only interacts with the ResourceManager, and just happened to only be used by TaskExecutor-related handlers.",0
"[FLINK-14504][runtime] List incomplete data setsWe don't have a mechanism to ensure that either all partitions of a data set are registered or the remaining partitions are released at some point.In these cases the user has to step in, but without being able to list incomplete partitions there's nothing that can be done.This commit relaxes the filtering, and introduces an additional optional count for the number of currently registered partitions.This count is only determined when the listing is requested for performance and complexity reasons.",1
[FLINK-14504][runtime] Introduce ClusterPartitionManager interface,2
[FLINK-14504][rest] Add Cluster DataSet REST API,5
[FLINK-17124][python] Fix PyFlink Job runs into infinite loop if Python UDF imports job code which is not enclosed in a `if name == 'main'` statementThis closes #11719.,2
[FLINK-13691][table] Remove deprecated query configThis closes #11481,5
correct logs information in KafkaPartitionDiscoverer,5
[FLINK-16995][table-common] Add new data structure interfaces in table-commonThis closes #11651,5
[FLINK-16960][runtime] Rename LogicalPipelinedRegion to DefaultLogicalPipelinedRegion,2
[FLINK-16960][runtime] Add PipelinedRegion interfaceThis closes #11647.,1
[FLINK-16748][python][doc] Add Python UDTF doc (#11531),2
[hotfix][doc] Typo fixups in the concepts/runtime part of the website. (#11740),1
[FLINK-17136][doc] rename toplevel DataSet/DataStream section titles,5
"[FLINK-17080][java,table] Fix possible NPE in Utils#CollectHelper This closes #11688",0
[FLINK-17103][table-planner-blink] Supports dynamic options for Blink planner* Implement dynamic options in Blink planner* Implement CSV connector* Add plan test OptionsHintTest* Add a Csv ITCase in CatalogTableITCaseThis closes #11711,2
[FLINK-13880][core] Correct the behavior of JobExecutionResult#getAccumulatorResult to match JavadocThis closes #11698,2
[hotfix][runtime] Remove unused method ExecutionJobVertex#generateDebugString(),0
[FLINK-17093][python][table-planner][table-planner-blink] Fix Python UDF to make it work with inputs from composite field (#11717),1
[FLINK-16222][metrics][docs] Document plugins support,1
[hotfix][rocksdb] Fix exception message,0
[FLINK-16576][state backends] Fix the problem of wrong mapping between stateId and metaInfo in HeapRestoreOperation,5
[FLINK-16576][state backends] Do not distribute KeyGroupsStateHandle which contains empty KeyGroupRangeThis closes #11555.,1
[FLINK-16887][table-planner-blink] Refactor retraction rules to support inferring ChangelogModeThis closes #11674,4
[FLINK-16822][sql-client] `table.xx` property set from CLI should also be set into TableEnvironment's TableConfigThis closes #11544,5
[FLINK-15827][runtime][coordination] Deprecate unused taskmanager.registration.* optionsThis closes #11743.,1
[FLINK-17064][table-planner] Improve literals conversion in ExpressionConverterIt simplifies conversion of literals in ExpressionConverter. It also fixes certain mappings from Flink's type system to Calcite's which were losing precision.,5
[hotfix] Use UTC when converting to/from SqlTimestamp and TimestampStringThis closes #11694,1
[FLINK-17084][table] Implement input type inference and output type strategy for ARRAY/ROW/MAP built-in functions (#11701)The type strategies are implemented using the new type stack. It alsoremoves those three planner expressions from the Blink planner as theyare no longer needed. Equivalent expressions in flink planner are notyet removed as they are needed for converting to RexNodes.It disables the FunctionDefinitionConvertRule for built-in functions asthe BridgingSqlFunction call generator supports only user defined functions so far.,1
[FLINK-16813][jdbc] JDBCInputFormat doesn't correctly map Short,5
"[FLINK-16820][jdbc] support reading timestamp, data, and time in JDBCTableSourcecloses #11663",5
[FLINK-16815][jdbc] add e2e tests for reading primitive data types from postgres with JDBCTableSource and PostgresCatalog,2
[FLINK-16486][python][docs] Add documentation for vectorized Python UDF (#11724),2
[FLINK-16598][k8s] Respect the rest port exposed by Service in Fabric8FlinkKubeClient#getRestEndpointThis closes #11715 .,2
[FLINK-16983][python] Support RowType in vectorized Python UDF (#11656),1
[FLINK-17152][table] Fix FunctionDefinitionUtil generate wrong resultType and acc type for AggregateFunctionDefinitionThis closes #11748,5
[FLINK-15486][tests] Remove timeout of LocalInputChannelTest#testConcurrentConsumeMultiplePartitions to avoid potential timeout problem on slow machine,0
[FLINK-16750][e2e] Always copy and show the logs when yarn e2e tests failedThis closes #11746.,0
[hotfix][sql] CliTablaeuResultViewTest runnable on Windows,1
[hotfix][sql] Add name for exector,1
[FLINK-17082][sql] Remove mocking in SQL client,4
[FLINK-17131][build] Downgrade javadoc-plugin,2
[FLINK-16346][tests] Use fixed JobIDs,0
[FLINK-16968][stats][metrics] Add StatsDReporterFactory,1
[hotfix][doc] Fix typo of TaskManagerSlot#jobId javadocThis closes #11773 .,2
[FLINK-17118][python] Add Cython support for primitive data types (#11718),5
[hotfix][javadocs] Fix typo,2
"[FLINK-15790][k8s] Make some interfaces in FlinkKubeClient asynchronous which potentially blocks the execution of RpcEndpoint's main threadThe interfaces in FlinkKubeClient will be called both in Client and ResourceManager. To avoid potentially blocking the execution of RpcEndpoint's main thread, these interfaces #createTaskManagerPod, #stopPod should be implemented asynchronously.This closes #11427.",1
[FLINK-17172][tests] Enable DEBUG level logging in Jepsen testsThis closes #11761.,3
[FLINK-17119][python] Add Cython support for composite types (#11767),1
[FLINK-17128][table] Add isBounded to TableSinkFactory#ContextThis closes #11726,1
[hotfix][runtime] Remove declaring of ResourceManagerException from ResourceActions#allocateResource.This exception is never thrown from production codes.,4
[hotfix][runtime] Code clean-ups in ActiveResourceManagerFactory.,4
[FLINK-16437][runtime] Introduce WorkerResourceSpec for describing resource specification of a requested worker between ResourceManager and SlotManager.,1
[FLINK-16437][runtime] Pass SlotManagerConfiguration into SlotManagerImpl.,5
[FLINK-16437][runtime] Create SlotManagerImpl with default WorkerResourceSpec.,1
[FLINK-16437][runtime] Create SlotManagerImpl with default numSlotsPerWorker.,1
[FLINK-16437][runtime] Compute pending slot profiles inside SlotManager when allocating resource.This means also check unfulfillable slot profiles inside SlotManager.,2
"[FLINK-16437][runtime] ResourceManager retrieve a collection of pending workers from SlotManager, instead of number of pending slots.",1
"[FLINK-16437][runtime] Remove numSlotsPerTaskManager from ActiveResourceManager and ContaineredTaskManagerParameters.Since now we compute pending slot profiles inside SlotManager, ResourceManagers no longer need to be aware of number of slots per worker.",1
[FLINK-16437][runtime] SlotManager allocate resource from ResourceManager with WorkerRequest instead of ResourceProfile.This marks ResourceManager is no longer aware of slot ResourceProfiles.This closes #11320.,2
[hotfix] Fix PerJobMiniClusterFactory does not properly calculate numSlotsPerTaskManager.,5
[FLINK-16581][table-planner-blink] Support state ttl for Mini-Batch deduplication using StateTtlConfigThis closes #11482,5
"Revert ""[FLINK-17119][python] Add Cython support for composite types (#11767)""This reverts commit 5eaf2b50a63b71be1606bf48713e72d64dfb84a3.",4
[FLINK-17132][metrics] Bump Prometheus to 0.8.1,2
"[hotfix][task] Avoid unnecessary actionExecutor for notifyCheckpointComplete.The method is already executed as a mail, which uses actionExecutor internally.",1
[hotfix][network] Remove unused InterruptedExceptions.,1
[hotfix][network] Move uncritical code out of lock in RemoteInputChannel#onBuffer.,4
[hotfix][task] Rename CheckpointedInputGate#cleanup to close and implement Closeable.,4
[hotfix][task] Narrowing checkpointing related exceptions to IOException.The narrower scope makes handling easier and avoids broading the scope of many existing functions in the course of unaligned checkpoint.,1
[hotfix][task] Generalizing MailboxExecutor#execute to ThrowingRunnable.,1
[FLINK-16587][checkpointing] Make ChannelStateWriterImpl#getWriteResult idempotent.Letting ChannelStateWriter extend CheckpointListener to cleanup in-progress state.,4
[FLINK-16587][coordinator] Ensuring channel deployment descriptors are lists.Recovery of unaligned checkpoints relies on consistent indexes of channels. This commit reflects the requirement on deployment.,1
[FLINK-16587][checkpointing] Introducing IndexedInputGate for abstracting single channel InputGates with a specific index.This commit facilitates promoting the index of all non-union gates to first class citizens and allows them to be reliably referenced by their index.,1
[FLINK-16587][checkpointing] Switch to positional input channel and subpartitions.All gates and partitions get their index injected.Channels and partition writers get their InputChannelInfo and ResultSubpartitionInfo injected. The info can be used to identify channels across restarts and is positional.Channels and subpartitions can be retrieved by index from the gate and the partition.The index-based approach facilitates easier storing and recovery of inflight data for unaligned checkpoints.,5
[FLINK-16587][checkpointing] Adding unaligned checkpoint config flag.Also passing the whole StreamConfig to InputProcessorUtil as there will be several additional unaligned configuration options in the future.,5
[FLINK-16587][checkpointing] Introduce BufferReceivedListener for notifying of received buffers and barriers from network channel.,1
[FLINK-16587][checkpointing] Implement CheckpointBarrierUnaligner to trigger checkpoint when receiving the first barrier.CheckpointBarrierUnaligner will receive more sophisticated strategies to trigger a checkpoint with later tasks of FLINK-14551.,2
[FLINK-16587][task] Moving event creation from OperatorChain to SubtaskCheckpointCoordinatorImpl.,1
"[FLINK-16587][checkpointing] Implement checkpoint barrier overtake in output partitions.Extended BufferAvailabilityListener with notifyPriorityEvent, which allows LocalInputChannels to completely bypass buffer queue and send barrier directly to Unaligner.",4
[FLINK-16587][checkpointing] Provide the method for getting unconsumed buffer from RecordDeserializer.,1
[FLINK-16587][checkpointing] Provide the method of getting in-flight buffers from input gate.,1
[FLINK-16587][checkpointing] Spill the in-flight input and output buffers during checkpointing.,2
"[FLINK-16587][checkpointing] Fix abortion of ChannelStateWriter and add test/IT cases for unaligned checkpoint.In ChannelStateCheckpointWriter#fail, DataOutputStream flushes on close, which is not possible when checkpointStream is closed before. That can happen either directly in fail or through a previous finishWriteAndResult.DataOutputStream#close does not need to be closed in both cases as long as checkpointStream is closed.checkpointStream#close is idempotent.",5
"Revert ""[FLINK-16945][checkpointing] Execute CheckpointFailureManager.FailJobCallback directly in main thread executor""This reverts commit 288750a76f64269de7f5eb2aee72feb92b048036.",4
"Revert ""[hotfix] Make the checkpoint resuming e2e case pass by increasing the retained checkpoints number""This reverts commit dd9f9bf040cb82ed7e18c9fdf7c7e1ca6f43f896.",4
"Revert ""[FLINK-14971][checkpointing] Remove lock of PendingCheckpoint and introduce IO lock for PendingCheckpoint""This reverts commit 6936713b3b9b0caea8ce080d9b9d3de16a4db46f.",5
"Revert ""[FLINK-14971][checkpointing] Remove coordinator-wide lock of CheckpointCoordinator""This reverts commit d8267be27ff397aaa3f0b7c2860f4bf8885fcd4b.",4
"Revert ""[FLINK-14971][checkpointing] Make CompletedCheckpointStore thread-safe to avoid synchronization outside""This reverts commit f248e6df7e79245091b569fa3afd107b78058fd9.",4
"Revert ""[hotfix] Harden ResumeCheckpointManuallyITCase""This reverts commit 300263e17a483a46c1bf4d2c0baee4a8ad31c26d.",4
"Revert ""[FLINK-14971][checkpointing] Introduce main thread executor in CheckpointCoordinator to execute all non-IO operations instead of the timer thread""This reverts commit 1a1386266ee94bf318f8105b96d2c84d74016f62.",4
"Revert ""[FLINK-14971][checkpointing] Handle ack/declined message of checkpoint""This reverts commit 874310f68acd418a0a1390f9bd667e506e0efb90.",4
[FLINK-16308] [docs] Fix Maven download links for SQL connectors.,2
[minor] Add ES7 to list of sql connector downloads,1
[FLINK-17052] Extract the Plan Generation logic from ExecutionEnvironmentThis closes #11671.,2
[FLINK-16967][metrics][slf4j] Add Slf4jReporterFactory,1
[FLINK-16962][metrics][datadog] Add DatadogHttpReporterFactory,5
"Revert ""[FLINK-17118][python] Add Cython support for primitive data types (#11718)""This reverts commit 1a5b35b1e1ea79a233cacc88e4574f446aba52ae.",4
[FLINK-17211] Enable JUnit 4 tests in flink-sql-parser moduleAdded junit 4 vintage engine to run junit 4 tests in junit 5environment.,3
[FLINK-16921][e2e] Use kubectl instead of curl to wait for rest endpoint upWe find that the curl may block in azure pipeline environment for K8s nodeport address. So this PR use the kubectl wait and kubectl logs to wait for the rest endpoint up.,2
"[FLINK-16921][e2e] Set service exposed type to NodePort explicitlyIn FLINK-16598, we change the behavior about how to get the rest port, it will make the e2e test failed when setting service exposed type to LoadBalancer.",5
[FLINK-16921][e2e] Enable K8s tests,3
[FLINK-17023][scripts] Improve handling of unexpected input,1
[FLINK-17132][metrics] Update licensing,5
[hotfix][runtime] Fix import order in PipelinedRegionComputeUtil,2
[FLINK-17181][runtime] Drop generic Types in Topology InterfaceCo-authored-by: Gary Yao <gary@apache.org>,2
[FLINK-16683][scripts] Remove Windows scripts,4
[FLINK-16895][docs] Remove build_docs.bat,2
[FLINK-17142][orc] Bump ORC dependency version to 1.5.6This closes #11759,2
[FLINK-16411][AZP] Use Maven cache in the same data centerThis closes #11800,5
[FLINK-8864][sql-client] Add cli command history in sql client and make it avaible after restartThis closes #11765,1
[FLINK-16823][table-planner-blink] Fix TIMESTAMPDIFF/TIMESTAMPADD yield incorrect resultsThis closes #11573,1
[FLINK-15400][elasticsearch] Support dynamic index for Elasticsearch sink connectorThis closes #11466,1
[hotfix] Force not null types for literals with non null value,1
[hotfix][table-api] Make ApiExpressionUtils#objectToExpressionConversionconvert byte[] to a BINARY literal,1
"[FLINK-16379][table] Introduce fromValues in TableEnvironment.The clause works briefly as follows:1. Convert the input to expressions (objects and expressions)2. Resolve the types of the expressions3. Either use a user provided type for the resulting table or run a type generalization over all rows4. Adapt the input rows to the type of the resulting table. It includes:     4a. checking if a literal class is a supported conversion class of the requested type     4b. applying a cast to the expected type   This is done recursively for ROW/MAP/ARRAY types.5. All rows that are constructed purely of literals are used in a values logical node, any calls are applied in a projection over a single row dummy values node. All those rows are unioned in the end.This closes #11290",2
[FLINK-16600][k8s] Respect the rest.bind-port config option for the Kubernetes setupThis closes #11705 .,1
[FLINK-17223][AZP] Clean up disk space on Azure-hosted builders,4
[FLINK-17068][python][tests] Ensure the permission of scripts set correctly before executing the Python tests (#11805),3
[FLINK-16366] [table] Introduce executeSql method in TableEnvironmentSupported statement:CREATE TABLE / DROP TABLE / ALTER TABLE /CREATE DATABASE / DROP DATABASE / ALTER DATABASE /CREATE FUNCTION / DROP FUNCTION / ALTER FUNCTION /CREATE CATALOG / USE CATALOG / USE [CATALOG.]DATABASE /SHOW CATALOGS / SHOW DATABASES / SHOW TABLES / SHOW FUNCTIONSThis closes #11700,1
[FLINK-17118][AZP] Use rmetzger/flink-ci:ubuntu-amd64-bcef226 image which contains gcc used for PyFlink cython tests,3
[FLINK-17118][python] Add Cython support for primitive data typesThis closes #11809.,5
[FLINK-17119][python] Add Cython support for composite types (#11812),1
[hotfix][docs] Fix overlapping text,0
"Revert ""[hotfix][docs] Fix overlapping text""This reverts commit b8b0331247fe6d023d4da44868cb1f3526b62c62.The commit has removed a license header from the file, causing the apache rat check to fail.",0
[FLINK-15816][k8s] Limit the value of kubernetes.cluster-id to have no more than 45 charactersThis closes #11708.,2
"[FLINK-16992][table-common] Add all ability interfaces for table sourcs and sinksThis adds all ability interfaces that are either supported already or mentionedin FLIP-95. This commit makes sure that all interfaces follow a common naming schemelike ""SupportsXXX"", ""applyXXX()"" and good documentation with consistent terminology.This closes #11692.",2
[FLINK-17156][checkpointing][hotfix] simplify cancellation in CheckpointBarrierUnaligner,1
[FLINK-17156][checkpointing] ignore cancelled checkpoints by CheckpointBarrierUnaligner,1
[FLINK-17257][yarn][test] Fix AbstractYarnClusterTest not compiling with hadoop 2.10.,3
[hotfix] Fix the code style in BashJavaUtilsITCase,0
[FLINK-16874] Respect the dynamic options when calculating memory options in taskmanager.shThis closes #11577.,2
[hotfix] Add RpcUtils#terminateRpcEndpoints,1
[hotfix] Add RpcUtils#INF_DURATION,5
[hotfix] Add RpcRuntimeException,1
[hotfix] Add AkkRpcRuntimeException,1
"[hotfix] Let AkkaUnknownMessageException extend AkkaRpcRuntimeExceptionAkkaUnknownMessageException represents a programming error which is notrecoverable. Consequently, this exception becomes an unchecked exceptionwith this commit.",0
[FLINK-15347] Bump AkkRpcVersion to 2,2
[FLINK-15347][tests] Add ActorSystemResource,5
"[FLINK-15347] Add SupervisorActor which monitors the proper termination of AkkaRpcActorsIn order to properly complete the termination future of an RpcEndpoint, we need to monitorwhen the underlying AkkaRpcActor has been removed from the ActorSystem. If this is not done,then it can happen that another RpcEndpoint using the same name cannot be started becausethe old RpcEndpoint is still registered.The way we achieve this monitoring is to introduce a helper actor which is responsible forstarting the AkkaRpcActors for all RpcEndpoints. Since the SupervisorActor is the parentof all RpcEndpoints, it can tell when they are being removed from the ActorSystem throughthe SupervisorStrategy.A consequence of the new actor is that the akka urls change from akka://flink@actorsystem:port/user/xyzto akka://flink@actorsystem:port/user/rpc/xyz. The respective method AkkaRpcServiceUtils.getRpcUrlhas been updated to reflect this change. This hierarchy change also warrants the bump of theAkkaRpcService.VERSION.The failure behaviour of the underlying ActorSystem has been changed so that it terminatesall running actors if an exception is thrown from the SupervisorActor. The assumption is thatsuch an exception always indicates a programming error and is unrecoverable.The same applies to failure originating from an AkkaRpcActor (children of the SupervisorActor).If such an exception is thrown, then we assume that the system is in an illegal state and shut itdown. The way it works is by recording the failure cause for the respective AkkaRpcActor andthen terminating the ActorSystem.",5
[FLINK-15347] Introduce separate dispatcher for SupervisorActorThe separate dispatcher ensures that the SupervisorActor can always make progress.This again ensures that the other RpcEndpoints won't deadlock when starting a newRpcEndpoint. The reason for this is because a newly started RpcEndpoint needs toregister at the SupervisorActor.,1
[hotfix] Add FutureUtils.forwardAsyncFutureUtils.forwardAsync forwards the source value to the target future usingthe provided executor.,1
"[FLINK-15347] Add dedicated termination future executor to SupervisorActorThe SupervisorActor must never block its own main thread. Due to this constraint,we must not complete the external termination futures from the main thread, becauseone does not know what the user does with this future. Hence, this commit introducesa dedicated termination future executor which is responsible for completing thetermination futures.This closes #11683.",1
[FLINK-17263][table-planner-blink] Replace RepeatFamilyOperandTypeChecker with CompositeOperandTypeChecker in plannerThis closes #11819,2
"[FLINK-17135][python][tests] Fix the test testPandasFunctionMixedWithGeneralPythonFunction to make it more stableThere are two caches in RelDataTypeFactoryImpl: KEY2TYPE_CACHE andDATATYPE_CACHE. KEY2TYPE_CACHE caches the mapping of Key(consists offield names and field types, etc) to RelDataType and can be used for thecanonization of row types. DATATYPE_CACHE caches the RelDataType instances.PythonCalcSplitRule will split a Calc RelNode which contains bothnon-vectorized Python UDF and vectorized Python UDF into two Calc RelNodes.For the test case testPandasFunctionMixedWithGeneralPythonFunction,the output type of the bottom Calc consists of two fields (f0: INTEGER, f1: INTEGER),let's call it row_type_0. This row type is already available in the cache(generated by other test cases, held in variable KEY2TYPE_CACHE) and so it will hit thecache when constructing this row type for the bottle Calc. However, during debugging, Ifound that the INTEGER type referenced by row_type_0 is already cleanedup from the cache DATATYPE_CACHE. Then when constructing the RexProgramfor the top Calc, it creates another INTEGER type and failure happens.To work around this problem, we adjust the test case a bit to make theoutput row type of the bottom Calc consisting of three fields instead oftwo fields to make the cache hit fail.",0
[FLINK-17120][python] Add Cython support for operations (#11784),1
[FLINK-17013][python] Support Python UDTF in old planner under batch mode (#11668),1
[FLINK-17014][runtime] TestingSchedulingTopology implements pipelined region getter interfaces,1
[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy,2
[FLINK-17264][scripts] Fix broken taskmanager.sh by using -ne to compare num_linesThis closes #11820.,1
[FLINK-17266] Make WorkerResourceSpec serializableThe MesosWorkerStore requires that the WorkerResourceSpec is serializablebecause it stores it as part of MesosWorkerStore.Worker in serialized format.This closes #11821.,1
[FLINK-17197][runtime] switch ContinuousFileReaderOperator state to FAILED on error,0
[hotfix][runtime] move ContinuousFileReaderOperator unit test to theappropriate class and module,3
[hotfix][runtime] rename ContinuousFileReaderOperator.TRANSITIONS to VALID_TRANSITIONS,2
"[FLINK-16572] [pubsub,e2e] Only acknowledge list of messages if the list is not empty + small style fixes (removal of uncommented code etc)]",4
"[FLINK-16656] Introduce the DispatcherBootstrapThis new interface generalizes how a Dispatcher can be initialized. Beforethis, a Dispatcher would always be initialized with a list of recovered jobs(that could be empty). With this generalization we can add other ways ofinitializing the jobs/state of a Dispatcher, which we will use in the follow-upcommits that add an application-mode dispatcher bootstrap.",1
[FLINK-16660] Add stop() to DispatcherBootstrap,1
"[FLINK-16660] Separate the code-paths of web submission and application modeAlthough in both cases, the main() method is executed on the cluster,in the case of Web submission, the cluster is shared across differentjobs that compete for the same resources on the dispatcher. This leadsto some restrictions when it comes to job execution, for example, inthe case of web submission, a job submission cannot be blocking (i.e.wait for the job's completion). This means that a separate JobClienthas to be returned, that limits the operations a user can make. Toachieve this in a clear way, this commit makes sure that the codepathsof the two job execution modes are distinct enough to be able toaccommodate their special needs.",5
"[FLINK-16660] Introduce the ApplicationDispatcherBootstrapThis adds the functionality needed for dispatcher to be ableto execute applications in ""Application Mode"", as describedin FLIP-85. The idea is that the bootstrap is responsible for:1) launching the recovered job graphs --when recovering from a failure2) launch the application's main()3) submit the non-executing job graphs of the application for execution   or re-attach a job client to the already running recovered ones4) terminate the cluster when the application is terminated   either normally or abruptly.",1
[FLINK-16658] Add ApplicationDispatcherGatewayServiceFactory for Application Mode execution,1
"[FLINK-16658] Add PackagedProgramRetrieverThis is the equivalent of the JobGraphRetriever but forreconstructing a PackagedProgram on the cluster. This isused for executing user code in Application Mode, wherethe main() is executed on the cluster.",1
[FLINK-16658] Wire the ApplicationDispatcherBootstrap to the StandaloneJobClusterEntryPoint,1
[minor] Remove unused ClassPathJobGraphRetriever,1
"[FLINK-16658] Make StandaloneJobClusterEntryPoint extend directly ClusterEntrypointThe StandaloneJobClusterEntryPoint is actually aStandaloneApplicationClusterEntryPoint now. To illustrate that, we breakthe previous hierarchy which would be misleading, but we keep the samename for backwards compatibility reasons.",4
"[FLINK-16660] Make rpc timeout and retry period configurable for application modeIn Application Mode, the user code is executed on the cluster but goesthrough rpc (to the dispatcher gateway). Currently, the closest availableoption is the WebOptions.TIMEOUT, but this does not cover both the timeoutand the retry period, and it is made for another reason. To this end, weadd two options specifically for this.",1
[FLINK-16658] Refactor ApplicationDispatcherBootstrap and testThis simplifies the internal structure of ApplicationDispatcherBootstrapand refactors the test to not assume as much about the internals ofApplicationDispatcherBootstrap.This closes #11696.,3
[FLINK-17249] Bump universal Kafka connector to Kafka 2.2.2Update the Kafka client dependency from 2.2.0 to 2.2.2 to integrate a number of fixes. The upgrade to 2.3.0 and onwards is more complicated due to Flink's usage of Kafka classes that are not public API for transactions integration (see FLINK-15362 for more details).,2
[hotfix][table sql planner/table sql legacy planner]fix icu license in NOTICE file,2
[hotfix][docs] fix broken SVG figure and include license this time,0
"[FLINK-16943][python] Support to set the configuration option ""pipeline.jars"" in PyFlink (#11768)",2
[FLINK-17206][table] refactor function catalog to support delayed UDF initialization.This closes #11785,5
"[hotfix][table-sql-parser] Don't ExtendedSqlNode when not needed, remove superfluous null checks.",4
[FLINK-17003][table-sql-parser] Support parsing LIKE clause in a CREATETABLE statement.This PR implements parsing and validation of LIKE clause in a CREATE TABLE statement. It verifies valid combinations of merging strategies and table descriptor features.This closes #11833,1
[hotfix][AZP] Re-evalute scheduled buildsThis is basically an empty commit. According to the scheduled builds documentationof AZP (https://docs.microsoft.com/en-us/azure/devops/pipelines/process/scheduled-triggers?view=azure-devops&tabs=yaml)we need to push a change to the pipeline definition to schedule the builds.,5
[FLINK-16412][hive] Disallow embedded metastore in HiveCatalogThis closes #11823,2
"[FLINK-15669] [sql-client] Fix SQL client can't cancel flink jobBefore, we were storing the ""result"" under a unique ID. When cancelling,LocalExecutor.cancelQueryInternal() is using that ID to try and cancelthe running Flink job. This failed, of course. Now we store the resultunder the JobID (which was also the behaviour before Flink 1.10) and cantherefore cancel the job.",2
[FLINK-17106][sql-parser] Support to parse TEMPORARY and IF NOT EXISTS in view definition,5
[FLINK-17106][table-planner] Support create and drop view in both plannersThis closes #11727,4
[FLINK-17126][java] Introduce CollectionPipelineExecutor for CollectionEnvironmentThis closes #11794,2
[FLINK-17126][java] set `execution.target` and `execution.attached` for TestEnvironmentThis closes #11794,3
[FLINK-17126][table-planner] Correct the execution behavior of BatchTableEnvironmentThis closes #11794,2
[hotfix][typo]Fix typo in RelationalQueryCompilerTest and TpcdsTestProgramThis closes #11841,3
[FLINK-17121][build system][python] Adds Pipeline of Building Wheel Packages in Azure CIThis closes #11741,1
[hotfix][docs] copy concepts/*stream-processing over to zh docs,2
[hotfix][docs] change KeySelector in program dataflow figure from String to lambda,5
[FLINK-17236][docs] Add Tutorials section overviewThis closes #11826.,1
[FLINK-17237][docs] Add Intro to DataStream API tutorialThis closes #11834.,5
[FLINK-17238][docs] Data Pipelines and ETL tutorialThis closes #11842.,5
[FLINK-17239][docs] Streaming Analytics tutorialThis closes #11843.,2
[FLINK-17240][docs] Add tutorial on Event-driven AppsThis closes #11845.,1
[FLINK-17241][docs] Add Fault Tolerance tutorialThis closes #11846.,1
"[FLINK-16662] Let PackagedProgramUtils create JobGraph under the user classloaderCurrently, in web submission JobGraph creation happens using the system classloader.This can lead to failures when, for example, the JobGraph creation uses code generationand needs the user code. This PR fixes it by doing the Jobgraph generation under theuser classloader.",1
[minor] Simplify PlanExecutor.execute() signature,5
[FLINK-16766][python] Support creating StreamTableEnvironment without passing StreamExecutionEnvironment (#11769),4
[FLINK-17323][task] Return NO_MORE_DATA from ChannelStateReader for unknown channelsThis closes #11861.,5
[FLINK-17138][sql-client] Close catalogs when close the sessionThis closes #11756,2
[FLINK-17209][table] Allow users to specify dialect in sql-client yamlThis close #11788,1
[FLINK-16779][table] Fix RAW type creation during type inference,5
[hotfix][sql-parser] Remove unused class SqlTimeUnit,1
[hotfix][table] Print more details during sink type mismatches,0
[FLINK-16779][table] Add RAW type support in DDL and functionsThis fully introduces the RAW type in DDL and functions. It allowsto support opaque data types in parser and planner.This closes #11568.,5
"Revert ""[FLINK-14499][metric] MetricRegistry#getMetricQueryServiceGatewayRpcAddress is Nonnull""This reverts commit 0cf9c2846ad1b293b91059d172dd68dd0ffbf803.",4
[FLINK-17226][metrics][prometheus] Remove relocations,4
[FLINK-17227][metrics][datadog] Remove relocations,4
[FLINK-16669][python] Introduce PythonFunctionFactory to provide a way to get the meta information of a Python UDF used in JavaThis closes #11749.,1
[FLINK-16669][python][table] Support parse and register Python UDF via sql ddl,1
"[FLINK-17338] Increase timeouts on LocalExecutorITCaseThese tests are very heavy because they're repeatedly compiling SQLqueries. This test takes unacceptably long, as a mitigation thisincreases the timeouts to try and make it more stable on CI.",1
[FLINK-16485][python] Support vectorized Python UDF in batch mode of old planner (#11859),1
[FLINK-17352][docs] Fix doc links using site.baseurl w/ link tagThis closes #11885,2
[hotfix] fix broken links in documentation,2
[hotfix] Add TimeUtils.toDuration,1
[hotfix] Simplify AkkaRpcService.connectInternal by relying on Akka APIs,0
[hotfix] Remove unused jobManagerAddress from StandaloneHAServices,1
[hotfix] Remove unused RESOURCE_MANAGER_RPC_ENDPOINT_NAME from StandaloneHaServices,1
[hotfix] Fix checkstyle violations in StandaloneHaServices,0
[FLINK-17072] Add test case for random actor resolution,3
[FLINK-17072] Let ResourceManager use random endpoint idThis commit ensures that every ResourceManager started by the same JVM processwill have a different endpoint id. This ensures that no new RM will receivemessages sent to an old RM.,1
"[FLINK-17072] Let Dispatcher use random endpoint idThis commit ensures that every Dispatcher, running in the same JVM,is started with a different endpoint id. This ensures that no newDispatcher instance will receive messages sent to an old instance.This closes #11693.",1
[FLINK-16473][doc][jdbc] add documentation for JDBCCatalog and PostgresCatalogcloses #11804,2
[FLINK-17188][python] Use pip instead of conda to install flake8 and sphinx (#11836),1
[FLINK-15971][python] Adjust the default value of bundle size and bundle time (#11881),2
[FLINK-16802][hive] Set schema info in JobConf for Hive readersThis closes #11735,5
[FLINK-14543][table] Support partition for temporary table,1
[FLINK-15901][hive] Support partitioned generic table in HiveCatalog,2
[FLINK-17020][runtime] Introduce GlobalDataExchangeMode for JobGraph generation,5
[hotfix][docs] link tags in zh docs require .zh.md links,2
[FLINK-17169][core] Add shortString() method to RowKind to get short string representationThis closes #11797,1
[FLINK-17169][table-planner-blink] Rename StreamRecordUtils#record() to insertRecord()This also Renames StreamRecordUtils#retractRecord() to updateBeforeRecord().This closes #11797,5
[FLINK-17169][table-blink] Fix allowLateness shouldn't affect producing updates of emit strategyThis closes #11797,5
[FLINK-17169][table-blink] Refactor BaseRow to use RowKind instead of byte headerThis closes #11797,1
[FLINK-16667][python][client] Support the Python dependency configuration options in CliFrontend (#11702),5
[FLINK-17344][test] Fix unstability on IdleTime metric test.Previously issue was that a thread could finish before the main thread reached .wait() call,5
[hotfix] Remove unused docs.rest.NoOpTransientBlobService,2
[hotfix] Make NoOpTransientBlobService a public testing class,3
[FLINK-17308] Pass ScheduledExecutorService to WebMonitorEndpoint,4
[FLINK-17308] Pass in ExecutionGraphCache to WebMonitorEndpoint,4
"[FLINK-17308] Extract ExecutionGraphCache interface and rename impl into DefaultExecutionGraphCacheThis commit extracts the ExecutionGraphCache interface from the implementation and renamesthe latter into DefaultExecutionGraphCache. Moreover, it introduces the NoOpExecutionGraphCacheimplementation which is used for the DocumentingDispatcherRestEndpoint.",2
[FLINK-17308] Add regular cleanup task for ExecutionGraphCacheThe WebMonitorEndpoint now schedules are regular cleanup task whichruns every 2 * WebOptions.REFRESH_INTERVAL and tries to clean upexpired ExecutionGraphCache entries. This ensures that we will removeunused entries.This closes #11879.,4
[hotfix][runtime] Throw exception from TestingSchedulingPipelinedRegion#getVertex() for unknown vertices,3
[FLINK-17180][runtime] Implement SchedulingPipelinedRegion interfaceImplement interfaces  - Toplogy#getAllPipelinedRegions()  - Topology#getPipelinedRegionOfVertex(ExecutionVertexID)in DefaultExecutionTopology to enable retrieval of pipelined regions.,0
"[FLINK-17180][runtime] Use SchedulingPipelinedRegion in RegionPartitionReleaseStrategyAvoid re-computing pipelined regions in theRegionPartitionReleaseStrategy using the PipelinedRegionComputeUtil.Instead, rely on the pipelined regions provided by the Topology.",2
"[FLINK-17180][runtime] Use SchedulingPipelinedRegion in RestartPipelinedRegionFailoverStrategyAvoid re-computing pipelined regions in theRestartPipelinedRegionFailoverStrategy using thePipelinedRegionComputeUtil. Instead, rely on the pipelined regionsprovided by the Topology.This closes #11857.",2
[hotfix][filesystems] Remove unused StopWatch,1
[FLINK-17345][python][table] Support register and get Python UDF in Catalog (#11884),2
[FLINK-17021][table-planner-blink] Blink batch planner set GlobalDataExchangeMode,5
[FLINK-13639] Refactor the IntermediateResultPartitionID to consist of IntermediateDataSetID and partitionIndex,5
[FLINK-17175][core] StringUtils.arrayToString() should consider Object[] lastly,2
[FLINK-16812][jdbc] support array types in PostgresRowConvertercloses #11766,1
[FLINK-17333][doc] add doc for 'create catalog' ddlcloses #11871,2
[FLINK-16935][table-planner-blink] Enable or delete most of the ignored test cases in blink planner.This closes #11874,2
[hotfix][k8s] Remove duplicated taskManagerMemoryMB from KubernetesTaskManagerParameters.,3
[hotfix][k8s][test] Allowing custom slot manager in KubernetesResourceManagerTest.,3
[FLINK-16439][runtime] Introduce PendingWorkerCounter for counting pending workers per WorkerResourceSpec in ActiveResourceManager.,1
[FLINK-16439][k8s] KubernetesResourceManager starts workers with resources requested by SlotManager.This means KubernetesResourceManager no longer:- be aware of the default task executor resources- assumes all workers are identicalThis closes #11323.,1
[hotfix][runtime][k8s] Renaming methods for better code readability.,1
[hotfix][yarn][test] Avoid using Mockito for Container in YarnResourceManagerTest.,3
[hotfix][yarn][test] Avoid using Mockito for ContainerStatus in YarnResourceManagerTest.,3
[hotfix][yarn][test] Avoid using Mockito for AMRMClientAsync in YarnResourceManagerTest.,3
[hotfix][yarn][test] Avoid using Mockito for NMClientAsync in YarnResourceManagerTest.,3
[hotfix][yarn][test] Avoid using Mockito for TaskExecutorGateway in YarnResourceManagerTest.,3
[hotfix][yarn] Code clean-ups in RegisterApplicationMasterResponseReflectorTest.,3
[FLINK-16438][yarn] Introduce WorkerSpecContainerResourceAdapter for converting between Flink WorkerResourceSpec and Yarn container Resource in YarnResourceManager.,1
[FLINK-16438][yarn] YarnResourceManager starts workers with resources requested by SlotManager.This means YarnResourceManager no longer:- be aware of the default task executor resources- assumes all workers are identical,1
[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager.,1
[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse.This closes #11353.,1
[FLINK-14258][table][filesystem] Integrate file system connector to streaming sinkThis closes #11796,5
[FLINK-15006][table-planner] Add option to shuffle-by-partition when dynamic insertingThis closes #11853,1
"Partial Revert ""[FLINK-15669] [sql-client] Fix SQL client can't cancel flink job""This partially reverts commit 0650e4b6b6a9725c3a9589a110b202478a68f90c.Only the tests are reverted because the fix is still good.  The addedtests don't work because of a race condition: if the query finishesbefore the test cancels them the job status will be FINISHED, and notCANCELLED, as the text expects.",5
[FLINK-17339][table-api] Change default planner to blinkThis closes #11910,2
[FLINK-17339][table-planner] Update test cases due to default planner change.,4
[FLINK-17339][sql-client] Change default planner to blink.,2
[FLINK-17339][table-planner-blink] Simplify test cases due to default planner changing.,4
[FLINK-17339][examples] Update examples due to default planner changing.,4
[FLINK-17339][misc] Update tests due to default planner changing.,4
[FLINk-17268][connector/common] Fix the bug of missing records during SplitFetcher wakeup. Added unit test for SplitFetcher.,3
[hotfix] Remove the unused Boundedness parameter.,2
[FLINK-17268][connector/common] Fix the shutdown sequence in SplitFetcher to avoid blocking on shutdown.Fix flaky SourceReaderTestBase#testAvailableOnEmptyQueue().,3
"[hotfix][checkpointing] Make CheckpointBarrierUnaligner#processEndOfPartition always return falseFor unaligned checkpoint, no buffer is stored in BufferStorage so CheckpointBarrierUnaligner#processEndOfPartition should always return false.This closes #11351.",1
[hotfix] Add more information to CheckpointCoordinatorConfiguration#toStringThis closes #11351.,5
"[FLINK-16404][runtime] Avoid caching buffers for blocked input channels before barrier alignmentThis commit is the first part of implementation to solve the dead lock problem when reducing the exclusive buffer of receiver side to 0.Reducing the number of exclusive buffers of receiver side to 0 can bring several advantages (may at the cost of some performance regression). One is that memory can be saved from the reduced network buffer usage. Another important benefit is that the in-flight data can be reduced so we can speed up checkpoint in cases of back pressure. However, for the current implementation, reducing the exclusive buffer of receiver side can incur deadlock problem because all the floating buffers might be requested away by some blocked input channels and never recycled until barrier alignment.To solve the problem, this commit mainly makes the following changes:1. At sender side, after sending a checkpoint barrier when aligned exactly-once checkpoint mode is used, the outgoing channel will be blocked and no data will be sent out until the channel is unblocked.2. At receiver side, no buffer will be stored in BufferStorage any more and after a checkpoint is completed or canceled, the receiver side will resume data consumption and unblock the upstream by sending a special event to the sender side.Note that after this patch we still can't set the exclusive buffer of receiver side to 0 because there is still deadlock problem which will be totally solved in the following up patches.",0
[hotfix] Remove unused TOTAL_FLINK_MEMORY_MB field,2
[hotfix] Fix checkstyle violations in TaskExecutorPartitionLifecycleTest,3
[hotfix] Let TaskExecutorOperatorEventHandlingTest extend TestLogger,3
"[FLINK-17301][tests] Use proper AkkaRpcService for TaskManagerRunnerStartupTestThe problem is that we used Mockito to mock a RpcService. Due to this, some of thefields which are later used are being null.",1
"[FLINK-17301][tests] Set BIND_HOST to localhost in TaskManagerRunnerStartupTestWe need to configure BIND_HOST to localhost, otherwise Netty will use thewildcard addresss to bind to an IPv6 address whose port is not blocked.This closes #11864.",1
[hotfix][runtime] Code clean-ups in BashJavaUtils and its test cases.,3
[FLINK-16742][dist] config.sh does not assume BashJavaUtils always return two lines of results.,5
[FLINK-16742][runtime] Ignore unknown command line options for BashJavaUtils.,2
[FLINK-16742][dist] Extend and use BashJavaUtils for JM memory configuration in start-up scripts.This closes #11545.,5
[FLINK-16472][dist] Remove unused memory configuration logics from config.sh.,5
"[FLINK-16742][runtime] Refactor BashJavaUtils, move to separated package and extract configuration loading logics.",2
[FLINK-16745][clients] Parse JobManagerProcessSpec from Configuration into ClusterSpecification,5
[FLINK-16745][yarn] Start Yarn JM with FLIP-116 JVM memory args,2
[FLINK-16745][k8s] Start Kubernetes JM with FLIP-116 JVM memory argsThis closes #11675.,2
[FLINK-16745][coordination] Remove unused container cutoff,1
[hotfix] Remove 'TaskManager' from MemoryBackwardsCompatibilityUtils#getLegacyTaskManagerHeapMemoryIfExplicitlyConfigured,5
[hotfix] Fix ProcessMemoryUtilsTestBase#testExceptionShouldContainRequiredConfigOptions to run also for TM,1
[FLINK-16746] Add default 'jobmanager.memory.process.size: 1600m' to flink-conf.yamlThe resulting default JVM heap size for standalone deployment is 1024Mb as before FLIP-116.The requested container size (Yarn and Kubernetes) will increase by default from 1024Mb to 1600Mb.,1
[FLINK-16746][conf] Deprecate jobmanager.heap.size and expose new memory optionsDeprecate legacy heap options: jobmanager.heap.size (and update deprecation of jobmanager.heap.mb)to use jobmanager.memory.heap.size for standaloneand jobmanager.memory.process.size for containerized (Yarn/K8s) environments.Expose the new JM memory options of FLIP-116 in user docs.This closes #11787.,2
[hotfix][mesos] Deduplicate code in mesos JM start bash scripts,0
[FLINK-17048][mesos] Add memory related JVM args to Mesos JM startup scriptsThis closes #11863.,1
[FLINK-17359] Fix EntropyInjector to resolve entropy for ClassLoaderFixingFileSystem,5
[hotfix] Set kafka-schema-registry-client to 4.1.0 in NOTICE,1
[FLINK-10911][scala-shell] Enable flink-scala-shell with Scala 2.12,2
[FLINK-17313] Fix type validation error when sink table ddl contains columns with precision of decimal/varchar (#11848),0
"Revert ""[FLINK-10911][scala-shell] Enable flink-scala-shell with Scala 2.12""This reverts commit b7ce6119158346504e0ddd8d0f110859304eacbd.Our per-push CI does not cover Scala 2.12 so we didn't notice thatScalaShellITCase does not actually pass.",4
[FLINK-16965][metrics][graphite] Add GraphiteReporterFactory,1
[FLINK-17009] Move Java lambda and Scala Extension doc under streaming section,2
"[FLINK-17009] Copy What is a Collection and Anatomy from api_concepts.md to datastream_api.mdThis also modernizes the text in some places and replaces references to""Collection"" by ""DataStream"".",5
[FLINK-17009] Copy Lazy Evaluation from api_concepts.md to datastream_api.mdThis also slightly modifies/updates the text and removes the sectionheader.,4
[FLINK-17009] Add intro to KeyedDataStream in state.md,5
[FLINK-17009] Copy Specifying Keys from api_concepts.md to state.mdWe also add a small introduction.,1
[FLINK-17009] Copy Specifying Keys section to DataSet documentationWe want to remove api_concepts.md so we need to preserve this part inthe DataSet documentation.,2
[FLINK-17009] Remove tuple/expression keys from state.mdWe now only document `KeySelector` user functions and discourage peoplefrom using tuple/expression keys. Seehttps://issues.apache.org/jira/browse/FLINK-17074 for the reasoningbehind this.,2
[FLINK-17009] Copy UDF section from api_concepts.md to toplevel DataStream sectionThis page is a bit tricky because we have a toplevel Java/Scala switcherbecause the sections are actually different for the different APIs. Wetherefore also don't have a table of contents.,1
"[FLINK-17009] Move Supported Data Type from api_concepts.md to types_serialization.mdThis seems like a better fit, plus we want to get rid of theapi_concepts.md page.",1
[FLINK-17009] Copy Accumulators & Counters from api_concepts.md to user_defined_functions.md,1
[FLINK-17009] Remove api_concepts.md,4
[FLINK-17395][release][python] Add the sign and shasum logic for PyFlink wheel packagesThis closes #11915.,2
[FLINK-16971][python][sql-client] Support Python UDF in SQL Client.This closes #11901.,1
[hotfix][yarn] Code clean-ups in WorkerSpecContainerResourceAdapter.,1
[FLINK-17390][yarn] Fix Hadoop 2.10+ compatibility for WorkerSpecContainerResourceAdapter.This closes #11916.,1
[hotfix][runtime] Code clean-ups in ResourceManagerRuntimeServices.,1
[hotfix][runtime] Code deduplication in ResourceManagerFactory and its implementations.,0
[FLINK-16440][runtime][metrics] Introduce SlotManagerMetricGroup for registering related metrics inside SlotManager.,2
[FLINK-16440][core] Introduce multiplication for Resource.,2
[FLINK-16440][runtime] Introduce multiplication for ResourceProfile.,2
[FLINK-16440][runtime] Extend ResourceOverview and TaskManager(Details)Info for registered/free resources.This closes #11363.,5
[FLINK-17315][tests] Increased timeouts of UnalignedCheckpointITCase.,1
[hotfix][docs] Fix typo,2
[FLINK-17311][python] Change the version of cython to 0.29.16,4
[FLINK-17311][AZP] Add the logic of compressed in tgz before uploading artifactsThis closes #11860,2
[FLINK-17074] Deprecate java Datastream.keyBy methods that do not use KeySelector,1
[FLINK-17074] Deprecate java Datastream.partitionCustom methods that do not use KeySelector,1
[FLINK-17074] Deprecate scala Datastream.keyBy methods that do not use KeySelector,1
[FLINK-17074] Deprecate scala Datastream.partitionCustom methods that do not use KeySelector,1
[FLINK-17210][sql-parser][hive] Implement database DDLs for Hive dialectThis closes #11791,5
[hotfix] Remove site.baseurl from {% link %} tagslink tags already include site.baseurl.,2
[FLINK-17111][table] Support SHOW VIEWS in Flink SQLThis closes #11869,2
[FLINK-17432][docs-training] Rename Tutorials to Training for better SEO (#11931)[FLINK-17432][docs-training] Rename Tutorials to Training for better SEO,1
[FLINK-10114] Add ORC BulkWriter support for StreamingFileSinkThis closes #11474.,2
[FLINK-17334][hive] Flink does not support HIVE UDFs with primitive return typesThis closes #11876,1
"[FLINK-16645][network] Limit the maximum backlogs in subpartitionsIn the case of data skew, most of the buffers in #LocalBufferPool can be requested away by onecertain partition, which increases the in-flight data and slow down the buffer alignment.To solve this problem, we add a config to limit the maximum backlog per subpartition. In thisway, we can check subpartition's backlog and make the stream task unavailable if thelimit is exceeded.",1
"[FLINK-16996][table-common] Add necessary methods to internal data structures- Add to primitive array methods to ArrayData- Add get(ArrayData, int, LogicalType) utility to ArrayData- Add get(Object key) to GenericMapData- Add get(RowData, int, LogicalType) utility to RowData- Add toString() to RowDataThis closes #11925",5
[FLINK-16996][table-common] Add binary implementations of internal data structuresThis closes #11925,5
[FLINK-16996][table-runtime-blink] Implement all the data structures and serializers around RowDataThis closes #11925,5
[FLINK-16996][table-runtime-blink] Remove legacy data formats (BaseRow)This closes #11925,5
[FLINK-16996][table] Refactor planner and runtime to use new data structuresThis closes #11925,5
[FLINK-16996][python] Refactor pyflink to use new data structuresThis closes #11925,5
[FLINK-16996][parquet] Refactor parquet connector to use new data structuresThis closes #11925,5
[FLINK-16996][orc] Refactor ORC connector to use new data structuresThis closes #11925,5
[FLINK-16996][hive] Refactor Hive connector to use new data structuresThis closes #11925,5
[FLINK-17414][python][docs] Update the documentation about PyFlink build about Cython supportThis closes #11927.,1
[FLINK-17391][filesystem] sink.rolling-policy.time.interval default value should be biggerThis closes #11933,5
[FLINK-17455][table][filesystem] Move FileSystemFormatFactory to table commonThis closes #11941,5
[hotfix][runtime] Add sanity check to SlotManagerConfiguration,5
[FLINK-16605][core][config] Add slotmanager.max-number-of-slots config option,5
[FLINK-16605][runtime] Pass the slotmanager.max-number-of-slots to the SlotManagerImpl,4
[FLINK-16605][runtime] Make the SlotManager respect the max limitation for slotsThis closes #11615.,1
[hotfix][tests] Deduplicate code in SlotManagerImplTest,3
[hotfix][network] Rename ResultPartitionWriter#initializeState to #readRecoveredState,5
[hotfix][checkpointing] Use practical ChannelStateReader instead of NO_OP,1
"[FLINK-17440][network] Resolve potential buffer leak in output unspilling for unaligned checkpointsIf there are any exceptions thrown while interacting with ChannelStateReader#readOutputData, we should close therespective BufferConsumer to avoid leak.",5
"[FLINK-16423][e2e] Introduce timeouts for HA testsBefore this change, HA tests were waiting indefinetly for certain conditions to be met.This change introduces a timeout in the test scripts that kills the test and prints the Flink logs for debugging.This closes #11831",0
[FLINK-17374][travis] Remove travis-related filesThis closes #11921,2
[FLINK-17374][travis] Remove tools/travis directory,4
[FLINK-17374][travis] Further removals of travis-mentions,4
[FLINK-17254][python][docs] Improve the PyFlink documentation and examples to use SQL DDL for source/sink definition.This closes #11945.,5
[FLINK-17148][python] Support converting pandas DataFrame to Flink Table (#11832),2
[FLINK-15591][sql-parser] Support parsing TEMPORARY in table definition,5
[FLINK-15591][table] Support create/drop temporary table in both plannersThis closes #11917,4
[hotfix][docs] fix some typos in elasticsearch connector,2
[FLINK-14241][test] Add arm support for docker testDocker-compose doesn't have arm release bin file. Use pip3 installfor arm archThis closes #9782,1
[FLINK-17325][orc] Integrate orc to file system connectorThis closes #11942,5
[FLINK-13390][checkpointing] Clarify the exact meaning of state size when executing incremental checkpointThis closes #9289.,2
[FLINK-17461][formats][json] Support JSON serialization and deseriazation schema for RowData typeThis closes #11944,5
[hotfix][javadocs] Fix typo,2
"[FLINK-17370][table-common] Ensure deterministic type inference extractionThis ensures that function signatures are always extracted in a deterministicway. Esp. when it comes to implicit casting, a deterministic type inferenceis important to evaluate sequences like f(INT) || f(BIGINT).This closes #11902.",2
[hotfix][table-common] Reduce number of public extraction classes,4
[FLINK-17471][python] Move the LICENSE and NOTICE file to the package root of the PyFlink source distribution. (#11956),2
"[FLINK-17436][python] Fix the IllegalAccessError caused by package-private access control when submitting Python job via ""flink run"". (#11930)",1
[FLINK-17373][table] Support the NULL type for function callsEnables support for untyped NULL literals in function calls. The nulltype remains a helper type. We don't expose this type through the DDLor allow it as a function return type.More cases of NULL can be supported once we enable type coercion.This closes #11904.,0
[FLINK-14652][checkpointing] Refactor notifyCheckpointComplete to SubtaskCheckpointCoordinatorThis closes #11721.,4
[minor] Remove empty check in ConfigUtils#encodeCollectionToConfig(),5
"[FLINK-16661] Allow to set ApplicationStatus when shutting down clusterCurrently, when calling DispatcherGateway#shutdownCluster(), theApplicationStatus is set to SUCCESS automatically. This is not sufficientwhen using the method to shut down the cluster due to a problem. Inaddition, this results in frameworks like Yarn displaying the applicationstatus as succeeded in any case. This commit adds a method to thedispatcherGateway where the Application status can be specified anduses the method in the ApplicationDispatcherBootstrap#stop() which isused to shut down the cluster in application mode. We did not add thenew method to the RestfulGateway because it does not fit there.",1
"[FLINK-16661] Move the ClassPathPackagedProgramRetriever to flink-clientsThis is done because the ClassPathPackagedProgramRetriever is going to bealso used by other ApplicationEntrypoints in the future, including theYarnApplicationClusterEntryPoint.",1
"[FLINK-16661][yarn] Add the YarnApplicationClusterEntryPointThis is the ClusterEntryPoint to be used when running anapplication on Yarn, in ""Application Mode"" (see in FLIP-85).",1
[FLINK-16661] Consolidating code in ApplicationClusterEntrypoints,1
[FLINK-16661] Add support for Application Mode to YarnThis commit adds Yarn support for Application Mode (FLIP-85).Shipping of the user-jar is done the same way the'yarn.per-job-cluster.include-user-jar' flag does it.,1
[FLINK-16661][cli] Add the 'run-application' commandThis command in the CLI aims at supporting execution ofuser applications in Application Mode (see FLIP-85) fromthe CLI. It goes through the ExecutorCLI and NOT throughthe FlinkYarnSessionCLI and the user has to write sth like:./bin/flink run-application  -t yarn-application  -Djobmanager.memory.process.size=2048m  -Dtaskmanager.memory.process.size=4096m  ../examples/streaming/StateMachineExample.jar,1
[FLINK-16661][cli] Fix log configuration forwarding for yarn application mode,5
"[FLINK-16661] Move the static job id setting to ApplicationDispatcherBootstrapHA support and static Job Ids go hand-in-hand, as HA requires thatthe id of a job graph stays fixed across consecutive executions. Inaddition, no 2 jobs can have the same job id while executing on thesame cluster. This commit consolidates this logic (in the contextof Application Mode) in one place, the ApplicationDispatcherBootstrap.",2
[FLINK-16661] Add YARN application end-to-end testThis renames the existing test_yarn_kerberos_docker.sh totest_yarn_job_kerberos_docker.sh to reflect that it is a per-job testand adds a new test based on that for YARN application mode.,3
[minor] Move getUsrLibDir() to YarnEntrypointUtils,1
[FLINK-16661] Report the correct ApplicationStatus when job cancelled,2
[minor] Verify cluster shutdown status in ApplicationDispatcherBootstrapThis also verifies cluster shutdown status in other tests,3
[FLINK-17125][python] Add a Usage Notes Page to Answer Common Questions Encountered by PyFlink UsersThis closes #11878,1
[hotfix] Fix formatting on python common questions,0
"[FLINK-17315][tests] Temporary disable UnalignedCheckpointITCase.Apparently, it's causing deadlocks.",1
[hotfix] fix donwload link,2
[hotfix] Add comments to FileType enum values,2
[hotfix] Factor out putTransientBlobStream from requestFileuploadFilePath,2
[FLINK-14816] Add thread dump feature for taskmanager,1
"[FLINK-14816] Let TaskManagerThreadDumpHandler return JSON responseInstead of serving plain text, this commit changes the TaskManagerThreadDumpHandlerto return a JSON response. This allows to further extend this handler to notonly generate a thread dump of all threads but also for a sub set. Morever,it allows to return a more structured return value in the future.This closes #11887.",1
[FLINK-16901][legal] Correctly handle the THIRD_PARTY_NOTICES file in kinesis connector bundled dependencyThis closes #11964.,2
"[FLINK-16103][docs-zh] Translate ""Configuration"" page of ""Table API & SQL"" into ChineseThis closes #11909",1
[FLINK-17423][python] Support Java UDTF and UDAF in Blink planner under batch mode for PyFlinkThis closes #11932.,2
[FLINK-17473][tests] Remove unused test utilitiesRemove classes:  - ArchivedExecutionBuilder  - ArchivedExecutionJobVertexBuilder  - ArchivedExecutionVertexBuilderThis closes #11958.,4
"[FLINK-16034][table-api, docs] Updat documentation with new Java Expression DSL (#11533)",1
[FLINK-17483][legal] Update flink-sql-connector-elasticsearch7 NOTICE file to correctly reflect bundled dependencies,2
[FLINK-17499][state-processor-api] LazyTimerService used to register timers via State Processing API incorectly mixes event time timers with processing time timersThis closes #11980,1
[FLINK-17489][core] Support any kind of array in StringUtils.arrayAwareToString()This closes #11969.,1
[FLINK-17515][yarn] Move YARN staging functionality to a separate classThis closes #11991.,1
[FLINK-17496][kinesis] Upgrade amazon-kinesis-producer to 0.14.0,2
[FLINK-17420][table sql / api]Cannot alias Tuple and Row fields when converting DataStream to Table (#11951)11951),5
[FLINK-17244][docs] Update the Getting Started page (#11988)* Update docs/getting-started/index.md,2
[FLINK-15101][connector/common] Add the SourceCoordinator implementation,1
[hotfix][table-common] Improve terminology around catalog table options,2
[hotfix][table-common] Enable receiving isBounded in DynamicTableSink,0
[FLINK-16997][table-common] Add new factory interfaces and discovery utilitiesImplements the new factory interfaces mentioned in FLIP-95. Adds new factory utilitiesthat can be used for FLIP-122 and future factories.It adds TestDynamicTableFactory and TestFormatFactory for reference implementationsof new factories.This closes #11959.,1
[FLINK-17332][k8s] Fix restart policy not equals to Never for native task manager podsThis closes #11949 .,0
[FLINK-17462][format][csv] Support CSV serialization and deseriazation schema for RowData typeThis closes #11962,5
[hotfix][tests] Add TestingTaskManagerActions implementation,3
[FLINK-17514] Let TaskCancelerWatchDog call TaskManagerActions.notifyFatalError with non-null causeIn order to avoid NPE we have to call TaskManagerActions.notifyFatalError with non-null arguments. Thiscommit changes the behaviour accordingly.,4
"[FLINK-17514] Fail fatally if the TaskCancelerWatchDog encounters exception in run methodIf the TaskCancelerWatchDog encounters an exception in the run method, then we can no longerguarantee that it will do its job. Hence, it is best to fail fatally by letting the exceptionbubble up so that it is handled by the uncaught exception handler.",0
"[FLINK-17514] Harden ExceptionUtils.tryEnrichTaskManagerError, .isMetaspaceOutOfMemoryError and .isDirectOutOfMemoryError to handle null valuesError handling code should not fail. Hence, this commit changes the methods ExceptionUtils.tryEnrichTaskManagerError,ExceptionUtils.isMetaspaceOutOfMemoryError and ExceptionUtils.isDirectOutOfMemoryError to properly handle a null argument.This closes #11994.",0
"[FLINK-17501][qs] Improve logging in AbstractServerHandler#channelRead(ChannelHandlerContext, Object)Log errors as soon as possible, i.e., before serializing and sending anerror response to the client. This mitigates the problem that errorsmight be masked by other errors that are caused by the error handlinglogic.This closes #11984.",2
[FLINK-17403][test] Fix invalid classpath in BashJavaUtilsITCaseThis closes #11934.,1
[FLINK-17255][python] Support HBase connector descriptor in PyFlink. (#11955),2
[FLINK-17460][orc][parquet] Create sql-jars for parquet and orcThis closes #11946,1
[FLINK-16871][runtime] Make more build time information available at runtime,1
[FLINK-16804] Deprecate all Table methods that accept expressions as aStringAll methods of Table (and related classes like e.g. GroupedTable) thatexpect expressions as a String were deprecated in favor of theExpression DSL counterparts. This commit also removes majority of theusages of the deprecated methods. The remaining methods explicitly testthe behavior of parsing/converting the String DSL.This closes #11989,3
[FLINK-17385][jdbc][postgres] Handled problem of numeric with 0 precisioncloses #11914,0
[FLINK-16102][docs-zh] Translate /dev/table/hive/scala_shell_hive.zh.md into ChineseThis closes #11590,1
[FLINK-17416][e2e][k8s][hotfix] Disable failing test,3
[FLINK-17306] Added open to DeserializationSchema,1
[FLINK-17306] Add open to KafkaDeserializationSchema,1
[FLINK-17306] Add open to KinesisDeserializationSchema,1
[FLINK-17306] Add open to PubSubDeserializationSchema,1
[FLINK-17306] Call open of DeserializationSchema in RMQ,2
[FLINK-17306] Add open to SerializationSchema,1
[FLINK-17306] Add open to KafkaSerializationSchema,1
[FLINK-17306] Add open to KinesisSerializationSchema,1
[FLINK-17306] Call open of SerializationSchema in PubSub sink,2
[FLINK-17306] Call open of SerializationSchema in RMQ sink,2
[FLINK-12717][python] Add windows support for PyFlink (#11960),2
"[FLINK-16782][state] Avoid unnecessary check on expired entry when ReturnExpiredIfNotCleanedUpCurrent implementation of getting unexpired value would always check whether this ttl value is expired first, however, this could be improved if we check `returnExpired` first.This closes #11513.",1
[FLINK-16029][table] Port CustomConnectorDescriptor to flink-table-common module,2
[FLINK-16029][table] Refactor CsvTableSink to support numFiles and writeMode,2
[FLINK-16029][table-planner-blink] Remove registerTableSource/registerTableSink in test cases of blink planner (use tableEnv.connect() instead).This closes #11276,1
[hotfix] Add QuadConsumer interfaceThis commit adds a QuadConsumer which takesfour arguments.,1
[hotfix] Add QuadFunction interfaceThis commit adds a QuadFunction which is similar to the Function interface with the difference that it takes four arguments.,1
[hotfix][tests] Let TestingResourceManagerGateway accept registerJobManagerFunctionThis commit extends the TestingResourceManagerGateway to take a registerJobManagerFunction instead of a consumer. This gives the freedom to also control the return value of the registerJobManager method.,1
[hotfix][tests] Use self gateway in TaskExecutorPartitionLifecycleTest.testJobMasterConnectionTerminationAfterExternalReleaseOrPromotionThe test used the RpcEndpoint in order to call Rpcs instead of the self gateway. This violatedthe RpcEndpoint contract and caused concurrent modifications  of the RpcEndpoint's state.,1
[hotfix] Extract JobLeaderService interface + rename impl into DefaultJobLeaderServiceThis commit allows to provide different JobLeaderService implementations to the TaskExecutor.,1
[hotfix] Fix checkstyle violations in TaskManagerServicesBuilder,0
[hotfix] Extract JobManagerTable interface + rename impl into DefaultJobManagerTableThis commit allows to provide different JobManagerTable implementations to the TaskExecutor.,1
"[hotfix][tests] Remove Mockito from TaskExecutorTestIn order to remove Mockito from the TaskExecutorTest, this commit introduces a TestingJobLeaderService and TestingJobManagerTable implementation.",3
[hotfix] Fix checkstyle violations in LibraryCacheManager,0
[hotfix] Fix checkstyle violations in BlobLibraryCacheManager,0
[hotfix] Factor out allocateSlot method from TaskExecutor.requestSlotThis commit simplifies TaskExecutor.requestSlot method by factoring out the slot allocation logic into TaskExecutor.allocateSlot.,2
[hotfix] Establish strict one to one mapping between primary and secondary key in DualKeyLinkedMapThis commit corrects the contract of the DualKeyLinkedMap which states that there can exactly be one entry with a given primary or secondary key and that there is a strict one-to-one relationship between the keys.,1
"[hotfix] Integrate TaskExecutor.jobManagerConnections into JobManagerTableThis commit merges the data structure TaskExecutor.jobManagerConnections into the JobManagerTable. The reason why this is possible is that jobManagerConnections is only a different index which maps ResourceID to JobManagerConnection. By letting the DefaultJobManagerTable use a DualKeyLinkedMap<JobID, ResourceID, JobManagerConnection> it is possible to remove the other index which simplifies the TaskExecutor.",4
[hotfix][tests] Add TestingPartitionProducerStateCheckerTesting implementation fo the PartitionProducerStateChecker interface. This implementation makes testing tasks easier.,3
[hotfix][tests] Make NoOpCheckpointResponder top level classMake NoOpCheckpointResponder a top level class so that it can be used by other tests as well.,3
[hotfix][tests] Add TestingLibraryCacheManagerThis commit adds a testing implementation of the LibraryCacheManager interface. This makes testing of components which interact with the LibraryCacheManager easier.,3
[hotfix][tests] Speed up TaskManagerRunnerConfigurationTest#testTaskManagerRpcServiceShouldBindToHostnameAddressDecrease the akka.lookup.timeout to 10 ms in order to speed up the TaskManagerRunnerConfigurationTest#testTaskManagerRpcServiceShouldBindToHostnameAddress test.,3
[hotfix][tests] Speed up TaskExecutorSubmissionTest.testRequestTaskBackPressureDecrease the number of backpressure samples and the delay between sampling in order to speed up the Speed up TaskExecutorSubmissionTest.testRequestTaskBackPressure test.,3
"[hotfix][tests] Add TestingFatalErrorHandlerResourceThe TestingFatalErrorHandlerResource provides a TestingFatalErrorHandler instance and checks when the reource is beingclosed whether an exception has been caught. If this is the case, then the exception will be rethrown.",3
"[FLINK-16408] Introduce JobTable which manages the lifecycle of job services on the TaskExecutorThe JobTable is a TaskExecutor service and is responsible for managing the lifecycle of TaskExecutor services which are bound to a job. One of these services is the LibraryCacheManager which will created for every job only once.Once the first slot for a new job is requested from the TaskExecutor it will create a new JobTable.Job entry which is initialized with the job services. As long as the TaskExecutor has slots allocated for a job, it will keep the job services running. When the last slot is freed, the TaskExecutor will close the JobTable.Job and thereby also close all associated services.Once the TaskExecutor establishes a connection to the leading JobManager for a given job, it will start additional services which are only valid as long as the connection to the JobManager exists. In order to model this behaviour, the JobTable.Job offers a JobTable.Job#connect() method which transforms the JobTable.Job into a JobTable.Connection. This class can be used to retrieve the required services to talk to the JobManager as well as to execute tasks.Once the TaskExecutor loses the connection to the leading JobManager, the JobTable.Connection can be disconnected via JobTable.Connection#disconnect(). Calling this method will transform the JobTable.Connection into a JobTable.Job and closes all services which are only valid as long as the connection to the JobManager exists.The JobTable replaces the JobManagerTable service.",1
[FLINK-16408] Remove JobManagerTable and its implementations,4
"[FLINK-16408] Bind job blob lifecycle to JobTable.JobThe PermanentBlobCache#registerJob method registers the use of job-related Blobs. Similarly, PermanentBlobCache#releaseJob will release all job-related blobs which makes them eligible for cleanup by the periodic clean up task.Since tasks belonging to the same job should be able to share blobs (e.g. jar blobs for the common user code class loader), the PermanentBlobCache#registerJob and PermanentBlobCache#releaseJob should be bound to the job lifecycle instead of the Task lifecycle. This is what this commit achieves by moving the #registerJob and #releaseJob calls from the Task to the JobTable.Job. Whenever we create new JobTable.Job, we will also call PermanentBlobCache#registerJob. We will only call PermanentBlobCache#releaseJob when we close JobTable.Job.",1
"[FLINK-16408] Bind user code class loader to lifetime of Job on TaskExecutorThis commit binds the user code class loader to the lifetime of a JobTable.Job on the TaskExecutor. This means that the TaskExecutor will not release the user code class loader as long as it contains an allocated slot for the respective job. This will ensure that a TaskExecutor can reuse the user code class loader across failovers (task and JM failovers). By reusing user code class loaders Flink will avoid to reload classes and, thus, decrease the pressure it puts on the JVM's metaspace. This will significantly improve situations where a class leak exists because Flink won't deplete the JVM's metaspace under recoveries.In order to achieve this, the LibraryCacheManager has been changed. The LibraryCacheManager only supports to register a LibraryCacheManager.ClassLoaderLease for a given job. As long as there is a single valid ClassLoaderLease, the LibraryCacheManager will not release the associated user code class loader. A LibraryCacheManger.ClassLoaderLease needs to be resolved in order to create and then obtain the user code class loader. This is done via LibraryCacheManager.ClassLoaderHandle#getOrResolveClassLoader. Upon calling this method the first time, one specifies the set of jars and class paths the user code class loader should be started with. Every subsequent call to this method will ensure that the underlying class loader contains the set of specified jars and class paths. If this is not the case, then this method will fail. Differently said, the system only supports one user code class loader per job at the moment.Once the owner of the LibraryCacheManager.ClassLoaderLease no longer needs the user code class loader, it should call LibraryCacheManager.ClassLoaderLease#close in order to invalidate the lease. Once all leases for a given job are invalidate, the LibraryCacheManager will release the underlying user code class loader.At the moment, there is only a single lease per job which is owned by the JobTable.Job and will be created when the JobTable.Job will be created. That way we ensure that the user code class loader lives as long as the JobTable.Job.In order to ensure that we reuse the user code class loader as long as the TaskExecutor has allocated slots for a given job, TaskExecutorSlotLifetimeTest#testUserCodeClassLoaderIsBoundToSlot has been added.",1
"[FLINK-16408] Let TaskExecutor reuse LibraryCacheManager instancesThis commit changes how LibraryCacheManager are being used. Instead of creating a new instance for every new job the TaskExecutor executes, the TaskExecutor will only have a single LibraryCacheManager which is used for all jobs to execute. This will decrease the number of class instances a TaskExecutor has to create a bit.This change also changes the lifecycle of the LibraryCacheManager a little bit: The LibraryCacheManager will now be closed as part of the TaskManagerServices which happens when the TaskExecutor shuts down.",4
[hotfix][tests] Replaced some manual TestingFatalErrorHandler usages with TestingFatalErrorHandlerResource,3
[FLINK-16408] Introduce JobTable.JobServices which allows combine more job servicesJobTable.JobServices will be used by the TaskExecutor to store the LibraryCacheManager.ClassLoaderLeaseas well as a handle to the PermamentBlobCache in order to release the blobs once the correspondingJobTable.Job is being closed.This closes #11963.,0
"[hotfix] Remove throws exception clause from DefaultJobLeaderService#removeJobWith this commit we remove the throws exception clause from DefaultJobLeaderService#removeJob.Even if closing the LeaderRetrievalService fails, we still have removed the entry from theDefaultJobLeaderService and we have stopped the JobManagerLeaderListener so that we won'treact to leader change notifications.",4
"[FLINK-17552][network] Do not cache InputChannels in UnionInputGateThis is a simple fix for a bug on the master branch that is not visible currently in anyway, but which is causingan inconsistent state with UnionInputGate if underlying channels are updated inside SingleInputGate",5
[hotfix][network] Improve error message in ChannelStateWriterImpl,0
[hotfix][network] Add debug message marking end of output recovery for unaligned checkpoints,0
[FLINK-17555][python] Remove duplicate FileSystem object in descriptors (#12023),5
[FLINK-16638][runtime][checkpointing] Flink checkStateMappingCompleteness doesn't include UserDefinedOperatorIDs,1
[FLINK-17092][python] Add retry when pip install dependencies (#12024),1
[FLINK-17251] [table] Introduce Table#executeInsert & add insert statement support to TableEnvironment#executeSqlThis closes #11862,1
[FLINK-16529][python] Add ignore_parse_errors() method to Json format in python APIThis closes #12014.,5
"[FLINK-16104][docs-zh] Translate ""Streaming Aggregation"" page of ""Table API & SQL"" into ChineseThis closes #11897",1
[FLINK-17256][python] Support keyword arguments in the PyFlink descriptor APIThis closes #12013.,2
[FLINK-17267] [table-planner] legacy stream planner supports explain insert operation,1
[FLINK-17267] [table-planner] legacy batch planner supports explain insert operation,1
[FLINK-17267] [table] TableEnvironment#explainSql supports EXPLAIN statement,1
[FLINK-17267] [table] Introduce TableEnvironment#explainSql api,2
[FLINK-17267] [table] Introduce Table#explain apiThis closes #11905,2
[hotfix][docs][s3] Clarify wording of S3 Filesystem supportThis closes #12043,1
[FLINK-17570] Fix recursive call in BatchTableEnvironment#fromValues,0
[hotfix][table-common] Make scan and sink RuntimeProvider interfaces public,1
[FLINK-16989][table-planner-blink] Rename current TableSourceScan into LegacyTableSourceScanThis closes #11985,2
[FLINK-16989][table-planner-blink] Support ScanTableSource in blink plannerThis closes #11985,2
[FLINK-17030][sql-parser] Add primary key syntax for CREATE TABLEThis closes #11950,1
[FLINK-17030][sql-parser] Add primary key syntax for ALTER TABLEThis closes #11950,1
[FLINK-17030][table-planner-blink] Add primary key syntax for CREATE TABLEThis closes #11950,1
[FLINK-17030][table-planner-blink] Add primary key syntax for ALTER TABLEThis closes #11950,1
"[FLINK-16097][docs-zh] Translate ""SQL Client"" page of ""Table API & SQL"" into ChineseThis closes #11961",1
[FLINK-17291][docs-zh] Translate training lesson on event-driven applications to chineseThis closes #11979,1
[FLINK-17204][connectors/rabbitmq] Make RMQ queue declaration consistent between source and sinkThis closes #12001,1
"[FLINK-17568][checkpointing] Fix the issue that task may consume input data after checkpoint barrier before checkpoint is performed for unaligned checkpointFor unaligned checkpoint, task may consume data after the checkpoint barrier before performing checkpoint which leads to consumption of duplicated data and corruption of data stream. More specifically, when the Netty thread notifies the checkpoint barrier for the first time and enqueues a checkpointing task in the mailbox, the task thread may still in data processing loop and if it reads a new checkpoint barrier from a input channel it will not return to the mailbox and instead it will continue to read data until all data is consumed or we have a full record, meanwhile, the data after checkpoint barrier may be read and consumed which lead to inconsistency.This commit fixes the problem by returning to mailbox each time a checkpoint barrier is processed by the task thread.",0
[hotfix][tests] Remove redundant test case CheckpointBarrierAlignerTestBase#testMultiChannelSkippingCheckpointsThis closes #12034.,3
[FLINK-17271][docs-zh] Translate new DataStream API trainingThis closes #11971,5
[FLINK-17585][python] PythonProgramOptions should not change the entrypoint when submitting a Java sql job which contains Python UDF. (#12051),1
[FLINK-17586][python] BatchTableEnvImpl uses the cached files registered in the ExecutionEnvironment to create the job pipeline. (#12050),1
[FLINK-17586][python] Use the real StreamExecutionEnvironment contained in DummyStreamExecutionEnvironment when translating the Python UDF physical nodes to operators. (#12048),1
[FLINK-16990][table-planner-blink] Support LookupTableSource in blink plannerThis closes #12047,2
"[FLINK-17564][checkpointing] Fix buffer disorder issue of RemoteInputChannel for unaligned checkpointFor unaligned checkpoint, when checkpointing the inflight data of incoming channels, both task thread and Netty thread may add data to the ChannelStateWriter. More specifically, the task thread will first request inflight buffers from the input channel and add the buffers to the ChannelStateWriter, and then the Netty thread will add the following up buffers (if any) to the ChannelStateWriter. The buffer adding action of task thread and Netty thread is not synchronized so the Netty thread may add buffers before the task thread which leads to disorder of the data and corruption of the data stream.This PR fixes the problem by requesting and enqueuing the inflight buffers in the synchronized block.",5
[FLINK-16367][table] Introduce TableEnvironment#createStatementSet apiThis closes #12042,3
[FLINK-17452][hive] Support creating Hive tables with constraintsThis closes #12017,1
[FLINK-17601][table-planner-blink] Correct the table scan node name in the explain result of TableEnvironmentITCase#testStatementSetThis closes #12060,3
[FLINK-16346][runtime][tests] Use BlockingNoOpInvokable,1
[FLINK-17286][table][json] Integrate json to file system connectorThis closes #12010,5
[FLINK-17289][docs]Translate tutorials/etl.md to Chinese,2
[FLINK-17454][python] Specify a port number for gateway callback server from python gateway.This closes #12061,2
[FLINK-17603][table][core] Prepare Hive partitioned streaming sourceThis closes #12063,2
[FLINK-17567][python][release] Create a dedicated Python directory in release directory to place Python-related source and binary packagesThis closes #12030.,1
"[FLINK-17369][tests] In RestartPipelinedRegionFailoverStrategyBuildingTest invoke PipelinedRegionComputeUtil directlyRestartPipelinedRegionFailoverStrategyBuildingTest means to test thelogic in PipelinedRegionComputeUtil. Currently, however, the pipelinedregions are retrieved indirectly fromRestartPipelinedRegionFailoverStrategy. This commit changes that byusing the PipelinedRegionComputeUtil directly from the test.",3
[FLINK-17369][tests] Rename RestartPipelinedRegionFailoverStrategyBuildingTest to PipelinedRegionComputeUtilTest,3
[FLINK-17369][tests] Reduce visiblity of internal test methodsReduce visiblity from public to private for methods  - PipelinedRegionComputeUtilTest#assertSameRegion(Set<SchedulingExecutionVertex>...)  - PipelinedRegionComputeUtilTest#assertDistinctRegions(Set<SchedulingExecutionVertex>...)This closes #11929.,3
[FLINK-17416][e2e][k8s] Use fixed v1.16.9 because fabric8 kubernetes-client could not work with higher version under jdk 8u252,1
[FLINK-17416][e2e][k8s] Enable k8s related tests,3
[FLINK-17523] Add call expression with a class of UDF as a parameter,2
[FLINK-17608][web] Add TM log and stdout page/tab backThis closes #12085.,2
[FLINK-17252][table] Add Table#execute api and support SELECT statement in TableEnvironment#executeSqlThis closes #12049,1
"[FLINK-16845] Adds implmentation of SourceOperator. This patch does the following:1. Add CoordinatedOperatorFactory interface.2. Rename SourceReaderOpertor to SourceOperator, add implementation and connect it to OperatorEventGateway.3. Rename SourceReaderStreamTask to SourceOperatorStreamTask4. Fix some bugs in StreamTaskMailboxTestHarness.",3
[FLINK-14257][table][filesystem] Integrate CSV to FileSystemTableFactoryThis closes #11755,5
[hotfix][network] Fix useless backlog value in BufferAndAvailability returned by RemoteInputChannel#getNextBuffer,1
[hotfix][network] Extract a general buffer manager for future reuse by recovered input channel,1
[hotfix][network] Maintain MemorySegmentProvider from InputChannel to SingleInputGate,1
[hotfix][tests] Refactor unit tests in RemoteInputChannelTest to avoid mock way,3
"[FLINK-16536][network][checkpointing] Implement InputChannel state recovery for unaligned checkpointDuring recovery process for unaligned checkpoint, the input channel state should also be recovered besides with existing operator states.We considered three guarantees during the implementation:1. Make input recovery happen after the output recovery for providing more floating buffers on output side firstly.2. Make partition request happen after input recovery for avoiding new data overtaking the previous state data.3. Introduce a dedicated single IO executor for unspilling the channel state one by one, to avoid potential random IO.This closes #11687.",5
[FLINK-17130][web] Enable listing JM logs and displaying logs by filenameThis closes #11731.,2
"[FLINK-17609][python] Execute the script directly when user specified the entry script with ""-py"" (#12079)",1
[FLINK-17577][table-common] SinkFormat#createSinkFormat should use DynamicTableSink.Context as parameterThis closes #12039,2
[FLINK-17434][hive] Hive partitioned source support streaming readThis closes #12004,1
[hotfix][parquet] Parquet notice file should be flink-parquet,2
[FLINK-17536][core] Change the config option for slot max limitation to slotmanager.number-of-slots.maxThis closes #12067.,5
[FLINK-17497][e2e] Properly switch to Scala 2.12 in quickstart testThis closes #12016,3
[hotfix][kafka] Remove unused method AbstractFetcher#emitRecord,1
"[FLINK-17307] Add collector to deserialize in KafkaDeserializationSchemaThis PR adds a way to emit multiple records fromKafkaDeserializationSchema. This is possible through a collector, whichwill buffer deserialized records in a queue and then emit all recordsatomically. The queue is reused for all incoming Kafka records tominimize creating new objects on the hot path.",1
[FLINK-17309][e2e tests]TPC-DS fail to run data generator due to network issues,0
[FLINK-17614][table] Add project it case for partition table in filesystem connectorThis closes #12091,5
[FLINK-17003] Added WATERMARKS as additional LIKE clause option inparser,1
"[FLINK-17002] Add util for merging ""tables"" for CREATE TABLE LIKECo-authored-by: Dawid Wysakowicz <dwysakowicz@apache.org>",1
[FLINK-17002] Support CREATE TABLE LIKE DDL in operation converter,1
[FLINK-17002] Disallow CREATE TABLE ... LIKE in legacy plannerThis closes #11981,1
[FLINK-17112][table] Support DESCRIBE statement in Flink SQLThis closes #11892,2
[FLINK-16521] Remove unused FileUtils#isClassFile,2
[FLINK-15841][core] Clarify that TimeWindow.intersect returns true if there is no gapThis also adds a test case to ensure this works as expected.,1
[FLINK-17342][checkpointing][hotfix] Synchronize access to CheckpointCoordinator.pendingCheckpoints,2
[FLINK-17342][checkpointing][hotfix] Extract CheckpointRequestDeciderPre-requsite refactoring to change decision logic,2
"[FLINK-17342][checkpointing] Enqueue savepoint requests in UC modeMotivation: current behavior of forcing savepoints causes excess ofmax-concurrent-checkpoints limit. Which violates current UnalignedCheckpoints (UC) assumption of a single concurrent barrier.Changes:1. Remove periodicTriggeringSuspended. Instead, if periodic request can't be executed now is ignored.2. Check queue before executing a new request (not after).3. Execute queued request when pending checkpoint is completed (instead of resuming timer).4. Don't set CheckpointRequest.force in UC mode.5. Change requests queue to PriorityQueue to prioritize savepoints. Limit its size.6. For savepoints, if running in UC mode and limit is reached then enqueue request instead of forcing it7. Don't throw trigger exceptions. CheckpointFailureManager ignores them",0
[hotfix][yarn] Remove duplicated adding ship files in yarn-tests,3
"[FLINK-13938][yarn] Add yarn.provided.lib.dirs for shared libs across apps on YARNCurrently, for every job execution, the flink lib jars are uploaded tohdfs and then register as Yarn local resources.This PR introduces the yarn.provided.lib.dirs YARN option which allowsusers to specify HDFS paths to dirs that contain files to be shared acrossapplications, e.g. the FLINK-DIST jar.This makes job submission more efficient as it allows for  two optimizations:* Use pre-uploaded flink binary to avoid uploading of flink system jars* By default, the resource visibility for the shared libs is set to PUBLIC  so that they will be downloaded only once and shared for all tasks running  on the same node. This will make launching a container faster.A command that leverages this feature looks like the following:./bin/flink run -m yarn-cluster -d \-yD yarn.provided.lib.dirs=""hdfs://$namenode_address/flink-lib/flink-1.11-SNAPSHOT/lib;hdfs://$namenode_address/flink-lib/flink-1.11-SNAPSHOT/plugins"" \examples/streaming/WindowJoin.jarThis closes #12040.",2
[hotfix] Fix Scala 2.12 build,0
[minor] Use FutureUtils.waitForAll() in AppDispatcherBootstrap.getApplicationResult(),1
[FLINK-17620] Rename StandaloneJobClusterEntryPoint to StandaloneApplicationClusterEntryPointThis PR renames the entrypoint but DOES NOT change the scripts as this would bea breaking change for already existing deployments and such a change wouldrequire a more thorough and more visible discussion with the community.This closes #12087.,1
[FLINK-17640][network] Temporarily disable unstable RecoveredInputChannelTest#testConcurrentReadStateAndProcessAndRelease,3
[FLINK-17315][checkpointing] Fix NPE in unaligned checkpoint after EndOfPartition eventsReleased deserializers cause NPE in StreamTaskNetworkInput#prepareSnapshot.,1
[FLINK-17315][checkpointing] Disable priority event listenerPriority event listener currently does not snapshot any buffers and causes additional synchronization points. We should re-enable/re-evaluate this concept once a proper threading model has been established on input side.,0
"[FLINK-17315][checkpointing] LocalInputChannel also checkpoints in-flight data.When a downstream tasks starts snapshotting input before the upstream task finished snapshotting output, it may happen that a buffer is neither snapshotted upstream or downstream. This commit replicates the logic of RemoteInputChannel to also store these buffers.",2
[FLINK-17315][checkpointing] Fixed SpillingAdaptiveSpanningRecordDeserializer#getUnconsumedBuffer.,5
[FLINK-17315][checkpointing] Only adding buffers to inflight data of PipelinedSubpartition.,5
[FLINK-17315][tests] Fix and reenable UnalignedCheckpointITCase.,0
[FLINK-17307] Add collector to deserialize method of DeserializationSchema,1
[FLINK-17307] Forward call to DeserializationSchema#collect with acollector in KafkaDeserializationSchemaWrapper,2
[FLINK-17307] Add collector to deserialize in RMQ,1
[FLINK-17307] Check for deserialize method with a Collector in Kinesis consumer,2
[FLINK-17307] Add collector to deserialize in PubSub,1
[FLINK-17628][python] Remove the unnecessary py4j log information. (#12098),5
[FLINK-17612][python][sql-client] Support Python command line options in SQL Client. (#12077),1
"[FLINK-16364][table] Deprecate the methods in TableEnvironment & Table proposed by FLIP-84which includes:TableEnvironment.sqlUpdate(String)TableEnvironment.insertInto(String, Table)TableEnvironment.execute(String)TableEnvironment.explain(boolean)TableEnvironment.fromTableSource(TableSource<?>)Table.insertInto(String)Please use TableEnvironment#executeSql for single statement,use Table#executeInsert for single sink,use TableEnvironment#createStatementSet for multiple sinks.This closes #11297",3
[FLINK-17633][table-common] Improve FactoryUtil to align with new format option keysThis closes #12099,1
[FLINK-17431][sql-parser-hive][hive] Implement table DDLs for Hive di (#11935)* [FLINK-17431][sql-parser-hive][hive] Implement table DDLs for Hive dialect part 1* address comments and fix collection delim* renaming* rebase* remove unused property* don't support bytes* add enums for hive constraint traits* store NN col names and add test* disallow varchar w/o precision* fix unparse for describe table* fix unparse row format* fix col type unparse* address comments,1
[FLINK-16991][table-planner-blink] Rename current LogicalSink into LogicalLegacySink,2
[FLINK-16991][table-planner-blink] Support DynamicTableSink in blink plannerThis closes #12086,2
[FLINK-17562][rest] Use correct headers for POST JobPlanHandler,0
[hotfix][rest][docs] Regenerate REST documentation,2
[FLINK-15154][runtime] Make blob sever respect 'jobmanager.bind-host'.,1
[FLINK-15154][runtime] Use local actor system for metrics query service when using single prc service mode in local execution.This closes #12022.,1
[hotfix][FLINK-17591][table-planner] Fix TableEnvironmentITCase.testExecuteSqlAndToDataStream failed,0
[FLINK-17476][tests] test recovery from snapshot created in different UC mode,1
"[FLINK-17336][CI] Update watchdog to properly kill watched processAs part of FLINK-16411, we introduced a run_mvn bash function. A sideeffect of this is that the watchdog was killing the run_mvn functioncall, but not the child process of that function (in this case)Maven.With this change, we are killing the function and all childrenof that function.Reference: https://stackoverflow.com/questions/2618403/how-to-kill-all-subprocesses-of-shell",1
[FLINK-17336][CI] Increase watchdog timeout to 10 minutes,1
[FLINK-17648][yarn] Make YarnApplicationClusterEntryPoint use the yarn.application-master.portThis closes #12109.,1
"[FLINK-17537][jdbc] Refactor flink-jdbc connector structure(1) Use Jdbc instead of JDBC.(2) Move interfaces and classes to org.apache.flink.connector.jdbc.(3) Keep ancient JDBCOutputFormat, JDBCInputFormat and ParameterValuesProvider in old package.(4) Add tests/ITCase for ancient Classes and new classes.(5) rename flink-jdbc module to flink-connector-jdbc.(6) update docs.This closes #12036",2
[FLINK-11086] Replace flink-shaded-hadoop-2 dependency by vanilla Hadoop dependency,2
[FLINK-11086][e2e] Properly add Avro JARs in SQLClientKafkaITCase,1
[FLINK-11086][HBase] Skip some HBase tests in Hadoop 3,3
[FLINK-11086][yarn] Use YARN_APPLICATION_CLASSPATH instead of flink-shaded-hadoop fat jar in tests,3
[FLINK-11086][e2e] Use HADOOP_CLASSPATH in end to end tests,3
[FLINK-11086][AZP] Add Hadoop3 test profile to nightlies,2
[FLINK-11086][docs] Make HADOOP_CLASSPATH approach more prominent in docs,2
[FLINK-11086] Clean up profiles and dependency exclusionsThis closes #11983,2
[FLINK-17660][table-common] Check default constructor for structured typesThis closes #12123.,2
[hotfix][docs] Fix and improve query configuration docs.* Fix: TableConfig is *not* passed back when a Table is translated.,4
[FLINK-17616][tests] Temporarily increase akka.ask.timeout in TPC-DS e2e testThis closes #12082.,3
[FLINK-10934][client] Make flink run-application could support local schema,1
[FLINK-10934][k8s] Support application mode for kubernetesThis closes #12003.,3
[FLINK-10934][e2e] Add e2e tests for Kubernetes application mode,3
[FLINK-10934][dist] Set log4j for Kubernetes cli,2
[FLINK-17636][network][tests] Fix the unstable unit tests in SingleInputGateTest,3
[FLINK-17640][network][tests] Fix the unstable unit tests in RecoveredInputChannelTest,3
[FLINK-17538][hbase] Refactor flink-hbase connector structure(1) rename flink-hbase module to flink-connector-hbase(2) Move interfaces and classes to org.apache.flink.connector.hbase(3) Keep ancient TableInputFormat in old package and mark deprecated(4) Restructure classes into sub-packages(5) Update documentationsThis closes #12102,2
[FLINK-17604][csv] Implement format factory for CSV serialization and deseriazation schema of RowData typeThis closes #12065,5
[FLINK-17663][task][hotfix] Do not hide original exception in case of a secondary failure during task clean up,4
"[FLINK-17663][network] Properly support UnionInputGates with unaligned checkpointsWithout this fix, various tests, like KeyedStateCheckpointingITCase, are failing with unaligned checkpointswith ArrayIndexOutOfBoundsException as CheckpointBarrierUnaligner#gateChannelOffsets would be incorrectlyinitialized.",5
[hotfix][hive] Should clear StreamTestSink in HiveTableSourceTestThis closes #12124,3
[FLINK-17646][python] Reduce the package size of PyFlink. (#12106),2
[FLINK-17679][python] Replace strlen with the Python len for cython bytes encoding (#12142),2
[FLINK-17655] Remove old and long deprecated TimestampExtractor,4
[FLINK-17655] Remove assignTimestamps from documentationThis was deprecated and now removed.,4
[FLINK-17654][core] Move Clock classes to flink-core to make them usable outside runtimeWe want to use them in the new WatermarkGenerator implementations infollow-up commits.,5
"[FLINK-17654][core] Minor cleanups in clock classesAdds JavaDocs.Makes implementations final, because they are not designed for inheritance.",1
[FLINK-17654] Make Clock interfaces in flink-core PublicEvolving,2
[FLINK-16946] Update user documentation for job manager memory modelThis closes #11947.,2
"[FLINK-17665][network] Replace isBuffer with BufferType field in BufferResponseThe current isBuffer field in BufferResponse can only represent whether it is buffer or event, so it has to deserialize the respective buffer to get the specific event type for some requirements on downstream side.By introducing the BufferType into the BufferResponse, we can get the required event type directly to avoid performance concerns.",1
[hotfix][test] Disable Google PubSub Emulator e2e test on aarch64This closes #12111,3
[hotfix][runtime] Remove useless class ZooKeeperCompletedCheckpointStoreITCaseThis closes #12083,1
[hotfix][typo]Fix typo in task_lifecycle docsThis closes #12068,2
[FLINK-15138][e2e][python] Add PyFlink e2e testsThis closes #12104.,3
[FLINK-17303][python] Support Python TableResultThis closes #12009.,1
[FLINK-17680][docs] Support @ExcludeFromDocumentation when generating REST API documentationsThis closes #12141.,2
"[FLINK-16383] Set close = true in monitor/lock scope in KafkaProducerBefore, the flag was changed outside the lock, which would allow thecase that the flag is set to true while someone else is holding the""close lock"".",1
"[FLINK-16383] Add debug logging to internal Kafka ProducerFor debugging FLINK-16383 we need to see who closes a Producer to tryand match the ""already closed"" exceptions.",1
[FLINK-16383] Enable DEBUG logging for internal Kafka Producer on CIThis should be disabled again after FLINK-16383 has been resolved.,0
"[FLINK-17578] In StreamEdge, use output tag in hashCode and equalsIt fixes the behavior: when we take the union of two side outputs. Flinkwas repeating the data from one twice.",5
[FLINK-17467][task][hotfix] Remove cast in CheckpointedInputGate,4
[FLINK-17467][task][checkpointing] Align channels on savepoint in UC mode,2
[FLINK-17467][task][checkpointing] Code cleanup,4
[hotfix][test] Fix formatting in StatefulStreamJobUpgradeTestProgram,3
"[FLINK-17467][task][e2e] Modify existing upgrade test to verify aligned savepointsNew upgrade job, upon upgrade modifies the job graph and type of processed record.This ensures that savepoints are executed always as aligned, with no in-flight data.",5
[FLINK-17222][table-common] Ensure deterministic field order in FieldsDataTypeNew method DataType.getChildren() provides better guarantees.This closes #12121.,1
"[FLINK-14881][s3] Bump aws-sdk-version to 1.11.754, httpclient to 4.5.9 and add aws-java-sdk-sts dependency to support WebIdentityToken",1
[FLINK-14881][kinesis] Bump aws-sdk-version to 1.11.754 to support WebIdentityTokenThis closes #12008,1
[FLINK-17668][table] Fix shortcomings in new data structuresThis fixes the following shortcomings in the new data structures:- The some data structures do not provide a hashCode/equals for testing.- RawValueData cannot be created from bytes.- Accessing elements requires dealing with logical types during runtime.- Null checks are performed multiple times during runtime even for types that are declared as NOT NULL.This closes #12130.,1
[FLINK-14807][rest] Introduce REST API for communication between clients and operator coordinatorsThis closes #12037,1
[FLINK-17667][table-planner-blink][hive] Support INSERT statement for hive dialectThis closes #12129,1
[FLINK-17629][json] Implement format factory for JSON serialization and deserialization schemaThis closes #12140,5
[FLINK-17387][hive] Implement LookupableTableSource for Hive connectorThis closes #11990,2
[FLINK-13811][python] Support converting flink Table to pandas DataFrameThis closes #12148.,5
[FLINK-12717][python] Remove script pyflink-gateway-server.sh which has been replaced with pyflink_gateway_server.pyThis closes #12125.,2
[FLINK-17710][python][hotfix] Fix unstable test for StreamSqlTests.test_execute_sql (#12160),3
"Revert ""[FLINK-17710][python][hotfix] Fix unstable test for StreamSqlTests.test_execute_sql (#12160)""This reverts commit be9779df4a817697788ed44fc618900595b248d8.",4
"Revert ""[FLINK-17303][python] Support Python TableResult""This reverts commit 381131a785700a7d07b822d6db4eaa72d2daab61.",5
"Revert ""[FLINK-17467][task][e2e] Modify existing upgrade test to verify aligned savepoints""This reverts commit fbec926d239ee7462059ab1cc43182d2e0a2a2ee.",4
[FLINK-17606][table] Introduce DataGenerator connector in tableThis closes #12074,5
[FLINK-17596][python] Move the Python UDF runner script out of the jar of flink-pythonThis closes #12092.,2
[FLINK-17697][jdbc] Fix JdbcFullTest.testEnrichedClassCastException is failed in JDK11This closes #12158,0
[hotfix][docs] Fix Kinesis consumer example,0
[FLINK-17693][table] Add createTypeInformation to DynamicTableSink#Context This closes #12154,5
[FLINK-17701][build] Exclude transitive jdk:tools dependency from all Hadoop dependencies.This closes #12156,2
"[FLINK-17664][table] Introduce print, blackhole connector in tableThis closes #12126",2
[FLINK-17722][python][build system] Keeps flink-sql-client_*.jar in cache between stagesThis closes #12164.,2
[FLINK-17652][config] Legacy JM heap options should fallback to new JVM_HEAP_MEMORY in standaloneThis closes #12110.,1
[hotfix] Rename JobManagerProcessUtils#processSpecFromConfigWithFallbackForLegacyHeap to processSpecFromConfigAndFallbackToNewOptIfLegacyHeapSet,5
[FLINK-11395][avro] Support for Avro StreamingFileSinkThis closes #11385,2
[FLINK-17435][hive] Hive non-partitioned source supports streaming readThis closes #12025,1
"Revert ""[FLINK-17435][hive] Hive non-partitioned source supports streaming read""This reverts commit 32bd0944d0519093c0a4d5d809c6636eb3a7fc31.",4
"[FLINK-17643][tests] Fix LaunchCoordinatorTest instability by completing stubbingThe LaunchCoordinatorTest was susceptible to test failures because a test did not fullydefine a mock. The test scheduled a scheduled action which, if executed long enough, wouldbe triggered and then call into an incomplete mock causing a NPE.This closes #12114.",1
[FLINK-17149][json][debezium] Introduce Debezium format to support reading debezium changelogs,4
[FLINK-17150][json][canal] Introduce Canal format to support reading canal changelogsThis closes #12152,4
[FLINK-17161][docs][docker] Document the official docker hub image and examples of how to use itThis closes #12131.,1
[FLINK-17218][checkpointing] Ensuring that ChannelStateWriter aborts previous checkpoints before a new checkpoint is started.,1
[FLINK-17218][checkpointing] Cleaning up ChannelStateWriter state after all data has been written and after sync checkpoint failure.,0
[FLINK-17218][tests] Adding recoverable failures and correctness checks to UnalignedCheckpointITCase.,0
[FLINK-17632][yarn] Always build the packaged program in the cluster for application mode,2
[FLINK-17632][yarn] Support to specify a remote path for job jarThis closes #12143.,1
[FLINK-17632][yarn] Move some variables as member of YarnApplicationFileUploader to make it more self-contained,1
[minor] Refactoring the ClassPathPackagedProgramRetriever creation,1
[hotfix][yarn] Add validation in YarnClusterDescriptor when parsing provided lib directories,1
"[FLINK-17729][yarn] Make mandatory to have lib/, plugin/ and dist in yarn.provided.lib.dirsIf the user specifies yarn.provided.lib.dirs, then the lib/ flink-dist andplugin/ dirs are expected to be found there. If they are not there, then thefeature cannot be used and the option should be set to null.If these dirs are provided, then these are going to be used to executethe application and NOT what the user may have locally (e.g. different flink or log4j versions).Alternatively we could go case-by-case and say if the file to be shippedhas the same name as one in the shared directories, then do not ship it and use the remote.But this way of doing things transparently to the user oftentimes leads tounpleasant surprises that are difficult to debug.This closes #12170.",0
[FLINK-17724][python] Set working directory before running the Python helper scripts.This closes #12167.,1
[hotfix][python] Shows only the slowest 20 tests,3
[FLINK-17590][fs-connector] Support bucket lifecycle listener in streaming file sink bucketsThis closes #12053,2
[FLINK-17435][hive] Hive non-partitioned source supports streaming readThis closes #12177,1
[FLINK-16624][k8s] Support user-specified annotations for the rest ServiceThis closes #12105 .,1
"[FLINK-17748][table] Remove registration of TableSource/TableSink in table envThe old TableSource/TableSink interface will be replaced by FLIP-95 in the future, thuswe choose a more lightweight solution to move the registration from TableEnvironementto TableEnvironmentInternal, keep these methods from users but still avaliable to ourcodebase.After FLIP-95 is done, we should continue to improve table factory and related descriptor APIto make it easy and intuitive for users to register user defined table (source & sink).This closes #12076",1
[hotfix] fix table walkthrough due to removing TableSource & TableSink registration,4
[hotfix] fix e2e test due to removing TableSource & TableSink registration,4
[FLINK-17450][sql-parser][hive] Implement function & catalog DDLs for Hive dialect This closes #12161,2
[FLINK-17727][task] don't create output stream with no channel state (unaligned checkpoints),1
"[FLINK-17727][e2e] Re-enable ""[FLINK-17467][task][e2e] Modify existing upgrade test to verify aligned savepoints"" after a fixThis reverts commit 3af17562eb791e3f486c38dbd94dc3328309b262.",5
[FLINK-17587][runtime] Extract StreamingFileSinkHelper from StreamingFileSink,2
[FLINK-17587][filesystem] Filesystem streaming sink support commit success file,2
[hotfix] fix the import of archetype resources,2
[FLINK-17737][task] use UnalignedCheckpointBarrierHandler for some calls to AlternatingCheckpointBarrierHandler,0
[FLINK-17737][task] Implement close by AlternatingCheckpointBarrierHandler,0
[FLINK-17737][task] Skip out of order barrier in AlternatingCheckpointBarrierHandler,0
[FLINK-17350][task][hotfix] Simplify checkpoint exception handlingCheckpoint exceptions do not need to report failures via Environment#failExternallysince Mailbox can properly handle exceptions in the mails (by shutting down thetask),0
[FLINK-17350][task] Fail task immediately if synchronous part snapshotState throws an exceptionTolerating synchronous part failures can lead to operators being left in an incosistent state.For more details please take a look in the ticket.,1
post-rebase fixup! [FLINK-17350][task] Fail task immediately if synchronous part snapshotState throws an exception,0
[hotfix][checkpointing] Fix the invalid argument in constuctor of CheckpointCoordinatorConfiguration,5
"[FLINK-17719][task][checkpointing] Provide ChannelStateReader#hasStates for hints of reading channel statesCurrently we rely on whether unaligned checkpoint is enabled to determine whether to read recovered states during task startup,then it will block the requirements of recovery from previous unaligned states even though the current mode is aligned. We canmake `ChannelStateReader` provide the hint whether there are any channel states to be read during startup, then we will neverlose any chances to recover from them.",1
"[FLINK-17734][streaming] Add an operator coordinator and sink function to collect sink data.* The coordinator acts as a proxy between the client and the sink function, because in some environments clients can't directly talk to task managers.* The sink function uses a simple to handle failures in order to achieve exactly-once semantics. See {{CollectSinkFunction}} for more details.This closes #12069",1
[FLINK-17526][avro] Support AVRO serialization and deseriazation schema for RowData typeThis closes #12133,5
[FLINK-17718][avro] Integrate avro to file system connectorThis closes #12162,5
[hotfix][table-common] Reduce conversion classes of BINARY/VARBINARY,0
[hotfix][table-common] Make the usage of structured types easier,1
[hotfix][table-common] Fix structured type field order,0
[hotfix][table-common] Fix conversion class of element array data types,5
"[FLINK-16999][table-runtime-blink] Add converters for all data types and conversion classesThis adds converters for all data types and all conversion classes. It refactors theDataFormatConverter for cleaner readability and adds a lot of tests.Among other conversions, it adds complete support for structured types(incl. immutable POJOs).The only not 100% unsupported types are TimeType and DayTimeIntervalType.This closes #12135.",1
"[FLINK-16075][docs-zh] Translate ""The Broadcast State Pattern"" page into Chinese",2
[FLINK-16075][docs-zh] modification based on klion26's review,2
[FLINK-17248] Introduce configuration for pool size of io-executor for ClusterEntrypoint and MiniClusterThis closes #11957.,5
"[FLINK-15836][k8s] Throw fatal error in KubernetesResourceManager when the pods watcher is closed with exceptionBy default the watcher will always reconnect in Kubernetes client internally. However, if the watchReconnectLimit is configured by users via java properties or environment, the watcher may be stopped. Then all the changes of pods will not be processed properly. The reason why the the watcher closed exceptionally is usually because of network problems or port abuse. The correct way is to fail the jobmanager pod and retry in a new one.This closes #11010.",1
[FLINK-15668][tests] Remove travis test stages for legacy scheduler,3
[FLINK-15668][tests] Remove AlsoRunWithLegacySchedulerThis closes #10899.,1
[FLINK-17739][network][tests] Fix unstable ResultPartitionTest#testInitializeMoreStateThanBuffer,5
"[FLINK-15629][runtime] Remove LegacyScheduler class, factory and tests",3
[FLINK-15629][runtime] Remove SchedulerBase#getExecutionGraph() which is not needed any more,1
[FLINK-15629][runtime] Remove the unused param restartStrategyFactory from SchedulerNGFactoryFactory#createSchedulerNGFactory(),1
[FLINK-15629][runtime] Remove unused JobManagerSharedServices#restartStrategyFactory,1
[FLINK-15629] Unify DefaultSchedulerBatchSchedulingTest with BatchSchedulingTestBaseThis closes #10883.,3
[FLINK-5763][state backends] Do not create local stream for savepoint of heapstatebackend,1
[FLINK-5763][state backends] Make savepoint selfcontain and relocatable,1
[hotfix][state backends] Minor code-style cleanups,4
"[FLINK-5763][state backends] (follow-up) Pull scope and relative/absolut path decision out of FsCheckpointStateOutputStreamThe FsCheckpointStateOutputStream should not have to be aware of the notion of checkpointstate scopes (exclusive / shared), or which one supports which path types.(There is previous entropy handling code in the FsCheckpointStateOutputStream which arguablyshould also not be there).",1
[hotfix][tests] Make FsCheckpointStateOutputStreamTest work on Windows OS,1
"[FLINK-5763][state backends] (follow-up) Rework MetaData Serializers and externalPointer passingThis fix has several goals:(1) Change the pointer / path resolution parsing from a static variable to a parameter that is passed.The serializers are singleton instances and currently assume to be usable in a multi-threaded manner.The static variables prevent this, usng the context object parameter restores this behavior.(2) Lower level serialization methods should not expose themselves directly to the tests.This methods makes (almost) all lower level serialization methods instance methods and package-private.Static access methods are gathered in one place, as a workaround for tests that require accesd tothose lower level methods (even through they should not).(3) With more unified access to the methods from tests, we can now make prevent that tests need tobe aware of the the context object or external pointer parameter.(4) Minor cosmetic cleanups around method grouping.",4
[hotfix][tests] Add some clarifying comment in MetadataV3SerializerTest,5
[FLINK-17694][core] Fix argument check for SimpleVersionedSerialization,0
[FLINK-10740][DataStream API] Add a utility SimpleVersionedListState,1
[FLINK-10740][DataStream API] Simplify SourceOperator by using SimpleVersionedListState,1
[hotfix][DataStream API] Minor formatting/warnings fixes in the SourceOperator and StreamOperator code.,1
"[hotfix][DataStream API] Fix style and warnings for CollectSinkOperatorFactoryIn particular, avoid raw types and do not generate compiler warnings, as per the Flinkcodeing style guide.",2
[FLINK-17696][streaming runtime] Add CoordinatorEventDispatcher to StreamOperatorParametersThis supports more eager initialization of operators that depends on the CoordinatorEventDispatcher.,1
[FLINK-17699][DataStream API] Initalize SourceOperator more eagerly and reduce scope or collaborators.This reduces the scope of necessary mocking in the tests and of special-casing in the setup logic.  - This removes the dependency on Source and replaces it with a reader factory  - This let's the SourceOperator register itself at the OperatorEventDispatcher,1
[FLINK-17028][hbase] Introduce a new HBase connector with new property keysThis closes #12178,5
[FLINK-17674][state] Type OperatorCoordinator state in checkpoints strictly to ByteStreamStateHandleState restore on the master side happens in the JobManager's main thread and must hence not do anypotentially blocking I/O operations.Typing the state to ByteStreamStateHandle makes sure that we can retrieve the data directly without I/Oas a strict contract.If state restoring becomes an asynchronous operation we can relax this restriction.,5
[hotfix][tests] Remove unused temp folder in CheckpointMetadataLoadingTest,5
[FLINK-17670][refactor] Refactor single test in CheckpointMetadataLoadingTest into finer grained tests.,3
"[FLINK-17670][checkpointing] Savepoint handling of ""non-restored"" state also takes OperatorCoordinator state into account.The savepoint restore now also fails when there is unmatched state from an OperatorCoordinator only,and non-restored state is not allowed.",1
[FLINK-17671][tests][refactor] Simplify ManuallyTriggeredScheduledExecutor for better debugability.,0
[FLINK-16177][refactor] Make test setup logic for OperatorCoordinatorSchedulerTest more flexible.,3
[FLINK-17672][scheduler] OperatorCoordinators receive failure notifications on task failure instead of restarts,0
[FLINK-10740][scheduler] Add failure reason to OperatorCoordinator.failTask(...),0
[FLINK-16177][checkpointing] Integrate OperatorCoordinator fully with checkpointing.  - This adds verious tests for OperatorCoordinator checkpointing  - The checkpoint coordinator also restores state to the OperatorCoordinator,1
"[FLINK-16357][checkpointing] Offer different methods for ""global restore"" and ""local restore"" in CheckpointCoordinatorGlobal restores are meant for initial savepoint restores, and for global failover in the scheduler.Global failover in the scheduler happens for example during master failover and as a safety net whenencountering unexpected/inconsistent situations that might impact correctness.Local failovers are all common task failures and recoveries.This commit offers different methods to be called in these two situations, but does not make use of thelocal restore method yet. All calls still go to the global restore, which was the previous behavior inall cases.The difference in the CheckpointCoordinator between local and global restore is currently that OperatorCoordinatorsare only restored during global restores.As a side effect, this change also eliminates the ""failWhenNoCheckpoint"" flag outside of the CheckpointCoordinator.The flag is exclusively used by the ""restoreSavepoint()"" method which is a separate call to the Coordinator anyways.",1
"[FLINK-16357][checkpointing] Only global failure/restores reset the coordinator state.The failure handling results are now flagged with whether the failure was a global failureor a task failure. Based on that, the Scheduler invokes different restore methods on theCheckpointCoordinator.",0
[FLINK-17702][tests][refactor] Refactor test utils to support different failover strategies.,0
"[FLINK-17702][scheduler] Cancellations during failover also notify the OperatorCoordinator as ""failed tasks""This closes #12137",0
[FLINK-7267][connectors/rabbitmq] Allow overriding RMQSource connection,1
[FLINK-7267][connectors/rabbitmq] Allow overriding RMQSink connectionThis closes #12185,1
[hotfix][docs] Fix typos in config option descriptionsThis closes #12191,5
[hotfix][runtime] Remove useless local variable in CompletedCheckpointStoreTest3testAddCheckpointMoreThanMaxRetainedThis closes #12066,3
[hotfix][docs] Fix some ScalaDocs in ExecutionEnvironment.scalaThis closes #12064,2
[FLINK-17582][quickstarts] Update quickstarts to use universal Kafka connectorThis closes #12044,1
[FLINK-17448][sql-parser-hive] Implement alter DDL for Hive dialectThis closes #12108,2
[FLINK-17451][table][hive] Implement view DDLs for Hive dialectThis closes #12029,2
[FLINK-17428][table-planner-blink] supports projection push down on the new DynamicTableSourceThis closes #12145,1
[FLINK-17772][python] Fix to_pandas to make it work in JDK 11This closes #12198.,1
[FLINK-16966][metrics][infuxdb] Add InfluxDBReporterFactory,5
[FLINK-17449][sql-parser-hive] Implement ADD/DROP partitionsThis closes #12195,4
[hotfix][table-common] Add validateExcept() to FactoryUtil,5
"[hotfix][kafka] Make FlinkKafkaConsumerBase#setStartFromTimestamp to be publicAll the Kafka versions are 0.10+ now, all the implementations have a publicsetStartFromTimestamp(). We don't need to keep this method protected in the base class.So that Kafka table source can call this method in kafka-base.",1
[FLINK-17026][kafka] Introduce a new Kafka connect or with new property keysThis close #12150,5
[FLINK-17757][avro] Implement format factory for Avro serialization and deserialization schema of RowData typeThis closes #12190,5
[FLINK-17735][streaming] Add an iterator to collect sink results through coordination rest api This closes #12073,1
[FLINK-17027] Introduce a new Elasticsearch 7 connector with new property keys,5
[FLINK-17027] Introduce a new Elasticsearch 6 connector with new property keysThis closes #12184,5
[FLINK-17764][Examples] Update tips about the default planner to blink when the planner parameter value is not recognizedThis closes #12194.,2
[hotfix] Add setupFlinkConfig to KubernetesTestBase to make sure flinkConfig is always setup before used,1
[hotfix] Fix the access modifiers in WorkerSpecContainerResourceAdapter,1
[hotfix] Refactor the setup function of KubernetesTestBase,3
[hotfix] Extract PluginManager interface,4
[FLINK-17407] Introduce ExternalResourceDriver and ExternalResourceInfo interface.,5
[FLINK-17407] Introduce config options for external resource framework,1
[FLINK-17407] Add utility class for external resource framework,1
[FLINK-17407] Forward extended resource request to YARN.,2
[FLINK-17407] Forward extended resource request to Kubernetes.,2
[FLINK-17407] Instatiate and pass ExternalResourceInfoProvider to RuntimeContext,1
[FLINK-17407] Get the information of external resource from FunctionContextThis closes #11854.,1
[FLINK-17649][table-planner-blink] Fix hash aggregate NPEGenerated hash aggregate code may produce NPE in some cases existing an aggregate call with Filter.This closes #12119,0
"[FLINK-17593][fs-connector] Support arbitrary recovery mechanism for PartFileWriterThis change includes two things:1. Make the PartFileWriter generic and decouple the PartFileWriter and RecoverableStream. According to different pre-commit / commit methods,this change allows us to extend different types of PartFileWriter.2. Make the Bucket/Buckets depends on the PartFileFactory instead of RecoverableWriter.This closes #12132",2
[FLINK-17594][fs-connector] Support Hadoop path-based part-file writerThis closes #12134,2
[FLINK-14255][hive] Integrate hive to streaming file sinkThis closes #12168,2
[hotfix][tests] Reformat default flink configuration map,5
[hotfix][tests] Add missing space to help text,1
[hotfix][tests] Add option -m PEM to ssh-keygenMake ssh-keygen output private key in PEM format so that Jsch does notcomplain about wrong private key format.,0
"[FLINK-17522][tests] Add details on how to run Jepsen testsDocument command line options for the 'lein run test' command.In the Docker section, add that DataStreamAllroundTestProgram must bebuilt first.Add details about types/roles of nodes and minimum number of nodesrequired.This closes #12019.",1
[FLINK-15758][MemManager] Remove KeyedBudgetManager and use AtomicLong,1
[FLINK-15758][MemManager] Remove MemoryManager#AllocationRequest,4
"[FLINK-15758][MemManager] Release segment and its unsafe memory in GC CleanerAfter #9747, managed memory is allocated from UNSAFE, not as direct nio buffers as before 1.10.The releasing of segments released also underlying unsafe memory which is dangerous in generalas there can be still references to java objects giving access to the released memory. If this referenceever leaks, the illegal memory access can result in memory corruption of other code parts w/o even segmentation fault.The solution can be similar to how Java handles direct memory limit:- underlying byte buffers of segments are registered to phantom reference queue with a Java GC cleaner which releases the unsafe memory- all allocations and reservations are managed by a memory limit and an atomic available memory- if available memory is not enough while reserving, the phantom reference queue processing is triggered to run hopefully discovered by GC cleaners- memory can be released directly or in a GC cleanerThe GC is also sped up by nulling out byte buffer reference in `HybridMemorySegment#free` which is inaccessible anyways after freeing.Otherwise also a lot of tests, which hold accidental references to memory segments, have to be fixed to not hold them.The `MemoryManager#verifyEmpty` checks that everything can be GC'ed at the end of the tests andafter slot closing in production to detect memory leaks if any other references are held, e.g. from `HybridMemorySegment#wrap`.This closes #11109.",3
[hotfix] remove IntelliJ '//noinspection ...' directives from MemoryManager,4
"Revert ""[FLINK-14255][hive] Integrate hive to streaming file sink""This reverts commit 547c168a8978a80072187a80d84d53d6e7f02260.I'm reverting these three related commits because it is important tohave confidence in our testing and to clearly separate the addition ofthe Bucket State upgrade test from changing the serializer.",4
"Revert ""[FLINK-17594][fs-connector] Support Hadoop path-based part-file writer""This reverts commit f850ec78b1554989f39053569ea821b19a2adc34.I'm reverting these three related commits because it is important tohave confidence in our testing and to clearly separate the addition ofthe Bucket State upgrade test from changing the serializer.",4
"Revert ""[FLINK-17593][fs-connector] Support arbitrary recovery mechanism for PartFileWriter""This reverts commit 339f5d84d0b7e9fe64534ea4e2adf7e35dee8398.I'm reverting these three related commits because it is important tohave confidence in our testing and to clearly separate the addition ofthe Bucket State upgrade test from changing the serializer.",4
[FLINK-17593] Turn BucketStateSerializerTest into an upgrade testWe need this for future changes to the serialization format.,4
[FLINK-17656][tests] Migrate docker e2e tests to flink-docker,2
[hotfix][docker] Prevent docker-compose cachingThe caching is overly aggressive and potentially even ignores changes to the .yml files.,2
[FLINK-17163][docker] Remove flink-contrib/docker-flink,2
[FLINK-17165][docker] Remove flink-container/docker,2
[FLINK-17740][docker] Remove flink-container/kubernetes,2
[FLINK-17408] Introduce GPUDriver and discovery scriptThis closes #11920.,2
[FLINK-15102][datastream/api] Add continuousSource() methods to the StreamExecutionEvironment.The patch also adds a new SourceEventType of NoMoreSplitsEvent to allow the SourceReaderBase to exit after all the work is done.,1
"Revert ""[FLINK-17593] Turn BucketStateSerializerTest into an upgrade test""This reverts commit 0341b4a8c5d45d0860e1a4671accf7772d515991.The test doesn't work because it has hard-coded paths to the localmachine where the test snapshot data was created in the snapshots.",1
[FLINK-17386][Security] fix LinkageError not captured during security context initialization.This closes #11936.,5
[FLINK-14255][hive] Integrate hive with parquet and orc format to streaming file sinkThis closes #12206,2
[FLINK-16999][table] Enable new data structure converters for connectors,5
[hotfix][table-planner-blink] Planner should pass query's changelog mode to DynamicTableSink#getChangelogMode,4
[FLINK-17029][jdbc] Introduce a new JDBC connector with new property keysThis closes #12176,5
[FLINK-17658] Add new TimestampAssigner and WatermarkGenerator interfaces,4
[FLINK-17658] Don't mention ingestion time in new TimestampAssignerWe don't want to necessarily treat this as an extra thing in the future.It really is just event-time with a special timestamp assigner.,4
[FLINK-17658] Rename DefaultTimestampAssigner to RecordTimestampAssigner,4
[FLINK-17659] Add common watermark strategies and WatermarkStrategies helper,1
[FLINK-17661] Add APIs for using new WatermarkStrategy/WatermarkGeneratorThis adds a method in DataStream as well as a new operator that doeswatermarks using a WatermarkStrategy.,1
[FLINK-17661] Add WatermarkMatchersThis might seem overkill now but it can become useful for future tests.,3
[FLINK-17661] Add test for new TimestampsAndWatermarksOperator,1
[FLINK-17661] Deprecate old Watermark Assigner APIWe add adapters for the old AssignerWithPeriodicWatermarks andAssignerWithPunctuatedWatermarks and use the newly introduced operator.,1
"[FLINK-17659] Rework WatermarkStrategy, add Suppliers for TimestampAssigner/WatermarkGeneratorWe add Suppliers for both TimestampAssigner and WatermarkGenerator toallow them to not be Serializable and add API methods for using them inWatermarkStrategies.This makes the WatermarkStrategy the one-stop thing when it comes totimestamps/watermarks. This makes it possible, for example, to easilygenerate code from the Table API.The WatermarkStrategy has a default RecordTimestampAssigner, which meansthat in most cases users don't need to specify a TimestampAssigner butwill use the timestamps provided by the source. Only aWatermarkGenerator is required in most cases.We also will use this for compatibility with the oldassigners/extractors in the KafkaConsumer. In the old model, bothtimestamp assigner and watermark extractor where in one and the sameobject and extracting a timestamp updates the state of the assigner. TheKafkaConsumer will de-serialize a new extractor for each partition,meaning we have to keep the new-model assigner and wm generator in oneand the same object. (The wrapping WatermarkStrategy for the oldassigners returns the same object for both TimestampAssigner andWatermarkGenerator)",4
[FLINK-17661] Add Scala API for using new WatermarkStrategy/WatermarkGenerator,1
[FLINK-17669] Add WatermarkOutputMultiplexerThis can be used in source implementations (or anywhere else really)that need to multiplex watermark updates from multiple partitions/splitsinto one single (network) watermark output.,1
[minor] Fix warnings in AbstractFetcher(Test),3
[FLINK-17669] Use new WatermarkGenerator for per-partition watermarking in KafkaConsumer,1
"[FLINK-17766] Use checkpoint lock instead of fine-grained locking in Kafka AbstractFetcherBefore, we were locking on the partition state object itself to preventconcurrent access (and to make sure that changes are visible acrossthreads). However, after recent changes we hold the checkpoint lock foremitting the whole ""bundle"" of records from Kafka. We can now also justuse the checkpoint lock in the periodic emitter callback and then don'tneed the fine-grained locking on the state for record emission.",1
[FLINK-17166][dist] Add file appender for flink-console.sh,2
[hotfix][docs] Fix broken link,2
[FLINK-17768][network] Disable UnalignedCheckpointITCase,2
"[FLINK-15670][core] Provide a utility function to flatten a recursive {@link Properties} to a first level property HashTableIn some cases, {@code KafkaProducer#propsToMap} for example, Properties is used purely as a HashTable without considering its default properties.",1
"[FLINK-15670][connector] Adds the producer for KafkaShuffle.KafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
"[FLINK-15670][connector] Kafka Shuffle Consumer PartKafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
"[FLINK-15670][connector] Kafka Shuffle API PartKafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
"[FLINK-15670] Kafka Shuffle Test Case + add log4j2 fileKafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
[FLINK-17692] Keep yarn.classpath in target folder to not pollute local builds,1
[FLINK-16160][table-planner-blink] Fix proctime()/rowtime() doesn't work for TableEnvironment.connect().createTemporaryTable()This closes #11837,1
[hotfix] Show hostname in error messageThis closes #11987.,1
Revert [FLINK-15670]This reverts commit 78b7c71d83d631c689fa5a3bace9fb40fb669f52 ff1695d92869fa4103d7d93828e048fa3fbf5a03 9fd02fe24d1ad68693f7f88f58929369f8b8022b e929c3c5fa631f9b35c73fd8e1e0db1f5a70b6df 03f5d54b99d5178f9268616a3ebf6cc30a403eda,5
[FLINK-17791][table][streaming] Support collecting query results under all execution and network environmentsThis closes #12202,1
[hotfix] Remove raw class usages in Configuration.,5
[FLINK-17715][sql-client] Align function DDL support with TableEnvironment in SQL clientThis closes #12171,1
[FLINK-17618][dist] Update comment on how to change log level for Flink,2
[FLINK-17602][docs] Corrected method name in dev/stream/broadcast_state document,2
"[FLINK-17681] Correct type when converting Row, Map, Array to RexNodesThis commit fixes the expression type when converting from aCallExpession to RexNode for Row, Map, Array constructors.It also adds support for LegacyTypeInformationType in FlinkTypeFactoryas it might end up there from the type inference.Lastly it makes the Row, Map, Array ctors return not null type, as thectors can not produce a null.This closes #12149",1
[FLINK-17617] Fix SQL Client autocompleteCloses #12084,0
[FLINK-17758][runtime] Remove unused AdaptedRestartPipelinedRegionStrategyNG,1
[FLINK-17759][runtime] Remove unused RestartIndividualStrategy,1
[FLINK-17357][table-planner-blink] add DROP catalog DDLThis closes #12197,2
Update version to 1.12-SNAPSHOT,5
"[FLINK-15670][core] Provide a utility function to flatten a recursive Properties to a first level property HashTableIn some cases, KafkaProducer#propsToMap for example, Properties is used purely as a HashTable without considering its default properties.",1
"[FLINK-15670][connector] Adds the producer for KafkaShuffle.KafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
"[FLINK-15670][connector] Adds the consumer for KafkaShuffle.KafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
"[FLINK-15670][connector] Kafka Shuffle API PartKafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
"[FLINK-15670] Kafka Shuffle Test Case + add log4j2 fileKafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
[FLINK-17543][Azure] Add timestamp to log name to allow multiple uploads per module,1
"[hotfix][Azure] Use 'ubuntu-16.04' for all AZP buildsAll builds except private-hosted ""test"" (not ""compile"")-stage jobs were already running on ""ubuntu-16.04"".Now everything runs on ubuntu-16.04.",1
[FLINK-17730][CI] Increase 'no output timeout' to 15 minutes,1
"[FLINK-17792][tests] Catch and log exception if jstack failsjstack can fail if the JVM process that we want to sample exits while orbefore we invoke jstack. Since a JVM process is free to exit at anytime, we should not propagate the exception so that we do not fail thetest prematurely.",3
[minor] Allow relative paths in LocalFileSystem,5
[FLINK-17593][Connectors/FileSystem] Turn BucketStateSerializerTest into an upgrade test,3
"[FLINK-17593][Connectors/FileSystem] Support arbitrary recovery mechanism for PartFileWriterThis change includes two things:1. Make the PartFileWriter generic and decouple the PartFileWriter andRecoverableStream. According to different pre-commit / commit methods,this change allows us to extend different types of PartFileWriter.2. Make the Bucket/Buckets depends on the PartFileFactory instead ofRecoverableWriter.",2
[FLINK-17593] Update BucketStateSerializerTest for v2,3
[FLINK-17777][tests] Set HADOOP_CLASSPATH for Mesos TaskManagersThis closes #12204.,1
[hotfix][client] Make ConfigUtils.decodeListFromConfig return new array list and throw exception,1
[FLINK-17796] Respect user specified classpath for application modeThis closes #12222.,1
[FLINK-17687][tests] Enable listing files recursively by pattern,2
[FLINK-17687][tests] Collect log files before tearing down Mesos,2
[FLINK-17687][tests] Simplify collection of Mesos logsThis closes #12203.,2
[hotfix][state-processor-api] Remove BoundedStreamConfig,5
[FLINK-17506][state-processor-api] SavepointEnvironment should honour 'io.tmp.dirs' property,5
"[FLINK-17781][coordination] Use Scheduler and MainThreadExecutor in OperatorCoordinator.Context.This needs (unfortunately) a switch to lazy initialization of the context:  - The Scheduler needs to be created before the OperatorCoordinator Context are created.    One could do that by creating the Coordinators lazily after the Scheduler.  - The Scheduler restores the savepoints as part of the scheduler creation, when the ExecutionGraph    and the CheckpointCoordinator are created early in the constructor.  - That means the OperatorCoordinator needs to exist (or an in placeholder component, here the    OperatorCoordinatorHolder) needs to exist to accept the restored state.That brings us to a cyclic dependency:  - OperatorCoordinator (context) needs Scheduler and MainThreadExecutor  - Scheduler and MainThreadExecutor need constructed ExecutionGraph  - ExecutionGraph needs CheckpointCoordinator  - CheckpointCoordinator needs OperatorCoordinatorBreaking the CycleTo break this cyclic dependency, this change introduces a form of lazy initialization:  - We eagerly create the OperatorCoordinators so they exist for state restore  - We provide an uninitialized context to them  . When the Scheduler is started (after leadership is granted) we initialize the   context with the (then readily constructed) Scheduler and MainThreadExecutorThis closes #12225",5
"[FLINK-17799][network] Fix performance regression in the benchmarksFLINK-16536 (re) introduced requestPartitions on critical path of AbstractRecordReader, whichamounts to couple of viritual calls, one lock acquisition and one volatile read. This overheadis what's cuasing performance drop.We can avoid subsequentional redundant calls, by checking against a local variable if we havealready requested partitions or not.",4
[FLINK-17506][state-processor-api] Use proper RocksDB configurations in KeyedStateInputFormat,5
[FLINK-16998][core] Add a changeflag to RowPartial commit for supporting a changeflag without backwards compatibility.This closes #12103.,4
[FLINK-15813][runtime] Set default value of config jobmanager.execution.failover-strategy to region,0
[FLINK-17594][filesystem] Support Hadoop path-based part-file writerThis closes #12224,2
[FLINK-14255][hive] Integrate mapred record writer to hive streaming sinkThis closes #12220,2
[FLINK-16094][docs-zh] Translate /dev/table/functions/udfs.zh.md into ChineseThis closes #11191,1
"[FLINK-16076][docs-zh] Translate ""Queryable State"" page into ChineseThis closes #12139.",1
[FLINK-17786][sql-client] Fix can not switch dialect in SQL CLIRemove dialect from ExecutionEntryThis closes #12217,1
[FLINK-17790][kafka] Fix JDK 11 compile error,0
[FLINK-17353][docs] Fix Broken links in Flink docs masterThis closes #12196,2
[docs-sync] Synchronize the latest documentation changes into Chinese documents,2
[FLINK-17027][hotfix] Rename back-off infix to backoff in new Elasticsearch properties,1
[FLINK-17626][fs-connector] Fs connector should use FLIP-122 format options styleThis closes #12212,1
[FLINK-17728] [sql-client] sql client supports parser statements via sql parserThis closes #12188,1
"[FLINK-17520] [core] Extend CompositeTypeSerializerSnapshot to allow migration based on outer snapshotThis commit deprecates isOuterSnapshotCompatible, which only allowssignaling if the outer config is either compatible or not compatible, infavor of a new resolveOuterSchemaCompatibility method which additionallyallows the user to signal migration.The change is backwards compatible, and allows subclasses that stillonly implement isOuterSnapshotCompatible to work as is.",1
"[FLINK-17520] [test] Simplify CompositeTypeSerializerSnapshotTestThe unit tests in CompositeTypeSerializerSnapshotTest were previouslyover-engineered w.r.t. how to mock the result of a compatibility check.It was doing string equals checks, whereas it is simple enough to justlet the new serializer wrap a mock compat result and just return thatfor the compatibility checks.",1
[FLINK-17520] [test] Add test case for outer snapshot requiring migration,1
[FLINK-17520] [core] Rework all implementations of CompositeTypeSerializerSnapshot#resolveOuterSchemaCompatibility,0
[FLINK-17520] [doc] Use new resolveOuterSchemaCompatibility in custom serialization docsThis closes #12209.,2
[FLINK-17527][flink-dist] Rename yarn log4j/logback configuration files so that they could be reused,1
[FLINK-17527][flink-dist] Make kubernetes-session.sh use session log4j/logback configuration filesThis closes #12236.,2
[FLINK-17619] Disable commit on checkpoints if no group.id was specified for Kafka table sourceCloses #12117,2
[hotfix] Disable e2e execution in PRs,0
"[FLINK-16383][task] Do not relay notifyCheckpointComplete to closed operators.Through StreamOperatorWrapper an operator may already be closed while the StreamTask is still running. Notification might be relayed in that time from the task to the closed operator causing issues on operators reacting on completed checkpoints, such as two phase commit sinks.This commit adds the information of the closing to the wrapper and avoids relaying notifications to closed operators.Also fixes a potential related issue in SubtaskCheckpointCoordinatorImpl#takeSnapshotSync.",0
[FLINK-16970][dist] Bundle JMXReporter separately from dist jar,2
[FLINK-17634][rest] Reject multiple registration for the same endpoint,2
[FLINK-17547][task][hotfix] Improve error handling1 catch one more invalid input in DataOutputSerializer.write2 more informative error messages,0
"[FLINK-17547][task][hotfix] Extract NonSpanningWrapper fromSpillingAdaptiveSpanningRecordDeserializer (static inner class)As it is, no logical changes.",4
"[FLINK-17547][task][hotfix] Extract SpanningWrapperfrom SpillingAdaptiveSpanningRecordDeserializer (static inner class).As it is, no logical changes.",4
[FLINK-17547][task][hotfix] Fix compiler warnings in NonSpanningWrapper,2
[FLINK-17547][task][hotfix] Extract methods from RecordsDeserializer,4
[FLINK-17547][task] Use iterator for unconsumed buffers.Motivation: support spilled recordsChanges:1. change SpillingAdaptiveSpanningRecordDeserializer.getUnconsumedBuffersignature2. adapt channel state persistence to new typesNo changes in existing logic.,2
[FLINK-17547][task][hotfix] Extract RefCountedFileWithStream from RefCountedFileMotivation: use RefCountedFile for reading as well.,2
[FLINK-17547][task][hotfix] Move RefCountedFile to flink-coreto use it in SpanningWrapper,1
[FLINK-17547][task] Implement getUnconsumedSegment for spilled buffers,1
[FLINK-17763][dist] Properly handle log properties and spaces in scala-shell.sh,2
[FLINK-17809][dist] Quote classpath and FLINK_CONF_DIR,5
[FLINK-17361] Add custom query on JDBC tables,5
"[FLINK-17361] Refactor JdbcTableSourceITCase to use TableResult instead of StreamITCaseUsing the static sink approach of StreamITCase is potentiallyproblematic with concurrency, plus the code is just plain nicer likethis.",0
[FLINK-17810][doc] Add document for K8s application modeThis closes #12245,2
[FLINK-12030][connector/kafka] Check the topic existence after topic creation using KafkaConsumer.,1
[hotfix][table] Improve testing implementation for the new projection push down,1
[FLINK-17797][connector/hbase] Align the behavior between the new and legacy HBase table sourceThis closes #12221,1
[FLINK-17798][connector/jdbc] Align the behavior between the new and legacy JDBC table sourceThis closes #12221,5
"Revert ""[hotfix] Disable e2e execution in PRs""This reverts commit 11644c57a48d3589afb56edbbe7ae98df7394f80.",5
[hotfix][table] Reduce friction around logical type roots,2
[hotfix][table] Update FLIP-65 functions to new data structure converters,5
[hotfix][table-planner-blink] Fix exception for invalid function signature,1
[FLINK-17541][table] Support inline structured typesThis enables inline structured types in the Blink planner. Inlinestructured types are extracted (e.g. in UDFs) and don't need to beregistered in a catalog. This finalizes FLIP-65 for scalar andtable functions because existing functions can be migrated with areplacement to the new type system.Structured type support should still be declared as experimentaluntil we have more tests and can also deal with structured typesin sources and sinks.This closes #12228.,3
[FLINK-8871][checkpoint] Support to cancel checkpoing via notification on task side,1
[FLINK-8871][checkpoint] Support to cancel checkpoing via notification on checkpoint coordinator side,1
[FLINK-8871][checkpoint][tests] Add ITcase for NotifiCheckpointAborted mechanism,1
"[FLINK-17725][tests] Disable OkHttpClient timeouts for FileUploadHandlerTestIn order to harden the test case FileUploadHandlerTest, this commit disables the timeoutsof the used OkHttpClient.This closes #12248.",1
[FLINK-16611][metrics][datadog] Send report in chunks,5
[FLINK-17622][connectors/jdbc] Remove useless switch for decimal in PostgresCatalogThis closes #12090,2
[FLINK-15947] Fix table implicit conversions structure,0
[FLINK-15947] Update docs with updated package structure.This closes #12232,5
"[FLINK-17780][checkpointing] Add task name to log statements of ChannelStateWriter.Add task name to the executor thread and to all method of ChannelStateWriter (as they can be called from any other thread), such that log statements can be connected to the respective task.",2
[FLINK-16922][table-common] Fix DecimalData.toUnscaledBytes() should be consistent with BigDecimla.unscaledValue.toByteArray()This closes #12265,5
[FLINK-17356][jdbc][postgres] Support PK and Unique constraintsThis closes #11906,1
[hotfix][table-planner-blink] Fix code generation error for CAST STRING to BYTES,0
[FLINK-17356][jdbc][postgres] Add IT cases for inserting group by query into posgres catalog table,2
"[FLINK-17846][table, e2e] Fix import in flink-walkthrough-table-scala",2
[FLINK-17675][docs] Update jquery dependency to 3.5.1This closes #12229,5
[hotfix][core] Add constant serialVersionUIDs to all serializable source API classes,1
[hotfix][core] Add/remove missing/incorrect serialVersionUID fields in Timestamp Assigner classes,4
[hotfix][docs] Fix comment about RocksDB timer default,5
[hotfix] Fix directory creation in TypeSerializerUpgradeTestBase,3
"[FLINK-13632] In TypeSerializerUpgradeTestBase.UpgradeVerifier return matcher instead of dataBefore, the test was using equals() to compare the expected data to the actual data. This does not work for types that don't have a proper equals() implementation. Now we return matchers and tests that use such types can return an appropriate matcher. Most tests can use the is() matcher, if the test data class has a proper equals() method.",5
[FLINK-13632] Port RowSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[hotfix][core] Fix warnings in TypeSerializerUpgradeTestBase,3
[hotfix][core] Fix migration version comparision for 1.10,0
[hotfix][core] Add open interval in MigrationVersion,1
[hotfix][core] Fix TypeSerializerUpgradeTestBase for serializer migration,3
[FLINK-16998][core] Support backwards compatibility for upgraded RowSerializer,1
"Revert ""[FLINK-17356][jdbc][postgres] Add IT cases for inserting group by query into posgres catalog table""This reverts commit 38ada4ad5ece2d28707e9403278133d8e5790ec0.",4
[FLINK-17645][runtime] Reset SafetyNetCloseableRegistry#REAPER_THREAD if it fails to start,0
[FLINK-17817][streaming] Fix type serializer duplication in CollectSinkFunctionThis closes #12272,1
[FLINK-17474][parquet][hive] Parquet reader should be case insensitive for hiveThis closes #12241,2
[FLINK-16074][docs-zh] Translate the Overview page for State & Fault Tolerance into ChineseThis closes #12096.,1
[FLINK-17356][jdbc][postgres] Add IT cases for inserting group by query into posgres catalog tableThis closes #12273,2
"[FLINK-17794][tests] Tear down installed software in reverse orderTear down installed software in reverse order in Jepsen tests. Thismitigates the issue that sometimes YARN's NodeManager directories cannotbe removed using 'rm -rf' because Flink processes keep running andgenerate files after the YARN NodeManager is shut down. rm -r removesfiles recursively but if files are created in the backgroundconcurrently, the command can still fail with a non-zero exit code.This closes #12249.",0
"[FLINK-17842][network] Fix performance regression in SpanningWrapper#clearFor some reason the following commit:54155744bd [FLINK-17547][task] Use RefCountedFile in SpanningWrappercaused a performance regression in various benchmarks. It's hard to tell whyas none of the benchmarks are using spill files (records are too small), soour best guess is that combination of AtomicInteger inside RefCountedFileplus NullPointerException handling messed up with JIT ability to get ridof the memory barrier (from AtomicInteger) on the hot path.",1
Merge pull request #12244 from pnowojski/f17258[FLINK-17258][network] Fix couple of ITCases that were failing with enabled unaligned checkpoints,0
"Revert ""Merge pull request #12244 from pnowojski/f17258""This reverts commit 463dc8b9cab99d6d5df07ec0e593843885e3ac72.",4
[FLINK-17258][network][test] Run ClassLoaderITCase#testDisposeSavepointWithCustomKvState without unaligned checkpointsThis test needs many concurent checkpoint & savepoints and this is currently not supported with unaligned checkpoints.,1
[FLINK-17258][sql][test] Fix AggregateITCase.testPruneUselessAggCall missing sortedThe result of this query doesn't guarantee any ordering. This brakes with enabled unaligned checkpoints.,0
[FLINK-17258][hotfix][network] Unify checkpoint id logging with CheckpointCoordinator,2
[FLINK-17805][hotfix][network] Fix/update/rename InputProcessorUtil.createCheckpointedInputGatePair method,1
[FLINK-17805][network] Fix ArrayIndexOutOfBound for rotated input gate indexesIt's possible that indexes of passed InputGates are not monotonic - that leftinput has higher input gate index. This commit fixes an ArrayIndexOutOfBound causedby this.,5
[FLINK-17771][python][e2e] Fix the OOM of the PyFlink end to end test on JDK11.This closes #12279.,3
[FLINK-17504][docs] Update Chinese translation of Getting Started / OverviewThis closes #12230,1
[FLINK-16911] Increase timeout in S3 ITCasesThe deadline is shared for all tests and it was probably to low.,3
[FLINK-17866][core][python] Change the implementation of the LocalFileSystem#pathToFile to fix the test case failure of PyFlink when running on Windows.This closes #12280.,1
[FLINK-17881][python][docs] Add documentation for PyFlink's Windows supportThis closes #12291.,1
[FLINK-17773] Update documentation for new WatermarkGenerator/WatermarkStrategies,1
[FLINK-17876][python][docs] Add documentation on how to use Python UDF in SQL DDLThis closes #12295.,1
[FLINK-17801][tests] Increase timeout of TaskExecutorTest.testHeartbeatTimeoutWithResourceManagerIncreasing the timeout because on AZP it can happen that calling the disconnectTaskExecutor takesmore than 150 ms. This commit increases the timeout to 10s.This closes #12242.,1
[hotfix][tests] Make ClientTest extend TestLogger,3
[hotfix][qs] Fix logging of exception in RequestWriteListenerLog stacktrace of exception instead of only the message.,2
[FLINK-13553][qs] Add logging to AbstractServerHandlerLog every request on trace level.Log caught exceptions in AsyncRequestTask.,2
[FLINK-13553][tests] Enable TRACE logging for org.apache.flink.queryablestateThis closes #12276.,2
[FLINK-17303][python] Return TableResult for Python TableEnvironmentThis closes #12246.,2
"[FLINK-17854][core] Move InputStatus to flink-coreThat way, the InputStatus can be used by API classes that directly connect with the asynchronousinput paradigm of the streaming runtime.",1
[FLINK-17854][core] Let SourceReader use InputStatus directly,1
[FLINK-17843][table-api] Check the RowKind when converting a Row from object to an expression,2
[FLINK-17004] Document the LIKE clause of CREATE TABLE statement.This closes #12075,1
[FLINK-17905][docs] Fix JDBC docs to remove the duplicate licence and markupThis closes #12305,4
[FLINK-16197][hive] Failed to query partitioned table when partition folder is removedThis closes #11175,4
[FLINK-17878][fs-connector] Transient watermark attribute should be initial at runtime in streaming file operatorsThis closes #12293,1
[FLINK-17651][table-planner-blink] DecomposeGroupingSetsRule generates wrong planwhen there exist distinct agg and simple agg with same filterThis closes #12208,0
[FLINK-17894][table] RowGenerator in datagen connector should be serializableThis closes #12310,5
"Merge pull request #12301 from Xeli/FLINK-16572-logs[FLINK-16572] [pubsub,e2e] Add check to see if adding a timeout to th",1
[FLINK-17822][MemMan] Use private Reference.tryHandlePending|waitForReferenceProcessing to trigger GC cleanerThis closes #12270.,4
[FLINK-16210] Extend the Flink Architecture section with more information about Flink Master components and application execution,2
"[hotfix][filesystems][test] Fix improper usage of System.nanoTime().Per the JavaDoc of System.nanoTime(), we should use `t1 - t0 < 0` rather than `t1 < t0` because of the possibility of numerical overflow.",1
[FLINK-17721][filesystems][test] Use independent timeout for each file status checking.,2
[FLINK-17230] Fix incorrect returned address of Endpoint for external Service of ClusterIP typeThis closes #12277 .,1
[FLINK-17565][k8s] Bump fabric8 version from 4.5.2 to 4.9.2This closes #12215 .,2
[FLINK-17870] Fix ScalaShell executeAsync to ship all dependenciesThis closes #12288.,0
[FLINK-17395][python] (followups) Don't remove the dist directory during clean,4
[FLINK-17189][table-planner] Table with proctime attribute cannot be read from Hive catalogThis closes #12260,2
[FLINK-17889][hive] Hive can not work with filesystem connectorThis closes #12309,5
[FLINK-17896][hive] HiveCatalog can work with new table factory because of is_genericThis closes #12316,1
[FLINK-17867][hive][test] Add hdfs dependency to hive-3.1.1 testThis closes #12318,3
[FLINK-17456][hive][test] Update hive connector tests to execute DDL & DML via TableEnvironmentThis closes #12281,3
[hotfix] Remove generic row for HiveTableFactoryThis closes #12324,4
[FLINK-15620][state][TTL] Remove deprecated enable default background cleanupThis closes #12304.,4
[FLINK-15621][state][TTL] Remove deprecated option and method to disable TTL compaction filterThis closes #12307.,4
[FLINK-17917][yarn] Ignore the external resource with a value of 0 in constructing InternalContainerResourceThis closes #12315.,2
[FLINK-17814][chinese-translation]Translate native kubernetes document to ChineseThis closes #12296,1
[FLINK-17929][docs] Fix invalid liquid expressionsThis closes #12322,0
"[FLINK-17939][docs-zh] Translate ""Python Table API Installation"" page into Chinese This close #12343",2
[FLINK-17802][kafka] Set offset commit only if group id is configured  for new Kafka Table sourceThis closes #12252,1
[hotfix][table-common] Add logical type root/family argument strategies,2
[FLINK-17936][table] Introduce new type inference for ASIntroduces the last missing pieces required to start porting theother expressions for a consistent API behavior.This closes #12331.,1
[FLINK-17375][CI] Rename log4j-travis.properties,2
[FLINK-17375] Move azure_controller into azure-pipelines folder,4
[FLINK-17375] Delete unused files in tools/- tools/qa-check.sh: not in use anymore- tools/merge_flink_pr.py: last commit created with script in 2016- tools/test_deploy_to_maven.sh: trivial,3
[FLINK-17375] Rename tools/travis_watchdog.sh -> tools/ci/ci_controller.sh,2
[FLINK-17375] Refactor travis_watchdog.sh into separate ci/ and azure-pipelines/ scripts.The guiding principle in this refactoring was to put everything generic (independentof concrete CI system (such as Travis or Azure)) into tools/ci/*and the scripts specific to a CI system (currently Azure) into tools/azure-pipelines/*.,5
[FLINK-17375] Adopt nightly python wheels jobs to refactored ci scripts,4
[hotfix][AZP] execute junit test result upload also when the previous stage failedThis closes #12268,0
[FLINK-17076][docs] Revamp Kafka Connector DocumentationThis closes #12257,2
[FLINK-17756][table] Drop table/view shouldn't take effect on each otherThis closes #12314,4
[FLINK-17820][checkpointing] Respect fileSizeThreshold in FsCheckpointStateOutputStream.flush()This closes #12332,2
[hotfix] Correct comment references to flink-yarn-tests,3
[hotfix] Rename org.apache.flink.yarn.util.YarnTestUtils into o.a.f.y.u.TestUtilsRenamed o.a.f.y.u.YarnTestUtils into o.a.f.y.u.TestUtils in order to avoid a naming conflict witho.a.f.y.YarnTestUtils from the flink-yarn module.,2
[FLINK-17938] Move YarnTestBase.findFile and YarnTestBase.RootDirFilenameFilter to o.a.f.y.u.TestUtilsMoving findFile and RootDirFilenameFilter to o.a.f.y.u.TestUtils allows to run the UtilsTest suite withoutrequiring that yarn.classpath has been generated. The latter is required whenever one uses the YarnTestBaseclass because it reads this file when the class is being loaded.This closes #12341.,2
"[FLINK-17750][tests] Harden YARNHighavailabilityITCase by increasing ZK session timeout to 20sIn order to harden YARNHighAvailabilityITCase against ZK session timeouts, the timeout has been increasedfrom 1s to 20s. This increase also increases the runtime of YARNHighAvailabilityITCase.testKillYarnSessionClusterEntrypointslightly.This closes #12347.",3
[FLINK-17934][fs-connector] StreamingFileWriter should set chainingStrategy,5
[FLINK-17934][fs-connector] Add listener to Buckets and remove listener for BucketsBuilder,4
[FLINK-17751][table-planner-blink] Fix proctime defined in ddl can not work with over window in Table apiThis closes #12342,1
[FLINK-17058] Adding ProcessingTimeoutTrigger of nested triggers.,1
"[hotfix][tests] Remove note that E2E exactly-once is not coveredThe statement is not correct because by submitting a self-verifying job thatfails if exactly-once semantics are violated, this aspect can be covered byflink-jepsen.",2
[hotfix][tests] Document flink-jepsen correctness model,2
[FLINK-17925][fs-connector] Fix Filesystem options to default values and typesThis closes #12323,5
[hotfix][runtime] Fix typo.,2
[hotfix] Remove useless FlinkYarnSessionCli#logAndSysout methodThis closes #11908,5
[hotfix] Fix a comment error in StreamExecLocalGroupAggregateThis closes #11728,0
[hotfix][tests][e2e] Delete empty plugin directory after moving jar,4
[FLINK-17812][dist] Bundle reporters in plugins/ directory,2
[FLINK-16694][ci] Limit number of dumped log lines,2
"[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIREDBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,if the failure of checkpointing is detected after checkpoint times out, the failure gets ignored sincethe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theoryunless something else fails.This PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`.",0
"[hotfix][runtime] Annotate ProcessingTimeCallback as a FunctionalInterfaceThe interface is used as such throught the runtime already, but is missing the annotationto guard the SAM nature.",1
"[hotfix][core] Add a constant for the special value ""NO_TIMESTAMP"".",1
[hotfix][DataStream API] Minor code cleanups,4
[FLINK-17898][core] Remove Exceptions from signatures of SourceOutput methods,4
[FLINK-17897][core] Classify FLIP-27 source API to @Experimental / @PublicEvolving,2
[FLINK-17903][core] WatermarkOutputMultiplexer supports String IDs and de-registration of outputs,1
[FLINK-17096][core] Simple performance improvements in WatermarkOutputMultiplexer,1
[FLINK-17904][runtime] Add scheduleWithFixedDelay to ProcessingTimeService,0
"[FLINK-17899][runtime][refactor] Make ProcessingTimeService always available to operators.Previously, it was not always supplied to operators to not create it unless needed.This change puts a lazy factory into the parameters supplied to all operators.",1
[FLINK-17899][core][refactor] Add a utility NoWatermarksGenerator,1
[FLINK-17899][runtime] Integrate FLIP-126 Watermarks with FLIP-27 Sources,2
[FLINK-17899][runtime] Remove unnecessary implementation of SourceContext in SourceOperatorStreamTaskFewer implementations of the interface make de-virtualization of its methods easier.,1
[FLINK-17899][runtime] Add WatermarkStrategies to countinuousSource() methods in the DataStream API,5
[FLINK-17950][Scala DataStream API] Fix StreamExecutionEnvironment.continuousSource(...) method  - Fix return type from Unit to DataStream  - Forward inferred TypeInformation  - Add test,3
[hotfix][core] Improve JavaDocs for FLIP-27 sources.,2
[hotfix] Adjust License Headers for FLIP-27 sources to be same as the remaining code base,5
[FLINK-16021][table-common] Fix DescriptorProperties.putTableSchema does not include PRIMARY KEYThis closes #12275,0
[FLINK-17942][table-planner-blink] Fix WindowOperator not call StateMapView.cleanup when destroying windowsThis closes #12358,4
[FLINK-17284][jdbc][postgres] Fix serial type columns not work in Postgres catalogThis closes #11900,2
"[FLINK-16086][docs-zh] Translate ""Temporal Tables"" page of ""Streaming Concepts"" into ChineseThis closes #11978",1
[FLINK-17689][kafka][table] Add integration tests for changelog source and formats (#12284)This closes #12284,4
[FLINK-17657][jdbc] Fix reading BIGINT UNSIGNED type field not work in JDBCThis closes #12290,5
[FLINK-17861][tests][hotfix] Fix ChannelStateCheckpointWriterTest.testRecordingOffsets1. Set writer position in NetworkBuffer passed to ChannelStateCheckpointWriter.write2. Reduce state size to fit in the configured MemoryCheckpointOutputStream,5
[FLINK-17861][task][checkpointing] Merge channel state serializer and deserializerMotivation:1. add a method that deserializes and then serializes data2. simplify,5
"[FLINK-17861][task][checkpointing] Split channel state handles sent to JMBefore this commit, if Unaligned checkpoints are enabled,channel state is written as state handles. Each channelhas a handle and each such handle references the sameunderlying streamStateHandle (this is done to havea single file per subtask).But, if the state is less then state.backend.fs.memory-threshold,the data is sent directly to JM as a byteStreamHandle.This causes each channel state handle to hold the whole subtask state.This change solves this by extracting relevant potionsof the underlying handles if they are byteStreamHandles.",3
[FLINK-17928][checkpointing] Fix ChannelStateHandle sizeStore state size explicitly because underlying statehandle may be shared.,0
"[FLINK-17375][hotfix] Fix print_stacktraces multiline-behaviorecho $VAR   # does not preserve newlinesecho ""$VAR"" # does print newlines as well",1
[FLINK-17958][core] Fix MathUtils#divideRoundUp bug for handling zero / negative values.This closes #12357.,0
[FLINK-17610][state] Align the behavior of result of internal map state to return empty iteratorThis closes #12078.,2
[FLINK-17988][checkpointing] Discard only unique channel state delegatesThe underlying state handles of channel state handles can be the same.Discard should only iterate over unique underlying handles.,0
[FLINK-17986] Fix check in FsCheckpointStateOutputStream.write,0
[hotfix][tests] Remove unused TestingScheduledExecutor,3
[hotfix][tests] Shutdown TaskmanagerServices,3
[FLINK-17558][runtime] Add Executors#newCachedThreadPool,1
[FLINK-17558][tests] Simplify partition tracker setup,1
[FLINK-17558][tests] Extract ShuffleEnvironment/PartitionTracker setup,1
[FLINK-17558][netty] Release partitions asynchronously,2
[FLINK-13632] Remove old PojoSerializerSnapshotMigrationTest,3
[FLINK-17956] Add Flink 1.11 MigrationVersion,2
"[FLINK-13632] Update TypeSerializerUpgradeTestBase for Flink 1.11We change MIGRATION_VERSIONS to only test versions > 1.11 because that'swhen we're adding the tests. We make an exception forPojoSerializerUpgradeTest and RowSerializerUpgradeTest, for which wehave earlier snapshots.This also changes the test base to only generate snapshots for theCURRENT_VERSION when we generateTestSetupFiles().",3
[FLINK-13632] Add Flink 1.11 snapshots for TypeSerializer upgrade testsTheses snapshots were created on the release-1.11 branch by un-@IgnoringTypeSerializerUpgradeTestBase.generateTestSetupFiles() and running testson each subclass individually.,3
[FLINK-13632] Port AvroSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port TtlSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port TupleSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port BufferEntrySerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ValueSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port PrimitiveArraySerializer test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port TimerSerializer test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port StreamElementSerializer test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port BaseTypeSerializer test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port VoidNamespaceSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port NullableSerializer test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ScalaOptionSerializer test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port KryoSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port NFASerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ScalaTrySerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port MapViewSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port WindowSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port UnionSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port TwoPhaseCommitSinkStateSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port KafkaSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ValueArraySerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port MapSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port CompositeSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ListSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ArrayListSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port CopyableSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port WritableSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ScalaEitherSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port LongValueWithProperHashCodeSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port Kafka011Serializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ListViewSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port JavaSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port LockableTypeSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port EnumSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port ScalaCaseClassSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port EnumValueSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Port TraversableSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-13632] Remove TypeSerializerSnapshotMigrationTestBaseAll tests have been ported to the new test base.,3
[FLINK-17882][table-common] Check for self references in structured typesThis closes #12294.,2
[hotfix][e2e] Increase 'no activity' timeout to 15 minutes,1
[FLINK-17824][e2e] Introduce timeout to 'resume savepoint' testThis closes #12350,3
[FLINK-17865][checkpoint] Increase default size of 'state.backend.fs.memory-threshold'This closes #12282.,1
"[FLINK-17463][tests] Avoid concurrent directory creation and deletionBlobCacheCleanupTest#testPermanentBlobCleanup() tests that job relatedfiles are cleaned up by a background task when the job is released fromthe PermanentBlobCache. The tests asserts that the uploaded blobs aredeleted from the filesystem. Because the scheduling of the backgroundtask cannot be controlled from outside the cache, the test polls thefilesystem. More precisely, the test uses BlobUtils#getStorageLocation()to build the path on the filesystem given a blobkey and tests theexistence of that path in regular intervals. As a side effect, however,BlobUtils#getStorageLocation() also creates all necessary directories tothat path if they do not exist yet. This leads to a situation wheredirectories and concurrently deleted and created, which can causeFileAlreadyExists exceptions. This commit fixes the issue.Note that the above applies to all tests that invokeBlobServerCleanupTest#checkFilesExist().This closes #12376.",3
[FLINK-17819][yarn] Fix error msg for yarn deployments when hadoop not in classpathThis closes #12317.,0
"[FLINK-17880][table] Use new inference for table/scalar function in catalogsThis updates catalog related operations (e.g. function DDL, SQL Client) tothe new type inference for scalar and table functions. Hive functions andlegacy planner still work with the old inference. With this commit we cantell an easier story about how to implement functions, because all mainentrypoints support the new inference.This closes #12336.",5
[FLINK-13782] Implement input type inference for logical functionsThis PR implements input type strategy for functions:EQUALS/NOT EQUALS/GREATER/GREATER EQUAL/LESS/LESS EQUAL,1
[FLINK-13782] Implement output type strategy for logical functionsThis PR implements input type strategy for functions:EQUALS/NOT EQUALS/GREATER/GREATER EQUAL/LESS/LESS EQUALThis closes #12377,1
[FLINK-13782] Implement type inference for more logical expressionsImplemented input & output type inference for:AND/OR/NOT/IS NULL/IS NOT NULL/IS TRUE/IS FALSE/IS NOT TRUE/IS NOTFALSE/BETWEEN/NOT BETWEENThis closes #12387,5
[FLINK-17744] Make (Stream)ContextEnvironment#execute call JobListener#onJobExecutedThis closes #12339.,1
[FLINK-17946][python] Fix the bug that the config option 'pipeline.jars' doesn't work.This closes #12372.,1
[FLINK-11523] Use OutputTag.typeInfo in harnessAbstractStreamOperatorTestHarness side output uses TypeSerializer returnedby `outputTag.getTypeInfo().createSerializer(executionConfig)`.This closes #11695,5
[FLINK-17844][build] Add tooling for updating japicmp configuration,5
[FLINK-17990][python] Fix the test of ArrowSourceFunctionTestBase.testParallelProcessing to use synchronized listThis closes #12404.,1
"[FLINK-16144] get client.timeout for the client, with a fallback to the akka.client.timeout.This closes #12179.",1
[FLINK-17952][python] Fix the bug that exception was thrown when creating BatchTableEnvironment via EnvironmentSettings with old planner.This closes #12400.,1
[FLINK-17842][network] Remove NextRecordResponse to improve deserialisation performanceThis removes NextRecordResponse and inlines NonSpanningWrapper#getNextRecord tofix second performance regression that happened on May 19th. This second regressionis visible as a difference between results from Mat 19th (before regression)and May 22nd - 29th (period after fixing the first performance regression):http://codespeed.dak8s.net:8000/timeline/?ben=networkBroadcastThroughput&env=2It was introduced by the following commit:[824100e1460dd2f78f689da72bc5d7b0c9dcbbde] [FLINK-17547][task][hotfix] Extract methods from RecordsDeserializernetworkBroadcastThroughput benchmark results are restored from ~1000 to ~1100 ops/ms on the Hetzner worker.,1
[hotfix][runtime] Fox log message for web.log.file to only pring config key and not deprecated keys,5
[hotfix][checkpointing] Beautify stack trace by stripping wrapping CompletionExceptions,0
[hotfix][checkpointing] Improve exception in case Coordinator State ack fails,0
[FLINK-16986][coordination] (part 1) Provide exactly-once guarantees around checkpoints and operator event sending.This closes #12234,1
[FLINK-16986][coordination][refactor] Reduce dependencies of OperatorCoordinatorHolder and OperatorCoordinatorCheckpointContextThis simplifies both testing and future refactoring.,4
[FLINK-16986][coordination][refactor] Change executor in OperatorCoordinatorSchedulerTestThis prepares the test to be ready to run with proper main-thread-execution in theOperatorCoordinators.,1
[FLINK-16986][coordination] (part 2) Make OperatorCoordinatorHolder driven by main thread executor,1
"[FLINK-16986][coordination] (part 3) Change OperatorCoordinator interface to support better exactly-once semanticsThe semantics are defined as follows:  - The OperatorCoordinator implementation must have a way of strictly ordering the sending of events and    the completion of the checkpoint future (for example the same thread does both actions, or the actions    are guarded by a mutex).  - Every event sent before the checkpoint future is completed should be before the checkpoint  - Eveny event sent after the checkpoint future is completed should be after the checkpointThe previous interface did not allow us to observe this point accurately. The future was created inside theapplication-specific OperatorCoordinator code and returned from the methods. By the time that the scheduler/checkpointingcode could observe the future (attach handlers to it), some (small amount of) time had inevitably passed in the meantime.Within that time, the future could already be complete and some events could have been sent, and in that case thescheduler/checkpointing code could not determin which events were before the completion of the future, and whichevents were after the completion of the future.The changed interface passes the future from the scheduler/checkpointing code into the coordinator. The future alreadyhas synchronous handlers attached to it which exactly mark the point when the future was completed, allowing thescheduler/checkpointing code to observe the correct order in which the Checkpoint Coordinator implementationperformed its actions (event sending, future completion).",1
[hotfix][coordination] Improve JavaDocs for OperatorCoordinator and OperatorCoordinatorHolder,1
[hotfix][coordination] Remove unused class ExecutionJobVertexCoordinatorContextThis class was left over from a prior refactoring.,4
[hotfix][coordination] Remove unused (and unimplemented) method 'failTask(...)' from OperatorCoordinator Context,1
[hotfix][table-common] Accept AbstractDataType for fields,5
[hotfix][table] Use AbstractDataType in fromValues(),5
[hotfix][tests] Move containsCause to FlinkMatchers,2
"[FLINK-18001][table-planner] Add a new test base for evaluating expressionsAdds a new test base that makes it possible to properly test built-in functionsof both SQL and Table API. Including error messages, full input and output datatype.This closes #12379.",5
[FLINK-18035][runtime] Use fixed thread pool,0
"Revert ""[FLINK-17558][runtime] Add Executors#newCachedThreadPool""This reverts commit 90b8455d08eda7a6a55f5cc952fa1adf3a48ff96.",4
"[FLINK-17887][table][connector] Improve interface of ScanFormatFactory and SinkFormatFactoryWe improved the interfaces with the following changes:1. Have a common interface DynamicTableSource.Context, and make Context of ScanTableSource and LookupTableSource extend it, and rename them to LookupContext and ScanContext2. Change parameter of ScanFormat.createScanFormat from ScanTableSource.Context to DynamicTableSource.Context3. Rename ScanFormat.createScanFormat to DecodingFormat#createRuntimeDecoder()4. Rename SinkFormat.createSinkFormat to EncodingFormat#createRuntimeEncoder()5. Rename ScanFormatFactory to DecodingFormatFactory6. Rename SinkFormatFactory to EncodingFormatFactoryThis closes #12320",1
[FLINK-17967][docs] Fix Chinese documentation build is brokenThis closes 12414,2
[FLINK-17968][hbase] Fix Hadoop Configuration is not properly serialized in HBaseRowInputFormatThis closes #12146,5
[FLINK-17340][docs] Update docs which related to default planner changing.This closes #12429,4
"[FLINK-17823][network] Resolve the race condition while releasing RemoteInputChannelRemoteInputChannel#releaseAllResources might be called by canceler thread. Meanwhile, the task thread can also call RemoteInputChannel#getNextBuffer.There probably cause two potential problems:1. Task thread might get null buffer after canceler thread already released all the buffers, then it might cause misleading NPE in getNextBuffer.2. Task thread and canceler thread might pull the same buffer concurrently, which causes unexpected exception when the same buffer is recycled twice.The solution is to properly synchronize the buffer queue in release method to avoid the same buffer pulled by both canceler thread and task thread.And in getNextBuffer method, we add some explicit checks to avoid misleading NPE and hint some valid exceptions.",1
[FLINK-17581][docs-zh] Update translation of S3 documentationThis closes #12380,2
[hotfix] Fix broken link and wrong node version command in runtime-web readmeThis closes #11041,1
[FLINK-17996][table-planner-blink] Fix NPE in CatalogTableStatisticsConverter.convertToColumnStats methodThis closes #12419,2
[FLINK-18008][runtime] HistoryServer logs environment info,5
[FLINK-18010][runtime] Expand HistoryServer logging,2
[FLINK-17970] Rename cluster.io-executor.pool-size config option into cluster.io-pool.sizeShortens the cluster.io-pool.size config option and updates the description of it.,5
[FLINK-17970] Increase default value of cluster.io-pool.size from #cores to 4 * #coresThis closes #12360.,1
[hotfix] Fix checkstyle violation in TaskSlotTableTest,3
[hotfix] Rename TaskSlotTableTest into TaskSlotTableImplTest,3
[hotfix] Add TaskSlotTableImplTest.testAllocatedSlotTimeout,3
"[FLINK-18012] Deactivate slot timeout when calling TaskSlotTable.tryMarkSlotActiveIn order to avoid timing out activated slots, we also need to deactivate the slot timeoutin case that TaskSlotTable.tryMarkSlotActive is being called. This can happen if the responsefor JobMasterGateway.offerSlots has been too late and timed out.This closes #12388.",1
"[FLINK-16057][hotfix][task] Remove MailboxProcessor.mainMailboxExecutor fieldCurrently, the field is unnecessary; further adding MailboxProcessorfield to MailboxExecutor creates cyclic dependency",1
[FLINK-16057][task] Optimize ContinuousFileReaderOperatorCurrent approach of re-enqueuing mails creates an overheadvisible in benchmarks. This change eliminates unnecessaryre-enqueueing of mails by checking mailboxExecutor.isIdle.,4
[FLINK-16057][task] Optimize TaskMailbox state retrievalDon't lock in TaskMailboxImpl.getState for task thread.This makes ContinuousFileReaderOperator about 29% faster.,2
[FLINK-17923][python] Allow Python worker to use off-heap memoryThis closes #12370.,1
"[FLINK-17992][checkpointing] Exception from RemoteInputChannel#onBuffer should not fail the whole NetworkClientHandlerRemoteInputChannel#onBuffer is invoked by CreditBasedPartitionRequestClientHandler while receiving and decoding the network data. #onBuffer canthrow exceptions which would tag the error in client handler and fail all the added input channels inside handler. Then it would cause a trickypotential issue as following.If the RemoteInputChannel is canceling by canceler thread, then the task thread might exit early than canceler thread terminate. That means thePartitionRequestClient might not be closed (triggered by canceler thread) while the new task attempt is already deployed into the same TaskManager.Therefore the new task might reuse the previous PartitionRequestClient while requesting partitions, but note that the respective client handler wasalready tagged an error before during above RemoteInputChannel#onBuffer, to cause the next round unnecessary failover.The solution is to only fail the respective task when its internal RemoteInputChannel#onBuffer throws any exceptions instead of failing the wholechannels inside client handler, then the client is still healthy and can also be reused by other input channels as long as it is not released yet.",1
[FLINK-17937][hive] Change some hive connector tests to IT casesThis closes #12333,3
[hotfix][docs] Fix the description of bounded-of-orderness in docs/dev/event_timestamps_watermarks.md,2
[FLINK-18052] Increase timeout for ES Search API in IT CasesThis closes #12434,1
[hotfix][python] Add the version for the APIs introduced in 1.11.0,1
[FLINK-17901][python] Add module interface in PyFlinkThis closes #12422.,2
[hotfix] Add directory flink-python/apache-flink-*.dev0 to gitignore,2
[FLINK-17895][table] Default value of rows-per-second in datagen can be limitedThis closes #12415,5
"[hotfix][hbase] Rename HBase connector option 'zookeeper.znode-parent' to 'zookeeper.znode.parent''zookeeper.znode.parent' configuration key is used in HBase, in order to be close to HBase users, it would be better to use the same key 'zookeeper.znode.parent'.",1
[FLINK-17995][docs][table] Redesign Table & SQL Connectors pagesThis closes #12386,2
[FLINK-17830][docs][hbase] Add documentation for the new HBase SQL connectorThis closes #12386,1
[FLINK-17774][streaming] Serialize results in CollectSinkFunction to deal with object reuseThis closes #12199,1
[FLINK-17774][table] Supports all kinds of changes for select resultThis closes #12199,4
"[FLINK-17376] Use JavaSerializer instead of getSerializableListState()We do this because we want to deprecate that method. We will have to getrid of using JavaSerialization completely soon, though.",1
"[FLINK-17376] Don't restore from Flink <= 1.2 state in Kafka connectorThis code was using the deprecated getSerializedListState(), which wewant to remove.",4
[FLINK-17376] Remove deprecated state access methods,4
[FLINK-18032] Remove outdated sections in migration guide,5
[FLINK-18075][kafka] Call open method of SerializationSchema in Kafka producerThe open method of SerializationSchema was not called in the universalKafka producer.This closes #12450,2
[FLINK-13782][table-api] Fix checking comparision of nested distinct/structured/raw typesThis closes #12396,0
[FLINK-17959][checkstyle] Exclude all beam classesThis closes #12459.,2
[FLINK-17959][python] Port Beam GrpcStateService class to flink-python moduleThis closes #12459.,2
[FLINK-17959][python] Fix the 'call already cancelled' exception when executing Python UDFThis closes #12459.,0
[FLINK-18051][AZP] Fail Maven setup stage on error,0
[hotfix][table-planner-blink] Prepare ExpressionTestBase for new type system,5
[hotfix][table-common] Align explicit casting with Calcite's SqlTypeCoercionRule,0
[hotfix][table-common] Add constraint argument type strategy,1
[FLINK-18005][table] Implement type inference for CASTThis closes #12411.,5
[FLINK-18011] Make WatermarkStrategy/WatermarkStrategies more ergonomicThis removes WatermarkStrategies and instead moves the convenienceentrypoint methods for strategies directly to WatermarmStrategy.WatermarkStrategy is now also itself the builder for more complexstrategies instead of WatermarkStrategies.,1
[FLINK-17945][python] Improve the error message when instantiating non-existing Java classThis closes #12469.,0
[hotfix][checkpointing] Fix the formatting of CheckpointBarrierUnaligner,1
"[FLINK-17994][checkpointing] Fix the race condition between CheckpointBarrierUnaligner#processBarrier and #notifyBarrierReceivedThe race condition happens as following:1. CheckpointBarrierUnaligner#notifyBarrierReceived triggers an async checkpoint(ch1) in mailbox by netty thread.2. CheckpointBarrierUnaligner#processBarrier also triggers a sync checkpoint(ch2) by task thread and executes immediately.3. When ch1 is taken from mailbox by task thread to execute, it will cause illegal argument exception because it is smaller than the previous executed ch2.For async checkpoint action, before it is actual executing, we can compare its id with previous executed checkpoint id. If it is not larger than the previousone, we should ignore it to exit directly.This closes #12406.",1
[FLINK-16451][table-planner-blink] Fix IndexOutOfBoundsException for DISTINCT AGG with constantsThis closes #12432,0
[FLINK-17466][table-planner-blink] Fix toRetractStream doesn't work correctly with Pojo conversion classThis closes #12425,1
"[FLINK-18069] [scala, docs] Scaladocs 2.12 fails to recognize inner interfacesThis is a similar issue as reported here:https://github.com/scala/bug/issues/10509.This seems to be a problem with Scala 2.12.x. The only workaround is toredundantly add the full-length qualifiers for such interfaces.",1
[FLINK-18037][javadocs] Remove duplicate word,4
[FLINK-18006] Always overwrite RestClientFactory in ElasticsearchXDynamicSinkWe always overwrite the RestClientFactory in order to workaround anissue with shading classes in lambdas deserialization method. That waywe never use the default lambda from ElasticsearchSink$Builder whichcannot be deserialized when used from aflink-sql-connector-elasticsearch module due to shading.This closes #12455,2
[FLINK-16975][documentation] Add docs for FileSystem connectorThis closes #12283,5
[FLINK-17935] Move set yarn.log-config-file to YarnClusterClientFactory.createClusterDescriptor()This closes #12455.,1
"Revert ""[FLINK-17935] Move set yarn.log-config-file to YarnClusterClientFactory.createClusterDescriptor()""This reverts commit 2eb73771",4
[FLINK-17931] Document fromValues clause in Table APIThis closes #12325,1
[FLINK-18055][sql-client] Fix catalog/database does not exist in sql clientThis closes #12431,5
[FLINK-18087][yarn] Fix uploading user artifact for Yarn job clusterThis closes #12463.,1
[FLINK-17918][table-blink] Fix AppendOnlyTopNFunction shouldn't mutate list value of MapStateThis closes #12441,1
[hotfix][table-planner-blink] Store last watermark in state to emit on recovery for EventTimeProcessOperator,1
[hotfix][python] Improve the error message when converting from Pandas DataFrame in the batch mode of old planner,5
[FLINK-18120] Don't expand documentation sections by defaultThis is basically a revert of FLINK-16041. The idea seemed good at thetime but with more sections being added this just looks too unwieldywhen you first open the docs,2
[FLINK-17935] Move set yarn.log-config-file to YarnClusterClientFactory.createClusterDescriptor()This closes #12455.,1
"[FLINK-17847][table-planner-blink] Fix runtime ArrayIndexOutOfBoundsException when accessing out-of-bounds elements of ARRAY dataThis changes the behavior of ARRAY element accessing:- if the accessing index is a literal which is less than 1, then an error will be thrown before job is submitted with readable exception message- if the accessing index is out-of-bound during runtime, then return null instead of throwing exceptionThis closes #12436",1
"[FLINK-17404] Make sure netty 3.10.6 is used in flink-runtimeDue to the recent changes in https://issues.apache.org/jira/browse/FLINK-11086 (""Add support for Hadoop 3""),the shaded netty dependency in flink-runtime changed depending on the Hadoop dependency version.The Hadoop 3 change affects the Netty version of flink-runtime depending on the hadoop version you are compiling Flink with:- our akka expects netty 3.10.6- with Hadoop 2.4.1 and Hadoop 2.8.3, flink-runtime shades netty 3.6.2 (the e2e test passes)- with Hadoop 3.1.3 netty is at 3.10.5 (the e2e test fails reliably)We add Netty 3.10.6 as a dependency to flink-runtime to make sure it is not overridden by any other dependencies.",1
[FLINK-16572] Clean up PubSub connector e2e test- execute as regular test to have proper logging- document copied code- fix typos,2
[FLINK-17384][connectors/hbase] Support reading hbase conf dir from flink-conf.yamlThis closes #12144.,5
[FLINK-16577][table-planner-blink] Fix numeric type mismatch error in column interval relmetadataThis closes #12326,5
[FLINK-17717][sql-parser] Throws for DDL create temporary system func with composite identifierThis closes #12352,5
[hotfix] Remove redundant backslash in the log of GPUDriverThis closes #12480.,2
[FLINK-18074][checkpoint] Ensure task could fail when exception thrown out on notified of checkpoint completed/aborted,0
[FLINK-18143][python] Fix Python meter metric incorrect value problem (#12498),0
[FLINK-15687][runtime][test] Fix accessing TaskSlotTable via TaskSubmissionTestEnvironment not in RPC main thread.,3
[FLINK-15687][runtime][test] Make TaskManagerActions access task slot table on rpc main thread in TaskSubmissionTestEnvironment.This closes #12399.,3
[FLINK-18059][sql-client] Fix create/drop catalog statement can not be executed in sql clientThis closes #12435,2
[FLINK-18142][hive] Wrong state names in HiveContinuousMonitoringFunctionThis closes #12497,1
[FLINK-18069][CI] Test if Scala/JavaDocs builds are passing in the compile stageThis closes #12447,1
[FLINK-17553][table] Fix plan error when constant exists in group window keyThis closes #12028,0
[FLINK-18038][statebackend] Log application-defined state backends after configuration,5
[FLINK-18042][build] Bump flink-shaded to 11.0,2
[FLINK-17816][metrics] Schedule latency markers with fixed delay,0
[FLINK-17974][docs] Extend docker documentationThis closes #12490,2
[hotfix][docs] Remove HADOOP_CONF_DIRThe Hadoop configuration page was quite confusing because it suggested that the user has toset the HADOOP_CONF_DIR as well. All jars and configs can and shouldbe passed through HADOOP_CLASSPATH. Period.This closes #12491,4
"[FLINK-15339][table][docs] Correct the terminology of ""Time-windowed Join"" to ""Interval Join"" in Table API & SQLThis closes #12483",2
[FLINK-18076][table sql / client] Use correct classloader when parsing queriesThis closes #12475,1
[FLINK-18048] Fix --host option for standalone application clusterThis closes #12426.,0
"[FLINK-17260] Make number of expected messages explicit in StreamingKafkaITCaseBefore, it could happen that we time out and return early, which wouldlead to a test failure. Now, we would fail at the source of the problem.",0
[FLINK-17260] Increase timeout for reading Kafka messages in StreamingKafkaITCase,1
[FLINK-17260] Make topic names unique in StreamingKafkaITCase to prevent clashesDuplicate topic names and leftover data could be a potential source ofinstabilities.,5
[FLINK-18020] Make topic names unique in SQLClientKafkaITCase to prevent clashesDuplicate topic names and leftover data could be a potential source of instabilities.,5
[FLINK-18020] Increase timeout in SQLClientKafkaITCase,1
"[FLINK-18139][checkpointing] Fixing unaligned checkpoints checks wrong channels for inflight data.CheckpointBarrierUnaligner#hasInflightData was not called with input gate contextual information, such that only the same first few channels are checked during initial snapshotting of inflight data for multi-gate setups.",1
[FLINK-18067][yarn] Change default value of yarnMinAllocationMB from zero to DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MBThis closes #12444.,5
[FLINK-18073][avro] Fix AvroRowDataSerializationSchema is not serializableThis closes #12471,5
[hotfix][avro] Fix AvroRowSerializationSchema doesn't support TIMESTAMP type,1
"[FLINK-18029][kafka] Add more ITCases for Kafka with new formats (avro, csv, json)This closes #12471",5
[FLINK-18110][fs-connector] StreamingFileSink notifies for buckets detected to be inactive on restoringThis closes #12496,2
[FLINK-18151][python] Resolve CWE22 problems in pyflink_gateway_server.py (#12503),2
"[FLINK-18149][k8s] Do not add DeploymentOptionsInternal#CONF_DIR to config mapDeploymentOptionsInternal#CONF_DIR is an internal option and stores the client config path. It should not be added to config map and used by JobManager pod. Instead, KubernetesConfigOptions#FLINK_CONF_DIR will be used.This closes #12501.",1
[FLINK-16350] Support Zookeeper 3.5 in test_ha_per_job_cluster_datastream.shThis closes #12504.,5
"[FLINK-18050][task][checkpointing] Use CloseableIterator to write ResultSubpartition stateCurrently, buffers passed to ChannelStateWriterImpl can be recycledtwice: once in normal case after writing; second inCheckpointInProgressRequest.cancel (called from ChannelStateWriteRequestDispatcherand other places).This change prevents this by using CloseableIterator which distinguishesused and unused elements.",1
[FLINK-18050][task][checkpointing] Simplify ChannelStateCheckpointWriter interface,2
[FLINK-17776][hive][doc] Add documentation for DDL&DML in hive dialectThis closes #12439,2
[FLINK-17406][doc] Add documentation about dynamic table optionsThis closes #12319,2
[FLINK-18046][hive] Decimal column stats not supported for Hive tableThis closes #12424,1
[FLINK-17512] Add notification settings to .asf.yaml,1
[FLINK-17635][docs][table] Add documentation about view supportThis closes #12502,1
[hotfix][pubsub] Use TestLogger,3
"[FLINK-16572][e2e][pubsub] Acknowledge message in previous testThe test running before the failing test did not properly acknowledge thereception of the message.That's also the reason why this test always logged a timeout exception.With this change, the test will fail with timeout exceptions, and maybe thisimproves the overall test stability.",3
[FLINK-18075] Remove deprecation of Kafka producer ctor that takeSerializationSchemaSerializationSchema is an important interface that is widely spread andused in other components such as Table API. It is also the most commoninterface for reusable interfaces. Therefore we should support it longterm in our connectors. This commit removes the deprecation of ctorsthat take this interface.Moreover it adds the most general ctor that takes all producerconfiguration options along with SerializationSchema. This makes itfeature equivalent with KafkaSerializationSchema in respect toconfiguration of the producer.,5
[FLINK-18075] Wrap the SerializationSchema in KafkaSerializationSchema in Kafka connector,2
[FLINK-13782][table-api] Implement type strategies for IF ELSEexpressionThis closes #12410,2
[FLINK-17260] Embellish assert output of StreamingKafkaITCase to help debugging,0
[FLINK-18075][hotfix] Use DeserializationSchema instead of KeyedDeserializationSchema in DynamicTableSink,1
[FLINK-17625][table-runtime-blink] Fix ArrayIndexOutOfBoundsException in AppendOnlyTopNFunctionThis closes #12303,1
"[FLINK-16101][docs-zh][table] Translate ""Hive Functions"" page of ""Hive Integration"" into ChineseThis closes #11664",1
[FLINK-17893][sql-client] SQL CLI should print the root cause if the statement is invalidThis closes #12355,1
[FLINK-16291][hive] Ban count from HiveModuleThis closes #12382,2
[FLINK-16559][hive] Add test for avro tableThis closes #12408,3
[FLINK-17902][python] Support the new interfaces about temporary functions in PyFlinkThis closes #12476.,2
[FLINK-18056][fs-connector] Hadoop path-based file writer adds UUID to in-progress file to avoid conflictsThis closes #12452,5
[FLINK-18130][hive][fs-connector] File name conflict for different jobs in filesystem/hive sink ()This closes #12485,5
[FLINK-18042][tests] Log path of used distribution,1
[FLINK-18042][tests] Auto-detect moduleDir,3
[FLINK-18042][tests] More helpful error message if jar cannot be found,0
[FLINK-18042][tests] Auto-detect distDir,3
"[FLINK-18136][checkpointing] Don't start channel state writer for savepointChannelStateWriter#start should be only called for unaligned checkpoint. While source triggeringsavepoint, SubtaskCheckpointCoordinator#initCheckpoint is introduced to judge the conditionwhether to start the internal writer or not. And this new method is also used in other places likeCheckpointBarrierUnaligner.This closes #12489.",1
[FLINK-18181][fs-connector] StreamingFileCommitter should not use fs modification time for proc committerThis closes #12526,1
[FLINK-18152][Depl] Fail fast in JM scripts if memory configuration failedThis closes #12521.,0
[hotfix][checkpointing] Add VisibleForTesting annotation for related methods,3
[FLINK-18063][checkpointing][refactoring] Implement default #isBlocked method in CheckpointBarrierHandlerSimplify the implementations of CheckpointBarrierTracker and CheckpointBarrierUnaligner to reuse the parent default implementation.This closes #12460.,1
"[FLINK-18063][checkpointing] Fix the invalid implementation of AlternatingCheckpointBarrierHandler#getAlignmentDurationNanosWe should take the value from active handler instead of aligned handler, because aligned handler is only used for savepoint and inmost cases the unaligned alignment duration should always be 0.This cloese #12460.",1
"[FLINK-18063][checkpointing] Fix the race condition of aborting checkpoint in CheckpointBarrierUnalignerThere are three aborting scenarios which might encounter race condition:1. CheckpointBarrierUnaligner#processCancellationBarrier2. CheckpointBarrierUnaligner#processEndOfPartition3. AlternatingCheckpointBarrierHandler#processBarrierThey only consider the pending checkpoint triggered by #processBarrier from task thread to abort it. Actually the checkpoint mightalso be triggered by #notifyBarrierReceived from netty thread in race condition, so we should also handle properly to abort it.This closes #12460.",0
[hotfix][tests] Add missing import,2
[hotfix][tests] Fix the compile issue caused by constructor change of CheckpointBarrierUnaligner,1
[hotfix][testing] Remove the unused import from CheckpointBarrierUnalignerTest,3
[FLINK-17765] Strip ExecutionException from StreamExecutionEnvironment.executeAsync,2
[FLINK-17765] Remove JobExecutionException from JobManagerRunnerImpl,1
[FLINK-17765] Remove uncheckedSupplier from Dispatcher.createJobManagerRunnerThis closes #12505.,1
[FLINK-17753] [table-planner-blink] Fix watermark defined in ddl does not work in Table apiThis closes #12335,1
[FLINK-18061] [table] TableResult#collect method should return a closeable iterator to avoid resource leakThis closes #12473,2
[FLINK-18195] Remove references to Expressions.interval(Duration) from (java)docsThis closes #12535,2
[FLINK-18208] Fix flink ES connector typosThis closes #12543,2
[FLINK-17872][doc] Add document for writing Avro files with StreamingFileSinkThis closes #12321,2
[FLINK-18045] Fix Kerberos credentials checkingThis closes #12462.,0
[FLINK-18126][python] Correct the exception handling of the Python CompletableFutureThis closes #12488.,2
[FLINK-18207][FLINK-18185][table] Fix datagen connector exactly-once bug and validation messageThis closes #12544,1
"[FLINK-16694] Run test_resume_externalized_checkpoints.sh with 15 min test timeoutIn order to harden test_resume_externalized_checkpoints.sh, it is now run with a 15 min test timeoutwhich will make the logs accessible in case of a stalling test.This closes #12530.",3
[FLINK-18176][document] Add supplement for file system connector documentThis closes #12522,2
[FLINK-18157][runtime] Jobstore size check compares against offHeapMemoryThis closes #12516.,2
[FLINK-18018][dist] Bundle GPU plugin in plugins/ directory,2
[FLINK-18156] Add 'or default' for min/max to JVM Overhead sanity check's error message,0
[FLINK-18154][Runtime] Check Total Flink Memory plus JVM metaspace is less than or equal to the configured Total Process MemoryThis closes #12520.,5
[hotfix] Improve JavaDocs comments for FlinkMemory/FlinkMemoryUtis,2
[FLINK-18057][tests] Fix unstable test SingleInputGateTest#testConcurrentReadStateAndProcessAndClose,3
[FLINK-16225] Implement user class loading exception handlerThis closes #12446.,0
[FLINK-10740][docs] Add documentation for FLIP-27 sourcesThis closes #12492,2
[FLINK-10740][docs] Add documentation for FLIP-27 Source API and SplitReader API.,2
[hotfix][docs] Add NEWLINE to end of SVG files,2
[hotfix][docs] Minor language cleanups for Data Source docs.,2
[FLINK-18104][python][windows] Fix the test failures on Windows.This closes #12552.,0
[hotfix][python] Add version information for the methods defined in CompletableFuture,5
[hotfix][python] Remove unnecessary methods in JobExecutionResult,4
[hotfix][avro] Fix TINYINT/SMALLINT types not work in Avro format,1
[hotfix][docs][table] Minor improvements on Filesystem and HBase connector page,5
[FLINK-18133][docs][avro] Add documentation for the new Avro formatThis closes #12523,1
[hotfix][docs-zh] Update corresponding Chinese Avro format pages,5
[FLINK-16681][jdbc] Fix JDBC source/sink lost connection after a long time idleThis closes #12427,5
[FLINK-18082][jdbc] Fix UnsignedTypeConversionITCase stalls in ch.vorburger.mariadb4j.DB.stopThis closes #12465,5
Fix typo in KafkaResource (#12564)This closes #12564,2
[hotfix][doc] Some minor languange clean-ups for the Source doc.,2
[FLINK-16217][sql-client] Fix exception catching to avoid SQL client crashesThis closes #11397.,0
[FLINK-16198] Fix FileUtilsTest on macOS1. Fix concurrent delete failure on macOS2. Fix relative compression path test failure,0
[FLINK-17498][tests] Increase CancelingTestBase rpc timeout to configured Akka ask timeoutThis commit hardens all CancelingTestBase tests by using the configured Akka ask timeout of200s as the rpc timeout.This closes #12531.,5
"[FLINK-17944][sql-client] Wrong output in SQL Client's table modeThis is a temporary workaround until we don't use Tuple2<Boolean, Row>to represent changelogs anymore.This closes #12346.",4
[FLINK-17869][hotfix] Add taskName to ChannelStateWriter log messages,2
[FLINK-17869][hotfix] Don't pass ChannelStateWrite Future to AsyncCheckpointRunnableOperatorSnapshotFinalizer already waits and holds this future.ChannelStateWriter.getWriteResult() can then be non-idempotent.ChannelStateWriter.stop() can then be removed.,4
"[FLINK-17869][task][checkpointing] Revert ""[FLINK-17218][checkpointing] Ensuring that ChannelStateWriter aborts previous checkpoints before a new checkpoint is started.""This reverts commit 24ff415f1b76392f75dea7c3538558d24fcb7058which introduced a race condition when task thread and nettythread compete for ChannelStateWriteResult.Instead, next commits fix it by:1. Map size validation error will be prevented simply by increasing the limit2. When a checkpoint is subsumed, it's write result will be removed from on future completion",4
[FLINK-17869][task][checkpointing] Abort channel state write if checkpoint is subsumedMotivation: stop writing channel state ASAP if the checkpoint is subsumedChanges:1. complete CheckpointBarrierUnaligner.ThreadSafeUnaligner#allBarriersReceivedFuture2. abort channel state write on its erroneous completion3. add cleanup parameter to ChannelStateWriter.abort to use cleanup=falsein the call above,4
"[FLINK-17869][task][checkpointing] Increase ChannelStateWriterImpl.DEFAULT_MAX_CHECKPOINTSChannelStateWriter map is cleaned up by the task thread,so the check in netty thread should take possible delayinto account.",4
[FLINK-17869][task][checkpointing] Ignore out of order checkpoints in SubtaskCheckpointCoordinatorCheck (by task thread) whether the current checkpoint was already aborted in the following scenario:1. on checkpoint barrier ThreadSafeUnaligner sends a mail to start checkpointing (netty thread)2. on cancellation marker CheckpointBarrierUnaligner aborts it (task thread)3. task thread processes a mail to start checkpointing,1
[FLINK-17869][tests] Unignore UnalignedCheckpointITCase,3
[FLINK-17869][task][checkpointing] Abort writing of channel state by RPCnotification,2
[FLINK-18215][conf] Add log level to JavaBashUtils log4j config,5
"[FLINK-16213] Move stateful-stream-processing.md introduction to form ""What is State"" section",4
"[FLINK-17982] Remove TODOs from stateful-stream-processingFor some sections, we will expand them in the future when we have actualfunctionality. Some aimed at expanding sections but they are also ok asthey are now.",1
[FLINK-16208] Add introduction to timely stream processing concepts documentation,2
"[FLINK-17982] Remove TODOs from timely-stream-processing.mdFor some sections, we will expand them in the future when we have actualfunctionality. Some aimed at expanding sections but they are also ok asthey are now.",1
[minor] Propagate recent changes to chinese documentation,2
[hotfix] Correct the default path of nvidia-gpu-discovery,0
[FLINK-18218][python][e2e] Add PyFlink YARN per-job e2e testsThis closes #12554.,3
[FLINK-17795][example] Add MatrixVectorMul exampleThis closes #12398.,1
[hotfix][cli] Update the help message of the Generic CLI,5
[hotfix] Fix typo in ops/deployment/index,2
[FLINK-18084] Rename the ExecutorCLI to GenericCLI according to docs,2
[FLINK-18084][docs] Document the Application ModeThis closes #12549.,2
[FLINK-17980][docs] Move getting started walkthroughs to Try Flink,2
[FLINK-17980][docs] Rename Hands-on Training to Learn Flink,2
[FLINK-17980][docs] Update headings of datastream and table walkthroughs,5
[FLINK-17980][docs] Update broken links,2
[FLINK-17980][docs] Add training redirects,5
[FLINK-17980][docs] Update broken links,2
[FLINK-17980][docs] Add training redirectsThis closes #12534,5
[FLINK-17980][docs] Move project setup into DataStream section,5
[FLINK-18188][Runtime] Derive JM Off-Heap memory from configured Total Flink Memory minus JVM Heap,2
[hotfix][table-common] Implement first type strategy,0
[hotfix][table-common] Add a common type strategy,1
[FLINK-13784][table] Implement type inference for math functionsThis closes #12464.,1
[FLINK-18239][e2e] Pin minikube version to v1.8.2,5
[FLINK-18034][runtime] Introduce PreferredLocationsRetriever,2
[FLINK-18034][runtime] ExecutionSlotAllocator uses PreferredLocationsRetriever to get preferred locations for tasks,1
[FLINK-18034][runtime] Remove unused preferredLocations from ExecutionVertexSchedulingRequirements,1
[hotfix][runtime] Remove ExecutionSlotAllocator#stop() which is never used in production,1
[FLINK-18232][hive] Fix Hive streaming source bugsThis closes #12573,0
[hotfix][avro] Link to Hadoop Integration in Avro format documentationThis closes #12580,2
[FLINK-18224][docs] Add document about sql client's tableau result modeThis closes #12569,2
[FLINK-18030][hive] Hive UDF doesn't accept empty string literal parametersThis closes #12403,2
[FLINK-17965][sql-parser-hive] Hive dialect needs to unescape backslash in string literalsThis closes #12378,2
[FLINK-18131][docs] Add documentation for the new JSON formatThis closes #12574,5
[FLINK-17113][sql-cli] Use executeSql to execute view statements and fix nullability loss problemThis closes #12456,0
[hotfix] Fix a code style local variable name issue in JobManagerProcessUtilsTest,3
"[FLINK-18214][Runtime] Remove Job Cache size check against JVM Heap sizeChecking that the job cache size is less than JVM heap for JM, may be inconclusive and confusing for users. The job cache size option does not strictly limit the real size and stays an advanced emergency mean. The job size calculation is approximate and the real cache size can be larger than its configured limit (`jobstore.cache-size`).Therefore, this PR removes the related code from `JobManagerFlinkMemoryUtils`, tests and memory tuning guide.This closes #12590.",3
[FLINK-18160][scripts] Do not log about HADOOP_CONF_DIR if HADOOP_CLASSPATH is set,1
[FLINK-18132][docs] Add documentation for the new CSV formatThis closes #12571,1
[hotfix][table-common] Fix TableSchemaUtils#getPhysicalSchema should keep the original constraint name,1
[FLINK-16497][jdbc][table] Improve default flush strategy for new JDBC sink for better out-of-boxThe default flush strategy for old JDBC sink is no flush interval and 5000 buffered rows.The new default flush strategy for new JDBC sink is '1s' flush interval and '100' buffered rows.This closes #12536,5
[FLINK-16496][hbase][table] Improve default flush strategy for new HBase sink for better out-of-boxThe default flush strategy for old HBase sink is no flush interval and 2MB buffered size.The new default flush strategy for new HBase sink is '1s' flush interval and '1000' buffered rows and '2mb' buffered size.This closes #12536,1
[FLINK-16495][elasticsearch][table] Improve default flush strategy for new Elasticsearch sink for better out-of-boxThe default flush strategy for old Elasticsearch sink is no flush interval and 5MB buffered size and 1000 rows.The new default flush strategy for new Elasticsearch sink is '1s' flush interval and '1000' buffered rows and '2mb' buffered size.This closes #12536,1
[hotfix][docs][hbase] Improve HBase connector documentation about primary key,2
[FLINK-17832][docs][es] Add documentation for the new Elasticsearch connectorThis closes #12579,1
[minor][docs] Update chinese version of flink-architecture.mdThis copies the changes from the *.md version to the *.zh.md version.,4
[FLINK-18237][fs-connector] Exception when reading filesystem partitioned table with stream modeThis closes #12576,5
[FLINK-17733][FLINK-16448][hive][doc] Adjust Hive doc & Add documentation for real-time hiveThis closes #12537,2
[FLINK-15849][doc] Update SQL-CLIENT document from type to data-typeThis closes #12567,5
[FLINK-18247][table-planner-blink] Fix unstable test: TableITCase.testCollectWithCloseThis closes #12595,3
[FLINK-18217][conf] Explicitly check for empty string* [FLINK-18217][conf] Explicitly check for empty string* +* ++,5
[hotfix][dist] Use dash in plugin directories,1
[FLINK-18058][mesos][tests] Increase heartbeat interval/timeout,1
[FLINK-17829][docs][jdbc] Add documentation for the new JDBC connectorThis closes #12487,5
[hotfix] Fix checkstyle violations in AllocatedSlot,0
[hotfix][runtime] Set root cause to pending request released exception,1
[FLINK-17017][runtime] Allow to set whether a physical slot payload will occupy the slot indefinitely,5
[FLINK-17017][runtime] Add SingleLogicalSlot#allocateFromPhysicalSlot() for physical slot assignment,2
[FLINK-17017][runtime] Enable to get whether a physical slot will be occupied indefinitely,5
[FLINK-17017][runtime] Enable to get allocated slots information of a slot pool,5
[FLINK-17017][runtime] Allow to disable batch slot request timeout check,1
[FLINK-17017][runtime] Allow nullable timeout for streaming slot request in slot pool,1
[FLINK-17017][runtime] Introduce BulkSlotProvider which allocates physical slots in bulks,1
[FLINK-17017][runtime] SchedulerImpl supports bulk slot allocation,1
[FLINK-17422][doc] Create user document for the external resource framework and the GPU pluginThis closes #12538.,1
[FLINK-17442][docs] Make example URL Flink version dependent,2
[hotfix] Fix head --lines usage in test scripts--lines does not work on macOS but -n works.,1
[FLINK-17831][docs] Add documentation for the new Kafka connectorThis closes #12482,1
[hotfix][docs][connectors] Improve SQL connectors documentation,2
[hotfix][docs] Fix parts of broken links,2
[FLINK-17788][scala-shell] Fix yarn session support in scala shell,1
"[FLINK-17182][network][tests] Fix the unstable RemoteInputChannelTest.testConcurrentOnSenderBacklogAndRecycleIn this unstable unit test, the exclusive buffers and floating buffers are recycled by differentthreads, which might cause unexpected race condition issue. But actually they should always berecycled by the same task thread in practice. So we refactor the test process to recycle them inthe same thread to avoid potential unnecessary issues.This closes #11924.",0
[FLINK-18256][orc] Exclude ORC's Hadoop dependency and pull in provided vanilla hadoop in flink-orc,2
[hotfix] Improve exception message for parsing kryo serializer classes from config,5
[FLINK-18241] Use correct user class loader in OptimizerPlanEnvironment & StreamPlanEnvironmentThis closes #12607,1
[hotfix][docs] Fix Liquid Exception in documentationThis closes #12626,2
[FLINK-18246][python][e2e] Disable PyFlink e2e tests when running on jdk11This closes #12598.,1
"[FLINK-18252][checkpointing] Fix savepoint overtaking output data.Currently, a checkpoint/savepoint barrier is always send as a priority events to the output partitions, where it overtakes data. After the fix a barrier is only a priority event iff it's unaligned.Also CheckpointCoordinator only set unaligned flag if the barrier belongs to a checkpoint.Ultimately, the unaligned checkpoint config option is not used by SubtaskCheckpointCoordinatorImpl except for initializing the channel state writer. The source of truth is now the CheckpointOptions.",5
[FLINK-18253][doc][avro] Add filesystem option documentation for AvroThis closes #12599,2
[FLINK-18141][doc][parquet] Add documentation for Parquet formatThis closes #12597,2
[FLINK-18175][conf] Log final memory configuration,5
[FLINK-17977][runtime] Log FS safety-net lifecycle on DEBUG,0
[FLINK-17977][runtime] Log initiation of savepoint operations,5
[FLINK-17977][runtime] Log leader grant/revocation to shutdown JobManager on DEBUG,0
[FLINK-17977][akka] Log target address retrieval on DEBUG,0
[FLINK-17977][runtime] Log registration attempts on DEBUG,0
"[FLINK-17977][runtime] Log incompatible security context factories on DEBUGBeing incompatible is perfectly normal, as it is for example the case if the security context isn't configured in the first place.",5
[FLINK-17977][runtime] Log message timeout on DEBUG,0
[FLINK-17977][runtime] Log outdated TaskExecutor registration on DEBUG,0
[FLINK-17977][core] Silence type extractor warnings for built-in Row,2
[FLINK-12855] Add WindowStagger to TumblingProcessingTimeWindows,1
[FLINK-18137] Handle discarding of triggering checkpoint correctlyBefore discarding a triggering checkpoint could cause a NPE which would stop theprocessing of subsequent checkpoint requests. This commit changes this behaviourby checking this condition and instantiating a proper exception in case that atriggering checkpoint is being discarded.This closes #12611.,4
[hotfix] Add @Nullable annotation to FutureUtils.getWithoutException,1
"[hotfix] Make sure that no exceptions are swallowed in CheckpointCoordinator.startTriggeringCheckpointIn order to avoid that CompletableFutures don't swallow exception they need to terminate with an exception handler.FutureUtils.assertNoException(CompletableFuture) asserts that the given future does not complete exceptionally. Ifit does, then the system will fail and the exception will be reported.",0
[FLINK-18233][tests] Increase test timeout to 20s for TaskExecutorSubmissionTestThis closes #12587.,3
[FLINK-18259][tests] Increase heartbeat timeouts for HeartbeatManagerTestIncreasing the heartbeat timeouts should harden the tests in case of slowtesting machines.This closes #12612.,3
[FLINK-17322][network] Fixes BroadcastRecordWriter overwriting memory segments on first finished BufferConsumer.BroadcastRecordWriter#randomEmit initialized buffer consumers for other non-target channels incorrectly leading to separate buffer reference counting and subsequently released buffers too early.This commit uses the new BufferConsumer#copyWithReaderPosition method to copy the buffer while updating the read index to the last committed write index of the builder.,5
[FLINK-17322][network] Disallowing repeated consumer creation for BufferBuilder.This is a partial revert of FLINK-10995.,2
[FLINK-17315][tests] Ignore unstable UnalignedCheckpointITCase one more time,3
[FLINK-17981][docs] rewrite docs home page,2
[FLINK-17981][docs] Link to statefun docs from the home page,2
[FLINK-17981][docs] Improvements to layout and content based on reviews,1
[FLINK-17981][docs] Add a section on getting help to the home pageThis closes #12556,1
[hotfix] Update release notes for 1.10,5
[FLINK-15687][runtime][test] Fix test instability due to concurrent access to JobTable.This closes #12623.,3
[hotfix][yarn] Code clean-up in YarnResourceManager.,4
[FLINK-18226][runtime] Fix ActiveResourceManager request extra workers on termination of existing workers.ActiveResourceManager decides whether and how many new wokers to request based on the following equation.workersToRequest = workersRequiredBySlotManager - workersRequestedByResourceManagerNotRegisteredwhere previsoutly 'workersRequestedByResourceManagerNotRegistered' was 'workersRequestedByResourceManagerNotAllocated'.This closes #12620.,5
[FLINK-18277][elasticsearch] Fix the returned value of Elasticsearch6DynamicSink#asSummaryString()This closes #12633,0
[FLINK-17836][hive][doc] Add document for Hive dim joinThis closes #12609,2
[FLINK-18265][fs-connector] Hidden files should be ignored when the filesystem table searches for partitionsThis closes #12628,5
[FLINK-18265][fs-connector] temp path in FileSystemOutputFormat should be deletedThis closes #12628,4
[FLINK-18140][doc][orc] Add documentation for ORC formatThis closes #12602,2
[FLINK-17686][doc] Add document to dataGen connector,5
[FLINK-17686][doc] Add document to blackhole connector,2
[FLINK-17686][doc] Add document to print connectorThis closes #12610,2
[hotfix][doc] Fix minor error in hive_streaming.md,0
[FLINK-18173][build] Bundle flink-csv and flink-json jars in libThis closes #12527,5
[FLINK-17623][elasticsearch] Support user resource cleanup in ElasticsearchSinkFunctionThis closes #12619,1
[FLINK-18089][network][tests] Config the e2e for netty shuffle memory control into azure pipelineThis closes #12614.,5
"[FLINK-17960][python][docs] Improve commands in the ""Common Questions"" document for PyFlink (#12367)",2
[FLINK-18197][hive] Add more logs for hive streaming integrationThis closes #12625,2
[hotfix] Relocation hadoop runtime utilThis closes #12646,1
[FLINK-18223] Fixed AvroSerializer to initialize GenericRecords in the correct wayThis closes #12591,5
[FLINK-17977] Improve checkpoint triggering log message,2
[FLINK-18147] Fix ORC document display problemsThis closes #12500.,0
[FLINK-13783][table] Implement type inference for string functionsThis closes #12593.,1
[FLINK-18039][connector/common] Introduce a RecreateOnResetOperatorCoordinator class to recreate an OperatorCoordinator instance when resetToCheckpoint() is invoked. Let SourceCoordinator leverage RecreateOnResetOperatorCoordinator to ensure a clean checkpoint reset.,1
[FLINK-18039] Ensure the source events are sent via the coordinator thread.,2
[minor] In FlinkKafkaInternalProducer add Javadoc to internal methods and clarify names,2
[minor] In FlinkKafkaInternalProducer add Javadoc to internal enqueueNewPartitions(),1
"[FLINK-17327] Always use close() with zero timeout in exactly-once Kafka ProducerNOTE: This fix does not work without also bumping the Kafka version tosth > 2.4 (2.3 might work as well). Because of KAFKA-6635/KAFKA-7763.Calling close() without timeout is equivalent to callingclose(Long.MAX_VALUE). This will leave lingering Kafka threads onshutdown, which eventually cause the Task Manager to be killed by theFlink Task watchdog.We also forbid calling close() without a timeout on our internalProducer, which means that we have to change some code that usestry-with-resources, because this calls close() without a timeout.We need to call close with a zero timeout to prevent in-flighttransactions from being aborted by the KafkaProducer/sender. This wouldbreak how we use transactions in our Kafka Producer.We don't update FlinkKafkaProducerBase, which is used fornon-exactly-once Kafka Producers.",1
"[FLINK-15362] Bump Kafka connector to 2.4.1This requires changes to how we use reflection for accessing internalsof KafkaProducer.Bumping the version doesn't work without the previous commit where wealways call close() with a zero timeout. If we don't call close() with azero timeout the producer/sender will internally abort in-flighttransactions, which would break how we use transactions in our Producer.We add a new error exclusion because the new Kafka version logs slightlydifferent things.We need to update the lz4-java dependency in flink-runtime to matchtransitive dependency of Kafka 2.4.1This is required for fixing FLINK-17327.",2
[FLINK-18162][connector/common] Serialize the splits in the AddSplitsEvent.,1
[FLINK-18261][parquet][orc] flink-orc and flink-parquet have invalid NOTICE fileThis closes #12622,2
[FLINK-18268][docs] Correct Table API in Temporal table docsThis closes #12630,2
[FLINK-18282][docs-zh] Retranslate the home page documentThis closes #12642,2
[hotfix] Introduce TaskManagerExceptionUtils,0
[FLINK-18250] Enrich OOM error messages with more details in ClusterEntrypointThis closes #.,1
"[FLINK-17891][yarn] Set execution.target=yarn-session in FlinkYarnSessionCli.run()Currently when starting a yarn session cluster using the yarn-session scriptor the FlinkYarnSessionCli.run() the displayed execution.target isyarn-per-job, which is misleading. We fix it by explicitly setting itto yarn-session.This closes #12635.",1
[hotfix][table-runtime-blink] Allow subclasses of Map as input conversion class,1
[FLINK-18248][docs] Update data type documentation for 1.11This closes #12606.,2
[FLINK-17976][docs][k8s/docker] Improvements about custom docker imagesThis closes #12558,2
[hotfix] Remove obsolete .gitattributes fileThis contained entries about bat scripts and vendored files from the old web UI.Both are not part of Flink any more.,2
[FLINK-18307][scripts] Rename 'slaves' file to 'workers',1
[hotfix][docs] Remove outdated confusing HDFS reference in cluster setup.,1
[FLINK-17666][table-planner-blink] Insert into partitioned table can fail with select *This closes #12656,0
[FLINK-17800][roksdb] Ensure total order seek to avoid user misuse,1
[FLINK-17800][roksdb] Support customized RocksDB write/read options and use RocksDBResourceContainer to get them,1
[FLINK-18322][connector/common][tests] Fix unstable ExecutorNotifierTest#testExceptionInHandler (#12676),3
[FLINK-18065][docs] Document FLIP-65 table and scalar functionsThis closes #12660.,1
[hotfix][table-common] Relax literal casting check in AdaptedCallContext,0
[hotfix][e2e] Sync kafka 0.10 versions,0
[hotfix][runtime] Move shared static test methods of physical slot into PhysicalSlotTestUtils,3
[hotfix][runtime] Move shared static test methods of slot allocator into ExecutionSlotAllocatorTestUtils,3
[FLINK-17018][runtime] Extract common logics of DefaultExecutionSlotAllocator into AbstractExecutionSlotAllocator,2
[FLINK-17018][runtime] Introduce OneSlotPerExecutionSlotAllocator which will request one physical slot for each single execution vertexOneSlotPerExecutionSlotAllocator allocates slots in bulks so that the SlotProvider can check whether this bulk of slot requests can be fulfilled at the same time.It has several limitations:1. Slot sharing will be ignored.2. Co-location constraints are not allowed.3. Intra-bulk input location preferences will be ignored.,1
[FLINK-17018][runtime] Use OneSlotPerExecutionSlotAllocator on pipelined region scheduling,1
[hotfix][runtime] Narrow down the access scope of DefaultExecutionSlotAllocator,0
[hotfix][runtime] Narrow down the access scope of SlotExecutionVertexAssignment,0
[FLINK-18298][table] Rename TableResult headers of SHOW statementsThis closes #12654.,2
[FLINK-18083][hbase] Improve exception message of TIMESTAMP/TIME out of the HBase connector supported precisionThis closes #12627,1
[FLINK-18294][e2e] Log java processes and disk usage,2
[hotfix][metrics][docs] Fix typo,2
[FLINK-18304][metrics][docs] Add example interval configuration to all supporting reporters,1
[FLINK-18304][metrics] Document default reporter interval,2
[FLINK-18209] Replace slave with worker in docker cluster test scripts,3
[FLINK-18134][FLINK-18135][docs] Add documentation for Debezium and Canal formatsThis closes #12632,2
[hotfix][docs] Improve HBase and JDBC connector documentation,2
[hotfix][FLINK-18314][docs] Fix wrong documentation in Kafka SQL Connector page,2
[hotfix][docs] Rearrange the order of SQL connectors in sidebar,2
"[FLINK-18311] Fix StreamingKafkaITCase on Kafka 2.4.1This was broken because the behaviour of the Kafka/ZooKeeper commandline tools on Kafka 2.4.1 is slightly different:zookeeper_shell.sh does not print debug output to stderr as it didbefore. We change queryBrokerStatus() to instead consume stdout andcheck that we get valid information for the broker.The output of kafka-topics.sh now has a space between ""PartitionCount:""and the partition count. Before we had ""PartitionCount:2"", now it's""PartitionCount: 2"". We fix this by making the regex more lenient.This also splits the waiting on ZooKeeper/Kafka into two loops to bettersee which one we're blocking on.",1
"[FLINK-18311] Make StreamingKafkaITCase more resilientBefore, it could happen that the new messages written in the test werenot written to the new partition. Now we use explicit keys of which weknow that they will hash to the second partition.You can verify this by changing ""key"" to ""keya"". The test will then faildeterministically.",5
[hotfix] Code cleanup: remove useless parameter from Environment#enrich method,2
[FLINK-18161][sql-client] Fix state retention config does not work in sql client,1
[FLINK-18161][sql-client] Fix configurations from flink-conf.yaml overwrite sql-client's propertiesThis closes #12643,5
[FLINK-17976][doc] Synchronize Chinese native Kubernetes document,2
[FLINK-17824][tests] Fix resume_savepoint e2e test by slowing down the Source (#12671)Fix test_resume_savepoint.sh e2e test by slowing down the Source.This prevents it from generating too much data to consume by the downstream which can lead to test timeouts (see FLINK-17824 for more information).,5
[FLINK-18291][e2e] Introduce timeout into Streaming File Sink s3 test,3
[hotfix][docs] Fix typo in operations playgroundThis closes #12663,2
[hotfix][docs] Fix broken link,2
[FLINK-18086][tests] Support to set standard inputs for AutoClosableProcess,1
[FLINK-18086][e2e] Migrate SQLClientKafkaITCase to use DDL and new options to create tablesThis closes #12657,1
[FLINK-18302][sql-cli] Fix SQL client uses wrong class loader when execute INSERT statements,0
[FLINK-18303][filesystem][hive] Fix Filesystem connector doesn't flush part files after rolling intervalThis commit introduces option 'sink.rolling-policy.check-interval' (default 1min) to control the frequency to check part file rollover.,2
"[FLINK-18238][checkpoint] Broadcast CancelCheckpointMarker while executing checkpoint aborted by coordinator RPCIn the case of aborting checkpoint RPC from CheckpointCoordinator, it will prevent executing the respective checkpoint which was already triggered before. But we also need to broadcast theCancelCheckpointMarker before exiting the execution , otherwise the downstream side wouldprobably wait for barrier alignment until deadlock.This closes #12664.",2
[FLINK-18332][state] Add error message to precondition in KeyGroupPartitionedPriorityQueueThis closes #12508.,0
[FLINK-18072][hbase] Fix HBaseLookupFunction can not work with new internal data structure RowDataThis closes #12594,5
[hotfix][e2e] Add 'flink' prefix to flink log backup directory,2
[FLINK-18301][e2e] Backup kafka logs on failure,0
[FLINK-17269][docs-zh] Translate new Training Overview to ChineseThis closes #12311,1
[FLINK-17005][docs-zh] Translate the CREATE TABLE ... LIKE syntax documentation to ChineseThis closes #12313,1
[FLINK-18329][legal] Fix typo,2
[FLINK-18331][legal] Sort NOTICE entries,2
[FLINK-18326][legal] Updated kubernetes NOTICE,5
[FLINK-18328][legal] Updated blink-planner NOTICE,2
[FLINK-14511][Deployment / YARN] Checking YARN queues with  root prefixThis closes #9978.,0
[FLINK-18330][python][legal] Update the NOTICE file of flink-python module adding beam-runners-core-java and beam-vendor-bytebuddyThis closes #12692.,1
[FLINK-16795][e2e] Increase e2e execution timeout +20m,1
"Revert ""[FLINK-17800][roksdb] Support customized RocksDB write/read options and use RocksDBResourceContainer to get them""This reverts commit f1250625b2ade530fa2619d6e1bb734832748d31.",4
"Revert ""[FLINK-17800][roksdb] Ensure total order seek to avoid user misuse""This reverts commit 8ca388ca0225ff22f532c8a65f97d8cfea027c22.",4
[FLINK-18094][network] Fixed UnionInputGate#getChannel.The method assumed that the gates have consecutive indexes starting at 0.,1
"[FLINK-18094][network] Add InputGate#getChannelInfos for easier testing.In the following commits, this method will be used to fetch information about all channels without explicitly needing to access the channels. Thus, for tests mocks just need to return meaningful InputChannelInfos instead of actually creating the respective channels.",1
[FLINK-18094][network] Simplifying InputProcessorUtil by delegating createCheckpointedInputGate to createCheckpointedMultipleInputGate.,1
[FLINK-18094][network] Using lists instead of collections of gates while creating checkpoint handlers.The actual implementation have been lists all along and we assume ordering anyways.,0
"[FLINK-18094][network] Buffers are only addressed through InputChannelInfo.This removes the need to translate the InputChannelInfo back and forth to flattened indexes across all InputGates.All index-based data structures are replaced by maps that associate a certain state to a given InputChannelInfo. For performance reasons, these maps are fully initialized upon construction, such that no nodes need to be added/removed during runtime and only values are updated.Additionally, this commit unifies the creation of BarrierHandlers (similar signature) and removes the error-prone offset handling from CheckpointedInputGate.",1
"[FLINK-18299][json] Fix the non SQL standard timestamp format in JSON formatThe current timestamp format in JSON format is not SQL standard which uses RFC-3339. This commit changes the default behavior to parse/generate timestamp using SQL standard. Besides, it introduces an option ""json.timestamp-format.standard"" to have the ability to fallback to ISO standard. This closes #12661",5
[FLINK-18242][state-backend-rocksdb] Remove the deprecated OptionsFactory and related classesThis closes #12683.,4
[hotfix][docs] Fix typo in sql queries,2
[FLINK-18236] fix es connector test ElasticsearchSinkTestBase.runElasticsearchSink* verify not right.,3
[hotfix][e2e] Fix package name+,0
[FLINK-18290][checkpointing] Don't System.exit on CheckpointCoordinator failure if it is shut down,0
[FLINK-17019][runtime] All pending requests removal goes to SlotPool#removePendingRequest() for centrally management,4
[FLINK-17019][runtime] Fulfill slot requests in request orderThis is to avoid slot competitions between slot allocation bulks which can lead to resource deadlocks.,2
[hotfix][runtime] Make DualKeyLinkedMap package private,2
[FLINK-17019][runtime] Make clear the iteration order contract of DualKeyLinkedMap,2
[FLINK-17019][runtime] Enable DualKeyLinkedMap for querying primary/secondary key with a given secondary/primary key,2
[FLINK-17019][runtime] Change primary key re-insertion in DualKeyLinkedMap to not affect the insertion order,2
[FLINK-17019][runtime] Remap orphaned slot allocation to pending slot request which just lost its allocation,2
[FLINK-18272][table-runtime-blink] Add retry logic to FileSystemLookupFunctionThis closes #12651,5
[FLINK-18300][sql-client] SQL Client doesn't support ALTER VIEWThis closes #12655,1
[FLINK-18319][notice] Lack LICENSE.protobuf in flink-sql-orcThis closes #12675,2
[FLINK-17383] Do not use CollectionEnvironment in flink-planner tests,3
"Revert ""[FLINK-17126][java] Introduce CollectionPipelineExecutor for CollectionEnvironment""This reverts commit c983ac9c49b7b58394574efdde4f39e8d33a8582.",4
[hotfix][table-api-java] Add missing @PublicEvolving annotations to classes in flink-table-api-javaThis closes #12694,2
[FLINK-16589][table-planner-blink] Split code for AggsHandlerCodeGeneratorThis closes 11512,0
[FLINK-18310][metrics] Properly handle interval parsing errors,0
[hotfix][metrics] Only parse reporter interval if required,1
[FLINK-18289][Checkpoint] Ensure notifyCheckpointAborted interface work in UDF operator,1
[hotfix][FLINK-18071] Temporarily ignore CoordinatorEventsExactlyOnceITCaseThis @Ignore must be un-done after the proper fix is implemented.,0
[FLINK-18358] Fix comparing double in TableEnvironmentITCaseThis closes #12703,1
[hotfix] Fix import checkstyle violation in TaskManagerRunnerThis closes #12705.,1
[hotfix][build] Adjust the file permission for update_japicmp_configuration.sh,5
[FLINK-18368][tests] Cleanup Kerberos settings after test.That way successive unit tests that reuse the JVM will not suffer from anincompatible initial configuration.,5
[FLINK-18343][e2e] Refactor file-line replacement into separate method,2
[FLINK-18343][e2e] Set Flink rootLogger to DEBUG,0
[hotfix][FLINK-18369] Temporarily disable unstable test,3
[FLINK-18370][Azure] Run tests nightly on Azure VMs,3
[hotfix][security] Remove never thrown exception in method signature,4
[hotfix][security] Make the credential variable names to be more descriptive,1
[FLINK-18205][security] Mitigate the use of reflection in HadoopModule,1
[FLINK-18205][security] Mitigate the use of reflection in Utils,1
"[FLINK-18119][table-blink] Expire state automatically and accurately for time range bounded over aggregationThis changes the state expiration behavior for RowTimeRangeBoundedPrecedingFunction and ProcTimeRangeBoundedPrecedingFunction. In the previous version, we use TableConfig.setIdleStateRetentionTime to cleanup state when it is idle for some time. However, a bounded over aggregation is just like a processing/event-time interval join or window aggregation, the state size should be bounded and stable. The operator should expire state automatically based on watermark and processing time without losing correctness.This closes #12680",1
[FLINK-18254][docs][table] Add documentation for primary key syntaxThis closes #12713,2
[hotfix][docs-zh] Translate navigation title into Chinese,2
[FLINK-17998][hs] Support Flink history server archive size limitationThis closes #12636.,2
[FLINK-10213] Task managers cache a negative DNS lookup of the blob server indefinitely* Added a test case for unresolved InetSocketAddresses that fails before the fix* Updated BlobClient to create the socket using the hostname and portAdded a check in the BlobClientTest.testUnresolvedInetSocketAddress() that the client is connected.This closes #6862.,3
[FLINK-17544][jdbc] Fix NPE and resource leak problem in JdbcOutputFormatThis closes #12712,5
[FLINK-18315][table-planner-blink] Fix INSERT INTO partitioned table with VALUES doesn't work correctlyThe VALUES would be patched up with partition fields.This closes #12677,1
"[FLINK-18381] Update Jekyll to 4.0.1Building the docs with Ruby 2.7 and Jekyll 4.0.0 spits out a lot ofwarnings, see https://github.com/jekyll/jekyll/issues/7947. Updating to4.0.1 fixes this.",0
"[FLINK-18377] Rename ""Flink Master"" back to JobManager in documentation",2
"[minor] Fix naming discrepancy in flink-architecture.mdBefore, we used JobManager/Flink Workers, not we useJobManager/TaskManagers for the section titles.",1
[FLINK-18378] Improve CatalogTable schema resolutionThis closes #12725,2
[FLINK-18352] Make DefaultClusterClientServiceLoader/DefaultExecutorServiceLoader thread-safeThis closes #12719.,1
[hotfix] Annotate the DefaultClusterClientServiceLoader as internal,0
"[FLINK-18392][docs-zh] Translate ""Debezium Format"" page into ChineseThis closes #12731",1
"[FLINK-18390][docs-zh] Translate ""JSON Format"" page into ChineseThis closes #12733",1
"[FLINK-17769] Wrong order of log events on a task failureWhen a task failure occurs, the error of disposing of an operator is loggedbefore the real rootcasue is printed, which is confusing.This fix suppressed exception occurring in disposing of an operator andattached the exception together with the rootcause.",1
[minor] Rename Flink Master to JobManager in processes.svgThis was missed in the recent renaming of Master back to JobManager.,2
"[minor] Rename ""Flink Worker"" to TaskManager in flink-architecture.mdThis makes it more in line with using JobManager for the other majorcomponent.",1
[FLINK-18372][runtime] Fix NPE problem when a slot is offered before JM is connected to a RM,0
"[hotfix][config] Remove CheckpointConfig#enableUnalignedCheckpoints without parameters.CheckpointConfig#enableUnalignedCheckpoints(boolean) makes it explicit and also is more future-proof. When unaligned checkpoints become the default, this method will be mostly useless and we would need to add a #disableUnalignedCheckpoints() for consistency.",1
[FLINK-18403][checkpointing] Ensure that unaligned checkpointing is only activated for EXACTLY_ONCE.,2
[hotfix][javadoc] Fix typo in CheckpointConfig#enableUnalignedCheckpoints java doc,2
[FLINK-17258][tests] Enabling unaligned checkpoint in all tests by default.,3
"[FLINK-18406] Add Nullable annotation to DualKeyLinkedMap.getValueByKeyA[FLINK-18406] Add Nullable annotation to DualKeyLinkedMap.getValueByKeyB[FLINK-18406] Add NullableAnnotation to DualKeyLinkedMap.getKeyAByKeyB[FLINK-18406] Add Nullable annotation to DualKeyLinkedMap.getKeyBByKeyA[FLINK-18406] Add Nullable annotation to DualKeyLinkeMap put, removeKeyA and removeKeyBThis closes #12738.",4
[hotfix] Remove unused SlotPoolImpl.get(SlotRequestId),1
[FLINK-17678][hbase] Add flink-sql-connector-hbase module to provide uber jar for HBase connectorThis closes #12687,1
"[hotfix][FLINK-18412] Fix JdbcFullTest failed to compile on JDK11This reverts the new added test in JdbcFullTest in ""[FLINK-17544][jdbc] Fix NPE and resource leak problem in JdbcOutputFormat"".",5
"[FLINK-18385][docs-zh] Translate ""DataGen SQL Connector"" page into ChineseThis closes #12730",1
"[FLINK-18353] Make enabling of the JVM Direct Memory limit configurable for JMThe JVM Direct Memory leak is unlikely in JM. Therefore, we coulddisable its limit by default. This way it could span into e.g. JVMOverhead w/o failure to improve the user experience as before FLIP-116.If user needs the limit, e.g. to investigate container OOMs, the limit can be enabled bysetting the 'jobmanager.memory.enable-jvm-direct-memory-limit' option.This closes #12745.",0
[hotfix] Fix checkstyle violations in JobManagerProcessUtilsTest,3
[hotfix] Fix checkstyile violations in BashJavaUtilsTest,3
[hotfix][core] Fix typo in SerializationSchema,2
[FLINK-18380][examples-table] Add a ChangelogSocketExample,4
[hotfix][table-common] Fix typo in EncodingFormatFactory,2
[FLINK-18066][docs] Rename old Table source/sink doc tolegacySourceSinks.md,2
[FLINK-18066] Add new Table source/sink documentationThis closes #12724.,2
[hotfix][table-common] Fix typos in docs of new source/sink interfaces,1
[FLINK-18360][history] Eagerly initialize overview files,2
[FLINK-18313][docs] Update Hive dialect doc about VIEWThis closes #12666,2
[FLINK-18320][hive][lega] Update licensing,5
"[FLINK-18359] Log failures in handler instead of ElasticsearchSinkBaseThis allows more control for the handler whether or not to log errormessages. In some cases, users know that they will get a lot offailures, for example when back-filling existing data in ES. For those,you don't want your log flooded with ERROR messages.",0
[hotfix][runtime] Fix code style in RunningJobsRegistryThis closes #11997.,1
[hotfix][runtime] Fix code-style in ZooKeeperJobGraphStoreThis closes #11996.,0
[hotfix][yarn] Remove the useless static variable of flink.yarn.Utils#DEFAULT_KEYTAB_FILEThis closes #11992.,2
[FLINK-17297] Log the lineage information between ExecutionAttemptID and SlotRequestIDThis closes #11850.,5
[hotfix][runtime] Simplify SlotPoolImpl#maybeRemapOrphanedAllocation,0
[FLINK-18407][runtime] Harden SlotPoolImpl#maybeRemapOrphanedAllocation,2
[FLINK-17298] Log the lineage information between SlotRequestID and AllocationIDThis closes #11851.,5
[hotfix][examples-table] Fix indention in ChangelogCsvFormat,4
[hotfix][docs] Fix wrong heading in user-defined function docs,2
"[FLINK-18283][API/Core,API/DataStream] Update outdated Javadoc for clear method of ProcessWindowFunction",1
[hotfix] [table-api-java] correct the logic of `truncateString` method in PrintUtils,3
[FLINK-18399][table-api-java] Fix TableResult#print can not print the result of unbounded stream queryThis closes #12728.,0
[FLINK-18348] RemoteInputChannel should checkError before checking partitionRequestClient,0
[hotfix][table] fix typos in PlannerBase javadoc,2
[hotfix][table] fix typos in TableEnvironment javadoc,2
[hotfix][table] Code cleanup: use new methods introduced in FLIP-84 instead of deprecated methods,1
[FLINK-17599][docs] Update documents due to FLIP-84,2
[FLINK-17599][docs] Add documents for DESCRIBE statement,2
[FLINK-17599][docs] Add documents for EXPLAIN statement,2
[FLINK-17599][docs] Add documents for USE statement,1
[FLINK-17599][docs] Add documents for SHOW statement,2
[FLINK-18416][table-common] Deprecate TableEnvironment#connect APIThis closes #12755,2
[FLINK-18194][walkthroughs] Remove table walkthrough archetype,4
[FLINK-18194][walkthroughs] Document new table walkthroughThis closes #12592,1
[FLINK-18351][table] Fix ModuleManager creates a lot of duplicate/similar log messagesThis closes #12757,2
[FLINK-18353] Update untranslated Chinese memory config doc files,2
[hotfix] Fix the access modifiers in TaskManagerRunner,1
[hotfix] Simplify the lambda expression in TaskManagerRunner,1
[FLINK-17579] Allow user to set the TaskManager ResourceID in standalone modeThis closes #12054.,1
[FLINK-18420][tests] Disable failed test SQLClientHBaseITCase in java 11This closes #12760,3
[FLINK-12489][Mesos] Add network resource paramter,2
[FLINK-12489][Mesos] Parametrize network resource by nameThis closes #8652.,1
[FLINK-14938] Use ConcurrentLinkedQueue in BufferingNoOpRequestIndexerThis solves the problem of concurrent modification when re-adding ESindex requests from a failure handler.,0
[FLINK-17639] Document which FileSystems are supported by the StreamingFileSinkThis closes #12737.,2
[FLINK-18425][table] Convert object arrays to primitive arrays in GenericArrayDataThis closes #12762.,5
"[FLINK-18426] Remove incompatible deprecated keys from ClusterOptionsClusterOptions.INITIAL_REGISTRATION_TIMEOUT, MAX_REGISTRATION_TIMEOUT and REFUSED_REGISTRATION_DELAYhave incompatible deprecated options of type Duration associated. This causes the system to failif they are specified. Since the deprecated keys have not been used for a very long time, this commitwill remove the deprecated keys from the ClusterOptions.This closes #12763.",4
[FLINK-18429][DataStream API] Make CheckpointListener.notifyCheckpointAborted(checkpointId) a default method.This avoid breaking many user programs that use this interface.This closes #12767,1
[hotfix][DataStream API] Fix checkstyle issues and JavaDocs in CheckpointListener.,2
[FLINK-18430][DataStream API] Classify CheckpointedFunction and CheckpointListener as @PublicThis closes #12767,1
[FLINK-18428][API/DataStream] Rename StreamExecutionEnvironment#continuousSource() to StreamExecutionEnvironment#source().This closes #12766,5
[FLINK-18168][table-runtime-blink] Fix array reuse for BinaryArrayData in convertersThis closes #12542.,5
[FLINK-17300] Log the lineage information between ExecutionAttemptID and AllocationIDThis closes #11852.,5
[FLINK-18417][table] Support List as a conversion class for ARRAYThis closes #12765.,1
[FLINK-18349][docs] Add release notes for Flink 1.11,2
fixup! [FLINK-18349][docs] Add release notes for Flink 1.11,2
[FLINK-17800][rocksdb] Ensure total order seek to avoid user misuse,1
[hot-fix][rocksdb] Ensure RocksDBKeyedStateBackend disposed at RocksDBStateMisuseOptionTestThis closes #12736.,5
[FLINK-17800][rocksdb] Support customized RocksDB write/read options and use RocksDBResourceContainer to get them,1
"[FLINK-18396][docs-zh] Translate ""Formats Overview"" page into ChineseThis closes #12775",1
"[FLINK-18386][docs-zh] Translate ""Print SQL Connector"" page into ChineseThis closes #12758",1
"[FLINK-18393][docs-zh] Translate ""Canal Format"" page into ChineseThis closes #12771",1
[FLINK-17292][docs-zh] Translate Fault Tolerance training lesson to ChineseThis closes #12727,1
"[FLINK-18198][docs-zh] Translate ""HBase SQL Connector"" page into ChineseThis closes #12644",1
"[FLINK-18423][docs] Fix Prefer tag in document ""Detecting Patterns"" page of ""Streaming Concepts""This closes #12764",2
[hotfix][doc] Add memory model figure for JM detailed configuration.,5
[hotfix][doc] Remove total process/flink memory from JM detailed memory configuration table.,5
[hotfix][doc] Replace 'Master' with 'JobManager' in memory configuration migration guide.,5
[hotfix][doc] Minor clean-ups in memory configuration docs.,2
[hotfix][doc-zh] Fix broken links to rocksdb state backend section,5
[FLINK-17465][doc-zh] Update translations for memory configurations.This closes #12761.,5
[FLINK-18324][docs-zh] Translate updated data type into ChineseThis closes #12748,1
[FLINK-18439][docs] Update sql client jar url in docsThis closes #12783,2
"[FLINK-12428][docs-zh] Translate the ""Event Time"" page into ChineseThis closes #12442",1
[FLINK-16976][docs-zh] Update chinese documentation for ListCheckpointed deprecationThis closes #12621,2
[FLINK-18435][metrics] Add support for intercepting reflection-based instantiations,1
[FLINK-18435][metrics] Adjust reporter factories to intercept reflection-based instantiations,2
[FLINK-18064][python] Adding unaligned checkpoint config options.,5
[hotfix][conf] Fix javadoc of CheckpointConfig#isUnalignedCheckpointsEnabled.,5
[hotfix][docs] Fix broken link in metrics.md.,2
[FLINK-18064][docs] Added unaligned checkpointing to docs.It's split into 3 parts to simulate the description of aligned checkpointing:- It's added on conceptual level in stateful-stream-processing.md with new/revised pics. It's written in a way that it could survive 1.12 without change.- A small change to dev/stream/state/checkpointing.md to show how it is enabled programmatically in Java/Scala/Python. Might need to be extended for 1.12 when new options become available (depending whether they can be programmatically changed or not).- A larger discussion in ops/state/checkpoints.md which includes the current limitations and a small glimpse into the next steps (will be in much more detail in blog post). This part needs to be largely rewritten for 1.12+ to reflect the new options.,1
[hotfix][docs] Replace/fix links in checkpointing documents.,2
[FLINK-17920][python][docs] Add the Python example of the Interval Join (#12779),1
[hotfix][docs] Fix Python example in the documentation about event_timeThis closes #12789.,2
"[FLINK-18394][docs-zh] Translate ""Parquet Format"" page into ChineseThis closes #12772",1
[hotfix][doc] Fix typo in TableConfig.java/hive_catalog.md/hive_catalog.zh.mdThis closes #12795,5
[hotfix] Fix broken links in release notes for 1.11,2
[hotfix] Fix broken links in Chinese 1.11 release notes,2
[hotfix][docs] Fix IDE setup typo,2
[FLINK-18455][build] Activate Java 11 profile also on later Java versions,2
[FLINK-18186][doc] Various updates on standalone kubernetes documentThis commit introduces the following updates.* Remove spec.replicas and spec.selector in jobmanager-job.yaml* Set NodePort to 30081 in jobmanager-rest-service.yaml* Use array of string for Container.args in jobmanager-job.yaml* Remove query-state port for jobmanager yaml and add to taskmanager yaml* Use log4j-console.properties for loggingThis closes #12690.,2
[FLINK-18186][doc] Add taskmanager query state service in standalone kubernetes document,2
"[FLINK-15794][Kubernetes] Generate the Kubernetes default image versionThe default image used by Kubernetes is 'flink:latest' which causes version compatibility problemsif the latest it not exactly the same as what you are using.The commit derives the default value from the actual Flink and Scala version,which the running Flink was built with (i.e. no longer latest).The latest tag is used only for snapshot versions until we have snapshot builds for docker images.This closes #11245.",2
[hotfix][checkpointing] Extract CheckpointFailureManager.handleCheckpointException method,0
[FLINK-18336][checkpointing] Ignore failures of past checkpoints in CheckpointFailureManagerPast checkpoints are subsumed checkpoints and savepoints.,0
[hotfix] Extend 1.11 release notes with more information about JM memory configuration,5
[FLINK-18125][Azure] Skip e2e execution on docs-only-PRsThis closes #12708,2
[hotfix] Fix flink-connector-hive NOTICE fileCorrectly state org.apache.parquet:parquet-format:2.4.0 as bundled dependency,2
[hotfix] Fix flink-connector-kinesis NOTICE fileCorrect bundled dependencies in NOTICE file:com.amazonaws:aws-java-sdk-dynamodb:jar:1.11.754 -> com.amazonaws:aws-java-sdk-dynamodb:jar:1.11.603com.amazonaws:aws-java-sdk-s3:jar:1.11.754 -> com.amazonaws:aws-java-sdk-s3:jar:1.11.603com.amazonaws:aws-java-sdk-kms:jar:1.11.754 -> com.amazonaws:aws-java-sdk-kms:jar:1.11.603,5
[hotfix] Fix flink-sql-parquet NOTICE fileRemove unused dependency org.apache.commons:commons-compress:1.20 from NOTICE fileThis closes #12811.,2
[FLINK-18472][docs] Local Installation Getting Started GuideThis closes #12810,1
[FLINK-18469][docs] Include Application Mode in 1.11 release notesThis closes #12809.,3
[FLINK-15416][network] Retry connection to the upstream task,1
[FLINK-15416][network] Remove ignored PartitionRequestClientFactoryTest.testResourceReleaseAfterInterruptedConnectThe test was ignored for 5 years already.,3
"[FLINK-18395][FLINK-18388][docs-zh] Translate ""ORC Format"" and ""CSV Format"" page into ChineseThis closes #12774",1
"[FLINK-18391][docs-zh] Translate ""Avro Format"" page into ChineseThis closes #12796",1
[hotfix] Add nohive classifier to orc-core in flink-sql-connector-hive:1.2.2 NOTICE file,2
[FLINK-18471] Remove references to org.uncommons.maths:uncommons-maths:1.2.2a in flink-runtime,2
[FLINK-18462][table-planner-blink] Improve the exception message when INSERT INTO mismatch types for empty charThis closes #12806,2
[FLINK-18461][table-planner-blink] Fix Changelog source can't be insert into upsert sink,4
[FLINK-18470] Ensure rocksdb is loaded in RocksKeyGroupsRocksSingleStateIteratorTest,3
[FLINK-18240][table-planner-blink] Allow to use % as modulus functionThis closes #12818,1
"[FLINK-18457][docs] Fix invalid links in ""Detecting Patterns"" page of ""Streaming Concepts"" This closes #12802",2
[FLINK-18422][docs] Update Prefer tag in documentation 'Fault Tolerance training lesson'This closes #12778,5
[FLINK-17761][connector/common] Add a constructor taking capacity as a parameter for FutureCompletingBlockingQueueThis closes #12566,2
[FLINK-16230][tests] Remove unnecessary for iterables from DeeplyEqualsCheckerAn equality check for Iterable differs significantly based on aparticular implementation. Therefore we should not have a generic way ofcomparing an iterable in the class. We should rather assume theyimplement a proper equals method or the logic is injected only in anaffected test.This closes #11181,3
[FLINK-18485] Update java to 8u251 in yarn docker kerberized test,3
[hotfix] Remove section about as-a-library from flink-architecture.mdThis describes possible future work and partially the describedfunctionality is already available with application mode.,1
[FLINK-18173][docs] Update missing release notes for flink-json and flink-csv packaging,2
[FLINK-18488][python] Added additional params to CsvTableSource constructorThis closes #12824.,2
"[FLINK-18387][docs-zh] Translate ""BlackHole SQL Connector"" page into ChineseThis closes #12797",1
[hotfix][elasticsearch] Fix validation message for 'sink.bulk-flush.max-actions' of ElasticsearchThis closes #12790,5
[FLINK-18501] Use inner class name for logging scheme mapping when filesystems are instantiated,5
[FLINK-18507][python] Move get_config implementation to TableEnvironment (#12830),5
[FLINK-18486][docs] add document for '%' module functionThis closes #12831,1
[hotfix] Update japicmp configuration for 1.11.0,5
[FLINK-18514][build] Bump groovy to 2.5.12,2
[FLINK-17075][coordination] Reconcile deployed Executions,2
[FLINK-18519][REST] Send exception to client when app fails to executeThis closes #12845.,0
[hotfix] Harden JarDeleteHandlerTest test,3
[FLINK-18458][build] Rename java.version property,5
[FLINK-18097][history] Delete all job-related files on expiration,2
"[FLINK-15414] catch the right KafkaException for binding errorsThe right exception should be `org.apache.kafka.common.KafkaException` instead of `kafka.common.KafkaException`At least the ""numTries"" exception should be thrown instead of the binding exception.",0
[FLINK-18502][FLINK-18505][docs] Add the missing 'legacySourceSinks.zh.md' page and synchronize content of 'sourceSinks.zh.md'This closes #12854,1
[FLINK-18524][table-common] Fix type inference for Scala varargsThis closes #12853.,5
[hotfix][docs] Improve data type documentation for Scala users,1
[FLINK-18520][table] Fix unresolvable catalog table functionsThis closes #12857.,1
[FLINK-17000][table] Ensure that every logical type can be represented as TypeInformationIntroduces a WrapperTypeInfo that can replace most (if not all) TypeInformation classesin the Blink planner. It is backed by logical types and uses internal serializers.This closes #12852.,1
[FLINK-18490][python] Refactor PythonFunctionRunner to make it more generalThis closes #12841.,1
[FLINK-18533][coordination] Disable cancellation of unknown deploymentsTemporarily disabled due to stability issues.,0
[FLINK-18534][kafka][table] Fix unstable KafkaTableITCase.testKafkaDebeziumChangelogSource This closes #12858,3
[FLINK-18484][core] Add length difference to arity exception in RowSerializer,1
[FLINK-18478] Use AvroFactory.extractAvroSpecificSchema in AvroDeserializationSchemaThis makes AvroFactory and the used method public where they werepackage private before.This fixes the problem that AvroDeserializationSchema was not workingwith types generated from avrohugger. It could also just be seen asrefactoring/code cleanup.,4
[FLINK-18453][tests] Fix overflow of AggregateITCase#testAggregationCodeSplitThis closes #12861,3
[FLINK-15221][kafka][table] Support sink delivery semantic for Kafka in Table APIThis closes #12805,1
[FLINK-18369] Fix instable TableEnvironmentITCase#testStatementSetWithSameSinkTableNamesReplaced TestingOverwritableTableSink with UnsafeMemoryAppendTableSinkas the first uses DataSet#writeAsText. This sink cannot be used twicewith the same path in a single JobGraph.,1
[FLINK-18434] Fix getter methods of AbstractJdbcCatalog,5
[hotfix] Extend ClassLoaderUtils with a way to add resources,1
[FLINK-18419] Make user ClassLoader available in TableEnvironment,1
[FLINK-18419] Create catalog in TableEnvironment using user ClassLoader,1
[FLINK-18361][es][table] Support username and password options for new Elasticsearch connectorCo-authored-by: zhisheng17 <zhisheng2018@gmail.com>This closes #12715,1
[hotfix][doc] Fix temporal_tables correlate with a changing dimension table section,4
[FLINK-18561][python] Build manylinux1 with better compatibility instead of manylinux2014 Python Wheel PackagesThis closes #12869.,1
[FLINK-18526][python][docs] Add documentation for Python UDF on how to use managed memoryThis closes #12855.,1
[FLINK-18324][docs-zh] Translate updated udf into ChineseThis closes #12794,1
"[FLINK-18539][datastream] Fix StreamExecutionEnvironment#addSource(SourceFunction, TypeInformation) doesn't use the user defined type informationThis closes #12863",5
[FLINK-18552][tests] Update migration tests of CEPMigrationTest to cover migration till release-1.11,3
[FLINK-18552][tests] Update migration tests of BucketingSinkMigrationTest to cover migration till release-1.11,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaConsumerBaseMigrationTest to cover migration till release-1.11,3
[FLINK-18552][tests] Update migration tests of ContinuousFileProcessingMigrationTest to cover migration till release-1.11,3
[FLINK-18552][tests] Update migration tests of WindowOperatorMigrationTest to cover migration till release-1.11,3
[FLINK-18552][tests] Update migration tests of StatefulJobSavepointMigrationITCase to cover migration till release-1.11,3
[FLINK-18552][tests] Update migration tests of StatefulJobWBroadcastStateMigrationITCase to cover migration till release-1.11,3
[FLINK-18528][table] Update UNNEST to new type systemThis closes #12862.,5
[hotfix][examples-table] Add missing format validation,5
[FLINK-18477][examples-table] Fix packaging of ChangelogSocketExampleThis closes #12884.,4
[FLINK-18002][json] Correct the behavior for ContainerNode as varchar typeThis closes #12421,5
[FLINK-16827][table-planner-blink] StreamExecTemporalSort should require a distribution trait in StreamExecTemporalSortRule.This closes #11643,1
[FLINK-18532][docs] Remove beta tag from MATCH_RECOGNIZEThis closes #12889,4
"[FLINK-18440][table-planner-blink] ROW_NUMBER function: ROW/RANGE not allowed with RANK, DENSE_RANK or ROW_NUMBER functionsThis closes #12868",1
[FLINK-18585][elasticsearch] Fix dynamic index doesn't work in new elasticsearch table sinkThis closes #12886,1
[hotfix][docs] Add 1.11 to the list of previous docs,2
[FLINK-16181][table-planner-blink] Fix IfCallGen throw NPE when operand's resultTerm is nullThis closes #11161,0
[FLINK-18529][hive] Query Hive table and filter by timestamp partition can failThis closes #12856,0
[FLINK-18593][doc] Hive bundle jar URLs are brokenThis closes #12896,2
[FLINK-18491][python] Extract the Beam specific coder classes into a separate Python moduleThis closes #12870.,4
[hotfix][table-planner-blink] Fix digest for inline structured types with generics,0
[hotfix][table-planner-blink] Fix row size estimation for structured types,0
[FLINK-18586][table-common] Simplify the creation of explicit structured typesThis closes #12887.,1
[hotfix][table-common] Update DataTypeUtils.transform for structured types,5
[FLINK-18591][metrics][documentation] Fix the format issue for metrics web page,0
[FLINK-18583][elasticsearch] Fix ElasticSearch6 sink uses index as document idThis closes #12890,2
[hotfix][docs] fix spelling,0
[hotfix][docs] Fix table example code,0
[FLINK-18573][metrics][influxdb] Fix services directory name,0
[FLINK-18573][metrics] Add test for loading reporters via service loader,3
[FLINK-17636][tests] Fix unstable test SingleInputGateTest#testConcurrentReadStateAndProcessAndClose,3
[FLINK-18594][doc] The link is broken in kafka docThis closes #12897,2
"[FLINK-18600] Temporary disable kerberized e2e yarn testsThe tests use oracle jdk, which we can no longer download withoutlogging in. This commit disables the affected tests until we find asolution.",3
[FLINK-18594][doc](follow-up) The link is broken in kafka doc,2
[FLINK-18618] Disable docker e2e tests,3
[FLINK-18619][docs] Update training to use WatermarkStrategyThis closes #12915,1
[FLINK-18163][task] Add RecordWriter.volatileFlusherException,1
[hotfix][docs-zh] Fix invalid links in the page 'dev/table/streaming/match_recognize.zh.md' (#12895),2
"[FLINK-16087][docs-zh] Translate ""Detecting Patterns"" page of ""Streaming Concepts"" into ChineseThis closes #12798",1
[FLINK-18569][table] Support limit() for unordered tablesThis closes #12904.,1
[hotfix] Suppport ITEM for ROW types.,0
[FLINK-18286] Fix type inference for GET & AT Calcite functionsThis commit fixes how Calcite infers/derives types for accessing nested columns of a ROW type.,5
[hotfix] Reuse a Flink cluster for expressions tests.,3
[FLINK-18286] Implement type inference for GET/FLATTEN,1
[FLINK-18618] Fix syntax error when disabling docker e2e tests,3
[FLINK-18588][hive] hive ddl create table support 'if not exists'This closes #12888,1
"[FLINK-18463][python] Make the ""input_types"" parameter of the Python UDF/UDTF decorator optional.This closes #12921.",2
"[FLINK-17285][python][doc-zh] Translate ""Python Table API"" page into ChineseThis closes #12901.",1
[FLINK-18618] Disable remaining docker e2e tests,3
[FLINK-18492][python] Extract the Beam specific operation classes into a separate Python moduleThis closes #12903.,4
[hotfix][doc] fix time duration unit in filesystem docThis closes #12925,2
[FLINK-18639][scripts] Print raw output from BashJavaUtils in case of execution failure.This closes #12933.,0
[FLINK-18618] Use moby engine instead of docker-ce,2
[FLINK-18618] Reenable docker tests,3
[FLINK-18612][fs] Fix the relative path issue in LocalFileSystemThis closes #12918,5
[FLINK-18635][docs] Fix typo on website,2
[hotfix][doc] Change TaskExecutor to TaskManager for External Resources page.,4
[hotfix][doc] Remove redundant punctuation for External Resources page.,4
[hotfix][doc] Enhance the description of options for External Resources page.,2
[FLINK-18264][doc-zh] Translate External Resources page to ChineseThis closes #12865.,1
[FLINK-18628][table-common] Fix error message for overloaded function with same parameter namesThis closes #12928.,2
[FLINK-18644][doc][hive] Remove obsolete hive connector docsThis closes #12940,2
[FLINK-18600] Upgrade kerberized yarn docker image to use openjdk,1
"Revert ""[FLINK-18600] Temporary disable kerberized e2e yarn tests""This reverts commit 9036bc0fd8b24d0a270f964a8116f5db781e4b3c.",5
[FLINK-18537][table] Remove ExecutionConfig for internal serializers,5
[FLINK-18537][table] Compare only field serializers in RowDataSerializer,5
"[FLINK-18537][table] Replace RowDataTypeInfo with InternalTypeInfoTypeInformation is a legacy class for the sole purpose of creating aTypeSerializer. Instances of TypeInformation are not required in thetable ecosystem but sometimes enforced by interfaces of other modules(such as org.apache.flink.api.dag.Transformation). Therefore, weintroduce InternalTypeInfo which acts as an adapter whenever typeinformation is required. Instances of InternalTypeInfo should onlybe created for passing it to interfaces that require type information.The class should not be used as a replacement for a LogicalType.Information such as the arity of a row type, field types, field names, etc.should be derived from the LogicalType directly.This closes #12900.",2
[hotfix][table-common] Remove unused InternalTypeInfo,5
[FLINK-17425][table-planner-blink] Support SupportsFilterPushDown on ScanTableSource in plannerThis closes #12866,1
[FLINK-18296][json] Add support for TIMESTAMP_WITH_LOCAL_ZONE type for Json formatThis closes #12756,5
[hotfix][docs] Fix hypelink typo in connect.md and connect.zh.md This closes #12936,2
[FLINK-18468][tests] Harden TaskExecutorITCase.testJobReExecutionAfterTaskExecutorTermination()This commit hardens the TaskExecutorITCase.testJobReExecutionAfterTaskExecutorTermination() byresubmitting the job under a new JobID. A JobID identifies a run of a job and should not bereused.This closes #12821.,1
[hotfix] Move ConfigOption type parsing to ConfigurationUtilsMoving the ConfigOption type parsing to ConfigurationUtils and makingConfigurationUtils.convertValue public allows to reuse the type parsinglogic for other places.,2
[FLINK-12336] HTTPS support for InfluxDbReporterThis closes #12814.,5
[FLINK-17789][core] DelegatingConfiguration should remove prefix instead of add prefix in toMapThis closes #12905,0
[FLINK-18607][build] Give the maven module a human readable nameThis closes #12907,2
[FLINK-18650][doc] Fix description of dispatcher in flink-architecture.md,2
[FLINK-18665][connector-fs] Filesystem connector should use TableSchema exclude computed columnsThis closes #12953,1
[FLINK-18558][streaming] Introduce collect iterator with at least once semantics and exactly once semantics without fault toleranceThis closes #12867,2
[FLINK-18621][sql-client] Simplify the methods of Executor interface in sql clientThis closes #12923,2
[hotfix][doc] Fix the table document errorsThis closes #12721,0
"[FLINK-16085][docs] Translate ""Joins in Continuous Queries"" page of ""Streaming Concepts"" into ChineseThis closes #12420",1
[FLINK-18672][docs] Fix Scala table UDF examplesThis closes #12961.,0
[FLINK-18671][docs] Update upgrade compatibility table for 1.11.0,5
[FLINK-15803][table] Unify validation for all kinds of UDFsExtracts the argument types early in order to perform the validationbased on AggregateInfo. The validation is the same for all kind of UDFs.This closes #12959.,5
[FLINK-18533][coordination] Tolerate pending deployments being reported,2
[FLINK-18421][checkpointing][tests] Fix logging of RejectedExecutionException during CheckpointCoordinator shutdown,2
[FLINK-18448][pubsub] Update Google Cloud PubSub dependenciesThis closes #12846,5
[FLINK-18487][table] Datagen and Blackhole factory omits unrecognized properties silentlyThis closes #12864,5
[FLINK-18667][docs] Data types documentation misunderstand usersThis closes #12976,1
[FLINK-18616][table] Add SHOW CURRENT DDLsThis closes #12934,1
[FLINK-18632][table-planner-blink] Assign the missing RowKind when toRetractStream with POJO typeCo-authored-by: luoziyu <ziyu@narvii.com>This closes #12955,2
[FLINK-18638][runtime] Add optional timeout message to FutureUtils.orTimeout,1
[FLINK-18629] Add type to ConnectedStreams#keyByAdding a generic type to the method makes it possible to pass the typefrom a lambda function. Otherwise a wildcard type '?' is derived asObject and thus TypeExtractor extract a GenericTypeInfo<Object> for thekey.,5
[FLINK-18521][release] Add script for creating snapshot branch,1
[FLINK-18552][tests] Update migration tests of FlinkKafkaProducer011MigrationTest to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaProducerMigrationOperatorTest to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaProducerMigrationTest to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of StatefulJobSavepointMigrationITCase (Java version) to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of StatefulJobWBroadcastStateMigrationITCase (Java version) to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of TypeSerializerSnapshotMigrationITCase cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of AbstractKeyedOperatorRestoreTestBase to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of AbstractNonKeyedOperatorRestoreTestBase to cover migration from 1.10,3
[FLINK-18552][tests] Update migration tests of FlinkKinesisConsumerMigrationTest to cover migration from 1.10,3
"[FLINK-15803][table] Use AggregateInfo as the single source of type descriptionThis refactors a lot of the code generation around aggregate functions. It doesthis for better code maintainability and in particular for having a single sourceof generating all types (arguments, accumulator, result).This closes #12967.",1
[FLINK-18697][table-api] Add the missing test scope to the flink-streaming-java_2.11:test-jar dependencyThis closes #12977,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaProducer011MigrationTest to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaProducerMigrationOperatorTest to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaProducerMigrationTest to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of StatefulJobSavepointMigrationITCase (Java version) to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of StatefulJobWBroadcastStateMigrationITCase (Java version) to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of TypeSerializerSnapshotMigrationITCase cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of AbstractKeyedOperatorRestoreTestBase to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of AbstractNonKeyedOperatorRestoreTestBase to cover migration from 1.11,3
[FLINK-18552][tests] Update migration tests of FlinkKinesisConsumerMigrationTest to cover migration from 1.11,3
[hotfix][docs]Fix typos in types_serialization.md and types_serialization.zh.md,2
[FLINK-18708][docs] Update the sql client jar url of kafka 0.10 and 0.11This closes #12990.,5
[FLINK-18655][flink-runtime] Set failOnUnableToExtractRepoInfo to false for git-commit-id-plugin (#12941),5
[FLINK-11547][flink-connector-kinesis] Fix JsonMappingException in DynamoDBStreamsSchema,5
[FLINK-18341][walkthroughs] Drop remaining table walkthrough archetypesThis closes #12970,5
[hotfix] Fix typo in JavaDoc in DagConnectionThis closes #12926,2
[FLINK-18710] Make ResourceProfileInfo serializableThis closes #12991.,5
[hotfix][docs] Fix 'event_driven.zh.md' doesn't add the title anchor. (#12952),1
[FLINK-18699][table-api-scala] Allow selecting fields without string interpolation in ScalaThis closes #12978.,1
[FLINK-18703][table] Use new data structure converters when legacy types are not presentThis closes #12987.,5
[FLINK-15366][table-planner-blink] Improve FlinkCalcMergeRule to merge calc nodes betterThis closes #12873,1
[FLINK-18730][docs] Remove Beta tag from SQL Client docs (#12997),2
"[FLINK-18656][network,metrics] Fix startDelay metric for unaligned checkpointsBefore this fix, startDelay metric was always set to zero for unaligned checkpoints.",1
"[FLINK-18646] Verify memory manager empty in a separate thread with larger timeoutUnsafeMemoryBudget#verifyEmpty, called on slot freeing, needs time to wait on GC of all allocated/released managed memory.If there are a lot of segments to GC then it can take time to finish the check. If slot freeing happens in RPC thread,the GC waiting can block it and TM risks to miss its heartbeat.Another problem is that after UnsafeMemoryBudget#RETRIGGER_GC_AFTER_SLEEPS, System.gc() is called for each attempt to run a cleanereven if there are already detected cleaners to run. This leads to triggering a lot of unnecessary GCs in background.The PR offloads the verification into a separate thread and calls System.gc() only if memory cannot be reserved andthere are still no cleaners to run after long waiting. The timeout for normal memory reservation is increased to 2 second.The full reservation, used for verification, gets 2 minute timeout.This closes #12980.",1
"[FLINK-18581] Do not try to run GC phantom cleaners for jdk < 8u72The private JVM method Reference#tryHandlePending was introduced at Java 8u72.The explicit processing of queued phantom GC cleaners was exposed before 8u72, also is was not used while reserving JVM direct memory.Therefore, we can only hope that the GC will be triggered and the cleaners get processed in GC after some timeout.This is suboptimal, therefore the PR changes Flink to not fail if the method is unavailable but logs a warning to upgrade Java.This closes #12981.",2
[FLINK-18281] Add window stagger to TumblingEventTimeWindow,1
"[FLINK-18595][network] Fix the deadlock of concurrently recycling buffer and releasing input channelAssuming two remote channels with buffer managers as listeners in LocalBufferPool, the deadlock happens as follows:1. While the Canceler thread calling ch1#releaseAllResources, it will occupy bm1's bufferQueue lock and try to call bm2#notifyBufferAvailable.2. While the task thread recycling exclusive buffer for ch2, then it will occupy bm2's bufferQueue lock and try to call bm1#notifyBufferAvailable.3. These two threads will both occupy the respective bm's bufferQueue lock and wait for other side's bufferQueue lock to cause deadlock.Regarding the solution, we can check the released state outside of bufferQueue lock in BufferManager#notifyBufferAvailable to return immediately.",1
"[FLINK-18656][task] Provide checkpointStartDelayNanos for SourceStreamTaskcheckpointStartDelayNanos for SourceStreamTask is meassured how long did it takefor the checkpoint triggering RPC call to finally start executing inside the mailboxthread. If the mailbox is busy, for example SourceFunction is backpressured, thistime can be quite significant.",1
[FLINK-18656][tests] Rename MultipleInputStreamTaskTestHarnessBuilder to StreamTaskMailboxTestHarnessBuilderThe orignal concept MultipleInputStreamTaskTestHarnessBuilder proved much moreversatile then initially expected and it can easily handle all of the uses cases:- MultipleInputStreamTask- OneInputStreamTask- SourceStreamTaskHence there is no need for the abstraction and no need to provide specialized versions ofMultipleInputStreamTaskTestHarnessBuilder for the other types of tasks.,3
[FLINK-18668][table-runtime-blink] BytesHashMap#growAndRehash should release newly allocated segments before throwing the exceptionThis closes #12968,1
[FLINK-FLINK-18746] Fix WindowStaggerTestThe problem was that WindowStagger.RANDOM is inclusive on the start andexclusive on the end of the interval while the test was assuming thatthe start is also exclusive.,3
[FLINK-15467][task] Wait for sourceTaskThread to finish before exiting from invoke,5
[hotfix][table] Rename UserDefinedAggregateFunction to ImperativeAggregateFunctionRenames this base class because users can easily mix up AggregateFunction andUserDefinedAggregateFunction. The new naming also prepares for the futureDeclarativeAggregateFunction. ImperativeAggregateFunction has already been introducedas a concept in the Blink planner.,2
[hotfix][table-api-java] Remove @Experimental annotation for function methods in TableEnvironment,1
[hotfix][table-api-java] Fix JavaDocs for TableEnvironment.fromValues,2
[hotfix][table] Remove deprecated AggregateFunction.requiresOver(),1
[hotfix][table-common] Add CallExpression.getFunctionName for easier printing,1
"[FLINK-15803][table] Update AggregateFunction and TableAggregateFunction to the new type systemThis updates imperative aggregate functions AggregateFunction and TableAggregateFunctionto the new type system with new type inference. The new stack is activated when usingTableEnvironment.createTemporarySystemFunction or call(Class, ...) in Table API. Otherlocations (SQL DDL, Table API Scala implicits) will be updated once we support theconcept of DataView as well. Currently, DataViews are not supported.This closes #13007.",1
[FLINK-18606][java-streaming] Remove unused generic parameter from SinkFunction.Context,1
[FLINK-10195][connectors/rabbitmq] Allow setting QoS,1
[FLINK-17529][connectors/rabbitmq] Upgrade com.rabbitmq:amqp-client to 5.9.0,2
[FLINK-17886][docs-zh] Update Chinese documentation for new WatermarkGenerator/WatermarkStrategiesThis closes #12665,1
[FLINK-13872][docs-zh] Translate Operations Playground to ChineseThis closes #9648,1
[FLINK-18579][jdbc] Remove deprecated classes in flink-connector-jdbc,5
[FLINK-15728][jdbc] Introduce FieldNamedPreparedStatement to support fields are bound multiple times in update statementThis closes #12882,5
[FLINK-18493] Make Yarn staging directory for Flink application configurableThis closes #13014.,5
[FLINK-18625][runtime] Maintain redundant taskmanagers to speed up failoverThis closes #12958.,0
[hotfix][docs] Update currentInputNWatermark metrics docs including N-ary operator,1
[FLINK-18362][FLINK-13838][yarn] Add yarn.ship-archives to support LocalResourceType.ARCHIVE(cherry picked from commit 094574fb81b87847568de465155b1eede8bb8771),1
[FLINK-16048][avro] Support read/write confluent schema registry avro data from Kafka,5
[hotfix] Remove dead code in TypeExtractor,4
"[hotfix] Remove warnings in TypeExtractor, AvroTypeInfo",5
[hotfix] Use List instead of ArrayList in TypeExtractor,4
"[FLINK-12175] Change filling of typeHierarchy in analyzePojo, for correctly creating fields TypeInfoCo-authored-by: Dawid Wysakowicz <dwysakowicz@apache.org>",5
[hotfix][docs] Fix 'event_timestamp_extractors.zh.md' by updating the chinese doc link,2
[FLINK-18776][avro] Avoid hardcoded scala versionThis closes #13032.,2
[hotfix][csv][docs] Fix 'csv.quote-character' format option documentation (#13035),2
[FLINK-17426][table-planner-blink] Support the SupportsLimitPushDown interface for ScanTableSourceThis closes #12964,1
[FLINK-18700][debezium] Debezium-json format throws NPE when PG table's IDENTITY config is not FULLThis commit add documentation for this case and throws a guide message in the exception.This closes #13019,2
[FLINK-18705][debezium] Fix Debezium-JSON throws NPE when tombstone message is receivedJust skip the tombstone messagesThis closes #13019,5
"[FLINK-18772] Disable web submission for per-job/application mode deploymentsWhen running Flink in per-job/application mode, it will instantiate a MiniDispatcherRestEndpoint.This endpoint does not instantiate the web submission REST handlers. However, it still displayedthe submit job link in the web ui. This commit changes the behaviour so that we no longer displaythis link when running Flink in per-job/application mode.This closes #13030.",2
[FLINK-16619][coordination] Log reception of slot reports only once,2
"[FLINK-18663][rest] Improve exception handling- ensure that request finalization runs even if handleException throws an exception- catch NPE in handleException, which occurs if the client closes the connection",0
[FLINK-18663][rest] Exit early if shutdown has started,2
[hotfix][rest][tests] Replace HandlerBlocker with BlockerSync,0
[hotfix][mesos] Remove the useless env variable in MesosTaskExecutorRunner,1
[hotfix][mesos] Fix the access modifiers in LaunchableMesosWorker,1
[FLINK-16566][mesos] Change the log level of the launching command and dynamic properties from DEBUG to INFO in Mesos,5
[FLINK-5552][runtime][jmx] Introduce JMXServer singleton,2
[FLINK-18756][table-api] Support IF NOT EXISTS for CREATE TABLE statementThis closes #13037,1
[FLINK-17290][docs-zh] Translate Streaming Analytics training lesson to ChineseCo-authored-by: lichengjian <lichengjian@meituan.com>This closes #12237,5
[FLINK-18748][Runtime/Checkpointing] trigger checkpoint immediately if it's unperiodic,2
[FLINK-18748][Runtime/Checkpointing] remove  function and add unit test for NonForced savepoints,1
[FLINK-18793] fix code link typoThis closes #13041.,2
[FLINK-17253][fs-connector] Support viewfs for hadoop version < 2.7This closes #11815.,1
[FLINK-17569][fs-connector] Delegate lease revoking to correct from viewfsThis closes #12035.,2
[FLINK-18658][tests] Forward RpcServiceSharing setting,1
[FLINK-18763][python] Support basic TypeInformation for Python DataStream API. (#13029),5
[FLINK-18690][runtime] Introduce ExecutionSlotSharingGroup and SlotSharingStrategy interface,2
[FLINK-18690][runtime] Implement LocalInputPreferredSlotSharingStrategy,2
[FLINK-18816] [docs] Correct API change in pyflink dependency management page (#13062),2
[FLINK-18769][table-planner-blink] Fix MiniBatch doesn't work with FLIP-95 source (#13038)This closes #13038,1
[FLINK-18764][python] Add DataStream class and support from_collection() in StreamExecutionEnvironment. (#13061),1
[FLINK-18749][k8s] Correct dependencies in Kubernetes pomThis closes #13058.,2
"[FLINK-18677][fix] Added handling of suspended or lost connections within the ZooKeeperLeaderRetrievalService.The listener needs to be notified in case of a connection loss so that it is able to initiate necessary actions on its side.[FLINK-18677][runtime] [style] Replaced spaces by TABs to follow the Apache Flink code styles.[FLINK-18677][runtime] [fix] Synchronize notifyLeaderLoss through lock and removed redundant code.The redundant code was moved into notifyIfNewLeaderAddress(String, UUID) which is then used by notifyLeaderLoss() and within nodeChanged(). Additionally, the method call of notifyLeaderLoss() is guarded now by a lock to synchronize the state change (i.e. lastLeaderAddress and lastLeaderSessionID).[FLINK-18677][runtime] The exception was added to make it more explicit that the method is not expected to be called.[FLINK-18677][runtime] Decreased wait time the queue to be filled since we're not expecting any objects.The test does not expect any calls happening. Hence, no CompletableFuture instance will be queued. The longer wait time would just result in a longer running test.[FLINK-18677][runtime] Added infinite wait time to happy test.The previous implementation had a fixed timeout. Slower machines might need longer to process the test which might result in test failures. The new implementation removes the timeout so that the test wouldn't fail just because of a poor performance of the machine the test is running on.[FLINK-18677][runtime] Moved log messages out of synchronization blocks.This closes #13055.",2
[hotfix][docs][config] Sort entries,5
[hotfix][docs][config] Remove leftover files,2
[FLINK-18804][docs][config] Skip file generation for empty tables,2
[FLINK-18805][config] Improve handling of upper-character sequences,1
[FLINK-18834][doc] Fix the broken link of rocks db html in config doc (#13074),2
[FLINK-18831][docs][python] Improve the documentation about the operations in Python Table APIThis closes #13070.,2
[hotfix][table-common] Fix invalid conversion class in data type transformer,5
[hotfix][table-runtime-blink] Return mutable instances for List converter,2
[hotfix][table-planner-blink] Remove PlannerTypeUtils.getArity,1
[hotfix][table-planner-blink] Reuse data structure converters whenever possible,5
[FLINK-15803][table] Replace type information with serializer in StateDataViewStore,5
[hotfix][core] Allow null instances in serializer tests,3
[FLINK-15803][table-runtime-blink] Add an external serializer that can handle all data types,5
[FLINK-15803][table-common] Update DataView classes to the new type system,5
[FLINK-15803][table-common] Integrate data views into data type extractor,4
[hotfix][table-common] Ensure valid internal class hierarchy for data types,5
[FLINK-15803][table] Support DataViews in FLIP-65 aggregate functionsThis enables support for ListView and MapView in FLIP-65 aggregatefunctions. There are two major differences to the previous design:1. We use the internal serialization format for checkpoints/savepointsof data views. Data structure converters are used at the edges whichmeans that we support all data types and conversion classes.2. The data types of data views are expressed in a declarative way. Wedon't instantiate the accumulators anymore. Instead users can useannotations or override getTypeInference.Old aggregate functions are still supported when usingTableEnvironment.registerFunction.This closes #13054.,1
[hotfix] Fix typo and correct the grammarThis closes #13057.,2
[hotfix][runtime] Fix typo in LocationPreferenceSlotSelectionStrategy,2
[hotfix][runtime] Fix typo in SlotPoolImplThis closes #13069.,2
[hotfix] Fix potential test concurrency instability in BulkSlotProviderImplTest,3
"[FLINK-18709][Coordination] Implement PhysicalSlotProviderPhysicalSlotProviderImpl tries to allocate a physical slot from the available idle cached slots in SlotPool.If it is not possible, it requests a new slot from the SlotPool.This closes #13018.",1
"[FLINK-18739] Implement MergingSharedSlotProfileRetrieverInput location preferences will be considered for each SharedSlot when allocating a physical slot for it.Input location preferences of a SharedSlot are the merged input location preferences of all the tasks to run in this SharedSlot.Inter-ExecutionSlotSharingGroup input location preferences can be respected in this way for ExecutionSlotSharingGroups belonging to different bulks.If ExecutionSlotSharingGroups belong to the same bulk, the input location preferences are ignored because of possible cyclic dependencies.Later, we can optimise this case when the declarative resource management for reactive mode is ready.Intra-ExecutionSlotSharingGroup input location preferences will also be respected when creating ExecutionSlotSharingGroup(s) in LocalInputPreferredSlotSharingStrategy.This closes #13028.",1
[FLINK-18839][docs][python] Add documentation about how to use catalog in Python Table APIThis closes #13077.,2
[FLINK-18796][kinesis] Make backpressureLatch volatile,1
[FLINK-18821][network] Report PartitionRequest failures to subsequent callers,0
[hotfix] Remove unused FutureUtils.runSync,1
[hotfix][k8s] Use constant logging variable to replace constant strings,2
[hotfix][k8s] Add log4j1 configuration to JobManager and TaskManager start command,5
[FLINK-15792][k8s] Make Flink logs accessible via kubectl logs per default,2
[FLINK-15792][k8s] Update logging section in native Kubernetes documentThis closes #12240,2
[hotfix][docs] Rephrase the description about file names in StreamingFileSink,2
[hotfix]fix java code in scala snippet,0
[FLINK-18838][python] Support JdbcCatalog in Python Table APIThis closes #13083.,5
"[FLINK-16510] Allow configuring shutdown behavior to avoid JVM freezeThis adds the configuration option `cluster.processes.halt-on-fatal-error`which defaults to `false`. If set to `true`, a custom SecurityManager will beinstalled on top of the existing SecurityManager to exit forcefully via`Runtime#halt`.Exiting that way may be necessary due to the Java 8 JVM freezing during agraceful shutdown when using the G1 garbage collector.This closes #13042.",1
[FLINK-17503][runtime] [logs] Refactored log output.The log output was cleaned up: - Only the key of the option is logged out instead of the whole   instance's toString() method. - A new utility method was introduce that adapts the log output in a   way that an adapted extension is used for maximum values instead of   logging the actual max value.This closes #13086.,2
[FLINK-18765][python] Support map() and flat_map() for Python DataStream API. (#13066),5
[hotfix][docs] Fix the link-tags of 'Side Outputs' page of 'DataStream API' (#13087),5
[FLINK-18678][hive][doc] Update doc about setting hive versionThis closes #12988,1
[FLINK-18847][docs][python] Add documentation about data types in Python Table APIThis closes #13084.,5
[FLINK-18688][table-planner-blink] Fix binary row writing with incorrect order in ProjectionCodeGenerator by removing for loop optimizationThis closes #12996,4
[FLINK-18766][python] Support add_sink() for Python DataStream API. (#13094),5
[hotfix][table-planner-blink] FlinkStreamProgram should not use FlinkBatchRuleSets (#13100),2
[hotfix] Skip e2e tests for aarch64This closes #13076,3
[FLINK-18859][tests] Increase timeout of ExecutionGraphNotEnoughResourceTest#testRestartWithSlotSharingAndNotEnoughResources to make it more stable,1
"[FLINK-18798][docs-zh] Translate ""Debugging Windows & Event Time"" page of ""Debugging & Monitoring"" into ChineseThis closes #13056",1
[FLINK-18864][python] Support key_by() operation for Python DataStream API. (#13097),5
[FLINK-18861][python] Support add_source() for Python DataStream API. (#13095),5
[FLINK-18862][table-planner-blink] Fix LISTAGG throws BinaryRawValueData cannot be cast to StringData exception during runtimeThis closes #13104,1
[FLINK-18874][python] Support conversions between Table and DataStream. (#13107),5
[FLINK-18865][doc] Update Kafka doc for setStartFromEarliest method,1
[FLINK-18848][python] Fix to_pandas to handle retraction data properlyThis closes #13099.,5
[FLINK-18883][python] Support reduce() operation for Python KeyedStream. (#13113),1
[FLINK-18760][runtime] Redundant task managers should be released when there's no job running in session clusterThis closes #13051.,1
[FLINK-18866][python] Support filter() operation for Python DataStream API. (#13098),5
[FLINK-18863][python] Support read_text_file() and print() interface for Python DataStream API. (#13117),5
[FLINK-18893][python] Fix Table.to_pandas for TableEnvironment created via EnvironmentSettingsThis closes #13120.,1
[FLINK-18844][json][maxwell] Support maxwell-json format to read Maxwell changelogsThis closes #13090,4
[hotfix][python] Remove unused variables,1
[FLINK-18483][kinesis] Test coverage improvements for FlinkKinesisConsumer/ShardConsumerThis closes #12850.,2
[FLINK-18682][orc][hive] Vector orc reader cannot read Hive 2.0.0 tableThis closes #12985,2
[FLINK-18885][python] Add partitioning interfaces for Python DataStream API. (#13119),5
[FLINK-18876][coordination] Move file after stream was closed,2
[FLINK-18773][runtime] Enable parallel user-code and plugin class loader.,1
"[hotfix][runtime] Resolve only already loaded classes in ChildFirstClassLoader.Classes that also need to loaded are already resolved through super.loadClassWithoutExceptionHandling(name, resolve).",0
[FLINK-18888][python] Support execute_async for StreamExecutionEnvironment. (#13126),1
[hotfix][table] Enable TypeInformationRawType for data structure converters,5
[hotfix][table-common] Enable hashCode/equals for materialized raw value data,5
[hotfix][table-common] Make BinaryRowData and NestedRowData comparable,5
[FLINK-18809][table-planner-blink] Introduce interface for InternalAggregateFunctionSimplifies the implementation because internal functions usually dont have verycomplex types or need annotations and therefore don't need access to DataTypeFactory.,5
[FLINK-18809][table-planner-blink] Update MaxWithRetractAggFunction,1
[FLINK-18809][table-planner-blink] Update MinWithRetractAggFunction,1
[FLINK-18809][table-planner-blink] Update CollectAggFunction,1
[FLINK-18809][table-planner-blink] Update ListAggFunctions,1
[FLINK-18809][table-planner-blink] Update First/LastValueAggFunction,1
[FLINK-18809][table-planner-blink] Ensure that all internal agg functions have been updated,5
[FLINK-18809][table-planner-blink] Update distinct aggregates to the new type systemThis closes #13106.,5
[FLINK-18355][tests] Remove SchedulerImpl in SlotPoolImplTest,3
[hotfix][tests] Merge SlotPoolInteractionsTest#TestingSlotPool with TestingSlotPoolImpl,3
[hotfix][tests] Move testProviderAndOwnerSlotAllocationTimeout from SlotPoolInteractionsTest to SchedulerImplTest,3
[hotfix][tests] Add SchedulerImplTest#testAllocateSlot to test the basic slot allocation function of SchedulerImpl,1
[FLINK-18355][tests] Remove SchedulerImpl in SlotPoolInteractionsTest,3
[FLINK-18355][tests] Remove redundant codes in SlotPoolImplTest#testAllocateWithFreeSlot,3
[FLINK-18355][tests] Refactor tests of SlotPoolImpl with SlotPoolUtils and SlotPoolBuilder,3
[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialectThis closes #13017,2
[FLINK-18867][hive] Generic table stored in Hive catalog is incompatible for 1.10This closes #13101,2
"[FLINK-18902][rest] Allow request serving while the REST handlers are shutting downIn order to serve the job execution result when using the per job mode, the RESThandlers must be able to serve requests while the RestServerEndpoint is being shutdown. Otherwise, it is not possible to serve the asynchronous operation resultssuch as the job execution result.This commit solves this problem by checking whether the InFlightRequestTrackerallows to enqueue a new request or not in the AbstractHandler. If it rejects a newrequest, this means that the handler has been shut completely shut down and that weshould close the connection to the client. If the InFlightRequestTracker still acceptsrequests, then this means that the RestHandler might still want to serve an asynchronousresult.This closes #13131.",0
[hotfix] Remove mocking from RestServerEndpointITCase,4
[FLINK-18815] Change Thread.sleep(2) to Thread.sleep(0) to fail SafetyNetCloseableRegistryTest#testClose more often,3
[FLINK-18815] Close safety net guarded closeable iff it is still registeredThis closes #13124.,2
[hotfix] Rename BufferManager#unsynchronizedGetExclusiveBuffersUsed to BufferManager#unsynchronizedGetAvailableExclusiveBuffersThis closes #12994.,1
[FLINK-18728][network] Make initialCredit of RemoteInputChannel finalThe filed initialCredit of RemoteInputChannel is set only once and can be accessed by multi threads. This patch makes the filed final and moves the initialization to the constructor of RemoteInputChannel to avoid potential thread safety issues.This closes #12994.,0
[hotfix] Change signature of MemorySegmentProvider#requestMemorySegments from requestMemorySegments() to requestMemorySegments(int)This change makes the interface more flexible and decouples NetworkBufferPool from the concept of exclusive buffer.This close #12994.,1
[FLINK-18856][checkpointing] Synchronize access to CheckpointCoordinator.lastCheckpointCompletionRelativeTime,2
[hotfix][test] Fix formatting in CheckpointRequestDeciderTest,3
[hotfix][docs] Add javadoc to CheckpointRequestDecider,2
[FLINK-18849][docs] Improve the code tabs of the Flink documents.This closes #13085,2
[FLINK-18659][hive][orc] Fix streaming write for Hive 1.x Orc tableThis closes #13078,0
[hotfix][runtime] Move active resource manager related classes to separate package.,4
[hotfix][runtime] Move PendingWorkerCounter to a separate file.,2
[hotfix][runtime] Make ResourceManager#onStart final.,1
[hotfix][runtime] Refactor resource manager termination handling.,4
[hotfix][runtime] Guard ResourceManager#startServicesOnLeadership from being overridden.,0
[hotfix][runtime] Refactor ResourceManager#onTaskManagerRegistration argument type.,4
[hotfix][runtime] Add equals() and hashCode() or CommonProcessMemorySpec.CommonProcessMemorySpec is a value class with well-defined equality relation.We use these equality for testing in the subsequent commits.,3
[FLINK-18719][runtime] Rename ActiveResourceManager to LegacyActiveResourceManager.,2
[FLINK-18719][runtime] Introduce interfaces ResourceManagerDriver and ResourceEventHandler.,0
[FLINK-18719][runtime] Introduce new ActiveResourceManager.This closes #13004.,1
[FLINK-18878][python] Support dependency management for Python StreamExecutionEnvironment. (#13136),1
[FLINK-18901][table] Use new type inference for aggregate functions in SQL DDLAll CREATE FUNCTION statements use the new type inference now. It might requireto update existing implementations to the new reflective type extraction logic.Use StreamTableEnvironment.registerFunction for the old stack.This closes #13142.,1
[FLINK-18884][python] Add chaining strategy and slot sharing group interfaces for Python DataStream API. (#13140),5
[hotfix][table] Keep aggregate functions in sync with code generation,1
[FLINK-18936][docs] Update documentation around aggregate functionsThis closes #13143.,1
[FLINK-18935] Reject CompletedOperationCache.registerOngoingOperation if cache is shutting downThis commit changes the CompletedOperationCache so that it rejects registerOngoingOperation callswith an IllegalStateException if the cache is already shutting down. This ensures that now newoperation will be enqueued while waiting for the previous operations to complete.This closes #13139.,1
"[FLINK-18220][runtime] Enrich heap space OOMs with memory configuration informationProvide the user with hints how to configure Flink in order to increase the heap spaceof the JobManager process in case that Java heap space OutOfMemory errors are encountered.[FLINK-18220][runtime] Changed the visibility of ClusterEntryPointExceptionUtils and its utility method to enable using it also in other packages.[FLINK-18220][runtime] Adapted signature of JobVertex.finalizeOnMaster and JobVertex.initializeOnMaster to indicate that not only Exceptions might occur.[FLINK-18220][runtime] Added OOM-enrichment to InputOutputFormatVertex.initializeOnMaster and InputOutputFormatVertex.finalizeOnMaster.[FLINK-18220][runtime] Extended ExceptionUtils adding a method for manipulating the error message within the cause tree of a passed Throwable.More specifically, this method is used to change the message of a OutOfMemoryError buried within a Throwable's cause tree.[FLINK-18220][runtime] Refactored newly added utility method by generalizing its purpose.The previous version was referring to a concrete use case already which is not the purpose of ExceptionUtils. Corresponding testcases were added as well.[FLINK-18220][runtime] Refactored newly added utility method by enabling to update multiple messages at once.This way, we avoid traversing the cause tree multiple times.[FLINK-18220][runtime] Made use of newly added ExceptionUtils.updateDetailMessage and cleaning up unused code.[FLINK-18220][runtime] Refactored code to not support deleting an error message.This was done in favor of simplifying the code over supporting a feature that was not requested.[FLINK-18220][runtime] Fixed missed out compiler errors.Revert ""[FLINK-18220][runtime] Adapted signature of JobVertex.finalizeOnMaster and JobVertex.initializeOnMaster to indicate that not only Exceptions might occur.""This reverts commit dc23b3a38f8118cc0f08d869d7b6268487197040.[FLINK-18220][runtime] Moved OOM message handling into more exposed code segments.[FLINK-18220][runtime] JavaDoc fix.[FLINK-18220][runtime] Extended ExceptionUtils.tryEnrichOutOfMemoryError to cover also heap space-related OutOfMemoryErrors.[FLINK-18220][runtime] Added error message for heap-space-related OutOfMemoryErrors.[FLINK-18220][runtime] Fixed compilation error.[FLINK-18220][runtime] Reverted the formatting changes accidentally pushed in 93d9627 but left the TaskManagerExceptionUtils.tryEnrichTaskManagerError(Throwable) change untouched.[FLINK-18220][runtime] Updated Exception methods to be more descriptive.[FLINK-18220][runtime] Typo fix in newly added exception message for JM heap space errors.[FLINK-18220][runtime] Updated JavaDoc to comply the actual implementation.[FLINK-18220][runtime] Added @Nullable constaints.[FLINK-18220][runtime] Moved OOM handling up the call hierarchy into the Dispatcher.[FLINK-18220][runtime] Moved OOM handling down from the generic failGlobal(Throwable) into vertexFinished().[FLINK-18220][runtime] Moved OOM handling up the call hierarchy into internalSubmitJob(JobGraph).[FLINK-18220][runtime] Added test class that checks whether the right error message prefix to extended error message mapping is applied.[FLINK-18220][runtime] Added IT testing that OOM error message enrichment is happening when an OutOfMemoryError occurs during initialization or finalization of a vertex.This closes #13111.",5
[FLINK-18956][task] StreamTask.invoke should catch ThrowableThis closes #13145.,2
[FLINK-18879][python] Support Row Serialization and Deserialization schemas for Python DataStream API. (#13150),5
[FLINK-18943][python] Support CoMapFunction for Python DataStream API,5
[FLINK-18943][python] Rename AbstractPythonFunctionOperator to AbstractOneInputPythonFunctionOperator,1
[FLINK-18945][python] Support CoFlatMap for Python DataStream API (#13152),5
[FLINK-16245][runtime] Decouple user from context classloaderAllows user classloader can be unloaded even if a reference on the context classloader outlives the user code.,1
[FLINK-16245][table] Close user classloader,1
"[FLINK-16245][tests] Adjust BatchFineGrainedRecoveryITCaseBecause the classloader is now closed when the task fails the UDF only has access to the bootstrap classloader, which doesn't contain our own test classes.",3
"[FLINK-16917][orc] Workaround for classloader leak in OrcFile.See https://issues.apache.org/jira/browse/ORC-653OrcFile#getStaticMemoryManager caches initial configuration and leaks classloader in it. Thus, new Flink jobs use the classloader of the first job implicitly.By adding ThreadLocalClassLoaderConfiguration, which forces the use of thread-local classloader over the initial classloader, Flink jobs use the appropriate classloader on higher runtime costs (no caches).This commit should be reverted, once the bug in ORC is fixed.",0
"[FLINK-16917][runtime] Added option to disable safety net user classloader.If users experience class loader leaks in libraries not under his control, they can force old behavior with the config option.",5
[FLINK-18081][doc] Fix broken links in Kerberos Authentication Setup and Configuration,5
[FLINK-18963][docs] Introduced IntelliJ subsection about adding a Copyright Profile for the Apache license.This closes #13165.,2
[hotfix] Move DualKeyLinkedMap to util package,2
"[FLINK-18751][Coordination] Implement SlotSharingExecutionSlotAllocatorSlotSharingExecutionSlotAllocator maintains a SharedSlot for each ExecutionSlotSharingGroup.SlotSharingExecutionSlotAllocator allocates physical slots for SharedSlot(s) and then allocates logical slots from it for scheduled tasks.The physical slot is lazily allocated for a SharedSlot, upon any hosted subtask asking for the SharedSlot.Each subsequent sharing subtask allocates a logical slot from the SharedSlot.The SharedSlot/physical slot can be released only if all the requested logical slots are released or canceled.When SlotSharingExecutionSlotAllocator receives a set of tasks to allocate slots for, it does the following:- Map the tasks to ExecutionSlotSharingGroup(s)- Check which ExecutionSlotSharingGroup(s) already have SharedSlot(s)- For all involved ExecutionSlotSharingGroup(s) which do not have a SharedSlot yet:  - Create a SlotProfile future by MergingSharedSlotProfileRetriever and then  - Allocate a physical slot from the PhysicalSlotProvider  - Create SharedSlot based on the returned physical slot futures  - Allocate logical slot futures for the tasks from all corresponding SharedSlot(s).- If physical slot future fails, cancel its pending logical slot requests within the SharedSlot- Generates SlotExecutionVertexAssignment(s)  based on the logical slot futures and returns the results.This closes #13071.",2
[FLINK-17295] Refactor the ExecutionAttemptID to consist of ExecutionVertexID and attemptNumber,4
[hotfix][docs] Fix various typos,2
[hoxfix] Fix various typos,2
[FLINK-18966][python] Support key_by() on ConnectedStreams for Python DataStream API (#13153),5
[hotfix] Fix typo,2
"[FLINK-17285][python][docs] Translate ""Python Table API"" page into Chinese (data type, metrics, etc)This closes #13116.",5
[FLINK-17621][e2e] Use default akka.ask.timeout in TPC-DS e2e test,3
[FLINK-18947][python] Support partition_custom() for Python DataStream API. (#13155),5
[FLINK-18886][python] Support Kafka connectors for Python DataStream API. (#13161),5
[FLINK-18212][table-planner-blink] Fix Lookup Join failed when there is a UDF equal condition on the column of temporal tableThis closes #13167,0
[FLINK-18972][runtime] BulkSlotProviderImpl disables batch slot request timeout check only when its slot allocation interface is really in use,1
[FLINK-18944][python] Support JDBC connector for Python DataStream API. (#13169),5
[FLINK-18965][sql-client] Exclude hadoop-hdfs transitive dependency for flink-sql-clientThis closes #13168,2
[hotfix][docs] Replaced outdated 'RocksDBStateBackend.setOptions(..)' by 'RocksDBStateBackend.setRocksDBOptions(..)' and fixed typo in parameter list (PptionsFactory -> RocksDBOptionsFactory).This closes #13185.,5
[FLINK-18219][runtime] Added OOM-enrichment for REST callsThis will result in an enriched OutOfMemoryError message when submitting a Job jar through the web UI.[FLINK-18219][runtime] Moved OOM error message enrichment into AbstractHandler.[FLINK-18219][runtime] Added test to check whether OOM error message enrichment is actually happening within AbstractHandler.[FLINK-18219][runtime] Added generic test utility classes providing a framework for TestRestServerEndpoint-related testing.[FLINK-18219][runtime] Moved OOM enrichment test from AbstractHandlerTest into newly created AbstractHandlerITCase.The new implementation utilizes the newly introduced test utility classes instead of Mockito.[FLINK-18219][runtime] Added JavaDoc to test utility classes.,3
"[FLINK-18219][runtime] Removed TestRestServerEndpoint from flink-client module. Instead, use newly added test utility class in flink-runtime.[FLINK-18219][runtime] Replaced inner class MultipartUploadResource.TestRestServerEndpoint by generic TestRestServerEndpoint.[FLINK-18219][runtime] Replaced inner class RestServerEndpointITCase.TestRestServerEndpoint by generic TestRestServerEndpoint.[FLINK-18219][runtime] Made TestRestServerEndpoint's Builder constructor private and added a static creator method instead.[FLINK-18219][runtime] Renamed TestHandler into TestRestHandler.[FLINK-18219][runtime] Removed TestVersionSelectionHandler* classes and used newly introduced TestRestHandler class instead.[FLINK-18219][runtime] Formatting changes to match the checkstyle definition.This closes #13115.",5
[FLINK-18752][yarn] Allow shipping single files for yarn executionThis closes #13103.,2
[FLINK-18949][python] Support Streaming File Sink for Python DataStream API. (#13156),5
[FLINK-18910][docs][python] Create the new documentation structure for Python documentation according to FLIP-133.This closes #13147.,2
[hotfix][docs][checkpointing] Fix typos,2
[FLINK-18643][Azure] Build a Flink snapshot release with the nightly cron-job.This closes #13125,2
[FLINK-18985][python][doc] Update the Sphinx doc for Python DataStream API. (#13191),5
[hotfix][yarn] remove incorrect javadoc,2
[FLINK-15448][runtime] Add metadata to ResourceID,5
[FLINK-15448][runtime] Add Node information to the ResourceId of TaskExecutor in YarnThis closes #13063.,5
"[FLINK-18930][docs-zh] Translate ""Hive Dialect"" page of ""Hive Integration"" into ChineseThis closes #13176",1
[FLINK-18814][docs-zh] Translate the 'Side Outputs' page of 'DataStream API' into ChineseThis closes #13088,1
[FLINK-17427][table-planner-blink] Support SupportsPartitionPushDown in plannerThis closes #12966,1
[FLINK-18994][doc-zh] Fix typo in setup taskmanager memory page of Chinese doc translations.This closes #13195.,2
[FLINK-18997][python] Rename parameter name type_info to result_type for DataStream.map(),5
[FLINK-18997][python] Rename parameter name type_info to result_type for DataStream.flat_map(),5
[FLINK-18200][python] Replace the deprecated interfaces with the new interfaces in the tests and examplesThis closes #12770.,3
[FLINK-15299][test] Move ClientUtils#submitJob & ClientUtils#submitJobAndWaitForResult to test scopeThis closes #11469 .,3
[FLINK-18953][python][docs] Add documentation for DataTypes in Python DataStream API (#13199),5
[FLINK-18912][python][docs] Add Python api tutorial under Python GettingStart (#13192),1
[FLINK-18449][kafka][table] Support topic list and topic pattern and partition discovery for Kafka source in Table APIThis closes #12908,1
[FLINK-18995][hive] Some Hive functions fail because they need to access SessionStateThis closes #13197,1
"[FLINK-18962][checkpointing][task] Change log level from DEBUG fto INFO or async part errorsNOTE: code change causes CancellationException to be logged at INFO level.To prevent this from failing e2e tests, CancellationException is ignored in e2e error parsing script.",0
[FLINK-18962][checkpointing] Log checkpoint decline reason,2
"[hotfix][tests] e2e/common.sh: add -type parameter to findThis prevents ""Is a directory"" error when running ""head"":Checking for exceptions...Found exception in log files; printing first 500 lines; see full logs for details:head: error reading '/home/vsts/work/1/s/flink-dist/target/flink-1.12-SNAPSHOT-bin/flink-1.12-SNAPSHOT/log/': Is a directory",2
[FLINK-18941][docs-zh] Correct typos in \docs\ops\memory\mem_setup_jobmanager.zh.md.This closes #13211.,2
[FLINK-15793][k8s] Replace kubernetes-entry.sh with unified docker-entrypoint.sh,2
[FLINK-15793][doc] Update documentation to show how to enable plugins for native K8s,0
[FLINK-15793][e2e] Add E2E test to enable plugin for native K8s,0
[FLINK-18900][hive] HiveCatalog should error out when listing partitions with an invalid specThis closes #13157,0
[FLINK-18993][Runtime]Invoke sanityCheckTotalFlinkMemory method incorrectly[FLINK-18993][Runtime]Invoke sanityCheckTotalFlinkMemory method incorrectlyThis closes #13198.,2
[FLINK-18813][docs-zh] Translate the 'Local Installation' page of 'Try Flink' into ChineseThis closes #13089.,1
"[FLINK-18855][docs-zh] Translate the ""Cluster Execution"" page of ""Application Development's DataSet API"" into ChineseThis closes #13173.",1
[hotfix][docs] Translate building.md to building.zh.mdThis closes #13188 .Signed-off-by: 313773543 <313773543@qq.com>,2
[FLINK-18512][kinesis] Introducing RecordPublisher. Refactor ShardConsumer to use PollingRecordPublisherThis closes #12881.,1
[FLINK-18955][Checkpointing] Add checkpoint path to job startup/restore message,1
"[FLINK-18742][cli] Respect all config args when creating packaged program at clientBefore this, options like the classloader order was not respected if specified inthe command like because the packaged program was created before we create theeffective configuration at the client. This commit changes the order of events.This closes #13024.",4
[hotfix][table-common] Allow finding a common type for empty strings,1
[FLINK-18553][table-api-java] Update set operations to new type systemThis closes #13200,5
[FLINK-18948][python][e2e] Add E2E test for Python DataStream APIThis closes #13206.,5
[hotfix][runtime] Avoid unnecessary map building in PipelinedRegionComputeUtil#buildOneRegionForAllVertices(),0
[FLINK-17330[runtime] Extract common methods out from PipelinedRegionComputeUtil#computePipelinedRegions(),4
[FLINK-19040][test] Properly close operator in SourceOperatorTest,3
[FLINK-19040][task] Close SourceReader in SourceOperator,1
[FLINK-16699][k8s] Support accessing secured services via K8s secretsThis closes #12899.,1
[FLINK-18750][table] SqlValidatorException thrown when select from a view which contains a UDTF call,5
"[FLINK-17159] Harden ElasticsearchSinkITCaseBefore, it could happen that the embedded node is not ready. Now we waitfor nodes/data nodes to be live before returning from the initializationmethod.",5
[FLINK-19041][python] Add dependency management for ConnectedStream in Python DataStream API. (#13236),5
[hotfix][docs] Use correct WebUI port,1
[FLINK-19032] Remove deprecated RuntimeContext#getAllAcumullators,1
[FLINK-19031] Remove deprecated StreamExecutionEnvironment#setStateBackend(AbstactStateBackend),1
"[FLINK-18917][docs][python] Add a ""Built-in Functions"" link (linked to dev/table/functions/systemFunctions.md) under the ""Python API"" -> ""User Guide"" -> ""Table API"" sectionThis closes #13226.",1
[FLINK-18720][runtime] Initialize ResourceManagerDriver with ScheduledExecutor rather than Executor.ScheduledExecutor will be used for scheduling events in the rpc main thread in subsequent commits.,1
[FLINK-18720][runtime] Introduce AbstractResourceManagerDriver as common base class of resource manager drivers.,2
[FLINK-18720][k8s] Introduce KubernetesResourceManagerDriver.,2
[FLINK-18720][k8s] Enable pod creation interval for KubernetesResourceManagerDriver.,1
[FLINK-18720][k8s] Switch kubernetes deployment to the new active resource manager implementation.This closes #13186.,1
[FLINK-18854][docs-zh] Translate the 'API Migration Guides' page of 'Application Development' into ChineseThis closes #13172,1
[FLINK-19058] Fix typo in Dataset transformations documentation,2
[FLINK-19052] [serialization] add constructor cache in PojoSerializer,1
"[hotfix][docs] Enforce reading files in UTF-8 in include_without_header.rbAll our documentation pages are encoded in UTF-8. However if notspecified, File.read will use the system default encoding. Thereforemaking it impossible to build docs in a system with a different defaultencoding. It is the case e.g. when building docs through the dockercontainer.",2
[FLINK-18797][examples] Update deprecated forms of keyBy in examples,5
[FLINK-18797][docs] Update deprecated forms of keyBy in docsThis closes #13135,2
[FLINK-18555][table-api] Make TableConfig options can be configured by string-based ConfigurationThis closes #12880,5
[FLINK-18973][docs-zh] Translate the 'History Server' page of 'Debugging & Monitoring' into ChineseThis closes #13212,1
[FLINK-18899][yarn] Enrich the description of 'yarn.application-attempts' to show the default value settingThis closes #13258.,1
[FLINK-19009][metrics] Fixed the downtime metric issue and updated the commentThis closes #13242.,5
[FLINK-19042][hive] Remove print table sink from HiveTableSourceITCase::testNonPartitionStreamingSourceThis closes #13238,3
[FLINK-19061][hive] HiveCatalog fails to get partition column stats if partition value contains special charactersThis closes #13264,1
[FLINK-18987][WebUI] Sort user configuration entries,5
[FLINK-17273][runtime] ActiveResourceManager closes task manager connections on worker terminated.This closes #13263.,1
[hotfix][docs] Fix links and typoes in new Source API docs,2
[hotfix] Refactor SubtaskCheckpointCoordinatorImpl.registerAsyncCheckpointRunnable,1
"[FLINK-19012][task] Check state of AsyncCheckpointRunnable before throwing an exceptionCurrently, SubtaskCheckpointCoordinatorImpl closes all runnables on close.It doesn't stop the actual threads, however. When closed runnable starts,it sees its parent is closed and throws an exception.This causes end-to-end tests failures.This change adds a check of runnable state.",1
[FLINK-19050][Documentation] Doc of MAX_DECIMAL_PRECISION should be DECIMALThis closes #13240,2
"[FLINK-19023][network] Remove unnecessary buffer pruning in RecordSerializerThis removes the behavior of the SpanningRecordSerializer to prune its internal serialization bufferunder special circumstances.Previously, the buffer was pruned when:  - The buffer becomes larger than a certain threshold (5MB)  - The full record end lines up exactly with a full buffer length (this change got introduced    at some point, it is not clear what the purpose is)This optimization virtually never kicks in (because of the second condition) and also is unnecessary.There is only a single serializer on the sender side, so this will not help to reduce the maximum memoryfootprint needed in any way.",1
"[FLINK-19024][network] Remove unused ""releaseMemory"" from ResultSubpartitionThe releaseMemory() call in the ResultSubpartition is currently not meaningful for anyexisting implementation.Future versions where memory may have to be released will quite possibly not implement that on asubpartition level. For example, a sort based shuffle has the buffers on a partition-level, ratherthan a subpartition level.We should thus remove the releaseMemory() call from the abstract subpartition interface. Concreteimplementations can still release memory on a subpartition level, if needed in the future.",4
[FLINK-19045][network] Remove obsolete 'taskmanager.network.partition.force-release-on-consumption' option.,1
[refactor][tests] Change ResultPartitionFactoryTest release-on-consumption testing to test behavior not implementation.This prepares the removal of certain subclasses that are currently used in the implementation test.,3
"[hotfix][network] Fix wrong string formatting for BufferOrEventThis previously assigned an object type to a %d argument, but should use a %s argument.",1
"[FLINK-19046][network] Introduce separate classes for ResultPartition typesThis helps to more cleanly separate the behaviors that are specific to pipelined or blockingshuffles, and is a preparation for adding Result Partitions that are not buffer-oriented.",1
[FLINK-19047][network] Move unaligned checkpointing methods to separate interfaces,4
[hotfix][network] Fix field visibility.,0
"[FLINK-19087][network] ReaultPartitionWriter exposes on subpartition-readers, not subpartitionsThis closes #13239",2
"[FLINK-18860][docs-zh] Translate ""Execution Plans"" page of ""Managing Execution"" into ChineseThis closes #13093",1
[FLINK-18694][web] Add unaligned checkpoint config to web uiThis closes #12962.,5
[FLINK-15853][hive][table-planner-blink] Use the new type inference for hive udfThis closes #13144,5
"[hotfix] Add a production factory method for MemoryManager, use builder in tests",3
[FLINK-19055] Wait less time for all memory GC in tests (MemoryManager#verifyEmpty)The waiting happens in a separate thread in production and does not disrupt anything.The problem is that tests use the same method which blocks the testing thread for too long.We do not need such big waiting time in tests. The PR refactors code to get back to the smaller waiting time in tests.This closes #13265.,3
[FLINK-14435][runtime] Added TaskExecutorMemoryConfiguration to TaskManagerDetailsHandler's REST endpoint.[FLINK-14435][runtime] Fixed failing test.[FLINK-14435][runtime] Aligned names in REST API and FLIP-102.This closes #13251.,3
[FLINK-18992][table-api-java] Fix Table API renameColumns JavaDocsThis closes #13257.,2
[FLINK-18977][datastream] Extract WindowOperator construction into a builder classThis closes #13178,1
[FLINK-18824][json][table] Support serialization for canal-json formatThis closes #13122,5
[FLINK-13857] Remove deprecated ExecutionConfig#get/setCodeAnalysisMode (#13287),5
[FLINK-18683][table-common] Support @DataTypeHint for table/aggregate function output typesAllows to use @DataTypeHint(...) as a synonym @FunctionHint(output = @DataTypeHint(...)) fortable and imperative aggregate functions.This closes #13149.,1
"[FLINK-18222][e2e] Stabilize Avro Confluent Schema Registry nightly testThe test was unstable because the broker tried to connect to ZK before ZK was running.With this change, we wait for ZK to be running before proceeding.This closes #13248",1
[FLINK-19049][table] Fix validation of table functions in projectionsValidates that table functions cannot be used at locations of scalarfunctions and vice versa. An exception is thrown in pre-flight phase.This closes #13285.,1
[FLINK-16768][tests] Let the watchdog also monitor mvn logsThis experimental change aims to make the watchdog more accurate by extending the monitoring from the output to log files produced by the tests.In particular the S3 tests seem to produce no output while they are producing output to the log files.The risk of this change is that a hanging test is still producing log output (e.g. the test is stuck in a retry-loop).,1
"[FLINK-18801][docs][python] Add a ""10 minutes to Table API"" document under the ""Python API"" -> ""User Guide"" -> ""Table API"" section.This closes #13273.",1
[FLINK-18852][table-planner] Fix StreamScan don't inherit parallelism from input in legacy plannerThis closes #13141Co-authored-by: davonliu <davonliu@tencent.com>,0
[hotfix][python][tests] Update all the test classes to extend from PyFlinkTestCase,3
[FLINK-19114][python] Introduce Expression class for Python Table APIThis closes #13278.,2
"[FLINK-19093][task] Fix isRunning check in AsyncCheckpointRunnable registrationCurrently, SubtaskCheckpointCoordinator#close call will close all the AsyncCheckpointRunnables outside of the synchronized block. When the respective AsyncCheckpointRunnable is registering meanwhile, it would throw an exception since the coordinator was already closed but the internal runnable is still running. After this commit, when runnable registration with closed coordinator, the check of isRunning state is replaced by checking whether the respective runnable still exists in the checkpoint map or not, to avoid unexpected exception thrown.This closes #13286.",1
[FLINK-15719] fix mistake of reading state in scala lang.This closes #13266.,0
[FLINK-19110][docs][python] Flatten current PyFlink documentation structure.This closes #13302.,2
"[FLINK-19084] Remove deprecated methods from ExecutionConfigThis commit removes deprecated, ineffective methods: - set/isFailTaskOnCheckpointError - disable/enableSysoutLogging - isLatencyTrackingEnabled",0
[FLINK-19105][docs] Fix documentation errors about FileSystem usageThis closes #13297.,1
[FLINK-18904][hotfix] Sort methods in StreamConfigPlace matching setters and getters close together,1
[FLINK-18904][hotfix] Remove unused methods in StreamConfig,5
[FLINK-18904][task] Migrate input serializers to inputs in StreamConfig,5
[FLINK-18904][task] Rename NumberOfInputs to NumberOfNetworkInputs in StreamConfigThis is a preparation for adding more generic Inputs field/accessor.,1
"[FLINK-18905][task] Rename headOperator to mainOperatormainOperator is driving the execution of the StreamTask, by pullingthe records from network inputs and/or source inputs and pushingproduced records to the remaining chained operators.",1
[FLINK-18905][hotfix][task] Extract OperatorChain#createChainOutputs method,1
[FLINK-18905][hotfix][task] Rename OperatorChain#chainEntryPoint to mainOperatorOutput,1
[FLINK-18905][hotfix][task] Move output and collector helper classes out of OperatorChain,1
[FLINK-18905][hotfix][task/test] Use StreamConfigChainer for setupOutputForSingletonOperatorChain,1
[FLINK-18905][hotfix] Extract common OutputTag#isResponsibleFor with explicit Nonnull check,4
"[FLINK-18905][task/datastream] Convert OneInputStreamOperator to InputThis will allow to avoid code duplication/wrapping passing records in the operator chains,as we ChainingOuptut class will be able to chain both Input and OneInputStreamOperator at the sametime.",1
[FLINK-18905][task] Allow SourceOperator chaining with MultipleInputStreamTask,5
"[FLINK-18905][hotfix][task] Simplify exception handling in StreamTask#dispatchOperatorEventSince Mails are allowed to throw an exception, there is no need to manually handlethe exceptions in every mail.",0
[hotfix][task] Add SuppressWarnings to StreamMultipleInputProcessor,2
[FLINK-18513][Kinesis] Add AWS SDK v2.x dependency and KinesisProxyV2,1
[FLINK-18513][Kinesis] Updated NOTICE file to reflect bundled dependencies,2
[FLINK-18513][Kinesis] Adding explicit CBOR dependency to fix runtime issue,0
[FLINK-18513][Kinesis] Inverting dependency control of KinesisProxyV2This closes #12944.,2
[hotfix] Exclude test AWS credentials profile from license checks,2
[FLINK-18513][Kinesis] Omitting AWS SDK services from shaded jar,2
[FLINK-14087][datastream] Clone the StreamPartitioner to avoid being shared at runtime.,1
[FLINK-19118][python] Support Expression in the operations of Python Table API (#13304),1
[FLINK-19108][table] Stop expanding the identifiers with scope aliased by the system with 'EXPR$' prefixThis closes #13293,0
[FLINK-18536][kinesis] Adding enhanced fan-out related configurations.This closes #13015.,5
[FLINK-18959][Runtime] Try to revert MiniDispatcher for archiveExecutionGraph and shutdown cluster upon cancel.This closes #13227.,5
[FLINK-19121][hive] Avoid accessing HDFS frequently in HiveBulkWriterFactoryThis closes #13301,2
[FLINK-15974][python] Support to use the Python UDF directly in the Python Table API (#13325),1
[FLINK-18984][python][docs] Add tutorial documentation for Python DataStream API (#13203),5
[FLINK-19036][docs-zh] Translate page 'Application Profiling & Debugging' of 'Debugging & Monitoring' into ChineseThis closes #13235.,1
[hotfix][runtime] Remove never thrown IOException for ContinuousFileMonitoringFunction#listEligibleFilesThis closes #12005,2
[hotfix][docs] Fix typoThis closes #13241,2
[hotfix][docs] Fix ExecutionEnvironment.scala doc errorThis closes #13324,0
[hotfix] fix typo in the javadocThis closes #13329,2
[FLINK-18598][python][docs] Add documentation on how to wait for the job execution to finish when using asynchronous APIsThis closes #13295.,1
[FLINK-16866] Make jobsubmission non-blockingThis closes #13217,1
[FLINK-19133] Open custom partitioners in KafkaSerializationSchemaWrapper (#13326),2
[FLINK-19097][python] Support add_jars() in Python StreamExecutionEnvironment.This closes #13292.,1
[FLINK-19035] Remove fold from DataStream API,5
[FLINK-19035] Remove DataStream#fold references from docs,2
"[FLINK-19109][task] Ignore isLoopRunning in MailboxExecutor.isIdleWhen closing, this flag is set, but mailbox can still contain(and receive new) mails (e.g. from timers) that should be processed.In particular, this check currently prevents periodic watermarks frombeing emitted.",1
[FLINK-19043][docs-zh] Translate the 'Logging' page of 'Debugging & Monitoring' into ChineseThis closes #13271,1
[FLINK-18337][table] Introduce TableResult#await method to block until data is ready or job finishedThis closes #12688.,5
[hotfix][table][connector] Use CollectionUtil#iteratorToList instead of Guava Lists,1
"[FLINK-19086] Revert ""[FLINK-19052] [serialization] add constructor cache in PojoSerializer""This reverts commit 162e3ead63e5766cf2116af09922a88537889e53which causedperformance regression 2020-08-28 in globalWindow benchmark",1
[FLINK-18333][jdbc] Harden fragile UnsignedTypeConversionITCase caused by MariaDB4jThis closes #13244,5
[FLINK-19148][docs] Fix crashed table in Flink Table API & SQL docsThis closes #13338,2
[hotfix][datastream] Fix the formatting of StreamEdge class,0
[FLINK-18832][datastream] Add compatible check for blocking partition with buffer timeoutFrom the requirement it is no need to enable buffer timeout for batch jobs since the downstream can only consume data when the upstream finishes.Furthermore the current implementation of BoundedBlockingSubpartition does not consider the concurrent issue from the flusher thread by enablingbuffer timeout. So it is nice to check this compatibility during job graph generation in advance and give a friendly message hint for users.This closes #13209.,1
[FLINK-19131][python] Add support of Python 3.8 in PyFlinkThis closes #13334.,2
"[FLINK-18913][docs][python] Add a ""TableEnvironment"" document under the ""Python API"" -> ""Table API User's Guide"" sectionThis closes #13314.",1
"[FLINK-19090][docs-zh] Translate ""Local Cluster"" page into ChineseThis closes #13279",1
[FLINK-17637][connector] fix the unstable HadoopS3RecoverableWriterITCase#testCleanupRecoverableState,3
[FLINK-14942][state-processor-api] Support Savepoint deep copy,1
"[FLINK-14942][docs] remove the ""shallow copy"" note in ""Modifying savepoints"" section, fix exampleThis closes #13309",0
[hotfix] Remove unused import in CheckpointCoordinatorTestingUtils,3
[hotfix] Use camel format to replace abbreviations for the variable names.,1
[hotfix] Throws the causing exception if a future is completed exceptionally unexpectedly.i,1
"[FLINK-18641][checkpointing] Fix CheckpointCoordinator to work with ExternallyInducedSource.This patch fixes the CheckpointCoordinator to make it work withExternallyInducedSource in cases that the task snapshots are triggeredby the external systems via master hooks, rather than the checkpointcoordinator.The problem in the current code is that when the task snapshots aretriggered externally via the master hooks, the checkpoint coordinatormay receive all the acks from the tasks before the master state snapshotcompletes. And this leads to checkpoint failure. The fix is to onlyfinalize the checkpoint when all of the operator coordinator checkpoint,master snapshots and task snapshots are fully taken.",1
[FLINK-18641][runtime/checkpointing] Checkpoint the operator coordinators before triggering the master hooks.We have to take the snapshot of the master hooks after the coordinator checkpoints has completed.This is to ensure the tasks are checkpointed after the OperatorCoordinators in caseExternallyInducedSource is used.,1
[hotfix] Make it more clear that the master hooks are also fired in the checkpoint timer thread.,1
[hotfix] Add unit test for checkpoint failure.,0
[FLINK-19112][table] Improve usability during constant expression reduction- Throw more meaningful exceptions.- Make metrics a no-op instead of throwing an exception.- Use job parameters instead of entire configuration.- Give meaningful exception for getExternalResourceInfos instead of NPE- Add more documentation at various locations- Skip expression reduction in case of an exceptionThis closes #13340.,2
[hotfix] Do not mix BulkSlotProvider into SlotProvider/SchedulerImpl,1
"[FLINK-18957] Factor out PhysicalSlotRequestBulk and PhysicalSlotRequestBulkChecker interfacesTo reuse PhysicalSlotRequestBulkChecker in SlotSharingExecutionSlotAllocator for tracking bulk of logical slots,we factor out PhysicalSlotRequestBulk and PhysicalSlotRequestBulkChecker interfaces.This way we can later provide their implementation for SlotSharingExecutionSlotAllocator.PhysicalSlotRequestBulkChecker just tracks physical slot fulfil-ability of pending slots in slot pool.If they cannot be fulfilled after timeout, the checker cancels the bulk.",1
[FLINK-18957] Use NoResourceAvailableException for bulk timeout,1
"[FLINK-18957] Track physical ResourceProfile with the SharedSlot in SlotSharingExecutionSlotAllocatorPhysicalSlotRequestBulkChecker requires ResourceProfiles of pending physical slots in PhysicalSlotRequestBulk.Therefore, SlotSharingExecutionSlotAllocator needs ResourceProfiles to create its PhysicalSlotRequestBulkto track the logical bulk fulfil-ability and we need to keep ResourceProfiles in SharedSlots.To achieve this, we move resourceProfileRetriever from MergingSharedSlotProfileRetriever to SlotSharingExecutionSlotAllocator.",2
[hotfix] Make logical slot DummyPayload public to reuse in other tests,3
"[FLINK-18957] Implement logical request bulk tracking in SlotSharingExecutionSlotAllocatorAfter we started to allocate physical slots and then logical slots from them for a bulk request in SlotSharingExecutionSlotAllocator,we need to track the fulfil-ability of the logical slot request bulk. If it cannot be fulfil after the requested timeout,we have to cancel all logical slot request futures to fail the bulk allocation.The underlying shared physical slots may be occupied by logical slots from different bulks.Hence, a physical slot request should be canceled only if there are no logical slots/bulks which need it.This ensures we will not wait indefinitely if all required slots for a bulk cannot be fully fulfilled.Track fulfil-ability steps:- Create a SharingPhysicalSlotRequestBulk to track  - all physical requests and  - logical slot requests (logical slot requests only which belong to the bulk)- Mark physical slot request fulfilled in SharingPhysicalSlotRequestBulk, once its future is done- If any physical slot request fails then clear the LogicalSlotRequestBulk to stop the fulfil-ability check- Schedule a fulfil-ability check in PhysicalSlotRequestBulkChecker for the SharingPhysicalSlotRequestBulk- In case of timeout cancel/fail the logical slot requests of the bulk in SharedSlot(s)This closes #13181.",2
[FLINK-19094][docs] Revise the description of watermark strategy in Flink Table documentThis closes #13282,2
[FLINK-19163][python][build system] Add building py38 wheel package of PyFlink in Azure CI (#13362),2
[FLINK-19147][sql-client] Support AutoCloseable interface for CliClientThis closes #13335.,1
[FLINK-19119][python][docs] Update the documentation to use Expression instead of strings in the Python Table APIThis closes #13348.,1
[FLINK-19166][table-runtime] StreamingFileWriter should register Listener before the initialization of buckets,5
[FLINK-18622][python] Add Table.limit method in the Python Table API (#13364),1
[hotfix][docs][python] Improve the documentation to use TableResult.wait,1
[hotfix][python] Add the version information for TableResult.wait,5
[FLINK-19070][hive] Hive connector should throw a meaningful exception if user reads/writes ACID tablesThis closes #13315,1
[FLINK-17779][orc] Orc file format support filter push downThis closes #13306,1
[hotfix][FLINK-19183][hive] Fix compile error by TableEnvHiveConnectorITCase.testTransactionalTable,3
[FLINK-16905][python] TableEnvironment.from_elements support ExpressionThis closes #13365.,1
[FLINK-18823][format] Support serialization for debezium-json formatThis closes #13333,5
[hotfix][runtime] Add missing Nullable annotations to vertex colocation group,1
[FLINK-14870][runtime] Ensure JobVertex slot sharing group to be non-null when created from a StreamNode,1
[hotfix][runtime] Close SlotPool in main threadOtherwise main thread check violation can happen if the SlotPool#close() triggers SlotPool#releaseSlot().,0
[hotfix][runtime] Always invoke SlotPool#releaseTaskManager() with a non-null errorThe error will be used to complete futures exceptionally. A null error can cause unexpected NullPointerException.,1
[FLINK-14870][runtime] Drop the nullable assumption of JobVertex slot sharing group,4
[FLINK-14870][runtime] Drop the nullable assumption of slot sharing group in scheduler components,4
[FLINK-14870][runtime] Drop the nullable assumption of slot sharing group in ScheduledUnit and remove the consequently unused methods in SchedulerImpl,1
[FLINK-18951][python][docs-zh] Translate Python Table API dependency management documentation into chinese.,2
[FLINK-18951][python][docs] Add documentation for dependency management for Python DataStream API.This closes #13232.,5
[FLINK-18833][docs][python] Improve the Python documentation about sqlThis closes #13075.,2
"[FLINK-19151][yarn] Update container resource normalization algorithm, with respect to Yarn FairScheduler.This closes #13347.",5
"[FLINK-19135] Strip ExecutionException in (Stream)ExecutionEnvironment.execute()In FLINK-14850 we changed the execute() method to be basicallyfinal JobClient jobClient = executeAsync(...);return jobClient.getJobExecutionResult(userClassloader).get();Unfortunately, this means that execute() now throws anExecutionException instead of a ProgramInvocationException orJobExecutionException as before. The ExecutionException is wrapping theother exceptions that we were throwing before.We didn't notice this in tests because most tests useTest(Stream)Environment which overrides the execute() method and sodoesn't go through the PipelineExecutor logic or the normal code path ofdelegating to executeAsync().This change brings us back to the previous behaviour.",4
[FLINK-19193] Recommend stop-with-savepoint in upgrade guidelines,2
[FLINK-18980][e2e] Add timeout to get logs from stalling test,3
[hotfix] Fix checkstyle violations in JobGraph and JobGraphTest,3
[FLINK-17016][runtime] Use SlotSharingExecutionSlotAllocator for pipelined region scheduling,1
"[FLINK-17016][runtime] Enable to use pipelined region scheduling strategyIt can be enabled via config option ""jobmanager.scheduler.scheduling-strategy=region""",5
[refactor][connectors] Backport of the connector-base exception handling from the Kafka Connector Pull Request,4
[FLINK-18447][build] Package 'flink-connector-base' into 'flink-dist',2
[hotfix][core] Add to Source Enumerator convenience methods to assign single split,1
[FLINK-19205][core] Add access to configuration and hostname in the SourceReaderContext,5
[hotfix][connectors] Add RequestSplitEvent to 'flink-connector-base',2
[hotfix][testing] Add a set of parameterizable testing mocks for the Split Reader APIThese utils are different to the previous mocks in that they don't hard-code ranges of values (integers)to emit and expect (validate) but that they return given sets of records and collect produced records.That makes them more reusable and more suitable for Arrange/Act/Assert-style testing.,3
[FLINK-19162][connectors] Add 'recycle()' to the RecordsWithSplitIds to support reuse of heavy objects.,1
"[refactor][DataStream API] Make DataStreamUtils.collect() methods more flexible.This supports simple ways of pulling bounded streams to the client, as well as a defined number ofelements from an unbounded stream.",1
[hotfix][javadocs] Improve JavaDocs for StreamExecutionEnvironment.addSource(...),1
[FLINK-18680][connectors] Make connector base RecordsWithSplitIds more lightweight.This turns the RecordsWithSplitIds structure from a holder of materialized collections toa simple iterator-like structure to allow for lazy materialization and object reuse.,1
"[hotfix][docs-zh] Fix invalid links in ""Concepts & Common API"" page of ""Table API & SQL"" (#13308)",2
[FLINK-19170][table] fix parameter naming error (#13361),0
"[hotfix] [javadocs] remove inexistent memory unit reference from MemorySize.javaThere is no ""q"" unit on `MemoryUnit` enum",4
[hotfix][javadocs] Fixed typo in Output.java (#12541),2
[hotfix][typo] fix typos in ProcTimeRangeBoundedPrecedingFunction & ProcTimeBoundedRangeOver (#12672)Co-authored-by: zoudan <zoudan@bytedance.com>,1
[FLINK-19083] Remove deprecated DataStream#splitThis closes #13343,5
[FLINK-19083] Remove deprecated DataStream#split from documentation,2
[hotfix][table] Refactor DataGen source to use LogicalTypeVisitor pattern,2
[FLINK-18735][table] Support bounded datagen tables,5
[FLINK-18735][table] Add support for more types to DataGen source,5
[FLINK-18735][table] Update documentation of DataGen source,5
[FLINK-18735][table] Add additional logging to DataGen sourceThis closes #13010,5
[hotfix] Fix checkstyle formatting,0
[hotfix] Fix checkstyle violations,0
[hotfix] Fix Pojo comparator field accessThe PojoComparator assumes it can access a field of a pojo directly. It assumes the field is either public or setAccessible was called before. This is the case though only if  the record went through serialization. This is not the case e.g. in CollectionExecution mode.Starting from this commit we make all fields accessible inPojoComparator constructor.,1
[hotfix] Extract joda conversions to a separate class,4
[hotfix] Fix schema to DataType/Type conversion,5
[hotfix] Fix time-micros and timestamp-micros handling,0
[hotfix] Migrate AvroTypesITCase to blink planner,2
[FLINK-18192] Upgrade avro to 1.10This commit upgrades the default version of avro that flink-avro will use. It should be possible to downgrade the avro version in a user job as the binary format is compatible and we do not expose any dependencies on avro in the API.Additionally this commit fixes handling of logical types: time-micros and timestamp-micros as well as interpretation of timestamp-millis in the AvroRowDataDeserializationSchema.,5
[FLINK-18802] Create an uber jar for avro for sql-client,1
[FLINK-18978][state-backends] Support full table scan of key and namespace from statebackendThis closes #13179,1
[FLINK-19092][sql-parser] Support to parse comment on computed columnThis closes #13352,1
[FLINK-18335] [tests] Add more debuging logs for NotifyCheckpointAbortedITCase (#13349),2
[FLINK-18695][network] Force netty to use direct buffers instead of heap buffers,1
[FLINK-19158][e2e] Increase download timeouts,1
[FLINK-19037] Forward ioExecutor from ClusterEntrypoint to DispatcherThis closes #13390,1
[FLINK-19152] Remove Kafka 0.10.x and 0.11.x connectors,4
[hotfix][hadoop] Minor code cleanups in HadoopFileStatus,2
[FLINK-19218][core] Remove inconsistent/misleading locality information from Local File Splits.,2
"[FLINK-19221][core][hadoop] Introduce the LocatedFileStatus to save block location RPC requests.When the HDFS Client returns a FileStatus (description of a file) it frequently returns a'LocatedFileStatus' which already contains all the BlockLocation information.We here expose this on the Flink side, to save RPC calls to the Name Node. For example file sources oftenrequest block locations for all files (to facilitate locality aware assignments), currently resulting inone RPC call to the Name Node for each file.When the FileStatus obtained from listing the directory (or getting details for a file) already hasthe block locations, we can save the extra RPC call per file to obtain that block location information.This closes #13394",5
[FLINK-17393][connectors] Wakeup the SplitFetchers more elegantly.This closes #13366,2
"[FLINK-19225][connectors] Various small improvements to SourceReaderBase - A slight improvement of main loop, to avoid a branch and improve inlining friendlyness. - Check for fetcher errors when moving between fetched.   This is still guaranteed to propagate the errors, just some micro- or milliseconds later.   In return we save one or two volatile accesses on the hot per-record path. - Extend logging in SourceReaderBase to simplify the debugging in the case something goes wrong. - Add Task name to Split Fetcher Threads to make it easier to attribute the threads when   analyzing stack traces.",1
[hotfix][tests] Move constants in SplitFetcherTest relevant to only one test into test method,3
"[refactor][core] Eagerly initialize the FetchTask to support proper unit testingPreviously, the FetchTask was constructed lazily in the run() method, which gets in theway of unit testing via the runOnce() method.",1
[FLINK-18128][connectors] Ensure idle split fetchers lead to availability notifications.,2
[FLINK-19223][connectors] Simplify Availability Future Model in Base ConnectorThis implements a model closer to the AvailabilityListener and AvailabilityHelper in the flink-runtime.This closes #13385,2
[FLINK-19245][connectors] Set default capacity for FutureCompletingBlockingQueue.,1
[hotfix][tests] Extend test coverage for FutureCompletingBlockingQueue.,3
[FLINK-18604][hbase] HBase ConnectorDescriptor can not work in Table APIThis closes #13276,1
[hotfix][docs] Fix broken link in datastream_api.md and datastream_api.zh.md,5
[FLINK-17554] Allow to register release hooks for the classloaderThis closes #13355,1
[hotfix] Add missing log4j2-test.properties files,2
"[FLINK-17393][connectors] (follow-up) Wakeup the SplitFetchers more elegantly.  - Remove the InterruptedException from methods where we now do not expect an InterruptedException    to be thrown any more.  - Removes the code that was previously clearing the interruption flag for ""benign interruptions"".  - Adjust comments to reflect actual code model  - Remove unused method  - Adjust tests to not use arbitrary interruptions but local (in the wakeup scope only)",1
[FLINK-19225][connectors] Various small improvements to SourceReaderBase (part 2)  - SourceReaderBase avoids not emitting an element (and exiting to caller / mailbox) when    transitioning between fetches  - Avoid eager checking of queue empty condition (requires lock acquisition) when determining    whether end of input is reached. Check that expensive condition last instead.,5
[hotfix][connectors] Improve JavaDocs for SingleThreadFetcherManager,2
[FLINK-19250][connectors] Fix error propagation in connector base (SplitFetcherManager).This makes sure that the reader is notified / woken up when the fetcher encounters an error.,0
[FLINK-19000] Forward initialization timestamp from Dispatcher to ExecutionGraphThis closes #13368,5
[hotfix] Consider INITIALIZING JobState also as scheduled in CliFrontend,5
[FLINK-19241] Forward ioExecutor into ResourceManagersThis closes #13399,2
"[FLINK-19251][connectors] Avoid confusing queue handling in ""SplitReader.handleSplitsChanges()""This removes the queue (and repeated queue passing logic) and simly passes a list of split changesdirectly and once, for the fetcher to handle.This closes #13400",0
[FLINK-19173][python] Introduce BatchArrowPythonGroupAggregateFunctionOperatorThis closes #13369,1
"[FLINK-18974][docs-zh]Translate the 'User-Defined Functions' page of ""Application Development's DataStream API"" into Chinese (#13225)Co-authored-by: zhushang <zhushang@qutoutiao.net>",5
[FLINK-17879][python] Update Python row serializer to support RowKindThis closes #13371.,1
[FLINK-19005][docs] List JDBC as a source of Metaspace leaks,5
[FLINK-9992][tests] Fix FsStorageLocationReferenceTest#testEncodeAndDecode by adding retries to generate a valid pathThis closes #13034,1
"[FLINK-19187][examples-table] Add a new basic Table API exampleThe example shows how to create, transform, and query a table. It should give a first impressionabout the look-and-feel of the API without going too much into details.This closes #13372.",1
[FLINK-18918][python][docs] Add dedicated connector documentation for Python Table APIThis closes #13193,2
[FLINK-19246][table-planner] Fix TableSourceITCase.testStreamScanParallelism fails on AzureThis closes #13407,0
[FLINK-19262][API/DataStream] Can not setParallelism for FLIP-27 sourceThis closes #13402,1
[FLINK-19184][python] Introduce BatchExecPythonAggregateRule and BatchExecPythonGroupAggregateThis closes #13388,2
[hotfix][docs][rest] Update rest_v1_dispatcher.html,5
[FLINK-19002][canal][json] Support to only read changelogs of specific database and table for canal-json formatThis closes  (#13294),5
[FLINK-19277][python] Introduce BatchArrowPythonGroupWindowAggregateFunctionOperator (#13415),1
[FLINK-18870][Kinesis] Update Kinesis Consumer website to document EFO Feature (#13261),2
[FLINK-19224][state-processor-api] Support reading window operator stateThis closes #13384,1
[FLINK-19064][hbase] HBaseRowDataInputFormat is leaking resourcesThis closes #13275,5
"[FLINK-19280][jdbc] Fix option ""sink.buffer-flush.max-rows"" for JDBC can't be disabled by setting to zeroThis closes #13432 Co-authored-by: dalong01.liu <dalong01.liu@vipshop.com>",1
[FLINK-18515][Kinesis] Adding FanOutRecordPublisher for Kinesis EFO supportThis closes #13189.,1
[FLINK-18661][Kinesis] Stream consumer Registration/Deregistration,2
[FLINK-18661] [kinesis] Updated FullJitterBackoff Default values for describeStream and describeStreamConsumerThis closes #13189.,5
[FLINK-19299][tests] Fix that NettyShuffleEnvironmentBuilder#setBufferSize does not take effect,1
[refactor][python] Rename AbstractPythonFunctionOperatorBase to AbstractPythonFunctionOperator,1
[FLINK-19301][python] Improve the package structure of Python DataStream APIThis closes #13436,5
[FLINK-19161][file connector] Add first version of the FLIP-27 File SourceThis closes #13401,2
[hotfix][runtime] Remove commented-out annotation in SourceOperator,1
[FLINK-19244][csv] Fix CSV format can't deserialize null ROW fieldThis closes #13426,0
[FLINK-18713][table-planner-blink] Change duration ConfigOption to duration typeThis closes #13392,5
[FLINK-19321][streaming][table] Fix CollectSinkFunction does not define serialVersionUIDThis closes #13442Co-authored-by: zhushang <zhushang@qutoutiao.net>,1
[FLINK-18725][e2e] Use ClusterIP instead of NodePort and remove query port in internal jobmanager serviceJobManager rest service and TaskManager query state service are optional. They could be enabled via apply two more yaml files. Refer to https://ci.apache.org/projects/flink/flink-docs-master/ops/deployment/kubernetes.html#deploy-job-cluster for more information.,5
[FLINK-18950][python][docs] Add documentation for Operations in Python DataStream APIThis closes #13230,5
[FLINK-17910][e2e] Fix debug log output to investigate rare test failure,0
[FLINK-19281][table-planner-blink] LIKE cannot recognize full table pathThis closes #13431,2
[FLINK-19186][python] Add Python building blocks to make sure the basic functionality of Pandas Batch Group Aggregation could workThis closes #13421,1
[FLINK-19272][table-common] Add metadata interfaces for FLIP-107Adds all @PublicEvolving interfaces mentioned in FLIP-107.This closes #13425.,1
[FLINK-17159] Add sanity check to ES6 ElasticsearchSinkITCaseWe now try and ping the cluster in a @Before method just like the normalES sink would.,1
[FLINK-19289][k8s] Remove pods terminated during JM failover.This closes #13448.,0
"[FLINK-19128][sql-client] Make ""parallellism"" and ""restart-strategy"" not set in sql-client-defaults.yaml by defaultThis closes #13332",1
[FLINK-19140][docs] Fix UDTF documentation which uses wrong aliasThis closes #13429.,0
"[FLINK-19270] Extract CheckpointableKeyedStateBackend interfaceThis commit extracts a minimal interface from AbstractKeyedStateBackend.This interface is returned by StateBackend interface, making it easierto implement custom keyed state backend without pulling in all the logicof AbstractKeyedStateBackend.This closes #13405",2
[FLINK-19229][python] Introduce the PythonStreamGroupAggregateOperator for Python UDAF. (#13420),1
[FLINK-19227][table] The catalog is still created after opening failed in catalog registeringThis closes #13414,2
[FLINK-18548][table-planner] Support temporal join on temporal table with computed columnsThis closes #13289,1
[FLINK-19361][hive] Create a synchronized metastore client to talk to a remote HMSThis closes #13455,1
[FLINK-16147][table-common] Let WatermarkSepc#toString contain outputType fieldThis closes #11125.,2
[FLINK-19311][coordination] Add ResourceRequirement(s),1
[FLINK-19243][kubernetes] Bump snakeyaml to 1.27,2
[FLINK-19243][elasticsearch] Bump snakeyaml to 1.27,2
[FLINK-19243][build] Enforce snakeyaml 1.27+,1
[FLINK-19273][sql-parser] Support METADATA syntax in SQL parserUpdates the parser to accept METADATA syntax for columns and inthe LIKE clause. Reworks the class hierarchy of table columns.Introduces new keywords and grammar.This closes #13452.,1
[FLINK-19333][python] Introduce BatchArrowPythonOverWindowAggregateFunctionOperatorThis closes #13451,1
"[FLINK-12250] Rewrite assembleNewPartPath to let it return a new PartPathWhile debugging some code, I've noticed assembleNewPartPath doesnot really return a new path. Also rewrote the code a bit so themutable inProgressPart is changed in a single place.",4
[FLINK-19165] Refactor the UnilateralSortMergerThis is a preparation for introducing a sorted inputs in BATCH executionmode. It refactors the UnilateralSortMerger into more composable pieces.Additionally it adds the option to use a push-based approach instead ofspawning a Reader thread that consumes from an input iterator.This closes #13357,1
[FLINK-19331][state-processor-api] Native resource leak when working with RocksDBThis closes #13445,5
"[FLINK-11779] Update the description of the CLI -m parameterWe now document that the CLI ignores -m parameter if high-availabilityis ZOOKEEPER1. Change the description message of -m parameter of `DefaultCLI` and`FlinkYarnSessionCli`.2. Change the description message of""rest.address.port""",1
[FLINK-11779] Update documentation about RestOptions,2
[FLINK-11779] Update documentation based on bin/flink output,2
[hotfix][network] Annotate NetworkSequenceViewReader#getNextBuffer as Nullable.,1
"[FLINK-19338][connectors/common] Remove null-check from SourceCoordinatorContext#unregisterSourceReader.If an error happens during startup, the reader may not be registered (yet), but cleanup is triggered anyways.",4
[hotfix][datastream] Chaining serialization exception during job graph generation.,5
[FLINK-19026][network] Adding priority events to buffer data type.It generalizes the current special treatment of unaligned checkpoints and will allow a consistent treatment of priority events on both input and output.The new type facilitates detection of priority events without the need to inspect the contents of a buffer on input side.It also eases the special treatment of priority event on output side as the contextual priority flag is now inlined after the buffer has been created.,1
[FLINK-19026][network] Adding PrioritizedDeque and use it in PipelinedSubpartition.PrioritizedDeque supports enqueue elements with priority such that it will be polled after all existing priority elements but before any non-priority element.It is a building block for fair scheduling with priority elevation that will be used also on input side in the next commits.,1
[FLINK-19026][network] Removing unnecessary priority flag on output side.The priority information is fully incorporated in Buffer.DataType now.,5
"[FLINK-19026][network] Generalizing BufferAndAvailability and BufferAndBacklog to capture the DataType of the next record.The data type of the next record allows to check for availability, whether it's an event, and whether the event has a priority.It also will allow handling future data types more smoothly.",5
[FLINK-19026][network] Move sequence number into PipelinedSubpartition and relay through BufferAndAvailability and BufferAndBacklog.The sequence number will be used in input side to avoid spurious priority notification in later commits.,1
[FLINK-19026][network] Refactor SingleInputGate#waitAndGetNextData.Better distinguishes between optional and non-optional variables. Add short cut for empty buffers.Next commit will build on this refactoring to incorporate priority events.,4
[hotfix][network] De-mockitofy InputGateFairnessTest.,3
"[FLINK-19026][network] Simplify lock acquisition in InputGates while polling.This is an alternative fix for FLINK-12510, where a cyclic deadlock can happen when a subpartition is being requested, another subpartition is freed, and data is being polled at the same time on an UnionInputGate. This fix avoids double-lock acquisition on polling by moving the availability notification for a newly acquired subpartitions outside of the lock of ResultPartitionManager. This change may trigger a availability notification on Subpartition without data being available, however, all relevant components are guarded against spurious wakeups.",5
[FLINK-19026][network] Using PrioritizedDeque on input side.PriorityDeque is also used in InputGates. BufferOrEvent and InputWithData are enriched with a flag indicating that there are more priority events.(Note relaying the DataType as on the output side would require lock acquisitions which are not warranted at this point in time),1
"[FLINK-19026][network] Simplify output priority notification.BufferAvailabilityListener#notifyPriorityEvent now is a simple notification to avoid any kind of secondary data flow on output side as it was originally intended before.For remote channels, notifyPriorityEvent behaves like an extra notifyDataAvailable call as an event is always pollable. For local channels, notifyPriorityEvent ultimately informs InputGate that the respective channel has a priority event.",5
[hotfix][network] Use IOExceptions where possible in CheckpointBarrierHandler.,0
"[FLINK-19026][network] Move spilling into channels.A future commit moves the Unaligner completely into task thread, which would result in late spilling of in-flight data during polling and potentially delay unBecause channels are now responsible for spilling in-flight data during unaligned checkpoint, in-flight data can be spilled as soon as the checkpoint has been.",5
"[FLINK-19026][network] Moving priority event handling from BufferReceivedListener to CheckpointedInputGate.This commit renders BufferReceivedListener obsolete and will allow a following commit to remove it entirely.A side-effect of this commit is that all events are handed over from CheckpointedInputGate to StreamTaskNetworkInput and break up the poll loop. However, since events are rare, it should have no visible impact on the throughput.",4
[FLINK-19026][checkpointing] Remove synchronization from CheckpointBarrierUnaligner.This concludes the refactoring: All priority events use the same buffer hand-over as normal events; the buffers are just reordered.Notification of priority event bypasses CheckpointBarrierHandler and directly triggers CheckpointedInputGate#processPriorityEvents.Note that checkpoints are not cancelled anymore if Unaligner received all barriers. This behavior is now in line with Aligner.,0
[FLINK-19026][network/task] Remove unused BufferReceivedListener and AbstractInvokable#executeInTaskThread.,1
[FLINK-19026][tests] Rewritten UnalignedCheckpointITCase to use new source interface.The rewritten test induces heavy backpressure which would not work at all with aligned checkpoints or legacy sources during the timeout period.,1
[FLINK-19286][runtime] Replace java streams on critical paths with normal for-loop,2
[FLINK-19286][runtime] Improve region vertex sorting performance,1
[FLINK-19286][runtime] Improve region sorting performance,1
[FLINK-19189][runtime] Enable pipelined region scheduling by default,0
[FLINK-19189][e2e] Let TPC-DS tests run in POINTWISE_EDGES_PIPELINED data exchange mode,4
[FLINK-19339] Support unions with logical types in Avro >= 1.9.xAvro 1.9.x introduced yet another mechanism for registering/looking upconversions for logical types.If a logical type is part of a union a static field MODEL$ of type SpecificDatais added to the generated Avro class with registered conversions for logical types.In this commit we try to use that SpecificData in AvroSerializer andAvro(De)SerializationSchema whenever available instead of instantiating a newunrelated one.The change is backwards compatible and if the field is not available wefallback to the old ways.,4
[FLINK-18737][docs-zh] Translate jdbc connector pageThis closes #13003,1
[FLINK-19364][python] Add Batch Physical Pandas Group Window Aggregate Rule and RelNodeThis closes #13460.,1
[FLINK-19178][runtime] Disable calculating managed memory fraction for fine grained resource specs.Disable for the following reasons:- Existing fraction calculation algorithm does not work with various managed memory use cases.- Currently there's no use cases for fine grained resource specs in production.It can be enabled later if we come up with a fraction calculation algorithm that works properly with various managed memory use cases.,1
[FLINK-19178][core] Introduce configuration option for managed memory consumer weights.,5
[FLINK-19178][core] Introduce ManagedMemoryUseCase.,1
[FLINK-19178][core] Extend Transformation for various managed memory use cases.,1
[FLINK-19178][runtime] Extend StreamNode for various managed memory use cases.,1
[FLINK-19179][runtime] Introduce ManagedMemoryUtils for configuration and calculations of managed memory.,5
"[FLINK-19179][runtime] Extend StreamConfig for various managed memory use cases.Convert managed memory fraction of use cases to fraction of slot, w.r.t. the configured use case weights.",1
[FLINK-19179][runtime] Calculate managed memory fractions for all use cases.This closes #13416.,1
"[FLINK-19391][network] Moved notification during subpartition request to the requester.This change avoid a deadlock on requestLock that may happen with concurrent release via input gate.This commit also fixes the broken SingleInputGateTest#testPartitionRequestLogic, where pollNext was a no-op.The deadlock was introduced by the alternative fix for FLINK-12510 in FLINK-19026 .The alternative fix avoided double lock acquisition in SingleInputGate#waitAndGetNextData by moving notifyDataAvailable from ResultSubpartition#createReadView to ResultPartitionManager#createSubpartitionView, which solved the circular deadlock of FLINK-12510 by not acquiring the buffers lock of PipelinedSubpartition.However, that fix didn't go far enough. For local channels, it is still possible to create a similar deadlock. While SingleInputGate reads from LocalInputChannel, it holds the lock inputChannelsWithData. The channel may start requesting the partition and tries to acquire requestLock.At the same time there is an update of partition info, which acquires the requestLock and notifies the SingleInputGate, which needs to lock on inputChannelsWithData.The solution is to first acquire the partition and release requestLock before notifying SingleInputGate.",5
"[FLINK-19320][task] Remove RecordWriter#clearBuffersPreviously, RecordWriter#clearBuffers was used to recycle the partially filled buffer in the serializer. However, currently the serializer does not contain any network buffer any more. The method now is used to finish the current BufferBuilders and only some tests and BatchTask use it. Actually, these usage should be replaced by RecordWriter#close which dose the same thing. So this patch removes RecordWriter#clearBuffers and the corresponding test cases.",3
[hotfix] Remove outdated description in Javadoc of RecordWriterThis closes #13447,2
[hotfix] Remove unused RecordWriterTest#TrackingBufferRecyclerThis closes #13447,3
"[FLINK-19302][network] Fix flushing BoundedBlockingResultPartitionCurrently, when flushing the BoundedBlockingSubpartition, the unfinished BufferConsumer will be closed and recycled, however the corresponding BufferBuilder is not finished and the writer can keep coping records to it which can lead to loss of data. This patch fix the issue by finishing the corresponding BufferBuilders first when flushing a BoundedBlockingResultPartition.",5
"[FLINK-19323][network] Small optimization of RecordWriter#serializeRecordCurrently, when serializing a record, the serializer will first skip 4 bytes for length filed and serialize the record. Then it gets the serialized record length and skips back to position 0 to write the length field. After that, it skip again to the tail of the serialized data. This patch avoids the last two skips by writing length field to position 0 directly.",5
[FLINK-19304][coordination] Add FLIP-138 feature toggle,1
[FLINK-19288] Make the InternalTimeServiceManager an interfaceThis refactoring allows to replace the InternalTimerService with adifferent implementation.Moreover it removes methods for retrieving the number of registeredtimers from AbstractStreamOperator(s) which were introduced for tests.This closes #13443,3
[FLINK-18906][hotfix] Fix JavaDoc for in InputProcessorUtil,2
[FLINK-18906][hotfix] Move isFinished checkState inside InputGate#resumeConsumptionThis will minimize the visible interface of an Input as used by CheckpointBarrierHandlers,0
[FLINK-18906][hotfix] Fix method names in CheckpointBarrierAlignerTestBase,3
[FLINK-18906][task] Construct StreamTaskSourceInput earlier in the OperatorChaininstead of in StreamMultipleInputProcessor. This will allow CheckpointBarrierHandlers touse and reference StreamTaskSourceInput instances.,1
[FLINK-18906][task] Decouple CheckpointBarrierHandlers from InputGatesThis is still only a refactor. It extracts an interface from the IndexedInputGateto be used by CheckpointBarierHandlers.,0
[FLINK-18906][hotfix] Provide helper and/or functions on availability futures,1
"[FLINK-18906][task] Fix processSingleStep semanticPreviously processSingleStep call could be ignored, and wouldn't process mail actions",0
[FLINK-18906][test] Generalise testing code for MultipleInputStreamTaskThis will allow to re-use it for checkpointing tests with chained sources,3
"[FLINK-18906][task] Expose InputProcessorUtil#createCheckpointBarrierHandlerThis will be useful in a next commit, where MultipleInputStreamTask will needto have an access to the CheckpointBarrierHandler",0
[FLINK-18906][task] Support StreamTaskSourceInput as BlockabledInputThis commit adds support for StreamTaskSourceInput as BlockableInput passed to CheckpointBarrierHandlers.Effectively this enables checkpointing with chained sources for MultipleInputStreamTask.,0
[FLINK-19134][python] Introduce BasicArrayTypeInfo and PrimitiveArrayTypeInfo for Python DataStream APIThis closes #13327.,5
[FLINK-19372][python] Support Pandas Batch Over Window AggregationThis closes #13475.,1
[FLINK-19124][datastream] Remove ClassLoader parameter from JobClient methods,2
"[FLINK-19377] Change parameters of EventTimeWindowCheckpointingITCaseWith the previous setup, where different parameters are used dependingon the state backend, tests for the heap based backends would alsosucceed when changing testSlidingTimeWindow() to use tumbling windows.This can be a headache for debugging so I'm changing the parameters tobe the same for all backends.",2
[FLINK-18907][test] Move MultipleInputStreamTaskChainedSourcesTest to MultipleInputStreamTaskTest,3
"[FLINK-18907][task] Fix too many endInput calls with chained sourcesSourceOperator's StreamOperatorWrapper was incorrectly emitting endInput eventto the mainOperatorWrapper, based on too simple chaining logic. It was replacedwith `isHead` check.",2
[FLINK-18907][test] Remove now duplicated testClosingAllOperatorsOnChainProperly test,3
"[FLINK-18907][task] Fix numRecordsIn metric with chained sourcesWith chained sources, task's and main operator's number of input recordsare two different things. The first one should take into account only recordscomming in from the network, ignoring records produced inside the task itself(like via a chained source). Main operator should on the other hand reportall records from all of the inputs (regardless if it's a network or chained input).",1
[FLINK-18907][test] Refactor MockSourceReaderMake the synchronisation around availability easier to understand.,1
[FLINK-18907][task] Add test coverage for watermarks with chained sources,3
[FLINK-18907][hotfix] Rename headOperator to mainOperator in the MultipleInputStreamTaskTest,3
"[FLINK-18907][hotfix] Replace old processIf/WhileAvailable with processSingleStepThe new versions have a bit different semantc. They process data/keep processing data,as long something was processed, instead of relaying on input/output availability.The biggest difference is, that processSingleStep can process mailbox actionseven if input is not available.",5
[FLINK-18907][task] Fix and add test coverage for watermarks gauges with chained sources,3
[FLINK-18907][hotfix] Fix the testWatermarkAndStreamStatusForwarding to do what it was intended to do,3
[FLINK-18907][test] Add stream status forwarding test for chained sourcesCurrently the test is affected by a known bug FLINK-18934.,2
"[FLINK-19411][task] Fix construction of MultipleInputStreamTask with union inputsPreviously number of input gates was assumed to be the same as number of logicalinputs, which is not true in case of union inputs.",2
[FLINK-19098][json][csv] Make RowData CSV and JSON converters publicThis closes #13303Co-authored-by: Jark Wu <jark@apache.org>,5
[FLINK-19421][python] Support Python UDAF in streaming modeThis closes #13462,1
[FLINK-18759][tests] Add readme.md for TPC-DS tools (#13283)[FLINK-18759][tests] Add readme.md for TPC-DS tools,2
[FLINK-19403][python] Support Pandas Stream Group Window AggregationThis closes #13483.,1
[FLINK-19417][python] Fix the implementation of StreamTableEnvironment.from_data_streamThis closes #13491.,5
[FLINK-18842][e2e] Add 10 minute timeout to building docker container,2
[hotfix][docs] Improve wording in documentation README,2
[FLINK-18795][hbase] Support HBase 2 delegation tokens,1
[FLINK-18795][hbase] Support for HBase 2This closes #13128,1
[FLINK-19433] [docs][table] Correct example of FROM_UNIXTIME function in documentThis closes #13493Co-authored-by: zhangqike <death_note0539>,2
[hotfix][start scripts] Remove java version check,4
[FLINK-19014][e2e] Increase startup timeout,1
[FLINK-16789][coordination][rest] Expose TaskExecutor JMX port,2
[hotfix][table-planner-blink] Improve exception of item operatorThis closes #13485,1
[FLINK-17818] Fix argument check of CsvReader.pojoType(),0
[FLINK-19137] Bump Parquet from 1.10.0 to 1.11.1,2
[FLINK-19137] Update NOTICE in flink-sql-parquet after Parquet version bump,2
[FLINK-19137] Update NOTICE in flink-connector-hive after Parquetversion bump,2
[FLINK-19445][hbase] Fix guava version conflict in Hbase 1.4 testCloses #13503,3
[hotfix] Remove outdated test from ManualWindowSpeedITCaseThis was testing old behaviour from when we removed the special alignedwindow operators. We don't need this anymore.,1
"[FLINK-19437][tests] Fix unstable test FileSourceTextLinesITCase.The test was unstable because test data files were not written atomically. Because of that, thestreaming source could ingest partial files, leading to unexpected results.This fix makes file writing atomic by first writing to a hidden temp file and then renaming thefile to the final file path.",2
[FLINK-17480][kubernetes][python] Support running PyFlink on KubernetesThis closes #13322.,3
[FLINK-19429][docs-zh][python] Translate page Data Types into Chinese (#13497),5
[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration (#13434),5
[FLINK-19430][docs-zh][python] Translate page datastream_tutorial into Chinese (#13498),5
[FLINK-14422][runtime] Added memory-related getter methods.,1
"[FLINK-14422][runtime] Added metrics for total memory, available memory, used memory and number of used memory segments.",1
[FLINK-14422][runtime] Extended REST API to also include network memory usage.This closes #13316.,1
"[FLINK-19388][coordination] Do not remove logical slots from SharedSlot if it is releasing`SharedSlot#release` releases all logical slots in a loop over their collection.The logical slot releases lead to their execution failures.This can cause cancellation of other executions sharing same slot.The execution failure can cause cancelation of other sharing executions by `Scheduler`.The canceled executions subsequently call `SharedSlot#returnLogicalSlot`which modifies the logical slot collection while it is being iterated in `SharedSlot#release`,if the canceled executions share the same slot. This leads to `ConcurrentModificationException`.To avoid the `ConcurrentModificationException`, the logical slot collection can be copied before iterating it.This closes #13511.",2
[hotfix] Fix TaskManagerDetailsHandlerTest compilation failure after merge of FLINK-19388,2
"[FLINK-19258][docs] Fix the wrong example for ""csv.line-delimiter"" optionThis closes #13524Co-authored-by: ron.liu <liudalong@bytedance.com>",0
[FLINK-19400][network] Removed legacy BufferPoolOwner.All implementations are doing only noop operations and it makes implementation of LocalBufferPool seemingly harder.The removal of BufferPoolOwner also eliminates the only source of IOException during NetworkBufferPool#redistributeBuffers and as such respective tests are also removed. The next commit cleans up exception handling.,4
[FLINK-19400][network] Remove superfluous IOExceptions.,4
"[FLINK-16972][network] Correctly enforcing subpartition quota in LocalBufferPool.Previously, it was possible for a subpartition to acquire (maxBuffersPerChannel+1) buffers, before LocalBufferPool became unavailable.Also, requestMemorySegment does not return a buffer for a channel over quota at all, making blocking requests blocking for respective subpartitions.",1
"[FLINK-16972][network] LocalBufferPool eagerly fetches global segments to ensure proper availability.Before this commit, availability of LocalBufferPool depended on a the availability of a shared NetworkBufferPool. However, if multiple LocalBufferPools simultaneously are available only because the NetworkBufferPool becomes available with one segment, only one of the LocalBufferPools is truly available (the one that actually acquires this segment).The solution in this commit is to define availability only through the guaranteed ability to provide a memory segment to the consumer. If a LocalBufferPool runs out of local segments it will become unavailable until it receives a segment from the NetworkBufferPool. To minimize unavailability, LocalBufferPool first tries to eagerly fetch new segments before declaring unavailability and if that fails, the local pool subscribes to the availability to the network pool to restore availability asap.Additionally, LocalBufferPool would switch to unavailable only after it could not serve a requested memory segment. For requestBufferBuilderBlocking that is too late as it entered the blocking loop already.Finally, LocalBufferPool now permanently holds at least one buffer. To reflect that, the number of required segments needs to be at least one, which matches all usages in production code. A few test needed to be adjusted to properly capture the new requirement.",1
"[FLINK-19392] Add default Boundedness to legacy sourcesSo far the legacy sources were made for streaming only.After the introduction of the new Source API and the notionof Boundedness, we can explicitly set the boundedness ofthe legacy source to CONTINUOUS_UNBOUNDED.",1
"[FLINK-19392] Detect runtime execution mode based on boundedness of sourcesThis option, when exposed to the user, it will allow to specifythe mode in which the pipeline is going to be executed, asdescribed in FLIP-134.This closes #13502.",1
[hotfix] Minor StreamGraphGenerator refactoring,4
[FLINK-18818][filesystem][tests] Ignore exceptions after files written successfully in HadoopRenameCommitter test,3
[FLINK-19447][hbase] Run HBase 2.2 integration test only if hadoop version is between 2.8.0 - 3.0.3This closes #13525.,3
[FLINK-19264][runtime] Add JobID to ExecutionAttemptID,1
"[FLINK-19317] Make EventTime the default TimeCharacteristicThis is part of the FLIP-134 (Batch execution for the DataStream API)work.Event time is the only sensible time characteristic for batchprocessing. We therefore change the default value of theTimeCharacteristic from ProcessingTime to EventTime. This means theDataStream API programs that were using event time before now just workwithout manually changing this setting. Processing-time programs willalso still work, because using processing-time timers is not dependenton the TimeCharacteristic. DataStream programs that don't set aTimestampAssigner or WatermarkStrategy will also still work if theydon't use operations that don't rely on (event-time) timestamps.  Thisis true for both BATCH and STREAMING execution mode.With this change, users don't need to callsetStreamTimeCharacteristic(EventTime) anymore. We will make sure theylearn of this by deprecating the method in a follow-up commit.The only real user-visible change of this is that programs that used theKeyedStream.timeWindow()/DataStream.timeWindow() operation, which isdependent on the TimeCharacteristic will now use event time by default.We don't think this operation is useful because the behaviour can besurprising. We recommend users always use an explicit processing-timewindow or event-time window.We also change the default watermark interval from 0 (disabled) to 200to match the previous behaviour of callingsetStreamTimeCharacteristic(EventTime).",1
[FLINK-19317] Remove unnecessary calls to setStreamTimeCharacteristic (java)I'm just removing calls the set EventTime because that's the new defaultnow.I'm also removing most calls to set ProcessingTime because it's notneeded for making processing-time timers/windows work. I only left itfor some tests that check specific failure behavior.I removed calls to set IngestionTime and replaced them by an explicitIngestionTimeWatermarkStrategy. I duplicated the sameIngestionTimeWatermarkStrategy in all the examples/tests because Iexplicitly didn't want to add an IngestionTimeWatermarkStrategy in oneof the core packages so that it is not discoverable because I think weshouldn't encourage users to use ingestion time.,1
[FLINK-19317] Remove unnecessary calls to setStreamTimeCharacteristic (scala)I'm just removing calls the set EventTime because that's the new defaultnow.I'm also removing most calls to set ProcessingTime because it's notneeded for making processing-time timers/windows work. I only left itfor some tests that check specific failure behavior.I removed calls to set IngestionTime and replaced them by an explicitIngestionTimeWatermarkStrategy. I duplicated the sameIngestionTimeWatermarkStrategy in all the examples/tests because Iexplicitly didn't want to add an IngestionTimeWatermarkStrategy in oneof the core packages so that it is not discoverable because I think weshouldn't encourage users to use ingestion time.,1
"[FLINK-19317] Update docs for new stream time characteristic defaultI remove most usages where EventTime is set and remove copy that talksabout the default.In general, we should discourage using the stream time characteristic asmuch as possible.",1
"[FLINK-19319] Deprecate setStreamTimeCharacteristic() and TimeCharacteristicAfter FLINK-19317 and FLINK-19318 we don't need this setting anymore.Using (explicit) processing-time windows and processing-time timers workfine in a program that has EventTime set as a time characteristic andonce we deprecate timeWindow() there are not other operations thatchange behaviour depending on the time characteristic so there's no needto ever change from the new default of event-time. Similarly, theIngestionTime setting can be achieved in the future by providing aningestion-time WatermarkStrategy.",1
[refactor][tests] Move some source test utils from flink-connector-base to flink-coreThis makes them reusable in unit tests for simple sources that are implemented in flink-core,2
[FLINK-19457][core] Add a number sequence generating source for the FLIP-27 source API.This closes #13512,1
[FLINK-18815][filesystems][tests] Join SafetyNetCloseableRegistry's reaper thread before assertionThis closes #13375.,3
"[hotfix][DataStream API] Remove ineffective and unneeded Serializability from StreamNode.The StreamNode implements Serializable, but contains non-serializable structures.",4
[FLINK-19434][DataStream API] Add source input chaining to StreamingJobGraphGenerator (part 1),5
[FLINK-19434][DataStream API] Add source input chaining to StreamingJobGraphGenerator (part 2)This fixes issues with InputGate numbering and with Operators that have a mix of chained sourcesand network inputs.,1
"[FLINK-19434][DataStream API] Add source input chaining to StreamingJobGraphGenerator (part 3)Some cleanups in StreamingJobGraphGenerator:  - checking for chainability via ChainingStrategy  - passing chain entry points as parameters, not as fields  - fix input gate index for network unions",1
"[FLINK-19027][tests] Decrease checkpoint timeout to avoid livelocking in UnalignedCheckpointITCase.For yet unknown reason, a quick checkpoint during recovery of unaligned checkpoint causes the checkpoint to not progress. Since the checkpoint timeout is longer than the test timeout, the test timeout hit first.",3
[FLINK-19295][yarn][tests] Exclude more meaningless akka shutdown errors (#13439),0
[FLINK-19123] Move PerJobMiniClusterJobClient to top level,5
[FLINK-19123] Move PerJobMiniClusterJobClient to runtime.minicluster package,5
[FLINK-19123] Make MiniClusterJobClient shutdown behaviour configurableWe also rename it from PerJobMiniClusterJobClient toMiniClusterJobClient to reflect the change.,4
"[FLINK-19123] Don't override execute()/executeAsync() in TestStreamEnvironmentInstead, we use a custom PipelineExecutorServiceLoader to inject aMiniClusterExecutor. This requires that we directly use MiniClusterinstead of the JobExecutor interface in the test environments because weneed to use asynchronous job submission. The alternative would be toextend the JobExecutor interface to allow async job submission.We have to fix OrcFileSystemITCase to actually wait for the job thatfills the test table to finish because now the async execution methodreturns too fast.",1
"[FLINK-19123] Remove unused JobExecutor interfacesThey were introduced to allow two different MiniCluster implementationswhen the ""new"" FLIP-6 code was introduced.In the previous commit we changed the TestEnvironments to directly use aMiniCluster so these interfaces are not required anymore.",1
[FLINK-19318] Deprecate timeWindow() operations in DataStream APIThis is part of FLIP-134 (https://cwiki.apache.org/confluence/x/4i94CQ).,5
[FLINK-19318] Remove mentions of timeWindow*() from documentationIt's deprecated and we want to encourage users to use the explicitwindow assigners.,1
[hotfix][rest] Add missing enum values to API snapshot,1
[FLINK-19410][rest] API stability covers enum value changes,4
[FLINK-19422] Upgrade Kafka and schema registry versions in the avro registry e2e test,3
[FLINK-19495] add documentation for avro-confluent format (#13534),5
[FLINK-19497][metrics][dropwizard] Override mutator methods in FlinkCounterWrapper,2
"[FLINK-19027][test][network] Ensure SingleInputGateTest does not swallow exceptions during cleanup.If any cleanup method fails, the original exception was swallowed. This commit uses try-with-resources with Guava's Closer to ensure that cleanup exception only appear as surpressed exceptions in case of test failures.Note that the cleanup order needs to be reversed as Closer closes in reversed order.",4
"[FLINK-19027][test][network] Set exclusive and floating buffers in UnalignedCheckpointITCase.This commit will amend the original build instability, but future commit will still ensure that a job will not livelock with a tight memory configuration.",5
"[FLINK-19027][network] Only assign exclusive buffers to RecoveredRemoteInputChannels when recovering channel state.Currently, exclusive buffers are assigned to all RecoveredRemoteInputChannels on construction, even though the channel may not read any data at all (aligned checkpoint, start from savepoint, start without checkpoint, etc.). The upcoming fix for the livelock assigns exclusive buffers also to local input channels, such that without the lazy initialization of this commit, tight memory configurations will not work anymore even if no channel state needs to be recovered at all.With this commit, buffers are only assigned when state is actually recovered.",1
"[FLINK-19027][network] Assign exclusive buffers to LocalRecoveredInputChannel.If a local channel does not receive a buffer during recovery, a live lock may occur where the local channel cannot recover because it is waiting for a buffer but upstream operators are fully backpressured and cannot release a buffer.It's important to treat LocalRecoveredInputChannel like RemoteInputChannels and assign exclusive buffers for recovery to avoid this situation.Note that due to FLINK-13203, it still possible to run into the livelock if the sink is deployed after upstream tasks take all buffers. However, it's a) much more unlikely and b) if FLINK-13203 gets resolved, this will then automatically also fix it for recovery.",0
Revert [FLINK-19027][tests] Decrease checkpoint timeout to avoid livelocking in UnalignedCheckpointITCase.The failing test actually revealed an edge case during recovery with local channels.,3
"[hotfix] Do not cache DataOutput in StatusWatermarkValveStatusWatermarkValve was caching a DataOutput passed in a constructor. From an architecture point of view it is a bug, because it ignores the DataOutput passed in the DataInput#emitNext(DataOutput). It made and implicit assumption that these two are always equal, which might not be true.In this PR I am passing the DataOutput as a parameter of StatusWatermarkValve methods.",2
[hotfix] Alllow declaring which ordering direction should be testedSome of the comparators might sort only in one direction. Therefore we should be able to somehow declare that only the supported direction should be tested in ComparatorTestBase.,3
"[FLINK-19472] Implement a one input sorting DataInputI implement a SortingDataInput which can wrap a regular network inputand sort the incoming records before passing them on to the DataOutput.The sorting input performs the final sorting when it receives anInputStatus.END_OF_INPUT from the chained input.The sorter uses a binary comparison of serialized keys of the incomingrecords. It uses first n bytes of the serialized key as a normalizedkey.Watermarks, stream statuses, or latency markers are not propagated, only the largest seen watermark isemitted after all records.This closes #13521",1
"[FLINK-19472] Add an option to enable sorted inputs for operatorsI added an option in StreamConfig to enable sorted input forOneInputStreamOperator. If the option is set, the network input will bewrapped with a sorting one.For now the option is never set (unless manually on a StreamGraph, asin a corresponding test). A way for users to use it will be introducedlater.",1
[FLINK-19472] Regenerate config options,5
[FLINK-19307][coordination] Add ResourceTracker,1
[FLINK-19308][coordination] (Slot)State as top-level class,2
[FLINK-19308][coordination] Add default TMSlotInformation#isMatchingRequirement,5
[FLINK-19308][coordination] Add TEConnection to TMSlotInformation,5
[FLINK-19308][coordination] Add SlotTracker,1
[hotfix][runtime] Add missing '@Override' annotations in Result Partition classes,1
[refactor][tests] Remove unnecessary wrapping with ConsumableNotifyingResultPartitionWriterDecorator,4
[FLINK-19441][network] Avoid loading of ResultPartition wrapper class for consumable notifications when possible.This separates the factory method code from the wrapping class (by making the wrapping class an inner class).Not loading the wrapper class when not needed simplifies the JIT's job of optimizing method calls to theResultPartition class.,1
"[hotfix][network] Add missing '@GuardedBy' annotations.The methods invoked under lock and accessing guarded fields must be annotated as well,for the inspections/spotbugs check to work properly.",1
[FLINK-18660] Bump flink-shaded to 1.12; Bump netty to 4.1.49 (#13549),2
[FLINK-19344] Fix DispatcherResourceCleanupTest race condition (#13540),3
"[FLINK-19486] Make ""Unexpected State Handle"" Exception more helpfulWe now point out what might be the most likely cause for the exception.In addition, we remove a lot of code duplication.",4
[minor] Fix Checkstyle in StateUtil,0
[FLINK-19516] Let MiniClusterJobClient.jobResultFuture complete after MiniCluster shut downThis commit changes the MiniClusterJobClient.jobResultFuture such that it completes afterthe MiniCluster's shut down has been triggered.This closes #13557.,5
[FLINK-19496][table] DataGen source DECIMAL always returns null (#13535),5
[FLINK-18410][table-runtime-blink] correct PartitionCommitTrigger subclass nameThis closes #13522,2
"[FLINK-19498][Connector Files] Port LocatableInputSplitAssigner to new File Source APIThis keeps the behavior of the previous assigner and only fixes some code style issues andcheckstyle violations.All concurrency-related tests are dropped, because the new FileSplitAssigners are not concurrent.This closes #13538",2
[hotfix][yarn] Fix variable typo in YarnResourceManager,2
[hotfix][yarn] Replace the require function to checkNotNull in Utils,1
[FLINK-18721][yarn] Introduce TaskExecutorProcessSpecContainerResourceAdapter,2
[FLINK-18721][yarn] Add builder for TestingYarnNMClientAsync and TestingYarnAMRMClientAsync,3
[FLINK-18721][yarn] Introduce YarnResourceManagerConfiguration,5
[FLINK-18721][yarn] Introduce TestingRegisterApplicationMasterResponse,3
[FLINK-18721][yarn] Introduce YarnResourceManagerClientFactory and YarnNodeManagerClientFactory,2
[FLINK-18721][yarn] Introduce YarnResourceManagerDriver,2
[FLINK-18721][yarn] Switch yarn deployment to the new active resource manager implementationThis closes #13311.,1
[FLINK-17341][runtime] Add TaskSlotTable.getActiveTaskAllocationIdsPerJobIntroduced new method for retrieving AllocationIDs of active TaskSlots based on the JobID in a Set.This newly introduced method replaces getActiveSlots(JobID) returning an Iterator to avoid ConcurrentModificationExceptions.This closes #13564.,1
[hotfix][tests] Report FailureReason in StreamTask tests,3
[hotfix][tests] Return empty array of gates instead of null,3
[FLINK-19385] Request partitions for each inputGate independently,2
[task][refactor] Introduce InputChannel.setupThis removes casts to RemoteInputChannel and RecoveredInputChannel,4
[FLINK-18989][task] Read channel state sequentiallyNon-sequential state reader and the associated code will be removed insubsequent commits.,4
[FLINK-18989][task] Read channel state unconditionallyMotivation: reduce the required test coverage (tests will be removed ina later commit).,4
[FLINK-18989][task] Allow conversion of RecoveredInputChannel only after state was fully consumedMotivation:1. Guarantee state is not lost2. Reduce the required test coverage (tests will be removed in the nextcommit),4
"[FLINK-18989][task] Remove non-sequental ChannelStateReader and the related code- ChannelStateReader and supporting classes- methods for channel state recovery in inputChannels, subpartitions, etc.- tests for reading channel state non-sequentially",3
[FLINK-19406][table-planner-blink] Casting row time to timestamp loses nullability infoThis closes #13477,5
[FLINK-19386][hive] Use blink planner util class in HiveCatalogUseBlinkITCaseThis closes #13518,2
[FLINK-19509][json] Support MULTISET type for JSON formatThis closes #13543,5
[FLINK-19291][avro] Fix exception for AvroSchemaConverter#convertToSchema when RowType contains multiple row fieldsThis closes #13472,0
"[FLINK-19561][docs] Correct the spelling mistakes in ""Monitoring REST API"" page of ""Debugging & Monitoring"" (#13578)",0
[FLINK-19409][table-api] Improve the example in Javadoc of ListViewThis closes #13487Co-authored-by: liujiangang <liujiangang@kuaishou.com>,2
[FLINK-19555] Remove unfenced execution of Disconnected message from MesosResourceManagerThis closes #13573.,4
[FLINK-19247][docs-zh] Update Chinese documentation after removal of Kafka 0.10 and 0.11This closes #13410,4
"[FLINK-19474] Implement a state backend that holds a single key at a timeThis commit introduces a SingleKeyStateBackend. This state backend is asimplified version of a state backend that can be used in a BATCHruntime mode. It requires the input to be sorted, as it only everremembers the current key. If the key changes, the current state isdiscarded. Moreover this state backend does not support checkpointing.",1
[FLINK-19539][jmx][tests] Shutdown JMXService after tests,3
[FLINK-19539][jmx] Synchronize accesses to port,2
[hotfix][docs] Adjust playground docs to Flink 1.11 output,2
[FLINK-19453][table] Deprecate old source and sink interfacesDeprecates all old source and sink interfaces and their helper interfacesthat are not required in FLIP-95.This closes #13516.,1
[FLINK-18068] Use FatalErrorHandler to handle the error thrown from executing on main thread in YarnResourceManagerDriverThis closes #13571.,0
[FLINK-19492][core] Consolidate Source Events between Source API and Split Reader APIThis closes #13533,5
[hotfix][mesos] Remove unused argument 'executor' from MesosServices.createMesosWorkerStore.,1
[hotfix][mesos] Replace deprecated UntypedActor with UntypedAbstractActor for MesosResourceManager.AkkaAdapter.,0
"[hotfix][mesos] Remove unused methods and extract interface for MesosArtifactServer.This makes testing easier for mesos deployment, by allowing using of testing implementation rather than mocking for MesosArtifactServer.",3
[hotfix][mesos] Separate creating of mesos scheduler driver from MesosConfiguration.This helps improving the testability.,3
[hotfix][mesos] Separate actor creation from MesosResourceManager.This improves the testability.,3
[FLINK-18722][runtime] Expose granting and revoking of RM leadership to ResourceManagerDriver.This is required for Mesos Deployment. See FLINK-9936 for more details.,2
[FLINK-18722][runtime] Expose resource manager's IO executor to resource manager drivers.,2
[FLINK-18722][mesos] Introduce MesosResourceManagerDriver.,2
[FLINK-18722][mesos] Switch to the new active resource manager for Mesos deployment.This closes #13313.,1
[hotfix] Rename ParquetStreamingFileSinkITCase,2
[hotfix] Fix the generic parameter declaration of ParquetAvroStreamingFileSinkITCase,2
[FLINK-11427][formats] Add protobuf parquet support for StreamingFileSinkThis reverts commit a9436d69d39652579a162a2d5822e08d96b849ff.,4
[FLINK-19470][orc][parquet] Parquet and ORC reader reachEnd returns false after it has reached endThis closes #13515,2
[FLINK-19341][table] Update all API related methods to FLIP-107This updates all API related classes to support the concept of ametadata column. It considers all location until planner level.- Updates TableColumn to a hierarchy of 3 column types.- Updates TableSchemaUtils and all related locations that rely oncomputed column but have to deal with metadata column as well now.This closes #13480.This updates all API related classes to support the concept of ametadata column. It considers all location until planner level.,5
[minor] StreamGraphGenerator.transformSink() refactoring,4
[FLINK-19485] Add the Transformation.getInputs() methodThis method is added to unify the way current transformationsexpose their input transformations to the StreamGraphGenerator.This will serve as a building block in the following commitsin order to unify the way Transformations are translated.,1
[hotfix] Make the StreamGraphGenerator use Transformation.getInputs()This will uniformize partially most of the transform*() methodsin the StreamGraphGenerator.,1
"[FLINK-19485] Add TransformationTranslator framework and OneInputTranslatorAdds the TransformationTranslator, the framework based on which Transformationsare going to be translated into their runtime implementationsdepending on if they are to be executed in BATCH or STREAMING andan example using the OneInputTransformation.Now the user will have to write a Translator for eachTransformation and register the Translator with theStreamGraphGenerator by putting it in the `translatorMap`.Translators must:1) have a 0-arg constructor2) be statelessThe boilerplate transformation translation code is moved from theStreamGraphGenerator to the SimpleTransformationTranslator. This isgoing to be the base translator for all existing Transformationsand all future ones which have a 1-to-1 mapping between transformationand operation.",4
[hotfix] Make Transformation.getTransitivePredecessors() return a list,1
[refactor] Reuse StreamOneInputProcessor in StreamMultiProcessor,1
[refactor] Reuse StreamOneInputProcessor in StreamTwoInputProcessor,1
[refactor] Remove SourceInputProcessor from StreamMultipleInputProcessor,4
[refactor] Extract StreamMultipleInputProcessor factory method,4
[refactor] Use BoundedMultiInput instead of OperatorChain in InputProcessorsI replaced the OperatorChain in StreamOneInputProcessor and other InputProcessors with a BoundedMultiInput. Moroever I made the OperatorChain implement BoundedMultiInput interface. It makes it easier to instantiate StreamOneInputProcessor in tests without the need to instantiate a whole OperatorChain.,1
[refactor] Call nextSelection after each emitNext,4
"[FLINK-19473] Implement multi inputs sorting DataInputI implement a MultiInputSortingDataInputs which is kind of a factory formultiple, related inputs. In case of sorting inputs of Two/Multipleinput operators not only the independent inputs should be sorted, butalso records across different inputs. Therefore the produced inputsshare a common context to synchronize which input should emit recordsnext.The coordination is done via inputs Availability. Only one of theinputs, with the current smallest element, is available at a time.",1
[minor] Minor fixes in javadocs and an exception message in SortingDataInput,5
[refactor] Extract StreamTwoInputProcessor factory method,4
[FLINK-19473] Enable two input sorting in TwoInputStreamTask,0
[FLINK-19473] Enable sorting inputs in MultiInputTasksThis closes #13529,0
[hotfix][checkpoint] Adding testlogger to all checkpoint tests.,3
"[FLINK-19478][docs-zh][python] Translate page ""intro_to_table_api"" into ChineseThis closes #13537.",1
[hotfix][docs-zh] Fix the link in the chinese doc,2
[hotfix][core] Annotate ManagedMemoryUseCase as Internal.,1
"[FLINK-19180][core] Rename ManagedMemoryUseCase.ROCKSDB to STATE_BACKENDTransformations can only declare usa cases of state backends. We need to decide whether to reserve managed memory for state backends at runtime, w.r.t the state backend type.",1
[FLINK-19180][runtime] Reserve managed memory only for state backends that use managed memory.,1
[FLINK-19180][runtime] Decalare managed memory use cases for transformations with state backends.,1
[FLINK-19180][state backends] Make rocksdb state backend respect managed memory fraction.This closes #13500.,5
[FLINK-19568][yarn] Create TM container launch contexts in IO executor.This closes #13591.,1
"[FLINK-19477][docs-zh][python] Translate page ""python_table_api_connectors"" into ChineseThis closes #13528.",1
[FLINK-19414][table-runtime] Introduce ColumnarRowIterator,2
[FLINK-19414][connector-file] Introduce forEachRemaining util for BulkFormat.Reader,5
[FLINK-19414][file connector] Extract FileSourceTextLinesITCase to AbstractFileSourceITCase,2
[FLINK-19414][parquet] Introduce ParquetColumnarRowInputFormat,2
[FLINK-19590] Fix the compile issue of flink-streaming-java module,2
[FLINK-19336][table] EncodingUtils#encodeObjectToString should propagate inner exceptionThis closes #13600,2
[FLINK-18850][table-runtime-blink] Add late records dropped metric for row time over windowsThis closes #13519,4
[FLINK-16753][checkpointing] Use CheckpointException to wrap exceptions thrown from AsyncCheckpointRunnableThis closes #11509.,1
[hotfix][kafka] Add serialVersionUID for FlinkKafkaConsumerThis closes #13597,2
"[FLINK-19522][jdbc] Add ""scan.auto-commit"" option for JDBC SQL connectorThis closes #13570",5
[FLINK-17857][e2e] Fix Kubernetes e2e tests on Mac OSThis closes #12451,3
"[FLINK-19448][connector base] Explicitly check for un-expected condition that would leave an inconsistent stateThis condition should never happen, but if it ever happened, it would leave the source in an idle state waiting formore input data, rather than shutting down.",5
[tmpfix] Set CI log level to TRACE for 'org.apache.flink.connector.base.source.reader' to debug FLINK-19448,2
"[FLINK-19427][FLINK-19489][tests] Fix test conditions for 'SplitFetcherTest.testNotifiesWhenGoingIdleConcurrent()'The changed logic also fixes flaky thread shutdown logic as a side effect, because it no longer relieson thread interrupting.This closes #13593",1
[FLINK-19511] Rename the 'SinkTransformation' to 'LegacySinkTransformation'We use the 'SinkTransformation' to represent the new sink API after the FLIP-143.So this commit renames the 'SinkTransformation' to 'LegacySinkTransformation'.,1
[FLINK-19231][python] Support ListState and ListView for Python UDAFThis closes #13507.,1
[FLINK-19309][coordination] Add TaskExecutorManager,1
[FLINK-19484][python][tests] Set longer timeout for jobmanager pod availability in PyFlink kubernetes application test (#13607),3
[FLINK-19570][tests] Remove preferred location tests from ExecutionTestThese tests relies on the problematic TestingExecutionVertex and blocks us from getting rid of it.We can safely remove these tests because they only test the behavior of legacy scheduler which will be removed soon.,4
[FLINK-19570][tests] Avoid directly creating ExecutionJobVertex and ExecutionVertex via constructors in testsThis is to avoid re-registering duplicated ExecutionAttemptID and causing global failure.Testing constructors of  ExecutionJobVertex and ExecutionVertex are removed.Subclasses of ExecutionVertex are also removed and related tests are reworked.,1
[FLINK-19512] Introduce the new sink APIThis is the new Transactional Sink API described in FLIP-143.This closes #13576.,1
[FLINK-17458] Stop TaskSubmissionTestEnvironment.testingRpcService when closing the environmentThis closes #13569.,3
[FLINK-19315][coordination] Add AllocatedSlotPool,1
[hotfix][test] Deduplicate TaskStateStatsTest code,3
[hotfix][task] Rename SubtaskCheckpointCoordinator#executorService to asyncOperationsThreadPool,0
[hotfix][task] Log when AsyncCheckpointRunnalbe starts executing (with the execution delay),1
[hotfix][test] Remove unnecessary abstraction in CheckpointBarrierAlignerTestBase,3
[hotfix][test] Simplify CheckpointBarrierAlignerTest,3
[hotfix][test] Deduplicate code of ValidatingCheckpointHandler,5
[hotfix][test] Fix method naming in CheckpointBarrierTrackerTest,3
"[FLINK-18662][task] Introduce CheckpointMetricsBuilderThis will later allow to solve in a hopefully elegant way the issue, thatsome checkpoint metrics are calculated after AsyncCheckpointRunnable's construction.CheckpointMetricsBuilder will be able to collect those additional metrics via CompletableFuture'swhile CheckpointMetrics class will remain a serializable class used in the RPC.",1
"[FLINK-18662][task] Calculate alignmentDurationNanos for unaligned checkpoints and CheckpointBarrierTrackerThis is modifing the alignmentDurationNanos metric for the CheckpointBarrierTracker. Previously it wasalways 0, now it's defined as the duration between processing first and the last checkpoint barrier.",2
[FLINK-19487][task] Fix calculation of checkpoinStartDelay for single channel CheckpointBarrierAlignerPreviously for one single channel this metric was always zero,0
[FLINK-18662][task] Add persisted bytes to CheckpointMetrics,1
[hotfix][test] Use ValidatingCheckpointHandler in AlternatingCheckpointBarrierHandlerTest,3
[FLINK-18662][task] Calculate processed bytes during alignment metric,2
[FLINK-18662][metrics] Expose persisted and processed bytes metrics to the REST and Web UI,2
[FLINK-18662][docs][metrics] Update the metrics documentation to reflect current state.,2
"[hotfix][task] Throw MailboxClosedException if TaskMailbox is closing instead of IllegalStateExceptionThis will allow to handle this particular exception, instead of catching IllegalStateException",0
[hotfix][test] Do not hide original exception in ShuffleCompressionITCase,3
[hotfix][task][network] Do not swallow exceptions from actions chained to the availability futures,1
"[FLINK-19414][file connector] Revert ""Extract FileSourceTextLinesITCase to AbstractFileSourceITCase"" (#13610)We should not have a test-jar for the flink-connector-files project, because the module it is not scala-versioned. Thus we cannot release an artifact with a dependency on a specific scala version (like the test jar).We need to have the connector test utils in a different project, or add a scala version to the module.",1
[FLINK-19416][python] Support Python datetime object in from_collection of Python DataStreamThis closes #13572.,5
[FLINK-19584][hbase] Not start flush thread when bufferFlushMaxMutations = 1This closes #13613,2
[FLINK-18999][table-common][table-planner-blink] Add isTemporary flag to table factory context,1
[FLINK-18999][hive] Temporary generic table doesn't work with HiveCatalog,2
[FLINK-19523][conf] Hide sensitive command-line configurations,5
[FLINK-19619][e2e] Temporarily disable the pubsub test,3
[FLINK-16620] - Add attempt information in TaskInfo,5
[FLINK-19404][python] Support Pandas UDAF in OverWindow of streaming modeThis closes #13504.,1
[FLINK-19475] Implement a time service for the batch execution modeI introduce a BatchExecutionInternalTimeServiceManager andBatchExecutionInternalTimeService which can be used in the batchexecution mode along with the BatchExecutionStateBackend. These servicesonly ever keep state for a single key at a time. They assume a perfectWatermark and fire timers only upon switching the current key. Thereforethey require the input to be sorted/grouped by the key.,1
[FLINK-18373][state backends][tests] Drop useless RocksDB performance unit testsThis closes #12784.,3
[FLINK-17073] [checkpointing] Introduce CheckpointsCleaner responsible for asynchronous checkpoints cleaning via the ioExecutor. This class counts the number of checkpoints to clean and reports it to CheckpointRequestDecider. Add a test for too many checkpoints to clean.,4
[FLINK-17073][checkpointing][refactor] Remove callbacks from Checkpoint classesPass CheckpointsCleaner and postCleanup as argumentsinstead of storing them in Checkpoints classes as callbacks.,4
[hotfix][checkpointing][refactor] Remove PendingCheckpoint.executorPass Executor as an argument instead of storing it as a field.,4
[FLINK-17073][checkpointing][refactor] Remove callback in ZK checkpoint store,4
[FLINK-17073][checkpointing][refactor] Remove callback from CheckpointsCleanerReplace cleanup Runnable with a direct call to CheckpointsCleaner.,4
[hotfix] Drop unnecessary PowerMockRunner from RMQSourceTest,3
[FLINK-17502] [flink-connector-rabbitmq] RMQSource custom deserialization schemaThis closes #12056Co-authored-by: Dawid Wysakowicz <dwysakowicz@apache.org>,2
[FLINK-19480][python] Support RichFunction in Python DataStream APIThis closes #13611.,5
[FLINK-18921][python][docs] Add a SQL link in PyFlink Table API documentationThis closes #13262.,2
[FLINK-19631][table-common] Fix JavaDoc in Decoding/EncodingFormatFactoryThis closes #13633.,2
"[FLINK-19420][docs-zh] Translate ""Program Packaging"" page into ChineseThis closes #13505",1
[hotfix][docs-zh] Fix some typos in SQL documentationsThis closes #13638,2
[FLINK-19637][coordination][tests] Remove AllocationIdsExposingRMGateway,4
[FLINK-19616][tests][parquet] avoid re-generate the protobuf files due to time inconsistency,2
"[FLINK-19572] Add the TwoInputTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the TwoInputTransformation.",2
"[FLINK-19573] Add the MultipleInputTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic out ofthe StreamGraphGenerator and put it into dedicated translators.This commit does so for the MultiInputTransformation.This closes #13635",2
[FLINK-19531] Add runtime writer operators for new Sink APIThis patch introduces two types of writer operators:1. The `StatelessWriterOperator` is for the case where the writer state serializer is not provided.2. The `StatefulWriterOperator` is for the case where the writer state serializer is provided.The `AbstractWriterOperator` is the base class of the two operators.,1
[FLINK-19531] Add more specific Sink API WriterOperator testsThese tests replace the previous monolithic tests by more fine-grainedtests for individual behaviours.,3
[FLINK-19618][docs] Fix broken links in docsThis closes #13632.,2
[hotfix] Disable potentially hanging e2e tests,3
[FLINK-19518] Show proper job duration for running jobs in web ui (#13560),1
[hotfix] Disable KryoSerializerConcurrencyCheckInactiveITCase if logging level is DEBUG,0
[FLINK-19237] Fix rejected slot offer bug in JobMasterThe JobMaster was rejecting slot offers from TaskExecutors erroneously in cases where the TaskExecutor ID is reused.This fixes the JobMaster.suspend() behavior to do proper bookkeeping of TaskExecutors.,0
[FLINK-19654][python][e2e] Merge PyFlink Table and DataStream e2e tests to avoid setting up the environment multiple times (#13652),1
[FLINK-19671] Raze .editorconfig by resetting to IntelliJ defaultThis creates an .editorconfig that has all the additional configurationoptions that IntelliJ provides but leaves them at the default. I'm doingthis so that the next commit can change those defaults and we canthus track where we diverge from the defaults.,4
[FLINK-19671] Update .editorconfig to conform to checkstyle and import orderingThis puts in place an opinionated code style that matches ourcheckstyle/import ordering requirements.,1
[hotfix][coordination] Remove unused SlotManager#unregisterTaskManagersAndReleaseResources,1
[FLINK-19306][coordination] Add DeclarativeSlotManager,1
[FLINK-19306][coordination] ResourceManager supports declarative resource management,1
"[FLINK-19658][e2e] Fix failing Local recovery and sticky scheduling testFLINK-16620 introduced a new naming scheme for tasks, whilst this e2e test was relying on the taskname to be constant across different attempts.",3
[hotfix][e2e] Let Local recovery and sticky scheduling timeout with logs,2
[FLINK-19459] Add snakeyaml to dependencyManagement,1
[FLINK-19324][yarn] Introduce TaskExecutorProcessSpecContainerResourcePriorityAdapter.,2
[FLINK-19324][yarn] Match requested and allocated containers with priority rather than resources.This closes #13592.,2
"[hotfix] Fixes in CEP operatorThe commit fixes two issues in the CEP operator:1. It tries to migrate the old state only in case when the state wasrestored. The problem here was that it uses applyToAllKeys for restorewhich might not be available e.g. in the BATCH runtime mode.2. It does not cache the last seen watermark any longer, but depends onthe result of TimerService#currentWatermark",1
[FLINK-19640] Enable sorting inputs for batchThis PR adds feature flags for enabling/disabling the sorting inputs andspecial types of a state backend and a timer service for BATCH executionruntime. Those options are enabled by default for BATCH runtimeexecution mode.,1
"[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph.There is currently no way to start from savepoints while using MiniCluster. The cluster config cannot be used (and would be a mismatch) because it's overridden by MiniClusterPipelineExecutorServiceLoader#createConfiguration.However, the jobgraph that is being generated in MiniClusterPipelineExecutorServiceLoader#MiniClusterExecutor only uses this configuration to translate the Pipeline/StreamGraph. In production code, savepoint restore settings are usually applied last and taken from the StreamGraph.",1
[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.,1
[FLINK-19072][FLINK-19073][FLINK-19076][table-planner] Import Temporal Table join rule for Stream (#13299)* [FLINK-19072][table-planner] Import Temporal Table join rule for stream* [FLINK-19073][table-planner] Imporve streamExecTemporalJoinRule for stream* [FLINK-19076][table-planner] Import rule to deal Temporal Join condition for stream,2
"[FLINK-18915][fs][orc] Set unique path to each new OrcBulkWriterSo far the path of the OrcBulkWriter was fixed because it isnot used to indicate the destination file, but we have used adedicated physical writer to write to the give output streamdirectly. However, this path is used internally as the key ofwriter in the ORC memory manager, thus we need to make it unique.This closes #13598",1
"[FLINK-19583] Expose the execution.runtime-mode to usersAs part of FLIP-134, this PR exposes the 'execution.runtime-mode'to the users. This options allows users to specify, among otherthings, the task scheduling, network shuffle behavior, and thetime semantics.This closes #13656",1
[FLINK-19469][hbase] Exclude org.glassfish:javax.el transitive dependency from hbase-2.2 connector as it is unreliable (#13622),2
[hotfix][checkstyle] Add Javadoc for DummyInputFormat (#13643),2
[FLINK-19669][coordination] PipelinedRegionSchedulingStrategy#init ResultPartitionType blocking check use isBlocking method,1
[FLINK-19654][python][e2e] Update the dependency from scipy to pytest to reduce the execution time (#13659),3
[FLINK-19181][python] Make python processes respect the calculated managed memory fractionThis closes #13492.,1
[FLINK-19689][yarn][test] Fix TaskExecutorProcessSpecContainerResourcePriorityAdapterTest failure for Hadoop 2.10+.This closes #13673.,0
[FLINK-19625][table-planner] Introduce multi-input exec node (#13671),2
"[FLINK-18937][python][docs] Add an ""Environment Setup"" section to the Installation documentation (#13170)",2
[hotfix][python][tests] Set the parallelism of Python DataStream API tests to 2,3
[FLINK-19450][python][tests] Optimize the Python CI Test to reduce execution timeThis closes #13520.,3
[hotfix][runtime] Added missing test MetricUtilsTest.testNonHeapMetricUsageNotStatic and renamed testHeapMetric to make it more descriptive.,1
[FLINK-19617][runtime] Introduced new metric for monitoring the JVM Metaspace.,1
[FLINK-13553] Disable TRACE console logging for queryable state,2
[FLINK-13553] Ignore KvStateServerHandlerTest because it is unstable,1
[FLINK-19619][e2e] Pin CloudSDK version to have access to pubsub emulator in testThe :latest version of google/cloud-sdk:latest has the pubsub emulator disabled.Google plans to add it again at a later point. See https://github.com/GoogleCloudPlatform/cloud-sdk-docker/issues/225 for details.,2
[FLINK-19672][connector-kafka] Update Kafka table sources and sinksThis closes #13681.,5
[hotfix][connector-kafka] Deprecate old Kafka table sources and sinks,0
[FLINK-19623][table-planner] Introduce ExecEdge to describe information on input edges for ExecNode (#13625)* [FLINK-19623][table-planner] Introduce ExecEdge to describe information on input edges for ExecNode,5
[FLINK-19643][python][docs] Add Pandas UDAF documentationThis closes #13663.,2
[FLINK-18836][python] Support Python UDTF return types which are not generatorThis closes #13608.,1
[FLINK-19649][sql-parser] Fix unparse method of sql create table without columns (#13651),1
[hotfix][yarn] Remove unused function in YarnResourceManagerDriverThis closes #13683.,1
[FLINK-19716][Kinesis][EFO] Unable to use Assume Role with EFO record publisherThis closes #13689.,1
[FLINK-19368][hive] TableEnvHiveConnectorITCase fails with Hive-3.xThis closes #13624,0
"[FLINK-19574] Add SourceTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the SourceTransformation.",2
"[FLINK-19576] Add LegacySinkTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the LegacySinkTransformation.",2
"[FLINK-19575] Add LegacySourceTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the LegacySourceTransformation.",2
"[FLINK-19577] Add the UnionTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the UnionTransformation.",2
"[FLINK-19578] Add PartitionTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the PartitionTransformation.",2
"[FLINK-19579] Add the SideOutputTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the SideOutputTransformation.This closes #13649",2
"[FLINK-16579][table] Upgrade Calcite version to 1.26 for Flink SQL (#13577)* Update Calcite version of pom and NOTICE fileAs a dependency, the Guava version upgrade to 29.0-jre, janino version upgrade to 3.0.11* Upgrade SQL parser Calcite version to 1.26.0* Fix the API change for plannerSqlParser, SqlValidator and SqlToRelConverter now have a Config bean for configurationSince CALCITE-2082, all the UDF needs a SqlOperandMetadata for operand type inference (before the change, it is SqlOperandTypeChecker)Since CALCITE-4215, Statistic default collations change from empty list to null* Replace the rule instance with new one since CALCITE-3923The core rules are changed to support new way of parameterization, and moved to CoreRules.* Since CALCITE-3877, the default over window bounds does not print out in the plan digest* Since CALCITE-3877, the default over window bounds does not print out in the plan digest* Since CALCITE-4220, the aggregate is promoted automatically after sql to rel conversion* The NDV algorithm has been tweaked since CALCITE-4132* All kinds of left plan changesThe predicate normalization now only happens during planning, that means it does not change in the digest anymoreThe HOP and SESSION window names changes to $HOP and $SESSION, both are deprecatedIS NOT DISTINCT FROM is expanded in the plan nowMany sort aggregate changes to hash aggregate which are more efficient",4
[FLINK-19695][table-runtime-blink] Fix ClassCastException when writing table with rowtime attributeThis closes #13679,0
[FLINK-19664][e2e] Upload logs before tests time outThis closes #13655,3
[FLINK-19707][table-runtime] Refactor table streaming file sinkThis closes #13684,2
"[FLINK-19728] Revert ""[FLINK-19689][yarn][test] Fix TaskExecutorProcessSpecContainerResourcePriorityAdapterTest failure for Hadoop 2.10+.""This reverts commit f734f59488afaa7ad984362a0dd62e99c134f062.",4
[FLINK-19728][yarn][test] Disable external resource related tests in TaskExecutorProcessSpecContainerResourcePriorityAdapterTest.This closes #13700.,3
"[FLINK-19458] Fix ZK-related CI instabilitiesWe used to have an increased session and connection timeout configured for TravisCI.On Azure, the environment variable we used for checking if we are in an CI environment doesn't exist anymore.This change enables the increased timeout on Azure as well.",1
"[hotfix][task] Drop CheckpointBarrierHandler#isBlocked methodThis method is only used to provide a checkState, that's not necessary while it will complicaterefactoring in the next step.",4
"[hotfix][test] Fix measuring alignmentDurationNanosMaxPreviously the expected alignmentDurationNanosMax was calculated before checkingthe actual alignmentDurationNanos. This meant that during a pending checkpointthe time for alignmentDurationNanos was still ticking, and the actual valuecould exceed the incorrectly calucated expected alignmentDurationNanosMax.",0
[FLINK-19679][task] Replace CheckpointBarrierUnaligner with more generic SingleCheckpointBarrierHandlerUnalignedController provides unaligned checkpoints functionalities.,1
[FLINK-19679][task] Migrate CheckpointBarrierAligner to the generic SingleCheckpointBarrierHandlerAlignedController replaces the custom logic of CheckpointBarrierAligner,2
[hotfix][test] Remove unused code in AlternatingCheckpointBarrierHandlerTest,3
[FLINK-19679][task] Migrate AlternatingCheckpointBarrierHandler to the generic SingleCheckpointBarrierHandler,0
"[FLINK-19732] Disable checkpointing in BATCH modeWhen a pipeline is executed in BATCH mode, its tasksare scheduled in independent regions and not all tasksare present throughout the execution. In this casescheckpointing should be disabled.This closes #13698",2
[hotfix] Add FlinkMatchers.willNotComplete to assert that a future times out,3
[hotfix] Let DispatcherResourceManagerComponent accept AutoCloseableAsync instead of WebMonitorEndpointThis commit improves the testability of DispatcherResourceManagerComponent by allowing to passin a AutoCloseableAsync implementation.,4
"[hotfix] Introduce ResourceManagerService to make DispatcherResourceManagerComponent easier to testBy passing an interface instead of ResourceManager, it is easier to test the DispatcherResourceManagerComponent.",3
[hotfix] Correct TestingDispatcherGatewayService closeAsync behaviorLet TestingDispatcherGatewayService complete the termination future when calling closeAsync.,3
"[FLINK-19022][rpc] Log if RpcEndpoint failed its terminationIn order to not swallow the failure reason of failed RpcEndpoints, we are nowlogging the cause of a RpcEndpoint failure.",0
"[FLINK-19022] Let TaskExecutor, Dispatcher, RM fail fatally if onStart throws a ThrowableIf TaskExecutor., Dispatcher. or ResourceManager.onStart throws a Throwable, the system isno longer in a valid state. Hence, this commit ensures that the components will properlycall FatalErrorHandler.onFatalError in such a case.",0
[FLINK-19022] Fail fatally if DispatcherGatewayService terminates unexpectedly in AbstractDispatcherLeaderProcessThis commit ensures that we fail fatally if the DispatcherGatewayService termiantes unexpectedly in theAbstractDispatcherLeaderProcess. This ensures that the system won't stay in an invalid state.,5
"[FLINK-19022] Fail DispatcherResourceManagerComponent fatally if ResourceManager terminates unexpectedlyAn unexpected termination of the ResourceManager indicates an invalid state. Hence, theDispatcherResourceManagerComponent should react to it by calling the FatalErrorHandler.",0
"[FLINK-19022] Fail TaskManagerRunner fatally if TaskExecutor terminates unexpectedlyAn unexpected termination of the TaskExecutor indicates that the system has reached aninvalid state. Therefore, the runner will fail fatally if this happens.This closes #13319.",0
[FLINK-19605][table-runtime-blink] Implement cumulative windowing for window aggregate operatorThis closes #13650,1
[FLINK-19483][python][e2e] Update PyFlink end-to-end tests to remove the unnecessary installation of zip (#13702),4
[task][hotfix] Remove PipelinedSubpartition.addBufferConsumer method,5
[FLINK-19699][e2e] Upload coredumps and jvm crash debugging information as well for e2e tests,3
[hotfix][tests] Improve condition readability,1
[FLINK-19232][python] Support MapState and MapView for Python UDAFThis closes #13665.,1
[FLINK-19718][hive] HiveTableSourceITCase.testStreamPartitionRead is not stable on AzureThis closes #13714,3
[FLINK-19747][orc] Move Predicate classes to OrcFiltersThis closes #13715,4
[FLINK-18415][python] Support TableResult#collect in the Python Table API to align with the Java Table APIThis closes #12902.,1
[FLINK-19689][yarn][test] Fix TaskExecutorProcessSpecContainerResourcePriorityAdapterTest.This closes #13719.,3
[FLINK-19395][table] Replace SqlConversionException with either TableException or ValidationExceptionThis closes #13481.,5
"[tests][checkpointing] Test retrieval error fails ZKStore.recoverThe added test, coupled with the next change (download checkpointsonly if necessary) allows to drop ZK-HA-ITCase. Otherwise,ZK-HA-ITCase would fail false-positively.",0
"[FLINK-19401][checkpointing] Download checkpoints only if neededIf checkpoints in ZK are the same as already downloaded then skipdownload. This prevents excessive S3 reads and eventually failure tostart the job, particularly in multi-region recovery.ZooKeeperHighAvailabilityITCase is dropped is it now failsfalse-positively.  Instead, unit testRetrievalFailsRecoverywas added in the previous commit.",1
[FLINK-19737][table] Introduce TableOperatorWrapperGenerator to translate transformation DAG in a multiple-input node to TableOperatorWrapper DAG (#13707),2
[FLINK-19624][table-planner-blink] Update deadlock break-up algorithm to cover more cases (#13692),4
[FLINK-19469][hbase] Exclude org.glassfish:javax.el transitive dependency from hbase-2.2 connector as it is unreliableThis closes #13720.,2
[hotfix][cep][docs] Fix the documentation of cep sqlThis closes #13687.,2
[FLINK-19629][avro] Fix NullPointException when deserializing map field with null valueThis closes #13634,0
[FLINK-19655][table-runtime-blink]  Fix NPE when using TemporalTableFunction after setting IdleStateRetentionTimeThis closes #13675,1
[FLINK-19734][table-planner-blink] Replace 'collection' connector by 'values' connector for temporal join plan testsThis closes #13708,3
[FLINK-19733][python] Refactor fast_operation and slow_operation to make the produce functions consistentThis closes #13713.,1
[hotfix][mesos] Fix checkstyle in Krb5ConfOverlay,5
[FLINK-18971][security] Introduce security.kerberos.krb5-conf.path option,5
[FLINK-18971][kubernetes] Support to mount kerberos conf as ConfigMap and Keytab as Secrete in Kubernetes,5
[FLINK-18971][mesos] Support security.kerberos.krb5-conf.path option in Mesos,5
[FLINK-18971][yarn] Support security.kerberos.krb5-conf.path option in YarnThis closes #13255.,5
[hotfix] Fix DeadlockBreakupTest due to Calcite upgrade (#13737),3
[hotfix][runtime][docs] Fixed JavaDoc.,2
[hotfix][runtime] Refactoring: Created generic TestingMetricRegistry that can be used in multiple tests.,3
[FLINK-14406][runtime] Introduced new TaskManager metrics Status.Flink.Memory.Managed.[Used|Total] for monitoring the managed memory.This required the following changes:- extending TaskSlotTable and its implementations to return AllocationIDs of all active TaskSlots- introducing new metrics for managed memory (used and total; available was skipped to avoid calling the same logic twice just to calculate the inverse of used memory)- extended documentation accordingly- added testcases to coverThis closes #13547.,3
[hotfix][runtime] Added missing test checking the proper implementation of UnsafeMemoryBudget.getAvailableMemorySize().,1
[hotfix][runtime] Removed test as it is kind of flaky but was just recently introduced in 296107e by me. A ticket will be created to address this issue again.,0
[hotfix][runtime] Fixed method name as it does not return the Task's AllocationIDs but the TaskSlot's.,0
[FlINK-19688][network] Don't cache InterruptedExceptions in PartitionRequestClientFactory,2
[FLINK-19657][yarn][tests] Whitelist common error in logs,2
[FLINK-17528][table] Remove RowData#get() API and use FieldGetter insteadThis closes #13653,1
[FLINK-17528][table] Remove ArrayData#get() API and use ElementGetter insteadThis closes #13653,1
[FLINK-19767] Add AbstractSlotPoolFactory,1
[FLINK-19274][table-common] Introduce TableSchema.toPersistedRowDataType,5
[hotfix][table-common] Provide a consumed data type for SupportsWritingMetadata,5
[hotfix][table-planner-blink] Port sink validation to Java,5
[FLINK-19274][table] Update sink validation for metadata columns and improve messages,1
[hotfix][table-planner-blink] Port source validation to Java,5
[FLINK-19274][table] Update source validation for metadata columns and improve messages,1
[hotfix][table-planner-blink] Simplify SQL expression to RexNode conversion,2
[FLINK-19274][table] Implement SupportsReadingMetadata and SupportsWritingMetadata for sources and sinksThis closes #13618.,5
"[FLINK-19660][docs-zh][python] Translate page ""table_environment.zh.md"" into ChineseThis closes #13672.",1
"[FLINK-19675][python] Fix PythonCalcExpandProjectRule to handle cases when the calc node contains WHERE clause, composite fields access and Python UDF at the same time (#13746)",1
[FLINK-19706][table-runtime] Add WARN logs when hive table partition has existed before commitThis closes #13716,2
[hotfix][table-common] Avoid unnecessary casting when creating type information in sources and sinksThis it is not a compatible change. But given that those interfaces are still relatively new andnot many people have changed to the new sources/sinks. We should do this change now or neverand avoid @SuppressWarning in almost all implementations.,2
[hotfix][connector-kafka] Merge KafkaITCase and KafkaTableTestBase,3
[hotfix][table-common] Add a new Row.deepEquals for all conversion classes,1
[FLINK-19275][connector-kafka] Support reading and writing Kafka metadataThis updates the `KafkaDynamicSource` and `KafkaDynamicSink` to read andwrite metadata according to FLIP-107. Reading and writing metadata of formatsis not supported yet.This closes #13732.,1
[FLINK-19720][table-api] Introduce new Providers and parallelism APIThis closes #13694,1
[hotfix] Close TestingServer in ZooKeeperLeaderElectionConnectionHandlingTest,3
"[FLINK-19557] Trigger LeaderRetrievalListener notification upon ZooKeeper reconnection in ZooKeeperLeaderRetrievalServiceWe have to trigger the LeaderRetrievalListener notification upon reconnecting to ZooKeeperbecause the NodeCache might not trigger the nodeChanged call if the server state is thesame as the state cached in the NodeCache. Therefore, we would miss to tell the listenerthat the old leader (before the connection loss) is still the valid leader.This closes #13725.",4
[FLINK-18117][e2e] Add debugging information for hadoop startup (#13757),5
[FLINK-19640] Add an IT case for bounded executionThis closes #13666.,1
[FLINK-19721][runtime] Support exponential backoff retries in RpcGatewayRetrieverThis is to speed up tests that spend unnecessary time sleeping.https://issues.apache.org/jira/projects/FLINK/issues/FLINK-19721?filter=reportedbymeSwitch RetryStrategy from Time to Duration,1
[FLINK-19721] Let RpcGatewayRetrievers in DispatcherResourceManagerComponent use ExponentialBackoffRetryStrategyThis closes #13711.,1
[FLINK-19726][table-planner] Implement DataStream and Source ProvidersThis closes #13696,1
[FLINK-19677][runtime] Make JobManager lazily resolve hostname of TaskManager and provide an option to turn off reverse resolution entirely[FLINK-19677][runtime][tests] Added test casesMore test case and formattingMinor changes after reviewRe-generated docsImprovements after reviewRemove spacesThis closes #13706.,4
[hotfix] Fix checkstyle violations in TaskManagerLocation,0
[FLINK-19586] Extract 'TestSink' from 'WriterOperatorTestBase'This patch extracts 'TestSink' from 'WriterOperatorTestBase' and all the sink related tests should reuse it.,1
[FLINK-19586] Add committer operators for STREAMING mode for new Sink API,1
[FLINK-19586] Add global committer operator for STREAMING mode for new Sink APIThis closes #13678.,1
[FLINK-19696] Add committer operator for BATCH mode for the new sink APIThis patch introduce two operators:1. BatchCommitterOperator is the runtime operator for executing the sinks Committer in the batch execution mode.2. BatchGlobalCommitterOperator is the runtime operator for executing the sinks GlobalCommitter in the batch execution modeThis closes #13703.,1
[FLINK-19769][streaming] Reuse StreamRecord when emitting records from source outputsThis closes #13748,1
[FLINK-19750][connector/kafka] Fix bug of not opening DeserializationSchema when FlinkKafkaConsumerBase recovers from state (#13785),2
[FLINK-19068][k8s] Improve log readability against duplicated pod termination events.This closes #13765.,2
[tests][network][refactor] Extract NettyServerAndClient.getConnectionID,1
[FLINK-19791][network][test] Connect to an opened port instead of 8080,3
[refactor][tests][network] Cleanup PartitionRequestClientFactoryTest,3
[FLINK-19676][docs] java package name error in docs.,2
[FLINK-19781] Upgrade commons-codec to 1.13,2
[hotfix][docs] Remove unused variable,1
"[FLINK-19154] ApplicationDispatcherBootstrap cleans up HA data only on FAILED, CANCELLED, SUCCEEDEDDepending on the status with which a job got terminated, we maywant to shutdown the cluster and clean up all HA data, or not. Tobe able to differentiate between the different termination reasonswe add the ApplicationFailureException.In addition, to be able to shutdown the cluster without cleaning upthe HA data, we need to be able to terminate the dispatcher's shutdown futurewith an exception. This is what the new error handler pass in theApplicationDispatcherBootstrap does. We chose to pass the FatalErrorHandleras a constructor argument because this allows for more robust code.This closes #13699",1
"[FLINK-19154] Pass DispatcherGateway to DispatcherBootstrapIn order to make sure that all calls from theApplicationDispatcherBootstrap are executed from the mainthread, we are passing the DispatcherGatewayto the Bootstrap and not the Dispatcher itself.This closes #13699",4
[FLINK-19154] Merge ApplicationDispatcherBootstrap#initialize() with constructor.,5
[hotfix] minor refactoring in ApplicationDispatcherBootstrap,4
[hotfix] Remove unused imports,2
[FLINK-19326][cep] Allow explicitly configuring time behaviour on CEP PatternStream,5
[minor] Add Javadocs to CEP PatternStream,2
[FLINK-19783] Upgrade Mesos version to 1.7 (#13783),2
[FLINK-19278] Bump Scala Macros to 2.1.1,2
[FLINK-19785] Upgrade to commons-io 2.7This closes #13782,2
[FLINK-19782][python] Remove antlr traces in flink-pythonThis closes #13780,2
[FLINK-16595][YARN] Support multiple HDFS NameNodes with KerberosThis closes #13690,1
[FLINK-19755][cep][docs] Fix CEP documentation error of the example in 'After Match Strategy' sectionThis closes #13754.,0
[FLINK-19780][table-planner-blink] Introduce FlinkRelMdUtil#numDistinctVals to work around precision problem in Calcite's implementation (#13764),0
[FLINK-19777][table-runtime-blink] Fix NullPointException for WindowOperator.close()This closes #13768,1
[FLINK-19553][web] Make timestamp of checkpoints shown with date format,5
[FLINK-19765][table] Reorder condition blocks in SqlToOperationConverter#convertThis closes #13753,2
[FLINK-19232][python] Support iterating MapState and MapViewThis closes #13739.,1
[FLINK-19654][python][e2e] Set the parallelism of PyFlink e2e tests to 2 to reduce the execution timeThis closes #13736.,3
[hotfix][runtime] Fix typo in MiniClusterThis closes #13584.,5
[FLINK-19787][table-runtime] Migrate Filesystem connector to new table source sink interfaceThis closes #13767,1
[FLINK-19594][web]Make subtask index start from zero,2
[hotfix][k8s] Wrap podsWatch as Optional in KubernetesResourceManagerDriver.,0
[FLINK-19700][k8s] Make Kubernetes Client in KubernetesResourceManagerDriver use io executorThis closes #13755.,1
[FLINK-19412][python] Refactor Python operation to eliminate code duplicationThis closes #13759.,4
"[FLINK-19547][Runtime] Add the partialRecordLength when creating a BufferConsumerPartial records happen if a record can not fit into one buffer, then the remaining part of the same recordis put into the next buffer. Hence partial records only exist at the beginning of a buffer.Partial record clean-up is needed in the mode of approximate local recovery.If a record is spanning over multiple buffers, and the first (several) buffers have got lost due to the failureof the receiver task, the remaining data belonging to the same record in transition should be cleaned up.`partialRecordLength` is the length of bytes to skip in order to start with a complete record,from position index 0 of the underlying MemorySegment. `partialRecordLength` is used in approximatelocal recovery to find the start position of a complete record on a BufferConsumer, so-called`partial record clean-up`.This commit includes1). API change to add `partialRecordLength` when creating a BufferConsumer2). Add `partialRecordLength` in `BufferWritingResultPartition` when emitRecord and `broadcastRecord`",1
[FLINK-19547][Runtime] Update `BufferConsumer` with `BufferConsumerWithPartialRecordLength` in PipelinedSubpartition.javaBufferConsumerWithPartialRecordLength includes BufferConsumer as well as partialRecordLengthThis commit includes two changes1. Update BufferConsumer with BufferConsumerWithPartialRecordLength in PipelinedSubpartition2. Implement partial record cleanup logic in BufferConsumer,2
[hotfix][runtime] Rename XXXSubPartitionBufferBuilderXXX to XXXUnicastBufferBuilderXXX,0
[FLINK-19479][DataStream] Allow explicitly configuring time behaviour on KeyedStream.intervalJoin(),5
[FLINK-19479] Add Javadocs to IntervalJoin.in(Processing|Event)Time,2
[minor] Fix warnings in KeyedStream,2
[hotfix] Log interrupted exception on debug when closing threads in ExternalSorter,0
[FLINK-18676] [FileSystem] Bump s3 aws version to handle WebIdentityTokenCredentialsProviderThis closes #13758,1
[FLINK-18676] [FileSystem] Adjust NOTICE files,2
[hotfix] Fix dependency version in Kinesis NOTICE file,2
[hotfix][tests] Let SlotSharingExecutionSlotAllocatorTest extend TestLogger,3
[hotifx][runtime] Print root cause of logical slot allocation failures,0
[hotfix] Remove unused OneSlotPerExecutionSlotAllocator,1
[FLINK_19552][coordination] Create PreferredLocationsRetriever in ExecutionSlotAllocatorFactory's,1
"[FLINK-19552][coordination] Consider only available input location preferences for slot profile in pipelined region schedulingThe pipelined region scheduling strategy schedules regions once all their input blocking dependencies are ready.The SlotSharingGroups of the region can include executions of other regions which are not scheduled yet including their dependencies.Hence we should not wait other unavailable input dependencies to unblock the current region scheduling.The new SlotSharingExecutionSlotAllocator creates the DefaultSyncPreferredLocationsRetrieverwhere the original InputsLocationsRetriever is wrapped with the AvailableInputsLocationsRetriever.It makes the InputsLocationsRetriever return only completed input location futures, others are filtered out.This allows to return completed future from DefaultSyncPreferredLocationsRetriever and make it synchronous and non-blocking.This closes #13730.",1
[FLINK-19252][security] Proactively create the working dir for Jaas security module,1
[FLINK-19508][DataStream] Add collect() operation on DataStreamThis closes #13752,5
[FLINK-19464][runtime] Rename CheckpointStorage interface to CheckpointStorageAccessThis closes #13794,2
[FLINK-19814] FeedbackTransformation is not supported in BATCH modeThis closes #13795.,1
[FLINK-19815] CoFeedbackTransformation is not supported in BATCH modeThis closes #13795.,1
[FLINK-19684][jdbc] Fix 'max-retries' option doesn't work when set to zeroThis closes #13669,1
[FLINK-19694][table-planner-blink] Support upsert ChangelogMode for ScanTableSource in plannerThis closes #13721,4
[FLINK-19694][table-planner-blink] Update MetadataHandlers for the new introduced StreamExecUpsertMaterialize nodeThis closes #13721,1
[FLINK-19694][table-runtime-blink] Support upsert ChangelogMode for ScanTableSource in runtimeThis closes #13721,1
[minor] Rename CliFrontend.parseParamters() to parseAndRun()Because that's what it does.,1
"[minor] Add project.basedir system property, use in CliFrontendTestUtilsBefore, we were relying on the current working directory, which isunreliable and can change, depending on where/how tests are executed.",3
"[FLINK-19493] In CliFrontend, make flow of Configuration more obviousBefore, it was up to the CustomCommandLine implementation whether anyConfiguration was passed through from the flink-conf.yaml or whereverthe base Configuration came from.Now, we make the flow of the Configuration explicit inCliFrontend.getEffectiveConfiguration(). Instead of relying on theConfiguration we get from the CustomCommandLine we ask theCustomCommandLine to materialize its settings and add them manually toan effective Configuration that the CliFrontend controls.This removes the Configuration parameter from CustomCommandLines thatdon't need it anymore, such as DefaultCLI, which means we also have totouch tests.This adds a new integration test in CliFrontendITCase that verifiescorrect parameter passing and also verifies that command line argumentsoverride base settings.",1
"[FLINK-19521] Support dynamic properties on DefaultCLIThis allows specifying arbitrary configuration options using the""-Dfoo=bar"" syntax. Before, this was only possible when using theGenericCLI or YARN cli.",1
[FLINK-19494] Add StreamExecutionEnvironment.fromSequence()This uses the new NumberSequenceSource underneath.,1
[hotfix] Fix StreamExecutionEnvironmentTest,3
[FLINK-19793][connector-kafka] Harden KafkaTableITCase.testKafkaSourceSinkWithMetadataHardens the KafkaTableITCase by further improving the new test utilities and ignoringnon-deterministic metadata columns.This closes #13802.,5
[hotfix][testing] Add common test utility for collecting all elements from a stream,3
[FLINK-13095][state-processor-api] Expose trigger state in window reader,2
[FLINK-13095][state-processor-api] Introduce window bootstrap writer for writing window operator stateThis closes #13510,1
[FLINK-18044][Connectors/Common] Add the subtask index information to the SourceReaderContext. (#12647),5
[FLINK-19789][hive] Migrate Hive connector to new table source sink interfaceThis closes #13771,1
[FLINK-19233][python] Support distinct and filter keywords on Python UDAFThis closes #13804.,1
[FLINK-19641][hive] Optimize parallelism calculating of HiveTableSource by checking file numberThis closes #13636,2
[FLINK-19201][python][tests] Add retry logic for conda install to avoid network problemsThis closes #13799.,0
[FLINK-19626][table-planner-blink] Introduce multi-input operator construction algorithm (#13742),1
[FLINK-19587][table-planner-blink] Fix error result when casting binary as varcharThis closes #13612,2
[FLINK-8357] Use rolling logs as default,2
"[FLINK-19627][table-runtime] Introduce OneInput, FirstInputOfTwoInput, SecondInputOfTwoInput, InputSelectionHandler for multiple input operator",1
[FLINK-19627][table-runtime] Introduce different Output sub-classes for multiple input operator,1
[FLINK-19627][table-runtime] Introduce multiple input operator for batch,1
[FLINK-19839][e2e] Properly forward test exit code to CI system,5
[FLINK-19569][table] Upgrade ICU4J to 67.1 (#13805),2
[FLINK-19764] Add More Metrics to TaskManager in Web UIThis closes #13786,1
[FLINK-18811][network] Pick another tmpDir if an IOException occurs when creating spill file,2
"[FLINK-19213][docs-zh] Translate ""Confluent Avro Format"" page into ChineseThis closes #13801",1
[FLINK-19077][table-blink] Support processing time temporal table join in runtimeThis closes #13300,1
[FLINK-18122][e2e] Make K8s test more resilient by retrying and failing docker image buildThis closes #13779,2
"[FLINK-19834] Make the TestSink reusable in all sink related testsThis patch does three things:1. Change the `Supplier&Function` fields to normal object fields, whichmakes the sink serializable easily2. Introduce the TestSink.Builder to create the test sink object.3. Change the TestSink from a generic class to a normal class, whichmake extract TypeInformation possible.",5
"Revert ""[FLINK-18122][e2e] Make K8s test more resilient by retrying and failing docker image build""This reverts commit d47433a9384b109cba4d83ab4cf4b9a3457de885.",4
[FLINK-19854][table-planner-blink] Fix the failed TableScanTest#testTemporalJoinOnUpsertSourceThis closes #13823,3
[FLINK-19770][python][tests] Extract PythonProgramOptionTest#testConfigurePythonExecution into an ITCaseThis closes #13756.,1
[hotfix][doc] Correct FSDataInputStream in FileSystem documentThis closes #13620,2
[hotfix][json] Add serialVersionUID to JsonInputFormat classThis closes #13809,5
[FLINK-19599][table] Introduce Filesystem format factories to integrate new FileSource to tableThis closes #13605,2
[FLINK-19766][table-runtime] Introduce File streaming compaction operatorsThis closes #13744,1
[FLINK-19702][hive] Avoid using static variable HiveConf.hiveSiteURLThis closes #13685,5
"[FLINK-19671][codestyle] Revert .editorconfig change violating our coding style> Rules about breaking the long lines:>> Break the argument list or chain of calls if the line exceeds limit or earlier if you believe that the breaking would improve the code readability> If you break the line then each argument/call should have a separate line, including the first one> Each new line should have one extra indentation (or two for a function declaration) relative to the line of the parent function name or the called entity",1
[hotfix][network] Remove unused EventSerializer#isEvent method,1
[hotfix][network] Rename ALIGNED_EXACTLY_ONCE_CHECKPOINT_BARRIER and improve java docs in DataType,5
[hotfix][checkpointing] Remove unused variable in AlternatingController,1
[FLINK-19680][checkpointing] Provide alignment timeout checkpoint option,1
[FLINK-19680][checkpointing] Announce timeoutable CheckpointBarriers,2
[FLINK-19836] Add SerializableSupplier in flink-coreThis existed in tests before but I'm planning to use this inSimpleVersionedSerializerTypeSerializerProxy and it fits with the otherspecial purpose Suppliers.,1
"[FLINK-19836] Add SimpleVersionedSerializerTypeSerializerProxyThis allows using a SimpleVersionedSerializer, which the Source and SinkAPI provide, in places where we need a TypeSerializer, such as whensetting the serializer that is used for records in a DataStream/that aresent between operators.",1
[hotfix][coordination] Refactor Builder for TestingSchedulingExecutionVertex in tests,3
[hotfix][coordination] Add execution state to RestartPipelinedRegionFailoverStrategyTest,3
[hotfix][coordination] Deduplicate verification logic in RestartPipelinedRegionFailoverStrategyTest,3
"[FLINK-19712][Coordination] Do not restart CREATED executions in RestartPipelinedRegionFailoverStrategyWhen a task fails and it is pipelined region failover strategy, alltasks in the region of the failed task and in the downstream regionswill be canceled for later re-scheduling. However, these tasks can bestill in CREATED state so that there is no need to cancel these tasks.Skipping canceling these tasks can speed up the failover and reduce alot of unnecessary CANCELING logs logs.This closes #13749.",2
[FLINK-18820] Emit MAX_WATERMARK at the end in SourceOperatorStarting from this commit we emit a MAX_WATERMARK when all records areproduced in SourceOperator or a stop with savepoint was triggered.This closes #13073,1
"[FLINK-19779][avro] Remove the ""record_"" field name prefix for Avro format deserializationNever modify and prefix the field name, instead, we now use the {rowName}_{fieldName}as the nested row type name because Avro schema does not allow same name row typewith different schema.",1
"[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization* Fix the TIME schema precision as 3* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,  DECIMAL, MAP, ARRAY* The table schema row type should be always non-nullable",5
[FLINK-18851][runtime-web] Add checkpoint type to checkpoint history,1
[hotfix] Fix typo,2
[hotfix][e2e] Skip python kubernetes e2e test on arma. MiniConda doesn't support aarch64 currently.b. Pyarrow which Pyflink depends on doesn't support aarch64 currently.,1
[FLINK-19357][fs-connector] Introduce createBucketWriter to BucketsBuilder,1
[FLINK-19357][fs-connector] Introduce FileLifeCycleListener to BucketsThis closes #13697,2
[FLINK-19078][table-runtime] Support row time temporal table join in runtimeThis closes #13307,1
[FLINK-19870][table-planner] Fix special case when the reuse of exchange causes the deadlock,1
[hotfix][python] Fix the module name of the entrypoint in pyflink-udf-runner.bat (#13848),2
"[FLINK-19749][docs] Improve the documentation in 'Table API' page, e.g. typo, sync between the English and Chinese doc, etcThis closes #13791.",2
[FLINK-18122][e2e] Make K8s test more resilient by retrying and failing docker image build (2nd try),1
[FLINK-19235][python] Support mixed use of built-in aggs with Python UDAFThis closes #13843.,1
[FLINK-19824][table-api] Refactor and merge SupportsComputedColumnPushDown and SupportsWatermarkPushDown interfacesThis closes #13806,1
"[FLINK-19835] Rename TimestampsAndWatermarks implementations to better reflect their purposeBefore, they were semantically tied to BATCH vs. STREAMING. Now, theirnaming just describes what they are doing because both of them might beused in both BATCH or STREAMING execution mode, depending on therequirements.",1
"[FLINK-19835] Turn SourceTransformation into a logical TransformationBefore, SourceTransformation was a PhysicalTransformation where theoperator was directly instantiated from the API. Now, we only create theoperator when we need to and when we know whether we're executing inBATCH or STREAMING mode.",1
[FLINK-19835] Make SourceOperator aware of BATCH/STREAMING execution mode,1
[refactor] Add a DEFAULT_CHAINING_STRATEGYFor cases where a field needs a default strategy because we don't wantto allow null values.This is explicitly not changing AbstractStreamOperator.chainingStrategybecause some parts might expect the different default of HEAD.,5
[FLINK-19762][WebUI] Improve content selection when double-clicking IDs,1
[FLINK-18363] Add user classloader to context in DeSerializationSchemaThis commit exposes the user code classloader along with the possibilityto register release hooks in the DeserializationSchema andSerializationSchema.Additionally it introduces a helper classes for easier creating theInitializationContexts from a RuntimeContext.This closes #13844,1
[FLINK-19892][python] Replace __metaclass__ field with metaclass keywordThis closes #13856.,2
[FLINK-19894][python] Fix the bug that from_pandas doesn't work well with index of float typeThis closes #13855.,1
[FLINK-19908][table-planner-blink] FlinkLogicalTableSourceScan and CommonPhysicalTableSourceScan should respect source reuse config option,5
[FLINK-19632] Introduce a new ResultPartitionType for Approximate Local Recovery,1
"[FLINK-19855][network] Specify channel AND gate in resume/block consumption()Given channelIndex only, UnionInputGate has to guess which wrapped inputgate this channel belongs to. For that, UnionInputGate expects channelindex with an inputGate offset. This contradicts with the contract ofother resumeConsumption() implementations.UnionInputGate.resumeConsumption isn't used currently but is planned tobe used in FLINK-19856.",2
[FLINK-19900] Remove surefire log4j configuration from pom.xml,5
[hotfix][table-runtime] Temporarily disable unstable tests in TemporalJoinITCaseThis closes #13875,5
[FLINK-19915][cep] fix comments bug of cep test.,3
"[FLINK-19907][network] Recover channel state before initializing operators chainOtherwise, operators in chain can emit watermarks or other data beforethe old data is being sent to the downstream.",5
[FLINK-19904][docs] Document possible mismatch between Xmx and maximum heap size metricSee https://plumbr.io/blog/memory-leaks/less-memory-than-xmx for further details.,2
[FLINK-19736] Add SinkTransformation along with TranslatorThis patch does three things:1. Introduce 'SinkTransformation' to represent the new sink api.2. Introduce 'SinkTransformationTranslator' that translates the'SinkTransformation' to the corresponding runtime operators.3. Make DataStream Sdk support new sink api.,1
[FLINK-19843][table] Fix ParquetFsStreamingSinkITCase.testPart which failed with 'Trying to access closed classloader' (#13873),1
"[FLINK-19703][hotfix][runtime] Remove the while-loop in Execution#processFailThe loop was introduced in case of concurrent issue, while the issue was already solved by FLINK-11417which forces all ExecutionGraph modification to be performed in the main thread.",1
[FLINK-19703][runtime] Replace the param 'isCallback' in Execution#processFail(...) with 'cancelTask'Because 'isCallback' is not accurate and can lead to confusion.This commit also adds a detailed explanation for params of Execution#processFail(...).,0
[FLINK-19703][runtime] Wrap TaskExecutionState with extra info of internal failure handlingExtra info includes wether to cancel task and whether to release partitions.,5
[FLINK-19865] Introduce default log rotation limit for non-standalone deployments,2
[FLINK-19875][table][fs-connector] Integrate file compaction to filesystem connectorThis closes #13852,5
[FLINK-19727][table] Implement ParallelismProvider for sink in blink plannerThis closes #13789,2
[FLINK-19235][python] Support mixed use with most built-in aggs for Python UDAFThis closes #13854.,1
[hotfix][table-common] Add ChangelogMode.toString(),4
[hotfix][core] Add Configuration.fromMap,5
[FLINK-19294][connector-kafka] Support key/value formats in Kafka table source and sinksThis closes #13862,1
[FLINK-19861][docs][table] Improve functions document which are not deterministicThis closes #13842,5
[FLINK-19833] Rename Sink API Writer interface to SinkWriterThis makes it more consistent with SourceReader.This closes #13887.,1
[FLINK-19760] Sink API: Make the `GlobalCommitter` not extend the `Committer`This patch decouples the `GlobalCommitter` from the `Committer`interface in the new Sink API.This closes #13888.,1
[FLINK-19841] Sink API: Rename GlobalStreamingCommitterOperator to StreamingGlobalCommitterOperatorThis makes it more consistent with other sink runtime operators.This closes #13889.,1
[FLINK-19932] Add integration test for BATCH execution on DataStream API,5
[FLINK-15408][table-planner-blink] Interval join supports non-equal condition,1
[FLINK-19831][coordination] Implement SlotManager#setFailUnfulfillableRequest,0
[FLINK-19740][python] Fix to_pandas to Support EventTime in Blink PlannerThis closes #13896.,2
[FLINK-16522][python] Add support of type hintsThis closes #13838.,1
[FLINK-19874][table-planner] Apply JoinDeriveNullFilterRule after join reorder,2
"[hotfix][config] Add env.isUnalignedCheckpointsEnabled() (java/scala/python)The next commits adds a force option, so this method is needed forconsistency.",1
[FLINK-19924][config] Add an option to force Unaligned Checkpoints,1
[FLINK-19924][config] Disallow Unaligned Checkpoints for iterative jobs by default,1
[FLINK-19924][config] Add StreamConfig.isGraphContainingLoopsThis allows subtasks to decide how to proceed with the recovery ofchannel state.,1
"[FLINK-19923][coordination] Remove unused BulkSlotProvider, its implementation and testsBulkSlotProvider and its implementation (#12375) is not used any morebecause it was introduced for the removed OneSlotPerExecutionSlotAllocator (#12256)replaced by SlotSharingExecutionSlotAllocator (#13071) for the PipelinedRegionSchedulingStrategy.This closes #13877.",4
[hotfix][coordination] Remove confusing 'Bulk' from test names in PhysicalSlotProviderImplTest,3
[hotfix] Minor JavaDocs fixes for File Source classes.,2
[FLINK-19800][connector file] Make FileSourceSplit / FileSourceSplitState interaction extensible,2
[FLINK-19802][connector files] Let BulkFormat createReader and restoreReader methods accept Splits directlyThis is a step in supporting File Sources for BulkFormats that need subclasses of FileSourceSplit.,2
[FLINK-19803][connector files] Make PendingSplitCheckpoint and its Serializer generic to support sub-classes of FileSourceSplit,2
[FLINK-19804][connector files] Make FileSource class generic with respect to split typesThis closes #13847,2
"[FLINK-19597][network] Introduce SortBuffer and PartitionSortedBuffer for sort-merge based blocking shuffleData of different channels can be appended to a SortBuffer and after the SortBuffer is finished, the appended data can be copied from it in the given channel index order. PartitionSortedBuffer is an implementation of SortBuffer and it sorts all appended records only by subpartition index. Records of the same subpartition keep the appended order.",5
"[FLINK-19600][network] Introduce PartitionedFile and the corresponding writer/reader for sort-merge based blocking shufflePartitionedFile is the persistent file type of sort-merge based blocking shuffle. It can contain multiple data regions and in each data region, data of the same subpartition is stored together. PartitionedFile can be produced by PartitionedFileWriter and consumed by PartitionedFileReader.",2
"[FLINK-19601][network] Introduce sort-merge based blocking result partition SortMergeResultPartition and the corresponding subpartition readerSortMergeResultPartition appends all added records and events to a SortBuffer and after the SortBuffer is full, all data in the SortBuffer will be copied and spilled to a PartitionedFile in subpartition index order. Different from the hash-based blocking shuffle implementation, a SortMergeResultPartition can write at most one file concurrently and can produce at most one data file along with one index file.",2
"[FLINK-19602][network] Introduce new config options to enable sort-merge based blocking shuffleTwo new config options are added to control the behavior of the sort-merge based blocking shuffle:1.taskmanager.network.sort-shuffle.min-buffers:Minimum number of network buffers required per sort-merge blocking result partition.2.taskmanager.network.sort-shuffle.min-parallelism: Parallelism threshold to switch between sort-merge blocking shuffle and the default hash-based blocking shuffle.With these new config options, the default behavior of blocking shuffle stays unchanged.",4
[FLINK-19603][network] Introduce shuffle data compression to sort-merge based blocking shuffleData will be compressed before spilled to disk and depressed at consumer side which can reducethe storage overhead and improve the disk/network IO performance.This closes #13595,1
[FLINK-19901][metrics] Fix caching offset for variables,1
[hotfix] Add Operator suffix to StreamGroupedReduce,0
[FLINK-19931] Do not emit intermediate results for reduce operation BATCH execution modeThis PR introduces ReduceTransformation and a corresponding translatorthat produces runtime execution mode dependent operator.The operator for the BATCH execution instead of emitting intermediate results after each incoming event it registers a callback for max watermark and then emits the result for a given key when the timer fires.,1
"[FLINK-19856][network] Emit EndOfChannelRecoveryEventThis event would allow to tear down ""virtual channels""used to read channel state on recovery with unaligned checkpoints andrescaling.",1
[FLINK-18716][python][docs] Remove the deprecated execute and insert_into calls in PyFlink Table API docsThis closes #12992.,2
[FLINK-19138][python] Support directly specifying input_types and result_types as DataTypes.ROWThis closes #13906.,5
[FLINK-19948][table-planner-blink] Fix calling NOW() function throws compile exceptionThis closes #13901,1
[FLINK-19873][canal-json] Skip DDL change events for Canal dataThis closes #13872,5
[FLINK-18325][table-sql-parser] Check null when calling SqlDataTypeSpec#getNullableThis closes #13836,5
[FLINK-19891][table-planner-blink] ScalarOperatorGens should generate a not-null type for IS NULL and IS NOT NULLThis closes #13851,1
[FLINK-19639][table-planner] Support nested projection push down in planner,1
"[FLINK-19927][coordination] Enable ExecutionStateUpdateListener state updates in EG independent from legacy schedulingThe state updates for ExecutionStateUpdateListener in ExecutionGraph#notifyExecutionChange are not done at the momentbecause ExecutionGraph#notifyExecutionChange is currently enabled only for legacy scheduling.This prevents from stopping deployment tracking for execution state TM/JM reconciliation, hence it leads to memory leaks.The state update handling is supposed to be done only in SchedulerNG (DefaultScheduler), not in legacy code of ExecutionGraph.However, this generally requires more refactoring for execution deployment tracking and reconciliation.Hence, this commit just enables ExecutionStateUpdateListener state updates in ExecutionGraph#notifyExecutionChange for SchedulerNG as a quick fix,before we refactor the execution deployment tracking and reconciliation.JobMasterExecutionDeploymentReconciliationTest#testExecutionDeploymentReconciliation is also extended with the checkthat ExecutionStateUpdateListener is called and the execution deployment tracking is stopped.The commit also refactors tests in JobMasterExecutionDeploymentReconciliationTest and introduces TestingExecutionDeploymentTrackerWrapper to facilitate ExecutionDeploymentTracker call checks.This closes #13908.",3
[hotfix][docs] Fix typos in StreamingFileSink javadocsThis closes #13819.,2
[FLINK-19809][coordination] Add DeclareResourceRequirementServiceConnectionManager,1
[FLINK-19862][coordination] Check for null in DeclarativeSlotManager#suspend,2
[FLINK-19960][table] Introduce PartitionFieldExtractor to extract partition field from splitThis closes #13919,4
[FLINK-19890][table][fs-connector] Introduce LimitableBulkFormat to wrap BulkFormat when limit pushed downThis closes #13914,2
[hotfix][build] Replace hard-coded project version,0
[FLINK-19899][Kinesis][EFO] Optimise error handling to use a separate exception delivery mechanism[FLINK-19898][Kinesis][EFO] Ignore ReadTimeoutException from SubcribeToShard retry policyThis closes #13886.,1
[FLINK-19844][python][docs] Add documentation for Python UDAFThis closes #13905.,2
[FLINK-19790][json] Clear reused ObjectNode's content for map converter in RowDataToJsonConvertersThis closes #13777,5
[FLINK-19867][table-common] Validation fails for UDF that accepts var-argsThis closes #13833.,0
[FLINK-19952][core] Replace deprecated ConfigOption builder in SecurityOptions.This closes #13904,5
"[FLINK-19897][webui] Improve UI related to FLIP-102Add Tooltip to Heap metrics cell.he tooltip text: The maximum heap displayed might differ from the configured values depending on the used GC algorithm for this process.Rename ""Network Memory Segments"" into ""Netty Shuffle Buffers""Rename ""Network Garbage Collection"" into ""Garbage Collection""This closes #13870.",1
[hotfix][kubernetes] Fixed parameter order in assertion statement of tests.,3
[FLINK-19662][runtime] Added helper method for generating the dynamic configuration parameters based on the underlying JobManagerProcessSpec.,2
[FLINK-19662][runtime][core] Moved assembleDynamicConfigsStr into ConfigurationUtils to be used by both TaskExecutorProcessUtils and JobManagerProcessUtils.This changed the way how the parameter list is generated for the TaskExecutor removing the final space. This made it necessary to update the JavaCmdTaskManagerDecoratorTest.,3
"[FLINK-19662][runtime][kubernetes][yarn][dist] Added dynamic parameters to BashJavaUtils' JobManager argument extraction. Additionally, the Kubernetes and Yarn deployment were extended accordingly.The parameters are returned using the newly introduced global environment variable DYNAMIC_PARAMETERS.",2
[FLINK-19622][mesos] Refactored dynamic parameter parsing to use ClusterEntrypointUtils' helper method instead.,1
[FLINK-19662][container][runtime][kubernetes][mesos][yarn] Moved ClusterEntrypointUtils into ClusterEntrypoint package.,1
[FLINK-19662][runtime] Switched from hardcoded 1 exit code to ClusterEntrypointUtils.STARTUP_FAILURE_RETURN_CODE.This closes #13747.,0
[FLINK-19936] Stabilize the SinkITCaseThis fixes instabilities related to1. false assumptions about the order of receiving   the notification that a checkpoint is complete.2. makes sure that the test exits ONLY when the   committer and the global committer have received   all expected elementsThis closes #13898.,3
[FLINK-19810][CI] Automatically run a basic NOTICE file check on CI,2
[FLINK-19849] Fix NOTICE files for 1.12 releaseThis closes #13796,1
[hotfix][doc-zh] Update link formats in mem_setup.zh.md.,1
[FLINK-19953][doc-zh] Translation in docs/ops/memory/mem_setup.zh.md,2
[FLINK-19941][kafka][table] Support sink parallelism configuration for Kafka connectorThis closes #13902Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>,5
[FLINK-19959][table-planner-blink] Multiple input creation algorithm now considers related inputs when deducing input priorities,1
[FLINK-19959][table-planner-blink] Add IT cases for multiple input,1
[FLINK-19885][webui] FLIP-104: Add More Metrics to JobManager in Web UIThis closes #13849.,1
[FLINK-19365][hive] Migrate Hive source to FLIP-27 source interface for batchThis closes #13915,2
[FLINK-18117][e2e] Dynamically allocate port causing test instabilities (#13894),3
[hotfix] Do not emit EndOfChannelRecoveryEvent for Approximate Local Recovery,0
[FLINK-17295] Make ExecutionAttemptID random again (#13929),1
[FLINK-19958] Add IOException to all I/O related Sink API signatures,1
[FLINK-19758] Extract common code for file sinks into shared module,2
[FLINK-19758] Add unified FileSink based on new Sink API,1
"[minor] Add explanatory comments to FileSinkITCase, fix warnings",2
[hotfix][k8s] Use a more generic WatchCallbackHandler to replace PodCallbackHandler,0
[hotfix][k8s] Introduce AbstractKubernetesWatcher with common logics,2
[hotfix][k8s] Abstract get common labels to KubernetesUtils#getCommonLabels,1
[hotfix][k8s] Add interface FlinkKubeClient#close with no exception,2
[hotfix][util] Make FutureUtils#retry could stop at non-retryable exception,1
[hotfix][test] Refactor TestingContender and TestingListener to abstract some common methods,3
"[hotfix][coordination] Introduce new interfaces and data structure for LeaderElection and LeaderRetrieval composition mechanismAfter this commit, we will have a DefaultLeaderElectionService. Composed with different LeaderElectionDriver, we could perform a leader election for the contender, and then persist the leader information to various storage. Also we will get a DefaultLeaderRetrievalService. Composed with different LeaderRetrievalDriver, we could we could retrieve the leader information from different storages.This will make the contract more clear and easier to add new leader election/retrieval services.",1
[hotfix][coordination] Wire ZooKeeper leader election/retrieval services to new interface,1
[hotfix][coordination] Introduce AbstractHaServices for common logics and wire ZookeeperHaServices to new interface,1
[FLINK-19542][k8s] Introduce data structures and common operations for KubernetesConfigMap,5
[FLINK-19542][k8s] Introduce data structures and interface for KubernetesLeaderElector,5
[FLINK-19542][k8s] Implement LeaderElectionService and LeaderRetrievalService based on Kubernetes APIThis closes #13644.,2
[FLINK-19821][python] Add ProcessFunction and timer access in Python DataStream APIThis closes #13803.,5
[FLINK-19986] Skip license check for scala 2.12 profile,2
"[FLINK-18916][python][docs] Add ""Operations"" under the ""Python API"" -> ""User Guide"" -> ""Table API"" section",1
"[FLINK-18922][python][docs] Add ""Catalogs"" under the ""Python API"" -> ""User Guide"" -> ""Table API"" section",1
[FLINK-19858][upsert-kafka] Introduce the upsert-kafka table factoryThis closes #13850,2
[hotfix][kafka] Disallow primary key on insert-only kafka table,1
[hotfix][upsert-kafka] Support sink parallelism on upsert-kafka sink,1
[FLINK-19079][table-runtime] Introduce row time deduplicate operator (#13331),1
"[FLINK-15981][refactor] Refactor NettyMessage#write() to allow writing multiple message parts.Rather than having to produce one message (as a composite buffer) this now allows writingmultiple partial messages. That way, we can combine different message types, like a memorybuffer (for headers and events) with file region buffers (for direct file transfer).",2
"[FLINK-15981][network] Implement zero-copy file transfer in network based on FileRegion for bounded blocking partitionsFor file-type bounded blocking partition, the previous way was to allocate two unpooled segments for every subpartitionto read data during network transfer. The memory overhead is serious and could cause OOM errors (direct memory).This change uses FileRegion to transfer file data to the network without copying it to memory first (zero-copy transfer).The exception is SSL-enabled setups: Direct transfer from file cache to network cannot work with SSL, because with SSL thedata needs to be encrypted before being pushed into the network socket. SSL-enabled setups still behave as before.",1
"[hotfix] Move FileBufferReaderITCase from 'flink-tests' to 'flink-runtime'This helps fix some comlications with access to test resources, which fails on the Azure Pipelines setup.",1
[hotfix] Add a waitUntil() method to the CommonTestUtils.,3
[hotfix] Replace finally block with JUnit After method in SourceOperatorTest.,3
"[FLINK-19698] Move the CheckpointListener from flink-runtime to flink-core.To maintain backwards compatibility, the CheckpointListener in flink-runtime is not deleted immediately.",4
[FLINK-19698][connector/common] Let SplitEnumerator/SourceReader/SourceCoordinator implement CheckpointListener.,2
[hotfix] Only close the SourceReader and EventTimeLogic in the SourceOperator if they are not null.,1
[FLINK-19698][connector/common] Add a close() method to the SplitReader.,1
[FLINK-19987] Fix Hbase1.4 tests on Hadoop 3.1.3,3
[FLINK-19645][tests] Increase akka rpc timeout for ShuffleCompressionITCaseThis closes #13936.,1
[FLINK-19993] Remove flink-connector-filesystem moduleThis closes #13941.,5
"[FLINK-20007] SinkTransformationTranslator connect SinkWriter to correct upstream nodeCurrently the translation logic does not take into account virtual nodes,e.g. repartioning. This PR changes this.This closes #13952.",4
[FLINK-19756][table-planner] Rename BatchExecMultipleInputNode/StreamExecMultipleInputNode to BatchExecMultipleInput/StreamExecMultipleInput,2
[FLINK-19756][table-planner] Refactor ExplainTest#testExplainMultipleInput method,3
[FLINK-19756][table-planner] Enable multiple input optimization by default,0
[FLINK-19868][csv] Remove 'csv.line-delimiter' option for CSV formatThis closes #13925,4
[minor][python] Minor code cleanup,4
[FLINK-19284][python][docs] Add documentation about how to use Python UDF in the Java Table API programThis closes #13945.,1
"[FLINK-18926][python][docs] Add a ""Environment Variables"" document under the ""Python API"" -> ""User Guide"" -> ""Table API"" sectionThis closes #13935.",1
[FLINK-18004][docs] Update checkpoint UI related pictures in documentation,2
[hotfix][deployment] Fix exceptional control flow in TaskDeploymentDescriptorFactory.,0
[hotfix][tests] Remove unused methods in ChannelPersistenceITCase.,1
[hotfix][util] Fix Precondition#checkNotNull annotations.,0
[hotfix][tests] Chain unexpected exception to assertion error.,0
[hotfix][core] InstantiationUtil#serializeObject creates ObjectOutputStream only when necessary.,1
[hotfix][checkpoint/test] Don't swallow the original exception when cleanup fails as well.,0
[FLINK-19533][checkpoint] Rewrite StateAssignmentOperation to only use generated OperatorID.,1
[FLINK-19533][checkpoint] Introduce builder for OperatorSubtaskState.The builder will make it easier to add more fields to OperatorSubtaskState in future commits.,1
[hotfix][checkpoint] Remove NonNull annotations and remove trivial doc in OperatorSubtaskState.,1
[FLINK-19533][runtime/streaming] Add SubtaskStateMapper to determine mapping between old and new subtasks.Each partitioner has a unique way to partition data. Only the partitioner can narrow down the state of old subtasks needed to recover the data on upstream and downstream side.Note that the mapper may create non-unique mappings during unaligned checkpoint rescaling. The replicated data will then be filtered by the partitioner downstream during recovery.,5
"[FLINK-19533][checkpoint] Adding subtask index to channel state handles.During downscaled recovery of in-flight data, multiple channel state handles are recovered at the same subtask and the subtask index is needed to distinguish between them.",0
[FLINK-19533][checkpoint] Add TaskStateAssignment to capture all intermediate state of StateAssignmentOperation.TaskStateAssignment encapsulates the state of one task and is ultimately transformed into an OperatorSubtaskState.Note this commit also removes ChannelStateNoRescalingPartitionerTest since it's not valid at the end of the PR anymore.,3
[FLINK-19533][checkpoint] Add multipass StateAssignmentOperation.This change allows StateAssignmentOperation to update the state assignment of one task while processing another task. The next commit will use it to set rescaling descriptor of upstream/downstream nodes.,1
[FLINK-19533][checkpoint] Add InflightDataRescalingDescriptor during rescaling.The descriptor contains virtual channel mappings that are used to restore spanning records while physical channels have been ambiguously rearranged (up- or downstream DOP changes).Note that the actual recovery with virtual channel will be added in a follow-up PR.,1
[FLINK-19837][DataStream] Don't emit intermediate watermarks from watermark operators in BATCH execution modeThis closes #13853,1
"[FLINK-19909] Shutdown application cluster in attached mode when job cancelledCurrently when executing an application in Attached Application modewe do not shutdown the cluster when the job is cancelled. That isbecause the exception thrown does not include the STATUS with whichthe job failed, so we cannot distinguish between different reasonsof unsuccessfule termination. This commit fixes this.This closes #13911.",0
[hotfix] Rename ApplicationFailureException to UnsuccessfulExecutionException,0
[FLINK-20003][coordination] Include resourceProfile at the end of SlotStatus#toString,2
[FLINK-20003][coordination] Add line-breaks and intendation in SlotReport#toString,5
[hotfix][coordination] Skip logging of excess resources if none exist,2
+,5
[FLINK-19902][coordination][tests] Adjust JobMasterTest to be compatible with declarative resource management,3
"[FLINK-20001] Don't use setAllVerticesInSameSlotSharingGroupByDefault in StreamGraphGeneratorI think the default of having all vertices in the same slot sharinggroup should be good for both BATCH and STREAMING right now. We canreconsider actually setting this flag in the future.Background information: this is a special setting that was introducedfor the Table API Blink runner/planner, which does special things withslot sharing (or lack thereof) and is more aware of memory requirementsand such. For general DataStream/DataSet programs changing the settingdoesn't make sense.",1
[FLINK-19742][e2e] Update e2e readme[skip ci]This closes #13948.,5
"[FLINK-19431][docs-zh] Translate ""Monitoring REST API"" page of ""Debugging & Monitoring"" into ChineseThis closes #13601",1
[FLINK-19939][table-planner-blink] Remove redundant union from multiple input node,4
[FLINK-19699] Log signals received by running tests,3
[FLINK-19699][e2e] Collect dmesg output after tests,3
"[FLINK-18546] Upgrade to Kafka Schema Registry Client 5.5.2The commit changes the packaging of flink-avro-confluent-registry module. We do no longer ship a fat-jar. Instead users should build the fat-jar themselves. It is because the upgraded version of registry client accesses fields from Avro of Jackson types. Because of the fact we can either bundle and shade both Avro and Jackson, or not shade Jackson. I decided it will be best not to ship a fat-jar and leave that decision to users.On the other hand for the sql-client it is better to provide fat-jars, however because of 1. I added a separate flink-sql-avro-confluent-registry module that builds a fat-jar (including Avro, and shaded jackson).",5
"Revert ""+""This reverts commit 9eb295f1dfdd6eb669376656f0b2156bedf687a9.",4
"Revert ""[FLINK-19902][coordination][tests] Adjust JobMasterTest to be compatible with declarative resource management""This reverts commit 4dfcc8e863bf3528a01f72f11a26b6cc8cd42e48.",4
[FLINK-19902][coordination][tests] Adjust JobMasterTest to be compatible with declarative resource management,3
[FLINK-19850] Add e2e tests for the new FileSink in streaming mode,2
"[hotfix] In FileBucketWriter, change the bucket part id to UUIDThis provides more ""uniqueness"" than just RandomStringUtils.",1
[FLINK-20006] Fix the unstable FileSinkITCase,2
[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk FormatThis closes #13724,2
"[FLINK-19384][core] Add common permissive exception signatures to all methods of Source.This makes the exception signatures consistent within the class and with the exception philisophyin other API classes, like transformation functions: Allow users to simply throw or forward anytype of checked exceptions.",1
[hotfix] Improve JavaDocs of SourceReader.,2
"Revert ""[FLINK-19850] Add e2e tests for the new FileSink in streaming mode""This reverts commit dfd2a55065e228b973f9e2343b6252ca308e5398.",4
[FLINK-19992][hive] Integrate new orc to Hive sourceThis closes #13939,1
[FLINK-19741] Let timer service skip reading raw keyed state if it isn't the writerThis closes #13761.,2
[FLINK-19748] Skip key groups that don't have a defined stream offset,1
[FLINK-19748] [test] Adjust raw keyed state test to only write some key groupsThis closes #13772..,3
[FLINK-19282][table-planner] Support watermark push down in planner,1
[FLINK-19886][hive] Integrate file compaction to Hive connectorThis closes #13937,2
"[FLINK-14356][table][formats] Introduce ""single-value"" format to (de)serialize message for single field",2
"[FLINK-14356][table][formats] Refactor and rename ""single-value"" to ""raw"" formatThis closes #13909",4
[FLINK-19644][hive] Support read latest partition of Hive table in temporal joinThis closes #13729,3
[hotfix][table-common] Improve terminology for data types in formats,5
[hotfix][table-common] Add hashCode/equals to DataTypes.Field,5
[FLINK-19276][json][connector-kafka] Support reading Debezium metadataThis exposes metadata for the Debezium JSON format according to FLIP-107.- Update the Kafka connector to expose format specific metadata.- Reconfigure the internal JsonRowDataDeserializationSchema to read additional fields.- Let DebeziumJsonDeserializationSchema access and convert those additional fields to metadata columns.This closes #13910.,5
[FLINK-19823][table][fs-connector] Filesystem connector supports de/serialization schemaThis closes #13957,1
[FLINK-19963] Allow SinkWriter use processing timer service.This closes #13969.,1
[minor][python] Minor code cleanup,4
[FLINK-19510][sink][fs] Support processing time policicies in FileSinkThis closes #13971.,2
"[FLINK-20008] Close LeaderElectionDriver outside of lock in DefaultLeaderElectionService.stop()In order to avoid deadlocks in LeaderElectionDrivers which call onGrantLeadership and revokeLeadershipunder an internal lock, we must not close the LeaderElectionDriver under the DefaultLeaderElectionService.lock.",2
"[FLINK-20008] Move LeaderContender callbacks back under the DefaultLeaderElectionService lockIn order to avoid seeing LeaderContender callbacks after the DefaultLeaderElectionServicehas been shut down, they need to be executed under the lock of the service. This entailsthat the user of this class should not close the service under the same lock as thecallback can acquire.",1
"[FLINK-20008] Move leaderRetrievalDriver.close out of lock scope in DefaultLeaderRetrievalService.closeThis commit moves the closing of the leaderRetrievalDriver used by the DefaultLeaderRetrievalServiceout of the lock scope. This ensures that if the LeaderRetrievalDriver triggers callbacks while holding a lock,then we won't deadlock.Moreover, this commit moves the LeaderRetrievalListener callback back under the lock scope in order to avoidcallbacks after the DefaultLeaderRetrievalService has been closed.This closes #13968.",4
"[FLINK-19811][table-planner] Introduce RexSimplify to simplify SEARCH conditionse.g. [CALCITE-4364] `a IN (1, 2) AND a = 1` should be simplified to `a = 1`",2
[hotfix] Move RetrievableStateStorageHelper and implementation out of zookeeper package so that it could be reused by Kubernetes high-availability,1
[hotfix][test] Abstract TestingLongStateHandleHelper from ZooKeeperStateHandleStoreTest so that it could be reused,1
[hotfix][coordination] Introduce the interface StateHandleStore and make ZooKeeperStateHandleStore as an implementation,0
"[hotfix][coordination] Introduce new interfaces and data structure for JobGraphStore composition mechanismAfter this commit, we will have a DefaultJobGraphStore. Combined with different StateHandleStore, we could persist the job graphs to various distributed storage. Also combined with different JobGraphStoreWatcher, we could get all the changes on the job graph store and do the response.",4
"[hotfix][coordination] Wire ZooKeeperJobGraphStore to the new interfaceWe introduce three specific composition implementations for ZooKeeper, ZooKeeperJobGraphStoreWatcher, ZooKeeperJobGraphStoreEventHandler, ZooKeeperJobGraphStoreUtil.* ZooKeeperJobGraphStoreWatcher is a watcher on JobGraphStore. It could monitor all the changes on the job graph store and notify the DefaultJobGraphStore via JobGraphStore.JobGraphListener.* ZooKeeperJobGraphStoreUtil is a utility class which could convert a ZooKeeper path to JobId, or vice versa.",4
[FLINK-19543][k8s] Implement KubernetesStateHandleStore based on Kubernetes API,0
[FLINK-19543][k8s] Introduce composition implementations to support JobGraphStore on Kubernetes,1
[FLINK-19543][k8s] Implement KubernetesRunningJobsRegistry based Kubernetes APIThis closes #13864.,1
[hotfix][test] Add TestingRetrievableStateStorageHelper which is settable with exception,1
[hotfix][coordination] Introduce CompletedCheckpointStore composition mechanism and migrate ZooKeeperCompletedCheckpointStore,0
[FLINK-19544][k8s] Implement CheckpointRecoveryFactory based on Kubernetes APIThis closes #13871.,2
[FLINK-20002] Add a StreamExecutionEnvironment#getExecutionEnvironment(Configuration) method,5
[FLINK-20019][core] Support all conversion classes in Row.equals/hashCodeThis closes #13967.,1
[minor] Rework Javadoc in Sink interface,2
"[hotfix][table-common] Improve SupportsPartitioning documentationRemove confusing ""prefix key"" term from the class JavaDoc.",2
[hotfix][table-common] Return serializable SerializationSchema instances in TestSchemaFactory,3
[hotfix][table-common] Add LogicalTypeChecks.hasWellDefinedString,2
[hotfix][table] Promote JoinedRowData to flink-table-common,2
[hotfix][table] Implement equals and hashCode in JoinedRowData,5
"[FLINK-18858][connector-kinesis] Use forward-compatible Guava APIReplace calls to the deprecated (and since 26.0-jre removed)    Futures#addCallback(ListenableFuture<V>, FutureCallback<? super V>)with    Futures#addCallback(ListenableFuture<V>, FutureCallback<? super V>, Executor)which is a forwards-compatible alternative if the third argument is setto MoreExecutors.directExecutor().This preserves the semantics of hte call and allows clients to use bothflink-connector-kinesis and flink-table (which since dc1da6a5 guava 29.0-jre).",2
"[FLINK-18858][connector-kinesis] Add Kinesis sources and sinksThis adds an implementation, unit-tests, and docs for the following factories:- KinesisDynamicSource - produces FlinkKinesisConsumer instances.- KinesisDynamicSink - produces FlinkKinesisProducer instances.- KinesisDynamicTableFactory - produces instances of the above two factories.The following ability interfaces are supported:- KinesisDynamicSink implements SupportsPartitioning through a specialized KinesisPartitioner class.- KinesisDynamicSource implements SupportsReadingMetadata through a specialized KinesisDeserializationSchema class.This closes #13770.",5
[hotfix][table] Move JoinedRowData to utils subpackage,5
[FLINK-20041][kafka] Support watermark push down for kafka sourceThis closes #13975,1
"[FLINK-20037][table-api] Fix the Javadoc of TableEnvironment#fromValues(AbstractDataType, Object...)This closes #13976Co-authored-by:  <yandufeng@sinochem.com>",5
[FLINK-19990][table-planner-blink] MultipleInput isChainableSource now considers DataStreamScanProviderThis closes #13942,5
[FLINK-18774][debezium-avro] Support debezium avro formatThis closes #13296,1
[FLINK-18774][debezium-avro] Improve debezium-avro format implementation,1
[FLINK-19850] Add e2e tests for the new FileSink in streaming mode,2
[FLINK-20031] Keep the UID of SinkWriter same as the SinkTransformationIn case we want to migrate the StreamingFileSink to the new Sink API wemight need to let user set the SinkWriter's uid same as theStreamingFileSink's. So that SinkWriter operator has the opportunity toreuse the old state. (This is just to keep the option open for now.)For this we need to let SinkWriter operator's uid is the same as theSinkTransformation.,1
[hotfix] Fix StreamingExecutionFileSinkITCase instability,2
[hotfix][python][docs] Fix the mistakes of connector options in the examples,0
[FLINK-19888][hive] Migrate Hive source to FLIP-27 source interface for streamingThis closes #13963,2
[FLINK-19934][Connector] Add SplitEnumeratorContext.runInCoordinatorThread(Runnable)This closes #13955,1
[hotfix][connector/common] Move SourceReaderTestBase to a separate module of flink-connector-test-utils in flink-test-utils-parent.,3
[hotfix][util] Add a util class to help closing components with timeout.,1
[hotfix][runtime/operator] Make RecreateOnResetOperatorCoordinator fully asynchronous.,1
[FLINK-18323][connector/kafka] Make a few methods in KafkaTestBase public so that it can run as a standalone Kafka service.,1
[hotfix][connector/common] Add a new util class to help with serde in the Source.,1
[hotfix][connector/common] Allow adding external tasks to the SplitFetcher. It helps avoid synchronizations between fetcher thread and main thread.,1
[FLINK-18323][connector/kafka] Add Kafka Source based on FLIP-27.,1
[hotfix] Add MockSplitEnumeratorContext.runInCoordinatorThread implementationThis commit adds a missing method implementation for SplitEnumeratorContext.runInCoordinatorThread.,1
"[FLINK-19693][runtime] Downstream Failover for Approximate Local RecoveryEnables downstream failover for approximate local recovery. That says if a task fails,all its downstream tasks restart, including itself. This is achieved by reusing the existingRestartPipelinedRegionFailoverStrategy --- treat each individual task connected byResultPartition.Pipelined_Approximate as a separate region.To achieve this, we introduced an attribute ""reconnectable"" in ResultPartitionTypeto indicate whether the partition is reconnectable. Notice that this is only a temporarysolution for now. It will be removed after: - Approximate local recovery has its won failover strategy to restart the failed set of   tasks instead of restarting downstream of failed tasks depending on   {@code RestartPipelinedRegionFailoverStrategy} - FLINK-19895: Unify the life cycle of ResultPartitionType Pipelined Family.   There is also a good discussion on this in FLINK-19632.",2
[FLINK-19693] Introduce a flag to enable approximate failover,0
[FLINK-19693] ITCases for Approximate Local Recovery,2
[FLINK-19717][connectors/common] Fix spurious InputStatus.END_OF_INPUT from SourceReaderBase.pollNext caused by split reader exception (#13776),1
[FLINK-19238][state-backend-rocksdb] Sanity check for RocksDB arena block sizeThis closes #13688.,5
[FLINK-20016][python] Support TimestampAssigner and WatermarkGenerator for Python DataStream API.This closes #13986.,5
"[FLINK-20033] Make JobManagerJobStatusListener call back run directlySince the ExecutionGraph can only be modified using the JobMaster's main thread, we no longerneed to trigger a jobStatusChanged async message when the JobManagerJobStatusListener.jobStatusChangescallback is triggered. This ensures that job status changes will directly be reported.",4
[FLINK-20033] Ensure that stopping a JobMaster will suspend the running jobThis commit adds a test which ensures that stopping a JobMaster will suspend the running job.This closes #13978.,1
"[hotfix] Remove unused parameters from JobMaster.jobStatusChangedThe implemenation of JobMaster.jobStatusChanged does not use the timestamp and the error.Hence, this commit removes them from the argument list.",4
[FLINK-20024][docs][docker] Add link to flink-docker repositoryThis closes #13962.,2
[FLINK-19974][python][e2e] Extract PyFlink YARN per-job test into a separate scriptThis closes #13930.,3
[FLINK-20047][coordination] DefaultLeaderRetrievalService should only notify the LeaderRetrievalListener when leader truly changedThis closes #13982.,4
[FLINK-19491] Add v2 snapshot test to AvroSerializerSnapshotTestWe do this before updating the version to 3 and changing theserialization format of the snapshot to ensure that the new code canread the older snapshot.This also adds the general infrastructure for testing restore from olderversions to the test.The generated serializer snapshot was created with snapshot v2.,1
[FLINK-19491][avro] Support large schema in AvroSerializerSnapshot,1
[FLINK-19933][DataStream] Execute and collect with limit fails on bounded datastream jobsThis closes #13893,5
"[FLINK-19265][core] Add to source coordinator built-in methods to signal ""no more splits"".This replaces custom events and event handling implemented by many sources.",1
[FLINK-20049][core] Add built-in method to request split in source API.This replaces the custom event handling done by many source implementations.,1
[hotfix][connector files] Remove empty default method override in FileSourceReader,2
[hotfix] Close File FormatReaders also when the source reader is closed before end of split.,2
[FLINK-20051][connector kafka] Ensure KafkaPartitionSplitRecords returned on consumer wakeup is properly initializes,5
[hotfix][doc] Change link format and add <a> tags in try-flink dir,2
[hotfix][doc] Change link format in flinkDev dir,2
[hotfix][doc] Change link format in internal dir,2
[hotfix][doc] Change link format in concepts dir,2
[hotfix][doc] Change link format in monitoring dir,2
[hotfix][doc] Change link format in learn-flink dirThis closes #13949,2
[FLINK-18570][hbase] improve log and exception message for hbase e2e test SQLClientHBaseITCase,3
[hotfix][hbase] Add missed ITCase in hbase2 connector,1
[FLINK-18938][table-api] Throw better exception message for querying sink only or source only connectorThis closes #13214,1
"[FLINK-20050][runtime/operator] Fix methods that are only visible for testing in RecreateOnResetOperatorCoordinator, so that they work with fully asynchronous thread model.",1
[FLINK-18755][docs-zh] RabbitMQ QoS Chinese Documentation,2
[FLINK-18070][table-planner-blink] Don't materialize time attribute for middle nodes in StreamCommonSubGraphBasedOptimizer,2
[FLINK-20045][tests] Let TestingLeaderEelctionEventHandler wait until being initializedThe commit changes the behaviour of the TestingLeaderElectionEventHandler so that it waitson being initialized before executing callbacks.This closes #14000.,5
[FLINK-19972][serialization] add more hints in case of incompatbilities,1
[FLINK-19394][docs-zh] Translate the 'Monitoring Checkpointing' page of 'Debugging & Monitoring' into Chinese,0
[FLINK-20064][docs] Fix the broken linksThis closes #14009.,2
[FLINK-19436][tests] Properly shutdown cluster in e2e tests,3
[refactor] Move Source Reader Test Utils classes from 'flink-core' test jar to 'flink-connector-test-utils',3
[FLINK-20063][connector files] FileSourceReader request only a split if it doesn't have one alreadyThis closes #14004,2
[FLINK-19882][e2e] Properly forward exit code in test,3
[FLINK-20023][docs] Remove note about downloading hadoop-specific Flink distribution,2
[FLINK-20069][build] Fix docs_404_check,2
[FLINK-19448][connector/common] Fix handling of finished splits and closing split fetchers in SourceReaderBaseThis closes #13989,1
[FLINK-19994][hotfix][runtime] Build pipelined regions only after DefaultExecutionTopology is fully constructedCurrently the `this` ref of DefaultExecutionTopology is published to PipelinedRegionComputeUtil in the constructor. This is a dangerous behavior and this commit targets to fix it.,0
[FLINK-19994][runtime] Do not force iteration job to generate one only pipelined region,1
[FLINK-19994][runtime] Remove unused interface method BaseTopology#containsCoLocationConstraints(),2
[FLINK-20013][network] Release network buffer in BoundedBlockingSubpartition if task is failed or canceled (#14008),0
[FLINK-20071][build] Add a dedicated stage to build the PyFlink wheel packgesThis closes #14013.,2
[hotfix][build] Update the expected wheel package number to 8 as we added support of py38,1
[FLINK-19842][python][tests] Fix the instable test case PyFlinkStreamUserDefinedTableFunctionTests.test_table_function_with_sql_queryThis closes #14010.,3
[FLINK-19912][json] Fix JSON format fails to serialize map value with null keysThis closes #13972,0
[FLINK-20058][kafka] Improve tests for per-partition-watermark kafka sourceThis closes #13997,3
[FLINK-20053][table][doc] Add document for file compactionThis closes #13990,2
[FLINK-13733][connector/kafka][test] Make FlinkKafkaInternalProducerITCase more robust.,2
[FLINK-13733][connector/kafka][test] Increase timeout to 60 seconds for FlinkKafkaInternalProducerITCase.testHappyPath,3
[FLINK-20068] Enhance the topic creation guarantee to ensure all the brokers receive the metadata update.,5
"[FLINK-19964][network] Avoid proactively pulling segments in destroyed LocalBufferPool.The following segment leak is closed:* Two LocalBufferPools are concurrently destroyed.* The second LocalBufferPool still gets buffer assigned while the first one is destroyed in NetworkBufferPool (always has been like this).* With the change in FLINK-16972, the second LocalBufferPool proactively acquires one of the assigned buffers.* Since it already has been destroyed this buffer is never returned to the NetworkBufferPool and simply vanishes from heap.",1
[FLINK-20035][tests] Use random port for rest endpoint in BlockingShuffleITCase and ShuffleCompressionITCase,1
"[FLINK-20018] Allow escaping in 'pipeline.cached-files' and 'pipeline.default-kryo-serializers'This commit enables escaping in options that expect a map ofstring-string entries. It lets users pass options such as e.g.pipeline.cached-files=name:file1,path:'oss://bucket/file1'",2
[FLINK-20076][runtime][test] Fixed DispatcherTest.testOnRemovedJobGraphDoesNotCleanUpHAFiles.We missed starting the JobGraphStore which caused an exception and prevented us testing the actual behavior even though the test succeeded.This closes #14019.,3
[FLINK-19673][doc-zh] Translate Standalone Cluster page into ChineseThis closes #13664.,1
[FLINK-19527][docs] Formatting and grammar fixesThis closes #14002,0
[FLINK-20079][task] Initialize operator chain before upstream partition request,1
[FLINK-19872][csv] Fix CSV format is unable to parse millisecond for TIME typeThis closes #13834,0
[hotfix][doc] Fix a concurrent issue in testing.md (#13974),3
[FLINK-20084][table-planner-blink] Fix NPE when generating watermark for null rowtime after watermark push downThis closes #14029,0
[FLINK-19253][connector/common] Synchronize setting the isIdle flag in SourceReaderBase.,1
[FLINK-19253][connector/common][test] Add test case to test when all split fetchers are closed with leftover element in queue,3
[minor] Fix the test name of SourceReaderBaseTest.testPollNextReturnMoreAvailableWhenAllSplitFetcherCloseWithLeftoverElementInQueue.,3
[FLINK-19340][table-runtime-blink] Support NestedRowData in RowDataSerializer#copyThe RowDataSerializer.copy() method did not consider NestedRowData which led toinconsistent MapState when using a heap state backend. This caused AggregateITCase.testListAggWithDistinctto be unstable when performing a distinct using map views.This closes #14035.The `RowDataSerializer.copy()` method did not consider `NestedRowData` which led toinconsistent `MapState` when using a heap state backend. This caused `AggregateITCase.testListAggWithDistinct`to be unstable when performing a distinct using map views.,1
[FLINK-20046][python] Fix the unstable test StreamTableAggregateTests.test_map_view_iterateThis closes #14043.,3
[FLINK-20077] Fix creating a view with MATCH_RECOGNIZE clause,1
"[FLINK-20075]When the JobMaster is initialized, the JobID of the JobGraph is retrieved again in the createlotpool methodThis closes #14015.",1
[checkpointing][refactor] Extract ChannelStatePersisterMotivation: unit testing,3
[FLINK-20097][checkpointing] Fix race conditions in ChannelStatePersister,0
"Revert ""[FLINK-20033] Ensure that stopping a JobMaster will suspend the running job""This reverts commit 86a96c7909a1c1db35157ebec4164529c0290c7d.",5
"Revert ""[FLINK-20033] Make JobManagerJobStatusListener call back run directly""This reverts commit 03047a78b6ad8017eb240548a009424d68ffc971.This closes #14037.",4
[FLINK-20029][table-planner-blink] Support computed columns with metadataFixes a bug in TableMergeUtil that prevented accessing metadata columnsin computed columns.This closes #14048.,5
[FLINK-20074][table-planner-blink] Fix can't generate plan when joining on changelog source without updatesThis closes #14027,5
[hotfix][table-planner-blink] Fix UpdateKindTrait inference of Join operator,1
[FLINK-19914][table-planner] fix TemporalJoinITCase.testEventTimeTemporalJoinChangelogUsingBeforeTime is instable,5
[FLINK-20096][docs] Add PyFlink overview,2
[hotfix][docs] crosslink udf documentation,2
[FLINK-20096][docs] Clean up Table API <-> DataFrame,5
[FLINK-20096][docs] Remove references to old versionsThis closes #14041,4
[FLINK-20093] Create a download page for all optional sql client componentsThis closes #14306,1
"[FLINK-20098] Don't add flink-connector-files to flink-distBefore, we had both flink-connector-files and flink-connector-base asdependencies of flink-dist.This implies, that users should use the dependency like this:<dependency><groupId>org.apache.flink</groupId><artifactId>flink-connector-files</artifactId><version>${project.version}</version><scope>provided</scope></dependency>which differs from other connectors where users don't need to specify<scope>provided</scope>.Also, flink-connector-files has flink-connector-base as a provideddependency, which means that examples that use this dependency will notrun out-of-box in IntelliJ because transitive provided dependencies willnot be considered.This change removes the dependencies from flink-dist and lets users usethe File Connector like any other connector.I believe the initial motivation for ""providing"" the File Connector inflink-dist was to allow us to use the File Connector under the hood inmethods such as StreamExecutionEnvironment.readFile(...). We coulddecide to deprecate and remove those methods or re-add the FileConnector as an explicit (non-provided) dependency again in the future.",1
[FLINK-20139][dispatcher] Enrich logs when MiniDispatcher shutting downThis closes #14058 .,5
[FLINK-20088][kinesis] Fix issue encountered when Polling consumer using timestamp with empty shardThis closes #14034.,1
[FLINK-20145][task] Don't expose modifiable PrioritizedDeque.iterator,2
"Revert ""[FLINK-20098] Don't add flink-connector-files to flink-dist""This reverts commit 3bd1a8163b6b9d1a1b7f3a293b919ea0af551c54.",4
[FLINK-20156] Correct JavaDoc example code in WatermarkStrategy.withTimestampAssignerIn order to compile with Java 8 we have to specify the generic parameter whenchaining WatermarkStrategy.withTimestampAssigner.This closes #14069.,4
[FLINK-19546][doc] Add documentation for native Kubernetes HAThis closes #14006.,2
[FLINK-20152] Document supported execution.target valuesThis closes #14070.,1
[FLINK-17470] Send sigkill to hanging processes in standalone scripts,2
[FLINK-20021][docs] Cleanup misuses of Dispatcher/JobManagerThis closes #13959.,1
[hotfix][network] Remove redundant data availability notification in SortMergeResultPartitionRemove redundant data availability notification in SortMergeResultPartition for FLINK-19391 has moved the notification to the requester.This closes #13991.,4
[hotfix][network] Call releaseAllResources() method directly in close() method of PartitionRequestQueueOne reason is to reduce code duplication and the other reason is that the availableReaders is also need to be cleared.This closes #13991.,0
[hotfix][doc] fix the usage example of datagen connector docThis closes #14060,2
[FLINK-20022][docs] Move statebackend tradeoffs out of checklistThis closes #13960.,4
[FLINK-20022] Add link from production readiness checklist to state backends page,2
[FLINK-20141][fs-connector] Add FileSink documentationThis closes #14061.,2
[FLINK-20141][fs-connector] Add FileSink javadocs,2
[FLINK-20141] Update Connectors main doc page for FS sinks,2
"[FLINK-20169] Move emitting MAX_WATERMARK out of the SourceOperator processing loopThis commit reverts some of the changes introduced infada6fb6ac9fd7f6510f1f2d77b6baa06563e222.Instead of checking for END_OF_INPUT in the SourceOperator, Iemit the MAX_WATERMARK from SourceOperatorStreamTask#afterInvoke. I check if the Task was cancelled or not. If it was notthat means the Task finished succesfully and we emit the MAX_WATERMARK.",5
[hotfix][table-planner-blink] Move function related tests to function package,1
[hotfix][table-planner-blink] Allow function tests with description,3
[hotfix][table-planner-blink] Allow function tests with other helper functions,1
[FLINK-18673][table] Improve support for ROW constructorThis closes #14067.,1
[FLINK-20144][docs] Change link format in doc/ops dirThis closes #14066,2
[FLINK-20043][kinesis] Add flink-sql-connector-kinesis module for SQL clientThis closes #14049.,2
[FLINK-19979][e2e] Add sanity check after bash e2e tests for no leftovers (#14033),3
"[FLINK-19863][tests][hbase] Harden HBase end-to-end testsThis commit checks the HBase processors and data dir have been cleaned up after shutting down a HBase cluster. And also checks the required resources, e.g. Zookeeper, HBase meta has been available when starting up a new HBase cluster.This closes #14032",1
[FLINK-19906][table-planner-blink] Fix incorrect result when compare two binary fieldsThis closes #13865,0
[FLINK-20177][docs] Fix the wrong link of kinesis in index.zh.mdThis closes #14087.,2
[FLINK-19859][docs] Add document for the upsert-kafka connectorThis closes #14017,2
"[FLINK-20163][docs-zh] Translate page ""raw format"" into ChineseThis closes #14075",1
[FLINK-19300] Fix input stream read to prevent heap based timer lossThis closes #14042.,0
[FLINK-19806][runtime] Harden DefaultScheduler for concurrent suspending and failing,0
"Revert ""[FLINK-19979][e2e] Add sanity check after bash e2e tests for no leftovers (#14033)""This reverts commit 4cc0e72208f57c33bcd1314342d97b9f3341f380.",4
[FLINK-18500][table] Make the legacy planner exception more clear when resolving computed columns types for schema,1
"Revert ""[FLINK-18500][table] Make the legacy planner exception more clear when resolving computed columns types for schema""This reverts commit 1909e933a7b9d6cbbbc7b79b6db62ebce041c136",5
[FLINK-20142][doc] Update the document for CREATE TABLE LIKE that source table from different catalog is supported,1
[hotfix][doc] Include config option TaskManagerOptions#MANAGED_MEMORY_CONSUMER_WEIGHTS into docs.,2
[FLINK-19182][doc] Update docs for intra-slot managed memory sharing.,2
[FLINK-19182][doc-zh] Update translation for intra-slot managed memory sharing.This closes #14079.,5
[FLINK-20147][connector-kafka] Replace lambdas with classes to prevent serialization issues,0
[FLINK-20147][json] Replace lambdas with classes to prevent serialization issuesThis closes #14081.,0
"[FLINK-20171][coordination] Improve error message for Flink process memory configurationCurrently, all configuration failures will result in IllegalConfigurationException from JobManagerProcessUtils or TaskExecutorProcessUtils.The exception error messages do not refer to the process type (JM or TM),it can only become clear from the stack trace.We can wrap main configuration calls with extra try/catch(TaskExecutorProcessUtils::processSpecFromConfig andJobManagerProcessUtils::processSpecFromConfigWithNewOptionToInterpretLegacyHeap)where IllegalConfigurationException is wrapped into another one which states type of the process (JM or TM).Closes #14083.",5
[FLINK-18500][table] Make the legacy planner exception more clear when resolving computed columns types for schema,1
[FLINK-20178][docs] Fix the broken link in mem_migration.zh.mdThis closes #14089.,2
[FLINK-20198][docs] Correct the wrong link in upsert-kafka.zh.mdThis closes #14107.,2
[hotfix][runtime] Fixed wrong HTTP error code used in exception handling of MultipartUploadResource.,1
"[hotfix][runtime] It was possible to traverse the directory of the host through /jobmanager/logs/<path-to-file>.The <path-to-file> had to be modified in a way that '../' referring to the parent folder needed to be replaced by '..%252f'. This enabled traversing the directory structure relative to the ./logs folder, e.g. /jobmanager/logs/..%252f/README.txt would return the content of the README.txt located in the FLINK_HOME folder (assuming Flink's default folder structure).This is fixed now. The passed path is ignored in the same way as it's already done for the TaskManagerCustomLogHandler.",5
[hotfix][runtime] A customized filename can be specified through Content-Disposition that also allows passing of path information which was not properly handled. This is fixed now.We just use the filename instead of interpreting any path information that was passed through a custom filename. Two tests were added to verify the proper behavior:1. a custom filename without path information was used2. a custom filename with path information was usedThe change required adapting the MultipartUploadResource in a way that it is used not as a @ClassRule but as a @Rule instead. This enables us to initialize it differently on a per-test level. The change makes the verification of the uploaded files configurable.,5
[FLINK-20107][network] Make InputChannel.statePersister immutableMotivation: avoid race conditions and programmer errors of not setting the field.,1
[FLINK-20102][docs][hbase] Update HBase connector documentation for HBase 2.x supportingThis closes #14059,1
[FLINK-20102][docs][hbase] Update connectors index for HBase connectorThis closes #14059,5
"[minor] Add rebalance case to DataStreamBatchExecutionITCaseBefore, we were only checking that the shuffle barrier induced by akeyBy() will affect failure recovery",0
"[FLINK-19816] Make job state cleanup dependent on final job resultIn order to avoid race conditions between stopping a Dispatcher and a finishingjob, we now wait on the actual job result to decide whether to clean up the job'sHA data or not. A stopping dispatcher will simply close the DispatcherJobs andcontinue the clean up operation on the job has been terminated.This closes #14055.",4
[FLINK-20028][table-planner-blink] FileCompactionITCase is unstableThis closes #14097,2
[FLINK-20183][python] Fix the default PYTHONPATH is overwritten in client sideThis closes #14108.,0
"[FLINK-18731][table-planner-blink] Fix monotonicity logic of UNIX_TIMESTAMP functionUNIX_TIMESTAMP function has INCREASING monotonicity only if it has empty function arguments, else has NOT_MONOTONIC monotonicity.This closes #12998",1
[FLINK-18731][table-planner-blink] Fix monotonicity logic of UUID functionThis closes #12998,1
[FLINK-19635][hbase] Fix HBaseConnectorITCase.testTableSourceSinkWithDDL is unstable with a result mismatch,3
[FLINK-20129][docs-zh] Create a Chinese download page for all optional sql client componentsThis closes #14074,1
[FLINK-20129][docs] Add raw format link to index.zh.md,2
[FLINK-20143][yarn] Support non-qualified path for Yarn shared libThis closes #14082.,1
[FLINK-20200][table-planner] Fix SQL Hints is not allowed in CREATE VIEW syntaxThis closes #14110,1
"[FLINK-20216][docs][python] Move ""Configuration"" and ""Environment Variables"" under ""Python API"" section",5
[FLINK-20202][python] Add the Check of Unsupported Result Type in Pandas UDAFThis closes #14113.,1
[FLINK-20197] Fix processing time support in FileSinkNow we pass the current processing time from thetimer service of the FileWriter to the context thatis passed in the write() method.This closes #14109.,4
[FLINK-20207][python] Improve the error message printed when submitting the pyflink jobs via 'flink run'This closes #14112.,1
"[FLINK-17159] Use testcontainers for Elasticsearch ITCasesThis should harden the tests because we now use random ports for the ESnodes. I have a suspicion that we had clashes before, which were causingtest instability.Additionally, this allows us to get rid of quite some of our own codefor setting up an ES environment. Once we drop ES5 we can additionallydrop ElasticsearchResource and EmbeddedElasticsearchNodeEnvironment.",4
[FLINK-17424][e2e] Adopt download strategy of Kafka tests in Elasticsearch testsThis closes #14106.,3
[hotfix][e2e] Simplify SQL client e2e testing matrix,3
[FLINK-19946][hbase] Add sink parallelism option for HBase connectorThis closes #13933,1
"[hotfix][docs][table] Fix code example in ""User Defined Functions"" page (#14086)Co-authored-by:  <yandufeng@sinochem.com>",1
[FLINK-17049][table-planner-blink] Support casting of rowsThis closes #14098.,1
[hotfix][table] Allow changing nullability using explicit cast in Table API,1
[FLINK-19949][csv] Unescape CSV format field delimiter characterThe field delimiter should be unescaped when read from a File.This closes #13900,2
[hotfix][csv] Improve CSV format tests and docs,2
[FLINK-20062][hive] ContinuousHiveSplitEnumerator should be lock-freeThis closes #13998,2
[FLINK-20187][table-common] Fix factory discovering is failed when source and sink factories are not implemented in one classThis closes #14105,0
[FLINK-200137][python] Handle the timestamp of elements properly in Python DataStream APIThis closes #14068.,5
"[FLINK-20098] Don't add flink-connector-files to flink-dist, make dependencies explicitWe currently add both flink-connector-files and flink-connector-base toflink-dist.This implies, that users should use the dependency like this:<dependency><groupId>org.apache.flink</groupId><artifactId>flink-connector-files</artifactId><version>${project.version}</version><scope>provided</scope></dependency>which differs from other connectors where users don't need to specify<scope>provided</scope>.Also, flink-connector-files had flink-connector-base as a provideddependency, which means that examples that use this dependency would notrun out-of-box in IntelliJ because transitive provided dependencies willnot be considered.This removes the dependencies from flink-dist which lets users use theFile Connector like any other connector.I believe the initial motivation for ""providing"" the File Connector inflink-dist was to allow us to use the File Connector under the hood inmethods such as StreamExecutionEnvironment.readFile(...). We coulddecide to deprecate and remove those methods or re-add the FileConnector as an explicit (non-provided) dependency again in the future.",1
[FLINK-20232][python] Handle object reuse properly in the operators of Python DataStream APIThis closes #14127.,5
[FLINK-15170][test] Replace System.currentTimeMillis with System.nanoTime in WebFrontendITCaseReplacing System.currentTimeMillis with System.nanoTime ensures that the test case won'tsuffer from jumping clocks as they can occur with System.currentTimeMillis. This shouldfix the observed test instability.This closes #14065.,3
[hotfx][runtime] Add explainations about managed memory fraction contracts in StreamingJobGraphGenerator.This closes #14135.,1
[FLINK-17943][hive] HiveFunctionWrapper#getUDFClass should use Thread.currentThread().getContextClassLoaderThis closes #14136,1
[FLINK-20204][docs-zh][kafka] Translate page 'upsert-kafka connector' into ChineseThis closes #14126,1
[FLINK-20243][docs] Remove useless words in CLI pageThis closes #14138Co-authored-by: xiaozilong <xiaozilong@bigo.sg>,1
[FLINK-20030][network] Rewrite RemoteInputChannel#getInflightBuffersUnsafe to use sequence numbersThis will make this method more stable for changes of the internal state of the RemoteInputChannelwhen timeouting aligned checkpoints.,4
[FLINK-20030][network] Introduce lastBarrierId in RemoteInputChannelThis allows to prevent overwriting of lastBarrierSqn fromBarrierController when processing a newer barrier.,1
[FLINK-17096][table-blink] Mini-batch group aggregation doesn't expire state even if state ttl is enabledThis closes #11830,0
[hotfix][table-blink] Improve state cleanup harness tests for group aggregation,3
[FLINK-20247][config] Disable unaligned timeout for 1.12.,5
[FLINK-20247][config] Disable forcing of unaligned checkpoints for 1.12.,1
[FLINK-20170][json] Fix JSON format loses precision when deserializing decimalsThis closes #14134,5
"[FLINK-20059][table-common] Update Javadoc for ""merge"" method of AggregateFunctionThis closes #14147",1
[FLINK-17470][scripts] Use timeout only if present (osx compat),1
[FLINK-20240] Add execution.runtime-mode setter in StreamExecutionEnvironmentThis closes #14137.,1
[fix] Make copies of the Configuration in the Environments.,5
"[hotfix] Reduce logging verbosity from the checkpoint-related REST handlersBefore the change, everytime the REST UI tried to access the checkpointing statistics, an ERROR message was logged.When using a BATCH job, this leads to log files looking like this:2020-11-13 15:27:38,785 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,788 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,788 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.2020-11-13 15:27:38,793 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.2020-11-13 15:27:38,793 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,797 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.2020-11-13 15:27:38,797 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler [] - Exception occurred in REST handler: Checkpointing is not enabled for this job (6df1c639d1904f8b7a54cf6a649ab567).2020-11-13 15:27:38,802 ERROR org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler [] - Exception occurred in REST handler: Checkpointing has not been enabled.With this change, these log messages are surpressed.",2
[FLINK-20165][CI] Update test docker imageRelevant version changes:adoptopenjdk-11-hotspot: 11.0.7+10-2 --> 11.0.9+11.2-3openjdk-8-jdk: 8u242-b08-0ubuntu3~16.04 --> 8u275-b01-0ubuntu1~16.04docker.io: 18.09.7-0ubuntu1~16.04.5 --> 18.09.7-0ubuntu1~16.04.6,2
[hotfix][yarn] Provide .out files in debug logs as well,2
[FLINK-20239][docs] Confusing pages: Hive Read & Write and Hive Streaming,5
[hotfix][docs] Clean up hive doc headersThis closes #14145,2
[FLINK-20276][connector file] Stream formats should apply decompressorsThis aligns the behavior with the legacy FileInputFormat which applied the decompressors automatically.,2
[hotfix][tests] Decouple atomic file writing from temp file filters.Atomic file writing (write to temp file and publish) currently relies on the optional temp file filteringin the file source. This couples basic test infrastructure to a specific feature. Basic tests fail when thatfeature is deactivated.Moving the temp files out of the test data directory decouples that.,5
[FLINK-20081][connector/common][source] The SourceCoordinator should fail the job instead of killing JM when it catches an unhandled exception.,0
[FLINK-20081][connector/common][source] Fix the executor notifier to let the handler run in main thread when handling exception from the callable.This closes #14030,1
[refactor] Add ManuallyTriggeredScheduledExecutorService from 'flink-runtime' to 'flink-test-utils-junit'.,3
[refactor] Consolidate code for 'ManuallyTriggeredScheduledExecutor' between test-utils and runtime tests.,3
[FLINK-20261][connector source] Enumerators do not assign splits to unregistered (failed) readers.,0
"[FLINK-20266][runtime] Replace dedicated thread pool in ComponentClosingUtils with use of 'FutureUtils.orTimeout()'This removes extra (non-daemon) threads, which were previously keeping the threads alive.",4
[hotfix][runtime] Adjust signatures of ComponentClosingUtils to use Duration rather than long milliseconds.This makes it more consistent with the effort to introduce type safe types and signatures for time.,1
[hotfix][runtime] Minor reorg in ComponentClosingUtils to avoid some wrapping.,0
[FLINK-20275][python] Fix the delimiter of the dependencies of Python DataStream APIThis closes #14159.,5
[FLINK-20211][doc] Use <ClusterId>-rest to get the external ip addressThis closes #14130.,1
[FLINK-20150][debezium-avro] Add documentation for the debezium-avro-confluent formatThis closes #14151,5
[FLINK-18452][table-runtime-blink] Fix StateMigrationException because RetractableTopNFunction#ComparatorWrapper might be incompatibleThis closes #14150,1
"[hotfix][FLINK-20059][table-common] Update Javadoc for ""merge"" method of TableAggregateFunction",1
"[FLINK-20229][docs] Remove the duplicate ""for"" word in security-kerberos.md pageThis closes #14124",1
[FLINK-20158][connectors/kafka] Add ResultTypeQueryable interface to KafkaSource,1
[FLINK-20180][fs-connector][translation] Add chinese File Sink docsThis closes #14077.,2
[FLINK-20283][python] Provide a meaningful exception message when managed memory fraction of Python worker process is invalidThis closes #14161.,1
[hotfix] Fix the pretty name of the flink-connector-test-utils projectMake this consistent with the naming pattern of other modules.,1
[hotfix] Use 'ExecutorThreadFactory' for Source Coordinator worker threads.This deduplicates some code.,1
[FLINK-20223][runtime] (part 1) Add the user code classloader to the Operator Coordinator Context,1
[FLINK-20223][runtime] (part 2) Set user code classloader as context class loader for SplitEnumerator creation and threadCo-authored-by: Jiangjie (Becket) Qin <jiangjie.qj@alibaba-inc.com>  - This moves the instantiation of the SplitEnumerator out of the constructor to prevent double-instantiation  - Add context class loaders to creation and coordinator thread  - Class-loading and SplitEnumerator instantiation is purely handled in the SourceCoordinator and does not leak    into RecreateOnResetOperatorCoordinator.,1
[FLINK-19864][tests] Fix unpredictable Thread.getState in StreamTaskTestHarness due to concurrent class loading,3
[FLINK-19878][table-planner-blink] Fix WatermarkAssigner shouldn't be after ChangelogNormalizeThis closes #14154,4
[FLINK-20145][checkpointing] Fix FileBasedBufferIterator#read.,5
"[FLINK-20145][network] Double-check if gate still has priority buffer when enqueuing in UnionInputGate.Since notification is not atomic in respect to gate enqueuing, priority event already polled by task thread when netty enqueues the gate.",2
"[FLINK-20145][task] Ignore double notification in StreamTwoInputProcessor.Currently, when a priority event is enqueued as the first event, it triggers both a priority and availability notification through respective futures.If the priority event is processed through CheckpointedInputGate#processPriorityEvent, the InputProcessor pulls on an empty gate.While we could try to avoid the double notification, there are a few race condition that may lead to no notifications and blocked application.It's much easier to simply allow double notification and ignore it when they are not useful.Note that StreamOneInputProcessor and StreamMultipleInputProcessor are already doing it.",1
[FLINK-20145][tests] Add ITCases for UC with union gates and multiple input operators.Unaligned checkpoints lacked coverage on these cases.Note that the extracted test base will be also used for rescaling tests in an upcoming PR.,3
[FLINK-20262] Building flink-dist docker image does not work without python2,1
[FLINK-20293] Remove the useless constructor of ContinuousFileMonitoringFunction,2
[FLINK-18279][docs] Simplify Table OverviewThis closes #14053,2
[hotfix][json] Consider nullability for Debezium ingestion timestamp,5
[FLINK-20072][docs] Add documentation for FLIP-107This closes #14156.,2
[hotfix][table-common] Improve SupportsWatermarkPushDown JavaDocs,2
[FLINK-20296][training-docs] remove obsolete content about keyBy(string),4
[FLINK-20193][runtime] Catch all uncaught Throwables from the SplitEnumerator in the SourceCoordinator.This also makes the error message in CoordinatorExecutorThreadFactory clearer.This closes #14104,0
[hotfix][runtime] Replace manual byte[] reading with DataInput.readFully(),5
[hotfix][runtime] Minor style warning cleanups in SourceCoordinatorContext,4
[hotfix][core] Fix JavaDocs for TemporaryClassLoaderContext,2
[FLINK-19325][checkpointing] Avoid flushing while writing metadata.The extra flushing causes a performance degrade without any real benefit as partial checkpoints are neither defined nor usable.,1
[FLINK-20278][Python] Throw a meaningful exception if the Python DataStream API job executes in batch modeThis closes #14164.,5
[FLINK-20214][k8s] Fix the unnecessary warning logs when Hadoop environment is not setThis closes #14132.,1
[FLINK-19630][hive][doc] Make bundled hive jar the recommended way to add dependenciesThis closes #14131,1
[FLINK-19653][hive] Reduce our dependency on hive runner for testsThis closes #14123,3
[FLINK-19175][table-planner] Tests in JoinITCase do not test BroadcastHashJoin,3
[FLINK-20035][tests] Fix wrong config key in JobGraphRunningUtilThis closes #14149.,1
[FLINK-20285][runtime] LazyFromSourcesSchedulingStrategy checks vertex's right before scheduling it,2
[hotfix] Fix the SingleThreadFetcherManager to get the running fetchers correctly.,1
[FLINK-20194] Change SourceReaderBase.onSplitFinished() to take a map of SplitId -> SplitState.,5
[FLINK-20194] Fix Kafka offset commit to coorectly handle the following cases:1. The SplitFetcher has exited.2. The offsets to be committed is empty.3. The offsets commit for finished splits.,5
[FLINK-19996][kafka] Add IT case for Debezium + Kafka + temporal joinThis closes #14080,1
[FLINK-20308][docs] Fix wrong links in some Chinese markdown filesThis closes #14190,2
[FLINK-19940][task] Improve naming of multi-input transformation,1
[hotfix][table-common] Improve error messages for connector hints,0
[FLINK-20186][table-common] Fix error message for conflicting factoriesThis closes #14176.,5
"[FLINK-17691] Truncate transactional.id in FlinkKafkaProducerBefore, it could happen that the id is too long, which would cause Kafkato throw.",1
[FLINK-20235][hive][parquet] Parquet lack additional dependencies after bumpingThis closes #14189,1
[hotfix][runtime] Replace dangling inline JavaDoc comment by regular comment,2
[FLINK-20270][refactor] Initialize reader in SourceOperator at an earlier point.That way we can access the reader during task setup and use it and its propertiesduring initialization of the SourceStreamTask.,5
[FLINK-20270][runtime] Add support for ExternallyInducedSource based on FLIP-27 to SourceOperatorStreamTask.,1
[hotfix][core] Extend JavaDocs for ExternallyInducedSourceReader.,2
[FLINK-18027][table] Improve ROW constructor documentationThis closes #14101.,2
[FLINK-20307][doc] Strength the document about temporal table join syntax,2
[FLINK-19415][hive][docs] Move Hive document to Table & SQL Connectors from Table API & SQLThis closes #14194,2
[FLINK-20271][table-runtime-blink] Fix ArrayIndexOutOfBounds for RetractableTopNFunctionThis closes #14173,1
[FLINK-20272][table-runtime-blink] Fix wrong result for TopN when removing records out of TopNThis closes #14173,4
[FLINK-20282][runtime] Improve error message for invalid managed memory fraction.,0
[FLINK-20282][runtime] Add logs for managed memory use cases whose consumer weights are 0 or missing.This closes #14163.,1
[FLINK-19535][runtime] Add a failed flag in the OperatorCoordinator to avoid failing the job multiple times.This closes #14158,0
"[FLINK-20222][checkpointing] Operator Coordinators are reset with null state when no checkpoint or state available.This includes the following cases:  - JobManager/Scheduler/Coordinator failover happens before the first checkpoint completed.  - Coordinator has not stored any state in the checkpoint.For both cases, this is useful to signal to the coordinators that a reset-to-checkpoint happened, even ifthey do not have checkpointed state to restore.",1
[FLINK-18988][table] Continuous query with LATERAL and LIMIT produces wrong resultThis closes #13291.,0
[FLINK-20267][runtime] The JaasModule didn't support symbolic links. This is fixed now.Tests were added to verify the change.This closes #14171.,4
[FLINK-19188][examples-table] Add a new streaming SQL exampleThis closes #13413.,1
[FLINK-20256][table-common] Allow errors when extracting the data type a DataViewThis closes #14183.,5
[FLINK-19398][connectors/hive] Fix the failure when creating hive connector from userclassloaderThis closes #14094,1
[hotfix][javadocs] Fix typo in RichFunctionThis closes #14148,1
[FLINK-20291][table][filesystem] Optimize the exception message of FileSystemTableSink when missing format dependenciesThis closes #14198,5
[FLINK-20306][table-planner-blink] Throw a meaningful exception when accessing temporal table as of constant timestampThis closes #14200,2
[FLINK-20295][table][fs-connector] Table File Source lost data when reading from directories with JSON formatThis closes #14192,5
"[FLINK-19775][tests] Fix SystemProcessingTimeServiceTest.testImmediateShutdownThe test SystemProcessingTimeServiceTest.testImmediateShutdown was unstable because thetest case testShutdownServiceUninterruptible was not properly clearing the isInterruptedflag it sets during its run. Consequently, the subsequent execution of testImmediateShutdowncould fail with an InterruptedException.This closes #14155.",0
"[FLINK-20310][doc] Add documentation for Debezium, Canal, Raw support for Filesystem connectorThis closes #14191",5
[FLINK-20191][docs] Add documentation for FLIP-95 ability interfacesThis closes #14111.,2
[FLINK-20333][python] Fix the issue that metaspace OOM will be thrown after submitting PyFlink UDF jobs multiple times to the standalone clusterThis closes #14205.,2
"[FLINK-20328][tests] Fixed buffer calculation in UnalignedCheckpointITCase.Ultimately, it was one buffer missing.",0
[hotfix][task] Fix checkstyle/IDE warnings in BatchTask and TempBarrier,2
[FLINK-19852][task] Reuse TempBarrier memory between iterations,1
[hotfix][docs] Update YARN config docs,2
[hotfix][table-planner-blink] Enable idle state cleanup for ChangelogNormalize operator,1
[FLINK-19795][table-blink] Fix Flink SQL throws exception when changelog source contains duplicate change eventsThis closes #14160fixup docsaddress review comments.update commentfix,0
[FLINK-20317][docs] Update SQL Format overview page (#14213),5
[hotfix][docs] The default value column of sink.partition-commit.success-file.name should be _SUCCESSThis closes #14031.,2
"[FLINK-20153] Add documentation for BATCH execution modeThis adds documentation for the new `BATCH` execution mode. We alsoexplain `STREAMING` execution mode because there is no central page thatexplains the basic behavior, so far.",1
[FLINK-20153] Add important considerations in execution mode docs,2
[FLINK-20153] Describe time behaviour in execution mode docs,2
[FLINK-20153] Add glossary entry for runtime execution mode,1
"[minor, doc] Add note.html include for easy note boxesIt can be used like this:{% capture my_note %}This is my note body, which can also include Markdown. Alternatively,you can write a non-markdown text straight in the include tag.{% endcapture %}{% include note.html content=my_note %}",1
[FLINK-20302] Recommend DataStream API with BATCH execution mode in DataSet docs,2
[hotfix] Shade avro in sql-avro jars,0
[FLINK-20175] Avro Confluent Registry SQL format does not support adding nullable columnsWe set null as the default value for nullable logical types. This makes it possible to add nullable columns without breaking backwards compatibility.,4
"[FLINK-19997] Implement an e2e test for sql-client with Confluent Registry Avro formatThe e2e test uses testcontainers to run Kafka, Schema Registry and Local Flink cluster. Testcontainers use docker underneath, therefore it is required to run the tests.The commit adds a helper FlinkContainer that wraps a local flink distribution and builds a temporary docker image on top of it. It exposes common tasks such as e.g. submitting sql job, it backs up the logs in case of failure etc.This commit introduces a KafkaContainerClient, which uses Kafka client on top of a given KafkaContainer to perform common tasks such as creating topics or reading and writing records using given Kafka Serializers.This closes #14085",1
[FLINK-20309][tests] Improved logging in UnalignedCheckpointITCase.,2
"[FLINK-20309][tests] Ignore splits that are re-added in UnalignedCheckpointITCase.Splits are only re-added when a particular task failed but has not been checkpointed yet. In this test setup, tasks are always checkpointed before. This avoids FLINK-20290, which may duplicate splits.Also this commit increases NETWORK_REQUEST_BACKOFF_MAX to avoid PartitionNotFoundExceptions.",1
[FLINK-20284][python] Port Grpc SharedResourceHolder class to flink-python moduleThis closes #14217.,2
"[FLINK-20284][python] Change default DESTROY_DELAY_SECONDS to 0For PyFlink jobs, the underlying netty server releases resources asynchronously in a separate thread when job finished.As PyFlink classes runs in user classloader which will be closed after job finished. ClassNotFoundError may be thrown andappear in the log. It doesn't affect the correctness, however, is very confusing for users.This commit changes the DESTROY_DELAY_SECONDS to 0 (original is 1) to improve this situation.This closes #14217.",1
[FLINK-20322][table-planner-blink] Rename union-all-as-breakpoint configuration and change the default value,4
[FLINK-20314][table-planner] Add rule to remove empty FlinkLogicalCalc,2
[FLINK-19998] Remove site.baseurl from {% link %} tags,2
[hotfix] Fix typo in MiniCluster classThis closes #14211,5
Update version to 1.13-SNAPSHOT,5
[FLINK-20184][doc] update hive streaming read and temporal table documentThis closes #14182,2
"[FLINK-20316][docs][table] Update the ""Deduplication"" section of ""Query"" pageThis closes #14214",1
[FLINK-20331][checkpointing][task] Don't fail the task if unaligned checkpoint was subsumed,0
[FLINK-20362][docs] Fix broken link in sourceSinks.zh.mdThis closes #14226.,2
[hotfix][docs] Add the missing datastream_execution_mode.zh.md,5
"[FLINK-17424][e2e] Further stabilize Elasticsearch downloadsThis aims to solve different issues while downloading Elasticsearchbinaries. We use wget (specialized in downloading) in the hope formore stability. Furthermore, we implement a retry logic ourselveswhich includes the successful tar archive extraction in case ofcorrupt downloads.This closes #14202.",4
[FLINK-19982][streaming] Change log level when CollectSinkFunction receives invalid requests for future investigationThis closes #14188,1
[FLINK-20365][python] The native k8s cluster could not be unregistered when executing Python DataStream jobs in attach modeThis closes 14232.,5
[FLINK-20245][hive][docs] Document how to create a Hive catalog from DDLThis closes #14227,2
[hotfix][kafka] Fix val declaration in scala code doc exampleCloses #13947.,2
[hotfix][table][docs] Fix table systemFunction lag description.This closes #14115.,5
[hotfix][docs] Fix typo in event_timestamps_watermarks.mdThis closes #13588.,2
[hotfix][table][docs] Fix typo in System (Built-in) Functions pageThis closes #12716.,1
[hotfix][connectors] Fixed typo in Source.java docsThis closes #14026.,2
"[minor,docs] Clarify *final results* in DataStream execution mode docs",2
[FLINK-20342][docs] Move ops/deployment/Overview to ops/Overview,4
[FLINK-20342][docs] Change Cluster & Deployment into Resource Providers,1
[FLINK-20342][docs] Renamed ops/deployment into ops/resource-providers,1
[FLINK-20342][docs] Reordered items in nav bar & fixed broken links from renaming ops/deployment into ops/resource-providers,1
[FLINK-20342][docs] Group ssl and kerberos documentation page under security,2
[FLINK-20342][docs] Move Plugins above File Systems,5
[FLINK-20342][docs] Split Deployment & Operations into Deployment and Operations,2
[FLINK-20342][docs] Move memory configuration from ops to deployment,5
[FLINK-20342][docs] Move plugins under filesystems,5
[FLINK-20342][docs] Move cli from ops to deployment,4
[FLINK-20342][docs] Move repls from ops to deployment,4
[FLINK-20342][docs] Remove config.md from ops,5
[FLINK-20342][docs] Group debugging topics under monitoring/debugging,0
[FLINK-20342][docs] Group monitoring guides under monitoring/monitoring,2
[FLINK-20342][docs] Move ops below deployment in navigation bar,4
[FLINK-20342][docs] Move monitoring/monitoring and monitoring/debugging to ops/monitoring and ops/debugging respectively,0
[FLINK-20342][docs] Change order in ops1. State2. Production readiness checklist3. Upgrading Apps,4
[FLINK-20342][docs] Split monitoring/metrics.md into monitoring/metrics.md and deployment/metric_reporters.md,2
[FLINK-20342][docs] Move monitoring/metrics.md to ops/metrics.md,4
[FLINK-20342][docs] Move monitoring/historyserver.md and monitoring/logging.md to deployment/*This removes effectively the Monitoring & Debugging entry.,1
"[FLINK-20342][docs] Move deployment/logging, historyserver and external_resources under advanced",2
[FLINK-20342][docs] Group standalone resource providers under resource-providers/standalone,1
[FLINK-20342][docs] Use fa-cogs as icon for Operations,1
[FLINK-20342][docs] Moce production readiness checklist and upgrading applications to back of Operations section,2
[FLINK-20342][docs] Move ops/monitoring/rest_api.md to ops/rest_api.md,4
[FLINK-20342][docs] Rearrange the order of resource providers,1
"[FLIN-20342][docs] Split up jobmanager_high_availability.md into ha/index.md, ha/kubernets_ha.md and ha/zookeeper_ha.md",2
[FLINK-20342][docs] Move deployment/config.md and deployment/memory/index.md to position 3 and 4,5
[FLINK-20342][docs] Add redirects for moved pagesThis closes #14223.,4
[FLINK-20351] Correct the logging of the location of a task failure on the JMThis commit logs the TaskManagerLocation.toString instead of the LogicalSlot.toStringwhen logging an Execution failure.This closes #14225.,0
[FLINK-18545][configuration] Introduce `pipeline.name` to allow users to specify job name by configuration,5
[FLINK-18545][configuration] Allow users to specify job name by configuration in ExecutionEnvironment,5
[FLINK-18545][python] Specify job name by `pipeline.name` for flink-python,2
[FLINK-18545][table] Specify job name by `pipeline.name` for sql job,2
[FLINK-20241][hive] Improve exception message when hive deps are missing on JM/TMThis closes #14203,1
[FLINK-20327][doc] The Hive's read/write page should redirect to SQL Fileystem connectorThis closes #14231,2
"[FLINK-20383][runtime] Fix race condition in notification.Notification happens outside of lock, so between non-null check and actual notification, readView could have been released.",0
[fix] Rename method in BroadcastStream,0
[fix] Field renaming in BroadcastConnectedStream,0
[FLINK-20304] Introduce the BroadcastStateTransformation.So far the Broadcast State pattern was a TwoInputTransformation.This did not allow for special handling when it comes totranslating it for Batch or Streaming execution. This commitintroduces a special transformation just for this.This closes #14216.,1
[FLINK-20304] Create base AbstractTwoInputTransformationTranslator.This base class factors out the common code between theTwoInputTransformationTranslator annd theBroadcastStateTransformationTranslator.,1
[FLINK-20366][table-planner-blink] ColumnIntervalUtil#getColumnIntervalWithFilter should consider constant predicate,1
[hotfix][docs] Document classloader shutdown hooks,1
[FLINK-20343] Add new Deployment overview page,1
[FLINK-20349][table-planner-blink] Fix checking for deadlock caused by exchange,4
"[FLINK-20389][tests] Fix UnalignedCheckpointITCase to work with unassigned splits.The test currently assumed that when induced failures happen, splits have been assigned to readers, which works fine for the planned snapshot-failure-recovery sequence.However, when unexpected failures happen, this assumption does not necessarily hold resulting in failures that may impede investigations.The test would still fail as the number of failures would be different from the expected numbers of failures, but investigation can focus on the unexpected failure then.",0
[FLINK-20384][doc] Fix Wrong Links in Some Chinese Docs,2
[hotfix][runtime] Expand JavaDocs (and reorder methods) in OperatorCoordinator.,1
"[hotfix][tests] Pull nested test suites out of CheckpointIDCounterTest and follow standard test-base pattern.That makes the tests consistent with the common practice in Flink and also ensures that the tests arepicked up by the Maven/Surefire build. Previously, these tests were not executed during a Maven build.",3
[FLINK-20396][checkpointing] Checkpoint Coordinator exposes the checkpoint ID of the restored checkpoint for partial state restores.This closes #14255,2
[FLINK-20344][dist] Change example value for default savepoint path flink-conf template.This makes it clearer that we recommend to have separate checkpoint and savepoint directories.This closes #14215,1
[FLINK-20391] Set FORWARD_EDGES_PIPELINED for BATCH ExecutionModeThis closes #14249,1
[hotfix][tests] Introduce TestingSchedulerNG implementation,3
"[FLINK-20382][runtime] Fail hard when JobMaster cannot start scheduling of a jobThis commit checks whether the SchedulerNG.startScheduling method failed. If this isthe case, then we fail hard by terminating the process.This closes #14251.",0
[hotfix] Expose FatalExitExceptionHandler's exit code via EXIT_CODE,0
[hotfix][docs] Update ZH variant of deployment/index,5
[FLINK-20347] Rework YARN resource provider pageThis closes #14238,1
[FLINK-20397][checkpointing] Pass checkpointId to OperatorCoordinator.resetToCheckpoint(),1
[FLINK-20396][checkpointing] Add a 'subtaskReset()' method to the OperatorCoordinator.This closes #14256,1
[hotfix][docs] Fix typo,2
[hotfix][javadocs] Fix typo,2
[hotfix][fs-connector] Remove unused state serializer from FileWriter,2
[hotfix][fs-connector] Fix the typo in the FileSinkITCase,2
"[FLINK-20337] Let StatefulSinkWriterOperator load StreamingFileSink's stateTo allow stateful migration from `StreamingFileSink` to `FileSink` welet the `StatefulSinkWriterOperator` load the `StreamingFileSink`'sstate (""bucket-state"") if it exists.",2
[FLINK-20337] Extend StatefulSinkWriterOperator Javadoc,2
[FLINK-20337] Let FileSink restore state from StreamingFileSinkThe FileWriterBucketStateSerializer is bumped past version 2 to allow itto restore the same old versions as BucketStateSerialize (fromStreamingFileSink).,2
[refactor] Factor test data generator/resolver out of BucketStateSerializerTestWe want to reuse this code for the new FileSink migration test as well.,3
[FLINK-20337] Add migration test for deserializing existing StreamingFileSink state with FileSink serializerThis re-uses the generated test data from BucketStateSerializerTest.,3
[refactor] Factor common testing code out of FileSinkITBaseWe want to reuse this code for the new FileSink migration test as well.,3
[FLINK-20337] Add ITCase for migrating from StreamingFileSink to FileSink,2
[refactor] Move FileSink migration tests to flink-connector-files,2
"[hotfix][docs] Change ""latter"" to ""later""",4
[FLINK-20410] Retry querying for schema in the schema registry e2e test.,3
[FLINK-20287][docs] Add documentation of how to switch memory allocator in Flink docker imageThis closes #14248.,1
"[FLINK-20413][runtime] Sources return splits in ""resetSubtask()"", rather than in ""subtaskFailed()""",0
[hotfix][connector files] Add some debug logging to file split enumerator.,2
[hotfix][build] Remove outdated CI logger config entries,5
[FLINK-20118][file connector] Introduce TaskManager and JobManager failures in FileSourceTextLinesITCaseThis closes #14199,2
[FLINK-19082][doc] Add docs for temporal table and temporal table join,2
[FLINK-20326][doc] fix broken links to define LookupableTableSource in temporal table pageThis closes #14152,1
[FLINK-20381][yarn] Restore yarn-session.sh -id argumentThis closes #14264,2
"[FLINK-20357][docs] Split HA documentation up into a general overview and the specific implementationsThis commit splits the HA documentation up into a general overview and the specific implementations:* ZooKeeper HA services* Kubernetes HA servicesMoreover, this commit moves resource-provider specific documentation to the respective resource-providerdocumentation.This closes #14254.",2
"[hotfix][k8s] Specify which characters are allowed for kubernetes.cluster-idOnly lowercase alphanumeric characters, ""-"" or ""."" are allowed.",1
[hotfix] Fix incorrect link tag,2
[FLINK-19969] CLI print run-application help msgThis closes #14157.,1
[fix] Fix GenericCLI.targetOption description msg,1
"[refactor] Delegate option printing fully to CLIsBefore, the ""-t"" option was hardcoded in CliFrontendParser although thatoption comes from GenericCLI.Now, print printHelpForRunApplication() has the same signature andbehaviour as the other printHelp...() methods.This lessens coupling but introduces the problem that we now filtermanually on the CLIs that support application mode in CliFrontendParser.If we really wanted we could add a ""supportsApplicationMode()"" flag toCLIs but I think that would be pushing it a bit.",1
[FLINK-20274][docs-zh] Translate page 'testing' into ChineseThis closes #14224,1
[FLINK-20426][docs] Fix broken links after Hadoop page removalThis closes #14272,4
"[hotfix][docs] Fix various broken links in the docsI used this to identify broken links in the zh.md files:git grep -E ""[^z][^h]\.md "" -- '*.zh.md'",2
[FLINK-20298][docs] Replace usage of site.baseurl in flink documentation,2
[FLINK-20423] Fix remaining occurences of site.baseurlThis closes #14235,5
[FLINK-20423][hotfix] Fix wrong link to html instead of md,2
"[FLINK-20444][runtime] Chain YieldingOperatorFactory to new sources.For legacy sources, we had to disable chaining because of incompatible threading models.New sources are working fine however and it would give some users massive performance improvements.",1
"[FLINK-20418][core] Fixing checkpointing of IteratorSourceReader.IteratorSourceReader fails checkpointing when assignment has not yet happened with NPE.Furthermore, if the last element of a split has been pulled just before checkpointing, then a split would be created with (to+1, to) leading to an IllegalArgumentException: 'from' must be <= 'to'.",1
[hotfix] Correct the description of security.kerberos.krb5-conf.path,5
[FLINK-20073][doc] Add native k8s integration to kerberos setup documentationThis closes #14241.,2
"[FLINK-20441] Deprecate CheckpointConfig.setPreferCheckpointForRecovery and .isPreferCheckpointForRecoveryCheckpointConfig.setPreferCheckpointForRecovery(true) can lead to data loss and duplicate outputs. Hence,it is no longer recommended to use.",1
[FLINK-20442][python][legal] Updated flink-python NOTICEThis closes #14282.,2
[FLINK-20054][formats] Fix ParquetInputFormat 3 level List handlingThis closes #13994,0
[FLINK-20315][doc] Optimize the compaction document to warn users about backpressureThis closes #14285,1
[FLINK-20221] DelimitedInputFormat does not restore compressed splitsCloses #14174,2
[FLINK-20428][test] Fix the unstable test ZooKeeperLeaderElectionConnectionHandlingTest#testConnectionSuspendedHandlingDuringInitializationThis closes #14268.,5
[FLINK-20055][configuration] Add Datadog 'apikey' to list of sensitive options,5
[FLINK-19989][python] Add collect operation in Python DataStream APIThis closes #13983.,5
[FLINK-20371][docs] Add docs for outer interval joinsThis closes #14230,2
"[FLINK-20436][table-planner-blink] Simplify ExecNode: Remove ""Planner"" type parameter & Remove the default implementation into ExecNodeBase",4
[FLINK-19527][Doc]Flink SQL Getting StartedThis closes #14003,1
[FLINK-16443][checkpointing] Make sure that CheckpointException are also serialized in DeclineCheckpoint.,1
"Revert ""[FLINK-14076] Ensure CheckpointException can be deserialized on JobManager""This reverts commit 2bcf5094",4
[FLINK-20292][doc] Improve the document about transforming connector/format SPI resource filesThis closes #14229,2
[FLINK-19984][core] Add TypeSerializerTestCoverageTestThis verifies that newly added TypeSerializerS have tests based onSerializerTestBase and TypeSerializerUpgradeTestBase.,3
[FLINK-19636][coordination] Refactor matching logic to make it re-usable,1
[FLINK-19636][coordination] Add DeclarativeSlotPool,1
[FLINK-19715][coordination] Fix inefficiencies in assignment of excess resources,0
[FLINK-20467][python][docs] Fix the example in Python DataStream API documentationThis closes #14297.,2
"[FLINK-19725][runtime] Increased the timeout for the instantiation of the akka logger.Occasionally, we had failing builds due to the Slf4Logger not being instantiated in time. The default setting is 5s which might be too low in cases where the VM the tests are running on is not processing fast enough to have the logger instantiated. For now, we're gonna try to work around it by increasing the timeout limit to 30s.This closes #14290.",1
[FLINK-20464] Some Table examples are not built correctly,2
[FLINK-20437][table-planner-blink] Move the utility methods in ExecNode into ExecNodeUtil,4
[FLINK-20437][table-planner-blink] Port ExecNode to Java,2
[hotfix] Speed up flink container creation in testcontainers,3
[FLINK-20432] Add timeouts to SQLClientSchemaRegistryITCaseThis closes #14275,1
[FLINK-20078][coordination] Factor out an ExecutionGraph factory method for DefaultExecutionTopology,2
[FLINK-20078][hotfix][coordination] Use executionGraph.getTotalNumberOfVertices in DefaultExecutionTopologyCo-authored-by: Zhu Zhu <reedpor@gmail.com>This closes #14020.,2
[FLINK-19863][test] Fix SQLClientHBaseITCase.testHBase failed with process timeoutThis closes #14274,0
"[FLINK-20469][minicluster] Enable TaskManager start and terminate in MiniClusterCurrently we expose startTaskManager/terminateTaskManager only in internal TestingMiniCluster.Nonetheless, they are useful methods to implement IT cases similar to E2E tests.This closes #14300.",3
[hotfix][docs] Fix broken links in gettingStarted.zh.md,1
[hotfix][docs] Fix broken links in gettingStarted.zh.md,1
[FLINK-20168][docs-zh] Translate page 'Flink Architecture' into Chinese.This closes #14088,2
[FLINK-19687][table] Support JSON_EXECUTION_PLAN for the explain resultThis closes #14165,5
[FLINK-20455][oss][legal] Move license to META-INF directory,5
[FLINK-20455][influxdb][legal] Inline notice,5
[FLINK-20455][table][legal] Exclude icu4j LICENSE file,2
[FLINK-20455][build][legal] Bundle LICENSE/NOTICE in various deployed jars,2
[FLINK-20455][build] Move notice checking into separate class,4
[FLINK-20455][build][legal] Add jar license checker,1
[FLINK-20429][kafka] Using proper watermark interval in KafkaTableITCase#testKafkaTemporalJoinChangelog testThis closes #14267,3
[FLINK-20486][hive] Hive temporal join shouldn't require a minimal 1h monitor intervalThis closes #14310,5
[hotfix][hbase][legal] Remove invalid NOTICE entries,4
[FLINK-18897][docs] Add document for maxwell json formatThis closes #14245,5
[FLINK-20273][table/kafka] Fix the Kafka 'round-robin' partitioner behaviour when message keys are specifiedThis closes #14320,0
Update japicmp configuration for 1.12.0,5
[FLINK-20493] Increase timeouts for building FlinkContainer images,2
[hotfix][docs] Improve the filesystem connector docThis closes #14325,2
[FLINK-20510][conf][log4j] Enable monitorInterval by default,0
[FLINK-20404][zookeeper] Disable JMX log4j integration,2
[FLINK-20250][table-runtime] Fix NPE when invoking AsyncLookupJoinRunner#close methodThis closes #14207,1
[FLINK-20300] Add Flink 1.12 release notesThis closes #14195,3
[FLINK-20485][table] Wrap data views into a lazy binary format,5
[FLINK-20485][table-runtime] Reuse internal data structures in ExternalSerializerThis closes #14309.,5
[hotfix][WebUI] Consistent time format of Taskmanager tab,0
[FLINK-20372][docs][kafka] Update Kafka SQL connector page to mention 'properties.*' optionsThis closes #14276,5
[FLINK-20419][table-planner-blink] Avoid dynamic partition grouping if the input defines collationThis closes #14294,2
[FLINK-20419][hive] Add tests for dynamic partition with order byThis closes #14294,3
[hotfix][docs] Add 1.12 to the list of previous docs,2
[FLINK-20534] Add Flink 1.12 MigrationVersion,2
[FLINK-20490][table-planner-blink] Don't share inputs between FlinkPhysicalRel and ExecNodeThis closes #14311,2
[FLINK-20355][docs] Move how to create Python Docker image to standalone/docker.md,2
[FLINK-20355][docs] Add new native K8s documentation pageRemove old native_kubernetes.md filesThis closes #14305.,2
"[FLINK-20468][minicluster] Enable leadership control in MiniCluster to test JM failoverCurrently, there is no easy way to test how JM failover (revoke and grant leadership)affects other features with the MiniCluster and its testing resource rule.The custom HA services can be provided to the TestingMiniCluster but there is no simple HA servicesto support revoking and granting leadership with a valid in-memory checkpoint store.Providing a way to enable such embedded HA services for the MiniCluster out of the box allows to implement IT cases similar to E2E tests.This closes #14301.",3
[FLINK-20353][docs][logging] Update logging documentation,2
"Rervert ""[FLINK-20534] Add Flink 1.12 MigrationVersion""This revert the commit d7598631b8da6d9173ec4f1e559af501c0c1dee8.",4
[FLINK-20525][python] Fix StreamArrowPythonGroupWindowAggregateFunctionOperator incorrect handling of rowtime and proctime fieldsThis closes #14327.,1
[FLINK-20500][upsert-kafka] Fix unstable UpsertKafkaTableITCase.testTemporalJoinThis closes #14330,3
[FLINK-20470][json] MissingNode can't be casted to ObjectNode when deserializing JSONThis closes #14316,5
[hotfix][elasticsearch] Fix javadoc of Elasticsearch6ConfigurationThis closes #14269,5
[FLINK-20508][python] Introduce PythonStreamGroupTableAggregateOperatorThis closes #14322.,1
[FLINK-20543][docs] Fix column name typo in upsert kafka docsThis closes #14343,2
[FLINK-20511][table-planner-blink] Deprecate the classes in scala `nodes.exec` packageThis closes #14335,1
[FLINK-20482][python] Support General Python UDF for Map Operation in Python Table APIThis closes #14317.,1
[FLINK-20550][docs] Fix savepoint directory option key,0
[FLINK-20456][docs] Remove negative language from index,4
[FLINK-20456][docs] Make dynamic tables sound less 'academic',1
[FLINK-20456][docs] Remove deprecated APIs from time attributes page and put event time first,4
[FLINK-20456][docs] Reorder temporal table and join pages,2
[FLINK-20456][docs] Simplify temporal table definition,5
[FLINK-20456][docs] Simplify streaming joins,2
[FLINK-20551][docs] Remove legacy planner from index and common conceptsThis closes #14292,4
"Revert ""[FLINK-20551][docs] Remove legacy planner from index and common concepts""This reverts commit 69dc0a297726adb1bc2eb49bd2f52e9d490e53f9.",5
[hotfix] Redirect temporal tables to legacy joins,0
[FLINK-20492][runtime] SourceOperator.dispose() should close the source reader.,1
[FLINK-20483][python] Support Pandas UDF for Map Operation in Python Table APIThis closes #14347.,1
[FLINK-20514][python] Introduce StreamExecPythonGroupTableAggregateRule and StreamExecPythonGroupTableAggregateThis closes #14331.,2
[FLINK-20506][python] Support FlatMap Operation in Python Table APIThis closes #14352.,1
"[FLINK-20356][docs] Updated Mesos documentation matching it with the new deployment page style.[FLINK-20356][docs] Added missing ""Mode"".[FLINK-20356][docs] Added missing ""is"".[FLINK-20356][docs] Fixed wrong number.[FLINK-20356][docs] Reorganized Mesos page moving advanced topics into Flink on Mesos Reference.The Marathon section's example is not working, yet. I haven't found a solution for setting the RPC address in a multi-slave environment, yet.[FLINK-20356][docs] Improved wording.[FLINK-20356][docs] Fixing the description on where bin/mesos-appmaster.sh can be called from.[FLINK-20356][docs] Made Flink version dynamic.[FLINK-20356][docs] Fixed highlight block.[FLINK-20356][docs] Shortened long line.[FLINK-20356][docs] Moved Flink on Mesos Architecture section down.[FLINK-20356][docs] Added Hadoop section.[FLINK-20352][docs] Updated Chinese CLI docs to align with the English version.[FLINK-20352][docs] Reorganized Marathon section.[FLINK-20352][docs] Fixed headline.[FLINK-20352][docs] Updated code blocks.[FLINK-20352][docs] Added remark on Marathon's environment variable.[FLINK-20352][docs] Aligned placeholder labels.[FLINK-20352][docs] Added job submission command.[FLINK-20352][docs] Replaced root by <flink-user> to align it with the Getting Started section.[FLINK-20352][docs] Aligned Chinese with English version.This closes #14258.",2
[FLINK-20352][docs] Updated CLI documentation to match the current state of the code.[FLINK-20352][docs] Added Savepoint link.[FLINK-20352][docs] Added -j info to dispose command.[FLINK-20352][docs] Added --allowNonRestoredState.[FLINK-20352][docs] Added more extensive details on the stop action which include the --drain parameter.[FLINK-20352][docs] Swapped stop and cancel subsections.[FLINK-20352][docs] Added $ prefix to commands and fixed formatting (linebreaks and indentation).[FLINK-20352][docs] Changed link label.[FLINK-20352][docs] Changed link target to point to Application Mode instead of the more general Deployment Modes.[FLINK-20352][docs] Updated Chinese CLI docs to align with the English version.[FLINK-20352][docs] Updated --target section[FLINK-20352][docs] Aligned English and Chinese version.This closes #14287.,2
"[FLINK-20512][table-planner-blink] Introduce getDesc(), getOutputType(), replaceInputEdge(int, ExecEdge) methods for ExecNodeThis closes #14337",1
[FLINK-20423] Remove site.baseurl from gettingStarted page,1
[hotfix] Fix links in stateful-stream-processing,2
[hotfix] Remove redirects for pages which were simply removed,4
"[FLINK-20422] Remove site.baseurl from redirectsBesides replacing site.baseurl this commit:* fixes a few redirects* breaks redirect chains, if a page was moved couple of times, each versions points to the final destination instead of jumping through pages* adds all redirects for Chinese versions",1
[FLINK-20422] Remove site.baseurl from remaining .html templates,5
[hotfix] Exclude spider.log file from jekyll,2
[hotfix][table-common] Give meaningful error message when extracting internal data structures,5
[hotfix][table-common] Deprecate legacy type information conversion methods,5
[hotfix][table-runtime-blink] Query converters for internal data structures,5
[hotfix][table-runtime-blink] Get RowDataSerializer from InternalSerializers,5
[hotfix][table-common] Fix JavaDoc typos for FunctionProviders,1
[hotfix][table] Use class name in UDF validation,5
[FLINK-18890][table] Update LookupTableSource to the new type systemThis closes #14329.,5
[FLINK-20520][metrics][docs] Document metric name escaping,2
[FLINK-20478][table-planner-blink] Adjust the explain result for blink plannerThis closes #14315,2
[hotfix] BatchExecRank#explainTerms should use `RelWriter#input` instead of `RelWriter#item` for input relThis closes #14315,1
[FLINK-20478][table-planner-blink] ExecNodePlanDumper only displays the attributes of ExecNodeThis closes #14315,2
"[FLINK-20478][table-planner-blink] Normalize ExecNode's description: print arithmetic operators, comparison operators and AND/OR operator as the infix style, and print other operators as the prefix styleThis closes #14315",0
[FLINK-20258][WebUI] Format configured memory sizes,5
[FLINK-20554][web] Correct the display of latest completed checkpoint size on the overview page,3
[hotfix] fix typo in upsert-kafka docs (#14363)Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>,2
[hotfix][javadocs] Fix typo,2
"[FLINK-20570][docs] Fix the NOTE tip style in ""Process Function"" page (#14369)Co-authored-by: 002399 <shizhengchao@fcbox.com>",1
[FLINK-20507][python] Support Aggregate Operation in Python Table APIThis closes #14353.,1
[FLINK-19490][conf] Document SOMAXCONN limit for 'blob.fetch.backlog',2
[FLINK-20422] Fix redirect link in temporal_table.md,2
[FLINK-20521][rpc] Add support for sending null responsesThe AkkaRpcActor failed at sending asynchronous null responses becauseit did not wrap the null value in a Status.Success message for local messages.For remote messages it ran into a NPE because it did not check theSerializedValue.getByteArray(). This commit fixes both problems so that Flink'sRPC service now supports to respond with null values.This closes #14359.,1
[hotfix] Add @Nullable annotation to SerializedValue.serializedData,5
[FLINK-20209][web] Add tolerable failed checkpoints config to web ui,5
[FLINK-20509][table-planner-blink] Refactor verifyPlan methods in TableTestBaseThis closes #14360,3
[hotfix][docs] Replace Mesos by K8s,2
"Partial Revert ""[FLINK-20422] Remove site.baseurl from remaining .html templates""This reverts commit 15b66a3b",4
[FLINK-20354] Rework standalone docs pageThis closes #14346,1
[FLINK-20515][table-planner-blink] Move ExecNodePlanDumper into `exec.utils` packageThis closes #14380,1
[FLINK-20515][table-planner-blink] Move ExecNode visitors into `exec.visitor` packageThis closes #14380,1
[FLINK-20515][table-planner-blink] Move ExecNode processors into `exec.processor` packageThis closes #14380,1
[FLINK-20515][table-planner-blink] Introduce new ExecNode base classesThis closes #14380,1
[FLINK-20515][table-planner-blink] Make BatchExecMultipleInput extended only from BatchExecNode and port it to JavaThis closes #14380,1
[FLINK-20515][table-planner-blink] Make StreamExecMultipleInput extended only from StreamExecNode and port it to JavaThis closes #14380,1
[FLINK-20515][table-planner-blink] Remove MultipleInputRelThis closes #14380,4
"[FLINK-19832][coordinator] Do not use the allocator sharedSlots to create a bulk in SlotSharingExecutionSlotAllocatorWe need to pass the slots map to the createBulk method instead of using the allocator's 'sharedSlots'because if any physical slots have already failed, their shared slots have been removedfrom the allocator's 'sharedSlots' by failed logical slots.This closes #13879.",2
[FLINK-19832][tests] Add test for immediately failed PhysicalSlot in SlotSharingExecutionSlotAllocatorThis commit adds the SlotSharingExecutionSlotAllocatorTest.failLogicalSlotsIfPhysicalSlotIsFailed whichensures that the SlotSharingExecutionSlotAllocator will fail all logical slots and return the physical slotimmediately if the requested physical slot future is completed exceptionally.This closes #13879.,2
[FLINK-20591] Remove JobManagerOptions.SCHEDULING_STRATEGY,4
[FLINK-20592] Remove LazyFromSourcesSchedulingStrategy,4
[FLINK-20593] Remove EagerSchedulingStrategy,4
[FLINK-20422] Fix invalid links across languages,2
[FLINK-20588][docs] Added appendix to Mesos documentation for deploying a Mesos cluster including Marathon locally.This closes #14381,2
[hotfix][datadog][tests] Cleanup code,4
[hotfix][datadog] Merge DSeries#add*()The distinction between metric types adds unnecessary complexity.,1
"[hotfix][datadog] Explicitly mark fields relevant for serializationIt was difficult to tell which fields are relevant for serialization. Adding annotations makes this more obvious, and allows us more freedom in regards to naming.",1
[hotfix][datadog][tests] Rework tests- re-parse JSON to ignore order of serialization- restrict 'DatadogHttpClient.serialize()' to 'DSeries'- test series serialization- refer to constants where possible,3
[hotfix][datadog] Remove outdated comments,5
"[FLINK-20533][datadog] Encapsulate metric meta dataThis allows us to use the 'MetricMetaData' container for histograms later on, which will not directly extend 'DMetric'.",5
[FLINK-20533][datadog] Add Histogram support,1
[hotfix] StreamExecLegacySink should use getInputNodes to translate the input node to transformationThis closes #14384,1
"[FLINK-20513][table-planner-blink] Introduce BatchPhysicalExchange, and make BatchExecExchange only extended from ExecNodeThis closes #14384",4
"[FLINK-20513][table-planner-blink] Introduce StreamPhysicalExchange, and make StreamExecExchange only extended from ExecNodeThis closes #14384",4
[FLINK-20325][build] Move docs_404_check to CI stageThis closes #14204,1
"[FLINK-20325] Create full (en, zh) doc build and check itThis closes #14391",2
[hotfix][flink-runtime] Fix broken CheckpointStatistics.equalsSee https://github.com/apache/flink/pull/14390 for more details.,2
[hotfix][jdbc] Fix invalid string formatSee https://github.com/apache/flink/pull/14390 for more details.,2
[FLINK-19259][kinesis] Remove references to allow classloader unloading,1
[hotfix][util] fix partition utilityThis closes #14408,0
[FLINK-20528][python] Support table aggregation for group aggregation in streaming modeThis closes #14389.,1
[FLINK-20601][docs][python] Rework PyFlink CLI documentation.This closes #14367.,2
[FLINK-20626][runtime] Fix issue concurrent of concurrent failing and canceling of an ExecutionGraphUpdate ExecutionGraphRestartTest to be based on the new scheduler to verify it.,1
[hotfix] Fix WatermarkStrategy explanation in execution mode docs,2
[FLINK-20607][docs] Fix example of FunctionHint in udfs pageThis closes #14388Co-authored-by: 002399 <shizhengchao@fcbox.com>,1
[FLINK-19013][state-backends] Add start/end logs for state restoration,2
"[hotfix][coordination] Ease debugging of errors during slot allocationWhen transitioning from PENDING to ALLOCATED we now first verify that the job ID is matching because this is a more serious issues.Furthermore, if either the slot state of job ID conditions are not met we now print  better error messages.Finally, log the state transitions of all slots.",2
"[FLINK-20605][coordination] Rework cancellation of slot allocation futuresThe previous approach did not properly because it could happen that the future has been completed at the time it is being cancelled (e.g., because the corresponding task executor was unregistered). This order of events can happen since the processing of the allocation is done asynchronously, and can be scheduled after any other event.This caused the processing to run although we expected this not too happen, resulting in various errors, including:- completing an allocation despite being shut down- completing an allocation despite the task executor not being registered anymore- completing an allocation despite the slot report already having reporter a slot as allocated",0
[FLINK-17760][runtime] Set InternalTaskFailuresListener to ExecutionGraph on starting SchedulerBaseThis allows us to create an ExecutionGraph with InternalTaskFailuresListener assigned without having to start scheduling it. It is required to rework some tests to be based on new scheduler.,1
[hotfix][runtime] Rename SchedulerTestingUtils#createScheduler(...) to createSchedulerBuilder(...) because it returns a builder,1
[FLINK-17760][hotfix][runtime] Rename SchedulerNG#setMainThreadExecutor() to #initialize()This is to reduce confusion because the method also does other initialization work.,1
"[FLINK-17760][runtime, tests] Rework ArchivedExecutionGraphTest and updates TaskManagerLocation to enable comparing LocalTaskManagerLocation",0
"[FLINK-17760][runtime, tests] Remove ExecutionGraphMetricsTest and add RestartTimeGaugeTestExecutionGraphMetricsTest can be superseded by the newly added RestartTimeGaugeTest and DefaultSchedulerTest#jobStatusIsRestartingIfOneVertexIsWaitingForRestart().",3
"[FLINK-17760][runtime, tests] Rework legacy tests to be based on new scheduler and remove those which are not needed anymore",4
"[FLINK-17760][runtime, tests] Add test to verify allocation will be canceled when a vertex is failed or canceled",0
"[FLINK-17760][runtime, tests] Add test to verify that all pending requests will be canceled when SlotPool is shutdown",3
"[FLINK-17760][runtime, tests] Add test to verify that vertices are properly restarted on slot allocation failures",0
[FLINK-19919][runtime] Remove legacy scheduling in ExecutionGraph components,4
[FLINK-19920][runtime] Remove legacy FailoverStrategy,0
[FLINK-19921][runtime] Remove legacy RestartStrategy,4
"[FLINK-20433][tests] Stabilizing UnalignedCheckpointITCase.Improves UnalignedCheckpointITCase in the following ways to avoid running into rare issues or better deal with them:- Reduce load on test machine: Executing a test with p=10 may spawn up to 70 tasks that until backpressured can potentially lead to a full load on 70 cores. This may causes larger GC pauses and other JVM freezes that will trigger the rare PartitionNotFound exception. Now, sources are throttled until the sink backpressures.- Keep track of restart attempts in split enumerator and sink with source instances. Only finish sources if the desired numbers of failures occurred to avoid finishing too quickly.- Avoid relying completely on notifyCheckpointComplete to finish test: notifyCheckpointComplete is not guaranteed to be called but the test completely relied on it. This may lead to indefinite test runs: Some sources are finished while others are still running, but new checkpoints are canceled because of the finished sources. Thus, too many aborted checkpoints will also lead to a completed test.- Readding splits to enumerator (after FLINK-20290 has been fixed). Any unexpected failure may have caused all splits to be dropped, which causes indefinite running tests.- Removing test-class level timeout - AZP has its own timeout that also provides thread dumps - something that would require a tremendous effort in JUnit4.",3
[hotfix][coordination] Add ExcessResource#toString(),1
[hotfix][coordination][tests] Remove error message assertions,3
[FLINK-19314][coordination][tests] Add TestingDeclarativeSlotPoolBuilder,3
[FLINK-19314][coordination] Add DeclarativeSlotPoolFactory,1
[FLINK-19314][coordination] Extend SlotPool interface,2
[FLINK-19314][coordination] Add DeclarativeSlotPoolBridge,1
[FLINK-19314][coordination] Wire notifications about resources not being available,2
[FLINK-19305][coordination][CI] Setup CI run with declarative slot management,1
[FLINK-10274][conf][docs] Document env.pid.dir,2
[FLINK-20647][python] Use yield to generate output data in ProcessFunction of Python DataStream APIThis closes #14414.,5
[FLINK-20669][python][legal] Add the jzlib LICENSE file in flink-python moduleThis closes #14418.,2
[hotfix][docs] Fix the PyFlink version specified in the Dockerfile,2
[hotfix][docs] Improve the filesystem SQL connector docThis closes #14365,2
"[FLINK-20582][docs] Fix typos in ""CREATE Statements"" pageThis closes #14370Co-authored-by: xiaozilong <xiaozilong@bigo.sg>",1
[FLINK-20668][table-planner-blink] Introduce translateToExecNode method for FlinkPhysicalRelThis closes #14417,2
[FLINK-20639][python] Use list to optimize the Row used by Python UDAF intermediate resultsThis closes #14412.,1
[FLINK-19947][table] Support 'sink.parallelism' configuration for 'print' connectorThis closes #13932,5
[FLINK-19880][json] Fix ignore-parse-errors option not work for the legacy JSON formatThis closes #14415Co-authored-by: Xiao Cai <flinkcx@163.com>,2
[FLINK-20666][python] Fix the deserialized Row losing the fields name informationThis closes #14422.,5
[FLINK-19905][jdbc] Fix the 'lookup.max-retries' option initial value is 1 in JdbcLookupFunctionThis closes #14377Co-authored-by:  <xiaojiawen1@xiaomi.com>,5
[FLINK-20673][table-planner-blink] ExecNode#getOutputType method should return LogicalType instead of RowTypeThis closes #14423,2
[FLINK-20665][connector-fs][table] FileNotFoundException when restore from latest Checkpoint in Sink CompactionThis closes #14438,3
[FLINK-19435][connectors/jdbc] Add hang test case to reveal deadlock when loading different sql driver classes concurrently using Class.forNameThis closes #14361,1
[FLINK-19435][connectors/jdbc] Fix deadlock when loading different sql driver classes concurrently using Class.forNameThis closes #14361,1
[FLINK-20630][dynamodb] DynamoDB Streams Consumer fails to consume from LatestThis closes #14407.,3
[FLINK-20629][kinesis] Migrate from DescribeStream to DescribeStreamSummaryThis closes #14406.,2
"[hotfix] Make SimpleTransformationTranslator methods finalThey should not be overridden, subclasses are meant to implement the""internal"" methods.",1
[FLINK-20646] Update memory requirements for ReduceTransformationThis closes #14413.,1
"[FLINK-19369][tests] Disable BlobClientSslTest.testGetFailsDuringStreaming*The test cases BlobClientSslTest.testGetFailsDuringStreamingForJobPermanentBlob,.testGetFailsDuringStreamingNoJobTransientBlob and .testgetFailsDuringStreamingForJobTransientBlobcan deadlock when being used with SSL enabled because an SSL stream can deadlock whennot being consumed and closed at the same time.This closes #14424.",1
[FLINK-20677] Introduce proper JobManagerRunnerResultThe JobManagerRunnerResult allows to express different terminationconditions for the JobManagerRunner:1) Job finished successfully2) Job did not finish3) Job initialization failedThis closes #14430.,0
[FLINK-20654][tests] Temporarily ignore UnalignedCheckpointITCase,3
"[FLINK-20516][table-planner-blink] Introduce StreamPhysicalTableSourceScan, and make StreamExecTableSourceScan only extended from ExecNodeThis closes #14398",1
"[FLINK-20516][table-planner-blink] Introduce BatchPhysicalTableSourceScan, and make BatchExecTableSourceScan only extended from ExecNodeThis closes #14398",1
[hotfix] Fix incorrect output type in StreamExecTableSourceScan & BatchExecTableSourceScan,0
[hotfix][test] Improve error message in ValidatingCheckpointHandler,5
[hotfix][test] Fix StreamConfig propagation to StreamTask in StreamTaskMailboxTestHarnessBuilder,3
[FLINK-19681][checkpointing] Choose controler before processing first barrier or announcement,2
[FLINK-19681][checkpointing] Timeout aligned checkpoints based on checkpointStartDelay,2
[FLINK-19681][tests] Adjust alignmentTimeout in unaligned checkpoint ITCases,3
[FLINK-19681][config][checkpointing] Un-hide alignment timeout option,5
[hotfix][network] Report channel index if failied to deserialize,0
[hotfix][checkpointing] Add preconditions to channels and controllers,1
"[FLINK-19681][checkpointing] Fix barrier tracking in input channelsLocalInputChannel:Reset lastSeenBarrier for any barriers, not just UC.In local channels, there are no announcements,therefore lastSeenBarrier may not be reset for AC,therefore extra buffers may be added to state.Reduces failure frequency in UnalignedCheckpointIT par-local case.RemoteInputChannel:Don't update tracking state during conversion. Only do itupon receiving a barrier.Reduces failure frequency in UnalignedCheckpointIT par-remote case.",0
"[FLINK-19681][checkpointing] Reset channel barrier tracking from AlignedControllerInput channels are unaware of controller types and always update theirpendingCheckpointBarrierId.  Therefore, resetting it also should be donein either case.  Otherwise, pendingCheckpointBarrierId may be left in awrong state upon receiving a new barrier.",1
[FLINK-19681][checkpointing] Resume consumption when receiving different upstream signalsSolves hanging up in 1/12 uc tests.,3
"[FLINK-19681][checkpointing] Use converted barrier after disabling alignmentOtherwise, further components (e.g. SubtaskCheckpointCoordinator) canget an AC barrier for the UC checkpoint.",1
[FLINK-19681][checkpointing] Address minor feedback,5
[FLINK-19681][checkpointing] Use time of start of alignment instead of checkpoint to timeout,1
[FLINK-19681][checkpointing] Switch controller before processing the first barrierIf a checkpoint announcement was processed and then UC-barrier arrives(from the upstream) then it should be processed by the UC controller.,2
[FLINK-19681][checkpointing] Don't timeout checkpoint on last barrier,2
[hotfix][checkpointing] Explicit creation of CheckpointOptionsThe motivation is to eliminate subtle bugs when changing checkpointtype on the fly.1. Only guess options when creating a new barrier from configuration2. For other cases provide explicit factory methods2. Carry the current checkpoint/barrier requirements instead of theinitial configuration.,5
"[FLINK-19681][network] Force priority for converted barriersWithout this, gate interprets barrier as outdatedbecause it has already seen its SQN during the announcement.Preventing announcements from updating gate lastSeenSqndoesn't work because it provokes concurrency issue withnotification (by efficitively disable lastSeenSqn guard).",0
"[FLINK-20610][table-planner-blink] Introduce StreamPhysicalCalc & StreamPhysicalPythonCalc, and make StreamExecCalc & StreamExecPythonCalc only extended from ExecNodeThis closes #14400This closes #14400",1
"[FLINK-20610][table-planner-blink] Introduce BatchPhysicalCalc & BatchPhysicalPythonCalc, and make BatchExecCalc & BatchExecPythonCalc only extended from ExecNodeThis closes #14400This closes #14400",1
[FLINK-20213][fs-connector] Partition commit is delayed when records keep comingThis closes #14442,2
"[FLINK-20608][table-planner-blink] Introduce StreamPhysicalLegacyTableSourceScan, and make StreamExecLegacyTableSourceScan only extended from ExecNodeThis closes #14427",1
"[FLINK-20608][table-planner-blink] Introduce BatchPhysicalLegacyTableSourceScan, and make BatchExecLegacyTableSourceScan only extended fromThis closes #14427",1
"[FLINK-20609][table-planner-blink] Introduce StreamPhysicalDataStreamScan, and make StreamExecDataStreamScan only extended from ExecNodeThis closes #14428",5
"[FLINK-20609][table-planner-blink] Introduce BatchPhysicalDataStreamScan, and make BatchExecDataStreamScan only extended from ExecNodeThis closes #14428",5
"[FLINK-20622][table-planner-blink] Introduce StreamPhysicalChangelogNormalize, and make StreamExecChangelogNormalize only extended from ExecNodeThis closes #14402",4
[FLINK-19942][jdbc] Support sink parallelism configuration for JDBC connectorThis closes #13907Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>,5
[FLINK-20697][docs] Fix the data type of 'lookup.cache.ttl' in JDBC pageThis closes #14446,1
"[FLINK-20623][table-planner-blink] Introduce StreamPhysicalWatermarkAssigner, and make StreamExecWatermarkAssigner only extended from ExecNodeThis closes #14429",1
[FLINK-20546][kafka] Fix util method misuse in KafkaDynamicTableFactoryTestThis closes #14371,3
"[FLINK-20624][table-planner-blink] Refactor StreamExecJoinRule, StreamExecIntervalJoinRule and StreamExecTemporalJoinRuleThis closes #14404",4
[hotfix][k8s] Fix k8s ha service doc.This closes #14416.,2
[FLINK-20703][table] HiveSinkCompactionITCase test timeoutThis closes #14453,3
[FLINK-20679][tests] Remove unstable test JobMasterTest.testSlotRequestTimeoutWhenNoSlotOfferingThe test JobMasterTest.testSlotRequestTimeoutWhenNoSlotOffering is no longer needed because the schedulingpart is coveredy by DefaultSchedulerTest.restartVerticesOnSlotAllocationTimeout which ensures that verticesare restarted on allocation timeouts. The allocation timeout part should be covered byPhysicalSlotRequestBulkCheckerImplTest.testUnfulfillableBulkIsCancelled which ensures that PhysicalSlotRequestBulksare timed out after a configured allocation timeout.This closes #14448.,5
[FLINK-20616][python] Support row-based operation to accept user-defined function directlyThis closes #14410.,1
[hotfix] Let TestingOnCompletionActions.getJobMasterFailedFuture return jobMasterFailedFuture,0
[hotfix] Remove unused method JobManagerRunnerImpl#isShutdown(),1
[hotfix][tests] Extend TestingSchedulerNG to accept a triggerSavepoint function,1
[FLINK-11719] Do not reuse JobMasterServices across leader sessionsThis commit changes how the JobManagerRunnerImpl uses JobMasterServices.Now we use a JobMasterService per leader session.,1
[FLINK-11719] Make JobMaster a PermanentlyFencedRpcEndpointThis commit changes the JobMaster to have a permanent fencing token.,4
[FLINK-11719] Make SchedulerNG in JobMaster finalSince the JobMaster is now a PermanentlyFencedRpcEndpoint we no longerneed to make the scheduler resettable.,1
[FLINK-11719] Factor HeartbeatManager creation out into separate methods,1
[hotfix] Split final and non-final fields in JobMaster,0
[FLINK-11719] Make starting and stopping of JobMaster services symmetricThis closes #14431.,1
[FLINK-20719][table-planner-blink] Change BatchExecNode & StreamExecNode to interface and make each node extended from ExecNodeBase directlyThis closes #14461,1
[FLINK-20519][hbase] Fix NOTICE file for bundled dependencies in flink-sql-connector-hbase-2.2This closes #14456,2
"[FLINK-20690][table-planner-blink] Introduce StreamPhysicalCorrelate & StreamPhysicalPythonCorrelate, and make StreamExecCorrelate & StreamExecPythonCorrelate only extended from ExecNodeThis closes #14443",1
"[FLINK-20690][table-planner-blink] Introduce BatchPhysicalCorrelate & BatchPhysicalPythonCorrelate, and make BatchExecCorrelate & BatchExecPythonCorrelate only extended from ExecNodeThis closes #14443",1
[FLINK-20621][python] Improve the TypeInformation implementation in Python DataStream APIThis closes #14401.,5
[hotfix][docs][conf] Add missing space,1
[hotfix][docs] Fix typo,2
[FLINK-19969][cli] List 'run-application' in help message,1
[hotfix][docs][example] Correct variable name,2
[hotfix][javadocs] Fix copy-paste error,0
"[FLINK-20650][k8s] Remove ""native-k8s"" command and add bash wrapper for JobManager and TaskManager container argsThe ""native-k8s"" command has been deprecated. Flink should use the pass-through mode. Note that Flink needs to add a ""bash -c"" wrapper so that the environment variables could be expanded when executing in the ""docker-entrypoint.sh"".The corresponding PR in flink-docker is https://github.com/apache/flink-docker/pull/49.This closes #14419",2
[hotfix][docs] Fix typo,2
[hotfix][docs][sql] Fix typo,2
[FLINK-20567][docs][table] Fix genericshttps://issues.apache.org/jira/browse/FLINK-20567?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel,5
[hotfix][coordination] Remove unused code,1
[hotfix][coordination] Move logging of resource declaration to slot pool,2
"[hotfix][coordination] Centralize skipping declaration of unchanged requirementsThere are multiple events where resource requirements might not actually change, and so far the user of the slot pool was responsible for checking that the requirements have actually changed to prevent unnecessary RPC calls.Since this is something that every user should check, we might as well always do this automatically.",1
"[FLINK-20694][coordination] Extend slot pool logging- log total acquired resources when declaring requirements, or after accepting new / releasing idle slots- log if an offer could not be matched to any requirement",1
"[FLINK-20694][coordination] Do not rematch freed slotsWhen a slot was freed the slot pool was trying to find another requirement it could potentially fulfill, using the same code paths as for newly offered slots, which also includes an increase in acquired resources.As a result we were potentially counting a single slot as multiple resources, causing an inconsistent state. The slot pool hence believed it had enough slots to fulfill the requirements, causing it to reject slots, while the Scheduler was waiting for enough slots to arrive and the RM repeatedly trying to provide the actually required slots.While it is not necessarily a bad thing to try an find another matching requirement, it is currently not necessary to do so, since the scheduler will use slots however it sees fit anyway. In the worst case we go through another slot allocation cycle.As such freed slots now remain assigned to the originally matched requirement, and this mapping will only change whe the slot is explicitly reserved for a different requirement.In the long-term it would be desirable for the slot pool to automatically adjust the matching if a slot was freed. This could prevent cases where we request new slots although we still have idling slots around that we could use, or release slots as idle although there are still outstanding requirements.However this needs a more sophisticated approach, it has to account for cases where:- a freed slot could not be matched to another requirement (i.e., it is truly an excess resource)- a freed slot was matched against another profile, which should go through the same codepath as for slot reservations for a different profile- also try to re-assign currently excess resources if the requirements are increased",1
[FLINK-20678] Let JobManagerRunnerImpl fail if the JobMasterService fails unexpectedlyThis is a safety net which ensures that the JobManagerRunnerImpl will fail if theJobMasterService fails unexpectedly.This closes #14432.,0
[FLINK-20640][python] Use cython to optimize the performance of Python UDAFThis closes #14449.,1
[FLINK-20640][python] Remove the type info of args (#14481),5
[FLINK-20752][coordination] Properly respect max-failures-per-interval,0
[hotfix][tests] Cleanup SimpleRecoveryITCaseBase,4
[FLINK-20439][runtime] Rework scheduleOrUpdateConsumers in ExecutionGraph and its sub-componentsnotifyPartitionDataAvailable() is introduced to replace scheduleOrUpdateConsumers() in the RPC code path.Execution#scheduleOrUpdateConsumers is renamed to #updatePartitionConsumers to be aligned with what id does.,5
[FLINK-20439][runtime] Rename `scheduleOrUpdateConsumers` to `notifyPartitionDataAvailable` to avoid confusion,5
[FLINK-20745][table] Clean useless codes: Never push calcProgram to correlateThis closes #14474,1
"[FLINK-20705][table-planner-blink] Introduce StreamPhysicalValues, and make StreamExecValues only extended from ExecNodeThis closes #14454",1
"[FLINK-20705][table-planner-blink] Introduce BatchPhysicalValues, and make BatchExecValues only extended from ExecNodeThis closes #14454",1
"[FLINK-20707][table-planner-blink] Introduce StreamPhysicalExpand, and make StreamExecExpand only extended from ExecNodeThis closes #14457",1
"[FLINK-20707][table-planner-blink] Introduce BatchPhysicalExpand, and make BatchExecExpand only extended from ExecNodeThis closes #14457",1
"[FLINK-20708][table-planner-blink] Introduce StreamPhysicalDropUpdateBefore, and make StreamExecDropUpdateBefore only extended from ExecNodeThis closes #14458",5
"[FLINK-20709][table-planner-blink] Introduce StreamPhysicalMiniBatchAssigner, and make StreamExecMiniBatchAssigner only extended from ExecNodeThis closes #14459",5
[FLINK-18382][docs-zh] Translate Kafka SQL connector documentation into ChineseThis closes #13876,1
[hotfix][docs] Fix the broken link in Kafka SQL connector page,2
[FLINK-20648][k8s] Add itcase for recovering from savepoint with Kubernetes HA enabledThis closes #14486,0
[FLINK-20552][jdbc] JdbcDynamicTableSink doesn't sink buffered data on checkpointThis closes #14387,5
[FLINK-19691][jdbc] Support connection.max-retry-timeout configuration for JDBC connectorThis closes #14387,5
[FLINK-20710][hive] Hive reading fail when splits on different FileSystem nameservicesThis closes #14452,5
[FLINK-20642][python] Introduce InternalRow to optimize the performance of Python UDAFThis closes #14487.,2
[FLINK-20664][k8s] Support setting service account for TaskManager pod.,1
[FLINK-20664][k8s][doc] Update RBAC section in native kubernetes documentThis closes #14447,2
"[FLINK-20764] In BatchGroupedReduceOperator, fix timer logicThis closes #14489",2
[FLINK-20702][python] Support map operation chained together in Python Table APIThis closes #14473.,1
"[FLINK-20706][table-planner-blink] Introduce StreamPhysicalUnion, and make StreamExecUnion only extended from ExecNodeThis closes #14455",1
"[FLINK-20706][table-planner-blink] Introduce BatchPhysicalUnion, and make BatchExecUnion only extended from ExecNodeThis closes #14455",1
"[FLINK-20736][table-planner-blink] Introduce BatchPhysicalLimit, and make BatchExecLimit only extended from ExecNodeThis closes #14472",1
"[FLINK-20736][table-planner-blink] Introduce StreamPhysicalRank & StreamPhysicalLimit, and make StreamExecRank & StreamExeLimit only extended from ExecNodeThis closes #14472",1
[FLINK-19650][jdbc][table] Support limit push down for the JDBC connectorThis closes #13800,5
[FLINK-20657][connectors/jdbc] Migrate jdbc InputFormat/LookupFunction to SimpleJdbcConnectionProvider for connection establishmentThis closes #14466,5
[FLINK-20712][python] Support join_lateral/left_outer_join_lateral to accept table function directlyThis closes #14500.,1
[FLINK-20620][table-planner-blink][python] Port BatchExecPythonCalc and StreamExecPythonCalc to JavaThis closes #14496.,2
[FLINK-20540][jdbc] Fix JdbcCatalog connection exception when baseUrl doesn't end with slashThis closes #14362Co-authored-by: zhao.zhang <zhao.zhang@upai.com>,5
[FLINK-20756][python] Fix the bug that it doesn't support field access of expression containing Python UDF in the condition of CalcThis closes #14492.,5
[FLINK-20259][web] Add explanation to Effective Configuration in JM/TM,5
[hotfix][docs] Fix typo,2
[hotfix][docs] Fix typo,2
[hotfix][docs][checkpointing] Fix and sync example code,0
[hotfix] Fix incorrect license headers,0
[refactor] Use tabs in checkstyle.xml to conform to our other XML files,2
[FLINK-20651] Move checkstyle ignores to suppressions.xmlKeeping them inline does not work with google-java-format.,1
[FLINK-20651] Remove checkstyle checks that don't work/are not needed with google-java-format,1
[FLINK-20651] Add suppressions for breakage after google-java-format formattingThe reformatting increases file length for some files.,2
[FLINK-20651] Fix formatting that doesn't work with google-java-format/checkstyle,1
[FLINK-20651] Add Spotless plugin with Google AOSP style,1
[FLINK-20651] Format code with Spotless/google-java-format,2
[FLINK-20651] Add .git-blame-ignore-revs for ignoring refactor commitThis file can be used via:$ git config blame.ignoreRevsFile .git-blame-ignore-revs,2
[FLINK-20651] Update .editorconfig to match google-java-format,5
[FLINK-20651] Add IDE instructions for google-java-format,1
[hotfix] Update .git-blame-ignore-revs,5
[FLINK-20793][core] Fix the NamesTest and JarSubmissionITCase due to code style refactorThis closes #14514.,4
[FLINK-18998] No watermark is shown in Flink UI when ProcessingTime is usedDisplay more informative message stating that Watermarks are only available when usingevent time if there are no watermarks to display in the web UI.This closes #14483.,1
"[FLINK-17331][runtime] Explicitly get the ByteBuf length of all classes which is written to NettyMessageCurrently, the length of some header fields in NettyMessage is hardcoded: InputChannelID, ExecutionAttemptID, e.t.c.So if we make some changes for such field, then we are not ware that it also needs to change the respective length for related netty messages component.This PR explicitly get the ByteBuf length of all classes which is written to NettyMessage to avoid such problems.",0
"[FLINK-20792][build] Allow shorthand calls to spotlessIt was not possible to just run 'mvn spotless:check', but instead one needed to use the fully qualified name of the plugin, i.e., 'mvn com.diffplug.spotless:spotless-maven-plugin:check'.This is due to 'force-shading'; this module is declared as a child of the flink-parent pom (i.e., the root pom of the project), but is not actually declaring that very module as it's parent.This seems to throw of maven, which fails to retrieve the plugin information from the parent.Note that this is just a band-aid; a proper fix would declare flink-parent as the parent of force-shading, but this is the easier fix.",0
[FLINK-20803][build][docs] Pin google-java-format version in install instructions,2
[FLINK-20806] Correct error message in TaskExecutor.disconnectJobManagerConnectionThis closes #14518.,0
[FLINK-20749] Add DeclarativeSlotPool.registerNewSlotsListenerThe DeclarativeSlotPool.registerNewSlotsListener can be used to register aDeclarativeSlotPool.NewSlotsListener which is notified whenever theDeclarativeSlotPool receives new slots or reserved slots are freed.This closes #14482.,1
[FLINK-20693][table-planner-blink][python] Port BatchExecPythonCorrelate and StreamExecPythonCorrelate to JavaThis closes #14503.,2
"[FLINK-20458][docs-zh] Translate ""Getting Started"" page of Table SQLThis closes #14437",1
[hotfix][tests] Disable alignment timeout by default in UnalignedCheckpointITCaseMost of the bugs in UC are revealed with higher back-pressure which is not created with alignment timeout.This change disables it by default and adds a new test (p=20) with the timeout enabled.,0
"[FLINK-20654][network] Fix channel indices in StreamTaskNetworkInputIn StreamTaskNetworkInput.prepareSnapshot, internal channelIndexis inconsistent with CheckpointedInputGate channelIndex.This change fixes data loss in UnalignedCheckpointITCase.cogroup.",5
"[FLINK-20654][checkpointing] Decline checkpoints until restored channel state is consumedIn scenarios with multiple inputs (e.g. co-group; not union) one input may receive acheckpoint barrier while the second input is still restoring state. This (previous)state is currently not included into the snapshot, which therefore will be incomplete.",2
"[FLINK-20654][tests] Disable throttling on checkpoint completion, not snapshotStateThis reduces the number of failures in UnalignedCheckpointITCase.union to ~2/100.",0
[FLINK-20606][hive][table] Fix CREATE FUNCTION is failed under Hive catalog in SQL CLI using -j optionThis closes #14392,1
[FLINK-20807][build] Remove/narrow various checkstyle suppressions,4
"[FLINK-18654][docs][jdbc] Correct missleading documentation in ""Partitioned Scan"" section of JDBC connectorThis closes #14523",5
[FLINK-20790][build][avro] Move generated files to target/generated[-test]-sources,3
[FLINK-20594][runtime] Replaced DefaultExecutionSlotAllocator and its Factory class by SlotSharingExecutionSlotAllocator and its Factory.TestingPhysicalSlotProvider was moved into its own class file and generalized to match other testcases besides SlotSharingExecutionSlotAllocatorTest.This closes #14465.,3
[FLINK-20595][runtime] Deleted SlotProviderStrategy and corresponding TestingSlotProviderStrategy.This closes #14521.,3
[FLINK-20805][table][build] Apply spotless formatting,2
"[FLINK-20805][table][build] Remove spotless exclusion for ""generated"" files",2
[hotfix] Add correct git blame ignore hash,1
"[FLINK-20704][table-planner] Some rel data type does not implement the digest correctlySome of the rel data types for legacy planner:- GenericRelDataType- ArrayRelDataType- MultisetRelDataTypeDo not implement the digest correctly, especially forGenericRelDataType , the RelDataTypeFactory caches the type instancesbased on its digest, a wrong digest impl would mess up the type instancecreation, e.g. without this patch, all the GenericRelDataType instanceshave same digest `ANY`.The MapRelDataType is not fixed because we ignore the key/valuenullability when creating the type, which conflicts with the digest.There is already issue (FLINK-20785) to track this.This closes #14451",2
[FLINK-20385][canal-json] Allow to read metadata for canal-json formatThis closes #14464,5
[FLINK-19962][docs] Add examples and explanations for UNNEST operation in SQL documentationThis closes #14527,2
[FLINK-20769][python] Support minibatch to optimize Python UDAFThis closes #14524.,5
[hotfix][docs][table Fix typo in CREATE statements page (#14533)Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>,1
[FLINK-20826][table] Fix minor bug in `UpdatingTopCityExample` (#14537)Co-authored-by: shuo.cs <shuo.cs@alibaba-inc.com>,5
[FLINK-20828][python] Fix some aggregate and flat_aggregate tests failed in py35 (#14540),0
[docs/javadoc][hotfix] Explicitly Document task cancellation timeout does not apply to task failure,0
[FLINK-17827][scala-shell] Setup default logging settings,1
[FLINK-20841][git] Remove .gitignore entries for generated files,2
[FLINK-20839][docs] Fix generics,0
[FLINK-20841][git] Remove .gitignore entries for generated files,2
"[FLINK-20615] Clean PartitionRequestClientFactory up if createPartitionRequestClient failsIn order to maintain the invariant that a failed createPartitionRequestClient won't leavea failed connection future in the clients field, this commit removes the client futureif its creation fails.This closes #14528.",0
[FLINK-20822][hive] Don't check whether a function is generic in Hive catalogThis fixes the ClassNotFound problem when create a generic but not loaded function in Hive catalogThis closes #14534,2
"[FLINK-19981][core][table] Add name-based field mode for RowThis adds a name-based field mode to the Row class. A row canoperate in 3 different modes: name-based, position-based, ora hybrid of both when leaving the Flink runtime. It simplifiesthe handling of large rows (possibly with hundreds of fields)and will make it easier to switch between DataStream API andTable API.See the documentation of the Row class for more information.This closes #14420.",5
[FLINK-19773][runtime] Implement ExponentialDelayRestartBackoffTimeStrategyApply spotless formattingThis closes #14425.,2
[hotfix][build] Deduplicate assembly plugin parameters,2
[FLINK-20634][dist] Only ship start-scala-shell.sh with Scala 2.11,2
"[minor] Update IDE setup guide, to apply Save Actions only to Java files",2
[FLINK-20846] Factor out CompletedCheckpointStore and CheckpointIDCounter creation in ExecutionGraphBuilder.buildGraph,1
[FLINK-20846] Move CheckpointIDCounter creation out of ExecutionGraphBuilder,1
[hotfix][tests] Replace explicit ExecutionGraphBuilder.buildGraph calls with TestingExecutionGraphBuilder,3
[hotfix] Remove unused ExecutionGraphBuilder.buildGraph method,1
[FLINK-20846] Move CompletedCheckpointStore creation out of ExecutionGraphBuilder.buildGraph,1
[FLINK-20846] Remove CheckpointRecoveryFactory from ExecutionGraphBuilder.buildGraph,4
"[FLINK-20846] Move checkpoint service shut down out of CheckpointCoordinatorBy moving the shut down of checkpoint services out of the CheckpointCoordinator,it is now possible to reuse these services across different CheckpointCoordinators.This closes #14553.",1
[hotfix] Remove unused jobStatus parameter from CheckpointCoordinator.shutdown(),2
[hotfix] Factor CompletedCheckpointStore and CheckpointIDCounter factories outMoved the factories of the CompletedCheckpointStore and the CheckpointIDCounter toSchedulerUtils in order to make them reusable.,1
[hotfix][tests] Remove ProgrammedSlotProviderRemoving the ProgrammedSlotProvider since it is no longer used.,1
[FLINK-20737][table-planner-blink] Use RowType instead of RelDataType when building aggregate infoThis closes #14478,5
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalGroupAggregate, and make StreamExecGroupAggregate only extended from ExecNodeThis closes #14478",1
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalPythonGroupAggregate, and make StreamExecPythonGroupAggregate only extended from ExecNodeThis closes #14478",1
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalLocalGroupAggregate, and make StreamExecLocalGroupAggregate only extended from ExecNodeThis closes #14478",1
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalGlobalGroupAggregate, and make StreamExecGlobalGroupAggregate only extended from ExecNodeThis closes #14478",1
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalIncrementalGroupAggregate, and make StreamExecIncrementalGroupAggregate only extended from ExecNodeThis closes #14478",1
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalGroupTableAggregate, and make StreamExecGroupTableAggregate only extended from ExecNodeThis closes #14478",1
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalPythonGroupTableAggregate, and make StreamExecPythonGroupTableAggregate only extended from ExecNodeThis closes #14478",1
[FLINK-20854][table-runtime-blink] Introduce BytesMultiMap to support buffering recordsThis closes #14563,1
[FLINK-20711][docs] Fix failure-handler parameter enumeration value typo in ES connector docThis closes #14467,2
[hotfix][metrics] Rename constant IS_BACKPRESSURE to IS_BACK_PRESSURE,0
[hotfix][task] Optimize and simplify Task#isBackPressured,0
[FLINK-20717][metrics] Provide new backPressuredTimeMsPerSecond metric,1
[FLINK-20718][metrics] Add busyTimeMsPerSecond metricIt's defined as inverted value of idleTimeMsPerSecond,1
[FLINK-14814][webui] Display back pressured and busy times,2
[FLINK-14814][webui] Color nodes based on back pressure,2
"[FLINK-19174][metrics] Fix idle and backpressured time accuracy on long sleepsIn particularly, if task is idling forever, as there are no new records incommingprevious version would report idleTime as 0% and busyTime as 100% which is incorrect.In this version, idleTime metric is aware that idling period has started and can takethat into account when updating it's value.",5
"[FLINK-20782][table-planner-blink] Introduce BatchPhysicalRank, and make BatchExecRank only extended from ExecNodeThis closes #14506",1
"[FLINK-20766][table-planner-blink] Introduce StreamPhysicalSort, and make StreamExecSort only extended from ExecNodeThis closes #14502",1
"[FLINK-20766][table-planner-blink] Introduce StreamPhysicalSortLimit, and make StreamExecSortLimit only extends from ExecNode.This closes #14502",1
"[FLINK-20766][table-planner-blink] Introduce StreamPhysicalTemporalSort, and make StreamExecTemporalSort only extended from ExecNode.This closes #14502",1
"[FLINK-20766][table-planner-blink] Introduce BatchPhysicalSort, and make BatchExeSort only extended from ExecNodeThis closes #14502",1
"[FLINK-20766][table-planner-blink] Introduce BatchPhysicalSortLimit, and make BatchExecSortLimit only extended from ExecNodeThis closes #14502",1
[hotfix][python][docs] Improve the documentation about Python dependency management,2
[refactor] Rename StreamConfig.setTypeSerializersIn() to setupNetworkInputs()Because that's what it does.,1
"[FLINK-20491] Turn BroadcastStateTransformation into ""logical"" TransformationNote: Broadcast operations in BATCH mode don't yet work with thischange. This needs follow-up changes from later commits. We just lay thegroundwork here and keep the same functionality.Before, we were creating operators in BroadcastConnectedStreams eagerly.Now, the transformation holds the user function and we add a Translatorthat creates the ""physical"" operators when translating the graph ofTransformations.We do this so that we can translate differently based on whether we'rein BATCH or STREAMING mode.",1
"[FLINK-20491] Add preferred/pass-though inputs in MultiInputSortingDataInputThis will allow processing the broadcast side of a broadcast operatorfirst, before processing the keyed side that requires sorting forstateful BATCH execution.For now, the wiring from the API is not there, this will be added infollow-up changes.",4
[FLINK-20491] Allow by-key-iteration from broadcast side in BATCH modeWe allow the operation but it is a no-op because there never is anykeyed state because we process all broadcast input before starting toprocess the keyed/other side.,1
"[FLINK-20491] Add per-input setting of BATCH execution requirementsThis doesn't change the actual behavior, we still set the same ""sorted""setting on both inputs. We will add tests and actually change thebehavior in a follow-up commit.",4
[FLINK-20491] Add broadcast operators for BATCH execution modeThis adds an ITCase because we need to check that all the componentswork together and that the wiring works correctly.This uses the previously added funtionality to specify that given inputsshould be processed before other inputs and should not be sorted.,1
[FLINK-20517] Support mixed keyed/non-keyed operations in BATCH mode,1
[FLINK-20517] Add test for mixed-inpput operations in BATCH execution mode,3
[FLINK-20882][checkstyle] Improve error messages for illegal imports,2
[FLINK-20738][table-planner-blink] Rename BatchExecGroupAggregateBase to BatchPhysicalGroupAggregateBase and do some refactoringThis closes #14562,4
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalHashAggregate, and make BatchExecHashAggregate only extended from ExecNodeThis closes #14562",1
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalLocalHashAggregate, and make BatchPhysicalLocalHashAggregate only extended from FlinkPhysicalRelThis closes #14562",2
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalSortAggregate, and make BatchExecSortAggregate only extended from ExecNodeThis closes #14562",1
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalLocalSortAggregate, and make BatchPhysicalLocalSortAggregate only extended from FlinkPhysicalRelThis closes #14562",2
"[FLINK-20738][table-planner-blink] Introduce BatchPhysicalPythonGroupAggregate, and make BatchExecPythonGroupAggregate only extended from ExecNodeThis closes #14562",1
[FLINK-20781] Avoid NPE after SourceOperator is closed.,1
"[FLINK-18090][core][table] Update Row#toString and provide legacy utilThis updates the Row.toString method to provide a good summary string.In particular it fixes the following issues:Changeflag: According to FLIP-95, a row describes an entry in achangelog. Therefore, it should visible whether a row is an insert,delete, or update change. Now indicated with +I, -D, +U, -U.Nested rows: In the old implementation it was not visible whether nestedrows exist or not due to missing start/end boundaries. Now indicated with[...] or {...}.Positioned rows vs. named rows: According to FLIP-136, it should be visiblewhether a row operates in name-based or position-based field mode. Nowindicated with [...] or {...}.Nested arrays in maps and lists: In the old implementation arrays in mapsor lists could not be represented.Wrong formatting: Most programming languages use a space after a comma.This is an incompatible change. If the legacy representation is stillrequired for tests, the old behavior can be restored via the flagRowUtils.USE_LEGACY_TO_STRING for the local JVM. However, relying onthe row's string representation for tests is not a good idea in general asfield data types are not verified.",5
[FLINK-18090] Update tests for new Row.toStringAll tests in modules apart from the Blink planner/runtimemodule have been updated.Otherwise we use a JUnit rule to make the migration ofthe remaining tests incremental.This closes #14568.,3
"[FLINK-20868][task][metrics] Pause the idle/back pressure timers during processing mailbox actionsFLINK-20717 introduced a bug, where any time spent on processing mails, when task is idle orback pressured, will be accounted to idle or back pressured time instead of the busy time.The fix is to assign idle or back pressure timer to the suspenssion marker and pause thistimer when MailboxProcessor is running mails.",1
[hotfix][test] Use varargs in StreamTaskTest#setupEnvironment,3
[FLINK-20836][runtime] Add total resource profile and default slot resource profile to WorkerRegistration,1
[FLINK-20836][runtime] Pass total resource and default slot resource in registering TaskManager to SlotManagerThis closes #14561,4
"[FLINK-20856][table-planner-blink] Introduce StreamPhysicalGroupWindowAggregate & StreamPhysicalGroupWindowTableAggregate, and make StreamExecGroupWindowAggregate only extended from ExecNodeThis closes #14569",1
"[FLINK-20856][table-planner-blink] Introduce StreamPhysicalPythonGroupWindowAggregate, and make StreamExecPythonGroupWindowAggregate only extended from ExecNodeThis closes #14569",1
[FLINK-20773][json] Support to parse unescaped control chars in string nodeThis closes #14508,1
[FLINK-20488][runtime][checkpoint] Show checkpoint type in the Web-UI (AC/UC) for each subtask,2
"[FLINK-20654][checkpointing] Decline checkpoints until input channels are recoveredIn regard to InputChannels, there are 3 cases when a checkpoint has to be declined:1. Channel state is not fully consumed2. Channel was not yet converted from Recovered to normal3. Channel was not yet converted from Unknown to normalIn the 1st case, new checkpoint may skip some recovered buffers.In the 2nd and 3rd cases, not handling checkpointStarted() callby normal channels can prevent incoming buffers from being captured.In all these cases new checkpoint would be inconsistent.",1
[FLINK-20877][table-runtime-blink] Move BytesMap classes to util packageThis closes #14572,1
[FLINK-20877][table-runtime-blink] Refactor BytesHashMap and BytesMultiMap to support window key1. Make BytesMap decouple with BinaryRowData key type2. Extract pages operations from AbstractRowDataSerializer into PagedTypeSerializer3. Introduce WindowKey structure and WindowKeySerializer4. Introduce BytesWindowHashMap and BytesWindowMultiMap to support window key5. Refactor tests to also cover the new introduced BytesWindowHashMap and BytesWindowMultiMapThis closes #14572,1
[FLINK-20522][table] Add SpecializedFunction for hooking into the UDF generationIntroduces the concept of SpecializedFunctions to hook into the planning phasefor generating runtime implementation lazily.,1
[hotfix][table-common] Add DataTypeUtils.toInternalDataType(DataType),5
[FLINK-20522][table] Introduce built-in runtime functionsCompletes the envisioned design of FLIP-32 and FLIP-65. It makesimplementing built-in functions as easy as implementing user-definedfunctions while keeping function definition and body (aka runtimeimplementation) separately.Adding a built-in function requires changes in only 2 classes:- BuiltInFunctionDefinitions for the definition and- the class that contains the actual runtime logic.,2
[FLINK-20522][table-planner-blink] Migrate InternalAggregateFunction to BuiltInAggregateFunction,1
[hotfix][table-common] Reformat BuiltInFunctionDefinitions,5
[FLINK-20522][table] Add built-in TYPEOF function,1
[FLINK-20522][table] Add built-in IFNULL functionThis closes #14378.,1
[FLINK-15660][runtime] request slot should success if the slot is already allocated with the same allocation id,2
[FLINK-20837][runtime] Refactor dynamic SlotIDThis closes #14560,4
[FLINK-20860][core] Rename ManagedMemoryUseCase#BATCH_OP to OPERATOR.,1
[FLINK-20860][core] Update valid names for TaskManagerOptions#MANAGED_MEMORY_CONSUMER_WEIGHTS.This closes #14576,5
[FLINK-20632] Use Docker image published to apache/flink by default,2
"[FLINK-20866][yarn] Set high-availability.cluster-id to application id if not configuredIn order to easily connect to an HA enabled Yarn cluster, this commit sets thehigh-availability.cluster-id to the application id if not configured. This issymmetric to how we deploy HA enabled clusters and makes it unnecessary toexplicitly set the high-availability.cluster-id if one tries to reconnectto the cluster.This closes #14577.",1
"[hotfix] Remove explicit YarnClusterDescriptor.zookeeperNamespaceThe YarnClusterDescriptor.zookeeperNamespace has been replaced by the configuration whichis deployed together with the Yarn cluster. Hence, it is no longer needed.",1
[FLINK-20832][docs] Deliver bootstrap css and js ourselvesThis closes #14583,2
[FLINK-20321][formats] Fix NPE when using Avro/Json/Csv formats to deserialize null input (#14539)This closes #14539Co-authored-by: Alex Wang <alex.wang.dev@gmail.com>,5
[hotfix] add scala note to spa docs,2
[FLINK-20857][table-planner-blink] Rename BatchExecWindowAggregateBase to BatchPhysicalWindowAggregateBase and do some refactoringThis closes #14574,4
"[FLINK-20857][table-planner-blink] Introduce BatchPhysicalHashWindowAggregate & BatchPhysicalLocalHashWindowAggregate, and make BatchExecHashWindowAggregate only extended from ExecNodeThis closes #14574",1
"[FLINK-20857][table-planner-blink] Introduce BatchPhysicalSortWindowAggregate & BatchPhysicalLocalSortWindowAggregate, and make BatchExecSortWindowAggregate only extended from ExecNodeThis closes #14574",1
"[FLINK-20857][table-planner-blink] Introduce BatchPhysicalPythonGroupWindowAggregate, and make BatchExecPythonGroupWindowAggregate only extended from ExecNodeThis closes #14574",1
[FLINK-20906][legal] Update copyright year to 2021 for NOTICE files.This closes #14598,2
[hotfix][docs] Fix typo in Kubernetes HA services documentation,2
"[FLINK-20596][runtime] Removed SlotProvider and Scheduler interfaces, corresponding classes, and test cases. Comments were adapted accordingly.",3
[FLINK-20600][runtime] Deleted unused SlotSharingManager and corresponding test class SlotSharingManagerTest.This closes #14578,3
[FLINK-20619][runtime] Remove unused InputDependencyConstraintThis work is part of FLINK-20589This closes #14579,2
[FLINK-20619][runtime] Remove setup of InputDependencyConstraintExeucutorUtils.setBatchProperties(StreamExecutionEnvironment) does not setInputDependencyContraint anymore as it's not used anywhere.FLINK-20589,2
[FLINK-20892][runtime] Remove ScheduledUnitThis closes #14580,4
"[FLINK-20901] Add DeclarativeSlotPool.setResourceRequirementsThis commits adds DeclarativeSlotPool.setResourceRequirements which sets the absolutelyrequired resources. Hence, this method can be used to overwrite the currently setresource requirements.This closes #14589.",1
"[FLINK-20798][k8s] Use namespaced kubernetes client when creating FlinkKubeClientAfter using namespaced kubernetes client, we will not need to always set the namespace when creating kubernetes resources(e.g. deployment, pods, configmap, watch, etc.).Address comments: Update the unit test to verify the configmap watch is created in appropriate namespaceThis closes #14570.",1
[FLINK-20770][k8s] Correct the description of kubernetes config option 'kubernetes.rest-service.exposed.type'This closes #14515.,5
[FLINK-20453][runtime][checkpoint] Move checkpointing classes to an appropriate package,4
"[FLINK-20783][table-planner-blink] Introduce BatchPhysicalHashJoin, and make BatchExecHashJoin only extended from ExecNodeThis closes #14516",1
"[FLINK-20783][table-planner-blink] Introduce BatchPhysicalNestedLoopJoin, and make BatchExecNestedLoopJoin only extended from ExecNodeThis closes #14516",1
[FLINK-20783][table-planner-blink] Use SortSpec in SortCodeGenerator and ComparatorCodeGenerator.This closes #14516,1
[FLINK-20907][docs] Replaces deprecated syntax in Table API docThis closes #14601,2
[FLINK-20852][metrics] Expose load update time from the MetrixFetcher,5
"[FLINK-20852][metrics] Drop BackPressureSampleService in favour of backPressuredTimeMsPerSecond metricBackPressureSampleService is no longer needed and furthermore it should be less accurate comparedto the backPressuredTime metric. This is because sampling used to work by checking Task#isBackPressuredmethod, which in some cases can return true, with task that should be back pressured, but tasks(especially flatMap operators) can sometimes ignore back pressure status and keep spining forlimited amount of time. Because of that for flatMap operators, like WindowOperator,BackPressureSampleService could return too high back pressured ratios.Further more this allows us to greatly simplify JobVertexBackPressureHandler and to removethe no longer needed BackPressureStatsTracker and BackPressureRequestCoordinator components.",4
[FLINK-20852][metrics] Deprecate back pressure sampling config options,5
[FLINK-20852][webui] Provide more detailed per subtask backpressure stats,1
[hotfix][docs] Update incosistency in the docs between Default shuffle service and the deprecated Network metrics,1
[FLINK-20905][K8s] Format the description of 'kubernetes.container.image' optionThis closes #14597,2
[FLINK-10868][runtime] Add failure rater for resource managerThis closes #8952,0
[FLINK-20848][connector/kafka] Fix Kafka consumer client ID with subtask ID suffix (#14556),0
"[hotfix][doc] Fix default format in document for temporal function FROM_UNIXTIME(numeric, format)This closes #14617",1
[FLINK-16005][flink-yarn] Support yarn and hadoop config overrideAdd flink.hadoop.<key> and flink.yarn.<key> optionLoad yarn and hadoop conf in UtilsUpdate hadoop link to stable versionThis closes #14477.,2
[FLINK-20930][runtime] Remove AbstractExecutionSlotAllocatorThis closes #14615.,4
[FLINK-20850][runtime] Removing usage of CoLocationConstraintsSee also FLINK-20589This closes #14584,2
[FLINK-20861][json] Introduce an option for serializing DECIMALs in JSON as plain number instead of scientific notationThis closes #14604,5
[hotfix][runtime] Record actual resources for slots allocated with UNKNOWN requirements.,1
[FLINK-20864][runtime] Apply exact matching logic for fine-grained resource managementThis closes #14612,2
"[FLINK-20916][runtime] Remove obsolete testcaseThe test itself does not test the functionality it complains to test. TheJobManagerCustomLogHandler does not decode the URL encoding at all. The URLparsing and decoding happens already earlier in the process (see RouterHandlerwhich utilizes QueryStringDecoder and parses the PathParameter objects). Itdoes not need to be tested individually in this test class. Hence, thistestcase is obsolete and, therefore, can be deleted.",4
[FLINK-20954][python] Support state cache between bundles (#14628),1
[FLINK-20750][python][table-planner-blink] Port stream python group aggregate nodes to Java (#14624),2
[FLINK-20921][python] Fixes the Date/Time/Timestamp type in Python DataStream APIThis closes #14607.,5
[FLINK-20940][table-planner] Use session time zone in LOCALTIME/LOCALTIMSTAMP functionsThis closes #14620,1
"[FLINK-20883][table-planner-blink] Introduce StreamPhysicalOverAggregate, and make StreamExecOverAggregate only extended from ExecNodeThis closes #14605",1
"[FLINK-20883][table-planner-blink] Introduce StreamPhysicalPythonOverAggregate, and make StreamExecPythonOverAggregate only extended from ExecNodeThis closes #14605",1
"[FLINK-20883][table-planner-blink] Introduce BatchPhysicalOverAggregate, and make BatchExecOverAggregate only extended from ExecNodeThis closes #14605",1
"[FLINK-20883][table-planner-blink] Introduce BatchPhysicalPythonOverAggregate, and make BatchExecPythonOverAggregate only extended from ExecNodeThis closes #14605",1
"[FLINK-20883][table-planner-blink] Rename OverWindowITCase to OverAggregateITCase, rename OverWindowTest to OverAggregateTest, and rename OverWindowHarnessTest to OverAggregateHarnessTestThis closes #14605",3
[FLINK-20903] Pass ComponentMainThreadExecutor to constructor of SchedulerBaseThis commit passes the ComponentMainThreadExecutor into the SchedulerBase instance viaits constructor.,4
"[FLINK-20903] Remove SchedulerNG.initialize()Since we can pass a ComponentMainThreadExecutor into the SchedulerNG, we nolonger need SchedulerNG.initialize().",5
[hotfix] Remove SchedulerBase.checkpointRecoveryFactory,4
[FLINK-20903] Pass JobStatusListener to SchedulerBase,4
"[FLINK-20903] Remove SchedulerNG.registerJobStatusListenerSince we can pass in the JobStatusListener into the SchedulerNG implementations,we no longer need the SchedulerNG.registerJobStatusListener and can remove it.This closes #14593.",4
"[hotfix] Remove SchedulerBase.initializeOperatorCoordinatorsSince we already know the MainThreadExecutor when creating the SchedulerBase,we can directly pass it to the construction of the coordinatorMap.",4
[FLINK-20960][doc] Add warning in 1.12 release notes for potential corrupted data stream with unaligned checkpoint.This closes #14632,5
[FLINK-20812][hbase] Support 'properties.*' option to pass through all the HBase propertiesThis closes #14536,4
"[FLINK-20948][table-planner-blink] Introduce StreamPhysicalDeduplicate, and make StreamExecDeduplicate only extended from ExecNodeThis closes #14626",1
[FLINK-20885][canal-json] Fix deserialization exception when using 'canal-json.table.include' to filter binlogs of multiple tablesThis closes #14631,2
[FLINK-19635][hbase] Set the HBase client retry num to default value for fixing unstable test HBaseConnectorITCaseThis closes #14649,1
"[FLINK-20941][table-planner-blink] Introduce StreamPhysicalMatch, and make StreamExecMatch only extended from ExecNodeThis closes #14625",1
[FLINK-20911][state-backend-rocksdb] Support configuration of RocksDB log level,2
[FLINK-20876][table-planner-blink] Introduce StreamPhysicalTemporalJoin and make StreamExecTemporalJoin only extends from ExecNodeThis closes #14606,1
[FLINK-20876][table-planner-blink] Apply JoinSpec to other join nodes and clean up parameters.This closes #14606,2
[FLINK-20751][python][table-planner-blink] Port batch python group aggregate nodes to Java (#14641),2
[FLINK-19971][hbase] Fix HBase connector dependencies,0
[FLINK-20967][docs] Add documentation for the new introduced 'properties.*' option in HBase connectorThis closes #14645,1
[FLINK-20879][table-api] Use MemorySize type instead of String type for memory ConfigOption in ExecutionConfigOptionsThis closes #14616,5
[FLINK-20927][yarn] Update configuration option in YarnConfigOptions class,5
[FLINK-20980][coordination] Improve edge-case handling,1
[FLINK-20981][coordination] Allow initializing jobs to be suspended,5
[FLINK-20309][network] Add NetworkActionsLogger for easier debugging,0
"[FLINK-20309][tests] Make source split assignment in UnalignedCheckpointITCase stable.Currently, the assignment is only stable if all splits are assigned at once. For any unexpected failure, the split assignment becomes more dynamic and the previously employed hash map made the assignment non-deterministic. The fix is to always assign a split to the same source instance, such that the base number (nextNumber % increment) is equal to the reader index.",0
"[FLINK-20462][runtime] Port MailboxOperatorTest to StreamTaskMailboxTestHarness.The test assumed that mail / input are processed alternately. However, there is no guarantee that in between two `processElement` multiple mails would be processed.The fix is to use the current StreamTaskMailboxTestHarness to have full control over the replay order.",3
[FLINK-20953][canal-json] Support regular expression to filter databases and tables for canal-jsonThis closes #14652,5
[FLINK-20937][table-api] Fix exception when DROP a table with illegal watermark definitionThis closes #14640Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>,5
"[FLINK-20348][kafka] Make ""schema-registry.subject"" optional for avro-confluent format when used with kafkaThis closes #14530Co-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>",1
[FLINK-20909][table-planner-blink] Fix mini-batch interval inference doesn't work well with event-time deduplicateThis closes #14610Co-authored-by: zhangjing14 <zhangjing14@kuaishou.com>,1
[FLINK-20966][table-planner-blink] Rename StreamExecIntermediateTableScan to StreamPhysicalIntermediateTableScanThis closes #14638,2
[FLINK-20966][table-planner-blink] Rename BatchExecIntermediateTableScan to BatchPhysicalIntermediateTableScanThis closes #14638,2
[FLINK-20933][python] Fix the Python operators of Python DataStream API doesn't use managed memory when mixed use with Python Table APIThis closes #14621.,1
[FLINK-20858][python][table-planner-blink] Port StreamExecPythonGroupWindowAggregate and BatchExecPythonGroupWindowAggregate to Java (#14665),2
[FLINK-20997][tests] Generate yarn classpath before test phase,3
"[FLINK-20925][table-planner-blink] Introduce StreamPhysicalLookupJoin and BatchPhysicalLookupJoin, and make related Stream/Batch ExecLookupJoin only extends from ExecNodeThis closes #14663",1
[FLINK-20914][core] Format the description of 'security.ssl.internal.session-cache-size' option,2
[hotfix][table-common] Add nullability to StructuredType.asSummaryString,1
[FLINK-20862][table] Support creating DataType from TypeInformation,5
[FLINK-20862] Make raw types of TypeInformation resolvableThis closes #14619.,5
[FLINK-15156] Warn user if System.exit() is called in user codeThis closes #14499,1
[FLINK-20840][table-planner] Properly transpose projection to joinThis closes #14644,2
[FLINK-20963][python] Update examples to use the latest recommended API (#14673),3
[FLINK-21006][hbase] HBaseTablePlanTest is failed with NoSuchMethodError in haoop 3.1.3This closes #14680,0
[FLINK-20913][hive] Do not use HiveConf constructor to avoid overriding properties with default valuesThis closes #14634Co-authored-by: dixingxing <dixingxing@autohome.com.cn>,5
[FLINK-17085][kubernetes] Remove FlinkKubeClient.handleExceptionThis closes #14666.,2
[FLINK-19656][metrics] Enforce non-null character filter,1
[FLINK-19656][metrics] Automatically replace delimiter characters in identifier and logical scope,2
[FLINK-20924][python][table-planner-blink] Port StreamExecPythonOverAggregate and BatchExecPythonOverAggregate to Java (#14690),2
[hotfix][sink][test] Unignore JdbcITCase,5
[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA),1
[FLINK-20971][table-api-java] Support calling SQL expressions in Table APIThis closes #14660.,1
"[FLINK-21010][table-planner-blink] Introduce StreamPhysicalJoin, and make StreamExecJoin only extended from ExecNodeThis closes #14685",1
"[FLINK-20949][table-planner-blink] Introduce StreamPhysicalSink, and make StreamExecSink only extended from ExecNodeThis closes #14637",1
"[FLINK-20949][table-planner-blink] Introduce BatchPhysicalSink, and make BatchExecSink only extended from ExecNodeThis closes #14637",1
"[FLINK-20949][table-planner-blink] Introduce StreamPhysicalLegacySink, and make StreamExecLegacySink only extended from ExecNodeThis closes #14637",1
"[FLINK-20949][table-planner-blink] Introduce BatchPhysicalLegacySink, and make BatchExecLegacySink only extended from ExecNodeThis closes #14637",1
[FLINK-20949][table-planner-blink] BatchCommonSubGraphBasedOptimizer should also consider Sink nodeThis closes #14637,2
[FLINK-20551][docs] Make SQL documentation Blink onlyThis closes #14594,2
[FLINK-21009] Can not disable certain options in Elasticsearch 7 connector,2
[FLINK-20946][python] Optimize ValueState implementationThis closes #14627.,2
[FLINK-20500][upsert-kafka] Fix unstable temporal join testThis closes #14689,3
"Revert ""[FLINK-20946][python] Optimize ValueState implementation""This reverts commit cf443681e89e3e942b200253e1b494aa02641bcb",4
(FLINK-21039) change legacy_planner.zh.md some English links to Zh links,2
[FLINK-19158][e2e] Fix wget timeout mechanism and cache configThis closes #14694,5
[FLINK-20992][checkpointing] Don't schedule checkpoint triggering during shutdownThis closes #14683.,2
[hotfix][docs] Fix typo in 'docs/dev/table/functions/udfs.md & udfs.zh.md'.,2
[hotfix][javadoc] Correct the wrong spelling 'perserves' to 'preserves'.,0
[FLINK-21019][es] Bump Netty to 4.1.46,2
[FLINK-21019][cassandra] Bump Netty to 4.1.46,2
[FLINK-21019][hbase] Bump Netty to 4.1.46,2
[FLINK-21019][hive] Bump Netty to 4.1.46,2
[FLINK-21019][python] Bump Netty to 4.1.46,2
"[FLINK-21042][docs] Fix code example in ""Aggregate Functions"" section in Table UDF pageThis closes #14702",1
[FLINK-20998][docs][table] The 'flink-raw.jar' mentioned in docs doesn't exist  and add prettier maven xml dependenciesThis closes #14672,5
[FLINK-20931][coordination] Remove globalModVersion from ExecutionGraph,4
[hotfix][coordination] Remove resetForNewExecution from ExecutionJobVertex,1
[FLINK-21041][table-planner-blink] Introduce ExecNodeGraph to wrap the ExecNode topologyThis closes #14700,2
"[FLINK-21044][connectors/jdbc] Use more random bytes in XidWith only 4 random bytes, testXidsUniqueAmongGenerators failsonce per ~100 runs as it deliberately uses same checkpointIdand subtaskIdx.This change makes SemanticXidGenerator use 8 random bytesinstead of 4 higher bytes of checkpointId.",1
[FLINK-20944][k8s] Do not resolve the rest endpoint address when the service exposed type is ClusterIPThis closes #14692.,1
[FLINK-21024][dist] Keep dynamic properties before job arguments.This closes #14697,2
[FLINK-19446][canal-json] Fix canal-json format parse UPDATE record with null value will get wrong resultThis closes #14693,0
"[FLINK-19771][connector-jdbc] Fix NPE when accessing array using postgresSwitching to handle arrays in createInternalConverter rather thancreateNullableInternalConverter, so nulls are handled properly.This closes #13787.",0
"[FLINK-21011][table-planner-blink] Introduce StreamPhysicalIntervalJoin, and make SteamExecIntervalJoin only extended from ExecNodeThis closes #14699",1
"[FLINK-21011][table-planner-blink] Fix missed renaming for BatchExecJoinRuleBase, BatchExecNestedLoopJoinRuleBase and BatchExecSingleRowJoinRuleThis closes #14699",0
[FLINK-17868][table-planner-blink] Fix proctime in DDL can not work in batch modeThis closes #14687,1
[FLINK-20654][docs] Adding unaligned checkpoint warning to release notes/docs.,2
[FLINK-20654][network] Improve tracing of buffersThis commit provides additional contextual information that is easing debugging.,0
"[FLINK-20654][network] Fix ChannelStatePersister#checkForBarrier.This commit also checks if #startPersisting called correctly.Note that a few test cases in UnalignedControllerTest already fail with this new check, such that no new tests are needed.",3
[hotfix][network] Fix SingleCheckpointBarrierHandler#cancelSubsumedCheckpoint log.,2
"[FLINK-20654][tests] Adding magic bytes to UnalignedCheckpointITCase to detect corruption quicker.Currently, a corruption is often only detected only downstream which makes debugging harder.",0
"[FLINK-18383][docs-zh] Translate ""JDBC SQL Connector"" documentation into ChineseThis closes #14675",1
[FLINK-20947][planner] Fix idle source doesn't work when pushing watermark into the sourceThis closes #14679,1
[FLINK-21050][examples-table] Add some advanced function examplesThis closes #14714.,1
[FLINK-21070][table-runtime-blink] Fix invalid reuse of generated codeCompileUtils reuses code based on only the class name. This could be error-proneas code that is slightly different would be ignored. The wrong behavior wasvisible during code generation of structured types.This closes #14720.,0
[hotfix][runtime] Fix the missing arguments in error message in MemoryManager and FsCheckpointStorageAccess,0
[hotfix][streaming][test] Allow AbstractStreamOperatorTestHarness to use managed memory for operator use case,1
[hotfix][table-runtime-blink] Make MemoryManager not null in LazyMemorySegmentPool,1
[hotfix][table-runtime-blink] Rename StateTtlConfigUtil to StateConfigUtil,5
[FLINK-21054][table-runtime-blink] Implement mini-batch optimized slicing window aggregate operatorThis closes #14708,1
[FLINK-20680][table-common] Fix invalid validation of var-arg function with no parameters,2
[FLINK-20680][table-planner-blink] Add additional var-arg testsThis closes #14435.,3
[FLINK-21020][build] Bump Jackson to 2.12.1,2
"[FLINK-21069][table-planner-blink] Configuration ""parallelism.default"" doesn't take effect for TableEnvironment#explainSqlThis closes #14742",5
[FLINK-21104][network] Improve debug information for unaligned checkpoints,5
"[FLINK-21104][network] Ensure that converted input channels start in the correct persisting state.When a checkpoint is aborted, the ChannelStatePersister of an input channel is stopped for that checkpoint.A barrier that arrives after that is simply ignored.However, if a channel is still being recovered during the abortion, the information that the checkpoint is stopped is lost for that particular channel.This commit initializes converted channels with that state correctly.Additionally, this commit includes test that helped to verify that the ChannelStatePersister is actually working correctly now.",1
[FLINK-21018] Update checkpoint related documentation for UI,2
[FLINK-20961][table-planner-blink] Fix NPE when no assigned timestamp defined in DataStreamThis closes #14735,5
[FLINK-21071][release][docker] Update docker dev branch in snapshot branch,2
[FLINK-19465][runtime / statebackends] Add CheckpointStorage interface and loader,1
[FLINK-19465][runtime / statebackends] Wire checkpoint storage through the runtime,1
[FLINK-19465][runtime / statebackends] Remove checkpoint storage methods from StateBackend interfaceThis closes #13797,4
[hotfix] lower checkpoint storage log to debug,0
[hotfix][checkpointing] Log checkpoint ID from notification,2
"[hotfix][checkpointing] Convert some CheckpointStatsTracker state to argumentsThis is a preparatory step for FLINK-19462.CheckpointStatsTracker is created with a fixed set of vertices.At time of checkpoint creation this set can be different.As checkpoint already carries the vertices there is no need to storethem as state.Besides that, changing the type from List<ExecutionJobVertex>to Map<JobVertexID, Integer> simplifies writing the tests.",3
[hotfix][checkpointing] Send state snapshot size as a metricThis is a preparatory step for FLINK-19462.Motivation:1. Ability to report metrics without state snapshot (subsequent commit)2. Consistency with other metrics,2
[hotfix][checkpointing] Collect and log discarded state sizeThis is a preparatory step for FLINK-19462.,2
[FLINK-19462][checkpointing] Make CheckpointStatsHistory always consistentThis is a preparatory step for FLINK-19462.Access to checkpoint stats by ID without calling history.snapshot()allows to update failed checkpoint stats without PendingCheckpointinstance.,0
[FLINK-19462][checkpointing] Extend PendingCheckpointStats by FailedCheckpointStatsInherit mutation semantics from PendingCheckpointStatsto allow updates even after checkpoint failed.,0
[FLINK-19462][checkpointing] Update checkpoint stats from late ACKs,5
[FLINK-19462][checkpointing] Report aborted checkpoint statsThis change introduces a new RPC from TM to JM.Existing one can't be used because it:a) confirms the checkpointb) requires task state snapshotThe call is issued after cancelling task state-persistingfutures upon receiving abortion notification. This waymore precise metrics are available (compared to reportingfrom AsyncCheckpointRunnable after cancellation).,1
[hotfix][runtime] Extract SchedulerBase.processCheckpointCoordinatorMessage,4
[hotfix][runtime] Remove unused SchedulerBase.checkpointRecoveryFactory,1
[hotfix][web] Show `-` in humanizeBytes for negative values,0
[FLINK-19381][docs] Fix docs for savepoint relocationThis closes #13488,2
[FLINK-21026][flink-sql-parser] Align column list specification syntax with hive in INSERT statementThis closes #14726,2
[hotfix] Remove a supportsAsynchronousSnapshots method used in tests only,3
[FLINK-21072] Refactor the SnapshotStrategy hierarchy1. The refactoring simplifies the snapshot strategy hierarchy a bit.2. It extracts the synchronous/asynchronous execution out of the SnapshotStrategy to a separate SnapshotStrategyRunner. Prior to those changes the logic was duplicated in most of the strategies.3. It introduces the concept of SnapshotResources for the synchronous part which can be later on used for introducing a common SavepointSnapshotResources.This closes #14719,1
[FLINK-20968][table-planner-blink] Remove legacy exec nodesThis closes #14733,4
[FLINK-20968][table-planner-blink] Rename ExecNode#getDesc to ExecNode#getDescriptionThis closes #14733,1
[minor][table-planner-blink] Move CommonPhysicalJoin and CommonPhysicalLookupJoin to `nodes.physical.common` packageThis closes #14733,1
[minor][table-planner-blink] Minor code cleanup for some exec nodes and physical nodesThis closes #14733,4
[FLINK-21122][docs-zh] Update checkpoint_monitoring.zh.mdThis closes #14756,5
[FLINK-21123][fs] Bump beanutils to 1.9.4,2
"[FLINK-21077] Introduce SlotPoolService to abstract SlotPool from JobMasterThis commit allows to support different SlotPoolService implementations which canaccommodate different slot pool implementations (e.g. SlotPool, DeclarativeSlotPool, etc.).This closes #14722.",5
[hotfix] fix broken documentation links,2
[FLINK-19393][docs-zh] Translate the 'SQL Hints' page of 'Table API & SQL' into ChineseThis closes #14710,1
[FLINK-21140][python] Extract zip file dependencies before adding to PYTHONPATHThis closes #14755.,1
[FLINK-21105][table-planner-blink] Rename ExecEdge to InputProperty and rename RequiredShuffle to RequiredDistributionThis closes #14757,1
[FLINK-18685] Make MiniClusterJobClient#getAccumulators non-blockingThis closes #14558,5
[FLINK-21006] Fix hbase 1.4 tests on Hadoop 3.xThis closes #14770,3
[FLINK-21059][kafka] KafkaSourceEnumerator does not honor consumer properties,2
[Flink-20999][docs] Adds usage examples to the Kafka Avro Confluent connector formatThis closes #14764,5
[FLINK-21072][hotfix] Clear resources in HeapSnapshotStrategy,2
[FLINK-12461] Document Scala 2.12.x situation,2
[FLINK-21017][docs] Fix missing backquote in table connectors docs,2
Fix typo in kinesis-connector module,2
[FLINK-20675][checkpointing] Only decline async checkpoint failure when task is still running,1
[FLINK-20675][checkpointing] Ensure asynchronous checkpoint failure could fail the job by default,0
[FLINK-20675][checkpointing] Refactor interfaces to decline checkpoint with CheckpointException,4
"[FLINK-21144][runtime] Implement MainThreadExecutor#schedule(callable, delay, unit)This closes #14769",2
[hotfix] Fix CheckpointFailureManagerITCase compile error,0
[FLINK-21158][runtime] wrong jvm metaspace and overhead size show in taskmanager metric pageThis closes #14779,1
[FLINK-21167] Make StateTable snapshots iterableIn order to implement an iterator required by a binary unified savepoint we need a way to iterate a snapshot.,1
[hotfix] Fix fields visibility in KeyGroupPartitioner,0
[FLINK-21182] Make HeapPriorityQueueStateSnapshot iterableIn order to implement an iterator for a unified savepoint we need a wayto iterate over all entries in a priority queue snapshot.,1
[FLINK-21163][python] Fix the issue that Python dependencies specified via CLI override the dependencies specified in configurationThis closes #14774.,5
[FLINK-21048][docs] Refactor documentation related to switch memory allocator,2
[FLINK-13996][docs] Update instructions on building with Maven 3.3.xThis closes #14805,5
[hotfix][docs] Add warning to K8s docs about LoadBalancer exposed type,5
[FLINK-21099] Introduce JobType to distinguish between batch and streaming jobs,2
[FLINK-13996][docs] Update instructions on building with Maven 3.3+,5
[FLINK-21151] Separate iterator creation from metadata writing in RocksFullSnapshotStrategyThe two things are not connected.,5
[FLINK-21151] Pass whole resources instead of fields in RocksFullSnapshotStrategyWe also move the fillMetaData() method and hide it in the resources.,5
[FLINK-21151] Move iterator creation one level up in RocksFullSnapshotStrategy,1
"[FLINK-21151] Properly take ownership in merging iterator in RocksFullSnapshotStrategyBefore, it was partially taking ownership of the resources passed to itin the constructor but outside code was still closing some of theresources, such as the ReadOptions.Now, we encapsulate creation of the merging iterator in a method andmake it fully responsible for closing the resources required by it.",1
[FLINK-21151] Move KV-State iterator creation to RocksDB snapshot resourcesThis is in preparation of completely factoring out the async writingpart of the strategy.,5
[FLINK-21151] Extract common interfaces from RocksDB state iterator and resourcesThis is in preparation of completely factoring out the async writingpart of the strategy.,5
"[FLINK-21151] Move asynchronous writing part out of RocksDB strategyThe previous preparations allow us to put this backend-independent partinto flink-runtime, where it can be used by other backends to writesnapshots in the same common format.FullSnapshotResources is now the common thing that backends mustprovide.",1
[FLINK-21151] Make RocksDBFullSnapshotResources a toplevel class,5
[FLINK-21164][rest] Delete temporary jars,4
[FLINK-21104][network] Adding task name to logged network buffers,1
[FLINK-21104][task] Ease debugging.,0
[FLINK-21104][tests] Fix UnalignedCheckpointITCase not completing when there is a failure while finishing.Also improved logging and check for data corruption.,5
[FLINK-21104][network] Do not enqueue released channels into the input gate.,2
"[FLINK-21104][network] Fix handling of obsolete CheckpointBarriers in UnalignedCheckpointsIf previous checkpoint is declined, it can happen that task receives both older and newercheckpoint barrier on two different channels, before processing any checkpoint cancellationmessage/RPC. If the newer checkpoint barrier happens to be processed before the obsolete oneincorrect `checkState` in ChannelStatePersister would cause job failure. This checkStatewas assuming that the previous checkpoint would have been aborted/stopped before triggeringthe new one, while in reality, this previous checkpoint has never been triggered on this taskso it also could not have been stopped.",1
"[FLINK-20654][network] Fix incorrect spilling/persisting logic in RemoteInputChannelThis commit fixes a bug where RemoteInputChannel was incorrectly deciding whichbuffers should be spilled, if it has received an obsoleted CheckpointBarrier,that hasn't been cancelled (yet?).",0
"[FLINK-21104][network] Priority notification after cancellation.During cancellation it may happen that CheckpointedInputGate may not poll a priority event if the corresponding channel has already been released. Until race conditions are removed, it safest to simply ignore an empty poll.",4
[FLINK-21112][python] Add ValueState/ListState/MapState and corresponding StateDescriptors for Python DataStream API.This closes #14758.,5
[FLINK-21112][python] Expose MapState to users,1
[FLINK-21169][kafka] flink-connector-base dependency should be scope compile,2
[FLINK-21216][python] Limit the numpy version < 1.20.0 (#14825),2
[FLINK-21226][table-common] Reintroduce TableColumn.of for backwards compatibility,2
[FLINK-21150][table-planner-blink] Introduce ExecEdge to connect two ExecNodesThis closes #14827,2
"[FLINK-21215][task] Do not overwrite the original CheckpointFailureReason in AsyncCheckpointRunnableBefore this change, original failure reason would be hidden and replaced with CHECKPOINT_ASYNC_EXCEPTION",0
"[FLINK-21215][task] Optimise order of cancellation AsyncCheckpointRunnable and notifing JobManagerThe order of cancelling AsyncCheckpointRunnable and notifing the JM was sub-optimal.Instead of notifing the JM first, we were first cancelling the future, which couldcreate a race condition, were the secondary failure was reported first, causingslightly less readable logs/error messages.",2
[FLINK-20359][k8s] Added Owner Reference to Job Manager in native kubernetesThis closes #14591,3
[FLINK-21139][runtime] Fix unstable ThresholdMeterTestThis closes 14823,3
[FLINK-20345][table-planner-blink] SplitAggregateRule: Adds an Expand node only if there are multiple distinct aggregate functionsThis closes #14602,1
[FLINK-21172][canal][json] Support 'event-timestampcanal-json format include es field (#14792),5
[FLINK-21207][csv] Fix 'csv.disable-quote-character' = 'true' can not take effect in source tableThis closes #14813,0
Add e2e_uploading_watchdog to all tasks.,1
[temp] Added infinite test.,3
[FLINK-20942][table] Digest of FLOAT literals throws UnsupportedOperationExceptionThis closes #14801.,1
"Revert ""Add e2e_uploading_watchdog to all tasks."" and ""[temp] Added infinite test.""This reverts commit 4227490dRevertThis reverts commit 94ecb916",4
[FLINK-9683][history] HistoryServer uses configured default fs scheme,5
"[FLINK-21092][table-planner-blink] Introduce getJsonPlan, explainJsonPlan and executeJsonPlan in TableEnvironmentInternalThis closes #14729",5
[FLINK-21093][table-planner-blink] Support StreamExecTableSource json serialization/deserializationThis closes #14729,5
[FLINK-21094][table-planner-blink] Support StreamExecSink json serialization/deserializationThis closes #14729,5
[FLINK-21096][table-planner-blink] Introduce ExecNodeGraphJsonPlanGenerator to serialize ExecNodeGraph to json plan and deserialize json plan to ExecNodeGraphThis closes #14729,5
[FLINK-21092][table-planner-blink] Move the spec classes in `exec.utils` to `exec.spec` packageThis closes #14729,1
[FLINK-10520][rest] Properly handle optional savepoint parameters,2
[FLINK-9844][client] PackagedProgram#close() closes ClassLoader,2
[FLINK-19360][scripts] Support spaces in '${JAVA_HOME}',1
"[FLINK-21132][runtime] Don't end input on stop with savepointEndOfInput was used to handle any stopping of the job. Whenstopping with savepoint the input is not actually ended.This causes issues with some sinks (e.g. Iceberg).With this change, endInput is not call for stop-with-savepoint.To differentiate stop-with-savepoint from other casesonly checkpoint (RPC/barriers) are considered and not network EOP.That's enough because EOP is only injected after the CP completion(i.e. when the downstream is also notified by sync savepoint by CPbarriers).",1
[FLINK-21132][runtime][tests] Stop with savepoint shouldn't end input,3
[FLINK-21132][runtime][tests] Parameterize StopWithSavepoint test with chaining strategy,5
[FLINK-21132][runtime][tests] Test StopWith Savepoint against concurrent EndOfInput,3
[hotfix][task] Rename SourceStreamTask.isFinished to wasStoppedExternally,5
[FLINK-21204][coordination] Remove LogicalSlot#getSlotSharingGroupId,2
[hotfix][coordination] Adjust TaskExecutor resource to reasonably large value for local executionThis fix is to avoid arithmetic overflow in calculating the resource overview of the minicluster.,5
[hotfix][coordination] Move utility methods of SlotManager to SlotManagerUtils for deduplication,4
"[hotfix][coordination] Add getters of AllocationID, JobID and SlotState in TaskManagerSlotInformation",5
[hotfix][runtime] Support copy ResourceProfile with its Builder.,2
[hotfix][runtime] Implement `toString()` for ResourceCounter.,0
[FLINK-20835][coordination] Add fine-grained resource management feature toggle,1
[FLINK-20835][coordination] Introduce WorkerResourceSpec#fromTotalResourceProfile for generating the require resources from pending task managers,1
[FLINK-20835][coordination] Introduce TaskManagerTracker to track TaskManager's resource and slot status,2
[FLINK-20835][coordination] Introduce the SlotStatusSyncer to allocate/free slot and reconcile the slot status,2
[FLINK-20835][coordination] Introduce ResourceAllocationStrategy and its default implementation for fine-grained resource management,2
[FLINK-20835][coordination] Introduce FineGrainedSlotManager,2
[FLINK-20835][test] Setup Azure build for running core and flink-tests for fine-grained resource managementThis closes #14647,3
[FLINK-21261][table-planner-blink] Improve digest of physical Expand nodeThis closes #14850,1
[FLINK-21185][table-api] Introduce TemporaryOperationListener interface for Catalog to listen on temporary object operationsThis closes #14802,2
[FLINK-20894][table-api] Introduce SupportsAggregatePushDown interfaceThis closes #14748,1
[FLINK-21078] Make TestingDeclarativeSlotPoolFactory a top-level classMaking the TestingDeclarativeSlotPoolFactory a top-level class makes it easier to reuse this classin other tests.,3
[FLINK-21078] Add DeclarativeSlotPoolService which encapsulates a DeclarativeSlotPoolThis commit adds the DeclarativeSlotPoolService which makes a DeclarativeSlotPool usablewith the JobMaster.,1
[FLINK-21078] Make DeclarativeSlotPoolService a parent of DeclarativeSlotPoolBridgeMaking DeclarativeSlotPoolService a parent of DeclarativeSlotPoolBridge allows to reuse the code formanaging the TaskManager connections. This will improve the maintainability of the code base.This closes #14853.,1
"[FLINK-21262] Remove SlotPool.suspend and SlotPoolService.suspendSince FLINK-11719 it is no longer necessary to suspend a SlotPool ora SlotPoolService. Hence, this commit removes this obsolete method.This closes #14854.",4
[FLINK-21277] Bump testcontainers version,3
[FLINK-21149][table-common] Remove deprecated CatalogBaseTable.getProperties()This closes #14759.,2
[FLINK-21255] Add WaitingForResources state for DeclarativeScheduler,1
[FLINK-21255] Add tests for WaitingForResources stateThis closes #14852,3
[FLINK-21272][checkpointing] Report incomplete metrics when aborted,2
[FLINK-21269][runtime] Add ResourceProfile field to SlotSharingGroup,2
[FLINK-21269][runtime] Introduce runtime interfaces for specifying SlotSharingGroup-based resource requirementsThe specified resource requirements will be passed on all the way to the corresponding SlotSharingGroup in ExecutionGraph.This closes #14860,4
[FLINK-20254][hive] Make PartitionMonitor fetching partitions with same create time properlyThis closes #14766,1
[FLINK-21210][coordination] ApplicationClusterEntryPoint explicitly closes PackagedProgram,1
[FLINK-21254] Add Created state for DeclarativeScheduler,1
[FLINK-21254] Add tests for Created state and State interfaceThis closes #14870,1
[refactor] Extract common logic for serializing delimited list,2
[refactor] Move RocksDBCompositeKeyBuilder to a common package,5
[hotfix] Fix Nonnull annotation in RegisteredKeyValueStateBackendMetaInfoSome of the methods are annotated with @Nullable even though theyforward to methods annotated with @Nonnull.,5
[hotfix] Add a wildcard type in heap state backend related classes,1
[FLINK-20978] Extract common restoring logic from RocksDB,5
[FLINK-20978] Implement HeapSavepointRestoreOperationThis commit implements the logic of restoring a heap keyed state backendfrom a savepoint in a unified binary format. It eagerly deserializes allstates and populates the in memory structures.,2
[FLINK-20978] Implement SavepointKeyedStateHandleIntroduce a marker SavepointKeyedStateHandle interface for state handles that describe savepoints. Based on the interface we can later decide which strategy to use when restoring from the handle.,0
[FLINK-20978] Implement test for migrating from Rocks savepointThis closes #14648,3
[hotfix] Fix RocksDB resource handling in RocksKeyGroupsRocksSingleStateIteratorTest,3
[FLINK-21066][runtime][checkpoint] Refactor CheckpointCoordinator to compute tasks to trigger/ack/commit dynamicallyThis closes #14734,4
[hotfix][jdbc] Fix typo in UnsignedTypeConversionITCaseThis closes #14876 Co-authored-by: xiaozilong <xiaozilong@bigo.sg>,1
[FLINK-21208][python] Make Arrow Coder serialize schema info in every batchThis closes #14844,5
[FLINK-21238][python] Support to close PythonFunctionFactory manuallyThis closes #14842,1
[FLINK-21273][coordination] Remove unused ExecutionVertexSchedulingRequirements,1
[FLINK-21047][coordination] Fix the incorrect registered/free resources information exposed by SlotManagerThis closes #14869,5
"[hotfix][runtime] Remove unused check for the ResourceSpec of SlotSharingGroup in calculation manage memory fractionAs the resource requirement will be set to the ResourceProfile of SlotSharingGroup, the calculation of manage memory fractionshould be aligned.",2
[hotfix][runtime] Remove unused ResourceSpec field in SlotSharingGroup,1
[FLINK-21270][runtime] Add ResourceProfile field to ExecutionSlotSharingGroup,2
[FLINK-21270][coordination] Generate the slot request respect to the resource specification of SlotSharingGroup if presentThis closes #14865,2
[hotfix][tests] TestingPhysicalSlot rejects payload if one is already assigned,3
[hotfix][coordination] Clarify shared slot number & allocation ids,0
[FLINK-21098][coordination] Add SlotAllocator,1
[hotfix][tests] Fix compile error,0
[hotfix][docs] Fix typo,2
[hotfix][docs][example] Correct variable name,2
[hotfix][docs] Removes link formatting of anchorsThe anchors for the docker-compose.yml were formatted like actual links whichmight be confusing to readers. A click wouldn't have had any impact.,5
[hotfix][tests] Extract PendingCheckpointTest.abort method,3
[FLINK-21033][checkpointing] Remove PendingCheckpoint.statsCallback,4
"[FLINK-21155][tests] Fix FileSourceTextLinesITCaseThe problem of the test case was that it is reusing the MiniCluster. Moreover, it kills for everyTaskManager failure the TaskManager at the index 0. Since this is only possible once, all precedingTaskManager failure test will succeed because not TaskManager is killed.This commit fixes the problem by not reusing the MiniCluster across multiple tests.This closes #14855.",3
[FLINK-21303][coordination] Remove LogicalSlot#getPhysicalSlotNumber,2
[FLINK-20417][k8s] Create a new watcher when the old one is closed with HTTP_GONEThis closes #14837.,1
[FLINK-21102] Add ScaleUpController for declarative scheduler,1
[FLINK-21134] Rename EXECUTION_MODE to INTERNAL_CLUSTER_EXECUTION_MODE,2
[FLINK-21134] Introduce 'scheduler-mode' config optionThis closes #14790,5
"[FLINK-20957][task][tests] Make sure we enter the measured sleep after the Task thread started measuring backPressure/idle timeMake sure that the Task thread actually starts measuring the backpressure beforewe start the measured sleep. The WaitingThread is started from within the mailboxso we should first wait until mailbox loop starts idling before we enter themeasured sleepBug was easy to reproduce/verify after modifying `WaitingThread` starting sequence from:```executor.submit(  waitingThread::start,  ""This task will submit another task to execute after processing input once."");```to:```executor.submit(() -> {    waitingThread.start();    Thread.sleep(10);  },  ""This task will submit another task to execute after processing input once."");```",0
[FLINK-21013][table-planner-blink] Ingest row time into StreamRecord in Blink plannerThis closes #14787.,2
[FLINK-21312][checkpointing] Reset OperatorChain.isStoppingBySyncSavepoint properlyReset OperatorChain.isStoppingBySyncSavepoint fromLegacySourceFunctionThread so that StreamTask can readit without relying on completionFuture callbacks whichcan fire later.,1
[hotfix][tests] Fix init of SavepointITCase.testStopSavepointWithBoundedInput1. Only one (main) thread counts down BoundedPassThroughOperator.snapshotAllowedLatch so it is set to 12. InfiniteTestSource.createdSources is updated from run()3. Propagate the exception from InfiniteTestSource.run(),5
[hotfix] Enforce StateTable return IterableStateSnapshot,1
[FLINK-21206] Implement HeapKeyValueStateIterator,2
[FLINK-21206] Write savepoints in unified format from HeapStateBackendThis closes #14809,2
[FLINK-20847][checkpointing] Remove unused argument from shutdown() in CompletedCheckpointStore,1
[hotfix][checkpointing] Update javadoc for CompletedCheckpointStore.shutdown(),2
[FLINK-21225][table-planner-blink] Support OVER window distinct aggregates in Table APIThis closes #14877,1
[FLINK-19520][configuration] Add randomization of checkpoint config in ITCases.,5
[hotfix] Move SchedulerBase specific queryable state logic into KvStateHandler to make it reusable,1
[hotfix] Introduce ExecutionGraphHandler to factor out ExecutionGraph logic from the SchedulerBase,2
[hotfix] Do not pass SchedulerNG to OperatorCoordinatorHolder,1
[hotfix] Introduce OperatorCoordinatorHandler for factoring out logic from the SchedulerBase,2
[FLINK-21256] Add Executing state for declarative scheduler,1
[FLINK-21256] Add tests for Executing state,3
[FLINK-21257] Add Restarting state for declarative schedulerThis closes #14879,1
[FLINK-21257] Add RestartingTest,3
[FLINK-21193][docs] Migrate Flink docs from Jekyll to Hugo,2
[FLINK-21193][docs] Update Rest API Generator to Hugo expand syntax,5
[hotfix] regenerate configurations,5
[FLINK-21193][docs] Update licenses,5
[FLINK-21193][docs] Update README,5
[FLINK-21193][release] Update source release script for Hugo,5
[FLINK-21193][release] Update python Sphynx build,5
[FLINK-21193][docs] Update docs ci check for hugo,2
[hotfix][docs] Add additional padding to main content div,1
[FLINK-21193][docs] Add buildbot script for building documentationThis closes #14903,2
"Revert ""[FLINK-21206] Implement HeapKeyValueStateIterator""This reverts commit d67ace2395e21188ad9663e36a1caaf357867897.",4
"Revert ""[FLINK-21206] Write savepoints in unified format from HeapStateBackend""This reverts commit fc995d3af957941e0e16e56e6830ef97acbadfd1.",4
[hotfix][state] Improve logging in AbstractKeyedStateBackend,2
[FLINK-21260] Add Finished state for DeclarativeScheduler,5
[FLINK-21260] Add tests for Finished stateThis closes #14912,5
[FLINK-21342][tests] Add '@Ignore' to *TestInstance classes,3
[hotfix][ci] Fix hugo docs builds,2
[FLINK-21258] Add Canceling state for DeclarativeScheduler,1
[FLINK-21258] Add test for Canceling stateThis closes #14909,3
[hotfix][tests] Import static constant in SourceStreamTaskTest,3
[FLINK-21312][checkpointing] Don't endInput() if stopped externally1. Only unset IsStoppingBySyncSavepoint in SourceStreamTask if wasnot stopped externally or cancelled2. Also unset it in StreamSource so that endInput is consistentfor head and tail operators3. ITCase is replaced with a lower level test.Legacy Source Thread needs checkpoint lock after it exits run()and before it re-sets OperatorChain.StoppingBySyncSavepoint.This creates a race condition because that lock is held bythe Task thread performing sync-savepoint.On a lower level there is no such problem because there isno checkpoint completion notification.,1
[FLINK-21363][docs] Fix baseurl in documentationThis closes #14926,2
[hotfix][docs] reintroduce google analytics and fix broken edit page,2
[FLINK-21361][table-planner-blink] Match on CatalogTable interface in FlinkRelMdUniqueKeysMatching on a specific implementation can break applications usingcustom catalog table implementations.This closes #14922.,2
[hotfix] fix mobile layout on documentation,2
[FLINK-21138] - User ClassLoader in KvStateServerHandler,0
[FLINK-21138][tests] Register serializer instance in AbstractQueryableStateTestBase.testCustomKryoSerializerHandlingThe test AbstractQueryableStateTestBase.testCustomKryoSerializerHandling only works if one registers an actualserializer instance.,1
[FLINK-21138] Fix classloader on QueryableStateClient,0
[FLINK-21138] Explicit Classloader in QueryableStateClient,2
[FLINK-21274][runtime] Change the ClusterEntrypoint.runClusterEntrypoint to wait on the result of clusterEntrypoint.getTerminationFuture().get() and do the System.exit outside of the future callback,5
[FLINK-21274] Block main thread when running the TaskManagerRunnerIn order to ensure that the TaskManager properly shuts down we need to letthe main thread block on the execution of the TaskManager. This will ensurethat there is always a non-daemon thread as long as the TaskManager runs.This closes #14906.,1
[FLINK-21315][state-processor-api]return DataSource<T> such that users can set operator names,1
[FLINK-21315][state-processor-api]set an operator name when collecting existing operator states.This closes #14907,1
[FLINK-21337] ComparableInputTypeStrategyTests is not running,1
[FLINK-21295][table-api] Support 'useModules' and 'listFullModules' in TableEnvironment and ModuleManagerThis closes #14895,1
[hotfix][docs] fix formatting of release notes,0
[hotfix] Fix ASCII art in the OperatorChain JavaDoc,2
[FLINK-21318][sql-client] Disable hive catalog tests in ExecutionContextTest for jdk 11This closes #14935,3
[hotfix][core] Remove unused HybridMemorySegment#getOffHeapBuffer.This method is only used in tests.,3
[FLINK-20663][core] Introduce MemorySegment#processAsByteBuffer.,2
[FLINK-20663][runtime] Migrate use cases of MemorySegment#wrap to MemorySegment#processAsByteBuffer.,1
[FLINK-20663][core] Forbid calling HybridMemorySegment#wrap on unsafe segments.,2
[FLINK-20663][core] Release unsafe memory instantly on segment freed.This closes #14904,2
[FLINK-21365][runtime] Document and make the contract of FutureUtils.ResultConjunctFuture more explicitAdd an explanation why is the current solution working and alsoclean it up a little bit (dropping unecessary volatile and adding final keyword).,1
[FLINK-21259] Add Failing state for DeclarativeScheduler,0
[FLINK-21259] Add tests for Failing stateThis closes #14910,0
[FLINK-21339][tests] Enable and fix ExceptionUtilsITCase,0
[FLINK-21338][test] Disable broken tests,3
[FLINK-21338][test] Relax ITCase naming constraints,3
[FLINK-21366][doc] mentions Maxwell as CDC tool in Kafka connector documentationThis closes #14743,2
[hotfix][docs] Correct rendering of maven modules,2
[hotfix][tests] Consolidate matching logic,2
[hotfix][tests] Rename ContainsCauseMatcher,1
[hotfix][tests] Add matcher for finding exception cause by Class,1
[FLINK-21377][coordination][tests] Move JobMaster QS tests to separate file,2
[FLINK-21377][coordination][tests] Refactor JobMasterQueryableStateTest,3
[FLINK-21377][coordination][tests] Provide enough slots for job deployment,1
"[FLINK-21377][coordination][tests] Relax job status checkWhether the job is FAILING/FAILED largely depends on whether the job deployment has started or not, and this is a detail that is not fully controlled in the test.",3
[FLINK-21384][docs] Automatically copy maven dependencies to clipboard on clickThis closes #14952,2
[hotfix][tests] Move test checkpoint component classes to upper level,3
[hotfix][coordination] Remove leftover comment,4
[hotfix][coordination] Assert that return of logical slot does not fail,0
[hotfix][coordination] Log that EG reached terminal state,2
[hotfix][conf] Honor explicit ENABLE_DECLARATIVE_RESOURCE_MANAGEMENT settings,1
"[hotfix][coordination] Clarify visibilityThe handlers are only supposed to be accessible by sub-classes, while the execution graph is only visible for testing purposes.",3
[hotfix][coordination] Add StateWithExecutionGraph#reportCheckpointMetrics,1
"[FLINK-21100][coordination] Adjust SharedSlot lifecycleThe external-release callback is now only run once the last logical slot has been returned.In practice the use-case for the callback is to bind a release call to the return of the last logical slot.The current behavior however muddies this contract since it may also be called from #release; leading to cases where #release is called twice on a single slot.This case got even worse when the slot was released before all logical slots have been returned; in this case all allocated logical slots are automatically being returned, triggering the callback, triggering another release call while the first one hasn't even finished yet.",5
[FLINK-21100][coordination] Refactor JMOptions#Scheduler to enum option,4
[FLINK-21100][coordination] Pass FatalErrorHandler to scheduler factory,0
[FLINK-21100][coordination] Add DeclarativeScheduler,1
[FLINK-21100][coordination] Add system property for enabling declarative scheduler,0
[FLINK-20534] Add Flink 1.12 MigrationVersionThis closes #14956.,2
[FLINK-20534] Add Flink 1.12 snapshots for TypeSerializer upgrade testsThis closes #14956.,3
[FLINK-14869][core] Introduce Resource#isZero,2
[FLINK-14869][core] Discard zero-valued extended resources in ResourceSpec,2
[FLINK-14869][core] Discard zero-valued extended resources in ResourceProfileThis closes #14955,2
[FLINK-19503][state] Add StateChangelog API,4
[FLINK-20580][rpc] Separate wire value class from user values,1
[FLINK-20580][core] Does not accept null value for SerializedValueThis closes #14936.,2
[FLINK-21381][docs] Add information about service account permissions to K8s HA service documentationThis closes #14946.,2
"[FLINK-16947][Azure] Attempt to fix maven network issuesThis updates the base docker image to use a modified maven version with a fixed http wagon version.Diff on the Dockerfile:diff --git a/Dockerfile b/Dockerfileindex dc8f1b5..68d080d 100644--- a/Dockerfile+++ b/Dockerfile@@ -37,6 +37,17 @@ RUN mkdir -p /usr/share/maven /usr/share/maven/ref \   && rm -f /tmp/apache-maven.tar.gz \   && ln -s /usr/share/maven/bin/mvn /usr/bin/mvn+# put custom http-wagon. More details: https://issues.apache.org/jira/browse/FLINK-16947?focusedCommentId=17285028&page+RUN cd /usr/share/maven/lib/ \+  && rm wagon-http-*-shaded.jar \+  && curl -O https://jitpack.io/com/github/lhotari/maven-wagon/wagon-http/5ff79d284/wagon-http-5ff79d284-shaded.jar++# add commons logging (needed for custom wagon)+RUN cd /tmp \+  && wget https://mirror.synyx.de/apache//commons/logging/binaries/commons-logging-1.2-bin.zip \+  && unzip commons-logging-1.2-bin.zip \+  && cp commons-logging-1.2/commons-logging-1.2.jar /usr/share/maven/lib/+ ENV MAVEN_HOME /usr/share/mavenThis has been committed in https://github.com/rmetzger/flink-ci/commit/98ad098128398c6b0621a7b17bea05fc0fbf1c07",2
[hotfix][docs] fix tab syncronization in documentationFixes the synchronization of tabs so that if a tab group on thepage does not contain the selection it will remain in a validstate of its existing selected tab.,2
[hotfix][runtime] Remove unused LegacyActiveResourceManagerFactory,1
[hotfix][runtime] No need to delete TM resource id from active RM configuration.The active resource manager drivers will overwrite the resource ids anyway before starting TMs.,5
[hotfix][runtime] Refactor configuration preparations for resource managers.,5
[FLINK-17061][runtime] Unset TM total process/flink memory size for fine-grained resource management.This closes #14954,2
[FLINK-21360][coordination] Make resource timeout configurable,5
[FLINK-21380][coordination] Hide terminal ExecutionGraph in StateWithExecutionGraph,2
[FLINK-21221][runtime] Deduplication for multiple ResourceCountersThis closes #14897.,2
[hotfix][docs] Mention Kubernetes HA on the Production Readiness page,2
[FLINK-21410][docs] Document checkpoint interval trade-offsThis closes #14964,2
[FLINK-21213][task] Degrade log level to INFO when ignore to decline checkpoint as task not running,1
[hotfix][runtime] Fixes ArchivedExecutionGraphTestThe previously used globalFailure only set the failureInfo on a ExecutionGraph-level. I switched to updateTaskExecutionState which will also set thefailureInfo on an Execution-level,5
[hotfix][runtime] Fixes checkstyle errors,0
[hotfix][runtime] Adds failure cause to log messageThe log message when transitioning to an exeuctionState having a failure causedidn't print the cause itself. This is fixed now.,0
[FLINK-21187][runtime] Adds exception historyThe initial implementation only collects the actual exception withoutconsidering any other failures that might happen concurrently.This closes #14798.,0
[hotfix][core] Minor code clean-ups in HeapMemorySegment.,4
[FLINK-21417][core] Migrate on-heap use cases of HybridMemorySegment to HeapMemorySegment.,1
"[FLINK-21417][core] Move some access methods from HybridMemorySegment to MemorySegment.This is in preparation for turning HybridMemorySegment into OffHeapMemorySegment, with all on-heap related logics moved out.The moved methods all have common implementations that are applicable for both heap and off-heap segments.- Some of the methods are overridden in HeapMemorySegment for efficiency. However, there's no harm to keep the commonly applicable implementations in the base class, despite they may only be used for the off-heap segments.- `put(DataInput,int,int)` and `get(DataOutput,int,int)` are partially moved. Only code paths applicable for both heap and off-heap segments are moved.",4
[FLINK-21417][core] Turn HybridMemorySegment into OffHeapMemorySegment.All on-heap specific logics are moved out.,4
[FLINK-21417][core] Seprate OffHeapMemorySegment into DirectMemorySegment and UnsafeMemorySegment.,2
[FLINK-21417][core] Re-abstract wrapping methods for memory segments.,2
[FLINK-21417][core] Update MemorySegmentFactory with explicit segment types.This closes #14966,5
[FLINK-21412][python] Fix Decimal type which doesn't work in UDAF and expression DSLThis closes #14973.,1
[FLINK-20536][tests] Update migration tests of CEPMigrationTest to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of AbstractNonKeyedOperatorRestoreTestBase to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of AbstractKeyedOperatorRestoreTestBase to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of FlinkKafkaProducerMigrationTest to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of ContinuousFileProcessingMigrationTest to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of TypeSerializerSnapshotMigrationITCase cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of WindowOperatorMigrationTest to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of FlinkKinesisConsumerMigrationTest to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of FlinkKafkaConsumerBaseMigrationTest to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of StatefulJobSavepointMigrationITCase (Java version) to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of StatefulJobWBroadcastStateMigrationITCase (Java version) to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of StatefulJobSavepointMigrationITCase (Scala version) to cover migration from 1.12,3
[FLINK-20536][tests] Update migration tests of StatefulJobWBroadcastStateMigrationITCase (Scala version) to cover migration from 1.12,3
"[FLINK-21297][table] Support 'LOAD/UNLOAD MODULE' syntaxSupport 'LOAD/UNLOAD MODULE' syntax both in SQL parser, TableEnvironment and SQL CLI.This closes #14944",1
"Revert FLINK-21417 due to performance regression.- 86015c766ba186f18c2b3b41c3900ea4f809a1c2: ""[FLINK-21417][core] Update MemorySegmentFactory with explicit segment types.""- 1d0f5e5bc4e4926554a2f381b96ee4d569de8af5: ""[FLINK-21417][core] Re-abstract wrapping methods for memory segments.""- 94362fa8917618ea3fa2a46b072abe528034070d: ""[FLINK-21417][core] Seprate OffHeapMemorySegment into DirectMemorySegment and UnsafeMemorySegment.""- 046f950a820b35fde6f411fb90f42ab1b5eaaeff: ""[FLINK-21417][core] Turn HybridMemorySegment into OffHeapMemorySegment.""- 10df8703a24b040481d1f56db5a74a3964c350c9: ""[FLINK-21417][core] Move some access methods from HybridMemorySegment to MemorySegment.- 0a664e1869e62005c37de2de0c19148468f1f059: ""[FLINK-21417][core] Migrate on-heap use cases of HybridMemorySegment to HeapMemorySegment.""",1
[FLINK-21402] Introduce SlotPoolServiceSchedulerFactory to bundle SlotPoolService and Scheduler factoriesThe SlotPoolServiceSchedulerFactory bundles the SlotPoolServiceFactory and SchedulerNGFactory to make sure thatwe only instantiate valid SlotPoolService and SchedulerNG combinations.This closes #14969.,1
[FLINK-21390] Rename DeclarativeScheduler to AdaptiveSchedulerNote that this commit also changes the system property to enable the adaptive schedulerfrom flink.tests.enable-declarative-scheduler to flink.tests.enable-adaptive-scheduler.This closes #14970.,3
[FLINK-21176][docs-zh] Translate the updates of 'avro-confluent.md' to ChineseThis closes #14896,1
[hotfix][table-planner-blink] Fix typo in PlannerContextThis closes #14812,2
[FLINK-21206] Implement HeapKeyValueStateIterator,2
[FLINK-21206] Write savepoints in unified format from HeapStateBackendThis closes #14925,2
[hotfix] Add timeout to bash scripts waiting for an event,1
[FLINK-21362][coordination] Move State.onEnter() logic into constructorThis closes #14963,2
[hotfix][checkpointing] Extract CheckpointSubsumeHelperThis is a pre-requisite refactoring for a subsequent bug fix.,0
[FLINK-21351][checkpointing] Don't subsume last checkpointWhen a savepoint is added to CompletedCheckpointStoreall previous checkpoints will be removed if number toretain is 1.This makes future incremental checkpoints invalid sincethey can refer to the discarded state.,1
"[hotfix][tests] Remove mock from testAddCheckpointWithFailedRemoveAdditionally, remove dead code and check that anexception was thrown.",4
[FLINK-21426][docs] adds English details to jdbc sink connectorThis closes #14975,5
[FLINK-20994][python] Add public method to create TableEnvironment in PyFlinkThis closes #14760.,2
[FLINK-21180][python] Move the state module from 'pyflink.common' to 'pyflink.datastream'This closes #14788.,5
[hotfix][runtime] Fix unstable TaskManagerCheckInSlotManagerTest#testTaskManagerIsNotReleasedInCaseOfConcurrentAllocation,3
[hotfix][runtime] Move generating PendingTaskManagerId to inside PendingTaskManager.,4
[hotfix][core] Update Resource#hashCode() to ignore BigDecimal scale.,5
[FLINK-21433][runtime] Replace defaultSlotProfile with numSlots for creating PendingTaskManager.This is to make sure `totalSlotResourceProfile == defaultResourceProfile.multiply(numSlots)`.This closes #14983,2
[FLINK-21435][table] Use a dedicated SQL expression in Table APIThis closes #14986.,1
[hotfix] Rename keys of JobManagerOptions.MIN_PARALLELISM_INCREASE and .RESOURCE_WAIT_TIMEOUTRename jobmanager.declarative-scheduler. to jobmanager.adaptive-scheduler to align it with FLINK-21390.,2
"[hotfix][table-planner-blink] Merge tests of MiniBatchGroupWindowITCase into GroupWindowITCaseThe Group Window Aggregate doesn't support mini-batch, so the test class doesn't make sense.",1
"[hotfix][table-planner-blink] Rename WindowAggregateTest to GroupWindowTestWe are going to introduce the new window TVF based aggregates,in order to avoid confusing, we call the legacy window aggregate ""GroupWindow"",and the new window aggregate ""WindowAggregate"".",1
"[FLINK-19608][table-planner-blink] Introduce SqlOperator definitions for TUMBLE, HOP, CUMULATE table-valued functionWe don't use the definitions in Calcite, because we have some special needs:1) we have time attribute type check on the DESCRIPTOR time column2) we need to derive type of window columns from the time attribute type (e.g. TIMESTAMP_LZ)3) we will output an additional column `window_time` which extends time attribute typeThis closes #14905",1
"[FLINK-19608][table-planner-blink] Support translating into TVF based window aggreagte physical nodeThis commits implement many parts:1) [FLINK-19611] Introduce WindowProperties MetadataHandler to propagate window properties.2) Recognize window aggregate and translate `FlinkLogicalAggregate` into `StreamPhysicalWindowAggregate`, by introduce `StreamPhysicalWindowAggregateRule`3) Push window TVF into `StreamPhysicalWindowAggregate`, by introduce `PushWindowTableFunctionIntoWindowAggregateRule`4) [FLINK-21304] Support split distinct aggregate for TVF based window aggregate, by introduce `ExpandWindowTableFunctionTransposeRule`5) Support cascading window aggregate, mainly fix `RelTimeIndicatorConverter` to propagate time attribute of window_time.This closes #14905",0
"[FLINK-19608][table-planner-blink] Introduce TVF based window aggregate exec nodeThis commits contain following parts:1) Introduce StreamExecWindowAggregate to translate into slicing window aggregate operator2) Update AggsHandlerCodeGenerator to support generate window properties based on window end timestamp3) Fix implementation of WindowedSliceAssigner::getWindowStart, it must delegate calls to real slice assignerThis closes #14905",1
[FLINK-19945][filesystem] Support sink parallelism configuration for FileSystem connectorThis closes #14727,5
[FLINK-21203][table-planner-blink] Prevent emission of identical update records in LastRowFunctionThis closes #14863,1
"[FLINK-21028][task] Do not interrupt the source thread on stop with savepointCurrently stop with savepoint relies on the EndOfPartitionEvents propagation and performsclean shutdown after the stop with savepoint (which can produce some records to process afterthe savepoint while stopping). If we interrupt source thread, we might leave the newtork stackin an inconsitent state. So, if we want to relay on the clean shutdown, we can not interruptthe source thread.",4
[FLINK-11678][runtime] Removes unnecessary obsolete method overwritingRestfulGateway provides the exact same method signature.DispatcherGateway.requestJob became obsolete with the changes made in ce49a904.,4
[hotfix][test] Removes unused inner class,1
[FLINK-21188][runtime] Introduces ExecutionGraphInfoThis closes #14804.,5
[FLINK-21101][Azure] Add nightly profile to run all tests with the adaptive scheduler,3
[FLINK-21005][table] Introduce new runtime provider for unified Sink API and implement in plannerThis closes #14822,1
[hotfix][table-planner-blink] Fix the failed FileSystemTableSinkTest,5
[hotfix] Drop compatibility with Flink <= 1.5This commits lets us clear some codepaths. It should still be possibleto migrate from Flink 1.5 <= through any newer version.,1
[FLINK-19970] State leak in CEP OperatorsThis commit fixing cleaning up timed out state that were otherwise heldback by newer states that were not timed out.Instead of keeping reference counter just for shared buffer nodes wekeep reference counters for edges as well. This lets us clean up nodesbased when we time out all compatible paths instead of waiting for all successors from different paths to time out.This closes #14979,4
[FLINK-19970] Update documentation regarding backwards compatibility,2
[hotfix][docs] Fix broken gh_link usage,2
[FLINK-21451][coordination] Remove JobID from TaskExecutionState,4
"[hotfix] Upgrade the os-maven-plugin depency, to version 1.7.0That would ensure that RISC-V arch. is supported.I tested it on a U54-MC based board - it worked.This closes #14934",1
[FLINK-21489][docs] Hugo docs add two anchor links to headers,2
[hotfix][docs] reintroduce build_docs.sh scriptThis closes #15008,2
[hotfix] Remove unnecessary if in RocksIncrementalSnapshotStrategy,4
[hotfix] Cleanup raw types around PriorityQueueSetFactory,1
[refactor] Remove AbstractRocksDBRestoreOperationSo far both the RocksFullSnapshotRestoreOperation andRocksIncrementalRestoreOperation extended fromAbstractRocksDBRestoreOperation in order to share some functions.However it required e.g. unnecessary parameters to be passed just tofulfill the requirements of the base class. Moreover a base class makesit harder to extend classes independently.This commit changes sharing the common code to use composition insteadof inheritance.,1
[refactor] Extract common interface for a single Rocks stateThis commit introduces an interface for iterating over a single state inRocksDB state backend. This is a prerequisite for storing heap timersalong with other states from RocksDB.,5
[hotfix] Fix RocksIncrementalCheckpointRescalingTestFew cases that were checked in the test are actually illegalcombination. They were testing keys that should never end up in a givensub task as they do not belong to a key group owned by the task.,3
[FLINK-21344] Handle heap timers in Rocks stateWe serialize the heap timers into the same format as if they wereactually stored in RocksDB instead of storing them in a raw operatorstate. It lets users change between using heap and RocksDB timers.,5
"[FLINK-21344] Do not store heap timers in raw operator state for asavepointWe do no longer serialize the heap timers in RocksDB state backend whentaking a savepoint. We still do it for checkpoints though.There is one gotcha in the PR, that the StateConfigUtil#isStateImmutableInStateBackendassumes the knowledge that checkpoints behave differently for heaptimers than savepoints.This closes #14913",5
[FLINK-21344] Test legacy heap timers,3
[FLINK-20659][yarn][tests] Add flink-yarn-test README,3
[FLINK-21481][build] Move git-commit-id-plugin execution to flink-runtime,2
[FLINK-21399][coordination][tests] Refactor registerSlotsRequiredForJobExecution,1
[FLINK-21399][coordination][tests] Provide enough slots for job deployment,1
[FLINK-21484][rest] Do not expose internal CheckpointType enum via the REST APIInstead use an intermediate class that can provide a backward compatibility anddetach the CheckpointType from the REST API.,1
[hotfix][task] Rename isStoppingBySyncSavepoint to ignoreEndOfInput,0
[FLINK-21453][checkpointing][refactor] Replace advanceToEndOfTime with new CheckpointType.SAVEPOINT_TERMINATE,1
"[FLINK-21453][checkpointing] Do not ignore endOfInput when terminating a job with savepointWhen job is stopping with savepoint WITH drain flag (terminating), there is no intentionto resume the job ever from that savepoint. Hence we have to make sure that we flushall of the buffered records from the job. To do that, we need to invoke endOfInput.",1
[FLINK-21358][docs] Adds savepoint 1.12.x to savepoint compatibility diagramThis closes #14920.,1
[FLINK-19466][runtime / state backends] Add default savepoint configuration to StreamExecutionEnvironmentIf a savepoint is specified in code it will always override anyconfiguration set in the clusters flink-conf. Conceptually savepointsare separate from checkpoints but internally they rely on the samemachinery. To avoid exposing savepoints in the CheckpointStorageinterface we instead override the SAVEPOINT_DIRECTORY configurationin the CheckpointStorageLoader,5
[FLINK-19466][runtime / state backends] Add JobManagerCheckpointStorage and FileSystemCheckpointStorage,5
[FLINK-19467][runtime / state backends] Implement HashMapStateBackend and EmbeddedRocksDBStateBackend,5
[FLINK-19467][examples] Update examples to new API,1
[FLINK-19467][docs] Regenerate configurations,5
[FLINK-19467][e2e] Migrate end-to-end tests to the modern APIThis closes #13912,3
[hotfix][docs] fix version tag in kubernetes docs,2
[FLINK-21343] Update documentation regarding unified savepoint formatThis closes #14981,2
fixup! [FLINK-21453][checkpointing][refactor] Replace advanceToEndOfTime with new CheckpointType.SAVEPOINT_TERMINATE,1
[FLINK-18550][sql-client] Use TableResult#collect to get SELECT result for sql clientThis closes #14958,1
[FLINK-21442][connectors/jdbc] Fix XaSinkStateSerializer serialization,0
[FLINK-21492] Don't let ActiveResourceManager swallow stack trace of exceptionThis closes #15010.,1
[FLINK-21490][datastream] Make job graph generation deterministic for multiple input nodes.Traversing the stream graph randomly for different input nodes during job graph generation causes the gates of multi-input operators to be swapped on restart. Unaligned checkpoints build on the assumption that the order is deterministic though.,5
"[FLINK-21490][tests] Harden UnalignedCheckpointITCase.The source readers currently inferred the number of checkpoints individually potentially causing a drift. Number of checkpoint and restarts is now calculated in the coordinator and propagated to the readers keeping them in sync. The mechanism to infer the number of restarts has been improved by directly notifying enumerator when a source reader is created (RuntimeContext is unavailable in source).Further, if the payload of the test passes MAX_INT, then checkHeader fails as it uses the upper 4 bytes of the long to check for magic bytes. A checkstate ensures that no overflow happens and aborts the test with a meaningful message. checkHeader further prints the expected and actual value.This commit includes some refactorings for the upcoming UnalignedCheckpointRescaleITCase which eases the maintenance of the test in 1.12 and master branch.",3
"[hotfix][core] Recovered IteratorSourceReader correctly checks splits on start.Currently, start checks the iterator which is always null before polling. This violates the invariant in notifyNoMoreSplits.",0
"[FLINK-21452][connector/common] Stop snapshotting registered readers in source coordinator.Sources used to store their registered readers into the snapshot. However, when downscaling, they have unmatched readers that violate a couple of invariants.The solution is to not store registered readers - they are re-registered on restart anyways.To keep it backward compatible, the best option is to always store an empty list of readers while writing the snapshot and discard any recovered readers from the snapshot.",1
[FLINK-21503][tests] Fix unstable UnalignedCheckpointCompatibilityITCase,0
[FLINK-21114][python] Add ReducingState and corresponding StateDescriptor for Python DataStream APIThis closes #14991,5
"[hotfix] Fix CheckpointCoordinatorTest to be consistent with the current implementationBefore, all three of these tests were exactly the same code: - testCheckpointAbortsIfTriggerTasksAreNotExecuted - testCheckpointAbortsIfTriggerTasksAreFinished - testCheckpointAbortsIfAckTasksAreNotExecutedThis removes testCheckpointAbortsIfAckTasksAreNotExecuted and changes the firsttwo tests to test different states. The first test has tasks in CREATED stateand the second test has them in FINISHED state, to reflect the name of thetest.",3
"[FLINK-21067][runtime][checkpoint] Modify the logic of computing which tasks to trigger/ack/commit to support finished tasksTo support checkpoint after tasks finished, for eachcheckpoint we would like to trigger the new ""root"" tasks,and wait / commit for all the running tasks. Thus this PRmodifies the logic of identifying the tasks to trigger / wait/ commit.This closes #14740",2
[hotfix] Complete AdaptiveScheduler.getTerminationFuture() when reaching Finished state,5
[FLINK-21398][tests] Fix JobMasterTest.testRestoringFromSavepoint and .testRestoringModifiedJobFromSavepointFix JobMasterTest.testRestoringFromSavepoint to also work with the AdaptiveScheduler by registering first slotsbefore checking the savepoint restore.Fix JobMasterTest.testRestoringModifiedJobFromSavepoint by splitting it into testRestoringModifiedJobFromSavepointFailsand testRestoringModifiedJobFromSavepointWithAllowNonRestoredStateSucceeds and then moving these tests to AdaptiveSchedulerTestand DefaultSchedulerTest to be more targeted.This closes #14999.,1
[hotfix] Add logging statement when the ExecutionGraph creation failed in the WaitingForResources state,0
[hotfix] Add logging to the DefaultAllocatedSlotPool,2
"[FLINK-21435][table] Implement Schema, ResolvedSchema, SchemaResolverThis closes #14996.",0
[hotfix][docs] Fix computed columns documentation,2
[hotfix][tests] Adds log message to MiniClusterWithClientResource shutdown,5
"[hotfix][task] Interrupt source legacy thread on failure.If a legacy source task fails outside of the legacy thread, the legacy threadblocks proper cancellation (completion future never completed).",5
[hotfix][test] Adds unit test for local and global failure happened concurrentlyThis test should verify that the scheduler works as expected when a localfailure succeeds a global fail-over operation before the restarting happened.,0
"[FLINK-21030][runtime] Adds trigger for global failoverWe cannot assume that the termination future is finishing when triggering asynchronous savepoint. It might be that the savepoint creation succeeds butthe graceful shutdown of the job fails. In this case, the job termination doesnot complete. The job might end up in an inconsistent state. That's why, aglobal fail over is triggered if the scheduler observes one of the currentexecutions ending up in a non-finished state.Unit tests and integration tests are added to cover this use-case.This closes #14847.",1
[hotfix][test] Removes unused jobId parameter,2
"[FLINK-21517][tests] Test harnesses should not bypass serialization stack for eventsSince FLINK-19297 we accidentally removed a test coverage for event (de)serialization from a lot of the unit tests,that were/are using test harnesses. For example because of that I almost broke 1.12.2 release,since `stop-with-savepoint --drain` was never only tested using test harnesses (didn't have an ITCasesand/or end to end test).",3
[FLINK-21515][tests] Fix testStopWithSavepointShouldNotInterruptTheSource instabilitySourceStreamTaskTest.testStopWithSavepointShouldNotInterruptTheSourceis unstable because the latch  can be reset after triggering (while it`ssupposed to be reset before the test starts).,3
[FLINK-21518][tests] Fix testMinCheckpointPause instabilityThe instability is caused by last assertion depending on timing.Solve by waiting on condition.Another issue is that failure can cause RejectionExecutionException.This is caused by shutting down executor (in tests finally block)without shutting down CheckpointCoordinator.Solve by shutting down CheckpointCoordinator first.,3
[hotfix][state/heap] Improve error messages,0
"[hotfix][tests] Disable incremental checkpoints in CEPOperatorTestThe test doesn't support incremental checkpoints and currently worksonly because state.backend.incremental is set to false by default.More specifically, if the snapshots that are created intestKeyedCEPOperatorCheckpointingWithRocksDB / testKeyedCEPOperatorNFAUpdateWithRocksDBare incremental then they may contain a placeholder StateHandle.In production, it is supposed to be replaced by the actual handle upon recovery by JM.However, in tests JM is not instantiated and TM (harness) tries to use place holders which causes exception.",1
[hotfix][tests] Improve ProcessingTimeWindowCheckpointingITCase1. Prevent from hanging out if stream contains duplicates2. Improve error reporting,0
[hotfix][checkpointing] Log detailed statistic (TRACE)Can be enabled with:logger.checkpoint.name = org.apache.flink.runtime.checkpointlogger.checkpoint.level = TRACE,2
[hotfix][state] Serialize KeyGroupsStateHandle in shared Incremental state handleMotivation: allow rescaling of HeapBackend state,1
[hotfix][coordination] Move utility profiles to FineGrainedSlotManagerTestBase,3
"[hotfix][runtime] Directly pass ResourceCounter as the totalRequirements to the RequirementMatcherAs the ResourceCounter is immutable, we can directly pass it as a argument, this also give us chance to optimize the matching perfermance",4
[FLINK-21479][coordination] Introduce TaskManagerResourceInfoProvider as the read-only interface of TaskManagerTracker,5
[FLINK-21479][coordination] Provide TaskManagerResourceInfoProvider to ResourceAllocationStrategyThis closes #15015,5
[hotfix][yarn][tests] Whitelist non-critical debug messages,0
[FLINK-21404][yarn][tests] Increase resource timeout,1
[FLINK-12607][rest] Expose maxParallelism of jobs and vertices,2
[hotfix][state] Remove hardcoded backend class name checkThe motivation is to simplify FLIP-158 ChangelogStateBackend implementation.,4
[hotfix][rest][tests] Pin line-endings in API snapshot,3
[minor] Add parameter name in HeapSavepointStateBackendSwitchTest,3
[FLINK-21505] Factor snapshot resource creation out of RocksFullSnapshotStrategyThis will allow us to create snapshot resources for a savepoint withoutusing a snapshot strategy.,1
[FLINK-21505] Extract SnapshotExecutionType from SnapshotStrategyRunner,1
"[FLINK-21505] Enforce common/unified savepoint format at the operator levelBefore, we were relying on the fact that all keyed backends would usethe same strategy for savepoints.Now, we're forcing them at the API level to provide a SavepointResourcesthat we can then use to create a unified savepoint usingSavepointSnapshotStrategy.This closes #14982",1
"[FLINK-21231][sql-client] Support ""SHOW VIEWS"" in SQL clientThis closes #14840",1
[hotfix][k8s] Remove the unused variable in KubernetesResourceManagerDriver,1
[hotfix][k8s] Rename the implicit variable pod to podWithoutMainContainer,0
[FLINK-15656][k8s] Unify the main container name of jobmanager and taskmanager pod,2
"[FLINK-15656][k8s] Support pod template for native kubernetes integrationBenifit from flexibility of pod template, we could support init container, sidecar container, volume mount, pod security context, etc.",5
[FLINK-15656][k8s] Support to overwrite and merge some K8s fields from pod template and config options,5
[FLINK-15656][k8s][doc] Add documentation for pod templateThis closes #14629.,2
[FLINK-20658][jdbc] Establish connection through driver with given name (#15043),5
"[hotfix] Decrease logging level for DefaultLeaderElectionService.onLeaderInformationChangeThe debug logging level caused quite some cluttering of debug logs because of frequent MODIFIED eventswhen using the K8sHaServices. Since this logging statement is more confusing, this commit decreases thelog level to trace.",2
[FLINK-18726][table-planner-blink] Support INSERT INTO specific columns in blink planner (#14977),2
[hotfix][docs] fix formatting for filesystem table connector,5
[hotfix][docs] remove duplicated file,2
[hotfix][docs] fix broken link,2
[FLINK-21369][docs] Document Checkpoint StorageThis closes #14932,1
[hotfix][docs] clean up schema evolution page,4
[FLINK-21199][python] Introduce InternalTimerService In PyFlinkThis closes #14803,2
[FLINK-21482][table-planner-blink] Support grouping set syntax for Window TVF based aggregationThis closes #15003,1
[FLINK-21509][python] add 'withProcessingTime()' method call when creating proctime slide window assigner in 'StreamExecPythonGroupWindowAggregate' classThis closes #15027,1
[FLINK-20964][python] Introduce PythonStreamGroupWindowAggregateOperatorThis closes #14775,1
[FLINK-21202][python] Introduce TimeWindow and CountWindow in PyFlinkThis closes #14816,2
[FLINK-21519] Temporarily disable SQLClientHBaseITCase,2
[FLINK-21168][python][table-planner-blink] Add support for general python group window aggregate function in Physical Rule and NodeThis closes #14791,1
[FLINK-21497][coordination] Only complete leader future with valid leader,2
[hotfix][docs][examples] Add missing semicolons,1
[FLINK-21556] Temporarily disable StreamingKafkaITCase,2
[FLINK-21545] Temporarily disabled Kerberized YARN e2e tests,3
[FLINK-21521][k8s] Pretty print K8s specifications in logsThis closes #15052.,2
[hotfix][runtime] Add job ID to RuntimeContext,1
fixup: address feedback (update javadoc),2
[FLINK-21545] Temporarily disabled Python on Yarn tests,3
[FLINK-21178][Runtime/Checkpointing] Task failure should trigger master hook's reset() (#14890),1
"[FLINK-21298][table] Support 'USE MODULES' syntax both in SQL parser, TableEnvironment and SQL CLIThis closes #15005",1
"Revert ""[FLINK-21178][Runtime/Checkpointing] Task failure should trigger master hook's reset() (#14890)""This reverts commit 816ce969",4
[FLINK-21502][coordination] Reduce frequency of global re-allocate resourcesThe trigger of requirements check will be delay by a fixed time to reduce the frequency of it.This closes #15047,0
[FLINK-21434][python] Fix encoding error when using the fast coder to encode a row-type field containing more than 14 fieldsThis closes #15063.,5
[FLINK-21115][python] Add AggregatingState and corresponding StateDescriptor for Python DataStream APIThis closes #15028.,5
"[FLINK-21475][decl-scheduler] Support StateWithExecutionGraph.suspend when EG has reached globally terminal stateSince we don't execute StateWithExecutionGraph.onGloballyTerminalState immediately if the EG reachesa globally terminal state, the StateWithExecutionGraph needs to support #suspend calls when the EG isin a globally terminal state. In order to do this, the commit changes the precondition inStateWithExecutionGraph.suspend from EG.getState() == JobStatus.SUSPEND to EG.getState().isTerminalState()after calling EG.suspend.This closes #15059.",1
[FLINK-21581][runtime] Mark RuntimeContext.getJobId @PublicEvolvingThe JobID added in FLINK-21570 is1) a breaking change2) may be changed after removing DataSet API,5
[hotfix][docs] Fix merge conflicts of checkpointing.mdThis closes #15079,5
[FLINK-21021][python] Bump Beam to 2.27.0 (#14741),2
[FLINK-20496][state backends] Introduce RocksDB metadata block size setting.,1
[FLINK-20496][state backends] RocksDB partitioned index/filters option.Configure partitioned index and filters options according to 'https://github.com/facebook/rocksdb/wiki/Partitioned-Index-Filters'.This closes #14341.,5
[FLINK-21576][runtime] Remove legacy ExecutionVertex#getPreferredLocations()It is superseded by DefaultPreferredLocationsRetriever now and is no longer used.Its test ExecutionVertexLocalityTest is superseded by DefaultPreferredLocationsRetrieverTest.,3
[FLINK-21552][runtime] Unreserve managed memory if OpaqueMemoryResource cannot be initialized.This closes #15057,5
[hotfix][docs] wrong brackets in CREATE VIEW statement,1
[FLINK-21587][test] Harden FineGrainedSlotManagerTest and AbstractFineGrainedSlotManagerITCaseTrigger all RPCs in the main thread and complete future after required action.This closes #15080,1
[hotfix][dist] Extract parseTmArgsAndExportLogs to config.sh so that it could be reused,1
[FLINK-21128][k8s] Introduce dedicated scripts for native K8s integration,2
[hotfix][metrics][tests] Use default scope formats,1
[hotfix][metrics] Cleanup raw type usages,4
[hotfix][tests] Add ManuallyTriggeredScheduledExecutorService#triggerAllNonPeriodicTasks,1
[FLINK-21458][coordination] Add numRestarts metric,1
[FLINK-21586][table-planner-blink] Implement ResolvedExpression.asSerializableString for SQLThis closes #15084.,0
[FLINK-21553][table-runtime-blink] Copy record if needed when flush window buffer records to stateThis closes #15081,2
[FLINK-18789][sql-client] Use TableEnvironment#executeSql method to execute insert statement in sql clientCo-authored-by: godfreyhe <godfreyhe@163.com>This closes #14962,1
[hotfix] Fix checkstyle violations in JobInformation,5
[FLINK-21580] Introduce TaskDeploymentDescriptorFactory.PartitionLocationConstraintTaskDeploymentDescriptorFactory.PartitionLocationConstraint replaces the boolean allowUnknownPartitions inthe TaskDeploymentDescriptorFactory.,1
[FLINK-21580] Remove ScheduleMode from ExecutionGraphRemoves ScheduleMode from ExecutionGraph and replace it with TaskDeploymentDescriptorFactory.PartitionLocationConstraint.,4
"[FLINK-21580] Remove ScheduleMode from JobGraph and its testThe JobGraph's JobType replaces the ScheduleMode. Before we always configured theScheduleMode in accordance with the JobType. Now, only the JobType defines whichtype of scheduling is selected.* JobType.STREAMING: The whole job must be deployed at the same time* JobType.BATCH: The job can be executed in stepsThis closes #15076.",5
[FLINK-21571][build] Fix japicmp referenceVersion,0
[FLINK-21347][coordination] Extract interface from ExecutionGraphThis closes #14950,4
[hotfix][docs] Remove incorrect line-breaks,4
"[FLINK-17401] Configure mesos labels for taskmanagersProvide an option to configure mesos labels for taskmanagers running on mesos.Mesos task labels can be used for different purposes such as monitoring, acl, etc.",1
[hotfix][table-planner-blink] LogicalType's serializer and deserializer should consider empty Char/VarChar/Binary/VarBinaryThis closes #14878,2
[FLINK-21245][table-planner-blink] Support RexNode and RelDataType json serialization/deserializationThis closes #14878,5
[FLINK-21245][table-planner-blink] Support StreamExecCalc json serialization/deserializationThis closes #14878,5
[minor][table-planner-blink] Improve regular expression for flink version replacement and make sure that the json plan is still valid after the node ids are replacedThis closes #14878,5
[FLINK-21542][docs][table] Add documentation for supporting INSERT INTO specific columnsThis closes #15070,1
[FLINK-21611][build] Ignore unresolvable artifacts for japicmp,2
[hotfix][docs] Fix variable name,0
[hotfix] Expose the partitionNum and IntermediateDataSetID from IntermediateResultPartitionID,5
[FLINK-21326] Add tests to make sure the descendant logic of building POINTWISE edges follows the initial logic,2
"[FLINK-21326] Introduce EdgeManager, ConsumerVertexGroup and ConsumedPartitionGroup",2
[FLINK-21326] Optimize the topology building in ExecutionGraphThis closes #14868.,2
[FLINK-21401] Introduce JobGraphTestUtils and rework PerJobMiniClusterFactoryTest to use streaming jobs,1
[FLINK-21401] Consolidate different JobGraphTestUtils into one class,3
[FLINK-21401] Use JobGraphTestUtils in JobGraphGeneratorTest,3
[FLINK-21401] Use JobGraphTestUtils in ClientUtilsTest,3
[FLINK-21401] Use JobGraphTestUtils in MiniDispatcherTest,5
[FLINK-21401] Replace manual JobGraph creation with factory methods,1
[hotfix][tests] Refactor JobMaster.testDeclineCheckpointInvocationWithUserException to not need JobMaster instance,3
[FLINK-21401] Replace explicit JobGraph generation with JobGraphTestUtil factories,3
[hotfix] Add @Nullable annotation to JobGraph constructors,1
[FLINK-21401] Add JobGraphBuilder and adapt call sites of JobGraph constructor,1
[FLINK-21401] Replace JobGraph constructors with JobGraphBuilder,2
[hotfix] Let ApplicationDispatcherBootstrapTest extend TestLogger,3
[FLINK-21401] Make DispatcherTest.testErrorDuringInitialization independent of underlying JobMaster implementationThis commit makes the DispatcherTest.testErrorDuringInitialization independent of the underlyingJobMaster implementation by splitting it into DispatcherTest.testJobManagerRunnerInitializationFailureFailsJoband JobManagerRunnerImplTest.testJobMasterCreationFailureCompletesJobManagerRunnerWithInitializationError whichtests in two steps what DispatcherTest.testErrorDuringInitialization tested by relying on the DefaultSchedulerto eagerly create an ExecutionGraph and to fail.,0
[FLINK-21401] Make DispatcherTest.testInvalidCallDuringInitialization not depend on underlying Scheduler implementationBy using the BlockingJobManagerRunnerFactory it is possible to decouple the DispatcherTest.testInvalidCallDuringInitializationfrom the underlying Scheduler implementation which was used for blocking the creation of the JobManagerRunner before.,1
[FLINK-21401] Make DispatcherTest.testWaitingForJobMasterLeadership independent of Scheduler implementationBy letting the DispatcherTest.testWaitingForJobMasterLeadership use the TestingJobManagerRunnerFactory we can abstract thistest from the implementation details of the Scheduler and when it shows which JobStatus.,3
"[FLINK-21401] Make DispatcherTest.testInitializationTimestampForwardedToExecutionGraph independent of Scheduler implementationChange Dispatcher.testInitializationTimestampForwardedToExecutionGraph to testInitializationTimestampForwardedToJobManagerRunnerwhich only tests that the initialization timestamp is forwarded to the JobManagerRunner. Additionally, this commit addsAdaptiveSchedulerTest.testExecutionGraphGenerationSetsInitializationTimestamp, AdaptiveSchedulerTest.testInitializationTimestampForwardingand DefaultSchedulerTest.testCorrectSettingOfInitializationTimestamp to test the timestamp forwarding for the different Schedulerimplementations.",3
[FLINK-21401] Make DispatcherTest.testFatalErrorIfRecoveredJobsCannotBeStarted independent of Scheduler implementationThis commit makes the DispatcherTest.testFatalErrorIfRecoveredJobsCannotBeStarted independent of the schedulerimplementation by using the TestingJobManagerRunnerFactory and letting the TestingJobManagerRunner completewith an initialization error.,0
[FLINK-21401] Make DispatcherTest.testNonBlockingJobSubmission independent of underlying schedulerMake DispatcherTest.testNonBlockingJobSubmission independent of underlying scheduler by using theBlockingJobManagerRunnerFactory and blocking the creation of the JobManagerRunner.,1
[hotfix] Remove leader elections from DispatcherTest where they are not neededThe leader elections are only needed where we instantiate a proper JobManagerRunnerImpl whichneeds leader election.,1
[FLINK-21401] Make MiniClusterITCase work with AdaptiveSchedulerThe AdaptiveScheduler needs to make the JobVertices serializable and let them usestatic fields to communicate with the test because the JobGraph is copied.This closes #15093.,1
[hotfix] Speed up MiniClusterITCase for AdaptiveScheduler by giving enough slots for test jobs,3
[hotfix] Let HistoryServerStaticFileServerHandlerTest extend TestLogger,3
"[hotfix] Ignore PerJobMiniClusterFactoryTest.testJobClientSavepoint for the adaptive schedulerThe adaptive scheduler does not support stop with savepoint yet. Therefore, this test cannot work.",1
[hotfix] Disable SavepointITCase.testStopWithSavepointFailingInSnapshotCreation and .testStopWithSavepointFailingAfterSnapshotCreation for the AdaptiveSchedulerThe AdaptiveScheduler does not support stopping jobs with savepoint yet.,1
[hotfix] Harden TaskManagerProcessFailureStreamingRecoveryITCase by increasing resource timeout to 30s for the AdaptiveSchedulerThe test seems to take some time to start the required TaskManagers. This can sometimes lead to resource timeouts in theWaitingForResources state if it takes too long. This commit fixes this problem by increasing the resource timeout to 30s.,1
[FLINK-21633][coordination] Index pending task managers in TaskManagerTrackerThis would accelerate the progress of finding matching pending task manager in the task manager registration.This closes #15094,2
[FLINK-21419][coordination] Remove GC cleaner mechanism for unsafe memory segmentsThis closes #15058,4
[FLINK-21549][table-planner-blink] Remove DynamicTableSourceSpecJsonDeserializer and set ClassLoader and Configuration to DynamicTableSourceSpec when creating ExecNodeGraphThis closes #15062,1
[FLINK-21549][table-planner-blink] Remove DynamicTableSinkSpecJsonDeserializer and set ClassLoader and Configuration to DynamicTableSinkSpec when creating ExecNodeGraphThis closes #15062,1
[FLINK-21549][table-planner-blink] Support json serialization/deserialization for the push-down result of DynamicTableSourceThis closes #15062,5
[FLINK-21549][table-planner-blink] Support json serialization/deserialization for the push-down result of DynamicTableSinkThis closes #15062,5
[FLINK-21549][table-planner-blink] FileSystemTableSource should return the accepted predicates when filter push-downThis close #15062,5
[FLINK-19610][table-planner-blink] Support streaming window TopN in plannerThis closes #15026,1
[FLINK-21531][table][hive] Introduce pluggable ParserThis closes #15050,2
[FLINK-21460][table-api] Support to create TableEnvironment using ConfigurationThis closes #15018,5
"[FLINK-21299][table] Support 'SHOW [FULL] MODULES' syntax in sql parser, TableEnvironment and SQL ClientThis closes #15087",1
[FLINK-21525] Move scheduler benchmarks to FlinkFix the compilation errors due to FLINK-21401,2
[FLINK-21635][jdbc] Support optional driverName in jdbc connection establishmentThis closes #15104,5
[FLINK-13554][k8s] Do not add worker node until pod is scheduled.,1
[FLINK-13554][runtime] Add a timeout for worker registration.This closes #15095,1
[FLINK-21668][sql-parse] Fix typo in SqlCreateDatabaseThis closes #15114,5
[FLINK-21641][python] Support 'useModules' and 'listFullModules' in PyFlink (#15101),2
[FLINK-21170][python] Add internal state hierarchy in PyFlinkThis closes #15092,2
[FLINK-21398][coordination][tests] Enable tests for adaptive scheduler,3
[hotfix][tests] Add JIRA references,1
[FLINK-21396][table-common] Improve usability of new schema hierarchyThis closes #15096.,1
[hotfix][docs] Removing unnecessary hot take about Scala.This closes #15126,4
[FLINK-21679][table] Set output type for transformations from SourceProvider and DataStreamScanProvider in CommonExecTableSourceScanThis closes #15120,5
[FLINK-21684][table-planner-blink] Fix typo in StreamExecDeduplicate (#15122),2
[FLINK-21656][hive] Add antlr parser for hive dialect (#15116),1
[hotfix][runtime][test] Add missing checks in TaskExecutorProcessUtils.,1
[hotfix][runtim] Minor clean-ups in FineGrainedSlotManager,4
[FLINK-21433][runtime] Introduce numSlots in TaskExecutorProcessSpec and WorkerResourceSpec.This will be used for customizing workers with different number of slots.,1
[FLINK-21433][runtime] Pass number of slots as dynamic properties to TMs.This closes #15128,4
[hotfix][runtime] Fixes parameter order in trace log messages,2
[hotfix][runtime] Adds debug message to resourceTimeout trigger,0
[FLINK-21428][runtime] Introduces new option taskmanager.slot.timeout,1
"[FLINK-21428][test] Fixes AdaptiveSchedulerSlotSharingITCaseLowered the newly introduced taskmanager.slot.timeout optionThe test failed occasionally due to a race condition between the task beingfreed by the TaskManager (calling TaskSlotTableImpl.freeSlotInternal(..) throughJobMaster.onStop()) and the ResourceManager cleaning up the job's requirements(JobMaster.dissolveResourceManagerConnection(..) through JobMaster.onStop()).The DefaultDeclarativeSlotPool triggers a new slot request for the finished jobif the TaskManager freed the slot before the requirements were cleaned up by theResourceManager. The AdaptiveScheduler's resource timeout and the TaskManager'sslot timeout are competing in this case since both timeouts set to 10s bydefault. The second job would fail if the resource times out before theadditional slot request was handled. Hence, we lower the slot timeout to workaround this special case.Additionally, the parallelism of the job was lowered to avoid running inresource timeouts in every run.",1
[FLINK-19763][metrics][tests] Fine and extend memory metric tests,3
[hotfix][connectors/kafka] Correctly check required configs in KafkaSourceBuilder,5
[hotfix][python] Don't deploy the test jars for special test purpose,3
[FLINK-21614][sql-client] Introduce a new integration test framework for SQL ClientThis closes #15089,1
[FLINK-21614][sql-client] Migrate tests to CliClientITCase and fix bugsThis closes #15089,0
[FLINK-19944][hive] Support sink parallelism configuration for Hive connectorThis closes #15060,5
[FLINK-21722][docs] Fix class reference in 'Generating Watermarks' page for Scala exampleThis closes #15142,0
[FLINK-21242][python] Support state access API for the map/flat_map/filter/reduce operations of Python KeyedStreamThis closes #15083,1
[FLINK-21690][checkpoint] Remove redundant tolerableCheckpointFailureNumber setting in CheckpointConfig,5
[FLINK-21192][python] Support setting namespace in RemoteKeyedStateBackendThis closes #14800,1
[FLINK-21632][python] Add NamespacedStateView and PerWindowStateDataViewStoreThis closes #15130,5
[hotfix][table-common] Move CatalogConfig to CatalogPropertiesUtil,2
[FLINK-21396][table-common] Add ResolvedCatalog(View/Table) and Catalog(View/Table).ofThis introduces ResolvedCatalogTable and ResolvedCatalogView. ResolvedCatalogTable usesa new CatalogPropertiesUtil for serialization into properties. We introduce aCatalogTable.of and CatalogView.of for creating instances easily and forceimplementers to not check against CatalogTableImpl which is actually an internalclass.This closes #15098.,2
[FLINK-21488][connectors/jdbc] Use JobID in XA global transaction ID,1
[hotfix][connectors/jdbc] Use full checkpoint ID in XA global transaction ID,1
[FLINK-20379][connector/kafka] Rename KafkaRecordDeserializer to KafkaRecordDeserializationSchema to follow the naming convention.,2
[FLINK-20379][connector/common] Add a method of getUserCodeClassLoader() method to the SourceReaderContext.,1
[FLINK-20379][connector/kafka] Added methods valueOnly(...) and open(..) in the KafkaRecordDeserializationSchema interface to enable the reuse of the DeserializationSchema and KafkaDeserializationSchema.,1
[FLINK-20379][connector/kafka] Add a convenient method setValueOnlyDeserializer(DeserializationSchema) to KafkaSourceBuilder.,1
[FLINK-20379][connector/common][test] Add TestingDeserializationContext and KafkaRecordDeserializationSchemaTest,3
[FLINK-21717][docs] Fix broken links to Java and Python Docs,2
[FLINK-21396][table] Resolve tables when calling Catalog.createTable/alterTableThis ensures that the framework always resolves CatalogTable or CatalogView beforecalling Catalog.createTable/alterTable. It is still possible to pass unresolvedbase tables when calling the catalog directly but this depends on the catalogimplementation.This closes #15137.,2
[hotfix][checkpoint] Ensure buffers are recycled on released RecoveredInputChannel.,0
[hotfix][network] Incomplete cleanup of buffer pools does no longer leak other resources.,4
"[FLINK-19801][checkpoint] Using lazy initialization of aux structure while creating InflightDataRescalingDescriptor.For rescaling unaligned checkpoints, rescaling descriptors need to be calculated. However, for larger setups, it can take a while to calculate mappings and thus it should be avoided for all aligned checkpoints, interchanges without data, and for trivial setup (simple upscaling of shuffles).There were some optimizations already in the code but it relied on determining the simple cases in advance, which is quite complicated and fell short in two regards. In certain cases, such as channels that or filled only on either upstream or downstream, it was too aggressive and lead to wrong results. Further, some optimization opportunities were left out.This commit also generalizes RescaledChannelMapping to RescaleMappings to be additionally used for subtask mappings.In this refactoring, the calculation of most aux structure is lazy to simplify the detection of the cases. Accordingly, most calculations are moved inside TaskStateAssignment and properly encapsulated.",4
[FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism.The descriptors will be used during unspilling and in the StreamTaskNetworkInput to create virtual channels.,1
[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED.This special watermark can be used to reflect the state of an subtask/gate/channel that hasn't received a watermark yet. It will be used in later rescaling recovery commits.,1
[FLINK-19801][network] Simplify RecordDeserializer interface.RecordDeserializer is now fully responsible for the buffer that it has been given.,2
[FLINK-19801][task] Extract AbstractStreamTaskNetworkInput from StreamTaskNetworkInput.AbstractStreamTaskNetworkInput will become the base of RescalingStreamTaskNetworkInput in the next commit.,1
[FLINK-19801][checkpoint] StreamTaskInput#prepareSnapshot throws CheckpointException to allow declining checkpoints.,5
"[FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput.The demultiplexing works in two dimensions for the following cases.* Subtasks of the current operator have been collapsed in a round-robin fashion.* The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly relevant to keyed exchanges).In both cases, records from multiple old channels are received over one new physical channel, which need to demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).For performance reasons, the virtual demultiplexing logic is implemented separately from StreamTaskNetworkInput, such that on after recovery, the network input is replaced with the non-recovery counter-part in all StreamInputProcessors.",1
[FLINK-19801][checkpoint] Recover data with virtual channels.This commit adds virtual channel support to SequentialChannelStateReader. The reader now replicates data on input and output side according to the InflightDataRescalingDescriptor and adds VirtualChannelSelector events before buffers.,1
[FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints.,0
[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints.,1
[hotfix] Report failure cause in test,3
[FLINK-21135][coord] Adjust parallelism of job for reactive modeThis closes #15071,2
[hotfix] Enable AdaptiveScheduler if reactive mode is enabled,0
[FLINK-21620][table] Support abbreviation TIMESTAMP_LTZ for TIMESTAMP WITH LOCAL TIME ZONEThis closes #15124.,1
[FLINK-21620][table] Use TIMESTAMP_LTZ as summary string for LocalZonedTimestampTypeThis closes #15124.,1
[FLINK-21710][table-planner-blink] FlinkRelMdUniqueKeys gets incorrect result on TableScan after project push-downThis closes #15138,1
[minor][table-planner-blink] Clean the unused code in FlinkRelMdUniqueKeysThis closes #15138,2
[FLINK-21388] [flink-parquet] support DECIMAL parquet logical type when parquet primitive type is INT32This closes #14961,2
[FLINK-21612][table-planner-blink] Support StreamExecGroupAggregate json serialization/deserializationThis closes #15103,5
[FLINK-21624][table-planner] Correct FLOOR/CEIL (TIMESTAMP/DATE TO WEEK) functionsThis closes #15125,1
[FLINK-21733][table-planner-blink] WatermarkAssigner incorrectly recomputing the rowtime index which may cause ArrayIndexOutOfBoundsException (#15150),1
[FLINK-17441][kinesis][test-stability] Updating test to assert if timeout occurs waiting for records (#15160),3
[FLINK-21730][table-planner-blink] Introduce ExecNodeTranslatorThis closes #15147,2
[FLINK-21523][hive] Fix ArrayIndexOutOfBoundsException when running hive partitioned source with projection push downCo-authored-by: zouyunhe <zouyunhe@bigo.sg>This closese #15068,1
[FLINK-21485][sql-client] Simplify the ExecutionContext (#15006),2
[hotfix][tests] Stabilize HistoryServerTest,3
[hotfix][tests] Add 60s timeout to UnalingCheckpointITCase,1
[hotfix][yarn][tests] Improve assertion in case job failed,0
[hotfix][yarn][tests] Add timeouts to yarn HA IT cases,1
[hotfix][coordination] Remove defaultParallelism argument,4
[hotfix][tests] Update JIRA reference,5
[FLINK-21400][coordination] Maintain attempt counts outside of ExecutionGraph,2
[FLINK-21400][coordination][tests] Enable tests requiring attempt counts,1
[hotfix][docs] Fix image source,0
[hotfix][rest][tests] Clarify instructions for generating API snapshot,3
[FLINK-21697][table-planner-blink] Support StreamExecMiniBatchAssigner json serialization/deserializationThis closes #15164,5
[FLINK-21709][table] Officially deprecate the legacy plannerThis closes #15144.,2
[FLINK-21606] Add JobID to JobMasterGateway.registerTaskExecutorThe newly introduce parameter of type JobID can be used to verify that thetarget JobMaster is really responsible for the job the TaskExecutor thinksthe JobMaster is responsible for.,1
[hotfix] Remove Mocking from RegisteredRpcConnectionTestIntroduce TestRegistrationGateway interface and DefaultTestRegistrationGateway for easier testing.,3
[FLINK-21606] Introduce RegistrationResponse.Rejection and RegisteredRpcConnection.onRegistrationRejectionIntroduce RegisteredRpcConnection.onRegistrationRejection to support rejection of regisration attempts.,1
"[FLINK-21606] Release job resources on TaskExecutor if the JobMaster rejects connection attemptsThe JobMaster can reject a connection attempt from the TaskExecutor if it is not responsible for theexpected job. In this case, the TaskExecutor has some old connection information for another job andshould release all the job related resources (slots, tracked partitions).",5
[FLINK-21606] Fail hard if the ResourceManager rejects a JobMaster registration,0
"[FLINK-21606] Fail TaskExecutor hard if the ResourceManager rejects its registration.The ResourceManager rejects the connection attempt of a TaskExecutor if the TaskExecutor is notknown to the ResourceManager. In this case, we don't wait for the max registration timeout butinstead fail hard and fast.This closes #15105.",0
[FLINK-21725][core] Update TupleGenerator to name setter/constructor arguments like fields,1
[FLINK-21725][core] Sync tuples with updated TupleGenerator,5
[FLINK-21725][table] Add tests for large tuplesThis closes #15154.,3
[hotfix][metrics] Adjust variable name,0
[hotfix][metrics] Remove unnecessary @Nullable annotation,4
[FLINK-20042][kinesis] Adding Kinesis Table API e2e test using the Java framework (#15085)[FLINK-20042][kinesis] Adding Kinesis Table API e2e test using the new Java framework,1
[FLINK-21651][sql-client] Migrate module-related tests in LocalExecutorITCase to new integration test frameworkThis closes #15174,1
[FLINK-20460][hbase] Support async lookup for HBase connector (#14684),1
[FLINK-21750][table-planner-blink] Support StreamExecWatermarkAssigner json serialization/deserializationThis closes #15194,5
[hotfix][runtime] Fix max number of slots check for TM registration.Should not count non-empty slots for number of matched pending slots.,0
"[hotfix][runtime] Extract class ClusterResourceOverview into interface ClusterResourceStatisticsProviderThe class references internal states of TaskManagerTracker, providing up-to-date statistics rather than snapshots.",5
[hotfix][runtime] Maintains totalRegisteredResource in FineGrainedTaskManagerTracker.This is to avoid duplicated calculations. It will be frequently used for max resource limitation checks.,1
[FLINK-21177][runtime] Add pending resources to ClusterResourceStatisticsProvider.,1
[FLINK-21177][core] Make Resource comparable.,1
[FLINK-21177][core] Introduce CPUResource#toHumanReadableString,2
[FLINK-21177][runtime] Introduce WorkerResourceSpec#getTotalMemoSize,1
[FLINK-21177][runtime] Support limiting max total resources for fine-grained resource management.This closes #15145,1
[FLINK-21646][table-planner-blink] Port the classes in windowingSpecs.scala to JavaThis closes #15198,2
[FLINK-21646][table-planner-blink] Port the classes in plannerWindowProperties.scala to JavaThis closes #15198,2
[FLINK-21646][table-planner-blink] Port FlinkRelBuilder.PlannerNamedWindowProperty to JavaThis closes #15198,5
[FLINK-21646][table-planner-blink] Support Duration json serialization/deserializationThis closes #15198,5
[FLINK-21646][table-planner-blink] Support StreamExecWindowAggregate json serialization/deserializationThis closes #15198,5
"[FLINK-21354] Introduce ChangelogStateBackend to delegate state accessThis change is to wrap the existing prod state backend (Rocksdb, Fs, Mem) to delegatestate access for these state backends. In the future, we can forward state changes toStateChangeLog when states are updated. In this PR, we only support keyed-state access.The changes include:1. Introduce `DelegatingStateBackend` interface for state backend delegation   (in the flink-runtime module)2. Introduce `ChangelogStateBackend` and related delegating states for   state delegation (in flink-state-backends module)3. Implement `ChangelogStateBackend`'s Loader in `StateBackendLoader`.   (in the flink-runtime module)",2
[FLINK-21707][runtime] Do not trigger scheduling of non-CREATED regions in PipelinedRegionSchedulingStrategy,1
[FLINK-21735][coordination] Harden JobMaster#updateTaskExecutionState()This closes #15196.,5
"[FLINK-21579][table-api] Support ""SHOW USER FUNCTIONS"" statement in Table API and SQL ClientThis closes #15110",1
[FLINK-21740][sql-client] Fix unstable CliTableauResultViewTest (#15211),3
[FLINK-19667] Add AWS Glue Schema Registry integration (#14737)Co-authored-by: Linyu <yaoliny@amazon.com>Closes https://github.com/apache/flink/pull/14737,2
[FLINK-21796] Temporarily disable SQLClientKafkaITCase,2
[hotfix][coordination] Guard assumption in AdaptiveScheduler.Restarting,0
"[FLINK-21535][tests] Improved the detection of the attempt number in UnalignedCheckpointITCase.Attempt number was inferred from the times a specific source reader was created. However, there was a race condition between the induced failure in FailureMapper#initializeState and the creation of the source reader. If the failure was induced first, no restart was detected and thus the test never finishes.The solution is now to track the restarts of all source tasks through Enumerator#addSplitsBack, which is called on recovery. Additionally, instead of just tracking only one specific source operator, all operators are now tracked and the results are consolidated when all readers are initialized.",5
[FLINK-20130][core] Add ZStandard to FileInputFormat,2
[FLINK-21704][table-planner-blink] Support json serialization/deserialization for ChangelogSourceThis closes #15210,4
[FLINK-21727][table-planner-blink] Add getter for catalogManager in ParserImplThis closes #15151,2
[FLINK-21727][table][hive] Support DDL in HiveParserThis closes #15151,1
"Revert ""[FLINK-20130][core] Add ZStandard to FileInputFormat""This reverts commit 889b3845217141b295eb2b60c3dd8a2c245b429a.",4
[FLINK-21793][k8s] Use RM generated JVM memory options.This closes #15214,1
[FLINK-21558][coordination] Skip check if slotreport indicates no change,4
[FLINK-21396][table-planner-blink] Use ResolvedCatalogTable within the plannerUpdates the planner to only use instances of ResolvedCatalogTable withResolvedSchema.This closes #15217.,0
[hotfix][table-planner] Fix integral types list in FunctionGenerator,1
[hotfix][doc] Fix sql functions name typo,2
"[FLINK-21622][table-planner] Introduce function TO_TIMESTAMP_LTZ(numeric [, precision])This closes #15136",1
[FLINK-16829][metrics][prometheus] Extract configuration in factory,5
[FLINK-21596] Increase time out for the CheckpointFailureManagerITCase,0
[refactor] Use ClassRule for MiniClusterResource in the CheckpointFailureManagerITCase,0
[FLINK-21532][table-api] Make CatalogTableImpl#toProperties and CatalogTableImpl#fromProperties case sensitive (#15234)Co-authored-by: liushouwei <liushouwei@autohome.com>,2
"[FLINK-21778][network] Use heap memory instead of direct memory as index entry cache for sort-merge shuffleCurrently, the sort-merge shuffle implementation uses a piece of direct memory as index entry cache for acceleration. This patch switches to heap memory instead to reduce the consumption of direct memory which can further reduce the possibility of OutOfMemoryError. Heap memory is better because the default direct memory size of Flink is only 128M which is quite small.",2
[FLINK-21801][table-common] Deprecate TableSchema and related classesThis closes #15243.,2
[FLINK-21801][table-api] Use ResolvedSchema in QueryOperationThis closes #15242.,0
[hotfix][test] Remove unexpected commented-out code in AbstractFineGrainedSlotManagerITCase,4
[hotfix][runtime] Pass total resource profile instead of default slot profile to DefaultResourceAllocationStrategyThe total resource profile will contain the entire information of external resources,5
[hotfix][core] Make Resource operation return the specific sub resource,1
[hotfix][runtime] Refactor external resource setter interface of ResourceProfile#Builder,2
[FLINK-21480][core] Introduce ExternalResource to represent all the user-defined external resource,1
"[FLINK-21480][runtime] Add external resources to WorkerResourceSpec, TaskExecutorResourceSpec and TaskExecutorProcessSpec",1
[FLINK-21480][yarn][k8s] Request external resource according to TaskExecutorProcessSpecThis closes #15112,2
[FLINK-21774][sql-client] Display all the SHOW command result in tableau formatThis closes #15213,2
[FLINK-19609][table-planner-blink] Support streaming window join in planner (#15195),1
"[FLINK-21610][tests] Harden ProcessFailureCancelingITCaseThe cancellation of the job may fail if the job termination finishes so quickly that the job has been cleaned up before the cancellation has been processed.The cancellation is unnecessary anyway because the TM failure causes the job to fail and we explicitly forbid restarts.As such we can just remove the cancel call.Furthermore, the conditions for when to kill the TM were not correct, as they did not ensure the job was actually deployed.",4
[FLINK-21462][sql-client] Use Configuration instead of Environment to store options and values in SQL Client (#15197),5
"[FLINK-21777][network] Replace the 4M data writing cache of sort-merge shuffle with writev system callCurrently, the sort-merge shuffle implementation uses 4M unmanaged direct memory as cache for data writing. This patch replaces the cache with writev system call which can reduce the unmanaged direct memory usage without any performance loss.",5
[FLINK-21815][table-planner-blink] Support json serialization/deserialization for StreamExecUnionThis closes #15233,5
[FLINK-21728][core] Introduce env for activating multiple-free checks for memory segments.,2
[FLINK-21728] Do not release segments in MemoryManager#release(Collection<MemorySegment>) if they have been released,2
[hotfix] Remove redundant sanity check in EdgeManager#connectPartitionWithConsumerVertexGroup,4
[hotfix] Make ExecutionGraphTestUtils#createSimpleTestGraph return DefaultExecutionGraph,3
[hotfix] Remove generic from LogicalTopology and its components,2
[FLINK-21328] Optimize the initialization of DefaultExecutionTopologyThis closes #15088,2
[hotfix][docs] Fix invalid link in windows.mdThis closes #15263.,2
[FLINK-21802][table-planner-blink] Fix  TimestampType/RowType/MapType/ArrayType/MultisetType json ser/deThis closes #15219,5
[FLINK-21849][sql-client] Add default module test case for 'SHOW [FULL] MODULES' (#15261),3
[hotfix][docs] Fix semicolon issues,0
[hotfix][core] Remove outdated example from MemorySegment JavaDoc.,2
[FLINK-21236][core] Remove HeapMemorySegment.Existing use cases are migrated to on-heap hybrid memory segment.,1
[FLINK-21744][table-planner-blink]Support StreamExecDeduplicate json serialization/deserializationThis closes #15220,5
[FLINK-21811][blink-table-planner] Support StreamExecJoin json serialization/deserializationThis closes #15239,5
[FLINK-21160][connector/kafka] Use deserializer class instance instead of class name to avoid NPE when invoking getProducedType (#14784),1
"[FLINK-21805][table-planner-blink] Support json serialization/deserialization for StreamExecRank, StreamExecSortLimit and StreamExecLimitThis closes #15231",5
[FLINK-21791][table-planner-blink] Support StreamExecLocalGroupAggregate and StreamExecGlobalGroupAggregate json serialization/deserializationThis closes #15264,5
[FLINK-21860][table-planner-blink] Support StreamExecExpand json serialization/deserializationThis closes #15268,5
[FLINK-21861][table-planner-blink] Support StreamExecIncrementalGroupAggregate json serialization/deserializationThis closes #15269,5
[FLINK-21852][table] Introduce NullAwareGetters to BinaryRowDataThis closes #15257,5
[hotfix][docs] Add 'IF NOT EXISTS' to create table statement (#15275),1
[FLINK-21561] Predownload/Cache large E2E test artifacts,3
[FLINK-21074][FLINK-21076][docs][coord] Document Reactive ModeThis closes #15064,2
[FLINK-21819][filesystems] Remove Swift filesystem,5
[FLINK-21837][table-planner-blink] Support StreamExecIntervalJoin json serialization/deserializationThis closes #15276,5
[FLINK-21818][table] Refactor SlicingWindowAggOperatorBuilder to accept serializer instead of LogicalTypeThis closes #15236,2
[FLINK-21851][table-runtime] Refactor BinaryRowDataKeySelector in testingThis closes #15256,3
[hotfix][table] Use type from RowDataKeySelector in StreamExecTemporalJoinThis closes #15277,5
[FLINK-20130][core] Add ZStandard to FileInputFormat,2
[FLINK-21843][table-planner-blink] Support StreamExecGroupWindowAggregate json serialization/deserializationThis closes #15270,5
[FLINK-21801][table-api] Use new schema in Table and TableResultReplaces Table(Result).getSchema with Table(Result).getResolvedSchemaThis closes #15266.,0
[FLINK-21654][tests] Adds retry loop to YarnClient.getApplicationsThis fix should cover the issue with YARN-7007. The corresponding discussionis happening in FLINK-15534.This closes #15134.,2
[hotfix][test] Adds initialization of flag that triggers cancellation,5
[FLINK-21813][table-planner-blink] Support StreamExecOverAggregate json serialization/deserializationThis closes #15271,5
[FLINK-21864][table-planner-blink] Support StreamExecTemporalJoin json serialization/deserializationThis closes #15281,5
[FLINK-21785][blink-table-planner] Support StreamExecCorrelate json serialization/deserializationThis closes #15215,5
[FLINK-21875][hotfix] Fix compilation error in IntelliJ. Removing reliance on shaded classes. (#15290),4
[FLINK-21602] Add CreatingExecutionGraph stateThe CreatingExecutionGraph state models the asynchronous ExecutionGraph creationafter enough resources have been acquired in the WaitingForResources state.,1
[FLINK-21602] Let AdaptiveScheduler create the ExecutionGraph in the ioExecutorThe AdaptiveScheudler creates the ExecutionGraph now in the ioExecutor.,1
[hotfix] Let delayed AdaptiveScheduler.runIfState method return ScheduledFutureBy letting the AdaptiveScheduler.runIfState method return a ScheduledFuture it is nowpossible to cancel scheduled actions.,1
"[hotfix] Let Restarting and WaitingForResources cancel scheduled tasks onLeaveBy canceling incompleted scheduled tasks when leaving, the states Restarting and WaitingForResourcesleave a cleaner state behind.",4
[FLINK-21602] Remove generic parameter from SlotAllocatorThe generic parameter will no longer be needed once the parallelism calculation and thereservation of slots happens in two separate steps.,2
"[FLINK-21602] Make SlotAllocator.tryReserveSlots failableIn order to prepare the SlotAllocator to support failing SlotAllocator.tryReserveSlotscalls, this commit changes its return type to Optional<? extends ReservedSlots>.",4
[FLINK-21602] Add DeclarativeSlotPool. and AllocatedSlotPool.containsFreeSlotThe newly introduced method containsFreeSlot allows to check whether an assumption thata given slot is still free holds true or not. This allows to continue reserving slotsfrom the DeclarativeSlotPool or not.,1
"[FLINK-21602] Let SlotSharingSlotAllocator check whether resources are available before reserving themThe SlotSharingSlotAllocator.tryReserve now checks whether the expected set of resources is still availablebefore reserving slots. If the resources are no longer available, then tryReserve will return Optional.empty().",1
[hotfix] Make TestExecutorResource generic in the ExecutorServiceMaking the TestExecutorResource generic in the ExecutorService has the advantage that the resourcecan also manage and return SchedulerExecutorServices.,3
[hotfix] Make SlotAllocator configurable for the AdaptiveScheduler,5
"[FLINK-21602] Split ExecutionGraph generation and slot assignments into two stepsIn order to properly support the asynchronous ExecutionGraph generation, we need to handlethe case where the set of available slots changed after the ExecutionGraph has been created.In this situation, we need to check whether the expected set of resources is still thereand if not, then go back to WaitingForResources. Moreover, we need to schedule a resourcecheck when entering the Executing state in order to not miss newly arrived slots.",1
[hotfix] Factor ExecutionGraph creation out into ExecutionGraphFactoryUsing the ExecutionGraphFactory for creating and restoring an ExecutionGraph allowsto share the functionality between the DefaultScheduler and the AdaptiveScheduler.,1
[hotfix] Annotate CheckpointsCleaner with @ThreadSafe,4
"[hotfix] Rename SchedulerNG.getTerminationFuture into getJobTerminationFutureThis is a preparational step to better distinguish the job termination future fromthe Scheduler termination future. Moreover, the return type was changed toCompletableFuture<JobStatus> to be more expressive.",4
"[FLINK-21602] Allow SchedulerNG to terminate asynchronouslyThis commit let the SchedulerNG extend the AutoCloseableAync interface in order to supportasynchronous termination behaviours. Moreover, this commit let the JobMaster wait on thescheduler's termination before terminating itself.",1
[hotfix] Add FutureUtils.switchExecutor utilityThe FutureUtils.switchExecutor utility allows to switch the executor for a givenCompletableFuture independent of whether it is completed normally or exceptionally.,1
[FLINK-21602] Track asynchronous background tasks in the AdaptiveSchedulerThe AdaptiveScheduler triggers asynchronous background tasks such as the creation of the ExecutionGraph.In order to know when we can stop the checkpointing services we have to keep track of these asynchronoustasks and only shut down the services after the tasks are completed. This ensures that there are noconcurrent accesses to the checkpoint services.This closes #15251.,1
[FLINK-21816][table-planner-blink] Support StreamExecMatch json serialization/deserializationThis closes #15272,5
"[FLINK-21466][sql-client] Make ""embedded"" parameter optional when start sql-client.shThis closes #15255",2
[FLINK-21466][sql-client] Add unit tests for SqlClientThis closes #15255,3
[FLINK-21381][state] Add test for KeyGroupedInternalPriorityQueue,3
"[FLINK-21831][state][changelog] Add missing delegation of KeyGroupedInternalPriorityQueueKeyGroupedInternalPriorityQueue provides public methods that will be modifyingthe delegated state backend, so it has to be proxyd as well.",1
[FLINK-21869][table-planner-blink] Make the field name in the json plan more readable for Rank nodeThis closes #15284,5
[FLINK-21869][table-planner-blink] Support StreamExecTemporalSort json serialization/deserializationThis closes #15284,5
[FLINK-21885] Fixed minor typo within batch execution criteria,2
[FLINK-21847][table] Support DESC as an abbreviation of the DESCRIBE statementThis closes #15285,1
[FLINK-21886][table-api] Loosen argument of TableEnvironmentInternal#executeInternal from QueryOperation to Operation (#15296),2
"[FLINK-21650][state/heap] Skip KGs not belonging to this backend on restore (instead of failing)Motivation:In the new incremental mode, heap backend wraps KeyGroupsStateHandleinto IncrementalRemoteKeyedStateHandle. The latter don't computeintersection because it is not directly aware of the offsets. So it justreturns a full keyrange if there is SOME intersection.On recovery, unused keyGroups are filtered out by RocksDB state backend.With this change, Heap state backend does the same.",4
[FLINK-21673][state/heap] Add extension points to snapshot reading/writing,1
[hotfix][state backend] Put the delegating log to ChangelogStateBackend constructor,4
[FLINK-21890][table-planner-blink] Rename DAGProcessor to ExecNodeGraphProcessorThis closes #15305,2
[FLINK-21814][datastream] Add host and port information in exception when CollectSink can't connect to the clientThis closes #15297,5
[FLINK-21887][sql-client] Add SHOW VIEWS test in CliClientITCase (#15298),3
[FLINK-21768][client]Optimize system.exit() logic of CliFrontendThis closes #15185.,2
[FLINK-21333] Add StopWithSavepoint state to adaptive schedulerThis closes #14948.,1
"[FLINK-21894][hive] Update type of HiveTablePartition#partitionSpec from Map<String, Object> to Map<String, String>This closes #15308",5
[FLINK-21899][table] Introduce SOURCE_WATERMARK built-in function to preserve watermark from source (#15326),1
"[FLINK-18384][docs-zh] Translate ""Elasticsearch SQL Connector"" page into Chinese (#15235)",2
"[FLINK-21838][docs-zh] retranslate ""JDBC SQL Connector"" page into Chinese (#15254)",5
[FLINK-21892][docs][table] Add documentation for the DESC statement syntax (#15325),2
[FLINK-21918][python] Add execution.runtime-mode setter in StreamExecutionEnvironmentThis closes #15335.,1
[FLINK-21300][docs][table] Update function module related documentation (#15230),2
[FLINK-21874][coordination] Ignore outdated slot allocation confirmations,5
[FLINK-21190][runtime] Refactors JsonArchivist interface,5
[FLINK-21190][runtime] Introduces exception history to web UI,2
[hotfix][build] Add missing antlr3 plugin version.This avoids build stability issues and clears some warnings.The version is the latest released plugin version (released 2014) and the one my setup (default settings) picked automaticallyin the absence of the proper version.,1
[FLINK-21506][mesos] Option for mesos task user,1
[FLINK-21922][python] Fix partition_by in Over doesn't work with expression DSLThis closes #15338.,1
[FLINK-21621][table-planner-blink] Support TIMESTAMP_LTZ arithmeticThis closes #15133,1
[FLINK-21136] Adjust timeouts for reactive modeThis closes #15159,2
[hotfix] remove useless code in PlannerBase,1
[FLINK-21868][table-planner-blink] Support StreamExecLookupJoin json serialization/deserializationThis closes #15318,5
[FLINK-21550][tests] Harden ZooKeeperHaServicesTest.testSimpleCloseThis commit hardens the ZooKeeperHaServicesTest by not busy loop waiting with a timeouton a leader election but instead to use LeaderRetrievalUtils.LeaderConnectionInfoListenerwhich offers a future which is completed when the leader is elected.This closes #15334.,5
"[FLINK-21879][tests] Harden ActiveResourceManagerTest.testWorkerRegistrationTimeoutNotCountingAllocationTimeThe requestResourceFuture needs to be completed within the main thread of the ResourceManager.Otherwise, we risk to not see the caused state changes.This closes #15329.",4
[Flink-21910][resourcemanager] fix the check that whether JobLeaderIdService has been statedThis closes #15228.,0
[hotfix][doc] Fix the less-than and greater-than sign in Kubernetes documentation,2
[FLINK-21382][docs] Update documentation for standalone Flink on Kubernetes with standby JobManagersThis closes #15248.,5
[FLINK-21348] Add tests for AdaptiveScheduler's StateWithExecutionGraphThis closes #15342,3
[FLINK-21913][table][connectors] Update DynamicTableFactory.Context to use ResolvedCatalogTableThis closes #15316.,2
"[hotfix][docs] Add ""Elastic Scaling"" to chinese docs",2
[FLINK-21855][docs] Document metrics limitations of reactive mode,2
[hotfix] Fix typo,2
[FLINK-21751][coordination] Reserve disconnectJobManager for external calls,2
[FLINK-21751][coordination] JM passes job status when disconnecting,4
[FLINK-21751][coordination] Add SlotTracker#getTaskExecutorsWithAllocatedSlotsForJob,1
[FLINK-21751][coordination] Add TaskExecutor#freeInactiveSlots,1
"[FLINK-21751][coordination] Only clear requirements for terminal jobsClear resource requirements for only if the job reached a globally terminal state, or the job has been removed from the resource manager via the job timeout.",4
[FLINK-21751][coordination] Reclaim inactive slot if requirements are cleared,1
[FLINK-21916] Allows multiple kinds of ManagedMemoryUseCase for the same operatorThis closes #15337.,1
[FLINK-21628][python] Support Python UDAF in Tumbling WindowThis closes #15212,1
[hotfix][core][test] Prioritize configurations over system properties for enabling fine-grained resource management.,0
[hotfix][core][test] Use properties rather than envs for fail multiple segment frees.This closes #15279,0
[hotfix][runtime] Annotate getters of TaskManagerInfo and TaskManagerDetailsInfo with JsonIgnore,5
[FLINK-21794][metrics] Support retrieving slot details via rest apiThis closes #15249,1
[FLINK-21698][table] Support casting between NUMERIC and TIMESTAMP_LTZ and disable casting between NUMERIC and TIMESTAMP type This closes #15132,1
[FLINK-20547][network] Fix inconsistent availability issue of LocalBufferPoolLocalBufferPool#checkAvailability may return wrong availability state of LocalBufferPool which may lead to the set of inconsistent availability state when LocalBufferPool#setNumBuffers is called. This patch fixes the issue.,0
[FLINK-21696][docs] Add output parameter in WatermarkGenerator scala sections,2
[FLINK-21937][python] Support batch mode in Python DataStream API for basic operationsThis closes #15349.,5
[hotfix][table-runtime-blink] Enable ExternalTypeInfo for all kinds of data types,5
"[FLINK-21872][table-api-java] Add utility for DataStream API's DataType, Schema, and projectionThis closes #15345.",5
[hotfix][core] Remove unnecessary not-freed check for releasing segments in memory manager.,4
[FLINK-21800][core] Guard MemorySegment against concurrent frees.This closes #15273,2
[FLINK-21822][table] Support the new factory stack for CatalogFactory,2
[FLINK-21822][table] Migrate built-in and test catalog factories to new stack,1
[FLINK-21822][table] Introduce CatalogFactoryHelperTHis closes #15245.,2
[hotfix][core] Fix typos in ReadableConfig,5
[FLINK-21944][python] Perform null check before closing arrowSerializer,2
[FLINK-21896][table-planner-blink] Correct the different serialization result for json plan between jdk8 and jdk11The reason is an object without serialVersionUID will be serialized to different result for jdk8 and jdk11This closes #15346,5
[FLINK-21655][table-planner-blink] Fix incorrect simplification for coalesce call on a groupingsets' resultThis closes #15117,1
[hotfix] Fix raw types in StreamTaskNetworkInputTest,3
[FLINK-21857] StackOverflow for large parallelism jobs when processing EndOfChannelStateEventThis commit moves draining the virtual channels at the end of recoveryout of the CheckpointedInputGate#pollNext method in to the main loop ofStreamTaskNetworkInput so that we do not build up a deeply nested stack.This closes #15323,1
[FLINK-21294][python] Support state access API for the map/flat_map operation of Python ConnectedStreamsThis closes #15149,1
[FLINK-21951][network] Fix the wrong if condition in BufferReaderWriterUtil#writeBuffersThe wrong if condition in BufferReaderWriterUtil#writeBuffers may lead to data loss when bulk writing a large number of buffers into file. This patch fixes the issue.,0
[FLINK-21930][docs] Fix typo in Hive temporal join example (#15292),2
[FLINK-21135][coord] Adds Precondition to AdaptiveSchedulerThis check is necessary since AdaptiveScheduler.calculateDesiredResourcesexpects the parallelism to be set for each JobVertex.,1
[FLINK-21745][tests] Sets the parallelism of 1 for testing JobVertex instancesThis was necessary to make the tests comply with the AdaptiveSchedulerrequirements of having the parallelism set for each JobVertex.This closes #15262,1
[FLINK-21076][docs] Add section about Adaptive SchedulerThis closes #15355,1
[FLINK-21581][core] Remove @PublicEvolving from RuntimeContext.getJobID,1
fixup! [FLINK-21581][core] Remove @PublicEvolving from RuntimeContext.getJobID,1
[FLINK-11408][datastream] Fix NPE and lost timer during window merging for ContinuousProcessingTimeTriggerThis fixes:* NPE in clear() due to state merged out.* Timer lost due to no timer registration for new window.This closes #15241,1
[hotfix] Make SchedulingDownstreamTasksInBatchJobBenchmarkTest extends TestLogger,3
"[FLINK-21731] Add benchmarks for DefaultScheduler's creation, scheduling and deployingThis closes #15148",1
[FLINK-21836][table] Support parsing special commands by introducing ExtendedParserThis closes #15265,1
[FLINK-21661][kinesis] Fix fetch interval for polling consumer (#15157),0
[FLINK-21933][kinesis] EFO consumer treats interrupts as retryable exceptions (#15347),1
"[FLINK-21701][sql-client] Support ""RESET key"" statement in the SQL ClientThis closes #15332",1
"[FLINK-21946][table-planner-blink] FlinkRelMdUtil.numDistinctVals produces exceptional Double.NaN result when domainSize is in range(0,1)This closes #15357",2
[FLINK-21629][python] Support Python UDAF in Sliding WindowThis closes #15350,1
[FLINK-20563][hive] Support built-in functions for Hive versions prior to 1.2.0This closes #14379,1
[FLINK-21975] Remove hamcrest dependency from SchedulerBenchmarkBase,4
[hotfix] Make IterableUtils.flatMap return Iterable rather than Iterator,1
[FLINK-21331] Optimize calculating tasks to restart in RestartPipelinedRegionFailoverStrategyThis closes #15312,0
[FLINK-21974][table] Support to match quoted values for SET option statementThis closes #15372,1
"[FLINK-20740][network] Introduce a separated buffer pool and a separated thread pool for sort-merge blocking shuffleCurrently, sort-merge blocking shuffle implementation uses some unmanaged direct memory and the netty thread for shuffle data read which can lead to direct memory OOM and stress the netty thread with file IO. This patch introduces a separated buffer pool and a separated thread pool for data read. In the following patch, the problem will be totally solved by the IO scheduling mechanism leveraging the introduced buffer pool and thread pool.This closes #15199",0
[hotfix] Let SimpleRecoveryITCaseBase extend TestLogger,3
[FLINK-21929][rocksdb][tests] Ensure to dispose state backend in StateBackendTestBase#testKeyGroupedInternalPriorityQueue finally,3
[FLINK-21929][statebackend][tests] Refactor StateBackendTestBase to ensure created keyed state backend could be disposed finally,1
[FLINK-19646][python] Introduce StreamExecutionEnvironment.from_source to support FLIP-27 source in Python DataStream APIThis closes #15378.,5
"[FLINK-21387][tests] Remove test timeout from DispatcherTest.testNonBlockingJobSubmission and .testInvalidCallDuringInitializationThe 5s test timeout for the DispatcherTest.testNonBlockingJobSubmission and .testInvalidCallDuringInitialization failed on the CIinfrastructure. Therefore, this commit removes these timeouts in order to harden the mentioned tests.This closes #15343.",3
[FLINK-21939][python] Support batch mode in Python DataStream API for process operation and reduce operationThis closes #15362.,5
[hotfix][python] Rename the parameter from result_type to output_type for flat_map,2
[hotfix][python] Rename the parameter from key_type_info to key_type for key_by,5
"[hotfix][core] Avoid self-surpression in ExceptionUtils#firstOrSuppressed.In case of OutOfMemoryError the same exception may be rethrown in several places (OOM is preallocated) and thus a self-surpression is attempted, leading to a shadowed stacktrace.",0
[hotfix][checkpointing] Adjusting logging level of per-buffer calls in ChannelStateWriter to trace.,2
"[FLINK-20654][checkpoint] Remove capacity of ChannelStateWriteRequestExecutorImpl.Currently, there is an unhelpful exception being thrown when capacity is reached. The capacity is also independent of the parallelism - for p = 5k, there are 10k exclusive buffers, which may easily fill up the queue if there is I/O backpressure because of concurrent writes.",1
[FLINK-20654][checkpointing] Measuring I/O duration and issue DEBUG statement for long times.,0
[FLINK-20654][checkpoint] Only trace buffers that are actually persisted.,2
[FLINK-20654][tests] Forcing network action logger on TRACE for Unaligned Checkpoint ITCases.,2
[FLINK-20654][tests] Add a time-limit to the induced backpressure.Also increase checkpointing interval with parallelism to avoid overloading I/O during recovery (slowing down checkpointing after recovery).,1
[FLINK-21713][table] Correct function CURRENT_TIMESTAMP/CURRENT_TIME/CURRENT_DATE/NOW/LOCALTIME/LOCALTIMESTAMPThis closes #15303,5
[FLINK-21416] increase the ssl handshake timeout to avoid connection reset/close in FileBufferReaderITCase,2
[FLINK-21715][table-api] Support implicit cast conversion between TIMESTAMP and TIMESTAMP_LTZThis closes #15363,1
[FLINK-21947][csv] Support TIMESTAMP_LTZ type in CSV formatThis closes #15356,1
[FLINK-21917][docs] Add back missing kafka.md Chinese documentation (#15392),2
[FLINK-21463][table-api] Support to parse 'RESET key' command,1
[FLINK-21463][sql-client] Unify SQL Client parser and TableEnvironment parserThis closes #15315,2
"[FLINK-21984][table] Change precision argument from optional to required in TO_TIMESTAMP_LTZ(numeric, precision)This closes #15379.",1
[hotfix] Package format-common to flink-csv/flink-json (#15394),5
[FLINK-21623][table-planner] Introduce CURRENT_ROW_TIMESTAMP() functionThis closes #15306,1
[FLINK-21978][table-planner] Disable cast conversion between Numeric type and TIMESTAMP_LTZ typeThis closes #15374,2
[FLINK-21888][hive] Maintain our own ASTNode class (#15301),2
[FLINK-21702][sql-client] Support option `sql-client.verbose` to print the exception stackThis closes #15383,1
[FLINK-21664][sql-parser] Support to parse STATEMENT SET syntaxThis closes #15282,1
[FLINK-21626][core] Make RuntimeContext.jobID non-optional,1
"[FLINK-21669][table-api] Support ""table.dml-sync"" option to execute statement in sync modeThis closes #15340",1
[FLINK-21738][table] Caching built-in functions for CoreModule and HiveModuleThis closes #15267,1
[FLINK-21989][table] Add a SupportsSourceWatermark ability interfaceThis closes #15388.,1
"[FLINK-19938][network] Implement shuffle data read scheduling for sort-merge blocking shuffleThis patch implements SortMergeResultPartitionReadScheduler which can read data for all downstream tasks consuming the corresponding SortMergeResultPartition. The scheduler always tries to read shuffle data in order of file offset, which maximums the sequential read so can improve the blocking shuffle performance.This closes #13924",1
[FLINK-21969][python] Invoke finish bundle method before emitting the max timestamp watermark in PythonTimestampsAndWatermarksOperatorThis closes #15401,1
[hotfix][formats][parquet] Fix argument references,0
[FLINK-19607][table-runtime-blink] Implement streaming window TopN operatorThis closes #15291,1
[FLINK-21330] Optimize the performance of PipelinedRegionSchedulingStrategyThis closes #15310,2
[FLINK-20114][connector/kafka] KafkaSourceReader should not commit offsets for partitions whose offsets have not been initialized.,5
[FLINK-20114][connector/common] SourceCoordinatorContext should not log and fail job again if it receives InterruptedException after it is closed.,0
[hotfix][connector/kafka] Reduce the offset commit logging verbosity from INFO to DEBUG.,0
[FLINK-20114][connector/common] SourceOperatorStreamTask should update the numRecordsOutCount metric,5
[FLINK-20114][connector/kafka] KafkaSourceEnumerator should close the admin client early if periodic partition discovery is disabled.,2
[hotfix][connector/kafka] Remove the unused close.timeout.ms config.,5
[FLINK-20114][connector/kafka] PartitionOffsetsRetrieverImpl.committedOffsets() should handle the case without committed offsets.,1
[FLINK-20114][connector/kafka] SourceOperatorStreamTask should check the committed offset first before using OffsetResetStrategy.This is necessary to keep the same behavior as the legacy FlinkKafkaConsumer.,2
[FLINK-20114][connector/kafka] Auto offset commit should be disabled by default.,1
[FLINK-20114][connector/kafka] Add IT cases for KafkaSource by migrating IT cases from FlinkKafkaConsumer.,2
[hotfix][examples] Update StateMachineExample to use KafkaSource,1
[FLINK-20114][connector/kafka] Remove duplicated warning and remove redundant default value for partition.discovery.interval.ms,4
[hotfix][docs] Add missing AggregatingStateDescriptor in State page (#15208),1
[FLINK-21590][build] Avoid hive logs in the SQL client console (#15384),2
[FLINK-21998][hive] Move copied hive classes to a separate package,4
[FLINK-21998][hive] Add more hive code,1
[FLINK-21306] Ensure fatal errors always stop the JVM processThis closes #15108,0
[FLINK-21758][metrics] Add default implementations for int methods,1
[FLINK-21758][metrics] Remove unnecessary method implementations,4
[hotfix][ui] Remove unrelated UI backpressure console logs,2
[FLINK-21630][python] Support Python UDAF in Session WindowThis closes #15391,1
[hotfix] Rename ExecutionVertex#getConsumedPartitions to ExecutionVertex#getConsumedPartitionGroup,1
[hotfix] Rename IntermediateResultPartition#getConsumers to IntermediateResultPartition#getConsumerVertexGroups,1
[FLINK-21332] Optimize releasing result partitions in RegionPartitionReleaseStrategyThis close #15314,2
"[FLINK-20757][network] Optimize data broadcast for sort-merge blocking shuffleFor data broadcast, we can only copy the record once when writing data into SortBuffer. Besides, we can write only one copy of the data when spilling the data into disk. These optimizations can improve the performance of data broadcast. This patch implements these optimizations.This closes #15259",5
[FLINK-12828][sql-client] Support -f option with a sql script as inputThis closes #15366,1
[hotfix][docs] Correct the check for hugo installation in build_docs.sh,2
[FLINK-21881][table-planner-blink] Support local global optimization for window aggregation in plan (#15412),1
[hotfix][docs] Update docs Readme to mention Hugo extended version.,2
[hotfix][doc] Do not refer to deprecated cancel-with-savepoint in the docs,2
[FLINK-21985][table][sql-client] Support EXPLAIN syntax in SQL Client and Table APIThis closes #15402,1
[FLINK-22022][table-planner-blink] Reduce the ExecNode scan scope to improve performance when converting json plan to ExecNodeGraphThis closes #15426,5
[hotfix] fix broken javadoc links in JDBC connector docThis closes #15413,2
[FLINK-20557][sql-client] Support STATEMENT SET in SQL CLIThis closes #15400,1
[FLINK-21945][streaming] Add StreamPartitioner#isPointwise.,1
"[FLINK-21945][checkpoint] Ensure that each operator is stored in the checkpoint, but do not store empty subtask states.Unaligned checkpoint recovery needs to know the old parallelism pre-rescaling of both upstream and downstream side. Currently, the state is omitted when an operator has no state at all. However, if the downstream operator is omitted, then it's impossible to calculate the channel mapping for upstream and vice versa.The change adds a couple of bytes to the checkpoint per operator (not suboperator). Thus, except for long stateless pipelines, the change would be barely noticeable.",4
[FLINK-21936][checkpoint] Fail early if attempting to rescale pointwise connection.,0
"[FLINK-21936][streaming] Explicitly encode support for unaligned checkpoints into StreamEdge.For any StreamNode, if there is at least one pointwise input, all inputs are marked as not supporting unaligned checkpoint. Thus, independent of the connection, no data is persisted between that node and the direct upstream nodes.",5
[FLINK-21945][streaming] Force aligned barriers on pointwise connections.Introduces the AlignmentType to CheckpointOptions that includes a FORCED_ALIGNED. This barrier acts as an aligned barrier but keeps a potential timeout internally. The timeout is then later used to restore the previous state in SubtaskCheckpointCoordinatorImpl.,1
[FLINK-21945][tests] Add pointwise connection to UnalignedCheckpointRescaleITCase.,1
[FLINK-21945][tests] Refactor UnalignedCheckpoint(Rescale)ITCase to automatically determine slots.This change makes maintenance much easier. Also this commits refactors UnalignedCheckpointITCase to use the same enum-style topology specification as UnalignedCheckpointRescaleITCase for consistency.,2
[FLINK-21945][streaming] Improved UnalignedCheckpointITCase union tests to not capture all elements.The changes allow the test to be executed for a longer time without running into OOM.,1
[FLINK-22020][table-planner-blink] Add org.reflections to 'include' list of maven shade pluginThis closes #15423,1
[FLINK-22037][benchmark] Remove the redundant blocking queue from DeployingTasksBenchmarkBase,4
[FLINK-22021][table-planner-blink] Fix INTERVAL types conversion in RexNodeExtractorThis closes #15424,4
[FLINK-21994][python] Support FLIP-27 based FileSource connector in PyFlink DataStream APIThis closes #15443.,5
[hotfix] Create parent interface for begin/end statement set operation. (#15444),1
"[FLINK-21842][python] Support user defined WindowAssigner, Trigger and ProcessWindowFunction on Python DataStream APIThis closes #15416",5
[refactor][checkpoint] Remove unused method in AlternatingController,1
[refactor][checkpoint] Use Clock instead of directly calling System.nanoTime around checkpoint barriers,5
[refactor][checkpoint] Extracted test builders for CheckpointedInputGate andCheckpointBarrierHandler,0
[refactor][checkpoint] Change always true if block to checkState in SingleCheckpointBarrierHandler,0
[FLINK-19682][checkpoint] Actively timeout checkpoint barriers on inputsThis closes #15313,2
"[FLINK-19682][checkpoint,tests] Add alignment timeout to it tests randomization",3
[FLINK-21252][quickstarts][scala] Forward target java version,1
[Hotfix][docs] Update IDE setupThis updates the setup to use a recent version of IntelliJ and links tothe patched version of the google-java-format plugin which needs to beused at the moment.It also contains some minor grammatical and typographical changes.,4
"[FLINK-21844][runtime] Do not auto-configure maxParallelism in REACTIVE scheduling modeThis moves the configuration and management of vertex parallelism into the control of the scheduler, instead of the ExecutionGraphVertex. This gives the Adaptive scheduler assurances about the task resources when scheduling.",5
[FLINK-21190][test] Adds comment about hashCode/equals implementation,1
[FLINK-21189][runtime] Introduces ExceptionHistoryEntryExtractor,4
[FLINK-21189][runtime] Adds timestamp to FailureHandlingResult,0
[FLINK-22011][table-planner-blink] Use BIGINT instead of TIMESTAMP(3) for slice end column of local window aggregateThis closes #15439,1
[FLINK-22011][table-runtime-blink] Support local global optimization for window aggregation in runtimeThis closes #15439,1
[FLINK-22058][python] Support FLIP-27 based NumberSequenceSource connector in PyFlink DataStream APIThis closes #15445.,5
[FLINK-22051][docs] Explain when to use stop-with-savepoint --drainThis commit extends the existing documentation by stating when to use stop-with-savepoint--drain and when not.This closes #15435.,1
[hotfix][docs] Use Hugo highlighting for danger and info sectionsThis commit uses Hugo's highlighting to emphasize danger and info sections in the cli.md.,5
[FLINK-21413][state] Clean TtlMapState and TtlListState after all elements are expiredThis closes #15016.,4
"[FLINK-21609][tests] Remove usage of LocalCollectionOutpuFormat from SimpleRecoveryITCaseBaseThe LocalCollectionOutputFormat does not work well together with restarts because it records resultsfrom different attempts. Hence, instead of using this format we now use the collect() call in theSimpleRecoveryITCaseBase.This closes #15389.",1
[hotfix][tests] Use MiniClusterWithClientResource in SimpleRecoveryITCaseBaseUsing the resource allows to reuse it across tests and ensures a proper shut down at the end.,3
[hotfix] Make SimpleRecoveryITCaseBase.testRestartMultipleTimes restart strategy agnostic,3
[FLINK-22061][file connector] Fix DEFAULT_NON_SPLITTABLE_FILE_ENUMERATOR to point to NonSplittingRecursiveEnumeratorThis closes #15446.,2
[FLINK-17012][runtime] 'RUNNING' state split into 'RUNNING' and 'RECOVERING' in order to distinguish when the task is really runningThis closes #15221,1
[FLINK-21103] Increased TTL for download cache entries,1
"Revert ""[FLINK-21519] Temporarily disable SQLClientHBaseITCase""This reverts commit b1255c4dd4235822c8538f4e55ce5de5142a96cf.",4
"Revert ""[FLINK-21796] Temporarily disable SQLClientKafkaITCase""This reverts commit 18a9f02fa2c34c36ea29b9f607b88668cf04194d.",4
"Revert ""[FLINK-21556] Temporarily disable StreamingKafkaITCase""This reverts commit 6f8f307e8a196fca8564dbec71ae0e71e34b3200.",5
[FLINK-21556] Add timeout to StreamingKafkaITCase,1
[FLINK-21403][coordination] Throw NoResourceAvailableExceptionAligns the behavior with the default scheduler.,2
[FLINK-21403][table][tests] Remove unnecessary testsThe behavior of the system if the parallelism is excessively high is not an API concern.,5
"[FLINK-21403][tests] Adjust MiniClusterITCaseReduce the number of slots for the test to 0, and set RESOURCE_WAIT_TIMEOUT to let the test pass with the adaptive scheduler.",4
"[FLINK-21148][test] Removes runTest in runDetachedModeTestrunDetachedModeTest is a utility method called by actual tests. These tests aretaking care of setting up the test context for cleanup. Hence, it does not haveto be included in runDetachedModeTest",3
[FLINK-21148][test] Makes the test fail early when running into a timeout,1
[FLINK-21148][test] Increases timeoutThe actual problem of the test failure was that YARN was not fast enough tospin up the Flink cluster. The test waited for 10secs for the job to finish.The logs indicate that there was no issue. The problems occurred when the testinitiated the killing of the YARN application after 10 seconds. Increasing thetimeout should fix this issue.,0
[FLINK-21148][test] Refactors test code to use CommonTestUtils for loops,3
"[hotfix][network] Recycle all buffers before failing releaseAllBuffersCurrently, BufferManager.releaseAllBuffers fails as soon as the recycling of the first buffer fails.This is correct as it likely caused by programmer error.However, this might cause resource leak and lead to subsequent test failures.After this change, it first tries to recycle all buffers and then throws exception if any.",4
[FLINK-22070][python] Support FileSink in PyFlink DataStream APIThis closes #15455.,5
[FLINK-21732][python] Bundle Java libraries into apache-flink-librariesThis closes #15386,2
[hotfix][table-common] Make POJO field detection more lenient,1
[hotfix][table-common] Simplify schema handling with metadata,5
[FLINK-19977][table-api-java] Use name-based projection in ExternalSchemaTranslator,1
[FLINK-19977][table-common] Allow passing RowKind in JoinedRowData,5
[hotfix][table-common] Add default implementation for CatalogTable.toProperties(),2
[FLINK-19977][table] Rework StreamTableEnvironment.fromDataStream,5
[hotfix][table-planner-blink] Use PEEK_FIELDS_NO_EXPAND semantics for structured types,1
[FLINK-19977][table] Allow legacy tests to work with new fromDataStreamThis closes #15428.,5
[hotfix][streaming-java] Allow .returns() on window functions,1
[FLINK-21934][table] Add new StreamTableEnvironment.toDataStreamThis closes #15457.,5
fixup! [FLINK-17012][runtime] 'RUNNING' state split into 'RUNNING' and 'RECOVERING' in order to distinguish when the task is really running,1
[FLINK-17012][streaming] Implemented the restore method in StreamTaskfixup,0
[refactor][streaming] Reorganised StreamTask#restore method,4
[FLINK-22053][core] Allow NumberSequenceSource to have less splits than parallelism.This closes #15449,1
[FLINK-21935][state backends] Remove async parameter for HashMapStateBackend.Checkpoints are always asynchronous now.,2
[FLINK-21935][state backends] Deprecate 'state.backend.async' options.MemoryStateBackend and FsStateBackend ignore the 'asyncSnapshots' parameter as well as the 'state.backend.async' optionand always use asynchronous snapshots now.The 'state.backend.async' ConfigOption is deprecated and unused (removed from all tests).This closes #15429,3
[hotfix][tests] Remove unused code.,1
[FLINK-21976] Remove all files under flink-ml-parentThis closes #15405.,2
[FLINK-21976] Remove fink-ml-* related configs from pom.xmlThis closes #15405.,5
[FLINK-21976] Remove Flink ML related examples from flink-examplesThis closes #15405.,2
[FLINK-21976] Remove python packages under flink-python/pyflink/mlThis closes #15405.,2
[FLINK-21976] Remove pyflink/ml related configs from python scriptsThis closes #15405.,5
[FLINK-21191][upsert-kafka] Support buffered sink function for upsert-kafkaThis closes #15434,1
[FLINK-21808][table-planner-blink] Add getter for RelOptCluster in PlannerContextThis closes #15253,1
[FLINK-21808][table-planner-blink] Add operation for CREATE TABLE ASThis closes #15253,1
[FLINK-21808][table-planner-blink] Add RelNode for SORT/DISTRIBUTE/CLUSTER BYThis closes #15253,1
[FLINK-21808][table-api-java] Add NOP operationThis closes #15253,1
[FLINK-21808][hive] Support DQL/DML in HiveParserThis closes #15253,1
[FLINK-16444][state] Separate state backend and checkpoint options,2
[FLINK-16444][state] Introduce latency tracking state config and basic classes,5
[FLINK-16444][state] Enable to create latency tracking state,1
[FLINK-20320][sql-client] Support init sql file in sql clientThis closes #15437,2
"[FLINK-22048] Remove akka.transport.* config optionsSince Flink uses TCP connections for Akka, we don't need to configure thetransport failure detector and the exposed configuration options are meaningless.Consequently, this commit removes them.This closes #15433.",4
[FLINK-21685][k8s] Use dedicated thread pool for Kubernetes client IO operationsThis closes #15385.,1
[FLINK-13550][rest] Add WebMonitor endpoint and Flame Graph REST handler,0
[FLINK-13550][ui] Add job vertex FlameGraph UI,1
[FLINK-13550][ui] Add automatically-generated package-lock.json,5
[FLINK-13550][docs] Add docs,2
[FLINK-13550][rest] Extracting light-weight gateway interface for flamegraph RPC endpoint for easier test setup and fixing RPC timeout.Co-authored-by: Chesnay Schepler <chesnay@apache.org>,0
[FLINK-21817][connector/common] Remove SplitAssignmentTracker and SourceCoordinatorContext from coordinator checkpointThis closes #15397,4
[FLINK-22093][coordination][tests] Harden ThreadInfoSampleServiceTest,5
[FLINK-21942][coordination] Remove job from JobLeaderIdService when disconnecting JobManager with globally terminal state,4
[FLINK-21942] Extract JobLeaderIdService interface to make the ResourceManager better testable,3
[FLINK-21942][tests] Introduce TestingJobLeaderIdService and use it in ResourceManagerTestThis closes #15407.,3
[FLINK-21817][connector/kafka] Remove mapping of reader id to split assignments from Kafka enumerator and its state,4
[FLINK-21159][connector/kafka] Signal NoMoreSplitsEvent to all readers even without any assignmentsThis closes #15461,2
[hotfix][connector/kafka] Fix incorrect lambda,0
[FLINK-21927][table-planner-blink] Resolve ExpressionReducer compile fail when running long term (#15354)This commit replaces CodeGenUtils#nameCounter from AtomicInteger to AtomicLong to resolveInteger overflow issue,0
"[hotfix][docs] Fix 'List of all Variables' links in metrics reportersCorrectly link to list of all metric variables,which has moved to the ops section.Signed-off-by: austin ce <austin.cawley@gmail.com>This closes #15475",4
[FLINK-22055][runtime] Fix RpcEndpoint MainThreadExecutor schedules callables with potential wrong time unit.This closes #15411,0
[FLINK-22095][python] Remove bundled licenses in apache-flink distributed packageThis closes #15478,1
[FLINK-22064][sql-client] Don't submit STATEMENT SET when no INSERT is added in the sql clientThis closes #15458,1
"[FLINK-21963] Harden ReactiveModeITCaseThis commit fixes a test instability in ReactiveModeITCase.testScaleDownOnTaskManagerLoss() where a CountDownLatch was counted down on an execution of the test source that got cancelled for a scale up event (despite its name, a scale up can happen in the test as well). This test instability only happens if there is enough time between the notification of new slots so that the source can start in between. On fast machines, the execution gets cancelled during scheduling, because the slots arrive together.With this commit, we are not using a latch, but counting the number of running instances explicitly.This closes #15417.",1
[FLINK-22076][python] Split the global test into multiple module testsThis closes #15481,3
[FLINK-21829][hive] Fix exception when custom hadoop conf path does not exist or there is no conf fileThis closes #15427,2
[FLINK-21714][table] Use TIMESTAMP_LTZ as return type for function PROCTIME()This closes #15280,1
[FLINK-21133][connector/checkpoint] Fix the stop-with-savepoint case in FLIP-27 source by stopping the mailbox loop in SourceOperatorStreamTask#finishTask().,5
[FLINK-22103][hive] Fix HiveModuleTest for Hive v1.2.1This closes #15482,3
[hotfix][docs] Fix the broken link in the python overview doc,2
[FLINK-21754][core] Fix 'Exception message does not point to the right path.'This closes #15486.,0
[FLINK-22050][runtime] Don't release StreamTask network resources from TaskCancellerConcurrent release could lead to race conditions.,1
[FLINK-21879][tests] Harden ActiveResourceManagerTest.testWorkerRegistrationTimeoutNotCountingAllocationTimeHardens the ActiveResourceManagerTest.testWorkerRegistrationTimeoutNotCountingAllocationTime by introducingthe assumption that the registration is faster than the start worker timeout.This closes #15474.,1
[FLINK-22003][checkpointing] Prevent checkpoint from starting if any Source isn't running,1
[hotfix][tests] Set checkpoint timeout in UnalignedCheckpointITCaseThis prevents test from timing out in case when a failover happensconcurrently with triggering a checkpoint (some execution status canchange right after triggering).,4
[hotfix][tests] Transition to RECOVERING before RUNNING in DefaultSchedulerTest,3
[FLINK-21880][tests] Ignore incomplete checkpoints in UnalignedCheckpointRescaleITCase,3
[FLINK-16947][Azure] Use latest docker image for CI,2
[FLINK-22094] Update release scripts after documentation switch to Hugo,2
[FLINK-17012][webui] Added support of RECOVERING state,1
[FLINK-22105][tests] Fix checkpoint id in testForceAlignedCheckpointResultingInPriorityEvents,3
[hotfix][tests] Close SubtaskCheckpointCoordinator in testsThis is to reveal any async failures occurring forexample when writing channel state.,0
[FLINK-22014][ha] Make sure that AbstractHaServices delete first the HA data before deleting blobs on closeAndCleanupAllDataThe AbstractHaServices should always first delete the HA data (pointers to jobs and checkpoints) before deleting the referencedobjects such as blobs. That way we ensure that we don't leave the system in an invalid state if the process stops abruptly becauseeither all the data is still available or the pointers have been cleared and Flink only leaves some orphaned blobs. The casewhere the pointers are still there but not the blobs will no longer be possible with this fix.This closes #15468.,0
"[FLINK-22006][k8s] Support to configure max concurrent requests for fabric8 Kubernetes client via JAVA opts or envsAfter this commit, users could use any one in the following Flink config options to set the concurrent max requests, which allows to run more jobs in a session cluster. Please note that, each Flink job will consume 3 concurrent requests.* containerized.master.env.KUBERNETES_MAX_CONCURRENT_REQUESTS: 200* env.java.opts.jobmanager: ""-Dkubernetes.max.concurrent.requests=200""",2
[FLINK-22006][doc] Add documentation about how to configure Fabric8 Kubernetes clientThis closes #15480.,5
[FLINK-21980][zk] ZooKeeperRunningJobsRegistry creates an empty znodeThis closes #15393.,1
[FLINK-21873][connector/common] Harden CoordinatedSourceRescaleITCase by checking exceptions more leniently.,2
"[FLINK-17957][sql-parser] Forbidden syntax ""CREATE SYSTEM FUNCTION"" for sql parser (#15494)",1
[hotfix][docs] Updata max parallelism behavior for Reactive Mode,5
[FLINK-21240][jdbc] Fix Mysql row converter doesn't support external LocalDateTime typeThis closes #15506,5
[hotfix][tests] Reverting log level to OFF,2
[FLINK-22081][core] Fix entropy injection metadata path in pluggable HadoopS3FileSystem,5
[FLINK-21386][datastream] Assert that AbstractUdfStreamOperator redirects OutputTypeConfigurable to function,1
[FLINK-21386][datastream] Postpone FromElementsFunction serialization to respect later type customizationThis fixes cases where earlier determined serializer was incorrect and returns() was ignored.This closes #15507.,0
[FLINK-21954][tests] Harden JobMasterTest.testRestoringFromSavepoint and .testRequestNextInputSplitWithGlobalFailoverThe test instability has been introduced by FLINK-21602 because the ExecutionGraphis now created asynchronously. This commit fixes the test instabilities in JobMasterTestby waiting for a task submission before asserting on the state.,3
"[FLINK-21954][tests] Harden JobMasterQueryableStateTestDue to FLINK-21602, the ExecutionGraph is now created asynchronously. That's why wehave to wait for a task submission until we can use queryable state because then theExecutionGraph is created.This closes #15465.",1
[FLINK-22138][table] Add field information to inline StructuredType strings,5
[hotfix][table-common] Add shortcut for defining rows without names in API,5
[FLINK-22138][table] Allow casting between row and structured typeThis closes #15516.,1
[FLINK-21152][build] Bump flink-shaded to 13.0,2
[FLINK-22142][ci] Don't log Kafka connector output to the AZP consoleThis commit removes the console logging of the Kafka connector to the AZP console.This closes #15512.,2
[FLINK-22077] Fix incorrect way to create cross-region ConsumedPartitionGroups in PipelinedRegionSchedulingStrategy[FLINK-22077] Add tests for computing cross-region ConsumedPartitionGroupsThis closes #15500.,3
[FLINK-22107][hive] Include antlr into hive connector uber jars (#15492),2
[FLINK-22102][hive] Throw meaningful exceptions for unsupported DDLs (#15515),1
[FLINK-22097][sql-client] CliResultView#cleanUp should wait RefreshThread exitsThis closes #15520,4
[FLINK-21833][table-runtime-blink] Fix state of TemporalRowTimeJoinOperator increase unlimitedly even state ttl is enabledThis closes #15247,0
[FLINK-22062][docs] Add 'Data Sources' (FLIP-27 sources overview page) page from 1.12.x to masterThis closes #15526,5
"[FLINK-22084][coordination] Use a consistent default max parallelism and restore logic in the Adaptive SchedulerEnsure that the same max parallelism value is usedas a the default in the Adaptive Scheduler betweensubmissions, and that the default is able to beoverridden from state restore.Previously, the default was used as if it werespecified by the user in the JobGraph, makingit impossible to rescale from a configuredmaxP to the default.",5
[FLINK-22143][table-runtime] Fix less lines than requested returned by LimitableBulkFormat (#15513),0
[FLINK-22148][table] Planner rules should use RexCall#equsls to check whether two rexCalls are equivalentThis closes #15529,1
[hotfix] Fix the release version for JdbcXaSinkFunction,5
[hotfix] Remove unnessary rollbackPreparedFromCheckpoint from JdbcXaSinkFunction.snapshot,5
[FLINK_21972][table-planner-blink] check whether TemporalTableSourceSpec can be serialized or notThis closes #15370,2
[FLINK-21519] Temporarily disable SQLClientHBaseITCase,2
[FLINK-20387][table] Support TIMESTAMP_LTZ as rowtime attributeThis closes #15485,1
[hotfix][table-runtime] Fix the exception info of raw format (#15418),5
[hotfix][yarn-tests] Check the applicationId in verifyStringsInNamedLogFiles,2
[FLINK-21008][coordination] Register ClusterEntrypoint#closeAsync as shutdown hook for the cleanupThis closes #15396.,4
[hotfix][docs] Add missing parenthesis,1
[hotfix] Use AllocationID instead of JobID when slot cannot be marked as active.,1
[FLINK-22172][python] Fix the bug of shared resource among Python Operators of the same slot is not releasedThis closes #15537.,1
"[FLINK-15146][core][ttl] Fix check that incremental cleanup size must be greater than zero.At the moment, we allow zero value for the TTL incremental cleanup size.Although technically zero value will not break the cleanup but practically there will be no cleanup.We change cleanupSize to be strictly greater than zero to avoid confusion.",5
[FLINK-22120][table-planner-blink] Remove duplicate code in generated code for map get (#15519)Co-authored-by: zoudan <zoudan@bytedance.com>,1
[hotfix][tests] Remove redundant setup statement in OperatorCoordinatorSchedulerTestThis is accidental leftover from some refactoring.,4
[hotfix][runtime] Minor format cleanup in OperatorCoordinatorHolder,1
[FLINK-21850][docs] Improve config descriptions of sort-merge blocking shuffle and remove outdated documentThis closes #15490.,2
[FLINK-22187][docs] Remove description of sync checkpoint mode of HashMapStateBackend,4
[FLINK-22191][python] Fix the thread safe problem in PythonSharedResourcesThis closes #15560.,0
[FLINK-22106][table-planner-blink] Result type of GeneratedExpression in StringCallGen should be compatible with their definition in FlinkSqlOperatorTableThis closes #15489,2
[FLINK-20230][table] FileSystemOutputFormat should delete file using FileSystemFactoryThis closes #15541,5
[FLINK-17371][table-runtime] Open testDefaultDecimalCasting case in DecimalTypeTestThis closes #15544,3
[FLINK-22015][table-planner-blink] Exclude IS NULL from SEARCH operators (#15547),1
[hotfix][table-common] Support negative decimal scale in fromValues,1
[FLINK-22151][table-api-java] Add grouped aggregation information to CallContext,5
"[FLINK-22151][table] Update type inference of avg, sum, sum0, count, min, max, stddevPop/Samp, varPop/SampThis closes #15551.",5
[FLINK-22184][client] Shutdown client outside of netty thread,2
[hotfix][test] Minor clean-ups in DemultiplexingRecordDeserializerTest.,3
[FLINK-21950][core][test] Fix double-freeing memory segment in DemultiplexingRecordDeserializerTest.We are planning to fail strictly on double-freeing memoty segments soon.This closes #15542,0
[FLINK-21031][checkpoint] Reenable JobMasterStopWithSavepointIT,0
"[FLINK-20816][tests] Fix race condition in NotifyCheckpointAbortedITCase.The test implicitly assumes that abortion of chk-1 happens before sync phase of chk-2. If abortion is late, the mail that handles the abortion is never executed since the waitLatch blocks the mailbox thread. The latch in turn is never triggered as chk-1 is not aborted.The fix is to move the wait latch on chk-2 into the source - the only operator that isn't checked for abortion. Thus, the deadlock cannot happen.",1
[FLINK-22131][python] Fix the bug of general udf and pandas udf chained together in map operationThis closes #15502.,1
"[FLINK-22082][table-planner-blink] Nested projection push down doesn't work for composite types, such as row(array(row))This closes #15493",1
[FLINK-22157][table-planner-blink] Fix join & select a portion of composite primary key will cause ArrayIndexOutOfBoundsExceptionThis closes #15540,1
[FLINK-22152][python] Fix the bug of same timers are registered multiple timesThis closes #15575.,0
[FLINK-22121][table-planner-blink] The field names in Rank and Over should be uniqueThis closes #15498,2
[FLINK-22166][table] Empty values with sort willl failThis closes #15571,0
[FLINK-21748][sql-client] Fix unstable LocalExecutorITCase (#15563),0
[FLINK-22202][parquet] Thread safety in ParquetColumnarRowInputFormatThis closes #15572,2
"[FLINK-21675][table-planner-blink] Fix that predicates can not be pushed into TableScan when there is a WatermarkAssigner between Filter and ScanCo-authored-by: fsk119 <33114724+fsk119@users.noreply.github.com>, godfreyhe <godfreyhe@163.com>This closes #15307",1
[hotfix][python] Fix possible null pointer exception in PythonDriver,0
[FLINK-21012][format-avro] Replace lambda with anonymous class to prevent serialization issuesThis closes #15583,0
[FLINK-17803][table] Should throw a readable exception when group by Map typeThis closes #15543,2
[hotfix][python] Improve the error message in PythonDriver,0
[FLINK-22124][python] Fix the bug that errors are not thrown in custom python functionThis closes #15590.,1
[FLINK-22215][runtime] RECOVERING state is renamed to INITIALIZING,5
[hotfix] Correct log statement content,2
[FLINK-22249][FLINK-22248] Temporarily disable JobMasterStopWithSavepointITCase,2
[FLINK-21305][table-planner-blink] Fix Cumulative and Hopping window should accumulate late events belonging to the cleaned sliceThis closes #15495,4
[FLINK-17371][table-runtime] Add cases for decimal castingThis closes #15568,1
[FLINK-22245][sql-client] Use PrintUtils.MAX_COLUMN_WIDTH as default max column width in client result viewsThis closes #15580,1
[hotfix][tests] Use the latest checkpoint in UnalignedCheckpointTests,3
[FLINK-22197][tests] Shutdown cluster before collecting checkpoints,3
[FLINK-21032][table] Not use ParallelFiniteTestSource in CompactionITCaseBaseThis closes #15538,1
[FLINK-22167][table-planner] Partial insert not works when complex fields reorderThis closes #15545,1
[FLINK-21743] Document limitation of JdbcXaSinkFunction for MySQL support,1
[FLINK-22252][docs][config] Fix backticks rendering,0
[FLINK-21431][kafka] Use testcontainers for Kafka table IT casesThis closes #15578,3
[FLINK-21839][docs] Document stop-with-savepoint behavior more explicitlyThis closes #15594,2
[FLINK-22207][hive] Fix retrieving Flink properties in Hive Catalog (#15564),2
[FLINK-21592][table-planner-blink] RemoveSingleAggregateRule fails due to nullability mismatch (#15082),0
[FLINK-22063][table] Fix bug that some join conditions are lost when building Lookup Join ExecNodeThis closes #15533,0
[FLINK-22212][coordination] Refactor resource requirement logging,2
[FLINK-22211][datastream] Only log exceptions if job has been initialized,5
[FLINK-22214][runtime] Refactor CheckpointStorageLoader- deduplicate and sync code between 'fromConfig' and 'createDefaultCheckpointStorage'- use constants for storage names- use quotes around used storage names,1
"[FLINK-22218][runtime] Silence sending of null input splitA null input split is sent as a signal that no more split is available. This isn't a detail we should expose via logging, and this circumstance is already logged elsewhere.",2
"[FLINK-22219][coordination] Reduce duplicate ExternalResource loggingReduce the public ExternalResourceUtils API, and move the logging into these API points from (now) internal methods.",2
[FLINK-22216][coordination] Log start of RM instead of SlotManager on info,5
[FLINK-22210][task] Log conversion of input channels on DEBUG,0
[FLINK-22220][task] Log task registration at network on DEBUG,0
[FLINK-22213][filesystem] Do not log factory hashcodes,2
[FLINK-22144][runtime][runtime-web] Adds more documentation and moves option- `jobmanager.exception-history-size` is moved to `web.exception-history-size`- the documentation was slightly extended- some minor mistakes in the docs are fixed,0
[refactor][runtime] Update FutureUtils to support delayed completing of a CompletableFuture,1
[refactor][runtime] Extend AkkaRpcServiceUtils to support instantiating custom AkkaRpcServices.,1
"[FLINK-21996][refactor] Make IteratorSourceReader work with multiple split requests.Previously, the IteratorSourceReader was designed to only ever be able to send a single split request.No second request could be handled, multiple splits could only be handled when they were restored froma checkpoint.That is both fragile and inextensible, because it doesn't support cases where more splits than subtasks aregenerated, and the contract can be broken with certain combinations of deployments, checkpoints, scaling, restoring.A variant that simply handles multiple splits when necessary is minimally more complex in the code, anda lot more flexible and robust.",5
[FLINK-21996][refactor] Make NumberSequenceSource extensible to allow specifying the number of desired sequence splits.,1
[FLINK-21996][tests] Add ITCase to test for delayed and failed operator event sending.,1
"[FLINK-21996][refactor] Unify exception handling for Operator Coordinator Events sent to not-running tasksSending an event to a not-running task sometimes throws an exception directly from the method (if the event is immediately sent)and sometimes completes the resulting future with an exception (for example if the event had to be enqueued until after checkpointbarrier injection to preserve exactly-once sematics).This changes the code to always report those exceptions through the result future and never through direct exception throwing,to simplify and unify the way this can be handled by the calling code.",0
[FLINK-21996][refactor] Pull in-line serialization call into separate statement to improve Exception handling accuracy.,1
"[FLINK-18071][coordination] (part 1) All event sending and checkpoint actions for OperatorCoordinator happen in Scheduler ThreadHaving event sending in the scheduler thream means that at the time when the event is dispatched to the subtask, we havea concistent view on the execution state of a task execution and are not subject to any race conditions.But when event sending is in the scheduler thread, the checkpoint completion must be in the scheduler thread as well,to that we keep strict ordering of events and checkpoints.",1
[hotfix][table-planner-blink] Extract primary key from resolved schemaThis closes #15539.,0
"[FLINK-21992][network] Fix availability notification in UnionInputGate.The available notification of UnionInputGate is reset when the last gate with data is read independent of how many buffers are still available in the gate.Further, data notification is only triggered on the first non-priority event in Single/UnionInputGate.",5
[FLINK-21859][coordination] Ignore outdated slot offer responses,5
[hotfix][tests] Remove unnecessary component,4
[FLINK-22180][coordination] Only reclaim slots if job is removed,4
[FLINK-21660][hive] Stop using is_generic to differentiate hive and flink tables (#15155),2
[hotfix][python] Add missing comments for a few methods in data_stream.py,5
[FLINK-22273][python][docs] Add documentation for General Python Group Window Aggregation in Python Table APIThis closes #15609.,2
[FLINK-22169][sql-client] Improve CliTableauResultView when printing batch results (#15603),1
"[FLINK-22260][table-planner-blink] Use unresolvedSchema during operation convertionsThe #getSchema implementation has been deprecated and returns null bydefault, so we need to instead use the unresolved schema and derive theTableSchema from that.This closes #15606.",0
[FLINK-20761][hive] Escape the location path when creating input splits (#15549),1
[hotfix] Let JobMasterStopWithSavepointITCase.ExceptionOnCallbackStreamTask implement finishTask to finishIn order to properly finish ExceptionOnCallbackStreamTask the Task needs to implement finishTask.,5
[FLINK-22154][table-planner-blink] Fix bug where PushFilterIntoTableSourceScanRule fails to deal with IN expressionsThis close #15525,0
[FLINK-22236][docs] Document opt-in behavior of FlameGraph[review] add @alpinegizmo suggestionsCo-authored-by: David Anderson <david@alpinegizmo.com>linktmptmp,2
[FLINK-20779][python][docs] Add documentation for row-based operation in Python Table APIThis closes #15607.,2
[FLINK-22125][python] Returns None when a key doesn't exist when calling MapState.get()This closes #15618.,1
[FLINK-22292][python][docs] Add documentation for state acess in Python DataStream APIThis closes #15623.,5
[hotfix][tests] Remove unnecessary volatile in RescalingITCase,4
[FLINK-21941] Make sure jobs do not finish before taking savepoint in RescalingITCase,5
[FLINK-22286][python] Fix picklebytescoder doesn't support custom python classThis closes #15626.,1
[FLINK-21990][streaming] Cancel task before clean up if execution was failed,0
[FLINK-22288][connectors / jdbc] Remove unnecessary argument in JdbcSink,5
[FLINK-22244][docs] Adjust Reactive Mode docsThis closes #15592,2
[FLINK-21879][tests] Harden ActiveResourceManagerTest.testWorkerRegistrationTimeoutNotCountingAllocationTimeWait for the registration response before measuring the passed time for the assumption criterion.This closes #15621.,4
[FLINK-21346][build system] Add uploading watchdog to all tasks with stacktraces.The test/e2e task is killed before timeout and artifacts are published in the regular way. If killed jps traces and watchdog output are additionally attached to mvn.logs.,2
[FLINK-21346][build system] Using FLINK_LOG_DIR in e2e.This closes #15546,2
[FLINK-22298][table-planner-blink] The ExecNode's id should always start from 1 in the json plan testsThis closes #15639,3
[FLINK-21346][hotfix] Revert installing required bc for e2e tests,3
"[hotfix][coordination] Add Main-Thread check to OperatorEvent sending on Execution.Now that the threading model of the OperatorCoordinatorHolder has been adjusted, we canfinally have this check and use this method in accordance with the general contract ofthe Scheduler.",1
"[FLINK-18071][coordination] (part 2) OperatorCoordinatorHolder does not implement OperatorCoordinator interface any moreOriginally it was designed that the OperatorCoordinatorHolder has the same interface as the OperatorCoordinator and simplyadds some hooks around the checkpoint triggering procedure.However, the OperatorCoordinatorHolder is becoming the glue between the scheduler threads and the scheduler's view ontasks and their status, and the OperatorCoordinator threads and their simplified view on the execution state. Thismeans they do require different interfaces.",1
"[FLINK-18071][coordination] (part 3) Adjust OperatorEventValve to accept self-contained ""send actions"".The ""send actions"" (as Callables) contain the events and versioned target information, so they can preciselyaddress the recipient regardless of whether they are sent immediately or later, after the targettask has failed/recovered.",0
[FLINK-18071][coordination] (part 4) Add to Execution a future for states INITIALIZING/RUNNINGThis doubles as a listener for when the execution has reached the state INITIALIZING or RUNNING.,1
"[FLINK-18071][coordination] (part 5) Communication from Coordinators to Tasks happens through gateways that are scoped to a single execution attempt.That way the events have a well specified target, no matter how much the actual sending is delayed due to raceconditions.This also un-ignores the CoordinatorEventsExactlyOnceITCase that now runs stable with this fix.",0
"[hotfix][coordination] Make failed event valve shutting smoother.Failing to shut the event valve is quite common, it happens whenever a checkpoint gets canceled.So we don't handle this as an IllegalState, because it is very much an expected state.",1
"[hotfix][coordination] Reduce lambda nesting for action on CompletableFutureDirectly use 'whenCompleteAsync()' with an executor, rather than 'whenComplete()' and nest a callto submit to the executor.",1
[hotfix][coordination] Remove unnecessary null check,4
[hotfix][tests] Minor debuggability improvements to CoordinatedSourceRescaleITCase,1
[hotfix][tests] Simplify and harden CoordinatorEventsExactlyOnceITCase,3
[hotfix][table-api-java] Improve built-in functions as parameters of user-defined functions,1
[FLINK-20613][table-planner-blink] Support unidirectional ExternalSerializer,1
[FLINK-20613][table] Introduce a legacy to non-legacy data type transformation,5
[FLINK-20613][table] Update TableResult.collect() to the new type systemThis closes #15588.,5
[FLINK-22290][checkpointing] Use duration for alignment timeout.,1
[FLINK-22290][checkpointing] Adding alignment timeout and force unaligned checkpoint options to PyFlink and polished Java API.,1
[hotfix][docs] Fix config doc structure,2
[FLINK-22249][tests] Add `FAILLING` to an assertion in JobMasterStopWithSavepointITCase,3
[FLINK-22248][tests] Remove timeouts from JobMasterStopWithSavepointITCase,4
[hotfix][tests] Cancel all running jobs after each test in AbstractTestBase,3
[FLINK-22248][tests] Improve JobMasterStopWithSavepoint#waitForJob to wait for all tasks running,1
"Revert ""[FLINK-22249][FLINK-22248] Temporarily disable JobMasterStopWithSavepointITCase""This reverts commit eb631935dcce5b037e3ad5245f48e373b5b3c426.",4
[FLINK-22276][runtime] Adds workaround for FLINK-22276This is just a temporary workaround. The actual fix should be provided byFLINK-22276 before releasing 1.13.This closes #15648.,2
[FLINK-21996][coordination] Ensure exactly-once guarantees for OperatorEvent RPCsThis consists of two changes that work together:  - Delay checkpoints until we have clarity about all in-flight OperatorEvents  - Fail target subtask if the result future for an OperatorEvent send fails,0
[hotfix][coordination] Add safety guard against uncaught exceptions for Future dependent lambdas,1
[FLINK-22016][table-planner-blink] RexNodeExtractor#visitLiteral should deal with NULL literals correctly (#15570),4
[FLINK-22308][sql-client] Fix CliTableauResultView print results after cancel in STREAMING mode (#15644),0
[FLINK-20855][table-runtime-blink] Fix calculating numBuckets overflow (#14566),0
[FLINK-22117] Reduce the logs if not all tasks are RUNNING when checkpointing,1
"[FLINK-22307][network] Increase the default value of data writing cache size (not configurable) for sort-merge blocking shuffleCurrently, the data writing cache of sort-merge blocking shuffle is 8M, which can be not enough if data compression is enabled. This patch increases the cache size to 16M which can improve the performance for high compression ratio scenarios.This closes #15651.",1
[FLINK-22310][table-planner-blink] Fix the incorrect deserialization result of LogicalWindowJsonDeserializerThis closes #15645,5
[FLINK-21627][table-planner-blink] The digest of TableScan should consider table hintsThis closes #15559,2
[FLINK-21627][table-planner-blink] The digest of Sink should consider table hintsThis closes #15559,2
[FLINK-22303][table-planner-blink] FlinkRelMdFilteredColumnInterval should remapping the columnIndex of the inputRel otherwise may cause IllegalArgumentException or get incorrectly metadataThis closes #15641,5
Update version to 1.14-SNAPSHOT,5
[FLINK-22327][python] Makes sure that bundleStarted is set to false when it throws exception in finishBundleThis closes #15650.,5
[FLINK-22104][sql-client] Fix unstable SqlClientTest.testExecuteSqlFileThis closes #15534,3
[FLINK-22099][table-planner-blink] Fix bug about throwing ArrayIndexOutOfBoundsException when window join deals with semi/anti queriesThis closes #15477,0
"[hotfix][docs] Removed reference to ""fold"" function in ""Windows"" page (#15574)",1
[FLINK-21798][test] Fail on double-freeing memory segment for CI tests.This closes #15566,3
[FLINK-22085][tests] Update NetworkFailureHandler to prevent closeOnFlush() from being called recursively,0
[FLINK-22339][python] Fix some encoding exceptions were not thrown in cython codersThis closes #15661.,0
[FLINK-22338][table-planner] Clear watermark output when test finished for FromElementSourceFunctionWithWatermarkThis closes #15659,1
[hotfix][runtime] Minor clean-up in ThreasholdMeter.,4
[FLINK-22340][runtime] Make ThresholdMeter thread safe.This closes #15662,1
[hotfix][python] Fix typo in BeamDataStreamPythonFunctionRunnerThis closes #15581.,5
[FLINK-22208][build] Bump snappy-java to 1.1.8.3,2
[FLINK-22098][table-planner-blink] Fix bug for window join: plan is wrong if join condition contains 'IS NOT DISTINCT FROM'This closes #15476,0
[hotfix][runtime] Wrong annotation was usedThe Throwable can be null in that case due to FLINK-21376. We're not enforcingthat behavior for now. FLINK-22060 covers the resolution on the ExecutionGraphside. FLINK-21376 covers the issue on the Task side.,0
[hotfix][test] Cleans up unused local variable,1
"[FLINK-22276][runtime] Fixes the concurrency issueThis commit fixes an issue where multiple failures can occur close to each other.In that case, the DefaultScheduler's restart logic competes for each of thesefailures. If multiple failures refer to the same Execution, it might be that therestart due to one failure handling cleans up the failure already. This leads toan IllegalArgumentException when archiving the next failure refering to the sameExecution. The issue was that the code relied on ExecutionVertices instead ofExecutions.The new implementation relies on the Executions that were present when thefailure was handled. Therefore, FailureHandlingResultSnapshot is introduced. Itextracts the Execution information from the ExecutionGraph.Additionally, instead of accessing on ExecutionVertex.getTaskNameWithSubtaskIndex()to collect the task name, the new implementation relies onExecution.getVertexWithAttempt(). This enables us to solely rely on the Executionwithout an extra dependency on the ExecutionVertex.The new implementation also removes the add method from RootExceptionHistoryEntry.This makes the instantiation cleaner. ExceptionHistoryEntryExtractor was replacedby the factory methods RootExceptionHistoryEntry.fromFailureHandlingResultSnapshot andRootExceptionHistoryEntry.fromFailureHandlingResultSnapshot as part of this effort.This closes #15640.",0
[FLINK-22351][coordination] Promote resource declaration log to INFO in FineGrainedSlotManagerThis closes # 15669,5
[FLINK-21073][docs] Mention that RocksDB would ignore java's equals/hashCode during comparing objects,5
[FLINK-22092][hive] Ignore static conf file URLs in HiveConfThis closes #15483,5
[FLINK-22297][python] Perform early validation for the result of Pandas UDFThis closes #15681.,5
[FLINK-22335][runtime][config] Increase default resource wait timeout for the adaptive scheduler.This closes #15657,1
[FLINK-21986][State Backends] fix native memory used by RocksDB not be released timely after job restart[FLINK-21986][State Backends] fix spotless-check errorThis closes #15619.,0
[FLINK-22352][mesos] Deprecates Mesos support,1
[FLINK-22264][docs] Fix misleading statement about Flink Job Cluster Kubernetes Support in Flink Architecture page[FLINK-22264][docs] Add Chinese documentationThis closes #15602.,2
[FLINK-22359][release] Remove updating version of pyflink in create_release_branch.sh,1
"[FLINK-21106][docs] Updates Flink docs to refer to the plugin's pagegoogle-java-format plugin 1.7.0.6 was released(https://github.com/google/google-java-format/issues/560). Hence, we do nothave to rely on the patched version of FLINK-21106 anymore.",2
[FLINK-22346][sql-client] Remove sql-client-defaults.yamlThis closes #15670,4
[FLINK-21796][FLINK-17510] Disable tests that use KafkaResource,1
[FLINK-22133][core] Add checkpointID to 'SplitEnumerator.snapshotState()'This closes #15677,1
[hotfix][rocksdb] Properly adjust RocksDB config options to new builder pattern,1
[FLINK-21694][rocksdb] Increase default value for 'state.backend.rocksdb.checkpoint.transfer.thread.num',5
[FLINK-22239][jdbc] Pool connections in JDBC XA sinkSome databases like PostgreSQL and MySql allow at mostone XA transaction per connection. Using new connectionfor each transaction (and pooling) allows to overcomethis limitation.,1
[FLINK-22239][jdbc] Rollback XA transactions on recoveryLeaving transactions not rolled back may lead to newtransactions being blocked by the old ones.,1
[FLINK-22239][tests] Test JDBC XA Sink against PostgreSQL,5
[hotfix][docs][pyflink] Regenerate docs and adjust PyFlink tests fpr FLINK-21694,2
[hotfix][runtime] Log checkpoint processing delay if above threshold,2
"[FLINK-21329][tests] Increase timeout and delay in local test_local_recovery_and_scheduling.shBack-pressure is likely to occur without injection delay at the sourcewhich may lead to delaying checkpoint triggering at the sourceswhich may lead to a timeout.To prevent this, test timeout is increased from 10m to 15mand injection delay of 100ms is added.",1
[FLINK-20722][hive] HiveTableSink should copy the record when converting RowData to RowThis closes #14484,5
[FLINK-22372][table-common] Fix typo of parameter name of LogicalTypeCasts#castTo methodThis closes #15686,2
[FLINK-22171][docs][sql-client] Update the SQL Client documentation for FLIP-163This closes #15595,2
"[hotfix][docs] Add SQL CLI examples in Table API ""Configuration"" page",5
"[FLINK-22302][docs][table] Restructure SQL ""Queries"" documentation into one page per operationThis closes #15642",2
[FLINK-22159][docs][table] Add documentation for the new window TVF based operationsThis closes #15642,1
"[FLINK-22302][docs][table] Update ""Queries"" Chinese documentationsThis closes #15642",2
[FLINK-22302][docs][table] Improvements content based on reviewsThis closes #15642,1
[FLINK-18206][table-api][sql-client] Fix the incorrect timestamp displayThis closes #15658,0
[hotfix][DataStream] Remove redundant call to StreamConfig#setCheckpointStorage,5
[hotfix][checkpointing] Properly record amount of processed data,5
[FLINK-22369][rocksdb] RocksDB state backend might occur ClassNotFoundException when deserializing on TM side,5
[FLINK-21302][table-planner-blink] Fix NPE when use row_number() in overAggThis closes #14880,1
[FLINK-22349][table-api] Throw Exception for unsupported Zone ID instead of using wrong valueThis closes #15678,0
[hotfix][docs][python] Fix the invalid url in state.md,0
[hotfix][table-planner-blink] Fix bug for window join: plan is wrong if join condition contains 'IS NOT DISTINCT FROM'Fix Flink-22098 caused by a mistake when rebasingThis closes #15695,1
[hotfix][docs] Fix the invalid urls in iterations.md,0
[FLINK-16384][table][sql-client] Support 'SHOW CREATE TABLE' statementThis closes #13011,1
"[FLINK-16384][table][sql-client] Improve implementation of 'SHOW CREATE TABLE' statement.This commit tries to1. resolve the conflicts2. revert the changes made on old planner3. apply spotless formatting4. fix DDL missing `TEMPORARY` keyword for temporary table5. display table's full object path as catalog.db.table6. support displaying the expanded query for view7. add view test in CatalogTableITCase, and adapt sql client test to the new test framework8. adapt docsThis closes #13011",2
[hotfix][docs][python] Add missing pages for PyFlink documentation,2
[FLINK-22348][python] Fix DataStream.execute_and_collect which doesn't declare managed memory for Python operatorsThis closes #15665.,1
[FLINK-22350][python][docs] Add documentation for user-defined window in Python DataStream APIThis closes #15702.,5
[FLINK-22354][table-planner] Fix the timestamp function return value precision isn't matching with declared DataTypeThis closes #15689,5
[FLINK-22354][table] Remove the strict precision check of time attribute fieldThis closes #15689,4
[FLINK-22354][table] Fix TIME field display in sql-clientThis closes #15689,0
"[hotfix] Set default value of resource-stabilization-timeout to 10sAdditionally, set speed up the AdaptiveScheduler ITCases by configuring a very lowjobmanager.adaptive-scheduler.resource-stabilization-timeout.",5
"[FLINK-22345][coordination] Remove incorrect assertion in schedulerWhen this incorrect assertion is violated, the scheduler can trip into an unrecoverablefailover loop.",0
"[hotfix][table-planner-blink] Fix the incorrect ExecNode's id in testIncrementalAggregate.outAfter FLINK-22298 is finished, the ExecNode's id should always start from 1 in the json plan tests, while the testIncrementalAggregate.out was overrided by FLINK-20613This closes #15698",2
"[FLINK-20654] Fix double recycling of Buffers in case of an exception on persistingException can be thrown for example if task is being cancelled. This was leading tosame buffer being recycled twice. Most of the times that was just leading to anIllegalReferenceCount being thrown, which was ignored, as this task was being cancelled.However on rare occasions this buffer could have been picked up by another taskafter being recycled for the first time, recycled second time and being picked upby another (third task). In that case we had two users of the same buffer, whichcould lead to all sort of data corruptions.",5
[hotfix] Regenerate html configuration after 4be9aff3eccb3808df1f10ef7c30480ec11a9cb0,5
"[FLINK-22001] Fix forwarding of JobMaster exceptions to user[FLINK-XXXX] Draft separation of leader election and creation of JobMasterService[FLINK-XXXX] Continued work on JobMasterServiceLeadershipRunner[FLINK-XXXX] Integrate RunningJobsRegistry, Cancelling state and termination future watching[FLINK-XXXX] Delete old JobManagerRunnerImpl classes[FLINK-22001] Add tests for DefaultJobMasterServiceProcess[FLINK-22001][hotfix] Clean up ITCase a bit[FLINK-22001] Add missing check for empty job graph[FLINK-22001] Rename JobMasterServiceFactoryNg to JobMasterServiceFactoryThis closes #15715.",2
[FLINK-22396][legal] Remove unnecessary entries from sql hbase connector NOTICE fileThis closes #15706,2
[FLINK-22396][hbase] Remove unnecessary entries from shaded plugin configuration,5
[FLINK-19980][table-common] Add a ChangelogMode.upsert() shortcut,4
[FLINK-19980][table-common] Add a ChangelogMode.all() shortcut,4
[FLINK-19980][table] Support fromChangelogStream/toChangelogStreamThis closes #15699.,4
[hotfix][table-api] Properly deprecate StreamTableEnvironment.execute,0
[FLINK-22345][coordination] Catch pre-mature state restore for Operator Coordinators,1
[FLINK-22168][table] Partition insert can not work with union allThis closes #15608,1
[FLINK-22341][hive] Fix describe table for hive dialectThis closes #15660,0
[FLINK-22000][io] Set a default character set in InputStreamReader,1
[FLINK-22385][runtime] Fix type cast error in NetworkBufferPoolThis closes #15693.,1
[FLINK-22085][tests] Update TestUtils::tryExecute() to cancel the job after execution failure.This closes #15713,0
[hotfix][runtime] fix typo in ResourceProfileThis closes #15723,2
[hotfix] Fix typo in TestingTaskManagerResourceInfoProvider,5
[FLINK-21174][coordination] Optimize the performance of DefaultResourceAllocationStrategyThis commit optimize the performance of matching requirements with available/pending resources in DefaultResourceAllocationStrategy.This closes #15668,1
[FLINK-22177][docs][table] Add documentation for time functions and time zone supportThis closes #15634,1
[FLINK-22398][runtime] Fix incorrect comments in InputOutputFormatVertex (#15705),0
"[FLINK-22384][docs] Fix typos in Chinese ""fault-tolerance/state""  page (#15694)",2
"[FLINK-21903][docs-zh] Translate ""Importing Flink into an IDE"" page into ChineseThis closes #15721",1
[FLINK-21659][coordination] Properly expose checkpoint settings for initializing jobs,5
[hotfix][tests] Remove unnecessary field,4
[FLINK-20723][tests] Ignore expected exception when retrying,1
[FLINK-20723][tests] Allow retries to be defined per class,1
[FLINK-20723][cassandra][tests] Retry on NoHostAvailableException,1
[hotfix][docs] Fix typo in jdbc execution options,5
[hotfix][docs] Fix typos,2
[FLINK-12351][DataStream] Fix AsyncWaitOperator to deep copy StreamElement when object reuse is enabled #8321 (#8321),0
[FLINK-22119][hive][doc] Update document for hive dialectThis closes #15630,2
[FLINK-20720][docs][python] Add documentation about output types for Python DataStream APIThis closes #15733.,5
[FLINK-20720][python][docs] Add documentation for ProcessFunction in Python DataStream APIThis closes #15733.,5
[FLINK-22294][hive] Hive reading fail when getting file numbers on different filesystem nameservicesThis closes #15624,5
[FLINK-22356][hive][filesystem] Fix partition-time commit failure when watermark is applied defined TIMESTAMP_LTZ columnThis closes #15709,0
[FLINK-22433][tests] Make CoordinatorEventsExactlyOnceITCase work with Adaptive Scheduler.The test previously relied on an implicit contract that instances of OperatorCoordinators are never recreatedon the same JobManager. That implicit contract is no longer true with the Adaptive Scheduler.This change adjusts the test to no longer make that assumption.This closes #15739,1
"[hotfix][tests] Remove timout rule from KafkaTableTestBaseThat way, we get thread dumps from the CI infrastructure when the test hangs.",3
[FLINK-21247][table] Fix problem in MapDataSerializer#copy when there exists custom MapDataThis closes #15569,5
[FLINK-21923][table-planner-blink] Fix ClassCastException in SplitAggregateRule when a query contains both sum/count and avg functionThis closes #15341,1
[FLINK-19449][doc] Fix wrong document for lead and lag,2
[FLINK-19449][table] Introduce LinkedListSerializer,2
[FLINK-19449][table] Pass isBounded to AggFunctionFactory,1
[FLINK-19449][table-planner] LEAD/LAG cannot work correctly in streaming modeThis closes #15747,1
[FLINK-18199][doc] translate FileSystem SQL Connector page into chineseThis closes #13459,1
[FLINK-22444][docs] Drop async checkpoint description of state backends in Chinese docs,2
[FLINK-22445][python][docs] Add documentation for row-based operationsThis closes #15757.,2
[FLINK-22463][table-planner-blink] Fix IllegalArgumentException in WindowAttachedWindowingStrategy when two phase is enabled for distinct aggThis closes #15759,0
[hotfix] Do not use ExecutorService.submit since it can swallow exceptionsThis commit changes the KubernetesLeaderElector to use ExecutorService.execute instead of submitwhich ensures that potential exceptions are forwarded to the fatal uncaught exeception handler.This closes #15740.,0
[FLINK-22431] Add information when and why the AdaptiveScheduler restarts or fails jobsThis commit adds info log statements to tell the user when and why it restarts or fails a job.This closes #15736.,0
[hotfix] Add debug logging to the states of the AdaptiveSchedulerThis commit adds debug log statements to the states of the AdaptiveScheduler to logwhenever we ignore a global failure.,0
"[hotfix] Harden against FLINK-21376 by checking for null failure causeIn order to harden the AdaptiveScheduler against FLINK-21376, this commit checks whether a taskfailure cause is null or not. In case of null, it will replace the failure with a generic cause.",1
[FLINK-22301][runtime] Statebackend and CheckpointStorage type is not shown in the Web UI[FLINK-22301][runtime] Statebackend and CheckpointStorage type is not shown in the Web UIThis closes #15732.,2
[hotfix][network] Remove unused method BufferPool#getSubpartitionBufferRecyclers,1
"[FLINK-22424][network] Prevent releasing PipelinedSubpartition while Task can still write to itThis bug was happening when a downstream tasks were failing over or being cancelled. If allof the downstream tasks released subpartition views, underlying memory segments/buffers couldhave been recycled, while upstream task was still writting some records.The problem is fixed by adding the writer (result partition) itself as one more referencecounted user of the result partition",1
[FLINK-22085][tests] Remove timeouts from KafkaSourceLegacyITCase,4
[FLINK-19606][table-runtime-blink] Refactor utility class JoinConditionWithFullFilters from AbstractStreamingJoinOperatorThis closes #15752,1
[hotfix][coordination] Add log for slot allocation in FineGrainedSlotManagerThis closes #15748,2
[FLINK-22074][runtime][test] Harden FineGrainedSlotManagerTest#testRequirementCheckOnlyTriggeredOnce in case deploying on a slow machineThis closes #15751,3
[FLINK-22470][python] Make sure that the root cause of the exception encountered during compiling the job was exposed to users in all casesThis closes #15766.,1
[hotfix][docs] Removed duplicate wordThis closes #15756 .,4
[hotfix][python][docs] Add missing debugging page for PyFlink documentation,2
[FLINK-22136][e2e] Odd parallelism for resume_externalized_checkpoints was added to run-nightly-tests.sh.,3
[FLINK-22136][e2e] Exception instead of system out is used for errors in DataStreamAllroundTestProgram,5
[hotfix][python][docs] Clarify python.files option (#15779),2
[FLINK-22476][docs] Extend the description of the config option `execution.target`This closes #15777.,1
"[FLINK-18952][python][docs] Add ""10 minutes to DataStream API"" documentationThis closes #15769.",2
[hotfix][table-planner-blink] Fix unstable itcase in OverAggregateITCase#testRowNumberOnOverThis closes #15782,3
[FLINK-22378][table] Derive type of SOURCE_WATERMARK() from time attributeThis closes #15730.,2
[hotfix][python][docs] Fix compile issues,0
[FLINK-22469][runtime-web] Fix NoSuchFileException in HistoryServer,2
[FLINK-22289] Update JDBC XA sink docs,2
"[FLINK-22428][docs][table] Translate ""Timezone"" page into Chinese (#15753)",2
[FLINK-22471][connector-elasticsearch] Remove commads from listThis is a responsibility of the Formatter implementation.,4
[FLINK-22471][connector-elasticsearch] Do not repeat default value,2
[FLINK-22471][connector-jdbc] Improve spelling and avoid repeating default values,1
[FLINK-22471][connector-kafka] Use proper Description for connector options,1
[FLINK-22471][connector-kinesis] Remove required from ConfigOptionThis is defined by where the factory includes the option.,5
[FLINK-22471][connector-kinesis] Use proper Description for connector options,1
[FLINK-22471][table-runtime-blink] Remove repetition of default values,4
[FLINK-22471][table-runtime-blink] Use proper Description for connector optionsThis closes #15764.,1
[hotfix][python][docs] Fix flat_aggregate example in Python Doc,2
[hotfix][python][docs] Add documentation to remind users to bundle Python UDF definitions when submitting the jobThis closes #15790.,5
"[FLINK-17783][orc] Add array,map,row types support for orc row writerThis closes #15746",1
[FLINK-22489][webui] Fix displaying individual subtasks backpressure-levelPreviously (incorrectly) backpressure-level from the whole task was being displayed foreach of the subtasks.,0
[FLINK-22479[Kinesis][Consumer] Potential lock-up under error condition,0
[FLINK-22304][table] Refactor some interfaces for TVF based window to improve the extendabilityThis closes #15745,1
[hotfix][python][docs] Fix python.archives docsThis closes #15783.,2
[FLINK-20086][python][docs] Add documentation about how to override open() in UserDefinedFunction to load resourcesThis closes #15795.,1
[FLINK-22438][metrics] Add numRecordsOut metric for Async IOThis closes #15791.,1
[FLINK-22373][docs] Add Flink 1.13 release notesThis closes #15687,3
[FLINK-22495][docs] Add Reactive Mode section to K8s,1
[FLINK-21967] Add documentation on the operation of blocking shuffleThis closes #15701,2
[FLINK-22232][tests] Add UnalignedCheckpointsStressITCase,1
[FLINK-22232][network] Add task name to output recovery tracing.,1
[FLINK-22232][network] Add task name to persist tracing.,1
[FLINK-22232][network] More logging of network stack.,1
[FLINK-22109][table-planner-blink] Resolve misleading exception message in invalid nested functionThis closes #15523.,1
"[FLINK-22426][table] Fix several shortcomings that prevent schema expressionsThis fixes a couple of critical bugs in the stack that prevented Table APIexpressions to be used for schema declaration. Due to time constraints,this PR could not make it into the 1.13 release but should be added tothe next bugfix release for a smoother user experience. For testing andconsistency, it exposes the Table API expression sourceWatermark() in Java,Scala, and Python API.This closes #15798",3
"[FLINK-22493] Increase test stability in AdaptiveSchedulerITCase.This addresses the following problem in the testStopWithSavepointFailOnFirstSavepointSucceedOnSecond() test.Once all tasks are running, the test triggers a savepoint, which intentionally fails, because of a test exception in a Task's checkpointing method. The test then waits for the savepoint future to fail, and the scheduler to restart the tasks. Once they are running again, it performs a sanity check whether the savepoint directory has been properly removed. In the reported run, there was still the savepoint directory around.The savepoint directory is removed via the PendingCheckpoint.discard() method. This method is executed using the i/o executor pool of the CheckpointCoordinator. There is no guarantee that this discard method has been executed when the job is running again (and the executor shuts down with the dispatcher, hence it is not bound to job restarts).",1
"[FLINK-22510][core] Format durations with highest unitWhen converting a configuration value to a string, durations were formattedin nanoseconds regardless of their values. This produces serialized outputswhich are hard to understand for humans.The functionality of formatting in the highest unit which allows the valueto be an integer already exists, thus we can simply defer to it to producea more useful result.This closes #15809.",1
[FLINK-22250][sql-parser] Add missing 'createSystemFunctionOnlySupportTemporary' entry in ParserResource.properties (#15582),1
[FLINK-22524][docs] Fix the incorrect Java groupBy clause in Table API docs (#15802),2
[FLINK-22522][table-runtime-blink] BytesHashMap prints many verbose INFO level logs (#15801),2
[FLINK-22539][python][docs] Restructure the Python dependency management documentation (#15818),2
[FLINK-22544][python][docs] Add the missing documentation about the command line options for PyFlink,2
Update japicmp configuration for 1.13.0,5
[hotfix][python][docs] Correct a few invalid links and typos in PyFlink documentation,2
[FLINK-22368] Deque channel after releasing on EndOfPartition...and don't enqueue the channel if it received EndOfPartitionpreviously.Leaving a released channel enqueued may lead toCancelTaskException which can prevent EndOfPartitionEventpropagation and the job being stuck.,2
[FLINK-14393][webui] Add an option to enable/disable cancel job in web uiThis closes #15817.,0
[FLINK-22323] Fix typo in JobEdge#connecDataSet (#15647)Co-authored-by: yunhua@dtstack.com <123456Lq>,5
[hotfix][python] Add missing space to exception message,1
[hotfix][docs] Fix typo,2
[FLINK-22535][runtime] CleanUp is invoked for task even when the task fail during the restore,0
[FLINK-22535][runtime] CleanUp is invoked despite of fail inside of cancelTask,0
[FLINK-22432] Update upgrading.md with 1.13.x,5
[FLINK-22253][docs] Update back pressure monitoring docs with new WebUI changes,4
[hotfix][docs] Update unaligned checkpoint docs,2
[hotfix][network] Remove redundant word from comment,4
[FLINK-21131][webui] Alignment timeout displayed in checkpoint configuration(WebUI),5
"[FLINK-22548][network] Remove illegal unsynchronized access to PipelinedSubpartition#buffersAfter peeking last buffer, this last buffer could have been processedand recycled by the task thread, before NetworkActionsLogger.traceRecoverwould manage to check it's content causing IllegalReferenceCount exceptions.Further more, this log seemed excessive and was accidentally added afterdebugging session, so it's ok to remove it.",4
[FLINK-22563][docs] Add migration guide for new StateBackend interfacesCo-authored-by: Nico Kruber <nico.kruber@gmail.com>This closes #15831,1
[FLINK-22379][runtime] CheckpointCoordinator checks the state of all subtasks before triggering the checkpoint,2
[FLINK-22488][hotfix] Update SubtaskGatewayImpl to specify the cause of sendEvent() failure when triggering task failover,0
[FLINK-22442][CEP] Using scala api to change the TimeCharacteristic of the PatternStream is invalidThis closes #15742,4
"[FLINK-22573][datastream] Fix AsyncIO calls timeout on completed element.As long as the mailbox is blocked, timers are not cancelled, such that a completed element might still get a timeout.The fix is to check the completed flag when the timer triggers.",0
"[FLINK-22573][datastream] Fix AsyncIO calls timeout on completed element.As long as the mailbox is blocked, timers are not cancelled, such that a completed element might still get a timeout.The fix is to check the completed flag when the timer triggers.",0
"[FLINK-22233][table] Fix ""constant"" typo in PRIMARY KEY exception messagesThis closes #15656Co-authored-by: wuys <wuyongsheng@qtshe.com>",2
[hotfix][hive] Add an ITCase that checks partition-time commit pretty wellThis closes #15754,1
[FLINK-22512][hive] Fix issue of calling current_timestamp with hive dialect for hive-3.1This closes #15819,0
[FLINK-22362][network] Improve error message when taskmanager can not connect to jobmanager,0
[FLINK-22581][docs] Keyword CATALOG is missing in sql client doc (#15844),2
[hotfix][docs] Replace local failover with partial failover,0
[FLINK-22266][hotfix] Do not clean up jobs in AbstractTestBase if the MiniCluster is not runningThis closes #15829,1
[hotfix][docs] Fix code tabs for state backend migration,0
[hotfix][docs][python] Fix the example in intro_to_datastream_api.md,5
[hotfix][docs][python] Add an overview page for Python UDFs,1
"[hotfix] Make reactive warning less strong, clarifications",2
[hotfix][docs] Re-introduce note about FLINK_CONF_DIRThis closes #15845,5
[hotfix][docs][python] Add introduction about the open method in Python DataStream API,5
[FLINK-21095][ci] Remove legacy slot management profile,2
[FLINK-22406][tests] Add RestClusterClient to MiniClusterWithClientResource,5
[FLINK-22406][coordination][tests] Stabilize ReactiveModeITCase,3
[FLINK-22419][coordination][tests] Rework RpcEndpoint delay tests,3
[FLINK-22560][build] Move generic filters/transformers into general shade-plugin configuration,5
[FLINK-22560][build] Filter maven metadata directory,5
[FLINK-22560][build] Add dedicated name to flink-dist shade-plugin execution,2
[FLINK-22555][build][python] Exclude leftover jboss files,2
[hotfix] Ignore failing test reported in FLINK-22559,2
[hotfix][docs] Fix typo in dependency_management.md,2
[hotfix][docs] Mention new StreamTableEnvironment.fromDataStream in release notes,5
[hotfix][docs] Mention new StreamTableEnvironment.fromDataStream in Chinese release notes,5
[FLINK-22505][core] Limit the scale of Resource to 8This closes #15815,2
[FLINK-19606][table-runtime-blink] Introduce WindowJoinOperator and WindowJoinOperatorBuilderThis closes #15760,1
[FLINK-22536][runtime] Promote the critical log in FineGrainedSlotManager to INFO levelThis closes #15850,5
[FLINK-22355][docs] Fix simple task manager memory model imageThis closes #15862,1
[FLINK-19606][table-planner] Introduce StreamExecWindowJoin and window join it casesThis closes #15479,2
[hotfix][docs] Correct the examples in Python DataStream API,5
[FLINK-17170][kinesis] Move KinesaliteContainer to flink-connector-kinesis.This testcontainer will be used in an ITCase in the next commit.Also move system properties required for test into pom.xml.,5
"[FLINK-17170][kinesis] Fix deadlock during stop-with-savepoint.During stop-with-savepoint cancel is called under lock in legacy sources. Thus, if the fetcher is trying to emit a record at the same time, it cannot obtain the checkpoint lock. This behavior leads to a deadlock while cancel awaits the termination of the fetcher.The fix is to mostly rely on the termination inside the run method. As a safe-guard, close also awaits termination where close is always caused without lock.",1
[FLINK-21181][runtime] Wait for Invokable cancellation before releasing network resources,1
[FLINK-22609][runtime] Generalize AllVerticesIterator,2
[hotfix][docs] Fix image links,2
[FLINK-22525][table-api] Fix gmt format in Flink from GMT-8:00 to GMT-08:00 (#15859),2
[FLINK-22559][table-planner] The consumed DataType of ExecSink should only consider physical columnsThis closes #15864.,5
[hotfix][core] Remove unused import,2
[FLINK-22537][docs] Add documentation how to interact with DataStream APIThis closes #15837.,5
[FLINK-22596] Active timeout is not triggered if there were no barriersThe active timeout did not take effect if it elapsed before the firstbarrier arrived. The reason is that we did not reset the future forcheckpoint complete on barrier announcement. Therefore we considered thecompleted status for previous checkpoint when evaluating the timeout forcurrent checkpoint.,1
[hotfix][test] Adds -e flag to interpret newline in the right way,1
"[FLINK-22566][test] Adds log extraction for the worker nodesWe struggled to get the logs of the node manager which made it hard toinvestigate FLINK-22566 where there was a lag between setting up the YARNcontainers and starting the TaskExecutor. Hopefully, the nodemanager logslocated on the worker nodes will help next time to investigate something likethat.",1
[FLINK-22577][tests] Harden KubernetesLeaderElectionAndRetrievalITCaseThis commit introduces closing logic to the TestingLeaderElectionEventHandler which wouldotherwise forward calls after the KubernetesLeaderElectionDriver is closed.This closes #15849.,3
[FLINK-22604][table-runtime-blink] Fix NPE on bundle close when task failover after a failed task openThis closes #15863,0
[hotfix] Disable broken savepoint tests tracked in FLINK-22067,2
[FLINK-22407][build] Bump log4j to 2.24.1- CVE-2020-9488,2
[FLINK-22313][table-planner-blink] Redundant CAST in plan when selecting window start and window end in window agg (#15806),2
[FLINK-22523][table-planner-blink] Window TVF should throw helpful exception when specifying offset parameter (#15803),2
[FLINK-22624][runtime] Utilize the remain resource of new pending task managers to fulfill requirement in DefaultResourceAllocationStrategyThis closes #15888,1
[FLINK-22413][WebUI] Hide Checkpointing page for batch jobs,2
"[FLINK-22364][doc] Translate the page of ""Data Sources"" to Chinese. (#15763)",5
[FLINK-22586][table] Improve the precision dedivation for decimal arithmeticsThis closes #15848,1
[hotfix][e2e] Output and collect the logs for Kubernetes IT cases,2
[FLINK-17857][test] Make K8s e2e tests could run on MacThis closes #14012.,1
[hotfix][ci] Use static methods,1
[FLINK-22556][ci] Extend JarFileChecker to search for traces of incompatible licenses,2
[FLINK-21700][security] Add an option to disable credential retrieval on a secure cluster (#15131),1
[FLINK-22408][sql-parser] Fix SqlDropPartitions unparse ErrorThis closes #15894,0
"[FLINK-21469][runtime] Implement advanceToEndOfEventTime for MultipleInputStreamTaskFor stop with savepoint, StreamTask#advanceToEndOfEventTime() is called (in source tasks)to advance to the max watermark. This PR implments advanceToEndOfEventTime forMultipleInputStreamTask chained sources.",2
[hotfix][docs] Fix all broken imagesCo-authored-by: Xintong Song <6509172+xintongsong@users.noreply.github.com>This closes #15865,1
[hotfix][docs] Fix typo in k8s docsThis closes #15886,2
[FLINK-22628][docs] Update state_processor_api.mdThis closes #15892,5
[hotfix] Add missing TestLogger to Kinesis tests,3
"[FLINK-22574] Adaptive Scheduler: Fix cancellation while in Restarting state.The Canceling state of Adaptive Scheduler was expecting the ExecutionGraph to be in state RUNNING when entering the state.However, the Restarting state is cancelling the ExecutionGraph already, thus the ExectionGraph can be in state CANCELING or CANCELED when entering the Canceling state.Calling the ExecutionGraph.cancel() method in the Canceling state while being in ExecutionGraph.state = CANCELED || CANCELLED is not a problem.The change is guarded by a new ITCase, as this issue affects the interplay between different AS states.This closes #15882",0
[FLINK-22640] [datagen] Fix DataGen SQL Connector does not support defining fields min/max option of decimal type fieldThis closes #15900,5
[FLINK-22534][runtime][yarn] Set delegation token's service name as credential aliasThis closes #15810,1
[FLINK-22618][runtime] Fix incorrect free resource metrics of task managersThis closes #15887,0
[FLINK-15064][table-planner-blink] Remove XmlOutput util class in blink planner since Calcite has fixed the issueThis closes #15911,0
[FLINK-19796][table] Explicit casting shoule be made if the type of an element in `ARRAY/MAP` not equals with the derived component typeThis closes #15906,2
[FLINK-22475][table-common] Document usage of '#' placeholder in option keys,2
[FLINK-22475][table-common] Exclude options with '#' placeholder from validation of required options,1
[FLINK-22475][table-api-java-bridge] Add placeholder options for datagen connectorThis closes #15896.,5
[FLINK-22511][python] Fix the bug of non-composite result type in Python TableAggregateFunctionThis closes #15796.,1
[[hotfix][docs] Changed argument for toDataStream to TableThis closes #15923 .,5
[FLINK-22654][sql-parser] Fix SqlCreateTable#toString()/unparse() lose CONSTRAINTS and watermarksThis closes #15918,1
[FLINK-22658][table] Remove Deprecated util class TableConnectorUtil (#15914),4
[FLINK-22592][runtime] numBuffersInLocal is always zero when using unaligned checkpointsThis closes #15915,1
[FLINK-22400][hive] fix NPE problem when convert flink object for MapThis closes #15712,2
[FLINK-22649][python][table-planner-blink] Support StreamExecPythonCalc json serialization/deserializationThis closes #15913.,5
"[FLINK-22502][checkpointing] Don't tolerate checkpoint retrieval failures on recoveryIgnoring such failures and running with an incompleteset of checkpoints can lead to consistency violation.Instead, transient failures should be mitigated byautomatic job restart.",0
[FLINK-22667][docs] Add missing slash,1
[FLINK-22650][python][table-planner-blink] Support StreamExecPythonCorrelate json serialization/deserializationThis closes #15922.,5
[FLINK-22652][python][table-planner-blink] Support StreamExecPythonGroupWindowAggregate json serialization/deserializationThis closes #15934.,5
[FLINK-22666][table] Make structured type's fields more lenient during castingCompare children individually for anonymous structured types. Thisfixes issues with primitive fields and Scala case classes.This closes #15935.,0
[hotfix][table-planner-blink] Give more helpful exception for codegen structured types,2
[FLINK-22620][orc] Drop BatchTableSource OrcTableSource and related classesThis removes the OrcTableSource and related classes including OrcInputFormat. Usethe filesystem connector with a ORC format as a replacement. It is possible toread via Table & SQL API snd convert the Table to DataStream API if necessary.DataSet API is not supported anymore.This closes #15891.,1
[FLINK-22651][python][table-planner-blink] Support StreamExecPythonGroupAggregate json serialization/deserializationThis closes #15928.,5
[FLINK-22653][python][table-planner-blink] Support StreamExecPythonOverAggregate json serialization/deserializationThis closes #15937.,5
[FLINK-12295][table] Fix comments in MinAggFunction and MaxAggFunctionThis closes #15940,1
"[FLINK-20695][ha] Clean ha data for job if globally terminatedAt the moment Flink only cleans up the ha data (e.g. K8s ConfigMaps, orZookeeper nodes) while shutting down the cluster. This is not enough fora long running session cluster to which you submit multiple jobs. Inthis commit, we clean up the data for the particular job if it reaches aglobally terminal state.This closes #15561.",5
[FLINK-22067][tests] Wait for vertices to using API,1
[hotfix][tests] Remove try/catch from SavepointWindowReaderITCase.testApplyEvictorWindowStateReader,3
[FLINK-22622][parquet] Drop BatchTableSource ParquetTableSource and related classesThis removes the ParquetTableSource and related classes including various ParquetInputFormats.Use the filesystem connector with a Parquet format as a replacement. It is possible toread via Table & SQL API and convert the Table to DataStream API if necessary.DataSet API is not supported anymore.This closes #15895.,1
[hotfix] Ignore failing KinesisITCase traacked in FLINK-22613,2
"[FLINK-19545][e2e] Add e2e test for native Kubernetes HAThe HA e2e test will start a Flink application first and wait for three successful checkpoints. Then kill the JobManager. A new JobManager should be launched and recover the job from latest successful checkpoint. Finally, cancel the job and all the K8s resources should be cleaned up automatically.This closes #14172.",4
[FLINK-22656] Fix typos,2
[hotfix][runtime] Fixes JavaDoc for RetrievableStateStorageHelperRetrievableStateStorageHelper is not only used by ZooKeeperStateHandleStore butalso by KubernetesStateHandleStore.,0
[hotfix][runtime] Cleans up unnecessary annotations,4
[FLINK-22494][kubernetes] Introduces PossibleInconsistentStateExceptionWe experienced cases where the ConfigMap was updated but the corresponding HTTPrequest failed due to connectivity issues. PossibleInconsistentStateExceptionis used to reflect cases where it's not clear whether the data was actuallywritten or not.,5
[FLINK-22494][ha] Refactors TestingLongStateHandleHelper to operate on referencesThe previous implementation stored the state in the StateHandle. This causesproblems when deserializing the state creating a new instance that does notpoint to the actual state but is a copy of this state.This refactoring introduces LongStateHandle handling the actual state andLongRetrievableStateHandle referencing this handle.,0
[FLINK-22494][ha] Introduces PossibleInconsistentState to StateHandleStore,0
[FLINK-22494][runtime] Refactors CheckpointsCleaner to handle also discardOnFailedStoring,0
[FLINK-22494][runtime] Adds PossibleInconsistentStateException handling to CheckpointCoordinatorThis closes #15832.,1
[FLINK-22515][docs] Add documentation for GSR-Flink Integration,2
[FLINK-20487][table-planner-blink] Remove restriction on StreamPhysicalGroupWindowAggregate which only supports insert-only input nodeThis closes #14830,1
[FLINK-22623][hbase] Drop BatchTableSource/Sink HBaseTableSource/Sink and related classesThis removes the HBaseTableSource/Sink and related classes including various HBaseInputFormats andHBaseSinkFunction. It is possible to read via Table & SQL API and convert the Table to DataStream API(or vice versa) if necessary. DataSet API is not supported anymore.This closes #15905.,1
[hotfix][hbase] Fix warnings around decimals in HBaseTestBase,3
"[FLINK-22636][zk] Group job specific zNodes under /jobs zNodeIn order to better clean up job specific HA services, this commit changes the layout of thezNode structure so that the JobMaster leader, checkpoints and checkpoint counter is now groupedbelow the jobs/ zNode.Moreover, this commit groups the leaders of the cluster components (Dispatcher, ResourceManager,RestServer) under /leader/process/latch and /leader/process/connection-info.This closes #15893.",5
[FLINK-22696][tests] Enable Confluent Schema Registry e2e test on jdk 11,3
[FLINK-22487][python] Support `print` to print logs in PyFlinkThis closes #15780.,2
[FLINK-22697][examples-table] Update StreamSQLExample to current API,5
[FLINK-22697][examples-table] Remove TPCHQuery3Table example,4
[FLINK-22697][examples-table] Update WordCountSQLExample to current API,5
[FLINK-22697][examples-table] Remove WordCountTable example,4
[FLINK-22697][examples-table] Update flink-examples-table pom.xmlThis closes #15948.,5
[hotfix][docs] Update SQL grammar for WITH and sub queries,5
[FLINK-22699][table-common] Declare ConstantArgumentCount as @PublicEvolving,2
[FLINK-22661][hive] HiveInputFormatPartitionReader can return invalid dataThis closes #15920,5
[FLINK-22704][tests] Harden ZooKeeperHaServicesTest.testCleanupJobDataThis commit hardens the ZooKeeperHaServicesTest.testCleanupJobData by making sure that allzNodes have been created before checking for their existence. This is done by waiting forthe leader information for the ResourceManager and the JobMaster.This closes #15954.,5
[FLINK-22692][tests] Disable CheckpointStoreITCase with adaptive schedulerAdaptive scheduler doesn't currently retry after failures on recovery.,0
[FLINK-22706][legal] Update NOTICE regarding docs/ contents,2
[FLINK-22451][table] Support (*) as argument of UDF in Table API (#15768),1
[FLINK-22708][config] Propagate savepoint settings from StreamExecutionEnvironment to StreamGraph,1
[FLINK-22694][e2e] Use SQL file in TPCH end to end tests (#15944),3
[FLINK-22266] Fix stop-with-savepoint operation in AdaptiveSchedulerThis closes #15884,0
[FLINK-22155][table] EXPLAIN statement should validate insert and query separatelyThis closes #15664,5
"[FLINK-22721][ha] Add default implementation for HighAvailabilityServices.cleanupJobDataIn order to not break the HighAvailabilityServices interface, this commit adds a defaultimplementation for the HighAavilabilityServices.cleanupJobData method which does nothing.Users of this interface are recommended to override this method and add a specificimplementation in order to clean up job specific HA services after a job completion.This closes #15969.",4
[FLINK-22203][table-runtime-blink] Fix ConcurrentModificationException for testing values sink functions (#15978),1
[FLINK-22713][docs] Correct document syntax errors in Kafka page (#15957),0
[FLINK-22638] Keep channels blocked on alignment timeoutThis commit keeps channels blocked in case an alignment timeout occurs.That way we prioritize the channels that we have not received thebarrier yet. This solution is based on the assumption that all upstreamoperators are working with aligned checkpoints and we do not minddelaying the subsequent checkpoints on the blocked channels.This closes #15897,1
[FLINK-22733][python] DataStream.union should handle properly for KeyedStream in Python DataStream APIThis closes #15981.,5
[FLINK-22688][coordination] Eases assertion on ExceptionHistoryEntry,1
[FLINK-22434] Store suspended execution graphs on termination to keep them accessibleBefore this change as soon as a cluster termination was initiated everyjob was suspended and not accessible anymore until recovery. By storingthe execution graph they will appear as SUSPENDED they are nowaccessible until the cluster is fully shutdown.,5
"[FLINK-22434] Retry in clusterclient if job state is unknownSince the dispatcher now exposed the SUSPENDED job state itneeds to be handled in the ClusterClient. We decided to notexpose this state because it would be an unexpected changefor users relying on the old behavior.In summary, the RestClusterClient will retry to receive adifferent state for jobs in SUSPENDED state.This closes #15799.",1
[FLINK-22745][zk] Trim starting slashes when creating a namespaced CuratorFramework facadeThis commit trims starting slashes from the namespace used to instantiate the CuratorFramework facadein ZooKeeperUtilityFactory because namespaces must not start with slashes.This closes #15988.,1
[FLINK-22719][table-planner-blink] Fall back to regular join instead of thrown exception if a join does not satisfy conditions to translate into WindowJoinThis closes #15963,2
[hotfix][python][docs] Add documentation about how to set config options in Python DataStream API program,5
[FLINK-22659][docs] Add execution.checkpointing.interval to docs of checkpoint configurationThis closes #15979.,5
[FLINK-18934][core] Extract reusable CombinedWatermark class,4
"[FLINK-18934][runtime] Idle stream does not advance watermark in connected streamWatermark in the two and multi input operators is computed in operators. So far operators were unaware of the StreamStatus, therefore even if a whole input was IDLE it could still block increasing the Watermark.This commit makes operators aware of the StreamStatus. The contract of the StreamStatus is that if a stream is IDLE it should not emit records nor watermarks.",1
[FLINK-18934][runtime] Drop StreamStatusMaintainer & StreamStatusProviderThe StreamStatus traverses the whole DAG and it's state should be kept on the operator level. Given those assumptions the maintainer & provider are no longer necessary.,1
[FLINK-22747] Upgrade to commons-io 2.8.0This closes #15989.,2
[FLINK-22639] Override URLClassLoader#getURLs,1
[FLINK-22464][runtime][tests] Disable a test failing with AdaptiveScheduler tracked in FLINK-22464,2
[FLINK-22725][coordination] SlotManagers unregister metrics in suspend(),2
[FLINK-22684][runtime] Added ability to ignore in-flight data during the recovery,5
fixup: Create the new operator states instead of changing old one,4
[FLINK-22319][table][sql-client] Support RESET table option for ALTER TABLE statementThis closes #15949,1
[FLINK-22740][docs] Drop legacy planner references in docsThis closes #15985.,2
[FLINK-22774][sql-connector-kinesis] Update Kinesis SQL connector's Guava to 27.0-jreAvoids that security tools complain about an outdated Guava version in the KinesisSQL connector.This closes #16005.,5
[FLINK-22784][jepsen] Update rest server leader path,5
"[FLINK-22613][tests] Fix FlinkKinesisITCase.testStopWithSavepoint.The test relies on a few elements remaining pending after stop-with-savepoint, however that can only be guaranteed heuristically: We cannot block task thread or else the respective savepoint will not succeed but we also cannot add infinite input as it's an IT test against Kinesis. Here, the fix is to add much more elements to Kinesis stream. An optimized sendMessage on the test client ensures timely setup.",1
[FLINK-22778] Upgrade to JUnit 4.13,3
[FLINK-22777][docs] Restored full Datastream API fraud detection example in Try Flink sectionThis closes #16003,2
[FLINK-21464][sql-client] Support ADD JAR in SQL Client (#15925),1
"[FLINK-22393][docs-zh] Translate the page of ""Execution Mode (Batch/Streaming)"" into Chinese (#15767)",2
[FLINK-22746][docs] Links to connectors in docs are brokenThis closes #15990,2
[hotfix][runtime] Remove unused field from OperatorChain,1
[FLINK-22780][streaming] Remove volatile from the idle flag in StreamSourceContexts,4
[FLINK-20140][python][docs] Add documentation for TableResult.collect for Python Table API.This closes #16014.,2
[FLINK-22760][Connectors/Hive] Fix issue of HiveParser::setCurrentTimestamp fails with hive-3.1.2This closes #15995,0
"[FLINK-22770][sql-parser][planner-blink] Expose SET/RESETThis adds the SET and RESET DCL statements directly into the parser andexposes them as their respective (pre-existing) operations.A major difference to the current SET/RESET supported in the SQL Clientis that we now require quoting of both key and value for consistency withoptions elsewhere in Flink SQL. To avoid a breaking change, the SQL Clientspecific implementation is kept for now which takes precedence.",4
[FLINK-22770][docs] Update usage of SET in docs to use quotesThis closes #16006.,3
"[FLINK-22655][sql-client] Fix ""-i init.sql"" doesn't work when first line is a commentThis closes #15980",1
[FLINK-22619][python] Drop usages of BatchTableEnvironment and old planner in PythonThis is a major cleanup of the Python module that drops support forBatchTableEnvironment and old planner.Removes usages of:- DataSet- BatchTableEnvironment- Legacy planner- ExecutionEnvironment,5
[FLINK-22619][python] Drop Python UDF serializers for old plannerThis closes #16008.,4
[FLINK-22759][docs] Correct the applicability of some RocksDB related options as per operator,1
[hotfix][docs] Improve soft deprecation message for DataSet users,1
[FLINK-22782][docs] Remove legacy planner from Chinese docsThis closes #16018.,2
[FLINK-22722][docs/kafka] Add documentation for Kafka new source (#15974),1
[FLINK-21741][sql-client] Support SHOW JARS statement in SQL Client (#16010),1
[FLINK-22689][doc] Fix Row-Based Operations Example in Table API documentation (#16036),2
[FLINK-22796][doc] Update mem_setup_tm documentationThis closes #16016,2
[FLINK-22794][sql-parser] Upgrade JUnit Vintage version to 5.7.2This closes #16034,3
[FLINK-22794][ci] Add missing sql parser module test to CI buildThis closes #16034,3
[FLINK-22814][metrics] Calculate checkpointStartDelay for FLIP-27 sources,2
[hotfix][hive] Remove duplicated interface implementationsThis closes #16030,4
[FLINK-22815][checkpointing] Disable unaligned checkpoints for broadcast partitioningBroadcast partitioning can not work with unaligned checkpointing. Thereis no guarantees that records are consumed at the same rate in allchannels. This can result in some tasks applying state changescorresponding to a certain broadcasted event while others don't. In turnupon restore it may lead to an unconsistent state.,4
"[FLINK-22815][checkpointing] Remove SubtaskStateMapper.DISCARD_EXTRA_STATE which doesnot workThe mapping implemented via DISCARD_EXTRA_STATE is not supported on thenetwork level. At the same time there is no use for that mapping. It'sbetter to remove the mapper for now, so that it is not used by mistake.",1
[hotfix] Disable TRACE network logging in UnalignedCheckpointTestBase,3
[FLINK-22686][checkpointing] Incompatible subtask mappings while resuming from unaligned checkpointsIn the initial implementation of rescaling channel data we assumed thatthe subtasks indices are the same for all input gates. This assumptionsdoes not hold when there are different partitioners. It can happen e.g.in case of a broadcast with a keyed input.The commit tracks the subtask indices separately for each partition andinput gate.This closes #16019,5
[FLINK-22686][hotfix] Rename InflightDataGateOrPartitionRescalingDescriptor.Rescaling to MappingType,5
[FLINK-22810][connector-elasticsearch] Drop usages of legacy planner in Elasticsearch modulesThis closes #16031.,4
[FLINK-22811][format-avro] Drop usages of legacy planner in Avro moduleThis closes #16032.,4
[FLINK-22813][connector-hive] Clean up flink-connector-hive's pom.xmlThis closes #16038.,5
[FLINK-22822][connector-jdbc] Clean up flink-connector-jdbc's pom.xmlThis closes #16039.,5
[FLINK-22831][scala-shell] Update Scala shell to use Blink plannerThis closes #16047.,2
[FLINK-22832][sql-client] Drop usages of legacy planner in SQL ClientThis closes #16052.,4
[FLINK-22820] Allow storing SUSPENDED jobs in FileExecutionGraphInfoStore,5
[FLINK-19896][table-blink] Improve first-n-row fetching in the Rank operatorThis closes #13921,1
[FLINK-22786][sql-client] sql-client can not create history file when under soft link path (#16029),2
[FLINK-22795][sql-client] Throw better exception when executing remote SQL file in SQL Client (#16049),2
[FLINK-22612][python] Restructure the coders in PyFlinkThis closes #15877.,2
[FLINK-22683][runtime] Fix the null or incorrect value of total Flink/process memory in creating TaskExecutorMemoryConfigurationThis closes #15936,5
[FLINK-22824][connector-kafka] Drop usages of legacy planner in Kafka modulesThis closes #16042.,4
[FLINK-21127][runtime][checkpoint] Stores finished status for fully finished operators in checkpointThis closes #14754,1
"[hotfix][runtime] Add check for zero default slot profile in calculating number of slots.A zero default slot profile leads to a infinite loop. This should not happen in production, but could make tests hard to debug.",0
[FLINK-21667][runtime] Introduce ResourceManagerProcessContext.This decouples the reusable and non-reusable parts for creating multiple resource manager instances.,1
[FLINK-21667][runtime] Wrap ResourceManager as a service.,2
"[FLINK-21667][runtime] Move RM leader election to ResourceManagerService.This means each ResourceManager only serves one leadership session. When leadership is revoked and re-granted, a new ResourceManager will be created.This closes #15524",1
[FLINK-22680][table-planner-blink] Fix IndexOutOfBoundsException when apply WatermarkAssignerChangelogNormalizeTransposeRuleThis closes #15997,4
[FLINK-22038][table-planner-blink] Update TopN to be without rowNumber if rowNumber field is never used by the successor CalcThis closes #16024,1
"Revert ""[FLINK-22680][table-planner-blink] Fix IndexOutOfBoundsException when apply WatermarkAssignerChangelogNormalizeTransposeRule""This reverts commit a364daa37202dc4d7a60c613f547cdcd6893ecd2.",4
"Revert ""[FLINK-22038][table-planner-blink] Update TopN to be without rowNumber if rowNumber field is never used by the successor Calc""This reverts commit 362aadc335af2b6887798d22f97bf72a74229e22.",4
[FLINK-22849][python] Move legacy testing utils to flink-python test jar,3
[FLINK-22849][e2e] Remove E2E tests for legacy plannerThis closes #16074.,3
[FLINK-22272][hive] HiveCatalog should allow getting generic table with empty schemaThis closes #15638,1
[FLINK-22863][runtime] Fix ArrayIndexOutOfBoundsException when building rescale edges in EdgeManagerBuildUtilThis closes #16071,0
[FLINK-15390][orc] List/Map/Struct types support for vectorized orc readerThis closes #15939,1
[FLINK-22376][runtime] BufferProvider is able to provide pure MemorySegment in order to avoid extracting it from the bufferBuilder,4
[FLINK-22376][runtime] Buffer is used inside of BufferBuilder for references counting,1
[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer,1
[hotfix] Clarification ownerships of the buffer for Remote InputChannel#onBuffer in javadoc,2
"[FLINK-22864][table] Remove the flink-table-planner and flink-table-uber moduleIn order to avoid user confusion, reduce duplicate code, and improve maintainabilityand testing times of the Flink project as a whole this removes the legacy plannermodule.It means that both the BatchTableEnvironment and DataSet API interop withTable API are reaching end of life. Use the unified TableEnvironment forbatch and stream processing with the new planner or the DataStream APIin batch execution mode.Users are encouraged to update their pipelines. Flink 1.13 is the lastversion that offers the old functionality.This closes #16080.",1
[FLINK-22680][table-planner-blink] Fix IndexOutOfBoundsException when apply WatermarkAssignerChangelogNormalizeTransposeRuleThis closes #16077,4
[hotfix][docs] Corrected markup backtick (#16082),2
[FLINK-22038][table-planner-blink] Update TopN to be without rowNumber if rowNumber field is never used by the successor CalcThis closes #16076,1
[hotfix][docs] Fix typo,2
[FLINK-22854][docs-zh] Translate 'Apache Flink Documentation' index page to Chinese. (#16062),2
[FLINK-17707][k8s] Support configuring replicas of JobManager deployment when HA enabledThis closes #15286,0
[FLINK-22855][docs-zh] Translate the 'Overview of Python API' page into Chinese.This closes #16061.,2
"[FLINK-22645][sql-parser] Add ""ALTER VIEW"" DDL for Flink dialectThis introduces the DDLALTER VIEW  RENAME TO ALTER VIEW  AS for the Flink dialect. These already exist for the Hive dialect, butshould be supported in the Flink dialect as well.This change omits ""ALTER VIEW  SET TBLPROPERTIES "" as this doesn't(yet) make sense for the Flink dialect.This closes #15946.",2
[FLINK-22847][sql-client] Quote options when using SET;,1
[hotfix][sql-client] Update usages of SET/RESET in tests,3
"[FLINK-22847][sql-client] Update usage in CLI ""HELP"" commandThis closes #16053.",5
[hotfix][docs] Update docs for updated 'SET;' output,1
[FLINK-22562][docs-zh] Translate recent updates to backpressure docs (#15866),2
"[FLINK-22895][docs] Fix example typo in ""Table Concepts & Common API"" pageThis closes #16087",1
[hotfix][network] Removed unused method in LocalInputChannel,1
[hotfix][task] Remove unused constructor in TestTaskStateManager,3
[hotfix][task] Rename triggerCheckpoint to better reflect a difference compared to other similarly named methods,1
[hotfix][test] Deduplicate test case between SourceStreamTask and SourceOperatorStreamTask,1
[FLINK-22833][metrics] Set checkpointStartDelay in checkpoint metrics for SourceTasksThis commit is fixing a bug of checkpointStartDelay being not set inCheckpointMetrics of SourceStreamTask and SourceOperatorStreamTask.,1
[FLINK-22835][tests] Assert latency tracking on delegated backend,3
[FLINK-22835][tests] Add assumptions to state backend tests,3
[hotfix][tests] Discard state snapshot iff not null,3
[FLINK-22835][tests] Use ChangelogStateBackend on recovery in the relevant tests,3
[FLINK-22889][tests] Ignore JdbcExactlyOnceSinkE2eTest temporarilyThis closes #16090,5
[FLINK-21742][sql-client] Support REMOVE JAR statement in SQL ClientThis closes #16013,4
[FLINK-22776][connector-jdbc] Delete unuseful casting to byte[] in AbstractJdbcRowConverter classThis closes #16058,5
[FLINK-22890][hive] HiveTestUtils should create partition after the data file is readyThis closes #16099,2
"[FLINK-22905][docs] Fix missing comma in SQL example in ""Versioned Table"" page This closes #16098",0
[FLINK-22789][hive] Support Hive version 2.3.7This closes #16015,1
[FLINK-13538][formats] Figure out wrong field name when serializer/deserializer throw exceptions while doing serializing/deserializing for json and csv format.This closes #16068,5
[FLINK-22856][Azure] Upgrade to ubuntu-20.04,2
[FLINK-22765][runtime][tests] Improve logging for debugging rare test failureThis closes #15998,0
"[FLINK-22876][tests] Adding SharedObjects junit rule to ease test development.Most test rely on static variables to sync between test code and UDFs to avoid serialization issues. However, static variables are error-prone and the tests look quaint.SharedObjects allow test developers to forget about the serialization and just use the objects across thread boundaries.",1
[FLINK-22876][tests] Migrated FileSinkMigrationITCase to SharedObjects as a showcase/test.,3
[FLINK-22496][tests] Harden ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHookHardens the ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook by increasing the timeout from 3s to 10s.,1
[FLINK-22496][tests] Include log output from started process in ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHookThis closes #16111.,5
[hotfix] Replace deprecated import org.junit.Assert.assertThat with org.hamcrest.MatcherAssert.assertThat,3
[FLINK-22906][docs] Add build time to Flink documentationThis closes #16100,2
[FLINK-22894][table-runtime] Fix rankEnd validation of WindowRank to support top1This closes #16088,1
[FLINK-22472][filesystem] close file of partition when partition is committableThis closes #16027,2
[FLINK-22726][hive] Support grouping__id in hive prior to 2.3.0This closes #15983,1
[FLINK-22734][table] Close input stream,2
[FLINK-22877][table] Remove BatchTableEnvironment and related classes,4
[FLINK-22877][table] Remove BatchTableSource and related classes,4
[FLINK-22877][table] Remove BatchTableSink and related classes,4
[FLINK-22877][table] Remove outdated comments,5
[FLINK-22877][table] Remove remaining comments around DataSetThis closes #16097.,5
[FLINK-22284] Log the remote address when channel is closed in NettyPartitionRequestClient,1
Fix according to review,0
[FLINK-22939][azure] Generalize JDK switch,2
[FLINK-19164][release] Use versions-maven-plugin to update versionThe old command unintentionally breaks other dependency versions if the Flink version exactly matches the dependency version.Versions-maven-plugin properly updates only the project's version.,5
[FLINK-22682][runtime] Expanded 'Completed checkpoint' log by finalizationTime,2
[FLINK-22919] Remove support for Hadoop1.x in HadoopInputFormatCommonBase.getCredentialsFromUGIThis closes #16107,1
Adding gcs documentation. Connecting flink to gcs.,2
[FLINK-22454][table-planner-blink] Ignore casting on interoperable type when extracting lookup keysThis closes #16094,4
[FLINK-21301][table-planner-blink] Decouple window aggregate allow lateness with state ttl configurationThis closes #16022,5
[FLINK-20926][maxwell][json] Allow to read metadata for maxwell-json formatThis closes #16040,5
[FLINK-22312][yarn][test] Fix test instabilities due to expected heartbeat exceptions in logThis closes #16127,2
[FLINK-22952][azure] Remove Ruby usage,4
[FLINK-22947][docs] Move DataSet to bottom of Applciation Development,5
[FLINK-22947][docs] Consolidate DataTypes and Serialization under DataStream,5
[hotfix][docs] Replace DataSet with DataStream,5
[FLINK-22947][docs] Move execution management to DataStream and OpsThis closes #16125,5
Apply suggestions from code reviewCo-authored-by: David Anderson <david@alpinegizmo.com>,5
[FLINK-22931][build] Migrate to flink-shaded-force-shading,2
[FLINK-22952][auure] Remove Ruby usage,4
[hotfix][azure] Fix broken yaml,0
[FLINK-22908][tests] Wait until job has started before testing shutdown,3
[FLINK-22744][table] Update and simplify EnvironmentSettings,1
[FLINK-22744][docs] Update and simplify docs for EnvironmentSettingsThis closes #16123.,1
[FLINK-22934][docs] Improve instructions for how to escape single quotes in SQLThis closes #16126,1
[FLINK-22963][doc] correct the description of taskmanager.memory.task.heap.size.This closes #16143,2
[FLINK-22712][python] Support accessing Row fields by attribute name in PyFlink Row-based OperationThis closes #16065.,2
[FLINK-22730][table-planner] Add per record code when generating table function collector code for lookup joinsThis closes #16104,1
[FLINK-20318][kafka] Fix cast question for properies() method in kafka ConnectorDescriptorThis closes #15250,0
[FLINK-22818][runtime] IgnoreInFlightDataITCase is blocking the map subtasks until the first checkpoint barrier reaches the sink,5
[hotfix][ci] Make NoticeFileChecker log severe issues at error level.This closes #16155,0
[FLINK-22957][table-runtime] Rank TTL should use enableTimeToLive of state instead of timerThis closes #16128,0
[FLINK-22329][hive] Inject current ugi credentials into jobconf when in hive connectorThis closes #15653,5
[hotfix][docs] Use non deprecated syntax in SinkFunction code sampleThis closes #16116,1
[hotfix][state/changelog] Change OpertorID type to string,4
[hotfix][state/changelog] Check delegated state for not being changelog,4
[FLINK-21355][state/changelog] Log changes (no metadata),5
[FLINK-22818][runtime] Emit constant numbers of data before the first checkpoint.,5
[FLINK-22899][table] ValuesUpsertSinkFunction needs to use global upsertThis closes #16091,1
[FLINK-23003][runtime] Fix resource leak in RocksIncrementalSnapshotStrategy,0
[hotfix] Rename Input#emitStreamStatus to processStreamStatusThis closes #16145,0
[FLINK-23004][yarn] Fix misleading logThis closes #16169,2
"[hotfix][table-common][table-planner-blink] Support deferred runtime implementation for built-in functionsWe can have functions which will not be implemented through a runtime class,but we still want to use the new function stack for them. In order to doso, we flag them.",1
[FLINK-22737][table-common][table-planner-blink] Introduce CURRENT_WATERMARK()This closes #16046.,2
[hotfix][docs] Allow formatting in SQL functions docs,2
[hotfix][table-common] Move specific type strategies out of TypeStrategies,4
[hotfix][table-common] Move specific input type strategies out of InputTypeStrategies,4
[hotfix][docs] Fix typos in  Scala Table-DataStream API docs,2
[hotfix][docs] Corrected timezone name and column alignment (#16103),2
[FLINK-22593][tests] Waiting for all tasks running before triggering savepoint in SavepointITCase,1
[FLINK-22625][connectors] Waiting for all tasks running before triggering savepoint in FileSinkMigrationITCase,2
[FLINK-22518][docs-zh] Translate the documents of High Availability into Chinese(#16084) (#16084)This fix #16084.,0
[FLINK-23024][rest] Make TaskManagerInfoWithSlots serializableThis closes #16188.,5
[FLINK-18182][kinesis] Updating to latest AWS SDK for Kinesis connector,3
[FLINK-22946][runtime] Recycle floating buffer outside the lock to avoid deadlock,2
[hotfix][core] Introduce config options constants in ConfigurationTest,5
"[FLINK-22878][core] Allow prefix syntax for ConfigOption.mapTypeThis adds support for prefix syntax in ConfigOptions of map type.Current syntax 1)value.avro-confluent.properties = schema: 1, other-prop: 2Additional syntax 2)value.avro-confluent.properties.schema = 1value.avro-confluent.properties.other-prop = 2Syntax 1 has precedence and is the default when calling `WritableConfig.set`.Thus, we still advertise syntax 1 with constant key spaces.However, esp. when working with connectors, formats, or other external systems,it is useful to forward property maps unchanged. Syntax 2 is more convenientfor users that define options via strings. Syntax 2 is used already in theproject by custom parsers at multiple locations. By introducing syntax 2,we simplify the code base for connector implementers.This closes #16150.",1
[FLINK_22662][yarn][test] Add logs for YARNHighAvailabilityITCaseThis closes #16197,1
[FLINK-22980][tests] Set parallelism on job vertex required by adaptive scheduler,1
[FLINK-22808][state/changelog] Log metadata,5
[hotfix] Refactor the initialization of StreamTask to expose CheckpointBarrierHandler,0
[FLINK-21085][runtime] SingleInputGate supports acquiring unfinished channels,5
"[FLINK-21085] Allows taking snapshot with closed operators if enabled checkpoints after tasks finishedSince the StreamTask would waiting till the downstream tasks have finishedprocessing all the pending records, during this period the checkpointhas to be taken with closed operators. In the future PR we woulddeal with this case by also reporting the status of operator finished.In this PR we would first not decline checkpoint in this scenarioso that we could add tests.",3
[FLINK-21085][runtime][checkpoint] Allows triggering checkpoint for non-source tasksThis closes #14820,1
[FLINK-22873][config][docs] Add ToC,1
[FLINK-22873][config][docs] Add ToC,1
[FLINK-20891][metrics][tests] Check that thread is still alive,3
"[FLINK-18182][kinesis] Fixing bad shading of AWS SDK config file, resulting in runtime errors when consuming using EFO",1
[FLINK-18182][kinesis] Adding cloudwatch dependency for AWS DynamoDB stream adapter,5
[FLINK-23018][state] Enable state factories to handle extended state descriptors,0
[hotfix][docs] fix img links and previous docs link,2
[FLINK-22993][filesystem] Fix the issue that CompactFileWriter won't emit EndCheckpoint with Long.MAX_VALUE checkpointId even though the inputs endThis closes #16161,2
[FLINK-21195][Connectors/FileSystem] LimitableBulkFormat is invalid when format is orcThis closes #16122,5
[FLINK-22987][ci] Fix scala suffix check* [FLINK-22987][ci] Fix scala suffix check* temporarily disable avro registry* Add basic precondition that at least 1 clean&infected module must be found* Invert exit handling,5
"[hotfix][docs] Fix groupBy() javadocs: make uniform, add links, fix UnsortedGrouping.",0
"[FLINK-21952] Make all the ""Connection reset by peer"" exception wrapped as RemoteTransportException",1
[FLINK-22881] Revert toggling IDLE/ACTIVE on records in IDLE stateThis closes #16095,4
[FLINK-22901][table] Introduce getUpsertKeys in FlinkRelMetadataQueryThis closes #16096,5
[FLINK-23034][runtime] Added compatibility for ExecutionState in HistoryServer,1
[FLINK-23040][table-common] Consider ConfigOption fallback keys in FactoryUtilThis closes #16214.,5
[FLINK-22886][state] Add unit test for resource leak in RocksIncrementalSnapshotStrategy,3
[FLINK-23030][network] PartitionRequestClientFactory#createPartitionRequestClient should throw when network failure,0
[FLINK-22988][tests] Port TestingUtils to java,3
[FLINK-22045][conf] Sync log level between ZK and shaded-ZK,2
[FLINK-23060] Move FutureUtils#toJava to separate class,4
[FLINK-22989][coordination][tests] Port Tasks to Java,3
[FLINK-22678][state][changelog] Configurations and user APIs for ChangelogStateBackendThis fix #16153.,0
[FLINK-22974][dist] Add execution checkpointing related configs in flink-conf.yaml.,5
"Revert ""[FLINK-22881] Revert toggling IDLE/ACTIVE on records in IDLE state""This reverts commit 2c260b53a37dfcc040c8d5cfbca36d010f9a3cef.",4
[FLINK-23040][table-common] Consider ConfigOption fallback keys of formats in FactoryUtilThis closes #16226.,5
[FLINK-23029] Extend PluginLoader to allow closing ClassLoader,1
"[FLINK-22788][table-planner-blink] Support equalisers for many fieldsWhen working with hundreds of fields, equalisers can fail to compilebecause the method body grows beyond 64kb. With this change, instead ofgenerating all code into one method, we generate a dedicated method perfield and then call all of those methods. This doesn't entirely removethe problem, but supports roughly a factor of 10 more fields and iscurrently deemed sufficient.This closes #16213.",1
[FLINK-23037][docs] Document limitations of unaligned checkpointsThis closes #16200,2
"[FLINK-22698][connectors/rabbitmq] Add deliveryTimeout to RabbitMQ sourceThis change enables setting the message delivery timeout in the RabbitMQ queueing consumer, allowing to properly stop the job in cases when no new message is available on the queue.Changes:- Add the ability to setDeliveryTimeout on the RMQConnectionConfig and its builder- Change default message delivery timeout in the RMQSource to 30 seconds (previously there was no timeout)- Extend RabbitMQ source unit tests",3
"[hotfix] Optimize table API WatermarkAssignerOperator idleness emittingAfter the removal of StreamStatusMaintainer we do not have a check of the currently announced StreamStatus, therefore the WatermarkAssignerOperator emits StreamStatus.ACTIVE for every incoming record.This change adds a local field for keeping track of the last emitted status and emits a new one only if it changed.",4
[FLINK-23011] Revert to not emitting IDLE when there are no PartialWatermarks,4
[FLINK-22881] Revert toggling IDLE/ACTIVE on records in IDLE stateThis closes #16095,4
[hotfix] Remove timeouts from HiveTableSinkITCase,4
[hotfix][docs] update JSON plan in operations playground,5
[FLINK-23081] Move Executors#directExecutorContext to AkkaFutureUtils,4
[FLINK-22462][connectors / jdbc] Fix XA connection leak,0
[FLINK-22462][tests] Fix and harden JdbcExactlyOnceSinkE2eTest1. Add test against MySQL2. Fix multiple issues in the test- Indefinite waiting in sources- Too early emission causing starvation in maps,1
[hotfix] Fix javadoc reference,2
[FLINK-23061] Split BootstrapTools,2
[FLINK-23092][python] Fix the issue that built-in UDAF could not be mixed use with Python UDAF in group windowThis closes #16240.,1
[FLINK-21938][docs] Add how to unit test python udfsThis closes #15360.,3
[FLINK-23075][python] Add Python API for enabling ChangelogStateBackendThis closes #16241.,4
[FLINK-22961][streaming] firstBarrierArrivalTime is recalculated when the first barrier or the barrier announcement received,2
[hotfix][tests] Setting alignment timeout to zero in order to start the unaligned checkpoint immediately,1
[FLINK-22085][tests] Add debug code to expose the sink status for KafkaSourceLegacyITCaseThis closes #16233,1
[FLINK-23027] Move chill dependency to flink-scala,2
[FLINK-22990][tests] Remove unused classes,1
[FLINK-22991][network] Use Optional in NettyBufferPool,1
[FLINK-23033][python] Add the missing ObjectArrayTypeInfo (#16220),5
[FLINK-23001][build] Fix missing Scala suffix by removing unneeded Scala-dependent dependency,4
[FLINK-23001][build] Re-enable Scala suffix check for avro-glue-registry moduleThis closes #16247,1
[FLINK-22992][security] Move SSLUtils#is*Enabled to SecurityOptions,0
[hotfix][tests] Use correct variable,1
[FLINK-23082] Split AkkaRpcServiceUtils,2
[FLINK-23073][formats / CSV] Fix space handling in Row CSV timestamp parserThis closes #16228,0
[FLINK-23059][docs] describe how to create ckp and savepoint dirs in operations playground docsThis closes #16218,2
[FLINK-23084] Move SecurityManager to flink-core,2
[FLINK-23084] Move Executors/-ThreadFactory to flink-core,2
[FLINK-22997] Replace AkkaUtils#get*Timeout*,1
[FLINK-23104][state-backend][build] Add scala version variable in pom of flink-statebackend-changelogThis closes #16248,4
[FLINK-22927][python] Fix the bug of JobStatusThis closes #16146.,0
"[hotfix][docs] Fix broken code block in ""Alter Statement"" pagesThis closes #16235",0
[FLINK-23096][Connectors/Hive] Optimize the SessionState exception capture to print out the correct and useful informationThis closes #16259,5
[FLINK-23119][python] Throw exceptions when compiling the job at places where Python UDAF is not supportedThis is to give a more helpful message if Python UDAF is used in places where it's not supported.This closes #16254.,1
[hotfix][table-common] Support prefix map syntax in FactoryUtil,0
[FLINK-21229][avro-confluent-registry] Shorten RegistryAvroOptions,1
[FLINK-21229][avro-confluent-registry] Add Confluent schema registry SSL support,1
[FLINK-21229][docs] Update avro-confluent docsThis closes #15808.,2
[FLINK-23131][conf] Remove scala from PLUGIN_ALWAYS_PARENT_FIRST_LOADER_PATTERNS,4
[FLINK-23087] Make AddressResolution a top-level class,1
[FLINK-23025][upsert-kafka] Fix upsert-kafka produce duplicates when enable object reuseThis closes #16257,1
[FLINK-23078] Add SchedulerBenchmarkUtils#shutdownTestingUtilDefaultExecutor,3
[FLINK-23057] add variable expansion for FLINK_ENV_JAVA_OPTS in flink-console.sh,2
[FLINK-23085] Move FutureUtils to flink-core * [FLINK-23085] Move FutureUtils to flink-core* +,2
[FLINK-23130][rest] Remove netty 3 reference,4
[FLINK-22052][python] Add new state backends to PyFlink,2
[FLINK-22052][python] Add new checkpoint storage classes to PyFlink,2
[FLINK-22052][python] Add set_default_savepoint_directory to PyFlinkThis closes #15441,2
[FLINK-23065][table-api-java] Introduce TableEnvironment#createTemporaryTable with new TableDescriptorThis closes #16243.,1
[hotfix][table-common] Make Schema class immutable,1
[hotfix][table-common] Mark SchemaResolver as @PublicEvolving,0
[FLINK-23133][python] Properly handle the dependencies when mixing use of Python Table API and Python DataStream APIThis closes #16272.,5
[FLINK-23138][python] Raise an exception if types other than PickledBytesTypeInfo are specified for state descriptorThis closes #16276.,5
[FLINK-22617][Hive] Add log for hive source that use native or mapred readerThis closes #16148,1
[FLINK-23010][hive] HivePartitionFetcherContextBase shouldn't list folders to discover new partitionsThis closes #16182,1
[FLINK-22147][connector/kafka] Refactor partition discovery logic in Kafka source enumerator,2
[hotfix][connector/test] Make MockSplitEnumeratorContext implement AutoClosable and shutdown executors at closing,1
[FLINK-22492][test] Use order-agnostic check in KinesisTableApiITCase.The query doesn't impose any ordering and a reorder may happen as is.,1
[FLINK-23118] Drop Mesos support,1
[FLINK-23028][docs] Improve documentation for pages of SQLThis closes #16070,2
[FLINK-22818][tests] Remembering important values only on certain checkpoint,2
[FLINK-23129][docs] Document ApplicationMode limitationsThis closes #16281,2
[hotfix][docs] Merge the two Flink POJO definitions to make the definition uniform.,5
[hotfix] Fix some typos in comments,2
[FLINK-22464][tests] Fix OperatorCoordinator test which is stalling or slow with AdaptiveSchedulerThis closes #16229,3
[hotfix] Let RunnablesTest extend TestLogger,3
[FLINK-23045][tests] Harden RunnablesTest by not relying on timeoutThis closes #16261.This commit hardens the RunnablesTest.testExecutorService_uncaughtExceptionHandler to not relyon timeouts to check whether the uncaught exception handler was called.,0
[hotfix][tests] Correct variable name in RunnablesTest.testExecutorService_uncaughtExceptionHandler,3
"[FLINK-23157][docs][table] Fix missing comma in ""Versioned Tables"" pageThis closes #16289",1
[FLINK-22940][sql-client] Make sql client column max width configurableThis closes #16245,5
[FLINK-23120][python] Fix ByteArrayWrapperSerializer.serialize to use writeInt to serialize the lengthThis closes #16258.,1
"[FLINK-23162][docs] Update column used in expression for creating table in ""Time Attribute"" pageThis closes #16301",1
[FLINK-22970][docs][table] The documentation for `TO_TIMESTAMP` UDF has an incorrect description (#16141),2
[FLINK-22966][runtime] StateAssignmentOperation returns only not null state handles,0
[hotfix][docs] Mention -D argument for CLI,2
[FLINK-23052][ci] Improve stability of maven snapshot deployment,1
[FLINK-23009][kinesis] Upgrade Guava for Flink Connector KinesisAlso make flink-sql-connector-kinesis use the Guava librarycoming transitively from the connector-kinesis dependency.,1
[FLINK-23078] Add SchedulerBenchmarkBase#teardown,1
[hotfix] Add whitespace to log statement in SourceCoordinatorProvider,1
[FLINK-23166][python] Fix ZipUtils to handle properly for softlinksThis closes #16309.,2
[hotfix][docs] Corrected tvf description and formatThis closes #16230,2
[hotfix][docs] fix typos (#16300),2
[FLINK-23041][streaming] Calculation of timeout for switching from AC to UC is based on the global checkpoint start time rather than the local first barrier received time,2
[FLINK-23041][runtime] Added new well defined checkpoint configuration aligned-checkpoint-timeout instead of alignment-timeout,5
[FLINK-23041][webui] Renamed alignment_timeout to aligned_checkpoint_timeout in WebUIThis closes #16227,2
[FLINK-23054][table] TemporalJoinRewrite should based on upsert key,2
[FLINK-23054][table] Rank update optimization should based on upsert key,5
[FLINK-23054][table] Join unique/pk optimization should based on upsert key,2
[FLINK-23054][table] Add SinkUpsertMaterialize before upsert sink to resolve change log disorderThis closes #16239,2
[hotfix][datastream] Remove raw casts in ContinuousFileReaderOperator.,2
"[FLINK-20888][runtime] Close outputs in OperatorChain.OperatorChain creates the outputs and owns them, so that it should also close them. Specific operators should not close the outputs.Also, ChainingOutput should never close the chained operator; it's not owning the operator.",1
[FLINK-23090] Introduce RpcSystem abstraction,5
[FLINK-21356][state/changelog] Serialize handles implementationsAdd ability to serialize metadata for in-memory and file implementations of changelog handles,0
[hotfix][state/changelog] Implement InMemoryChangelogStateHandle.getKeyGroupRange,4
[hotfix][state/changelog] Introduce StateChangelogHandleReaderInverse control when reading StateChangelogHandles to avoidembedding logic into handles and make the reader creation explicit andsymmetric to writer.The reader is now obtained from StateChangelogWriterFactory which isrenamed in a subsequent commit.,4
[hotfix][state/changelog] Rename WriterFactory to Storage after adding Reader,1
"[FLINK-21356][state/changelog] Implement checkpointing using changelogBoth materialized and non-materialized state are checkpointed.But materialization and recovery from changelog will be implemented in subsequent commits.For now,- changelog grows indefinitely (not truncated)- state changes are not applied on recovery, tests fail with incorrect results",0
"[FLINK-21356][state/changelog] Implement recovery using changelogBoth materialized and non-materialized states are read for recovery.Materialization will be implemented in subsequent commits.For now, changelog grows indefinitely.",5
[hotfix][state/changelog] Rename StateChangelogHandle to ChangelogStateHandle,4
[FLINK-23088] Add flink-rpc-core module,2
[FLINK-23089] Add flink-rpc-akka-module,2
"[FLINK-22964][connector/common] Exclude flink-core from connector-common dependencies.Connectors get shaded into the user jar and as such should contain no unnecessary dependencies to flink. However, connector-base is exposing `flink-core` which then by default gets shaded into the user jar. Except for 6MB of extra size, the dependency also causes class loading issues, when `classloader.parent-first-patterns` does not include `o.a.f`.",0
[FLINK-23017][sql-client] HELP in sql-client still shows the removed SOURCE functionality (#16321),1
"[FLINK-22954][runtime] Avoid StackOverflowException when a large scale job is canceling or failingCancel all pending requests of a canceled/failed execution version, or the requests may be fulfilled with a slot released by a previously fulfilled task and then released immediately, which is executed recursively and may cause StackOverflowException when the scale is too large.",1
"[FLINK-23156][docs][table] Fix links related to ""docs/dev/table/sql/queries"" (#16323)",2
"[FLINK-22462][tests] Fix JdbcExactlyOnceSinkE2eTest by pausing emission until checkpoint confirmedCurrently, the test job makes too many attempts with little progress andeventually times out.Too many attempts are made because each checkpoint can be failed by anyFailingMapper that reaches its randomly chosen threshold. And if somesubtask becomes back-pressured then any of three others will likely failthe checkpoint, reverting the progress.This change makes sources to pause for the checkpoint confirmation; andfixes static fields so that it runs more reliably in a loop locally.",1
[FLINK-22593][tests] Waiting all tasks running before triggerSavepoint,1
[FLINK-23059][docs-zh] Translate update to operations playground docs to Chinese (#16279),2
[FLINK-23142][table] UpdatableTopNFunction output wrong order in the same unique keyThis closes #16284,0
"[FLINK-23200][docs][table] Fix code example typo in ""Table API"" page (#16338)",2
[hotfix][formatting] Fix autoformatting which made javadoc of JobVertex#operatorIDs unreadable,1
[FLINK-23149][table-code-splitter] Introduce the new Java code splitter moduleThis closes #16283,1
[FLINK-23213][python] Refactor the code strucuture of Python DataStream APIThis PR refactors the following to make the code path simpler:- Merge ProcessFunctionOperation and DataStreamStatelessFunctionOperation into StatelessFunctionOperation- Move timerservice.py to package pyflink.fn_execution.datastream- Merge OneInputRowWithTimerHandler and TwoInputRowWithTimerHandler into InputHandler,0
[FLINK-23196][tests] use MiniClusterResource,5
[FLINK-23168][table-common][table-api-java] GenericInMemoryCatalog shouldn't merge properties for alter DB operation,5
[FLINK-23168][hive] HiveCatalog shouldn't merge properties for alter DB operationThis closes #16335,5
[FLINK-22528][docs] Document latency tracking metrics for state accesses,2
[hotfix][docs] Fix variable name,0
[FLINK-23213][python] Move class SimpleStateRequestHandler into a separate file,2
[FLINK-23213][python] Refactor BeamPythonFunctionRunner to make it more readable by grouping similar methods together,1
[FLINK-23213][python] Remove BeamTableStatefulPythonFunctionRunner and BeamTableStatelessPythonFunctionRunner and merge them into BeamTablePythonFunctionRunner,1
[hotfix][release-notes] Update release notes for 1.13 with accumulators semantics change in MiniClusterJobClientFLINK-18685 changed the semantics of the MiniClusterJobClient. This commit updates the 1.13 release notesaccordingly.This closes #16256.,5
[hotfix][streaming] Fix the boundary condition when fetch limited records from streaming jobThis closes #16256,0
[FLINK-21086][runtime][checkpoint] Add EndOfUserRecordsEvent,1
[FLINK-21086][runtime][checkpoint] Let result partition supports waiting for the downstream tasks to processed all the records,1
[FLINK-21086][runtime][checkpoint] StreamTask waits for all the records get processed by downstream tasks,1
[FLINK-21086][runtime][checkpoint] Downstream tasks response with Ack message when received EndOfUserRecordsEvent,1
[FLINK-21086][runtime][checkpoint] Make CheckpointBarrierHandler supports alignment with finished channels,5
[FLINK-23226][docs-zh] Fix Flink Chinese doc learn-flink/etl transformation.svg display issueThis closes #16364,0
[hotfix]: Fix broken javaDoc inline link.,2
[hotfix][core] Fix typo in the Builder of ResourceSpec,2
[hotfix][core] Check the cpu and heap memory to be positive when building ResourceSpec,0
[FLINK-21925][core] Introduce public SlotSharingGroupUsers can use this class to describe the name and the the different resource components of a slot sharing group.,1
[FLINK-21925][core] Introduce SlotSharingGroupUtils which contains utility for SlotSharingGroup,2
[FLINK-21925][core] Introduce #slotSharingGroup(SlotSharingGroup) for configuring slot sharing group with its resource,5
[FLINK-21925][core] Introduce StreamExecutionEnvironment#registerSlotSharingGroup,2
[FLINK-21925][core] Introduce fine-grained.shuffle-mode.all-blocking to avoid resource deadlock in batch jobs that apply fine-grained resource managementThis closes #16307,2
[FLINK-23232][python] Use pickle.loads defined in pyflink to avoid race condition of the default pickle,2
[hotfix][testutil] Add test utilization for listening metric registration,3
[FLINK-22766][connector/kafka] Report offsets and Kafka consumer metrics in Flink metric group,2
[FLINK-23215][table-code-splitter] Move NOTICE file into META-INFThis closes #16350,5
[FLINK-22884][hive] HiveCatalog should mark views as generic and store schema in propertiesThis closes #16149,2
"[FLINK-23225][doc-zh] Fixed some translation mismatches in the ""flink-architecture"" page (#16363)",2
[FLINK-22898][Connectors/Hive] return default-parallelism in HiveParallelismInference when there is no source inferThis closes #16310,5
[FLINK-22972][datastream] Forbid emitting from closed StreamSourceContexts,5
"[FLINK-22972][datastream] Remove StreamOperator#dispose in favour of close and finishThis commit cleans up StreamOperator API in regards to the termination phase and introduces a clean finish() method for flushing all records without releasing resources.The StreamOperator#close  method which is supposed to flush all records, but at the same time, currently, it closes all resources, including connections to external systems. We need separate methods for flushing and closing resources because we might need the connections when performing the final checkpoint, once all records are flushed. Moreover, the logic for closing resources is duplicated in the StreamOperator#dispose  method.This closes #16351",1
[FLINK-22972][docs] Update description of a task lifecycle,5
[FLINK-23095][runtime] Close the channel unspilling thread pool after restore,2
[FLINK-22700] [api] Propagate watermarks to sink API (FLIP-167)This closes #15950.,2
"[FLINK-23260][docs] Fix the link for Page ""docs/libs/gelly/overview"" (#16382)",2
"[FLINK-23259][docs] Fix the link for page ""docs/dev/datastream/operators/overview"" (#16381)",5
[FLINK-22714][table-planner-blink] Simplify window TVF to a simple window assigner if successornode is WindowRank or WindowJoinThis closes #16025,2
[FLINK-22781][table-planner-blink] Fix bug in emit behavior of GroupWindowAggregate to skip emit window result if input stream of GroupWindowAggregate contains retraction and input counter of input records for current window is zeroThis closes #16219,0
[FLINK-21445][clients] Refactors ClassPathPackagedProgramRetrieverClassPathPackagedProgramRetriever is replaced by DefaultPackagedProgramRetriever.A new interface EntryClassInformationProvider is introduced encapsulating theextraction of the actual jar/job class information. This enables us to test thethe functionality in a more fine-grained way. Improvements like fail-early werenot added as part of this refactoring to limit the scope of the change.,4
[FLINK-21445][clients] Adds configuration parameter to DefaultPackagedProgramRetrieverThis is the actual fix for FLINK-21445.,2
"[FLINK-22880][table] Remove 'blink' term from code baseThis removes all mentionings of the term ""blink"" in the codebase. In order to reduce user confusion, do not use this termanymore but refer to as ""Flink SQL"" or ""Flink Table API"".This closes #16374.",2
[hotfix][tests] Add flink-table-code-splitter to 'table' stage,2
[FLINK-23074][connector-hive] Shade parquet class in hive-exec to prevent conflict with flink-parquet moduleThis closes #16353,2
[FLINK-23256][docs][table] Update EXPLAIN output example in Table API pages (#16380),5
[FLINK-15031][runtime] Netty Shuffle Service supports to announce fine grained network buffer requirementThis closes #16173.,1
[FLINK-15031][runtime] Scheduler enriches network memory requirement in ResourceProfile of SSG,2
[FLINK-21448] Add dependency for ChangelogStateBackend ITTests,3
[FLINK-21448] Randomize ITTests,3
[FLINK-21448] Add randomization of state changelog config,5
[FLINK-23270][docs][table] Impove description of Regular Joins section (#16392)Co-authored-by: liufangliang <tanghao@xiaohongshu.com>,2
[FLINK-23220] MailboxProcessor should wait for default action available even if there are no mails,2
[FLINK-22996][docs] fix documentation of COALESCEThis fixes #16362,0
[hotfix][docs] Fix code snippet with incorrect scala syntaxThis closes #16391,0
[hotfix][docs] fix typo in SQL functionsThis closes #16390,1
[FLINK-23220][hotfix] Remove unnecessary ensureDefaultActionSuspend,4
[FLINK-22879][table] Rename flink-table-uber-blink to flink-table-uberIt might be required to update job dependencies. Note that flink-table-uberused to contain the legacy planner before Flink 1.14 and now cotains theonly officially supported planner (i.e. previously known as 'Blink' planner).,2
[FLINK-22879][table] Rename flink-table-runtime-blink to flink-table-runtimeIt might be required to update job dependencies.,5
[FLINK-22879][table] Rename flink-table-planner-blink to flink-table-plannerIt might be required to update job dependencies. Note that flink-table-plannerused to contain the legacy planner before Flink 1.14 and now cotains theonly officially supported planner (i.e. previously known as 'Blink' planner).This closes #16386.,2
[FLINK-23182][connectors/rabbitmq] Fix connection leak in RMQSource,0
"[FLINK-23070][table-api-java] Introduce TableEnvironment#createTableThis behaves much like the previously introduced #createTemporaryTable,but actually permanently stores the table in a catalog.This closes #16285.",2
[hotfix][docs][cassandra] Added missing cluster builder arg for cassandra sink (#16365),1
[FLINK-23184][table-runtime] Fix compile error in code generation of unary plus and minusThis closes #16406,0
[FLINK-23066][table-api-java] Introduce TableEnvironment#from(TableDescriptor)This closes #16287.,2
[FLINK-23283][table-planner] Fix unstable case GroupWindowITCase#testWindowAggregateOnUpsertSourceThis closes #16408,3
[FLINK-23165][python] Add StreamExecutionEnvironment#registerSlotSharingGroup to PyFlink and ScalaThis closes #16405.,2
[FLINK-23280][python] Fix the issue that Python ExplainDetails does not have JSON_EXECUTION_PLAN optionThis closes #16407.,5
[hotfix][table-planner] Expose returning the only raw results if possible,0
[FLINK-23067][table-api-java] Introduce Table#executeInsert(TableDescriptor)This closes #16290.,2
[hotfix][table-api-java] Improve JavaDocs for DML behavior,2
[hotfix][docs] Fixed errors references for  'site.scala version suffix' and 'site.version'This closes #16340,0
[FLINK-22889] Add debug statements to JdbcExactlyOnceSinkE2eTest,5
[FLINK-21804][state/changelog] Create and wire changelog storage with state backendThis fix #16341.,0
[FLINK-23298][datagen] Normalize parameter names in RandomGeneratorVisitor and SequenceGeneratorVisitorThis closes #15965,2
[FLINK-23222][docs-zh] Translate page 'Application Profiling & Debugging' into Chinese (#16359),0
[FLINK-23178][hive] Raise an error for writing stream data into partitioned hive tables without a partition committerThis closes #16370,5
[FLINK-22443][streaming-java] Fix overflow in MultipleInputSelectionHandler,0
[FLINK-23202] Introduce marker interface to filter out Flink related RPC messagesThe marker interface rpc.messages.Message identifies all Flink related RPC messages. This canbe used to filter for these messages and to trigger specific actions.,1
"[FLINK-23202][rpc] Fail rpc requests for unreachable recipients eagerlyThis commit adds the DeadLettersActor that monitor Akka's dead letter mailbox. Whenever aFlink Message is received if sends a failure to the sender to notify the sender about theunreachability of the recipient. That way it is possible to eagerly fail the result futures,and not having to wait on the rpc timeout.",0
[hotfix] Deduplicate logic to build rpc method stringThis commit deduplicates the logic to build a string representation of a rpc.,2
[FLINK-23202][rpc] Fail with AkkaRecipientUnreachableException if local actor has terminatedThis commit replaces the AskTimeoutException with an AkkaRecipientUnreachableException if the local actorhas already terminated. This works by looking at the exception message. This ensures that we respond withthe right exception if the local actor is unreachable.This closes #16342.,1
[hotfix][test] Replace junit.Assert.assertThat with hamcrest.MatcherAssert.assertThat in AkkaRpcServiceTest,3
[hotfix][test] Replace junit.Assert.assertThat with hamcrest.MatcherAssert.assertThat in RemoteAkkaRpcServiceTest,3
"[FLINK-23276][state/changelog] Fix missing delegation in getPartitionedStateChangelog backend creates delegating functions on recoveryso that user can later provide function code.Some branches do not register delegates currently,this change fixes it.",0
[FLINK-21087][runtime][checkpoint] StreamTask waits for all the pending checkpoints to finish before finishedThis closes #14857,5
"[FLINK-23071][table-api-java] Introduce StatementSet#addInsert(TableDescriptor, Table)This closes #16291.",1
"[FLINK-23308] Optimize checks if SourceContext is closedThis commit tries to optimize checks on the hot path for closedSourceContext. It removes unnecessary duplicated calls ofcheckNotClosed.There is no certainty it fixes the problem, however we want to runbenchmarks for a couple of days and see how it affects the performance.",1
"[FLINK-23278][state/changelog] Allow recovery without non-materialized stateMotivation:1. ChangelogBackend.savpoint() currently simply delegates tothe underlying backend, so the snapshot doesn't containnon-materialized state2. Enable migration to ChangelogBackend from savepoints3. Some tests create savepoints directly using underlying backendsand then try to recover a regular job from them. This fails withChangelogBackend enabled.",0
[hotfix] Minor clean-ups in YARNHighAvailabilityITCase,4
[FLINK-22662][yarn][test] Stabilize YARNHighAvailabilityITCaseThis closes #16395,1
[FLINK-22994][table-planner] Improve the performace of invoking nesting udfThis closes #16163,1
[FLINK-23306][table] Reduce usages of legacy TableSchemaThis closes #16425.,2
[FLINK-23262][tests] Check watermark frequency instead of countThis closes #16415,3
[FLINK-23080][datastream] Introduce SinkFunction#finish() method.,5
[FLINK-23080] Add finish() for the TwoPhaseCommitSinkThis closes #16385,5
[FLINK-23223] Notifies if there are available data on resumption for pipelined subpartition,5
[hotfix][state/ttl] Don't wrap with TTL twice,0
"[FLINK-23277][state/changelog] Store and recover TTL metadata using changelogUpon recovery, changelog backend creates underlying states to apply changes.TTL config is not available at that moment, so states are currently createdregardless of job TTL settings.This change stores TTL config along with metadata (in changelog); anduses it on recovery.Note: values are already serialized as TTL values and serializers as TTL seralizersNote: upgrading TTL settings is not possible (see FLINK-23143)",2
"[FLINK-22819][yarn] Remove 'yarn.am.liveness-monitor.expiry-interval-ms' override for tests.This is an interval between AM container allocation and actually running RM Client inside this container,which can take longer in resource limited environment such as CI. If heartbeats between AM and RM don'twork and a test relies on this, then it will fail a bit later because the default value is 5 minutes.This closes #16413.",1
[hotfix][docs] Update release notes for 1.13 with state backend migration detailsCo-authored-by: David Anderson <david@alpinegizmo.com>,5
"[FLINK-23308] Replace regular SourceContext with a throwing one on closeThis commit adds a thin wrapper that will substitute on close, a regular SourceFunction.SourceContextwith a one that throws an exception on any interaction. We do that instead of adding a flag in WatermarkContextfor performance reasons.This closes #16446",1
[FLINK-23267][table-planner] Enable Java code splitting for all generated classesThis closes #16349,0
[FLINK-23023][table-planner] Support offset in window TVFThis closes #16215,1
"[FLINK-23243][docs-zh] Translate ""SELECT & WHERE clause"" page into Chinese (#16418)",1
"[FLINK-23292][docs] Fix some link issues on page  ""docs/content/docs/dev/table/concepts/dynamic_tables"" (#16410)",2
"[FLINK-23285][docs] Fix some link issues on page  ""docs/dev/datastream/event-time/generating_atermarks/"" (#16400)",5
"[FLINK-23268][docs] Fix some link issues on page  ""docs/dev/table/sql/queries/match_recognize/"" (#16384)",2
"[FLINK-23109][docs] Translate ""Scala API Extensions"" pages into Chinese (#16319)",2
"[FLINK-23318][tests] Fix AkkaRpcActorTest.testOnStopFutureCompletionDirectlyTerminatesAkkaRpcActorAfter FLINK-23202 the AkkaRcpActorTest.testOnStopFutureCompletionDirectlyTerminatesAkkaRpcActor became unstablebecause it assumed that RPC call after the RpcEndpoint is terminated won't be executed. With FLINK-23202 thesecalls are now sent to the dead letter box which will result in a Failure response. Consequently, the second rpcis now failing with an RecipientUnreachableException. This commit updates the test to assert for this condition.Before, the test was passing because of a potential race condition where the second result future was not completed.This closes #16438.",1
[FLINK-23290][table-runtime] Fix NullPointerException when filter contains casting to booleanThis closes #16420,0
[FLINK-23021] Check for illegal job graph modifications with finishedoperatorsIf we restore from a checkpoint with finished vertices there are certaingraph modifications that are not supported. Usesrs can not add a runningoperator followed by a finished one. We throw an exception if weidentify such case.Moreover so far we do not support vertices with part of the chainfinished. This might happen if the chainning changes before the restore.We throw an exception in that case as well.,4
[hotfix][runtime] Log TaskThread StackTrace from the WatchDogShow where the task is stuck when the watchdog goes off (interrupted isn't triggered).Motivated by debugging FLINK-22889.,2
[FLINK-23348][kafka][test] Activate at-least-once related kafka it cases.This closes #16459,3
[FLINK-23064][connector-elasticsearch] Make connector options PublicEvolving,1
[FLINK-23064][connector-hbase] Make connector options PublicEvolving,1
[FLINK-23064][connector-kinesis] Make connector options PublicEvolving,1
[FLINK-23064][connector-jdbc] Create PublicEvolving JdbcOptions,5
[FLINK-23064][format-json] Make JsonOptions PublicEvolving,5
[FLINK-23064][format-avro][format-avro-confluent-registry] Expose config options as PublicEvolving,5
[FLINK-23064][format-csv] Expose CsvOptions as PublicEvolving,2
[FLINK-23064][table-api-java-bridge] Expose DataGenOptions as PublicEvolving,5
[FLINK-23064][table-runtime-blink] Expose FileSystemOptions as PublicEvolving,5
"[FLINK-23064][table-runtime-blink] Expose options for ""raw"" format as PublicEvolving",2
[FLINK-23064][connector-kafka] Expose connector options as PublicEvolvingThis closes #16334.,2
[hotfix][table-planner-blink] Fix typos in error messages for changelog mode,4
[FLINK-22590][table-api-scala-bridge] Add Scala implicit conversions for new API methodsThis updates the Scala implicits to the new methods introduced in FLIP-136 forDataStream API <-> Table API conversion.The changes might require an update of pipelines that used `toTable` or implict conversionsfrom `Table` to `DataStream[Row]`.This closes #16440.,5
[hotfix][table-api] Add environment pre-condition to fromXXStream() methods,1
[FLINK-11103][runtime] Set a configurable uncaught exception handler for all entrypoints[FLINK-11103][docs] Generate docs for ClusterOptions changes[FLINK-11103][tests] Add integration test for ClusterUncaughtExceptionHandler to check exit behaviourThis closes #15938.,0
[hotfix][tests] Remove unnecessary sleep from RemoteAkkaRpcActorTest.failsRpcResultImmediatelyIfRemoteRpcServiceIsNotAvailable,3
[hotfix] Remove redundant if condition in BufferManagerThis closes #11877.,4
[hotfix] Remove outdated comments in UnionInputGateThis closes #11877.,5
[hotfix] Simplify RemoteInputChannel#onSenderBacklog and call the existing method directlyThis closes #11877.,2
[hotfix] Fix typos in NettyShuffleUtilsThis closes #11877.,2
[FLINK-16641][network] (Part#1) Introduce a new network message BacklogAnnouncement which can bring the upstream buffer backlog to the downstream,2
"[FLINK-16641][network] (Part#2) Distinguish data buffer and event buffer for BoundedBlockingSubpartitionDirectTransferReaderCurrently, the BoundedBlockingSubpartitionDirectTransferReader does not distinguish data buffer and event buffer but it does not allocate floating credits for events, which means it relies on at least one exclusive credit to send the events. This patch changes the logic and distinguishes data buffer and event buffer for BoundedBlockingSubpartitionDirectTransferReader, after which the BoundedBlockingSubpartitionDirectTransferReader does not rely on the exclusive credits any more and we can set the exclusive credit to 0 after we finish FLINK-16641.",2
"[FLINK-16641][network] (Part#3) Support to announce the upstream backlog to the downstream tasksThis batch introduce the ability of announcing upstream backlog to the downstream tasks through the BacklogAnnouncement message when the exclusive credit is 0. This gives the upstream tasks the ability to actively allocate credits from the downstream tasks, which is needed by FLINK-16641.",2
"[FLINK-16641][network] (Part#4) Release all allocated floating buffers of RemoteInputChannel on receiving any channel blocking event if the exclusive credit is 0This patch tries to release all allocated floating buffers of RemoteInputChannel on receiving any channel blocking event if the exclusive credit is 0 because a blocked channel does not need any credit and after that, these released credits can be used by other active channels. This can avoid the deadlock where credits are assigned to channels which do need them and those channels who need credits can not get any when the exclusive credit is 0.",2
"[FLINK-16641][network] (Part#5) Send empty buffers to the downstream tasks to release the allocated credits if the exclusive credit is 0Currently,the empty buffers are not sent to the downstream tasks. This patch changes the logic and sends empty buffers to the downstream tasks when the exclusive credit is 0 release the allocated floating credits. If we do not do that, the downstream task may allocate more credits than needed which may lead to dead lock without exclusive credits.",2
"[FLINK-16641][network] (Part#6) Enable to set network buffers per channel to 0This PR enables to set the number of network buffer per channel (taskmanager.network.memory.buffers-per-channel) to 0. Previously, the value can not be set to 0 because of dead lock, FLINK-16641 solves the problem and we can set it to 0 now.",1
[FLINK-23235][connector] Fix SinkITCase instabilityThis closes #16441.,0
[FLINK-23359][test] Fix the number of available slots in testResourceCanBeAllocatedForDifferentJobAfterFreeThis closes #16469,3
[FLINK-23150][table-planner] Remove the old code split implementationThis closes #16460,4
[FLINK-21088][runtime][checkpoint] Assign a finished snapshot to task if operators are all finished on restore,5
[FLINK-21088][runtime][checkpoint] Pass the finished on restore status to TaskStateManager,5
[FLINK-21088][runtime][checkpoint] Pass the finish on restore status to operator chain,1
[FLINK-23356][hbase] Do not use delegation token in case of keytabCloses #16466,1
[FLINK-23368][python] Fix the wrong mapping of state cache in PyFlinkThis closes #16476.,2
[FLINK-23233][runtime] Ensure checkpoints confirmed after all the failed events processed for OepratorCoordinatorThis closes #16432.,0
[FLINK-21368] Remove RpcService#getExecutor,1
[hotfix] Replace AskTimeException usages in tests,3
[hotfix] Remove akka dependency in MetricUtilsTest,3
[hotfix] Allow @Internal annotation on fields,1
[hotfix] Extract logging parent-first patterns into constant,2
[FLINK-18783] RpcSystem extends AutoCloseable,5
[FLINK-18783] RpcSystem#load accepts Configuration,5
"[FLINK-18783] Add ComponentClassLoaderThe new ComponentClassLoader is intended as a CL that can eventually support all of our class-loading needs, including plugins, rpc systems and user-code.",1
[FLINK-18783] Load Akka with separate classloader,2
[hotfix][runtime] Log slot pool status if unable to fulfill job requirements,1
"[FLINK-22545][coordination] Fix check during creation of Source Coordinator thread.The check was meant as a safeguard to prevent re-instantiation after fatal errors killed a previous thread.But the check was susceptible to thread termination due to idleness in the executor.This updates the check to only fail if there is in fact an instantiation next to a running thread, or after apreviously crashed thread.",1
"[hotfix] Remove unnecessary warning suppression.This suppression was added to supress compiler warning about 'finally' not returning from 'System.exit()'.With the introduction of the indirection to the security manager, this compiler warning no longer happens.",2
[hotfix][docs][kafka] Corrected idleness attribute nameThis closes #16451,2
[FLINK-23347][docs][datatream] Updated operators windowAll descriptionThis closes #16455,1
[FLINK-22865][python] Optimize state serialize/deserialize in PyFlinkThis closes #16069.,2
"Revert ""[FLINK-18783] Load Akka with separate classloader""This reverts commit e341e47804ca966f22056bce8533b0d92a993953.",4
"[FLINK-23312][ci] speed up compilation for e2e testsThe ""compile"" builder already applies all checks so we can use -Dfast here;also, the web UI is not actually needed in the E2E tests.",3
[FLINK-23069][table-api-java] Support schemaless Table#executeInsert(TableDescriptor),1
[FLINK-23069][table-api-java] Rename ExternalSchemaTranslator,2
[FLINK-23069][table-api-java] Support schemaless StatementSet#addInsertThis closes #16470.,1
[FLINK-23370][table-planner] Propagate Boundedness of ScanRuntimeProviders to TransformationThis closes #16492.,1
[FLINK-22547][tests] Harden OperatorCoordinatorHolderTest.Ensure that the 'FutureCompletedAfterSendingEventsCoordinator' cannot exit before it has completedthe triggered checkpoint (completed the checkpoint future).,3
[hotfix][tests] Fix deprecation warnings for OperatorCoordinatorHolderTest,3
[FLINK-22477] Delete DefaultSlotPoolServiceFactory,4
[FLINK-22477] Remove SlotPoolImpl reference from SingleLogicalSlot,2
[FLINK-22477] Remove SlotPoolImpl from ExecutionGraphRestartTestThis commit replaces the SlotPoolImpl with the DeclarativeSlotPoolBridge in theExecutionGraphRestartTest.,3
"[FLINK-22477] Port SlotPoolBatchSlotRequestTest to use DeclarativeSlotPoolBridgeThis commit ports the SlotPoolBatchSlotRequestTest to use the DeclarativeSlotPoolBridge. Sometests which are no longer valid for the DeclarativeSlotPoolBridge have been removed. Moreover,this commit fixes a bug in the DeclarativeSlotPoolBridge.PendingRequest.markUnfulfillable.",0
[FLINK-22477][tests] Replace SlotPoolImpl usage with DeclarativeSlotPoolBridge in DefaultSchedulerBatchSchedulingTest,3
[FLINK-22477][tests] Replace SlotPoolImpl with DeclarativeSlotPoolBridge in SchedulerEndToEndBenchmarkBase,5
[FLINK-22477][tests] Rename SlotPoolRequestCompletionTest to DeclarativeSlotPoolBridgeRequestCompletionTestRename SlotPoolRequestCompletionTest to DeclarativeSlotPoolBridgeRequestCompletionTest and replace SlotPoolImplusage by DeclarativeSlotPoolBridge usage.,3
[FLINK-22477] Replace SlotPoolImpl with DeclarativeSlotPoolBridge in SlotPoolInteractionsTest,3
[hotfix] Import MatcherAssert.assertThat in DefaultDeclarativeSlotPoolTest,3
[hotfix][tests] Rename DefaultDeclarativeSlotPoolTest.testOfferingTooManySlots into testOfferingTooManySlotsWillRejectSuperfluousSlots,3
[FLINK-22477][tests] Remove SlotPoolInteractionsTest.testExtraSlotsAreKeptThe test SlotPoolInteractionsTest.testExtraSlotsAreKept is no longer valid for theDeclarativeSlotPoolBridge because this SlotPool will only accept slots it has askedfor.,1
"[FLINK-22477][tests] Remove SlotPoolPendingRequestFailureTesttestFailingAllocationFailsPendingSlotRequests, testFailingAllocationFailsRemappedPendingSlotRequestsand testFailingResourceManagerRequestFailsPendingSlotRequestAndCancelsRMRequest are no longer needed,because the declarative resource management no longer allows the RM to fail individual slot requests.SlotPoolPendingRequestFailureTest.testPendingSlotRequestTimeout is subsumed bySlotPoolInteractionsTest.testSlotAllocationTimeout.",3
[FLINK-22477] Move DeclarativeSlotPoolBridge test creation in to SlotPoolUtils,1
[FLINK-22477][tests] Replace TestingSlotPoolImpl with DeclarativeSlotPoolBridge in DefaultSchedulerComponentsFactoryTest,3
[hotfix][tests] Add DeclarativeSlotPoolServiceTest.testCloseReleasesAllSlotsForAllRegisteredTaskManagersThis commit adds a test which tests that all slots for all registered TaskManagers arereleased upon calling DeclarativeSlotPoolService.close().,3
[hotfix][tests] Add DeclarativeSlotPoolBridgeTest.testAcceptingOfferedSlotsWithoutResourceManagerConnectedThis commit adds DeclarativeSlotPoolBridgeTest.testAcceptingOfferedSlotsWithoutResourceManagerConnectedto ensure that SlotOffers are accepted if there is no ResourceManager connection.,3
[hotfix][tests] Use MatcherAssert.assertThat in DeclarativeSlotPoolBridgeTest,3
[FLINK-22477][tests] Remove SlotPoolImplTest,3
[FLINK-22477][tests] Remove AllocatedSlotsTest and AvailableSlotsTest,3
[hotfix][tests] Let PhysicalSlotProviderImplWithDefaultSlotSelectionStrategyTest extend TestLogger,3
[FLINK-22477][tests] Remove TestingSlotPoolImpl from PhysicalSlotProviderResource,1
[FLINK-22477][tests] Remove TestingSlotPoolImpl from PhysicalSlotProviderImplWithDefaultSlotSelectionStrategyTest and PhysicalSlotProviderImplWithSpreadOutStrategyTest,3
[FLINK-22477][tests] Remove unused methods from SlotPoolUtils,1
[FLINK-22477][tests] Remove SlotPoolBuilder,4
[FLINK-22477][tests] Remove TestingSlotPoolImpl,3
[FLINK-22477] Remove SlotPoolImpl,4
"[FLINK-22477] Remove ResourceManagerGateway.requestSlotThe ResourceManagerGateway.requestSlot method has only been used by the removedSlotPoolImpl. Hence, it is now possible to remove it.",4
"[FLINK-22477] Remove SlotPool.failAllocation(AllocationID, Exception)This commit removes the SlotPool.failAllocation(AllocationID, Exception) method that hasonly been used by the removed SlotPoolImpl.",4
[hotfix][tests] Fix capital variable names in ExecutionGraphRestartTest,3
[hotfix][tests] Replace assertThat with MatcherAssert.assertThat in PhysicalSlotProviderImplWithDefaultSlotSelectionStrategyTest,3
[hotfix][tests] Replace assertThat with MatcherAssert.assertThat in PhysicalSlotProviderImplWithSpreadOutStrategyTest,3
[hotfix][tests] Let PhysicalSlotProviderImplWithSpreadOutStrategyTest extend TestLogger,3
[FLINK-22477][tests] Extend DeclarativeSlotPoolBridgeBuilder to support build and buildAndStartThis closes #16485.,1
"[FLINK-23188][table-planner] Preserve function identifier during filter pushdownWhen a source implements SupportsFilterPushdown, filters are converted fromRexNode to Expression, and rejected filters are subsequently convertedback. However, during this conversion the function identifier for built-infunctions was lost, causing an exception downstream.This closes #16396.",1
[hotfix] Avoid excessive logging in DeclarativeSlotPoolBridge,2
[FLINK-23374][table-code-splitter] Add support for constructor call in JavaParserThis closes #16489,1
"[FLINK-16093][docs-zh] Translate ""System Functions"" page of ""Functions"" into Chinese (#16348)",1
[FLINK-23107][table-runtime] Separate implementation of deduplicate rank from other rank functionsThis closes #16434,1
[FLINK-23201][streaming] Calculate checkpoint alignment time only for last started checkpoint,2
[FLINK-23201][streaming] Reset alignment only for the currently processed checkpointThis closes #16361,1
[hotfix][yarn] Remove unused internal options in YarnConfigOptionsInternal,5
[FLINK-22627][runtime] Remove SlotManagerImpl and its related tests,3
[FLINK-22627][runtime] Remove TaskManagerSlot,4
[FLINK-22627][runtime] Remove PendingSlotRequest,4
[FLINK-22627][runtime] Remove unused slot request protocolThis closes #15899.,1
"[hotfix] Fix isClosed() for operator wrapper and proxy operator close to the operator chainPreviously isClosed() is marked after the finish() is called, which isnot as expected. This would break the assumption that checkpoints arealso supported after finish() is called. Currently we keep the codethat checks whether the operators are closed on checkpoints as asafeguard, but in realistic it should not happen.Besides, we also proxy the operator close to OperatorChain so that inthe following we could skip the lifecycle of the operators uniformly.",1
[FLINK-21089][runtime] Skip the lifecycle method of operators if finished on restore,5
[FLINK-21089][runtime] Skip execution for the legacy source task if finished on restore,5
[FLINK-21089][runtime] Skip the execution of new sources if finished on restore,5
[hotfix] Split the final checkpoint related tests to a separate test class.This is necessary since the StreamTaskTest is too big and has exceed thelimitation of file size configured in checkstyle plugin.,5
[FLINK-22843][docs-zh] Document and code are inconsistentThis closes #16337,2
"[FLINK-21928][core] Introduce org.apache.flink.util.concurrent.FutureUtils#handleException method, that allows future to recover from the specied exception.",1
"[FLINK-21928][clients] JobManager failover should succeed, when trying to resubmit already terminated job in application mode.[FLINK-21928][clients] Tolerate missing job result for already terminated jobs after JM failover in application mode.",0
[FLINK-21928][clients][runtime] Introduce static method constructors of DuplicateJobSubmissionException for better readability.This closes #16464.,1
[FLINK-23372][streaming-java] Disable AllVerticesInSameSlotSharingGroupByDefault in batch modeThis ensures consistency in terms of slot behavior between Table API batch mode and DataStreamAPI batch mode. It should lead to better resource utilization when running complex pipelineswith data dependencies between regions.This closes #16499.,5
[FLINK-22017][coordination] Get the ConsumedPartitionGroup that IntermediateResultPartition and DefaultResultPartition belong to,1
[FLINK-22017][coordination] Allow BLOCKING result partition to be individually consumableThis closes #16436.,1
[hotfix][tests] Extend ManuallyTriggeredScheduledExecutorService to also return cancelled tasks,3
[hotfix][tests] Remove Mockito usage from HeartbeatManagerTest,3
[hotfix] Introduce static inner classes for HeartbeatTargets in JobMaster,1
[hotfix] Introduce static inner classes for HeartbeatTargets in ResourceManager,1
[hotfix] Add FutureUtils.unsupportedOperationFuture(),1
[hotfix] Introduce static inner classes for HeartbeatTargets in TaskExecutor,1
[hotfix] Add TriConsumerWithException interface,1
"[FLINK-23209] Introduce HeartbeatListener.notifyTargetUnreachableWith this commit Flink's HeartbeatServices listen to the result of the heartbeat rpcs.If a rpc fails with RecipientUnreachableException, then it will fail the heartbeat andcall HeartbeatListener.notifyTargetUnreachable. All Flink components (ResourceManager,JobMaster and TaskExecutor) will treat this signal similar to a heartbeat timeout. Thismeans that connection failures on the TCP layer will now speed up the detection of lostcomponents.",0
"[FLINK-23209] Introduce failed heartbeat rpc threshold before marking target as unreachableThis commit introduces heartbeat.rpc-failure-threshold that can be used to configure the numberof failed heartbeat rpcs until a target is marked as unreachable. This can be used to detectdead TaskManagers faster as it has a detection time of threshold * heartbeat interval. The defaultvalue of this option is 2. If this refined heartbeat mechanism creates too many false positives,then this mechanism can be disabled by setting the threshold to -1.This closes #16357.",1
[FLINK-23093] Limit default io pool size to 4 for Mini Cluster.This closes #16274.,5
"[FLINK-21246] Fail fast if a failure occurs when triggering a checkpointon a TaskPrior to the change we did not check if the request finished successfully. If it did not, we wereleaving the checkpoint to fail due to a subsequent checkpoint. Since the Tasks can now finish it may be a more common situation that weend up with a failed checkpoint triggering. We should fail thecheckpoint fast if we realize we failed to trigger some tasks.This closes #16493",0
[FLINK-23367][state] Ensure InternalPriorityQueue#iterator could be closed for changelog state-backend,4
[FLINK-23400][python] Support to decode a single record for the Python coderThis closes #16508.,1
[hotfix][python] Remove unnecessary classes such as AbstractRowDataPythonScalarFunctionOperator and AbstractPythonTableFunctionOperator,1
[hotfix][python] Remove unless classes for the old planner,4
[FLINK-21770][metrics] JobManagerMG#addJob accepts job ID and name,1
[FLINK-21771][metrics][tests] Replace StreamTaskTestHarness#TestTaskMetricGroup,3
[FLINK-21756][jmx] Move JMXServer to flink-core,2
[FLINK-21775][metrics] Migrate JobManagerMG instatiations to factory method,2
[FLINK-21766][metrics] Remove OperatorMetricGroup#parent(),1
[FLINK-22386][tests] Cache docker images,2
[FLINK-21776][metrics] Migrate JobManagerJobMG instantiations to factory method,2
[hotfix][flink-core] fix typo in error message,0
[FLINK-23311][tests] fix PojoSerializerTest user POJO not taking dumm5 into account for hashCode and equals,1
[FLINK-23311][tests] nicer error messages in PojoSerializerTest via hamcrest,3
[FLINK-23311][tests] fix wrong parameter order in assertSame(),3
[FLINK-21757][metrics] Add LogicalScopeProvider interface,2
[FLINK-21759][metrics][tests] Add TestMetricGroup,3
[FLINK-21760][metrics][jmx] Remove flink-runtime dependency,2
[FLINK-21761][metrics][influxdb] Remove flink-runtime dependency,2
[FLINK-21772][metrics][slf4j] Remove flink-runtime dependency,2
[FLINK-21773][metrics][statsd] Remove flink-runtime dependency,2
[hotfix][metrics][tests] Cleanup test,3
[FLINK-21764][metrics][dropwizard] Remove flink-runtime dependency,2
[FLINK-21762][metrics][prometheus] Remove flink-runtime dependency,2
[hotfix][python][docs] Correct the docs of interval join,2
[FLINK-22676][coordination] The partition tracker stops tracking internal partitions when TM disconnectsThis closes #16118.,2
[FLINK-21084][runtime][checkpoint] Task reports finished snapshot on checkpoint if it is finished on restore,5
[FLINK-21084][runtime][checkpoint] CheckpointCoordinator records finished state for operators in tasks finished on restoreThis closes #16238,5
"[FLINK-23371][streaming-java] Allow disabling progressive watermarks for SourceFunctionIt might be a rare use case but since SourceFunction is still widely used, it ensurescorrectness and consistency with the FLIP-27 stack when used in a DynamicTableSource.",1
[FLINK-23371][table-planner] Disable progressive watermarks for bounded SourceFunctionsThis closes #16497.,1
[FLINK-23406][tests] Harden ClusterUncaughtExceptionHandlerITCase.testExitDueToUncaughtExceptionThis commit hardens the ClusterUncaughtExceptionHandlerITCase.testExitDueToUncaughtException by not blockingthe ClusterEntrypoint's main thread and therefore releasing the ClusterEntrypoint.lock.This closes #16514.,1
[FLINK-20975][hive][tests] Allow integral partition filter pushdownThis closes #16475,1
[FLINK-22452][Connectors/Kafka] Support specifying custom transactional.id prefix in FlinkKafkaProducer,2
[FLINK-22545][hotfix][coordination] Extend logging (temporarily) to debug test instability,3
[FLINK-22677][runtime] DefaultScheduler supports async registration of produced partitionsThis closes #16383.,1
[FLINK-22677][runtime] AdaptiveScheduler requires partition registration to be completed immediately,1
[FLINK-23409][runtime][test] Add logs for FineGrainedSlotManager#checkResourceRequirementsThis closes #16530,1
[FLINK-23115][python] Add ConfigOptions/TableDescriptor/FormatDescriptor/Schema in Python Table APIThis closes #16516.,5
[FLINK-23115][python] Expose create_table/create_temporary_table/from_descriptor of TableEnvironment in Python Table APIThis closes #16516.,1
[FLINK-23115][python] Expose Table#execute_insert and StatementSet#add_insert in Python Table APIThis closes #16516.,1
[FLINK-22862][python] Support profiling in PyFlinkThis closes #16063.,2
[hotfix][conf] Correct config option reference in resourcemanager.standalone.start-up-time,5
[hotfix][connectors/jdbc] Rename JdbcOutputFormat to JdbcRowOutputFormatCurrent JdbcOutputFormat works only with Rows which makes the namemisleading and doesn't allow to use it for more abstract version(which will be introduce in the subsequent commit).,1
"[hotfix][connectors/jdbc] Merge Batching and Abstract into JdbcOutputFormatCurrently, AbstractJdbcOutputFormat is only extended byJdbcBatchingOutputFormat making support of object reusemore complex than it could be (added in a subsequentcommit).",1
[hotfix][connectors/jdbc] Rename JdbcDynamicOutputFormatBuilder to JdbcOutputFormatBuilder,5
[FLINK-21367][connectors/jdbc] Support Object Reuse in JDBC sink,5
[FLINK-23186][docs] improve installation pageThis closes #16414,1
[FLINK-23395] Bump Okhttp to 3.14.9,2
[FLINK-20562][sql-client][table] Support explain details for EXPLAIN statementThis closes #15317,1
"[FLINK-23407][docs][core] Documented enums for config optionsWe now generate the list of available values into the description, ratherthan the type. Furthermore, by implementing the DescribedEnum interface,enums can be documented directly in code and have their description bepart of the generated output.",2
[FLINK-23407][docs] Use DescribedEnum for existing config option enumsThis closes #16515.,5
[FLINK-23402][streaming-java] Refactor ShuffleMode to StreamExchangeMode,4
[FLINK-23402][streaming-java] Fix minor code issues around 'shuffle mode',0
[FLINK-23402][streaming-java] Refactor GlobalDataExchangeMode to GlobalStreamExchangeMode,4
[FLINK-23402][streaming-java] Mark GlobalStreamExchangeMode as @InternalThis closes #16536.,4
[hotfix][docs] fix image rendering on local installation,0
[FLINK-23429][state-processor-api] Use Path instead of Path.getPath() to preserve FileSystem infoThis closes #16542,5
[FLINK-18783] Load Akka with separate classloader,2
[hotfix][tests] Fix raw generics in OperatorEventSendingCheckpointITCase,1
"[hotfix][coordination] Reduce log level for suppressed failures from WARN to DEBUG.Suppressed failures happen when the coordinator is receiving a fail() call while it is alreadyundergoing a failure/recovery cycle. This happens relatively frequently because of follow-uperrors triggered by the fact that the coordinator is undergoing failover.This was previously logged with WARN level, we change it to DEBUG, because these follow-up errorsare not something that should alert the user, they are usually not relevant at all. We only outputthem on DEBUG level for debugging cases.",0
[hotfix][coordination] Provide richer exception message for suppressed exceptions durnig coordinator failover,0
[FLINK-23401][python] Refactor the construction of transformation into getTransformsThis closes #16541.,1
[FLINK-23401][python] Use ParDoPayload to represent the user-defined functions in Python DataStream APIThis closes #16541.,5
[FLINK-23401][python] Separate data and timer processing into different channelsThis closes #16541.,5
[FLINK-23434][table-planner] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg functionThis closes #16539,1
[FLINK-23204] Provide StateBackends access to MailboxExecutor (#16531)There are several places in ChangelogStateBackend that need execute actions from the task thread- DFS writer: collect so far uploaded changes; handle upload results after completion- ChangelogKeyedStateBackend: checkpointing to combine state handles upon upload completion by writer- ChangelogKeyedStateBackend: materialization take a snapshot (sync phase) and handle results of the async phaseThis PR provides access to mailbox executor to simply threading model (avoid using lock).,1
[FLINK-23455][e2e] Remove the usage of the sql-client YAML file in SQLJobSubmissionThis closes #16555,2
[FLINK-23446][e2e] Refactor SQL Client end to end tests to replace YAML file with SQL DDLThis closes #16549,2
[FLINK-23363][table-code-splitter] Java code splitter now supports functions with return statements,1
[FLINK-23149][table-code-splitter] DeclarationRewriter should also rename local variables having the same name with existing member variables,2
[FLINK-23149][table-code-splitter] MemberFieldRewriter should not rewrite references field as it is a special name used by all code generatorsThis closes #16496,1
[FLINK-23352][streaming-java] Add configuration for batch size and socket timeout of collect sink (#16540),5
[FLINK-22861][table-planner] Fix return value deduction of TIMESTAMPADD functionThis closes #16511,1
[FLINK-21411][rocksdb] Update FRocksDB to bump bzip2 dependency versionThis closes #16568.,5
"[FLINK-23476][build] Remove unused dependencyThe akka.version property was recently moved to flink-rpc-akka, but there was still a reference to that property from the unused akka-testkit dependency in the root pom.",3
"[FLINK-22054][k8s] Using a shared watcher for ConfigMap watchingInitially, we started a separate connection for each ConfigMap watching.This change introduces KubernetesConfigMapSharedWatcher for allConfigMap watching.Internally, this change provides a implementaionKubernetesConfigMapSharedInformer based on SharedIndexInformer for theshared watcher interface.",5
[FLINK-22054][dist] Suppress the verbose log in kubernetes informerThis closes #15501.,5
[FLINK-21911][table-api] Add built-in greatest/least functions supportThis closes #16020,1
[FLINK-23467][e2e] Remove usage of the sql-client YAML file in pyflink.sh This closes #16574,2
[hotfix][metrics] Rename MinMaxAvgStats to StatsSummaryMotivation: add more aggregated info to MinMaxAvgStatsin the subsequent commits.,5
[hotfix][metrics] Introduce immutable snapshots for checkpoint statsMotivation: allow to use mutable histograms and their immutablesnapshots.,1
[hotfix][tests] De-duplicate code in ArchivedExecutionGraphTestMotivation: allow to test more snapshot summary valueseasier in a subsequent commit.,3
[FLINK-23144][metrics] Add percentiles to checkpoint statistics,1
[hotfix][docs] Fix typos,2
[FLINK-23471][checkpoint] Try best to ensure all operators and state manager handle the checkpoint complete notification,0
[FLINK-23402][streaming-java] Default to GlobalStreamExchangeMode.ALL_EDGES_BLOCKING in batch mode,4
"[FLINK-23402][streaming-java][table-planner] Add ShuffleMode optionThis introduces the config option execution.shuffle-mode which is anenum of values ALL_EXCHANGES_BLOCKING, ALL_EXCHANGES_PIPELINED, andAUTOMATIC.It replaces table.exec.shuffle-mode and allows to influence theGlobalStreamExchangeMode for both DataStream API and Table APIconsistently.This closes #16578.",5
[hotfix][docs] Regenerate options,2
"Revert ""[FLINK-23434][table-planner] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg function""This reverts commit a26887e1e257c6e9e14ad09d9aebe6416e69a4e1.",4
"[FLINK-23432][docs] Fix the markdown header issue in ""ops/state/checkpoints.md"" pageThis closes #16537",1
"[FLINK-23489][docs] Fix ""flink-config.yaml"" to ""flink-conf.yaml"" in ""cli.md"" pageThis closes #16586",1
[hotfix] Use execute to avoid exception being swallowed in KubernetesSharedInformer,5
[FLINK-23478][k8s] Guarantee the event handling order in KubernetesSharedInformerThis closes #16583.,5
[FLINK-23373][task] Fix source input serializer in StreamTaskMailboxTestHarness,3
[FLINK-23373][task] Fully support object reuse in OperatorChainThis closes #16518.,1
[hotfix][build] Remove duplicate dependency,4
[FLINK-23447][build] Bump lz4-java to 1.8.0,2
[FLINK-22893][zookeeper] Replace NodeCache with TreeCache,2
[FLINK-23329][build] Bump flink-shaded to 14.0,2
[hotfix][build] remove duplicate scalatest dependency,3
[FLINK-23102][rest] Return empty FlameGraph if feature is disabled,2
[FLINK-23364][table-planner] Add tests about code splitting for some generated classesThis closes #16566,3
[FLINK-23474] Extract internal version of InputStatusThis commit separates internal and user facing versions of InputStatus.User sources should never return e.g. the END_OF_RECOVERY status andthus we need an internal status.,1
[FLINK-22540][sql-client] Remove Yaml environment file in SQL Client (#16563),2
[FLINK-23369][connector-hive] Use enums for connector optionsThis also replaces ConsumeOrder with the (new) PartitionOrder as theyrepresent the same thing.,1
[FLINK-23369][connector-kafka] Use enums for optionsThis closes #16482.,1
[FLINK-23482][table] Simplify BlinkExecutorFactory stackThis closes #16585.,2
[FLINK-23005][coordination] Pass ConsumedPartitionGroup to TaskDeploymentDescriptorFactory as the key of cache,4
[FLINK-23005][coordination] Introduce CompressedSerializedValue,2
[FLINK-23005][coordination] Cache compressed serialized value of ShuffleDescriptorsThis closes #16314.,2
[FLINK-23218][coordination] Distribute the ShuffleDescriptors via blob serverThis closes #16538.,2
[FLINK-22715][table-runtime] Implement streaming window assigner table function operatorThis closes #16521,1
[FLINK-23438]  Bump httpclient from 4.5.3 and 4.5.9 to 4.5.13 + Bump httpcore from 4.4.6 and 4.5.11 to 4.4.14,2
[FLINK-23217][table-planner] Support StreamExecValues json serialization/deserializationThis closes #16544,5
[FLINK-23413][table-planner] Port RelTimeIndicatorConverter from SCALA to JAVAThis closes #16520,2
[FLINK-20323][table-planner] CorrelateSortToRankRule supports dealing with multiple group keysThis closes #16503,1
[FLINK-23500][akka] Create tmp dir if it doesn't exist,1
[hotfix] Move DirectlyFailingFatalErrorHandler to flink-runtime,2
[FLINK-23504][tests] Isolate TestingRpcService from Akka,3
[FLINK-23496][ci] Use MVN_GLOBAL_OPTIONS during maven snapshot deployment,1
[FLINK-19739][table-runtime] Fix compile exception for window aggregate in batch jobsThis closes #16591,0
[FLINK-22860][sql-client] Supplement 'HELP' command prompt message for SQL CLIThis closes #16060,2
[FLINK-22985][table-runtime] Fix NullPointerException when comparing temporal type with invalid string literalThis closes #16462,0
[FLINK-23490][examples][table] Updated print output in StreamWindowSQLExampleThis closes #16587,5
[FLINK-23322][connectors/rabbitmq] Increase RMQSource handshake timeout tolerating network congestions,1
[FLINK-22936][table-api] Support column comment in Schema and ResolvedSchemaThis closes #16588,0
[FLINK-23418][e2e] Increase the timeout to make kubernetes application ha test more stableThis closes #16602.,3
[FLINK-23460] Use a global feature flag in the CheckpointBarrierHandler,0
[FLINK-23460] Use a global feature flag in the CheckpointCoordinator,1
[FLINK-23460] Use global flag for enabling final checkpoints inSubtaskCheckpointCoordinator,0
[hotfix][state/changelog] Drop unused handle constructor and reader interface,0
[hotfix][tests] Introduce TestTaskStateManagerBuilderMotivation: allow to customize StateChangelogStorageFactorywithout resorting to mutable state.,4
[FLINK-21353][state] Add DFS-based StateChangelog,4
[FLINK-21353][state/changelog] Implement batching,4
[FLINK-21353][state/changelog] Implement retries,4
[FLINK-21353][tests] Use FS store in ChangelogBackend tests,3
[FLINK-23497][table-planner] Add dependency for scala-parser-combinatorsIt is contained in Scala 2.11 but needs to be added explicitly for Scala 2.12.This closes #16610.,1
[FLINK-22657][Connectors/Hive] HiveParserDDLSemanticAnalyzer directly return operationsThis closes #16416,2
[FLINK-23517][build] Add error messages for bannedDependencies rules,0
[FLINK-23354][blob] Limit the size of ShuffleDescriptors in PermanentBlobCache on TaskExecutorThis closes #16498.,2
[FLINK-23452][refactor] Extracted PeriodTimer interface for the abstraction of idle/backpressure time management,4
[FLINK-23452][runtime] Added extra classes for the ability to calculate throughput,1
[FLINK-23452][core] Added specific configuration for the calculation of the throughput,5
[hotfix] Stopping the StreamTask#systemTimerService explicitly after the invoke,5
[FLINK-23452][streaming] Integration ThroughputCalculator in StreamTask for the calculation of the subtask level throughput,2
[FLINK-23534] Fix flink-dstl-dfs version used in changelog statebackend,4
[FLINK-23239][hive][test] Fix race condition in HiveTableSinkITCase::testStreamingSinkWithTimestampLtzWatermarkThis closes #16634,3
[FLINK-19929] Upgrade Kinesis dependencies,2
[FLINK-23537][table-common] Make JoinedRowData publicThis closes #16631,5
"[FLINK-22889][tests] Use LogLevelRule JdbcExactlyOnceSinkE2eTestCurrently, log level is defined in log4j2-test.properties which isn't used in CI.",1
[FLINK-22889][tests] Configure MySQL lock wait timeout in JdbcExactlyOnceSinkE2eTestThis makes it clear whether waiting lock is the reason of timeoutof task cancellation or snapshot.,1
[FLINK-22889][tests] Log InnoDB details in JdbcExactlyOnceSinkE2eTest to ease debugging,0
[FLINK-23297] Upgrade Protobuf to 3.17.3,2
[FLINK-23546][dist] Supress error messages on macOS,0
[hotfix] Replace deprecated Assert.assertThat,3
[FLINK-22802][k8s] Bump fabric8 Kubernetes client version to 5.5.0,2
[FLINK-22802][k8s] Remove the unnecessary temporary fix for fabric8 Kubernetes client max concurrent requestsThis closes #16607.,0
[FLINK-23518][tests] Wait until curator has connected,3
[FLINK-23578][python] Remove PythonFlatMapOperator/PythonMapOperator/PythonPartitionCustomOperator operatorsThis closes #16664.,1
"[FLINK-23063][python] Remove TableEnvironment#connect APIThe TableEnvironment#connect API has been replaced by CREATE TABLE DDLin SQL and TableDescriptors in Table API via TableEnvironment#create_temporary_table(String, TableDescriptor).Note that the new method uses the FLIP-95 interfaces.",1
"[FLINK-23063][table-api][planner] Remove TableEnvironment#connect APIThe TableEnvironment#connect API has been replaced by CREATE TABLE DDLin SQL and TableDescriptors in Table API via TableEnvironment#createTemporaryTable(String, TableDescriptor).Note that the new method uses the FLIP-95 interfaces.",1
[FLINK-23063][table-api-java] Remove CatalogTableBuilderThis closes #16594.,2
"[hotfix] Remove the unnecessary suppressing logger for kubernetes informerIn FLINK-22802, the fabric8 Kubernetes client has been upgraded to 5.5.0, the verbose log level has been changed to Debug, so we don't need to suppress it manually.This closes #16661.",0
[FLINK-23450][avro-confluent-registry] Set properties map for DebeziumAvroFormatThis closes #16565.,1
[FLINK-23571][table-planner] Set internal query-start options when translate ExecNodeGraph to Transformation (#16668),1
[FLINK-23573][runtime][test] Add RecipientUnreachableException to the whitelist for e2e log checkings.This closes #16677,2
[hotfix][python] Fix the input value is None in IterableCoderImplThis closes #16611.,0
[FLINK-22911][python] Rework from_data_stream/create_temporary_view/to_data_stream of TableEnvironment in Python Table APIThis closes #16611.,5
[FLINK-22911][python] Add to_changelog_stream/from_changelog_stream to StreamTableEnvironment in Python Table APIThis closes #16611.,4
[FLINK-22911][python] Optimize the output format of RowTypeInfo and ExternalTypeInfoThis closes #16611.,5
[FLINK-22911][python] Optimize from_collection/from_elements to support RowKind and InstantThis closes #16611.,1
[FLINK-22911][python][doc] Add documentation how to interact with DataStream API in PyFlinkThis closes #16611.,2
[FLINK-23567][hive] Fix CNFE when creating hive table with locationThis closes #16665,1
"[FLINK-23591][docs] Fix the broken link in page ""mem_tuning.md""This closes #16682",2
"[FLINK-23423][docs-zh] Translate the page of ""Elasticsearch Connector"" into Chinese (#16547)",2
"[FLINK-16090][docs-zh] Translate ""Table API"" page of ""Table API & SQL"" into Chinese (#16316)",2
[FLINK-23584][python] Introduce PythonCoProcessOperator and remove PythonCoFlatMapOperator & PythonCoMapOperatorThis closes #16672.,1
[FLINK-23594][python] Ignore test_from_and_to_data_stream_event_time temporarily,5
[hotfix][table] Support new type system in flatten() function,1
[FLINK-15804][table-api-scala] Use new type inference for implicit ScalarFunction calls in ScalaThis closes #16678.,1
[FLINK-23569][docs] Fix typo,2
[hotfix][runtime][checkpoint] Rename isFinished to isFinishedOnRestore for task state,5
[FLINK-21080][runtime][checkpoint] The task reports whether it has called operators' finish method,5
[FLINK-21080][runtime][checkpoint] Fails checkpoints if some operators has union state are partly finished,5
[FLINK-21080][runtime][checkpoint] Report latest completed checkpoint id when notifying checkpoint abortThis closes #16633,3
[FLINK-23562][CI] Update CI JDK to 1.8.0_292,5
[hotfix][state][test] Add test file generation guide in AbstractOperatorRestoreTestBase,3
[FLINK-23529][core][test] Add Flink 1.13 MigrationVersionThis closes #16636,2
[hotfix] Fix checkstyle in JobVertex and DefaultExecutionGraphConstructionTest,3
[FLINK-23599] Remove JobVertex#connectIdInput and its related unit testsThis closes #16686.,3
[FLINK-23172][docs] Fix broken links to the restart strategy page on the Configuration page,5
[FLINK-23172][docs] Fix broken links to the failover strategy page on the Configuration pageThis closes #16624.,1
[FLINK-23524][tests] Harden AdaptiveSchedulerClusterITCase,3
[FLINK-23539][metrics][influxdb] Filter '\n' in tags,5
[FLINK-23183][connectors/rabbitmq] Fix ACKs for redelivered messages in RMQSource and add integration testsChanges:- channel.basicReject in RMQSource is called in case of already processed (and checkpointed) but redelivered messages (e.g. after the job failover)- add integration test that verifies that the source actually consumes the messages- add integration test reproducing the message redelivery issue in case of ack failure,0
[FLINK-23531][table] Supports compact-changes in row-time deduplicate mini-batchThis closes #16630,5
[hotfix][core] Support prefix maps in UnmodifiableConfiguration,5
[FLINK-23498][streaming-java] Remove StreamExecutionEnvironment.getConfiguration(),5
[FLINK-23498][streaming-java] Expose StreamExecutionEnvironment.getConfiguration(),5
[FLINK-23498][streaming-java] Expose an easier StreamExecutionEnvironment.configure(),5
[hotfix][table-planner] Remove unused field from PlannerBase,1
[FLINK-23498][table] Introduce a full planner configurationThis is an MVP version of a layered configuration of Executor and Table API.This closes #16626.,5
[FLINK-23511][docs] Fix display of system metrics,5
[FLINK-23463][docs] Replace <div> tags with ShortCodes,2
[FLINK-22891][runtime] Using CompletableFuture to sync the scheduling of checkResourceRequirementsThe result of ScheduledFuture#isDone can be false negativeThis closes #16640,1
[FLINK-25313][connector-elasticsearch] Remove legacy Elasticseach connectorUse the new connector via option 'connector' = 'elasticsearch-7'.,1
[FLINK-23513][connector-kafka] Remove legacy Kafka connectorUse the new connector via option 'connector' = 'kafka'.,1
"[FLINK-23513] Deprecate legacy CSV connectorWe don't remove the connector itself as it is still used in tests.However, we can remove the descriptors and mark it deprecated.",4
[FLINK-23513][table-common] Remove unused descriptor classes,1
[FLINK-23513] Remove format descriptors,4
[FLINK-23513][docs] Fix docs due to new CSV connector,1
[FLINK-23513][table-common] Remove FunctionDescriptor,1
[FLINK-23513][table-common] Remove CoreModuleDescriptor,4
[FLINK-23513][table-common] Deprecate remaining descriptors,5
[hotfix][table-api-java] Missing @Test annotation in TableEnvironmentTest,3
[FLINK-23513][table-api-java] Remove StreamTableDescriptorValidator,5
[FLINK-23513][e2e] Remove legacy factory check in test_sql_client.shThis closes #16638.,3
"[FLINK-23487][s3] Update aws and presto-hive dependenciesNewer versions are required to make IRSA (IAM Role for Service Account)work properly with S3. Since presto-hive now also directly depends onaws-java-sdk-sts, we make sure to exclude it from presto-hive and useour own version instead.This fixes IRSA for s3-presto, though not yet s3-hadoop.This closes #16592.",0
[FLINK-23402][streaming-java] Simplify shuffle mode for batch executionThis closes #16679.,2
[hotfix][docs] add missing file extension to redirect alias,2
"[FLINK-23590][streaming] Replace System.currentTimeMillis with SystemClock.relativeTimeMillis() in the testPreviously test was using System.currentTimeMillis() while production code effectively was using System.nanoTime(), which was causing inconsistencies between readings.",1
[hotfix][streaming] Removed useless calculateThroughput in the test,3
[FLINK-22670][FLIP-150][connector/common] Hybrid source baseline,2
[hotfix][connector][jdbc] Corrected exception variable name (#16662),5
"[FLINK-23214][runtime] Make ShuffleMaster a cluster level shared serviceThis patch makes ShuffleMaster a cluster level shared service, which makes it consistent with the ShuffleEnvironment.",1
[FLINK-22674][runtime] Provide JobID when applying for shuffle resources by ShuffleMaster#registerPartitionWithProducer,1
[FLINK-23249][runtime] Introduce ShuffleMasterContext to ShuffleMaster,2
"[FLINK-22675][runtime] Add lifecycle methods to ShuffleMasterThis patch adds some lifecycle methods to ShuffleMaster including open, close, registerJob and unregisterJob.This closes #16465.",1
[FLINK-23558][streaming] Ignoring RejectedExecutionException during s (#16653)* [FLINK-23558][streaming] Ignoring RejectedExecutionException during submitting the throughput calculation* [hotfix] Clarification of execution thread of actionExecutor in javadoc,2
[FLINK-23619][python] Remove PythonTimestampsAndWatermarksOperatorThis closes #16703.,1
[hotfix][python] Remove unused classes RunnerInputType and RunnerOutputType,1
[FLINK-23581][docs] Fix links to download page,2
[FLINK-23492][runtime] Harder testCachedStatsCleanedAfterCleanupInterval,3
"Revert ""[FLINK-23487][s3] Update aws and presto-hive dependencies""This reverts commit 48526e43bdbd4e837be863e4ac002ec7d8b03c64.",5
"[FLINK-22382][tests] Harden ProcessFailureCancelingITCase.testCancelingOnProcessFailureThis commit hardens the ProcessFailureCancelingITCase.testCancelingOnProcessFailure by increasing theaccepted heartbeat timeout. To mitigate the increase heartbeat timeout, this PR also sets the numberof acceptable failed heartbeat requests to 2 before marking a TM as dead.This closes #16704.",0
[FLINK-23453][refactor] Made a safe method for getting the number of buffers in the queue visible in the interface.,1
[FLINK-23453][core] Added the rest configuration for buffer-debloater,5
[FLINK-23453][runtime] Message for notification about new buffer size(NewBufferSize) was added,1
[FLINK-23453][runtime] Prepared Gates and Channels classes for either providing information for the calculation of buffer size and receiving the recalculated buffer size.,5
[FLINK-23453][streaming] Created the buffer debloater for the ability to automatically change the buffer size based on the throughput.,4
[FLINK-23453][streaming] Integration BufferDebloater to StreamTask,2
[FLINK-23453][core] Renaming configuration automatic-buffer-adjustment -> buffer-debloat,5
[FLINK-23437][jdbc] Add an option to (dis)allow XA transaction multiplexing,1
[FLINK-23587][k8s] Set the annotations on JobManager deployment when using native kubernetesThis closes #16697.,3
[FLINK-23621][datastream] Adding InterruptedException to Sink interfaces to facilitate async communication patterns.,1
[FLINK-23621][core] Move MailboxExecutor to flink-core and org.apache.flink.streaming.api.operators,2
[FLINK-23621][operators] Add MailboxExecutor handling to AbstractSinkWriterOperatorFactory such that extending factories only need to implement YieldingOperatorFactory to access it.,1
"[FLINK-23621][datastream] Adding mailbox, userClassLoader, and numberOfParallelSubtasks to Sink#InitContext.",5
[FLINK-21116][tests] Harden DefaultDispatcherRunnerITCase#leaderChange_withBlockingJobManagerTermination_doesNotAffectNewLeader.This closes #16695.,4
[FLINK-22405] [table-runtime] Support CharType for the LeadLagAggFunction in batch modeThis closes #16650,1
[FLINK-23634][tests] Explicitly trigger scheduled tasks... in BatchingStateChangeUploaderTest instead of waitingto make the test less flaky.,3
"[FLINK-23487][s3] Update aws and presto-hive dependenciesNewer versions are required to make IRSA (IAM Role for Service Account)work properly with S3. Since presto-hive now also directly depends onaws-java-sdk-sts, we make sure to exclude it from presto-hive and useour own version instead.This fixes IRSA for s3-presto, though not yet s3-hadoop.This closes #16717.",0
[FLINK-23610][tests] Harden DefaultSchedulerTest,3
[FLINK-23570][docs] Remove unnecessary scala suffixes,0
"[FLINK-23617][datastream] Clarify Sink usage and allow Sink to explicitly list compatible states.Currently, FileSink is able to read state from StreamingFileSink for a drop-in replacement but it's hard-coded in SinkTransformTranslator. In fact, all sinks effectively claim that they can read old StreamingFileSink state.This abstraction will be used in later commits by the newly introduced SinkWriterStateHandler during recovery.",0
[FLINK-23617][datastream] Add SinkOperator and CommitterOperator and introducing write state and commit handler.The SinkOperator is writing data and can directly use a co-located commit handler. It optionally forwards committables a CommitterOperator with a different parallelism where another commit handler is applied.Note that both operators exchange the committables as byte[] using the committable serializer to avoid falling back to Kryo.,1
[FLINK-23617][datastream] Translate sink into the new SinkOperatorFactory and CommitterOperatorFactory.This commit converts existing sink operators into SinkWriterStateHandler and CommitterHandler and composes them into the new operators.Further all test cases are adjusted to test the new combinations.,1
[hotfix][sql-parser] Fixed typo in flink-sql-parser (#16711),2
[hotfix][test] Replace MockStreamTask with StreamTaskMailboxTestHanressMockStreamTask and MockEnvironment are deprecated classes that are not fully initialised.For example they have no input gates configured.,5
"[FLINK-23560][task] Fix performance regression by unnecessary throughput calcuationsIf there are no input gates, there is no point of calculating the throughput and runningthe debloater. At the same time, for SourceStreamTask using legacy sources and checkpointlock, enqueuing even a single mailbox action can cause performance regression. This isespecially visible in batch, with disabled checkpointing and no processing time timers.",1
[hotfix][runtime] Fix typo,2
[FLINK-23509][connectors/kafka] Create new ProducerIdAndEpoch when resuming Kafka transactionBefore this change we did not create a new ProducerIdAndEpoch and rathermutated the already created one. This can overwrite the internallyused static ProducerIdAndEpoch#None which is used to describe a noninitialized state. Once the static object is mutated it breaks therecovery of transactions.,4
[FLINK-21108][web] Add custom netty HTTP request inbound/outbound handlersCloses #16463,0
"[hotfix][task] Rename BufferDebloater#targetBufferSizeFactortargetBufferSizeFactor is not actually a factor, but it's desiredtotal buffer size expressed in units of time.",1
[hotfix][test] Rewrite debloating test to use mailbox test harness,3
[FLINK-23408][task] Add metrics for buffer debloating,1
[hotfix][tests] Move getMostRecentCompletedCheckpoint to TestUtils,3
[hotfix][core] Add adapter between Sink.InitContext and SerializationSchema.InitializationContext,5
[FLINK-22902][connectors/kafka] Port KafkaSink to FLIP-143This commit introduces a new KafkaSink which is based onFLIP-143.,1
[hotfix][state] Allow to load FsStateChangelogStorageFactory,4
[hotfix][state/changelog] Persist and restore default valueThe default value of ValueState is currently alwaysrestored to null by the ChangelogStateBackend.This change writes it along with metadata and uses on recovery.,1
[FLINK-23279][state/changelog] Don't discard private stateDiscarding private state for the changelog backendwill be addressed in FLINK-23139.Discarding it now fails some tests by invalidatingcheckpoints on abortion.,5
[FLINK-23279][tests] Configure some tests to use FS DSTLSome tests produce too many state changes sothe testing (in-memory) implementation can'tkeep up.,3
[FLINK-23279][tests] Randomly use Changelog Backend in testsUnless LocalRecovery is enabled which is currentlynot supported by the Changelog State Backend.,4
[FLINK-22312][yarn][test] Fix log whitelist for AMRMClient heartbeat interruption.This closes #16733,2
[FLINK-23673][docs-zh] Fix the prompt and warning text block for Chinese pages (#16748),2
[FLINK-12438][doc-zh]Translate Task Lifecycle document into Chinese (#16304),2
[FLINK-23579][table-runtime] Fix compile exception in hash functions with varbinary argumentsThis closes #16718,1
[FLINK-23648][task] Replace StreamTwoInputProcessor with StreamMultipleInputProcessorMultiple input version seems to be better optimised so maintaining both doesn't make sense.,1
"[FLINK-23661][build] Use standard maven dependency resolution for protobuf pluginWhen the ""protocArtifact"" configuration parameter is used then the plugin downloads protoc via maven, and not it's own mechanism.",1
[FLINK-23624][metrics] Migrate TaskManagerMG instatiations to factory method,2
"[FLINK-23479][table-planner] Fix the unstable test cases about json planThe reason about the unstable test cases is the inner serializer instance in RawType is serialized directly as String to json which is mutable. While for a RawType representing DataView, the inner logical type is stable and accessible, we should serialize the inner logical type to make the json plan stable. For other case, we just keep the previous behavior.This closes #16599",5
[FLINK-21979][runtime] Cleanup completed checkpoint store after dispatcher cleans up HA services.This closes #16535.,4
[FLINK-23408] Rename EndOfUserRecords to EndOfData,5
[FLINK-23408] Add hasReceivedEndOfData to InputGatesThis commits introduces a method for checking if an InputGate received EndOfData on all underlying channels. It implements a similar logic to EndOfPartitionEvent and corresponding isFinished method.,5
[FLINK-23408] Support EndOfData in blocking subpartitionsWe want to rely on EndOfData to call finish/endInput methods on operators. Those methods are important in BATCH execution mode as well. In order to properly handle the EndOfData event we must make blocking subpartitions support it.,1
[hotfix] Static import Assert.assertEquals in KafkaShuffleITCase,3
"[FLINK-23408] Call finish/endInput on EndOfData eventWe want to be able to bring the entire topology with a single checkpoint/savepoint. In order to do that we must be able to call finish on all operators before such a checkpoint is triggered. The idea is to emit EndOfData, which once received, triggers finish()/endInput(). After such a sequence we can trigger a checkpoint/savepoint which meets the aforementioned criteria.As part of the commit we made the InputProcessors and in turn InputSelection work with EndOfData, which is a special kind of event that signals end of data, but after that point we still might receive e.g. barriers on such inputs. Therefore we can't exclude those inputs from input selection yet.",5
[refactor] Move exception handling into the legacy source thread.,4
[hotfix] Update StreamTask javadoc,2
[hotfix] Fix CollectResultBuffer,0
[FLINK-23408] Emit end of data for stop-with-savepoint --drain,5
"[FLINK-23541][task] Replace SourceOperator#emittedEndOfData with finished futureThis is a small refactor that creates a slightly better contract:- future returned from #stop() completes after operator processes #finish() callinstead of the previous one:- future returned from #stop() completes after returning END_OF_INPUTThe previous version was more fragile, as a lot of things could happen betweenreturning END_OF_INPUT and calling #finish()Secondly this gets rid of the CompletableFuture from the emitNext() methodwhich could potentialy cause some performance problems (it shouldn't, but it could)",0
[FLINK-23541][task] Optimise hot path for the SourceOperator,1
"[FLINK-23208] let late processing timers fired immediatelyThis speeds up triggering of the timers, as we don't have to always wait1ms between triggering next timer if all of them are from the past.",2
[FLINK-23644][build] Resolve maven warnings,2
[FLINK-23631][docs] Fix broken links in documentations (#16716),2
[FLINK-23626][metrics] Migrate all TaskMG instantiations to factory method,2
[hotfix][metrics] Fix compile issue,0
[FLINK-23255][test] Introduce JUnit 5 dependencies (#16551)[FLINK-23255][test] Introduce JUnit 5 dependencies.All existing JUnit4 tests are run through the vintage runner of JUnit5.,3
[FLINK-23192][table] Move connector & format options to consistent packagesWe should advertise the following package structure:For connector options:org.apache.flink.connector.XX.table.XXConnectorOptionsFor format options:org.apache.flink.formats.XX.XXFormatOptions[FLINK-23192][connector-hbase] Move HBase table connector options class[FLINK-23192][table] Move DataGen connector to a proper package[FLINK-23192][table] Move print sink and split config options[FLINK-23192][table] Move blackhole connector[FLINK-23192][table] Move raw format[FLINK-23192][formats] Mark factories as internalThis closes #16708.,2
[FLINK-23416][runtime] Don't log NoResourceAvailableException stacktraceThis closes #16523.,2
[hotfix] Remove unused MODULES_LEGACY_SLOT_MANAGEMENT variable from ci/stage.sh,1
"[FLINK-23701][docs] Fix Error translation in ""Builtin Watermark Generators"" page (#16767)",0
[FLINK-23408] Waiting for final checkpoint completed before finishing ataskStarting from this commit if a task finishes because it processed allincoming data it will wait for at least one final checkpoint tocomplete  which started after we processed all data. This lets us flushall buffered data and commit any side effects caused by processing thelast chunk of data.,5
"[hotfix][table] Fix unionAll typo in ""Table API"" page (#16749)",2
[FLINK-23246][table-planner] Refactor the time indicator materializationThis closes #16620,4
[FLINK-23434][table-planner] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg functionThis closes #16759,1
"[FLINK-23615][docs] Fix the mistake in ""systemfunctions"" page (#16757)",5
[FLINK-22606][hive] Simplify the usage of SessionStateThis closes #16700,2
[FLINK-23662][rpc][akka] Port all Scala code to Java,2
"[FLINK-23646][streaming-java][table] Use pipeline name consistently across DataStream API and Table APIThis simplifies the code in StreamExecutionEnvironment, TableEnvironment, StreamGraphGenerator to setthe pipeline option for the job name. The StreamGraphGenerator is responsible to declare the defaultjob name for batch and streaming jobs.This closes #16728.",1
[hotfix][python] Fix the bug of NPE in PythonCorrelateSplitRuleThis closes #16760.,0
[FLINK-18562][fs] Upgrade hadoop to 3.3.1 - Needed for ABFS support,1
[FLINK-18562][fs] Adding ABFS support to access ADLS Gen2 storage accounts,1
[hotfix] Fix typos in ExecutionGraph,2
[hotfix] Remove unused variables in DefaultExecutionGraph#attachJobGraph,1
[hotfix] Add the @Test tag for DefaultExecutionTopologyTest#testGetAllPipelinedRegions,3
[hotfix] Replace deprecated Assert.assertThat in DefaultSchedulingPipelinedRegionTest,3
[hotfix] Cleanup PipelinedRegionComputeUtil,4
[hotfix] Fix checkstyle violations in JobEdge,0
[hotfix] Remove unused method JobEdge#connectDataSet,5
[FLINK-22773][coordination] Make DefaultLogicalPipelinedRegion inherit from LogicalPipelinedRegion,2
[FLINK-22773][coordination] Make DefaultLogicalTopology inherit from LogicalTopology,2
[FLINK-22773][coordination] Introduce DefaultLogicalEdge,2
[FLINK-22773][coordination] Optimize the construction of pipelined regionsThis closes #16688.,2
[hotfix][docs] Update docs README.md,2
[FLINK-23692][ui] Clarify text on 'Cancel Job' confirmation button,5
[FLINK-23544][table-planner] Window TVF Supports session window in planThis closes #16669,1
[FLINK-23695][runtime] Fix DispatcherFailoverITCase so it works with the AdaptiveScheduler.This closes #16766.,1
[FLINK-23688][hadoop] Make JaasModule.getAppConfigurationEntries publicCloses #16758,5
[FLINK-23693][tests] Add principal creation possibilities to SecureTestEnvironmentCloses #16764,3
[hotfix][runtime] setThroughputMeter renamed to setThroughputCalculator according to name of the set object.,1
[refactor][runtime] Unification of obtaining reader in PartitionRequestQueue,5
[FLINK-23454][runtime] NewBufferSize migrated from long to int for bufferSize because the bufferSize is always int.,1
[FLINK-23454][runtime] Added the support of changing the max capacity to BufferBuilder,4
[FLINK-23454][runtime] Subpartition is able to notify the desirable buffer size for input buffer consumer.,2
[FLINK-23454][runtime] Notifying the subpartitions about the new received buffer size.,1
[FLINK-23454][runtime] LocalInputChannel notifying the subpartition about the new buffer size directly.,1
[FLINK-23454][runtime] ResultPartition changes the BufferBuilder size according to the desirable buffer size of each subpartition.,4
[FLINK-23726][runtime] Read buffer debloat configuration from task manager configuration rather than task configuration.,5
[FLINK-23722][fs] Downgrade shaded hadoop to 3.2.2 to avoid HADOOP-17771.,2
[FLINK-23722][fs] Downgrade shaded hadoop to 3.2.2 to avoid HADOOP-17771.,2
[FLINK-23678][tests] Harden KafkaSinkITCase#testWriteRecordsToKafkaWithExactlyOnceGuaranteeBefore this change multiple variables were changed across thread barrieswithout proper synchronization. The change introduces propersynchronization to alleviate the seen problem.,0
[FLINK-23475][runtime][checkpoint] Supports repartition partly finished broacast states (#16714)* [FLINK-23475][runtime][checkpoint] Supports repartition partly finished broacast states* Fix the judgement of unfinished and wrong comment / variable* Fix the tests* Add todo,2
"[FLINK-23685][docs-zh] Translate ""Java Lambda Expressions"" page into Chinese (#16753)",2
[FLINK-23645][table-sql] Fix SqlClient doesn't response correctly to Signal.INT (#16743),0
[hotfix][python][tests] Refactor the test cases in DataStreamTests to reduce the number of itcases,5
[FLINK-23616][python] Support to chain the Python DataStream operators as much as possibleThis closes #16777.,1
[FLINK-23678][kafka] Temporarily ignore KafkaSinkITCase.testWriteRecordsToKafkaWithExactlyOnceGuarantee.,3
"[FLINK-11634][docs] Translate ""State Backends"" page into Chinese (#16522)this fix #16522",0
[hotfix][table-planner] Propagate AssertionError in BuiltInFunctionTestBase,5
[hotfix][table-common] Introduce a symbol() argument type strategy,0
[hotfix][table-planner] Allow BuiltInFunctionTestBase to assert on runtime errors,0
[FLINK-16200][table] Support JSON_EXISTS in SQL & Table APIThis is partially based on the work done by @XuQianJin-Stars inhttps://github.com/apache/flink/pull/11186.supersedes #11186,2
[FLINK-16200][table-planner] Refactor CustomizedConvertRuleThis closes #16691.,4
[FLINK-23699] Fixed RocksDBOptions attribute reference,5
[FLINK-23713][tests] Do not hide original exceptions in SavepointITCase,3
[FLINK-7355][tests] Remove YARNSessionFIFOITCase.testfullAlloc and .testResourceComputationThis commit removes YARNSessionFIFOITCase.testfullAlloce and .testResourceComputation because:* There is no point in having them if they are ignored constantly because of the memory consumption.* They are not maintained due to them being @IgnoredThis closes #16785.,1
[FLINK-23707][streaming-java] Use consistent managed memory weights for StreamNodeThis closes #16771.,1
[FLINK-23716][docs-zh] Translate the 'Zipping Elements in a DataSet' page inito Chinese (#16775),5
[FLINK-23309][python] Optimize the finish bundle logic to make the Python UDF results could be processed in a pipeline manner during finishBundleThis closes #16467.,5
[FLINK-23742][python] Ignore test_keyed_co_process for the time being,3
[FLINK-22673][docs] Add docs for JAR related commands and remove the usage of the YAML fileThis closes #16779,2
[FLINK-23032][hive] Refactor HiveSource to make it usable in data stream jobThis closes #16430,5
[FLINK-23742][python] Fix instable test test_keyed_co_process,3
[FLINK-22912][python] Support state ttl in Python DataStream APIThis closes #16667.,5
[FLINK-22452][docs] list the configuration methods of FlinkKafkaProducer and add ProducerFencedException in Troubleshooting,1
[FLINK-23742][python][followup] Fix the checkstyle issue in test_data_stream.py,5
[hotfix][python] Ignore PythonTableFunctionOperatorTest temporarily,3
[hotfix][k8s] Fabric8FlinkKubeClient#checkAndUpdateConfigMap lower number of indentations.,5
[FLINK-23507] Use IP address of a kubernetes node when constructing node port connection string for the REST gateway.This closes #16720.,1
[hotfix][table] Improve signature of Executor,1
"[FLINK-20897][streaming-java] Make boundedness mutable in LegacySourceTransformationInputFormat, SourceFunction, and DataStream API are exposed via table source runtimeproviders that might not set the boundedness correctly. However, the table planner hasthe correct information and needs a way to enrich these transformations. The new sourcestack will set this property correctly.",5
[FLINK-20897][table-planner] Add FlinkContext.isBatchMode flag,2
[FLINK-20897][table-planner] Derive boundedness in TransformationScanProvider,1
"[FLINK-20897][table-planner] Support batch mode in StreamTableEnvironmentThis enables batch mode for StreamTableEnvironment.Both StreamExecutionEnvironment, TableEnvironment, and StreamTableEnvironmentuse StreamGraphGenerator with the same configuration. Previous work ensuredthat when execution.runtime-mode is set to BATCH all batch properties areeither set consistently (e.g. shuffle mode) or have no impact on the pipeline(e.g. auto watermark interval, state backends).Most of the changes are removing checks and ensuring that internal (e.g. values)and external (e.g. data stream, table source) source transformations are setto BOUNDED. The latter is a complex topic as we currently use 4 different waysof expressing external sources:- InputFormatProvider: Boundedness needs to be explicitly set by the plannerdue to custom formats that don't extend from FileInputFormat.- SourceFunctionProvider: Boundedness needs to be explicitly set by the plannervia custom transformation to also disable progressive watermarks.- DataStreamScanProvider: Boundedness needs to be explicitly set by the plannerto ensure old behavior again. New source interfaces + FileInputFormat are fine.- TransformationScanProvider: Boundedness can be derived automatically and willonly work with new source interfaces + FileInputFormat.This closes #16793.",2
[FLINK-23705][connectors/kinesis] Unregistering metric reporting for closed shards,2
[FLINK-23473][runtime] Do not create transaction in TwoPhaseCommitSinkFunction after finish (#16768),5
[hotfix][connectors/kafka] Make KafkaSinkBuilder#setDeliveryGuarantee public,1
[hotfix][connectors/kafka] Disable logging,2
[hotfix][connectors/kafka] Warn if transaction cancellation on startup fails,0
[hotfix][connectors/kafka] Expose KafkaSinkContext in KafkaRecordSerializationSchema#open,0
[hotfix][connectors/base] Implement DescribedEnum with DeliveryGuarantee to use it as Table API configuration,5
[FLINK-23639][connectors/kafka] Migrate Table API Kafka connector to use FLIP-143 KafkaSink,1
[FLINK-23639][docs] Update Kafka SQL connector docs to reflect new configuration,5
[hotfix][python] Use StreamExecutionEnvironment.getConfiguration to access configuration,5
[FLINK-14482][rocksdb] Bump FRocksDB version to 6.20.3This closes #16794.,5
[hotfix][test/testcontainers] Use Testcontainer BOM to manage versions in the project,3
[FLINK-19554][connector/testing-framework] Basic abstractions of connector testing framework,1
[FLINK-19554][testutil/container] Support TM restarting in FlinkContainer and network accessibility from other containers,1
[FLINK-19554][connector/testing-framework] Implementations of TestEnvironment,3
[FLINK-19554][connector/testing-framework] Connector testing framework utilities based on JUnit 5,3
[FLINK-19554][connector/testing-framework] Base test class for source with fundamental test cases,3
[FLINK-19554][connector/testing-framework] KafkaSource IT and E2E case based on connector testing framework,1
[FLINK-23621] Add InterruptedException to ProcessingTimeService#onProcessingTime,1
[FLINK-23735][connectors/kafka] Migrate BufferedUpsertSinkFunction to FLIP-143 Sink API,1
[hotfix][task] Improve and unify logging in StreamTask,2
"[FLINK-23741][checkpointing] Properly decline triggerCheckpoint RPC if StreamTask is not runningWith ENABLE_CHECKPOINTS_AFTER_TASKS_FINISH enabled, final checkpoint can deadlock(or timeout after very long time) if there is a race condition between selectingtasks to trigger checkpoint on and finishing tasks. FLINK-21246 was supposed tohandle it, but it doesn't work as expected, because futures from:org.apache.flink.runtime.taskexecutor.TaskExecutor#triggerCheckpointandorg.apache.flink.streaming.runtime.tasks.StreamTask#triggerCheckpointAsyncare not linked together. TaskExecutor#triggerCheckpoint reports that checkpointhas been successfully triggered, while StreamTask might have actually finished.",5
[FLINK-23556][table] Disable constantly failing test,3
[FLINK-23708][task][refactor] Split OperatorChain into Finished and Regular classes,5
[FLINK-23708][task] Fix do not use operators when task isFinishedOnRestore,5
[hotfix][test] Rewrite SourceTaskTerminationTest to mailbox,3
[hotfix][test] Add support for EndOfData in tests,3
[FLINK-23698][task] Add test for emitting EndOfData with finishedOnRestore tasks,5
[FLINK-23698][task] Re emit and pass watermarks in finished on restore tasks,5
"[hotfix][task] Replace if check with checkState for a condition that should never happenAfter changing the meaning of close() (to defacto dispose()), `isClosed()` shouldnever happen.",4
[refactor][core] Extract common context creation in CollectionExecutor,1
[refactor][connectors] Only use MockSplitReader.Builder for instantiation.,1
[FLINK-23652][core/metrics] Extract Operator(IO)MetricGroup interfaces and expose them in RuntimeContext,1
[FLINK-23652][test] Adding InMemoryMetricReporter and using it by default in MiniClusterResource.,5
[FLINK-23652][connectors] Adding common sink metrics.,1
[FLINK-23652][connectors] Adding common source metrics.,1
[FLINK-23189][checkpoint] Count and fail the task in case of IOExceptions in CheckpointCoordinator,0
[FLINK-23189][checkpoint] Replace CheckpointFailureReason.EXCEPTION with IO_EXCEPTION,0
[hotfix][test] Do not hide original exceptions in CheckpointCoordinatorTest,3
fixup! [FLINK-23189][checkpoint] Count and fail the task in case of IOExceptions in CheckpointCoordinator,0
[hotfix][tests] Add ZooKeeperResource.stop(),1
[hotfix][tests] Rename ZooKeeperLeaderElectionConnectionHandlingTest to ZooKeeperLeaderRetrievalConnectionHandlingTest,3
[FLINK-10052][ha] Tolerate temporarily suspended ZooKeeper connectionsSigned-off-by: tison <wander4096@gmail.com>,2
[FLINK-10052][tests] Extend test suite for handling of ZooKeeper connectionsAdded some more tests to ZooKeeperLeaderElectionConnectionHandlingTest and ZooKeeperLeaderRetrievalConnectionHandlingTest.,3
[hotfix][tests] Replace Junit assertThat with Hamcrest's in ZooKeeperLeaderRetrievalConnectionHandlingTest,3
[FLINK-10052][docs] Update ZooKeeper HA services documentation to include support for tolerating suspended connectionsThis closes #16801.,1
"[hotfix][tests] Clean up ZooKeeperLeaderRetrievalConnectionHandlingTestRemove unnecessary fields, unnecessary configurations and add restart method forthe ZK TestingServer.",3
[FLINK-23746][tests] Harden SuccessAfterNetworkBuffersFailureITCase.testSuccessfulProgramAfterFailureThis commit decreases the parallelism used by the test job in order to reduce the time it takes to deploythe whole job.This closes #16812.,3
"[FLINK-23732][tests] Increase logger-startup-timeout to 50sIn order to harden tests on slow CI, this commit increases the logger-startup-timeout from 30s to 50s.This closes #16814.",2
[hotfix] Replace deprecated Assert.assertThat in LocalInputPreferredSlotSharingStrategyTest,3
[FLINK-22767][coordination] Optimize the initialization of LocalInputPreferredSlotSharingStrategyThis closes #16687.,5
"[FLINK-22483][runtime] Remove CompletedCheckpointStore#recover) method an change contract of CheckpointRecoveryFactory#createCompletedCheckpointStore, so that newly constructed CheckpointStore is already recovered.It's enough to recover CompletedCheckpointStoreshould only once, right after JobMasterRunner gains leadership. This also ensures that we'll fetch checkpoints from the external store in a ""jobmaster-future-thread"", without pontetially blocking RPC threads.This closes #16652.",1
[FLINK-23713][tests] Harden SavepointITCase.testStopWithSavepointWithDrainGlobalFailoverIfSavepointAbortedThis commit makes the SavepointITCase.testStopWithSavepointWithDrainGlobalFailoverIfSavepointAborted no longerassert for an internal exception message that is an implementation detail of Flink. Instead the test now checksthat all tasks are running again after failing to write the savepoint.This closes #16818.,0
[FLINK-23736][docs] Delete test line,3
[hotfix][docs] Fix typo,2
[FLINK-23738][state] Hide ChangelogBackend config optionsThe feature won't be released in the upcoming release. # Please enter the commit message for your changes. Lines starting,4
[FLINK-23738][state] Remove ChangelogBackend from the public APIsThe feature won't be released in the upcoming release. # Please enter the commit message for your changes. Lines starting,4
[FLINK-23738][tests] Disable ChangelogBackend in testsThe feature won't be released in the upcoming release.,3
[FLINK-23616][python] Support to chain the Python DataStream operators in execute_and_collectThis closes #16804.,1
[FLINK-23616][python] Support chaining optimization when mixing use of Python Table API and Python DataStream APIThis closes #16810.,5
[FLINK-23744][sql-client] Fix unstable CliClientTest#testCancelExecutionInteractiveMode (#16803),3
[FLINK-12403][doc-zh]Translate 'How to use logging' page into Chinese (#16313),2
[FLINK-23771][runtime][checkpoint] Fix the issue of getAllReceivedFuture if all channels are finishedThis closes #16827.,5
[FLINK-18840][table-api] Add StreamStatementSet.attachAsDataStream()This closes #16816.,5
[FLINK-23627][metrics] Migrate OperatorMG instantiations to factory method,1
[FLINK-23625][metrics] Migrate TaskManagerJobMG instantiations to factory method,2
[FLINK-23560][runtime] Calculate absoluteTimeMillis only once for idle metric and throughput calculation. (#16772)* [FLINK-23560][runtime] Calculate absoluteTimeMillis only once for idle metric and throughput calculation.* [hotfix][runtime] Update measurement start time only if the measurement was started before throughput calculation.,5
[FLINK-23720][table] Migrate ModuleFactory to the new stack- [table] Migrate HiveModule- [table] Migrate CoreModule- [table] Add a module factory helper- [table] Remove ModuleDescriptor(Validator)- [sql-client] Remove unsued test module- [table] Move deprecated logic into FactoryUtil for easier removal- [table] Make LOAD MODULE summary string more SQL-likeThis closes #16781.,1
[FLINK-22871][python] Support to specify python client interpreter used to compile jobsThis closes #16833.,1
[FLINK-21222][python] Support loopback mode to allow Python UDF worker and client reuse the same Python VMThis closes #16732.,1
[hotfix][tests] Downgrade log statement from metric InMemoryReporter,2
"[FLINK-23785][tests] Synchronize accesses in InMemoryReporter.Even through TestReporter methods are synchronized, InMemoryReporter needs additional synchronizations since it retains metrics and groups outside of the notify* callbacks. Thus, the callbacks and any other InMemoryReporter method may be called in parallel causing concurrent modifications to the data structures.This implementation naively uses full-fledged synchronization barriers since accesses to the InMemoryReporter are rare.",1
[FLINK-23785][tests] Use unique operator names for metric tests.,3
[FLINK-23247][table-planner] Materialize time attribute fields of regular join's inputsThis close #16739,2
[hotfix][table-planner] Extend BuiltInFunctionTestBase to expect different data types,5
[hotfix][table-common] Introduce a strategy for type literal arguments,0
[hotfix][table-common] Introduce forceNullable as a type strategy,1
[FLINK-16201][table] Support JSON_VALUEThis closes #16776.,5
[hotfix][python] Remove jsonExists and jsonValue from PyFlink for now,2
[hotfix][table-common] Rename nullable() to nullableIfArgs(),0
"[FLINK-23802][kinesis][efo] Request next record from the Flink source thread rather than the AWS SDK response thread. Increase Read Timeout to 6m, higher than the maximum Shard subscription duration (5m) and enable TCP keep alive.",0
[FLINK-23111][runtime-web] Bump angular's and ng-zorro's version to 8,2
[FLINK-23111][runtime-web] Bump angular's and ng-zorro's version to 9,2
[FLINK-23111][runtime-web] Bump angular's and ng-zorro's version to 10,2
[FLINK-23111][runtime-web] Bump angular's and ng-zorro's version to 12,2
"[FLINK-23111][runtime-web] Fix maven build node version, several dependencies, and NOTICEThis closes #16603.",0
[FLINK-22914][connector/kafka] Use FLIP-27 KafkaSource in table connectorThis closes #16809,1
[FLINK-22519][python] Support tgz files as python archivesThis closes #15813.,2
[FLINK-23767][streaming] Update definition of StreamStatus.,5
[FLINK-23767][streaming] Rename StreamStatus to WatermarkStatus.git grep -l 'streamStatus' | xargs sed -i '' -e 's/streamStatus/watermarkStatus/g'git grep -l 'StreamStatus' | xargs sed -i '' -e 's/StreamStatus/WatermarkStatus/g'git grep -l 'streamstatus' | xargs sed -i '' -e 's/streamstatus/watermarkstatus/g'git grep -l 'Stream Status' | xargs sed -i '' -e 's/Stream Status/Watermark Status/g'git grep -l 'Stream status' | xargs sed -i '' -e 's/Stream status/Watermark status/g'git grep -l 'stream status' | xargs sed -i '' -e 's/stream status/watermark status/g'Renamed class StreamStatus(Test) -> WatermarkStatus(Test)Renamed package streamstatus -> watermarkstatusReverted Kinesis as it does have a real StreamStatusmvn spotless:apply,4
[FLINK-23767][connectors] Add WatermarkOutput#markActive.The new method allows to quickly disable automatic watermark advancement when a partition becomes active but actually reading the data and extracting watermarks will be delayed.,4
"[FLINK-23767][connectors] Revert going automatically idle when no partitions are (temporarily) available.This is in-line with the refined definition where only user controlled settings should turn a source instance idle. For example, previously a Kinesis source with finished shard would go idle without a way for the user to avoid it causing potential late records when a new shard is assigned to that particular reader instance.",1
"[FLINK-12141] [API/Type Serialization System] Allow @TypeInfo annotation on POJO field declarations (#8344)- build on existing code, extend checks, tests, and docsCo-authored-by: yangfei5 <yangfei5@xiaomi.com>Co-authored-by: Nico Kruber <nico@ververica.com>",2
[FLINK-21290][table-planner] Support project push down for window TVFThis closes #16689,1
"[FLINK-23812][rocksdb] support configuring RocksDB logging (#16848)This allows further tuning RocksDB's info logger with the following three new parameters:- `state.backend.rocksdb.log.max-file-size` sets the max info log file size- `state.backend.rocksdb.log.file-num` configures the number of info log files to keep- `state.backend.rocksdb.log.dir` sets the directory of the info log files, e.g. to put these logs onto a (separate) volume that may not be local and is retained after container shutdown for debugging purposes",0
[FLINK-20731] Introduce new pulsar source connector for flink.,2
"[FLINK-23629][tests] Remove redundant file-async and mem-async test runs from EventTimeWindowCheckpointingITCaseBecause all snapshots are async, the MEM and MEM_ASYNC, as well as FILE and FILE_ASYNC are now the same.This removes unneccessary cases to save testing time.",3
[FLINK-23630][tests] Make EventTimeWindowCheckpointingITCase run on Windows.This fixes the creation of Paths to be properly platform independent.,1
[FLINK-23710][connectors/kafka] Move FLIP-143 KafkaSink to org.apache.kafka.connector.kafka.sink,4
[FLINK-23710][connectors/kafka] Deprecate FlinkKafkaProducer,2
[FLINK-23765][python] Fix the NPE in Python UDTFThis closes #16843.,0
[FLINK-23649][rocksdb] Add FRocksDB packages to parent-first classloading patterns,5
[FLINK-23789][rocksdb] Remove unnecessary setTotalOrderForSeek for Rocks iteratorThis fix #16834.,0
[FLINK-23680][streaming] Wait until all expected threads would be triggered in testOpenCloseAndTimestamps (#16797),3
"[FLINK-13092][docs-zh] Translate ""kubernetes.md"" page into ChineseThis closes #16780",1
[FLINK-23420][table-runtime] LinkedListSerializer now checks for null elements in the listThis closes #16699,2
[FLINK-23289][table-common] Add null check in BinarySection's constructor and pointTo methodThis closes #16754,1
[FLINK-23198][docs] Fix the demo of ConfigurableRocksDBOptionsFactorythis fix #16371.,0
[hotfix][runtime][checkpoint] Remove unused methods,1
[FLINK-23759][runtime][checkpoint] Ignore the restored checkpoints when reporting latest completed id with abortion messageThis closes #16822,1
[FLINK-22844][docs][table] Add documentation to introduce ExplainDetails for EXPLAIN sytnax (#16051),2
[FLINK-23734][table] Migrate ParserFactory to Factory,2
[FLINK-23734][table] Migrate PlannerFactory to FactoryThis closes #16788.,2
[FLINK-23111][runtime-web] Fix missing table component's nzFrontPagination inputThis closes #16854.,0
"[FLINK-23330][table-api] Deprecate old fromDataStream, toAppendStream, toRetractStreamThis closes #16855.",5
[FLINK-21926][doc] Expose fine-grained relevant configs to user doc,2
[FLINK-21926][doc] Add docs for fine-grained resource managementThis closes #16561,2
[FLINK-23362][tests] Remove timeouts,4
[FLINK-22545][tests] Fix delayed split assignment in OperatorEventSendingCheckpointITCase,1
[hotfix][state-processor-api] test state reader with modern state backend stack,3
[hotfix][docs] replace references to MemoryStateBackend with HashMapStateBackend,2
[hotfix] support setting additional configuration on WritableSavepoint,5
[FLINK-23728][state-processor-api] State bootstrapping fails on new state backend factory stackThis closes #16849,1
"[FLINK-23844][hotfix] Fix spelling mistakes for ""async"" (#16868)",0
[FLINK-22198][connector/kafka] Redirect KafkaContainer output to log4j and print debug log if test hangsThis closes #16860,3
"[FLINK-23686][connector/kafka] Increase counter ""commitsSucceeded"" per commit instead of per partition",1
[FLINK-23044][docs] Fix typos,2
[hotfix][python] Remove unnecessary output in startup of loopback mode,4
[FLINK-23806][runtime] Avoid StackOverflowException when a large scale job failed to acquire enough slots in timeThis closes #16842.,0
[FLINK-23757][python] Support json_exists and json_valueThis closes #16874.,5
[FLINK-22217][runtime][logging] Add quotes around job name,1
[FLINK-23776][streaming] Fix handling of timestamp-less records in Source metrics.,0
[hotfix][docs] Fix metric types,0
[FLINK-23813][connectors/jdbc] Update delete executor in TableJdbcUpsertOutputFormat... so that it is properly initializated after reconnection,5
"[FLINK-23724][network] Fix the network buffer leak when ResultPartition is released (#16844)* [FLINK-23724][network][refactor] Make TaskCanceler call ResultPartitionWriter#fail instead of ResultPartitionWriter#closeOriginally, the TaskCanceler calls the ResultPartitionWriter#close method to early release input and output buffer pools. However, the the ResultPartitionWriter#close method can also be called by the task thread to release other network resources which may lead to race conditions. This patch makes TaskCanceler call ResultPartitionWriter#fail instead of ResultPartitionWriter#close and close the output buffer pool in ResultPartitionWriter#fail which avoids the potential race conditions.This closes #16844.* [FLINK-23724][network] Fix the network buffer leak when ResultPartition is releasedThis patch fixes the network buffer leak issue by closing all BufferBuilders in the BufferWritingResultPartition#close method.This closes #16844.",0
[hotfix][checkpoint] Extract CheckpointPlan to be an interface,4
[hotfix][checkpoint] Refactor PendingCheckpoint to delegate fulfill states to the CheckpointPlan,4
[FLINK-23512][checkpoint] Store whether a subtask is finished in the checkpoint,5
[FLINK-23512][runtime][checkpoint] Check illegal modification when restoring from checkpoint with partly finished stateThis closes #16655,5
[hotfix][checkpoint] Add flag to skip the illegal jobgraph check if not restore on startup,1
[FLINK-21867][webui] Expose concurrent exceptions,2
[hotfix][docs] Update IDE Setup guideThis closes #16892.,1
"[FLINK-23841][doc]Modify incorrect English statements for page ""execution_configuration""This closes #16866.",5
[FLINK-23528][kinesis] Do not interrupt main thread during cancellation.This commit instead uses a future for a soft wakeup during cancellation.,1
[hotfix][metrics] Allow to mock OperatioIOMetricGroup in SinkWriterMetricGroup,1
[FLINK-23838][connectors/kafka] Implement FLIP-33 metrics for KafkaSinkThis PR adds the FLIP-33 metrics numBytesOut and currentSendTime to theFLIP-143 KafkaWriter.,1
[FLINK-23430][runtime][checkpoint] Allows taking snapshots for operator coordinators which all corresponding tasks finished,5
"[FLINK-23866][connectors/kafka] Statically assign partitions when reading transaction log topicBefore this PR we simply used KafkaConsumer#subcribe(topic) to read fromthe transaction log topic. Unfortunately, this has the downside that notall partitions are immediately assigned to the consumer. This couldcause an IllegalStateException when trying to access the latest offsetof a not yet assigned partition.Now the partitions are fetched once and the consumer is assigned to allof them immediately.",1
[hotfix][testutil] Fix inconsistent condition checking result in waitUntil,0
[hotfix][testutil] Return Optional in MetricListener getters,1
[FLINK-23773][connector/kafka] Report numBytesIn and pendingRecords in KafkaSource,2
[FLINK-23640][connectors/kafka] Add KafkaRecordSerializationSchemaBuilder to cover common serialization scenarios,1
[FLINK-23172][docs] Fix broken links to Task Failure Recovery page on Configuration pageThis closes #16724.,1
"[FLINK-23903][tests] Harden ZooKeeperLeaderRetrievalConnectionHandlingTest.testSuspendedConnectionDoesNotClearLeaderInformationIfClearanceOnLostConnectionThe problem was that the test restarted the ZooKeeper TestingServer. Due to this, it was possiblethat the ZooKeeperLeaderRetrievalDriver could reconnect to the Zk server. In this case, the driverresends the connection information which makes the test fail because it expects that no leader updateswill be sent. This commit fixes the problem by stopping the TestingServer instead of restarting it. Thatway, it is no longer possible that the driver can reconnect.This closes #16912.",3
[hotfix] Correct ZooKeeperLeaderElectionDriver.toString implementationThis commit corrects the ZooKeeperLeaderElectionDriver.toString implementation to properlylist the leaderLatchPath and the connectionInformationPath.,5
[hotfix][tests] Let ElasticSearch6DynamicSink tests extend TestLogger,3
[FLINK-23894][akka] Disable warning from RemoteActorRefProvider,1
[FLINK-23898][akka] Fix log level mappingWARN -> WARNINGTRACE -> DEBUG,0
[FLINK-23868][Client] JobExecutionResult printed event if suppressSysout is enabledThis closes #16891 .,0
[FLINK-23871][Runtime/Coordination] Dispatcher should handle finishing job exception when recoverThis closes #16894.,5
[FLINK-23893][docs] Add limitation of fine grained resource managementDocument that the slot allocation result might not be optimal.,2
[FLINK-23097][tests] Harden test_queryable_state_restart_tm.shThis commit hardens the test_queryable_state_restart_tm.sh e2e test by only writing thecount value of state entries on notifyCheckpointComplete. Before we have written out uncommittedinformation out that led to test failures.This closes #16910.,0
[FLINK-21538][tests] Set default parallelism to 4 for Elasticsearch6DynamicSinkITCase.testWritingDocumentsThis commit sets the default parallelism of Elasticsearch6DynamicSinkITCase.testWritingDocuments to 4 in orderto reduce the load for our CI infrastructure.This closes #16918.,5
[hotfix] Let Elasticsearch7DynamicSink* test cases extend from TestLogger,3
[FLINK-22333][tests] Harden Elasticsearch7DynamicSinkITCase.testWritingDocuments by setting parallelism to 4This commit hardens the Elasticsearch7DynamicSinkITCase.testWritingDocuments tests by settings its parallelismto 4. Otherwise the test is run with as many CPUs are available on the machine. This can slow down the teston our CI infrastructure.This closes #16924.,5
[FLINK-23910][streaming] Correct exception message,2
[FLINK-23658][metrics][jmx] Cleanup code,4
[hotfix][tests] Assert job not terminated while waiting for tasks running,1
"[FLINK-23811][tests] Handle finished subtasks in CommonTestUtils.waitForAllTaskRunningCommonTestUtils.waitForAllTaskRunning returns when all the subtasks are running ANDthe job is running and not finished. However, with FLIP-147, subtasks may finish andthe job will still be running. So the method won't return and instead timeout.This commit adds a flag to indicate whether to fail or proceedwhen a finished sub-task is encountered.",5
[FLINK-23172][docs] Fix broken links,2
[hotfix][runtime] Remove the lastResourceRequirementsCheck in FineGrainedSlotManager,1
[FLINK-23889][runtime] Cleanup unnecessary logging from FineGrainedSlotManagerThis closes #16934,2
[FLINK-23929][python] Operator with multiple outputs should not be chained with one of the outputsThis closes #16948.,1
[FLINK-23753][python][docs] Add documentation about Python operator chaining,5
[hotfix][python] Ignore the meaningless exception in PythonEnvUtils.getLibFiles,2
[FLINK-23809][checkpoint] Respect the finished flag when extracting operator states due to skip in-flight dataThis closes #16913.,5
[FLINK-22221][runtime][logging] Clarify purpose of spill directories,2
[FLINK-23840][runtime][logging] Clarify logging around CheckpointStorage,2
[FLINK-23931][python] Improve the exception message shown in PythonDriverThis closes #16954.,1
"[FLINK-23906][tests] Increase the default akka.ask.timeout for the MiniCluster to 5 minutesThis commit sets the akka.ask.timeout, if not explicitly configured, to 5 minutes when usingthe MiniCluster. The idea behind this change is to harden all our tests that rely on the MiniClusterand run into TimeoutExceptions on our slow CI infrastructure.This closes #16921.",5
[FLINK-22932][tests] Harden RocksDBStateBackendWindowITCase by using RpcUtils.INF_TIMEOUT for MiniCluster RPC timeoutThis commit sets the default rpc timeout for the MiniCluster to RpcUtils.INF_TIMEOUT. This should be ok sincein a local execution the communication between the different components should be reliable.This closes #16914.,5
[FLINK-23940][python][docs] Improve the documentation about how to use logging in PyFlink jobsThis closes #16961.,2
[hotfix][python][docs] Update the examples to use latest API,3
"[FLINK-23936][python] Disable cleanup the Python UDFs which are inactive for a few minutesThis would avoid reinitializing the Python UDFs which usually is a heavy operationin scenarios such as machine learning, e.g., loading a big ML modelThis closes #16958.",5
[hotfix] Add missing import AkkaOptions to MiniClusterConfiguration,5
[FLINK-22791][docs] Documentation for HybridSource,2
"[FLINK-20461][tests] Check replication factor before asking for JobResultThis commit hardens the YARNFileReplicationITCase by checking the replication factor beforeasking for the JobResult. If done in the reverse order, then it can happen that the Flink applicationhas already terminated before doing the file replication check because the per-job mode has alreadydelivered the JobResult.This closes #16917.",1
[FLINK-23909][connector-jdbc][scala-shell][yarn] Remove redundant variables and improve some style format in coding.This closes #16931.,1
[FLINK-23770][runtime][checkpoint] Retrieve the state with both uidHash and generated ID on checking finished state consistency This closes #16825.,5
[hotfix] Extend set of GitHub repository labels,1
[FLINK-22198][connector/kafka] Disable log retention on Kafka broker in KafkaTableTestBase (#16897),3
[FLINK-23556][tests] Make SQLClientSchemaRegistryITCase more stable (#16952),1
[FLINK-16769][table] Use new type inference in Table.flatMap()This closes #16850.,5
[FLINK-23116][docs][table] Minor documentation fixes & improvementsThis closes #16863.,1
[hotfix] Use ExceptionUtils.firstOrSuppressed in JobManagerSharedServices,1
[hotfix][table-common] Fix minor issues in Schema class,0
[hotfix][table-common] Provide Schema.derived() for convenience,1
[FLINK-23920][table-common] Keep primary key when inferring schema with SchemaTranslatorThis closes #16944.,5
[FLINK-23755][table] Modify the default value of table.dynamic-table-options.enabled to trueThis closes #16887,0
"[FLINK-23908][runtime] Hint user about possibly non-deterministic shuffle key, when attemting to access out-of-the-bounds state key group.This closes #16930.",5
[FLINK-23845][docs] Improve PushGatewayReporter config:deleteOnShutdown descriptionThis closes #16823.,5
[FLINK-23923][python] Log the environment variables and command when starting Python processThis closes #16965.,2
[hotfix][docs] Fix typo in CLI docs,2
[FLINK-23948][python][doc] Fix the priority description of the python client executableThis closes #16975.,0
[FLINK-22710][formats] Explicitly set the bucket assigner to avoid writing into two buckets in the testsThis closes #16950.,3
[FLINK-23911][table-common] Emphasize that #applyReadableMetadata must be idempotent,5
[FLINK-23911][table-planner] Make SupportsReadingMetadata visible in the plan digests,5
"[FLINK-23911][table-planner] Apply metadata spec even if no metadata were usedInitially a table source is instantiated and #applyReadableMetadata iscalled with all metadata declared in the table's schema. During theprojection pushdown we copy the table source and call #applyReadableMetadatawith only those metadata that are actually used, allowing the source toonly produce metadata which are actually required.If we skip this step if no metadata columns are used, the source continuesto believe that all (declared) metadata are required. This producesunnecessary work.This closes #16956.",1
[hotfix][docs] Remove list of supported JDBC driversJDBC DataStream sink only relies on JDBC standard(as opposed to Table API which lists dialectsexplicitly).,5
[FLINK-23876][docs] Add JDBC XA DataSource examples,5
[FLINK-23776][docs] Clarify JDBC XA sink usage,5
[hotfix] How to build documentation using Hugo Docker image.Co-authored-by: Daisy T <infoverload@users.noreply.github.com>This closes #16970,5
[FLINK-23941][python][docs] Add missing API in PyDocsThis closes #16976.,2
[hotfix][python][docs] Add state API in PyDocs,2
[FLINK-23938][checkpoint] Do not resume channels if the barrier is received via RPC This closes #16977.,2
[FLINK-23984][python][tests] Temporary disable the PyFlink end to end tests due to Python 3.7 was removed from debian,4
[FLINK-13973][runtime][checkpoint] Fix the state assignments if uidHash is setThis closes #16836.,1
[FLINK-23965][e2e] Store logs under FLINK_DIR/logThis commit reverts the change that we store the logs under FLINK_DIR/logs because this canmake the e2e tests fail if the directory does not exist. Now we store the logs under FLINK_DIR/logThis closes #16981.,2
[hotfix][e2e] Only retrieve allocated ports if no sudo password is requiredThis commit executes the allocated port retrieval only if no password is required for sudo.This makes it easier to run e2e tests locally.,3
[FLINK-23954][tests] Add more logging to test_queryable_state_restart_tm.sh for debugging purposes,0
[FLINK-23954][e2e] Add debug logging to KvStateSerializerThis closes #16986.,2
[FLINK-23915][table] Fix catalog and primary key resolution of temporary tablesThis closes #16960.,2
[FLINK-23818][python][docs] Add documentation about tgz files for python archivesThis closes #16993.,2
[FLINK-22702][tests] Add test data supplier which provide null timestamp field to kafka connector tests,3
[hotfix][tests] Don't test emit from Operator.close()The contract was refined in FLINK-22972 (FLIP-147).,2
[hotfix][runtime] Extract Task.runWithSystemExitMonitoring to simplify subsequent changes,4
[hotfix][runtime] Prevent double cancelTask() calls,0
[FLINK-23862][runtime] Cleanup StreamTask if cancelled after restore before invoke,4
"[FLINK-23862][runtime] Extract interfaces from AbstractInvokableThe previous commits introduced a contractbetween Task and StreamTask about cleaning up resources.To make this contract more explicit,the relevant methods (cleanUp, invoke, restore, plus related)are moved to a separate interface TaskInvokable.Furthermore, to allow Task to explicitly reference the new interfacecheckpointing and coordination interfaces are extracted.The requirement to extend AbstractInvokable is removed from its javadoc.",2
[FLINK-23862][runtime] Replace usages of AbstractInvokable with interfaceA follow-up step after introduction of task interfaces to:- accept TaskInvokable in place of AbstractInvokable- make StreamTask implement the interfaces directly,1
[FLINK-23877][connector/pulsar] Provide an embedded pulsar server for testing.,3
"[FLINK-23877][connector/pulsar] Drop the ConfigurationDataCustomizer, use ClientBuilder and PulsarAdminBuilder for creating instance.",1
"[FLINK-23877][connector/pulsar] Change pulsar config option's type, drop PulsarJsonUtils, make it strong type support.",1
[FLINK-23877][connector/pulsar] Change the config setter in pulsar source builder. Drop Properties. Remove useless config options.,5
"[FLINK-23877][connector/pulsar] Since we have use the StartCursor, it's no need to expose the resetIncludeHead option for users.",1
"[FLINK-23877][connector/pulsar] Enrich the config options' description, make sure all the options have a detailed description.",1
"[FLINK-18080][docs-zh] Translate ""security-kerberos"" page into Chinese (#16787)",2
[FLINK-23994][python] Handle properly for null values in ArrayDataSerializer and MapDataSerializerThis closes #16998.,5
[FLINK-23884][checkpoint] Fix the concurrent problem between triggering savepoint with drain and task finishingThis closes #16905.,5
[FLINK-23808][checkpoint] Bypass operators when advanceToEndOfEventTime for both legacy and new source tasksThis closes #16861.,1
[FLINK-23800][rocksdb] Expose live-sst-files-size to RocksDB native metrics,5
[hotfix][runtime] Invert MailboxProcessor#isDefaultUnactionAvailable to MailboxProcessor#isDefaultActionAvailable,0
[FLINK-24006][tests] Stop mailbox processor before asserting the idleness when new mails arriveThis commits ensure that the MailboxExecutorImplTest#testIsIdle actuallyensure the wanted behaviour of FLINK-19109 that after the mailboxprocessor is stopped it is still possible to consume control messages(not idle).,2
[FLINK-23794][tests] Fix InMemoryReporter instantiation by associating each reporter with a unique id that is used to retrieve it.,1
"[FLINK-23794][tests] Remove InMemoryReporter from MiniClusterResource.Tests that need InMemoryReporter will register it themselves in the MiniClusterResource.The life-cycle of the InMemoryReporter is now bound to the minicluster (as any other reporter). Thus, if a tests need isolation, a new minicluster should be spawned just for this case.",5
[FLINK-24013][misc] Add IssueNavigationLink for IDEA git logThis can make IDEA support hyperlink on JIRA Ticket and GitHub PR on Git pluginThis closes #17008,2
[FLINK-23998][legal] Include flink-dist in NoticeFileChecker,2
"Revert ""[FLINK-23984][python][tests] Temporary disable the PyFlink end to end tests due to Python 3.7 was removed from debian""This reverts commit 3555741a12ba9fb65e8db9f731a131ab39d1cfe8",5
[FLINK-23984][python][tests] Update test_kubernetes_pyflink_application to use conda to install PythonThis closes #17014.,1
"[FLINK-24015] Log failure cause of failed jobs on the DispatcherIn order to avoid that we don't log failure causes of failed jobs (e.g. initialization errors),this commit lets the Dispatcher log the failure cause when archiving the job. This will ensurethat there will be always a record of what happened in the logs of the Dispatcher.This closes #17012.",2
[FLINK-23945][docs] Correct s3 URI in K8s ha documentationThis closes #17016.,2
[FLINK-23561][yarn]Detail the container completed messageUpdate flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManagerDriver.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>Update flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManagerDriver.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>Update flink-yarn/src/test/java/org/apache/flink/yarn/YarnResourceManagerDriverTest.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>[FLINK-23561][yarn]Detail the container completed message[FLINK-23561][yarn]Detail the container completed messageUpdate flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManagerDriver.javaCo-authored-by: Till Rohrmann <till.rohrmann@gmail.com>[FLINK-23561][tests] Fix word spell error[FLINK-23561][yarn] Detail the container completed message,2
[FLINK-23561][tests] Simplify YarnResourceManagerDriverTest.testingGetContainerCompletedCause,3
[FLINK-23561][tests] Extend YarnResourceManagerDriverTest.testOnContainerCompleted to cover different ContainerStatusThis closes #16847.,3
[FLINK-23967][tests] Remove Scala references in OneInputStreamTaskTest,3
"[FLINK-23776][datastream] Optimize source metric calculationThere is a performance regression of 15% on new sources in InputBenchmark. A couple of issues are fixed with this commit:- MetricTrackingOutput in SourceOperator adds 1 virtual calls per record. This accounts for ~5% of the regression. The solution is to move the functionality inside WatermarkToDataOutput.- Lazy registration of CURRENT_EMIT_EVENT_TIME_LAG gauge. This adds ~2% overhead as it checks for each record whether the metric has been registered already. The solution is to always add the metric and just return some UNDEFINED value when there is no record.- Check of NO_TIMESTAMP. This adds ~3% overhead as it's a long comparison for each record. The solution is to lazily check the timestamp in the gauge. This solution depends on the prior solution.- Fusion of recordEmitted() and eventTimeEmitted(). This removes 2% overhead and is possible after the previous optimizations.A bit of regression may remain after this commit. Future work may further improve the situation. However, it may also be the price to be paid for the additional metrics. In real sources with I/O, the remaining regression will not be as noticeable. For example, the micro benchmarks imply that the new source is 2x faster than the old sources but we do not see any difference in actual sources.",1
Update version to 1.15-SNAPSHOT,5
[FLINK-24036][ci] Fix SSL download link,2
[hotfix][tests] Disabling flaky source testing + PulsarSourceITCase cases.,3
[FLINK-23968][tests] Remove unused code from TestBaseUtils,3
[FLINK-24010][connector/common] HybridSourceReader/Enumerator delegate checkpoint notifications,2
[FLINK-23055][docs][table] Add documentation for window tvf offset. (#17015),1
"[FLINK-23899][docs-zh] Translate the ""Elastic Scaling"" page into Chinese (#16928)",2
[FLINK-23917][table-planner] Project metadata before push-down even if projection push-down is not supportedThis closes #16984.,1
[FLINK-24026][misc] Fix FLIP link can't be recognized correctly by IDEA (#17021),2
[hotfix] Replace deprecated Assert.assertThat,3
[FLINK-23833][coordination] Add ConsumedPartitionGroup#getIntermediateDataSetID,5
[FLINK-23833][coordination] Make PartitionReleaseStrategy#vertexFinished return a list of releasable ConsumedPartitionGroups,5
[FLINK-23833][coordination] Rename PartitionReleaseStrategy to PartitionGroupReleaseStrategy,2
[FLINK-23833][coordination] Individually clean up the cache for ShuffleDescriptorsThis closes #16856.,4
[FLINK-23833][coordination] Rename IntermediateResult#notifyPartitionChanged to IntermediateResult#clearCacheForConsumedPartitionGroup,4
[FLINK-9925][tests] Harden ClientTest by making handler shareableThis commit makes the handler that is used for the testConcurrentQueries shareable sothat Netty won't fail if another pipeline is created.,1
[FLINK-9925] Rework Client to encapsulate concurrency of single connectionThis commit replaces the Client.pendingConnections and .establishedConnectionswith a single data structure connections of type ServerConnection. The logic ofa pending and established conneciton is moved into this class. This allows to getrid of concurrent access to the Client data structures.This closes #16915.,5
[hotfix] Print the test parameters for UnalignedCheckpointTestBase to help debugging when the case is stuckThis closes #17009.,0
"[FLINK-23466][network] Fix the bug that buffer listeners may not be notified when recycling buffersPreviously, the buffer listener will be removed from the listener queue when notified and then it will be added to the listener queue again if it needs more buffers. However, if some buffers are recycled meanwhile, the buffer listener will not be notified of the available buffers. For example:1. Thread 1 calls LocalBufferPool#recycle().2. Thread 1 reaches LocalBufferPool#fireBufferAvailableNotification() and listener.notifyBufferAvailable() is invoked, but Thread 1 sleeps before acquiring the lock to registeredListeners.add(listener).3. Thread 2 is being woken up as a result of notifyBufferAvailable() call. It takes the buffer, but it needs more buffers.4. Other threads, return all buffers, including this one that has been recycled. None are taken. Are all in the LocalBufferPool.5. Thread 1 wakes up, and continues fireBufferAvailableNotification() invocation.6. Thread 1 re-adds listener that's waiting for more buffer registeredListeners.add(listener).7. Thread 1 exits loop LocalBufferPool#recycle(MemorySegment, int) inside, as the original memory segment has been used.At the end we have a state where all buffers are in the LocalBufferPool, so no new recycle() calls will happen, but there is still one listener waiting for a buffer (despite buffers being available).This change fixes the issue by letting the buffer listener request multiple buffers one after another without having to enqueue BufferListener to the registeredListener queue.This closes #17009.",0
[hotfix][refactor] Remove BufferListener#NotificationResult to simplify the codeThis closes #17009.,4
[FLINK-24027][filesystems] Remove excessive dependencies from NOTICE files,2
"Revert ""[FLINK-23954][e2e] Add debug logging to KvStateSerializer""This reverts commit 6a7b5e8079cfced519ac5e106f0fb7277131f8bd.",4
"[FLINK-23954][tests] Fix e2e test test_queryable_state_restart_tm.shThe problem was that we output the number of state entries at the time when the checkpointis confirmed. However, at this point in time we might have already added more elements tothe map. Hence, we risk reporting more elements than are actually contained in the checkpoint.The solution is to remember what the element count was when creating the checkpoint.This closes #17027.",1
[FLINK-23947] Improve logging of granting/revoking leadership in DefaultDispatcherRunnerThis commit logs on info level when the DefaultDispatcherRunner was granted or revoked its leadership.This closes #17033.,1
[FLINK-23962][table-planner] Fix updateKind trait propagating problem in changelog inference for DAG optimizingThis closes #16979,2
[FLINK-23897][hive][doc] Fix obsolete doc about creating hive table with flink dialectThis closes #16907,2
[FLINK-23857][table-runtime][hive] Insert overwrite should clear existing data when source is emptyThis closes #16936,5
[FLINK-24033][table-planner] Propagate unique keys for fromChangelogStreamThis closes #17048.,4
[FLINK-24056][ha] Remove unused ZooKeeperUtilityFactory,1
[FLINK-24049][python] Handle properly for field types need conversion in TupleTypeInfoThis closes #17046.,5
[FLINK-23519][metrics] Expose state name as varibale if enable state latency tracking,0
[FLINK-23287][docs][table] Add documentation for Window Join in SQL (#16997),2
"[FLINK-13636][docs-zh] Translate the ""Flink DataStream API Programming Guide"" page into Chinese (#16852)",5
"[FLINK-24035][network] Guarantee that the LocalBufferPool is initialized with one bufferPreviously, The buffer listeners are not notified when the the local buffer pool receives available notification from the global pool. This may cause potential deadlock issue:1. A LocalBufferPool is created but there is no available buffers in the global NetworkBufferPool.2. The LocalBufferPool registers an available buffer listener to the global NetworkBufferPool.3. The BufferManager requests buffers from the LocalBufferPool but no buffer is available. As a result, it registers an available buffer listener to the LocalBufferPool.4. A buffer is recycled to the global NetworkBufferPool and the LocalBufferPool is notified about the available buffer.5. The LocalBufferPool requests the available buffer from the global NetworkBufferPool but the registered available buffer listener of BufferManager is not notified and it can never get a chance to be notified so deadlock occurs.This patch fixes this issue by guaranteeing that the LocalBufferPool is initialized with one buffer. With this piece of guaranteed buffer, the LocalBufferPool will be in the healthy buffer request and recycle loop. Note: We are not fixing this issue by notifying the buffer listeners when the local buffer pool receives available notification from the global pool because of the potential deadlock.",1
[FLINK-24003][python] Fix lookback mode doesn't work when mixing use of Python Table API and Python DataStream APIThis closes #17010.,5
[FLINK-23924][python][examples] Add PyFlink examplesThis closes #17045.,2
[FLINK-23715][parquet] Support for reading fields that do not exist in Parquet filesThis closes #16778,2
[FLINK-24004][table-planner] Introduce TableFactoryHarness,2
[FLINK-23663][table-planner] Push primary key filters through ChangelogNormalizeThis closes #17011.,4
[hotfix][table-planner] Migrate PushProjectIntoTableSourceScanRuleTest to test harness,3
[hotfix][table-common] Improve source and sink provider docs,2
[FLINK-23895][table] Upsert materializer is not inserted for all sink providersThis closes #17060.,1
[FLINK-24051][connectors/kafka] Make groupId optional when constructing a KafkaSourceSetting a groupdId for the KafkaSource is often not necessary andcomplicates the setup for users that do not rely on specificsemantics which are implied by the groupId.,1
[FLINK-23875][io] Add utils to read and write versioned list data,5
[FLINK-23875][connectors/kafka] Snapshot reduceBuffer of ReducingUpsertWriterIn addition to the underlying writer we also have to snapshot the bufferwhich is used to reduce the upsert records. Before this PR it was notdone and it can lead to incorrect results if the pipeline fails whilethe buffer is not empty. In this case on recovery the buffer will startempty and the previously contained records might not be replayed.,0
[FLINK-24055][connectors/kafka] Deprecate FlinkKafkaConsumer,2
[hotfix][docs][metrics] Remove blank lines in code samples,4
[hotfix][docs][metrics] Fix RestAPIDocGenerator javadocs formatting,2
[FLINK-24084][docs] Correct the examples in SQL JOIN docsThis closes #17076,2
"Revert ""[FLINK-23875][connectors/kafka] Snapshot reduceBuffer of ReducingUpsertWriter""This reverts commit 31e5fa196de6d695e062d942e9d952e300439840.In the discussion in FLINK-23875, Jark showed that this commit is a no-op that just adds unnecessary complexity.",1
[FLINK-23351][tests] Harden FileReadingWatermarkITCase by counting watermarks after source operator finishesThis PR changes the semantic of FileReadingWatermarkITCase to wait foran expected number of watermarks after the ContinuousFileReaderOperatorfinishes instead of calculating the expected watermark number with anerror margin. The error margin was not realiable enough and causedinstabilities on different systems.,5
[FLINK-23664][connectors/kafka] Mark KafkaSink as PublicEvolving,2
"[FLINK-23664][connectors/kafka] Make kafka producer properties optional for building a KafkaSinkInitially, the properties were the only place where the bootstrap serverscould be configured. This changed because the builder offers a method toonly set servers without supplying properties.",1
[FLINK-23664][connectors/kafka] Not register Kafka metrics of KafkaSink if register.producer.metrics is false,2
[FLINK-23664][docs] Add docs for KafkaSink,2
[FLINK-24081][table-planner] Fix StreamExecOverAggregate and StreamExecTemporalSort operator didn't support TIMESTAMP_LTZ rowtime (#17074),1
[FLINK-24062][python] Fix the serialization of timer to avoid serializing timer data partiallyThis closes #17065.,5
[FLINK-23468][test] Do not hide original exception if SSL is not available,3
[FLINK-23854][datastream] Expose the restored checkpoint id in ManagedInitializationContext.,5
[FLINK-23854][datastream] Pass checkpoint id to SinkWriter#snapshotState and restoredCheckpointId to Sink#InitContext.,5
"[FLINK-23896][streaming] Implement retrying for failed committables for Sinks.In batch mode and add stop-with-savepoint with drain, the CommitRetryer will wait indefinitively in a close loop to avoid data loss.Otherwise, it will retry every second until all commits succeed.",1
[hotfix][connectors/kafka] Add TestLogger to Kafka tests.,3
[FLINK-23678][tests] Re-enable KafkaSinkITCase and optimize it.,0
"[FLINK-23854][connectors/kafka] Abort transactions on close in KafkaWriter.All transactions that have been opened since last (pre)commit are transient by definition, so cancel them asap.",5
[FLINK-23854][connectors/kafka] Transfer KafkaProducer from writer to committer.,2
[FLINK-23896][connectors/kafka] Retry committing KafkaCommittables on transient failures.,0
[FLINK-23854][connectors/kafka] Add FlinkKafkaInternalProducer#setTransactionalId.This will allow reuse of the producer in the next commit which will also include FlinkKafkaInternalProducerITCase.,2
[FLINK-23854][connectors/kafka] Reliably abort lingering transactions in Kafka.The new approach depends on successively aborting transactions until an unused transaction is ensured. This approach covers all edge cases including failures before first checkpoint and downscaling without checkpoints.,0
[FLINK-23854][kafka/connectors] Adding pooling,1
"[FLINK-24085][docs] Add page title for ""Versioned Tables"" and ""Time Zone"" pagesThis closes #17077",1
[hotfix][docs] Soft-deprecating Streaming File Sink,2
[FLINK-23817][docs] Add metric description to Kafka source.,1
[hotfix][docs] Remove general operator task/operator metrics in Kafka Sink docs.,2
[FLINK-23750][docs][table] Add documentation for Window Top-N after Windowing TVF (#16983),2
"[FLINK-24029][docs] Fix ""dept_id"" typo in SQL ""Getting Started"" pageThis closes #17025",1
[FLINK-24099][docs] Refer to nightlies.apache.org,2
"[FLINK-23971][tests] fix connector testing framework error when compare records in different splitsAdd split index parameter to generate test data, make sure T.equals(object) return false when records come from differernt splits.",1
[FLINK-24087][connector-kafka] Avoid importing Table API classes for DataStream API programsThis closes #17082.,5
[FLINK-23859] Fix typos,2
[hotfix] Fix typos,2
[FLINK-22885][table] Supports 'SHOW COLUMNS' syntax (#16723),1
[FLINK-23797][tests] Wait for all task running before savepoint for all tests in SavepointITCase,3
[hotfix] Fix spotless violations,0
"[FLINK-24035][network][refactor] Move the blocking allocation of one floating buffer logic from the constructor of LocalBufferPool to SingleInputGate#setupChannels()This refactor makes the code cleaner and easier to understand. Besides, for the output side, the blocking allocation of one floating buffer is not needed.This closes #17075.",4
[FLINK-17495][metrics] Add support for configuring additional variables,1
[FLINK-24042][javadoc] Corrected the description of stderr in DataStream java docThis closes #17042 .,2
[FLINK-24097][python] Remove is_streaming_mode checks in StreamTableEnvironmentThis closes #17094.,4
[FLINK-24083][python] Fix Python UDTF to handle properly when the result is strThis closes #17091.,0
[FLINK-24106][docs] Remove notice that pyflink does not support state TTL,1
[FLINK-24005][coordination] Only return fulfilled requirements for reserved slots,1
[FLINK-24058][coordination] Extract TimerService interface,4
[FLINK-24058][coordination] Use ExecutorUtils#gracefulShutdown,1
[FLINK-24058][coordination][tests] Add TestingTimerService,3
"[FLINK-24058][coordination][tests] Harden TaskSlotTableImplTestInstead of checking that the the timeout is not being triggered, instead check that the timeout is being cancelled.",3
[FLINK-24058][tests] Cleanup DefaultTimerServiceTest,3
[FLINK-24058][coordination][tests] Add test for TimerService#isValid,3
[FLINK-24047][tests] Retry if leader election is in progress,1
[FLINK-24054][table-runtime] Let SinkUpsertMaterializer produce +U's when possibleThis closes #17079.,2
[FLINK-22812][hive] Copy hive code and upgrade avro for hive 3.1.2This closes #16037,2
[FLINK-22812][hive] Fix HiveConf initialization bug if hive-site.conf is not availableThis closes #16037,5
[FLINK-22812][hive] Port HIVE-21508This closes #16037,2
[FLINK-22812][hive] address feedback commentsThis closes #16037,5
[hotfix][docs] Use language-specific comment syntax,1
[hotfix][table-api] Expose NOT for Table API,0
[hotfix][table-planner] add test cases for AND and OR,3
[hotfix][table-planner] Ensure that IS JSON never returns NULL,5
[FLINK-16501][table] Support IS JSON predicate in Table APIThis closes #16805.,5
[hotfix][test] Clearly mark old TestHarness classes as deprecatedOld test harness should no longer be used and any new code shouldbe using StreamTaskMailboxTestHarness,3
[FLINK-22002][tests] Let taskmanager.slot.timeout fall back to akka.ask.timeoutThis commit lets taskmanager.slot.timeout fall to akka.ask.timeout so that the MiniClusterwill run by default with a 5 min taskmanager.slot.timeout. This should harden against CIpauses.This closes #16995.,1
"[FLINK-22227][clients] Log submitted job name, id and receiving jobmanager",2
[FLINK-24130][python] Fix RowDataSerializerTest after FLINK-24054This closes #17127.,2
[hotfix] Let PartitionRequestClientFactoryTest extend TestLogger,3
[FLINK-24121][flink-python] There are spelling mistakes in the notes.This closes #17110,2
[hotfix][python] Add missing space to error message,0
[FLINK-24060][Tests]Move ZooKeeperUtilTest to right classThis closes #17063.,3
[FLINK-24105][python] Fix the state ttl does not take effect in PyFlinkThis closes #17115.,2
"[FLINK-23242][docs-zh] Translate the page of ""Handling Application Parameters"" into Chinese (#16949)",2
[FLINK-23907] Use primitive functional interfaces,1
[FLINK-24023][runtime-web] The names of metrics are incomplete (#17117),2
"Revert ""[FLINK-23544][table-planner] Window TVF Supports session window in plan""This reverts commit 34d51002Currently, the session window TVFs syntax is not correct. The syntax mentioned in FLIP is depended on CALCITE-4337. We will re-introduce this feature in FLINK-24024 after CALCITE-4337 is finished.",5
[FLINK-23111][runtime-web] Fix monaco editor async setupThis closes #16980.,1
[FLINK-20427] Remove configuration option to prefer checkpoints over newer savepoints,1
[FLINK-20427] Remove mention of prefer-checkpoints setting from the docsThis closes #17114.,2
[hotfix] Remove ZooKeeperCompletedCheckpointStoreMockitoTest.java (made redundant by DefaultCompletedCheckpointStoreUtilsTest.java),3
[FLINK-24120] Add docs for using environment variable MALLOC_ARENA_MAX to avoid unlimited memory increasingThis closes #17132.,1
[hotfix] Remove CompletionException from failure cause in Execution.deploy,1
"[FLINK-24091][tests] Harden TaskManagerProcessFailureBatchRecoveryITCaseThis commit hardens the TaskManagerProcessFailureBatchRecoveryITCase.testTaskManagerProcessFailure by decreasingthe heartbeat interval and the number of failed heartbeat RPCs. Moreover, it increases the delay between job restartsso that there is enough time for the heartbeat rpc to fail.This closes #17107.",0
[FLINK-23654][runtime] Splitting IO and future threadpools and adding advanced configurations[FLINK-23654] Use fixed thread pool for JobManagerSharedServices.ioExecutor[FLINK-23654] Update keys of JobManagerOptions.JOB_MANAGER_FUTURE_POOL_SIZE and .JOB_MANAGER_IO_POOL_SIZEThe new key name for JobManagerOptions.JOB_MANAGER_FUTURE_POOL_SIZE is jobmanager.future-pool.size andJobManagerOptions.JOB_MANAGER_IO_POOL_SIZE is jobmanager.io-pool.size.This closes #16946.,1
[FLINK-21090] Add tests for stop-with-savepoint and FLIP-147,3
[FLINK-21090] Minor code improvements* Do not extend from the TriFunction* Use non deprecated watermark assigners* Log exceptions in case of a global termination stateThis closes #16773,2
[FLINK-24021][HA]Handle curator framework start error by register UnhandledErrorListener before start zk clientThis closes #17053.,0
[FLINK-23916][python] Add python API to set tolerable checkpoint failure number,0
[FLINK-23916][docs] Update the documentation how to set tolerable checkpoint failure number,0
[FLINK-24064][connector/common] HybridSource restore from savepoint,2
[hotfix][docs] Fix sentence,0
[hotfix][docs] Move 'Running in an IDE' section to prerequisitesWhen going through the tutorial step-by-step you will encounter the error right at the beginning but might not notice this section at the bottom. As most developers are probably using an IDE this also becomes a prerequisite to actually get the tutorial to run.,1
[FLINK-24158][runtime] Remove useless collector in LimitOperatorSigned-off-by: TennyZhuang <zty0826@gmail.com>This closes #17148 .,1
"Revert ""[FLINK-23759][runtime][checkpoint] Ignore the restored checkpoints when reporting latest completed id with abortion message""This reverts commit 45d87361cbb6ab36956ddaa4c142ffa2249d1400.",4
[FLINK-24096][checkpoint] Skip the complete notification for checkpoints before task startupThis closes #17123.,2
[FLINK-24134][python][docs] Update the documentation about how to install PyFlink in dockerThis closes #17154.,2
[FLINK-24090][docs] Added Troubleshooting section with ignoring in-flight data explanation into unaligned checkpoints page,5
[hotfix][connector/common] Expose splitFinishedHook in SplitFetcher for fine-grained testing,3
[FLINK-23773][connector/kafka] Mark empty splits as finished to cleanup states in SplitFetcher,4
[FLINK-24020][web] Aggregate HTTP requests before custom netty handers are getting the dataCloses #17022,5
[refactor][streaming] Improved description of the calculation of the processing time delay,1
[refactor][streaming] Busy waiting in checkScheduledTimestamps replaced by CompletableFuture,4
[FLINK-23960][streaming] checkScheduledTimestamps changed according to semantic of the calculation processing time delay,4
[FLINK-23839][kafka] Improve warnings on InvalidTxnState-/ProducerFencedException,2
[FLINK-24088][streaming] Log FlinkJobNotFoundException in debug instead of warn level in CollectResultFetcher for a cleaner logThis closes #17093,2
[FLINK-23113][runtime-web] Migrate from tslint to eslint and add stylelint for less,1
[FLINK-23113][runtime-web] Apply ESLint and Stylelint fixed to files,2
[FLINK-23114][runtime-web] Fix dependency vulnerabilities,0
[FLINK-23112][runtime-web] Enforce npm run lint in ciThis closes #16902.,1
[FLINK-23912][coordination] Ignore repeated empty requirements declarations,1
[FLINK-23983][tests] Ensure to close and dispose created keyed-statebackend in StateBackendTestBase,3
"[FLINK-24172][docs][table] Fixed missing quote for join examples in ""Table API"" page (#17166)",0
[FLINK-24069][tests] Fail IgnoreInFlightData test when there is not enough data for it for all checkpoints not only the first one,5
[FLINK-24069][tests] Added exponentially increasing checkpoint interval for every next attempt of testIgnoreInFlightDataDuringRecovery,5
[FLINK-23832][docs] Update DataStream API Integration pageThis closes #16871.,1
[hotfix][tests] Parameterize PartiallyFinishedSourcesITCase with failover strategy,0
"[FLINK-24162][tests] Check MAX_WATERMARK per attempt in FLIP-147 testsAdjust DrainingValidator to validate subtask events if:- finished normally, last attempt- finished normally, recovered, finished - both attempts must emit MAX_WATERMARK and end inputSkip if task wasn't finished and the attempt failed (by any subtask).",0
[FLINK-23457][network] Select a desirable buffer size,2
[FLINK-23612][table-runtime] Fix compile exception for ROUND function with some numeric input argumentsThis closes #16731,1
[FLINK-23614][table-planner] The resulting scale of TRUNCATE(DECIMAL) is not correctThis closes #16740,1
[FLINK-24131][tests] Harden leak check in KafkaSinkITCase.,3
"[FLINK-24131][datastream] Ensure that SinkWriter#prepareCommit is not called twice for final commit.With FLIP-147 (final checkpoint) and the respective opt-in option, a sink would invoke prepareCommit twice for the final commit.",5
[FLINK-24131][datastream] Recommit recovered transactions as quickly as possible.,5
[FLINK-24131][datastream] Ensure writer and committer are closed correctly even with Interruptions.,5
[FLINK-24131][connectors/kafka] Ensure kafka writer and producer closed correctly even with Interruptions.,2
[FLINK-24131][runtime] Introduce CheckpointIDCounter#INITIAL_CHECKPOINT_ID.,5
[FLINK-24131][connectors/kafka] Improve debuggability of KafkaWriter.This also aligns the transaction ids with checkpoint ids starting at 1.,0
[FLINK-24131][connectors/kafka] Improve handling of committer errors in KafkaCommitter.,0
[FLINK-24131][connectors/kafka] Improve threading model of KafkaWriter.Removed pending records as it doesn't add anything to KafkaWriter#flush (same post-condition as per JavaDoc) but introduces instabilities because of concurrency.,1
[FLINK-24131][connectors/kafka] Fix KafkaWriter currentSendTime metric.The metric can only be registered once and should simply take the currentProducer to calculate.,0
[FLINK-24151][connectors/kafka] Add concurrent checkpoint test to KafkaSinkITCase.,3
"[FLINK-22971][tests] Bump testcontainers to 1.16.0This version uses http5 as the default transport, which is not affected by the race condition we run into.https://github.com/testcontainers/testcontainers-java/issues/3531",3
[hotfix][table-planner] Convert JSON enums more explicitly,5
[FLINK-16202][table] Support JSON_QUERYThis closes #16858.,5
[hotfix][docs] Update Window TopN SQL example,5
[FLINK-24165][datastream] Fix typo in javadoc of KeyContext classThis closes #17157,2
[FLINK-24181][build][docs] Bump JSoup to 1.14.2,2
[FLINK-23807][connector/testing-framework] Use RestClient to detect TaskManager failure in test environments,3
[FLINK-24126][connector/kafka] Use increment of bytes consumed/produced for updating numBytesIn/Out in Kafka connector,5
[hotfix][yarn-tests] Fixes path definition for local YARN-test working directory artifact collection,1
"[hotfix][yarn-tests] Replaces runtime by timestampThe intend is to improve local debugging matching log events in different logfiles (YARN, Flink) via the timestamp.",2
"[FLINK-23611][yarn-tests] Disables INFO log messages coming from YARN's ResourceLocalizationServiceWe observed regular INFO log messages being produced by ResourceLocalizationService after the test ran into a timeout:```22:51:31,785 [AsyncDispatcher event handler] INFO  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService [] - Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 022:51:32,398 [AsyncDispatcher event handler] INFO  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService [] - Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0```These log messages appeared every 10 minutes which prevented the ci/tools/test_controller.sh's watchdog mechanism tokick in. The watchdog mechanism relies on no output being produced for a given amount of time. This way, thetest_controller script was unable to archive the YARN Flink log.",2
[hotfix] Remove outdated JavaDocs in SourceFunction about deprecated TimeCharacteristic,1
[hotfix] Deduplicate JavaDocs in SourceFunction,1
[hotfix][core] Make the example for checkpointed SourceFunction a bit less strange.,1
[FLINK-23527][core] Clarify semantics of SourceFunction.cancel() with respect to thread interruptions.,1
[FLINK-24137][python] Add more logs during starting up Python worker,1
[FLINK-24137][python][tests] Upload logs for PyFlink tests,3
[FLINK-24115][docs] Fix outdated SQL Temporal Join example (#17121),5
[FLINK-24163][test] Increase the checkpoint timeout for PartiallyFinishedSourcesITCaseThis closes #17170.,5
[FLINK-24148][state] Add bloom filter option in RocksDBConfiguredOptionsthis fix #17142.,0
[FLINK-23949][checkpoint] Fix first incremental checkpoint after a savepoint degenerate into a full checkpointthis fix #16969.Co-authored-by: wangfeifan <zoltar9264@163.com>Co-authored-by: jinghaihang <jinghaihang_hrbeu@163.com>,0
[FLINK-24183][legal] Add aws-java-sdk-s3 to source NOTICE,1
[FLINK-24170][build] Use maven-directory-plugin:directory-of goal,1
[FLINK-23961][kubernetes] Hint user about missing 'kubernetes.cluster-id' config option,5
[FLINK-24203][runtime][tests] Bind to port 0,3
[FLINK-24034] Upgrade apache commons dependencies,2
"[HOTFIX][docs] fix sentence to make the description more clear by adding one word ""much"" and get rid of ""to be feasible"".",1
[FLINK-23848][connector/pulsar] Fix the consumer not found.,0
[FLINK-23848][connector/pulsar] Make sure the topic would only be sought once.,1
[FLINK-22889][tests] Increase timeouts in JdbcExactlyOnceSinkE2eTest...to tolerate occasional long XA PREPARE executions in MySQL.,5
[FLINK-24068][checkpoint] Also check for alignment start when received EndOfPartition from pending channelsThis closes #17131.,2
[FLINK-24160][tests] Use FS checkpoint storage in PartiallyFinishedSourcesITCaseThis closes #17165.,5
"[FLINK-24041][connectors] First draft of API, Add DynamoDB sink to verify API, Add Firehose sink, Refactor to use FLIP-143: Unified Sink API, Increase robustness for flush, Add license header, Update JavaDoc comments",2
"[FLINK-24041][connectors] Added unit and integration tests for the generic sink implementation. Corrected an inconsistency that led to prepareCommit() not fully flushing the entire contents of the buffer at checkpoint time, removed catching of RuntimeExceptions in concrete implementations, added @PublicEvolving to classes, rearranged cosmetics of classes, corrected spelling errors, changed tests to reflect removal of RuntimeException, added checks on the parameters passed to AsyncSinkWriter at construction time, simplified batch creation part of Sink, amended tests, and test harness now guarantees ordering, added Javadoc for AsyncSinkWriter, removed redundant flushIfFull, removed duplicate assertion, removed redundant overriding in SinkInitContext, refactored static class into anonymous function, cleaned up imports, all test methods now begin with ""test"", refactored duplication in tests, Fixed spelling error, removed ResultFuture and all references to this construct. Now using Consumer<T> to accept requeue candidates",5
"[FLINK-24195][docs-zh] Translate ""DESCRIBE Statements"" page of ""SQL"" into Chinese (#17192)",2
"[FLINK-24196][docs-zh] Translate ""EXPLAIN Statements"" page of ""SQL"" into Chinese (#17195)",2
[FLINK-24059][Connectors/Common][test] Allow SourceReaderTestBase.NUM_SPLITS to be overridden (#17064),3
"Revert ""[FLINK-24041][connectors] Added unit and integration tests for the generic sink implementation. Corrected an inconsistency that led to prepareCommit() not fully flushing the entire contents of the buffer at checkpoint time, removed catching of RuntimeExceptions in concrete implementations, added @PublicEvolving to classes, rearranged cosmetics of classes, corrected spelling errors, changed tests to reflect removal of RuntimeException, added checks on the parameters passed to AsyncSinkWriter at construction time, simplified batch creation part of Sink, amended tests, and test harness now guarantees ordering, added Javadoc for AsyncSinkWriter, removed redundant flushIfFull, removed duplicate assertion, removed redundant overriding in SinkInitContext, refactored static class into anonymous function, cleaned up imports, all test methods now begin with ""test"", refactored duplication in tests, Fixed spelling error, removed ResultFuture and all references to this construct. Now using Consumer<T> to accept requeue candidates""This reverts commit 271a346920f4ff873ef21957e97332fcf1af14be.",4
"Revert ""[FLINK-24041][connectors] First draft of API, Add DynamoDB sink to verify API, Add Firehose sink, Refactor to use FLIP-143: Unified Sink API, Increase robustness for flush, Add license header, Update JavaDoc comments""This reverts commit 2e33a40cde17aaa8bfc171f3ea28d2961733fb9d.",4
[FLINK-24193][tests] Add ClassLoaderExtension,1
[FLINK-24193][rest][tests] Migrate tests to ClassLoaderExtension,3
[hotfix][rest][tests] CleanupThis reverts commit 69de4b66b27f4b83e3b5fff59dfc793209c72640.,4
[FLINK-24155][documentation] Sync Chinese version of documentation to configure CheckpointFailureManager (#17173),0
[FLINK-24031] Extend vcs.xml,5
[FLINK-23462] [docs-zh] Translate the abfs documentation to chinese,2
[FLINK-24199][python] Expose StreamExecutionEnvironment#configure in Python APIThis closes #17206.,5
[FLINK-24137][python] Fix the cases that Python boot process exits before Python SDK harness connects to the Java Operator in lookback modeThis closes #17214.,1
[FLINK-24137][python] Fix the issue that tests planned to run in process mode was actually executed in loopback modeThis closes #17214.,1
[FLINK-24213][qs] Introduce factory for established connection,2
[FLINK-24213][qs] Use single lock in ServerConnection,1
"[FLINK-23836][doc-zh] Translate ""Execution Configuration"" page into Chinese (#16865)",5
"[FLINK-24041][connectors] First draft of API, uses FLIP-143: Unified Sink API, Increase robustness for flush, Add license header, Update JavaDoc comments, added unit and integration tests for the generic sink implementation. Corrected an inconsistency that led to prepareCommit() not fully flushing the entire contents of the buffer at checkpoint time, removed catching of RuntimeExceptions in concrete implementations, added @PublicEvolving to classes, rearranged cosmetics of classes, corrected spelling errors, changed tests to reflect removal of RuntimeException, added checks on the parameters passed to AsyncSinkWriter at construction time, simplified batch creation part of Sink, amended tests, and test harness now guarantees ordering, added Javadoc for AsyncSinkWriter, removed redundant flushIfFull, removed duplicate assertion, removed redundant overriding in SinkInitContext, refactored static class into anonymous function, cleaned up imports, all test methods now begin with ""test"", refactored duplication in tests, Fixed spelling error, removed ResultFuture and all references to this construct, Now using Consumer<T> to accept requeue candidates",5
[FLINK-22357][core] Upgrades API stability of unified source API to @Public (= stable).,2
[hotfix][core] Improve/fix JavaDocs in SplitEnumeratorContext class.,2
[FLINK-22358][connector base] Add stability annotations to connector base and iterator sources.,1
[hotfix][connectors] Deduplicate config default in FutureCompletingBlockingQueue.,5
[FLINK-23345][python] Limits the version requests to 2.26.0 or aboveThis closes #17219.,2
[FLINK-23944][connector/pulsar] Enable PulsarSourceITCase.testTaskManagerFailure after test framework was fixed.This closes #17201,0
[FLINK-22603][table-planner] The digest can be produced by SourceAbilitySpecThis closes #17118,2
[FLINK-24123][python] Optimize the python operator instances of the same job to share one python environment resources in the same jvmThis closes #17180.,1
[FLINK-24161] Fix interplay of stop-with-savepoint w/o drain with final checkpointsThis closes #17200,0
"[FLINK-23864][docs] Add flink-connector-pulsar module to flink-docs, auto generate the config document.",2
[FLINK-23864][connector/pulsar] Release Pulsar Message if user enable poolMessage option.,0
[FLINK-23864][connector/pulsar] Remove PULSAR_AUTO_UPDATE_PARTITIONS option.,5
[FLINK-23864][docs] Add pulsar connector document (Chinese & English).,2
[hotfix] Improve language for error message when checkpoint is declined due to some tasks being finished already.,5
[FLINK-24065][connector] Upgrade the state of TwoPhaseCommitSink to support empty transaction after finished,5
[FLINK-18880][python] Respect configurations defined in flink-conf.yaml and environment variables when executing in local modeThis closes #17216.,5
[FLINK-24244][python] Logging whether it's executed in loopback modeThis closes #17234.,2
"[FLINK-24220][doc]Translate ""RESET Statements"" page of ""SQL"" into Chinese (#17224)",1
[FLINK-24043][runtime] Reuse the code of 'check savepoint preconditions'.This closes #17023.,1
"[FLINK-24184][task] Introduce lock to guard against race conditions around shouldInterruptOnCancelPreviously there was a potential race condition in disabling interrupts while closing resources.It used be guarded by a volatile variable, but there might have been a race condition when:1. interrupter thread first checked the shouldInterruptOnCancel flag2. shouldInterruptOnCancel flag switched to false as Task/StreamTask entered cleaning up phase3. interrupter issued an interrupt while Task/StreamTask are closing/releasing resources, potentially causing a memory leak",1
[FLINK-24245][python] Fix the problem caused by multiple jobs sharing the loopback mode address stored in the environment variable in PyFlinkThis closes #17239.,2
"[FLINK-24221][docs-zh] Translate ""JAR Statements"" page of ""SQL"" into Chinese (#17225)",2
[FLINK-23458][docs] Added the network buffer  documentation along with the buffer debloat doc,2
[FLINK-24243][python] Cleanup code to use latest API to avoid warningsThis closes #17237.,2
[FLINK-24098] Document FLIP-147 capabiliites and limitationsThis closes #17135,2
[hotfix][table] REGEXP_EXTRACT return type should always be nullableThis closes #17242.,4
[hotfix][docs] Adding new sources on overview pagesThis closes #17266,1
[FLINK-24206][connector/pulsar] Close the pulsar client properly.Pulsar Consumer would be closed in SplitReader if it reaches the end of split. The registered Consumer would also be closed in PulsarClient if we call PulsarClient.close(). This would cause race condition. We have to use PulsarClient.shutdown() which don't close Consumer instead.This closes #17255,1
"[FLINK-24212][k8s]fix the problem that kerberos krb5.conf file is mounted as empty directory, not the expected fileThis closes #17198",2
"[FLINK-24219][docs-zh] Translate ""SET Statements"" page of ""SQL"" into Chinese (#17223)",1
[FLINK-24267][python][docs] Update the example tutorial to use latest APIThis closes #17273.,3
[FLINK-24276][python] Avoid confusing output when executing in loopback modeThis closes #17274.,5
[hotfix][connector] Use null to replace empty pending transaction in 2pc sinkThis closes #17251.,1
[FLINK-24266][checkpoint] Log improvement for aborting checkpoint due to tasks are finishingThis closes #17250.,5
"[hotfix][docs] Fix output of test jobPreviously, the output listed here was the one for `head` and not `tail`as it's described in the steps to execute the test.This closes #17261.",3
[FLINK-23607][state/changelog] Make Changelog Backend a transitive dependency...of flink-test-utils instead of direct dependency of each module.,3
[FLINK-23607][state/changelog] Cleanup dependencies of DSTL DFS,4
[FLINK-23607][state/changelog] Document checkpointing.changelog in pom.xml,5
[FLINK-22275][table] Support random past for timestamp types in datagen connector (#15703),5
[FLINK-24283][connector/pulsar] Use stick key consumer in Key_Shared subscription. This would make sure Pulsar won't treat the flink reader as a shared consumer.This fix https://github.com/apache/pulsar/pull/12035,0
[FLINK-24282][connectors/kafka] Make topic selector for KafkaSink serializableIt is possible to calculate the target topic per record. Therefore userscan provide a lambda when constructing the KafkaSink. Before thiscommit the lambda was not marked as serializable and could not betransferred to the workers.,1
[FLINK-24139][table-planner] Push down more predicates through Join in stream modeThis closes #17272,2
[FLINK-21589][docs] Document table pipeline upgradesThis closes #17260,2
[hotfix][docs] Add glossary entry for 'Table program',1
"[FLINK-24217][docs-zh] Translate ""LOAD Statements"" page of ""SQL"" into Chinese (#17221)",2
[FLINK-24277][connector/kafka] Add configuration for committing offset on checkpoint and disable it if group ID is not specified,1
[FLINK-24277][connector/kafka] Remove auto-generated group id in Kafka table source,4
[FLINK-24277][connector/kafka] Add OffsetsInitializerValidator interface for validating offset initializer in KafkaSourceBuilder,5
[FLINK-24234][connectors] Added byte based flushing for AsyncSinkWriter,1
[FLINK-24234][connectors] Time based flushing for AsyncSinkWriter,2
"[FLINK-24218][docs-zh] Translate ""UNLOAD Statements"" page of ""SQL"" into Chinese (#17222)",2
[FLINK-24305][python] Limit the protobuf version<3.18This closes #17298.,2
[FLINK-24133][core] Network failure test replaced by comment in the code due to high expense of stabilizing such low important test,3
[hotfix] Fix a typo in 'estimatedTimeToConsume(r)BuffersMs',2
[FLINK-23969][connector/pulsar] Create e2e tests for pulsar connector.,3
[hotfix] Proxy SplitContext#isArgumentNull correctly,0
[hotfix] Relax condition for argument countThe argument count doesn't actually need to be a ConstantArgumentCount.This condition is unnecessarily restrictive.,0
[hotfix] Introduce InputTypeStrategies#repeatingSequence,0
[hotfix] Remove unused JsonUtils,5
[hotfix] Make all converters @Internal,1
[hotfix] remove duplicate case,4
"[hotfix] Handle ANY during type inferenceIf we have a call A(B(C)) and A() infers its argument to be of type ANY,this causes an error during the return type inference of B() because itcurrently only handles UNKNOWN.",0
[FLINK-16203][table] Support JSON_OBJECTThis closes #17186,5
[FLINK-23180] Do not initialize checkpoint base locations when checkpointing is disabledThis fix #17151.Co-authored-by: Jiayi Liao <liaojiayi@bytedance.com>,0
[FLINK-11250][runtime] Added method init for RecordWriter for initialization resources(OutputFlusher) outside of constructor (#17187)* [refactor][streaming] Ability to change bufferTimeout for StreamEdge in StreamConfigChainer* [FLINK-11250][streaming] Correctly clean up stream task on every place it uses,1
[FLINK-24317][python][tests] Optimize the implementation of Top2 in test_flat_aggregateThis closes #17309.,3
[hotfix][connectors/kafka] Remove unused code from KafkaDynamicSink,1
[FLINK-24281][connectors/kafka] Only allow KafkaSinkBuilder creation with KafkaSink.builder(),1
[FLINK-24281][connectors/kafka] Migrate all format tests from FlinkKafkaProducer to KafkaSink,2
[FLINK-24292][connectors/kafka] Use KafkaSink in examples instead of FlinkKafkaProducer,2
[hotfix][connectors/kafka] Rename EventDeSerializer to EventDeSerializationSchema in examples,0
[FLINK-24248][docs]update Gradle dependency,5
[FLINK-24129][connectors-pulsar] Harden TopicRangeTest.rangeCreationHaveALimitedScope.,3
[Hotfix][streaming] Fix a typo.,2
[FLINK-24233][runtime] Ignore message about new buffer size if the reader doesn't ready yet,1
[FLINK-24300] SourceOperator#getAvailableFuture reuses futureCallers of SourceOperator#getAvailableFuture might call the methodmultiple times even if the returned future does not complete. Before thecommit each we were creating a new combined future from theSourceReader#isAvailable and the forcedStop one. If the underlyingSourceReader#isAvailable has not changed this operation is unnecessary.What is even worse each such operation adds another entry onto thesource reader's availability future stack which caused performanceregression.The commit reuses the combined future if the underlyingSourceReader#isAvailable future has not changed.This closes #17303,4
[FLINK-24287][python][tests] Update grpcio version in tox.ini (#17301),5
[FLINK-24168][table-planner] Update MATCH_ROWTIME function which could receive 0 argument or 1 argumentThis closes #17205,1
[FLINK-22944][state] Optimize writing changelogWrite state name and type once fullyand later only write a short identifier.,4
[FLINK-22944][state] Re-use output in StateChangeLogger,4
[hotfix][docs] fix link from upsert-kafka to kafka Table(!) connector,2
[hotfix][test] Derive expected files from getFilesToUploadThis simplifies debugging if the number of files is modified.,2
"[FLINK-24197] Guard against CLRF being split across chunksThis commit adds a defense mechanism against https://github.com/netty/netty/issues/11668.If the CRLF prefix of a multipart delimiter is split across 2 chunks an exception is thrown because Netty incorrectly treats CR as data.If CR is the last byte of the current chunk, then we pessimistically assume that this case occurred.We exclude the trailing CR from the current chunk, and add it to the front of the next received chunk.",1
"[FLINK-24156][network] Guard against erroneous SocketTimeoutExceptionsOn JDK11 JDK-8237858 can cause SocketTimeoutExceptions to be thrown duringServerSocket.accept() calls, even when configured with an infinite timeout.This change works around this issue by catching these erroneous exceptionsand retrying indefinitely.",5
[hotfix] Refactor PlannerMocks be used as holder of different mocksSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
"[FLINK-22942] [sql/planner] Disable UPSERT INTO statement, including a testSigned-off-by: slinkydeveloper <francescoguard@gmail.com>",2
[release] Create 1.14 release-notesThis closes #17182,3
"[FLINK-24303][coordination] Failure when creating a source enumerator lead to full failover, not JobManager failure.Instead of letting exceptions during the creation of the Source Enumerator bubble up (and utimately failthe JobManager / Scheduler creation), we now catch those exceptions and trigger a full (global) failoverfor that case.This closes #17324",0
[FLINK-24253][jdbc] Migrate JDBC validation from TableSchema to DataType,5
[FLINK-24253][jdbc] Load Dialects via ServiceLoader,5
[FLINK-24253][jdbc] Mark Dialect as Public and move converter out of internal package,4
[FLINK-24253][jdbc] Cleanup JavaDoc of newly public interfaces,1
[FLINK-24253][jdbc] move default implementations to AbstractDialectThis closes #17264,4
[FLINK-24340] Only print exception on job failure/suspension,0
[FLINK-23389] Add integration with Glue Schema Registry JSON data format (#16513)Co-authored-by: Kexin Hui <khi@amazon.com>,5
[FLINK-24347][connectors/kafka] Keep idle source readers if parallelism is higher than partitions in KafkaSourceBefore this commit the enumerator signalled the leftover source readers without a partition to finish.This caused that checkpointing was not possible anymore because it is only supported if all tasks arerunning or FLIP-147 is enabled.This closes #17327,0
[FLINK-24159][docs][Runtime/Checkpointing] document of entropy injection may mislead users,1
[FLINK-24329][pulsar][tests] Fix port conflict,5
[FLINK-24262][runtime] Remove unused ContainerOverlays,1
[FLINK-23827][table-planner] Fix ModifiedMonotonicity inference for some nodesThis closes #16853,5
[FLINK-23651][python] Support RabbitMQ in PyFlinkThis closes #16798.,2
[hotfix][test] Remove unwanted timeout inside the testTimeouts are checked by the CI on the higher level.,3
[hotfix][test] Do not hide original exception in the tests,3
[hotfix][test] Create a dedicated file for StreamTask cancellation tests,3
[hotfix][test] Remove unused class in StreamTaskTest,3
[hotfix][test] Move LocalBufferPool destroy tests to LocalBufferPoolDestroyTest file,2
[FLINK-23739][table] BlackHoleSink & PrintSink implement SupportsPartitioning interfaceThis closes #16792,1
[FLINK-24353][scripts] Respect dynamic configurations when calculating memory sizes.This closes #17335,5
[FLINK-23991][yarn] Specifying yarn.staging-dir fail when staging scheme is different from default fs schemeCloses #16994,0
"[FLINK-23385][table] Implement COALESCE functionImplement COALESCE function and expose it in Expressions#coalesce. This removes the usage of the CASE WHEN THEN rewrite by Calcite, resolving the various type inference issues as underlined in FLINK-23385 and FLINK-21582Signed-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17256",2
[hotfix][flink-avro] Use local actual schema variable (#17305),1
[hotfix] Add flinkbot as collaborator,2
[FLINK-24344][runtime] testTriggerCheckpointAfterIoException throws exception from initializeLocationForCheckpoint rather than from getAndIncrement,1
[FLINK-24344][runtime] Calling the CheckpointFailureManager even if the exception happens during the checkpoint initialization,5
[FLINK-24315][k8s] Add retry logic when watching podsA fatal error will be thrown if the retry fails.This closes #17321.,0
[FLINK-24358][formats] Fix flink-avro-glue-schema-registry dependency convergence.,2
[FLINK-24358][formats] Fix flink-json-glue-schema-registry dependency convergence.This closes #17338,5
[FLINK-24336][python] Fix the issue that jar url list may contain empty string.This closes #17322.,0
[hotfix] Make it possible to force MockSourceReader to wait for initial splits assignment,5
[FLINK-24280] Initialize base locations for checkpoints lazily in thefirst checkpointIn FLINK-23180 we changed the initialization of base path locations toonly be called if periodic checkpoints are enabled. It worked becauseperiodic checkpoints were the only kind of checkpoints. Now we areintroducing manually triggered checkpoints which can be triggered by auser even if periodic checkpoints are disabled. That's why we need topossibly initialize the base locations on the first checkpoint that istriggered manually.,5
[FLINK-24280] Support manual checkpoints triggering from a MiniClusterThis closes #17278,5
[FLINK-24360] Drop Scala Shell,4
[hotfix][docs] Remove flink-connector-base as required dependency from the kafka connector,1
[FLINK-24271][docs] Add document for special char in JSON_VALUEThis closes #17275,5
[FLINK-23950] Revert [FLINK-23738][state] to re-enable ChangelogBackend (#17287)This reverts commits:- d6bccd13190f0dbb2505b4512a38ae71b3d78195- b4c385e41832f16e39d5cbe4fb69ead9bbe077b2- 67dd4932133d74d88666433d4d8aa4a6cbc94c78,5
[hotfix][docs] Fix typo for 'exactly-once' in docs,2
[FLINK-24358][e2e] Fix glue shema registry e2e tests dependency convergence.This closes #17359,3
"[hotfix][docs] Remove the explicit requirement of flink-connector-base, and add missing StartCursor in pulsar connector document.",2
[FLINK-24373][docs] Remove BETA Tag from FLIP-27 Source DocsThis closes #17353,2
[FLINK-24375] Let name of flush thread in RecordWriter contain subtask index.,2
[hotfix][runtime][test] Use builder for creating TestingResourceManager.,3
[FLINK-24377][runtime] Actively release TM resource after heartbeat timeout.This closes #17362,2
[hotfix] Remove outdated comment in CheckpointCoordinator,5
[FLINK-24374] Retry querying for checkpoint statsThe checkpoint stats are updated after the corresponding future for acheckpoint is completed. Therefore we might retrieve the old stats thatdo not reflect the just completed checkpoint yet. In this commit we doretry until we reach the desired number of checkpoints.,1
[hotfix][test] Reduce visibility of test classes in SinkWriterOperatorTest,3
[FLINK-24371][datastream] Call preCommit on SinkWriter although no committer is availableBefore this change if no committer was after the SinkWriter in thepipeline preCommit was never called. With this change preCommit is nowcalled as well but the return values are discarded as before.,4
[FLINK-24380][k8s] Terminate the pod if it failedThis closes #17361.,0
Update japicmp configuration for 1.14.0,5
[FLINK-23316][table-runtime][hive] Add test for Custom PartitionCommitPolicyThis closes #17245,3
[release] Add 1.14 docs link to the list of previous versions,2
[FLINK-24394][table-planner] Improve efficiency of tests using BuiltInFunctionTestBaseAdd the possibility to tests multiple TableApi expressionsand/or SQL expressions as multiple table columns using just oneexecution of the pipeline to speed up the total test execution time.Refactor existing tests of BuiltInFunctions to use the new approachwhereever possible.This closes #17341.,1
[FLINK-23313][docs] Reintroduce temporal table function documentationThis closes #17356,2
[hotfix][docs] Move out the time zone page from streaming concepts sectionThis closes #17377,4
[hotfix][python][docs] Update the README of PyFlink,2
[release][docs] Clean up 1.14 release notesThis closes #17392,3
[FLINK-20845] Drop Scala 2.11 support,1
[hotfix][docs] Fix typo in sources docThis closes #17380,2
[FLINK-21142][connector-hive] Hide Guava from Hadoop and security toolsThis closes #16012.,2
[hotfix][hive] Use consistent relocation pattern for Parque in Hive,1
[FLINK-24410][tests] Upgrade Confluent Platform OSS version,5
[FLINK-21853][e2e] Harden common_ha.sh#ha_tm_watchdogThis commit hardens the common_ha.sh#ha_tm_watchdog function by always startingthe expected number of TaskManagers. This will ensure that the e2e tests that areusing this function also pass if a TaskManager dies accidentally.,4
"[FLINK-21853][e2e] Reduce the number JM kills in test_ha_per_job_cluster_datastream.sh and test_ha_datastream.shThis commit reduces the number of JM kills in test_ha_per_job_cluster_datastream.sh and test_ha_datastream.sh because onCI killing the JM 3 times can take more than the current timeout (15 minutes) (2 minutes per successful checkpoint, 8successful checkpoints required to pass).This closes #17137.",4
[FLINK-24117][HA]Remove unHandledErrorListener in ZooKeeperLeaderElectionDriver and ZooKeeperLeaderRetrievalDriveradd testsThis closes #17150.,3
[FLINK-19792][table-planner] Fix IntervalJoin with time equality predicateThis closes #17369.,0
[hotfix][table-api-java] Mark ModuleManager as internal,0
[hotfix][core] Added OptionalUtils,1
[FLINK-24388][table-planner] Provide ModuleManager in FlinkContext,2
[FLINK-24388][table-planner] Introduce Module#getTableSourceFactory,1
[FLINK-24388][table-planner] Introduce Module#getTableSinkFactoryThis closes #17384.,1
[hotfix][table-api-scala] Use Expression* to trigger implicit conversion,1
[FLINK-16204][table] Support JSON_ARRAY()This closes #17313.,5
[hotfix][table-api-scala] Unwrap Expression args for jsonObject and jsonArray,5
[hotfix][table-common] Fix grammar mistake in FunctionDefinition,5
[hotfix][docs] Mention that modules can provide table source/sink factories,1
[hotfix][streaming] Improve Input class javadoc,2
[FLINK-24367] RpcSystem#loader evaluates all service entries,5
[FLINK-24367][tests] Streamline instructions,3
"[FLINK-24367][tests] Add FallbackAkkaRpcSystemLoaderThe added loader constructs the classloader based on the target/classes directory of flink-rpc-akka, after downloading required dependencies via maven.",1
[FLINK-24269][Runtime / Checkpointing] Rename methods around final checkpointsThis closes #17316,2
[hotfix] Fix incorrect state.backend.local-recovery descriptionState that only the MemoryStateBackend does not support local recovery.,1
[hotfix][table-planner] Disable IntervalJoinITCase.testRowTimeInnerJoinWithEquiTimeAttrs until FLINK-24443 is fixed,0
[FLINK-24399][table-common] Add DataTypes#of(LogicalType)Signed-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Add DataType#toInternalSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Add DataType methods to improve ergonomics when accessing row data type instancesSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Improved DataType#getChildren javadocSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Refactor ResolvedSchema#to[...]RowDataType() methods and add new ResolvedSchema#getPrimaryKeyIndexesSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Fix DataTypeUtils#flattenToNames javadocSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Add DynamicTableSource.Context#createTypeInformation(LogicalType) and DynamicTableSink.Context#createTypeInformation(LogicalType)Signed-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24399][table-common] Add DynamicTableFactory.Context#getPrimaryKeyIndexes and DynamicTableFactory.Context#getPhysicalRowDataTypeSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17381.,2
[FLINK-23049][tests] Checkpoint is triggered manually for UnalignedCheckpointCompatibilityITCase,3
[FLINK-24275][rest] Refactor parameter resolving into separate methods,2
[FLINK-24275][rest] Add HandlerRequest factory methodsAdd factory methods for production code paths (where parameters must be resolved from the maps that Netty provides) and test code paths (where parameters are already resolved).,0
[FLINK-24275][rest] Simplify HandlerRequest generics,0
[FLINK-24275][rest] Streamline JobCancellationMessageParameters,2
[FLINK-24275][rest] Idempotent job cancellation,2
[FLINK-24445][build] Copy rpc-akka jar in package phase,2
"[FLINK-24382][metrics] Do not compute recordsOut metric in SinkOperator to allow sinks emitting a flexible number of recordsInitially, we assumed every incoming record of a sink creates oneoutgoing record after SinkWriter#write is called. This is not correctfor all sinks thus the SinkWriter should now increment the counteraccordingly.",1
[FLINK-20928] Fix flaky test by retrying notifyCheckpointComplete until either commit success or timeout,1
"[FLINK-24405][tests] Introduce util to reliably drain all messages from a kafka topicThe approach used before the introduction was to poll the topic with agiven timeout and if the poll did not return a record treat it as allrecords have been read. Unfortunately, due to network issues or similarthe poll can easily return without any records but end offset was notreached making the tests unreliable. The new util always drains allmessages until the end offset is reached.",1
[FLINK-24405][tests] Harden kafka tests based on KafkaTestBase,3
"[hotfix][FileSource] Internal refactoring to remove duplicated code without API change. Rename method argument names from ""reader"" to ***Format to improve the code readability.",1
"[FLINK-24393][table-planner] Add CAST tests for type combinationsAdd tests for currently supported type combinations, list also unsupportedones in comment sections alongside a url pointing to the corresponding issue.This closes #17396.",0
"[hotfix] Fix typo,'Kafka' corrected to 'Kafka'",2
[hotfix] Fix typo multiple word mistakes,2
[FLINK-24324][connectors/elasticsearch] Add Elasticsearch 7 sink based on the unified sink (FLIP-143),1
"[hotfix][datastream] Add missing Internal annotations for OperatorCoordinator classFor now we don't want to expose the coordinators, just things that use acoordinator, like the SourceEnumerator.",1
[FLINK-24431][kinesis][efo] Stop consumer deregistration when EAGER EFO configured. (#17417)* FLINK-24431 Stop consumer deregistration when EAGER EFO configured.* FLINK-24431 Verify criteria for stream deregistration in unit tests.* FLINK-24431 Update documentation to reflect new EAGER EFO strategy changes.* FLINK-24431 Remove Java 11 language feature usage in consumer unit test.* FLINK-24431 Untranslated zh documentation updated to match kinesis documentation changes.,4
[FLINK-24359][table-runtime] Use ResolvedSchema in AbstractFileSystemTableSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17350.,2
"[FLINK-24421][table-runtime] Fix conversion of strings to TIMEFollowing calcite-avatica behaviour, fix the behaviour of parsingstring into unix time when the string is incomplete, missing 1 orboth `:` time units separator. Previously, minutes and seconds whereset to default value `1` instead of `0` when missing from the parsedstring. Issue was fixed in avatica with:https://github.com/apache/calcite-avatica/commit/cac2ffaaf97572d21cba195d7590d9ab0d32382eThis closes #17418.",0
[FLINK-24472][tests] Wait for cancellation future to complete,3
"[FLINK-24442][table][docs] Fix markup to show back ticks in ""Queries"" page (#17408)",0
"[FLINK-24361][docs] Fix typo in ""Time Attributes"" page (#17339)There are only two ways to define a processing time attribute but the time_attributes.md said has ""three"".",2
"[FLINK-24182][task] Do not interrupt tasks/operators that are already closingOtherwise if we interrupt operator that is doing a blocking call to releasesome resources in closing, we can cause those resources to leak. A good exampleis Kafka sink, which wants to abort transactions in close() method.",1
"[hotfix][task] Remove redundant interrupt callRegardless if task was failing or not, we would still interrupt the source threada couple of lines later inside `cancelOperator(true)` -> `interruptSourceThread()`",1
[FLINK-24182][test] Rewrite testCleanUpExceptionSuppressing to use mailbox test harnessPreviously this test was invoking cleanUp method from outside of the mailbox threadwhich is not allwoed. Without this fix one of the later commits would cause this testto fail.,0
[FLINK-24182][task] Unify exception preProcessing logic,2
[FLINK-24182][task] Interrupt source task via `maybeInterrupt` callThis makes it more similar to how non source tasks are working andall code interrupts are originating from the same place.,1
"[FLINK-24182][task] Extend test coverage of interruptions in SourceStreamTaskIf we have a source that takes long time to cancel, SourceStreamTask shouldalways wait for the source thread to finish. Regardless if SourceStreamTask iscleanly cancelled or interrupted.This was working properly on the master before this commit. Here we are justadding test coverage for that.",3
[hotfix][task] Fail if TASK_CANCELLATION_TIMEOUT causes overflow,1
[FLINK-24182][task] Unify failureCause handling and improve loggingNow failureCause is set in only one place and catching CancelTaskExceptiongives more detailed logs.,2
"[FLINK-24182][task] Reimplement FLINK-21181 to close early local buffer poolsClosing network resources is a valid way to cancel a job to avoid interrupting thetask if they are backpressured and waiting for a buffer. To do so, we need to revertFLINK-21181 and close the buffer pools. To avoid errors as reported in FLINK-21181we make sure that CancelTaskException is thrown when closing buffer pools whencancelling task.",1
"[FLINK-24182][task] Remove unused return value from cancel methodAfter changes in the previous commit, this is no longer needed.This is kept as separate commit to make the previous commit easier to understand.",1
[FLINK-24357][tests] Harden ZooKeeperLeaderElectionConnectionHandlingTestThis commit hardens ZooKeeperLeaderElectionConnectionHandlingTest.testLoseLeadershipOnLostConnectionIfTolerateSuspendedConnectionsIsEnabledby allowing that exceptions can occur if the connection to ZooKeeper is lost. We do this by clearing the fatal error handlerat the end of the test.This closes #17398.,3
[FLINK-24451][HA]Replace the scattered objects with encapsulated LeaderInformation in DefaultLeaderElectionServiceThis closes #17414.,5
[FLINK-24437][HA]Remove unhandled exception handler from CuratorFramework before closing it,1
[FLINK-23458][docs] Added the network buffer  documentation along with the buffer debloat doc to chinese part of the documentationThis closes #17435,2
[FLINK-21345][table-planner] Fix bug of union all join temporal table,0
[FLINK-22954][table-planner] Rewrite Join on constant TableFunctionScan to CorrelateThis closes #16192,1
[FLINK-24291][table-planner] Decimal precision is lost when deserializing records from testcsvThis closes #17308,3
[FLINK-24389][table] Fix NPE in CatalogTableImpl#getDescription (#17438),2
[FLINK-23358][core] Refactor CoreOptions parent first patterns to List optionsThis closes #16821,4
[FLINK-24459][table] Performance improvement of file sink (#17416),2
[FLINK-24417] Update MigrationVersion with 1.14,5
[FLINK-24417] Regenerate files for migration testsThis closes #17403,3
[FLINK-24376][runtime] Use operator name for constructing OperatorCoordinatorProvider instead of chained name,1
[FLINK-23549][docs][kafka] Fix syntax error in create table example in Kafka connector page (#16639),1
[FLINK-24443][table-runtime] Reenable IntervalJoinITCase.testRowTimeInnerJoinWithEquiTimeAttrsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17423.,2
[refactor][streaming] Types corrections for BufferDebloaterTest,3
[refactor][streaming] Builder for parameters of  BufferDebloaterTest,3
[FLINK-24467][streaming] Announce the min and max buffer size despite last diff less than thresholdThis closes #17437,2
[FLINK-23978][scala] Move Scala-reliant FieldAccessors to flink-streaming-scala,2
[FLINK-24513][tests] Make AkkaRpcSystemLoaderTest an ITCase,5
[FLINK-24503][k8s] Change default REST service type to ClusterIPThis patch aims to improve security of Flink native Kubernetes deploymenton vendor k8s cluster as the original defaults LoadBalancer results inREST API and web UI exposed to the wild Internet if the developer forgetsor fails to override the defaults.Signed-off-by: nanmu42 <i@nanmu.me>This closes #17461,0
[FLINK-24460][rocksdb] Error handling improvement for RocksIteratorWrapperthis closes #17419.,1
[FLINK-24480][table-planner] Do not discard exception in testThis closes #17469,3
[FLINK-24432][rocksdb] RocksIteratorWrapper.seekToLast() logic typo,2
[FLINK-24540] Fix file stream resource leaks,2
[FLINK-23704][task] Extract LatencyMarkerEmitter class,4
[FLINK-23704][test] Introduce SourceOperatorTestHarnes,3
[FLINK-23704][task] FLIP-27 sources are not generating LatencyMarkers,2
[FLINK-23704][task] Apply review suggestsion for generating LatencyMarkers in FLIP-27 sources,2
[FLINK-23704][test] Remove unused CollectorDataOutput class,5
"[FLINK-17914][hs] Keep archives if listStatus failsIf FileSystem#listStatus threw an exception then all archives from that directory were removed, because we did not remove the contained jobs from the set of jobs to remove.It should be fine to keep these archives around, because such failures should only be temporary.",0
[hotfix] Refactor JobArchiveFetcherTask#run,1
"[FLINK-17914] Restructure HistoryServerMoves the fetcher scheduling to history server and merge HistoryServerArchiveFetcher and JobArchiveFetcherTask.This way the HistoryServer takes care of everything required for a long-running application, while the fetcher is entirely focused on a single fetch.",1
[FLINK-17914][tests] Increase chances of concurrent deletions,4
[FLINK-24017][kryo] Pin registration IDs of Java types,2
[FLINK-24017][kryo] Move FlinkChillPackageRegistrar to flink-java,2
[FLINK-24017][kryo] Add scala-free code paths,1
[hotfix][docs] Fix typo,2
[FLINK-24563][table-planner] Fix NullPointerException when comparing timestamp_ltz with random stringThis closes #17497,0
[FLINK-24559][build] Fix flink-rpc-akka packaging,2
[FLINK-24535][Formats] Upgrade Glue Schema Registry library to the latest version,3
[FLINK-24418][table-planner] Add support for casting RAW to BINARYImplement casting from generic RAW type into BINARY/VARBINARY/BYTESThis closes #17450.,3
[FLINK-24469][runtime] Allow to have zero number of buffers in use for channelsWe allow channels to have zero number of buffers in use in order to avoid miscalculation in case of channel data skew.This closes #17479,5
"[FLINK-24465] Fix disabling buffer timeout for pipelined exchangesThe goal is to fix the possibility to disable buffer timeout for pipelined exchanges. It has been broken in FLINK-18832,which was supposed to add a check that buffer timeout is properly configured if blocking exchanges are present in the graph.In this commit we treat -1 again as a valid configuration value instead of an UNDEFINED. However, it removes the automatic disabling of buffer timeout for blocking exchanges.This closes #17471",4
[hotfix][docs] Add additional sentence for minio usersSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][docs] Specify that json format works for append only streamsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][docs] Specify that there is no defined ingestion order for the files in a directory when using the filesystem connectorSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17343.,2
[FLINK-24480][table-planner] Reduce number of fields in testThis closes #17499.,3
"[FLINK-24564][formats] Change the default compression to snappy for parquet, avro in tableThis closes #17500",4
[FLINK-24584][qs] Improve assertion,3
[FLINK-24461][table] Let PrintUtils accept only internal data structuresSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17441.,2
[FLINK-24387][table-planner] Remove code generation dependency on actual JSON node,5
[FLINK-24387][table] Support JSON_STRING()This closes #17481.,5
"[FLINK-9432][table-planner] Enable EXTRACT for DECADE, ISODOW, ISOYEARThis closes #17422.",4
[FLINK-24516][archetype] Modernize Maven Archetype,2
[FLINK-24516][archetype] Update archetype documentationThis closes #17487,2
[FLINK-24355][runtime] Expose the flag for enabling checkpoints after tasks finish in the Web UI,5
[FLINK-24585][filesystem] Print the change in the size of the compacted filesThis closes #17517,2
[FLINK-24562][yarn][test] YarnResourceManagerDriverTest should not use ContainerStatusPBImpl.newInstanceThis closes #17496,1
[FLINK-24308][docs] Translate Kafka DataStream connector documentation to Chinese,2
[FLINK-24546][docs] Fix missing description of Acknowledged stats on checkpointingthis fix #17482.,0
[hotfix] Sync zh release notes 1.14,0
[hotfix] Update release notes with changes to StreamStatusThis closes #17447,4
[FLINK-24318][table-planner] Casting a number to boolean has different results between 'select' fields and 'where' conditionThis closes #17311,2
"[FLINK-23271][table-planner] Disallow cast from decimal numerics to booleanFollowing discussions on the issue and the relevant calcite issue: CALCITE-4777the support for decimal numerics is dropped, and only from integer numerics(TINYINT, SMALLINT, INT, BIGINT) remains as is.This closes #17439.",4
"[hotfix][table-planner] Beautify the assertion error message in BuiltInFunctionTestBaseWhen testing multiple cases as multiple columns of a tableseparate them in error msg output for TableApi with a `, `.",0
"[hotfix][table-planner] Remove prefix for TypeCheckUtils methodsUse consistently the methods of TypeCheckUtils without the prefix, since `TypeCheckUtils._` is anyway imported",2
[FLINK-24397][connectors/kafka] Remove TableSchema usage from Kafka table connector,4
[FLINK-24397][connectors/hbase] Remove TableSchema usage from Hbase table connector,4
[FLINK-24397][connectors/jdbc] Cleanup the Jdbc table connector by removing legacyThis closes #17459.,4
[hotfix][docs] Extend documentation for speeding up maven builds,2
[FLINK-24600][ui] Remove duplicate 99th percentile,4
"[FLINK-24604] Remove tests which use decimal -> boolean castThe decimal->boolean cast has been dropped but another PR added sometests using this cast, removing the casts, and keep only the ones thatcast interger numerics to boolean.Follows: #32f7cc9e34be67eaf1b746697f2fabefcd5f46c5Follows: #fc92a8830d07416d37be0ed4c5fe472ac0531c25This closes #17530.",4
[FLINK-24563][table-planner][test] Re-enable tests for invalid strings->timestamp_tz castRe-enable tests for invalid strings->timestamp_tz cast conversionFollows: 75e5a89529f4c1bec87d7090e527ce64e9188bc1This closes #17512.,3
[FLINK-24468][runtime] Moved the methods for sending messages from NetworkClientHandler to NettyPartitioonRequestClient since it is not responsibility of handler to send them,0
[FLINK-24468][runtime] Replaced submit by execute for submitting buffer size calculation to mailbox,2
[FLINK-15987][table-planner] Fix SELECT 1.0e0 / 0.0e0 throws NumberFormatExceptionThis closes #17436,0
[FLINK-24575][table-runtime] Migrate TestRowDataCsvInputFormat to DeserializationSchemaFactorySigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17515.,2
[FLINK-24019][build][dist] Package Scala APIs separately,2
[refactor][tests] Expanded toString for TestEventSource,3
[FLINK-24331][tests] Forbid to finish the TestEventSource if it has not sent at least one value,3
[FLINK-24560][build][yarn] Copy example jars in pre-integration-test phasejars don't exist before packaging phase,3
[FLINK-24561][build] Build archetype jars in compile phase,2
[FLINK-24613][doc] Documentation on orc supported data types is outdatedThis closes #17543,5
[FLINK-21357][runtime/statebackend]Periodic materialization for generalized incremental checkpoints (#16606)* [hotfix][state] Introduce ChangelogOptions and backend materialization related configurations* [hotfix][state] Fix log4j2-test.properties for flink-statebackend-changelog* [hotfix][runtime] Move AsyncExceptionHandler from flink-streaming-java to flink-runtime* [FLINK-21357][state] Periodic materialization for generalized incremental checkpoints* [do not commit][for testing only]* fixup! [FLINK-21357][state] Periodic materialization for generalized incremental checkpointsRemove waiting for termination of periodicExecutor* fixup! [hotfix][state] Introduce ChangelogOptions and backend materialization related configurationsRemove changelog_configuration.html* fixup! [FLINK-21357][state] Periodic materialization for generalized incremental checkpointsclose periodicMaterializationManager properly* fixup! [FLINK-21357][state] Periodic materialization for generalized incremental checkpointsadd synchronized access to periodicExecutor in PeriodicMaterializationManager* fixup! [FLINK-21357][state] Periodic materialization for generalized incremental checkpointsmake the semantics of allowedNumberOfFailures consistent* fixup! [FLINK-21357][state] Periodic materialization for generalized incremental checkpointsRemove Test Code* fixup! [hotfix][state] Introduce ChangelogOptions and backend materialization related configurationsadd filesystem for STATE_CHANGE_LOG_STORAGE config description* fixup! [FLINK-21357][state] Periodic materialization for generalized incremental checkpointsseveral minior fixes* fixup! [hotfix][state] Introduce ChangelogOptions and backend materialization related configurationscompiling the docs* fixup! [do not commit][for testing only]reset random flag of changelog,4
[FLINK-24500][table] Move SqlDateTimeUtils to table-common as DateTimeUtilsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17454.,2
[FLINK-24018][build] Remove Scala dependencies from Java APIs,4
[FLINK-24634][build] Make Java 11 target opt-in,1
[FLINK-24488][connectors/kafka] Fix KafkaRecordSerializationSchemaBuilder does not forward timestamp,0
[FLINK-18312][rest] Refactor CompletedOperationCache- return Optional instead of nullable- wrap result/exception in OperationResult to be more ergonomic,4
[FLINK-18312][rest] Introduce TriggerSavepointMode enum,2
[FLINK-18312][rest] Rename RestfulGateway#*savepointClarify what the method actually returns.,2
[FLINK-18312][rest] Add operation cache to dispatcher,1
[FLINK-18312][rest] Move savepoint operation state into Dispatcherdispatcher,4
[FLINK-24599][table] Replace static methods with convenient methods in LogicalTypeMake the code of calling `hasRoot`/`hasFamily` less verbose byreplacing the static utility methods with member methods`LogicalType#is()`.This closes #17550.,2
[FLINK-10230][table] Support 'SHOW CREATE VIEW' syntax to print the query of a viewThis closes #17352,1
[FLINK-24647][runtime/coordination] Log thrown exception if UncaughtExceptionHandleMode.LOG is set,1
[FLINK-24541][runtime] Quoting the external resource list in generating dynamic config stringThis closes #17533,5
[FLINK-24662][python][tests] Set the version of Docutils to 0.17.1,2
[hotfix][connector/testing-framework] Let ExternalContext#generateTestData returns List to preserve order,5
[FLINK-23914][connector/testing-framework] Improve descriptions in test data matchers to reveal more info on failure,0
[FLINK-23914][connector/testing-framework] Add INFO log to track running stage of connector testing framework,1
[FLINK-24486][rest] Make async result store duration configurable,5
[FLINK-16205][table-planner] Test base for aggregation functions,1
[FLINK-16205][table-planner] Serialize JSON with stable key order,5
"[FLINK-16205][table] Support JSON_OBJECTAGGA few notes regarding the implementation(1) In order to have deterministic results, we sort the object keys    alphabetically. However, there is no built-in way in Jackson to do this    yet for the tree representation (JsonNode), so we need an extra    conversion step. See    https://www.mail-archive.com/jackson-user@googlegroups.com/msg01877.html    for more details.(2) We represent (NULL|ABSENT) ON NULL as two separate built-in functions    for now. This is necessary because otherwise we would have to ship    the symbol across the network for each record, which leads to various    problems. Calcite essentially uses the same workaround.This closes #17549.",1
"[FLINK-23391][connector/kafka] Fix flaky Kafka source metric test by retrying notifyCheckpointComplete until success or timeoutWhen calling KafkaSourceReader.notifyCheckpointComplete(), KafkaConsumer.commitAsync() might fail because of coordinator movement or network instability during the test. Retrying offset commit until success will increase the stability of the case and has no side effect since this operation is idempotent.",1
[FLINK-24654][table] Fix NPE on RetractableTopNFunction when some records were cleared by state ttlThis closes #17570,1
"[FLINK-16206][table] Support JSON_ARRAYAGGWe represent (NULL|ABSENT) ON NULL as two separate built-in functionsfor now. This is necessary because otherwise we would have to shipthe symbol across the network for each record, which leads to variousproblems. Calcite essentially uses the same workaround. This is thesame as was done for JSON_OBJECTAGG.This closes #17562.",5
[FLINK-24381][table] Hiden sensitive config values,5
[FLINK-24310][doc]Use >= instead of == to cover the downscaling scenario,2
[FLINK-24470][streaming] Added EMA calculation for buffer size inside BufferDebloater,1
[FLINK-24470][runtime] Removed EMA calculation for throughput,4
[hotfix][streaming] Update new calculated buffer size value only if the announcement doesn't fail,0
[hotfix][test] Move CompletedCheckpointStore#storeFor to a test class,3
"[FLINK-23647][checkpointing] Wait for CheckpointsCleaner to complete before closing clusterThis change should prevent errors in tests that are checking for existence ofcheckpoint files. Before this change, checkpoint files could have disappearedafter job submitted via mini cluster has already finished/closed, which wasleading to some unexpected test failures.",0
[FLINK-24612][connectors/kafka] Configure Kafka test container log levels accordingly to test logger,2
[FLINK-24676][table-planner] Fix schema mismatch exception if explain insert with partial columnThis closes #17584,0
[FLINK-24673][formats] Deprecate old Row SerializationSchema/DeserializationSchemaSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17589.,2
[FLINK-24678][runtime/metrics] Correct the metric name of map state contains latency,2
[hotfix][table-runtime] Fix ArrayDataSerializer null fields writingSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24462][table] Introduce CastRule interface to reorganize casting codeSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17522.,2
[FLINK-24670][docs] Restructure unaligned checkpoints docs to checkpointing under backpressure,2
[FLINK-24695][docs] Update how to configure unaligned checkpoints,5
[refactor][runtime] Extracted resize buffer method in BufferWritingResultPartition,4
[FLINK-24190][runtime] Forbid to split the first record in the buffer if it physically fit it.,2
[hotfix][docs] Fix typo in network_mem_tuning.md,1
[FLINK-24327][connectors/elasticsearch] Integrate unified Elasticsearch 7 sink with Table API,2
[hotfix][table-common] fix DataType methods in DynamicTableFactory docstring,2
[FLINK-24408][table-planner] Enable code splitting for large number of VALUES clauseThis closes #17586,1
[FLINK-24492][table-planner] Fix incorrect implicit type conversion between numeric and (var)charThis closes #17444,2
[FLINK-20895][table-planner] Support local aggregate push down in table plannerCo-authored-by: Sebastian Liu <liuyang0704@gmail.com>This closes #17344,1
[FLINK-20443][API/DataStream] ContinuousProcessingTimeTrigger doesn't fire at the end of the window,5
[FLINK-20443][API/DataStream] ContinuousEventTimeTrigger  optimization,1
[FLINK-23919][table-planner] Fix field name conflict bug in WindowUtilThis closes #17604,0
[FLINK-24553][core] Changed buffer debloat default configuration values to more optimal,5
[FLINK-24671][runtime] Return 0 buffers in use until subpartition view initialization in order to avoid NPE,5
[hotfix][table-planner][tests] Improve exception assertion in BuiltInFunctionTestBaseImprove assertion of TableApi exception validation.,5
"[FLINK-24454][table-planner][tests] Consolidate cast testsCheck for `CAST` tests in other classes, move them in `CastFunctionITCase`,or completely remove them if are already contained in `CastFunctionITCase`.This closes #17579.",1
[hotfix][table-common] Disable cast from binary to date/timeDon't allow to cast from `BINARY`/`VARBINARY`/`BYTES` to any of`DATE`/`TIME`/`TIMESTAMP`/`TIMESTAMP_LTZ` in verification stage.,5
[FLINK-24720][tests] Remove flink-runtime-web dependency,2
[FLINK-15550][runtime] Don't ignore the interruption for testCancelTaskExceptionAfterTaskMarkedFailed,3
[FLINK-24699][build] Run scalastyle in validate phase,5
[hotfix] Refactor the registerJobManager to registerJobMasterThis closes #17428.,4
[FLINK-24167][Runtime]Add default HeartbeatReceiver and HeartbeatSender to simplify the usage of HeartbeatTargetThis closes #17426.,1
[FLINK-24723][archetype] Add ServicesResourceTransformer transformerThis closes #17633,1
[FLINK-24725][python] Update Cython to the latest versionThis closes #17644.,3
[FLINK-23015][table-runtime] Implement streaming window Deduplicate operatorThis closes #17571,1
[FLINK-24728][table-runtime] Close output stream in batch SQL file sinkThis closes #17638,2
"[FLINK-24648][table] CEIL and FLOOR support DECADE, CENTURY, MILLENNIUMThis closes #17569",1
[hotfix][tests] Allow customized configuration of input gates in StreamTestSingleInputGate,3
"[FLINK-24189] Extract BufferDebloatConfigurationExtract a BufferDebloatConfiguration which reads and validates optionsfrom a general purpose Configuration. This way we do not need to passaround the entire task configuration, but just a concise set ofnecessary options.",1
[FLINK-24189] Perform buffer debloating per single gateThis commit moves calculating throughput as well debloating buffers tothe gate level. It should help with situations when there is asignificant difference in gates throughput.,4
[FLINK-24746][ci] Disable Alibaba maven mirror,2
[FLINK-24714][table-api-java] Validate partition keys for ResolvedCatalogTableThis closes #17624.,2
[FLINK-24706][tests] Increase restart delay to 5 seconds,1
[FLINK-24706][coordination] Strip completion exception in HeartbeatManager,2
[FLINK-24706][rpc] Forward deserialization errors to returned future,0
"[FLINK-24609][akka][build] Use same Scala properties as root pomMaven does not properly resolve dependencyManagement entries if the parent/child module declare one for the same dependency with different properties being used in the artifactId.Hence we unfortunately need to use the same property names, which should however not cause issues in the future (if say, a 2.13 profile is introduced), because the properties defined in the child take precedence.",1
[hotfix][runtime] Refactor testing methods out from SlotProfile into SlotProfileTestingUtils,3
[hotfix][runtime] Rename `previousExecutionGraphAllocations` in SlotProfile to `reservedAllocations` to avoid confusion,5
[hotfix][tests] Factor PerJobMiniClusterFactoryTest#MyCancellableInvokable out to be a standalone test class in flink-runtime,2
[FLINK-19142][runtime] Use LocationPreferenceSlotSelectionStrategy for batch jobs even if local recovery is enabled,0
[FLINK-19142][runtime] Fix slot hijacking after task failoverThis closes #15229.,0
[FLINK-24550][rpc] Use ContextClassLoader for message deserialization,1
[hotfix] Fix spotless violation,0
[FLINK-24748] Remove CheckpointStatsTracker#getJobCheckpointingConfigurationThe CheckpointCoordinatorConfiguration was unnecessarily stored in the CheckpointStatsTracker. We can store it directly in the ExecutionGraph instead.,5
[hotfix][table-common] Add DataType#excludeFieldsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17642.,2
[FLINK-24597][state] Avoid KeyedStateBackend#getKeysAndNamespaces to return duplicate dataThis closes #17525,5
[FLINK-24704][table-runtime] Fix exception when the input record loses monotonicity on the sort key field of UpdatableTopNFunctionThis closes #17605,5
[FLINK-24770] Remove error from JobStatusListenerThe error is not currently used anywhere and makes it harder to add more uses of the interface.,1
[hotfix] Fix formatting issues in generated files,2
[FLINK-24208][rest] Support user-supplied Savepoint triggerId,1
[FLINK-24208][rest] Consistent nullable getters,1
[FLINK-24208][rest] Add StopWithSavepointTriggerRequestBodyTest,3
"[FLINK-24603][e2e] Simplify FlinkDistribution#submitJobWe wait either way for the process to complete (be it for the submission when detached, or the job completion when attached to parse the JobID), so we can just run the submission process in a blocking fashion",1
[FLINK-24603][e2e] Allow arbitrary jars to be added to the distributionRequired for adding a user-provided Scala library to lib.,1
[FLINK-24603][e2e] Add support for setting job main class,1
[FLINK-24603][e2e] Add test for Scala-free Flink,2
[FLINK-24747][table] Let SupportsProjectionPushDown#applyProjection provide the projected data typeSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17662.,2
[FLINK-24778][table-common] Add DataTypes#ROW(List<Field>) to reduce friction when using Stream of fieldsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17688.,2
[hotfix][table-planner][tests] Fix links to JIRA tickets in CAST integration testsThis closes #17683.,3
[FLINK-24715][connectors][filesystems][formats] Update multiple Jackson dependencies to latest version,3
[FLINK-24740][testinfrastructure] Update testcontainers dependency to the latest version,3
[FLINK-24749] Add CachingSupplier,1
[FLINK-24749][coordination] Reuse CheckpointStatsTracker,1
[hotfix][docs]fix kafka datastream connector mistake,5
[FLINK-24719][jdbc] Update Postgres test dependencies,3
[hotfix][table-common] Fix nullability for DataTypeUtils.appendRowFields,5
[FLINK-24796][ci] Reduce size of compile build artifact,2
"[FLINK-23427][chinese-translation] Translate the page of ""Blocking Shuffle"" into ChineseThis closes #16627.",1
"Revert ""[FLINK-23427][chinese-translation] Translate the page of ""Blocking Shuffle"" into Chinese""This reverts commit b296cb4849efb05ac94da7b5e95b7e5afa3d8e14.",4
"[FLINK-23427][chinese-translation] Translate the page of ""Blocking Shuffle"" into ChineseThis closes #16627.",1
[FLINK-24475] Remove no longer used NestedMap* classesThis fix #17650.,0
[FLINK-24401][runtime] Fix the bug of TM cannot exit after Metaspace OOM,0
[FLINK-24738][runtime] Ignoring buffer size announcement if the channel is released already,2
[refactor][runtime] Getting rid of code style warnings in LocalInputChannelTest,3
"Revert ""[FLINK-24746][ci] Disable Alibaba maven mirror""This reverts commit 35b8d8b984bc023619d70267af51bfdba417dbc2.",5
[FLINK-24746][ci] Use local Nexus cacheEach machine now has their own Nexus instance.,1
[FLINK-24806][connectors/rabbitmq] Fix container startup in RMQSourceITCaseThis closes #17709.,1
"[FLINK-24414][table-planner] Remove example test for left padding of decimalsAfter discussion on the issue, was decided to not support left padding of decimals,to the integral digits specified by precision-scale, as major DBs also don't supportit. Removing the example issue in the IT cast tests.This closes #17694.",3
[FLINK-24761][table] Fix PartitionPruner code gen compile failThis closes #17672,0
[FLINK-24798][cli] Bump commons-cli to v1.5.0,2
[FLINK-24665][s3] Update Presto Hadoop dependency to v2.7.4-9,5
[FLINK-24717][table-planner] Push down partitions before filters in table sourcesThis closes #17652.,2
[FLINK-24793][tests] Skip DefaultSchedulerLocalRecoveryITCase when testing AdaptiveSchedulerThis closes #17710.,3
[hotfix][table-common][tests] Add tests for LogicalTypeMerging decimal rulesAdd tests for all methods of `LogicalTypeMerging` which calculate the precisionand scale of the resulting decimal for arithmetic operations like `+ - * / % round`as well as for `avg` and `sum` aggregate functions.,1
"[hotfix][table-common] Add java docs to LogicalTypeMergingAdd more explanation in `LogicalTypeMerging#adjustPrecisionScale()` methodregarding the decision to not follow 100% the Microsoft's SQL Server rulesbut instead the Hive/Spark behaviour, when calculating the resulting precisionof a decimal operation.",2
"[FLINK-24691][table-planner] Fix decimal precision for SUMSince SUM is using internally `plus()` operator to implement the sumaggregation, the decimal return type calculated by `LogicalTypeMerging#findSumAggType()`gets overriden by the calculation for the `plus()` operator done by`LogicalTypeMerging#findAdditionDecimalType()`. To prevent this add a special`aggDecimalPlus()` operator to be used exclusively for aggregate function to avoidoverriding their calculated precision.This closes #17634.",1
[hotfix][table-planner] Add comment in codegen to specify which rule generated the castingSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][table-planner] Add codegen loggingSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][table-planner] Improved error messages in ExpressionTestBaseSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24684][table-planner] Add to-string cast rules using the new CastRule stackSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17658.,2
[FLINK-24822][table-planner] Improve subclasses of CatalogTableSpecBase related method parameterThis closes #17721,2
[FLINK-24738][runtime] Ignoring buffer size announcement if the subpartition view has not created yet,1
[FLINK-24615][table] Add infrastructure to support metadata for filesystemSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17544.,2
[FLINK-24658][runtime] Added debug logs for BufferDebloater,2
[FLINK-24501][table-runtime] Stores window progress into state in order to check whether an input element is late or not for window-tvf aggregate operatorThis closes #17509,1
[FLINK-24001][table-runtime] Window table-valued function operator support proctime windowThis closes #17673,1
[FLINK-24667][runtime] Fix error handling in ChannelStateCheckpointWriter- Don't propagate single checkpoint failure to prevent exiting from  ChannelStateWriteRequestExecutorImpl loop- Handle error during closing the stream- Swap suppressed exceptions to prevent them from piling up in the  stacktrace,0
"[FLINK-21289][deployment] FIX missing load pipeline.classpaths in application mode, for both k8s and yarnThis closes #14891.",0
[FLINK-24816][rabbitmq] Bump amqp-client to v5.13.1,2
[FLINK-24816][rabbitmq] Bump RabbitMQ testcontainer to v3.9.8,3
[FLINK-24825][nifi] Update nifi-site-to-site-client to v1.14.0,5
[FLINK-24828][tests][testinfrastructure] Bump Powermock to v2.0.9,5
[FLINK-24771][jdbc][tests] Bump test dependencies mariadb-java-client to 2.7.4 and mysql-connector-java to 8.0.27,5
"[FLINK-24227][connectors] Improved AsyncSink base by adding a builder, adding more commonly used metrics, more java docs around certain implementation tips, and a fatalException callback. Using a builder to build AsyncSinkWriterTest mocks, added test to test timing, fixed setCurrentSendTimeGauge so that no race conditions may occur, changed protected fields to private and installed protected getters. Removed MetricGroupMocks and using existing mocks, made build() public in AsyncSinkBase. Made the exceptionConsumer a field. Reverted the signature of submitRequestEntries now that the exception consumer is a protected field, Changed consumer to private variable with getter",1
[hotfix][tests] Replace MockOperatorStateBackend with default,1
[FLINK-24818][state] Correct the ttlConfig comment in StateDescriptorThis fix #17714.,0
[FLINK-24040][metrics][slf4j] Catch NoSuchElementExceptions,2
[FLINK-24827][build] Bump maven-dependency-plugin to 3.2.0,2
[FLINK-24800][tests] Ignoring testDisablingBufferTimeout test,3
[FLINK-23696][connectors/rabbitmq] Fix RMQSourceTest.testRedeliveredSessionIDsAck test,3
[FLINK-24639][kinesis] Add UniformShardAssigner (#17583),1
[FLINK-24834][connectors / filesystem] Add typed builders to DefaultRollingPolicyThis closes #17731,1
[FLINK-24741][connectors/filesystem] Deprecate FileRecordFormat and update the javadoc appropriately.,2
[FLINK-24765][kafka] Bump Kafka version to 2.8By bumping the kafka version to the latest 2.x release we include thelatest patches of Kafka which should harden our tests.,3
[FLINK-24765][kafka] Mark tests which are unstable in the IDE,3
[FLINK-24765][tests] Use DockerImageVersions to reference Kafka docker image,2
[FLINK-24733][connector/pulsar] Data loss in pulsar source when using shared mode,1
[FLINK-23014][table-planner] Support streaming window Deduplicate in plannerThis closes #17632,1
"[FLINK-24383][streaming] Remove the deprecated SlidingTimeWindows, TumblingTimeWindows, BaseAlignedWindowAssigner.",4
[FLINK-24755][docs] Document solution for 'package sun.misc does not exist' with JDK 11,2
[FLINK-24455][tests]FallbackAkkaRpcSystemLoader checks maven exit code,5
[FLINK-24800][runtime] Changed the assert condition for checking buffer timeout disabling test,3
[FLINK-24724][build] Update japicmp jaxb dependencies,5
[FLINK-23990][runtime-web] Replace custom monaco editor with nz-code-editor,2
[FLINK-23990][runtime-web] Lazy load exception editors and add strong typed,1
[FLINK-24774] Adaptive scheduler notifies listeners for all job state transitions,2
[FLINK-24773][kafka] Fail job if unhandled exception occurs during committingUnhandled exceptions during committing usually imply that data is lost.We should not only log and continue processing but fail the job to givethe user the choice what should be done.,1
[hotfix][table-planner] Add ExpressionCodeGeneratorCastRule extracting generateExpression from AbstractExpressionCodeGeneratorCastRuleSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][table-planner] Fix primitives/boxed primitives behaviour of ExpressionEvaluatorSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24779][table-planner] Add numeric casting rulesSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17738.,2
[hotfix][table-planner] Move all casting rules to casting package and make them package-privateSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24552][tests] Moved randomization of buffer debloat from StreamEnvironment to MiniClusterResourceThe reason we moved it is that it is not possible to configure it via StreamEnvironment.This closes #17581,5
[hotfix][table-planner] Move EnrichedRowData to table-runtimeSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17753.,2
[hotfix][tests] Make RpcEndpointTest more informative,5
[FLINK-22419] Wait unlimited in RpcEndpointTest.testCallAsyncTimeout,3
[hotfix][runtime] fix formatting in MiniClusterResource,5
[FLINK-24887][rest] Add CompletedOperationCache#containsOperation,1
[FLINK-24887][rest] Triggers do not check previous result,2
[FLINK-24784][runtime] Enable state.backend.latency-track.state-name-as-variable by default,0
[FLINK-24690][runtime] Changed the calculation of reaching buffer debloat threshold into more expected way,4
[FLINK-24685][table] Let planner offer RowData to string casting for printingSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17739.,2
"Revert ""[FLINK-24724][build] Update japicmp jaxb dependencies""This reverts commit 76fdff9d54ffeb2ab68137218593119955fe7ee2.",4
[FLINK-24586][table] SQL functions should return STRING instead of VARCHAR(2000)This closes #17691.,1
[FLINK-24869] flink-core should be provided in flink-file-sink-commonflink-core should be provided in flink-file-sink-common,2
[FLINK-24689][runtime-web] Add log's last modified time in log list viewThis closes #17698.,2
[hotfix][testutils] Read result files recursively,2
"[hotfix][yarn-tests] drop assertion on streaming word count outputThe modern FileSink keeps output files hidden until a bucket roll;based on time, file size, or checkpoint. This is different fromDataStream#writeTextFile which always writes visible files. Therolling behavior makes checking job output flakey, however, thatis not really the point of this test so it is dropped.",4
[hotfix][e2e] Run kerberos test under AUTOMATIC execution,3
[FLINK-24830][examples] Update DataStream WordCount exampleThis closes #17760,5
"[FLINK-24864][metrics] Release TaskManagerJobMetricGroup with the last slot rather than taskMotivation:TaskManagerJobMetricGroup might be used by components shared across tasks of a job(e.g. ChangelogStorage). The lifecycle of those is bound to slots rather than tasks(for various reasons including performance).Releasing them differently causes those metrics to be not reported.Besides that, this simplifies release code in TaskManagerJobMetricGroupand makes its lifecycle more consistent (creation and deletion in thesame place).",4
[FLINK-24875][ci] Move e2e job definition into separate template,5
[FLINK-24875][ci] Add group parameter to e2e job,2
"[FLINK-24875][ci] Eagerly create cache directoriesThe cache task fails if the cache directory does not exist, which can happen if you get a cache miss and no test creates said directory.",1
[FLINK-24875][ci] Split e2e tests into 2 groups,3
[FLINK-24839][fs-connector] Increase Timeout of FsStreamingSinkITCaseBase to 240This closes #17803,1
[FLINK-24831][examples] Update DataStream Window examples,5
[FLINK-24635][examples] Fix deprecations in Twitter example,0
[FLINK-24635][examples] Fix deprecations in state machine example,0
[FLINK-24635][examples] Fix deprecations in socket example,0
[FLINK-24635][examples] Fix deprecations in window join example,0
[FLINK-24635][examples] Fix deprecations in side output example,0
[FLINK-24635][examples] Fix deprecations in iterations example,0
[FLINK-24635][examples] Fix deprecations in async example,0
[hotfix][examples] Replace StreamingFileSink with FileSink,2
[FLINK-24635][examples] Fix deprecations in changelog socket example,4
[FLINK-24833][examples] Prevent use of deprecated APIs in flink-examplesThis closes #17802,2
"[FLINK-24776][table] Clarify DecodingFormat and introduce ProjectableDecodingFormatClearly separates projectable formats from non-projectable formats. Before this,the semantics were not 100% clear which led to inconsistent connector and formatimplementations.The FileSystemTableSource has been updated to distinguish betweenthose two interfaces now. Users that implemented custom formats forFileSystemTableSource might need to verify the implementation.For convienience, we introduces helper classes such as ProjectedRowDataand Projection to ease the implementation.This closes #17768.",5
"[FLINK-24409][kafka] Fix collection of KafkaSourceReaderMetrics for topics containing periodsInternally, Kafka translates the periods in topic names to underscore.This led to that Flink could not collect the metrics and logged awarning. With this commit we also translate the topic name before tryingto collect the metrics.",1
[FLINK-24409][kafka] Log PendingRecords metrics name if record lag collection fails,0
[FLINK-24631][k8s] Use a stable subset of labels to select jobManager and taskManager podsThis closes #17685.,1
[FLINK-24656][docs] Add documentation for window deduplicationThis closes #17651,2
[FLINK-24889][table] Support casting MULTISET to STRINGThis closes #17786.,1
[hotfix][coordination] Improve hint to build akka RPC system.,5
[FLINK-24366][runtime] Don't log error for failed task restore if the task is already canceled.,0
[FLINK-24255][tests] Test environments respect configuration when being instantiated.This closes #17240,5
[FLINK-23842][coordination] Add logging statements in SourceCoordinators for reader registration and split requests.This closes #16867,2
[FLINK-24835][table-planner] Fix bug in `RelTimeIndicatorConverter` when materialize time attribute fields of regular join's inputsThis closes #17733,0
[FLINK-24616][connectors][table] Add metadata from FileStatus in FileSystemTableSourceThis closes #17776.,5
"[FLINK-24608][table-planner][table-runtime] Insert rowtime into StreamRecord for SinkProvidersPreviously, sinks built using the unified sink framework were missing the `timestamp`from the `StreamRecord` when used with `TableAPI`. Introduce a new Operator which setsthe timestamp to each `StreamRecord` from the corresponding field of each row.This closes #17759.",1
[hotfix][table-planner][tests] Use static imports to avoid qualifiers,2
[hotfix][table-planner][tests] Remove unnecessary `throws Exception`,4
[FLINK-23381][state] Back-pressure on reaching state change to upload limit,4
[FLINK-24918][state] Support to specify the data dir for state benchmarkThis closes #17846.,5
[FLINK-24781][table-planner] Added CastRule#canFail and make sure ScalarOperatorGens wraps the cast invocation in a try-catchSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24781][table-planner] Add string parsing methods to BinaryStringDataUtil and add from string cast rulesSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24781][table-planner] Refactor cast of literals to use CastExecutorSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17800.,2
[FLINK-24928][ui] Improve isNilThis improves the type signature of isNil such that it acts as a typeguard.,1
"[FLINK-24928][ui] Remove deepFinddeepFind was inherently type-unsafe, and actually not really needed inmost cases as we can use selector functions instead.This actually surfaced several type mismatches were paths given todeepFind didn't exist on the interface.",1
[FLINK-24928][ui] Introduce angular-testing-libraryThis commit aims to improve available infrastructure for writing unittests in Flink UI.,2
"[FLINK-24928][ui] Remove ""Interface"" suffix from interface namesThere's no reason to have such a suffix and it only adds noise.",1
"[FLINK-24928][ui] Improve type-safetyNote that this is only a partial improvement. It focuses on usingexplicit visibility modifiers, making use of readonly, reordering classmembers, and some other minor things.",1
[FLINK-24928][ui] Prevent runaway recursion on NaN value,1
"[FLINK-24928][ui] Remove SafeAnyThere is nothing ""safe"" about any, and in fact this already surfacedseveral issues. We should not only discourage but prevent the use of anygoing forward, so this commit removes this helper type and fixes typeswhere it was used to the possible extent without changing behavior.",4
[FLINK-24928][ui] Rename interfaces CheckPoint to Checkpoint,2
[FLINK-21639][docs] docs still state that AsyncWaitOperator is not chainableCo-authored-by: liliwei <hililiwei@gmail.com>Co-authored-by: David Anderson <david@alpinegizmo.com>,1
[hotfix][e2e] Adds missing quotesThere's going to be a parsing issue reported if no parameter is passed due tothe if condition being rendered to [ == '1' ]. Adding the quotes fixes thisproblem.,0
[FLINK-24113] Add option to disable automatic shutdown in application mode,1
[FLINK-24113][tests] Migrate ApplicationDispatcherBootstrapTest to JUnit 5,3
[FLINK-24113] Refactor ApplicationDispatcherBootstrap#clusterShutdownFuture- rename to bootstrapShutdownFuture- simplify logic,2
[FLINK-24113][tests] Reduce duplication in ApplicationDispatcherBootstrapTest,3
[FLINK-24775][coordination] move JobStatus-related metrics out of ExecutionGraph,4
[hotfix] Remove MetricGroup parameter from EG builder,2
[FLINK-24903][coordination] Harden AdaptiveSchedulerTest,3
[FLINK-24876][docs] Remove metrics limitation of Adaptive Scheduler,4
[FLINK-24964] Upgrade frontend-maven-plugin to 1.11.0,2
[FLINK-24708][table-planner] Fix wrong results of the IN operatorThis closes #17806,1
[FLINK-24495][python][tests] Upgrade virtualenv versionThis closes #17877.,3
[FLINK-24937][e2e] Return correct exit code in build_imageThis closes #17823.,1
[FLINK-24739][docs] Add backreference from the deployment mode of a resource provider to the high-level deployment mode overview.,1
[FLINK-24739][docs] Highlight the fact that the Application Mode excpects user jars to be bundled with the Flink distribution.,2
[FLINK-24991] FlinkStatistic compiles on later Scala versions,2
[FLINK-24992] StreamingWithStateTestBase compiles on later Scala versions,3
[FLINK-25004][build] Disable spotless on Java 17,2
[FLINK-24989][build] Bump shade-plugin to 3.2.4,2
[FLINK-24988][build] Upgrade lombok to 1.18.22,2
[FLINK-24990][tests] Make InMemory[Async]LookupFunction public,1
[FLINK-25005][build] Add java17-target profile,2
[FLINK-24981][build] Fix profile activations for JDK 12+,2
[FLINK-24993][core] Harden ExceptionUtils against changes to exceptions,4
[FLINK-24986][tests] Replace anonymous StreamStateHandle class,0
[hotfix][tests] Move assertions closer to test bodiesThis allows to add metrics to TaskManagerMetricGroupwithout changing the tests and improves readability.,1
[FLINK-23486][state] Add changelog storage metrics,4
[FLINK-24763][fs-connector] LimitableReader should swallow exception when reached limitThis closes #17792,1
[FLINK-24861][connector][jdbc] Support to disable caching missing key for lookup cache (#17754),1
"[FLINK-24958][docs] Fix the link and typo in SQL ""Joins"" page (#17832)",2
[FLINK-24583][connectors/elasticsearch] Improve teststability by blocking until all records have been acknowledged by Elasticsearch,3
[FLINK-24832][tests][testinfrastructure] Update JUnit5 to v5.8.1,3
[FLINK-24627][tests] Port JUnit 4 rules to JUnit5 extensions,3
[FLINK-24979][build][hbase] Remove MaxPermSize setting,1
[FLINK-24983][build] Upgrade surefire to 3.0.5-M5,2
[FLINK-24984][ci] Rename MAVEN_OPTS variable,2
[FLINK-24138][tests] Introduce architectural tests,3
[FLINK-24985][tests] Relax assumptions of stacktrace layout,3
[FLINK-24802][table] Improve cast ROW to STRING,1
[FLINK-24996][ci] Update CI image to contain Java 17,5
[FLINK-25042] Allow calls to @VisibleForTesting from inner classes,3
[FLINK-24858][core] Prevent version mismatches in TypeSerializersBefore this commit some serializers handled the version informationincorrectly in the corresponding serializer snapshot which could leadduring eagerly instantiation that the wrong version of the serializerwas used to deserialize the data.,5
[FLINK-24922][docs]Fix spelling errors in the word parallism (#17807)Co-authored-by: xiangqiao <xiangqiao@kuaishou.com>,0
[FLINK-24760][docs] Update user document for batch window tvf (#17670),2
[FLINK-24294][refactor][core] Created AutoCloseableRegistry as alternative of CloseableRegistry only for AutoCloseable,1
[FLINK-24294][streaming] Register all stream task resources to one closer in order to avoid the resources leakThis closes #17701,2
[refactor][core] Removed unused method addCloseableInternal in AbstractAutoCloseableRegistry,1
[FLINK-25039][build] Disable shading of test jar by default,3
[FLINK-24982][tests] Fix file leak,2
[FLINK-25058][tests] Consider exceptions for API annotation scanning,3
[hotfix][csv] Remove duplicate code,4
[FLINK-24963][yarn] Improve output of queue names,1
[hotfix][git] Add 'flink-python/.idea/' to .gitignore file,2
[FLINK-25061][tests] Add assertj in flink-parentSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
"[hotfix] Add our code quality guide in the ""verifying this change"" section of the PR templateSigned-off-by: slinkydeveloper <francescoguard@gmail.com>",2
[FLINK-24971][tests] Adding retry function for failures in Bash e2e tests,3
[FLINK-25064][rest] Remove incorrect @VisibleForTesting,3
[hotfix][tests] Extract originOwner variable,4
[FLINK-25063][tests] Allow @VisibleForTesting calls from enclosing class,3
[hotfix][tests] Allow @VisibleForTesting calls from static inner classes,3
[FLINK-25067][doc] Correct the description of RocksDB's background threads for flush and compaction,5
"[FLINK-24227][connectors] Introduced maxRecordSizeInBytes and changed the behaviour of flushOnBufferSizeInBytes, renamed all instances of flushOnBufferSizeInBytes to maxBatchSizeInBytes to reflect the new behaviour of this parameter (#17913)",2
[FLINK-24543][runtime] Avoid possible inconsistencies of ZookeeperStateHandleStore in case of unstable connection.This closes #17607.,0
[FLINK-24789][runtime] Close CheckpointCleaner after checkpoint services in `DefaultScheduler#closeAsync()` and `AdaptiveScheduler#closeAsync()`.'This closes #17693.,4
"[FLINK-22775][cassandra][tests] Lower write consistency level to ANYThis consistency level is only available on write, so we need to create one builder for reading and one for writing. Some sinks are used for both reading and writing, in that case, reading builder is used.",1
[FLINK-24763][parquet] Ignore unstable ParquetFileSystemITCase.testLimitableBulkFormatThis closes #17923,5
"[hotfix][docs] Fix typo of ""Limitation"" in ""State Schema Evolution"" page (#17707)",2
[FLINK-23798][state] Avoid using reflection to get filter when partition filter is enabled,0
[FLINK-20370][table] part1: Fix wrong results when sink primary key is not the same with query result's changelog upsert keyThis closes #17699,4
[FLINK-24325][connectors/elasticsearch] Remove Elasticsearch 5 from connectors,4
[FLINK-24325][connectors/elasticsearch] Extract common unified Elasticsearch sink for versions 6 and 7,4
[FLINK-24325][connectors/elasticsearch] Integrate common unified Elasticsearch sink with Table API for versions 6 and 7,2
[FLINK-24325][connectors/elasticsearch] Migrate KeyExtractorTest to JUnit 5 and remove dependency on deprecated TableSchema,4
[hotfix][connectors/elasticsearch] Fix license formatting,0
[hotfix][connectors/elasticsearch] Move files from streaming.connectors.elasticsearch.table to connector.elasticsearch.table,2
[FLINK-24325][connectors/elasticsearch] Make ElasticsearchSinkBuilderBase type-capturing,1
[FLINK-24325][tests] Update Elasticsearch CI tests,3
[FLINK-21327][table-planner-blink] Support window TVF in batch mode (#17666),1
"[FLINK-25065][docs] Update document for ""lookup.cache.caching-missing-key"" option for jdbc connector (#17918)",5
[FLINK-21407][doc][formats] Add formats to DataStream connectors doc,2
[FLINK-21407][doc][formats] Move haddop input and output formats to hadoop.md formats page,1
[FLINK-21407][doc][formats] Update hadoop doc,2
[FLINK-21407][doc][formats] Drop old formats,4
[FLINK-21407] bump microsoft-hadoop-azure version,2
[FLINK-21407][doc][formats] Split DataSet connectors page into different formats and create a formats sub-folder like in table api doc,2
[FLINK-24596][table] Allow using unified Sinks with the DataStreamSinkProvider,5
[FLINK-24596][core] Introduce SerializableFunction and unify usages,1
[FLINK-24596][kafka] Make passed lambdas of UpsertKafka serializable,4
[FLINK-21214][kafka/IT] Add retry rule for FlinkKafkaProducerITCase,2
[FLINK-24848][rest] Return 404 for unknown operation,2
[FLINK-25080][tests] Move TestingUtils to flink-core,2
[FLINK-25080][tests] Remove dependency on Acknowledge class,4
[FLINK-25080][tests] Move ManuallyTriggeredScheduledExecutor to flink-core,2
[FLINK-25080][tests] Move tests to flink-core,2
[FLINK-25047][table] Resolve architectural violationsThis closes #17898.,0
[hotfix][examples][build] Fix typo,2
[FLINK-22769][yarn] Allow Yarn to ship symlinks[FLINK-22769][flink-yarn]add unit test for listFilesInDirectory with Symbolic linkThis closes #15999.,2
[hotfix] Use Hamcrest assertThat in FileUtilsTest,3
[FLINK-24507][table] Cleanup DateTimeUtilsThis closes #17878.,5
[FLINK-24046][state] Refactor the EmbeddedRocksDBStateBackend configuration logicThis closes #17874.,2
[FLINK-24980] Introduce numBytesProduced counter into ResultPartition to record the size of result partition.This closes #17905.,2
[FLINK-25060][table-common] Replace projection methods of FLINK-24399 with the new Projection utilThis closes #17906.,1
[FLINK-15493][test] Inherit retry rule annotations to sub classes,1
[FLINK-15493][test] Add retry rule for all tests based on KafkaTestBase,3
[FLINK-25075][table] Refactored PlannerExpressionParser to avoid instantiation through reflectionsThis closes #17931.,4
[FLINK-25112][tests] Remove cache-ttl for Java e2e tests,3
[FLINK-25092][tests][elasticsearch] Refactor test to use artifact cacher,1
[FLINK-25093][tests] Refactor test to use retry function for cloning Flink docker repo,2
[FLINK-24902][table-planner] Port integer numeric -> boolean and boolean -> numeric to CastRuleThis closes #17911.,2
"[hotfix][ci] Properly setup cron builds for 1.13+Azure was only running cron jobs for older releases because it cached some outdated configuration. We recently synced the cron schedules, which disabled cron jobs for anything but master, as this is what was configured in the azure file.",2
[FLINK-25079][test-utils-junit] Add new assertj style assertions in FlinkAssertions to replace FlinkMatchers,2
[FLINK-25079][table-common] Add some initial assertj assertions for table data and types apis,5
[FLINK-25079][table-common] Refactored some tests to use the new assertionsThis closes #17932.,3
[FLINK-21467] Clarify javadocs of Bounded(One/Multi)Input interfacesWe clarify contracts of Bounded(One/Multi)Input interfaces. Especiallyadding a warning none of those interfaces should be used for commitingside effects.,1
"[FLINK-25134][test] Remove unused RetryRule from KafkaConsumerTestBaseBefore this commit the RetryRule actually prevented retries of testsinheriting from KafkaConsumerTestBase. Now, the retries are handled byKafkaTestBase and all subclasses have the same retry behaviour.",1
[FLINK-24919][runtime] Getting vertex only under synchronization,1
[refactor][runtime] CheckpointStatsTracker passed to CheckpointCoordinator via constructor as not null parameter,2
[FLINK-25071][parquet] SerializableConfiguration should not load resourcesThis closes #17987,5
"[FLINK-24902][table-planner] Add back support for casting decimal to booleanSince FLINK-24576 and the relevant CALCITE-4777 are still open, add backthe support to cast from decimal/float/double to a boolean with a commentto remove in the future, pointing to that issue.This closes #17984.",0
[FLINK-23791] Enable RocksDB info log by default,2
"Revert ""[hotfix][ci] Properly setup cron builds for 1.13+""This reverts commit cf454ddf18a062b6c46f7074b29057e39bb13820.Turns out you can't configure cron builds for other branches on master.",5
"[FLINK-24227][connectors/kinesis] Moved AWS general utils to base connector, Updated AWS SDK v2 dependency to meet convergence criteria, Updated async http client creation with new defaults",1
"Update file_sink.md[FLINK-25091] change Official website document ""FileSink"" orc compression attribute reference error",0
"Update file_sink.md[FLINK-25091] change Official website document ""FileSink"" orc compression attribute reference error",0
[Hotfix] Fix typos.,2
[FLINK-24859][doc][formats] Make new formats name coherent,1
[FLINK-24859][doc][formats] document text file reading,2
[FLINK-24859][doc][formats] document parquet file reading,2
Address review comments,1
[FLINK-25150][API] Fix the violation of api annotationThis closes #18002.,0
"[hotfix][table-runtime Improve performance of UpdatableRowDataUse a `BitSet` instead of `boolean[]` to use less memory and speed upresetting all fields to ""not-updated"" when setting a new delegate row.",1
[FLINK-24753] Implement CHAR/VARCHAR length validation for sinks- Create a new `ConstraintValidator` operator that implements the existingNOT NULL constraint for sinks- Implement the new CHAR/VARCHAR length validator inside this new operatorThis closes #17811.,1
[FLINK-24813][table-planner] Improve ImplicitTypeConversionITCaseThis closes #17771,1
[FLINK-24506][config] Adds checkpoint directory to CheckpointConfigThis enables the user to pass in the checkpoint directory through the Flinkconfiguration again. This fixes an issue that was introduced by FLINK-19463.,2
[hotfix] Migrates CheckpointConfigFromConfigurationTest to Junit5,3
[hotfix] Make IncrementalLocalKeyedStateHandle serializable by copying sharedStateHandleIDs,0
[hotfix][tests] Remove Mocking from TaskLocalStateStoreImplTestMockito's spy prevented TaskLocalStateStoreImplTest from succeeding because a mockcannot be serialized.,1
[hotfix][table-runtime] Update copyright for some filesystem classesSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][dist] flink-json and flink-csv are now declared as dependencies in the flink-dist to enforce the reactor orderSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][connectors] Every connector now shades the flink-connector-base in its uber jarSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24687][table-common] Fix the Table Factory loading mechanism to tolerate NoClassDefFoundError. Added a test and converted FactoryUtil to use assertj.Signed-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24687][table-planner] Remove planner dependency on FileSystemConnectorOptionsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24687][parquet] Copied DecimalDataUtils#is32BitDecimal and DecimalDataUtils#is32BitDecimal in ParquetSchemaConverter to remove the dependency on DecimalDataUtils (from planner)Signed-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-24687][table-runtime] Refactored test csv format to be independent of planner (except ScanRuntimeProviderContext.INSTANCE::createDataStructureConverter) and to implement SerializationSchema more than BulkWriterFormatFactory. Moved to a specific packageSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
"[FLINK-24687][table][connectors] Move FileSystemTableSink, FileSystemTableSource to flink-connector-files and columnar support to flink-table-commonNow table packages don't depend on flink-connector-files anymore. Fix orc and parquet format to use only common classes and not planner nor runtime classes.- [connector-files] Add @Internal to all public classes and interfaces- [orc][parquet][hive] Drop scala suffix from flink-orc and flink-parquet- [architecture-tests] Updated the violations file- [connector-elasticsearch-base] Add flink-connector-base as dependency, which was previously brought in through flink-table-api-java-bridge -> flink-table-api-java -> flink-table-common -> flink-connector-files -> flink-connector-base.- [orc][parquet] Add issue link for partition keys handling- [table-uber][dist] Now flink-connector-files is not shaded inside table-uber anymore but it's loaded in /lib in the distribution as flink-connector-files- [docs] Update sql_connectors.ymlThis closes #17897.",5
"[FLINK-25022][rest] Run jars in separate threadsUse a dedicated thread to run each jar, so that pooled threads can't keep references to user-code (e.g., in a ThreadLocal).",1
[FLINK-25161][build] Update japicmp jaxb-impl dependency for Java 11+,5
[FLINK-24227][connectors/kinesis] Relocated flink-connector-aws-base in flink-connector-kinesis shaded jar (#18010)Co-authored-by: Nuno Afonso <afonsona@amazon.com>,2
"[FLINK-17782] Add array,map,row types support for parquet row writerThis closes #17542",1
"[FLINK-25111][table-api][table-planner] Add config option to determine CAST behaviourAdd a new `ExecutionConfigOption`, so that users can choose between the legacybehaviour of CAST or the new one, including improvements and fixes.This closes #17985.",0
[hotfix][table-planner] Add class header comment to generated codeUse a class header comment to add useful configuration variables that canhelp debugging a generated class code. Added timezone and legacy behaviourinfo in this comment on the generated class implementing CAST.,5
[hotfix][build] Remove ES5 connector dependency from flink-architecture-tests,3
[FLINK-24290][table] Support structured types in JSON functionsThis closes #18018.,1
[hotfix][runtime] Remove useless method ExecutionGraph#getTotalNumberOfVertices,1
[FLINK-25031][runtime] Job finishes iff all job vertices finishThis closes #17969.,5
[FLINK-21027][state] Introduce KeyedStateBackend#isSafeToReuseKVState for opmitization hint (#17945),1
[FLINK-24777][docs] Correct description of 'Processed (persisted) in-flight data'This closes #17686.,5
[FLINK-25163][state] Replace setIncreaseParallelism with setMaxBackgroundJobs in RocksDB,5
[FLINK-24326][docs][connectors/elasticsearch] Update elasticsearch sink pages with new unified sink API (FLIP-143) implementation,1
[FLINK-25186][table-common] Fix ServiceLoaderUtil#load to work with Java 11This closes #18020.,1
[FLINK-24686][doc]Make doc clear on AsyncFunction#timeout() overriding,1
Add hints for emitting no records,1
[FLINK-23493][python] Remove the calling of child process in the beam_boot.pyThis closes #18025.,4
[FLINK-22113][table-planner] Implement column uniqueness checking for TableSourceTableThis closes #17962Co-authored-by: guanghxu <xuguangheng1995@gmail.com>,2
[FLINK-25072][streaming] Introduce description on Transformation and StreamGraphThis closes #17924.,2
[FLINK-25114][table-runtime] Remove flink-scala dependency and scala suffixThis closes #18011.,0
[FLINK-25014][table-api-java] Perform toDataStream projection case-insensitiveThis closes #18029.,5
[hotfix][table-api-java] Migrate SchemaTranslatorTest to assertj,3
[FLINK-25204][Docs] Fix Spell one more as in the DataStream interval join docs,2
"[hotfix][docs][hive] Minor update to ""Hive Read & Write "" page (#16529)",5
"[FLINK-23532] Pass a flag for draining along with EndOfDataFor the sake of unification, we want to emit EndOfData in case of stop-with-savepoint both with and without drain. This is a preparation so that we can enclose the flag inside of EndOfData.",5
"[hotfix] Remove duplicated handling of stop-with-savepoint trigger failureAfter FLINK-23741 the failure is handled in Task#triggerCheckpointBarrier, therefore we no longer need to handle it inside of StreamTask. Moreover if a failure had occured in assertTriggeringCheckpointExceptions the failed checkpoint would have not been declined.",0
"[FLINK-23532] Unify stop-with-savepoint without and with drainWe unify the stop-with-savepoint with and without drain. Both of thoseoptions follow a similar codepath.1. First of all we always emit EndOfData in case of a clean shutdown, but with a flag which determines if we should call StreamOperator#finish and flush all records.2. Secondly, we stop sources once we receive a trigger for synchronous checkpoint instead of shutting them down after the checkpoint completes.3. Lastly, we no longer wait in a synchronous mailbox loop, but instead we wait on a future in the StreamTask#afterInvoke.",5
[FLINK-23532] Remove unnecessary StreamTask#finishTask,5
[hotfix][table-common] Fix typo in ProjectableDecodingFormat,2
[FLINK-20370][table] part2: introduce 'table.exec.sink.keyed-shuffle' option to auto keyby on sink's pk if parallelism are not the same for insertOnly inputThis closes #17939,2
"[FLINK-25180][tests] Upgrade Jepsen to 0.1.19Jepsen 0.1.19 is smarter when it comes to detecting already installed dependencies, where unnecessary retries to install something can result in errors.This also required a Clojure upgrade to 1.10.0. Later patch releases are not compatible with Jepsen.The Jepsen upgrade had an odd and undocumented behavioral change where DB#teardown is called at the start of the test, presumably to clean up stuff from previous runs. However, both our dbs nor jepsen-zookeeper fail if the db hasn't been setup yet. To save time we just catch exceptions that occur during the teardown, log them, and continue as if nothing happened.",2
"[FLINK-24977][connectors/kafka] Replace ConfigOption lookup in Map<String, String> object with proper lookup in Configuration object",5
[FLINK-24372][connectors/elasticsearch] Deprecate old (pre FLIP-143) Elasticsearch connector,2
[FLINK-25189][connectors/elasticsearch] Bump Elasticsearch 7 to v7.15.2,2
[FLINK-25189][connectors/elasticsearch] Bump Elasticsearch 6 to 6.8.20,2
[FLINK-25189][docs][connectors/elasticsearch] Update supported versions on Elasticsearch connector page,1
[FLINK-25052][table-planner] Port row to row casting to CastRuleThis closes #18027.,2
[FLINK-25156][table-planner] Support distinct type in CastRulesThis closes #18030.,1
[FLINK-24859][doc][formats] Make new formats name coherent: introduce previous names classes to indicate deprecation to the users,1
[FLINK-25011][runtime] Introduce vertex parallelism decider and default implementation.This closes #17952.,2
[FLINK-24728][tests] Add tests to ensure SQL file sink closes all created filesThis closes #17655,2
[FLINK-24489][CEP] The size of entryCache & eventsBufferCache in the SharedBuffer should be defined with a threshold to limit the number of the elements in the cacheCo-authored-by: Arvid Heise <arvid@ververica.com>,5
[FLINK-23170][state] write metadata after materialization,5
[hotfix] Change ChangelogStateBackendTestUtils#testMaterializedRestore to single thread,3
[FLINK-23170][state] add unit test for Timer Restore for different statebackends,3
[FLINK-24077][HBase/IT] Add check of row count after insert and wait explicitly for job to finish.,5
"[FLINK-24077][HBase/IT] use MiniClusterWithClientResource as @ClassRule.while using TableEnvironment in the ITCase, a Flink MiniCluster will be started/stopped automatically in the background. Since the shutdown of the MiniCluster will be called asynchronously, CollectResultFetcher will get data lost sometimes based on race conditions and the unchecked RuntimeException java.lang.IllegalStateException will be thrown that we were not aware of.The solution is to control the lifecycle of the MiniCluster manually in this test. The MiniClusterWithClientResource could be a good fit in this case.",5
[FLINK-25157][table-planner] Introduce NullToStringCastRuleThis closes #18039.,2
[FLINK-25155] Implement claim snapshot restore modeWe add a RestoreMode flag to be passed along with the savepoint path. It determines the way a snapshot should be restored from. If a CLAIM mode is specified Flink will take the ownership of the initial snapshot and will treat it as if it was created as a regular checkpoint. It might delete it at a certain point in time.,4
[FLINK-25155] Support claim mode in cli,1
[FLINK-25155] Support claim mode in rest api,1
"[FLINK-24086][checkpoint] Rebuild SharedStateRegistry only when the restore method is called for the first timeFrom FLINK-22483, the CompletedCheckpointStore will not change during task failover.So we only need to rebuild the SharedStateRegistry once, which can reduce the recovery time during failover.",0
[FLINK-25223][connectors/elasticsearch] Disable Elasticsearch 7 Testcontainer tests due to frequent CI failuresThis closes #18062.,0
[FLINK-21504][checkpoint] Return the subsumed checkpoint when adding the completed checkpoint,1
[FLINK-21504][checkpoint] Introduce notification of subsumed checkpoint,2
[FLINK-21504] Add tests to combine subsume with checkpoints and savepoints,3
[hotfix] Remove VisibleForTesting for AbstractStreamOperator#getKeyedStateBackend,1
[FLINK-25096] Fixes empty exception history for JobInitializationException (#17967),5
[FLINK-17510][tests] Enable StreamingKafkaITCase,0
[FLINK-25038][testutils] Refactor FlinkContainer to split JM and TMs to individual containers and supports HA,1
"[FLINK-25241][architecture] Add missing prefix for ArchUnitThis fails the CI if violations are removed, ensuring that the violationstore is updated properly.",5
[FLINK-25241][hotfix] Remove resolved violations,0
[FLINK-24987][streaming-java] Add explicit enum value NO_EXTERNAL_CHECKPOINTS as default for externalized-checkpoint-retention,1
[FLINK-24987][docs] Improve ExternalizedCheckpointCleanup documentation,2
[FLINK-24186][table-planner] Allow multiple rowtime attributes for collect() and print()This closes #17217.,1
"[FLINK-25126][kafka] Reset internal transaction state of FlinkKafkaInternalProducer if transaction finalization failsIn the KafkaCommitter we retry transactions if they failed duringcommitting. Since we reuse the KafkaProducers we update the usedtransactionalId to continue committing other transactions. To preventaccidental overwrites we track the transaction state inside theFlinkKafkaInternalProducer.Before this change, the state was not reset on a failures during thetransaction finalization and setting a new transactionalId failed.The state is now always reset nevertheless whether finalizing thetransaction fails (commit, abort).",0
"[FLINK-25257][TE] Let TaskExecutor use TaskExecutorBlobService interface instead of concrete BlobCacheService implementationThis commit decouples the TaskExecutor from the BlobCacheService implementation by introducing a TaskExecutorBlobServiceinterface that abstracts the concrete implementation details away. Due to this change we also introduced a JobPermanentBlobServiceto decoupled the TaskExecutor from relying on the PermanentBlobCache implementation. Moreover, this commit introduces aNoOpTaskExecutorBlobService that simplifies testing.This closes #18081.",3
[hotfix][docs] Fix typo in textLines parameter for Map transformation,2
[FLINK-25240][build] Upgrade Log4j2 to 2.15.0,2
[hotfix][docs] Update Log4j version in Gradle template,2
[FLINK-20195][coordination] Deduplicate jobs for overview,2
[FLINK-25266][tests] Disable StreamingKafkaITCase,3
[FLINK-25159][tests] Disable broken E2E tests,3
[FLINK-25159][tests] Fix rule usage,0
[FLINK-25159][tests] Streamline E2E surefire setup,1
[FLINK-23937][Documentation] Fix PQ comment in KeyGroupPartitionedPriorityQueue (#16957),0
[hotfix][docs] Improve the description of JDBC docs (#17661),2
[FLINK-25229][table] Introduce flink-table-api-bridge-baseThis closes #18065.,2
[hotfix][docs][connectors] Add missing comma,1
[FLINK-25153] Inappropriate variable naming (#18003),2
[FLINK-25245][ci] Support Java 11 for docker e2e tests,3
[hotfix][docs] Fix Scala example for MiniCluster testThis closes #17949,3
[FLINK-22096][tests] Fix port conflict for ServerTransportErrorHandlingTest#testRemoteClose,3
[FLINK-25020] Properly forward exception,2
[FLINK-25222][tests] Remove NetworkFailureProxy used in Kafka testsWe suspect that the NetworkFailureProxy is causing constant connectivityproblems to the brokers during testing resulting in either networktimeouts or corrupted results.Since the NetworkFailureProxy is only used for testing the deprecatedFlinkKafkaProducer/Consumer we can safely remove it because we will notadd new features to the connectors.,1
[hotfix][tests] Close Kafka AdminClients to prevent resource leaks,3
[hotfix][tests] Await broker shutdown during KafkaTestEnvironmentImpl#shutdown,3
[FLINK-24565][avro] Port avro file format factory to BulkReaderFormatFactoryThis closes #17520,2
"[FLINK-24232][coordination] Skip history server archiving for suspended jobsDo not create an archive for suspended jobs, as this would eventually lead to multiple archive attempts which we currently do not support.",1
"[FLINK-24413][table] Apply trimming & padding when CASTing to CHAR/VARCHARApply trimming when CASTing to `CHAR(<length>)` or `VARCHAR(<length>)`and the length of the result string exceeds the length specified.Apply padding to the right with spaces when CASTing to `CHAR(<length>)`and the result string's length is less than the specified length, sothat the length of result string matches exactly the length.This closes #18063.",1
[hotfix][table] Make use of VarCharType.STRING_TYPEReplace occurrences of `new VarCharType(MAX_LENGTH()` with new constant`VarCharType.STRING_TYPE`.,2
[hotfix][table-planner][tests] Minor fixes to remove IDE warnings.,2
[hotfix][table] Rename precision to length for CHAR/VARCHAR sink enforcerRename all `precision` references in code and docs to `length`which were introduced with: https://github.com/apache/flink/commit/1151071b67b866bc18225fc7f522d29e819a6238,2
"[FLINK-25304][table-planner][tests] Add tests for padding of fractional secondsAdd Unit and IT tests to validate the `0` padding of the fractional secondswhen casting a `TIMESTAMP` or `TIMESTAMP_LTZ` to string, so that the lengthof the fractional seconds in the resulting string matches the `precision`specified on the source type.This closes #18106.",1
[FLINK-25295][build] Update log4j2 dependency to 2.16.0,2
[FLINK-24580][Connectors/Kinesis] Make ConnectTimeoutException recoverable (#17785)* [FLINK-24580][Connectors/Kinesis] Consider ConnectTimeoutException recoverable* [FLINK-24580][Connectors/Kinesis] Use ExceptionUtils to inspect exception,1
[FLINK-25051][table-planner] Port raw <-> binary logic to CastRule,2
[FLINK-24419][table-planner] Trim to length when casting to BINARY/VARBINARYThis closes #17919.,2
[FLINK-25076][table-planner] Improve vertex name for sql jobThis closes #18042,1
[FLINK-24762][table-runtime] Remove agg function: INCR_SUMThis closes #17669,1
[FLINK-24846][streaming] Ignoring completing async operator record if mailbox is closed already,1
[FLINK-25326][connectors/kafka] Fix application of log levels in KafkaUtils.createKafkacontainer,1
[FLINK-17151][table] Align Calcite's and Flink's SYMBOL typesThis closes #18107.,2
[FLINK-24862][hive]Fix hive user-defined function cannot be used normally in hive dialect (#17761),1
"[FLINK-25158][table-planner][table-runtime] Fix NULL, TRUE and FALSE string representation to uppercaseThis closes #18098.",1
[hotfix][table-planner] Fix compilation issues in CastRulesTest,3
[FLINK-25274][table-api-java-bridge] Migrate datagen connector from deprecated TableSchemaresolves #18094,0
"[FLINK-25282][table-planner][table-runtime] Move runtime code from table-planner to table-runtime- Removes the dependency on SqlFunctions from Calcite- Move DefaultWatermarkGeneratorSupplier to runtime and rename to GeneratedWatermarkGeneratorSupplier- Remove dependency on BuiltInMethod from Calcite for floor, ceil and abs- Copy from Calcite json functions in SqlJsonUtils. Now jackson and jsonpath are shipped by runtime.- Move various Flink functionsThis closes #18108.",1
[refactor] Extract addCompletedCheckpointToStore method,1
[refactor] Extract finalizeCheckpoint method,4
[refactor] Extract logCheckpointInfo,5
[FLINK-25191] Skip savepoints for recoveryThis closes #18092,2
[FLINK-25191][checkpointing] Update documentation for savepoints & failure recovery,0
"[FLINK-21068][connectors/elasticsearch] Support 'connection.request-timeout','connection.timeout', 'socket.timeout' options for elasticsearch connector.",1
[hotfix][runtime] Extract SharedStateRegistry interface,1
[FLINK-24611] Pass checkpoint ID to SharedStateRegistryCheckpoint ID will be used instead of reference countingto track shared state usage.,1
"[FLINK-24611] Register shared state on checkpoint ACKAfter changing shared state discard to subsumption,this change allows to eventually discard state ofaborted checkpoints (or not completed by the time ofjob termination).",1
"[FLINK-24611] Discard shared state on checkpoint subsumptionReference counting in SharedStateRegistry is replaced withlowest checkpoint ID for each state artifact.Once that checkpoint is subsumed, the artifact is deleted.This allows to avoid re-uploading state artifacts when acheckpoint is aborted.",1
"[FLINK-24611] Discard shared state on job terminationDiscard shared state of not subsumed checkpoints on job termination.Do this only if:1. the job is in a globally terminal state. Otherwise,it can be a suspension, after which this state might still be needed.2. and checkpoint is not retained (it might be used externally)3. and checkpoint handle removal succeeded (e.g. from ZK) - otherwise, it mightstill be used in recovery if the job status is lost",1
"[FLINK-24611] Don't re-upload unconfirmed RocksDB SSTJM behavior was changed to discard shared state ofall checkpoints, including aborted, only on subsumption;therefore, uploaded files can be re-used now regardless ofcheckpoint confirmation by JM or abortion.",5
"[FLINK-24611] Adjust shared state entry de-duplicationBecause shared state is now registered before checkpoint completionit is possible that a new state should be kept in case of collision:1. Flink recovers from a failure using a checkpoint 12. State Backend is initialized to UID xyz and a set of SST: { 01.sst }3. JM triggers checkpoint 24. TM sends state handle: ""xyz-002.sst""; JM registers it under the key: ""xyz-002.sst""5. TM crashes; everything is repeated from (2)6. TM recovers from checkpoint 1 to the same state as in (2): backend UID ""xyz"", SST { 01.sst }7. JM triggers checkpoint 38. TM sends NEW state ""xyz-002.sst""9. JM discards it as duplicate10. checkpoint completes, but a wrong SST file is used(omitted KG range here for simplicity)",1
[hotfix] Update DeactivatedCheckpointCompletedCheckpointStore javadoc,2
[FLINK-24227][connectors/kinesis] Moved utilities files from flink-connector-kinesis to new module flink-connector-aws-kinesis-data-streams in readiness for new sink,1
[FLINK-24227][connectors/kinesis] Added Kinesis Data Streams Sink into a new module flink-connectors/flink-connector-aws-kinesis-data-streams,5
"[FLINK-24227][connectors/kinesis] Removed dependency on AWS SDK v1, separated user agents, moved common utils to separate class, rolled back dependency on AWS SDK v2 to match other connectors, Moved general defaults to new more general class",1
"[FLINK-24227][connectors/kinesis] Fixing Backward Compatibility for AWSConfigConstants Class, Removing dependency on assert in tests.",3
[FLINK-25223][connectors/elasticsearch] Limit Elasticsearch testcontainer memory allocation,3
[FLINK-25175][table-api] Introduce TableDescriptor.forConnector,2
[FLINK-25174][table-api] Introduce Catalog.supportsManagedTable,2
[FLINK-25174][table] Introduce ManagedTableFactory,2
[FLINK-25174][table] Implement callback for managed tableThis closes #18088,2
[FLINK-25147][connectors][test] Migrate Cassandra connector tests to testContainers,3
[FLINK-24846][streaming] Guava import fix in AsyncWaitOperatorTest,3
[hotfix][checkstyle] Forbidding to import org.testcontainers.shaded,3
[FLINK-23375][connector/jdbc] Build JDBC test jar.,3
"[FLINK-25192][checkpointing] Implement no-claim mode supportWe introduce NO_CLAIM restore mode in which we do not take ownership ofthe restored checkpoint. We do enforce the first, successful checkpointafter a restore to be ""full"" meaning it can not share any artefacts withthe initial one.Taking a ""full"" snapshot needs support from state backend, therefore weadd a method supportsNoClaimMode to the Snapshottable interface, sothat state backend can add support incrementally. If a state backenddoes not support forces snapshots, user can switch to either the LEGACYmode or CLAIM mode.This closes #18086",1
[hotfix] Make PseudoRandomValueSelector return the selected value,1
[hotfix][hack] Make ChangelogStateBackend randomized tests work with forced full snapshots,1
[FLINK-21406][parquet] Rename ParquetAvroWriters to AvroParquetWriters,2
[FLINK-21406][parquet] Add AvroParquetReaders to read parquet files into Avro types.This closes #17501.,2
[FLINK-25364][python][table-planner] Remove dependency on planner for Python code generationThis closes #18152.,4
"[FLINK-25366][table-planner][table-runtime] Implement BINARY/VARBINARY length validation for sinksSimilar to the length validation for CHAR/VARCHAR, implement the same logic forBINARY/VARBINARY and apply any necessary trimming or padding to match the lengthspecified in the corresponding type.This closes #18142.",1
"[FLINK-25215][table] ISODOW, ISOYEAR fail and DECADE gives wrong result for timestamps with timezonesThis closes #18044.",0
[FLINK-25268][yarn] Support task manager node-label in Yarn deploymentThis closes #18087.,1
[FLINK-25123][table-planner] Remove redundant info for the ExecNode's descriptionThis closes #18127,5
"[FLINK-25363][python][table] Refactor shared group window classes for Python- Move window pojos from planner to runtime, renamed and deprecated.- Refactor PythonStreamGroupWindowAggregateOperator to remove usage of LogicalWindowThis closes #18154.",2
[FLINK-25375] Update log4j2 dependency to 2.17.0 to addressCVE-2021-45105This closes #18149.,1
[FLINK-25399][tests] Disable changelog backend in testsStabilize the builds until the issue is resolved.,0
"[FLINK-25305][checkpoint] Always wait for input channel state and result partition state get completed in AsyncRunnableThis closes #18112.This PR fixes the issue that if a task is marked FINISHED_ON_RESTORE and then taking unaligned checkpoints,currently it does not include the channel states in the operators' states. This might cause that when takingunaligned checkpoints:1. The first barrier arrived.2. The unligned checkpoints would snapshot the state after the first barrier and start the asynchronous part immediately.3. The unaligned checkpoints relies on waiting till all the channel states' futures are done to ensure reporting to JM   happens after all barriers are aligned. However, if the channel states are not included, this assumption would be broken.4. If the reporting happens before all barriers are aligned, the reporting would fail due to failing to build CheckpointMetrics.",0
[hotfix][checkpoint] Fix the wrong parameters due to base code change in StreamTaskFinalCheckpointsTest,3
[FLINK-25132][connector/kafka] Move record deserializing from SplitFetcher to RecordEmitter to support object-reusing deserializer,1
"[FLINK-25365][python] Remove remaining references to planner from Python- Move DataViewSpec, ListViewSpec and MapViewSpec out of DataViewUtils and inside table-runtime- Move PythonInputFormatTableSource from PythonTableUtils and convert to Java- Converted PythonTableUtils to Java and moved to flink-python- Refactor PythonBridgeUtils to remove usage of calcite classes- Remove runtime dependency on flink-table-plannerThis closes #18156.",2
[FLINK-25085][runtime] Add a scheduled thread pool in MainThreadExecutor and close it when the endpoint is stoppedThis closes #18007.,1
[FLINK-25422][python] Specify requirements in dev-requirements.txtThis closes #18185.,5
[hotfix][docs] Minor fixes in Network Memory Tuning Guide,1
[FLINK-24481][docs] Translate buffer debloat documenation to chineseThis closes #17953,1
[FLINK-25173][table][hive] Introduce CatalogLock and implement HiveCatalogLockThis closes #18114,2
[FLINK-25429][state] Avoid to close output streams twice during uploading changelogs,4
[FLINK-25094][test] Correct the LatencyTrackingMapStateTest#verifyIteratorThis closes #18111.,3
[FLINK-23047] Ignore CassandraConnectorITCase until the flakiness of this test is fixed.This closes #18204.,0
[FLINK-24785][runtime] Relocate RocksDB's log under flink log directory by defaultThis closes #17833.,2
[FLINK-25426] Disable UnalignedCheckpointRescaleITCase because it fails regularly,0
[FLINK-25427] Disable SavepointITCase.testTriggerSavepointAndResumeWithNoClaim because it is unstable,1
[FLINK-24772][docs] Add documentation for individual window table-valued function (#17885),1
[FLINK-25446][state] Avoid improper sanity check on read bytes on DataInputStream#read(byte[]),5
[FLINK-24912][state-processor-api] Migrate savepoint bootstrapping to DataStream APICo-authored-by: Jun Qin <11677043+qinjunjerry@users.noreply.github.com>,1
[FLINK-24912][state-processor-api] Migrate savepoint reader to DataStream APICo-authored-by: Jun Qin <11677043+qinjunjerry@users.noreply.github.com>,1
[FLINK-24912][state-processor-api] Update documentation for DataStream based APICo-authored-by: Jun Qin <11677043+qinjunjerry@users.noreply.github.com>This closes #18170,1
[hotfix][jdbc] Fix method name typo in Postgres test This closes #16635,3
[FLINK-25372] Move ThreadDumpInfo out from taskmanager-specific package,5
[FLINK-25372] Add REST API for request JobManager thread-dump,1
[FLINK-25372] Add thread dump feature for jobmanager on Web UIThis closes #18148,1
[hotfix] Refactor type of states within ChangelogKeyedStateBackend,4
[FLINK-25465][state] Correct the logic of materizating wrapped changelog state,4
[FLINK-25468] Copy SST files if they cannot be hard linked in RocksDBHandle.restoreInstanceDirectoryFromPathThe RocksDBHandle.restoreInstanceDirectoryFromPath hard links SST files. If this operation does notwork because the source directory is on a different file system then it will now copy the file over.This closes #18222.,2
[FLINK-23999][table-planner] Support evaluating individual window table-valued function in planner (#17684),1
[FLINK-25474][table-planner] Fix Idea Scala plugin can not compile RexExplainUtilThis closes #18226,0
[FLINK-25147] add keyspace drop because the docker image is reused and modified by the tests.,3
[FLINK-25415] Add retries to CasandraConnectorITCaseAdd 3 retrials to all tests and to startAndInitializeCassandra() methods in CassandraConnectorITCase upon NoHostAvailableException which happens under load when cluster.connect() is called.,5
[hotfix][connectors][docs] Use big M letters for month in date format,5
[hotfix][table-planner] Code fixes for Aggregate FunctionsApply some small code optimisations for the build-in aggregate functions.,1
[hotfix][table-planner][tests] Fix test for SumWithRetractAggUse `TestValuesTableFactory` to setup the source changelog stream any makesure that the SQL query will generate `SumWithRetractAggFunction`  toimplement sum aggregations.,1
"[FLINK-24809][table-common][table-planner] Fix precision for aggs on DECIMAL typesSince `Sum0AggFunction`,`SumWithRetractAggFunction` and `AvgAggFunction` are using internally `plus()` and `minus()` operators to implement the sum and avgaggregation (`minus()` is used also for the `WithRetract`), the decimal returntype calculated by `LogicalTypeMerging#findSumAggType()` (also for the`AvgAggFunction`s internal `SumType`) gets overriden by the calculation forthe `plus()` (and/or `minus()`) operator done by`LogicalTypeMerging#findAdditionDecimalType()`. To prevent this add a special`aggDecimalMinus()` operator and use it together with the previously added `aggDecimalPlus()` in those aggregate functions to avoid overriding thecalculated precision of their decimal return type.See also FLINK-24691.This closes #18135.",2
[FLINK-25398] Show complete stacktrace when requesting thread dumpThis closes #18158.,2
"[FLINK-18295][runtime] Change result partition to explicitly have one ConsumerVertexGroup (instead of a collection of ConsumerVertexGroup)The change involves all representations of result partition, including `SchedulingResultPartition`(and all its implementations) and `IntermediateResultPartition`.",4
[FLINK-18295][runtime] Change IntermediateDataSet to explicitly have exactly one consumer vertexThe corresponding DefaultLogicalResult is updated as well.This closes #18218.,5
[FLINK-25128][table-planner][table-runtime] Move aggregate and table functions with runtime logic in runtime,1
[FLINK-25128][table-planner] Fix usage of avatica core DateTimeUtils class,5
"[FLINK-25128][table] Reorganize table modules and introduce flink-table-planner-loader- [table-planner] PlannerBase is now using the class' classloader in order to load the ParserFactory. This makes sure that it will try to load first from its own classpath, and then from the parent classpath.- [table] Removed flink-table-uber and replaced with flink-table-api-java-uber to ship only api related packages in a single uber jar- [table-runtime] Now table-runtime ships janino and code splitter.- [table-planner] Introduce table-planner loader bundle, a variant of the table-planner uber jar that includes scala, in order to be used by flink-table-planner-loader- [table-planner-loader] Introduce flink-table-planner-loader- [java-ci-tools] Add flink-table-planner-loader in the excluded modules- [dist] Rework distribution to include table-api-java-uber, table-runtime, table-planner-loader and cep in lib, while table-planner_${scala.version} in opt.- [sql-client] Rework SQL Client dependencies and remove scala suffix.- [examples][e2e] Use planner-loader wherever is possible in tests and examples- [table] Add README documenting the various modules- [table-planner-loader] Allow access to javassist from parent classpath- [table-planner] Make sure the object mapper is using the correct classloader",1
[FLINK-25128][e2e] Update tests to replace the planner jars whenever necessary to check both plannersThis closes #18134.,3
[FLINK-25472][core] Update to Log4j 2.17.1This closes #18228.,2
[hotfix][connector/source] fix comment typoThis closes #18195.,2
[FLINK-24352] [table-planner] Add null check for temporal table check on SqlSnapshotThis closes #17845,1
[FLINK-25418][python] Install dependencies offline if the cache dir is specifiedThis closes #18186.,2
[FLINK-25294][python] Fix cloudpickle importThis closes #18099.,2
[FLINK-24657][runtime] Added metric of the total real size of input/output buffers queue,1
[FLINK-24657][docs] Added outputQueueSize and inputQueueSize into metrics page,1
[refactor][runtime] Added postfix `unsafe` for methods ResultSubpartition#getTotalNumberOfBuffers and ResultSubpartition#getTotalNumberOfBytes,1
[refactor][runtime] Removed extra methods for optimization of calculation of absoluteTimeMillis for ThroughputCalculator since they haven't been used anymore,1
[FLINK-25454][runtime] Pause and resume time for throughput calculator only from one thread.,1
[FLINK-21186][network] Wrap IOException in UncheckedIOException in RecordWriterOutput,2
"[hotfix][table-planner] Assume that length of source type is respected for CASTWhen casting to CHAR/VARCHAR/BINARY/VARBINARY, we assume thatthe length of the source type CHAR/VARCHAR/BINARY/VARBINARY isrespected, to avoid performance overhead by applying checks and trimmingat runtime. i.e. if input type is `VARCHAR(3)`, input value is 'foobar' and targettype is `VARCHAR(4)`, no trimming is applied and the result value remains:`foobar`.",1
[FLINK-25187][table-planner] Apply padding when CASTing to BINARY(<length>)Similarly to `CHAR(<length>)` when casting to a `BINARY(<length>)`apply padding with 0 bytes to the right so that the resulting `byte[]`matches exaxctly the specified length.This closes #18162.,1
[FLINK-25496] Fix the compatibility issue of jdk8 and 11 in ThreadDumpInfoTest.testComparedWithDefaultJDKImplemetationThis closes #18249.,5
[hotfix][docs] Fixing multiple 404 links in docsThis closes #18234.,2
"[FLINK-16154][docs-zh] Translate ""Operator/Join"" into ChineseThis closes #14858.",1
"[FLINK-16153][docs-zh] Translate ""Operator/windows"" into ChineseThis closes #14773.",1
[FLINK-25414][metrics] Provide getMaxSingleMeasurement in TimerGaugegetMaxSingleMeasurement() returns the longest marked period as measuredby the given TimerGauge. For example the longest consecutive back pressuredperiod.,5
"[FLINK-25414][metrics] Split backPressuredTime metric into soft and hardThis will allow user to differentiate between hard (blocked) back pressuretime and soft, and also it will allow us to present the maxSoft/HardBlockedTimesseparately for sort and hard case.",5
[FLINK-25414][metrics] Expose maxSoft(Hard)BackPressureTimeMs,2
[FLINK-25414][metrics] Document maxSoft/HardBackPressureTime and soft/hardBackPressureTimeMsPerSecond metrics,5
[hotfix][hive] Remove unused LOG reference from HiveTableSourceThis closes #18243.,2
[hotfix][docs] Fix typo in name for data_stream_api.md,5
[FLINK-24857][test][FileSource][Kafka] Upgrade SourceReaderTestBase to JUnit 5,3
[FLINK-23230] Fix protoc dependency for Apple Silicon / m1 support,1
[hotfix][docs] Remove duplicate dot in generating_watermarks.md,4
"Revert ""[FLINK-25085][runtime] Add a scheduled thread pool in MainThreadExecutor and close it when the endpoint is stopped""This reverts commit 5580cd6283eec0b977e1c5351fd3cdec2956510a.",4
"Revert ""[FLINK-25427] Disable SavepointITCase.testTriggerSavepointAndResumeWithNoClaim because it is unstable""This reverts commit fe3dfbca7ac8bada810726f1568e69fea855b039.",4
"Revert ""[FLINK-25426] Disable UnalignedCheckpointRescaleITCase because it fails regularly""This reverts commit 276570e223a9b4ddb3939101b0fe3ff995ac46c5.",5
[FLINK-23946][clients] Dispatcher in application mode should be able to recover after losing and regaining leadership.This closes #17000.,5
[FLINK-25105][checkpoint] Enables final checkpoint by defaultThis closes #18068.,0
[FLINK-25477][docs] Make the directory structure of the State Backends document display correctly,2
[FLINK-25370][docs] update HBase SQL Connector Options table-name description,5
[hotfix][flink-walkthrough] Fix typo in name for archetype-resources/pom.xml,5
[FLINK-25074][datastream] Simplify name of WindowOperatorThis closes #18056.,1
[hotfix] [javadocs] Fix typo in org.apache.flink.sql.parser.ddl.SqlCreateTable,2
[FLINK-25460][core] Update slf4j-api dependency to 1.7.32,5
[FLINK-25176][table] Fix typos and migrate SqlToOperationConverterTest to use assertJ,3
"[FLINK-25176][table] Introduce ""ALTER TABLE ... COMPACT"" syntaxThis closes #18236",2
[FLINK-16152][doc-zh] Translate dev/datastream/operators/overview.md into ChineseThis closes #16889.,1
[FLINK-25427] Disable SavepointITCase.testTriggerSavepointAndResumeWithNoClaim because it is unstableThis closes #18263.,1
[FLINK-25261][state] Truncate changelog upon materialization,4
[FLINK-25340][testutils] Remove JM temp files before stopping container to avoid file permission issuesCo-authored-by: Fabian Paul <fabianpaul@ververica.com>,0
[FLINK-25263][e2e/kafka] Re-enable temporarily disabled KafkaSourceE2ECase,0
[hotfix][connector/kafka] Add Kafka connector dependency in Kafka E2E test module,3
[FLINK-25183][table] Optimize changelog normalize for the managed table upsert modeThis closes #18199,4
[FLINK-25516][table-api-java] Add catalog object compile/restore optionsThis closes #18262.,2
[FLINK-25239][connector/jdbc] delete useless variables,1
[FLINK-22821][core] Stabilize NetUtils#getAvailablePort in order to avoid wrongly allocating any used ports,1
[FLINK-25464][python] Turn on output infos for package installation in toxThis closes #18270.,5
[hotfix][doc]Fixed the problem that the Windows document Window Assigners and Window Functions of the master branch could not jump correctly.,1
[hotfix][docs] Fix incorrect Python tableEnvironment attribute reference,0
[FLINK-25010][hive] Speed up hive's createMRSplits by multi thread (#17988),1
[hotfix][connector-files][connector-hive] Move Hive specific configs out of FileSystemConnectorOptionsThis closes #18177.,5
[FLINK-25513][python] Handle properly for None result in flat_map and map of ConnectedStreamThis closes #18280.,0
[FLINK-25526][table-common] Deprecate the classes of the old factory stackThis closes #18269.,2
"[FLINK-25518][table-planner] Harden JSON utilities for serde of the persisted plan- Fixes JsonSerdeUtil to create just one instance of ObjectMapper.- Removes FlinkDeserializationContext as SerdeContext is now passed through  the Jackson built-in DeserializationContext.- Removes all usages of ObjectMapper within the Deserializers, replacing  them with proper usage of DeserializationContext.This closes #18264.",4
[hotfix][table-runtime][table-planner] Fix the shading package name of com.jayway and remove bad transitive deps,4
[FLINK-25525][examples-table] Fixed regression which doesn't allow to run the examples from IDEA,1
[FLINK-25487][core][table-planner-loader] Improve verbosity of classloading errorsThis closes #18283.,0
[FLINK-24758][filesystem]  Introduce 'partitiontime-extractor.formatter-pattern' to format extracted partition timeThis closes #17749.,4
[FLINK-24880][python] Fix PeriodicThread to handle properly for negative wait timeout valueThis closes #18292.,0
[FLINK-25228][table-test-utils] Introduce flink-table-test-utilsThis closes #18255.,3
[FLINK-25536] Adjust the order of variable declaration and comment in StateAssignmentOperation,2
[FLINK-25210][pulsar][e2e][tests] add resource file to test jar,3
[FLINK-25519][Connectors] Promote StreamExecutionEnvironment#fromSource() from @Experimental to @PublicEvolving,2
[FLINK-25510][Connectors / Kafka][tests] Add using committed offsets test cases for KafkaPartitionSplitReader,3
[FLINK-25510][Connectors / Kafka][tests] Update the validation method and add comments,1
[FLINK-25307][test] Print the curl logs is querying dispatcher startup failedThis closes #18298.,0
[FLINK-25224][filesystem] Bump Hadoop version to 2.8.5,5
[FLINK-25141][connector/elasticsearch] Add sink parallelism option,1
[FLINK-25141][docs] Add es sink parallelism option,1
[FLINK-25178][table] Throw exception when managed table sink needs checkpointingThis closes #18219,2
[hotfix][quickstarts] Fix misprints in DataStreamJob.java and DataStreamJob.scala,5
[hotfix][doc] fix typo of 'note that' and 'now that',2
[hotfix][docs] Fix type name for INTERVAL SECOND in Data Type Extraction section of types.md,4
[FLINK-25576][Connectors][JDBC] Upgrade com.h2database:h2 to 2.0.206,5
"[FLINK-25369][table] Provide tables of specified catalog/databasePreviously, CatalogManager always used the current catalog/databaserather than the specified one.resolves #18146",0
[hotfix][table-api-java] Make DataTypeFactory configurable for CatalogManager,2
[hotfix][table-common] Check for invalid unresolved types in DataTypes.of(LogicalType),5
[hotfix][table-common] Create UnresolvedIdentifier from ObjectIdentifier,0
[hotfix][table-api-java] Expose LogicalType creation in DataTypeFactory,5
[hotfix][table-common] Fix LogicalType to DataType conversion for DistinctType,5
[hotfix][table-common] Allow disabling autoboxing for DataTypeUtils.isInternal,5
[hotfix][table-planner] Make JSON plan test base more lenient for differently configured IDEs,5
[FLINK-25230][table-planner] Harden type serialization for LogicalType and DataType,5
[FLINK-25230][table-planner] Regenerate JSON plansThis closes #18274.,5
[FLINK-25032][runtime] Allow ExecutionJobVertex to be initialized lazily.,5
[FLINK-25032][runtime] Allow parallelism of ExecutionJobVertex to be decided lazily.,1
[FLINK-25032][runtime] Enable to create a dynamic graph.This closes #18023.,1
[FLINK-25266][tests] Consolidate Kafka testutils to make them part of the test jar,3
[FLINK-25266][e2e] Support job jar submission with FlinkContainers,2
[FLINK-25266][e2e] Convert StreamingKafkaITCase to SmokeKafkaITCase covering application packaging,2
"[FLINK-25362][docs] allow SQL maven artifact listIf a connector needs more than one maven dependency, these can instead bedefined as a list/array now. The old syntax with a single string is also stillpossible.",1
[FLINK-25362][docs] fix the Avro Format maven dependencyIt was falsely pointing to the shaded sql artifact.,0
"[FLINK-25362][docs] fix maven instructions for ""Confluent Avro Format""",5
[FLINK-25461][python] Update net.sf.py4j:py4j dependency to 0.10.8.1This closes #18209.,5
[FLINK-25280][connector/kafka] Disable log deletion in KafkaTestEnvironmentImpl to prevent records from being deleted during test run,1
[FLINK-25390][table-common] Introduce forwardOptions for table and format factories,2
"[FLINK-25190][coordination][metrics] Add ""numPendingTaskManagers"" metrics",1
[FLINK-25488][table] Clarify delimiters usage in STR_TO_MAP functionThis closes #18251.,1
[FLINK-25553][filesystem] Remove MapR filesystem,5
[FLINK-24884][runtime-web] use correct typeresolves #17775,0
[hotfix][python][docs] Fix typo in a description of submitting option,2
"[FLINK-24694][docs-zh] Translate ""Checkpointing under backpressure"" page into Chinese",2
[FLINK-22602][Formats][Parquet] Upgrade Parquet dependency to 1.12.2,2
"[FLINK-25107][formats/gsr] Adding support to define AWS Credential Provider from property map, fixing e2e tests",3
[FLINK-25107][formats/gsr] Migrate tests to use Assert4J,3
[FLINK-25601][state][config] Update the 'state.backend' option,5
[FLINK-25209][tests] Wait until the consuming topic is ready before polling records in KafkaContainerClient#readMessagesThis closes #18326,3
"[FLINK-25179] Add document for array,map,row types support for parquet row writer",1
[FLINK-25608][metrics] Add stability annotations,1
[hotfix][core] Fix javadoc in (Global)committer for retries.,2
[hotfix][streaming] Improve StreamGraphGenerator's performance by using a IdentityHashMap to track transformations.The already transformed transformation are copied into adifferent map and compared. If the transformation does not properlyimplement equals the isTransformed check may fail and the transformationis copied multiple times. Now that is hardened because wecheck the object reference.,1
[FLINK-25569][core] Extract public facing ProcessingTimeService to flink-core,2
[FLINK-25569][core] Mark UserCodeClassLoader as PublicEvolving,1
[FLINK-25569][core] Mark SimpleVersionedSerializer as PublicEvolving,2
[FLINK-25569][core] Add decomposed Sink V2 interface.The new interface separates concerns and will make future refactorings and extensions easier. The user immediately which methods needs to be implemented.,1
[FLINK-25531][connectors/kafka] Force immediate shutdown of FlinkInternalKafkaProducer to speed up testRetryComittableOnRetriableError,3
[FLINK-14100][jdbc] Introduce Oracle dialect for JDBC ConnectorThis closes #17676.,5
[FLINK-25441][network] Wrap failure cuase with ProducerFailedException only for PipelinedSubpartitionView.,0
[hotfix] Rename some methods of NetworkBufferPool and add more comments for better readabilityThis closes #18173.,1
"[FLINK-25407][network] Fix the issues caused by FLINK-24035This PR tries to fix the issues caused by FLINK-24035. More specifically, there are two issues, the first one is the deadlock caused by acquiring the 'factoryLock' in NetworkBufferPool and the other is the incorrect decreasing of the required segments of NetworkBufferPool. Both issues occur during exception handling of requesting segments. Actually, when reserving memory segments for LocalBufferPool, there is no need to modify the value of required segments. As a result, there is no need to acquire the 'factoryLock'. This PR fixes the issues by removing the required segments decreasing logic together with the 'factoryLock' acquiring during exception handling of requesting segments in NetworkBufferPool.This closes #18173.",1
[FLINK-25351][annotations] Introduce `FlinkVersion` as a global enumRename `MigrationVersion` to `FlinkVersion` and move it to`flink-annotations` in the`org.apache.flink` package so that is availableglobally and will facilitate the APIs and SQL/TableAPI versioningand upgrades.This closes #18340.,2
"[FLINK-24803][table-planner] Fix cast BINARY/VARBINARY to STRINGUse an hex string representation when casting any kind of`BINARY`, `VARBINARY` or `BYTES` to `CHAR`/`VARCHAR`/`STRING`, e.g.:```SELECT CAST(CAST(x'68656C6C6F20636F6465' AS BINARY(10)) AS VARCHAR)```gives:```68656c6c6f20636f6465```Apply padding or trimming if needed and also implement, the inversecast as well from the hex string to a`BINARY`/`VARBINARY`/`BYTES` type.With legacy behaviour enabled we will converting each byte to a UTF8char and the opposite.This closes #18221.",0
[FLINK-25341][table-planner] Add StructuredToStringCastRuleThis closes #18182,1
"[FLINK-24954][network] Refresh read buffer request timeout on buffer recycling/requesting for sort-shuffleThe implementation of read buffer request timeout for sorting shuffle is a little aggressive. When a running task encounters data skew or the task is slow, a timeout exception may be triggered. To improve this situation, when at least one buffer is recycled or allocated, the buffer request timeout should be refreshed to avoid throwing a timeout exception.This closes #17936.",1
[FLINK-25230][table-planner] Replace RelDataType with LogicalType serialization,2
[FLINK-25230][table-planner] Regenerate JSON plansThis closes #18342.,5
[FLINK-25392][table-planner] Support new EXECUTE STATEMENT SET BEGIN ... END; syntaxThis closes #18215.,1
[FLINK-24886][core] Let TimeUtils parse 10 m as 10 minutesThis closes #17777.,3
[FLINK-25504][Kafka] Upgrade Confluent to v6.2.2 and Kafka-Client to 2.8.1,5
[FLINK-25044][pulsar][test]: fix the messsageId overflow when set to latest,3
[FLINK-25044][pulsar][test]: improve unit test for pulsar source,3
[FLINK-25613][build] Sync surefire versions,2
[FLINK-25160][docs] Clarified purpose of execution.checkpointing.tolerable-failed-checkpoints,0
[FLINK-25167][API / DataStream]Expose StreamOperatorFactory in ConnectedStreams#transform,1
[FLINK-25167][API / DataStream]mark StreamOperatorFactory as @PublicEvolving and add the new volation,1
[hotfix][table-planner] Ignore LogicalRelDataTypeConverterTest temporarily,5
[FLINK-25570][tests] Ignore TypeSerializer tests for nested serializers based on SimpleVersionedSerializerTypeSerializerProxyBefore this commit is was not possible to use aSimpleVersionedSerializer as part of a TypeInfo becausethe TypeSerializerTestCoverageTest picked up the anonymous class andexpected a test case.,3
[FLINK-25570][streaming] Add topology extension points to Sink V2.A user may add arbitrary data stream topology before writer and before and after committer.,2
[FLINK-25034][runtime] Support flexible number of subpartitions in IntermediateResultPartition.,1
[FLINK-25034][runtime] Let InputGateDeploymentDescriptor supports subpartition range.This closes #18050.,1
[hotfix] Port DefaultSlotPoolServiceSchedulerFactoryTest to use Junit5,3
"[FLINK-25533] Forward preferred allocations into the DeclarativeSlotPoolBridgeThis commit forwards the preferred allocations into the DeclarativeSlotPoolBridge so thatnew slots can be matched against the preferred allocations.Moreover, the commit introduces a RequestSlotMatchingStrategy that is used by the DeclarativeSlotPoolBridgeto match slots to pending requests. If local recovery is enabled, then Flink will use thePreferredAllocationRequestSlotMatchingStrategy that first tries to match pending requests to slots based ontheir preferred allocation and then falls back to SimpleRequestSlotMatchingStrategy that matches solely on theResourceProfile basis.This closes #18286.",2
[hotfix] Remove @Nonnull annotations from SlotPool,4
[FLINK-10804] [core] [runtime] Transfer suppressed exceptions with SerializedThrowable[FLINK-10804] [runtime] deprecated methods are removed in SerializedThrowableSerializerTest[FLINK-10804] [runtime] SerializedThrowableSerializerTest actualizedThis closes #16506.,3
[FLINK-24444][runtime][tests] Wait until checkpoints stopped triggering,3
[hotfix][tests] Refactor scheduler factory methodsFactory methods were refactored to first create a builder that sets various defaults and then override the defaults.,1
[FLINK-23976][metrics] Add additional job status metrics,1
[hotfix] Fix the typo in RocksDBIncrementalRestoreOperation,5
[FLINK-25580][state] Improve the logic of over fraction calculate for RocksDB restoreThis closes #18305.,5
[hotfix][tests] Harden AdaptiveSchedulerTest,3
[hotfix] Add 1.15 to FlinkVersionThe upcoming version to be released need to exist already in master so thatwhen the new release branch is created from master the version of the releaseis already there.,1
"[hotfix][table-common] Introduce ObjectIdentifier.ofAnonymous to allow storing anonymous, but still uniquely identified, namesThis closes #18370.",1
[FLINK-24824][coordination] Use CREATED for WaitingForResources/CreatingEG,1
[FLINK-25278][ci] Use Maven proxy for confluent repo,5
[hotfix] Fix ArchivedExecutionConfigBuilder#setMaxParallelism,5
"[FLINK-25395][state] Don't discard changelog shared state on TMAfter FLINK-25395, shared (incremental) state can be re-usedby state backends regardless of the confirmation by JM.JM will only discard it on checkpoint subsumption or job termination.However, state can also be discarded by TM in case of failures: - AsyncCheckpointRunnable.cleanup - StreamOperatorStateHandler.snapshotState - SubtaskCheckpointCoordinatorImpl.cleanupThose cleanups might render previous checkpoints invalid.This change fixes it by removing discard calls from the Changelogstate handles.",0
"[FLINK-25395][state] Re-upload unconfirmed RocksDB shared stateRevert RocksDB backend snapshotting behavior to pre-FLINK-24611,i.e. re-upload state unless confirmed by JM.Otherwise, TM might discard shared state in case of abort or failure.That would invalidate previous or future checkpoints.Keeping that state might increase the number of orphaned filesleft on DFS, unless there is some TM-side registry or globalgarbage collection (FLINK-24852).",2
[FLINK-25589][docs][connectors] Update Chinese version of Elasticsearch connector docs,2
"Revert ""[hotfix] Add 1.15 to FlinkVersion""This reverts commit 1cd880139d90c45933018d549d7a6f394f7eee80.",4
[FLINK-24737][runtime-web] Update outdated web dependenciesresolves #17711,0
[FLINK-25193][docs] Document restore modeThis closes #18141,2
[FLINK-24858][release][docs] Recommend users to upgrade to 1.14.3 from 1.13.x to use state serializer fix,0
[FLINK-25658][ci] Use Nexus npm cache,1
"[FLINK-25654][network] Remove the redundant locks in SortMergeResultPartition and PartitionSortedBuffer.After FLINK-2372, the task canceler will never call the close method of ResultPartition, which can reduce some race conditions and simplify the code. This PR aims to remove some redundant locks in SortMergeResultPartition and PartitionSortedBuffer.This closes #18364.",5
[FLINK-25073][streaming] Introduce TreeMode description for verticesThis closes #17938.,2
[FLINK-24899][network] Enable data compression for blocking shuffle by defaultThis closes #17814.,5
[FLINK-25656][Kinesis] Upgrade software.amazon.glue:schema-registry-common and software.amazon.glue:schema-registry-serde dependency from 1.1.5 to 1.1.8,1
[FLINK-25657][Kinesis] Upgrade com.amazonaws:amazon-kinesis-client dependency from 1.14.1 to 1.14.7,2
"[FLINK-25646][docs] Added ""High parallelism"" limitation for buffer debloating docs  (#18351)",2
[FLINK-25611][core] Remove CoordinatorExecutorThreadFactory thread creation guards,1
[FLINK-15585][table-common] Declare TableFunction collector transient,1
[FLINK-15585][table] Improve function identifier string in plan digest,1
[FLINK-15585][table-planner] Update plan testsThis closes #18352.,3
[FLINK-20286][connector-files] Table source now supports monitor continuouslyThis closes #18176.,1
[FLINK-25639][network] Increase the default read buffer size of sort-shuffle to 64MThis closes #18350.,1
[FLINK-25638][network] Increase the default write buffer size of sort-shuffle to 16MThis closes #18350.,1
[FLINK-25637][network] Make sort-shuffle the default shuffle implementation for batch jobsThis closes #18350.,1
[hotfix][table-common] Fix InternalDataUtils for MapData tests,3
[FLINK-17321][table] Add support casting of map to map and multiset to multisetThis closes #18287.,1
[FLINK-25676][python] Support set_description in DataStream APIThis closes #18380.,5
[hotfix][python] Remove the outdated comments in test_environment_completeness,3
[refactor] Make CheckpointStateOutputStream a top level class,1
[FLINK-25194] Implement an API for duplicating artefacts,2
"[FLINK-25650][docs] Added ""Interplay with long-running record processing"" limit in unaligned checkpoint documentation",2
[hotfix][table-api-scala-bridge] Deprecate toAppendStream and toRetractStream,0
[hotfix][table-common] Add default implementation for DynamicTableFactory.Context#getEnrichmentOptions to alleviate breaking change,4
"Revert ""[FLINK-25399][tests] Disable changelog backend in tests""This reverts commit 1d1e72f0c4677e27d19345e5465c6d4a0ef6408f.The issue has been fixed in FLINK-25395 by commits:- 4691b66545010ed812624a259869c7a522663720- e28f4e2c5d4d54f5f727b9557024c537becfd054",2
[FLINK-25399][tests] Use FS-based changelog in PartiallyFinishedSourcesITCase,5
[FLINK-25633] Set locale to en-US to avoid ambiguous decimal formattingsThis commit sets the locale to en-US in order to avoid ambiguous decimal formattings thatcan cause the CPUResourceTest to fail.This closes #18343.,0
"[FLINK-25609][table] Anonymous/inline tables don't require ObjectIdentifier anymore- Move TableLookupResult to the upper level, rename to ContextResolvedTable and support anonymous tables (tables without identifier)- Renamed CatalogQueryOperation and CatalogSinkModifyOperation to SourceQueryOperation and SinkModifyOperation and propagate ContextResolvedTable- Moved and renamed InlineCatalogTable to ExternalCatalogTable. Now it accepts the unresolved schema.- Add CatalogManager#getTableOrError- Methods in Table, TableEnvironment and StatementSet with anonymous tables now don't generate ObjectIdentifier anymore, while  methods using ObjectIdentifier will perform a lookup at the call site, rather than later during the planning.- QueryOperationConverter manually creates the RelNode for anonymous tables, skipping Calcite table resolution- Propagate ContextResolvedTable throughout the stack up to the ExecNodes.This closes #18349.",0
[hotfix] Replace hamcrest with assertJ in ConfigurationUtilsTest,5
[hotfix] Rename ClusterEntrypoint.ShutdownBehaviour enum valuesRenamesShutdownBehaviour.STOP_APPLICATION -> ShutdownBehaviour.GRACEFUL_SHUTDOWNShutdownBehaviour.STOP_PROCESS -> ShutdownBehaviour.PROCESS_FAILURE,0
[FLINK-25402] Make JobManager process resource id configurable via jobmanager.resource-id,5
[FLINK-25402] Introduce ClusterOptions.PROCESS_WORKING_DIR_BASE for configuring a process directoryThis commit introduces the configuration option to configure a working directory for the JobManagerand TaskManager process. The resulting working directory will be <WORKING_DIR_BASE>/jm_<RESOURCE_ID>and <WORKING_DIR_BASE>/tm_<RESOURCE_ID> respectively.,1
[FLINK-25402] Clear tmp directory when setting up the working directoryThis commit ensures that the <WORKING_DIR>/tmp directory is always empty when aprocess is being started.,1
[FLINK-25402] Let taskmanager.state.local.root-dirs default to <WORKING_DIR>/localState,1
[FLINK-25402] Set state.backend.rocksdb.localdir to default to <WORKING_DIR>/tmpThis is a behaviour change because before the RocksDB local dir would default to io.tmp.dirs.This closes #18083.,5
[hotfix] Remove unused TaskExecutorLocalStateStoresManagerTest.TOTAL_FLINK_MEMORY_MB,3
[FLINK-25404] Let blob.storage.directory default to <WORKING_DIR>/blobs,1
[FLINK-25404] Introduce borrowed and owned storage directory to BlobServer/Cache for better clean upThis commit allows to pass a borrowed storage directory to the BlobServer/Cache. Borrowed storage directorieswon't be automatically cleaned up when shutting the BlobServer/Cache down. This allows to move the lifecyclemanagement of these directories to the owner of the BlobServer/Cache.This closes #18164.,4
[hotfix] Update TestingBlobStoreBuilder to use TriFunction,1
[hotfix] Remove mocking from BlobServerPutTest,3
[hotfix] Remove mocking from BlobServerGetTest,3
[hotfix] Refactor BlobServer.getFileInternal to not take expected blob file,2
[hotfix] Speed up BlobClientTest by removing 10s sleep,4
[hotfix] Simplify TransientBlobCleanupTask to not rely on internal BlobServer details,4
[FLINK-25405] Let BlobServer check and delete corrupted blobs at start upThis commit introduces the BlobUtils.checkAndDeleteCorruptedBlobs that is called by theBlobServer at start up to delete all potentially corrupted blobs.,4
[FLINK-25405] Let AbstractBlobCache check for corrupted blobs at start upThis commit lets the AbstractBlobCache all the BlobUtils.checkAndDeleteCorruptedBlobsin its storage directory to delete all corrupted cached blobs.This closes #18191.,4
[FLINK-25406] Let FileSystemBlobStore sync output streamIn order to avoid losing data the FileSystemBlobStore should call FSDataOutputStream.sync()when putting new results. This will ensure that no data is kept in caches and might be lostin case of a node crash.,5
"[FLINK-25406] Let BlobUtils.moveTempFileToStore first write file to BlobStore for persistenceIn order to avoid the situation that we write some local file but do not persist the datain the blob store, this commit changes the order in which the moveTempFileToStore movesfiles. Now, we first try to write the file to the BlobStore to persist it and only then wemake it visible locally.This closes #18192.",1
[FLINK-25436] Let TransientBlobCache register recovered transient blobs with expiry timesThis commit lets the TransientBlobCache register recovered transient blobs with their correspondingexpiry times. This enables the TransientBlobCache to clean recovered transient blobs up.,4
[FLINK-25436] Let PermanentBlobCache expire recovered permanent blobsThis commit adds for all recovered permanent blobs an expiry timeout. This willmake sure that recovered orphaned blobs get eventually cleaned up.,4
[FLINK-25436] Let BlobServer automtically expire recovered transient blobsThis commit enables the BlobServer to automatically register expiration timeoutsfor recovered transient blobs. This makes sure that orphaned transient blobs getcleaned up eventually.,4
"[FLINK-25436] Let Dispatcher only retain recovered jobs in BlobServerBy letting the Dispather only retain recovered jobs in the BlobServer, we makesure that orphaned job-scoped blobs are being cleaned up from the BlobServer.This closes #18194.",4
[FLINK-15352][connector-jdbc] Develop MySQLCatalog to connect Flink with MySQL tables and ecosystem.This closes #16962.,5
"[FLINK-24904][docs] Updated docs to reflect new KDS Sink and deprecated old producer based on KPL, also updated metrics page to include KDS Sink",5
"[FLINK-11838][fs][gs] Create Google Storage file system with RecoverableWriter supportAdd RecoverableWriter support for Google Storage, to allow Flink to write to GS buckets via StreamingFileSink. This involves registering a FileSystem implementation for GS, utilizing the Google-provided GoogleHadoopFileSystem, and then implementing the RecoverableWriter interface.The RecoverableWriter implementation writes temporarary files to blobs in GS when the recoverable stream is persisted, and composes those temporary blobs together on commit.This closes #15599",1
[FLINK-24210][runtime] Return the correct serialized length for window-related serializerThis closes #17720.,2
[FLINK-22643][network] Reuse tpc connections between taskmanagersThis closes #18365.,1
[hotfix][runtime] Add checkNotNull for Supplier/Function in DefaultResultPartition/DefaultExecutionVertex.,1
[FLINK-25033][runtime] DefaultExecutionTopology supports update.,5
[FLINK-25033][runtime] RegionPartitionGroupReleaseStrategy and LocalInputPreferredSlotSharingStrategy support update.This closes #18102.,5
[FLINK-24163][tests] Reduce key space in PartiallyFinishedSourcesITCaseToo large key space leads to timeouts during recovery.This closes #18403.,5
[hotfix][connectors] Fix: Infinite loop can arise when prepareCommit(flush=false) is called in AsyncSinkWriter with buffered elements,5
[FLINK-25677][table-planner] Update ReplicateRows to the new type inferenceThis closes #18401.,5
[hotfix][metrics][docs] Note that new job status metrics may evolve,1
[hotfix][docs] Fixing multiple internal and external 404 linksThis closes #18316.,2
[FLINK-25427] Harden the SavepointITCase.testTriggerSavepointAndResumeWithNoClaim by implicitly cloning the JobGraphs submitted into the MiniCluster.,5
[FLINK-24697][flink-connectors-kafka] add auto.offset.reset configuration for group-offsets startup mode,1
"[FLINK-25709] Always delete non-deterministic working directoriesThis commit introduces the distinction between deterministic and non-deterministicworking directories. The former have an explicit configured ResourceID. The latterwill always be deleted because the assumption is that the user won't want to recoverfrom them. Otherwise, he would have given a deterministic ResourceID.",5
[FLINK-25709] Add shutdown hook for the TaskManagerRunnerThis closes #18419.,1
[FLINK-15648][k8s] Support to configure limit for CPU and memoryThis closes #17098.,5
[FLINK-24334][k8s] Set FLINK_LOG_DIR environment for JobManager and TaskManager pod if configured via optionsThis closes #17503.,5
[FLINK-25681][table-planner] Remove failure test in CodeSplitITCase to avoid deep exception stackThis closes #18404,3
"[FLINK-25199][network] Make sure StreamEdges are uniquePreviously, if there was a node that was self-unioned with itself,it was creating a situation with two identical StreamEdges. Bothwith the same partitioning, from the same source node to the sametarget node.This was causing issues when constructing output collectors andpicking the correct RecordWriters, as StreamTask was not able touniquely identify given StreamEdge and was assigning the sameRecordWriter to both of the edges. As a result all stream elementswere sent twice through the same RecordWriter. It was actually prettyharmless apart of calculating the combined watermark downstream,since all watermarks were always comming just from one singleedge/inputgate, and the unused edges were always stuck withmin watermark.As a solution we are making sure that StreamEdges are uniqueby introducing a uniqueId field, incremented for every pairof StreamEdges connecting the same node.",1
[FLINK-25731][connectors/kinesis] Deprecated FlinkKinesisProducer,2
[FLINK-23944][test][pulsar] 1. change the Matcher to validate both size and data 2. pulsar IT test generate deterministic data,5
[FLINK-20188][Connectors][Docs][FileSystem] Added documentation for File SourceCo-authored-by: shihong90 <2572805166@qq.com>Co-authored-by: Alexander Fedulov <1492164+afedulov@users.noreply.github.com>,1
[FLINK-25674][connectors][cassandra][tests] Add drop tables to be idempotent in case of retrials and the related test,3
[FLINK-25674][connectors][cassandra][tests] use constants instead of string literals to avoid copy/paste,1
[FLINK-25678][runtime] Make TaskExecutorStateChangelogStoragesManager.shutdown thread-safeThe method is called from the shutdown hook and must be thread-safe.,1
[FLINK-25683][table] Pass MAX_WATERMARK in InputConversionOperatorMAX_WATERMARK emitted automatically has a special handling e.g. in BATCHruntime mode. It flushes remaining records at the end of processing.Therefore we should not discard those when converting to a Tablepipeline.This closes #18405,5
[hotfix][pulsar] Use correct super types for reader and fetcher manager.,1
[hotfix][source] Use only one watermark class in SourceOperatorEventTimeTest.,3
[FLINK-25277][flink-runtime] add shutdown hook to stop TaskExecutor on SIGTERM,1
[FLINK-25277][flink-runtime] synchronize termination and release of containers in YARNResourceManagerDriverThis closes #18169.,2
[FLINK-25287][connectors/testing-framework] Refactor connector testing framework interfaces for more scenarios,1
[FLINK-25287][connectors/kafka] Use connector testing framework for Kafka tests,3
[FLINK-25287][connectors/pulsar] Use connector testing framework interface for Pulsar tests,3
[FLINK-25287][formats/avro] Use connector testing framework interface for Avro format IT caseThis closes #18137.,1
[hotfix][connectors] Improve the typo and code style,2
[FLINK-25712][connectors/testing-framework] Merge flink-connector-testing module to flink-connector-test-utils moduleThis closes #18437.,3
[hotfix][docs]fix flink sql Cascading Window TVF Aggregation exception (#18414),2
[FLINK-24905][connector/kinesis] Creating table package in flink-connector-aws-kinesis-data-streams and moving partition key generators,4
"[FLINK-24905][connector/kinesis] Adding KinesisDataStreams Table API sink connector, moving related utils from legacy connector to new connector, modifying end-to-end test.",3
[FLINK-24905][docs] Updating documentation for Kinesis table API connector,2
[FLINK-25036][runtime] Introduce vertex wise scheduling strategyThis closes #18126.,2
[FLINK-25732][coordination] Pass serializable collection,4
[hotfix][annotations] Add v1.15 as the next Flink version to masterThe upcoming version to be released need to exist already in master so thatwhen the new release branch is created from master the version of the releaseis already there.Follows: #18340This closes #18381.,1
[FLINK-24768][runtime-web] upgrade Angular and NG-ZORRO versions to 13resolves #18413,0
[hotfix][yarn] Disable Yarn Debug logging for tests,3
"[FLINK-17808] Rename checkpoint meta file to ""_metadata"" until it has completed writingThis closes #18157.",5
[FLINK-25669][runtime] Support register operator coordinators for newly initialized ExecutionJobVertexThis closes #18407.,5
[hotfix][docs] Regenerate config docs,2
[FLINK-25715][runtime] Introduce TestingDispatcherGateway#newBuilder() method,3
[FLINK-25715][coordination] Allow submission of failed jobsAdds a new config option for allowing failures in the jobs main method to result in a submission of a failed job.,0
[hotfix][runtime] Extract a common method to parse rest port from web interface URL,4
[FLINK-24947][k8s] Support host network for native K8s integrationThis closes #18119.,1
"[FLINK-25520][Table SQL/API] Implement ""ALTER TABLE ... COMPACT"" SQL* Add compaction callback to ManagedTableFactory, ManagedTableListener and CatalogManager* Let SqlToOperationConverter convert the compact clause to ModifyOperation* Let SourceQueryOperation accept partition_spec as dynamic options* Let QueryOperationConverter and FlinkRelBuilder translate dynamic options as hints* Implement TestManagedTableFactory/TestManagedTableSource/TestManagedTableSink to support plan test",3
"[FLINK-25520][Table SQL/API] Implement ITCase for ""ALTER TABLE ... COMPACT"" SQLThis closes #18394* Add TestManagedFileSourceReader, TestManagedFileSourceSplitEnumerator, TestManagedIterableSourceSplit, TestManagedFileSourceSplitSerializer* Add TestManagedSinkWriter, TestManagedCommittable, TestManagedSinkCommitter, TestManagedSinkCommittableSerializer",3
[FLINK-25758][flink-gs-fs-hadoop] Fix licensing issues with JDK11This closes #18452,0
[FLINK-25171][table-planner] Validation of duplicate fields in ddl sqlThis closes #18017,5
"[FLINK-25524] Fix ChangelogStateBackend.notifyCheckpointCompleteWhen triggering materialization, Changelog backend uses fakecheckpoint ID to obtain a (materialized) snapshot.That same ID must be used when proxying checkpointcompletion/abortion notifications to the nested backend.On recovery, nested backend might read lastCompletedCheckpointIDfrom its snapshot; in particular, when enabling changelog, whichmay cause inconsistency.This change:- adds a mapping from checkpoint to materializationID- stores materializationID in checkpoint metadata- selects max materializationID on recovery (to handle upscaling)",0
[FLINK-25739][dist] Include Changelog to flink-dist jar,2
[FLINK-25391][connector-elasticsearch] Forward catalog table options,2
[FLINK-25391][connector-jdbc] Forward catalog table options,2
[FLINK-25391][connector-files] Forward catalog table options,2
[FLINK-25391][connector-kafka] Forward catalog table options,2
[FLINK-25391][connector-kinesis] Forward catalog table options,2
[FLINK-25391][connector-hbase] Forward catalog table options,2
[FLINK-25391][format-avro] Forward catalog table options,2
[FLINK-25391][format-csv] Forward catalog table options,2
[FLINK-25391][format-json] Forward catalog table optionsThis closes #18290.,2
[hotfix][table-common] More Javadoc on DynamicTableFactory.Context#getObjectIdentifier,1
[FLINK-25791][table-planner] Add Parser to the SerdeContext,1
[FLINK-25791][table-planner] Use serializable string for ObjectIdentifier in JSONThis closes #18485.,5
[hotfix][table-planner] Unify the JSON test utilities,3
[hotfix][rest][docs] Regenerate REST API docs,2
[FLINK-14954][rest] Add OpenAPI spec generator,1
[FLINK-25702][Kafka] Use the configure feature provided by the kafka Serializer/DeserializerThis closes #18397.,1
[FLINK-24041][connector] Fixing reversed insertion of failed requests,0
[FLINK-25763][match-recognize][docs] Updated docs to use code tag consistent with other tables,1
[FLINK-25769][table-common] Introduce hidden functions in module system,5
[FLINK-25769][table] Introduce internal and versioned built-in functions,1
[FLINK-25769][table-planner] Update some SqlFunction to new architectureThis closes #18464.,1
[FLINK-25668][runtime] Support to compute network memory for dynamic graph.This closes #18376.,1
[hotfix][dist] Include flink-gs-fs-hadoop into flink-dist,2
"[hotfix][fs][gs] Update serializer version.The purpose of this change is to prevent serialization/deserialization problemsbetween the PR and the final merged versions, as the PR has been opened for along time and we noticed it already have many users before being merged.This commit should change nothing for new users of the officially merged version.See the following discussion for more details:https://github.com/apache/flink/pull/15599#issuecomment-1017633539This closes #18409",2
"[FLINK-21790][network] Shuffle data directories to make directory selection of different TaskManagers fairerCurrently, different TaskManagers select data directory in the same order and if there are multiple disk, some disks may stores more data than others which is bad for performance. A simple improvement is that each TaskManager shuffles the given data directories randomly and select the data directory in different order.This closes #18456.",5
[FLINK-21789][network] Make FileChannelManagerImpl#getNextPathNum select data directories fairlyFileChannelManagerImpl#getNextPathNum is not atomic which may cause unfairness of data directory selection. This change makes the selection of data directories fair which is good for load balance and performance especially when there are multiple disks.This closes #18458.,5
[FLINK-18356][tests] Disable fork-reuse for table-plannerThis closes #18510.,1
[hotfix][filesystem] Fix the typo in InProgressFileWriterThis closes #18438,2
[FLINK-25368][connectors/kafka] Substitute KafkaConsumer with AdminClient in OffsetsInitializer,5
[hotfix] fix a typo in KafkaTestBase,3
[FLINK-25590][metrics] Introduce RequestedMemoryUsage and log warnings if usage exceeds 100%,2
fixup! [FLINK-25590][metrics] Introduce RequestedMemoryUsage and log warnings if usage exceeds 100%,2
[FLINK-25348][build] Clear japicmp exclusions,2
[FLINK-25811][connector/base] changing failed requests handler to accept list in AsyncSinkWriter,0
[FLINK-25818][Docs][Kafka] Add explanation how Kafka Source deals with idleness when parallelism is higher then the number of partitions,1
[FLINK-25673][tests] Wait until all slots are freed,3
[hotfix][tests] Add missing '=',1
[FLINK-25754][elsaticsearch] Remove unused private class,1
[FLINK-24041][connectors] Removed public setter for elementConverter in Async Sink. Concrete implementations must now construct this elementConverter,1
[hotfix] Introduce TestingFatalErrorHandlerExtensionThe TestingFatalErrorHandlerExtension replaces the TestingFatalErrorHandlerResource forJunit5.,3
[FLINK-24038] Move leader session id generation to LeaderElectionDriverMoving the leader session id generation into the LeaderElectionDriver will allow us to builda high availability service where we have a single leader elector for multiple components whichshare the same leader session id.,1
[hotfix] Mark DefaultLeaderElectionService running right after calling start()This is important because otherwise we will ignore confirmLeadership callbacks thatoriginate from the start call.,5
[FLINK-24038] Introduce DefaultMultipleComponentLeaderElectionServiceThe DefaultMultipleComponentLeaderElectionService allows to register multiple LeaderElectionEventHandlers.This allows to have a single leader election service for multiple Flink components.,2
[FLINK-24038] Implement ZooKeeperMultipleComponentLeaderElectionHaServicesThe ZooKeeperMultipleComponentLeaderElectionHaServices use the DefaultMultipleComponentLeaderElectionService togetherwith the ZooKeeperMultipleComponentLeaderElectionDriver to do leader election for multiple Flink componentsusing a single ZooKeeper based leader election.This commit adds the ZooKeeperSingleLeaderElectionHaServices that can be activatedby configuring zookeeper_single as the high-availability.,5
[hotfix] Let KubernetesSharedWatcher only require an ExecutorThis commit changes the KubernetesSharedWatcher to only require an Executor insteadof an ExecutorService.,1
[hotfix][tests] Refactor KubernetesHighAvailabilityRecoverFromSavepointITCaseThis commit changes the KubernetesHighAvailabilityRecoverFromSavepointITCase to dependless on internal implementation details and more on the public API.,4
[FLINK-24038] Add KubernetesMultipleComponentLeaderElectionHaServicesThis commit adds KubernetesMultipleComponentLeaderElectionHaServices that only perform a singleleader election per JobManager process.,1
[hotfix] Refactor Kubernetes tests to make the test fixture reusable,0
[FLINK-24038] Add KubernetesMultipleComponentLeaderElectionDriverTest,3
[FLINK-24038] Introduce HighAvailabilityOptions.USE_OLD_HA_SERVICES as safety hatch,1
[FLINK-24038] Replace old KubernetesHaServices with KubernetesMultipleComponentLeaderElectionHaServices,2
[FLINK-24038] Replace ZooKeeperHaServices with ZooKeeperMultipleComponentLeaderElectionHaServices,2
"[FLINK-24038] Disable leadership tests when using multiple component leadership ha servicesThis commit disables the leadership tests done by the KubernetesCheckpointIDCounter and the KubernetesStateHandleStorewhen using the multiple component leadership ha services. This is necessary because when using this ha service, then theconfig maps used by KubernetesCheckpointIDCounter and KubernetesStateHandlStore have not LeaderElector assigned. Moreover,this commit explicitly creates the required config maps which have been created before by the LeaderElector.This closes #17485.",1
[FLINK-25557][checkpoint] Introduce incremental/full checkpoint size Statistics,2
[FLINK-25557][changelog] Introduce incremental checkpoint size stats for changelog state,4
[FLINK-25557][docs] Add documentation for incremental checkpoint size,2
[FLINK-25719][python] Support General Python UDF in Thread ModeThis closes #18418.,1
[FLINK-25312][hive] HiveCatalog supports Flink's managed tableThis closes #18500,2
[FLINK-25836][python] Fix the unstable test test_keyed_process_function_with_state in PyFlinkThis closes #18528.,2
"[FLINK-25774][network] Restrict the maximum number of buffers can be used per result partition for sort-shuffleCurrently, for sort-shuffle, the maximum number of buffers can be used per result partition is Integer.MAX_VALUE. However, if too many buffers are taken by one result partition, other result partitions and input gates may spend too much time waiting for buffers which can influence performance. This patch restricts the maximum number of buffers can be used per result partition to Math.max(min, 4 * numSubpartitions). Note that the selected value is an empirical one based on the TPC-DS benchmark results.This closes #18470.",1
"[FLINK-25780][network] Reduce the maximum size of data output buffer per result partition for sort-shuffleThe data output buffer of sort-shuffle is for better disk IO performance and currently, the total data output buffer size is 16M which is pretty big. However, blocking request too many buffers may influence performance. This patch reduces the maximum size of data output buffer from 16M to 8M to reduce the buffer request time. Note that the selected value is an empirical one based on the TPC-DS benchmark results.This closes #18471.",5
"[FLINK-25781][network] Adjust the maximum number of buffers can be used per result partition for data read of sort-shuffleCurrently, for sort-shuffle, the maximum number of buffers can be used per result partition for shuffle data read is 32M. However, for large parallelism jobs, 32M is not enough and for small parallelism jobs, 32M may waste buffers. This patch tries to solve the problem by adjusting the maximum number of buffers can be used per result partition for shuffle data read from 32M to Math.max(16M, numSubpartitions).This closes #18473.",5
"[FLINK-25786][network] Adjust the generation of subpartition data storage order for sort-shuffle from random shuffle to random shiftCurrently, for sort-shuffle, the generation of subpartition data storage order is random shuffle. However, if there is no enough resources to run the downstream consumer tasks in parallel, the performance can be influenced because of the random disk IO caused by the random subpartition data storage order. This patch tries improve this scenario by adjusting the generation of subpartition data storage order for sort-shuffle from random shuffle to random shift.This closes #18474.",5
[FLINK-25035][runtime] Move consumedSubpartitionIndex from SingleInputGate to InputChannel,4
[FLINK-25035][runtime] SingleInputGate supports consuming subpartition rangeThis closes #18130.,1
[FLINK-25810][connector/kinesis] Adding Kinesis data streams SQL client uber jar and end to end test.This closes #18468.,3
"[FLINK-24703][connectors][format] Adds CSV File System decoding format based on file-connector-files StreamFormat.'flink-connector-file' introduced new interfaces for interacting with thefile system. This commit contributes to the goal of migrating all formatsused for writing files to this API, in particular, StreamFormat used byFileSource. It also introduces a generic Converter interface to map typesbetween the native format types representation and their correspondingtypes expected by Flink (in particular Table/SQL API).Co-authored-by: Arvid Heise <arvid@ververica.com>",2
"[FLINK-24703][connectors][format] Add CSV File System encoding format based on BulkWriter.'flink-connector-file' introduced new interfaces for interacting with thefile system. This commit contributes to the goal of migrating all formatsused for writing files to this API, in particular, BulkWriter used byFileSink. It also makes use of the generic Converter interface to map typesbetween the types used by Flink (in particular by Table/SQL API) and thenative format types of the format encoder. This commit also adds teststhat use the reader added and the previous commit and the writer added inthis commit together.",1
[hotfix] Adds fail to DispatcherTest,3
[hotfix] Adds missing JavaDoc,2
[hotfix] Makes intention of comment clearer,1
[hotfix] Migrates ApplicationStatusTest to JUnit5 and AssertJ,3
[hotfix] Adds TestLogger extension to ApplicationDispatcherBootstrapTest,3
[hotfix] Introduces TestingPartialDispatcherServices,3
"[hotfix] Removes @Nonnull annotations from DispatcherServices and PartialDispatcherServicesWithJobGraphStoreInstead, null checks are added",1
"[FLINK-25430][runtime] Add JobResultStoreThis commit adds the JobResultStore interface, a in-memoryimplementation EmbeddedJobResultStoreand, and correspondingtest, container and utility classes. (FLIP-194)",3
[FLINK-25430][runtime] Integrates JobResultStoreinto the DispatcherIntegrates the JobResultStore (using the EmbeddedJobResultStore implementation) into the Dispatcher through HighAvailabilityServices.It replaces the RunningJobsRegistry but doesn't add any otherfunctionality.,1
[FLINK-25430][runtime] Renames JobGraphStoreFactory into JobPersistenceComponentFactorySeparate commit to prepare the further JobResultStoreintegration. JobGraphStoreFactory becomesJobPersistenceComponentFactory because we want tointegrate the initialization analogously to how theJobGraphStore initialization is integrated.,5
[FLINK-25430][runtime] Renames PartialDispatcherServicesWithJobGraphStore into PartialDispatcherServicesWithJobPersistenceComponentsSeparate commit to prepare the further JobResultStoreintegration. PartialDispatcherServicesWithJobGraphStorebecomes PartialDispatcherServicesWithJobPersistenceComponentsbecause we want to integrate the initialization analogouslyto how the JobGraphStore initialization is integrated.,5
[FLINK-25430][runtime] Integrates JobResultStore initialization along JobGraphStore initializationThe goal is to do the recovery of dirty JobResults fromthe JobResultStore along the JobGraph recovery. Bothwill be pass through the call chain up to the Dispatcher.The *DispatcherLeaderProcess implementations take care ofthis recovery and make sure that any JobGraph that isrecovered but has a matching dirty JobResult is not passedon into the Dispatcher. There's a dedicated Preconditionchecking this in the Dispatcher constructor itself.,4
[hotfix] Migrates SessionDispatcherLeaderProcessTest to JUnit5/AssertJ,3
[hotfix] Migrates ApplicationDispatcherBootstrapITCase to JUnit5/AssertJ,3
[FLINK-25805][table-planner] Use DataType compact representation for default conversion classesThis closes #18533.,5
[FLINK-25826][table-planner] Handle symbols at a central place with serializable formatThis closes #18529.,0
[hotfix] Expose EvictingBoundedList.isDroppedIndexThis commit exposes the EvictingBoundedList.isDroppedIndex method to allow for checkswhether an element in the list has already been dropped.,4
[hotfix] Fix checkstyle violations in EvictingBoundedList,0
[hotfix] Replace Hamcrest assertThat with assertj assertThat in ExecutionVertexTest,3
"[FLINK-25831] Retrieve the latest non-null prior property from ExecutionVertexIn order to not lose information about prior Executions, this commit iterates over allprior executions in the ExecutionVertex in order to find the first non-null prior locationand allocation.This closes #18526.",5
[hotfix] Remove unused ExecutionVertex.LOG,2
[hotfix][azure] fix ArchUnit flagThis mistake actually prevented the CI from failing when violationshave been fixed.,0
[FLINK-25790][flink-gs-fs-hadoop] Support RecoverableWriter auth via Hadoop configThis closes #18489,5
[FLINK-25577][docs] Update GCS documentationThis closes #18430,2
[FLINK-25861][avro] Move states of AbstractAvroBulkFormat into its readerThis closes #18549,4
[FLINK-25849] Add TaskManager session id to JobMaster.registerTaskManagerThe TaskManager session id allows to distinguish between duplicate registration attemptsand a new TaskManager instance that has an old ResourceID.Signed-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #18534.,2
[FLINK-25707] AdaptiveScheduler transitions executions to scheduled,2
[FLINK-25707] Forbid transitions from CREATED -> DEPLOYING,1
[FLINK-25773][build] Upgrade to flink-shaded 15.0,2
[FLINK-25776][build] sync netty versions,2
[FLINK-25808][rest][docs] JsonTypeInfo property uses valid java identier,1
"[FLINK-25816][state] Remove checkpoint abortion notification of notify backendThe notification currently causes an exception and adds complexity.It's also not necessary, unlikely to be delivered (because of thedifference in checkpoint/materialization intervals) and unlikely to beutilized (it will arrive only after the nested snapshot has completedand most likely do the same GC as in completion notification).",1
[hotfix][table-api-java] Use correct Preconditions method in CatalogManager,2
[hotfix][table-common][table-api-java] Add various equals/hashCode to catalog-related classes,2
[hotfix][table-planner] Add FlinkContext.getClassLoader,2
[FLINK-25386][table-planner] Harden persisted plan for catalog tablesThis closes #18427.,2
[hotfix][table-planner] Enable parallel test execution for serde tests. Also fix some annotation mistakes.,0
[hotfix][table-planner] Add an env variable to improve dev loop on plan tests.,3
[FLINK-25753][tests] Fix KafkaTableITCase.testStartFromGroupOffsetsLatest,3
[hotfix][legal] Fix kinesis-data-streams licensing,5
[FLINK-25807][rest][docs] Deduplicate fields that only differ by naming convention,2
[FLINK-25024][docs] Add Changelog backend docs,2
"[FLINK-25479][rpc] Serialize TaskStateSnapshot when sending to JM from TMCheckpointCoordinator doesn't expect to receive the same object more than once:in production environment, state handles are (de)serialized while sending via RPC.However, in tests, local RPC may be used, without (de)serialization. This causestest failures when using state backends which re-use objects (e.g. materializedstate of ChangelogStateBackend).Using the same KeyedStateHandle *object* should be allowed for backends.This change makes RpcCheckpointResponder serialize TaskStateSnapshot whensending to JM from TM.",1
[FLINK-25016][build] Upgrade to Netty 4.1.70,2
[FLINK-24339][rest] Remove guard against CRLF split across chunks,4
[FLINK-25767][docs-zh] Totally translate state.md into ChineseThis closes #18460.,1
[FLINK-24978][build] Upgrade ASM to 9.2,2
[FLINK-25045][runtime] Introduce AdaptiveBatchSchedulerThis closes #18462.,2
[FLINK-25614][table-runtime] Update LocalWindowAggregate chain strategy to ALWAYSThis closes #18331.,5
[FLINK-25486][Runtime/Coordination] Fix the bug that flink will lost state when zookeeper leader changesThis closes #18296.,4
[hotfix][Runtime/Coordination] Minor fix,0
"[FLINK-25431][runtime] Implement a file-based JobResultStoreThis commit contains an implementation of the JobResultStore backed by afile-system. By default, this filesystem is based on the settings forhigh-availability.storageDir and the cluster-id, but can be overridenwith the job-result-store.storage-path setting.Alongside this setting, it also introduces a new optionjob-result-store.delete-on-commit, which determines whether theunderlying file for the job result entry is deleted when it is clean, orwhether it is renamed and persisted. By default, this option is true.",4
[FLINK-25147][connectors][Cassandra][test] Use parent test containers version,3
[FLINK-25771][connectors][Cassandra][test] Raise all read/write/miscellaneous requests timeouts,3
[FLINK-25771][connectors][Cassandra][test] Add a test that raiseCassandraRequestsTimeouts indeed changes the configuration inside the container.,5
[FLINK-25220][test] update flink pom for ArchUnit test infra- define some ArchUnit dependencies in the dependencyManagement- exclude archunit-violations stores from the license check,5
"[FLINK-25220][test] Split architecture-tests and build ArchUnit extension- create submodule flink-architecture-tests-base, flink-architecture-tests-production, flink-architecture-tests-test- build ArchUnit extension and move the common part to the flink-architecture-tests-base submodule- refactoring and move ArchUnit tests and rules to the flink-architecture-tests-production submodule",3
[FLINK-25220][test] develop ArchUnit rules and test base for ITCase,3
[FLINK-25220][test] ITCase ArchUnit test for HBase-2.2 connector,3
[FLINK-25220][test] ITCase ArchUnit test for files connector,2
[FLINK-25220][test] update README.md,2
[FLINK-25744] Split CheckpointType for checkpoint & savepointCheckpoints & savepoints often contain a disjoint parts of typespecification. E.g. PostCheckpointAction apply only to savepoints.When adding new properties it becomes harder and harder to keep bothconfigurations in a single class.,5
"[FLINK-25744] Support native savepointsWe introduce a savepoint type flag both to the CLI and REST API thatcontrols the binary format of the savepoint to take. Native savepointsare taken in the state backend specific binary format. They can befaster to take and restore from, but they do not support e.g. changingthe state backend.This commit does not support RocksDB incremental savepoints yet. Whenincremental savepoints are configured, native savepoints will fail.",0
[FLINK-25744][docs] Document savepoint format,2
"[FLINK-25728][task] Avoid unnessesary CompletableFuture.thenRun calls on idle inputProcessor's avaiableFuture, preventing memory leaks.",1
[FLINK-25728][task] Simplify MultipleInputAvailabilityHelper,2
[hotfix] Add TestingUtils.infiniteDurationTestingUtils.infiniteDuration returns a Duration of one year. This shouldbe long enoug to simulate an infinite Duration.,5
[FLINK-25847] Fix deadlock in DefaultMultipleComponentLeaderElectionServiceThe cause for the deadlock was that we called into the LeaderElectionEventListenerfrom under the lock of the DefaultMultipleComponentLeaderElectionService. That waythe lock could escape from this class. The problem has been solved by using theleadershipOperationExecutor to call into the LeaderElectionEventListener.This closes #18569.,1
[hotfix][tests] Fix SessionDispatcherLeaderProcessTest.onRemovedJobGraph_terminatesRunningJobProperly wait on the future completion for the assertion.,3
"[FLINK-25855] Allow JobMaster to accept excess slots when restarting the jobThis commit allows the JobMaster to accept excess slots when the job is restarting.The way it works is that the DefaultScheduler tells the DefaultSlotPoolBridge whenthe job is restarting. If during this time new slots should be offered, then theDefaultSLotPoolBridge calls DeclarativeSlotPool.registerSlots which accepts allslot offers. Once the job leaves the RESTARTING state, the DefaultSlotPoolBridgewill call DeclarativeSlotPool.offerSlots which only accepts those slots that arecurrently required.[FLINK-25855] Add DeclarativeSlotPool.registerSlotsThis closes #18542.",1
[FLINK-24270][checkpoint] Refactor the tests related to the VertexFinishedStateChecker.This closes #18196.,5
[FLINK-25307][test] Change nodename used in e2e tests to localhostThis closes #18481.,3
[FLINK-25145][build] Drop ZK 3.4 / Support ZK 3.6,1
"[FLINK-25041][e2e] Improve error handling for missing environment variables in E2E testsThere are several points where the E2E tests check that an environmentvariable is nonempty before proceeding with the tests, such as theE2E_TARBALL_CACHE. Usually, this results in a friendly error messagestating ""You have to export the E2E Tarball Cache as E2E_TARBALL_CACHE"".However, if running the scripts with nounset during development, this resultsin an `E2E_TARBALL_CACHE: unbound variable` error, which is less friendly tothe user.This PR changes these instances to use parameter expansion for thesevariables, so that even with nounset, the user recieves the friendlyerror message for a missing environment variable.",0
"[FLINK-24228][connectors/firehose] Amazon Kinesis Data Firehose sink based on the Async Sink Base implemented: - Refactored AWSUnifiedSinksUtil into a class that caters for Kinesis and Firehose - Extracted commonalities between KDS & KDF sinks into flink-connector-aws-base - Implemented integration test based on Localstack container - Changing host/container ports to be different, changing HTTP1.1 to being the default, localstack issue fixed - Added docs page, changed type in Firehose, turned logging off, removed unused dependencies.",1
[FLINK-24228][connectors/firehose] Added documentation (&.zh docs) for the new Firehose sink.,1
"[FLINK-24228][connectors/firehose] Allows end users to supply a serialization schema rather than an ElementConverter, thereby encapsulating the Firehose `Record` from the user, verifying stream objects in KinesisFirehoseITCase",1
[FLINK-25445] No need to create local recovery dirs when disabled local-recovery in TaskExecutorLocalStateStoresManager,3
[FLINK-25905][build] Add Experimental to japicmp exclude list,1
[FLINK-25894][build] Explicitly set streaming-java oldVersion,1
[FLINK-25819][tests] Improve error reporting,0
[FLINK-25564][tests] Leave cleanup to rule,4
[FLINK-25880][Docs] Implement Matomo in Flink documentation (#18577)* [FLINK-25880][docs] Remove Google Analytics implementation* [FLINK-25880][docs] Add Matomo tracking code to base layout,1
[FLINK-25597][conf][docs] Clarify options for local directories,5
[FLINK-25423][state-processor-api] Enable loading state backend via configuration in SavepointWriter,5
[refactor][state-processor-api] Move state backend loading and restoration into utility,4
[refactor][state-processor-api] Remove usages of deprecated class,4
[FLINK-25423][state-processor-api] Enable loading state backend via configuration in SavepointReader,5
[FLINK-25423][state-processor-api] Enable loading state backend via configuration in DataSet APIThis closes #18223,5
[FLINK-25575][streaming] Add data structure to collect CommittableMessages.Using operators will be able to bulk commit committables and retry failed.Co-authored-by: Arvid Heise <arvid@ververica.com>,0
[FLINK-25575][streaming] Expose transformations currently held by the StreamExecutionEnvironmentThe SinkV2 will dynamically add transformations to the stream graphgeneration while already generating. So we need to query the newly addedtransformations from the StreamExecutionEnvironment.Co-authored-by: Arvid Heise <arvid@ververica.com>,1
"[FLINK-25575][streaming] Scope batch exchanges in PartitionTransformation to batch mode.This change allows DataStream internally to insert fail-over regions into the operator graph that are only used in batch mode. For streaming mode, these exchanges are reset to UNDEFINED and set during StreamGraph construction.Co-authored-by: Arvid Heise <arvid@ververica.com>",1
[FLINK-25575][streaming] Add SinkV1Adapter that simulates Sink V1 in V2 interfaces.This adapter allows Flink to only use one code path to execute both V1 and V2 interfaces. It also shows that the V2 interface is able to capture all nuances of V1.Co-authored-by: Arvid Heise <arvid@ververica.com>,1
[FLINK-25575][table][test] Ignore CompactManagedTableITCase because it requires the GlobalCommitter,1
"[FLINK-25575][streaming] Switch the implementation of Sink operator to V2.Sink will now consist of two operators: WriterOperator and CommitterOperator. They are chained by default in streaming mode and behave like Sink V1 in respect to sharing committable instances.State handling of the writer is similar to V1, however, more logic is being placed inside the SinkWriterStateHandler.Committer state is being entirely outsourced to the previously introduced CommittableCollector.The SinkTransformationTranslator is now responsible to dynamicallyexpand the one sink transformation to multiple transformation to ensurethat all topologies are properly instantiated.Co-authored-by: Arvid Heise <arvid@ververica.com>",2
"[FLINK-25387][FLINK-25388][FLINK-25389][table-planner] Introduce ExecNodeMetadata- Introduce a new annotation `ExecNodeMetadata` on `ExecNode`s which is used toimprove the serialization/deserialization to/from JSON plan of `ExecNode`s andfacilitate the upgrade of the pipeline, since every ExecNode has now also a versionattached.- List all the JSON plan eligible `ExecNode`s in `ExecNodeMetadataUtil` and use a static list to register them in Jackson.- Annotate all those eligible `ExecNode`s with the new annotation and provide aname constructed by the class name using `-` separators. All versions are set nowto 1.- Use an `ExecNodeContext` POJO which uses the uniqueId, name and version toserialize/deserialize them in a JSON plan in the form of `<id>_<exec-node-name>_<version>`.- Fix issues with `@JsonIgnoreProperties` and `@JsonIgnore`, and opt for the classbased annotation instead of the per field annotation of `@JsonIgnore`.- Update the test plans with the new JSON scheme derived by the changes.This closes #18479.",4
[hotfix][table-planner] Remove org.reflections usage and dependency,4
"[FLINK-25925][tests] Require slot pool to only accept the same set of slots as beforeInstead of also accepting excess slots, we only need to require the same set of slotsas before. This commit changes the JobMasterTest.testJobMasterAcceptsExcessSlotsWhenJobIsRestartingaccordingly.This closes #18608.",3
[FLINK-25206][clients] Make prevention of configurations in user jars configurableAdd configuration option to disable configuration in user jars. Thesubmission will fail instantly before the job creation.,1
[FLINK-19845][connector-files] Prune FileSystemFormatFactorySigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][docs][connector/files] Fix directory watching docsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-25685][rest] RestClusterClient supports uploading local file path with scheme,2
[hotfix][table-planner] Use jdk 8 and java time modules for optional ser/deSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix] Log toString of discarded message if RpcActor is not running,1
[FLINK-25885] Suppress error reporting for ResourceManagerServiceImpl.deregisterApplicationThis commit suppresses the error reporting for ResourceManagerServiceImpl.deregisterApplicationin order to harden the ClusterEntrypointTest.testWorkingDirectoryIsDeletedIfApplicationCompletes.This is a temporary fix until FLINK-25893 has been fixed.This closes #18567.,0
[FLINK-25879][Docs] Track used search terms in Matomo,1
[hotfix][legal] Remove org.reflections from NOTICEFollows: #d9d72ef142a2343f37b8b10ca6e04dc7f6ca086eof: #18479,4
[FLINK-25949][connector/firehose] Fixing wrong Http protocol default value for kinesisfirehoseSinkBuilder,0
"[FLINK-21788][network] Throw PartitionNotFoundException if the partition file has been lost for blocking shuffleCurrently, if the partition file has been lost for blocking shuffle, FileNotFoundException will be thrown and the partition data will not be regenerated. This change makes it throw PartitionNotFoundException instead.This closes #18515.",1
[FLINK-25860][network] Move read buffer allocation and output file creation to setup method for sort-shuffle result partition to avoid blocking the main threadThe read buffer allocation and output file creation of sort-shuffle is performed by the main thread. These operations are a little heavy and can block the main thread for a while which may influence other RPC calls including the follow-up task deployment. This change aims to solve the issue by moving read buffer allocation and output file creation to setup method.This closes #18554.,1
[hotfix] Makes FileSystemBlobStore.(delete|deleteAll) comply to the BlobStore interface,5
[hotfix] Removes unused classloader parameter from CheckpointRecoveryFactory.createRecoveredCompletedCheckpointStore,1
[hotfix] Refactors nested if statements,4
[FLINK-25432][runtime] Adds generic interfaces for cleaning up Job-related data,5
[FLINK-25432][runtime] Refactors JobGraphWriter interface to implement LocallyCleanableResource and GloballyCleanableResource,4
[FLINK-25432][runtime] Makes BlobServer implement LocallyCleanableResource and GloballyCleanableResource,4
[FLINK-25432][runtime] Makes HighAvailabilityServices implement LocallyCleanableResource and GloballyCleanableResource,4
[FLINK-25432][runtime] Makes JobManagerMetricGroup implement LocallyCleanableResource and GloballyCleanableResource,4
[FLINK-25432][runtime] Adds JobManagerRunnerRegistry and integrates it into the Dispatcher,1
[FLINK-25432][runtime] Integrates ResourceCleaner functionality into Dispatcher,1
"[FLINK-25745] Support RocksDB incremental native savepointsIncremental savepoints do not reuse sst files from previous checkpoints.At this point they re-upload those files. Moreover they do not registerits files as reusable by future checkpoints. Lastly, all sst files arecreated in the EXCLUSIVE scope with relative paths, which makes thesavepoint relocatable.",1
"[FLINK-25745] Do not log exception if CompletedCheckpointStorageLocation#disposeStorageLocation failed in CLAIM modeIf we restore from a savepoint (self contained and relocatable) itsdirectory may contain shared files. If we restore in CLAIM mode, thosefiles can be reused by future checkpoints and thus disposing such asnapshot location may fail, as it still may contain shared files.",2
[FLINK-25129][docs] Restructure project configuation pages,5
[FLINK-25331][tests] FlinkImageBuilder checks for Java 17,2
[hotfix][test] Extract SourceOperatorTestBase from SourceOperatorTest,3
"[hotfix][test] Fix SourceOperatorTest#testSameAvailabilityFuturePreviously this test was returning always CompletedFuture, which technically speakingshould have been converted to AVAILABLE. And it also wasn't testing the importantbehaviour, that when being unavailable for long period of time, getAvailableFutureshouldn't be producing new CompletableFuture per each call.",1
[FLINK-25827][task] Move and rename MultipleInputAvailabilityHelper,4
[FLINK-25827][task] Fix potential memory leak in SourceOperator when using CompletableFuture.anyOf,1
[FLINK-25947][build] Simplify shade-plugin configuration,5
"[FLINK-21752] NullPointerException on restore in PojoSerializerIn order to support Pojo schema migration, we added a new ctor to thePojoSerializer, which uses data extracted from a snapshot. However theduplicate method still used the old ctor which tries to recreate partsof the data from the current context.We should use the same ctor as we use for schema migration in theduplicate methods. We must make sure though all serializers are properlyduplicated.",1
[FLINK-21752] Add a call to TypeSerializer#duplicate in migration testsWe should verify that a TypeSerializer even after migration can besafely duplicated. In order to do that we can duplicate a new serializerin the TypeSerializerUpgradeTestBase before we try to use fordeserialization.,1
[FLINK-25573][table] Add SinkV2Provider to execute SinkV2s with the TableAPI,1
[FLINK-25573][kafka] Migrate KafkaSink to SinkV2,2
"[FLINK-25726][streaming] Check committer existence in SinkV1Adapter to determine if a committer is neededBefore this commit the serializer presence was the indicator.Unfortunately, the serializer is also required in case of using a globalcommitter. The topology having a single writer and a global committer inSink V1 would have failed.",0
[FLINK-25726][streaming] Add Global Committer as post commit topology,2
[FLINK-25725][table][tests] Use GlobalCommitter for CompactManagedTableITCaseWith the introduction of FLINK-25575 the committer operator runs alwayswith the same parallelism as the sink writer. Previously in batch modethe committer had always parallelism one to avoid correctness issues.The test was built with this assumption although this was neverguaranteed. The test is now using the global committer to ensure havinga committer receiving all committables.,1
[FLINK-25578][core] Graduate and deprecate unified Sink API V1,2
[FLINK-25924][connectors/firehose] Adding a timeout for the LocalstackContainer,1
[hotfix] Migrates BlobServerCleanupTest to JUnit5/AssertJ,3
[FLINK-25954][runtime] Adds cleanup testcases to BlobServerCleanupTest,3
"[FLINK-25953][runtime] Reorganizes dispatcher cleanup related testsThis includes introducing a TestingDispatcher.Builder and aligningthe usages of the TestingDispatcher instantiation between tests.Additionally, tests were renamed, obsolete tests were removed andcleanup-related tests moved into DispatcherResourceCleanupTest.",3
[FLINK-20830][k8s] Add type of Headless_Cluster_IP for external rest serviceThis closes #18461.,1
[FLINK-25839][e2e] Print the previous logs of restarted pod for k8s e2e tests,3
[FLINK-25895][table-planner] Split ExecNodeGraphJsonPlanGenerator and add ExecNodeGraph ser/de for intermediate JsonPlanGraph representationThis closes #18572.,5
[FLINK-25741][runtime] Skip buffer pools which have no floating buffer in buffer redistributing.This closes #18433.,2
[hotfix][table] Expose table.exec.rank.topn-cache-size config option`table.exec.topn.cache-size` config option was previously defined inside`StreamExecRank` and still marked as experimental. Move it to`ExecutionConfigOptions` and generate the corresponding docs.This closes #18540.,2
[hotfix][table-api][table-planner][test] Fix `HarnessTableDescriptor#toBuilder`Fix `HarnessTableDescriptor` to return the correct `Builder` and in turnthe correct `CatalogTable` which is the `HarnessCatalogTable` and not the`DefaultCatalogTable`.,2
[FLINK-25199][table-planner][test] Test fromValues() watermark propagationAdd a test in table-planner to validate the correct watermarkpropagation in case of `fromValues()`.Replace assertions in the class with assertj.It follows #18420.This closes #18439.,3
[hotfix][table-planner][tests] Use final for variables in `CommonExecSinkITCase`,1
[FLINK-25492][state/changelog] Fix materialization boundary for InMemoryStateChangelogWriter,4
[FLINK-25892][aws-base][test] add ArchUnit tests for test code,3
[FLINK-25892][kinesis-data-streams][test] add ArchUnit tests for test code,3
[FLINK-25892][kinesis-firehose][test] add ArchUnit tests for test code,3
[FLINK-25892][connector-base][test] add ArchUnit tests for test code,3
[FLINK-25892][cassandra][test] add ArchUnit tests for test code,3
[FLINK-25892][elasticsearch6][test] add ArchUnit tests for test code,3
[FLINK-25892][elasticsearch7][test] add ArchUnit tests for test code,3
[FLINK-25892][elasticsearch-base][test] add ArchUnit tests for test code,3
[FLINK-25892][gcp-pubsub][test] add ArchUnit tests for test code,3
[FLINK-25892][hbase1.4][test] add ArchUnit tests for test code,3
[FLINK-25892][hbase-base][test] add ArchUnit tests for test code,3
[FLINK-25892][hive][test] add ArchUnit tests for test code[FLINK-25892][hive][test] bugs fix[FLINK-25892][hive][test] bugs fix,0
[FLINK-25892][jdbc][test] add ArchUnit tests for test code,3
[FLINK-25892][kafka][test] add ArchUnit tests for test code,3
[FLINK-25892][kinesis][test] add ArchUnit tests for test code,3
[FLINK-25892][pulsar][test] add ArchUnit tests for test code,3
[FLINK-25892][rabbitmq][test] add ArchUnit tests for test code,3
[FLINK-25892][hadoop][test] add ArchUnit tests for the test code,3
[hotfix] Use properly shaded guava version,1
[FLINK-24780][table-planner] Port time/date/timestamp casts to new structure.Implement the time/date/timestamp related casts using the `CastRule`s structureand remove the relevant code from `ScalarOperatorGens`.This closes #18582.,1
"[FLINK-24439][source] Introduce CoordinatorStoreIn order to allow SourceCoordinatorss from different Sources (for example twodifferent Kafka sources, or Kafka and Kinesis) to align watermarks, they haveto be able to exchange information/aggregate watermarks from those differentSources. To enable this, we need to provide some CoordinatorStore concept,that would be a thread safe singleton.",1
[hotfix] Rewrite FsCheckpointStreamFactoryTest to JUnit 5,3
"[FLINK-25952] Savepoints on S3 are not relocatable even if entropy injection is not enabledWe treat all filesystems that extend from EntropyInjectingFileSystem asif they always inject entropy. However, we support returning null fromEntropyInjectingFileSystem#getEntropyInjectionKey which translates todisabled entropy injections. In such cases we should support savepointsrelocation by creating relative paths for exclusive files.",2
"[FLINK-25955][runtime] Moves maximum retained checkpoints parameter extraction into utility methodThe number of retained checkpoints needs to be extractedin the Scheduler and the cleanup process. Therefore, theextraction logic is moved from SchedulerUtils intoDefaultCompletedCheckpointStoreUtils.",4
"[FLINK-25955][runtime] Makes TestingCheckpointIDCounter and TestingCompletedCheckpointStore more genericWe need to extend the TestingCheckpointIDCounter to enabletriggering an Exception in the shutdown process on execution.This selective requirement could have been made with less changes.Instead, I decided to provide the most generic Testing*implementation offering a proper TestingCheckpointIDCounterimplementation which makes it more future-proof.",1
"[FLINK-25955][runtime] Introduces CheckpointResourcesCleanupRunnerCheckpointResourcesCleanupRunner is introduced along the correspondingfactory interface. This JobManagerRunner implementation handles thecleanup of jobs that terminated globally but were not properly cleanedup.CheckpoinResourcesCleanupRunnerTest and DispatcherTest.testJobCleanupWithoutRecoveredJobGraphare added to cover the functionality. Additionally, DispatcherFailoverITCasewas extended accordingly.A few Testing* implementations were added along this change to improvethe testability of the code.",3
[FLINK-25956][kryo] Remove noisy warnings,2
[FLINK-25957][ci] Cache cassandra/pulsar images,2
[hotfix] Clarify caching requirements,1
[FLINK-25917][tests] Share RpcSystem,5
[hotfix] Add TestingRpcServiceExtension for Junit5 tests,3
[FLINK-25817] Let TaskLocalStateStoreImpl persist TaskStateSnapshotsThis commit lets the TaskLocalStateStoreImpl persist the TaskStateSnapshots into thedirectory of the local state checkpoint. This allows to recover the TaskStateSnapshotsin case of a process crash. If the TaskStateSnapshot cannot be read then the whole localcheckpointing directory will be deleted to avoid corrupted files.,2
[hotfix] Simplify TaskLocalStateStoreImpl by removing testing constructor,3
[FLINK-25817] TaskSlotTable persists on local filesystem the slot allocation idsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-25817] Introduce SlotAllocationSnapshotPersistenceServiceThe SlotAllocationSnapshotPersistenceService has the goal to encapsulate the logic forpersisting SlotAllocationSnapshot into its own service.,2
[FLINK-25817] Test that the TaskExecutor can recover persisted allocation ids,3
[FLINK-25817] Move local state directory creation into TaskManagerServicesConfiguration.fromConfigurationThis commit also adds the resource id to the localState directory in order to avoid clashes with otherprocesses running on the same machine.,1
"[FLINK-25817] Let TaskExecutorLocalStateStoresManager only deleted owned local state directoriesThis commit makes sure that the TaskExecutorLocalStateStoresManager only deletes local state directorieson shutdown if they are owned by it. If the local state is stored under the working directory, then it isborrowed and, thus, won't be deleted when the TaskExecutorLocalStateStoresManager shuts down.",3
[FLINK-25817] Expose rest and rpc port at ClusterEntrypoint,1
[FLINK-25817] Add LocalRecoveryITCaseAdds an integration test for local recovery under process faults using the newlyintroduce working directory feature to persist state locally.,1
[hotfix] Set TestProcess logging to DEBUGThis commit changes CommonTestUtils.printLog4jDebugConfig to set the log level to DEBUGfor easier debugging of failed tests that use the TestProcess.,3
[hotfix] Allow AllocationID to be built from hexString representation,1
[FLINK-25817] Clean up of orphaned local stateThis commit adds logic to clean up orphaned local state by only retaining those allocationdirectories that could be recovered from the SlotAllocationSnapshotPersistence service.,5
[FLINK-25817] Unify logic between TaskExecutor.requestSlot and TaskExecutor.tryLoadLocalAllocationSnapshotsThis commit unifies the logic between TaskExecutor.requestSlot and TaskExecutor.tryLoadLocalAllocationSnapshots.This helps to reduce maintaince costs since both method use the same logic.This closes #18237.,2
[FLINK-25984][core] Remove deprecated API usages,4
[FLINK-25976][connectors/kinesis] Updating the default number of in flight records to 50This closes #18652,5
[FLINK-25932][table-planner] Add deterministic uid to every transformation created by StreamExecNodeThis closes #18621.,1
"[hotfix][table-planner] Use JsonIgnoreProperties to avoid plan mistakesMake use of `JsonIgnoreProperties` where ever possible and protectfrom future fields to be added by mistake to the json plans.Move the `JsonInclude` next to the corresponding fields, so thatis 100% visible what fields are affected.This closes #18618.",5
[FLINK-26006][aws] Close AWS SDK resources,2
[FLINK-25888][metrics] Move JobStatusMetrics to upper level,4
[FLINK-25888][metrics] Make JobStatusMetrics logic re-usable,2
[FLINK-25888][coordination] ExecutionStateUpdateListener provides previous state,1
[FLINK-25888][coordination][metrics] Capture deploymentTime,2
[FLINK-22311] [connector/jdbc] Validate maxRetries for XA SinkCo-authored-by: Alexander Fedulov <1492164+afedulov@users.noreply.github.com>,1
[hotfix][runtime] Extract common inner classes and methods to ExecutionGraphInfoStoreTestUtils,5
[FLINK-25329][runtime] Use cache in memory graph store and support memory graph store in session clusterThis closes #18360.,1
[hotfix][core] Complete the scala API for the new sink,1
[FLINK-25572][connectors/filesystem] Update File Sink to use decomposed interfacesThis closes #18642.,1
[FLINK-26032][client] add log info for the status of job submission and execution result.This closes #18677.,5
[FLINK-25745] Document incremental savepoints in CLAIM mode limitationThis closes #18645,2
"[FLINK-25960][network] Distribute the data read buffers more fairly among result partitions for sort-shuffleCurrently, the data read buffers for sort-shuffle are allocated in a random way and some result partitions may occupy too many buffers which leads to the starvation of other result partitions. This patch improves the scenario by not reading data for those result partitions which already occupy more than the average number of read buffers per result partition.This closes #18631.",5
[FLINK-26046][rest][docs] Fix link to OpenAPI spec,2
[FLINK-26039][table-runtime] Fix the incorrect value getter in map unnest table functionThis closes #18679.,1
[FLINK-25696][datastream] Introduce metadataConsumer to InitContext in SinkThis closes #18412,5
[FLINK-26001][avro] Implement ProjectableDecodingFormat for avro BulkDecodingFormatThis closes #18657,2
[hotfix][docs] Fix example,0
[FLINK-25841][table] Introduce new APIs for FLIP-190 single statement plan compilation,1
[FLINK-25841][table] Add helpful JavaDocs at various locationsThis closes #18573.,2
[FLINK-26044][table] Properly declare an internal UNNEST functionThis closes #18685.,1
[hotfix] Let TaskExecutorTest.testReleaseInactiveSlots use TaskExecutorGateway,1
[FLINK-26036] Only respond to TaskExecutor.freeSlot when runningThis commit changes the TaskExecutor to only respond to freeSlot when running.This avoids that during the shut down of a TaskExecutor a JobMaster free slotcall will delete the slot allocation snapshot. The JobMaster will send theserpcs because the TaskExecutor disconnects from it. It is important to keep theslot allocation snapshot in order to be able to recover this information whenrestarting the process.This closes #18684.,5
[FLINK-24440][source] Announce and combine latest watermarks across SourceOperators,1
[hotfix][ci] Always print environment information,5
[hotfix][table-api-java] Add missing annotations to PlanReference,1
[FLINK-25742][akka] Remove the serialization of rpc invocation at Flink side.This closes #18434.,2
[FLINK-25975][docs] add document about AvroParquet format use cases[FLINK-25975][docs] bugs fixThis closes #18660.,0
[FLINK-26035][build][planner] Add table-planner-loader-bundle module,1
[FLINK-25755][runtime] Introduce shared state transition interfaces,2
[hotfix][test] replace the deprecated ParquetAvroWriters with the AvroParquetWriters,3
[hotfix][doc] update document since ParquetAvroWriters has been deprecated and replaced by AvroParquetWriters.,2
[hotfix][doc] fix typos,2
[hotfix][doc] add class level java doc.,2
[FLINK-26034][Build System] Add maven wrapper for FlinkThis closes #18697.,2
[FLINK-26064] Temporarily disable KinesisFirehoseSinkITCase.,2
"[FLINK-26062][state/changelog] Replace poll() with remove() for PQ statesPriorityQueue elements with equal priority can be polled indifferent order before and after recovery.This may result in e.g. timers being removed or not being firedThis change addresses this by recording poll() as remove(),which is based on equals.",4
[FLINK-25996][runtime] Introduce job property isDynamicGraph to ExecutionConfigThis closes #18672.,5
[FLINK-26004][runtime] Introduce ForwardForConsecutiveHashPartitionerThis closes #18673.,2
[FLINK-24897][yarn] Make usrlib work for YARN application and per-jobThe $FLINK_HOME/usrlib will be shipped automatically and included into the system classpath when running a per-job/application cluster. This behavior can be controlled with the yarn.classpath.include-user-jar parameter.This closes #18531.,2
[FLINK-25530][python][connectors/pulsar] Support Pulsar source connector in Python DataStream API. (#18388),5
"[FLINK-25830][docs]Typo mistake in ""Metric Report page"" of the documentationThis closes #18713.",2
[FLINK-25937][datastream] Restore the environment parallelism before transforming in SinkExpander#expand,5
[FLINK-26054][build] Add enforcer rule to forbid direct dependency on table planner,1
[FLINK-26073][onnectors] Remove Twitter connector,4
[FLINK-26072][connectors] Deprecate NiFi connector,2
[FLINK-25433] Add retry logic to DefaultResourceCleaner,4
[FLINK-25844][table-api-java] Expose StatementSet#compilePlanThis closes #18701.,1
"Revert ""[hotfix][ci] Always print environment information""This reverts commit f5819cec01eab914e8d4e7db41587b715a557e3b.",5
[hotfix][docs] Cleanup project configuration page,5
[FLINK-26036] Don't execute TaskExecutor.freeSlotInternal if not runningThis commit prevents the execution of TaskExecutor.freeSlotInternal if theTaskExecutor is shutting down. This will preserve the slot allocation informationwhen shutting down.This closes #18711.,5
[FLINK-25999] Deprecate Per-Job Mode,2
[hotfix][build] Move one-off properties into using modules,1
[FLINK-25785][Connectors][JDBC] Upgrade com.h2database:h2 to 2.1.210,5
[FLINK-26071][table] Add various improvements to plan compilation- Now Planner#compilePlan fails if the plan cannot be serialized.- Add CompiledPlan#explain and toString implementation.- Invoking Planner#loadPlan will fail on Batch planner.This closes #18701.,0
[FLINK-26076] Fix ArchUnit violations in Source(Sink)MetricsITCaseThis closes #18709,1
[FLINK-25990][table-api-java-bridge] Add ProviderContext for generating uids in DataStream/Transformation Scan/SinkProviderThis might break existing implementations if the provider was implemented as a Java lambda. Please note thatthe interface was not annotated as a @FunctionalInterface.This closes #18667.,1
[hotfix][changelog] Let ChangelogStateHandleStreamImpl to serialize checkpointed size,4
[FLINK-25478][chaneglog] Correct the state register logic of ChangelogStateBackendHandle,4
"[FLINK-25943][connector/common] Add buffered requests to snapshot state in AsyncSyncWriter, Implement state serializer in AsyncSyncWriter and KinesisDataStreams and KinesisFirehose.",5
"[FLINK-25796][network] Avoid record copy for result partition of sort-shuffle if there are enough buffers for better performanceCurrently, for result partition of sort-shuffle, there is extra record copy overhead introduced by clustering records by subpartition index. For small records, this overhead can cause even 20% performance regression. This patch aims to solve the problem.In fact, the hash-based implementation is a nature way to achieve the goal of sorting records by partition index. However, it incurs some serious weaknesses. For example, when there is no enough buffers or there is data skew, it can waste buffers and influence compression efficiency which can cause performance regression.This patch solves the issue by dynamically switching between the two implementations, that is, if there are enough buffers, the hash-based implementation will be used and if there is no enough buffers, the sort-based implementation will be used.This closes #18505.",1
[FLINK-25987][state/changelog] Replace lastSqn with nextSqn()The current semantics of ChangelogWriter.lastAppendedSqn doesn't allowto distinguish between initial empty and non-empty states.This results in wrong SQN passed to truncate and persist methods.This change solves this by replacing lastAppendedSqn with nextSqn.It essentially moves the responsibility to call sqn.next() on materializationfrom backend to writer which has the knowledge of whether there were any changes or not.,4
[FLINK-25610][connector/firehose] Adding table API  for kinesis firehose.,1
[FLINK-25610][connector/firehose] moved common context data to base class for AsyncDynamicTableSinkFactory.,5
[FLINK-25810][connector/kinesis] Renaming e2e test module for kinesis data streams.,5
[FLINK-25995][table-planner] Make implicit assumption of SQL local hash explicitThis closes #18707,1
[FLINK-25840][tests] Add semantics test support for connector test frameworkThis closes #18547,1
[FLINK-25466][state] Enable state descriptor to handle StateTtlConfig#DISABLED,5
[FLINK-25118][streaming] Add vertex topology index prefix in vertex name,0
[FLINK-24880][python] Fix PeriodicThread to handle properly for negative wait timeout valueThis closes #18640.,0
[FLINK-25883][python] Set the default value of DEFAULT_BUNDLE_PROCESSOR_CACHE_SHUTDOWN_THRESHOLD_S to 30 days,1
[Flink-25484][fs-connector] Support inactivityInterval config in table apiThis closes #18359,5
[FLINK-25940][python] Fix the unstable test test_keyed_process_function_with_state in PyFlinkThis closes #18742.,2
"[hotfix] Makes TestingDispatcher using the set JobResultStore for recovered dirty job results if none is setThis change changed the behavior in theDispatcherTest.testDuplicateJobSubmissionWithGloballyTerminatedJobId a bit.Previously, the an entry was added to the JobResultStore to simulate a jobwith the given job ID already being submitted. This job result wasn't passedin as a dirty job result to the Dispatcher, though. The test worked as expected,still, because it just didn't create a cleanup runner (due to the missing dirtyJobResult). The Dispatcher.isDuplicateJob still worked like normal because it lookedup the JobResultStore and found the dirty JobResultEntry.With the change, this a dirty JobResult is passed into the Dispatcher which triggersthe creation of a CleanupRunner. The creation of the CleanupRunner will go down thecode path and parse the JobResult trying to derive the JobStatus from the ApplicationsStatus,which is not possible for ApplicationStatus.UNKNOWN. That's where the Exception is thrown.The test can be updated easily by just using a valid ApplicationStatus.",1
[hotfix] Introduces timeout variables in CheckpointResourcesCleanupRunnerTest,3
[hotfix] Introduces builder factory method for single-job JobManaagerRunnerRegistry,1
[FLINK-25974] Moves CheckpointsCleaner into CheckpointResourcesCleanupRunnerWe can handle the closing of the CheckpointsCleaner internally similar tohow it's done in SchedulerBase.closeAsync where the CheckpointsCleaner is closedasynchronously right after the checkpoint-related resources are shutdown.,4
"[FLINK-25974] Removes cleanup future cancellationWe don't want to cancel the cleanup but let the call fail exceptionally.This matches the behavior of JobMasterServiceLeadershipRunner:The cancellation of JobMasterServiceLeadershipRunner triggersthe cancellation of the Scheduler which cancels the ExecutionGraph.The termination of the ExecutionGraph is propagated to the Dispatcherwhere the normal job removal and cleanup is triggered. As a consequence,JobMasterServiceLeadershipRunner is closed which closes theDefaultJobMasterServiceProcess which closes the JobMaster through theRpcEndpoint's closeAsync. That triggers the stopping of the Schedulerthrough JobMaster.onStop and JobMaster.stopJobExecution and as aconsequence shutting down the checkpoint-related stores on the main thread.",1
[hotfix][table-planner] Avoid rawtypes warning in StreamExecDeduplicate,2
[hotfix][table-planner] Move non-temporal-sort config option to InternalConfigOptionsMove experimental config option for `StreamExecSort` from the class to the`InternalConfigOptions`.,5
[hotfix][table-api][table-planner][docs] Move StreamExecDeduplicate options to ExecutionConfigOptionsMove options used in `StreamExecDeduplicate` to `ExecutionConfigOptions`.,5
[hotfix][table] Rename operator name optionRename: `table.optimizer.simplify-operator-name-enabled` to`table.exec.simplify-operator-name-enabled` and move it from`OptimizerConfigOptions` to `ExecutionConfigOptions` since ithas nothing to do with the optimizer.,5
"[FLINK-25388][table-planner] Add consumedOptions to ExecNodeMetadataScanned all annotated StreamExecNodes and added the `consumedOptions` paramto their `@ExecNodeMetadata` annotation, denoting which configuration optionseach ExecNode is using that might influence the topology and thus statefulrestores.This closes #18624.",2
[hotfix][table-planner] Rename transformation name for StreamExec(Python)GroupWindowAggregate,0
"[FLINK-26067] Remove timeout on TestingContender#awaitRevokeLeadership. If the test failure repeats, we should get a full thread dump that could provide us with more context.",1
[FLINK-25697][prometheus] Add 'hostUrl' parameter for pushgateway,2
[FLINK-21407][docs][formats] Remove MongoDb connector as it is not supported on DataStream API.,5
"[FLINK-26068] Update ZooKeeperStateHandleStore to use an indepotent replace operation for #setStateHandle, that has been introduced in CURATOR-584, to avoid possible BadVersionException during connection issues.",0
[hotfix][test] Move test only used method to test,3
[FLINK-24441][source] Block SourceOperator when watermarks are out of alignment,1
[hotfix][tests] Don't override ChangelogEnable setting from pom.xml,5
[FLINK-26093][tests] Adjust SavepointFormatITCase for ChangelogStateBackend,4
[hotfix][datastream] move the change and restore of env parallelism into the adjusTransformations method.,4
[hotfix][datastream] bug fix,0
[hotfix][sql-parser] Convert tests to JUnit 5 and enable parallel test execution,3
[FLINK-25845][table] Add EXECUTE PLAN,1
[FLINK-25845][table] Add COMPILE PLAN and COMPILE AND EXECUTE PLANThis closes #18648.,1
[hotfix][docs] Improve guide for generating config options docs,2
[hotfix][docs] Remove too specific command in docs/README.md,2
[FLINK-26101][changelog] Avoid shared state registry to discard multi-registered identical changelog stateThis closes #18741.,4
[hotfix][table-planner] Remove unused imports in SetOpRewriteUtil,1
[hotfix][table-common] Clarify serializability of CatalogTable,2
[FLINK-25870][table] Introduce ContextResolvedFunction similar to ContextResolvedTableThis closes #18703.,0
[hotfix][tests] Disable changelog in JsonAggregationFunctionsITCase,5
[FLINK-23559][tests] Randomize periodic materialisation interval in tests,3
[FLINK-25288][tests] Add savepoint/metric cases in source suite of connector test framework,1
[FLINK-25288][tests][pulsar] Make pulsar e2e tests more robustThis closes #18516.,3
[hotfix][doc] Fix typos.,2
[FLINK-25046][runtime] Convert unspecified edge to rescale when using adaptive batch schedulerThis closes #18715.,1
[FLINK-25583][connectors/filesystem] Prepare resources for serializer migration tests.This closes #18758.,3
[FLINK-25783][docs-zh] Translate azure_table_storage.md page into Chinese.This closes #18766.,2
[FLINK-25198][docs] Add doc about name and description of operatorThis closes #18400.,1
[FLINK-25640][docs] Enhance the document for blocking shuffleThis closes #18723.,2
[hotfix][docs] Describe how to resolve the ITCASE_USE_MINICLUSTER rulecloses #18695,5
[hotfix] Correct JUnit 5 assertions in SourceOperatorAlignmentTest,3
"[FLINK-25982] Support idleness with watermark alignmentWhen a SourceOperator becomes idle it reports MAX_WATERMARK to thesource coordinator, allowing other participating tasks/sources toprogress their watermark. As soon as the operator becomes active itsends an actual watermark. Either a new, updated or the old one if itbecame active without increasing the watermark.",1
[FLINK-26090][table] Remove pre FLIP-84 APIsThis closes #18724.,4
[FLINK-26002][tests] Added RestoreUpgradedJobITCase for checking situation with restoring savepoint/checkpoint on changed job,4
[FLINK-25574][connectors/async] Migrate AsyncSink connectors to decomposed SinkV2,2
[hotfix][annotations] Add FlinkVersion#current,2
[FLINK-26055][table] Use FlinkVersion rather than version string from core in persisted planThis closes #18755.,2
[FLINK-25825][connector-jdbc] MySqlCatalogITCase fails on azureThis closes #18653.,0
[FLINK-25906][streaming] check explicit env allowed on StreamExecutionEnvironment own.,1
[FLINK-25821][python][doc] Add the doc of execution mode in PyFlinkThis closes #18748.,2
[FLINK-26077][runtime] Support operators send request to Coordinator and return a response (#18737),1
[FLINK-24474] Default rest.bind-address to localhost in flink-conf.yaml,5
[FLINK-25289][tests] Introduce sink test suite in connector test frameworkThis closes #18496.,1
[hotfix][tests][connector/kafka] Disable KafkaSink metric tests until FLINK-26126 has been fixed,0
[hotfix][network] Remove the deduplication for CancelPartitionRequest.To avoid the memory leak in the record map for deduplication.,4
[FLINK-15455][network] Enabled tcp connection reuse across multi jobs.This closes #18417.,1
[FLINK-25053][docs] Document how to use the usrlib to load code in the user code class loaderThis closes #18450.,1
[hotfix] Adds @Nullable annotation,1
[hotfix] Introduces public constants for file extension,2
[hotfix] Adds missing assert to make finally use of the local variable,1
[FLINK-26015] Adds TestContainerExtension and MinioTestContainer,5
[FLINK-26015] Fixes FileSystemJobResultStoregetFileStatus does not work with object storeslike s3 on directories. I created FLINK-26061 tocover a proper solution for this. We should alignthe contracts here and make it more obvious.,1
[FLINK-26015] Adds testcase covering a basic job execution in HA with object store as a backend storage,3
[FLINK-26174][kinesis] Add Internal annotation to KinesisDataStreamsSink#restoreThis closes #18795.,5
[FLINK-25973][runtime] Renamed ArchivedExecutionGraph.createFromInitializingJob into createSparseArchivedExecutionGraphThe renaming became necessary because the method is now also usedin the CheckpointResourcesCleanupRunner where the job is not ininitialization phase anymore.,5
[FLINK-25978][runtime] Removes obsolete cleanup tests from DispatcherTestThe Dispatcher cleanup is entirely covered by the following tests:- DispatcherResourcesCleanupTest: Tests whether local or global cleanup     are triggered.- DispatcherResourceCleanerFactoryTest: Tests that the right components are     cleaned up for the local and the global cleanup.- The individual components have there own cleanup unit tests:  - BlobServerCleanupTest  - DefaultJobGraphStoreTest  - DefaultJobManagerRunnerRegistryTest  - AbstractHaServicesTest  - JobManagerGroupTest,3
[FLINK-26017][runtime] Adds log message to when a job is marked as dirtyThis log message serves as a counterpart to when the job is marked asclean which is already logged in the Dispatcher. This enables the user toverify the state of the JobResultStore through log messages.,2
[FLINK-26107][runtime] OperatorCoordinator uses failure handler of the current state,0
[hotfix][runtime] Adds & fixes JavaDoc,2
[FLINK-26117][runtime] Introduces ofLocalResource in DispatcherResourceCleanerFactoryThis method is utilized by the JobManagerMetricGroup and theJobManagerRunnerRegistry. Both of them provide local artifactsbut need to be called as part of the global cleanup as well.That change makes it possible to remove the obsoleteGloballyCleanableResource interface from JobManagerRunnerRegistry.,1
[FLINK-26117][runtime] Removes GloballyCleanableResource from JobManagerRunnerRegistry,1
[FLINK-26148][runtime] Change the format of adaptive batch scheduler config option to jobmanager.adaptive-batch-scheduler.XXXThis closes #18782.,5
[FLINK-24246][connector/pulsar] Bump PulsarClient version to latest 2.9.11. Bump the pulsar-client-all version in pom file.2. Exclude useless dependencies for pulsar-client-all.3. Bump the Pulsar docker version.4. Change the dependencies to pass the tests.5. Drop PulsarTransactionUtils and fix compile issues in tests.6. Add bouncycastle to Pulsar e2e tests.,3
[FLINK-26020][connector/pulsar] Unified Pulsar Connector config model for Pulsar source and sink.1. Define new PulsarConfiguration for common config class.2. Define new PulsarConfigValidator for common config validation.3. Merge SourceConfiguration and Configuration into one class.4. Change source config options' description and regenerate the docs.5. Fix the compile error in tests.6. Drop Configuration in constructor parameters for all the source classes.,2
[FLINK-26023][connector/pulsar] Create a Pulsar sink config model for matching ProducerConfigurationData.,5
[FLINK-26024][connector/pulsar] Create a PulsarSerializationSchema for better records serialization.,1
[FLINK-26022][connector/pulsar] Implement at-least-once and exactly-once Pulsar Sink.,2
"[FLINK-26025][connector/pulsar] Replace MockPulsar with new Pulsar test tools based on PulsarStandalone.1. Drop some unused fields in test classes.2. Fix the checkstyle issues for source test.3. Fix violations for Pulsar connector according to the flink-architecture-tests.4. Create a standalone Pulsar for test.5. Add new methods to PulsarRuntimeOperator.6. Fix the bug in PulsarContainerRuntime, support running tests in E2E environment.7. Create PulsarContainerTestEnvironment for supporting E2E tests.8. Add a lot of comments for Pulsar testing tools.9. Drop mocked Pulsar service, use standalone Pulsar instead.",1
[FLINK-26026][connector/pulsar] Create unit tests for Pulsar sink connector.,3
[FLINK-26038][connector/pulsar] Support delay message on PulsarSink.,1
[FLINK-25571] Update Elasticsearch Sink to use decomposed interfaces,1
[FLINK-25980][datastream] remove unnecessary condition,4
[FLINK-25532] Improve Documentation of Flink Docker-Compose (#18725)* [FLINK-25532] add Flink SQL Client example to docker-compose docs* [hotfix] restructure docker docs and remove docker swarm,2
[FLINK-24745][format][json] Support Oracle OGG json formatThis closes #17657.,5
[FLINK-24745][format][json] Improve the metadata tests and documentation of OGG json formatThis closes #18738.,5
[FLINK-26119][connectors/common] Switching AsyncSinkWriterStateSerializer from @Internal to @PublicEvolving,2
"[hotfix][table-api-java] Extract explain, execute and compilePlan API capabilities into specific interfaces",4
[FLINK-26089][table-api-java] Introduce TablePipelineThis closes #18755.,2
[FLINK-25701][kafka] Add Flink API annotation to all connector classes based on the new Source/Sink design,1
[FLINK-25701][kafka] reduce architectural violation,2
[FLINK-26060][table-planner] Remove persisted plan feature support for Python UDFsThis closes #18688.,1
[FLINK-24474] Bind Jobmanager and Taskmanager RPC host addresses to localhost by default,1
[FLINK-26177][tests] Disable PulsarSourceITCase rescaling tests temporarily,3
[hotfix][tests] Explicitly disable changelog in migration tests,3
"[FLINK-26079][state/changelog] Disallow recovery from non-changelog checkpointsPrivate state of non-changelog checkpoints is not registeredwith the SharedStateRegistry on recovery.Therefore, after recovering in CLAIM mode it will be discardedas soon as the initial checkpoint is subsumed.This change disallows recovery by checking handle types duringChangelog backend creation.",1
[FLINK-26095][metrics] Respect bind-host for MQS actor system,5
[FLINK-25983] Add a metric for tracking watermark driftThis commit introduces a metric in SourceOperator to track the driftfrom the current aligned maximal watermark in a watermark group. Themetric is computed for every subtask of a source.,1
[hotfix][test] Add support for field assignability in ArchUnit,1
[hotfix] Fix JUnit 5 mini cluster arch unit rules,5
[FLINK-25983] Add API for configuring maximal watermark driftWe should be able to specify a watermark alignment group and maximaldrift from the current watermark on a per source/task/partition basis.This can be done by adding configuration parameters to theWatermarkStrategy.,2
[hotfix][test-utils-junit] Fix bad FlinkAssertions method signature,3
[hotfix][table] Rename table.exec.sink.legacy-cast-behaviour to table.exec.legacy-cast-behaviour,0
[hotfix][table-planner] Improve CastRule#canFail for nested types,0
[FLINK-24385][table] Introduce TRY_CASTThis closes #18611.,1
[hotfix][core] Do not set parallelism without checking whether the parallelism is set when translating Sink.,1
"[FLINK-25583][connectors/filesystem] Introduce CompactingFileWriter, implement in implementations of InProgressFileWriter.",2
[FLINK-25583][connectors/filesystem] Add the getPath and getSize methods in PendingFileRecoverable.,2
"[FLINK-25583][connectors/filesystem] Add bucketId and compactedFileToCleanup in FileSinkCommittable, delete compactedFileToCleanup in FileCommitter.",2
[FLINK-25583][connectors/filesystem] Add compaction support for FileSink.,2
[FLINK-25583][connectors/filesystem] Add IT cases for compaction in FileSink.This closes #18680.,2
[FLINK-26118][connectors/common] Setting defaults in test to reduce test complexity,3
[FLINK-26118][connectors/common] Add support for AsyncSink to downscale with state. AsyncSinkWriter can be restored from multiple BufferedRequestState,1
[FLINK-26189][build] Remove bundling of grizzled-slf4j from rpc-akka,4
[hotfix][legal] Add missing Scala license to rpc-akka,1
[FLINK-25490][checkpoint] Complete the Chinese document regarding final checkpointThis closes #18766.,2
[FLINK-26168][runtime] The judgment of chainable ignores StreamExchangeMode when partitioner is ForwardForConsecutiveHashPartitionerThis closes #18789.,4
[FLINK-26199][table-api-java] Annotate StatementSet#compilePlan as experimental.This closes #18809.,1
[FLINK-26187][docs] Chinese docs only redirect for chinese urls,2
[hotfix][legal] Sort gs-fs-hadoop NOTICE entries,0
[hotfix][build] Cleanup unnecessary shade-plugin settingsThese settings are automatically inherited from the parent pom.,1
[FLINK-26180][connectors/filesystem] Update docs to introduce the compaction for FileSink.This closes #18797.,2
[FLINK-26014][docs] Add documentation for how to configure the working directory,1
[FLINK-26014][docs] Add documentation for how to use the working directory on K8sThis closes #18808.,1
[FLINK-25289][tests][kafka] Use plain flink-connector-test-utils jar,3
[FLINK-26195][kafka] use TestLoggerExtension in JUnit5 tests,3
[FLINK-26164] Document watermark alignmentThis closes #18783,2
[hotfix][state] Explicitly validate native savepoints support,1
[FLINK-26165][tests] Don't test NATIVE savepoints with Changelog enabled,0
[FLINK-26185] Update Elasticsearch6SinkExample to use new unified Sink interface,1
[FLINK-26185] Update Elasticsearch7SinkExample to use new unified Sink interface,1
[hotfix][tests] Migrate AdaptiveSchedulerTest to assertj,3
[FLINK-21439][runtime] Move FailureResult into separate class,0
[FLINK-21439][runtime] Deduplicate failure handling logic,2
[FLINK-21439][runtime] AdaptiveScheduler supports exception history,1
[FLINK-26218] Enable JUnit 5 Automatic Extension Detection,3
[FLINK-26167][table-planner] Explicitly set the partitioner for the sql operators whose shuffle and sort are removedThis closes #18785,4
[FLINK-26215][statsd] Migrate tests to JUnit5,3
[FLINK-26219][slf4j] Migrate tests to JUnit5,3
[FLINK-24307][docs] Cleanup Scala examples,4
[hotfix][pulsar] Disable tests,3
[FLINK-26105][e2e] Removes printing of logs to stdout for pyflink_testI removed the test_pyflink.sh to align it with how errors arehandled in other e2e tests. The logs are accessible through thebuild artifacts and shouldn't spill into stdout. The rollingfilenames in flink might lead to a strange ordering anyway.,2
[FLINK-26105][e2e] Fixes log file extensionRolling log file naming strategy is enabled by default whichmight cause test instabilities do to the relevant substringnot being present in the *.log file. This change expands thegrep and find calls to also consider *.log.[0-9]+ files.,2
[FLINK-23240][runtime] Master process supports living through multiple leader sessions.This is supported on all non-Yarn deployments. The Yarn deployment is not supported because each AM process can only register at Yarn RM for once.close #18793,1
[FLINK-26192][pulsar] Remove call to Runtime#halt,1
[FLINK-26241][pulsar] Fix divide-by-zero error,0
[FLINK-26231][state/changelog] Fix ChangelogStateBackendHandle constructor,4
[FLINK-24407][doc-zh] Fix the broken links in Chinese document of Pulsar connectorThis closes #17622.,2
[FLINK-25600][sql-client] Support new statement set syntax in sql clientThis closes #18363,1
[FLINK-25600][docs] Update doc about new statement set syntaxThis closes #18363,1
[FLINK-25225][e2e] Add e2e TPCDS tests to run against the AdaptiveBatchSchedulerThis closes #18720.,1
"[FLINK-25992][Runtime/Coordination, Tests] For stability, wait until the latest restored checkpoint is not null to avoid race condition",3
[hotfix][avro] Add comments to explain why projection pushdown works for avro bulk formatThis closes #18717,1
[FLINK-25491][table-planner] Fix bug: generated code for a large IN filter can't be compiledThis closes #18675,0
[FLINK-26233][connectors/filesystem] Fix the FileSinkCompactionSwitchITCase.testSwitchingCompaction.This closes #18837.,3
[FLINK-25893][runtime] Fix that ResourceManagerServiceImpl may call ResourceManager#deregisterApplication before RM being fully started.,0
[FLINK-25893][runtime] Do not report error if ResourceManagerServiceImpl#deregisterApplication is called when there's no leading RM.,0
"Revert ""[FLINK-25885] Suppress error reporting for ResourceManagerServiceImpl.deregisterApplication""This reverts commit 59d2d84d83696d4775b6ff3ec97f8274ff6e371f.close #18853",4
[FLINK-26016][hive] Fix FileSystemLookupFunction does not produce correct results when hive table uses columnar storageThis closes #18777,1
[FLINK-24607] Let Deadline handle duration overflow.,0
[FLINK-24607] Add util methods to shutdown executor services.,1
[FLINK-24607] Make OperatorCoordinator closure more robust.,1
[FLINK-26235][connectors/filesystem] CompactingFileWriter and PendingFileRecoverable should not be exposed to users.This closes #18827.,1
[FLINK-26210][pulsar][tests] Add jaxb-api to e2e test,3
[FLINK-26145][docs] Fix a kubernetes image that does not exist in the document.This closes #18799.,2
"[FLINK-26120][tests] Relax CheckpointIDCounterTestBase assertionsThe test was verifying that the counters produced perfect sequences, but we only require strictly monotonous sequences.",1
[FLINK-25856][python] Fix use of UserDefinedType in from_elementsThis closes #18826.,1
[FLINK-26064][connector/firehose][connector/kinesis] Using separate event loop groups for firehose and kinesis IT tests.,3
[hotfix][table-planner] Improve error reporting when serializing CatalogTable into the planThis closes #18801.,2
[FLINK-26221][prometheus] Migrate tests to JUnit5,3
[FLINK-25851][build][tests] Bump bytebuddy to 1.8.22,3
[FLINK-25851][cassandra][tests] Inject dynamic table name into Pojos,3
[FLINK-26152] [docs] Translate the page of SQL/queries/WITH clause (#18828),1
"[FLINK-26146] Add tests of flink version upgrades to cover native snapshotsTurned SavepointMigrationTestBase into SnapshotMigrationTestBase that supports testing canconicalsavepoints, native savepoints, and checkpoints; and adapted sub classes accordingly.",3
[FLINK-26176] Fix scala savepoint migration tests- Remove test parameters and artifacts for tests of rocksb state backend since artifacts are no  rocksdb savepoints but actually memory state savepoints- Remove test parameters and artifacts for tests of savepoints with Flink version 1.7 or below  as those are not safe to restore due to bug FLINK-10493,2
[FLINK-26146] Adapt scala tests to cover native snapshots migrationAdapt scala savepoint migration tests to cover native savepoints and checkpoints.This closes #18850,3
[FLINK-25977][connectors/kinesis] Closing HTTP & SDK clients in sink & integration tests.,3
[FLINK-26278][table-api-java] Add Expressions.col to Table APIThis closes #18861.,1
[FLINK-25941][streaming] Only emit committables with Long.MAX_VALUE as checkpoint id in batch modeBefore this commit the SinkWriter and Committer operators emittedcommittables on endInput. This was troublesome because by doing so thecheckpointId was set to effectively Long.MAX_VALUE becausethe emission was not part of any checkpoint. With the completion ofFLIP-143 all jobs in streaming mode have a final checkpoint when theytransition to finish so we can rely on the normal checkpoint mechanismand only need endInput for the batch execution.,5
[FLINK-26294][test] Using fixed description for ArchUnit ITCaseRules,0
[FLINK-26227][graphite] Migrate tests to JUnit5,3
"[FLINK-26299] Reintroduce old JobClient#triggerSavepoint,stopWithSavepoint methods",2
[hotfix][core] Add CollectionUtil#entry and CollectionUtil#map,1
"[FLINK-25428][table] Expose string casting for map, multiset, structured, row and rawThis closes #18524.",1
[FLINK-24446][table] Fix missing fractional seconds during STRING to TIMESTAMP castingThis closes #18632.,0
[FLINK-26300][connectors/common] Increased timeout for LocalstackContainer to start.,1
[hotfix] Change the scope of WatermarksWithWatermarkAlignment,4
[hotfix] Make AbstractTestBase MiniCluster final,5
[hotfix][tests] Add instructions for updating archunit stores,5
[FLINK-26225][jmx] Migrate tests to JUnit5,3
[FLINK-25782][docs-zh] Translate datastream filesystem.md page into Chinese.This closes #18718.,5
[FLINK-26228][dropwizard] Migrate tests to JUnit5,3
[FLINK-26226][influxdb] Migrate tests to JUnit5,3
[FLINK-26291][connectors/firehose] Changed integration test from asserting exactly once to at least once....,3
[FLINK-25798][docs-zh] Translate datastream/formats/text_files.md page into Chinese.This closes #18493.,5
[FLINK-26042][python][doc] Raise exception when python version does not meet requirements.This closes #18894.,1
[FLINK-24571][connectors/elasticsearch] Supports a system time function(now() and current_timestamp) in index pattern,1
[FLINK-26319][table-planner] Fix expected exception in CastFunctionITCase,1
[FLINK-25385][table-planner] Clean up RexNodeSerdeTest,3
[hotfix][table-api-java] Fix typo in TableConfigOptions,5
[hotfix][table] Deprecate legacy function stack classes,1
[hotfix][table-planner] Improve exception message for ContextResolvedTable serde,0
[FLINK-25385][table] Harden internal function handling,1
[FLINK-25385][table] Harden symbol handling,2
[FLINK-25385][table-planner] Harden the function serialization in JSON plan,5
[FLINK-25385][table-planner] Regenerate plansThis closes #18858.,2
[FLINK-26318][tests] Recover from the latest checkpoint in ChangelogCompatibilityITCaseThis closes #18898.,4
[FLINK-26297][table-planner] Rename ShortcutUtils method to get TableConfig,5
[hotfix][table-planner] Organize imports in scala files,2
[FLINK-26297][table-planner][table-runtime] Introduce ExecNodeConfigIntroduce `ExecNodeConfig` and make appropriate changes so that all`ExecNode`s are using this new class which contains the merged configurationfrom the planner (including executor) and the node's persisted configurationin the JSON plan.Replace usages of `TableConfig` with `ReadableConfig` or at least`ExecNodeConfig` wherever possible.,5
"[FLINK-26297][table] Use `tableConfig` as name for `TableConfig` variablesTo make clear separation of configurations used, and prepare for futureeffort to use `ReadableConfig` instead of `TableConfig` rename variablesand function args that require `TableConfig` to `tableConfig` instead ofplain `config` or `conf`.Minor code improvements to remove IDE warnings in the touched classes.",2
"[FLINK-26297][table-planner] Rename PlannerConfiguration to PlannerConfigTo be consistent with `TableConfig`, `ExecNodeConfig`, etc.This closes #18888.",5
[FLINK-26159][doc] add description for MAX_FETCH_RECORD related questionUpdate docs/content/docs/connectors/datastream/pulsar.mdCo-authored-by: MartijnVisser <martijn@2symbols.com>Update docs/content/docs/connectors/datastream/pulsar.mdCo-authored-by: MartijnVisser <martijn@2symbols.com>add Chinese documentation,2
[FLINK-26160][pulsar][doc] update the doc of setUnboundedStopCursor(),1
[FLINK-25247][docs] Remove mentions of Java 8,4
[FLINK-25793][connector/base] Fix high thourouput bug for throttling destinations.,0
"[hotfix][tests] Lazily create MiniClusterResourceConfiguraitonCertain configuration parameters (e.g., ports) are inferred from other extensions. As extensions commonly only really start up resources in before*() methods the current approach of determining the configuration up-front imposes limitations as to whether a MiniClusterExtension can be static or not.With this change the configuration can also be passed in with a Supplier that is evaluated right before the cluster is started.",4
"[hotfix][tests] Restructure AbstractHaJobRunITCaseRefactors the test to make use of a static MiniClusterExtension, in preperation FLINK-26252.",2
[FLINK-26252][tests] Refactor MiniClusterExtension to support JUnit 5 parallel tests,3
[FLINK-25846][connector/kinesis] Fixing stuck at Cancelling on failed requests,0
[FLINK-25848][connectors/kinesis] KDS Sink failing fast when bad credentials are provided.,1
[FLINK-25848][connectors/firehose] Separated unit style tests for the KDF Sink into KinesisFirehoseSinkTest,3
[hotfix] Uses close instead of stop in ZooKeeperExtension post-test cleanup,4
[hotfix] Aligns state check in ZooKeeperExtension,0
[hotfix] Migrates ZooKeeperLeaderRetrievalConnectionHandlingTest to JUnit5/assertj,3
"[FLINK-26121][runtime] Adds clearUnhandledEvents() methodWe experienced some ZK connection issue which resulted in aSUSPEND and a RECONNECT event which were not handled and,therefore, stayed in the queue blocking a thread for thesecond event (because the capacity of the internally usedArrayBlockingQueue is set to 1). Shutting down the driverinitiates a shutdown of the ExecutorService which is usedfor the listeners internally (seeZooKeeperLeaderRetrievalDriver.close()). The blocking threadwill cause a fatal error through an InterruptedException.The test will fail due to the fatal error in the end.Cleaning unhandled events at the end of the test run fix the issue. Additionally, the tests were aligned by moving genericcode into a helper method.",4
[FLINK-26283][table-planner] Harden AggregateCall serialization in JSON planThis closes #18872.,5
[hotfix][table-planner] Clean up serde classes,4
[FLINK-26186][test] use reside in shaded package filter,1
[FLINK-26186][test] Allow caller annotated with @VisibleForTesting call target method annotated with VisibleForTesting.,3
[FLINK-25761][docs-zh] Translate Avro format page into Chinese (#18641),2
"[FLINK-26320][docs] Update the default value from ""1m"" to ""1min"" in Hive pageThis closes #18768",1
[FLINK-25927][docs][formats] Add DataStream documentation for CSV format,2
[typos] Typos in PULL_REQUEST_TEMPLATE.mdcluser => cluster,1
[FLINK-21565][table-planner] Support more integer types in TIMESTAMPADDThis closes #17793,1
[FLINK-26354] -restoreMode should be --restoreMode and should have a shorthand,2
[FLINK-25819][runtime] Reordered requesting and recycling buffers in order to avoid race condition in testIsAvailableOrNotAfterRequestAndRecycleMultiSegments,3
[FLINK-25819][runtime] Added new test for 'Insufficient number of network buffers' scenario into NetworkBufferPoolTest,3
[hotfix][runtime] CodeStyle correction for NetworkBufferPoolTest,3
[FLINK-26287][table] Add convenience method TableConfig.set,5
[FLINK-26287][table] Update some test classes for the new TableConfig.setThis closes #18895.,5
[FLINK-25249][connector/kafka] Reimplement KafkaTestEnvironment with KafkaContainer,3
[FLINK-26143][connector/kafka] Temporarily disable FlinkKafkaProducerITCase.testFlinkKafkaProducerFailBeforeNotify because it hangs in IDE and CI,1
[FLINK-25249][connector/kafka] Use 1 broker in Kafka tests to reduce complexity of environment,3
[hotfix][sqlclient][docs] Improved sql client docs (#18855),2
[hotfix]fix method name typos (#18904),2
[FLINK-26314][connectors/filesystem] Disable unaligned checkpoints for StreamingExecutionFileSinkITCase.This closes #18916.,2
"[FLINK-26285] Fixes an inconsistency which was introduced by c3a6b51 as part of changes done for FLINK-19543This issue never appeared because of the following reasons:- getAllAndLock is only called by the CompletedCheckpoint  recovery which happens during the recovery of a job (i.e.  after failover)- the removal happens through releaseAndTryRemove which can  be called in the following places:  - through DefaultCompletedCheckpointStore.addCheckpointAndSubsumeOldestOne    That happens after a job is already recovered and running  - through DefaultCompletedCheckpointStore.shutdown    ...where it's only called if the job reached a    globally-terminal state (i.e. it's not subject to    job recovery)  - through DefaultJobGraphStore.globalCleanupAsync    ...which is also only called on jobs that reached a    globally-terminal state (i.e. it's not subject to    job recovery)  - ZooKeeperStateHandleStore.releaseAndTryRemoveAll    ...which seems to be legacy code which is not used    anywhere in production, anymore. I'm leaving it here    because it might make sense to remove ZooKeeper    completely, anyway.",4
[FLINK-26357][avro-parquet] add FLINK API annotations,2
[FLINK-26357][avro-parquet] make AvroParquetRecordFormat package private and update javadoc.,2
[hotfix] [docs] Typo in filesystem.md (#18788)with AvroParquetWriters from ParquetAvroWriters rename,5
[hotfix] Removes invalid JavaDoc,2
"[FLINK-26284] Refactors lock node structure to support atomic deletion in ZooKeeperStateHandleStoreInvestigations as part of this change:- No changes necessary to getAllHandles. The releaseAll and remove*All  methods run idempotent operations on the child nodes. Other  than that, it's only used in DefaultJobGraphStore.getJobIds  which is used for recovering jobs. The job recovery calls  getAndLock which would fail for a marked-as-deleted JobGraph.  That specific error is ignored during the recovery. The JavaDoc  is updated accordingly.- About ZooKeeperStateHandleStore.exists:  Nodes being marked as deleted are not considered as existing  anymore.  Only appearance in the code is in DefaultJobGraphStore.putJobGraph  where it leads to a addAndLock call. We have to handle  this properly in the addAndLock call for state handles  that are marked for deletion.- About ZooKeeperStateHandleStore.addAndLock:  It will call to releaseAndTryRemove the state if the state is marked  for deletion.- About ZooKeeperStateHandleStore.replace:  The replace is only called with a lock being assigned for the  connection. This already prevents concurrent deletions.  In this commit, a Precondition check is added for a lock being  acquired before executing the actual replace logic.  Making sure that the caller has a lock on the  StateHandle prevents us from updating the state while  this state is being deleted. This is added to harden the replace  implementation",1
[FLINK-26053][sql-parser] Fix LOOKAHEAD warning for EXPLAINThis makes STATEMENT a reserved keyword.This closes #18764.,1
[hotfix] Log architecture on startup,2
"[FLINK-25026] UnalignedCheckpointRescaleITCase.shouldRescaleUnalignedCheckpoint fails on AZPTests that extend from UnalignedCheckpointTestBase create a lot ofMiniClusters. E.g. the rescale it case creates 72 tests * 2 clusters(pre & post rescale). Direct buffers allocated by netty are freed duringthe GC.At the same time Flink uses PooledBufferAllocator, where we return usedbuffers earlier and we do not need to wait for GC to kick in. The ideato make the test more stable is to reuse a single NettyBufferPool forall clusters that are started in those tests. That way we can reusebuffers that were previously allocated and we do not need to wait untilthey are freed.Lastly as a note. This should not be an issue in production setups, aswe do not start multiple shuffle environments in a single JVM process(TM).",1
"[FLINK-26331] Makes configuration for repeatable cleanups follow the configuration pattern for task restartsThe issue is that repeatable cleanups leveragethe RetryStrategy. In contrast, task restartsuse RestartBackoffTimeStrategy. We might want toalign these two approaches and provide a genericinterface to allow retries. FLINK-26359 wascreated to cover this.",1
[FLINK-26374][table-planner] Support nullability in nested JSON_OBJECT valuesThis closes #18929.,5
[FLINK-25789][docs-zh] Translate the formats/hadoop page into Chinese.This closes #18480.,2
[FLINK-26289][runtime] AdaptiveScheduler: Allow exception history to be queried by the REST API.,1
[hotfix][javadoc] Fix typo of getTriggeredSavepointStatus,1
[hotfix][docs][table] Document the new `TablePipeline` API objectThis closes #18804.,1
[hotfix] [runtime] Remove unused method ResourceManager#getNumberRequiredTaskManagers()This closes #18662.,1
[FLINK-25792][connectors] Only flushing the async sink base if it is possible to do it in a non blocking fashion or if the buffer is full. Added test to verify blocking behaviour when number of max in flight requests has been reached. Bubble up interrupted exception if raised while waiting to clear an in flight request in the async sink.,3
"[FLINK-25792][connectors] Changed repeated yielding in write to non blocking flush after complete request, changed tests so that the mailbox thread is cleared before each write().",3
[FLINK-26132][table-planner] Fix serialization of anonymous tablesThis closes #18770.,0
[FLINK-26373][connector/kinesis] Rename KinesisDataStreams module and classes into KinesisStreams,5
[FLINK-26296][docs] Add missing documentation for JobResultStore and repeatable resource cleanup strategy,4
[hotfix][docs][table] Fix docs for SHA1,2
[hotfix] Fix deprecated method call in the docs (#18939),2
[FLINK-25243][k8s] Increase the k8s transactional operation max retries in the integration tests to make the tests more stableThis closes #18891.,3
[FLINK-26347][rpc] Using system classloader in deserialization of RemoteRpcInvocationThis closes #18935.,5
[FLINK-26434][table] Remove 'table.planner' config option and remaining Blink referencesThis closes #18886.,2
[hotfix][Pattern Recognition][docs] Fixed an issue that the example of Time constraint omits a comma.This closes #18335,0
[hotfix] improvements to savepoint docs (#18909)* [hotfix] [docs] remove unneccessary mentions to old Flink version in Savepoints docs* [hotfix] misc improvements and simplifications to savepoint docs,2
[FLINK-26280][table-planner] Add 'table.exec.legacy-transformation-uids' to support old transformation uid generation behaviourThis closes #18879.,1
[FLINK-26387][connectors/kafka] Disable testBrokerFailure in ITCase tests,3
[FLINK-26398][docs] Adding docs for Kinesis Firehose table api,2
[FLINK-26286][kubernetes] Introduce idempotent KubernetesStateHandleStore.,0
[FLINK-26131][table] Let CompiledPlan implement Executable and simplify TableEnvironmentThis closes #18885,2
[FLINK-26191][connectors/elasticsearch] Revert Elasticsearch dependencies to 7.10.2 to keep Apache 2 license,4
[FLINK-22255][documentation] add note to documentation,2
[FLINK-25659][table-planner] Enable flaky LogicalRelDataTypeConverterTest with debug information,5
[FLINK-26429][runtime-web] Bump karma from 6.3.11 to 6.3.14Signed-off-by: martijnvisser <martijn@2symbols.com>,2
[FLINK-26430][runtime-web] Bump follow-redirects from 1.14.7 to 1.14.8Signed-off-by: martijnvisser <martijn@2symbols.com>,2
[FLINK-26223] Updates log4j configurationThis change moves ZK-related log output into adedicated file and enables INFO logging for ZKagain to determine instabilities.,2
[FLINK-26353] flink stop --help does not list --type option,2
[FLINK-26353] Add short option for savepoint format type,1
[FLINK-26338] Cross reference savepoint format from cli.mdThis closes #18900,2
"Revert ""[FLINK-25659][table-planner] Enable flaky LogicalRelDataTypeConverterTest with debug information""This reverts commit e3a30d6577d80ba38131f6b80647e3b91e7acca6.",4
"Revert ""[FLINK-26314][connectors/filesystem] Disable unaligned checkpoints for StreamingExecutionFileSinkITCase.""This reverts commit 69276df0",4
"[FLINK-26403][datastream] Fixes the endOfInput logic of sink writer and committer.SinkWriterOperator should emit all the pending committables on endOfInput,and CommitterOperator should commit all committables when the final checkpointis completed or on endOfInput if there's no final checkpoint.This closes #18938.",1
[hotfix][runtime] Remove unused ResourceManagerServicesThis closes #18959.,1
[FLINK-25833][core] FlinkUserCodeClassLoader is registered as parallel capable,2
[FLINK-25958][refactor][runtime] Separated the logic of creating and reporting the statistic in order to use it in different place in the future,1
[FLINK-25958][runtime] Mark CompletedCheckpoint as discarded before it will be really discarded in order to avoid synchronization for changing discarded flag,4
[FLINK-25958][runtime] Report completed statistic only after the completed checkpoint will be added to checkpoint store,1
[FLINK-25958][runtime] Report failed statistic if adding of completed checkpoint to checkpoint store fails,0
[FLINK-24474] set default for taskmanager.host,1
[FLINK-26352][runtime-web] Add missing license headers to WebUI source files,2
[FLINK-26407][end-to-end-tests] Increase timeouts for MetricsAvailabilityITCase.,1
[FLINK-26049][checkpoint] initialize CheckpointLocation after create PendingCheckpoint,1
[FLINK-26049][checkpoint] Moving checkpoint failure log and report failed checkpoint to CheckpointFailureManager,0
[FLINK-26049][checkpoint] Adding CheckpointStatsTracker logic without pending checkpoint,2
[FLINK-26387][connector/kafka] Use multi-broker kafka cluster in broker failure testsThis closes #18965.,3
[hotfix][connector/kafka] Cleanup unused helper method in KafkaTestEnvironmentImpl,3
[FLINK-25631][table] Support enhanced `show tables` syntax (#18361),1
[hotfix][docs] Update documentation for SQL Create page (#16737),1
[FLINK-25799][docs] Translate table/filesystem.md page into Chinese (#18655),5
[FLINK-26464][metrics] Make the meaning of lastCheckpointSize stay as before,1
[FLINK-20633][python] Add retry times to download avroThis closes #18954.,1
"[FLINK-26453][clients] Prevent program configurations also when executeAsync is calledWith FLINK-25206 it is possible to disallow configuration changes insidethe user program. Before this commit the validation only happened whena job was executed synchronously and asynchronous submissions stillsucceeded. Now, the asynchronous submission also fails.",0
[FLINK-25969][table-runtime] Clean up caches in CompileUtils more aggressivelyThis closes #18971.,4
"[FLINK-26126][metrics] Introduce new counter metrics for sending records by SinkWriter.We found that the new sink v2 interface will have a wrong numRecordsOut metric for the sink writers. We send a fixed number of records to the source, but the numRecordsOut of the sink continues to increase by the time.The problem is that both the SinkWriterOperator and the KafkaWriter are using the same counter metric for counting the outgoing records. Same records sent by the SinkWriterOperator to the post topology and written by the KafkaWriter to the downstream system will be count twice in the same counter metric.",5
[FLINK-26126][kafka] use record/byte send counter metrics from SinkWriterMetricGroup directly. Bug fixed. Enable the metric test in KafkaSinkITCase and KafkaSinkE2ECase again.,3
[FLINK-26126][kafka] develop record out error counter metric,0
[FLINK-26126][test] migrate KafkaWriterITCase to AssertJ,3
[FLINK-26229][datadog] Migrate tests to JUnit5,3
[FLINK-26230][metrics] Migrate tests to JUnit5,3
[FLINK-25659][table-planner] Fix flaky LogicalRelDataTypeConverterTestThis closes #18372.,5
[FLINK-26455][state/changelog] Don't fail on materialization cancellation,0
"[FLINK-23843][runtime] Properly fail the job when SplitEnumeratorContext.runInCoordinatorThread() throws an exception.Now that coordinatorExecutor is a ScheduledExecutorService, UncaughtExceptionHandler is useful only for exception raised by the threadPool as the JVM now uses a ScheduledFutureTask that catches exceptions in its run method. Manually catch the exceptions and call the exception handler.",0
[FLINK-26504][python] Fix the incorrect type error in unbounded Python UDAFThis closes #18990.,0
[FLINK-26463][table-planner] Use MiniCluster for TableEnvironmentITCase and moved some tests to TableEnvironmentTestThis closes #18968.,3
[FLINK-26302][build] Upgrade rat-plugin to 1.13,2
[FLINK-26303][build] Print rat-plugin violations to the console,2
[hotfix][state/changelog] Schedule timeouts on a separate thread,4
[FLINK-26396][state/changelog] Fail upload if last attempt times out,0
[FLINK-15550][runtime] Debug logging for TaskTest,3
[hotfix][docs] Fix HTML formatting in ops/metrics.mdFix 'Note' paragraph and adapt to style to other 'Note' paragraphs of the rest of the document.,2
[FLINK-25143][test] Add ITCase for periodic materialization,1
[FLINK-18356][tests] Enable fork-reuse for table-plannerSigned-off-by: martijnvisser <martijn@2symbols.com>,1
[FLINK-26099][docs][table] Fix typo in proctime attribute exampleThis closes #18740.,2
[FLINK-26440][connector/filesystem] Make CompactorOperatorStateHandler supporting unaligned checkpoint.This closes #18955.,1
[hotfix][streaming] Enabling GlobalCommitter SinkITCases,0
[FLINK-26516][streaming] Recover GlobalCommittables with Sink V1 GlobalCommittable serializerWith SinkV2 the committer and global committer work very similar andthey only write committables into state. SinkV1's GlobalCommitter on theother hand used to write GlobalCommittables into state so this commitsadds an migration path.This closes #18805.,1
[FLINK-26531][kafka] KafkaWriterITCase.testMetadataPublisher failed on azureThis closes #19005.,0
[FLINK-25971][table-planner] Hide JsonSerdeUtil#getObjectMapperThis closes #18878.,5
[FLINK-26543][python] Fix the issue that exceptions generated during startup are lost in Python loopback modeThis closes #19013.,0
[FLINK-25129][docs] Improvements to the table-planner-loader related docs (#18812)[FLINK-25129][docs] Improvements to the project configuration docs. This closes #18812,2
[FLINK-25771][cassandra][tests] Raise client timeouts,3
[FLINK-26232][avro] Migrate tests to JUnit5,3
"Revert ""[FLINK-26232][avro] Migrate tests to JUnit5""This reverts commit a3dff681d511a56f5d2a557e1804bbd5a10757ea.",4
[refactor][state/changelog] Extract StateChangeUploadScheduler interface from StateChangeUploaderMotivation: the two interfaces should have different semanticsregarding returning upload result vs completing upload tasks with it calling upload().That would allow to discard unnecessarily uploaded state in subsequent commit.,1
[refactor][state/changelog] Complete upload tasks in StateChangeUploadScheduler... instead of StateChangeUploader.That would allow to discard unnecessarily uploaded state in subsequent commit.,1
[FLINK-26485][state/changelog] Discard unnecessarily uploaded state,4
[hotfix][state/changelog] Fix UploadTask.getSize,1
[FLINK-26232][avro] Migrate tests to JUnit5,3
[hotfix][runtime] Fix typos.,2
[FLINK-26517][runtime] Normalize the decided parallelism to power of 2 when using adaptive batch scheduler.This closes #19003.,1
"[FLINK-26492][metric] deprecate numRecordsOutErrorsCounter, replace it with umRecordsSendErrorsCounter",0
"[FLINK-26492][kafka] deprecate numRecordsOutErrorsCounter, replace it with umRecordsSendErrorsCounter",0
"[FLINK-26492][firehose] deprecate numRecordsOutErrorsCounter, replace it with umRecordsSendErrorsCounter",0
"[FLINK-26492][kinesis] deprecate numRecordsOutErrorsCounter, replace it with umRecordsSendErrorsCounter",0
[FLINK-26557][docs] Extend CsvFormat documentation based on release-testing feedbackThis closes #19030.,5
[FLINK-26555][runtime] Adds closing and flushing to OutputStream,1
[FLINK-26484][fs] Introduces Presto-specific FileSystem implementation that handles the recursive deletionThis requires a minor refactoring of AbstractS3FileSystemFactoryto make it easier to inject the new class. Tests for exists callsand delete calls were added.,1
[FLINK-26450] Makes FileStateHandle.discardState fail if the file couldn't be deleted,4
[FLINK-26550][checkpoint] Correct the information of checkpoint failure,0
[hotfix][runtime] Adds missing @ExtendWith to DefaultResourceCleanerTest,3
[hotfix][runtime] Adds check for consistency to avoid NullPointerExceptionLocalFileSystem.listStatus returns null in case of the path being invalid.,5
[FLINK-26494][runtime] Adds log message to cleanup failure,0
[hotfix][table-planner] Raw to Binary can fail if the user type ser/de fails,0
[FLINK-26125][docs][table] Add new documentation for the CAST changes in 1.15. This closes #18813,4
[FLINK-26306][state/changelog] Randomly offset materialization,1
"Revert ""[hotfix][table-planner] Raw to Binary can fail if the user type ser/de fails""This reverts commit cbfca3afae5d33f9137ae97eb4f4c27ea0d82919.The method is not used anywhere but causes compilation errors.",0
[FLINK-26564][connectors/filesystem] Fix the bug that CompactCoordinatorStateHandler doesn't properly handle the cleanup-in-progress requests.This closes #19032.,4
[FLINK-26349][AvroParquet][test] add test for reading reflect records from parquet file created with generic record schema.,1
[FLINK-26349][test] migrate AvroParquetRecordFormatTest to AssertJ,3
"[hotfix][docs] Chinese translation of ""Running in an IDE"". This closes #19044",1
[FLINK-26547][coordination] No requirement adjustments for unmatched slots,1
[hotfix][table-planner] RawToBinaryCastRule can fail. This closes #19055,0
[FLINK-26589][connectors/kinesis][connectors/firehose] Updating KDS/KDF logging level from warn to debug on failure and from trace to NONE on write.,0
[FLINK-26388][docs] Adds information about missed out artifacts in repeatable cleanup with a reference to the FLINK issue,0
[FLINK-24538][runtime][tests] Fix race condition when offering information to leader event queue in TestingRetrievalBase,3
[hotfix][runtime] Adds missing serialVersionUID to DuplicateJobSubmissionException,1
[FLINK-26583][runtime] Adds log message for when a Job is submitted that is already marked as cleaned,4
[FLINK-26580][connectors/filesystem] Fix the bug that FileSink CompactCoordinator adds in-progress committable as toCompacted,1
[FLINK-26580][connectors/filesystem] CompactorOperatorStateHandler can accept multiple remaining in-progress files from different buckets.,2
[hotfix][connectors/filesystem] Rename the operatorName in topology of the state handler operators.,1
[hotfix][connectors/filesystem] Make the compactor tests to extend TestLogger.This closes #19052.,3
"[FLINK-26610][datastream] Check whether sink uid is set when expanding sink topology.Currently sink developers may set uid for operators inside thecustomized topology. In this case if the sink uid is not set, therewill be duplicate operator uids if the sink is added multiple timesin a job.",1
[FLINK-26610][connectors/filesystem] Do not add state handlers for file compaction if compaction is not explicitly disabled.This closes #19061.,2
[FLINK-26534][table-planner] shuffle by sink's primary key should cover the case that input changelog stream has a different parallelism (#19006),4
[FLINK-26532][metrics][test] using the numRecordsSend counter to get the correct metric,1
[FLINK-25235][runtime] Re-enable ZooKeeper test with multi-component leader election (see FLINK-24038)The TestingMiniCluster had to be adapted a bit to make this work.The new multi-component leader election assumes that there's asingle leader election instance available per JobManager that isclosed as soon as the JobManager is shut down. The TestingMiniClusterused a single leader election that's shared between multipleJobManagers and closed after all these JMs are shutdown.The new implementation creates an individualHighAvailabilityServices instance per JM and closes this instance assoon as the JM shuts down to revoke the leadership and enable otherJMs to pick the leadership up again.,0
[FLINK-26295][table-planner] Parse strategies should allow spaces between operation and semicolonThis closes #18874.,1
[FLINK-26501][e2e-tests] Added new exception to white list since the failed checkpoint exception is always logging on the task manager site now,2
"[FLINK-26596][runtime][test] Adds leadership loss handlingIf the ZK connection is flaky, we might collect anotherZK connection loss. This is now handled properly.",0
[hotfix][runtime][test] Removes obsolete CompletableFuture usageThe test never utilizes the CompletableFuturebecause it always sets an already completedCompletableFuture.,1
[FLINK-24274][Documentation] Wrong parameter order in documentation of State Processor API,2
"[FLINK-25927][connectors][build] Consistent flink-connector-base usageflink-connector-base was previously inconsistently used in connectors (directly shaded in some and transitively pulled in via flink-connector-files which was itself shaded in the table uber jar). FLINK-24687 moved flink-connector-files out from the flink-table uber jar. This commit implements a combined approach for ensuring a smooth transition for both Flink users and for external connector developers, as outlined in this:- all internal Flink connectors that depend on flink-connector-base now shade and relocate it- for compatibility, until external developers implement the same change, flink-connector-base is also included into flink-dist",2
Update version to 1.16-SNAPSHOT,5
[FLINK-25800][docs] Update incorrect links in the datastream/execution_mode.md pages. This closes #18491,5
[FLINK-26444][python] Align the WindowAssigners with the Java DataStream APIThis closes #18957.,5
[FLINK-26506][python] Support StreamExecutionEnvironment.registerCachedFile in Python DataStream APIThis closes #19011.,5
[FLINK-26444][python] Move all window tests into test_window.pyThis closes #18957.,3
[FLINK-26500][runtime][test] Increases the deadline to wait for parallelismThe deadline of 10s wasn't sufficient enough for AzureCI runs.,1
[FLINK-26421][table] Remove planner & executor string identifiersRemove planner&executor string identifiers from `EnvironmentSettings`and use the default strings which are only used anyway.,1
"[hotfix][table-api] Remove deprecated create methodsThose 2 methods accept also a TableConfig, which is not necessary,since with the new approach, extra configuration will be passed through`EnvironmentSettings` instead. If those methods are still around willcreate confusion.",5
"[FLINK-26421] Use only EnvironmentSettings to configure the environmentUse `EnvironmentSettings` with the new method `withConfiguration` in its`Builder` to specify configuration options on top of the one inheritedby the environment (flink-conf.yml, CLI params).The `TableConfig` contains all of the config options specified by the env(flink-conf.yml, CLI params) + all the extra configuration defined by theuser app through the `EnvironmentSettings`.",1
[FLINK-26421][table-api-java] Improve JavaDocs of TableConfigThis closes #18980.,5
[FLINK-25528][state-processor-api] state processor api do not support increment checkpoint,1
[FLINK-25528][state-processor-api] state processor api do not support increment checkpointmake checkpoint type configurable.,5
[FLINK-25528][state-processor-api] state processor api do not support increment checkpoint1. limit the checkpoint type in the savepoint type and full checkpoint type.2. add the SnapshotUtils test with the full checkpoint.,3
[FLINK-25528][state-processor-api] state processor api do not support increment checkpointonly support savepoint but support switching savepoint format.,1
[FLINK-25528][state-processor-api] state processor api do not support increment checkpointupdate the unit test code.,3
[FLINK-25528][state-processor-api] state processor api do not support increment checkpointreuse the unit test code.,3
[FLINK-25528][state-processor-api] state processor api do not support increment checkpointsplit the test case.,3
"Revert ""[FLINK-25528][state-processor-api] state processor api do not support increment checkpoint""",1
[FLINK-25528][state-processor-api] Support native savepointthis closes #18840,1
"[FLINK-25771][cassandra][tests] Remove keyspace dropSince each test uses a separate table we no longer need to re-create the keyspace for each run, reducing the load on the cluster.",1
[FLINK-26177][Connector/pulsar] Use mocked pulsar runtime instead of embedded runtime and enable tests.,3
[FLINK-26551][table-planner] Change legacy casting config option to DISABLED by defaultThis closes #19020.,5
[FLINK-26650][checkpoint] Avoid to print stack trace for checkpoint trigger failure if not all tasks are started,0
[FLINK-26582][table][tests] Convert table modules assertions to AssertJ,3
"[FLINK-26063][runtime] Set current key before polling next PQ elementSome InternalPriorityQueue implementations need a correct key/groupset before performing poll() or remove().In particular, ChangelogKeyGroupedPriorityQueue logs key group so thatstate changes can be re-distributed or shuffled.This change re-orders queue.poll and keyContext.setCurrentKey.",1
[hotfix][connector/common] Fix typo of variable in SourceOperator,1
[FLINK-26018][connector/common] Create per-split output on split addition in SourceOperatorThis change could avoid watermark being pushed forward by records from the first split in the first fetch when multiple splits are assigned to the source operator.,1
[hotfix][release] Add 1.16 to the flink versions enumThis closes #19097.,2
[FLINK-25648][k8s] Avoid redundant query on k8s deployment when creating task manager podsThis closes #18854.,1
[hotfix][yarn] Factor out the generation of application master environments into a separate method,0
[FLINK-26030][yarn] Set FLINK_LIB_DIR to 'lib' under working dir in YARN containersThis closes #18739.,1
[FLINK-26520][table] Implement SEARCH operator in codegenImplements the SEARCH operator in the codegen and removesthe scalar implementation of IN and NOT_IN. Now every scalarIN/NOT_IN using a constant set is implemented through SEARCH(following Calcite's development on the topic CALCITE-4173)and plans will only have SEARCH.This closes #19001.,1
[FLINK-26166][runtime-web] Add auto newline detection to prettier formatter,1
[FLINK-26106][runtime] Used 'filesystem' for state change log storage in BoundedSourceITCase,2
"[FLINK-26418][runtime][test] Use java.io.tmpdir for tmpWorkingDirPreviously, the tmpWorkingDirectory was created in the current workingdirectory, and as a result there were directories created in the rootdirectories of the modules, i.e. `flink-table/flink-table-planner` whichwere not cleaned up with `mvn clean`.",4
[FLINK-26281][connectors/elasticsearch] setting default delivery guarantee to AT_LEAST_ONCE,1
"[FLINK-26613][streaming] Allow setting operator uid hashes for predefined sink operatorsSince the topology has changes between Flink 1.14 and 1.15 it mighthappen that stateful upgrades are not possible if no pior operator uidswere set. With this commit, users can set operator uid hashes for therespective operators.",1
[FLINK-26613][streaming] Use Flink 1.13 sink committer operator uid patternSince there is no dedicated committer operator in Flink 1.14 it is safeto use the uid pattern of 1.13 to ease upgrades from Flink 1.13 to 1.15.,2
[FLINK-26573][test] Do not resolve the metadata file which is in progress,2
[FLINK-26604][doc] add more information for Avro records support and clean up redundant content of bounded and unbounded data.- mvn dependency- using namespace in schema for reflect records[FLINK-26604][doc] bug fix,0
[FLINK-26658][docs] Migrate documentation build to Github Actions,2
[FLINK-26658][docs] Add missing quotes,1
[FLINK-26658][docs] Write docs to actual directory,2
[hotfix][ci] Return tools/ci/docs.sh,2
[FLINK-26652][runtime] Makes the cleanup not fail fatallyThe user explicitly marked the cleanup retry logic toterminate after a certain amount of attempts. This should beconsidered as desired behavior and shouldn't make the clusterfail fatally.,0
[hotfix][docs] Updates the default value from the fixed delay strategyWe want to try infinitely if nothing is specified.,5
[hotfix][docs] Uses @OverrideDefault instead of noDefaultValue for exponential-delay.attempts,1
[hotfix][runtime][test] Improves assert message,3
[hotfix][docs] Adds missing JRS configuration parameter in Chinese documentation,2
[hotfix][tests] Fixed wrong default value in test,3
[FLINK-26658][docs] Pin actions/checkout version,2
[FLINK-26658][docs] Allow running workflow on other branches,1
[FLINK-26658][docs] Setup cron builds,1
[FLINK-26607][python] Correct the MAX_LONG_VALUE/MIN_LONG_VALUE in several placesThis closes #19089.,2
[hotfix][doc] Re-generate rest docs,2
[FLINK-26641][rest] Introduce rest api to fetch job status,2
"[FLINK-26641][client] Request the job status directly from the rest apiBefore this commit, the client will fetch the current job status from JobDetails,which might be stale for a few seconds because of the cache mechanism. As the jobstatus is lightweight enough, we fetch it directly from a specific job status fetcherREST API which has no information delay. In this way, we shorten the time client waitsfor the Job to finish initializing.This closes #19095.",5
[hotfix][test] Remove unused waitUntilJobInitializationFinished of TestUtilsThis closes #19114.,3
[hotfix][ci] Try to fix the e2e ci pipeline upgrading the libssl version,0
[FLINK-26658][docs] Checkout correct branch in cron builds,2
[hotfix][javadocs] Fix name of the element in the createFieldGetter method of RowData. This closes #18261,5
[FLINK-26482][python] Support WindowedStream.reduce in Python DataStream APIThis closes #19054.,5
[FLINK-26680][coordination] Properly handle deleted jobs during recovery,4
[hotfix][python][docs] Improve the documentation about how to specify jar files on Windows,2
[FLINK-26693][Documentation] Modify the grammar mistake in savepoints.md. This closes #19125,2
[FLINK-26687][Connectors][NiFi] Remove Apache NiFi connector,4
[FLINK-26536][python] Fix RemoteKeyedStateBackend#merge_namespaces to handle properly for the timerserviceThis closes #19008.,0
[hotfix][tests] Update junit4 to junit5 in endpoint related test case,3
[FLINK-25085][runtime] Support schedule task in MainThreadExecutor local thread poolThis closes #18303.,1
[FLINK-26619][python][docs] Add document for the window assigners in Python DataStream APIThis closes #19122.,5
"[FLINK-26698][runtime] Uses the actual basePath instance instead of only the path of Path instanceThe issue before the fix was, that using getPath would stripoff the scheme information which causes problems in situationswhere the FileSystem is not the default FileSystem",5
[hotfix][runtime] Makes use of static variable,1
[hotfix][table-api-scala-bridge] Fix imports of StreamTableEnvironmentImpl,2
[hotfix][table] Replace TableConfig constructor with getDefault(),1
"[FLINK-26688][table-planner] Remove usages of TableConfig.nullCheckRemove usages of `TableConfig`s `nullCheck` which is used in codegeneration, since it was not actually used so far the option itselfhas been deprecated and planned to be removed in next releases.With this change, we can replace the necessicity top pass around`TableConfig` instead of `ReadableConfig` in various places.",5
[FLINK-26689][table] Replace `TableConfig` with `ReadableConfig`Replace concrete `TableConfig` with `ReadableConfig` wherever possibleto have a transparent reading of configuration options wihtout the needof calling specific methods on the `TableConfig` object.Add `getLocalTimeZone()` to `TableConfigUtils` to be able to retrievethe timezone from a `ReadableConfig` without the need of passing around`TableConfig` as method args.This closes #19045.,5
[FLINK-26420][File] use numRecordsSendCounter from SinkWriterMetricGroup directly.,1
[FLINK-26420][Connector-base] use numRecordsSendCounter from SinkWriterMetricGroup directly.,1
[FLINK-26420][test] migrate FileWriterTest to AssertJ.,3
[FLINK-26420][test] migrate AsyncSinkWriterTest to AssertJ.,3
[FLINK-26560][state] Make the threshold of the overlap fraction of incremental restoring configurableThis closes #19106.,5
[hotfix][docs] Fix doc for interval of years,2
[hotfix][docs] Clarify semantic of tolerable checkpoint failure number,0
[hotfix][doc] Re-generate docs,2
[FLINK-26578][docs-zh] Translate new Project Configuration section to Chinese. This closes #19100,5
[FLINK-26701][connectors] Revert FLINK-25927 apart from adding connector-base to flink-dist,2
[FLINK-26716][test][connectors/jdbc] Migrate PostgreSQL tests to Testcontainers,3
[FLINK-26381][docs] Wrong documentation order of Chinese version of Learn Flink. This closes #19010,2
[FLINK-25797][Docs] Translate datastream/formats/parquet.md page into Chinese. This closes #18646Co-authored-by: Jing Ge <gejing@gmail.com>Co-authored-by: wangzhiwubigdata <changye.wcy@cainiao.com>Co-authored-by: Zhiwu Wang <2827873682@qq.com>,5
[FLINK-26618][sql-client] Fix 'remove jar' statement is not aligned with pipeline jarsThis closes #19070.,4
[hotfix][docs] Fix the broken link for late events/lateness,2
"[FLINK-26690][runtime] Makes globalCleanupAsync call the removal even if the JobGraph is not put into the JobGraphStore, yetThis can happen if cleanup is triggered after afailover of a dirty JobResultStore entry (i.e. ofa globally-terminated job). In that case, norecovery of the JobGraph happens and, therefore, noJobGraph is added to the internal addedJobGraphscollection.This required KubernetesStateHandleStore.releaseAndTryRemoveto work for non-existing state as well. The ZooKeeperStateHandleStoreimplementation is already idempotent in this matter.ZooKeeperStateHandleStore.releaseAndTryRemove already works like that.",1
[hotfix][docs] Aligns JavaDoc with method signature,2
[FLINK-26723][runtime]fix the error message thrown by SourceCoordinatorContext,0
[FLINK-25226][doc] Add documentation about the AdaptiveBatchSchedulerThis closes #18757.,2
[FLINK-26717][fs][core] Move s3 common utils to flink-coreThis closes #19141,2
[FLINK-26151]Avoid inprogressfileRecoverable not be clean up after restoring the bucketThis closes #18776.,4
"[FLINK-21321]: change RocksDB rescale to use deleteRangePreviously, the Flink incremental checkpoint restore operation wouldscan and delete individual keys during recovery when rescaling. This isdone to truncate the ranges of the checkpoints which are no longer partof the assigned key-range for a worker.Now, this operation is replaced and uses RocksDB's deleteRangeoperation. This operation is preferred because it can cheaply removedata, via tombstones.The RocksDB API for DeleteRange is here,https://github.com/facebook/rocksdb/blob/bcd32560dd5898956b9d24553c2bb3c1b1d2319f/include/rocksdb/db.h#L357-L373Tombstones are described in further detail here,https://rocksdb.org/blog/2018/11/21/delete-range.htmlAdditionally, this adds a benchmark test based onRocksIncrementalCheckpointRescalingTest which triggers the modifiedre-scaling code.",3
[FLINK-21321][Runtime/StateBackends] Add ITCases for rescaling from checkpoint,1
[FLINK-5151][docs] Add descriptions about object mutations of state backendsThis closes #19143.,1
[FLINK-26422][docs-zh][table]update chinese doc with the new TablePipeline docs,2
[hotfix][docs]add the missing ending symbol ;,2
[hotfix][elasticsearch] Make TestEmitter#createIndexRequest private,3
[FLINK-26633][elasticsearch] Add recordSend metric to elasticsearch sink,1
[FLINK-26688][table] Completely remove unused options from TableConfigRemoves the previously deprecated (in 1.15) unused options `nullCheck`and `decimalContext` from TableConfig.This closes #19147.,5
"[FLINK-26733][table-api-java][python] Deprecate TableConfig ctorDeprecate `new TableConfig()` in favour of `TableConfig.getDefault()`since the latter was mostly used, but in some places also the normalctor. This way we will have consistency and all consumers will use thestatic method instead.",1
[FLINK-26421][python] Remove TableConfig from StreamTableEnvironment#createFollowing: 57742b85095147711070c566069244c40ed8e77c remove the`TableConfig` from `StreamTableEnviroment#create()` and allowconfiguration only via `EnviromentSettings.with_configuration()`.,5
[FLINK-26421][python] Add warnings to deprecated methods in EnvironmentSettings,1
[FLINK-26727][python] Fix the implementation of sub-interpreter in Thread ModeThis closes #19150.,0
[FLINK-26334][datastream] Modified getWindowStartWithOffset method in org.apache.flink.table.runtime.operators.window.TimeWindow and org.apache.flink.streaming.api.windowing.windows.TimeWindow . Added test cases in unit test TimeWindowTest.Co-authored-by: Lin WanNi <linwanniderz@foxmail.com>Co-authored-by: Guo YuanFang <1650213825@qq.com>,3
[FLINK-26642][connector/pulsar] Fix support for non-partitioned topic[FLINK-26642][connector/pulsar] Fix class reference problem[FLINK-26642][connector/pulsar] Fix variable reference[FLINK-26642][connector/pulsar] Remove shaded Lists,4
[hotfix][runtime] Remove unnecessary method.,4
"[FLINK-26279] Add mailbox metricsAdd metrics for mailbox latency, throughput and queue size to TaskIOMetricGroup.",1
"[FLINK-26592][state/changelog] Use mailbox in FsStateChangelogWriter instead of a lockWhen a task thread tries to schedule an upload, it might wait for available capacity.Capacity is released by the uploading thread on upload completion.  After releasing,it must notify the task thread about the completion.Both task and uploading thread acquire FsStateChangelogWriter.lock. That causesa deadlock if uploader releases capacity insufficient for task thread to proceed.This change removes the lock and makes uploader thread to use mailbox actions.",1
"Partially revert ""[hotfix][runtime] Remove unnecessary method.""This reverts commit a1473daaffbab7cf7abc974fadb634408eeb3db7.",5
[FLINK-26249][test-utils] Refactor BuiltIn(Aggregate)FunctionTestBase to JUnit 5 and run tests in parallelThis closes #18940.,3
"[FLINK-25904][metrics] Lazily initialize PercentilePercentile serialization doesn't work properly (see MATH-1642), so instead of serialize the data array and lazily initialize the Percentile as needed.",5
[FLINK-26704][table] Remove deprecated Table API string expressionsThis closes #19148.,4
[FLINK-26495][table-planner] Prohibit hints(dynamic table options) on viewThis closes #19007,2
[FLINK-11388][fs] Add abstract test classes for recoverable writers (s3/oss)This closes #19181,3
[FLINK-25549][state/changelog] Migrate flink-dstl to use JUnit5This closes #18978.,3
[FLINK-26775][python] WindowOperator#process_element registers wrong cleanup timerThis closes #19186.,4
[FLINK-26638][connectors/elasticsearch] Revert Table-API implementation to SinkFunction-based one,1
[FLINK-26638][connectors/elasticsearch] Update docs for Table-API implementation to SinkFunction-based one,1
[FLINK-26779][rest] OperationKey implements Serializable,2
"[hotfix][connector-hive] Avoid serializing TableConfigUse and pass around only `threadNum` which is the only option read,instead of the whole `TableConfig`, to prevent the relevant classesthat are serialized from trying to serialize also the `TableConfig`.",5
"[FLINK-26709][table] Replace TableConfig.getConfiguration.set()Since `TableConfig` is a `WritableConfig`, callers should directly call`TableConfig.set()` and avoid going throught `#getConfiguration()` whichis there only for advanced internal configuration read value purposes.",5
"[FLINK-26709][table] Replace TableConfig.getConfiguration.get/getOptional()Replace `TableConfig.getConfiguration().get(<option>)/getOptional(<option>)` with `TableConfig.get(<option>)/getOptional(<option>)` since `TableConfig`is now a `ReadableConfig` and the `get/getOptional` give a full view,including the `rootConfiguration`, which makes all the options comingfrom the environment (flink-conf.yaml, CLI params) available.",2
"[FLINK-26709][table] Replace TableConfig.getConfigurationReplace `TableConfig.getConfiguration()` with directly passing`TableConfig`, since `TableConfig` is now a `ReadableConfig` and the calls to `get/getOptional` give a full view, including the `rootConfiguration`, which makes all the options coming from theenvironment (flink-conf.yaml, CLI params) available.",2
"[FLINK-26777][table-planner] Remove `PlannerConfig` from `PlannerBase`Remove `PlannerConfig` delegation class, since `TableConfig` is now theone that holds the complete view of `rootConfiguration` (environmentconfig) + `configuration` (the application specific configuration).This closes #19187.",5
[hotfix][table-planner][tests] Use EnvironmentSettings to pass configurationUse the new way for passing application specific configuration throughthe `EnviromentSettings`.,1
[hotfix][table-planner] Remove ExecNodeConfig#getLocalTimeZoneRemove `ExecNodeConfig#getLocalTimeZone` by replacing its usages withthe newly introduced method in the utility class `TableConfigUtils`.,5
[hotfix][table-planner] Remove ExecNodeConfig#getMaxIdleStateRetentionTime()Replace `ExecNodeConfig#getMaxIdleStateRetentionTime()` with a method in`TableConfigUtils` to keep the class clean and remove another directusages of `TableConfig` in favour of `ReadableConfig`.,5
[hotfix][Streaming] fix wrong local variable name in MailboxProcessor and fix typo in java doc.,2
[hotfix][doc] fix typo in java doc.,2
[FLINK-26758][container] Migrate tests to JUnit 5,3
[FLINK-26747][gpu] Migrate tests to JUnit5,3
"[FLINK-26767][python] Update code to use the changes for TableConfigAdjust the python code to match the latest changes to the corresponding`TableConfig` and `EnvironmentSettings`, so that python also uses thenew API methods, and can benefit from the app config + env config viewthat `TableConfig` provides.This closes 19086.",1
[hotfix][python][docs] Update documentation on how to use with_configuration in EnvironmentSettings,1
[hotfix][table-planner] Deprecate SqlFunctions of old function stack,1
[FLINK-26518][table-planner] Port FlinkRelBuilder to Java,2
[FLINK-26518][table] Support BridgingSqlFunction with SqlTableFunction for Scala implicitsThis closes #19137.,1
[FLINK-26766][Runtime/StateBackends] Fix ChangelogStateHandleStreamImpl#getIntersection,4
[FLINK-26281][connectors/elasticsearch] Remove unused 'connection.max-retry-timeout' optionThis closes #19202.,1
[FLINK-26477][python] Support WindowedStream.aggregate API in PyFlinkThis closes #19176.,2
[FLINK-26770][table-planner] Fix ArrayToArrayCastRule result data structureThis closes #19188.,5
[hotfix][table-common] Improve JavaDocs of GenericArrayData,5
[FLINK-26609][python] Support sum operation in KeyedStreamThis closes #19126.,1
[FLINK-26819][table-runtime] Fix wrong results when AppendOnlyFirstNFunction with offset and without rank number (#19212),1
"[hotfix][docs] Fix typo in the ""SQL Deduplication"" page (#19213)",2
[FLINK-26805][table] Managed table breaks legacy connector without 'connector.type'This closes #19209,4
[FLINK-26695][runtime] Evaluation of deleteConfigMap's return value added,1
[hotfix][python][docs] Fix the example in intro_to_datastream_api,5
[FLINK-26741][runtime] Changes method signature of CheckpointIDCounter.shutdownThe new method returns a CompletableFuture that can be processed.This also includes adding idempotency tests for the ZK and k8simplementations.,3
[hotfix][runtime] Adds missing configuration parameter to cleanup error log message,2
[hotfix][table-planner] Remove unused imports,2
[FLINK-26843][table-planner] Use TableConfigUtils to get local timezone.Replace usages of `TableConfig#getLocalTimeZone()` with`TableConfigUtils.getLocalTimeZone(tableConfig)` to facilitatepassing `ReadableConfig` instead of concrete `TableConfig`.,5
[FLINK-26843][table-planner] Use ShortcutUtils.unwrap[TableConfig/Context]Cleanup code by using the utilitty methods of `ShortcutUtils`:`unwrapTableConfig` and `unwrapContext`.,5
"[FLINK-26843][table-planner] Replace `TableConfig` with `ReadableConfig`Replace `TableConfig` with `ReadableConfig` where possible, to cleanupthe usages, and make sure that `TableConfig` is only used where it'sabsolutely necessary, because of the extra functionality it provides.",1
[FLINK-26843][table-planner] Cleanup TableConfig & ReadableConfigCleanup usages and naming of variables regarding `TableConfig` and`ReadableConfig` to make clear what is used/passed as variables andmethod args.This closes #19205.,4
[hotfix][table-planner][tests] Cleanup by using PlannerMocksCleanup some test code by using `PlannerMocks` instead of creating`PlannerContext` manually.,1
[hotfix][table-planner][tests] Cleanup by using JsonSerdeTestUtilUse `JsonSerdeTestUtil#configuredSerdeContext()` to avoid creating`SerdeContext`s manually.,1
[FLINK-26700][docs] Document restore mode in chineseCo-authored-by: Yun Tang <myasuka@live.com>,2
[hotfix][docs] correct checkpoint directory in restore mode document,2
[FLINK-26789][tests] Fix broken RescaleCheckpointManuallyITCase,0
[hotfix][docs][metrics] Remove outdated statements,5
[FLINK-26846][python] Fix the gauge metricThis closes #19226.,0
[FLINK-26638][connectors/elasticsearch] update the Chinese document accordinglyThis closes #19211.,2
[FLINK-26855][python] Fix Sphinx check failure caused by Jinja2 dependency (#19238),1
[FLINK-26809][tests] Assert histogram state after stopping the uploaderThere is a race condition in ChangelogStorageMetricsTest.testAttemptsPerUpload:- the assertion is made as soon as upload (future) is completed- the histogram is updated after completing the upload (on success)Moving assertion out of try/close block solves the problem.,0
[FLINK-26736][tests] Migrate flink-avro-confluent-registry to JUnit5,3
[FLINK-26847][python] Ensure command line option '-py' works in YARN application modeThis closes #19227.,1
"[hotfix][core] Add method to get all ConfigOptions from an ""Options"" classThis is needed for generating a `ReadableConfig` with all consumedoptions by a give `ExecNode`s to be persisted in JSON plan.",5
[hotfix][table-planner] Remove consumed options not affecting the topology.Remove `table.exec.source.idle-timeout` and `table.exec.state.ttl`.,4
[FLINK-26075][table-planner] Persist node configuration to JSON plan- Add a new JSON field to the plan called configuration which  includes all the options used by the ExecNode along with their values.- Use the previously introduced ExecNodeConfig class to merge the  configuration deserialized from the JSON plan with the Planner  configuration.,5
[FLINK-26075][table-planner][test] Regenerate JSON plansThis closes #19232.,5
[FLINK-26615][tests] Fix timings in BatchingStateChangeUploadSchedulerTest.testUploadTimeout,3
[FLINK-26395][docs] Correct the wrong description of SQL function: RAND_INTEGER. This fixes #19104,0
[FLINK-26865][python] Fix the potential failure of loading library in Thread ModeThis closes #19244.,0
[FLINK-26708] TimestampsAndWatermarksOperator should not propagate WatermarkStatus,1
[FLINK-11388][oss] Add Aliyun OSS recoverable writerThis closes #19072,1
[FLINK-26799][state/changelog] fix seek condition in StateChangeFormat#read,4
[FLINK-26842][python][tests] Port Scala code to Java,3
[FLINK-26842][python] Remove scala-bridge dependency,4
[hotfix][task] Add task name to BufferDebloater logging,2
"[FLINK-26783] Do not trigger global failover if failed during commiting side-effects during stop-with-savepointIf a job fails during commitin side-effects of the stop-with-savepoint and we restart to the latest checkpoint instead of savepoint, we might end up producing duplicates. On the other hand if we restart to the savepoint we end up in a situation where a running Flink job depends on the existence of the savepoint.In this commit we do not trigger a global failover in case the savepoint completed successfully, but the job failed during committing side effects. In that case we will finish the completable future with an exception that explains that the savepoint is consistent, but it might have uncommitted side effects and we ask users to manually restart a job from that savepoint if they want to commit side effects.This closes #19198",1
[FLINK-26849][metrics] Deduplicate metric (un)registration logic,2
[FLINK-26850][metrics] Add Metric#getMetricType,1
[FLINK-26851][docs] Document prefix for SuffixOptionAllows to define a prefix for SuffixOptions that is also written into the generated html file.This allows us to use the same file for documentating the fully-qualified option (prefix + suffix) or just the suffix option.,0
[FLINK-26851][metrics] Migrate reporter options to proper ConfigOptions,5
[FLINK-26780][coordination] Add option to force RPC serialization,1
[FLINK-26780][tests] Force RPC serialization,1
[FLINK-26814][python][yarn] Ensure PyFlink jobs works in YARN application modeThis closes #19208.,1
[hotfix][release] Update the compatibility table for the release 1.14 and 1.15This closes #19144.,5
"[FLINK-24351][docs] Translate ""JSON Function"" pages into ChineseThis closes #17789.",1
[FLINK-26634][docs-zh] Update Chinese version of Elasticsearch connector docsThis closes #19101.,2
[FLINK-26028][Connector/pulsar] add sink documentation; change some pulsar source documentation.,2
[FLINK-26616][tests] Remove deadlines from CommonTestUtils,3
[FLINK-26251][akka] Migrate test to JUnit5,3
[hotfix][tests] Cleanup MessageSerializationTest,3
[FLINK-26134][docs] Added documentation page with Checkpoint/Savepoint guarantees,2
[FLINK-26629][runtime] fix bug in code comment of SubtaskStateMapper.RANGE,0
[hotfix][ci] Setup ML notifications for GHA,1
[hotfix][doc] Modify spelling error in elastic_scaling.md,0
[FLINK-26794][tests] Use API to access job checkpoints in IT casesUsing dedicated API has the following advantages over looking for checkpoints on FS:- less prone to NoSuchFileException- less brittle because file layout is not a declared API- less IO usage,2
[FLINK-26673][changelog] Disable periodic materialization when periodicMaterializeDelay is negative,4
[hotfix] Fix CsvRowDataDeserializationSchema constructor,5
"[FLINK-26281][connectors/elasticsearch] Remove deprecated 'type', explain exactly-once semantic. This closes #19200",4
[refactor][streaming] Migrate Source(Operator)StreamTaskTest to JUnit5 and assertj,3
[FLINK-25256][streaming] Externally induced sources replay barriers received over RPC instead of inventing them out of thin air.This change preserves the CheckpointOptions and properly integrates user-triggered snapshots and workflows with more than one source.The externally induced source now merely delays the barrier instead of being able to insert one at a whim which would never work in aforementioned setups.,1
[FLINK-25256][streaming] Clarify the contract of ExternallyInducedSource(Reader).,2
"[FLINK-26092][table-runtime] Fix `JSON_OBJECTAGG` when emitting `NULL`Previously, when the Json aggregation is taking place, and idJsonOnNull.NULL is selected, which means that we still want to emita `null` JSON node, .i.e `{.... ""myField"" : null ... }` when no valuesget accumulated, we used a null `StringData` object. When`state.backend.changelog.enabled` is enabled, the contents of the mapaccumulating the aggregated records, gets serialized leading to NPE,since `null` is not supported by `StringDataSerilizer`.To solve this, we instead create a StringData with an empty `byte[]`,which denotes the null, and when the aggregation ends and we createthe final JSON result, we check for a `byte[]` of `length` `0` inorder to write the JSON `null` node.",5
[hotfix][tests] Remove Deadlines from CommonTestUtils added in new methods,1
[FLINK-26882][tests] Fix unstable RescaleCheckpointManuallyITCase,0
"[FLINK-25227][table-planner] Fix LEAST/GREATEST to return primitivesPreviously, `LEAST` and `GREATEST` functions would return primitivetypes in the generated code implementing their logic, producing issuesfor operators applied on top of them, and most importantly comparisonoperators, i.e.:```f0 INT, f1 INTSELECT GREATEST(f0, f1) = GREATEST(f0, f1)```would return `FALSE`, since the generated code would return `Integer`instead of `int`, as the result of `GREATEST`, and the `=` operatoron `Integer` objects would return false, even if the actual integervalue of them was the same.",1
[FLINK-26887][tests] Drop Jepsen tests,3
[FLINK-26885][metrics][tests] Migrate MetricRegistryImplTest to JUnit5,3
[FLINK-26885][metrics][tests] Cleanup MetricRegistryImplTest,3
[FLINK-26134][docs] Added documentation page with Checkpoint/Savepoint guarantees,2
[FLINK-25440][doc][pulsar] Stop and Start cursor now all uses publishTime instead of eventTime; doc changed to reflect this change,4
[FLINK-26923] Do not trigger global failover if failed during commiting side-effects during stop-with-savepoint for adaptive scheduler,0
[FLINK-25961] [connectors/elasticsearch] Remove transport client from Elasticsearch 6/7 connectors (tests only)Signed-off-by: Andriy Redko <andriy.redko@aiven.io>,3
[hotfix][runtime][tests] Modify spelling error in RestServerSSLAuthITCase.java,0
[FLINK-26575][checkpoint] Improve the info message when restoring keyed state backend,5
[FLINK-26928][connector/kafka] Remove unnecessary docker network creation in tests and close network on shutdown()This closes #19282.,1
[FLINK-26460][table-planner] Fix Unsupported type when convertTypeToSpec: MAPThis closes #18967,1
[FLINK-11388][docs][oss]Update docs for OSS Recoverable writerThis closes #19292,2
"[FLINK-26798][runtime] Hardens test against unexpected heartbeattestJobFailureWhenTaskExecutorHeartbeatTimeout failed due to a heartbeatbeing processed during the test. The missing payload of the testimplementation caused an unexpected error after the JobGraph was alreadyrunning (and therefore, expected some executions being present in theExecutionDeploymentReport of the TaskExecutorToJobManagerHeartbeatPayload.The heartbeatFromTaskManager call is not necessary in this test becausewe're simulating a timeout of the heartbeat, anyway. Removing this callfixes the issue.",0
[FLINK-23399][state] Add a benchmark for rescaling,1
[FLINK-26920][python] Handles the dependencies properly in create_temporary_viewThis closes #19318.,1
[hotfix][test-utils-junit] Improve exception assertions,3
[FLINK-26986][python] Remove deprecated string expressions in Python Table APIThis closes #19326.,4
[FLINK-26797][runtime] Makes the test less strictWe only care about monotonically increasing numbers.Unstable connections could cause a retry by the curatorclient. See FLINK-26120 where a the same error cause wasfixed in the same way.,0
"[hotfix][runtime] Adds debug logs for FinalRequestProcessor to CI runorg.apache.zookeeper.server.FinalRequestProcessor provides debug logs for actualoperations being performed on the server, which might be interesting to seewhen investigating test instabilities.The following logs are part of the debug logs:Processing request:: sessionid:0x1003757ccd40000 type:getData cxid:0x11 zxid:0xfffffffffffffffe txntype:unknown reqpath:/flink/default/checkpoint_id_counter...contains the type of request (e.g. 'getData') and path (e.g. '/flink/default/checkpoint_id_counter').",2
[FLINK-26931][Connector/pulsar] Make the producer name and consumer name unique for each instance.,1
"[FLINK-26961][connectors][filesystems][formats] Update Jackson Databind and Annotations to 2.13.2.2, Jackson Dataformat to 2.13.2, Jackson Core to 2.13.2 and Jackson-BOM to 2.13.2.20220328. This closes #19303",5
"[FLINK-26728][python] Support min, max, min_by, max_by operation in KeyedStreamThis closes #19242.",1
[FLINK-26738][state] Mark StateDescriptor#defaultValue as deprecated with clear docsThis closes #19229.,2
[FLINK-26739][hive] Support minor version 2.3.8 and 2.3.9 of HiveThis closes #19167.,1
[FLINK-26540][hive] Support handle join involving complex types in on conditionThis closes #19012,0
[FLINK-26969][python][examples] Add a few examples of window operation in Python DataStream APIThis closes #19328.,5
[FLINK-26994][ci] Merge Core/Libraries CI profiles,2
[FLINK-27024][build] Cleanup surefire configuration,5
[FLINK-26645][Connector/pulsar] Support subscribe only one topic partition.,1
[FLINK-21585][metrics] Add options for in-/excluding metrics,1
[FLINK-21585][tests] Use filter to reduce amount of logged metrics,2
[FLINK-26886][metrics][docs] Document pull/push tag/identifier reporter behavior,2
[FLINK-26998][state] Activate default log-level options in RocksDB state backendthis closes #19335.,5
[FLINK-14998][fs] Remove FileUtils#deletePathIfEmptythis closes #19330.,4
"[FLINK-26987][runtime] Fixes getAllAndLock livelockThis livelock can happen in situations where an entry was markedfor deletion but is not deleted, yet.",4
[FLINK-25907][runtime][security] Add pluggable delegation token manager,1
[FLINK-26712][table-planner] Metadata keys should not conflict with physical columnsThis reduces the likelihood for name collisions between metadata columns and physicalcolumns. It might break some connector implementations that used SupportsReadable/WritingMetadataand name-based column arithmetics. We don't recommend using name-based column arithmetics butindex-based ones.This closes #19236.,1
[FLINK-27034][gcp][tests] Use testcontainers,3
[FLINK-27026][build] Upgrade checkstyle pluginnewer version no longer require dependency resolution,1
[FLINK-27027][ci] Prevent creation of empty log files,2
[FLINK-27027][ci] Add default log file suffix,0
[hotfix][metrics][docs] Update documentation,2
[FLINK-26368] [kafka] Add setProperty method to KafkaSinkBuilder,5
[hotfix] Modify spelling error in IOUtils.java,0
[hotfix][runtime] Adds write method for consistency reasons,1
[hotfix] Fixes typo in NonClosingOutputStreamDecorator,2
[hotfix] Fixes error in JavaDoc,2
"[FLINK-26957][runtime] Removes flush in FileSystemJobResultStoreThe writeValue calls close by default internally. Calling flush afterwardscould cause errors. It's also not really necessary. OutputStream.flush doesnot guarantee persistence according to its JavaDoc. In contrast, callingclose does guarantee it.",2
[FLINK-26957][runtime] Adds invariant to LocalDataOutputStream to verify that no operation is allowed on a closed stream,1
[FLINK-27047][tests] Remove timeoutsThere's no guarantee that the cleanup is initiated synchronously.,5
[FLINK-27042][metrics] Fix instability of StreamTaskTest#testMailboxMetricsSchedulingRemove assertion for latency measurement from StreamTaskTest#testMailboxMetricsScheduling as itcauses instability and is already covered in StreamTaskTest#testMailboxMetricsMeasurement.,3
"[FLINK-27044][Connectors][Hive] Drop support for Hive versions 1.*, 2.1.* and 2.2.* which are no longer supported by the Hive community",1
[FLINK-27046][tests] Migrate avro/json schema registry to JUnit 5,3
[FLINK-25238][table-runtime] Fix ArrayDataSerializer#copy for customized types,5
[FLINK-27069][python] Fix the potential memory corruption in Thread ModeThis closes #19368.,0
[FLINK-27064][test] move ArchUnit rules for production code to the source folder and build a ProductCodeArchitectureBase which can be used by other test outside this module and even in the other repo via dependency.,3
[FLINK-27068][python][tests] Fix the unstable tests test_keyed_min_and_max and test_keyed_min_by_and_max_by (#19369),3
[FLINK-25897][docs] Update gradle quickstart quide to gradle 7.3.3,5
address comments,1
[FLINK-27088][Documentation] Fix the example of using StringDeserializer for deserializing Kafka message value as string,1
"[hotfix][test] rename to replace ""Product"" with ""Production"" for consistent naming convention",3
[FLINK-26835][serialization] Fix concurrent modification exception,0
[FLINK-27086][doc] Add a QA about how to handle exception when use hive parser in hive dialect document (#19373),2
[FLINK-25379][connectors] Support limit push down in DATAGEN connector,5
[FLINK-26810][connectors/elasticsearch] Use local timezone for TIMESTAMP_WITH_LOCAL_TIMEZONE fields in dynamic index,1
[FLINK-27108][python] Fix the state cache clean up logicThis closes #19386.,2
"[FLINK-25716][docs-zh] Translate ""Streaming Concepts"" page of ""Application Development > Table API & SQL"" to Chinese",2
[FLINK-24940][docs] Correct usage about how to create Hive catalog via Flink SQL CLI. This closes #17829,2
[FLINK-26993][tests] Wait until checkpoint was actually triggered,3
[FLINK-26190][python] Remove getTableConfig from ExecNodeConfigurationThis closes #19333.,5
[FLINK-26710][tests] Refactor TestLoggerResource to not swallow messages,1
[FLINK-27122] Remove FutureUtils#retryWithDelay variants without RetryStrategy,1
[FLINK-27125][tests] Fix ExecutorService leaks,0
[FLINK-27119][tests] Use try-with-resources for JobMasters,1
[FLINK-27105][docs] fix ChangelogStorage.uploadQueueSize metric type,4
[hotfix][build][python][tests] Remove Scala suffix,0
[FLINK-25926][Connectors][JDBC] Update org.postgresql:postgresql to 42.3.3. This required adding support for smallserial and applying changes after refactoring pgjdbc/pgjdbc#1194. PG's bytea[] now uses primitive arrays. This closes #18604Co-authored-by: Sergey Nuyanzin <snuyanzin@gmail.com>,1
[FLINK-26011][avro][test] add ArchUnit tests for the test code,3
[FLINK-26011][avro-confluent-registry][test] add ArchUnit tests for the test code,3
[FLINK-26011][avro-glue-schema-registry][test] add ArchUnit tests for the test code,3
[FLINK-26011][compress][test] add ArchUnit tests for the test code,3
[FLINK-26011][csv][test] add ArchUnit tests for the test code,3
[FLINK-26011][hadoop-bulk][test] add ArchUnit tests for the test code,3
[FLINK-26011][json][test] add ArchUnit tests for the test code,3
[FLINK-26011][json-glue-schema-registry][test] add ArchUnit tests for the test code,3
[FLINK-26011][orc][test] add ArchUnit tests for the test code,3
[FLINK-26011][orc-nohive][test] add ArchUnit tests for the test code,3
[FLINK-26011][parquet][test] add ArchUnit tests for the test code,3
[FLINK-26011][sequence-file][test] add ArchUnit tests for the test code,3
[FLINK-26394][checkpoint] Cancel the checkpoint completable future when checkpoint is aborting.,2
[hotfix][python] Remove nosiy warnings,2
[FLINK-27126][python] Respect the state cache size configuration for Python DataStream operatorsThis closes #19394.,1
[FLINK-27111][table][docs] Update docs regarding TableEnvironment configuration (#19387)* [FLINK-27111][table][docs] Update docs regarding TableEnvironment configurationFollowing the work on [FLINK-16835] update the docs accordingly tomention the use of `EnvironmentSettings` and that `TableEnvironement`related configuration can also be set in `flink-conf.yaml`.This closes #19387,5
"[FLINK-27089][table-planner] Fix bug with TRY_CAST in batch modeWhen in batch mode, the `getMonotonicity()` method of a function iscalled, to determine possible optimisations. For `TRY_CAST` theimplementation needs to call `getOperandType(1)` to get the target (alsothe function's return) type of the cast. This fails as for `CAST` and`TRY_CAST` at this point we have only one operand.`CAST` solves this in Calcite code, more specifically in`RexCallBinding#create()` where in case the `kind` of the function is`CAST`, a special `RexCastCallBinding` instance is created which storesthe return (target) type and returns it when `getOperandType(1)` iscalled.For `TRY_CAST` we don't have access to the stack to do somethingsimilar, and we cannot set the kind of `TRY_CAST` to `CAST` (currently,it's `OTHER_FUNCTION`, as this will allow the calcite stack to applyrules and optimisations to the `TRY_CAST` call and at some pointconvert it to a regular `CAST` call, thus breaking the functionalityof `TRY_CAST` (return null instead of failing).As a solution to the problem, we simply don't implement the`getMonotonicity()` method for `TRY_CAST`, lossing possibleoptmisations.This closes #19379.",1
[hotfix][tests] Close TaskExecutor/TMServices,3
[FLINK-27045][tests] Remove shared executor,4
[hotfix][tests] Fix compile error,0
"[FLINK-26519][table-planner] Remove FlinkTypeFactory singletonThe FlinkTypeFactory should not be a singleton as it caches typeinstances that could lead to classloading issues. Also, whenintroducing user-defined types a singleton could cause issues.This closes #19113.",0
[FLINK-26467][table] Compile RowDataToStringConverter lazilyThis closes #19087.,5
[FLINK-26852][state] Avoid RocksDBMapState#clear swallowing related exception,1
[hotfix][table-common] Use correct naming convention for TRY_CAST,1
[FLINK-27118][yarn] TM ignores localhost BIND_HOSTThis closes #19395.,2
[FLINK-27143][docs][tests] Migrate flink-docs to JUnit 5,3
"[FLINK-26995][tests] Fix tests failing with fork-reuse enabled- PipelinedApproximateSubpartitionTest re-uses PipelinedSubpartitionTest, but the latter shuts down the executor service- StreamGraphGeneratorTest relied on hard-coded transformation ids- TaskManagerRunnerTest nulled the security manager which could interfere with other tests",3
[FLINK-26995][tests] Migrate tests to ITCasesThese classes were only renamed:- FileUploadHandlerTest requires exclusive usage of DeleteOnExitHooks- StreamTaskTimerTest requires exclusive access to to StreamTask#TRIGGER_THREAD_GROUP- SinkTransformationTranslatorTest fails ita) relies on initially starting out with a clean state in the streaming graph generationb) relies on test cases permanently mutating the state in the streaming graph generationSome tests of the following classes were moved into a separate ITCase:- MemoryExecutionGraphInfoStoreTest relies on static SignallingBlockingNoOpInvokable- StreamTaskTest requires exclusive usage of the OutputFlusher,1
[FLINK-26995][build] Enable fork-reuse for all unit tests,3
[FLINK-26995][tests] Mark several tests as unit tests,3
[FLINK-27063][Connectors/Hive] Upgrade Hive 2.3 connector from 2.3.6 to 2.3.9,2
"[FLINK-26985][runtime] Don't discard shared state of restored checkpointsCurrently, in LEGACY restore mode, shared state ofincremental checkpoints can be discarded regardlessof whether they were created by this job or not.This invalidates the checkpoint from which the jobwas restored.The bug was introduced in FLINK-24611. Before that,reference count was maintained for each shared stateentry; ""initial"" checkpoints did not decrement thiscount, preventing their shared state from being discarded.This change makes SharedStateRegistry to:1. Remember the max checkpiont ID encountered during recovery2. Associate each shared state entry with a checkpoint ID that created it3. Only discard the entry if its createdByCheckpointID > highestRetainCheckpointID(1) is called from:- CheckpointCoordinator.restoreSavepoint - to cover initial restore from a checkpoint- SharedStateFactory, when building checkpoint store - to cover the failover case(see DefaultExecutionGraphFactory.createAndRestoreExecutionGraph)Adjusting only the CheckpointCoordinator path isn't sufficient:- job recovers from an existing checkpoints, adds it to the store- a new checkpoint is created - with the default restore settings- a failure happens, job recovers from a newer checkpoint- when a newer checkpoint is subsumed, its (inherited) shared statemight be deleted",4
[hotfix][python] Cleanup the code to pass cachedFiles into extractPythonConfiguration,5
[hotfix][python][tests] Cleanup the API completeness test,3
[FLINK-26864] Fix performance regression from mailbox latency measurement,0
[hotfix][table-planner] Make sure the iterator is always closed when reading results in BuiltInFunctionTestBaseSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
"[hotfix][table] When executing JUnit 5 tests in parallel, make sure the per class execution is serialized. This makes sure that all methods within one class run in parallel, but top-level classes will run sequentially, in order to avoid MiniCluster clashes between different test classes.See https://junit.org/junit5/docs/current/user-guide/#writing-tests-parallel-execution for more details.Signed-off-by: slinkydeveloper <francescoguard@gmail.com>",2
[hotfix][python][docs] Sync the documentation of a few classes with the correspoinding Java classes,2
[FLINK-xxxxx][runtime-web] Improve error message rendering- don't hide after a timeout (was: 4.5s)- expand the message box,0
fixup: use width 'auto',1
[FLINK-26757][state] Change the default value of state.backend.rocksdb.restore-overlap-fraction-threshold to 0,5
[FLINK-24586][table-planner] JSON_VALUE should return STRING instead of VARCHAR(2000)This closes #19014.,5
[FLINK-27035][python][tests] Reduce memory usage of ByteArrayWrapperSerializerTest,3
"[FLINK-26681][hive] Support sql end with "";"" for Hive dialectThis closes #19105",1
"[FLINK-26553][build] Add scalafmt for formatting the Scala codebaseRun 'mvn spotless:apply' for auto-formatting the code base. Usually,IntelliJ should pick it up automatically if the Scala plugin is installed.This closes #19025.",1
[FLINK-26553][build] Format code with Spotless/scalafmt,2
[FLINK-26553][build] Ignore scalafmt commit in .git-blame-ignore-revs,2
[FLINK-25806][ha] Remove legacy HA services,4
[FLINK-8518][table] Support EXTRACT for EPOCH and more options in Table APIThis closes #18179.,4
[FLINK-26977] Remove no longer valid tests in JobMasterStopWithSavepointITCaseTests in JobMasterStopWithSavepointITCase are no longer valid. Inparticular the way number of restarts is calculated is wrong. Moreovercases that were supposed to be tested in the class are already coveredin SavepointITCase.,3
[FLINK-26977] Unify SavepointITCase#testStopWithSavepointFailingAfterSnapshotCreation for both schedulersThis closes #19439,3
[FLINK-26756][table-planner] Fix the deserialization error for match recognizeThis closes #19179,0
"[FLINK-27196][table] Remove SerializationSchemaFactory, DeserializationSchemaFactory and TableFormatFactorySigned-off-by: slinkydeveloper <francescoguard@gmail.com>",2
[hotfix][docs] Add missing slash,1
[hotfix][table-common] ConstraintArgumentTypeStrategy uses Predicate rather than function,1
[FLINK-13785][table] Port time functions to new type inferenceThis closes #19190.,5
[hotfix][docs] Allow manual trigger for docs build,2
[hotfix][docs] Skip QA plugins for scala docs,2
[hotfix][docs] Workaround for FLINK-27232,2
[FLINK-27224][build] Drop 'flink.forkCountTestPackage' property,5
[hotfix][python][examples] Add a few examples about the basic operations of Python Table API & DataStream API,5
[FLINK-27223][python] Fix the state access problem when python.state.cache-size is set to 0This closes #19457.,1
[FLINK-27168][python] Introduce ContinuousProcessingTimeTrigger and ContinuousEventTimeTriggerThis closes #19421.,1
"[FLINK-27050][runtime] Removes default RpcSystem instanceHaving a default RpcSystem in TestingDispatcher.Buildercaused threads being spawned without cleanup. Instead, weshould rely on the RpcSystem instance provided by the test.",3
[hotfix][tests] Allow retrieval of termination future for running jobs,1
"[hotfix][tests] Wait for JobManagerRunner terminationNeed to make sure the job manager runner is complete, because the test runner does not implement required methods to query job details.",1
[FLINK-27140][coordination] Write job result in ioExecutor,2
[FLINK-25269][tests] Migrate AbstractHandlerTest to JUnit5,3
[FLINK-25269][rest] Return 503 if rpc endpoint is not started,2
[FLINK-25694][Filesystem][S3] Upgrade Presto to resolve GSON/Alluxio Vulnerability. This closes #19428Signed-off-by: David N Perkins <David.N.Perkins@ibm.com>,0
"[FLINK-27120][docs-zh] Translate ""Gradle"" tab of ""Application Development > Project Configuration > Overview"" to Chinese. This closes #19403Co-authored-by: Roc Marshal <flinker@126.com>",2
[FLINK-27222][coordination] Decouple last (al)location from execution history,2
"[hotfix][docs-zh] Fix ""Google Cloud PubSub"" Chinese page under ""DataStream Connectors"" (#19483)Co-authored-by: JustDoDT <2391554474@qq.com>",5
[FLINK-27272][table-planner] Fix the incorrect plan for query with local sort is incorrect if adaptive batch scheduler is enabledThis closes #19497,0
[FLINK-27220][runtime] Remove redundant null-check for primitive parametersThis closes #19454.,2
"[hotfix][docs-zh] Delete the ""mongodb.md"" file under ""Formats"" under ""DataStream Connectors"". (#19491)Co-authored-by: JustDoDT <2391554474@qq.com>",5
[FLINK-27213][python] Introduce PurgingTriggerThis closes #19480.,2
[hotfix][python][tests] Improve the window tests by adding window start and window end to make the test results more readable,3
[FLINK-27148][checkpoint] Skip snapshotting the coordinators state or the master state if the pending checkpoint has been disposed.This closes #19464.,2
[FLINK-25867][docs-zh] translate ChangelogBackend documentation to chinese,2
[hotfix][docs] fix anchor mistask in changelog monitoring,4
[hotfix][docs-zh] fix missing link tag in State Backends document,2
[hotfix][docs-zh] fix title level in State Backends document,2
[FLINK-27256][runtime] Log the root exception in closing the task manager connectionThis closes #19481.,2
[FLINK-27278][docs] Fix wrong indentation in windows docs,2
[FLINK-27250][sql][build] Remove custom surefire config,5
[FLINK-27252][hive][build] Remove surefire fork settings,1
"[FLINK-27121][docs-zh] Translate ""Configuration#overview"" paragraph and the code example in ""Application Development > Table API & SQL"" to Chinese. This closes #19435",5
[FLINK-27265][docs] Flink comes with five built-in BulkWriter factories instead of the mentioned four in filesystem.md. This closes #19489,5
[FLINK-27225][build] Remove redundant reuseForks settings,1
[hotfix][build] Drop unnecessary surefire config in flink-distSetting 'log.level' should have no effect.,2
[FLINK-27234][jdbc] Enable fork-reuse for unit tests,3
[FLINK-27253][cassandra][build] Remove custom surefire config,5
[FLINK-24236][metrics][tests] Migrate ReporterSetupTest to JUnit 5,3
[FLINK-24236][metrics][tests] Migrate tests to factory approach,3
"[hotfix][docs] Fixed memory units in ""Migration Guide"" under ""Memory Configuration"" page. This closes #19506",5
[FLINK-27229][cassandra][build] Remove test netty dependency,3
"[FLINK-27212][table-planner] Use UTF-8 encoding when casting between binary/character stringRevert behaviour of binary to string casts and vice versa, to not usehex enconding/decoding, but simple UTF-8 bytes transformation from abyte[] to a string and vice versa.",1
"[FLINK-27212][table-planner] Change printing of binary columns to use `x'ab3234f0'` formatAdd an `isPrinting()` method to the `CastRule.Context` set to true used by`RowDataToStringConverterImpl` which defines a different casting behaviourfor `BinaryToStringCastRule` when printing binary columns, so that we outputcolumns of binary type as (for example): `x'ab03f98e'`, which can easily be copypasted as a binary literal to another SQL query.This closes #19507.",5
[FLINK-27232][build] Explicitly configure scalafmt in each module,5
[FLINK-27208][docs] Add scalafmt docs,2
[FLINK-27231][licence] Fix the SQL Pulsar licence issue,0
[FLINK-27230][licence] Remove the unused licence entries from Kinesis connector,1
[FLINK-27233][licence] Remove the unused licence entries from Elasticsearch7 connector,1
[FLINK-27263][table] Rename the metadata column to the user specified name in DDLThis closes #19521.,1
[FLINK-27267][contrib] Migrate tests to JUnit5,3
[hotfix][docs] Misprint in types.md,2
[FLINK-25109][table-sql-client] Update JLine3 to 3.21.0. This closes #17961,5
[hotfix][docs-zh] Improving Chinese translation for Table concepts overview documentation.,2
[FLINK-27163][docs] Fix broken table layout for metrics due to incorrectly defined rowspan. This fixes #19420,0
[FLINK-27298][docs] Change the used table name in the SQL Client documentation to the correct name. This closes #19510,2
[FLINK-27319] Duplicated '-t' option for savepoint format and deployment target,1
[FLINK-27287][tests] Migrate tests to MiniClusterResource,5
[FLINK-27287][tests] Use random ports,1
[FLINK-27317][build] Use absolute paths to .scalafmt.conf,5
[FLINK-27317][build] Don't fork build for attaching sources,2
[FLINK-27317][build] Bump maven-source-plugin to 3.2.1,2
[FLINK-27325][build] Remove custom forkCount settings,1
[FLINK-27206][metrics] Remove reflection annotations from reporters,4
[FLINK-27206][metrics] Deprecate reflection-based reporter instantiation,2
[FLINK-27145][table] Support code gen for aggregate function with empty parameterThis closes #19418,2
[FLINK-27315][docs] Fix the demo of MemoryStateBackendMigration,0
[FLINK-27247][table-planner] ScalarOperatorGens.numericCasting is not compatible with legacy behaviorThis closes #19470.,1
[FLINK-25548][table] Migrate sq-parser tests to JUnit5,3
[FLINK-27167][test] change the junit-jupiter dependency scope to compile,3
[hotfix][build] Remove disabled checkstyle rules,4
[FLINK-27339][tests] Add missing package,1
[FLINK-27321][ci] Migrate java-ci-tools to JUnit 5,3
[examples][python] Add examples on how to use json/csv/avro formats in Python DataStream API,5
[FLINK-27218] fix the problem that the internal Serializer in OperatorState may have not been updated when sechema changes,4
[FLINK-22984][python] Don't pushdown Calc containing Python UDFs into table sourceThis closes #19551.,5
[FLINK-27187][state/changelog] Add changelog storage metric totalAttemptsPerUpload,4
[FLINK-23252][changelog] Support recovery from checkpoint after disabling changelog backend,4
[FLINK-23252][changelog] Introduce CheckpointBoundKeyedStateHandle#rebound,0
[hotfix] Remove unused classes,1
[FLINK-26477][python] Support side output in Python DataStream APIThis closes #19453.,5
[hotfix][python][tests] Remove useless test utility methods,3
[FLINK-27369][table-planner] Fix the type mismatch error in RemoveUnreachableCoalesceArgumentsRuleThis closes #19566,4
[FLINK-27381][connector/common] Use Arrays.hashcode for HybridSourceSplit wrappedSplitBytes,1
[FLINK-23902][connectors/hive] Add support to Hive version 3.1.3.This closes #19512.,1
[FLINK-24491][runtime] Make the job termination wait until the archiving of ExecutionGraphInfo finishes,5
[FLINK-23659][metrics][prometheus] Cleanup code,4
[FLINK-27398][scala] Move completeness test to flink-scala,2
[FLINK-27390][build] Remove unused flink-tests dependencies,3
[FLINK-27389][tests] Move flink-tests test utils to flink-test-utils,3
[FLINK-27351][tests] Use sane TM resource spec,1
[hotfix][build][influxdb] Remove unused dependency,1
[FLINK-26246][build][tests] Setup JUnit 5 infrastructure for parallel test execution,3
[FLINK-24721][build] Remove unnecessary relativePath to parent,4
[FLINK-24222] Fully migrate ReporterSetupTest to ContextClassLoaderExtension,3
"[FLINK-27308][Filesystem][S3] Update the Hadoop implementation for filesystems to 3.3.2. This closes #19514This PR includes making sure that commons-compress is included so that class org.apache.commons.compress.archivers.tar.TarArchiveInputStream is available. This class is required in order to read a TAR archive as an InputStream.The NOTICE files (where applicable) also include a reference to the Hadoop Thirdparty Shaded dependencies, like we also do for flink-python.Co-authored-by: Chinmay Sumant <csumant@apple.com>",2
[FLINK-27409][runtime] Cleanup stale slot allocation record when the resource requirement of a job is emptyThis closes #19580.,1
[hotfix][build] Restrict number of forkCounts when running locally down to some sane valuesThe previous values would require tens of GB of memory on modern machines.,1
[FLINK-27209][build] Half the memory and double forkCount for running unit testsAdditionally mark TaskExecutorRecoveryTest as an ITCase due to memory consumption and starting up TaskManagers,3
[FLINK-25541][tests] Migrate tests to JUnit 5,3
[FLINK-27282][python] Fix the bug of wrong positions mapping in RowCoderThis closes #19505.,0
[FLINK-27228][ci] Limit fine-grained RM to flink-runtime/tests,3
[FLINK-27228][ci] Redistributed modules across CI profiles-> runtime* gelly* statebackends* dstl* queryable-state-> connectors -> connectors_1* remaining filesystems/formats* hbase-> kafka/gelly -> connectors_2* pubsub* pulsar* rabitmq* aws-> misc* architecture-tests,3
[FLINK-20808][build] Remove redundant checkstyle rules,4
[FLINK-25550][k8s] Migrate tests to JUnit 5,3
[python][docs] Update examples to use print method to view the table results,1
[FLINK-27431][rpc] Allow RpcTimeouts to be specified as Duration,1
[FLINK-27428][core] Deduplicate #toDuration(Time),2
[FLINK-27430][tests] Remove unused timeout field,1
[FLINK-14820][core] Remove unused scheduleWithDelay,1
[FLINK-14820][core] Migrate FutureUtils to Duration,2
[python][docs] Update documentation to remove deprecated API examples,4
[FLINK-24804][FLINK-25505] Upgrade oshi-core to version 6.1.5,2
[hotfix][test][formats] Detach TableCsvFormatITCase from JsonPlanTestBase,5
[python][docs] Update the documentation of introduction of table api,2
[hotfix][webui] Disable creating of test-jar,3
[FLINK-26244][webui] Migrate tests to JUnit5,3
[FLINK-27427][rpc] Remove timeouts from RpcUtils#terminate*,4
[FLINK-27426][rpc][tests] Remove unnecessary future timeouts,4
[FLINK-27426][rpc] Migrate RPC system internals to Duration,5
[FLINK-27324][rpc] Migrate tests to JUnit 5,3
[FLINK-26298][rpc][tests] Migrate tests to JUnit5,3
[FLINK-25511][state] Introduce StreamStateHandle IDThe ID will be used to track state usage on TM;State objects not shared with JM will be discarded.,1
[FLINK-25511][state/changelog] Discard pre-emptively uploaded state changes not included into any checkpoint,4
[FLINK-27382][runtime] Moves cluster shutdown to when the job cleanup is done in job mode,4
"[hotfix][runtime][test] Adds additional test for when the JobManagerRunner result completes exceptionallyAdditionally, I moved the test's documentation into theproduction code because it makes more sense to have thereasoning over there.",1
[FLINK-27367][table-planner] Support cast int to date in legacy cast behavior (#19585),5
[FLINK-27420] Recreate metric groups for each new RM to avoid metric lossThis closes #19607,1
[FLINK-26154][tests] Improve logging in SavepointFormatITCase,2
[FLINK-27452][tests] Move TestBaseUtils#getFromHttp to WebFrontendITCase,3
[FLINK-27453][tests] Cleanup TestBaseUtils,3
[hotfix][table-planner] Remove TableConfig as member variable in PlannerContext,5
[hotfix][table-planner] Simplify PlannerContext signatures related to CatalogManager,2
[hotfix][table] Simplify code in ParserImpl and FunctionLookup,1
[FLINK-22857][table-planner] Simplify DefaultSqlExprToRexConverterFactory to RexFactory,2
[FLINK-22857][table-common] Expose more RuntimeContext functionalities in FunctionContext,1
[FLINK-22857][table] Support evaluating expressions in SpecializedFunction,1
[FLINK-26947][table] Add ARRAY_CONTAINS functionThis closes #19543.,1
[FLINK-27459][tests] Reset context environment,1
[FLINK-27454][tests] Explicitly import TestBaseUtils,3
[FLINK-27454][tests] Remove inheritance from TestBaseUtils,3
[FLINK-27460][runtime] Remove unused notifyPartitionDataAvailable process,5
"[FLINK-27394][Documentation] Document how you can add externally hosted documentation in a virtual filemounted system that's only known to Hugo, using Hugo Modules.",1
[FLINK-27394][Documentation] Remove existing Elasticsearch documentation since it has been moved to apache/flink-connector-elasticsearch,2
[FLINK-27394][Documentation][Buildsystem] Update build pipeline to get latest documentation from external connector repository,2
"[FLINK-27394][Documentation] Document how you can add externally hosted documentation in a virtual filemounted system that's only known to Hugo, using Hugo Modules.",1
"[FLINK-27441][webfrontend] fix ""nzScroll"" calculationsCo-authored-by: Ferenc Csaky <fcsaky@cloudera.com>",0
[FLINK-27066][tests][connectors/elasticsearch] Reintroduce e2e tests in ES as Java tests.TODO: switch off logging,2
[FLINK-27066][tests][connectors/elasticsearch] Remove bash-based E2E Elasticsearch tests,3
[FLINK-27352][json][tests] Migrate flink-json to JUnit5,3
[hotfix][json][tests] Fix location of services directory,0
[FLINK-27470][state][tests] Migrate test to JUnit5,3
[FLINK-27368][table-planner] Trim casts from character string to numericThis closes #19565.,2
[FLINK-27485][docs] Fix documentation build pipeline Fix the documentation build pipeline by 1) using a different Git command (which is supported by the installed Git version on the Docker image) and 2) upgrading Hugo and making sure that this is added to the PATH (#19632)- use compatible command to get the current git branch- put hugo onto PATH,1
[hotfix][docs] Fix class name in docs for ExecutionEnvironment class,2
[FLINK-26496][yarn][tests] Migrate tests to JUnit5,3
[FLINK-27442][Formats][Avro Confluent] Add Confluent repo to module flink-sql-avro-confluent-registry,5
[FLINK-27465] Handle conversion of negative long to timestamp in AvroRowDeserializationSchema,0
[FLINK-24766] Ceiling/flooring dates to day returns wrong results. This includes handling millis for timestamps. This closes #17677,0
release notes for the 1.15 release,5
Update japicmp configuration for 1.15.0,5
[hotfix][metrics] Ignore compatibility warnings for Metric#getMetricTypeThe change is source-compatible.,4
[hotfix][k8s][tests] Fix import,2
[FLINK-27486][core] Mark documentation formatting tools as PublicEvolving,2
[FLINK-27486][hybrid] Make hybrid source building blocks as PublicEvolving,1
[FLINK-27486][tests] Fix archunit test violations in connector-base module,3
[hotfix][ci] Update libssl download link,2
[release] Add 1.15 docs link to the list of previous versions,2
[FLINK-27477][yarn][tests] Drop flink-yarn test-jar,3
[FLINK-26052][docs-zh] Document savepoint format,2
[FLINK-27469][yarn][tests] Drop CliFrontendRunWithYarnTestThe detached/parallelism options aren't handled by the yarn session CLI.See CliFrontendParser#getProgramSpecificOptions.,1
[FLINK-25970][core] Add type of original exception to the detailMessage of SerializedThrowable.This closes #19615,1
[release] Change the stable doc versions,2
[FLINK-24820][docs] Wrong description in documentation for IS DISTINCT FROM,2
[hotfix][docs-zh] Delete redundant English content in Chinese documents.,2
[FLINK-27533][coordination][tests] Remove retry attempt limitThe test could fail if the polling loop ran too quickly or if the timing was just right that it always missed the restarting state.Remove the limit and just wait for as long as needed.,4
[hotfix][docs] Fix the inaccessible huawei cloud  link.,2
[FLINK-27476][tests] Add dedicated import option for selecting production code,2
[FLINK-27461][Kubernetes] Add option to set userAgent for kubeclientThis closes #19630.,1
[release] Upgrade current version to 1.15 for TypeSerializerUpgradeTestBase and create snapshots,1
[release] Upgrade current version to 1.15 for FlinkKafkaConsumerBaseMigrationTest and create snapshots,1
[release] Upgrade current version to 1.15 for FlinkKafkaProducerMigrationTest and create snapshots,1
[release] Upgrade current version to 1.15 for FlinkKinesisConsumerMigrationTest and create snapshots,1
[release] Upgrade current version to 1.15 for ContinuousFileProcessingMigrationTest and create snapshots,1
[release] Upgrade current version to 1.15 for CEPMigrationTest and create snapshots,1
[release] Upgrade current version to 1.15 for WindowOperatorMigrationTest and create snapshots,1
[release] Upgrade current version to 1.15 for StatefulJobSnapshotMigrationITCase and create snapshots,1
[release] Upgrade current version to 1.15 for StatefulJobWBroadcastStateMigrationITCase and create snapshots,1
[release] Upgrade current version to 1.15 for TypeSerializerSnapshotMigrationITCase and create snapshots,1
[release] Upgrade current version to 1.15 for AbstractOperatorRestoreTestBase and create snapshots,1
[release] Upgrade current version to 1.15 for StatefulJobSavepointMigrationITCase and create snapshots,1
[release] Upgrade current version to 1.15 for StatefulJobWBroadcastStateMigrationITCase and create snapshots,1
[hotfix][doc] fix the mismatch result in Window Join example (#19665)Signed-off-by: TennyZhuang <zty0826@gmail.com>,0
[FLINK-27545][python][examples] Update the example in PyFlink shellThis closes #19673.,2
[hotfix][docs-zh] Add known issues with Pulsar client under Java 11 to Chinese documentation.,2
[FLINK-27480][kafka] Explain possible metrics InstanceAlreadyExistsException in docs,2
[hotfix][docs] Fix the formatting errors of some Chinese documents.,2
"[hotfix][docs] Mention changes of ""RuntimeContext#getMetricGroup"" in 1.14 release notes.This closes #19676",1
"[hotfix][table-planner][tests] Remove configuration for default legacy-cast-behaviourSince `table.exec.legacy-cast-behaviour` is disabled by default, thereis no need to explicitely set it in the configuration of the Castrelated IT tests.Call `super.getConfiguration()` to inherit the configuration set in thesuperclass and add/override with more config options in the subclass.",5
[hotfix][table][tests] Clean-up tests and update to assertJ,3
[hotfix][table][tests] Replace ExpectedException with assertJReplace deprecated ExpectedException with assertJ's`assertThatThrownBy` and improve certain assertions by assertingthe Exception class or the Exception message where missing.This closes #19262.,3
[hotfix]Remove unused variable in KubernetesEntrypointUtils,1
[Flink-26112][k8s]Refactor the FlinkKubeClient interface to deal with service name directly,2
[FLINK-26112][k8s]Port getRestEndpoint method to the specific service type subclassThis closes #18762.,1
[FLINK-26588][docs] Translate the new CAST documentation to ChineseThis closes #19498.,1
[hotfix] Fix comment typos in AsyncIOExample,2
[FLINK-27487][kafka] Only forward measurable Kafka metrics and ignore others,2
[hotfix][docs-zh] Fix two inaccessible links. (#19678)* [hotfix][docs-zh] Fix two inaccessible links to the Iterations documentation. This fixes #19678,0
[FLINK-27255] [flink-avro] flink-avro does not support ser/de of large avro schema (#19645)Co-authored-by: Haizhou Zhao <haizhou_zhao@apple.com>,1
[FLINK-27565][runtime-web] Bump minimist from 1.2.5 to 1.2.6 in /flink-runtime-web/web-dashboard. This closes #19501Bumps [minimist](https://github.com/substack/minimist) from 1.2.5 to 1.2.6.- [Release notes](https://github.com/substack/minimist/releases)- [Commits](https://github.com/substack/minimist/compare/1.2.5...1.2.6)---updated-dependencies:- dependency-name: minimist  dependency-type: indirect...Signed-off-by: dependabot[bot] <support@github.com>,1
[FLINK-27450][hive] Upgrade default hive version to fix Hive SessionState initialization issue with jdk11,0
[FLINK-27048][test] Add ArchUnit rule that connectors should only depend on public API,1
[FLINK-27563][docs] Fix yarn doc page display error.,0
[hotfix][doc] Extensible unified Sink uses new metric to capture outgoing records,1
[hotfix][connectors/kafka] Fix spelling of setDeliveryGuarantee method,1
"[hotfix][docs] fix ""parameters""",2
"[hotfix][docs]correct configuration key ""taskmanager.network.detailed-metrics"" in metrics document",2
[FLINK-27260][Runtime/REST] Expose changelog configurations in Rest API,5
FLINK-27260][Runtime/Web] Expose changelog configurations in web ui,5
[hotfix][table] avoid NPE and add more UTs. Remove System.out.println() call.This closes #19699.,5
[FLINK-27297][python] Add get_execution_environment method with configuration argument.This closes #19685.,5
[hotfix][connector][elasticsearch] Reduce testutils log level (#19707),2
[FLINK-27560][python] Refactor SimpleStateRequestHandler to support both keyed state and operator stateThis closes #19687.,1
[FLINK-27421][python] Bundle test utility classes (#19700),3
[FLINK-25470][changelog] Expose more metrics of ChangelogStateBackend and materialization,4
[hotfix][docs] Fix the wrong display of totalNumberOfCheckpoints in metric.md,0
[FLINK-26206][runtime-web] add service layer abstraction and refactor config service,5
[FLINK-27271][python] Introduce Globalwindows window allocatorThis closes #19696.,2
[FLINK-27185][formats] Convert format modules to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-27564][python] Separate different connectors into separate packagesThis closes #19711.,2
[FLINK-27271][python] Expose GroupWindow to users,1
[FLINK-24433][Tests][Buildsystem] Turn off debug logging for all end-to-end tests to avoid flooding the disk space,3
[FLINK-17232][k8s] Disable the implicit behavior to use the Service externalIP as the address of the Endpoint,1
[FLINK-27323][table][tests] Migrate table-api-java to JUnit5,3
[FLINK-27566][aws][tests] Migrate aws-kinesis-firehose to JUnit5,3
[FLINK-24433][Tests][Buildsystem] Remove additional pre-installed packages to clean up more diskspace before starting the E2E tests. Also removing the line that removes `^ghc-8.*` since that doesn't exist anymore on the machines.,4
[FLINK-27649][connectors/elasticsearch] Remove slf4 dependency causing unwanted log output,2
[hotfix][table] Add objectReuse parameter for AsyncLookupJoinITCase. (#19728),5
[FLINK-26909][Client/Job Submission] Allow to set parallelism to be -1 from CliThis closes #19651.,1
[FLINK-27501][tests] Migrate SerializerTestBase to JUnit5,3
[FLINK-27567][aws][tests] Migrate connector-aws-kinesis-streams to JUnit5,3
[FLINK-27433][tests] Store RocksDB logs in its database folder for e2e tests,3
[FLINK-25543][yarn][tests] Migrate tests to JUnit5,3
[FLINK-27059][compress][tests] Migrate tests to JUnit5,3
[hotfix][elasticsearch] Fix typo,2
[hotfix][akka][docs] Replace LocalRpcInvocation with RpcInvocationThis closes #8033.,2
[FLINK-27662][tests] Migrate TypeInformationTestBase to JUnit5,3
"[FLINK-24433][Connector][Elasticsearch] Disable Elasticsearch disk allocation decider. Elasticsearch by default goes into read-only mode when the disk usage is above 85%. On the Azure E2E tests, this is quite common.We therefore disable the entire disk allocation decider, as documented on https://www.elastic.co/guide/en/elasticsearch/reference/6.2/disk-allocator.html",2
[hotfix][python] Fix lint-python typo,2
[FLINK-27561][aws][tests] Migrate connector-aws-base to JUnit5,3
[FLINK-27669][tests] Migrate flink-file-sink-common to JUnit5,3
[FLINK-27673][table][tests] Migrate flink-table-api-scala to JUnit5,3
[FLINK-27607][tests] Migrate module flink-connector-files to JUnit5,3
[FLINK-27185][connector] Convert connector-elasticsearch modules to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-27185][connector] Convert connector-hive module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-27185][connector] Convert connector-base module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-25795][python][connector/pulsar] Support pulsar sink connector in PyFlink DataStream APIThis closes #19682.,5
[FLINK-27340][python][tests] Migrate flink-python to JUnit5,3
[FLINK-27682][tests] Migrate ComparatorTestBase to JUnit5,3
[FLINK-27680][Connector][Pulsar] Disable PulsarSinkITCase and PulsarSourceITCase on JDK 11 since Pulsar doesn't support JDK 11 fully,1
[FLINK-27185][connector] Convert connector-cassandra module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-27676][python] Fix on_timer output behind triggering watermarkThis closes #19765.,0
[FLINK-27174][connector/kafka] Fix checking of bootstrapServers when already provided in producer Properties,1
[FLINK-25950][runtime] Use idempotent delete for zk nodeThis cleanup is made possible by upgrading the curatordependency from 2.12 to 2.5.0.,4
[FLINK-27698][tests][table] Migrate flink-table-api-java-bridge to JUnit5,3
[FLINK-27672][tests][table] Migrate flink-table-common to JUnit5,3
[FLINK-26788][core] Add cause when AbstractDeserializationSchema throw exceptionThis closes #19241.,1
[hotfix][runtime] Add serialVersionUID to ExecutionVertexID,1
[FLINK-17295][runtime] Introduce ExecutionGraphID,2
"[FLINK-17295][runtime] Refactor ExecutionAttemptID to consist of executionGraphId, executionVertexId and attemptNumber",4
[FLINK-17295][runtime] Rework MetricGroup methods to ensure param consistency,2
[FLINK-17295][runtime] Simplify ExecutionVertexID retrieval in scheduler,2
[FLINK-17295][runtime] Remove unnecessary fields from TaskDeploymentDescriptor,4
[FLINK-17295][runtime] Remove unnecessary fields from Execution and ArchivedExecution,4
"[FLINK-17295][runtime] Refine tests to ensure the consistency of jobVertexId, subtaskIndex, attemptNumber and executionAttemptId",3
[FLINK-27490][table][tests] Migrate test to JUnit5 for flink-table-code-splitter,2
[FLINK-26480][python] Support window_all in Python DataStream APIThis closes #19758.,5
[FLINK-27711][python][connector/pulsar] Fix the typo of the method name from set_topics_pattern to set_topic_patternThis closes #19774.,1
[hotfix][python] Fix typo of lint-python (#19769),2
[FLINK-27694][python][build] Move lint-python log location (#19768),2
[hotfix][python][connector/pulsar] Improve PulsarDeserializationSchema.flink_type_info set execution_config default to None,5
[FLINK-27699][python][connector/pulsar] Support StopCursor.at_publish_timeThis closes #19771.,1
[FLINK-26043][runtime][security] Add periodic kerberos relogin to KerberosDelegationTokenManager[FLINK-27605][tests] Updated Mockito version to 3.4.6 in order to use static method mocking,1
[FLINK-27735][testinfrastructure] Update testcontainers dependency to v1.17.2,3
[FLINK-24735][sql-client] Catch Throwable rather than Exception in LocalExecutor to avoid client crashThis closes #19773.,2
[hotfix][docs] Update java doc to use DataStream API instead of deprecated DataSet APIThis closes #19784.,5
[hotfix][docs][connector/pulsar] Fix doc typo of setDeliveryGuarantee,1
[FLINK-27732][tests] Migrate flink-examples-table to JUnit5,3
[hotfix][tests] Fix command not found error in azure watchdog script,0
[FLINK-25188][python][build] Support m1 chip.This closes #18769.,1
"Revert ""[FLINK-25188][python][build] Support m1 chip.""This reverts commit 7e9be789",4
[FLINK-27733][python] Rework on_timer output behind watermark bug fixThis closes #19788.,0
[FLINK-27219][sql-client] Print exception stack when get errorsThis closes #19796.,0
[FLINK-27751][build] Disable jboss repository,2
[FLINK-27754][shell] Add stderr when singular flink-dist*.jar cannot be resolved for config.sh.,5
[FLINK-27690][python][connector/pulsar][docs] Add pulsar example and documentationThis closes #19775.,2
[FLINK-27251][checkpoint] Refactor the barrier alignment timer and default priority sequence number,4
[FLINK-27251][checkpoint] Timeout aligned to unaligned checkpoint barrier in the output buffers,2
[FLINK-27251][checkpoint] Refactor the close() and cancel() of SubtaskCheckpointCoordinator,4
[FLINK-27757][Connector][Elasticsearch] Elasticsearch connector should not use `flink-table-planner` but `flink-table-planner-loader`. We also need to add `flink-table-runtime` to avoid ClassNotFoundException on `org.apache.flink.table.shaded.com.jayway.jsonpath.spi.mapper.MappingProvider`,5
[FLINK-27532][build][clients] Drop flink-clients test-jar,3
[FLINK-27763][kinesis][tests] Remove netty bundling&relocation,4
[hotfix][docs-zh] Fix the formatting errors of some Chinese documents.,2
[FLINK-26074] Improve FlameGraphs scalability for high parallelism jobs,1
[FLINK-27740][tests] Migrate flink-test-utils-junit to JUnit5,3
[FLINK-27760][python] Fix the issue that NPE is thrown when executing PyFlink Table API jobs in batch modeThis closes #19816.,2
[FLINK-27776][python] Throw meaningful exceptions when UDAF doesn't override method 'merge' is used in cases where 'merge' is usedThis closes #19817.,1
[FLINK-27169][tests] Increase changelog upload timeout in tests,3
[FLINK-27169][tests] Set timeout for operator lifecycle tests,3
[hotfix][tests] Raise logging level in TestJobExecutor,3
[hotfix][python] Fix flake8 check E523 error for format method has unused arguments (#19822),1
[hotfix][python] Fix flake8 check E302 error for blank lines (#19821),0
[FLINK-27818][rest][docs] Model enums as references,2
[FLINK-27825][docs] Update the doc of aligned checkpoint timeout,2
[FLINK-27657][python] Implement remote operator state backend in PyFlinkThis closes #19743.,2
[FLINK-27779][connectors/cassandra] Remove `flink-table-planner` in favor of `flink-table-test-utils`,3
[FLINK-27779][connectors/kafka] Remove `flink-table-planner` in favor of `flink-table-test-utils`,3
[FLINK-27779][connectors/kinesis] Remove `flink-table-planner` in favor of `flink-table-test-utils`,3
[FLINK-27779][connectors/aws-kinesis] Remove `flink-table-planner` in favor of `flink-table-test-utils`,3
[FLINK-27522][network] Ignore max buffers per channel when allocate buffer,2
[hotfix][streaming] Remove flink-tests dependency,3
[FLINK-27527][test-utils] Create a file-based upsert sink connector for testing internal components,3
[hotfix][doc] fix typo and enlarge image,2
[FLINK-27797][python] Fix the issue that PythonTableUtils.getCollectionInputFormat cannot correctly handle None valuesThis closes #19834.,0
[FLINK-27630][table-planner] Add maven-source-plugin for table planner testing connectors (#19746),3
[FLINK-15854][hive] Use the new type inference for Hive UDTF (#18958),5
[FLINK-27829][python] Remove calcite dependency (#19841),4
[FLINK-27683][table-planner] Fix SQL hints can't work with targetColumnsThis closes #19847,1
[FLINK-25188][python][build] Support m1 chipThis closes #19802.,1
[hotfix][table] Fix typo in comment of WindowBufferThis closes #19879,2
"[FLINK-25705][docs]Translate ""Metric Reporters"" page of ""Deployment"" in to Chinese.This fixes #19496.Co-authored-by: Roc Marshal <flinker@126.com>",2
[FLINK-27811][build][netty] Remove unused netty dependency,1
[FLINK-27810][es][tests] Reduce number of bundled dependencies,3
[hotfix] Fix typo in comment of PojoTypeInfo,5
[FLINK-21996][python] Support Kinesis connector in Python DataStream APIThis closes #19869.,5
[FLINK-27901][python] Support TableEnvironment.create(configuration)This closes #19883.,5
[hotfix][table-common] Deprecate CatalogFunction#isGenericSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][table-planner] Remove apply implementation for CodeGeneratorContextSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix][table-api-java] Fix singleton config in EnvironmentSettingsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-15635][table] Add user classloader to EnvironmentSettingsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-15635][table] Propagate ClassLoader whenever is appropriateSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-15635][python] Remove creating a new ClassLoader in add_jars,1
[FLINK-15635][table] Fix Scala format problems and address feedbacks,5
[fixup][table-planner] Refactoring CodeGeneratorContext by add user ClassLoader,1
[FLINK-15635][table] Improve implementation of user classloader,1
[FLINK-25699][table] Use HashMap for MAP value constructors,1
[FLINK-27910][connector/filesystem] Register the timer to enforce rolling policy when file sink starts from scratch.This closes #19889.,2
[FLINK-27185][connector] Convert connector-jdbc module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>Co-authored-by: Sergey Nuyanzin <sergey.nuyanzin@aiven.io>,2
[FLINK-27902][network] Remove unnecessary attribute hasBackPressure in ResultPartitionType.,4
[FLINK-27902][network] Add ConsumingConstraint and releaseBy in ResultPartitionType to decoupling scheduling and partition release.,1
[FLINK-27902][network] Using mustBePipelinedConsumed method to compute pipelined regions.,1
[FLINK-27902][network] Introduce canBePipelinedConsumed to replace some previous isPipelined calls that actually judge whether the downstream can consume data when upstream is not finish.,5
"[FLINK-27902][network] Using isReleaseByScheduler and isReleaseByUpstrem to replace some previous isPipelined,isBlocking and isReconnectable calls that actually refer to partition release logical.",2
[FLINK-27902][network] Introduce isPipelinedOrPipelinedBoundedResultPartition to replace some previous isPipelined calls that actually judge whether the resultPartitionType is Pipelined or PipelinedBounded.,5
[FLINK-27902][network] Introduce isBlockingOrBlockingPersistentResultPartition and replace all remaining isBlocking calls.,5
"[FLINK-27902][network] remove useless isPipelined, isBlocking and isReconnectable in ResultPartitionType.This closes #19885",1
[FLINK-27457][cassandra] Implement flush() logic in output formats,2
[FLINK-27924][python][docs] Include pulsar in the list of supported connectors in DataStream (#19887),5
[FLINK-27955][python] Fix the problem of windows installation failure in PyFlinkThis closes #19909.,2
[FLINK-27418][table-planner] Fix topN retraction for previously deleted recordThis closes #19778,4
[FLINK-27185][connector] Convert connector-kafka module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>Co-authored-by: Sergey Nuyanzin <sergey.nuyanzin@aiven.io>,2
[FLINK-24865][CEP] Support MATCH_RECOGNIZE in Batch modeThis closes #18408,1
[FLINK-27729][python][pulsar] Support constructing StartCursor and StopCursor from MessageIdThis closes #19917.,1
[FLINK-27968][tests] Disable PlannerScalaFreeITCase,3
[FLINK-27791][tests] Prevent mocked UGI bleeding into other tests,3
[FLINK-27959][TableSQL/API][avro] Remove usage of deprecated TableSchema from flink-avro,2
[FLINK-25714][runtime-web] upgrade ng-zorro-antd and remove unnecessary dependency,4
[FLINK-27920][doc] Documented enums constant support ExcludeFromDocumentation annotationThis closes #19888,2
[FLINK-25931][format] Add projection pushdown support for CsvFormatFactoryThis closes #19286,1
[FLINK-27734][runtime-web] fix checkpoint interval in WebUI,0
[FLINK-27058][python][build] Add support for Python 3.9This closes #19895.,1
[FLINK-27935][python][docs] Add Pyflink example of create temporary view documentThis closes #19918.,2
[FLINK-23890][cep] Optimize cep operator timer register policyThis closes #19259.,1
[FLINK-27968][e2e] Fix PlannerScalaFreeITCase- only run the test in e2e profile- remove unnecessary dependencies,4
[FLINK-27651][table] Support CREATE FUNCTION USING JAR syntaxThis closes #19742,1
[FLINK-27921][Runtime] Introduce the checkResourceRequirementsWithDelay in DeclarativeSlotManagerThis closes #19886.,1
[hotfix] fix typo in StreamingJobGraphGenerator.,2
[FLINK-27903][network] Introduce HYBRID result partition type.,2
[FLINK-27903][streaming] Make StreamGraph supports hybrid result partition type.,1
[FLINK-27903][runtime] Make pipelinedRegionSchedulingStrategyTest also support testing for hybrid resultPartitionType.This closes #19927,3
[FLINK-27737][rpc] Remove legacy support for unfenced executor in FencedRpcEndpointThis closes #19938,1
[FLINK-27778][table][planner] Use correct 'newName()' method,1
[FLINK-28000][runtime][security] Throw exception when principal is set in the configuration without keytab,5
[FLINK-27890][examples] Fix the bug introduced By [FLINK-19317] to use the return result after assignTimestampsAndWatermarks,1
[FLINK-27756] Setting batches to one and extending sending margin in checkLoggedSendTimesAreWithinBounds test.,3
[FLINK-27185][connector] Convert connector-kinesis module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-27544][docs]Example code in 'Structure of Table API and SQL Programs' is out of date and cannot run. This closes #19681,1
[hotfix][docs] Update memory unit Mb.,5
[hotfix][docs-zh] Add missing the flame_graphs.md file to debugging.,0
[FLINK-27171][runtime][security] Add periodic kerberos delegation token obtain possibility to DelegationTokenManager,1
[hotfix][network] Fix the typo about subpartition,2
[hotfix][fault-tolerance][docs] Corrected typo in state page,2
[Hotfix] fix typos,2
[FLINK-27658][runtime] SafetyNetWrapperClassLoader expose addURL method to allow registering jar dynamically,1
[FLINK-27041][connector/kafka] Catch IllegalStateException in KafkaPartitionSplitReader.fetch() to handle no valid partition caseThis closes #19456.,1
"[hotfix] Cleanup EnumValueSerializerCompatibilityTest- 'in' variable was unused- 'out' variable was unnecessary because the reporter by default prints to stderr anyway, and there isn't a real benefit in using stdout",1
"[FLINK-24995][tests] Migrate tests to ConsoleReporter#finish'ConsoleReporter#finish' behaves just like '#printSummary', but is also supported in later versions.Additionally, we now fail the test if the compiler reported any warnings/errors, as without it the summary business didn't provide a benefit in the first place.",1
"[FLINK-27999][hive] Fix Hive3 issues- VirtualColumn.VIRTUAL_COLUMN_NAMES has a different type in hive2 vs hive3, causing NoSuchFieldErrors since our code is only compiled against hive2- HiveConf is a singleton that is modified in various ways; adds a band-aid to resolve some issues",0
[FLINK-27895][hive][ci] Enable nightly Hive 3.x tests,3
"[FLINK:27808][ha] Allow ""kubernetes"" as HA_MODE",1
[hotfix][docs] Improve HA_MODE description,1
[FLINK-24960][yarn-tests] change order of statements to avoid race condition,4
[hotfix] Rework BinaryInputFormatTest to be based on AssertJ,3
[FLINK-28018][core] correct the start index for creating empty splits in BinaryInputFormat#createInputSplits,1
[FLINK-27819][rest][docs] Use proper operationIds,1
[FLINK-27965][table-planner] Fix EXPLAIN PLAN produces wrong query schema for insert clause with static partitionThis closes #19940,1
[hotfix][tests] Avoid hard-coded class name,3
[FLINK-28005][tests] Reduce network memory in UnalignedCheckpointTestBase,3
[hotfix][build] Introduce property for common surefire arg line,5
[FLINK-28006][tests] Run prod architecture tests in 1 JVM,3
[hotfix][tests] Streamline SubmissionBufferingTaskManagerGateway,3
[hotfix][tests] Remove magic number,4
[hotfix][tests] Always respond to task cancellation requestsThe previous cancel setup doesn't make sense if you aren't aware that one of the tests forces a restart.We now immediately respond to any task cancellation request instead.,1
"[FLINK-28052][tests] Remove RunFailedJobListenerThe RunFailedJobListener had rather obscure semantics.It considered a job to be terminal after it was restarted. This is awfully specific to a particular test case.A cleaner approach is to just cancel the job and wait for it to terminate.Additionally it considered a job as running purely based on the job status, whereas, in particular when checkpointing is involved, waiting for the tasks to be submitted is a better measure.In fact, testExceptionHistoryWithTaskFailureFromStopWithSavepoint was a broken since a savepoint was never triggered, as not all tasks were running.",1
[FLINK-27762][connector/kafka] Catch WakeupException and retry KafkaConsumer invocations in split assignmentThis closes #19828.,1
[FLINK-28019][table] fix error when retract a staled record if state ttl enabled in RetractableTopNFunctionThis closes #19942,1
[FLINK-26824][cassandra] Upgrade driver to 3.11.2,2
[FLINK-28004][ci] Reduce heap memory consumption by 25%,2
[FLINK-27881][Connector/Pulsar] Never return null for PulsarMessageBuilder.,2
[FLINK-26941][cep] Support Pattern end with notFollowedBy in case time constraint is definedThis closes #19295.,5
[FLINK-27932][python] Introduce WatermarkStrategy.no_watermarks and WatermarkStrategy.no_watermarks to align with Java APIThis closes #19896.,2
[FLINK-27983][table-common] Introduce SupportsStatisticsReport interfaceThis closes #19939,1
[FLINK-27984][table-common] Introduce FileBasedStatisticsReportableInputFormat interfaceThis closes #19939,2
[FLINK-27987][connector/file] Let FileSystemTableSource extend from SupportsStatisticReportThis closes #19939,1
[FLINK-27985][table-planner] Introduce FlinkRecomputeStatisticsProgram to compute statistics after filter push and partition pruningThis closes #19939,1
[FLINK-27006][table] Support SingleValueAggFunction for CHAR data typeThis closes #19338,5
[FLINK-18887][python][connector/elasticsearch] Add ElasticSearch connector for Python DataStream APIThis closes #19732.,5
[FLINK-28095][oss] Replace commons-io IOUtils dependency,2
[FLINK-28007][bugfix/connectors] Migrated Kinesis Firehose & Streams sink tests to using synchronous http clients..,1
[FLINK-22920][formats] Fix guava version conflict between calcite and hadoop component. (#19965),5
[FLINK-20765][table-planner] Fix ScalarOperatorGens doesn't set proper nullability for result type of generated expressionsThis closes #19851,1
"[FLINK-28060][Connector/Kafka] Updated Kafka Clients to 3.1.1 to resolve the issue where Flink is unable to commit its offset back to Kafka in case of Kafka Broker becoming unavailable. This should be resolved when the broker comes back up, but due to KAFKA-13563 that doesn't work. Since that fix has only become available with Kafka Clients 3.1.1, this commit updates the Kafka Clients dependency from 2.8.4 to 3.1.1.No interfaces needed to be adjusted.It was necessary to change some of our Bash e2e tests since they still relied on the Zookeeper parameter which has been removed in this version.The other necessary change was adjusting the KafkaConsumerTestBase class since the level of exception is changed in the new Kafka Clients so exception.getCause().getMessage()  throws an NPE in the test case.",3
[FLINK-28114][python] Fix the issue that the Python client interpreter could not point to an archive file in distributed file system,5
[FLINK-27523][runtime] Runtime supports producing and consuming cached intermediate resultsThis closes #19653.,1
[FLINK-28107][python][connector/elasticsearch] Support id of document is nullThis closes #20002.,2
[FLINK-27861][table] Introduce ResourceManager to manage JAR resources (#19859),2
[FLINK-27159][table] Support firstValue/lastValue in the Table APIThis closes #19958.,1
[hotfix] Rework GlobFilePathFilterTest to be based on AssertJ & JUnit5,3
[FLINK-28105][Tests] test the copied object in GlobFilePathFilterTest#testGlobFilterSerializable,3
[FLINK-28002][python] Fixes the issue that add_jars doesn't work on JDK11This closes #19947.,1
[FLINK-28147][Python] Update httplib2 to at least 0.19.0 to address CVE-2021-21240,1
[FLINK-26762][network] Add the overdraft buffer in ResultPartition,1
[hotfix] Removed foul language. This closes #18722[hotfix] Removed foul language. This closes #18722,4
"[FLINK-28077][checkpoint] Allow buffers to be discarded asynchronouslyThe dataFuture may never be completed, so waiting for that might cause the task to get stuck.We now chain the cleanup to the dataFuture instead; if it is complete it will run immediately, otherwise it _may_ run at a later point if the future ever completes.The latter is a safeguard against potential buffer leaks.",1
[FLINK-28044][runtime][security] Make hadoop filesystems configuration available to all deployment targetsThis closes #19953.,1
[FLINK-26762][docs] Document overdraft buffers,2
fixup! [FLINK-26762][docs] Document overdraft buffers,2
fixup! fixup! [FLINK-26762][docs] Document overdraft buffers,2
[hotfix][tests] Cleanup StopWithSavepointTest,3
[FLINK-27972][coordination] Wait until savepoint operation is complete,2
[FLINK-27972][tests] Forbid multiple state transitions,3
[FLINK-27667][yarn-tests] Stabilize flaky YARN integration tests,3
[hotfix][docs] Fix the inaccessible documentation link,2
[hotfix][ci] Update libssl download link,2
[hotfix][docs] Fix the Intellij key nouns.,0
[hotfix][legal] Correct module name in NOTICE,0
[hotfix][javadoc] Misprint in javadoc at QuadFunction.java`@oaram` => `@param`,2
[FLINK-28112][filesystems] Fix error message when directly supported file system not able to be handled,0
"[FLINK-28196][build] Rename hadoop.version propertyPrevent conflicts with the hadoop.version property in the Hadoop parent pom, when using Maven 3.8.5+.",1
[FLINK-28194][python] Remove avro sql jar workaround (#20045),1
[FLINK-27766][sql-gateway] Introduce the basic components for the SqlGatewayService,2
[FLINK-27766][sql-gateway] Introduce the OperationManager for the SqlGatewayService,2
[FLINK-27865][docs] Add example for configuring SASL and SSL in Kafka DataStream and SQL connector (#19904),5
[FLINK-27926][Docs] Translating the `Upgrading Applications and Flink versions` page to Chiinese,2
[hotfix][table-api-java][javadoc]fix and unified the example JavaDoc for most DSL methods of Table class,2
"[FLINK-27290][docs-zh] Translate the ""Data Type"" section of ""Data Types"" in to Chinese.Co-authored-by: LuNing Wang <rsl4@foxmail.com>",5
[FLINK-28175][ci] Improve license checker output,1
[FLINK-27466][jdbc][docs] Clarify metaspace leak fix,0
"[hotfix][tests] Clarify interfaceThese 2 methods were never used via the gateway, but are called directly on the instance.This was misleading because I couldn't figure out why the serialization didn't fail for these methods.",0
[FLINK-27933][coordination] OperationResult is serializable,2
"[FLINK-27933][coordination] Fix/document RPC serializability violations- allow tests to opt-out of serializability force- never force serialization in AkkaRpcActorOversizedResponseMessageTest, because it affected the payload size- DispatcherTest no longer relies on retrieving the same object instance via RPC- ResourceManager#requestTaskExecutorThreadInfoGateway is just not serializable; see FLINK-27954- ClassLoaderITCase wrongly assumed that serialization occurs",0
[FLINK-27933][coordination][tests] Force serialization applies to return value,1
[FLINK-28133][runtime] Rework DefaultScheduler to directly deploy executionsThis closes #20039.,1
[FLINK-28193][runtime] Enable to identify whether a job vertex contains source/sink operatorsThis closes #20043.,1
[FLINK-27794][connectors/jdbc] Fix the wrong primary key for MysqlCatalog when there are tables with same name in different databasesThis closes ##20025.,5
[FLINK-28239][table] Add commons-math3 to owner classpath,1
[FLINK-28169] Disabling Flaky  GlueSchemaRegistryJsonKinesisITCase test to unblock build CI,3
[FLINK-28226][python] Limit grpcio<1.47 (#20058),2
"[FLINK-16078] [docs-zh] Translate ""Tuning Checkpoints and Large State"".Co-authored-by: Jun He <xuehaijuxian@gmail.com>This closes #19503.",2
[FLINK-28195][python] Annotate Python3.6 as deprecated in PyFlink 1.16This closes #20078.,2
"[hotfix][runtime] Cleanup for the temporary fix of FLINK-13063 which is completely solved by FLINK-162191. In FLINK-13063 the chaining strategy of AsyncWaitOperatorFactory is HEAD, AsyncWaitOperatorTest#addAsyncOperatorLegacyChained is for manually setting it to ALWAYSand now it is no long needed since FLINK-16219 change the chaining strategy of AsyncWaitOperatorFactory to ALWAYS.2. test case rename: testStateSnapshotAndRestoreWithObjectReused -> testObjectReusedbecause the case does not contain the snapshot and restore logic in it.This closes #19961.",2
[FLINK-26762][docs-zh] Translate the doc of overdraft buffers,2
[FLINK-25097][table-planner] Fix bug in inner join when the filter condition is boolean typeThis closes #19579,0
[FLINK-28258][runtime] Introduce ExecutionHistory to host historical executions for each execution vertexThis closes #20080.,2
[FLINK-28195][python] Fix the build wheelsThis closes #20085.,0
[FLINK-28217] Bumps [mysql-connector-java](https://github.com/mysql/mysql-connector-j) from 8.0.27 to 8.0.29.Flink doesn't bundle this dependency but only uses it for testing. Bumping this dependency will also address false positives for CVE-2022-21363 (direct vulnerability) and CVE-2021-22569 (vulnerability from included dependency).,1
[FLINK-28036][hive] HiveInspectors should use correct writable type to create ConstantObjectInspectorThis closes #19949,1
[hotfix][docs] Add a chinese doc of first_value/last_value in the Table API (#20088),2
[FLINK-27304][hive] Calcite's varbinary type should be converted to Hive's binary type.This closes #19562,2
[FLINK-27392][cep] CEP Pattern supports definition of the maximum time gap between eventsThis closes #20029.,5
[FLINK-23995][hive] Fix bug of table name parser when using Hive dialectThis closes #16999,1
[FLINK-27116][hive] Support read Hive table partitioned by decimal typeThis closes #19388,1
[FLINK-28173][formats] Specify guava version explicitly in flink-orc and flink-parquet.,2
"[hotfix][docs] Remove redundant ""."" from sample code",4
[FLINK-28263][TPCDS][Tests] Clean-up generated data folder by TPCDS test,3
[FLINK-28092][table] Support ASCII and CHR built-in function in the Table APIThis closes #19988.,1
[FLINK-27964][python] Support Cassandra connector in Python DataStream APIThis closes #19945.,5
[FLINK-19869][connectors/jdbc] Add support for postgres UUID type,1
"[FLINK-28043][formats][parquet] Fix ""Invalid lambda deserialization"" in AvroParquetReadersThis closes #19956.",0
[hotfix] Fix the generic of RecordWriter,0
[FLINK-27789][network] Disable overdraft buffer for LegacySource,2
"[FLINK-28269][Kubernetes] Install cri-dockerd and crictl so that we can continue to use Kubernetes 1.24+ and the `none` driver, since Kubernetes 1.24 has dropped support for Dockershim.",2
[FLINK-27586][python] Support non-keyed co-broadcast processing in PyFlinkThis closes #19878.,2
[FLINK-28080][runtime] Introduce MutableURLClassLoader as parent class of FlinkUserClassLoader and SafetyNetWrapperClassLoader,2
[FLINK-28047][api] Deprecate StreamExecutionEnvironment#readFile()/readTextFile() methods,2
[FLINK-28259][flink-parquet] Bump protoc version to 3.21.2 for proper ARM support,1
[FLINK-28213][runtime] StreamExecutionEnvironment configure method support override pipeline.jars optionThis closes #20057.,1
[hotfix][docs] Remove a unuseful space,1
[hotfix] Add Extension META-INF for flink-runtime module to support junit5.,3
[FLINK-27906][runtime] Introduce HsDataIndex.This closes #20031,5
[FLINK-28290][sql-gateway] Set lastAccessTime when create the Session Object (#20107),1
[FLINK-27031][runtime] Assign even empty old state to the task if the upstream has output states since the task should be prepared to filter these old incoming states from upstream,2
"Revert ""[FLINK-26079][state/changelog] Disallow recovery from non-changelog checkpoints""This reverts commit 6fc4bad2",4
[FLINK-25872][state] Support restore from non-changelog checkpoint with changelog enabled in CLAIM mode,0
[FLINK-28182][python][avro] Support Avro generic record decoder in PyFlinkThis closes #20040.,2
[FLINK-26361][hive] Create LogicalFilter with CorrelationId to fix failed to rewrite subquery in hive dialect (#18920),0
[hotfix][rest] Remove the stale items in rest_v1_dispatcher,4
[FLINK-28308] Introduce metrics of the accumulated time that a running task is busy / idle / back-pressuredThis closes #20110.,1
[FLINK-28309][rest] Introduce metrics of the duration that a task stays in each statusThis closes #20111.,2
[FLINK-28135][runtime] Introduce SlowTaskDetectorThis closes #20054.,2
[FLINK-28136][runtime] Implement ExecutionTimeBasedSlowTaskDetectorThis closes #20072.,2
"[hotfix][runtime][tests] Migrate TaskManagerLocationTest, TaskExecutorToResourceManagerConnectionTest and TaskManagerRunnerConfigurationTest to JUnit5",3
[FLINK-28142][runtime] Enrich TaskManagerLocation with node information,5
[FLINK-28142][runtime] Enrich TaskExecutorRegistration with node informationThis closes #20056.,5
[FLINK-28323][python][kafka] Support KafkaSource in PyFlinkThis closes #20113.,2
[FLINK-28288][table][python] Support decode and encode in Table API (#20098),1
[FLINK-28140][python][docs] Improve the documentation by adding Python examples in DataStream API Integration pageThis closes #20121.,1
"[FLINK-28169][e2e-test/glue,kinesis] Re-enabled integration test that was failing due a shaded dependency test-jar requiring a transitive shaded test-jar being satisfied by a later unshaded dependency test-jar, changed so that unshaded dependency test-jar is loaded earlier in pom",3
[FLINK-28134][runtime] Introduce SpeculativeExecutionJobVertex and SpeculativeExecutionVertexThis closes #20082.,2
[FLINK-28134][runtime] Rework TaskDeploymentDescriptorFactory to accept an execution to deployThis helps to decouple the task deployment from ExecutionVertex#getCurrentExecutionAttempt().,1
"[FLINK-28134][runtime] Wait for all the executions to be terminated before finishing a jobIn speculative execution, it is possible that when all the execution vertices finish, some executions are still running. We need to waiting for all them to be terminated(canceled) before conducting job finalization.",1
[FLINK-28271][runtime] Add config options for speculative schedulerThis closes #20087.,5
[FLINK-28143][runtime] Introduce BlockListTracker.,2
[FLINK-28143][runtime] Introduce BlocklistHandler.This closes #20079.,0
[FLINK-28238][sql-gateway] Fix unstable testCancelOperationAndFetchResultInParallel (#20063),3
[FLINK-28298][table][python] Support left and right in Table API (#20104),1
[FLINK-28310][rest] Introduce aggregating task metricsWe add AggregatedTaskDetailsInfo to JobVertexTaskManagersHandler and JobVertexDetailsHandlerThis closes #20123.,0
[FLINK-28336][python][format] Support parquet-avro format DataStream APIThis closes #20124.,5
[FLINK-38340][python][tests] Support using system conda env for testingThis closes #20125.,3
"[FLINK-19358][runtime] Make the job id distinct in application mode when HA is enabled.Previously, the job id will be set to zero in application mode when HA is enabled and the job id is not configured by user.This commit makes the job id distinct across different jobs in such case, which allows HistoryServer to distinguish it.This closes #20042.",1
[FLINK-28329][Tests] Output the top 15 directories in terms of used disk space,1
[FLINK-27822][docs-zh] Translate the doc of checkpoint/savepoint guarantees,2
[FLINK-28354][table][python] Support instr and locate in Table API (#20132),1
"[FLINK-27854][tests] Add support for FlinkContainers to work with both existing Docker images and flink-dist builds- Refactors FlinkContainers initialization prpocess by introducing centralized configuration holders (FlinkContainersSettings and TestContainersSettings).- Previously FlinkContainers workflow was based on always recreating images from local 'flink-dist'. This contribution adds support for external Docker images (required for externalized connectors repositories, where 'flink-dist' is not present).",2
[FLINK-28240][network] Fix the bug that NetworkBufferPool#getRequestedSegmentsUsage may throw ArithmeticException.,1
[FLINK-28222][sql] Remove unused format dependencies,1
[FLINK-28222][csv] Add flink-sql-csv module,2
[FLINK-28222][json] Add flink-sql-json module,5
[FLINK-26793][documentation] Add recommendations about the write timeout to the javadoc of Cassandra sink and output format.,2
[FLINK-25231][python]Update Pyflink to use the new type systemThis closes #19140.,5
[hotfix][doc] fix code error compared to explanation in filesystem.md. This closes #20094,5
[FLINK-25908][runtime][security] Add HadoopFSDelegationTokenProvider,1
[FLINK-27199][Connector/Pulsar] Bump the pulsar-client-all to latest 2.10.0.,3
"[FLINK-27199][Connector/Pulsar] Pulsar 2.10.0 deprecated the queue length, add new memory-based options.",1
[FLINK-27199][Connector/Pulsar] Move mocked Pulsar runtime to new local memory based metastore. Drop embedded Pulsar runtime. Add a bootstrap script for Pulsar docker runtime.,1
[FLINK-28355][python][e2e] Clean up python environment after e2e tests (#20156)* [FLINK-28355][python][e2e] Clean up python environment after e2e tests. This closes #20156,3
[FLINK-27806][table] Support binary & varbinary types for datagen connectorThis closes #19827.,5
[FLINK-28322][table-api] DataStreamScan(Sink)Provider's new method is not compatibleThis closes #20119,1
[FLINK-28313][rest] Add history server flag to DashboardConfigurationThis closes #20142.,5
[FLINK-28274][runtime] set the max parallelism of ContinuousFileMonitoringFunction to 1,2
[FLINK-26323][tests] Allow CREATED state,1
[FLINK-26979][core] Make Transformation#getNewNodeId() thread-safe,1
[FLINK-26979][core][tests] Add thread-safety test,3
[FLINK-15855][hive] Use the new type inference for Hive UDAFThis closes #19920,5
[FLINK-28404][tests] Invert isAssignableFrom order,3
[hotfix][rest] Rename ClusterConfigurationInfo to ConfigurationInfo,5
[FLINK-28311][rest] Introduce JobManagerEnvironmentHandler,0
[FLINK-28311][rest] Introduce JobManagerJobConfigurationHandler,5
[FLINK-28311][rest] Introduce JobManagerJobEnvironmentHandlerThis closes #20150.,0
[FLINK-26600][tests] Wait with savepoint until job is running,1
[hotfix][runtime] Fix typos in BlocklistContext,2
[FLINK-28391][runtime] Fix unstable test DefaultBlocklistHandlerTest#testRemoveTimeoutNodesThis closes #20169.,3
[FLINK-28392][runtime] DefaultExecutionDeployer avoid retrieving executions from ExecutionGraph#currentExecutionsThis closes #20178.,2
[FLINK-28369][table][python] Support PARSE_URL in Table API (#20146),1
[FLINK-27767][sql-gateway] Introduce Endpoint API and utils (#19849),2
[FLINK-28393][python][avro] Support AvroInputFormat in PyFlink DataStream APIThis closes #20163.,5
[FLINK-28312][rest] Introduce REST APIs for log URL retrievalThis closes #20179.,2
[FLINK-28176][python] Refactor the test in test_connectors.pyThis closes #20191.,3
[FLINK-28334][table-planner] Fix PushProjectIntoTableSourceScanRule: covers the case when table source SupportsReadingMetadata and not SupportsProjectionPushDownThis closes #20118,1
[FLINK-26813[sql-parser] Supports ADD/MODIFY column/watermark/constraint syntax for ALTER TABLE (#19193),1
[hotfix] Remove unused methods in StreamGraph,1
"[FLINK-28357][datastream] Disallow null elements in StreamNode#typeSerializersInOtherwise tasks can not correctly determine number of inputs. This was causing anissue where restored as finished OneInputStreamTask was waiting for MAX_WATERMARKfrom two inputs, where the second one was null.The problem was that {{FinishedOnRestoreInput#FinishedOnRestoreInput}} was beingconstructed with wrong number of inputs, because of some accidental {{null}}passed from the {{StreamGraphGenerator}}.",4
[FLINK-28015][table][python] Support FROM_UNIXTIME in Table API (#20161),1
[FLINK-28140][python][docs] Improve the documentation by adding Python examples in Time Attributes page (#20194),1
[FLINK-27244][hive] Support read sub-directories in partition directory with Hive tablesThis closes #19482,1
[FLINK-27244][hive] Improve documentation of reading partition with subdirectories for Hive tables,2
[FLINK-26414][hive] Hive dialect supports macro (#19561),1
[FLINK-28201][ci] Generalize utils around dependency plugin,2
[FLINK-28439][table][python] Support SUBSTR and REGEXP built-in function in Table API (#20201),1
[FLINK-28388][docs][tests] Fix documentation buildThis closes #20189.,2
"[FLINK-28247][hive] fix ""no any field presented in group by"" exception when over window contains grouping function in Hive dialectThis closes #20071.",1
[FLINK-28413][python][parquet] Support ParquetColumnarRowInputFormat in PyFlinkThis closes #20198.,2
[FLINK-28409][tests] Move FlinkContainerTestEnvironment and dependendencies into flink-connector-test-utils,3
[FLINK-25720][python] Support Python UDTF in Thread ModeThis closes #20175.,1
[FLINK-28230][ci] Unify Dependency class,2
[hotfix] Migrate BufferReaderWriterUtilTest to junit5 and assertJ.,3
[FLINK-27907][runtime] Introduce HsSubpartitionFileReader and HsResultPartitionReadScheduler.,2
[FLINK-27907] Introduce HsMemoryDataSpiller.This closes #19960,5
[FLINK-28426][python] Supports m1 wheel package in PyFlinkThis closes #20190.,2
[hotfix][Runtime/Configuration] Fix typo in ProcessMemoryUtils Class,2
[FLINK-27556][state] Inline state handle id generation...  to avoid unnecessary overhead when it's not used.,1
[FLINK-28172][changelog] Scatter dstl files into separate directories by job id,2
[FLINK-28454][kafka][docs] Fix the wrong timestamp unit of KafkaSource,0
[hotfix][docs] Update code formatting instructions for newer IntelliJ versions,1
[FLINK-26675][runtime] Parallelized heavy serialization in StreamingJobGraphGeneratorThis closes #19108.,2
[FLINK-28466][tests] Bump assertj to 3.23.1,3
[FLINK-25315][tests] Introduce extensions and utils to help the Junit5 migrationCo-authored-by: Hang Ruan <ruanhang1993@hotmail.com>This closes #20145.,3
[hotfix] Fix typo,2
[FLINK-28379][tests] Prevent mocked UGI bleeding into other tests,3
[hotfix][runtime][tests] Migrate DeclarativeSlotPoolServiceTest and JobMasterTest to JUnit5,3
"[FLINK-28144][runtime] Introduce BlocklistDeclarativeSlotPool.BlocklistDeclarativeSlotPool is an implementation of DeclarativeSlotPool that help to support blocklist mechanism, it will avoid allocating slots that located on blocked nodes.",1
[FLINK-28144][runtime] Introduce SlotPoolService#releaseFreeSlotsOnTaskManager to release free slots eagerly when blocking nodes,2
[FLINK-28144][runtime] Introduce blocklist handler factory and a no-op blocklist handler.,0
[FLINK-28144][runtime] Let JobMaster support blocklist.This closes #20153.,1
[hotfix] Migrate failure handling tests to JUnit5,3
[FLINK-28402][runtime] Create FailureHandlingResultSnapshot with the truly failed executionThis closes #20221.,0
[FLINK-26621][tests] Close delegate keyed state backend,3
"[hotfix][docs] Fix formatting in ""Standalone"" Chinese doc (#20213)",2
"[FLINK-27205][docs-zh] Translate ""Concepts -> Glossary"" page into Chinese.",2
[FLINK-28314][runtime-web] make modules depend on a common config abstraction,5
[FLINK-28314][runtime-web] add cluster configuration tab in completed job detail pageThis closes #20212,1
[FLINK-24660][connector/kafka] allow setting KafkaSubscriber in KafkaSourceBuilderThis closes #19366,1
[FLINK-27768][sql-gateway] Allow executing sql for the SqlGatewayService (#19846),1
[FLINK-28286][state] move 'enablechangelog' constant to flink-core module,2
[FLINK-27989][table-planner] Csv format supports reporting statisticsThis closes #20007,1
[FLINK-27884][connectors] Move OutputFormatBase to flink-core,2
[hotfix] Remove the initialCapacity param from the constructor of DualKeyLinkedMapThe initial capacity of a map does not make much sense and is not necessarily needed currently.,1
"[hotfix][tests] Merge DefaultSchedulerBuilder and AdaptiveBatchSchedulerBuilderThe extending AdaptiveBatchSchedulerBuilder is in a good shape, which requires hack logics to create AdaptiveBatchScheduler. Merging them can make it simpler to create different schedulers.",1
[FLINK-28137][runtime] Introduce SpeculativeSchedulerThis closes #20222.,2
[hotfix] Migrate SlotSharingExecutionSlotAllocatorTest to JUnit5,3
[FLINK-28137][runtime] Enable SimpleExecutionSlotAllocator to do batch slot request timeout check,0
[FLINK-27376][table] Support current_database built-in function (#19218),1
[FLINK-28525][hive] Fix unstable test for HiveDialectITCase#testTableWithSubDirsInPartitionDirThis closes #20259.,3
[FLINK-27703][core] Extend timeout and add logs for FileChannelManagerImplTestThis closes #20239.,3
[FLINK-24786][state] Introduce and expose RocksDB statistics as metrics,5
[FLINK-28536][table-planner] Adds an internal postOptimize method for physical dag processingThis closes #20262,2
[FLINK-28486][docs-zh] Flink FileSystem SQL Connector Doc is not rightThis closes #20255,2
[FLINK-28457][runtime] Introduce JobStatusHook to allow users to listen for the job status changesThis closes #20223.,4
[FLINK-28315][runtime-web] introduce aggregate stats in tables of the subtasks and taskmanagersThis closes #20260,2
[FLINK-28250][Connector/Kafka] Fix exactly-once Kafka Sink out of memory,0
[FLINK-27990][table-planner] Parquet format supports reporting statisticsThis closes #20008,1
[FLINK-28075][table-planner] get statistics for partitioned table even without partition pruningThis closes #20248,1
[FLINK-28508][table][python] Support SPLIT_INDEX and STR_TO_MAP built-in function in Table API (#20250),1
[FLINK-28546][python][release] Add the release logic for py39 and m1 wheel packageThis closes #20274.,1
[FLINK-28053][sql-gateway] Introduce the operation lock to execute operation in sequence (#20149),2
[FLINK-28316][runtime-web] add external JM and TM log links under history serverThis closes #20270,2
[FLINK-27991][table-planner] ORC format supports reporting statisticsThis closes #20009,1
[FLINK-27623][table] Add 'table.exec.async-lookup.output-mode' to ExecutionConfigOptionsThis closes #19759,5
[hotfix][docs-zh] Add missing the working_directory.md file to the standalone part.,2
[hotfix][docs-zh]Fix Chinese document format errors.,0
[FLINK-27878][datastream] Add Retry Support For Async I/O In DataStream APIThis closes #19983.,5
[FLINK-28464][python][csv] Support CsvReaderFormatThis closes #20220.,1
[FLINK-27587][python] Support keyed co-broadcast processingThis closes #20144.,1
[FLINK-28558][history] Improve log-url configuration usability.This closes #20280,5
[FLINK-28509][table][python] Support REVERSE built-in function in Table API (#20278),1
[FLINK-28140][python][docs] Improve the documentation by adding Python examples in several pagesThis closes #20290.,1
[FLINK-28198][connectors][cassandra] raise driver timeouts per session request and raise it higher than cluster side timetouts (#20184)* [FLINK-28198][connectors][cassandra] Raise driver timeouts per session request and raise it higher than cluster side timeouts. This closes #20184,2
[FLINK-27905] Introduce HsSpillingStrategy interface and selectiveSpillingStrategyallSpillingStrategy implementation.This closes #20100,2
[FLINK-27162][runtime] Trigger non-periodic checkpoint in 'timer' threadThis closes #19864.,2
[FLINK-28307][doc] Update history server docs w.r.t. FLIP-241.This closes #20297,2
"[FLINK-27013][hive] Hive dialect supports IS_DISTINCT_FROM (i.e. ""<=>"" operator)This closes #19315",1
[FLINK-28490][sql-parser] Introduce `ANALYZE TABLE` syntax in sql parserThis closes #20242,2
[hotfix][table-runtime] Avoid NPE for SliceAssigner and improve error messageThis closes #20302,1
[hotfix][table] Remove unnecessary reset on underlying collector of TableFunctionCollector (#20309),1
[FLINK-28544][python][e2e] Clean up python environment after e2e testsThis closes #20301.,3
[hotfic][doc] Fix JavaDoc of chapter ETL. This closes #20077Co-authored-by: MartijnVisser <martijn@2symbols.com>,2
[hotfix][runtime] Strengthen SpeculativeScheduler and its testsStablizes tests and better exposes exceptions for troubleshooting.,1
[FLINK-28612][runtime] SpeculativeScheduler cancels pending slot allocation after canceling pending executionsThis closes #20312.,2
"[FLINK-28089][hive] Hive dialect support ""TABLESAMPLE (N rows)"" (#19989)",1
[FLINK-27659][table-planner] Support to use jar that is registered by 'CREATE FUNCTION USING JAR' syntaxThis closes #20001,1
"[FLINK-28452][python] Support ""Reduce"" and ""aggregate"" operations of ""window_all"" in Python datastream APIThis closes #20219.",5
[FLINK-28446][runtime] Expose more information in PartitionDescriptor to support more optimized Shuffle ServiceThis closes #20200.,1
[FLINK-28547][runtime] Add IT cases for SpeculativeScheduler.This closes #20271.,1
[FLINK-28376][network] Restrict the number of threads for sort-shuffle data readThis closes #20308.,5
[FLINK-28608][runtime][security]Make Hadoop FS token renewer configurable,5
[FLINK-27996][hive] Hive dialect supports INTERVAL typesThis closes #19955,1
[hotfix][runtime] Remove com.sun.istack.NotNull from testutils,3
[FLINK-28556][refactor] Extract header fields of Buffer into a BufferHeader class for blocking shuffle file IOThis closes #20328.,2
[FLINK-28377][network] Decrease the memory size per request for sort-shuffle data read from 8M to 4MThis closes #20325.,5
[FLINK-28491][table-planner] Introduce HyperLogLogPlusPlusThis closes #20243,2
[FLINK-28491][table-planner] Refactor AggFunctionTestBase: Allows its input type and its output type to be differentThis closes #20243,1
[FLINK-28491][table-planner] Introduce APPROX_COUNT_DISTINCT aggregate function for batch sqlThis closes #20243,1
[FLINK-28551][network] Store the number of bytes instead of the number of buffers in index entry for sort-shuffleThis closes #20326.,1
[hotfix][runtime][tests] Migrates some tests to Junit5,3
[FLINK-28145][runtime] Introduce BlockedTaskManagerChecker into SlotManager to avoid allocating slots that located on blocked nodes.,2
[FLINK-28145][runtime] Let ResourceManagerDriver support filtering out blocked nodes when requesting new TMs from external resource managers,1
[FLINK-28145][runtime] Let ResourceManager support blocklistThis closes #20218.,1
[hotfix] Remove duplicated inherited interfaces of AdaptiveBatchScheduler,4
[FLINK-28138][runtime] Add metric numSlowExecutionVertices for speculative execution,1
[FLINK-28138][runtime] Add metric numEffectiveSpeculativeExecutions for speculative executionThis closes #20321.,1
[FLINK-27188][Connector][StreamingFileSink] Mark StreamingFileSink as deprecated since it has been replaced by FileSink. This includes replacing or removing references to StreamingFileSink in the documentation,2
[FLINK-27931][sql-gateway] Introduce the SqlGateway to assemble all componentsThis closes #19894,2
[hotfix] Migrate SourceCoordinator tests to JUnit5,3
[FLINK-28586][runtime] Introduce method ExecutionVertex#getCurrentExecution(int attemptNumber),1
[FLINK-28586][runtime] Let SourceCoordinator context know whether `supportsConcurrentExecutionAttempts`,1
[FLINK-28586][runtime] Refactor some OperatorCoordinator methods to be aware of execution attempts,1
[FLINK-28586][runtime] Improve SourceCoordinator and SourceCoordinatorContext to support execution attempt level split requests and eventsThis closes #20299.,1
"[FLINK-28586][runtime] Ignore compatibility warnings for SplitEnumeratorContext#registeredReadersOfAttempts() and SplitEnumeratorContext#sendEventToSourceReader(int,int,SourceEvent)The change is source-compatible.",4
[FLINK-28146][runtime] Sync blocklist information between JobMaster & ResourceManager.This closes #20264.,5
"[FLINK-28640][runtime] Let BlocklistDeclarativeSlotPool accept duplicate slot offersThe BlocklistDeclarativeSlotPool should accept a duplicate (already accepted) slot, even if it's from a currently blocked task manager. Because the slot may already be assigned to an execution, rejecting it will cause a task failover.This closes #20341.",0
[FLINK-26047][yarn] Support remote usrlib in HDFS for YARN deployment,1
[FLINK-28451][table][hive] Use UserCodeClassloader instead of the current thread's classloader to load functionThis closes #20211,1
[FLINK-28451][hive] Borrow Kryo from SerializationUtilities in HiveFunctionWrapperThis closes #20211,1
[FLINK-27618][sql] Flink SQL supports CUME_DIST function (#19727),1
[FLINK-28150][sql-gateway][hive] Introduce the hiveserver2 endpoint and factoryThis closes #20101,2
[FLINK-28090][python] Support attachAsDataStream in Python Table APIThis closes #19987.,5
"[FLINK-23528][datastream] Let CollectSinkOperator publish results in #close.DataStream#executeAndCollect expects the CollectSinkOperator to register the accumulator at the end of the application or fails with some exception.However, a stop-with-savepoint without drain would not trigger CollectSinkOperator#finish and thus skip the registration.",5
"[FLINK-23528][connectors/kinesis] Use proper mock of ExecutorService in KinesisDataFetcherTest.Mockito makes it so much harder to debug tests. Here, we replace Mockito with a small test class that emulates the previously dispersed functionality in a simpler way.",1
[FLINK-23528][connectors/kinesis] Gracefully shutdown  shard consumer to avoid InterruptionExceptions.,2
[FLINK-23528][connectors/kinesis] Reenable FlinkKinesisITCase and rewrite stopWithSavepoint.,2
[FLINK-23528][connectors/kinesis]Graceful shutdown of Kinesis Consumer in EFO mode,2
[FLINK-24713][Runtime/Coordination] Postpone resourceManager serving after the recovery phase has finishedThis closes #20256,5
[FLINK-28585][runtime] Ensure all the concurrent executions of SpeculativeExecutionVertex to share the same input splitsThis allows speculative execution for sources tasks from jobs with InputFormatSource.This closes #20322.,1
[hotfix] Introduce BufferIndexAndChannel and make HsSpillingStrategy using it instead of BufferWithIdentity.,1
[hotfix] HsSpillingStrategy.Decision return Map group by subpartition id instead of List,0
[hotfix] HsMemoryDataSpiller's spilling thread will trigger fatal error when an exception is encountered.,0
[FLINK-27904][runtime] Introduce HsMemoryDataManager to manage in-memory data of hybrid shuffle modeThis closes #20293,5
[FLINK-28353][k8s] Exclude unschedulable nodes when generating the node portThis closes #20134.,2
[FLINK-28549][python] Support DataStream PythonProcessOperator in Thread ModeThis closes #20276.,1
[FLINK-28660][runtime] Simplify logs of blocklistThis closes #20349.,2
[FLINK-28610][runtime] Enable speculative execution for sourcesThis closes #20345.,0
[FLINK-28636][tests] Add utility for checking POJO compliance,1
[FLINK-28628][table] Introduce Operation Execution Plugin (#20247),2
"[FLINK-28448] Fix bugs in BoundedDataTestBase when enable compression1. If enable compression, intermediateBuffer must reduce reference count after write it to file.2. The logic of using the compressed buffer size to calculate the amount of data is wrong.This closes #20203.",0
"[FLINK-28448] BoundedDataTestBase writes and reads long instead of integer value, makes it easier to compress data for default lz4 compressorThis closes #20203.",5
[FLINK-27579][client] Make the client.timeout and parallelism.default could take effect in CLI frontendThis closes #19772.,1
[FLINK-28267][test] Disable KafkaSourceLegacyITCase#testBrokerFailure,3
[FLINK-28624][csv] Accept mapper/schema factories,2
[FLINK-28644][datastream] Add DataStream#collectAsync,5
[FLINK-28644][tests] Migrate state-processing-api to new collectAsync(),1
[FLINK-28680] Revisit 'free_disk_space.sh' to free up more space,2
[FLINK-26853][state] Update state serializer in StateMap when metaInfo changed,4
[FLINK-27692][changelog] Refactor ChangelogSnapshotState,4
[FLINK-27692][changelog] Support local recovery for materialized part,1
[FLINK-28416][table] Add (Async)LookupFunction and providers in replace of (Async)TableFunction as the API for lookup table (#20177),1
[hotfix][runtime] Fix the logger of BlocklistDeclarativeSlotPool,2
[FLINK-27536][Connectors / Common] Rename method parameter in AsyncSinkWriter,2
[FLINK-27536][Connectors / Common] Rename method parameter in AsyncSinkWriter,2
[FLINK-28510][python][connector] Support using new KafkaSinkThis closes #20263.,1
[FLINK-28577][web] Fix the null error of reading checkpointed_size in checkpoint tab,0
[FLINK-18202][protobuf] Introduce protobuf formatThis closes #14376,2
[FLINK-28475][connector/kafka] Fix Kafka source could not stop with stopping offset = 0Co-authored-by: Mason Chen <mas.chen@berkeley.edu>This closes #20234,1
[FLINK-28698][runtime-web] fix order of aggregate durations to follow task state transitions,0
[FLINK-28698][runtime-web] fix order of subtask duration badges to follow task status transitionsThis closes #20372,0
[FLINK-28523][tests] Increase Zookeeper session timeouts,1
[FLINK-28634][json] Add simple JsonSerDeSchema,5
[FLINK-28634][json] Deprecate JsonNodeDeserializationSchemaSubsumed by more general 'JsonDeserializationSchema'.,5
"[FLINK-28152][sql-gateway][hive] Introduce option ""thrift.host"" for HiveServer2 Endpoint and improve codes",1
[FLINK-28152][sql-gateway] Simplify SessionHandle and OperationHandle,0
[FLINK-28152][sql-gateway][hive] Support GetOperationStatus and GetResultSetMetadata for HiveServer2Endpoint,5
[FLINK-28152][sql-gateway][hive] Allow executing statement and fetching results for the HiveServer2Endpoint,1
[FLINK-27384][hive] Fix the modified partitions are missed in temporal table with create-time modeThis closes #20376.,1
[FLINK-28602][state/changelog] Close stream of StateChangeFsUploader normally while enabling compression,0
[FLINK-25735][content.zh] Chinese Translation - Add documentation for KDS Async Sink.,2
[FLINK-28463][sql-parser] Supports CREATE TABLE AS SELECT syntax (#20252),1
[FLINK-28679][hive] HiveServer2 Endpoint supports to build with Hive3 (#20358),1
[FLINK-28559][python] Support DataStream PythonKeyedProcessOperator in Thread ModeThis closes #20375.,1
[FLINK-28519][network] Fix the bug that SortMergeResultPartitionReadScheduler may not read data sequentiallyThis closes #20320.,5
[FLINK-28471][docs-zh] Translate hive_read_write.md into ChineseThis closes #20227,1
[FLINK-28707][table] Introduce SupportsDynamicFilteringThis closes #20384,1
[FLINK-28140][python][docs] Improve the documentation connector pages and metrics pagesThis closes #20385.,2
[FLINK-25142][hive] Fix user-defined hive UDTF initialize exception in hive dialectThis closes #19400,5
[FLINK-25142][hive] (followups) Fix user-defined hive UDTF initialize exception in hive dialectThis closes #19400,5
[FLINK-27387][hive] Hive dialect supports multi-insert statement (#19647),1
"[FLINK-26410][hive] Hive dialect supports ""transform using 'xxx'""This closes #19818",1
"[FLINK-26412][hive] Hive dialect supports ""CREATE FUNCTION ... USING JAR"" statementThis closes #20251",1
[FLINK-26366][hive] Support INSERT OVERWRITE DIRECTORY statementThis closes #19520,1
[FLINK-28664][python] Support FileSink using Avro GenericRecord bulk writerThis closes #20383.,1
[FLINK-28096][hive] Hive dialect support set variables (#20000),1
"[FLINK-26270][Formats][CSV] Flink SQL write data to kafka by CSV format , whether decimal type was converted to scientific notation. This closes #20127",5
"[FLINK-28748][docs-zh] Translate ""SELECT DISTINCT"" page into Chinese. This closes #20395* [FLINK-28748][docs-zh] Translate ""SELECT DISTINCT"" page into Chinese.",2
[FLINK-24787][docs] Add more details of state latency tracking documentation,2
[hotfix][runtime][tests] Migrates some tests to Junit5,3
[FLINK-28588][rest] Add blocked flag in TaskManagerInfo and TaskManagerDetailsInfo,5
[FLINK-28588][rest] Add blocked task manager count and blocked slot count in ResourceOverview and ClusterOverview,1
[FLINK-28588][rest] Archive all current executions in ArchivedExecutionVertex.,2
[FLINK-28588][rest] MetricStore supports to store and query metrics of multiple execution attempts of a subtask.,1
[FLINK-28588][rest] Acquire information of all current executions in REST handlers if applicableThis closes #20296.,0
[FLINK-28752][python][table-planner] Add the json plan support in Python UDFsThis closes #20398.,1
[hotfix][docs-zh] Fix the formatting of Chinese documents.,2
[FLINK-28495][docs][docs-zh] Fix typos or mistakes of Flink CEP Document. This closes #20272* [FLINK-28495][docs][docs-zh] Fix typos or mistakes of Flink CEP Document in the official website,2
[hotfix] Make HsMemoryDataManager runWithLockMethod private.,1
[hotfix] HsMemoryDataManager spillAsync's callback should assertNoException.,3
[hotfix] Rename HsResultPartitionReadScheduler to HsFileDataManager Rename HsResultPartitionReadScheduler to HsFileDataManager as it plays the same role of FileDataManager mentioned in FLIP.,5
[hotfix] Simplify the logic related to release and fail reader in HsFileDataManager.,5
[FLINK-27908] HsBufferContext ignore repeatedly startSpilling and release instead of checkState.,2
[FLINK-27908] ResultPartition's subclass using setupInternal instead of setup to do initialization work.,1
[FLINK-27908] Extends onResultPartitionClosed to HsSpillingStrategy.,2
"[FLINK-27908] Add lifecycle method to HsFileDataManager, HsMemoryDataManager and HsMemoryDataSpiller.",5
[FLINK-27908] HybridShuffleConfiguration supports set spilling strategy type.,1
[FLINK-27908] Let HsMemoryDataManager can register HsSubpartitionViewInternalOperations and supports notifyDataAvailable.,5
[FLINK-27908] Introduce HsSubpartitionView based on HsDataView and it's implementations.,5
[FLINK-27908] Introduce HsResultPartition,2
[FLINK-27908] ResultPartitionFactory also supports HYBRID type.This closes #20371,1
[FLINK-26542][hive] Hive dialect supports queries with multiple same columns in select (#19017),1
[FLINK-28589][runtime-web] show blocked free slots and blocked tm in overview,2
[FLINK-28589][runtime-web] show blocked badge in tm list and detail pages,2
[hotfix][runtime-web] explicitly markForCheck OnPush dynamic component using injector,1
[FLINK-28589][runtime-web] enable expanded rows of other concurrent attempts for subtasksThis closes #20380.,0
[hotfix][runtime-web] replace loading icon with text to avoid spin animation bottleneck,0
[FLINK-27769][sql-gateway]Adjust the RestAPIVersion and RestfulGateway to adapt a variety of endpoints,2
[FLINK-27769][sql-gateway]Introduce the REST endpoint frameworkThis closes #20236,1
"[hotfix] Migrate CreditBasedPartitionRequestClientHandlerTest, NettyMessageClientSideSerializationTest, SingleInputGateTest and BlockCompressionTest to Junit5/AssertJThis closes #20216.",3
[FLINK-28382][network] Introduce LZO and ZSTD compression based on aircompressor for blocking shuffleThis closes #20216.,2
introduce AvroParquetWriters to support writing generic records to parquet file in Python DataStream APIThis closes #20403.,5
[FLINK-27016][hive] Support access array type in a struct and support access fields in a struct arrayThis clsoes #19283Co-authored-by: Jark Wu <jark@apache.org>,1
[FLINK-24342][table] Add right bracket to filesystem partitioner escape list,5
[FLINK-28759][e2e] Enable speculative execution for in AdaptiveBatchScheduler TPC-DS e2e testsThis closes #20407.,3
"[hotfix][network] Modify the log level of ""Failed to read shuffle data."" to DEBUGThe log was DEBUG level and was changed to ERROR level by mistake. To avoid confusing users, we should change it back to DEBUG.",0
[FLINK-28745][python] Support DataStream PythonCoProcessOperator and PythonKeyedCoProcessOperator in Thread ModeThis closes #20396.,1
[FLINK-25962][avro] Use namespaces for generated records,1
[FLINK-28373][network] Read a full buffer of data per file IO read request for sort-shuffleThis closes #20335.,2
[FLINK-28417][table] Add interfaces for LookupCache and default implementation (#20196),1
[FLINK-28771][runtime] Assign speculative execution attempt with correct CREATED timestampThis closes #20411.,1
[FLINK-28765][docs] Add documentation for protobuf formatThis closes #20408,2
[FLINK-28151][hive] Allow to cancel the Operation for the HiveServer2 Endpoint.This closes #20402,1
[FLINK-27770][sql-gateway] Introduce the script to start/stop/stop-all gateway,2
[FLINK-27770][sql-gateway] Refactor SqlGateway E2E testsThis closes #20174,3
[FLINK-27988][table-planner] Let HiveTableSource extend from SupportStatisticsReportThis closes #20084,1
[FLINK-28011][hive] HiveSource should get partitions in batch instead of getting partition one by oneThis closes #20015,1
[FLINK-28418][table] Add runtime provider interfaces for partial caching lookup (#20414),1
[FLINK-28597][state] Discard initial checkpoints without a delay in common  cases,5
[FLINK-28740][python][format] Support CsvBulkWriterThis closes #20391.,1
[FLINK-27951][Docs] Translate ops/debugging/debugging_classloading.md into Chinese. This closes #20436,0
[FLINK-28776][table-planner] RowTimeMiniBatchAssginerOperator doesn't need separate chain with upstream operator (#20417),1
[FLINK-28791][sql] Add missing jdk.tools exclusion,1
"[FLINK-27292][docs-zh] Translate the ""Data Type Extraction"" section of ""Data Types"" to Chinese. This closes #20316* [FLINK-27292][docs-zh] Translate the ""Data Type Extraction"" section of ""Data Types"" to Chinese",5
[hotfix][sql-gateway]Add RestConfigUtils to test rest endpoint,3
[hotfix][sql-gateway]Add default timeout for AbstractSqlGatewayRestHandler,0
[FLINK-28161][sql-gateway]Introduce the session related API for REST endpointThis closes #20418,2
"[FLINK-28492][table-planner] Support ""ANALYZE TABLE"" executionThis closes #20363",1
[FLINK-28708][table-planner] Introduce planner rules to optimize DPP patternThis closes,2
[FLINK-28212][hive-dialect] Fix IndexOutOfBoundsException when over window SELECT doesn't contain all fields of inputThis closes #20060,0
"[hotfix] Move util to WebFrontedITCaseThis util is a bit questionable, so we're moving it to reduce exposure.",4
[hotfix] Move util to WebFrontedITCase,2
[FLINK-25545][flink-clients][JUnit5 Migration] Module: flink-clients.This closes #18928.Co-authored-by: Ryan Skraba <ryan@skraba.com>,2
[FLINK-25252][kafka] Enabling Kafka tests on Java 11,3
[FLINK-28629][sql-gateway] Return operation schema until operation is in terminal state,2
[FLINK-28629][sql-gateway][hive] Allow to getCatalogs in the HiveServer2 EndpointThis closes #20334,2
[FLINK-28720][hive][connectors] Add Hive partition when flink has no data to write (#20394),5
[FLINK-28459][table-planner] Supports non-atomic CREATE TABLE AS SELECT (#20392),1
[FLINK-28419][table] Add runtime provider interface for full caching lookup + implement Periodic and Timed cache reload triggersThis closes #20382,1
"Revert ""[FLINK-28373][network] Read a full buffer of data per file IO read request for sort-shuffle""This reverts commit 1c044753b0f0e4c23f954d71f355d1368c41061f for CI stability.",4
[FLINK-28804][formats] Use proper stand-ins for missing metric groups,1
[FLINK-27908] HsSubpartitionView should calculate backlog no less than true value.This closes #20445,2
[hotfix] Add hybrid shuffle to taskmanager.memory.framework.off-heap.batch-shuffle.size description.,1
[FLINK-27909] Add document for hybrid shuffle mode.This closes #20433,2
[FLINK-28795][hive] Fix unstable test for HiveDialectQueryITCase#testInsertDirectory (#20446),3
[FLINK-28801][oss] Bump OSS SDK to 3.13.2This closes #20450,2
[FLINK-28781] Rename blockingShuffleCompressionEnabled to batchShuffleCompressionEnabled.,0
"[FLINK-28781] Hybrid Shuffle should support compression.Compression is a useful feature for batch jobs, which can significantly reduce disk load and the amount of data transferred over the network. Hybrid shuffle should also support the compression of spilled data, especially under the full spilling strategy.This closes #20426",5
[hotfix][docs] Remove limitation about CLAIM mode and RocksDB native savepoints,5
"Revert ""[FLINK-25745] Do not log exception if CompletedCheckpointStorageLocation#disposeStorageLocation failed in CLAIM mode""This reverts commit d91cb003",4
[FLINK-26371][hive] Support variable substitution for sql statement while using Hive dialect (#19656),1
[FLINK-26362][hive] Fix IndexOutOfBoundsException when sub-query selects all fields  when using Hive dialectThis closes #18937,1
[FLINK-28835][docs] Fix unaligned checkpoints documented compatibilityIt looks like there was a typo and we initially merged version conflictingwith what was agreed in FLIP-203.,5
[FLINK-28296][hive] Support the Hive UDAF which implement GenericUDAFResolver interface (#20102),0
[FLINK-27620][sql] Flink SQL supports PERCENT_RANK function (#20347),1
[FLINK-28630][sql-gateway][hive] Allow to GetSchemas in the HiveServer2 EndpointThis closes #20401,1
[FLINK-28808][csv] Create mapper on server-side,1
[FLINK-28713][tests] Remove unused curator-test dependency,3
[FLINK-25645][table-runtime] Fix UnsupportedOperationException when hash shuffle by a field with array typeThis closes #19709,1
[FLINK-28733][scripts] jobmanager.sh supports dynamic parameters,2
Update log4j.properties,2
[FLINK-27217][hive] Support partition filter push down when there exists default partition for Hive source.This closes #19450,1
[FLINK-27217][hive] Improve default partition test casesThis closes #19450,3
[FLINK-27619][sql] Support NTILE Function,1
[FLINK-27619][sql] fix use wrong constant for over window.,0
[FLINK-28570][table-planner] Extends FlinkRelOptUtil to support print upsertKey infoThis closes #20393,5
[FLINK-28570][table-planner] Append upsertMaterialize info by a simpler way of overriding the explainTerms method for StreamPhysicalSinkThis closes #20393,5
[FLINK-28570][table-planner] Introduces a base class StreamPhysicalGroupWindowAggregateBase for all related sub-classesThis closes #20393,2
[FLINK-28570][table-planner] Extracts common attributes into StreamPhysicalGroupAggregateBase for all sub-classesThis closes #20393,4
[FLINK-28570][table-planner] Optimize upsertKey inference for lookup join and fix ConnectorCatalogTable lost pk on stream sourceThis closes #20393,2
[FLINK-28570][table-planner] Introduces a StreamNonDeterministicPlanResolver to validate and try to solve (lookup join only) the non-deterministic updates problem which may cause wrong result or errorThis closes #20393,0
[FLINK-27524][datastream] Introduce cache API to DataStreamThis closes #20147.,5
[FLINK-28772][hive] Supports ADD JAR command in Hive dialectThis closes #20413,1
[FLINK-28772][hive] Improve exception messages for ADD JARThis closes #20413,1
[FLINK-28834][examples-table] Add temporal join example and IT testThis closes #20464,3
[hotfix][tests] Remove unnecessary mock,4
[FLINK-28807] Honor schema lifecycle,2
[FLINK-28709][source] Introduce coordinatorListeningID in SourceCoordinator to listen to events from other coordinatorsThis closes #20374,2
[FLINK-28709][table] Introduce DynamicFilteringData and the DynamicFilteringDataCollectorOperator to build and distribute the dataThis closes #20374,5
[FLINK-28709][table] Introduce ExecutionOrderEnforcerOperator to ensure the source with dynamic filtering is executed after the DynamicFilteringData is collectedThis closes #20374,5
[FLINK-28826][network] Avoid notifying too frequently when recycling buffers for BatchShuffleReadBufferPoolThis closes #20461.,5
[FLINK-28782][python][connector/filesystem] FileSink supports compactionThis closes #20428.,1
[FLINK-28710][table-planner] The fact source of DPP must be FLIP-27 sourceThis closes #20472,2
[FLINK-28710][table-planner] Supports dynamic filtering executionThis closes #20472,1
[FLINK-28633][sql-gateway][hive] Allow to GetTables in the HiveServer2 EndpointThis closes #20438,1
[FLINK-28822][python] Avoid creating VectorizedColumnBatch for each read in ArrowReader (#20458),1
[FLINK-28234][table-planner] Fix Infinite or NaN exception in ExpressionReducerThis closes #20062,5
[FLINK-28851][sql-gateway][hive] Remove useless OperationType,1
[FLINK-28851][hive] Allow to GetTypeInfo in the HiveServer2 EndpointThis closes #20468,5
[FLINK-27790][table] Port ADD JAR & SHOW JARS syntax implementation from SqlClient to TableEnvironment sideThis closes #20361,1
[FLINK-27790][table] Revert changes to AddJarOperation,1
[FLINK-27790][table] Fix test failure in set.q and function.q of SQL Client,1
[FLINK-27790][table] Fix NoClassDefFoundError of guava in UsingRemoteJarITCase,1
[FLINK-28420][table] Support partial caching in sync and async lookup runnerThis closes #20480,1
[FLINK-28688][python] Support DataStream PythonWindowOperator in Thread ModeThis closes #20435.,1
"[FLINK-28678][table-planner] Copy some nodes from calcite, and need revert when upgrade calcite-1.31Since currently the feat [CALCITE-5107] is not introduced to the calcite version flink used, so just temporarily copy the files and cherry-pick this feat directly. When the calcite upgrades to 1.31, these classes should be deleted.This pr is just to copy some nodes from calcite, but doesn't do any modification on them.This closes #20359",4
"[FLINK-28678][table-planner] Support SQL hint for Filter, SetOp, and etc. Mainly cherry-pick from [calcite-5107]Since currently the feat [CALCITE-5107] is not introduced to the calcite version flink used, so just temporarily cherry-pick this feat to copied files directly. When the calcite upgrades to 1.31, these classes should be deleted.This closes #20359",4
"[FLINK-28682][table-planner] Copy SqlToRelConverter from calciteDue to Calcite will expand the whole SQL Rel Node tree that contains query block, but sometimes the query block should be perceived. A new node QueryBlockAlias will be added into the RelNode tree to isolate the query block and some hints (like join hints) will not be propagated into the query block.This pr is just to copy SqlToRelConverter from calcite and doesn't do any modification.This closes #20359",1
[FLINK-28682][table-planner] Support join hint in batch rulesThis closes #20359,1
[FLINK-28713][yarn] Bump curator-test dependencyThis closes #20483,3
[FLINK-27966][python] Make the connector imports more explicit by adding connector type,1
[hotfix][python][tests] Split the test cases of connectors & formats into separate files,2
[FLINK-28827][python] Complete DataType support in DataStream API (#20460),5
[FLINK-28836][python] Support broadcast in Thread ModeThis closes #20490.,1
[FLINK-28599][table-planner] Adding FlinkJoinToMultiJoinRule to support translating left/right outer join to multi joinThis closes #20303,1
[FLINK-28793][sql-gateway][hive] Allow to GetInfo in the HiveServer2 EndpointThis closes #20444,5
[FLINK-28788][python] Support SideOutput in Thread ModeThis closes #20488.,1
[FLINK-23143][state/changelog] Support state migration for ChangelogStateBackend,4
[refactor][state] Rename createInternalState to createOrUpdateInternalState,5
[hotfix][python] Make the format imports more explicit by adding format type,1
"[hotfix][tests] Migrate tests relevant to FLINK-28663 to Junit5/AssertJMigrated tests include DefaultExecutionGraphConstructionTest, EdgeManagerBuildUtilTest, EdgeManagerTest, ExecutionJobVertexTest, IntermediateResultPartitionTest, RemoveCachedShuffleDescriptorTest, JobTaskVertexTest, DefaultExecutionTopologyTest, DefaultExecutionVertexTest, DefaultResultPartitionTest, AdaptiveBatchSchedulerTest and ForwardGroupComputeUtilTest.This closes #20350.",3
[FLINK-28663][runtime] Allow multiple downstream consumer job vertices sharing the same intermediate dataset at scheduler sideThis closes #20350.,5
[hotfix][csv][tests] Open schemas,3
[FLINK-28621][formats] Initialize mappers in open(),5
[FLINK-28621][core] Add central Jackson mapper factory methods,1
[FLINK-28621] Enable Date/Time&Optional support for all mappers,1
[FLINK-28094][kinesis] Removing references to Regions enum and instead using RegionUtils so that we include future AWS Regions as well,1
[FLINK-23252][state/changelog] [docs] Update the docs about disabling changelog,4
[FLINK-28865] Add new PrintSink,1
[FLINK-28380][runtime] Produce one intermediate dataset for multiple consumer job vertices consuming the same dataThis closes #20351.,5
"[FLINK-24614][parquet] Support complex types (arrya, map, row) for parquet readerThis closes #20442",1
[FLINK-28631][sql-gateway][hive] Support to GetFunctions in the HiveServer2EndpointThis closes #20479,1
[hotfix][sql-gateway] Use camelCase for REST request/response body fields in session related APIs.,1
[FLINK-28162][sql-gateway]Introduce the operation related API for REST endpoint,2
[FLINK-28164][sql-gateway]Introduce utilities API for REST endpoint,2
[FLINK-28163][sql-gateway]Introduce the statement related API for REST endpointThis closes #20451,2
[hotfix] Migrate PipelinedRegionSchedulingStrategyTest and StrategyTestUtil to Junit5 and AssertJ.,3
[FLINK-28799] PipelinedRegionSchedulingStrategy maintain scheduled regions,2
[FLINK-28799] PipelinedRegionSchedulingStrategy supports all resultPartitionType.This closes #20487,1
[FLINK-28183][python] Model python test dependencies in MavenThis closes #20470.,3
"[FLINK-28753][table-planner] Improve FilterIntoJoinRule which could push some predicates to another sideFor the above filter of inner/left/right join or the join condition of inner join, the predicate which field references are all from one side join condition can be pushed into another join sideThis closes #20432",1
[FLINK-28843][StateBackend] Fix restore from incremental checkpoint with changelog checkpoint in claim mode,4
[FLINK-28568][table-runtime] Implements a new lookup join operator (sync mode only) with state to eliminate non-deterministic resultThis closes #20324,5
[FLINK-28699][state] Make non-incremental rocksdb checkpoint as native formatThis closes #20399.,5
[FLINK-28880][docs][cep] Fix wrong result of strict contiguity of looping patternsThis closes #20508.,0
[FLINK-27155][changelog] Reduce multiple reads to the same Changelog file in the same taskmanager during restore,2
[FLINK-28094][kinesis][glue] Updating AWS SDK versions for Kinesis connectors and Glue Schema Registry formats,1
"[FLINK-26413][hive] Supports ""LOAD DATA INPATH"" in Hive dialectThis closes #19556",5
[FLINK-28373][network] Read a full buffer of data per file IO read request for sort-shuffleThis closes #20457.,2
[FLINK-25485][connector/jdbc] Add default jdbc option 'rewriteBatchedStatements' for MySQL dialectThis closes #18469.,5
"[FLINK-28785][network] Hybrid shuffle consumer thread and upstream thread may have deadlock.In hybrid shuffle mode, subpartition view lock will be acquired by consumer thread, and further wait the read lock of MemoryDataManager. But MemoryDataManager may acquire write lock to make a global spilling decision, and then wait subpartition view lock to get consuming offset. In this case, deadlock will occurs.consumer thread : acqurie subpartition lock -> wait read lock.upstream thread  : acquire write lock -> wait subpartition lock.This closes #20456",1
[hotfix][build][hbase] Remove unused property,5
[FLINK-25244][hbase] Enable Java 11 tests for HBase 2.2,3
[FLINK-28860][tests] Disable CacheITCase temporarilyThis closes #20512.,3
[FLINK-28711][hive] Hive source supports dynamic filteringThis closes #20415,1
[FLINK-27693][changelog] Support local recovery for non-materialized part,1
[FLINK-27693][docs] Remove local recovery from the Limitations of changelog,4
[FLINK-28178][runtime-web] Show the delegated StateBackend and whether changelog is enabled in the UI,0
[FLINK-28606][Runtime/Checkpointing] Preserve consistency of OperatorEvent from OperatorCoordinator to subtasks,1
[FLINK-28606][Runtime/Checkpointing] Refractor coordination tests with JUnit5 Assertions,3
[FLINK-28873][configuration] Make jobmanager.scheduler visible in documentation,2
[FLINK-28854][connector/jdbc] Migrate JDBC lookup table to the new LookupFunction and caching interface,1
[FLINK-28487][connectors] Introduce configurable RateLimitingStrategy for AsyncSinkWriter,5
[hotfix][python] Refactor thread mode Python runtime to make it more readable,1
[FLINK-28871][table-planner] Force the output edges of dynamic filtering data collector to be BLOCKINGThis closes #20497.,5
[FLINK-28857][docs] Add Document for DataStream Cache APIThis closes #20491.,5
"[hotfix] Migrate PartitionFileWriteReadTest, SortMergeResultPartitionReadSchedulerTest, SortMergeSubpartitionReaderTest to Junit5 and AssertJThis closes #20333.",3
"[FLINK-28623][network] Optimize the use of off-heap memory by blocking and hybrid shuffle readerCurrently, each FileReader (PartitionFileReader or HsSubpartitionFileReaderImpl) will internally allocate a headerBuffer with the size of 8B. Besides, PartitionFileReader also has a 12B indexEntryBuf. Because FileReader is of subpartition granularity, if the parallelism becomes very big, and there are many slots on each TM, the memory occupation will even reach the MB level. In fact, all FileReaders of the same ResultPartition read data in a single thread, so we only need to allocate one headerBuffer for each ResultPartition to optimize it.This closes #20333.",5
[FLINK-28862][python][format/parquet] Support ParquetBulkWriterThis closes #20499.,1
[FLINK-28886][python] Support HybridSource in Python DataStream APIThis closes #20515.,5
[FLINK-28778][SQL/API] Bulk fetch of table and column statistics for given partitionsThis closes #20501Co-authored-by: Jing Ge <gejing@gmail.com>,2
[FLINK-28797][hive] HiveSource enables vector reading for complex data type with parquet format,5
[FLINK-28797][hive] Simplify useModules for the parquet complex type tests,3
[FLINK-28731][conf] Log dynamic properties,2
[FLINK-28532][table] Support full caching in lookup join runner using InputFormats as scan runtime provider (#20447),1
[FLINK-28529][state/changelog] Fix unstable ChangelogPeriodicMaterializationSwitchStateBackendITCase#testSwitchFromDisablingToEnablingInClaimMode,3
[refactor][state/changelog] Rename ChangelogPeriodicMaterialization* to ChangelogRecovery*,4
[FLINK-28868][connector/hbase] Migrate HBase table connector to the new LookupFunction interfaceThis closes #20495,1
[FLINK-28876][python][format/orc] Support Orc formatThis closes #20505.,1
[hotfix] Migrate RestartPipelinedRegionFailoverStrategyTest to Junit5 and AssertJ.,3
[FLINK-28701] Split HYBRID result partition type to HYBRID_FULL and HYBRID_SELECTIVE.,2
[FLINK-28701] RestartPipelinedRegionFailoverStrategy takes reConsumable into account when decide partition available.,0
[FLINK-28701] Remove WIP prefix of ALL_EXCHANGE_HYBRID_FULL and ALL_EXCHANGE_HYBRID_SELECTIVE in BatchShuffleMode and expose them to documents.This closes #20429,2
[FLINK-27338][hive] Improve splitting file for Hive sourceThis closes #20377,2
[FLINK-26929][table-runtime] Introduce adaptive hash join strategy for batch hash join (#20365),2
[FLINK-28821][table-planner] Adjust join cost for dpp query pattern which could help more plans use dppThis closes #20462,1
[FLINK-28481][k8s] Bump the fabric8 kubernetes client to 5.12.3This closes #20390.,2
[FLINK-28774][hive] Allow user to configure whether to enable sort not when it's for dynamic partition writing for HiveSourceThis closes #20419,0
[FLINK-28632][sql-gateway][hive] Allow to GetColumns/GetPrimaryKeys/GetTableTypes in the HiveServer2 EndpointThis closes #20493,1
[FLINK-28848][table-planner] Introduces LOOKUP join hint to support delayed retry for lookup join (table alias unsupported in hint)This is the main part of FLINK-28779 to implement FLIP-234: Support Retryable Lookup Join To Solve Delayed Updates Issue In External SystemsThis closes #20482,5
[hotfix][table-planner] Use scala isInstanceOf to check lookup function type instead of one-level parent class compartion in LookupJoinCodeGeneratorThis bug can be reproduced by AsyncLookupJoinITCase#testAsyncJoinTemporalTableWithLookupThresholdWithInsufficientRetry when caching is disabled in FLINK-28849This closes #20482,2
"[hotfix][runtime] Do last attempt without successfully canceling the retry timer to prevent unexpected incomplete element during finish phase in AsyncWaitOperatorIt is hard to reproduce this in runtime tests, but occasionally happens in AsyncLookupJoinITCase#testAsyncJoinTemporalTableWithLookupThresholdWithSufficientRetry of FLINK-28849. It's better to add a separate test in runtime.This closes #20482",1
[FLINK-28849][table-planner] Fix errors when enable retry on async lookup and add more testsDisable retry on async because of two problems need to be resolved firstThis closes #20482,0
[FLINK-28060][kafka] Bump Kafka to 3.2.1,2
[hotfix][python] Move json/avro/csv SerializationSchema implementations into the corresponding files,2
[FLINK-28895][python] Perform RowRowConverter automically when writing RowData into sinkThis closes #20525.,5
[FLINK-28904][python][docs] Add missing connector/format documentationThis closes #20535.,2
[FLINK-28898][state/changelog] Fix unstable ChangelogRecoverySwitchStateBackendITCase#testSwitchFromEnablingToDisablingWithRescalingOut,3
[FLINK-28900] Fix RecreateOnResetOperatorCoordinatorTest compilation failureThis closes #20532.,0
[FLINK-28783] [flink-core] Fix typo in ConfigOptions's example codeThis closes #20427.,5
"[FLINK-28884] HsSubpartitionView should be initialized to a notifiable state.HsSubpartitionView should be initialized to a notifiable state, there may be a problem of never consuming otherwise. Imagine the following situation: Downstream task has no initial credit(i.e. exclusive buffers is configured to zero), if there is no data output in the upstream, it will feedback a zero backlog to downstream input channel. All subsequent data available notifications will be intercepted as needNotify is false.",5
"[FLINK-28884] Reset needNotify to true when get a zero backlog.HsSubpartitionView should be notifiable when downstream get a zero backlog. Generally speaking, if the backlog is zero, when data become available, even if there is no credit, the backlog information will be notified also. However, in the hybrid shuffle, the notification will be ignored. This behavior is incorrect.This closes #20529",5
[FLINK-28888] The statistics of HsResultPartition are not updated correctlyThis closes #20528,5
[FLINK-27588][python][docs] Update broadcast state related documentation (#20550),2
[FLINK-28887][python] Fix the bug of custom metrics in Thread ModeThis closes #20540.,0
[FLINK-28767][sql-gateway] Fix unstable SqlGatewayServiceITCase.testCancelOperation,3
[FLINK-27856][k8s] Fix the NPE when no spec is configured in pod templateThis closes #20516.,5
[hotfix][python][dcos] Fix the typos in the Metrics Doc,2
[FLINK-28921][python][docs] Optimize the Python DataStream Window DocumentationThis closes #20557.,2
[FLINK-27570][runtime] Count checkpoint finalization failures in CheckpointFailureManager,0
[FLINK-28626][tests] Fix unstable RescaleCheckpointManuallyITCase when unaligned checkpoint is enabled,0
"[FLINK-27399][Connector/Pulsar] Change initial consuming position setting logic for better handle the checkpoint. (#19972)* Change the initial start cursor and stop cursor to better handle the consuming behaviors.* Create the initial subscription instead seek every time. This should fix the wrong position setting.* Fix the wrong stop cursor, make sure it stops at the correct space* Drop Consumer.seek() for https://github.com/apache/pulsar/pull/16171",4
[FLINK-28932][Table/SQL] Remove use of deprecated method,1
[FLINK-26771][hive] Fix incomparable exception between boolean type and numeric type in Hive dialectThis closes #19182,0
[FLINK-28817] NullPointerException in HybridSource when restoring from checkpoint (#20530),2
[FLINK-28855][hive] Fix 'Table.INDEX_TABLE' not found in the Hive3 (#20514),0
[FLINK-28208][hive] Set parallelism for map operator in class HiveTableSink's method createBatchSink (#20471),1
[FLINK-28944][python][docs] Update the Python execution mode documentationThis closes #20561.,2
[FLINK-28878][tests] Increase slot request timeout of PipelinedRegionSchedulingITCaseThis helps to make the tests more stable.This closes #20559.,3
[FLINK-28908][python] Fix LIST type in Python DataStream APIThis closes #20539.,5
[FLINK-28795][hive] Fix unstable test in HiveDialectQueryITCaseThis closes #20569.,1
[FLINK-28916][e2e] Add e2e test for create function using jar syntax (#20545),1
[FLINK-28913][hive] Fix failed to open HiveCatalog when it's for hive3 (#20573),2
"[FLINK-28861][table] Make UID generation behavior configurable and plan-only by defaultBefore this commit, due to changes for FLIP-190, every operator generated by the plannergot a UID assigned. However, the UID is based on a static counter that might return differentresults depending on the environment. Thus, UIDs are not deterministic and make statefulrestores impossible e.g. when going from 1.15.0 -> 1.15.1. This PR restores the old pre-1.15behavior for regular Table API. It only adds UIDs if the operator has been created from acompiled plan. A compiled plan makes the UIDs static and thus deterministic.table.exec.uid.generation=ALWAYS exists for backwards compatibility and could make statefulupgrades possible even with invalid UIDs on best effort basis.",1
"[FLINK-28861][table] Fix bug in UID format for future migrations and make it configurableBefore this commit, the UID format was not future-proof for migrations. The ExecNode versionshould not be in the UID, otherwise, operator migration won't be possible once plan migrationis executed. See the FLIP-190 example that drops a version in the plan, once operator migrationhas been performed. Given that the plan feature is marked as @Experimental, this change shouldstill be possible without providing backwards compatibility.However, the config option table.exec.uid.format allows for restoring the old format and solvesother UID related issues on the way.This closes #20555.",0
[FLINK-28899][table-planner] Fix LOOKUP hint with retry option on async lookup modeThis closes #20531,1
[FLINK-28773][hive] Allow to write a success file after finish for Hive sink in batch modeThis closes #20469,5
[FLINK-28773][hive] Improve tests of writing success filesThis closes #20469,2
[FLINK-28773][hive] Fix the NPE of FileSystemOutputFormat#finalizeGlobal,5
[FLINK-28003][sql-client] Disable SqlCompleter when using -f {file} in SQL ClientThis closes #20182,2
[FLINK-28548][filesystem] Fix FileNotFoundException when the commit partition base path is not createdThis closes #20269,1
[hotfix][files] Fix the compile problem of FileSystemCommitterTest,5
[FLINK-28955][yarn] Add direct curator-test dependency,3
"[FLINK-28994][runtime-web] Enable withCredentials for outgoing HTTP requestsSome environments require cookies to authenticate the Flink UI. By enabling the withCredentialsflag, Angular will send cookies along with the request.Signed-off-by: Ingo Brk <airblader@apache.org>This closes #20593.",0
[FLINK-27386][hive] Fix assert exception when specific join hint in union statement (#19583),3
[FLINK-26505][hive] Support non equality condition for left semi join in Hive dialect. (#18994),1
[FLINK-27015][hive] Fix exception for casting timestamp to decimal in Hive dialect (#20571),0
[FLINK-27917][Connector/Pulsar] Drop Consumer.seek() in the testing method for fixing the race condition. (#20567),0
[FLINK-28925][runtime] HsSubpartitionMemeoryDataManager return a readOnlySlice to downstream instead of original buffer.,5
[FLINK-28925][runtime] Fix the NPE problem caused by double release buffer.This closes #20591,1
"[FLINK-28861][table][docs] Update ""upgrading"" documentation to include notice regarding the Table API operator issue",0
[FLINK-28780][docs] Fix incorrect description of function dayofmonth. (#20424),1
"[FLINK-28922][docs-zh] Translate ""ORDER BY clause"" page into Chinese.This closes #20551",1
"[FLINK-28924][docs-zh] Translate ""LIMIT clause"" page into Chinese.This closes #20552",1
[FLINK-28978][kinesis] Update AWS Regions validation to allow for future AWS regions,1
[FLINK-28488][kafka] Only forward measurable Kafka metrics and ignore others,2
[FLINK-28996][datadog] Move parameter parsing into factory,2
[FLINK-28997][datadog] Add switch to use logical identifier,2
[hotfix][docs] Fix typo,2
[FLINK-29002][datadog] Deprecate 'tags' option,5
[FLINK-29007][e2e] Add missing hadoop-hdfs-client with Hadoop 3,1
[FLINK-28951][table-planner] Make header with one line commentsThis closes #20568.,1
[FLINK-28986][table-planner] UNNEST function with nested filter fails to generate planThis closes #20601,0
[FLINK-28963][sql-gateway] Add REST API compatibility test,3
[FLINK-28800][network] BatchShuffleReadIOExecutor using ScheduledExecutorService instead of ExecutorService.,1
[FLINK-28800][network] HsFileDataManager should avoid busy-loop when fileReader has not data to readThis closes #20553,5
[FLINK-28990][table-planner] Fix BatchPhysicalDynamicFilteringDataCollector with empty output typeThis closes #20594,5
[FLINK-28965][hive] Partition shouldn't be created if no data is generated for dynamic partitionThis closes #20599,5
[FLINK-28917][table-runtime] Add SQL test for adaptive hash joinThis closes #20602,3
[FLINK-28956][hive] Fix non-multi insert statement fall into multi insert logic in Hive dialect (#20572),2
[FLINK-29017][docs] Replace all links to github master with shortcode,2
[hotfix][flink-runtime] Fix the task class typoThis closes #20623,2
[FLINK-29034] HYBRID_FULL result partition type is not yet reConsumableThis closes #20624,2
[FLINK-29009][build] Converge nimbus-jose-jwt,2
[FLINK-29009][build] Converge okio,2
"[FLINK-28987][table-planner] Fix incorrect async to sync lookup fallback path of LegacyTableSourceTableby fixing this we can completely avoid create user lookup function instance to determine if async lookupis enabled for execution, and make the exec lookup join node immutable and easier to maintainThis closes #20592",1
[FLINK-28987][table-planner] Refine description of lookup join transformation with async params and retry strategy for easier debuggingThis closes #20592,0
[FLINK-28972][python][connector/pulsar] Align Start/StopCursor methods with the Java APIThis closes #20589.,2
[FLINK-29028][python][docs] Align DataStream.cache in Python DataStream APIThis closes #20618.,5
[FLINK-28992][table-planner] Fix: Change Ndv takes the max value instead of sum of all partitions when getting partition table column statsThis closes #20595,1
[hotfix][build] Use ${flink.shaded.version} for flink-docs and flink-runtime,2
[hotfix][build] Add japicmp exclusion for getSideOutput incompatibilityChange is source-compatible.,4
[hotfix][build] Fix streaming-java oldVersion artifactIdRemove temporary scala suffix settings for 1.15 in japicmp,1
[FLINK-29051][quickstarts] Do not create dependency-reduced-pom,1
[FLINK-28139][docs] Add documentation for speculative executionThis closes #20507.,2
[FLINK-28676] Update copyright year to 2014-2022 in NOTICE files,2
[FLINK-29012][docs] Fix incorrect description of function minusThis closes #20611,1
[FLINK-29036][docs] Cleanup Source documentation,2
[FLINK-28995][hive] HiveSourceDynamicFileEnumerator filters out a partition without matching if one of the fields is null but its type is not nullableThis closes #20612,2
[hotfix][core][table] Use ReadableConfig were applicable,5
"[hotfix][streaming-java] Avoid deep copy in StreamExecutionEnvironment.getConfigurationStreamExecutionEnvironment.getConfiguration() was not only a ReadableConfig but also adeep copy. This caused various problems downstream (Python API) and makes accessingconfiguration expensive. Root configuration of TableConfig should not be a snapshotbut a reference that always reflects the current status of StreamExecutionEnvironment.Otherwise, when merging e.g. PipelineOptions.JARS, it is possible that entries getlost when an outdated root configuration is used during merging.",1
[hotfix][table] table.resource.download.dir -> table.resources.download-dir,0
[hotfix][table-api-java] Small improvements to TableConfig,5
[FLINK-29014][streaming-java][table] Improve end-to-end story about PipelinesOptions.JARSThis closes #20633.,1
[FLINK-28977] NullPointerException in HybridSourceSplitEnumerator.close (#20587),2
[FLINK-28993][table-planner] Refactor SupportsDynamicFiltering to provide getAcceptedFilterFields method to avoid modifing the DynamicTableSource object if calling applyDynamicFiltering method in join reorder rulesThis closes #20596,1
[FLINK-28993][table-planner] Fix adjusting join cost for dpp query pattern errorThis closes #20596,0
[FLINK-29041][tests] Add utility to test POJO compliance without any Kryo usage,3
[FLINK-28735][scripts] Deprecate jobmanager.sh host/port parameters,2
[FLINK-29030][core] Add constant for generic type doc reference,2
[FLINK-29030][core] Note that generic types can affect schema evolution,2
[FLINK-29030][core] Log a message if any tuple/pojo field is handle as generic type,0
[FLINK-29016][docs] Clarify Kryo limitations w.r.t. data-structures,5
[FLINK-28265][k8s] Make KubernetesStateHandleStore#addEntry idempotentThis closes #20590.,0
[FLINK-28815][docs] Translate the Real Time Reporting with the Table API page into ChineseThis closes #20510.,1
[FLINK-28936][sql-gateway] Fix REST endpoint can not serialize uncompacted LogicalType (#20617),2
[FLINK-28841][scripts][docs] Document dynamic properties support,1
[FLINK-29081][table-planner] Capitalize join hints to avoid case sensitiveThis closes #20669,2
"[FLINK-28493][docs] Add document to describe ""ANALYZE TABLE"" syntaxThis closes #20506",2
[FLINK-29029][python] Fix the bug of InternalTypeInfo mapping to IdentityConverter in Thread ModeThis closes #20621.,5
[FLINK-29059][table-planner] Fix the existing column stats are deleted incorrectly when analyze table for partial columnsThis closes #20672,4
[FLINK-28177][Connectors/ElasticSearch] Fix the unstable Elasticsearch6DynamicSinkITCase.testWritingDocumentsNoPrimaryKeyThis closes #20362.,3
[hotfix][sql-gateway]Modify url in operation related message headers,0
[hotfix][sql-gateway]Modify the response format and adjust SqlGatewayRestEndpointFactory,0
[FLINK-27773][sql-gateway]Introduce the rest E2E tests for SQL Gateway,3
fixup! [FLINK-27773][sql-gateway]Introduce the rest E2E tests for SQL Gateway,3
"[FLINK-29096][table] Add test for json_value, which json path has blank characters.This closes #20675",5
[FLINK-29096][table] Update documentation for JSON_VALUE special characters,5
[hotfix][state] Extract PeriodicMaterializationManager into state-backend-commonThis commit is copied from #19312 / FLINK-26965 .It allows to:- test PeriodicMaterializationManager easier (subsequent commit)- reuse PeriodicMaterializationManager for non-changelog cases (e.g. FLIP-151),4
[hotfix][tests] Use negative changelog materialization interval in tests...instead of a big value so that the subsequent change won't break them.,4
[hotfix][state] Fix logging in Materializer and make FLINK-28976 more explicit,2
[FLINK-28976][state] Don't add extra delay to the 1st materialization,1
[FLINK-29046][Connectors/Hive] Fix HiveTableSourceStatisticsReportTest fails with Hive 3.xThis closes #20664,0
[FLINK-27175][hive] Fix fail to call Hive UDAF when the UDAF accepts one parameter with array typeThis closes #19423,2
[FLINK-29035][table-planner] Fix bug of ExpressionReducer does not work with jar resourcesThis closes #20635,1
[FLINK-28883][hive] Fix HiveTableSink failed to report statistic to hive metastore in batch modeThis closes #20549,0
[FLINK-29056] Throw PartitionNotFoundException if the partition file is not readable for hybird shuffle.This closes #20666,2
[FLINK-29105][k8s] Fix the unstable k8s test 'testAddAndLockShouldNotThrowAlreadyExistExceptionWithSameContents',3
[hotfix] Add TaskManager id in the exception message,1
[FLINK-29121][sql-gateway] Fix failed SqlGatewayRestAPIStabilityTest,3
[hotfix][tests] Nicer migration path for typo fix,0
[FLINK-29062][build] Fix protobuf plugin proxy issue on flink-protobuf module.,2
[FLINK-27030][tests] Prevent race-condition,3
[hotfix][tests] Minor cleanup,4
[FLINK-29097][sql-gateway] Move json se/deserializers from sql-gateway-api to sql-gatewayThis closes #20678,5
[FLINK-28609][Connector/Pulsar] PulsarSchema didn't get properly serialized. (#20698),1
[FLINK-29038][runtime] Fix unstable case AsyncWaitOperatorTest#testProcessingTimeRepeatedCompleteOrderedWithRetryThis closes #20702.,3
[FLINK-28814][Connectors][JDBC] Update org.postgresql:postgresql to 42.4.1,5
"[FLINK-28121][docs-zh]Translate ""Extension Points"" and ""Full Stack Example"" in ""User-defined Sources & Sinks"" page",1
[FLINK-29123][k8s] Dynamic paramters are not pushed to working with kubernetes,1
[FLINK-28751][table] Improve the performance of JSON functions with json path (#20397),5
[FLINK-29087][connector/jdbc] Change dependencies order to avoid compile failure while running in ideaThis closes #20670.,1
[FLINK-29005][parquet] Parquet row type reader should not return null value when some child fields is nullThis closes #20616,2
[FLINK-26474][hive] Fold exprNode to fix the issue of failing to call some hive udf required constant parameters with implicit constant passedThis closes #18975,4
[FLINK-29019][doc][parquet] Updating parquet format document that support read complex type,1
[FLINK-29130][state] Correct the doc description of local-recovery,2
[FLINK-24718] Update Avro dependency to 1.11.1,5
[hotfix][docs] List FileSystem also as a source,5
[hotfix][tests] Replace deprecated AbstractThrowableAssert#getRootCause,3
[FLINK-28938][hive] Fix HiveServer2 Endpoint can not set variable correctly,1
[FLINK-28938][hive] Improve error messages for unsupported interfaces,1
[hotfix][doc]Update doc of REST API in runtime module,1
[FLINK-28974][sql-gateway]Add doc for the API and Option of sql gateway rest endpointThis closes #20622,2
[FLINK-29138][table-planner] fix project can not be pushed into lookup sourceThis closes #20717,0
[FLINK-29053] Hybrid shuffle has concurrent modification of buffer when compression is enabledThis closes #20647,0
[FLINK-29161][tests] Fix the built docker image name,2
[hotfix][docs] Fix typo,2
[hotfix][csv][javadoc] Fix reference,0
"[FLINK-28078][tests] Mitigate likelihood to run into test stability issues caused by CURATOR-645CURATOR-645 covers a bug in the LeaderLatch implementation that causes a race condition if a child node, participating in the leader election, is removed too fast. This results in a different code branch being executed which triggers a reset of the LeaderLatch instead of re-collecting the children to determine the next leader.The issue occurs because LeaderLatch#checkLeadership is not executed transactionally, i.e. retrieving the children and setting up the watcher for the predecessor is not done atomically. This leads to the race condition where a children (the previous leader's node) is removed before setting up the watcher which results in an invalid handling of the situation using reset.Adding some sleep here (simulating the leader actually doing something) will reduce the risk of falling into the race condition because it will give the concurrently running LeaderLatch instances more time to set up the watchers properly.This is only meant as a temporary solution until CURATOR-645 is resolved and the curator dependency on the Flink side is upgraded.",2
[FLINK-28948][table] Increase test coverage for lookup full caching + fix metrics,0
[FLINK-28971][docs] Adds user documentation for the new LOOKUP hintThis closes #20577,1
[FLINK-29112][table-planner] Print the lookup join hint on the node in the original RelNode tree for easier debuggingThis closes #20686,0
[FLINK-29180] fix: show subtask metrics as default in vertex detail (#20737),0
[FLINK-28858][docs] Add document to describe join hints for batch sqlThis closes #20513,2
[FLINK-29091][table-planner] Fix the determinism declaration of the rand function to be consistent with the current behaviorThis closes #20674,1
Update version to 1.17-SNAPSHOT,5
[hotfix][release] Add 1.17 to the flink version enum,2
[FLINK-29182][table] fix redundant computations in SumAggFunction. (#20738),1
[FLINK-27017][hive] Fix divide by zero exception with Hive dialect (#19216),0
[FLINK-28429][python] Remove the warnings in the Python testsThis closes #20685.,3
[FLINK-28429][python] Optimize PyFlink testsThis closes #20685.,3
[FLINK-28429][python] Skip cython test on python-only-PRsThis closes #20685.,3
[FLINK-28429][python] Upgrade the version of grpcio-toolsThis closes #20685.,2
"[FLINK-29013][hive] Fix fail to use BinaryRecordReader in ""transform using"" syntax with Hive dialect (#20643)",1
[FLINK-28070][tests] Migrate ScalaAPICompletenessTestBase to Junit5,3
"[FLINK-28122][docs-zh] Translate ""Overview"" and ""Project Configuration"" in ""User-defined Sources & Sinks"" page into Chinese",1
[FLINK-27718][hive] Fix fail to count mutiple fields excpetion in Hive dialect (#19406),0
[FLINK-28659][flink-java][JUnit5 Migration] Migrate flink-java to use junit5.This closes #20715.Co-authored-by: Sergey Nuyanzin <sergey.nuyanzin@aiven.io>,3
[FLINK-29022][docs][table] Add document for CREATE FUNCTION USING JAR feature (#20628),1
[FLINK-29196][python] Update flink-python NOTICEThis closes #20758.,2
[hotfix][cassandra][tests] Use CassandraTupleOutputFormat,1
[FLINK-28897][runtime] Fix bug of failed to generate JobGraph when using UDF and enable checkpointThis closes #20713,0
[hotfix][docs] Fix file reference`jobmanager-session-deployment.yaml` -> `jobmanager-session-deployment-non-ha.yaml`.,2
[FLINK-28941][Runtime/Checkpointing] Add concurrent checkpoint support in Operator CoordinatorThis closes #20752.,1
[FLINK-29205][connectors/kinesis] Passthrough use config to HTTP client when constructing Async Client for Kinesis EFO,5
[hotfix][docs][release] Update the building branch in workflowThis closes #20748.,1
[fixup][table-planner] Using user classloader instead of thread context classloader,1
[FLINK-29074][Connectors/JDBC] Fix ClassNotFound exception when using jdbc connector by add jar syntaxThis closes #20707,1
[FLINK-29096][table] Keep backward compatibility of JdbcCatalog constructor,5
[FLINK-14101][jdbc-connector] Support SQLServer dialect in the jdbc connector.This closes #20235.,5
[FLINK-29210][Docs][SQL Client] Add required parameter when running SQL Client via Docker Compose,2
[FLINK-29210][Docs][SQL Client] Copy English Docker documentation to Chinese documentation to bring them back in sync,2
[FLINK-28860][datastream] Cache consumption in stream mode recompute result in case of cache miss,5
[hotfix][datastream] Fix cache invalidate with remote session cluster,5
[FLINK-28860][runtime] JobMaster wait for partition promote before close,2
[FLINK-29118][sql-gateway][hive] Remove default GenericInMemoryCatalog in the HiveServer2 Endpoint when openSession This closes #20714,2
[FLINK-29184][sql-gateway] Close resource manager when closing Session,2
[FLINK-29132][rest] Cleanup subtask attempt metrics according to the JobDetails to avoid memory leak.This closes #20733.,4
"[FLINK-29153][connector/kafka] Retry KafkaConsumer#commitAsync on WakeupException in KafkaConsumerThreadKafkaConsumerThread makes a wakeup on the KafkaConsumer on offset commit to wakeup the potential blocking KafkaConsumer.poll(). However the wakeup might happen when the consumer is not polling. The wakeup will be remembered by the consumer and re-examined while committing the offset asynchronously, which leads to an unnecessary WakeupException.",1
[hotfix][tests][table-planner] Add two more cases to verify the conflict of multiple LOOKUP hintsThis closes #20743,5
[FLINK-28787][table-planner] Rename getUniqueKeys to getUpsertKeys in CommonPhysicalJoinThis closes #20763,1
[hotfix] Fix the missing comma in create_snapshot_branch.sh,1
[FLINK-29207][connector/pulsar] Fix Pulsar message eventTime may be incorrectly set to a negative number (#20765),1
"[FLINK-29047][k8s] Shade fabric8 kubernetes dependency with org.apache.flink.shaded prefix in flink-kubernetesFor supporting stepDecorators SPI(pluginable decorators), we propose to package the implementation class and associated dependencies into a plugin jar.So we need to load the said dependencies from parent class loader, as the most part / all of plugin decorators depend on the fabric8 kubernetes dependency,such as replies on the kubernetes models/client from fabric8.So we need to shade all the said classes in flink-kubernetes and flink-dist.",2
[FLINK-29211][hive][legal] Update 2.3.9 NOTICE,5
[FLINK-28934][Connector/pulsar] Fix split assignment in different Pulsar subscriptions.,0
[FLINK-27388][Connector/pulsar] Change the topic setup logic in Pulsar runtime operator.,1
[FLINK-28084][Connector/pulsar] Disable retry and delete reconsume logic on PulsarUnorderedPartitionSplitReader.,1
[FLINK-27611][Connector/pulsar] Fix ConcurrentModificationException during checkpoint on Pulsar unordered reader.,0
[FLINK-27400][Connector/pulsar] Filter system topics for Pulsar connector.,5
[FLINK-28934][Connector/pulsar] Support connector testing tools for Pulsar unordered source.,3
[FLINK-29067][Table SQL/API] Replace deprecated SqlParser#configBuilder with SqlParser#config,5
[FLINK-29120][table-planner] Avoid join hint propagating into viewThis closes #20697,2
[FLINK-29217][tests] Guarantee checkpoint order in OC testThis closes #20781.,3
