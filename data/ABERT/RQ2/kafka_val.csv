commit_msg,labels
"KAFKA-13509; Support max timestamp in GetOffsetShell (KIP-815) (#11173)This patch implements KIP-815 as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-815%3A++Support+max-timestamp+in+GetOffsetShell.Reviewers: Luke Chen <showuon@gmail.com>, Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",5
Remove redundant TOC and introduction in Running Streams Applications (#8686)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Update documentation.html to refer to 2.6 (#8745),2
"MINOR: Enable fatal warnings with scala 2.13 (#8429)* Upgrade to Scala 2.13.2 which introduces the ability to suppress warnings.* Upgrade to scala-collection-compat 2.1.6 as it introduces the@nowarn annotation for Scala 2.12.* While at it, also update scala-java8-compat to 0.9.1.* Fix compiler warnings and add @nowarn for the unfixed ones.Scala 2.13.2 highlights (besides @nowarn):* Rewrite Vector (using ""radix-balanced finger tree vectors""),for performance. Small vectors are now more compactlyrepresented. Some operations are now drastically faster onlarge vectors. A few operations may be a little slower.* Matching strings makes switches in bytecode.https://github.com/scala/scala/releases/tag/v2.13.2Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
KAFKA-10689: fix windowed FKJ topology and put checks in assignor to avoid infinite loops (#9568)Fix infinite loop in assignor when trying to resolve the number of partitions in a topology with a windowed FKJ. Also adds a check to this loop to break out and fail the application if we detect that we are/will be stuck in an infinite loopReviewers: Matthias Sax <matthias@confluent.io>,5
"KAFKA-13542: Add rebalance reason in Kafka Streams (#12018)Reviewers: Bruno Cadonna <bruno@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-3954; Consumer should use internal topics information returned by the brokerIt previously hardcoded it.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1613 from ijuma/kafka-3954-consumer-internal-topics-from-broker",5
"KAFKA-3365; Add documentation method for protocol types and update doc generation (#4735)Reviewers: Sandor Murakozi <smurakozi@gmail.com>, Magnus Edenhill <magnus@edenhill.se>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9068: Fix javadoc of Stores.{persistent,inMemory}SessionStore (#7908)Reviewer: Matthias J. Sax <matthias@confluent.io>",5
KAFKA-13125: close KeyValueIterator instances in internals tests (part 2) (#11107)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-2793: Use ByteArrayDeserializer instead of StringDeserializer for keys in ConsoleConsumer with new consumer.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #482 from ewencp/kafka-2793-console-consumer-new-consumer-deserializer,1
"MINOR: Fix handling of dummy record in EndToEndLatency toolEndToEndLatency tool produces a dummy record in case the topic does not exist. This behavior was introduced in this PR https://github.com/apache/kafka/pull/5319  as part of updating the tool to use latest consumer API. However, if we run the tool with producer acks == 1, the high watermark may not be updated before we reset consumer offsets to latest. In rare cases when this happens, the tool will throw an exception in the for loop where the consumer will unexpectedly consume the dummy record. As a result, we occasionally see Benchmark.test_end_to_end_latency system test failures.This PR checks if topic exists, and creates the topic using AdminClient if it does not exist.Author: Anna Povzner <anna@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5950 from apovzner/fix-EndToEndLatency",0
MINOR: A few cleanups and compiler warning fixes (#6986)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13946; Add missing parameter to kraft test kit `ControllerNode.setMetadataDirectory()` (#12225)Added parameter `metadataDirectory` to `setMetadataDirectory()` so that `this.metadataDirectory` would not be set to itself.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12381: remove live broker checks for forwarding topic creation (#10240)Removed broker number checks for invalid replication factor when doing the forwarding, in order to reduce false alarms for clients.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-557 Patch to avoid assigning offsets to Log.appends as part of replication. Reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397190 13f79535-47bb-0310-9956-ffa450edef68,2
KAFKA-7403; Use default timestamp if no expire timestamp set in offset commit value (#5690)This fixes a regression caused by KAFKA-4682 (KIP-211) which caused offset commit failures after upgrading from an older version which used the v1 inter-broker format.,1
"KAFKA-7119: Handle transient Kerberos errors as non-fatal exceptions (#5487)Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",0
KAFKA-7702: Fix matching of prefixed ACLs to match single char prefix (#5994)Reviewers: Jun Rao <junrao@gmail.com>,0
"KAFKA-7613: Enable -Xlint:rawtypes for connect, fixing warnings (#8571)Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: Add varint serde utilities for new message formatAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2647 from hachikuji/add-varint-serdes,1
MINOR: Improve log messages when authentications fail: (#6250)- Include more detail in the client log message if the disconnection happensduring authentication.- Include exception message in the Selector info entry when authenticationfails and unwrap `DelayedResponseAuthenticationException`.- Remove duplicate debug log on authentication failure in the Selector.,0
"MINOR Removed copying storage libraries specifically as they are already copied. (#10647)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",4
"MINOR: add missing docs for record-e2e-latency metrics (#10251)Need to add missing docs for the record-e2e-latency metrics, and new TRACE recording levelReviewers: Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-6658; Fix RoundTripWorkload and make k/v generation configurable (#4710)Make PayloadGenerator an interface which can have multiple implementations: constant, uniform random, sequential.Allow different payload generators to be used for keys and values.This change fixes RoundTripWorkload.  Previously RoundTripWorkload was unable to get the sequence number of the keys that it produced.",1
"KAFKA-4198; Fix race condition in KafkaServer.shutdown()It contained this step:      val canShutdown = isShuttingDown.compareAndSet(false, true)      if (canShutdown && shutdownLatch.getCount > 0) {without any fallback for the case of `shutdownLatch.getCount == 0`. So in the caseof `shutdownLatch.getCount == 0` (when a previous call to the shutdown methodwas right about to finish) you would set `isShuttingDown` to true again without anypossibility of ever getting the server started (since `startup` will check`isShuttingDown` before setting up a new latch with count 1).Long story short: concurrent calls to shutdown can get the server locked in a broken state.This fixes the reported error:java.lang.IllegalStateException: Kafka server is still shutting down, cannot re-start!at kafka.server.KafkaServer.startup(KafkaServer.scala:184)at kafka.integration.KafkaServerTestHarness$$anonfun$restartDeadBrokers$2.apply$mcVI$sp(KafkaServerTestHarness.scala:117)at kafka.integration.KafkaServerTestHarness$$anonfun$restartDeadBrokers$2.apply(KafkaServerTestHarness.scala:116)at kafka.integration.KafkaServerTestHarness$$anonfun$restartDeadBrokers$2.apply(KafkaServerTestHarness.scala:116)at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)at scala.collection.immutable.Range.foreach(Range.scala:160)at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)at kafka.integration.KafkaServerTestHarness$class.restartDeadBrokers(KafkaServerTestHarness.scala:116)at kafka.api.ConsumerBounceTest.restartDeadBrokers(ConsumerBounceTest.scala:34)at kafka.api.ConsumerBounceTest$BounceBrokerScheduler.doWork(ConsumerBounceTest.scala:158)Author: Armin Braun <me@obrown.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2568 from original-brownbear/KAFKA-4198",3
"Revert ""MINOR: fix typo in `AbstractIndex.scala` (#9745)"" (#9751)This reverts commit 8577ceae874fac7958340e5cc4277bc54b336fda.",4
MINOR: Using primitive data types for loop index (#9705)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-13231; `TransactionalMessageCopier.start_node` should wait until the process if fully started (#11264)This patch ensures that the transaction message copier is fully started in `start_node`. Without this, it is possible that `stop_node` is called before the process is started which results in not stopping it at all.Reviewers: Jason Gustafson <jason@confluent.io>",5
Trivial commit - explicitly exclude build/rat-report.xml from rat check,5
"KAFKA-2300: Error in controller log when broker tries to rejoin clusterAuthor: flavio junqueira <fpj@apache.org>Reviewers: Ismael Juma, Guozhang WangCloses #102 from fpj/2300 and squashes the following commits:7bd2edb [flavio junqueira] KAFKA-2300: Removed unnecessary s"" occurrences.aa6ec90 [flavio junqueira] KAFKA-2300: Wrapped all occurences of sendRequestToBrokers with try/catch and fixed string typo.f1261b1 [flavio junqueira] Fixed some style issues.9b6390a [flavio junqueira] Updated package name and removed unnecessary imports.dbd1bf3 [flavio junqueira] KAFKA-2300: Error in controller log when broker tries to rejoin cluster",2
"KAFKA-8600: Use RPC generation for DescribeDelegationTokens protocolRefactors the DescribeDelegationToken to use the generated RPC classes.Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Author: Viktor Somogyi <viktorsomogyi@gmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7154 from viktorsomogyi/refactor-describe-dt",4
MINOR: Improve document description in zero-copy (#12099)Follow up of #12052 to improve the description.Reviewer: David Jacot <djacot@confluent.io>,5
"MINOR: Fix NPE in KafkaAdminClient.describeUserScramCredentials (#9374)`KafkaAdminClient.describeUserScramCredentials` should not fail with a NPE when `users` is `null` as `null` means that all the users must be returned.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-7519 Clear pending transaction state when expiration fails (#5820)Make sure that the transaction state is properly cleared when the`transactionalId-expiration` task fails. Operations on that transactionalid would otherwise return a `CONCURRENT_TRANSACTIONS` errorand appear ""untouchable"" to transaction state changes, preventingtransactional producers from operating until a broker restart ortransaction coordinator change.Unit tested by verifying that having the `transactionalId-expiration` taskwon't leave the transaction metadata in a pending state if the replicamanager returns an error.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-9618: Directory deletion failure leading to error task RocksDB open (#8186)We should have the following order:1) close state stores2) wipe out local directory3) release directory lockto avoid the issue. There's an known problem that with some FS one cannot delete the lock file while the calling thread still grabs the file lock, and this would be fixed in another ticket.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR:  exchange redundant Collections.addAll with parameterized constructor (#4521)* Exchange manual copy to collection with Collections.addAll call* Exchange redundant Collections.addAll with parameterized constructor callReviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-10218: Stop reading config topic in every subsequent tick if catchup fails once (#8973)Add logic to reset the existing `canReadConfigs` in `DistributedHerder` once the herder is able to successfully read the configs again. Added unit test to verify the functionality.Author: Chris Egerton <chrise@confluent.io>Reviewer: Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Introduce the KIP-500 Broker lifecycle manager (#10095)Add the KIP-500 broker lifecycle manager.  It owns the broker state.  Its inputs aremessages passed in from other parts of the broker and from the controller: requests to startup, or shut down, for example. Its output are the broker state and various futures that canbe used to wait for broker state transitions to occur.The lifecycle manager handles registering the broker with the controller, as described inKIP-631. After registration is complete, it handles sending periodic broker heartbeats andprocessing the responses.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ron Dagostino <rdagostino@confluent.io>",5
"KAFKA-8729: Add upgrade docs for KIP-467 on augmented produce response (#7522)Add a paragraph explaining the producer caller's expected behavior change on record validation failure scenarios that are improved by KIP-467.Reviewers: Tu V. Tran <tu@confluent.io>, Jason Gustafson <jason@confluent.io>",5
trivial fix to use foreach instead of mapgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1402731 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-2117; Use the correct metadata field for reading offset struct; reviewed by Jun Rao and Jiangjie Qin,1
"KAFKA-3047: Explicit offset assignment in Log.append can corrupt the logThis fix was suggested by Maciek Makowski, who also reported the problem.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1029 from ijuma/KAFKA-3047-log-append-can-corrupt-the-log",2
"KAFKA-9851: Revoking Connect tasks due to connectivity issues should also clear the running assignment (#8804)Until recently revocation of connectors and tasks was the result of a rebalance that contained a new assignment. Therefore the view of the running assignment was kept consistent outside the call to `RebalanceListener#onRevoke`. However, after KAFKA-9184 the need appeared for the worker to revoke tasks voluntarily and proactively without having received a new assignment. This commit will allow the worker to restart tasks that have been stopped as a result of voluntary revocation after a rebalance reassigns these tasks to the work. The fix is tested by extending an existing integration test.Reviewers: Randall Hauch <rhauch@gmail.com>",3
MINOR: Show the specified value in logging the deprecation warnings of internal converter (#5212)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-4667: Connect uses AdminClient to create internal topics when needed (KIP-154)The backing store for offsets, status, and configs now attempts to use the new AdminClient to look up the internal topics and create them if they don’t yet exist. If the necessary APIs are not available in the connected broker, the stores fall back to the old behavior of relying upon auto-created topics. Kafka Connect requires a minimum of Apache Kafka 0.10.0.1-cp1, and the AdminClient can work with all versions since 0.10.0.0.All three of Connect’s internal topics are created as compacted topics, and new distributed worker configuration properties control the replication factor for all three topics and the number of partitions for the offsets and status topics; the config topic requires a single partition and does not allow it to be set via configuration. All of these new configuration properties have sensible defaults, meaning users can upgrade without having to change any of the existing configurations. In most situations, existing Connect deployments will have already created the storage topics prior to upgrading.The replication factor defaults to 3, so anyone running Kafka clusters with fewer nodes than 3 will receive an error unless they explicitly set the replication factor for the three internal topics. This is actually desired behavior, since it signals the users that they should be aware they are not using sufficient replication for production use.The integration tests use a cluster with a single broker, so they were changed to explicitly specify a replication factor of 1 and a single partition.The `KafkaAdminClientTest` was refactored to extract a utility for setting up a `KafkaAdminClient` with a `MockClient` for unit tests.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2984 from rhauch/kafka-4667",5
Minor: Don't swallow errors when altering log dirs in ReplicaManager (#8348)Reviewers: José Armando García Sancio <jsancio@gmail.com>,2
kafka-1973; Remove the accidentally created LogCleanerManager.scala.orig; patched by Grant Henke; reviewed by Jun Rao,4
"MINOR: Remove unnecessary null checks (#4708)Remove unnecessary null check in StringDeserializer, MockProducerInterceptor and KStreamImpl.Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Improve Connect docs (#11642)- Fix indendation of code blocks- Add links to all SMTs and PredicatesReviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>",2
"KAFKA-13043: Implement Admin APIs for offsetFetch batching (#10964)This implements the AdminAPI portion of KIP-709: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=173084258. The request/response protocol changes were implemented in 3.0.0. A new batched API has been introduced to list consumer offsets for different groups. For brokers older than 3.0.0, separate requests are sent for each group.Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>Co-authored-by: David Jacot <djacot@confluent.io>Reviewers: David Jacot <djacot@confluent.io>,  Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: KafkaService should print node hostname on failureAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3715 from cmccabe/kafka_service_print_node_hostname_on_failure",0
MINOR: Doc change related to ZK sasl configsAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2620 from omkreddy/MINOR-ZK-CHANGE,4
"KAFKA-3330; Truncate log cleaner offset checkpoint if the log is truncatedbecketqin Can you take a look?Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1009 from lindong28/KAFKA-3330",5
"MINOR; DeleteTopics version tests (#12141)Add a DeleteTopics test for all supported versions. Convert theDeleteTopicsRequestTest to run against both ZK and KRaft mode.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",1
move shutting down of fetcher thread out of critical path; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-612git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1411070 13f79535-47bb-0310-9956-ffa450edef68,4
KAFKA-2857; Retry querying the consumer group while initializingThis applies to new-consumer based groups and would avoid scenarios in which user issues a `--describe` query while the group is initializing.Example: The following could occur for a newly created group.```kafkakafka:~/workspace/kafka$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group gNote: This will only show information about consumers that use the Java consumer API (non-ZooKeeper-based consumers).Error: Executing consumer group command failed due to The group coordinator is not available.```With this PR the group is queried repeatedly at specific intervals within a preset (and configurable) timeout `group-init-timeout` to circumvent unfortunate situations like above.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2538 from vahidhashemian/KAFKA-2857,5
"MINOR: tune KIP-631 configurations (#10179)Since we expect KIP-631 controller fail-overs to be fairly cheap, tunethe default raft configuration parameters so that we detect nodefailures more quickly.Reduce the broker session timeout as well so that broker failures aredetected more quickly.Reviewers: Jason Gustafson <jason@confluent.io>, Alok Nikhil <anikhil@confluent.io>",5
KAFKA-4458; add per partition in-sync and assigned replica count (KIP-96)Author: Xavier Léauté <xavier@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2186 from xvrl/per-partition-replica-metrics,5
KAFKA-6672; ConfigCommand should create config change parent path if needed (#4727)Change `KafkaZkClient.createConfigChangeNotification` to ensure creation of the change directory. This fixes failing system tests which depend on setting SCRAM credentials prior to broker startup. Existing test case has been modified for new expected usage.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-9472: Remove deleted Connect tasks from status store (#8118)Although the statuses for tasks are removed from the status store when their connector is deleted, their statuses are not removed when only the task is deleted, which happens in the case that the number of tasks for a connector is reduced.This commit adds logic for deleting the statuses for those tasks from the status store whenever a rebalance has completed and the leader of a distributed cluster has detected that there are recently-deleted tasks. Standalone is also updated to accomplish this.Unit tests for the `DistributedHerder` and `StandaloneHerder` classes are updated and an integration test has been added.Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-12522: Cast SMT should allow null value records to pass through (#10375)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Lee Dongjin <dongjin@apache.org>, Chris Egerton  <fearthecellos@gmail.com>",4
"KAFKA-5274: AdminClient Javadoc improvementsPublish Javadoc for common.annotation package, which containsInterfaceStability.Finally, mark AdminClient classes with `Evolving` instead of `Unstable`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Colin Mccabe, Gwen ShapiraCloses #3316 from ijuma/kafka-5274-admin-client-javadoc",2
HOTFIX: add space to avoid checkstyle failure,0
"MINOR: DefaultMessageFormatter custom deserializer fixesThe ability to specify a deserializer for keys and values was added in a recent commit (845c6eae1f6c6bcf11), but it contained a few issues.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #987 from ijuma/console-consumer-cleanups",4
KAFKA-432 allow consumer to read from followers; patched by Yang Ye; reviewed by Neha and Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397422 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9645: Fallback to unsubscribe during Task Migrated (#8220)After #7312, we could still return data during the rebalance phase, which means it could be possible to find records without corresponding tasks. We have to fallback to the unsubscribe mode during task migrated as the assignment should be cleared out to keep sync with task manager state.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-6418; AdminClient should handle empty or null topic names better (#4470),1
"MINOR: Remove unused SecurityProtocol.TRACEIt adds complexity for no benefit since we don't useit anywhere.Also removed a few unused imports, variables anddefault parameters.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>Closes #3856 from ijuma/remove-security-protocol-trace",4
"MINOR: Add Streams system test for broker backwards compatibilityAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2403 from mjsax/addStreamsClientCompatibilityTest",3
"KAFKA-7414; Out of range errors should never be fatal for follower (#5654)This patch fixes the inconsistent handling of out of range errors in the replica fetcher. Previously we would raise a fatal error if the follower's offset is ahead of the leader's and unclean leader election is not enabled. The behavior was inconsistent depending on the message format. With KIP-101/KIP-279 and the new message format, upon becoming a follower, the replica would use leader epoch information to reconcile the end of the log with the leader and simply truncate. Additionally, with the old format, the check is not really bulletproof for detecting data loss since the unclean leader's end offset might have already caught up to the follower's offset at the time of its initial fetch or when it queries for the current log end offset.With this patch, we simply skip the unclean leader election check and allow the needed truncation to occur. When the truncation offset is below the high watermark, a warning will be logged. This makes the behavior consistent for all message formats and removes a scenario in which an error on one partition can bring the broker down.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",0
KAFKA-1910; Refactor new consumer and fixed a bunch of corner cases / unit tests; reviewed by Onur Karaman and Jay Kreps,3
"MINOR: Make the build compile with Scala 2.13 (#6989)Scala 2.13 support was added to build via #5454. This PR adjusts the code so thatit compiles with 2.11, 2.12 and 2.13.Changes:* Add `scala-collection-compat` dependency.* Import `scala.collection.Seq` in a number of places for consistent behavior betweenScala 2.11, 2.12 and 2.13.* Remove wildcard imports that were causing the Java classes to have priority over theScala ones, related Scala issue: https://github.com/scala/scala/pull/6589.* Replace parallel collection usage with `Future`. The former is no longer included bydefault in the standard library.* Replace val _: Unit workaround with one that is more concise and works with Scala 2.13* Replace `filterKeys` with `filter` when we expect a `Map`. `filterKeys` returns a viewthat doesn't implement the `Map` trait in Scala 2.13.* Replace `mapValues` with `map` or add a `toMap` as an additional transformationwhen we expect a `Map`. `mapValues` returns a view that doesn't implement the`Map` trait in Scala 2.13.* Replace `breakOut` with `iterator` and `to`, `breakOut` was removed in Scala2.13.* Replace to() with toMap, toIndexedSeq and toSet* Replace `mutable.Buffer.--` with `filterNot`.* ControlException is an abstract class in Scala 2.13.* Variable arguments can only receive arrays or immutable.Seq in Scala 2.13.* Use `Factory` instead of `CanBuildFrom` in DecodeJson. `CanBuildFrom` behavesa bit differently in Scala 2.13 and it's been deprecated. `Factory` has the behaviorwe need and it's available via the compat library.* Fix failing tests due to behavior change in Scala 2.13,""Map.values.map is not strict in Scala 2.13"" (https://github.com/scala/bug/issues/11589).* Use Java collections instead of Scala ones in StreamResetter (a Java class).* Adjust CheckpointFile.write to take an `Iterable` instead of `Seq` to avoidunnecessary collection copies.* Fix DelayedElectLeader to use a Map instead of Set and avoid `to` call thatdoesn't work in Scala 2.13.* Use unordered map for mapping in SimpleAclAuthorizer, mapping of orderedmaps require an `Ordering` in Scala 2.13 for safety reasons.* Adapt `ConsumerGroupCommand` to compile with Scala 2.13.* CoreUtils.min takes an `Iterable` instead of `TraversableOnce`, the latter doesnot exist in Scala 2.13.* Replace `Unit` with `()` in a couple places. Scala 2.13 is stricter when it expectsa value instead of a type.* Fix bug in CustomQuotaCallbackTest where we did not necessarily set `partitionRatio`correctly, `forall` can terminate early.* Add a couple of spotbugs exclusions that are needed by code generated by Scala 2.13* Remove unused variables, simplify some code and remove procedure syntax in a fewplaces.* Remove unused `CoreUtils.JSONEscapeString`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"MINOR: Bump admin client retries for creating repartition topics (#6063)The topology optimization test was getting intermittent failures because of failures to create repartition topics on startup. This PR Increased admin client retriesI kicked off the system test with 25 repeats, all passed http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2018-12-21--001.1545436859--bbejeck--MINOR_flaky_optimization_test_create_repartition_fails--6cd55e2/report.htmlReviewers: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4079; Documentation for secure quotasDetails in KIP-55.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1847 from rajinisivaram/KAFKA-4079,5
"KAFKA-13345: Use ""delete"" cleanup policy for windowed stores if duplicates are enabled (#11380)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>",5
MINOR: Update shell scripts to support z/OS system (#7913)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"KAFKA-4631; Request metadata in consumer if topic/partitions unavailableIf leader node of one more more partitions in a consumer subscription are temporarily unavailable, request metadata refresh so that partitions skipped for assignment dont have to wait for metadata expiry before reassignment. Metadata refresh is also requested if a subscribe topic or assigned partition doesn't exist.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2622 from rajinisivaram/KAFKA-4631",5
"KAFKA-8705: Remove parent node after leaving loop to prevent NPE (#7117)Fixes case where multiple children merged from a key-changing node causes an NPE.Reviewers:  Matthias J. Sax <mjsax@apache.org>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-8586: Fail source tasks when producers fail to send records (#6993)Changed Connect's `WorkerSourceTask` to capture non-retriable exceptions from the `producer.send(...)` (e.g., authentication or authorization errors) and to fail the connector task when such an error is encountered. Modified the existing unit tests to verify this functionality.Note that most producer errors are retriable, and Connect will (by default) set up each producer with 1 max in-flight message and infinite retries. This change only affects non-retriable errors.",0
"MINOR: Fix bug in AdminClient node reassignment following connection failure (#5112)We added logic to reassign nodes in callToSend after a connection failure, but we do not handle the case when there is no node currently available to reassign the request to. This can happen when using MetadataUpdateNodeIdProvider if all of the known nodes are blacked out awaiting the retry backoff. To fix this, we need to ensure that the call is added to pendingCalls if a new node cannot be found.",1
MINOR: Remove unused `scalatest` definition from `dependencies.gradle` (#10655)Related PR where the `scalatest` usage was removed: #9858Reviewers: Ismael Juma <ismael@juma.me.uk>,4
KAFKA-1760: New consumer.,1
"KAFKA-12326: Corrected regresion in MirrorMaker 2 executable introduced with KAFKA-10021 (#10122)Fixes the recent change to the `MirrorMaker` class (used only in the MirrorMaker 2 executable) that uses a `SharedTopicAdmin` client as part of Connect, so that the correct properties into the `SharedTopicAdmin`.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"MINOR: Fix bug where we would incorrectly load partition reassignment info from ZK (#7334)Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",5
"KAFKA-5273: Make KafkaConsumer.committed query the server for all partitionsBefore this patch the consumer would return the cached offsets for partitions in its current assignment. This worked when all the offset commits went through the consumer.With KIP-98, offsets can be committed transactionally through the producer. This means that relying on cached positions in the consumer returns incorrect information: since commits go through the producer, the cache is never updated.Hence we need to update the `KafkaConsumer.committed` method to always lookup the server for the last committed offset to ensure it gets the correct information every time.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson, Guozhang WangCloses #3119 from apurvam/KAFKA-5273-kafkaconsumer-committed-should-always-hit-server",5
"KAFKA-3060: Refactor MeteredStore and RockDBStore ImplChanges include:1) Move logging logic from MeteredXXXStore to internal stores, and leave WindowedStore API clean by removed all internalPut/Get functions.2) Wrap common logging behavior of InMemory and LRUCache stores into one class.3) Fix a bug for StoreChangeLogger where byte arrays are not comparable in HashSet by using a specified RawStoreChangeLogger.4) Add a caching layer on top of RocksDBStore with object caching, it relies on the object's equals and hashCode function to be consistent with serdes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #826 from guozhangwang/K3060",5
KAFKA-651 Add system tests for auto create topic; reviewed by Neha Narkhede,1
"MINOR: fix the path metadata shell uses for client quotas (#11437)Client quotas should appear under /client-quotas rather than /configs, since client quotas arenot configs. Additionally we should correctly handle the case where the entity name is null(aka ""default"" quotas.)Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-10017: fix uncaucht-exception handling in EosBetaUpgradeIntegrationTest (#9733)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Fix wrong configuration in Adding and Removing Listeners docs (#11992)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
DOCS: Update protocol doc for missing data type (#10162)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-4788: Revert ""KAFKA-4092: retention.bytes should not be allowed to be less than segment.bytes""The intent is good, but it needs to take into account broker configs as well.See KAFKA-4788 for more details.This reverts commit 4ca5abe8ee7578f602fb7653cb8a09640607ea85.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #2588 from ijuma/kafka-4788",4
"KAFKA-3968: fsync the parent directory of a segment file when the file is created (#10405)Kafka does not call fsync() on the directory when a new log segment is created and flushed to disk.The problem is that following sequence of calls doesn't guarantee file durability:fd = open(""log"", O_RDWR | O_CREATE); // suppose open creates ""log""write(fd);fsync(fd);If the system crashes after fsync() but before the parent directory has been flushed to disk, the log file can disappear.This PR is to flush the directory when flush() is called for the first time.Reviewers: Jun Rao <junrao@gmail.com>",2
"KAFKA-3258; Delete broker topic metrics of deleted topicsDelete per-topic metrics when there are no replicas of any partitions of the topic on a broker.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Manikumar reddy O <manikumar.reddy@gmail.com>, Ashish Singh <asingh@cloudera.com, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #944 from rajinisivaram/KAFKA-3258",5
"KAFKA-3112; Warn instead of error on unresolvable bootstrap serverso that unresolvable DNS names are ignored and only throw an error if no other bootstrap servers are resolvable.Author: Jonathan Bond <jbond@netflix.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #792 from bondj/KAFKA-3112",0
"KAFKA-9501: convert between active and standby without closing stores (#8248)This PR has gone through several significant transitions of its own, but here's the latest:* TaskManager just collects the tasks to transition and refers to the active/standby task creator to handle closing & recycling the old task and creating the new one. If we ever hit an exception during the close, we bail and close all the remaining tasks as dirty.* The task creators tell the task to ""close but recycle state"". If this is successful, it tells the recycled processor context and state manager that they should transition to the new type.* During ""close and recycle"" the task just does a normal clean close, but instead of closing the state manager it informs it to recycle itself: maintain all of its store information (most importantly the current store offsets) but unregister the changelogs from the changelog reader* The new task will (re-)register its changelogs during initialization, but skip re-registering any stores. It will still read the checkpoint file, but only use the written offsets if the store offsets are not already initialized from pre-transition* To ensure we don't end up with manual compaction disabled for standbys, we have to call the state restore listener's onRestoreEnd for any active restoring stores that are switching to standbysReviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
HOTFIX: Fix main classpath libs glob for release (fixup KAFKA-3615 regression)bin/kafka-run-class.sh does not correctly setup the CLASSPATH in release rc2.Author: Dana Powers <dana.powers@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1302 from dpkp/KAFKA-3615-fix,0
"KAFKA-2929: Migrate duplicate error mapping functionalityDeprecates ErrorMapping.scala in core in favor or Errors.java in common.Duplicated exceptions in core are deprecated as well, to ensure the mapping is correct.Author: Grant Henke <granthenke@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #616 from granthenke/error-mapping",0
Kafka-10064 Add documentation for KIP-571 (#8760)* Update documentation for KIP-571* update doc for KIP-571* fix comments,0
KAFKA-10403: Replace Scala collection by Java collection in Log4jController (#9182)This removes the need to have the Scala library in the classpathwhen deserializing the MBean.Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-12288: remove task-level filesystem locks (#10342)The filesystem locks don't protect access between StreamThreads, only across different instances of the same Streams application. Running multiple processes in the same physical state directory is not supported, and as of PR #9978 it's explicitly guarded against), so there's no reason to continue locking the task directories with anything heavier than an in-memory map.Reviewers: Rohan Desai <rodesai@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-12596: remove --zookeeper option from topic command (#10457)Also:* Remove `ZookeeperTopicService`* Remove `TopicCommandWithZKClientTest`* Fix a topic create validation bug* Adjust existing testsReviewers: Ismael Juma <ismael@juma.me.uk>,3
KAFKA-5388; Replace ZkClient.subscribe*Changes methods with equivalent ZkUtils methodsAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3281 from baluchicken/KAFKA-5388,4
"KAFKA-7855: Kafka Streams Maven Archetype quickstart fails to compile out of the box (#6194)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Improve javadoc of user-customizable metrics API (#7810)Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",1
"KAFKA-3699: Update protocol page on website to explain how KIP-35 should be used…uld be usedAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Oleksiy Krivoshey <oleksiy@luckyteam.co.uk>, Gwen Shapira <cshapi@gmail.com>, Magnus Edenhill <magnus@edenhill.se>, Dana Powers <dana.powers@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1395 from SinghAsDev/KAFKA-3699",5
MINOR: Handle nulls in NonEmptyListValidatorAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3045 from ewencp/minor-non-empty-list-validator-nulls,5
MINOR: KIP-631 KafkaConfig fixes and improvements (#10114)Add the new KIP-631 configs to KafkaConfigTest to fix the test failure.Rename InitialBrokerRegistrationTimeoutMs toInitialBrokerRegistrationTimeoutMsProp for consistency with the otherproperties.Add ControllerListenerNamesProp as specified in KIP-631.Give nodeId and brokerId the same value in KafkaConfig.Reviewers: David Arthur <mumrah@gmail.com,5
"MINOR: refactor how ConfigurationControl checks for resource existence (#11835)ConfigurationControl methods should take a boolean indicating whether the resource is newlycreated, rather than taking an existence checker object. The boolean is easier to understand. Alsoadd a unit test of existing checking failing (and succeeding).Reviewers: Kirk True <kirk@mustardgrain.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"MINOR: Upgrade gradle plugins and test libraries for Java 14 support (#8519)Also:* Remove deprecated `=` in resolutionStrategy.* Replace `AES/GCM/PKCS5Padding` with `AES/GCM/NoPadding`in `PasswordEncoderTest`. The former is invalid and JDK 14 rejects it,see https://bugs.openjdk.java.net/browse/JDK-8229043.With these changes, the build works with Java 14 and Scala 2.12. Thesame will apply to Scala 2.13 when Scala 2.13.2 is released (shouldhappen within 1-2 weeks).Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
Change MessageSet.sizeInBytes to Int; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-556git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401760 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Remove unused variable (#9303)Reviewers: John Roesler <vvcephei@apache.org>,1
MINOR: Update `config/consumer.properties` to have new consumer propertiesAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4055 from omkreddy/update-consumer-props,5
"KAFKA-1053 Kafka patch review tool that integrates JIRA and reviewboard; reviewed by Joel Koshy, Swapnil Ghike and Guozhang Wang",5
"MINOR: fix shouldWaitForMissingInputTopicsToBeCreated test (#11902)This test was falling occasionally. It does appear to be a matter of the tests assuming perfecting deduplication/caching when asserting the test output records, ie a bug in the test not in the real code. Since we are not assuming that it is going to be perfect I changed the test to make sure the records we expect arrive, instead of only those arrive.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"HOTFIX: WindowedStreamPartitioner does not provide topic name to serializerAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2777 from mjsax/hotfix-window-serdes-trunk",0
KAFKA-4883: handle NullPointerException while parsing login modue control flag (#4849),2
"KAFKA-12879: Revert changes from KAFKA-12339 and instead add retry capability to KafkaBasedLog (#11797)Fixes the compatibility issue regarding KAFKA-12879 by reverting the changes to the admin client from KAFKA-12339 (#10152) that retry admin client operations, and instead perform the retries within Connect's `KafkaBasedLog` during startup via a new `TopicAdmin.retryEndOffsets(..)` method. This method delegates to the existing `TopicAdmin.endOffsets(...)` method, but will retry on `RetriableException` until the retry timeout elapses.This change should be backward compatible to the KAFKA-12339 so that when Connect's `KafkaBasedLog` starts up it will retry attempts to read the end offsets for the log's topic. The `KafkaBasedLog` existing thread already has its own retry logic, and this is not changed.Added more unit tests, and thoroughly tested the new `RetryUtil` used to encapsulate the parameterized retry logic around any supplied function.",1
"MINOR: Fix small spelling error (#5760)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-10391: Overwrite checkpoint in task corruption to remove corrupted partitions (#9170)In order to do this, I also removed the optimization such that once enforced checkpoint is set to true, we always checkpoint unless the state stores are not initialized at all (i.e. the snapshot is null).Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@gmail.com>",5
"MINOR: Reduce build time by gating test coverage plugins behind a flag (#8899)Most builds don't require test coverage output, so it's wastefulto spend cycles tracking coverage information for each methodinvoked.I ran a quick test in a fast desktop machine, the absolutedifference will be larger in a slower machine. The tests wereexecuted after `./gradlew clean` and with a gradle daemonthat was started just before the test (and mildly warmed upby running `./gradlew clean` again).`./gradlew unitTest --continue --profile`:* With coverage enabled: 6m32s* With coverage disabled: 5m47sI ran the same test twice and the results were within 2s ofeach other, so reasonably consistent.16% reduction in the time taken to run the unit tests is areasonable gain with little downside, so I think this is agood change.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",4
MINOR: Refactor abstractConfig#configuredInstance (#7129)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-7335; Store clusterId locally to ensure broker joins the right cluster (#7189)This patch stores `clusterId` in the `meta.properties` file. During startup, the broker checks that it joins the correct cluster and fails fast otherwise.The `meta.properties' is versioned. I have decided to not bump the version because 1) the clusterId is null anyway if not present in the file; and 2) bumping it means that rolling back to a previous version won't work.I have refactored the way the metadata is read and written as it was strongly coupled with the brokerId bits. Now, the metadata is read independently during the startup and used to 1) check the clusterId and 2) get or generate the brokerId (as before).Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9748: Add Streams eos-beta integration test (#8496)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-8601: Add UniformStickyPartitioner and tests (#7199)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
"KAFKA-10810: Replace stream threads (#9697)StreamThreads can now be replaced in the streams uncaught exception handlerReviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>, Leah Thomas <lthomas@confluent.io>",5
"MINOR: Update to Gradle 2.9 and update generated `gradlew` fileMore performance improvements:""In many cases, Gradle 2.9 is much faster than Gradle 2.8 when performing incremental builds.Very large builds (many thousands of source files) could see incremental build speeds up to 80% faster than 2.7 and up to 40% faster than 2.8.Gradle now uses a more efficient mechanism to scan the filesystem, making up-to-date checks significantly faster. This improvement is only available when running Gradle with Java 7 or newer.Other improvements have been made to speed-up include and exclude pattern evaluation; these improvements apply to all supported Java versions.Gradle now uses much less memory than previous releases when performing incremental builds. By de-duplicating Strings used as file paths in internal caches, and by reducing the overhead of listing classes under test for Java projects, some builds use 30-70% less memory that Gradle 2.8.""https://docs.gradle.org/current/release-notesAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Guozhang WangCloses #549 from ijuma/gradle-2.9",2
MINOR: Remove no longer required --new-consumer switch in docsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1905 from ijuma/no-new-consumer-switch-in-examples,1
"MINOR: A few cleanups of usage of Either in TCAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3284 from hachikuji/minor-either-usage-cleanup",4
"HOTFIX: Check hasNext in KStreamWindowReduceAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Matthias J. SaxCloses #1520 from guozhangwang/KHotfix-iter-hasNext-window-value-getter",0
HOTFIX: Fix verification of version probing (#10943)Fixes and improves version probing in system test test_version_probing_upgrade().,3
HOTFIX: fix partition ordering in assignmentworkround partition ordering not preserved by the consumer group management.guozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #868 from ymatsuda/partitionOrder,5
KAFKA-9024: Better error message when field specified does not exist (#7819)Author: Nigel Liang <nigel@nigelliang.com>Reviewer: Randall Hauch <rhauch@gmail.com>,0
"KAFKA-12967; KRaft broker should forward DescribeQuorum to controller (#10900)We added the DescribeQuorum API in KIP-595. This patch adds the logic to forward DescribeQuorum requests to the controller when KRaft is enabled. The KRaft broker listener has already been enabled in DescribeQuorumRequest.json. The zk broker is not enabled, however, so DescribeQuorum requests will not be advertised and will be rejected at the network layer.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, David Arthur <mumrah@gmail.com>",1
KAFKA-1499; trivial follow-up (remove unnecessary parentheses),4
MINOR: Vagrant provisioning fixesAuthor: Magnus Edenhill <magnus@edenhill.se>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2767 from edenhill/harden_provision,5
"HOTFIX: only try to clear discover-coordinator future upon commit (#12244)This is another way of fixing KAFKA-13563 other than #11631.Instead of letting the consumer to always try to discover coordinator in pool with either mode (subscribe / assign), we defer the clearance of discover future upon committing async only. More specifically, under manual assign mode, there are only three places where we need the coordinator:* commitAsync (both by the consumer itself or triggered by caller), this is where we want to fix.* commitSync, which we already try to re-discovery coordinator.* committed (both by the consumer itself based on reset policy, or triggered by caller), which we already try to re-discovery coordinator.The benefits are that for manual assign mode that does not try to trigger any of the above three, then we never would be discovering coordinator. The original fix in #11631 would let the consumer to discover coordinator even if none of the above operations are required.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR; Clean up LeaderAndIsrResponse construction in `ReplicaManager#becomeLeaderOrFollower` (#10234)This patch refactors the code, which constructs the `LeaderAndIsrResponse` in `ReplicaManager#becomeLeaderOrFollower`, to improve the readability and to remove unnecessary operations.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",4
"KAFKA-7372: Upgrade Jetty for preliminary Java 11 and TLS 1.3 support (#5600)""Jetty 9.4.12 includes compatibility for JDK 11. Additionally, TLS 1.3 support has been implemented. While full functionality for new JDK features is not yet supported, this release has been built and tested for compatibility with the latest releases from Oracle.""http://dev.eclipse.org/mhonarc/lists/jetty-announce/msg00124.htmlReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: double -Xss setting from 2m to 4m in build.gradle (#8264)I have seen an increased incidence in StackOverflowError(s) when compiling scala. Thischange doubles the max stack size to 4m.```> Task :core:compileScala FAILEDFAILURE: Build failed with an exception.* What went wrong:Execution failed for task ':core:compileScala'.> java.lang.StackOverflowError (no error message)```Reviewers: Andrew Choi <a24choi@edu.uwaterloo.ca>, Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-9888: Copy connector configs before passing to REST extensions (#8511)The changes made in KIP-454 involved adding a `connectorConfig` method to the ConnectClusterState interface that REST extensions could use to query the worker for the configuration of a given connector. The implementation for this method returns the Java `Map` that's stored in the worker's view of the config topic (when running in distributed mode). No copying is performed, which causes mutations of that `Map` to persist across invocations of `connectorConfig` and, even worse, propagate to the worker when, e.g., starting a connector.In this commit the map is copied before it's returned to REST extensions.An existing unit test is modified to ensure that REST extensions receive a copy of the connector config, not the original.Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",5
trivial fix to include violated payload size in MessageSizeTooLargeException; patched by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1298030 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA4811; ReplicaFetchThread may fail to create due to existing metricHave fetcherThreadMap keyed off brokerId + fetcherId instead of broker + fetcherId, but did not consider the case where port is changed.Author: huxi <huxi@zhenrongbao.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2606 from amethystic/kafka4811_ReplicaFetchThread_fail_create",0
"MINOR: Rework NewPartitionReassignment public API (#7638)This patch removes the NewPartitionReassignment#of() method in favor of a simple constructor. Said method was confusing due to breaking two conventions - always returning a non-empty Optional and thus not being used as a static factory method.Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",1
"MINOR: Fix unexpected request error in kraft shutdown (#12538)We have been seeing a few exceptions like the following when running integration tests:```[2022-08-18 13:02:59,470] ERROR [ControllerApis nodeId=3000] Unexpected error handling request RequestHeader(apiKey=FETCH, apiVersion=13, clientId=raft-client-0, correlationId=7) -- FetchRequestData(clusterId='txpo87ZUSbGSeV2v7H0n_w', replicaId=0, maxWaitMs=500, minBytes=0, maxBytes=8388608, isolationLevel=0, sessionId=0, sessionEpoch=-1, topics=[FetchTopic(topic='__cluster_metadata', topicId=AAAAAAAAAAAAAAAAAAAAAQ, partitions=[FetchPartition(partition=0, currentLeaderEpoch=1, fetchOffset=6, lastFetchedEpoch=1, logStartOffset=-1, partitionMaxBytes=0)])], forgottenTopicsData=[], rackId='') with context RequestContext(header=RequestHeader(apiKey=FETCH, apiVersion=13, clientId=raft-client-0, correlationId=7), connectionId='127.0.0.1:63113-127.0.0.1:63114-0', clientAddress=/127.0.0.1, principal=User:ANONYMOUS, listenerName=ListenerName(CONTROLLER), securityProtocol=PLAINTEXT, clientInformation=ClientInformation(softwareName=apache-kafka-java, softwareVersion=unknown), fromPrivilegedListener=false, principalSerde=Optional[org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder@201038c3]) (kafka.server.ControllerApis:76)java.util.concurrent.CompletionException: java.util.NoSuchElementException: key not found: BROKER_NOT_AVAILABLEat java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:315)at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:320)at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:936)at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)at org.apache.kafka.raft.KafkaRaftClient.lambda$handleRequest$19(KafkaRaftClient.java:1666)at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)at kafka.raft.TimingWheelExpirationService$TimerTaskCompletableFuture.run(TimingWheelExpirationService.scala:32)at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)at java.base/java.lang.Thread.run(Thread.java:833)Caused by: java.util.NoSuchElementException: key not found: BROKER_NOT_AVAILABLE```There are two causes for this error that I found. First, we were not shutting down the timer services in `RaftManager` which are used in the purgatory implementation. This meant that operations remaining in purgatory could be completed even after `RaftManager` was shutdown. Second, the shutdown order in `KafkaClusterTestKit` was problematic. The `RaftManager` instance depends on the `SocketServer` in `ControllerServer`, but it was the latter that was shutdown first. Instead, we should shutdown `RaftManager` first as we do in `KafkaRaftServer`. Reviewers: Ismael Juma <ismael@juma.me.uk>",0
KAFKA-6835: Enable topic unclean leader election to be enabled without controller change (#4957)Reviewers: Jun Rao <junrao@gmail.com>,4
"KAFKA-4607: Validate the names of auto-generated internal topicsI considered catching errors to add further information about naming internal state stores. However, Topic.validate() will throw an error that prints the offending name, so I decided not to add too much complexity.Author: Nikki Thean <nthean@etsy.com>Reviewers: Matthias J. Sax, Guozhang Wang, Eno Thereska, Damian Guy, Ismael JumaCloses #2331 from nixsticks/internal-topics",1
"KAFKA-7588: Pass custom configs to the ChannelBuilder implementations (#1037) (#7794)Provide custom configs to ChannelBuilders in addition to parsed `values()`Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Andrew Choi <andchoi@linkedin.com",2
Upgrade to metrics jar to 3.x to pick up csv reporter fixes; KAFKA-542; patched by Joel Koshy; reviewed by Neha Narkhede.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396336 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-1055 BrokerTopicStats should distinguish between messages received and messages actually appended (i.e., not dropped for various reasons).",4
KAFKA-8887; Use purgatory for ACL updates using async authorizers (#7404)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"KAFKA-2978: consumer stops fetching when consumed and fetch positions get out of syncAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Michal Turek, Ismael Juma, Guozhang WangCloses #666 from hachikuji/KAFKA-2978",5
"MINOR: Provide better messages when waiting for a condition in test (#7488)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-12237; Support lazy initialization of quorum voter addresses (#9985)With KIP-595, we previously expect `RaftConfig` to specify the quorum voter endpoints upfront on startup. In the general case, this works fine. However, for testing where the bound port is not known ahead of time, we need a lazier approach that discovers the other voters in the quorum after startup. In this patch, we take the voter endpoint initialization out of `KafkaRaftClient.initialize` and move it to `RaftManager`. We use a special address to indicate that the voter addresses will be provided later This approach also lends itself well to future use cases where we might discover voter addresses through an external service (for example).Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: prefix topics if internal config is set (#11611)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Implement toString for NetworkClient#InFlightRequestAuthor: Bryan Baugher <bryan.baugher@cerner.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3805 from bbaugher/inFlightRequest_toString,5
"KAFKA-6886: Externalize secrets from Connect configs (KIP-297)This commit allows secrets in Connect configs to be externalized and replaced with variable references of the form `${provider:[path:]key}`, where the ""path"" is optional.There are 2 main additions to `org.apache.kafka.common.config`: a `ConfigProvider` and a `ConfigTransformer`.  The `ConfigProvider` is an interface that allows key-value pairs to be provided by an external source for a given ""path"".  An a TTL can be associated with the key-value pairs returned from the path.  The `ConfigTransformer` will use instances of `ConfigProvider` to replace variable references in a set of configuration values.In the Connect framework, `ConfigProvider` classes can be specified in the worker config, and then variable references can be used in the connector config.  In addition, the herder can be configured to restart connectors (or not) based on the TTL returned from a `ConfigProvider`.  The main class that performs restarts and transformations is `WorkerConfigTransformer`.Finally, a `configs()` method has been added to both `SourceTaskContext` and `SinkTaskContext`.  This allows connectors to get configs with variables replaced by the latest values from instances of `ConfigProvider`.Most of the other changes in the Connect framework are threading various objects through classes to enable the above functionality.Author: Robert Yokota <rayokota@gmail.com>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5068 from rayokota/KAFKA-6886-connect-secrets",5
"KAFKA-4417: Update build dependencies for 0.10.2 cycleNotes on the updates:* Gradle to 3.2: better incremental build and faster IDE import times (https://docs.gradle.org/3.2/release-notes)* zkclient to 0.10: it now uses slf4j-api instead of log4j* zookeeper to 3.4.9: a few important bug fixes (http://zookeeper.apache.org/doc/r3.4.9/releasenotes.html)* jackson to 2.8.5: lots of updates (https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.6, https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.7, https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.8)* jersey to 2.24: bug fixes (https://jersey.java.net/release-notes/2.23.html, https://jersey.java.net/release-notes/2.24.html)* jopt to 5.0.3: minor improvements, the major version bump is due to requiring Java 7 instead of 6 (https://pholser.github.io/jopt-simple/changes.html)* argparse4j to 0.7.0: minor tweaks and improvements (https://github.com/tatsuhiro-t/argparse4j/blob/argparse4j-0.6.0/NEWS, https://github.com/tatsuhiro-t/argparse4j/blob/argparse4j-0.7.0/NEWS)* Gradle plugins* bcpkix to 1.55: quite a few additions, but nothing that matters to us (http://www.bouncycastle.org/releasenotes.html)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2144 from ijuma/gradle-3.2-and-deps",5
kafka-1670 (followup to fix system tests); Corrupt log files for segment.bytes values close to Int.MaxInt; patched by Sriharsha Chintalapani; reviewed by Jun Rao,2
MINOR: Fix flaky HighAvailabilityTaskAssignorIntegrationTest (#8884)Reduce test data set from 1000 records to 500.Some recent test failures indicate that the Jenkins runners aren'table to process all 1000 records in two minutes.Also add sanity check that all the test data are readable from theinput topic.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
KAFKA-13618: Fix typo in BatchAccumulator (#11715)Co-authored-by: Kvicii <Karonazaba@gmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
KAFKA-9701: Add more debug log on client to reproduce the issue (#8272)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
MINOR: Fix some field definitions for ListOffsetReponse (#6214)Reviewers: Jun Rao <junrao@gmail.com>,1
"MINOR: Reduce ZK reads and ensure ZK watch is set for listener update (#4670)Ensures that ZK watch is set for each live broker for listener update notifications in the controller. Also avoids reading all brokers from ZooKeeper when a broker metadata is modified by passing in brokerId to BrokerModifications and reading only the updated broker.The existing listener update test verifies both these changes. Earlier, the test did not detect missing watch for the last broker since metadata of all brokers were read from ZK (adding a watch for all) when any broker was updated.Reviewers: Jun Rao <junrao@gmail.com>",5
MINOR: Fix incorrect log for out-of-order KTable (#11905)Reviewers: Luke Chen <showuon@gmail.com>,2
kafka-2103; kafka.producer.AsyncProducerTest failure; patched by Ewen Cheslack-Postava; reviewed by Jun Rao,0
MINOR: Fix comments in KStreamKStreamJoinTestMinor comment fixes.Author: Elias Levy <fearsome.lucidity@gmail.com>Reviewers: Guozhang WangCloses #1885 from eliaslevy/fix-test-comments,3
"KAFKA-4986; Producer per StreamTask support (KIP-129)Enable producer per task if exactly-once config is enabled.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2773 from mjsax/exactly-once-streams-producer-per-task",5
KAFKA-4165; Add 0.10.0.1 as a source for compatibility testsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1959 from hachikuji/KAFKA-4165,5
"MINOR: Adjust checkstyle suppression paths to work on WindowsUse the file name whenever possible and replace / with [/\\]when it's not.Also remove unnecessary suppresions.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>Closes #3431 from ijuma/fix-checkstyle-suppressions-on-windows",0
MINOR: catch a commit failure due to rebalance in StreamThreadStreamThread should keep going after a commit was failed due to a group rebalance.Currently the thread just dies.guozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #933 from ymatsuda/catch_commit_failure,0
"KAFKA-10616: Always call prepare-commit before suspending for active tasks (#9464)Today for active tasks we the following active task suspension:1. closeAndRevive in handleTaskCorruption.2. closeClean in assignor#onAssignment.3. closeClean in shutdown.4. closeDirty in assignor#onAssignment.5. closeDirty in listener#onPartitionsLost.6. closeDirty in shutdown.7. suspend in listener#onPartitionsRevoked.Among those, 1/4/5/6 do not call prepareCommit which would stateManager#flushCache and may cause illegal state manager. This PR would require a prepareCommit triggered before suspend.Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",1
"KAFKA-2851 Using random file names for local kdc files to avoid conflicts.I originally tried to solve the problem by using tempfile, and creating and using scp() utility method that created a random local temp file every time it was called. However, it required passing miniKdc object to SecurityConfig setup_node which looked very invasive, since many tests use this method. Here is the PR for that, which I think we will close: https://github.com/apache/kafka/pull/609This change is the least invasive change to solve conflicts between multiple tests jobs.Author: Anna Povzner <anna@confluent.io>Reviewers: Geoff AndersonCloses #610 from apovzner/kafka_2851_01",5
"KAFKA-2371: Add distributed support for Copycat.This adds coordination between DistributedHerders using the generalized consumersupport, allowing automatic balancing of connectors and tasks across workers. Afew pieces that require interaction between workers (resolving configinconsistencies, forwarding of configuration changes to the leader worker) areincomplete because they require REST API support to implement properly.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson, Gwen ShapiraCloses #321 from ewencp/kafka-2371-distributed-herder",1
KAFKA-12931: KIP-746: Revise KRaft Metadata Records (#10867)Implement the metadata records changes described in KIP-746. Fix unittests as needed.Reviewers: David Arthur <mumrah@gmail.com>,3
"KAFKA-10052: Harden assertion of topic settings in Connect integration tests (#8735)A recently added assertion in Connect integration tests uses `KafkaConsumer#partitionsFor` to verify that a topic was created with the expected number of partitions and replicas. However, probably because of metadata propagation delays, this call doesn't always return a valid `PartitionInfo` for the topic that has just been created and the test is terminated with a NPE. This commit changes the assertion to perform retries in order to verify the topic settings and uses the admin client to describe the topics instead.Tests have been adjusted to use the new assertion. Reviewers: Randall Hauch <rhauch@gmail.com>",3
"KAFKA-2531: Add Ducktape based tests for KafkaLog4jAppenderAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Geoff Anderson, Edwerd Ribeiro, Ewen Cheslack-Postava, Gwen ShapiraCloses #235 from SinghAsDev/KAFKA-2531",2
"MINOR: Modify Connect service's startup timeout to be passed via the init (#5882)Currently, the startup timeout is hardcoded to be 60 seconds in Connect's test service. Modifying it to be passable via init. This can safely be backported as well.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Make link in quickstart dynamic (#12057)Reviewer: Matthias J. Sax <mjsax@apache.org>,2
KAFKA-139 cross-compile multiple Scala versions and upgrade to SBT 0.12.1 patch by Derek Chen-Becker reviewed by Joe Stein,5
"MINOR: Use String#format for niceMemoryUnits result (#12389)Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>",1
"MINOR: TestSecurityRollingUpgrade system test fixes (#10886)The TestSecurityRollingUpgrade. test_disable_separate_interbroker_listener() system test had a design flaw: it was migrating inter-broker communication from a SASL_SSL listener to an SSL listener in one roll while immediately removing the SASL_SSL listener in that roll. This requires two rolls because the existing SASL_SSL listener must remain available throughout the first roll so that unrolled brokers can continue to communicate with rolled brokers throughout. This patch adds the second roll to this test and removes the original SASL_SSL listener on that second roll instead of the first one. The test was not failing all the time -- it was flaky.The TestSecurityRollingUpgrade.test_rolling_upgrade_phase_two() system test was not explicitly identifying the SASL mechanism to enable on a third port when that port was using SASL but the client security protocol was not SASL-based. This was resulting in an empty sasl.enabled.mechanisms config, which applied to that third port, and then when the cluster was rolled to take advantage of this third port for inter-broker communication the potential for an inability to communicate with other, unrolled brokers existed (similar to above, this resulted in a flaky test).Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-13916; Fenced replicas should not be allowed to join the ISR in KRaft (#12240)This PR implements the first part of KIP-841. Specifically, it implements the following:1. Adds a new metadata version.2. Adds the InControlledShutdown field to the BrokerRegistrationRecord and BrokerRegistrationChangeRecord and bump their versions. The newest versions are only used if the new metadata version is enabled.3. Writes a BrokerRegistrationChangeRecord with InControlledShutdown set when a broker requests a controlled shutdown.4. Ensures that fenced and in controlled shutdown replicas are not picked as leaders nor included in the ISR.5. Adds or extends unit tests.Reviewes: José Armando García Sancio <jsancio@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>",1
"MINOR: Slight MetadataCache tweaks to avoid unnecessary work (#8728)- Avoid tuple allocations by using `Map.update` instead of `+=`- Use `empty` instead of `apply` to avoid unnecessary array allocationReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Andrew Choi <a24choi@edu.uwaterloo.ca>",5
TRIVIAL: add @throws ConsumerWakeupException in KafkaConsumerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen ShapiraCloses #311 from guozhangwang/wakeupComments,1
"HOTFIX: fix flaky StateDirectoryTest.shouldReturnEmptyArrayIfListFilesReturnsNull (#8310)StateDirectoryTest.shouldReturnEmptyArrayIfListFilesReturnsNull always moves the stage dir to /tmp/state-renamed so it always fails if there is already a folder (for example, the stuff leaved by previous test).Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA 3671: Move topics to SinkConnectorConfigAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Dan Norwood <norwood@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1335 from Ishiihara/sink-connector-config",5
"KAFKA-10168: fix StreamsConfig parameter name variable (#8865)Implements KIP-626.Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-2342; KafkaConsumer rebalance with in-flight fetch can cause invalid positionAuthor: Jason Gustafson <jason@confluent.io>Closes #88 from hachikuji/KAFKA-2342 and squashes the following commits:cabb017 [Jason Gustafson] KAFKA-2342; KafkaConsumer rebalance with in-flight fetch can cause invalid position,1
"HOTFIX: reduce log verbosity on commitAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3414 from mjsax/hotfix-commit-logging",2
KAFKA-4472; offsetRetentionMs miscalculated in GroupCoordinatorFix possible integer overflow.Author: Kim Christensen <kich@mvno.dk>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2200 from kichristensen/MiscalculatedOffsetRetention,1
"MINOR: Use underscore for variable initialization in BrokerServer (#12471)In Scala its standard practice to use _ whenever you are initializing variables. In regards to implementation, for object references _ initialization maps to null so there is no change in behaviour.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>",4
"KAFKA-6813: return to double-counting for count topology names (#5075)#4919 unintentionally changed the topology naming scheme. This change returns to the prior scheme.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-10503: MockProducer doesn't throw ClassCastException when no partition for topic exists (#9309)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-13791: Fix potential race condition in FetchResponse#`fetchData` and `forgottenTopics` (#11981)Fix FetchResponse#`fetchData` and `forgottenTopics`: Assignment of lazy-initialized members should be the last step with double-checked lockingReviewers: Luke Chen <showuon@gmail.com>,5
"KAFKA-5175; Fix transient failure in ControllerIntegrationTest.testPreferredReplicaLeaderElectionThe transient failure came from the controller processing the preferred replica leader electionbefore the restarted broker (the preferred replica leader) has joined isr, causing preferredreplica leader election to fail and for the final zookeeper state validation to fail.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3067 from onurkaraman/KAFKA-5175",2
"MINOR: Link to related class in the Admin `alterPartitionReassignments` documentation (#7912)Also document the parameters of `ReplicaAssignment` in `ControllerContext`.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8578: Add basic functionality to expose RocksDB metrics (#6979)* Adds RocksDBMetrics class that provides methods to get sensors from the Kafka metrics registry and to setup the sensors to record RocksDB metrics* Extends StreamsMetricsImpl with functionality to add the required metrics to the sensors.Reviewers: Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Improve broker id documentationAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael JumaCloses #585 from granthenke/brokerid,2
"KAFKA-4942: Fix commitTimeoutMs being set before the commit actually startedThis fixes KAFKA-4942This supersededs #2730/cc simplesteph gwenshap ewencpAuthor: Nick Pillitteri <nickp@smartertravelmedia.com>Author: simplesteph <stephane.maarek@gmail.com>Reviewers: simplesteph <stephane.maarek@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2912 from 56quarters/fix-connect-offset-commit",0
"MINOR. Update Epoch field descrition in FetchRequest api doc (#7673)The `Epoch` field description was copy of the `SessionId` field. Thischange updates it to describe `Epoch` instead.No code change, only description changes. Code compiles.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-12283: disable flaky testMultipleWorkersRejoining to stabilize build (#10408)Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
"KAFKA-4397: Refactor Connect backing stores for thread safetyAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2123 from kkonstantine/KAFKA-4397-Refactor-connect-backing-stores-for-thread-safety",4
HOTFIX: Add comment to remind ordering restrictions on RegexSourceIntegrationTest (#7812),3
"MINOR: Upgrade gradle to 6.8 and test retry plugin to 1.2.0 (#9849)Also fix generation of `gradlew` when `APP_HOME` contains a directory with spacesin its name.Release notes:* https://docs.gradle.org/6.8/release-notes.html* https://github.com/gradle/test-retry-gradle-plugin/releases/tag/v1.2.0In addition to existing tests, verified that `./gradlewAll jar` succeeds.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",3
"MINOR: Add indent space after hyperlink in `docs/upgrade.html` (#12353)Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Divij Vaidya <divijvaidya13@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9203: Check for buggy LZ4 libraries and remove corresponding workarounds (#10196)* Remove the workarounds that were added back in https://github.com/apache/kafka/pull/7769* Add a check to detect buggy LZ4 library versionsThis check allows us to safely remove the workarounds for buggyLZ4 versions without users encountering cryptic errors if theyaccidentally have an older LZ4 library on the classpath, asdescribed in KAFKA-9203.With this change the use will get a clear error message indicatingwhat the problem might be if they encounter this situation.Note: This now instantiates a compressor in the decompression code.This should be safe with respect to JNI libraries, since we always use`LZ4Factory.fastestInstance()` which takes care of falling back to a pureJava implementation if JNI libraries are not present.This was tested with lz4 1.3.0 to make sure it triggers the exception when running`KafkaLZ4Test`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Co-authored-by: Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-6778; AdminClient.describeConfigs() should return error for non-existent topics (#4866)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-3631; Fix Struct.toString for nullable arrayOfAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1279 from granthenke/struct-fix,0
"KAFKA-3711: Ensure a RecordingMap is passed to configured instancesSee https://issues.apache.org/jira/browse/KAFKA-3711I've tested locally that this change does indeed resolve the warning I mention in the ticket:```org.apache.kafka.clients.consumer.ConsumerConfig: The configuration metric.dropwizard.registry = kafka-metrics was supplied but isn't a known config.```where `metric.dropwizard.registry` is a configuration value defined in a custom `MetricReporter` (https://github.com/SimpleFinance/kafka-dropwizard-reporter).With this change, the above warning no longer appears, as ewencp predicted.This contribution is my original work and I license the work to the project under the project's open source license.Author: Jeff Klukas <jeff@klukas.net>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1479 from jklukas/abstractconfig-originals",5
"KAFKA-6028: Improve the quota throttle communication (KIP-219)This implements KIP-219, where a broker returns a response with throttle time onquota violation immediately after processing the corresponding request.  Afterthe response is sent out, the broker will keep the channel muted until thethrottle time is over. Also, on receiving a response with throttle time, clientwill block outgoing communication to the broker for the specified throttle time.See PR 4830, 5064 and 5094 for all the review historyAuthor: Jon Lee <jonlee@jonlee-ld1.linkedin.biz>Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>,  Dong Lin <lindong28@gmail.com>Closes #5064 from jonlee2/kip-219",5
"MINOR: StopReplicaResp and StopReplicaReq Test should cover all available version (#10068)Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: Code refactor - cleaning up some boolean assignmentsAuthor: Ishita Mandhan <imandha@us.ibm.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>Closes #2013 from imandhan/KAFKA-refactor",4
"KAFKA-10080; Fix race condition on txn completion which can cause duplicate appends (#8782)The method `maybeWriteTxnCompletion` is unsafe for concurrent calls. This can cause duplicate attempts to write the completion record to the log, which can ultimately lead to illegal state errors and possible to correctness violations if another transaction had been started before the duplicate was written. This patch fixes the problem by ensuring only one thread can successfully remove the pending completion from the map.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",4
"MINOR: Improve readability of `tryProcessAlterPartition` (#12515)After 520f72995d, the subsequent checks are ensuring thatthe leader and partition epochs are not less than. So,make that explicit.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-9419: Fix possible integer overflow in CircularIterator (#7950)The CircularIterator class uses a wrapping index-based approach to iterate over a list. This can be a performance problem O(n^2) for a LinkedList. Also, the index counter itself is never reset, a modulo is applied to it for every list access. At some point, it may be possible that the index counter overflows to a negative value and therefore may cause a negative index read and an ArrayIndexOutOfBoundsException.This fix changes the implementation to avoid these two scenarios. Uses the Collection Iterator classes to avoid using an index counter and it avoids having to seek to the correct index every time, this avoiding the LinkedList performance issue.I have added unit tests to validate the new implementation.* KAFKA-9419: Integer Overflow Possible with CircularIterator* Added JavaDoc. Support null values in the underlying collection* Always return true for hasNext(). Add more JavaDoc* Use an advance method to load next value and always return true in hasNext()* Simplify test suite* Use assertThrows in tests and remove redundant 'this' identifierCo-authored-by: David Mollitor <dmollitor@apache.org>Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-4743; [KIP-122] Add Reset Consumer Group Offsets toolingAuthor: Jorge Quilcate <quilcate.jorge@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2624 from jeqo/feature/rewind-consumer-group-offset",1
HOTFIX: delete removed WindowedStore.put() method (#10517)Reviewers: Boyang Chen <boyang@confluent.io>,5
MINOR: Use API hyperlinks in 'Kafka Protocol Guide' to facilitate navigationFinding the protocol associated with an API key can be a challenge in the lengthy [web page](http://kafka.apache.org/protocol.html#protocol_api_keys).Adding hyperlinks would definitely help with that.Co-authored with imandhan.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2467 from vahidhashemian/minor/hyperlinks_in_kafka_protocol_guide,2
HOTFIX: RegexSourceIntegrationTest needs to cleanup shared output topic (#5008)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
KAFKA-13891: reset generation when syncgroup failed with REBALANCE_IN_PROGRESS (#12140)Reviewers: Luke Chen <showuon@gmail.com>,0
"KAFKA-12887 Skip some RuntimeExceptions from exception handler (#11228)Instead of letting all RuntimeExceptions go through and be processed by the uncaught exception handler, IllegalStateException and IllegalArgumentException are not passed through and fail fast. In this PR when setting the uncaught exception handler we check if the exception is in an ""exclude list"", if so, we terminate the client, otherwise we continue as usual.Added test checking this new case. Added integration test checking that user defined exception handler is not used when an IllegalStateException is thrown.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
Merge branch 'trunk' of https://git-wip-us.apache.org/repos/asf/kafka into trunk,1
"KAFKA-6030; Fix Integer overflow in cleanable ratio computationAuthor: Xin Li <Xin.Li@trivago.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #4043 from lisa2lisa/fix(cherry picked from commit bb27215ceac9caaac446b5fe43d3f3284624fcb4)Signed-off-by: Jason Gustafson <jason@confluent.io>",5
MINOR: Add upgrade guide for KAFKA-8421 (#7925)Co-Authored-By: A. Sophie Blee-Goldman <ableegoldman@gmail.com>Reviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>,1
KAFKA-2161; Fix a few copyrights,0
"KAFKA-7011 - Remove ResourceNameType field from Java Resource class. (#5160)The initial PR for KIP-290 #5117 added a `ResourceNameType` field to the Java and Scala `Resource` classes to introduce the concept of Prefixed ACLS.  This does not make a lot of sense as these classes are meant to represent cluster resources, which would not have a concept of 'name type'. This work has not been released yet, so we have time to change it.This PR looks to refactor the code to remove the name type field from the Java `Resource` class. (The Scala one will age out once KIP-290 is done, and removing it would involve changes to the `Authorizer` interface, so this class was not touched).This is achieved by replacing the use of `Resource` with `ResourcePattern` and `ResourceFilter` with `ResourceFilterPattern`.  A `ResourcePattern` is a combination of resource type, name and name type, where each field needs to be defined. A `ResourcePatternFilter` is used to select patterns during describe and delete operations.The adminClient uses `AclBinding` and `AclBindingFilter`. These types have been switched over to use the new pattern types.The AclCommands class, used by Kafka-acls.sh, has been converted to use the new pattern types.The result is that the original `Resource` and `ResourceFilter` classes are not really used anywhere, except deprecated methods. However, the `Resource` class will be used if/when KIP-50 is done.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",1
MINOR: make sure all fiedls of o.p.k.s.a.Action are NOT null (#10764)I'm migrating Ranger's kafka plugin from deprecated Authorizer (this is already removed by 976e78e) to new API (see https://issues.apache.org/jira/browse/RANGER-3231). The kafka plugin needs to take something from field resourcePattern but it does not know whether the field is nullable (or users need to add null check). I check all usages and I don't observe any null case.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: Add KafkaEventQueue (#10030)Add KafkaEventQueue, which is used by the KIP-500 controller to manage its event queue.Compared to using an Executor, KafkaEventQueue has the following advantages:* Events can be given ""deadlines."" If an event lingers in the queue beyond the deadline, itwill be completed with a timeout exception. This is useful for implementing timeouts forcontroller RPCs.* Events can be prepended to the queue as well as appended.* Events can be given tags to make them easier to manage. This is especially useful forrescheduling or cancelling events which were previously scheduled to execute in the future.Reviewers: Jun Rao <junrao@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",1
"Replication Data Loss in Mirror Maker Bouncing testcase; patched by Jun Rao; reviewed by Joel Koshy, John Fung and Neha Narkhede; kafka-567git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397717 13f79535-47bb-0310-9956-ffa450edef68",3
"MINOR: Remove duplicate `createKafkaMetricsContext` (#10376)This patch removes the duplicated `createKafkaMetricsContext` from `KafkaBroker`. It is already present in `Server`. Also added some small style cleanups.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
Minor checkin to remove an empty packagegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1344965 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-10305: Print usage when parsing fails for ConsumerPerformance (#9071)https://issues.apache.org/jira/browse/KAFKA-10305When `kafka-consumer-perf-test.sh` is executed without required options or no options at all, only the error message is displayed. It's better off showing the usage as well like what we did for kafka-console-producer.sh.",1
"KAFKA-12553: Refactor recovery logic to introduce LogLoader (#10478)In this PR, I have refactored the recovery logic code introducing a new class kafka.log.LogLoader responsible for all activities related with recovery of log segments from disk. With this change, the recovery logic has been moved out of the Log class and into the new LogLoader class.Advantages:This refactor has the following advantages over the existing code:As such, the recovery logic is invoked once only during Log instantiation. Some parts of the recovery logic are fairly independent from the rest of the Log class. By moving the independent private logic to a separate LogLoader class, the existing Log class has become more modular, and the constructor behavior is a lot simpler now. Therefore, this makes the code more maintainable.This PR takes us a step closer towards the Log layer reactor work (KAFKA-12554). The Log recovery logic reads and writes to LeaderEpochFileCache and ProducerStateManager instances, so as such the logic does not fit very well into the definition of a ""local log"". By extracting it out of the Log class, in the future this will make it much easier to clearly define the separation of concerns between LocalLog and UnifiedLog.Reviewers: Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2
KAFKA-9939; Fix overcounting delayed fetches in request rate metrics (#8586)Fetches which hit purgatory are currently counted twice in fetch request rate metrics. This patch moves the metric update into `fetchMessages` so that they are only counted once. Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-5231: Bump up producer epoch when sending abort txn markers on InitPidAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson, Jun RaoCloses #3066 from guozhangwang/K5231-bump-up-epoch-when-abort-txn",5
"MINOR: Do not collect zk persistent data by defaultIn system tests zookeeper service, it is overkill and space-intensive to collect zookeeper data logs by default. This minor patch turns off default collection.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #504 from granders/minor-zk-change-log-collect",4
"KAFKA-8443; Broker support for fetch from followers (#6832)Follow on to #6731, this PR adds broker-side support for [KIP-392](https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica) (fetch from followers). Changes:* All brokers will handle FetchRequest regardless of leadership* Leaders can compute a preferred replica to return to the client* New ReplicaSelector interface for determining the preferred replica* Incremental fetches will include partitions with no records if the preferred replica has been computed* Adds new JMX to expose the current preferred read replica of a partition in the consumerTwo new conditions were added for completing a delayed fetch. They both relate to communicating the high watermark to followers without waiting for a timeout:* For regular fetches, if the high watermark changes within a single fetch request * For incremental fetch sessions, if the follower's high watermark is lower than the leaderA new JMX attribute `preferred-read-replica` was added to the `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=some-consumer,topic=my-topic,partition=0` object. This was added to support the new system test which verifies that the fetch from follower behavior works end-to-end. This attribute could also be useful in the future when debugging problems with the consumer.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
kafka-1990; Add unlimited time-based log retention; patched by Jeff Holoman; reviewed by Jun Rao,2
"KAFKA-3670; ControlledShutdownLeaderSelector should pick the preferred replica as the new leader, if possibleAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1338 from ijuma/kafka-3670-controlled-shutdown-leader-selector-preferred-replica",1
"KAFKA-12514: Fix NPE in SubscriptionState (#10369)Return null for partitionLag if there is no current position.This was the desired semantics, the lack of the check was anoversight.Patches: KIP-695Patches: a92b986c855592d630fbabf49d1e9a160ad5b230Reviewers: Walker Carlson <wcarlson@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@apache.org>",5
"MINOR: Dump log tool should support bootstrap checkpoint (#12556)This patch adds support to `kafka-dump-log.sh` to print the `bootstrap.checkpoint` file from KIP-778: https://cwiki.apache.org/confluence/display/KAFKA/KIP-778:+KRaft+Upgrades.Reviewers:  dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>",5
"KAFKA-9206; Throw KafkaException on CORRUPT_MESSAGE error in Fetch response (#8111)If a completed fetch has an error code signifying a _corrupt message_, throw a `KafkaException` that notes the fetch offset and the topic-partition.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-2140 follow up, checking in newly renamed file ConsumerRebalanceFailedException",0
"KAFKA-12997: Expose the append time for batches from raft (#10946)Add the record append time to Batch. Change SnapshotReader to set this time to thetime of the last log in the last batch. Fix the QuorumController to remember the lastcommitted batch append time and to store it in the generated snapshot.Reviewers: David Arthur <mumrah@gmail.com>, Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",0
"KAFKA-2832: Add a consumer config option to exclude internal topicsA new consumer config option 'exclude.internal.topics' was added toallow excluding internal topics when wildcards are used to specifyconsumers.The new option takes a boolean value, with a default 'false' value (i.e.no exclusion).This patch is co-authored with rajinisivaram edoardocomar mimaisonAuthor: edoardo <ecomar@uk.ibm.com>Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma, Jun Rao, Gwen ShapiraCloses #1082 from edoardocomar/KAFKA-2832",2
KAFKA-3697; Clean up website documentation of client usageThis is to imply that the Java consumer/producer are the recommended consumer/producer now.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1921 from vahidhashemian/KAFKA-3697,5
Fix typo in MockProducer JavaDoc (#4606),2
KAFKA-7235: Detect outdated control requests and bounced brokers using broker generation (#5821)* KAFKA-7235: Detect outdated control requests and bounced brokers using broker generation* Add broker_epoch in controlled shutdown request* Move broker epoch check into controller for ControlledShutdownRequest* Refactor schema definition for controler requests/responses* Address comments* Address comments* Address comments* Send back STALE_BROKER_EPOCH error in ControlledShutdown response* Fix build issue* Address comments* Address comments* Address comments* Address comments* Fix tests after rebase* Address comments* Address comments,1
"MINOR: Modify checkstyle to allow import classes only used in javadocAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #1317 from guozhangwang/KJavaDocImport",2
"MINOR: Add random aborts to system test transactional copier serviceAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3340 from hachikuji/add-random-aborts-to-system-test",5
MINOR: Use producer template in verifiable producer service (#5581)Also remove an unused old consumer template.Reviewers: Jason Gustafson <jason@confluent.io>,5
revisit broker config in 0.8; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-325git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1384624 13f79535-47bb-0310-9956-ffa450edef68,5
MINOR: Fix AbstractStickyAssignor doc (#11727)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR; Fix partition change record noop check (#12073)When LeaderRecoveryState was added to the PartitionChangeRecord, thecheck for being a noop was not updated. This commit fixes that andimproves the associated test to avoid this oversight in the future.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",3
kafka-937; fix bug exposed in ConsumerOffsetChecker; patched by Jun Rao; reviewed by Alexey Ozeritskiy,1
"KAFKA-12614: Use Jenkinsfile for trunk and release branch builds (#10473)* Run all JDK/Scala version combinations for trunk/release branch builds.* Only retry failures in PR builds for now (we can remove this distinction if/whenwe report flaky failures as described in KAFKA-12216).* Disable concurrent builds* Send email to dev list on build failure* Use triple double quotes in `doValidation` since we use string interpolationfor `SCALA_VERSION`.* Update release.py to output new `Unit/integration tests` Jenkins linkReviewers: Gwen Shapira <cshapi@gmail.com>, David Arthur <mumrah@gmail.com>",2
KAFKA-1251 Further metric naming standardization.,5
"KAFKA-3441: 0.10.0 documentation still says ""0.9.0""Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1122 from granthenke/docs-10",2
kafka-1010; Concurrency issue in getCluster() causes rebalance failure and dead consumer; patched by Sam Meder; reviewed by Jun Rao,0
"KAFKA-9918; SslEngineFactory is NOT closed when channel is closing (#8551)This patch ensures that `SslEngineFactory` is closed. The default implementation (**DefaultSslEngineFactory**) does not have any releasable object so we didn't notice this issue. However, it would be better to fix this issue for custom engine factories.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-13748: Do not include file stream connectors in Connect's CLASSPATH and plugin.path by default (#11908)With this change we stop including the non-production grade connectors that are meant to be used for demos and quick starts by default in the CLASSPATH and plugin.path of Connect deployments. The package of these connector will still be shipped with the Apache Kafka distribution and will be available for explicit inclusion. The changes have been tested through the system tests and the existing unit and integration tests. Reviewers: Mickael Maison <mickael.maison@gmail.com>, Randall Hauch <rhauch@gmail.com>",3
MINOR: Replace TopicAndPartition with TopicPartition in `Log` and `ReplicaManager`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2268 from ijuma/topicpartition-vs-topicandpartition,5
"MINOR: Make LeaderAndIsr immutable case classAlso include a few code readability improvements.Author: jozi-k <jozef.koval@protonmail.ch>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2731 from jozi-k/immutable_LeaderAndIsr",1
"KAFKA-8147: Update upgrade notes for KIP-446 (#8965)Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-5464; StreamsKafkaClient should not use StreamsConfig.POLL_MS_CONFIGAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3439 from mjsax/kafka-5464-streamskafkaclient-poll",5
"MINOR: Fix typo in Vagrant READMEthe wrong word in this sentence "" allows us to bring machies up in parallel on AWS."" .“machies” change to ""machines"".Author: Yang Wei <yangvlive@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1949 from yangwei71/trunk",1
MINOR: add slf4jlog4j to streams exampleAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1731 from guozhangwang/Kminor-log4j-streams-examples,2
"MINOR: fix round_trip_fault_test.py - don't assign replicas to nonexistent brokers (#10908)The broker id starts with 1 (https://github.com/apache/kafka/blob/trunk/tests/kafkatest/services/kafka/kafka.py#L207) so round_trip_fault_test.py fails because it assigns replica to nonexistent broker.The interesting story is the failure happens only on KRaft only. KRaft mode checks the existent ids (https://github.com/apache/kafka/blob/trunk/metadata/src/main/java/org/apache/kafka/controller/ReplicationControlManager.java#L950). By contrast, ZK mode has no such check and the min.insync.replicas is set to 1 so this test works with ZK mode even though there is one replica is always off-line.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: Fix typo in `ClusterTool` (#10706)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-5754; Refactor Streams to use LogContextThis PR utilizes `org.apache.kafka.common.utils.LogContext` for logging in `KafkaStreams`. hachikuji, ijuma please review this and let me know your thoughts.Author: umesh chaudhary <umesh9794@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3727 from umesh9794/KAFKA-5754",2
"throw corresponding invalid producer epoch (#9700)As suggested, ensure InvalidProducerEpoch gets caught properly on stream side.Reviewers: Guozhang Wang <wangguoz@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-3207: Fix StateChangeLogger to use the right topic nameAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #865 from guozhangwang/K3207,1
"KAFKA-9658; Fix user quota removal (#8232)Adding (add-config) default user, user, or <user, client-id> quota and then removing it via delete-config does not update quota bound in ClientQuotaManager.Metrics for existing users or <user,client-id>. This causes brokers to continue to throttle with the previously set quotas until brokers restart (or <user,client> stops sending traffic for sometime and sensor expires). This happens only when removing the user or user,client-id where there are no more quotas  to fall back to. Common example where the issue happens: Initial no quota state --> add default user quota --> remove default user quota. The cause of the issue was `DefaultQuotaCallback.quotaLimit` was returning `null` when no default user quota set, which caused `ClientQuotaManager.updateQuotaMetricConfigs` to skip updating the appropriate sensor, which left it unchanged with the previous quota. Since `null` is an acceptable return value for `ClientQuotaCallback.quotaLimit`, which is already treated as unlimited quota in other parts of the code, this PR ensures that `ClientQuotaManager.updateQuotaMetricConfigs` updates the quotas for which  `ClientQuotaCallback.quotaLimit` returns `null` to unlimited quota.Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5547; Return TOPIC_AUTHORIZATION_FAILED error if no describe access for topicsAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3924 from omkreddy/KAFKA-5547-TOPIC-AUTHRO",5
KAFKA-10855; Fix non-local return in `KafkaApis.handle` (#9753)The non-local return when `maybeHandleInvalidEnvelope` returns true causes the default error handler to execute after a response has already been sent. This patch rewrites the check as a local return.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,0
"KAFKA-955 After a leader change, messages sent with ack=0 are lost; reviewed by Jay Kreps, Neha Narkhede and Jun Rao",4
"MINOR: Include response in request logIt's implemented such that there is no overhead if request logging isdisabled.Also:- Reduce metrics computation duplication in `updateRequestMetrics`- Change a couple of log calls to use string interpolation instead of `format`- Fix a few compiler warnings related to unused imports and unused defaultarguments.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Roger Hoover <roger.hoover@gmail.com>, Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3801 from ijuma/log-response-in-request-log",2
"KAFKA-13752: Uuid compare using equals in java (#11912)This patch fixes a few cases where we use `==` instead of `equals` to compare UUID. The impact of this bug is low because `Uuid.ZERO_UUID` is used by default everywhere.Reviewers: Justine Olshan <jolshan@confluent.io>, dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: Make TopicDescription's other constructor public (#7405)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-3280: KafkaConsumer Javadoc contains misleading description of heartbeat behavior and correct useThis is my original work and I license the work to the project under the project's open source license.Author: Richard Whaling <rwhaling@spantree.net>Reviewers: Jason Gustafson, Gwen ShapiraCloses #968 from rwhaling/docs/kafkaconsumer-heartbeat-doc-improvement",2
"KAFKA-10679: [Streams] migrate kafka-site updated docs to kafka/docs (#9554)During the AK website upgrade, changes made to kafka-site weren't migrated back to kafka-docs.This PR is an attempt at porting the streams changes to kafka/docsFor the most part, the bulk of the changes in the PR are cosmetic.For testing:I reviewed the PR diffsRendered the changes locallyReviewers: John Roesler <john@confluent.io>",5
"KAFKA-7501: Fix producer batch double deallocation when receiving message too large error on expired batch (#5807)Minor clean-ups for clarity included.Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
"MINOR: Removed explicit class checks for PolicyViolationException (#4515)PolicyViolationException is a subclass of ApiException, and the handling was identical, hence explicit checking not required.",1
"KAFKA-9346: Consumer back-off logic when fetching pending offsets (#7878)Let consumer back-off and retry offset fetch when the specific offset topic has pending commits.The major change lies in the broker side offset fetch logic, where a request configured with flag WaitTransaction to true will be required to back-off when some pending transactional commit is ongoing. This prevents any ongoing transaction being modified by third party, thus guaranteeing the correctness with input partition writer shuffling.Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9807; Protect LSO reads from concurrent high-watermark updates (#8418)If the high-watermark is updated in the middle of a read with the `read_committed` isolation level, it is possible to return data above the LSO. In the worst case, this can lead to the read of an aborted transaction. The root cause is that the logic depends on reading the high-watermark twice. We fix the problem by reading it once and caching the value.Reviewers: David Arthur <mumrah@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>",0
"MINOR: remove ""gradle wrapper"" from travis.yml (#9610)Reviewers: Ismael Juma <ismael@juma.me.uk>",5
MINOR: Add synchronization to the protocol name check (#8349)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-808 Migration tool internal queue between consumer and producer threads should be configurable; reviewed by Jun Rao,5
"MINOR: fix reading SSH output in Streams system tests (#9665)SSH outputs in system tests originating from paramiko are bytes. However, the logger in the system tests does not accept bytes and instead throws an exception. That means, the bytes returned as SSH output from paramiko need to converted to a type that the logger (or other objects) can process.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
"KAFKA-8496: System test for KIP-429 upgrades and compatibility (#7529)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Update snappy-java to 1.1.8.1 (#9646)It includes small performance improvements:* https://github.com/google/snappy/releases/tag/1.1.8* https://github.com/xerial/snappy-java/blob/1.1.8.1/Milestone.mdReviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"MINOR: Fix AlterPartitionManager topic id handling in response handler (#12317)https://github.com/apache/kafka/commit/f83d95d9a28267f7ef7a7b1e584dcdb4aa842210 introduced topic ids in the AlterPartitionRequest/Response and we just found a bug in the request handling logic. The issue is the following.When the `AlterPartitionManager` receives the response, it builds the `partitionResponses` mapping `TopicIdPartition` to its result. `TopicIdPartition` is built from the response. Therefore if version < 2 is used, `TopicIdPartition` will have the `ZERO` topic id. Then the `AlterPartitionManager` iterates over the item sent to find their response. If an item has a topic id in its `TopicIdPartition` and version < 2 was used, it cannot find it because one has it and the other one has not.This patch fixes the issue by using `TopicPartition` as a key in the `partitionResponses` map. This ensures that the result can be found regardless of the topic id being set or not.Note that the case where version 2 is used is handled correctly because we already have logic to get back the topic name from the topic id in order to construct the `TopicPartition`.`testPartialTopicIds` test was supposed to catch this but it didn't due to the ignorable topic id field being present. This patch fixes the test as well.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4461: Added support to ProcessorTopologyTestDriver for internal topicsThis resolves an issue in driving tests using the ProcessorTopologyTestDriver when `groupBy()` is invoked downstream of a processor that flags repartitioning.Ticket: https://issues.apache.org/jira/browse/KAFKA-4461Discussion: http://search-hadoop.com/m/Kafka/uyzND1wbKeY1Q8nH1dguy guozhangwangThe contribution is my original work and I license the work to the project under the project's open source license.Author: Adrian McCague <amccague@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2499 from amccague/KAFKA-4461_ProcessorTopologyTestDriver_map_groupbykey",3
"MINOR: Exclude KIP-500.md from rat check (#10354)Builds are failing since this file does not have a license. Similar .md files do not seem to have licenses,so I've added this file to the exclude list.",2
KAFKA-6181 Examining log messages with {{--deep-iteration}} should show superset of fields (#9204)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-10604: Fix Streams default state.dir (#9420)Make the default state store directory location to followOS-specific temporary directory settings or java.io.tmpdirJVM parameter, with Utils#getTempDir.Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",1
MINOR: add test to make sure ProcessorStateManager can handle State Stores with logging disabledAdding the test so we know that the State Stores with logging disabled or without a topic don't throw any exceptions.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1916 from dguy/state-store-logging-disabled,2
kafka-1438 (follow-up); Migrate client tools out of perf;  patched by Sriharsha Chintalapani; reviewed by Jun Rao,1
KAFKA-8611: Refactor KStreamRepartitionIntegrationTest (#8470)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-10110: Corrected potential NPE when null label value added to KafkaMetricsContext (#8811)Also added a new unit test to verify the functionality and expectations.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>,5
KAFKA-6617; Improve controller performance by batching reassignment znode write operationKafkaController currently writes reassignment znode once for every partition that has been successfully reassigned. This is unnecessary and controller should be able to update reassignment znode once to remove all partitions that have been reassigned from the reassignment znode.Author: Dong Lin <dolin@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4659 from lindong28/KAFKA-6617,2
"MINOR: Remove use of `NoSuchElementException` in `KafkaMetadataLog` (#10344)Replace the use of the method `last` and `first` in `ConcurrentSkipListSet` with the descending and ascending iterator respectively. The methods `last` and `first` throw an exception when the set is empty this causes poor `KafkaRaftClient` performance when there aren't any snapshots.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Extract SCALA_BINARY_VERSION from SCALA_VERSIONWill allow users to set one fewer environment variable if they need tochange scala version. Still, SCALA_BINARY_VERSION can be explicitly set.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2130 from kkonstantine/MINOR-Extract-SCALA_BINARY_VERSION-from-SCALA_VERSION",4
"KAFKA-2377: Add basic system test for copycat using source and sink file connectors.Tests standalone mode by running separate source and sink connectors, cattingdata into the source file, and validating the output in the sink file. Restartsthe service to verify that clean restarts will result in tasks resuming wherethey left off.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Geoff Andreson, Gwen ShapiraCloses #150 from ewencp/kafka-2377-copycat-system-test",5
KAFKA-2752: Follow up to fix checkstlyeAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-PostavaCloses #492 from granthenke/fix,0
"MINOR: clean up node and store sensors (#5450)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-12790: Remove SslTransportLayerTest.testUnsupportedTlsVersion (#10922)Support for TLS 1.0/1.1 was disabled in recent versions of Java 8/11and all versions of 16 causing this test to fail.It is possible to make it work by updating the relevant security property,but it has to be done before the affected classes are loaded and it cannot be disabled after that. Given the low value of the test, we removeit.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Luke Chen <showuon@gmail.com>",5
KAFKA-2091; Expose a partitioner interface in the new producer(https://cwiki.apache.org/confluence/display/KAFKA/KIP-+22+-+Expose+a+Partitioner+interface+in+the+new+producer);reviewed by Joel Koshy and Jay Kreps,5
"KAFKA-8960: Move Task determineCommitId in gradle.build to Project Level (#7420)Reviewers: Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@confluent.io>",5
MINOR: trivial logCleanerEnable doc cleanupAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1958 from omkreddy/MINOR-DOC-CHAGE,2
"KAFKA-7652: Part I; Fix SessionStore's findSession(single-key) (#6134)Let findSessions(final K key) to call on underlying bytes store directly, using the more restricted range.Fix the conservative upper range for multi-key range in session schema.Minor: removed unnecessary private WrappedSessionStoreBytesIterator class as it is only used in unit test.Minor: removed unnecessary schema#init function by using the direct bytes-to-binary function.Please read the original PR for more detailed explanation of the root cause of the bug.Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-2042; Update topic list of the metadata regardless of cluster information; reviewed by Guozhang Wang,5
"KAFKA-13351: Add possibility to write kafka headers in Kafka Console Producer (KIP-798) (#11456)This patch adds the possibility to write Kafka headers with the `kafka-console-producer` as specified in KIP-798: https://cwiki.apache.org/confluence/display/KAFKA/KIP-798%3A+Add+possibility+to+write+kafka+headers+in+Kafka+Console+Producer.Reviewers: David Jacot <djacot@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",5
"MINOR: refactor streams system test class hierachyAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Guozhang WangCloses #2392 from mjsax/minor-system-test-rework",5
"KAFKA-9212; Ensure LeaderAndIsr state updated in controller context during reassignment (#7795)KIP-320 improved fetch semantics by adding leader epoch validation. This relies onreliable propagation of leader epoch information from the controller. Unfortunately, wehave encountered a bug during partition reassignment in which the leader epoch in thecontroller context does not get properly updated. This causes UpdateMetadata requeststo be sent with stale epoch information which results in the metadata caches on thebrokers falling out of sync.This bug has existed for a long time, but it is only a problem due to the new epochvalidation done by the client. Because the client includes the stale leader epoch in itsrequests, the leader rejects them, yet the stale metadata cache on the brokers preventsthe consumer from getting the latest epoch. Hence the consumer cannot make progresswhile a reassignment is ongoing.Although it is straightforward to fix this problem in the controller for the new releases(which this patch does), it is not so easy to fix older brokers which means new clientscould still encounter brokers with this bug. To address this problem, this patch alsomodifies the client to treat the leader epoch returned from the Metadata response as""unreliable"" if it comes from an older version of the protocol. The client in this case willdiscard the returned epoch and it won't be included in any requests.Also, note that the correct epoch is still forwarded to replicas correctly in theLeaderAndIsr request, so this bug does not affect replication.Reviewers: Jun Rao <junrao@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",0
KAFKA-8988; Replace CreatePartitions Request/Response with automated protocol (#7493)This change updates the CreatePartitions request and response api objectsto use the generated protocol classes.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-5442: Streams producer client.id are not unique for EOSAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3329 from mjsax/kafka-5442-producer-id-conflict,5
"KAFKA-9983: KIP-613: add INFO level e2e latency metrics (#8697)Add e2e latency metrics at the beginning and end of task topologiesas INFO-level processor-node-level metrics.Implements: KIP-613Reviewers: John Roesler <vvcephei@apache.org>, Andrew Choi <a24choi@edu.uwaterloo.ca>, Bruno Cadonna <cadonna@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-4617; Improve configuration of Gradle’s eclipse taskGenerate core project with correct source folders. In additionset output folders same as command line build. Don't generateunnecessary projects.Author: Dhwani Katagade <dhwani_katagade@persistent.com>Reviewers: Edoardo Comar <ecomar@uk.ibm.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2382 from dhwanikatagade/gradle_eclipse_plugin_path_fix",0
"MINOR: Increase spotBugs max heap to 2 GB (#7497)Gradle 5.0 has reduced the heap size forworkers and there have been reports of`GC overhead limit exceeded` errors.Also see:https://discuss.gradle.org/t/spotbugsplugin-with-gradle-5-0-fails-gc-overhead-limit-exceeded/30461Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com, Scott Hendricks <scott.hendricks@confluent.io>",5
"MINOR: Document endpoints for connector topic tracking (KIP-558)Update the site documentation to include the endpoints introduced with KIP-558 and a short paragraph on how this feature is used in Connect.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Toby Drake <tobydrake7@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #8148 from kkonstantine/kip-558-docs",2
Merge remote-tracking branch 'origin/0.8' into trunk,1
KafkaServer can throw a NullPointerException during startup if zookeeper is down; KAFKA-94git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156940 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Add proper checks to KafkaConsumer.groupMetadata (#9349)Add following checks to `KafkaConsumer.groupMetadata`:1. null check of coordinator (replace NPE by `InvalidGroupIdException` which is same to other methods)2. concurrent check (`groupMetadata` is not thread-safe so concurrent check is necessary)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-8006: Guard calls to init and close from global processor (#6353)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-8816: Make offsets immutable to users of RecordCollector.offsets (#7223)Make offsets immutable to users of RecordCollector.offsets. Fix up anexisting case where offsets could be modified in this way. Add a simpletest to verify offsets cannot be changed externally.Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-1988; Fix org.apache.kafka.common.utils.Utils.abs and add Partitioner.toPositive; reviewed by Jun Rao and Guozhang Wang,1
MINOR: add task ':streams:testAll' (#9073)Adds a new task (`:streams:testAll`) to gradle to run all the tests for all Streams sub-projects.Reviewers: Boyang Chen <boyang@confluent.io>,5
MINOR: fix number of nodes used in test_compatible_brokers_eos_v2_enabled (#12211)Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: Upgrade ducktape to version 0.8.1  (#9933)ducktape 0.8.1 was updated to include the following changes/fixes from 0.7.x branch:* Junit reporting support* fix for an issue where unicode characters in exception message would cause test runner to hang on py27.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
"KAFKA-5032; Update the docs for message size configs across the boardBefore 0.11, we used to have limits for maximum message size on the producer, broker, and consumer side.From 0.11 onward, these limits apply to record batches as a whole. This patch updates the documentation of the configs to make this explicit.A separate patch will have more extensive upgrade notes to tie all the changes together in one narrative.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3374 from apurvam/KAFKA-5032-message-size-docs",2
"KAFKA-12205; Delete snapshots less than the snapshot at the log start (#10021)This patch adds logic to delete old snapshots. There are three cases we handle:1. Remove old snapshots after a follower completes fetching a snapshot and truncates the log to the latest snapshot2. Remove old snapshots after a new snapshot is created.3. Remove old snapshots during recovery after the node is restarted.Reviewers: Cao Manh Dat<caomanhdat317@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-12331: Use LEO for the base offset of LeaderChangeMessage batch (#10138)The `KafkaMetadataLog` implementation of `ReplicatedLog` validates that batches appended using `appendAsLeader` and `appendAsFollower` have an offset that matches the LEO. This is enforced by `KafkaRaftClient` and `BatchAccumulator`. When creating control batches for the `LeaderChangeMessage` the default base offset of `0` was being used instead of using the LEO. This is fixed by:1. Changing the implementation for `MockLog` to validate against this and throw an `RuntimeException` if this invariant is violated.2. Always create a batch for `LeaderChangeMessage` with an offset equal to the LEO.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-9685: Solve Set concatenation perf issue in AclAuthorizerTo dismiss the usage of operation ++ against Set which is slow when Set has many entries. This pr introduces a new class 'AclSets' which takes multiple Sets as parameters and do 'find' against them one by one. For more details about perf and benchmark, refer to [KAFKA-9685](https://issues.apache.org/jira/browse/KAFKA-9685)Author: jiao <jiao.zhang@linecorp.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8261 from jiao-zhangS/jira-9685",0
"KAFKA-12747: Fix flakiness in shouldReturnUUIDsWithStringPrefix (#10643)Consecutive UUID generation could result in same prefix.Reviewers: Josep Prat <josep.prat@aiven.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",0
"KAFKA-3776: Unify store and downstream caching in streamsThis is joint work between dguy and enothereska. The work implements KIP-63. Overview of main changes:- New byte-based cache that acts as a buffer for any persistent store and for forwarding changes downstream.- Forwarding record path changes: previously a record in a task completed end-to-end. Now it may be buffered in a processor node while other records complete in the task.- Cleanup and state stores and decoupling of cache from state store and forwarding.- More than 80 new unit and integration tests.Author: Damian Guy <damian.guy@gmail.com>Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #1752 from enothereska/KAFKA-3776-poc",3
HOTFIX: Change header back to http instead of https to path license header test (#6347)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Update jmh to 1.27 for async profiler support (#9129)Also updated the jmh readme to make it easier for new people to knowwhat's possible and best practices.There were some changes in the generated benchmarking code thatrequired adjusting `spotbugs-exclude.xml` and for a `javac` warningto be suppressed for the benchmarking module. I took the chanceto make the spotbugs exclusion mode maintainable via a regexpattern.Tested the commands on Linux and macOS with zsh.JMH highlights:* async-profiler integration. Can be used with -prof async,pass -prof async:help to look for the accepted options.* perf c2c [2] integration. Can be used with -prof perfc2c,if available.* JFR profiler integration. Can be used with -prof jfr, pass-prof jfr:help to look for the accepted options.Full details:* 1.24: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-August/002982.html* 1.25: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-August/002987.html* 1.26: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-October/003024.html* 1.27: https://mail.openjdk.java.net/pipermail/jmh-dev/2020-December/003096.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Lucas Bradstreet <lucasbradstreet@gmail.com>",4
"MINOR: Improve scaladoc for AuthorizerAuthor: Magnus Reftel <magnus.reftel@skatteetaten.no>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>Closes #2151 from reftel/feature/authorizer_name_reference",1
"KAFKA-3336: Unify Serializer and Deserializer into SerializationAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Michael G. Noll, Ismael JumaCloses #1066 from guozhangwang/K3336",5
KAFKA-692 ConsoleConsumer outputs diagnostic message to stdout instead of stderr; reviewed by Neha Narkhede,2
"KAFKA-14032; Dequeue time for forwarded requests is unset (#12360)When building a forwarded request, we need to override the dequeue time of the underlying request to match the same value as the envelope. Otherwise, the field is left unset, which causes inaccurate reporting.Reviewers; Jason Gustafson <jason@confluent.io>",5
kafka-1210; Windows Bat files are not working properly; patched by Stevo Slavic; reviewed by Jun Rao,1
KAFKA-914; Break deadlock between initial rebalance and watcher-triggered rebalances; reviewed by Jun Rao and Neha Narkhede,5
"KAFKA-8717; Reuse cached offset metadata when reading from log (#7081)Although we currently cache offset metadata for the high watermark and last stable offset, we don't use it when reading from the log. Instead we always look it up from the index. This patch pushes fetch isolation into `Log.read` so that we are able to reuse the cached offset metadata.Reviewers: Jun Rao <junrao@gmail.com>",5
"KAFKA-12788: improve KRaft replica placement (#10494)Implement a striped replica placement algorithm for KRaft. This alsomeans implementing rack awareness.  Previously, KRraft just chosereplicas randomly in a non-rack-aware fashion.  Also, allow replicas tobe placed on fenced brokers if there are no other choices.  This wasspecified in KIP-631 but previously not implemented.Reviewers: Jun Rao <junrao@gmail.com>",1
KAFKA-9707: Fix InsertField.Key should apply to keys of tombstone records (#8280)* KAFKA-9707: Fix InsertField.Key not applying to tombstone events* Fix typo that hardcoded .value() instead of abstract operatingValue* Add test for Key transform that was previously not testedSigned-off-by: Greg Harris <gregh@confluent.io>* Add null value assertion to tombstone test* Remove mis-named function and add test for passing-through a null-keyed record.Signed-off-by: Greg Harris <gregh@confluent.io>* Simplify unchanged record assertionSigned-off-by: Greg Harris <gregh@confluent.io>* Replace assertEquals with assertSameSigned-off-by: Greg Harris <gregh@confluent.io>* Fix checkstyleTest indent issueSigned-off-by: Greg Harris <gregh@confluent.io>,5
"KAFKA-9749; Transaction coordinator should treat KAFKA_STORAGE_ERROR as retriable (#8336)When handling a WriteTxnResponse, the TransactionMarkerRequestCompletionHandler throws an IllegalStateException when the remote broker responds with a KAFKA_STORAGE_ERROR and does not retry the request. This leaves the transaction state stuck in PendingAbort or PendingCommit, with no way to change that state other than restarting the broker, because both EndTxnRequest and InitProducerIdRequest return CONCURRENT_TRANSACTIONS if the state is PendingAbort or PendingCommit. This patch changes the error handling behavior in TransactionMarkerRequestCompletionHandler to retry KAFKA_STORAGE_ERRORs. This matches the existing client behavior, and makes sense because KAFKA_STORAGE_ERROR causes the host broker to shut down, meaning that the partition being written to will move its leadership to a new, healthy broker.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6145: KIP-441: Improve assignment balance (#8588)Validate that the assignment is always balanced wrt:* active assignment balance* stateful assignment balance* task-parallel balanceReviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"MINOR: Fix ambiguous log message in RecordCollectorWhen producing fails in Kafka Streams, it gives an error like below:```Error sending record: null```by this line: https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollector.java#L59This isn't not making sense because of:- Practically metadata is always null when exception != null : https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordBatch.java#L107-L109- It's quite misleading as we would interpret it like ""Kafka Streams attempted to send 'null' as a record"" which isn't in factAs I find a PR #873  as the origin of the above line I changed it to instantiate callback on each send in order to log destination topic at least.Author: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #1555 from kawamuray/MINOR-record-collector-log-message",2
"KAFKA-12863: Configure controller snapshot generation (#10812)Add the ability for KRaft controllers to generate snapshots based on the number of new record bytes that have been applied since the last snapshot. Add a new configuration key to control this parameter. For now, itdefaults to being off, although we will change that in a follow-on PR. Also, fix LocalLogManager so thatsnapshot loading is only triggered when the listener is not the leader.Reviewers: Colin P. McCabe <cmccabe@apache.org>",2
MINOR: Include request header in exception when correlation of request/response failsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1793 from ijuma/include-request-header-if-request-correlation-fails,0
KAFKA-4717: Use absolute paths to files in root directory so all jars include LICENSE and NOTICE filesAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2473 from ewencp/kafka-4717-connect-license-and-notice-files,2
"KAFKA-7759; Disable WADL output in the Connect REST API (#6051)This patch disables support for WADL output in the Connect REST API since it was never intended to be exposed. Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
use zk for auto rebalance,1
"MINOR: hygene cleanup in TransactionManagerTest (#5951)Reviewers: Andras Katona <41361962+akatona84@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
KAFKA-6515; Adding toString() method to o.a.k.connect.data.Field (#4509),5
"kafka-2132; Move Log4J appender to a separate module; patched by Ashish Singh; reviewed by Gwen Shapira, Aditya Auradkar and Jun Rao",2
KAFKA-3529: Fix transient failure in testCommitAsyncAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1234 from hachikuji/KAFKA-3529,5
"KAFKA-5597; Improve Metrics docs generationInstead of having the metrics registry and theorg.apache.kafka.common.metrics.Metrics object be separate things,have the metrics registry hold a copy of the Metrics object.That way, all the metricInstance stuff is hidden, and we don'thave to make sure that the metrics registry and the Metricsobject are configured identicailly (with the same tags).I personally think this looks a little better.Author: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3799 from wushujames/producer_sender_metrics_docs_different",2
KAFKA-8542; Cache transaction first offset metadata on follower (#6943)Followers should cache the log offset metadata for the start offset of each transaction in order to be able to compute the last stable offset without an offset index lookup. This is needed for follower fetching in KIP-392.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Fix bug of empty position in windowed and session stores #11713 Reviewers: John Roesler <vvcephei@apache.org>,0
MINOR: Remove findbugs exclusion matching removed old producer (#5090)KAFKA-6921 removed deprecated scala producer. This pull request removes the now unnecessary findbugs exclusion that matched one of the affected classes.,5
MINOR: remove unneccessary `public` keyword from `Partitioner` interface (#10708)Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: Use EnumMap/EnumSet if possible (#3919)They are more efficient than HashMap/HashSet.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-2856: Add KTable non-stateful APIs along with standby task supportguozhangwang* added KTable API and impl* added standby support for KTableAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #604 from ymatsuda/add_ktable,1
MINOR: Set log level for producer internals to trace for transactions testWe need this to debug most issues with the transactions system test.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3261 from apurvam/MINOR-set-log-level-for-producer-to-trace-for-transactions-test,3
A new file part of KAFKA-116 was accidentally not checked in. This commit fixes it; patched by nehanarkhede; reviewed by chrisburroughsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1161276 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Add missing space in isolation-level doc (#7473)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-2408: ConsoleConsumerService direct log output to fileconsole consumer writes to System.out, while (some) log4j loggers operate in other threads.This occasionally led to funky interleaved output which disrupted parsing of consumed messages by ConsoleConsumerService, leading to spurious test failures.This fix directs log output to a separate file.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-PostavaCloses #123 from granders/KAFKA-2408 and squashes the following commits:247b0e0 [Geoff Anderson] Updated line counting to use wc -l66d6f4f [Geoff Anderson] lower -> uperrcase constantse67f554 [Geoff Anderson] Changed incorrect license headeraf67e01 [Geoff Anderson] Merged in upstream trunk8f89044 [Geoff Anderson] Added another lifecycle check. Wait for log file to exist before exmaning contents.521a84b [Geoff Anderson] Updated console consumer to directo log output directly to file rather than stdout",2
"KAFKA-4646: Improve test coverage AbstractProcessorContextException paths in `register()`, `topic()`, `partition()`, `offset()`, and `timestamp()`, were not covered by any existing testsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. SaxCloses #2447 from dguy/KAFKA-4646",3
"KAFKA-2585; ConsoleConsumer should not hang infinitely upon exceptionAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma, Onur Karaman, Gwen ShapiraCloses #247 from lindong28/KAFKA-2585",5
"KAFKA-12342: Remove MetaLogShim and use RaftClient directly (#10705)This patch removes the temporary shim layer we added to bridge the interfacedifferences between MetaLogManager and RaftClient. Instead, we now use theRaftClient directly from the metadata module.  This also means that themetadata gradle module now depends on raft, rather than the other way around.Finally, this PR also consolidates the handleResign and handleNewLeader APIsinto a single handleLeaderChange API.Co-authored-by: Jason Gustafson <jason@confluent.io>",5
KAFKA-6680: Fix issues related to Dynamic Broker configs (#4731)- Fix kafkaConfig initialization if there are no dynamic configs defined in ZK.- Update DynamicListenerConfig.validateReconfiguration() to check new Listeners must be subset of listener mapReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR: Fix logging message in `NetworkClient.poll` not to mention `producer`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #507 from ijuma/fix-error-message-in-network-client-poll,0
MINOR: Rename RecordFormat to RecordVersion (#4809)Also include a few clean-ups:* Method/variable/parameter renames to make them consistent withthe class name* Return `ApiVersion` from `minSupportedFor`* Use `values` to remove some code duplication* Reduce duplication in `ApiVersion` by introducing the `shortVersion`method and building the versions map programatically* Avoid unnecessary `regex` in `ApiVersion.apply`* Added scaladoc to a few methodsSome of these were originally discussed in:https://github.com/apache/kafka/pull/4583#pullrequestreview-98089400Added a test for `ApiVersion.shortVersion`. Relying on existing testsfor the rest since there is no change in behaviour.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-6711: GlobalStateManagerImpl should not write offsets of in-memory stores in checkpoint file (#5219),2
Add a queue of zookeeper notifications in the zookeeper consumer to reduce the number of rebalancing attempts; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-265git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1243721 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Fix api exception single argument constructor usage (#6956)Api exception types usually have a single argument constructor which accepts the exception message. However, some types actually use this constructor to initialize a field. This inconsistency has led to some cases where exception messages were being incorrectly passed to these constructors and interpreted incorrectly. For example, this leads to confusing messages like the following in the log when we hit a GROUP_MAX_SIZE_REACHED error:```Attempt to join group failed due to fatal error: Consumer group The consumer group has reached its max size. already has the configured ...```This patch fixes the problem by changing these constructors so that the exception message is provided consistently. This affected `GroupAuthorizationException`, `TopicAuthorizationException`, and `GroupMaxSizeReachedException`. Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
TRIVIAL: Fix spurious logging in console consumer.,2
KAFKA-5100; ProducerPerformanceService failing due to parsing errorAuthor: Jun Rao <junrao@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2890 from junrao/kafka-5100,0
"KAFKA-14163; Retry compilation after zinc compile cache error (#12507)We have been seeing builds fail due to errors such as the following:```Timeout waiting to lock zinc-1.6.1_2.13.8_17 compiler cache (/home/jenkins/.gradle/caches/7.5.1/zinc-1.6.1_2.13.8_17). It is currently in use by another Gradle instance.```This patch includes a workaround: if the compilation fails due to this zinc compile cache error, then we retry it.Reviewers: Ismael Juma <ismael@juma.me.uk>Co-authored-by: Lucas Bradstreet <lucasbradstreet@gmail.com>",1
"HOTFIX: don't try to remove uninitialized changelogs from assignment & don't prematurely mark task closed (#8140)This fixes two issues which together caused the soak to crash/some test to fail occasionally.What happened was: In the main StreamThread loop we initialized a new task in TaskManager#checkForCompletedRestoration which includes registering, but not initializing, its changelogs. We then complete the loop and call poll, which resulted in a rebalance that revoked the newly-initialized task. In TaskManager#handleAssignment we then closed the task cleanly and go to remove the changelogs from the StoreChangelogReader only to get an IllegalStateException because the changelog partitions were not in the restore consumer's assignment (due to being uninitialized).This by itself should^ be a recoverable error, as we catch exceptions here and retry closing the task as unclean. Of course the task actually was successfully closed (clean) so we now get an unexpected exception Illegal state CLOSED while closing active taskThe fix(es) I'd propose are:1. Keep the restore consumer's assignment in sync with the registered changelogs, ie the set ChangelogReader#changelogs but pause them until they are initialized edit: since the consumer does still perform some actions (gg fetches) on paused partitions, we should avoid adding uninitialized changelogs to the restore consumer's assignment. Instead, we should just skip them when removing.2. Move the StoreChangelogReader#remove call to before the task.closeClean so that the task is only marked as closed if everything was successful. We should do so regardless, as we should (attempt to) remove the changelogs even if the clean close failed and we must do unclean.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4060: Remove zk client dependency in kafka streamsdguy guozhangwang This is a new PR for KAFKA-4060.Author: Hojjat Jafarpour <hojjat@Hojjat-Jafarpours-MBP.local>Author: Hojjat Jafarpour <hojjat@HojjatJpoursMBP.attlocal.net>Reviewers: Damian Guy, Matthias J. Sax, Isamel Juma, Guozhang WangCloses #1884 from hjafarpour/KAFKA-4060-Remove-ZkClient-dependency-in-Kafka-Streams-new",4
"Don't generate Uuid with a leading ""-"" (#11901)",5
MINOR: Use match instead of if/else in KafkaZkClientAlso use ZkVersion.NoVersion instead of -1.Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4196 from mimaison/zkclient_refactor,4
KAFKA-9559: Change default serde to be `null` (#10813)Implements KIP-741Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-5161: add code in reassign-partitions to check broker existenceAdded code to check existence of the brokers in the proposed plan.Author: amethystic <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2962 from amethystic/kafka5161_reassign_check_invalid_brokerID,1
"KAFKA-10357: Extract setup of changelog from Streams partition assignor (#10163)To implement the explicit user initialization of Kafka Streams asdescribed in KIP-698, we first need to extract the code for thesetup of the changelog topics from the Streams partition assignorso that it can also be called outside of a rebalance.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: AdminClient should register with `AppInfoParser`Also make ""created"" message more consistent across clients.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3658 from ijuma/admin-client-should-register-with-app-info-parser",5
"KAFKA-12730; Avoid duplicate logout if Kerberos login fails (#10611)From Java 9 onwards, LoginContext#logout() throws an NPE if invoked multiple times due to https://bugs.openjdk.java.net/browse/JDK-8173069. KerberosLogin currently attempts logout followed by login in a background refresh thread. If login fails we retry the same sequence. As a result, a single login failure prevents subsequent re-login. And clients will never be able to authenticate successfully after the first failure, until the process is restarted. The commit checks if logout is necessary before invoking LoginContext#logout(). Also adds a test for this case.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",3
"KAFKA-13727; Preserve txn markers after partial segment cleaning (#11891)It is possible to clean a segment partially if the offset map is filled before reaching the end of the segment. The highest offset that is reached becomes the new dirty offset after the cleaning completes. The data above this offset is nevertheless copied over to the new partially cleaned segment. Hence we need to ensure that the transaction index reflects aborted transactions from both the cleaned and uncleaned portion of the segment. Prior to this patch, this was not the case. We only collected the aborted transactions from the cleaned portion, which means that the reconstructed index could be incomplete. This can cause the aborted data to become effectively committed. It can also cause the deletion of the abort marker before the corresponding data has been removed (i.e. the aborted transaction becomes hanging).Reviewers: Jun Rao <junrao@gmail.com>",4
"KAFKA-9140: Also reset join future when generation was reset in order to re-join (#7647)Otherwise the join-group would not be resend and we'd just fall into the endless loop.Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-5376; Ensure aborted transactions are propagated in DelayedFetchAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3239 from hachikuji/KAFKA-5376",5
KAFKA-974 can't use public release maven repo because of failure of downloaded dependency,0
"MINOR: Improve reproducability of raft simulation tests (#10422)When a `@Property` tests fail, jqwik helpfully reports the initial seed that resulted in the failure. For example, if we are executing a test scenario 100 times and it fails on the 51st run, then we will get the initial seed that generated . But if you specify the seed in the `@Property` annotation as the previous comment suggested, then the test still needs to run 50 times before we get to the 51st case, which makes debugging very difficult given the complex nature of the simulation tests. Jqwik also gives us the specific argument list that failed, but that is not very helpful at the moment since `Random` does not have a useful `toString` which indicates the initial seed. To address these problems, I've changed the `@Property` methods to take the random seed as an argument directly so that it is displayed clearly in the output of a failure. I've also updated the documentation to clarify how to reproduce failures.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Validate the KRaft controllerListener config on startup (#11070)Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",5
MINOR: Supplement unit test for KAFKA-13175 (#11304)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-5797: Delay checking of partition existence in StoreChangelogReader1. Remove timeout-based validatePartitionExists from StoreChangelogReader; instead only try to refresh metadata once after all tasks have been created and their topology initialized (hence all stores have been registered).2. Add the logic to refresh partition metadata at the end of initialization if some restorers needing initialization cannot find their changelogs, hoping that in the next run loop these stores can find their changelogs.As a result, after `initialize` is called we may not be able to start initializing all the `needsInitializing` ones.As an optimization, we would not call `consumer#partitionsFor` any more, but only `consumer#listTopics` fetching all the topic metadata; so the only blocking calls left are `listTopics` and `endOffsets`, and we always capture timeout exceptions around these two calls, and delay to retry in the next run loop after refreshing the metadata. By doing this we can also reduce the number of request round trips between consumer and brokers.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #3748 from guozhangwang/K5797-handle-metadata-available",5
"KAFKA-4733: Improve Streams Reset Tool console outputAdded general explanation of the tool and what it does. Also added few details to the arguments.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Matthias J. Sax, Michael G. Noll, Guozhang WangCloses #2503 from gwenshap/KAFKA-4733",1
"MINOR: Increase the timeout in one of Connect's distributed system tests (#7789)Author: Randall Hauch <rhauch@gmail.com>Reviewers: Nigel Liang <nigel@nigelliang.com>, Roesler <john@confluent.io>",5
MINOR: Fix comment on how to consume __consumer_offsets (#3710),1
KAFKA-7922: Return authorized operations in describe consumer group responses (KIP-430 Part-1)-  Use automatic RPC generation in DescribeGroups Request/Response classesAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #6322 from omkreddy/KIP-430-Return-Ops,5
MINOR: Enable KRaft in transactions_test.py #11121Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
"KAFKA-10017: fix flaky EOS-beta upgrade test (#9688)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: GroupMetadataManager#shutdown should remove metrics (#11313)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-70 Patch from Prashanth Menon to add space-based retention setting.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1171886 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13861; Fix the validateOnly behavior for CreatePartitions requests in KRaft mode (#12106)The KRaft implementation of the `CreatePartitions` ignores the `validateOnly` flag in therequest and creates the partitions if the validations are successful. Fixed the behaviornot to create partitions upon validation if the `validateOnly` flag is true.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12849: KIP-744 TaskMetadata ThreadMetadata StreamsMetadata as API (#10840)Implementation of KIP-744.Creates new Interfaces for TaskMetadata, ThreadMetadata, andStreamsMetadata, providing internal implementations for each of them.Deprecates current TaskMetadata, ThreadMetadata under o.a.k.s.processor,and SreamsMetadata under a.o.k.s.state.Updates references on internal classes from deprecated classes to new interfaces.Deprecates methods on KafkaStreams returning deprecated ThreadMeatada andStreamsMetadata, and provides new ones returning the new interfaces.Update Javadocs referencing to deprecated classes and methods to pointto the right ones.Co-authored-by: Bruno Cadonna <cadonna@apache.org>Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-6054: Update Kafka Streams metadata to version 3 (#4880) - adds Streams upgrade tests for 1.1 release - introduces metadata version 3Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: improve descriptions of Streams reset tool optionsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck, Guozhang WangCloses #3107 from mjsax/minor-reset-tool-options",1
KAFKA-6049: Add time window support for cogroup (#7774)Follow up to PR #7538 (KIP-150)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-7464; catch exceptions in ""leaderEndpoint.close()"" when shutting down ReplicaFetcherThreadAfter KAFKA-6051, we close leaderEndPoint in replica fetcher thread initiateShutdown to try to preempt in-progress fetch request and accelerate repica fetcher thread shutdown. However, leaderEndpoint can throw an Exception when the replica fetcher thread is still actively fetching, which can cause ReplicaManager to fail to shutdown cleanly. This PR catches the exceptions thrown in ""leaderEndpoint.close()"" instead of letting it throw up in the call stack.Author: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5808 from hzxa21/KAFKA-7464",4
MINOR: Add num threads logging upon shutdown (#11652)1. Add num of threads logging upon shutdown.2. Prefix the shutdown thread with client id.Reviewers: John Roesler <vvcephei@apache.org>,0
"HOTFIX: fix compilation error (#8424)Reviewers: Matthias J. Sax <matthias@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <guozhang@confluent.io",5
"fix typo in processor-api developer guide docs (#7689)Fixed a small typo on the Processor API page of the Kafka Streams developer guide docs. (""buildeer"" changed to ""builder"")Reviewers: Bill Bejeck <bbejeck@gmail.com>",4
"KAFKA-3243: Fix Kafka basic ops documentation for Mirror maker, blacklist is not supported for new consumers…list is not supported for new consumersAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #923 from SinghAsDev/KAFKA-3243",5
"KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson, Ismael Juma, Joel Koshy, Jun Rao, and Edward Ribeiro",1
"KAFKA-8745: DumpLogSegments doesn't show keys, when the message is null (#7152)Make sure to show the message key, even when the message value is null.This changes the output of one of the tools. Is the output of the tool considered a public API? Does this need a discussion or a KIP?Testing: Ran the tool on a compacted topic. Previously, the tool did not show any message keys for tombstone messages (messages where the value is null). Now, the tool shows message keys.Reviewers: Mickael Maison <mimaison@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-776 Changing ZK format breaks some tools; reviewed by Neha Narkhede,4
"MINOR: Move `RaftRequestHandler` to `tools` package (#9377)To avoid confusion since it is only used by `TestRaftServer`, this PR moves `RaftRequestHandler` to the `tools` package and renames it to `TestRaftRequestHandler`.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
KAFKA-10556: NPE if sasl.mechanism is unrecognized (#9356)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-3426; Improve protocol type errors when invalid sizes are receivedAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Gwen ShapiraCloses #1100 from ijuma/kafka-3426-invalid-protocol-type-errors-invalid-sizes",0
"MINOR: improve Store parameter checksAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4063 from mjsax/minor-improve-store-parameter-checks",2
MINOR: Fix brokerId passed to metrics reporters (#4497)Remove caching of brokerId in DynamicBrokerConfig constructor and delay initialization until brokerId is set in KafkaConfig.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-5414; Revert KAFKA-5327 which changed ConsoleConsumer offset commit behaviorThis reverts commit d7d1196a0b542adb46d22eeb5b6d12af950b64c9.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3277 from hachikuji/KAFKA-5414,5
kafka-1797; add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Neha Narkhede,1
"MINOR: Fixed incomplete sentence in introduction docsAuthor: Jakub Dziworski <jakub.dziworski@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1994 from JakubDziworski/doc_fix",2
"KAFKA-2988; Change default configuration of the log cleanerAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #686 from granthenke/compaction",4
"KAFKA-870 hadoop-producer KafkaRecordWriter writes entire input buffer capacity, even when intended payload is smaller; reviewed by Neha Narkhede",5
MINOR: remove unnecessary placeholder from WorkerSourceTask#recordSent (#10659)Reviewers: Tom Bentley <tbentley@redhat.com>,1
"KAFKA-10684; Avoid additional envelope copies during network transmission (#9563)This patch creates a new `SendBuilder` class which allows us to avoid copying ""zero copy"" types when transmitting an api message over the network. This generalizes the pattern that was previously used only for `FetchResponse`. Initially we only apply this optimization to the `Envelope` types and `FetchResponse`, but in the future, it can be the default implementation for `toSend`.The patch also contains a few minor cleanups such as moving envelope parsing logic into `RequestContext`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
"HOTFIX: Task#dirtyClose should not throw (#8258)We need to swallow exceptions from StateManagerUtil#close in dirtyClose for both active and standby tasks.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Refactor return value (#4810)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: update to correct clock skewewencpUpdated the provisioning script to install ntp daemon.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Gwen ShapiraCloses #383 from granders/minor-systest-clock-skew,5
"KAFKA-3745: Add access to read-only key in value joiner (#10150)This PR implements adding read-only access to the key for KStream.join as described in KIP-149This PR as it stands does not affect the Streams Scala API. Updating the Streams Scala API will be done in a follow-up PR.Additionally, the original KIP did not include the KTable API, but I don't see any reason why we wouldn't want the same functionality there as well, this will be done in an additional follow-up PR after updating the existing KIP.Reviewers: Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-2599: Fix Metadata.getClusterForCurrentTopics throws NPE…h null checkingAuthor: Edward Ribeiro <edward.ribeiro@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #262 from eribeiro/KAFKA-2599",5
HOTFIX: fix ProcessorStateManager to use correct ktable partitionsguozhangwang* fix ProcessorStateManager to use correct ktable partitions* more ktable testsAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #635 from ymatsuda/more_ktable_test,3
"KAFKA-9602: Close the stream internal producer only in EOS (#8166)This bug reproduces through the trunk stream test, the producer was closed unexpectedly when EOS is not turned on.Will work on adding unit test to guard this logic.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
"MINOR: Fix flaky TestUtils functions (#4743)TestUtils#produceMessages should always close the KafkaProducer, evenwhen there is an exception.  Otherwise, the test will leak threads whenthere is an error.TestUtils#createNewProducer should create a producer with arequestTimeoutMs of 30 seconds by default, not around 10 seconds.This should avoid tests that flake when the load on Jenkins climbs.Fix two cases where a very short timeout of 2 seconds was getting set.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-3855: Guard race conditions in TopologyBuilderMark all public `TopologyBuilder` methods as synchronized as they can modify data-structures and these methods could be called from multiple threadsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1633 from dguy/kafka-3855,5
"KAFKA-9563: Fix Kafka Connect documentation around consumer and producer overrides (#8124)Kafka Connect main doc required a fix to distinguish between worker level producer and consumer overrides and per-connector level producer and consumer overrides, after the latter were introduced with KIP-458.  * [KAFKA-9563] Fix Kafka connect consumer and producer override documentationCo-authored-by: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: fix doc (#12243)Reviewers: Luke Chen <showuon@gmail.com>,2
kafka-1700; examples directory - README and shell scripts are out of date; patched by Geoffrey Anderson; reviewed by Jun Rao,5
kafka-1381; transient unit test failure in AddPartitionsTest; patched by Jun Rao; reviewed by Neha Narkhede,3
"MINOR: Change topic zNode's new reassigning fields names to snake case in order to be consistent with other fields (#7458)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",1
"MINOR: Remove 1 minute minimum segment interval (#5323)* new minimum is 0, just like window size* refactor tests to use smaller segment sizes as wellReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4602; KIP-72 - Allow putting a bound on memory consumed by Incoming requeststhis is the initial implementation.Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>Closes #2330 from radai-rosenblatt/broker-memory-pool-with-muting",5
KAFKA-7719: Improve fairness in SocketServer processors (KIP-402) (#6022)Limit the number of new connections processed in each iteration of eachProcessor. Block Acceptor if the connection queue is full on all Processors.Added a metric to track accept blocked time percent. See KIP-402 for details.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-7288: Fix for SslSelectorTest.testCloseConnectionInClosingState (#5504)Ensure that sends are completed before waiting for channel to be closed based on idle expiry, since channel will not be expired if added to ready keys in the next poll as a result of pending sends.Reviewers: Jun Rao <junrao@gmail.com>",1
"KAFKA-2464: client-side assignment for new consumerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jiangjie Qin, Onur Karaman, Ewen Cheslack-Postava, Guozhang WangCloses #165 from hachikuji/KAFKA-2464",5
"Handle topic names with / on Kafka server (0.8 branch); patched by Swapnil Ghike; reviewed by Jay Kreps, Joel Koshy and Jun Rao; KAFKA-495git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383739 13f79535-47bb-0310-9956-ffa450edef68",0
"MINOR: Fix swallowed NPE in KafkaServer.close() (#5339)If the server fails to connect to zk, `kafkaScheduler` will be `null`when closing  `KafkaServer`. The NPE is swallowed so it'sharmless apart from the confusing log noise.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-13916; Fenced replicas should not be allowed to join the ISR in KRaft (KIP-841, Part 2) (#12181)This path implements [KIP-841](https://cwiki.apache.org/confluence/display/KAFKA/KIP-841%3A+Fenced+replicas+should+not+be+allowed+to+join+the+ISR+in+KRaft). Specifically, it implements the following:* It introduces INELIGIBLE_REPLICA and NEW_LEADER_ELECTED error codes.* The KRaft controller validates the new ISR provided in the AlterPartition request and rejects the call if any replica in the new ISR is not eligible to join the the ISR - e.g. when fenced or shutting down. The leader reverts to the last committed ISR when its request is rejected due to this.* The partition leader also verifies that a replica is eligible before trying to add it back to the ISR. If it is not eligible, the ISR expansion is not triggered at all.* Updates the AlterPartition API to use topic ids. Updates the AlterPartition manger to handle topic names/ids. Updates the ZK controller and the KRaft controller to handle topic names/ids depending on the version of the request used.Reviewers: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7940: Fix flaky test case in `CustomQuotaCallbackTest` (#9777)This patch attempts to fix `CustomQuotaCallbackTest#testCustomQuotaCallback`. The test creates 99 partitions in a topic, and expects that we can get the partition info for all of them after 15 seconds. If we cannot, then we'll get the error:```org.scalatest.exceptions.TestFailedException: Partition [group1_largeTopic,69] metadata not propagated after 15000 ms```15 secs is not enough to complete the 99 partitions creation on a slow system. So, we fix it by explicitly wait until we've got the expected partition size before retrieving each partition info and we increase the wait time to 60s for all partition metadata to be propagated.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-8824: bypass value serde on null (#7235)In a KTable context, we should not pass null into a user-supplied serde.Testing: I verified that the change to the test results in test failures without the patch.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>,",5
kafka-1809; Refactor brokers to allow listening on multiple ports and IPs; patched by Gwen Shapira; reviewed by Joel Koshy and Jun Rao,1
"MINOR: Clean-up client javadoc warnings (#9463)Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
MINOR: Escape '<' and '>' symbols in quickstart streams code snippetThis was missing from [an earlier PR](https://github.com/apache/kafka/pull/2247) that escaped these symbols in another section of the doc.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2453 from vahidhashemian/doc/escape_lt_gt_in_streams_code,2
KAFKA-7412: clarify the doc for producer callback (#5798)The metadata in the callback is not null with non-null exception.Reviewers: Jun Rao <junrao@gmail.com>,5
KAFKA-13577: Replace easymock with mockito in kafka:core - part 1 (#11672)Reviewers: Tom Bentley <tbentley@redhat.com>,5
"MINOR: Fix logger name override (#4600)This regressed during the log4j -> scalalogging change.Added unit tests, one of which failed before the fix.",0
Replica.hw should be initialized to the smaller of checkedpointed HW and log end offset; patched by Yang Ye; reviewed by Jun Rao; KAFKA-539git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1395861 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7475 - capture remote address on connection authetication errors, and log it (#5729)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Ensure transactional message copier failures are logged (#11268)This patch has a couple small improvements to `TransactionalMessageCopier` logging:- Log all fatal exceptions which cause the copier to shutdown unexpectedly- Log all non-fatal exceptions which cause the copier to abort a transactionReviewers: David Jacot <djacot@confluent.io>,5
Dead code in the Log4j appender; patched by Jose Quinteiro; reviewed by Jun Rao; KAFKA-303git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1303239 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR; Use right enum value for broker registration change (#12236)The code used BrokerRegistrationFencingChange.FENCE when unfencing a broker and used BrokerRegistrationFencingChange.UNFENCE when fencing a broker, this is confusing. This commit flips the values of the two enums and changes their usage at all of the call sites.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-4183; Centralize checking for optional and default values in JsonConverterCleaner to just check once for optional & default value from the `convertToConnect()` function.It also helps address an issue with conversions for logical type schemas that have default values and null as the included value. That test case is _probably_ not an issue in practice, since when using the `JsonConverter` to serialize a missing field with a default value, it will serialize the default value for the field. But in the face of JSON data streaming in from a topic being [generous on input, strict on output](http://tedwise.com/2009/05/27/generous-on-input-strict-on-output) seems best.Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1872 from shikhar/kafka-4183",5
HOTFIX: GlobalStateManagerImpl in trunk has renamed the consumer field,1
KAFKA-6317; Maven artifact for kafka should not depend on log4jIt should only depend on slf4j-api (like kafka-clients). Therelease tarball still includes log4j and slf4j-log4j12.Manually verified that there are no duplicate dependenciesin the release tarball and `./gradlew core:dependencies`looks good.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4297 from ijuma/kafka-6317-kafka-slf4j-api-only,5
"KAFKA-6704: InvalidStateStoreException from IQ when StreamThread closes store (#4801)While using an iterator from IQ, it's possible to get an InvalidStateStoreException if the StreamThread closes the store during a range query.Added a unit test to SegmentIteratorTest for this condition.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Deploy VerifiableClient in constructor to avoid test timeouts (#8651)Previous to this fix a plugged-in verifiable client, such asconfluent-kafka-python, would be deployed on the node in the backgroundworker thread as the client was started. Since this could be time consuming(e.g., 10+ seconds) and since the main test thread would continue tooperate, it was common for the current test to time out waitingfor e.g. the verifiable producer to produce messages while it was in factstill deploying.The fix here is to deploy the verifiable client on the node whenthe verifiable client is instantiated, which is thus a blockingoperation on the main test thread, avoiding any test-based timeouts.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-5464: Follow up. Increase poll timeoutAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3496 from mjsax/KAFKA-5464-follow-up",5
"KAFKA-3270; Added some Happy Path Tests for the Reassign Partitions Commandwith help from enothereska  :)Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@apache.org>, Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #956 from benstopford/KAFKA-3270-ReassignPartitionsCommand-Tests",3
"KAFKA-2675; SASL/Kerberos follow upAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #376 from ijuma/KAFKA-2675-sasl-kerberos-follow-up",1
MINOR: add test case for fetching from a compacted topicAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #426 from hachikuji/compacted-topics,5
KAFKA-12959: Distribute standby and active tasks across threads to better balance load between threads (#11493)Balance standby and active stateful tasks evenly across threadsReviewer: Luke Chen <showuon@gmail.com>,5
"MINOR: Remove no longer used ReflectionsUtil class (#8762)This class has been unused since KIP-146 was merged, which introduced another way to load Connect plugins. Removing from the code base. Reviewers: Boyang Chan <boyang@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: Fix JavaDocs markup (#8459)Reviewers: Bill Bejeck <bbejeck@gmail.com>,2
"KAFKA-3086: Remove unused method in MirrorMaker.Author: Jakub Nowak <jakub.nowak94@interia.pl>Reviewers: Ismael Juma, Gwen Shapira, Grant Henke, Guozhang WangCloses #758 from Mszak/kafka-3086",1
"KAFKA-4885: Add client.close as exception handler in streams system testsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Damian Guy, Jason GustafsonCloses #2693 from guozhangwang/K4885-system-test-unexpected-exception-handler",5
"KAFKA-3627: consumer fails to execute delayed tasks in poll when records are availableAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei <liquanpei@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1295 from hachikuji/KAFKA-3627",5
"KAFKA-2644; Run relevant ducktape tests with SASL_PLAINTEXT and SASL_SSLRun sanity check, replication tests and benchmarks with SASL/Kerberos using MiniKdc.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Jun Rao <junrao@gmail.com>Closes #358 from rajinisivaram/KAFKA-2644",5
"KAFKA-5192: add WindowStore range scan (KIP-155)Implements range scan for keys in windowed and session storesModifies caching session and windowed stores to use segmented cache keys.Cache keys are internally prefixed with their segment id to ensure key ordering in the cache matches the ordering in the underlying store for keys spread across multiple segments.This should also result in fewer cache keys getting scanned for queries spanning only some segments.Author: Xavier Léauté <xavier@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #3027 from xvrl/windowstore-range-scan",5
"HOTFIX: In Connect test with auto topic creation disabled, ensure precreated topic is always usedAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3112 from ewencp/hotfix-precreate-topic",0
"KAFKA-12736: KafkaProducer.flush holds onto completed ProducerBatch(s) until flush completes (#10620)When flush is called a copy of incomplete batches is made. Thismeans that the full ProducerBatch(s) are held in memory until the flushhas completed. Note that the `Sender` removes producer batchesfrom the original incomplete collection when they're no longerneeded.For batches where the existing memory pool is used thisis not as wasteful as the memory will be returned to the pool,but for non pool memory it can only be GC'd after the flush hascompleted. Rather than use copyAll we can make a new array with only theproduceFuture(s) and await on those.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-8225 & KIP-345 part-2: fencing static member instances with conflicting group.instance.id (#6650)For static members join/rejoin, we encode the current timestamp in the new member.id. The format looks like group.instance.id-timestamp.During consumer/broker interaction logic (Join, Sync, Heartbeat, Commit), we shall check the whether group.instance.id is known on group. If yes, we shall match the member.id stored on static membership map with the request member.id. If mismatching, this indicates a conflict consumer has used same group.instance.id, and it will receive a fatal exception to shut down.Right now the only missing part is the system test. Will work on it offline while getting the major logic changes reviewed.Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7010: Rename ResourceNameType to PatternType (#5205)The initial PR for KIP-290 #5117 added a new `ResourceNameType`, which was initially a field on `Resource` and `ResourceFilter`. However, follow on PRs have now moved the name type fields to new `ResourcePattern` and `ResourcePatternFilter` classes. This means the old name is no longer valid and may be confusing. The PR looks to rename the class to a more intuitive `resource.PatternType`.@cmccabe also requested that the current `ANY` value for this class be renamed to avoid confusion. `PatternType.ANY` currently causes `ResourcePatternFilter` to bring back all ACLs that would affect the supplied resource, i.e. it brings back literal, wildcard ACLs, and also does pattern matching to work out which prefix acls would affect the resource.  This is very different from the behaviour of `ResourceType.ANY`, which just means the filter ignores the type of resources.  `ANY` is to be renamed to `MATCH` to disambiguate it from other `ANY` filter types. A new `ANY` will be added that works in the same way as others, i.e. it will cause the filter to ignore the pattern type, (but won't do any pattern matching).Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",1
"HOTFIX: Increase kafkatest startup wait time on ConnectDistributed serviceAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3006 from kkonstantine/HOTFIX-Align-startup-wait-time-for-ConnectDistributed-service-with-ConnectStandalone-in-kafkatests",3
"KAFKA-13114; Revert state and reregister raft listener (#11116)RaftClient's scheduleAppend may split the list of records into multiplebatches. This means that it is possible for the active controller tosee a committed offset for which it doesn't have an in-memory snapshot.If the active controller needs to renounce and it is missing anin-memory snapshot, then revert the state and reregister the Raftlistener. This will cause the controller to replay the entire metadatapartition.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Producers should set delivery timeout instead of retries  (#5425)Use delivery timeout instead of retries when possible and remove various TODOs associated with completion of KIP-91.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-654 Irrecoverable error while trying to roll a segment that already exists; patched by Neha Narkhede; reviewed by Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1419627 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-4058: Failure in org.apache.kafka.streams.integration.ResetIntegrationTest.testReprocessingFromScratchAfterReset - use AdminTool to check for active consumer groupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1767 from mjsax/kafka-4058-trunk,1
KAFKA-4529; LogCleaner should not delete the tombstone too early.cc junraoAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2260 from becketqin/KAFKA-4529-trunk,1
"KAFKA-12303: Fix handling of null values by Flatten SMT (#10073)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <gregh@confluent.io>",5
KAFKA-12398: Fix flaky test `ConsumerBounceTest.testClose` (#10243)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-5631; Use Jackson for serialising to JSON- Rename `encode` to `legacyEncodeAsString`, wecan remove this when we remove `ZkUtils`.- Introduce `encodeAsString` that uses Jackson.- Change `encodeAsBytes` to use Jackson.- Avoid intermediate string when convertingBroker to json bytes.The methods that use Jackson only supportJava collections unlike `legacyEncodeAsString`.Tests were added `encodeAsString` and`encodeAsBytes`.Author: umesh chaudhary <umesh9794@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4259 from umesh9794/KAFKA-5631",1
"MINOR: Disable Travis PR builds (#10038)Kafka is consuming over 50% of all our Travis executors according to Apache Infra, so let's disable it for now.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-9014: Fix AssertionError when SourceTask.poll returns an empty list (#7491)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
MINOR: add useful debug log messages to KConnect source task executionAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #957 from gwenshap/source_worker_debug,0
MINOR: Use enum for close mode in Selector instead of two booleans (#4559),1
KAFKA-3315: Add REST and Connector API to expose connector configurationAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #964 from Ishiihara/expose-connector-config,5
"KAFKA-10747: Extend DescribeClientQuotas and AlterClientQuotas APIs to support IP connection rate quota (KIP-612) (#9628)This PR adds support for IP entities to the `DescribeClientQuotas` and `AlterClientQuotas` APIs. This PR also adds support for describing/altering IP quotas via `kafka-configs` tooling.Reviewers: Brian Byrne <bbyrne@confluent.io>, Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",5
MINOR: add docs for 2.7 TRACE-level e2e latency metrics (#9339)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
kafka-1375; Formatting for in README.md is broken; patched by Stevo Slavic; reviewed by Jun Rao,2
KAFKA-521 Refactor the log subsystem. Patch reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1416253 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: Access apiversions data via method not field (#9759)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"MINOR: Docs update, Java clients use Kafka MetricsThis contribution is my original work and I license the work to the project under the project's open source license.Author: Jeff Klukas <jeff@klukas.net>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3249 from jklukas/docs-no-more-yammer-metrics-in-client",2
MINOR: update GroupMetadataManager#getMagic docs (#10442)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"MINOR: TopicIdPartition improvements (#11374)1. It should not require a TopicPartition during construction and normalusage.2. Simplify `equals` since `topicId` and `topicPartition` are nevernull.3. Inline `Objects.hash` to avoid array allocation.4. Make `toString` more concise using a similar approach as`TopicPartition` since this `TopicIdPartition` will replace`TopicPartition` in many places in the future.5. Add unit tests for `TopicIdPartition`, it seems like we had none.6. Minor clean-up in calling/called classes.Reviewers: David Jacot <djacot@confluent.io>, Satish Duggana <satishd@apache.org>",5
"MINOR: Let the list-store return null in putifabsent (#11335)This is to make sure that even if logging is disabled, we would still return null in order to workaround the deserialization issue for stream-stream left/outer joins.Reviewers: Matthias J. Sax <mjsax@apache.org>",0
"Follow up to KAFKA-695:Broker shuts down due to attempt to read a closed index file, reviewed by Neha and Jay",2
"KAFKA-9418; Add new sendOffsetsToTransaction API to KafkaProducer (#7952)This patch adds a new API to the producer to implement transactional offset commit fencing through the group coordinator as proposed in KIP-447. This PR mainly changes on the Producer end for compatible paths to old `sendOffsetsToTxn(offsets, groupId)` vs new `sendOffsetsToTxn(offsets, groupMetadata)`.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5435; Improve producer state loading after failureAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>Closes #3361 from hachikuji/KAFKA-5435-ALT",5
KAFKA-3754; Add GC log retention policy to limit size of logAdd a default log retention policy to keep GC logs from growing too largeAuthor: Ryan P <ryan.n.pridgeon@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1431 from rnpridgeon/KAFKA-3754,2
"KAFKA-13096: Ensure queryable store providers is up to date after adding stream thread (#10921)When a new thread is added the queryable store providers continues to use the store providers it was given when KafkaStreams was instantiated. This means IQ will start performing lookups against an out-of-date list of threads, and may eventually become completely broken. We must make sure the QueryableStoreProvider is updated when threads are added and removed.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",4
KAFKA-5508; Documentation for altering topicsOperations documentation should guide user to employ `kafka-configs.sh` to add/remove configs for a topic.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3429 from huxihx/KAFKA-5508_Doc_for_altering_topics,2
MINOR: Improve documentation of AdminClient and fix exception thrownMake documentation consistent across methods and throwIllegalStateException instead of IllegalArgumentException insome cases.Also include a couple of minor fixes in upgrade.html.Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3781 from lindong28/minor-admin-client-comment,0
"Fixed docs regarding caching default (#6375)The current docs are out of date regarding the default caching state.Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",5
Use withRequiredArg while parsing jopt options in all tools; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-786,1
"KAFKA-8349; Add Windows batch files corresponding to kafka-delete-records.sh and kafka-log-dirs.sh (#6709)Some shell scripts don't have corresponding batch files in bin\windows.For improving Windows platform support, This PR adds the following batch files:- bin\windows\kafka-delete-records.bat- bin\windows\kafka-log-dirs.batReviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-12382: add a README for KIP-500 (#10227)Reviewers: Tom Bentley <tbentley@redhat.com>, Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",5
https://issues.apache.org/jira/browse/KAFKA-10456 (#9240)Fix typo in description of ConsoleProducer.,2
KAFKA-1341 Client Selector doesn't check connection id properly; reviewed by Jay Kreps and Neha Narkhede,5
KAFKA-10878 Check failed message in ProtocolSerializationTest (#9776)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"MINOR: Clarify config names for EOS versions 1 and 2 (#9670)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-8972 (2.4 blocker): clear all state for zombie task on TaskMigratedException (#7608)Third bugfix for the failing broker bounce system test with cooperative rebalancing:tl;dr We need to remove everything associated with a task when it is closed, but in some cases (eg AssignedTasks#commit) on a TaskMigratedExceptionwe would close it as a zombie and then (only) remove the taskId from therunning` map. This left its partitions, restorers, state stores, etc around and in an undefined state, causing exceptions when closing and/or opening the stores again.Longer explanation:In AssignedTasks (the abstract class from which the standby and active task variations extend) a commit failure (even due to broker down/unavailable) is treated as a TaskMigratedException after which the failed task is closed as a zombie and removed from running -- the remaining tasks (ie those still in running are then also closed as zombies in the subsequent onPartitionsLostHowever we do not remove the closed task from runningByPartition nor do we remove the corresponding changelogs, if restoring, from the StoreChangelogReader since that applies only to active tasks, and AssignedTasks is generic/abstract. The changelog reader then retains a mapping from the closed task's changelog partition to its CompositeRestoreListener (and does not replace this when the new one comes along after the rebalance). The restore listener has a reference to a specific RocksDBStore instance, one which was closed when the task was closed as a zombie, so it accidentally tries to restore to the ""old"" RocksDBStore instance rather than the new one that was just opened.Although technically this bug existed before KIP-429, it was only uncovered now that we remove tasks and clear their state/partitions/etc one at a time. We don't technically need to cherrypick the fix back earlier as before we just blindly clear all data structures entirely during an eager rebalance.Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-6773; Allow offset commit/fetch/describe/delete with empty groupId (#4851)We had a regression in #4788 which caused the offset commit/fetch/describe APIs to fail if the groupId was empty. This should be allowed for backwards compatibility. Additionally, I have modified DeleteGroups to allow removal of the empty group, which was missed in the initial implementation. I've added a test case to ensure that we do not miss this again in the future.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
HOTFIX: Increase timeout for bounce testAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1874 from enothereska/hotfix-bounce-test,3
"MINOR: Pin ducktape version to < 0.9 (#12242)With newer ducktape versions than < 0.9 system testsmay run into authentication issues with the AK system testinfrastructure.The version will be bumped up once we have infrastructurein place for newer paramiko versions brought in by ducktape0.9.Reviewers: Lucas Bradstreet <lucas@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Kvicii <Karonazaba@gmail.com>",5
Trogdor: Add Task State filter to /coordinator/tasks endpoint (#5907)Reviewers: Colin McCabe <cmccabe@apache.org>,1
MINOR: optimize integration test shutdown (#8366)* delete topics before tearing down multi-node clusters to avoid leader elections during shutdown* tear down all nodes concurrently instead of sequentiallyReviewers: Matthias J. Sax <matthias@confluent.io>,5
Explicitly list ZooKeeper as a dependency instead of including jar in-treepatch by cburroughs; reviewed by nehanarkhede and hsaputra for KAFKA-90git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160905 13f79535-47bb-0310-9956-ffa450edef68,1
"HOTIFX: streams system test do not start up correctlyAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang, Damian Guy, Eno ThereskaCloses #2428 from mjsax/hotfixSystemTests",5
"KAFKA-4241: StreamsConfig doesn't pass through custom consumer and producer properties to ConsumerConfig and ProducerConfigpass through user-defined consumer and producer properties from StreamsConfig to ConsumerConfig and ProducerConfig.For example, consumer interceptor support, i.e, consumer.interceptor.classes=SomeClassAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1943 from dguy/interceptor",1
"KAFKA-4247; Prevent CLASSPATH from beginning with a single colonDifferent fix for problem addressed by https://github.com/apache/kafka/pull/1953. Should prevent the CLASSPATH environment variable from being prefixed by a single colon before the JVM is invoked in the run-class script, which will then prevent the current working directory from being unintentionally included in the classpath when using the Reflections library.If the current working directory should still be included in the classpath, it just needs to be explicitly specified either with its fully-qualified pathname or as a single dot (""."").Author: Chris Egerton <chrise@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Jun Rao <junrao@gmail.com>Closes #4406 from C0urante/fix-colon-prefixed-classpath",0
"HOTFIX: Revert KAFKA-10199 which is causing compilation failures (#12532)Compilation is failing after these two commits:```> Task :streams:compileJava/Users/jgustafson/Projects/kafka/streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java:852: error: cannot find symbol                        tasks.addPendingTaskToClose(restoringTask.id());                             ^  symbol:   method addPendingTaskToClose(org.apache.kafka.streams.processor.TaskId)  location: variable tasks of type org.apache.kafka.streams.processor.internals.Tasks1 error```Also here:```[2022-08-17T20:58:20.912Z] > Task :streams:compileTestJava[2022-08-17T20:58:20.912Z] /home/jenkins/jenkins-agent/workspace/Kafka_kafka-pr_PR-12530/streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java:822: error: method setupForRevocation(Set<Task>,Set<Task>) is already defined in class TaskManagerTest[2022-08-17T20:58:20.912Z]     private TaskManager setupForRevocation(final Set<Task> tasksInStateUpdater,``` This patch reverts them.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
TRIVIAL: Fix misc. numerical issues in histogram.,0
"MINOR: Enable kraft support in quota integration tests (#12217)Enable kraft support in BaseQuotaTest and its extensions.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>",1
"KAFKA-8835; KIP-352 docs update (#7434)Doc updates for KIP-352.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8615: Change to track partition time breaks TimestampExtractor (#7054)The timestamp extractor takes a previousTimestamp parameter which should be the partition time. This PR adds back in partition time tracking for the extractor, and renames previousTimestamp --> partitionTimeReviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <mjsax@apache.org>",4
"kafka-1337; follow-up patch to add broker list for new producer in system test overriden function; patched by Guozhang Wang; reviewed by Neha Narkhede, Jun Rao",1
"MINOR: Upgrade to Gradle 2.13There are a few improvements in 2.12 and 2.13. I am particularly interested in the performance improvements:* 2.12: ""This release brings support for compile only dependencies, improved build script compilation speed and even better IDE support.""* 2.13: ""We've achieved performance improvements during Gradle's configuration and execution phase, where we have measured up to 25% improvements to build time in our performance tests. No changes to your build script are necessary to start taking advantage of these improvements.""Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1271 from ijuma/gradle-2.13",1
KAFKA-6145: KIP-441: avoid unnecessary movement of standbys (#8436)Reviewers: John Roesler <vvcephei@apache.org>,5
"MINOR: improve description of `commit.interval.ms` config (#12169)Reviewers: Luke Chen <showuon@gmail.com>, Kvicii Y <@Kvicii>, Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-8725; Improve LogCleanerManager#grabFilthiestLog error handling (#7475)KAFKA-7215 improved the log cleaner error handling to mitigate thread death but missed one case. Exceptions in grabFilthiestCompactedLog still cause the thread to die.This patch improves handling to ensure that errors in that function still mark a partition as uncleanable and do not crash the thread.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-6702: Wrong className in LoggerFactory.getLogger method (#4772)Reviewers: Manikumar Reddy, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6361: Fix log divergence between leader and follower after fast leader fail over (#4882)Implementation of KIP-279 as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-279%3A+Fix+log+divergence+between+leader+and+follower+after+fast+leader+fail+overIn summary:- Added leader_epoch to OFFSET_FOR_LEADER_EPOCH_RESPONSE- Leader replies with the pair( largest epoch less than or equal to the requested epoch, the end offset of this epoch)- If Follower does not know about the leader epoch that leader replies with, it truncates to the end offset of largest leader epoch less than leader epoch that leader replied with, and sends another OffsetForLeaderEpoch request. That request contains the largest leader epoch less than leader epoch that leader replied with.Reviewers: Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>",1
Expose different data to fetch requests from the follower replicas and consumer clients; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-376git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1382828 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR: Use exceptions in o.a.k.common if possible and deprecate ZkUtils (#5255)Also:- Remove exceptions in `kafka.common` that are no longer used.- Keep `kafka.common.KafkaException` as it's still used by `ZkUtils`,`kafka.admin.AdminClient` and `kafka.security.auth` classes andwe would like to maintain compatibility for now.- Add deprecated annotation to `kafka.admin.AdminClient`. The scaladocstated that the class is deprecated, but the annotation was missing.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
"KAFKA-8341. Retry Consumer group operation for NOT_COORDINATOR error (#6723)An API call for consumer groups must send a FindCoordinatorRequest to find the consumer group coordinator, and then send a follow-up request to that node.  But the coordinator might move after the FindCoordinatorRequest but before the follow-up request is sent.  In that case we currently fail.This change fixes that by detecting this error and then retrying.  This fixes listConsumerGroupOffsets, deleteConsumerGroups, and describeConsumerGroups.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Boyang Chen <bchen11@outlook.com>",4
KAFKA-3642: Fix NPE from ProcessorStateManager when the changelog topic not existsIssue: https://issues.apache.org/jira/browse/KAFKA-3642Author: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1289 from kawamuray/KAFKA-3642-streams-NPE,0
"KAFKA-3504; Log compaction for changelog partitionAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #1203 from enothereska/KAFKA-3504-logcompaction",2
KAFKA-216: Add nunit license to the NOTICE file.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1208878 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Pass a streams config to replace the single state dir (#4714)This is a general change and is re-requisite to allow streams benchmark test with different streams tests. For the streams benchmark itself I will have a separate PR for switching configs. Details:1. Create a ""streams.properties"" file under PERSISTENT_ROOT before all the streams test. For now it will only contain a single config of state.dir pointing to PERSISTENT_ROOT.2. For all the system test related code, replace the main function parameter of state.dir with propsFilename, then inside the function load the props from the file and apply overrides if necessary.3. Minor fixes.Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Add clarifying ""additionally"" to streams aggregator docs that is missing in one place. (#8237)Reviewer: Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3182; Fix testSocketsCloseOnShutdown transient failures* Turned off Nagle on the sending sockets to force the socket to physically acknowledge after the first write in `sendRequest`* Added a `200ms` delay between write attempts (necessary on Linux, but not Mac)Author: Armin Braun <armin.braun@1und1.de>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2632 from original-brownbear/KAFKA-3182",1
"MINOR: Fix a wrong description in PipeDemo's javadoc (#6901)This PR fixes a wrong input stream name in PipeDemo's javadoc.Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix event output inconsistencies in TransactionalMessageCopier (#12098)This patch fixes some strangeness and inconsistency in the messages written by `TransactionalMessageCopier` to stdout. Here is a sample of two messages.Progress message:```{""consumed"":33000,""stage"":""ProcessLoop"",""totalProcessed"":33000,""progress"":""copier-0"",""time"":""2022/04/24 05:40:31:649"",""remaining"":333}```The `transactionalId` is set to the value of the `progress` key.And a shutdown message:```{""consumed"":33333,""shutdown_complete"":""copier-0"",""totalProcessed"":33333,""time"":""2022/04/24 05:40:31:937"",""remaining"":0}```The `transactionalId` this time is set to the `shutdown_complete` key and there is no `stage` key.In this patch, we change the following:1. Use a separate key for the `transactionalId`.2. Drop the `progress` and `shutdown_complete` keys.3. Use `stage=ShutdownComplete` in the shutdown message.4. Modify `transactional_message_copier.py` system test service accordingly.Reviewers: David Arthur <mumrah@gmail.com>",3
KAFKA-9832: fix attempt to commit non-running tasks (#8580)KAFKA-9832: fix attempt to commit non-running tasksReviewers: Matthias J. Sax <matthias@confluent.io>,5
DumpLogSegments outputs wrong offsets; kafka-128 patched by junrao; reviewed by Joelgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1163929 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6481; Improving performance of the function ControllerChannelManager.addUpd……ateMetadataRequestForBrokers*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Lucas Wang <luwang@linkedin.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #4472 from gitlw/improving_addUpdateMetadataRequestForBrokers",5
"KAFKA-3303; Pass partial record metadata to ProducerInterceptor.onAcknowledgement on errorThis is a KIP-42 followup.Currently, If sending the record fails before it gets to the server, ProducerInterceptor.onAcknowledgement() is called with metadata == null, and non-null exception. However, it is useful to pass topic and partition, if known, to ProducerInterceptor.onAcknowledgement() as well. This patch ensures that  ProducerInterceptor.onAcknowledgement()  gets record metadata with topic and maybe partition. If partition is not set in 'record' and KafkaProducer.send() fails before partition gets assigned, then ProducerInterceptor.onAcknowledgement() gets RecordMetadata with partition == -1. Only time when  ProducerInterceptor.onAcknowledgement() gets null record metadata is when the client passes null record to KafkaProducer.send().Author: Anna Povzner <anna@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ashish Singh <asingh@cloudera.com>, Jun Rao <junrao@gmail.com>Closes #1015 from apovzner/kip42-3",5
KAFKA-5160; KIP-98 Broker side support for TxnOffsetCommitRequestThis patch adds support for the `TxnOffsetCommitRequest` added in KIP-98. Desired handling for this request is [described here](https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit#bookmark=id.55yzhvkppi6m) .The functionality includes handling the stable state of receiving `TxnOffsetCommitRequests` and materializing results only when the commit marker for the transaction is received. It also handles partition emigration and immigration and rebuilds the required data structures on these events.Tests are included for all the functionality.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2970 from apurvam/KAFKA-5160-broker-side-support-for-txnoffsetcommitrequest,1
"MINOR: Improve KafkaStreamsTest: testInitializesAndDestroysMetricsReporters (#11494)Add additional asserts for KafkaStreamsTest: testInitializesAndDestroysMetricsReporters to help diagnose if it flakily fails in the future.- MockMetricsReporter gets initialized only once during KafkaStreams construction, so make assert check stricter by ensuring initDiff is one.- Assert KafkaStreams is not running before we validate whether MockMetricsMetricsReporter close count got incremented after streams close.Reviewer: Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-12952 Add header and footer records for raft snapshots (#10899)Add header and footer records for raft snapshots. This helps identify when the snapshotstarts and ends. The header also contains a time.  The time field is currently set to 0.KAFKA-12997 will add in the necessary wiring to use the correct timestamp.Reviewers: Jose Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-12648: standardize startup timeout to fix some flaky NamedTopologyIntegrationTest tests (#11824)Seen a few of the new tests added fail on PR builds lately with ""java.lang.AssertionError: Expected all streams instances in [org.apache.kafka.streams.processor.internals.namedtopology.KafkaStreamsNamedTopologyWrapper@7fb3e6b0] to be RUNNING within 30000 ms""We already had some tests using the 30s timeout while others were bumped all the way up to 60s, I figured we should try out a default timeout of 45s and if we still see failures in specific tests we can go from there",3
KAFKA-5258; Move all partition and replica state transition rules into their statesToday PartitionStateMachine and ReplicaStateMachine define and assert thevalid state transitions inline for each state. It's cleaner to move thetransition rules into ReplicaState/PartitionState and do the assertion atthe top of the handleStateChange.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3071 from onurkaraman/KAFKA-5258,2
"KAFKA-5550; Connect Struct.put() should include the field name if validation fails (#3507)Changed call to use the overload of ConnectSchema.validateValue() method with the field name passed in. Ensure that field in put call is not null.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-1251 Missed one per-node metric.,5
KAFKA-9944: Added supporting customized HTTP response headers for Kafka Connect. (#8620)Added support for customizing the HTTP response headers for Kafka Connect as described in KIP-577.Author: Jeff Huang <jeff.huang@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"MINOR: Fix ProcessorTopologyTestDriver to support multiple source topicsThere's a minor bug in ProcessorTopologyTestDriver that prevents it from working with a topology that contains multiple sources.  The bug is that ```consumer.assign()``` is called while looping through all the source topics, but, consumer.assign resets the state of the MockConsumer to only consume from the topics passed in.  This patch fixes the issue by calling consumer.assign once with all the TopicPartition instances.  Unit test (testDrivingSimpleMultiSourceTopology) included.This contribution is my original work and I license the work to the project under the project's open source license.Author: Mathieu Fenniak <mathieu.fenniak@replicon.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1782 from mfenniak/ProcessorTopologyTestDriver-multiple-source-bugfix",3
KAFKA-13941; Reenable ARM in Jenkinsfile (#12221)This patch reenables the ARM build in Jenkins since https://issues.apache.org/jira/browse/INFRA-23305 has been resolved.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
MINOR: Fix bugs identified by compiler warnings (#6258)- Add missing string interpolation- Fix and simplify testElectPreferredLeaders- Remove unused code- Replace deprecated usage of JUnit `assertThat`- Change var to val and fix non-exhaustive pattern match- Fix eta warning- Simplify code- Remove commented out codeReviewers: Jun Rao <junrao@gmail.com>,4
KAFKA-6760: Fix response logging in the Controller (#4834)- Override toString in LeaderAndIsrResponse and StopReplicaResponse- Add unit testsReviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-2409; have KafkaConsumer.committed return null when there is no commitAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Onur Karaman, Guozhang WangCloses #243 from hachikuji/KAFKA-2409",5
MINOR: Reinstate info-level log for dynamic update of SSL keystores (#6925)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"MINOR: Avoiding attempt to connect to Zookeeper on closing consumer for deleting random group.id with the new oneWith the new consumer the ""/consumers"" path on Zookeeper isn't filled by consumer info. On closing the new consumer, there is some code that is useless to execute for trying to connect to Zookeeper (but the URL is null).Author: ppatierno <ppatierno@live.com>Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3301 from ppatierno/old-consumer-delete-groupid",4
"MINOR: Brokers in KRaft don't need controller listener (#11511)The KRaft brokers should not list the names in `controller.listener.names` in `listeners` because brokers do not bind to those endpoints. This commit also removes the extra changes to the security protocol map because the `PLAINTEXT` protocol doesn't require additional configuration.To fully support all of the security protocol configuration additional changes to `QuorumTestHarness` are needed. Those changes can be made when migrating integration tests that need this functionality.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",5
Add recordMetadata() to StateStoreContext (#11498)Implements KIP-791Reviewers: John Roesler <vvcephei@apache.org>,3
"KAFKA-7298; Raise UnknownProducerIdException if next sequence number is unknown (#5518)If the only producer state left in the log is a transaction marker, then we do not know the next expected sequence number. This can happen if there is a call to DeleteRecords which arrives prior to the writing of the marker. Currently we raise an OutOfOrderSequence error when this happens, but this is treated as a fatal error by the producer. Raising UnknownProducerId instead allows the producer to check for truncation using the last acknowledged sequence number and reset if possible.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Improve exception messages when state stores cannot be accessed. (#4383),1
"KAFKA-12152; Idempotent Producer does not reset the sequence number of partitions without in-flight batches (#9832)When a `OutOfOrderSequenceException` error is received by an idempotent producer for a partition, the producer bumps its epoch, adjusts the sequence number and the epoch of the in-flight batches of the partitions affected by the `OutOfOrderSequenceException` error. This happens in `TransactionManager#bumpIdempotentProducerEpoch`.The remaining partitions are treated separately. When the last in-flight batch of a given partition is completed, the sequence number is reset. This happens in `TransactionManager#handleCompletedBatch`.However, when a given partition does not have in-flight batches when the producer epoch is bumped, its sequence number is not reset. Similarly, when a in-flight batch eventually fails after the producer epoch is bumped, the batch is discarded and sequence number for its partition is not reset. In both cases, it results in having subsequent producer request to use the new producer epoch with the old sequence number and to be rejected by the broker.With this patch, the producer id/epoch is now stored in the partition state. This ensure that the producer id/epoch of a given partition remains consistent with its sequence number. When the producer epoch is bumped, the producer epoch of the partition is lazily updated and its sequence number is reset accordingly. This happens only when all the in-flight batches have been resolved.Reviewers: Bob Barrett <bob.barrett@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: Use `close()` instead of `dispose()` in various RocksDB classesThe latter has been deprecated.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1690 from ijuma/rocks-db-dispose-methods-deprecated,5
KAFKA-5584; Fix integer overflow in Log.sizeIt may lead to wrong metrics and it may breaksize-based retention.Author: Gregor Uhlenheuer <kongo2002@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3521 from kongo2002/KAFKA-5584,4
Minor: Fix KafkaConsumer Constructor Summary javadocAuthor: jholoman <jeff.holoman@gmail.com>Reviewers: Gwen ShapiraCloses #576 from jholoman/minor-consumer-constructor-javadoc,2
"KAFKA-4144: Allow per stream/table timestamp extractorAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Damian Guy, Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2466 from jeyhunkarimov/KAFKA-4144",4
"KAFKA-8277: Fix NPEs in several methods of ConnectHeaders (#6550)Replace `headers.isEmpty()` by calls to `isEmpty()` as the latter does a null check on heathers (that is lazily created).Author: Sebastián Ortega <sebastian.ortega@letgo.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Arjun Satish <arjunconfluent.io>, Randall Hauch <rhauch@gmail.com>",5
KAFKA-9041; Flaky Test LogCleanerIntegrationTest#testIsThreadFailed (#7542)Aims to fix the flaky LogCleanerIntegrationTest#testIsThreadFailed by changing how metrics are cleaned.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-5402; Avoid creating quota related metrics if quotas not enabledAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3303 from rajinisivaram/KAFKA-5402",5
MINOR: AbstractCoordinatorTest should close coordinator explicitly (#10001)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Improve Kafka Streams JavaDocs with regard to record metadata (#10810)Reviewers: Luke Chen <howuon@gmail.com>, Josep Prat <josep.prat@aiven.io>, John Roesler <john@confluent.io>",5
"MINOR: Next round of fetcher thread consolidation (#5587)Pull the epoch request build logic up to `AbstractFetcherThread`. Also get rid of the `FetchRequest` indirection.Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Fix compilation error in PlaintextConsumerTest under scala 2.12 (#5674),3
MINOR: exclude all `src/generated` and `src/generated-test` (#10671)Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,3
"KAFKA-7056: Moved Connect’s new numeric converters to runtime (KIP-305)KIP-305 added numeric converters to Connect, but these were added in Connect’s API module in the same package as the `StringConverter`. This commit moves them into the Runtime module and into the `converters` package where the `ByteArrayConverter` already lives. These numeric converters have not yet been included in a release, and so they can be moved without concern.All of Connect’s converters must be referenced in worker / connector configurations and are therefore part of the API, but otherwise do not need to be in the “api” module as they do not need to be instantiated or directly used by extensions. This change makes them more similar to and aligned with the `ByteArrayConverter`.It also gives us the opportunity to move them into the “api” module in the future (keeping the same package name), should we ever want or need to do so. However, if we were to start out with them in the “api” module, we would never be able to move them out into the “runtime” module, even if we kept the same package name. Therefore, moving them to “runtime” now gives us a bit more flexibility.This PR moves the unit tests for the numeric converters accordingly, and updates the `PluginsUtil` and `PluginUtilsTest` as well.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5222 from rhauch/kafka-7056",5
"KAFKA-6979; Add `default.api.timeout.ms` to KafkaConsumer (KIP-266) (#5122)Adds a configuration that specifies the default timeout for KafkaConsumer APIs that could block. This was introduced in KIP-266.Reviewers: Satish Duggana <satish.duggana@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10301: Do not clear Partition#remoteReplicasMap during partition assignment updates (#9065)We would previously update the map by adding the new replicas to the map and then removing the old ones.During a recent refactoring, we changed the logic to first clear the map and then add all the replicas to it.While this is done in a write lock, not all callers that access the map structure use a lock. It is safer to revert tothe previous behavior of showing the intermediate state of the map with extra replicas, rather than anintermediate state of the map with no replicas.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-6300; SelectorTest may fail with ConcurrentModificationExceptionSynchronization is added w.r.t. sockets ArrayList to avoid ConcurrentModificationExceptionAuthor: tedyu <yuzhihong@gmail.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4299 from tedyu/trunk",1
"KAFKA-1030 Addition of partitions requires bouncing all the consumers of that topic; reviewed by Neha, Swapnil, Joel",1
KAFKA-4363; Documentation for sasl.jaas.config propertyAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2316 from rajinisivaram/KAFKA-4363,5
KAFKA-4290: Fix timeout overflow in WorkerCoordinator.pollAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2009 from hachikuji/KAFKA-4290,5
MINOR: Remove `toStruct` and `fromStruct` methods from generated protocol classes (#9960)Update few classes that were still using the removed methods (includingtests that are no longer required).Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
HOTFIX: Verifiable producer request timeout needs conversion to millisecondsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2494 from hachikuji/hotfix-verifiable-producer-request-timeout,0
"KAFKA-12334: Add the KIP-500 metadata shellThe Kafka Metadata shell is a new command which allows users tointeractively examine the metadata stored in a KIP-500 cluster.It can examine snapshot files that are specified via --snapshot.The metadata tool works by replaying the log and storing the state intoin-memory nodes.  These nodes are presented in a fashion similar tofilesystem directories.Reviewers: Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>, Igor Soarez <soarez@apple.com>",5
"MINOR: Remove slf4j-log4j from kafka-streams compile dependenciesAs kafka-streams is intended to be used by applications that may or may not wish to use log4j, kafka-streams itself should not have a dependency on a concrete log framework.  This change adapts the dependencies to be API-only for compile, and framework-specific for the test runtime only.I read through the [Contributing Code Guidelines](https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes) and interpreted this as a trivial change that doesn't require a Jira ticket.  Please let me know if I've interpreted that wrongly.This contribution is my original work and I license the work to the project under the project's open source license.Author: Mathieu Fenniak <mathieu@encouragemarketing.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1639 from mfenniak/fix-slf4j-dependency-for-streams",0
"MINOR: revert KIP-770 (#12383)KIP-770 introduced a performance regression and needs some re-design.Needed to resolve some conflict while reverting.This reverts commits 1317f3f77a9e1e432e7a81de2dcb88365feeac43 and 0924fd3f9f75c446310ed1e97b44bbc3f33c6c31.Reviewers:  Sagar Rao <sagarmeansocean@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-4861; GroupMetadataManager record is rejected if broker configured with LogAppendTimeThe record should be created with CreateTime (like in the producer). The conversion toLogAppendTime happens automatically (if necessary).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2657 from ijuma/kafka-4861-log-append-time-breaks-group-data-manager,5
"MINOR: Update dependencies for Kafka 2.4 (#7126)Scala 2.12.9 brings another 5% ~ 10% improvement in compiler performance,improved compatibility with JDK 11/12/13, and experimental infrastructure forbuild pipelining.zstd update includes performance improvements, among which theprimary improvement is that decompression is ~7% faster.Level | v1.4.0 | v1.4.1 | Delta-- | -- | -- | --1 | 1390 MB/s | 1453 MB/s | +4.5%3 | 1208 MB/s | 1301 MB/s | +7.6%5 | 1129 MB/s | 1233 MB/s | +9.2%7 | 1224 MB/s | 1347 MB/s | +10.0%16 | 1278 MB/s | 1430 MB/s | +11.8%Jetty 9.4.19 includes a number of bug fixes:https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.19.v20190610Mockito 3.0.0 switched the Java requirement from 7 to 8.Several updates to owaspDepCheckPlugin (4.0.2 -> 5.2.1).The rest are patch updates.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: consolidate processor context for active/standby (#8669)This is a prerequisite for KAFKA-9501 and will also be useful for KAFKA-9603There should be no logical changes here: the main difference is the removal of StandbyContextImpl in preparation for contexts to transition between active and standby.Also includes some minor cleanup, eg pulling the ReadOnly/ReadWrite decorators out into a separate file.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-1815; ServerShutdownTest fails in trunk; patched by Chris Cope; reviewed by Jun Rao,1
KAFKA-7110: Add windowed changelog serde (#5307)Currently the TimeWindowedSerde does not deserialize the windowed keys from a changelog topic properly. There are a few assumptions made in the TimeWindowedDeserializer that prevents the changelog windowed keys from being correctly deserialized. This PR will introduce a new WindowSerde to allow proper deserialization of changelog windowed keys. Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
HOTFIX: Fix apache headers in float serde class fileshachikujiAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2679 from guozhangwang/KHotfix-serde-headers,0
MINOR: Rename the @metadata topic to __cluster_metadata #11102Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
"KAFKA-3941: Delay eviction listener in InMemoryKeyValueLoggedStore after restorationAlso move the initialization that restores from changelog to inner stores.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Dan NorwoodCloses #1610 from guozhangwang/K3941-avoid-eviction-listener",4
MINOR: Update kafka-run-class.bat to handle spaces in classpathhandle existing classpath with spaceslist each lib dependency individuallyAuthor: Jon Freedman <jon.freedman@zoho.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2433 from jonfreedman/trunk,1
KAFKA-6277: Ensure loadClass for plugin class loaders is thread-safe.`loadClass` needs to be synchronized to protect subsequent calls to `defineClass`.Details in the javadoc of this PR as well as here too: https://docs.oracle.com/javase/7/docs/technotes/guides/lang/cl-mt.html/cc ewencp rhauchAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4428 from kkonstantine/KAFKA-6277-Make-loadClass-thread-safe-for-class-loaders-of-Connect-plugins,1
KAFKA-12273 InterBrokerSendThread#pollOnce throws FatalExitError even… (#10024)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Use `Map.forKeyValue` to avoid tuple allocation in Scala 2.13 (#9299)`forKeyValue` invokes `foreachEntry` in Scala 2.13 and falls back to`foreach` in Scala 2.12.This change requires a newer version of scala-collection-compat, soupdate it to the latest version (2.2.0).Finally, included a minor clean-up in `GetOffsetShell` to use `toArray`before `sortBy` since it's more efficient.Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, José Armando García Sancio <jsancio@users.noreply.github.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-8729, pt 2: Add error_records and error_message to PartitionResponse (#7150)As noted in the KIP-467, the updated ProduceResponse is```Produce Response (Version: 8) => [responses] throttle_time_ms  responses => topic [partition_responses]    topic => STRING    partition_responses => partition error_code base_offset log_append_time log_start_offset      partition => INT32      error_code => INT16      base_offset => INT64      log_append_time => INT64      log_start_offset => INT64      error_records => [INT32]         // new field, encodes the relative offset of the records that caused error      error_message => STRING          // new field, encodes the error message that client can use to log itself    throttle_time_ms => INT32with a new error code:```INVALID_RECORD(86, ""Some record has failed the validation on broker and hence be rejected."", InvalidRecordException::new);Reviewers: Jason Gustafson <jason@confluent.io>, Magnus Edenhill <magnus@edenhill.se>, Guozhang Wang <wangguoz@gmail.com>",5
Fatal error during KafkaServerStable startup when hard-failed broker is re-started; patched by Swapnil Ghike; reviewed by Jun Rao and Jay Kreps; kafka-757,0
"KAFKA-13423: GlobalThread should not log ERROR on clean shutdown (#11455)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",5
"KAFKA-7225; Corrected system tests by generating external properties file (#5489)Fix system tests from earlier #5445 by moving to the `ConnectSystemBase` class the creation & cleanup of a file that can be used as externalized secrets in connector configs. Reviewers: Arjun Satish <arjun@confluent.io>, Robert Yokota <rayokota@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: Fixed default streams state dir location. (#5441)Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Simon Clark <simonc6r@gmail.com>Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>,0
"MINOR: Update to Gradle 6.5 and tweak build jvm config (#8751)Gradle 6.5 includes a fix for https://github.com/gradle/gradle/pull/12866, whichaffects the performance of Scala compilation.I profiled the scalac build with async profiler and 54% of the time was on GCeven after the Gradle upgrade (it was more than 60% before), so I switched tothe throughput GC (GC latency is less important for batch builds) and itwas reduced to 38%.I also centralized the jvm configuration in `build.gradle` and simplified it a bitby removing the minHeapSize configuration from the test tasks.On my desktop, the time to execute clean builds with no cached Gradle daemonwas reduced from 127 seconds to 97 seconds. With a cached daemon, it wasreduced from 120 seconds to 88 seconds. The performance regression whenwe upgraded to Gradle 6.x was 27 seconds with a cached daemon (https://github.com/apache/kafka/pull/7677#issuecomment-616271179), so itshould be fixed now.Gradle 6.4 with no cached daemon:```BUILD SUCCESSFUL in 2m 7s115 actionable tasks: 112 executed, 3 up-to-date./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.15s user 0.12s system 0% cpu 2:08.06 total```Gradle 6.4 with cached daemon:```BUILD SUCCESSFUL in 2m 0s115 actionable tasks: 111 executed, 4 up-to-date./gradlew clean compileScala compileJava compileTestScala compileTestJava  0.95s user 0.10s system 0% cpu 2:01.42 total```Gradle 6.5 with no cached daemon:```BUILD SUCCESSFUL in 1m 46s115 actionable tasks: 111 executed, 4 up-to-date./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.27s user 0.12s system 1% cpu 1:47.71 total```Gradle 6.5 with cached daemon:```BUILD SUCCESSFUL in 1m 37s115 actionable tasks: 111 executed, 4 up-to-date./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.02s user 0.10s system 1% cpu 1:38.31 total```This PR with no cached Gradle daemon:```BUILD SUCCESSFUL in 1m 37s115 actionable tasks: 81 executed, 34 up-to-date./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.27s user 0.10s system 1% cpu 1:38.70 total```This PR with cached Gradle daemon:```BUILD SUCCESSFUL in 1m 28s115 actionable tasks: 111 executed, 4 up-to-date./gradlew clean compileScala compileJava compileTestScala compileTestJava  1.02s user 0.10s system 1% cpu 1:29.35 total```Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: Improve checks for CogroupedStreamAggregateBuilder (#9141)Update `CogroupedStreamAggregateBuilder` to have individual builders dependingon the windowed aggregation, or lack thereof. This replaced passing in all optionsinto the builder, with all but the current type of aggregation set to null and thenchecking to see which value was not null.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-5449; Fix race condition on producer dequeuing of EndTxn requestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3348 from hachikuji/fix-has-unflushed-synchronization",0
kafka-880; NoLeaderPartitionSet should be cleared before leader finder thread is started up; patched by Jun Rao; reviewed by Neha Narkhede,1
MINOR: Move `ext` block above `allprojects` block in `build.gradle` (#11741)`ext` contains definitions that should be accessible in `allprojects`(even though we don't use any right now).Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Fix config name and remove hard coded values (#12564)Fix config name and remove hard coded valuesReviewers: Luke Chen <showuon@gmail.com>,4
KAFKA-12991; Fix unsafe access to `AbstractCoordinator.state` (#10879)This patch fixes the unsynchronized accesses to `AbstractCoordinator.state`.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,0
"KAFKA-4714; TimestampConverter transformation (KIP-66)Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3065 from ewencp/kafka-3209-timestamp-converter",5
"KAFKA-9076: support consumer sync across clusters in MM 2.0 (#7577)In order to make the Kafka consumer and stream application migrate from source to target clustertransparently and conveniently, e.g. in event of source cluster failure, a background job is proposedto periodically sync the consumer offsets from the source to target cluster, so that when theconsumer and stream applications switche to the target cluster, they will resume to consume fromwhere they left off at source cluster.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, Thiago Pinto, Srinivas Boga",5
KAFKA-2962: stream-table table-table joinsguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #644 from ymatsuda/join_methods,5
KAFKA-8090: Use automatic RPC generation in ControlledShutdownAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6423 from mimaison/controlled-shutdown,1
"KAFKA-2120: cleaning follow-upTrivial fix to get rid of unused statements in kafkaProducer.Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>Reviewers: Edward Ribeiro, Guozhang WangCloses #320 from MayureshGharat/kafka-2120-followup",2
AsyncProducerStats is not a singleton; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-207git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1204768 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Fix broken documentation linkThe link to 'Producer Configs' section of the documentation is updated with this PR.Author: vahidhashemian <vahidhashemian@us.ibm.com>Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #692 from vahidhashemian/typo03/fix_broken_doc_link,2
MINOR: Give correct instructions for retaining previous unclear leader election behaviourAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3561 from ijuma/fix-upgrade-note-for-unclean-leader-election,4
KAFKA-1259 Close blocked only until all messages had been sent not until all acknowledgements had been received.,5
"KAFKA-9991: Fix flaky unit tests (#8843)The latest commit #8254 on this test deleted all topics after each test, but the topic was actually shared among tests before. And after that we are relying on the less-reliable auto-topic generation to get the topic which makes the test flaky.I'm now using different topics for different tests, also setting the app.id for tests differently.Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"Minor: Replace InternalTopicMetadata with InternalTopicConfig (#6886)Quick tech debt cleanup. For some reason StreamsPartitionAssignor uses an InternalTopicMetadata class which wraps an InternalTopicConfig object along with the number of partitions. But InternalTopicConfig already has a numPartitions field, so we should just use it directly instead.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <bruno@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-12415 Prepare for Gradle 7.0 and restrict transitive scope for non api dependencies (#10203)Gradle 7.0 is required for Java 16 compatibility and it removes a number ofdeprecated APIs. Fix most issues preventing the upgrade to Gradle 7.0.The remaining ones are more complicated and should be handledin a separate PR. Details of the changes:* Release tarball no longer includes includes test, sources, javadoc and test sources jars (theseare still published to the Maven Central repository).* Replace `compile` with `api` or `implementation` - note that `implementation`dependencies appear with `runtime` scope in the pom file so this is a (positive)change in behavior* Add missing dependencies that were uncovered by the usage of `implementation`* Replace `testCompile` with `testImplementation`* Replace `runtime` with `runtimeOnly` and `testRuntime` with `testRuntimeOnly`* Replace `configurations.runtime` with `configurations.runtimeClasspath`* Replace `configurations.testRuntime` with `configurations.testRuntimeClasspath` (except forthe usage in the `streams` project as that causes a cyclic dependency error)* Use `java-library` plugin instead of `java`* Use `maven-publish` plugin instead of deprecated `maven` plugin - this changes thecommands used to publish and to install locally, but task aliases for `install` and`uploadArchives` were added for backwards compatibility* Removed `-x signArchives` line from the readme since it was wrong (it was ano-op before and it fails now, however)* Replaces `artifacts` block with an approach that works with the `maven-publish` plugin* Don't publish `jmh-benchmark` module - the shadow jar is pretty large and notparticularly useful (before this PR, we would publish the non shadow jars)* Replace `version` with `archiveVersion`, `baseName` with `archiveBaseName` and`classifier` with `archiveClassifier`* Update Gradle and plugins to the latest stable version (7.0 is not stable yet)* Use `plugin` DSL to configure plugins* Updated notable changes for 3.0Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Randall Hauch <rhauch@gmail.com>",4
"KAFKA-10092: Remove unnecessary contructor and exception in NioEchoServer (#8794)Reviewers: notifygd, Andrew Choi <andrew.choi@uwaterloo.ca>, Jakob Homan, Chia-Ping Tsai <chia7712@gmail.com>",4
"KAFKA-2800; Update outdated dependenciesChanges:* org.scala-lang:scala-library [2.10.5 -> 2.10.6]   * Scala 2.10.6 resolves a license incompatibility in scala.util.Sorting   * Otherwise identical to Scala 2.10.5* org.xerial.snappy:snappy-java [1.1.1.7 -> 1.1.2]   * Fixes SnappyOutputStream.close() is not idempotent* net.jpountz.lz4:lz4 [1.2.0 -> 1.3]* junit:junit [4.11 -> 4.12]* org.easymock:easymock [3.3.1 -> 3.4]* org.powermock:powermock-api-easymock [1.6.2 -> 1.6.3]* org.powermock:powermock-module-junit4 [1.6.2 -> 1.6.3]* org.slf4j:slf4j-api [1.7.6 -> 1.7.12]* org.slf4j:slf4j-log4j12 [1.7.6 -> 1.7.12]* com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider [2.5.4 -> 2.6.3]* com.fasterxml.jackson.core:jackson-databind [2.5.4 -> 2.6.3]* org.eclipse.jetty:jetty-server [9.2.12.v20150709 -> 9.2.14.v20151106]* org.eclipse.jetty:jetty-servlet [9.2.12.v20150709 -> 9.2.14.v20151106]* org.bouncycastle:bcpkix-jdk15on [1.52 -> 1.53]* net.sf.jopt-simple:jopt-simple [3.2 -> 4.9]* removed explicit entry for org.objenesis:objenesis:2.2 (resolved transitively)Author: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #513 from granthenke/update-deps",5
"KAFKA-6739; Ignore headers when down-converting from V2 to V0/V1 (#4813)Ignore headers when down-converting to V0/V1 since they are not supported. Added a test-case to verify down-conversion sanity in presence of headers.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7269: Add docs for KStream.merge (#5512)Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-2399; Replace `Stream.continually` with `Iterator.continually``Iterator.continually` is more efficient (it doesn't allocate a `Cons` instance per element) and we don't need the extra functionality provided by `Stream.continually`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-PostavaCloses #106 from ijuma/kafka-2399-replace-stream-continually,1
KAFKA-12246: Remove redundant suppression in KafkaAdminClient (#9989)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"MINOR: Fix Streams metadata upgrade system test (#7118)Reviewers: A. Sophie Blee-Goldmann <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-4312: If filePath is empty string writeAsText should have more meaningful error message…eaningful error messageAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2042 from bbejeck/KAFKA-4312_write_as_text_throws_NPE_empty_string,0
HOTFIX: fix log message in version probing system test (#8341)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-2486; fix performance regression in new consumerThe sleep() in KafkaConsumer's poll blocked any pending IO from being completed and created a performance bottleneck. It was intended to implement the fetch backoff behavior, but that was a misunderstanding of the setting ""retry.backoff.ms"" which should only affect failed fetches.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #180 from hachikuji/KAFKA-2486",5
KAFKA-3740: Part I: expose StreamConfig properties in ProcessorContextThis is the part I of the work to add the StreamsConfig to ProcessorContext.We need to access StreamsConfig in the ProcessorContext so other components (e.g. RocksDBWindowStore or LRUCache can retrieve config parameter from application)Author: Henry Cai <hcai@pinterest.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1553 from HenryCaiHaiying/config,5
MINOR: Fix typo in docs (#10423)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-320 testZKSendWithDeadBroker fails intermittently due to ZKNodeExistsException; patched by nehanarkhede; reviewed by junrao and prashanth menongit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1310661 13f79535-47bb-0310-9956-ffa450edef68,0
"MINOR: Code cleanup and JavaDoc improvements for clients and StreamsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4128 from mjsax/minor-cleanupminor fix",0
MINOR: set group initial rebalance delay to 0 in server.propertiesoverride the setting of `group.initial.rebalance.delay` in server.propertiesAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3254 from dguy/minor-prop-change,4
MINOR: Fix ThrottledReplicaListValidator doc error. (#6537)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
MINOR: remove unused log field from KStreamTransformValuesProcessorremove unused log field from KStreamTransformValuesProcessorAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2717 from dguy/remove-unused-log-para,4
"MINOR: add memory management section to streams docsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Eno Thereska <eno.thereska@gmail.com>Closes #3604 from dguy/memory-management-docs",2
KAFKA-7935: UNSUPPORTED_COMPRESSION_TYPE if ReplicaManager.getLogConfig returns None (#6274)Replaced `forall` with `exists`. Added a unit test to `KafkaApisTest` that failed before the change.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR:Fix table outer join test (#5099),3
MINOR: Refactor GroupMetadataManager cleanupGroupMetadata (#4504)Refactoring avoids the need to call this method with a infinity as current time to remove all group offsets (when manually deleting the group).,4
"MINOR: clarify wording around fault-tolerant state stores (#7510)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-12172 Migrate streams:examples module to JUnit 5 (#9857)This PR includes following changes.1. replace org.junit.Assert by org.junit.jupiter.api.Assertions2. replace org.junit by org.junit.jupiter.api3. replace Before by BeforeEach4. replace After by AfterEachReviewers: Ismael Juma <ismael@confluent.io>,5
"KAFKA-2457; StackOverflowError during buildsThe default is typically `1m` for 64-bit machines and the Scala compiler sometimes needs more than this.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Manikumar Reddy, Gwen ShapiraCloses #157 from ijuma/kafka-2457-stackoverflowerror-during-builds",0
"MINOR: Remove Diamond and code code Alignment (#8107)Minor cleanup on streams internal classes, with diamond class removal and long function signature breakdown.Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
"MINOR: Simplify ApiKeys by relying on ApiMessageType (#9748)* The naming for `ListOffsets` was inconsistent, in some places it was `ListOffset` and in othersit was `ListOffsets`. Picked the latter since it was used in metrics and the protocol documentationand made it consistent.* Removed unused methods in ApiKeys.* Deleted `CommonFields`.* Added `lowestSupportedVersion` and `highestSupportedVersion` to `ApiMessageType`* Removed tests in `MessageTest` that are no longer relevant.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",3
KAFKA-6144: Add KeyQueryMetadata APIs to KafkaStreams (#7960)Deprecate existing metadata query APIs in favor of newones that include standby hosts as well as partitioninformation.Closes: #7960Implements: KIP-535Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>Reviewed-by: John Roesler <vvcephei@apache.org>,5
"MINOR: clean up some replication code (#10564)Centralize leader and ISR changes in generateLeaderAndIsrUpdates.Consolidate handleNodeDeactivated and handleNodeActivated into thisfunction.Rename BrokersToIsrs#noLeaderIterator to BrokersToIsrs#partitionsWithNoLeader.Create BrokersToIsrs#partitionsLedByBroker, BrokersToIsrs#partitionsWithBrokerInIsrIn ReplicationControlManagerTest, createTestTopic should be a memberfunction of ReplicationControlTestContext.  It should invokeReplicationControlTestContext#replay so that records are applied to allparts of the test context.Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",3
kafka-946; Kafka Hadoop Consumer fails when verifying message checksum; patched by Sam Meder; reviewed by Jun Rao,0
MINOR: Remove duplicate doc headersAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2021 from omkreddy/LATEST-DOC-CHANGE,3
"MINOR; Retry on test failure for branch builds and increase max test retry to 10 (#12601)Originally, we only enabled retries for PR builds to avoid hiding timingrelated issues. In practice, however, the results are too noisy withoutany retry due to various environmental issues.Enable 1 retry for all builds and increase the max test retry to 10.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-13749: CreateTopics in KRaft must return configs (#11941)Previously, when in KRaft mode, CreateTopics did not return the active configurations for thetopic(s) it had just created. This PR addresses that gap. We will now return these topicconfiguration(s) when the user has DESCRIBE_CONFIGS permission. (In the case where the user doesnot have this permission, we will omit the configurations and set TopicErrorCode. We will also omitthe number of partitions and replication factor data as well.)For historical reasons, we use different names to refer to each topic configuration when it is setin the broker context, as opposed to the topic context. For example, the topic configuration""segment.ms"" corresponds to the broker configuration ""log.roll.ms"". Additionally, some brokerconfigurations have synonyms. For example, the broker configuration ""log.roll.hours"" can be used toset the log roll time instead of ""log.roll.ms"". In order to track all of this, this PR adds atable in LogConfig.scala which maps each topic configuration to an ordered list of ConfigSynonymclasses. (This table is then passed to KafkaConfigSchema as a constructor argument.)Some synonyms require transformations. For example, in order to convert from ""log.roll.hours"" to""segment.ms"", we must convert hours to milliseconds. (Note that our assumption right now is thattopic configurations do not have synonyms, only broker configurations. If this changes, we willneed to add some logic to handle it.)This PR makes the 8-argument constructor for ConfigEntry public. We need this in order to make fulluse of ConfigEntry outside of the admin namespace. This change is probably inevitable in generalsince otherwise we cannot easily test the output from various admin APIs in junit tests outside theadmin package.Testing:This PR adds PlaintextAdminIntegrationTest#testCreateTopicsReturnsConfigs. This test validatessome of the configurations that it gets back from the call to CreateTopics, rather than just checkingif it got back a non-empty map like some of the existing tests. In order to test theconfiguration override logic, testCreateDeleteTopics now sets up some custom static and dynamicconfigurations.In QuorumTestHarness, we now allow tests to configure what the ID of the controller should be. Thisallows us to set dynamic configurations for the controller in testCreateDeleteTopics. We will havea more complete fix for setting dynamic configuations on the controller later.This PR changes ConfigurationControlManager so that it is created via a Builder. This will make iteasier to add more parameters to its constructor without having to update every piece of test codethat uses it. It will also make the test code easier to read.Reviewers: David Arthur <mumrah@gmail.com>",3
Updated SBT JAR to 0.12.1,5
KAFKA-2056; Fix transient testRangePartitionAssignor failure; reviewed by Guozhang Wang,0
MINOR: Fix documentation table of contents and `BLOCK_ON_BUFFER_FULL_DOC`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1423 from ijuma/minor-doc-fixes,2
recommit: revisit the become leader and become follower state change operations using V3 design; patched by Yang Ye; reviewed by Neha Narkhede and Jun Rao; kafka-343git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1368092 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: fix broken WorkerSourceTask testAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #859 from hachikuji/hotfix-worker-source-test,3
"KAFKA-991; Rename config queue size to queue bytes in hadoop producer; patched by Swapnil Ghike, reviewed by Joel Koshy.",5
KAFKA-5920; Handle SSL handshake failures as authentication exceptions1. Propagate `SSLException` as `SslAuthenticationException` to enable clients to report these and avoid retries2. Updates to `SslTransportLayer` to process bytes received even if end-of-stream3. Some tidy up of authentication handling4. Report exceptions in SaslClientAuthenticator as AuthenticationExceptionsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3918 from rajinisivaram/KAFKA-5920-SSL-handshake-failure,5
"KAFKA-6562: Make jackson-databind an optional clients dependency (#5110)Use `provided` scope in Maven.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Update JavaDoc to use new APIAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax<matthias@confluent.io>Closes #4068 from bbejeck/MINOR_fix_java_doc_example_for_1_0_API",2
"KAFKA-5919; Adding checks on ""version"" field for tools using itAdding checks on ""version"" field for tools using it.This is a new version of the closed PR #3887 (to see for more comments and related discussion).Author: Paolo Patierno <ppatierno@live.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5126 from ppatierno/kafka-5919-update",5
"MINOR: Typographical error corrected in the StreamsBuilder Javadoc.Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3695 from Kamal15/typo_error",2
"MINOR: Add missing @cluster annotation to StreamsNamedRepartitionTopicTest (#10697)The StreamsNamedRepartitionTopicTest system tests did not have the @cluster annotation and was therefore taking up the entire cluster. For example, we see this in the log output:kafkatest.tests.streams.streams_named_repartition_topic_test.StreamsNamedRepartitionTopicTest.test_upgrade_topology_with_named_repartition_topic is using entire cluster. It's possible this test has no associated cluster metadata.This PR adds the missing annotation.Reviewers: Bill Bejeck <bbejeck@apache.org>",1
"KAFKA-4561; Ordering of operations in StreamThread.shutdownTasksAndState may void at-least-once guaranteesIn `shutdownTasksAndState` and `suspendTasksAndState` we commit offsets BEFORE we flush any state. This is wrong as if an exception occurs during a flush, we may violate the at-least-once guarantees, that is we would have committed some offsets but NOT sent the processed data on to other Sinks.Also during suspend and shutdown, we should try and complete all tasks even when exceptions occur. We should just keep track of the exception and rethrow it at the end if necessary. This helps with ensuring that StateStores etc are closed.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2281 from dguy/kafka-4561",3
"KAFKA-4468: Correctly calculate the window end timestamp after read from state storesI have decided to use the following approach to fixing this bug:1) Since the Window Size in WindowedDeserializer was originally unknown, I have initializeda field _windowSize_ and created a constructor to allow it to be instantiated2) The default size for __windowSize__ is _Long.MAX_VALUE_. If that is the case, then thedeserialize method will return an Unlimited Window, or else will return Timed one.3) Temperature Demo was modified to demonstrate how to use this new constructor, giventhat the window size is known.Author: Richard Yu <richardyu@Richards-Air.attlocal.net>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3745 from ConcurrencyPractitioner/trunk",1
"KAFKA-4457; Add BrokerApiVersionsCommandAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2184 from cmccabe/KAFKA-4457",5
System Test Transient Failure on testcase_0122; patched by Sriram Subramanian; reviewed by Jun Rao and Neha Narkhede; kafka-772,3
KAFKA-7890: Invalidate ClusterConnectionState cache for a broker if the hostname of the broker changes. (#6215),4
MINOR: Refactor unit tests around RocksDBConfigSetter (#9358)* Extract the mock RocksDBConfigSetter into a separate class.* De-dup unit tests covering RocksDBConfigSetter.Reviewers: Boyang Chen <boyang@confluent.io>,5
"KAFKA-9509: Increase timeout when consuming records to fix flaky test in MM2 (#8894)A simple increase in the timeout of the consumer that verifies that records have been replicated seems to fix the integration tests in `MirrorConnectorsIntegrationTest` that have been failing more often recently. Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Sanjana Kaundinya <skaundinya@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: Javadoc formatting for MetricsContext (#11419)The Javadoc for MetricsContext wasn't correctly formatted for nice/readable HTML output.Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
KAFKA-6770; Add New Protocol Versions to 1.1.0 documentation (#4847)Update 1.1 docs to include 2 new versions to existing APIs:- DescribeConfigs v1- Fetch v7Also fix a typo in1 FetchRequest.,2
"KAFKA-2878; Guard against OutOfMemory in Kafka brokerSanity check array size in requests before allocationAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ashish Singh <asingh@cloudera.com>, Jun Rao <junrao@gmail.com>Closes #577 from rajinisivaram/KAFKA-2878",5
"MINOR: Add metric templates for sender/fetcher rate totalsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: James Cheng <jylcheng@yahoo.com>, Ismael Juma <ismael@juma.me.uk>Closes #3882 from rajinisivaram/MINOR-KAFKA-5738-metricstemplates",5
kafka-937; delta patch; ConsumerFetcherThread can deadlock; patched by Jun Rao; reviewed by Joel Koshy,5
MINOR: Use distinct consumer groups in dynamic listener tests (#4870),3
"MINOR; enable KRaft in ConfigCommandIntegrationTest (#11732)Adding KRaft and ZK params to ConfigCommandIntegrationTest wherever appropriate.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
MINOR: Fix sasl.jaas.config doc string (#4921),2
MINOR: fix command help description on zookeeper host strings URLs (#2940),0
KAFKA-1910 Follow-up; Revert the no-offset-committed error code; reviewed by Joel Koshy,0
"MINOR: Clarify meaning of end offset in consumer javadocs (#4885)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8670; Fix exception for kafka-topics.sh --describe without --topic mentioned (#7094)If there are **no topics** in a cluster, kafka-topics.sh --describe without a --topic option should return empty list, not throw an exception.Reviewers: Jason Gustafson <jason@confluent.io>",5
kafka-2101; Metric metadata-age is reset on a failed update; patched by Tim Brooks; reviewed by Jun Rao,5
"MINOR: Updated configuration docs with RocksDBConfigSetter#close (#6784)The old docs here used a now deprecated method to set the block cache size. In switching over to the new one we would now need to construct a Cache object and therefore also need to close it, so this is a good opportunity to demonstrate the RocksDBConfigSetter#close method that will need to be implemented by users.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINOR internal KIP-629 changes to methods and variablescc gwenshapAuthor: Xavier Léauté <xvrl@apache.org>Reviewers: Gwen ShapiraCloses #9405 from xvrl/minor-kip-629-vars,4
"kafka-1363; testTopicConfigChangesDuringDeleteTopic hangs; patched by Timothy Chen; reviewed by Guozhang Wang, Neha Narkhede and Jun Rao",5
"KAFKA-3933; Always fully read deepIteratorAvoids leaking native memory and hence crashing brokers on bootup due torunning out of memory.Seeeing as `messageFormat > 0` always reads the full compressed messageset and is the default going forwards, we can use that behaviour toalways close the compressor when calling `deepIterator`Author: Tom Crayford <tcrayford@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1660 from tcrayford/dont_leak_native_memory_round_2",1
"MINOR: Fix deadlock between StreamThread and KafkaStreamsThis may be a reason why we see Jenkins jobs time out at times.I can reproduce it locally.With current trunk there is a possibility to run into this:```sh""kafka-streams-close-thread"" #585 daemon prio=5 os_prio=0 tid=0x00007f66d052d800 nid=0x7e02 waiting for monitor entry [0x00007f66ae2e5000]   java.lang.Thread.State: BLOCKED (on object monitor)at org.apache.kafka.streams.processor.internals.StreamThread.close(StreamThread.java:345)- waiting to lock <0x000000077d33c538> (a org.apache.kafka.streams.processor.internals.StreamThread)at org.apache.kafka.streams.KafkaStreams$1.run(KafkaStreams.java:474)at java.lang.Thread.run(Thread.java:745)""appId-bd262a91-5155-4a35-bc46-c6432552c2c5-StreamThread-97"" #583 prio=5 os_prio=0 tid=0x00007f66d052f000 nid=0x7e01 waiting for monitor entry [0x00007f66ae4e6000]   java.lang.Thread.State: BLOCKED (on object monitor)at org.apache.kafka.streams.KafkaStreams.setState(KafkaStreams.java:219)- waiting to lock <0x000000077d335760> (a org.apache.kafka.streams.KafkaStreams)at org.apache.kafka.streams.KafkaStreams.access$100(KafkaStreams.java:117)at org.apache.kafka.streams.KafkaStreams$StreamStateListener.onChange(KafkaStreams.java:259)- locked <0x000000077d42f138> (a org.apache.kafka.streams.KafkaStreams$StreamStateListener)at org.apache.kafka.streams.processor.internals.StreamThread.setState(StreamThread.java:168)- locked <0x000000077d33c538> (a org.apache.kafka.streams.processor.internals.StreamThread)at org.apache.kafka.streams.processor.internals.StreamThread.setStateWhenNotInPendingShutdown(StreamThread.java:176)- locked <0x000000077d33c538> (a org.apache.kafka.streams.processor.internals.StreamThread)at org.apache.kafka.streams.processor.internals.StreamThread.access$1600(StreamThread.java:70)at org.apache.kafka.streams.processor.internals.StreamThread$RebalanceListener.onPartitionsRevoked(StreamThread.java:1321)at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:406)at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:349)at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:310)at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:296)at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1037)at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1002)at org.apache.kafka.streams.processor.internals.StreamThread.pollRequests(StreamThread.java:531)at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:669)at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:326)```In a nutshell: `KafkaStreams` and `StreamThread` are bothwaiting for each other since another intermittent `close`(eg. from a test) comes along also trying to lock on`KafkaStreams` :```sh""main"" #1 prio=5 os_prio=0 tid=0x00007f66d000c800 nid=0x78bb in Object.wait() [0x00007f66d7a15000]   java.lang.Thread.State: WAITING (on object monitor)at java.lang.Object.wait(Native Method)at java.lang.Thread.join(Thread.java:1249)- locked <0x000000077d45a590> (a java.lang.Thread)at org.apache.kafka.streams.KafkaStreams.close(KafkaStreams.java:503)- locked <0x000000077d335760> (a org.apache.kafka.streams.KafkaStreams)at org.apache.kafka.streams.KafkaStreams.close(KafkaStreams.java:447)at org.apache.kafka.streams.KafkaStreamsTest.testCannotStartOnceClosed(KafkaStreamsTest.java:115)```=> causing a deadlock.Fixed this by softer locking on the state change, that guaranteesatomic changes to the state but does not lock on the whole object(I at least could not find another method that would require morethan atomicly-locked access except for `setState`).Also qualified the state listeners with their outer-class to makethe whole code-flow around this more readable (having twointerfaces with the same naming for interface and method and thenusing them between their two outer classes is crazy hard to readimo :)).Easy to reproduced yourself by running`org.apache.kafka.streams.KafkaStreamsTest` in a loop for a bit(save yourself some time by running 2-4 in parallel :)). Eventuallyit will lock on one of the tests (for me this takes less than 1 minwith 4 parallel runs).Author: Armin Braun <me@obrown.io>Author: Armin <me@obrown.io>Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2791 from original-brownbear/fix-streams-deadlock",0
"KAFKA-5629; ConsoleConsumer should respect auto.offset.reset if specified on the command linewhen ""auto.offset.reset"" property is specified on the command line but overridden by the code during startup. Currently the ConsoleConsumer silently overrides that setting, which can create confusing behavior.Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3566 from soenkeliebau/KAFKA-5629",5
kafka-1567; Metric memory leaking after closing the clients; patched by Jiangjie Qin; reviewed by Guozhang Wang and Jun Rao,5
"KAFKA-2844; Separate keytabs for sasl testsUse a different keytab for server and client in SASL testsAlso:* Improve approach used to build the JAAS files programmatically* Delete stale `kafka_jaas.conf` file* Move `FourLetterWords` to its own file, add `Zk` prefix and clean-up its usageAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Harsha Chintalapani, Gwen ShapiraCloses #533 from ijuma/separate-keytabs-for-sasl-tests",3
"kafka-1212; System test exception handling does not stop background producer threads; patched by Guozhang Wang; reviewed by Neha Narkhede, Joel Koshy, and Jun Rao",3
MINOR: Improve instructions for running system tests with dockerAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3649 from enothereska/minor-docker-docs,2
kafka-1278; More flexible helper scripts; patched by Nathan Brown; reviewed by Jun Rao,5
MINOR: fix ClassCastException handling (#8156)Reviewers: John Roesler <john@confluent.io>,5
"MINOR: Do not wait for first line of console consumer output since we now have a more reliable test using JMXWaiting for the first line of output was added in KAFKA-2527 when JmxMixin was originally added as a heuristic todetermine when the process was ready. We've since determined this is not good enough given JmxTool's limitationsand now include a separate, more reliable check before starting JmxTool. This check is also dangerous since aconsumer that is started before data is available in the topic, it won't output anything to stdout and only logserrors to a separate log file. This means we may have a long delay between starting the process and starting JMXmonitoring.Since we have a more reliable check for liveness via JMX now (and in cases that need it, partition assignmentmetrics via JMX), we should no longer need to wait for the first line of output.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>Closes #3447 from ewencp/dont-wait-first-line-console-consumer",5
KAFKA-9865: Expose output topic names from TopologyTestDriver (#8483)Implements KIP-594Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-9839; Broker should accept control requests with newer broker epoch (#8509)A broker throws IllegalStateException if the broker epoch in the LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest is larger than its current broker epoch. However, there is no guarantee that the broker would receive the latest broker epoch before the controller: when the broker registers with ZK, there are few more instructions to process before this broker ""knows"" about its epoch, while the controller may already get notified and send UPDATE_METADATA request (as an example) with the new epoch. This will result in clients getting stale metadata from this broker. With this PR, a broker accepts LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest if the broker epoch is newer than the current epoch.Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-5829; Only delete producer snapshots before the recovery pointAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4023 from ijuma/kafka-5829-avoid-reading-older-segments-on-hard-shutdown,5
"MINOR: Removed deprecated schedule function (#4908)While working on this, I also refactored the MockProcessor out of the MockProcessorSupplier to cleanup the unit test paths.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: update exception message for KIP-120Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4078 from mjsax/hotfix-streams,0
KAFKA-4160: Ensure rebalance listener not called with coordinator lockAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1855 from hachikuji/KAFKA-4160,5
KAFKA-6731: waitOnState should check the state to be the target start. (#4808)KafkaStreams.waitOnState() should check the state to be the given one instead of the hard-coded `NOT_RUNNING`.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-8091; Wait for processor shutdown before testing removed listeners (#6425)DynamicBrokerReconfigurationTest.testAddRemoveSaslListeners removes a listener, waits for the config to be propagated to all brokers and then validates that connections to the removed listener fail. But there is a small timing window between config update and Processor shutdown. Before validating that connections to a removed listener fail, this commit waits for all metrics of the removed listener to be deleted, ensuring that the Processors of the listener have been shutdown.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",4
"KAFKA-5006: Improve thrown exception error logs1. Only log an ERROR on the first encountered exception from the callback.2. Wrap the exception message with the first thrown message information, and throw the exception whenever `checkException` is called.Therefore, for the `store.put` call, it will throw a `KafkaException` with the error message a bit more intuitive.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Xavier Léauté <xavier@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3534 from guozhangwang/K5006-exception-record-collector",5
"MINOR: update docs JSON serde links (#6465)Reviewers: Joel Mamill <joel@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
KAFKA-3783; Catch proper exception on path delete- ZkClient is used for conditional path deletion and wraps `KeeperException.BadVersionException` into `ZkBadVersionException`- add unit test to `SimpleAclAuthorizerTest` to reproduce the issue and catch potential future regressionAuthor: Sebastien Launay <sebastien@opendns.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1461 from slaunay/bugfix/KAFKA-3783-zk-conditional-delete-path,4
"KAFKA-10020: Create a new version of a scala Serdes without name clash (KIP-616) (#8955)Wildcard import of the old org.apache.kafka.streams.scala.Serdes leadsto a name clash because some of implicits has the same names as typesfrom the scala's std lib. The new oak.streams.scala.serialization.Serdes isthe same as the old Serdes, but without name clashes.The old one is marked as deprecated.Also, add missing serdes for UUID, ByteBuffer and Short types inthe new Serdes.Implements: KIP-616Reviewers: John Roesler <vvcephei@apache.org>",1
"KAFKA-3851; Automate release notes and include links to upgrade notes for release and most recent docs to forward users of older releases to newest docs.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1670 from ewencp/kafka-3851-automate-release-notes",2
MINOR: Follow-up improvements on top of KAFKA-5793Simplified the condition in Sender#failBatch()Added log in TransactionManager#updateLastAckedOffset()Author: tedyu <yuzhihong@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3935 from tedyu/trunk,1
MINOR: record lag max metric documentation enhancement (#12367)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Updating comment that fell out of sync with codeAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #681 from gwenshap/minor-herder-comment,5
MINOR: support KRaft in TransactionsExpirationTest (#11633)Reviewers: José Armando García Sancio <jsancio@gmail.com>,3
"KAFKA-9432:(follow-up) Set `configKeys` to null in `describeConfigs()` to make it backward compatible with older Kafka versions.- After #8312, older brokers are returning empty configs,  with latest `adminClient.describeConfigs`.  Old brokers  are receiving empty configNames in `AdminManageer.describeConfigs()` method. Older brokers does not handle empty configKeys. Due to this old brokers are filtering all the configs.- Update ClientCompatibilityTest to verify describe configs- Add test case to test describe configs with empty configuration KeysAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #9046 from omkreddy/KAFKA-9432",5
"KAFKA-3392: ConsumerRecords iterator throws NoSuchElementException when a TopicPartition is emptyThis contribution is my original work, and I license it under the project's open source license.CC jkrepsAuthor: Drausin Wulsin <daedalus2718@gmail.com>Author: John Doe <daedalus2718@gmail.com>Reviewers: Jason GustafsonCloses #1055 from drausin/bugfix/consumer-records-iterator",0
MINOR: Add Timed wait to SslTransportLayerTest.testNetworkThreadTimeRecorded (#4811)Avoid test hanging when there is a failure by limiting wait time.,0
MINOR: Add some class javadoc to Admin client (#9459)Reviewers: Lee Dongjin <dongjin@apache.org>,2
"MINOR: Relax Unsupported Version check on BrokerCompatibilityTest (#5170)In BrokerCompatibilityTest.java, when older versioned broker is used (0.10.1, 0.10.2), LIST_OFFSET is not supported as well. Hence in the verification phase, there is a possibility that consumer hit the UnsupportedVersionException earlier than Streams actually hits it:org.apache.kafka.common.errors.UnsupportedVersionException: The broker does not support LIST_OFFSETS with version in range [2,3]. The supported range is [0,1].While the test is waiting fororg.apache.kafka.common.errors.UnsupportedVersionException: Cannot create a v0 FindCoordinator request because we require features supported only in 1 or later.Both are valid errors to expect (the former is from consumer while the latter is from producer of the streams app).Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: add docs for KIP-680 (#10048)Reviewers: Bill Bejeck <bill@confluent.io>, Jim Galasyn <jim.galasyn@confluent.io>",5
KAFKA-8442; Include ISR in Metadata response even if there is no leader (#6836)Currently the Metadata response returns an empty ISR if there is no active leader. The behavior is inconsistent since other fields such as the replica list and offline replicas are included. This patch changes the behavior to return the current known ISR. This fixes a problem with the topic describe command which fails to report ISR when a leader is offline.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-5210: Application Reset Tool does not need to seek for internal topicsmjsax dguy guozhangwang Could you please review the changes.Author: Bharat Viswanadham <bharatv@us.ibm.com>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #3073 from bharatviswa504/KAFKA-5210",4
"KAFKA-4225; Replication Quotas: Control Leader & Follower Limit SeparatelyAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1932 from benstopford/KAFKA-4225-over-KAFKA-4216",5
"KAFKA-10768 Make ByteBufferInputStream.read(byte[], int, int) to follow the contract (#9761)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-9441: remove prepareClose() to simplify task management (#8833)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-6185; Remove channels from explictlyMutedChannels set when closedThis memory leak could eventually lead to an OutOfMemoryError. Thiswas particularly likely in case of down conversions as the leakedchannels would hold on to the record batch (which is only loadedinto the heap in case of down conversions).Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4193 from rajinisivaram/KAFKA-6185-oom,5
"KAFKA-5364; Don't fail producer if drained partition is not yet in transactionDue to the async nature of the producer, it is possible to attempt to drain a messages whose partition hasn't been added to the transaction yet. Before this patch, we considered this a fatal error. However, it is only in error if the partition isn't in the queue to be sent to the coordinator.This patch updates the logic so that we only fail the producer if the partition would never be added to the transaction. If the partition of the batch is yet to be added, we will simply wait for the partition to be added to the transaction before sending the batch to the broker.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3202 from apurvam/KAFKA-5364-ensure-partitions-added-to-txn-before-send",1
"KAFKA-3378; Follow-up to ensure we `finishConnect` for immediately connected keysAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Larkin Lowrey <llowrey@gmail.com>, Jun Rao <junrao@gmail.com>Closes #1103 from ijuma/kafka-3378-follow-up",5
KAFKA-9537 - Cleanup error messages for abstract transformations (#8090)Added check if the transformation is abstract. If so throw an error message with guidance for the user. Ensure that the child classes are also not abstract.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,1
"KAFKA-9748: Extend Streams integration tests for EOS beta (#8441)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-6464: Fix Base64URL encode padding issue under JRE 1.7 (#4455)The org.apache.kafka.common.utils.Base64 class defers Base64 encoding/decoding to the java.util.Base64 class beginning with JRE 1.8 but leverages javax.xml.bind.DatatypeConverter under JRE 1.7.  The implementation of the encodeToString(bytes[]) method returned under JRE 1.7 by Base64.urlEncoderNoPadding() blindly removed the last two trailing characters of the Base64 encoding under the assumption that they would always be the string ""=="" but that is incorrect; padding can be ""="", ""=="", or non-existent. This commit fixes that problem.The commit also adds a Base64.urlDecoder() method that defers to java.util.Base64 under JRE 1.8+ but leverages javax.xml.bind.DatatypeConverter under JRE 1.7.Finally, there is a unit test to confirm that encode/decode are inverses in both the Base64 and Base64URL cases.",5
"HOTFIX: Missing streams jar in releaseObservation: when doing ""gradlew releaseTarGz"" the streams jar was not included in the tarball. Adding a line to include it. ijuma guozhangwang could you please review. Thanks.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #984 from enothereska/trunk",1
"KAFKA-4741; Fix potential buffer leak in RecordAccumulator in case of exceptionAuthor: Satish Duggana <sduggana@hortonworks.com>Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2509 from satishd/buffer-cleanup",4
"update source link in interactive query page (#9261)Currently, the source reference are all pointing to the 1.0 version codes,which is obviously wrong. Update to the current dotVersion.Reviewers: John Roesler <vvcephei@apache.org>",5
"MINOR: Fix sensor removal assertion in `MetricTest.testRemoveInactiveMetrics` (#11755)The test case `MetricTest.testRemoveInactiveMetrics` attempts to test removal of inactive sensors, but one of the assertions is checking the wrong sensor name (""test.s1"" instead of ""test.s2""). The patch fixes the assertion to use the right sensor name.Reviewers: Jason Gustafson <jason@confluent.io>Co-authored-by: zhonghou3 <zhonghou3@jd.com>",5
"KAFKA-13132; Ensure topicId is updated on replicas even when the leader epoch is unchanged (#11126)In 3.0, there was a change that resulted in no longer assigning topic IDs to the log and the partition.metadata file in certain upgrade scenarios, specifically when upgrading from IBP 2.7 or below to 3.0. In this case, there may not be a bump to the leader epoch when the topicId is assigned by the controller, so the LeaderAndIsr request from the controller would be ignored by the replica. This PR fixes the problem by adding a check for whether we need to handle the LeaderAndIsr request given a new topic ID when one is not yet assigned in the log and code to assign a topic ID when the log is already associated to a partition in ReplicaManager.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-12212; Bump Metadata API version to remove `ClusterAuthorizedOperations` fields (KIP-700) (#9945)This patch bumps the version of the Metadata API and removes the `IncludeClusterAuthorizedOperations` and the `IncludeClusterAuthorizedOperations` fields from version 11 and onward.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-8590; Use automated TxnOffsetCommit type and add tests for OffsetCommit  (#6994)This PR changes the TxnOffsetCommit protocol to auto-generated types, and add more unit test coverage to the plain OffsetCommit protocol.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-1582; System Test should wait for producer to finish; reviewed by Joel Koshy and Guozhang Wang,5
"KAFKA-2516: Rename o.a.k.client.tools to o.a.k.toolsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ewen Cheslack-PostavaCloses #310 from granthenke/tools-packaging",1
"MINOR: update required MacOS version (#9025)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
"yThis security vulnerability was found in netty-codec-http, but [caused by netty itself](https://github.com/netty/netty/commit/c735357bf29d07856ad171c6611a2e1a0e0000ec) and [fixed in 4.1.59.Final](https://github.com/netty/netty/security/advisories/GHSA-5mcr-gq6c-3hq2). So, upgrade the netty version from 4.1.51.Final to 4.1.59.Final.Author: Lee Dongjin <dongjin@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #10235 from dongjinleekr/feature/KAFKA-12389",0
"KAFKA-7415; Persist leader epoch and start offset on becoming a leader (#5678)This patch ensures that the leader epoch cache is updated when a broker becomes leader with the latest epoch and the log end offset as its starting offset. This guarantees that the leader will be able to provide the right truncation point even if the follower has data from leader epochs which the leader itself does not have. This situation can occur when there are back to back leader elections.Additionally, we have made the following changes:1. The leader epoch cache enforces monotonically increase epochs and starting offsets among its entry. Whenever a new entry is appended which violates requirement, we remove the conflicting entries from the cache.2. Previously we returned an unknown epoch and offset if an epoch is queried which comes before the first entry in the cache. Now we return the smallest . For example, if the earliest entry in the cache is (epoch=5, startOffset=10), then a query for epoch 4 will return (epoch=4, endOffset=10). This ensures that followers (and consumers in KIP-320) can always determine where the correct starting point is for the active log range on the leader.Reviewers: Jun Rao <junrao@gmail.com>",2
"MINOR: Prevent creating partition.metadata until ID can be written (#10041)Currently the partition.metadata file is created when the log is created. However, clusters with older inter-broker protocols will never use this file. This PR moves the creation of the file to when we write to the file.This PR also deletes the partition.metadata file on startup if the IBP version is lower than 2.8.Reviewers: Jun Rao <junrao@gmail.com>",2
"KAFKA-9273: Extract testShouldAutoShutdownOnIncompleteMetadata from S… (#9108)The main goal is to remove usage of embedded broker (EmbeddedKafkaCluster) in AbstractJoinIntegrationTest and its subclasses.This is because the tests under this class are no longer using the embedded broker, except for two.testShouldAutoShutdownOnIncompleteMetadata is one of such tests.Furthermore, this test does not actually perfom stream-table join; it is testing an edge case of joining with a non-existent topic, so it should be in a separate test.Testing strategy: run existing unit and integration testReviewers: Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@apache.org>",5
"KAFKA-8229; Reset WorkerSinkTask offset commit interval after task commit (#6579)Prior to this change, the next commit time advances_each_ time a commit happens -- including when a commit happensbecause it was requested by the `Task`. When a `Task` requests acommit several times, the clock advances far into the futurewhich prevents expected periodic commits from happening.This commit changes the behavior, we reset `nextCommit` relativeto the time of the commit.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-371 Patch from Jonathan Creasy reviewed by me. Correctly handle the case of an empty string as topic name or invalid partition number.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1363022 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-4399; Fix deadlock between cleanupGroupMetadata and offset commitAuthor: Alexey Ozeritsky <aozeritsky@yandex-team.ru>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2125 from resetius/KAFKA-4399",1
MINOR: Use `jps` cmd to find out the pid of TransactionalMessageCopierAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #6787 from omkreddy/transaction_test,3
trivial fix to add the missing Logging classgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401909 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-3233: expose consumer per-topic metricsIn version of 0.8.2.1, the old consumer will provide the metrics reporter per-topic consumer metrics under group 'ConsumerTopicMetrics'. For example:*.ConsumerTopicMetrics.clientId.[topic name].BytesPerSec.count*.ConsumerTopicMetrics.clientId.[topic name].MessagesPerSec.countThese consumer metrics are useful since it helps us monitor consumer rate for each topic. But the new consumer(0.9.0.0) doesn't expose per topic metrics anymore, even though I did find sensor objects in consumer metrics object collecting per-topic metrics.After investigation, I found that these sensors are not registering any KafkaMetrics.Author: Yifan Ying <yying@fitbit.com>Reviewers: Grant Henke, Jason Gustafson, Guozhang WangCloses #939 from happymap/KAFKA-3233",1
"HOTFIX: fix NPE in Kafka Streams IQ (#8158)Reviewers: Vito Jeng <vito@is-land.com.tw>, Guozhang Wang <guozhang@confluent.io>",5
kafka-1727; Fix comment about message format; patched by Muneyuki Noguchi; reviewed by Jun Rao,0
"KAFKA-3615: Exclude test jars in kafka-run-class.shgranders hachikuji Can you take a look when you have time? Appreciate your time to review.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1263 from Ishiihara/classpath-no-test-jar",3
Add wait condition for state RUNNING (#7476),1
kafka-1738; Partitions for topic not created after restart from forced shutdown; patched by Jun Rao; reviewed by Neha Narkhede,1
"KAFKA-4850: Enable bloomfilters (#6012)This PR enables BloomFilters for RocksDB to speed up point lookups.The request for this has been around for some time - https://issues.apache.org/jira/browse/KAFKA-4850For testing, I've done the followingRan the standard streams suite of unit and integration testsKicked off the simple benchmark test with bloom filters enabledKicked off the simple benchmark test with bloom filters not enabledKicked off streams system testsMatthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",5
KAFKA-1852; Reject offset commits to unknown topics; reviewed by Joel Koshy,1
"KAFKA-3853; Extend OffsetFetch API to allow fetching all offsets for a consumer group (KIP-88)Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2074 from vahidhashemian/KAFKA-3853",5
"KAFKA-7215: Improve LogCleaner Error Handling (#5439)The thread no longer dies. When encountering an unexpected error, it marks the partition as ""uncleanable"" which means it will not try to clean its logs in subsequent runs.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-6710: Remove Thread.sleep from LogManager.deleteLogs (#4771)`Thread.sleep` in `LogManager.deleteLogs` potentially blocks a scheduler thread for up to `log.segment.delete.delay.ms` with a default value of a minute. To avoid this, `deleteLogs` now deletes the logs for which `currentDefaultConfig.fileDeleteDelayMs` has elapsed after the delete was scheduled. Logs for which this interval has not yet elapsed are considered for deletion in the next iteration of `deleteLogs`, which is scheduled sooner if required.Reviewers: Jun Rao <junrao@gmail.com>, Dong Lin <lindong28@gmail.com>, Ted Yu <yuzhihong@gmail.com>",1
KAFKA-2324; Update to Scala 2.11.7Author: Ismael Juma <ismael@juma.me.uk>Closes #82 from ijuma/kafka-2324 and squashes the following commits:d71bf5c [Ismael Juma] KAFKA-2324; Update to Scala 2.11.7,5
"KAFKA-7572: Producer should not send requests with negative partition id (#10525)This PR is for KAFKA-7572, which fixes the issue that producers will throw confusing exceptions when a custom Partitioner returns a negative partition. Since the PR #5858 is not followed by anyone currently, I reopen this one to continue the work.Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-5879; Controller should read the latest IsrChangeNotification znodes when handling IsrChangeNotification eventAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3840 from lindong28/KAFKA-5879",4
"KAFKA-3119: Adding -daemon option to zookeeper-server-start.sh USAGE, similar to kafka-server-start.shOutput after fix:#satul# ./kafka-server-start.shUSAGE: ./kafka-server-start.sh [-daemon] server.properties#satul# ./zookeeper-server-start.shUSAGE: ./zookeeper-server-start.sh [-daemon] zookeeper.propertiesAuthor: Atul Soman <atul.soman@microfocus.com>Reviewers: Gwen ShapiraCloses #785 from atulsm/trunk",1
KAFKA-1856 Add PreCommit Patch Testing patch by Ashish K Singh reviewed by Gwen Shapira,3
KAFKA-1438 Migrate client tools out of perf; reviewed by Neha Narkhede,1
HOTFIX: remove non-os streams example repo reference from web docs,2
"KAFKA-13629: Use faster algorithm for ByteUtils sizeOfXxx algorithm (#11721)Replace loop with a branch-free implementation.Include:- Unit tests that includes old code and new code and runs through several ints/longs.- JMH benchmark that compares old vs new performance of algorithm.JMH results with JDK 17.0.2 and `compiler` blackhole mode are 2.8-3.4 faster withthe new implementation. In a real application, a 6% reduction in CPU cycles wasobserved in the `send()` path via flamegraphs.```ByteUtilsBenchmark.testSizeOfUnsignedVarint                            thrpt    4  1472440.102 ±  67331.797  ops/msByteUtilsBenchmark.testSizeOfUnsignedVarint:·async                     thrpt               NaN                  ---ByteUtilsBenchmark.testSizeOfUnsignedVarint:·gc.alloc.rate             thrpt    4       ≈ 10⁻⁴               MB/secByteUtilsBenchmark.testSizeOfUnsignedVarint:·gc.alloc.rate.norm        thrpt    4       ≈ 10⁻⁷                 B/opByteUtilsBenchmark.testSizeOfUnsignedVarint:·gc.count                  thrpt    4          ≈ 0               countsByteUtilsBenchmark.testSizeOfUnsignedVarintSimple                      thrpt    4   521333.117 ± 595169.618  ops/msByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·async               thrpt               NaN                  ---ByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·gc.alloc.rate       thrpt    4       ≈ 10⁻⁴               MB/secByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·gc.alloc.rate.norm  thrpt    4       ≈ 10⁻⁶                 B/opByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·gc.count            thrpt    4          ≈ 0               countsByteUtilsBenchmark.testSizeOfVarlong                                   thrpt    4  1106519.633 ±  16556.502  ops/msByteUtilsBenchmark.testSizeOfVarlong:·async                            thrpt               NaN                  ---ByteUtilsBenchmark.testSizeOfVarlong:·gc.alloc.rate                    thrpt    4       ≈ 10⁻⁴               MB/secByteUtilsBenchmark.testSizeOfVarlong:·gc.alloc.rate.norm               thrpt    4       ≈ 10⁻⁶                 B/opByteUtilsBenchmark.testSizeOfVarlong:·gc.count                         thrpt    4          ≈ 0               countsByteUtilsBenchmark.testSizeOfVarlongSimple                             thrpt    4   324435.607 ± 147754.813  ops/msByteUtilsBenchmark.testSizeOfVarlongSimple:·async                      thrpt               NaN                  ---ByteUtilsBenchmark.testSizeOfVarlongSimple:·gc.alloc.rate              thrpt    4       ≈ 10⁻⁴               MB/secByteUtilsBenchmark.testSizeOfVarlongSimple:·gc.alloc.rate.norm         thrpt    4       ≈ 10⁻⁶                 B/opByteUtilsBenchmark.testSizeOfVarlongSimple:·gc.count                   thrpt    4          ≈ 0               counts```Reviewers: Ismael Juma <ismael@juma.me.uk>, Artem Livshits",3
MINOR: fix docs around leader rebalancing to reflect default of true (#7614)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
Minor: Remove the accidentally checked in file which broke checkStyle.,2
MINOR: Fix `ConsumerConfig.ISOLATION_LEVEL_DOC` (#11915)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Add more exception information in ProcessorStateManagerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Jun RaoCloses #2276 from guozhangwang/KMinor-exception-message",5
KAFKA-13480: Track Position in KeyValue stores (#11514)Add position tracking to KeyValue stores in support of KIP-796Reviewers: John Roesler <vvcephei@apache.org>,1
"KAFKA-8940: Tighten up SmokeTestDriver (#7565)After many runs of reproducing the failure (on my local MP5 it takes about 100 - 200 run to get one) I think it is more likely a flaky one and not exposing a real bug in rebalance protocol.What I've observed is that, when the verifying consumer is trying to fetch from the output topics (there are 11 of them), it poll(1sec) each time, and retries 30 times if there's no more data to fetch and stop. It means that if there are no data fetched from the output topics for 30 * 1 = 30 seconds then the verification would stop (potentially too early). And for the failure cases, we observe consistent rebalancing among the closing / newly created clients since the closing is async, i.e. while new clients are added it is possible that closing clients triggered rebalance are not completed yet (note that each instance is configured with 3 threads, and in the worst case there are 6 instances running / pending shutdown at the same time, so a group fo 3 * 6 = 18 members is possible).However, there's still a possible bug that in KIP-429, somehow the rebalance can never stabilize and members keep re-rejoining and hence cause it to fail. We have another unit test that have bumped up to 3 rebalance by @ableegoldman and if that failed again then it may be a better confirmation such bug may exist.So what I've done so far for this test:1. When closing a client, wait for it to complete closure before moving on to the next iteration and starting a new instance to reduce the rebalance churns.2. Poll for 5 seconds instead of 1 to wait for longer time: 5 * 30 = 150 seconds, and locally my laptop finished this test in about 50 seconds.3. Minor debug logging improvement; in fact some of them is to reduce redundant debug logging since it is too long and sometimes hides the key information.Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
"Revert ""draft patch""This reverts commit aa1546b0907c959a4df90a7e3d48bad0890d1f2f.",4
"KAFKA-7658: Follow up to original PR (#8027)Follow up to original PR #7985 for KIP-523 (adding `KStream#toTable()` operator)  - improve JavaDocs  - add more unit tests  - fix bug for auto-repartitioning  - some code cleanupReviewers: High Lee <yello1109@daum.net>, John Roesler <john@confluent.io>",5
"KAFKA-3522: Add TimestampedWindowStore builder/runtime classes (#6173)Add TimestampedWindowStore builder/runtime classesReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
kafka-1136; Add subAppend in Log4jAppender for generic usage; patched by Jie Huang; reviewed by Joel Koshy and Jun Rao,2
"KAFKA-4893; Fix deletion and moving of topics with long namesAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen Shapira, David Arthur, James Cheng, Vahid HashemianCloses #6869 from cmccabe/KAFKA-4893",5
MINOR: Consumer should throw KafkaException on invalid checksumInvalidRecordException is not part of the public API so go backto the behaviour before ff557f02 for now.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1676 from hachikuji/raise-kafka-exception-on-invalid-crc,5
MINOR: updated documentation where RocksDBStore was being used as the sample class for byte[] versus Bytes examples (#5884)Co-authored-by: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-9229: Fix incompatible change in InitProducerIdRequest (#7746)Reviewers: Jason Gustafson <jason@confluent.io>, José Armando García Sancio <jsancio@gmail.com>",5
"KAFKA-7941: Catch TimeoutException in KafkaBasedLog worker thread (#6283)When calling readLogToEnd(), the KafkaBasedLog worker thread should catch TimeoutException and log a warning, which can occur if brokers are unavailable, otherwise the worker thread terminates.Includes an enhancement to MockConsumer that allows simulating exceptions not just when polling but also when querying for offsets, which is necessary for testing the fix.Author: Paul Whalen <pgwhalen@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Arjun Satish <arjun@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>",5
"KAFKA-597 Refactor scheduler. Fixes a couple of bugs, and adds the ability to mock scheduled tasks.git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1419692 13f79535-47bb-0310-9956-ffa450edef68",1
MINOR: remove unused flag 'hasIdempotentRecords' (#9884)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: improve resilience of Streams test producers (#6028)Some Streams system tests have failed during the setup phasedue to the producer having retries disabled and getting sometransient error from the broker.This patch adds a retries parameter to the VerifiableProducer(default unchanged), and sets retries to 10 for Streams tests.It also sets acks equal to the number of brokers for Streams tests.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-4568; Simplify test code for multiple SASL mechanismsRemove workaround for testing multiple SASL mechanisms usingsasl.jaas.config and the new support for multiple clientmodules within a JVM.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>Closes #2373 from rajinisivaram/KAFKA-4568",5
trivial change to remove -UseCompressedOops option from script,1
MINOR: Add security considerations for remote JMX in Kafka docs (#6544)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
KAFKA-12503: inform threads to resize their cache instead of doing so for them (#10356)Make it so threads do not directly resize other thread's cachesReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
"MINOR: Remove flaky assertion in verifyCloseOldestConnectionWithStagedReceivesThis seems to fail a lot in Jenkins although it always passes locallyfor me. Removing the assertion to restore Jenkins stability whilewe investigate in more detail.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3543 from ijuma/remove-selector-test-assertion",3
"KAFKA-13799: Improve documentation for Kafka zero-copy (#12052)Improve documentation for Kafka zero-copy. Kafka combines pagecache and zero-copy to greatly improve message consumption efficiency. But zero-copy only works in PlaintextTransportLayer.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
port paragrpah from CP docs (#7808)The AK Streams architecture docs should explain how the maximum parallelism is determinedReviewers: Bill Bejeck <bbejeck@gmail.com>,2
KAFKA-7051: Improve the efficiency of ReplicaManager (fixup),0
KAFKA-42 Cluster expansion feature; patched by Neha; reviewed by Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396808 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Enable a number of xlint scalac warningsUpdate the code where possible to fix the warnings. The unusedwarning introduced in Scala 2.12 is quite handy and providesa reason to compile with Scala 2.12.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3464 from ijuma/scala-xlint,5
"KAFKA-3945; Change the type of 'acks' config in console producer to StringThe `acks` config that is provided to console producer with `request-required-acks` comes with `all`, `-1`, `0`, `1` as valid options (`all` and `-1` being interchangeable). Currently, the console producer expects an integer for this input and that makes `all` to become an invalid input. This PR fixes this issue by changing the input type to String.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Manikumar reddy O <manikumar.reddy@gmail.com>, Grant Henke <granthenke@gmail.com, Ismael Juma <ismael@juma.me.uk>Closes #1618 from vahidhashemian/KAFKA-3945",4
"KAFKA-2337;  Verify that metric names will not collide when creating new topics; patched by Grant Henke; reviewed by Edward Ribeiro, Ashish Singh and Gwen Shapira",1
"MINOR: log warning when topology override for cache size is non-zero (#11959)Since the topology-level cache size config only controls whether we disable the caching layer entirely for that topology, setting it to anything other than 0 has no effect. The actual cache memory is still just split evenly between the threads, and shared by all topologies.It's possible we'll want to change this in the future, but for now we should make sure to log a warning so that users who do try to set this override to some nonzero value are made aware that it doesn't work like this.Also includes some minor refactoring plus a fix for an off-by-one error in #11796Reviewers: Luke Chen <showuon@gmail.com>, Walker Carlson <wcarlson@confluent.io>, Sagar Rao <sagarmeansocean@gmail.com>",5
"HOTFIX: handle commit failed exception on stream thread's suspend task1. Capture `CommitFailedException` in `StreamThread#suspendTasksAndState`.2. Remove `Cache` from AbstractTask as it is not needed any more; remove not used cleanup related variables from StreamThread (cc dguy to double check).3.  Also fix log4j outputs for error and warn, such that for WARN we do not print stack trace, and for ERROR we remove the dangling colon since the exception stack trace will start in newline.4. Update one log4j entry to always print as WARN for errors closing a zombie task (cc mjsax ).Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3574 from guozhangwang/KHotfix-handle-commit-failed-exception-in-suspend",0
"KAFKA-13417; Ensure dynamic reconfigurations set old config properly (#11448)This patch fixes a bug in `DynamicBrokerConfig` which causes some configuration changes to be ignored. In particular, the bug is the result of the reference to the old configuration getting indirectly mutated prior to the call to `BrokerReconfigurable.reconfigure`. This causes the first dynamic configuration update to pass effectively the same configuration as both `oldConfig` and `newConfig`. In cases such as in `DynamicThreadPool`, the update is ignored because the old configuration value matches the new configuration value.This bug only affects KRaft. It is protected in the zk broker by the call to `DynamicBrokerConfig.initialize()`, which overwrites the stored reference to the original configuration. The patch fixes the problem by ensuring that `initialize()` is also invoked in KRaft when `BrokerServer` starts up.Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-14148: Update ResetOffsetsDoc (#12491)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Fix join group request timeout lower bound (#8702)If the request timeout is larger than the rebalance timeout, we should use the former as the JoinGroup request timeout. This patch also includes some minor improvements to request/response logging in `NetworkClient` including adding the request timeout to the log message.Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7455: Support JmxTool to connect to a secured RMI port. (#5968)Reviewers: Attila Sasvari <asasvari@apache.org>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
"MINOR: Remove KafkaStreams#toString (#4909)Remove the deprecated KafkaStreams#toString function. Also override toString() for internal classes for debugging purposes.Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-8953: Rename UsePreviousTimeOnInvalidTimestamp to UsePartitionTimeOnInvalidTimestamp (#7633)Implements KIP-530Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Add missing @Test annotation to MetadataTest#testMetadataMerge (#8141)Reviewers: Brian Byrne <bbyrne@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-4331: Kafka Streams resetter is slow because it joins the same group for each topic- reworked to use a sinlge KafkaConsumer and subscribe only onceAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2049 from mjsax/improveResetTool,1
KAFKA-1156 Improve reassignment tool to output the existing assignment to facilitate rollbacks; reviewed by Jun Rao,1
"KAFKA-12204; Implement DescribeCluster API in the broker (KIP-700) (#9903)This PR implements the DescribeCluster API in the broker.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-12313: KIP-725: Streamlining configs for Windowed Deserialisers (#10542)This PR aims to streamline the configurations for WindowedDeserialisers as described in KIP-725. It deprecates default.windowed.key.serde.inner and default.windowed.value.serde.inner configs in StreamConfig and adds windowed.inner.class.serde. Reviewers: Anna Sophie Blee-Goldman<ableegoldman@apache.org>,1
trivial fix for stylecheck error on Jenkins,0
KAFKA-12287: Add WARN logging on consumer-groups when reset-offsets by timestamp or duration can't find an offset and defaults to latest (#10092)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
HOTFIX: remove unsued StreamsConfig from StreamsPartitionAssignor,5
KAFKA-1276 Make topic command list the possible topic-level configs that are available.,5
"KAFKA-9945: TopicCommand should support --if-exists and --if-not-exists when --bootstrap-server is used (#8737)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",1
"KAFKA-4603: Fixed the argument of shell in doc    KAFKA-4603 the argument of shell in doc wrong and command parsed error    In ""7.6.2 Migrating clusters"" of document security.html, the argument ""--zookeeper.connection"" of shell ""zookeeper-security-migrat.sh""   is wrong  and the using of OptionParser is not correct    This patch corrected the doc and changed the OptionParser constructorAuthor: auroraxlh <xin.lihua1@zte.com.cn>Reviewers: Xi Hu <huxi_2b@hotmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2322 from auroraxlh/my-issue",0
"KAFKA-12543: Change RawSnapshotReader ownership model (#10431)Kafka networking layer doesn't close FileRecords and assumes that they are already open when sending them over a channel. To support this pattern this commit changes the ownership model for FileRawSnapshotReader so that they are owned by KafkaMetadataLog.Reviewers: dengziming <swzmdeng@163.com>, David Arthur <mumrah@gmail.com>, Jun Rao <junrao@gmail.com>",5
"KAFKA-10214: Fix zookeeper_tls_test.py system testAfter 3661f981fff2653aaf1d5ee0b6dde3410b5498db security_config is cached. Hence, the later changes to security flag can't impact the security_config used by later tests.issue: https://issues.apache.org/jira/browse/KAFKA-10214Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Ron Dagostino <rdagostino@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8949 from chia7712/KAFKA-10214",5
MINOR: Clarify impact of num.replica.fetchers (#12153)The documentation for `num.replica.fetchers` should emphasize the fact that the count applies to each source broker individually. Also mention the tradeoff.Reviewers: Jason Gustafson <jason@confluent.io>,5
2198Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2198 from enothereska/hotfix-stream-states,0
"MINOR: Improve usage of LogManager.currentDefaultConfig (#11094)In `deleteLogs`, we use a consistent value for `fileDeleteDelayMs`for the whole method. In `DynamicBrokerConfig.reconfigure`, it'sa minor readability improvement, but there should be no change inbehavior.Reviewers: David Arthur <mumrah@gmail.com>",4
KAFKA-1583; Encapsulate replicated log implementation details intoReplicaManager and refactor KafkaApis; reviewed by Joel Koshy and JunRao,4
"KAFKA-5260; Producer should not send AbortTxn unless transaction has actually begunKeep track of when a transaction has begun by setting a flag, `transactionStarted` when a successfull `AddPartitionsToTxnResponse` or `AddOffsetsToTxnResponse` had been received. If an `AbortTxnRequest` about to be sent and `transactionStarted` is false, don't send the request and transition the state to `READY`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3126 from dguy/kafka-5260",5
"MINOR: Update gradlew.bat as per latest gradle releaseWhen invoking `gradle` on a recent version, it updates `gradlew.bat` to fix a typo. It's an annoyance at development time as it causes a diff on whatever branch one is working on.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1034 from ijuma/update-gradlew.bat",5
kafka-2013; benchmark test for the purgatory; patched by Yasuhiro Matsuda; reviewed by Jun Rao,3
KAFKA-889 Add mbeans to track socket server's response queue size in addition to request queue size; reviewed by Jun Rao and Joel Koshy,1
KAFKA-4994; Remove findbugs suppression for OffsetStorageWriter (#5385)Remove findbugs suppression for OffsetStorageWriter because it is no longer needed.,1
MINOR: Fix logging in ControlRecordType- typo error corrected (spelling)Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2885 from Kamal15/log,2
KAFKA-13698; KRaft authorizer should use host address instead of name (#11807)Use `InetAddress.getHostAddress` in `StandardAuthorizer` instead of `InetAddress.getHostName`.Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>,5
"KAFKA-13600: Kafka Streams - Fall back to most caught up client if no caught up clients exist (#11760)The task assignor is modified to consider the Streams client with the most caught up states if no Streams client exists that is caught up, i.e., the lag of the states on that client is less than the acceptable recovery lag.  Unit test for case task assignment where no caught up nodes exist.Existing unit and integration tests to verify no other behaviour has been changedCo-authored-by: Bruno Cadonna <cadonna@apache.org>Reviewer: Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-9274: handle TimeoutException on task reset (#10000)Part of KIP-572: We move the offset reset for the internal ""main consumer"" when we revive a corrupted task, from the ""task cleanup"" code path, to the ""task init"" code path. For this case, we have already logic in place to handle TimeoutException that might be thrown by consumer#committed() method call.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-5745; makeLeader should invoke `convertHWToLocalOffsetMetadata` before marking it as leaderAuthor: huxihx <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3682 from huxihx/KAFKA-5745",5
"MINOR: Reduce logging levelAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3505 from enothereska/minor-less-logs",2
"KAFKA-4714; Flatten and Cast single message transforms (KIP-66)Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2458 from ewencp/kafka-3209-even-more-transforms",5
KAFKA-9295: increase session timeout to fix flaky KTableKTableForeignKeyInnerJoinMultiIntegrationTest (#10715)Increase session timeout to fix flaky KTableKTableForeignKeyInnerJoinMultiIntegrationTest.shouldInnerJoinMultiPartitionQueryableReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,3
MINOR: Change log level for group member failure from debug to infoAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3523 from guozhangwang/KMinor-group-coordinator-member-failure-info-log4j,5
KAFKA-5599; ConsoleConsumer: deprecate --new-consumer optionMarked --new-consumer as deprecated in the help of ConsoleConsumerand a warning will be printed if it's used.Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3537 from ppatierno/kafka-5599,1
MINOR: remove unnecessary null check (#7299)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Seal the HostedPartition enumeration (#6917)Makes HostedPartition a sealed trait and make all of the match cases explicit.Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"Kafka-2587:  Only notification handler will update the cache and all verifications will use waitUntilTrue.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #277 from Parth-Brahmbhatt/KAFKA-2587",1
"KAFKA-1742; ControllerContext removeTopic does not correctly update state; reviewed by Joel Koshy, Guozhang Wang and Neha Narkhede",5
"MINOR: Reorder StreamThread shutdown sequenceWe need to close producer first before closing tasks to make sure all messages are acked and hence checkpoint offsets are updated before closing tasks and their state. It was re-ordered mistakenly before.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #845 from guozhangwang/KStreamState",5
"KAFKA-6532: Reduce impact of delegation tokens on public interfaces (#4524)Keep delegation token implementation internal without exposing implementation details to pluggable classes:  1. KafkaPrincipal#tokenAuthenticated must always be set by SaslServerAuthenticator so that custom PrincipalBuilders cannot override.  2. Replace o.a.k.c.security.scram.DelegationTokenAuthenticationCallback with a more generic ScramExtensionsCallback that can be used to add more extensions in future.  3. Separate out ScramCredentialCallback (KIP-86 makes this a public interface) from delegation token credential callback (which is internal).Reviewers: Jun Rao <junrao@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
MINOR: replace remove() with delete() after 5.0.1 RocksDB upgradeAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2380 from guozhangwang/KMinor-remove-deprecated-rocksDB,5
"KAFKA-1180 WhiteList topic filter gets a NullPointerException on complex Regex patch by Joe Stein, reviewed by Joel Koshy",1
MINOR: Fix quickstart in docsReverting some of the recent changes to quickstart doc. Further explanation is provided inline.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2539 from vahidhashemian/doc/fix_quickstart_issues,2
"MINOR: Mention switch to reload4j in Notable changes in 3.1.1 (#12313)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Kvicii",4
ZK consumer may lose a chunk worth of message during rebalance; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-154git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1182028 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: remove KTable.to from the docs (#10464)Reviewers: Bill Bejeck <bill@confluent.io>,5
"KAFKA-7223: document suppression buffer metrics (#6024)Document the new metrics added in #5795Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Print offset and size in sendFetchesAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3063 from guozhangwang/KMinor-more-logging-in-fetcher,2
"KAFKA-7535; KafkaConsumer doesn't report records-lag if isolation.level is read_committedFetchResponse should return the partitionData's lastStabeleOffsetAuthor: lambdaliu <lambdaliu@tencent.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Dhruvil Shah <dhruvil@confluent.io>, Dong Lin <lindong28@gmail.com>Closes #5835 from lambdaliu/KAFKA-7535",5
"KAFKA-10069: Correctly remove user-defined ""predicate"" and ""negate"" configs from transformation properties (#8755)With the recent introduction of predicated SMTs, properties named ""predicate"" and ""negate"" should be ignored and removed in case they are present in transformation configs. This commit fixes the equality check to be with the key of the config to apply proper removal. Reviewers: Tom Bentley <tbentley@redhat.com>, Konstantine Karantasis <konstantine@confluent.io>",5
KAFKA-12814: Remove Deprecated Method StreamsConfig getConsumerConfigs (#10737)Removes method deprecated via KIP-276.Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-6513: Corrected how Converters and HeaderConverters are instantiated and configuredThe commits for KIP-145 (KAFKA-5142) changed how the Connect workers instantiate and configure the Converters, and also added the ability to do the same for the new HeaderConverters. However, the last few commits removed the default value for the `converter.type` property for Converters and HeaderConverters, and this broke how the internal converters were being created.This change corrects the behavior so that the `converter.type` property is always set by the worker (or by the Plugins class), which means the existing Converter implementations will not have to do this. The built-in JsonConverter, ByteArrayConverter, and StringConverter also implement HeaderConverter which implements Configurable, but the Worker and Plugins methods do not yet use the `Configurable.configure(Map)` method and instead still use the `Converter.configure(Map,boolean)`.Several tests were modified, and a new PluginsTest was added to verify the new behavior in Plugins for instantiating and configuring the Converter and HeaderConverter instances.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4512 from rhauch/kafka-6513",5
"MINOR: Use new version of ducktapeducktape diff: https://github.com/confluentinc/ducktape/compare/v0.7.8...v0.7.9- bcrypt (a dependency of ducktape) dropped Python2.7 support.ducktape-0.7.9 now pins bcrypt to a Python2.7-supported version.Author: Andrew Egelhofer <aegelhofer@confluent.io>Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9192 from andrewegel/trunk",1
Minor: Fix @link in MetricName commentAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Guozhang WangCloses #651 from lindong28/minor-fix-link-comment,2
KAFKA-12573; Remove deprecated `Metric#value` (#10425)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-9753: A few more metrics to add (#8371)Instance-level:* number of alive stream threadsThread-level:* avg / max number of records polled from the consumer per runOnce, INFO* avg / max number of records processed by the task manager (i.e. across all tasks) per runOnce, INFOTask-level:* number of current buffered records at the moment (i.e. it is just a dynamic gauge), DEBUG.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-9441: Add internal TransactionManager (#8105)Upfront refactoring for KIP-447.Introduces `StreamsProducer` that allows to share a producer over multiple tasks and track the TX status.Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Use ConcurrentMap for ConsumerNetworkClient UnsentRequestsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2656 from hachikuji/minor-cleanup-unsent-requests,4
"KAFKA-6741:  Disable Selector's idle connection timeout in testNetworkThreadTimeRecorded() test (#4824)Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Add fetch from follower system test (#7166)This adds a basic system test that enables rack-aware brokers with the rack-aware replica selector for fetch from followers (KIP-392). The test asserts that the follower was read from at least once and that all the messages that were produced were successfully consumed. Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Update comment in SimpleAclAuthorizer to have correct JSON format`ConsumerGroup` should be `Group`.Author: Dustin Cote <dustin@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2534 from cotedm/acl-znode-correction,5
"MINOR: SaslChannelBuilder should be idempotentAfter we call `release`, we should null out the reference sothat we neither use it or release it a second time.This should fix the following exception that has been reported:```text[2017-06-23 03:24:02,485] ERROR stream-thread [...] Failed to close consumer:  (org.apache.kafka.streams.processor.internals.StreamThread:1054)org.apache.kafka.common.KafkaException: Failed to close kafka consumer        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1623)        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1573)        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1549)        at org.apache.kafka.streams.processor.internals.StreamThread.shutdown(StreamThread.java:1052)        at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:538)Caused by: java.lang.IllegalStateException: release called on LoginManager with refCount == 0        at org.apache.kafka.common.security.authenticator.LoginManager.release(LoginManager.java:106)        at org.apache.kafka.common.network.SaslChannelBuilder.close(SaslChannelBuilder.java:125)        at org.apache.kafka.common.network.Selector.close(Selector.java:257)        at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:505)        at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.close(ConsumerNetworkClient.java:439)        at org.apache.kafka.clients.ClientUtils.closeQuietly(ClientUtils.java:71)        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1613)```It's worth noting that it's not clear how `SaslChannelBuilder.close()` is called more thanonce and it would be good to understand that as well.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3422 from ijuma/sasl-channel-builder-idempotent",5
"KAFKA-10761; Kafka Raft update log start offset (#9816)Adds support for nonzero log start offsets.Changes to `Log`:1. Add a new ""reason"" for increasing the log start offset. This is used by `KafkaMetadataLog` when a snapshot is generated.2. `LogAppendInfo` should return if it was rolled because of an records append. A log is rolled when a new segment is created. This is used by `KafkaMetadataLog` to in some cases delete the created segment based on the log start offset.Changes to `KafkaMetadataLog`:1. Update both append functions to delete old segments based on the log start offset whenever the log is rolled.2. Update `lastFetchedEpoch` to return the epoch of the latest snapshot whenever the log is empty.3. Add a function that empties the log whenever the latest snapshot is greater than the replicated log. This is used when first loading the `KafkaMetadataLog` and whenever the `KafkaRaftClient` downloads a snapshot from the leader.Changes to `KafkaRaftClient`:1. Improve `validateFetchOffsetAndEpoch` so that it can handle fetch offset and last fetched epoch that are smaller than the log start offset. This is in addition to the existing code that check for a diverging log. This is used by the raft client to determine if the Fetch response should include a diverging epoch or a snapshot id. 2. When a follower finishes fetching a snapshot from the leader fully truncate the local log.3. When polling the current state the raft client should check if the state machine has generated a new snapshot and update the log start offset accordingly.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Clarify max.request.size and max.messsage.bytes wrt compression (#7575)Explicitly mention that max.request.size validates uncompressed record sizes and max.message.bytes validates compressed record sizes.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-646 Missing files from previous commit,2
"KAFKA-3522: Add RocksDBTimestampedStore (#6149)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: In the MetadataResponse schema, ignorable should be a boolean",5
MINOR: Add transactionalId in more log lines in the producer.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3343 from apurvam/KAFKA-5449-fix-bad-state-transition-in-transaction-manager,0
remove connection timeout in SyncProducer; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-579git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401775 13f79535-47bb-0310-9956-ffa450edef68,4
MINOR: Remove unnecessary old consumer usage in tests and other clean-ups (#5199)- Update some tests to use the Java consumer.- Remove ignored `ProducerBounceTest.testBrokerFailure`. This testis flaky and it has been superseded by `TransactionBounceTest`.- Use non-blocking poll for consumption methods in `TestUtils`.This is a step on the road to remove the old consumers.,4
broker needs to know the replication factor per partition; patched by Yang Ye; reviewed by Jun Rao; kafka-510git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396673 13f79535-47bb-0310-9956-ffa450edef68,2
"MINOR: Remove spammy, unhelpful log message in the controller (#7879)This patch removes a spammy log message in the controller which is printed every time the leader imbalance ratio is checked. It is unhelpful because preferred leaders are generally deterministic and is spammy because it includes _every_ partition in the cluster.Reviewers: Jonathan Santilli <jonathansantilli@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-13983: Fail the creation with ""/"" in resource name in zk ACL (#12359)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"MINOR: Improvements in group metadata cleanup and test coverageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #2202 from hachikuji/group-expiration-cleanup",4
KAFKA-8265: Initial implementation for ConnectorClientConfigPolicy to enable overrides (KIP-458) (#6624)Implementation to enable policy for Connector Client config overrides. This isimplemented per the KIP-458.Reviewers: Randall Hauch <rhauch@gmail.com>,5
KAFKA-5968; Create/remove request metrics during broker startup/shutdownReplaces the static `RequestMetrics` object with a class so that metricsare created and removed during broker startup and shutdown to avoid metricstests being affected by metrics left behind by previous tests.Also reinstates `kafka.api.MetricsTest` which was failing frequently earlierdue to tests removing the static request metrics.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3991 from rajinisivaram/KAFKA-5968,5
"MINOR: Remove outdated comment in Connect's WorkerCoordinator (#9805)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-7280; Synchronize consumer fetch request/response handling (#5495)This patch fixes unsafe concurrent access in the consumer by the heartbeat thread and the thread calling `poll()` to the fetch session state in `FetchSessionHandler`.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Replacing for with foreach loop in stream test classesAuthor: Prabhat Kashyap <prabhat.kashyap@knoldus.in>Reviewers: Ismael Juma, Damian Guy, Guozhang WangCloses #2305 from PKOfficial/code-refactor",4
"MINOR: Increase number of messages in replica verification tool testIncrease the number of messages produced to make the test more reliable. The test failed in a recent build and also fails intermittently when run locally. Since the producer uses acks=0 and the test stops as soon as a lag is observed, the change shouldn't have a big impact on the time taken to run when lag is observed sooner.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4312 from rajinisivaram/MINOR-replicaverification-test",5
"KAFKA-8564; Fix NPE on deleted partition dir when no segments remain (#6968)Kafka should not NPE while loading a deleted partition dir with no log segments. This patch ensures that there will always be at least one segment after initialization.Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7446: Fix the duration and instant validation messages. (#5930)Changes made as part of this commit. - Improved error message for better readability at millis validation utility - Corrected java documentation on `AdvanceInterval` check. - Added caller specific prefix text to make error message more clear to developers/users.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Jacek Laskowski <jacek@japila.pl>",5
"KAFKA-13841: Fix a case where we were unable to place on fenced brokers in KRaft mode (#12075)This PR fixes a case where we were unable to place on fenced brokers In KRaft mode. Specifically,if we had a broker registration in the metadata log, but no associated heartbeat, previously theHeartbeatManager would not track the fenced broker. This PR fixes this by adding this logic to themetadata log replay path in ClusterControlManager.Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2
"KAFKA-3732: Add an auto accept option to kafka-acls.shAdded a new argument to AclCommand: --yes. When set, automatically answer yes to promptsAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Gwen ShapiraCloses #1406 from mimaison/KAFKA-3732",1
"MINOR: Log unexpected exceptions in Connect REST calls that generate 500s at a higher log levelThe ConnectExceptionMapper was originally intended to handle ConnectException errors for some expected cases where we just want to always convert them to a certain response and the ExceptionMapper was the easiest way to do that uniformly across the API. However, in the case that it's not an expected subclass, we should log the information at the error level so the user can track down the cause of the error.This is only an initial improvement. We should probably also add a more general ExceptionMapper to handle other exceptions we may not have caught and converted to ConnectException.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #4227 from ewencp/better-connect-error-logging",2
KAFKA-2942: inadvertent auto-commit when pre-fetching can cause message lossAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #623 from hachikuji/KAFKA-2942,5
KAFKA-2295; Support dynamically loaded classes from context class loaderRebased code..Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Guozhang WangCloses #314 from omkreddy/KAFKA-2295,1
KAFKA-1252 Implement retries in new producer.,1
"KAFKA-6302: Improve AdmintClient JavaDocsReviewers: Colin P. McCabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #4332",5
"KAFKA-13021: disallow grace called after grace set via new API (#11188)Disallow calling grace() if it was already set via ofTimeDifferenceAndGrace/WithNoGrace(). Add the check to disallow grace called after grace set via new API, and add tests for them.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-7287: Set open ACL for old consumer znode path (#5503)Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",1
MINOR: Fix nonsense test line from TopicCommandTest (#10551)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"KAFKA-9051: Prematurely complete source offset read requests for stopped tasks (#7532)Prematurely complete source offset read requests for stopped tasks, and added unit tests.Author: Chris Egerton <chrise@confluent.io>Reviewers: Arjun Satish <arjun@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Jinxin Liu <liukrimhim@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-3371: ClientCompatibilityTest system test failingbecketqin have a look if this looks reasonable to you. Thanks.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1051 from enothereska/kafka-3371",5
MINOR: Replaced unnecessary isDefined and get on option values with foldAuthor: himani1 <1himani.arora@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2050 from himani1/refactored_code,4
MINOR: add list_topics command to help debug testsAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2052 from xvrl/test-add-list-topics,3
KAFKA-3887: KAFKA-3817 follow-up to avoid forwarding value if it is null in KTableRepartitionAlso handle Null value in SmokeTestUtil.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #1597 from guozhangwang/KHotfix-check-null,0
"KAFKA-6016; Make the reassign partitions system test use the idempotent producerWith these changes, we are ensuring that the partitions being reassigned are from non-zero offsets. We also ensure that every message in the log has producerId and sequence number.This means that it successfully reproduces https://issues.apache.org/jira/browse/KAFKA-6003.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4029 from apurvam/KAFKA-6016-add-idempotent-producer-to-reassign-partitions",1
KAFKA-1250 Add logging to new producer.,1
"MINOR: add a space to separate two wordsI think we should add a space here, otherwise the two words will join together.And replace the host string with a constant, otherwise when I need to modify the host, I need to modify several files.Author: 郑谦00117553 <00117553@zte.intra>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2132 from ZhengQian1/trunk",1
"KAFKA-4291; TopicCommand --describe should show topics marked for deletionDeveloped with edoardocomarAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>Closes #2011 from mimaison/KAFKA-4291",2
"KAFKA-7897; Disable leader epoch cache when older message formats are used (#6232)When an older message format is in use, we should disable the leader epoch cache so that we resort to truncation by high watermark. Previously we updated the cache for all versions when a broker became leader for a partition. This can cause large and unnecessary truncations after leader changes because we relied on the presence of _any_ cached epoch in order to tell whether to use the improved truncation logic possible with the OffsetsForLeaderEpoch API.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Jun Rao <junrao@gmail.com>",1
"KAFKA-12479: Batch partition offset requests in ConsumerGroupCommand (#10371)Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-12648: fix NPE due to race condtion between resetting offsets and removing a topology (#11847)While debugging the flaky NamedTopologyIntegrationTest. shouldRemoveOneNamedTopologyWhileAnotherContinuesProcessing test, I did discover one real bug. The problem was that we update the TopologyMetadata's builders map (with the known topologies) inside the #removeNamedTopology call directly, whereas the StreamThread may not yet have reached the poll() in the loop and in case of an offset reset, we get an NP.eI changed the NPE to just log a warning for now, going forward I think we should try to tackle some tech debt by keeping the processing tasks and the TopologyMetadata in syncAlso includes a quick fix on the side where we were re-adding the topology waiter/KafkaFuture for a thread being shut downReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-8290: Close producer for zombie task (#6636)When we close a task and EOS is enabled we should always close the producer regardless if the task is in a zombie state (the broker fenced the producer) or not.I've added tests that fail without this change.Reviewers: Matthias J. Sax <mjsax@apache.org>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8817: Remove timeout for the whole test (#7313)I bumped into this flaky test while working on another PR. It's a bit different from the reported PR, where it actually timed out at parsing localhost:port already. I think what we should really test is that the closing call can complete, so I removed the whole test timeout and add the timeout for the shutdown latch instead.Reviewers: Jason Gustafson <jason@confluent.io>, cpettitt-confluent <53191309+cpettitt-confluent@users.noreply.github.com>",5
"KAFKA-13152: Replace ""buffered.records.per.partition"" with ""input.buffer.max.bytes"" (#11424)This PR is an implementation of: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=186878390. The following changes have been made:* Adding a new config input.buffer.max.bytes applicable at a topology level.* Adding new config statestore.cache.max.bytes.* Adding new metric called input-buffer-bytes-total.* The per partition config buffered.records.per.partition is deprecated.* The config cache.max.bytes.buffering is deprecated.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
"HOTFIX: Do Not use unlimited num messages in IntegrationTestUtilsRemoved readKeyValues() that give UNLIMITED_MESSAGES which will doom to exhaust all wait time, as all its callers actually do provide the expected number of messages.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2507 from guozhangwang/KHotfix-not-use-limited-num-messages",0
"KAFKA-2388: refactor KafkaConsumer subscribe APIAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Edward Ribeiro, Onur Karaman, Ismael Juma, Guozhang WangCloses #139 from hachikuji/KAFKA-2388 and squashes the following commits:377c67e [Jason Gustafson] KAFKA-2388; refactor KafkaConsumer subscribe API",4
"KAFKA-13021: clarify KIP-633 javadocs and address remaining feedback (#11114)There were a few followup things to address from #10926, most importantly a number of updates to the javadocs. Also includes a few missing verification checks.Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Israel Ekpo",5
"KAFKA-4636; Per listener security settings overrides (KIP-103)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #2406 from ijuma/kafka-4636-per-listener-security-settings",1
"KAFKA-9011: Scala bindings for flatTransform and flatTransformValues in KStream (#7520)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-7589: Allow configuring network threads per listener (#11560)Implements KIP-788. The number of network threads can be set per listener using the following syntax:listener.name.<listener>.num.network.threads=<num>Reviewers: Tom Bentley <tbentley@redhat.com>, Andrew Eugene Choi <andrew.choi@uwaterloo.ca>, David Jacot  <djacot@confluent.io>",5
KAFKA-5169; KafkaConsumer.close should be idempotentAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2968 from mjsax/kafka-5169-consumer-close,5
KAFKA-890 The list of brokers for fetching metadata should be shuffled; reviewed by Joel Koshy,5
MINOR: Add missing log argument (#10262)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-9449; Adds support for closing the producer's BufferPool. (#7967)The producer's BufferPool may block allocations if its memory limit has hit capacity. If the producer is closed, it's possible for the allocation waiters to wait for max.block.ms if progress cannot be made, even when force-closed (immediate), which can cause indefinite blocking if max.block.ms is particularly high. This patch fixes the problem by adding a `close()` method to `BufferPool`, which wakes up any waiters that have pending allocations and throws an exception.Reviewers: Jason Gustafson <jason@confluent.io>",5
server should shut down on encountering invalid highwatermark file; patched by Yang Ye; reviewed by Jun Rao; kafka-509git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1392988 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-5953: Register all jdbc drivers available in plugin and class pathsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4030 from kkonstantine/KAFKA-5953-Connect-classloader-isolation-may-be-broken-for-JDBC-drivers",5
KAFKA-1886 SimpleConsumer swallowing ClosedByInterruptException; reviewed by Neha Narkhede,5
KAFKA-3301; CommonClientConfigs.METRICS_SAMPLE_WINDOW_MS_DOC is incor……rectAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1114 from granthenke/window-docs,2
KAFKA-6049: Add session window support for cogroup (#7782)Follow up to PR #7538 (KIP-150)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: un-deprecate StreamsConfig overloads to support dependency injection (#10484)In #5344 it came to our attention that the StreamsConfig overloads of the KafkaStreams constructors are actually quite useful for dependency injection, providing a cleaner way to configure dependencies and better type safety.Reviewers: Matthias J. Sax <mjsax@confluent.io>",5
"KAFKA-7987: Reinitialize ZookeeperClient after auth failures (#7751)Schedules client reinitialization if Zookeeper auth failure is encountered. This allows for reconnections when transient network errors are encountered during connection establishment. The Zookeeper client doesn't expose details of the auth failure so we can't determine whether an error is retriable or not, so all auth failures are retried.Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>",5
"KAFKA-6215: fix transient failures in KafkaStreamsTest - set streams state.dir to test-dir (default /tmp is not reliable)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>Closes #4221 from mjsax/minor-fix-instable-tests",3
"KAFKA-3771; Improving Kafka core code- Used flatMap instead of map and flatten- Use isEmpty, NonEmpty, isDefined as appropriate- Used head, keys and keySet where appropriate- Used contains, diff and find where appropriate- Removed redundant val modifier for case class constructor- toString has no parameters, no side effect hence without () consistent usage- Removed unnecessary return , parentheses and semi colons.Author: Joshi <rekhajoshm@gmail.com>Author: Rekha Joshi <rekhajoshm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1451 from rekhajoshm/KAFKA-3771",4
KAFKA-10677; Complete fetches in purgatory immediately after resigning (#9639)This patch adds logic to complete fetches immediately after resigning by returning the BROKER_NOT_AVAILABLE error. This ensures that the new election cannot be delayed by fetches which are stuck in purgatory. Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-8333; Load high watermark checkpoint lazily when initializing replicas (#6800)Currently we load the high watermark checkpoint separately for every replica that we load. This patch makes this loading logic lazy and caches the loaded map while a LeaderAndIsr request is being handled.Reviewers: Jun Rao <junrao@gmail.com>,0
KAFKA-5066; Add KafkaMetricsConfig (Yammer metrics reporters) props to documentationAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5563 from omkreddy/KAFKA-5066-KAFKA-METRICS-CONFIG,5
KAFKA-3605: Return error if connector config includes mismatching connector name.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason GustafsonCloses #1253 from ewencp/kafka-3605-connector-name-mismatch,5
"KAFKA-7418: Add the missing '--help' option to Kafka commands (KIP-374)Changes made as part of this [KIP-374](https://cwiki.apache.org/confluence/x/FgSQBQ) and [KAFKA-7418](https://issues.apache.org/jira/browse/KAFKA-7418) - Checking for empty args or help option in command file to print Usage - Added new class to enforce help option to all commands - Refactored few lines (ex `PreferredReplicaLeaderElectionCommand`) to   make use of `CommandDefaultOptions` attributes. - Made the changes in help text wordingsRun the unit tests in local(Windows) few Linux friendly tests are failing butnot any functionality, verified `--help` and no option response by runningScala classes, since those all are having `main` method.Author: Srinivas Reddy <srinivas96alluri@gmail.com>Author: Srinivas Reddy <mrsrinivas@users.noreply.github.com>Author: Srinivas <srinivas96alluri@gmail.com>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Manikumar Reddy <manikumar.reddy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Mickael Maison <mickael.maison@gmail.com>Closes #5910 from mrsrinivas/KIP-374",5
"MINOR: Remove unused class (#5037)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-10402: Upgrade system tests to python3 (#9196)For now, Kafka system tests use python2 which is outdated and not supported.This PR upgrades python to the third version.Reviewers: Ivan Daschinskiy, Mickael Maison <mickael.maison@gmail.com>, Magnus Edenhill <magnus@edenhill.se>, Guozhang Wang <wangguoz@gmail.com>",1
kafka-2088; kafka-console-consumer.sh should not create zookeeper path when no brokers found and chroot was set in zookeeper.connect; patched by Zhiqiang He; reviewed by Gwen Shapira and Jun Rao,1
"KAFKA-12938: Fix and reenable testChrootExistsAndRootIsLocked test (#10916)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Igor Soarez <soarez@apple.com>",3
"KAFKA-7492 : Updated javadocs for aggregate and reduce methods returning null behavior. (#6285)This is an update to the existing javadocs for KGroupedStream class.Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-13717: skip coordinator lookup in commitOffsetsAsync if offsets is empty (#11864)Reviewer: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-4569; Check for wakeup on every call to KafkaConsumer.pollAuthor: Armin Braun <me@obrown.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2699 from original-brownbear/KAFKA-4569",5
"MINOR: Switch to use AWS spot instancesPricing for m3.xlarge: On-Demand is at $0.266. Reserved is at about $0.16 (40% discount). And Spot is at $0.0627 (76% discount relative to On-Demand, or 60% discount relative to Reserved). Insignificant fluctuation in the past 3 months.Ran on branch builder and works as expected -- each worker is created using spot instances (https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1982/console)This can be safely backported to 0.10.2 (tested using https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1983/)Author: Max Zheng <maxzheng.os@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5707 from maxzheng/minor-switch@trunk",1
"KAFKA-4752: Fixed bandwidth calculationAuthor: Eno Thereska <eno@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2551 from enothereska/KAFKA-4752-join-bw",5
"KAFKA-7639: Read one request at a time from socket to avoid OOM (#5920)Prior to this commit, broker's Selector used to read all requests available on the socket when the socket is ready for read. These are queued up as staged receives. This can result in excessive memory usage when socket read buffer size is large. We mute the channel and stop reading any more data until all the staged requests are processed. This behaviour is slightly inconsistent since for the initial read we drain the socket buffer, allowing it to get filled up again, but if data arrives slighly after the initial read, then we dont read from the socket buffer until pending requests are processed.To avoid holding onto requests for longer than required, this commit removes staged receives and reads one request at a time even if more data is available in the socket buffer. This is especially useful for produce requests which may be large and may take long to process. Additional data read from the socket for SSL is limited to the pre-allocated intermediate SSL buffers.Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-13595: Allow producing records with null fields in ConsoleProducer (#11695)Implements KIP-810: https://cwiki.apache.org/confluence/display/KAFKA/KIP-810%3A+Allow+producing+records+with+null+values+in+Kafka+Console+ProducerConsoleProducer accepts a new setting, `null.marker`, that allows settings the record key, value or headers to null. This can be used to produce ""tombstone"" records.Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Israel Ekpo <israelekpo@gmail.com>",5
KAFKA-6331; Fix transient failure in AdminClientIntegrationTest.testAlterReplicaLogDirsAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4306 from lindong28/KAFKA-6331,3
MINOR: Small fixes in the documentation (#8623)These minor documentation fixes included: 1. fix broken links2. remove redundant sentences3. fix content format issueReviewers: Konstantine Karantasis <konstantine@confluent.io>,5
"KAFKA-12779: rename namedTopology in TaskId to topologyName #11192Update to KIP-740.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Israel Ekpo <israelekpo@gmail.com>",5
KAFKA-3163; Minor follow up for (KIP-33)junrao Could you take a look when get a chance? Thanks.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1769 from becketqin/KAFKA-3163-follow-up,1
"MINOR: Some broker code cleanups #10948Fix the JavaDoc for the ClientQuotaManagerConfig#throttle function torefer to the correct parameter name.BrokerEndPointTest#testHashAndEquals should test the BrokerEndPointclass, rather than the MetadataBroker class.TopicConfigHandler: make the kafkaController argument optional, since we won'thave it when in KRaft mode.Remove the unecessary ConfigRepository argument for the Partition class.Remove the unused TestUtils#deleteBrokersInZk function.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-7858: Automatically generate JoinGroup request/responseReviewers: Colin P. McCabe <cmccabe@apache.org>,2
"Kafka_7064 - bug introduced when switching config commands to ConfigResource  (#5245)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",5
"KAFKA-7207: Make rate & total metrics documentation consistent (#5429)Some sections of the Monitoring metrics documentation list out the -total metrics, and some sections do not list them out. Make them consistent and list out the missing -total metrics.",1
"KAFKA-130 Add a ""console producer"" that sends messages from standard inputgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178659 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-10309: KafkaProducer's sendOffsetsToTransaction should not block infinitively (#9081)Modified KafkaProducer.sendOffsetsToTransaction() to be affected with max.block.ms, and added timeout test for blocking methodsReviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Xi Hu <huxi_2b@hotmail.com>",5
KAFKA-10592: Fix vagrant for a system tests with python3Fix vagrant for a system tests with a python3.Author: Nikolay Izhikov <nizhikov@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9480 from nizhikov/KAFKA-10592,3
"HOTFIX: Fixes to javadoc and to state store name for link joinsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #1674 from enothereska/hotfix-misc-joins",0
"MINOR: wait for broker startup for system tests (#4363)ensure that brokers are registered at ZK before start() returnsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Damian Guy <damian@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-2790: doc improvementsAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Jun Rao, Guozhang WangCloses #491 from gwenshap/KAFKA-2790",1
"KAFKA-6958: Overload methods for group and windowed stream to allow to name operation name using the new Named class (#6413)This is the last PR for the KIP-307.NOTE : PR 6412 should be merge firstThanks a lot for the review.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-6718 / Add rack awareness configurations to StreamsConfig (#11837)This PR is part of KIP-708 and adds rack aware standby task assignment logic.Rack aware standby task assignment won't be functional until all parts of this KIP gets merged.Splitting PRs into three smaller PRs to make the review process easier to follow. Overall plan is the following:⏭️ Rack aware standby task assignment logic #10851⏭️ Protocol change, add clientTags to SubscriptionInfoData #10802👉 Add required configurations to StreamsConfig (public API change, at this point we should have full functionality)This PR implements last point of the above mentioned plan.Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
"MINOR: adding global store must ensure unique namesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2909 from mjsax/minor-fix-add-global-store",0
"MINOR: Avoid unnecessary leaderFor calls when ProducerBatch queue empty (#7196)The RecordAccumulator ready calls `leaderFor` unnecessarily when the ProducerBatchqueue is empty. When producing to many partitions, the queue is often empty and the`leaderFor` call can be expensive in comparison. Remove the unnecessary call.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
kafka-1287; enable log4j in command line tools using the new producer; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,1
"MINOR: Raft request thread should discover api versions (#10157)We do not plan to rely on the IBP in order to determine API versions for raft requests. Instead, we want to discover them through the ApiVersions API. This patch enables the flag to do so. In addition, this patch adds unsupported version as well as authentication version checking to all of the derivatives of `InterBrokerSendThread` which rely on dynamic api version discovery. Test cases for these checks have been added.Reviewers:  Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>",5
MINOR: KStream JavaDoc fixAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2284 from mjsax/javaDoc,2
kafka-1169; missing synchronization in access to leaderCache in KafkaApis; patched by Jun Rao; reviewed by Neha Narkhede,5
"KAFKA-4932: Add support for UUID serialization and deserialization (KIP-206)[KAFKA-4932](https://issues.apache.org/jira/browse/KAFKA-4932)Added a UUID Serializer / Deserializer.Added the UUID type to the SerializationTestAuthor: Brandon Kirchner <brandon.kirchner@civitaslearning.com>Reviewers: Jeff Klukas <jeff@klukas.net>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4438 from brandonkirchner/KAFKA-4932.uuid-serde",5
"KAFKA-10332: Update MM2 refreshTopicPartitions() logic (#9343)Trigger task reconfiguration when:- topic-partitions are created or deleted on source cluster- topic-partitions are missing on target clusterAuthors: Mickael Maison <mickael.maison@gmail.com>, Edoardo Comar <ecomar@uk.ibm.com>Reviewer: Randall Hauch <rhauch@gmail.com>",1
"KAFKA-7144: Fix task assignment to be even (#5390)This PR now justs removes the check in TaskPairs.hasNewPair that was causing the task assignment issue.This was done as we need to further refine task assignment strategy and this approach needs to include the statefulness of tasks and is best done in one pass vs taking a ""patchy"" approach.Updated current tests and ran locallyReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-149 minor commit to fix the project file to not reference the perf sub project anymoregit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179855 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR:Updated Rabobank descriptiondguy Please reviewAuthor: Manjula K <manjula@kafka-summit.org>Author: manjuapu <manjula@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3963 from manjuapu/customer-logo-stream,2
"KAFKA-5925: Adding records deletion operation to the new Admin Client APIThis is the PR related to the [KIP-204](https://cwiki.apache.org/confluence/display/KAFKA/KIP-204+%3A+Adding+records+deletion+operation+to+the+new+Admin+Client+API) in order to add the `deleteRecords` operation to the new Admin Client (it's already available in the ""legacy"" one).Other than that, unit test and integration tests are added as well (such integration tests come from the ""legacy"" integration tests in order to test the new addition in the same way as the ""legacy"" one).Author: Paolo Patierno <ppatierno@live.com>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4132 from ppatierno/kafka-5925",5
"MINOR: internal config objects should not be logged (#5389)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Add RaftReplicaManager (#10069)This adds the logic to apply partition metadata when consuming from the Raft-basedmetadata log.RaftReplicaManager extends ReplicaManager for now to minimize changes to existingcode for the 2.8 release. We will likely adjust this hierarchy at a later time (e.g. introducinga trait and adding a helper to refactor common code). For now, we expose the necessaryfields and methods in ReplicaManager by changing their scope from private to protected,and we refactor out a couple of pieces of logic that are shared between the twoimplementation (stopping replicas and adding log dir fetchers).Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
MINOR: improve JavaDocs about auto-repartitioning in Streams DSL (#6269),2
MINOR: Add another common error case for CorruptRecordException's error messageAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3541 from ewencp/corrupt-record-null-key-compacted-topic,0
"KAFKA-4465: Create docker image and scripts for running tests locallyAuthor: Raghav Kumar Gautam <raghav@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2197 from raghavgautam/trunk",1
KAFKA-5958; Global stores access state restore listenerAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3973 from bbejeck/KAFKA-5958_global_stores_access_state_restore_listener,5
"enforce broker.id to be a non-negative integer; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-424git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374440 13f79535-47bb-0310-9956-ffa450edef68",1
kafka-1620; Make kafka api protocol implementation public; patched by Anton Karamanov; reviewed by Jun Rao,1
"MINOR: remove FilteredIteratorguozhangwangremoving an unused class, FilteredIterator, and its test.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Gwen ShapiraCloses #816 from ymatsuda/remove_obsolete_class",4
MINOR: Update year in NOTICE (#10308)This is required to run a release as it is checked in release.pyReviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
trivial fix to 0.9.0 docs,2
"KAFKA-10847: Set shared outer store to an in-memory store when in-memory stores are supplied (#10613)When users supply in-memory stores for left/outer joins, then the internal shared outer store must be switch to in-memory store too. This will allow users who want to keep all stores in memory to continue doing so.Added unit tests to validate topology and left/outer joins work fine with an in-memory shared store.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-1866 LogStartOffset gauge throws exceptions after log.delete(); reviewed by Neha Narkhede,4
"HOTFIX: Adding init file so streams benchmark is autodiscoveredWithout this file the benchmark does not run nightly.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1645 from enothereska/hotfix-streams-test",3
MINOR: Specify keyalg RSA for SSL key generation commandsAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3305 from omkreddy/ssl-doc,2
"KAFKA-8187: Add wait time for other thread in the same jvm to free the locks (#6818)Fix KAFKA-8187: State store record loss across multiple reassignments when using standby tasks.Do not let the thread to transit to RUNNING until all tasks (including standby tasks) are ready.Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-13777: Fix potential FetchResponse#responseData race condition issue (#11963)In Fix FetchResponse#responseData, we did a double-checked lock for the responseData, but the assignment of lazy-initialized object(responseData) didn't assign in the last step, which would let other threads get the partial object. Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
remove sleep in test (#12525)Remove spurious sleep in ConsumerCoordinatorTestReviewers: Ismael Juma <mlists@juma.me.uk>,3
"KAFKA-6026; Fix for indefinite wait in KafkaFutureImplAuthor: bartdevylder <bartdevylder@gmail.com>Author: Bart De Vylder <bartdevylder@gmail.com>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #4044 from bartdevylder/KAFKA-6026",5
"MINOR: fix the way total consumed is calculated for verifiable consumer (#9143)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Add code quality checks (and suppressions) to checkstyle.xmlAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2594 from dguy/checkstyle",5
Fix a typo in delegation.token.expiry.time.ms docs (#5449)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>,2
MINOR: LogCleaner.validateReconfiguration fixes (#4770)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-13277; Fix size calculation for tagged string fields in message generator (#11308)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
KAFKA-439 Fix bad javadoc. Patch from Jim Plush. Reviewed and modified by Jay Kreps.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1373052 13f79535-47bb-0310-9956-ffa450edef68,2
"MINOR: Cache Node's hashCode to improve the producer's performance  (#4350)`Node` is immutable so this is safe.With 100 brokers, 150 topics and 350 partitions, `HashSet.contains` in `RecordAccumulator.ready` took about 40% of the application time. Itis caused by re-calculating a hash code of a leader (Node instance) forevery batch entry. Caching the hashCode reduced the time of`HashSet.contains` in `RecordAccumulator.ready` to ~2%. Themeasurements were taken with Flight Recorder.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ted Yu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-7139; Support option to exclude the internal topics in kafka-topics.sh (#5349)This patch implements KIP-338: https://cwiki.apache.org/confluence/display/KAFKA/KIP-338+Support+to+exclude+the+internal+topics+in+kafka-topics.sh+command.Reviewers: Andras Beni <andrasbeni@cloudera.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5673; refactor KeyValueStore hierarchy to make MeteredKeyValueStore outermostrefactor StateStoreSuppliers such that a `MeteredKeyValueStore`  is the outermost store.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3592 from dguy/key-value-store-refactor",4
KAFKA-14183; Cluster metadata bootstrap file should use header/footer (#12565)The boostrap.checkpoint files should include a control record batch forthe SnapshotHeaderRecord at the start of the file. It should alsoinclude a control record batch for the SnapshotFooterRecord at the endof the file.The snapshot header record is important because it versions the rest ofthe bootstrap file.Reviewers: David Arthur <mumrah@gmail.com>,2
gitignore for git-svn users.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1153592 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Use self-managed mode instead of KIP-500 and nozk (#10362)KIP-500 is not particularly descriptive. I also tweaked the readme text a bit.Tested that the readme for self-managed still works after these changes.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8500; Static member rejoin should always update member.id (#6899)This PR fixes a bug in static group membership. Previously we limit the `member.id` replacement in JoinGroup to only cases when the group is in Stable. This is error-prone and could potentially allow duplicate consumers reading from the same topic. For example, imagine a case where two unknown members join in the `PrepareRebalance` stage at the same time. The PR fixes the following things:1. Replace `member.id` at any time we see a known static member rejoins group with unknown member.id2. Immediately fence any ongoing join/sync group callback to early terminate the duplicate member.3. Clearly handle Dead/Empty cases as exceptional.4. Return old leader id upon static member leader rejoin to avoid trivial member assignment being triggered.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12648: fixes for query APIs with named topologies (#11609)Fixes some issues with the NamedTopology version of the IQ methods that accept a topologyName argument, and adds tests for all.Reviewers:  Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
