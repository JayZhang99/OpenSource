commit_msg,labels
"Fixed URL typo for Intellischool (#14372)URL for Intellischool was mistyped... silly mistake, apologies to the repo mods!",2
[AIRFLOW-794] Access DAGS_FOLDER and SQL_ALCHEMY_CONN exclusively from settingsCloses #2013 from gsakkis/settings,1
Show Triggers table in Webserver (#17876)This PR adds a view for Triggers table and adds permissions for that view.,1
Do not set `TaskInstance.max_tries` in `refresh_from_task` (#21018),1
[AIRFLOW-5185] Move GCP Video Intelligence to core (#5794)This commit moves GCP Video Intelligence from contrib to core.For more information check AIP-21.,5
Add no_status to state priority list (#22985),1
[Relay][Op] Pad operator (#1843),1
"Add different modes to sort dag files for parsing (#15046)This commit adds the feature to allow users to set one of the following modes, the scheduler will list and sort the dag files to decide the parsing order.:- `modified_time`: Sort by modified time of the files. This is useful on large scale to parse the recently modified DAGs first.- `random_seeded_by_host`: Sort randomly across multiple Schedulers but with same order on the same host. This is useful when running with Scheduler in HA mode where each scheduler can parse different DAG files.- `alphabetical`: Sort by filename",2
Remove remaining `pylint: disable` comments (#19541),5
[AIRFLOW-XXX] Add Veikkaus to Airflow users (#4874),1
Adding tomorrow_ds and yesterday_ds to default macros,1
"Fix constraint generation on CI (#23194)This is another small aftermath after the #23104 - this could notbe tested during PRs because generate-constraints only run inmain in apache/airflow repo and a problem crept in that I haveforgotten to add --run-in-parallel for those breeze commands,which resulted in missing the python version to generateconstraints for.This change adds --run-in-parallell and list of python versionsto work on so that generate constraints might start work again.",1
[AIRFLOW-6610] Move software classes to providers package (#7231)* [AIP-21] Move contrib.hooks.mongo_hook providers.mongo.hooks.mongo* [AIP-21] Move contrib.hooks.openfaas_hook providers.openfass.hooks.openfaas* [AIP-21] Move contrib.hooks.redis_hook providers.redis.hooks.redis* [AIP-21] Move contrib.operators.docker_swarm_operator providers.docker.operators.docker_swarm* [AIP-21] Move contrib.operators.redis_publish_operator providers.redis.operators.redis_publish* [AIP-21] Move contrib.operators.kubernetes_pod_operator providers.cncf.kubernetes.operators.kubernetes_pod* [AIP-21] Move contrib.sensors.bash_sensor sensors.bash* [AIP-21] Move contrib.sensors.celery_queue_sensor providers.celery.sensors.celery_queue* [AIP-21] Move contrib.sensors.mongo_sensor providers.mongo.sensors.mongo* [AIP-21] Move contrib.sensors.python_sensor sensors.python* [AIP-21] Move contrib.sensors.redis_key_sensor providers.redis.sensors.redis_key* [AIP-21] Move contrib.sensors.redis_pub_sub_sensor providers.redis.sensors.redis_pub_sub* [AIP-21] Move hooks.docker_hook providers.docker.hooks.docker* [AIP-21] Move hooks.mssql_hook providers.microsoft.mssql.hooks.mssql* [AIP-21] Move hooks.mysql_hook providers.mysql.hooks.mysql* [AIP-21] Move hooks.oracle_hook providers.oracle.hooks.oracle* [AIP-21] Move hooks.postgres_hook providers.postgres.hooks.postgres* [AIP-21] Move hooks.presto_hook providers.presto.hooks.presto* [AIP-21] Move hooks.samba_hook providers.samba.hooks.samba* [AIP-21] Move hooks.sqlite_hook providers.sqlite.hooks.sqlite* [AIP-21] Move operators.bash_operator operators.bash* [AIP-21] Move operators.docker_operator providers.docker.operators.docker* [AIP-21] Move operators.mssql_operator providers.microsoft.mssql.operators.mssql* [AIP-21] Move operators.mysql_operator providers.mssql.operators.mysql* [AIP-21] Move operators.oracle_operator providers.oracle.operators.oracle* [AIP-21] Move operators.papermill_operator providers.papermill.operators.papermill* [AIP-21] Move operators.postgres_operator providers.postgres.operators.postgres* [AIP-21] Move operators.presto_check_operator providers.presto.operators.presto_check* [AIP-21] Move operators.python_operator operators.python* [AIP-21] Move operators.sqlite_operator providers.sqlite.operators.sqlite* Update docs,2
Chart: Rename kerberos-keytab secret file (#20064),2
[TIR] cast disparate floating point types for binary ops (#8517)* handle upcasting case* test upcasting tests for tir* address comaniac comments* formatting* add negative tests* fix failing test now allow other thingsCo-authored-by: Andrew Zhao Luo <andrewzhaoluo@system76-pc.localdomain>,5
[AIRFLOW-4672] Make airflow/hooks Pylint compatible (#7767),1
"Refactor DAG pages to be consistent (#25402)There were a few DAG pages that were inconsistent:- Missing error handling for non-existing dag_ids- Not passing the orm model for the templates use (most notably missing  the ""next run"" info in the header)",5
[AIRFLOW-4995] Fix DB initialisation on MySQL (#5614)* [AIRFLOW-4995] Fix initdb for MySQL 8.0.16+,5
closes apache/incubator-airflow#2291 *Obsolete PR.*,5
Update tflite tutorial to use TFLite r1.13 schema (#3271),1
Fix typo in DagFileProcessorAgent._last_parsing_stat_received_at (#11022)`_last_parsing_stat_recieved_at` -> `_last_parsing_stat_received_at`,2
[AIRFLOW-XXXX] Update LICENSE versions and remove old licenses (#7553),4
Merge pull request #86 from woodlee/docs-editsVarious documentation spelling and grammar edits,2
Fix S3Hook transfer config arguments validation (#25544)* Fix S3Hook transfer config arguments validation* Add proper exception type,1
[AIRFLOW-554] Add Jinja support to Spark-sqlAllow SQL passed to Spark-SQL operator to be JinjatemplatedCloses #1828 fromdanielvdende/spark_sql_operator_jinja,1
Upgrade to latest version of FVP based on Arm(R) Corstone(TM)-300 software (#9672)* Upgrade to latest version of FVP based on Arm(R) Corstone(TM)-300 softwareChange-Id: I22685c117f3b6e9bc53c25ede14bb91c2b9f85f3* Upgrade to latest version of FVP based on Arm(R) Corstone(TM)-300 software- Allow CI tests to pass with existing FVPChange-Id: I67117de96c525fa01dae1d402a5f08743681a246,4
Update documents for using MySQL (#14174)Co-authored-by: Jarek Potiuk <jarek@potiuk.com>Co-authored-by: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>,1
"fix wrong type declaration of float64 ""log"" in intrin_math.py (#1169)",2
[AIRFLOW-2782][Airflow 2782] Removes unused hard-coded dagreD3Closes #3635 from verdan/AIRFLOW-2782-dagred3-fix,2
"Added k9s as integrated tool to help with kubernetes testing (#12163)The K9s is fantastic tool that helps to debug a running k8sinstance. It is terminal-based windowed CLI that makes youseveral times more productive comparing to using kubectlcommands. We've integrated k9s (it is run as a docker containerand downloaded on demand). We've also separated out KUBECONFIGof the integrated kind cluster so that it does not mess withkubernetes configuration you might already have.Also - together with that the ""surrounding"" of the kubernetestests were simplified and improved so that the k9s integrationcan be utilized well. Instead of kubectl port forwarding (whichcaused multitude of problems) we are now utilizing kind'sportMapping feature + custom NodePort resource that mapsport 8080 to 30007 NodePort which in turn maps it to 8080port of the Webserver. This way we do not have to establishan external kubectl port forward which is prone to error andmanagement - everything is brought up when Airflow getsdeployed to the Kind Cluster and shuts down when the Kindcluster is stopped.Yet another problem fixed was killing of postgres by one of thekubernetes tests ('test_integration_run_dag_with_scheduler_failure').Instead of just killing the scheduler it killed all pods - includingthe Postgres one (it was named 'airflow-postgres.*'). That causedvarious problems, as the database could be left in a strange state.I changed the tests to do what it claimed was doing - so killing only thescheduler during the test. This seemed to improve the stabilityof tests immensely in my local setup.",1
Update stale link to new location (#6819),1
Fix tvmc run error message when inputs aren't found. (#10017),0
export VirtualMachine for Windows (#11947),5
[AIRFLOW-6199] Add GKE example with XCOM (#6755),1
Optimize log when using VerticaOperator (#25566),1
"Revert ""[Relay][QNN] Add unit test for int8 (#4159)"" (#4192)This reverts commit 6f9d028b80f9e41fd577b5c6a7229cafcfc72173.",4
[runtime][refactor] Unify vm and interpreter objects (#4693)* unify vm and interpreter objects* move closure back vm* adt/closure back to vm.adt/vm.closure* closure base,4
[Onnx] Add Adagrad (#9001)* adagrad impl* passing tests* docstringCo-authored-by: Andrew Zhao Luo <andrewzhaoluo@system76-pc.localdomain>,5
Fix odbc hook sqlalchemy_scheme docstring (#25421),2
Dataproc submit job operator async (#25302),1
Don't run migration for adhoc command (#16255),1
[AutoScheduler] Add task.desc for its function name (#7794),1
More typing in SchedulerJob and TaskInstance (#24912)* More typing in SchedulerJob and TaskInstance,2
"Remove old test dag that is out of place (#16391)This dag hasn't been used in tests since about 2017, and is the lastfile in the top level `dags/` folder -- it's high time we removed it",4
"postgres_operator_howto_guide.rst (#23789)Saying ""**the** PostgreSQL database"" confused me. I thought it was implying that a user could/should connect to the airflow metadata db",5
"Chart: Adds labels to Kubernetes worker pods (#16203)We want to set labels on the KubernetesExecutor worker pods as well asone would expect those pods to show up when, say, filtering running podsby release name.",1
Better multiple_outputs inferral for @task.python (#20800),5
Fixing up Http*,0
[BYODT] fix CMAKE flag name + update documentation (#6567)* documentation fixes + better name* fix up comments,0
dump lowered IR when debug logging (#292)* dump lowered ir when debug log* avoid calling tvm.lower() twice when not debug,0
Clean up f-strings in logging calls (#23597),2
Fixing sqlite test,3
enter the shell breeze2 environment (#21145),5
support P12 credentials; compatibility with existing GCS connections,1
Merge pull request #1055 from lumengxi/chartImprove [Hide/Show all series] perforamce,2
[PASS]Treat Halide call_type as pure expression (#2404),4
Remove flask-admin based Plugins (#11515),4
remove clang compile warnings (#9942),2
"[Fix] relay onnx frontend bug when [A, B, M, N] * [1, B, N, K] (#9911)* [Fix] relay onnx frontend bug when [A, B, M, N] * [1, B, N, K]* fix lineCo-authored-by: tomoyazhang <tomoyazhang@tencent.com>",0
Support extra config options for Sentry (#8911)For now only dsn can be configured through the airflow.cfg. Need support 'http_proxy' option for example (it can't be configured through the environment variables). This change implements solution for supporting all existed (and maybe future) options for sentry configuration.,5
[TIR] Add DeclBuffer IR node and functors (#12300)* [TIR] Add DeclBuffer node* [TIR] Add IR functors for DeclBuffer* [TVMScript] Add printer and parser for DeclBuffer* Update printer* Update printer* Add test case* lint* fix,0
[Relay][AlterOpLayout] NHWC to NCHWc pad operator. (#4103)* [Relay][AlterOpLayout] NHWC to NCHWc pad operator.* Fixing culprit.* Flaky test 1.* Flaky test 2.,3
[AIRFLOW-6109] [AIP-21] Rename GCP function operators and hooks (#6977),1
Namespacing plugins properly,2
import zip,2
Adding support for multiple task-ids in the external task sensor (#17339)* Adding support for multiple task-ids in the external task sensor* Fixing flake8 errors* Fixing import errors,0
Remove extraneous treeData fields (#22763),5
Improve the Error message in Breeze for invalid params (#10980)Changed `Is` to `Passed`Before:```ERROR:  Allowed backend: [ sqlite mysql postgres ]. Is: 'dpostgres'.Switch to supported value with --backend flag.```After:```ERROR:  Allowed backend: [ sqlite mysql postgres ]. Passed: 'dpostgres'.Switch to supported value with --backend flag.```,1
[CODEGEN] Fix alignment generation (#955),0
use sasl/kerberos for snakebite if configured as such,5
[ONNX][Converter] Add dynamic nodes support (#9380)* [ONNX][Converter] Add support for dynamic nodes* fix lint,0
"Update ``GKEDeleteClusterOperator`, ``GKECreateClusterOperator`` docstrings (#22212)updated misleading docstrings to use Kubernetes rather than Compute as this takes Kubernetes engine zone as location parameters",2
[Relay] add some check for the ad algorithm (#3585)* do* fix test,3
Merge pull request #429 from jlowin/import_errmore informative error message,0
Move presto.execute inside try catch to handle errorThis commit fixes an issue where malformed SQL would raise aDatabaseError outside of the try catch block in the hook. Thisshould now raise a PrestoException as expected.,1
Add groups in CI output for parallell tasks (#25702)Some of our tasks run in parallel in CI. Their output is now groupedone group per parallel task and printed at the end only.Progress is displayed while the tasks are executed.,1
Update INTHEWILD.md (#10649)Added Datasprints as INTHEWILD markdown section,5
Simplify import check in CLI (#11668)* Simplify import chekc in CLI* fixup! Simplify import chekc in CLI* fixup! fixup! Simplify import chekc in CLI,2
[AIRFLOW-5184] Move GCP Natural Language to core (#5792),4
Merge similar sections on docs/howto/connection/index.rst (#10224),2
Fixing ParamValidationError when executing load_file in Glue hooks/operators (#16012)* Fixing ParamValidationError when executing load_file in Glue hooks/operatorsCo-authored-by: Rahul Raina <raina_rahul@singaporeair.com.sg>,1
"[Runtime] Add graph_executor get_input_index API. (#8633)* [Runtime] Add graph_executor get_input_index API.In graph_executor use case, user can use set_input withinput index to set input parameter, but there is no straightforward way to get correct index number with input name, hereprovide get_input_index API to do such work.* Update python/tvm/contrib/graph_executor.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Update python/tvm/contrib/graph_executor.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Update src/runtime/graph_executor/graph_executor.ccCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Update python/tvm/contrib/graph_executor.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>Co-authored-by: Cody Yu <comaniac0422@gmail.com>",5
[AIRFLOW-5764][depends on #6434] Avoid loading corrupted DAGs in a breeze environment (#6436),2
Fixed typo in plugins.rst,2
[AIRFLOW-4571] Add headers to templated field for SimpleHttpOperator (#5326)* [AIRFLOW-4571] Add headers field to templated field for SimpleHttpOperator,1
[Legalize][QNN] Pass out_types to Legalize. Update QNN requantize to read from out_types. (#3782),5
Add dependency of constraints on docs (#24866)The dependency between constraints and docs jobs in CI weremissing and it led to Sphinx 5 breaking our main builds becausethe constraints were updated even if the docs building failedThis change prevents similar case in the future - constraintswill not get updated if only docs build fails,0
[iOS] Add tracker support into ios-rpc application (#7876)* [IOS-RPC] Missprint in flag valueSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS-RPC] custom_dyld up commit id. Fix mem leakSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS-RPC] build without schemeSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS-RPC] Add tracker support into ios-rpc appAlso containes:* Links with tvm_runtime.dylib* Minor improvements from UX perspective* Add cli args support* Add caching for url/port/key attributesSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS-RPC] lint fixSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS-RPC] Uniform serversAlso:- Disabled bit-code- Enabled ARC- Use custom DSO loader by default- Single button to connect/disconnect- Add verbose flagSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS_RPC] Min changes. Fix warningsSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* [IOS-RPC] Fix review commentsSigned-off-by: Alexander Peskov <peskovnn@gmail.com>* Fix RPC connection to tracker* Fix typo* Fix build for local developer profile* Add tvmrpc xcode scheme* Revert unnecessary change* Remove old mechanism of reloading libs* Display ip and port for PureRPC mode* Update tests* Remove tvmLauncher from ios_rpc* Add updating tvm_build_dir in init_proj script* Update default bundle* Update README.md for ios_rpc* Fix lint* Apply comments* Rename PureRPC to StandaloneCo-authored-by: Egor Churaev <egor.churaev@gmail.com>,0
Refactor code references from tree to grid (#23254),4
[Bugfix] Fix visit_attrs error if its function pointer is equal to nullptr (#8920)* fix visit_attrs equals nullptr on python container object* add a test a for python container object about function dir and getattr* change test_ir_container.py to the pytest style* update the style to fix ci error* update the style of ir container to fix ci error,0
Add PReLU support to mxnet frontend (#1249),1
merging with master,5
Add semver and description of preparing rc2+ issue for providers (#25649)While releasing the providers two small problems were detected(as I recreated all my envs from scratch and released evenrc3 this time :)),1
"Fix typoe in migrations: RESOURCE_DAGS to RESOURCE_DAG. (#12460)This was missed in CI because it only became a problem when run with existing DAG data in the DB, which CI doesn't have.",5
Resolve more warnings in msvc (#6702),2
Add missing cmath header (#287)f9ed337552a26cc55c7c0fb22cd54839ee13f19c added a call to std::logwithout including cmath,2
[Relay] Port LSTM to Relay for testing (#2011),3
Blur mode,5
"[microNPU] Remove identity operations between non-compute operations (#10411)Builds upon the work in #10254 to remove identity operations sandwichedbetween two non-compute operations (reshape/strided slice - concatenateis handled differently), under certain conditions. Specifically, anidentity operation is not removed when the dimensionality between thetwo non-compute operations is reduced, due to non-congruent valuesbeing accessed incorrectly. For example,```strided_slice(dims=4) -> identity -> reshape(dims=4)```becomes...```strided_slice -> reshape```but,```strided_slice(dims=4) -> identity -> reshape(dims=2)```remains as...```strided_slice -> identity -> reshape```Change-Id: Ie28ba384fcb3230d6f4651c0c19e2b9526ebcc42",4
[Profiler] Do not aggregate frames with different devices (#9290),2
[AIRFLOW-2761] Parallelize enqueue in celery executor (#4234),5
[AIRFLOW-6537] Fix backticks in rst files (#7140),2
AIRFLOW-5484: fix PigCliHook has incorrect named parameter (#6112),2
[AIRFLOW-2678] Fix db schema unit test to remove checking fab models,4
Webserver: Sanitize values passed to origin param (#10334),2
"[CONTAINER] Add default python iterator for Map. (#8061)* [CONTAINER] Add default python iterator for Map.* formatting* add keys(), values()",1
[PASS] Add gradient pass (#28),4
More tests,3
[Topi][Cuda]Optimizations of global_ave_pool for NHWC layout (#5450)* Optimizations of global_ave_pool for NHWC layout* Optimize the code format to pass inspection of pylintCo-authored-by: Shawn-Inspur <wushaohua@inspur.com>,4
Add typing for jira provider (#10005),1
Make celery worker_prefetch_multiplier configurable (#8695),5
[AIRFLOW-5257] ElasticSearch log handler errors when attemping to close logs (#5863),2
"[microTVM] Zephyr: add mps3_an547 board support (#10479)* [microTVM] Zephyr: add mps3_an547 board supportAdd mps3_an547 board support to microTVM.On Zephyr this board is supported by two emulators: QEMU and FVP. Thiscommit only enables the support for running mps3_an547 on QEMU, sincecurrently there isn't a FVP transporter on microTVM. The main differencebetween these two emulators is that FVP is provided by Arm as a closedsource emulator and it supports the Ethos-U55 accelerator.The mps3_an547 is an Arm reference board. For more details, please see:https://developer.arm.com/tools-and-software/development-boards/fpga-prototyping-boards/mps3Since there are already specific tests enabled on the CI to testEthos using the AOT executor, for instance, this commit will only addsupport for mps3_an547 using QEMU for now, also enabling the board to betested on the CI.The FPU is disabled on this commit (""fpu"": false, in boards.json). Thisis due to commit d4cc1c2196 (""target/arm: Enable MVE in Cortex-M55"")being absent in QEMU v6.1.1, so it's not available in any zephyr-sdkrelease yet. That commit enables MVE (M-Profile Vector Extension) and sofully enables the instructions to run the code generated when FPU isenabled on Zephyr. It's available from QEMU v6.2.0.This commit also adds support for the QEMU_BIN_PATH env variable so itturns easy setting an alternative QEMU version other than the one thatis available via PATH, when running / testing any virtualized board,either by the CI in the future or locally by the users/devs.Finally this commit fixes two typos in comments.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* mehrdadh review: Add comment on why FPU is disabled if mps3_an547 supports it",1
[MetaSchedule] Mutator Rule: Mutate Unroll (#10045)* mutate-unroll* mutate-unroll,5
[AIRFLOW-XXX] Pin pinodb dependency (#4704),5
[COMMUNITY] vegaluisjose -> Committer (#6582),3
"[Adreno] Add markup pass of relay tensors for static texture planning (#11878)* [Adreno] Add static texture markup relay passCo-authored-by: Chris Sullivan <csullivan@octoml.ai>* lint check* Remove hardcoded texture limit, check through target options* fix cpplint* Add winograd into annotation pass* fix clang* Remove extra call of PlanDevice in OptimizeImpl* Remove one more extra call of PlanDevice in OptimizeImpl* Fix/add scopes for static texture planning tests* Remove test_2conv2d as duplication of test_plan_device_issue* remove comments in test_residual_block* address review comments* fix black hits* Add textures test descriptions* Address PR commentsCo-authored-by: Chris Sullivan <csullivan@octoml.ai>",5
Add option to bulk clear DAG Runs in Browse DAG Runs page (#11226)closes: #11076,1
[Relay][Frontend] Add slice axis op in mxnet converter (#2706)* Add slice axis op in mxnet converter* Fix lint,0
Version 0.2.3.3,5
register auto-scheduler to more ops (#6879),5
[TOPI] Fix CUDA pooling schedule (#8957),0
Added a FAQ section to the Upgrading to 2 doc (#13979)Added a FAQ question to the Upgrading to 2 doc and added an initialquestion and answer around needing providers to be installed beforeconnection types show up in the UI.,1
Bump pre-commit hooks (#17000)Just upgrades to latest minor versions of pre-commit hooks,1
Minor documentation tweaks to the FAQ under the fernet key section,2
Printing hostname on 404 page,5
Add FAB base class and set import_name explicitly. (#19667)* Add FAB base class and set import_name explicitly.* Fix linter errors caused by FAB code* Update airflow/www/extensions/init_appbuilder.pyCo-authored-by: Josh Fell <48934154+josh-fell@users.noreply.github.com>* Update airflow/www/extensions/init_appbuilder.pyCo-authored-by: Josh Fell <48934154+josh-fell@users.noreply.github.com>Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>Co-authored-by: Josh Fell <48934154+josh-fell@users.noreply.github.com>,1
"[AIRFLOW-5693] Support the ""blocks"" component for the Slack messages (#6364)- fix doc string issues",0
System test for EMR Serverless  (#25559)* System test for EMR Serverless following the template in #24643 (AIP-47)* Remove example_emr_serverless.py from example_dags,2
[AIRFLOW-2853] Add official committers to READMECloses #3699 from andscoop/Add-core-commiters-to-readme,1
Add Context stub to Airflow packages (#20817)We agreed that context.pyi is useful to be included in theairflow package as it will help our users with autocomplete andverification of the custom operators.,1
[ci] Add manual workflow to upload files to CI bucket (#11856)This adds a `workflow_dispatch` only GitHub Action that committers can use to upload files to the CI bucket for use like in #11839,1
[AIRFLOW-680] Disable connection pool for commandsThis is a continuation of Max's PR here:https://github.com/apache/incubator-airflow/pull/1021We have seen a very substantial DB cpu usagedecrease from this PR (~10x).This PR was originally created by plypaul I amjust cherrypicking onto master for him.Testing Done:- Has been running in Airbnb production for quitesome time (off of a different merge base though)Closes #1925 from aoen/ddavydov/reduce_db_sessions,5
close apache/incubator-airflow#1579 *closed for inactivity*,5
"[AIRFLOW-4052] Allow filtering using ""event"" and ""owner"" in ""Log"" view (#4881)In the RBAC UI, users can check Logs. But they could only use ""dag_id"", ""task_id"", ""execution_date"", or ""extra"" to filter, while filtering using ""event"" and ""owner"" will be very useful (to allow users to check specific events that happened, or check what a specific user did).",1
[AIRFLOW-2952] Fix Kubernetes CI (#3957)- Update outdated cli command to create user- Remove `airflow/example_dags_kubernetes` as the dag already exists in `contrib/example_dags/`- Update the path to copy K8s dags,2
"[AIRFLOW-3069] Log all output of the S3 file transform script (#3914)The output of the process spawned by S3FileTransformOperator is notproperly decoded, which makes reading logs rather difficult. Additonally,the stderr stream is only shown when process exit code is not equal to 0.- Send both output streams (stdout & stderr) to the logger.- Decode the output, so that new lines can be displayed correctly.- Include process exit code in the exception message, if the process fails.- Remove a potential deadlock, caused by `stderr=subprocess.PIPE`.- Don't load all output into memory.",1
[RELAY][OP]log_softmax op (#1857),2
Fix failed KubernetesPodOperator tests (#12461)Fixes failure in KubernetesPodOperator tests cause bynodeSelector arguments,1
[AIRFLOW-1660] Change webpage width to full-widthCloses #2646 from lxneng/feature/full_width_page,4
Support quantized ABS operator in TFLite frontend (#9411),1
drop the tmp table after ingestion,4
Fix Extra Links in Gannt View (#8308)Extra link didn't appear after changes in  https://github.com/apache/airflow/pull/8220 for Gantt View,4
[microTVM][CI] Rename ci_qemu to ci_cortexm (#12281)* rename files* ci script* demo* RVM files* jenkins* more ci* Jenkins* fake name for ci_cortexm* merge with main* add cortexm config file,2
[AIRFLOW-2847] Remove legacy imports support for plugins (#3692),1
[DOCS] Try upgrade build (#1066),1
Fix a bug of flatten in ONNX to Relay converter (#3180)* fix onnx frontend flatten bug* Update onnx.py* Update onnx.py* Update onnx.py,5
[AIRFLOW-5925] Relax funcsigs and psutil version requirements (#6580),1
[Frontend][Pytorch]Add Pytorch advanced indexing (#6318)* Add Pytorch advanced indexing* Minor fix for test* Fix for cuda,0
[AIRFLOW-6818] Prevent Docker cache-busting on when editing www templates (#7432)There is two parts to this PR:1. Only copying www/webpack.config.js and www/static/ before running the   asset pipeline2. Making sure that _all_ files (not just the critical ones) have the   same permissions.,2
[Rust][CI] Move CI over to new Rust crates and try to fix flaky test. (#6011),3
More chart improvements,1
[LLVM/RUNTIME] Support Parallel for on CPU (#54),1
"Fixed button size in ""Actions"" group. (#17902)",0
"Backport fix to allow pickling of Loggers to Python 3.6 (#18798)When sending objects around via multiprocessing (on Python 3.6 or lower)it would fail if that object contained a Logger object.To fix that we have ""backported"" the change in Python 3.7 to make Loggerobjects be pickled ""by name"". (In Python 3.7 the change adds`__reduce__` methods on to the Logger and RootLogger objects, but herewe achieve it `copyreg` stdlib module so we don't monkeypatchanything.)This mainly applies to using Kubernetes client >12 (which is notcurrently possible as we restrict that version) but this adds supportfor it anywhere it might happen inside Python 3.6.",1
Fix VTA Tutorial for more strict graphrt check (#1737),0
"Be build -> built, and a stray space (#20703)",5
"[RPC] Prefer IPv4 between IPv4 and IPv6 (#7013)This change fix problem with version of IP protocol on MacOS.  Previousthe `rpc_tracker` and `query_rpc_tracker` were not able connect to eachother with default hostnames.The root cause was in method `socket.getaddrinfo`. In `rpc_tracker` thedefault hostname is ""0.0.0.0"" and `getaddrinfo` returns IPv4 type. In`query_rpc_tracker` the default hastname is ""localhost"" and`getaddrinfo` on MacOS returns IPv6 type. Note: on Linux both have IPv4type.These tools worked by different protocols and this is why`query_rpc_tracker` wasn't able connect to `rpc_tracker`.Now we will prefer IPv4 type. And both `rpc_tracker` and`query_rpc_tracker` will use the same version of protocol.",1
[TOPI] sparse_dense Op sparse_data input added  (#6889)* [TOPI] sparse_dense op sparse_data input added* [1] clang issue resolved* [2] python format resolved* [3] lint error resolved* [4] Review comments handled* [5] Lint error resolved* [6] Review comments handled* [7] Review comments handled* [8] Review comments handled,0
Adding coveralls call,1
Fixed a failing example,0
[AIRFLOW-6575] Entropy source for CI tests is changed to unblocking (#7185)On Travis CI blocking entropy source slows startup time of a number ofcontainers. This change changes the entropy source to unblocking one.,4
Add AWS DMS replication task operators (#15850),1
"Speed up tests that use BackfillJob (#17648)Calling `heartbeat` was putting in a sleep in which isn'tnecessary/useful in tests, where we want it to run as quick as possible.The sleep has been kept in ""normal"" mode as otherwise the status output(`[backfill progress] | finished run %s of %s |` etc.) will beessentially spammed, rather than only being printed every few seconds.This makes the tests/jobs/ run in about 20s (vs 120s without thechange.)",4
Add ONNX LinearRegressor operator support (#10477),1
"Split and improve BigQuery example DAG (#8529)* Simplify existing example DAG and add consistent UI colors* Move BigQueryConsoleLink to top* Split DAG into two separate* Add transfer example* Fix check interval operatorCould not cast literal {{ macros.ds_add(ds, -1) }} to type DATE at [1:51]'}], 'state': 'DONE'}}* Add BigQuery queries example* fixup! Add BigQuery queries example",1
Add tool to clear stale images. (#11772),1
[TOPI] VNNI support for int8 dense (#10230)* wip* revert for now* simplify blocking* add bench script* update type rel* refactor tests* end to end compilation working* paralleize outer loop* add shape check* fused schedule first cut* restore original test* black* add vnni check* add relay test* skip on ci* check dtype* lint* make it tunable* minor cleanup,4
[ETHOSN] Add support for Ethos-N 21.02 driver stack release. (#7628)- Updated default Ethos-N driver stack to 21.02  - Fixed some test failures associated with this change,4
improved backwards compatibility (#21524)Co-authored-by: Maximilian Mehnert <memax@live.de>,1
[ci] Use r5.large nodes for builds and lint (#11258)This uses `r5.large` for linting and build steps and splits lint into 2 to keep runtime down. This is a subset split off of #11120. Once `task_cpp_unittest.sh` is fixed so it picks up sccache we can enable these smaller nodes there as well.,0
fix WebUiTests for SequentialExecutor,3
Add airflow connections get command (#10214),1
[Relay] Fixes to sum (#2439),0
fix c api,0
Switching debug to false on log server,2
[AIRFLOW-6942] Use tabulate to display DagBag Report (#7566),2
"Revert ""[AIRFLOW-78] airflow clear leaves dag_runs""This reverts commit 197c9050ef3a142c18aa97819da48ee8cadbf8d8.Regressions were observed and tasks were not scheduled in case ofmax_dag_runs reached.",2
"Fix Breeze2 autocomplete (#22695)Breeze2 autocomplete did not work because we were using some oldway of adding it (via click-complete). Since then click hasnative (and very well working) autocomplete support without anyexternal dependencies needed. It cannnot automatically generatethe completions but it is not needed either, because we canstore generated completion scripts in our repo.We also move some imports to local and catch rich_click importerror to minimize dependencies needed to get autocompleteworking. Setup-autocomplete install (and upgrade if neededclick in case it needs to be used by autocomplete script.Fixes: #21164",0
Added Hook for Amazon RDS. Added `boto3_stub` library for autocomplete. (#20642),1
fix dependenci and improve doc (#1535),2
Add driazati to triagers. (#11004)- This is to help with work on things like the merge bot and issue triage.,0
Fix typo change GitHyb to GitHub (#18640),4
[AutoTVM] Update XGBoost verbosity option (#5649),5
[SYMBOL] Enable get index from symbol (#286),1
[AIRFLOW-2220] Remove duplicate numeric list entry in security.rstThis duplicate entry was causing rst formattingissues in the securitysection of the documentation.Closes #3133 from dan-sf/AIRFLOW-2220,2
[fix] vec * mat in matmul in onnx converter (#11174)* fix: vec * mat in matmul in onnx converter* fix: pylint* fix: vec-mat matmul* fix test* fix test,3
Fix caffe2 relay frontend (#2733),0
Add more type annotations to AWS hooks (#10671)Co-authored-by: Kamil Bregu≈Ça <kamil.bregula@polidea.com>,1
Improve environment variables in GCP Secret Manager test (#13844),3
[AIRFLOW-XXX] Replace string with str in docstring for consistency (#6589),2
"Support external Redis in Helm Chart (#12010)* Fix chart network policies definion and complianceFollowup to #12003:* Some network policies & ingress are not valid  against the jsonschema (empty values mostly)* Some network policies conditionnal definitions  were incorrect* Support external redis instance in helm chartThe main objective here is to support the useof an external redis instance in the helm chart.The values 'data.brokerUrl' and'data.brokerUrlSecretName' are added andtemplates are updated.This support is added with no breaking changes(hopefully); only the redis.brokerURLSecretNamevalue is removed, but it wasn't actually used inthe chart.Extensive tests for the redis related part of thischart are also added (including runtime checks onthe values).Docs also updated.Closes #11705",5
Fix K8S CI job name rendering (#12007),0
Fix string concatenation using `f-strings` (#15200)Some of the strings had implicit concatentations. This commit fixes it.,0
Use Hash of Serialized DAG to determine DAG is changed or not (#10227)closes #10116,4
"Prepare to switch master branch for main. (#14688)There are many more references to ""master"" (even in our own repo) thanthis, but this commit is the first step: to that process.It makes CI run on the main branch (once it exists), re-words a fewcases where we can to easily not refer to master anymore.This doesn't yet re-name the `constraints-master` or `master-*` images -that will be done in a future PR.(We don't be able to entirely eliminate ""master"" from our repo as werefer to a lot of other GitHub repos that we can't change.)",4
[TIR][REFACTOR] Add tir prefix to type keys (#5802),0
[AIRFLOW-6449] Remove Github actions until a known bug is fixed (#7035),0
"[TOPI] FIFO buffer op, to accelerate sequence modeling with dilated convolutions (#4039)* Add FIFO buffer op to enable explicit computation re-use in convolution* Add a test* Add end-to-end test with 1D convolution* Add a stub in MXNet frontend* Address reviewer comments* Add back stub for MXNet frontend",1
prevent aggressive unrolling in vthread (#983),5
[AIRFLOW-XXX] Add task execution process on Celery Execution diagram (#6961),1
Add bulk_insert_rows() for more performant inserts.,1
Bump pre-commit hook versions (#22887),1
Add MSSQL link to breeze visuals.py and breeze-legacy,2
Allow long type values in shape list (#1806)* Allow long type values in shape list* Update build_module.py,5
[CI] Add log check to the sphinx gallery docs (#5643)* [CI] Add log check to the sphinx gallery docsThis PR add log check to sphinx gallery tutorials to preventthe case when sphinx failed to capture the error in tutorials.* Fix the status,0
[AIRFLOW-1252] API accept JSON when invoking a trigger dag (#2334),2
"GitHub Action lint Python code for syntax errors (#4688)* GitHub Action lint Python code for syntax errorshttps://flake8.pycqa.org/en/latest/user/error-codes.htmlOn the flake8 test selection, this PR does _not_ focus on ""_style violations_"" (the majority of flake8 error codes that [__psf/black__](https://github.com/psf/black) can autocorrect).  Instead these tests are focus on runtime safety and correctness:* E9 tests are about Python syntax errors usually raised because flake8 can not build an Abstract Syntax Tree (AST).  Often these issues are a sign of unused code or code that has not been ported to Python 3.  These would be compile-time errors in a compiled language but in a dynamic language like Python they result in the script halting/crashing on the user.* F63 tests are usually about the confusion between identity and equality in Python.  Use ==/!= to compare str, bytes, and int literals is the classic case.  These are areas where __a == b__ is True but __a is b__ is False (or vice versa).  Python >= 3.8 will raise SyntaxWarnings on these instances.* F7 tests logic errors and syntax errors in type hints* F82 tests are almost always _undefined names_ which are usually a sign of a typo, missing imports, or code that has not been ported to Python 3.  These also would be compile-time errors in a compiled language but in Python a __NameError__ is raised which will halt/crash the script on the user.* Force a retest* Rename start_rpc_server_to_tracker.py to start_rpc_server_to_tracker.shThis is a bash file, not a Python file.",2
"[QNN] Requantize operator (#3531)* [Relay] [Quantization] WIP - Common files for the qauntization work.* [Relay] [Quantization] WIP - Prototyping requantize op.* Requantize operator implementation.Requantize converts one quantized tensor representation to another quantizedrepresentation. The PR has following implementation features- Requantize operator defined in qnn namespace - relay.qnn.requantize- Lowering of the requantize to exisiting Relay operators- Integer fixed point implementation of requantize    - Two rounding modes - FE_UPWARDS (round towards infinity) and    FE_AWAY_FROM_ZERO (std::round behavior)- Floating point implementation as well, that can act as reference or can beused for devices when FP32 computation is not used.- Unit test casesRelevant Issue - https://github.com/dmlc/tvm/issues/2351Credit to TFLite and GemmLowp to provide reference implementations.* Typo and lint fixes.* Doc fix.* Uncommenting the lint script (fixing mistake).* Modifying the unit tests.* Moving C++ files into src/relay/qnn* Moving python files to python/tvm/relay/qnn. Some minor fixes.* Moving the attrs.h inside the include directory.* Pushing files that I forgot earlier. Changing util location.* Incorporating comments. API change. Lint fixes.* Modifying the GetFixedPointMultiplierShift API as per comments.* Forgot the dialect change.* Changing rewrite to qnn_lower.* Renaming Quantize to Qnn for clarity.* Remove use_int_domain.* Incorportaing review comments.* Adding API doc for QNN dialect.* Move the qnn_lower pass to transform namespace.* Moving from expr to module. Adding namespace in C++.* Minor sentence rewrites. Added qnn namespace.* Added the API doc.* Chanding default out_dtype to int8. Adding a test with in/out_dtype as uint8.* Style fixes. Better error messages.* Adding documentation.* More documentation fixes.* Adding out dtype check for requantize.* Adding corner case for FP32 to fixed point conversion.* Adding extra line.* Documentation fix.* Adding static inline.* Incorporating jackwish comment. Removed idtype from requantize lowering.* Removing Quantize/Dequantize code. Restricting Requantize to (u)int8/int32.* Style fixes.* Fix the docs.* Move to Legalize API.",4
[TIR] Fix assert for tensorcore int8 intrinsics (#12365),3
closes apache/incubator-airflow#1933 *Closed for inactivity*,5
"Switch to python 3.4, 3.5 was a bit too ambitious for now",5
[AIRFLOW-5718] Add SFTPToGoogleCloudStorageOperator (#6393),1
Adding light colors to the graph view,1
Increase typing coverage for postgres provider (#10864),1
Add optional location to bigquery data transfer service (#15088) (#20221),5
"[Relay][Parser] Improve Relay parser and pretty printing, including CMAKE (#2377)",1
[EXECUTOR] Split graph_executor to header file and (runtime) source file (#300)* [EXECUTOR] Split graph_executor to header file and (runtime) source file* Fix,0
allow libbacktrace to be used when cross compiling the runtime (#7917),1
More fixes and tweaks to the cuda conda packages (#3281),0
[REFACTOR][RELAY] move fallback_device to config (#5690),5
Quick fix,0
Workaround job race bug on biguery to gcs transfer (#24330)Fixes: #24277,0
Assign TS type to fix linting (#15090),0
Merge pull request #998 from joshmarlow/docs-tweakPedantic documentation tweaks,2
Fix SystemsManagerParameterStoreBackend test (#25751)This has been failing since the backend moved use_ssl to a separatedattribute instead of bundling it in kwargs.,5
[AIRFLOW-3594] Unify different License Header,5
"[ci] Remove commit check on ci skipping logic (#10537)* [ci] Remove commit check on ci skipping logicThis makes it very hard to use an sometimes out of the submitter's control (e.g. when Jenkins decides to push a merge commit before running CI) for dubious benefit (the PR title is where people are looking after-the-fact anyways, so having it in the commit message doesn't make much sense). This removes the check for the commit message in order to make the process smoother.commit-id:dbd18808* Address commentscommit-id:ecd2be81Co-authored-by: driazati <driazati@users.noreply.github.com>",1
More operators for Databricks Repos (#22422),5
"[AIRFLOW-3046] Report fail from ECS Operator when host terminates (#4039)Add check for host termination to ECS OperatorIf an ECS task fails to complete because the host it's running on is terminated, we need to raise an exception so it can be retried.",1
[BUILD] warning fix: new does not have an alignment parameter     (#1478),2
"[AIRFLOW-2930] Fix celery excecutor scheduler crash (#3784)Caused by an update in PR #3740.execute_command.apply_async(args=command, ...)-command is a list of short unicode strings and the above code pass multiplearguments to a function defined as taking only one argument.-command = [""airflow"", ""run"", ""dag323"",...]-args = command = [""airflow"", ""run"", ""dag323"", ...]-execute_command(""airflow"",""run"",""dag3s3"", ...) will be error and exit.",0
[Relay][Runtime] Add VM compiler.  (#3139)* Implement the VM compiler* Fix issues* Fix ASF headers* Fix test issue* Apply typo fixes.* Update src/relay/backend/vm/compiler.ccCo-Authored-By: ÈõæÈõ®È≠îÁêÜÊ≤ô <lolisa@marisa.moe>* Refactor compiler* Fix* Fix* Fix in benchmark* Fix* Address comments,1
[AIRFLOW-5625] Update MLEngine integration doc and typehint (#6293)* [AIRFLOW-5625] Update MLEngine integration doc and typehint,2
Fixing 'signal only works in main thread' error with timeouts,0
[Relay][Text Format] Fix Pretty Printing Annotations (#3041),0
[AIRFLOW-1160] Update Spark parameters for MesosCloses #2265 from cameres/master,2
change version number (#1175),4
[SCHEDULE] Detect useless bound early (#264)* [SCHEDULE] Detect useless bound early* fix,0
[AIRFLOW-1802] Convert database fields to timezone aware,5
"[AIRFLOW-475] make the segment granularity in Druid hook configurableThe Druid hook now has hardcoded`segmentGranularity` - ""DAY"", we need itconfigurable for different use cases.mistercrunch aoen plypaulCloses #1771 fromhongbozeng/hongbo/segment_granularity",1
Added Ubisoft to Airflow usersCloses #2911 from Walkoss/master,1
fix bug where multiple volume mounts created (#10915),1
Setting the default queue in BaseOperator,1
[AIRFLOW-1564] Use Jinja2 to render logging filenameStill backwards compatible with python formatCloses #2565 from NielsZeilemaker/AIRFLOW-1564,1
[AIRFLOW-2203] Speed up Operator ResourcesSet default values of Resources loaded from the configuration to prevent4x Config lookups for every task created.,1
[TFLite] Quantized version of unit test for Dense (#7113)Added quantized version of unit test for FullyConnected/DenseAdded check for -1 in case if bias not supplied,1
Update taskinstance REST API schema to include dag_run_id field (#19105)This PR adds dag_run_id field to taskinstance schema,2
"[BYOC] Switch TensorRT BYOC integration to IRModule-at-a-time using RelayToTIR hook (#11979)* [BYOC] Switch TensorRT BYOC integration to IRModule-at-a-time using RelayToTIR hookThis does for the TensorRT integration what #11631 did for the CUTLASS integration.- All compilation options are captured within the attributes of a Target of  kind ""tensorrt"" (instead of the ""relay.ext.tensorrt.options"" attribute in  PassContext). This means all BYOC configurations options needed by Collage can  be captured uniformly by a list-of-Targets. It also means RPC boundaries (as used  internally at OctoML) only need to worry about maintaining the fidelity of the  Target instance(s) rather than reaching into the PassContext.- Compilation is switched from function-at-a-time (relying on the TECompiler) to  IRModule-at-a-time (using the RelayToTIR target-specific hook mechanism). Though  not strictly necessary for Collage I want to check the path is now clear to  deprecate the support for BYOC in TEComplier.- Get all the TensorRT tests going again, except for a few I've disabled with  x-link to a new issue #11765. CAUTION: The TensorRT runtime is not supported in  CI so many of these tests are cosmetic.- While trying to track down a 'free(): invalid pointer' error in test_tensorrt_int8_exp.py  made the TensorRT allocs/frees more robust, but turns out its also broken in main.  No harm leaving these changes in though.* - Lints* - Woops, fix test* - lints* - Use default tensorrt target if none given in targets list* - fix free error* - accidentally introduced 'transforms' namespace- can't use default Target(""tensorrt"") arg* - D'oh! Include ended up #if protected* - restore mark for test_dynamic_offload- handle missing runtime in versioning- turn test_maskrcnn_resnet50 back on now that we have the  import-torch-first workaround.* - wibble",1
[Doc]refine the example description of max/min/sum/tag_scope (#4974),2
[DOCS] VTA installation guide (#1428),2
[FRONTEND][TFLITE] get input tensor information from graph (#7400)* [FRONTEND][TFLITE] get input tensor information from graph* remove bare-except* fix lint* delete empty line* comment change* move some of the tflite frontend code from tvmc to tflite.py* update shape and dtype when user provided them* remove unused var. pass user provided shape_dict* remove duplicate code,4
"[TIR] Support tensorization using ldmatrix + MMA (#11355)* [TIR] Support tensorization using ldmatrix + MMAcommit 3218facf100b0dfc55715acfd1cee156764129baAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 14:04:56 2022 +0900    some clean upcommit 7a235b69dc2023b3098ed44d591edb63b20a8f4eAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 13:55:11 2022 +0900    parameterize over storage scope in mma store intrincommit 827ea4c434c35607b241f8e0ae2efe3214ac2458Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 13:37:38 2022 +0900    properly handle floordiv/mod in codegencommit 42d4c6f42182c9fd79566c0955f99cc82abd5144Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 09:53:57 2022 +0900    update tuned factors for fp16commit 328d0aa36b2ea9ea1b051970d612bff82d2d20e6Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 08:43:30 2022 +0900    all tests workingcommit 5e086cf5fd1404ac38f85c4bfbe692687b45a16cAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 07:48:43 2022 +0900    add doc for mma_fill and mma_store intrincommit 4f945c4116b6d3bdc965ecb2be2229bb46dc11abAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 18 06:39:01 2022 +0900    remove testscommit df7708f7f67761d9c18f9564bc15abd50c12ac69Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 19:52:14 2022 +0900    unified testcommit 754c83eeb8510b31fb9652b089177f9b8e642ec0Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 19:36:24 2022 +0900    clean up LowerWarpmemorycommit 178c3dcee7bfa17d5d93fec02aa858dc62151670Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 19:15:04 2022 +0900    Use IndexMapcommit 07fb58910338c62847fd902b37801d09b8c673b0Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 17:51:44 2022 +0900    remove 16x8x8 testcommit 2b05b5a5470ac221d559f31a31a8e2ff753b2414Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 17:31:35 2022 +0900    generate mma fill/storecommit bf23fc50f0ffa99e875d9247ca66acec0c36677fAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 12:23:30 2022 +0900    mma intrin generation with meta programmingcommit 5afb5f00afd642cb1e39872edc7965f476dcdcb7Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 17 05:26:14 2022 +0900    ldmatrix intrin generation with meta programmingcommit fb62abb3424b88ec48c697e306e05889a3ac306fAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 20:30:49 2022 +0900    minorcommit 5a80adce24e84d3ec6bf931b60cb9c730d243394Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 19:55:57 2022 +0900    revert some changecommit e599a55078ee75f2480a721098341812db58cf6fAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 19:54:18 2022 +0900    remove obsolete filescommit 4b13b85ff91d0d592a7e0c01924e0b49b82f35a8Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 19:51:21 2022 +0900    wipcommit 848de63455539e25cd0d43e5a65fd048636ef0f7Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 19:44:29 2022 +0900    wipcommit b35bff97ed10c22559e2164eb7538db0f711ce7eAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 19:31:18 2022 +0900    update parse error msgcommit ad9b053ef865b1f91f03d7b15ed7aae3420ee213Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 19:26:51 2022 +0900    fix for avoiding Buffer.vload(...) casecommit 54c686443e370edbfae860d0809b1b6182d26414Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 18:59:55 2022 +0900    wipcommit 078060fe28d22f1db5f07b1c382dee438f02df60Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 18:57:34 2022 +0900    wipcommit 576f8415e65e0e8a8a7808885e219b3b53867950Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 18:52:15 2022 +0900    wipcommit 12a376ae2f44aa6660121e64e0358f2866624f7fAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 17:54:58 2022 +0900    Squashed commit of the following:    commit 48eef4981d1a55aaf3b0ac935f2a10347cb1ac2d    Author: Masahiro Masuda <masahi129@gmail.com>    Date:   Mon May 16 17:40:48 2022 +0900        more comment    commit 8f67fc87038834e9f7e2c5cd3dfe61fabf442206    Author: Masahiro Masuda <masahi129@gmail.com>    Date:   Mon May 16 17:11:27 2022 +0900        update test    commit ad85036621c005b733763e67ceffae39c356ec99    Author: Masahiro Masuda <masahi129@gmail.com>    Date:   Mon May 16 16:54:01 2022 +0900        add test    commit 4a5dc3ffd5d0bb4a1700e57897c9e0f26e3d2a88    Author: Masahiro Masuda <masahi129@gmail.com>    Date:   Mon May 16 16:40:47 2022 +0900        [TVMScript] Support function call to help construct ASTcommit 76c1bcf0ade45d7433a0066236add8372b1cc547Author: Masahiro Masuda <masahi129@gmail.com>Date:   Mon May 16 16:30:07 2022 +0900    simplify iterator in layout transformcommit 936280324ea2c91429a6a85a1b8ee89c7b825928Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 11:31:39 2022 +0900    remove obsolet filescommit 2e119b422d72d726d5f2bd20fe48a1e62fcb0510Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 10:43:59 2022 +0900    calculate mma store dst index using inverse affine mapcommit 9489434ee52b546e2abb2ab28173eefd51525ba4Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 10:01:12 2022 +0900    simplify storecommit 1adcb77b8bba8e5d91080fe6cbfc7add7f4365c2Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 09:43:40 2022 +0900    simplified fillcommit 7b13c736d23e0eac94137aa918101d788e60d4f3Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 09:22:17 2022 +0900    simplify intrin desc using index map functioncommit bcf212dda0f94c51f55c48921f61d92fd3b83777Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 07:16:42 2022 +0900    seems to workcommit dd8ccf9ec2e48100158152e5d4590d141424e2e2Author: Masahiro Masuda <masahi129@gmail.com>Date:   Sat May 14 07:11:57 2022 +0900    poking with the parsercommit 596582cbfbd08ebe23ea71aaf7a447472415ccd1Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 20:04:59 2022 +0900    16x8x32 4k trans workingcommit 273f89a8a6ac34f7c79147563922d34d44bffd08Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 19:52:13 2022 +0900    add 16x8x16 fp16 transcommit 8e2066cc4c6e86616bc9751324e63ba81a3b02afAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 19:32:37 2022 +0900    16x8x16 4k trans workingcommit c2d0744051733e94f840d4517bcee9ca5d444c75Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 19:25:52 2022 +0900    16x8x16 trans workingcommit c2e314cdda1c3a931781e51a863901ea178dffecAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 16:19:32 2022 +0900    tuned int8 4k, 91 TOPScommit 94d9d965f19ff1a2ebdd342079ef420fb537b16aAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 15:59:33 2022 +0900    int8 4k tune workingcommit 3ca8ca02593aff7540c9655aa831348246171752Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 08:43:57 2022 +0900    mma 16x8x32 int8 working with ldmatrix b workaroundcommit 54f1cb731d4b42a6cbc08baf144e74646400eef5Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 18:23:27 2022 +0900    wipcommit 9d2844db602dc65af4dbd06a73fdd815f486b8b9Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 16:38:53 2022 +0900    test tensorize without layout transformcommit 86ee6dabc801aeb8d6917bec6de97b42025dbdd1Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 15:15:34 2022 +0900    int8 4k tensorize workscommit 39f9e32c9a64222c91daba2c32969b27207a31d2Author: Masahiro Masuda <masahi129@gmail.com>Date:   Fri May 13 12:44:39 2022 +0900    begin int8 4k tunecommit 6fa91e55b5ab2ba0f901d0d35be1b2fb3ab092b0Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu May 12 18:53:20 2022 +0900    try fix ldmatrix b for int8commit 7a962cddc4799fa3df0c0fdf3c056146d3f2cbdfAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Thu May 12 18:28:34 2022 +0900    fixed warp_coeffcommit a0afb5698f307382147a38819e004a2db7f554b1Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu May 12 12:20:01 2022 +0900    wipcommit f70ccd09b07d5325454ffdc39a7619ea84aa7e06Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu May 12 12:09:57 2022 +0900    int8 tensorize workingcommit 20321fa4674dabc78fe55b5e0e2876c35b245d21Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu May 12 07:06:22 2022 +0900    starting 16x8x32 int8commit 441fd193c59cdc436d87ab35896cbb8c779ddf35Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu May 12 05:50:46 2022 +0900    adding fp16 accum casecommit c9d40b69b1b57bfaddffba09ea07624ae90ee465Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 17:04:29 2022 +0900    clean upcommit 5b2d48635e762c77c824d1c259ac8bcbcc949421Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 16:38:19 2022 +0900    16x8x16 4k tune workingcommit c3cb170d85600d03da5c3f4cda03552208ca0b8cAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 16:20:27 2022 +0900    tensoriz fixedcommit 68039b081efcdd6aea1d132940b3745f50164974Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 15:55:25 2022 +0900    begin 16x8x16 4k tunecommit ced5d8d980cc267d4735957c25cb60d71ae977d2Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 15:50:11 2022 +0900    16x8x16 workedcommit 3d2c90d77c1bb2df2193e9af6cbaa2bd927a26d8Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 15:47:26 2022 +0900    fixcommit 403050b03ad6b4f0ee8d45088ffb324727bbae48Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 15:45:10 2022 +0900    add 16x8x16 testcommit 18e8d73661c99cd1c83021063b41a457afcb1638Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 06:50:32 2022 +0900    fixed mma store codegen for 16x8x16commit ec81250561195705122bccb9a2372f71de68121fAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 04:25:25 2022 +0900    add 16x8x16 mma store codegencommit e08df2a62a4809bcd39782949283c16e7703aa5cAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 03:47:47 2022 +0900    tensorized C_warp initcommit ae0678918929c1ceec73f2039467040c5bb7823bAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed May 11 03:06:06 2022 +0900    mma store codegen workingcommit deb4d6646cc93d4cdb4f2560ce723bee4d86e144Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 10 19:22:57 2022 +0900    update lower warp memorycommit 71fe5fe465300705fa94f9544a2e1a5070de6e0dAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Tue May 10 09:01:42 2022 +0900    tensorizing mma storecommit e80a1f148c47f2a3fac2363a733d8d4e2a2631d0Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu Apr 28 19:54:08 2022 +0900    clean upcommit a9640f4b7c3c9f22b87ca74a61003438dfd8f992Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu Apr 28 19:40:55 2022 +0900    add tunable 4k test, 36 TFLOPScommit b9f7eae7041d1a9b3e434c331c874e8347e89dc4Author: Masahiro Masuda <masahi129@gmail.com>Date:   Thu Apr 28 18:01:08 2022 +0900    fixed bug in LowerWarpMemory index splitting for ldmatrixcommit 00df30823f874910ed1ec1f74718100311764234Author: Masahiro Masuda <masahi129@gmail.com>Date:   Wed Apr 27 07:58:17 2022 +0900    fixed missing reverse_compute_atcommit 93f9fe7e5f7ad16c8d0e6240c16c0281a0e97decAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed Apr 27 06:55:12 2022 +0900    add 4k testcommit 3689ef712aa4b282a4818fa2fa2e7e349c3a5eecAuthor: Masahiro Masuda <masahi129@gmail.com>Date:   Wed Apr 27 06:54:09 2022 +0900    temp disable high dim base indices check in tensorizecommit 0c859c4f385ba0b6f9477b569b80cee80b5b7282Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue Apr 26 19:18:23 2022 +0900    clean upcommit f6aadbfcfbd73c1667a6de7aedc5894232b8e750Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue Apr 26 19:13:09 2022 +0900    Add 16x8x8 MMA + LDMatrix testcommit 4cf6b20c6ca415e967ab58d80e4a77c701ad7255Author: Masahiro Masuda <masahi129@gmail.com>Date:   Tue Apr 26 18:04:17 2022 +0900    testing 16x8x8 ldmatrix tensoriation* set measure_perf to False* add requires_gpu decorator in tests, always test build on non-ampere* skip cuda compile on old gpu",3
[RELAY] Remove re-exports of tvm.transform (#5337),4
Convert Cloudformation Sample DAG to System Test (#24447),3
"[MetaSchedule] Add Testing Script with ONNX Support (#11587)This PR introduces 2 tuning script for meta schedule and auto scheduler tuning support with onnx files. Now we can easily introduce onnx models benchmarking with command line scripts. Sample tuning call looks similar to the following scriptFor Meta Schedule ONNX tuning:```python3 -m tvm.meta_schedule.testing.tune_onnx_meta_schedule \    --model-name   ""$MODEL_NAME""                             \    --onnx-path    ""$ONNX_PATH""                              \    --input-shape  ""$INPUT_SHAPE""                            \    --target       ""$TARGET""                                 \    --num-trials   $NUM_TRIALS                               \    --rpc-host     $RPC_HOST                                 \    --rpc-port     $RPC_PORT                                 \    --rpc-key      $RPC_KEY                                  \    --rpc-workers  $RPC_WORKERS                              \    --work-dir     $WORK_DIR                                 \    |& tee         ""$WORK_DIR/$MODEL_NAME.log""```For AutoScheduler ONNX tuning:```python3 -m tvm.meta_schedule.testing.tune_onnx_auto_scheduler \    --model-name   ""$MODEL_NAME""                              \    --onnx-path    ""$ONNX_PATH""                               \    --input-shape  ""$INPUT_SHAPE""                             \    --target       ""$TARGET""                                  \    --num-trials   $NUM_TRIALS                                \    --rpc-host     $RPC_HOST                                  \    --rpc-port     $RPC_PORT                                  \    --rpc-key      $RPC_KEY                                   \    --rpc-workers  $RPC_WORKERS                               \    --log-dir      $WORK_DIR                                  \    |& tee         ""$WORK_DIR/$MODEL_NAME.log""```",2
"[CI][DOCKER] Fix cuda11 nvidia-docker support for non-Tesla gpus (#8163)Starting cuda11, libcuda can be linked to a version of libcuda in/usr/local/cuda/compact. The particular linked librarydoes not work for non-Tesla GPUs, causing ""no CUDA capable devices found""even though nvidia-smi shows available GPUs.This PR makes makes sure we always prioritize linking/usr/lib/x86_64-linux-gnu/libcuda.so.1so the nvidia docker cuda11 images works for non-Tesla GPU envs.",1
"[CUDA] Initial support for dynamic shared memory (#8466)* send dyn shmem size to runtime* add dyn shared storage scope* associate buffer var and its storage scoe in split_host_device* tried NVPTX but failed with INVALID_PTX error* test stub* dynamic shmem reduce working* log2 issue fixed* nvptx working* refactor llvm shmem allocation* make linkage argument* support rocm too* send dyn shmem param to hip runtime* remove alloc map from split_host_device.cc* remove attr::storage_scope from split_host_device* lint fix* formatting* update calling convention doc* minor update to test* remove log* remove kDynShared, dyn.shared -> shared.dyn* support backward compat* update json/binary reader/writer* thread_axis_tags -> launch_param_tags* ThreadAxisConfig -> LaunchParamConfig* remove use_dynamic_shared_memory from FunctionInfo meta data* revert change in test_tir_ir_builder.py* make sure kUseDynamicSharedMemoryTag is the last tag* remove continue* update doc string following name change* more comment update following name changeCo-authored-by: masa <masa@pop-os.localdomain>Co-authored-by: Masahiro Masuda <masahi@129@gmail.com>",4
add tanh dispatch (#619),1
[TEST] Remove script that references previously removed content. (#2481),4
[Testing] Add model loader for int8 BERT (#10622)* add model loader for qat bert-base* add test* pylint* ignore mypy* Update python/tvm/meta_schedule/testing/tlcbench.pyCo-authored-by: Junru Shao <junrushao1994@gmail.com>* use a dedicated process for converting* return input info* encode batch size and seq_len information in cached file pathCo-authored-by: Junru Shao <junrushao1994@gmail.com>,2
Merge pull request #887 from airbnb/undead_suicideKilling tasks that aren't in a running state,1
[Arith] Inequalities solver (#5618),5
"Show serialization exceptions in DAG parsing log (#17277)Make sure that any exceptions that happen when writing serialized DAGsto the db get written to the DAG parsing log, instead of only being addedto `import_errors` for consumption via the UI.",2
"Add Range op to ONNX, make tvm arange op support negative steps (#6647)",1
[AIRFLOW-1291] Update NOTICE and LICENSE files to match ASF requirementsJIRA:https://issues.apache.org/jira/browse/AIRFLOW-1291* Update NOTICE with proper year range for ASFcopyright* Break down LICENSE intolicenses/LICENSE-[project].txt* add license header to jqClock.min.js[AIRFLOW-1291] Update NOTICE and LICENSE files tomatch ASF requirements* Update NOTICE with proper year range for ASFcopyright* Break down LICENSE intolicenses/LICENSE-[project].txt* add license header to jqClock.min.jsfix license checkCloses #2354 frommistercrunch/copyright_license_touchups,0
Add colors to compute_at edges and thread/block indices. (#5111),1
"Replace generation of docker volumes to be done from python (#23985)The pre-commit to generate docker volumes in docker composefile is now written in Python and it also uses the newer ""volume:""syntax to define the volumes mounted in the docker-compose.",2
Require atleast 1 approving reviews for PRs (#12020)Looks like we can control this setting via .asf.yaml : https://cwiki.apache.org/confluence/display/INFRA/git+-+.asf.yaml+features#git.asf.yamlfeatures-BranchProtection,5
[AIRFLOW-942] Add mytaxi to Airflow usersCloses #2111 from terezaif/patch-1,1
[AIRFLOW] Force PGPORT env. var to be a string (#7773)Because subprocess.Popen loops through all the env vars and crashes if a value of an env var is not a string.,1
[Fix][TOPI] remove wrong fix in x86's dense_nopack operator (#8687),1
Implement expand_kwargs() against a literal list (#25925),2
"[ci] Add GitHub Actions bot to merge PRs on demand (#10833)This implements https://discuss.tvm.apache.org/t/rfc-allow-merging-via-pr-comments/12220. The bot can be invoked from a top-level review comment or via a regular PR comment. The text `@tvm-bot merge` anywhere in the body will trigger the bot. Right now it checks that the latest commit is reviewed and that all CI jobs that have run on that commit are successful. If it fails, it will leave a comment on the PR with the reason.This is just a start and some features are left for followups:* Various TODOs throughout the code* ""Scheduled"" merges that happen once CI finishes* Allowing committers to merge without getting a fresh review for changes after an approval",4
"Revert ""fix cuda half math function is undefined: hpow, htanh (#6225)"" (#6249)This reverts commit ed04cdd35f1990959ec788be0131b1388fd11d31.",4
Override project in dataprocSubmitJobOperator (#14981),5
"[Topi,x86] Split MKL from BLAS. (#6182)Make cblas and mkl seperate entities in cmake and topi, allowing usersto use both a BLAS library and MKL. In the future, MKL specificfunctions can be added easily. MKLDNN is also split off from MKL andBLAS for the same reasons.Other improvements:  - cblas and mkl strategies are now only applied when they are viable.  - compile_engine will log which implementation it has chosen and why.",2
"[Relay] Add RecoverVirtualDeviceMap helper (#12085)* [Relay] Add RecoverVirtualDeviceMap helperDevice planning is halfway through the transition to using the virtual_device_field on every expression node to capture device/target/etc info. In the meantimeit is necessary to derive from a 'device aware' visitor so as to track deviceinformation. In Collage this is not feasible, so as a stop gap allow the mapfrom expression nodes to virtual devices to be reconstructed as a stand alonemap.This code can be removed once expr->virtual_device() is the canonical representation.* - review comments",4
"[PROFILER] Theoretical roofline models (#11066)`tvm.analysis.roofline_analysis` adds estimated roofline performance to aprofiling report. The roofline model measures how close an operator getsto best possible memory bandwidth or FLOP/s depending on whether it ismemory or compute bound. This computation uses the runtime of theoperator along with two numbers extracted from the TIR code: bytes ofmemory touched and number of floating point operations. Because thesenumbers are extracted from TIR, they may not be 100% accurate. The bestpossible memory bandwidth and FLOP/s are measured by running smallprograms that are memory and compute bound respectively.For now, this function only works with llvm cpu targets, but it shouldbe possible to extend to GPU targets.",1
"Fix order of returned rows in a flaky test_outlets_dataset test (#25231)In Postgres especially (but in generaly in all databases, ifthere is no order specified in select query, the rows mightcome in random order. It depends on many factors.The test query here retrieved the dags without any order butexpected the list to be in specific order.This PR adds ordering - it also removes side-effects of thetest by using fixture that clears the datasets before and afterthe tests that rely/modify datasets - because othrwise failure ofone of the tests can create side effects that fail the othertests (this is what happened in this case)",3
"Adds Pendulum 1.x -> 2.x upgrade documentation (#18955)closes: #18634Adds documentation about the upgrade from Pendulum `1.x` to `2.x` as discussed in the issue.  Assumptions that were made:- Most of the Pendulum changes are already documented in the official Pendulum docs.Added the following: - Mention the upgrade from `1.x` to `2.x`- Added an example of a code snippet that will now throw errors- Added link to official pendulum `2.x` docs that discuss the changes from `1.x` to `2.x`The macros documentation as mentioned in the issue were actually pointing to the updated Pendulum documentation, so no changes were added for the same. For instance, consider the link for the macro [prev_execution_date](https://pendulum.eustace.io/docs/#introduction)",5
Fixes failure of the build scripts when remote repo does not exist (#9188),0
[AIRFLOW-1335] Use MemoryHandler for buffered loggingCloses #2386 from saguziel/aguziel-buffer-logger-apache,2
Fix typo in TaskGroup docstrings (#13475)`prerfix_group_id` -> `prefix_group_id`,0
[AIRFLOW-3332] Add method to allow inserting rows into BQ table (#4179),1
"[AIRFLOW-3104] Add .airflowignore info into doc (#3939).airflowignore is a nice feature, but it was not mentioned at all in the documentation.",2
[AIRFLOW-6062] Executor would only delete workers in its own namespace (#7123)* [AIRFLOW-6062] Executor would only delete pods in its own namespace* add tests* clean up PR* static tests* Update airflow/executors/kubernetes_executor.pyCo-Authored-By: Kaxil Naik <kaxilnaik@gmail.com>* Update airflow/executors/kubernetes_executor.pyCo-Authored-By: Kaxil Naik <kaxilnaik@gmail.com>* Update airflow/executors/kubernetes_executor.pyCo-authored-by: Kaxil Naik <kaxilnaik@gmail.com>,5
Update TVM ci-cpu docker image to v.079 (#9454)* Requested in #9296 * Validated at   https://ci.tlcpack.ai/blue/organizations/jenkins/tvm/detail/ci-docker-staging/169/pipeline/,2
Update node installation cmd (#10744),5
Fix airflow version in migration 587bdf053233 (#22935),0
[AIRFLOW-6379][depends on AIRFLOW-6377] Simplify `airflow task run` logic (#6936)* [AIRFLOW-6377] Decouple cli utils from argparse.Namespace,2
Fix mismatch between docs and Azure Data Factory Hook (#19442),1
"[AIRFLOW-737] Fix HDFS Sensor directory.Due to a bad ordering in the fake snakebiteclient, one test was wrongly True.Closes #1989 fromvfoucault/fixbug/hdfssensor_folder",0
Add operator link to access DAG triggered by TriggerDagRunOperator (#11254)This commit adds TriggerDagRunLink which allows users to accesseasily access in Web UI a DAG triggered by TriggerDagRunOperator,2
Add default `conf` parameter to Spark JDBC Hook (#8787),1
[AIRFLOW-832] Let debug server run without SSLCloses #2051 from gsakkis/fix-debug-server,0
Update INTHEWILD.md (#17832)Add Tapsi to the list of Airflow users,1
Add confirming getopt and gstat #14750 (#14751),1
Use getfqdn to make sure urls are fully qualifiedgethostname only resolves host part while often fully qualified domain names are required.* Resolves #1437,0
Support unknown backends in entrypoint_prod.sh (#22883),1
More user-friendly message on incorrect configuration (#9436)* More user-friendly message on incorrent configuration* Update tests/test_configuration.py* Update tests/test_configuration.py,5
es new system tests (#22811),3
[Relay][Op] Add operators full and full_like (#1845),1
correct conv2d workload for resnet18 (#750),1
"Support remote logging in elasticsearch with filebeat 7 (#14625)Filebeat 7 renamed some fields (offset->log.offset and host->host.name),so allow the field names Airflow uses to be configured.Airflow isn't directly involved with getting the logs _to_elasticsearch, so we should allow easy configuration to accomodatewhatever tools are used in that process.",1
Unnecessary use of list comprehension (#10416)It is better to use list constructor which is faster and more readable,1
Fix python version command (#23818),0
[Relay][Frontend][TFlite] Add parses support for UNPACK tflite operator (#4447)* use SPLIT & SQUEEZE = UNPACK as implemented in tensorflow parser  Relay doesn't support UNPACK* tflite 1.13: UNPACK doesn't work as exepcted -> copies the values from  1st unpacked tensor to the other unpacks* tflite 1.13: doesn't accept negative axis,1
[AIRFLOW-2503] Fix broken links in CONTRIBUTING.md- Fix broken links in `CONTRIBUTING.md`Closes #3397 from kaxil/AIRFLOW-2503,2
"[Relay, TOPI] Refactor Adaptive pool and add 3d support (#5049)* add stub for nd impl* refactored indices compute* refactored divide step* remove unused variables, add doc* fix lint* add relay op def* add python registration* refactor topi test* update relay tests, but test result is weird* workaround for weird bug* add relay adaptive pool 3d test* add topi tests* update doc for 3d* typo fix* fix lint* add more tests including NDHWC",3
"[AIRFLOW-2247] Fix RedshiftToS3Transfer not to fail with ValueErrorRedshiftToS3Transfer callsS3Hook.get_credentials() and triesto take the return value as a tuple with twoelements but fails.This is because the return value isReadOnlyCredentials, whichshould be handled as a single object or a tuplewith tree elements.This PR fixes the above problem.Closes #3158 from sekikn/AIRFLOW-2247",0
"Update to Pytest 6.0 (#14065)And pytest 6 removed a class that the rerunfailures plugin was using, sowe have to upgrade that too.",1
"Make ``BaseSerialization.serialize`` ""public"" to other classes. (#26142)It is still not designed for use by DAG authors, but this says ""itsokay to use elsewhere in Airflow""",1
[AIRFLOW-6896] AzureCosmosDBHook: Move DB call out of __init__ (#7520)* [AIRFLOW-6896] AzureCosmosDBHook: Move DB call out of __init__* Fix tests* fixup* Fix test,3
[Fix] Fix recursive let for well formed check (#5780),0
"Introduction tutorial formatting fixes (#9539)* Introduction tutorial formatting fixesThis fixes some rST issues I noticed while going through the getting started tutorial. Some of these shouldn't be too controversial like using ` instead of `` and consistency fixes. I noticed lots of the `.. note:`s have titles even though they don't really render as anything special in Sphinx, but the base `.. admonition:` does render the title in the top line. This looks nicer IMO and wastes less space but it could go either way, I didn't change it in all places yet either.* Convert the rest of the tutorial `.. note::` directives to `.. admonition::`* Fix compilation for matmul tutorial + some random formatting fixes* Fix ambiguous links and remove namespaceCo-authored-by: driazati <driazati@users.noreply.github.com>",1
Add CUDA conv2d for NHWC layout (#4737),1
[VTA] add doc to tsim-example driver and update verilator env variable (#3302)* add documentation and check for extension* add env variable for verilator include* fix typo* this will test if path exist otherwise it won't buid* check if verilator path and binary is set properly* add ?* remove export* no longer needed,4
Prepare for Python 3.10 adding (#22075)We need to merge this change to `main` first before weenable Python 3.10 in order to make sure our build-imageworkflow is ready to build 3.10 images.,1
"[microTVM][RVM] Always destroy the VM if all tests pass (#8739)Currently base-box-tool 'test' command will skip destroying the test VMif a single provider is specified (i.e. --provider virtualbox) even ifall tests pass. This is confusing (no warning is displayed to the user)and that will leave host resources (like USB devices necessary to runthe test) locked by the VM. So if the user tries to run a program thatuses the locked resource (e.g. openocd) cryptic failures might happen.Moreoever, even if all tests pass and more than one provider isspecified but the option '--skip-build' is set a VM will be left runningwithout notice.This commit changes that behavior by:1. Always destroying the VM if the release test pass2. Always keeping the VM up and running if a test fails1. guarantees no resource remains locked by the VM without necessity. Anew flag '--skip-destroy' is introduced in case the user still wants tokeep a VM up and running if the release tests pass. 2. guarantees the VMwhere the test failed is left running for further inspection of the testthat failed.Finally, for both 1. and 2. cases a proper message is displayed to theuser to inform if a VM was left running or not and about what actionsthe user can take next accordingly to the test result in the VM.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>",3
[GCC] Fix GCC8.1 and GCC8.2 template dispatch compilation issue (#6893)* update* [GCC] Fix GCC8.1 and GCC8.2 template dispatch compilation issue,0
[PYTHON] Add buffer name when creating tensor bindings (#5670),1
Update ethos-u-vela for demo app (#10129)Update from ethos-u-vela 2.1.1 -> 3.2.0,5
Fix issue rendering k8s V1Pod (#11952)* Fix issue rendering k8s V1PodAdds return statement for json serialization of k8s.V1Pod thatpreviously caused errors in UI* fix task_instances,0
[AIRFLOW-1437] Modify BigQueryTableDeleteOperatorBigQueryTableDeleteOperator should define deletion_dataset_tableas a template field.Closes #2459 from yu-iskw/bq-delete,4
Extract TaskLogReader from views.py (#9391)Co-authored-by: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>,1
Provide data for ci tests,3
[Hexagon][Docker] Update image version (#11332),5
Minor improve to assertion (#3295),3
Merge pull request #1025 from d-lee/masterAdd notes on connection password encryption,4
[MetaSchedule] Refactor testing workloads (#10497),1
Fixing the magnifying glass icon pointing to the wrong place,0
Improving json encoding,5
Skip mapping against mapped ti if it returns None (#25047),2
Quit and clean when TVM is interrupted (#3640),4
GoogleApiToS3Operator: update sample dag and doc (#22507),2
Support quantized NEG operator in TFLite frontend (#9404),1
[VTA][Dockerfile] Chisel dependencies for TSIM CI (#3721),2
Fix some Changelog entries (#19604)Some changelog entries were not formatted correctly,4
[AIRFLOW-XXXX] Add Changelog & Updating.md section for 1.10.9 (#7385),5
"[TIR] Utility function to decide loop mapping for auto tensorization (#11050)* [TIR] Add TensorizeInfo and GetTensorizeLoopMapping* expose PreOrderVisit to python* add test case* add conv2d nchwc test* add mma test* add arm nhwc conv2d test* Revert ""add arm nhwc conv2d test""This reverts commit eb147f33bb02d62a0eacc9cdfe777ac047ee1bc9.* refine* add doc* update* fixd condition* black* pylint* Update python/tvm/tir/schedule/analysis.pyCo-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>* run black* bring back logic in original code to support loop permutation* add comment* simplify* minor fix to testCo-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>",1
Correct typo (#20345),2
"[AIRFLOW-1779] Add keepalive packets to ssh hookMake use of paramiko's set_keepalive method tosend keepalive packets everykeepalive_interval seconds.  This will preventlong running queries with no terminaloutput from being termanated as idle, for exampleby an intermediate NAT.Set on by default with a 30 second interval.Closes #2749 from RJKeevil/add-sshhook-keepalive",1
[AIRFLOW-4037] Log response in SimpleHttpOperator even if the response check fails,0
[TIR][UX] allow override when register TensorIntrin (#12439)* allow override when register TensorIntrin* lint,1
add favicon in rtd (#3379),1
"Replace Stale Bot with Stale Github Action (#14494)Looks like Stable Bot is not working anymore for us, so let's replace it with Github Action that runs everyday at 00:00",1
add version life cycle table (#15936)* add version life cycle table* add to airflow docs* fixes,0
"[TOPI, x86] Properly handle fused ops in TE softmax schedule   (#12015)* fix x86 softmax fusion* properly handle the case where softmax and fuseed op having different layout* add test",3
[AIRFLOW-5918][part of AIRFLOW-5893] Group tests for the Pools command (#6567),3
"modify datastore hook so that authorization is maintained for the lifetime of the hook, rather than re-authorizing for each request.",1
Add Airflow 2.0.0 to requirements table (#13140),1
[AIRFLOW-5843] Add conf option to Add DAG Run view (#7281),1
Update kerberos_login with new cfg locations and move some logic,2
Unify flag name for long running tests (#8045),3
"Add new lint check to now allow realtive imports (#10825)Relative and absolute imports are functionally equivalent, the onlypratical difference is that relative is shorter.But it is also less obvious what exactly is imported, and harder to findsuch imports with simple tools (such as grep).Thus we have decided that Airflow house style is to use absolute importsonly",2
Better error message for untemplatable types,0
"Stop Log Spamming when `[core] lazy_load_plugins` is False (#13578)* Stop Log Spamming when `[core] lazy_load_plugins` is FalseCurrently when `[core] lazy_load_plugins` is False, it spams logs with the following line:```Loading 1 plugin(s) took 0.79 seconds```Example```root@a20fe6919413:/usr/local/airflow# pythonPython 3.7.9 (default, Dec 11 2020, 14:53:17)[GCC 8.3.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> from airflow import version[2021-01-08 20:20:51,730] {plugins_manager.py:286} INFO - Loading 1 plugin(s) took 0.79 seconds```",5
"[Runtime][ThreadPool] Handle the default value of affinity mode. (#10434)* [Runtime][ThreadPool] Handle the default value of affinity mode and acorner case of function 'SetMaxConcurrency'. 1. Handle the default value of affinity mode. 2. After calling the function 'SetMaxConcurrency' with a non-zero value,    if calling the function 'SetMaxConcurrency' again with a zero value ,    then the second setting can not correctly set the max_concurrency value    into zero.    use new logic to fix this issue.* address review comments.* polish the warning message.",2
Chart: configurable number of retention days for log groomers (#17764),2
[AIRFLOW-XXX] Typo fixCloses #3474 from prabeesh/patch-1,0
Merge pull request #143 from airbnb/fix_prefix_sensorfixing copypasta issue with prefix sensor + docs,2
fix style of example block (#24078),0
[NNVM][Keras] allow only tensorflow backend (#1392),1
[NNVM] Move FTVMCompute registration of the elementwise operator to c++ (#1351),1
[RUNTIME] Fault tolerant vulkan init error (#1107),0
[AIRFLOW-7041] make bowler dependency local (#7691),1
[AIRFLOW-6800] Close file object after parsing ssh config (#7415),5
Merge pull request #1090 from msumit/qbol_templateAdding template support in qbol operator,1
Bring MappedOperator members in sync with BaseOperator (#24034),1
[FRONTEND][TENSORFLOW] support multiply outputs (#4980)* [FRONTEND][TENSORFLOW] support multiply outputs* [TENSORFLOW][TEST] add tf_testing.AddShapesToGraphDef test* update frontend test* retrigger CI,3
Fix Kubernetes Executor logs for long dag names (#10942)See #10292,2
Adding doc reference to Celery broker setup doc in installation instructino,2
Remove old option - git_password from sensitive_config_values (#12821),5
[TVM] Fixed SPIR-V codegen for OpControlBarrier (#1409),0
[CONTRIB] cuBLAS integration (#744)* add cublas support* integrate cublas to topi dense* add cublas error check* minor fix* fix lint* remove topi import from contrib unittest,3
[AIRFLOW-6971] Fix return type in CloudSpeechToTextRecognizeSpeechOperator (#7607),1
[RUNTIME][OPENCL] set type_key even when platform is not available (#2741),1
Add prim::device op (#5584),1
Improvements for `SnowflakeHook.get_sqlalchemy_engine`  (#20509),1
add FTPHook,1
"Remove certifi limitations from eager upgrade limits (#23995)The certifi limitation was introduced to keep snowflake happy whileperforming eager upgrade because it added limits on certifi. Howeverseems like it is not limitation any more in latest versions ofsnowflake python connector, so we can safely remove it from here.The only remaining limit is dill but this one still holds.",5
Run KubernetesPodOperator tests on any executor (#19810)Previously these tests were restricted to run only on KubernetesExecutor. But there is no reasonwe cannot run them on other executors.,1
[DOCS] Update to reflect the repo name change (#6967),4
Import ABC from collections.abc (#9649),2
[AIRFLOW-5499] Move GCP utils to core (#6122),4
[CI] Fix the hexagon string (#5304),0
Remove redundant character escape from regex (#15740),4
[TOPI] add dilation operators (#316)* add dilation operators* fix pylint* dilate testcases success* n-D tensor dilation* support arbitrary dimension,1
Stripe uses Airflow,1
ROCm: Add SaveToFile and LoadFile (#3665)...and add rocm module_save to the tests.,3
Fixes some of the flaky tests in test_scheduler_job (#14792)The Parallel tests from #14531 created a good opportunity toreproduce some of the race conditions that cause some of thescheduler job test to be flaky.This change is an attempt to fix three of the flaky teststhere by removing side effects between tests. The previousimplementation did not take into account that scheduler jobprocesses might still be running when the test finishes andthe tests could have unintended side effects - especiallywhen they were run on a busy machine.This PR adds mechanism that stops all runningschedulerJob processes in tearDown before cleaningthe database.Fixes: #14778Fixes: #14773Fixes: #14772Fixes: #14771Fixes: #11571Fixes: #12861Fixes: #11676Fixes: #11454Fixes: #11442Fixes: #11441,0
Allow templates in more DataprocUpdateClusterOperator fields (#21865),5
Merge pull request #464 from jlowin/fix_tree_roundingconsolidate base_date rounding in tree view,5
[AIRFLOW-895] Address Apache release incompliancies* Fixes missing licenses in NOTICE* Corrects license header* Removes HighCharts left overs.Closes #2098 from bolkedebruin/AIRFLOW-895,2
Add option to propagate tags in ECSOperator (#8811)Co-authored-by: Joao Ponte <jpe@plista.com>,1
BugFix: Editing a DAG run or Task Instance on UI causes an Error (#12770)closes https://github.com/apache/airflow/issues/12489,0
Add link on External Task Sensor to navigate to target dag (#11481)Co-authored-by: Kaz Ukigai <kukigai@apple.com>,2
Use a bare raise so the original exception gets propagated.,1
[TOPI] add take (#1158),1
"[AIRFLOW-2034] Fix mixup between %s and {} when using str.formatConvention is to use .format for string formating oustide logging, else use lazy formatSee comment in related issuehttps://github.com/apache/incubator-airflow/pull/2823/filesIdentified problematic case using following command line.git/COMMIT_EDITMSG:`grep -r '%s'./* | grep '\.format('`Closes #2976 from knil-sama/fix-mixup-format-str",0
"Remove Shebang in docker scripts (#21224)Now that all the scripts in docker build are using direct bashcalling, shebang on those scripts is not needed (and harmful).Some of the IDEs and pre-commits will insist on making the filesas executable (which just happened in one of the previous commits)and this - depending on the system umask setting - might add theexecutable bit set for the owner and for group or just the owner.Removing both - executable bit and shebang will make sure therewill be no temptation to add the executable bit (thus the executablebit will not trigger cache invalidation)",5
[AIRFLOW-XXX] Fix typo in README (#5008),2
RBAC ui: fix missing task runs being rendered as circles instead of squares (#8253),1
add a few gradients (#5899),1
Add MXNet converter for RNN layer ops (#3125),1
[AIRFLOW-1794] Remove uses of Exception.message for Python 3Closes #2766 from dhuang/AIRFLOW-1794,1
doc: fixed docstring for sql param in Neo4jOperator (#17407),1
Fix docs build on RTD (#12161),2
"Chart: Adds support for custom command and args (#16153)Some images may not want to use the same command/args as the communityimage, so expose them as parameters.",2
Fix the errors raised when None is passed to template filters (#25593),4
"[microTVM] Update Zephyr 2.5 (#7786)* update to zephyr 2.5* unbreak test_zephyr* fix stack size* always create packer.log* add qemu debugging* fix transport with debug false* size down ring buf, shouldn't need to be so large* update to zephyr 2.5* fix buffer size* cleanup* cleanup* remove debugger* nit* update ci script* remove debug mode* fix packer log* comment* update ci_qemu* change zephyr version on Vagrant* make it compatible to zephyr 2.4Co-authored-by: Andrew Reusch <areusch@octoml.ai>",5
"Add more complete instruction for reproducing failed integration tests (#19646)When integration tests are failing, breeze prints the exactreproduction step to recreate the same environment. However whenintegration tests were enabled it missed the --integrationflags that were necessary to enable the integrations.This PR adds the --integration flags to the instructions and alsoadds the comment that Kerberos integration currently does not workwith docker-compose v2.",2
Fix names + typos and load_file args,2
Migrate Jenkins example DAGs to new design #22451 (#24138),1
Update docstrings to adhere to sphinx standards (#14918),2
[Relay][AlterOp] Minor refactor. (#4064),4
Add Azure Blob Storage to GCS transfer operator (#11321),1
fix typo (#56),2
"dilation fixed for (1, 1) case (#477)",0
[Relay] Add support of conv2d with NHWC for Bifrost (#8430)Reuse generic Mali strategy for conv2d with NHWC inBifrost target.,1
"Add Hexagon VTCM and discontiguous allocation support (#9525)* WIP Allocation abstraction for VTCM and DDR.* Add Hexagon VTCM and discontiguous allocation support* differentiate between dimensions and allocations* remove change to llvm codegen* add integration test_add_vtcm to demo vtcm alloc* remove cmake change* forcing contiguous allocation in device API, for nowCo-authored-by: Chris Sullivan <csullivan@octoml.ai>",5
fixed rocm runtime. set default gcn arch to be gfx803 (#544),1
Merge pull request #449 from airbnb/fix_joinFixing SKIPPED from propagating when it shouldn't,5
"Refactor, refactor code structure, fix pynq rpc (#29)",0
"Adding `only_active` parameter to /dags endpoint (#14306)I noticed that the `/dags` endpoint returns information on all entries in the DAG table, which is often many more DAGs than are activeand likely includes DAGs which have been removed from Airflow. This PR adds a boolean `only_active` parameter to the `/dags` endpoint which will then only return active DAGs. I also noticed that this endpoint was hitting a deprecated codepath by dumping a `DAG` object to the DAGDetailSchema, thus hitting calling `DAG.is_paused()` I have updated the schema to call the correct function (`DAG.get_is_paused`) since I'm assuming the deprecated functions may be removed some day.",4
"[VTA] Infinite recursive device_api.ext_dev call fix (#7985)#3843 fixed the infinite recursive call for the Xilinx boards, but didn't fix it for the intel boards. This fixes it for the DE10 (same missing symbol problem with same fix).",0
add dilation in x86 NCHWc depthwise conv support (#4962) (#6267),1
update compiler version in docs (#5281),2
Fix hidden tooltip position (#19261)Only apply a large z-index when the tooltip is supposed to be display.,0
"[AIRFLOW-329] Update Dag Overview Page with Better Status ColumnsRenamed 'Recent Statuses' to 'Recent Tasks'.Created 'DAG Stats' column. Created a cache tabledag_stats to hold data for 'DAG Stats' column withdirty bit for each row. Upon dagrun creation,state change, or deletion via web UI, appropriaterows will have dirty set to true and then dirtyrows will be refreshed with up to date data. Uponexecution of `airflow upgradedb` command, ifdag_stat is empty then it will be populated fromdag_run data.API endpoints in views.py have also been changed.'/dag_stats' has been renamed to '/task_stats',and endpoint reused for the 'DAG Stats' column.Dear Airflow Maintainers,Please accept this PR that addresses the followingissues:-https://issues.apache.org/jira/browse/AIRFLOW-329Testing Done:- Added a unit test to core tests, tests thatdag_stats table is appropriately updated afterdagrun creation and state change-Added sanity check for '/dag_stats' and'/task_stats' API endpointsRenamed 'Recent Statuses' to 'Recent Tasks'.Created 'DAG Stats' column. Created a cache tabledag_stats to hold data for 'DAG Stats' column withdirty bit for each row. Upon dagrun creation,state change, or deletion via web UI, appropriaterows will have dirty set to true and then dirtyrows will be refreshed with up to date data. Uponexecution of `airflow webserver` command, all rowsin dag_stat will be dirtied and cleaned.API endpoints in views.py have also been changed.'/dag_stats' has been renamed to '/task_stats',and endpoint reused for the 'DAG Stats' column.Closes #1730 from normster/dagstat",2
"[FIX] Fix depthwise conv2d on non-cuda GPU platforms (#8379)The depthwise_conv2d schedule had a bad check to make sure the iterationaxis was not larger than max_num_threads. Now the iteration axis isbounded by its size or max_num_threads, whichever is smaller.",1
Replace deprecated postgresql chart location with bitnami/postgresql (#13928),2
Merge pull request #1108 from kretes/patch-1new company + link to pitfalls,2
[AIRFLOW-5294] Make GCP MLEngine pylint compatible (#5892)This commit make MLEngine operators and tests pylint compatible,3
Fix documentation errors in apache-airflow/lineage.rst (#21158),0
Fixes detection of version 2 of docker-compose (#17062)Docker compose 2 added `v` in front of the version :(,1
Check if job object is None before calling .is_alive() (#19380)Co-authored-by: Jonathan Fernandes <jfernandes@virtela.net>,5
Store inventories in GitHub Action cache (#15109)fixes #14989.,0
[AIRFLOW-785] Don't import CgroupTaskRunner at global scopecgroups is not a required dependency,1
Expose flower and redis ports in breeze (#11624),5
"[AIRFLOW-385] Add symlink to latest scheduler log directoryCreate a symbolic link to the directory contaningthe latest scheduler logs, and update the linkwhen the target changes.Update the test_scheduler_job test case to verifythat the symbolic link is created.Implementation:- Create a symbolic link to the directorycontaining the latest scheduler logs, and updatethe link when the target changes.Testing Done:- Extend test_scheduler_job test case to verifythat the correct symbolic link is created.Closes #1842 from vijaysbhat/latest-log-symlink",5
"Switches to ghcr.io container registry (#16775)After fixing permission problems, we can now switch to ghcr.io",0
"[AIRFLOW-729] Add Google Cloud Dataproc cluster creation operatorThe operator checks if there is already a clusterrunning with the provided name in the providedproject.If so, the operator finishes successfully.Otherwise, the operator issues a rest API call toinitiatethe cluster creation and waits until the creationis successful before exiting.Closes #1971 frombodschut/feature/dataproc_operator",5
"Add support for modifying celery worker deployment strategy (#15213)This commit modifies the worker template to allow passing a non-default deployment update strategy to worker deployments, in particular celery workers. The values have been set to allow 100% maxSurge and 50% maxUnavailable allowing new deployments of celery workers to launch a full set of replicas before the old set goes away. Allowing the new workers to pick up work as quickly as possible, rather than the current default which is 1 at a time.`maxSurge` is the number of pods that will be scheduled beyond the replica count during a rolling deploy. You can specify specific values or percentages. For example if you set the `maxSurge` to 100% and had 4 replicas, when a rolling deployment started it would launch 4 new pods and then scale down the old ones as the new ones came online.",1
"Remove  redundant ``numpy`` dependency (#17594)Missed removing ``numpy`` from `setup.cfg` in https://github.com/apache/airflow/pull/17575. It was only added in setup.cfg in https://github.com/apache/airflow/pull/15209/files#diff-380c6a8ebbbce17d55d50ef17d3cf906numpy already has `python_requires` metadata: https://github.com/numpy/numpy/blob/v1.20.3/setup.py#L473so we don't need to set `numpy<1.20;python_version<""3.7""`",1
[TOPI] Update tophub according to the fix in schedule (opencl and rocm) (#3752),0
[BUGFIX] Fix CRT static test bug (#5293)* [CI][DOCS] Make sure to refresh the cython part* [BUGFIX] Fix CRT static test bug* Fix demo_static* resolve review comment,0
add missing spaces,1
[TVM] ref_counter -> ref_counter_ (#5184),5
Add WorldRemit as Airflow user (#8786),1
Merge pull request #153 from airbnb/hivesensor_templateFixing minor templating issue in HivePartitionSensor,0
"[ARITH][IR] Introduce FloorDiv/Mod (#3479)* [ARITH][IR] Introduce FloorDiv/Mod* Address review comments* address review comments, fix div sub rule",0
[AIRFLOW-1438] Change batch size per query in schedulerThis should help if query size is limited. It alsoreduces how longlocks are held.Closes #2462 from saguziel/aguziel-paginate-query,4
[TARGET] Move target_host usage to new target style. (#9497)- Add deprecation warnings to functions with target_host parameters.- Update the build usage to new target style.,1
"Use our yaml util in all providers (#24720)Our yaml util, which uses libyaml where possible, has been available incore since 2.0.2. Providers now require 2.2.0+, so we can safely use itnow.",1
"[TIR][REFACTOR] Migrate low-level passes in tvm.lower to the Unified IR pass manager. (#5364)- Migrate BoundCheckers and Simplify- Migrate RewriteUnsafeSelect and RemoveNoOp- Migrate UnrollLoop and StorageRewrite- Migrate InjectDoubleBuffer and InjectVirtualThread- Migrate LoopPartition and Vectorize- Migrate CoProcSync, LiftAttrScope, InjectCopyIntrinWe still keep ir_pass registerations for now.Need a separate PR to refactor the parts before the StorageFlatten.",4
[TIR] For-kind inheritance in decompose-reduction (#9814),5
[AIRFLOW-2826] Add GoogleCloudKMSHook (#3677)Adds a hook enabling encryption and decryption through Google Cloud KMS.This should also contribute to AIRFLOW-2062.,0
Fix broken docs build (#11900),2
[AIRFLOW-3938] QuboleOperator Fixes and Support for SqlCommand (#4832),1
[AIRFLOW-5572] Clear task reschedules when clearing task instances (#6217),2
Update example dataset DAGs names (#25910)* Update example dataset DAGs namesThe terminology upstream/downstream in datasets was previously renamedto produces/consumes.,5
Standardize the `pre-commit` config (#22686)Minor sorting of files/folder/terms,2
[build][hexagon] fix several compiler warnings (#11245),2
"[DLL] Use local dll, not de-allocate function in shutdown",1
Improve documentation and examples in example_asana.py (#15959),2
Default to 0 if no rows loaded in GCS to BQ operator.,1
[AIRFLOW-6837] Limit description length of a Dag on HomePage (#7457),2
"[MetaSchedule][M4a] User-API: Tune-TE/TIR/Relay (#10079)* Add tuning scripts for tir, te & relay.Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>Minor fix.Nits.Add back tests.* slightly improve tune.pyCo-authored-by: Junru Shao <junrushao1994@gmail.com>",1
Merge pull request #221 from mistercrunch/artwr/s3_fuzzy_key_matchingAdding wildcard matching for S3 hook and operators,1
Stronger type checker during conversion,5
Parameterize test_link_params. (#9276),3
"Get rid of Airflow 1.10 in Breeze (#15712)Gets rid of Airflow 1.10 in Breeze and script/configuration.We were still using occasionally the master version of Breeze torun 1.10 version of Airflow, but this madness should end now whenwe are approaching 2.1 release. All changes in Breeze were so farported to 1.10 but this is about the time to finish it.",5
[AIRFLOW-570] Pass root to date form on ganttCloses #1837 from forklady42/gantt-root,5
Doc clarifications around start_date,5
fix bug when converting constant nodes with types of int64 or float64 (#6159)Co-authored-by: yuweilong <yuweilong03@meituan.com>,0
[AIRFLOW-4113] Unpin boto3 (#6884),5
Added LLVM TargetIRAnalysis pass (#2386),4
[AIRFLOW-3516] Support to create k8 worker pods in batches (#4434),1
"Fix dag.clear() to set multiple dags to running when necessary (#15382)closes: #14260related: #9824When clearing task across dags using ExternalTaskMarker the dag state of the external DagRun is not set to active. So cleared tasks in the external dag will not automatically start if the DagRun is a Failed or Succeeded state.#9824 tried to fix a similar issue for subdag. But it did not fix ExternalTaskMarker. This PR fixes both.Two changes are made to fix the issue:Make clear_task_instances set DagRuns' state to dag_run_state for all the affected DagRuns.The filter for DagRun in clear_task_instances is fixed too. Previously, it made an assumption that execution_dates for all the dag_ids are the same, which is not always correct.test_external_task_marker_clear_activate is added to make sure the fix does the right thing.",0
[AIRFLOW-5727] SqoopHook: Build --connect parameter only if port/schema are defined (#6397),2
[DNNL] Add TensorRequisite concept (#11345)Allow to use DNNL runtime in multi instance mode.Thread safe execution of Run() method.Signed-off-by: Alexander Peskov <peskovnn@gmail.com>,1
"[CI][Docker]Update Hexagon docker image to Ubuntu 20.04 (#10932)* fix permission* update pip versionAdd ONNX, TFLite, Tensorflow and update SDK version",5
Update download url for Airflow Version (#11800)All the versions are available at https://archive.apache.org/dist/airflow/ and this link appears in https://pypi.org/project/apache-airflow/,2
"Further speed up fixing ownership in CI (#23782)After #23775 I noticed that there is yet another small improvementarea in the CI buld speed. Currently build-ci-image builds and pushonly ""commit-tagged"" images, but ""fix-ownership"" requiresthe ""latest"" image to run.This PR adds --tag-as-latest option also to build-image andbuild-prod-image commands - similarly as for the pull-image andpull-prod-image. This will retag the ""commit"" images as latest in thebuild-ci-images step and allow to save 1m on pulling the latest imagebefore fix-ownership (bringing it back to 1s overhead)",0
Update PULL_REQUEST_TEMPLATE.md,5
fix merge issue,0
Merge pull request #779 from RealImpactAnalytics/BIG-2210_Base_date_in_task_duration_viewAdding base date and run number form to Task Duration and Landing Times views,1
[AIRFLOW-3521] Fetch more than 50 items in `airflow-jira compare` script (#4300),5
[Target] enable -arch=sm_xx for assigning cuda target arch and deprecate autotvm.measure.set_cuda_target_arch api (#9544)* [Target] enable -arch=sm_xx for assigning cuda target arch and deprecate autotvm.measure.set_cuda_target_arch apiSigned-off-by: ZQPei <ziqiangpei@foxmail.com>* [Format] fix format error in CISigned-off-by: ZQPei <ziqiangpei@foxmail.com>* [Target] add warnings to target.cuda and fix errors in ciSigned-off-by: ZQPei <ziqiangpei@foxmail.com>* [Target] fix docstringSigned-off-by: ZQPei <ziqiangpei@foxmail.com>* [Target] amend warning conditionSigned-off-by: ZQPei <ziqiangpei@foxmail.com>,2
"[ONNX] Update Slice op conversion to take strides into account, clean up tests (#6467)Co-authored-by: masa <masa@pop-os.localdomain>",3
Don't warn if start_date is None,5
[AIRFLOW-3705] Fix PostgresHook get_conn to use conn_name_attr (#5841)Update PostgresHook's get_conn method to directly call the specifiedconn_name_attr rather that always using self.postgres_conn_id.Currently subclassing PostgresHook requires overriding thepostgres_conn_id attribute in order to establish a separate connection.Add an additional unit test for this case checking that the subclassedPostgresHook's get_conn calls the correct arguments and that the hookcalls the correction connection_id in get_connection.,1
Add silent mode to rpc server and rpc tracker (#1268),1
Add __wrapped__ property to _TaskDecorator (#23830)Co-authored-by: Sanjay Pillai <sanjaypillai11 [at] gmail.com>,5
"Stronger language about Docker Compose customizability (#22304)* Stronger language about Docker Compose customizabilityDespite our warnings, our users continue treating the DockerCompose that we exposed as something that should be easy toextend and customize for their own needs, yet they continueto struggle with some basic behaviour of containers, Docker Composeand how they interact. This results in vast space of potentialproblems as Docker Compose gives the user a false premise ofsomething that ""just works"" where it requires quite a deepunderstanding on how it works.When you get things wrong with Docker Compose, you often end upwith extremely confusing messages, that might suggest that theproblem is with Airflow, but really the problem is with how usersinteract with their custom Docker images, registries, pulling,networking, mounting volumes and plenty other things.While this is the same with Kubernetes and Helm Chart, Helm Chart makesit infinitely easier to customize in declarative way (this is whatour values.yaml does) and anything that has not been foreseen by HelmChart developers is ""hard"" by definition.Docker Compose makes no such distinction. You really can't make DockerCompose customizable by configuration, and any customization in itrequires modifying the compose file and for people who do not knowwhat they are doing will eventually lead to errors that they are notable to diagnose and leads to creation of ""Airlfow isssues"", where theyshould be brought to ""Docker Compose"" issues.Example of that is here: https://github.com/apache/airflow/discussions/22301where there are at least two issues that are not reproducible withoutknowing in detail what the user has done, how the image was buildand distributed, and how the docker-compose installation interactedwith them. This leads to a terrible distraction for supportingusers of Airflow as the issues are really Docker Compose issues andAirflow maintainers should not be involved in solving those.This PR adds a bit stronger language and statement about the scopeand customizability of the Quick Start Docker Compose of ours. Notonly mentioning ""Lack of Production Readiness"" but also theresponsibility of the user to understand and diagnose docker composeerrors on their own and setting expectations that issues with DockerCompose running should be directed elsewhere.* Update docs/apache-airflow/start/docker.rst* Update docs/apache-airflow/start/docker.rstCo-authored-by: Daniel Standish <15932138+dstandish@users.noreply.github.com>* Update docs/apache-airflow/start/docker.rstCo-authored-by: Daniel Standish <15932138+dstandish@users.noreply.github.com>Co-authored-by: Daniel Standish <15932138+dstandish@users.noreply.github.com>",1
"[topi][relay] new PR to re-add tan to TVM (#5025)* Add relay operation relay.op.tan.* Update tan implementation in TVM.* Update tests.* Add shape function for tan.* Add missing main test to python/frontend/tensorflow/test_forward.* Revert, back to sin/cos.* Revert ""Revert, back to sin/cos.""This reverts commit 4da5b503b921585ba9d80944b29136142b575c40.* Fix implementation of tan in cuda. Do not support tan for float16.Simplify topi/tests/python/test_topi_math. Add testing for tan with float32 and float64.Finally implement tan as sin/cos in llvm.",3
Bug-fix GCSToS3Operator (#22071),1
Make execution_date optional for command `dags test` (#26111)* Make execution_date optional for command `dags test`,3
Add support for absolute opeartion (#1406),1
"Remove type hint causing DeprecationWarning in Firestore operators (#9819)* Import Iterable from collections.abc in firestore operatorsDeprecationWarning: Using or importing the ABCs from 'collections'instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working* Remove the type hint",4
[Relay] Fix Type Arguments not Attached (#6385),0
"Migrate Google example sql_to_sheets to new design AIP-47 (#24814)related: #22447, #22430",1
Update errors.rst (#24412)Fix wording in some sentences,0
"Add pod_override setting for KubernetesExecutor (#10756)* Add podOverride setting for KubernetesExecutorUsers of the KubernetesExecutor will now have a ""podOverride""option in the executor_config. This option will allow users tomodify the pod launched by the KubernetesExecutor using a`kubernetes.client.models.V1Pod` class. This is the first stepin deprecating the tradition executor_config.* Fix k8s tests* fix docs",2
"[LLVM][TIR] Propagate variable names to parameters. (#10514)* [LLVM][TIR] Propagate variable names to parameters.To aid in debugging, generate the variable names of function/closureparameters based on their TIR names.  These function/closure names canthen be observed in the generated LLVM IR.* Use name parameter in CreateLoad.* Fixed unit tests that check the parameter name.",2
"Merge pull request #1220 from jlowin/fix_executor_failedFix case where Executors fail to report failure, creating infinite loopThanks for the great commit message",5
fix python lint warnings (#3145),2
[AIRFLOW-5399] Add invoke operator for GCP Functions (#5995),1
[AIRFLOW-2586] Stop getting AIRFLOW_HOME value from config file in bash operatorCloses #3484 fromyrqls21/kevin_yang_fix_bash_operator,0
Implement XComArg.zip(*xcom_args) (#25176),5
"Add docker-context-files detection and cleanup flag. (#15593)When building images for production we are using docker-context-fileswhere we build packages to install. However if those context filesare not cleaned up, they unnecessary increase size and time neededto build image and they invalidate the COPY . layer of the image.This PR checks if docker-context-files folder contains just readmewhen Breeze build-image command is run (for cases whereimages are not built from docker-context-files). Inversely italso checks that there are some files in case the image isbuilt with --install-from-docker-context-files switch.This PR also ads a --cleanup-docker-context-files switch toclean-up the folder automatically. The error mesages also helpthe user instructing the user what to do.",1
"[AIRFLOW-2259] Dataflow Hook Index out of rangeBecause the api doesn't return the job, because itisn't known yetor because it cannot be found, it could be thatthe log lines arentavailable yet. Also use the locations based apicall, which returnsthe jobs immediately. This call seems to work forus-central, butdoesn't return any jobs for other regions.Closes #3165 from Fokko/AIRFLOW-2259",1
"Monkey patch greenlet celery pools (#8559)Celery pools of type eventlet and gevent use greenlets,which requires monkey patching the app:https://eventlet.net/doc/patching.html#monkey-patchOtherwise task instances hang on the workers and are neverexecuted.",1
"[AIRFLOW-XXXX] Expose SQLAlchemy's connect_args and make it configurable (#6478)In many use cases users need to configure SQLAlchemy's connect_args (e.g. pass ssl.check_hostname=False to PyMySQL), and Airflow should expose this option and make it configurable.",5
"Fix some migrations (#21670)In the xcom migration, there's a bad join. The clauses need to be wrapped in and_.  And in both, for sqlite we need to temporarily suspend FK enforcement before dropping the tables.",4
closes apache/incubator-airflow#1753 *example DAG not functional*,1
[AIRFLOW-2993] s3_to_sftp and sftp_to_s3 operators (#3828)Add operators for transferring files between s3 and sftp.,2
Do not show meta-data when printing IRModule (#6881),5
"[AIRFLOW-68] Align start_date with the schedule_intervalThis particular issue arises because of an alignment issue betweenstart_date and schedule_interval. This can only happen with cron-basedschedule_intervals that describe absolute points in time (like ‚Äú1am‚Äù) asopposed to time deltas (like ‚Äúevery hour‚Äù)In the past (and in the docs) we have simply said that users must makesure the two params agree. But this is counter intuitive. As in thesecases, start_date is sort of like telling the scheduler to‚Äústart paying attention‚Äù as opposed to ‚Äúthis is my first execution date‚Äù.This patch changes the behavior of the scheduler. The next run date ofthe dag will be treated as ""start_date + interval"" unless the start_dateis on the (previous) interval in which case the start_date will be thenext run date.",5
Bump croniter from `<1.1` to `<1.2` (#20489),5
error info (#69),5
[Relay] fix checkwellform (#2705)* do* address comment,1
Add detailed email docs for Sendgrid (#21958)Improved documentation for Sendgrid emailFixes #20419,0
"[AIRFLOW-5050] Correctly delete FAB permission m2m objects in sync_perms (#5679)Without this fix we can end up in the situation where trying to deletethrows an error:    > psycopg2.IntegrityError: update or delete on table    > ""ab_permission_view"" violates foreign key constraint    > ""ab_permission_view_role_permission_view_id_fkey"" on table    > ""ab_permission_view_role""    > DETAIL:  Key (id)=(57) is still referenced from table    ""ab_permission_view_role"".",4
[AIRFLOW-XXX] Add Liberty Global to company list (#3685),1
Update Thumbtack points of contact in Airflow Users list (#9701)The previously-listed person is no longer at the company,1
"[AIRFLOW-683] Add jira hook, operator and sensorCloses #1950 from jhsenjaliya/AIRFLOW-683",1
"[Relay, Op] Add conv2d generic layout op strategy when meta schedule is enabled (#12104)",0
"[Bugfix][IR][ATTRS] Fix AttrEqual for Array and StrMap, double (#5054)- Use fuzzy comparison for double.- Removed the hack for BatchNormAttrs and DictAttr.Also removed a warning from text printer printing.",2
Chart: Default to Airflow 2.2.4 (#21745),2
[AIRFLOW-1517] Remove authorship of secrets and init container,5
"Revert ""[AIRFLOW-1955] Do not reference unassigned variable""This reverts commit 9565a9879280d83c6c3987d3a6f8b8933168cedf.",4
"[TIR] Prevent loop binding over-simplification (#11578)@vinx13 @jinhongyii and I observe a recent regression on TVM mainline: over-simplification in`Schedule.split` leads to information loss that negatively impacts search space generation.**Impact.** This affects common operators like `softmax` and even simpler reductions.**Example.** Consider splitting a simple reduction loop:```python@T.prim_funcdef main(    A: T.Buffer[2, ""float32""],    B: T.Buffer[2, ""float32""],    C: T.Buffer[(), ""float32""],) -> None:    for i in T.serial(2):  # <= split `i` into `i_0` and `i_1`, where `i_0` is a trivial loop        with T.block(""C""):            k = T.axis.reduce(2, i)            with T.init():                C[()] = T.float32(1)            C[()] = T.min(C[()], A[k] / B[k])```Splitting loop `i`  by factors `[1, 2]`, we get:```python@T.prim_funcdef main(    A: T.Buffer[2, ""float32""],    B: T.Buffer[2, ""float32""],    C: T.Buffer[(), ""float32""],) -> None:    for i_0, i_1 in T.grid(1, 2):        with T.block(""C""):            k = T.axis.reduce(2, i_1)  # <= i_0 is not part of the binding,                                       # so the system cannot tell if i_0 is a reduction loop            with T.init():                C[()] = T.float32(1)            C[()] = T.min(C[()], A[k] / B[k])```In this case, loop `i_0` will be considered as a spatial loop, even it‚Äôs the outcome of splittinga reduction loop. However, if we change the factors from `[1, 2]` to `[2, 1]`, loop `i_0` becomesa reduction loop. This means the loop iteration property depends on the loop extent.**Why is it problematic**? MetaSchedule has an assumption: extremely seldomly, a loop extent wouldimpact the iteration property of the loop itself, i.e. no matter the extent is 1 or 2 or anything,the fact that the loop is a reduction loop should rarely change.As an example, `Auto-Bind` finds the outer `k` spatial loops, which are fused together and bound tothread axis. In the trace, the number (`k`) of the outer loops has to be a constant.However, if Auto-Bind thinks there are `k=3` outer loops to fuse during search space generation,where the last loop happens to be a reduction loop with extent 1, as shown below:```pythonfor spatial_loop_0 in range(...):  for spatial_loop_1 in range(...):    for reduction_loop in range(1):  # <= Auto-Bind mistakes this loop as spatial, because extent==1```During evolutionary search, the extent of reduction_loop will change and become larger than 1.In this case, the binding strategy will consistently fail because it considers fusing `k=3` loops- which means the entire search strategy will fail with almost no valid candidates.Thanks @MasterJH5574 for figuring out the root cause of the issue,and @jinhongyii for valuable pointers to the right fix!",0
Error in description after deployment (#9723)* Error in description after deploymentCo-authored-by: Daniel Debny <daniel.debny@polidea.com>,0
fixing copypasta issue with prefix sensor + docs,2
"Add docs about Scheduler HA, how to use it and DB requirements (#11467)",1
"[Hexagon] Do not pass lookup_linked_params to graph executor (#10944)This function is no longer used or generated, so it comes from theregistry as an ""empty"" PackedFunc. If the lookup function is provided,the executor will expect it not to be empty, which leads to a failedassertion.",3
Updated link to official documentation (#9629)The link to official documentation should point to the documentation page instead of the home page.,2
[CI] Fix clang-format error (#5577),0
Limit azure-servicebus to not be used on ARM (#24635)Azure service bus uses uamqp which does not build for ARM architectureand we need to disable it as a dependency for ARM.,1
Add Apache License to .github/workflows/repo-sync.yml (#10229)`.github/workflows/repo-sync.yml` was missing Apache license,5
[AIRFLOW-3495] Validate one of query and query_uri passed to DataProcSparkSqlOperator (#5510)DataProcSparkSqlOperator and DataProcHiveOperator are working either with queryor query_uri. Passing both doesn't make sense so check at construction time.,1
[RPC] callback option rpc server starts (#1092),5
[BYOC-DNNL]rewrite downsize blocks for rensetv1 to get better performance (#11822)* rewrite downsize blocks for rensetv1 to get better performance* fix lint,0
Display progress for docs build (#13000),2
update dependency (#1495),5
Check that visible_on isn't in the past,5
"[DOC/LICENSE] Make doc and license consistent, opensource repo when we get approval (#134)",1
[REFACTOR][PY] tvm._ffi (#4813)* [REFACTOR][PY] tvm._ffi- Remove from __future__ import absolute_import in the related files as they are no longer needed if the code only runs in python3- Remove reverse dependency of _ctypes _cython to object_generic.- function.py -> packed_func.py- Function -> PackedFunc- all registry related logics goes to tvm._ffi.registry- Use absolute references for FFI related calls.  - tvm._ffi.register_object  - tvm._ffi.register_func  - tvm._ffi.get_global_func* Move get global func to the ffi side,1
"[AIRFLOW-4394] Don't test behaviour of BackfillJob from CLI tests (#5160)It is slow, and we already have tests of that behaviour. All we need totest is that we call `dag.run()` correctly. Mocking ftw.",2
"docs: TESTING.rst: fix not loading image (#14247)[This image loads](https://github.com/apache/airflow/blob/master/images/testing/run-test.png) but [this](https://github.com/apache/airflow/blob/master/images/testing/run-tests.png) as referred to in the docs, not.",2
Merge pull request #1096 from amread/pool-recycle-configMake SqlAlchemy pool_recycle and pool_size configurable,5
[AIRFLOW-XXX] Update README.md (#4709),2
put FTPHook in contrib module,1
Merge pull request #553 from bolkedebruin/rewire_wwwRewire www-app to have a function to return an app,1
"Better docs, tweaks",2
Merge pull request #1545 from jgao54/zip-bug-fix,0
[Relay][Quantization] Fix Bug Which Cause Negative Left Shift Op (#7432),1
Fix incorrect typing and move config args out of extra connection config to operator args (#11635),1
"[TVMC] run: Don't use static path to find model.tar (#9712)* [TVMC] run: Don't use static path to find model.tarCurrently 'tvmc run' when '--device micro' is specified looks for themodel in the project directory at <project_dir>/model.tar. That worksfor Zephyr but fails on Arduino because model.tar is actually located at<project_dir>/src/model/model.tar. As a consequence 'tvmc run' when usedto run a model on Arduino exists because model.tar is never found.This commit fixes it by using the MLF path returned by the Project APIinstead of using a static path.This commit also adds a project_dir attribute to TVMCPackage that can beset when a MLF archive is loaded/imported so the project dir can beconveniently found (similarly to package_path attribute).Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [TVMC] test: Add test for importing a MLF with project_dirAdd test for TVMCPackage when importing a MLF archive and setting aproject directory too. Setting a project dir is only supported when aMLF model is imported, so it must fail on Classic format.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>",0
[TOPI] Fix x86 schedule for conv out_dtype (#1072),0
Fix misprint (#2243),0
Pins PIP to 20.2.4 in our Dockerfiles (#12738)Until we make sure that the new resolver in PIP 20.3 workswe should pin PIP to 20.2.4.This is hopefully a temporary measure.Part of #12737,1
Merge pull request #1075 from airbnb/pig_operatorPig hook and operator stub,1
[Docs] Bring Your Own Codegen Guide -- Part 1 (#4602)* BYOC tutorial: codegen C* Address comments* Address comments* Add build option* Address comments* Use TVM_DLL_EXPORT_TYPED_FUNC,1
"Fixes retrieval of correct branch in non-master related builds (#10912)When we ported the new CI mechanism to v1-10-test it turned outthat we have to correct the retrieval of DEFAULT BRANCHand DEFAULT_CONSTRAINTS_BRANCH.Since we are building the images using the ""master"" scripts, we need tomake sure the branches are retrieved from _initialization.sh of theincoming PR, not from the one in the master branch.Additionally versions 2.7 and 3.5 builds have to be merged tomaster and excluded when the build is run targeting master branch.",1
#1592 [PASS] Fix missing mem CHECK in storage_rewrite (#1616),0
[DOCS] Added casting to hybrid script doc and fixed pass infra doc (#6174)* updated hybridscript docs and pass infra docs* forgot uint16,2
Merge pull request #170 from mistercrunch/template_list_dictsSupport for dicts and list in operators template_fields,1
Adds automated user creation in production image (#13728)* Adds automated user creation in the production imageThis PR implements automated user creation for the production imagecontrolled by environment variables.This is a solution for anyone who would like to make a quick testof the production image and would like to:* init/upgrade the DB automatically* create a userThis is particularly useful for internal SQLite db initializationbut can also be used to initialize the user in docker-composeor similar cases where there is no equivalent of init containersthat are usually used to perform the initialization.Closes #860,5
Fix Constraints failure in PRs (#20631)The #20624 broke PRs that are changing setup.py.This PR fixes it.,0
Production image can be run as root (#14226)* Production image can be run as root* fixup! Production image can be run as root* fixup! fixup! Production image can be run as rootCo-authored-by: Kamil Bregula <kamilbregula@Kamils-MacBook-Pro.local>Co-authored-by: Kamil Bregu≈Ça <kamilbregula@apache.org>,1
Adding pyhs2 in requirements.txt,5
[AIRFLOW-179] Fix DbApiHook with non-ASCII charsString serialization fails when string contains non-ASCII charactersCloses #1553 fromjohnbodley/dbapi_hook_serialization-remedy,5
"[AIRFLOW-900] Fixes bugs in LocalTaskJob for double run protectionRight now, a second task instance being triggeredwill causeboth itself and the original task to run becausethe hostnameand pid fields are updated regardless if the taskis already running.Also, pid field is not refreshed from db properly.Also, we shouldcheck against parent's pid.Will be followed up by working tests.Closes #2102 from saguziel/aguziel-fix-trigger-2",0
Redundant batch_flatten removed for 2D input matrix in Dense layer. (#9792)* Redundant batch_flatten removed for 2D input matrix in Dense layer.* Fix to follow code review. infer_type for input[0] is called once.,5
"[microNPU] Adding rounding mode attribute to operators (#9514)* [microNPU] Adding rounding mode attribute to operatorsAllows rounding mode to be specified for each supported operator.By default ""TFL"" is used, which matches that of the behavior of TFLite.Other rounding mode options include ""NATURAL"" which rounds to thenearest value and ""TRUNCATE"" which rounds towards zero.",1
"[AIRFLOW-2932] GoogleCloudStorageHook - allow compression of file (#3893)- Add gzip functionality to GoogleCloudStorageHook.upload- Resolve docstring mistype, added additional information to  tell user that there is option to compress- Add test case for file_to_gcs",2
Fix more ONNX URLs (#10220)PR #10218 was not enough for this fix so this should probably run through full CI to make sure it got everything.cc @mousius @masahiCo-authored-by: driazati <driazati@users.noreply.github.com>,1
[community] @electriclilies -> Reviewer (#8684),3
Fix Flake8 errors (#8841),0
[AIRFLOW-5787] Moving AWS SQS to /providers/aws (#6474),1
macOS is now supported (#8396)Remove warning about macOS support from tutorial,1
"[AIRFLOW-XXX] Better instructions for airflow flower (#4214)* Better instructions for airflow flowerIt is not clear in the documentation that you need to have flower installed to successful run airflow flower. If you don't have flower installed, running airflow flower will show the following error which is not of much help:airflow flower                                                                                       [2018-11-20 17:01:14,836] {__init__.py:51} INFO - Using executor SequentialExecutor                                                      Traceback (most recent call last):                                                                                                         File ""/mnt/secondary/workspace/f4/typo-backend/pipelines/model-pipeline/airflow/bin/airflow"", line 32, in <module>                         args.func(args)                                                                                                                        File ""/mnt/secondary/workspace/f4/typo-backend/pipelines/model-pipeline/airflow/lib/python3.6/site-packages/airflow/utils/cli.py"", line 74, in wrapper                                                                                                                              return f(*args, **kwargs)                                                                                                              File ""/mnt/secondary/workspace/f4/typo-backend/pipelines/model-pipeline/airflow/lib/python3.6/site-packages/airflow/bin/cli.py"", line 1221, in flower                                                                                                                               broka, address, port, api, flower_conf, url_prefix])                                                                                   File ""/mnt/secondary/workspace/f4/typo-backend/pipelines/model-pipeline/airflow/lib/python3.6/os.py"", line 559, in execvp                  _execvpe(file, args)                                                                                                                   File ""/mnt/secondary/workspace/f4/typo-backend/pipelines/model-pipeline/airflow/lib/python3.6/os.py"", line 604, in _execvpe                raise last_exc.with_traceback(tb)                                                                                                      File ""/mnt/secondary/workspace/f4/typo-backend/pipelines/model-pipeline/airflow/lib/python3.6/os.py"", line 594, in _execvpe                exec_func(fullname, *argrest)                                                                                                        FileNotFoundError: [Errno 2] No such file or directory* Update use-celery.rst",1
Merge pull request #11 from mistercrunch/tweaksA few tweaks while running core_cx,1
Adding source types to C++ reduce functions (#1771),1
[AIRFLOW-6666] Resolve js-yaml advisory (#7283),0
Add docs for AIP 39: Timetables (#17552),2
Fix awkward log info in dbapi_hook (#8482)Co-authored-by: Liang Hao <liahao@tesla.com>,5
Remove remaining deprecated classes and replace them with PEP562 (#26167)This is a follow-up after #26513 - removal of all remainingdeprecated classes and replace them with PEP-562 dynamic attributeloading.,5
added error checking to loading symbol json (#2301),5
fix tests (#11368),3
Remove unneeded parentheses from Python file (#12968),2
[Cleanliness] [Easy] Make TVM leak-sanitizer and Wnon-virtual-dtor clean. (#2046),4
Docs: update ``ci.yml`` link in TESTING.rst (#16496)Update link in TESTING.rst guide. Hopefully this is the CI.yml file being referred to.,2
[skip ci][ci] Fix Jenkinsfile (#12387)This got out of date after merging #12178Co-authored-by: driazati <driazati@users.noreply.github.com>,1
"[AIRFLOW-8187] Extend elastic DAG with a binary tree, grid, star (#8277)",2
[Rust] Add rust runtime to CI (#1851),1
[AIRFLOW-6801] Make use of ImportError.timestamp (#7425),2
Add drain option when canceling Dataflow pipelines (#11374)* Add drain option when cancel Dataflow pipelines* fixup! Add drain option when cancel Dataflow pipelines* fixup! fixup! Add drain option when cancel Dataflow pipelines* fixup! fixup! fixup! Add drain option when cancel Dataflow pipelines,5
[AIRFLOW-6476] Fix directories created by docker (#7066)Some of the files that are mounted to breeze might not be created when firsttime run and then docker will turn them into directories.We should delete dirs/touch files in both breeze script and static checkscripts to get it fixed,0
"Add better feedback to Breeze users about expected action timing (#23827)There are a few actions in Breeze that might take more or less timewhen invoked. This is mostly when you need to upgrade Breeze orupdate to latest version of the image because some dependedncieswere added or image was modified.While we have improved significantly the waiting time involvednow (and caching problems have been fixed to make it as fastpossible), there are still a few situations that you need to havea good connectivity and a little time to run the upgrade. Whichis often not something you would like to loose your time on ina number of cases when you need to do things fast.Usually Breeeze does not force the user to perform such longactions - it allows to continue without doing them (either bytimeout or by letting user answer ""no"" to question asked.Previously Breeze have not informed the user about the exepctedtime of running such operation, but with this change it tellswhat is the expected delay - thus allowing the user to makeinformed action whether they want to run the upgrade or not.",1
"[TIR] Asynchronous stage in software pipeline (#12171)* [TIR] Support asynchronous stages in software pipeline transform* Support interleaved async producers separated by a consumer* clean up* adding doc* adding doc* simplifying* make wait count computation a two pass process* commit_stage -> commit_queue, wait_stage -> wait_queue* make async_commit_queue special scope stmt* codegen async_commit_queue in cuda* clean up* clean up* Move block predicate outside of commit_queue* updating test* test updated* changed async_wait to an annotation* update doc* update meaning of software_pipeline_async_stages* update test* fixing codegen* more fix* remove one of tests that have async and sync ops in the same stage* format* lint and other fix* Define attr::software_pipeline_async_stages* populate wait count in a separate function* fold variabel consumed into AsyncStateLocal* introduce CompletePipelineLoopStatements function for further refactor",4
[AIRFLOW-6341] Make tests/models pylint compatible (#6897),3
"Make helm chart commands compatible with 1.10.14 image (#13526)* Make chart command compatible with 1.10.14 image* [""airflow"", ""webserver""] does not work with the apache image* [""webserver""] works, as does ""bash"" ""-c"" etcCo-authored-by: Daniel Standish <dstandish@users.noreply.github.com>Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>",1
"[BYOC] Allow custom codegens to register their own constant updater (#6697)* [BYOC] Allow custom codegens to register their own constant updaterCurrently, all codegens using BYOC must make use of the defaultConstantUpdater pass. However, certain codegens, like Ethos-N,don't want to store any constants in metadata module. Thisprovides an interface (via a global) to register a customconstant updating method and assigns a 'null' updater for theEthos-N codegen.Change-Id: Ibd71d3091f992362eeede5d894eedb373b2dbc8f* Fix to use symbol in const nameChange-Id: I0ade81af9002d413c5b20a50488018e8cd8d8bad* Remove ;Change-Id: I61967bc4997efb87f87b49dad7e0a660c536ef35* Remove ccompiler constant updaterChange-Id: Iea9ee0f689683512fa114afeadeccb7fc9048e4f* Unregister updater after testChange-Id: I8009940bb2ac949f2c3f0d72c943a5b74afd6954* Create UpdateConstants utility functionChange-Id: I83c8c6f92cfe3be3a7e811e98a4eec17590186ff",4
Add AArch64 frontend dependencies to Dockerfile (#10676)Preparing to run more of the frontend tests on AArch64 by installing all the dependencies in the container,3
Merge pull request #1426 from jgao54/bug-fixcorrect missed arg.foreground to arg.daemon in cli,0
"Cleaner output for Docker image building (#20747)There was some ""junk"" output generated by the scripts that areused in Airflow image building. The junk has been cleaned up sothat no unnecessary warnings are generated.This change includes:* making sure that when everything is fine, there are no  warnnings generated by PROD docker build proces* making sure that when CI image is build the only remaining  warning is ""Using root"" - this warning cannot be silenced  https://github.com/pypa/pip/issues/10556 and instead  in CI build we explain in green that this is invalid warning* the ""scripted"" steps of docker build have nicely blue headers  that visually separate steps of building the iamge and give  more information on what's going on* the current way of printing ouput will play very nicely with  BUILDKIT UI where Blue color indicates progress in buildingSeparated out from #20238",5
closes apache/incubator-airflow#1770 *PR abandonned by submitter*,5
[BYOC][CONTRIB] Vitis-AI codegen integration (#6343)* [BYOC][CONTRIB] VITIS-AI integration* Remove environment related files* Update vitis_ai.rst* Add review changes* Remove new lines and note frame in vitis_ai.rst* use sys.exit* Add condition for vitis_ai runtime exec function* remove unused graph_json* correct indentation* use code python instead of bash* Rename VITISAI.cmake to VitisAI.cmake* use relay.ext.vitis_ai.options.build_dir in comparison* Re-add deleted docker related files* Make use of PyXIR XGraph and RuntimeModule serialization & refactor flow* Fix linter errors* Fix linter errors* Address sphinx warnings* Add infertype to fix Vitis-AI annotation test* Renaming util to utils* Add Vitis-AI flag to config.cmake file* Move vitis-ai config options to compiler sources instead of runtime sources* Fix clang-format errorsCo-authored-by: Anil Martha <anil.martha@xilinx.com>Co-authored-by: anilm (generated by with_the_same_user script) <anilm@xhdabidk40.xilinx.com>Co-authored-by: Jorn Tuyls <jornt@xilinx.com>,1
Remove last missed snakebite skip (#21025),4
fixup! Adds timeout to all curl commands (#13431) (#13435),1
[AIRFLOW-6356] clear/dag_state should not show logs from other dags (#6951),2
[Relay] Add a non-recursive LetNode VisitExpr_ for LabelOps Pass to avoid stack overflow (#8917)* Add a non-recursive Let VisitExpr_ for LabelOps* fake commit to retrigger CI* fake commit to retrigger the CI* fix CI issue* fix CI issue,0
Handle vectorize for LE statement (#3137)* Handle vectorize for LE statementFix a new cases introduced by commit 7afbca5691fdb599cd90b043d5a5036e55cae2d6* Add test,3
Fix typo in AWS doc (#22097),2
Use single-threaded SGX parallel (#975),1
[AUTOTVM] Fix GATuner and improve error message (#1605),0
KubernetesPodOperator template fix (#10963)* Ensure that K8sPodOperator can pull namespace from pod_template_fileFixes a bug where users who run K8sPodOperator could not run becausethe operator was expecting a namespace parameter* add test* self.pod* Update airflow/providers/cncf/kubernetes/operators/kubernetes_pod.pyCo-authored-by: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>* don't create pod until run* spellcheckCo-authored-by: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>,1
[WIP] [Relay] [NNVM] [Frontend] implement MaxPool-8 and MaxPool-10 (#3114),5
"[BYOC-DNNL] Bug Fix (#12314)* add bias_add checker, check op's order in catched pattern* fix wrong return in legalize_pad_avg_pool* add check for pooling, ceil_mode=True has not been supported by onednn currently.* fix lint* fix test error",0
Remove Presto check operators (#7884),1
Fixes quoting bug introduced in #10473 (#10477)Copy pasted curly quotes from a web page <facepalm>,0
Fix typos and minor simplification in TESTING.rst (#13194),3
fix type bug about topi test unitest (#12285),3
[AIRFLOW-4211] Add tests for WebHDFSHook (#5015),1
Merge pull request #1137 from jlowin/rls3Remote Log Storage (take 2),2
Fix typo of resultBackendConnection in chart README (#9537),2
Merge pull request #627 from bolkedebruin/masterPort kerberos authentication to new authentication structure,1
Set dags_are_paused_at_creation's default value to True,2
[PASS][RUNTIME] Support attr scope lift and runonce (#303),1
sets encoding to utf-8 by default while reading task logs (#17965),2
[AutoScheduler] Fix incorrectly array context device and hide info at the beginning (#7632)* [AutoScheduler] Fix incorrectly array context device and hide info at the beginning* Lint fix,0
keep Log scrolling only to nearest div (#24689),2
Remove extra postgres dependency from AWS Provider (#18844)* Remove extra prostgres dependency* Removed postgres cross dependency on aws provider,1
"[AIRFLOW-XXXX] Fix typo from upstream to downstream (#7595)This is how it used to be:Each DAG Run will contain a task_1 Task Instance and a task_2 Task instance. Both Task Instances willhave ``execution_date`` equal to the DAG Run's ``execution_date``, and each task_2 will be *upstream* of(depends on) its task_1.if task_2 depends on task_1 this means task_2 is set downstream of tastk_1  - wondering if I am missing something here - or misreading it",1
[Issue#22846] allow option to encode or not encode UUID when uploading from Cassandra to GCS (#23766),1
"Add Python 3 compatibility fixIn Python 3, errors don‚Äôt have a `message` attribute",0
[Pass] Simplify consecutive casts in Relay (#10133)* initial commit* initial commit* update test* jostle,3
Rename CloudBaseHook to GoogleBaseHook and move it to google.common (#8011),4
[AutoScheduler] Fix the type inference for conv3d (#7475),5
Fix tf reshape (#4285)* Fix tf reshape* Fix test* Fix pylint* Fix pylint,0
Docs: Fix links (#2118),2
[AIRFLOW-5053] Add support for configuring under-the-hood csv writer in MySqlToHiveTransfer Operator (#5669),1
Improve GCS system test envs (#13946)The same bucket cannot be used as source and destination,1
[AIRFLOW-6704] Copy common TaskInstance attributes from Task (#7324),2
Docs: Clarify ``sentry_on`` value is not quoted with example (#20639)Clarify the value for ``sentry_on`` is not quoted by providing an example.,1
[EXECUTOR] Improve LayoutTransform pass (#273)* [EXECUTOR] Improve LayoutTransform pass* Remove offline params for now* Small fix,0
[AIRFLOW-6459] Increase verbosity of pytest (#7049),3
"Revert ""[Vulkan] Support uniform buffer object for passing many scalar arguments (#7717)"" (#7821)This reverts commit 5bc1cec4c4acf0a54889227c1d19a6b65b6803c2.",4
Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602)Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit,1
"[AIRFLOW-3139] include parameters into log.info in SQL operators, if any (#3986)For all SQL-operators based on DbApiHook, sql command itself is printedinto log.info. But if parameters are used for the sql command, theparameters would not be included in the printing. This makes the logless useful.This commit ensures that the parameters are also printed into thelog.info, if any.",5
[AIRFLOW-XXX] Fix Broken Link in CONTRIBUTING.md,2
Fix grammar in UPDATING.md (#10841)`changes` -> `changed`,4
[AIRFLOW-7064] Add CloudFirestoreExportDatabaseOperator (#7725),5
"[AIRFLOW-4981][AIRFLOW-4788] Always use pendulum DateTimes in task in‚Ä¶ (#5654)* [AIRFLOW-4981][AIRFLOW-4788] Always use pendulum DateTimes in task instance contextIn certain situations, like when using fixed cron schedules such as `012 * * *`, the `execution_date`, `prev_execution_date`, and`next_execution_date` variables in macros were native python `datetime`objects instead of, as stated in the docs, pendulum `DateTime` objects.",5
The CRON job now is working and triggers builds on DockerHub (#8549)The CRON job from previous runs did not have everything workingafter the emergency migration to Github Actions.This change brings back following improvements:* rebuilding images from the scratch in CRON job* automatically upgrading all requirements to test if they are new* pushing production images to github packages as cache* pushing nightly tag to github,1
"Fix templated default/example values in config ref docs (#16442)We should show the actual default/example value in the configurationreference docs, not the templated values.e.g. `{dag_id}` like you get in a generated airflow.cfg, not `{{dag_id}}like is stored in the airflow.cfg template.",5
Mark Smart Sensor as an early-access feature (#11499),5
"[ETHOSU] Add early simplify to fix LoopPartition (#9387)* [ETHOSU] Add early simplify to fix LoopPartitionCertain loops aren't correctly partitioned if the loopcondition hasn't been simplified. This can happen whena copy loop is split by a non-factor. To fix this, anadditional simplify pass is added to the TIR pipelineprior to LoopPartition.Change-Id: Icd4ff14648ccaed41384da50c6d183a122b30048* Fix linting againChange-Id: I9c9dc2ee2c679861866b23531e88584b94198e51",4
[microNPU] Add support for unary elementwise CLZ (#9577)Add support for the CLZ (count leading zeros) operatorand the codegen test.Co-authored-by: Rishabh Jain <rishabh.jain2@arm.com>,3
[AIRFLOW-4660] Make airflow/bin Pylint compatible (#6294),1
[AIRFLOW-1545] Add Nextdoor to companies listAdd Nextdoor to company listAdd Nextdoor to companies listCloses #2448 from SivaPandeti/master,1
[ci] Remove TensorCore node name (#11048),4
Only send an SlaCallbackRequest if the DAG is scheduled (#26089),2
[RUNTIME] Switch time evaluator to use device specific timing. (#7631),1
"Bug fix for debug builds in micro_session.cc (#6968)* If the build decides not to inline kReceiveBufferSizeBytes,  we will encounter a linking error.Change-Id: Ibbe5b20fdd63acb2b4652ca9896f5737eaf14b00",4
[AIRFLOW-1887] Renamed endpoint url variables3_endpoint_url is a legacy name from when AwsHookwas only used toconnect to S3. The endpoint_url is more generaland what is effectivelyused elsewhere for this piece of information.Closes #2848 from villasv/AIRFLOW-1887,5
"Add CONCATENATION to tflite frontend, support Inception V3 (#2643)* Add CONCATENATION to tflite frontend* fix typo* Fix codestyle* Fix code style* simplify convert map* Update",5
Improving the TriggerDagRunOperator example,2
[AIRFLOW-3008] Move Kubernetes example DAGs to contrib,2
Fixed reading from zip package to default to text. (#13984)* Fixed reading from zip package to default to text.* Fixed open_maybe_zip unit test to account for io.TextIOWrapper.,3
[AutoTVM] Add batch_matmul to tunable operations (#4242)* Batch matmul tuning running but with errors.* Default x86 schedule as good as before.* Code Cleanup* Remove unused argument.* improved template documentation.* Silly lint fix* Removed leftover comment.* Moved cfg declaration to schedule for batch_matmul* Moved x86 dense cfg declaration to schedule.* lint fix* Removed duplicate cfg declaration in dense.* Reverted changes to dense.,4
Synchronizes updated changelog after buggfix release (#16464),0
"Update flask_wtf version to work with werkzeug>=1.0 (#11939)Werkzeug 0.16 deprecated werkzeug.url_encode, and removed it in 1.0, sowe need the fixed version of flask_wtf",0
[AIRFLOW-5488]Remove unused variables from tmp_configuration_copy method (#6114),5
add range to plan memory (#147),1
Add TriggererJob to jobs check command (#19179),1
Use [kerberos] in cfg instead of [security],5
[Relay][heterogeneous] Fix tuple annotation (#3311)* [Relay][heterogeneous] Fix TupleGetItem* retrigger ci* retrigger ci,1
[QNN] Use sigmoid Lookup Table method instead of fallback to fp32 (#12038),1
use css to toggle visibility depending on connection type,1
[AIRFLOW-XXX] Add FullContact to list of companies that use airflow (#5953),1
Manage Flask AppBuilder Tables using Alembic Migrations (#12352)closes https://github.com/apache/airflow/issues/9155The Migration is idempotent and allows both upgrade and downgrade.It also takes care of https://github.com/dpgaspar/Flask-AppBuilder/pull/1368i.e. increasing the length of ab_view_menu.name column from 100 to 250,1
Further validation that only task commands are run by executors (#9240),1
Fix failing TestGoogleDiscoveryApiHook & SnowflakeExampleDagsSystemTest (#9259),5
"Turn provider's import warnings into debug logs (#14903)When only some providers are installed, cross-dependencies betweenthe providers might cause import erors. Those import errors arerepeated in webserver as it is reloaded every 30 seconds.Since ""only some providers"" case is valid, it should not generatewarrnings if it is an ImportError. Those warnings are nowturned into debug messages.Fixes: #14286",0
[DOCS] Mention incubating in readme (#4401),2
fix (#111),0
Add OpenSlate to INTHEWILD.md (#10581),1
Add Bigtable Update Instance Hook/Operator (#10340)Add Bigtable Update Instance Hook/Operator,1
AIRFLOW-960 Add .editorconfig file,2
Fix While Node StructuralEqual and StructuralHash issue (#11073),0
Fixed naming in the Spark Connection Extra field (#18469)Changed the naming of the Extra fields from spark_home/spark_binary/deploy_mode to spark-home/spark-binary/deploy-mode to match what is actually in the codebase,4
[Flaky] TFLite quantized conv test (#6084),3
Add banner_timeout feature to SSH Hook/Operator (#21262)Recently ssh tests in CI started to fail intermittently withError reading SSH protocol banner error. This error is raisedwhen SSH server is slow to start (which might happen forexample when there is not enough entropy to generate keys)This can be mitigated by adding banner_timeout.,1
Add dynamic fields to snowflake connection (#14724)Adds form fields and custom form behavior for the Snowflake connection so it is more obvious to new users what fields need to be filled out. Also the doc_strings for the hook are updated to reflect the params along with helpful information using sphinx directives. I have categorized the fields below to explain the change.,4
Group Google services in one section (#8623),5
Add docs about supported logging levels (#14507)* Add docs about supported logging levels* fixup! Add docs about supported logging levelsCo-authored-by: Kamil Bregula <kamilbregula@Kamils-MacBook-Pro.local>,2
"Add a way to import Airflow without side-effects (#25832)I know it's been a long-standing issue that it should be possible to import Airflow as a library without side-effects, and while I think the ultimate fix for this is to go through and steadily remove the need to call `settings.initalize()` in `__init__.py`, I am currently working on a project where I would really like to use Airflow without it doing strange things to logging, sys.path, or atexit.As such, this PR wraps the import side-effect in a simple environment variable check that code can use to disable the side-effects for now, while we slowly try and progress towards a ""cleaner"" solution. Without this, I am having to dynamically modify the source code of `__init__.py` in an import hook, and nobody wants that!I don't believe it's possible to write tests for this as Airflow is already imported when tests are running, but if you can think of a way, let me know and I'll have a go. The environment variable name is also up for consideration - I just picked something that looked a bit like a setting, but we can deliberately make it not look like that if we want.",1
Fix typos (#12022),2
fix extern naming (#1238),0
"Push and schedule duplicates are not cancelled. (#11397)The push and schedule builds should not be cancelled even ifthey are duplicates. By seing which of the master mergesfailed, we have better visibility on which merge causeda problem and we can trace it's origin faster even if the buildswill take longer overall.Scheduled builds also serve it's purpose and they shouldbe always run to completion.",1
"[NVPTX] libdevice support, enable NVPTX backend in topi tests (#1365)",3
[RELAY] Enable registering op with python (#8002)Add a new API register_opNote: Implementing a op by pure python is still limited:  1. Custom type relation (add_type_rel()) is still not     available in python.  2. Setting number inputs (set_num_inputs()) needs     plevel > 128 in python.     (see tests/python/relay/test_ir_op.py),3
[AIRFLOW-903] New configuration setting for the default dag viewAdded a new configuration setting for the defaultview a dag should display when clicked on theindex page.Make sure we do lower for jinja url_for functionCloses #2103 from jakromm/master,1
fix bug in dense_nopack if dynamic input shape (#8166),0
closes apache/incubator-airflow#3310 *Fixed in another PR.*,0
[Relay] GradientCell Relay Pass (#5039)* save* gradient.rly* fix* NOT WORKING: gradient cell pass* test gradient pass* fixed basic call ops* more tests* fix bug* transform calls to one ones_like zero zero_like* maintenance stuff* fix linting* linting* linting* throw default* remove unrelated changes* import gradent.rly in pass* comment* linting* remove changes to test files* move gradient_cell.cc to transforms* revert change* update files with new commits* type* wrapper function to main outermost function type* fix linting* fix unsigned and signed int comparison* review* GetConstructor definition in module and change op comparison* update node instantiations* increase code readabilityCo-authored-by: Marisa Kirisame <lolisa@marisa.moe>,1
[Hexagon] Introduce new DeviceAPI (#9355)* Compile hexagon device api from runtime/hexagon/hexagon whenbuilding for hexagon and USE_HEXAGON_DEVICE is not set.* Add hexagon_common.h utilities including customtvm runtime logging for hexagon.* Introduce HexagonBuffer class to store hexagon allocation metadata.* Add HexagonDeviceAPIv2 for use on hexagon.* Add hexagon packed function wrapper.* Add custom linked param lookup for hexagonthat wraps params in an unmanaged HexagonBuffer.* Add custom hexagon module based of library module node.* Apply clang formatting* Apply cpplint changes.,4
"Fix empty excludes in selective checks (#20622)After removing Python 3.6, some of the excludes have beenempty - which caused error when evaluating combinations to runim main or when FULL_TESTS were needed.This PR brings sane excludes",3
[DOCKER] Pin keras version (#6032),2
[AIRFLOW-5167] Update dependencies for GCP packages (#7116),5
[microtvm][Zephyr] Increase timeout to fix flaky tests (#8846)* increase timeout* trigger,1
A few basic chart improvements,1
Cosmetics,5
Allow passing backend_kwargs to AWS SSM client (#8802),4
[AIRFLOW-XXX] Fix some operator names in the docs (#3778),2
Separate nodeSelector logic of chart (#13508),2
Update permission migrations to use new naming scheme. (#16400),1
[AIRFLOW-XXX] Minor fix for BREEZE.rst,0
Merge pull request #247 from airbnb/fix_string_testing_in_email_utilfixing redundant condition introduced by 2to3 with a compatible correct test,3
"[DOCS] Move git_howto to rst, add Stage documents to te (#5055)",2
Databricks: add support for triggering jobs by name (#21663),1
Ask users reporting UI bugs to include photo or video (#7790),0
[AIRFLOW-5361] Add system tests for BigQuery (#5968),3
[TEST][FLAKY] topi/tests/python/test_topi_sort.py::test_argsort (#4891)* [TEST][FLAKY] topi/tests/python/test_topi_sort.py::test_argsort* upadate test function of argsort like topk* Shuffle index and get data from shuffled index* Replace the random.uniform with np.arange,5
Moved connection type specific top/limit logic from app view to limit_sql utility function. Removed top_sql utility function.,1
[AIRFLOW-XXX] Add information how to configure pytest runner (#6736),1
no need for session handling,5
Beware of negative pool slots.Sometimes the scheduler over-allocates tasks in a pool. When that happens thenumber of open slot counts will go negative. The `not open_slots` code onlyworks if the scheduler observes the pool going to zero. If it has gone negativethe previous logic will schedule an unlimited number of pool tasks.,2
[AIRFLOW-4856] Make git sync run_as_user an config option (#5494)* [AIRFLOW-4856] change hard coded run_as_usertry to use worker_run_as_user* [AIRFLOW-4856] change hard coded run_as_useradd unit test* [AIRFLOW-4856] change hard coded run_as_usercreate new param git_sync_run_as_user* [AIRFLOW-4856] change hard coded run_as_useradd back remove option* [AIRFLOW-4856] change hard coded run_as_userfix Flake8* [AIRFLOW-4856] change hard coded run_as_userfix Flake8* [AIRFLOW-4856] change hard coded run_as_userfix unit test* [AIRFLOW-4856] change hard coded run_as_userchange the default value to it's old 65533,4
Make container creation configurable when uploading files via WasbHook (#20510),1
"[ACL] Adjust mobilenet test for Keras 2.9 (#12541)In Keras 2.7, one ""reshape"" operator was removed fromthe Mobilenet model, making our test which verifies thenumber of operators to be incorrect.This patch adjusts the operator count so that it is in linewith the changes in Keras. For reference, the change inkeras repo was done in hash b6abfaed132 ""Remove unnecessaryreshape layer in MobileNet architecture"".",4
[AIRFLOW-358][AIRFLOW-430] Add `connections` cliThis PR adds a `connections` command to Airflow'sCLI. The new`connections` command hopes to make it easier toautomate Airflow'sdeployment to different environments. Users won'thave to directlyinteract with the database or input connectionsmanually on the UI.Closes #1802 from PedroMDuarte/connections-cli,5
[AIRFLOW-3408] Remove outdated info from Systemd Instructions (#4269),5
Bump moto version (#24222)* Bump moto versionversion 3.1.10 broke main but the issue was fixed since in motorelated: https://github.com/spulec/moto/pull/5165* fix moto,0
"Highlight task states by hovering on legend row (#23678)* Rework the legend row and add the hover effect.* Move horevedTaskState to state and fix merge conflicts.* Add tests.* Order of item in the LegendRow, add no_status support",1
Support sub warp reduction for CUDA target. (#10207)* upd* upd* upd* lint* fix* upd docstring* upd,2
Release 2.2.0 (#18892),5
[TensorIR][M2a] Verification of cached flags (#8114)* [TensorIR][M2a] Verification of cached flagsCo-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>* Address comments* Update src/tir/schedule/analysis/verify.ccCo-authored-by: Cody Yu <comaniac0422@gmail.com>Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Cody Yu <comaniac0422@gmail.com>,1
Pin google-cloud-datacatalog to <0.8  (#8957)`field_path` was renamed to `tag_template_field_path` in >=0.8 and there might be other unknown errors,0
Chart: Remove unnecessary pod_template_file defaults (#19690),2
"Disable fail-fast on pushing images to docker cache (#24005)There is an issue with pushing cache to docker registry thatis connected to containerd bug but started to appear morefrequently recently (as evidenced for example byhttps://github.community/t/buildx-failed-with-error-cannot-reuse-body-request-must-be-retried/253178). The issue is still open in containerd:https://github.com/containerd/containerd/issues/5978.Until it if fixed, we disable fail-fast on pushing cacheso that even if it happens, we just have to re-run that singlepython version that actually failed. Currently there is a muchlower chance of success because all 4 build have to succeed.",1
Upsampling op support (#298)* add nnvm upsampling symbol* add upsampling mxnet frontend* add doc for upsampling op* cleanup upsampling test* minor fix* use schedule_injective for upsampling* upgrade tvm,1
Improve `airflow-github` dev script (#19631),1
fix setting task nodes class names (#18607)The stroke colour and tooltips were not setcorrectly for some tasks (depending on the ordering of `g.nodes`).,1
Flag --start-airflow for breeze (#10837),5
[AIRFLOW-3023] Fix docstring datatypes,5
Small docs readme update (#14062)* Add instruction for running docs locally* Fix RST syntax* Update docs/README.rstCo-authored-by: Kaxil Naik <kaxilnaik@gmail.com>Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>,2
[runtime][hexagon] improved file-copy logic (#12194)- Add `tvm::runtime::CopyFile` function.- Change `HexagonModuleNode::SaveToFile` to use new function  instead of a shell `cp` invocation.  This fixes a problem where the `cp`-based implementation  couldn't handle certain valid filenames.  This also fixes a bug where `SaveToFile` simply skips the  file-copying step on Mac OSX.,2
Poison pill for undeads,5
Fix typo in webserver.rst (#17288)Porting https://github.com/apache/airflow-site/pull/454 to Airflow docs. Added @pumpkiny9120 as co-authorCo-authored-by: Yanan Valencia <pumpkiny9120@gmail.com>,1
Allow MesosExecutor to re-register with MesosThis PR adds the ability to re-register the framework of theMesosExecutor with Mesos. That way tasks on Mesos keep running whilethe Scheduler is being restarted.,1
Brings back GKEStartPodOperator to google provider. (#11664),1
"[Airflow 1332] Split logs based on try numberThis PR splits logs based on try number and addtabs to display different task instance tries.**Note this PR is a temporary change forseparating task attempts. The code in this PR willbe refactored in the future. Please refer to #2422for Airflow logging abstractions redesign.**Testing:1. Added unit tests.2. Tested on localhost.3. Tested on production environment with S3 remotestorage, MySQL database, Redis, one Airflowscheduler and two airflow workers.Closes #2383 from AllisonWang/allison--add-task-attempt",1
AIP-47 - Migrate redshift DAGs to new design #22438 (#24239),1
Fix failing main spellcheck build (#17761),0
"Converts the specification of branch for pushes to be flexible (#17065)We already have flexible configuration of branches in CI workflowbut we missed them in build-images.yml - as a result direct pushesto v2-1-test branch are not building the images.This PR brings flexible branch specification to build-imagesworkflow as well so that we will not have to update iteven when we release 2.2, 3.0 etc. branches.",5
"Skip DAG perm sync during parsing if possible (#15464)For DAGs without `access_control` that already have their PermissionViewrecords, we can skip syncing their permissions during parsing. This cutsdown on database queries and is faster (~2 seconds, mostly import time).",2
"[Relay, OpFusion] Fix handling TupleGetItem for nested tuples (#2929)",1
[AIRFLOW-2906] Add support for DataDog's dogstatsd when emitting metrics (#7376),5
Encryption tweaks,5
Updating Jenkins example DAGs to use XComArgs (#16874),1
[AIRFLOW-XXXX] Add known issue  - example_dags/__init__.py (#7444),5
[AIRFLOW-5001] Moving building image to before_install phase (#5648)(cherry picked from commit 15d78b723db3bf05f845025fcceafe3170563063),5
Add Changelog for Airflow Chart 1.3.0 (#19417),2
[CODEGEN] Force not inline compute core for better debug (#557)* [CODEGEN] Force not inline compute core for better debug* also support llvm4,1
Cleaner output of docker image building scripts (#20679),2
[Hexagon] Disable broken test on physical device (#11960),3
Improve version check for kubectl (#24882)kubectl 1.24.0 added a warning that broke the version detection.It leads to redownload kubectl everytime we run a breeze-legacy command.,1
Packing and data layout change added to conv2d_nchw (#479)* conv2d layout change and packing added for the last workload* packing added for other workloads* conv2d added packing for first workload* fix pylint error,0
"[AIRFLOW-XXX] Airflow 1.10.1 release notes in UPDATING.mdSimply adding a header in the right place, as through dumb luck we hadthe changes in the right order.",4
Update chain() and cross_downstream() to support XComArgs (#16732)Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>,1
Fix bugs in URI constructor for MySQL connection (#24320)* Fix bugs in URI constructor for MySQL connection* Update unit tests,3
Insrease timeout for occasionally failing Dask test (#21051),3
Convert ECS Fargate Sample DAG to System Test (#25316),3
update `task-generated mapping` example (#23424)Co-authored-by: James Timmins <jameshtimmins@gmail.com>Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>,5
Gcp ai hyperparameter tuning (#17790)* Add hyperparameters to MLEngineStartTrainingJobOperator* Fixed pre-commit errors* Added passing hyperparameters to MLEngineStartTrainingJobOperator in example_mlengine.py* Added passing hyperparameters to Google ML CreateTrainingJob operator,1
[AIRFLOW-1242] Allowing project_id to have a colon in it.Closes #2335 from zoyahav/master,1
[Op] Do not override specified layout in pooling (2nd PR) (#9328)* [Op] Do not override specified layout in pooling (2nd PR)* [Op] Do not override specified layout in pooling (2nd PR)* [Op] Do not override specified layout in pooling (2nd PR)* [Op] Do not override specified layout in pooling (2nd PR),5
"Simplify fab has access lookup (#19294)* Use FAB models.* Remove incorrect conversions to new permission naming scheme.* Fix missing FAB renames.* Remove unused FAB compatibility fixes in models.py.* Set perms directly on user objects.* Set perms properties on User model.* Rename missed old naming scheme conversion.* Remove unused imports.* Remove unused imports.* Remeve get_user_roles() method.* Make permissions eagerload.* Remove unused imports.* Clarify query params.* Modify sort logic so MSSQL passes.* Add text modifier to order_by values.* Remove calls to get_*_dags.* Add back execution_date* Add back comma to match rest of file.* Remove unused permission functions.* Fix failing tests.* Pass user object to current_app.appbuilder.sm.has_all_dags_access.* Remove attempts to fix query.* Update the api_connexion query builders.* Add typing.* Apply sorts directly to model objects.* Apply sorts directly to model objects.* Standardize custom sort code.* Code review* Augment xcom docs (#20755)* Fix relationship join bug in FAB/SecurityManager with SQLA 1.4 (#21296)This is fixed in SQLA 1.4.19, but the fix makes the intent clearer hereanyway.* Docs: Fix task order in overview example (#21282)* Update stat_name_handler documentation (#21298)Previously stat_name_handler was under the scheduler section of theconfiguration but it was moved to the metrics section since 2.0.0.* Update recipe for Google Cloud SDK (#21268)* Use FAB models.* Remove incorrect conversions to new permission naming scheme.* Fix missing FAB renames.* Remove unused FAB compatibility fixes in models.py.* Set perms directly on user objects.* Set perms properties on User model.* Rename missed old naming scheme conversion.* Remove unused imports.* Remove unused imports.* Remeve get_user_roles() method.* Make permissions eagerload.* Remove unused imports.* Clarify query params.* Modify sort logic so MSSQL passes.* Add text modifier to order_by values.* Remove calls to get_*_dags.* Add back execution_date* Add back comma to match rest of file.* Remove unused permission functions.* Fix failing tests.* Pass user object to current_app.appbuilder.sm.has_all_dags_access.* Remove attempts to fix query.* Update the api_connexion query builders.* Add typing.* Apply sorts directly to model objects.* Apply sorts directly to model objects.* Standardize custom sort code.* Make sure joined fields prefetch.* Dont use cached_property, since its only on > 3.8.Co-authored-by: Ash Berlin-Taylor <ash@apache.org>Co-authored-by: Lewis John McGibbney <lewis.mcgibbney@gmail.com>Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>Co-authored-by: Lucia Kasman <38845383+luciakasman@users.noreply.github.com>Co-authored-by: Fran S√°nchez <fj-sanchez@users.noreply.github.com>Co-authored-by: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>",1
[RPC] Added native debug logging to Android RPC (#1432),2
Add rules describing SemVer approach for various Airflow packages. (#16422),1
#1159 bug fixed (#1164)* #1159 bug fixed* #1159 #1164 fixed,0
closes apache/incubator-airflow#1580 *PR abandonned by submitter*,5
[AIRFLOW-XXX] Add Aizhamal Nurmamat kyzy to contributors list (#5370),1
Add doc warning about connections added via envvars (#17915)Closes #17852,1
[TVMC][VitisAI] Enable Vitis AI target through TVMC (#7577)* Enable Vitis AI target through TVMC & change PassContext API's* Update python/tvm/contrib/target/vitis_ai.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Update python/tvm/contrib/target/vitis_ai.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Change Vitis AI  API to  & address comments & fix linter issues* Update docs/deploy/vitis_ai.rstCo-authored-by: Leandro Nunes <leandro.nunes@arm.com>* Update docs/deploy/vitis_ai.rstCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Add Vitis AI initiliazation to separate init config in TVMC composite target registry* Lazy load pyxir package in Vitis AI codegen to avoid hard dependency for TVMC* Fix TVMC Vitis AI test for compiler.compile_model API change* Lazy load pyxir package in Vitis AI partitioning passCo-authored-by: Jorn Tuyls <jornt.tuyls@gmail.com>Co-authored-by: Cody Yu <comaniac0422@gmail.com>Co-authored-by: Leandro Nunes <leandro.nunes@arm.com>,4
[Bugfix] Fix caffe2 nnvm frontend (#2996),0
[microTVM] Fix `build` directory exists error (#12575)When you build a project from existing project directory using `tvm.micro.project.GeneratedProject.from_directory` it would show up error if build directory previously existed.,0
Add Delete/Create S3 bucket operators (#8895),1
[AIRFLOW-3090] Specify path of key file in log message (#3921),2
Restructure documentation for releasing Airflow/Providers (#12350),1
Merge pull request #68 from airbnb/fix_queueFixing queue prioritization,0
Rename shared_ptr<Node> to NodePtr (#8),5
bump sphinx-jinja (#22101),5
[FIX] Fix target warning (#560)* [FIX] Fix target warning* [FIX] Deduplicate options* Fix* Fix,0
add mssql health check (#16103),1
Fix MSVC build error with container.h (#4455),0
Fix brokend master (#13201),0
Move Impersonation test back to quarantine (#10809)Seems that TestImpersonation is not stable even in isolationMoving it back to quarantine for now.,4
Merge pull request #60 from mistercrunch/chartChart link + email bug,0
Merge pull request #250 from JackDanger/doc-typo-you-yourTypo in config docs,2
"[Relay][Training] Add checkpoint annotation for checkpointing memory optimization (#4146)* add checkpoint annotation for checkpointing memory optimization* add alpha-equivalence checkpoint test and fix gradient type issue* fix build issues* ignore checkpoint annotation when checking missing gradients* refactor, fix checkpoint compute for tuple and add tests",3
GraphTuner supports relay.module as input (#3434),1
[AIRFLOW-639]AIRFLOW-639] Alphasort package namesCloses #1895 from zodiac/alphasort_requirements,1
[Relay/topi] Support scalar inputs in where op (#6383)* support where with scalars* add test for where with scalar* add comment,1
Add support for missing uint types. (#272),1
[Relay] Remove FTVMCompute from TNonComputational ops (#9334)* remove FTVMCompute from noncomputational ops* Remove injective schedule registration for on_device since it is non-computational* lint,4
"Enable more checks for pydocstyle (#10741)Enable D106, D207 and D208D106Missing docstring in public nested classD207Docstring is under-indentedD208Docstring is over-indented",2
[AIRFLOW-XXX] Add software transfer operators (#6207),1
"KEDA task count query should ignore k8s queue (#17433)CeleryKubernetesExecutor lets us use both celery and kubernetes executors.KEDA lets us scale down to zero when there are no celery tasks running.If we have no celery tasks running, and we run a k8s task, then KEDA willlaunch a worker even though there are still no celery tasks.  We can preventthis from happening by ignoring the kubernetes queue in the KEDA query.",1
"[VTA] hotfix for de10-nano driver (#4081)Issue:git clone latest TVM/VTA and run VTA on xilinx FPGA board, applicationcrashed due to the ""call stack overflow"" which caused by a infinite recursivefunction call. this issue ever happen before and get addressed by PR 3843.Analysis:seems like de10-nano driver PR  used old code base then the  logic changeof 3843 get eliminated.Solution:add the logic back.",2
Move dag_processing.processor_timeouts to counters section (#23393),2
[Debug] Add Dump function for Object type (NFC) (#5207)Signed-off-by: Wei Pan <weip@nvidia.com>,1
Enable hipModuleGetGlobal() (#4321),1
"Fix doc for ""hiding sensitive variables"" in Variable View (#12113)",2
"Docs: Better description for `pod_template_file` (#16861)In Airflow 2+, `pod_template_file` is the only way to configure workers,so we can remove the ""other fields"" language.",4
Prepare documentation for cncf.kubernetes 4.0.1 release (#23374),2
Inclusive Language (#18349),5
[Relay] Make check stricter by using Feature. Fixed multiple bugs. (#6326)* savelintlintlintfix lintlintupdatelintsavesavesavelintformatformatsavesavefixuse a form more suitable for numeric checksave* save* save* lint* save* lint* fix* fix,0
"[AIRFLOW-2843] Add flag in ExternalTaskSensor to check if external DAG/task exists (#4547)In ExternalTaskSensor, it may be good to providean option to cease waiting immediately if the externalDAG/task specified doesn't exist.To provide an argument ""check_existence"". Set to True to checkif the external DAG/task exists, and immediately cease waitingif the external DAG/task does not exist.The default value is set to False (no check or ceasingwill happen) so it will not affect any existing DAGs orcurrent user expectation.",1
[AIRFLOW-453] Add XCom Admin PageCloses #1756 from msumit/AIRFLOW-453,1
[AIRFLOW-5384] Improve dst param info in FileToGCSOperator (#5985)This commit add more info about dst parameter to indicate that the pathmust include file name.,2
Fix incorrect stride in conv2d_nhwc_python (#1670),0
"[AIRFLOW-4574] SSHHook private_key may only be supplied in extras (#6163)* discussion on original PR suggested removing private_key option as init param* with this PR, can still provide through extras, but not as init param* also add support for private_key in tunnel -- missing in original PR for this issue* remove test related to private_key init param* use context manager to auto-close socket listener so tests can be re-run",1
[AIRFLOW-5508] Add config setting to limit which StatsD metrics are emitted (#6130),1
Altering TODO.md,2
[AIRFLOW-2718] Backfill reset_dagrun option allows user to specify certain tasksCloses #3579 from feng-tao/reset_specic_tasks_for_backfill,1
[AIRFLOW-1805] Allow Slack token to be passed through connectionAllow users to pass in Slack token throughconnection which can provide better security. Thisenables user to expose token only to workersinstead to both workers and schedulers.Closes #2789 fromyrqls21/add_conn_supp_in_slack_op,1
[RUNTIME][CONTRIB] CoreML Runtime (#5283)* [RUNTIME][CONTRIB] CoreML Runtime* fix lint* fix CI* use xcrun to compile coreml model,1
[Relay] Handle memory scope during lowering from relay level (#11874)Relay expressions can have assigned virtual devices with certainmemory scope. This change landing of memory scope information fromRelay level to tir,5
"[ONNX][Relay] Add dynamic unsqueeze / expand_dims op (#9039)* initial dyn unsqueeze example* simplify, properly unpack scalar* basic tests* squish bugs -- assign proper types* working topi* fix things* temp work* fix casting to int64* shape encoding method for axis* working shape encoding metric* add comment* move to non-rank encoded axis* failing regime* fix* it works!* add test* add comment on shape func* remove unused topi* undo some file changes* more cleanup* newline* clean up* clean up* enable multiple axis tests* move tests to dynamic op* Update docs* add converter* initial dyn unsqueeze example* simplify, properly unpack scalar* basic tests* squish bugs -- assign proper types* working topi* fix things* temp work* fix casting to int64* shape encoding method for axis* working shape encoding metric* add comment* move to non-rank encoded axis* failing regime* fix* it works!* add test* add comment on shape func* remove unused topi* undo some file changes* more cleanup* newline* clean up* clean up* enable multiple axis tests* move tests to dynamic op* Update docs* add converter* working tests* add test, remove unneeded file* fix things* more lint* more lint* pick things* disable opencl tests* unsqueeze tests* clean up* dyn stuff* add num_newaxisCo-authored-by: Andrew Zhao Luo <andrewzhaoluo@system76-pc.localdomain>",5
"[microNPU] Refactor base address determination to codegen (#9929)This commit introduces BaseAddress ObjectRef to determinebase addresses in the codegen for microNPU. This isrequired when multiple memory pools become available. Thus,base addresses could not be statically determined in thesource module.",1
Add more refactor steps for providers.google (#8010)* Add more refactor steps for providers.google* fixup! Add more refactor steps for providers.google,1
"[AIRFLOW-4588] Add GoogleDiscoveryApiHook and GoogleApiToS3Transfer (#5335)- add documentation to integration.rstThe hook provides:- a get_conn function to authenticate to the Google API via an airflow connection- a query function to dynamically query all data available for a specific endpoint and given parameters. (You are able to either retrieve one page of data or all data)The transfer operator provides:- basic transfer between google api and s3- passing an xcom variable to dynamically set the endpoint params for a request- exposing the response data to xcom, but raises exception when it exceeds MAX_XCOM_SIZECo-authored-by: louisguitton <louisguitton@users.noreply.github.com>",1
"Fix race in Celery tests by pre-creating result tables (#8909)We noticed our Celery tests failing sometimes with> (psycopg2.errors.UniqueViolation) duplicate key value violates unique> constraint ""pg_type_typname_nsp_index""> DETAIL:  Key (typname, typnamespace)=(celery_tasksetmeta, 2200) already existsIt appears this is a race condition in SQLAlchemy's ""create_all()""function, where it first checks which tables exist, builds up a list of`CREATE TABLE` statements, then issues them. Thus if two celery workerprocesses start at the same time, they will find the the table doesn'tyet exist, and both try to create it.This is _probably_ a bug in SQLA, but this should be an easy enough fixhere, to just ensure that the table exists before launching any Celery tasks.",0
"[AIRFLOW-4734] Upsert functionality for PostgresHook.insert_rows() (#8625)PostgresHook's parent class, DbApiHook, implements upsert in its insert_rows() methodwith the replace=True flag. However, the underlying generated SQL is specific to MySQL's""REPLACE INTO"" syntax and is not applicable to PostgreSQL.This pulls out the sql generation code for insert/upsert out in to a method that is thenoverridden in the PostgreSQL subclass to generate the ""INSERT ... ON CONFLICT DOUPDATE"" syntax (""new"" since Postgres 9.5)",1
[TOPI] Add generic batch norm (#9694)* Add topi batch norm and tests* Handle none values correctly* Return correct nun outputs for onnx* Use moving var/mean and update tests* Add a test for batch norm folding* Fix comment* Format with black* Re-order test args to match interface* Call fold constant manually,3
Bugfix edge case around recent time related fix in tree view,0
Add verbose flag to ./build_docs.py (#13403),2
[AIRFLOW-XXX] Add Bombora Inc using Airflow,1
Fix typo in a comment (#8129)Fix typo in a comment about AOT executor.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>,2
Fix spelling in AWS docs (#12379),2
Add taskflow to accepted words (#11902),1
Enable IRFunctor based IRMutator,0
Fix typo in docstrings (#12220)`meatadata` -> `metadata`,5
[AIRFLOW-3655] Escape links generated in model views (#4522),2
"Set tvm.micro.project_api as a Python Module (#8963)* Add missing tvm.micro.project_api module file. The missing  __init__.py makes it impossible to import this module with  `import tvm.micro.project_api`.* This uncover 30-ish linting errors, which are also fixed here.",0
v1.2.0,5
only mark needed tasks as success,5
[AIRFLOW-2203] Cache static rules (trigger/weight)No need to recalculate them everytime just to see if they are valid,5
fix (#3769),0
Get Airflow Variables from Hashicorp Vault (#7944),1
"[ci] Default to n=2 for test parallelism (#12376)This decreases the test times for most of the tests except a few that did not run under pytest-xdist with 2 worker nodes. This also doesn't decrease overall runtime since CI is still bottlenecked on other jobs. However, this could lead to savings in compute which makes CI more sustainable so this is still worthwhile, though we should revert this if we start seeing ""weird"" errors like OOMs more often.",0
convert TimeSensorAsync target_time to utc on call time (#25221),1
Fix minor issues with Announcements Dev Scripts (#8141),0
[skip ci] Use Stanford Cars mirror to fix CI docs build (#11812),2
[AIRFLOW-2363] Fix return type bug in TaskHandlerCloses #3259 fromyrqls21/kevin_yang_fix_s3_logging,2
prevent DAG callback exception from crashing scheduler (#10096),2
[AIRFLOW-2682] Add how-to guides for bash and python operatorsCloses #3552 from tswast/airflow-2682-bash-python-how-to,1
Fix some typos (#8101)* fix bugs in the auto scheduler record:* reformat the code* reformat the code* use the os.path.abspath* change error to warning* reformat the warning code* fix some typos* fix some typos* fix some typos* fix the port number typo,2
"Fix Zephyr flashing on physical hardware, busted in #7813 (#7853)",0
Improvements for pod template file with git sync container (#11511)* Helm chart fixes in pod template- default pod_template image to `defaultAirflowRepository:defaultAirflowTag`- fix never-ending git-sync init containers- fix broken reference to volume* Fix helm chart test,3
Fixes automated upgrade to latest constraints. (#11399)Wrong if query in the GitHub action caused upgrade to latestconstraints did not work for a while.,1
[AIRFLOW-5886] Selective copying of sources in Docker image (#6538)This change further improves time of rebuilds for docker image when yoursources change (very useful in case of building kubernetes image). It adds onlydirectories that are needed (it is synchronised with .dockerignore and localmounts) and in the sequence that reflects frequency of changes. Also pipinstall is not done again after sources change (there is no point) so thebuild is much faster when only sources or test file change.,4
[Relay] Fix shape func for strided slice (#10418)* fix dyn strided slice* add tests* remove stuff* jostle ci* jostle ci* jostle,4
"Grid, fix toast for axios errors (#25703)",0
[COMMUNITY] @mbaret -> Reviewer (#5322),3
Check GCP guides on docs build stage on CI (#9171),2
[AIRFLOW-3675] Use googlapiclient for google apis (#4484)The deprecated apiclient package name is used in a number of places.This commit changes it to googleapiclient and modifies the rightpackages to be used instead.,1
Add missing space between label and value (#14008),1
"Implementation of uTVM (#3227)* uTVM interfaces (#14)* some minor interface changes* implemented HostLowLevelDevice* added MicroDeviceAPI* implemented micro_common and added Python interfaces* current status, semi implemented micro session* added micro_common implementation and python interfaces (#18)* added micro_common implementation and python interfaces (#18)* current status, semi implemented* host test working* updated interfaces for MicroSession arguments allocation* make somewhat lint compatible* fix based on comments* added rounding macro* fix minor bug* improvements based on comments* Clean up `binutil.py` and make Python-3-compatible* Change argument allocation design* Address feedback and lint errors* Improve binutil tests* Simplify allocator (per @tqchen's suggestions)* Doc/style fixes* farts* mcgee* rodata section werks(and so does `test_runtime_micro_workspace.py`)* simple graph runtime werk* TEMP* ResNet works, yo* First round of cleanup* More cleanup* runs a dyson over the code* Another pass* Fix `make lint` issues* ready to pr... probably* final* Undo change* Fix rebase resolution* Minor fixes* Undo changes to C codegen tests* Add `obj_path` in `create_micro_lib`* TEMP* Address feedback* Add missing TODO* Partially address feedback* Fix headers* Switch to enum class for `SectionKind`* Add missing ASF header* Fix lint* Fix lint again* Fix lint* Kill lint warnings* Address feedback* Change Python interface to MicroTVMAll interaction with the device is now through `Session` objects, whichare used through Python's `with` blocks.* Reorder LowLevelDevice interface* Store shared ptr to session in all alloced objects* Move helper functions out of `tvm.micro`* Switch static char arr to vector* Improve general infra and code qualityDoes not yet address all of tqchen's feedback* Forgot a rename* Fix lint* Add ASF header* Fix lint* Partially address MarisaKirisame's feedback* Lint* Expose `MicroSession` as a node to Python* Revert to using `Session` constructor* Fix compiler error* (Maybe) fix CI error* Debugging* Remove* Quell lint* Switch to stack-based session contexts* Make uTVM less intrusive to host codegenAnd use SSA for operands of generated ternary operators* Inline UTVMArgs into UTVMTask struct* Remove `HostLowLevelDevice` header* Remove `BaseAddr` class* Address feedback* Add ""utvm"" prefix to global vars in runtime* Fix lint* Fix CI* Fix `test_binutil.py`* Fix submodules* Remove ResNet tests* Make `test_binutil.py` work with nose* Fix CI* I swear this actually fixes the binutil tests* lint* lint* Add fcompile-compatible cross-compile func* Add docs for uTVM runtime files* Move pointer patching into `MicroSession`* Fix lint* First attempt at unifying cross-compile APIs* Fix lint* Rename `cross_compile` back to `cc`* Address feedback* Remove commented code* Lint* Figure out failing function* Remove debugging code* Change ""micro_dev"" target to ""micro""* Add checks in tests for whether uTVM is enabled* Add TODO for 32-bit support* Rename more ""micro_dev"" to ""micro""* Undo renameWe already have `tvm.micro` as a namespace.  Can't have it as a methodas well.* Fix failing CIThanks to @tqchen for finding this bug.  Emitting ternary operators for`min` and `max` causes concurrency bugs in CUDA, so we're moving theternary op emissions from `CodeGenC` to `CodeGenCHost`.* Address feedback* Fix lint",0
Azure: New sftp to wasb operator (#18877)* Azure: New sftp to wasb operatorCo-authored-by: Guilherme da Silva Goncalves <guilherme.goncalves@bancointer.com.br>Co-authored-by: Josh Fell <48934154+josh-fell@users.noreply.github.com>,1
add exclusive mode for rpc server (#941),1
"Converts Dockerfiles to be standalone (#22492)This change is one of the biggest optimizations to the Dockerfilesthat from the very beginning was a goal, but it has been enabledby switching to buildkit and recent relase of support forthe 1.4 dockerfile syntax. This syntax introduced two features:* heredocs* links for COPY commandsBoth changes allows to solve multiple problems:* COPY for build scripts suffer from permission problems. Depending  on umask setting of the host, the scripts could have different  group permissions and invalidate docker cache. Inlining the  scripts (automatically by pre-commit) gets rid of the problem  completely* COPY --link allows to optimize and parallelize builds for  Dockerfile.ci embedded source code. This should speed up  not only building the images locally but also it will allow  to use more efficiently cache for the CI builds (in case no  source code change, the builds will use pre-cached layers from  the cache more efficiently (and in parallel)* The PROD Dockerfile is now completely standalone. You do not  need to have any folders or files to build Airlfow image. At  the same time the versatility and support for multiple ways  on how you can build the image (as described in  https://airflow.apache.org/docs/docker-stack/build.html is  maintained (this was a goal from the very beginning of the  PROD Dockerfile but it was not easily achievable - heredocs  allow to inline scripts that are used for the build and the  pre-commits will make sure that there is one source of truth  and nicely editable scripts for both PROD and CI Dockerfile.The last point is really cool, because it allows our users tobuild custom dockerfiles without checking out the code ofAirflow, it is enough to download the latest releasedDockerfile and they can easily build the image.Overall - this change will vastly optimize build speed forboth PROD and CI images in multiple scenarios.",4
[AIRFLOW-2511] Fix improper failed session commit handling causing deadlocks (#4769),1
order dag run drop down in graph view,4
Quarantine test_mark_success_on_success_callback (#17364)The test is quarantined and recorded in #17363,3
add documentation on kerberos authentication,2
Pin Flask-Appbuilder to 2.3.2 (#8602),5
Fix Windows build (#3429),0
Add wildcard possibility to `package-filter` parametere (#23672)the glob parameters (for example `apache-airflow-providers-*`) didnot work because only fixed list of parameters was allowed.This PR converts the package-filter parameter to stop verifying thevalue passed - so autocomplete continues to work but you shouldstill be able to use glob.It also removes few places where the parameters were used with`--` separator.,1
[AIRFLOW-XXX] Add more AWS transfer operators (#6205),1
Fix MyPy issues in ``airflow/decorators`` and ``airflow/models`` (#20859)Fix MyPy issues in ``airflow/decorators`` and ``airflow/models``,0
Update CSV ingest code for tutorial (#18960),5
[ci][docker] Fix deploy to tlcpackstaging on Docker Hub (#12282)This was previously broken since it wouldn't pick up the new images names and there was an errant `'` floating around,1
"Do not include mypy volume by default (#25958)MyPy volume was included by default in shell command, but it isnot needed and might lead to missing mypy-cache volume problem.It is useful for debugging mypy problems so it is still useful tohave it as an option of shell command.",1
Fix mypy errors in asana example dags (#20593),2
"Move all ""old"" SQL operators to common.sql providers (#25350)Previously, in #24836 we moved Hooks and added some new operators to thecommon.sql package. Now we are salso moving the operatorsand sensors to common.sql.",1
[Hexagon] Add test for registered schedules (#11016)* add hexagon schedule tests* moved tests to sub-directories,3
move FTPHook to contrib folder,1
[AIRFLOW-4204] Update super() calls (#7248),5
fixin spellin,0
The PROD cache is pushed always in regular cache build step (#26254)In v2-4-test it turned out that PROD cache build was a bittoo limited - the cache has not been prepared if branch was notmain (copy&paste victim). This PR fixes this - cache is always buildin merge run regardless of the branch we are in.,1
Fix type var docs (#4208),2
[AIRFLOW-XXXX] Fix typo in tests/jobs/test_base_job.py (#7698),3
Add __repr__ to SerializedDagModel (#9862)Before: `<airflow.models.serialized_dag.SerializedDagModel at 0x7fab30d68c50>`After: `<SerializedDag: example_xcom_args>`,2
Fixes documentation-only selective checks (#12038)There was a problem that documentation-only checks triggeredselective checks without docs build (they resulted inbasic-checks-only and no images being built.This occured for example in #12025This PR fixes it by adding image-build and docs-build as twoseparate outputs.,2
Merge pull request #30 from mistercrunch/session_fixessqlalchemy session fixes,0
[AIRFLOW-5398] Update contrib example DAGs to context manager (#5998)- replaces the explicit assignment of a dag to a task to be implicit via context manager- changes task dependencies to be defined via bit shifting operator instead of set_upstream/set_downstream- update docs for papermill to extract the code example from the code,4
[TVM][BUGFIX] Fix missing reduction init predicates (#2495)* [TVM][BUGFIX] Fix reductions in split axes* A test case for the problem* Fix the fix: skip loops that are related to reduction AND are unrelated to axis,0
reinstated params as parameter to SlackAPIOperatorallow failure,0
[AIRFLOW-2404] Add additional documentation for unqueued taskCloses #3286 from AetherUnbound/feature/task-not-queued-doc,2
[Relay] Legalize and AlterOpLayout for Int8 Intel. (#3961),5
Bump moment from 2.29.1 to 2.29.2 in /airflow/www (#22873)Bumps [moment](https://github.com/moment/moment) from 2.29.1 to 2.29.2.- [Release notes](https://github.com/moment/moment/releases)- [Changelog](https://github.com/moment/moment/blob/develop/CHANGELOG.md)- [Commits](https://github.com/moment/moment/compare/2.29.1...2.29.2)---updated-dependencies:- dependency-name: moment  dependency-type: direct:development...Signed-off-by: dependabot[bot] <support@github.com>Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>,1
"Update minimum sphinx versions after upgrading sphinx-autoapi (#20170)* Allow point releases of AutoAPI 1.8 (I used with 1.8.4 in all my testing)* Require at least Sphinx v4  A few things got deprecated in Sphinx 4, and as this dep is only for  us building docs we can pick and choose what we like without impacting  users, so lets stay up-to-date.",5
conv2d schedule fall back warning fixed (#450),0
[AIRFLOW-5041] just force PYTHON_VERSION variable (#5660)There is no need for python3.6 to be installed in the host.,1
[AIRFLOW-2181] Convert password_auth and test_password_endpoints from DOS to UNIXCloses #3102 from dan-sf/AIRFLOW-2181,3
"[AIRFLOW-4316] support setting kubernetes_environment_variables config section from env var (#5668)When AIRFLOW_KUBERNETES_ENVIRONMENT_VARIABLES__AIRFLOW_HOME is set inthe scheduler, AIRFLOW_HOME should be set for workers, not airflow_home.",1
[AIRFLOW-6066] Added pre-commit checks for accidental debug stmts (#6662),0
Update link for Announcement Page (#11337),2
"[AIRFLOW-25] Configuration for Celery always requiredDear Airflow Maintainers,Please accept this PR that addresses the following issues:- AIRFLOW-25For now, if airflow.cfg has no [celery] section, all subcommands fail.This patch adds the default values for Celery-related propertiesas well as existing 'default_queue' and 'flower_port',so as to make all subcommands work and suppress ""not found in config""warnings even if [celery] section is omitted.Author: Kengo Seki <sekikn@apache.org>Closes #1558 from sekikn/AIRFLOW-25.",5
Add howto doc for Salesforce connection (#10482),1
"[AIRFLOW-XXX] Remove incorrect note about Scopes of GCP connection (#5242)The issue raised in https://issues.apache.org/jira/browse/AIRFLOW-2522 was resolved.Scope is not ignored when default credentials are used. This note should be deleted.Scope is read in:https://github.com/apache/airflow/blob/master/airflow/contrib/hooks/gcp_api_base_hook.py#L88-L92When default credentails is used, then this code is used:https://github.com/apache/airflow/blob/master/airflow/contrib/hooks/gcp_api_base_hook.py#L94-L97so scope is passed to the external library.",4
timing closure fix for default VTA config (#1489),5
Enables Kerberos sidecar support (#11130)Some of the users of Airflow are using Kerberos to authenticatetheir worker workflows. Airflow has a basic support for Kerberosfor some of the operators and it has support to refresh thetemporary Kerberos tokens via `airflow kerberos` command.This change adds support for the Kerberos side-car that connectsto the Kerberos Key Distribution Center and retrieves thetoken using Keytab that should be deployed as Kubernetes Secret.It uses shared volume to share the temporary token. The nicething about setting it up as a sidecar is that the Keytabis never shared with the workers - the secret is only mountedby the sidecar and the workers have only access to the temporarytoken.Depends on #11129,1
[AIRFLOW-3213] Create ADLS to GCS operator (#4134),1
Remove incorrect extension registration of tvm::Target (#1272),1
[AIRFLOW-XXX] Bump mixin-deep from 1.3.1 to 1.3.2 in /airflow/www (#5941)Bumps [mixin-deep](https://github.com/jonschlinkert/mixin-deep) from 1.3.1 to 1.3.2.- [Release notes](https://github.com/jonschlinkert/mixin-deep/releases)- [Commits](https://github.com/jonschlinkert/mixin-deep/compare/1.3.1...1.3.2)Signed-off-by: dependabot[bot] <support@github.com>,1
Add type annotations to S3 hook module (#10164),1
Rename DatasetTaskRef to TaskOutletDatasetReference (#25919),5
Re-run all tests when Dockerfile or Github worflow change (#8924)Fixes #8921,0
[TOPI] Group conv2d NHWC op implementation (#6510),5
Add Winograd matrices computation. (#3553),1
[TOP] GraphExecutor (#11),5
"Add server default for map_index in Log table (#23056)When logging CLI actions we insert a record into the Log table.  But for 2.3 we add column map_index to Log, and if the Log model expects map_index to be there the insert will fail and a warning will be emitted.We can avoid the error and warning by adding a server_default of NULL on map_index in Log. I choose NULL instead of -1 because generally speaking map_index doesn't make sense for Log tables.",2
Rework the flask app to return an app. First iteration,1
[FIX] Fix bug and typo in rpc_server (#263)* [FIX] Fix bug and typo in rpc_server* [FIX] Remove unnecessary condition,4
"[Hexagon] Do not auto-build apps when building TVM (#9970)* [Hexagon] Do not auto-build apps when building TVMThe Hexagon cmakes have recently become unwieldy due to a complexnetwork of dependencies between various automatically built components.This was in large part because of trying to automatically build someapps, which then tried to build TVM runtimes again, but with theirown configurations.This patch removes the ability to automatically build any Hexagon--related apps from the main TVM build. The following cmake optionsare now deprecated:  - `USE_HEXAGON_LAUNCHER`  - `USE_HEXAGON_PROXY_RPC`In order to build the binaries needed for HexagonLauncher fromtvm.contrib.hexagon:  - Build TVM+runtime for x86, with codegen for Hexagon enabled.    This can be done via `USE_HEXAGON_DEVICE=sim` or `target`.  - Build Android runtime and tvm_rpc with `-DUSE_RPC=ON`,    `-DUSE_CPP_RPC=ON`, and `-DUSE_HEXAGON_RPC=ON`.  - Build Hexagon runtime with `-DUSE_HEXAGON_RPC=ON`, and    `-DBUILD_STATIC_RUNTIME=ON`.* Add README.md* Restart CI* Add optional variable to set output directory",1
Disable Flower by default from docker-compose (#23685),2
"[Bugfix, CuDNN] fix segfault when cudnnDestroy called with destroyed cuda context (#8267)* fix: cudnnDestroy called after cuda context is over* refact: rename global var with `g_`* clang-format* refact: let cudnn handlers leak",0
Add how-to Guide for WinRM operators (#21344),1
[AIRFLOW-XXX] Update Contributing Guide - Git Hooks (#4120)- changes pre-commit example to use methods- adds activating virtual env for python to run things like flake8 locally- changes pre-commit file to use set -e command to instantly exit if any non-zero error occurs- changes flake8 call to lint the repo instead of not only the changes files,2
[AIRFLOW-5387] Fix show paused pagination bug (#6100),0
Fix CI tests so they correctly fail in case of error! (#19678),0
"Add dangling rows check for TaskInstance references (#22924)We are adding some foreign keys in 2.3.0 so we want make it more likely that migration succeeds by detecting FK violations and moving the records out of the table before creating the FK.  We already had a check for ""missing"" dag runs, but this adds a check for TaskInstance.  In most cases we replace the ""missing dag run"" check with a ""missing TI"" check since from 2.2.0 a TI implies the existence of a DR anyway.",1
Workflows assets & system tests migration (AIP-47) (#24105)* Workflows assets & system tests migration (AIP-47)Co-authored-by: Wojciech Januszek <januszek@google.com>,3
Rare bug fix when around task instance duration,0
"When CLI changes, we also re-run K8S tests (#13305)Since K8S tests use Airflow CLI (via Helm Chart) we shouldalso run the K8S tests when CLI changes.Fixes #12780",4
"[RUNTIME][DSO] Improve TVMBackendPackedCFunc to allow return val (#4637)* [RUNTIME][DSO] Improve TVMBackendPackedCFunc to allow return value.Previously the signature of LibraryModule's PackedFunc does not support return value.This wasn't a limitation for our current usecase but could become oneas we start to generate more interesting functions.This feature also start to get interesting as we move towards unifiedobject protocol and start to pass object around.This PR enhances the function signature to allow return values.We also created two macros TVM_DLL_EXPORT_PACKED_FUNC and TVM_DLL_EXPORT_TYPED_FUNCto allow manual creation of functions that can be loaded by a LibraryModule.Examples are added in apps/dso_plugin_module.The change to TVMBackendPackedCFunc is backward compatible,as previous function will simply ignore the return value field.* address review comments",1
[MIPS] Fix CALL16 reloc at 0x290 not against global symbol (#7634),0
"[AIRFLOW-3034]: Readme updates : Add Slack & Twitter, remove Gitter",4
[AIRFLOW-2264] Improve create_user cli help messageCloses #3168 from feng-tao/airflow-2264,1
[AIRFLOW-1505] Document when Jinja substitution occursCloses #2523 from TrevorEdwards/airflow-1505,2
[AIRFLOW-963] Fix non-rendered code examplesPlease accept this PR that addresses the followingissues:-https://issues.apache.org/jira/browse/AIRFLOW-963Testing Done:- ran sphinx-build locally and confirmed correctlyrenderedCloses #2139 from sekikn/AIRFLOW-963,5
Update CODEOWNERS for the Helm chart (#20451),2
[COMMUNITY] Bohan Hou -> reviewer (#7837),3
[docs] Update tlcpack-sphinx-addon (#12188)This includes https://github.com/tlc-pack/tlcpack-sphinx-addon/commit/545450acaf0ee4e2932d8c5d9ab6e321d0bc86c8 which fixes the sphinx-gallery cards and closes #12156,0
Add `template_fields` to `S3ToSnowflake` operator (#15926),1
Typo: Tensorflow --> TensorFlow (#3249),2
More conditional imports,2
"Use html urls instead of onclick for dags view links. (#12539)The dags view uses onclick events for dagrun and taskinstance links.This breaks url previews, copying urls, opening links in a new tab, etc.This patch uses svg anchors with href attributes instead of onclickevents so that these links behave like normal links.",2
[ci][docker] fix the path of custom toolchain in ci_qemu for csinn2 (#11905),0
"Fix broken KubeExecutor tests (#19680)We had deleted the example_kubernetes_executor_config dag and put it allin the sinle example_kubernetes_executor, but the tests had been brokenfor a while that we didn't notice.",3
New generic tableau operator: TableauOperator  (#16915),1
Fix auto-scheduling after 9c6658721 (#8478),0
"[TIR] StmtFunctor RenewDefs (#10843)* [TIR] StmtFunctor RenewDefsIn this PR, I introduce a StmtFunctor `RenewDefs` for deep copy all definition nodes in PrimFunc (including Var, Buffer, and IterVar). This functor can create a new PrimFunc with the same behavior as the old one but contains different Nodes.This Functor may help TIR fusion or inline multiple PrimFuncs* add ut* address comments* address comments* lint* lint",1
[AIRFLOW-1200] Forbid creation of a variable with an empty keyCloses #2299 from skudriashev/airflow-1200,1
"BUG #8013: Remove register_alter_op_layout example from dev/use_pass_infra.py (#9076)* BUG #8013: Remove register_alter_op_layout example from dev/use_pass_infra.pyThis tutorial registers a global layout transformation for conv2d for alltargets which is not well-formed. Later uses of conv2d in the tutorialspick that layout up then assert fail in the conv2d type-relation.Better would be to register a transform for an entirely fake target, butthat is beyond my current level of expertise.In general our use of sphinx/sphinx_gallery for running and rendering thetutorials is highly suspect since there is no inter-example isolation: - Examples using tensorflow will gobble up GPU memory and not give it back. - Any examples which use any of the (many!) global registration mechanisms   need to ensure the registrant is safe across all tutorials.I recall seeing a thread with the sphinx_gallery where they said they'd prefernot to work on process-level isolation, but it's probably worth pinging again.While digging into this I noticed we had a slicing cast in AlterOpLayout dueto a derived class of ObjectRef introducing virtuals. I moved the virtuals tothe corresponding Node classes. In this case we got away with it since theObjectRef happened to not get copied but we were on very thin ice.* [checkpoint] Woops, forgot there was an extra AlterOpLayoutI should have run locally, there goes 6hrs of CI.",1
"Task instances could be double triggered when using the --force, not anymore",1
Add BigQueryInsertJobOperator (#8868)* Add BigQueryInsertJobOperator* fixup! Add BigQueryInsertJobOperator* fixup! fixup! Add BigQueryInsertJobOperator* fixup! fixup! fixup! Add BigQueryInsertJobOperator,1
"Improve the tensorflow frontend _test_spop_resource_variables to support tensoflow 2.6 (#9978)On tensorflow 2.4 the test is expected to fail as the generated graph is not forzen.On tensorflow 2.6 the generated graph is identified as frozen, therefore the test is not needed",3
Add deps for Relay (#1463),1
[AIRFLOW-XXX] Added DataCamp to list of companies in README (#4009),5
"[TOPI] Print shape information when the input shape not compatible with (#9876)reshaped shape.[Issue]When the input shape not compatible with reshaped shape and not dynamicin topi reshape, the two shape sum value will get printed out as an errormessage, but such shape sum value is not helpful for the trouble shooting.[Solution]Print the shape detail, user can use such information to located relatedoperator for trouble shooting.",1
Support google-cloud-bigquery-datatransfer>=3.0.0 (#13337),5
Fix Volume/VolumeMount KPO DeprecationWarning (#19726),2
[SPIR-V] Add SPIR-V lowering for While node (#7574)* Add SPIR-V lowering for WhileNode* test vulkan in while loop tests,3
[ONNX] Disable failing tests on AArch64 (#12256)Change-Id: I170d2a8032dcb19d6ba3f67d9b0441944def84b8,4
[ETHOS-N] Re-enabled tests and updated module hashes (#8498),5
Add warning about nnpack installing googletest (#5185),3
Stop using start_date in default_args in example_dags (#9982),2
Cancel queued/running builds on second push to PR (#9513)We need to Cancel builds on PRs too.,1
Add Next Run to UI (#17732)* add next run to home page* add nextrun to dag pages* keep date check consistent* fix test_views* Include data interval values in /last_dagruns view* Use dag.next_dagrun_create_after* Fix timezone formattingUse `<time>` to use our existing `datetime_utils` to format and handle timezone changes* Update next and last run tooltips* wrap meta tags in if statementCo-authored-by: Tzu-ping Chung <tp@astronomer.io>,1
Fix Vertex AI Custom Job training issue (#25367),0
Add options to extend list of sensitive keywords (#9397),1
update boring-cyborg.yml (#24872),5
"Implemented Basic EKS Integration (#16571)* Implemented Basic EKS Integration* Remove explicit region defaultingcr https://code.amazon.com/reviews/CR-52973030* Refactor the token generation and remove the AWS CLI dependency.* move kubeconfig generator into `hooks/eks.py`* EKS List hooks return all results* Use a tempfile to store kubeconfig data* Move kube config into Hook class as a contextmanager* Removed random traits in tests* Rework the eks.rst doc file* Implemented Jinja templates for operators- Added jinja template fields- Refactored fields to snake_case since they are now exposed- Removed a couple of straggling pylint instructions; pylint is no longer used* conn_id refactor- Refactored using IDE magic: - any field named `self.conn_id` is now `self.aws_conn_id` - any param named `conn_id` is now `aws_conn_id` - any constant named `CONN_ID` is now `DEFAULT_CONN_ID`- Sensors were missing template fields, added those.* Remove try/log blocks from hooks* Implemented EKS system tests* Remove List and Describe Operators and supporting code.* Fixed `nextToken` final result bug* Remove some nesting and some unnecessary logging before raising an exception* Use the force* Improved docs and samples* Additional jinja templating* Corrected some misused Optionals.* Doc formatting fix* Corrected logo* Corrected logo - background and size",2
[Airflow-2760] Decouple DAG parsing loop from scheduler loop (#3873),2
[MetaSchedule] random compute location (#9940)Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>,1
"[AIRFLOW-3502] Update config template to reflect supporting different Celery pool implementation (#5477)The support to different Celery pool implementation has been addedin https://github.com/apache/airflow/pull/4308.But it's not reflected in the default_airflow.cfg yet, while it'sthe main portal of config options to most users.",1
Merge pull request #9 from mistercrunch/fixesDenser graph view,0
[AIRFLOW-5687] Fix Upgrade pip to 19.0.2 in CI build pipeline (#6361),0
Exclude snowflake-sqlalchemy v1.2.5 (#20245),5
[PYTORCH]aten::norm support added (#5776),1
[AIRFLOW-3990] Compile regular expressions. (#4813),5
"Remove unnecessary python 3.6 conditionals (#20549)Since Python 3.7 is now the lowest supported version, we no longer needto have conditionals to support 3.6.",1
Support mean in NNVM to Relay converter. (#2680),1
Merge pull request #2628 from moertel/registry-login,2
[DOCS] Add some notes about LLVM (#373)Add some notes about LLVM before building TVM,1
Prevent running `airflow db init\upgrade` migrations and setup in parallel. (#16311),1
"[Relay][Frontend][TFlite] Add add parser support for relational ops (#4695)Add support for: greater_equal, less, less_equal, equal, not_equalAdd tests for the elemwise relational ops",3
Adhere to flask_login specs and return the user_id with get_id,1
Fixes unclean installation of Airflow 1.10 (#7796)Removal of airrflow installed via -e . leaves .egg-info folderthat makes subsequent airflow installation not clean.This folder should be removed before install,4
[AIRFLOW-5365] No need to do image rebuild when switching master/v1-10-test (#5972),3
Merge pull request #90 from gtoonstra/masterExplanation about the meaning of date parameter,2
Support host_name on Datadog provider (#23784)This is required to use other Datadog tenants like app.datadoghq.eu,5
Refreshing TODO list,2
adding a sed comand to replace airflow_home automatically in default airflow.cfg,5
"[CI] Remove `llvm -device=arm_cpu` and `cuda -libs=cudnn` from the default test target list (#10500)After recent improvement in GPU frontend tests, I found that `topi: GPU` has become a bottleneck. From the log https://ci.tlcpack.ai/blue/organizations/jenkins/tvm/detail/PR-10391/14/pipeline/319, it is clear that topi tests are running on target `llvm -device=arm_cpu` and `cuda -libs=cudnn`, which I claim is completely redundant since we already run on `llvm` and `cuda` targets. In https://github.com/apache/tvm/pull/9905, I've already removed them from `DEFAULT_TEST_TARGETS`, but `topi: GPU` uses its own list of targets which still includes `llvm -device=arm_cpu` and `cuda -libs=cudnn`. I propose to remove them from topi test targets, which hopefully will cut topi GPU tests time by half.",3
"Use kubernetes queue in kubernetes hybrid executors (#23048)When using ""hybrid"" executors (`CeleryKubernetesExecutor` or `LocalKubernetesExecutor`),then the `clear_not_launched_queued_tasks` mechnism in the `KubernetesExecutor` canreset the queued tasks, that were given to the other executor. `KuberneterExecutor` should limit itself to the configured queue when working in the""hybrid"" mode.",1
"[AIRFLOW-2707] Validate task_log_reader on upgrade from <=1.9 (#3881)We changed the default logging config and config from 1.9 to 1.10, butanyone who upgrades and has an existing airflow.cfg won't know they needto change this value - instead they will get nothing displayed in the UI(ajax request fails) and see ""'NoneType' object has no attribute 'read'""in the error log.This validates that config section at start up, and seamlessly upgradesthe old previous value.",5
Fix AwsGlueJobSensor to stop running after the Glue job finished (#9022)* Extract get_job_state and fix poke of AwsGlueJobSensor* Save hook and reuse in GlueJobSensor* Add descriptions for some functions* Fix tests according to changed function definition* Fix too long line* Add type hints and apply review* Fix type errorCo-authored-by: JB Lee <jb.lee@sendbird.com>,5
"[TE] Correctly generate buffer binds with axis separators (#10819)In SchedulePostProcToPrimfunc, when the axis separator attribute ismoved to the buffer properties, it doesn't update buffers that are inthe buffer bind scope.  This occurs if `Stage.tensorize` is called fora stage whose layout transformation includes `te.AXIS_SEPARATOR`.",5
Initial commit,5
"[Frontend][Pytorch] Add axis N when maxpool3d layout is (C,D,H,W) (#12467)* Add axis N if input is (C,D,H,W) layout.* Add (C,D,H,W) test case.",3
Chart docs: note uid write permissions for existing pvc (#17170),2
Add type annotations for redis provider (#9815),1
[AIRFLOW-4438] Add Gzip compression to S3_hook (#7680),1
drop alembic version_table in resetdb,5
[AutoScheduler] Fix a bug in thread binding (#6683)* fix for lstm use case* update,5
"[Topi][Unittests] Parametrized tests in `test_topi_dense.py`, split out gpu-independent implementations (#8336)* [Topi][UnitTests] Parametrized tests in test_topi_dense.pyNow, tests run for multiple data types, can be extended withadditional datatypes.* [Topi] Separated generic-gpu nn.dense implementations into topi.gpu.denseAs a follow-up to the renaming of ""gpu"" to ""cuda"", separatingimplementations that require CUDA (e.g. dense_cublas.cuda) fromimplementations that require any GPU, but not necessarily a CUDA GPU(e.g. dense_small_batch.gpu).My intent is to pair this migration with the extension of unit teststo cover additional GPU runtimes, migrating only implementations thatrun correctly on non-CUDA GPU devices.* [Vulkan][Codegen] Updated storage sync to avoid incorrect matmul results on some GPUs- In ThreadAllreduceBuilder, separate out load/store so that they can  have a memory barrier in-between.- In Vulkan codegen, added Workgroup memory sync for subgroup thread  sync, since the different subgroup threads can still access  workgroup memory.  Longer-term, may need tir enhancements to  separate out sync of control/memory.Co-authored-by: Eric Lunderberg <elunderberg@octoml.ai>",5
"When precommits are run, output is silenced (#10390)The output of pre-commit builds on both CI and locallyis now limited to only show errors, unless verbosevariable is set.We are utilising aliases if possible but in case ofpre-commits they are run in non-interactive shell whichmeans that aliases do not work as expected so we haveto run a few functions directly in other toshow spinner.Extracted from #10368",4
Add black to lint docker image (#6451),2
"[VISITOR] New ExprFunctor, StmtFunctor Interface. Modular analysis (#58)* [ARITH/VISITOR] Modular Analysis, ExprFunctor, StmtFunctor* retrigger* [IRFunctor] Migrated CodegenC* [IRFUNCTOR] Migrate CodeGenLLVM* [IRFunctor] Migrate canonical* [IRFunctor] Migrate vectorize* [IRFunctor] migrate CodeGenStackVM",1
Fix rust rt link (#8631)* Fix support for linking to only libtvm_runtimealso ensures that the ResNet example uses the new support.* Fix build.rs to rebuild if the Python script changesCo-authored-by: Jared Roesch <roeschinc@gmail.com>,4
Fix broken link in dev/README_RELEASE_PROVIDER_PACKAGES.md (#14916)`PROVIDER_PACKAGES.md` was renamed to `PROVIDER_PACKAGE_DETAILS.md`,1
[AIRFLOW-3881] Correct to_csv row number (#4699),5
Add Easy Taxi to list of companies using Airflow,1
[Profiler] Add significant VM instructions to profiling report (#9292)Added a hooks to the VM execution loop to record runtime of certaininstructions with significant runtimes. Now the profiling report willinclude data allocation and transfer times.,5
Assign area:webserver label to webserver_command.py (#8998),5
[AIRFLOW-XXXX] Update tests info in CONTRIBUTING.rst (#7466),5
"First/last names can be empty (#25476)* First/last names can be emptyThe User schema restricts first and last names to not-null, and anempty string satisfies that requirement. The API insisted names haveat least one character, which caused errors when the database had anacceptably empty string.",5
set old_log if file doesn't exist,2
save (#3033)savesavesaveupstreamlintremove bad changesfix buildsavesaveplease the ci godUpdate src/relay/pass/partial_eval.ccCo-Authored-By: Wei Chen <ipondering.weic@gmail.com>savefix testci is ANGRYfix rebase problemfix rebaseadd testsavesavecomment,3
[TensorIR][Tutorial] Blitz course (#9315)* blitz course* update* black* update* update* Update gallery/tutorial/tensor_ir_blitz_course.pyCo-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>* Update gallery/tutorial/tensor_ir_blitz_course.pyCo-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>* Update gallery/tutorial/tensor_ir_blitz_course.pyCo-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>* typo* change linksCo-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>,2
"[TVMScript] Represent ramp as index slice (#11308)* support represent ramp as index slice in tvmscript* fix testcase's comment, check slice lanes instead of extent",3
[AIRFLOW-4266] Add mypy to setup.py dependencies (#5069)- remove old comment regarding to cloudant upgrade,4
[DOC] Scan tutorial (#98)* [DOC] Scan tutorial* Fix according to ziheng's comment,0
[AIRFLOW-6432] Raise appropriate exception in EmrAddStepsOperator when using job_flow_name and no cluster is found (#6898)* [AIRFLOW-6432] fixes in EmrAddStepsOperatorfix EmrAddStepsOperator broken ref & faulty test* changes after CR #1* Add exception and test case* Update airflow/contrib/hooks/emr_hook.pyCo-Authored-By: Tomek Urbaszek <turbaszek@gmail.com>* Update airflow/contrib/hooks/emr_hook.pyCo-Authored-By: Tomek Urbaszek <turbaszek@gmail.com>* Update airflow/contrib/operators/emr_add_steps_operator.pyCo-Authored-By: Tomek Urbaszek <turbaszek@gmail.com>* Update airflow/contrib/hooks/emr_hook.pyCo-Authored-By: Tomek Urbaszek <turbaszek@gmail.com>* Update tests/contrib/operators/test_emr_add_steps_operator.pyCo-Authored-By: Tomek Urbaszek <turbaszek@gmail.com>* changes after CR #2Co-authored-by: Tomek Urbaszek <turbaszek@gmail.com>,4
[AIRFLOW-6220] Remove redundant BigQuery hook tests (#6776),3
Restore 'filename' to template_fields (#18466),2
Fix failing test in DagCode (#9565)PR https://github.com/apache/airflow/pull/9554 introduced this error and because of Github issue currently (github is down / has degraded performance) the CI didn't run fully,1
Upgraded to latest version of requirements (#8239),1
[PASS] RewriteUnsafeSelect lowers unsafe select to condition expr (#335),4
"[TVMC] --disable-pass option added to compile mode (#7816)* [TVMC] --disable-pass option added to compile modeAdded --disable-pass option to TVMC compile mode to disallowcertain supplied passes in PassContext for the compiler.Change-Id: Iae1849d7b051ac9288509dc458a58788c865537a* Added test, addressed requestsChange-Id: If688f65441d3aa9967ab823adf899cfc704bd097* added printing of available passesChange-Id: I7a4706c03c0d64cade4977d431bcb25b3708f213* C0415(import-outside-toplevel)Change-Id: I33d6f6f86d182de2e21e895ec2dfe9f11f5916dd",4
[Frontend][PaddlePaddle] Support more common operators (#9428)* update ci-gpu to v0.78* add some common operators* code format* add transpose and swish* add unitest,3
"[Relay, Quantization, TOPI] int8 dense on CUDA & Dense op quantization  (#2877)* Quantize dense layers* Add out_dtype arggument to dense; Add dense_int8 on CUDA* Add topi unittest of dense int8* Fix relay* Fix topi integration* Fix quantization* Update dense_rewrite* Triger CI* Change qconfig quantize_dense to quantize_op* Fix* Remove quantize_op from qconfig",5
Merge branch 'master' of github.com:mistercrunch/Airflow,1
[PYTHON][FFI] Skip numpy.ascontiguousarray if C_CONTIGUOUS == True (#9073),5
Add the new logical operators to the doc. (#2761),2
[FIX] Verify that tensor reshape is valid. (#6215),0
[AIRFLOW-1314] Small cleanup to address PR comments (#24)* Small cleanup to address PR comments* Remove use of enum* Change back to 3.4,4
"Add pre/post execution hooks (#17576)Adds overrideable pre-/ post- execution hooks. With this change you can override pre-/post- hooks at the time of DAG creation, without the need of creating your own derived operators. This means that you can - for example - skip /fail any task by raising appropriate exception in a method passed as the pre- execution hook based on some criteria (for example you can make a number of tasks always skipped in a development environment). You can also plug-in post-execution behaviour this way that will be always executed at the same worker as the task run, sequentially to the task (as opposed to callbacks, which can be executed elsewhere and asynchronously)",1
Clean noqa labels wrongly handled by black linter (#12791),0
"Move config item 'worker_precheck' from section [core] to [celery] (#12746)* Move config item 'worker_precheck' from section [core] to [celery]This configuration is ONLY applicable for Celery Worker.So it should be in section [celery], rather than [core]* Add to deprecation/migration automatic list",1
"[TECompiler] Decouple TE compute and schedule lowering in ScheduleBuilder (#10561)* Decouple TE compute and schedule lowering in ScheduleBuilder* fixed merge conflict* removed create_schedule stuff* add public, fix include path convention* Forgot visiting arg in ScheduleBuilder CallNode vsit* fixed anchor impl selection",0
Merge pull request #548 from jlowin/shortcircuitAdd ShortCircuitOperator,1
[AIRFLOW-6758] Skip git version retrieval in case of invalid git (#7382)This happens when you have shared clone of the repository,5
Update operators.rst (#25358),1
"[BYOC][TRT] Allocate GPU data buffers and transfer data when needed (#6872)* Allocate data buffers for gpufix* Rename AllocateDeviceBuffer, update docstrings* Remove unneeded cast",4
Fix task instances iteration in a pool to prevent blocking (#20816),0
[AIRFLOW-4235] Add table-hover css class to DAGs table (#5033),2
fix first-order AD tuple/projection expr duplication (#8318),0
declare type name for optional<TShape> (#429)* declare type for optional tshape* add doc* move code to another place,4
[AIRFLOW-6659] Move AWS Transfer operators to providers package (#7274)* [AIP-21] Move contrib.operators.dynamodb_to_s3 providers.amazon.aws.operators.dynamodb_to_s3* [AIP-21] Move contrib.operators.hive_to_dynamodb providers.amazon.aws.operators.hive_to_dynamodb* [AIP-21] Move contrib.operators.imap_attachment_to_s3_operator providers.amazon.aws.operators.imap_attachment_to_s3* [AIP-21] Move contrib.operators.mongo_to_s3 providers.amazon.aws.operators.mongo_to_s3* [AIP-21] Move contrib.operators.s3_to_sftp_operator providers.amazon.aws.operators.s3_to_sftp* [AIP-21] Move contrib.operators.sftp_to_s3_operator providers.amazon.aws.operators.sftp_to_s3* [AIP-21] Move operators.gcs_to_s3 providers.amazon.aws.operators.gcs_to_s3* [AIP-21] Move operators.google_api_to_s3_transfer providers.amazon.aws.operators.google_api_to_s3_transfer* [AIP-21] Move operators.redshift_to_s3_operator providers.amazon.aws.operators.redshift_to_s3* [AIP-21] Move operators.s3_to_redshift_operator providers.amazon.aws.operators.s3_to_redshift,1
Fix static check on Master (#13721)#13714 broke the master,0
[REFACTOR][TIR] Migrate Low-level Passes to Pass Manager (#5198)* [TIR][TRANSFORM] Migrate LowerIntrin* LowerDeviceStorageAccessInfo* Migrate LowerWarpMemory,5
Supporting list of emails,1
Improve AArch64 depthwise convolution through smlal/smlal2 intrinsic (#6711)* Improve depthwise convolution through smlal/smlal2 intrinsic- Added an intrinsic to load a single int16x8 vector and produce two  int32x4 output vectors through smlal/smlal2 instructions- Changed the NHWC depthwise schedule to accomodate the aforementioned  intrinsicChange-Id: I347c3bf98fa8dd87057304dcda0d78e558424c57* Address review comments* Rebasing - 2* Rebasing - 3* Rebasing - 3* Fix linting,0
[TOPI][CUDA] Schedule for pool_grad (#3622)* [TOPI][CUDA] Schedule for pool_grad* Relay test* Fix fused op* doc* Remove set scope local,1
Clean up in-line f-string concatenation (#23591),4
Chart: Change default Airflow version to 2.0.2 (#15497)2.0.2 is more stable than 2.0.0 so this commit changes the defaultAirflow version to 2.0.2,4
Merge pull request #139 from mistercrunch/time_sensorAdding TimeSensor (operator),1
[CMSIS-NN] Fixed error in finding input's dtype in maxpool (#11701),0
"Add Simply Business to the documentation-list of ""companies using Airflow"" (#8516)* moved to a better place* renamed name",1
SID Oracle DB connection support (indent fix),0
Remove duplicate dependecies (#14611),4
Pylint: Enable deprecated-string-function check (#7839),1
expose SaveToFile symbol on windows (#1685),2
Remove opengl runtime and cmake (#5712),1
"[AIRFLOW-218] Added option to enable webserver gunicorn access/err logsCloses #1577 from aoen/ddavydov/better_http_response_loggingAdded an option to enable gunicorn access/error logs.The default config will now log webserver errors/accesses to stderr.Also made the 404 page hostname text default page color instead ofwhite, since white text is pretty hard to see against a whitebackground.",0
Fix curand. (#11901),0
Order filenames for migrations (#22168)Sometimes you want to quickly find recent migrations.  This makes it easier,1
[AIRFLOW-2440] Google Cloud SQL import/export operator (#4251),1
"[AIRFLOW-3079] Improve migration scripts to support MSSQL Server (#3964)There were two problems for MSSQL.  First, 'timestamp' data type in MSSQL Serveris essentially a row-id, and not a timezone enabled date/time stamp. Second, alembic creates invalid SQL when applying the 0/1 constraint to boolean values. MSSQL shouldenforce this constraint by simply asserting a boolean value.",3
"ImapAttachmentToS3Operator: fix it, update sample dag and update doc (#22351)",2
hive provider: restore HA support for metastore (#19777),1
[ci] Add conditionals for non-Python tests (#11438)These don't get sharded in any way so there's no point in running them multiple times.cc Mousius areusch,1
[docs] missing param in metastore sensor,2
Merge pull request #1592 from aoen/ddavydov/add_testing_done_section_to_pr_template,3
Pass first basic case of bound inference,5
Dataflow - add waiting for successful job cancel (#11501)Co-authored-by: Kamil Bregu≈Ça <kamil.bregula@polidea.com>,1
use python3.7 install script in ci-qemu (#10799)* use python3.7 install script in ci-qemu* update pyton venv to 3.7* setuptools is just python3...* don't use apt-add-repository (breaks with python3.7 as python3 on ubuntu 18.04,4
[AIRFLOW-6436] Create & Automate docs on Airflow Configs (#7015),5
Update license file to note libbacktrace (#9579)Co-authored-by: Tianqi Chen <tqchen@users.noreply.github.com>,1
[Metal] Reduce number of threads for reduction layers (#8206)Reduced default number of threads in reduction kernels for Metal.Default code generation generated thread block with the following size:32x32x1. With this size number of threads per threadgroup was equal to1024 (32 * 32 * 1). Sometimes device doesn't have enough resources andin this case we will get an exception that the block size is greaterthan value of maxTotalThreadsPerThreadgroup.To prevent such situation we decrease default number of threads. Withthis fix every model should work with default codegen and auto-tuning orauto-scheduling will select the optimal number of threads.,1
[LLVM] Protect ll when emit pass (#436),4
Fix example DAG for MLEngine in backport package (#7813),2
[Relay] Create header file for realize.cc (#11093)* Move class definitions to header file* Trim out unnecessary includes* Run clang-format-10* Remove unnecessary class declarations* Adjust grammar to trigger CI* Change comment phrasing again to trigger CICo-authored-by: Jonathan Sparling <jsparling@westus2-ml-vm-sg01.2xo54b0zdm3epgab0khwgzehke.xx.internal.cloudapp.net>,4
Fix indentation of the new notification entry (#22567),1
[AIRFLOW-4905] Add colours to flake8 output (#5541),1
"Fix BranchDateTimeOperator to be timezone-awreness-insensitive (#25944)* fIx BranchDateTimeOperator to be timezone-awreness-insensitiveThe BranchDateTimeOperator was sensitive to whether timezoneaware or timezone noive parameters were passed to it. Actuallyit worked a bit unpredictably - if use_task_logical_date wasused, the lower/upper ranges were supposed to be timezone aware,but when ""now()"" was used, the ranges were supposed to be timezonenaive. One of our examples has been broken because it wascomparing naive and aware datetime.This PR coerces all values to timezone aware Pendulum datetime usingthe timezone of the Dag, which makes it insensitive to whether theaware or naive ranges have been used.Also, we missed example in the howto showing logical date usage(and it was rather strange as logical date is the only reasonableusage of the operator - using utcnow() make the DAG essentiallynon-idempotent - it's result depends on when the task is run whichmight make sense in some cases but most of the time is somethingthat should be discouraged.The documentation has been updated to explain that.* Also use tz when converting non-Pendulum datetimePlus a better written docstring.Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>",2
"[FRONTEND][TENSORFLOW] Add Pad and PadV2 support (#1545)* [FRONTEND][TENSORFLOW] Add Pad and PadV2 support* Add assettion to _pad, and fix testcase for pad.",3
"Fix DagRun execution order from queued to running not being properly followed (#18061)We made a fix that resolved max_active_runs not allowing other dagruns to move torunning state, see #17945 and introduced a bug that dagruns were not following theexecution_date order when moving to running state.This PR fixes it by adding a 'max_active_runs` column in dagmodel. Also an extra testnot connected with this change was added because I was able to trigger the bug whileworking on this",1
[topi] fix strategy for sparse dense cuda (#5782),0
Remove unused pre-commit and Fix CI (#12964),0
Add 2.4.0b1 to issue template (#26242),0
[AIRLOW-XXX] Add Secret Escapes to companies list (#5286),1
Increasing timeout for gunicorn,1
Switch from zdesk to zenpy in ZendeskHook (#21349),1
[AIRFLOW-3141] Add missing missing sensor tests. (#3991),3
Adding Wooga to the list of companies using Airflow in the readme,1
[AIRFLOW-6667] Resolve serialize-javascript advisory (#7282),0
[RUNTIME] Api to get number of runtime threads (#10896)* [RUNTIME] Api to get number of runtime threadsAdd `tvm::runtime::threading::NumThreads` and `tvm.runtime.num_threads`as a way to get the number of threads in use by the TVM runtime.* check if equal to hardware threads or hardware threads/2,1
"[TOPI][Relay][TensorFlow] Add OneHot operator (#3781)* Add one-hot to Relay* topi implementation* Working* add topi test* Add TF test* Fix check* fix linting issues* fix documentation* Fix documentation* Add support for on_value, off_value, axis, dtype* Add full support for axis* Fix compute and update test_forward* Move on_value and off_value to inputs* Add topi test* Update tests* Update docs* Fix style* re-enable tests* Add one_hot to mxnet converter",1
[TensorFlow] Disable failing tests on AArch64 (#12257)* [TensorFlow] Disable failing tests on AArch64Change-Id: I7a53ce2d0dfff682b2953a26cace53fc5cc5d388* Fix lintChange-Id: If60d6e6ad24230f3c7f17c7ec55a7febcbba90fd,4
[AIRFLOW-XXX] Fix incorrect docstring parameter (#5729),2
update guards for adding encrypted,1
Fix spelling error causing tests to fail on main (#18021)I merged the PR that added this too eagerly,1
[Frontend]Make onnx gemm tensor C optional (#7489)* Make onnx gemm tensor C optional* fix codestyle* add tests* fix codestyle,0
Add sensors section to describe different modes of sensors (#12803)closes: #10816,1
Welcome users on creating their first issue (#7867),0
[AIRFLOW-1300] Enable table creation with TBLPROPERTIESEnable TBLPROPERTIES parameter in load_df andload_file methods ofHiveCliHook and TransferHive operatorsCloses #2364 fromkrishnabhupatiraju/tblproperties_hiveclihook,1
debugging PR,0
[RELAY][PASS] Common subexpression elimination (#2639),4
Remove Outdated SQLCheckOperator Docstring (#10589)This method is now implemented,2
Fix PRC typo (#2939),2
[CODE] Halide attributions (#3824),5
Support Python 3.6 in generate-integrations-json.py (#13610),5
Merge pull request #323 from airbnb/fixing_s3_sensor_loggingfixing s3 sensor missing '/',2
Bugfix in HiveStatsOperator,1
Merge pull request #368 from yoziru-desu/airflow-oracle-hookOracleHook: Add Oracle SQL Support,1
Add muldelete action to TaskInstanceModelView (#18438),4
[AIRFLOW-2747] Explicit re-schedule of sensors (#3596)* [AIRFLOW-2747] Explicit re-schedule of sensorsAdd `mode` property to sensors. If set to `reschedule` anAirflowRescheduleException is raised instead of sleeping which setsthe task back to state `NONE`. Reschedules are recorded in new`task_schedule` table and visualized in the Gantt view. New TIdependency checks if a sensor task is ready to be re-scheduled.* Reformat sqlalchemy imports* Make `_handle_reschedule` private* Remove print* Add comment* Add comment* Don't record reschule request in test mode,3
"[AIRFLOW-3183] Fix bug in DagFileProcessorManager.max_runs_reached() (#4031)The condition is intended to ensure the functionwill return False if any file's run_count is still smallerthan max_run. But the operator used here is ""!="".Instead, it should be ""<"".This is because in DagFileProcessorManager,there is no statement helping limit the upperlimit of run_count. It's possible thatfiles' run_count will be bigger than max_run.In such case, max_runs_reached() methodmay fail its purpose.",0
"[AIRFLOW-2516] Fix mysql deadlocks (#6988)Deadlocks were occuring in mysql when task_instance was modifiedby two queries at the same time. One query used state as selectioncriteria and updated it in the same query where second query justupdated the state for the same table. The first query locked stateindex first and primary index afterwards, the second query lockedprimary index first and state afterwards - leading to deadlocks.This change splits the first query into two independent ones.First query makes select FOR UPDATE and selects all the taskinstances to act on (this will lock primary index only)and second updates all affected task instances.Note that performance impact for that is neglectable because thisquery is only run once every scheduler loop and the second partof it (looping through task instances) will only happen in casethere are some manually modified DagRun states - so it is onlyrun to correct some wrong states of DagRun. This should happenvery infrequently.",5
[hotfix] missing include headers (#4204),0
Docs: Fix Taskflow API docs (#16574)Add missing `def` statement and `EmailOperator` import.,2
"Set killMode to 'control-group' for webservice.serviceThe gunicorn workers where not properly killed on `systemctl stop`command. By removing the KillMode setting the default parameter""control-group"" is used and all childrens are properly killed",1
Fixed wrong value of store-dag-code default (#16093)Fixes: #16090,0
[COMMUNITY] @kevinthesun -> PMC (#7803),3
[AIRFLOW-6516] BugFix: airflow.cfg does not exist in Volume Mounts (#7109),5
[AIRFLOW-933] use ast.literal_eval rather eval because ast.literal_eval does not executeinput.This PR addresses the following issues:- *(https://issues.apache.org/jira/browse/AIRFLOW-933)*This PR is trying to solve a secure issue. Thetest was done by setting up a local web server andreproduce the issue described in JIRA link above.Closes #2117 from amaliujia/master,2
Add note to restart runners when updating committers (#19795)Also link to a script that can generate the list of committers,2
Adding logging to hive_to_mysql,2
"[Relay][Prelude] Use the Relay parser to define the Relay prelude (#3043)* Add ability to load Prelude from disk* Port over id* Define compose* Linting errors and style changes* Eliminate unnecessary parens* Rename identType to typeIdent (makes more sense)* Another unnecessary paren* Bump the version number for the text format* Ensure .rly (Relay text files) are permitted* Correct release number and simplify grammar rule* Correct load_prelude docstring* Corrections to _parser* Add Apache headers to prelude source file* Remove test_prelude (redundant)* Correct misleading error message* Add check that parser is enabled in Prelude* Commit pre-generated parser, ensure generated files are treated as binaries, and have parser tests always fire* Permit parser files and git attributes files* Exclude gitattributes and parser files from apache check* Another attempt at appeasing Apache audit checker* Corrections to rat-excludes* Apache should be truly appeased now* Ignore Relay parser files by name* Mark parser files as generated so they don't show up on Github* Add parsing helper function for tests* Mark parser files as not detectable",2
"[microNPU] Mean legalization support (#9576)Supports legalizing a Relay mean operation to an equivalent series ofNPU operations. Mean can be legalized given one of three cases:    - Case 1 (axis == [1, 2] and keepsdims == True):        depthwise_conv2d + binary_elementwise    - Case 2 (ifm qparams == ofm qparams):        pooling    - Case 3 (else):        depthwise_conv2dCo-authored-by: Rishabh Jain <rishabh.jain2@arm.com>",2
UX Enhancement: Separate actions from links in DAG navigation (#9894),2
"[RVM] Fix AttributeError when action is not specified (#9683)Although an action (build, test, or release) is always required bybase-tool-box.py currently actions are not set as ""required"" in theparser, hence it doesn't complain when an action is missing and laterwhen 'args.platform' attribute (present in all actions) is referencedthe tool exits abruptly due to an AttributeError (because 'platform' isnot set), without giving any clue on what went wrong. For instance:$ python3 ./base-box-tool.py --provider virtualbox # no action is givenThis commit fixes it by setting action subparsers as required so theparser complains when no action is specified.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>",1
"Use resource permissions for Airflow view access (#11362)Migrate the Airflow view to use resource-backed permissions. This includes creation of a custom has_access decorator, deprecation of the has_dag_accessdecorator, a migration script to update existing roles to use the new permissions, and adding the new has_access decorator to the Airflow view class's methods.",1
re-initiating hook in execute,1
Unpin ``cattrs`` (#20872)This was pinned because of issue mentioned in https://github.com/apache/airflow/issues/16172 . However this was fixed in 1.8.0 of cattrs by https://github.com/python-attrs/cattrs/issues/151Changelog entry - https://cattrs.readthedocs.io/en/latest/history.html#id9,3
Testing XCom endpoint joins to avoid regression (#11859),3
[DOC] More detailed installation instruction (#262)* [DOC] More detailed installation instruction* fix lang,0
[RELAY][OP] roi_pool operator alter layout (#6516)Co-authored-by: honghua.cao <honghua.cao@streamcomputing.com>,1
Merge pull request #379 from CooperLuan/masteradd attachments support in EmailOperator,1
AIRFLOW-168 Correct evaluation of @once scheduleIf the schedule @once was used with a start_date two dagrunswould be created as next_run_date would be none and comparedagainst dag.start_date. This patch fixes that by returningimmediately if a dagrun has already occured with an @onceschedule.,2
Fix winograd infer tize (#7092),5
Update __init__.pyAdd oracle_hook integration,1
"Fix ``DetachedInstanceError`` when dag_run attrs are accessed from ti (#18499)Loading a taskinstance doesn't load the corresponding dag_run withthe effect that when the dag_run attr is accessed from the ti it givesa DetachedInstanceError, dag_run is not bound to a session.This PR fixes it by making an extra query to get the dagrun using therelationship between the two objects",1
[Frontend][Tensorflow]add batch_dim support for gatherV2 (#7951)* add batch_dim support* fix lint* add check for num of arguments for topi.take* fix gpu test cases* add check for batch_dims in take_grad,1
[AIRFLOW-4934] Fix ProxyFix due to Werkzeug upgrade (#5563),0
[HYBRID FRONTEND] Modify hybrid script to new interface; hybrid op supported; enable compilation_database in CMakeList.txt (#1757),5
Fixed test-target command (#8795)Wrong parameter sequence were passed to the run script.,1
Tests are working for newly added backport providers (#9739)* Tests are working for newly added backport providers,1
Added missing project_id to the wait_for_job (#24020),1
Update to latest requirements 2020.04.12 (#8262),1
Add install/uninstall api to databricks hook (#12316)- adding install Databricks API to databricks hook(api/2.0/libraries/install)- adding uninstall Databricks API to databricks hook (2.0/libraries/uninstall),1
Refactoring x86 conv2d_NCHWc (#3944),4
"[Hexagon] Make local symbols visible to loaded modules in RPC server (#11611)The simulator library `libhexagon_rpc_sim.so` contains TVM runtime builtinto it, but since it's loaded as a ""local"" library these symbols are notvisible to shared libraries loaded by subsequent dlopens. (Same applies tosymbols from the C++ runtime.)To make these symbols visible, dlopen the defining libraries as ""global"".(Re-dlopeninig an already loaded library is a well-defined operation.)",5
[AIRFLOW-3607] Optimize dep checking when depends on past set and concurrency limit,1
"Doc Fix around Secret/Connection/Variable (#12571)Documentation fixes/improvements:- For Variables set by Environment Variable,   it was highlighted that it may not appear in the web UI.   But this was not highlighted for Connections set by Environment Variable.   This PR adds this note (in docs/howto/connection/index.rst).- Fix wrong docstring of airflow.secrets.base_secrets.BaseSecretsBackend.get_variable().- The Secret Backends don't properly mentioning Variables in the docstrings   (all the focus was put on Connections only). This PR addresses this.- Other a few minor changes.",4
[TIR] Move UnifyThreadBinding to earlier stage (#9365)* Move unify thread binding to earlier stage* Unify thread binding support AttrStmt,1
[REFACTOR] Remainings of util => utils (#6778),5
"[FIX,TOPI] Default to inlining fused operations for conv NCHWc int8 (#10682)Inlining fused operations used to be the default and performs better onx86.",1
[tvmc] Fix inconsistent usage of host_name -> hostname (#8324)* This prevents a python error when running tuning via   and RPC tracker on tvmc. * Add test case,3
[PASS][TENSOR] Use correct select semantics (#2394),1
BugFix: CLI 'kubernetes cleanup-pods' should only clean up Airflow-created Pods (#15204)closes: #15193Currently condition if the pod is created by Airflow is not considered. This commit fixes this.We decide if the Pod is created by Airflow via checking if it has all the labels added in PodGenerator.construct_pod() or KubernetesPodOperator.create_labels_for_pod().,1
"Remove missing extras in Airflow 2.2 check (#25738)The Airflow 2.2 check install airflow with predefined set of extras,but some of those extras were missing in 2.2 because the providerswere not existing yet then. There was also a 'dot' instead of comain the list of extras between apache.beam and apache.atlas.It did not have too bad effect, because those dependencies arepulled in when the providers get installed, but it did not correctlytest the apache.atlas and apache.beam upgrade scenarios - from theversions that were installed in 2.2 to the latest version in main.This PR fixes it.",0
Update release_dockerhub_image.yml (#26033)Signed-off-by: sashashura <93376818+sashashura@users.noreply.github.com>Signed-off-by: sashashura <93376818+sashashura@users.noreply.github.com>,1
"Fix Elasticsearch external log link with ``json_format`` (#16467)When using json_format with elasticsearch remote logging theexecution date is sanitized, so we need to use the samesanitized value when building the log_id for external links.",2
Add state details to EMR container failure reason (#19579),0
"Enable USE_CUSTOM_LOGGING for Hexagon Launcher (#11185)* Enable USE_CUSTOM_LOGGING for Hexagon Launcher* Fix clang-format error* Remove ""ERROR:"" from LOG messages",2
[FRONTEND][TF] conv2d_transpose 'SAME' support kernel more than 1x1 (#4484)* [FRONTEND][TF] conv3d_transpose 'SAME' support kernel more than 1x1* revised per as review comments* add more fallback wolkaround to make all tests pass,4
[AIRFLOW-3268] Better handling of extras field in MySQL connection (#4113),1
"[TOPI] Add support for groupped conv3d (#9873)* [TOPI] Add support for groupped conv3dChange conv3d to use generic conv implementation which supports grouppedconvolutions. Also, remove support for non-float16 tensorcore operationsas they cause large degradation in accuracy. Generic conv now supportsautoscheduler.* correct none check* add tests for floordiv simplification* fixed incorrect test for autoscheduler* formatting* add groups to winograd* fix tensorcore* manually simplify index instead of relying on simplifier* formatting* add groups argument to conv3d_ncdhw_winograd_without_weight_transform* formatting",1
Testing,3
[AIRFLOW-1276] Forbid event creation with end_data earlier than start_date,5
chore: Refactoring and Cleaning Apache Providers (#24219),1
Add ODBC extra for the production image (#18407)The ODBC extra has been missing from #18382. This PR adds themissing extra and verifies if pyodbc is importable in the PRODimage.,2
Merge pull request #650 from patrickleotardif/patch-6Add URI encoding to Web UI actions,1
[AIRFLOW-5652] Add provider package to lint rules (#6326),1
[AIRFLOW-1389] Support createDisposition in BigQueryOperatorCloses #2470 from yu-iskw/bq-operator,1
Remove hard-coded container name for trino (#17525)This had no negative effect because we only run trino duringintegration tests but it could actually prevent two integrationtests run in parallel on the same machine if we choose otherwiseand it will look better in logs:```NAMEairflow-integration-mysql_pinot_1airflow-integration-mysql_statsd-exporter_1airflow-integration-mysql_redis_1airflow-integration-mysql_mysql_1airflow-integration-mysql_cassandra_1airflow-integration-mysql_grafana_1airflow-integration-mysql_openldap_1trinoairflow-integration-mysql_kdc-server-example-com_1airflow-integration-mysql_mongo_1airflow-integration-mysql_rabbitmq_1airflow-integration-mysql_airflow_run_908822c9c10f```,2
"Separate Installing from sources section and add more details (#18171)This PR separate installing Airflow from sources section and also fixes links for binary source, it had `-bin` suffix which we don't use anymore. And I have added section on verifying integrity. And add more details with examples",1
"[ONNX][TOPI] Support select_last_index for argmin/max (#8816)* support select_last_index for argmin/max* reverse conditions which made on accident* forward args in reduce.py* make proper nodes for reduction ops* remove complicated nested lambdas* fix lambda capture for conversion* forward more arguments* forward more args* enable onnx tests* wrapping casts to remove ambiguity* revert changes extraneous* correct incorrect attrs being used for ops* change attributes* remove old impl* register new attribute node* clean up test* reformat* reformat* coolio* stable comparison* casts to avoid ambiguity* casting more* correct arg passing* support select_last_index for argmin/max* reverse conditions which made on accident* forward args in reduce.py* make proper nodes for reduction ops* remove complicated nested lambdas* fix lambda capture for conversion* forward more arguments* forward more args* enable onnx tests* wrapping casts to remove ambiguity* revert changes extraneous* correct incorrect attrs being used for ops* change attributes* remove old impl* register new attribute node* clean up test* reformat* reformat* coolio* stable comparison* casts to avoid ambiguity* casting more* correct arg passing* fix broken input* OneElementReduceAttrs-->ArgReduceAttrs""* reduce boilerplate* change names* remove log statement* jostle ciCo-authored-by: Andrew Zhao Luo <andrewzhaoluo@system76-pc.localdomain>",5
[VirtualMachine] Zero copy in set_input when input is DLTensor (#11003)* method of creating of NDArray from external DLTensor was implemented* set input without copying for DLTensor source* code clean up* update description and comments after reviewCo-authored-by: Valery Chernov <valery.chernov@deelvin.com>,5
"Merge remote-tracking branch 'origin/feature_dry_run' into feature_dry_run# Please enter a commit message to explain why this merge is necessary,# especially if it merges an updated upstream into a topic branch.## Lines starting with '#' will be ignored, and an empty message aborts# the commit.",5
[RUNTIME] better parallel launcher and task distribution (#1026),1
[ARITH] Subspace division (#7760),5
"Update production-deployment.rst (#24121)The sql_alchemy_conn option is in the database section, not the core section.  Simple typo fix.",0
[AIRFLOW-6635] Speed up static checks (#7256),5
Chart: refactor webserver and flower networkpolicy (#16619)This adds support for overriding ports on the webserver and flowernetworkpolicies. This allows sidecars with webservers in them tofunction when networkpolicy is enabled.This also renamed the existing parameter used to define `from` in the networkpolicies ingress.,1
"Merge pull request #901 from criccomini/bigquery-operatorMake Google Cloud Storage download operator use a filename, not a fil‚Ä¶",2
[Rust][IRModule] Flesh out IRModule methods (#6741)* WIP* WIP* WIP* WIP* Disable WASM and fix rebase* Work on finishing tests* Make entire object system printable* Write some more tests for IRModule* All tests pass* Format* Restore module.cc* Bump syn,4
Add Community Page (#1063),1
[TEAM] jroesch -> Reviewer (#1746),5
[AIRFLOW-5537] Yamllint is not needed as dependency on hostIt used to be needed for pre-commits but is not needed any moreas it is automatically installed as dependency in the virtualenvcreated by pre-commit,1
Avoid loading executors in jobs (#7888),5
"[Ansor][AutoTVM v2.0] Phase 1: Add follow_split and follow_fused_split steps (#6142)* Add cache_read/cache_write step* Update* Add follow split and follow fused splitSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>Conflicts:src/auto_scheduler/compute_dag.ccsrc/auto_scheduler/transform_step.ccsrc/auto_scheduler/transform_step.htests/python/unittest/test_auto_scheduler_loop_state.py* add loop_state.pySigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Update* Update* Update state->current_compute_dag to Optional* Add some doc strings for Follow_Split and Follow_fused_splitSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Check code using c-lintSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add more doc strings and change the order for follow split.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add record test for follow_split and follow_fused_splitSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add record test for follow_splitSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add record test for follow_fused_split.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add test record for follow_fused_split1. delete a comment2. add ""fuse"" between follow_split and follow_fused_splitSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add doc strings for some functions and variablesSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Fix the code format in src/auto_scheduler/transform_step.hSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Update* Update doc* Update* Update* Fix follow_split and follow_fused_split record test.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Doc update* Update some doc stringsSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Fix code style and some function definitions.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* UpdateSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add comments on parameters.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Add more doc strings and fix some.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* UpdateSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* UpdateSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* UpdateSigned-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>* Update.Signed-off-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>Co-authored-by: chengfan.jcf <chengfan.jcf@alibaba-inc.com>Co-authored-by: jingbang.yjb <jingbang.yjb@alibaba-inc.com>",5
"[Topi][UnitTests] Parameterize conv2d and depthwise_conv2d tests (#8433)* [UnitTests][Topi] Updated test_topi_conv2d_nchw.py to have parametrized tests.- Better error messages, displays which workloads/targets failed and why.- Fixed bug in topi.nn.conv2d._get_workload exposed by the  parametrized tests.  Incorrect padding if the ""SAME"" parameter is  used with dilation>1.- Fixed bug in tvm.topi.x86.group_conv2d._get_default_config, missing  dilation parameter in call to _get_conv2d_workload.* [UnitTests][Topi] Parametrized the tests in test_topi_depthwise_conv2d.pyIn preparation for parametrizing to test on float16 as well.- Single test_conv2d test with parameters for layout/input sizes.- Extended the support for NCHWc layouts, so that they could be  included in the parametrization.  (Implemented  topi.testing.depthwise_conv2d_python_nchwc and  topi.nn.scale_shift_nchwc, added layout argument to  topi.nn.depthwise_conv2d._get_workload).Co-authored-by: Eric Lunderberg <elunderberg@octoml.ai>",5
[FRONTEND][TENSORFLOW]Add Split and realdiv op support (#2123)* Add Split and realdiv op support* Fix the pad calculation in the case of dilated convolution,0
"Add params dag_id, task_id etc to XCom.serialize_value (#19505)When implementing a custom XCom backend, in order to store XCom objects organized by dag_id, run_id etc, we need to pass those params to `serialize_value`.",2
Fix duplicate changelog entries (#19759)Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>,4
"Handle missing/null serialized DAG dependencies (#16393)When a serialized DAG is missing a ""dag_dependencies"" field (possiblewhen upgrading), PostgreSQL would return NULL when accessing the fieldwith a JSON function. This value would fail subsequent code, so we needsome logic to handle it.Fix #16356",0
"[AIRFLOW-260] Handle case when no version is foundIf no version is found, the ‚Äú.name‚Äù attribute can‚Äôt be accessed,causing a crash.",1
[FRONTEND] DarkNet Yolo2 Frontend Support  (#377),1
[AIRFLOW-42] Adding logging.debug DagBag loading stats (#1460)* Adding logging.debug DagBag loading stats* Linting* Fix py3* Tweaks,0
"[Relay][Topi] Add max mode to ROI align (#7440)* ROI align with max on cpu passes* onnx test file was not running gpu testsgit status!* all passing* fix lint* lint again* lint* lint* typo* remove import* fix import* add inf, -inf to hybridscript and respond to comments* shorten code* make atol lower",1
"Store per-task TIDeps in serialized blob (#12858)Without this change sensors in ""reschedule"" mode were being instantlyrescheduled because they didn't have the extra dep thatBaseSensorOperator added.To fix that we need to include deps in the serialization format (but tosave space only when they are not the default list). As of this PR rightnow, only built-in deps are allowed -- a custom dep will result in a DAGparse error.We can fix that for 2.0.x, as I think it is a _very_ uncommon thing todo.Fixes #12783",2
[AIRFLOW-3865] Add API endpoint to get python code of dag by id (#4687),2
fix linting command instruction (#1919),0
[Docker] Update onnxoptimizer to 0.2.7 (#12278)Co-authored-by: Christopher Sidebottom <chris.sidebottom@arm.com>,5
Make setup_kdc executable,1
Update ``dagbag_size`` documentation (#18824)Closes #10431,2
README.md touchup,0
This test (test_mark_success_on_success_callback) fails often (#8563)I am moving the test to quarantine for now.,3
[AIRFLOW-3190] Make flake8 compliant,1
"Chart: Only mount DAGs in webserver when required (#16229)Regardless of gitsync or persistence, 2.0+ does not need the DAGs in thewebserver.",2
[Runtime]Considering DLTensor's byte_offset in ZeroCopy function (#11340),1
Add how-to guide for hive operator (#21590),1
Move tests under correct test class (#22768),3
Improved telemetry for Databricks provider (#25115)* Improved telemetry for Databricks provider,1
[TensorIR] add TIRTextPrinter support for Block and BlockRealize (#7716)Co-authored-by: Junru Shao <junrushao1994@gmail.com>,1
applying local_infile flag,5
v0.4.4,5
[Relay] Incorporate TypeRelations into more tests (#1792),3
Add MicroTVM support for the STM32F746 Discovery board (#7225)* Add MicroTVM support for the STM32F746 Discovery boardSigned-off-by: Tom Gall <tom.gall@linaro.org>* Add reference to the discovery board in the docsSigned-off-by: Tom Gall <tom.gall@linaro.org>,2
"Refine LSTMBlockCell to support dynamic rnn (#5963)1. Refine conversion of `LSTMBlockCell`       1) Make its output follows definition in TensorFlow       2) Avoid introducing variables which doesn't match any placeholder nodes in TensorFlow graph    2. About change in test_forward_ptb       States nodes of LSTMBlockCell in this PB file  are actually Constant node.       TF can feed data to those Constant nodes but relay can't do that, so current conversion of LSTMBockCell introduces extra variables to solve this issue.       But this causes that relay IR doesn't match original TF graph. This PR solves this issue by convert those states node into placeholders.",0
Tensor API,5
Merging multiple sql operators (#9124)* Merge various SQL Operators into sql.py* Fix unit test code format* Merge multiple SQL operators into one1. Merge check_operator.py into airflow.operators.sql2. Merge sql_branch_operator.py into airflow.operators.sql3. Merge unit test for both into test_sql.py* Rename test_core_to_contrib Interval/ValueCheckOperator to SQLInterval/ValueCheckOperator* Fixed deprecated class and added check to test_core_to_contrib,3
[AutoScheduler] Print the time used for measurement (#6972)* [AutoScheduler] Print the time used for measurement* address comments,1
Changing the ascii header,4
Update to new helm stable repo (#12137)Switch out deprecated helm repo for new stable repo.- https://www.cncf.io/blog/2020/11/05/helm-chart-repository-deprecation-update/- https://helm.sh/docs/faq/#i-am-getting-a-warning-about-unable-to-get-an-update-from-the-stable-chart-repository,5
Updated manual PROD image push and verification steps (#15449),5
"[AIRFLOW-877] Remove .sql template extension from GCS download operatorPrior to this patch, if you use a templated file with a .sql extension,and it's templated, you'd receive an exception because Airflow would tryand load the file (that hasn't yet been downloaded) to template it. Thispatch fixes that.Closes #2083 fromsarfarazsoomro/sas/fix_gcs_download_op",0
Fix doc of strided_slice (#2103),2
Add @task.kubernetes taskflow decorator (#25663)Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>,1
[AIRFLOW-3924] Fix try number in alert emails (#4741)Alert emails sent via email_alert() have the correct try numberin the body of the text.Add a test to ensure the first email sent says `Try 1`.,1
Add scripts for automated build and testing (#10194),3
Add HashiCorp Vault Hook (split-out from Vault secret backend) (#9333)Split-off vault hook from vault secret backend,1
[LLVM] Fix build breaks from StringRef changes (#4923)- llvm::StringRef to std::string conversion is explicit now.Signed-off-by: Wei Pan <wpan11nv@nvidia.com>,4
[AIRFLOW-6862] Do not check the freshness of fresh DAG (#7481),2
Chart: Support elasticsearch connection scheme (#20564),1
Only pickle_info for non subdags,2
Fix typo in Breeze message on OSX (#15498)`ou` -> `you`,2
Dev: Update script used in generating issues for status of testing of RC (#21950),3
Show more DAGs on main page,2
"Make Kubernetes job description fit on one log line (#18377)Currently, when the Kubernetes executor creates a pod it prints a dictionary description of the pod across many lines (can easily be 20+ lines). This is fine if you're reading the log in a stream in a text file, but throws off log search tools like Kibana. A better practice would be to print the whole pod description on a single line. It is quite easy to prettify a dictionary if one wants to see it back in a more human-friendly form with the newlines.This update simply forces the log from this command into a single line.",2
[TE/TIR] Fix create_prim_func to properly handle rank 0 tensors. (#8128)We handle lowering rank 0 tensors to rank 1 buffers with a singleelement.,0
"[AIRFLOW-2335] fix issue with jdk8 download for ciMake sure you have checked _all_ steps below.- [x] My PR addresses the following [Airflow JIRA](https://issues.apache.org/jira/browse/AIRFLOW/)issues and references them in the PR title. Forexample, ""\[AIRFLOW-XXX\] My Airflow PR""    -https://issues.apache.org/jira/browse/AIRFLOW-2335    - In case you are fixing a typo in thedocumentation you can prepend your commit with\[AIRFLOW-XXX\], code changes always need a JIRAissue.- [x] Here are some details about my PR, includingscreenshots of any UI changes:There is an issue with travis pulling jdk8 that ispreventing CI jobs from running. This blocksfurther development of the project.Reference: https://github.com/travis-ci/travis-ci/issues/9512#issuecomment-382235301- [x] My PR adds the following unit tests __OR__does not need testing for this extremely goodreason:This PR can't be unit tested since it is justconfiguration. However, the fact that unit testsrun successfully should show that it works.- [ ] My commits all reference JIRA issues intheir subject lines, and I have squashed multiplecommits if they address the same issue. Inaddition, my commits follow the guidelines from""[How to write a good git commitmessage](http://chris.beams.io/posts/git-commit/)"":    1. Subject is separated from body by a blank line    2. Subject is limited to 50 characters    3. Subject does not end with a period    4. Subject uses the imperative mood (""add"", not""adding"")    5. Body wraps at 72 characters    6. Body explains ""what"" and ""why"", not ""how""- [ ] In case of new functionality, my PR addsdocumentation that describes how to use it.    - When adding new operators/hooks/sensors, theautoclass documentation generation needs to beadded.- [ ] Passes `git diff upstream/master -u --""*.py"" | flake8 --diff`Closes #3236 from dimberman/AIRFLOW-2335_travis_issue",0
"HttpHook: Use request factory and respect defaults (#14701)Use Request's session.request factory for HTTP request initiation, this will useenvironment variables and sensible defaults for requests.Also use verify option only if it is provided to run method, as requests libraryalready defaults to True.Our organization uses firewalls and custom SSL certificates to communicatebetween systems, this can be achieved via `CURL_CA_BUNDLE` and`REQUESTS_CA_BUNDLE` environment variables.  Requests library takes both intoaccount and uses them as default value for verify option when sending request toremote system.Current implementation is setting verify to True, which overwrites defaults andas results requests can not be made due to SSL verification issues. This PR isfixing the problem.",0
[Relay] Improve more operator mxnet frontend importer (#2772),2
[AIRFLOW-4246] Flask-Oauthlib needs downstream dependencies pinning due to breaking changes (#5045),4
"Adds back documentation about context usage in Python/@task (#18868)There were many questions recently along the line of""How do I access context from TaskFlow task"". Surprisingly,the paragraph about accessing current context was removed fromthe ""Concepts"" (where it was there for Airflow 2.0.0) but wasnever added to the ""TaskFlow Tutorial"" where it actually belongs.Also Python Operator's description about passing contextvariables as kwargs have been removed when `provide_context`parameter was removed (it was only present in the docstringof `provide_context` and you could likely deduce this behaviourfrom several examples, but it was not mentioned anywhere.This PR adds the description with examples to the Python operatoras well as adds similar description in TaskFlow tutorial, includingthe possibility of using `get_current_context` deep down thestack to retrieve the context variables even if they are notpassed via kwargs.",4
"[AIRFLOW-3813] Add CLI commands to manage roles (#4658)* [AIRFLOW-3813] Add CLI commands to manage rolesHere is the help text of the new command `airflow roles`:    usage: airflow roles [-h] [-c] [-l] [role [role ...]]    positional arguments:      role          The name of a role    optional arguments:      -h, --help    show this help message and exit      -c, --create  Create a new role      -l, --list    List rolesCreate is reentrant, i.e., it only adds a new role if it does not exist.* Update docs on role creation",1
Merge pull request #1003 from r39132/masterUpdate to the README such as adding Hootsuite,1
[PTX] Support mma.sp to use Sparse Tensor Cores and refactor mma codegen (#10339)* init* upd* upd* lint* lint again* upd* add m16n8k32 testcase* format* use make_tuple instead of initializer list* add metadata offset* upd* docstring and sanity* add u8s8s32 back* improvement* compatible #9727,1
Dataset doc update (#26232),5
correct state mentioned in logs,2
"Revert ""[AIRFLOW-1716] Fix multiple __init__ def in SimpleDag""This reverts commit e05254f8731ac55e169cdc581a38b0d3fe06267d.",4
[AIRFLOW-886] Pass result to post_execute() hookThe post_execute() hook should receivethe Operator result in addition to theexecution context.,1
Losser restriction for colorlog (#13176),2
Show current wheelhouse,1
[AIRFLOW-1724] Add Fundera to Who uses Airflow?Closes #2694 from andyxhadji/fundera,1
"[Hexagon] Move aot/graph_executor interactions into launcher (#10907)* [Hexagon] Move aot/graph_executor interactions into launcherFollow-up from https://github.com/apache/tvm/pull/10581, applyingsimilar changes to the AOT and graph executor interactions.  Thismoves the file management and upload/download from the unit tests intothe launcher.* Added Session.test_executor to avoid duplication in graph/aot test.* Resolve lint errors* Moved link flags workaround out of session, into create_aot_shared* Separated Session.get_*_executor and Session.get_executor_from_factory* Updated to resolve lint error",0
Fix D202 issue (#24322),0
add missing nullptr check (#4773),1
"[AIRFLOW-196] Fix bug that exception is not handled in HttpSensorDear Airflow Maintainers,Please accept this PR that addresses the following issues:- [*AIRFLOW-196*](https://issues.apache.org/jira/browse/AIRFLOW-196)If exception happens in poke function in HttpSensor, it is notwell handled that make the sensor finish successfully, which isincorrect obviously.Author: Junwei Wang <i.junwei.wang@gmail.com>Closes #1561 from junwei-wang/master.",5
Add right padding (#25554),1
Rename test_local_setting.py to test_settings.py (#12437),3
closes apache/incubator-airflow#1353 *PR abandonned by submitter*,5
"Initialize finished counter at zero (#23080)Sets initial count of task finished state to zero.This enables acquiring the rate from zero to one(particularly useful if you want to alert on any failures).We're using the Prometheus statsd-exporter. Since countersare usually used with a PromQL function like `rate`, it's importantthat counters are initialized at zero, otherwise when a taskfinishes the rate function will not have a previous value to comparethe state count to.For example, what we'd like to do:```sum by (dag_id, task_id) (rate(airflow_ti_finish{state='failed'}[1h])) >0```This tells us the failure rate of tasks over time.What I've tried to do instead to ensure the metric captures the changefrom zero to one:```(sum by (dag_id, task_id) (rate(airflow_ti_finish{state='failed'}[1h])) > 0) or sum by (dag_id, task_id) (airflow_ti_finish{state='failed'} != 0 unless (airflow_ti_finish{state='failed'} offset 1m))```Two useful posts on this subject:https://www.robustperception.io/why-predeclare-metricshttps://www.section.io/blog/beware-prometheus-counters-that-do-not-begin-at-zero/Co-authored-by: Bill Franklin <b.franklin@mwam.com>",2
Quelch deprecation warning in tests (#20900),3
[AIRFLOW-6247] Fix sort order in Alembic Migration template (#6809)* [AIRFLOW-6247] Fix sort order in Alembic Migration template,0
"Chart: Add tests for tolerations, affinity & node-selector (#15297)This commits adds tests and improve tests coverage for the Helm chartby testing that tolerations, affinity and node-selector can be modifiedfor the following components:- Flower- Pgbouncer- Scheduler- Statsd- Webserver- Worker",1
black format master (#6494),5
[Auto Scheduler]add task name during printing table info (#11098)* add task name during printing table info* address comments and fix lint* better look* fix linting* fix linting again,0
add num_runs query param for tree refresh (#16437)- add `num_runs` as a meta field to add to the tree refresh request,1
"Optimizes image verification steps. (#14780)So far we had matrix of builds that verified images - eachimage was verified by separate matrix-based job and thoseverifications were run after all images were alredy available.This step optimizes it. Those steps are run in the same jobas ""waiting for image"", also they run in parallel which willmake them a bit faster.This verification is fast and it can be run on any machinein parallel without any problems.",0
[AIRFLOW-5545] Fixes recursion in DAG cycle testing (#6175)* Fixes an issue where cycle detection uses recursionand stack overflows after about 1000 tasks(cherry picked from commit 63f1a180a17729aa937af642cfbf4ddfeccd1b9f)* reduce test length* slightly more efficient* Update airflow/utils/dag_cycle_tester.pyCo-authored-by: Kaxil Naik <kaxilnaik@gmail.com>* slightly more efficient* actually works this timeCo-authored-by: Daniel Imberman <daniel@astronomer.io>Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>,1
"Fix XCom.delete error in Airflow 2.2.0 (#18956)In Airflow 2.2.0 XCom.delete causes error, by trying to update dag_run table dag_id and execution_date columns to NULLs.sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column ""dag_id"" violates not-null constraint[SQL: UPDATE dag_run SET dag_id=%(dag_id)s, execution_date=%(execution_date)s WHERE dag_run.id = %(dag_run_id)s][parameters: {'dag_id': None, 'execution_date': None, 'dag_run_id': 2409}]Setting passive_deletes to the string value ‚Äòall‚Äô will disable the ‚Äúnulling out‚Äù",4
"Charting, may not belonng in Airflow on the long run...",1
"Add documentation and release policy on ""latest"" constraints (#21093)",3
[BUGFIX] [Hybrid Script] fix in-correct value index in hybrid script (#2268),0
[CPP_RPC] allow user supplied work dir (#7670)* [CPP_RPC] allow user supplied work dir* clang format,1
"[ci] Delay pytest errors until all invocations have run (#10521)* [ci] Delay pytest errors until all invocations have runThis makes it a little easier to gather CI signal on a PR by ensuring that all pytest invocations run. Currently pytest runs through to completion for a single invocation so some failures are gathered, but not all. This is annoying for development since its hard to guage how a PR actually fared in CI without seeing the full picture. This will increase demands on CI since failures won't cause the skip the following pytests, but we can monitor CI to see if this has a big impact on queue times.This also also kind of a stop-gap since this wouldn't be an issue if we used a single pytest invocation, but that is difficult since we rely on loading `tvm` multiple times over the course of the test suite.* Don't use a file to stash info between runs* Fix exit code handlingCo-authored-by: driazati <driazati@users.noreply.github.com>",1
[NNPACK] temporary disable nnpack test (#2115),3
fix migration script to support sqlite workaround,1
[Community] @Hzfengsy -> Committer (#8908),3
Useful help information in test-target and docker-compose commands (#8796)There was no useful information printed in test-target anddocker-compose commands. It's fixed now,0
Add dense schedules to __init__ for cpu (#2855)* Add dense schedules to __init__ for cpu* Add documentation for topi::shape* Add additional imports to topi CPU __init__.,5
Fixed numeric list (#17813),0
closes apache/incubator-airflow#1702 *PR abandonned by submitter*,5
"Introduces separate runtime provider schema (#13488)The provider.yaml contains more information that required atruntime (specifically about documentation building). Thosefields are not needed at runtime and their presence is optional.Also the runtime check for provider information should be morerelexed and allow for future compatibility (withadditional properties set to false). This way we can add new,optional fields to provider.yaml without worrying about breakingfuture-compatibility of providers with future airflow versions.This changei restores 'additionalProperties': false in themain, development-focused provider.yaml schema and introducednew runtime schema that is used to verify the provider info whenproviders are discovered by airflow.This 'runtime' version should change very rarely as change toadd a new required property in it breaks compatibility ofproviders with already released versions of Airflow.We also trim-down the provider.yaml file when preparing providerpackages to only contain those fields that are required in theruntime schema.",1
Fix compile warnings. (#6204),2
[AIRFLOW-1326][[AIRFLOW-1326][AIRFLOW-1184] Don't split argument array -- it's already an array.[Closes #2382 from ashb/spark-submit-operator-preserve-spaces,1
Adding a config param to not load example dags,2
Proper sqlalchemy syntax for desc,5
"Fixed runs-on for non-apache repository (#14737)The change #14718 by mistake left the 'self-hosted"" runs-on in case ofpush or schedule. This caused failures on non-apache repositories.",0
Y labels on charts,2
[RUNTIME] Add System Lib (#227)* [RUNTIME] Add System Lib* lint* lint* fix compile,0
Correctly set `dag.fileloc` when using the `@dag` decorator (#16384)Previously this was always showing up as `airflow/models/dag.py`!,2
[AIRFLOW-XXX] Add Chao-Han to committer list (#5846),1
"Improved MLF to contain workspace info (#7938)* Improved MLF to contain workspace infoAdded functionality to calculate workspace, io and constantmemory required by each primfunc and main function. Moreover,the workspace information required by each primfunc and mainis reported in metadata.json in the Model Library Format(MLF).- added functionality to record tir and relay primfuncs- added tests for model_library_format changesChange-Id: Ib4a8b787345aa35f8a1645e8a648fad84de37bce* Improved MLF to contain workspace info* disable AoT for now* addressing commentsChange-Id: I5f041ec461b02dac6ea9c96ea50eb400d55eef53* Improved MLF to contain workspace info* addressed comments* added aot executor supportChange-Id: I9b54a7939d8ccb3c6ce0454f0fe62866ac66eb5c* Improved MLF to contain workspace info* removed redundant utils.pyChange-Id: I256dd88fab31a595bf9509bd1c4ab59b0c145b1e* Improved MLF to contain workspace info* removed redundant ffi apiChange-Id: I9ad6795aa839edfdfd05b902d4531fb0a20e894d",4
[AIRFLOW-1156] BugFix: Unpausing a DAG with catchup=False creates an extra DAG run (#8776),1
"[Torch, Quantization] Necessary workaround to prepare for 1.6 update (#6602)* add support for 1.6 quantized models* fix lint* move version check function to a common utils* fix lintCo-authored-by: masa <masa@pop-os.localdomain>",0
"[Frontend][Tensorflow] Support SAME padding for dynamic h, w when stride == 1 (#7885)* Support SAME padding for dynamic workloads when stride == 1* Fix lint* Fix lint",0
Fixing the wiring,0
[AIRFLOW-6977] Fix BigQuery DTS example DAG (#7612),2
[COMMUNITY] Junru's and Wuwei's PGP key for ASF release (#9488)* add PGP into KEYS* add wuwei's pgp as well,1
[AIRFLOW-1384] Add ARGO/CaDC as a Airflow userCloses #2434 from abhijeetdhumal/master,1
[AIRFLOW-5601] Use built-in pagination mechanism in MLEngine hook (#6267),1
checked split,5
Added a helper function that dumps Node to stderr (#1703),1
Dataflow operators don't not always create a virtualenv (#10373),1
allow constant value let binding in script (#11115),1
Support dequantizing scalar inputs (#8207),1
"[Relay/TOPI][OP] Add meshgrid op in Relay, TOPI, Pytorch frontend (#5961)* Add meshgrid op with pytorch importer* Fix c++ lint* Fix pylint* Meshgrid: add scalar test for pytorch, add topi python wrapper* Add indexing mode attr.* Add MeshgridAttrs python binding* c++ lint",5
add symbol::GetChildren (#104),1
Add initial support for quantized transpose convolution in Relay (#6899)* Add initial support for quantized transpose convolution in RelayThis work is based on @jainris initial PR: https://github.com/apache/incubator-tvm/pull/6523I added a relay.qnn.conv2d_transpose node. The strategy I followed is toconvert to int16 and invoke nn.conv2d_transpose (which already exists inrelay). Main changes:- The node declaration lives in relay/qnn/op/convolution_transpose.cc- Cast int8->int16 and subsequent offset removal is in tvm/relay/qnn/op/legalizations.py.- I added and tested the operator in the tflite front-end- I added a unit-test in Relay for qnn.conv2d_transposeCo-authored-by: Rishabh Jain <jainris@users.noreply.github.com>* Fix linting* Addressing review commentsCo-authored-by: Rishabh Jain <jainris@users.noreply.github.com>,1
"Revert ""upgrade ci lint docker file (#11734)"" (#11787)This reverts commit 7bfbc74c65684d1e25e235335da41c94372a561a, as itgenerates near 500 code violations when PyLint was updated from 2.4.4 to2.9.3.Issue #11785 for details.",0
Fix typo in ``NotPreviouslySkippedDep`` (#13933),2
"Allow publishing Docker images with more pre-release versions (#18170)Without it, it currently fails with the following:```Building and pushing 2.2.0b1 Airflow PROD image for 3.9ERROR: Bad value for install-airflow-version: '2.2.0b1'. Only numerical versions allowed for PROD image here'!ERROR: The previous step completed with error. Please take a look at output above###########################################################################################                   EXITING WITH STATUS CODE 1###########################################################################################Finished the script build_dockerhub.shElapsed time spent in the script: 0 secondsExit code 1```",2
"Add a possibility to switch back to building images by secret (#10509)You can now define secret in your own fork:AIRFLOW_GITHUB_REGISTRY_WAIT_FOR_IMAGEIf you set it to ""false"", it skips building images in separateworkflow_run - images will be built in the jobs run in theCI Build run and they won't be pushed to the registry.Note - you can't have secrets starting with GITHUB_, that's whythe AIRFLOW_* prefix",0
"[C Codegen] Remove global packed variables when interface_api=""packed"" and target=""c"" (#10645)* fix pack global variables* address comments",1
"[AIRFLOW-6699] Parameterize weekday sensor tests (#7316)Using the parameterized library, consolidate the true or ""happy path""tests, reducing overall code to maintain and showing each test case inone list of tuples.",3
Fix typo in docs/stable-rest-api/redoc.rst (#10248)`shpinx` -> `Sphinx`,2
"[TVMScript] Printer Frame (#12366)This PR:- Implement Frame for the TVMScript Unified PrinterCompared to the prototype version, this:- Removes the dependency of VarTable (SymbolTable) from Frame- Adds a callback array to the Frame base class so that VarTable can add callback to clean variable when Frame goes out scopeTracking issue: https://github.com/apache/tvm/issues/11912",0
"[AIRFLOW-544] Add Pause/Resume toggle buttonAdd Pause/Resume toggle button to DAG detailspage, so one does notneed to go back and forth to view the details anddo the action.Closes #1818 from msumit/AIRFLOW-544",2
[AIRFLOW-XXX] Fix Flake8 issues,0
"Use print() function in both Python 2 and Python 3 (#3440)Discovered via: __flake8 . --count --select=E9,F63,F72,F82 --show-source --statistics__Legacy __print__ statements are syntax errors in Python 3 but __print()__ function works as expected in both Python 2 and Python 3.",1
"Enable pushing early image cache to ghcr.io registry (#26119)In order to react quicker to changes in setup.py, setup.cfg andDockerfiles, we can push an early image cache to the ghcr.io cache.This build is done way before constraints are regenerated so it isusing the ""current"" constraints at the moment the merge happens.This should be safe - if the image fails to build (we ignore that)the cache will not be pushed, but if it will, then even if we mergea new commit quickly and the rest of the build is cancelled, thecache will be refreshed with new Dockerfile/setup.py/setup.cfg andthe subsequent builds will run much faster.",1
[BYOC] Pattern Language MergeComposite (#5656)* Pattern Language MergeComposite* fix DNNL pattern* Use builtin binary operator syntax for demo* Improve unit test,3
Ensure Kerberos token is valid in SparkSubmitOperator before running `yarn kill` (#9044)do a kinit before yarn kill if keytab and principal is provided,1
Merge pull request #117 from mistercrunch/colorsShowing the number of task instance by state,1
"Relax Flask-Appbuilder version to ~=2.3.4 (#8857)""Bump jQuery to 3.5"" was reverted. And so we can upgrade and remove email_validator dependencySee also: https://github.com/dpgaspar/Flask-AppBuilder/blob/master/CHANGELOG.rst#improvements-and-bug-fixes-on-234",4
[Hexagon]Refactor Hexagon_SDK_PATH (#11282)* refactor HEXAGON_SDK_PATH and remove HEXAGON_GTEST,3
Hotfix CI (black check not caught by PR CI) (#11056),0
"[Fix,Conda] update conda download url (#6760)Co-authored-by: Shibui Yusuke <yusuke.shibui@ShibuinoMacBook-Pro.local>",5
Adds --install-wheels flag to breeze command line (#11317)If this flag is specified it will look for wheel packages placed in distfolder and it will install the wheels from there after installingAirflow. This is useful for testing backport packages as well as in thefuture for testing provider packages for 2.0.,1
Update filepaths in boring-cyborg.yml (#14628)- Remove entries for non-existing files- Add more files for kubernetes labels,2
[TOPI] Fix CUDA Library Tuning (#6132),0
Adding a link to docker-airflow,2
[AIRFLOW-6120] Rename GoogleCloudBaseHook (#6734)* [AIRFLOW-6120] Rename GoogleCloudBaseHook,5
AIRFLOW-167: Add dag_state option in cli,2
[AIRFLOW-6656] Fix AIP-21 moving (#7272),4
closes apache/incubator-airflow#1637 *Closed for inactivity*,5
Log memory usage in CgroupTaskRunner (#21481),1
[AIRFLOW-1157] Fix missing pools crashing the schedulerThrow a warning when a pool associated with a TaskInstancedoesn't exist instead of crashing the scheduler.Use the default value of 0 slots for non-existentpools.Closes #3002 from iansuvak/1157_nonexistent_pool,1
Upgrade Windows build to use windows-2019 runner (#10585)* Switch to windows-2019 build.* Use Visual Studio 2019 generator.,1
Log filename template records (#20165),2
[ARITH] RewriteSimplifier: improved cmp simplification (#2851),1
new company + link to pitfallsallegro added as a company using airflow + link to common pitfalls,2
[AIRFLOW-6262] add on_execute_callback to operators (#6831),1
"Fix test_external_codegen, broken by #8591 (#8630)",3
Merge pull request #136 from mistercrunch/dag_paramsAdding DAG level params,2
Merge pull request #1 from mtustin-handy/mtustin-handy-mysql-commit-patchFix issue https://github.com/airbnb/airflow/issues/459 - mysql error 2014,0
[AIRFLOW-XXX] Add protocol transfer operators (#6208),1
Update versions in UPDATING.md for 2.0.0b1 release (#12244),5
Change CloudDatastoreExportEntitiesLink to StorageLink,2
[OP] Conv2d and Depthwise Conv2d for Raspberry Pi (#49)* [TUTORIAL] ImageNet Inference on Raspberry Pi* Update tvm,5
"Fix typos: duplicated ""the"" (#10647)",2
[AIRFLOW-1692] Change test_views filename to support WindowsCloses #2673 from NielsZeilemaker/AIRFLOW-1692,1
"Increase default `worker_refresh_interval` to `6000` seconds (#14970)The default value for `[webserver] worker_refresh_interval` was `30` seconds forAirflow <=2.0.1. However, since Airflow 2.0 DAG Serialization is a hard requirementand the Webserver used the serialized DAGs, there is no need to kill an existingworker and create a new one as frequently as `30` seconds.",1
[AIRFLOW-4973] Add Cloud Data Fusion Pipeline integration (#7486),5
1.7.1.1,5
update remaining old import paths of operators (#15127),1
"Produce less verbose output when building docker mount options (#9103)The previous method of generating this list had two ""problems""/nigglesthat this PR solves, when running with VERBOSE=true- Firstly, LOCAL_MOUNTS was set at the top level, so running with  `set -x` produced 30 extra lines of output.- Because of the `while read` used, it created 4 or 5 lines _per_ mount,  resulting in a lot verbose output.Nothing I've changed here is ""critical"", it's just making it a biteasier to see with the debug output what is going on, by running fewercommands.I have also expanded the BATS test a little bit to check each pair (`-v`and its following option)",3
[TIR][REFACTIR] Update TIR nodes std::string->String. (#5793)This PR updates the remaining TIR node's member to useString instead of std::string.,1
[AIRFLOW-6866] Fix wrong export for Mac on Breeze (#7485),0
Update chart readme to remove astronomer references (#13210),4
sftp_to_s3 stream file option (#17609),2
"Update `SimpleHttpOperator` to take auth object (#15605)A `requests.auth.AuthBase` object is not passed through from the`SimpleHttpOperator` to the underlying `HttpHook`, thus if you want touse the `SimpleHttpOperator` but have a custom auth_type, you mustinherit from it and override the execute method.  Update the operatorto take this parameter.",2
Fix Experimental API Client (#9849),0
Remove redundant section from dev/README.md toc (#10689),2
[Relay][Pass] Avoid FoldConstant folding some ops (#4245)* [Relay][Pass] Avoid FoldConstant folding some ops* rename,4
Use correct connection id,1
"[AIRFLOW-XXX] Fix typo in python_sensor.py docstring (#6521)I fixed typo from ""the the"" to ""the"".",2
Add a retry with wait interval for SSH operator #14489 (#19981),1
"Fix rendering nested task fields (#18516)When we are referring ``{{task}}` in jinja templates we can alsorefer some of the fields, which are templated. We are notable to solve all the problems with such rendering (specificallyrecursive rendering of the fields used in JINJA templating mightbe problematic. Currently whether you see original, or renderedfield depends solely on the sequence in templated_fields.However that would not even explain the rendering problemdescribed in #13559 where kwargs were defined after opargs andthe rendering of opargs **should** work. It turned out thatthe problem was with a change introduced in #8805 which madethe context effectively holds a DIFFERENT task than the currentone. Context held an original task, and the curren task wasactually a locked copy of it (to allow resolving upstreamargs before locking). As a result, any changes done byrendering templates were not visible in the task accessedvia {{ task }} jinja variable.This change replaces the the task stored in context with thesame copy that is then used later during execution so thatat least the ""sequential"" rendering works and templatedfields which are 'earlier' in the list of templated fieldscan be used (and render correctly) in the following fields.Fixes: #13559",0
"[Hexagon] Add optimized schedule for nn.pad (#12714)Motivation:In case of quantized models nn.pad operation typically is not fused with QNN opsand lives as a standalone operation. In this case it uses default injectiveschedule for Hexagon target and it is not optimized very well (based onanalysis of real models like ResNet50 INT8).What was done:New schedule for Pad operation was implemented instead of default injective schedule.For Hexagon target injective schedule does fusion of all axis and vectorizationon 128/64/32 (depends on dtype). It works fine for Add, Sub, etc... but not for Pad.New optimized schedule does these steps (fusion+vectorization) only if last tensordimension is divisible by 128/64/32 (depends on dtype). It was done only for Hexagon,for other targets (x86, cuda, etc.) there is no changes and it uses default injectiveschedule.Benchmark results on Snapdragon 888:4d NHWC layout with ((0, 0), (1, 1), (1, 1), (0, 0)) padding, ""uint8"" dtype:shape              | default schedule, ms | optimized schedule, ms |      speedup      |-------------------|----------------------|------------------------|-------------------|(1, 112, 112, 32)  |         10,03        |           0.2          |    50.1x times    |(1, 56, 56, 128)   |         0,099        |          0,085         |  ~1x (no speedup) |---------------------------------------------------------------------------------------|4d NCHW layout with ((0, 0), (0, 0), (1, 1), (1, 1)) padding, ""uint8"" dtype:shape              | default schedule, ms | optimized schedule, ms |      speedup      |-------------------|----------------------|------------------------|-------------------|(1, 128, 56, 56)   |         10.96        |          1.38          |    7.9x times     |(1, 32, 126, 126)  |          1.66        |          1.58          |  ~1x (no speedup) |(1, 32, 128, 128)  |         13.98        |          2.66          |    5.25x times    |---------------------------------------------------------------------------------------|5d NCHWc layout with ((0, 0), (0, 0), (1, 1), (1, 1), (0, 0)) padding, ""uint8"" dtype:shape              | default schedule, ms | optimized schedule, ms |      speedup      |-------------------|----------------------|------------------------|-------------------|(1, 4, 56, 56, 32) |          6.39        |          0.29          |     22x times     |(1, 56, 56, 128)   |          0.15        |          0.15          |  ~1x (no speedup) |---------------------------------------------------------------------------------------|Summary:For some input tensors we get up to 50x times speedup, for other performance is the same.No performance degradations were detected.",5
Bump path-parse from 1.0.6 to 1.0.7 in /airflow/ui (#25803)Bumps [path-parse](https://github.com/jbgutierrez/path-parse) from 1.0.6 to 1.0.7.- [Release notes](https://github.com/jbgutierrez/path-parse/releases)- [Commits](https://github.com/jbgutierrez/path-parse/commits/v1.0.7)---updated-dependencies:- dependency-name: path-parse  dependency-type: indirect...Signed-off-by: dependabot[bot] <support@github.com>Signed-off-by: dependabot[bot] <support@github.com>Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>,1
Allow blank lines after docstring (#21477),2
Fix Static-check failure (#12356),0
Chart: Update default Airflow version to 2.2.2 (#19603),5
WIP: Add how_to readme to install tvm with nnpack support (#610)* feat(docs) add how_to for tvm install with nnpack support* feat(docs) change python package paragraph* feat(doc) remove unsure sentence* add comments on nnpack usage vs TVM* remove mxnet nnpack tips for nthread change,4
"Add extra sync when adding executable flag to installation scripts (#20987)Seems that when AUFS is a backing storage for Docker, changingthe script to executable and executing it right after during thebuild phase might cause an error: 'text file busy'https://github.com/moby/moby/issues/13594Workaround for that is to add extra `sync` command after changingthe executable flag to make sure that the filesystem change haspropageted to the underlying AUFS storage.This PR adds the sync and also makes sure that both CI And PRODimage use same formatting, executable bits and `&&` betweencommands rather than `;`. The `&&` is better to separate thecommands because it will not continue with execution steps in thesame bash command after previous command fails. This causedconfusion as to what is the reason for docker build failure.The problem was raised in the #20971 discussion.",0
[Arith] Fix floormod rewrite simplify rule (#10626),0
Update pre-commit checks (#15583),5
Fix incorrect Env Var to stop Scheduler from creating DagRuns (#8920),2
"[RUNTIME] Update graph runtime to rely on smarter planner, add get_input (#990)",1
Enable miopen transpose convolution and fp16 support (#3952)* Enable miopen transpose convolution and fp16 support* linter,1
Add missing args to `airflow clear`Running `airflow clear dag_id` from the CLI fails because the`only_failed` and `only_running` args weren‚Äôt supplied by the factory.,1
formatting issue,0
"Reduce ""start-up"" time for tasks in CeleryExecutor (#11372)This is similar to #11327, but for Celery this time.The impact is not quite as pronounced here (for simple dags at least)but takes the average queued to start delay from 1.5s to 0.4s",2
[DOC] Fix typos in tutorials (#287),2
Remove clang-7 requirement for vulkan. (#8107)* Breaks build with new 18.04 ci-gpu docker container.,2
"update default key for xcom_pull, and docs/example",2
Add DANA Indonesia to the Companies uses Airflow (#13995)* Add DANA Indonesia to the Companies uses Airflow* Fix sorting order,0
"[BugFix][VTA] Fix vta_conv2d crash issue after change vta_config.json configuration. (#3213)Issue:Once change LOG_BLOCK_IN or LOG_BLOCK_OUT into > 4 value, when run vta‚ÄúSimple Matrix Multiply‚Äù or load vta, vta would crash at vta_conv2d.py.Analysis:This issue caused by resnet18 logic of vta_conv2d.py which havein_filter minmum size that is 16. > 4 value would cause such in_filtercheck failed then make xfer_size be empty and find_schedules functionreturn a empty list finally cause crash.Solution:add the empty list check.",1
Removing older Object detection TFlite test (#5477),3
Support query timeout as an argument in CassandraToGCSOperator (#18927)Support query timeout as an argument in CassandraToGCSOperator (#18927),1
[AIRFLOW-4069] Add Opsgenie Alert Hook and Operator (#4903),1
"Add ADR describing reasoning why we build images and security of it (#20407)* Add ADR describing reasoning why we build images and security of itThe ADRs document the decision why Docker imaages are used as commonenvironment for CI and development environment, and also why buildingimages should be done in a secure way.",1
Merge pull request #4 from mistercrunch/config_parserintegrating config parser to read config values from a file,2
Add doc and sample dag for S3CopyObjectOperator and S3DeleteObjectsOperator (#22959),4
"Aws secrets manager backend (#17448)With this proposed modification, you can use AWS Secrets Manager using keys and values and have some kind of freedom to choose different words for each key to make the get_conn work.",1
replace main_session with @provide_session,1
"Increase the default ``min_file_process_interval`` to decrease CPU Usage (#13664)With the previous default of `0`, the CPU Usage mostly stays around 100.As in Airflow 2.0.0, the scheduling decisions have been moved out fromDagFileProcessor to Scheduler, we can keep this number high.closes https://github.com/apache/airflow/issues/13637",0
Set grant type of the Tabular hook (#25099),1
[AIRFLOW-3573] Remove DagStat table (#4378)* Remove DagStat usage* Remove tests* Remove dag_stat table from db* Removed dagstat class* Revert change* Fixing test,3
Adding item to TODO,2
Modified pick best to accumulate the best configurations from both the input and output file. (#3225),2
Add GCSToPrestoOperator (#21084),1
[AUTOTVM] typo (#2478)* [AUTOTVM] typo* trigger CI,2
[SCHEDULE] Fix boundary check (#2126)* Fix boundary check* Add unittest,3
Fix small typo in nn.conv2d_gemm_weight_transform (#5925)* Fix small typo in nn.conv2d_gemm_weight_transformChange-Id: I7844d898ebf82592f78f478982262ef95f83cc3e* Add TOPI conv2d_gemm unit testsChange-Id: I9ed82a68acffcf0dd9720781f8be4aada9d8e6e4,3
[AIRFLOW-1556][Airflow 1556] Add support for SQL parameters in BigQueryBaseCursorCloses #2557 from rajivpb/sql-parameters,2
Fix parenthesis preventing Keda ScaledObject creation (#13183),1
Fix stray order_by(TaskInstance.execution_date) (#21705),5
[AIRFLOW-3096] Reduce DaysUntilStale for probot/stale,5
example,5
Doc: Update description for executor-bound dependencies (#22601)These suggestions were missed in https://github.com/apache/airflow/pull/22573- https://github.com/apache/airflow/pull/22573/files#r837754616- https://github.com/apache/airflow/pull/22573/files#r837755144- https://github.com/apache/airflow/pull/22573/files#r837755355,2
support slicing with out of order axes (#8959),1
[CMSIS_NN] Align CMSIS-NN in TVM to TFLu SHA (#12030)* [CMSIS_NN] Align CMSIS-NN in TVM to TFLu SHAChange-Id: I7bb3b92196ad9f1a22eee87d704545e72b79ca0b* Updated CMSIS SHA to CMSIS TOTChange-Id: I0fec18e823478da991d49aa782f58f1c2f6212ba,4
Add waiting for ARM instance docker connection (#22672)One of the recent rebases lost waiting for the connection on SSH,2
Documenting the now broken down packages,2
Adding task instance state change to view.,4
Modify debug output (#10372)1. Modify debug output to make it more readable3. Replace magic number with a variable `error_ct_threshold`3. Add function to set error counter threshold externally for debug purposes,0
Add Kogan.com to the list of users,1
Fix broken Triggering Dag from UI functionality (#8148),1
[VTA] Update docker for TSIM based simulation (#4674),2
Fixing failing quarantined test cases in test_task_command (#19864),3
"Support PyTorch grid_sample  (#10184)* [relay] Fix stack overflow in device_planner observed on windows due to recursive function calls.* Revert ""[relay] Fix stack overflow in device_planner observed on windows due to recursive function calls.""This reverts commit 70581364771e2415b37b202a9fa6a937f275cfc6.* [PyTorch] Add grid_sample with zeros and border padding mode for PyTorch.",1
Fix mypy errors in providers/amazon/aws/operators (#20401),1
"Introduce RESTARTING state (#16681)closes: #16680This PR makes sure that when a user clears a running task, the task does not fail. Instead it is killed and retried gracefully.This is done by introducing a new State called RESTARTING. As the name suggests, a TaskInstance is set to this state when it's cleared while running. Most of the places handles RESTARTING the same way SHUTDOWN is handled, except in TaskInstance.is_eligible_to_retry, where it is always be treated as eligible for retry.",1
"Update modules_management.rst (#21889)need to add packages in setup.py, otherwise the package can not be found",1
[Doc][AutoTVM] Fix bugs that override n_trials (#4842),0
[AIRFLOW-6460] Reduce timeout in pytest (#7051),3
[AIRFLOW-XXX] Fix BashOperator Docstring (#4052),2
Improve graph view load time for dags with open groups (#17821)* Only draw once during initial graph setupThe previous behavior could cause significat slowness for when loadingthe graph view for large dags with many task groups.* Improve name and fix camelCased* Fix indent* PR suggestions remove args,4
Fix broken tests after URL restructure PR (#21489),3
Move Backport Providers docs to our docsite (#11136),2
update docs for installation for CUDA (#3832),2
[Relay][Frontend] Caffe2 Support (#2507)* [Relay][Frontend] Add Caffe2 Support* [Relay][Frontend] Add Caffe2 Support (fix unsed import)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 model import)* [Relay][Frontend] Add Caffe2 Support (fix model install and reflect code reviews)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 model import)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 model import)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 model import)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 frontend import)* [Relay][Frontend] Add Caffe2 Support (rename function name in test_forward)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 model import)* [Relay][Frontend] Add Caffe2 Support (fix caffe2 model import)* [Doc] Caffe2 frontend tutorial* [Doc] Caffe2 frontend tutorial* [Doc] Caffe2 frontend tutorial* [Relay][Frontend] Add Caffe2 Support (remove unsed file),2
Add the dag_id to AirflowDagCycleException message (#26204),2
"More sensible docker caching strategy for Prod images (#9547)Local caching is now default strategy when buildingthe Production image.You can still change it to pulled - similar to CI buildsby providing the right build flag and this is whatis used in CI by default. The flags in Breeze are now updatedto be more eplanatory and friendly (build-cache-*) and a flagfor ""disabled"" cache option is added as well.Also the Dockerfile and Dockerfile.ci files are not neededany more in the docker context. They used to be needed whenwe built the Kubernetes image in the container, but sincewe are now using production image directly - we do not needthem any nmore.Combining setting the default strategy to local and removingthe Dockerfile from the context has the nice effect that youcan iterate much faster on the Production image withouttriggering rebuilds of half of the docker imageas soon as the Dockerfile changes.",4
"Adding max_partition macro, fixing bugs",0
[AIRFLOW-6436] Add x_frame_enabled config in config.yml (#7024),5
[AIRFLOW-XXX] Remove smart quotes from default config (#5471)It causes problems on Python2 trying to read the file as ASCII,2
"[RFC][RUNTIME] Introduce new object protocol. (#4115)* [RUNTIME] Introduce new object protocol.This PR introduces a new object protocol to unify the node and object.We also updated the existing runtime::vm code to make use of the new system.Update to the node will be done in a follow up PR.Other changes:- Remove object related code in json serializer as that code logic was not complete  and we have a separate serializer for VM, can revisit later.* address review  comment* Fix the child slot logic",2
Docs: Fix rendering of ``PYTHONPATH`` values (#16664),0
"Uses DOCKER_TAG when building image in DockerHub (#12050)DockerHub uses `hooks/build` to build the image and it passesDOCKER_TAG variable when the script is called.This PR makes the DOCKER_TAG to provide the default valuei for tagthat is calculated from sources (taking the default branch andpython version). Since it is only set in the DockerHub build, itshould be safe.Fixes #11937",0
Fix documentation error in `git_sync_template.yaml` (#13197)When reading the documentation (https://airflow.apache.org/docs/apache-airflow/stable/executor/kubernetes.html?highlight=pod_override#pod-template-file) I noticed that there are errors in `volumes` and `volumeMounts` sections.,0
Fix Minor Bugs in Apache Sqoop Hook and Operator (#16350),1
Set `webhook_endpoint` as templated field in `DiscordWebhookOperator`(#22570),1
"[Bugfix] Simultaneous layout transform and axis separators. (#10553)Previously, SchedulePostProcToPrimFunc would first generate the mapfrom buffer object to layout transformation, then would update bufferswith the axis separators.  However, it failed to replace the bufferobjects in the layout transformation map, so the transformationwasn't applied.This PR correctly updates the layout transformation map, andadds a unit test to catch this failure mode.",0
[AIRFLOW-5555] Remove Hipchat integration (#6184),4
Refine 'task not mapped' warning (#22678),2
Few docs fixes (#2703),0
[TFLite] Support TFLite FP32 Relay frontend. (#2365)* Support TFLite FP32 Relay frontend.* Fix lint issue* Remove unnecessary variables and packages* Add method doc string* Fix capital letter of method doc string* Add TFLite FP32 Relay frontend based on latest code* Merge the latest code* Solve cython issue with relay type inference* Modify code based on suggestions,5
Doc: Fix incorrect filename references (#20277)Minor typo corrections. I changed the filenames in the example folder structure instead of the later references to be consistent with the other examples in the documentation.,2
docstring,2
[PASS][ConvertLayout] Fixes AttributeError during ConvertLayout to NHWC (#6419)Fixes an issue described in #6410. In order to retrieve the shape a tensor `checked_type` should be used.Change-Id: I991d194d9cc15ee20464ff2e239fd05c035000c8,4
closes apache/incubator-airflow#3409 *Closed for inactivity*,5
¬µTVM RPC server and Part 1 of AutoTVM compilation infrastructure (#6334),5
Fix broken link to Trigger Rules (#25840)The link has been replaced by cross-referencing.,2
Made use of authentication consistent (#10610)Fixed a couple of places where authorization was used instead of authentication,1
Doc: Add FAQ to speed up parsing with tons of dag files (#17519)This feature was added in https://github.com/apache/airflow/pull/16075. This PR adds it to docs to avoid situations like https://github.com/apache/airflow/issues/17437closes https://github.com/apache/airflow/issues/17437,0
[AIRFLOW-1776] Capture stdout and stderr for loggingThe new logging framework was not properlycapturing stdout/stderroutput. Redirection the the correct loggingfacility is required.Closes #2745 from bolkedebruin/redirect_std,1
Tiny doc fixes after releasing backports (#14173),0
Adding an entry for Variables in the docs,2
[FRONTEND][TENSORFLOW] fix the convertion of sum and add testcase for it (#1654)* [TENSORFLOW] fix the convertion of sum and add testcase for it* delete checking tyoe of axis and divide reduce test,3
"[Docker][Vulkan] Allow Vulkan GPU access in docker container. (#8784)- The environment variable NVIDIA_DRIVER_CAPABILITIES must include  ""graphics"" in order to expose Vulkan drivers to the container.  This  is added both to Dockerfile.ci_gpu for future image builds, and to  docker/bash.sh for compatibility with current images.- The configuration files needed by the vulkan launcher and glvnd must  be exposed to the container.  These are only included in  `docker/bash.sh`, as they may vary by host and so cannot be baked  into the image.",2
[TFLite] Support quantized EQUAL op in TFLite frontend (#11520)* [TFLite] Support quantized EQUAL op in TFLite frontendSupport EQUAL quantization operation conversion as part of issue #9187* [TFLite] Support quantized EQUAL op in TFLite frontendUpdate elementwise quantized test for EQUAL opChange-Id: I3897d1ac07051ebfc10356ad45397117b592f878,4
Fixing recursion max_depth bug in deepcopying DAGs,2
Increase typing coverage for Elasticsearch (#9911),3
"Revert ""[AIRFLOW-XXXX] Prevent Docker cache-busting on when editing www templates (#7427)""This reverts commit 3eb30ed12ced9b776e2588f694d90412071f41f0.",4
name mismatch (#21055),5
[BUILD/CODEGEN] Allow combine multiple functions in build stage. (#169)* [BUILD/CODEGEN] Allow combine multiple functions in build stage.* Enhance code module* fix compile,0
Updating TODO.md,2
"[AIRFLOW-1853] Show only the desired number of runs in tree viewPreviously, the ""Number of runs"" option was notbeing respected for DAGs that were externallytriggered. Now, only the set number of runs isshown regardless of DAG trigger type.Also adjust www_rbacCloses #3288 fromAetherUnbound/feature/AIRFLOW-1853",1
Update scheduler deployment - dags volume mount (#10630),2
Improved cloud tool available in the trimmed down CI container (#9167)* Improved cloud tool available in the trimmed down CI containerThe tools now have shebangs which make them available forpython tools. Also /opt/airflow is now mounted from thehost Airflow sources which makes it possible for the tools tocopy files directly to/from the sources of Airflow.It also contains one small change for Linux users - the filescreated by docker gcloud are created with root user so in order to fixthat the directories mounted from the host are fixed when you exitthe tool - their ownership is changed to be owned by the host user,1
"[AIRFLOW-3554] Include contrib folders in code coverage stats (#4351)contrib/ was excluded previously (in the AirBnB days) as there was a distinction between contrib and ""core"" even though it was in tree. That distinction doesn't hold any more, so we care about the coverage of the contrib folders too.",3
Add statistic calculation for Provider's testing. (#21564)This script allows to calculate some basic stats of testing forprovider releases.,1
Merge pull request #543 from jochem/masteradded wetransfer to airflow users,1
Fix links in documentation (#23975)* fix links* added right link to breeze,2
"[AIRFLOW-1349] Fix backfill to respect limitsBefore, if a backfill job was triggered that wouldinclude a dag runalready in a RUNNING state, the dag run within thebackfill would beincluded in the count agains the max_active_runslimit. Also, if abackfill job generated multiple dag runs it couldpotentiallyviolate max_active_runs limits by executing alldag runs.Now the limit is checked per dag run to becreated, and the backfill jobwill only run the dag runs within the backfill jobthat could beincluded within the limits.Also, if the max_active_runs limit has alreadybeen reached, theBackfillJob will wait and loop trying to createthe required dag runs assoon as a dag run slot within the limit isavailable until all dag runsare completed.These changes provide a more consistent behavioraccording to themax_active_runs limits definition and allows theuser to run backfilljobs with existing RUNNING state when alreadyconsidered within thelimits.Closes #2454 from edgarRd/erod-fix-backfill-max",0
[AIRFLOW-XXX] Update timezone doc (#4592),2
[AIRFLOW-XXX] Give a clue what the 'ds' variable isIt's not explained anywhere else in thetutorial...Closes #2679 from tgs/patch-1,5
"[LICENSE] clarify the blockingqueue license, update version to 0.6.0 (#4414)",5
Going more generic on DatbaseConnection's extra json field to support multiple hiveconf statements,5
"The code was taken from: https://github.com/wndhydrnt/airflow/tree/docker_operatorCredit to: @wndhydrntThis branch, came to solve the CI problems.",0
"Disables --warn-unused-ignore flag for mypy (#10880)There is a problem with MyPy's implementation of--warn-unused-ignore flag, that depending on it's incrementalor full run it will sometimes throw an ""unused ignore"" error(entirely randomly it seems). The problem is described(but only workarounded) inhttps://github.com/python/mypy/issues/2960.The workaround is to disable --warn-unused-ignore flag.There is little harm in having unused ignores and we canclean them up from time to time easily.",4
[Topi][Relay] Support for FP16 ERF on CPU. (#11413)* Functionality and tests implemented* Formatting and lint.* Typo fix.* Reduce strictness for fp16 tests.Co-authored-by: Ubuntu <ubuntu@ip-172-31-53-187.us-west-2.compute.internal>,3
Fix apply defaults for task decorator (#16085),0
[CI] Further open up Rust permissions (#10115)Tested this with `./tests/scripts/task_rust.sh` to ensure it builds.,3
[AIRFLOW-6561] Add possibility to specify default resources for airflow k8s workers (#7168)Co-authored-by: Stijn De Haes <stijndehaes@gmail.com>,1
"Don't bake ENV and _cmd into tmp config for non-sudo (#18772)If we are running tasks via sudo then AIRFLOW__ config env vars won't bevisible anymore (without them showing up in `ps`) and we likely mightnot have permission to run the _cmd's specified to find the passwords.But if we are running as the same user then there is no need to ""bake""those options in to the temporary config file -- if the operator decidedthey didn't want those values appearing in a config file on disk, thenlets do our best to respect that.Note: this commit originally appears in 2019 but a critical piece wasmissing, meaning that the secrets/envs were still actually appearing.",2
"Reset PIP version after eager upgrade (#13251)PIP upgrades itself after eager update, and since we (for now)stick with the 20.2.4 version we want to reset PIP to thatversion after eager upgrade.",1
Merge pull request #197 from mistercrunch/stickyMake root sticky when navigating across days,1
Add 'steps' into template_fields in EmrAddStepsRendering templates which are in steps is especially useful if youwant to pass execution time as one of the paramaters of a step inan EMR cluster. All fields in template_fields will get rendered.,1
[AIRFLOW-5176] Add Azure Data Explorer (Kusto) operator (#5785),1
enhance access_ptr that args can support Expr (#970),1
"Retry Dagbag.sync_to_db to avoid Deadlocks (#12046)Previously we added Retry in DagFileProcessor.process_file toretry dagbag.sync_to_db. However, this meant that if anyone callsdagbag.sync_to_db separately then also need to manage retrying itby themselves. This caused failures in CI for MySQL.resolves https://github.com/apache/airflow/issues/11543",0
"[ci][docs] Don't delete old versions when checking out docs (#11612)We don't have a good way to tell if a file was deleted or not in a docs update, so currently we delete the entire `docs/` folder and replace it from the build. However, this includes old version docs that aren't build in the normal docs build. This excludes them from the deletion so they stick around between updates. We'll have to revisit this list at each release but it should be a simple update.Co-authored-by: driazati <driazati@users.noreply.github.com>",1
Conv2d modified for better performance (#516)* conv2d tweaked for better end-to-end performance* syntax changed,4
Simplify full broadcast (#7423)* convert argwhere(full(const)) to reshape(arange())* Add IsWildcard syntatic sugar* add a simplify expression to fold full into broadcast ops* Allow constant folding of full-like ops after SimplifyExpr* fix a bug with the Attr Pattern matching* remove skip_list,4
implement API v1 for variables (#9273)* implement api v1 for variables* add test for limit parameter default value* change offset behavior* address review feedback* addressed more review feedbacks* return total item count in db for total_entries field,5
Fix QNN type inference (#7074)* check for incomplete types in QNN Relation functions* add regression test from #7067* respond to review comments,3
fix asan check heap-use-after-free (#2071),1
Fix generating types like float44 and float88 (#5722),0
Add dag-processor cli command (#22305),2
Improve test coverage for ConfObject in dag_run_schema (#10738)Adds test to verify that string can be passed to conf and ConfObject._deserialize works.,1
#393 Scheduler does not pickle DAGs for non-local executors,2
[Hotfix][MetaSchedule] Importing from test foldeer (#11695)A concurrent merge breaks the unittest which imports directly from`meta_schedule.testing`.,3
add Holimetrix in user list,1
Relay C++ Build Module (#3082)* [Relay] C++ Build module* asdf,5
[Frontend][Paddle] Fix pool2d op (#11029)* fix pool2d op* [frontend][Paddle] Fix pool2d Op* reformat files,2
"[Frontend] Add Span filling for frontends to Relay (#9723)* [Frontend] Add Span filling for frontends to Relay* Add a common span filling feature for tf1/2, tflite and pytorch.* Add test case for Span filling in each frontend.* Expose Tuple and TupleGetItem to python end* [Frontend] Add Span filling for frontends to Relay* Fix lint errors* Change default string of scope_part in Pytorch* Reorder the span position for one to many conversion* [Frontend] Add Span filling for frontends to Relay * nit fixed * Add a bool flag to control print span * refactor pytorch get span to a birefer way* [Frontend] Add Span filling for frontends to Relay* Add one more condition for spanFller* Refine the format for those pytorch node without scopeName* [Frontend] Add Span filling for frontends to Relay* Fix lint",0
"Revert ""Use yaml safe load (#22085)"" (#22089)This reverts commit 7f4935bab36c41d5927610e38c46a30da2b80906.",4
fix: cloudwatch logs fetch logic (#20814),2
[AIRFLOW-6709] Fixed failing git sync (#7332),0
add conv2d transpose and fix bugs (#1566),0
Add support of placement in the DockerSwarmOperator (#18990),2
"Migrate Google azure_fileshare example DAG to new design AIP-47 (#24349)related: #22430, #22447",1
Fix spellings (#14483),0
[AutoScheduler] Tutorial on auto-scheduling a network for GPU (#6882)* add a tutorial on auto-scheduling a network for cuda* fix typo* fix training time printing* fix lint* fix* upload logs* fix* use weighted sum as the default objective function* update ci logs* fix the bug in kill_child_processes* fix test* address comments* add early stopping in task scheduler & fix a stuck issue in measurement* fix lint* trigger CI* fix early stopping,0
"[AIRFLOW-2270] Handle removed tasks in backfillFix issue with backfill jobs of dags, where tasksin theremoved state are not run but still considered tobe pending,causing an indefinite loop.Closes #3176 from ji-han/AIRFLOW-2270_dag_backfill_removed_tasks",4
Add Mongo projections to hook and transfer (#17379),1
AIP-47 - Migrate Airbyte DAGs to new design (#25135),1
[AIRFLOW-2431] Add the navigation bar color parameter for RBAC UICloses #3326 from jgao54/navbar-color,2
Remove inapplicable arg 'output' for CLI pools import/export (#13071),2
Deprecate Tableau personal token authentication (#16916)* Deprecate Tableau personal token authentication* Fix spelling in documentation* Fix styling issue in TableauHook,1
"Auto-discover C/C++ compiler instead of hardcoding g++ (#10007)Some platforms (e.g. FreeBSD) use clang as the default OS compiler,and there is no g++.",1
Update release notes for 3 extra providers released (#18018)We are releasing out-of-bands providers now:* Hashicorp - due to bug found in previous version* Celery - due to change in Celery dependency* Microsoft PSRP - due to bug found and fixed after relesing first  version,0
Docs: Fix task order in overview example (#21282),0
Simplify TF get_output_names (#3025),1
Streamline & simplify __eq__ methods in models Dag and BaseOperator (#13449)- Use getattr() instead of __dict__ as __dict__ doesn't return  correct values for properties.- Avoid unnecessary condition checks (the removed condition checks are covered by _comps),4
Fix compile error when AddRewrite gets additional args (#10669),1
[TOPI] Formalize the tag system (#473),5
[Relay][Frontend][darknet] Solve tvm parsing darknet resnext failure bug (#3778)* test_darkent_bug* test_darkent* add resnext tests,3
removed pass,4
"Dumps more logs in case of CI failure (#11614)We do not dump airflow logs on success any more, but we dump themand all the container logs in case of failure, so that we canbetter investigate cases like #11543 - that includes enablingfull deadlock information dumping in our mysql database.",5
[Bugfix] Fix AutoTVM bug (#3462)* fix autotvm* fix bug when heap_items is empty,0
"Rename backport packages to provider packages (#11459)In preparation for adding provider packages to 2.0 line weare renaming backport packages to provider packages.We want to implement this in stages - first to rename thepackages, then split-out backport/2.0 providers as part ofthe #11421 issue.",0
Add more weekday operator and sensor examples #26071 (#26098),1
[AutoScheduler] Add layout rewrite support for dense and batch matmul on CPU (#7161)* [AutoScheduler] Add layout rewrite for dense and batch_matmul* Fix test & Address comments* Fix shape inference* fix test,3
"Gather operation with indices as tensor expr in TFLite frontend (#6168)* gather with indices as tensor exprAdded handling of indices as tensor exprto gather operation, unit tests amendedCode cheking out of boundary error refactoredin more ""pythonic"" way. Fixed bug in negativeaxis value normalisation* replaced with get_tensor_expr",1
"Protect against the case when emulated Python is used on M1s (#25229)People might have an intel Python installed on M1s. This happenedalready. The result of it that they (unknowingly) suffer from10x slower speed of any Python code they use (even locally).This can happen in two cases:* you can run in ""arm"" terminal and your python might be  Intel based (for example when your environment is old or  managed before it was ready for ARM architecture) or when  you use some scientific package managers like anaconda that  still have not switched to ARM. In this case we  detect different architecture reported by Python and system.* you can run it in emulated terminal when your IDE has been  installed using different architecture. In this case, we detect  if rosetta emulation is running via sysctl command.This also impact Breeze because we are using Python architecturein order to determine which platform image should be used byBreeze.This change adds big, fat warning and 20 seconds of delay askingthe user if they REALLY want to run Breeze command using emulatedarchitecture. If they answer y - it will continue. If they do not answeror answer anything else, the command will error out.",0
[TIR][Printer] text format printer considering future parsing use (#5483),1
Fix a issue when running with graph_runtime_debug in python (#2271)* fix a issue when running with graph_runtime_debug in python;* add support to `debug_get_output` in python;* comply with the linter;,0
[PYTHON] Support DLTensor compatible API (#136)* [PYTHON] Support DLTensor compatible API* optimize for common path,1
docs: fix inconsistencies in configuration docs (#17317),2
[API] Move all RTTI related code to one place (#20)* [API] Move all RTTI related code to one place* add back rtti comment,1
[AIRFLOW-2139] Remove unncecessary boilerplate to get DataFrame using pandas_gbqCloses #3066 from mremes/improvement/cleanup-bigquery-hook,4
[TIR] VNNI and ARM dot product intrinsic for tensorization (#10925),2
Add labels to each Jenkins step (#9556)Co-authored-by: driazati <driazati@users.noreply.github.com>,1
[ci] Look for any tags in issues before adding new tags (#10685)Previously this searched for a specific `cc @abc` line by itself before looking for people to tag. This led to a double-tag in #10679. The change here updates it to check for `@`-ed people anywhere in the PR/issue body and filters those out.,0
Update to latest isort & pre-commit-hooks (#11813),1
Add ``.gitattributes`` for ignoring tests files in ``git archive`` (#16122)I did this manually while releasing the Helm Chart.,2
[LANG] Add all and any in the python API (#196)* [LANG] Add all and any in the python API* compatible with python3,1
[Relay][Frontend] Add MXNet test example for relay (#2316)* Add MXNet test example for relay* Fix a bug in BiasAddSimplifier,1
Fix pytorch frontend prim::Constant issue (#6051),0
"[EZ][Typo] Correct gather, scatter type rel error message (#10023)",0
Add max_map_size to limit XCom task mapping size (#20976),1
Documentation text did not match the sample code,2
Add params.* to Jenkins file parameters (#8771)* Prefix all parameters with params.* so that it checks   whether parameters exist before using them * This is a follow-up fix on #8721 so that existing PRs work   without being re-triggered manually twice,1
[AIRFLOW-651] Hotfix setup.pyCloses #1902 from r39132/hotfix,0
Merge pull request #825 from abridgett/feature/gantt_color_alternate_rowscolor alternate rows so it's easier to use,1
"Explain scheduler fine-tuning better (#18356)* Explain scheduler fine-tuning betterA lot of users have an expectations that Airflow Scheduler will`just work` and deliver the `optimal performance` for them withoutrealising that in case of such comples systems as Airflow is youoften have to decide what you should optimise for or accept sometrade-offs or increase hardware capacity if you are not willing tomake those trade-offs.Also it's not clear where the responsibilityis - should it `just work` or should the user be responsible forunderstanding and fine tuning their system (both approaches arepossible, there are some complex systmes which utilise a lot ofautomation/AI etc. to fine tune and optmise their behaviour butAirflow expects from the users to know a bit more on how thescheduling works and Airflow maintainers deliver a lot ofknobs that can be turned to fine tune the system and to maketrade-off decisions. This was not explicitely stated in ourdocumentation and users could have different expectations aboutit (and they often had judging from issues they raised).This PR adds a ""fine-tuning"" chapter that aims to set theexpectations of the users at the right level - it explains whatAirflow provides, but also what is the user's responsibility - todecide what they are optimising, to see where their bottlenecksare and to decide if they need to change the configuration orincrease hardware capacity (or make appropriate trade-offs).It also brings more of the fine-tuning parameters to the`tuneables` section of scheduler, based on some of the recentquestions asked by the users - seems that having a specificoverview of all performance-impacting parameters is a good idea,and we only had a very limited subset of those.Some user prefer `watch` rather than read that's why this PRalso adds the link to the recording of talk from theAirlfow Summit 2021 where Ash describes - in a very conciseand easy to grasp way - all the whys and hows of the scheduler.If you understand why and how the scheduler does what it does,fine-tuning decisions are much easier.* fixup! Explain scheduler fine-tuning better",1
Add Flux to chart gitops docs (#24288),2
Remove duplicated entries in changelog (#19331)Amazon provider had wrong tag set (2.3.0 pointed to rc1 insteadof rc2) which resulted in duplicated entries in changelog.This PR fixes it,0
fix compact_dataflow (#9747)Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>,5
Enable Markdownlint rule MD003/heading-style/header-style (#12427) (#12438)Co-authored-by: John Bampton <jbampton@users.noreply.github.com>,1
Add new teammate to Polidea (#11000),1
[AIRFLOW-6297] Add Airflow website link to UI docs (#6849),2
[Community] @elvin-n -> Reviewer (#9321),3
Halide -> HalideIR (#698),5
Fix typo in docker-stack documentation (#16221),2
[AIRFLOW-1831] Add driver-classpath spark submitAdd the ability to set the driver-classpath forthe spark_submitoperator and hook.Closes #2800 from danielvdende/add-spark-driver-classpath,1
typo: Xlinx => Xilinx (#2283)typo: Xlinx => Xilinx,2
[AIRFLOW-6261] flower_basic_auth eligible to _cmd (#6825)Make the configuration option flower_basic_auth from celeryavailable as the stdout of a command as it contains sensitiveinformation.,5
Add more json-schama checks + display all errors (#12805),0
Migrate Papermill example DAGs to new design #22456 (#24146),1
Add Handy to list of users,1
Re-serialize all DAGs on 'airflow db upgrade' (#24518),5
Merge pull request #1145 from airbnb/dag_cliper-DAG specifc CLI & refactoring,4
"[TIR] Update region min/extent in ReplaceBufferMutator (#12725)Prior to this commit, `ReplaceBufferMutator` only checks`BufferRegionNode::buffer` to determine if a `BufferRegion` needs tobe replaced, and doesn't check the `BufferRegionNode::region`.  As aresult, updating `T.reads(A[B[i]])` would fail to replace `B`.This commit checks `BufferRegionNode::region` for buffer usage toresolve this issue.",0
"Fix ``breeze kind-cluster shell`` (#20015)This was failing with the following:```/Users/kaxilnaik/Documents/GitHub/astronomer/airflow/scripts/ci/kubernetes/ci_run_kubernetes_tests.sh: line 102: constraints[@]: unbound variableExporting logs for cluster ""airflow-python-3.7-v1.20.2"" to:/tmp/kind_logs_2021-12-03_0_0```and was caused by https://github.com/apache/airflow/pull/17290",1
[AIRFLOW-3744] Abandon the use of obsolete aliases of methods (#4568),1
"[Relay] Fix invalid shape function for ""copy"" operator (#9749)The 'script' for of the shape function was ill-formed,resulting in a TIR shape function which did not assignto it's output, which in turn caused either OOM orassert fails as uninitialized dimensions worked theirway downstream. That fix is in python/tvm/relay/op/tensor.py.Everything else is for testing and debugging as I trackedthis down.Special thanks to Lily for helping me with the scalar vstensor switch in the copy shape function.[This is CORE-112 in OctoML JIRA.]",5
"[AIRFLOW-4822] Fix bug where parent-dag task instances are wrongly cleared (#5444)Full matching required in this case, so the regex should start and endwith ""^$"". Blurred matching might result in irrelevant task instances becleared.Also in this commit:* Added independent test dag: `clear_subdag_test_dag`* Polished related unit test: `test_subdag_clear_parentdag_downstream_clear`",3
hive_hook: Using -f with a temp file instead of -e,2
[3/10] Moved TIR generation from Python to C++ for CMSIS-NN (#8951)* [CMSIS-NN] Moved TIR Generation to C++* Deleted self import for cmsisnnChange-Id: I2cdcd7a90aa4749877c48bc6c7c4d27328856860* Reusing CodeGenC VistiExpr for softmaxChange-Id: Ie41b695fa06468cd3b0bfe428c360e98438a9180,4
Cleanup imports,2
Improve the x86 auto-tune tutorial (#3609),1
checkin basic expr,5
Merge pull request #61 from mistercrunch/backfill_dep_pastdepends_on_past backfill fix,0
[AIRFLOW-XXX] Remove `of to` typo. (#4542)[AIRFLOW-XXX] Remove `of to` typo.,2
[TVMScript] StmtDoc Definitions (#12111)This PR addes:- All StmtDoc subclasses- Python bindings for StmtDocTracking issue: https://github.com/apache/tvm/issues/11912,0
"[TVM] Rewrite simplification rule to eliminate unnecessary conditionals. (#4076)The current bounds checking infrastructure inserts checks like:```for (i, 0, bounds[n]) {  if (likely(i < bounds[n]) {     ...  }}```into the TVM IR which is currently not removed by simplification infrastructure.This is a little unclean, as these are trivially true since for a loop var `i`with a given min and extent, we are guaranteed that `i >= min` and `i < min +extent`. Thus, we can insert these checks into the IR and use them to eliminatetrivial bounds checks early on.",1
"[UnitTests] Added cuDNN to default test targets (#8383)* [Target][UnitTests] Look up target requirements based on tvm.target.Target- Read target.kind.name instead of using string manipulation.- Target device query on a non-existent target is no longer an error.  This occurs if expanding `vulkan -from_device=0` on a non-GPU  machine.* [UnitTests] Added cuDNN target to default test targetsSome unit tests explicitly test cudnn in addition to`tvm.testing.enabled_targets()`.  This moved the cudnn checks into thesame framework as all other targets, and adds it to the default listof targets to be run.  Also, added `@tvm.testing.requires_cudnn` fortests specific to cudnn.* [UnitTests] pytest.xfail for CuDNN conv2d with asymmetric padding* [Topi][CuDNN] Added handling of dilation to conv2d_cudnn* [Topi] Skip dynamic batch matmul on cudnn, vulkan, openclPreviously, cuda/nvptx targets were excluded.  Changed it to look upby target.kind.name, and to also exclude vulkan/opencl, as the dynamiclookup currently doesn't work on those backends.Co-authored-by: Eric Lunderberg <elunderberg@octoml.ai>",5
Fix build on RTD (#12551),0
"Revert ""Fix cancelling of Pull Request builds when image build fails (#20939)"" (#20964)This reverts commit b171e03924fba92924162563f606d25f0d75351e.",4
"Fix the process of requirements generations (#8648)Right now requirements will be only checked during theCI build if the setup.py has changed and if yes, clear instructionswill be given. The diff will still be printed otherwise butit will not cause the job to fail",0
Add content to file (forgot to save before committing) (#10565),2
Update best-practices.rst (#17357),5
"[AIRFLOW-1930] Convert func.now() to timezone.utcnow()func.now() defaults to the timezone of thedatabase,we assume that everything is in UTC which mightnot bethe case if func.now() is used.Closes #2882 from bolkedebruin/AIRFLOW-1930",1
Fix failing tests from #9250 (#9307),3
Fix quarantined/flaky tests in test_local_task_job.py (#17385)This PR attempts to fix some flaky/quarantined tests in test_local_task_job.pyby removing assert not process.is_alive() in the tests and making sure process.joinis called with timeout,5
Improve instructions to install Airflow Version (#11339)The instructions can be replaced by `./breeze start-airflow` command,1
"[Metaschedule] Add test case for multi-anchor subgraph (#10856)This adds a demonstration of extracting, scheduling, and e2e-compiling relay subgraphs with multiple anchor ops. Since task extraction is not associated with TE scheduling anymore, extracting a subgraph with multiple anchor TE compute just works.The test case manually creates a simple fused mod with two `relay.dense`. But in the future, an effort like https://github.com/apache/tvm/pull/9628 should make it easier to construct multi-anchor subgraphs.The extracted TensorIR block corresponding to two TE `dense` compute looks like this:```@tvm.script.ir_moduleclass Module:    @T.prim_func    def main(placeholder: T.Buffer[(128, 128), ""float32""], placeholder_1: T.Buffer[(128, 128), ""float32""], placeholder_2: T.Buffer[(128, 128), ""float32""], T_matmul_NT: T.Buffer[(128, 128), ""float32""]) -> None:        # function attr dict        T.func_attr({""global_symbol"": ""main"", ""tir.noalias"": True})        # body        # with T.block(""root"")        T_matmul_NT_1 = T.alloc_buffer([128, 128], dtype=""float32"")        for i0, i1, i2 in T.grid(128, 128, 128):            with T.block(""T_matmul_NT""):                i, j, k = T.axis.remap(""SSR"", [i0, i1, i2])                T.reads(placeholder[i, k], placeholder_1[j, k])                T.writes(T_matmul_NT_1[i, j])                T.block_attr({""layout_free_placeholders"":[placeholder_1]})                with T.init():                    T_matmul_NT_1[i, j] = T.float32(0)                T_matmul_NT_1[i, j] = T_matmul_NT_1[i, j] + placeholder[i, k] * placeholder_1[j, k]        for i0, i1, i2 in T.grid(128, 128, 128):            with T.block(""T_matmul_NT_1""):                i, j, k = T.axis.remap(""SSR"", [i0, i1, i2])                T.reads(T_matmul_NT_1[i, k], placeholder_2[j, k])                T.writes(T_matmul_NT[i, j])                T.block_attr({""layout_free_placeholders"":[placeholder_2]})                with T.init():                    T_matmul_NT[i, j] = T.float32(0)                T_matmul_NT[i, j] = T_matmul_NT[i, j] + T_matmul_NT_1[i, k] * placeholder_2[j, k]    ```",5
[BYOC][ETHOSN] Introduce further operator support (#6355)* [BYOC][ETHOSN] Introduce further operator supportThis PR introduces support for the following operators: - Quantized Fully Connected - Quantized Addition - Depth-to-space - Max/Avg Pool 2D - Quantized Relu (Clip) - Reshape - Quantized SigmoidCo-authored-by: Leo Blonk <Leo.Blonk@arm.com>Co-authored-by: Tristan O'Connor <tristan.oconnor@arm.com>Co-authored-by: Ramana Radhakrishnan <ramana.radhakrishnan@arm.com>* Skip tf imports if not availableChange-Id: I11bcf4a78014fa63e7b8e3b0cb00eecfd6cb7760* ethos -> ethosnChange-Id: I1fb1a11d0765f6d69f04c24b9c24e08665b8af6a* Reduce random testing in test_additionChange-Id: Id06063a0a0cf5f01356df23dc5d4bbbcb47cfa99* Reduce random testing in test fullyconnectedChange-Id: I330408dfabc4bd804373f100581ce909ff724052* Fix dumb mistake with renameChange-Id: I2c5007be485b323116a0e8bab0f9106ea5ec834b* Added comments to update the hashes in network tests when necessaryChange-Id: I13828c918c959daa492b9ed942a882c86d6690d1* Fix github nameChange-Id: Idaa70ab9c2ec8db2828d51d15e7c23f28670ec82* Use black formattingChange-Id: I538171bd547a16395bef155a1dad28e8b3e347f2Co-authored-by: Leo Blonk <Leo.Blonk@arm.com>Co-authored-by: Tristan O'Connor <tristan.oconnor@arm.com>Co-authored-by: Ramana Radhakrishnan <ramana.radhakrishnan@arm.com>,4
Fix grammar in API docs (#13444)Fixes some minor grammatical issues,0
Core: Enable the use of __init_subclass__ in subclasses of BaseOperator (#17027)This fixes a regression in 2.1 where subclasses of BaseOperator could nolonger use `__init_subclass__` to allow class instantiation timecustomization.Related BPO: https://bugs.python.org/issue29581Fixes: https://github.com/apache/airflow/issues/17014,0
Update Helm Chart docs for 1.0.0 release (#15957)Updates repo name and chart name and some minor errors,0
"Increase timeouts even longer for on_kill test (#20056)Seems that when the system is busy, the timeouts we had towait for tasks to start were a bit to short. Increasing them.Related to #20054",1
[ETHOSN] Update to 20.08 version of the ethosn-driver. (#6606)- Updated ethosn relay backend to account for 20.08 api changes around cascading and quantization.   - Note: 20.05 compatibility is maintained for now to avoid compilation and test failures while the docker image still uses 20.05. The version switch can be removed along with associated compatibility measures when no longer necessary.,4
Add test for BQ operations using location (#9206),1
[FRONTEND][TENSORFLOW] Support AttrValue that has different types of value in a list (#2177),1
[AIRFLOW-4502] Add new CLI command - task_states_for_dag_run (#6993)Co-Authored-By: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>,1
[Relay][Frontend][ONNX] Add support for broadcasting to Where and MatMul (#4267),1
"AIRFLOW-3590: Change log message of executor exit status (#4616)Try to make the log message clearer in the presence of rescheduled tasks -i.e that the task exited with 0/1, not the status of the task, without having eachexecutor having to know about reschedule or other states we might introduce.",2
Add docs about reload_on_plugin_change opiton (#9575),4
Free TensorRT engine and context (#7702),5
fix buffer elem_offset calculation (#1762),1
Get tags of saved model automaticallyRemove exception trail in tf parser error messageFix lintFix comments,0
Bring back code coverage (#10143)Fixes #10138,0
Merge pull request #1400 from jlowin/missing-args-clearAdd missing args to `airflow clear` - confirmed this change works locally.,1
"Fixes ScheduleInterval spec (#22635)In the schedule interval, the data can actually match more than one schema and the `__type` should decide which type of the interval it actually matches. Fixes https://github.com/apache/airflow-client-go/issues/20",0
"Move Var back to Expr, add format str test",3
[CI] Update docker image ci_lint to obtain Python 3.6 from ppa:deadsnakes/ppa (#4505) (#4506),2
[CI] Ensure rat ignores rust cargo lock files [CI] Ensure rat ignores emacs backup files [CI] Ensure rat ignores .egg-info (#3314),5
[AIRFLOW-XXXX] Add Probot App to add labels on PR (#7053),1
[Frontend][PaddlePaddle] Add operators of interploate/flatten and modify try_infer_value (#9459)* add interploate and flatten* fix spells* fix diff* rename unit test name* add parameters for common:try_infer_value* eliminate unnecessary diff* fix pylint problem* fix pylint problem* eliminate unnecessary diff,0
"Reset sphinx-gallery version to 0.4.0 (#9280)Seeing:```ERROR: Could not find a version that satisfies the requirement sphinx-gallery==0.4.1 (from versions: 0.0.4, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.0.10, 0.0.11.post1, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.1.10, 0.1.11, 0.1.12, 0.1.13, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.6.1, 0.6.2, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.9.0, 0.10.0)ERROR: No matching distribution found for sphinx-gallery==0.4.1```This was changed in https://github.com/apache/tvm/pull/9115",4
checkin basic var,5
"[TFLite runtime] Allow to set number of threads to TFLite interpreter (#6901)* Support for setting thread count in TFLite runtime,Co-authored-by: FrozenGene <zhaowu@apache.org>* fix lintCo-authored-by: FrozenGene <zhaowu@apache.org>",0
Tree view bugfix None in hidden form field,0
Fix ``triggerer`` query where limit is not supported in some MySQL version (#17601)This PR fixes the triggerrer query where limit is not supported in some DB versions and also fixed the issue where total_hours was used on a timedelta.,1
Modifying README to link to the wiki committer list,2
Add docs,2
"Fix processor cleanup on DagFileProcessorManager (#22685)* Fix processor cleanupReferences to processors weren't being cleaned up afterkilling them in the event of a timeout. This lead toa crash caused by an unhandled exception when trying toread from a closed end of a pipe.* Reap the zombie when killing the processorWhen calling `_kill_process()` we're generatingzombies which weren't being `wait()`ed for. Thisled to a process leak we fix by just calling`waitpid()` on the appropriate PIDs.* Reap resulting zombies in a safe wayAccording to @potiuk's and @malthe's input, the waywe were reaping the zombies could cause some racy andunwanted situations. As seen on the discussion over at`https://bugs.python.org/issue42558` we can safelyreap the spawned zombies with the changes we haveintroduced.* Explain why we are actively waitingAs suggested by @potiuk explaining why we chose to actively wait on an scenario such as this one can indeed be useful for anybody taking a look at the code some time from now...Co-authored-by: Jarek Potiuk <jarek@potiuk.com>* Fix small typo and triling whitespaceAfter accepting the changes proposed on the PRwe found a small typo (we make those on a daily basis)and a trailing whitespace we though was nice to delete.Hope we made the right choice!* Fix call to `poll()`We were calling `poll()` through the `_process` attributeand, as shown on the static checks triggered by GitHub,it's not defined for the `BaseProcess` class. We insteadhave to call `poll()` through `BaseProcess`'s `_popen`attribute.* Fix processor cleanupReferences to processors weren't being cleaned up afterkilling them in the event of a timeout. This lead toa crash caused by an unhandled exception when trying toread from a closed end of a pipe.* Reap the zombie when killing the processorWhen calling `_kill_process()` we're generatingzombies which weren't being `wait()`ed for. Thisled to a process leak we fix by just calling`waitpid()` on the appropriate PIDs.* Reap resulting zombies in a safe wayAccording to @potiuk's and @malthe's input, the waywe were reaping the zombies could cause some racy andunwanted situations. As seen on the discussion over at`https://bugs.python.org/issue42558` we can safelyreap the spawned zombies with the changes we haveintroduced.* Explain why we are actively waitingAs suggested by @potiuk explaining why we chose to actively wait on an scenario such as this one can indeed be useful for anybody taking a look at the code some time from now...Co-authored-by: Jarek Potiuk <jarek@potiuk.com>* Fix small typo and triling whitespaceAfter accepting the changes proposed on the PRwe found a small typo (we make those on a daily basis)and a trailing whitespace we though was nice to delete.Hope we made the right choice!* Fix call to `poll()`We were calling `poll()` through the `_process` attributeand, as shown on the static checks triggered by GitHub,it's not defined for the `BaseProcess` class. We insteadhave to call `poll()` through `BaseProcess`'s `_popen`attribute.* Prevent static check from failingAfter reading through `multiprocessing`'s implementation wereally didn't know why the static check on line `239` wasfailing: the process should contain a `_popen` attribute...That's when we found line `223` and discovered the trailing`# type: ignore` comment. After reading up on it we foundthat it instructs *MyPy* not to statically check that veryline. Given we're having trouble with the exact same attributewe decided to include the same directive for the static checker.Hope we made the right call!* Fix test for `_kill_timed_out_processors()`We hadn't updated the tests for the method whosebody we've altered. This caused the tests to failwhen trying to retrieve a processor's *waitable*,a property similar to a *file descriptor* inUNIX-like systems. We have added a mock property tothe `processor` and we've also updated the `manager`'sattributes so as to faithfully recreate the state ofthe data sctructures at a moment when a `processor`is to be terminated.Please note the `assertions` at the end are meant tocheck we reach the `manager`'s expected state. We havechosen to check the number of processor's against anexplicit value because we're defining `manager._processors`explicitly within the test. On the other hand, `manager.waitables`can have a different length depending on the call to`DagFileProcessorManager`'s `__init__()`. In this test theexpected initial length is `1` given we're passing `MagicMock()`as the `signal_conn` when instantiating the manager. However,if this were to be changed the tests would 'inexplicably' fail.Instead of checking `manager.waitables`' length against a hardcodedvalue we decided to instead compare it to its initial lengthso as to emphasize we're interested in the change in length, notits absolute value.* Fix `black` checks and `mock` decoratorsOne of the methods we are to mock required a ratherlong `@mock.patch` decorator which didn't pass thechecks made by `black` on the precommit hooks. Ontop of that, we messed up the ordering of the`@mock.patch` decorators which meant we didn'tset them up properly. This manifested as a `KeyError`on the method we're currently testing. O_oCo-authored-by: Jarek Potiuk <jarek@potiuk.com>",3
Bump version,5
"[TVMC] Workspace Pools Parameters (#11427)* [TVMC] Workspace Pools ParametersAttributes from tvmc are now passable into the created PoolInfo objectsinside WorkspaceMemoryPools. This is passed in to relay.build that getattached to IRModule attribute.* [TVMC] Workspace Pools ParametersAddress comments, fix linting. Testing improved.Change-Id: Iea79329b6b9ec1cbc51e5c293449bf6dd43b00c5* [TVMC] Workspace Pools ParametersUpdate workspace pools test namingChange-Id: Ib698d6248be1e6f44340f27db3641c985bc5c5d8* [TVMC] Workspace Pools ParametersAdd test for parameter overrides.Change-Id: I67d5470dcfbfbc9ab27f34e20a9269d2070193ca* [TVMC] Workspace Pools ParametersRebasing over #10189Updates to the way a WorkspaceMemoryPool object is createdChange-Id: I1f0e1d240343af311ddb3ed5c564cc1ab329f463* [TVMC] Workspace Pools ParametersFix linting, fix CIChange-Id: If75f8709ac4ad925655eca54b3e5c1bb09d025e8* [TVMC] Workspace Pools ParametersAdd mcpu and mattr to target registry for cmsis-nnChange-Id: I15257b8d01624c071c738cab6d12ecb84ed6cb16* [TVMC] Workspace Pools ParametersAdded test for override on single pool when multiple pools are presentUpdated functionality of parsing multiple attributesChange-Id: I2c0745051b7a923dd7f75040bfb89bbc99376a11",4
Quarantine test_mark_success_no_kill test (#17580)This test is flaky.Logging it in: #17579,2
[RPC] Link in whole archive with BUILD_STATIC_RUNTIME (#10260)* [RPC] Link in whole archive with BUILD_STATIC_RUNTIME* Restart CI,1
Add pre-commit to sort INTHEWILD.md file automatically (#10851),2
[AIRFLOW-XXX] Add note about moving GCP from contrib to core (#6119),4
Postgres operator unit tests,3
[AIRFLOW-2369] Fix gcs testsThe version was hardcoded and would break if youupdate the versionof Apache AirflowCloses #3260 from Fokko/airflow-2369-fix-tests,3
"Have proper default for webserver.expose_config in Helm Chart (#13596)webserver.expose_config should have consistent default value withthe normal Airflow default settings (False).This helps encourage safer setting up in Helm context, also avoidaccidental exposure of config (if users don't carefully check the configbefore install the chart)",2
Fix possible reference to undeclared variable (#19933),0
register depthwise conv2d as generic function (#1108),1
Stop using start_date in default_args in example_dags (2) (#9985),2
"The fix_ownership works independently of backend choice (#9664)The script failed on a ""clean"" installation if the imagerequired cleaning and the database was not started.",5
Reorder Migrations to make it 1.10.13 compatible (#12496)This commits makes Airflow 2.0 migrations compatible with 1.10.13 so users caneasily upgrade from 1.10.13 to 2.0,1
[AIRFLOW-XXX] Speed up building of Cassanda module on Travis (#5233)Our new environment already sets this env var but we aren't using thisyet,1
[RUNTIME] Fix compile errors of OpenCL FPGA backend (#4492),0
"``KubernetesExecutor`` should default to template image if used (#19484)Currently, the user must specify image and tag in airflow.cfg, even when they are using a pod template file.  If the pod template file specifies an image and tag, the user should not be forced to also specify this in airflow.cfg.",5
"Fixes doc for SQSSensor (#15323)As far as I understand, Docstrings for `SQSSensor` seemes to include a mistake.The key for XCom should be 'messages', not 'message'.https://github.com/apache/airflow/blob/0f327788b5b0887c463cb83dd8f732245da96577/airflow/providers/amazon/aws/sensors/sqs.py#L91",1
[CI] Upgrade Python dependencies as part of Docker image buildMake sure that Python package dependencies we install as part of the Docker image setup take precedence over previously Ubuntu installed packages that might be installed (e.g python3-***) via apt.,1
"Check that the node is not null, add contains to OpMap (#3037)",1
Remove unused internal function left over form Scheduler HA work (#16269)As of AIP-15 this function is not called anymore and should have beendeleted then.,4
Reorder middleware - ProxyFix and BaseUrl (#8157),0
Remove unneeded parentheses after Black formatting (#12380),4
[AIRFLOW-XXX] Fix flake8 failure from #4184,0
Fix Get Valid Counts when the number of boxes is zero (#7229),1
docs: NOTICE: Updated 2016-2019 to 2016-now (#14248),5
[AIRFLOW-5350] Fix bug in the num_retires field in BigQueryHook (#5955),1
[AIRFLOW-2396] Add support for resources in kubernetes operator[AIRFLOW-2396] Add support for resources inkubernetes operator[AIRFLOW-2396] Add support for resources inkubernetes operatorCloses #3352 from ese/resources,1
Change error.h path in doc.h (#1794),2
[AIRFLOW-1820] Remove timestamp from metric nameCloses #2792 from wrp/datetime,5
"[AIRFLOW-2074] Fix log var name in GHE authA previous log refactor changed the logger namefrom `_log` to `log`,but didn't update callers.Closes #3011 from cmlad/fix-ghe-auth-logging",2
[RUST][CI] Add rust frontend tests in Jenkins (#2375),3
"[email alerts] Fixed alerts for multiple recipientsFixed the case where smtplib.sendmail would interpret a single stringas a list with a single address as per RFC 822. Fixed ""To"" header aswell",0
"Add ""please use search"" in bugfix template (#8492)* Please use search before creating bug issue* fixup! Please use search before creating bug issue",0
"[CI] Refactor of tvm.testing.requires_* annotations (#11313)* [CI] Improved skip messages when using @tvm.testing.requires_*Previously, the same message was given regardless of why a testcouldn't be run.  This has been split up into separate checks for TVMcmake options in `config.cmake`, enabled targets in `TVM_TEST_TARGETS`environment variable, and checks for available hardware.* Refactor to specify repeated feature marks, compile-only markers* Fixed lint errors* Import from contrib, not from a different import* Removed use of requires_llvm() as a list of marks* Corrected mark from requires_gpu to requires_cuda* Adding missing ""not""* Added USE_CMSISNN as a requirement for corstone300.",1
"Fix missing <cassert> header, caused compilation failure. (#7740)",0
Support creating GCP connections from the Airflow UI,1
[Target] Fix device mask issue and typos (#9768)* [Target] Fix device mask issue and typos* Skip target hook,1
Add params to the DAG details endpoint (#13790),2
Replace old Variables View Screenshot with new (#9620),1
Remove redundant note on HTTP Provider (#17595)Since https://github.com/apache/airflow/pull/16974 we have switched back to including HTTP provider and this comment now is not correct.,1
Adding back example_dags,2
Only validate Params when DAG is triggered (#20802),2
"[AIRFLOW-504] Store fractional seconds in MySQL tablesBoth utcnow() and now() return fractional seconds. Theseare sometimes used in primary_keys (eg. in task_instance).If MySQL is not configured to store these fractional secondsa primary key might fail (eg. at session.merge) resulting ina duplicate entry being added or worse.Postgres does store fractional seconds if left unconfigured,sqlite needs to be examined.",5
Debounce status highlighting in Grid view (#24710)* Add delay / debounce to not always highlight tasks* fix linting* single delay variable at 200ms,0
[Relay][Fix] Fix alter op layout when calling a global var (#4454)* [Relay][Fix] Fix alter op layout when calling a global var* add test case,3
[CMAKE] Fix cmake build (#520),1
"[AIRFLOW-843] Exception availabe in context for on_failure_callback (#2135)Store exceptions encountered executing a task in the context dict,making it available for on_failure_callback handlers.",0
Fix `task_instance_mutation_hook` when importing airflow.models.dagrun (#15851)If a dag imported `airflow.models.dagrun` it would cause task_instance_mutation_hook from the site local settings to not be picked up.,1
"Add another way to dynamically generate DAGs to docs (#21297)Also, move dynamic DAG generation cases from ""best practices"" to ""how to"" section",2
[TOPI] Fix flaky testcase for check round (#4211),3
Assert dont crash on null strides (#976),3
[AIRFLOW-1917] Trim extra newline and trailing whitespace from log (#3862),2
[AIRFLOW-1544] Add DataFox to companies listCloses #2544 from sudowork/datafox-companies,5
Add alternate cublaslt library name. CUDA 11.0 uses cublasLt. (#6541),1
"A clone of test/python/unittest/test_runtime_micro.py, however (#5546)modified to run specifically on ARM cortex-M hardware, whichcurrently is just the STM32F746 discovery board.Signed-off-by: Tom Gall <tom.gall@linaro.org>",1
Add emr cluster link (#18691),2
[EXECUTOR] Enable load executor remotely (#245)* [EXECUTOR] Enable load executor remotely* [EXECUTOR] Pipeline* Pass bytearray directly* Enable load dynamic library in rpc_server.py* Fix* lint* Return Module from remote side directly* Remove unused header file* Fix* fix,0
"[CI] Update ci_arm and ci_lint (#10146)This includes sccache, and these are the less troublesome images.Also see #10120 for update issue.",0
TimeSensor should respect the default_timezone config (#9699),5
"SLA can be set at task level, email notifications get sent",1
add relu (#1849),1
"[BugFix][VTA] Fix bug in vta runtime DepPop function. (#3208)Issue:    One of existing illegal dependency check's condition always true,    the correct logic actually should be such check for store and load.Solution:    Fix the said logic issue.",0
[AIRFLOW-3764] Simplify chained comparisons in IF block (#4580),5
Add ``Scribd`` to INTHEWILD.md (#17685)* Update INTHEWILD.mdAdd Scribd* Update INTHEWILD.md* use single-bracket style - makes more sense that way,1
"Chart: Fix applying labels on Triggerer (#18299)Currently it errors with:```{""result"":{""message"":""YAML parse error on airflow/charts/airflow/templates/triggerer/triggerer-deployment.yaml: error converting YAML to JSON: yaml: line 30: mapping values are not allowed in this context""},""deployment"":{}}```This PR fixes that and adds unit tests around it.",3
remove duplicated cast op when lowering qnn.requantize op in float mode (#12234),4
[TOPI] Fix x86 conv2d template when tuning with unpacked layout (#5938)* fix x86 conv2d and conv2d_transpose template* address comments,1
Fix DB Migration for SQLite to upgrade to 2.0 (#13921)closes https://github.com/apache/airflow/issues/13877,0
Force-remove container after DockerOperator execution (#23160)Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>Co-authored-by: park.z <park.z@bybit.com>,1
Fix md formatting of UPDATING.md (#21347),5
[AIRFLOW-XXX] Omit vendor packages from being covered by codecov (#5013),5
[AIRFLOW-3964][AIP-17] Consolidate and de-dup sensor tasks using Smart Sensor (#5499)Co-authored-by: Yingbo Wang <yingbo.wang@airbnb.com>,1
[ci] Disable flaky onnx tests (#11376)Co-authored-by: driazati <driazati@users.noreply.github.com>,1
2.2.4 has been released (#21744),5
Chart: ``gitsync`` Clean Up for ``KubernetesExecutor``  (#15925)The gitsync ssh key was being mounted into the KubernetesExecutor workerwhich we don't need or want. This also does some more minor gitsyncrelated cleanup.Closes: #15900,4
[Parser] Typo in mod creation (#6165),1
"[AIRFLOW-1658] Kill Druid task on timeoutIf the total execution time of a Druid taskexceeds the max timeoutdefined, the Airflow task fails, but the Druidtask may still keeprunning. This can cause undesired behaviour ifAirflow retries thetask. This patch calls the shutdown endpoint onthe Druid task tokill any still running Druid task.This commit also adds tests to ensure that allmocked requests inthe Druid hook are actually called.Closes #2644 fromdanielvdende/kill_druid_task_on_timeout_exceeded",1
[AIRFLOW-XXX] Adding new contributor to G Adventures (#5222)G Adventures' Airflow-based project has a new contributor[ci skip],1
[AIRFLOW-2305][AIRFLOW-2027] Fix CI failure caused by []Closes #3205 from sekikn/AIRFLOW-2305,1
[CMSIS-NN] Aligned buffer sizes for Conv2D post CMSIS-NN SHA update (#11359),5
Add Handling of Zero Len Arguments (#6923)* Update tensorrt.py* Update tensorrt.py* Update tensorrt.py,5
Fix MyPy Errors for dataproc package (#20327)Part of #19891,5
Move FlattenAtrousConv before AlterOpLayout in the default opt pipeline. (#11706)Co-authored-by: Andrey Malyshev <elvin.nnov@gmail.com>Co-authored-by: Andrey Malyshev <elvin.nnov@gmail.com>,4
Adding test for sensor operator based on WebHDFSHook,1
Return output of last task from task_group wrapper. (#15779),5
[Ansor] Support multiple output ops and fix Python API printing (#6584),0
Fix Example in config_templates for Secrets Backend (#8074),5
[PyTorch] add var_mean support (#10233)* [PyTorch] add var_mean support* update mean_variance,5
Avoid recursing too deep when redacting logs (#16491)Fix #16473,0
Adding a TimeDeltaSensor,1
[Arith] linear system and equation solver (#5171)* [arith] linear system and equation solverCo-authored-by: Sergei Grechanik <sergei.grechanik+h@gmail.com>* avoid constructing analyzer every time* generate random test cases and address commentsCo-authored-by: Sergei Grechanik <sergei.grechanik@gmail.com>* rename linear_system to int_constraints* add comments and use random seed* message for reporting failure with seed* add SEqualReduce to IntConstraints; allow variables & ranges to be NoneCo-authored-by: Sergei Grechanik <sergei.grechanik+h@gmail.com>Co-authored-by: Sergei Grechanik <sergei.grechanik@gmail.com>,1
Grid fix details button truncated and small UI tweaks (#23934)* Show details button and wrap on LegendRow.* Update following brent review* Fix display on small width* Rotate icon for a 'ReadLess' effect,0
"Avoid calling DAG.following_schedule() for TaskInstance.get_template_context() (#20486)This can use a more modern mechanism since get_template_context() hasenough context (namely, the current data interval).",5
Support ``strategy``/``updateStrategy`` on scheduler (#16069)Allow the schedulers strategy (for Deployment) orupdateStrategy (for StatefulSet) to be set via helm parameters.,2
[Relay] Port param dict save/load from NNVM (#2620),2
"[AIRFLOW-1942] Update Sphinx docs to remove deprecated import structureUpdate Sphinx docs to use correct importstructure. Fixes improperlymocked modules that resulted in hooks notdisplaying. Fixes executorsand operators section, which weren't displayinganything.Closes #2894 from andyxhadji/AIRFLOW-1942",1
[AutoScheduler] Check duplicated names in the compute dag (#6973)* [AutoScheduler] check duplicated names in the compute dag* fix lint* fix pooling* fix pooling,0
fix help message display for dags test subcommand (#8552),3
[PYTORCH]ReplicationPad support added (#5708),1
[relay][vm] move vm opt passes to pass manager (#3323),4
Add Postmates to Airflow users listCloses #1599 from Syeoryn/masterAdd Postmates to Airflow users list,1
Only send email if task.email exists,5
[PASS] add plan memory (#19),1
[AIRFLOW-1723] Make sendgrid a pluginCloses #2727 from fenglu-g/master,1
[CUTLASS] Profile only the largest-possible alignment by default (#10036)* introduce profile_all_alignments option* add profile_all_alignment option to API* wip* fixed dynamic case* black* update gen_gemm too* minor improvement* fix* all tests work* add doc* fixed for sm = 75 case* fix typo* remove unused import* profile_all -> find_first_valid* fix,0
[AIRFLOW-XXX] Add Crealytics to the list of Airflow users (#5446),1
[AIRFLOW-5186] Move GCP Translate to core (#5795)This commit moves GCP Translate from contrib to core.For more information check AIP-21.,5
[ci][docker] Regenerate Jenkinsfile on each run (#11886)This makes it so the generated PRs pass CICo-authored-by: driazati <driazati@users.noreply.github.com>,1
[Relay] Add dynamic SparseToDense (#6892)* [Relay] Add dynamic SparseToDense* Fix comments,0
Removed duplicated dag_run join in Dag.get_task_instances() (#20591)Co-authored-by: hubert-pietron <hubert.pietron95@gmail.com>,2
[AIRFLOW-256] Fix test_scheduler_reschedule heartratetest_scheduler_reschedule runs two schedulerjob quitefast after one another this sometimes is faster thanthe heartrate allows and thus the tasks will not getrescheduled and the test will fail. Fixed by settingheartrate to 0.,1
Sync committers list with Apache project page (#24900),5
Merge pull request #412 from airbnb/test_picklesTesting the pickling,3
Merge pull request #705 from airbnb/tsAdding utility macros around ts,1
[OpenCL] Fix type casting (#11038)* [OpenCL] Fix type castingThe previous PR apache/tvm#11021 was reverted in apache/tvm#11035 dueto it affected performance of generated OpenCL code.This PR fixed the same issue but doesn't lead to performancedegradation. Tested on Resnet50_v2 network.* Implement using select built-in,1
[CUDA][TOPI] Fix CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES with NMS for certain GPUs (#7623)* Use less threads for certain GPUs to avoid register limit* Move util function to nvcc.py* Fix lint,0
Enable the sparse schedule (#3651),0
"[Relay] PlanDevices supports 'free' on_device annotations (#9693)* [Relay] PlanDevices supports 'free' on_device annotationsThis is in support of #9613, which allows PlanDevices to be runafter lowering so as to flow memory constraints in andout of PrimFuncs. That requires a way to insert device_copieswhen the memory scopes chosen during separate lowering of fusedprimitive functions clashes, but otherwise avoid device_copies whenscopes can be chosen so as to avoid them.We support that by generalizing the ""on_device"" annotation toallow the device constraint to be independently controlled forits 'body' and 'result'.# Standard user annotation: body is constrained to Son_device(body, S)# Used by PlanDevices to 'fix' expression to S# (was is_fixed=True)on_device(body, S, constrain_result=True)# Used by PlanDevices to indicate a device_copy can be# inserted if necessary.on_device(body, S, constrain_body=False)# Supported, but currently has no use.on_device(body, S, constrain_result=True, constrain_body=False)A few extra odd's 'n ends collected along the way: - Some CallLowered cleanup which I found useful. - The usual extra debugging output needed as I debugged.   In return I removed some particularly verbose logging I'd   added while tracking down unexpected object copies. - Cleanup warnings from clang-12 as I touch files.* [checkpoint] unused var",1
Doc: Add column names for DB Migration Reference (#23853)Before the automation: https://airflow.apache.org/docs/apache-airflow/2.2.5/migrations-ref.htmlCurrently (with missing column names): https://airflow.apache.org/docs/apache-airflow/2.3.0/migrations-ref.html,2
Fixing MyPy issue inside tests providers microsoft wasb systems (#20967),5
[AIRFLOW-4085] FileSensor now takes glob patterns for `filepath` (#5358),2
[nvcc] enable multiple arch in one fatbin (#4377),0
Add trigger rule tooltip (#26043)* Display operator trigger rule in graph view tooltip* Change order of trigger rule in tooltip* Fix linting errors in airflow/www* Fix additional lint errors in airflow/www/views.py* Wrap trigger rule display in if statement* Add null as 2nd argument to tiTooltip in gantt.jsAccomodates the additional argument for the tiTooltip object* Update airflow/www/static/js/task_instances.jsChange condition for determining if task.trigger_rule is presentCo-authored-by: Brent Bovenzi <brent.bovenzi@gmail.com>Co-authored-by: Brent Bovenzi <brent.bovenzi@gmail.com>,5
"[¬µTVM] Add support for mps2_an521 board (#7813)* [¬µTVM] Zephyr: Allow user inform if a board is emulatedSome boards supported by Zephyr that run emulated by default, i.e. their.yaml config file sets the field ""simulation: qemu"", don't have theprefix ""qemu_"" on their names, so ¬µTVM can't currently recognize it asan emulated target to properly use the QEMU transporter (instead of theserial port) to open a session against it. Such a boards usually havereal physical (hardware) counterparts, being specific boards and notgeneric or ""fake"" ones simply tied to a CPU type of interest.That commit allows the ¬µTVM user to explicitly inform that ¬µTVM needsto use the QEMU transporter to open a session against a given board byadding the suffix ""-qemu"" to the board name. That is necessary becausefor boards that don't have the name prefixed by ""qemu_"" and even thoughrun emulated by default on Zephyr there is no easy way to detect them,since it's not possible to determine it by looking at any Cmakegenerated file or by using the `west` command to query that info.The case where the board is emulated by default but has the prefix""qemu_"" in its board name is already handled by the current code.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [¬µTVM] Add new target mps2_an521This commit adds a new ¬µTVM target to support the Arm reference boardMPS2-AN521, which is based upon a Cortex-m33 core.For more details about that board, please see:http://developer.arm.com/tools-and-software/development-boards/fpga-prototyping-boards/mps2Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [¬µTVM] Add an example for the mps2_an521 boardThis commit adds an example on how to run the Zephyr demo under apps/using as a target the Arm mps2_an521 board, which is emulated by defaulton Zephyr. The example is added to the tutorial script micro_tflite.py,where other examples for other targets exist.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* Fix lintFix lint accordingly to the CI error.* Satisfy lintSatisfy lint about boolean expression format.* Address suggestion from AndrewAddress suggestion from Andrew in the review.Also updates the comment about suffix being trimmed off.Thanks,Gustavo",0
fix typo in backend interpreter (#2752),2
Make docs clear that Auth can't be disabled for Stable API (#13568),2
"add black-format to docker/lint.sh, suppport in-place format (#6601)",2
[ATTR/SYMBOL] Expose op_name attr to python (#132)* [ATTR/SYMBOL] Expose op_name attr to python* fix xcode,0
CMake/make adjustments and warning fix (#106)* CMake/make adjustments and warning fix* Fix warnings,2
[VTA][Chisel] scale dram base address in hardware instead of runtime (#3772)* [VTA][Chisel] scale dram base address in hardware instead of runtime* remove trailing spaces,4
test,3
Deploy the Pretrained Model on Jetson Nano  (#11037)* Create deploy_model_on_nano.pyadd deploy_model_on_nano.py* Update deploy_model_on_nano.py* fix doc build bug* Update deploy_model_on_nano.py* fix ci error* Update deploy_model_on_nano.py,5
Fix spelling (#11821),0
[AIRFLOW-4027] Make experimental tests more stateless (#4854),3
Remove code duplication in the test suite test_views_acl.py (#20887),3
[AIRFLOW-3682] Use aws_default in EMR related operators (#4465),1
[Contrib] Add MKL DNN option (#4323)* [Contrib] Add MKL DNN* update* update,5
[TEST] Add memoize to save test data (#424)* [TEST] Add memoize to save test data* Update comment* mark py version,5
Stop pylint complaining about useless import alias. (#2655)Recent pylint warngs about import renames with no effect.  Removethem.,4
[NNVM/TOPI][OP] Split : default axis to 0 and allow negative values - nump‚Ä¶ (#1883),1
[AIRFLOW-XXX] Add resources & links to CONTRIBUTING.rst (#6405),2
[Contrib] cblas batch_matmul (#3210),5
Added the destionation filename to template_fields GoogleCloudStorageDownloadOperator,1
[CI] update oneDNN to v2.6 (#11140)* enable CI to get and build latest oneDNN release* remove the source code after installed* fix wget error and improve naming* refine the cmake/make commandsCo-authored-by: driazati <9407960+driazati@users.noreply.github.com>* pinned to v2.6 by default* simplify the logic and install to /usr/libCo-authored-by: driazati <9407960+driazati@users.noreply.github.com>,1
Make models/pool.py pylint compatible (#8068)* Make models/pool.py pylint compatible* Fixed for isortCo-authored-by: matsubara <matsubara@matsubaranoMacBook-Pro.local>,0
[AIRFLOW-2778] Explicit import for dag_processing.list_py_file_pathsThe use of utils.dag_processing.list_py_file_paths causes a failure ifutils.dag_processing is not already loaded indirectly.,2
Lowering parallelism on Travis cfg,5
Add Apache 2 License,1
You can sync your fork master with apache/airflow master via UI (#10209)We are using newly added feature of GitHub to add manually triggeredworkflow to enable manually-triggered force-syncing of your forkwith apache/airflow.,1
[DOCS] Fix links (#1263),2
Improve UI file naming/patterns (#12486)* Use friendlier terms for file naming* Correlate asset names to template names,1
Add back 'refresh_all' method in airflow/www/views.py (#10328)closes https://github.com/apache/airflow/issues/9749,0
Fix broadcast shape (#6422)* Fix broadcast shape* Fix test* Minor fix,0
[fix] quantize op consistent with python description (#11872)* move round op before `add expanded_output_zero_point`* consistent with python description `(round(input_tensor/output_scale) + output_zero_point`,1
TVM debugresult dump to Chrome Tracing (#2922),0
[TOPI][x86] Legalize - Support int8xint8 convolution to use VNNI instructions. (#4196),1
[AIRFLOW-5676] Rename CloudSpannerHook to SpannerHook (#6409),1
"Update Kubernetes library version (#18797)Previously we pinned this version as v12 as a change to Kube libraryinternals meant v1.Pod objects now have a logger object inside them, andcouldn't be pickled on Python 3.6.To fix that we have ""backported"" the change in Python 3.7 to make Loggerobjects be pickled ""by name"". (In Python 3.7 the change adds`__reduce__` methods on to the Logger and RootLogger objects, but herewe achieve it `copyreg` stdlib module so we don't monkeypatchanything.)This fix is also applied in to airflow core in a separate commit, but wealso apply it here in the provider so that cncf.kubernetes clientlibrary can be updated but still used with older versions of Airflowthat don't have this fix in.",0
Fix OpenShift Guidelines link in IMAGES.rst (#9978),2
Bugfix around graph's width/height,0
Hive stats collection operator,1
[AIRFLOW-3022] Add volume mount to KubernetesExecutorConfig (#3855)Added volumes and volume_mounts to the KubernetesExecutorConfig so`volumes` or `secrets` can be mount to worker pod.,1
Created initial guide for HDFS operators  (#11212)closes https://github.com/apache/airflow/issues/8197Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>,0
[AIRFLOW-3612] Remove incubation/incubator mention (#4419),4
"[TFLite] QNN support for TFLite 2.1.0 quantized models (#5848)* [TFLite] TFLite 2.x parser quantization support.* Address comments. Fix a bug for depthwise conv* Added tests for relu, conv, quantize. Address comments.* Using web-data. Minor refactoring.* Removing TF hub package* Trigger CI.* Handle TFLite input layer naming.* Addressing reviews.* Retrigger CI.",1
Use version invariant rustfmt (#2886),1
[AIRFLOW-4194] Set dag_run state to failed when user terminate backfill (#5016),1
[CUTLASS] Initial support for conv2d wgrad (#10177)* [CUTLASS] Add wgrad support (without split-k)* run black* wgrad tests now work under pytest* dw conv2d properly supported for wgrad* all tests work* fixed for sm75* cpplint* fix conv2d grad test,3
"[AIRFLOW-356][AIRFLOW-355][AIRFLOW-354] Replace nobr, enable DAG only exists locally message, change edit DAG iconAddresses the following issues:- [https://issues.apache.org/jira/browse/AIRFLOW-356](https://issues.apache.org/jira/browse/AIRFLOW-356)- [https://issues.apache.org/jira/browse/AIRFLOW-355](https://issues.apache.org/jira/browse/AIRFLOW-355)- [https://issues.apache.org/jira/browse/AIRFLOW-354](https://issues.apache.org/jira/browse/AIRFLOW-354)- Replace `<nobr>` with `flexbox`- ""This DAG seems to be existing only locally"" now shows up- Change edit DAG icon from info to edit- Rename `dttm` variable to `file_last_changed_on_disk`- Rename `dags` variable to `webserver_dags`- Adds a comment clarifying what `self.file_last_changed` is- Clarifies what the `dag.last_expired` column represents- Refactors some previously very nested logic in `views.py` and adds comments- Properly indents `dags.html` and adds comments to it- Edit DAG icon changed- Home page now sort of responsive, no longer fixed width- User will occasionally see ""This DAG seems to be existing only locally"" message- Verify that edit dag button is now an edit icon and click on it- Resized home page, check that last column does not wrap![image](https://cloud.githubusercontent.com/assets/130362/17126889/2e7adb12-52b6-11e6-9a18-b31e424e4be8.png)Clean up html, replace nobr with flexboxRefactor HomeViewRename variables and update commentsCloses #1678 from zodiac/xuanji_refactor",4
"Add CI-friendly progress output for tests (#24236)This is the first step to run breeze tests in parallel in CI.This flag adds ""limited progress"" output when running testswhich means that the runnig tests will just print few lines withpercent progress and color status indication from last fewprogress lines of Pytest output, but when it completes, the whole output isprinted in a CI group - colored depending on status.The final version (wnen we implement parallel test execution) shouldalso defer writing the output to until all tests are completed, butthis should be a follow-up PR.",3
"Added ""all"" to allowed breeze integrations and tried to clarify on fail (#9872)",0
Explicitly point Jinja2 documentation to 2.11.x (#15847),2
[AIRFLOW-6548] Restore GCS tests removed by migration (#7152)This PR restores tests that were accidentally removed inhttps://github.com/apache/airflow/pull/6077,4
Make Smart Sensors DB Migration idempotent (#13892),5
Merge pull request #369 from airbnb/template_dict[PythonOperator] pass a dict of templates to get templatified,1
[ARITH] fix zero iter bug in arith (#8494)* fix* black,0
Merge remote-tracking branch 'upstream/master' into systemd,5
[PYTORCH]Activations for pytorch (#5194)* [PYTORCH]Activations for pytorch* Review comments updated,5
Merge pull request #82 from airbnb/fix_hive_hook_to_use_internal_tableUse internal table. Using external was leading to duplicates.,1
"[AIRFLOW-1432] Charts label for Y axis not visibleThe NVD3 charts did _have_ labels on the y-axissaying the unit (hours,minutes etc) but they weren't _visible_. nvd3.jscorrectly places labelson the xAxis, but it doesn't correctly space themon the vertical axis.Closes #2710 from ashb/AIRFLOW-1432-chart-y-axes",2
"[Relay] IndexedGraph improvements in preparation for Collage (#11481)* [Relay] Odd's 'n ends changes to help Collage. - Complete the implementation of WithFields.   (Unfortunately they appear to be without unit tests and I continue this tradition...) - InferTypeExpr for InferTypeLocal but return the expression rather than the type. - Remove python binding of InlineComposites since C++ impl was removed some time ago. - Make IndexedGraph<Expr/DFPattern> more robust as stand-alone datastructure, and avoid unnecessary copies.   This will become a fundamental datastructure in Collage rather than just a helper for DFPatternMatcher. - Extend IndexedGraph with a notion of 'basic block' on every dataflow node. Needed by Collage to   avoid impossible partitions.* - Revert non IndexedGraph changes.* - Stick to 'Indexed graph' terminology- More tests* - Stick to 'Indexed graph' terminology- More tests* - Remove silly unit test",3
[AIRFLOW-477][AIRFLOW-478] Restructure security section for clarityCloses #1775 from alexvanboxel/docs/security,2
Merge pull request #204 from mistercrunch/modelview_filterUsing CRUD for main view,1
[REFACTOR] relay::Module Def -> TypeDef (#4665)* [REFACTOR] relay::Module Def -> TypeDefThe term Def was not very clear about what is the object of interest(could be function def or type def).Changes the term to TypeDef to be more explicit.* Update include/tvm/relay/module.hCo-Authored-By: Wei Chen <ipondering.weic@gmail.com>Co-authored-by: Wei Chen <ipondering.weic@gmail.com>,5
"[AIRFLOW-225] Better units for task duration graphRight now the job duration window defaults to hours, which for short lived tasksresults in numbers out to five decimals. This patch adjusts the scale of the Y-axisin accordance with the maximum value of the durations to be shown.",1
[MetaSchedule] Sample-Perfect-Tile (#9449)Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>,1
Add missing session.commit() at end of initdbThe chart is added to the session but not committed.,1
[AIRFLOW-5333] Move init docs to class docs in PubSub (#5938),2
[AIRFLOW-2539][AIRFLOW-2359] Move remaing log config to configuration fileCloses #3435 fromNielsZeilemaker/env_logging_filename,2
Dispose unused connection pool (#21565),1
properly pass through command-line args in docker/bash.sh (#6599),2
[OpenGL] Let OpenGL texture always be 1024 x nrows. (#817)* OpenGL texture is always 1024 x nrows.* Address review comments.,1
"Retrieve airflow branch/constraints from env variables (#25053)We are using the ""main"" breeze to build even v2-3 images andit has to retrieve the branch and constraints not from thePython constants but from environment variables that areset by build-image.yaml. Otherwise ""main"" is used to push/pullimage and constraints.This pr changes the retrieval in build image to retrievebranch, constraints branch (and debian version) from envvariables if they are set.",1
[typo] sin ==> in (#2238)sin ==> in,2
"Make SchedulerJob not run EVERY queued taskSchedulerJob loads EVERY queued task and tries to run it, which createsconflicts with any other Job trying to do the same (BackfillJob fromCLI or subdag, or potentially [one day] other schedulers). This createsa new method, process_events, which polls the Scheduler‚Äôs own executorfor queued tasks and adds them to a set. The scheduler then onlyconsiders that set when prioritizing queued tasks.",1
Improved the tutorial,1
Make expressions in the DynamicToStatic pass tests more dynamic (#8989),3
AIRFLOW-5529 Add Apache Drill provider. (#16884),1
[AIRFLOW-5182] remove unused incorrect import (#5867),2
"(GitHub CI) update most CI workflows (stale, build-images, etc) (#24705)* Update stale.yml* Update build-images.yml* Update release_dockerhub_image.yml* Update codeql-analysis.yml* Update ci.yml",5
Sort integrations.json by lowercase integration name (#13105),5
"Fix spacing in ``AwsBatchWaitersHook`` docstring (#15839)Sphinx requires the short description to be separated by a newline, otherwise it considers all lines as the short description. See [the rendered docs](https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/_api/airflow/providers/amazon/aws/hooks/batch_waiters/index.html) for the issue - the one liner description is currently ""A utility to manage waiters for AWS batch services **Examples:**"".",0
"update areActiveRuns, fix states (#25962)",0
[Frontend] Prevent tflite frontend from producing int64 shape/parameters (#7030),2
Merge pull request #945 from criccomini/masterAdd documentation to gcs_download_operator,1
"[Relay][Frontend][ONNX] Broadcast condition, x, and y for Where op (#4774)* ONNX frontend broadcast condition* fix* fix styleCo-authored-by: Jon Soifer <jonso@microsoft.com>",0
Merge pull request #853 from airbnb/hotfix_getdagFixing a bug where some dags can't be retrived from DagBag.get_dag,2
Clarify filename_template deprecation message (#25749),2
"[Frontend][TFlite] Cast MirrorPad paddings to int32 (#9468)* [Frontend][TFlite] Cast MirrorPad padding to int32 As an int64 paddings of MirrorPad would generate wrong TIR as result, try to cast to int32 for best compatibility.* [Frontend][TFlite] Add tests for MirrorPad with int64 paddings* Update test_forward.py",3
docfix: Fix a couple of minor typos.,2
Add reference for SubDagOperator (#12297)It would be better for users to have a link when they see SubDagOperator where they can read about it instead of just Class names,2
[VTA][Chisel] rename USE_TSIM macro with USE_VTA64 and cleanup runtime (#3872),1
[Relay][Pass] Add pass to remove unused functions in relay module (#4334)* [Relay][Pass] Add pass to remove unused functions in relay module* Add tests* Fix lint* Fix visit order* Add pass argument* Fix,0
[AIRFLOW-143] setup_env.sh doesn't leverage cache for downloading minicluster,5
[Tutorial]NLP Sequence to sequence model for translation (#1815)* [Tutorial]NLP Sequence to sequence model for translation* Review comments* Review comments updated,5
[AIRFLOW-809][AIRFLOW-1] Use __eq__ ColumnOperator When Testing BooleansThe .is_ ColumnOperator causes the SqlAlchemy'sMSSQL dialect to produceIS 0 when given a value of False rather than avalue of None. The __eq__ColumnOperator does this same test with the addedbenefit that it willmodify the resulting expression from and == to aIS NULL when the targetis None.This change replaces all is_ ColumnOperators thatare doing booleancomparisons and leaves all is_ ColumnOperatorsthat are checking forNone values.Closes #2022 from gritlogic/AIRFLOW-809,2
"[CI][Docker] set environment variables for UTF-8, to prevent errors when running `black` (#8089)* Sets environment shell encoding to UTF-8 * This prevents the black formatting tool to exit with the following error:   ""RuntimeError: Click will abort further execution because Python was    configured to use ASCII as encoding for the environment""",1
"Add MicroTVM tutorial using the STM32F746 discovery board (#5655)* Add MicroTVM tutorial using the STM32F746 discovery boardwith a sample tflite modelSigned-off-by: Tom Gall <tom.gall@linaro.org>* Fix: add a reference to the new turtorials/micro directorySigned-off-by: Tom Gall <tom.gall@linaro.org>* fix: Cosmetic, align Micro TVM text with dividerSigned-off-by: Tom Gall <tom.gall@linaro.org>* Fixes to remove warnings, spaces for readability, code blocksSigned-off-by: Tom Gall <tom.gall@linaro.org>* remove use of dload in favor of requests for obtaining the TFLite modelSigned-off-by: Tom Gall <tom.gall@linaro.org>* add setup for CMSIS_ST_PATHcomment out portion of tutorial that will not run without a physical board availableSigned-off-by: Tom Gall <tom.gall@linaro.org>* Fix warning due to ** in python but part of a comment blockThe block is commented out since it can only run on deviceSigned-off-by: Tom Gall <tom.gall@linaro.org>* Numerous reworks to address feedback.Within docs/conf.py place the microTVM tutorial prior to the VTA tutorialsWithin the micro_tflite  - rework section headers  - reorder code so model prep code is all in one place as well as code    for running on device  - address indentation feedback  - remove '' '' usage which I mistakenly thought was getting around a    sphinx issue involving **Signed-off-by: Tom Gall <tom.gall@linaro.org>* Change disable_vectorize to use current approach with tvm.transform.PassContextChange to pull example model from github with download_testdataAdd 2.5K tflite modelCouple of small changes following https://sphinx-gallery.github.io/stable/syntax.htmlSigned-off-by: Tom Gall <tom.gall@linaro.org>* remove use of relay.build_config in favor of PassContextSigned-off-by: Tom Gall <tom.gall@linaro.org>* Couple of minor 4 space fix upsSigned-off-by: Tom Gall <tom.gall@linaro.org>* Change to use tvm.transform.PassContext for disable_victorize and disabling FuseOpsSigned-off-by: Tom Gall <tom.gall@linaro.org>* Remove binary module from repoChange download_testdata back to pull model from linaro serverSigned-off-by: Tom Gall <tom.gall@linaro.org>* Couple of small cosmetic changes. (spaces and extra lines)Signed-off-by: Tom Gall <tom.gall@linaro.org>* Convert link to tf docs to examine a tf lite model to use RST syntaxSigned-off-by: Tom Gall <tom.gall@linaro.org>",1
"[Relay, TOPI] Add negative log likelihood loss (nll_loss) op (#8056)* add nll_loss* enrich the doc and rename parameters* update upon review* add tests* update based on reviews* update upon reviews* update upon reviews",5
Replace old Airflow screenshots with new images (#9393),1
[Release] resolve license issues (#4408),0
[AIRFLOW-5650] Add GSN Games into airflow users in README.md (#6323),2
[AIRFLOW-2994] Fix command status check in Qubole Check operator (#3790),1
Update README.md typo (#2132),2
"Fix CI Test -- Accidentally quoted ""LEVEL"" instead of it beingldap3.LEVEL",3
[AIRFLOW-XXX] Endesa readme update (#6671),5
[TIR][Printer] Fix SelectNode TIRTextPrinter bracket mismatch (#7405)Co-authored-by: honghua.cao <honghua.cao@streamcomputing.com>,0
Arm(R) Cortex(R)-M55 CPU and Arm(R) Ethos(TM)-U55 NPU Demo App (#8922)This commit adds a demo application that uses TVM to run a model on bare metal Arm¬Æ Cortex¬Æ-M55 CPU and Arm¬Æ Ethos‚Ñ¢-U55 NPU. The demo demonstrates running Mobilenet_v1 TFLite model on the Fixed Virtual Platform (FVP) of the Arm(R) Corstone(TM)-300 reference package.,0
"Ensure we heartbeat the DagFileProcessorManager regularly. (#10706)It could have wedged, (but the process still be alive) and we wouldnever notice.In this I use `time.monotonic` rather than a `datetime` object for tworeasons:1. We don't need the expense of a ""full"" date time object since all we    care about is the second diff between two points in time.2. It is ""more correct"" as `datetime.now()` would be inaccurate if the   system clock changes (NTP etc.)",4
[AIRFLOW-6323] Remove non-ascii letters from default config (#6878),5
Removes Python 3.6 support (#20467)Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>,1
Change the storage of frame to use threadLocal rather than Dict (#21993)There is a very probable WeakKeyDict bug in Python standardlibrary (to be confirmed and investigated further) thatmanifests itself in a very rare failure of thetest_stacktrace_on_failure_starts_with_task_execute_methodThis turned out to be related to an unexpected behaviour(and most likely a bug - to be confirmed) of WeakKeyDictwhen you have potentially two different objects with thesame `equals` and `hash` values added to the sameWeakKeyDict as keys.More info on similar report (but raised for a bit differentreason) bug in Python can be found here:https://bugs.python.org/issue44140We submitted a PR to fix the problem found https://github.com/python/cpython/pull/31685,0
"Doc: Fix remote name in Airflow publishing guide (#18451)Avoid errors such as below:```‚ùØ git checkout constraints-${VERSION_CONSTRAINT_BRANCH}hint: If you meant to check out a remote tracking branch on, e.g. 'origin',hint: you can do so by fully qualifying the name with the --track option:hint:hint:     git checkout --track origin/<name>hint:hint: If you'd like to always have checkouts of an ambiguous <name> preferhint: one remote, e.g. the 'origin' remote, consider settinghint: checkout.defaultRemote=origin in your config.fatal: 'constraints-2-2' matched multiple (2) remote tracking branches```",5
Add example SLA DAG (#19563)This PR adds example SLA DAG,2
add docs (#75),2
"Make spelling of ""axes"" consistent (#7460)",1
Add `OpsgenieDeleteAlertOperator` (#23405)* Add `OpsgenieDeleteAlertOperator`,4
Fixed failing pylint errors introduced in #13403 (#13429)This fixes a failing pylint error introduced in #13403. This erroralso trigger another pylint problem involved with c-extension,0
[AIRFLOW-5231] Fix S3Hook.delete_objects method (#7375),4
[AutoScheduler] Use VM to extract tasks for dynamic models (#7173)* use VM for dynamic shape* make it work* add test* finalize* finalize* format* address comment* comment* improve task extraction,4
[AIRFLOW-6594] Raise an exception when the GCP connection is misconfigured (#7209),5
Misc Improvements,1
[Torch] Add index_put operator (#7465)* [Torch] Add index_put operator* Skip test_frontends.py::test_load_model__pth,3
Prevent text-selection of scheduler interval when selecting DAG ID (#11503),2
[FIX] several bugs found when using NNVM (#391),1
"fix: filter condition of TaskInstance does not work #17535 (#17548)Make sure that after clicking the All Instances button in the Task Instance panel, the results will be filtered by dag_id and task_idcloses https://github.com/apache/airflow/issues/17535",0
Fixing bad ONE_FAILED in recent PR,0
Share app instance between Kerberos tests (#15141),3
Improve Helm Chart Git-Sync documentation (#15937)Mounting DAGs from a private Github repo using Git-Sync sidecar isquite complex because of the several steps required and the manyother moving parts.The PR aims to ameliorate some of these pain points so that users canhave a smoother experience when mounting their DAGs from private reposon Github.,2
Print right number of parentheses for LoadNode (#5965)Stop printing the unnecessary ')' after each LoadNode that didn'thave a matching '('.,5
BugFix: TypeError in monitor_pod (#14513)If the log read is interrupted before any logs are produced then`last_log_time` will not be set and the line`delta = pendulum.now() - last_log_time` will fail with```TypeError: unsupported operand type(s) for -: 'DateTime' and 'NoneType'```This commit fix this issue by only updating `read_logs_since_sec` if`last_log_time` has been set.,1
[REFACTOR][TIR] Introduce PrimFuncPass. (#5139)* [REFACTOR][TIR] Introduce PrimFuncPass.- Introduce PrimFuncPass- Convert one pass to the unified Pass API.* Address comments* Fix comments,0
Add metric for job start/end task run (#8680)Co-authored-by: Ace Haidrey <ahaidrey@pinterest.com>,1
Move static array initialization into a function go avoid link errors (#12678)* Move static array initialization into a function go avoid link errors* Fix line length,0
"Automatically create section when migrating config (#16814)Previously, if a config is migrated to a new section, the migration codewould crash with NoSectionError if the user does not add that section toairflow.cfg after upgrading Airflow. This patch automatically creates anempty section when that happens to avoid Airflow from crashing.",1
v0.4.5,5
[CI] Temporary disable rust test (#3809),3
[AIRFLOW-4929] Pretty print JSON Variables in UI (#5573)- serialize JSON variables with newlines and indentation- use monospace font family for `val` textarea- set height of `val` textarea dynamically,1
Don't display when None (#12415),5
Fix build break on Windows. (#1179),4
"[TVMScript] TracedObject class that simplifies tracing ObjectPaths (#12299)Motivation: when printing a piece of TIR, we need to track an ObjectPath from the root TIR object to the currently printed object. This means that we need a convenient way to maintain an ObjectPath whenever we access a sub-object, e.g. via an attribute.Tracking issue: https://github.com/apache/tvm/issues/11912",0
Use namedtuple for TaskInstanceKeyType (#9712)* Use namedtuple for TaskInstanceKeyType,1
Remove unused usage of logging module (#14632)Unless I am missing something the logging module was imported in the following files but was not used:- airflow/api_connexion/endpoints/dag_source_endpoint.py- airflow/api_connexion/endpoints/version_endpoint.py,2
[FIX] Bug fix for batch_matmul parameters mismatch (#8785),2
Remove legacy image convention (#17692)The image convention has been changed recently and we kept it fora while to allow PRs to run without rebasing. More than a weekhappened since and we can remove the legacy option now.Follow up after #17356,4
Relay reshape reshape_like compute and schedule (#2159),5
Fix tooltip for mapped tasks (#22994)* Fix tooltip for mapped tasks* Only show count when it exists* Handle singular task,0
preserve int division,5
"Migrate jsx files that affect run/task selection to tsx (#24509)* convert all useSelection files to tsUpdate grid data ts, remove some anys* yarn, lint and tests* convert statusbox to ts* remove some anys, update instance tooltip* fix types* remove any, add comment for global vars* fix url selection and grid/task defaults* remove React.FC declarations* specify tsconfig file path* remove ts-loader",4
"[Onnx] Support Bidirectional RNNs (#8337)* modify lstm to be easily bidirectional* make it obvious some matriciies are packed via prime notation* fix var name* more var names* add op split* keyword arg names* missing implicit cls arg* deal with extra dimensions* last of the fixes* refactor rnn tests to support directions* bidirectional tests* test forward results* go backwards* more fixes* reverse tokens on reverse pass* parameterized directions* double up activations in bidirect* slow attribute forgetting* lstm interface is v. confus* test forward complete* add GRU outline* revisiion2* why was tehre a not* gru tests* missing bounds, copy pasta!* add comment* ensure all args fp",1
Docs: Fix grammar in ``docs/apache-airflow/start/docker.rst`` (#18484)Fixed grammatical issues  in ``docs/apache-airflow/start/docker.rst``,2
"Improve Docker cache reuse by pointing to the current version of the image, (#5466)on top of another image to be used as reference.",1
[AIRFLOW-6596] Enforce description should not be empty (#7211),1
Update S3PrefixSensor to support checking multiple prefixes within a bucket (#18807),0
"Increase timeout of the job pushing to GitHub registry (#18856)Building and pushing image to GitHub Registry might take more than10 minutes, depending on the ""CI Build step"" - it can takeshorter or longer, depending on whether the change in Dockerfile,setup.py, setup.cfg.The jobs occassionally fail with 10 minute limit. Changing it to40 minutes seems much more reasonable.",4
[REFACTOR][BOYC] Non recursive partitioning (#5493)* non recursive partitioning* refactor maps* rebase upstream* refactor shared output* address commentsCo-authored-by: Cody Yu <comaniac0422@gmail.com>,1
Support export ADT value in Python (#3299)* Support export ADT value in Python* Cache original functions* Cleanup* Cleanup,4
"use explicit --mount with types of mounts rather than --volume flags (#23982)The --volume flag is an old style of specifying mounts used by docker,the newer and more explicit version is --mount where you have tospecify type, source, destination in the form of key/value pairs.This is more explicit and avoids some guesswork when volumes aremounted (for example seems that on WSL2 volume name might beguessed as path wrongly). The change explicitly specifies whichof the mounts are bind mounts and which are volume mounts.Another nice side effect of this change is that when source ismissing, docker will not automatically create directories with themissing name but it will fail. This is nicer because before itled to creating directories when they were missing (for example.bash_aliases and similar). This allows us to avoid some cleanupsto account for those files being created - instead we simplyskip those mounts if the file/folder does not exist.",2
[AIRFLOW-64] Add note about relative DAGS_FOLDERCloses #1474 from itajaja/patch-1.,2
"[TOPI,CUDA] Don't enable cudnn conv2d kernel if is not supported (#10021)* [TOPI,CUDA] Don't enable cudnn conv2d kernel if is not supportedSpecifically, check that layout is not NCHW if datatype is int8.* remove all conv2d_cudnn int8 support",1
[microTVM]Fix test util functions (#12641)* Fix test utils* Update python/tvm/micro/testing/utils.pyCo-authored-by: driazati <9407960+driazati@users.noreply.github.com>,1
[AIRFLOW-3960] Adds Google Cloud Speech operators (#4780),1
Add airflow connections export command (#9856) (#10081),1
[Refactor][VM] Port memory_alloc to c++ (#7369)* Port memory_alloc to c++* remove memory python pass,4
[COMMUNITY] @anijain2305 -> Committer (#4921),3
"[METAL] set MTLBuffer purgeable state (#6376) (#6438)* [METAL] set MTLBuffer purgeable state (#6376)When using manual reference counting, MTLBufferpurgeable state should be set before releasing.* Fix lint error from tvm-ci",0
Migrate Google calendar example DAG to new design AIP-47 (#24333)related: #22447,1
[AIRFLOW-XXX] Add simple guidelines to unit test writing (#6846),3
Use sql_alchemy_conn for celery result backend when result_backend is not set (#24496),1
"Disclaimer in Kubernetes executor pod template (#19686)This came in when upgrading from 2.1.4 to 2.2.x, and using non-default dag folder.Because of https://github.com/apache/airflow/issues/8061all dags stopped working.Add a note that the examples for pod template are not final,and require more configuration variables to be passed explicitly.",4
Arm(R) Ethos(TM)-U NPU codegen integration (#8849)This commit integrates the codegen for Arm¬Æ Ethos‚Ñ¢-U.* Adding Conv2D tests and a mobilenet_v1 conv2d offload test.Co-authored-by: Grant Watson <grant.watson@arm.com>Co-authored-by: Leandro Nunes <leandro.nunes@arm.com>Co-authored-by: Christopher Sidebottom <chris.sidebottom@arm.com>Co-authored-by: Matthew Barret <matthew.barrett@arm.com>Co-authored-by: Grant Watson <grant.watson@arm.com>Co-authored-by: Leandro Nunes <leandro.nunes@arm.com>Co-authored-by: Christopher Sidebottom <chris.sidebottom@arm.com>Co-authored-by: Matthew Barret <matthew.barrett@arm.com>,3
Merge pull request #202 from mistercrunch/dag_refactorDissociating DagModel object from DAG object,2
[Fix][microTVM] QEMU RPC issue (#8021)* add test* fix test* add parameter to test* cleanup* format* address comments* address comments* direct read/write from/to ring buffer* merge fix* add comment,1
[AIRFLOW-5875] Fix typo in example_qubole_operator.py (#6525),1
"Update set-up-database.rst (#24983)Add notice about MySQL's `NO_ZERO_DATE` mode, which could cause database operation error in some cases.",0
Force order in list API endpoints (#9366),1
link the math library by default (#4713),2
SlackWebhookHook use password instead of extra (#12674)closes: #12214,4
[Relay][Frontend] Tensorflow version support upgrade from 2.1.0 to 2.3.1 (#6706),1
[AIRFLOW-XXX] Links to Pendulum in macros.rst (#5229)* [AIRFLOW-XXX] Links to Pendulum in `macros.rst`* Add links to the Pendulum library in the relevant part of `macros.rst`Signed-off-by: mr.Shu <mr@shu.io>* [ci skip],2
Bump Pandas requirement to <1.0,1
Fix wrong reference in tracking-user-activity.rst (#22745),1
"Remove thrift as a core dependency (#13471)`thrift` is a dependency for Apache Hive and it is not required by Core Airflow:```airflow/providers/apache/hive/hooks/hive.py:489:        # This is for pickling to work despite the thrift hive client notairflow/providers/apache/hive/hooks/hive.py:500:        """"""Returns a Hive thrift client.""""""airflow/providers/apache/hive/hooks/hive.py:502:        from thrift.protocol import TBinaryProtocolairflow/providers/apache/hive/hooks/hive.py:503:        from thrift.transport import TSocket, TTransportairflow/providers/apache/hive/hooks/hive.py:531:            from thrift_sasl import TSaslClientTransportairflow/providers/apache/hive/sensors/hive_partition.py:41:    :param metastore_conn_id: reference to the metastore thrift serviceairflow/providers/apache/hive/sensors/metastore_partition.py:28:    queries generated by the Metastore thrift service when hittingairflow/providers/apache/hive/sensors/named_hive_partition.py:36:    :param metastore_conn_id: reference to the metastore thrift service```",2
Accept custom run ID in ``TriggerDagRunOperator`` (#18788)Fix #17438,0
"Correctly deserialize dagrun_timeout field on DAGs (#8735)We weren't deserializing this correctly (it was left as a float) butnothing _was_ using it, and we hadn't explicitly tested it.We already have example dags with this field, so we just need to checkfor this field.",2
Fixed month in backport packages to October (#11242),0
"[AIRFLOW-2606] Fix DB schema and SQLAlchemy model* Add test that verifies that database schema and SQLAlchemy model are in sync* Add exception for users.password that doesn't exist in model and tables created by other tests* Add migration script to merge the two heads* Add migration script to fix not-null constrains for MySQL that were lost by 0e2a74e0fc9f_add_time_zone_awareness* Add migration script to fix FK constraint for existing SQLite DBs* Enable ForeignKey support for SQLite, otherwise 2e82aab8ef20_rename_user_table won't change FK in chart and known_event tables",2
[build] Update libinfo and add lint rule (#10774)* [build] Update libinfo and add lint ruleThis updates `tvm.support.libinfo()` to be in-line with the current tvm options. It also adds a lint rule to ensure these stay matched up in the future as well as a script to print out the options in more detail. This should add in communication when debugging (i.e. tell someone to run `python -c 'import tvm; tvm.support.describe()` to learn everything you need about their envrionment)* Fix pylintCo-authored-by: driazati <driazati@users.noreply.github.com>,1
[AIRFLOW-1729] improve dagBag timeCloses #3171 from q2w/master,2
Merge pull request #90 from mistercrunch/configFix docs,2
[Quantize] Skip for same input-output domain scale. (#2611),5
Fixes timeout in helm chart tests (#12209),3
Fix TFLite 2.9 tests (#12130)This pr fixes the tests that will be broken when we will update TFLite tothe 2.9 version.We will update TensorFlow and TFLite versions to 2.9 so that we canbenefit from improvements in packaging to support multiple platformsand Operating Systems.,5
Convert issue templates into forms (#17855)Following the discussion athttps://lists.apache.org/x/thread.html/r36d084d83cf7a66698c84185558e1bbe971c59533d4ac5d4994b0aca@%3Cdev.airflow.apache.org%3EThe issue templates are now Forms.,0
"[Relay][Op] Add compute, schedule, and tests for expand_dims and squeeze (#2133)",3
Docs: Fix default 2.2.5 log_id_template (#24455)I accidentally got the wrong default for 2.2.5 when documenting howto fix elasticsearch remote logging after upgrading to 2.3.0+.,2
Only refresh active dags on dags page (#24770)* Only refresh active dags on home page* Make feedback updates* Replace function parameters with object* Fix eslint errors* Update airflow/www/static/js/dags.jsCo-authored-by: Brent Bovenzi <brent.bovenzi@gmail.com>Co-authored-by: Brent Bovenzi <brent.bovenzi@gmail.com>,2
"Fixed a bug in the convert_fully_connected() function (#10371)In case we need to change the output shape, need to convert the output_shape tuple to list before the change.",4
fix db migration downgrade actions (#12608),5
Fix mypy errors in aws/transfers (#20403),0
Add production Build Image in the new Breeze (#21956),1
Add packages to function names in bash (#10670)Inspired by the Google Shell Guide where they mentionedseparating package names with :: I realized that this wasone of the missing pieces in the bash scripts of ours.While we already had packages (in libraries folders)it's been difficult to realise which function is where.With introducing packages - equal to the library file namewe are *almost* at a level of a structured language - andit's easier to find the functions if you are looking for them.Way easier in fact.Part of #10576,1
"[AIRFLOW-5704] Improve Kind Kubernetes scripts for local testing (#6516)* Fixed problem that Kubernetes tests were testing latest master  rather than what came from the local sources.* Kind (Kubernetes in Dcocker) is run in the same Docker as Breeze env* Moved Kubernetes scripts to 'in_container' dir where they belong now* Kubernetes cluster is reused until it is stopped* Kubernetes image is build from image in docker already + mounted sources* Kubectl version name is corrected in the Dockerfile* KUBERNETES_VERSION can now be used to select Kubernetes version* Running kubernetes scripts is now easy in Breeze* We can start/recreate/stop cluster using  --<ACTION>-kind-cluster* Instructions on how to run Kubernetes tests are updated* The old ""bare"" environment is replaced by --no-deps switch",5
corrected invalid port location in connection defaults ... was meant for mssql_default not http_default,5
add lendup,1
[AIRFLOW-XXXX] Fix reference in concepts doc (#7135)Correcting reference in Concepts -> Cluster Policy doc from airflow_setting.py to airflow_local_settings.py,1
Modify db clean to also catch the ProgrammingError exception (#23699),0
error handling in dag refresh and spinner during refresh,2
Add generic CLI tool wrapper (#9223)* Add generic  CLI tool wrapper* Pas working directory to container* Share namespaces between all containers* Fix permissions hack* Unify code styleCo-authored-by: Felix Uellendall <feluelle@users.noreply.github.com>* Detect standalone execution by checking symboli link* User friendly error message when env var is missing* Display error to stderr* Display errors on stderr* Fix permission hack* Fix condition in if* Fix missing env-file* TEST: Install airflow without copying ssources* Update scripts/ci/in_container/run_prepare_backport_readme.shCo-authored-by: Felix Uellendall <feluelle@users.noreply.github.com>,1
[AIRFLOW-5250] Fix dmypy error for gcp hooks (#5856),1
"Make skip_exit_code configurable in BashOperator (#14963)Exit code 127 is used when a command is not found and we don't want toskip those tasks. Exit code 99 was arbitrarily chosen, however, mostimportantly it isn't used as a standard exit code:https://tldp.org/LDP/abs/html/exitcodes.htmlThis also allows users to provide their own `skip_exit_code` if theywant to use a different exit code than the default 99.Co-authored-by: Daniel Standish <15932138+dstandish@users.noreply.github.com>",1
Documenting the cluster policy feature,2
Bugfix: Scheduler fails if task is removed at runtime (#14057)closes https://github.com/apache/airflow/issues/13464,0
Bump version to 1.8.0a4,5
[AIRFLOW-6842] Skip fixing ownership on Mac (#7469),0
[AIRFLOW-4321] Replace incorrect info of Max Size limit of GCS Object Size (#5106),5
"[Airflow 13779] use provided parameters in the wait_for_pipeline_state hook (#17137)I removed wait_for_pipeline_state from start_pipeline hook. By this call, I think we have a bug in this operator, for example when we have pipeline which starting more than 300 seconds, so it have a starting status, we get the error because this pipepline is not in correct state after 300 seconds. Even when we pass our parameters sucess_states and pipeline_timeout we get this error in this case, so I think when I pass both parameters the logic should use them not default. Why we have 300 second and these SUCCESS_STATES + [PipelineStates.RUNNING], because we had these values in the wait_for_pipeline_state call which I removed from hook, I think we should replace this 300 second and use default value from __init__ method (this is a open question I think)",5
Delay the creation of ssh proxy until get_conn() (#20474) (#20474),1
[AIRFLOW-2642] fix wrong value git-sync initcontainer env GIT_SYNC_ROOT (#3519),5
[Relay]Improve Shape Func handling for Tuple inputs (#5467)* Improve Shape Func handling for Tuple inputs* Fix lint* Improve* Fix build,0
[AIRFLOW-XXX] Add Dailymotion to company listCloses #3601 from germaintanguy/master,1
[Topi] Fast mode in take op (#3325),5
fixed typo,2
[AIRFLOW-1089] Add Spark application argumentsAllows arguments to be passed to the Sparkapplication beingsubmitted. For example:- spark-submit --class foo.Bar foobar.jar arg1arg2- spark-submit app.py arg1 arg2Closes #2229 from camshrun/sparkSubmitAppArgs,1
Update README.md (#9798),2
[FFI] Fix global free destruction (#985),0
[AIRFLOW-XXXX] Update .mailmap with some missing authors (#7290),5
Improved instructions for custom image build with docker compose (#21052)* Create build.rst* Update docs/docker-stack/build.rstCo-authored-by: Jarek Potiuk <jarek@potiuk.com>* fix doc buildCo-authored-by: Jarek Potiuk <jarek@potiuk.com>Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>,1
[CODEGEN LLVM GPU] Initialize llvm before lookup for the target (#2683),1
[MetaSchedule] JSONDatabase Utilities (#11680)This PR adds some utility to JSONDatabase to accelerate its loading/saving time.,5
Upgrade `moto` library to version 3.0 (#22005)Update `moto` library to version 3.0,5
[AIRFLOW-2088] Fix duplicate keys in MySQL to GCS Helper function- Remove the duplicate key in`MySqlToGoogleCloudStorageOperator` in the`type_map` helper function that maps from MySQLfields to BigQuery fields.Closes #3022 from kaxil/duplicate-keys-fix,0
"Merge pull request #108 from mistercrunch/adhocTask ""adhoc"" parameter",2
[microNPU][2c] Add performance modelling to cascader (#9778)* [microNPU][2c] Initial Performance Model* Added the pre-computed performance modelling per block.* Added the aggregation of cycles given a stripe config.* Implemented the op-specific performance code for conv2d.* Created a DeviceConfig class to hold constant performance related datathat is dependent on the accelerator configuration* Added generation of all valid block configs. This is pre-computed andgiven as an argument when constructing EthosuParts.* Implemented selection of the block config that gives the least amountof data read given a StripeConfig.* Add test guards* Extended block config testing,3
"Fix mini scheduler not respecting wait_for_downstream (#18310)When wait_for_downstream is set on a task, mini scheduler doesn't respect itand goes ahead to schedule unrunnable task instances.This PR fixes it by checking the dependency in mini schedulerCo-authored-by: Kaxil Naik <kaxilnaik@gmail.com>",5
update webgpu api (#6547),5
Chart: Include Datadog example in production guide (#17996)This is to enable exporting of logs to a Datadog agent running in the same cluster.,1
Unify return_code interface for task runner (#24093),1
"Add parses support for zeros_like tflite operator (#4042)The tensorflow zeros_like operation provided in array_ops.py produces directly a tensor with zeroswithout a graph, using only the shape and type of the input. This imposes the use of gen_array_ops.pythat produces both a tensor and a graph so a comparison between tflite and tvm can be done.",1
[Hexagon] Export `ir_lower_vtcm_pass` function in the init file (#10330),2
[AIRFLOW-8474]: Adding possibility to get job_id from Databricks run (#8475)* [AIRFLOW-8474]: Adding possibility to get job_id from Databricks runCo-Authored-By: Jiajie Zhong <zhongjiajie955@hotmail.com>,1
"[SimplifyExpr] Add simplify for dq->arg funcs (#12580)* add simplify for dq->arg funcs* add comments, fix lint* move comments to the right spots",4
[microNPU][4] Add the cascader Proposal generator (#9959)* [microNPU][4] Add the cascader Proposal generatorThe Proposal generator takes optimal Plans and combinesthem to find optimal 'Proposals' - sets of disjointPlans that cover every Part in a CascaderGraph. Itultimately produces a Pareto-frontier of 'optimal'Proposals in terms of estimated cycles and memory usage.Change-Id: Id42099819a596496a5769bae22f08eeb75ec69b6* FixesChange-Id: I4f5f2a298bd3bb379c7c8d179150358923b0dd66,4
[intrin]support fmod for cuda (#1964),1
"[Relay] Prepare for new plan_devices.cc (part II) (#9130)* Prepare for new plan_devices.cc (part II)These changes came from changing https://github.com/apache/tvm/pull/9038 to usetvm.parser.fromtext instead of manual AST construction.- Demote FunctionOnDeviceAttrs to just a pair of DictAttrs entries so  that the parser will understand them on Function definitions.- Connect some special operators to their attributes so parsing understands them  at call sites.- Don't silently ignore attributes during parsing.- Implement OptFunctionOnDevice so won't add device annotations for kUnknownDeviceType.- Allow the parser to be given an initial metadata map to support examples which  need constants.- More DLOG -> VLOG conversions to reduce debug clutter.* [checkpoint] Keep existing ParseModule ffi to simplify rust bindings* [checkpoint] Address Christopher's comments.* [checkpoint] Andrew's comments from #9038* [checkpoint] Jared's comments from #9038* [checkpoint] Woops, forgot rename.",1
[TVMScript] Add for loop syntax sugar (#9620)* add for loop syntax sugar* remove prints* better doc* finish thread binding* fix CI* fix CI* address comments* update sstub* fix CI* remove failed test* update stub* address comments* add decorator,1
[AIRFLOW-5340] Fix GCP DLP example (#5945)Use do_xcom_push instead of deprecated xcom_push,1
use SetAffinity when logical cores > physical cores (hyperthreading) (#1453),2
"[AIRFLOW-1170] DbApiHook insert_rows inserts parameters separatelyInstead of creating a sql statement with allvalues, we send the valuesseparately to prevent sql injectionCloses #2270 from NielsZeilemaker/AIRFLOW-1170",1
[Relay][VM] Add ReshapeTensor instruction in the VM to replace the reshape op (#6089)* [VM] Add reshape tensor instruction* update* lint* fix* fix,0
[AIRFLOW-6076] fix dag.cli() KeyError (#13647),0
Fixing tests,3
Document `hdfs_namenode_principal` for HDFS connections (#18987)* Document `hdfs_namenode_principal` for HDFS connections,2
"[AIRFLOW-5369] Adds interactivity to pre-commits (#5976)This commit adds full interactivity to pre-commits. Whenever you run pre-commitand it detects that the image should be rebuild, an interactive question willpop up instead of failing the build and asking to rebuild with REBUILD=yesThis is much nicer from the user perspective. You can choose whether to:1) Rebuild the image (which will take some time)2) Not rebuild the image (this will use the old image with hope it's OK)3) Quit.Answer to that question is carried across all images needed to rebuild.There is the special ""build"" pre-commit hook that takes care about that.Note that this interactive question cannot be asked if you run onlysingle pre-commit hook with Dockerfile because it can run multiple processesand you can start building in parallel. This is not desired so instead we failsuch builds.",0
[Relay] More type alpha equality test coverage (#1823),3
Add dmlc-core to the list of installed header directories. (#4035)There are dependencies on dmlc-core in TVM public API headers(e.g. some headers include dmlc/logging.h) so it needs to be installedas part of TVM for TVM headers to be actually usable.,2
fix pynq 32-bit address pointers (#3558),1
Fix references in docs (#8984),2
Pin Hadolint to version released 2020.04.20 (#8485),5
[AIRFLOW-XXXX] Update docs on starting Kubernetes tests (#7530),3
"Fix artifact for MyPy checks (#23094)Occasionally MyPy detects errors which have not been detectedbefore. This is likely caused by having too many files passedto MyPY. If the number of files to pass to MyPy is too big,pre-commit will automatically split the list of files intoseveral ""mypy"" commands. If we are unlucky the list of fileswill cause MyPy to detect slightly different errors.We split the mypy checks to be run separately for airflow coreand airflow providers to limit the list of files to be shorter.We are also preparing for splitting off providers so this isgood idea in general.",1
"Better version handling for Arduino (#11043)* Fix bug allowing microTVM to be used with Arduino version v0.20 and   above (see changes to _parse_connected_boards) and adds relevant unit   tests.                                                                                                                                          * Only perform version check when calling build or flash (things that   actually require arduino-cli), and adds relevant unit tests.                                                                                    * Only raise a warning if the arduino-cli version present is below the  min version (previously any version other than v0.18 would cause an     error).                                                                                                                                         * Change version comparison to use version.check, like the rest of TVM",1
Enable & Fix Whitespace related PyDocStyle Checks (#9458),2
"Gunicorn works better if temporary folder uses tmpfs (#9534)This is discussed in the documentation of gunicorn.You can find more information here: https://docs.gunicorn.org/en/stable/faq.html#how-do-i-avoid-gunicorn-excessively-blocking-in-os-fchmodSince we are using docker, we always have shared memoryavailable (at least 64MB).Closes #9379",2
Removing sql field from being searchabel to fix bug,0
"Gracefully handle missing start_date and end_date for DagRun (#14452)closes: #14384This PR fixes two issues:1) A TypeError that would be raised from _emit_duration_stats_for_finished_state() when the scheduler transitions a DagRun from a running state into a success or failed state if the DagRun did not have a start_date or end_date set.2) An issue with the DagRunEditForm, which would clear the start_date and end_date for a DagRun, if the form was used to transition a DagRun from a failed state back into a running state (or any other state). In the event where the scheduler would determine the DagRun should've been in the failed or success state (e.g. because the task instances weren't cleared), then this would lead to a scheduler crash.",1
Fix regression in SQLThresholdCheckOperator (#9312),1
Simplify chained SQL Queries in Connexion API Endpoints (#9424)- The SQLAlchemy Queries can be nested- The comma filters command can take multiple filters,5
"[LANG/BUFFER] Change buffer arguments to match DLPack order, add scope (#203)",1
[AIRFLOW-7022] Simplify DagFileProcessor.process_file method (#7674),2
"Use local definitions for k8s schema validation (#20544)Instead of using remote schemas to validate helm chart values, we willvendor in the definitions locally so the chart can be used withoutusing outbound connections.There is a precommit hook that will ensure only the definitions we useare included in our schema file, as there are quite a few of them alltogether otherwise.",1
[TE Schedule] Fix broken 2D softmax TE schedules when axis=0 (#11803)* Support arbitrary reduce axis in softmax schedule.* Fix lint.,0
Fix import path for `SageMakerHook` in `airflow/contrib/sensors/sagemaker_training` (#20930),5
Split contributor's quick start into separate guides. (#23762)The foldable parts were not good. They made links not to work aswell as they were not too discoverable.Fixes: #23174,0
Closes apache/incubator-airflow#2484 *Obsolete PR*,5
Finalised Datastore documentation (#20138)Co-authored-by: Dmytro Kazanzhy <dkazanzhy@demandbase.com>,5
"Optimize Multiplatform cache builds (#22258)This PR starts an ARM EC2 instance and forwards socket via SSHso that it can be used by docker buildx build with airflow_cachemulti-platform builders.The instance is created only when ""main"" build reaches the cachebuild job/step. The instances run for maximum 50 minutes andthen self-terminate, also the instance is killed when the jobeither succeeds or fails.",0
[microTVM] Fix RVM onnx dependency and Zephyr document update (#7774)* fixing poetry* fix onnx issue* add zephyr README* Update README.md* clean up* moved onnx* replace with poetry* add tflie,1
Merge pull request #239 from mistercrunch/blur_modeDemo mode - blurs task_ids and other sensitive-ish information,5
[GraphRuntime] Debug graph runtime (#3232),1
"Fix bug in airflow.stats timing that broke dogstatsd mode (#15132)The fix for this was very easy -- just a `timer` -> `timed` typo.However it turns out that the tests for airflow.stats were insufficientand didn't catch this, so I have extended the tests in two ways:1. Test all the other stat methods than just incr (guage, timer, timing,   decr)2. Use ""auto-specing"" feature of Mock to ensure that we can't make up   methods to call on a mock object.   > Autospeccing is based on the existing spec feature of mock.   > It limits the api of mocks to the api of an original object (the   > spec), but it is recursive (implemented lazily) so that attributes of   > mocks only have the same api as the attributes of the spec. In   > addition mocked functions / methods have the same call signature as   > the original so they raise a TypeError if they are called   > incorrectly.",0
[AIRFLOW-4688]: Fix Pylint checks on modules under `scripts` folder (#7850),0
Add RedshiftDataHook (#19137)Use the AWS `redshift-data` API to interact with AWS redshift clustersCo-authored-by: john-jac <jacnjoh@amazon.com>,5
swap pytorch and tvm import order (#7380),2
Support rank-0 tensor (#687)* Support rank-0 tensor* fix lint,0
Fix blueprint confusion when creating the app multiple times through gunicorn,1
[Bugfix][Keras] axis of softmax (#3834),0
Update ubuntu_install_paddle.sh (#9082),1
add onnx reverse sequence op (#7771)Co-authored-by: xp224797 <xp224797@alibaba-inc.com>,1
Show dataset readiness for the next run (#25141),1
"Complete pytorch grid_sample (#10504)Pytorch's grid_sample() supports various interpolation options:(1) data dimension: 2D / 3D(2) interpolation method: nearest / bilinear / bicubic(3) padding_mode: zeros / border / reflection(4) align_corners: True / FalseHowever, TVM only supports a part of above options:(1) data dimension: 2D(2) interpolation method: bilinear(3) padding_mode: zeros / border(4) align_corners: TrueThis commit completes the options not supported by TVM, and keeps existinggrid_sample of onnx/pytorch uninfluenced.Co-authored-by: shukun.net",5
"[TVMC] Allow options on --target to contain dots. (#7651)* Allow tvmc compile --target options to accept dots * Adds testing for dot separator in quoted and unquoted   values * Add an ""unquoting"" conditional so that quoted and   unquoted strings look the same when parsed",1
Properly remove user for test_create_user (#15981),3
Improve various docstrings in Apache Hive providers (#19866),1
Fix typo in elasticearch frontend docs (#16490),2
[Frontend] [Tensorflow] ReadVariableOp operator support (#4952)* tf frontend read variable op* pylint fix* tf frontend freezed graph pruned ops,1
[AIP-31] Implement XComArg to pass output from one operator to the next (#8652)Co-authored-by: Tomek Urbaszek <tomasz.urbaszek@polidea.com>Co-authored-by: Evgeny Shulman <evgeny.shulman@databand.ai>,5
futurize stage 1: remove redundant exception,4
"[UnitTest] Disable ptx mma tests on unsupported nvcc versions. (#10229)* [UnitTest] Disable ptx mma tests on unsupported nvcc versions.- Modified `tvm.contrib.nvcc.get_cuda_version` to return a  `(major,minor,release)` tuple rather than a float.- Implemented `tvm.testing.requries_nvcc_version` decorator to specify  the minimum `(major,minor,release)` version needed to run a unit  test.- Applied decorated to unit tests in `test_tir_ptx_mma.py` that fail  on earlier nvcc versions.* Fix lint errors.* Updated a few of the cuda version checks.* More lint fixes.* Only compare major/minor in find_libdevice, not release version.",0
"[DOCS] Fix Sphinx Warnings (RST indent, cross-ref, and image scale) (#4920)* fix indents* Fix image scale and cross-ref",0
[AMP] Add default op attribute registration to __init__.py (#8460)* add attribute registration to init* blackify* remove unused improt* jostle ci* avoid circular import* change order to match orig* other thingsCo-authored-by: Andrew Zhao Luo <andrewzhaoluo@system76-pc.localdomain>,5
[AIRFLOW-6655] Move AWS classes to providers (#7271),1
Move Compute library to 21.11 (#9754),4
"[microNPU] Fix incorrectly calculated stride when converting NHWC to NHCWB16 (#9560)Fixes an issue that causes strides to be incorrectly calculated when thenumber of channels in the input is less than 16 and involves a conversionfrom NHWC to NHCWB16. This is due to TVM being 'too smart' when analyzinggenerated TE and removing compute that is deemed unnecessary. Consequently,strides over data are incorrectly calculated leading to an outputmismatch.The PR uses a reduce sum operation to trick TE's data dependencyanalyzer into looping over a whole block (16), rather than the numberof channels actually used (< 16). This causes the calculated strides tobe a multiple of 16 which is required for NHCWB16 format.Change-Id: Ibf76a94a12cebf51fa716fcac1de932a271c4a6d",4
[AIRFLOW-425] Add white fill for null state tasks in tree view.Closes #1727 from gwax/tree_null_task_fill,1
Add ``extra_headers`` argument to ``LivyHook`` and ``LivyOperator`` (#16512)Adds an `extra_headers` option to `LivyHook` and `LivyOperator`. This allows passing extra header options to requests before sending a request to Livy. This is required for instance when CSRF protection is enabled (i.e. on HDinsights): https://github.com/MicrosoftDocs/azure-docs/issues/10457.,2
Rename xcom_push -> xcom_push_flag to avoid collision with parent class BaseOperatorhttps://github.com/airbnb/airflow/issues/991,0
Allow to specify path to kubeconfig in KubernetesHook (#10453),1
[Bugfix][Build] Fix building with LLVM-10 on macOS (#5859),0
Reorder migrations to include bugfix in 2.2.4 (#21598),0
fixup! Prepare to switch to debian bullseye (#21522) (#21536),0
[refactor][relay pass] Separate analysis and transform passes (#5035)* [refactor][relay pass] Separate analysis and transform passes into different subfolders* remove pass folder,4
TF argmax - handling int64 datatype (#6674)Co-authored-by: Ubuntu <ubuntu@ip-172-31-0-202.us-west-2.compute.internal>,5
Fix pause/unpause Dag on dag view (#15865)This PR adds a `pausedUrl` via `<meta>` tag that is readable by js instead of a jinja template. This was causing a bug where a user couldn't pause/unpause a dag from the dag page.,2
Add missing description field to Pool schema(REST API) (#19841)The description field is missing in pool schema,1
[CI] Force doc build pass to mark success (#158),4
[AIRFLOW-6619] Add cluster_fields to BigQueryCreateEmptyTableOperator (#7242),1
use dbapihook as base for jdbchook,5
fix typo in google provider additional extras (#24431),1
"[microNPU] Fix offloading incompatible average pool (#11469)Fixes offloading a few corner cases of average pooling. Specificallynot offloading nn.avg_pool2d when:* The attribute count_include_pad=True* Padding exceeds the dimensions [3, 3, 4, 4]* The pool size is greater than [8, 8] when the pool uses paddingChange-Id: I7be546e28ebe1f17482f3ed3cee56996a71bfcd1",4
Deprecate `DummyOperator` in favor of `EmptyOperator` (#22832)* Deprecate `DummyOperator` in favor of `EmptyOperator`,1
Update test connection functionality to use custom form fields (#21330),1
"[CI] Update docker image ci_cpu,i386 to include verilator (#3738)",2
"[Relay] s/SEScope/VirtualDevice/g (#9759)* [Relay] s/SEScope/VirtualDevice/gNobody liked 'SEScope', and 'DeviceMcDeviceFace' is too verbose, so itseems 'VirtualDevice' has the popular vote.",5
"more flexible UT execution- we now can specify nose parameter on the command line of ./run_unit_test.sh.- if unspecified, the script falls back to previous behaviour, i.e. run all UTs",1
Add Operation class,1
Reject 'connections add' CLI request if URI provided is invalid (#12370)The validity is decided by availability of both 'scheme' and 'netloc' in the parse result,1
"[AIRFLOW-1393][[AIRFLOW-1393] Enable Py3 tests in contrib/spark_submit_hook[The unit tests in`tests/contrib/hooks/test_spark_submit_hook.py`were skiped if run in Python3 because some testcases loop foreverdue to a mismatch/misunderstanding about bytes vsstring that didn'tmatter under Py2 (i.e. the mocked data forsubprocess.Popen wasreturning a String, but the actual Popen callwould return bytes.)The fix is to use bytes and `six.ByteIO` so thatthe tests work on Py2and Py3. Alsowe had to patch `subprocess.Popen` inthe right place sothe mocks are picked up.Closes #2427 from ashb/enable-spark_submit_hook_tests-py3",3
Rename operator mapping map() to apply() (#21754),1
xcode.py: Decode bytes before output (#2833),5
[Core][Build] Move build module transformations and utilities to C++ (#9103)* Initial investigation* More progress!* More progress / notes* rewrite build_for_device mostly in c++* More progress* Initial split of transformations applied to device and host as post split action from mixed module* Combine duplicate passes after spliting mod on aot and vm flows* Minor cleanup* Move target mangling to driver_api.cc* Move more build utlities to cpp driver api* [Build][WIP] Moving build utilities to C++ from Python* [Build] Remove comments* [lint] Pass black* More formating* Move more build functionality into cpp* Remove comments* Remove unused defs and imports* Address PR comments* More PR comments* More comments* More comments* Add comments on the new split function* Fix PR comments on clarity* Test CI* Fix format* Refactor build* Expose splitted composite passes to python* Format files* Test fix* Fix for annotating entry funcs on code targeting CPU* Prevent entry funcs to be annotated when compiling for CPU with C runtime enabled* Guard for aot executor entry* Sphix format* Sanity fix* Sphinx fixCo-authored-by: electriclilies <lilyorthsmith@gmail.com>,0
Merge pull request #1228 from jlowin/remote-logging-fixDon't lstrip remote storage URL because it could strip the bucket name,1
[TFLite] Fix detection of crop in convert_batch_to_space_nd (#6670),0
[TIR] Check dynamic shared memory in VerifyGPUCode (#10923),5
[MAINTAINER] add srkreddy1238 as reviewer (#1305),1
Merge pull request #1870 from gtoonstra/maxactiveruns_fix,0
Fixing tests,3
Register SkipVectorize (#3228),5
[AIRFLOW-686] Match auth backend config sectionThis commit makes that refers the sameconfiguration when usingldapgroup owner mode with ldap auth.Closes #1930 from keybod/AIRFLOW-686,1
[Pytorch] Add quantized::leaky_relu (#11729)* emptycommit 2nd try* add operator and test* example output* lint with black* register param index* remove assert as it is a warning in torch* fix algo bugCo-authored-by: yuanfz <42092999+FZYUAN-1@users.noreply.github.com>,1
"[AIRFLOW-3078] Basic operators for Google Compute Engine (#4022)Add GceInstanceStartOperator, GceInstanceStopOperator and GceSetMachineTypeOperator.Each operator includes:- core logic- input params validation- unit tests- presence in the example DAG- docstrings- How-to and Integration documentationAdditionally, in GceHook error checking if response is 200 OK was added:Some types of errors are only visible in the response's ""error"" fieldand the overall HTTP response is 200 OK.That is why apart from checking if status is ""done"" we also checkif ""error"" is empty, and if not an exception is raised with errormessage extracted from the ""error"" field of the response.In this commit we also separated out Body Field Validator toseparate module in tools - this way it can be reused betweenvarious GCP operators, it has proven to be usable in at leasttwo of them now.Co-authored-by: sprzedwojski <szymon.przedwojski@polidea.com>Co-authored-by: potiuk <jarek.potiuk@polidea.com>",1
"Add note in Updating.md about FAB datamodel change (#14478)Use of CustomSQLAInterface instead of SQLAInterface to create custom data model.From Airflow 2.0, if you want to define your own Flask App Buildermodels you need to use CustomSQLAInterface instead of SQLAInterface.For Non-RBAC replace:`from flask_appbuilder.models.sqla.interface import SQLAInterface``datamodel = SQLAInterface(your_data_model)`with RBAC (in 1.10):`from airflow.www_rbac.utils import CustomSQLAInterface``datamodel = CustomSQLAInterface(your_data_model)`and in 2.0:`from airflow.www.utils import CustomSQLAInterface``datamodel = CustomSQLAInterface(your_data_model)`",5
[QNN] Add per-channel quantization to add/subtract/multiply (#10718)* Add per-channel quantization to QNN add/subtract/multiply* Add feedback* Add feedback - round 2* Fix for arm test* Add params to the test* Try again* Try int* Move lhs_axis and rhs_axis* Add as an attribute* Add quotes,1
[AIRFLOW-5781] AIP-21 Migrate AWS Kinesis to /providers/amazon/aws (#6588),1
[ONNX]LpPool Support added (#5696),1
Allowing for relative path and dot notation for -sd,1
Merge pull request #823 from airbnb/fix_infer_trFixing bad ONE_FAILED in recent PR,0
[CI][VitisAI] Update CI Vitis AI PyXIR version to v0.3.1 (#8814)* Update CI Vitis AI PyXIR version to v0.3.1* Add Vitis AI requirements to gen_requirements.py,1
[Runtime][MISRA-C][Bundle] Bundle deployment with static linking (#5158)* test file for static link added* rename files* Fixed static linking issue* cleanup* changed to dynamic and static demo* MISRA-C static and dynamic test* cleanup* cleanup* Update README.md* cleanup headers* update readme,5
correct call to set_dependency,1
[TensorFlow] Fix a bug output index is ignored (#3631)Enhance test to cover this case,3
[BUFFER] Smarter slice to detect compactness (#587)* [BUFFER] Smarter slice to detect compactness* move simplify of begins early,4
[TEST] Various CI fixes for the VTA and Relay  (#5181)* [VTA] Set the correct type for synchronize* Fix the legacy API* Temporary remove the structural equal,4
"Snowflake Provider: Improve tests for Snowflake Hook (#20745)This PR improves `test_run_storing_query_ids_extra` test for Snowflake Hook.- Redundant testing of `Snowflake.get_conn` (This is already tested in `test_get_conn_should_call_connect`)- The expected values were derived from input, so you can't easily fail the test ! I have passed expected results and input separately- We were passing duplicate values in `query_ids`. I have fixed that by changing the code to only access `cur.sfqid` once in a variable and reuse that variable for logging and returning.Co-Authored-By: bharanidharan14 <94612827+bharanidharan14@users.noreply.github.com>",1
Merge pull request #233 from mistercrunch/artwr/fixed_S3_wildcard_checkFix an iterate on None issue,0
[AIRFLOW-868] Add postgres_to_gcs operator and unittestsAdds a postgres_to_gcs operator to contrib so that a user can copy adump from postgres to google cloud storage. Tests write to localNamedTemporayFiles so we correctly test serializing encoded ndjson inboth python3 and python2.7.,5
Remove trigger-dag-run with configuration from quarantine (#16818)This test caused missing failure that manifested in 2.1.1 inthe #16810,0
[Relay] Keras frontend upsample and 1 channel conv2d fixes (#3937)* Fix upsample layout in keras frontend.* Fixed group conv being used instead of conv when channels=1* Add new conv2d test to catch bugs when channels=1.,0
[AIRFLOW-4000] Return response when no file (#4822),2
[Oracle] Oracle Hook - automatically set current_schema when defined in Connection (#19084),1
"[AutoTVM][RPCRunner] timeout is not passed correctly (#6924)* [AutoTVM][RPCRunner] timeout is not passed correctly* like @merrymercy suggests, scale timeout with (n_parallel + 1)* Apply suggestions from code review* Apply suggestions from code reviewCo-authored-by: Lianmin Zheng <lianminzheng@gmail.com>",4
"[Relay] Fix TFlite frontend for unpack, stridedslice (#10333)We found this while converting an RNN model.The relay tflite frontend use squeeze at converting unpack, but when theunpack.axis=0, `None` is passed to relay.squeeze(), which would squeezeall dimensions with length 1, causing different results from TFLite.A possible fix might be, assign the unpack.axis as-is to relay.squeeze()As for stridedslice, when the tflite frontend handles shrink_axis_mask,the wrapped `begin` should be used, instead of the original one whichcan be negative. It can cause errors athttps://github.com/apache/tvm/blob/d65ff6594d4d6db0062537a1d43c0504173b8e5c/include/tvm/topi/detail/strided_slice.h#L140Related cases are also added to the python test.",3
Add redshift create cluster snapshot operator (#25857),1
[ARITH] normalize iter affine map expr to PrimExpr (#7759),5
"[Rust] Fix memory leak #2 (#8725)* Add C++ API for computing type key from type index* Try and isolate leak* Rewrite the bindings to fix the ArgValue lifetime issueThere are still quite a few issues left to resolve in this patch, but I believe the runtimechanges stablize memory consumption as long as the parameters are only set once. ByteArrayalso has some totally broken unsafe code which I am unsure of how it was introduced.* Finish handling tvm-rt issues due to ArgValue lifetimeThis patch further refactors the bindings to better handle thelifetime issues introduced by detecting the argument memory leak.* WIP memory leak* There is issue using TVMCb function which is breaking refcount* Fix fallout from the lifetime refactor* Another tweak* Follow up work from the memory leak, attempt to clean up ByteArray* Add some todos for future work* Fix doc string* Clean up the changes* Format",4
[Adreno] Change compute/schedule for ToMixedPrecision pass (#12537)* [Adreno] Change compute/schedule for ToMixedPrecision pass* Address CI fails* address PR comments* Fix AutoTVM flow,0
[AutoTVM][BugFix] Fix autotvm on the conv2d_nchw_winograd.mali operator (#6130)* [AutoTVM] Fix conv2d_nchw_winograd.mali* Fix pylint errorCo-authored-by: Yanming Wang <yanmwang@amazon.com>,0
[AIRFLOW-3550] Standardize GKE hook (#4364),1
[AIRFLOW-908] Print hostname at the start of cli runCloses #2329 from AllisonWang/master,1
Update logging & doc for LocalFilesystem Secrets Backend (#12597)- Support towards YAML is added in PR https://github.com/apache/airflow/pull/9477  Most docs were updated for this. But a few docstrings and exception logging were missed,2
[AIRFLOW-2473] Fix wrong skip condition for TransferTestsThis PR fixes wrong @skipUnlessImported whichdecoratesTransferTests and does minor refactoring.Closes #3411 from sekikn/AIRFLOW-2473,4
Merge pull request #199 from mistercrunch/fixs3_to_hives3_to_hive: Move init of hooks to execute method,1
Add workers extraVolumes to Kubernetes pod template for Helm Chart (#14743),2
Fix error when running tasks with Sentry integration enabled. (#13929)Co-authored-by: Ash Berlin-Taylor <ash@apache.org>,0
[microNPU] Add support for LeakyReLU (#10127)* [microNPU] Add support for LeakyReLUAdds support for offloading an int8 Leaky ReLU activation functionto the NPU by legalizing to a LUT.Change-Id: I63dd5b16a1a2a747b11f15a5b8124810e2ebf491* refactor LeakyReLUParams to inherit from LutActivationParamsChange-Id: I35b59200b16a7eff1915f771ab6b5d9181d4f3ab,4
[AIRFLOW-950] Missing AWS integrations on documentation::integrationsCloses #2552 from Swalloow/master,2
Increasing type coverage for salesforce provide (#11135),1
Airflow UI fix vulnerabilities - Prototype Pollution (#24201),0
Replace nuke with useful information on error page (#11346)This PR replaces nuke asciiart with text about reporting a bug.As we are no longer using asciiarts this PR removes it.,4
added one more UT for WIthLogger + a few more tested cases +  minor code cleanup,4
[TIR][LowerMatchBuffer] Fix lowering strides when source region has higher dimension than the buffer (#9145)* [TIR][LowerMatchBuffer] Fix lowering strides when source region has higher dimension than the buffer* use int instead of size_t,1
"Fix tree view if config contains "" (#9250)If you run DAG with `{""\"""": """"}` configuration tree view will be broken:```tree:1 Uncaught SyntaxError: Unexpected string in JSON at position 806    at JSON.parse (<anonymous>)    at tree?dag_id=hightlight_test&num_runs=25:1190```JSON.parse is given incorrectly escaped json string.",5
[bashoperator] making env param a templated field,2
Fix retries causing constraint violation on MySQL with DAG Serialization (#9336)The issue was caused because the `rendered_task_instance_fields` table did not have precision and hence causing `_mysql_exceptions.IntegrityError`.closes https://github.com/apache/airflow/issues/9148,0
Support additional apt dependencies (#9189)* Add ADDITONAL_DEV_DEPS and ADDITONAL_RUNTIME_DEPS* Add examples for additional apt dev and runtime dependencies* Update comment* Fix typo,2
Add Vikram in the Airflow Committer's list (#13489),1
Add `2.3.0rc2` to issue templates (#23298),0
[TOPI] add binary broadacst (#456)* add binary broadacst* fix testing* revise testing threshold,3
Remove redundant parentheses from Python file (#14336),2
Add `passphrase` and `private_key` to default sensitive fileld names (#16392),2
[Meta Schedule][M3a] TaskScheduler (#9154)* Add docs.* Add TaskScheduler.Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>* Retrigger CI after hotfix.Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>,1
[VM] Move param bind to OptimizeModule (#7451)* [VM] Move param bind to OptimizeModule* add test to verify the number of free vars after opt* remove const from OptimizeModule,4
fix android packed runtime (#1430),1
Make extra link work in UI (#25500),1
"[AIRFLOW-2500] Fix MySqlToHiveTransfer to transfer unsigned type properlyMySQL supports unsigned data types, but Hivedoesn't.So if MySqlToHiveTransfer maps MySQL's data typestoHive's corresponding ones directly (e.g. INT ->INT),unsigned values over signed type's upper boundtransferred from MySQL are interpreted as invalidby Hive, and users get NULL.To avoid it, this PR fixes MySqlToHiveTransferto map MySQL data types to Hive's wider ones(e.g. SMALLINT -> INT, INT -> BIGINT, etc.).Closes #3446 from sekikn/AIRFLOW-2500",5
SageMaker system tests - Part 1 of 3 - Prep Work (AIP-47) (#25078)* Sagemaker Operator - Improve type hints and docstrings* SageMaker Operator Unit Test Improvements- Add explicit unit testing for integer_fields- Improve type hinting- Standardize some variable naming* Sagemaker Operators - Configure integer fields at runtime,1
[MetaSchedule][Test] Add unittests for NRM (#12250),3
Cosmetic polish,1
"Renames main workflow to `Tests` (#17650)This is a long-overdue change for CI workflows. Since we are buildingimages in a separate workflow, the `CI Builds` name of the workflowwas - first of all misleading, and secondly - too long. The workflownames displayed in the GitHub UI contains the workflow name as prefixso having as short as possible name is an advantage.The `Tests` names seems to be appropriate because this is in factwhat we do in this workflow.The change updates the name of workflow as well as documentationthat referred to it and fixes a few inconsistencies found innames of the `Build Image` -> `Build Images` workflow.The sequence diagrams showing the CI workflow have been alsoregenerated with the new name (thanks to mermaid it was super-easy)",1
Fix deprecation messages in airflow.utils.helpers (#9398),0
Move LOAD_DEFAULT_CONNECTIONS env var to database config section in CI (#24536),5
[Target] Add Target Parser for Arm(R) Cortex(R) M-Profile CPUs (#12319)This implements an initial Target Parser which uses the same logic asthe CMSIS-NN compiler flags to update the features and keys of the `c`and `llvm` `Target`s.Refactoring of the CMSIS-NN logic will be in a separate patch.,2
Update `airflow tasks *` commands to lookup TaskInstances from DagRun Table (#16030)This change allows to lookup TaskInstances using DagRun.run_id in task commandsCo-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>,2
[BUGFIX] Fix search path for libtvm_topi.so (#4467),0
Fix helm unit test for pod_template_file (#12345)Fixes bug in unittest that is causing master to fail.,0
import str from builtins,2
"Fix json serialization for NDArray (#11303)When `NDArray` is being stored as `ObjectRef`, the serializer won't trigger the right path for storage. Under the new serialization mode, we need to be able to leverage the `repr_bytes` mechanism to save `NDArray`.This change is backward compatible -- ndarray saved in previous format will continue to work. And fixes the problem of serialization when `NDArray` is involved as part of `ObjectRef`. In the future, we can consider consolidate the `NDArray` save into the `repr_bytes` and remove the specialization as we evolve to newer versions",1
"Allow switching xcom_pickling to JSON/Pickle (#12724)Without this commit, the Webserver throws an error whenenabling xcom_pickling in the airflow_config by setting `enable_xcom_pickling = True`(the default is `False`).Example error:```>           return pickle.loads(result.value)E           _pickle.UnpicklingError: invalid load key, '{'.airflow/models/xcom.py:250: UnpicklingError--------------------------------------------------```",0
futurize stage 1: absolute imports,2
Upgrade PIP to 22.0.4 (just released) (#22081),5
Add Databricks provider to boring cyborg (#25238),1
[AIRFLOW-6165] Housekeep utils.dates.date_range & add tests (#6720),3
Fix select * query xcom push for BigQueryGetDataOperator (#22936)Use in instead of get for conditinal check,1
Fix typographical error. (#6664),0
[HEXAGON] QCOM hexagon library (qhl) (#12149)* qcom hexagon library (qhl)* fix lint errors* fix lint errorsCo-authored-by: aakaverm <aakaverm@qti.qualcomm.com>,0
"[ETHOSN] Streamline Ethos(TM)-N cross-compile rpc usage (#9477)* When cross-compiling the runtime or rpc application, LLVM is not  required so don't insist on it being enabled for Ethos-N.",0
"Production images on CI are now built from packages (#12685)So far, the production images of Airflow were using sourceswhen they were built on CI. This PR changes that, to buildairflow + providers packages first and install themrather than use sources as installation mechanism.Part of #12261",1
Fix deprecation messages after splitting redshift modules (#20366)We recently split redshift into redshift_sql and redshift_cluster. Somehow I screwed up the module paths in the deprecation messages.,0
[TOPI] Enable scatter_add on GPU  (#6856)* enable scatter gpu test on cuda* adding update_func arg* pytorch scatter_add gpu tests working* update 3d and 4d scatter* enable scatter_add gpu testCo-authored-by: masa <masa@pop-os.localdomain>,3
[REFACTOR][IR] Move to runtime::String (#5276)* Use runtime::String* move string to tvm namespace* add const char* constructor* implicit cast from std::string,1
Detect invalid package fiiters (#12996),5
[FRONTEND][ONNX] Some bug fixes and Shape operator fixed for relay. (#2850)* [FRONTEND][ONNX] Some bug fixes and Shape operator fixed for relay.* * test cases* * ci error,0
Backport packages are renamed to include backport in their name (#8767),5
Allow Linker script files to be committed (#8745)This is a source file type needed for https://github.com/apache/tvm/pull/8744Co-authored-by: Grant Watson <grant.watson@arm.com>Co-authored-by: Grant Watson <grant.watson@arm.com>,2
[RELAY][PASS] add a relay pass to count #macs of a model (#2609)* add a relay pass to count #macs of a model* remove unnecessary includes* fix end-of-file issues* address review comments* remove test resnet* address more review comments* use data layout string to locate the input channel* fix bug in conv 2d output tensor checking* C must exist,0
"Update refreshing constraints instructions (#21001)After changing to buildx, instructions to refresh constraintsshould not include --local-cache, because buildx efficientlycaches rebuilds anyway and if you have not build ""upgrade""image before locally, --local-cache is not useful.",1
[RUNTIME] Unify load params interface (#7559),2
[AIRFLOW-741] Log to debug instead of info for app.pyCloses #1977 from bolkedebruin/AIRFLOW-741,5
[NNVM] Fix check in layout parsing (#1502)* [NNVM] Fix check in layout parsing* add one workload,1
"Improve validation of Group id (#17578)When Group id of task group is used to prefix task id, it shouldfollow the same limitation that task_id has, plus it should nothave '.'. The '.' is used to separate groups in task idso it should not be allowed in the group id.If this is not checked at Task Group creation time, users willget messages about invalid task id during deserializationand it's not entirely obvoius where the error came fromand it crashes the scheduler..Also this validation will be performed at parsing time, ratherthan at deserialization time and the DAG will not even getserialized, so it will not crash the scheduler.Fixes: #17568",0
Add package filter info to Breeze build docs (#18550),2
Fix `collect_dags` docstring typo.,2
Detect partial examples DAGs for Google (#12277),2
Fix three typos (#5620)Co-authored-by: Zeng Liyong <liyong.zeng@streamcomputing.com>,2
[AIRFLOW-4459] Fix wrong DAG count in /home page when DAG count is zero (#5235),2
[Doc] Correct description for macro task_instance_key_str (#11062)Correction based on code https://github.com/apache/airflow/blob/master/airflow/models/taskinstance.py,2
"add Fernet key to test config- congiguration.py now generates the test config and real airflow config with the same method- fix warning logs in local UT execution, related to missing FERNET-KEY in unittest.cfg- fix warning logs in Travis UT exeuction, related to missing FERNET-KEY in airflow_travis.cfg- added one to validate config generation",5
"[TVMC][microTVM] Add new micro context (#9229)* [microTVM] zephyr: Make platform options comply with RFC-0020Make Zephyr platform options comply with RFC-0020 specification.Project options now need to specify the required metadata for everyoption, i.e. 'required', 'optional', and 'type'.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [microTVM] arduino: Make platform options comply with RFC-0020Make Arduino platform options comply with RFC-0020 specification.Project options now need to specify the required metadata for everyoption, i.e. 'required', 'optional', and 'type'.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [microTVM] crt: Make crt options comply with RFC-0020Make crt project options comply with RFC-0020 specification.Project options now need to specify the required metadata for everyoption, i.e. 'required', 'optional', and 'type'.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [microTVM][Unittest] Adapt test to RFC-0020Adapt test to new metadata fields accordingly to RFC-0020 specification.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [microTVM] Add info() method to GeneratedProject classAdd info() method to GeneratedProject class so one can use the ProjectAPI to query options for project dirs instead of only for templateprojects.This commit also adds for the sake of convenience a setter and a getterfor 'options' in case it's necessary to set or get 'options' after aGeneratedProject class is instantiated without initializing 'options'.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [microTVM] Fix typo in python/tvm/micro/session.pyFix typo in comment.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* Allow multiple runs on micro targetsCurrently there is a limitation on microTVM / TVM which doesn't allowrunning a model multiple times in sequence without previously flashingthe model to the device.Root cause is that RPCModuleNode class destructor is called once a runfinishes. The destructor sends a RPCCode::kFreeHandle packet withtype_code = kTVMModuleHandle to the device which wipes entries incrt/src/runtime/crt/common/crt_runtime_api.c:147:static const TVMModule*registered_modules[TVM_CRT_MAX_REGISTERED_MODULES] when TVMFreeMod() iscalled when the target receives a kFreeHandle packet.Hence when one tries to re-run a model registered_modules[0] == NULLcauses a backtrace on the host side. Probably never before a model onmicroTVM was run without being flashed just before the run, so tvmc runimplementation for micro targets exposed the issue.This commit fixes it by not calling TVMFreeMod() for system_lib_handleon the target side when a session terminates so the pointer to thesystem_lib_handle is not flushed from 'registered_modules', allowingmultiple runs on micro targets.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [TVMC] Pass main parser when calling add_*_parser functionsCurrently when a add_*_parser functions are called in main.py to buildand add the various subparsers to the main parser only a subparser ispassed to the functions. However if one of these functions need to builda dynamic parser it needs also to call the main parser at least once toparse once the command line and get the arguments necessary to finallybuild the complete parser.This commit fixes that limitation by passing also the main parser whencalling the subparser builders so it can be used to build the dynamicsubparses.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [TVMC] micro: Add new micro contextThis commit introduces support for micro targets (targets supported bymicroTVM). It creates a new micro context under the new TVMC command'tvmc micro'. Moreover, three new subcommands are made available in thenew context under 'tvmc micro': 'create-project', 'build', and 'flash'.The new support relies on the Project API to query all the optionsavailable for a selected platform (like Zephyr and Arduino) and alsofrom any adhoc platform template directory which provides a customProject API server.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>* [TVMC] run: Add support for micro devicesAdd support for micro devices using the Project API to query all optionsavailable for a given platform and open a session with an specifiedmicro device. Use of 'tvmc run' with micro device is enabled via the'--device micro' option in addition to the project directory.Once the project directory is specified 'tvmc run' will make all optionsspecific to the platform found in the project dir available as optionsin 'tvmc run'. They can be listed by '--list-options' and passed via'--options'.Signed-off-by: Gustavo Romero <gustavo.romero@linaro.org>",4
"Remove pointer arithmetic in StorageObj::AllocNDArray (#7890)The data pointers returned by AllocDataSpace are intended to be opaquehandlers, where previous implementation assumed pointer arithmetic isvalid on them.  Updated to instead use the byte_offset field toindicate the offset in the allocated array.Co-authored-by: Eric Lunderberg <elunderberg@octoml.ai>",5
"Task Instance Modal UX Enhancements (#10944)* Improve modal UX with logical form ordering, semantic form elements, visual hierachy tweaks* make modal header prefix dynamic if SUBDAG* Add heading as demarcation between action sections within modal* Update doc screenshot w/ added modal heading",1
Optimize the implmentation of scale (#10884),5
Fix parsing file that contains multi byte char,2
[AIRFLOW-5801] Get GCP credentials from file instead of JSON blob (#7869)* fix assumption of getting gcp credentials from file instead of JSON blob* fix deprecation warning,2
[Target] Remove deprecated parameters from target (#12416)* remove depricated parameters in target* lint* fix cpp testsfix* remove more configs in test files* address comments* fix error* fix hexagon* fix micro tutorial* fix integration tests* fix hexagon* lint* fix unittest* fix readme* fix assert executor in target* address comments* fix tutorials* fix hexagon target* fix tutorial* fix for tutorials* hexagon,0
Update setup.py (#803)fix errors when running `python3 setup.py sdist bdist_wheel`,1
An operator to post messages to a Slack Channel,1
[AIRFLOW-537] Add WiseBanyan as Airflow user[]Closes #1815 fromkevinjmullen/AIRFLOW-537-WiseBanyan,1
Changed script to be the existing script name.,4
[AIRFLOW-1593] expose load_string in WasbHookCloses #2596 from NielsZeilemaker/AIRFLOW-1593,1
"Speed up clear_task_instances by doing a single sql delete for TaskReschedule (#14048)Clearing large number of tasks takes a long time. Most of the time is spent at this line in clear_task_instances (more than 95% time). This slowness sometimes causes the webserver to timeout because the web_server_worker_timeout is hit.```        # Clear all reschedules related to the ti to clear        session.query(TR).filter(            TR.dag_id == ti.dag_id,            TR.task_id == ti.task_id,            TR.execution_date == ti.execution_date,            TR.try_number == ti.try_number,        ).delete()```This line was very slow because it's deleting TaskReschedule rows in a for loop one by one.This PR simply changes this code to delete TaskReschedule in a single sql query with a bunch of OR conditions. It's effectively doing the same, but now it's much faster. Some profiling showed great speed improvement (something like 40 to 50 times faster) compared to the first iteration. So the overall performance should now be 300 times faster than the original for loop deletion.",4
Fix recording console for new rich-click 1.5 (#24611),1
[TE] Minor bugfix in message_passing.cc (#5254),4
Fix clear future recursive when ExternalTaskMarker is used (#9515),1
Fixing task status for non-running and non-committed tasks  (#22410),1
Testing the pickling,3
More doc fixes,0
[AIRFLOW-7084] Lazy initialize plugins for each entrypoint (#7758),1
"support adb-shell style cpp_rpc (#8223)* support adb-shell style cpp_rpc* fix review problems,  #8223* add comment & use /data/local/tmp dir in shell terminal case* fix spelling errors* fix spelling errorsCo-authored-by: rqg <ranqingguo90@qq.com>Co-authored-by: rqg <ranqingguo318@gmail.com>",0
Add ElasticSearch Connection Doc (#16436),2
[AIRFLOW-2566] Change backfill to rerun failed tasksCloses #3464 from feng-tao/airflow-2566,0
Docs: Fix url for ``Elasticsearch`` (#16275)`https://https//www.elastic.co/elasticsearch` -> `https://www.elastic.co/elasticsearch`,0
[microTVM] Autotuning performance tests (#11782)* Common autotuning test* Autotuned model evaluation utilities* Bugfixes and more enablement* Working autotune profiling test* Refactoring based on PR commentsBugfixes to get tests passingRefactor to remove tflite model for consistencyBlack formattingLinting and bugfixesAdd Apache license headerUse larger chunk size to read filesExplicitly specify LRU cache size for compatibility with Python 3.7Pass platform to microTVM common testsBetter comment for runtime boundStop directory from being removed after session creation* Use the actual Zephyr timing libraryUse unsigned integerAdditional loggingTry negationTry 64 bit timerUse Zephyr's timing libraryFix lintingEnable timing utilities,0
"[AIRFLOW-2815] Use correct copyright period""onwards"" is not specific enough",1
"[AIRFLOW-727] try_number is not increasedA dag that has retries enabled will retry indefinitelyas try_number gets reset to 0 in LocalTaskJob astask_instance is not fully populated, but neverthelesssaved to the databases.This was caused by a commit inhttps://github.com/apache/incubator-airflow/pull/1939",1
[AIRFLOW-XXX] add DigitalOcean to official Airflow users list (#4099),1
"[RPC] Fix cpp_rpc connection to rpc_tracker (#8388)* [RPC] Fix cpp_rpc connection to rpc_trackerFixed connection cpp_rpc application to rpc_tracker which was broken bythis commit: 0bbaf0e.Also, made it possible to create a linux shared library on MacOS.Without this change default tuning didn't work on MacOS.* Add explicitly check on dylib",1
Improve Windows development compatibility for breeze (#24098),1
Bring back numbered lists to TVM docs. (#7290)* Upstream fix in https://github.com/tlc-pack/tlcpack-sphinx-addon/commit/995178d81e6e38eabbc28da2b285b68583c88769,1
Add PaddlePaddle dependency in docker file (#8742),2
"Save PyTorch frontend state in object (#7023)While the functional approach is pretty neat, we ended up havingglobal state (default frontend, dtype) and it'll be more soon(caching of inferred types, see #6900). To not have to pass aroundthe state, this moves the op conversion into a class with instanceshaving the state.",4
[ETHOSN] Add support for special indices of Reshape (#12556)This pr adds support for the special indices values of the reshape operator for the Arm(R) Ethos(TM)-N NPU.,1
Add documentation links to README,2
[DOCS] Add docs of logical snd right shift (#1834),2
"[AIRFLOW-483] Change print to logging statementDear Airflow Maintainers,Please accept this PR that addresses the followingissues:https://issues.apache.org/jira/browse/AIRFLOW-483Testing Done:This fix prevented the stdout from being spammedby the file content.Closes #1780 fromskogsbaeck/fix/gcs_download_operator",0
[microTVM] Zephyr: add B-U585I-IOT02A board support (#10416),1
[FQ2I] Add log op to FQ2I (#10924)* unary op for resize2d and test* renamed test* added log in quantized form* black'd some files* changed suggested commentary,4
Add werkzeug limitation until flask-login will handle it (#25270)* Add werkzeug limitation until flask-login will handle it* comments for afterwards,0
Change stdout and stderr access mode to append in commands (#25253)Co-authored-by: Iuhos Zolt√°n <iuhosz@ukatemi.com>Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>,4
"[TOPI, Relay] ROI Pool operator (#2811)",1
[AIRFLOW-XXX] Add TokenAnalyst to Airflow Users (#6605),1
[AIRFLOW-XXXX] Prohibit non-finished PR (#7543),5
Merge pull request #230 from mistercrunch/artwr/spelling_policefixin spellin,0
Allow datatypes besides fp32 in conv2d_transpose for cuda. (#6593),5
"[AIRFLOW-3905] Allow using ""parameters"" in SqlSensor (#4723)* [AIRFLOW-3905] Allow 'parameters' in SqlSensor* Add check on conn_type & add testNot all SQL-related connections are supported by SqlSensor,due to limitation in Connection model and hook implementation.",1
[AIRFLOW-1125] Document encrypted connectionsClarify documentation regarding fernet_key and howtoenable encryption if it was not enabled duringinstall.Closes #2251 from boristyukin/airflow-1125,0
Prevent clickable bad links on disabled pagination (#15074),2
"[LLVM] More optimized option, allow emit assembly (#187)",1
[RUST] Add conv3d transpose Rust bindings (#11471)* Add conv3d transpose Rust bindings* Fix typename* Add base,1
Improving the Chart list view,2
Update fuse_ops.cc (#2102),1
Fix ISSUE-812 to not allow the scheduler to start if the backend is sqlite and the executor is not SequentialExecutor,1
"[REFACTOR][TE][TIR] Call::Halide => ProducerLoad, DSL/TIR decouple. (#5743)In the HalideIR's design, DSL components and IR are mixed together.For example, Call::Halide can containa reference to a function which isconstructed in the tensor expression language.While this coupled design simplifies certain aspect of the DSL construction,it prevents the TIR to evolve as a clean standalone IR:- The additional tensor expression provided in the function is opaque to the IR  and may become obsolete as we transform them.- The duplication of the information in the DSL tensor and IR makes it hard to  design a stand-alone text format (when there are elements shared in the tensor  expression and normal statements).This PR aims to clearly de-couple the TIR from high-level DSL structures(tensor expression),while still provide clear extensions to build DSLs on top of the TIR.We introduce a DataProducer as a base class for high level tensor expressions objectsthat produce data. We then introduce ProducerLoad to replace the Call::Halide usage,so that the Call node can always be self contained and used for low-level calls.The high-level tensor expression DSL can still generate a PrimExpr that contains a ProducerLoad.These PrimExprs contains fragments of information that can be combined together togenerate a low-level TIR PrimFunc.We also state clearly that DataProducer **should not** appear in any TIR PrimFunc.Instead, the high-level DSL layer should lowered DataProducers to Buffers and TIR statementsthat produces these buffers. We can further provide verifications to validate such invariance.Changes:- Introduce DataProducer to serve as a base class for Tensor in tensor expressions.- Migrate use of Call::Halide to ProducerLoad- Migrate the other usages of Calls.We will also create follow-up PRs to migrate the remaining two DSL related IR nodes(Realize/Provide)to use the DataProducer.",5
Fix db downgrades (#19994)Downgrading from 2.2.0 wasn't working on Postgres or MySQL.,1
[AIRFLOW-298] fix incubator diclaimer in docsCloses #1640 from mistercrunch/disclaimer_tweaks[AIRFLOW-298] fix incubator diclaimer in docs,2
"[Fix] Fix some errors in unittests (#12170)* unittests fix 0* fix unittests* fix unittests* fix unittest* fix unittest* fix unittest* Revert ""fix unittest""This reverts commit 09b6b410bc51e91ca256e888d380e5648739d257.* fix unittests* fix",0
[Torch] Support bincount and scatter_add ops (#6740),1
Add `parameters` to templated fields in `OracleOperator` (#22857),1
"Additional properties should be allowed in provider schema (#13440)The additional properties should be allowed in provider schema,otherwise future version of providers will not be compatible witholder versions of Airflow.Specifying 'additionalProperties' as allowed we are opening up toadding more properties to provider.yaml.This change fixes this is for now by removing extra fieldsadded since the Airlow 2.0.0 schema and verifying that the 2.0.0schema correctly validates such modified dictionary.In the future we might deprecate 2.0.0 and add >=2.0.1 limitationto the provider packages in which case we will be able to removethis modification of the provider_info dict.Also added additional test for provider packages whether theyinstall on Airflow 2.0.0. This tests might remain even after thedeprecation of 2.0.0 - we can just move it to 2.0.1. However thiswill give us much bigger confidence that the providers willcontinue work even for older versions of Airflow 2.0.We might have to modify that test and only include the providersthat are backwards-compatible, in case we have some providersthat depend on future Airflow versions. For now we assumeall providers should be installable from master on 2.0.0.",1
Update Databricks API from 2.0 to 2.1 (#19412),5
[AIRFLOW-31][AIRFLOW-200] Add note to updating.mdAIRFLOW-31 and AIRFLOW-200 deprecated the old important mechanism and should be noted in UPDATING.mdCloses #1643 from jlowin/patch-1,5
"[AIRFLOW-1163][AIRFLOW-XXX] Add support for x-forwarded-* headersWhen running Airflow behind a L7 proxy that sendsx-fowarded-* headers, the Flask app miscontructsredirect URIs.Closes #3580 from c4milo/master",1
Make numpy effectively an optional dependency for Oracle provider (#24272)Better fix to #23132,0
[TOPI][Hexagon] Implement quantized elementwise for hexagon (#12606)* [TOPI][Hexagon] Add test and schedule for uint8 resize2d* Fix correctness issue* Reformat* [TOPI][Hexagon] Implement quantized elementwise* Reformat* Address review comments* Reformat* Revert* Address review comments,1
Add Betterment to companies list (#4088),1
[AIRFLOW-6972] Shorter frequently used commands in Breeze (#7608),1
[AIRFLOW-6206] Move and rename AWS batch operator [AIP-21] (#6764)- conform to AIP-21  - see https://issues.apache.org/jira/browse/AIRFLOW-4733  - see https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-21%3A+Changes+in+import+paths  - use airflow.providers.amazon.aws.operators.batch.AwsBatchOperator  - deprecate airflow.contrib.operators.awsbatch_operator.AWSBatchOperator- fix pylint for airflow/providers/amazon/aws/operators/batch.py,1
Update Airflow Release Doc (#23322)Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>,1
"[AIRFLOW-1384] Add to README.md CaDC/ARGOadded to  currently **officially** using Airflow:[California Data Collaborative](http://californiadatacollaborative.org) powered by [ARGOLabs](http://www.argolabs.org)Dear Airflow maintainers,Please accept this PR. I understand that it willnot be reviewed until I have checked off all thesteps below!- [x] My PR addresses the following [Airflow JIRA]**https://issues.apache.org/jira/browse/AIRFLOW-1384**- The California Data Collaborative is a uniquecoalition of forward thinking municipal watermanagers in California who along with ARGO, astartup non-profit that builds, operates, andmaintains data infrastructures, are pioneering newstandards of collaborating around andadministering water data for millionsCalifornians.ARGO has deployed a hosted version of Airflow onAWS and it is used to orchestrate data pipelinesto parse water use data from participatingutilities to power analytics. Furthermore, ARGOalso uses Airflow to power a data infrastructurefor citywide street maintenance viahttps://github.com/ARGO-SQUID- [x] My PR adds the following unit tests __OR__does not need testing for this extremely goodreason:Change to README.md does not require unit testing.- [x] My commits all reference JIRA issues intheir subject lines, and I have squashed multiplecommits if they address the same issue. Inaddition, my commits follow the guidelines from""[How to write a good git commitmessage](http://chris.beams.io/posts/git-commit/)"":    1. Subject is separated from body by a blank line    2. Subject is limited to 50 characters    3. Subject does not end with a period    4. Subject uses the imperative mood (""add"", not""adding"")    5. Body wraps at 72 characters    6. Body explains ""what"" and ""why"", not ""how""Update README.mdadded to  currently **officially** using Airflowsection of README.md[California Data Collaborative](https://github.com/California-Data-Collaborative) powered by [ARGOLabs](http://www.argolabs.org)Added CaDC/ARGO Labs to README.mdPlease consider adding [ArgoLabs](www.argolabs.org) to the Airflow userssection.**Context**- The California Data Collaborative is a uniquecoalition of forward thinking municipal watermanagers in California who along with ARGO, astartup non-profit that builds, operates, andmaintains data infrastructures, are pioneering newstandards of collaborating around andadministering water data for millionsCalifornians.- ARGO has deployed a hosted version of Airflow onAWS and it is used to orchestrate data pipelinesto parse water use data from participatingutilities to power analytics. Furthermore, ARGOalso uses Airflow to power a data infrastructurefor citywide street maintenance viahttps://github.com/ARGO-SQUIDCloses #2421 from vr00n/patch-3",5
add note to airflow.cfg,5
add another default location to verilator (#3324),1
The --force-pull-images is restored in breeze (#15063)It's been accidentally removed during rebase.,4
Prepare documentation for July release of providers. (#17015),1
Add system tests for CloudSecretManagerBackend (#10235)* Add system tests for CloudSecretManagerBackend* fixup! Add system tests for CloudSecretManagerBackend,3
Fix failing tests from #8997 (#9576),3
Insures that we keep the same client connection through the sensor's lifecycle,2
support multipart uploads,1
"[PASS] Memory barrier detection, storage access lower. (#317)",4
"Add reattach flag to ECSOperator (#10643)..so that whenever the Airflow server restarts, it does not leave rogue ECS Tasks. Instead the operator will seek for any running instance and attach to it.",1
Separate infer_data_interval for data interval timetables (#17755)CronDataIntervalTimetable and DeltaDataIntervalTimetable needdifferent infer_data_interval implementations because the 'align'method aligns the time *forward*. CronDataIntervalTimetable needs tocall get_prev one more time than DeltaDataIntervalTimetable to get thecorrect interval.,1
Fix Helm Chart Testing guide (#11909),3
Upgrade to latest `pip` version 22.2.1 released today (#25348),3
Addressing issues around try_number being off,1
Merge pull request #180 from mistercrunch/fix_autocommitSetting autocommit default,0
"Seperate provider verification as standalone breeze command (#23454)This is another step in simplifying and converting to Python all ofthe CI/local development tooling.This PR separates out verification of providers as a separatebreeze command `verify-provider-packages`. It was previously part of""prepare_provider_packages.py"" but it has been nowextracted to a separate in-container python file and it waswrapped with breeze's `verify-provider-packages` command.No longer provider verification is run with ""preparing provider docs""nor ""preparing provider packages"" - it's a standaline command.This command is also used in CI now to run the tests:* all provider packages are built and created on CI together with¬† airflow version* the packages are installed inside the CI image and providers are  verified* the 2.1 version of Airflow is installed together with all 2.1  - compatible providers and provider verification is run there too.This all is much simpler now - we got rediof some 500 lines of bashcode again in favour of breeze python code.Fixes: #23430",0
Add USC Graduate School to INTHEWILD.md (#10843),1
[AIRFLOW-3350] Explain how to use Bitshift Composition with lists (#4191),1
Show hostname when clicking the clock,5
[Autotvm] Support override (#3292),1
"Fix prod image build (#12314)Running `setup.py` was failing with a KeyError: yandex, meaning #12265didn't quite fix it.It is unclear to at this point why CI passed on that PR.",4
Remove legacy hack for TaskInstance without DagRun (#20108),2
"[TIR] Fix printing enum in TransformLayout::AsPython (#11211)After this PR, `as_python` can handle `transform_layout` correctly. The result will be like```pythonsch.transform_layout(..., buffer_index_type=""read"", ...)```Previously `buffer_index_type` was printed unquoted.",0
[AIRFLOW-2377] Improve Sendgrid sender supportCloses #3266 from ms32035/sendgrid_sender,1
"Improve www.security.get_accessible_dags() and webserver performance (#12458)* Improve www.security.get_accessible_dags() and webserver performance- the performance of get_accessible_dags() is improved by returning as early as possible- the changes made in www.views.py are based on the fact that the check  on permissions.RESOURCE_DAG is already done in get_accessible_dags(),  which is invoked by get_accessible_dag_ids() then.* Fix-up. Incorporate the changes suggested by jhtimmins with minor changeCo-Authored-By: jhtimmins <jameshtimmins@gmail.com>",4
Add breeze parameter test-timeout to override pytest timeouts (#25766)* Add breeze parameter test-timeout to override pytest timeouts,3
[RELAY] Fix ops in packed layout (#2472)* [RELAY] Fix ops in packed layout* Fix style,0
fix doc (#510),2
"Remove unused Scheduler ""authenticate"" config (#8310)",5
[AIRFLOW-XXXX] Add versions_added field to configs (#7354),5
Fixes,0
Add Trade Republic to list of Airflow users (#13111)I changed the company. I am now working for Trade Republic.,1
Handle empty tuple (#95),0
"Do not silently allow the use of undefined variables in jinja2 templates (#11016)This can have *extremely* bad consequences. After this change, a jinja2template like the one below will cause the task instance to fail, if theDAG being executed is not a sub-DAG. This may also display an error onthe Rendered tab of the Task Instance page.task_instance.xcom_pull('z', key='return_value', dag_id=dag.parent_dag.dag_id)Prior to the change in this commit, the above template would pull thelatest value for task_id 'z', for the given execution_date, from *any DAG*.If your task_ids between DAGs are all unique, or if DAGs using the sametask_id always have different execution_date values, this will appear toact like dag_id=None.Our current theory is SQLAlchemy/Python doesn't behave as expected whencomparing `jinja2.Undefined` to `None`.",2
Unify error messages and complete type field in response (#10333)Co-authored-by: Kamil Bregu≈Ça <mik-laj@users.noreply.github.com>,1
Fix import in unit test example (#21703),3
Omit contrib from coverage report,3
"Add two methods to BigQueryBaseCursor:get_method, which allows access to the schema of a given BigQuery table.get_tabledata, which allows access to all the data in a given table.",5
Merge pull request #284 from mistercrunch/flower_portTying the flower_port configuration param to the CLI,2
"[DOCKER] Revert git shallow clone change. (#2841)This patch reverts one of my earlier patches (squashed in #2710) toreduce bandwidth requirements of git clone, in this particular case weare checking out a specific hash rather than a tag or branch name. The--branch option to git clone permits tags or branches but does notpermit a specific hash.",1
Fix closing connection dbapi.get_pandas_df (#23452),5
add UT for round_time()(in order to make coverage checks ok ^__^),3
Honor schema type for MySQL to GCS data pre-process (#8090),5
[FIX] Fix Typo (#164),2
[RELAY] Add broadcast_to operator (#2276),1
"Fixed crashing webserver after /tmp is mounted from the host (#9378)The bug was introduced in f17a02d33047ebbfd9f92d3d1d54d6d810f596c1Gunicorn uses a lot of os.fchmod in /tmp directory and it can create someexcessive blocking in os.fchmodhttps://docs.gunicorn.org/en/stable/faq.html#how-do-i-avoid-gunicorn-excessively-blocking-in-os-fchmodWe want to switch to use /dev/shm in prod image (shared memory) to makeblocking go away and make independent on the docker filesystem used (osxfs hasproblems with os.fchmod and use permissions as well).Use case / motivationAvoiding contention might be useful = in production image.This can be done with:GUNICORN_CMD_ARGS=""--worker-tmp-dir /dev/shm""",1
"[Frontend,TOPI] Improve dynamism for BatchMatmul and Dense (#7496)* [TOPI] Dense cuda schedule support dynamic dimension* [TOPI] batch_matmul cublas te computation support dynamism* [Frontend] tensorflow frontend: dynamic support for BatchMatmul* [TOPI] nn batch_matmul te computation support dynamism* fix CI* Update python/tvm/topi/nn/batch_matmul.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Update python/tvm/topi/cuda/batch_matmul.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* remove concat_dynamic_shape function* update topi dense op integer checking* fix ci* Update python/tvm/relay/frontend/tensorflow.pyCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Update batch_matmul.py* [Frontend] add test for batch_matmul in dynamic shaped caseCo-authored-by: Cody Yu <comaniac0422@gmail.com>",3
Merge branch 'impyla' into minicluster,5
Change the default celery worker_concurrency to 16 (#13612)This change was unintentional -- https://github.com/apache/airflow/pull/7205That PR just changed it to work with breeze. Since we had `16` as default in 1.10.xand to get better performance and keep in line with `dag_concurrency` and`max_active_runs_per_dag` -- I think `16` makes more sense.,1
implement SSHExecuteOperator,1
[Refactor][Relay] Refactor Relay Python to use new FFI (#5077)* refactor relay python* revert relay/ir/*.py to relay* Address comments* remove direct access to analysis and transform namespace,4
Allow install-dev to include all necessary header files (#338),2
[Relay] [Op] zeros_like and ones_like (#1835),5
[Refactor] Remove scope attribute from Buffer class (#8463)Co-authored-by: masa <masa@pop-os.localdomain>,4
"[AIRFLOW-2203] Cache signature in apply_defaultsCache inspect.signature for the wrapper closure to avoid calling it atevery decorated invocation. This is separate sig_cache created perdecoration, i.e. each function decorated using apply_defaults will havea different sig_cache.",1
Fixes a problem with checked-out version of the selective check (#11891)The non-master version of selective check script hasbeen checked out by mistake in the build-info step.,5
[FRONTEND][TEST] Remove duplicated frontend tests (#2414)* Remove duplicated frontend tests* Add test for nnvm to relay* Add test to script* Remove dcgan in nnvm_to_relay test due to unsupported op in cuda* Fix bug in converting conv2d from nnvm to relay* Fix dropout,4
f◊ü◊° Broken link in api.rst (#21165)Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>,1
azure key vault optional lookup (#12174),5
Merge pull request #882 from asnir/docker_operatorDocker operator,1
fix docs of threefry_split and threefry_generate (#8035),2
"Add `make docs` and doc building instructions (#9534)* Update doc building instructions and pin dependenciesThis pins the dependencies for the docs and adds `pytest` as adependency which was missing when I built. Tested out therequirements.txt with a fresh `ubuntu:focal` Docker image to verify thatthe required depedencies work.* Address comments, add Makefile for docs and add to instructions* Use Python for running scripts* Fix lint, add lint command* Add option for cpu to only run the precheck, address comments* Fix 'make doc' usage, add some -x's* Fix bad condition on --cpu, add defaults for envs* Fix another 'make doc'* Fix for running on MacOSCo-authored-by: driazati <driazati@users.noreply.github.com>",1
Add `S3CreateObjectOperator` (#22758)* Add S3CreateObjectOperatorCo-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>,1
[Relay] fix incorrect binding of Lets in ANF conversion (#10078)* fix incorrect binding of lets in ANF conversion* add test case* remove really weird auto-import from debugging* address comments,1
Unify approach for user questions asked in Breeze (#23335)This change documents and unifies the approach we've taken forthe user inut handling when it comes to confirmation questions.,5
[AIRFLOW-5586] Improve CLI error messaging (#6246),0
Renamed Connection.get_hook parameter to make it the same as in SqlSensor and SqlOperator. (#19849),1
[Relay/TOPI][OP] Add clip and wrap mode support in take (#2858)* Update take* Add special case for canonical simplify and fix test cases* Use lower case for wrap and clip* remove unnecssary lower* Fix mxnet converter for take* fix,0
[ci][tvmbot] Enable re-run for GitHub Actions (#12295)This adds the right permissions so anyone associated with the repo can trigger a re-run (GitHub hasn't flagged all committers as repo `COLLABORATORS` for some reason so it's difficult to determine from a username who has commit rights) and makes it so `@tvm-bot rerun` also re-runs all the Actions on a PR.,1
"[Relay][Frontend][TFLite] frontend operator support: batch_to_space_nd, space_to_batch_nd (#3850)* Fix unittest* Fix pylint error: Line 915 too long* Fix the conflicting files* frontend operator support: space_to_batch_nd* add test case for frontend operator support: space_to_batch_nd* add test case for frontend operator support: space_to_batch_nd* frontend operator support: space_to_batch_nd* Fix ValueError: don't know how to convert type <class 'numpy.ndarray'> to node",0
Add cli command for 'airflow dags reserialize` (#19471),2
Group UPDATING.md  entries into sections (#10090),5
[FEATURE] update K8S-KIND to 0.13.0 (#23636),5
[Python dep] Add missing dep pkg for relay (#2568),1
Order broken DAG messages in UI (#12749),2
Add parser support for SUM tflite operator (#4182),1
Remove DAG refresh buttons (#17263)Now that the DAG parser syncs DAG specific permissions there reallyisn't a need to manually refresh DAGs via the UI.,2
[AIRFLOW-1769] Add support for templates in VirtualenvOperatorCloses #2741 from saguziel/aguziel-virtualenv-templates,1
[AIRFLOW-5800] Add a default connection entry for PinotDbApiHook (#6457),5
[Frontend][TFLite] Fix fully_connected converter when batch size is not 1 (#6038)* Fix fully_connected when batched* Remove unused variable,1
feat(KubernetesPodOperator): Add support of container_security_context (#25530),1
"Document Airflow's versioning and release policy for users (#14132)This document aims to show users what they can expect and rely upon fromAirflow versions.It is far from complete and we will build it up over time, but creatingthe document from scratch is the hard part!",2
[SCHEDULE] Fuse support for 0 rank tensor (#1328),1
"Workaround occasional deadlocks with MSSQL (#19856)We already have a mechanism to retry operations that could resultin temporary deadlocks - this have been helpful with handling MySQLdeadlocks - however similar problems occur occasionally in MSSQL andthere we get a DBAPIError rather than OperationalError:`sqlalchemy.exc.DBAPIError: (pyodbc.Error) ('40001', '[40001][Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Transaction(Process ID 55) was deadlocked on lock resources with another processand has been chosen as the deadlock victim. Rerun the transaction.(1205) (SQLExecDirectW)');This PR adds DBAPIError to the list of errors that are handledby `run_with_db_retries` to mitigate such occasional deadlocks.",5
Expose relay BindParamsByName to Python (#4751)* expose BindParamByName to python* fixed alpha equal test,3
Update link (#6838),2
[AIRFLOW-1489] Fix typo in BigQueryCheckOperatorCloses #2501 from mrkm4ntr/airflow-1489,1
Merge pull request #129 from airbnb/headersAdding headers to CRUD views,1
Add SnowSQL installation script to Breeze (#23065),1
[CODEGEN] Use correct math intrin for metal (#562),1
Prevents failure on fixing permissions for files with space in it (#9076),2
Fix spellings (#13867),0
Simplify strings previously split across lines (#18679),5
Fix forgetting to expose yesterday_ds_nodash and tomorrow_ds_nodash,1
Consistently refer to section names (#10369),5
Merge pull request #1387 from jgao54/cli-variable-supportSupport list/get/set variables in the CLI,1
[RPC] Fix ios_rpc build (#8864),0
[AIRFLOW-4024] Improve local client tests (#4850)* Improve local client tests* remove self.session* Fixing import,2
init (#7943),5
Fix the error caused by passing unused context in JiraSensor.poke (#23352)* Fix the error caused by passing unused context in JiraSensor.pokeThe sample ticket object used in the test is mocked more realistically and the original field_checker_func is used.,1
reshape with non constant shape argument (#6411),5
[tvm4j] Java runtime README (#391),1
"[TOPI] Use cblas for dense and batch_matmul when ""cblas"" is in the target libraries (#3787)* Support cblas library in dense* start to add support for generic batch_matmul compute* Add x86 override for batch_matmul* Fix linting* reset file* Fix typos* dummy change to re-trigger CI",4
[Hexagon] Add doc on TVM - Hexagon RPC flow (#10507)* [Hexagon] Add doc on TVM - Hexagon RPC flow* updated for the latest code* add TODO on removing rpc_local_session.cc,4
Delete _ir_pass.pyi,4
Add project_id to client inside BigQuery hook update_table method (#13018),5
[AIRFLOW-1912] airflow.processor should not propagate loggingThe root logger will write to stdout. Ifredirection is usedwhich is the case for processors and task runs(not runners)this can end up in an endless loop in casepropagation is True.Closes #2871 from bolkedebruin/AIRFLOW-1912,1
[AIRFLOW-5691] Rewrite Dataproc operators to use python library (#6371),1
Added haodf to INTHEWILD.md (#21510)Added haodf to the list of companies using Apache Airflow,1
Merge pull request #1332 from jbrownlucid/patch-3Add Lucid to list of users,1
Add contribute page about CI (#9906)* Add contribute page about CIThis adds some docs with a description of the TVM CI and some usage instructions to both make contributing more friendly and educate existing developers about how CI runs. Bikeshedding on content is welcomeNote: The TODOs are blocked on some other PRs and will be done before landing* docker instructions* Comments* RebaseCo-authored-by: driazati <driazati@users.noreply.github.com>,1
[AIRFLOW-3557] Fix various typos (#4357),2
Add FlattenAtrousConv transformation (#10996),1
Fix structure and typo in Updating.md (#14005),5
[FRONTEND][TFLite] Fully connected op conversion made in sync with TFLite (#5510)* [FRONTEND][TFLite] Fully connected op conversion made in sync with TFLite* [1] Test case added* [2] Review comments handled* [3] Prints removed,4
[ETHOSN] Match config for is-supported with compilation target (#9160)The Ethos-N variant configuration for the is-supported functionality is nowthe same as the variant configuration for the actual compilation,5
"[RPC] Improve RPCServer AsyncIO support. (#5544)* [RPC] Improve RPCServer AsyncIO support.When the RPCServer is in the async IO mode, it is possible for the serverto directly serve async function that may return its value via a callback in the future.This mode is particular useful to the web environment, where blocking is not an option.This PR introduces the Async support to the RPCSession, allowing the AsyncIO driven serversto serve the async functions. These functions will still be presented as synchronized versionon the client side.Followup PR will refactor the web runtime to make use of this feature.* Address comments",1
Updating Apache example DAGs to use XComArgs (#16869),1
Add tests for dry run,1
Fix Bug in Bilinear Interpolation and Add Deform Conv to PT FrontEnd (#7397)* Fix Bug in Bilinear Interpolation* Add NHWC Tests* clean* Fix Bug and Add Deformable Conv PyTorch for completeness* Add Tensor Utils* Remove stuff* Include vector* PR Comments* Empty Commit for CICo-authored-by: Ubuntu <ubuntu@ip-172-31-42-251.us-east-2.compute.internal>,4
Tons of tests improvments,3
[AIRFLOW-461] Restore parameter position for BQ run_load method (#4077),1
Disable OpenGL test temporary (#801),3
Fixing the fix,0
Action to redirect where you come from,5
"[PASS] Improve SSA conversion, add forbid list in loop-par (#142)",1
[AutoScheduler] Accelerate feature extraction for winograd (#6981)* [AutoScheduler] Accelerate feature extraction for winograd* fix an overflow in feature.cc* address comments* address comments* Update include/tvm/te/schedule.hCo-authored-by: Cody Yu <comaniac0422@gmail.com>* Use a smaller min_repeat_ms* Use a smaller min_repeat_msCo-authored-by: Cody Yu <comaniac0422@gmail.com>,1
Adding --local option to backfill,1
Change AOT from ExprVisitor to MixedModeVisitor (#8856)This should allow better scale-ability for AOT when targeting larger networks.,1
[AIRFLOW-6373] Make airflow/utils pylint compatible (#6929)This PR removes airflow/utils/* files from pylint todo listand implements required changes.,4
"[AIRFLOW-1398] Allow ExternalTaskSensor to wait on multiple runs of a taskCurrently using the execution_date_fn parameter ofthe ExternalTaskSensorsensors only allows to wait for the completion ofone given run of thetask the ExternalTaskSensor is sensing.However, this prevents users to have setups wheredags don't have the sameschedule frequency but still depend on oneanother. For example, let's sayyou have a dag scheduled hourly that transformslog data and is owned bythe team in charge of logging. In the currentsetup you cannot have otherhigher level teams, that want to use thistransformed data, createdags processing transformed log data in dailybatches, while making surethe logged transformed data was properly created.Note that simply waiting for the data to bepresent (using e.g. theHivePartitionSensor if the data is in hive) mightnot be satisfactorybecause the data being present doesn't mean it isready to be used.This commit makes it possible to do exactly thatby being able to havean ExternalTaskSensor wait for multiple runs ofthe task it is sensing tohave finished. Now higher level teams can setupdags with anExternalTaskSensor sensing the end task of the dagthat transforms thelog data and waiting for the successful completionof 24 of its hourly runs.Closes #2431 from rlk-ama/pr/multiple-dates-external-task-sensor",5
"[CI] Fix windows build, add azure pipeline (#3458)",1
docs(impersonation): update note so avoid misintrepretation (#17701),5
"[AIRFLOW-1314] Improve k8s supportAdd kubernetes config section in airflow.cfg and Inject GCP secrets upon executor start. (#17)Update Airflow to Pass configuration to k8s containers, add some Py3 ‚Ä¶ (#9)* Update Airflow to Pass configuration to k8s containers, add some Py3 compat., create git-sync pod* Undo changes to display-source config setter for to_dict* WIP Secrets and Configmaps* Improve secrets support for multiple secrets. Add support for registry secrets. Add support for RBAC service accounts.* Swap order of variables, overlooked very basic issue* Secret env var names must be upper* Update logging* Revert spothero test code in setup.py* WIP Fix tests* Worker should be using local executor* Consolidate worker setup and address code review comments* reconfigure airflow script to use new secrets method",1
[TensorIR] [Script] adding support for opaque block (#7829)* change complete tag* add parsing support for opaque block* address and add testcase* address* address,1
[AIRFLOW-4402] Update super() calls to PY3 for nvd3 (#5168),5
Standardize AwsLambda (#25100)* Standardize AwsLambdaThe `aws_lambda.py` is not the standard file path. The `aws_` prefix is not needed.For the file name I used the same path as the hook.* fix deprecated_classes.py* update verify_providers.py,1
[Runtime] MISRA-C compliant TVM runtime (#3934)* implement of MISRA-C compliant TVM runtime;* working on bundle_deploy_c demo* move header files into include dir* fix compatibility issues* fix compatibility issues* resolve most of the warnings and errros* implement c_backend_api* introduce bridge* working well* move to header files and bundle.c into src/runtime/crt* clean up* satisfy linter* clean up* test with the cat image* remove synset* refactoring* refactoring* refactoring* initial crt_runtime_api.c* improved compatibility with g++* using exposed API in c_runtime_api.h* call from c_runtime_api.h* clean up* lint* merge into apps/bundle_deploy directoryChange-Id: I51904db81b8589e65d107d8ca77b47452e3812b5* make the demo runs in ciChange-Id: I2c24f8b592508833d3555311c2b24d1931f19385* address review commentsChange-Id: I027ddff15c31fb4da0bd0e461427dce619de1f93* releaseChange-Id: I5ad5bb8426468aac9fc8d074e56ddea358a7fd91* fix ci testingChange-Id: Ic2e82fb3051b6c254ef32a964f976b61e3e5fe4d* add test case for misra c runtimeChange-Id: Ie0dfd0ade6be4665b4384db7d260a6c69b35010f* fread files in testing to avoid calling xxdChange-Id: Ie7fbc16b4b0b9509918d986a841f443900813bef,4
[AIRFLOW-5480] Fix flaky impersonation (#6098),0
[RUNTIME] RPC runtime that support run testing on remote device. (#147)* [RUNTIME] RPC runtime that support run testing on remote device.* Fix ctypes in OSX.* fix lint,0
[FIX] Add CombineInternal<Mod> & Fix LoopPartition (#138)* Add CombineInternal<Mod> & Fix LoopPartition* Add check for path,1
[Ansor][AutoTVM v2.0] Phase 1: Add pragma/storage_align/rfactor steps (#6141)* Add pragma/storage_align/rfactor step* Update* Update* Update UT* Update,5
[BYOC] [ACL] ACL Runtime padding workaround (#6724)This workaround prevents execution of operations via ACL runtimein case if arguments or output tensor require memory padding.Workaround is applicable to all ACL versions prior forecoming ACL 20.11(which will not use data padding).,1
"Allow pathlib.Path in DagBag and various util fns (#15110)We do a lot of path manipulation in this test file, and it's easier tounderstand by using pathlib without all the nested `os.path.*` calls.This change adds ""support"" for passing Path objects to DagBag andutil functions.",1
[AIRFLOW-2980] ReadTheDocs - Fix Missing API Reference,0
support custom IP address from rpc server to tracker (PUT) (#1243),1
[AIRFLOW-4529] Add support for Azure Batch Service (#8024),1
[AIRFLOW-2550] Implements API endpoint to list DAG runsCloses #3499 from verdan/AIRFLOW-2550-list-dagruns,2
"Add permission ""extra_links"" for Viewer role and above (#10719)This change adds 'can extra links on Airflow' to the Viewer role and above. Currently, only Admins can see extra links by default.",2
Make sure build-prod-image works in the new Breeze2 (#22660)Some defaults were missing for manual build of PROD images.,1
Fixed collision on self.queue,0
Adding utility macros around ts,1
Fix bug check trt (#10600)Co-authored-by: Michalis Papapdimitriou <mpapapdimitriou@octoml.ai>,5
Migrate simplifier to new infra. (#3368),5
[BYOC][ACL] ACL migrated to v21.02 (#7649)This PR switches ACL* version from v20.11 to v21.02ACL stands for Compute Library for the Arm¬Æ Architecture.Change-Id: Id364b571d5611ca6eb6d2bde09448a65aae3f73b,4
[ONNX] Add ReduceSum opset13 support (non-dynamic) (#11606)* [ONNX] Add ReduceSum opset13 support (non-dynamic)* Add check* Add support for constant axis* noop* Rework logic,2
[NNVM][TENSORFLOW] Sigmoid op support #1367 (#1369),1
[Relay][Op] fix conv transpose weight dtype inference (#8962)Fixes type inference error when data and weight have different dtype,5
Simplify enclave lifecycle management (#1013),5
Validate JSON schema files with JSON Schema (#12682),5
Merge pull request #390 from johnw424/patch-1Fix grammatical error in README.md,2
Fixing HiveCliHook test,3
"[Docker] Refactor/clean-up of docker/bash.sh (#8670)* [Docker] Refactor/clean-up of docker/bash.sh- Added detailed help message, displayed using `-h` or `--help`.- Optional flags handled using `getopt`, can now occur in any order.- `--mount` flag may occur more than once.- Switched from short arguments to docker-run to long arguments  (e.g. `--volume` instead of `-v`).  Short arguments are good  shortcuts for interactive work, but can be more difficult to read in  longer scripts.- Mount the `.tvm_test_data` folder, to avoid re-downloading test data  already available in the host environment.* [Docker] docker/bash.sh CI fixDash-prefixed arguments as part of the command now require prefixing with-- to separate them from arguments intended for docker/bash.sh* [Docker] docker/bash.sh, consistent quoting* [Docker] Added --repo-mount-point for docker/bash.sh* [Docker] Updated command-line parsing of docker/bash.sh- Maintained previous behavior, any unrecognized flags after the  docker/bash.sh are part of the command, no -- is  needed. (e.g. docker/bash.sh ci_gpu make -j2)- Reverted changes to Jenskinsfile to add a --, no longer needed.* [Docker] Fixed multi-argument commands* [Docker] docker/bash.sh check permissions before mounting ~/.tvm_test_data* [Docker] Consistent workplace directory in docker/bash.sh for JenkinsSome locations in the CI perform build commands outside of the buildsteps (e.g. tests/scripts/task_ci_setup.sh#L38), and cmake doesn'tlike it if the build directory changes.  These should probably bemoved into the build steps of the CI, and be packed in tvm_multilib inthe Jenkinsfile, but for the meantime maintaining a consistent/workspace directory on all CI nodes allows cmake to run.* [Docker] Updated bash.sh for MacOS compatibilityMacOS has an older version of bash that handles arrays slightlydifferently.  All instances of array expansion `""${ARRAY[@]}""` shouldinstead be written as `${ARRAY[@]+""${ARRAY[@]}""}`.  Otherwise, `set -u`will erroneously complain about an undefined variable. Seehttps://stackoverflow.com/a/61551944 for details.Even though this is an older version of bash (observed in version3.2.57), this is the last major version available under GPLv2 and istherefore the default version on MacOSX.  At some point, the`docker/bash.sh` could be migrated to python for ease ofmaintenance/testing.",3
[VTA] add support to event counters (#3347)* add support to event counters in VTA* fix comment* fix event-counter interface parameter* no longer needed* add sim back* add docs to event counters* fix docs* add more details about event counting* make dpi-module docs more accurate,2
[AIRFLOW-6720] Enforce alphabetical order for CONN_TYPE_TO_HOOK (#7344),1
Don't use alternative linker for static libraries (#10870)Otherwise we may end up with things like this (make VERBOSE=1):/usr/bin/ar qc libtvm_runtime.a  -fuse-ld=lld CMakeFiles/tvm_runtime_ob.../usr/bin/ar: invalid option -- 'e'Usage: /usr/bin/ar [emulation options] [-]{dmpqrstx}[abcDfilMNoPsSTuvV]...       /usr/bin/ar -M [<mri-script]...,2
"[Relay] Restore dominator check (#11616)It is ok to match a sub-graph which has dataflowoutside of the sub-graph, provided all such flowseventually come into the sub-graph.",1
Remove special serde logic for mapped op_kwargs (#23860)Co-authored-by: Daniel Standish <15932138+dstandish@users.noreply.github.com>,1
Fix formatting code block in TESTING.rst (#8985),3
[Fq2i][ fix output type on fq2i binary ops with constant inputs (#12236)* fix output type on fq2i binary ops with constant inputs* allow off by one on test,3
New google operator: SQLToGoogleSheetsOperator (#17887),1
Sort functions (#11814),1
[AIRFLOW-XXX] Ignore python files under node_modules in docs (#5063)Some node modules ship .py files which we don't want in our docs.Without this change if you attempt to build docs locally on a tree whichyou have already compiled the www assets it will fail.,0
[AIRFLOW-XXXX] Remove unused local variable value (#7496),1
Don't reference sphinx airflow theme via `@` URL in requirements. (#12957)PyPI rejects uploading a dist with an `@` in the requirements.,1
"Allow fractional seconds for timeout values (#11966)Python 3.3 added the `sigitimer()` function, which unlike `alarm`,allows fractional seconds to be specified (it still raises a SIGALRMwhen the timeout expires)",1
"Fix cycle bug with attaching label to task group (#24847)The problem was specific to EdgeModifiers as they try to be""transparent"" to upstream/downstreamThe fix is to set track the upstream/downstream for the task groupbefore making any changes to the EdgeModifiers' relations -- otherwisethe roots of the TG were added as dependencies to themeslves!",1
Expose FTVMInferCorrectLayout Python interface (#8755)Co-authored-by: kueitang <kueitang@qti.qualcomm.com>,5
[AIRFLOW-413] Fix unset path bug when backfilling via picklePlease accept this PR that addresses the following issues:- https://issues.apache.org/jira/browse/AIRFLOW-413This fixes a bug when a pickled DAG is used in a backfill.Testing Done:- Existing unit tests + running a backfill command that used to fail  before on this errormistercrunch artwr plypaulCloses #1723 from aoen/ddavydov/fix_undefined_path_for_backfilling,0
[RUNTIME] Improve memory usage for RPC (#1741),1
"Fix type annotations in OracleOperator,  JdbcOperator, SqliteOperator (#17406)",1
add missing inline (#910),1
Fixed changelog for January 2022 (delayed) provider's release (#21439),1
[AIRFLOW-1567] Updated docs for Google ML Engine operators/hooksCloses #2573 from yk5/master,1
add rocm codegen unittest for cross thread reduction (#4423),3
[AIRFLOW-7076] Add support for HashiCorp Vault as Secrets Backend (#7741),1
Add end-to-end SGX ResNet inference example (#388),5
* `CloudDatastoreImportEntitiesOperator` : Remove `xcom_push`. Please use `BaseOperator.do_xcom_push` (#23252)* `CloudDatastoreExportEntitiesOperator` : Remove `xcom_push`. Please use `BaseOperator.do_xcom_push`,1
Add Airflow 2.0.1 to Changelog and Updating.md (#14151)Changelog- https://github.com/apache/airflow/commit/38083fc353befcd012d07e65b29d0c9b9cd0ec7b- https://github.com/apache/airflow/commit/beb8af5ac6c438c29e2c186145115fb1334a3735and update the Updating.md,5
Catching celery's REVOKED state,5
Update CODEOWNERS for the chart docs and k8s provider (#21202),1
"Modernize DAG-related URL routes and rename ""tree"" to ""grid"" (#20730)Co-authored-by: Igor Kholopov <kholopovus@gmail.com>",2
Add parser support for ReLU tflite operator (#4022),1
TimeSensor should respect DAG timezone (#9882),2
[AIRFLOW-262] Simplify commands in MANIFEST.in,5
fix typo (#12183)* fix typo* fix typo,2
Wait option for dagrun operator (#12126)* Add wait_for_completion option to dag run operator.* Add wait_for_completion option to dag run operator.* Change code format to pass sanity check.* Simplify the logic to check dag run state.* Move sleep in the beginning of loop and update pydoc.* Change elif to if on checking allowed_statesCo-authored-by: Kaz Ukigai <kukigai@apple.com>,1
Display better error message when importing providers has errors (#21182)When there are import errors in providers we printed errorsin a folded group which lead to poor discovery of those errors.Also with recent changes to Airflow main for upcoming 2.3 versionsome errors might become more common when developing providers.Specifically the way how to import Context in order to satisfyMyPy and keep Airflow 2.1 compatibility is not obvious.This change introduces helpful guideline to users adding newproviders:* moving errors outside of the folded group with imports* adding comment explaining what the errors are about* adding message about backwards compatibility in case  errors happen during 2.1.0 backwards-compatibility check* adding explanation and suggest a fix in the common Context  impport error,0
[ConvertLayout] slice_like support (#7184),1
[AIRFLOW-1094] Run unit tests under contrib in TravisRename all unit tests under tests/contrib to startwith test_* and fixbroken unit tests so that they run for the Python2 and 3 builds.Closes #2234 from hgrif/AIRFLOW-1094,1
[AutoScheduler] Bug fix for layout rewrite CI error in i386 (#6830),0
Add note about using dag_run.conf in BashOperator (#9143),1
[MetaSchedule][Test] Add unittests for SFM (#12251),3
[Relay][Passes] Iterative A-normal Traversals (#7374)* [WIP][Relay][Passes] non-recursive a-normal traversals* fix clang warning* Refactor ANormal Iterative traversal into a higher order function utility with lambdas* refactor missed pass* add explict use of  to lamdbas,5
[AIRFLOW-XXXX] Fix a typo in flower command (#7074),2
[ci] Add tests for PR linter (#12680)This adds some checks for the current usages of the PR linter and fixes the case where the script would error uncleanly when a PR body was `null`.,4
[AIRFLOW-4295] Make `method` case insensitive in HTTPHook (#5173)Make the method: `run` in the HttpHook compare the attribute: 'method' in a case insensitive way.This resolves the issue where a Httphook created with parameter `method='get'` would not betreated as a GET-request in the run method and the attribute `params`would be omitted in the Http request.,2
[ARM] Fix NCHWc int8 dot product schedule lowering (#10773)* [ARM] Fix NCHWc int8 dot product schedule lowering* fix arm task extraction test not running* skip test on i386,3
Fixes failing formatting of DAG file containing {} in docstring (#9779),2
"Add Playsimple Games to ""Who uses Apache Airflow?"" (#10253)",1
[TOPI] add 3D upsampling Op. (#4584)* [TOPI] add 3D upsampling Op.* fix lint issues* change align_corners to coordinate_transformation_mode* fix resize3d half_pixel* make a simple function and clean up trilinear_resize3d_python* fix doc,2
MXNet NDArray bridge. (#930)* MXNet NDArray bridge.Support convert a tvm Function as MXNet's async NDArray function.* fix lint* update comment,5
"[Relay][TOPI] Fix compute and schedule bugs for conv2d_winograd_nhwc on mali device. (#8091)1. add argument `auto_scheduler_rewritten_layout=""""` in conv2d_winograd_nhwc_mali;2. add `need_auto_scheduler_layout=True` for conv2d_strategy_mali andconv2d_winograd_without_weight_transfrom_strategy_mali.Signed-off-by: haizhu.shao <haizhu.shao@gmail.com>",1
"[ETHOSN] Add support for concatenate with negative axis (#12686)Supports offloading concatenate with a negative axis to the NPU. In addition, parameterized the concatenate unit tests.",3
[Hexagon] Skip test_avg_pool2d_slice because of segfault on hardware (#11929),1
[Relay] [Training] Fix ad for concatenate (#3729)* reproduce error* fix* lint* lint,0
Bump UI packages to latest releases (#14902),3
[Relay][Transform] Support Dumping IR to help debugging (#3493)* [Relay][Transform] Support Dumping IR to help debugging* debugprint->printir,0
"[AIRFLOW-3706] Fix tooltip max-width by correcting ordering of CSS files (#4947)The ""airflowDefaultTheme.css"" file is created by webpack out ofbootstrap-theme.css, which is a ""base"" file. But this was loaded _after_Airflow's main.css, meaning the `max-width` we set on `.tooltip-inner`was being replaced by the default from bootstrap.",1
[AIRFLOW-1786] Enforce correct behavior for soft-fail sensorsSoft-fail sensor failure causes skip of alldownstream tasks. It also enables ability to setup non-blocking and soft-fail sensors in the sameway as for regular sensors.Closes #3509 from artem-kirillov/AIRFLOW-1786,0
Fix relative include path (#10402),0
replace extra links value (#21971),2
[RELAY][OP] end to end support for pad op. (#2213),1
Add count_include_pad support (#498)* update tvm submodule* Add count_include_pad support to avg_pool,1
"[OpenCL] Avoid SelectNode ambiguous overloading (#11488)* [OpenCL] Avoid SelectNode ambiguous overloading* Revert ""[OpenCL] Avoid SelectNode ambiguous overloading""This reverts commit 60f68d2e7f750a0f8e62536da7b3327d1f5f29c1.* [OpenCL] Avoid SelectNode ambiguous codegen",4
"ci: Fix CodeQL Workflow for Javascript (#11941)We removed a bracket in bdd5e0b#diff-63bd641104d10e25f141d518a16b22a151d125e12701df2f9e79734b23b90188 due to which one of the conditions for CodeQL javascript has changed by mistake, so it is trying to run git checkout HEAD^2 for merged commits too instead of just running it on PRs.Example failed run on Master: https://github.com/apache/airflow/runs/1326054227",1
[MetaSchedule] Implement ScheduleFn as a C++ class (#12513),5
[Relay] fix exponential blowup in interpreter (#3559),0
[TOPI] Fix softmax bug (#437),0
[AIRFLOW-5709] Fix regression in setting custom operator resources. (#6331),1
"Add JSON linter to DAG Trigger UI (#13551)* Add JSON linter to Variable/DAG Trigger UIsAdding codemirror and jshint to lint the text input for add/edit a Variable and for config when triggering a DAG.variable_add whitespaceRemove JSON linter for add/edit VariablesVariable values can be either plain text or json which makes linting more complicated and not worth it for now.* Add JSON linter to DAG Trigger UIAdding codemirror and jshint to lint the text input for config when triggering a DAG.variable_add whitespaceAdd JSON linter to Variable/DAG Trigger UIsAdding codemirror and jshint to lint the text input for add/edit a Variable and for config when triggering a DAG.variable_add whitespaceRemove JSON linter for add/edit VariablesVariable values can be either plain text or json which makes linting more complicated and not worth it for now.update trigger dag conf testFixed failing test by adding `id=""json""` to the  expected html in the `test_trigger_dag_params_conf` test",3
[RUNTIME] Simplify dynamic library and code path. (#27)* [RUNTIME] Simplify dynamic library and code path.* reword the readme,1
Fix failing static check in master (#13082),0
Check free space python version for Breeze2 (#20701),5
"[AIRFLOW-2851] Canonicalize ""as _..."" etc imports (#3696)",2
make jdbc operator consistent with other db operators,1
CSS Changes to adjust content width as per screen size and responsive table with multiline td. (#12227),2
"Speed up Kubernetes tests ~30% on main. (#25143)We should have enough resources - we were limiting them to 2 parallelruns (we assumed 4 CPUs are needed for full K8S tests). Howevermonitoring shows that ~20/30% memory and up to 4 CPUs are usedwhen 2 tests are running in parallel (on a big instance) but the testshave also some peaks that might cause more than 3 parallel tests to fail.We currently run 5 tests so increasing the limit to 3 for self-hostedrunners should actually speed it up quite a bit (generally speaking wehad to run 2 tests in parallel twice and 5th test was run as standalone.By increasing the limit to 3 we switch to 3x, 2x mode - which not onlywill safe 30% of the time, but also has a free ""slot"" for one moreK8S version.",1
"Only compare updated time when Serialized DAG exists (#13899)closes https://github.com/apache/airflow/issues/13667The following error happens when Serialized DAGs exist in Webserver or Scheduler but it has just been removed from serialized_dag table,mainly due to the removal of DAG file.```Traceback (most recent call last):  File ""/home/app/.pyenv/versions/3.8.1/envs/airflow-py381/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py"", line 1275, in _execute    self._run_scheduler_loop()  File ""/home/app/.pyenv/versions/3.8.1/envs/airflow-py381/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py"", line 1377, in _run_scheduler_loop    num_queued_tis = self._do_scheduling(session)  File ""/home/app/.pyenv/versions/3.8.1/envs/airflow-py381/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py"", line 1516, in _do_scheduling    self._schedule_dag_run(dag_run, active_runs_by_dag_id.get(dag_run.dag_id, set()), session)  File ""/home/app/.pyenv/versions/3.8.1/envs/airflow-py381/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py"", line 1629, in _schedule_dag_run    dag = dag_run.dag = self.dagbag.get_dag(dag_run.dag_id, session=session)  File ""/home/app/.pyenv/versions/3.8.1/envs/airflow-py381/lib/python3.8/site-packages/airflow/utils/session.py"", line 62, in wrapper    return func(*args, **kwargs)  File ""/home/app/.pyenv/versions/3.8.1/envs/airflow-py381/lib/python3.8/site-packages/airflow/models/dagbag.py"", line 187, in get_dag    if sd_last_updated_datetime > self.dags_last_fetched[dag_id]```A simple fix is to just check if `sd_last_updated_datetime` is not `None` i.e. Serialized DAG for that dag_id is not None",2
"[AIRFLOW-125] Add file to GCS operatorAdds an operator to upload a file to Google Cloud Storage. Used as follows:```pyfrom airflow.contrib.operators.file_to_gcs import FileToGoogleCloudStorageOperatorgcs = FileToGoogleCloudStorageOperator(        bucket='a-bucket-i-have-access-to-on-gcs',        dag=dag,        task_id='upload_stuff',        google_cloud_storage_conn_id='an-airflow-bigquery-connection',        src=os.path.join(os.path.dirname(__file__), 'csv/some_file.csv'),        dst='project/some_file.csv')```",2
Add support for extra links coming from the providers (#12472)Closes: #11431,1
[AIRFLOW-6485] BigQuery hook - add missing test for BIgQueryBaseCursor methods (#7077),3
winograd_nnpack (#2721),5
[AIRFLOW-5650] remove githubhandle (#6328),0
Remove duplicate line call in CI (#19728),4
"Add more fields to REST API get DAG(dags/dag_id) endpoint (#22637)The DagModel columns have increased since this endpoint was created. This PR improves theendpoint by including all the missing fields of the DagModel on the endpoint.This update also touched on DAGDetails schema because it inherits from DAGSchema.In a future PR, when more details would be added to the DAGDetails endpoint, we couldseparate it from the DAGSchema. They are related but not really the same. One is adatabase object while the other is not",5
add travis wait to workaround timeouts,1
remove snakebite from requirements,1
fix compute inline not to over write annotated opaque accesses (#9509),0
Fix task instance api cannot list task instances with None state (#19487)* Fix task instance api cannot list task instances with None stateThe task instance state can be None and in the API we accept `none` for null state.This PR fixes this issue by converting the `none` to None and improving the queryso that the DB can get this state.,1
Merge pull request #44 from airbnb/timeout_importsAdding a timeout Context object and using it when importing dags,2
fix dump ir (#2235),0
Testing emails (dryrun),1
"[AIRFLOW-4871] Allow creating DagRuns via RBAC UI (#5507)All this needed to enable the form was to add `can_add` to thepermission listThe run_id field is a required form (though the DB doesn't have it asnot nullable) - the scheduler requires it. so I have enabled therequired validation for it.The `validators_columns` attribute on the view was ignored by FABbecause we set `add_form` and `edit_form` directly, so I have removedthe property",5
[AIRFLOW-6405] Add GCP BigQuery Table Upsert Operator (#7126)* [AIRFLOW-6405] Add GCP BigQuery Table Property Upsert Operator* [AIRFLOW-6405] Remove unnecessary checks from BQ hook,1
[AIRFLOW-5306] Fix the display of links when they contain special characters (#5904),2
[RUNTIME] Fix TypeKey2Index when for root Object (#8547)* [RUNTIME] Fix TypeKey2Index when for root Object* Temp skip tsim tests,3
[AIRFLOW-9300] Add DatafusionPipelineStateSensor and aync option to the CloudDataFusionStartPipelineOperator (#17787),5
[AIRFLOW-2132] Add step to initialize databaseCloses #3064 from kylehayes/patch-2,5
Proper title for XCom List View page (#12169),5
Removing redundant relabeling of password conn field (#18386),4
"[Contrib][ONNX] Handle removal of onnx.utils.polish_model (#9178)Onnx 1.9 removed optimizers from the core repository (see discussionin https://github.com/onnx/onnx/pull/2834), includingonnx.utils.polish_model, breaking RelayToONNXConverter.  This PR addonnxoptimizer.optimize as a fallback method if onnx.utils.polish_modelis unavailable.Also updates tutorials/documentation to recommend installingonnxoptimizer when installing onnx, because the current PyPI versionof onnx is above version 1.9.",1
"[AIRFLOW-2903] Change default owner from ""Airflow"" to ""airflow""",4
Merge pull request #1291 from jlowin/scheduler_start_dateDon't schedule runs before the DAG's start_date,5
[AIRFLOW-3112] Fix SFTPHook not validating hosts by default (#4085),5
This patch adds license checking for Airflow. For now it will store a numberin Travis' cache to make sure current builds do not fail but newly addedfiles should have a license header included.,2
[AIRFLOW-5000] Remove duplicate end_date and reorder template (#5618)* Remove the duplicate end_date in template context* Reorder template context key to make ds together,1
Allow retrieving Connections from Secrets Backend using CLI (#8440)Co-Authored-By: Kaxil Naik <kaxilnaik@gmail.com>,1
"Fixes constraint generation for pypi providers (#15470)* Fixes constraint generation for pypi providersThe constraints generated from PyPI version of providers, missedcore requirements of Airflow, therefore the constraints were notconsistent with setup.py core requirements.Fixes: #15463",0
Remove duplicate dependency ('curl') from Dockerfile (#8412),2
"[MATH][TOPI][NNVM] introduce trunc, round (#1310)",1
Add QEMU setup to uTVM tutorial. (#7296),1
Branch setup for v2-4 (#26236),1
[PASS] Allow compact checking when strides is available (#669)* [PASS] Allow compact checking when strides is available* remove assert compact,3
Fix yamllint check with lines too long (#25573),0
[AIRFLOW-5254] Move GCP Tasks to core (#5860)This commit moves GCP Tasks from contrib to core.For more information check AIP-21.,5
"[Relay, TOPI] Add numpy style cumsum op (#7334)* Add cumsum relay/topi op* relay tests working* add torch frontend converter* fix for importing detr* fix bad merge* begin cuda cumsum* support non innermost axis* support rank higher than 3* making binop parameter* fix overflow issue in thrust scan* generic binop parameter working* relay test working* fixed for bool input* remove pytorch change* fix pylint* doc update* Update python/tvm/topi/cumsum.pyCo-authored-by: Tristan Konolige <tristan.konolige@gmail.com>* Update tests/python/relay/test_op_level3.pyCo-authored-by: Tristan Konolige <tristan.konolige@gmail.com>* add example outputs* add supported input and output dtype in thrust log* adding more loop var names* fix cpplint* fix missing check for the cuda target in nms thrust sort* parallelize cpu cumsum* making binop argument tir function* update doc for binop* doc updateCo-authored-by: Tristan Konolige <tristan.konolige@gmail.com>",5
Error message when task is gone on task details page,0
Add test_connection to Azure Batch hook (#25235)* Add test_connection to Azure Batch hook* Apply review suggestions,1
"[AIRFLOW-3306] Disable flask-sqlalchemy modification tracking. (#4146)By default, flask-sqlalchemy tracks model changes for its event system, whichadds some overhead. Since I don't think we're using the flask-sqlalchemyevent system, we should be able to turn off modification tracking and improveperformance.",1
[BYOC-DNNL] add partition test on sum pattern (#12357)* add partition test on sum pattern* fix lint,0
"[AIRFLOW-6761] Fix WorkGroup param in AWSAthenaHook (#7386)Unknown parameter in input: ""Workgroup"", must be one of: QueryString, ClientRequestToken, QueryExecutionContext, ResultConfiguration, WorkGroup",1
"[AIRFLOW-4591] Make default_pool a real pool (#5349)`non_pooled_task_slot_count` and `non_pooled_backfill_task_slot_count`are removed in favor of a real pool, e.g. `default_pool`.By default tasks are running in `default_pool`.`default_pool` is initialized with 128 slots and user can change thenumber of slots through UI/CLI. `default_pool` cannot be removed.",4
[AIRFLOW-1035] Use binary exponential backoffCloses #2196 from IvanVergiliev/exponential-backoff,1
[AIRFLOW-XXX] Add a third way to configure authorization (#6134),5
[PASS] add a pass for the specific hardware accelarator when it is not binded (#1999),4
Make sure to be py3 compatible,1
support for continue backfill on failures (#22697),0
Add helm chart 1.2.0 to chart bug issue template (#18609),0
[AIRFLOW-2530] KubernetesOperator supports multiple clustersCloses #3425 from mrkm4ntr/airflow-2530,1
[DOC] minor language use improvements (#3317),1
Add Authentication for Stable API (#10267),1
Handle no Dagrun in DagrunIdDep (#8389),2
[AIRFLOW-5169] Pass GCP Project ID explicitly to StorageClient in GCSHook (#5783),1
[AIRFLOW-3650] Skip running on mysql for the flaky test (#4457),3
"Clean-up airflow/kubernetes/kube_config.py (#12627)- Remove the stale internal method `_get_security_context_val`  It was added in PR #5429, but to what I can see, it's not needed anymore.- Avoid hard-coding when we can (we already have `core_section` specified, so can avoid using ``'core'`)- Narrow down what we import from `airflow.settings`",1
Correctly handle multiple '=' in LocalFileSystem secrets. (#21694),5
Support google-cloud-tasks>=2.0.0 (#13347),1
"Add `is_floating_point()` test and better type support in `verify_model_vm()` (#7134)* Add div_ and is_floating_point operators* Add handling of exprs to op, update tests* add test + supporting functions* Revert whitespace changes* Properly assign dtype to random integers* Reformat with black* Switched default dtype logic, removed extra line",4
"[AIRFLOW-7026] Improve SparkSqlHook's error message (#7749)* Replace self._conn.host in the error message with  self._master, because the former is unused in  SparkSqlHook actually.* Add self._sql into the error message, because it's  the executed query or a file that contains it.",2
Add more information about using GoogleAdsHook (#9951)This hook requires two connections and it's not obvious howto use it and what is the purpose of each connection.,1
[AIRFLOW-XXX] GCP operators documentation clarifications (#4273),2
[API] Expose AutoInlineInjective (#368),5
[AIRFLOW-6383] Add no trailing-whitespace pre-commit hook (#6941),1
closes apache/incubator-airflow#2337 *No longer a bug*,0
Update CONTRIBUTORS.md,5
"Add link to docs index to table of contents (#12594)Without this, it's not obvious how to get back to the main page",1
"[AIRFLOW-703][AIRFLOW-1] Stop Xcom being cleared too earlyXComs should only be cleared when it is certainthat the task will run. Previously, XComs were clearedbefore it was determined if tasks were runnable, queable,or just being marked success. Now XComs are clearedimmediately before the task actually starts.Closes #1951 from blrnw3/fix/xcom_bug_AIRFLOW-703",0
"[AIRFLOW-5829] Get rid of the checklicence image (#6495)This change is a further step of simplifying the set of scriptsused by CI. The separate checklicence image was implemented as anoptimisation of the licence check time. The image to download wassmall and could be downloaded slightly faster in CI. However thatmade all the management script more complex and lead to havingseparate jobs for check licence and static checks. That lead toactually longer time of Travis jobs - because new machine had tobe spun-off for checklicence check only.With this change, the CI image is the only one left and it is slightlybigger (with RAT tool added) but the same image is used for all thetests - unit tests, static checks and checklicence checks.This also makes it easier to manage the images and decreases updateoverhead on the developers using Breeze.",1
add dry run for backfill CLI,1
Merge pull request #420 from airbnb/better_jsonImproving json encoding,5
Adds 'cncf.kubernetes' package back to backport provider packages. (#10659),1
"Use found pod for deletion in KubernetesPodOperator (#22092)Due to bad user configuration, it's possible that pod creation fails because pod with name already exists.  Then in cleanup, the pod that was already there is deleted.  When we use find_pod it looks up based on more than name, so we are confident if we found a pod there it's safe to delete.",4
[AIRFLOW-6451] self._print_stat() in dag_processing.py should be skippable (#7134),2
[AIRFLOW-2532] Support logs_volume_subpath for KubernetesExecutorThe kubernetes section in the configuration filesupportslogs_volume_subpath for KubernetesExecutor.Closes #3430 from imroc/AIRFLOW-2532,2
"Avoid changing executable bits in docker scripts (#21211)There are various problems with executable bits in scripts usedin different environments in docker builds:* depending on the umask of the Linux host system, group bits  might be set or not - this might lead to Docker cache  invalidation* on Windows host systems, when file is copied to Docker, the  executable bits might be lost when the file is copied to  docker context* when AUFS is used as backing storage changing executable bit  might lead to crashes if there is no extra sync* changing executable bit of the script leads to actual change  of the cache while building, which also might produce  cache invalidationAs the result we cannot rely on the executable bits of the scriptsand cannot change them in the image either.This change removes executable bits from the scripts for group andother, and executes all the docker scripts via `bash` command.",2
"[AIRFLOW-4799] don't mutate self.env in BashOperator execute method (#5421)* in tests using bash operator repeatedly, env is populated with contents of environment.* on subsequent runs, render_templates will try to render contents of env.* this produces unpredictable behavior where missing template error may be thrown, or env paths may be replaced with ""template file"" contents",2
Adding task_instance_key_str to default template macros,1
[Relay][Training] Make AutoDiff thread through global function. (#6336)* save* lint* lint* fix warning* fix test* save,3
[AIRFLOW-4445] mushroom cloud errors too verbose (#6952)* [AIRFLOW-4445] mushroom cloud errors too verbose,0
Fix incorrect .airflowignore behavior with multiple nested directories (#11994)* Add failing test* Fix failing test,3
import chr,2
Minor improvment to tutorial example,5
[AIRFLOW-6366] Fix migrations for MS SQL Server (#6920),0
Move scripts for prod image preparation to dev (#19623)The script belongs to dev. Also it had `echo` debug commands leftafter testing that are removed now.,4
[AIRFLOW-5759] Don't allow additional arguments in BaseOperator (#6435),1
[MetaSchedule] Mutator: Mutate compute location (#10028)Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Junru Shao <junrushao1994@gmail.com>Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>,1
"Add more informative messages when rebuilding the image (#18496)Reviewed and updated the messages printed when image needed tobe rebuild. Some messages were unclear or duplicatd. I removedall the ambiguities and added some colors. Also there wasapparently the case that automated rebuild on commit did not takeinto account the check of whethere image needs to be pulled, thatcould lead to longer rebuild times in this case.",1
[AIRFLOW-7048] Allow user to chose timezone to use in UI (#8046)Co-authored-by: Sam Black <samblackk@users.noreply.github.com>,1
[AIRFLOW-4504] Remove join_args option in run_command() (#5272),1
[AIRFLOW-XXX] Update manage-connections.rst (#4020)Explain how to connect with MySQL,5
[CODEGEN] Multiple parallel in one launch (#399),5
Allow RPCWrappedFunc to rewrite runtime::String as std::string (#5796),1
"Fetch PR labels from API for Build Images workflow (#18572)The event payload in GitHub does contain PR labels, but they are ""fixed""at the time the original event is triggered, meaning that if you re-runthe Build Image job at a later date (say after the ""full tests needed""label has been automatically applies) it will still see the same values.",3
Fix grammar in BREEZE.rst (#10904)`Other uses the Airflow Breeze environment` -> `Other uses of the Airflow Breeze environment`,1
[TOPI] fix weight layout in conv2d_transpose (#616),0
Merge pull request #1249 from SaurabhBajaj/patch-1update link to Lyft's website,2
Fix typo in .pre-commit-config.yaml (#8126),5
update doc (#47),2
Add reference link for KubernetesPodOperator in kubernetes.rst (#11782)This makes it easy to go to the class definition and find the arguments/params that can be passed to the Operator,1
"[Meta Schedule][M3b] Runner (#9111)This PR is part of the meta schedule project (#8473) that adds theasynchronous program runner interface, as well as a referenceimplementation of RPCRunner. LocalRunner will be implemented withPopenPool executor in a follow-up PR.Co-authored-by: Xiyou Zhou <xiyou@octoml.ai>Co-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>Co-authored-by: Ruihang Lai <lairuihangdongdong@qq.com>Co-authored-by: Hongyi Jin <3231950289@qq.com>Co-authored-by: Wuwei Lin <wuwei@apache.org>Co-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>Address commentsCo-authored-by: Cody Yu <comaniac0422@gmail.com>fix lint",0
Add additional dependency for postgres extra for amazon provider (#18737),1
typos and xcom changes,4
Fixed issue 1012: pool not used with celery executor,1
"Enable serialization by default (#11491)We actually need to make serialization the default, but this is aninterim measure for Airflow2.0.0.alpha1 reeaseSince many of the tests will fail with it enabled (they need fixing upto ensure DAGs are in the serializated table) as a hacky measure we haveset it back to false in the tests.",3
"[VTA][TSIM] Serial GEMM Application Added (#4082)* app init push* fix on readme* change name, add bit serial explanantion* rm serialLoadMM, change doc* syntax change for readme* add parallel test functionality* fix readme* add python doc* syntax",2
lengend color fix for dark ops,0
Jekyll (#3262),5
Properly style code blocks in links (#20938),2
Replace changelog/updating with release notes and towncrier now (#22003),5
Add tophub for x86 (#1955),1
[COMMUNITY] @phisiart -> Committer (#2165),3
Fix airflow_local_settings.py showing up as directory (#10999)Fixes a bug where the airflow_local_settings.py mounts as a volumeif there is no value (this causes k8sExecutor pods to fail),0
Improve setUp/tearDown in Cloud Firestore system test (#7862),3
Fix airflow.www.views import (#8050),2
Add extra links endpoint (#9475),2
Passing self to setAutocommit,1
enable UI feature to recursively set success=True for all operators within SubDagOperator,2
