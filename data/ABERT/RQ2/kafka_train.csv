commit_msg,labels
"KAFKA-4779; Fix security upgrade system test to be non-disruptiveThe phase_two security upgrade test verifies upgrading inter-broker and client protocols to the same value as well as different values. The second case currently changes inter-broker protocol without first enabling the protocol, disrupting produce/consume until the whole cluster is updated. This commit changes the test to be a non-disruptive upgrade test that enables protocols first (simulating phase one of upgrade).Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2589 from rajinisivaram/KAFKA-4779",5
"KAFKA-13155; Fix concurrent modification in consumer shutdown (#11164)The `TransactionalMessageCopier` tool, which is used in system tests attempts to close the consumer as part of a shutdown hook. Although the access is synchronized, there is no guarantee that the consumer has finished polling when shutdown is invoked. The patch fixes the problem by call `wakeup()` from the shutdown hook and pushing the call to `close()` to the main thread.Reviewers: David Jacot <djacot@confluent.io>",5
trivial change to README to make the gradle wrapper download clearer,1
"MINOR: Add KIP-584 to upgrade.html file (#9511)Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Boyang Chen <boyang@confluent.io>",5
KAFKA-13301 Config documentation optimized for 'request.timeout. ms' and 'max.poll.interval.ms'. (#11329)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-139 cross-compile multiple Scala versions the dependency jars moved and the bin scripts needed to point to the new locations,1
"KAFKA-2072; Replace StopReplica Request/Response with their org.apache.kafka.common.requests equivalentsAuthor: David Jacot <david.jacot@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com>Closes #196 from dajac/KAFKA-2072-part-2",2
"KAFKA-3170; Set default fetch_min_bytes in new consumer to 1Set default to 1 instead of 1024, this matches the existing doc and feels like a better default value. Have run the unit tests with the change.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson, Ismael Juma, Grant Henke, Guozhang WangCloses #832 from rajinisivaram/KAFKA-3170",5
trivial change to 0.9.0 docs to fix outdated ConsumerMetadataRequest,5
"KAFKA-13940; Return NOT_LEADER_OR_FOLLOWER if DescribeQuorum sent to non-leader (#12517)Currently the server will return `INVALID_REQUEST` if a `DescribeQuorum` request is sent to a node that is not the current leader. In addition to being inconsistent with all of the other leader APIs in the raft layer, this error is treated as fatal by both the forwarding manager and the admin client. Instead, we should return `NOT_LEADER_OR_FOLLOWER` as we do with the other APIs. This error is retriable and we can rely on the admin client to retry it after seeing this error.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-12996; Return OFFSET_OUT_OF_RANGE for fetchOffset < startOffset even for diverging epochs (#10930)If fetchOffset < startOffset, we currently throw OffsetOutOfRangeException when attempting to read from the log in the regular case. But for diverging epochs, we return Errors.NONE with the new leader start offset, hwm etc.. ReplicaFetcherThread throws OffsetOutOfRangeException when processing responses with Errors.NONE if the leader's offsets in the response are out of range and this moves the partition to failed state. The PR adds a check for this case when processing fetch requests and throws OffsetOutOfRangeException regardless of epoch.Reviewers: Luke Chen <showuon@gmail.com>, Nikhil Bhatia <rite2nikhil@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-3949: Fix race condition when metadata update arrives during rebalanceAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Vahid Hashemian, Guozhang WangCloses #1762 from hachikuji/KAFKA-3949",5
"MINOR: doc change for deprecate removal (#5006)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"Rename streams tutorial and quickstartChanged these topic titles:- Write your own Streams Applications -> Tutorial: Write a Streams Application- Play with a Streams Application -> Run the Streams Demo ApplicationAuthor: Joel Hamill <joel@Joel-Hamill-Confluent.local>Author: Joel Hamill <11722533+joel-hamill@users.noreply.github.com>Reviewers: Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4017 from joel-hamill/joel-hamill/streams-titles",5
"KAFKA-9614: Not initialize topology twice in StreamTask (#8173)We only initialize topology when transiting from restoring -> running.Also tighten some unit tests for this fix:a. restoring -> suspended should just write checkpoint file without committing.b. suspended -> restoring should not need any inner updates.c. restoring -> running should always try to fetch committed offsets, and forward timeout exceptions.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-13613: Remove hard dependency on HmacSHA256 algorithm for Connect (#11894)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",4
KAFKA-3836: KStreamReduce and KTableReduce should not pass nulls to DeserializersMinor changes to check null changes.Author: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1591 from jeyhunkarimov/KAFKA-3836,4
"KAFKA-5630; Consumer should block on corrupt records and keep throwing an exceptionThis patch handles the case that a CorruptRecordException is thrown from the iterator directly.The fix is a little tricky as exceptions can be thrown from a few different scenarios. The current approach is to let the same record go through the exact same process as last time when exception is thrown, so the exception will be thrown at the same step. The only problem for that is the iterator state will change once it throws an exception. To handle that we cache the first iterator exception and put it into the suppressed exception of the IllegalStateException thrown in the future.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3573 from becketqin/KAFKA-5630",5
"KAFKA-6748: double check before scheduling a new task after the punctuate call (#4827)After the punctuate() call, we would like to double check on the scheduled flag since the call itself may cancel it.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",5
"KAFKA-2517; Performance Regression post SSL implementation (zero copy)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>Closes #273 from ijuma/kafka-2517-ssl-zero-copy-regression",1
"KAFKA-3878; Support exponential backoff policy via reconnect.backoff.max (KIP-144)Summary:- add `reconnect.backoff.max.ms` common client configuration parameter- if `reconnect.backoff.max.ms` > `reconnect.backoff.ms`, apply an exponential backoff policy- apply +/- 20% random jitter to smooth cluster reconnectsAuthor: Dana Powers <dana.powers@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Roger Hoover <roger.hoover@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1523 from dpkp/exp_backoff",2
"KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1 (#9406)We currently stop polling in `Sender` in a transactional producer if there is only one broker in the bootstrap server list and `max.in.flight.requests.per.connection=1` and Metadata response is pending when InitProducerId request is ready to be sent. In this scenario, we attempt to send FindCoordinator to `leastLoadedNode`, but since that is blocked due to `max.in.flight=1` as a result of the pending metadata response, we never unblock unless we poll. This PR ensures we poll in this case.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-3149; Extend SASL implementation to support more mechanismsCode changes corresponding to KIP-43 to enable review of the KIP.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@apache.org>, Ismael Juma <ismael@juma.me.uk>Closes #812 from rajinisivaram/KAFKA-3149",5
"Revert ""KAFKA-10713: Stricter protocol parsing in hostnames (#9593)""This reverts commit 8a59a228817df221ac9acc7cce4f6c9dd702e9ef since it breaksclient configurations like `bootstrap.servers=SASL_PLAINTEXT://localhost:49767`.A KIP will be submitted to discuss the details and an adjusted change willbe submitted depending on the outcome of that.",4
"KAFKA-4830; Augment KStream.print() to allow users pass in extra parameters in the printed stringI extend `KStream#print()` to `KStream#print(KeyValueMapper<K, V, String>)`.So I add the following methods :1. `KStream#print(KeyValueMapper<K, V, String>)`2. `KStream#print(KeyValueMapper<K, V, String>, String streamName)`3. `KStream#print(KeyValueMapper<K, V, String>, Serde<K>, Serde<V>)`4. `KStream#print(KeyValueMapper<K, V, String>, Serde<K>, Serde<V>, String streamName)`Author: jameschien <jameschien@staff.ruten.com.tw>Author: jedichien <james.chain1990@gmail.com>Author: JamesChien <jedichien@users.noreply.github.com>Author: JamesChien <james.chain1990@gmail.com>Reviewers: Bill Bejeck <bbejec@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3085 from jedichien/KAFKA-4830",1
KAFKA-14076: Fix issues with KafkaStreams.CloseOptions (#12408)- used static memberId was incorrect- need to remove all threads/members from the group- need to use admit client correctlyAdd test to verify fixes.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-4580; Use sasl.jaas.config for some system testsSwitched console_consumer, verifiable_consumer and verifiable_producer to use new sasl.jaas_config property instead of static JAAS configuration file when used with SASL_PLAINTEXT.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2323 from rajinisivaram/KAFKA-4580",5
"KAFKA-4360：Controller may deadLock when autoLeaderRebalance encounter zk expiredAuthor: tuyang <tuyang@meituan.com>Author: xiguantiaozhan <kafkausr@126.com>Reviewers: Ismael Juma, Jiangjie Qin, Guozhang WangCloses #2094 from xiguantiaozhan/rebalance_deadlock",5
KAFKA-1086 Improve GetOffsetShell to find metadata automatically; reviewed by Jun Rao,5
"KAFKA-13490: Fix createTopics and incrementalAlterConfigs for KRaft mode #11416For CreateTopics, fix a bug where if one createTopics in a batch failed, they would all fail withthe same error code.  Make the error message for TOPIC_ALREADY_EXISTS consistent with the ZK-basedcode by including the topic name.For IncrementalAlterConfigs, before we allow topic configurations to be set, we should check thatthey are valid. (This also applies to newly created topics.) IncrementalAlterConfigs should ignorenon-null payloads for DELETE operations. Previously we would return an error in these cases.However, this is not compatible with the old ZK-based code, which ignores the payload in thesecases.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3159; stale high watermark segment offset causes early fetch returnAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #884 from hachikuji/K3159",5
KAFKA-1046 Added support for Scala 2.10 builds while maintaining compatibility with 2.8.x; reviewed by Neha and Jun,5
"KAFKA-4222; QueryableIntegrationTest.queryOnRebalance transient failureDon't produce messages on a separate thread continuosly. Just produce one of each value and stop.Close the producer once finished.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3080 from dguy/qs-test",3
HOTFIX: reduce streams benchmark input records to 10 millionWe are occasionally hitting some timeouts due to processing not finishing. So rather than failing the build for these reasons it would be better to reduce the runtime.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3725 from dguy/fix-system-test,5
MINOR: Log error if offsets topic creation failsThis problem is hard to debug otherwise as there errorreturned to the client (“Coordinator not available”) is notvery informative.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2652 from enothereska/minor-warning-enforcement-offset,2
"MINOR: Update javadoc of `SnapshotWriter.createWithHeader` (#11530)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-12374: Add missing config sasl.mechanism.controller.protocol (#10199)Fix some cases where we were erroneously using the configuration of the inter brokerlistener instead of the controller listener.  Add the sasl.mechanism.controller.protocolconfiguration key specified by KIP-631.  Add some ducktape tests.Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>, Boyang Chen <boyang@confluent.io>",5
MINOR: Remove unused Utils.delete (#10622)Anna Sophie Blee-Goldman <ableegoldman@apache.org>,4
KAFKA-2066; Use client-side FetchRequest/FetchResponse on serverAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #2069 from hachikuji/KAFKA-2066,5
"MINOR: Allow timestamp parameter in `ProcessorTopologyTestDriver.process`All current implementations process records using the same timestamp. This makes it difficult to test operations that require time windows, like `KStream-KStream joins`.This change would allow tests to simulate records created at different times, thus making it possible to test operations like the above mentioned joins.Author: Sebastian Gavril <sgavril@wehkamp.nl>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3753 from sebigavril/allow-timestamps-in-test-driver",3
KAFKA-1664 Kafka does not properly parse multiple ZK nodes with non-root chroot; reviewed by Neha Narkhede and Jun Rao,5
"KAFKA-2294; javadoc compile error due to illegal <p/> , build failing (jdk 8); patched by Jeff Maxwell; reviewed by Jakob Homan",0
KAFKA-12492: Fix the formatting of example RocksDBConfigSetter (#10486)Fix the formatting of example RocksDBConfigSetter due to the un-arranged spaces within <pre> tag.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
KAFKA-9734: Fix IllegalState in Streams transit to standby (#8319)Consolidate ChangelogReader state management inside of StreamThread to avoid having to reason about all execution paths in both StreamThread and TaskManager.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"KAFKA-6264; Split log segments as needed if offsets overflow the indexes (#4975)This patch adds logic to detect and fix segments which have overflowed offsets as a result of bugs in older versions of Kafka.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10387: Fix inclusion of transformation configs when topic creation is enabled in Connect (#9172)Addition of configs for custom topic creation with KIP-158 created a regression when transformation configs are also included in the configuration of a source connector. To experience the issue, just enabling topic creation at the worker is not sufficient. A user needs to supply a source connector configuration that contains both transformations and custom topic creation properties. The issue is that the enrichment of configs in `SourceConnectorConfig` happens on top of an `AbstractConfig` rather than a `ConnectorConfig`. Inheriting from the latter allows enrichment to be composable for both topic creation and transformations. Unit tests and integration tests are written to test these combinations. Reviewers: Randall Hauch <rhauch@gmail.com>",3
"MINOR: Fix kafka.server.RequestQuotaTest missing new ApiKeys. (#8302)The test was broken by commit 227a7322b77840e08924b9486e4bda2f3dfc1f1a.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",3
kafka-1699; autoRebalanceScheduler.shutdown() causes deadlock while controller shutting down; patched by Sriharsha Chintalapani; reviewed by Jun Rao,1
"KAFKA-5815; add Printed class and KStream#print(printed)Part of KIP-182- Add `Printed` class and `KStream#print(Printed)`- deprecate all other `print` and `writeAsText` methodsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3768 from dguy/kafka-5652-printed",5
"MINOR: Add registerController method to KafkaZkClient (#4598)And change KafkaController to use the newly introduced method.Also remove redundant `InZk` postfixes from `registerBrokerInZk` and`updateBrokerInfoInZk`.As `checkedEphemeralCreate` is not used outside of `KafkaZkClient`any longer, reduce its visibility.ControllerIntegrationTest already covers this functionality well, it validates therefactor.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-5720; Fix AdminClientIntegrationTest#testCallInFlightTimeouts* When a call is aborted, that should count as a ""try"" in the failure log message.* FailureInjectingTimeoutProcessorFactory should fail the first request it is asked about.* testCallTimeouts should expect the first request it makes to fail because of the timeout we injected.* FailureInjectingTimeoutProcessorFactory should track how many failures it has injected, and the test should verify that one has been injected.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3731 from cmccabe/KAFKA-5720",5
"KAFKA-10379: Implement the KIP-478 StreamBuilder#addGlobalStore() (#9148)From KIP-478, implement the new StreamBuilder#addGlobalStore() overloadthat takes a stateUpdateSupplier fully typed Processor<KIn, VIn, Void, Void>.Where necessary, use the adapters to make the old APIs defer to the new ones,as well as limiting the scope of this change set.Reviewers: Boyang Chen <boyang@apache.org>",1
KAFKA-2915: Fix problem with System Tests that use bootstrap.servers embedded in jinja filesFixes problems in mirror maker and consumer testshttp://jenkins.confluent.io/job/kafka_system_tests_branch_builder/290/http://jenkins.confluent.io/job/kafka_system_tests_branch_builder/289/Author: Ben Stopford <benstopford@gmail.com>Reviewers: Guozhang WangCloses #608 from benstopford/KAFKA-2915-jinja-bug,0
"MINOR: Move `configurations.all` to be a child of `allprojects` (#10349)It was incorrectly set within `dependencyUpdates` and it still worked.That is, this is a no-op in terms of behavior, but makes it easier toread and understand.I tested that `releaseTarGz` produced a tar with two versions of`javassist` _without this block_ and a single version with it (in eitherposition).Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
KAFKA-12427: Don't update connection idle time for muted connections (#10267)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR: Fix partition state change error msg (#11427)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Missing punctuation marks in quickstart (#5755)Minor fix for missing punctuation marks in the quickstart.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-13661; Consistent permissions in KRaft for CreatePartitions API (#11745)In #11649, we fixed one permission inconsistency between kraft and zk authorization for the `CreatePartitions` request. Previously kraft was requiring `CREATE` permission on the `Topic` resource when it should have required `ALTER`. A second inconsistency is that kraft was also allowing `CREATE` on the `Cluster` resource, which is not supported in zk clusters and was not documented in KIP-195: https://cwiki.apache.org/confluence/display/KAFKA/KIP-195%3A+AdminClient.createPartitions. This patch fixes this inconsistency and adds additional test coverage for both cases.Reviewers: José Armando García Sancio <jsancio@gmail.com>",3
"KAFKA-10220: Add null check for configurationKey in AdminManager.describeConfigs()Add null check for configurationKey to avoid NPE, and add test for it.Author: Luke Chen <showuon@gmail.com>Reviewers: Tom Bentley <tbentley@redhat.com>, huxi <huxi_2b@hotmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8966 from showuon/KAFKA-10220",3
HOTFIX: Disable test until fixedAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2217 from enothereska/hotfix-disable-smoke-test,3
MINOR: Fix typo (thread -> threads) in MirrorMaker (#10130)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
KAFKA-13287: Upgrade RocksDB to 6.22.1.1 (#11317)This commit upgrades RocksDB from 6.19.3 to 6.22.1.1Reviewer: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
KAFKA-9226: Updated documentation section on log deletion policies. (#7738)Reviewers: Mickael Maison <mickael.maison@gmail.com>,4
"KAFKA-13690: Fix flaky test in EosIntegrationTest (#11887)I found a couple of flakiness with the integration test.IQv1 on stores failed although getting the store itself is covered with timeouts, since the InvalidStoreException is upon the query (store.all()). I changed to the util function with IQv2 whose timeout/retry covers the whole procedure. Example of such failure is: https://ci-builds.apache.org/blue/organizations/jenkins/Kafka%2Fkafka-pr/detail/PR-11802/11/tests/With ALOS we should not check that the output, as well as the state store content is exactly as of processed once, since it is possible that during processing we got spurious task-migrate exceptions and re-processed with duplicates. I actually cannot reproduce this error locally, but from the jenkins errors it seems possible indeed. Example of such failure is: https://ci-builds.apache.org/blue/organizations/jenkins/Kafka%2Fkafka-pr/detail/PR-11433/4/tests/Some minor cleanups.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-7433; Introduce broker options in TopicCommand to use AdminClient (KIP-377)The PR adds --bootstrap-server and --admin.config options to TopicCommand and implements an alternative, AdminClient based way of topic management.As testing I've duplicated the existing tests and made them working with the AdminClient options.Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Reviewers: Andras Katona <41361962+akatona84@users.noreply.github.com>, Sandor Murakozi <smurakozi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #5683 from viktorsomogyi/topiccommand-adminclient",5
"KAFKA-12268: Implement task idling semantics via currentLag API (#10137)Implements KIP-695Reverts a previous behavior change to Consumer.poll and replacesit with a new Consumer.currentLag API, which returns the client'scurrently cached lag.Uses this new API to implement the desired task idling semanticsimprovement from KIP-695.Reverts fdcf8fbf72bee9e672d0790cdbe5539846f7dc8e / KAFKA-10866: Add metadata to ConsumerRecords (#9836)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <guozhang@apache.org>",5
MINOR: Add missing deprecations on old request objectsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3651 from hachikuji/add-missing-request-deprecations,1
"KAFKA-6958: Overload KStream methods to allow to name operation name using the new Named class (#6411)Sub-task required to allow to define custom processor names with KStreams DSL(KIP-307) : - overload methods for stateless operations to accept a Named parameter (filter, filterNot, map, mapValues, foreach, peek, branch, transform, transformValue, flatTransform) - overload process method to accept a Named parameter - overload join/leftJoin/outerJoin methodsReviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>,Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-3995; KIP-126 Allow KafkaProducer to split and resend oversized batchesAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2638 from becketqin/KAFKA-3995",1
"KAFKA-2955; Add a simple "">"" prompt to console producerAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma, Guozhang Wang, Gwen ShapiraCloses #1233 from omkreddy/KAFKA-2955",1
Fix KAFKA-7789 by increasing the key size for the RSA keys generated for (#6096)Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-10028: Implement write path for feature versioning system (KIP-584) (#9001)Summary:In this PR, I have implemented the write path of the feature versioning system (KIP-584). Here is a summary of what's in this PR:New APIs in org.apache.kafka.clients.admin.Admin interface, and their client and server implementations. These APIs can be used to describe features and update finalized features. These APIs are: Admin#describeFeatures and Admin#updateFeatures.The write path is provided by the Admin#updateFeatures API. The corresponding server-side implementation is provided in KafkaApis and KafkaController classes. This can be a good place to start the code review.The write path is supplemented by Admin#describeFeatures client API. This does not translate 1:1 to a server-side API. Instead, under the hood the API makes an explicit ApiVersionsRequest to the Broker to fetch the supported and finalized features.Implemented a suite of integration tests in UpdateFeaturesTest.scala that thoroughly exercises the various cases in the write path.Other changes:The data type of the FinalizedFeaturesEpoch field in ApiVersionsResponse has been modified from int32 to int64. This change is to conform with the latest changes to the KIP explained in the voting thread.Along the way, the class SupportedFeatures has been renamed to be called BrokerFeatures, and, it now holds both supported features as well as default minimum version levels.For the purpose of testing, both the BrokerFeatures and FinalizedFeatureCache classes have been changed to be no longer singleton in implementation. Instead, these are now instantiated once and maintained in KafkaServer. The singleton instances are passed around to various classes, as needed.Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-10131: Remove use_zk_connection flag from ducktape (#9274)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-2768: AdminClient ignore member list for non-stable groups…stabilizingAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma, Jason Gustafson, Guozhang WangCloses #447 from SinghAsDev/KAFKA-2768",2
"KAFKA-12897: KRaft multi-partition placement on single broker (#10823)#10494 introduced a bug in the KRaft controller where the controller will loop forever in StripedReplicaPlacer trying to identify the racks on which to place partition replicas if there is a single unfenced broker in the cluster and the number of requested partitions in a CREATE_TOPICS request is greater than 1.This patch refactors out some argument sanity checks and invokes those checks in both RackList and StripedReplicaPlacer, and it adds tests for this as well as the single broker placement issue.Reviewers: Jun Rao <junrao@gmail.com>",0
"MINOR: Log member id of the leader when assignment are received (#10817)Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Register metrics beans at kafka server startup; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-592git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403601 13f79535-47bb-0310-9956-ffa450edef68,2
KAFKA-12297: Make MockProducer return RecordMetadata with values as per contractThis is a simple change to MockProducer as per request in KAFKA-12297.MockProducer currently returns a null RecordMetadata on Exception. The fix will make MockProducer return the right value as per specification.This only impacts clients which use send with a custom callback and try to then use the RecordMetadata inspite of getting an exception. This should mostly impact customer unit and integration tests as the mock end point was never intended for use in a real Kafka cluster.Author: Akhilesh Dubey <adubey@confluent.io>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #10110 from aadubey/trunk,1
KAFKA-9672: Leader with ISR as a superset of replicas (#9631)It is possible for the the controller to send LeaderAndIsr requests withan ISR that contains ids not in the replica set. This is used duringreassignment so that the partition leader doesn't add replicas back tothe ISR. This is needed because the controller updates ZK and thereplicas through two rounds:1. The first round of ZK updates and LeaderAndIsr requests shrinks the ISR.2. The second round of ZK updates and LeaderAndIsr requests shrinks the replicaset.This could be avoided by doing 1. and 2. in one round. Unfortunately thecurrent controller implementation makes that non-trivial.This commit changes the leader to allow the state where the ISR containsids that are not in the replica set and to remove such ids from the ISRif required.Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-2734: kafka-console-consumer should allow empty topic for old consumer.…ot specifying topicAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Sriharsha Chintalapani, Guozhang WangCloses #412 from SinghAsDev/KAFKA-2734",1
"MINOR: Correct usage of ConfigException in file and directory config providersThe two-arg variant is intended to take a property name and value, not an exception message and a cause.As-is, this leads to confusing log messages like:```org.apache.kafka.common.config.ConfigException: Invalid value java.nio.file.NoSuchFileException: /my/missing/secrets.properties for configuration Could not read properties from file /my/missing/secrets.properties```Author: Chris Egerton <chrise@confluent.io>Reviewers: Gwen ShapiraCloses #11555 from C0urante/patch-1",5
Update doc of curried joins and aggregates (#5053)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-2926; [MirrorMaker] InternalRebalancer calls wrong method of external rebalancer…ternal rebalancerAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #611 from gwenshap/KAFKA-2926",5
"MINOR: Change `AlterPartition` validation order in `KafkaController` (#12032)Currently we validate recovery state before checking leader epoch in `KafkaController`. It seems more intuitive to validate leader epoch first since the leader might be working with stale state, which is what we do in KRaft. This patch fixes this and adds a couple additional validations to make the behavior consistent. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
KAFKA-9018: Throw clearer exceptions on serialisation errors (#7496)Improved the exception messages that are thrown to indicate whether it was a key or value conversion problem.Author: Mario Molina <mmolimar@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,0
"KAFKA-5671: Add StreamsBuilder and Deprecate KStreamBuilderAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3602 from mjsax/kafka-5671-add-streamsbuilder",1
"KAFKA-3128; Add metrics for ZooKeeper events zookeeper metricsAlso:* Remove redundant `time.milliseconds` call in `Sensor.record`* Clean-up a number of tests and remove a manual test that is no longer requiredAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Liquan Pei <liquanpei@gmail.com>, Jun Rao <junrao@gmail.com>Closes #1265 from ijuma/kafka-3128-zookeeper-metrics",1
MINOR: Fix a startup NPE in BrokerServer (#10989)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
"MINOR: cleanup RocksDBStore tests  (#8510)One of the new rocksdb unit tests creates a non-temporary rocksdb directory wherever the test is run from, with some rocksdb files left behind after the test(s) are done. We should use the tempDirectory dir for this testingReviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-13919: expose log recovery metrics (#12347)Implementation for KIP-831.1. add remainingLogsToRecover metric for the number of remaining logs for each log.dir to be recovered2.  add remainingSegmentsToRecover metric for the number of remaining segments for the current log assigned to the recovery thread.3. remove these metrics after log loaded completely4. add tests Reviewers: Jun Rao <jun@confluent.io>, Tom Bentley <tbentley@redhat.com>",5
MINOR: Add restoration time tracking (#9830)Add Stream restoration time tracking logReviewers: John Roesler <vvcephei@apache.org>,2
"MINOR:Upgrade guide updates for KIP-479 (#7550)Reviewers: A. Sophie Blee-Goldmann <sophie@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5474: Streams StandbyTask should no checkpoint on commit if EOS is enabled<strike> - actual fix for `StandbyTask#commit()` </strike>Additionally (for debugging): - EOS test, does not report ""expected"" value correctly - add `IntegerDecoder` (to be use with `kafka.tools.DumpLogSegments`) - add test for `StreamTask` to not checkpoint on commit if EOS enabledAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3375 from mjsax/kafka-5474-eos-standby-task",5
"KAFKA-8040: Streams handle initTransactions timeout (#6372)As of 2.0, Producer.initTransactions may throw a TimeoutException, which is retriable. Streams should retry instead of crashing when we encounter this exceptionReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",1
"MINOR: Defer log recovery until LogManager startup (#10039)Currently log recovery begins as soon as we instantiate `LogManager`, but when using aRaft-based metadata quorum we won't have configs until after we catch up on the metadatalog.  We therefore defer log recovery until we actually invoke `startup()` on the `LogManager`instance.  This timing difference has no effect when using ZooKeeper because weimmediately invoke `startup()` on the instantiated instance, but it gives us the necessaryflexibility for accurate log recovery with updated configs when using a Raft-based metadataquorum.The `LogCleaner` is currently instantiated during construction just after log recoverycompletes, and then it is started in `startup()`.  As an extra precaution, since we areno longer performing recovery during construction, we both instantiate and start thelog cleaner in `startup()` after log recovery completes.We also convert `LogManager` to use a `ConfigRepository` to load topic configs(which can override the default log configs) instead of having a hard-codeddependency on ZooKeeper.  We retrieve the topic configs when we invoke `startup()`-- which again is effectively no different from a timing perspective than what we dotoday for the ZooKeeper case.One subtlety is that currently we create the log configs for every topic at this point-- if a topic has no config overrides then we associate a copy of the defaultconfiguration with the topic inside a map, and we retrieve the log configs for thattopic's partitions from from that map during recovery.  This PR makes a change tothis series of events as follows.  We do not associate a copy of the the defaultconfiguration with a topic in the map if the topic has no configs set when we queryfor them.  This saves some memory -- we don't unnecessarily copy the defaultconfig many times -- but it also means we have use the default log configs forthat topic later on when recovery for each of its partitions begins.The difference is that the default configs are dynamically reconfigurable, and theycould potentially change between the time when we invoke `startup()` and whenlog recovery begins (log recovery can begin quite some time after `startup()` isinvoked if shutdown was unclean).  Prior to this patch such a change would notbe used; with this patch they could be if they happen before recovery begins.This actually is better -- we are performing log recovery with the most recentknown defaults when a topic had no overrides at all. Also, `Partition.createLog`has logic to handle missed config updates, so the behavior is eventually the same.The transition of the broker state from `STARTING` to `RECOVERY` currentlyhappens within the `LogManager`, and it only occurs if the shutdown wasunclean.  We move this transition into the broker as it avoids passing areference to the broker state into the `LogManager`.  We also now alwaystransition the broker into the `RECOVERY` state as dictated by [the KIP-631 broker state machine](https://cwiki.apache.org/confluence/display/KAFKA/KIP-631%3A+The+Quorumbased+Kafka+Controller#KIP631:TheQuorumbasedKafkaController-TheBrokerStateMachine).Finally, a few clean-ups were included. One worth highlighting is that `Partition`no longer requires a `ConfigRepository`.Reviewers: David Arthur <david.arthur@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-3824; Clarify autocommit delivery semantics for consumerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1936 from hachikuji/KAFKA-3824",5
"KAFKA-13152: Replace ""buffered.records.per.partition"" with ""input.buffer.max.bytes"" (#11796)Implements KIP-770Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-9093: NullPointerException in KafkaConsumer with group.instance.id (#7590)`log` in KafkaConsumer does not get initialized if an invalid value for group.intance.id is given during consumer construction. In this case we should skip the catch block's close procedure since no internal objects have been initialized yet.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-4144 Follow-up: add one missing overload function to maintain backward compatibilityA follow up RP to fix [issue](https://github.com/confluentinc/examples/commit/2cd0b87bc8a7eab0e7199fa0079db6417f0e6b63#commitcomment-22200864)Author: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Bill Bejeck, Guozhang WangCloses #3109 from jeyhunkarimov/KAFKA-4144-follow-up",4
"KAFKA-6150: KIP-204 part III; Change repartition topic segment size and ms1. Create default internal topic configs in StreamsConfig, especially for repartition topics change the segment size and time to smaller value.2. Consolidate the default internal topic settings to InternalTopicManager and simplify InternalTopicConfig correspondingly.3. Add an integration test for purging data.4. MINOR: change TopologyBuilderException to IllegalStateException in StreamPartitionAssignor (part of https://issues.apache.org/jira/browse/KAFKA-5660).Here are a few public facing APIs that get added:1. AbstractConfig#originalsWithPrefix(String prefix, boolean strip): this for simplify the logic of passing admin and topic prefixed configs to consumer properties.2. KafkaStreams constructor with Time object for convienent mocking in tests.Will update KIP-204 accordingly if people re-votes these changes.Author: Guozhang Wang <wangguoz@gmail.com>Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4315 from guozhangwang/K6150-segment-size",5
KAFKA-1760 Follow-up: fix compilation issue with Scala 2.11,0
KAFKA-385 Fix race condition between checkSatisfied and expire in RequestPurgatory; fixed constant expiration of follower fetch requests as checkSatisfied was not getting called; add metrics to the RequestPurgatory; add a KafkaTimer convenience class; patched by Joel Koshy; reviewed by Jun Rao and Jay Kreps.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374069 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1251: Add metrics to the producer.,1
KAFKA-5404; Add more AdminClient checks to ClientCompatibilityTestAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3263 from cmccabe/KAFKA-5404,5
"KAFKA-7158: Add unit test for window store range queries (#5466)While debugging the reported issue, I found that our current unit test lacks coverage to actually expose the underlying root cause.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-820 Topic metadata request handling fails to return all metadata about replicas; reviewed by Jun Rao,5
MINOR: Update TupleForwarder comment (#4414)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-8729, pt 3: Add broker-side logic to handle the case when there are record_errors and error_message (#7167)All the changes are in ReplicaManager.appendToLocalLog and ReplicaManager.appendRecords. Also, replaced LogAppendInfo.unknownLogAppendInfoWithLogStartOffset with LogAppendInfo.unknownLogAppendInfoWithAdditionalInfo to include those 2 new fields.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Close timing window in SimpleAclAuthorizer startup (#5318)ZooKeeper listener for change notifications should be created before loading the ACL cache to avoid timing window if acls are modified when broker is starting up.Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@confluent.io>",5
"KAFKA-8371: Remove dependence on ReplicaManager from Partition (#6705)This patch attempts to simplify the interaction between Partition and the various components from `ReplicaManager`. This is primarily to make unit testing easier. I have also tried to eliminate the OfflinePartition sentinel which has always been unsafe.Reviewers: Boyang Chen <bchen11@outlook.com>, David Arthur <mumrah@gmail.com>",3
"KAFKA-10022:console-producer supports the setting of client.id (#8698)""console-producer"" supports the setting of ""client.id"", which is a reasonable requirement, and the way ""console consumer"" and ""console producer"" handle ""client.id"" can be unified. ""client.id"" defaults to ""console-producer""Co-authored-by: xinzhuxiansheng <xinzhuxiansheng@autohome.com.cn>Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
"MINOR: Avoid double null check in KStream#transform() (#6429)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Add toString to various Kafka Metrics classes (#10330)This was useful while debugging a JDK 16 test failure, I noticed thesewere missing.Reviewers: David Jacot <david.jacot@gmail.com>",0
MINOR: Avoid duplicate processing of notifications in ZkNodeChangeNotificationListenerAlso fix potential NPE.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3615 from omkreddy/zk-notif-duplicates,0
"KAFKA-9568: enforce rebalance if client endpoint has changed (#8299)Since the assignment info includes a map with all member's host info, we can just check the received map to make sure our endpoint is contained. If not, we need to force the group to rebalance and get our updated endpoint info.Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Tweak IBM i support in ""stop"" scripts (#9810)Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
"MINOR: cleanup deprectaion annotations (#6290)If deprecated interface methods are inherited, the @Deprication tag should be used (instead on suppressing the deprecation warning).Reviewers:  Guozhang Wang <wangguoz@gmail.com>,  John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: update stream docs for kip-134Add a section in the streams docs about the broker config introduced in KIP-134Author: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Bill Bejeck, Guozhang WangCloses #3179 from dguy/kip134-doc",2
KAFKA-4376; Cross compile to Scala 2.12.0Author: Bernard Leach <leachbj@bouncycastle.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2113 from leachbj/2.12.0-trunk-build,1
"KAFKA-10169: swallow non-fatal KafkaException and don't abort transaction during clean close (#8900)If there's any pending data and we haven't flushed the producer when we abort a transaction, a KafkaException is returned for the previous send. This is a bit misleading, since the situation is not an unrecoverable error and so the Kafka Exception is really non-fatal. For now, we should just catch and swallow this in the RecordCollector (see also: KAFKA-10169)The reason we ended up aborting an un-flushed transaction was due to the combination ofa. always aborting the ongoing transaction when any task is closed/revokedb. only committing (and flushing) if at least one of the revoked tasks needs to be committed (regardless of whether any non-revoked tasks have data/transaction in flight)Given the above, we can end up with an ongoing transaction that isn't committed since none of the revoked tasks have any data in the transaction. We then abort the transaction anyway, when those tasks are closed. So in addition to the above (swallowing this exception), we should avoid unnecessarily aborting data for tasks that haven't been revoked.We can handle this by splitting the RecordCollector's close into a dirty and clean flavor: if dirty, we need to abort the transaction since it may be dirty due to the commit attempt failing. But if clean, we can skip aborting the transaction since we know that either we just committed and thus there is no ongoing transaction to abort, or else the transaction in flight contains no data from the tasks being closedNote that this means we still abort the transaction any time a task is closed dirty, so we must close/reinitialize any active task with pending data (that was aborted).In sum:* hackily check the KafkaException message and swallow* only abort the transaction during a dirty close* refactor shutdown to make sure we don't closeClean a task whose data was actually abortedReviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4223; RocksDBStore should close all open iterators on closeKeep track of open Rocks DB iterators. When a store is closed, close all open iterators.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1917 from dguy/kafka-4223",5
KAFKA-2649: Add support for custom partitioning in topology sinksAdded option to use custom partitioning logic within each topology sink.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Guozhang WangCloses #309 from rhauch/kafka-2649,2
"KAFKA-10870; Handle REBALANCE_IN_PROGRESS error in JoinGroup (#9792)Handle REBALANCE_IN_PROGRESS error in JoinGroup, which is possible if there is a replication timeout while persisting the group state after the rebalance completes.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2741: Make SourceTaskContext and SinkTaskContext interfaces and keep implementations in runtime jar.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #420 from ewencp/task-context-interfaces,1
"KAFKA-13051; Require principal builders implement `KafkaPrincipalSerde` and set default (#11011)This patch adds a check to ensure that principal builder implementations implement `KafkaPrincipalSerde` as specified in KIP-590: https://cwiki.apache.org/confluence/display/KAFKA/KIP-590%3A+Redirect+Zookeeper+Mutation+Protocols+to+The+Controller. This patch also changes the default value of `principal.builder.class` to `DefaultKafkaPrincipalBuilder`, which was already the implicit behavior when no principal builder was specified.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: remove unnecessary #remove overrides (#7178)Iterator#remove has a default implementation that throws UnsupportedOperatorException so there's no need to override it with the same thing.Should be cherry-picked back to whenever we switched to Java 8Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Fix comment in quick union (#5244)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-12932: Interfaces for SnapshotReader and SnapshotWriter (#11529)Change the snapshot API so that SnapshotWriter and SnapshotReader are interfaces. Change the existing types SnapshotWriter and SnapshotReader to use a different name and to implement the interfaces introduced by this commit.Co-authored-by: loboxu <loboxu@tencent.com>Reviews: José Armando García Sancio <jsancio@users.noreply.github.com>,1
"MINOR: Add topic config to PartitionsSpec (#5523)Reviewers: Bob Barrett <bob.barrett@outlook.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-9023: Log request destination when the Producer gets disconnected (#7498)Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Jacot <djacot@confluent.io>",5
[9/N][Emit final] Emit final for session window aggregations (#12204)* Add a new API for session windows to range query session window by end time (KIP related).* Augment session window aggregator with emit strategy.* Minor: consolidated some dup classes.* Test: unit test on session window aggregator.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-7006 - remove duplicate Scala ResourceNameType in preference to… (#5152)remove duplicate Scala ResourceNameType in preference to in preference to Java ResourceNameType.This is follow on work for KIP-290 and PR #5117, which saw the Scala ResourceNameType class introduced.I've added tests to ensure AclBindings can't be created with ResourceNameType.ANY or UNKNOWN.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",1
"KAFKA-9203: Revert ""MINOR: Remove workarounds for lz4-java bug affecting byte buffers (#6679)"" (#7769)This reverts commit 90043d5f as it caused a regression in some cases:> Caused by: java.io.IOException: Stream frame descriptor corrupted>         at org.apache.kafka.common.record.KafkaLZ4BlockInputStream.readHeader(KafkaLZ4BlockInputStream.java:132)>         at org.apache.kafka.common.record.KafkaLZ4BlockInputStream.<init>(KafkaLZ4BlockInputStream.java:78)>         at org.apache.kafka.common.record.CompressionType$4.wrapForInput(CompressionType.java:110)I will investigate why after, but I want to get the safe fix into 2.4.0.The reporter of KAFKA-9203 has verified that reverting this changemakes the problem go away.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",0
"KAFKA-4627; Fix timing issue in consumer close testsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2367 from rajinisivaram/KAFKA-4627",5
"KAFKA-3702: Change log level of SSL close_notify failure (#5397)SslTransportLayer currently closes the SSL engine and logs a warning if close_notify message canot be sent because the remote end closed its connection. This tends to fill up broker logs, especially when using clients which close connections immediately. Since this log entry is not very useful anyway, it would be better to log at debug level.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Fix SslEngineFactory javadoc (#9055)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
kafka-2169; Upgrade to zkclient-0.5; patched by Parth Brahmbhatt; reviewed by Jun Rao,5
KAFKA-1764; ZookeeperConsumerConnector should not put multiple shutdown commands to the same data chunk queue; reviewed by Joel Koshy and Guozhang Wang,5
KAFKA-9334: Added more unit tests for Materialized class (#7871)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Use GitHub git repo for push by default (#4352),1
"KAFKA-8122: Fix Kafka Streams EOS integration test (#7470)Reviewers: Guozhang Wang <guozhang@confluent.io>, Chris Pettitt <cpettitt@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-6607: Commit correct offsets for transactional input data (#8091)Reviewers: Guozhang Wang <guozhang@confluent.io>,5
"MINOR: Fix typos in security section1. I think the instructions in step 2 of the security section which describe adding the CA to server/client truststores are swapped. That is, the instruction that says to add the CA to the server truststore adds it to the client truststore (and vice versa).2. ""clients keys"" should be possessive (""clients' keys"").This contribution is my original work, and I license the work to the project under the project's open source license.Author: Samuel Taylor <staylor@square-root.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1651 from ssaamm/trunk",1
"KAFKA-3512: Added foreach operatormiguno guozhangwang please have a look if you can.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #1193 from enothereska/kafka-3512-ForEach",5
"KAFKA-8421: Still return data during rebalance (#7312)Not wait until updateAssignmentMetadataIfNeeded returns true, but only call it once with 0 timeout. Also do not return empty if in rebalance.Trim the pre-fetched records after long polling since assignment may have been changed.Also need to update SubscriptionState to retain the state in assignFromSubscribed if it already exists (similar to assignFromUser), so that we do not need the transition of INITIALIZING to FETCHING.Unit test: this actually took me the most time :)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>, Jason Gustafson <jason@confluent.io>, Richard Yu <yohan.richard.yu@gmail.com>, dengziming <dengziming1993@gmail.com>",5
"KAFKA-6813: Remove deprecated APIs in KIP-182, Part II (#4976)1. Remove the deprecated StateStoreSuppliers, and the corresponding Stores.create() functions and factories: only the base StateStoreSupplier and MockStoreSupplier were still preserved as they are needed by the deprecated TopologyBuilder and KStreamBuilder. Will remove them in a follow-up PR.2. Add TopologyWrapper.java as the original InternalTopologyBuilderAccessor was removed, but I realized it is still needed as of now.3. Minor: removed StateStoreTestUtils.java and inline its logic in its callers since now with StoreBuilder it is just a one-liner.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Update dependencies for Kafka 2.7 (part 1) (#9082)I left out updates that could be risky. Preliminary testing indicateswe can build (including spotBugs) and run tests with Java 15 withthese changes. I will do more thorough testing once Java 15 reachesrelease candidate stage in a few weeks.Minor updates with mostly bug fixes:- Scala: 2.12.11 -> 2.12.12 (compiler and collection performance improvements)- Bouncy castle: 1.64 -> 1.66 (several bug fixes)- HttpClient: 4.5.11 -> 4.5.12 (small number of bug fixes)- Mockito: 3.3.3 -> 3.4.4 (several bug fixes and Java 15 support)- Netty: 4.5.10 -> 4.5.11 (several bug fixes)- Snappy: 1.1.7.3 -> 1.1.7.6 (small number of bug fixes)- Zstd: 1.4.5-2 -> 1.4.5-6 (small number of bug fixes)Gradle plugin and library upgrades:- Gradle version plugins: 0.28.0 -> 0.29.0 (small number of bug fixes)- Git: 4.0.1 -> 4.0.2 (small number of bug fixes)- Scoverage plugin: 4.0.1 -> 4.0.2 (small number of bug fixes)- Shadow plugin: 5.2.0 -> 6.0.0 (Java 15 support and require Gradle 6.0)- Test Retry plugin: 1.1.5 -> 1.1.6 (small number of bug fixes)- Spotless plugin: 4.4.4 -> 5.1.0 (several internal changes that should not matter to us)- Spotbugs: 4.0.3 -> 4.0.6 (small number of bug fixes)- Spotbugs plugin: 4.2.4 -> 4.4.4 (small number of bug fixes)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"KAFKA-10191 fix flaky StreamsOptimizedTest (#8913)Call KafkaStreams#cleanUp to reset local state before starting application up the second run.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
HOTFIX: Introduce max wait time for retry-and-backoff while creating tasksAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3327 from mjsax/hotfix-backoff-retry,0
"MINOR: Update Kafka Streams upgrade docs for KIP-444, KIP-470, KIP-471, KIP-474, KIP-528 (#7515)Reviewers: Jukka Karvanen <jukka.karvanen@jukinimi.com>, Guozhang Wang <guozhang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-5534; KafkaConsumer `offsetForTimes` result should include partitions with no offsetFor topics that support timestamp search, if no offset is found for a partition, the partition should still be included in the result with a `null` offset value. This `KafkaConsumer` method currently excludes such partitions from the result.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3460 from vahidhashemian/KAFKA-5534",5
"KAFKA-12660; Do not update offset commit sensor after append failure (#10560)Do not update the commit-sensor if the commit failed and add test logic. The patch also adds 2 unit tests, the first for `OFFSET_METADATA_TOO_LARGE` error, the second is to cover circumstance when one offset is committed and the other is failed with `OFFSET_METADATA_TOO_LARGE`. Both of these cases were uncovered previously.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-2055; Fix transient ConsumerBounceTest.testSeekAndCommitWithBrokerFailure failure.…kerFailures failure;Author: lvfangmin <lvfangmin@gmail.com>Reviewers: GuozhangCloses #98 from lvfangmin/KAFKA-2055 and squashes the following commits:057a1f1 [lvfangmin] KAFKA-2055; Fix transient ConsumerBounceTest.testSeekAndCommitWithBrokerFailures failure;,0
"MINOR: Fix streams Scala foreach recursive call (#5539)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
HOTFIX: Close transactional producers in all new testsAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3093 from apurvam/HOTFIX-close-leaked-producers-in-transactions-test,3
MINOR: Remove logic conditional on exception messages from LogValidator (#7744)Such logic is very brittle. Take the chance to simplify the code a bit.Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"MINOR: increase number of unique keys for Streams EOS system test (#5640)Increasing the number of unique keys, to increase likelihood that the test exposes KAFKA-7192.Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-6145: KIP 441 remove balance factor (#8597)Reviewers: John Roesler <vvcephei@apache.org>,4
"KAFKA-6859; Do not send LeaderEpochRequest for undefined leader epochs (#5320)If a broker or topic has a message format < 0.11, it does not track leader epochs. LeaderEpochRequests for such will always return undefined, making the follower truncate to the highe watermark. Since there is no use to use the network for such cases, don't send a request.Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3070: SASL unit tests dont work with IBM JDKUse IBM Kerberos module for SASL tests if running on IBM JDKDeveloped with edoardocomarBased on https://github.com/apache/kafka/pull/738 by rajinisivaramAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Edoardo Comar <ecomar@uk.ibm.com>Closes #2878 from mimaison/KAFKA-3070",5
"MINOR: Remove connection id from Send and consolidate request/message utils (#9714)Connection id is now only present in `NetworkSend`, which is nowthe class used by `Selector`/`NetworkClient`/`KafkaChannel` (whichworks well since `NetworkReceive` is the class used forreceived data).The previous `NetworkSend` was also responsible for adding a sizeprefix. This logic is already present in `SendBuilder`, but for theminority of cases where `SendBuilder` is not used (includinga number of tests), we now have `ByteBufferSend.sizePrefixed()`.With regards to the request/message utilities:* Renamed `toByteBuffer`/`toBytes` in `MessageUtil` to`toVersionPrefixedByteBuffer`/`toVersionPrefixedBytes` for clarity.* Introduced new `MessageUtil.toByteBuffer` that does not includethe version as the prefix.* Renamed `serializeBody` in `AbstractRequest/Response` to`serialize` for symmetry with `parse`.* Introduced `RequestTestUtils` and moved relevant methods from`TestUtils`.* Moved `serializeWithHeader` methods that were only used intests to `RequestTestUtils`.* Deleted `MessageTestUtil`.Finally, a couple of changes to simplify coding patterns:* Added `flip()` and `buffer()` to `ByteBufferAccessor`.* Added `MessageSizeAccumulator.sizeExcludingZeroCopy`.* Used lambdas instead of `TestCondition`.* Used `Arrays.copyOf` instead of `System.arraycopy` in `MessageUtil`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Ensure producer state append exceptions areuseful (#6591)We should include partition/offset information when we raise exceptions during producer state validation. This saves a lot of the discovery work to figure out where the problem occurred. This patch also includes a new test case to verify additional coordinator fencing cases.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR: Fix homophone typo in Design documentationNoticed that there was a small typo in section 4.1 of the Design documentation on the [website](https://kafka.apache.org/documentation.html#majordesignelements) ('new' vs. 'knew'). This patch corrects that.Author: Chris Pinola <chris@pinola.co>Reviewers: Guozhang WangCloses #391 from chrnola/minor/design-doc-typo,2
HOTFIX: fix streams tutorial code example,0
"MINOR: Move ProtoUtils methods to ApiKeysAlso move `requireTimestamp` to `minVersion` logic from `Fetcher` to`ListOffsetRequest.Builder.forConsumer()`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2580 from ijuma/move-proto-utils-to-api-keys",4
"KAFKA-3100; Broker.createBroker should work if json is version > 2 and still compatibleAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com>Closes #773 from ijuma/kafka-3100-create-broker-version-check",1
"MINOR: Typo fix in commentsAuthor: Nafer Sanabria <nafr.snabr@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1595 from naferx/minor-typo",2
MINOR: regression test for task assignor config (#8743)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
"KAFKA-13200: Fix MirrorMaker2 connector version (#11212)Use the Kafka version instead of hardcoding it to 1.Reviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>",1
KAFKA-5362: Add Streams EOS system test with repartitioning topicAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3310 from mjsax/kafka-5362-add-eos-system-tests-for-streams-api,5
"KAFKA-3623: KStreamTestDriver extends ExternalResourceIn the streams project, there are a number of unit tests that has duplicatecode with respect to the tearDown() method, in which it tries to close theKStreamTestDriver connection. The goal of this changeset is to eliminatethis duplication by converting the KStreamTestDriver class to an ExternalResourceclass which is the base class of JUnit Rule.In every unit tests that calls KStreamTestDriver, we annotate the KStreamTestDriverusing Rule annotation. In the KStreamTestDriver class, we override the after()method. This after() method in turn calls the close() method which was previouslycalled in the tearDown() method in the unit tests. By annotating the KStreamTestDriveras a Rule, the after() method will be called automatically after every testcase.Author: johnma14 <mariamj@us.ibm.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3589 from johnma14/bug/KAFKA-3623",0
kafka-1711; WARN Property topic is not valid when running console producer; patched by Joe Crobak; reviewed by Jun Rao,1
"KAFKA-12571: Eliminate LeaderEpochFileCache constructor dependency on logEndOffset (#10426)This PR is a precursor to the recovery logic refactor work (KAFKA-12553).Problems:For refactoring the recovery logic (KAFKA-12553), we would like to move the logic to initialize LeaderEpochFileCache out of the Log class and into a separate static function. In the future, once we successfully initialize LeaderEpochFileCache outside Log, we will be able pass it as a dependency into both the Log recovery module and Log class constructor. However, currently the LeaderEpochFileCache constructor takes a dependency on logEndOffset (via a callback), which poses the following problems:Blocks the instantiation of LeaderEpochFileCache outside Log class. Because, outside Log the logEndOffset is unavailable to be passed into LeaderEpochFileCache constructor. As a result, this situation blocks the recovery logic (KAFKA-12553) refactor work.It turns out the logEndOffset dependency is used only in 1 of the LeaderEpochFileCache methods: LeaderEpochFileCache.endOffsetFor, and just for 1 particular case. Therefore, it is overkill to pass it in the constructor as a dependency. Also a callback is generally not a neat way to access dependencies and it poses code readability problems too.Solution:This PR modifies the code such that we only pass the logEndOffset as a parameter into LeaderEpochFileCache.endOffsetFor whenever the method is called, thus eliminating the constructor dependency. This will also unblock the recovery logic refactor work (KAFKA-12553).Tests:I have modified the existing tests to suit the above refactor.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-5164: Ensure SetSchemaMetadata updates key or value when Schema changesWhen the `SetSchemaMetadata` SMT is used to change the name and/or version of the key or value’s schema, any references to the old schema in the key or value must be changed to reference the new schema. Only keys or values that are `Struct` have such references, and so currently only these are adjusted.This is based on `trunk` since the fix is expected to be targeted to the 0.11.1 release.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3198 from rhauch/kafka-5164",5
"KAFKA-8179: Part 4, add CooperativeStickyAssignor (#7130)Splits the existing StickyAssignor logic into an AbstractStickyAssignor class, which is extended by the existing (eager) StickyAssignor and by the new CooperativeStickyAssignor which supports incremental cooperative rebalancing.There is no actual change to the logic -- most methods from StickyAssignor were moved to AbstractStickyAssignor to be shared with CooperativeStickyAssignor, and the abstract MemberData memberData(Subscription) method converts the Subscription to the embedded list of owned partitions for each assignor.The ""generation"" logic is left in, however this is always Optional.empty() for the CooperativeStickyAssignor as onPartitionsLost should always be called when a generation is missed.Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
HOTFIX: Fix NPE in StreamTask#shouldCheckpointState (#12341)The mocks were not setup correctly in StreamTask#shouldCheckpointStatewhich caused a null pointer exception during test execution.,3
MINOR: Add note about which files need to be edited when updating the version numberAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael JumaCloses #879 from ewencp/version-bump-instructions,5
"kafka-1690; Add SSL support to Kafka Broker, Producer and Consumer; patched by Sriharsha Chintalapani; reviewed Rajini Sivaram, Joel Koshy, Michael Herstine, Ismael Juma, Dong Lin, Jiangjie Qin and Jun Rao",5
kafka-1558; AdminUtils.deleteTopic does not work; patched by Sriharsha Chintalapani; reviewed by Jun Rao,1
"Minor: Fixed ConsumerOffset#path (#5060)consumer offset path in zookeeper should be /consumers/${group}/offsets/${topic}/${partition} instead of /consumers/${group}/offset/${topic}/${partition}. Added `s` to the word `offset`.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>",1
MINOR: add upgrade text (#7013)Reviewers: David Arthur <mumrah@gmail.com>,1
"KAFKA-4298; Ensure compressed message sets are not converted when log cleaningAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2019 from hachikuji/KAFKA-4298",5
"KAFKA-6313; Add SLF4J as direct dependency to Kafka coreRecent changes are now directly using the SLF4J API, so we should have a direct dependency.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4296 from rhauch/kafka-6313",1
HOTFIX: do not depend on file modified time in StateDirectoryTest,3
KAFKA-5052; Don't pass underlying internal exception to RetriableCommitFailedExceptionAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2838 from apurvam/KAFKA-5052-dont-send-uderlying-exception-to-retriableoffsetcommitfailed,0
KAFKA-1725 Configuration file bugs in system tests add noise to output and break a few tests; reviewed by Neha Narkhede,3
"KAFKA-8346; Improve replica fetcher behavior for handling partition failure [KIP-461] (#6716)The replica fetcher thread is terminated in case a partition crashes which leads to under replication. This behavior can be improved by dropping the failed partition. The thread can continue monitoring the rest of the partitions. If all partitions of a thread have failed, the thread would be shut down. This is documented in KIP-461: https://cwiki.apache.org/confluence/display/KAFKA/KIP-461+-+Improve+Replica+Fetcher+behavior+at+handling+partition+failure.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"Revert ""KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson, Ismael Juma, Joel Koshy, Jun Rao, and Edward Ribeiro""This reverts commit da39931afad8008bc2b385a75a462777be051435.",4
KAFKA-9969: Exclude ConnectorClientConfigRequest from class loading isolation (#8630)This fix excludes `ConnectorClientConfigRequest` and its inner class from class loading isolation in a similar way that KAFKA-8415 excluded `ConnectorClientConfigOverridePolicy`.Reviewer: Konstantine Karantasis <konstantine@confluent.io>,5
"KAFKA-12464: enhance constrained sticky Assign algorithm (#10509)1. Make code simpler and cleaner2. After the PR: the testLargeAssignmentAndGroupWithUniformSubscription (1 million partitions) will run from ~2600 ms down to ~1400 ms, improves 46% of performance, almost 2x faster!!Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: updated names for deprecated streams constants (#6466)* updated names for deprecated streams constants* add DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG in place of deprecatedReviewers: Jim Galasyn <jim.galasyn@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-10271: Performance regression while fetching a key from a single partition (#9020)StreamThreadStateStoreProvider excessive loop over calling internalTopologyBuilder.topicGroups(), which is synchronized, thus causing significant performance degradation to the caller, especially when store has many partitions.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-1052; integrate add-partitions command into topicCommand; patched by Sriram Subramanian; reviewed by Jun Rao,1
"MINOR: state.cleanup.delay.ms default is 600,000 ms (10 minutes). (#6345)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Remove o.a.kafka.common.utils.Base64 and IS_JAVA8_COMPATIBLEWe no longer need them since we now require Java 8.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Andras Beni <andrasbeni@cloudera.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5049 from ijuma/remove-base64",4
KAFKA-739 Handle null message payloads in messages and in the log cleaner. Reviewed by Jun and Neha.,4
"MINOR: kafka-site introduction section improvements*Clarify multi-tenant support, geo-replication, and some grammar fixes.*Author: Joel Hamill <joel-hamill@users.noreply.github.com>Reviewers: GUozhang WangCloses #4212 from joel-hamill/intro-cleanup",4
Fix wildcard consumption to work with greater than one stream; KAFKA-550; patched by Joel Koshy; reviewed by Jun Rao and Neha Narkhede.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396425 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7091; AdminClient should handle FindCoordinatorResponse errors (#5278)- Update KafkaAdminClient implementation to handle FindCoordinatorResponse errors- Remove scala AdminClient usage from core and streams testsReviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>",5
Trivial commit: Fix whitespace in Utils.rm.,0
"MINOR: fix bypasses in ChangeLogging stores (#6266)The change-logging stores should not bypass methods in underlying stores.If some of you have a minute, can you take a quick look at this? I happened to notice during some other refactoring that the change-logging store layer sometimes bypasses the underlying store and instead calls across to a different layer.It seems unexpected that it should do so, and it might actually cause problems. There was one spot where it's impossible to avoid it (in the windowed store), but I added a note justifying why we bypass the underlying store.Thanks,-John* MINOR: fix bypasses in ChangeLogging stores* fix testReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",3
KAFKA-4070: implement Connect Struct.toString()Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Gwen ShapiraCloses #1790 from shikhar/add-struct-tostring,1
"MINOR: remove unused Properties from GraphNode#writeToTopology (#11263)The GraphNode#writeToTopology method accepts a Properties input parameter, but never uses it in any of its implementations. We can remove this parameter to clean things up and help make it clear that writing nodes to the topology doesn't involve the app properties.Reviewers: Bruno Cadonna <cadonna@confluent.io>",5
"MINOR: remove unneccessary public keyword from ProducerInterceptor/ConsumerInterceptor interface (#10801)Co-authored-by: “KahnCheny” <“kahn.cheny@gmail.com”>Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-3612: Added structure for integration testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Damian Guy, Michael G. Noll, Guozhang WangCloses #1260 from enothereska/KAFKA-3612-integration-tests",3
"KAFKA-9809: Shrink transaction timeout for streams (#8407)As documented in the KIP:We shall set `transaction.timout.ms` default to 10000 ms (10 seconds) on Kafka Streams. Reviewer: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2877: handle request timeout in sync groupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ben Stopford, Guozhang WangCloses #582 from hachikuji/KAFKA-2877",5
"KAFKA-9131: Remove dead code for handling timeout exception (#7635)Remove in catch clause and move it to the callback.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Use toString in Records implementations only for summary metadata (#7290)This patch fixes a couple problems with logging of request/response objects which include records data. First, it adds a missing `toString` to `LazyDownConversionRecords`. Second, it changes the `toString` of `MemoryRecords` to not print record-level information. This was always a dangerous practice, but it was especially bad when these objects ended up in request logs. With this patch, implementations use `toString` only to print summary details.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-10664: Delete existing checkpoint when writing empty offsets (#9534)Delete the existing checkpoint file if told to write empty offsets map to ensure that corrupted offsets are not re-initialized fromReviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@apache.org>",5
"KAFKA-9305: Add version 2.4 to Streams system tests (#7841)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Clarify how to publish specific projects to the local repo (#11938)The current README instruction for local publishing boils the ocean by building and installing every jar in the project with both 2.12 and 2.13. While that is some times what people want to do, they are also often trying to just build a specific jar.Reviewers: Bill Bejeck <bbejeck@apache.org>",1
"KAFKA-2390; followup; add unit test for OffsetOutOfRange exceptionAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jason Gustafson, Guozhang WangCloses #239 from lindong28/KAFKA-2390-followup",1
MINOR: Fix deprecation version for NotLeaderForPartitionException (#9056)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"MINOR: Refactor code for restoring tasks (#5768)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-13873 Add ability to Pause / Resume KafkaStreams Topologies (#12161)This PR adds the ability to pause and resume KafkaStreams instances as well as named/modular topologies (KIP-834).Co-authored-by: Bruno Cadonna <cadonna@apache.org>Reviewers: Bonnie Varghese <bvarghese@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@apache.org>, Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Enable scala/java joint compilation consistently for `core` module (#10485)We were doing it only for test files previously.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jose Sancio <jsancio@gmail.com>",2
time-based reconnect in producer; patched by Yang Ye; reviewed by Jun Rao; KAFKA-268git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1243786 13f79535-47bb-0310-9956-ffa450edef68,1
"HOTFIX: turn off auto topic creation in embedded kafka clusterTurning off auto topic creation in the EmbeddedKafkaCluster used by Streams as it can cause race conditions that lead to build hangs.Fixed the couple of tests that needed to have some topics manually createdAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1941 from dguy/disable-auto-topic-create",1
"KAFKA-12367; Ensure partition epoch is propagated to `Partition` state (#10200)This patch fixes two problem with the AlterIsr handling of the quorum controller:- Ensure that partition epoch is updated correctly after partition change records and ispropagated to Partition- Ensure that AlterIsr response includes partitions that were successfully updatedAs part of this patch, I've renamed BrokersToIsrs.TopicPartition toBrokersToIsrs.TopicIdPartition to avoid confusion with the TopicPartition object which isused virtually everywhere. I've attempted to address some of the testing gaps as welll.Reviewers: Colin P. McCabe <cmccabe@apache.org>",3
"KAFKA-10764: Add support for returning topic IDs on create, supplying topic IDs for delete (#9684)Updated CreateTopicResponse, DeleteTopicsRequest/Response and added some new AdminClient methods and classes. Now the newly created topic ID will be returned in CreateTopicsResult and found in TopicAndMetadataConfig, and topics can be deleted by supplying topic IDs through deleteTopicsWithIds which will return DeleteTopicsWithIdsResult.Reviewers: dengziming <dengziming1993@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Check store directory empty to decide whether throw task corrupted exception with EOS (#8180)Before we register the stores (and hence create the store dirs), we check if the task dir is empty except the lock / checkpoint files. Then later when loading the checkpoint files if we do not find the offsets AND the store dirs are not empty, meaning that the stores may be not empty, we treat it as task corrupted.Reviewers: John Roesler <vvcephei@apache.org>",1
"MINOR: Support using the ZK authorizer with KRaft (#10550)This patch adds support for running the ZooKeeper-basedkafka.security.authorizer.AclAuthorizer with KRaft clusters. Set theauthorizer.class.name config as well as the zookeeper.connect config while alsosetting the typical KRaft configs (node.id, process.roles, etc.), and thecluster will use KRaft for metadata and ZooKeeper for ACL storage. A systemtest that exercises the authorizer is included.This patch also changes ""Raft"" to ""KRaft"" in several system test files. It alsofixes a bug where system test admin clients were unable to connect to a clusterwith broker credentials via the SSL security protocol when the broker was usingthat for inter-broker communication and SASL for client communication.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-5783; Add KafkaPrincipalBuilder with support for SASL (KIP-189)Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #3795 from hachikuji/KAFKA-5783",5
KAFKA-1519 Make it possible to disable the line seperator in the console consumer. Patch from Gwen Shapira.,1
"KAFKA-13229: add total blocked time metric to streams (KIP-761) (#11149)* Add the following producer metrics:flush-time-total: cumulative sum of time elapsed during in flush.txn-init-time-total: cumulative sum of time elapsed during in initTransactions.txn-begin-time-total: cumulative sum of time elapsed during in beginTransaction.txn-send-offsets-time-total: cumulative sum of time elapsed during in sendOffsetsToTransaction.txn-commit-time-total: cumulative sum of time elapsed during in commitTransaction.txn-abort-time-total: cumulative sum of time elapsed during in abortTransaction.* Add the following consumer metrics:commited-time-total: cumulative sum of time elapsed during in committed.commit-sync-time-total: cumulative sum of time elapsed during in commitSync.* Add a total-blocked-time metric to streams that is the sum of:consumer’s io-waittime-totalconsumer’s iotime-totalconsumer’s committed-time-totalconsumer’s commit-sync-time-totalrestore consumer’s io-waittime-totalrestore consumer’s iotime-totaladmin client’s io-waittime-totaladmin client’s iotime-totalproducer’s bufferpool-wait-time-totalproducer's flush-time-totalproducer's txn-init-time-totalproducer's txn-begin-time-totalproducer's txn-send-offsets-time-totalproducer's txn-commit-time-totalproducer's txn-abort-time-totalReviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-1782: fix JUnit3 MisuseAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #135 from ewencp/kafka-1782-junit3-misusage and squashes the following commits:0ae6258 [Ewen Cheslack-Postava] KAFKA-1782: Junit3 Misusage",3
"HOTFIX: Fixes to metric names of StreamsA couple of fixes to metric names to match the KIP- Removed extra strings in the metric names that are already in the tags- add a separate metric for ""all""Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3491 from enothereska/hotfix-metric-names",0
KAFKA-544 Trivial fix--migration tool is using message when it should be using a byte array. Checked in w/o review.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410588 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Update README to specify Gradle 4.6 as the minimum required version (#5606)#5602 uses `annotationProcessor`, which was introduced in Gradle 4.6.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-7210: Add system test to verify log compaction (#5226)* Updated TestLogCleaning tool to use Java consumer and rename as LogCompactionTester.* Enabled the log cleaner in every system test.* Removed configs from ""kafka.properties"" with default values and `socket.receive.buffer.bytes`as the override did not seem necessary.* Updated `kafka.py` logic to handle duplicates between `kafka.properties` and `server_prop_overrides`.* Updated Gradle build so that classes from `kafka-clients` test jar can be used insystem tests.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-2722; Improve ISR change propagation.The patch has two changes:1. fixed a bug in controller that it sends UpdateMetadataRequest of all the partitions in the cluster.2. Uses the following rules to propagate ISR change: 1) if there are ISR changes pending propagation and the last ISR change is more than five seconds ago, propagate the changes. 2) if there is ISR change at T in the recent five seconds, delay the propagation until T + 5s. 3) if the last propagation is more than 1 min ago, ignore rule No.2 and propagate ISR change if there are changes pending propagation.This algorithm avoids a fixed configuration of ISR propagation interval as we discussed about in KIP-29.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #402 from becketqin/KAFKA-2722",5
"MINOR: Update stream documentation (#8622)fix broken linksrephrase a sentenceupdate the version numberReviewers: Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@apache.org>",5
"KAFKA-6170; KIP-220 Part 2: Break dependency of Assignor on StreamThreadThis refactoring is discussed in https://github.com/apache/kafka/pull/3624#discussion_r132614639. More specifically:1. Moved the access of `StreamThread` in `StreamPartitionAssignor` to `TaskManager`, removed any fields stored in `StreamThread` such as `processId` and `clientId` that are only to be used in `StreamPartitionAssignor`, and pass them to `TaskManager` if necessary.2. Moved any in-memory states, `metadataWithInternalTopics`, `partitionsByHostState`, `standbyTasks`, `activeTasks` to `TaskManager` so that `StreamPartitionAssignor` becomes a stateless thin layer that access TaskManager directly.3. Remove the reference of `StreamPartitionAssignor` in `StreamThread`, instead consolidate all related functionalities such as `cachedTasksIds ` in `TaskManager` which could be retrieved by the `StreamThread` and the `StreamPartitionAssignor` directly.4. Finally, removed the two interfaces used for `StreamThread` and `StreamPartitionAssignor`.5. Some minor fixes on logPrefixes, etc.Future work: when replacing the StreamsKafkaClient, we would let `StreamPartitionAssignor` to retrieve it from `TaskManager` directly, and also its closing call do not need to be called (`KafkaStreams` will be responsible for closing it).Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #4224 from guozhangwang/K6170-refactor-assignor",4
"KAFKA-5095: Adjust accepted overhead for ThreadCacheTestAuthor: Eno Thereska <eno@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2877 from enothereska/KAFKA-5095-cacheOverheads",5
MINOR: Some html fixes in Streams DSL documentation (#8503)* Minor: Some html fixes Streams DSL documentation: - duplicate id - duplicate opening <span> element - surplus closing </div> tag* Replaced opening/closing quotation mark codes with &quot; (they caused w3c validation to complain).* Replaced right arrow that wasn't rendered correctly with &rarr;Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
kafka-1797; (addressing Manikumar Reddy's comment) add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Manikumar Reddy and Neha Narkhede,1
"KAFKA-8813: Refresh log config if it's updated before initialization (#7305)A partition log in initialized in following steps:1. Fetch log config from ZK2. Call LogManager.getOrCreateLog which creates the Log object, then3. Registers the Log objectStep #3 enables Configuration update thread to deliver configurationupdates to the log. But if any update arrives between step #1 and #3then that update is missed. It breaks following use case:1. Create a topic with default configuration, and immediately after that2. Update the configuration of topicThere is a race condition here and in random cases update made insecond step will get dropped.This change fixes it by tracking updates arriving between step #1 and #3Once a Partition is done initializing log, it checks if it has missed anyupdate. If yes, then the configuration is read from ZK again.Added unit tests to make sure a dirty configuration is refreshed. Testedon local cluster to make sure that topic configuration and updates arehandled correctly.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-9924: Prepare RocksDB and metrics for RocksDB properties recording (#9098)Refactor the RocksDB store and the metrics infrastructure in Streamsin preparation of the recordings of the RocksDB properties specified in KIP-607.The refactoring includes:* wrapper around BlockedBasedTableConfig to make the cache accessible to the  RocksDB metrics recorder* RocksDB metrics recorder now takes also the DB instance and the cache in addition  to the statistics* The value providers for the metrics are added to the RockDB metrics recorder also if  the recording level is INFO.* The creation of the RocksDB metrics recording trigger is moved to StreamsMetricsImplReviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",4
"KAFKA-2652: integrate new group protocol into partition groupingguozhangwang* added ```PartitionGrouper``` (abstract class) * This class is responsible for grouping partitions. Each group forms a task. * Users may implement this class for custom grouping.* added ```DefaultPartitionGrouper``` * our default implementation of ```PartitionGrouper```* added ```KafkaStreamingPartitionAssignor``` * We always use this as ```PartitionAssignor``` of stream consumers. * Actual grouping is delegated to ```PartitionGrouper```.* ```TopologyBuilder``` * added ```topicGroups()```   * This returns groups of related topics according to the topology * added ```copartitionSources(sourceNodes...)```   * This is used by DSL layer. It asserts the specified source nodes must be copartitioned. * added ```copartitionGroups()```   * This returns groups of copartitioned topics* KStream layer * keep track of source nodes to determine copartition sources when steams are joined * source nodes are set to null when partitioning property is not preserved (ex. ```map()```, ```transform()```), and this indicates the stream is no longer joinableAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #353 from ymatsuda/grouping",5
KAFKA-245 Pull zkclient jar from Maven; patched by pyritschard; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1229794 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10818: Skip conversion to `Struct` when serializing generated requests/responses (#7409)Generated request/response classes have code to serialize/deserialize directly to`ByteBuffer` so the intermediate conversion to `Struct` can be skipped for them.We have recently completed the transition to generated request/response classes,so we can also remove the `Struct` based fallbacks.Additional noteworthy changes:* `AbstractRequest.parseRequest` has a more efficient computation of request size thatrelies on the received buffer instead of the parsed `Struct`.* Use `SendBuilder` for `AbstractRequest/Response` `toSend`, made the superclassimplementation final and removed the overrides that are no longer necessary.* Removed request/response constructors that assume latest version as they are unsafeoutside of tests.* Removed redundant version fields in requests/responses.* Removed unnecessary work in `OffsetFetchResponse`'s constructor when version >= 2.* Made `AbstractResponse.throttleTimeMs()` abstract.* Using `toSend` in `SaslClientAuthenticator` instead of `serialize`.* Various changes in Request/Response classes to make them more consistent and torely on the Data classes as much as possible when it comes to their state.* Remove the version argument from `AbstractResponse.toString`.* Fix `getErrorResponse` for `ProduceRequest` and `DescribeClientQuotasRequest` touse `ApiError` which processes the error message sent back to the clients. This wasuncovered by an accidental fix to a `RequestResponseTest` test (it was calling`AbstractResponse.toString` instead of `AbstractResponse.toString(short)`).Rely on existing protocol tests to ensure this refactoring does not change observed behavior (aside from improved performance).Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-13527: Add top-level error code field to DescribeLogDirsResponse (#11599)Implements KIP-784: https://cwiki.apache.org/confluence/display/KAFKA/KIP-784%3A+Add+top-level+error+code+field+to+DescribeLogDirsResponseReviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>",5
"MINOR: improve JavaDocs for KStream.through() (#6639)Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-942 version jar name change for 0.8.0-beta1 release,4
"MINOR: improve state directory test (#5961)Reviewers: Bill Bejeck <bill@confluent.io>, Kamal Chandraprakash (@kamalcph), Guozhang Wang <guozhang@confluent.io>",5
MINOR: Clean up process rate and latency metrics test (#8172)Reviewers: John Roesler <vvcephei@apache.org>,3
"KAFKA-6454: Allow timestamp manipulation in Processor API (#4519)Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
inor: Added few variable and their descriptions to vagrant readme… with the Vagranfile.local fileAuthor: Christian Posta <christian.posta@gmail.com>Reviewers: Gwen ShapiraCloses #942 from christian-posta/ceposta-doco,2
"KAFKA-3397: use -1(latest) as time default value for tools.GetOffsetShellminor fix for prompt the user, or we will get a error message:>Missing required argument ""[time]""Author: Xin Wang <best.wangxin@163.com>Reviewers: Ashish Singh, Guozhang WangCloses #1068 from vesense/patch-4",1
"KAFKA-9295: improve KTableKTableForeignKeyInnerJoinMultiIntegrationTest (#10409)Wait for Streams to get to RUNNING before proceeding with the test, some general cleanupReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",4
MINOR: update producer client request timeout in system testAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4168 from bbejeck/MINOR_update_streams_produer_timeout_in_system_test,5
KAFKA-9812: fix infinite loop in test code (#8411)Reviewers: Boyang Chen <boyang@confluent.io>,5
"KAFKA-7500: MirrorMaker 2.0 (KIP-382)Implementation of [KIP-382 ""MirrorMaker 2.0""](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0)Author: Ryanne Dolan <ryannedolan@gmail.com>Author: Arun Mathew <arunmathew88@gmail.com>Author: In Park <inpark@cloudera.com>Author: Andre Price <obsoleted@users.noreply.github.com>Author: christian.hagel@rio.cloud <christian.hagel@rio.cloud>Reviewers: Eno Thereska <eno.thereska@gmail.com>, William Hammond <william.t.hammond@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jakub Korzeniowski, Tim Carey-Smith, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Arun Mathew, Jeremy-l-ford, vpernin, Oleg Kasian <oleg.kasian@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Qihong Chen, Sriharsha Chintalapani <sriharsha@apache.org>, Jun Rao <junrao@gmail.com>, Randall Hauch <rhauch@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #6295 from ryannedolan/KIP-382",1
Fix SslTransportLayerTest.testUnsupportedCiphers to work with Java 11 (#5570)Java 11 supports TLS 1.3 which has different cipher names thanprevious TLS versions so the simplistic way of choosing ciphersis not guaranteed to work. Fix it by configuring the contextto use TLS 1.2.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-13103: add REBALANCE_IN_PROGRESS error as retriable error for AlterConsumerGroupOffsetsHandler (#11086)This patch adds `REBALANCE_IN_PROGRESS` error as retriable error for `AlterConsumerGroupOffsetsHandler`, and tests for it.Reviewers: David Jacot <djacot@confluent.io>",5
HOTFIX: Add license information to release_notes.py,5
"MINOR: Update scala version in bin scripts to 2.13.8 (#12477)This PR updates scala versions inside `bin/scripts` (i.e., `kafka-run-class.sh`).#12273 only modified `gradle.properties`.Reviewers: Ismael Juma <ismael@juma.me.uk>Signed-off-by: morsak <xorsak02@stud.fit.vutbr.cz>",1
"KAFKA-10012; Reduce overhead of strings in SelectorMetrics (#8684)`SelectorMetrics` has a per-connection metrics, which means the number of `MetricName` objects and the strings associated with it (such as group name and description) grows with the number of connections in the client. This overhead of duplicate string objects is amplified when there are multiple instances of kafka clients within the same JVM.  This patch addresses some of the memory overhead by making `metricGrpName` a constant field and introducing a new field `perConnectionMetricGrpName`. Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: code cleanup for Kafka Streams task interface (#9801)Reviewer: John Roesler <john@confluent.io>,5
"MINOR: Fix typo in consumer ACL exampleAuthor: sunnykrgupta <sunnygupta.kr@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2839 from sunnykrGupta/trunk",1
KAFKA-10246 : AbstractProcessorContext topic() throws NPE (#9034)AbstractProcessorContext topic() throws NullPointerException when modifying a state store within the DSL from a punctuator. Reorder the check to avoid the NPE.Co-authored-by: Ashish Roy <v-ashish.r@turvo.com>Reviewers: Boyang Chen <boyang@confluent.io>,5
MINOR: Cleanup generic & throw syntax in connect (#7892)Reviewers: Jason Gustafson <jason@confluent.io>,5
"SyncProducer does not correctly timeout; patched by Prashanth Menon; reviewed by Jun Rao, Neha Narkhede; KAFKA-305git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1305454 13f79535-47bb-0310-9956-ffa450edef68",2
"MINOR: Fix flaky shouldRejectNonExistentStoreName (#9426)Fix flaky test by making sure Streams isrunning before making assertions about IQ.Reviewers: Lee Dongjin <dongjin@apache.org>, Guozhang Wang <guozhang@apache.org>, Chia-Ping Tsai <chia7712@apache.org>",3
HOTFIX: unsubscribe does not clear user assignment properlyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #439 from hachikuji/unsubscribe-hotfix,0
"KAFKA-8424: replace ListGroups request/response with automated protocol (#6805)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-6145: Pt. 5 Implement high availability assignment (#8337)Adds a new TaskAssignor implementation, currently hidden behind an internal feature flag, that implements the high availability algorithm of KIP-441.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: First cut at porting State Store docs to AKAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3629 from bbejeck/docs-updates-for-kip-167",5
"KAFKA-1108 When controlled shutdown attempt fails, the reason is not always logged; reviewed by Neha Narkhede",2
KAFKA-6573: Update brokerInfo in KafkaController on listener update (#4603)Update `KafkaController.brokerInfo` when listeners are updated since this value is used to register the broker in ZooKeeper if there ZK session expires. Also added test to verify values in ZK after session expiry.,3
"KAFKA-12523: handle TaskCorruption and TimeoutException during handleCorruption  and handleRevocation (#10407)Need to handle TaskCorruptedException and TimeoutException that can be thrown from offset commit during handleRevocation or handleCorruptionReviewers: Matthias J. Sax <mjsax@confluent.org>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-12933: Flaky test ReassignPartitionsIntegrationTest.testReassignmentWithAlterIsrDisabled (#11244)Removes assertion added in #10471. It's unsafe to assert thatthere are partition movements ongoing for some of the tests inthe suite because partitions in some of the tests have 0 data,which may complete reassignment before `verify` can run.Tests pass locally.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-5215; Small Javadoc fixes for AdminClient#describeTopicsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Roger Hoover <roger.hoover@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3013 from cmccabe/KAFKA-5215",5
"KAFKA-5541: Streams should not re-throw if suspending/closing tasks failsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4037 from mjsax/kafka-5541-dont-rethrow-on-suspend-or-close-2",5
KAFKA-6156; Metric tag values with colons must be sanitizedWindows directory paths often contain colons which are not allowed inyammer metrics. Metric tag values with special characters must bequoted.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4173 from huxihx/KAFKA-6156,5
DelayedOperationTest.testRequestExpiry transient failure; reviewed by Neha Narkhede,0
KAFKA-759 Commit/FetchOffset APIs should not return versionId; reviewed by Neha Narkhede,1
"MINOR: expand logging and improve error message during partition count resolution (#11364)Recently a user hit this TaskAssignmentException due to a bug in their regex that meant no topics matched the pattern subscription, which in turn meant that it was impossible to resolve the number of partitions of the downstream repartition since there was no upstream topic to get the partition count for. Debugging this was pretty difficult and ultimately came down to stepping through the code line by line, since even with TRACE logging we only got a partial picture.We should expand the logging to make sure the TRACE logging hits both conditional branches, and improve the error message with a suggestion for what to look for should someone hit this in the futureReviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: disable flaky Streams EOS integration testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3272 from mjsax/minor-disable-eos-tests,3
MINOR: Increase unit test coverage of method ProcessorTopology#updateSourceTopics() (#9654)The unit tests for method ProcessorTopology#updateSourceTopics() did not cover allcode paths.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
"KAFKA-12994 Migrate JoinWindowsTest and SessionWindowsTest to new API (#11214)As detailed in KAFKA-12994, unit tests using the old API should be either removed or migrated to the new API.This PR migrates relevant tests in JoinWindowsTest.java and SessionWindowsTest.java.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",3
"KAFKA-9932: Don't load configs from ZK when the log has already been loaded (#8582)If a broker contains 8k replicas, we would previously issue 8k ZK calls to retrieve topicconfigs when processing the first LeaderAndIsr request. That should translate to 0 afterthese changes.Credit to @junrao for identifying the problem.Reviewers: Jun Rao <junrao@gmail.com>",0
"KAFKA-1113 log.cleanup.interval.mins property should be renamed; Trivial patch, no review",5
"MINOR: Fix a number of warnings in mirror/mirror-client (#8074)Reviewers: Ismael Juma <ismael@juma.me.uk>, Ryanne Dolan <ryannedolan@gmail.com>, Andrew Choi <a24choi@edu.uwaterloo.ca>",2
KAFKA-7437; Persist leader epoch in offset commit metadata (#5689)This commit implements the changes described in KIP-320 for the persistence of leader epoch information in the offset commit protocol.Reviewers:  Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-4162: Fixed typo ""rebalance""Author: David Chen <mvjome@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1853 from mvj3/KAFKA-4162",5
MINOR: Log the exception thrown by Selector.poll (#4873),2
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunk,1
MINOR: Fixed broken link to the IBM article about j-zerocopy (#6749)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-1662 gradle release issue permgen space patch by Sriharsha Chintalapani reviewed by Joe Sein,0
KAFKA-5289: handleStopReplica should not send a second response`shutdownIdleFetcherThreads()` can throw InterruptedExceptionfor example.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3096 from ijuma/kafka-5289-stop-replica-should-not-send-two-responses,5
"KAFKA-9365: Add server side change  to include consumer group information within transaction commit (#7897)To be able to correctly fence zombie producer txn commit, we propose to add (member.id, group.instance.id, generation) into the transaction commit protocol to raise the same level of correctness guarantee as consumer commit.Major changes involve:1. Upgrade transaction commit protocol with (member.id, group.instance.id, generation). The client will fail if the broker is not supporting the new protocol.2. Refactor group coordinator logic to handle new txn commit errors such as FENCED_INSTANCE_ID, UNKNOWN_MEMBER_ID and ILLEGAL_GENERATION. We loose the check on transaction commit when the member.id is set to empty. This is because the member.id check is an add-on safety for producer commit, and we also need to consider backward compatibility for old producer clients without member.id information. And if producer equips with group.instance.id, then it must provide a valid member.id (not empty definitely), the same as a consumer commit.Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Tighten up metadata upgrade test (#6531)Reviewers: Bill Bejeck <bbejeck@gmail.com>,3
kafka-1451; Broker stuck due to leader election race; patched by Manikumar Reddy; reviewed by Jun Rao,5
"KAFKA-3147; Memory records is not writable in MirrorMakerRemove the batch from the RecordAccumulator once its closed while aborting batches. Make sure we don't accept new batch appends to RecordAccumulator while the producer is being closed.Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>Reviewers: Jiangjie Qin, Ismael Juma, Guozhang WangCloses #825 from MayureshGharat/KAFKA-3147",2
MINOR: Empty logDirs validation should include error messageAuthor: Vogeti <svogeti@BANL149adbd9b.local>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2407 from vogetihrsh/KAFKA-4520,1
KAFKA-2048; Change lock synchronized to inLock() for partitionMapCond; reviewed by Guozhang Wang,4
KAFKA-177 Remove the clojure clients until correctly implemented and refactored; patched by nehanarkhede; reviewd by jefferydamickgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1195281 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6727; Fix broken Config hashCode() and equals() (#4796)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4789: Added support to ProcessorTopologyTestDriver to forward timestamps to internal topicsThis resolves the issue in the ProcessorTopologyTestDriver that the extracted timestamp is not forwarded with the produced record to the internal topics.JIRA ticket: https://issues.apache.org/jira/browse/KAFKA-4789The contribution is my original work and I license the work to the project under the project's open source license.guozhangwang dguyAuthor: Hamidreza Afzali <hrafzali@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2590 from hrafzali/KAFKA-4789_ProcessorTopologyTestDriver_timestamp",3
"KAFKA-4357; Fix consumer group describe output when there is no active member (old consumer)Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jason Gustafson <jason@confluent.io>Closes #2075 from vahidhashemian/KAFKA-4357",5
"MINOR: Cleanup admin creation logic in integration tests (#11790)There seemed to be a little sloppiness in the integration tests in regard to admin client creation. Not only was there duplicated logic, but it wasn't always clear which listener the admin client was targeting. This made it difficult to tell in the context of authorization tests whether we were indeed testing with the right principal. As an example, we had a method in TestUtils which was using the inter-broker listener implicitly. This meant that the test was using the broker principal which had super user privilege. This was intentional, but I think it would be clearer to make the dependence on this listener explicit. This patch attempts to clean this up a bit by consolidating some of the admin creation logic and making the reliance on the listener clearer.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
KAFKA-4991; Resolve findbugs warnings in KerberosLogin (#4394),2
"KAFKA-5820: Remove unneeded synchronized keyword in StreamThreadI removed synchronized keyword from 3 methods.I ran the change thru streams module where test suite passed.Author: tedyu <yuzhihong@gmail.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3777 from tedyu/trunk",1
kafka-1513; Cleanup KafkaServerStartable code; patched by Evgeny Vereshchagin; reviewed by Jun Rao,4
"MINOR: Add comments to constrainedAssign and generalAssign method (#9096)Enhance the understandability for constrainedAssign and generalAssign method by getting more detailed meta comments.Co-authored-by: A. Sophie Blee-Goldman <ableegoldman@gmail.com>Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@gmail.com>",5
"MINOR: Improve PartitionState logging and remove duplication of codeCurrently, logs involving PartitionState are not very helpful.```Broker 449 cached leader info org.apache.kafka.common.requests.UpdateMetadataRequest$PartitionState3285d64a for partition <topic>-<partition> in response to UpdateMetadata request sent by controller 356 epoch 138 with correlation id 0TRACE state.change.logger: Broker 449 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState66d6a8eb correlation id 3 from controller 356 epoch 138 for partition [<topic>,<partition>]```Author: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1609 from SinghAsDev/partitionState",4
"KAFKA-3201: Added rolling upgrade system tests from 0.8 and 0.9 to 0.10Three main tests:1. Setup: Producer (0.8) → Kafka Cluster → Consumer (0.8)First rolling bounce: Set inter.broker.protocol.version = 0.8 and message.format.version = 0.8Second rolling bonus, use latest (default) inter.broker.protocol.version and message.format.version2. Setup: Producer (0.9) → Kafka Cluster → Consumer (0.9)First rolling bounce: Set inter.broker.protocol.version = 0.9 and message.format.version = 0.9Second rolling bonus, use latest (default) inter.broker.protocol.version and message.format.version3. Setup: Producer (0.9) → Kafka Cluster → Consumer (0.9)First rolling bounce: Set inter.broker.protocol.version = 0.9 and message.format.version = 0.9Second rolling bonus: use inter.broker.protocol.version = 0.10 and message.format.version = 0.9Plus couple of variations of these tests using old/new consumer and no compression / snappy compression.Author: Anna Povzner <anna@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #980 from apovzner/kafka-3201-02",5
KAFKA-5268; Fix bounce test transient failure by clearing partitions before writing Complete state to transaction logAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3089 from hachikuji/KAFKA-5268,5
"MINOR: Improve IntegrationTestUtils documentation (#5664)* 1. Add Javadoc to undocumented methods. 2. Add documentation on  parameters in  methods. 3. Fix typo and method ordering.* Remove IntegrationTestUtils#produceKeyValuesSynchronouslyWithTimestamp(String, Collection<KeyValue<K, V>>, Properties, Headers, Long)",3
MINOR: Remove allow concurrent test (#8641)Reviewers: John Roesler <vvcephei@apache.org>,3
"MINOR: clarify why suppress can sometimes drop tombstones (#6195)Reviewers: Jonathan Gordon, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2397: add leave group request to force coordinator trigger rebalanceLet's say every consumer in a group has session timeout s. Currently, if a consumer leaves the group, the worst case time to stabilize the group is 2s (s to detect the consumer failure + s for the rebalance window). If a consumer instead can declare they are leaving the group, the worst case time to stabilize the group would just be the s associated with the rebalance window.This is a low priority optimization!Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jason Gustafson, Guozhang WangCloses #103 from onurkaraman/leave-group",2
"KAFKA-10199: Handle restored tasks output by state updater (#12554)Once the state updater restored an active task it puts itinto an output queue. The stream thread reads the restoredactive task from the output queue and after it verifiedthat the task is still owned by the stream thread it transitsit to RUNNING.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",5
"MINOR: fix control plane listener + kraft error message (#11729)The current error message suggests that controller.listener.names is a replacement forcontrol.plane.listener.name. This is incorrect since these configurations have very differentfunctions. This PR deletes the incorrect message.Reviewers: David Jacot <david.jacot@gmail.com>, Kvicii",4
KAFKA-2199 Make signing artifacts optional and disabled by default for SNAPSHOTs and allow remote Maven repository configuration from the command line.,5
"KAFKA-9600; EndTxn should enforce strict epoch checking if from client (#8164)This PR enhances the epoch checking logic for endTransaction call in TransactionCoordinator. Previously it relaxes the checking by allowing a producer epoch bump, which is error-prone since there is no reason to see a producer epoch bump from client.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-8558:  Add StreamJoined config object to join (#7285)Reviewer: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5162; Add a reference to AdminClient to docs/api.htmlAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>Closes #2958 from cmccabe/KAFKA-5162",5
"KAFKA-5166: Add option ""dry run"" to Streams application reset toolAddressed the below review comment from #PR #2998 from mjsaxI am wondering if it would be better, to ""embed"" the dry-run into the actual code and branch on each place. Otherwise, if things get changed, we could easily introduce bugs (ie, dry run show something different than what the actual reset code does.We could introduce methods like mabyeSeekToBeginning() that either does the seek or only prints to stdout. This would ensure that the main logic is used to ""feed"" into dry-run and we don't have code duplication.WDYT?Author: Bharat Viswanadham <bharatv@us.ibm.com>Reviewers: Matthias J. Sax, Damian Guy, Eno Thereska, Guozhang WangCloses #3005 from bharatviswa504/KAFKA-5166",1
"KAFKA-9500: Fix FK Join Topology (#8015)Corrects a flaw leading to an exception while building topologies that include both:* A foreign-key join with the result not explicitly materialized* An operation after the join that requires source materializationAlso corrects a flaw in TopologyTestDriver leading to output records being enqueued in the wrong order under some (presumably rare) circumstances.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2874; shutdown ZK process reliablyAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Flavio Junqueira <fpj@apache.org>, Jun Rao <junrao@gmail.com>Closes #573 from miguno/KAFKA-2874",5
"KAFKA-2348; Drop support for Scala 2.9`testAll` passed locally.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Harsha, Ewen, GuozhangCloses #87 from ijuma/kafka-2348-drop-support-for-scala-2.9 and squashes the following commits:cf9796a [Ismael Juma] KAFKA-2348; Drop support for Scala 2.9",1
"MINOR: enable EOS during smoke test IT (#10870)This IT has been failing on trunk recently. Enabling EOS during the integration testmakes it easier to be sure that the test's assumptions are really true during verificationand should make the test more reliable.I also noticed that in the actual system test file, we are using the deprecated propertyname ""beta"" instead of ""v2"".Reviewers: Boyang Chen <boyang@apache.org>",5
"KAFKA-4310; Add missing Windows script `kafka-consumer-groups.bat`add file 'kafka-consumer-groups.bat' for Windows platformAuthor: amethystic <huxi_2b@hotmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>Closes #2037 from amethystic/kafka-4310_add_consumer_groups_script",1
"KAFKA-6069: Properly tag KafkaStreams metrics with the client id.Author: Tommy Becker <tobecker@tivo.com>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4081 from twbecker/KAFKA-6069",5
"KAFKA-5203; Metrics: fix resetting of histogram sampleWithout the histogram cleanup, the percentiles are calculatedincorrectly after purging of one or more samples: event countsgo out of sync with counts in histogram buckets, and bucketwith lower value gets chosen for the given quantile.This change adds the necessary histogram cleanup.Author: Ivan A. Melnikov <iv@altlinux.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3002 from iv-m/kafka-5203-percentiles-fix",0
"KAFKA-5379: ProcessorContext.appConfigs() should return parsed valuesAuthor: Tommy Becker <tobecker@tivo.com>Author: Tommy Becker <twbecker@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3455 from twbecker/kafka-5379",5
KAFKA-9718; Don't log passwords for AlterConfigs in request logs (#8294)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"KAFKA-14198; swagger-jaxrs2 dependency should be compileOnly (#12609)Verified that the artifact generated by `releaseTarGz` no longer includesswagger-jaxrs2 or its dependencies (like snakeyaml).Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Chris Egerton <fearthecellos@gmail.com>",1
"KAFKA-9931: Implement KIP-605 to expand support for Connect worker internal topic configurations (#8654)Added support for -1 replication factor and partitions for distributed worker internal topics by expanding the allowed values for the internal topics’ replication factor and partitions from positive values to also include -1 to signify that the broker defaults should be used.The Kafka storage classes were already constructing a `NewTopic` object (always with a replication factor and partitions) and sending it to Kafka when required. This change will avoid setting the replication factor and/or number of partitions on this `NewTopic` if the worker configuration uses -1 for the corresponding configuration value.Also added support for extra settings for internal topics on distributed config, status, and offset internal topics.Quite a few new tests were added to verify that the `TopicAdmin` utility class is correctly using the AdminClient, and that the `DistributedConfig` validators for these configurations are correct. Also added integration tests for internal topic creation, covering preexisting functionality plus the new functionality.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"MINOR: unify calls to get committed offsets and metadata (#7463)Reviewers: Chris Pettitt <cpettitt@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
HOTFIX: fix compilation error due to merge of KAFKA-3812Merge of KAFKA-3812 caused a compilation error in StreamThreadStateStoreProviderTestAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1641 from dguy/fix-compile-error,0
KAFKA-3717; Support building aggregate javadoc for all project modulesThe task is called `aggregatedJavadoc` and the generated html will be under `<project.dir>/build/docs/javadoc/`.I also disabled javadoc for `tools` and `log4j-appender` as they are not public API.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1398 from ijuma/kafka-3717-aggregate-javadoc,2
"MINOR: document how to escape json parameters to ducktape tests (#8546)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13761: KafkaLog4jAppender deadlocks when idempotence is enabled (#11939)When a log entry is appended to a Kafka topic using KafkaLog4jAppender, the producer.send operationmay hit a deadlock if the producer network thread also tries to append a log at the same log level.This issue is triggered when idempotence is enabled for the KafkaLog4jAppender and the producertries to acquire the TransactionManager lock.This is a temporary workaround to avoid deadlocks by disabling idempotence explicitly inKafkaLog4jAppender.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-3735: Dispose all RocksObejcts upon completenessAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Roger Hoover, Eno Thereska, Ismael JumaCloses #1411 from guozhangwang/K3735-dispose-rocksobject",5
kafka-937; ConsumerFetcherThread can deadlock; patched by Jun Rao; reviewed by Joel Koshy,5
KAFKA-2950: Fix performance regression in the producerRemoves all the System.currentTimeMillis calls to help with performance on small messages.Author: Jay Kreps <jay.kreps@gmail.com>Reviewers: Guozhang WangCloses #632 from jkreps/producer-perf-regression,5
KAFKA-2487: change kafka.examples.Consumer to use the new java consumerAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang WangCloses #297 from SinghAsDev/KAFKA-2487,1
"KAFKA-6750: Add listener name to authentication context (KIP-282) (#4829)PrincipalBuilder implementations can now take the listener into accountwhen creating the Principal. This is especially interesting in deploymentswhere inter-broker traffic is on a different listener than client traffic orwhen the same protocol is used by multiple listeners.The change in itself is mostly ""plumbing"" as the listener name needs to bepassed from ChannelBuilders all the way down to all classes implementingAuthenticationContext.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",5
"KAFKA-8336; Enable dynamic reconfiguration of broker's client-side certs (#6721)Enable reconfiguration of SSL keystores and truststores in client-side channel builders used by brokers for controller, transaction coordinator and replica fetchers. This enables brokers using TLS mutual authentication for inter-broker listener to use short-lived certs that may be updated before expiry without restarting brokers.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
"KAFKA-4218: Enable access to key in ValueTransformer and ValueMapperThis PR is the partial implementation for KIP-149. As the discussion for this KIP is still ongoing, I made a PR on the ""safe"" portions of the KIP (so that it can be included in the next release) which are 1) `ValueMapperWithKey`, 2) `ValueTransformerWithKeySupplier`, and 3) `ValueTransformerWithKey`.Author: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4309 from jeyhunkarimov/KIP-149_hope_last",4
"KAFKA-9726: Add IdentityReplicationPolicy to MirrorMaker2 (#10652)This new policy enables active/passive, one-way replication without renaming topics, similar to MM1. This implementation is described in KIP-382 (adopted), originally as ""LegacyReplicationPolicy"".This enables operators to migrate from MM1 to MM2 without re-architecting their replication flows, and enables some additional use-cases for MM2. For example, operators may wish to ""upgrade"" their Kafka clusters by mirroring everything to a completely new cluster. Such a migration would have been difficult with either MM1 or MM2 previously.When using IdentityReplicationPolicy, operators should be aware that MM2 will not be able to detect cycles among replicated topics. A misconfigured topology may result in replicating the same records back-and-forth or in an infinite loop. However, we don't prevent this behavior, as some use-cases involve filtering records (via SMTs) to prevent cycles.Reviewers: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Ryanne Dolan <rdolan@twitter.com>Co-authored-by: Matthew de Detrich <mdedetrich@gmail.com>Co-authored-by: Ivan Yurchenko <ivanyu@aiven.io>",1
"Add recent versions of Kafka to the matrix of ConnectDistributedTest (#7024)Reviewers: Arjun Satish <arjun@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"KAFKA-3030: Remove unused scala dependenciesAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #713 from granthenke/scala-deps",1
"MINOR: Delete unused DeleteTopicsWithIdsResult (#10957)Reviewers: Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-7322; Fix race condition between log cleaner thread and log retention thread when topic cleanup policy is updatedIn order to fix race condition between log cleaner thread and log retention thread when dynamically switching topic cleanup policy, existing log cleaner in-progress map is used to prevent more than one thread from working on the same topic partition.Author: Xiongqi Wesley Wu <xiongqi.wu@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5591 from xiowu0/trunk",1
"MINOR: Just one put and flush to generation rocksDB File in RocksDBStoreTest (#7469)After merged #7412 we realized it does not necessarily need that long time: instead of putting 2 million records, we can just have a single put followed by a flush, to make sure that rocksDB file exists locally (verified that after flush the sst file always exist).Now the RocksDBStoreTest takes about 2.5 seconds, and removing the integration annotation from it.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-2951; Add a test to verify produce, consume with ACLs for topic/group wildcard resources (#5054)",3
"MINOR: Break up StreamsPartitionAssignor's gargantuan #assign (#8245)Just a minor refactoring of StreamsPartitionAssignor's endless assign method into logical chunks to hopefully improve readability. No logical changes, literally just moving code around and adding docs.The hope is to make it easier to write and review KIP-441 PRs that dig into the assignment logic.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-4864; added correct zookeeper nodes for security migratorAuthor: simplesteph <stephane.maarek@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2655 from simplesteph/fix-security-migrator-tool,0
"MINOR: Docs on state store instantiation (#5698)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-3116; Specify minimum Gradle version required in ReadmeAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #813 from vahidhashemian/KAFKA-3116,1
"MINOR: fix error message (#9730)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
Add compression to C# client; patched by Eric Hauser; KAFKA-153git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1185772 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-9274: fix incorrect default value for `task.timeout.ms` config (#9385) - part of KIP-572 - also add handler method to trigger/reset the timeout on a taskReviewer: John Roesler <john@confluent.io>,5
system test to validate consistency of replicas; patched by John Fung; reviewed by Jun Rao; KAFKA-341git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350316 13f79535-47bb-0310-9956-ffa450edef68,5
KAFKA-12862: Update Scala fmt library and apply fixes (#10784)Updates the scala fmt to the latest stable version.Applies all the style fixes (all source code changes are done by scala fmt).Removes setting about dangling parentheses as `true` is already thedefault.Reviewer: John Roesler <john@confluent.io>,5
MINOR: Fix sftp_mkdir in release.pyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3789 from ijuma/ftp-release-py-fixes,0
"KAFKA-4859: Set shorter commit interval for integration tests with cachingAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Armin Braun, Damian Guy, Jason GustafsonCloses #2682 from guozhangwang/K4859-cache-commit-interval",3
"KAFKA-9113: Clean up task management and state management (#7997)This PR is collaborated by Guozhang Wang and John Roesler. It is a significant tech debt cleanup on task management and state management, and is broken down by several sub-tasks listed below:Extract embedded clients (producer and consumer) into RecordCollector from StreamTask.guozhangwang#2guozhangwang#5Consolidate the standby updating and active restoring logic into ChangelogReader and extract out of StreamThread.guozhangwang#3guozhangwang#4Introduce Task state life cycle (created, restoring, running, suspended, closing), and refactor the task operations based on the current state.guozhangwang#6guozhangwang#7Consolidate AssignedTasks into TaskManager and simplify the logic of changelog management and task management (since they are already moved in step 2) and 3)).guozhangwang#8guozhangwang#9Also simplified the StreamThread logic a bit as the embedded clients / changelog restoration logic has been moved into step 1) and 2).guozhangwang#10Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Boyang Chen <boyang@confluent.io>",5
kafka-1003; ConsumerFetcherManager should pass clientId as metricsPrefix to AbstractFetcherManager; patched by Swapnil Ghike; reviewed by Jun Rao,0
kafka-1419; cross build for scala 2.11; patched by Ivan Lyutov; reviewed by Joe Stein and Jun Rao,5
KAFKA-10722: Improve JavaDoc for KGroupedStream.aggregate and other similar methods (#9606)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-10000: Utils methods for overriding user-supplied properties and dealing with Enum types (#11774)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"KAFKA-9219: prevent NullPointerException in Kafka Connect metrics (#7652)`assignmentSnapshot` may take a moment to get initialized in some cases, especially whenKafka Connect is started from scratch. While `assignmentSnapshot` is not initialized, return 0 in both `measure()` methods.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Edoardo Comar <ecomar@uk.ibm.com>",5
MINOR: Fixed way how logging methods are used for having a consistent oneIn the stream library there are few cases where we don't leverage on logging methods features (i.e. using {} placeholder instead of string concatenation or passing the exception variable)Author: ppatierno <ppatierno@live.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3419 from ppatierno/streams-consistent-logging,2
"KAFKA-12515; Feature support should be ignorable in ApiVersion response (#10377)Feature support should be treated as ignorable in the api version response so that we can gracefully downgrade for older clients without additional logic in the broker.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Add method to Herder to control logging of connector configs during validation (#8263)* The Herder interface is extended with a default method that allows choosing whether to log all the connector configurations during connector validation or not. * The `PUT /connector-plugins/{connector-type}/config/validate` is modified to stop logging the connector's configurations when a validation request is hitting this endpoint. Validations during creation or reconfiguration of a connector are still logging all the connector configurations at the INFO level, which is useful in general and during troubleshooting in particular. Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <github@juma.me.uk>",5
DumpLogSegment offset verification is incorrect for compressed messages (second fix); patched by Yang Ye; reviewed by Jun Rao; KAFKA-614git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415004 13f79535-47bb-0310-9956-ffa450edef68,0
kafka-883; System Test - update migration tool testsuite after 0.7 ProducerPerformance sends seq MessageID; patched by John Fung; reviewed by Jun Rao,3
MINOR: Fix client.quota.callback.class doc (#11510)Reviewers: David Jacot <djacot@confluent.io>,5
"Fix for flaky test in StoreQueryIntegrationTest (#11129)Fix a bug in StoreQueryIntegrationTest::shouldQueryOnlyActivePartitionStoresByDefault that causes the test to fail in the case of a client rebalancing. The changes in this PR make sure the test keeps re-trying after a rebalancing operation, instead of failing.Reviewers: Luke Chen <showuon@gmail.com>, John Roesler <vvcephei@apache.org>",0
"KAFKA-7111: Log error connecting to node at a higher log level (#5312)There are cases where the broker would return an unresolve-able address (e.g broker inside a docker network while client is outside) and the client would not log any information as to why it is timing out, since the default log level does not print DEBUG messages.Changing this log level will enable easier troubleshooting in such circumstances. This change does not change the logs shown on transient failures like a broker failure.",0
KAFKA-5498: ConfigDef derived from another ConfigDef did not correctly compute parentless configsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #3412 from ewencp/kafka-5498-base-configdef-parentless-configs,5
KAFKA-2454; Deadlock between log segment deletion and server shutdown.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>Closes #153 from becketqin/KAFKA-2454,4
KAFKA-921; Expose max lag and min fetch rate mbeans for consumers and replica fetchers; reviewed by Jun Rao.,5
Minor: Missing LicenseAuthor: Sriharsha Chintalapani <harsha@hortonworks.com>Reviewers: Gwen ShapiraCloses #524 from harshach/missing-license,1
MINOR: Increased default EC2 instance sizeAWS instance size increased to m3.xlarge to allow all system tests to pass. ijuma ewencp have a look please.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Gwen ShapiraCloses #1046 from enothereska/minor-aws,4
"KAFKA-10573 Update connect transforms configs for KIP-629 (#9403)Changes the Connect `ReplaceField` SMT's configuration properties, deprecating and replacing `blacklist` with `exclude`, and `whitelist` with `include`. The old configurations are still allowed (ensuring backward compatibility), but warning messages are written to the log to suggest users change to `include` and `exclude`.This is part of KIP-629.Author: Xavier Léauté <xvrl@apache.org>Reviewer: Randall Hauch <rhauch@gmail.com>",4
KAFKA-5355; Test cases to ensure isolation level propagated in delayed fetchInclude a few logging improvements.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3230 from hachikuji/KAFKA-5355-TESTS,3
KAFKA-5690; Add support to list ACLs for a given principal (KIP-357)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5633 from omkreddy/KAFKA-5690-LIST-PER-PRICIPAL,1
"KAFKA-13357; Store producer IDs in broker snapshotsWhen creating snapshots, controllers generate a ProducerIdsRecord indicating the highest producer IDthat has been used so far. Brokers should generate the same record, so that the snapshots can becompared.Also, fix a bug in MetadataDelta#finishSnapshot. The current logic will produce the wrong result ifall objects of a certain type are completely removed in the snapshot. The fix is to unconditionallycreate each delta object.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-4317: Regularly checkpoint StateStore changelog offsetsCurrently the checkpoint file is deleted at state store initialization and it is only ever written again during a clean shutdown. This can result in significant delays during restarts as the entire store needs to be loaded from the changelog.We can mitigate against this by frequently checkpointing the offsets. The checkpointing happens only during the commit phase, i.e, after we have manually flushed the store and the producer. So we guarantee that the checkpointed offsets are never greater than what has been flushed.In the event of hard failure we can recover by reading the checkpoints and consuming from the stored offsets.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2471 from dguy/kafka-4317",1
KAFKA-1001; Handle follower transition in batch; patched by Guozhang Wang; reviewed by Jun Rao,0
"MINOR: Fix typos introduced in KIP-559 (#8042)A few references to KIP-559 in the schema definitions needed to be fixed.Reviewers: Brajesh Kumar <bristy@users.noreply.github.com>, Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5143: add kafka-broker-api-version.bat for Windows platformAdded kafka-broker-api-versions.bat for Windows platformAuthor: amethystic <huxi_2b@hotmail.com>Reviewers: Vahid Hashemian, Ismael Juma, Guozhang WangCloses #2943 from amethystic/kafka-5143_offer_broker_api_versions_bat",1
MINOR: Add log entry for KafkaException in StreamThread#runLoop (#6144)I've observed several reports of sudden unexpected streamthread shutdown with the log entry like:State transition from PENDING_SHUTDOWN to DEADbut there is no related error logs before this line at all. I suspect this is because we intentionally do not log for KafkaException and there's some edge cases where we miss internally and hence caused this. I'm adding the ERROR level log entry here in order to reveal more information in case I saw this again in the future.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-3337: Extract selector as a separate groupBy operator for KTable aggregationsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1231 from mjsax/kafka-3337-extact-key-selector-from-agg,5
MINOR: fix indention in <pre> tagsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2553 from mjsax/hotfixDocs2,2
"KAFKA-5473; handle ZK session expiration properly when a new session can't be established(WIP: this commit isn't ready to be reviewed yet. I was checking the travis-ci build with the configuration changes in my account and opened the PR prematurely against trunk. I will make it consistent with Contribution guidelines once it's well tested.)https://issues.apache.org/jira/browse/KAFKA-5473Design:`zookeeper.connection.retry.timeout.ms` => this determines how long to wait before triggering the shutdown. The default is 60000ms.Currently the implementation only handles the `handleSessionEstablishmentError` by waiting for the sessionTimeout.Author: Prasanna Gautam <prasannagautam@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3990 from prasincs/KAFKA-5473",0
trivial fix to log topics in fetching metadata properlygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387269 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-2882: Add constructor cache for Snappy and LZ4 Output/Input streams in Compressor.javaIn `wrapForOutput` and `wrapForInput` methods of `org.apache.kafka.common.record.Compressor`,  `Class.forName(""[compression codec]"")` and `getConstructor` methods are invoked for each `wrapForOutput` / `wrapForInput` call. Reflection calls are expensive and impact performance at high volumes. This patch adds a cache for `Constructor` to reduce the reflection overhead.In our production deployments, this has reduced producer CPU usage by about 20%Author: Maksim Logvinenko <mlogvinenko@gmail.com>Reviewers: Ismael JumaCloses #580 from logarithm/compressor-getclass-cache",2
"HOTFIX: move Conusmed to o.a.k.streams.kstream (#5033)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Ensure same version of scala library is used for compile and at runtime (#9168)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-5659; Fix error handling, efficiency issue in AdminClient#describeConfigsIf a request for a broker configuration failed due to a timeout orthe broker not being available, we would fail the futuresassociated with the non-broker request instead (and never fail thebroker future, which would be left uncompleted forever).We would also do an unnecessary request if only broker configs wererequested.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3585 from cmccabe/KAFKA-5659",5
"KAFKA-10531: Check for negative values to Thread.sleep call (#9347)System.currentTimeMillis() is not monotonic, so using that to calculate time to sleep can result in negative values. That will throw IllegalArgumentException.This change checks for that and sleeps for a second (to avoid tight loop) if the value returned is negative.Author: Shaik Zakir Hussain <zhussain@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
MINOR: Fix incorrect JavaDoc (type mismatch) (#4632)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-8275; Take throttling into account when choosing least loaded node (#6619)If a node is currently throttled, we should take it out of the running for `leastLoadedNode`. Additionally, current logic seems to favor connecting to new nodes rather than using existing connections which have one or more in flight requests. The javadoc is slightly vague about whether this is expected, but it seems not.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Clarification in producer config documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Dana Powers, Gwen ShapiraCloses #1732 from vahidhashemian/minor/clarify_producer_config_documentation",5
"KAFKA-5448: Change TimestampConverter configuration name to avoid conflicting with reserved 'type' configuration used by all TransformationsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: David Tucker, Gwen ShapiraCloses #3342 from ewencp/kafka-5448-change-timestamp-converter-config-name",5
KAFKA-713 Update Hadoop producer for Kafka 0.8 changes; reviewed by Neha Narkhede,4
"KAFKA-13491: IQv2 framework (#11557)Implements the major part of the IQv2 framework as proposed in KIP-796.Reviewers: Patrick Stuedi <pstuedi@apache.org>, Vicky Papavasileiou <vpapavasileiou@confluent.io>, Bruno Cadonnna <cadonna@apache.org>",1
"KAFKA-8538 (part of KIP-345): add group.instance.id to DescribeGroup (#6957)Include group.instance.id in the describe group result for better visibility.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-5355; DelayedFetch should propagate isolation level to log readTests will be added in a subsequent commit.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3221 from hachikuji/KAFKA-5355,5
"Minor typo: ""result _is_ a"" > ""result _in_ a"" (#11876)Reviewers Bill Bejeck <bbejeck@apache.org>",2
"MINOR: reduce() javadocs: clarify position of argumentsAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #2651 from miguno/trunk-reduce-javadocs",2
"KAFKA-1624; bump up default scala version to 2.11.4 to compile with java 8; reviewed by Joe Stein, Gwen Shapira and Joel Koshy",5
"KAFKA-5731; Corrected how the sink task worker updates the last committed offsetsPrior to this change, it was possible for the synchronous consumer commit request to be handled before previously-submitted asynchronous commit requests. If that happened, the out-of-order handlers improperly set the last committed offsets, which then became inconsistent with the offsets the connector task is working with.This change ensures that the last committed offsets are updated only for the most recent commit request, even if the consumer reorders the calls to the callbacks.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3662 from rhauch/kafka-5731",5
"MINOR: code cleanup (#6057)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Add unit test for KAFKA-8676 to guard against unrequired task restarts (#7287)Added unit test for recent fix of `KafkaConfigBackingStore`.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
KAFKA-12160: Remove max.poll.interval.ms from config docs (#10182)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-6878 Switch the order of underlying.init and initInternal (#4988)This is continuation of #4978.From Guozhang:I think to fix this issue, in init we could consider switching the steps of 1 and 2:initInternal(context);underlying.init(context, root);sincevolatile boolean open = false;it should be sufficient. In this case the check on step 3) will fail if underlying.init is not completed and we will throw InvalidStateStoreException.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
KAFKA-262 Bug in the consumer rebalancing logic causes one consumer to release partitions that it does not own; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1242552 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12909: disable spurious left/outer stream-stream join fix for old JoinWindows API (#10861)We changed the behavior of left/outer stream-stream join via KAFKA-10847.To avoid a breaking change during an upgrade, we need to disable thisfix by default.We only enable the fix if users opt-in expliclity by changing theircode. We leverage KIP-633 (KAFKA-8613) that offers a new JoinWindowsAPI with mandatory grace-period to enable the fix.Reviewers: Sergio Peña <sergio@confluent.io>, Israel Ekpo <israelekpo@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Extract Gradle and its plugins versions into dependencies.gradle (#6648)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
KAFKA-2989; System tests should verify partitions consumed after rebalancingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #702 from hachikuji/KAFKA-2989,5
"KAFKA-13821: Update Kafka Streams WordCount demo to new Processor API (#12139)https://issues.apache.org/jira/browse/KAFKA-13821Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Bill Bejeck <bbejeck@apache.org>",0
"KAFKA-3989; MINOR: follow-up: update script to run from kafka root…h-benchmarks/jmh.shAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2654 from bbejeck/KAFKA-3989_follow_up",1
KAFKA-102 Patch from Blake Matheny. Clean up logging.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1157920 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Fix chunked down-conversion behavior when no valid batch exists after conversion (#5173)We might decide to drop certain message batches during down-conversion because older clients might not be able to interpret them. One such example is control batches which are typically removed by the broker if down-conversion to V0 or V1 is required. This patch makes sure the chunked down-conversion implementation is able to handle such cases.,0
"MINOR: Fix flaky ConsumerTopicCreationTest (#6727)`ConsumerTopicCreationTest` relied on `KafkaConsumer#poll` to send a `MetadataRequest` within 100ms to verify if a topic is auto created or not. This is brittle and does not guarantee if the request made it to the broker or was processed successfully. This PR fixes the flaky test by adding another topic; we wait until we consume a previously produced record to this topic. This ensures MetadataRequest was processed and we could then check if the topic we're interested in was created or not.Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7406: Name join group repartition topics (#5709)Reviewer: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"kafka-1982; (add missing files) change kafka.examples.Producer to use the new java producer; patched by Ashish Singh; reviewed by Gwen Shapira, Mayuresh Gharat and Jun Rao",1
KAFKA-7904; Add AtMinIsr partition metric and TopicCommand option (KIP-427)- Add `AtMinIsrPartitionCount` metric to `ReplicaManager`- Add `AtMinIsr` metric to `Partition`- Add `--at-min-isr-partitions` describe `TopicCommand` optionhttps://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103089398Author: Kevin Lu <lu.kevin@berkeley.edu>Author: lu.kevin@berkeley.edu <kelu@paypal.com>Reviewers: Gwen ShapiraCloses #6421 from KevinLiLu/KAFKA-7904,5
MINOR: Use ApiUtils' methods static imported consistently (#9763)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
kafka-947; isr-expiration-thread may block LeaderAndIsr request for a relatively long period; patched by Jun Rao; reviewed by Joel Koshy,5
"KAFKA-9040; Add --all option to config command (#7607)Implement --all option for describing all configs (both dynamic and static) as documented in KIP-524 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-524%3A+Allow+users+to+choose+config+source+when+describing+configs.Reviewers: Brian Byrne <bbyrne@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR - Fix typo in Streams Dev Guide (#4972)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-10173: Fix suppress changelog binary schema compatibility (#8905)We inadvertently changed the binary schema of the suppress buffer changelogin 2.4.0 without bumping the schema version number. As a result, it is impossibleto upgrade from 2.3.x to 2.4+ if you are using suppression.* Refactor the schema compatibility test to use serialized data from older versionsas a more foolproof compatibility test.* Refactor the upgrade system test to use the smoke test application so that weactually exercise a significant portion of the Streams API during upgrade testing* Add more recent versions to the upgrade system test matrix* Fix the compatibility bug by bumping the schema version to 3Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-3519: Refactor Transformer's transform / punctuate to return nullable valuesAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Dan Norwood, Anna PovznerCloses #1204 from guozhangwang/KTransformR",4
"KAFKA-9030: Document client-level (a.k.a. instance-level) metrics (#7501)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
HOTFIX: fix validity check in sticky assignor tests (#8815)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-1860: Fix issue that file system errors are not detected unless Kafka tries to write.When the disk (raid with caches dir) dies on a Kafka broker, typically the filesystem gets mounted into read-only mode, and hence when Kafka tries to read the disk, they'll get a FileNotFoundException with the read-only errno set (EROFS). However, as long as there is no produce request received, hence no writes attempted on the disks, Kafka will not exit on such FATAL error and keep on throwing exception : java.io.FileNotFoundExceptionIn this case, the JVM should stop if the underlying file system goes in to Read only mode.Author: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Lin Dong, Gwen Shapira, Ismael Juma, Guozhang WangCloses #698 from MayureshGharat/KAFKA-1860",5
"KAFKA-10312; Fix error code returned in Metadata response when leader is not available (#9112)MetadataCache#getPartitionMetadata returns an error when the topic's leader Idis present at MetadataCache but listener endpoint is not present for this leader.For older versions, LEADER_NOT_AVAILABLE is returned while LISTENER_NOT_FOUND isreturned for new metadata versions.The problem is that getPartitionMetadata was looking up MetadataCache's host brokerId ratherthan the topic's leader id while determining what error to return. Thiscould result in the call returning LISTENER_NOT_FOUND when it shouldhave returned LEADER_NOT_AVAILABLE. This commit corrects this behavior.Unit tests were already present to test out the error codes returnedunder different situations but they were giving out a false positive.The test was using same broker id for both the MetadataCache's host aswell as for the topic's leader. Error manifests when the MetadataCache'shost id is changed. Improved the test.This commit also consolidated couple of related tests to reduce codeduplication.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Update docs for KIP-530 and KIP-562 (#8388)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-2771: Added rolling upgrade system test (ducktape) for Secured ClusterTests rolling upgrade from PLAINTEXT to SSLAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Geoff Anderson, Ismael JumaCloses #496 from benstopford/security-upgrade-test",3
KAFKA-13429: ignore bin on new modules (#11415)Reviewers: John Roesler <vvcephei@apache.org>,1
KAFKA-1263 Snazzy up the README markdown for better visibility on github; patched by Joe Stein; reviewed by Neha Narkhede,1
HOTFIX: fix broken link for wordcount demo exampleAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2644 from mjsax/hotfixBrokerLink,2
"KAFKA-13007; KafkaAdminClient getListOffsetsCalls reuse cluster snapshot (#10940)In getListOffsetsCalls, we rebuild the cluster snapshot for every topic partition. instead, we should reuse a snapshot.For manual testing (used AK 2.8), i've passed in a map of 6K topic partitions to listOffsetsWithout snapshot reuse:duration of building futures from metadata response: **15582** millisecondstotal duration of listOffsets: **15743** millisecondsWith reuse:duration of building futures from metadata response: **24** millisecondstotal duration of listOffsets: **235** millisecondsReviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: Clarify logging behavior with errors.log.include.messages property (#11758)The docs are a little misleading and some users can be confused about the exact behavior of this property.,5
KAFKA-1764; ZookeeperConsumerConnector should not put multiple shutdown commands to the same data chunk queue; reviewed by Joel Koshy and Guozhang Wang,5
"KAFKA-8530; Check for topic authorization errors in OffsetFetch response (#6928)The OffsetFetch requires Topic Describe permission. If a client does not have this, we return TOPIC_AUTHORIZATION_FAILED at the partition level. Currently the consumer does not handle this error explicitly, but raises it as a generic `KafkaException`. For consistency with other APIs and to fix transient test failures in `PlaintextEndToEndAuthorizationTest`, we should raise `TopicAuthorizationFailedException` instead.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-6122: Global Consumer should handle TimeoutExceptionImplements KIP-224:- adding new StreamsConfig `retires`- uses `retires` and `retry.backoff.ms` to handle TimeoutException in GlobalStateManager- adds two new tests to trigger TimeoutException in global consumer- some minor code cleanup to reduce number of parameters we need to pass aroundAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4206 from mjsax/kafka-6122-global-consumer-timeout-exception",5
"KAFKA-3584; Fix synchronization issue between deleteOldSegments() and delete() methodsThis PR is to fix synchronization issue between deleteOldSegments() and delete() method calls. log.deleteOldSegments() call throws NullPointerException after log.delete() method call.cc ijuma junraoAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1367 from omkreddy/KAFKA-3584",4
"KAFKA-4335: Add batch.size to FileStreamSource connector to prevent OOMWhen the source file of `FileStreamSource` is a large file, `FileStreamSourceTask.poll()` will result in OOM. This pull request added `batch.size` parameter which can restrict the poll size.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Study <ph.study@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4356 from phstudy/KAFKA-4335",5
MINOR: fix scala serde tests (#5644)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"HOTFIX: improve error message on invalid input record timestampAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang, Ismael Juma, Michael G. Noll, Eno ThereskaCloses #2076 from mjsax/hotfixTSExtractor",4
"MINOR: explain producer naming within StreamsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3378 from mjsax/minor-producer-naming",5
"KAFKA-13406: skip assignment validation for built-in cooperativeStickyAssignor (#11439)This fix is trying to skip the assignment validation for built-in cooperative sticky assignor, since (a) we know the assignment is valid since we do essentially this same check already in the cooperative sticky assignor, and (b) the check is broken anyways due to potential for claimed `ownedPartitions` to be incorrect Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"MINOR: Update schema field names in DescribeAcls Request/ResponseAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin Patrick McCabe <cmccabe@apache.org>Closes #8075 from omkreddy/KAFKA-9026-Fix",0
kafka-1370; Gradle startup script for Windows; patched by Stevo Slavic; reviewed by Jun Rao,5
KAFKA-3125: Add Kafka Streams ExceptionsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #809 from guozhangwang/K3125,5
KAFKA-7819: Improve RoundTripWorker (#6187)RoundTripWorker to should use a long field for maxMessages rather than an int.  The consumer group used should unique as well.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-3842: consolidate utility methods to TestUtils…stUtils, added method for pausing tests to TestUtilsChanges made: 1. Added utility method for creating consumer configs. 2. Added methods for creating producer, consumer configs with default values for de/serializers. 3. Pulled out method for waiting for test state to TestUtils (not using Thread.sleep). 4. Added utility class for creating streams configs and methods providing default de/serializers.Author: bbejeck <bbejeck@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1532 from bbejeck/KAFKA_3842_add_helper_functions_test_utils",3
KAFKA-6732: Fix Streams doc ref link (#4806)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-8168; Add a generated ApiMessageType classAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen ShapiraCloses #6510 from cmccabe/KAFKA-8168,5
"MINOR: Fix internal topic manager tests (#11574)When the unit tests of the internal topic manager testare executed on a slow machine (like sometimes in automatic builds)they sometimes fail with a timeout exception instead of the expectedexception. To fix this behavior, this commit replaces the use ofsystem time with mock time.Reviewer: John Roesler <vvcephei@apache.org>",5
Check max message size on server; patched by Swapnil Ghike; reviewed by Joel Koshy and Jun Rao; KAFKA-490git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383730 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Clarify how to fix conversion issues when plain JSON data is used with schemas.enable=trueAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2041 from ewencp/clarify-json-converter-failure,5
"KAFKA-9850 Move KStream#repartition operator validation during Topolo… (#8550)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Upgrade to Gradle 4.8.1 (#5263)Maven Central dropped support for all versionsbut TLS 1.2, so dependency resolution fails ifGradle builds run with JDK 7. 2.0 and trunkrequre JDK 8, but every other version isaffected.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-8639: Replace AddPartitionsToTxn with Automated Protocol  (#8326)Part of the protocol automation effort.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-10279; Allow dynamic update of certificates with additional SubjectAltNames (#9044)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"MINOR: Improve topic management instructions for Kafka Streams examplesAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2812 from miguno/trunk-streams-examples-docs",2
MINOR: Replace EasyMock with Mockito in connect:basic-auth-extension (#11321)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-4049: Fix transient failure in RegexSourceIntegrationTestAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <me@ewencp.org>Closes #1746 from guozhangwang/K4049-RegexSourceIntegrationTest-failure",3
"MINOR: Remove duplicate `subscribe` call in ConsumerPerformance (#5828)In the `consume` method, the consumer subscribes the topic, so no need to dothe same thing before the method call. Also include minor clean-up in `consume`.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-5636: Add Sliding Windows documentation (#9264)Add necessary documentation for KIP-450, adding sliding window aggregations to KStreamsReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9700: Fix negative estimatedCompressionRatio (#8285)There are cases where `currentEstimation` is less than`COMPRESSION_RATIO_IMPROVING_STEP` causing`estimatedCompressionRatio` to be negative. This, in turn,may result in `MESSAGE_TOO_LARGE`.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"MINOR: move tiered storage related configs to a separate class within LogConfig (#11110)The original code uses a RemoteLogManagerConfig class to store KIP-405 configs and adds three configs to LogConfig. This makes the code complicated and developers may be confused.This PR allows us to access RemoteLogManagerConfig from KafkaConfig and do the same for LogConfig. Kafka developers will see the same interface for the KIP-405 configs. After this change, if we want to read remoteStorageEnable we should use LogConfig.tieredLogConfig.remoteStorageEnable instead of LogConfig.remoteStorageEnable. The same for localRetentionMs and localRetentionBytes. If we want to read configs in RemoteLogManagerConfig, we should use KafkaConfig.tieredKafkaConfig.xxx.Reviewers: Satish Duggana <satishd@apache.org>, Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"Add log message in release.py (#8461)When building a release candidate with release.py, if it's not the first RC, we need to drop the previous RC's artifacts from the staging repository before closing the new ones. This adds a log message to remind the release manager of this",2
"KAFKA-10555: Improve client state machine (#9720)Implements KIP-696: Add new state PENDING_ERROR to KafkaStreams client.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-6640; Improve efficiency of KafkaAdminClient.describeTopics() (#4694)Currently in KafkaAdminClient.describeTopics(), for each topic in the request, a complete map of cluster and errors will be constructed for every topic and partition. This unnecessarily increases the complexity of describeTopics() to O(n^2). This patch improves the complexity to O(n).Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-2892 Consumer Docs Use Wrong MethodThe KafkaConsumer docs use a non-existent method for assigning partitions (consumer.assign).The JavaDocs show as:```String topic = ""foo"";TopicPartition partition0 = new TopicPartition(topic, 0);TopicPartition partition1 = new TopicPartition(topic, 1);consumer.assign(partition0);consumer.assign(partition1);```Should be:```String topic = ""foo"";TopicPartition partition0 = new TopicPartition(topic, 0);TopicPartition partition1 = new TopicPartition(topic, 1);consumer.assign(Arrays.asList(partition0, partition1));```Author: Jesse Anderson <eljefe6a@gmail.com>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #592 from eljefe6a/trunk",1
"MINOR: Remove `updatePartitionReplicaAssignment` from `ControllerContext` (#7924)The method updatePartitionReplicaAssignment allows the user to directlymodify the replicas assigned to a partition without also modifying theaddingReplicas and removingReplicas fields. This is not a safe operationfor all inputs. Clients should instead use updatePartitionFullReplicaAssignment.Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Improve Join integration test coverage, PART I0. Rename `JoinIntegrationTest` to `StreamStreamJoinIntegrationTest`, which is only for KStream-KStream joins.1. Extract the `AbstractJoinIntegrationTest` which is going to be used for all the join integration test classes, parameterized with and without caching.2. Merge `KStreamRepartitionJoinTest.java` into `StreamStreamJoinIntegrationTest.java` with augmented stream-stream join.3. Add `TableTableJoinIntegrationTest` with detailed per-step expected results and removed `KTableKTableJoinIntegrationTest`.Findings of the integration test:1. Confirmed KAFKA-4309 with caching turned on.2. Found bug KAFKA-6398.3. Found bug KAFKA-6443.4. Found a bug that in CachingKeyValueStore, we would flush before putting the record into the underlying store, when the store is going to be used in the downstream processors with flushing it would result in incorrect results, fixed the issue along with this PR.5. Consider a new optimization described in KAFKA-6286.Future works including stream-table joins will be in other PRs.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #4331 from guozhangwang/KMinor-join-integration-tests",3
"KAFKA-3703; Graceful close for consumers and producer with acks=0Process requests received from channels before they were closed. For consumers, wait for coordinator requests to complete before returning from close.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1836 from rajinisivaram/KAFKA-3703",5
"KAFKA-3762 Log.loadSegments() should log the message in exceptionAdding an error logging message in Log.loadSegments() in the case when an index file corresponding to a log file exists but an exception is thrown.Signed-off-by: Ishita Mandhan <imandhaus.ibm.com>Author: Ishita Mandhan <imandha@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1480 from imandhan/KAFKA-3762",5
"MINOR: improve error logging in List De/Serializer classes (#11338)Our soak test application ran into an error constructing the ListDeserializer and crashed, but unfortunately the actual causing exception was not logged anywhere. This PR adds logging for this case, as well as a few others around this class and the corresponding serializer where additional logging would be helpfulReviewers: Guozhang Wang",2
"MINOR: Fix highest offset when loading KRaft metadata snapshots (#11386)When loading a snapshot the broker BrokerMetadataListener was using the batch's append time, offsetand epoch. These are not the same as the append time, offset and epoch from the log. This PR fixesit to instead use the lastContainedLogTimeStamp, lastContainedLogOffset and lastContainedLogEpochfrom the SnapshotReader.This PR refactors the MetadataImage and MetadataDelta to include an offset and epoch. It also swapsthe order of the arguments for ReplicaManager.applyDelta, in order to be more consistent withMetadataPublisher.publish.Reviewers: Colin P. McCabe <cmccabe@apache.org>",5
MINOR: Fix version range check in MessageTest (#7663)This patch fixes the test utility `testAllMessageRoundTripsFromVersion` in `MessageTest` which was unintentionally excluding the highest version.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-9577; SaslClientAuthenticator incorrectly negotiates SASL_HANDSHAKE version (#8142)The SaslClientAuthenticator incorrectly negotiates supported SaslHandshakeRequest version and  uses the maximum version supported by the broker whether or not the client supports it. This bug was exposed by a recent version bump in https://github.com/apache/kafka/commit/0a2569e2b9907a1217dd50ccbc320f8ad0b42fd0.This PR rolls back the recent SaslHandshake[Request,Response] bump, fixes the version negotiation, and adds a test to prevent anyone from accidentally bumping the version without a workaround such as a new ApiKey. The existing key will be difficult to support for clients < 2.5 due to the incorrect negotiation.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>, Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
trivial fix to authorization CLI table,0
"MINOR: Correctly mark offset expiry in GroupMetadataManager's OffsetExpired metricWe would mistakenly increment the `OffsetCommits` metric insteadAuthor: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>Reviewers: David Jacot <djacot@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7624 from stanislavkozlovski/minor-fix-group-coordinator-offset-expiry-metric",0
KAFKA-12597: Remove deprecated --zookeeper option in ReassignPartitionsCommand (#10471)Also remove zookeeper dependent methods and tests.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"[KAFKA-7024] Rocksdb state directory should be created before opening the DB (#6138)In RocksDBStore.openDB we callFiles.createDirectories(dir.getParentFile().toPath()); return RocksDB.open(options, dir.getAbsolutePath());We would also add the absolute file path as well to avoid the extra logging.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13104: Controller should notify raft client when it resigns #11082When the active controller encounters an event exception it attempts to renounce leadership.Unfortunately, this doesn't tell the RaftClient that it should attempt to give up leadership. Thiswill result in inconsistent state with the RaftClient as leader but with the controller asinactive.  This PR changes the implementation so that the active controller asks the RaftClientto resign.Reviewers: Jose Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",4
"MINOR: Use Exit.exit instead of System.exit in MM2 (#8321)Exit.exit needs to be used in code instead of System.exit.Particularly in integration tests using System.exit is disrupting because it exits the jvm process and does not just fail the test correctly. Integration tests override procedures in Exit to protect against such cases.Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Randall Hauch <rhauch@gmail.com>",3
KAFKA-916; Break deadlock between fetcher shutdown and error partition handling; reviewed by Jun Rao.,0
KAFKA-1943; MessageSizeTooLarge and MessageSetSizeTooLarge should not be counted toward broker-side producer failure rate,0
HOTFIX: remove old security suggestions,4
"KAFKA-9810: Document Connect Root REST API on / (#8408)Document the supported endpoint at the top-level (root) REST API resource and the information that it returns when a request is made to a Connect worker.Fixes an omission in documentation after KAFKA-2369 and KAFKA-6311 (KIP-238)Reviewers: Toby Drake <tobydrake7@gmail.com>, Soenke Liebau <soenke.liebau@opencore.com>",2
MINOR: Fix few typos in the javadocs/docs,2
MINOR: Fix typo in the Admin API Javadoc example (#11243)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-13935 Fix static usages of IBP in KRaft mode (#12250)* Set the minimum supported MetadataVersion to 3.0-IV1* Remove MetadataVersion.UNINITIALIZED* Relocate RPC version mapping for fetch protocols into MetadataVersion* Replace static IBP calls with dynamic calls to MetadataCacheA side effect of removing the UNINITIALIZED metadata version is that the FeatureControlManager and FeatureImage will initialize themselves with the minimum KRaft version (3.0-IV1).The rationale for setting the minimum version to 3.0-IV1 is so that we can avoid any cases of KRaft mode running with an old log message format (KIP-724 was introduced in 3.0-IV1). As a side-effect of increasing this minimum version, the feature level values decreased by one.Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-6145: KIP-441 Pt. 6 Trigger probing rebalances until group is stable (#8409)Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-9016; Warn when log dir stopped serving replicasAuthor: uttpal <kumar.uttpal@oyorooms.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #7563 from uttpal/KAFKA-9016",2
"KAFKA-8107; Flaky Test kafka.api.ClientIdQuotaTest.testQuotaOverrideDelete (#8394)Invoke `waitForQuotaUpdate` after the quotas are removed. It also changesthe default request quota to `Long.MaxValue`.Reviewers: Anna Povzner <anna@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-8111; Set min and max versions for Metadata requests (#6451)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"KAFKA-13883: Implement NoOpRecord and metadata metrics (#12183)Implement NoOpRecord as described in KIP-835. This is controlled by the newmetadata.max.idle.interval.ms configuration.The KRaft controller schedules an event to write NoOpRecord to the metadata log if the metadataversion supports this feature. This event is scheduled at the interval defined inmetadata.max.idle.interval.ms. Brokers and controllers were improved to ignore the NoOpRecord whenreplaying the metadata log.This PR also addsffour new metrics to the KafkaController metric group, as described KIP-835.Finally, there are some small fixes to leader recovery. This PR fixes a bug where metadata version3.3-IV1 was not marked as changing the metadata. It also changes the ReplicaControlManager toaccept a metadata version supplier to determine if the leader recovery state is supported.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
MINOR: Make JoinGroupRequest and LeaveGroupRequest 'Reason' field ignorable (KIP-800) (#11679)The `Reason` field must be ignorable otherwise new client does not work with older brokers.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-8448: Cancel PeriodicProducerExpirationCheck when closing a Log instance (#6847)Cancel PeriodicProducerExpirationCheck when closing a Log instance, to avoid a memory leak.  Add a method to KafkaScheduler to make this possible.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",1
fix log4j to avoid duplicating log entries in kafkagit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1158447 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-2814: Make Kafka Connect system test REST requests use hostname that is compatible with running under AWS.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #517 from ewencp/kafka-2814-connect-rest-on-aws,1
"MINOR: Fix use of ConfigException in AbstractConfig class (#11349)* Log full trace for class-not-found errors, improve accuracy of error messagesReviewers: Tom Bentley <tbentley@redhat.com>",0
"KAFKA-3499: prevent array typed keys in KeyValueStoreAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma, Josh Gruenberg, Michael G. Noll, Ewen Cheslack-PostavaCloses #1229 from guozhangwang/K3499",5
"MINOR: Improve decimal scale mismatch error message in Connect (#11384)Use term Decimal, rather than BigDecimal.Reviewers: Tom Bentley <tbentley@redhat.com>",1
MINOR: Enable topic deletion in test configs (#5616)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: Collect metadata log dir in kraft system tests (#12215)It is useful to collect the directory for `__cluster_metadata` in system tests. We use a separate directory from user partitions, so it must be configured separately. Reviewers: David Arthur <mumrah@gmail.com>",5
KAFKA-10306: GlobalThread should fail on InvalidOffsetException (#9075)* KAFKA-10306: GlobalThread should fail on InvalidOffsetException* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>,1
KAFKA-6123: Give client MetricsReporter auto-generated client.id (#5383),5
"KAFKA-12347: updating TaskMetadata (#10211)added committed offset, high watermark and idle duration to the taskMetadata.Reviewers: Boyang Chen <boyang@confluent.io>",5
"KAFKA-13763: Refactor IncrementalCooperativeAssignor for improved unit testing (#11983)The goals here include:1. Create an overloaded variant of the IncrementalCooperativeAssignor::performTaskAssignment method that is more testing friendly2. Simplify the parameter list for the IncrementalCooperativeAssignor::handleLostAssignments method, which in turn simplifies the logic for testing this class3. Capture repeated Java 8 streams logic in simple, reusable, easily-verifiable utility methods added to the ConnectUtils classReviewers: Luke Chen <showuon@gmail.com>",1
"KAFKA-8968: Refactor task-level metrics (#7566)Introduces TaskMetrics classIntroduces dropped-recordsReplaces skipped-records with dropped-records with latest built-inmetrics versionDoes not add standby-process-ratio and active-process-ratioDoes not refactor parent sensors for processor node metricsReviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: Document ordering contract of iterator for window stores and session storesAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2751 from miguno/trunk-streams-window-iterator-doc-fixes",2
MINOR: Log error when storing assignment fails (#12526)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-5311: Support ExtendedDeserializer in Kafka StreamsAuthor: Dale Peakall <dale@peakall.net>Reviewers: Michael André Pearce <michael.andre.pearce@me.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3199 from subnova/streams-extendeddeserializer",5
MINOR: remove unnecessary null checkAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3445 from mjsax/minor-remove-null-check,4
"MINOR: Create a new topic for each test for flaky RegexSourceIntegrationTest (#6853)The RegexSourceIntegrationTest has some flakiness as it deletes and re-creates the same output topic before each test. This PR reduces the chance for errors by creating a unique output topic for each test.Reviewers:  Matthias J. Sax <mjsax@apache.org>,  Boyang Chen <boyang@confluent.io>",5
"KAFKA-5733: RocksDB bulk load with lower number of levelsThis is to complete Bill's PR #3664 on KAFKA-5733, incorporating the suggestion in https://github.com/facebook/rocksdb/issues/2734.Some minor changes: move `open = true` in `openDB`.Author: Bill Bejeck <bill@confluent.io>Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3681 from guozhangwang/K5733-rocksdb-bulk-load",5
"MINOR: fix Scala compiler warning (#6417)Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",2
MINOR: Fix javadoc warnings (#8809)This commit fixes javadoc warnings caused by missing imports.Reviewers: Bill Bejeck <bbejeck@apache.org>,2
"MINOR: Add logging to Connect SMTsIncludes Update to ConnectRecord string representation to givevisibility into schemas, useful in SMT tracingAuthor: Cyrus Vafadari <cyrus@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5860 from cyrusv/cyrus-logging",2
"KAFKA-4551: StreamsSmokeTest.test_streams intermittent failureRemove use of TestTimestampExtractor as it causes the logs to roll and segments get deleted.Remove the wcnt example as it is dependent on the TestTimestampExtractor - windowed counting is covered elsewhere.Change all aggregate operations to use TimeWindow as use of UnlimitedWindow was causing logs to roll and segments being deleted.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang Wang, Eno ThereskaCloses #2319 from dguy/smoke-test",3
KAFKA-1279 Socket server should close all connections when it is shutdown.,5
"KAFKA-10894; Ensure PartitionInfo replicas are not null in client quota callback (#9802)Previously offline replicas were included as `null` in the array of replicas in `PartitionInfo` when populated by the `MetadataCache` for the purpose of the client quota callback. This patch instead initializes empty non-null nodes, which is consistent with how `PartitionInfo` is constructed by the clients in `MetadataResponse`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-5055: Fix Kafka Streams skipped-records-rate sensor bugFix as described in the [KAFKA-5055 Jira comment](https://issues.apache.org/jira/browse/KAFKA-5055?focusedCommentId=15990086&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15990086).mjsax guozhangwang take a lookAuthor: dpoldrugo <dpoldrugo@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2949 from dpoldrugo/KAFKA-5055-skipped-records-rate-sensor-bug",0
KAFKA-1550; Patch review tool should use git format-patch for patch generation; reviewed by Guozhang Wang and Joel Koshy,1
MINOR: Add upgrade notes for KIP-62Author: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1956 from hachikuji/add-kip-62-upgrade-notes,1
"KAFKA-6970: All standard state stores guarded with read only wrapper (#6016)Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-7039: Create an instance of the plugin only it's a Versioned PluginCreate an instance of the plugin only it's a Versioned Plugin. Prior to KIP-285, this was done for only for Connector and this PR will continue to have the same behavior.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5191 from mageshn/KAFKA-7039",5
"Trogdor: Added commonClientConf and adminClientConf to workload specs (#4757)Currently, WorkerUtils will be able to create topics when there is no security. To be able to work with secure kafka, WorkerUtils.createTopic() needs to be able to take security configs. This PR adds commonClientConf field to both producer bench and roundtrip workload specs so that users can specify security and other common configs once for producer/consumer and adminClient. Also added adminClientConf field to workload specs so that users can specify adminClient specific configs if they want to. For completeness, added consumerConf and producerConf to roundtrip workload spec.Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Hint about ""docker system prune"" when ducker-ak build fails (#10995)Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Jason Gustafson <jason@confluent.io>",5
add JMX on broker to track bytes/messages per topic; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-272git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1244755 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9627: Replace ListOffset request/response with automated protocol (#8295)Reviewers: Boyang Chen <reluctanthero104@gmail.com>, David Jacot <djacot@confluent.io>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",5
MINOR: Fix exception message in Copycat's Time logical type.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #291 from ewencp/fixup-time-logical-type,2
"KAFKA-13967: Document guarantees for producer callbacks on transaction commit (#12264)Clarify in producer docs that `send` callbacks are invoked prior to transaction completion.Reviewers: Tom Bentley <tbentley@redhat.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Include StickyAssignor in system tests (#5223)Reviewers: Jason Gustafson <jason@conflent.io>,5
"KAFKA-2476: Add Decimal, Date, and Timestamp logical types.To support Decimal, this also adds support for schema parameters, which is anextra set of String key value pairs which provide extra information about theschema. For Decimal, this is used to encode the scale parameter, which is partof the schema instead of being passed with every value.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #281 from ewencp/kafka-2476-copycat-logical-types",2
MINOR: Small refactorings on KTable joins (#5540)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
fixed incubation urlSigned-off-by: Joe Stein <joestein@apache.org>,0
KAFKA-2258: add failover to mirrormaker testThis PR adds failover to simple end to end mirror maker testMarked as WIP for 2 reasons:- We may want to add a couple more test cases where kafka is being used to store offsets- There appears to be a test failure in the hard failover caseAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-PostavaCloses #427 from granders/KAFKA-2258-mirrormaker-test,3
KAFKA-12922: MirrorCheckpointTask should close topic filter (#10849)Reviewers: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Daniel Urban <durban@cloudera.com>,5
"KAFKA-2405; Don't kill the JVM on session establishment failureAs noted in the JIRA https://issues.apache.org/jira/browse/KAFKA-2405 currently the KafkaHealthCheck causes the JVM to terminate in cases where session establishment with Zookeeper fails. I don't know if retrying (after a while) is a better way to fix this but at least, IMO, the session establishment failure shouldn't kill the JVM. This commit removes the `System.exit()` call.Author: Jaikiran Pai <jaikiran.pai@gmail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>Closes #111 from jaikiran/kafka-2405 and squashes the following commits:0255fdb [Jaikiran Pai] KAFKA-2405 Don't kill the JVM on session establishment failure",0
"KAFKA-955 (followup patch) After a leader change, messages sent with ack=0 are lost; reviewed by Neha Narkhede and Jun Rao",4
"KAFKA-8991: Enable scalac optimizer (#7452)The scalac optimizer is able to inline methods to avoid lambda allocations, eliminatingthe runtime cost of higher order functions in many cases. The compilation parameterswe are using here were introduced in 2.12.x, so we don't enable them for Scala 2.11.Also, we enable a more aggressive inlining policy for the `core` project since it'snot meant to be used as a library.See https://www.lightbend.com/blog/scala-inliner-optimizer for more information aboutthe optimizer.I verified that the lambda allocation in the code below (from LogCleaner.scala) went awayafter this change with Scala 2.12 and 2.13.```scalaprivate def consumeAbortedTxnsUpTo(offset: Long): Unit = {  while (abortedTransactions.headOption.exists(_.firstOffset <= offset)) {    val abortedTxn = abortedTransactions.dequeue()    ongoingAbortedTxns.getOrElseUpdate(abortedTxn.producerId, new AbortedTransactionMetadata(abortedTxn))  }}```The relevant part of the bytecode when compiled with Scala 2.13 looks like:```textprivate void consumeAbortedTxnsUpTo(long);    Code:       0: aload_0       1: invokespecial #54                 // Method abortedTransactions:()Lscala/collection/mutable/PriorityQueue;       4: invokevirtual #175                // Method scala/collection/mutable/PriorityQueue.headOption:()Lscala/Option;       7: dup       8: ifnonnull     13      11: aconst_null      12: athrow      13: astore        4      15: aload         4      17: invokevirtual #145                // Method scala/Option.isEmpty:()Z      20: ifne          48      23: aload         4      25: invokevirtual #148                // Method scala/Option.get:()Ljava/lang/Object;      28: checkcast     #177                // class kafka/log/AbortedTxn```The increased inlining causes some spurious spotBugs warnings, I added a few suppressionsand fixed one warning by avoiding unnecessary boxing.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
kafka-896; merge 0.8 (988d4d8e65a14390abd748318a64e281e4a37c19) to trunk; patched by Jun Rao; reviewed by Jay Kreps,1
KAFKA-3439; Added exceptions thrownAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang WangCloses #1213 from enothereska/KAFKA-3439-throws,1
"MINOR: Increase timeout of Zookeeper service in system testsThe previous timeout was 10 seconds, but system test failures have occurred when Zookeeper has started after about 11 seconds. Increasing the timeout to 30 seconds, since most of the time this extra time will not be required, and when it is it will prevent a failed system test.In addition to merging to `trunk`, please backport to the `0.11.x` and `0.10.2.x` branches.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3774 from rhauch/MINOR-Increase-timeout-of-zookeeper-service-in-system-tests",5
"KAFKA-8992; Redefine RemoveMembersFromGroup interface on AdminClient  (#7478)This PR fixes the inconsistency involved in the `removeMembersFromGroup` admin API calls:1. Fail the `all()` request when there is sub level error (either partition or member)2. Change getMembers() to members()3. Hide the actual Errors from user4. Do not expose generated MemberIdentity type5. Use more consistent naming for Options and Result typesReviewers: Guozhang Wang <wangguoz@gmail.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Use SecurityProtocol in AuthenticationContextSince we removed the unused `TRACE` option from `SecurityProtocol`, it now seems safer to expose it from `AuthenticationContext`. Additionally this patch exposes javadocs under security.auth and relocates the `Login` and `AuthCallbackHandler` to a non-public package.Author: Jason Gustafson <jason@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3863 from hachikuji/use-security-protocol-in-auth-context",1
"KAFKA-9669; Loosen validation of inner offsets for older message formats (#8647)Prior to KAFKA-8106, we allowed the v0 and v1 message formats to contain non-consecutive inner offsets. Inside `LogValidator`, we would detect this case and rewrite the batch. After KAFKA-8106, we changed the logic to raise an error in the case of the v1 message format (v0 was still expected to be rewritten). This caused an incompatibility for older clients which were depending on the looser validation. This patch reverts the old logic of rewriting the batch to fix the invalid inner offsets.Note that the v2 message format has always had stricter validation. This patch also adds a test case for this.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Optimize the matches method of AccessControlEntryFilter (#11768)* MINOR: Make the getters in match method in AccessControlEntryFilter consistencyReviewers: Luke Chen <showuon@gmail.com>,1
"KAFKA-10702; Skip bookkeeping of empty transactions (#9632)Compacted topics can accumulate a large number of empty transaction markers as the data from the transactions gets cleaned. For each transaction, there is some bookkeeping that leaders and followers must do to keep the transaction index up to date. The cost of this overhead can degrade performance when a replica needs to catch up if the log has mostly empty or small transactions. This patch improves the cost by skipping over empty transactions since these will have no effect on the last stable offset and do not need to be reflected in the transaction index.Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-3259 KAFKA-3253; KIP-31/KIP-32 Follow-upThis PR includes a number of clean-ups:* Code style* Documentation wording improvements* Efficiency improvementsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #943 from ijuma/kafka-3259-kip-31-32-clean-ups,4
"KAFKA-12554: Refactor Log layer (#10280)TL;DR:This PR implements the details of the Log layer refactor, as outlined in this document: https://docs.google.com/document/d/1dQJL4MCwqQJSPmZkVmVzshFZKuFy_bCPtubav4wBfHQ/edit. Few details maybe different from the doc, but it is more or less the same.STRATEGY:In this PR, I've extracted a new class called LocalLog out of Log. Currently LocalLog is purely an implementation detail thats not exposed outside Log class (except for tests). The object encapsulation is that each Log instance wraps around a LocalLog instance.This new LocalLog class attempts to encompass most of the responsibilities of local log surrounding the segments map, which otherwise were present in Log previously. Note that not all local log responsibilities have been moved over to this new class (yet). The criteria I used was to preserve (for now) in existing Log class, any logic that is mingled in a complex manner with the logStartOffset or the LeaderEpochCache or the ProducerStateManager.Reviewers: Ismael Juma <ismael@juma.me.uk>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2
"KAFKA-4635; Client Compatibility follow-upsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2414 from cmccabe/KAFKA-4635",5
"MINOR: Fix broker compatibility testsUpdated the System test `stream_broker_compatibility_test.py` to address system test failures as we have removed explicit broker version checking- Ignore the `0.8.2.2` and `0.9.0.0` tests because the `NetworkClient` only logs `UnsupportedVersionException`s that occur and will continue to retry connecting.  Once issue https://issues.apache.org/jira/browse/KAFKA-6297 is addressed, we may re-enable these tests.- Updated existing tests expected error messages- Updated Streams code in test for to make sure we fail fast for incompatible brokersAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4286 from bbejeck/MINOR_fix_broker_compatibility_tests",3
"KAFKA-5119; Ensure global metrics are empty before running testMetricCollectionAfterShutdownDepending on the test execution order, the global registry wouldcontain some metrics causing the test to fail.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>Closes #2915 from ijuma/socket-server-test-metric-collection-after-shutdown",3
"KAFKA-14170: Fix NPE in the deleteTopics() code path of KRaft Controller (#12533)Fix a bug in ReplicationControlManager where we got a NullPointerException when removing a topicwith no offline replicas, and there were other topics that did have offline replicas.Fix an issue in MetadataDelta#replay where we were replaying RemoveTopicRecord twice.Reviewers: Colin P. McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",4
"MINOR: Fix the generation extraction util (#10204)Reviewers: Matthias J. Sax <matthias@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-1914; follow-up to address unit test failure,0
"KAFKA-3595: window stores use compact,delete config for changelogschangelogs of window stores now configure cleanup.policy=compact,delete with retention.ms set to window maintainMs + StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIGStoreChangeLogger produces messages with context.timestamp().Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1792 from dguy/kafka-3595",5
KAFKA-830 partition replica assignment map in the controller should be a Set; reviewed by Jun Rao and Swapnil Ghike,1
fix string formatting; write data to stdout in ConsumerShellgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1164353 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-1854 Allow JIRA username and password to be prompted in the absence of a jira.ini file, during patch submission; reviewed by Neha Narkhede",2
MINOR: Fix JavaDoc of OffsetIndex#append (#11744)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"MINOR: add upgrade guide for Kafka Streams APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Eno ThereskaCloses #2114 from mjsax/updateDocUpgradeSection",5
"MINOR: make the constructor of InMemoryKeyValueStore public so that it can be re-used by custom (in-memory) stores (#5310)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3007: implement max.poll.records (KIP-41)Author: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #931 from hachikuji/KAFKA-3007",5
KAFKA-3445: Validate TASKS_MAX_CONFIG's lower boundCurrently the property TASKS_MAX_CONFIG is not validated against nonsensical values such as 0. This patch leverages the Range.atLeast() method to ensure value is at least 1.Author: Ryan P <Ryan.N.Pridgeon@Gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1132 from rnpridgeon/KAFKA-3445,5
trival fix to remove 2 empty filesgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397623 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Remove kafka-consumer-offset-checker.bat for KAFKA-3356 (#4703),1
MINOR: Remove unused imports from tests whose packages were fixedI missed this when reviewing:https://github.com/apache/kafka/commit/a58b459bddd5b1dcab224b53cda0196e947a5b09Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #836 from ijuma/remove-unused-imports,4
kafka-1390; TestUtils.waitUntilLeaderIsElectedOrChanged may wait longer than it needs; patched by Jun Rao; reviewed by Guozhang Wang,3
Improve Kafka internal metrics; patched by Jun Rao; reviewed by Joel Koshy and Neha Narkhede; KAFKA-203git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1384202 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: list-topics should not require topic param`kafka.list_topics(...)` should not require a topic parameterAuthor: Brian Bushree <bbushree@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #6367 from brianbushree/list-topics-no-topic,5
"KAFKA-13957: Fix flaky shouldQuerySpecificActivePartitionStores test (#12289)Currently the tests fail because there is a missing predicate in the retrievableException which causes the test to fail, i.e. the current predicatescontainsString(""Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING""),containsString(""The state store, source-table, may have migrated to another instance""),containsString(""Cannot get state store source-table because the stream thread is STARTING, not RUNNING"")wasn't complete. Another one needed to be added, namely ""The specified partition 1 for store source-table does not exist."". This is because its possible forassertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));orassertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));(depending on which branch) to be thrown, i.e. seeorg.apache.kafka.streams.errors.InvalidStateStorePartitionException: The specified partition 1 for store source-table does not exist.at org.apache.kafka.streams.state.internals.WrappingStoreProvider.stores(WrappingStoreProvider.java:63)at org.apache.kafka.streams.state.internals.CompositeReadOnlyKeyValueStore.get(CompositeReadOnlyKeyValueStore.java:53)at org.apache.kafka.streams.integration.StoreQueryIntegrationTest.lambda$shouldQuerySpecificActivePartitionStores$5(StoreQueryIntegrationTest.java:223)at org.apache.kafka.streams.integration.StoreQueryIntegrationTest.retryUntil(StoreQueryIntegrationTest.java:579)at org.apache.kafka.streams.integration.StoreQueryIntegrationTest.shouldQuerySpecificActivePartitionStores(StoreQueryIntegrationTest.java:186)This happens when the stream hasn't been initialized yet. I have run the test around 12k times using Intellij's JUnit testing framework without any flaky failures. The PR also does some minor refactoring regarding moving the list of predicates into their own functions.Co-authored-by: Bruno Cadonna <cadonna@apache.org>Reviewer: Bruno Cadonna <cadonna@apache.org>",1
KAFKA-9922: Update demo instructions in examples README (#8559)Class kafka.examples.SimpleConsumerDemo was removed. But the java-simple-consumer-demo.sh was not removed and README was not updated.This commit removes java-simple-consumer-demo.sh and updates the demo instructions in the examples README. Author: Jiamei Xie <jiamei.xie@arm.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>,5
KAFKA-6184; report a metric of the lag between the consumer offset ...Add `records-lead` and partition-level `{topic}-{partition}.records-lead-min|avg` for fetcher metrics.junrao  Please kindly review. Thanks.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #4191 from huxihx/KAFKA-6184,1
"KAFKA-12432: AdminClient should time out nodes that are never ready (#10281)Previously, if we assigned one or more calls to a remote node, but itnever became available, AdminClient would block until the calls hittheir the API timeout.  This was particularly unfortunate in the casewhere the calls could have been sent to a different node in the cluster.This PR fixes this behavior by timing out pending connections toremote nodes if they take longer than the request timeout.There are a few other small cleanups in this PR: it removes theunecessary Call#aborted, sets Call#curNode to null after the call hasfailed to avoid confusion when debugging or logging, and adds a""closing"" boolean rather than setting newCalls to null when the clientis closed.  Also, it increases the log level of the log message thatindicates that we timed out some calls because AdminClient closed,and simplifies the type of callsInFlight.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-12574: KIP-732, Deprecate eos-alpha and replace eos-beta with eos-v2 (#10573)Deprecates the following 1. StreamsConfig.EXACTLY_ONCE2. StreamsConfig.EXACTLY_ONCE_BETA3. Producer#sendOffsetsToTransaction(Map offsets, String consumerGroupId)And introduces a new StreamsConfig.EXACTLY_ONCE_V2 config. Additionally, this PR replaces usages of the term ""eos-beta"" throughout the code with the term ""eos-v2""Reviewers: Matthias J. Sax <mjsax@confluent.io>",5
"MINOR: Remove throwing exception if not found from describe topics (#6112)We recently improved the handling of the InternalTopicManager retries with #6085. The AdminClient will throw an InvalidTopicException if the topic is not found. We need to ignore that exception as when calling AdminClient#describe we may not have had a chance to create the topic yet, especially with the case of internal topicsI've created a new test asserting that when an InvalidTopicException is thrown when the topic is not found we continue on.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Add check for empty topics iterator in ReplicaVerificationTool.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang Wang, Gwen ShapiraCloses #1167 from SinghAsDev/minorFixRelicaLagTool",0
"KAFKA-12926: ConsumerGroupCommand's java.lang.NullPointerException at negative offsets while running kafka-consumer-groups.sh (#10858)This patch fixes the `ConsumerGroupCommand` to correctly handle missing offsets, which are returned as `null` by the admin API.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: Bump version to 0.9.1.0-SNAPSHOTSince we created the 0.9.0 branch a while back.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #575 from ijuma/bump-to-0.9.1.0-SNAPSHOT,1
KAFKA-4364: Remove secrets from DEBUG loggingleverage fix from KAFKA-2690 to remove secrets from task loggingAuthor: rnpridgeon <ryan.n.pridgeon@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2115 from rnpridgeon/KAFKA-4364,5
"KAFKA-7050; Decrease default consumer request timeout to 30s (#5203)This patch changes the default `request.timeout.ms` of the consumer to 30 seconds. Additionally, it adds logic to `NetworkClient` and related to components to support timeouts at the request level. We use this to handle the special case of the JoinGroup request, which may block for as long as the value configured by `max.poll.interval.ms`.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Fix format violations streams scala tests (#5402)@guozhangwang @mjsax hot fix for streams scala test format violationsReviewers: Guozhang Wang <wangguoz@gmail.com>,3
"MINOR: add ConfigUtils method for printing configurations (#10714)Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>",5
"MINOR: Default GroupInitialRebalanceDelayMsProp to 0 and OffsetsTopicPartitionsProp to 5 in testsThis should make tests faster. Tests that require specific values can override these values.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3236 from ijuma/default-initial-rebalance-delay-and-offsets-topic-partitions",5
KAFKA-2742: Fix SourceTaskOffsetCommitter to handle removal of commit tasks when they are already in progress.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #421 from ewencp/wait-on-in-progress-source-offset-commits,1
"KAFKA-1323; Fix regression due to KAFKA-1315 (support for relativedirectories in log.dirs property broke). Patched by Timothy Chen andGuozhang Wang; reviewed by Joel Koshy, Neha Narkhede and Jun Rao.",5
"KAFKA-8743: Flaky Test Repartition{WithMerge}OptimizingIntegrationTest (#7472)All four flavors of the repartition/optimization tests have been reported as flaky and failed in one place or another:* RepartitionOptimizingIntegrationTest.shouldSendCorrectRecords_OPTIMIZED* RepartitionOptimizingIntegrationTest.shouldSendCorrectRecords_NO_OPTIMIZATION* RepartitionWithMergeOptimizingIntegrationTest.shouldSendCorrectRecords_OPTIMIZED* RepartitionWithMergeOptimizingIntegrationTest.shouldSendCorrectRecords_NO_OPTIMIZATIONThey're pretty similar so it makes sense to knock them all out at once. This PR does three things:* Switch to in-memory stores wherever possible* Name all operators and update the Topology accordingly (not really a flaky test fix, but had to update the topology names anyway because of the IM stores so figured might as well)* Port to TopologyTestDriver -- this is the ""real"" fix, should make a big difference as these repartition tests required multiple roundtrips with the Kafka cluster (while using only the default timeout)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5515; Remove date formatting from SegmentsRemove date formatting from `Segments` and use the `segementId` instead.Add tests to make sure can load old segments.Rename old segment dirs to new formatting at load time.Author: Damian Guy <damian.guy@gmail.com>Reviewers: tedyu <yuzhihong@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3783 from dguy/kafka-5515",5
avoid logging stacktrace directly; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-231git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1226599 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12155: Metadata log and snapshot cleaning #10864This PR includes changes to KafkaRaftClient and KafkaMetadataLog to support periodiccleaning of old log segments and snapshots.Four new public config keys are introduced: metadata.log.segment.bytes,metadata.log.segment.ms, metadata.max.retention.bytes, andmetadata.max.retention.ms.These are used to configure the log layer as well as the snapshot cleaning logic. Snapshotand log cleaning is performed based on two criteria: total metadata log + snapshot size(metadata.max.retention.bytes), and max age of a snapshot (metadata.max.retention.ms).Since we have a requirement that the log start offset must always align with a snapshot,we perform the cleaning on snapshots first and then clean what logs we can.The cleaning algorithm follows:1. Delete the oldest snapshot.2. Advance the log start offset to the new oldest snapshot.3. Request that the log layer clean any segments prior to the new log start offset4. Repeat this until the retention size or time is no longer violated, or only a singlesnapshot remains.The cleaning process is triggered every 60 seconds from the KafkaRaftClient pollingthread.Reviewers: José Armando García Sancio <jsancio@gmail.com>, dengziming <dengziming1993@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",4
"KAFKA-12483: Enable client overrides in connector configs by default (KIP-722) (#10336)Changes the default value for the `connector.client.config.override.policy` worker configuration property from `None` to `All`. Modified unit tests to verify all policies still work, and that by default connectors can override all client policies.See https://cwiki.apache.org/confluence/display/KAFKA/KIP-722%3A+Enable+connector+client+overrides+by+defaultUpdated the documentation for the worker's client overrides policy to mention the new default.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-3522: add missing guards for TimestampedXxxStore (#6356)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
commit missing code,5
"KAFKA-7080 and KAFKA-7222: Cleanup overlapping KIP changes Part 2#5804 removed `Windows#segmentInterval`, but did not remove all references to it.Author: John Roesler <john@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5806 from vvcephei/fix-missing-segment-interval",0
MINOR: CollectionUtils.groupDataByTopic in OffsetsForLeaderEpochRequest/ResponseAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2821 from benstopford/kip-101-cleanup-group-by,4
HOTFIX: update Streams security docs,2
MINOR: Remove retries entry from Streams config table (#8733)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Remove ignored tests that hang, added new versions for EOS tests (#5666)Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-13284: Use sftp to upload artifacts in release.py (#11394)- automatically upload artifacts to Apache Home using sftp- fix the logic to find JDK 17Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: missing fullstop in doc for `max.partition.fetch.bytes`Author: Shikhar Bhushan <shikhar@schmizz.net>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1969 from shikhar/patch-2,5
"KAFKA-5679; Add logging for broker termination due to SIGTERM or SIGINTThis depends on sun.misc.Signal and sun.misc.SignalHandler, which may beremoved in future releases. But along with sun.misc.Unsafe, these classesare available in Java 9 (see JEP 260), so they are safe to use for now.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3668 from rajinisivaram/KAFKA-5679",5
KAFKA-4339; Update system tests to accommodate the new consumer group describe outputAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2061 from vahidhashemian/KAFKA-4339,1
MINOR: Upgrade ducktape to 0.7.6Author: Brian Bushree <bbushree@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #7138 from brianbushree/update-ducktape,5
"KAFKA-10500: Makes the Stream thread list resizable (#9543)Change the StreamThreads to be held in a List so that wecan dynamically change the number of threads easily.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-13803: Refactor Leader API Access (#12005)This PR refactors the leader API access in the follower fetch path.Added a LeaderEndPoint interface which serves all access to the leader.Added a LocalLeaderEndPoint and a RemoteLeaderEndPoint which implements the LeaderEndPoint interface to handle fetches from leader in local & remote storage respectively.Reviewers: David Jacot <djacot@confluent.io>, Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"MINOR: Reduce sends created by `SendBuilder` (#9619)This patch changes the grouping of `Send` objects created by `SendBuilder` in order to reduce the number of generated `Send` objects and thereby the number of system writes.Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"HOTFIX: fix threading issue in MeteredKeyValueStore`MeteredKeyValueStore` wasn't thread safe. Interleaving operations could modify the state, i.e, the `key` and/or `value` which could result in incorrect behaviour.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3588 from dguy/hotfix-metered-kv-store",0
"KAFKA-12928: Add a check whether the Task's statestore is actually a directory (#10862)Throw an exception if a state directory exists as a regular fileReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Luke Chen <showuon@gmail.com>",2
MINOR: Fixed a few typos in configs and streams docs (#4452)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-3578: Allow cross origin HTTP requests on all HTTP methodsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1288 from Ishiihara/kip-56,5
MINOR: Improve EOS example exception handling (#8052)The current EOS example mixes fatal and non-fatal error handling. This patch fixes this problem and simplifies the example.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-8805; Bump producer epoch on recoverable errors (#7389)This change is the client-side part of KIP-360. It identifies cases where it is safe to abort a transaction, bump the producer epoch, and allow the application to continue without closing the producer. In these cases, when KafkaProducer.abortTransaction() is called, the producer sends an InitProducerId following the transaction abort, which causes the producer epoch to be bumped. The application can then start a new transaction and continue processing.For recoverable errors in the idempotent producer, the epoch is bumped locally. In-flight requests for partitions with an error are rewritten to reflect the new epoch, and in-flights of all other partitions are allowed to complete using the old epoch. Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8039 - Use MockTime in fast reauth test to avoid transient failures (#6383)Test uses 100ms as connections.max.reauth.ms and checks that a second reauthentication doesn't occur within the hard-coded 1 second minimum interval. But since the interval is small, we cannot guarantee that the time between the two checks is not higher than 1 second. Change the test to use MockTime so that we can control the time.Reviewers: Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
KAFKA-10497 Convert group coordinator metadata schemas to use generat… (#9318)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-4251: fix test driver not launching in Vagrant 1.8.6custom ip resolver in test driver makes incorrect assumption when calling vm.communicate.execute, causing driver to fail launching with Vagrant 1.8.6, due to https://github.com/mitchellh/vagrant/pull/7676Author: Xavier Léauté <xavier@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1962 from xvrl/fix-vagrant-resolver",0
"KAFKA-2389: remove commit type from new consumer.A shot to remove commit type from new consumer. The coordinator constructor takes a default offset commit callback mainly for testing purpose.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Guohang WangCloses #134 from becketqin/KAFKA-2389",3
"MINOR: Improve on Streams log4jAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Dan Norwood, Matthias J. Sax, Jason Gustafson, Eno ThereskaCloses #2026 from guozhangwang/KMinor-improve-logging",2
"KAFKA-12196: Migrate connect:api module to JUnit 5 (#9909)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
MINOR: fix JavaDoc in SegmentIteratorAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2364 from mjsax/hotfix,0
"MINOR: fix flaky Streams EOS system test (#4728)Reviewer: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-2642; Run replication tests with SSL and SASL clientsFor SSL and SASL replication tests, set security protocol for clients as well.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ben Stopford <benstopford@gmail.com>, Geoff Anderson <geoff@confluent.io>, Jun Rao <junrao@gmail.com>Closes #563 from rajinisivaram/KAFKA-2642",5
"MINOR: Remove unused variables, methods, parameters, unthrown exceptions, and fix typos (#9457)Reviewers: Chia-Ping Tsai <chia7712@gmail.com",2
"KAFKA-4217: Add KStream.flatTransform (#5273)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-13510: Connect APIs to list all connector plugins and retrieve their configs (#11572)Implements KIP-769: https://cwiki.apache.org/confluence/display/KAFKA/KIP-769%3A+Connect+APIs+to+list+all+connector+plugins+and+retrieve+their+configuration+definitionsReviewers: Tom Bentley <tbentley@redhat.com>, Chris Egerton <fearthecellos@gmail.com>",5
"KAFKA-9559 add docs for changing default serde to null (#10988)#10813 changed the default serde from ByteArraySerde as discussed in KIP-741. This adds proper documentation so users know to set a serde through the configs or explicitly pass one in.Reviewers: Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
KAFKA-1878; ProducerFailureHandlingTest.testCannotSendToInternalTopic fails with TimeoutException while trying to fetch metadata for topic; patched by jaikiran pai; reviewed by Jun Rao,5
kafka-1743; ConsumerConnector.commitOffsets in 0.8.2 is not backward compatible; patched by Manikumar Reddy; reviewed by Jun Rao,1
"KAFKA-3487: Support classloading isolation in Connect (KIP-146)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3028 from kkonstantine/KAFKA-3487-Support-classloading-isolation-in-Connect",1
MINOR: remove unused import in TopicIdWithOldInterBrokerProtocolTest (#10037)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"KAFKA-10153: Error Reporting in Connect Documentation (#8858)Added a section about error reporting in Connect documentation, and another about how to safely use the new errant record reporter in SinkTask implementations.Author: Aakash Shah <ashah@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
MINOR: remove duplicate code in PartitionStateMachine.doHandleStateChanges (#9546)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"KAFKA-13309: fix InMemorySessionStore#fetch/backwardFetch order issue (#11337)In #9139, we added backward iterator on SessionStore. But there is a bug that when fetch/backwardFetch the key range, if there are multiple records in the same session window, we can't return the data in the correct order.Reviewers: Anna Sophie Blee-Goldman <ableegoldman<apache.org>",5
"KAFKA-12574: remove internal Producer config and auto downgrade logic  (#10675)Minor followup to #10573. Removes this internal Producer config which was only ever used to avoid a very minor amount of work to downgrade the consumer group metadata in the txn commit request in Kafka StreamsReviewers: Ismael Juma <ismael@juma.me.uk>, Matthias J. Sax <mjsax@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Test the new KIP-500 quorum mode in ducktape (#10105)Add the necessary test annotations to test the new KIP-500 quorum broker modein many of our ducktape tests. This mode is tested in addition to the classicApache ZooKeeper mode.This PR also adds a new sanity_checks/bounce_test.py system test that runsthrough a simple produce/bounce/produce series of events.Finally, this PR adds @cluster annotations to dozens of system tests that weremissing them. The lack of this annotation was causing these tests to grab theentire cluster of nodes.  Adding the @cluster annotation dramatically reducedthe time needed to run these tests.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",3
"HOTFIX: Fix bug in readToLogEnd in KafkaBasedLog.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2211 from kkonstantine/HOTFIX-Correctly-read-to-end-of-offsets-log-in-Connect-KafkaBasedLog",2
"KAFKA-2663 KAFKA-2664; Add quota-delay time to request processing time break-up; avoid using copy-on-write map for metricsThis has 2 fixes:KAFKA-2664 - This patch changes the underlying map implementation of Metrics.java to a ConcurrentHashMap. Using a CopyOnWriteMap caused new metrics creation to get extremely slow when the existing corpus of metrics is large. Using a ConcurrentHashMap seems to speed up metric creation time significantlyKAFKA-2663 - Splitting out the throttleTime from the remote time. On throttled requests, the remote time went up artificially.Some status on using a ConcurrentMap. Time to create :- 100k sensors (1.5 seconds)- 200k sensors (3 seconds)- 400k sensors (9 seconds)- 500k sensors (14 seconds)Please refer this test (originally written by Joel) http://pastebin.com/LnKjbY9aAuthor: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>Closes #369 from auradkar/K-2664",2
KAFKA-2123: add callback in commit api and use a delayed queue for async requests; reviewed by Ewen Cheslack-Postava and Guozhang Wang,1
"kafka-1928; Move kafka.network over to using the network classes in org.apache.kafka.common.network; patched by Gwen Shapira; reviewed by Joel Koshy, Jay Kreps, Jiangjie Qin, Guozhang Wang and Jun Rao",1
KAFKA-8114: Wait for SCRAM credential propagation in DelegationTokenEndToEndAuthorizationTest (#6452)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR: Add 3.0 and 3.1 to streams system tests (#11716)Reviewers: Bill Bejeck <bill@confluent.io>,5
"KAFKA-7483: Allow streams to pass headers through Serializer. (#5751)Satish Duggana <sduggana@hortonworks.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-2838; Allow comma in super users, allow comma in CLI authz prop……erties.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #529 from Parth-Brahmbhatt/KAFKA-2838",1
"MINOR: Add async and different sync startup modes in connect service test classAllow Connect Service in system tests to start asynchronously.Specifically, allow for three startup conditions:1. No condition - start async and return immediately.2. Semi-async - start immediately after plugins have been discovered successfully.3. Sync - start returns after the worker has completed startup. This is the current mode, but its condition is improved by checking that the port of Connect's REST interface is open, rather than that a log line has appeared in the logs.An associated system test run has been started here:https://jenkins.confluent.io/job/system-test-confluent-platform-branch-builder/586/ewencp rhauch, I'd appreciate your review.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4423 from kkonstantine/MINOR-Add-async-and-different-sync-startup-modes-in-ConnectService-test-class",3
MINOR: add process(Test)Messages to the README (#8480),3
HOTFIX: Checkstye fixes follow up for KAKFA-2531.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #248 from ewencp/hotfix-kafka-2531-checkstyle,0
"KAFKA-3915; Don't convert messages from v0 to v1 during log compactionThe conversion is unsafe as the converted message size may be greaterthan the message size limit. Updated `LogCleanerIntegrationTest` to test the max message size case for both V0 and the current version.Also include a few minor clean-ups:* Remove unused code branch in `LogCleaner.compressMessages`* Avoid unintentional usage of `scala.collection.immutable.Stream` (`toSeq` on an `Iterator`)* Add explicit result type in `FileMessageSet.iterator`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #1643 from ijuma/kafka-3915-log-cleaner-io-buffers-message-conversion",4
MINOR: Fix restoring for source KTableAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #860 from guozhangwang/KRestoreChangelog,4
"KAFKA-4158; Reset quota to default value if quota override is deletedAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #1851 from lindong28/KAFKA-4158",4
kafka-1146; toString() on KafkaStream gets stuck indefinitely; patched by Arup Malakar; reviewed by Jun Rao,5
MINOR: Various javadoc fixes (#10272)- Use consistent options for `javadoc` and `aggregatedJavadoc`- `aggregatedJavadoc` depends on `compileJava`- `connect-api` inherits `options.links`- `streams` and `streams-test-utils` javadoc exclusions should be morespecific to avoid unexpected behavior in `aggregatedJavadoc` when thejavadoc for multiple modules is generated togetherReviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
MINOR: findbugs should generate XML reports in JenkinsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2842 from cmccabe/findbugs-xml,5
shutdown watch executor thread properly; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-265git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1245295 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-5249; Fix incorrect producer snapshot offsets when recovering segmentsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #3060 from hachikuji/KAFKA-5249,5
"KAFKA-3781; Errors.exceptionName() can throw NPEAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1476 from ijuma/kafka-3781-exception-name-npe",5
"KAFKA-9599 create unique sensor to record group rebalance (#8159)The ""offset deletion"" and ""group rebalance"" should not be recorded by the same sensor since they are totally different.The code is introduced by #7276.Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Remove stack trace of the lock exception in a debug log4j (#10231)Although the lock exception log is at the DEBUG level only, many people were confused with stack traces that something serious happened; plus, in the source code there is only one call path that can lead to the capture of LockException at task manager/stream thread, so even for debugging purposes there’s no extra information we can get from anyways.Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"MINOR: Fix remaining core, connect and clients tests to pass with Java 11 (#5771)- SslFactoryTest should use SslFactory to create SSLEngine- Use Mockito instead of EasyMock in `ConsoleConsumerTest` as one ofthe tests mocks a standard library class and the latest released EasyMockversion can't do that when Java 11 is used.- Avoid mocking `ConcurrentMap` in `SourceTaskOffsetCommitterTest`for similar reasons. As it happens, mocking is not actually needed here.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
bump up release version to 0.8.3,5
"KAFKA-4558; throttling_test fails if the producer starts too fastWith this change, the consumer will be considered initialized in theProduceConsumeValidate tests once its partitions have been assigned.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2347 from apurvam/KAFKA-4588-fix-race-between-producer-consumer-start",0
KAFKA-708 ISR becomes empty while marking a partition offline; reviewed by Jun Rao,5
"MINOR: Fix failing test due to KAFKA-10556 PR (#9372)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-1245 the jar files and pom are not being signed so nexus is failing to publish them patch by Joe Stein; Reviewed by Jun Rao,0
"KAFKA-2972; Add missing `partitionsRemaingList.add` in `ControlledShutdownResponse` constructorAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Guozhang WangCloses #649 from ijuma/KAFKA-2972-controlled-shutdown-response-bug",0
ConsumerOffsetChecker does not work with 0.8; kafka-685; patched by Maxime Brugidou; reviewed by Jun Rao,1
"MINOR: incorrect javadoc formattingWhen wrapped in a `{code ...}` block, `&lt;&gt;` are not formatted as `<>`.For instance, see the formatting of the example in https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/KafkaStreams.htmlAuthor: Aaron Coburn <acoburn@amherst.edu>Reviewers: Matthias J. Sax, Guozhang WangCloses #2671 from acoburn/javadoc_formatting",2
KAFKA-2190; Flush mirror maker before commiting offsets; abort themirror-maker producer with close(0) on send error; reviewed by JoelKoshy,0
"KAFKA-3894; log cleaner can partially clean a segmentAs discussed in https://issues.apache.org/jira/browse/KAFKA-3894, this PR makes the log cleaner do a ""partial"" clean on a segment, whereby it builds a partial offset map up to a particular offset in a segment. Once cleaning resumes again, we will continue from the next dirty offset, which can now be located in the middle of a segment.Prior to this PR, segments with overly numerous keys could crash the log cleaner thread, as it was required that the log cleaner had to fit at least a single segment in the offset map.Author: Tom Crayford <tcrayford@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1725 from tcrayford/dont_crash_log_cleaner_thread_if_segment_overflows_buffer",4
"KAFKA-5455; Better Javadocs for the transactional producer and consumerAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3353 from apurvam/KAFKA-5455-proper-javadocs-eos-clients",2
MINOR: Remove clients/out directoryIt was committed inadvertently.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4172 from ijuma/remove-out-folder,4
"KAFKA-8940: decrease session timeout to make test faster and reliable (#10871)While there might still be some issue about the test as described here by @ableegoldman , but I found the reason why this test failed quite frequently recently. It's because we increased the session timeout to 45 sec in KIP-735.The reason why increasing session timeout affected this test is because in this test, we will keep adding new stream clients and remove old one, to maintain only 3 stream clients alive. The problem here is, when old stream closed, we won't trigger rebalance immediately due to the stream clients are all static members as described in KIP-345, which means, we will trigger trigger group rebalance only when session.timeout expired. That said, when old client closed, we'll have at least 45 sec with some tasks not working.Also, in this test, we have 2 timeout conditions to fail this test before verification passed:1. 6 minutes timeout2. polling 30 times (each with 5 seconds) without getting any data. (that is, 5 * 30 = 150 sec without consuming any data)For (1), in my test under 45 session timeout, we'll create 8 stream clients, which means, we'll have 5 clients got closed. And each closed client need 45 sec to trigger rebalance, so we'll have 45 * 5 = 225 sec (~4 mins) of the time having some tasks not working.For (2), during new client created and old client closed, it need some time to do rebalance. With 45 session timeout, we only got ~100 sec left. In slow jenkins env, it might reach the 30 retries without getting any data timeout.Therefore, decreasing session timeout can make this test completes faster and more reliable.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
MINOR: Add Rolling Upgrade Notes to Security DocsAnd added info about the krb5.conf file as we don't appear to mention that in the current docsAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael JumaCloses #625 from benstopford/security_docs,2
"MINOR: The new KIP-500 code should treat cluster ID as a string (#10357)Cluster ID has traditionally been treated as a string by the Kafka protocol (for example,AdminClient returns it as a string).  The new KIP-500 code should continue this practice.  Ifwe don't do this, upgrading existing clusters may be harder to do.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7980 - Fix timing issue in SocketServerTest.testConnectionRateLimit (#6391)Test currently checks that there were at least 5 polls when 5 connections are established with connectionQueueSize=1. But we could be doing the check just after the 5th connection before the 5th poll, so updated the check to verify that there were at least 4 polls.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
KAFKA-7762; Update KafkaConsumer Javadoc examples to use poll(Duration timeout) APIAuthor: Matthias Wessendorf <mwessend@redhat.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6052 from matzew/use_new_poll_api,1
"KAFKA-6172; Cache lastEntry in TimeIndex to avoid unnecessary disk accessAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin <becket.qin@gmail.com>Closes #4177 from lindong28/KAFKA-6172",1
"KAFKA-6266: Repeated occurrence of WARN Resetting first dirty offset (#8089)Previously, checkpointed offsets for a log were only updated if the log was chosen for cleaning once the cleaning job completes. This caused issues in cases where logs with invalid checkpointed offsets would repeatedly emit warnings if the log with an invalid cleaning checkpoint wasn't chosen for cleaning.Proposed fix is to update the checkpointed offset for logs with invalid checkpoints regardless of whether it gets chosen for cleaning.Reviewers: Anna Povzner <anna@confluent.io>, Jun Rao <junrao@gmail.com>",5
"HOTFIX: Fix putAll and putIfAbsent logic for correct eviction behaviorAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2038 from enothereska/hotfix-put-cache",0
"KAFKA-7161: check invariant: oldValue is in the state (#5366)Reviewers: Vasily Sulatskov <redvasily@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-13298: Improve documentation on EOS KStream requirements (#11355)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-6945: Add docs about KIP-373 (#12346)Reviewers: Manikumar Reddy,2
KAFKA-8222 & KIP-345 part 5: admin request to batch remove members (#7122)This PR adds supporting features for static membership. It could batch remove consumers from the group with provided group.instance.id list.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-13660: Switch log4j12 to reload4j (#11743)This bumps the slf4j version to 1.7.36 and swaps out log4j 1.2.17 withreload4j 1.2.19Signed-off-by: Mike Lothian <mike@fireburn.co.uk>Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Bruno Cadonna <cadonna@apache.org>",1
KAFKA-7250: fix transform function in scala DSL to accept TranformerSupplier (#5468)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-1188 Stale LeaderAndIsr request could be handled by the broker on Controller failover; reviewed by Neha, Jun",0
"KAFKA-4913; prevent creation of window stores with less than 2 segmentsThrow IllegalArgumentException when attempting to create a `WindowStore` via `Stores` or directly with `RocksDBWindowStoreSupplier` when it has less than 2 segments.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3410 from dguy/kafka-4913",5
"KAFKA-7921: log at error level for missing source topic (#6262)This condition is a fatal error, so error level is warranted, to provide more context on why Streams shuts down.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8098: fix the flaky test by disabling the auto commit to avoid member rejoiningIn the test, we first test removing 1 member from group, and then test removing the other 2 members from group, and it failed sometimes at the 2nd member number assert. After investigation, I found it's because we enabled auto commit for the consumers(default setting), and the removed consumer offset commit will get the `UNKNOWN_MEMBER_ID` error, which will then make the member rejoin. (check ConsumerCoordinator#OffsetCommitResponseHandler) So, that's why after the 2nd members removing, the members will sometimes be not empty.I set the consumer config to disable the auto commit to fix this issue. Thanks.Author: Luke Chen <showuon@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9062 from showuon/KAFKA-8098",0
"KAFKA-4214; kafka-reassign-partitions fails all the time when brokers are bounced during reassignmentThere is a corner case bug, where during partition reassignment, if thecontroller and a broker receiving a new replica are bounced at the sametime, the partition reassignment is failed.The cause of this bug is a block of code in the KafkaController whichfails the reassignment if the aliveNewReplicas != newReplicas, ie. ifsome of the new replicas are offline at the time a controller failsover.The fix is to have the controller listen for ISR change events even fornew replicas which are not alive when the controller boots up. Once thesaid replicas come online, they will be in the ISR set, and the newcontroller will detect this, and then mark the reassignment assuccessful.Interestingly, the block of code in question was introduced inKAFKA-990, where a concern about this exact scenario was raised :)This bug was revealed in the system tests in https://github.com/apache/kafka/pull/1904.The relevant tests will be enabled in either this or a followup PR when PR-1904 is merged.Thanks to junrao identifying the issue and providing the patch.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1910 from apurvam/KAFKA-4214",1
"MINOR: kafka system tests should support larger EBS volumes for newer instances (#12382)When running with 4th generation instances supporting EBS only, we needto use a larger volume or else we run out of  disk space during a systemtest run.This change also parameterizes the instance type as an env variable foreasier testing.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-12697: Add FencedBrokerCount and ActiveBrokerCount metrics to the QuorumController (#10772)Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
KAFKA-8514: Move the scala-java8-compat dependency from clients to core (#6910)`clients` is a Java-only module and should not have any Scala dependency.Reviewers: Ismael Juma <ismael@juma.me.uk>,4
KAFKA-2744: Commit source task offsets after task is completely stoppedAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #423 from ewencp/commit-source-offsets-after-work-thread-exits,1
"KAFKA-9053: AssignmentInfo#encode hardcodes the LATEST_SUPPORTED_VERSION (#7537)Also put in some additional logging that makes sense to add, and proved helpful in debugging this particular issue.Unit tests verifying the encoded supported version were added.This should get cherry-picked back to 2.1Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13998: JoinGroupRequestData 'reason' can be too large (#12298)The `reason` field cannot contain more than 32767 chars. We did not expect to ever reach this but it turns out that it is possible if the the message provided in the `Throwable` somehow contains the entire stack trace. This patch ensure that the reason crafted based on exceptions remain small.Co-authored-by: David Jacot <djacot@confluent.io>Reviewers:  Bruno Cadonna <cadonna@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org>, David Jacot <djacot@confluent.io>",5
"KAFKA-13091; Ensure high watermark incremented after AlterIsr returns (#11245)After we have shrunk the ISR, we have an opportunity to advance the high watermark. We do this currently in `maybeShrinkIsr` after the synchronous update through ZK. For the `AlterIsr` path, however, we cannot rely on this call since the request is sent asynchronously. Instead we should attempt to advance the high watermark in the callback when the `AlterIsr` response returns successfully.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: code cleanup (#6054)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Ismael Juma <ismael@confuent.io>",5
"KAFKA-10766: Unit test cases for RocksDBRangeIterator (#9717)This PR aims to add unit test cases for RocksDBRangeIterator which were missing.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-13572 Fix negative preferred replica imbalanced count metric (#12405)Currently, preferredReplicaImbalanceCount calculation has a race that becomes negative when topic deletion is initiated simultaneously. This PR addresses the problem by fixing cleanPreferredReplicaImbalanceMetric to be called only once per topic-deletion procedureReviewers: Luke Chen <showuon@gmail.com>",4
"KAFKA-852, remove clientId from Offset{Fetch,Commit}Response. Reviewed by Jay.",1
MINOR: Set JVM parameters for the Gradle Test executor processesWe suspect that the test suite hangs we have been seeing aredue to PermGen exhaustion. It is a common reason forhard JVM lock-ups.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1926 from ijuma/test-jvm-params,3
"KAFKA-9126: KIP-689: StreamJoined changelog configuration (#9708)Add withLoggingEnabled and withLoggingDisabled for StreamJoinedto give StreamJoined the same flexibility as MaterializedReviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-4702: Parametrize streams benchmarks to run at scaleAuthor: Eno Thereska <eno.thereska@gmail.com>Author: Eno Thereska <eno@confluent.io>Author: Ubuntu <ubuntu@ip-172-31-22-146.us-west-2.compute.internal>Reviewers: Matthias J. Sax, Guozhang WangCloses #2478 from enothereska/minor-benchmark-args",5
"KAFKA-404 When using chroot path, create chroot on startup if it doesn't exist; reviewed by Neha Narkhede",1
KAFKA-5198: Synchronize on RocksDbStore#openIterators…it is accessed from multiple threadsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3000 from cmccabe/KAFKA-5198,5
"KAFKA-2312: use atomic long for thread id reference; reviewed by Ewen Cheslack-Postava, Jason Gustafson, Ismael Juma and Guozhang Wang",1
"KAFKA-502 Adding 30 more system tests, reviewed by Jun and Neha; patched by John Funggit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396687 13f79535-47bb-0310-9956-ffa450edef68",3
"MINOR: Improve Gradle Caching and Fix Deprecations (#12003)* Fix UP-TO-DATE check in `create*VersionFile` tasks`create*VersionFile` tasks explicitly declared output UP-TO-DATE status as being false. This change properly sets the inputs to`create*VersionFile` tasks to the `commitId` and `version` values andsets `receiptFile` locally rather than in an extra property.* Enable output caching for `process*Messages` tasks`process*Messages` tasks did not have output caching enabled. Thischange enables that caching, as well as setting a property name andRELATIVE path sensitivity.* Fix existing Gradle deprecationsReplaces `JavaExec#main` with `JavaExec#mainClass`Replaces `Report#destination` with `Report#outputLocation`Adds a `generator` configuration to projects that need to resolvethe `generator` project (rather than referencing the runtimeClasspathof the `generator` project from other project contexts.Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
KAFKA-9724 Newer clients not always sending fetch request to older brokers (#8376)Newer clients were getting stuck entering the validation phase even when a broker didn't support it. This commit will bypass the AWAITING_VALIDATION state when the broker is on an older version of the OffsetsForLeaderEpoch RPC.,1
"MINOR: Fix flaky ControllerMutationQuotaTest.testQuotaMetric (#9417)`ClientQuotaManager.updateQuota` updates the in-memory quota before updating the configuration of the metric. Therefore, `quotaLimit` can return the updated value while the metric's configuration still returns the previous one. This patch updates the test to be resilient to this case.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-13706: Remove closed connections from MockSelector.ready (#11839)Reviewers: David Jacot <djacot@confluent.io>,5
Support configurable send / receive socket buffer size in server; patched by John Fung; reviewed by Jun Rao; KAFKA-200git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1228480 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9451: Update MockConsumer to support ConsumerGroupMetadataReviewers: Boyang Chan <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3022: Deduplicate common project configurations- Move testJar to subprojects config- Move CheckStyle to subprojects config- Move testLogging to subprojects config- Add testSourceJar in subprojects config- Minor cleanupAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #712 from granthenke/build-dedupe",5
"KAFKA-12994: Migrate TimeWindowsTest to new API (#11215)As raised in KAFKA-12994, All tests that use the old API should be either eliminated or migrated to the new API in order to remove the @SuppressWarnings(""deprecation"") annotations. This PR will migrate over all the relevant tests in TimeWindowsTests.javaReviewers: Anna Sophie Blee-Goldman",3
KAFKA-5566: fixed race condition between flush and commitAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3504 from mjsax/kafka-5566-queryable-state-test,3
"KAFKA-4993; Fix findbugs warnings in kafka-clientsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2779 from cmccabe/KAFKA-4993",5
"KAFKA-6850: Add Record Header support to Kafka Streams Processor API (KIP-244) (#4955)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-10587; Rename kafka-mirror-maker CLI command line arguments for KIP-629[KAFKA-10587](https://issues.apache.org/jira/browse/KAFKA-10587) Rename kafka-mirror-maker CLI command line arguments for KIP-629Replace ""whitelist"" argument in kafka-mirror-maker cli command with ""include""Author: OmniaGM <o.g.h.ibrahim@gmail.com>Reviewers: Luke Chen, Xavier Leaute, Gwen ShapiraCloses #10937 from OmniaGM/KAFKA-10587",1
"KAFKA-7192: Wipe out if EOS is turned on and checkpoint file does not exist (#5421)1. As titled and as described in comments.2. Modified unit test slightly to insert for new keys in committed data to expose this issue.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-13846: Use the new addMetricsIfAbsent API (#12287)Use the newly added function to replace the old addMetric function that may throw illegal argument exceptions.Although in some cases concurrency should not be possible they do not necessarily remain always true in the future, so it's better to use the new API just to be less error-prone.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-10000: Add new source connector APIs related to exactly-once support (KIP-618) (#11773)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Reviewers: Tom Bentley <tbentley@redhat.com>, Hector Geraldino <hgeraldino@bloomberg.net>, Andrew Eugene Choi <andrew.choi@uwaterloo.ca>",1
"MINOR: Clean up some test dependencies on ConfigCommand and TopicCommand (#8527)Avoid calling into ConfigCommand and TopicCommand from tests that are not relatedto these commands.  It's better to just invoke the admin APIs.Change a few cases where we were testing the deprecated --zookeeper flag to testingthe --bootstrap-server flag instead.  Unless we're explicitly testing the deprecated codepath, we should be using the non-deprecated flags.Move testCreateWithUnspecifiedReplicationFactorAndPartitionsWithZkClient fromTopicCommandWithAdminClientTest.scala into TopicCommandWithZKClientTest.scala,since it makes more sense in the latter.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-7534: Error in flush calling close may prevent underlying store  from closing (#5833)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-3431: Remove `o.a.k.common.BrokerEndPoint` in favour of `Node`Also included a minor efficiency improvement in kafka.cluster.EndPoint.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1105 from ijuma/kafka-3431-replace-broker-end-point-with-node,1
Merge pull request #3567 from bobrik/unclean-docs-clarificationKAFKA-4711: fix docs onunclean.leader.election.enable default,4
"KAFKA-2770: Catch and ignore WakeupException for commit upon closingAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen Shapira, Geoff Anderson, Jason GustafsonCloses #470 from guozhangwang/K2770",5
"KAFKA-10471 Mark broker crash during log loading as unclean shutdown (#9364)LogManager writes a clean shutdown file when the broker shuts down. Thepresence of this file indicates that the broker had a clean shutdown andlog recovery is not needed upon the next boot up.Earlier, LogManager would check for this file at the start of log loading workflow,and delete it after the log has been loaded. If the broker were to crashwhile loading logs, the file would not be deleted and mislead LogManager when ittries to load logs upon next boot up. Hence, a crash during log loadingwill not be considered a hard reset of broker.As part of this fix, we delete the clean shutdown file as soon as welook it up, at the start of log loading workflow. Thereafter, we maintain a booleanflag to indicate if broker underwent clean shutdown or not. So, if thebroker were to crash while logs are being loaded, LogManager will beable to detect this as a hard reset.Reviewers: Jun Rao <junrao@gmail.com>",1
"KAFKA-10179: Pass correct changelog topic to state serdes (#8902)Until now we always passed the default changelog topic nameto the state serdes. However, for optimized source tablesand global tables the changelog topic is the source topic.Most serdes do not use the topic name passed to them.However, if the serdes actually use the topic name for(de)serialization aorg.apache.kafka.common.errors.SerializationException is thrown.This commits passed the correct changelog topic to the stateserdes of the metered state stores.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>",5
MINOR: Fix flaky test shouldQuerySpecificActivePartitionStores (#9873)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
MINOR: Some images should be centered in the documentationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2029 from hachikuji/center-some-images,5
"KAFKA-10647; Only serialize owned partitions when consumer protocol version >= 1 (#9506)A regression got introduced by https://github.com/apache/kafka/commit/466f8fd21c6651ea5daa50154239e85fa629dbb4. The owned partition field must be ignored for version < 1 otherwise the serialization fails with an unsupported version exception.Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-10002; Improve performances of StopReplicaRequest with large number of partitions to be deleted (#8672)Update checkpoint files once for all deleted partitions instead of updating them for each deleted partitions. With this, a stop replica requests with 2000 partitions to be deleted takes ~2 secs instead of ~40 secs previously.Refactor the checkpointing methods to not compute the logsByDir all the time. It is now reused as much as possible.Refactor the exception handling. Some checkpointing methods were handling IOException but the underlying write process already catches them and throws KafkaStorageException instead.Reduce the logging in the log cleaner manager. It does not log anymore when a partition is deleted as it is not a useful information.Reviewers:  Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
KAFKA-4130; Link to Varnish architect notes is brokenAuthor: Andrea Cosentino <ancosen@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1835 from oscerd/KAFKA-4130,5
KAFKA-1309; Fix cross-compilation issue (due to use of deprecated JavaConversions API in javaapi.OffsetCommitRequest; reviewed by Neha Narkhede,1
"KAFKA-7245: Deprecate WindowStore#put(key, value) (#7105)Implements KIP-474.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-4248; Consumer should rematch regex immediately in subscribeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1954 from hachikuji/rematch-regex-on-subscribe,5
"KAFKA-6383: complete shutdown for CREATED StreamThreads (#4343)* KAFKA-6383: complete shutdown for CREATED StreamThreadsWhen transitioning StreamThread from CREATED to PENDING_SHUTDOWNfree up resources from the caller, rather than the stream thread,since in this case the stream thread was never actually started.Have StreamThread.setState return the old state. If the old state isCREATED in StreamThread.shutdown() then start the thread so that itcan free the resources owned by the StreamThread.Add a KafkaStreams test to verify that the producer gets closed evenif KafkaStreams was not startedReviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Skip quota check when replica is in sync (#6344)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3924; Replacing halt with exit upon LEO mismatch to trigger gra……ceful shutdownThe patch is pretty simple and the justification is explained in https://issues.apache.org/jira/browse/KAFKA-3924I could not find Andrew Olson, who seems to be the contributor of this part of the code, in github so I am not sure whom I should ask to review the patch. the contribution is my original work and that i license the work to the project under the project's open source license.Author: Maysam Yabandeh <myabandeh@dropbox.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Andrew Olson <andrew.olson@cerner.com>, Jun Rao <junrao@gmail.com>Closes #1634 from maysamyabandeh/KAFKA-3924",4
KAFKA-42 part 2: new filesgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396814 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-7197: Support Scala 2.13 (#5454)- include Scala 2.13 in gradle build- handle future milestone and RC versions of Scala in a better way- if no Scala version is specified, default to scala 2.12 (bump from 2.11)- include certain Xlint options (removed by Scala 2.13) for Scala 2.11/2.12 build only- upgrade versions for dependencies:   - scalaLogging: 3.9.0 -->> 3.9.2  - scalatest:        3.0.7 -->> 3.0.8  - scoverage:       1.3.1 -->> 1.4.0Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-6042: Avoid deadlock between two groups with delayed operationsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4103 from rajinisivaram/KAFKA-6042-group-deadlock(cherry picked from commit 5ee157126d595b913761cf1887963460bbe12855)Signed-off-by: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10505: Fix parsing of generation log string. (#9312)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4929: Transformation Key/Value type references should be to class name(), not canonicalName()Changing getCanonicalName() references to getName() so that docs update with ""$"" instead of ""."".  Also added a connect-plugin-discovery.sh CLI to list all of the transformations available.Author: Bruce Szalwinski <bruce.szalwinski@cdk.com>Reviewers: Gwen ShapiraCloses #2720 from bruce-szalwinski/transforms and squashes the following commits:ec3b5b9 [Bruce Szalwinski] remove connect-plugin-discovery.  will submit in a different PReba0af7 [Bruce Szalwinski] Key / Value transformations are static nested classes and so are referenced using OuterClass$Key and OuterClass$Value.",1
KAFKA-709 change in default blocking tripped test checking queue is full so updated test in case someone changes the new default to something else,1
KAFKA-6729: Follow up; disable logging for source KTable. (#5038)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Fixed javadoc for committed return valueIf no offset has been committed, then committed method does not return (null) value, instead NoOffsetForPartitionException is thrown in that case.Author: Stevo Slavić <sslavic@gmail.com>Reviewers: Ismael, GuozhangCloses #89 from sslavic/patch-4 and squashes the following commits:5c0a152 [Stevo Slavić] MINOR: Fixed javadoc for committed return value",2
MINOR: additional refactoring around the use of ErrorsA couple of updates were missed in the [PR](https://github.com/apache/kafka/pull/2475) that replaced the use of error codes with Errors objects.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2635 from vahidhashemian/minor/Errors_refactoring_leftover,4
"KAFKA-7285: Create new producer on each rebalance if EOS enabled (#5501)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-872; Socket server should set send/recv socket buffer sizes; reviewed by Jun Rao.,1
KAFKA-8376; Least loaded node should consider connections which are being prepared (#6746)This fixes a regression caused by KAFKA-8275. The least loaded node selectionshould take into account nodes which are currently being connect to. Thisincludes both the CONNECTING and CHECKING_API_VERSIONS states since`canSendRequest` would return false in either case.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-4860; Allow spaces in paths on windowsWhen we install kafka on path with spaces, batch files were failing, this PR is trying to fix this issue.Author: Vladimír Kleštinec <klestinec@gmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>Closes #2649 from klesta490/trunk",1
Implement a few of the API suggestions from the mailing list.,5
KAFKA-2175; Change INFO to DEBUG for socket close on no error; and partition reassignment JSON; reviewed by Gwen Shapira and Joel Koshy,5
MINOR: Add upgrade tests for FK joins (#12122)Follow up PR for KAFKA-13769.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-5457; MemoryRecordsBuilder.hasRoomFor should account for record headersAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3355 from apurvam/KAFKA-5457-memoryrecordsbuilder-has-room-for-should-account-for-headers",5
refactor ReplicaManager; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-351git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1375670 13f79535-47bb-0310-9956-ffa450edef68,4
fix kafka-server-start.sh to take an optional producer propertygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1157560 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Stabilization fixes broker down test trunk (#6043)This PR addresses a few issues with this system test flakiness. This PR is a cherry-picked duplicate of #6041 but for the trunk branch, hence I won't repeat the inline comments here.1. Need to grab the monitor before a given operation to observe logs for signal2. Relied too much on a timely rebalance and only sent a handful of messages.I've updated the test and ran it here https://jenkins.confluent.io/job/system-test-kafka-branch-builder/2143/ parameterized for 15 repeats all passed.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
"KAFKA-7895: fix Suppress changelog restore (#6536)Several issues have come to light since the 2.2.0 release:upon restore, suppress incorrectly set the record metadata using the changelog record, instead of preserving the original metadatarestoring a tombstone incorrectly didn't update the buffer size and min-timestampReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bruno Cadonna <bruno@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-12270: Handle race condition when Connect tasks attempt to create topics (#10032)When a source connector is configured to create missing topics has multiple tasks that generate records for the same topic, it is possible that multiple tasks may simultaneously describe the topic, find it does not exist, and attempt to create the task. One of those create topic requests will succeed, and the other concurrent tasks will receive the response from the topic admin as having not created the task and will fail unnecessarily.This change corrects the logic by moving the `TopicAdmin` logic to create a topic to a new `createOrFindTopics(…)` method that returns the set of created topic names and the set of existing topic names. This allows the existing `createTopics(…)` and `createTopic(…)` methods to retain the same behavior, but also allows the `WorkerSourceTask` to know from its single call to this new method whether the topic was created or was found to exist.This adds one unit test and modifies several unit tests in `WorkerSourceTaskWithTopicCreationTest` that use mocks to verify the behavior, and modifies several existing unit tests for `TopicAdminTest` to ensure the logic of the new method is as expected.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-6193; Only delete reassign_partitions znode after reassignment is complete- Ensure that `partitionsBeingReassigned` is fully populated before`removePartitionFromReassignedPartitions` is invoked. This isnecessary to avoid premature deletion of the `reassign_partitions`znode.- Modify and add tests to verify the fixes.- Add documentation.- Use `info` log message if assignedReplicas == newReplicas andremove control flow based on exceptions.- General logging improvements.- Simplify `initializePartitionAssignment` by relying on logic alreadypresent in `maybeTriggerPartitionReassignment`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4283 from ijuma/kafka-6193-flaky-shouldPerformMultipleReassignmentOperationsOverVariousTopics",2
"KAFKA-14133: Replace EasyMock with Mockito in WorkerCoordinatorTest and RootResourceTest (#12509)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Dalibor Plavcic <dalibor.os@proton.me>",3
MINOR: Make MockClient#poll() more thread-safe (#5942)It used to preallocate an array of responses and then complete each response from the original collection sequentially. The problem was that the original collection could have been modified (another thread completing the response) while this was hapenning,0
"KAFKA-9651: Fix ArithmeticException (÷ by 0) in DefaultStreamPartitioner (#8226)In Streams `StreamsMetadataState.getMetadataWithKey`, we should use the inferred max topic partitions passed in directly from the caller than relying on cluster to contain its topic-partition information.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Standardize logging of Worker-level messages from Tasks and ConnectorsThis ensures all logs have the connector/task ID, whether tasks are source or sink, and formats them consistently.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3639 from ewencp/standardize-connector-task-logging",2
"MINOR: Fix broken JMX link in docs by adding missing starting double quote (#8587)The href attribute missed the starting double quote, so the hyperlink is interpreted as https://docs.oracle.com/.../agent.html"", with a redundant tailing double quote. Add the missing starting double quote back to fix this issue.Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: update java doc for deprecated methods (#10722)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Annotate test BlockingConnectorTest as integration test (#9379)`BlockingConnectorTest` was incorrectly running as a unit test. Categorize this test correctly as integration test by adding the appropriate annotationReviewer: Randall Hauch <rhauch@gmail.com>,1
"MINOR: Make JUnit 5 the default for new projects (#9882)Instead of listing the projects that should use JUnit 5, list theprojects that are still using JUnit 4.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",3
"MINOR: more log4j entry on elect / resignation of coordinators (#9416)When a coordinator module is being elected / resigned, our log entry is usually associated with a background scheduler on loading / unloading entries and hence it is unclear at the exact time when the election or resignation happens, and we have to then compare with the KafkaAPI's log entry for leaderAndISR / StopReplica to infer the actual time. I think add a couple new log entries indicating the exact time when it happens is helpful.Reviewers: Boyang Chen <boyang@confluent.io>, Lee Dongjin <dongjin@apache.org>, Bruno Cadonna <bruno@confluent.io>",5
MINOR: Add method `hasMetrics()` to class `Sensor` (#7692)Sometimes to be backwards compatible regarding metrics the simplestsolution is to create an empty sensor. Recording an empty sensor onthe hot path may negatively impact performance. With hasMetrics()recordings of empty sensors on the hot path can be avoided withoutbeing to invasive.Reviewers: Bill Bejeck <bbejeck@gmail.com>,1
MINOR: Revert assertion in MockProducerTest (#9956)This patch reverts an assertion which was wrongly changed in https://github.com/apache/kafka/pull/9955.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-10554; Perform follower truncation based on diverging epochs in Fetch response (#9382)From IBP 2.7 onwards, fetch responses include diverging epoch and offset in fetch responses if lastFetchedEpoch is provided in the fetch request. This PR uses that information for truncation and avoids the additional OffsetForLeaderEpoch requests in followers when lastFetchedEpoch is known.Co-authored-by: Jason Gustafson <jason@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Nikhil Bhatia <rite2nikhil@gmail.com>",5
"KAFKA-4574; Ignore test_zk_security_upgrade until KIP-101 landsThe transient failures make it harder to spot real failures and we can live without what is being tested (adding security to ZK via a rolling upgrade) until KIP-101 lands.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>Closes #2742 from ijuma/disable-zk-upgrade-test",3
"MINOR: Fix typo in Operations sectionThis contribution is my original work, and I license the work to the project under the project's open source license.Author: Samuel Taylor <staylor@square-root.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1630 from ssaamm/trunk",1
KAFKA-1953; KAFKA-1962; Disambiguate purgatory metrics; restore delayed request metrics; reviewed by Guozhang Wang,5
"KAFKA-12998: Implement broker-side KRaft snapshots (#10931)This PR implements broker-side KRaft snapshots, including both saving andloading. The code for triggering a periodic broker-side snapshot will come in afollow-on PR. Loading should work with just this PR. It also implementsreloading broker snapshots after initialization.In order to facilitate snapshots, this PR introduces the concept ofMetadataImage and MetadataDelta. MetadataImage represents the metadata stateretained in memory. It is basically a generalization of MetadataCache thatincludes a few things that MetadataCache does not (such as features and clientquotas.) KRaftMetadataCache is now an accessor for the data stored in this object.Similarly, MetadataImage replaces CacheConfigRespository and ClientQuotaCache.It also subsumes kafka.server.metadata.MetadataImage and related classes.MetadataDelta represents a change to a MetadataImage. When a KRaft snapshot isloaded, we will accumulate all the changes into a MetadataDelta first, prior toapplying it. If we must reload a snapshot because we fell too far behind whileconsuming metadata, the resulting MetadataDelta will contain all the changesneeded to catch us up. During normal operation, MetadataDelta is also used toaccumulate the changes of each incoming batch of metadata records. Theseincremental deltas should be relatively small.I have removed the logic for updating the various manager objects fromBrokerMetadataListener and placed it into BrokerMetadataPublisher. This makesit easier to unit test BrokerMetadataListener.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-3069: Fix recursion in ZkSecurityMigratorI'm also fixing a bug in the testChroot test case.Author: Flavio Junqueira <fpj@apache.org>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #736 from fpj/KAFKA-3069,5
"(Cherry-pick) KAFKA-9274: handle TimeoutException on task reset (#10000) (#10372)This PR was removed by accident in trunk and 2.8, bringing it back.Co-authored-by: Matthias J. Sax <matthias@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10777: Add additional configuration to control MirrorMaker 2 internal topics naming convention - KIP-690 (#11220)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
MINOR: Fix race condition in KafkaStreamsTest.shouldReturnThreadMetadataAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4337 from mjsax/minor-fix-kafakstreamstest,3
"MINOR: fix flaky shouldRemoveOneNamedTopologyWhileAnotherContinuesProcessing (#11827)This test has been failing somewhat regularly due to going into the ERROR state before reaching RUNNING during the startup phase. The problem is that we are reusing the DELAYED_INPUT_STREAM topics, which had previously been assumed to be uniquely owned by a particular test. We should make sure to delete and re-create these topics for any test that uses them.",1
MINOR: Fix static mock usage in TaskMetricsTest (#12373)Before this PR the calls to the static methods on StreamsMetricsImpl were just calls and not a verification on the mock. This miss happened during the switch from EasyMock to Mockito.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
KAFKA-10199: Implement removing active and standby tasks from the state updater (#12270)This PR adds removing of active and standby tasks from the default implementation of the state updater. The PR also includes refactoring that clean up the code.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"KAFKA-9793: Expand the try-catch for task commit in HandleAssignment (#8402)As title suggests, we would like to broaden this check so that we don't fail to close a doom-to-cleanup task.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
"MINOR: factor state checks into descriptive methods and clarify javadocs (#11123)Just a bit of minor cleanup that (a) does some prepwork for another PR I'm working on, (b) updates the javadocs & exception messages to report a more useful error to the user and describe what they actually need to do, and (c) hopefully makes these state checks more future-proof by defining methods for each kind of check in one place that can be easily updated instead of tracking down every individual check.Reviewers: Walker Carlson <wcarlson@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-6916; Refresh metadata in admin client if broker connection fails (#5050)Refresh metadata if broker connection fails so that new calls are sent only to nodes that are alive and requests to controller are sent to the new controller if controller changes due to broker failure. Also reassign calls that could not be sent.Reviewers: Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5427; Transactional producer should allow FindCoordinator in error stateAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3297 from hachikuji/KAFKA-5427",5
"HOTFIX: follow-up on KAFKA-725 to remove the check and return empty response instead of throw exceptionsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Stig Døssing, Ismael Juma, Jun RaoCloses #1327 from guozhangwang/K725r",4
"KAFKA-5131; WriteTxnMarkers and complete commit/abort on partition immigrationWrite txn markers and complete the commit/abort for transactions in PrepareXXstate during partition immigration.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2926 from dguy/kafka-5059",5
"KAFKA-4131; Multiple Regex KStream-Consumers cause Null pointer exceptionFix for bug outlined in KAFKA-4131Author: bbejeck <bbejeck@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #1843 from bbejeck/KAFKA-4131_mulitple_regex_consumers_cause_npe",1
"MINOR: update streams quickstart for KIP-182Author: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3984 from dguy/quickstart-update",5
trivial change to print out last offset in DumpLogSegmentsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179500 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6761: Construct logical Streams Graph in DSL Parsing (#4983)This version is a WIP and intentionally leaves out some additional required changes to keep the reviewing effort more manageable. This version of the process includes1. Cleaning up the graph objects to reduce the number of parameters and make the naming conventions more clear.2. Intercepting all calls to the InternalToplogyBuilder and capturing all details required for possible optimizations and building the final topology.This PR does not include writing out the current physical plan, so no tests included. The next PR will include additional changes to building the graph and writing the topology out without optimizations, using the current streams tests.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
some more changes,4
"KAFKA-7961; Ignore assignment for un-subscribed partitions (#6304)Whenever the consumer coordinator sends a response that doesn't match the client consumer subscription, we should check the subscription to see if it has changed. If it has, we can ignore the assignment and request a rebalance. Otherwise, we can throw an exception as before.Testing strategy: create a mocked client that first sends an assignment response that doesn't match the client subscription followed by an assignment response that does match the client subscription.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-10527; Voters should not reinitialize as leader in same epoch (#9348)One of the invariants that the raft replication protocol relies on is that each record is uniquely identified by leader epoch and offset. This can be violated if a leader remains elected with the same epoch between restarts since unflushed data could be lost.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-3608; Fix ZooKeeper structures and output format in documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #1257 from vahidhashemian/KAFKA-3608,2
KAFKA-5995; Rename AlterReplicaDir to AlterReplicaDirsAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3993 from lindong28/KAFKA-5995,5
"KAFKA-4384; ReplicaFetcherThread stops after ReplicaFetcherThread receives a corrupted messageAuthor: Jun He <jun.he@airbnb.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2127 from jun-he/KAFKA-4384",5
"KAFKA-12648: Make changing the named topologies have a blocking option (#11479)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-7009: Suppress the Reflections log warning messages in system testsThis could be backported to older branches to reduce the extra log warning messages there, too.Running Connect system tests in this branch builder job: https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1773/Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5151 from rhauch/kafka-7009",5
"MINOR: Update streamResetter option description (#11613)Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-10756; Add missing unit test for `UnattachedState` (#9635)This patch adds a unit test for `UnattachedState`, similar to `ResignedStateTest` and `VotedStateTest`.Reviewers: Jason Gustafson <jason@confluent.io>",5
"[KAFKA-8522] Streamline tombstone and transaction marker removal (#10914)This PR aims to remove tombstones that persist indefinitely due to low throughput. Previously, deleteHorizon was calculated from the segment's last modified time.In this PR, the deleteHorizon will now be tracked in the baseTimestamp of RecordBatches. After the first cleaning pass that finds a record batch with tombstones, the record batch is recopied with deleteHorizon flag and a new baseTimestamp that is the deleteHorizonMs. The records in the batch are rebuilt with relative timestamps based on the deleteHorizonMs that is recorded. Later cleaning passes will be able to remove tombstones more accurately on their deleteHorizon due to the individual time tracking on record batches.KIP 534: https://cwiki.apache.org/confluence/display/KAFKA/KIP-534%3A+Retain+tombstones+and+transaction+markers+for+approximately+delete.retention.ms+millisecondsCo-authored-by: Ted Yu <yuzhihong@gmail.com>Co-authored-by: Richard Yu <yohan.richard.yu@gmail.com>",5
MINOR: add logfilename to error message when file missingewencpAuthor: dan norwood <norwood@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1307 from norwood/log-filename-when-missing-file,2
KAFKA-8126: Flaky Test org.apache.kafka.connect.runtime.WorkerTest.testAddRemoveTask (#6475)Changed the WorkerTest to use a mock Executor.Author: Attila Doroszlai <adoroszlai@apache.org>Reviewer: Randall Hauch <rhauch@gmail.com>,1
KAFKA-3211: Handle WorkerTask stop before start correctlyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #874 from hachikuji/KAFKA-3211,5
"K7657 handling thread dead state change (#6091)While looking into KAFKA-7657, I found there are a few loopholes in this logic:We kept a map of thread-name to thread-state and a global-thread state at the KafkaStreams instance-level, in addition to the instance state itself. stateLock is used when accessing the instance state, however when we are in the thread state change callback, we are accessing both the thread-states as well as the instance state at the same time in the callers of setState without a lock, which is vulnerable to concurrent multi-stream threads. The fix is a) introduce a threadStatesLock in addition to the stateLock, which should always be grabbed to modify the thread-states map before the stateLock for modifying the instance level; and we also defer the checking of the instance-level state inside the setState call.When transiting to state.RUNNING, we check if all threads are either in RUNNING or DEAD state, this is because some threads maybe dead at the rebalance period but we should still proceed to RUNNING if the rest of threads are still transiting to RUNNING.Added unit test for 2) above. Also simplified another test as a nit change.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>",1
MINOR: remove NewTopic#NO_PARTITIONS and NewTopic#NO_REPLICATION_FACTOR as they are duplicate to CreateTopicsRequest#NO_NUM_PARTITIONS and CreateTopicsRequest#NO_REPLICATION_FACTOR (#9077)Consolidate constant values of NO_PARTITIONS and NO_REPLICATION_FACTOR as stated in the title.Reviewers: Boyang Chen <boyang@confluent.io>,5
"MINOR: Java8 cleanup (#6599)Reviewers: Bill Bejeck <bill@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"MINOR: Mark RocksDBStoreTest as integration test (#7412)shouldNotThrowExceptionOnRestoreWhenThereIsPreExistingRocksDbFiles takes1m30s, which is too long for a unit test.`RocksDBTimestampedStoreTest` inherits from `RocksDBStoreTest` and it'simplicitly considered an integration test too.Reviewers: Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Use Set instead of List for multiple topics (#5024)Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-6102; Consolidate MockTime implementations between connect and clientsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #4105 from cmccabe/KAFKA-6102",5
KAFKA-13441: Fix typo in upgrade.html (#11483)Reviewers: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: gf13871 <gf13871@ly.com>,2
KAFKA-765 Corrupted messages in produce request could shutdown the broker; reviewed by Jun Rao and Sriram Subramanian,5
KAFKA-2654: optimize unnecessary poll(0) away in StreamTaskguozhangwangThis change aims to remove unnecessary ```consumer.poll(0)``` calls.* ```once``` after some partition is resumed* whenever the size of the top queue in any task is below ```BUFFERED_RECORDS_PER_PARTITION_CONFIG```Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #315 from ymatsuda/less_poll_zero,5
KAFKA-5033; Set default retries for the idempotent producer to be infiniteAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3091 from apurvam/KAFKA-5033-bump-retries-for-idempotent-producer,5
KAFKA-2163; The offsets manager's stale-offset-cleanup and offset load should be mutually exclusive; reviewed by Jun Rao,1
"MINOR: Reset timer when all the buffer is drained and empty (#7573)For scenarios where the incoming traffic of all input partitions are small, there's a pitfall that the enforced processing timer is not reset after we have enforce processed ALL records. The fix itself is pretty simple: we just reset the timer when there's no buffered records.Reviewers: Javier Holguera <javier.holguera@gmail.com>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
kafka-2249; KafkaConfig does not preserve original Properties; patched by Gwen Shapira; reviewed by Jun Rao,5
"KAFKA-7354; Fix IdlePercent and NetworkProcessorAvgIdlePercent metricCurrently, MBean `kafka.network:type=Processor,name=IdlePercent,networkProcessor=*` and `afka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent` could be greater than 1. However, these two values represent a percentage which should not exceed 1.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5584 from huxihx/KAFKA-7354",1
"MINOR: KIP-211 Follow-up (#5272)Updates the description of `offsets.retention.minutes` config, and fixes an upgrade note.",0
"KAFKA-6592: Follow-up (#4864)Do not require ConsoleConsumer to specify inner serde as s special property, but just a normal property of the message formatter.",5
"KAFKA-6275: Add DeleteGroups API (KIP-229) (#4479)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-985 integer overflow in log time configuration values. Patch from Frank Fejes.,5
"MINOR: Add missing configs for resilience settingsReviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: Use port 0 in ResetIntegrationWithSslTestI found this by running the tests while I happened tohave a kafka broker running.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4065 from tombentley/MINOR-random-port,1
Avoid increasing app ID when test is executed multiple times (#10939)The integration test TaskMetadataIntegrationTest will increasethe length of the app ID when its test methods are called multipletimes in one execution. This is for example the case if yourepeatedly run the test until failure in IntelliJ IDEA. This mightalso lead to exceptions because the state directory depends on theapp ID and directory names have a length limit.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-9188; Fix flaky test SslAdminClientIntegrationTest.testSynchronousAuthorizerAclUpdatesBlockRequestThreads (#7918)The test blocks requests threads while sending the ACL update requests and occasionally hits request timeout. Updated the test to tolerate timeouts and retry the request for that case. Added an additional check to verify that the requests threads are unblocked when the semaphore is released, ensuring that the timeout is not due to blocked threads.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
MINOR: Add missing quote for malformed line content (#8070)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
KAFKA-10304: Refactor MM2 integration tests (#9224)Co-authored-by: Ning Zhang <nzhang1220@fb.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>,3
"KAFKA-4108; Improve DumpLogSegments offsets-decoder output formatThis PR improves the output format of DumpLogSegments when the `--offset-decoder` option is used for consuming `__consumer_offsets`, especially when it comes to group metadata.An example of the partial output with existing formatting:```key: metadata::console-consumer-40190 payload: consumer:range:1:{consumer-1-20240b92-fbf4-44d5-bf8c-66b6d70c9948=[foo-0]}```An example of the same output with suggested formatting:```key: {""metadata"":""console-consumer-40190""} payload: {""protocolType"":""consumer"",""protocol"":""range"",""generationId"":1,""assignment"":""{consumer-1-20240b92-fbf4-44d5-bf8c-66b6d70c9948=[foo-0]}""}```Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1937 from vahidhashemian/KAFKA-4108",5
"KAFKA-10247: Correctly reset state when task is corrupted (#8994)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: provide an example for deserialization exception handler (#5231)Also added a paragraph from data types to link to the example code.Reviewers: Matthias J. Sax <mjsax@apache.org>,2
"MINOR: Remove unused TopicAndPartition and remove unused symbols (#7119)With the removal of ZkUtils and AdminUtils, TopicAndPartition is finallyunused.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-7920; Do not permit zstd produce requests until IBP is updated to 2.1 (#6256)Fail produce requests using zstd until the inter.broker.protocol.version is large enough that replicas are ensured to support it. Otherwise, followers receive the `UNSUPPORTED_COMPRESSION_TYPE` when fetching zstd data and ISRs shrink.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-5391; Replace zkClient.delete* method with an equivalent zkUtillsijuma can you please review.Author: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3245 from baluchicken/KAFKA-5391,4
MINOR: Cache metrics were missingAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3262 from enothereska/minor-missing-metric,5
KAFKA-8855; Collect and Expose Client's Name and Version in the Brokers (KIP-511 Part 2) (#7749)Collect and expose the KIP-511 client name and version information the clients now provide to the server as part of ApiVersionsRequests.  Also refactor how we handle selector metrics by creating a ChannelMetadataRegistry class.  This will make it easier for various parts of the networking code to modify channel metrics.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
trivial change to use the correct path of kafka-clients.jar in kafka-run-class.sh,1
"KAFKA-9929: fix: add missing default implementations (#9321)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10607: Consistent behaviour for response errorCounts() (#9433)Reviewers: Lee Dongjin <dongjin@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",0
"KAFKA-6538: Changes to enhance  ByteStore exceptions thrown from RocksDBStore with more human readable info (#5103)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3085; BrokerChangeListener computes inconsistent live/dead broker listAuthor: David Jacot <david.jacot@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #752 from dajac/KAFKA-3085",4
"KAFKA-8405; Remove deprecated `kafka-preferred-replica-election` command (#10443)The `kafka-preferred-replica-election` command was deprecated in 2.4. This path removes it for 3.0. `kafka-leader-election` can be used instead.Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"Time based log segment rollout (0.8 branch); patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-475git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377165 13f79535-47bb-0310-9956-ffa450edef68",2
"MINOR: Fix typo in upgrade docs (#11466)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",2
KAFKA-7792: Add simple /agent/uptime and /coordinator/uptime health check endpoints (#6130)Reviewed-by: Colin P. McCabe <cmccabe@apache.org>,1
KAFKA-8390: Use automatic RPC generation in CreateDelegationToken (#6828)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
MINOR: Remove redundant apostrophe in doc (#9976)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-13673: disable idempotence when config conflicts (#11788)Disable idempotence when conflicting config values for acks, retriesand max.in.flight.requests.per.connection are set by the user. For theformer two configs, we log at info level when we disable idempotencedue to conflicting configs. For the latter, we log at warn level sinceit's due to an implementation detail that is likely to be surprising.This mitigates compatibility impact of enabling idempotence by default.Added unit tests to verify the change in behavior.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",5
MINOR: fix kafka-metadata-shell.sh (#10226)* Fix CLASSPATH issues in the startup script* Fix overly verbose log messages during loading* Update to use the new MetadataRecordSerde (this is needed now that we  have a frame version)* Fix initializationReviewers: Jason Gustafson <jason@confluent.io>,5
MINOR:: Fix typos (#6079)1. Use singular form instead of plural form2. Add a missing period,1
KAFKA-12754: Improve endOffsets for TaskMetadata (#10634)Improve endOffsets for TaskMetadata by updating immediately after polling a new batchReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
HOTFIX: remove unused import for RequestHeaderTest,3
"KAFKA-1683; persisting session information in RequestsAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Sriharsha Chintalapa, Ismael Juma, Edward Ribeiro, Parth Brahmbhatt, Jun RaoCloses #155 from gwenshap/KAFKA-1683",5
"KAFKA-9830: Implement AutoCloseable in ErrorReporter and subclasses (#8442)* The DeadLetterQueueReporter has a KafkaProducer that it must close to clean up resources* Currently, the producer and its threads are leaked every time a task is stopped* Responsibility for cleaning up ErrorReporters is transitively assigned to the    ProcessingContext, RetryWithToleranceOperator, and WorkerSinkTask/WorkerSinkTask classes* One new unit test in ErrorReporterTest asserts that the producer is closed by the dlq reporterReviewers: Arjun Satish <arjun@confluent.io>, Chris Egerton <chrise@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
kafka-1803; UncleanLeaderElectionEnableProp in LogConfig should be of boolean; patched by Dave Parfitt; reviewed by Jun Rao,5
"MINOR: Fix generic types in StreamsBuilder and Topology (#8273)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-3495; NetworkClient.blockingSendAndReceive` should rely on requestTimeoutAlso removed the code for handling negative timeouts in `blockingReady` as `Selector.poll` has not supported that for a while.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1177 from ijuma/kafka-3495-blocking-send-and-receive-request-timeout,1
trivial fix to add trace logging in FetcherRunnablegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1244792 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-5656; Support bulk attributes request on KafkaMbean where some attributes do not existAuthor: Erik Kringen <erik.kringen@icloud.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3582 from ErikKringen/trunk",1
kafka-1562; kafka-topics.sh alter add partitions resets cleanup.policy; patched by Jonathan Natkins; reviewed by Jun Rao,4
KAFKA-5603; Don't abort TX for zombie tasksAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3719 from mjsax/kafka-5603-dont-abort-tx-for-zombie-tasks-2,5
KAFKA-1437; Consumer metadata response should include (empty) coordinator information if the coordinator is unavailable; reviewed by Neha Narkhede and Guozhang Wang.,5
change default zk connection limit to infinite; KAFKA-88git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1155041 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Add note about topic IDs to upgrade doc (#10125)Reviewers: Jun Rao <junrao@gmail.com>,2
"MINOR: Refactor replica log dir fetching for improved logging (#6313)In order to debug problems with log directory reassignments, it is helpful to know when the fetcher thread begins moving a particular partition. This patch refactors the fetch logic so that we stick to a selected partition as long as it is available and log a message when a different partition is selected.Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>",2
MINOR: Update powermock and enable its tests when running with Java 9Also:1. Fix WorkerTest to use the correct `Mock` annotations. `org.easymock.Mock`is not supported by PowerMock 2.x.2. Rename `powermock` to `powermockJunit4` in `dependencies.gradle` forclarity.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3881 from ijuma/kafka-5884-powermock-java,5
MINOR: Add actual state directory to related exceptions (#11751)For debugging it is useful to see the actual state directory whenan exception regarding the state directory is thrown.Reviewer: Bill Bejeck <bbejeck@apache.org>,1
"KAFKA-3548: Use root locale for case transformation of constant stringsFor enums and other constant strings, use locale independent case conversions to enable comparisons to work regardless of the default locale.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Manikumar Reddy, Ismael Juma, Guozhang Wang, Gwen ShapiraCloses #1220 from rajinisivaram/KAFKA-3548",5
"MINOR: don't require key serde in join materialized (#7557)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Support KRaft in GroupAuthorizerIntegrationTest (#12336)Support KRaft in `GroupAuthorizerIntegrationTest`. Reviewers: David Arthur <mumrah@gmail.com>,3
"MINOR: remove commented out code and System.out.printlnRemove commented out code and System.out.println from KTableKTableJoinIntegrationTestAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2092 from dguy/cleanup-comments",4
"KAFKA-4516: When a CachingStateStore is closed it should clear its associated NamedCacheClear and remove the NamedCache from the ThreadCache when a CachingKeyValueStore or CachingWindowStore is closed.Validate that the store is open when doing any queries or writes to Caching State Stores.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2235 from dguy/kafka-4516",5
"KAFKA-13128: wait for all keys to be fully processed in #shouldQueryStoresAfterAddingAndRemovingStreamThread (#11113)This test is flaky due to waiting on all records to be processed for only a single key before issuing IQ lookups and asserting whether data was found.Reviewers:  Phil Hardwick, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-6086: Provide for custom error handling when Kafka Streams fails to produceThis PR creates and implements the `ProductionExceptionHandler` as described in [KIP-210](https://cwiki.apache.org/confluence/display/KAFKA/KIP-210+-+Provide+for+custom+error+handling++when+Kafka+Streams+fails+to+produce).I've additionally provided a default implementation preserving the existing behavior. I fixed various compile errors in the tests that resulted from my changing of method signatures, and added tests to cover the new behavior.Author: Matt Farmer <mfarmer@rsglab.com>Author: Matt Farmer <matt@frmr.me>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4165 from farmdawgnation/msf/kafka-6086",5
"KAFKA-7023: Add unit test (#5197)Add a unit test that validates after restoreStart, the options are set with bulk loading configs; and after restoreEnd, it resumes to the customized configsReviewers: Matthias J. Sax <matthias@confluent.io>",5
"MINOR: add javadoc comment to PersistenKeyValueFactory.enableCachingmissing javadoc on public API method PersistenKeyValueFactory.enableCachingAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1891 from dguy/minor-java-doc",2
"KAFKA-6819: Pt. 1 - Refactor thread-level Streams metrics (#6631)* StreamsMetricsImpl wraps the Kafka Streams' metrics registry and provides logic to createand register sensors and their corresponding metrics. An example for such logic can be found inthreadLevelSensor(). Furthermore, StreamsMetricsmpl keeps track of the sensors on thedifferent levels of an application, i.e., thread, task, etc., and provides logic to remove sensors perlevel, e.g., removeAllThreadLevelSensors(). There is one StreamsMetricsImpl object perapplication instance.* ThreadMetrics contains only static methods that specify all built-in thread-level sensors andmetrics and provide logic to register and retrieve those thread-level sensors, e.g., commitSensor().* From anywhere inside the code base with access to StreamsMetricsImpl, thread-level sensors can be accessed by using ThreadMetrics.* ThreadsMetrics does not inherit from StreamsMetricsImpl anymore.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3016: phase-1. A local store for join windowguozhangwangAn implementation of local store for join window. This implementation uses ""rolling"" of RocksDB instances for timestamp based truncation.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #726 from ymatsuda/windowed_join",5
"KAFKA-10754: fix flaky tests by waiting kafka streams be in running state before assert (#9629)The flaky test is because we didn't wait for the streams become RUNNING before verifying the state becoming ERROR state. This fix explicitly wait for the streams become RUNNING state. Also, put the 2nd stream into try resource block so it will be closed after the test.Reviewers: Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
KAFKA-7658: Add KStream#toTable to the Streams DSL (#7985)Implements KIP-523.Reviewer: Matthias J. Sax <matthias@confluent.io>,5
kafka-1154; replicas may not have consistent data after becoming follower; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,5
"KAFKA-5279: TransactionCoordinator must expire transactionalIdsremove transactions that have not been updated for at least `transactional.id.expiration.ms`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Apurva Mehta, Guozhang WangCloses #3101 from dguy/kafka-5279",5
"KAFKA-9742: Fix broken StandbyTaskEOSIntegrationTest (#8330)Relax the requirement that tasks' reported offsetSum is less than the endOffsetSum for thosetasks. This was surfaced by a test for corrupted tasks, but it can happen with real corruptedtasks. Rather than throw an exception on the leader, we now de-prioritize the corrupted task.Ideally, that instance will not get assigned the task and the stateDirCleaner will makethe problem ""go away"". If it does get assigned the task, then it will detect the corruption anddelete the task directory before recovering the entire changelog. Thus, the estimate we provideaccurately reflects the amount of lag such a corrupted task would have to recover (the whole log).Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"HOTFIX: Only measure in nano when producer metadata refresh is required (#12102)We added the metadata wait time in total blocked time (#11805). But we added it in the critical path of send which is called per-record, whereas metadata refresh only happens rarely. This way the cost of time.nanos becomes unnecessarily significant as we call it twice per record.This PR moves the call to inside the waitOnMetadata callee and only when we do need to wait for a metadata refresh round-trip (i.e. we are indeed blocking).Reviewers: Matthias J. Sax <matthias@confluent.io>",5
"MINOR: comments on KStream methods, and fix genericsguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #591 from ymatsuda/comments",5
"KAFKA-3260 - Added SourceTask.commitRecordAdded commitRecord(SourceRecord record) to SourceTask. This method is called during the callback from producer.send() when the message has been sent successfully. Added commitTaskRecord(SourceRecord record) to WorkerSourceTask to handle calling commitRecord on the SourceTask. Updated tests for calls to commitRecord.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #950 from jcustenborder/KAFKA-3260",5
"KAFKA-6234; Increased timeout value for lowWatermark response to fix transient failures (#4238)Removed timeout from get call that caused the test to fail occasionally, this will instead fall back to the wrapping waitUntilTrue timeout. Also added unnesting of exceptions from ExecutionException that was originally missing and put the retrieved value for lowWatermark in the fail message for better readability in case of test failure.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-310 Incomplete message set validation checks in Log's append API can corrupt on disk log segment; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1303861 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-4216; Control Leader & Follower Throttled Replicas SeparatelySplits the throttled replica configuration (the list of which replicas should be throttled for each topic) into two. One for the leader throttle, one for the follower throttle.So: quota.replication.throttled.replicas=>quota.leader.replication.throttled.replicas & quota.follower.replication.throttled.replicasAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1906 from benstopford/KAFKA-4216-seperate-leader-and-follower-throttled-replica-lists",5
"KAFKA-2697: client-side support for leave groupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #414 from hachikuji/KAFKA-2697",5
"MINOR: Bump the request timeout for the transactional message copierMultiple inflights means that when there are rolling bounces or other cluster instability, there is an increased likelihood of having previously tried batch expire in the accumulator. This is a fatal errorfor a transactional producer, causing the `TransactionalMessageCopier` to exit. To work around this, we bump the request timeout. We can get rid of this when KIP-91 is merged.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4039 from apurvam/MINOR-bump-request-timeout-in-transactional-message-copier",5
KAFKA-10693: Close quota managers created in tests (#9573)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-12591; Remove deprecated `quota.producer.default` and `quota.consumer.default` configurations (#10427)`quota.producer.default` and `quota.consumer.default` were deprecated in AK 0.11.0.0. Dynamic default quotas must be used instead. This patch removes them for AK 3.0. Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-3021: Centralize dependency version managementAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #741 from granthenke/central-deps,5
"MINOR: Fix build and JavaDoc warnings (#8291)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, @SoontaekLim, Bill Bejeck <bill@confluent.io>",5
"KAFKA-10599: Implement basic CLI tool for feature versioning system (#9409)This PR implements a basic CLI tool for feature versioning system. The KIP-584 write up has been updated to suit this PR. The following is implemented in this PR:--describe:Describe supported and finalized features.Usage: $> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --describe [--from-controller] [--command-config <path_to_java_properties_file>]Optionally, use the --from-controller option to get features from the controller.--upgrade-all:Upgrades all features known to the tool to their highest max version levels.Usage: $> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --upgrade-all [--dry-run] [--command-config <path_to_java_properties_file>]Optionally, use the --dry-run CLI option to preview the feature updates without actually applying them.--downgrade-all:Downgrades existing finalized features to the highest max version levels known to this tool.Usage: $> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --downgrade-all [--dry-run] [--command-config <path_to_java_properties_file>].Optionally, use the --dry-run CLI option to preview the feature updates without actually applying them.Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",5
"MINOR: Code refacotring in KTable-KTable Join (#4486)1. Rename KTableKTableJoin to KTableKTableInnerJoin. Also removed abstract from other joins.2. Merge KTableKTableJoinValueGetter.java into KTableKTableInnerJoin.3. Use set instead of arrays in the stores function, to avoid duplicate stores to be connected to processors.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-2705; Remove static JAAS config file for ZK auth testsRemove static login config file.Author: Flavio Junqueira <fpj@apache.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #380 from fpj/KAFKA-2705,2
kafka-1999; Fix failing unit-test: kafka.api.ProducerFailureHandlingTest > testNotEnoughReplicasAfterBrokerShutdown; patched by Gwen Shapira; reviewed by Jun Rao,3
"MINOR: Fixed Non-Final Close Method + its DuplicationAuthor: Armin Braun <me@obrown.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2582 from original-brownbear/cleanup-nonfinal-close",4
KAFKA-12393: Document multi-tenancy considerations (#334) (#10263)KAFKA-12393: Document multi-tenancy considerationsAddressed review feedback by @dajac and @rajinisivaramPorted from apache/kafka-site#334Reviewers: Bill Bejeck <bbejeck@apache.org>,5
KAFKA-10776: Add version attribute in RequestsPerSec metrics documentation (#9661)See https://cwiki.apache.org/confluence/display/KAFKA/KIP-272%3A+Add+API+version+tag+to+broker%27s+RequestsPerSec+metricReviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-8611: update documentation for KIP-221 (#8558)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Fix typos in `TransactionManager` (#11924)Reviewers: Kvicii <Karonazaba@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: improve StateStore JavaDocsClarify that state directory must use `storeName`Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4228 from mjsax/minor-state-store-javadoc",2
"KAFKA-6145: KIP-441: Build state constrained assignment from balanced one (#8497)Implements: KIP-441Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: Clarify ReadOnlyWindowStore's time range behaviourHighlight that the range in `fetch` is inclusive of both `timeFrom` and `timeTo`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2811 from dguy/minor-window-fetch-java-doc",2
"KAFKA-6145: Add new assignment configsAdd 4 new assignor configs in preparation for the new assignment algorithm:1. acceptable.recovery.lag2. balance.factor3. max.warmup.replicas4. probing.rebalance.interval.msImplements: KIP-441Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
KAFKA-7309; Upgrade Jacoco for Java 11 supportJacoco 0.8.2 adds Java 11 support:https://github.com/jacoco/jacoco/releases/tag/v0.8.2Java 11 RC1 is out so it would be good for us toget a working CI build.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5568 from ijuma/jacoco-0.8.2,1
"KAFKA-7704: MaxLag.Replica metric is reported incorrectly (#5998)On the follower side, for the empty `LogAppendInfo` retrieved from the leader, fetcherLagStats set the wrong lag for fetcherLagStats due to `nextOffset` is zero.",1
KAFKA-13930: Add 3.2.0 Streams upgrade system tests (#12209)* KAFKA-13930: Add 3.2.0 Streams upgrade system testsApache Kafka 3.2.0 was recently released. Now we needto test upgrades from 3.2 to trunk in our system tests.Reviewer: Bill Bejeck <bbejeck@apache.org>,3
MINOR: remove unused hitRatio field in NamedCacheAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3384 from dguy/remove-unused-field,4
"KAFKA-9847: add config to set default store type (KIP-591) (#11705)Reviewers: Hao Li <hli@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-3265; Add a public AdminClient API in Java (KIP-117)Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2472 from cmccabe/KAFKA-3265",5
KAFKA-7321: Add a Maximum Log Compaction Lag (KIP-354) (#6009)KAFKA-7321: Add a Maximum Log Compaction Lag (KIP-354)Records become eligible for compaction after the specified time interval.Author: Xiongqi Wu <xiowu@linkedin.com>Reviewer: Joel Koshy <jjkoshy@gmail.com>,2
KAFKA-1233 Integration test for the new producer; reviewed by Jay Kreps and Neha Narkhede,1
"KAFKA-12194: use stateListener to catch each state change (#9888)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <bruno@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: Add all topics created check streams broker bounce test (trunk) (#6243)The StreamsBrokerBounceTest.test_broker_type_bounce experienced what looked like a transient failure. After looking over this test and failure, it seems like it is vulnerable to timing error that streams will start before the kafka service creates all topics.Reviewers:  Matthias J. Sax <mjsax@apache.org>, John Roesler <john@confluent.io>",5
KAFKA-1253 Compression in the new producer; reviewed by Jay Kreps and Jun Rao,1
"Fix compile errors from KAFKA-12543 (#10719)Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jun Rao <junrao@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-4234; Revert automatic offset commit behavior in consumer's `unsubscribe()`Temporarily disable the offset commit (when auto commit is enabled) in the new consumer's `unsubscribe()` method towards a workaround for the issue reported in [KAFKA-3491](https://issues.apache.org/jira/browse/KAFKA-3491).For now, a call to `unsubscribe()` can be made to reset the offsets in case processing the batch received from the most recent `poll()` is interrupted (due to some exception).Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1944 from vahidhashemian/KAFKA-4234",5
"KAFKA-4950; Fix ConcurrentModificationException on assigned-partitions metric update (#3907)Use a volatile field to track the size of the set of assigned partitions to avoid the concurrent access to the underlying linked hash map.Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Tolerate limited data loss for upgrade tests with old message format (#7102)To avoid transient system test failures, tolerate a small amount of data loss due to truncation in upgrade system tests using older message format prior to KIP-101, where data loss was possible.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-13772: Partitions are not correctly re-partitioned when the fetcher thread pool is resized (#11953)Partitions are assigned to fetcher threads based on their hash modulo the number of fetcher threads. When we resize the fetcher thread pool, we basically re-distribute all the partitions based on the new fetcher thread pool size. The issue is that the logic that resizes the fetcher thread pool updates the `fetcherThreadMap` while iterating over it. The `Map` does not give any guarantee in this case - especially when the underlying map is re-hashed - and that led to not iterating over all the fetcher threads during the process and thus in leaving some partitions in the wrong fetcher threads.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: standardize rebalance related logging for easy discovery & debugging (#9295)Some minor logging adjustments to standardize the grammar of rebalance related messages and make it easy to query the logs for quick debugging resultsGuozhang Wang <wangguoz@gmail.com>,0
KAFKA-8056; Use automatic RPC generation for FindCoordinator (#6408)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-5915; Support unmapping of mapped/direct buffers in Java 9As mentioned in MappedByteBuffers' class documentation, itsimplementation was inspired by Lucene's MMapDirectory:https://github.com/apache/lucene-solr/blob/releases/lucene-solr/6.6.1/lucene/core/src/java/org/apache/lucene/store/MMapDirectory.java#L315Without this change, unmapping fails with the following message:> java.lang.IllegalAccessError: class kafka.log.AbstractIndex (in unnamed module 0x45103d6b) cannot access class jdk.internal.ref.Cleaner (in module java.base) because module java.base does not export jdk.internal.ref to unnamed module 0x45103d6bAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3879 from ijuma/kafka-5915-unmap-mapped-buffers-java-9",5
MINOR: Increase zk connection timeout in tests for client created in `KafkaServer`We had already made this change to the client created in `ZooKeeperTestHarness`.I last saw this failure when `SaslPlaintextTopicMetadataTest.testAliveBrokerListWithNoTopics`was executed in Jenkins.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2066 from ijuma/increase-zk-timeout-in-kafka-server,1
MINOR: Make sure generated docs don't get checked inAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Guozhang WangCloses #469 from granthenke/generated-configs,5
MINOR: make sure alterAclsPurgatory is closed when controller server … (#10868)Reviewers:  Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-5627; Reduce classes needed for LeaderAndIsrPartitionState and MetadataPartitionStateAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3565 from lindong28/KAFKA-5627",5
KAFKA-1996 Fix scaladoc error.,0
"KAFKA-13419: Only reset generation ID when ILLEGAL_GENERATION error (#11451)Updated: This PR will reset generation ID when ILLEGAL_GENERATION error since the member ID is still valid.=====resetStateAndRejoin when REBALANCE_IN_PROGRESS error in sync group, to avoid out-of-date ownedPartition== JIRA description ==In KAFKA-13406, we found there's user got stuck when in rebalancing with cooperative sticky assignor. The reason is the ""ownedPartition"" is out-of-date, and it failed the cooperative assignment validation.Investigate deeper, I found the root cause is we didn't reset generation and state after sync group fail. In KAFKA-12983, we fixed the issue that the onJoinPrepare is not called in resetStateAndRejoin method. And it causes the ownedPartition not get cleared. But there's another case that the ownedPartition will be out-of-date. Here's the example:consumer A joined and synced group successfully with generation 1New rebalance started with generation 2, consumer A joined successfully, but somehow, consumer A doesn't send out sync group immediatelyother consumer completed sync group successfully in generation 2, except consumer A.After consumer A send out sync group, the new rebalance start, with generation 3. So consumer A got REBALANCE_IN_PROGRESS error with sync group responseWhen receiving REBALANCE_IN_PROGRESS, we re-join the group, with generation 3, with the assignment (ownedPartition) in generation 1.So, now, we have out-of-date ownedPartition sent, with unexpected results happenedWe might want to do resetStateAndRejoin when RebalanceInProgressException errors happend in sync group. Because when we got sync group error, it means, join group passed, and other consumers (and the leader) might already completed this round of rebalance. The assignment distribution this consumer have is already out-of-date.Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13947: Use %d formatting for integers rather than %s (#12267)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>, Kvicii <kvicii.yu@gmail.com>",1
kafka-2241; AbstractFetcherThread.shutdown() should not block on ReadableByteChannel.read(buffer); patched by Dong Lin; reviewed by Jun Rao,5
"KAFKA-4340; Follow-up fixing system test failures and handling non default log.retention.msAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2544 from becketqin/KAFKA-4340_follow_up",2
"KAFKA-5314; exception handling and cleanup for state storesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3135 from enothereska/exceptions-stores-KAFKA-5314",5
Patching remaining files from KAFKA-644git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418569 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-9445: Allow adding changes to allow serving from a specific partition (#7984)Implements KIP-562.Reviewers: Vinoth Chandar <vchandar@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-2893: Add a simple non-negative partition seek checkAuthor: jinxing <jinxing@fenbi.com>Author: ZoneMayor <jinxing6042@126.com>Reviewers: Guozhang WangCloses #628 from ZoneMayor/trunk-KAFKA-2893,1
MINOR: Use min/max function when possible (#8577)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: fix shutdownHook in ConsoleConsumerAuthor: Confluent <confluent@Confluents-MacBook-Pro.local>Reviewers: Jun Rao <junrao@gmail.com>Closes #548 from guozhangwang/HFConsoleConsumer,5
"KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [partial] (#4832)* Remove ProcessorTopologyTestDriver from TopologyTest* Fix ProcessorTopologyTest* Remove ProcessorTopologyTestDriver and InternalTopologyAccessor* Partially refactored StreamsBuilderTest but missing one test* Refactor KStreamBuilderTest* Refactor AbstractStreamTest* Further cleanup of AbstractStreamTest* Refactor GlobalKTableJoinsTest* Refactor InternalStreamsBuilderTest* Fix circular dependency in build.gradle* Refactor KGroupedStreamImplTest* Partial modifications to KGroupedTableImplTest* Refactor KGroupedTableImplTest* Refactor KStreamBranchTest* Refactor KStreamFilterTest* Refactor KStreamFlatMapTest KStreamFlatMapValuesTest* Refactor KStreamForeachTest* Refactor KStreamGlobalKTableJoinTest* Refactor KStreamGlobalKTableLeftJoinTest* Refactor KStreamImplTest* Refactor KStreamImplTest* Refactor KStreamKStreamJoinTest* Refactor KStreamKStreamLeftJoinTest* Refactor KStreamKTableJoinTest* Refactor KStreamKTableLeftJoinTest* Refactor KStreamMapTest and KStreamMapValuesTest* Refactor KStreamPeekTest and KStreamTransformTest* Refactor KStreamSelectKeyTest* Refactor KStreamTransformValuesTest* Refactor KStreamWindowAggregateTest* Add Depercation anotation to KStreamTestDriver and rollback failing tests in StreamsBuilderTest and KTableAggregateTest* Refactor KTableFilterTest* Refactor KTableForeachTest* Add getter for ProcessorTopology, and simplify tests in StreamsBuilderTest* Refactor KTableImplTest* Remove unused imports* Refactor KTableAggregateTest* Fix style errors* Fix gradle build* Address reviewer comments:  - Remove properties new instance  - Remove extraneous line  - Remove unnecessary TopologyTestDriver instances from StreamsBuilderTest  - Move props.clear() to @After  - Clarify use of timestamp in KStreamFlatMapValuesTest  - Keep test using old Punctuator in KStreamTransformTest  - Add comment to clarify clock advances in KStreamTransformTest  - Add TopologyTestDriverWrapper class to access the protected constructor of TopologyTestDriver  - Revert KTableImplTest.testRepartition to KStreamTestDriver to avoid exposing the TopologyTestDriver processor topology  - Revert partially migrated classes: KTableAggregateTest, KTableFilterTest, and KTableImplTest* Rebase on current trunk an fix conflictsReviewers: Matthias J Sax <matthias@confluentio>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-3185: Allow users to cleanup internal Kafka Streams data- added Kafka Stream Application Reset ToolAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang, Michael G. NollCloses #1636 from mjsax/kafka-3185",5
"KAFKA-8400; Do not update follower replica state if the log read failed (#6814)This patch checks for errors handling a fetch request before updating follower state. Previously we were unsafely passing the failed `LogReadResult` with most fields set to -1 into `Replica` to update follower state. Additionally, this patch attempts to improve the test coverage for ISR shrinking and expansion logic in `Partition`.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
MINOR: Fixed a couple of typos in Config docsAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Gwen ShapiraCloses #6259 from mimaison/config-typos,5
MINOR: Typo fixes in ReplicaFetchMaxBytesDocAuthor: Dionysis Grigoropoulos <dgrig@erethon.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1228 from Erethon/trunk,1
"KAFKA-13971:Atomicity violations caused by improper usage of ConcurrentHashMap (#12277)Reviewers: Divij Vaidya <diviv@amazon.com>, Chris Egerton <fearthecellos@gmail.com>",1
"MINOR: improve log4j messaging (#4530)Reviewers: Matthias J. Sax <matthias@confluent.io>, James Cheng <jylcheng@yahoo.com>",5
"KAFKA-6036: Follow-up; cleanup sendOldValues logic ForwardingCacheFlushListener  (#6017)This is a follow-up PR from the previous PR #5779, where KTabeSource always get old values from the store even if sendOldValues. It gets me to make a pass over all the KTable/KStreamXXX processor to push the sendOldValues at the callers in order to avoid unnecessary store reads.More details: ForwardingCacheFlushListener and TupleForwarder both need sendOldValues as parameters.a. For ForwardingCacheFlushListener it is not needed at all, since its callers XXXCachedStore already use the sendOldValues values passed from TupleForwarder to avoid getting old values from underlying stores.b. For TupleForwarder, it actually only need to pass the boolean flag to the cached store; and then it does not need to keep it as its own variable since the cached store already respects the boolean to pass null or the actual value..The only other minor bug I found from the pass in on KTableJoinMerge, where we always pass old values and ignores sendOldValues.Reviewers: Matthias J. Sax <mjsax@apache.org>",4
KAFKA-4777; Backoff properly in consumer heartbeat thread if no brokers are availableAuthor: Allen Xiang <allen.xiang@monsanto.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2564 from allenxiang/client-heartbeat-fix,0
KAFKA-5960; Follow-up cleanupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3976 from hachikuji/version-fix-followup,0
MINOR: Fix bugs in handling zero-length ImplicitLinkedHashCollections (#7163)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
MINOR: system tests - avoid 'sasl.enabled.mechanisms' in listener overrides (#7018)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-13850: Show missing record type in MetadataShell (#12103)AccessControlEntryRecord and RemoveAccessControlEntryRecord are added in KIP-801, FeatureLevelRecord was added in KIP-778, and BrokerRegistrationChangeRecord was added in KIP-841, and NoOpRecord was added in KIP-835, I added these 5 record types in MetadataShell. Reviewers: Luke Chen <showuon@gmail.com>",5
"KAFKA-12648: introduce TopologyConfig and TaskConfig for topology-level overrides (#11272)Most configs that are read and used by Streams today originate from the properties passed in to the KafkaStreams constructor, which means they get applied universally across all threads, tasks, subtopologies, and so on. The only current exception to this is the topology.optimization config which is parsed from the properties that get passed in to StreamsBuilder#build. However there are a handful of configs that could also be scoped to the topology level, allowing users to configure each NamedTopology independently of the others, where it makes sense to do so.This PR refactors the handling of these configs by interpreting the values passed in via KafkaStreams constructor as the global defaults, which can then be overridden for individual topologies via the properties passed in when building the NamedTopology. More topology-level configs may be added in the future, but this PR covers the following:max.task.idle.mstask.timeout.msbuffered.records.per.partitiondefault.timestamp.extractor.classdefault.deserialization.exception.handlerReviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>, Luke Chen <showuon@confluent.io>",5
"KAFKA-10235 Fix flaky transactions_test.py (#8981)Reducing timeout of transaction to clean up the unstable offsets quicker. IN hard_bounce mode, transactional client is killed ungracefully. Hence, it produces unstable offsets which obstructs TransactionalMessageCopier from receiving position of group.Reviewers: Jun Rao <junrao@gmail.com>",1
"MINOR: Remove unused imports, exceptions, and values (#6117)1. Remove unthrown exceptions from MemoryRecordsBuilderTest2. Remove unused imports from ReplicaFetcherThread, ZooKeeperClient, ApiVersionTest, PartitionTest3. Remove unused value from PartitionTest",3
"KAFKA-4303; Ensure commitSync does not block unnecessarily in poll without in-flight requestsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2031 from hachikuji/KAFKA-4303",5
Niek Sanders - KAFKA-284 fixed compilation issue for cpp clientgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1295388 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-8755: Fix state restore for standby tasks with optimized topology (#7238)Key changes include:1. Moves general offset limit updates down to StandbyTask.2. Updates offsets for StandbyTask at most once per commit and only when we need and updated offset limit to make progress.3. Avoids writing an 0 checkpoint when StandbyTask.update is called but we cannot apply any of the records.4. Avoids going into a restoring state in the case that the last checkpoint is greater or equal to the offset limit (consumer committed offset). This needs special attention please. Code is inStoreChangelogReader.5. Does update offset limits initially for StreamTask because it provides a way to prevent playing to many records from the changelog (also the input topic with optimized topology).NOTE: this PR depends on KAFKA-8816, which is under review separately. Fortunately the changes involved are few. You can focus just on the KAFKA-8755 commit if you prefer.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",4
"MINOR: update AWS test setup guideAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Joseph Rea <jrea@users.noreply.github.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2575 from mjsax/minor-update-system-test-readme",5
"MINOR: Fix JSON generation of nested structs with non-matching type/name (#9277)The schema specification allows a struct type name to differ from the field name. This works with the generated `Message` classes, but not with the generated JSON converter. The patch fixes the problem, which is that the type name is getting replaced with the field name when the struct is registered in the `StructRegistry`.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-5144: renamed variables in MinTimestampTracker and added commentsThe descendingSubsequence is a misnomer. The linked list is actually arranged so that the lowest timestamp is first and larger timestamps are added to the end, therefore renamed to ascendingSubsequence.The minElem variable was also misnamed. It's actually the current maximum element as it's taken from the end of the list.Added comment to get() to make it clear it's returning the lowest timestamp.Author: mihbor <mihbor@users.noreply.github.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2948 from mihbor/patch-4",1
"MINOR: Compatibility and upgrade tests for 0.11.0.xAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>Closes #3454 from ijuma/test-upgrades-from-0.11.0.x",3
"MINOR: Include TopicPartition in warning when log cleaner resets dirty offsetTypically this error condition is caused by topic-level configuration issues, so it is useful to include which topic partition was reset for operator use when debugging the root cause.Author: Dana Powers <dana.powers@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1801 from dpkp/log_topic_partition_reset_dirty_offset",2
Fix wildcard consumption to work with greater than one stream; KAFKA-550; patched by Joel Koshy; reviewed by Jun Rao and Neha Narkhede.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1396425 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Improve a Windows quickstart instructionThe output of `wmic` can be very long and could truncate the search keywords in the existing command. If those keywords are truncated no process is returned in the output. An update is suggested to the command by which the query is performed inside the `wmic` command itself instead of using pipes and `find`.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4083 from vahidhashemian/minor/improve_quickstart_for_windows_wmic,1
"MINOR: syntax brush for java / bash / json / textAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Derrick Or <derrickor@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3214 from guozhangwang/KMinor-doc-java-brush",2
kafka-2005; Generate html report for system tests; patched by Ashish Singh; reviewed by Jun Rao,3
KAFKA-4585: Lower the Minimum Required ACL Permission of OffsetFetch (KIP-163)Details can be found in the [KIP](https://cwiki.apache.org/confluence/display/KAFKA/KIP-163%3A+Lower+the+Minimum+Required+ACL+Permission+of+OffsetFetch).Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3661 from vahidhashemian/KAFKA-4585,5
KAFKA-368 use the pig core jar from maven instead of distributing it patch by Joe Stein reviewed by Jun Rao and Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1352145 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Improve EOS related config docsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4284 from mjsax/minor-improve-eos-docs",2
"KAFKA-6254; Incremental fetch requestsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #4418 from cmccabe/KAFKA-6254",5
KAFKA-6930: Convert byte array to string in KafkaZkClient debug log (#5061)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-13563: clear FindCoordinatorFuture for non consumer group mode (#11631)After KAFKA-10793, we clear the findCoordinatorFuture in 2 places:1. heartbeat thread2. AbstractCoordinator#ensureCoordinatorReadyBut in non consumer group mode with group id provided (for offset commitment. So that there will be consumerCoordinator created), there will be no (1)heartbeat thread , and it only call (2)AbstractCoordinator#ensureCoordinatorReady when 1st time consumer wants to fetch committed offset position. That is, after 2nd lookupCoordinator call, we have no chance to clear the findCoordinatorFuture , and causes the offset commit never succeeded.To avoid the race condition as KAFKA-10793 mentioned, it's not safe to clear the findCoordinatorFuture in the future listener. So, I think we can fix this issue by calling AbstractCoordinator#ensureCoordinatorReady when coordinator unknown in non consumer group case, under each ConsumerCoordinator#poll.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-6111: Improve test coverage of KafkaZkClient, fix bugs found by new tests;",3
kafka-1851; OffsetFetchRequest returns extra partitions when input only contains unknown partitions; patched by Jun Rao; reviewed by Neha Narkhede,1
"MINOR: fix broken JavaDoc links (#10890)Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-13310 : KafkaConsumer cannot jump out of the poll method, and the… (#11340)Title: KafkaConsumer cannot jump out of the poll method, and cpu and traffic on the broker side increase sharplydescription: The local test has been passed, the problem described by jira can be solvedJIRA link : https://issues.apache.org/jira/browse/KAFKA-13310Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",0
"MINOR: Add extra notice about IQv2 compatibility (#11944)Added an extra notice about IQv2's API compatibility, as discussed in the KIP-796 vote thread.Reviewers: Bill Bejeck <bbejeck@apache.org>, @Kvicii",1
MINOR: Fix typo in leader epoch change log message (#4476),2
"KAFKA-2153 kafka-patch-review tool uploads a patch even if it is empty; reviewed by Neha Narkhede, Gwen Shapira",5
KAFKA-9662: Wait for consumer offset reset in throttle test to avoid losing early messages (#8227),3
KAFKA-1327; Log cleaner metrics follow-up patch to reset dirtiest log cleanable ratio; reviewed by Jun Rao(cherry picked from commit 874620d),4
"KAFKA-8962; Use least loaded node for AdminClient#describeTopics (#7421)Allow routing of `AdminClient#describeTopics` to any broker in the cluster than just the controller, so that we don't create a hotspot for this API call. `AdminClient#describeTopics` uses the broker's metadata cache which is asynchronously maintained, so routing to brokers other than the controller is not expected to have a significant difference in terms of metadata consistency; all metadata requests are eventually consistent.This patch also fixes a few flaky test failures.Reviewers: Ismael Juma <ismael@juma.me.uk>, José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5320: Include all request throttling in client throttle metricsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3137 from rajinisivaram/KAFKA-5320",5
"MINOR: KIP-182 follow up; add deprecation annotations to test classesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4051 from mjsax/minor-kip-182-follow-up",5
Disallow clients to set replicaId in FetchRequest; kafka-699; patched by Jun Rao; reviewed by Neha Narkhede,1
TRIVIAL: Fix failing producer integration tests.,3
HOTFIX: fix active task process ratio metric recording,0
"KAFKA-4764; Wrap SASL tokens in Kafka headers to improve diagnostics (KIP-152)SASL handshake protocol changes from KIP-152.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #3708 from rajinisivaram/KAFKA-4764-SASL-diagnostics",5
"MINOR: Introduce `producer.config` property to `ConsoleProducer`This makes it easier to pass security properties in the same wayto `ConsoleConsumer` and `ConsoleProducer`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #544 from ijuma/producer-config-in-console-producer",5
"* MINOR: Catching null pointer exception for empty leader URL when assignment is null (#4798)Catch null pointer exception for empty leader URL when assignment is null.Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7182: SASL/OAUTHBEARER client response missing %x01 seps (#5391)The SASL/OAUTHBEARER client response as currently implemented in OAuthBearerSaslClient sends the valid gs2-header ""n,,"" but then sends the ""auth"" key and value immediately after it.This does not conform to the specification because there is no %x01 after the gs2-header, no %x01 after the auth value, and no terminating %x01. Fixed this and the parsing of the client response inOAuthBearerSaslServer, which currently allows the malformed text. Also updated to accept and ignore unknown properties as required by the spec.Reviewers: Stanislav Kozlovski <familyguyuser192@windowslive.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-12245; Fix flaky `FetcherTest.testEarlierOffsetResetArrivesLate` (#10006)Rewrite the test case so that it is deterministic and does not depend on multiple threads.Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-13243: KIP-773 Differentiate metric latency measured in ms and ns (#11302)KAFKA-13243: KIP-773 Differentiate metric latency measured in ms and nsImplementation of KIP-773Deprecates inconsistent metrics bufferpool-wait-time-total,io-waittime-total, and iotime-total.Introduces new metrics bufferpool-wait-time-ns-total,io-wait-time-ns-total, and io-time-ns-total with the same semantics asbefore.Adds metrics (old and new) in ops.html.Adds upgrade guide for these metrics.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Tom Bentley <tbentley@redhat.com>",1
"kafka-1864; Revisit defaults for the internal offsets topic; patched by Jun Rao; reviewed by Jeol Koshy, Neha Narkhede, and Gwen Shapira",1
MINOR: Simplify controller election utilities (#6944)This patch simplifies the controller election API. We were passing `LeaderIsrAndControllerEpoch` into the election utilities even though we just needed `LeaderAndIsr`. We also remove some unneeded collection copies `doElectLeaderForPartitions`.Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-9487: Follow-up PR of Kafka-9445 (#8033)Follows up on the original PR for KAFKA-9445 to address a final round of feedbackReviewers: John Roesler <vvcephei@apache.org>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-9101: Create a fetch.max.bytes configuration for the broker (#7595)Create a fetch.max.bytes configuration for the broker as described by KIP-541.Reviewers: Gwen Shapira <gwen@confluent.io>,5
Controller tests throw several zookeeper errors; patched by Yang Ye; reviewed by Jun Rao; KAFKA-416git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377161 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-2811: add standby tasksguozhangwang* added a new config param ""num.standby.replicas"" (the default value is 0).* added a new abstract class AbstractTask* added StandbyTask as a subclass of AbstractTask* modified StreamTask to a subclass of AbstractTask* StreamThread  * standby tasks are created by calling StreamThread.addStandbyTask() from onPartitionsAssigned()  * standby tasks are destroyed by calling StreamThread.removeStandbyTasks() from onPartitionRevoked()  * In addStandbyTasks(), change log partitions are assigned to restoreConsumer.  * In removeStandByTasks(), change log partitions are removed from restoreConsumer.  * StreamThread polls change log records using restoreConsumer in the runLoop with timeout=0.  * If records are returned, StreamThread calls StandbyTask.update and pass records to each standby tasks.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #526 from ymatsuda/standby_task",5
"KAFKA-9911: Add new PRODUCER_FENCED error code (#8549)Add a separate error code as PRODUCER_FENCED to differentiate INVALID_PRODUCER_EPOCH. On broker side, replace INVALID_PRODUCER_EPOCH with PRODUCER_FENCED when the request version is the latest, while still returning INVALID_PRODUCER_EPOCH to older clients. On client side, simply handling INVALID_PRODUCER_EPOCH the same as PRODUCER_FENCED if from txn coordinator APIs.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-8002; Log dir reassignment stalls if future replica has different segment base offset (#6346)This patch fixes a bug in log dir reassignment where Partition.maybeReplaceCurrentWithFutureReplica would compare the entire LogEndOffsetMetadata of each replica to determine whether the reassignment has completed. If the active segments of both replicas have different base segments (for example, if the current replica had previously been cleaned and the future replica rolled segments at different points), the reassignment will never complete. The fix is to compare only the LogEndOffsetMetadata.messageOffset for each replica. Tested with a unit test that simulates the compacted current replica case.Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-13689: Revert AbstractConfig code changes (#11863)Reviewer: Luke Chen <showuon@gmail.com>,4
"MINOR: Add select changes from 3rd KIP-307 PR for incrementing name index counter (#6754)When users provide a name for operation via the Streams DSL, we need to increment the counter used for auto-generated names to make sure any operators downstream of a named operator still produce a compatible name.This PR is a subset of #6411 by @fhussonnois. We need to merge this PR now because it covers cases when users name repartition topics or state stores.Updated tests to reflect the counter produces expected number even when the user provides a name.Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",5
"MINOR: Remove the InvalidTopicException handling in InternalTopicManager (#6167)Note we can only remove this handling in 2.2 but not in 2.1 since #6124 is only in 2.2.Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-2508; Replace UpdateMetadata{Request,Response} with o.a.k.c.req……uests equivalentAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <mail@harsha.io>Closes #896 from granthenke/update-metadata and squashes the following commits:2eb5d59 [Grant Henke] Address reviews497258d [Grant Henke] KAFKA-2508: Replace UpdateMetadata{Request,Response} with o.a.k.c.requests equivalent",5
Add missing backslash (#4474)There're missing backslash when running the quick start tutorial.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Refactor RaftClientTest to be used by other tests (#9476)There is a lot of functionality in KafkaRaftClientTest that is useful for writing other tests. Refactor that functionality into another class that can be reused in other tests.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3214: Added system tests for compressed topicsAdded CompressionTest that tests 4 producers, each using a different compression type and one not using compression.Enabled VerifiableProducer to run producers with different compression types (passed in the constructor). This includes enabling each producer to output unique values, so that the verification process in ProduceConsumeValidateTest is correct (counts acks from all producers).Also a fix for console consumer to raise an exception if it sees the incorrect consumer output (before we swallowed an exception, so was hard to debug the issue).Author: Anna Povzner <anna@confluent.io>Reviewers: Geoff Anderson, Jason GustafsonCloses #958 from apovzner/kafka-3214",5
"KAFKA-9441: Improve Kafka Streams task management (#8776) - make task manager agnostic to task state - make tasks state transitions idempotentReviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Correct spelling errors in KafkaRaftClient (#12061)Correct spelling errors in KafkaRaftClientReviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,1
MINOR: Fix KRaft snapshot delete bug in Scala 2.12 (#10997)The sliding window + takeWhile behavior over a sequence seems somewhatdifferent between Scala 2.12 and Scala 2.13. This PR works around thedifference by using foreach with an early return.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-9216: Enforce that Connect’s internal topics use `compact` cleanup policy (#8828)This change adds a check to the KafkaConfigBackingStore, KafkaOffsetBackingStore, and KafkaStatusBackingStore to use the admin client to verify that the internal topics are compacted and do not use the `delete` cleanup policy.Connect already will create the internal topics with `cleanup.policy=compact` if the topics do not yet exist when the Connect workers are started; the new topics are created always as compacted, overwriting any user-specified `cleanup.policy`. However, if the topics already exist the worker did not previously verify the internal topics were compacted, such as when a user manually creates the internal topics before starting Connect or manually changes the topic settings after the fact.The current change helps guard against users running Connect with topics that have delete cleanup policy enabled, which will remove all connector configurations, source offsets, and connector & task statuses that are older than the retention time. This means that, for example, the configuration for a long-running connector could be deleted by the broker, and this will cause restart issues upon a subsequent rebalance or restarting of Connect worker(s).Connect behavior requires that its internal topics are compacted and not deleted after some retention time. Therefore, this additional check is simply enforcing the existing expectations, and therefore does not need a KIP.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>, Chris Egerton <chrise@confluent.io>",5
KAFKA-2379: Add basic documentation for Kafka Connect.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #475 from ewencp/kafka-2379-connect-docs,2
"KAFKA-3694; Ensure broker Zk deregistration prior to restart in ReplicationTestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1365 from hachikuji/KAFKA-3694",5
"KAFKA-671 DelayedProduce requests should not hold full producer request data; reviewed by Neha Narkhede, Jun Rao and Jay Kreps",5
KAFKA-670 Clean spurious .index files; reviewed by Neha Narkhede,2
KAFKA-1883 Fix NullPointerException in RequestSendThread; reviewed by Neha Narkhede,0
MINOR: Add images missing from documentationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2008 from hachikuji/add-missing-images,1
KAFKA-10085: correctly compute lag for optimized source changelogs (#8787)Split out the optimized source changelogs and fetch the committed offsets rather than the end offset for task lag computationReviewers: John Roesler <vvcephei@apache.org>,1
"MINOR: Fix transiently failing consumer group admin integration test (#5067)Since the producer is using retries=0, we need to await topic creation before sending any records.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-5854; Handle SASL authentication failures as non-retriable exceptions in clientsThis PR implements the client-side of KIP-152, by modifying `KafkaConsumer`, `KafkaProducer`, and `ConsumerGroupCommand` to throw a non-retriable exception when SASL authentication fails.This PR is co-authored with rajinisivaram.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, tedyu <yuzhihong@gmail.com>Closes #3832 from vahidhashemian/KAFKA-5854",5
"KAFKA-6560: Replace range query with newly added single point query in Windowed Aggregation (#4578)* Add a new fetch(K key, long window-start-timestamp) API into ReadOnlyWindowStore.* Use the new API to replace the range fetch API in KStreamWindowedAggregate and KStreamWindowedReduce.* Added corresponding unit tests.* Also removed some redundant byte serdes in byte stores.",4
"MINOR: Clean up tmp files created by tests (#12233)There are a bunch of tests which do not clean up after themselves. This leads toaccumulation of files in the tmp directory of the system on which the tests arerunning. This code change fixes some of the main culprit tests which leak the files in thetemporary directory.Reviewers: Ismael Juma <ismael@juma.me.uk>, Kvicii <kvicii.yu@gmail.com>",2
"KAFKA-7965; Fix testRollingBrokerRestartsWithSmallerMaxGroupSizeConfigDisruptsBigGroup (#6557)Most of the time, the group coordinator runs on broker 1. Occasionally the group coordinator will be placed on broker 2. If that's the case, the loop starting at line 320 have no chance to check and update `kickedOutConsumerIdx`. A quick fix is to safely do another round of loop to ensure `kickedOutConsumerIdx` always be checked after the last broker restart.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-12197: Migrate connect:transforms module to JUnit 5 (#9907)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-13003: In kraft mode also advertise configured advertised port instead of socket port (#10935)In Kraft mode, Apache Kafka 2.8.0 advertises the socket port instead of the configured advertised port.A broker with the following configuration:listeners=PUBLIC://0.0.0.0:19092,REPLICATION://0.0.0.0:9091advertised.listeners=PUBLIC://envoy-kafka-broker:9091,REPLICATION://kafka-broker1:9091advertises on the PUBLIC listener envoy-kafka-broker:19092, however I would expect thatenvoy-kafka-broker:9091 is advertised. In ZooKeeper mode it works as expected. This PR changes the BrokerServer class so that in Kraft mode the configured advertised port isregistered as expected.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-8836; Add `AlterISR` RPC and use it for ISR modifications (#9100)This patch implements [KIP-497](https://cwiki.apache.org/confluence/display/KAFKA/KIP-497%3A+Add+inter-broker+API+to+alter+ISR), which introduces an asynchronous API for partition leaders to update ISR state.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-4050; Allow configuration of the PRNG used for SSLAdd an optional configuration for the SecureRandom PRNG implementation, with the default behavior being the same (use the default implementation in the JDK/JRE).Author: Todd Palino <Todd Palino>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #1747 from toddpalino/trunk",1
"KAFKA-3092: Replace SinkTask onPartitionsAssigned/onPartitionsRevoked with open/closeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #815 from hachikuji/KAFKA-3092",5
KAFKA-3558; Add compression_type parameter to benchmarks in benchmark_test.py* Use a fixed `Random` seed in `EndToEndLatency.scala` for determinism* Add `compression_type` to and remove `consumer_fetch_max_wait` from `end_to_end_latency.py`. The latter was never used.* Tweak logging of `end_to_end_latency.py` to be similar to `consumer_performance.py`.* Add `compression_type` to `benchmark_test.py` methods and add `snappy` to `matrix` annotation* Use randomly generated bytes from a restricted range for `ProducerPerformance` payload. This is a simple fix for now. It can be improved in the PR for KAFKA-3554.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1225 from ijuma/kafka-3558-add-compression_type-benchmark_test.py,3
"KAFKA-12339: Add retry to admin client's listOffsets (#10152)`KafkaAdmin.listOffsets` did not handle topic-level errors, hence the UnknownTopicOrPartitionException on topic-level can obstruct a Connect worker from running when the new internal topic is NOT synced to all brokers. The method did handle partition-level retriable errors by retrying, so this changes to handle topic-level retriable errors in the same way.This allows a Connect worker to start up and have the admin client retry when the worker is trying to read to the end of the newly-created internal topics until the internal topic metadata is synced to all brokers.Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"MINOR: Fix Trogdor tests, partition assignments (#4892)",3
"KAFKA-3607: Close KStreamTestDriver upon completing; follow-up fixes to be tracked in KAFKA-3623Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Michael G. Noll, Ismael JumaCloses #1258 from guozhangwang/K3607",0
MINOR: Convert LogLoader into a class (#11693)The logic for log loading is encapsulated in `LogLoader`. Currently all the methods are static and we pass the parameters through a separate object `LogLoaderParams`. This patch simplifies this structure by turning `LogLoader` into a normal object and get rid of `LogLoaderParams`. Reviewers: David Jacot <djacot@confluent.io>,5
HOTFIX: fix consumer config for streamsguozhangwangMy bad. I removed ZOOKEEPER_CONNECT_CONFIG from consumer's config by mistake. It is needed by our own partition assigner running in consumers.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #959 from ymatsuda/hotfix3,0
"KAFKA-1719 Make mirror maker exit when one consumer/producer thread exits; reviewed by Neha Narkhede, Joel Koshy and Guozhang Wang",1
MINOR: fix typoAuthor: kenji yoshida <6b656e6a69@gmail.com>Reviewers: Ismael JumaCloses #996 from xuwei-k/patch-1,2
"MINOR: Support streaming decompression of fetched records for new formatAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2738 from hachikuji/streaming-compressed-iterator",5
"KAFKA-3217: Close producers in unit testsProducers that are not closed auto-create topics in subsequent tests when Kafka server port is reused. Added missing close().Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #882 from rajinisivaram/KAFKA-3217",5
"KAFKA-8360: Docs do not mention RequestQueueSize JMX metric (#9325)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Co-authored-by: akumar <akumar@cloudera.com>",2
"KAFKA-10199: Add tasks to state updater when they are created (#12427)This PR introduces an internal config to enable the state updater. If the state updater is enabled newly created tasks are added to the state updater. Additionally, this PR introduces a builder for mocks for tasks.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-3452 Follow-up: Refactoring StateStore hierarchiesThis is a follow up of https://github.com/apache/kafka/pull/2166 - refactoring the store hierarchies as requestedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2360 from dguy/state-store-refactor,4
KAFKA-4719: Consumption timeout should take into account producer request timeoutAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2479 from hachikuji/KAFKA-4719,5
MINOR: Update year in NOTICE (#8207)Reviewers: Ismael Juma <ismael@confluent.io>,5
KAFKA-7021: Update upgrade guide section for reusing source topic (#5195)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-2807: Fix Kafka Connect packaging and move VerifiableSource/Sink into runtime jar.Gradle does not handle subprojects with the same name (top-level tools vsconnect/tools) properly, making the dependency impossible to express correctlysince we need to move the ThroughputThrottler class into the top level toolsproject. Moving the current set of tools into the runtime jar works fine sincethey are only used for system tests at the moment.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #512 from ewencp/kafka-2807-redux",3
MINOR: Add unit for max latency in ProducerPerformance output (#6014)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-8199: Implement ValueGetter for Suppress (#6781)See also #6684KTable processors must be supplied with a KTableProcessorSupplier, which in turn requires implementing a ValueGetter, for use with joins and groupings.For suppression, a correct view only includes the previously emitted values (not the currently buffered ones), so this change also involves pushing the Change value type into the suppression buffer's interface, so that it can get the prior value upon first buffering (which is also the previously emitted value).Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Reset java.security.auth.login.config in ZK-tests to avoid config reload affecting subsequent tests (#11602)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"KAFKA-14013: Limit the length of the `reason` field sent on the wire (#12388)KIP-800 added the `reason` field to the JoinGroupRequest and the LeaveGroupRequest as I mean to provide more information to the group coordinator. In https://issues.apache.org/jira/browse/KAFKA-13998, we discovered that the size of the field is limited to 32767 chars by our serialisation mechanism. At the moment, the field either provided directly by the user or constructed internally is directly set regardless of its length.This patch sends only the first 255 chars of the used provided or internally generated reason on the wire. Given the purpose of this field, that seems acceptable and that should still provide enough information to operators to understand the cause of a rebalance.Reviewers: David Jacot <djacot@confluent.io>",5
Merge remote branch 'origin/0.8' into trunk,1
"MINOR: Revert EmbeddedZooKeeper renameEven though this class is internal, it's widelyused by other projects and it's better to avoidbreaking them until we have a publicly supportedtest library.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4138 from ijuma/revert-embedded-zookeeper-rename",4
"KAFKA-8599: Use automatic RPC generation in ExpireDelegationTokenAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>Closes #7098 from mimaison/KAFKA-8599",1
KAFKA-8892: Display the sorted configs in Kafka Configs Help Command.Author: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>Reviewers: Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7319 from kamalcph/KAFKA-8892,5
"KAFKA-9386; Apply delete ACL filters to resources from filter even if not in cache (#7911)With the old SimpleAclAuthorizer, we were handling delete filters that matched a single resource by looking up that resource directly, even if it wasn't in the cache. AclAuthorizerTest.testHighConcurrencyDeletionOfResourceAcls relies on this behaviour and fails intermittently when the cache is not up-to-date. This PR includes the resource from non-matching filters even if it is not in the cache to retain the old behaviour.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-7032 The TimeUnit is neglected by KakfaConsumer#close(long, Tim… (#5182)",3
"KAFKA-2639: Refactoring of ZkUtilsI've split the work of KAFKA-1695 because this refactoring touches a large number of files. Most of the changes are trivial, but I feel it will be easier to review this way.This pull request includes the one Parth-Brahmbhatt started to address KAFKA-1695.Author: flavio junqueira <fpj@apache.org>Author: Flavio Junqueira <fpj@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #303 from fpj/KAFKA-2639",1
trival fix to remove a 0 byte filegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383464 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-991; Reduce the queue size in hadoop producer; patched by Swapnil Ghike, reviewed by Jay Kreps and Joel Koshy.",5
"KAFKA-3058; remove the usage of deprecated config propertiesAuthor: Konrad <konkalita@gmail.com>Author: konradkalita <konkalita@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #732 from konradkalita/Kafka-3058",5
"HOTFIX: fixed section incompatible Steams API changesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2492 from mjsax/hotfixDocs",2
KAFKA-5689; Add MeteredWindowStore and refactor store hierarchyAdd MeteredWindowStore and ChangeLoggingWindowBytesStore.Refactor Store hierarchy such that Metered is always the outermost storeDo serialization in MeteredWindowStoreAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3692 from dguy/kafka-5689,4
"KAFKA-4749; Fix join-time-max and sync-time-max MeasurableStat typeGroupCoordinatorMetrics currently sets up join-time-max and sync-time-max incorrectly as a ""new Avg()"" MeasurableStat instead of ""new Max()""Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2520 from onurkaraman/KAFKA-4749",5
KAFKA-1121 DumpLogSegments tool should print absolute file name to report inconsistencies; reviewed by Neha Narkhede and Guozhang Wang,2
"KAFKA-6829: retry commits on unknown topic or partition (#4948)For the UNKNOWN_TOPIC_OR_PARTITION error, we could change the consumer's behavior to retry after this error. While this is a rare case since the user would not commit offsets for topics unless they had been able to fetch from them, but this doesn't really handle the situation where the broker hasn't received any metadata updates.Reviewers: Jason Gustafson <jason@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-6567: Remove KStreamWindowReducer (#5922)This pull request removes the final reference to KStreamWindowReducer and replaces it with KStreamWindowAggregateSigned-off-by: Samuel Hawker sam.b.hawker@gmail.comcontribution is my original work and that I license the work to the project under the project's open source license.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7800; Dynamic log levels admin API (KIP-412)<!--Is there any breaking changes?  If so this is a major release, make sure '#major' is in at least onecommit message to get CI to bump the major.  This will prevent automatic down stream dependencybumping / consuming.  For more information about semantic versioning see: https://semver.org/Suggested PR template: Fill/delete/add sections as needed. Optionally delete any commented block.-->What----<!--Briefly describe **what** you have changed and **why**.Optionally include implementation strategy.-->References----------[**KIP-412**](https://cwiki.apache.org/confluence/display/KAFKA/KIP-412%3A+Extend+Admin+API+to+support+dynamic+application+log+levels)[**KAFKA-7800**](https://issues.apache.org/jira/browse/KAFKA-7800)[**Discussion Thread**](http://mail-archives.apache.org/mod_mbox/kafka-dev/201901.mbox/%3CCANZZNGyeVw8q%3Dx9uOQS-18wL3FEmnOwpBnpJ9x3iMLdXY3gEug%40mail.gmail.com%3E)[**Vote Thread**](http://mail-archives.apache.org/mod_mbox/kafka-dev/201902.mbox/%3CCANZZNGzpTJg5YX1Gpe5S%3DHSr%3DXGvmxvYLTdA3jWq_qwH-UvorQ%40mail.gmail.com%3E)<!--Copy&paste links: to Jira ticket, other PRs, issues, Slack conversations...For code bumps: link to PR, tag or GitHub `/compare/master...master`-->Test&Review------------Test cases covered:* DescribeConfigs* Alter the log level with and without validateOnly, validate the results with DescribeConfigsOpen questions / Follow ups--------------------------If you're a reviewer, I'd appreciate your thoughts on these questions I have open:1. Should we add synchronization to the Log4jController methods? - Seems like we don't get much value from it2. Should we instantiate a new Log4jController instead of it having static methods? - All operations are stateless, so I thought static methods would do well3. A logger which does not have a set value returns ""null"" (as seen in the unit tests). Should we just return the Root logger's level?Author: Stanislav Kozlovski <familyguyuser192@windowslive.com>Reviewers: Gwen ShapiraCloses #6903 from stanislavkozlovski/KAFKA-7800-dynamic-log-levels-admin-ap",2
KAFKA-4964; Use correct keystore/trustore name in documentationAuthor: shuguo zheng <zheng.shuguo@zte.com.cn>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2749 from zhengsg/local,2
"MINOR; Fix LICENSE-binary based on the 3.3 dependencies (#12579)The following commands don't show any missings licenses$ ./gradlewAll clean releaseTarGz$ tar xzf core/build/distributions/kafka_2.13-3.3.0-SNAPSHOT.tgz$ cd kafka_2.13-3.3.0-SNAPSHOT/$ for f in $(ls libs | grep -v ""^kafka\|connect\|trogdor""); do if ! grep -q ${f%.*} LICENSE; then echo ""${f%.*} is missing in license file""; fi; done",2
"KAFKA-4390; Replace MessageSet usage with client-side alternativesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #2140 from hachikuji/KAFKA4390",5
KAFKA-2484: Add schema projection utilitiesThis PR adds schema projection utilities to copycat.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-PostavaCloses #307 from Ishiihara/schema-projection,1
"KAFKA-12586; Add `DescribeTransactions` Admin API (#10483)This patch contains the `Admin` implementation of the `DescribeTransactions` APIs described in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Introduce `installAll` and accept major as well as full Scala versionWe can take advantage of the fact that major Scala versions are binary compatible (since 2.10) to make the build a little more user-friendly.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack=Postava, Grant HenkeCloses #574 from ijuma/install-all-and-major-instead-of-full-version",1
KAFKA-2335; fix comment about thread safetyAuthor: Jason Gustafson <jason@confluent.io>Closes #78 from hachikuji/KAFKA-2335 and squashes the following commits:c697998 [Jason Gustafson] KAFKA-2335; fix comment about consumer thread safety,0
KAFKA-2665: Add images to code github…art of the code githubAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Guozhang WangCloses #325 from gwenshap/KAFKA-2665,1
"MINOR: auto.offset.reset docs not in sync with validationIn this commit https://github.com/apache/kafka/commit/0699ff2ce60abb466cab5315977a224f1a70a4da#diff-5533ddc72176acd1c32f5abbe94aa672 among other things auto.offset.reset possible options were changed from smallest to earliest and from largest to latest, but not in documentation for that configuration property.This patch fixes documentation for auto.offset.reset consumer configuration property so it is in sync with validation logic.Author: Stevo Slavić <sslavic@gmail.com>Reviewers: Jason, Ismael, GuozhangCloses #91 from sslavic/patch-5 and squashes the following commits:f4c9656 [Stevo Slavić] MINOR: auto.offset.reset docs not in sync with validation",5
"KAFKA-12762: Use connection timeout when polling the network for new connections (#10649)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Tom Bentley <tbentley@redhat.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Tom Bentley <tombentley@users.noreply.github.com>",1
KAFKA-8748: Fix flaky testDescribeLogDirsRequest (#7182)The introduction of KIP-480: Sticky Producer Partitioner had theside effect that generateAndProduceMessages can often writemessages to a lower number of partitions to improve batching.testDescribeLogDirsRequest (and potentially other tests) relieson the messages being written somewhat uniformly to the topicpartitions. We fix the issue by including a monotonicallyincreasing key in the produced messages.I also included a couple of minor clean-ups I noticed whiledebugging the issue.The test failed very frequently when executed locally before thechange and it passed 100 times consecutively after the change.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
"KAFKA-3514: Remove min timestamp tracker (#5382)1. Remove MinTimestampTracker and its TimestampTracker interface.2. In RecordQueue, keep track of the head record (deserialized) while put the rest raw bytes records in the fifo queue, the head record as well as the partition timestamp will be updated accordingly.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Code cleanup in StreamsResetter (#5891)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-12272: Fix commit-interval metrics (#10102)Reviewer: A. Sophie Blee-Goldman <sophie@confluent.io>,5
"KAFKA-9654; Update epoch in `ReplicaAlterLogDirsThread` after new LeaderAndIsr  (#8223)Currently when there is a leader change with a log dir reassignment in progress, we do not update the leader epoch in the partition state maintained by `ReplicaAlterLogDirsThread`. This can lead to a FENCED_LEADER_EPOCH error, which results in the partition being marked as failed, which is a permanent failure until the broker is restarted. This patch fixes the problem by updating the epoch in `ReplicaAlterLogDirsThread` after receiving a new LeaderAndIsr request from the controller.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Minor logging fix,0
MINOR: Fix Javadoc Issues (#4190)This PR mainly fixes some broken links and invalid references in the clients Javadoc,2
"KAFKA-10435; Fetch protocol changes for KIP-595 (#9275)This patch bumps the `Fetch` protocol as specified by KIP-595: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum. The main differences are the following:- Truncation detection - Leader discovery through the response- Flexible version supportThe most notable change is truncation detection. This patch adds logic in the request handling path to detect truncation, but it does not change the replica fetchers to make use of this capability. This will be done separately.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6150: KIP-204 part III; Purge repartition topics with the admin client1. Add the repartition topics information into ProcessorTopology: personally I do not like leaking this information into the topology but it seems not other simple way around.2. StreamTask: added one more function to expose the consumed offsets from repartition topics only.3. TaskManager: use the AdminClient to send the gathered offsets to delete only if a) previous call has completed and client intentionally ignore-and-log any errors, or b) no requests have ever called before.NOTE that this code depends on the assumption that purge is only called right after the commit has succeeded, hence we presume all consumed offsets are committed.4. MINOR: Added a few more constructor for ProcessorTopology for cleaner unit tests.5. MINOR: Extracted MockStateStore out of the deprecated class.6. MINOR: Made a pass over some unit test classes for clean ups.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4270 from guozhangwang/K6150-purge-repartition-topics",5
KAFKA-3606: Traverse CLASSPATH during herder startewencp Can you take a quick look?Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1252 from Ishiihara/pre-list-connectors,5
"MINOR: further InternalTopologyBuilder cleanup  (#8046)Followup to KAFKA-7317 and KAFKA-9113, there's some additional cleanup we can do in InternalTopologyBuilder. Mostly refactors the subscription code to make the initialization more explicit and reduce some duplicated code in the update logic.Also some minor cleanup of the build method.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
"KAFKA-4274; Consumer `offsetForTimes` times out on empty mapAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1993 from becketqin/KAFKA-4274",5
"KAFKA-10000: Add producer fencing API to admin client (KIP-618) (#11777)* KAFKA-10000: Add producer fencing API to admin clientReviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>",1
HOTFIX: Handle Connector version returning 'null' during plugin loading.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3321 from kkonstantine/HOTFIX-Handle-null-version-returned-from-Connector-interface-during-plugin-loading,0
"KAFKA-8746: Kibosh must handle an empty JSON string from Trogdor (#7155)When Trogdor wants to clear all the faults injected to Kibosh, it sends the empty JSON object {}. However, Kibosh expects {""faults"":[]} instead.  Kibosh should handle the empty JSON object, since that's consistent with how Trogdor handles empty JSON fields in general (if they're empty, they can be omitted). We should also have a test for this.Reviewers: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",3
KAFKA-8944: Fixed KTable compiler warning. (#7393)https://issues.apache.org/jira/browse/KAFKA-8944Reviewers: Bill Bejeck <bbejeck@gmail.com>,0
"KAFKA-3319: improve session timeout broker/client config documentationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke, Ismael Juma, Guozhang WangCloses #1106 from hachikuji/KAFKA-3319",5
"MINOR: Enable testLogCleanerStats (#9608)The `testLogCleanerStats` test in `LogCleanerTest.scala` was not implemented but not enabled. This PR adds the `@Test` annotation, and also gives it a larger map to allow the test to pass as intended. Also fixes a few misleading comments.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: expose vagrant base box as variableAdded base_box variable to Vagrantfile. This makes it possible to override the base box in Vagrantfile.local.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Guozhang WangCloses #137 from granders/minor-expose-vagrant-box and squashes the following commits:44936f7 [Geoff Anderson] Added base_box variable to Vagrantfile. This makes it possible to override the base box in Vagrantfile.local.,2
"KAFKA-10618: Rename UUID to Uuid and make it more efficient (#9566)As decided in KIP-516, the UUID class should be named Uuid. Change all instances oforg.apache.kafka.common.UUID to org.apache.kafka.common.Uuid.Also modify Uuid so that it stores two `long` fields instead of wrapping java.util.UUIDto reduce memory usage.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
KAFKA-4272; Add missing 'connect' Windows batch scriptsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2146 from vahidhashemian/KAFKA-4272,5
"KAFKA-3129; Console producer issue when request-required-acks=0change console producer default acks to 1, update acks docs.  Also added the -1 config to the acks docs since that question comes up often.  ijuma and vahidhashemian, does this look reasonable to you?Author: Dustin Cote <dustin@confluent.io>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>Closes #1795 from cotedm/KAFKA-3129",5
Fix Javadoc of KafkaConsumer (#6155)The Javadoc is using Properties.put which should never be used because it allows putting non-strings into a Properties object which is designed to only handle strings.Two other minor fixes so the examples actually work,1
KAFKA-6771. Make specifying partitions more flexible (#4850),1
KAFKA-1914; follow-up to fix SimpleFetchTest; reviewed by Joel Koshy,3
"MINOR: Controller should process events without rate metrics (#7732)Fixes #7717, which did not actually achieve its intended effect. The event manager failed to process the new event because we disabled the rate metric, which it expected to be present.Reviewers: Ismael Juma <ismael@juma.me.uk",1
"KAFKA-5758; Don't fail fetch request if replica is no longer a follower for a partitionWe log a warning instead, which is what we also do if the partitionhasn't been created yet.A few other improvements:- Return updated high watermark if fetch is returned immediately.This seems to be more intuitive and is consistent with the casewhere the fetch request is served from the purgatory.- Centralise offline partition handling- Remove unnecessary `tryCompleteDelayedProduce` that wouldalready have been done by the called method- A few other minor clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3954 from ijuma/kafka-5758-dont-fail-fetch-request-if-replica-is-not-follower",0
"KAFKA-13666 Don't Only ignore test exceptions for windows OS for certain tests. (#11752)Tests are swallowing exceptions for supported operating systems, which could hide regressions.Co-authored-by: Rob Leland <rleland@apache.org>Reviewer: Bruno Cadonna <cadonna@apache.org>",1
"dont spam (#7730)This ends up spamming the logs and doesn't seem to be providing much useful information, rather than logging the full task (which includes the entire topology description) we should just log the task id.Reviewers: Matthias J. Sax <mjsax@apache.org>, Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-1070 Auto assign broker id; reviewed by Neha Narkhede,5
"KAFKA-12921: Upgrade zstd-jni to 1.5.0-2 (#10847)This PR aims to upgrade `zstd-jni` from `1.4.9-1` to `1.5.0-2`.This change will incorporate a number of bug fixes and performance improvements made in `1.5.0` of `zstd`:- https://github.com/facebook/zstd/releases/tag/v1.5.0- https://github.com/luben/zstd-jni/releases/tag/v1.5.0-1- https://github.com/luben/zstd-jni/releases/tag/v1.5.0-2The most recent `1.5.0` release offers +25%-140% (compression) and +15% (decompression) performanceimprovements under certain conditions. Those conditions are unlikely to apply to Kafka with the defaultconfiguration, however.Since this is a dependency change, this should pass all the existing CIs.Reviewers: Lee Dongjin <dongjin@apache.org>, Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-7180; Fixing the flaky test testHWCheckpointWithFailuresSingleLogSegmentBy waiting until server1 has joined the ISR before shutting down server2Rerun the test method many times after the code change, and there is no flakiness any more.Author: Lucas Wang <luwang@linkedin.com>Reviewers: Mayuresh Gharat <gharatmayuresh15@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5387 from gitlw/fixing_flacky_logrecevorytest",3
KAFKA-1184 High-Level Consumer: expose fetcher threads number as a parameter; reviewed by Neha Narkhede,2
"KAFKA-10469: Resolve logger levels hierarchically (#9266)Previous to root logger level was used, ignoring intervening loggers withdifferent levels.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Lee Dongjin <dongjin@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-8570; Grow buffer to hold down converted records if it was insufficiently sized (#6974)When the log contains out of order message formats (for example v2 message followed by v1 message) and consists of compressed batches typically greater than 1kB in size, it is possible for down-conversion to fail. With compressed batches, we estimate the size of down-converted batches using:```    private static int estimateCompressedSizeInBytes(int size, CompressionType compressionType) {        return compressionType == CompressionType.NONE ? size : Math.min(Math.max(size / 2, 1024), 1 << 16);    }```This almost always underestimates size of down-converted records if the batch is between 1kB-64kB in size. In general, this means we may under estimate the total size required for compressed batches.Because of an implicit assumption in the code that messages with a lower message format appear before any with a higher message format, we do not grow the buffer we copy the down converted records into when we see a message <= the target message format. This assumption becomes incorrect when the log contains out of order message formats, for example because of leaders flapping while upgrading the message format.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-141 Check and make sure that the files that have been donated have been updated to reflect the new ASF copyright;patched by nehanarkhede; reviewd by jjkoshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180185 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1107 Follow up review cleanup comments,4
"kafka-1307; potential socket leak in new producer and clean up; reviewed by Jay Kreps, Guozhang Wang and Neha Narkhede",4
"KAFKA-7007:  Use JSON for /kafka-acl-extended-changes path (#5161)Keep Literal ACLs on the old paths, using the old formats, to maintain backwards compatibility.Have Prefixed, and any latter types, go on new paths, using JSON, (old brokers are not aware of them)Add checks to reject any adminClient requests to add prefixed acls before the cluster is fully upgraded.Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",0
"MINOR: Replace statement lambda with expression lambda (#11723)Reviewers: Kvicii <Karonazaba@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: Fix static membership link in Streams upgrade notes (#7439)Fix broken linkReviewers: John Roesler <vvcephei@apache.org>,2
KAFKA-2785; Include Kafka Connect jars in releaseTarGz.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #473 from ewencp/kafka-2785-include-copycat-jars-in-release,1
"MINOR: Assume unclean shutdown for metadata log (#10363)Currently the metadata log assumes successful shutdown and skips recovery. For now, we prefer to err on the safe side and assume instead that the replica was shutdown uncleanly so that we can force full recovery. This is justified in the short term because:1. Snapshots are not fully implemented for the metadata log2. The replicas (controllers and brokers) need to read the entire metadata log to load it into memory.In other words, we need to read through the metadata log once on startup anyway. A long-term fix will be provided in https://issues.apache.org/jira/browse/KAFKA-12504.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix group coordinator is unavailable log (#12335)Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Luke Chen <showuon@gmail.com>",1
"Only schedule AlterIsr thread when we have an ISR change (#9749)This patch removes the periodic scheduling of a thread to send AlterISR requests and instead sends a request as soon as an ISR update is ready to send. When a response is received, the callback checks for any unsent items and will schedule another request if necessary.",5
KAFKA-352 Unknown topic error code handling for all requests; patched by Neha Narkhede; reviewed by Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1363507 13f79535-47bb-0310-9956-ffa450edef68,0
kafka-1598; Fix variable typo in Kafka main class; patched by Jarek Jarcec Cecho; reviewed by Jun Rao,2
"MINOR: buffer should ignore caching (#5819)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6535: Set default retention ms for Streams repartition topics to Long.MAX_VALUE (#4730)Implements KIP-284Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Improve log4j on stream thread and stream processAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2685 from guozhangwang/KMinor-improve-log4j",2
"KAFKA-9466: Update Kafka Streams docs for KIP-447 (#8621)Reviewers: Boyang Chen <boyang@confluent.io>, Jim Galasyn <jim.galasyn@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Bump up version to 1.1.0-SNAPSHOT,5
"MINOR: Small javadoc/code cleanups in connect api and transforms (#12558)Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>",4
"KAFKA-8529; Flakey test ConsumerBounceTest#testCloseDuringRebalance (#11097)When the replica fetcher receives a top-level error in the fetch response, it marks all partitions are failed and adds a backoff delay before resuming fetching from them. In addition to this, there is an additional backoff enforced after the top-level error is handled, so we end up waiting twice the configured backoff time before resuming. This patch removes this extra backoff.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-12758 Added `server-common` module to have server side common classes.  (#10638)Added server-common module to have server side common classes. Moved ApiMessageAndVersion, RecordSerde, AbstractApiMessageSerde, and BytesApiMessageSerde to server-common module.Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
kafka-850; add an option to show under replicated partitions in list topic command; patched by Jun Rao; reviewed by Neha Narkhede,1
KAFKA-7402: Implement KIP-376 AutoCloseable additions,1
"KAFKA-13216: Use a KV with list serde for the shared store (#11252)This is an alternative approach in parallel to #11235. After several unsuccessful trials to improve its efficiency i've come up with a larger approach, which is to use a kv-store instead as the shared store, which would store the value as list. The benefits of this approach are:Only serde once that compose <timestamp, byte, key>, at the outer metered stores, with less byte array copies.Deletes are straight-forward with no scan reads, just a single call to delete all duplicated <timestamp, byte, key> values.Using a KV store has less space amplification than a segmented window store.The cons though:Each put call would be a get-then-write to append to the list; also we would spend a few more bytes to store the list (most likely a singleton list, and hence just 4 more bytes).It's more complicated definitely.. :)The main idea is that since the shared store is actively GC'ed by the expiration logic, not based on time retention, and since that the key format is in <timestamp, byte, key>, the range expiration query is quite efficient as well.Added testing covering for the list stores (since we are still use kv-store interface, we cannot leverage on the get() calls in the stream-stream join, instead we use putIfAbsent and range only). Another minor factoring piggy-backed is to let toList to always close iterator to avoid leaking.Reviewers: Sergio Peña <sergio@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-12904: Corrected the timeout for config validation REST API resource (#10834)The constant is specified in milliseconds, and so the MILLISECOND time unit should be used instead of SECONDS.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
KAFKA-12189 ShellTest can replace 'assumeTrue' by (junit 5) conditional test (#9898)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"KAFKA-6274: Use topic plus dash as prefix of auto-generated state store namesUse `topic-` as the prefix of the auto-generated state store name.Also add a unit test for this functionality.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>Closes #4268 from guozhangwang/K6274-table-source-store-name",5
"KAFKA-5461; Add metric to track global topic count and global parition count in a clusterAuthor: Abhishek Mendhekar <amendhekar@linkedin.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3549 from abhishekmendhekar/KAFKA-5461",2
kafka-1369; snappy version update 1.1.x; patched by Roger Hoover; reviewed by Jun Rao,5
"KAFKA-8983; AdminClient deleteRecords should not fail all partitions unnecessarily (#7449)The deleteRecords API in the AdminClient groups records to be sent by the partition leaders. If one of these requests fails, we currently fail all futures, including those tied to requests sent to other leaders. It would be better to fail only those partitions included in the failed request.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-7705; Fix and simplify producer config in javadoc example (#6000)The example in the producer's javadoc contained an inconsistent value for `delivery.timeout.ms`. This patch removes the inconsistent config and several unnecessary overrides in order to simplify the example.Reviewers: huxi <huxi_2b@hotmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6958: Add new NamedOperation interface to enforce consistency in naming operations (#6409)Sub-task required to allow to define custom processor names with KStreams DSL(KIP-307) :  - add new public interface NamedOperation  - deprecate methods Joined.as() and Joined.name()  - update Suppredded interface to extend NamedOperationReviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: streams dev guide fixupAuthor: Joel Hamill <joel@Joel-Hamill-Confluent.local>Author: Joel Hamill <11722533+joel-hamill@users.noreply.github.com>Reviewers: Derrick Or <derrickor@gmail.com>, Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3862 from joel-hamill/joel-hamill/streams-dev-guide",5
KAFKA-13072: Make RemoveMembersFromConsumerGroupHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11035)This patch improve the error handling in `RemoveMembersFromConsumerGroupHandler` and ensures that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Some cleanups in the transactional producerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2933 from hachikuji/minor-transactional-client-cleanup",4
"KAFKA-13008: Try to refresh end offset when partitionLag returns empty (#11057)1. When listOffset result is retrieved inside Fetcher, check if the partitions are part of the subscriptions of the consumer; if yes update the corresponding LSO or HW based on the isolation level.2. When partitionLag cannot return result since the log end offset (LSO/HW) is not known, send an async list offset which would be completed by other calls polling (also the hb thread may complete it as well), and hope the next partitionLag would get the result.3. Keep track of list-offset request sent at the subscription state level so that frequent currentLag calls would not cause excessive list-offset requests.Then on the streams side, the first partitionLag would still return empty, but soon enough the subsequent partitionLag should return data and we would not wait for the fetch response to update fetched state.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, John Roesler <vvcephei@apache.org>",5
"KAFKA-4881: add internal leave.group.on.close config to consumerAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #2650 from dguy/consumer-leave-group-config",5
MINOR: Small logging fixes in AbstractCoordinator (#7230)Reviewers: Jason Gustafson <jason@confluent.io>,5
additional trivial 0.9.0 doc changes,4
MINOR: Use MessageDigest equals when comparing signature (#10898),1
"KAFKA-6049: extend Kafka Streams Scala API for cogroup (KIP-150) (#7847)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Add 2.0, 2.1 and 2.2 to broker and client compat testsThese are important to ensure we don't break compatibility.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #6794 from ijuma/update-version-compat-tests",5
"KAFKA-4818; Exactly once transactional clientsAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2840 from apurvam/exactly-once-transactional-clients",5
MINOR: Fix JAAS configuration numbering (#7601)7.3.1.1 JAAS configuration for Kafka brokers was followed by7.3.1.4 JAAS configuration for Kafka clients instead of 7.3.1.2.Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"MINOR: Gracefully handle non-assigned case in fetcher metric (#7383)Minor tweak to gracefully handle a possible IllegalStateException while checking a metric value.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: rename InternalProcessorContext.initialized (#5672)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Make TestUtils usable for KRaft mode (#11410)Make TestUtils usable for KRaft mode by using KafkaBroker instead of KafkaServer where appropriate,and adding some alternate functions that use AdminClient instead of ZooKeeper.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: To verify segment.hasOverflow, the path of the segment should be printed (#10925)When refer to the return ""Check whether the last offset of the last batch in this segment overflows the indexes"", if the result is not expected, the path of the segment should be printed so that users can find problems.Reviewers: Luke Chen, Guozhang Wang <wangguoz@gmail.com>",0
KAFKA-1308 Publish jar of test utilities to Maven,3
KAFKA-1173 Using Vagrant to get up and running with Apache Kafka patch by Ewen Cheslack-Postava reviewed by Joe Stein,1
"KAFKA-3452; Follow-up: Add SessionWindows - TimeWindows represent half-open time intervals while SessionWindows represent closed time intervalsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2342 from mjsax/kafka-3452-session-window-follow-up",5
MINOR; Move quota integration tests to using the new quota API. (#8954)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: Remove # from .bat start scriptOn Windows, the following output is seen when starting Zookeeper and Kafka servers:```'#' is not recognized as an internal or external command,operable program or batch file.```This pull request makes a minor correction to the Windows `kafka-run-class.bat` script to replace the use of `#` with `rem`.Author: P. Thorpe <paul.thorpe@uk.ibm.com>Reviewers: Vahid Hashemian, Gwen ShapiraCloses #1740 from p-thorpe/trunk",1
"KAFKA-9309: Add the ability to translate Message classes to and from JSON (#7844)Reviewers: David Arthur <mumrah@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",5
"KAFKA-10316: Consider renaming getter method for Interactive Queries (#9120) - implements KIP-648 - Deprecated the existing getters and added new getters without `get` prefix to `KeyQueryMetadata`Co-authored-by: johnthotekat <Iabon1989*>Reviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-2311; Make KafkaConsumer's ensureNotClosed method thread-safeHere is the patch on github ijuma.Acquiring the consumer lock (the single thread access controls) requires that the consumer be open. I changed the closed variable to be volatile so that another thread's writes will visible to the reading thread.Additionally, there was an additional check if the consumer was closed after the lock was acquired. This check is no longer necessary.This is my original work and I license it to the project under the project's open source license.Author: Tim Brooks <tim@uncontended.net>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1637 from tbrooks8/KAFKA-2311",5
KAFKA-14160: Streamline clusterId retrieval in Connect (#12536)Cache the Kafka cluster Id once it has been retrieved to avoid creating many Admin clients at startup.Reviewers: Chris Egerton <fearthecellos@gmail.com>,1
"MINOR: Bump trunk to 3.2.0-SNAPSHOT (#11458)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Fixed StickyAssignor javadoc formattingStickyAssignor javadoc has a bunch of formatting issues which make it pretty hard to read:http://kafka.apache.org/0110/javadoc/org/apache/kafka/clients/consumer/StickyAssignor.htmlcc vahidhashemianAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>Closes #3670 from mimaison/sticky_assignor_javadoc",2
"KAFKA-10729; Bump remaining RPC's to use tagged fields. (#9601)As a follow-up from [KIP-482](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields), this PR bumps the version for severalRPC's to enable tagged fields via the flexible versioning mechanism.Additionally, a new IBP version `KAFKA_2_8_IV0` is introduced toallow replication to take advantage of these new RPC versions forOffsetForLeaderEpoch and ListOffset.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Handle segment splitting edge cases and fix recovery bug  (#5169)This patch fixes the following issues in the log splitting logic added to address KAFKA-6264:1. We were not handling the case when all messages in the segment overflowed the index. In this case, there is only one resulting segment following the split.2. There was an off-by-one error in the recovery logic when completing a swap operation which caused an unintended segment deletion.Additionally, this patch factors out of `splitOverflowedSegment` a method to write to a segment using from with an instance of `FileRecords`. This allows for future reuse and isolated testing.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
"KAFKA-2645: Document potentially breaking changes in the release note……s for 0.9.0Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Guozhang WangCloses #337 from granthenke/docs",2
"KAFKA-7277: Migrate Streams API to Duration instead of longMs times (#5682)Reviewers: Johne Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-5040; Increase number of retries from the default of 0Author: Eno Thereska <eno@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2819 from enothereska/minor-increase-retries",1
"KAFKA-8662; Fix producer metadata error handling and consumer manual assignment (#7086)Ensure that Producer#send() throws topic metadata exceptions only for the topic being sent to and not for other topics in the producer's metadata instance. Also removes topics from consumer's metadata when a topic is removed using manual assignment.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: add DEFAULT_PORT for Trogdor Agent and Coordinator (#4674)Add a DEFAULT_PORT constant for the Trogdor Agent and Coordinator.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: gradle wrapper should handle directories with spacesIf attempting to build the project from a directory with spaces in its name and gradle-wrapper.jar is missing, the script will fail to download a new one because the ""if"" condition will break because $APP_HOME will resolve to multiple strings. Protecting $APP_HOME with quotes fixes the issue. Tested by deleting gradle.wrapper and trying to build.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Chia-Ping TsaiCloses #9813 from gwenshap/fix_gradlew",0
"KAFKA-1901; Move Kafka version to be generated in code by build (instead of in manifest); reviewed by Ismael Juma, Joel Koshy, Jason Rosenberg",4
"KAFKA-8636; Add documentation change for max poll interval with static members (#7048)Clarify the behavior of `max.poll.interval.ms` for static consumers since it is slightly different from dynamic members.Reviewers: Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Jason Gustafson <jason@confluent.io>",5
KAFKA-5405; Request log should log throttle timeRecord `apiThrottleTime` in RequestChannel.junrao  A trivial change. Please review. Thanks.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3265 from huxihx/KAFKA-5405,4
KAFKA-10842; Use `InterBrokerSendThread` for raft's outbound network channel (#9732)This patch contains the following improvements:- Separate inbound/outbound request flows so that we can open the door for concurrent inbound request handling- Rewrite `KafkaNetworkChannel` to use `InterBrokerSendThread` which fixes a number of bugs/shortcomings- Get rid of a lot of boilerplate conversions in `KafkaNetworkChannel` - Improve validation of inbound responses in `KafkaRaftClient` by checking correlationId. This fixes a bug which could cause an out of order Fetch to be applied incorrectly.Reviewers: David Arthur <mumrah@gmail.com>,1
"KAFKA-2746; Add support for using ConsumerGroupCommand on secure installAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>Closes #534 from SinghAsDev/KAFKA-2746",5
"KAFKA-6320: Move ZK metrics in KafkaHealthCheck to ZookeeperClient (#4351)* Moved metrics in KafkaHealthCheck to ZookeeperClient.* Converted remaining ZkUtils usage in KafkaServer to ZookeeperClient and removed ZkUtils from KafkaServer.* Made the re-creation of ZooKeeper during ZK session expiration with infinite retries.* Added unit tests for all new methods in KafkaZkClient.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Improve log warning to include the log nameAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3562 from ijuma/tweak-log-warning,2
KAFKA-5389; Replace zkClient.exists method with zkUtils.pathExistsijuma can you please reviewAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3243 from baluchicken/KAFKA-5389,5
"MINOR: bump version in kraft readme (#11596)Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Jacot <djacot@confluent.io>",5
KAFKA-1648; Robin consumer balance throws an NPE when there are no topics,5
"MINOR: Streams API JavaDoc improvementsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2437 from mjsax/javaDocImprovements7",2
"KAFKA-6366: Fix stack overflow in consumer due to many offset commits during coordinator disconnect (#4349)When the coordinator is marked unknown, we explicitly disconnect its connection and cancel pending requests. Currently the disconnect happens before the coordinator state is set to null, which means that callbacks which inspect the coordinator state will see it still as active. If there are offset commit requests which need to be cancelled, each request callback will inspect the coordinator state and attempt to mark the coordinator dead again. In the worst case, if there are many pending offset commit requests that need to be cancelled, this can cause a stack overflow. To fix the problem, we need to set the coordinator to null prior to cancelling pending requests.I have added a test case which reproduced the stack overflow with many pending offset commits. I have also added a basic test case to verify that callbacks for in-flight or unsent requests see the coordinator as unknown which prevents them from attempting to resend.This patch also includes some minor cleanups which were noticed along the way.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: update Streams upgrade notes with removed APIs (#10420)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"KAFKA-9091: Add a metric tracking the number of open connections with a given SSL cipher type (#7588)Reviewers: Tom Bentley <tbentley@redhat.com>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-4501; Java 9 compilation and runtime fixesCompilation error fixes:- Avoid ambiguity error when appending to Properties in Scalacode (https://github.com/scala/bug/issues/10418)- Use position() and limit() to fix ambiguity issue (https://github.com/scala/bug/issues/10418#issuecomment-316364778)- Disable findBugs if Java 9 is used (https://github.com/findbugsproject/findbugs/issues/105)Compilation warning fixes:- Avoid deprecated Class.newInstance in Utils.newInstance- Silence a few Java 9 deprecation warnings- var -> val and unused fixesRuntime error fixes:- Introduce Base64 class that works in Java 7 and Java 9Also:- Set --release option if building with Java 9Note that tests involving EasyMock (https://github.com/easymock/easymock/issues/193)or PowerMock (https://github.com/powermock/powermock/issues/783)will fail as neither supports Java 9 currently.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3647 from ijuma/kafka-4501-support-java-9,1
MINOR: Removed unused imports in a few tests (#4938)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-8591; WorkerConfigTransformer NPE on connector configuration reloading (#6991)A bug in `WorkerConfigTransformer` prevents the connector configuration reload when the ConfigData TTL expires. The issue boils down to the fact that `worker.herder().restartConnector` is receiving a null callback. ```[2019-06-17 14:34:12,320] INFO Scheduling a restart of connector workshop-incremental in 60000 ms (org.apache.kafka.connect.runtime.WorkerConfigTransformer:88)[2019-06-17 14:34:12,321] ERROR Uncaught exception in herder work thread, exiting:  (org.apache.kafka.connect.runtime.distributed.DistributedHerder:227)java.lang.NullPointerException        at org.apache.kafka.connect.runtime.distributed.DistributedHerder$19.onCompletion(DistributedHerder.java:1187)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder$19.onCompletion(DistributedHerder.java:1183)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:273)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:219)```This patch adds a callback which just logs the error.Reviewers: Robert Yokota <rayokota@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9274: Remove `retries` from InternalTopicManager (#9060) - part of KIP-572 - replace `retries` in InternalTopicManager with infinite retires plus a new timeout, based on consumer config MAX_POLL_INTERVAL_MSReviewers: David Jacot <djacot@confluent.io>, Boyang Chen <boyang@confluent.io>",5
KAFKA-240 ProducerRequest wire format protocol update and related changesgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1296577 13f79535-47bb-0310-9956-ffa450edef68,4
"Minor: fix sasl.kerberos.service.namesasl.kerberos.service.name surround by double quote didn't work, have to remove.Author: BINLEI XUE <kongpo0412@gmail.com>Reviewers: Gwen ShapiraCloses #720 from secjex/patch-1",4
MINOR: Use new consumer in ProducerCompressionTestThis should be less flaky as it has a higher timeout. I also increased the timeoutin a couple of other tests that had a very low (100 ms) timeouts.The failure would manifest itself as:```textjava.net.SocketTimeoutExceptionat sun.nio.ch.SocketAdaptor$SocketInputStream.read(SocketAdaptor.java:229)at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103)at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:85)at kafka.network.BlockingChannel.readCompletely(BlockingChannel.scala:129)at kafka.network.BlockingChannel.receive(BlockingChannel.scala:120)at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:100)at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:84)at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SimpleConsumer.scala:133)at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:133)at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:133)at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply$mcV$sp(SimpleConsumer.scala:132)at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:132)at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:132)at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:131)at kafka.api.test.ProducerCompressionTest.testCompression(ProducerCompressionTest.scala:97)```Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3178 from ijuma/producer-compression-test-flaky,3
MINOR: Remove kraft authorizer from list of missing features (#12146)Also tweak the list of missing features a bitReviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,1
kafka-2264; SESSION_TIMEOUT_MS_CONFIG in ConsumerConfig should be int; patched by Manikumar Reddy; reviewed by Jun Rao,5
"KAFKA-10199: Handle exceptions from state updater (#12519)1. In state updater, when handling task corrupted exception due to invalid restoring offset, first delete the affected partitions from the checkpoint before reporting it back to the stream thread. This is to mimic the same behavior in stream threads's StateManager#handleCorruption#closeDirtyAndRevive. It's cleaner to do so inside the restore thread, plus it enables us to optimize by only deleting those corrupted partitions, and not all.2. In the state manager, handle the drained exceptions as follows (this is the same as handling all exceptions from handleAssignment): 1) Task-migrated, throw all the way to stream-thread as handleTaskMigrated, 2) any fatal Streams exception, throw all the way to stream-thread to trigger exception handler, 3) Task-corrupted, throw to the stream-thread as handleCorruption. Note that for 3), we would specially distinguish if the corrupted-tasks are already closed (when they are thrown from handleAssignment or not (when they are thrown from the state updater).Reviewers: Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Improve Trogdor external command worker docs (#6438)Reviewers: Colin McCabe <cmccabe@apache.org>, Xi Yang <xi@confluent.io>",5
"KAFKA-7388 equal sign in property value for password (#5630)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Murali Mani <murali.mani@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-3229 ensure that root statestore is registered with ProcessorStateManagerPass through the root StateStore in the init method so the inner StateStore can register that object.Author: tomdearman <tom.dearman@gmail.com>Reviewers: Yasuhiro MatsudaCloses #904 from tomdearman/KAFKA-3229,3
"MINOR: Use full package name when classes referenced in documentationThe `metric.reporters` description in the documentation says to implement the `MetricReporter` class, but the actual class is `MetricsReporter`. [MetricsReporter.java](https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/metrics/MetricsReporter.java)The configurations documentation is also inconsistent as some references to classes do not have the full package name while others do.ijumaAuthor: Kevin Lu <kelu@paypal.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3875 from KevinLiLu/trunk",1
"KAFKA-9066: Retain metrics for failed tasks (#8502)Author: Chris Egerton <chrise@confluent.io>Reviewers: Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-4423: Drop support for Java 7 (KIP-118) and update deps (#5046)* Set --source, --target and --release to 1.8.* Build Scala 2.12 by default.* Remove some conditionals in the build file now that Java 8is the minimum version.* Bump the version of Jetty, Jersey and Checkstyle (the newerversions require Java 8).* Fixed issues uncovered by the new version if Checkstyle.* A couple of minor updates to handle an incompatible sourcechange in the new version of Jetty.* Add dependency to jersey-hk2 to fix failing tests causedby Jersey upgrade.* Update release script to use Java 8 and to take into accountthat Scala 2.12 is now built by default.* While we're at it, bump the version of Gradle, Gradle plugins,ScalaLogging, JMH and apache directory api.* Minor documentation updates including the readme and upgradenotes. A number of Streams Java 7 examples can be removedsubsequently.",4
"MINOR: improve JavaDocs for Streams PAPI WordCountExample (#5442)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Fix a number of warnings in clients test (#8073)Reviewers: Ismael Juma <ismael@juma.me.uk>, Andrew Choi <li_andchoi@microsoft.com>",3
"MINOR: Remove older brokers from upgrade test (#11117)As of version 2.2.1 , Kafka Streams uses message headers andthus requires broker version 0.11.0 or newer.Reviewers: John Roesler <john@confluent.io>, Ismael Juma <ismael@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-5602; ducker-ak: support --custom-ducktapeSupport a --custom-ducktape flag which allows developers to installtheir own versions of ducktape into Docker images.  This is helpful forducktape development.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>Closes #3539 from cmccabe/KAFKA-5602",5
HOTFIX: Rename WakeupException in MirrorMakerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael JumaCloses #375 from guozhangwang/HFWakeup,1
KAFKA-1498 Follow-up: add metric on avg record size.,1
"MINOR: Added one test and some clarifying comments on tests with simulated EOS (#7626)Added one test and some comments to clarify how EOS is ""enabled"" for some of the tests.Ran all streams tests.Reviewers: Matthias J. Sax <mjsax@apache.org>",3
copy branch 0.8 to trunkgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1413738 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10417: Update Cogrouped processor to work with suppress() and joins (#9727)Correct the implementation of the Cogroupprocessor to implement KTableProcessorSupplier.Change the cogrouped processor from PassThrough toKTablePassThrough to allow for sending old values.KTablePassThrough extends KTableProcessorSupplier instead ofProcessorSupplier to implement sending old values and the view() method.Reviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-5900: Add task metrics common to both sink and source tasksAdded metrics that are common to both sink and source tasks.Marked as ""**WIP**"" since this PR is built upon #3864, and will need to be rebased once that has been merged into `trunk`. However, I would still appreciate initial reviews since this PR is largely additive.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3911 from rhauch/kafka-5900",5
"KAFKA-12802 Added a file based cache for consumed remote log metadata for each partition to avoid consuming again incase of broker restarts. (#11058)Added snapshots for consumed remote log metadata for each partition to avoid consuming again in case of broker restarts. These snapshots are stored in the respective topic partition log directories.Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",5
"KAFKA-12924 Replace EasyMock and PowerMock with Mockito in streams metrics tests (#10850)Reviewers: John Roesler <vvcephei@apache.org>, Ismael Juma <ijuma@apache.org>",3
MINOR: Addressed minor typos in READMEs. (#10905)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
Add test cases to test log size retention and more; patched by John Fung; reviewed by Jun Rao; KAFKA-591git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1407680 13f79535-47bb-0310-9956-ffa450edef68,2
KAFKA-8435: replace delete groups request/response with automated protocol (#6860)Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
KAFKA-8618: Replace Txn marker with automated protocol (#7039)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
KAFKA-10224: Update jersey license from CDDL to EPLv2 (#9089)Update jersey license from CDDL to EPLv2Author: Rens Groothuijsen <l.groothuijsen@alumni.maastrichtuniversity.nl>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-8715; Fix buggy reliance on state timestamp in static member.id generation (#7116)The bug is that we accidentally used the current state timestamp for the group instead of the real current time. When a group is first loaded, this timestamp is not initialized, so this resulted in a `NoSuchElementException`. Additionally this violated the intended uniqueness of the memberId, which could have broken the group instance fencing. Fix is made and unit test to make sure the timestamp is properly encoded within the returned member.id.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8091; Use commitSync to check connection failure in listener update test (#6450)The use of consumer.poll() made the test flaky since in some cases, it doesn't wait for coordinator connection.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",3
"MINOR: Vagrant AWS overrideable EC2 instance name prefixewencpThis small change allows users to use Vagrantfile.local to specify a custom prefix for names of ec2 instances brought up with vagrant.This makes management of multiple aws test clusters a little easier since individual clusters can be assigned different name prefixes.if `ec2_instance_name_prefix` is not specified in `Vagrantfile.local`, behavior will be exactly the same as before this change.Testing:- aws: I verified worker nodes, broker nodes, zk nodes with and without the prefix override. Behavior is as expected- locally: I verified that bringing up worker nodes, broker nodes, zk nodes on a local machine is not impacted by this change.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #801 from granders/minor-vagrant-aws-overrideable-prefix",0
"KAFKA-9274: Remove `retries` for global task (#9047) - part of KIP-572 - removed the usage of `retries` in `GlobalStateManger` - instead of retries the new `task.timeout.ms` config is usedReviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Add HttpMetricsReporter for system testsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #4072 from ewencp/http-metrics",5
"KAFKA-10638: Fix QueryableStateIntegrationTest (#9521)This test has been observed to have flaky failures.Apparently, in the failed runs, Streams had entered a rebalancebefore some of the assertions were made. We recently madeIQ a little stricter on whether it would return errors instead ofnull responses in such cases:KAFKA-10598: Improve IQ name and type checks (#9408)As a result, we have started seeing failures now instead ofsilently executing an invalid test (I.e., it was asserting thereturn to be null, but the result was null for the wrongreason).Now, if the test discovers that Streams is no longer running,it will repeat the verification until it actually gets a validpositive or negative result.Reviewers: Chia-Ping Tsai <chia7712@apache.org>",1
"Initial commit (#10454)This PR is a precursor to the recovery logic refactor work (KAFKA-12553).I've renamed the file: core/src/test/scala/unit/kafka/log/LogUtils.scala to core/src/test/scala/unit/kafka/log/LogTestUtils.scala. Also I've renamed the underlying lass from LogUtils to LogTestUtils. This is going to help avoid a naming conflict with a new file called LogUtils.scala that I plan to introduce in core/src/main/scala/kafka/log/ as part of the recovery logic refactor. The new file will also contain a bunch of static functions.Tests:Relying on existing tests to catch regressions (if any) since this is a simple change.Reviewers: Satish Duggana <satishd@apache.org>, Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-3290: fix race condition with worker task shutdown and mock validationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #1008 from hachikuji/KAFKA-3290-REVISITED,5
MINOR: Downgrade to Gradle 4.5.1 (#4791)There is a regression in 4.6 that causes`testAll` to fail:https://github.com/gradle/gradle/pull/4680Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3449: Rename filterOut() to filterNot() to achieve better terminology…nologyHi all,This is my first contribution and I hope it will be good.The PR is related to this issue:https://issues.apache.org/jira/browse/KAFKA-3449Thanks a lot,AndreaAuthor: Andrea Cosentino <ancosen@gmail.com>Reviewers: Yasuhiro Matsuda, Guozhang WangCloses #1134 from oscerd/KAFKA-3449",0
kafka-1667; topic-level configuration not validated; patched by Dmytro Kostiuchenko; reviewed by Jun Rao,5
"KAFKA-12951: restore must terminate for tx global topic (#10894)Reviewers: Guozhang Wang <guozhang@confluent.io>, Luke Chen <showuon@gmail.com>, Gasparina Damien <d.gasparina@gmail.com>",5
"MINOR: Code cleanup to improve generic typing (#8251)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-4658; Improve test coverage InMemoryKeyValueLoggedStoreAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3293 from jeyhunkarimov/KAFKA-4658",4
MINOR: Replace ApiVersion by auto-generated protocol (#9746)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-7672 : force write checkpoint during StreamTask #suspend (#6115)This fix is aiming for #2 issue pointed out within https://issues.apache.org/jira/browse/KAFKA-7672In the current setup, we do offset checkpoint file write when EOS is turned on during #suspend, which introduces the potential race condition during StateManager #closeSuspend call. To mitigate the problem, we attempt to always write checkpoint file in #suspend call.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: Streams upgrade system test cleanup (#7571)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>,",5
"KAFKA-4123: Queryable State returning null for key before all stores in instance have been initializedMark the store as open after the DB has been restored from the changelog.Only add the store to the map in ProcessorStateManager post restore.Make RocksDBWindowStore.Segment override openDB(..) as it needs to mark the Segment as open.Throw InvalidStateStoreException if any stores in a KafkaStreams instance are not available.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1824 from dguy/kafka-4123",3
HOTFIX: fix StateManagerUtilTest and StreamTaskTest failures (#8247)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-10061; Fix flaky `ReassignPartitionsIntegrationTest.testCancellation` (#8749)We have seen this test failing from time to time. In spite of the low quota, it is possible for one or more of the reassignments to complete before verification that the reassignment is in progress. The patch makes this less likely by reducing the quota even further and increasing the amount of data in the topic.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: refactor error message of task migration (#4803)In the stream thread capture of the TaskMigration exception, print the task full information in WARN. In other places only log as INFO, plus additional context information.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Allow for asynchronous start of producer consumer in validation testAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1909 from kkonstantine/MINOR-Async-start-in-produce-consume-validate,5
enhance copying array (#9209)Reviewers: Bill Bejeck <bbejeck@apache.org>,2
MINOR: Add StorageTool as specified in KIP-631 (#10043)Add StorageTool as specified in KIP-631. It can format and describe storage directories.  Fix a bug in `ZkMetaProperties#toString`.Reviewers: David Arthur <mumrah@gmail.com>,0
KAFKA-3187: Make kafka-acls.sh help messages more generic.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #892 from SinghAsDev/KAFKA-3187,1
"MINOR: Fix warn logging in RecordCollectorImplFix warn log message in RecordCollectorImpl so it prints the exception message rather than `{}`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, GuozhangWang <wangguoz@gmail.com>Closes #4318 from dguy/minor-logging-record-collector",2
MINOR: Should commit a task if the consumer position advanced as well (#11151)Reviewers: John Roesler <vvcephei@apache.org>,2
HOTFIX: ConsoleConsumer using wrong old consumer config value for auto.offset.resetAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3665 from hachikuji/hotfix-auto-reset-console-consumer,0
KAFKA-7838: Log leader and follower end offsets when shrinking ISR (#6168)Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-7047: Added SimpleHeaderConverter to plugin isolation whitelistThis was originally missed when headers were added as part of KIP-145 in AK 1.1. An additional unit test was added in line with the StringConverter.This should be backported to the AK `1.1` branch so that it is included in the next bugfix release. The `SimpleHeaderConverter` class that we're referencing was first added in the 1.1.0 release, so there's no reason to backport earlier.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5204 from rhauch/kafka-7047",5
KAFKA-2340: Improve KafkaConsumer Fetcher test coverageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #112 from hachikuji/KAFKA-2340 and squashes the following commits:cc49ca2 [Jason Gustafson] KAFKA-2340; improve KafkaConsumer Fetcher test coverage,3
MINOR: Upgrade Gradle to 6.6 (#9160)A couple of important bug fixes affecting Scala compilation are the main driver:* https://github.com/gradle/gradle/issues/13224* https://github.com/gradle/gradle/issues/13392Full release notes for the other improvements:* https://docs.gradle.org/6.6/release-notes.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"KAFKA-5816; [FOLLOW UP] create ProducedInternal classCreate `ProducedInternal` and remove getters from `Produced`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3810 from dguy/kafka-5816-follow-up",5
TRIVIAL: remove TODO in KafkaConsumer after KAFKA-2120Author: Guozhang Wang <wangguoz@gmail.com>Closes #278 from guozhangwang/TL-KafkaConsumer,2
MINOR: Handle error metrics removal during shutdownAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4187 from rajinisivaram/MINOR-metrics-cleanup,5
"KAFKA-9695; Handle null config values for createTopics, alterConfigs (#8266)Throw InvalidRequestException if null configs are specified for CreateTopics, AlterConfigs or IncrementalAlterConfigs.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
"KAFKA-7288 - Make sure no bytes buffered when relying on idle timeout in channel close test (#6390)SelectorTest.testCloseConnectionInClosingState sends and receives messages to get the channel into a state with staged receives and then waits for idle timeout to close the channel. When run with SSL, the channel may have buffered bytes that prevent the channel from being closed. Updated the test to wait until there are no buffered bytes as well.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-4343: Expose Connector type in REST API (KIP-151)https://cwiki.apache.org/confluence/display/KAFKA/KIP-151+Expose+Connector+type+in+REST+APIAuthor: dan norwood <norwood@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2960 from norwood/KIP-151",5
KAFKA-6243: Enable dynamic updates of broker metrics reporters (#4464)Dynamic metrics reporter updates described in KIP-226. This includes:  - Addition and removal of metrics reporters  - Reconfiguration of custom metrics reporter configs  - Tests for metrics reporter updates at default cluster-level and as per-broker config for testingReviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-2211: Adding simpleAclAuthorizer implementation and test cases.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #195 from Parth-Brahmbhatt/KAFKA-2211",3
"MINOR: Reduce log cleaner offset memory usage in KRaftClusterTestKit (#11533)We now use 2MB as with the other test harnesses.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Colin Patrick McCabe <cmccabe@confluent.io>, Luke Chen <showuon@gmail.com>",5
kafka-1645; some more jars in our src release; patched by Joe Stein; reviewed by Jun Rao,5
"MINOR: FetchRequest.Builder maxBytes for version <3The maxBytes field should be set to DEFAULT_RESPONSE_MAX_BYTES,the same way as the constructor using the Struct does.codeveloped with mimaisonAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2694 from edoardocomar/MINOR-FetchRequest",2
"KAFKA-10478: Allow duplicated ports in advertised.listeners (#9281)Remove the requirement for unique port numbers for the advertised.listener parameters.This restriction makes for the listeners parameter but there's not reason to apply thesame logic for advertised.listeners.Being able to do this opens possibilities for some practical applications when usingKerberos authentication. For example, when configuring Kafka using Kerberos authenticationand a Load Balancer we need to have two SASL_SSL listeners: (A) one running with thekafka/hostname principal and (B) another using kafka/lb_name, which is necessary forproper authentication when using the LB FQDN. After bootstrap, though, the client receivesthe brokers' addresses with the actual host FQDNs advertised by the brokers. To connectto the brokerd using the hostnames the client must connect to the listener A to be able toauthenticate successfully with Kerberos.Author: Andre Araujo <asdaraujo@gmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Tom Bentley <tbentley@redhat.com>",1
MINOR: Trogdor should not assume an agent co-located with the controller (#4712),5
KAFKA-2306: add another metric for buffer exhausted; reviewed by Guozhang Wang,1
"KAFKA-12361; Use default request.timeout.ms value for Connect producers (#10178)Connect uses a high request timeout as a holdover from the days prior to KIP-91 when this was required to guarantee records would not get timed out in the accumulator. Having a high request timeout makes it harder for the producer to gracefully handle unclean connection terminations, which might happen in the case of sudden broker death.Reducing that value to the default of 30 seconds should address that issue, without compromising the existing delivery guarantees of the Connect framework. Since the delivery timeout is still set to a very-high value, this change shouldn't make it more likely for `Producer::send` to throw an exception and fail the task.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-13032: add NPE checker for KeyValueMapper (#11241)Currently KStreamMap and KStreamFlatMap classes will throw NPE if the call to KeyValueMapper#apply() return null. This commit checks whether the result of KeyValueMapper#apply() is null and throws a more meaningful error message for better debugging.Two unit tests are also added to check if we successfully captured nulls.Reviewers: Josep Prat <josep.prat@aiven.io>,  Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
MINOR: fix and improve StreamsConfig JavaDocs (#8086)Reviewer: John Roesler <john@confluent.io>,5
"MINOR: Documentation for KIP-585 (#8839)* Add documentation for using transformation predicates.* Add `PredicateDoc` for generating predicate config docs, following the style of `TransformationDoc`.* Fix the header depth mismatch.* Avoid generating HTML ids based purely on the config name since thereare very likely to conflict (e.g. #name). Instead allow passing a functionwhich can be used to generate an id from a config key.The docs have been generated and tested locally. Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-3132: URI scheme in ""listeners"" property should not be case-sen……sitiveAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael JumaCloses #811 from granthenke/listeners-case",5
MINOR: LogLoader: Add log identifier at few missing areas (#10819)Reviewers: Jun Rao <junrao@gmail.com>,2
KAFKA-538 missing apache license header in sbt and util.hgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1391715 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Misc improvements on runtime / storage / metrics / config parts (#4525)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"Revert ""KAFKA-1764; ZookeeperConsumerConnector should not put multiple shutdown commands to the same data chunk queue; reviewed by Joel Koshy and Guozhang Wang""This reverts commit d99af88eafefbfd1c537a64f8107cd9041346015.",4
KAFKA-6697: Broker should not die if getCanonicalPath fails (#4752)A broker with multiple log dirs will die on startup if dir.getCanonicalPath() throwsIOException for one of the log dirs. We should mark such log directory as offlineinstead and the broker should start if there is a healthy log dir.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
MINOR: Fix support for custom commit ids in the build (#12014)This regressed in ca375d8004c1 due to a typo. We need testsfor our builds. :)I verified that passing the commitId via `-PcommitId=123`works correctly.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-9161: add docs for KIP-441 and KIP-613 and other configs that need fixing (#9027)Add docs for KIP-441 and KIP-613.Fixed some miscellaneous unrelated issues in the docs:* Adds some missing configs to the Streams config docs: max.task.idle.ms,topology.optimization, default.windowed.key.serde.inner.class, and default.windowed.value.serde.inner.class* Defines the previously-undefined default windowed serde class configs, including choosing a default (null) and giving them a doc string, so the yshould nwo show up in the auto-generated general Kafka config docs* Adds a note to warn users about the rocksDB bug that prevents setting a strict capacity limit and counting write buffer memory against the block cacheReviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
MINOR: Preserve the base offset of the original record batch in V2The previous code did not handle this correctly if a batch wascompacted more than once.Also add test case for duplicate check after log cleaning andimprove various comments.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3145 from hachikuji/minor-improve-base-sequence-docs,2
"MINOR: move ""Added/Removed sensor"" log messages to TRACE (#7502)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Correct Connect docs on connector/task states (#11914)The `DESTROYED` state is represented internally as a tombstone record when running in distributed mode and by the removal of the connector/task from the in-memory status map when running in standalone mode. As a result, it will never appear to users of the REST API, and we should remove mention of it from our docs so that developers creating tooling against the REST API don't write unnecessary logic to account for that state.Reviewers: Mickael Maison <mickael.maison@gmail.com>",2
"Liars in PrimitiveApiTest that promise to test api in compression mode, but don't do this actually; patched by Kostya Golikov; reviewed by Guozhang Wang and Jun Rao",3
KAFKA-9171: Handle ReplicaNotAvailableException during DelayedFetch (#7678)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
KAFKA-3768; Replace all pattern match on boolean value by if/else block.Author: Satendra kumar <satendra@knoldus.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1445 from satendrakumar06/remove_boolean_pattern_match,4
"MINOR: Remove stray comma from PartitionInfo.toStringRemoved the extra ',' character while printing the replicas / in-sync replicasarray.Author: Kamal <kamal@nmsworks.co.in>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2306 from Kamal15/trunk",1
"MINOR: Removed 1/2 of the hardcoded sleeps in StreamsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1422 from enothereska/minor-integration-timeout2",4
"KAFKA-10113; Specify fetch offsets correctly in `LogTruncationException` (#8822)This patch fixes a bug in the constructor of `LogTruncationException`. We were passing the divergent offsets to the super constructor as the fetch offsets. There is no way to fix this without breaking compatibility, but the harm is probably minimal since this exception was not getting raised properly until KAFKA-9840 anyway.Note that I have also moved the check for unknown offset and epoch into `SubscriptionState`, which ensures that the partition is still awaiting validation and that the fetch offset hasn't changed. Finally, I made some minor improvements to the logging and exception messages to ensure that we always have the fetch offset and epoch as well as the divergent offset and epoch included.Reviewers: Boyang Chen <boyang@confluent.io>, David Arthur <mumrah@gmail.com>",5
"MINOR: Support KRaft in ReplicaFetchTest (#12345)Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3361: Initial protocol documentation page and generation- Moves all generated docs under /docs/generated- Generates docs for Protocol, Errors, and ApiKeys- Adds new protocol.html pageAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #970 from granthenke/protocol-doc-wip",2
"MINOR: Fix comment about AbstractFetcherThread.handlePartitionsWithError (#7205)Reviewers: Stanislav Kozlovski<stanislav_kozlovski@outlook.com>, William Hammond<william.t.hammond@gmail.com>, Chia-Ping Tsai<chia7712@gmail.com>",0
"KAFKA-2073: migrate to client-side topic metadata request/responseAuthor: Jason Gustafson <jason@confluent.io>Author: Ismael Juma <ismael@juma.me.uk>Author: hachikuji <jason@confluent.io>Reviewers: Grant Henke, Ismael Juma, Gwen Shapira, Flavio JunquieraCloses #988 from hachikuji/KAFKA-2073",5
"KAFKA-6879; Invoke session init callbacks outside lock to avoid Controller deadlock (#4977)Fixes a deadlock between the controller's beforeInitializingSession callback which holds the zookeeper client initialization lock while awaiting completion of an asynchronous event which itself depends on the same lock.Also catch and log callback exceptions to ensure the ZooKeeper reconnection takes place.Finally, configure KafkaScheduler in ZooKeeperClient to have at least 1 thread.Added tests that fail or hang without the changes in this PR.Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-9244: Update FK reference should unsubscribe old FK (#7758)Reviewers: Adam Bellemare <adam.bellemare@wishabi.com>, John Roesler <john@confluent.io>",5
KAFKA-1126 Remove the DISCLAIMER it is left over from incubation reviewed by Neha,4
KAFKA-6247; Install Kibosh on Vagrant and fix release downloads in DockerFix an omission where Kibosh was not getting installed on Vagrantinstances running in AWS.Fix an issue where the Dockerfile was unable to download old ApacheKafka releases.  See the discussion on KAFKA-6233.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4240 from cmccabe/KAFKA-6247,5
"MINOR: Fix typo in javadoc of `flatMapValues`Author: Michael G. Noll <michael@confluent.io>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2607 from miguno/trunk-flatMapValues-docstring",2
"MINOR: Replace null with an actual value for timestamp field in InsertField SMT unit tests (#8649)Add actual values instead of just passing null in unit tests that check the behavior of the InsertField SMT when trying to insert a field that takes its value from the Kafka record timestamp.Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-8362: fix the old checkpoint won't be removed after alter log dir (#9178)In KIP-113, we support replicas movement between log directories. But while the directory change, we forgot to remove the topicPartition offset data in old directory, which will cause there are more than 1 checkpoint copy stayed in the logs for the altered topicPartition. And it'll let the LogCleaner get stuck due to it's possible to always get the old topicPartition offset data from the old checkpoint file.I added one more parameter topicPartitionToBeRemoved in updateCheckpoints() method. So, if the update parameter is None (as before), we'll do the remove action to remove the topicPartitionToBeRemoved data in dir, otherwise, update the data as before.Reviewers: Jun Rao <junrao@gmail.com>",5
KAFKA-13785: add processor metadata to be committed with offset (#11829)Part of KIP-825Reviewers: Matthias J. Sax <matthias@confluent.io>,5
kafka-861; IndexOutOfBoundsException while fetching data from leader; patched by Sriram Subramanian; reviewed by Jun Rao and Neha Narkhede,5
"KAFKA-4914: Partition reassignment tool should check types before persisting state in ZooKeeper (#2708)Prior to this, there have been instances where invalid data was allowed to be persisted inZooKeeper, which causes ClassCastExceptions when a broker is restarted and reads thistype-unsafe data.Adds basic structural and type validation for the reassignment JSON viaintroduction of Scala case classes that map to the expected JSONstructure. Also use the Scala case classes to deserialize the JSONto avoid duplication.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Fix typo in ClusterTestExtensionsTest (#12218)Reviewers: Kvicii <Karonazaba@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Better messaging for invalid fetch response (#6427)Users have reported (KAFKA-7565) that when consumer poll wake up is used,it is possible to receive fetch responses that don't match the copied topicpartitions collection for the session when the fetch request was created.This commit improves the error handling here by throwing anIllegalStateException instead of a NullPointerException. And bygenerating a message for the exception that includes a bit of moreinformation.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-2386; increase timeouts for transient test failure in ConsumerCoordinatorResponseTestsThere are two race conditions in the test case ""testGenerationIdIncrementsOnRebalance."" First, a delay before the second join group request can timeout the initial group and cause the generationId to unexpectedly reset. Second, a delay in the join group request handling will timeout the request itself and cause the test to fail.  This commit doesn't address these race conditions, but increases the timeouts to make them more unlikely. If the problem reoccurs, then we'll probably need a better solution.Author: Jason Gustafson <jason@confluent.io>Reviewers: Gwen Shapira <cshapi@gmail.com>Closes #107 from hachikuji/KAFKA-2386 and squashes the following commits:a53460a [Jason Gustafson] KAFKA-2386; increase timeouts for transient test failure in ConsumerCoordinatorResponseTest",3
KAFKA-7514: Add threads to ConsumeBenchWorker (#5864)Add threads with separate consumers to ConsumeBenchWorker.  Update the Trogdor test scripts and documentation with the new functionality.Reviewers: Colin McCabe <cmccabe@apache.org>,1
"MINOR: Reduce replica.fetch.backoff.ms in ReassignPartitionsClusterTest (#5887)The default backoff of 1000ms when there are no partitions to fetch can cause `shouldExecuteThrottledReassignment` to fail due to it taking too long. So we reduceit to 100ms.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk",5
KAFKA-2084; trivial follow-up (remove JUnit3Suite dependency),3
"KAFKA-10362: When resuming Streams active task with EOS, the checkpoint file is deleted (#9247)Deleted the checkpoint file before the transition from SUSPENDED state to RESTORING stateReviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-2753: improve SyncGroup error handling in clientAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #433 from hachikuji/KAFKA-2753,5
kafka-907; controller needs to close socket channel to brokers on exception ; patched by Jun Rao; reviewed by Neha Narkhede,5
MINOR: Ensure `InterBrokerSendThread` closes `NetworkClient` (#9999)We should ensure `NetworkClient` is closed properly when `InterBrokerSendThread` is shutdown. Also use `initiateShutdown` instead of `wakeup()` to alert polling thread.Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Fix for typos in processor-api.html (#6961)This PR intendent to address some typos in https://kafka.apache.org/documentation/streams/developer-guide/processor-api.html page.Invalid configuration option specified in the example. I've replaced with closest constant TopicConfig.MIN_IN_SYNC_REPLICAS_CONFIG, since LogConfig.MinInSyncReplicasProp() requires Scala stuffReference to LogConfig seems to be obsolete, I believe I've moved it to correct lineApostrophe displayed incorrectlyReviewers: John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-3856 (KIP-120) step two: extract internal functions from public facing TopologyBuilder class - extract InternalTopologyBuilder from TopologyBuilder - deprecate all ""leaking"" methods from public TopologyBuilder API - changed TopologyDescription and all nested classed into interfacesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3536 from mjsax/kafka-3856-extract-internal-topology-builder",4
MINOR: Fix SessionStore#fetchSession parameter names (#11999)Fixes a small copy/paste error from #10390 that changed the parameter namesfor fetchSession from the singular session form (eg `startTime`) to the rangeform (eg `earliestSessionStartTime`).Reviewers: John Roesler <vvcephei@apache.org>,2
MINOR: Fix transient test failure in SslTransportLayerTest (#5396)Reviewers: Jason Gustafson <jason@confluent.io>,5
Update to sbt 0.7.7patch by cburroughs; reviewed by junrao for KAFKA-92git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178669 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-2436; log.retention.hours should be honored by LogManagerAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Joel Koshy, Gwen ShapiraCloses #142 from lindong28/KAFKA-2436",2
"KAFKA-5045: Clarify on KTable APIs for queryable storesThis is the implementation of KIP-114: KTable state stores and improved semantics:- Allow for decoupling between querying and materialisation- consistent APIs, overloads with queryableName and without- depreciated several KTable calls- new unit and integration testsIn this implementation, state stores are materialized if the user desires them to be queryable. In subsequent versions we can offer a second option, to have a view-like state store. The tradeoff then would be between storage space (materialize) and re-computation (view). That tradeoff can be exploited by later query optimizers.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2832 from enothereska/KAFKA-5045-ktable",1
KAFKA-3691; Confusing logging during metadata update timeoutAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1509 from granthenke/timeout-logging,2
KAFKA-8857; Don't check synonyms while determining if config is readOnly (#7278)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"KAFKA-2459: Mark last committed timestamp to fix connection backoffThis fix applies to three JIRAs, since they are all connected.KAFKA-2459Connection backoff/blackout period should start when a connection is disconnected, not when the connection attempt was initiatedBackoff when connection is disconnectedKAFKA-2615Poll() method is broken wrt timeAdded Time through the NetworkClient API. Minimal change.KAFKA-1843Metadata fetch/refresh in new producer should handle all node connection states gracefullyI’ve partially addressed this for a specific failure case in the JIRA.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Ismael Juma, Guozhang WangCloses #290 from enothereska/trunk",1
"MINOR: Use statically compiled regular expressions for efficiency (#5168)Reviewers: Andras Beni <andrasbeni@cloudera.com>, Sriharsha Chintalapani <sriharsha@apache.org>, Jason Gustafson <jason@confluent.io>",5
HOTFIX: Convert exception introduced in KAFKA-3637 to warning since clearly it is happening.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2283 from enothereska/hotfix-state-transition-warn,0
"KAFKA-7986: Distinguish logging from different ZooKeeperClient instances (#6493)A broken can have more than one instance of ZooKeeperClient. For example, SimpleAclAuthorizer creates a separate ZooKeeperClient instance when configured.This commit makes it possible to optionally specify the name for the ZooKeeperClient instance. The name is specified only for a broker's ZooKeeperClient instances, but not for commands' and tests'.Reviewers: Jun Rao <junrao@gmail.com>",3
"KAFKA-1260 Integration Test for New Producer Part II: Broker Failure Handling; reviewed by Jay Kreps, Neha Narkhede and Jun Rao",0
"KAFKA-2536: topics tool should allow users to alter topic configurationThis is a minimal revert of some backward incompatible changes made in KAFKA-2205, with the addition of the deprecation logging message.Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #305 from granthenke/topic-configs",5
MINOR: Fix doc variable typos in `TopicConfig` (#11972)Reviewers: Luke Chen <showuon@gmail.com>,5
"MINOR: improve Puncutation JavaDocs and add runtime argument check (#5895)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10054: KIP-613, add TRACE-level e2e latency metrics (#9094)Adds avg, min, and max e2e latency metrics at the new TRACE level. Also adds the missing avg task-level metric at the INFO level.I think where we left off with the KIP, the TRACE-level metrics were still defined to be ""stateful-processor-level"". I realized this doesn't really make sense and would be pretty much impossible to define given the DFS processing approach of Streams, and felt that store-level metrics made more sense to begin with. I haven't updated the KIP yet so I could get some initial feedback on thisReviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5107; remove preferred replica election state from ControllerContextKAFKA-5028 moves the controller to a single-threaded model, so we would no longer have work interleaved between preferred replica leader election, meaning we don't need to keep its state.This patch additionally addresses a bug from KAFKA-5028 where it made onPreferredReplicaElection keep the line calling topicDeletionManager.markTopicIneligibleForDeletion but removes the line calling topicDeletionManager.resumeDeletionForTopicsAuthor: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2927 from onurkaraman/KAFKA-5107",2
"KAFKA-6684: Support casting Connect values with bytes schema to stringAllow to cast LogicalType to string by calling the serialized (Java) object's toString().Added tests for `BigDecimal` and `Date` as whole record and as fields.Author: Amit Sela <amitsela33@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Robert Yokota <rayokota@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4820 from amitsela/cast-transform-bytes",5
"KAFKA-5078; PartitionRecords.fetchRecords(...) should defer exception to the next call if iterator has already moved across any valid recordSuppose there are two valid records followed by one invalid records in the FetchResponse.PartitionData(). As of current implementation, PartitionRecords.fetchRecords(...) will throw exception without returning the two valid records. The next call to PartitionRecords.fetchRecords(...) will not return that two valid records either because the iterator has already moved across them.We can fix this problem by defering exception to the next call of PartitionRecords.fetchRecords(...) if iterator has already moved across any valid record.Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Jiangjie Qin <becket.qin@gmail.com>Closes #2864 from lindong28/KAFKA-5078",5
MINOR: Added missing method parameter to `performAssignment` javadoc (#6744)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-6383: Complete shut down for streams threads that have not started*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Rohan Desai <desai.p.rohan@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4382 from rodesai/KAFKA-6383",5
"MINOR: Example style improvementsThese are minor, but no reason to make our example code look worse than it has to.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant HenkeCloses #940 from ijuma/example-style-improvements",1
"MINOR: Introduce NetworkClient.hasInFlightRequestsIt’s a minor optimisation, but simple enough.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2658 from ijuma/has-in-flight-requests",5
KAFKA-8232; Test topic delete completion rather than intermediate state (#6581)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
"KAFKA-3825: Allow users to specify different types of state stores in Streams DSLAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #1588 from jeyhunkarimov/KAFKA-3825",4
KAFKA-1739 Remove testComplexCompressDecompress in MessageCompressionTest; reviewed by Neha Narkhede,3
"KAFKA-8410: Update the docs to reference the new PAPI (#10994)Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-4935; Deprecate client checksum API and compute lazy partial checksum for magic v2Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3123 from hachikuji/KAFKA-4935",5
trivial change to remove a compilation warning; patched by Jun Rao,2
"KAFKA-8807: Flaky GlobalStreamThread test (#7418)A minor refactor to explicitly verify that Processor#close is only called once.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>,  Bruno Cadonna <bruno@confluent.io>,",5
"MINOR: Filter out quota configs for ConfigCommand using --bootstrap-server (#9030)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, David Jacot <djacot@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",5
KAFKA-13579: Patch upgrade of netty/jetty/jackson (#11656)Reviewers: Ismael Juma <ismael@juma.me.uk,5
"KAFKA-4895; Fix findbugs ""format string should use %n rather than \n"" in toolsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2684 from cmccabe/KAFKA-4895",5
MINOR: Update jackson to latest 2.10.5 (#9058)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
KAFKA-373 Fix trunk broker failure test to work with mirror maker; patched by John Fung; reviewed by Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1358407 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: removed incorrect deprecation annotations (#9061)Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, John Roesler <john@confluent.io>",5
KAFKA-6180; Add a Validator for NonNull configurations and remove redundant null checks on lists (#4188),4
KAFKA-1315 log.dirs property in KafkaServer intolerant of trailing slash; reviewed by Neha Narkhede and Guozhang Wang,5
"MINOR: Address flaky `KafkaAdminClient` tests (#9091)Fixes flakiness in `KafkaAdminClientTest` as a result of #8864. Addresses the following flaky tests:- testAlterReplicaLogDirsPartialFailure- testDescribeLogDirsPartialFailure- testMetadataRetriesReviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8221; Add batch leave group request (#6714)This patch is part of KIP-345. We are aiming to support batch leave group request issued from admin client. This diff is the first effort to bump leave group request version.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-12792: Fix metrics bug and introduce TimelineInteger (#10707)Introduce a TimelineInteger class which represents a single integervalue which can be changed while maintaining snapshot consistency. Fix acase where a metric value would be corrupted after a snapshot restore.Reviewers: David Arthur <mumrah@gmail.com>,0
"KAFKA-5090: Fix Kafka Streams SessionStore.findSessions javadoc brokenAuthor: mihbor <mbor81@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2874 from mihbor/patch-1",2
HOTFIX: Increase number of retries in smoke testAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2014 from enothereska/hotfix-smoke-test,3
"KAFKA-13710: bring the InvalidTimestampException back for record error (#11853)Reviewers: Guozhang Wang <guozhang@confluent.io>, Ricardo Brasil <anribrasil@gmail.com>",5
MINOR: Word count should account for extra whitespaces between words (#10229)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Remove erroneous extra <code> in design doc (#9657)Reviewers: Bill Bejeck <bbejeck@apache.org>,2
"KAFKA-4699; Invoke producer callbacks before completing the futureThis behaviour was changed in 8b3c6c0, but it caused interceptortest failures (which rely on callbacks) and since we’re so close tocode freeze, it’s better to be conservative.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2440 from ijuma/kafka-4699-callbacks-invoked-before-future-is-completed",5
KAFKA-9587: Add omitted configs in KafkaProducer javadoc (#8150)Simple javadoc fix that aligns the properties with the text. Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,0
"MINOR: Update to Gradle 6.8.1 (#9953)A number of regressions were fixed (see ""Fixed issues"" section):https://docs.gradle.org/6.8.1/release-notes.htmlReviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
KAFKA-5373; Revert breaking change to console consumerThis patch reverts b63e41ea78a58bdea78be33f90bfcb61ce5988d3since it broke the console consumer -- the consumer printsthe addresses of the messages instead of the contents withthat patch.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3218 from apurvam/KAFKA-5373-fix-console-consumer,0
"KAFKA-3847: Use a separate producer per source taskAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson, Gwen ShapiraCloses #1727 from ewencp/kafka-3847-per-task-producers and squashes the following commits:7d39724 [Ewen Cheslack-Postava] Add timeout for closing producers.98ec7f6 [Ewen Cheslack-Postava] KAFKA-3847: Use a separate producer per source task",1
MINOR: Reset `streamTime` on clear (#8250)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-12324: Upgrade jetty to fix CVE-2020-27218Here is the fix. The reason of [CVE-2020-27218](https://nvd.nist.gov/vuln/detail/CVE-2020-27218) was [Incorrect recycling of `HttpInput`](https://bugs.eclipse.org/bugs/show_bug.cgi?id=568892) and [patched in 9.4.35.v20201120](https://github.com/eclipse/jetty.project/security/advisories/GHSA-86wm-rrjm-8wh8).This PR updates Jetty dependency into the following version, 9.4.36.v20210114.Author: Lee Dongjin <dongjin@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #10177 from dongjinleekr/feature/KAFKA-12324",5
"KAFKA-13296: warn if previous assignment has duplicate partitions (#11347)Reviewers: Matthias J. Sax <matthias@confluent.io>, Luke Chen <showuon@gmail.com>",5
"MINOR: Upgrade Gradle to 7.1.1 and remove JDK 15 build (#10968)Gradle 7.1 improves Java incremental compilation:https://docs.gradle.org/7.1.1/release-notes.htmlWe previously kept the JDK 15 build because sometests didn't work with JDK 16. Since then, a numberof PRs were submitted to fix this so it's bestto remove the JDK 15 build before we create the3.0 release branch.Finally bump `test-retry` gradle plugin version too.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Luke Chen <showuon@gmail.com>",3
KAFKA-14039 Fix AlterConfigPolicy usage in KRaft (#12374)Only pass configs from the request to the AlterConfigPolicy. This changes the KRaft usage of the AlterConfigPolicy to match the usage in ZK mode.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-3164: Document client and mirrormaker upgrade procedure/require……mentsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #838 from granthenke/upgrade-docs,2
MINOR: Fix typo in SMT doc: s/RegexpRouter/RegexRouterAuthor: Robin Moffatt <robin@rmoff.net>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3576 from rmoff/patch-1,5
"HOTFIX: Remove from restoringByPartition once restored (#7631)Minor follow up to #7608: For some reason the AssignedStreamTasks#updateRestored method only updates the restoring and restoredPartitions data structures, but there is a third map holding restored tasks & partitions: restoringByPartitionsAlso improves the TaskManager#closeLostTasks logging, by separating by case and logging the specific failure before throwing.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-5876: Add new exception types for Interactive Queries (#8200)- part of KIP-216- adds new sub-classes of InvalidStateStoreExceptionReviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: convert some more junit tests to support KRaft (#12456)* MINOR: convert some more junit tests to support KRaftIntroduce TestUtils#waitUntilLeaderIsElectedOrChangedWithAdmin, a ZK-free alternative toTestUtils#waitUntilLeaderIsElectedOrChanged.Convert PlaintextProducerSendTest, SslProducerSendTest, TransactionsWithMaxInFlightOneTest,AddPartitionsToTxnRequestServerTest and KafkaMetricsReporterTest to support KRaftReviewers: dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>",1
"KAFKA-10143; Improve test coverage for throttle changes during reassignment (#8891)In KIP-455, we changed the behavior of the reassignment tool so that the `--additional` flag is required in order to use the command to alter the throttle. This patch improves the documentation to make this clearer and adds some integration tests to validate the behavior.This patch also contains a few minor code quality improvements:- Factor out a helper `calculateCurrentMoveMap` from `calculateMoveMap` to compute the current move map, which makes the logic easier to follow- Rename `calculateMoveMap` to `calculateProposedMoveMap` to make intention clearer- Split `modifyBrokerThrottles` into two methods `modifyLogDirThrottle` and `modifyInterBrokerThrottle`- Move logic to compute leader and follower throttles into a new method `modifyReassignmentThrottle`, which takes it out of the execution path when log dir throttles are changed- Minor stylistic improvements such as replacing `.map.flatten` with `.flatMap`Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",1
HOTFIX: Remove Java verion 1.6 in quick-start docsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang WangCloses #1546 from guozhangwang/KHotfix-remove-JDK6-docs,4
"KAFKA-3310; Fix for NPEs observed when throttling clients.The fix basically ensures that the throttleTimeSensor is non-null before handing off to record the metric value. We also record the throttle time to 0 so that we don't recreate the sensor always.Author: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>Closes #989 from auradkar/KAFKA-3310",2
"KAFKA-4494: Reduce startup and rebalance time by batching restoration of storesReplace one-by-one initialization of state stores with bulk initialization.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2560 from dguy/kafka-4494",5
"kafka-1117; tool for checking the consistency among replicas; patched by Jun Rao; reviewed by Neha Narkhede, Joel Koshy, Swapnil Ghike, Guozhang Wang",5
MINOR: Bump Gradle version to 5.0 (#5964)Gradle 5.0 was released on 26 November. See the release notes for enhancements and fixes: https://docs.gradle.org/5.0/release-notes.html.A notable bugfix ensures that Javadoc artifacts are cleaned between builds.The upgraded wrapper was spot-checked against the commands in the README and theREADME was updated not to use removed system property `-Dtest.single`.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"MINOR: Avoid some unnecessary collection copies in KafkaApisAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4035 from hachikuji/KAFKA-5547-followup and squashes the following commits:f6b04ce1a [Jason Gustafson] Add a couple missed common fieldsd3473b14d [Jason Gustafson] Fix compilation errors and a few warnings58a0ae695 [Jason Gustafson] MINOR: Avoid some unnecessary collection copies in KafkaApis",2
KAFKA-842 Mirror maker can lose some messages during shutdown; reviewed by Jun Rao,1
"MINOR: Fix flaky system test assertion after static member fencing (#9033)The test case `OffsetValidationTest.test_fencing_static_consumer` fails periodically due to this error:```Traceback (most recent call last):  File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/venv/lib/python2.7/site-packages/ducktape-0.7.8-py2.7.egg/ducktape/tests/runner_client.py"", line 134, in run    data = self.run_test()  File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/venv/lib/python2.7/site-packages/ducktape-0.7.8-py2.7.egg/ducktape/tests/runner_client.py"", line 192, in run_test    return self.test_context.function(self.test)  File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/venv/lib/python2.7/site-packages/ducktape-0.7.8-py2.7.egg/ducktape/mark/_mark.py"", line 429, in wrapper    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)  File ""/home/jenkins/workspace/system-test-kafka_2.6/kafka/tests/kafkatest/tests/client/consumer_test.py"", line 257, in test_fencing_static_consumer    assert len(consumer.dead_nodes()) == num_conflict_consumersAssertionError```When a consumer stops, there is some latency between when the shutdown is observed by the service and when the node is added to the dead nodes. This patch fixes the problem by giving some time for the assertion to be satisfied.Reviewers: Boyang Chen <boyang@confluent.io>",5
"MINOR: Fix now that kafka.apache.org resolves to 3 IP addresses (#9294)Reviewers: David Jacot <david.jacot@gmail.com>, Boyang Chen <boyang@confluent.io>, David Arthur <mumrah@gmail.com>",5
"KAFKA-14143: Exactly-once source connector system tests (#11783)Also includes a minor quality-of-life improvement to clarify why some internal REST requests to workers may fail while that worker is still starting up.Reviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",1
"KAFKA-7413: Replace slave terminology with follower in documentation (#5653)Reviewers: John Roesler <john@confluent.io>, Ryanne Dolan, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Removed accidental double negation in error message. (#7834),0
"KAFKA-6765: Handle exception while reading throttle metric value in test (#4869)Quota tests wait for throttle metric to be updated without waiting for requests to complete to avoid waiting for potentially large throttle times. This requires the test to read metric values while a broker may be updating the value, resulting in exception in the test. Since this issue can also occur with JMX metrics reporter, change synchronization on metrics with sensors to use the sensor as lock.",1
"KAFKA-9929: Support backward iterator on SessionStore (#9139)Implements KIP-617 for `SessionStore`Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-9038; Allow creating partitions while a reassignment is in progress  (#7582)Prior to this patch, partition creation would not be allowed for any topic while a reassignment is in progress. The PR makes this a topic level check. As long as a particular topic is not being reassigned, we allow partitions to be increased.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8934: Create version file during build for Streams (#7397)The Kafka Clients library includes a version file that contains its version and Git commit ID.Since Kafka Streams wants to expose version and commit ID in the metrics it needs to read the version file. To enable the users to check during runtime for version mismatches between the Streams library and the Clients library, the version file is copied from Clients during buildtime and during runtime only the Streams version file is read.If Streams would read Clients' version file during runtime, it would read a wrong version and commit ID if the libraries where not build from repositories in different states.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: update Streams docs for KIP-123Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Ewen Chesklack-Postava, Bill Bejeck, Guozhang WangCloses #3194 from mjsax/minor-update-docs-for-kip-123",5
"MINOR: Remove RollingBounceTest since its functionality is covered by the ReplicationTest system testRollingBounceTest is a system test that cannot be run reliably in unit tests and ReplicationTest is a superset of thefunctionality: in addition to verifying that bouncing leaders eventually results in a new leader, ReplicationTest alsovalidates that data continues to be produced and consumed.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #1242 from ewencp/minor-remove-rolling-bounce-integration-test",3
"KAFKA-6991: Fix ServiceLoader issue with PluginClassLoader (KIP-285)Fix ServiceLoader issue with PluginClassLoader and add basic-auth-extension packaging & classpath*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5135 from mageshn/KAFKA-6991",5
kafka-2044; Support requests and responses from o.a.k.common in KafkaApis; patched by Gwen Shapira; reviewed by Jun Rao,1
"KAFKA-2360; Extract producer-specific configs out of the common PerfConfigSeparate `batch.size`, `message-size` and `compression-code` from PerfConfig to a newly-created ProducerPerfConfig in order to hide them in ConsumerPerf tool.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3613 from huxihx/KAFKA-2360",5
kafka-1344; Kafka-console-producer.sh support snappy compression; patched by Ivan Lyutovg; reviewed by Jun Rao,1
"KAFKA-6718: Add documentation for KIP-708 (#11923)Adds documentation for KIP-708: Rack awareness for Kafka StreamsCo-authored-by: Bruno Cadonna <cadonna@apache.org>Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
KAFKA-5266; Follow-up improvements for consumer offset reset tool (KIP-122)Implement improvements defined here: https://issues.apache.org/jira/browse/KAFKA-5266Author: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3102 from jeqo/feature/KAFKA-5266,5
KAFKA-4345; Run decktape test for each pull requestAs of now the ducktape tests that we have for kafka are not run for pull request. We can run these test using travis-ci. Here is a sample run:https://travis-ci.org/raghavgautam/kafka/builds/170574293Author: Raghav Kumar Gautam <raghav@apache.org>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>Closes #2064 from raghavgautam/trunk,1
MINOR: the top-level error message of AlterPartitionReassignmentsResponseData does not get propagated correctly (#9392)Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-3684: SinkConnectorConfig does not return topics in config validation.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1356 from Ishiihara/bug-fix-validate,5
HOTFIX: add igore import to streams_upgrade_test,3
KAFKA-5013; Fail the build when findbugs failsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2805 from cmccabe/KAFKA-5013,5
KAFKA-1539 Fsync offset checkpoint file after writing.,2
MINOR: Next release will be 1.0.0Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3580 from ijuma/bump-to-1.0.0-SNAPSHOT,5
MINOR: cleanup and add tests to StateDirectoryTest (#8304)Adds tests for edge conditions of listAllTaskDirectoriesAlso includes some minor cleanup of the StateDirectoryTest classReviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-7251; Add support for TLS 1.3 (#7804)Adds support for TLSv1.3 in SslTransportLayer. Note that TLSv1.3 is only enabled from Java 11 onwards, so we test the code only when running with Java11 and above.Tests run on this PR:  - SslTransportLayerTest: This covers testing of our SslTransportLayer and all tests are run with TLSv1.3 when running with Java 11. These tests are also run with TLSv1.2 for all Java versions.  - SslFactoryTest: Also run with TLSv1.3 on Java 11 onwards in addition to TLSv1.2 for all Java versions.  - SslEndToEndAuthorizationTest - Run only with TLSv1.3 on Java 11 onwards and only with TLSv1.2 on earlier Java versions. We have other versions of this test which use SSL that continue to be with TLSv1.2 on Java 11 to avoid reducing test coverage for TLSv1.2Additional testing for done for TLSv1.3:  - Most tests that use SSL use TestSslUtils.DEFAULT_TLS_PROTOCOL_FOR_TESTS which is set to TLSv1.2. I have run all clients and core tests with DEFAULT_TLS_PROTOCOL_FOR_TESTS=TLSv1.3 with Java 11.  - Ran a few system tests locally with TKSv1.3Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",3
"KAFKA-6897; Prevent KafkaProducer.send from blocking when producer is closed (#5027)After successful completion of KafkaProducer#close, it is possible that an application calls KafkaProducer#send. If the send is invoked for a topic for which we do not have any metadata, the producer will block until `max.block.ms` elapses - we do not expect to receive any metadata update in this case because Sender (and NetworkClient) has already exited. It is only when RecordAccumulator#append is invoked that we notice that the producer has already been closed and throw an exception. If `max.block.ms` is set to Long.MaxValue (or a sufficiently high value in general), the producer could block awaiting metadata indefinitely.This patch makes sure `Metadata#awaitUpdate` periodically checks if the network client has been closed, and if so bails out as soon as possible.",1
kafka-950; Leader election rate may be reported on a non-controller; patched by Jun Rao; reviewed by Sriram Subramanian,5
"MINOR: Streams system tests fixes/updates (#4689)Some changes required to get the Streams system tests working via DockerTo test:TC_PATHS=""tests/kafkatest/tests/streams"" bash tests/docker/run_tests.shThat command will take about 3.5 hours, and should pass. Note there are a couple of ignored tests.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-9924: Add remaining property-based RocksDB metrics as described in KIP-607 (#9232)This commit adds the remaining property-based RocksDB metrics as described in KIP-607, except for num-entries-active-mem-table, which was added in PR #9177.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
kafka-2118; Cleaner cannot clean after shutdown during replaceSegments; patched by Rajini Sivaram; reviewed by Jun Rao,5
HOTFIX: logic in QuerybaleStateIntegrationTest.shouldBeAbleToQueryState incorrectThe logic in `verifyCanGetByKey` was incorrect. It was```windowState.size() < keys.length &&countState.size() < keys.length &&System.currentTimeMillis() < timeout```but should be:```(windowState.size() < keys.length || countState.size() < keys.length) && System.currentTimeMillis() < timeout```Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1879 from dguy/minor-fix-test,3
"KAFKA-3805: Check if DB is null.- Check if DB is null before flushing or closing. In some cases, a state store is closed twice. This happens in `StreamTask.close()` where both `node.close()` and `super.close` (in `ProcessorManager`) are called in a sequence. If the user's processor defines a `close` that closes the underlying state store, then the second close will be redundant.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Andrés Gómez, Ismael Juma, Guozhang WangCloses #1485 from enothereska/KAFKA-3805-locks",1
"KAFKA-7190; Retain producer state until transactionalIdExpiration time passes (#7388)As described in KIP-360, this patch changes producer state retention so that producer state remains cached even after it is removed from the log. Producer state will only be removed now when the transactional id expiration time has passed. This is intended to reduce the incidence of UNKNOWN_PRODUCER_ID errors for producers when records are deleted or when a topic has a short retention time. Tested with unit tests.Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"HOTFIX: Reverted timeouts to larger valuesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #1324 from enothereska/hotfix-timeouts",0
"MINOR: Catch InvocationTargetException explicitly and propagate underlying cause (#12230)Catch InvocationTargetException explicitly and propagate underlying causeReviewers: Ismael Juma <mlists@juma.me.uk>, Matthew de Detrich <mdedetrich@gmail.com>, Kvicii, Luke Chen <showuon@gmail.com>",1
trival change to increase default producer request timeout,1
MINOR: fix listeners doc to close <code> properly (#9655)Fixes a problem with an incorrectly closed <code> in the doc for listeners.Reviewers: Bill Bejeck <bbejeck@apache.org>,2
"KAFKA-7284: streams should unwrap fenced exception (#5499)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
HOTFIX: suppress deprecation warnings to fix compilation errors (#11400)Reviewers: Bill Bejeck <bill@confluent.io>,5
"KAFKA-5252; Fix transient failures LogCleanerTest testCommitMarkerRemoval and testAbortMarkerRemovalAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3064 from hachikuji/KAFKA-5252",5
"KAFKA-3525; getSequenceId should return 1 for first data node creationZkUtils.getSequenceId() method is used to generate broker id sequence numbers. During startup, each broker updates the data at /brokers/seqid zk path and returns stat.getVersion as next sequence id.stat.getVersion returns ""1"" for first data update. So ZkUtils.getSequenceId() should return ""1"" on first data update.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Flavio Junqueira <fpj@apache.org>, Ismael Juma <ismael@juma.me.uk>Closes #1224 from omkreddy/KAFKA-3525",5
MINOR: Restore stream-table duality description (#8995)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-13098: Fix NoSuchFileException during snapshot recovery (#11071)Fix a bug where if a snapshot file is deleted while we're running snapshot recovery,a NoSuchFileException will be thrown and snapshot recovery will fail.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
"MINOR: Mark new Scala streams tests as integration tests (KIP-270 follow-up) (#5631)Reviewers: Eno Thereska <eno.thereska@gmail.com>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
add toString for RocksDbWindowBytesStoreSupplier (#8952)Add toString() to RocksDbWindowBytesStoreSupplier to amend the logging gap.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
KAFKA-1576: Make delete topic command a little more user-friendly. Patch from Gwen Shapira.,1
"KAFKA-13773: catch kafkaStorageException to avoid broker shutdown directly (#12136)When logManager startup and loadLogs, we expect to catch any IOException (ex: out of space error) and turn the log dir into offline. Later, we'll handle the offline logDir in ReplicaManage, so that the cleanShutdown file won't be created when all logDirs are offline. The reason why the broker shutdown with cleanShutdown file after full disk is because during loadLogs and do log recovery, we'll write leader-epoch-checkpoint fil. And if any IOException thrown, we'll wrap it as KafkaStorageException and rethrow. And since we don't catch KafkaStorageException, so the exception is caught in the other place and go with clean shutdown path.This PR is to fix the issue by catching the KafkaStorageException with IOException cause exceptions during loadLogs, and mark the logDir as offline to let the ReplicaManager handle the offline logDirs.Reviewers: Jun Rao <jun@confluent.io>, Alok Thatikunta <alok123thatikunta@gmail.com>",5
KAFKA-657 Add APIs for the consumer to commit and fetch offsets on the broker.,1
MINOR: Unifies implementations for commitSync (#6319)Co-authored-by: Ilya Ganelin <ilya@slower.ai>Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"MINOR: Add shutdown tests for KRaft (#11606)Augments existing shutdown tests for KRaft. Adds the ability to update configs in KRaft tests,and in both the ZK and KRaft cases to be able to update configs without losing the server'slog directory and data.Reviewers: Colin P. McCabe <cmccabe@apache.org>",5
KAFKA-6233: Removed unnecessary null check in StringSerializerRemoved unnecessary null checkif (encodingValue != null && encodingValue instanceof String)null instanceof String returns false hence replaced the check withif (encodingValue instanceof String)Author: Sagar Chavan <sagar.chavan3172@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4232 from sagarchavan3172/trunk,1
"KAFKA-7324: NPE due to lack of SASLExtensions in SASL/OAUTHBEARER (#5552)Set empty extensions if null is passed in.Reviewers: Satish Duggana <sduggana@hortonworks.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-2669; Fix LogCleaner.awaitCleaned for LogCleanerIntegrationTestLogCleanerIntegrationTest calls LogCleaner.awaitCleaned() to wait until cleaner has processed up to given offset. However, existing awaitCleaned() implementation doesn't wait for this. This patch fix the problem.Author: Dong Lin <lindong@cis.upenn.edu>Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #327 from lindong28/KAFKA-2669",0
"KAFKA-10833: Expose task configurations in Connect REST API (KIP-661) (#9726)This PR adds a new REST endpoint to Connect: GET /{connector}/tasks-config, that returns the configuration of all tasks for the connector.Details in: https://cwiki.apache.org/confluence/display/KAFKA/KIP-661%3A+Expose+task+configurations+in+Connect+REST+APICo-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Oliver Dineen <dineeno@uk.ibm.com>Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",5
"MINOR: Enhance the documentation with the metric unit which is milliseconds (#10148)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2
"MINOR: Added safe deserialization implementationAuthor: Hooman Broujerdi <hoomanb@hoomanb.usersys.redhat.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3563 from rhauch/deserialization-validation",5
KAFKA-12527: Remove deprecated PartitionGrouper annotation (#10380)A quick follow-up rebased on https://github.com/apache/kafka/pull/10302 to remove deprecated annotation.,4
"KAFKA-7440; Add leader epoch to fetch and list-offset request (#6190)As part of KIP-320, we should add the expected leader epoch to Fetch and ListOffsets requests. This will allow us ultimately to detect log truncation.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Handle null values in validatorsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1316 from ewencp/minor-handle-null-values-validators,5
"KAFKA-9004; Prevent older clients from fetching from a follower (#7531)With KIP-392, we allow consumers to fetch from followers. This capability is enabled when a replica selector has been provided in the configuration. When not in use, the intent is to preserve current behavior of fetching only from leader. The leader epoch is the mechanism that keeps us honest. When there is a leader change, the epoch gets bumped, consumer fetches fail due to the fenced epoch, and we find the new leader.However, for old consumers, there is no similar protection. The leader epoch was not available to clients until recently. If there is a preferred leader election (for example), the old consumer will happily continue fetching from the demoted leader until a periodic metadata fetch causes us to discover the new leader. This does not create any problems from a correctness perspective–fetches are still bound by the high watermark–but it is unexpected and may cause unexpected performance characteristics.This patch fixes this problem by enforcing leader-only fetching for older versions of the fetch request.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-5188; Integration tests for transactionsAuthor: Apurva Mehta <apurva@confluent.io>Author: Jason Gustafson <jason@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2994 from apurvam/KAFKA-5188-exactly-once-integration-tests,3
"KAFKA-8179: PartitionAssignorAdapter (#7110)Follow up to new PartitionAssignor interface merged in 7108 is mergedAdds a PartitionAssignorAdapter class to maintain backwards compatibilityReviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9127: don't create StreamThreads for global-only topology (#8540)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>",5
MINOR: clarify node grouping of input topics using pattern subscription (#7793)Updates the HTML docs and the javadoc.Reviewers: John Roesler <vvcephei@apache.org>,2
"KAFKA-9819: Fix flaky test in StoreChangelogReaderTest (#8488)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-8964: Refactor thread-level metrics depending on built-in metrics version (#7474)* Made commit-over-tasks sensor and skipped-records sensor optional since they are removed in the latest version* Refactored methods for sensor creation* Adapted unit and integration testsReviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-10199: Remove tasks from state updater on shutdown (#12562)The state updater removes its updating and paused task on shutdown.The removed tasks are added to the output queue for removed tasks.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-4016: Added join benchmarksAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Damian Guy, Guozhang WangCloses #1700 from enothereska/join-benchmarks",1
"KAFKA-4469; Fix consumer performance regression from inefficient list removal and copyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2190 from hachikuji/KAFKA-4469",5
Require values in Utils.getTopic* methods to be positive (0.8 branch); patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-481git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377214 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-5876: KIP-216 Part 4, Apply InvalidStateStorePartitionException for Interactive Queries (#10657)KIP-216, part 4 - apply InvalidStateStorePartitionExceptionReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",3
"KAFKA-4112: Remove alpha quality label from Kafka Streams in docsRephrase 'alpha quality' wording in Streams section of api.html.Couple of other minor fixes in streams.htmlAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang, Ismael Juma, Michael G. NollCloses #1811 from dguy/kstreams-312",0
"KAFKA-7165: Retry the BrokerInfo registration into ZooKeeper (#5575)* Add logic to retry the BrokerInfo registration into ZooKeeperIn case the ZooKeeper session has been regenerated and the brokertries to register the BrokerInfo into Zookeeper, this code deletesthe current BrokerInfo from Zookeeper and creates it again, just ifthe znode ephemeral owner belongs to the Broker which tries to registerhimself again into ZooKeeper* Add test to validate the BrokerInfo re-registration into ZooKeeper",5
"KAFKA-6415; Use WARN log level for Metadata in system testWhen a log entry is appended to a Kafka topic using `KafkaLog4jAppender`, the producer.send operation may block waiting for metadata. This can result in deadlocks in a couple of scenarios if a log entry from the producer network thread is also at a log level that results in the entry being appended to a Kafka topic.1. Producer's network thread will attempt to send data to a Kafka topic and this is unsafe since producer.send may block waiting for metadata, causing a deadlock since the thread will not process the metadata request/response.2. `KafkaLog4jAppender#append` is invoked while holding the lock of the logger. So the thread waiting for metadata in the initial send will be holding the logger lock. If the producer network thread has.a log entry that needs to be appended, it will attempt to acquire the logger lock and deadlock.This is a temporary workaround to avoid deadlocks in system tests by setting log level to WARN for `Metadata` in `VerifiableLog4jAppender`. The fix has been verified using the system tests log4j_appender_test.py which started failing when the info-level log entry was introduced.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Satish Duggana <satish.duggana@gmail.com>, tedyu <yuzhihong@gmail.com>Closes #4375 from rajinisivaram/KAFKA-6415-log4jappender",5
KAFKA-5239; Allocate memory outside the lock in producer buffer poolMove byte buffer allocation out of lock.Add unit test for restoring count when OOM is thrown from byte buffer allocation.Author: Sean McCauliff <smccauliff@linkedin.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #3053 from smccauliff/kafka-5239,2
"KAFKA-1501 Let the OS choose the port in unit tests to avoid collisions. Patch by Ewen CP, reviewed by Guozhang and me.",3
"KAFKA-3625: TopologyTestDriver must process output for wall-clock-time punctuations and on close() (#4502)Author: Matthias J. Sax <matthias@confluent.io>Reviewer: Damian Guy <damian@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Remove scala KafkaException (#11913)Use the standard org.apache.kafka.common.KafkaException instead of kafka.common.KafkaException.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@confluent.io>",5
KAFKA-12699: Override the default handler for stream threads if the stream's handler is used (#12324)Override the default handler for stream threads if the stream's handler is used. We do no want the java default handler triggering when a thread is replaced.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,0
KAFKA-3863: System tests covering connector/task failure and restartAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1519 from hachikuji/KAFKA-3863,5
KAFKA-5542; Improve Java doc for LeaderEpochFileCache.endOffsetFor()Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3468 from benstopford/KAFKA-5542,2
KAFKA-3831; Prepare for updating new-consumer-based Mirror Maker's default partition assignment strategy to round robinThis patch adds proper warning message and necessary doc updates for updating the default partition assignment strategy of Mirror Maker from range to round robin. The actual switch would occur as part of a major release cycle (to be scheduled).Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1499 from vahidhashemian/KAFKA-3831,5
MINOR: add mvn-pgp-plugin to sign streams quickstart jarsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3793 from dguy/sign-mvn-jars,1
KAFKA-9009: increase replica.lag.time.max.ms to make the test reliable (#10665)Reviewers: Mickael Maison <mickael.maison@gmail.com>,3
"MINOR: Fix wrong debug log message (#7137)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3097: Update docs to mention PrincipalType ""User"" is case sensitive (#5734)Reviewers: Jun Rao <junrao@gmail.com>",1
"KAFKA-12648: Pt. 3 - addNamedTopology API (#10788)Pt. 1: #10609Pt. 2: #10683Pt. 3: #10788In Pt. 3 we implement the addNamedTopology API. This can be used to update the processing topology of a running Kafka Streams application without resetting the app, or even pausing/restarting the process. It's up to the user to ensure that this API is called on every instance of an application to ensure all clients are able to run the newly added NamedTopology. Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"MINOR: Update the link to the Raft paper in docs (#8560)Update the link to the Raft paper pointing to the Usenix conference link.old broken link: https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdfnew link: https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdfReviewers: Boyang Chen <boyang@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-4785; Records from internal repartitioning topics should always use RecordMetadataTimestampExtractorAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3106 from jeyhunkarimov/KAFKA-4785",4
"MINOR: Assert ExecutionException details in testCreatePartitions (#7017)Due to the accidental duplication of `case e: ExecutionException`,the verification code was not actually running.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, David Arthur <mumrah@gmail.com>",5
KAFKA-5281; System tests for transactionsAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3149 from apurvam/KAFKA-5281-transactions-system-tests,5
"KAFKA-2824: MiniKDC based tests don't run in VirtualBoxThis is a hack which works. Is there a better way?Build (v2) of the replication_test.py running here: http://jenkins.confluent.io/job/kafka_system_tests_branch_builder/185/Author: Ben Stopford <benstopford@gmail.com>Reviewers: Geoff Anderson, Gwen ShapiraCloses #520 from benstopford/fix-for-sasl-virtual-box",0
"KAFKA-5918: Fix minor typos and errors in the Kafka Streams turotialI found several minor issues with the Kafka Streams tutorial:* Some typos  * ""As shown above, it illustrate that the constructed ..."" instead of ""As shown above, it illustrate_s_ that the constructed ...""  * ""same as Pipe.java below"" instead of ""same as Pipe.java _above_""  * Wrong class name in the `LineSplit` example* Incorrect imports for the code examples  * Missing `import org.apache.kafka.streams.kstream.KStream;` in `LineSplit` and `WordCount` example* Unnecessary (and potentially confusing) split by whitespaces in the `WorkCount` class (the split into words happened already in `LineSplit`)Author: Jakub Scholz <www@scholzj.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3883 from scholzj/stream-tutorial-typos",2
MINOR: Remove deprecated Resource class constructor usage (#5624)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
KAFKA-9316: Update command line option 'property' description in ConsoleProducerAuthor: huxihx <huxi_2b@hotmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7854 from huxihx/KAFKA-9316,5
"KAFKA-7223: Suppression Buffer Metrics (#5795)Add the final batch of metrics from KIP-328Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Update ""Java Version"" sectionUse the latest information from LinkedIn and mention that the latestreleased version is recommended from a security perspective.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant HenkeCloses #603 from ijuma/java-version-recommendation",5
"KAFKA-10395: relax output topic check in TTD to work with dynamic routing (#9174)Reviewers: Boyang Chen <boyang@apache.org>, Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
merge 0.8 to trunk and resolve conflicts,5
"MINOR: Remove header and key/value converter config value logging (#6660)The debug log lines in the `Plugins` class that log header and key/value converter configurations should be altered as the configurations for these converters may contain secrets that should not be logged in plaintext. Instead, only the keys for these configs are safe to expose.Author: Chris Egerton <cegerton@oberlin.edu>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"MINOR: remove duplicate map in StoreChangelogReader (#5143)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [cleanup] (#4939)* Add method to create test properties to StreamsTestUtils* Make TopologyTestDriver protected constructor package-private* Add comment suggesting the use of TopologyTestDriver to KStreamTestDriver* Cleanup:    - GlobalKTableJoinsTest    - KGroupedStreamImplTest    - KGroupedTableImplTest    - KStreamBranchTest    - KStreamFilterTest    - KStreamFlatMapTest    - KStreamFlatMapValuesTest    - KStreamForeachTest    - KStreamGlobalKTableJoinTest    - KStreamGlobalKTableLeftJoinTest    - KStreamImplTest    - KStreamKStreamJoinTest    - KStreamKStreamLeftJoinTest    - KStreamGlobalKTableLeftJoinTest    - KStreamKTableJoinTest    - KStreamKTableLeftJoinTest    - KStreamMapTest    - KStreamMapValuesTest    - KStreamPeekTest    - StreamsBuilderTest    - KStreamSelectKeyTest    - KStreamTransformTest    - KStreamTransformValuesTest    - KStreamWindowAggregateTest    - KTableForeachTestReviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4553; Improve round robin assignment in Connect to avoid uneven distributions of connectors and tasksAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2272 from ewencp/kafka-4553-better-connect-round-robin",1
"MINOR: remove unused TimeUnit from MetricConfigAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #600 from lindong28/minor",5
KAFKA-6614: configure internal topics with message.timestamp.type=CreateTime by default (#7889)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: improve error message for incorrect window-serde initialization (#7067)Reviewers: Tim Berglund <tim@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-3718; propagate all KafkaConfig __consumer_offsets configs to OffsetConfig instantiationKafka has two configurable compression codecs: the one used by the client (source codec) and the one finally used when storing into the log (target codec). The target codec defaults to KafkaConfig.compressionType and can be dynamically configured through zookeeper.The GroupCoordinator appends group membership information into the __consumer_offsets topic by:1. making a message with group membership information2. making a MessageSet with the single message compressed with the source codec3. doing a log.append on the MessageSetWithout this patch, KafkaConfig.offsetsTopicCompressionCodec doesn't get propagated to OffsetConfig instantiation, so GroupMetadataManager uses a source codec of NoCompressionCodec when making the MessageSet. Let's say we have enough group information such that the message formed exceeds KafkaConfig.messageMaxBytes before compression but would fall below the threshold after compression using our source codec. Even if we had dynamically configured __consumer_offsets with our favorite compression codec, the log.append will throw RecordTooLargeException during analyzeAndValidateMessageSet since the message was unexpectedly uncompressed instead of having been compressed with the source codec defined by KafkaConfig.offsetsTopicCompressionCodec.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1394 from onurkaraman/KAFKA-3718",5
"KAFKA-10438: Lazy initialization of record header to reduce memory usage (#9223)There are no checks on the header key so instantiating key (bytes to string) is unnecessary.One implication is that conversion failures will be detected a bit later, but this is consistentwith how we handle the header value.**JMH RESULT**1. ops: +12%1. The optimization of memory usage is very small as the cost of creating extra ```ByteBuffer``` isalmost same to byte array copy (used to construct ```String```). Using large key results in betterimprovement but I don't think large key is common case.**BEFORE**```Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   UnitsRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15  2035938.174 ± 1653.566   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15     2040.000 ±    0.001    B/op``````Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   UnitsRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15  1979193.376 ± 1239.286   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15     2120.000 ±    0.001    B/op```**AFTER**```Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   UnitsRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15  2289115.973 ± 2661.856   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15     2032.000 ±    0.001    B/op``````Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score     Error   UnitsRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15  2222625.706 ± 908.358   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15     2040.000 ±   0.001    B/op```Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Only include transactional id in LogContext if it's setAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3910 from ijuma/transactional-id-should-be-optional-in-log-context",2
"KAFKA-4366: KafkaStreams.close() blocks indefinitelyAdded `timeout` and `timeUnit` to `KafkaStreams.close(..)`. Now do close on a thread and `join` that thread with the provided `timeout`.Changed `state` in `KafkaStreams` to use an enum.Added system test to ensure we don't deadlock on close when an uncaught exception handler that calls `System.exit(..)` is used and there is also a shutdown hook that calls `KafkaStreams.close(...)`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2097 from dguy/kafka-4366",1
"KAFKA-4233: StateDirectory fails to create directory if any parent directory does not existChange the creation of the directories, in the StateDirectory constructor, to use mkdirs so any parents get created. Throw an exception if the directory doesn't exist and couldn't be createdAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Eno Thereska, Guozhang WangCloses #1942 from dguy/kafka-4233",1
"KAFKA-10679: Migrate upgrade changes from site to kafka/docs (#9551)During the AK website upgrade, changes made to kafka-site weren't migrated back to kafka-docs.This PR is an initial attempt at porting the changes to kafka/docs, but it does not include the streams changes. Those will come in a separate PR.For the most part, the bulk of the changes in the PR are cosmetic. Only the introduction.html has substantial changes, but it's a direct port from the live documentation.For testing:I reviewed the PR diffsRendered the changes locallyReviewers: Matthias J. Sax <mjsax@apache.org>",4
"MINOR: KTable.count() to only take a selector for keyAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen Shapira, Yashiru Matsuda, Michael NollCloses #872 from guozhangwang/KCount",2
MINOR: Upgrade zk to 3.5.6 (#7544)It includes an important fix for people running on k8s:* ZOOKEEPER-3320: Leader election port stop listen whenhostname unresolvable for some timeReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
KAFKA-6630: Speed up the processing of TopicDeletionStopReplicaResponseReceived events on the controller (#4668)Reviewed by Jun Rao <junrao@gmail.com>,4
"KAFKA-10029; Don't update completedReceives when channels are closed to avoid ConcurrentModificationException (#8705)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-8859: Refactor cache-level metrics (#7367)Cache-level metrics are refactor according to KIP-444:tag client-id changed to thread-idname hitRatio changed to hit-ratiomade backward compatible by using streams config built.in.metrics.versionReviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",5
MINOR: Mention leader in a few follower/controller log messages (#4835),2
KAFKA-7076; Skip rebuilding producer state when using old message format (#5254)This patch removes the need to build up producer state when the log is using V0 / V1 message format where we did not have idempotent and transactional producers yet.Also fixes a small issue where we incorrectly reported the offset index corrupt if the last offset in the index is equal to the base offset of the segment.,1
"MINOR: Import RaftConfig config definitions into KafkaConfig (#9916)This patch moves Raft config definitions from `RaftConfig` to `KafkaConfig`, where they are re-defined as internal configs until we are ready to expose them. It also adds the missing ""controller"" prefix that was added by KIP-631.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-4758; Connect missing checks for NO_TIMESTAMPAuthor: rnpridgeon <ryan.n.pridgeon@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>Closes #2533 from rnpridgeon/no_timestamp",5
"KAFKA-10542: Migrate KTable mapValues, passthrough, and source to new Processor API (#11099)As part of the migration of KStream/KTable operations to the new Processor API (KAFKA-8410), this PR includes the migration of KTable:* mapValues,* passthrough,* and source operations.Reviewers: John Roesler <vvcephei@apache.org>",4
"HOTFIX: Avoid mutable default arguments in system test servicesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1947 from hachikuji/hotfix-producer-perf-service",0
MINOR: ListPartitionReassignmentsResponse should not be entirely failed when a topic-partition does not exist  (#7486)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
KAFKA-548 remove partition from ProducerRequestPartitionData and FetchResponsePartitionData; patched by Yang Ye; reviewed by Neha and Joelgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397744 13f79535-47bb-0310-9956-ffa450edef68,5
KAFKA-727 broker can still expose uncommitted data to a consumer; reviewed by Neha Narkhede,5
KAFKA-7498: Remove references from `common.requests` to `clients` (#5784)Add CreatePartitionsRequest.PartitionDetails similar to CreateTopicsRequest.TopicDetails to avoid references from `common.requests` package to `clients`.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-9544; Fix flaky test `AdminClientTest.testDefaultApiTimeoutOverride` (#8101)There is a race condition with the backoff sleep in the test case and setting the next allowed send time in the AdminClient. To fix it, we allow the test case to do the backoff sleep multiple times if needed.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-13671: Add ppc64le build stage (#11833)Reviewers: David Arthur <mumrah@gmail.com>,1
"KAFKA-13172: Add downgrade guidance note for 3.0 (#11184)Reviewers: Luke Chen <showuon@gmail.com>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@confluent.io>",5
KAFKA-1580; Reject producer requests to internal topics; reviewed by Joel Koshy and Neha Narkhede,5
KAFKA-13549: Add repartition.purge.interval.ms (#11610)Implements KIP-811.Add a new config `repartition.purge.interval.ms` that limits how often data is purged from repartition topics.,5
KAFKA-1328 follow up: Updated javadoc,2
KAFKA-941 Add Apache 2.0 license to missing code source files,2
"KAFKA-8792; Default ZK configuration to disable AdminServerKafka ships with default ZK configuration. With the upgrade to ZK 3.5, our defaults include running ZK's AdminServer on port 8080. This is an unfortunate default as it tends to cause conflicts.I suggest we default to disable ZK's AdminServer in the default ZK configs that we ship. Users who want to use AdminServer can enable it and set the port to something that works for them. Realistically, in most production environments, a different ZK server will be used anyway. So this is mostly to save new users who are trying Kafka on their own machine from running into accidental and frustrating port conflicts.Author: Gwen Shapira <gwen@confluent.io>Reviewers: Ismael JumaCloses #7203 from gwenshap/zk_disable_adminserver",5
MINOR: Use string/log interpolation instead of string concat in core and clients (#5850)Also removed a few unused imports and tweaked the log message slightly.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-9535; Update metadata before retrying partitions when fetching offsets (#8088)Today if we attempt to list offsets with a fenced leader epoch, consumer will retry without updating the metadata until the timeout is reached. This affects synchronous APIs such as `offsetsForTimes`, `beginningOffsets`, and `endOffsets`. The fix in this patch is to trigger the metadata update call whenever we see a retriable error before additional attempts.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-4554; Fix ReplicaBuffer.verifyChecksum to use iterators instead of iterablesThis was changed in b58b6a1bef0 and caused the `ReplicaVerificationToolTest.test_replica_lags`system test to start failing.I also added a unit test and a couple of other minor clean-ups.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2280 from ijuma/kafka-4554-fix-replica-buffer-verify-checksum,0
"KAFKA-2430; Listing of PR commits in commit message should be optionalIf there is a single commit in the PR, then it's never listed.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #136 from ijuma/kafka-2430-optional-listing-commits and squashes the following commits:64f1aec [Ismael Juma] Listing of PR commits in commit message should be optional",5
"KAFKA-2573: Mirror maker system test hangs and eventually failsAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Geoff Anderson, Guozhang WangCloses #234 from SinghAsDev/KAFKA-2573",0
MINOR: Update `config/producer.properties` to have new producer propertiesAlso include some trivial clean-ups in `ProducerConfig`and `BaseProducer`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #710 from ijuma/use-new-producer-properties-in-config,5
KAFKA-14035; Fix NPE in `SnapshottableHashTable::mergeFrom()` (#12371)The NPE causes the kraft controller to be in an inconsistent state. Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-6928: Refactor StreamsPartitionAssignor retry logic (#6085)1. The retry loop of the InternalTopicManager would just be: a) describe topics, and exclude those which already exist with the right num.partitions, b) for the remaining topics, try to create them. Remove any inner loops.2. In CreateTopicResponse and MetadataResponse (for describe topic), handle the special error code of TopicExist and UnknownTopicOrPartition in order to retry in the next loop.3. Do not handle TimeoutException since it should already been handled inside AdminClient.Add corresponding unit tests for a) topic marked for deletion but not complete yet, in which case metadata response would not contain this topic, but create topic would return error TopicExists; b) request keep getting timed out.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-2136; Add throttle time (on quota violation) in fetch/produceresponses; reviewed by Joel Koshy, Dong Lin and Jun Rao",1
"KAFKA-9701 (fix): Only check protocol name when generation is valid (#8324)This bug was incurred by #7994 with a too-strong consistency check. It is because a reset generation operation could be called in between the joinGroupRequest -> joinGroupResponse -> SyncGroupRequest -> SyncGroupResponse sequence of events, if user calls unsubscribe in the middle of consumer#poll().Proper fix is to avoid the protocol name check when the generation is invalid.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-8391; Temporarily ignore flaky Connect rebalance integration testsI've spent quite a bit of time on trying to discover the root cause, with no luck so far. I have been able to reproduce it locally by running the following 100 times:```./gradlew connect:runtime:clean connect:runtime:test --tests org.apache.kafka.connect.integration.RebalanceSourceConnectorsIntegrationTest```The `testReconfigConnector` test failed 28% of the time and the others failed 0%. This issue and KAFKA-8661 suggest that `testDeleteConnector` and `testStartTwoConnectors` are also flaky, though I've not seen those tests fail locally.Because this flakiness is causing issues for the rest of the project, I'm going to temporarily ignore several of the flaky ITs while I continue to investigate:* `RebalanceSourceConnectorsIntegrationTest.testReconfigConnector`* `RebalanceSourceConnectorsIntegrationTest.testDeleteConnector`* `RebalanceSourceConnectorsIntegrationTest.testStartTwoConnectors`**This should be backported to the `2.3` branch, which is when these integration tests were first added.**Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ismael JumaCloses #7237 from rhauch/kafka-8391-temporary",1
"KAFKA-4687; Fix InvalidTopicException due to topic creation race conditionWe now throw the correct TopicExistsException instead.Author: Andrew Olson <aolson1@cerner.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2425 from noslowerdna/KAFKA-4687",5
MINOR: update docs with regard to KIP-123Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3232 from mjsax/minor-update-docs-for-kip-123,5
"KAFKA-5490; Cleaner should retain empty batch if needed to preserve producer last sequenceAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #3406 from hachikuji/KAFKA-5490",5
MINOR: doc fix related to monitoring consumer lagAuthor: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1814 from alexlod/consumer-lag-doc-fix,2
MINOR: Fixes for streams system tests (#4935)This PR fixes some regressions introduced into streams system tests and sets the upgrade tests to ignore until PR #4636 is merged as it has the fixes for the upgrade tests.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
Update System Test due to new argument --sync in ProducerPerformance; patched by Jun Rao; reviewed by Neha Narkhede and Jun Rao; kafka-594git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1404197 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-5609: Connect log4j should also log to a file by default (KIP-521) (#7430)Implemented KIP-521 to change the provided Connect Log4J configuration file to also write logs to files and to rotate them daily.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-5226; Fixes issue where adding topics matching a regexsubscribed stream may not be detected by all followers untilonJoinComplete returns.Author: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3157 from bbejeck/KAFKA-5226_null_pointer_source_node_deserialize",5
"MINOR: remove unused fields from KTableImplRemove `keySerde`, `valSerde`, `OUTERTHIS_NAME`, `OUTEROTHER_NAME`, `LEFTTHIS_NAME`, `LEFTOTHER_NAME` from `KTableImpl` as they are all unused fieldsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2119 from dguy/minor-ktable-unused",1
"MINOR: Shutdown RockDB metrics recording trigger thread (#7417)added shutdown for thread that triggers recording of RocksDBMetricsadded unit tests to verify the start and shutdown of the threadrefactored a bit of codeReviewers: Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
MINOR: Fix exception handling in case of file record truncation during writeIn case of file record truncation during write due to improper types usage(`AtomicInteger` in place of `int`) `IllegalFormatConversionException` wouldbe thrown instead of `KafkaException`Author: Kamil Szymanski <kamil.szymanski.dev@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2275 from kamilszymanski/file_record_truncation_during_write,2
"KAFKA-2733: Standardize metric name for Kafka StreamsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda, Jun RaoCloses #643 from guozhangwang/K2733",5
"KAKFA-3599: Move WindowStoreUtils to package ""internals""Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Michael G. Noll, Guozhang WangCloses #1266 from mjsax/kafka-3599-minorCodeCleanup",4
kafka-1205; README in examples not update; patched by Ailing Zhang; reviewed by Jun Rao,5
"KAFKA-7741: Streams exclude javax dependency (#6121)As documented in https://issues.apache.org/jira/browse/KAFKA-7741,the javax dependency we receive transitively from connect is incompatiblewith SBT builds.Streams doesn't use the portion of Connect that needs the dependency,so we can fix the builds by simply excluding it.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
kafka-console-producer does not take in customized values of --batch-size or --timeout; patched by Jun Rao; reviewed by Edward Smith; KAFKA-279git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1303232 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Extends RocksDB docs (#10046)We recommend users to switch to jemalloc for RocksDB.Co-authored-by: Jim Galasyn <jim.galasyn@confluent.io>Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Rohan Desai <rohan@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
MINOR: Bump version to 2.0.0-SNAPSHOT (#4804),5
trival fix to make hash code positive; patched by Joel Koshy; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1177516 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Logging/debugging improvements for transactionsAuthor: Jason Gustafson <jason@confluent.io>Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3185 from hachikuji/minor-transaction-logging-improvements",2
"KAFKA-5362: Add EOS system tests for Streams APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3201 from mjsax/kafka-5362-add-eos-system-tests-for-streams-api",5
MINOR: Make Histogram#clear more readable (#9679)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
KAFKA-13494: WindowKeyQuery and WindowRangeQuery (#11567)Implement WindowKeyQuery and WindowRangeQuery asproposed in KIP-806Reviewer: John Roesler <vvcephei@apache.org>,2
"KAFKA-6054: Add 'version probing' to Kafka Streams rebalance (#4636)implements KIP-268Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8231: Expansion of ConnectClusterState interface (#6584)Expand ConnectClusterState interface and implementation with methods that provide the immutable cluster details and the connector configuration. This includes unit tests for the new methods.Author: Chris Egerton <cegerton@oberlin.edu>Reviews: Arjun Satish <arjun@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-3629; KStreamImpl.to(...) throws NPE when the value SerDe is nullguozhangwangAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #1272 from dguy/kstreamimpl-to-npe and squashes the following commits:49d48fb [Damian Guy] actually commit the fix07ce589 [Damian Guy] fix npe in KStreamImpl.to(..)74d396d [Damian Guy] fix npe in KStreamImpl.to(..)",0
"MINOR: fix client_compatibility_features_test.py (#10292)Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",5
"MINOR: fix EOS test race conditionAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4048 from mjsax/fix-eos-test-race-condition",3
KAFKA-10798; Ensure response is delayed for failed SASL authentication with connection close delay (#9678)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"MINOR: Remove redundant fields in dump log record output (#11101)In 2.8, the dump log output regressed to print batch level information for each record, which makes the output much noisier. This patch changes the output to what it was in 2.7 and previous versions. We only print batch metadata at the batch level.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Fix misspelling in protocol documentationReviewers: Colin P. McCabe <cmccabe@apache.org>,2
"MINOR: A few cleanups in KafkaApis and TransactionMarkerChannelManagerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3171 from hachikuji/minor-txn-channel-cleanups",4
"KAFKA-7678: Avoid NPE when closing the RecordCollector (#5993)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
DOCS-3625: Add section to config topic: parameters controlled by Kafka Streams (#8268)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-10077: Filter downstream of state-store results in spurious tombstones (#9156)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-6145: Add unit tests to verify fix of bug KAFKA-9173 (#8689)Ensure that the assignor will always assign tasks to new instances.Reviewers: John Roesler <vvcephei@apache.org>,1
"MINOR: Add missing apiversion test for 3.0 (#10748)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: add test for StreamsSmokeTestDriver (#6231)* MINOR: add test for StreamsSmokeTestDriverHi @bbejeck @mjsax @ableegoldman @guozhangwang ,Please take a look at this when you get the chance.The primary concern is adding the test. It will help us verify changes to the smoke test (such as adding suppression).I've also added some extra output to the smoke test stdout, which will hopefully aid us in diagnosing the flaky tests.Finally, I bundled in some cleanup. It was my intention to do that in a separate PR, but it wound up getting smashed together during refactoring.Please let me know if you'd prefer for me to pull any of these out into a separate request.Thanks,-JohnAlso, add more output for debuggability* cleanup* cleanup* refactor* refactor* remove redundant printlns* Update EmbeddedKafkaCluster.java* move to integration package* replace early-exit on pass* use classrule for embedded kafka* pull in smoke test improvements from side branch* try-with-resources* format events instead of printing long lines* minor formatting fixReviewers:  Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",0
"KAFKA-6534: Enforce a rebalance in the next poll call when encounter task migration (#4544)The fix is in two folds:For tasks that's closed in closeZombieTask, their corresponding partitions are still in runningByPartition so those closed tasks may still be returned in activeTasks and standbyTasks. Adding guards on the returned tasks and if they are closed notify the thread to trigger rebalance immediately.When triggering a rebalance, un-subscribe and re-subscribe immediately to make sure we are not dependent on the background heartbeat thread timing.Some minor changes on log4j. More specifically, I moved the log entry of closeZombieTask to its callers with more context information and the action going to take.I can re-produce the issue with EosIntegrationTest may hand-code the heartbeat thread to GC, and confirmed this patch fixed the issue. Unfortunately this test cannot be added to AK since currently we do not have ways to manipulate the heartbeat thread in unit tests.Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-5749; Add MeteredSessionStore and ChangeloggingSessionBytesStore.Make MeteredSessionStore the outermost store.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3729 from dguy/kafka-5749,4
"MINOR: MetadataResponse#toStruct should serialize null leaders correctly. (#4449)In MetadataResponse deserialization, if the partition leader key is setto -1, the leader is set to null.  The MetadataResponse#toStruct codeshould handle this correctly as well.Also fix a case in KafkaApis where we were not taking into account thepossibility of the leader being null.RequestResponseTest should test this as well.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10240: Suppress WakeupExceptions during sink task shutdown (#9003)A benign `WakeupException` can be thrown by a sink task's consumer if the task is scheduled for shutdown by the worker. This is caught and handled gracefully if the exception is thrown when calling `poll` on the consumer, but not if calling `commitSync`, which is invoked by a task during shutdown and also when its partition assignment is updated.If thrown during a partition assignment update, the `WakeupException` is caught and handled gracefully as part of the task's `iteration` loop. If thrown during shutdown, however, it is not caught and instead leads to the misleading log message ""Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted."".These changes catch the `WakeupException` during shutdown and handle it gracefully with a `TRACE`-level log message.A unit test is added to verify this behavior by simulating a thrown `WakeupException` during `Consumer::commitSync`, running through the `WorkerSinkTask::execute` method, and confirming that it does not throw a `WakeupException` itself.Reviewers: Greg Harris <gregh@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"KIP-28: Add a processor client for Kafka StreamingThis work has been contributed by Jesse Anderson, Randall Hauch, Yasuhiro Matsuda and Guozhang Wang. The detailed design can be found in https://cwiki.apache.org/confluence/display/KAFKA/KIP-28+-+Add+a+processor+client.Author: Guozhang Wang <wangguoz@gmail.com>Author: Yasuhiro Matsuda <yasuhiro.matsuda@gmail.com>Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Author: ymatsuda <yasuhiro.matsuda@gmail.com>Author: Randall Hauch <rhauch@gmail.com>Author: Jesse Anderson <jesse@smokinghand.com>Author: Ismael Juma <ismael@juma.me.uk>Author: Jesse Anderson <eljefe6a@gmail.com>Reviewers: Ismael Juma, Randall Hauch, Edward Ribeiro, Gwen Shapira, Jun Rao, Jay Kreps, Yasuhiro Matsuda, Guozhang WangCloses #130 from guozhangwang/streaming",5
"KAFKA-1483 Split Brain about Leader Partitions; reviewed by Guozhang, Jun and Neha",5
"KAFKA-6308; Connect Struct should use deepEquals/deepHashCodeThis changes the Struct's equals and hashCode method to use Arrays#deepEquals and Arrays#deepHashCode, respectively. This resolves a problem where two structs with values of type byte[] would not be considered equal even though the byte arrays' contents are equal. By using deepEquals, the byte arrays' contents are compared instead of ther identity.Since this changes the behavior of the equals method for byte array values, the behavior of hashCode must change alongside it to ensure the methods still fulfill the general contract of ""equal objects must have equal hashCodes"".Test rationale:All existing unit tests for equals were untouched and continue to work. A new test method was added to verify the behavior of equals and hashCode for Struct instances that contain a byte array value. I verify the reflixivity and transitivity of equals as well as the fact that equal Structs have equal hashCodesand not-equal structs do not have equal hashCodes.Author: Tobias Gies <tobias.gies@trivago.com>Author: Tobias Gies <tobias@tobiasgies.de>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #4293 from tobiasgies/feature/kafka-6308-deepequals",5
KAFKA-1597 New metrics: ResponseQueueSize and BeingSentResponses; reviewed by Neha Narkhede and Jun Rao,1
"MINOR: Tidy up pattern type comparisons, remove unused producer-id (#5593)Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
KAFKA-13444: Fix OAuthCompatibilityTool help and add SSL options (#11486)Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-9447: Add new customized EOS model example (#8031)With the improvement of 447, we are now offering developers a better experience on writing their customized EOS apps with group subscription, instead of manual assignments. With the demo, user should be able to get started more quickly on writing their own EOS app, and understand the processing logic much better.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"HOTFIX: Fix broken links (#5676)Reviewers: Joel Hamill <11722533+joel-hamill@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-162 Upgrade the python client to use the new message format.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1186535 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13630: Reduce amount of time that producer network thread holds batch queue lock (#11722)Hold the `deque` lock for only as long as is required to collect and make a decision in`ready()` and `drain()` loops. Once this is done, remaining work can be done without lock,so release it. This allows producers to continue appending.For an application with with a single producer thread and a high send() rate, this changereduces spinlock CPU cycles from 14.6% to 2.5% of the send() path, or moreclearly a 12.1% improvement in efficiency for the send() path by reducing the duration ofcontention events with the network thread. Note that this application was executed withJava 8, which has a slower crc32c implementation.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Artem Livshits <84364232+artemlivshits@users.noreply.github.com>",1
"KAFKA-10723: Fix LogManager shutdown error handling (#9596)The asynchronous shutdown in LogManager has the shortcoming that if during shutdown any of the internal futures fail, then we do not always ensure that all futures are completed before LogManager.shutdown returns. This is because, this line in the finally clause shuts down the thread pools asynchronously. As a result, despite the shut down completed message from KafkaServer is seen in the error logs, some futures continue to run from inside LogManager attempting to close some logs. This is misleading during debugging. Also sometimes it introduces an avoidable post-shutdown activity where resources (such as file handles) are released or persistent state is checkpointed in the Broker.In this PR, we fix the above behavior such that we prevent leakage of threads. If any of the futures throw an error, we skip creating of checkpoint and clean shutdown file only for the affected log directory. We continue to wait for all futures to complete for all the directories.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2
"MINOR: changes embedded broker time to MockTimeAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Ismael Juma, Guozhang WangCloses #1808 from mjsax/mockTime",5
"KAFKA-3357; Update to Scala 2.11.8Scala 2.11.8 has been released with a number of bug fixes:* http://www.scala-lang.org/news/2.11.8/There are a few important collection fixes:* https://issues.scala-lang.org/browse/SI-9497* https://github.com/scala/scala/pull/4714* https://github.com/scala/scala/pull/4693And also some pattern matcher fixes.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Ashish SinghCloses #1032 from ijuma/kafka-3357-update-to-scala-2.11.8",5
MINOR: set initial capacity of ArrayList for all json converters (#9962)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-2551; Update Unclean leader election docsAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <mail@harsha.io>Closes #1054 from omkreddy/KAFKA-2551",2
"MINOR: Auth operations must be null when talking to a pre-KIP-430 broker (#6812)Authorized operations must be null when talking to a pre-KIP-430 broker.If we present this as the empty set instead, it is impossible for clientsto know if they have no permissions, or are talking to an old broker.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"MINOR: Remove deprecated parameter in ProcessorContext#register (#4911)Updated the upgrade doc as well since we do not have an overloaded function without the deprecated parameter before. Also renamed the 1.2 release version to 2.0.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Handle some null cases in BrokerMetadataPublisher (#11029)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",5
KAFKA-3786: Let ConfigDef filter property key value pairsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1465 from guozhangwang/K3786-config-parsing,5
"KAFKA-4509: Task reusage on rebalance fails for threads on same hostAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2233 from mjsax/kafka-4509-task-reusage-fix",0
trival fix to kafka-563: KafkaScheduler shutdown in ZookeeperConsumerConnector should check for config.autocommitgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396678 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR: Fix hard coded strings in ProduceResponseAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma, Ewen Cheslack-Postava and Guozhang WangCloses #131 from granthenke/minor-string and squashes the following commits:3c6250d [Grant Henke] MINOR: Fix hard coded strings in ProduceResponse",0
MINOR: Update Scala 2.11 to 2.11.12The main change is Java 9 support.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4185 from ijuma/scala-2.11.12,5
"KAFKA-4292: Configurable SASL callback handlers (KIP-86) (#2022)Implementation of KIP-86. Client, server and login callback handlers have been made configurable for both brokers and clients.Reviewers: Jun Rao <junrao@gmail.com>, Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
"KAFKA-7027: Add an overload build method in scala (#6373)The Java API can pass a Properties object to StreamsBuilder#build, to allow, e.g., topology optimization, while the Scala API does not yet. The latter only delegates the work to the underlying Java implementation.Reviewers: John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
MINOR: Fix system test broken by change of consumer group tool output format… formatAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1039 from gwenshap/minor-consumer-groups,5
KAFKA-274 Handle corrupted messages cleanly; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1245299 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7976; Update config before notifying controller of unclean leader update (#6426)When unclean leader election is enabled dynamically on brokers, we notify controller of the update before updating KafkaConfig. When processing this event, controller's decision to elect unclean leaders is based on the current KafkaConfig, so there is a small timing window when the controller may not elect unclean leader because KafkaConfig of the server was not yet updated. The commit fixes this timing window by using the existing BrokerReconfigurable interface used by other classes which rely on the current value of KafkaConfig.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
KAFKA-10089 The stale ssl engine factory is not closed after reconfigure (#8792)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-12552: Introduce LogSegments class abstracting the segments map (#10401)This PR is a precursor to the recovery logic refactor work (KAFKA-12553).In this PR, I've extracted the behavior surrounding segments map access within kafka.log.Log class into a new class: kafka.log.LogSegments. This class encapsulates a thread-safe navigable map of kafka.log.LogSegment instances and provides the required read and write behavior on the map. The Log class now encapsulates an instance of the LogSegments class.Couple advantages of this PR:Makes the Log class a bit more modular as it moves out certain private behavior thats otherwise within the Log class.This is a precursor to refactoring the recovery logic (KAFKA-12553). In the future, the logic for recovery and loading of segments from disk (during Log) init will reside outside the Log class. Such logic would need to instantiate and access an instance of the newly added LogSegments class.Tests:Added a new test suite: kafka.log.LogSegmentsTest covering the APIs of the newly introduced class.Reviewers: Satish Duggana <satishd@apache.org>, Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-4253: Fix Kafka Stream thread shutting down process orderingChanged the ordering in `StreamThread.shutdown`1. commitAll (we need to commit so that any cached data is flushed through the topology)2. close all tasks3. producer.flush() - so any records produced during close are flushed and we have offsets for them4. close all state managers5. close producers/consumers6. remove the tasksAlso in `onPartitionsRevoked`1. commitAll2. close all tasks3. producer.flush4. close all state managersAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1970 from dguy/kafka-4253",4
kafka-1412; transient unit test failure in ProducerSendTest.testAutoCreateTopic; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,3
MINOR: Move common consumer tests out of abstract consumer class (#6548)ConsumerBounceTest redundantly executes a couple test cases which were included in the abstract class `BaseConsumerTest`. We should try to keep a cleaner separation of testing logic and utility logic so that this does not happen (the build time is long enough without doing unnecessary work). This PR moves the cluster initialization and consumer utilities out of BaseConsumerTest and into a new class AbstractConsumerTest. We then let ConsumerBounceTest extend AbstractConsumerTest.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-6884; Consumer group command should use new admin client (#5032)Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-10803: Fix improper removal of bad dynamic config (#9682)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-9802; Increase transaction timeout in system tests to reduce flakiness (#8736)We have been seeing increased flakiness in transaction system tests. I believe the cause might be due to KIP-537, which increased the default zk session timeout from 6s to 18s and the default replica lag timeout from 10s to 30s. In the system test, we use the default transaction timeout of 10s. However, since the system test involves hard failures, the Produce request could be blocking for as long as the max of these two in order to wait for an ISR shrink. Hence this patch increases the timeout to 30s.Note this patch also includes a minor logging fix in `Partition`. Previously we would see messages like the following:```[Broker id=3] Leader output-topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR 3,2,1 addingReplicas  removingReplicas .Previous leader epoch was -1.```This patch fixes the log to print as the following:```[Broker id=3] Leader output-topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [3,2,1] addingReplicas []  removingReplicas []. Previous leader epoch was -1.```Reviewers: Bob Barrett <bob.barrett@confluent.io>, Ismael Juma <github@juma.me.uk>",5
KAFKA-6554; Missing lastOffsetDelta validation before log append (#4585)Add validation checks that the offset range is valid and aligned with the batch count prior to appending to the log. Several unit tests have been added to verify the various invalid cases.,1
"KAFKA-9384: Loop improvements (#7907)Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
disable dup topic in consumer request; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-240git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1244650 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: change modifier of ConsumerRecords(FetchedRecords) from public to package-private (#10036)Reviewers: Ismael Juma <mlists@juma.me.uk>,4
"KAFKA-3179; Fix seek on compressed messagesThe fix itself is simple.Some explanation on unit tests. Currently we the vast majority of unit test is running with uncompressed messages.  I was initially thinking about run all the tests using compressed messages. But it seems uncompressed messages are necessary in a many test cases because we need the bytes sent and appended to the log to be predictable. In most of other cases, it does not matter whether the message is compressed or not, and compression will slow down the unit test. So I just added one method in the BaseConsumerTest to send compressed messages whenever we need it.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>Closes #842 from becketqin/KAFKA-3179",2
"KAFKA-7012: Don't process SSL channels without data to process (#5237)Avoid unnecessary processing of SSL channels when there are some bytes buffered, but not enough to make progress.Reviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>, Jun Rao <junrao@gmail.com>",1
"MINOR: Refactor CheckpointFile to improve testability (#7391)Refactors CheckpointFile such that buffers can be read in lieu of files. Thisis a relatively simple refactoring as we already create a buffered reader overthe checkpoint file.#6742, which improves the performance of the checkpointing code, requiresa similar refactoring of code, although it does go further than this.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",4
KAFKA-10799 AlterIsr utilizes ReplicaManager ISR metrics (#9677)Add small interface to Partition.scala that allows AlterIsr and ZK code paths to update the ISR metrics managed by ReplicaManager. This opens the door for consolidating even more code between the two ISR update code paths.,5
"KAFKA-4504; Clarify that retention.bytes is a partition level configAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3814 from omkreddy/KAFKA-4504",5
"KAFKA-3209: KIP-66: single message transformsBesides API and runtime changes, this PR also includes 2 data transformations (`InsertField`, `HoistToStruct`) and 1 routing transformation (`TimestampRouter`).There is some gnarliness in `ConnectorConfig` / `ConfigDef` around creating, parsing and validating a dynamic `ConfigDef`.Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2299 from shikhar/smt-2017",5
minor fix for KAFKA-1152; ReplicaManager's handling of the leaderAndIsrRequest should gracefully handle leader == -1; patched by Swapnil Ghike; reviewed by Jun Rao,0
"KAFKA-14108: Ensure both JUnit 4 and JUnit 5 tests run (#12441)When the migration of the Streams project to JUnit 5 started with PR #12285, we discovered that the migrated tests were not run by the PR builds. This PR ensures that Streams' tests that are written in JUnit 4 and JUnit 5 are run in the PR builds.Co-authored-by: Divij Vaidya <diviv@amazon.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-6046; DeleteRecordsRequest to a follower should return NOT_LEADERTested with DeleteRecordsRequestTest by Tom Bentley, which is part ofa separate pull request.Author: tedyu <yuzhihong@gmail.com>Reviewers: Tom Bentley <tbentley@redhat.com>, Ismael Juma <ismael@juma.me.uk>Closes #4052 from tedyu/trunk",1
MINOR: Use bootstrap-server instead of broker-list in doc (#10832)* MINOR: Use bootstrap-server instead of broker-list in docReviewers: Luke Chen <showuon@gmail.com>,2
"KAFKA-10011: Remove task id from lockedTaskDirectories during handleLostAll (#8682)As stated, we couldn't wait for handleRebalanceComplete in the case of handleLostAll, as we already closed the active task as dirty, and could potentially require its offset in the next thread.runOnce call.Co-authored-by: Guozhang Wang <wangguoz@gmail.com>Reviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: Set `sendTime` in `doSend` instead of `InFlightRequests.add` and rename method names for consistencyhachikuji MayureshGharat jjkoshy Thoughts?Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Mayuresh Gharat <gharatmayuresh15@gmail.com>, Jason Gustafson <jason@confluent.io>, Joel Koshy <jjkoshy.w@gmail.com>Closes #264 from ijuma/tweak-send-ms",5
MINOR: fix the wrong/missing anchor in docs caused link error (#10413)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-13394: Topic IDs should be removed from PartitionFetchState if they are no longer sent by the controller (#11459)With KAFKA-13102, we added topic IDs to the InitialFetchState and the PartitionFetchState in order to send fetch requests using topic IDs when IBP is 3.1. However, there are some cases where we could initially send topic IDs from the controller and then no longer to do so (controller changes to an IBP < 2.8). If we do not remove from the PartitionFetchState and one broker is still IBP 3.1, it will try to send a version 13 fetch request to brokers that no longer have topic IDs in the metadata cache. This could leave the cluster in a state unable to fetch from these partitions.This patch removes the topic IDs from the PartitionFetchState if the log contains a topic ID but the request does not. This means that we will always handle a leader and isr request if there is no ID in the request but an ID in the log. Such a state should be transient because we are either * upgrading the cluster and somehow switched between a new IBP controller and an old one --> and will eventually have all new IBP controllers/brokers.* downgrading the cluster --> will eventually have all old IBP controllers/brokers and will restart the broker/delete the partition metadata file for them.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-642 Addressing Jun's follow up comments--(1) add parans to make statement more clear, (2) remove the initial offset from the fetch response since the message set itself now contains all offsets.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1417977 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-10470: Zstd upgrade and buffering (#9499)Zstd-jni 1.4.5-6 allocates large internal buffers inside of ZstdInputStream and ZstdOutputStream. This caused a lot of allocation and GC activity when creating and closing the streams. It also does not buffer the reads or writes. This causes inefficiency when DefaultRecord.writeTo() does a series of small single bytes reads using various ByteUtils methods. The JNI is more efficient if the writes of uncompressed data were flushed in large pieces rather than for each byte. This is due to the the expense of context switching between the Java code and the native code. This is also the case when reading as well. Per luben/zstd-jni#141 the maintainer of zstd-jni and I agreed to not buffer reads and writes in favor of having the caller do that, so here we are updating the caller.In this patch, I upgraded to the most recent zstd-jni version with the buffer reuse built-in. This was done in luben/zstd-jni#143 and luben/zstd-jni#146 Since we decided not to add additional buffering of input/output with zstd-jni, I added the BufferedInputStream and BufferedOutputStream to CompressionType.ZSTD just like we currently do for CompressionType.GZIP which also is inefficient for single byte reads and writes. I used the same buffer sizes as that existing implementation.NOTE: if so desired we could pass a wrapped BufferSupplier into the Zstd*Stream classes to have Kafka decide how the buffer recycling occurs. This functionality was added in the latter PR linked above. I am holding off on this since based on jmh benchmarking the performance gains were not clear and personally I don't know if it worth the complexity of trying to hack around the reflection at this point in time. The zstd-jni uses a very similar default recycler as snappy does currently which seems to provide decent efficiency. While this PR fixes the defect, I feel that using BufferSupplier in both zstd-jni and snappy is outside of the scope of this bugfix and should be considered a separate improvement. I would prefer this change get merged in on its own since the performance gains here are very significant relative to the more incremental and minor optimizations which could be achieved by doing that separate work.There are some noticeable improvements in the JMH benchmarks (excerpt):BEFORE:Benchmark                                                                                                                    (bufferSupplierStr)  (bytes)  (compressionType)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt       Score     Error   UnitsCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed                                                CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   27743.260 ± 673.869   ops/sCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.alloc.rate                                 CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    3399.966 ±  82.608  MB/secCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.alloc.rate.norm                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  134968.010 ±   0.012    B/opCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Eden_Space                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    3850.985 ±  84.476  MB/secCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Eden_Space.norm                   CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  152881.128 ± 942.189    B/opCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Survivor_Space                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     174.241 ±   3.486  MB/secCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Survivor_Space.norm               CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    6917.758 ±  82.522    B/opCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.count                                      CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    1689.000            countsCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.time                                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   82621.000                msJMH benchmarks doneBenchmark                                                                                                    (bufferSupplierStr)  (bytes)  (compressionType)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt       Score       Error   UnitsRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage                                                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   24095.711 ±   895.866   ops/sRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.alloc.rate                                     CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2932.289 ±   109.465  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.alloc.rate.norm                                CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  134032.012 ±     0.013    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Eden_Space                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    3282.912 ±   115.042  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Eden_Space.norm                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  150073.914 ±  1342.235    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Survivor_Space                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     149.697 ±     5.786  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Survivor_Space.norm                   CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    6842.462 ±    64.515    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.count                                          CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    1449.000              countsRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.time                                           CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   82518.000                  msRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize                                                     CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    1449.060 ±   230.498   ops/sRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.alloc.rate                                      CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     198.051 ±    31.532  MB/secRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.alloc.rate.norm                                 CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  150502.519 ±     0.186    B/opRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space                             CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     200.064 ±    31.879  MB/secRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space.norm                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  152569.341 ± 13826.686    B/opRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.count                                           CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15      91.000              countsRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.time                                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   75869.000                  msRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize                                                CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2609.660 ±  1145.160   ops/sRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.alloc.rate                                 CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     815.441 ±   357.818  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.alloc.rate.norm                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  344309.097 ±     0.238    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     808.952 ±   354.975  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space.norm                   CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  345712.061 ± 51434.034    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Old_Gen                           CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.019 ±     0.042  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Old_Gen.norm                      CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15      18.615 ±    42.045    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Survivor_Space                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15      24.132 ±    12.254  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Survivor_Space.norm               CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   13540.960 ± 14649.192    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.count                                      CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     148.000              countsRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.time                                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   23848.000                  msJMH benchmarks doneAFTERBenchmark                                                                                                                (bufferSupplierStr)  (bytes)  (compressionType)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt       Score      Error   UnitsCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed                                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  147792.454 ± 2721.318   ops/sCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.alloc.rate                             CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2708.481 ±   50.012  MB/secCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.alloc.rate.norm                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   20184.002 ±    0.002    B/opCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Eden_Space                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2732.667 ±   59.258  MB/secCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Eden_Space.norm               CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   20363.460 ±  120.585    B/opCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Old_Gen                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.042 ±    0.033  MB/secCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.churn.G1_Old_Gen.norm                  CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.316 ±    0.249    B/opCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.count                                  CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     833.000             countsCompressedRecordBatchValidationBenchmark.measureValidateMessagesAndAssignOffsetsCompressed:·gc.time                                   CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    8390.000                 msJMH benchmarks doneBenchmark                                                                                                (bufferSupplierStr)  (bytes)  (compressionType)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt       Score      Error   UnitsRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage                                                CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  166786.092 ± 3285.702   ops/sRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.alloc.rate                                 CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2926.914 ±   57.464  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.alloc.rate.norm                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   19328.002 ±    0.002    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Eden_Space                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2938.541 ±   66.850  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Eden_Space.norm                   CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   19404.357 ±  177.485    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Old_Gen                           CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.516 ±    0.100  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Old_Gen.norm                      CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       3.409 ±    0.657    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Survivor_Space                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.032 ±    0.131  MB/secRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.churn.G1_Survivor_Space.norm               CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.207 ±    0.858    B/opRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.count                                      CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     834.000             countsRecordBatchIterationBenchmark.measureIteratorForBatchWithSingleMessage:·gc.time                                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    9370.000                 msRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize                                                 CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   15988.116 ±  137.427   ops/sRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.alloc.rate                                  CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     448.636 ±    3.851  MB/secRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.alloc.rate.norm                             CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   30907.698 ±    0.020    B/opRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space                         CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     450.905 ±    5.587  MB/secRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space.norm                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   31064.113 ±  291.190    B/opRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.churn.G1_Old_Gen                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.043 ±    0.007  MB/secRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.churn.G1_Old_Gen.norm                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       2.931 ±    0.493    B/opRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.count                                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     790.000             countsRecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize:·gc.time                                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     999.000                 msRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize                                            CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15   11345.169 ±  206.528   ops/sRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.alloc.rate                             CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2314.800 ±   42.094  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.alloc.rate.norm                        CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  224714.266 ±    0.028    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space                    CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    2320.213 ±   45.521  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Eden_Space.norm               CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15  225235.965 ±  803.309    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Old_Gen                       CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       0.026 ±    0.005  MB/secRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.churn.G1_Old_Gen.norm                  CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15       2.551 ±    0.455    B/opRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.count                                  CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15     994.000             countsRecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize:·gc.time                                   CREATE   RANDOM               ZSTD             200           1000                 2  thrpt   15    1189.000                 msJMH benchmarks doneReviewers: Ismael Juma <ismael@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-8386; Use COORDINATOR_NOT_AVAILABLE error when group is Dead (#6762)The Dead state in the coordinator is used for groups which are either pending deletion or migration to a new coordinator. Currently requests received while in this state result in an UNKNOWN_MEMBER_ID which causes consumers to reset the memberId. This is a problem for KIP-345 since it can cause an older member to fence a newer member. This patch changes the error code returned in this state to COORDINATOR_NOT_AVAILABLE, which causes the consumer to rediscover the coordinator, but not reset the memberId.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8454; Add Java AdminClient Interface (KIP-476) (#7087)Adds an `Admin` interface as specified in [KIP-476](https://cwiki.apache.org/confluence/display/KAFKA/KIP-476%3A+Add+Java+AdminClient+Interface).Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: cleanup policy doc update (#6692)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-10720: Document prohibition on header mutation by SMTs (#9597)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",2
KAFKA-12284: Wait for mirrored topics to be created (#10185)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"KAFKA-8859: Expose built-in streams metrics version in `StreamsMetricsImpl` (#7323)The streams config built.in.metrics.version is needed to add metrics ina backward-compatible way. However, not in every location where metrics areadded a streams config is available to check built.in.metrics.version. Thus,the config value needs to be exposed through the StreamsMetricsImpl object.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-4361: Streams does not respect user configs for ""default"" paramsEnable user provided consumer and producer configs to override the streams default configs.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2084 from dguy/kafka-4361",5
KAFKA-2881: Improve Consumer Configs and API DocumentationAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen ShapiraCloses #584 from guozhangwang/K2881,2
KAFKA-506 Hadoop consumer not advancing to next offset. No review.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397388 13f79535-47bb-0310-9956-ffa450edef68,1
Separate Streams documentation and setup docs with easy to set variables- Seperate Streams documentation out to a standalone page.- Setup templates to use handlebars.js- Create template variables to swap in frequently updated values like version number from a single file templateData.jsAuthor: Derrick Or <derrickor@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2245 from derrickdoo/docTemplates,2
"KAFKA-13211: add support for infinite range query for WindowStore (#11227)Add support for infinite range query for WindowStore. Story JIRA: https://issues.apache.org/jira/browse/KAFKA-13210Reviewers: Patrick Stuedi <pstuedi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",0
MINOR: Improve KafkaProducer Javadocs (#12537)While reviewing KIP-588 and KIP-691 I went through the exception throwing behavior and wanted to improve the related javadocs a little bit.Reviewers: John Roesler <vvcephei@apache.org>,2
MINOR: Fix an example in the Kafka Streams tutorial to be compilable (#6647)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,0
"MINOR: replace Thread.isAlive by Thread.is_alive for Python code (#11545)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-8487: Only request re-join on REBALANCE_IN_PROGRESS in CommitOffsetResponse (#6894)Plus some minor cleanups on AbstractCoordinator.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13160: Fix bug in BrokerMetadataPublisher handling of default resources (#11168)When dealing with the default resource, BrokerMetadataPublisher should translate its name from the emptystring (KRaft convention) to ""<default>"" (ZK convention). In the long term, we should eventually move fromusing a string to this for using an Option[String].Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
MINOR: Add system tests README link from main README (#6939),2
"KAFKA-8985; Add flexible version support to inter-broker APIs (#7453)This patch adds flexible version support for the following inter-broker APIs: ControlledShutdown, LeaderAndIsr, UpdateMetadata, and StopReplica. Version checks have been removed from `getErrorResponse` methods since they were redundant given the checks in `AbstractRequest` and the respective`*Data` types.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
MINOR: Fix minor typos in `PartitionChangeBuilder` (#12101)Reviewers: Luke Chen <showuon@gmail.com>,4
"KAFKA-5790, KAFKA-5607; Improve error handling in SocketServer to avoid issues laterChanges:  1. When an exception is encountered in any of the methods in `Processor` while processing a channel, log the exception and close the connection. Continue to process other channels.  2. Fixes KAFKA-5790: SocketServer.processNewResponses should not skip a response if exception is thrown.  3. For `IllegalStateException` and `IOException` in `poll()`, don't close the `Selector`. Log the exception and continue.  4. Close channel on any failed send in `Selector`.  5. When closing channel fails or is closed, leave channel state as-is, indicating the state in which the channel was moved to closing.  6. Add tests for various failure scenarios.  7. Fix timing issue in `SocketServerTest.testConnectionIdReuse` by waiting for new connections to be processed by the server.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3548 from rajinisivaram/KAFKA-5607",5
MINOR: Refactor DescribeAuthorizedOperationsTest (#9938)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
KAFKA-2429: Add annotations to mark classes as stable/unstableThis also marks the consumer as unstable to show an example of using these annotations.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #133 from ewencp/stability-annotations and squashes the following commits:09c15c3 [Ewen Cheslack-Postava] KAFKA-2429: Add annotations to mark classes as stable/unstable,1
KAFKA-5750; Elevate log messages for denials to INFO in SimpleAclAuthorizerAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3698 from omkreddy/KAFKA-5750,5
"KAFKA-9058: Lift queriable and materialized restrictions on FK Join (#7541)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5928; Avoid redundant requests to zookeeper when reassign topic partitionAuthor: uncleGen <hustyugm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>Closes #3894 from uncleGen/KAFKA-5928",5
MINOR: compatibility tests for streamsUpdate system tests to make use of the newly released 0.11 version.Add on to https://github.com/apache/kafka/pull/3454Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3479 from enothereska/minor-compatibility-tests,3
"KAFKA-10847: Set StreamsConfig on InternalTopologyDriver before writing topology (#10640)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-3582; Remove references to Copcyat from Kafka Connect property filesjunraoAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1236 from Ishiihara/minor-fix,0
MINOR: Refactor versions in `FutureSubscriptionInfo` (#7849)Simplify `FutureSubscriptionInfo`Reviewers: John Roesler <vvcephei@apache.org>,5
"MINOR: Shutdown ControllerEventThread via event instead of interruptionIf the ControllerEventThread is interrupted when a request isbeing sent, it may lead to an IllegalStateException being thrown.This, in turn, can lead to a NullPointerException inunregisterPartitionReassignmentIsrChangeHandlers,To avoid these issues, we make the ControllerEventThreaduninterruptable and we shut it down by clearing the queueand enqueuing a special event.To make the code more robust, we also setReassignedPartitionsContext.reassignIsrChangeHandlerduring construction instead of setting it to null first.Finally, misleading log messages in ephemeral nodecreation have been clarified.For reference, the relevant log lines from the relevantflaky test:```text[2017-11-15 10:30:13,869] ERROR Error while creating ephemeral at /controller with return code: OK (kafka.zk.KafkaZkClient$CheckedEphemeral:101)[2017-11-15 10:30:14,155] ERROR Haven't been able to send leader and isr requests, current state of the map is Map(101 -> Map(topic1-0 -> PartitionState(controllerEpoch=2, leader=101, leaderEpoch=3, isr=101, zkVersion=3, replicas=100,102,101, isNew=false)), 100 -> Map(topic1-0 -> PartitionState(controllerEpoch=2, leader=101, leaderEpoch=3, isr=101, zkVersion=3, replicas=100,102,101, isNew=false)), 102 -> Map(topic1-0 -> PartitionState(controllerEpoch=2, leader=101, leaderEpoch=3, isr=101, zkVersion=3, replicas=100,102,101, isNew=false))). Exception message: java.lang.InterruptedException (kafka.controller.ControllerBrokerRequestBatch:101)[2017-11-15 10:30:14,156] ERROR Haven't been able to send metadata update requests to brokers Set(102, 103, 104, 101, 105), current state of the partition info is Map(topic1-0 -> PartitionState(controllerEpoch=1, leader=101, leaderEpoch=2, isr=[101], zkVersion=2, replicas=[100, 102, 101], offlineReplicas=[100])). Exception message: java.lang.InterruptedException (kafka.controller.ControllerBrokerRequestBatch:101)[2017-11-15 10:30:14,158] ERROR [Controller id=101] Forcing the controller to resign (kafka.controller.KafkaController:101)[2017-11-15 10:30:14,158] ERROR [Controller id=101] Error completing reassignment of partition topic1-0 (kafka.controller.KafkaController:107)java.lang.NullPointerExceptionat kafka.controller.KafkaController$$anonfun$unregisterPartitionReassignmentIsrChangeHandlers$1.apply(KafkaController.scala:784)at kafka.controller.KafkaController$$anonfun$unregisterPartitionReassignmentIsrChangeHandlers$1.apply(KafkaController.scala:783)```Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #4219 from ijuma/fix-npe-unregister-zk-listener",0
"KAFKA-3497: Streams ProcessorContext should support forward() based on child nameAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Yuto Kawamura, Michael G. Noll, Guozhang WangCloses #1194 from enothereska/kafka-3497-forward",1
MINOR: move the test cases which don't need brokers from TopicCommandWithAdminClientTest to TopicCommandTest (#9501)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
MINOR: kafkatest - adding whitelist for interbroker sasl configs (#7093),5
"KAFKA-3003: Update the replica.highWatermark correctlyAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #688 from becketqin/KAFKA-3003",5
"KAFKA-9517: Fix default serdes with FK join (#8061)During the KIP-213 implementation and verification, we neglected to test thecode path for falling back to default serdes if none are given in the topology.Reviewer: Bill Bejeck <bbejeck@gmail.com>",2
kafka-1406; Fix scaladoc/javadoc warnings; patched by Alan Lee; reviewed by Jun Rao,2
"KAFKA-5038; Throw correct exception of locking of state directory failsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2848 from enothereska/KAFKA-5038-trunk",1
"KAFKA-12154; Raft Snapshot Loading API (#10085)Implement Raft Snapshot loading API.1. Adds a new method `handleSnapshot` to `raft.Listener` which is called whenever the `RaftClient` determines that the `Listener` needs to load a new snapshot before reading the log. This happens when the `Listener`'s next offset is less than the log start offset also known as the earliest snapshot.2.  Adds a new type `SnapshotReader<T>` which provides a `Iterator<Batch<T>>` interface and de-serializes records in the `RawSnapshotReader` into `T`s3.  Adds a new type `RecordsIterator<T>` that implements an `Iterator<Batch<T>>` by scanning a `Records` object and deserializes the batches and records into `Batch<T>`. This type is used by both `SnapshotReader<T>` and `RecordsBatchReader<T>` internally to implement the `Iterator` interface that they expose. 4. Changes the `MockLog` implementation to read one or two batches at a time. The previous implementation always read from the given offset to the high-watermark. This made it impossible to test interesting snapshot loading scenarios.5. Removed `throws IOException` from some methods. Some of types were inconsistently throwing `IOException` in some cases and throwing `RuntimeException(..., new IOException(...))` in others. This PR improves the consistent by wrapping `IOException` in `RuntimeException` in a few more places and replacing `Closeable` with `AutoCloseable`.6. Updated the Kafka Raft simulation test to take into account snapshot. `ReplicatedCounter` was updated to generate snapshot after 10 records get committed. This means that the `ConsistentCommittedData` validation was extended to take snapshots into account. Also added a new invariant to ensure that the log start offset is consistently set with the earliest snapshot.Reviewers: dengziming <swzmdeng@163.com>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-48 Patch to add ""long poll"" support to fetch requests. git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1332413 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-9971: Error Reporting in Sink Connectors (KIP-610) (#8720)Implementation for KIP-610: https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors based on which sink connectors can now report errors at the final stages of the stream that exports records to the sink system. This PR adds the `ErrantRecordReporter` interface as well as its implementation - `WorkerErrantRecordReporter`. The `WorkerErrantRecordReporter` is created in `Worker` and brought up through `WorkerSinkTask` to `WorkerSinkTaskContext`. An integration test and unit tests have been added.Reviewers: Lev Zemlyanov <lev@confluent.io>, Greg Harris <gregh@confluent.io>, Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-10705: Make state stores not readable by others (#9583)Change permissions on the folders for the state store so they're no readable or writable by ""others"", but still accessible by owner and group members.Reviewers: Bruno Cadonna <bruno@confluent.io>,  Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"MINOR: KIP-584: Remove admin client facility to read features from controller (#9536)In this PR, I have eliminated the facility in Admin#describeFeatures API and it's implementation to be able to optionally send a describeFeatures request to the controller. This feature was not seen to be particularly useful, and besides it also poses some hindrance to post KIP-500 world where no client would be able to access the controller directly.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",1
"KAFKA-4066; Fix NPE in consumer due to multi-threaded updatesAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1763 from rajinisivaram/KAFKA-4066",5
MINOR: Rename package `internal` to `internals` for consistency (#5137),5
"KAFKA-2641; Upgrade path for ZK authenticationThis pull request adds a configuration parameter and a migration tool. It is also based on pull request #303, which should go in first.Author: flavio junqueira <fpj@apache.org>Author: Flavio Junqueira <fpj@apache.org>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #313 from fpj/KAFKA-2641",2
KAFKA-9779: Add Stream system test for 2.5 release (#8378)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Cluster file generator should produce valid jsonThis way, if the ${KAFKA_NUM_CONTAINERS} is changed in docker/run_tests.sh, the json is still validAuthor: Emanuele Cesena <emanuele.cesena@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2370 from 0x0ece/patch-1",5
"KAFKA-5179; Log connection termination during authenticationAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma, Jun RaoCloses #2980 from rajinisivaram/KAFKA-5179",5
"MINOR: Fix small typo in main README (#7779)Fixed a small typo in the main README file (""They are also are printed"" --> ""They are also printed"").Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2
MINOR: Adding kafka-storage.bat file (similar to kafka-storage.sh) for windows. (#11816)Reviewers: Jun Rao <junrao@gmail.com>,2
Minor fix: Turning on TCP NODELAY in the Simple Consumer. This fix has a significant impact on single fetch request performance from a latency standpointgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1339944 13f79535-47bb-0310-9956-ffa450edef68,1
ZookeeperConsumerConnector needs to connect to new leader after leadership change; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-362git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1360261 13f79535-47bb-0310-9956-ffa450edef68,4
"MINOR: Adding secondary nav to Streams webpageAdded secondary navigation to Streams sub-pages: - quickstart.html - core-concepts.html - developer-guide.html - tutorial.htmlAuthor: Manjula K <manjula@kafka-summit.org>Reviewers: Joel Hamill <joel-hamill@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4222 from manjuapu/streams-nav",1
"KAFKA-4656; Improve test coverage of CompositeReadOnlyKeyValueStoreAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3292 from jeyhunkarimov/KAFKA-4656",4
A tool to UPDATE Zookeeper partition-offset with input from a file; patched by John Fung; reviewed by Jun Rao; KAFKA-255git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1291536 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-8972 (2.4 blocker): bug fix for restoring task (#7617)This is a typo bug which is due to calling a wrong map.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8945/KAFKA-8947: Fix bugs in Connect REST extension API (#7392)Fix bug in Connect REST extension API caused by invalid constructor parameter validation, and update integration test to play nicely with JenkinsFix instantiation of TaskState objects by Connect framework.Author: Chris Egerton <chrise@confluent.io>Reviewers: Magesh Nandakumar <mageshn@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-702 Deadlock between request handler/processor threads; reviewed by Neha Narkhede, Jun Rao",0
"KAFKA-7082: Concurrent create topics may throw NodeExistsException (#5259)This is an unexpected exception so `UnknownServerException`is thrown back to the client.This is a minimal change to make the behaviour match `ZkUtils`.This is better, but one could argue that it's not perfect. A moresophisticated approach can be tackled separately.Added a concurrent test that fails without this change.Reviewers: Jun Rao <junrao@gmail.com>",4
"KAFKA-13137; KRaft Controller Metric MBean names incorrectly quoted (#11131)Controller metric names that are in common between the ZooKeeper-based and KRaft-based controller must remain the same, but they were not in the AK 2.8 early access release of KRaft. For example, the non-KRaft MBean name `kafka.controller:type=KafkaController,name=OfflinePartitionsCount` incorrectly became `""kafka.controller"":type=""KafkaController"",name=""OfflinePartitionCount""` (note the added quotes and the lack of plural).  This patch fixes the issues, closes the test gap that allowed the divergence to occur, and adds de-registration logic to remove the metrics when the controller is closed (this logic was missing).Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3470: treat commits as member heartbeatsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #1206 from hachikuji/KAFKA-3470",5
"KAFKA-12782: Fix Javadocs generation by upgrading JDK (#10780)This, upgrades JDK to version 15 for the docs generation, this way wecan circumvent bug https://bugs.openjdk.java.net/browse/JDK-8215291present in JDK11Reviewers: Ismael Juma <ismael@juma.me.uk>",0
KAFKA-6938: Add documentation for accessing Headers on Kafka Streams Processor API (#5128)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"MINOR: Use `Topic::isInternalTopic` instead of directly checking (#7047)We don't allow changing number of partitions for internal topics. To doso we check if the topic name belongs to the set of internal topicsdirectly instead of using the ""isInternalTopic"" method. This breaks theencapsulation by making client aware of the fact that internal topicshave special names.This is a simple change to use the method `Topic::isInternalTopic`method instead of checking it directly in ""alterTopic"" command. Wealso reduce visibility to `Topic::INTERNAL_TOPICS` to avoid unnecessary reliance on it in the future.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Remove unused TopicAndPartition usage in tests (#5419)Also replace `TopicAndPartition` with `TopicPartition` in `MetadataCache`.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-9711 The authentication failure caused by SSLEngine#beginHandshake is not properly caught and handled (#8287)SSLEngine#beginHandshake is possible to throw authentication failures (for example, no suitable cipher suites) so we ought to catch SSLException and then convert it to SslAuthenticationException so as to process authentication failures correctly.Reviewers: Jun Rao <junrao@gmail.com>",0
"KAFKA-2071: Replace Producer Request/Response with their org.apache.kafka.common.requests equivalentsThis PR replaces all occurrences of kafka.api.ProducerRequest/ProducerResponse by their common equivalents.Author: David Jacot <david.jacot@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #110 from dajac/KAFKA-2071",5
"KAFKA-1044; Eliminate direct and non-optional log4j references from `core`Use slf4j (via scala-logging) instead. Also:- Log4jController is only initialised if log4j if in the classpath- Use FATAL marker to support log4j's FATAL level (as the log4j-slf4j bridge does)- Removed `Logging.swallow` in favour of CoreUtils.swallow, which logs to thecorrect loggerAuthor: Viktor Somogyi <viktor.somogyi@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3477 from viktorsomogyi/KAFKA-1044",2
MINOR: Add offset information to consumer_test error messagesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2426 from hachikuji/improve-consumer-test-error-messages,3
MINOR: Use static imports in KafkaLog4jAppenderInstead of redefining the constants.Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3349 from Kamal15/log4j2,2
"KAFKA-5227; Remove unsafe assertion, make jaas config saferAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3037 from rajinisivaram/KAFKA-5227",5
"MINOR: Clarify log deletion configuration options in server.propertiesI spent a bit of time tracking down why files were being deleted before they reached log.retention.hours of age. It turns out that the time and size log retention schemes function independently, and not as the original comment ""The minimum age of a log file to be eligible for deletion"" might indicate to a new user.Author: Mark Rose <markrose@markrose.ca>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #28 from MarkRose/fix_misleading_configuration_file_for_trunk",5
KAFKA-2894: WorkerSinkTask should rewind offsets on rebalanceAuthor: Konstantine Karantasis <k.karantasis@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1771 from kkonstantine/KAFKA-2894-rewind-offsets-on-rebalance,1
"KAFKA-6661: Ensure sink connectors don’t resume consumer when task is pausedChanged WorkerSinkTaskContext to only resume the consumer topic partitions when the connector/task is not in the paused state.The context tracks the set of topic partitions that are explicitly paused/resumed by the connector, and when the WorkerSinkTask resumes the tasks it currently resumes all topic partitions *except* those that are still explicitly paused in the context. Therefore, the change above should result in the desired behavior.Several debug statements were added to record when the context is called by the connector.This can be backported to older releases, since this bug goes back to 0.10 or 0.9.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4716 from rhauch/kafka-6661",5
MINOR: Use Scala Future in CoreUtils testAlso rename UtilsTest to CoreUtilsTest and notethat `getOrElseUpdate` has the right behaviourin Scala 2.12.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4142 from ijuma/use-scala-futures-in-core-utils-test,3
"KAFKA-2715: Removed previous system_test folderewencp Nothing too complicated hereAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #392 from granders/minor-remove-system-test",5
"MINOR: update new version in additional placesNote: This goes only to trunk. 0.10.0 branch will need a separate PR with different versions.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1109 from gwenshap/minor-fix-version-trunk",0
"MINOR: Introduce KafkaBroker trait for use in dynamic reconfiguration (#10019)Dynamic broker reconfiguration needs to occur for both ZooKeeper-basedbrokers and brokers that use a Raft-based metadata quorum.  DynamicBrokerConfigcurrently operates on KafkaServer, but it needs to operate on BrokerServer(the broker implementation that will use the Raft metadata log) as well.This PR introduces a KafkaBroker trait to allow dynamic reconfiguration towork with either implementation.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin Patrick McCabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-10357: Extract setup of repartition topics from Streams partition assignor (#9848)KIP-698: extract the code for the setup of the repartition topics from the Streams partition assignor so that it can also be called outside of a rebalance.Reviewers: Leah Thomas <lthomas@confluent.io> , Guozhang Wang <guozhang@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"MINOR: Update JUnit to 4.13 and annotate log cleaner integration test (#6248)JUnit 4.13 fixes the issue where `Category` and `Parameterized` annotationscould not be used together. It also deprecates `ExpectedException` and`assertThat`. Given this, we:- Replace `ExpectedException` with the newly introduced `assertThrows`.- Replace `Assert.assertThat` with `MatcherAssert.assertThat`.- Annotate `AbstractLogCleanerIntegrationTest` with `IntegrationTest` category.Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, David Arthur <mumrah@gmail.com>",5
MINOR: Use .asf.yaml to direct github notifications to JIRA and mailing lists (#8521)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-5708; Upgrade Jackson from 2.8.5 to 2.9.1Jackson release notes:- https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.8- https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.9Author: dejan2609 <dejan2609@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>Closes #3631 from dejan2609/jackson-upgrade",5
"KAFKA-3409: handle CommitFailedException in MirrorMakerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Ashish Singh, Guozhang WangCloses #1115 from hachikuji/KAFKA-3409",5
MINOR: Remove multi-byte charactor in docsThere are multi-byte characters In quickstart.html and security.html.This PR will fix it.Author: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Grant HenkeCloses #897 from sasakitoa/remove_multi_byte_character,4
"KAFKA-9623: Keep polling until the task manager is no longer rebalancing in progress (#8190)This bug is found via the flaky SmokeTestDriverIntegrationTest. Without this PR the test fails every 3-4 times, after this issue is fixed we've run the test 20+ locally without error.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-5522; ListOffsets should bound timestamp search by LSO in read_committedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3456 from hachikuji/KAFKA-5522",5
Improve the command line tools in the bin directory to use the compression feature correctly; KAFKA-112; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160529 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: optimize performAssignment to skip unnecessary check (#11218)Found this while reading the code. We did a ""a little heavy"" check each time after performing assignment, which is to compare the ""assigned topics"" set and the ""subscribed topics"" set, to see if there's any topics not existed in another set. Also, the ""assigned topics"" set is created by traversing all the assigned partitions, which will be a little heavy if partition numbers are large.However, as the comments described, it's a safe-guard for user-customized assignor, which might do assignment that we don't expected. In most cases, user will just use the in-product assignor, which guarantee that we only assign the topics from subscribed topics. Therefore, no need this check for in-product assignors.In this PR, I added an ""in-product assignor names"" list, and we'll in consumerCoordinator check if the assignor is one of in-product assignors, to decide if we need to do the additional check. Also add test for it.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-1328 New consumer APIs; reviewed by Jun Rao and Guozhang Wang,1
"KAFKA-5037: Fix infinite loop if all input topics are unknown at startup1. At the beginning of assign, we first check that all the non-repartition source topics are included in the metadata. If not, we log an error at the leader and set an error in the Assignment userData bytes, indicating that leader cannot complete assignment and the error code would indicate the root cause of it.2. Upon receiving the assignment, if the error is not NONE the streams will shutdown itself with a log entry re-stating the root cause interpreted from the error code.Author: tedyu <yuzhihong@gmail.com>Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>Closes #5322 from tedyu/trunk",1
"KAFKA-9232; Coordinator new member timeout does not work for JoinGroup v3 and below (#7753)The v3 JoinGroup logic does not properly complete the initial heartbeat for new members, which then expires after the static 5 minute timeout if the member does not rejoin. The core issue is in the `shouldKeepAlive` method, which returns false when it should return true because of an inconsistent timeout check.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Add system test for optimization upgrades (#5912)This is a new system test testing for optimizing an existing topology. This test takes the following steps1. Start a Kafka Streams application that uses a selectKey then performs 3 groupByKey() operations and 1 join creating four repartition topics2. Verify all instances start and process data3. Stop all instances and verify stopped4. For each stopped instance update the config for TOPOLOGY_OPTIMIZATION to all then restart the instance and verify the instance has started successfully also verifying Kafka Streams reduced the number of repartition topics from 4 to 15. Verify that each instance is processing data from the aggregation, reduce, and join operationStop all instances and verify the shut down is complete.6. For testing I ran two passes of the system test with 25 repeats for a total of 50 test runs.All test runs passedReviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-5822; Consistent log formatting of topic partitionsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3778 from hachikuji/KAFKA-5822,5
"KAFKA-12906; Added RecordDeserializationException containing partition and offset  (#10836)As documented in KIP-334 (https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=87297793), we should add a new RecordDeserializationException, which is raised by the consumer when failing to parse a record. This allows the consumer to decide to take an action such as to shut down or skip past the record. Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Upgrade ducktape to 0.7.5 (#6197)Reviewed-by: Colin P. McCabe <cmccabe@apache.org>,2
"KAFKA-5081: Force jackson-annotations to a single version matching expected Jackson version**JIRA ticket:** [KAFKA-5081 two versions of jackson-annotations-xxx.jar in distribution tgz](https://issues.apache.org/jira/browse/KAFKA-5081)**Solutions:**1. accept this merge request **_OR_**2. upgrade jackson libraries to version **_2.9.x_** (currently available as a pre-release only)**Related jackson issue:** [Add explicit \`jackson-annotations\` dependency version for \`jackson-databind\`](https://github.com/FasterXML/jackson-databind/issues/1545)**Note:** previous (equivalent) merge request #2900 ended up deep in the sand with swarm of messages due to flaky test, so I opted to close it and to open this one.ijuma: FYIAuthor: dejan2609 <dejan2609@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3116 from dejan2609/KAFKA-5081",5
"[MINOR]: Fix typo in Fetcher comment (#7934)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-13435; Static membership protocol should let the leader skip assignment (KIP-814) (#11688)This patch implements KIP-814 as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-814%3A+Static+membership+protocol+should+let+the+leader+skip+assignment.Reviewers: Luke Chen <showuon@gmail.com>, Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Improve confusing admin client shutdown logging (#10107)If the admin client is shutdown with some unfinished calls, we see messages such as the following in the log:```2021-02-09 11:08:05.964 DEBUG [AdminClient clientId=adminclient-1] Call(callName=fetchMetadata, deadlineMs=1612843805378) timed out at 9223372036854775807 after 1 attempt(s)```The problem is that we are using passing `Long.MaxValue` as the current time in `Call.fail` in order to ensure the call is timed out and we are discarding the original cause. The patch fixes the problem by setting `aborted=true` instead and preserving the original exception message.Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
merge from 0.8 da4512174b6f7c395ffe053a86d2c6bb19d2538a and resolve conflicts,5
KAFKA-8617: Use automated protocol for `EndTxn` API (#7029)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13933: Fix stuck SSL unit tests in case of authentication failure (#12159)When there is an authentication error after the initial TCP connection, the selector never becomes READY, and these tests wait forever waiting for this state.This will happen while using an JDK like OpenJDK build that does not support the required cipher suites.Reviewers: Luke Chen <showuon@gmail.com>,  Tom Bentley <tbentley@redhat.com>, Divij Vaidya <diviv@amazon.com>",1
"KAFKA-8501: Removing key and value from exception message (#6904)Messages containing key and value were moved to the TRACE logging level, however the exception is still adding the key and value.This commits remove the key and value from StreamsException.Reviewers: Bill Bejeck <bbejeck@gmail.com>",4
"KAFKA-10847: improve throughput of stream-stream join with spurious left/outer join fix (#10917)The fix to avoid spurious left/outer stream-stream join results, showedvery low throughput for RocksDB, due to excessive creation of iterators.Instead of trying to emit left/outer stream-stream join result for everyinput record, this PR adds tracking of the lower timestamp bound ofleft/outer join candidates, and only tries to emit them (and create aniterator) if they are potentially old enough.Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Sergio Peña <sergio@confluent.io>",5
"KAFKA-4203: Align broker default for max.message.bytes with Java producer default (#4154)Also: Improve error message, Add test, Minor code quality fixesVerified that the test fails if the broker default for max message bytes is lower or higher than the currently set value.Reviewers: Andrew Choi <andchoi@linkedin.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2
"MINOR: Rename unit test class for `MeteredTimestampedWindowStore` (#6826)Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",3
MINOR: Replace easymock with mockito in log4j-appender (#10852)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-5099; Replica Deletion Regression from KIP-101Replica deletion regressed from KIP-101. Replica deletion happens when a broker receives a StopReplicaRequest with delete=true. Ever since KAFKA-1911, replica deletion has been async, meaning the broker responds with a StopReplicaResponse simply after marking the replica directory as staged for deletion. This marking happens by moving a data log directory and its contents such as /tmp/kafka-logs1/t1-0 to a marked directory like /tmp/kafka-logs1/t1-0.8c9c4c0c61c44cc59ebeb00075a2a07f-delete, acting as a soft-delete. A scheduled thread later actually deletes the data. It appears that the regression occurs while the scheduled thread is actually trying to delete the data, which means the controller considers operations such as partition reassignment and topic deletion complete. But if you look at the log4j logs and data logs, you'll find that the soft-deleted data logs actually won't get deleted.The bug is that upon log deletion, we attempt to flush the LeaderEpochFileCache to the original file location instead of the moved file location. Restarting the broker actually allows for the soft-deleted directories to get deleted.This patch avoids the issue by simply not flushing the LeaderEpochFileCache upon log deletion.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2986 from onurkaraman/KAFKA-5099",2
KAFKA-2859: Fix deadlock in WorkerSourceTask.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #554 from ewencp/kafka-2859-deadlock-worker-source-task,1
KAFKA-3407 - ErrorLoggingCallback trims helpful diagnostic information.This should help when diagnosing issues with the console producer. This allows the logger to use `exception` rather than `exception.getMessage()`.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1079 from jcustenborder/KAFKA-3407,5
"KAFKA-9159: The caller of sendListOffsetRequest need to handle retriable InvalidMetadata (#7665)Loop call Consumer.endOffsets Throw TimeoutException: Failed to get offsets by times in 30000ms after a leader change.Reviewers: Steven Lu, Guozhang Wang <wangguoz@gmail.com>",4
"MINOR: Catch Throwable in commitSourceTask()Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1402 from Ishiihara/source-task-commit-record",5
"KAFKA-12276: Add the quorum controller code (#10070)The quorum controller stores metadata in the KIP-500 metadata log, not in ApacheZooKeeper. Each controller node is a voter in the metadata quorum. The leader of thequorum is the active controller, which processes write requests. The followers are standbycontrollers, which replay the operations written to the log. If the active controller goes away,a standby controller can take its place.Like the ZooKeeper-based controller, the quorum controller is based on an event queuebacked by a single-threaded executor. However, unlike the ZK-based controller, the quorumcontroller can have multiple operations in flight-- it does not need to wait for one operationto be finished before starting another. Therefore, calls into the QuorumController returnCompleteableFuture objects which are completed with either a result or an error when theoperation is done. The QuorumController will also time out operations that have beensitting on the queue too long without being processed. In this case, the future is completedwith a TimeoutException.The controller uses timeline data structures to store multiple ""versions"" of its in-memory state simultaneously. ""Read operations"" read only committed state, which is slightly olderthan the most up-to-date in-memory state. ""Write operations"" read and write the latestin-memory state. However, we can not return a successful result for a write operation untilits state has been committed to the log. Therefore, if a client receives an RPC response, itknows that the requested operation has been performed, and can not be undone by acontroller failover.Reviewers: Jun Rao <junrao@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",5
"KAFKA-6687: rewrite topology to allow reading the same topic multiple times in the DSL (#9582)Rewrite DSL topology to allow reading a topic or pattern multiple timesReviewers: Bruno Cadonna <cadonna@confluent.io>, Leah Thomas <lthomas@confluent.io>",5
"MINOR: Fix RecordContext Javadoc (#12130)A prior commit accidentally changed the javadoc for RecordContext.In reality, it is not reachable from api.Processor, only Processor.Reviewers: Guozhang Wang <guozhang@apache.org>",2
"MINOR: Specify character encoding in NetworkTestUtils (#5965)This attempts to address the flaky test `SaslAuthenticatorTest.testCannotReauthenticateWithDifferentPrincipal()` I was not able to reproduce locally even after 150 test runs in a loop, but given the error message:```org.junit.ComparisonFailure: expected:<[6QBJiMZ6o5AqbNAjDTDjWtQSa4alfuUWsYKIy2tt7dz5heDaWZlz21yr8Gl4uEJkQABQXeEL0UebdpufDb5k8SvReSK6wYwQ9huP-9]> but was:<[????ï¿½ï¿½ï¿½ï¿½????OAUTHBEARER]>````????ï¿½ï¿½ï¿½ï¿½????` seems to mean invalid UTF-8.We now specify the charset when writing out and reading in bytes.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-12981; Ensure LogSegment.maxTimestampSoFar and LogSegment.offsetOfMaxTimestampSoFar are read/updated in sync (#10960)This patch ensures that `maxTimestampSoFar` and `offsetOfMaxTimestampSoFar` are consistent with each others. It does so by storing them together. It relates to KIP-734 which exposes them via the admin client.Reviewers: Ismael Juma <ismael@juma.me.uk>, David Jacot <djacot@confluent.io>",5
"KAFKA-3459: Returning zero task configurations from a connector does not properly clean up existing taskshachikuji ewencp Can you take a look when you have time?Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1248 from Ishiihara/kafka-3459",5
"Options in SyncProducerConfig and AsyncProducerConfig can leak, KAFKA-83git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1154804 13f79535-47bb-0310-9956-ffa450edef68",1
"MINOR: Change ""no such session ID"" log to debug (#5316)Improve the log messages while at it and fix some code style issues.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"MINOR: refactor Log to get rid of ""return"" in nested anonymous function (#9162)Scala uses NonLocalReturnException to implement the control flow of returning from a nested anonymous function. That is anti-pattern so we should avoid using it in the hot methods.Reviewers: Ismael Juma <ismael@confluent.io>",5
"MINOR: typo in variable name ""unkownInfo""Author: Evgeny Veretennikov <evg.veretennikov@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3433 from evis/unkown_info_typo",5
"MINOR: Improve AuthorizerIntegrationTest (#7926)This patch improves the authorizer integration tests in the following ways:1. We use a separate principal for inter-broker communications. This ensures that ACLs set in the test cases do not interfere with inter-broker communication. We had two test cases (`testCreateTopicAuthorizationWithClusterCreate` and `testAuthorizationWithTopicExisting`) which depend on topic creation and were timing out because of inter-broker metadata propagation failures. The timeouts were treated as successfully satisfying the expectation of authorization. So the tests passed, but not because of the intended reason.2. Previously `GroupAuthorizerIntegrationTest` was inheriting _all_ of the tests from `AuthorizerIntegrationTest`. This seemed like overkill since the ACL evaluation logic is essentially the same. Totally this should take about 5-10 minutes off the total build time and make the authorizer integration tests a little more resilient to problems with inter-broker communication.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
broker deletes all file segments when cleaning up an empty log segment; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-292git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1297324 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-8262, KAFKA-8263: Fix flaky test `MetricsIntegrationTest` (#6922)- Timeout occurred due to initial slow rebalancing.- Added code to wait until `KafkaStreams` instance is in state RUNNING to check registration of metrics and in state NOT_RUNNING to check deregistration of metrics.- I removed all other wait conditions, because they are not needed if `KafkaStreams` instance is in the right state.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: Rename `ZkVersion` to `PartitionEpoch` (#12071)This patch does some initial cleanups in the context of KAFKA-13790. Mainly, it renames `ZkVersion` field to `PartitionEpoch` in the `LeaderAndIsrRequest`, the `LeaderAndIsr` and the `Partition`.Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>",5
KAFKA-4673: Fix thread-safety of Python VerifiableConsumer classAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2427 from ewencp/kafka-4673-verifiable-consumer-thread-safety,5
MINOR: fix some ducktape test issues (#10181)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
"KAFKA-7002: Add a config property for DLQ topic's replication factor (KIP-298)Currently, the replication factor is hardcoded to a value of 3. This means that we cannot use a DLQ in any cluster setup with less than three brokers. It is better to have the user specify this value if the default value does meet the requirements.Testing: A unit test is added.Signed-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5145 from wicknicks/KAFKA-7002",5
"KAFKA-3189: Kafka server returns UnknownServerException for inherited exceptions… exceptionsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #856 from granthenke/inherited-errors",0
"MINOR: refactor replica last sent HW updates due to performance regression (#7671)This change fixes a performance regression due to follower last seen highwatermarkhandling introduced in 23beeea. maybeUpdateHwAndSendResponse is expensive forbrokers with high partition counts, as it requires a partition and a replica lookup for everypartition being fetched. This refactor moves the last seen watermark update into the followerfetch state update where we have already looked up the partition and replica.I've seen cases where maybeUpdateHwAndSendResponse is responsible 8% of CPU usage, not including the responseCallback call that is part of it.I have benchmarked this change with `UpdateFollowerFetchStateBenchmark` and it adds 5nsof overhead to Partition.updateFollowerFetchState, which is a rounding error compared to thecurrent overhead of maybeUpdateHwAndSendResponse.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-7223: Add name config to Suppressed (#5731)KIP-372 (allow naming all internal topics) was designed and developed concurrently with suppression.Since suppression introduces a new internal topic, it also needs to be nameable.Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-1997: Follow-up patch, hardcode key/value serializer in mirror maker to byte serializer.Hardcode the key/value serializer to ByteArraySerializer according to Jun’s comments.Author: Jiangjie Qin <jqin@jqin-ld1.linkedin.biz>Reviewers: Guozhang WangCloses #120 from becketqin/KAFKA-1997 and squashes the following commits:7f2e5a6 [Jiangjie Qin] KAFKA-1997: Follow-up patch, hardcode key/value serializer in mirror maker to byte serializer.",1
MINOR: Fix transient test failure in DynamicConnectionQuotaTest (#5544)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-12350: Correct the default value in doc (#10165)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
HOTFIX: Improve error handling for ACL requests- Use ResourceType.toJava instead of ResourceType.fromString. The latterdoesn't work for TransactionalId (or any type with two camel-casewords).- Replace Throwable with ApiError in response classes.- Return InvalidRequest instead of Unknown error if ANY or UNKNOWNare provided during ACL creation.- Rename `unknown()` to `isUnknown()` in a few places thatwere missed previously.- Add tests.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3364 from ijuma/acls-fromString-fixes,0
"MINOR: remove storage/src/generated from tracked files (#10637)Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>, Satish Duggana <satishd@apache.org>",5
KAFKA-9818: Fix flaky test in RecordCollectorTest (#8507)Reviewer: John Roesler <john@confluent.io>,5
MINOR: Change the log output information in the KafkaConsumer assign method (#12026)Reviewers: Luke Chen <showuon@gmail.com>,5
MINOR: Move ZkMetadataCache into its own file. (#10942)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-8774: Regex can be found anywhere in config value (#7197)Corrected the AbstractHerder to correctly identify task configs that contain variables for externalized secrets. The original method incorrectly used `matcher.matches()` instead of `matcher.find()`. The former method expects the entire string to match the regex, whereas the second one can find a pattern anywhere within the input string (which fits this use case more correctly).Added unit tests to cover various cases of a config with externalized secrets, and updated system tests to cover case where config value contains additional characters besides secret that requires regex pattern to be found anywhere in the string (as opposed to complete match).Author: Arjun Satish <arjun@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"KAFKA-10847: Remove internal config for enabling the fix (#10941)Also update the upgrade guide indicating about the grace period KIP and its indication on the fix with throughput impact.Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>",0
KAFKA-5563: Standardize validation and substitution of connector names in REST API connector configs…from config to own function and added check to create connector call.Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4230 from soenkeliebau/KAFKA-5563,5
MINOR: Improved code quality for various files. (#9037)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
MINOR: Redesign of Streams page to include video & logosguozhangwang Please review.Author: Manjula K <manjula@kafka-summit.org>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4059 from manjuapu/redesign-streams-page,2
"KAFKA-3989; Initial support for adding a JMH benchmarking moduleAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1712 from bbejeck/KAFKA-3989_create_jmh_benchmarking_module",1
"KAFKA-14036; Set local time in `ControllerApis` when `handle` returns (#12372)In `ControllerApis`, we are missing the logic to set the local processing end time after `handle` returns. As a consequence of this, the remote time ends up reported as the local time in the request level metrics. The patch adds the same logic we have in `KafkaApis` to set `apiLocalCompleteTimeNanos`.Reviewers: José Armando García Sancio <jsancio@gmail.com>",1
"KAFKA-8256; Replace Heartbeat request/response with automated protocol (#6691)Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: add ""flush=True"" to all print in system tests (#9711)That makes the behavior of print equal to pyhton2.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-5608; Follow-up to fix potential NPE and clarify method nameAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>Closes #3553 from ijuma/kafka-5608-follow-up,0
"(docs) Add JavaDocs for org.apache.kafka.common.security.oauthbearer.secured (#11811)Reviewers:  Luke Chen <showuon@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-8383; Integration tests for unclean `electLeaders` (#6857)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: ConnectionStressWorker: add missing executor shutdown (#6558),1
KAFKA-1444 kafka.javaapi.TopicMetadata and PartitionMetadata doesn't forward the toString method; reviewed by Neha Narkhede,5
"KAFKA-8974: Trim whitespaces in topic names in sink connector configs (#7442)Trim whitespaces in topic names specified in sink connector configs before subscribing to the consumer. Topic names don't allow whitespace characters, so trimming only will eliminate potential problems and will not place additional limits on topics specified in sink connectors.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Typo in KafkaConsumer javadocAuthor: Antony Stubbs <antony.stubbs@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2157 from astubbs/trunk",1
MINOR: Test ReplicaManager Metric Names (#11066)This patch closes a test gap where we do not check ReplicaManager metrics remain as expected. Therewas a bug in 2.8 where the metrics moved under a different class name for the KRaft case. Havingsuch tests would have helped identify the bug.Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
"MINOR: improve the partitioner.class doc (#10987)Reviewers: Josep Prat <josep.prat@aiven.io>, Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
kafka-1542; normal IOException in the new producer is logged as ERROR; patched by David Corley; reviewed by Jun Rao,0
"KAFKA-4700: Don't drop security configs in `StreamsKafkaClient`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska, Damian Guy, Guozhang WangCloses #2441 from ijuma/streams-kafka-client-drops-security-configs",5
KAFKA-6245: Dynamic update of topic config defaults (#4466)Dynamic update of default topic configs as described in KIP-226.,5
KAFKA-901 follow up changes to fix update metadata response handling and request logging,2
"MINOR: log epoch and offset truncation similarly to HWM truncation (#11140)This patch improves logging around follower truncation. Specifically, the log message includes the end epoch state obtained from the leader and the resulting truncation state on the follower. An example log message is given below:```Truncating partition topic1-0 with TruncationState(offset=5, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=0, leaderEpoch=0, endOffset=5)```Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Add Replication Quotas Test RigThis test rig lives in the other.kafka package so isn't part of our standard tests. It provides a convenient mechanism for measuring throttling performance over time. Measurements for each experiment are charted and presented to the user in an html file. The output looks like this:**Experiment4**- BrokerCount: 25- PartitionCount: 100- Throttle: 4,000,000 B/s- MsgCount: 1,000- MsgSize: 100,000- TargetBytesPerBrokerMB: 400![image](https://cloud.githubusercontent.com/assets/1297498/19070450/3251bc52-8a23-11e6-88fe-94de6b9147c2.png)![image](https://cloud.githubusercontent.com/assets/1297498/19070467/4c19f38e-8a23-11e6-986a-ba19d16819ca.png)Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1957 from benstopford/throttling-test-rig",3
"[TRIVIAL] Remove unused StreamsGraphNode#repartitionRequired (#6227)I found this defect while inspecting [KAFKA-7293: Merge followed by groupByKey/join might violate co-partitioning](https://issues.apache.org/jira/browse/KAFKA-7293); This flag is never used now. Instead, `KStreamImpl#repartitionRequired` is now covering its functionality.Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",1
KAFKA-3012: Avoid reserved.broker.max.id collisions on upgradeProvides a configuration to opt out of broker id generation.Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #762 from granthenke/id-generation,5
HOTFIX: checkstyle for newly added unit test,3
"MINOR: Add some logging for the transaction coordinatorAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3278 from apurvam/MINOR-add-logging-to-transaction-coordinator-in-all-failure-cases",2
KAFKA-7030; Add configuration to disable message down-conversion (KIP-283) (#5192)Add support for the topic-level `message.downconversion.enable` config as part of KIP-283.,5
"KAFKA-8611: Add KStream#repartition operation (#7170)Implements KIP-221.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-2743: Make forwarded task reconfiguration requests asynchronous on backoff on retrying.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #422 from ewencp/task-reconfiguration-async-with-backoff,5
"MINOR: Enable the TransactionsBounceTestI'll let this have multiple runs on the branch builder to see if it fails, and investigate if so.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3441 from apurvam/MINOR-enable-transactions-bounce-test",3
"MINOR: add window verification to sliding-window co-group test (#10745)Reviewers: Luke Chen <showuon@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"MINOR: improve test stability for Streams broker-compatibility testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Magnus Edenhill, Eno Thereska, Damian Guy, Guozhang WangCloses #2836 from mjsax/minor-broker-comp-test",3
"KAFKA-3103; Fix transient Failure in testIsrAfterBrokerShutDownAndJoinsBackAll three defects have the same root cause.Root cause is ClientUtils.fetchTopicMetadata returns the BrokerEndPoints in a non-deterministic order, so we need to sort the expected endpoints and the received endpoints so we can correctly compare them.Author: Denise Fernandez <dcbfernandez@gmail.com>Reviewers: Ismael Juma, Grant Henke, Guozhang WangCloses #822 from rowdyrabbit/KAFKA-3103",5
KAFKA-12548; Propagate record error messages to application (#10445)KIP-467 added a field in the produce response to allow the broker to indicate which specific records failed validation. This patch adds the logic to propagate this message up to the application.Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-12360: Document new time semantics (#11003)Update the docs for task idling, since the semantics havechanged in 3.0.Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Luke Chen <showuon@gmail.com>, Boyang Chen <boyang@apache.org>",5
"KAFKA-5021; Update delivery semantics documentation for EoS (KIP-98)Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #3388 from hachikuji/KAFKA-5021",5
"KAFKA-14201; Consumer should not send group instance ID if committing with empty member ID (server side) (#12598)The consumer group instance ID is used to support a notion of ""static"" consumer groups. The idea is to be able to identify the same group instance across restarts so that a rebalance is not needed. However, if the user sets `group.instance.id` in the consumer configuration, but uses ""simple"" assignment with `assign()`, then the instance ID nevertheless is sent in the OffsetCommit request to the coordinator. This may result in a surprising UNKNOWN_MEMBER_ID error.This PR attempts to fix this issue for existing consumers by relaxing the validation in this case. One way is to simply ignore the member id and the static id when the generation id is -1. -1 signals that the request comes from either the admin client or a consumer which does not use the group management. This does not apply to transactional offsets commit.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6936: Implicit materialized for aggregate, count and reduce (#5066)In #4919 we propagate the SerDes for each of these aggregation operators.As @guozhangwang mentioned in that PR:```reduce: inherit the key and value serdes from the parent XXImpl class.count: inherit the key serdes, enforce setting the Serdes.Long() for value serdes.aggregate: inherit the key serdes, do not set for value serdes internally.```Although it's all good for reduce and count, it is quiet unsafe to have aggregate without Materialized given. In fact I don't see why we would not give a Materialized for the aggregate since the result type will always be different (otherwise use reduce) and also the value Serde is simply not propagated.This has been discussed previously in a broader PR before but I believe for aggregate we could pass implicitly a Materialized the same way we pass a Joined, just to avoid the stupid case. Then if the user wants to specialize, he can give his own Materialized.Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3888: send consumer heartbeats from a background thread (KIP-62)Author: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #1627 from hachikuji/KAFKA-3888",5
"MINOR: Fix doc for producer throttle time metricsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3169 from rajinisivaram/MINOR-producer-metrics",5
KAFKA-4250; Make ProducerRecord and ConsumerRecord extensibleSigned-off-by: radai-rosenblatt <radai.rosenblattgmail.com>Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>Closes #1961 from radai-rosenblatt/extensibility,1
"KAFKA-10164; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part II, Admin Changes) (#8968)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
kafka-871; Rename ZkConfig properties; patched by Swapnil Ghike; reviewed by Jun Rao,5
"KAFKA-9337: Simplify MirrorMaker2 sample config (#7872)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, Robert Požarickij",5
"KAFKA-9775: Fix IllegalFormatConversionException in ToolsUtilsThe runtime type of Metric.metricValue() needn't always be a Double,for example, if it's a gauge from IntGaugeSuite.Since it's impossible to format non-double values with 3 point precisionIllegalFormatConversionException resulted.Author: Tom Bentley <tbentley@redhat.com>Author: Tom Bentley <tombentley@users.noreply.github.com>Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #8373 from tombentley/KAFKA-9775-IllegalFormatConversionException",1
"MINOR: Reduce in-memory copies of partition objects in onJoinComplete() and onJoinPrepare()`ConsumerCoordinator.onJoinPrepare()` currently makes multiple copies of the set of assigned partitions. We can let `subscriptions.assignedPartitions()` return a view of the underlying partition set, copy it only once and re-use the copied value.Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>Closes #5124 from radai-rosenblatt/copy-all-the-things",1
"KAFKA-13794: Follow up to fix producer batch comparator (#12006)In comparator, objects that are not equal need to have a stable order otherwise, binary search may not find the objects. Improve the producer batch comparator",1
"MINOR: Use method references instead of anonymus classes in Errors (#5525)Remove `ApiExceptionBuilder` in favour of `Function<String, ApiException>`.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"MINOR: Add setting input partitions for task mocks (#12510)We recently added a builder to create task mocks for unittests. This PR adds the functionality to add input partitionsto task mocks when the builder is used.Reviewers: Walker Carlson <wcarlson@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@apache.org>",5
MINOR: Use reflection for signal handler and do not enable it for IBM JDK (#5047)The Signal classes are not available in the compile classpathif --release is used so we use reflection as a workaround.As part of that moved the code to Java and added a simpleunit test.Also disabled the signal handler if the IBM JDK is being useddue to KAFKA-6918.Manually tested shutdown via ctrl+c and verified thatthe message is printed.,3
"MINOR: Add new build target for system test libsKAFKA-2644 adds MiniKdc for system tests and hence needs a target to collect all MiniKdc jars. At the moment, system tests run `gradlew jar`. Replacing that with `gradlew systemTestLibs` will enable kafka jars and test dependency jars to be built and copied into appropriate locations. Submitting this as a separate PR so that the new target can be added to the build scripts that run system tests before KAFKA-2644 is committed. A separate target for system test artifacts will allow dependency changes to be made in future without breaking test runs.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #361 from rajinisivaram/kafka-systemTestLibs",5
KAFKA-12810: Remove deprecated TopologyDescription.Source#topics (#10727)Removes methods that were deprecated via KIP-321.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-5886; Introduce delivery.timeout.ms producer config (KIP-91) (#5270)Co-authored-by: Sumant Tambe <sutambe@yahoo.com>Co-authored-by: Yu Yang <yuyang@pinterest.com>Reviewers: Ted Yu <yuzhihong@gmail.com>, Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-3195; Transient test failure in OffsetCheckpointTest.testReadWriteAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #855 from ijuma/kafka-3195-offset-checkpoint-test-transient-failure,3
merge from 0.8 c12d2ea9e5b4bdcf9aeb07c89c69553a9f270c82 to trunk,1
KAFKA-13075: Consolidate RocksDBStoreTest and RocksDBKeyValueStoreTest (#11034)Consolidate the RocksDBStoreTest and RocksDBKeyValueStoreTest files into a single test class for the RocksDBStore.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
KAFKA-2650: Change ConfigCommand --deleted-config option to align wit……h TopicCommandAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #308 from granthenke/configcommand,5
"KAFKA-7031: Connect API shouldn't depend on Jersey (KIP-285)Connect API currently depends on Jersey API as a side-effect of KIP-285. It should only depend on the JAX RS API.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5190 from mageshn/KAFKA-7031(cherry picked from commit 51ac53d9037e703507c4b6bdf7658a8793c3c7ec)Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>",5
KAFKA-3417: Wrap metric reporter calls in try/catch blocks (#3635)Prevent exception thrown by metric reporters to impact request processing and other reporters.Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-7341 Migrate core module to JUnit 5 (#9855)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-3353; Remove deprecated producer configsThese configs have been deprecated since 0.9.0.0:block.on.buffer.full, metadata.fetch.timeout.ms and timeout.msAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2987 from ijuma/kafka-3353-remove-deprecated-producer-configs",5
MINOR: change task initialization logging levelsIn `AssignedTasks` log at debug all task ids that are yet to be initialized.In `StreamsTask` log at trace when the task is initialized.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3905 from dguy/minor-task-init-logging,5
"KAFKA-9290: Update IQ related JavaDocs (#8114)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-5235: GetOffsetShell: Support for multiple topics and consumer configuration override (KIP-635) (#9430)This patch implements KIP-635 which mainly adds support for querying offsets of multiple topics/partitions.Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: Upgraded RocksDB to 5.3.6Solves a problem as described here: https://groups.google.com/forum/#!topic/confluent-platform/cR02K2o6BIwAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3472 from enothereska/minor-upgrade-rocksdb-5.1.2,5
"KAFKA-12487: Add support for cooperative consumer protocol with sink connectors (#10563)Currently, the `WorkerSinkTask`'s consumer rebalance listener (and related logic) is hardcoded to assume eager rebalancing, which means that all partitions are revoked any time a rebalance occurs and then the set of partitions included in `onPartitionsAssigned` is assumed to be the complete assignment for the task. Not only does this cause failures when the cooperative consumer protocol is used, it fails to take advantage of the benefits provided by that protocol.These changes alter framework logic to not only not break when the cooperative consumer protocol is used for a sink connector, but to reap the benefits of it as well, by not revoking partitions unnecessarily from tasks just to reopen them immediately after the rebalance has completed.This change will be necessary in order to support [KIP-726](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=177048248), which currently proposes that the default consumer partition assignor be changed to the `CooperativeStickyAssignor`.Two integration tests are added to verify sink task behavior with both eager and cooperative consumer protocols, and new and existing unit tests are adopted as well.Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <k.karantasis@gmail.com>",3
kafka-813; (add the missing file) Minor cleanup in Controller; patched by Swapnil Ghike; reviewed by Neha Narkhede and Jun Rao,4
"MINOR: add useConfiguredPartitioner and skipFlush options for ProduceBenchAdd a ""useConfiguredPartitioner"" boolean to specify testing with the configured partitioner, rather than overriding the partitioner in the test.Add a ""skipFlush"" boolean to specify skipping the flush operation when producing.  This is helpful when testing some scenarios where linger.ms is greater than 0.Reviewers: Colin P. McCabe <cmccabe@apache.org>",3
"KAFKA-13863; Prevent null config value when create topic in KRaft mode (#12109)This patch ensures consistent handling of null-valued topic configs between the zk and kraft controller. Prior to this patch, we returned INVALID_REQUEST in zk mode and it was not an error in kraft. After this patch, we return INVALID_CONFIG consistently for this case.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-9450: Decouple flushing state from commiting (#8964)In Kafka Streams the source-of-truth of a state store is in its changelog, therefore when committing a state store we only need to make sure its changelog records are all flushed and committed, but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary.On the other hand, flushing a state store too frequently may have side effects, e.g. rocksDB flushing would gets the memtable into an L0 sstable, leaving many small L0 files to be compacted later, which introduces larger overhead.Therefore this PR decouples flushing from committing, such that we do not always flush the state store upon committing, but only when sufficient data has been written since last time flushed. The checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. This is okay since: a) if EOS is not enabled, then it is fine if the local persisted state is actually ahead of the checkpoint, b) if EOS is enabled, then we would never write a checkpoint file until close.Here's a more detailed change list of this PR:1. Do not always flush state stores when calling pre-commit; move stateMgr.flush into post-commit to couple together with checkpointing.2. In post-commit, we checkpoint when: a) The state store's snapshot has progressed much further compared to the previous checkpoint, b) When the task is being closed, in which case we enforce checkpointing.3. There are some tricky obstacles that I'd have to work around in a bit hacky way: for cache / suppression buffer, we still need to flush them in pre-commit to make sure all records sent via producers, while the underlying state store should not be flushed. I've decided to introduce a new API in CachingStateStore to be triggered in pre-commit.I've also made some minor changes piggy-backed in this PR:4. Do not delete checkpoint file upon loading it, and as a result simplify the checkpointNeeded logic, initializing the snapshotLastFlush to the loaded offsets.5. In closing, also follow the commit -> suspend -> close ordering as in revocation / assignment.6. If enforceCheckpoint == true during RUNNING, still calls maybeCheckpoint even with EOS since that is the case for suspending / closing.Reviewers: John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-2803: Add hard bounce system test for Kafka Connect.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #494 from ewencp/kafka-2803-connect-hard-bounce-system-test,5
"KAFKA-12183: Add the KIP-631 metadata record definitions (#9876)Add the metadata gradle module, which will contain the metadata recorddefinitions, and other metadata-related broker-side code.Add MetadataParser, MetadataParseException, etc.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",5
"KAFKA-3870: Expose state store names in DSLAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Michael G. Noll, Guozhang WangCloses #1526 from enothereska/expose-names-dsl",5
MINOR: Upgrade to Gradle 7.3.3 (#11518)Updates Gradle to its newer version 7.3.3. This version includes thefollowing relevant features:- Support for Java 17- Support for Scala 3For a further description of the release notes see:https://docs.gradle.org/7.3.3/release-notes.htmlI did the update as per the description in Gradle's release notes:```./gradlew wrapper --gradle-version=7.3.3```This means `gradlew` script is updated to the newest version.Verified that `gradlewAll jar` and `gradlew releaseTarGz` still succeed.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-6494; ConfigCommand update to use AdminClient for broker configs (#4503)Use new AdminClient for describing and altering broker configs using ConfigCommand. Broker quota configs as well as other configs will continue to be processed directly using ZooKeeper until KIP-248 is implemented.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Make Serdes less confusing in Scala (#4963)Serdes are confusing in the Scala wrapper:* We have wrappers around Serializer, Deserializer and Serde which are not very useful.* We have Serdes in 2 places org.apache.kafka.common.serialization.Serde and in DefaultSerdes, instead we should be having only one place where to find all the Serdes.I wanted to do this PR before the release as this is a breaking change.This shouldn't add more so the current tests should be enough.Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",5
Fix missing reference in kafka.py (#7715)Also fix a default value for a dictionary arg,0
KAFKA-3380; Add system test for GetOffsetShell toolAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #1048 from SinghAsDev/KAFKA-3380,1
"MINOR: Remove spammy log message during topic deletionDeletion of a large number of topics can cause a ton of log spam. In a test case on 2.2, deletion of 50 topics with 100 partitions each caused about 158 Mb of data in the controller log. With the improvements to batch StopReplica and the patch here, we reduce that to about 1.5 Mb.Kudos to gwenshap for spotting these spammy messages.Author: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #6738 from hachikuji/remove-verbose-topic-deletion-log-message",4
KAFKA-3514: Upgrade Documentation (#5714)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-831 Controller does not send the complete list of partitions to a newly started broker; reviewed by Jun Rao,1
kafka-1681; Newly elected KafkaController might not start deletion of pending topics; patched by Sriharsha Chintalapani; reviewed by Jun Rao,4
MINOR: Fix comment in Exit.java to refer to the right method (#12592)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"Parameters zkSessionTimeOutMs and zkConnectionTimeoutMs are reversed in SimpleAclAuthorizerAlso use named parameters in KafkaServer for clarity (even though it was correct previously).Author: Matt <wangm92@163.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1646 from wangzzu/wangzzu",2
"MINOR: restructure Windows to favor immutable implementation (#5536)Update to KIP-328.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",5
"KAFKA-3393; Updated the docs to reflect the deprecation of block.on.buffer.full and usage of max.block.msAuthor: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1060 from MayureshGharat/KAFKA-3393",2
"KAFKA-3162: Added producer and consumer interceptorsThis is the most of the KIP-42: Producer and consumer interceptor. (Except exposing CRC and record sizes to the interceptor, which is coming as a separate PR; tracked by KAFKA-3196).This PR includes:1. Add ProducerInterceptor interface and call its callbacks from appropriate places in Kafka Producer.2. Add ConsumerInterceptor interface and call its callbacks from appropriate places in Kafka Consumer.3. Add unit tests for interceptor changes4. Add integration test for both mutable consumer and producer interceptors.Author: Anna Povzner <anna@confluent.io>Reviewers: Jason Gustavson, Ismael Juma, Gwen ShapiraCloses #854 from apovzner/kip42",5
KAFKA-10350: add forwarding manager implementation with metrics (#9580)add forwarding manager implementation with metricsReviewers: David Arthur <mumrah@gmail.com>,1
"KAFKA-5975; No response when deleting topics and delete.topic.enable=false (#3960)This PR implements [KIP-322](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=87295558).Reviewers: Tom Bentley <tbentley@redhat.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Fix broken link to Streams tutorial (#12426)Also fix Transforming Data Pt. 2 video titleReviewer: Bruno Cadonna <cadonna@apache.org>,1
"MINOR: System test for error handling and writes to DeadLetterQueueAdded a system test which creates a file sink with json converter and attempts to feed it bad records. The bad records should land in the DLQ if it is enabled, and the task should be killed or bad records skipped based on test parameters.Signed-off-by: Arjun Satish <arjunconfluent.io>*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Arjun Satish <arjun@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5456 from wicknicks/error-handling-sys-test",5
KAFKA-13312; 'NetworkDegradeTest#test_rate' should wait until iperf server is listening (#11344)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-7169: Validate SASL extensions through callback on server side (#5497)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6145: Pt 2. Include offset sums in subscription (#8246)KIP-441 Pt. 2: Compute sum of offsets across all stores/changelogs in a task and include them in the subscription.Previously each thread would just encode every task on disk, but we now need to read the changelog file which is unsafe to do without a lock on the task directory. So, each thread now encodes only its assigned active and standby tasks, and ignores any already-locked tasks.In some cases there may be unowned and unlocked tasks on disk that were reassigned to another instance and haven't been cleaned up yet by the background thread. Each StreamThread makes a weak effort to lock any such task directories it finds, and if successful is then responsible for computing and reporting that task's offset sum (based on reading the checkpoint file)This PR therefore also addresses two orthogonal issues:1. Prevent background cleaner thread from deleting unowned stores during a rebalance2. Deduplicate standby tasks in subscription: each thread used to include every (non-active) task found on disk in its ""standby task"" set, which meant every active, standby, and unowned task was encoded by every thread.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
Kafka has become a TLPgit-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1414576 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: allow retries for unitTest and integrationTest runs (#8323)We will currently retry if you run gradle test, but not unitTest orintegrationTest, which are used directly in Jenkins. This means that wehave not been achieving the expected retry behavior.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"MINOR: Rename `AlterIsrManager` to `AlterPartitionManager` (#12089)Since we have changed the `AlterIsr` API to `AlterPartition`, it makes sense to rename `AlterIsrManager` as well and some of the associated classes.Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-4774; Inner classes which don't need a reference to the outer c……lass should be staticAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2558 from cmccabe/KAFKA-4774",5
"KAFKA-8404: Add HttpHeader to RestClient HTTP Request and Connector REST API (#6791)When Connect forwards a REST request from one worker to another, the Authorization header was not forwarded. This commit changes the Connect framework to add include the authorization header when forwarding requests to other workers.Author: Hai-Dang Dam <damquanghaidang@gmail.com>Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",1
"MINOR: Remove AbstractFetcherThread.PartitionData (#5233)Since ConsumerFetcherThread has been removed, we havean opportunity to simplify the *FetcherThread classes. Thisis an unambitious first step which removes the now unneeded`PartitionData` indirection.",5
HOTFIX: bug updating cache when loading group metadataThe bug causes only the first instance of group metadata in the topic to be written to the cache (because of the putIfNotExists in addGroup). Coordinator fail-over won't work properly unless the cache is loaded with the right metadata.Author: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #462 from hachikuji/hotfix-group-loading,0
"KAFKA-3890: Streams use same task assignment on cluster rolling restartCurrent task assignment in TaskAssignor is not deterministic.During cluster restart or rolling restart, we have the same set of participating worker nodes.  But the current TaskAssignor is not able to maintain a deterministic mapping, so about 20% partitions will be reassigned which would cause state repopulation.When the topology of work nodes (# of worker nodes, the TaskIds they are carrying with) is not changed, we really just want to keep the old task assignment.Add the code to check whether the node topology is changing or not:- when the prevAssignedTasks from the old clientStates is the same as the new task list- when there is no new node joining (its prevAssignTasks would be either empty or conflict with some other nodes)- when there is no node dropping out (the total of prevAssignedTasks from other nodes would not be equal to the new task list)When the topology is not changing, we would just use the old mapping.I also added the code to check whether the previous assignment is balanced (whether each node's task list is within [1/2 average -- 2 * average]), if it's not balanced, we will still start the a new task assignment.Author: Henry Cai <hcai@pinterest.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1543 from HenryCaiHaiying/upstream",1
"MINOR: Update rocksDB dependency to 4.9.0rocksdbjni version 4.9.0 now includes support for running on Windows; this PR updates Kafka Stream's dependency to that version.  Tests pass locally, except for a timeout in testReprocessingFromScratchAfterReset that doesn't seem related; it happens with and without this change.This contribution is my original work and I license the work to the project under the project's open source license.Author: Mathieu Fenniak <mathieu.fenniak@replicon.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1783 from mfenniak/update-rocksdb-4.9",5
KAFKA-633 Fix mostly consistent test failure in testShutdownBroker; patched by Joel Koshy; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418155 13f79535-47bb-0310-9956-ffa450edef68,3
"KAFKA-2455: Fix failure in kafka.consumer.MetricsTest.testMetricsLeakDelayedFetchMetrics are loaded dynamically in function ""onExpiration"";use assertNull(DelayedFetchMetrics) to initialize DelayedFetchMetrics explicitly;Author: jinxing <jinxing@fenbi.com>Author: ZoneMayor <jinxing6042@126.com>Reviewers: Ismael Juma, Guozhang WangCloses #694 from ZoneMayor/trunk-KAFKA-2455",1
MINOR: Modify the Exception type of the testCommitOffsetAsyncNotCoordinator method (#11512)Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-2786: Only respond to SinkTask onPartitionsRevoked after the WorkerSinkTask has finished starting up.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #476 from ewencp/kafka-2786-on-partitions-assigned-only-after-start,5
Update Go Client to new version of Go; patched by AaronR; KAFKA-296git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1300777 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10243; ConcurrentModificationException while processing connection setup timeouts (#8990)This PR fixes a bug introduced in #8683.While processing connection set up timeouts, we are iterating through the connecting nodes to process timeouts and we disconnect within the loop, removing the entry from the set in the loop that it iterating over the set. That raises a ConcurrentModificationException exception. The current unit test did not catch this because it was using only one node.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Upgrade note on compacted topics behaviour on receiving message without keyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Guozhang WangCloses #798 from ijuma/upgrade-notes-unkeyed-messages-to-compacted-topics",5
"KAFKA-4682; Revise expiration semantics of consumer group offsets (KIP-211 - Part 1) (#4896)This patch contains the improved offset expiration semantics proposed in KIP-211. Committed offsets will not be expired as long as a group is active. Once all members have left the group, then offsets will be expired after the timeout configured by `offsets.retention.minutes`. Note that the optimization for early expiration of unsubscribed topics will be implemented in a separate patch.",1
"MINOR: Self-managed -> KRaft (Kafka Raft) (#10414)`Self-managed` is also used in the context of Cloud vs on-prem and it canbe confusing.`KRaft` is a cute combination of `Kafka Raft` and it's pronounced like `craft`(as in `craftsmanship`).Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jose Sancio <jsancio@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",5
"MINOR: Fix `toString` NPE in tableProcessorNode (#6807)This gets hit when debug logging is enabled.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Remove unnecessary license generation code in wrapper.gradle (#7742)Newer versions of Gradle handle this automatically. Tested with Gradle 5.6.Credit to @granthenke for the tip.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
KAFKA-12450: Remove deprecated methods from ReadOnlyWindowStore (#10294)Implement first part of https://cwiki.apache.org/confluence/display/KAFKA/KIP-667%3A+Remove+deprecated+methods+from+ReadOnlyWindowStore.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-1755; Reject compressed and unkeyed messages sent to compacted topics; reviewed by Mayuresh Gharat, Neha Narkhede and Guozhang Wang",5
"MINOR: Fix doc format in upgrade notesAuthor: hejiefang <he.jiefang@zte.com.cn>Reviewers: Srinivas <srinivas96alluri@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6076 from hejiefang/modifynotable",5
"KAFKA-4855: Struct SchemaBuilder should not allow duplicate fieldsewencp can you please review.Author: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2732 from baluchicken/KAFKA-4855",5
"MINOR: Fix small typo in design sectionSentence was missing ""as"", minor grammar clean up.Author: Paul Cavallaro <paulcavallaro@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1151 from paulcavallaro/docs-fix",2
KAFKA-3051 KAFKA-3048; Security config docs improvementsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #724 from ijuma/minor-security-fixes,0
"HOTFIX: recreate state.dir after cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1940 from mjsax/hotfix-resetTool",0
"HOTFIX: do not call partitioner if num partitions is non-positiveAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Damian GuyCloses #1929 from guozhangwang/KMinor-check-zero-num-partitions and squashes the following commits:c8edc2d [Guozhang Wang] fix unit test3127f9c [Guozhang Wang] do not call partitioner if num partitions is non-positive",3
HOTFIX: set timestamp in SinkNodeguozhangwangSetting the timestamp in produced records in SinkNode. This forces the producer record's timestamp same as the context's timestamp.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1137 from ymatsuda/set_timestamp_in_sinknode,1
MINOR: A few logging improvements in group coordinatorAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3259 from hachikuji/group-coordinator-logging-improvements,2
KAFKA-1327 Add log cleaner metrics.,4
MINOR; Various code cleanups (#10319)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"KAFKA-5976; Improve trace logging in RequestChannel.sendResponseIt now records the correct size for `Send` and does more appropriatelogging if the connection is being closed or if no response is beingsent.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Denis Bolshakov, Ismael Juma <ismael@juma.me.uk>Closes #3961 from huxihx/KAFKA-5976",2
"KAFKA-9558; Fix retry logic in KafkaAdminClient listOffsets (#8119)This PR is to fix the retry logic for `getListOffsetsCalls`. Previously, if there were partitions with errors, it would only pass in the current call object to retry after a metadata refresh. However, if there's a leader change, the call object never gets updated with the correct leader node to query. This PR fixes this by making another call to `getListOffsetsCalls` with only the error topic partitions as the next calls to be made after the metadata refresh. In addition there is an additional test to test the scenario where a leader change occurs.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6761: Reduce streams footprint part IV add optimization (#5451)This PR adds the optimization of eliminating multiple repartition topics when the KStream resulting from a key-changing operation executes other methods using the new key and reduces the repartition topics to one.Note that this PR leaves in place the optimization for re-using a source topic as a changelog topic for source KTable instances. I'll have another follow-up PR to move the source topic optimization to a method within InternalStreamsBuilder so it can be performed in the same area of the code.Additionally, the current value of StreamsConfig.OPTIMIZE is all and we'll need to have another KIP to change the value to 2.1.An integration test RepartitionOptimizingIntegrationTest which asserts the same results for an optimized topology with one repartition topic as the un-optimized version with four repartition topics.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4041: Update ZooKeeper to 3.4.13 (#5376)This includes a fix for ZOOKEEPER-2184 (Zookeeper Clientshould re-resolve hosts when connection attempts fail), whichfixes KAFKA-4041.Updated a couple of tests as unresolvable addresses are nowretried until the connection timeout. Cleaned up tests a little.Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: some trace logging for streams debuggingAuthor: Ubuntu <norwood@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1882 from norwood/streams-logging",2
Leave the default port alone (it was accidentally changed to 9093).git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1198047 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-8131; Move --version implementation into CommandLineUtils (#6481)This patch refactors the implementation of the --version option and moves it into the default command options. This has the benefit of automatically including it in the usage output of the command line tools. Several tools had to be manually updated because they did not use the common options.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Simplify log cleaner and fix compiler warnings- Simplify LogCleaner.cleanSegments and add comment regarding threadunsafe usage of `LogSegment.append`. This was a result of investigatingKAFKA-4972.- Fix compiler warnings (in some cases use the fully qualified name as aworkaround for deprecation warnings in import statements).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4016 from ijuma/simplify-log-cleaner-and-fix-warnings,4
"Remove ReassigningPartitions metric when shutting down ReplicaManager (#10260)One gauge is missing in ReplicaManager#removeMetricsReviewers: Chia-Ping Tsai <chia7712@gmail.com>, Anna Sophie Blee-Goldman < ableegoldman@apache.org>",4
"KAFKA-9279: Fail producer transactions for asynchronously-reported, synchronously-encountered ApiExceptions (#11508)Reviewers: Mickael Maison <mickael.maison@gmail.com>",0
KAFKA-622 Create mbeans per client; patched by Swapnil; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415021 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: updated MacOS compatibility statement for RocksDB (#8687)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-7052 Avoiding NPE in ExtractField SMT in case of non-existent fields (#8059)Author: Gunnar Morling <gunnar.morling@googlemail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,4
"KAFKA-7223: In-Memory Suppression Buffering (#5693)Reviewer: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10295: Wait for connector recovery in test_bounce (#9043)Signed-off-by: Greg Harris <gregh@confluent.io>,5
"MINOR: Do not require request timeout be larger than session timeout (#5246)This check was left over from the old consumer logic in which the join group was bound by the session timeout. Since we use a custom timeout for JoinGroup, this restriction no longer makes sense.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-1286 Follow-up comment from Jun: Change the backoff default time configuration.,5
MINOR: remove note on future multi-cluster support of Kafka Streams (#11363)Reviewer: Bill Bejeck <bill@confluent.io>,5
"MINOR: use 'mapKey' to avoid unnecessary grouped data (#10082)1. add 'mapKey=true' to DescribeLogDirsRequest2. rename PartitionIndex to Partitions for DescribeLogDirsRequest3. add 'mapKey=true' to ElectLeadersRequest4. rename PartitionId to Partitions for ElectLeadersRequest5. add 'mapKey=true' to ConsumerProtocolAssignmentReviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"make produce-sync flush (#8925)Call Producer#flush to make sure all records are indeed sent ""synchronously"" when EOS is not enabled in the OptimizedKTableIntegrationTest#shouldApplyUpdatesToStandbyStore.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-7849: Fix the warning when using GlobalKTable (#7104)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: add retry to system test curl commands (#8961)Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-7616; Make MockConsumer only add entries to the partition map returned by poll() if there are any records to return…eturned by poll() if there are any records to returnThe MockConsumer behaves unlike the real consumer in that it can return a non-empty ConsumerRecords from poll, that also has a count of 0. This change makes the MockConsumer only add partitions to the ConsumerRecords if there are records to return for those partitions.A unit test in MockConsumerTest demonstrates the issue.Author: Stig Rohde Døssing <stigdoessing@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5901 from srdo/KAFKA-7616",0
kafka-1989; New purgatory design; patched by Yasuhiro Matsuda; reviewed by Guozhang Wang and Jun Rao,1
"KAFKA-3158; ConsumerGroupCommand should tell whether group is actually deadThis patch fix differentiates between when a consumer group is rebalancing or dead and reports the appropriate error message.Author: Ishita Mandhan <imandha@us.ibm.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1429 from imandhan/KAFKA-3158",5
MINOR: Rename examples to example (#9886)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
MINOR: Fix bug in Struct.equals and use Objects.equals/Long.hashCode (#6680)* Fixed bug in Struct.equals where we returned prematurely and added tests* Update RequestResponseTest to check that `equals` and `hashCode` ofthe struct is the same after serialization/deserialization only when possible.* Use `Objects.equals` and `Long.hashCode` to simplify code* Removed deprecated usages of `JUnitTestSuite`Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
KAFKA-7320; Add consumer configuration to disable auto topic creation [KIP-361] (#5542)Implements KIP-361 to provide a consumer configuration to specify whether subscribing or assigning a non-existent topic would result in it being automatically created or not.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-7273: Extend Connect Converter to support headers (#6362)Implemented KIP-440 to allow Connect converters to use record headers when serializing or deserializing keys and values. This change is backward compatible in that the new methods default to calling the older existing methods, so existing Converter implementations need not be changed. This changes the WorkerSinkTask and WorkerSourceTask to use the new converter methods, but Connect's existing Converter implementations and the use of converters for internal topics are intentionally not modified. Added unit tests.Author: Yaroslav Tkachenko <sapiensy@gmail.com>Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Randall Hauch <rhauch@gmail.com>",3
"KAFKA-6683; Ensure producer state not mutated prior to append (#4755)We were unintentionally mutating the cached queue of batches prior to appending to the log. This could have several bad consequences if the append ultimately failed or was truncated. In the reporter's case, it caused the snapshot to be invalid after a segment roll. The snapshot contained producer state at offsets higher than the snapshot offset. If we ever had to load from that snapshot, the state was left inconsistent, which led to an error that ultimately crashed the replica fetcher.The fix required some refactoring to avoid sharing the same underlying queue inside ProducerAppendInfo. I have added test cases which reproduce the invalid snapshot state. I have also made an effort to clean up logging since it was not easy to track this problem down.One final note: I have removed the duplicate check inside ProducerStateManager since it was both redundant and incorrect. The redundancy was in the checking of the cached batches: we already check these in Log.analyzeAndValidateProducerState. The incorrectness was the handling of sequence number overflow: we were only handling one very specific case of overflow, but others would have resulted in an invalid assertion. Instead, we now throw OutOfOrderSequenceException.Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>",5
MINOR: fix checkstyle issue in ConsumerConfig.java (#8038)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: A fewer method javadoc and typo fix (#12253)Fixes an unneeded parameter doc in `MemoryRecordsBuilder` and a typo in `LazyDownConversionRecordsSend`.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>Co-authored-by: zhaobo <zhaobo@kuaishou.com>",5
"MINOR: Connect status tracking API followupFixes from Ishiihara's review.Author: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei, Gwen ShapiraCloses #974 from hachikuji/status-tracking-followup",5
"KAFKA-8204: fix Streams store flush order (#6555)Streams previously flushed stores in the order of their registration, which is arbitrary. Because stores may forward values upon flush (as in cached state stores), we must flush stores in topological order.Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2
"MINOR: Reduce log level of spammy message in `LeaderEpochFileCache` (#10198)Since we do epoch validation as part of the fetch handling these days, the log message  `LeaderEpochFileCache.endOffsetFor` has become very noisy when DEBUG is enabled (which is often the default for system tests). This patch reduces the level to TRACE.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: fix upgrade docs for Streams (#5394)Reviewers: Guozhang Wang <guozhang@confluent.io>, Rajini Sivaram <rajini@confluent.io>",5
"KAFKA-9183; Remove redundant admin client integration testing (#7690)This patch creates a `BaseAdminIntegrationTest` to be the root for all integration test extensions. Most of the existing tests will only be tested in `PlaintextAdminIntegrationTest`, which extends from `BaseAdminIntegrationTest`. This should cut off about 30 minutes from the overall build time.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Fix assertion in testCreatePermissionMetadataRequestAutoCreate (#7864)Since `retry` expects a `by name` parameter, passing a nullary functioncauses assertion failures to be ignored. I verified this by introducinga failing assertion before/after the fix.I checked other `retry` usages and they looked correct.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-6923; Refactor Serializer/Deserializer for KIP-336 (#5494)This patch implements KIP-336. It adds a default implementation to the Serializer/Deserializer interface to support the use of headers and it deprecates the ExtendedSerializer and ExtendedDeserializer interfaces for later removal.Reviewers: Satish Duggana <sduggana@hortonworks.com>, John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: remove unused code from MessageTest (#9961)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"MINOR: adding docs for failed stream thread metric (#9974)Add docs for KIP-663.Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-7029: Update ReplicaVerificationTool not to use SimpleConsumer (#5188)We need to send fetch requests to replicas so we have to useNetworkClient instead of KafkaConsumer.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
MINOR: Serialize state change logs for handling LeaderAndIsr and StopReplica requests (#8493)This patch moves the state change logger logs for handling a LeaderAndIsr/StopReplica request inside the replicaStateChangeLock in order to serialize the logs. This helps to tell apart per-partition actions of concurrent LAIR/StopReplica requests in cases where requests pile up waiting on the lock.Reviewer: Jun Rao <junrao@gmail.com>,2
"KAFKA-1109 Need to fix GC log configuration code, not able to override KAFKA_GC_LOG_OPTS; reviewed by Neha Narkhede",2
"KAFKA-3931: Fix transient failures in pattern subscription testsFull credit for figuring out the cause of these failures goes to hachikuji.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang Wang, Ismael Juma, Jason GustafsonCloses #1594 from vahidhashemian/KAFKA-3931",0
"KAFKA-9797; Fix TestSecurityRollingUpgrade.test_enable_separate_interbroker_listener (#8403)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
MINOR: Optimize assertions in unit tests (#9955)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: fix checkpoint write failure warning log (#6008)We saw a log statement in which the cause of the failure to write a checkpoint was not properly logged.This change logs the exception properly and also verifies the log message.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3514: Part III, Refactor StreamThread main loop (#5428)* Refactor the StreamThread main loop, in the following:1. Fetch from consumer and enqueue data to tasks.2. Check if any tasks should be enforced process.3/ Loop over processable tasks and process them for N iterations, and then check for 1) commit, 2) punctuate, 3) need to call consumer.poll4. Even if there is not data to process in this iteration, still need to check if commit / punctuate is needed5. Finally, try update standby tasks.*Add an optimization to only commit when it is needed (i.e. at least some process() or punctuate() was triggered since last commit).*Found and fixed a ProducerFencedException scenario: producer.send() call would never throw a ProducerFencedException directly, but it may throw a KafkaException whose ""cause"" is a ProducerFencedException.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-12562: Remove deprecated APIs in KafkaStreams and returned state classes (#10412)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
KAFKA-13445: Add ECDSA test for JWT validation (#11487)Reviewers: Jun Rao <junrao@gmail.com>,5
MINOR: Remove unnecessary printlnLooks like this println might have been left in there by mistake.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Guozhang WangCloses #429 from rajinisivaram/latency-args-print,5
"KAFKA-2624; Change log message positionLog warning message before truncating log in order todisplay right offset value for the truncated log.Author: Francois Visconte <f.visconte@criteo.com>Reviewers: Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>Closes #287 from dopuskh3/KAFKA-2624",2
"KAFKA-9748: extend EosIntegrationTest for EOS-beta (#8331)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-3078: Add ducktape tests for KafkaLog4jAppender producing to SASL enabled Kafka clusterNote that KAFKA-3077 will be required to run these tests.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #747 from SinghAsDev/KAFKA-3078,5
"KAFKA-6688. The Trogdor coordinator should track task statuses (#4737)Reviewers: Anna Povzner <anna@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: ignore unused configuration when ConsumerCoordinator is not constructed (#12041)Following PR #11940, ignore unused config when ConsumerCoordinator is not constructed.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-608 and KAFKA-630 getTopicMetadata does not respect producer config settings and fix auto-create topic; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415909 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7925 - Create credentials only once for sun.security.jgss.native (#6337)When sun.security.jgss.native=true, we currently create a new server credential for every new client connection and add to the private credential set of the server's Subject. This is expensive and can result in an unbounded number of private credentials in the Subject used by the broker. The PR creates a credential immediately after login so that a single credential can be reused.Reviewers: Guozhang Wang <wangguoz@gmail.com",1
HOTFIX: ClassCastException in Request error loggingFixed ClassCastException resulting from missing type hint in request logging.Author: Armin Braun <me@obrown.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2571 from original-brownbear/fix-logging-err-response,2
"KAFKA-7194; Fix buffer underflow if onJoinComplete is retried after failure (#5417)An untimely wakeup can cause ConsumerCoordinator.onJoinComplete to throw a WakeupException before completion. On the next poll(), it will be retried, but this leads to an underflow error because the buffer containing the assignment data will already have been advanced. The solution is to duplicate the buffer passed to onJoinComplete.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Fix typo in GlobalKTable javadocsAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #2626 from miguno/trunk-globalktable-typos",2
KAFKA-9295: revert session timeout to default value (#10736)Revert the hard-coded increased session timeout now that the default is 45sReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
KAFKA-1233 Follow up changes to new producer integration test; reviewed by Jay Kreps,3
"KAFKA-6027; Access to log should throw KafkaStorageException after the log has been marked offlineAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #4045 from lindong28/KAFKA-6027",2
"KAFKA-2738: Replica FetcherThread should connect to leader endpoint matching its inter-broker security protocol.…atching its inter-broker security protocolAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Jun Rao, Guozhang WangCloses #428 from gwenshap/KAFKA-2738",5
KAFKA-5232; Fix Log.parseTopicPartitionName to handle deleted topics with a period in the nameThis issue would only be triggered if a broker was restarted whiledeletion was still taking place.Included a few minor improvements to that method and its tests.Author: Jaikiran Pai <jaikiran.pai@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3050 from jaikiran/KAFKA-5232-trunk,1
MINOR - Increase the number of Trogdor Histogram buckets to 10000 (#8627)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
MINOR: remove duplicate code from resetByDuration (#9699)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-9265: Fix kafka.log.Log instance leak on log deletion (#7773)KAFKA-8448 fixes problem with similar leak. The Log objects are beingheld in ScheduledExecutor PeriodicProducerExpirationCheck callback. Thefix in KAFKA-8448 was to change the policy of ScheduledExecutor toremove the scheduled task when it gets canceled (by callingsetRemoveOnCancelPolicy(true)).This works when a log is closed using close() method. But when a log isdeleted either when the topic gets deleted or when the rebalancingoperation moves the replica away from broker, the delete() operation isinvoked. Log.delete() doesn't close the pending scheduled task and thatleaks Log instance.Fix is to close the scheduled task in the Log.delete() method too.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-8800: Increase poll timeout in poll[Records]UntilTrue (#7211)If retrieving metadata during `poll(Duration)` repeatedly takes longer than thepoll timeout, we don't make progress and `waitUntilTrue` eventually times outcausing the test to fail. This behaviour differs from the older `poll(long)` thatwould block until metadata retrieval had completed. The flakiness was likelyintroduced when we switched from the latter to the former.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
KAFKA-829 Mirror maker needs to share the migration tool request channel; reviewed by Jun Rao,1
"MINOR: Improve broker registration and Log logging (#8714)Broker registration previously:> INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT),EndPoint(localhost,9093,ListenerName(SSL),SSL)), czxid (broker epoch):4294967320 (kafka.zk.KafkaZkClient)Now:> INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092,SSL://localhost:9093, czxid (broker epoch):4294967320 (kafka.zk.KafkaZkClient)The second improvement is to avoid logging messages like:> ""Deleting segments List()""Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",4
"KAFKA-7864; validate partitions are 0-based (#6246)Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jun Rao <junrao@gmail.com>",5
KAFKA-1910; follow-up on fixing buffer.flip on produce requests,0
"MINOR: MiniKdc JVM shutdown hook fix (#7946)Also made all shutdown hooks consistent and added testsReviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-2150; move partitionMapCond.await into partitionMapLock; reviewed by Guozhang Wang,4
MINOR: Improve introduction section in docs to better cover connect and streams. Make uses and ecosystem pages stand alone.,5
"MINOR: Fix static mock usage in ProcessorNodeMetricsTest (#12323)Before this PR the calls to StreamsMetricsImpl.addInvocationRateAndCountToSensor()were just calls and not a verification on the mock. This miss happenedduring the switch from EasyMock to Mockito.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-6036: Local Materialization for Source KTable (#5779)Refactor the materialization for source KTables in the way that:If Materialized.as(queryableName) is specified, materialize;If the downstream operator requires to fetch from this KTable via ValueGetters, materialize;If the downstream operator requires to send old values, materialize.Otherwise do not materialize the KTable. E.g. builder.table(""topic"").filter().toStream().to(""topic"") would not create any state stores.There's a couple of minor changes along with PR as well:KTableImpl's queryableStoreName and isQueryable are merged into queryableStoreName only, and if it is null it means not queryable. As long as it is not null, it should be queryable (i.e. internally generated names will not be used any more).To achieve this, splitted MaterializedInternal.storeName() and MaterializedInternal.queryableName(). The former can be internally generated and will not be exposed to users. QueryableName can be modified to set to the internal store name if we decide to materialize it during the DSL parsing / physical topology generation phase. And only if queryableName is specified the corresponding KTable is determined to be materialized.Found some overlapping unit tests among KTableImplTest, and KTableXXTest, removed them.There are a few typing bugs found along the way, fixed them as well.-----------------------This PR is an illustration of experimenting a poc towards logical materializations.Today we've logically materialized the KTable for filter / mapValues / transformValues if queryableName is not specified via Materialized, but whenever users specify queryableName we will still always materialize. My original goal is to also consider logically materialize for queryable stores, but when implementing it via a wrapped store to apply the transformations on the fly I realized it is tougher than I thought, because we not only need to support fetch or get, but also needs to support range queries, approximateNumEntries, and isOpen etc as well, which are not efficient to support. So in the end I'd suggest we still stick with the rule of always materializing if queryableName is specified, and only consider logical materialization otherwise.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-10199: Handle task closure and recycling from state updater (#12466)1. Within the tryCompleteRestore function of the thread, try to drain the removed tasks from state updater and handle accordingly: 1) for recycle, 2) for closure, 3) for update input partitions.2. Catch up on some unit test coverage from previous PRs.3. Some minor cleanups around exception handling.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-6399: Remove Streams max.poll.interval override (#6509)Since we now call poll during restore, we can decrease the timeoutto a reasonable value, which should help Streams make progress ifthreads get stuck.Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",1
"KAFKA-14008: Add docs for Streams throughput metrics introduced in KIP-846 (#12377)Reviewers: Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-7930: topic is not internal if explicitly listed in args (#6267)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-13646; Implement KIP-801: KRaft authorizer (#11649)Currently, when using KRaft mode, users still have to have an Apache ZooKeeper instance if they want to use AclAuthorizer. We should have a built-in Authorizer for KRaft mode that does not depend on ZooKeeper. This PR introduces such an authorizer, called StandardAuthorizer. See KIP-801 for a full description of the new Authorizer design.Authorizer.java: add aclCount API as described in KIP-801. StandardAuthorizer is currently the only authorizer that implements it, but eventually we may implement it for AclAuthorizer and others as well.ControllerApis.scala: fix a bug where createPartitions was authorized using CREATE on the topic resource rather than ALTER on the topic resource as it should have been.QuorumTestHarness: rename the controller endpoint to CONTROLLER for consistency (the brokers already called it that). This is relevant in AuthorizerIntegrationTest where we are examining endpoint names. Also add the controllerServers call.TestUtils.scala: adapt the ACL functions to be usable from KRaft, by ensuring that they use the Authorizer from the current active controller.BrokerMetadataPublisher.scala: add broker-side ACL application logic.Controller.java: add ACL APIs. Also add a findAllTopicIds API in order to make junit tests that use KafkaServerTestHarness#getTopicNames and KafkaServerTestHarness#getTopicIds work smoothly.AuthorizerIntegrationTest.scala: convert over testAuthorizationWithTopicExisting (more to come soon)QuorumController.java: add logic for replaying ACL-based records. This means storing them in the new AclControlManager object, and integrating them into controller snapshots. It also means applying the changes in the Authorizer, if one is configured. In renounce, when reverting to a snapshot, also set newBytesSinceLastSnapshot to 0.Reviewers: YeonCheol Jang <YeonCheolGit@users.noreply.github.com>,  Jason Gustafson <jason@confluent.io>",5
"KAFKA-5645; Use async ZookeeperClient in SimpleAclAuthorizerAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>Closes #4155 from omkreddy/KAFKA-5645-ZK-AUTHORIZER-VERSION2",2
"Revert ""KAFKA-13152: Replace ""buffered.records.per.partition"" with ""input.buffer.max.bytes"" (#11424)""This reverts commit 14c6030c6ad70997863070f5b93c817ea8829425.Reason: Implemenation breaks backward compatibility",4
"MINOR: Added missing import (KafkaVersion) to kafka.py (#10154)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-1337: Fix incorrect producer configs after config renaming.,5
"MINOR: Avoid possibly resolvable name in tests (#12198)Reviewers: Divij Vaidya <diviv@amazon.com>, David Jacot <djacot@confluent.io>",5
MINOR; Close parenthesis in PartitionInfo.toStringTrivial patchis trivial.Author: Magnus Reftel <magnus.reftel@skatteetaten.no>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1458 from magnusr/feature/paren,5
kafka-1603; MirrorMaker consumer does not put the message key into ProducerRecord; patched by Jiangjie Qin; reviewed by Jun Rao,1
MINOR: Fix docs for end-to-end record latency metrics (#10449)Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,2
MINOR: Fix zk path in KafkaHealthCheck commentAuthor: Stig <stig@linux-pr4q.suse>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1182 from srdo/comment-fix,0
MINOR: fix typos on web doc's upgrade guideAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3804 from mjsax/hotfix,0
"KAFKA-10544: Migrate KTable aggregate and reduce (#11316)As part of the migration of KStream/KTable operations to the new Processor API https://issues.apache.org/jira/browse/KAFKA-8410, this PR includes the migration of KTable aggregate/reduce operations.Reviewers: John Roesler <vvcephei@apache.org>",0
"KAFKA-9929: Support backward iterator on WindowStore (#9138)Implements KIP-617 on WindowStore that depends on #9137.Testing strategy: extend existing tests to validate reverse operations are supported.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-1549; dead brokers coming in the TopicMetadataResponse; patched by Nicu Marasoiu; reviewed by Jun Rao,5
"KAFKA-8980: Refactor state-store-level streams metrics (#7584)Refactors metrics according to KIP-444Introduces StateStoreMetrics as a central provider for state store metricsAdds metric scope (a.k.a. store type) to the in-memory suppression bufferReviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",1
"KAFKA-10706; Ensure leader epoch cache is cleaned after truncation to end offset (#9633)This patch fixes a liveness bug which prevents follower truncation from completing after a leader election. If there are consecutive leader elections without writing any data entries, then the leader and follower may have conflicting epoch entries at the end of the log.The problem is the shortcut return in `Log.truncateTo` when the truncation offset is larger than or equal to the end offset, which prevents the conflicting entries from being resolved. Here we change this case to ensure `LeaderEpochFileCache.truncateFromEnd` is still called.Reviewers: Jun Rao <junrao@gmail.com>",2
"KAFKA-12738: send LeaveGroup request when thread dies to optimize replacement time (#11801)Quick followup to #11787 to optimize the impact of the task backoff by reducing the time to replace a thread. When a thread is going through a dirty close, ie shutting down from an uncaught exception, we should be sending a LeaveGroup request to make sure the broker acknowledges the thread has died and won't wait up to the `session.timeout` for it to join the group if the user opts to `REPLACE_THREAD` in the handlerReviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",5
MINOR: Small refactor of request quotas handling in KafkaApis- Avoid unnecessary inner methods- Remove redundant parameter in `sendResponseExemptThrottle`- Go through `sendResponseExemptThrottle` for produce requests with acks=0- Tighten how we handle cases where there’s no responseAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3087 from ijuma/kafka-apis-improvements,1
"KAFKA-12600: Remove deprecated config value `default` for client config `client.dns.lookup` (#10458)The config has been deprecated since Kafka 2.6 (released ~1 year before3.0), but it was the default before it got deprecated. As such, it'sreasonably unlikely that people would have set it explicitly.Given the confusing `default` name even though it's _not_ the default, Ithink we should remove it in 3.0.Also remove `ClientDnsLookup.DEFAULT` (not public API), which unlocksa number of code simplications.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-10589; Rename kafka-replica-verification CLI command line arguments for KIP-629 (#11007)This patch marks --topic-white-list as deprecated argument and introduce --topics-include for kafka-replica-verification as described in KIP-629: https://cwiki.apache.org/confluence/display/KAFKA/KIP-629%3A+Use+racially+neutral+terms+in+our+codebase.Reviewers: Xavier Léauté <xavier@confluent.io>, Lee Dongjin <dongjin@apache.org>, David Jacot <djacot@confluent.io>",5
"MINOR: Generalize server startup to make way for KIP-500 (#9883)This patch attempts to generalize server initialization for KIP-500. It adds a `Server` trait which `KafkaServer` extends for the legacy Zookeeper server, and a new `KafkaRaftServer` for the new server. I have also added stubs for `KafkaRaftBroker` and `KafkaRaftController` to give a clearer idea how this will be used.Note that this patch removes `KafkaServerStartable`, which was intended to enable custom startup logic, but was not codified into an official API and is not planned to be supported after KIP-500. Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",1
MINOR: Move some TopicCommand and ConfigCommand integration tests to unit tests (#12024)Move some TopicCommand and ConfigCommand integration tests to unit tests to speed up the testsReviewers: Luke Chen <showuon@gmail.com>,3
"MINOR: Update to Gradle 2.14.1Better performance is always welcome:""The Gradle build itself has seen a 50% reduction in configuration time. You'll see the biggest impact on multi-project builds""Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1644 from ijuma/update-gradle",5
"MINOR: Add KIP-500 BrokerServer and ControllerServer (#10113)This PR adds the KIP-500 BrokerServer and ControllerServer classes and makes some related changes to get them working.  Note that the ControllerServer does not instantiate a QuorumController object yet, since that will be added inPR #10070.* Add BrokerServer and ControllerServer* Change ApiVersions#computeMaxUsableProduceMagic so that it can handleendpoints which do not support PRODUCE (such as KIP-500 controller nodes)* KafkaAdminClientTest: fix some lingering references to decommissionBrokerthat should be references to unregisterBroker.* Make some changes to allow SocketServer to be used by ControllerServer aswe as by the broker.* We now return a random active Broker ID as the Controller ID inMetadataResponse for the Raft-based case as per KIP-590.* Add the RaftControllerNodeProvider* Add EnvelopeUtils* Add MetaLogRaftShim* In ducktape, in config_property.py: use a KIP-500 compatible cluster ID.Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",1
MINOR: Increase gradle daemon’s heap size to 2g (#8700)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-2737: Added single- and multi-consumer integration tests for round-robin assignmentTwo tests:1. One consumer subscribes to 2 topics, each with 2 partitions; includes adding and removing a topic.2. Several consumers subscribe to 2 topics, several partition each; includes adding one more consumer after initial assignment is done and verified.Author: Anna Povzner <anna@confluent.io>Reviewers: Guozhang WangCloses #413 from apovzner/cpkafka-76",5
KAFKA-8034: Use automatic RPC generation in DeleteTopicsReviewers: Colin P. McCabe <cmccabe@apache.org>,4
"KAKFA-13699: new ProcessorContext is missing methods (#11877)We added `currentSystemTimeMs()` and `currentStreamTimeMs()` to the`ProcessorContext` via KIP-622, but forgot to add both to the new`api.ProcessorContext`.Reviewers: Ricardo Brasil <anribrasil@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8649: Send latest commonly supported version in assignment (#7423)Instead of sending the leader's version and having older members try to blindly upgrade.The only other real change here is that we will also set the VERSION_PROBING error code and return early from onAssignment when we are upgrading our used subscription version (not just downgrading it) since this implies the whole group has finished the rolling upgrade and all members should rejoin with the new subscription version.Also piggy-backing on a fix for a potentially dangerous edge case, where every thread of an instance is assigned the same set of active tasks.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-2406: Throttle ISR propagationThis is a follow up patch for KAFKA-2406. Further test to verify if this change alone is enough to solve the problem or not.Author: Jiangjie Qin <becket.qin@gmail.com>Author: Jiangjie Qin <jqin@jqin-ld1.linkedin.biz>Reviewers: Jun Rao <junrao@gmail.com>Closes #114 from becketqin/KAFKA-2406,2
KAFKA-4483; Fix NPE in `Log` constructor if log level is INFO or finerAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2207 from ijuma/kafka-4483-npe-in-log-constructor,2
MINOR: fix bug in AbstractFetcherManagerTest on INFO level (#11696)Fix a bug where AbstractFetcherManagerTest would fail with an exception when corelogging was turned on.Reviewers: David Arthur <mumrah@gmail.com>,2
"KAFKA-12612: Remove `checksum` from ConsumerRecord/RecordMetadata for 3.0 (#10470)The methods have been deprecated since 0.11 without replacement sincemessage format 2 moved the checksum to the record batch (instead of therecord).Unfortunately, we did not deprecate the constructors that take a checksum(even though we intended to) so we cannot remove them. I have deprecatedthem for removal in 4.0 and added a single non deprecated constructor to`ConsumerRecord` and `RecordMetadata` that take all remaining parameters.`ConsumerRecord` could do with one additional convenience constructor, butthat requires a KIP and hence should be done separately.Also:* Removed `ChecksumMessageFormatter`, which is technically not publicAPI, but may have been used with the console consumer.* Updated all usages of `ConsumerRecord`/`RecordMetadata` constructorsto use the non deprecated ones.* Added tests for deprecated `ConsumerRecord/`RecordMetadata`constructors.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: Replace deepIterator/shallowIterator with deepEntries/shallowEntriesThe latter return `Iterable` instead of `Iterator` so that enhanced foreach can be usedin Java.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2261 from ijuma/deepEntries-shallowEntries,1
"KAFKA-3095: Add documentation on format of sasl.kerberos.principal.to.local.rulesAdd some basic documentation about the format, a link to get more detailed information and an example usage.  I didn't want to make a huge section on the format since it documented elsewhere but I can expand is folks want.https://issues.apache.org/jira/browse/KAFKA-3095Author: Tom Graves <tgraves@yahoo-inc.com>Reviewers: Gwen ShapiraCloses #776 from tgravescs/KAFKA-3095",0
HOTFIX: remove unused import causing checkstyle to failAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #244 from hachikuji/hotfix-checkstyle,0
"[HOT FIX] in-memory store behavior should match rocksDB (#6657)While working on consolidating the various store unit tests I uncovered some minor ""bugs"" in the in-memory stores (inconsistencies with the behavior as established by the RocksDB stores).open iterators should be properly closed in the case the store is closedfetch/findSessions should always throw NPE if key is nullwindow end time should be truncated at Long.MAX_VALUE rather than throw exception(Verified in-memory stores pass all applicable rocksDB tests now, unified unit tests coming in another PR)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",3
KAFKA-1959; Rename group to groupId in TestOffsetManager due to collision with Thread.group in IBM's JDK; reviewed by Joel Koshy and Gwen Shapira,3
KAFKA-12323 Follow-up: Refactor the unit test a bit (#10205)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Fixing log format typo (#7219)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"MINOR: increase system test kafka start timeout (#5934)The Kafka Streams system tests fail with some regularity due to a timeout starting the broker.The initial start is quite quick, but many of our tests involve stopping and restarting nodes with data already loaded, and also while processing is ongoing.Under these conditions, it seems to be normal for the broker to take about 25 seconds to start, which makes the 30 second timeout pretty close for comfort.I have seen many test failures in which the broker successfully started within a couple of seconds after the tests timed out and already initiated the failure/shut-down sequence.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
"MINOR: Tag `RaftEventSimulationTest` as `integration` and tweak it (#9925)The test takes over 1 minute to run, so it should not be considered aunit test.Also:* Replace `test` prefix with `check` prefix for helper methods. A commonmistake is to forget to add the @Test annotation, so it's good to use adifferent naming convention for methods that should have the annotationversus methods that should not.* Replace `Action` functional interface with built-in `Runnable`.* Remove unnecessary `assumeTrue`.* Remove `@FunctionalInterface` from `Invariant` since it's not usedin that way.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-10035: Safer conversion of consumer timeout parameters (#9028)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Clean-up MemoryRecords variables and APIsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jun RaoCloses #348 from guozhangwang/MemoryRecordsCapacity,4
KAFKA-425 Wrong class name in scripts. Patch from Akira Kitada reviewed by Jay Kreps.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1373054 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-13067 Add internal config to lower the metadata log segment size (#11031)Add an internal configuration in order to facilitate system and integration tests that need a smallerlog segment size. Since this is not intended for use in production, log an ERROR message if it isset to a non-default level.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-5167: Release state locks in case of failureAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3449 from mjsax/kafka-5167-streams-task-gets-stuck-after-re-balance-due-to-LockException",1
"KAFKA-7633: Allow Kafka Connect to access internal topics without cluster ACLs (#5918)When Kafka Connect does not have cluster ACLs to create topics,it fails to even access its internal topics which already exist.This was originally fixed in KAFKA-6250 by ignoring the clusterauthorization error, but now Kafka 2.0 returns a different responsecode that corresponds to a different error. Add a patch to ignore thisnew error as well.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Remove the very misleading comment linesIt is not true in practice. Maybe the implied feature is not yet implemented or removed.These lines can be super misleading.Please merge.Thank you.Author: gaob13 <gaob13@mails.tsinghua.edu.cn>Reviewers: Ismael Juma, Ewen Cheslack-PostavaCloses #793 from gaob13/trunk",1
"KAFKA-5887; Replace findBugs with spotBugs and upgrade to Gradle 4.10findBugs is abandoned, it doesn't work with Java 9 and the Gradle plugin will be deprecated inGradle 5.0: https://github.com/gradle/gradle/pull/6664spotBugs is actively maintained and it supports Java 8, 9 and 10. Java 11 is not supported yet,but it's likely to happen soon.Also fixed a file leak in Connect identified by spotbugs.Manually tested spotBugsMain, jarAll and importing kafka in IntelliJ and runninga build in the IDE.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Dong Lin <lindong28@gmail.com>Closes #5625 from ijuma/kafka-5887-spotbugs",0
"KAFKA-6877; Remove completedFetch upon a failed parse if it contains no records.This patch removed a completedFetch from the completedFetches queue upon a failed parse if it contains no records. The following scenario explains why this is needed for an instance of this case – i.e. in TopicAuthorizationException.0. Let's assume a scenario, in which the consumer is attempting to read from a topic without the necessary read permission.1. In Fetcher#fetchedRecords(), after peeking the completedFetches, the Fetcher#parseCompletedFetch(CompletedFetch) throws a TopicAuthorizationException (as expected).2. Fetcher#fetchedRecords() passes the TopicAuthorizationException up without having a chance to poll completedFetches. So, the same completedFetch remains at the completedFetches queue.3. Upon following calls to Fetcher#fetchedRecords(), peeking the completedFetches will always return the same completedFetch independent of any updates to the ACL that the topic is trying to read from.4. Hence, despite the creation of an ACL with correct permissions, once the consumer sees the TopicAuthorizationException, it will be unable to recover without a bounce.Author: Adem Efe Gencer <agencer@linkedin.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #4974 from efeg/fix/parseCompletedFetchRemainsInQueue",0
"MINOR: Fix LogDirFailureTest flakeEnsure that `TestUtils.waitUntilTrue(..)` is blocked on both send completed and a new leader being assignedAuthor: Gardner Vickers <gardner@vickers.me>Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Dong Lin <lindong28@gmail.com>Closes #5695 from gardnervickers/log-dir-failure-test-fix",3
"KAFKA-13474: Allow reconfiguration of SSL certs for broker to controller connection (#12381)What:When a certificate is rotated on a broker via dynamic configuration and the previous certificate expires, the broker to controller connection starts failing with SSL Handshake failed.Why:A similar fix was earlier performed in #6721 but when BrokerToControllerChannelManager was introduced in v2.7, we didn't enable dynamic reconfiguration for it's channel.Summary of testing strategy (including rationale)Add a test which fails prior to the fix done in the PR and succeeds afterwards. The bug wasn't caught earlier because there was no test coverage to validate the scenario.Reviewers: Luke Chen <showuon@gmail.com>",5
KAFKA-10779; Reassignment tool sets throttles incorrectly when overriding a reassignment (#9807)This patch fixes a bug when overriding a reassignment in `ReassignPartitionsCommand` due to the invalid assumption that adding replicas are not included in the full replica set. It also simplifies the logic to construct the move maps and makes some stylistic improvements.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-12557: Fix hanging KafkaAdminClientTest (#10404)Fix a hanging test in KafkaAdminClientTest by forcing the admin client to shut downwhether or not there are pending requests once the test harness enters shutdown.Reviewers: Ismael Juma <ijuma@apache.org>, Guozhang Wang <guozhang@apache.org>",3
"MINOR: Small code cleanups in GroupCoordinator (#12563)Reviewers: Jeff Kim <jeff.kim@confluent.io>, Luke Chen <showuon@gmail.com>",5
MINOR: fix verifiable consumer assertionAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #597 from hachikuji/fix-verifiable-consumer-assertion,3
"KAFKA-7620: Fix restart logic for TTLs in WorkerConfigTransformerThe restart logic for TTLs in `WorkerConfigTransformer` was broken when trying to make it toggle-able.   Accessing the toggle through the `Herder` causes the same code to be called recursively.  This fix just accesses the toggle by simply looking in the properties map that is passed to `WorkerConfigTransformer`.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5914 from rayokota/KAFKA-7620",5
KAFKA-14194: Fix NPE in Cluster.nodeIfOnline (#12584)When utilizing the rack-aware consumer configuration and rolling updates are being applied to the Kafka brokers the metadata updates can be in a transient state and a given topic-partition can be missing from the metadata. This seems to resolve itself after a bit of time but before it can resolve the `Cluster.nodeIfOnline` method throws an NPE. This patch checks to make sure that a given topic-partition has partition info available before using that partition info.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-4486: Don't commit offsets on exceptionAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #2225 from enothereska/KAFKA-4486-exception-commit",1
KAFKA-1819 Cleaner gets confused about deleted and re-created topics; reviewed by Neha Narkhede,1
"[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Merge remote branch 'origin/0.8' into trunk,1
"MINOR: Add an extra check in StreamThreadTest (#8214)During the handle-corruption logic, we first remove the partitions from the changelog reader (and hence from the restore consumer), and then add them back during the task.revive() function. During this period the test main thread may happen to call addRecords which could throw IllegalStateException: a race condition.The fix here is to wait for a position() call to return 0, which means the partitions have been added back to the restore consumer, and the seek-to-beginning has been called as well.Reviewers: Matthias J. Sax <mjsax@apache.org>",1
"Fix for KAFKA-7974: Avoid zombie AdminClient when node host isn't resolvable (#6305)* Fix for KAFKA-7974: Avoid calling disconnect() when not connecting* Resolve host only when currentAddress() is calledMoves away from automatically resolving the host when the connection entry is constructed, which can leave ClusterConnectionStates in a confused state.Instead, resolution is done on demand, ensuring that the entry in the connection list is present even if the resolution failed.* Add Javadoc to ClusterConnectionStates.connecting()",2
"KAFKA-3284: Remove beta label from security documentation4 release cycles (0.9.0.0, 0.10.0.0, 0.10.1.0, 0.10.2.0) should be enoughto remove the beta label.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2286 from ijuma/kafka-3284-security-beta-label",4
"MINOR: Controller should log UpdateMetadata response errors (#7717)Create a controller event for handling UpdateMetadata responses and log a message when a response contains an error.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-6265: Add #queryableStoreName() to GlobalKTableA spinoff of original pull request #4340 for resolving conflicts.Author: RichardYuSTUG <yohan.richard.yu2@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4413 from ConcurrencyPractitioner/kafka-6265-2",5
MINOR: Safe string conversion to avoid NPEsShould be ported back to 2.0Author: Cyrus Vafadari <cyrus@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #6004 from cyrusv/cyrus-npe,5
"MINOR: Small optimizations and removal of unused code in Streams (#10856)Remove unused methods in internal classesMark fields that can be final as finalRemove unneeded generic type annotationConvert single use fields to local final variablesUse method reference in lambdas when it's more readableReviewers: Matthias J. Sax <mjsax@apache.org>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-12499: add transaction timeout verification (#10482)This PR tries to add the check for transaction timeout for a comparison against commit interval of streams. If transaction timeout is smaller than commit interval, stream should crash and inform user to update their commit interval to be larger or equal to the given transaction timeout, or vise versa.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-5327; Console Consumer should not commit messages not printed (#4546)Ensure that the consumer's offsets are reset prior to closing so that any buffered messages which haven't been printed are not committed.,1
"KAFKA-8677: Simplify the best-effort network client poll to never throw exception (#7613)Within KafkaConsumer.poll, we have an optimization to try to send the next fetch request before returning the data in order to pipelining the fetch requests; however, this pollNoWakeup should NOT throw any exceptions, since at this point the fetch position has been updated. If an exception is thrown and the callers decide to capture and continue, those records would never be returned again, causing data loss.Also fix the flaky test itself.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: improve license header check by providing head file instead of (prefix) header regexAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2303 from mjsax/licenseHeader",5
MINOR: Add kraft controller listener to AlterConfigsRequest #11119Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
KAFKA-1861; Publishing kafka-client:test in order to utilize the helper utils in TestUtils; patched by Manikumar Reddy; reviewed by Jun Rao,3
HOTFIX: Revert async change in ProduceConsumeValidateTestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1945 from hachikuji/hotfix-produce-consume-validate,5
"KAFKA-9396; Use JDK `emptyIterator` in `ConnectHeaders` Class (#7922)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Scala cleanups in core (#12058)Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>",4
trivial change to clarify comments in KAFKA-4229,4
MINOR: FileStreamSinkTask should create file if it doesn't exist (#5406)A recent change from `new FileOutputStream` to `Files.newOutputStream` missed the `CREATE` flag (which is necessary in addition to `APPEND`).Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: Consolidate Utils.newThread, Utils.daemonThread and KafkaThreadRemoved the first two in favour of the latter.Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3350 from Kamal15/utilcleanup",4
"KAFKA-1215; Rack-Aware replica assignment optionPlease see https://cwiki.apache.org/confluence/display/KAFKA/KIP-36+Rack+aware+replica+assignment for the overall design.The update to TopicMetadataRequest/TopicMetadataResponse will be done in a different PR.Author: Allen Wang <awang@netflix.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com>Closes #132 from allenxwang/KAFKA-1215",5
MINOR: remove duplicate code of serializing auto-generated data (#9964)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-10661; Add new resigned state for graceful shutdown/initialization (#9531)When initializing the raft state machine after shutting down as a leader, we were previously entering the ""unattached"" state, which means we have no leader and no voted candidate. This was a bug because it allowed a reinitialized leader to cast a vote for a candidate in the same epoch that it was already the leader of. This patch fixes the problem by introducing a new ""resigned"" state which allows us to retain the leader state so that we cannot change our vote and we will not accept additional appends.This patch also revamps the shutdown logic to make use of the new ""resigned"" state. Previously we had a separate path in `KafkaRaftClient.poll` for the shutdown logic which resulted in some duplication. Instead now we incorporate shutdown behavior into each state's respective logic.Finally, this patch changes the shutdown logic so that `EndQuorumEpoch` is only sent by resigning leaders. Previously we allowed this request to be sent by candidates as well.Reviewers: dengziming <dengziming1993@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-919; Disabling of auto commit is ignored during consumer group rebalancing; patched by Phil Hargett; reviewed by Jun Rao,1
"KAFKA-3502; move RocksDB options construction to init()In RocksDBStore, options / wOptions / fOptions are constructed in the constructor, which needs to be dismissed in the close() call; however in some tests, the generated topology is not initialized at all, and hence the corresponding state stores are supposed to not be able to be closed as well since their `init` function is not called. This could cause the above option objects to be not released.This is fixed in this patch to move the logic out of constructor and inside `init` functions, so that no RocksDB objects will be created in the constructor only. Also some minor cleanups:1. In KStreamTestDriver.close(), we lost the logic to close the state stores but only call `flush`; it is now changed back to call both.2. Moved the forwarding logic from KStreamTestDriver to MockProcessorContext to remove the mutual dependency: these functions should really be in ProcessorContext, not the test driver.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2381 from guozhangwang/K3502-pure-virtual-function-unit-tests",3
"KAFKA-3641; Fix RecordMetadata constructor backward compatibilityAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #1292 from granthenke/recordmeta-compat",5
"MINOR: Upgrade ducktape to 0.7.7 (#8487)This fixes a version pinning issue where a transitive dependency had amajor version upgrade that a dependency did not account for, breakingthe build.Reviewers: Andrew Egelhofer <aegelhofer@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Verify startup of zookeeper service in system testsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3707 from kkonstantine/MINOR-Verify-startup-of-zookeeper-service-in-system-tests-by-connecting-to-port,5
MINOR: Remove duplicate definition about 'the' from kafka project (#10370)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-10511; Ensure monotonic start epoch/offset updates in `MockLog` (#9332)There is a minor difference in behavior between the epoch caching logic in `MockLog` from the behavior in `LeaderEpochFileCache`. The latter ensures that every new epoch/start offset entry added to the cache increases monotonically over the previous entries. This patch brings the behavior of `MockLog` in line. It also simplifies the `assignEpochStartOffset` api in `ReplicatedLog`. We always intend to use the log end offset, so this patch removes the start offset parameter.Reviewers: Boyang Chen <boyang@confluent.io>",5
MINOR: ConsumerNetworkClient does not need to send the remaining requests when the node is not ready (#6264)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
MINOR: speed up release script (#9070)Fixes slow release due to establishing a separate SSH connection per file to copy.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
MINOR: Increase wait in ZooKeeperClientTest (#11973)Increase wait in ZooKeeperClientTest.testReinitializeAfterAuthFailureso that the testcase of https://github.com/apache/kafka/pull/11563actually fails without the corresponding source code fix.Followup of https://issues.apache.org/jira/browse/KAFKA-13461.Co-Authored-By: Gantigmaa Selenge <gantigmaa.selenge1@uk.ibm.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-9072: Add Topology naming to the dev guide (#7629)Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-4527: task status was being updated before actual pause/resumeh/t ewencp for pointing out the issueAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2277 from shikhar/kafka-4527,5
"KAFKA-10394: Add classes to read and write snapshot for KIP-630 (#9512)This PR adds support for generating snapshot for KIP-630.1. Adds the interfaces `RawSnapshotWriter` and `RawSnapshotReader` and the implementations `FileRawSnapshotWriter` and `FileRawSnapshotReader` respectively. These interfaces and implementations are low level API for writing and reading snapshots. They are internal to the Raft implementation and are not exposed to the users of `RaftClient`. They operation at the `Record` level. These types are exposed to the `RaftClient` through the `ReplicatedLog` interface.2. Adds a buffered snapshot writer: `SnapshotWriter<T>`. This type is a higher-level type and it is exposed through the `RaftClient` interface. A future PR will add the related `SnapshotReader<T>`, which will be used by the state machine to load a snapshot.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-10010: Should make state store registration idempotent (#8681)Standby task could also at risk of getting into illegal state when not being closed during HandleLostAll:1. The standby task was initializing as CREATED state, and task corrupted exception was thrown from registerStateStores2. The task corrupted exception was caught, and do a non-affected task commit3. The task commit failed due to task migrated exception4. The handleLostAll didn't close the standby task, leaving it as CREATED state5. Next rebalance complete, the same task was assigned back as standby task.6. Illegal Argument exception caught as state store already registeredReviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
Improve wording in GroupMinSessionTimeoutMsDocAuthor: Jeff Widman <jeff@jeffwidman.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2291 from jeffwidman/patch-1,2
"KAFKA-6913: Add Connect converters and header converters for short, integer, long, float, and double (KIP-305)*[KIP-305](https://cwiki.apache.org/confluence/display/KAFKA/KIP-305%3A+Add+Connect+primitive+number+converters) has been approved.*Added converters and header converters for the primitive number types for which Kafka already had serializers and deserializers. All extend a common base class, `NumberConverter`, that encapsulates most of the shared functionality. Unit tests were added to check the basic functionality.These classes are not used by any other Connect code, and must be explicitly used in Connect workers and connectors.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Arjun Satish <wicknicks@users.noreply.github.com>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5034 from rhauch/kafka-6913",5
"MINOR: Use `waitUntil` to fix transient failures of ControllerFailoverTestWithout it, it's possible that the assertion is checked before the exceptionis thrown in the callback.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3182 from ijuma/fix-controller-failover-flakiness",0
"MINOR: Remove duplicate method in test classes (#10535)1. Remove duplicate serializing auto-generated data in RequestConvertToJsonTest, this is inspired by #99642. Remove RequestTestUtils.serializeRequestWithHeader since we added a AbstractRequest.serializeWithHeader in #10142Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede,1
"MINOR: Make ConfigDef safer by not using empty string for NO_DEFAULT_VALUE.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2660 from ewencp/minor-make-configdef-safer",5
"MINOR: Record all poll invocations (#9234)Record the pollSensor after every invocation to poll, rather than just when we get records back so that we can accurately gauge how often we're invoking Consumer#poll.Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@apache.org>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-8884: class cast exception improvement (#7309)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-10847: Add new RocksDBTimeOrderedWindowStore that persists (time-key)-value records (#10331)This new store is more efficient when calling range queries with only time parameters, like `fetch(from, to)`. For range queries using key ranges, then the current RocksDBWindowStore should be used.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: Use an explicit `Errors` object when possible instead of a numeric error codeAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2475 from vahidhashemian/minor/use_explicit_Errors_type_when_possible",0
KAFKA-2533: Create a member Metadata.Listener inside KafkaConsumerAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang WangCloses #220 from SinghAsDev/KAFKA-2533,5
"MINOR: improve logging of tasks on shutdown (#7597)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-2886: Handle sink task rebalance failures by stopping worker taskAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #767 from hachikuji/KAFKA-2886",5
"KAFKA-9670; Reduce allocations in Metadata Response preparation (#8236)This PR removes  intermediate  conversions between `MetadataResponse.TopicMetadata` => `MetadataResponseTopic` and `MetadataResponse.PartitionMetadata` => `MetadataResponsePartition` objects.There is 15-20% reduction in object allocations and 5-10% improvement in metadata request performance.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson<jason@confluent.io>",5
"MINOR: Fix regex on connector path param in ConnectorsResourceAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Shikhar Bhushan <shikhar@schmizz.net>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2108 from ewencp/fix-rest-api-regex",0
"MINOR: fix quoted boolean in FetchRequest.json (#10998)Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",5
MINOR: Fix mis-spell in ConsumerConfig.scalaAuthor: Michael Blume <mike@loggly.com>Reviewers: Guozhang WangCloses #4 from MichaelBlume/patch-1,2
MINOR: add equals()/hashCode() for Produced/Consumed (#4979)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-6687: restrict DSL to allow only Streams from the same source topics (#9609)Followup to PR #9582, need to restrict DSL so only KStreams can be created from the same set of topic(s)s but not KTables, which can be tackled as followup workReviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",5
"KAFKA-4657: Improve test coverage of CompositeReadOnlyWindowStoreThis commmit brings improved test coverage for window store fetch methodand WindowStoreIteratorAuthor: Andrey Dyachkov <andrey.dyachkov@zalando.de>Reviewers: Damian Guy, Guozhang WangCloses #2672 from adyach/trunk",1
KAFKA-3666; Update links for new consumer APIPull request to update the consumer API links in the docs.Author: Dustin Cote <dustin@dustins-mbp.attlocal.net>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1331 from cotedm/KAFKA-3666,2
KIP-546: Implement describeClientQuotas and alterClientQuotas. (#8083)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"MINOR: Added unit tests for ConnectionQuotas (#8650)Reviiewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-7389: Enable spotBugs with Java 11 and disable false positive warnings (#5943)See https://github.com/spotbugs/spotbugs/issues/756 for details onthe false positives affecting try with resources. An example is:> RCN | Nullcheck of fc at line 629 of value previously dereferenced in> org.apache.kafka.common.utils.Utils.readFileAsString(String, Charset)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
KAFKA-1732 DumpLogSegments tool fails when path has a '.'; reviewed by Neha Narkhede,0
"KAFKA-6729: Reuse source topics for source KTable's materialized store's changelog (#5017)1. In InternalTopologyBuilder#topicGroups, which is used in StreamsPartitionAssignor, look for book-kept storeToChangelogTopic map before creating a new internal changelog topics. In this way if the source KTable is created, its source topic stored in storeToChangelogTopic will be used.2. Added unit test (confirmed that without 1) it will fail).3. MINOR: removed TODOs that are related to removed KStreamBuilder.4. MINOR: removed TODOs in StreamsBuilderTest util functions and replaced with TopologyWrapper.5. MINOR: removed StreamsBuilderTest#testFrom as it is already covered by TopologyTest#shouldNotAllowToAddSourcesWithSameName, plus it requires KStreamImpl.SOURCE_NAME which should be a package private field of the KStreamImpl.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-4521; MirrorMaker should flush all messages before releasing partition ownership during rebalanceAuthor: Dong Lin <lindong28@gmail.com>Author: Dong Lin <dolin@linkedin.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #2241 from lindong28/KAFKA-4521,2
MINOR: Update the javadoc of SocketServer#startup(). (#7215)Update the javadoc of SockerServer#startup(). SocketServer#startProcessors() does not exist any more and it has been replaced by SocketServer#startDataPlaneProcessors() and SocketServer#startControlPlaneProcessor().Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-4434; KafkaProducer configuration is logged twiceProducerConfig calls AbstractConfig.init where does the logs. KafkaProducer init will inovoke ProducerConfig.init twice that leads to logging twice.Author: huxi <huxi@zhenrongbao.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2307 from amethystic/kafka-4434_Kafkaproducer_log_twice,2
MINOR: Some logging improvements for debugging delayed produce status (#4691)A few small logging improvements which help debugging replication issues.,0
"MINOR: Add explanation for disabling forwarding from value transformers (#8771)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
HOTFIX: Fix build error caused by ControllerApisTest.scala (#10146)Introduced by #10113. The error was:```14:01:06 > Task :core:compileTestScala14:01:06 [Error] /home/jenkins/agent/workspace/LoopTest-Kafka/kafka/core/src/test/scala/unit/kafka/server/ControllerApisTest.scala:70: the result type of an implicit conversion must be more specific than Object```Reviewers: Ismael Juma <ismael@juma.me.uk,3
"MINOR: Added doc for KIP-535 and updated it for KIP-562 (#8395)Reviewers: Boyang Chen <boyang@confluent.io>, Vinoth Chandar <vchandar@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: add Utils.isBlank to check whitespace character string and empty string (#10012)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-5862: Remove ZK dependency from Streams reset tool, Part IAuthor: Bill Bejeck <bill@confluent.io>Author: bbejeck <bbejeck@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3927 from bbejeck/KAFKA-5862_remove_zk_dependency_from_streams_reset_tool",4
"MINOR: change initial value of Min stat to Double.MAX_VALUE (not MIN)this is consistent with the Max stat implementation.Author: Zack Dever <zdever@pandora.com>Reviewers: Aditya Auradkar, Gwen ShapiraCloses #1143 from zackdever/min-stat-fix",0
"KAFKA-7223: Suppress API with only immediate emit (#5567)Part 1 of the suppression API.* add the DSL suppress method and config objects* add the processor, but only in ""identity"" mode (i.e., it will forward only if the suppression spec says to forward immediately)* add testsReviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1461; Implement per-partition back-off for replica fetcher; reviewed by Jun Rao and Guozhang Wang,5
"MINOR: Log more information when producer snapshot is written (#10757)This patch logs more information when a producer snapshot is written to the disk.Reviewers: Ismael Juma <mlists@juma.me.uk>, Lucas Bradstreet <lucas@confluent.io>",5
"KAFKA-2763: better stream task assignmentguozhangwangWhen the rebalance happens each consumer reports the following information to the coordinator.* Client UUID (a unique id assigned to an instance of KafkaStreaming)* Task ids of previously running tasks* Task ids of valid local states on the client's state directoryTaskAssignor does the following* Assign a task to a client which was running it previously. If there is no such client, assign a task to a client which has its valid local state.* Try to balance the load among stream threads.  * A client may have more than one stream threads. The assignor tries to assign tasks to a client proportionally to the number of threads.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #497 from ymatsuda/task_assignment",5
"MINOR: Additional testing of logical type handling in Cast transformReviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
kafka-1041; Number of file handles increases indefinitely in producer if broker host is unresolvable; patched by Rajasekar Elango; reviewed by Jun Rao,5
"KAFKA-10199: Expose read only task from state updater (#12497)The state updater exposes tasks that are in restorationto the stream thread. To ensure that the stream threadonly accesses the tasks to read from the tasks withoutmodifying any internal state, this PR introduces aread-only task that throws an exception if the callertries to modify the internal state of a task.This PR also returns read-only tasks fromDefaultStateUpdater#getTasks().Reviewer: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-7976 - Fix DynamicBrokerReconfigurationTest.testUncleanLeaderElectionEnable (#6374)Ensure that controller is not shutdown in the test.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"KAFKA-10388; Fix struct conversion logic for tagged structures (#9166)The message generator was missing conversion logic for tagged structures. This led to casting errors when either `fromStruct` or `toStruct` were invoked. This patch also adds missing null checks in the serialization of tagged byte arrays, which was found from improved test coverage.Reviewers: Colin P. McCabe <cmccabe@apache.org>",3
"KAFKA-5506; Fix NPE in OffsetFetchRequest.toString and logging improvementsNetworkClient's logging improvements:- Include correlation id in a number of log statements- Avoid eager toString call in parameter passed to log.debug- Use node.toString instead of passing a subset of fields to thelogger- Use requestBuilder instead of clientRequest in one of the logstatementsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3420 from ijuma/kafka-5506-offset-fetch-request-to-string-npe",1
"MINOR: Add metrics in operations doc for KIP-429 / KIP-467 (#7527)Reviewers: Tu V. Tran <tu@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6857; Leader should reply with undefined offset if undefined leader epoch requested (#4967)The leader must explicitly check if requested leader epoch is undefined, and return undefined offset so that the follower can fall back to truncating to high watermark. Otherwise, if the leader also is not tracking leader epochs, it may return its LEO, which will the follower to truncate to the incorrect offset.",1
"KAFKA-9080: Revert the check added to validate non-compressed record batch does have continuous incremental offsets#7167 added a check for non-incremental offsets in `assignOffsetsNonCompressed`, which is not applicable for message format V0 and V1. Therefore, I added a condition to disable the check if the record version precedes V2.Author: Tu Tran <tu@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7628 from tuvtran/KAFKA-9080",5
"MINOR: consume from outputTopic in EosIntegrationTest.runSimpleCopyTestPreviously, the code mistakenly consumed from inputTopic, whichworked, but didn't actually verify that the messages were correctlycopied from inputTopic to outputTopic.Author: Joel Dice <jdice@mersive.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3522 from dicej/trunk",1
"MINOR: Fix unused arguments used in formatted string and log messages (#8036)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-5849; Add process stop, round trip workload, partitioned test* Implement process stop faults via SIGSTOP / SIGCONT* Implement RoundTripWorkload, which both sends messages, and confirms that they are received at least once.* Allow Trogdor tasks to block until other Trogdor tasks are complete.* Add CreateTopicsWorker, which can be a building block for a lot of tests.* Simplify how TaskSpec subclasses in ducktape serialize themselves to JSON.* Implement some fault injection tests in round_trip_workload_test.pyAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4323 from cmccabe/KAFKA-5849",5
MINOR: Fix typos in code commentsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #673 from vahidhashemian/typo02/fix_typos_in_code_comments,2
KAFKA-10685: strictly parsing the date/time format (#9576)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Fix transient failure of testCannotSendToInternalTopicIt’s a simple matter of creating the internal topic before trying to sendto it. Otherwise, we could get an `UnknownTopicOrPartitionException`in some cases.Without the change, I could reproduce a failure in less than5 runs. With the change, 30 consecutive runs succeeded.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2584 from ijuma/test-cannot-send-to-internal-topic-transient-failure",3
"KAFKA-3522: TopologyTestDriver should only return custom stores via untyped getStateStore() method (#6756)Reviewers: Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-2755: Suspicious reference forwarding cause NPE on handleDescribeGroup.…xistent consumer groupAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang WangCloses #435 from SinghAsDev/KAFKA-2755,0
HOTFIX: decrease session timeout in flaky NamedTopologyIntegrationTest (#11259)Decrease session timeout back to 10s to improve test flakinessReviewers: Walker Carlson <wcarlson@confluent.io>,5
"KAFKA-12773; Use UncheckedIOException when wrapping IOException (#10749)The raft module may not be fully consistent on this but in general in that module we have decided to not throw the checked IOException. We have been avoiding checked IOException exceptions by wrapping them in RuntimeException. The raft module should instead wrap IOException in UncheckedIOException. Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6145: Set HighAvailabilityTaskAssignor as default in streams_upgrade_test.py (#8613)Generalize the verification in the upgrade test so that itdoes not rely on the task assignor's behavior.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-13056; Do not rely on broker for snapshots if controller is co-resident (#11013)When a node is serving as both broker and controller, we should only rely on the controller to write new snapshots.Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",1
KAFKA-9780: Deprecate commit records without record metadata (#8379)Author: Mario Molina <mmolimar@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-8972 (2.4 blocker): TaskManager state should always be updated after rebalance (#7620)Currently when we identify version probing we return early from onAssignment and never get to updating the TaskManager and general state with the new assignment. Since we do actually give out ""real"" assignments even during version probing, a StreamThread should take real ownership of its tasks/partitions including cleaning them up in onPartitionsRevoked which gets invoked when we call onLeavePrepare as part of triggering the follow-up rebalance.Every member will always get an assignment encoded with the lowest common version, so there should be no problem decoding a VP assignment. We should just allow onAssignment to proceed as usual so that the TaskManager is in a consistent state, and knows what all its tasks/partitions are when the first rebalance completes and the next one is triggered.Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Pass `--continue` to gradle in jenkins.shThis ensures that the whole test suite is executed evenif there are failures. It currently stops at a moduleboundary if there are any failures. There is a discussionto change the gradle default to stop after the first test failure:https://github.com/gradle/gradle/issues/6513`--continue` is recommended for CI in that discussion.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5599 from ijuma/jenkins-script-continue,0
MINOR: Add validation in MockAdminClient for replication factor (#7712)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Fix Streams scala format violations (#5472)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
provides windows batch script for starting Kafka/Zookeeper; patched by Antoine Vianey; reviewed by Jun Rao; kafka-581git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401782 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: distinguish between missing source topics and internal assignment errors (#9446)Introduce an ASSIGNMENT_ERROR code to distinguish from INCOMPLETE_SOURCE_TOPIC_METADATA and shut down all members in case of an unexpected exception during task assignment.Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <vvcephei@apache.org>",5
KAFKA-2121; Fix Closeable backward-compatibility; reviewed by Guozhang Wang,0
MINOR: Fix JavaDoc warning (#7546)Reviewers: Bill Bejeck<bbejeck@gmail.com>,2
"KAKFA-9503: Fix TopologyTestDriver output order (#8065)Migrates TopologyTestDriver processing to be closer to the same processing/orderingsemantics as KafkaStreams. This corrects the output order for recursive topologiesas reported in KAFKA-9503, and also works similarly in the case of task idling.",1
MINOR: Fix 404 security features links (#6634)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Reflection free implementation of `defaultKerberosRealm` (#6978)The existing implementation triggers warnings in Java 9+ and relieson internal classes that vary depending on the JDK provider. The proposedimplementation fixes these issues and it's more concise.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Guozhang Wang <wangguoz@gmail.com>",5
TRIVIAL: Fix spelling of log messageAuthor: Magnus Reftel <magnus.reftel@skatteetaten.no>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2335 from reftel/feature/triggering,5
"MINOR: Null out all buffer references in RequestChannel.RequestThe previous code kept two references to `Buffer` and only nulledout one of them.As part of this, I removed the `case` modifier from`RequestChannel.{Request, Response}`. They don't seem to be goodmatches given the types of fields they contain (mutable buffers andopaque `Send` instances).Also removed a couple of unused files in `kafka.network`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3596 from ijuma/release-buffer-in-request",5
"KAFKA-9776: Downgrade TxnCommit API v3 when broker doesn't support (#8375)Revert the decision for the sendOffsetsToTransaction(groupMetadata) API to fail with old version of brokers for the sake of making the application easier to adapt between versions. This PR silently downgrade the TxnOffsetCommit API when the build version is small than 3.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10134: Enable heartbeat during PrepareRebalance and Depend On State For Poll Timeout (#8834)1. Split the consumer coordinator's REBALANCING state into PREPARING_REBALANCE and COMPLETING_REBALANCE. The first is when the join group request is sent, and the second is after the join group response is received. During the first state we should still not send hb since it shares the same socket with the join group request and the group coordinator has disabled timeout, however when we transit to the second state we should start sending hb in case leader's assign takes long time. This is also for fixing KAFKA-10122.2. When deciding coordinator#timeToNextPoll, do not count in timeToNextHeartbeat if the state is in UNJOINED or PREPARING_REBALANCE since we would disable hb and hence its timer would not be updated.3. On the broker side, allow hb received during PREPARING_REBALANCE, return NONE error code instead of REBALANCE_IN_PROGRESS. However on client side, we still need to ignore REBALANCE_IN_PROGRESS if state is COMPLETING_REBALANCE in case it is talking to an old versioned broker.4. Piggy-backing a log4j improvement on the broker coordinator for triggering rebalance reason, as I found it a bit blurred during the investigation. Also subsumed #9038 with log4j improvements.The tricky part for allowing hb during COMPLETING_REBALANCE is in two parts: 1) before the sync-group response is received, a hb response may have reset the generation; also after the sync-group response but before the callback is triggered, a hb response can still reset the generation, we need to handle both cases by checking the generation / state. 2) with the hb thread enabled, the sync-group request may be sent by the hb thread even if the caller thread did not call poll yet.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-6591; Move super user check before ACL matching  (#4618)Currently the check whether a user as a super user in `SimpleAclAuthorizer` is performed only after all other ACLs have been evaluated. Since all requests from a super user are granted we don't really need to apply the ACLs. This patch returns true if the user is a super user before checking ACLs, thus bypassing the needless evaluation effort.Reviewers: Andy Coates <big-andy-coates@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13162: Ensure ElectLeaders is properly handled in KRaft (#11186)This patch fixes several problems with the `ElectLeaders` API in KRaft:- `KafkaApis` did not properly forward this request type to the controller.- `ControllerApis` did not handle the request type.- `ElectLeadersRequest.getErrorResponse` may raise NPE when `TopicPartitions` is null.- Controller should not do preferred election if `ElectLeaders` specifies `UNCLEAN` election.- Controller should not do unclean election if `ElectLeaders` specifies `PREFERRED` election.- Controller should use proper error codes to handle cases when desired leader is unavailable or when no election is needed because a desired leader is already elected.- When election for all partitions is requested (indicated with null `TopicPartitions` field), the response should not return partitions for which no election was necessary.In addition to extending the unit test coverage in `ReplicationControlManagerTest`, I have also converted `LeaderElectionCommandTest` to use KRaft.Reviewers: dengziming <swzmdeng@163.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, David Arthur <mumrah@gmail.com>",1
"KAFKA-8291 : System test fix (#6637)As titled, this PR changed the default reset policy to latest accidentally for system tests, which in fact was earliest.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-9086: Refactor processor-node-level metrics (#7615)Refactors metrics according to KIP-444Introduces ProcessorNodeMetrics as a central provider for processor node metricsReviewers:  Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",1
"KAFKA-9175: Update MirrorMaker 2 topic/partition metrics (#7688)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",1
"KAFKA-4416; Add a `--group` option to console consumerThis simplifies running a console consumer as part of a custom group. Note that group id can be provided via only one of the three possible means: directly using `--group ` option (as part of this PR), as property via `--consumer-property` option,  or inside a config file via `--consumer.config` option.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2150 from vahidhashemian/KAFKA-4416",5
"KAFKA-4284: Make Partitioner a Closeable and close it when closing the producer[KAFKA-4284](https://issues.apache.org/jira/browse/KAFKA-4284)Even though Partitioner has a close method it is not closed when the producer is closed. Serializers, interceptors and metrics are all closed, so partitioners should be closed to.To be able to use the same mechanism to close the partitioner as the serializers, etc. I had to make the `Partitioner` interface extend `Closeable`. Since this doesn't change the interface that feels ok and should be backwards compatible.Looking at [KAFKA-2091](https://issues.apache.org/jira/browse/KAFKA-2091) (d6c45c70fb9773043766446e88370db9709e7995) that introduced the `Partitioner` interface it looks like the intention was that the producer should close the partitioner.This contribution is my original work and I license the work to the project under the project's open source license.Author: Theo <theo@iconara.net>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2000 from iconara/kafka-4284",5
"MINOR: document restriction against running multiple Streams apps on same state.dir (#10187)Reviewers: Leah Thomas <lthomas@confluent.io>, Almog Gavra <almog@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-13868: Replace YouTube embedded video with links on streams page (#12438)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"MINOR: Fix flaky StateDirectoryTestThis fixes:```java.lang.AssertionError: expected:<2> but was:<3>at org.junit.Assert.fail(Assert.java:88)at org.junit.Assert.failNotEquals(Assert.java:834)at org.junit.Assert.assertEquals(Assert.java:645)at org.junit.Assert.assertEquals(Assert.java:631)at org.apache.kafka.streams.processor.internals.StateDirectoryTest.shouldCleanUpTaskStateDirectoriesThatAreNotCurrentlyLocked(StateDirectoryTest.java:145)```While running test in infinite loop, hit other problems: - fixed file management (release all locks and close everything) - increased sleep time for `shouldCleanupStateDirectoriesWhenLastModifiedIsLessThanNowMinusCleanupDelay` too (was flaky as well)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2781 from mjsax/minor-fix-stateDirectoryTest",3
"kafka-2104; testDuplicateListeners() has a typo; patched by Gwen Shapira; reviewed by Sriharsha Chintalapani, Onur Karaman and Jun Rao",2
"KAFKA-7502: Cleanup KTable materialization logic in a single place (#6174)This is a draft cleanup for KAFKA-7502. Here is the details:* Make KTableKTableJoinNode abstract, and define its child classes ([NonMaterialized,Materialized]KTableKTableJoinNode) instead: now, all materialization-related routines are separated into the other classes.* KTableKTableJoinNodeBuilder#build now instantiates [NonMaterialized,Materialized]KTableKTableJoinNode classes instead of KTableKTableJoinNode.Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",1
"KAFKA-12234: Implement request/response for offsetFetch batching (KIP-709) (#10962)This implements the request and response portion of KIP-709. It updates the OffsetFetch request and response to support fetching offsets for multiple consumer groups at a time. If the broker does not support the new OffsetFetch version, clients can revert to the previous behaviour and use a request for each coordinator.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: Wording fix in Streams DSL docs (#5692)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
MINOR: Remove unused DoublyLinkedListIt used to be used by MirrorMaker but its usage was removed in KAFKA-1997.Author: Grant Henke <granthenke@gmail.com>Reviewers: Jiangjie QinCloses #638 from granthenke/remove-dll,4
"KAFKA-2480: Add backoff timeout and support rewindsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #340 from Ishiihara/backoff",1
MINOR: Improve code style in FenceProducersHandler (#12208)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: improve hanging ResetIntegrationTestSometimes `ResetIntegrationTest` hangs and thus the build times out. We suspect, that this happens if no data is written into the input topics. Right now, input data is written once and reused for both test cases. If for some reason, the broker gets recreated (between both test cases), no data will be available for the second test method and thus the test hangs.This change ensures, that input data is written for each test case individually.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Eno Thereska, Guozhang WangCloses #2630 from mjsax/minor-reset-integration-test",3
"KAFKA-4309; Allow ""pluggable"" properties in KafkaService in System TestsAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2034 from benstopford/throttling-system-test-kafka-changes",5
KAFKA-7453: Expire registered channels not selected within idle timeout (#5712)Reviewers: Jun Rao <junrao@gmail.com>. Ismael Juma <ismael@juma.me.uk>,5
KAFKA-1867 liveBroker list not updated on a cluster with no topics; reviewed by Neha Narkhede,5
KAFKA-775 Very long error message on the producer during produce requests failures; skipped review since patch is minor log4j change,4
MINOR: retry when deleting offsets for named topologies (#11604)When this was made I didn't expect deleteOffsetsResult to be set if an exception was thrown. But it is and to retry we need to reset it to null. Changing the KafkaStreamsNamedTopologyWrapper for remove topology when resetting offsets to retry upon GroupSubscribedToTopicException and swallow/complete upon GroupIdNotFoundExceptionReviewers: Anna Sophie Blee-Goldman <ableegoldman@ache.>,1
"KAFKA-6957 make InternalTopologyBuilder accessible from AbstractStream subclasses (#5085)Currently, the AbstractStream class defines a copy-constructor that allow to extend KStream and KTable APIs with new methods without impacting the public interface.However adding new processor or/and store to the topology is made throught the internalTopologyBuilder that is not accessible from AbstractStream subclasses defined outside of the package (package visibility).Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-4422 / KAFKA-8700 / KAFKA-5566: Wait for state to transit to RUNNING upon start (#7519)I looked into the logs of the above tickets, and I think for a couple fo them it is due to the fact that the threads takes time to restore, or just stabilize the rebalance since there are multi-threads. Adding the hook to wait for state to transit to RUNNING upon starting.Reviewers: Chris Pettitt <cpettitt@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-9313: Set `use_all_dns_ips` as the new default for `client.dns.lookup` (KIP-602) (#8644)This applies to the producer, consumer, admin client, connect workerand inter broker communication.`ClientDnsLookup.DEFAULT` has been deprecated and a warningwill be logged if it's explicitly set in a client config.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-2089; Increase metadata wait time in unit testIncrease timeout in test to avoid transient failures due to long GC or slow machine.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2057 from rajinisivaram/KAFKA-2089,5
Fix ASF license headers for C# client; patched by Eric Hauser; #KAFKA-137git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1174493 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-3077: Enable KafkaLog4jAppender to work with SASL enabled brokersAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #740 from SinghAsDev/KAFKA-3077",5
fix condition to use await instead of wait; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-265git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1244765 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: fix typo in config for eos-v2 docs of the upgrade guide (#11001)One of the configs has a typo and should have been exactly_once _v2 rather than just exactly_onceReviewers: John Roesler <vvcephei@apache.org>,2
MINOR: Fix javadoc for consumer offsets lookup APIs which do not block indefinitely (#4613)The blocking time for these APIs is bounded by the request timeout.,5
KAFKA-2570: commit offsets on rebalance/close when auto-commit is enabledAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #257 from hachikuji/KAFKA-2570,5
"KAFKA-5717; InMemoryKeyValueStore should delete keys with null values during restoreFixed a bug in the InMemoryKeyValueStore restoration where a key with a `null` value is written in to the map rather than being deleted.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3650 from dguy/kafka-5717",4
"MINOR: MetricsIntegrationTest should set StreamsConfig.STATE_DIR_CONFIG (#6687)Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Update streams RocksDb to 4.1.0This is the latest version in Maven even though HISTORY.md includes releases all the way to 4.5.0.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <ghenke@cloudera.com>, Guozhang Wang <wangguoz@gmail.com>Closes #937 from ijuma/update-rocks-db-for-streams",5
KAFKA-5523: Remove ReplayLogProducer tool (#5092)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"MINOR: Fix and clarify kraft README and example configuration files (#11616)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-238 getTopicMetadata API; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1235492 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR: various random minor fixes and improve KafkaConsumer JavaDocsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3884 from mjsax/minor-fixed-discoverd-via-exception-handling-investigation",0
ConsumerOffsetChecker now works with hostnames (in addition to IP) in the brokers/ids zk path; KAFKA-549; patched by Bob Cotton; reviewed by Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1395809 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Fix ZooKeeperAuthorizerTest for KRaft (#11095)This patch fixes the ZooKeeperAuthorizerTest for KRaft. The system test was notconfiguring/reconfiguring/restarting the remote controller quorum with the correct security settings.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
MINOR: improve logging of consumer system testsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1199 from hachikuji/improve-consumer-systests,5
"KAFKA-2275: Add ListTopics() API to the Java consumer; reviewed by Jason Gustafson, Edward Ribeiro and Guozhang Wang",1
"KAFKA-9033; Use consumer/producer identity in generated clientId (#7514)By default, if the user does not configure a `client.id`, then we use a very generic identifier, such as `consumer-15`. It is more useful to include identifying information when available such as `group.id` for the consumer and `transactional.id` for the producer.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5096; Log invalid user configs and use defaultsKafka Streams does not allow users to modify some consumer configurations.Currently, it does not allow modifying the value of 'enable.auto.commit'.If the user modifies this property, currently an exception is thrown.The following changes were made in this patch:- Defined a new array 'NON_CONFIGURABLE_CONSUMER_CONFIGS' to hold the names  of the configuration parameters that is not allowed to be modified- Defined a new method 'checkIfUnexpectedUserSpecifiedConsumerConfig' to  check if user overwrote the values of any of the non configurable configuration  parameters. If so, then log a warning message and reset the default values- Updated the javadoc to include the configuration parameters that cannot be  modified by users.- Updated the corresponding tests in StreamsConfigTest.java to reflect the changes  made in StreamsConfig.javaAuthor: Mariam John <mariamj@us.ibm.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #2990 from johnma14/bug/kafka-5096",0
"MINOR: Improve error message for inconsistent broker idsProvides a more actionable and descriptive error message.Author: Grant Henke <granthenke@gmail.com>Reviewers: Ashish Singh <asingh@cloudera.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #847 from granthenke/broker-id-error",0
"KAFKA-2948; Remove unused topics from producer metadata setIf no messages are sent to a topic during the last refresh interval or if UNKNOWN_TOPIC_OR_PARTITION error is received, remove the topic from the metadata list. Topics are added to the list on the next attempt to send a message to the topic.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Author: rsivaram <rsivaram@uk.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #645 from rajinisivaram/KAFKA-2948",5
"MINOR: Fix zk client session state metric names and various async zk clean-ups- Fix zk session state and session change rate metric names: typeshould be SessionExpireListener instead of KafkaHealthCheck. Testverifying the fix was included.- Handle missing controller in controlled shutdown in the same way as ifthe broker is not registered (i.e. retry after backoff).- Restructure BrokerInfo to reduce duplication. It now contains aBroker instance and the JSON serde is done in BrokerIdZNodesince `Broker` does not contain all the fields.- Remove dead code from `ZooKeeperClient.initialize` and removeredundant `close` calls.- Move ACL handling and persistent paths definition from ZkUtils toZkData (and call ZkData from ZkUtils).- Remove ZooKeeperClientWrapper and ZooKeeperClientMetrics fromZkUtils (avoids metrics clash if third party users create a ZkUtilsinstance in the same process as the broker).- Introduce factory method in KafkaZkClient that createsZooKeeperClient and remove metric name defaults fromZooKeeperClient.- Fix a few instances where ZooKeeperClient was not closed in tests.- Update a few TestUtils methods to use KafkaZkClient instead ofZkUtils.- Add test verifying SessionState metric.- Various clean-ups.Testing: mostly relying on existing tests, but added a coupleof new tests as mentioned above.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>Closes #4359 from ijuma/kafka-6320-kafka-health-zk-metrics-follow-up",3
KAFKA-1697; Remove support for producer ack > 1 on the broker; reviewed by Joel Koshy,1
"MINOR: re-add removed test coverage for 'KAFKA-12983: reset needsJoinPrepare flag' (#11332)In 11231 we fixed a bug in which the consumer would reset its state unnecessarily, and fixed up the tests accordingly. Unfortunately this also wiped out the test coverage for https://issues.apache.org/jira/browse/KAFKA-12983 that was added in 10986. This test coverage was re-added during a cherrypick to the 2.7 branch; this PR ports that up to trunk. This test has been verified to fail without the corresponding fix, ie resetting the `needsJoinPrepare` flagReviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-7557: optimize LogManager.truncateFullyAndStartAt() (#5848)Instead of calling deleteSnapshotsAfterRecoveryPointCheckpoint for allLogs, invoking it only for the logs being truncated.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",1
MINOR: Add explicit result type in public defs/vals (#7993)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
Minor: Move trogdor out of tools and into its own gradle module (#10539)Move Trogdor out of tools and into its own gradle module.  This allows us to minimizethe dependencies of the tools module.  We still keep Trogdor in the CLASSPATHcreated by kafka-run-class.sh.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-10667: add timeout for forwarding requests (#9564)add total timeout for forwarding, including the underlying broker-to-controller channel timeout setting.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7126; Reduce number of rebalance for large consumer group after a topic is createdThis patch forces metadata update for consumers with pattern subscription at the beginning of rebalance (retry.backoff.ms is respected). This is to prevent such consumers from detecting subscription changes (e.g., new topic creation) independently and triggering multiple unnecessary rebalances. KAFKA-7126 contains detailed scenarios and rationale.Author: Jon Lee <jonlee@linkedin.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5408 from jonlee2/KAFKA-7126",5
"update batch.size doc (#11160)We didn't mention anything about the linger.ms and upper the bound batch size concept in the batch.size, which will make users believe we'll send every batch with this batch.size setting value.Reviewers: Boyang Chen <bchen11@outlook.com>",1
"MINOR: clarify message ordering with max in-flight requests and idempotent producer (#10690)The docs for the max.in.flight.requests.per.connection and enable.idempotence configs currently imply that setting the max in-flight request greater than 1 will break the message ordering guarantee, but that is only true if enable.idempotence is false. When using an idempotent producer, the max in-flight request can be up to 5 without re-ordering messages.Reviewers: Matthias J. Sax <mjsax@confluent.io>, Ismael Juma <mlists@juma.me.uk>, Luke Chen <showuon@gmail.com>",5
"MINOR: Don't ignore deletion of partition metadata file and log topic id clean-ups (#10761)Log if deletion fails and don't expose log topic id for mutability outside of `assignTopicId()`.Also remove an unnecessary parameter in `PartitionTest`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",5
"KAFKA-4851: only search available segments during Segments.segments(from, to)restrict the locating of segments in `Segments#segments(..)` to only the segments that are currently available, i.e., rather than searching the hashmap for many segments that don't exist.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2645 from dguy/session-windows-testing",3
KAFKA-9514; The protocol generator generated useless condition when a field is made nullable and flexible version is used (#8793)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-9274: Mark `retries` config as deprecated and add new `task.timeout.ms` config (#8864) - part of KIP-572 - deprecates producer config `retries` (still in use) - deprecates admin config `retries` (still in use) - deprecates Kafka Streams config `retries` (will be ignored) - adds new Kafka Streams config `task.timeout.ms` (follow up PRs will leverage this new config)Reviewers: John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>, Randall Hauch <randall@confluent.io>",5
MINOR: Replace for within for each; replace if-elseif with matchIn some Places for the loop was used but it can be replaced by the for each.In One file if else if else was used so I replaced the same with match.Author: Akash Sethi <akash.sethi@knoldus.in>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2435 from akashsethi24/trunk,1
"MINOR: Include security configs for topic delete in system tests (#9142)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6145: KIP-441: Enforce Standby Task Stickiness (#8696)We should treat standbys similarly to active stateful tasks andre-assign them to instances that are already caught-up on themwhile we warm them up on the desired destination, instead ofimmediately moving them to the destination.Reviewers: Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-5454: Add a new Kafka Streams example IoT orientedAdded a Kafka Streams example (IoT oriented) using ""tumbling"" windowAuthor: Paolo Patierno <ppatierno@live.com>Author: ppatierno <ppatierno@live.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Michael G. Noll <michael@confluent.io>Closes #3352 from ppatierno/stream-temperature-example",5
"KAFKA-9460: Enable only TLSv1.2 by default and disable other TLS protocol versions (KIP-553) (#7998)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-1502 source jar is empty patch by Jun Rao reviewed by Joe Stein,5
"KAFKA-6813: Remove deprecated APIs in KIP-182, Part I (#4919)I'm breaking KAFKA-6813 into a couple of ""smaller"" PRs and this is the first one. It focused on:Remove deprecated APIs in KStream, KTable, KGroupedStream, KGroupedTable, SessionWindowedKStream, TimeWindowedKStream.Also found a couple of overlooked bugs while working on them:2.a) In KTable.filter / mapValues without the additional parameter indicating the materialized stores, originally we will not materialize the store. After KIP-182 we mistakenly diverge the semantics: for KTable.mapValues it is still the case, for KTable.filter we will always materialize.2.b) In XXStream/Table.reduce/count, we used to try to reuse the serdes since their types are pre-known (for reduce it is the same types for both key / value, for count it is the same types for key, and Long for value). This was somehow lost in the past refactoring.2.c) We are enforcing to cast a Serde<V> to Serde<VR> for XXStream / Table.aggregate, for which the returned value type is NOT known, such the enforced casting should not be applied and we should require users to provide us the value serde if they believe the default ones are not applicable.2.d) Whenever we are creating a new MaterializedInternal we are effectively incrementing the suffix index for the store / processor-node names. However in some places this MaterializedInternal is only used for validation, so the resulted processor-node / store suffix is not monotonic.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-4035; AclCommand should allow Describe operation on groupsAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #1723 from omkreddy/KAFKA-4035",1
MINOR: Upgrade to Scala 2.12.13 (#9981)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-12892: Disable testChrootExistsAndRootIsLocked (#10820)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"KAFKA-3422: Add overloading functions without serdes in Streams DSLAlso include:1) remove streams specific configs before passing to producer and consumer to avoid warning message;2) add `ConsumerRecord` timestamp extractor and set as the default extractor.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Michael G. Noll, Ewen Cheslack-PostavaCloses #1093 from guozhangwang/KConfigWarn",5
"MINOR: Make it explicit in consumer docs that poll() is needed for callback to run (#4480)Make it clear in the docs that the rebalance listener is only invoked during an active call to `poll()`. Plus a few additional doc cleanups.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: Use Gradle's JUnitPlatform for upgrade-system-tests modules (#9922)Add a runtime dependency on the jupiter engine to avoid failuresduring `./gradlew unitTest/integrationTest/test` for `upgrade-system-tests-*`.Also remove `connect` and `examples` from the JUnit 5 blocklist since theycontains no tests.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"KAFKA-4153: Fix incorrect KStream-KStream join behavior with asymmetric time windowThe contribution is my original work and I license the work to the project under the project's open source license.guozhangwangAuthor: Elias Levy <fearsome.lucidity@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #1846 from eliaslevy/KAFKA-4153",1
"KAFKA-12579: Remove various deprecated clients classes/methods for 3.0 (#10438)* Remove `ExtendedSerializer` and `ExtendedDeserializer`, deprecated since 2.1.The extra functionality was also made available in `Serializer` and `Deserializer`.* Remove `close(long, TimeUnit)` from the producer, consumer and admin client,deprecated since 2.0 for the consumer and 2.2 for the rest. The replacement is `close(Duration)`.* Remove `ConsumerConfig.addDeserializerToConfig` and `ProducerConfig.addSerializerToConfig`,deprecated since 2.7 with no replacement. These methods were not intended to be public APIand are likely not used much (if at all).* Remove `NoOffsetForPartitionException.partition()`, deprecated since 0.11. `partitions()`should be used instead.* Remove `MessageFormatter.init(Properties)`, deprecated since 2.7. The `configure(Map)`method should be used instead.* Remove `kafka.common.MessageFormatter`, deprecated since 2.7.`org.apache.kafka.common.MessageFormatter` should be used instead.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
KAFKA-676 Change the build script for the core sub project to create a test jar. Reviewed by Neha.,3
KAFKA-1512 Fixes for limit the maximum number of connections per ip address patch by Jeff Holoman reviewed by Jay Krepps and Gwen Shapira,1
"MINOR: add missing quickstart.html file (#9722)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: Fix KTable-KTable foreign-key join example (#9683)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-12254: Ensure MM2 creates topics with source topic configs (#10217)MM2 creates new topics on the destination cluster with default configurations. It has an async periodic task to refresh topic configurations from the source to destination. However, this opens up a window where the destination cluster has data produced to it with default configurations. In the worst case, this could cause data loss if the destination topic is created without the right cleanup.policy. This commit fixes the above issue by ensuring that the right configurations are supplied to AdminClient#createTopics when MM2 creates topics on the destination cluster.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-4703: Test with two SASL_SSL listeners with different JAAS contextsTests broker with multiple SASL mechanisms with different endpoints for different mechanisms. Each endpoint uses its own JAAS context.Author: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Rajini Sivaram, Ismael JumaCloses #2506 from baluchicken/KAFKA-4703",5
kafka-1389; transient unit test failure in ProducerFailureHandlingTest; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,3
KAFKA-12633: Remove deprecated APIs in TopologyTestDriver (#10508)As well as related test classes.Reviewers: John Roesler <vvcephei@apache.org>,3
KAFKA-1577; Follow-up patch: Fix exception in connection-quotas while shutting down by forcing key-cancellation; reviewed by Joel Koshy and Neha Narkhede,1
KAFKA-13436: Omitted BrokerTopicMetrics metrics in the documentation (#11473)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
TopicCount.constructTopicCount isn't thread-safe; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-379git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1386987 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Typo in documentation of topic config removalAuthor: Ján Koščo <3k.stanley@gmail.com>Reviewers: Ismael Juma, Grant Henke, Guozhang WangCloses #768 from s7anley/trunk",1
"KAFKA-8389: Remove redundant bookkeeping from MockProcessor (#6761)Remove processedKeys / processedValues / processedWithTimestamps as they are covered with processed already.Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-13837; Return an error from Fetch if follower is not a valid replica (#12150)When a partition leader receives a `Fetch` request from a replica which is not in the current replica set, the behavior today is to return a successful fetch response, but with empty data. This causes the follower to retry until metadata converges without updating any state on the leader side. It is clearer in this case to return an error, so that the metadata inconsistency is visible in logging and so that the follower backs off before retrying. In this patch, we use `UNKNOWN_LEADER_EPOCH` when the `Fetch` request includes the current leader epoch. The way we see this is that the leader is validating the (replicaId, leaderEpoch) tuple. When the leader returns `UNKNOWN_LEADER_EPOCH`, it means that the leader does not expect the given leaderEpoch from that replica. If the request does not include a leader epoch, then we use `NOT_LEADER_OR_FOLLOWER`. We can take a similar interpretation for this case: the leader is rejecting the request because it does not think it should be the leader for that replica. But mainly these errors ensure that the follower will retry the request.As a part of this patch, I have refactored the way that the leader updates follower fetch state. Previously, the process is a little convoluted. We send the fetch from `ReplicaManager` down to `Partition.readRecords`, then we iterate over the results and call `Partition.updateFollowerFetchState`. It is more straightforward to update state directly as a part of `readRecords`. All we need to do is pass through the `FetchParams`. This also prevents an unnecessary copy of the read results.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Fix redundant typos in comments and javadocs (#8693)* MINOR: Fix typo in RecordAccumulator* MINOR: Fix typo in several filesReviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-5309: Stores not queryable after one thread died - introduces a new thread state DEAD - ignores DEAD threads when queryingAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #3140 from mjsax/kafka-5309-stores-not-queryable",5
"KAFKA-9027, KAFKA-9028: Convert create/delete acls requests/response to use generated protocol (#7725)Also add support for flexible versions to both protocol types.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Colin Patrick McCabe <cmccabe@apache.org>Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>Co-authored-by: Jason Gustafson <jason@confluent.io>",5
KAFKA-348 merge trunk to branch 1239902:1310937 patch by Joe Stein reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1344526 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: remove ""auto.commit.interval.ms"" from ""Manual Offset Control"" exampleAuthor: xuwei-k <6b656e6a69@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1578 from xuwei-k/Manual-Offset-Control-example",1
KAFKA-3136: Rename KafkaStreaming to KafkaStreamsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen ShapiraCloses #800 from guozhangwang/KRename,5
"KAFKA-3098: ""partition.assignment.strategy"" appears twice in documentationAuthor: David Jacot <david.jacot@gmail.com>Reviewers: Gwen ShapiraCloses #774 from dajac/KAFKA-3098",2
"Setting broker state as running after publishing to ZKjunraoCurrently, the broker state is set to running before it registers itself in ZooKeeper.  This is too early in the broker lifecycle.  If clients use the broker state as an indicator that the broker is ready to accept requests, they will get errors.  This change is to delay setting the broker state to running until it's registered in ZK.Author: Roger Hoover <roger.hoover@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1426 from theduderog/broker-running-after-zk",1
"MINOR: Improve Kafka documentationImprove the documentation by fixing typos, punctuations, and correcting the content.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #778 from vahidhashemian/typo05/fix_documentation_typos",2
Minor fix for delete topic,4
MINOR: do not create a StandbyTask if there is no state store in the taskguozhangwangAn optimization which may reduce unnecessary poll for standby tasks.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #535 from ymatsuda/remove_empty_standby_task,5
KAFKA-4140: Upgrade to ducktape 0.6.0 and make system tests parallel friendlyUpdates to take advantage of soon-to-be-released ducktape features.Author: Geoff Anderson <geoff@confluent.io>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1834 from granders/systest-parallel-friendly,5
KAFKA-2253; fix deadlock between removeWatchersLock and watcher operations list lock; reviewed by Onur Karaman and Jiangjie Qin,4
CompressionUtils introduces a GZIP header while compressing empty message sets KAFKA-109; patched by Neha; reviewed by Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159459 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-2221: Log the real exception which triggered a reconnectThe commit here improves the logging in SimpleConsumer to log the real reason why a reconnect was attempted. Relates to https://issues.apache.org/jira/browse/KAFKA-2221.The same patch was submitted a while back but wasn't merged because SimpleConsumer was considered deprecated and users' aren't expected to use it. However, more and more users in the user mailing list are running into this log message but have no way to understand what the root cause is. So IMO, this change still adds value  to such users who are using SimpleConsumer.Author: Jaikiran Pai <jaikiran.pai@gmail.com>Reviewers: Jiangjie Qin, Ismael Juma, Guozhang WangCloses #138 from jaikiran/kafka-2221",1
"MINOR: only request rejoin and log if necessary for metadata snapshot and subscription checks (#11112)Since now we call do not necessarily complete the rebalance within a poll call, we may keep checking the rejoinNeededOrPending which hits either of the conditions and returns true, but then returns early, resulting in flooding log entries. This PR would only log/set the flag when it was not set yet, effectively only logging for the first time.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-1902; fix MetricName so that Yammer reporter can work correctly; patched by Jun Rao; reviewed by Manikumar Reddy, Manikumar Reddy and Joel Koshy",1
"MINOR: improve Streams checkstyle and code cleanup (#5954)Reviewers: Guozhang Wang <guozhang@confluent.io>, Nikolay Izhikov <nIzhikov@gmail.com>, Ismael Juma <ismael@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-13542: add rebalance reason in Kafka Streams (#11804)Add rebalance reason in Kafka Streams.Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Fix MirrorConnectorsIntegrationTest (#9341)In `setup()`, `primary` was checked to be running twice, instead of `backup`.Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
"KAFKA-2000; Delete topic should also delete consumer offsets.Author: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #1850 from omkreddy/KAFKA-2700-DELETE",4
"KAFKA-9583; Use topic-partitions grouped by node to send OffsetsForLeaderEpoch requests (#8077)In `validateOffsetsAsync` in t he consumer, we group the requests by leader node for efficiency. The list of topic-partitions are grouped from `partitionsToValidate` (all partitions) to `node` => `fetchPostitions` (partitions by node). However, when actually sending the request with `OffsetsForLeaderEpochClient`, we use `partitionsToValidate`, which is the list of all topic-partitions passed into `validateOffsetsAsync`. This results in extra partitions being included in the request sent to brokers that are potentially not the leader for those partitions.This PR fixes the issue by using `fetchPositions`, which is the proper list of partitions that we should send in the request. Additionally, a small typo of API name in `OffsetsForLeaderEpochClient` is corrected (it originally referenced `LisfOffsets` as the API name).Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
standardizing json values stored in ZK; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-755,5
"KAFKA-2666: Docs: Automatically generate documentation from config classes…the way we always planned toAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Jun Rao, Guozhang WangCloses #382 from gwenshap/KAFKA-2666",5
"MINOR: Replace EasyMock with Mockito in connect:file (#11471)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
"MINOR: Update dependencies.gradle, Dockerfile, version.py, and bash.sh for 2.4.1 upgrade (#8387)These files were missed in the 2.4.1 releaseReviewers: Ismael Juma <ismael@confluent.io>",5
KAFKA-12462: proceed with task revocation in case of thread in PENDING_SHUTDOWN (#10311)Always invoke TaskManager#handleRevocation when the thread is in PENDING_SHUTDOWNReviewers: Walker Carlson <wcarlson@confluent.io>,5
"KAFKA-5272; Policy for Alter Configs (KIP-133)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3210 from ijuma/kafka-5272-improve-validation-for-describe-alter-configs",5
"MINOR: Add logging when commitSync fails in StreamTaskWhen `consumer.commitSync` fails in `StreamTask`, the `CommitFailedException` bubbles up to [here](https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java#L780) and swallowed.  It'd be great if we knew which offsets failed to commit so that we may rewind our consumer.Author: J$ <jmonette@homeaway.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2514 from jmoney8080/jsm.addCommitLogLogging",2
MINOR: Fixed typos in KGroupedTable Javadoc (#4552)* Fix typo: substractor -> subtractor* Fix typo: javadoc references deprecated overloadReviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-7763; Calls to commitTransaction and abortTransaction should not block indefinitely  (#6066)Currently, commitTransaction and abortTransaction wait indefinitely for the respective operation to be completed. This patch uses the producer's max block time to limit the time that we will wait. If the timeout elapses, we raise a TimeoutException, which allows the user to either close the producer or retry the operation.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Update the kafka-reassign-partitions script command in documentation (#12237)Reviewers: Luke Chen <showuon@gmail.com>,2
"MINOR: Rename RecordBatch to ProducerBatch to free the name for KIP-98Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2646 from hachikuji/rename-record-batch",5
"MINOR: Use thread name and task for sensor name (#5111)Changes to keep the operation name as is and make the sensor name unique.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-1319; kafka jar doesn't depend on metrics-annotation any more; patched by Jun Rao; reviewed by Neha Narkhede,5
"KAFKA-4769: Add Float serializer, deserializer, serdeAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Dongjin Lee, Eno Thereska, Damian Guy, Colin P. McCabe, Matthas J. Sax, Guozhang WangCloses #2554 from miguno/KAFKA-4769",5
Leverage new ConfigSetter#close method to properly open/close filter (#6730)Uses the close method added in KIP-453 to properly init & close RocksObjects in RocksDBStoreTestReviewers: Bill Bejeck <bbejeck@gmail.com>,5
KAFKA-8760; New Java Authorizer API (KIP-504) (#7268)New Java Authorizer API and a new out-of-the-box authorizer (AclAuthorizer) that implements the new interface.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
Minor: Fixes to Selector's javadocAuthor: Ismael Juma <ismael@juma.me.uk>Closes #126 from ijuma/minor-selector-javadoc-fixes and squashes the following commits:a26f529 [Ismael Juma] Minor fixes to Selector's javadoc,2
MINOR: Do not log retriable offset commit exceptions as errors (#5904)Reviewers: Jason Gustafson <jason@confluent.io>,5
"kafka-1073; CheckReassignmentStatus is broken; patched by Jun Rao; reviewed by Guozhang Wang, Swapnil Ghike and Neha Narkhede",5
trivial fix to make output of ConsumerOffsetChecker sortedgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1229876 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-320 testZKSendWithDeadBroker fails intermittently due to ZKNodeExistsException; patched by nehanarkhede; reviewed by junrao and prashanth menongit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1310937 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-13090: Improve kraft snapshot integration testCheck and verify generated snapshots for the controllers and thebrokers. Assert reader state when reading last log append time.Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"MINOR: INFO log4j when request re-join (#9068)While debugging a rebalance scenario I found that inside rejoinNeededOrPending when we trigger rebalance due to metadata or subscription changes it is not logged, and hence it's actually a bit tricky to find out the reason of the triggered rebalance. I'm adding two INFO log4j entries to fill in the gap.Other requestRejoin() calls are already covered.Reviewers: Boyang Chen <boyang@confluent.io>",5
"KAFKA-9498; Topic validation during the topic creation triggers unnecessary TopicChange events (#8062)This PR avoids generating unnecessary TopicChange events during the topic validation. It does so by adding a registerWatch field in the GetChildrenRequest request. This allows to not register the watch when topics are queried from the topic validation logic.Reviewers: Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-3983; Add additional information to Acceptor debug messageAdd additional information to Acceptor debug message upon connection acceptanceAuthor: rnpridgeon <ryan.n.pridgeon@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1648 from rnpridgeon/trunk,1
KAFKA-12703; Allow unencrypted private keys when using PEM files (#11916)Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-229 Patch from Joe Stein. Log full exception stack trace instead of just message.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1226549 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10023: Enforce broker-wide and per-listener connection creation… (#8768)Implements the part of KIP-612 that adds broker configurations for broker-wide and per-listener connection creation rate limits and enforces these limits.Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5363 (KIP-167): implementing bulk load, restoration event notificationAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3325 from bbejeck/KAFKA-5363_add_ability_to_batch_restore",1
"KAFKA-5216: Fix peekNextKey in cached window/session store iteratorsguozhangwang mjsax dguyAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #3016 from xvrl/kafka-5216",5
KAFKA-3267; Describe and Alter Configs Admin APIs (KIP-133)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3076 from ijuma/kafka-3267-describe-alter-configs-protocol,5
"KAFKA-6620: Fix documentation about 'exactly_once'Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4380; Document the purpose of clean shutdown file in the code.Remove the previous TODO to remove the clean shutdown file with some of the discussion from https://github.com/apache/kafka/pull/2104.Author: Holden Karau <holden@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3742 from holdenk/KAFKA-4380-document-clean-shutdown-file,4
"KAFKA-12508: Emit records with same value and same timestamp (#10360)Emit on change introduced in Streams with KIP-557 might lead todata loss if a record is put into a source KTable and emitteddownstream and then a failure happens before the offset could becommitted. After Streams rereads the record, it would find a recordwith the same key, value and timestamp in the KTable (i.e. the samerecord that was put into the KTable before the failure) and notforward it downstreams. Hence, the record would never be processeddownstream of the KTable which breaks at-least-once and exactly-onceprocessing guarantees.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",4
KAFKA-10893 Increase target_messages_per_sec of ReplicaScaleTest to reduce the run time (#9797)Reviewers: David Arthur <mumrah@gmail.com>,1
"MINOR: Log client disconnect events at INFO level (#11449)Client disconnects are crucial events for debugging. The fact that we only log them at DEBUG/TRACE means we rarely have them available outside of a testing context. This patch therefore increases verbosity to INFO level. In practice, we already have backoff configurations which should prevent these logs from getting too spammy. Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: Fix spelling and grammar issues in ReplicaFetcherThread detailed commentI noticed them while looking at the recent commit:https://github.com/apache/kafka/commit/87eccb9a3bea56e5d7d5696aaddef1421f038903Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Guozhang WangCloses #829 from ijuma/fix-comments-in-replica-fetcher-thread",0
MINOR: ACLs for secured cluster system tests (#9378)This PR adds missing broker ACLs required to create topics and SCRAM credentials when ACLs are enabled for a system test. This PR also adds support for using PLAINTEXT as the inter broker security protocol when using SCRAM from the client in a system test with a secured cluster-- without this it would always be necessary to set both the inter-broker and client mechanisms to a SCRAM mechanism. Also contains some refactoring to make assumptions clearer.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR: refactor build method to extract methods from if statementsAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3833 from bbejeck/MINOR_extract_methods_from_build,4
"KAFKA-8791: RocksDBTimestampedStore should open in regular mode by default (#7201)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>, Richard Yu <yohan.richard.yu@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Handle Metadata v0 all topics requests during parsing (#6300)Use of `MetadataRequest.isAllTopics` is not consistently defined for all versions of the api. For v0, it evaluates to false. This patch makes the behavior consistent for all versions.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6772: Load credentials from ZK before accepting connections (#4867)Start processing client connections only after completing KafkaServer initialization to ensure that credentials are loaded from ZK into cache before authentications are processed. Acceptors are started earlier so that bound port is known for registering in ZK.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-188 Support multiple data directories. Patch reviewed by Neha and Jun.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1405102 13f79535-47bb-0310-9956-ffa450edef68,5
KAFKA-13794; Fix comparator of `inflightBatchesBySequence` in `TransactionManager` (#11991)Fixes a bug in the comparator used to sort producer inflight batches for a topic partition. This can cause batches in the map `inflightBatchesBySequence` to be removed incorrectly: i.e. one batch may be removed by another batch with the same sequence number. This leads to an `IllegalStateException` when the inflight request finally returns. This patch fixes the comparator to check equality of the `ProducerBatch` instances if the base sequences match.Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Use commitId property if setThis allows a build system to set the correct commit ID when .git/HEAD would be wrongif there are local commits for build purposes.Author: Max Zheng <mzheng@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3606 from maxzheng/read-commit@trunk",1
"MINOR: Remove deprecated KTable#writeAs, print, foreach, to, through (#4910)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Use the correct processor id in the processor thread nameThis restores the behaviour before 1265d7cb7.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #294 from ijuma/fix-processor-thread-name,0
"MINOR: Update log statements in alterBrokerConfigs/alterTopicConfigs methodsCurrent below log statements are not useful. This PR logs readable/masked configs during alterBrokerConfigs/alterTopicConfigs method call.`[Admin Manager on Broker 1]: Updating topic test with new configuration kafka.server.KafkaConfigc9ba35e3`Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>Closes #9824 from omkreddy/admin-logs",2
support changing host/port of a broker; patched by David Arthur; reviewed by Jun Rao; kafka-474git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396116 13f79535-47bb-0310-9956-ffa450edef68,4
KAFKA-7067; Include new connector configs in system test assertion (#5242)The new connector configs added in  KIP-297 and KIP-298 need to be updated in the connect_rest_test.py so that the expected results match the actual.,3
"KAFKA-9331: Add a streams specific uncaught exception handler (#9487)This PR introduces a streams specific uncaught exception handler that currently has the option to close the client or the application. If the new handler is set as well as the old handler (java thread handler) will be ignored and an error will be logged.The application shutdown is achieved through the rebalance protocol.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Leah Thomas <lthomas@confluent.io>, John Roesler <john@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
KAFKA-13209: Upgrade jetty-server to fix CVE-2021-34429Upgrading to 9.4.43.v20210629Release notes: https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.43.v20210629Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
AsyncProducer shutdown logic causes data loss; KAFKA-116; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160946 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Iterate over partitions only once when building LeaderAndIsrRequest (#8915)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: fix flaky ConsumerBounceTest.testCloseFixes `java.util.concurrent.ExecutionException: java.lang.AssertionError: Close finished too quickly 5999`.The close test sets a close duration in milliseconds, but measures the time taken in nanoseconds. This leads to small error due to the resolution in each, where the close is deemed to have taken too little time.When I measured the start and end with nanoTime, I found the time taken to close was `5999641566 ns (5999.6ms)` which seems close enough to be a resolution error. I've run the test 50 times and have not hit the ""Close finished too quickly"" issue again, whereas previously I hit a failure pretty quickly.Author: Lucas Bradstreet <lucas@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #7683 from lbradstreet/flaky-consumer-bounce-test",3
"MINOR: Proactively update producer topic access time. (#7672)Changes the ProducerMetadata to longer record a sentinel TOPIC_EXPIRY_NEEDS_UPDATE upon topic map emplacement, and instead set the expiry time directly. Previously the expiry time was being updated for all touched topics after a metadata fetch was processed, which could be seconds/minutes in the future.Additionally propagates the current time further in the Producer, which should reduce the total number of current-time calls.Reviewers: Ismael Juma <ismael@juma.me.uk>,  Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-10841: Extract conversion from LogReadResult to FetchPartitionData (#9743)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Do not swallow exception when collecting PIDs (#8914)During Streams' system tests the PIDs of the Streamsclients are collected. The method the collects the PIDsswallows any exception that might be thrown by thessh_capture() function. Swallowing any exceptionsmight make the investigation of failures harder,because no information about what happened are recorded.Reviewers: John Roesler <vvcephei@apache.org>",5
"KAFKA-3306: Change metadata response to include required additional fi……elds- Adds boolean type to the protocol- Allows protocol arrays to be null (optionally)- Adds support to ask for no topics in the metadata request- Adds new fields to the Metadata response protocol- Adds server code to handle new fields   - Support no-topic metadata requests   - Track controller id in the metadata cache   - Check if a topic is considered internal   - Included rack information if present   - Include all replicas and ISRs, even if node is down- Adds test code to test new functionality independent of the clientAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ismael Juma, Ashish SinghCloses #1095 from granthenke/metadata-changes",5
"MINOR: Use Exit.addShutdownHook instead of directly adding hooks to Runtime (#12283)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Igor Soarez  <soarez@apple.com>, Kvicii <kvicii.yu@gmail.com>",1
MINOR: Remove a couple of redundant `CoreUtils.rm` methodsAlso:* Rename remaining `CoreUtils.rm` to `delete` for consistency* Use `try with resources` in `Utils` to simplify code* Silence compiler warning due to exception catch clause in `TestUtils`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1153 from ijuma/remove-redundant-core-utils-rm,4
KAFKA-12451: Remove deprecation annotation on long-based read operations in WindowStore (#10296)Complete https://cwiki.apache.org/confluence/display/KAFKA/KIP-667%3A+Remove+deprecated+methods+from+ReadOnlyWindowStore by removing deprecation annotation on long-based read operations in WindowStore.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
kafka-1419 (followup); cross build for scala 2.11; patched by Stevo Slavic; reviewed by Jun Rao,5
"KAFKA-1686; Implement SASL/KerberosThis PR implements SASL/Kerberos which was originally submitted by harshach as https://github.com/apache/kafka/pull/191.I've been submitting PRs to Harsha's branch with fixes and improvements and he has integrated all, but the most recent one. I'm creating this PR so that the Jenkins can run the tests on the branch (they pass locally).Author: Ismael Juma <ismael@juma.me.uk>Author: Sriharsha Chintalapani <harsha@hortonworks.com>Author: Harsha <harshach@users.noreply.github.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Parth Brahmbhatt <brahmbhatt.parth@gmail.com>, Jun Rao <junrao@gmail.com>Closes #334 from ijuma/KAFKA-1686-V1",5
"KAFKA-4863; Querying window store may return unwanted keysMake sure that the iterator returned from `WindowStore.fetch(..)` only returns matching keys, rather than all keys that are a prefix match.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2662 from dguy/kafka-4863",0
KAFKA-9868: Reduce number of transaction log partitions for embed broker (#8522)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-4060; Follow-up: Throw exceptions when internal topics to create already exist with unexpected number of partitionsRe-branched the trunk and applied the changes to the new branch to simplify commit log.Author: Hojjat Jafarpour <hojjat@Hojjat-Jafarpours-MBP.local>Reviewers: Ismael Juma, Damian Guy, Eno Thereska, Guozhang WangCloses #2389 from hjafarpour/KAFKA-4060-Remove-ZkClient-dependency-in-Kafka-Streams-followup-from-trunkAddress Ismael's comments upon merging",4
MINOR: Consistent terminal period in Errors.defaultExceptionMessage (#3909)Reviewers: Mickael Maison <mickael.maison@gmail.com>,0
"KAFKA-6854; Handle batches deleted during log cleaning of logs with txns (#4962)Log cleaner grows buffers when result.messagesRead is zero. This contains the number of filtered messages read from source which can be zero when transactions are used because batches may be discarded. Log cleaner incorrectly assumes that messages were not read because the buffer was too small and attempts to double the buffer size unnecessarily, failing with an exception if the buffer is already max.message.bytes. Additional check for discarded batches has been added to avoid growing buffers when batches are discarded.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-5743; Ducktape services should use subdirs of /mntAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3680 from cmccabe/KAFKA-5743,5
"MINOR: onControllerResignation should be invoked if triggerControllerMove is calledAlso update the test to be simpler since we can use a mock event to simulate the issuemore easily (thanks Jun for the suggestion). This should fix two issues:1. A transient test failure due to a NPE in ControllerFailoverTest.testMetadataUpdate:```textCaused by: java.lang.NullPointerExceptionat kafka.controller.ControllerBrokerRequestBatch.addUpdateMetadataRequestForBrokers(ControllerChannelManager.scala:338)at kafka.controller.KafkaController.sendUpdateMetadataRequest(KafkaController.scala:975)at kafka.controller.ControllerFailoverTest.testMetadataUpdate(ControllerFailoverTest.scala:141)```The test was creating an additional thread and it does not seem like it was doing theappropriate synchronization (perhaps this became more of an issue after we changedthe Controller to be single-threaded and changed the locking)2. Setting `activeControllerId.set(-1)` in `triggerControllerMove` causes `Reelect` not to invoke `onControllerResignation`. Among other things, this causes an `IllegalStateException` to be thrown when `KafkaScheduler.startup` is invoked for the second time without the corresponding `shutdown`. We now simply call `onControllerResignation` as part of `triggerControllerMove`.Finally, I included a few clean-ups:1. No longer update the broker state in `onControllerFailover`. This is no longer neededsince we removed the `RunningAsController` state (KAFKA-3761).2. Trivial clean-ups in KafkaController3. Removed unused parameter in `ZkUtils.getPartitionLeaderAndIsrForTopics`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #2935 from ijuma/on-controller-resignation-if-trigger-controller-move",4
"MINOR: Fix sensor retrieval in stand0by task's constructor (#7632)We should not use StreamsMetricsImpl. threadLevelSensor directly which would only retrieve the sensor but would not add any metrics to the sensor. Generally speaking we should always use the corresponding-level Metrics class (e.g. ThreadMetrics) to get the sensors which are populated with metrics.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
kafka-1799; ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG doesn't work; patched by Manikumar Reddy; reviewed by Jun Rao,1
KAFKA-828 Preferred Replica Election does not delete the admin path on controller failover; reviewed by Neha Narkhede and Jun Rao,0
"KAFKA-6738: Implement error handling for source and sink tasks (KIP-298)This PR implements the features described in this KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-298%3A+Error+Handling+in+ConnectThis PR changes the Connect framework to allow it to automatically deal with errors encountered while processing records in a Connector. The following behavior changes are introduced here:**Retry on Failure**: Retry the failed operation a configurable number of times, with backoff between each retry.**Task Tolerance Limits**: Tolerate a configurable number of failures in a task.We also add the following ways to report errors, along with sufficient context to simplify the debugging process:**Log Error Context**: The error information along with processing context is logged along with standard application logs.**Dead Letter Queue**: Produce the original message into a Kafka topic (applicable only to sink connectors).New **metrics** which will monitor the number of failures, and the behavior of the response handler are added.The changes proposed here **are backward compatible**. The current behavior in Connect is to kill the task on the first error in any stage. This will remain the default behavior if the connector does not override any of the new configurations which are provided as part of this feature.Testing: added multiple unit tests to test the retry and tolerance logic.Author: Arjun Satish <arjun@confluent.io>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5065 from wicknicks/KAFKA-6378",5
set the rejoinNeeded in listener's onSuccess,1
KAFKA-1431 ConsoleConsumer - Option to clean zk consumer path;reviewed by Neha Narkhede and Jun Rao,4
"MINOR: Allow schedule and commit in MockProcessorContextThis change allows for testing custom Processors and Transformers that call `schedule` and `commit` using KStreamTestDriver, by _not_ throwing `UnsupportedOperationException`.This PR is my original work.Author: Mats Julian Olsen <mats@plysjbyen.net>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3992 from mewwts/allow-schedule-and-commit",1
"MINOR: Remove SubscriptionState.Listener and replace with assignmentId tracking (#6559)We have not had great experience with listeners. They make the code harder to understand because they result in indirectly maintained circular dependencies. Often this leads to tricky deadlocks when we try to introduce locking. We were able to remove the Metadata listener in KAFKA-7831. Here we do the same for the listener in SubscriptionState.Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
Fix bug in ByteBufferSend that lead to incorrect complete() method.,0
KAFKA-1910; Fix two bugs on MemoryRecords and KafkaConsumer; reviewed by Onur Karaman,0
"KAFKA-2998: log warnings when client is disconnected from bootstrap brokersAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke, Guozhang WangCloses #769 from hachikuji/KAFKA-2998",5
"KAFKA-13682; KRaft Controller auto preferred leader election (#11893)Implement auto leader rebalance for KRaft by keeping track of the set of topic partitions which have a leader that is not the preferred replica. If this set is non-empty then schedule a leader balance event for the replica control manager.When applying PartitionRecords and PartitionChangeRecords to the ReplicationControlManager, if the elected leader is not the preferred replica then remember this topic partition in the set of imbalancedPartitions.Anytime the quorum controller processes a ControllerWriteEvent it schedules a rebalance operation if the there are no pending rebalance operations, the feature is enabled and there are imbalance partitions.This KRaft implementation only supports the configurations properties auto.leader.rebalance.enable and leader.imbalance.check.interval.seconds. The configuration property leader.imbalance.per.broker.percentage is not supported and ignored.Reviewers: Jun Rao <junrao@gmail.com>, David Arthur <mumrah@gmail.com>",1
KAFKA-10351: Add tests for IOExceptions for GlobalStateManagerImpl/OffsetCheckpoint (#9121)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"Minor: Fix ps command example in docsProcess grep command has been updated. Previous ""ps  | grep server-1.properties""  command is showing nothing.Author: Satendra Kumar <satendra@knoldus.com>Reviewers: Gwen ShapiraCloses #1386 from satendrakumar06/patch-1",5
MINOR: Update max.connections.per.ip.overrides config docs (#4819)Add a validation check to make sure max.connections.per.ip.overrides is configured when max.connections.per.ip is set zero. Also clean up the config description.,5
"MINOR: fix comment in TimingWheel (#11480)Co-authored-by: jiangyuan04 <jiangyuan04@baidu.com>Reviewers: Luke Chen <showuon@gmail.com>, Jun Rao <junrao@gmail.com>",0
"KAFKA-4453 : Added code to separate controller connections and requests from the data plane (#5921)KIP-291 Implementation : Added code to separate controller connections and requests from the data plane.Tested with local deployment that the controller request are handled by the control plane and other requests are handled by the data plane.Also added unit tests in order to test the functionality.Author: Lucas Wang <luwang@linkedin.com>, Author: Mayuresh Gharat <gharatmayuresh15@gmail.com>Reviewers: Joel Koshy <jjkoshy@gmail.com>, Jun Rao <junrao@gmail.com>",2
"KAFKA-7532: Clean-up controller log when shutting down brokers (#5831)This line prints out (when empty):```[2018-10-23 12:19:59,977] INFO [Controller id=0] Removed ArrayBuffer() from list of shutting down brokers. (kafka.controller.KafkaController)```Use `mkString` to eliminate `ArrayBuffer` and only log if not empty.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
"kafka-1135; Code cleanup - use Json.encode() to write json data to zk; patched by Swapnil Ghike; reviewed by Neha Narkhede, Guozhang Wang and Jun Rao",5
"kafka-347; change number of partitions of a topic online; patched by Sriram Subramanian; reviewed by Neha Narkehede, Guozhang Wang, Joel Koshy and Jun Rao",4
KAFKA-12587 Remove KafkaPrincipal#fromString for 3.0 (#10447)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
trivial fix to make create topic script executablegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1231403 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1382. Update zkVersion on partition state update failures; reviewed by Neha Narkhede,0
MINOR: Double timeout passed to `producer.close` in `sendAndVerifyTimestamp`We have had transient failures in this method when Jenkins isoverloaded.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1359 from ijuma/increase-producer-close-timeout-in-test,3
"KAFKA-4744: Increased timeout for bounce testAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Matthias J. Sax, Guozhang WangCloses #2601 from enothereska/KAFKA-4744-bounce",3
MINOR: Increase security test timeouts for transient failures (#6760)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"KAFKA-10084: Fix EosTestDriver end offset (#8785)Check the uncommitted end offset after the committed end offset,so we can be sure never to miss a pending end-transaction marker.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
HOTFIX: group rebalance can throw illegal generation or rebalance in progressAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #370 from hachikuji/hotfix-rebalance-error,0
"KAFKA-7576; Fix shutdown of replica fetcher threads (#5875)ReplicaFetcherThread.shutdown attempts to close the fetcher's Selector while the thread is running. This in unsafe and can result in `Selector.close()` failing with an exception. The exception is caught and logged at debug level, but this can lead to socket leak if the shutdown is due to dynamic config update rather than broker shutdown. This PR changes the shutdown logic to close Selector after the replica fetcher thread is shutdown, with a wakeup() and flag to terminate blocking sends first.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: Improve error message in MirrorConnectorsIntegrationBaseTest (#10268)Reviewers: Mickael Maison <mickael.maison@gmail.com>,3
HOTFIX: checkstyle error in ProcessorStateManager (#8874)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-2485; Allow producer performance to take properties from a file…… via --consumer.config command line parameterAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ewen Cheslack-Postava, Onur KaramanCloses #174 from lindong28/KAFKA-2485",2
"KAFKA-4467: Run tests on travis-ci using dockerijuma ewencp cmccabe harshach Please review.Here is a sample run:https://travis-ci.org/raghavgautam/kafka/builds/191714520In this run 214 tests were run and 144 tests passed.I will open separate jiras for fixing failures.Author: Raghav Kumar Gautam <raghav@apache.org>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2376 from raghavgautam/trunk",1
"KAFKA-8839 : Improve streams debug logging (#7258)* log lock acquistion failures on the state store* Document required uniqueness of state.dir path* Move bunch of log calls around task state changes to DEBUG* More readable log messages during partition assignmentReviewers: Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Fix typo on introduction pageAuthor: ash <ashishg@qburst.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2259 from ashishg-qburst/intro,2
"KAFKA-6501; Dynamic broker config tests updates and metrics fix (#4539)1. Handle listener-not-found in MetadataCache since this can occur when listeners are being updated. To avoid breaking clients, this is handled in the same way as broker-not-available so that clients may retry.2. Set retries=1000 for listener reconfiguration tests to avoid transient failures when metadata cache has not been updated 3. Remove IdlePercent metric when Processor is deleted, add test4. Reduce log segment size used during reconfiguration to avoid timeout while waiting for log rolling5.Test markPartitionsForTruncation after fetcher thread resize6. Move per-processor ResponseQueueSize metric back to RequestChannel.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9231: Streams Threads may die from recoverable errors with EOS enabled (#7748)Fix three independent causes of threads dying:1. `ProducerFencedException` isn't properly handed while suspending a task, and leads to the thread dying.2. `IllegalStateException`: an internal assertion is violated because a store can get orphaned when an exception is thrown during initialization, again leading to the thread dying.3. `UnknownProducerIdException`: This exception isn't expected by the Streams code, so when we get it, the relevant thread dies. It's not clear whether we always need to catch this, and in the future, we won't expect it at all, but we are catching it now to be sure we're resilient if/when it happens. Important note: this might actually harm performance if the errors turn out to be ignorable, and we will now rebalance instead of ignoring them.Also, add missing test coverage for the exception handling code.Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Fix typo ""Exsiting"" -> ""Existing"" (#11547)Co-authored-by: Kurt Ostfeld <kurt@samba.tv>Reviewers: Kvicii <Karonazaba@gmail.com>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-3729: Revert adding Serde auto-config (#6630)* Revert ""MINOR: Add unit test for SerDe auto-configuration (#6610)""This reverts commit 172fbb2dd55144e2e44777174f970b56768e1777.* Revert ""[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)""This reverts commit e56ebbffca57741d398283e46073ed4170f8f927.The two merged PRs introduce a breaking change. Reverting to preserve backward compatibility. Jira ticket reopened.Reviewers: Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-1261 Make it possible to configure the metadata refresh.,5
"KAFKA-1919: Always update the metadata, when a metadata response is received to ensure we back off.",5
"Revert ""KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede""This reverts commit de432a09e632f78df9e580b51277f81582c3f026.",4
MINOR: log static broker configs in KRaft mode (#11067)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"HOT FIX: close RocksDB objects in correct order (#7076)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Re-applied old patch from KAFKA-139Had to make some additional changes based on further mainline work. LeavingKafkaProject.scala in place as a reference for now.,1
"KAFKA-5051; Avoid reverse DNS lookup to obtain hostname for TLSAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2835 from rajinisivaram/KAFKA-5051",5
"MINOR: Temporarily disable flaky Streams EOS system tests (#4355)Reviewers: Bill Bejeck <bill@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
kafka-1092; Add server config parameter to separate bind address and ZK hostname; patched by Roger Hoover; reviewed by Jun Rao,1
"MINOR: Use explicit type in AclCommandInference sometimes fails for this case.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #885 from ijuma/use-explicit-type-in-acl-command",1
kafka-2131; Update new producer javadocs with correct documentation links; patched by Manikumar Reddy; reviewed by Jun Rao,2
MINOR: Change topic-exists log for CreateTopics from INFO to DEBUG (#7666)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
KAFKA-5738; Upgrade note for cumulative count metric (KIP-187)Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4014 from rajinisivaram/MINOR-upgrade-KIP-187,5
KAFKA-4814; Enable ZK ACLs only when zookeeper.set.acl is setAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2845 from rajinisivaram/KAFKA-4814,5
"MINOR: Fix typo in CreateTopicsResponse.json (#8300)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Boyang Chen <boyang@confluent.io>",5
KAFKA-1845 KafkaConfig should use ConfigDef patch by Andrii Biletskyi reviewed by Gwen Shapira,5
KAFKA-1237 mirror maker using 08 consumer and 09 producer; reviewed by Jay Kreps and Joel Koshy,1
"KAFKA-13770: Restore compatibility with KafkaBasedLog using older Kafka brokers (#11946)The `retryEndOffsets(…)` method in `TopicAdmin` recently added (KAFKA-12879, #11797) to allow the `KafkaBasedLog.start()` method to retry any failures reading the last offsets for a topic. However, this introduce a regression when talking to older brokers (0.10.x or earlier).The `KafkaBasedLog` already had logic that expected an `UnsupportedVersionException` thrown by the admin client when a Kafka API is not available on an older broker, but the new retry logic in `TopicAdmin` did not account for this and wrapped the exception, thereby breaking the `KafkaBasedLog` logic and preventing startup.The fix is to propagate this `UnsupportedVersionException` from the `TopicAdmin.retryEndOffsets(…)` method. Added a new unit test that first replicated the problem before the fix, and verified the fix corrects the problem.",0
"KAFKA-8904: Improve producer's topic metadata fetching. (#7781)When the producer encouteres new topic(s), it now only fetches the metadata for the new topics. For cases where a producer interacts with a lot of topics, this reduces the cost for the topic being evicted from the cache, and during startup when populating the topic cache.Additionally adds a new producer configuration variable 'metadata.max.idle.ms', which controls how long topic metadata may be idle (i.e. not produced to) before it's finally discarded from the metadata cache.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, dengziming <dengziming1993@gmail.com>",5
kafka-1453; Add a channel queue jmx in Mirror Maker;  patched by Guozhang Wang; reviewed by Jun Rao,1
KAFKA-8410: Revert Part 1: processor context bounds (#8414) (#8595)This reverts commit 29e08fd2c2d3349ba5cbd8fe5a9d35a0cea02b85.There turned out to be more than expected problems with adding the generic parameters.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-2413; New consumer's subscribe(Topic...) api fails if called more than onceAuthor: Onur Karaman <okaraman@linkedin.com>Reviewers: Ashish Singh, Ismael Juma, Jason GustafsonCloses #122 from onurkaraman/KAFKA-2413 and squashes the following commits:cc340fc [Onur Karaman] fix ConsumerCoordinator updateConsumer",5
"KAFKA-8579: Expose RocksDB metrics (#7209)RocksDB metrics are added to the Kafka metrics. For each segmented state store onlyone set of metrics is exposed rather than one set of metrics for each segment.The metrics are not computed yet.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Explain the separate  upgrade paths for consumer groups and Streams (#7516)Document the upgrade path for the consumer and for Streams (note that they differ significantly).Needs to be cherry-picked to 2.4Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-1706; Add a byte bounded blocking queue utility; reviewed by Joel Koshy,1
"MINOR: Controller and async ZookeeperClient improvements* Fix issue in `retryRequestsUntilConnected` where the same responsecould appear multiple times (implies that we are lacking test coverage)* Introduce type member in AsyncRequest for the AsyncResponsetype and refactor the code to eliminate most downcasts* Remove a number of unnecessary collection copies in`retryRequestsUntilConnected`* Move ControllerContext to its own file* Rename getACL/setACL to getAcl/setAcl to match Kafka namingconvention* Replace tuple of 3 elements with case class in one place (weshould do this in other places too)* Extract `send` and `shouldWatch` from`ZooKeeperClient.handleRequests`* Use pattern matching instead of if/else chains in a few places (weshould do it in more places)* A couple of renames to avoid overloads and hence benefit frombetter type inference* Use Option and default arguments instead of passing null insome places* `Expired` is no longer a case class since it has no parameters,but it has state* Various minor clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Onur Karaman <okaraman@linkedin.com>Closes #4088 from ijuma/async-zkclient-cleanups",4
KAFKA-10759 Add ARM build stage (#9992)Only validation and unit test stages are enabledCo-authored-by: Peng.Lei <73098678+xiao-penglei@users.noreply.github.com>,1
MINOR: Remove unused foreign-key join class (#8547)Reviewers: John Roesler <john@confluent.io>,5
"KAFKA-7617: Add authorization primitives to security pageThis is a security page improvement that adds documentation about Kafka authorization primitives to the security page.Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Author: Viktor Somogyi <viktorsomogyi@gmail.com>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Srinivas <srinivas96alluri@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Mickael Maison <mickael.maison@gmail.com>Closes #5906 from viktorsomogyi/security-page-improvement",1
"MINOR: Ensure exception messages include partition/segment info when possible (#4907)Reviewers: Anna Povzner <anna@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KIP-551: Expose disk read and write metrics (#8569)Reviewers: David Arthur <mumrah@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",5
"KAFKA-5819; Add Joined class and relevant KStream join overloadsAdd the `Joined` class and the overloads to `KStream` that use it.Deprecate existing methods that have `Serde` paramsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3776 from dguy/kip-182-stream-join",5
"KAFKA-10163; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part I, Broker Changes) (#8933)This PR implements the broker side changes of KIP-599, except the changes of the Rate implementation which will be addressed separately. The PR changes/introduces the following:  - It introduces the protocol changes.  - It introduces a new quota manager ControllerMutationQuotaManager which is another specialization of the ClientQuotaManager.  - It enforces the quota in the KafkaApis and in the AdminManager. This part handles new and old clients as described in the KIP.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-13815: Avoid reinitialization for a replica that is being deleted (#12029)This PR tries to avoid the reinitialization of the leader epoch cacheand the partition metadata if the corresponding replica is being deleted.With this change, the asyncDelete method can run more efficiently,which means a StopReplica request with many partitions to be deleted can beprocessed more quickly.Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-3256; Add print.timestamp option to console consumer.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #949 from becketqin/KAFKA-3256,1
Add Snappy Compression as a Codec; patched by Joe Stein; reviewed by Neha Narkhede and Jun Rao; KAFKA-187git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1202045 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6474: remove KStreamTestDriver (#6732)The implementation of KIP-258 broke the state store methods in KStreamTestDriver.These methods were unused in this project, so the breakage was not detected.Since this is an internal testing utility, and it was deprecated and partially removed infavor of TopologyTestDriver, I opted to just complete the removal of the class.Reviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4422; Drop support for Scala 2.10 (KIP-119)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>Closes #2956 from ijuma/kafka-4422-drop-support-scala-2.10,4
kafka-900; ClosedByInterruptException when high-level consumer shutdown normally; patched by Jun Rao; reviewed by Neha Narkhede,5
"MINOR: Tighten FileRecords size checks to prevent overflow (#5332)Add some additional size validation to prevent overflows when using `FileRecords`. Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-6145: Remove check to reuse previous assignment (#8590)Since we cannot guarantee to reassign the correct number ofstand-by tasks when reusing the previous assignment and thereassignment is rather a micro-optimization, it is removedto keep the algorithm correct and simple.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: Update LinkedIn JVM tuning settingsThis is a follow-up as the previous update was missing some changes.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Todd Palino, Guozhang WangCloses #607 from ijuma/java-tuning-settings",1
Add ConfigurableProducerSpec to Trogdor for improved E2E latency tracking. (#9736)Reviewer: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-9769: ReplicaManager Partition.makeFollower Increases LeaderEpoch when ZooKeeper disconnect occurs (#8479)Skip the partition incurring ZooKeeper exception when becoming leader or follower.Reviewers: Joel Koshy <jjkoshy@gmail.com>,  Jun Rao <junrao@gmail.com>",1
MINOR: fix image 404s in streams docFixes image 404s in streams docs (e.g. https://kafka.apache.org/documentation/streams/developer-guide/interactive-queries.html).Related https://github.com/apache/kafka-site/pull/114Author: Joel Hamill <joel-hamill@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4389 from joel-hamill/fix-404-streams,0
"KAFKA-9200: ListOffsetRequest missing error response for v5 (#7704)ListOffsetResponse getErrorResponse is missing a a case for version 5, introducedby 152292994e4 and released in 2.3.0.```java.lang.IllegalArgumentException: Version 5 is not valid. Valid versions for ListOffsetRequest are 0 to 5                                                                                                                                                                                                                                                                       at org.apache.kafka.common.requests.ListOffsetRequest.getErrorResponse(ListOffsetRequest.java:282)                                                                                                                                                                                                                                                                        at kafka.server.KafkaApis.sendErrorOrCloseConnection(KafkaApis.scala:3062)                                                                                                                                                                                                                                                                                                at kafka.server.KafkaApis.sendErrorResponseMaybeThrottle(KafkaApis.scala:3045)                                                                                                                                                                                                                                                                                            at kafka.server.KafkaApis.handleError(KafkaApis.scala:3027)                                                                                                                                                                                                                                                                                                               at kafka.server.KafkaApis.handle(KafkaApis.scala:209)                                                                                                                                                                                                                                                                                                                     at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:78)                                                                                                                                                                                                                                                                                                     at java.lang.Thread.run(Thread.java:748)```Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-1947 can't explicitly set replica-assignment when add partitions; reviewed by Neha Narkhede,1
"MINOR: Always specify the keystore type in system testsAlso throw an exception if a null keystore type is seenin `SecurityStore`. This should never happen.The default keystore type has changed in Java 9 (http://openjdk.java.net/jeps/229), so we need tobe explicit to have consistent behaviour acrossJava versions.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3808 from ijuma/set-jks-explicitly-in-system-tests",5
"KAFKA-5636: Improve handling of ""early"" records in sliding windows (#9157)Update for KIP-450 to handle ""early"" records.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: fix potential NPE in PartitionData.equals (#9391)the field metadata is nullable (see https://github.com/apache/kafka/blob/trunk/clients/src/main/resources/common/message/OffsetFetchResponse.json#L50)Reviewers: David Jacot <david.jacot@gmail.com>,5
"KAFKA-7080: replace numSegments with segmentInterval (#5257)See also KIP-319.Replace number-of-segments parameters with segment-interval-ms parameters in various places. The latter was always the parameter that several components needed, and we accidentally supplied the former because it was the one available.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2769; Multi-consumer integration tests for consumer assignment incl. session timeouts and corresponding fixes-- Refactored multi-consumer integration group assignment validation tests for round-robin assignment-- Added multi-consumer integration tests for session timeout expiration:   1. When a consumer stops polling   2. When a consumer calls close()-- Fixes to issues found with session timeout expiration tests woth help from Jason Gustafson: Try to avoid  SendFailedException exception by cancelling the scheduled tasks and ensuring metadata update before sending group leave requests + send leave group request with retries.Author: Anna Povzner <anna@confluent.io>Reviewers: Jason Gustafson, Guozhang WangCloses #472 from apovzner/cpkafka-81",5
"MINOR: Replace empty string concattenation with String.valueOf() where possible. (#4369)This is something I did after my working hours, I would ask people reviewing this do the same, don't take time for this during your work hours.I try to keep such a PR as limited as possible, for clarity of reading.==========Using an empty string concat in order to achieve the String representation of the value you want is bad for 2 reasons, as explained here: (https://stackoverflow.com/questions/1572708/is-conversion-to-string-using-int-value-bad-practiceReadability: it shows what you're trying to do.Depending on your compiler, it might attempt to create your String by first creating a StringBuffer, appending your value to it and then doing .toString() on that. Which is inefficient.Also, the Metrics.java file had an empty string being added for the sole reason that the page width forced a string to continue on a new line. Removed that.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
"KAFKA-5129; Add ACL checks for Transactional APIsAdd ACL checks for Transactional APIsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2979 from dguy/kafka-5129",5
Checking in KEYS file to be used to verify Kafka releasesgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179887 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Increase timeout in log4j system test to avoid transient failures (#5658)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"MINOR: Remove ControllerEventManager metrics on close (#6788)Remove created metrics when shutting down `ControllerEventManager`. This fixes transient failures in `ControllerEventManagerTest.testEventQueueTime` and is generally good hygiene.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
MINOR: remove ZK from system testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2391 from mjsax/kafka-4060-zk-follow-up-system-tests,5
KAFKA-2461; request logger no longer logs extra information in debug modeAuthor: asingh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #169 from SinghAsDev/KAFKA-2461,0
MINOR: Fix typos in KafkaConsumer docsAuthor: Jeff Widman <jeff@jeffwidman.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2178 from jeffwidman/patch-1,5
"KAFKA-9048 Pt1: Remove Unnecessary lookup in Fetch Building (#7576)Get rid of partitionStates that creates a new PartitionState for each state since all the callers do not require it to be a Seq.Modify ReplicaFetcherThread constructor to fix the broken benchmark path.This PR:Benchmark                                  (partitionCount)  Mode  Cnt        Score       Error  UnitsReplicaFetcherThreadBenchmark.testFetcher               100  avgt   15     9280.953 ±    55.967  ns/opReplicaFetcherThreadBenchmark.testFetcher               500  avgt   15    61533.546 ±  1213.559  ns/opReplicaFetcherThreadBenchmark.testFetcher              1000  avgt   15   151306.146 ±  1820.222  ns/opReplicaFetcherThreadBenchmark.testFetcher              5000  avgt   15  1138547.929 ± 45301.938  ns/opTrunk:Benchmark                                  (partitionCount)  Mode  Cnt        Score       Error  Units |   |   |   |   |  -- | -- | -- | -- | -- | --ReplicaFetcherThreadBenchmark.testFetcher               100  avgt   15     9305.588 ±    51.886  ns/op |   |   |   |   |  ReplicaFetcherThreadBenchmark.testFetcher               500  avgt   15    65216.933 ±   939.827  ns/op |   |   |   |   |  ReplicaFetcherThreadBenchmark.testFetcher              1000  avgt   15   151715.514 ±  1361.009  ns/op |   |   |   |   |  ReplicaFetcherThreadBenchmark.testFetcher              5000  avgt   15  1231958.103 ± 94Reviewers: Jason Gustafson <jason@confluent.io>, Lucas Bradstreet <lucasbradstreet@gmail.com>",5
"KAFKA-8853; Create sustained connections test for TrogdorThis creates a test that generates sustained connections against Kafka.  Thereare three different components we can stress with this, KafkaConsumer,KafkaProducer, and AdminClient.  This test tries use minimal bandwidth perconnection to reduce overhead impacts.This test works by creating a threadpool that creates connections and thenmaintains a central pool of connections at a specified keepalive rate.  Thekeepalive action varies by which component is being stressed:  * KafkaProducer:  Sends one single produce record.  The configuration for    the produce request uses the same key/value generator as the ProduceBench    test.  * KafkaConsumer: Subscribes to a single partition, seeks to the end, and    then polls a minimal number of records.  Each consumer connection is its    own consumer group, and defaults to 1024 bytes as FETCH_MAX_BYTES to keep    traffic to a minimum.  * AdminClient: Makes an API call to get the nodes in the cluster.NOTE: This test is designed to be run alongside a ProduceBench test for aspecific topic, due to the way the Consumer test polls a single partition.There may be no data returned by the consumer test if this is run on its own.The connection should still be kept alive, but with no data returned.Author: Scott Hendricks <scott.hendricks@confluent.io>Reviewers: Stanislav Kozlovski, Gwen ShapiraCloses #7289 from scott-hendricks/trunk",1
MINOR: remove dangling quickstart-*.html (#9721)Reviewers: Guozhang Wang <guozhang@confluent.io>,5
"[MINOR] Clean up PartitionAssignor for KIP-441 (#7649)On-the-side cleanups extracted from the PR for KAFKA-9103, so that the actual PR can be as small as possible.Reviewers: Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-644 https://svn.apache.org/repos/asf/kafka/branches/0.8; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418545 13f79535-47bb-0310-9956-ffa450edef68,2
HOTFIX: Auto-repartitioning for merge() and code simplificationsfollow-up to auto-through feature: - add sourceNode to transform() - enable auto-repartitioning in merge() - null check not required anymore (always join-able due to auto-through)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1580 from mjsax/hotfix,0
"KAFKA-3419: clarify difference between topic subscription and partition assignmentAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ashish Singh, Ismael Juma, Guozhang WangCloses #1158 from hachikuji/KAFKA-3419",5
MINOR: Provide valid examples in README page. (#10259)* MINOR: Provide valid examples in README page.- `testMetadataUpdateWaitTime` method is removed from MetadataTest class.-  Removed the travis CI documentation.Reviewers: Luke Chen <showuon@gmail.com>,2
MINOR: Address review comments for KIP-504 authorizer changes (#7379)Reviewers: Manikumar Reddy <manikumar@confluent.io>,5
"MINOR: Maybe decorate inner topics for SourceNodeWhen creating the source node in TopologyBuilder, we need to decorate its input topics if they are inner (i.e. repartition) topics with the prefix.Also did some minor cleanup in the printing function for better visualization in debugging.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Damian Guy, Eno Thereska, Jun RaoCloses #2320 from guozhangwang/KMinor-source-topic-fix",0
Bug in the queue timeout logic of the async producer; patched by Neha Narkhede; reviewed by Jun Rao; KAFKA-138git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1176672 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Mention in configuration of broker setting log.retention.ms that -1 disables retention by time (#6464)Includes an update to the relevant configuration doc.,2
"KAFKA-4008: Module ""tools"" should not be dependent on ""core""moved streams application reset tool from tools to coreAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1685 from mjsax/moveResetTool(cherry picked from commit f2405a73ea2dd4b636832b7f8729fb06a04de1d5)Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>",4
"MINOR: Fix connector startup error logging (#9784)If a connector fails on startup, the original cause of the error gets discarded by the framework and the only message that gets logged looks like this:```[2020-12-04 16:46:30,464] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'conn-1' (org.apache.kafka.connect.runtime.distributed.DistributedHerder)org.apache.kafka.connect.errors.ConnectException: Failed to start connector: conn-1        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$5(DistributedHerder.java:1297)        at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:258)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1321)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$1400(DistributedHerder.java:127)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder$13.call(DistributedHerder.java:1329)        at org.apache.kafka.connect.runtime.distributed.DistributedHerder$13.call(DistributedHerder.java:1325)        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)        at java.base/java.lang.Thread.run(Thread.java:834)```The changes here should cause the original cause of the connector startup failure to be logged as well.```[2020-12-30 09:56:35,481] ERROR [test-connector|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'conn-1' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:599)org.apache.kafka.connect.errors.ConnectException: Failed to start connector: conn-1at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$4(DistributedHerder.java:1298)at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:294)at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1322)at org.apache.kafka.connect.runtime.distributed.DistributedHerder.processConnectorConfigUpdates(DistributedHerder.java:597)at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:416)at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:294)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements```Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",0
MINOR: Note that slf4j-log4j in version 1.7.35+ should be used (#12114)Adds a note to the upgrade notes to use slf4j-log4j version1.7.35+ [1] or slf4j-reload4j to avoid possible compatibility issuesoriginating from the logging framework [2].[1] https://www.slf4j.org/manual.html#swapping[2] https://www.slf4j.org/codes.html#no_tlmReviewer: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-3016: phase-2. stream join implementationsguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #737 from ymatsuda/windowed_join2,5
MINOR: Update docs to say 2.3 (#6881)Jason Gustafson <jason@confluent.io>,5
"MINOR: additional kip-182 doc updatesAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3971 from dguy/kip-182-docs",2
MINOR: set up temp directories properly in StreamTaskTestguozhangwangStreamTaskTest did not set up a temp directory for each test. This occasionally caused interference between tests through state directory locking.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #317 from ymatsuda/fix_StreamTaskTest,3
"[KAFKA-6730] Simplify State Store Recovery (#5013)Reviewer: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: Remove workarounds for lz4-java bug affecting byte buffers (#6679)lz4/lz4-java#65 was included in lz4-java 1.4.0.Relying on existing tests for verification.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"MINOR: Update log and method name in TopologyMetadata (#11589)Update an unclear log message and method name in TopologyMetadataReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>, Luke Chen <showuon@confluent.io>",5
"KAFKA-12193: Re-resolve IPs after a client disconnects (#9902)This patch changes the NetworkClient behavior to resolve the target node's hostname after disconnecting from an established connection, rather than waiting until the previously-resolved addresses are exhausted. This is to handle the scenario when the node's IP addresses have changed during the lifetime of the connection, and means that the client does not have to try to connect to invalid IP addresses until it has tried each address.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Satish Duggana <satishd@apache.org>, David Jacot <djacot@confluent.io>",5
KAFKA-3844; Sort configuration items in logKAFKA-3844; Sort configuration items in logAuthor: Rekha Joshi <rekhajoshm@gmail.com>Author: Joshi <rekhajoshm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1559 from rekhajoshm/KAFKA-3844,2
KAFKA-2121; add missing file,2
"KAFKA-12375: fix concurrency issue in application shutdown (#10213)Need to ensure that `enforceRebalance` is used in a thread safe wayReviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"KAFKA-5891; Proper handling of LogicalTypes in Cast (#4633)Currently logical types are dropped during Cast Transformation.This patch fixes this behaviour.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
kafka-1994; Evaluate performance effect of chroot check on Topic creation; patched by Ashish Singh; reviewed by Gwen Shapira and Jun Rao,1
"KAFKA-7808: AdminClient#describeTopics should not throw InvalidTopic if topic name is not found (#6124)* Update KafkaAdminClient#describeTopics to throw UnknownTopicOrPartitionException.* Remove unused method: WorkerUtils#getMatchingTopicPartitions.* Add some JavaDoc.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>, Ryanne Dolan <ryannedolan@gmail.com>",2
"KAFKA-8550: Fix plugin loading of aliased converters in Connect (#6959)Connector validation fails if an alias is used for the converter since the validation for that is done via `ConfigDef.validateAll(...)`, which in turn invokes `Class.forName(...)` on the alias. Even though the class is successfully loaded by the DelegatingClassLoader, some Java implementations will refuse to return a class from `Class.forName(...)` whose name differs from the argument provided.This commit alters `ConfigDef.parseType(...)` to first invoke `ClassLoader.loadClass(...)` on the class using our class loader in order to get a handle on the actual class object to be loaded, then invoke `Class.forName(...)` with the fully-qualified class name of the to-be-loaded class and return the result. The invocation of `Class.forName(...)` is necessary in order to allow static initialization to take place; simply calling `ClassLoader.loadClass(...)` is insufficient.Also corrected a unit test that relied upon the old behavior.Author: Chris Egerton <chrise@confluent.io>Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
MINOR: Fix some typosJust a doc changeAuthor: John Eismeier <john.eismeier@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4573 from jeis2497052/trunk,1
KAFKA-2140 Improve code readability; reviewed by Neha Narkhede,1
"KAFKA-1350 Fix excessive state change logging;reviewed by Jun,Joel,Guozhang and Tim",2
"MINOR: Push JMX metric name mangling into the JmxReporter (KIP-190 follow up)Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3980 from ewencp/dont-mangle-names",5
HOTFIX: fix paths in streams indexAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3502 from dguy/doc-fixes,2
"MINOR: document increased network bandwidth of 0.10 under replicationIf you're pushing close to the network capacity, 0.10's additional 8 bytes per message can lead to overload of your network. We (Heroku Kafka) ran into this issue whilst benchmarking 0.10 RC and the ijuma suggested it belonged in the update note.Comments/suggestions welcome.Author: Tom Crayford <tcrayford@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1389 from tcrayford/upgrade_note_about_increased_network_bandwidth",1
"MINOR: improve Streams error message (#5975)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-7903: automatically generate OffsetCommitRequest (#6583)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
HOTFIX: fix off-by-one stream offset commitguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #372 from ymatsuda/commit_offset,1
"MINOR: improve test coverage for dynamic LogConfig(s) (#7616)Adding a dynamically updatable log config is currently error prone, as it is easy toset them up as a val not a def and this would result in a dynamically updatedbroker default not applying to a LogConfig after broker restart.This PR adds a guard against introducing these issues by ensuring that all logconfigs are exhaustively checked via a test.For example, if the following line was a val and not a def, there would be aproblem with dynamically updating broker defaults for the config.https://github.com/apache/kafka/blob/4bde9bb3ccaf5571be76cb96ea051dadaeeaf5c7/core/src/main/scala/kafka/server/KafkaConfig.scala#L1216Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-3522: Add TimestampedKeyValueStore builder/runtime classes (#6152)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"HOTFIX: AddOffsetsToTxnResponse using incorrect schema in parseThe parse method was incorrectly referring to `ApiKeys.ADD_PARTITIONS_TO_TXN`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3056 from dguy/hotfix-add-offsets-to-txn-response",0
"KAFKA-7484: fix suppression integration tests (#5748)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10834: Remove redundant type casts in Connect (#10053)Cleanup up to remove redundant type casts in Connect and use the diamond operator when needed Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
MINOR: Remove incorrect code in metadata module build (#9897)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
KAFKA-7333; Protocol changes for KIP-320This patch contains the protocol updates needed for KIP-320 as well as some of the basic consumer APIs (e.g. `OffsetAndMetadata` and `ConsumerRecord`). The inter-broker format version has not been changed and the brokers will continue to use the current API versions.Author: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5564 from hachikuji/KAFKA-7333,5
DumpLogSegment offset verification is incorrect for compressed messages; patched by Yang Ye; reviewed by Jun Rao; KAFKA-614git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410649 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Traverse plugin path recursively in Connect (KIP-146)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3173 from kkonstantine/MINOR-Traverse-plugin-path-recursively-in-Connect,5
Bump trunk to 2.6.0-SNAPSHOT (#8026),1
"MINOR: Update minimum required Gradle version to 4.7 (#5642)After commit f123d2f, the minimum required gradle version changed to 4.7This is due to the use of isJava11Compatible() in build.gradle. It wasintroduced in version 4.7 (https://github.com/gradle/gradle/blob/master/subprojects/base-services/src/main/java/org/gradle/api/JavaVersion.java#L172-L180)Reviewers: Ismael Juma <ismael@juma.me.uk>",1
HOTFIX: follow up on KAFKA-4275Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2039 from mjsax/hotfix-ktableLeftJoin,0
KAFKA-2809; Improve documentation linkingOften it is useful to link to a specific header within the documentation. Especially when referencing docs in the mailing lists.This adds anchors and links for all headers in the docs.Author: Grant Henke <granthenke@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #498 from granthenke/doc-links,2
"MINOR: Use FetchRequest v8 and ListOffsetRequest v3 in ReplicaFetcherThread (#5342)If inter.broker.protocol.version is 2.0-IV1 or newer. Also fixed ListOffsetRequestso that v2 is used, if applicable.Added a unit test which verifies that we use the latest version of the variousrequests by default. Included a few minor tweaks to make testing easier.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-3421: Update docs with new connector featuresewencp gwenshap Docs. I also tried to clean up some typos. However, it seems that the we don't have two words without space in between in the source yet they showed up as no space in between in the generated doc.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1227 from Ishiihara/config-doc",5
MINOR: Fix javadoc of `flatTransform()` (#7803)The two missing } in the javadoc of flatTransform() lead to thefollowing javadoc compile warnings:.../KStream.java:1156: warning - End Delimiter } missing for possible See Tag in comment stringReviewers: Bill Bejeck <bbejeck@gmail.com>,2
"KAFKA-4473: RecordCollector should handle retriable exceptions more strictlyThe `RecordCollectorImpl` currently drops messages on the floor if an exception is non-null in the producer callback. This will result in message loss and violates at-least-once processing.Rather than just log an error in the callback, save the exception in a field. On subsequent calls to `send`, `flush`, `close`, first check for the existence of an exception and throw a `StreamsException` if it is non-null. Also, in the callback, if an exception has already occurred, the `offsets` map should not be updated.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2249 from dguy/kafka-4473",5
MINOR: Optimise performance of `Topic.validate()`I included a JMH benchmark and the results follow. Theimplementation in this PR takes no more than 1/10thof the time when compared to trunk. I also includedresults for an alternative implementation that is a littleslower than the one in the PR.Trunk:```textTopicBenchmark.testValidate                                topic  avgt   15  134.107 ±  3.956  ns/opTopicBenchmark.testValidate                    longer-topic-name  avgt   15  316.241 ± 13.379  ns/opTopicBenchmark.testValidate  very-long-topic-name_with_more_text  avgt   15  636.026 ± 30.272  ns/op```Implementation in the PR:```textTopicBenchmark.testValidate                                topic  avgt   15  13.153 ± 0.383  ns/opTopicBenchmark.testValidate                    longer-topic-name  avgt   15  26.139 ± 0.896  ns/opTopicBenchmark.testValidate  very-long-topic-name.with_more_text  avgt   15  44.829 ± 1.390  ns/op```Alternative implementation where boolean validChar = Character.isLetterOrDigit(c) || c == '.' || c == '_' || c == '-';```textTopicBenchmark.testValidate                                topic  avgt   15  18.883 ± 1.044  ns/opTopicBenchmark.testValidate                    longer-topic-name  avgt   15  36.696 ± 1.220  ns/opTopicBenchmark.testValidate  very-long-topic-name_with_more_text  avgt   15  65.956 ± 0.669  ns/op```Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3234 from ijuma/optimise-topic-is-valid,5
"KAFKA-3840; Allow clients default OS buffer sizesFollow up on KAFKA-724 (#1469) to allow OS socket buffer sizes auto tuning for both the broker and the clients.Author: Sebastien Launay <sebastien@opendns.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1507 from slaunay/enhancement/os-socket-buffer-size-tuning-for-clients",1
"KAFKA-8306; Initialize log end offset accurately when start offset is non-zero (#6652)This patch ensures that the log end offset of each partition is initialized consistently with the checkpointed log start offset.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix shouldNotResetEpochHistoryHeadIfUndefinedPassed (#9218)In LeaderEpochFileCacheTest.scala, code is identical for `shouldNotResetEpochHistoryHeadIfUndefinedPassed` and `shouldNotResetEpochHistoryTailIfUndefinedPassed`. Seems `truncateFromStart` should be invoked in `shouldNotResetEpochHistoryHeadIfUndefinedPassed` instead of `truncateFromEnd`.",1
kafka-1868; ConsoleConsumer shouldn't override dual.commit.enabled to false if not explicitly set; patched by Jun Rao; reviewed by Jeol Koshy,1
KAFKA-192 CompressionUtilTest does not run and fails when it does;patched by joestein;reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1198536 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6238; Fix inter-broker protocol message format compatibility checkThis patch fixes a bug in the validation of the inter-broker protocol and the message format version. We should allow the configured message format api version to be greater than the inter-broker protocol api version as long as the actual message format versions are equal. For example, if the message format version is set to 1.0, it is fine for the inter-broker protocol version to be 0.11.0 because they both use message format v2.I have added a unit test which checks compatibility for all combinations of the message format version and the inter-broker protocol version.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4583 from hachikuji/KAFKA-6328-REOPENED",5
"KAFKA-13790; ReplicaManager should be robust to all partition updates from kraft metadata log (#12085)This patch refactors the `Partition.makeLeader` and `Partition.makeFollower` to be robust to all partition updates from the KRaft metadata log. Particularly, it ensures the following invariants:- A partition update is accepted if the partition epoch is equal or newer. The partition epoch is updated by the AlterPartition path as well so we accept an update from the metadata log with the same partition epoch in order to fully update the partition state.- The leader epoch state offset is only updated when the leader epoch is bumped.- The follower states are only updated when the leader epoch is bumped.- Fetchers are only restarted when the leader epoch is bumped. This was already the case but this patch adds unit tests to prove/maintain it.In the mean time, the patch unifies the state change logs to be similar in both ZK and KRaft world.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-2549: Fixing checkstyle failure resulting due to unused imports…… in Selector.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Gwen ShapiraCloses #215 from Parth-Brahmbhatt/KAFKA-2549,2
MINOR: Delete unused `jenkins.sh` (#9919)This was replaced by `Jenkinsfile` a while back and it's out of date.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-12819: Add assert messages to MirrorMaker tests plus other quality of life improvements (#10762)Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",1
"MINOR: Fix ProducerPerformance bug when numRecords > Integer.MAX (#5956)Current code will fall into non-stop loop and send more message to broker, and Stat in PerfCallback method record will throw ArrayIndexOutOfBoundsException",0
"HOTFIX: Correct ordering of input buffer and enforced processing sensors (#12363)1. As titled, fix the right constructor param ordering.2. Also added a few more loglines.Reviewers: Matthias J. Sax <matthias@confluent.io>, Sagar Rao <sagarmeansocean@gmail.com>, Hao Li <1127478+lihaosky@users.noreply.github.com>",1
"HOTFIX: check logic of KAFKA-2515 should be on buffer.limit()Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #332 from guozhangwang/K2515-hotfix",0
"KAFKA-13890: Improve documentation of `ssl.keystore.type` and `ssl.truststore.type` (#12226)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , David Jacot <djacot@confluent.io>, Kvicii <kvicii.yu@gmail.com>",5
"KAFKA-10120: Deprecate DescribeLogDirsResult.all() and .values() (#9007)Reviewers: Mickael Maison <mickael.maison@gmail.com>, David Jacot <djacot@confluent.io>, Lee Dongjin <dongjin@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-12870; Flush in progress not cleared after transaction completion (#10880)We had been using `RecordAccumulator.beginFlush` in order to force the `RecordAccumulator` to flush pending batches when a transaction was being completed. Internally, `RecordAccumulator` has a simple counter for the number of flushes in progress. The count gets incremented in `beginFlush` and it is expected to be decremented by `awaitFlushCompletion`. The second call to decrement the counter never happened in the transactional path, so the counter could get stuck at a positive value, which means that the linger time would effectively be ignored.This patch fixes the problem by removing the use of `beginFlush` in `Sender`. Instead, we now add an additional condition in `RecordAccumulator` to explicitly check when a transaction is being completed. Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-13102: Topic IDs not propagated to metadata cache quickly enough for Fetch path (#11170)Before we used the metadata cache to determine whether or not to use topic IDs. Unfortunately, metadata cache updates with ZK controllers are in a separate request and may be too slow for the fetcher thread. This results in switching between topic names and topic IDs for topics that could just use IDs.This patch adds topic IDs to FetcherState created in LeaderAndIsr requests. It also supports updating this state for follower threads as soon as a LeaderAndIsr request provides a topic ID.We've opted to only update replica fetcher threads. AlterLogDir threads will use either topic name or topic ID depending on what was present when they were created.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Format the revoking active log output in `StreamsPartitionAssignor` (#10242)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-13603: Allow the empty active segment to have missing offset index during recovery (#11345)Within a LogSegment, the TimeIndex and OffsetIndex are lazy indices that don't get created on disk until they are accessed for the first time. However, Log recovery logic expects the presence of an offset index file on disk for each segment, otherwise, the segment is considered corrupted.This PR introduces a forceFlushActiveSegment boolean for the log.flush function to allow the shutdown process to flush the empty active segment, which makes sure the offset index file exists.Co-Author: Kowshik Prakasam kowshik@gmail.comReviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",5
kafka-1971; starting a broker with a conflicting id will delete the previous broker registration; patched by Jun Rao; reviewed by Neha Narkhede,4
MINOR: Add spotlessScalaCheck dependency to streams-scala test task (#5479)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"MINOR: Fix typos in Kafka website pageFix two minor typos in Kafka official website page.Author: Gabriel Zhang <smalldirector@yahoo.com>Reviewers: Ismael Juma, Guozhang WangCloses #742 from smalldirector/kafka-document-typos-fix",2
KAFKA-10794 Replica leader election is too slow in the case of too many partitions (#9675)Co-authored-by: limengmonty <limengmonty@didichuxing.com>Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
Allow users to specify 'if-not-exists' when creating topics while testing (#4715)Author: Chris Egerton <chrise@confluent.io>,5
MINOR: Avoid unnecessary `ConcurrentHashMap.get`Also remove incorrect comment.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #790 from ijuma/avoid-unnecessary-get,1
"MINOR: Fix flaky shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound (#11155)1. This test is taking two iterations since the firs iteration is designed to fail due to unknow topic leader. However both the timeout and the backoff are set to 50ms, while the actual SYSTEM time is used. This means we are likely to timeout before executing the second iteration. I thought about using a mock time but dropped that idea as it may forgo the purpose of this test, instead I set the backoff time to 10ms so that we are almost unlikely to hit this error anymore.2. Found a minor issue while fixing this which is that when we have non-empty not-ready topics, but the topics-to-create is empty (which is possible as the test shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound itself illustrates), we still call an empty create-topic function. Though it does not incur any round-trip it would still waste some cycles, so I branched it off and hence also simplified some unit tests.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@confluent.io>",5
"MINOR: Add serialized vagrant rsync until upstream fixes broken parallelismSee https://github.com/mitchellh/vagrant/issues/7531. The core of the issue is that vagrant rsync uses a fixed set of 1000 possible temp file entries for SSH ControlMaster files to cache SSH connections for rsyncing. A few notes:* We can't break down the steps further and maintain performance due to various limitations in vagrant/vagrant-aws (rsync is only executed on `vagrant up`/`vagrant reload`/`vagrant rsync`, you can't enable/disable and rsync shared folder only during some of those stages, and provisioning only runs in parallel with vagrant-aws during `vagrant up`).* We need to isolate each of the serialized rsync calls. (If we assumed `parallel` was available, we actually could get the parallelism back.) This is required because even across calls they could randomly choose the same temporary file.* If there's a chance multiple instances were running on the same server at the same or nearly the same time, they can conflict since the same temp file entries are used globally. This means anything running on shared CI servers might end up syncing data between different CI jobs (!!), which could lead to some very strange results. Especially weird if they aren't even for the same type of job.* Provisioning error check needs to be removed because it is catching rsync errors, but those can still happen in the initial `vagrant up` rsync step before the `vagrant up` provisioning step. It seems likely this bug was the cause of missing files anyway so this check might not be as valuable anymore.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3380 from ewencp/deparallelize-rsync",2
"MINOR: Change rocksdb logging to error levelAccording to the java-doc: https://github.com/facebook/rocksdb/blob/master/java/src/main/java/org/rocksdb/Logger.java#L31 the rocksdb logging level should be set Error or Fatal for production usage.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2477 from dguy/rocks-db-logging",5
"KAFKA-5702; extract refactor StreamThreadExtracted `TaskManager` to handle all task related activities.Make `StandbyTaskCreator`, `TaskCreator`, and `RebalanceListener` static classes so they must define their dependencies and can be testing independently of `StreamThread`Added interfaces between `StreamPartitionAssignor` & `StreamThread` to reduce coupling.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Eno Thereska <eno.thereska@gmail.com>Closes #3624 from dguy/stream-thread-refactor",4
"MINOR: Use `forEach` and `ifPresent` to simplify Scala code (#8642)* Use `forEach` instead of `asScala.foreach` for Java Iterables.* Use `ifPresent` instead of `asScala.foreach` for Java Optionals.* Use `forEach` instead of `entrySet.forEach` for Java maps.* Keep `asScala.foreach` for `Properties` as the Scala implementationhas a better interface (keys and values are of type `String`).* A few clean-ups: unnecessary `()`, `{}`, `new`, etc.Reviewers: Manikumar Reddy <manikumar@confluent.io>",5
"MINOR: Add DuplicateBrokerRegistrationException (#10029)Add DuplicateBrokerRegistrationException, as specified in KIP-631.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix error message in exception when records have schemas in Connect's Flatten transformation (#3982)In case of an error while flattening a record with schema, the Flatten transformation was reporting an error about a record without schema, as follows: ```org.apache.kafka.connect.errors.DataException: Flatten transformation does not support ARRAY for record without schemas (for field ...)```The expected behaviour would be an error message specifying ""with schemas"". This looks like a simple copy/paste typo from the schemaless equivalent methods, in the same file Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-10477: Fix JsonConverter regression to treat MISSING nodes as NULL nodes (#9306)Fixes a regression introduced in `JsonConverter` with previous upgrades from Jackson Databind 2.9.x to 2.10.x. Jackson Databind version 2.10.0 included a backward-incompatible behavioral change to use `JsonNodeType.MISSING` (and `MissingNode`, the subclass of `JsonNode` that has a type of `MISSING`) instead of `JsonNodeType.NULL` / `NullNode`. See https://github.com/FasterXML/jackson-databind/issues/2211 for details of this change.This change makes recovers the older `JsonConverter` behavior of returning null on empty input.Added two unit tests for this change. Both unit tests were independently tested with earlier released versions and passed on all versions that used Jackson 2.9.x and earlier, and failed on all versions that used 2.10.x and that did not have the fixed included in the PR. Both of the new unit tests pass with this fix to `JsonConverter`.Author: Shaik Zakir Hussain <zhussain@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"KAFKA-6608; Add timeout parameter to blocking consumer calls [KIP-266] (#5014)This patch implements the consumer timeout APIs from KIP-266 (everything except `poll()`, which was done separately).Reviewers:  John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: Ensure heartbeat last poll time always updated (#5308)We need to ensure that the last poll time is always updated when the user call poll(Duration). This patch fixes a bug in the new KIP-266 timeout behavior which would cause this to be skipped if the coordinator could not be found while the consumer was in an active group.Note that I've also fixed some type inconsistencies for various timeouts.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
MINOR: Update Quickstart in documentation to account for Windows platformsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1990 from vahidhashemian/doc/quickstart_update_windows,5
KAFKA-9294: Add tests for Named parameter (#7927)Part 2 -- tests for stateful KStream operatorsReviewers: Bill Bejeck <bill@confluent.io>,5
"MINOR: Remove unsupported rsync and ssh commands from release.py (#11309)ssh and rsync access has been removed from home.apache.org.Removing the commands from release.py and replacing them with a note to make sure they are manually uploaded with an sftp client instead.Reviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: more details in error message descriptions (#3267)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
ProducerRequest should take ByteBufferMessageSet instead of MessageSet; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-632git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1414917 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Code cleanup, subject: log statements.I'm doing this in my spare time, so don't let reviewing this PR take away actual work time. This is just me going over the code with the Intellij analyzer and implementing the most easily implementable fixes.This PR is focused only on seemingly erronous log statements.1: A log statement that has 4 arguments supplied but only 3 `{}` statements2: A log statement that checks is debug is enabled, but then logs on `info` level.Author: coscale_kdegroot <koen.degroote@coscale.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3886 from KoenDG/loggingErrors",2
MINOR: Remove redundant code from BrokerApiVersionsCommand (#10556)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"KAFKA-1740 follow-up: add state checking in handling heartbeat request; reviewed by Onur Karaman, Ewen Cheslack-Postavam and Guozhang Wang",1
KAFKA-1258 Automatically delete temporary directories with a shutdown hook during tests to avoid leaking temp files. Patch by Manikumar Reddy.,2
"KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs (#8812)1. Don't advance recovery point in `recoverLog` unless there was a cleanshutdown.2. Ensure the recovery point is not ahead of the log end offset.3. Clean and flush leader epoch cache and truncate produce state managerif deleting segments due to log end offset being smaller than log startoffset.4. If we are unable to delete clean shutdown file that exists, mark thedirectory as offline (this was the intent, but the code was wrong).Updated one test that was failing after this change to verify the new behavior.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"Fix retry logic for producers; patched by Prashanth Menon; reviewed by Jun Rao, Neha Narkhede; KAFKA-49git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1343255 13f79535-47bb-0310-9956-ffa450edef68",2
"MINOR: Update AclCommand help message to match implementation (#7990)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
MINOR: Fix typos in LogValidator (#6449),5
MINOR: Improve maven artifactory url in release.py (#5931),1
"MINOR: Update ZooKeeper upgrade notesAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Magnus Edenhill <magnus@edenhill.se>, Colin Patrick McCabe <cmccabe@apache.org>Closes #7818 from omkreddy/zk-note",5
"KAFKA-5428; Transactional producer should only abort batches in fatal error stateAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3298 from hachikuji/KAFKA-5428",5
"KAFKA-8475: Temporarily restore SslFactory.sslContext() helperTemporarily restore the SslFactory.sslContext() function, which some connectors use. This function is not a public API and it will be removed eventually. For now, we will mark it as deprecated.",4
KAFKA-9426: Use switch instead of chained if/else in OffsetsForLeaderEpochClient (#7959)Reviewers: Ismael Juma <ismael@juma.uk>,1
kafka-2265; creating a topic with large number of partitions takes a long time; patched by Manikumar Reddy; reviewed by Jun Rao,1
KAFKA-2034 sourceCompatibility not set in Kafka build.gradle; reviewed by Neha Narkhede and Ewen Cheslack-Postava,1
KAFKA-13166 Fix missing ControllerApis error handling (#12403)Makes all ControllerApis request handlers return a `CompletableFuture[Unit]`. Also adds an additional completion stage which ensures we capture errors thrown during response building.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>,0
"MINOR: Remove zkclient dependency (#7036)ZkUtils was removed so we don't need this anymore.Also:* Fix ZkSecurityMigrator and ReplicaManagerTest not toreference ZkClient classes.* Remove references to zkclient in various `log4j.properties`and `import-control.xml`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
"HOTFIX: fix failing test PlaintextAdminIntegrationTest.testElectPreferredLeaders (#8178)Confirmed the test passes after this (minor) change.Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-9310: Handle UnknownProducerId from RecordCollector.send (#7845)Reviewers:  Matthias J. Sax <mjsax@apache.org>,0
"MINOR: Improvements on Streams log4j1. add thread id as prefix in state directory classes; also added logs for lock activities.2. add logging for task creation / suspension.3. add more information in rebalance listener logging.4. add restored number of records into changlog reader.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Damian Guy, Ewen Cheslack-PostavaCloses #2702 from guozhangwang/KMinor-streams-task-creation-log4j-improvements",2
"KAFKA-12201: Migrate connect:basic-auth-extensio module to JUnit 5 (#9892)Also:* Remove unused powermock dependency* Remove ""examples"" from the JUnit 4 list since one module was alreadyconverted and the other has no testsReviewers: Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-13496: Add reason to LeaveGroupRequest (KIP-800) (#11571)This patch adds a `reason` field to the `LeaveGroupRequest` as specified in KIP-800: https://cwiki.apache.org/confluence/display/KAFKA/KIP-800%3A+Add+reason+to+JoinGroupRequest+and+LeaveGroupRequest.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-9165: Fix jersey warnings in Trogdor (#7669)Reviewers: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2
"Misc. minor house-keeping fixes: add reasonable GC settings, fix up README, fix up example configs, fix the logging for tools, use a log directory for logs instead of the root directory.",2
MINOR: Consolidate broker request/response handlingThis patch contains a few small improvements to make request/response handling more consistent. Primarily it consolidates request/response serialization logic so that `SaslServerAuthenticator` and `KafkaApis` follow the same path. It also reduces the amount of custom logic needed to handle unsupported versions of the ApiVersions requests.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3673 from hachikuji/consolidate-response-handling,5
MINOR: JavaDoc cleanup (#7873)Reviewers: Bill Bejeck <bill@confluent.io>,5
MINOR: replace deprecated Class.newInstance() to new one (#10610)* replace deprecated Class.newInstance() to class.getDeclaredConstructor().newInstance()* throw ReflectiveOperationException to cover all other exceptionsReviewers: Tom Bentley <tbentley@redhat.com>,1
"MINOR: Remove deprecated assertThat usage from KafkaLog4jAppenderTest (#6257)Replace `Assert.assertThat` with `MatcherAssert.assertThat`.Two commits (08036fa4b1 and c7f99bc2b) were merged at a similar time andthey passed the build in isolation, but not together.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Documentation for Rack AwarenessAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1369 from benstopford/rack-awareness-docs,2
"KAFKA-5588: Remove deprecated --new-consumer tools option (#5097)Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Switch to using the Gradle RAT plugin (#10491)The Gradle RAT plugin properly declares inputs and outputs and is alsocachable. This also relieves the Kafka developers from maintaining the buildintegration with RAT.The generated RAT report is identical to the one generated previously. The onlydifference is the RAT report name: the RAT plugin sets the HTML report name to`index.html` (still under `build/rat`).Verified that the rat task fails if unlicensed files are present (and not excluded). Also`./gradlew rat` succeeds when there is no .git folder.,2
KAFKA-2767; Upgrade ZkClient version to 0.7Author: Flavio Junqueira <fpj@apache.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #449 from fpj/KAFKA-2767,2
MINOR: fix RocksDBStore range searchThe range is inclusive according to KeyValueStore's java doc.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #883 from ymatsuda/minor,5
KAFKA-1663 Controller unable to shutdown after a soft failure; reviewed by Neha Narkhede,0
"KIP-421: Support for resolving externalized secrets in AbstractConfig (#6467)Updated AbstractConfig to be able to resolve variables in config values when the configuration includes config provider properties.Author: Tejal Adsul <tejal@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
kafka-933; Hadoop example running DataGenerator causes kafka.message.Message cannot be cast to [B exception; patched by drunkedcat; reviewed by Jun Rao,1
"MINOR: Improve exception messages in FileChannelRecordBatch (#6068)Replace `channel` by `fileRecords` in potentially thrown KafkaExceptiondescriptions when loading/writing `FileChannelRecordBatch`. This makes exceptionmessages more readable (channel only shows an object hashcode, fileRecords showsthe path of the file being read and start/end positions in the file).Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-98 Fix hardcoded ports in unit tests so you can run them while running kafka.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1157922 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: Add missing default arguments to __init__This caused the bounce and smoke tests to fail on trunk.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2524 from enothereska/hotfix-tests,3
KAFKA-9512: Flaky Test LagFetchIntegrationTest.shouldFetchLagsDuringRestoration (#8076)- Added additional synchronization and increased timeouts to handle flakiness - Added some pre-cautionary retries when trying to obtain lag mapReviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Fix wording in Metadata.add javadocAuthor: sven0726 <sven0726@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1719 from sven0726/trunk,1
KAFKA-2321; Introduce CONTRIBUTING.mdAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: GuozhangCloses #97 from ijuma/kafka-2321 and squashes the following commits:4834464 [Ismael Juma] KAFKA-2321; Introduce CONTRIBUTING.md,5
"KAFKA-13846: Adding overloaded metricOrElseCreate method (#12121)Reviewers: David Jacot <djacot@confluent.io>, Justine Olshan <jolshan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-774 Periodic refresh of topic metadata on the producer does not check for error code in the response; reviewed by Swapnil Ghike,0
"KAFKA-13858; Kraft should not shutdown metadata listener until controller shutdown is finished (#12187)When the kraft broker begins controlled shutdown, it immediately disables the metadata listener. This means that metadata changes as part of the controlled shutdown do not get sent to the respective components. For partitions that the broker is follower of, that is what we want. It prevents the follower from being able to rejoin the ISR while still shutting down. But for partitions that the broker is leading, it means the leader will remain active until controlled shutdown finishes and the socket server is stopped. That delay can be as much as 5 seconds and probably even worse.This PR revises the controlled shutdown procedure as follow:* The broker signals to the replica manager that it is about to start the controlled shutdown.* The broker requests a controlled shutdown to the controller.* The controller moves leaders off from the broker, removes the broker from any ISR that it is a member of, and writes those changes to the metadata log.* When the broker receives a partition metadata change, it looks if it is in the ISR. If it is, it updates the partition as usual. If it is not or if there is no leader defined--as would be the case if the broker was the last member of the ISR--it stops the fetcher/replica. This basically stops all the partitions for which the broker was part of their ISR.When the broker is a replica of a partition but it is not in the ISR, the controller does not do anything. The leader epoch is not bumped. In this particular case, the follower will continue to run until the replica manager shuts down. In this time, the replica could become in-sync and the leader could try to bring it back to the ISR. This remaining issue will be addressed separately.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6733: Printing additional ConsumerRecord fields in DefaultMessageFormatter (#9099)Implementation of KIP-431 - Support of printing additional ConsumerRecord fields in DefaultMessageFormatterhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-431%3A+Support+of+printing+additional+ConsumerRecord+fields+in+DefaultMessageFormatterReviewers: David Jacot <djacot@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-4564; Follow-up to fix test_timeout_on_pre_010_brokers system test failureAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2897 from mjsax/KAFKA-4564-follow-up",5
"KAFKA-10545: Create topic IDs in ZooKeeper and Controller (#9473)Topic IDs must be created for all new topics and all existing topics that do not yet have a topic ID. In ZooKeeper, the ID is written to the TopicZNode, and in the controller, it is stored in a map.This is a preliminary change before the second part, which will propagate these IDs to brokers.Reviewers: Lucas Bradstreet <lucas@confluent.io>, dengziming <dengziming1993@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5126: Implement KIP-98 transactional methods in the MockProducerAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2951 from mjsax/kafka-5126-add-transactions-to-mock-producer",1
MINOR: remove unneeded comments to avoid misleading message (#11122)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"KAFKA-6517: Avoid deadlock in ZooKeeperClient during session expiry (#4551)ZooKeeperClient acquires initializationLock#writeLock to establish a new connection while processing session expiry WatchEvent. ZooKeeperClient#handleRequests acquires initializationLock#readLock, allowing multiple batches of requests to be processed concurrently, but preventing reconnections while processing requests. At the moment, handleRequests holds onto the readLock throughout the method, even while waiting for responses and inflight requests to complete. But responses cannot be delivered if event thread is blocked on the writeLock to process session expiry event. This results in a deadlock. During broker shutdown, the shutdown thread is also blocked since it needs the readLock to perform ZooKeeperClient#unregisterStateChangeHandler, which cannot be acquired if a session expiry had occurred earlier since this thread gets queued behind the event handler thread waiting for writeLock.This commit reduces locking in ZooKeeperClient#handleRequests to just the non-blocking send, so that session expiry handling doesn't get blocked when a send is blocked waiting for responses. Also moves session expiry handling to a separate thread so that Kafka controller doesn't block the event handler thread when processing session expiry.",0
KAFKA-12335 Upgrade junit from 5.7.0 to 5.7.1 (#10145)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"HOTFIX: Fix wrong setting of Serde in `MeteredTimestampWindowStore` (#6808)Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",1
KAFKA-506 Move to logical offsets. Reviewed by Jun and Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1395729 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10006: Don't create internal topics when LeaderNotAvailableException (#8712)1. return the topicsNotReady to makeReady including tempUnknownTopics, and not create topic to wait for next retry2. tempUnknownTopics will be created each retry since we count the tempUnknownTopics as part of topicsNotReady3. add 2 more tests to total test 3 cases:  3.1 shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound  3.2 shouldCompleteValidateWhenTopicLeaderNotAvailableAndThenDescribeSuccess  3.3 shouldThrowExceptionWhenKeepsTopicLeaderNotAvailableReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
kafka-1376; transient test failure in UncleanLeaderElectionTest; patched by Jun Rao; reviewed by Joel Koshy,3
MINOR: add MockConfigRepository (#10927)Use MockConfigRepository rather than CachedConfigRepository in unittests. This is useful for an upcoming change that will removeCachedConfigRepository.Reviewers: David Arthur <mumrah@gmail.com>,5
"KAFKA-13224: Ensure that broker.id is set in KafkaConfig#originals (#11312)Some plugins make use of KafkaConfig#originals rather than theKafkaConfig object. We should ensure that these plugins see thecorrect value for broker.id if the broker is running in KRaft mode andnode.id has been configured, but not broker.id.This PR does this by ensuring that both node.id and broker.id are set inthe originals map if either one is set.  We also check that they are setto the same value in KafkaConfig#validateValues.Co-author: Ron Dagostino <rdagostino@confluent.io>",5
"KAFKA-4176: Only call printStream.flush for System.outAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck, Damian GuyCloses #1965 from guozhangwang/K4176-only-flush-for-standardoutput",5
"KAFKA-13506: Write and restore position to/from changelog (#11513)Introduces changelog headers to pass position informationto standby and restoring stores. The headers are guarded by an internalconfig, which defaults to `false` for backward compatibility. Once IQv2is finalized, we will make that flag a public config.Reviewers: Patrick Stuedi <pstuedi@apache.org>, John Roesler <vvcephei@apache.org>",5
"KAFKA-4326; Refactor LogCleaner for better reuse of common copy/compress logicAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2053 from hachikuji/KAFKA-4326",5
"KAFKA-13986; Brokers should include node.id in fetches to metadata quorum (#12498)Currently we do not set the replicaId in fetches from brokers to the metadata quorum. It is useful to do so since that allows us to debug replication using the `DescribeQuorum` API.Reviewers: dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
MINOR: improve trogdor commandline (#4721)Allow -c as a synonym for --agent.config and --coordinator.config.Allow -n as a synonym for --node-name.Add an example trogdor.conf file.,2
"KAFKA-8102: Add an interval-based Trogdor transaction generator (#6444)This patch adds a TimeIntervalTransactionsGenerator class which enables the Trogdor ProduceBench worker to commit transactions based on a configurable millisecond time interval.Also, we now handle 409 create task responses in the coordinator command-line client by printing a more informative messageReviewers: Colin P. McCabe <cmccabe@apache.org>",5
"KAFKA-5990: Enable generation of metrics docs for Connect (KIP-196)A new mechanism was added recently to the Metrics framework to make it easier to generate the documentation. It uses a registry with a MetricsNameTemplate for each metric, and then those templates are used when creating the actual metrics. The metrics framework provides utilities that can generate the HTML documentation from the registry of templates.This change moves the recently-added Connect metrics over to use these templates and to then generate the metric documentation for Connect.This PR is based upon #3975 and can be rebased once that has been merged.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3987 from rhauch/kafka-5990",5
"MINOR: Fix incorrect pattern matching on `version` in `CheckpointFile`Also add test and refactor things a little to make testing easier.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>Closes #2822 from ijuma/hotfix-checkpoint-file",2
MINOR: remove unused eosEnabled field from ProcessorStateManagerremove unused eosEnabled field from ProcessorStateManagerAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3469 from dguy/minor-remove-unused-boolean,4
MINOR: Ensure initial topic configs and updates are loggedThis patch adds logging of topic config overrides during creation or during the handling of alter config requests. Also did some minor cleanup to avoid redundant validation logic when adding partitions.Author: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5812 from hachikuji/minor-log-topic-creation-configs,5
"HOTFIX: KIP-104 follow-up: remove duplicated per-processor-node throughput metrics, and also rename some other sensorsThis is the HOTFIX PR for any issues detected with KIP-104 until code freeze. Note: do not merge until close to code freeze.The name changes reflect feedback received while writing the documentation.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Dan Norwood, Guozhang WangCloses #2398 from enothereska/hotfix-streams-metrics",0
KAFKA-3105: Use `Utils.atomicMoveWithFallback` instead of `File.rename`It behaves better on Windows and provides more useful error messages.Also:* Minor inconsistency fix in `kafka.server.OffsetCheckpoint`.* Remove delete from `streams.state.OffsetCheckpoint` constructor (similar to the change in `kafka.server.OffsetCheckpoint` in https://github.com/apache/kafka/commit/836cb1963330a9e342379899e0fe52b72347736e#diff-2503b32f29cbbd61ed8316f127829455L29).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #771 from ijuma/kafka-3105-use-atomic-move-with-fallback-instead-of-rename,4
HOTFIX: make sure to go through all shutdown stepsAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #928 from ymatsuda/shutdown,5
MINOR: Increase timeout for flaky ResetConsumerGroupOffsetTest (#6900)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
KAFKA-8379; Fix KafkaAdminClientTest.testUnreachableBootstrapServer (#6753)Initiate `unreachable server` scenario before starting admin client to avoid timing issues if node is disconnected from the test thread while admin client network thread is processing a metadata request.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-6519; Reduce log level for normal replica fetch errors (#4501)Out of range and not leader errors are common in replica fetchers and not necessarily an indication of a problem. This patch therefore reduces the log level for log messages corresponding to these errors from `ERROR` to `INFO`. Additionally, this patch removes some redundant information in the log message which is already present in the log context.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-7660: fix parentSensors memory leak (#5953)In StreamsMetricsImpl, the parentSensors map was keeping references to Sensors after the sensors themselves had been removed.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Fix visibility of Log.{unflushedMessages, addSegment} methods (#9966)Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-8452: Compressed BufferValue (#6848)De-duplicate the common case in which the prior value is the same as the old value.Reviewers: Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-987 Avoid checkpointing offsets in Kafka consumer that have not changed since the last commit; reviewed by Neha Narkhede,4
"KAFKA-10189: reset event queue time histogram when queue is empty (#8935)add a timeout for event queue time histogram;reset eventQueueTimeHist when the controller event queue is empty;Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Igor Soarez <i@soarez.me>, Jun Rao <junrao@gmail.com>",1
"KAFKA-2822: DescribeConsumerGroup now returns empty list for non-existent group.…tent group, it used to throw IllegalArgumentExceptionAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Jason Gustafson, Guozhang WangCloses #515 from SinghAsDev/KAFKA-2822",1
"MINOR: Remove unused TopicCommand.askToProceed() method (#9465)Reviewers: Gwen (Chen) Shapira <cshapi@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-5368: Add test for skipped-records metric (#4365)* KAFKA-5368: Add test for skipped-records metricReviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4229; Controller can't start after several zk expired eventAuthor: pengwei <pengwei.lihuawei.com>Reviewers: wangguoz.gmail.comAuthor: pengwei-li <pengwei.li@huawei.com>Author: c00353482 <c00353482@huaweiobz.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2175 from pengwei-li/trunk,1
"KAFKA-2690: Hide passwords while logging the config.Added PASSWORD_STRING in ConfigDef that returns ""[hidden]"" when method toString is invoked.Author: Jakub Nowak <jakub.nowak94@interia.pl>Reviewers: Ismael Juma, Gwen Shapira, Jun RaoCloses #371 from Mszak/ssl-password-protection",4
HOTFIX: Fix reset integration test hangs on busy wait (#4491)* do not use static properties* use new object to take appID* capture timeout exception inside conditionReviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-8348: Fix KafkaStreams JavaDocs (#6707),2
"KAFKA-2965; Two variables should be exchanged.Author: unknown <w00312082@szxbz258.huaweiobz.com>Reviewers: Ismael Jumah, Grant Henke, Gwen ShapiraCloses #646 from boweite/kafka-2965",4
KAFKA 3656: Remove logging outstanding messages when producer flush failsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1319 from Ishiihara/kafka-3656,5
"KAFKA-10000: Add new preflight connector config validation logic (#11776)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2
"MINOR: Fixes to AWS init script for testingA path was wrong in the script and in the documentation.Author: Roger Hoover <roger.hoover@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1309 from theduderog/fix_aws_init",5
"MINOR. implement --expose-ports option in ducker-ak (#7269)This change adds a command line option to the `ducker-ak up' command to enable exposing ports from docker containers. The exposed ports will be mapped to the ephemeral ports on the host. The option is called `expose-ports' and can take either a single value (like 5005) or a range (like 5005-5009). This port will then exposed from each docker container that ducker-ak sets up.Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-7223: add tests in preparation for suppression (#5687)This is Part 2 of suppression.Part 1 was #5567In an effort to control the scope of the review, this PR is just the tests for buffered suppression.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12815: Update JavaDocs of ValueTransformerWithKey (#10731)Reviewers: Luke Chen <howuon@gmail.com>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"TRIVIAL: Updated testing readmeMinor update to point to testing tutorial, and install the correct version of vagrant-hostmanagerAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Gwen ShapiraCloses #187 from granders/minor-testing-readme-update",5
KAFKA-3430: Allow users to set key in KTable.toStream and in KStream.… With KStream the method selectKey was added to enable getting a key from values before perfoming aggregation-by-key operations on original streams that have null keys.Author: bbejeck <bbejeck@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1222 from bbejeck/KAFKA-3430_allow_users_to_set_key_KTable_toStream,1
"MINOR: Make log cleaner tests more efficient and less flaky (#5836)`testMarksPartitionsAsOfflineAndPopulatesUncleanableMetrics` sometimes failsbecause the 15 second timeout expires. Inspecting the error message from the buildfailure, we see that this timeout happens in the writeDups() calls which call roll().```text[2018-10-23 15:18:51,018] ERROR Error while flushing log for log-1 in dir /tmp/kafka-8190355063195903574 with offset 74 (kafka.server.LogDirFailureChannel:76)java.nio.channels.ClosedByInterruptException...at kafka.log.Log.roll(Log.scala:1550)...at kafka.log.AbstractLogCleanerIntegrationTest.writeDups(AbstractLogCleanerIntegrationTest.scala:132)...```After investigating, I saw that this test would call Log#roll() around 60 times every run.Increasing the segmentSize config to `2048` reduces the number of Log#roll() callswhile ensuring that there are multiple rolls still.I saw that most other LogCleaner tests also call roll() ~90 times, so I've changed thedefault to be `2048`. I've also made the one test which requires a smaller segmentSizeto set it via the args.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-10767: Adding test cases for all, reverseAll and reverseRange for ThreadCache (#9779)The test cases for ThreaCache didn't have the corresponding unit tests for all, reverseAll and reverseRange methods. This PR aims to add the same.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Use annotationProcessor instead of compile for JMH annotation processorThis fixes the following Gradle warning:> The following annotation processors were detected on the compile classpath:> 'org.openjdk.jmh.generators.BenchmarkProcessor'. Detecting annotation processors> on the compile classpath is deprecated and Gradle 5.0 will ignore them. Please add> them to the annotation processor path instead. If you did not intend to use annotation> processors, you can use the '-proc:none' compiler argument to ignore them.With this change, the warning went away and `./jmh-benchmarks/jmh.sh` continuesto work.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5602 from ijuma/annotation-processor",1
"KAFKA-10559: Not letting TimeoutException shutdown the app during internal topic validation (#9432)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
remove cs (#6950)cleanup of some redundant checkstyleReviewers: Bill Bejeck <bbejeck@gmail.com>,4
"KAFKA-5291; AdminClient should not trigger auto creation of topics- Added a boolean `allow_auto_topic_creation` to MetadataRequest andbumped the protocol version to V4.- When connecting to brokers older than 0.11.0.0, the `allow_auto_topic_creation`field won't be considered, so we send a metadata request for all topicsto keep the behavior consistent.- Set `allow_auto_topic_creation` to false in the new AdminClient andStreamsKafkaClient (which exists for the purpose of creating topicsmanually); set it to true everywhere else for now. Other clients will eventuallyrely on client-side auto topic creation, but that’s not there yet.- Add `allowAutoTopicCreation` field to `Metadata`, which is used by`DefaultMetadataUpdater`. This is not strictly needed for the new`AdminClient`, but it avoids surprises if it ever adds a topic to `Metadata`via `setTopics` or `addTopic`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3098 from ijuma/kafka-5291-admin-client-no-auto-topic-creation",1
"KAFKA-10665: close all kafkaStreams before purgeLocalStreamsState (#9674)The flaky tests are because we forgot to close the kafkaStreams before purgeLocalStreamsState, so that sometimes there will be some tmp files be created/deleted during streams running(ex: checkpoint.tmp), and caused the DirectoryNotEmptyException or NoSuchFileException be thrown.Reviewers:  Levani Kokhreidze, Bill Bejeck <bbejeck@apache.org>",2
KAFKA-1757 Unmap file prior to delete on windows.,4
"KAFKA-8866; Return exceptions as Optional<ApiException> in authorizer API (#7294)Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
KAFKA-10515: Properly initialize nullable Serdes with default values (#9338)Also introduced the notion of WrappingNullableSerdes (aligned to the conceptof WrappingNullableSerializer and WrappingNullableDeserializer) and centralizedinitialization in WrappingNullables.The added integeration test KTableKTableForeignKeyJoinDistributedTest testswhether all serdes are now correctly set on all stream clients.Reviewers: John Roesler <vvcephei@apache.org>,1
Deleting the KEYS file from trunkgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1182546 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-2676: Fix incorrect package name in testsAlso fixed a couple of other tests with the same issue.This is my original work and I license the work to the project under the project's open source licenseAuthor: Kim Christensen <kich@mvno.dk>Reviewers: Ismael JumaCloses #828 from kichristensen/KAFKA-2676,1
MINOR: Remove redundant CRC validation for non-compressed records in older message formatsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2881 from hachikuji/fix-redundant-crc-check,0
"KAFKA-4750: Bypass null value and treat it as deletes (#4508)Here is the new rule for handling nulls:* in the interface store, put(key, null) are handled normally and value serde will still be applied to null, hence needs to handle null values* in the inner bytes store, null bytes after serialization will be treated as deletes.* in the interface store, if null bytes get returned in get(key), it indicate the key is not available; and hence serde will be avoided and null object will be returned.More changes:* Update javadocs, add unit tests accordingly; augment MockContext to set serdes for the newly added tests.* Fixed a discovered bug which is exposed by the newly added tests.* Use the new API to remove all old APIs in the existing state store tests.* Remove SerializedKeyValueIterator since it is not used any more.This is originally contributed by @evis.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian@confluent.io>",5
KAFKA-8938: Improve allocations during Struct validation in ConnectSchema (#7384)Struct value validation in Kafka Connect can be optimizedto avoid creating an Iterator when the expectedClasses list is ofsize 1. This is a meaningful enhancement for high throughputconnectors.Reviewers: Konstantine Karantasis <konstantine@confluent.io>,5
KAFKA-7441; Allow LogCleanerManager.resumeCleaning() to be used concurrentlyAuthor: Xiongqi Wesley Wu <xiongqi.wu@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5694 from xiowu0/fixrace2,0
"KAFKA-3394; allow null offset metadata in commit APIAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Jun Rao <junrao@gmail.com>Closes #1064 from hachikuji/KAFKA-3394",5
Expose JMX operation to set logger level dynamically; patched by Jun Rao; reviewed by Jay Kreps; KAFKA-429git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1377172 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9555 Added default RLMM implementation based on internal topic storage. (#10579)KAFKA-9555 Added default RLMM implementation based on internal topic storage.This is the initial version of the default RLMM implementation.This includes changes containing default RLMM configs, RLMM implementation, producer/consumer managers.Introduced TopicBasedRemoteLogMetadataManagerHarness which takes care of bringing up a Kafka cluster and create remote log metadata topic and initializes TopicBasedRemoteLogMetadataManager.Refactored existing RemoteLogMetadataCacheTest to RemoteLogSegmentLifecycleTest to have parameterized tests to run both RemoteLogMetadataCache and also TopicBasedRemoteLogMetadataManager.Refactored existing InmemoryRemoteLogMetadataManagerTest, RemoteLogMetadataManagerTest to have parameterized tests to run both InmemoryRemoteLogMetadataManager and also TopicBasedRemoteLogMetadataManager.This is part of tiered storage KIP-405 efforts.Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",5
HOTFIX: Simplify ConsoleConsumer stripWithPrefix function,1
"KAFKA-9034: Use double quotes around $JAVA_HOME evn variableThis allows kafka tools to work on Cygwin where $JAVA_HOME typically contains a space (e.g. ""C:\Program Files\Java\jdkXXX"")Author: sebwills <sw@sebwills.com>Reviewers: Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8481 from sebwills/patch-1",5
"KAFKA-4954; Request handler utilization quotasSee KIP-124 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-124+-+Request+rate+quotas) for detailsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2744 from rajinisivaram/KAFKA-4954",5
MINOR: Update system test MANIFEST.inewencpSome *.properties files were missing from `kafkatest` package. This update makes `kafkatest` services once again useable by external dependenciesI've tested this change on aws with confluent system testsAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-PostavaCloses #385 from granders/minor-update-test-manifest,5
KAFKA-3081: KTable AggregationAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #761 from guozhangwang/K3081,2
"KAFKA-4476: Kafka Streams gets stuck if metadata is missing - break loop in StreamPartitionAssigner.assign() in case partition metadata is missing - fit state transition issue (follow up to KAFKA-3637: Add method that checks if streams are initialised) - some test improvementsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Ismael Juma, Guozhang WangCloses #2209 from mjsax/kafka-4476-stuck-on-missing-metadata",5
MINOR: Fix deadlock in ZooKeeperClient.close() on session expiry (#4672)Reviewers: Jun Rao <junrao@gmail.com>,0
"KAFKA-3008: Parallel start and stop of connectors and tasks in ConnectAuthor: Konstantine Karantasis <konstantine@confluent.io>Author: Konstantine Karantasis <k.karantasis@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1788 from kkonstantine/KAFKA-3008-Parallel-start-and-stop-of-connectors-and-tasks",5
Minor log4j fix to ISR shrinking logic,2
"KAFKA-3013: Display the topic-partition in the exception message for expired batches in recordAccumulatorAdded topic-partition information to the exception message on batch expiry in RecordAccumulatorAuthor: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Gwen Shapira, Lin Dong, Ismael JumaCloses #695 from MayureshGharat/kafka-3013",5
MINOR: enable reassign_partitions_test.py for kraft (#11064)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
KAFKA-1170 ISR can be inconsistent during partition reassignment for low throughput partitions; reviewed by Jun Rao and Guozhang Wang,5
"MINOR: fixup typo in ops.htmlpretty boring docfix, ""no"" -> ""not""Author: Scott Ferguson <smferguson@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2269 from smferguson/fixup_typo_in_add_remove_topics",4
ConsumerIterator throws a IllegalStateException after a ConsumerTimeout occurs; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-241git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1233501 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-149: Current perf directory has buggy perf tests; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179791 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7104: More consistent leader's state in fetch response (#5305)Do not update LogReadResult after it is initially populated when returning fetches immediately (i.e. without hitting the purgatory). This was done in #3954 as an optimization so that the followers get the potentially updated high watermark. However, since many things can happen (like deleting old segments and advancing log start offset) between initial creation of LogReadResult and the update, we can hit issues like log start offset in fetch response being higher than the last offset in fetched records.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-132 Patch from Scott Andreas to avoid flush when there is nothing to flush. Looks like due to atime attribute in the filesystem this can lead to flushing file metadata.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1171889 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9344: Override default values inside ConsumerConfigs (#7876)Similar to KAFKA-8928, during consumer construction, some configs might be overridden (client.id for instance), but the actual values will not be reflected in the info log. It'd better display the overridden values for those configs.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1459 kafka.tools.ConsumerOffsetChecker throws NoNodeException; reviewed by Neha Narkhede,1
kafka-1609; New producer metadata response handling should only exclude a PartitionInfo when its error is LEADER_NOT_AVAILABLE; patched by Dong Lin; reviewed by Jun Rao,0
KAFKA-10316: Consider renaming getter method for Interactive Queries (#9146)- updates docs for KIP-648Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-8901; Extend consumer group command to use the new Admin API to delete consumer offsets (KIP-496)It add support to delete offsets in the `kafka-consumer-group`.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: David Jacot <djacot@confluent.io>Reviewers: Gwen ShapiraCloses #7362 from dajac/KAFKA-8901-delete-offsets-command",4
"KAFKA-6324; Change LogSegment.delete to deleteIfExists and harden log recovery- Rename `delete()` to `deleteIfExists()` in `LogSegment`, `AbstractIndex`and `TxnIndex`. Throw exception in case of IO errors for more informativeerrors and to make it less likely that errors are ignored, `boolean` is usedfor the case where the file does not exist (like `Files.deleteIfExists()`).- Fix an instance of delete while open (should fix KAFKA-6322 andKAFKA-6075).- `LogSegment.deleteIfExists` no longer throws an exception if any ofthe files it tries to delete does not exist (fixes KAFKA-6194).- Remove unnecessary `FileChannel.force(true)` when deleting file.- Introduce `LogSegment.open()` and use it to improve encapsulationand reduce duplication.- Expand functionality of `LogSegment.onBecomeInactiveSegment()`to reduce duplication and improve encapsulation.- Use `AbstractIndex.deleteIfExists()` instead of deleting files manually.- Improve logging when deleting swap files.- Use CorruptIndexException instead of IllegalArgumentException.- Simplify `LogCleaner.cleanSegments()` to reduce duplication andimprove encapsulation.- A few other clean-ups in Log, LogSegment, etc.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Ted Yu <yuzhihong@gmail.com>Closes #4040 from ijuma/kafka-5829-follow-up",2
MINOR: Remove integration package prefix from ConsumerTopicCreationTest (#6916)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"KAFKA-5061 - Make default Worker Task client IDs distinct (#6097)Use the task ID to make the default client IDs used by Worker Tasks distinct and stable. This is avoids name conflicts on JMX MBeans and enables useful monitoring.This implements https://cwiki.apache.org/confluence/display/KAFKA/KIP-411%3A+Make+default+Kafka+Connect+worker+task+client+IDs+distinct.See: https://issues.apache.org/jira/browse/KAFKA-5061Author: Paul Davidson <>Reviewer: Cyrus Vafadari <cyrusv@alum.mit.edu>, Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
Fix streams web doc configs tables (#4943)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"MINOR: Add pull request templateAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4174 from ijuma/pull-request-template",5
"KAFKA-2558: ServerShutdownTest is failing intermittentlySee jira for a description.Author: fpj <fpj@apache.org>Reviewers: Onur Karaman, Ismael Juma, Guozhang WangCloses #224 from fpj/KAFKA-2558",0
MINOR: Move KTable source topic for changelog to optimization framework (#6500)Since we've added Kafka Streams optimizations in 2.1 we need to move the optimization for source KTable nodes (use source topic as changelog) to the optimization framework.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"MINOR: Removed unnecessary Vagrantfile hackThe hack here is no longer necessary with up-to-date versions of Vagrant, vagrant-hostmanager, and vagrant-aws. What's more, the change in c8b60b63 caused a chain of infinite recursion on OSX, preventing bringup of VMs on a typical laptop.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #867 from granders/remove-vagrantfile-hack and squashes the following commits:14f4395 [Geoff Anderson] Removed uneccessary references to version 1.5.0 of vagrant-hostmanager8799afe [Geoff Anderson] Removed Vagrantfile hack which is no longer necessary with up-to-date versions of Vagrant, vagrant-hostmanager, and vagrant-aws",5
"KAFKA-5636: SlidingWindows (KIP-450) (#9039)Add SlidingWindows API, implementation, and tests.An edge case and an optimization are left to follow-on work.Implements: KIP-450Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",5
"KAFKA-14187: kafka-features.sh: add support for --metadata (#12571)This PR adds support to kafka-features.sh for the --metadata flag, as specified in KIP-778.  Thisflag makes it possible to upgrade to a new metadata version without consulting a table mappingversion names to short integers. Change --feature to use a key=value format.FeatureCommandTest.scala: make most tests here true unit tests (that don't start brokers) in orderto improve test run time, and allow us to test more cases. For the integration test part, test bothKRaft and ZK-based clusters. Add support for mocking feature operations in MockAdminClient.java.upgrade.html: add a section describing how the metadata.version should be upgraded in KRaftclusters.Add kraft_upgrade_test.py to test upgrades between KRaft versions.Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",3
"MINOR: KStream: fix typo in javadocAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Guozhang Wang, Damian GuyCloses #2668 from miguno/trunk-kstream-javadoc-typo",2
"KAFKA-4208; Add Record HeadersAs per KIP-82Adding record headers api to ProducerRecord, ConsumerRecordSupport to convert from protocol to api added Kafka Producer, Kafka Fetcher (Consumer)Updated MirrorMaker, ConsoleConsumer and scala BaseConsumerAdd RecordHeaders and RecordHeader implementation of the interfaces Headers and HeaderSome bits using are reverted to being Java 7 compatible, for the moment until KIP-118 is implemented.Author: Michael Andre Pearce <Michael.Andre.Pearce@me.com>Reviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2772 from michaelandrepearce/KIP-82",5
correlationId is not set in FetchRequest in AbstractFetcherThread; patched by Jun Rao; reviewed by Neha Narkhede and Swapnil Ghike; kafka-738,1
"KAFKA-3517; Add documentation for SASL/PLAINDocumentation corresponding to KIP-43 - SASL/PLAIN and multiple mechanism support.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Magnus Edenhill <apache_m@edenhill.se>, Jun Rao <junrao@gmail.com>Closes #1232 from rajinisivaram/KAFKA-3517",5
"KAFKA-7884; Docs for message.format.version should display valid values (#6209)The config docs for message.format.version and log.message.format.version show invalid (corrupt?) ""valid values"". The problem is that`ApiVersionValidator#toString` is missing. In contrast, all other Validators like `ThrottledReplicaListValidator` or `Range`, have its own `toString` method. This patch solves this problem by adding `ApiVersionValidator#toString`. It also provides a unit test for it.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Use JUnit 5 in raft module (#9331)I also removed a test class with no tests currently (Jason filed KAFKA-10519 forfilling the test gap).Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Fix export command for additional env vars in connect system testsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2126 from kkonstantine/MINOR-Fix-formatting-of-env-vars-in-connect-system-test-template,5
"MINOR: Eliminate unnecessary partition lookups (#8484)There are two cases in the fetch pass where a partition is unnecessarily looked upfrom the partition Pool, when one is already accessible. This will be a fairly minorimprovement on high partition count clusters, but could be worth 1% from someprofiles I have seen.More importantly, the code is cleaner this way.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
MINOR: enable KRaft in MetadataRequestTest (#11637)Reviewers: David Arthur <mumrah@gmail.com>,5
"KAFKA-4526; Disable throttling test until it can be fixed correctly.At present, the test is fragile in the sense that the console consumerhas to start and be initialized before the verifiable producer beginsproducing in the produce-consume-validate loop.If this doesn't happen, the consumer will miss messages at the head ofthe log and the test will fail.At present, the consumer is considered inited once it has a PID. This isa weak assumption. The plan is to poll appropriate metrics (likepartition assignment), and use those as a proxy for consumerinitialization. That work will be tracked in a separate ticket. For now,we will disable the tests so that we can get the builds healthy again.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2278 from apurvam/KAFKA-4526-throttling-test-failures",3
"KAFKA-9823: Follow-up, check state for handling commit error response (#8548)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>",5
Handle topic names with / on Kafka server; patched by Jun Rao; reviewed by Neha Narkhede; kafka-470git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1381856 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-2358: Cluster collection returning methods never return nullSee https://issues.apache.org/jira/browse/KAFKA-2358Author: Stevo Slavic <sslavic@gmail.com>Reviewers: Jason Gustafson, Guozhang WangCloses #96 from sslavic/feature/KAFKA-2358",0
"KAFKA-10673: Cache inter broker listener name used in connection quotas (#9555)`config.interBrokerListenerName` and `config.listeners` were called several times per connection accept. As these calls are expensive, it is preferable to rely on cached values.Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-4056: Kafka logs values of sensitive configs like passwordsIn case of unknown configs, only list the name without the valueAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Jaikiran, Gwen Shapira, Grant Henke, Ryan Pridgeon, Dustin CoteCloses #1759 from mimaison/KAFKA-4056",5
"KAFKA-7778: document scala suppress API (#6586)Document the minor API change.Reviewers: Casey Green <greenc421@gmail.com>, Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",4
"KAFKA-5357 follow-up: Yammer metrics, not Kafka MetricsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3242 from guozhangwang/K5357-yammer-metrics",5
"MINOR: Make JAAS configurable via template variables in system tests (#5554)Currently, the only way in system tests to add a new variable to the `jaas.conf` template file is to directly edit the path the config is constructed by adding new keyword arguments.This wasn't necessarily a big problem, since you'd only need edit the `security_config.py` file as JAAS settings should come from the security settings.Now, with the addition of [KIP-342](https://cwiki.apache.org/confluence/display/KAFKA/KIP-342%3A+Add+support+for+Custom+SASL+extensions+in+OAuthBearer+authentication), the OAuthBearer JAAS config supports arbitrary values in the form of SASL extensions. This patch exposes a more convenient API to overrides these values in system tests.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-3829: Ensure valid configuration prior to creating connectorAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Shikhar Bhushan <shikhar@schmizz.net>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1911 from hachikuji/KAFKA-3829",5
KAFKA-5462: Add configuration to build custom SSL principal name (KIP-371)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>Closes #5684 from omkreddy/KAFKA-5462-SSL-Name,5
"KAFKA-12889: log clean relative index range check of group consider empty log segment to avoid too many empty log segment left (#10818)To avoid log index 4 byte relative offset overflow, log cleaner group check log segments offset to make sure group offset range not exceed Int.MaxValue.This offset check currentlly not cosider next is next log segment is empty, so there will left empty log files every about 2^31 messages.The left empty logs will be reprocessed every clean cycle, which will rewrite it with same empty content, witch cause little no need io.For __consumer_offsets topic, normally we can set cleanup.policy to compact,delete to get rid of this.My cluster is 0.10.1.1, but after analyze the trunk code, it should has same problem too.Co-authored-by: Liu Qiang(BSS-HZ) <qliu.zj@best-inc.com>Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-3557; Update rocksdb to 4.4.1 and patch updates to snappy and slf4j* The hope is that RocksDb 4.4.1 is more stable than 4.1.0 (occasional segfaults) and 4.2.0 (very frequent segfaults), release notes for 4.4.1: https://www.facebook.com/groups/rocksdb.dev/permalink/925995520832296/* slf4j 1.7.21 includes thread-safety fixes: http://www.slf4j.org/news.html* snappy 1.1.2.4 includes performance improvements requested by Spark, which apply to our usage: https://github.com/xerial/snappy-java/blob/master/Milestone.mdI ran the stream tests several times and they passed every time while 4.2.0 segfaulted every time.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1219 from ijuma/kafka-3557-update-rocks-db-4.4.1-snappy-slf4j",5
MINOR: Remove redundant checkpoint thread started field in ReplicaManager (#6813)We have two fields `highWatermarkCheckPointThreadStarted` and `hwThreadInitialized` which appear to be serving the same purpose. This patch gets rid of `hwThreadInitialized`.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-7134: KafkaLog4jAppender exception handling with ignoreExceptions (#5415)Reviewers: Andras Beni <andrasbeni@cloudera.com>, Sandor Murakozi <smurakozi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-12332; Error partitions from topics with invalid IDs in LISR requests (#10143)Changes how invalid IDs are handled in LeaderAndIsr requests. The ID check now occurs before leader epoch. If the ID exists and is invalid, the partition is ignored and a new `INCONSISTENT_TOPIC_ID` error is returned in the response.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-12293: Remove JCenter from buildscript and delete buildscript.gradleThey're no longer used and JFrog is sunsetting JCenter.https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenterReviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-10535: Split ProcessorContext into Processor/StateStore/Record Contexts (#9361)Migrate different components of the old ProcessorContext interfaceinto separate interfaces that are more appropriate for their usages.See KIP-478 for the details.Reviewers: Guozhang Wang <guozhang@apache.org>, Paul Whalen <pgwhalen@gmail.com>",3
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunk,1
JUnit extensions for integration tests (#9986)Adds JUnit 5 extension for running the same test with different types of clusters. See core/src/test/java/kafka/test/junit/README.md for details,3
restrict topic names (reopened); patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-495git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1390800 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: test ktable state store creationguozhangwang* a test for ktable state store creationAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #661 from ymatsuda/more_ktable_test,3
"[MINOR] Guard against crashing on invalid key range queries (#6521)Due to KAFKA-8159, Streams will throw an unchecked exception when a caching layer or in-memory underlying store is queried over a range of keys from negative to positive. We should add a check for this and log it then return an empty iterator (as the RocksDB stores happen to do) rather than crashReviewers: Bruno Cadonna <bruno@confluent.io> Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-9324: Drop support for Scala 2.11 (KIP-531) (#7859)* Adjust build and documentation.* Use lambda syntax for SAM types in `core`, `streams-scala` and`connect-runtime` modules.* Remove `runnable` and `newThread` from `CoreUtils` as lambdasyntax for SAM types make them unnecessary.* Remove stale comment in `FunctionsCompatConversions`,`KGroupedStream`, `KGroupedTable' and `KStream` about Scala 2.11,the conversions are needed for Scala 2.12 too.* Deprecate `org.apache.kafka.streams.scala.kstream.Suppressed`and use `org.apache.kafka.streams.kstream.Suppressed` instead.* Use `Admin.create` instead of `AdminClient.create`. Static methodsin Java interfaces can be invoked since Scala 2.12. I noticed thatMirrorMaker 2 uses `AdminClient.create`, but I did not change themas Connectors have restrictions on newer client APIs.* Improve efficiency in a few `Gauge` implementations by avoidingunnecessary intermediate collections.* Remove pointless `Option.apply` in `ZookeeperClient``SessionState` metric.* Fix unused import/variable and other compiler warnings.* Reduce visibility of some vals/defs.Reviewers: Manikumar Reddy <manikumar@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Gwen Shapira <gwen@confluent.io>",5
KAFKA-13201: Convert KTable suppress to new PAPI (#11213)Migrate Suppress as part of the migration of KStream/KTable operations to the new Processor API (KAFKA-8410)Reviewers: John Roesler <vvcephei@apache.org>,1
KAFKA-2797: Only run rat when in the .git repository since it require s the .gitignore to generate the list of files to ignoreAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #485 from ewencp/kafka-2797-disable-rat-when-git-missing,2
"KAFKA-6390: Update ZooKeeper to 3.4.11, Gradle and other minor updates (#4345)Updates:- Gradle, gradle plugins and maven artifact updated- Bug fix updates for ZooKeeper, Jackson, EasyMock and SnappyNot updated:- RocksDB as it often causes issues, so better done separately- args4j as our test coverage is weak and the update was afeature releaseAlso fixed scala-reflect version to match scala-library.Release notes for ZooKeeper 3.4.11:https://zookeeper.apache.org/doc/r3.4.11/releasenotes.htmlA notable fix is improved handling of UnknownHostException:https://issues.apache.org/jira/browse/ZOOKEEPER-2614Manually tested that IntelliJ import and build still works.Relying on existing test suite otherwise.Reviewers: Jun Rao <junrao@gmail.com>",3
"test access, fixed spacegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1245316 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-10436: Implement KIP-478 Topology changes (#9221)Convert Topology#addProcessor and #addGlobalStoreAlso, convert some of the internals in support of addProcessorReviewers: Bill Bejeck <bbejeck@apache.org>",1
"MINOR: Move `KafkaYammerMetrics` to server-common (#11970)With major server components like the new quorum controller being moved outside of the `core` module, it is useful to have shared dependencies moved into `server-common`. An example of this is Yammer metrics which server components still rely heavily upon. All server components should have access to the default registry used by the broker so that new metrics can be registered and metric naming conventions should be standardized. This is particularly important in KRaft where we are attempting to recreate identically named metrics in the controller context. This patch takes a step in this direction. It moves `KafkaYammerMetrics` into `server-common` and it implementsstandard metric naming utilities there. Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",4
"KAFKA-4943: Make /config/users with SCRAM credentials not world-readableAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma, Jun RaoCloses #2733 from rajinisivaram/KAFKA-4943",5
"KAFKA-8237; Untangle TopicDeleteManager and add test cases (#6588)The controller maintains state across `ControllerContext`, `PartitionStateMachine`, `ReplicaStateMachine`, and `TopicDeletionManager`. None of this state is actually isolated from the rest. For example, topics undergoing deletion are intertwined with the partition and replica states. As a consequence of this, each of these components tends to be dependent on all the rest, which makes testing and reasoning about the system difficult. This is a first step toward untangling all the state. This patch moves it all into `ControllerContext` and removes many of the circular dependencies. So far, this is mostly a direct translation, but in the future we can add additional validation in `ControllerContext` to make sure that state is maintained consistently.Additionally, this patch adds several mock objects to enable easier testing: `MockReplicaStateMachine` and `MockPartitionStateMachine`. These have simplified logic for updating the current state. This is used to create some new test cases for `TopicDeletionManager`. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jun Rao <junrao@gmail.com>",1
change comments,4
KAFKA-915; Mirror maker system tests should wait for topics to be created. (This patch is a work-around until KAFKA-956 is resolved.); patched by John Fung; reviewed by Joel Koshy.,0
MINOR: Remove code of removed metric (#12453)When we removed metric skipped-records in 3.0 we missed toremove some code related to that metric.Reviewer: Guozhang Wang <wangguoz@gmail.com>,4
"KAFKA-10017: fix flaky EosBetaUpgradeIntegrationTest (#8963)The current failures we're seeing with this test are due to faulty assumptions that it makes and not any real bug in eos-beta (at least, from what I've seen so far).The test relies on tightly controlling the commits, which it does by setting the commit interval to MAX_VALUE and manually requesting commits on the context. In two phases, the test assumes that any pending data will be committed after a rebalance. But we actually take care to avoid unnecessary commits -- with eos-alpha, we only commit tasks that are revoked while in eos-beta we must commit all tasks if any are revoked, but only if the revoked tasks themselves need a commit.The failure we see occurs when we try to verify the committed data after a second client is started and the group rebalances. The already-running client has to give up two tasks to the newly started client, but those tasks may not need to be committed in which case none of the tasks would be. So we still have an open transaction on the partitions where we try to read committed data.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-2480: Handle retriable and non-retriable exceptions thrown by sink tasks.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #450 from ewencp/kafka-2480-unrecoverable-task-errors,0
kafka-2115; Error updating metrics in RequestChannel; patched by Gwen Shapira; reviewed by Jun Rao,5
"MINOR: Subscribe/assign calls should be logged at info level (#6299)Since we are logging offset resets and such at info level, it makes sense to use the same level for subscriptions and assignments.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-9539; Add leader epoch in StopReplicaRequest (KIP-570) (#8257)This PR adds the leader epoch field to `StopReplicaRequest` as documented in KIP-570. Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-1891 MirrorMaker hides consumer exception - making troubleshooting challenging patch by Gwen Shapira reviewed by Joe Stein,1
"MINOR: fix flaky EosIntegrationTest.shouldCommitCorrectOffsetIfInputTopicIsTransactional[at_least_once] (#11878)In this test, we started Kafka Streams app and then write to input topic in transaction. It's possible when streams commit offset, transaction hasn't finished yet. So the streams committed offset could be less than the eventual endOffset.This PR moves the logic of writing to input topic before starting streams app.Reviewers: John Roesler <vvcephei@apache.org>",2
"KAFKA-6486: Implemented LinkedHashMap in TimeWindows (#4628)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
kafka-1424; (followup patch) transient unit test failure in testSendWithDeadBroker; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,5
"KAFKA-5163; Support replicas movement between log directories (KIP-113)Author: Dong Lin <lindong28@gmail.com>Reviewers: Tom Bentley <tbentley@redhat.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3874 from lindong28/KAFKA-5163",2
"KAFKA-5839: Upgrade Guide doc changes for KIP-130Author: Florian Hussonnois <florian.hussonnois@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3811 from fhussonnois/KAFKA-5839minor fixes",0
MINOR: Add test for ConsumerNetworkClient.trySend (#6739)Reviewers: Jason Gustafson <jason@confluent.io>,5
HOTFIX: Fix compilation error in `ProducerStateManagerTest` (#6603)Reviewers: Jason Gustafson <jason@confluent.io>,5
"Revert ""MINOR: Remove redundant argument from TaskMetricsGroup#recordCommit (#9642)""This reverts commit 047ad654da7903f3903760b0e6a6a58648ca7715.",4
"KAFKA-3143: Controller should transition offline replicas on startupAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #5041 from omkreddy/KAFKA-3143",5
"KAFKA-3636; Change default max session timeout to 5 minutesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Onur Karaman <okaraman@linkedin.com>, Ismael Juma <ismael@juma.me.uk>Closes #1284 from hachikuji/KAFKA-3636",2
"MINOR: Extend release.py with a subcommand for staging docs into the kafka-site repoAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>Closes #3917 from ewencp/stage-docs",2
MINOR: Followers should not have any remote replica states left over from previous leadership (#12138)This patch ensures that followers don't have any remote replica states left over from previous leadership.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-10001: Should trigger store specific callback if it is also a listener (#8670)The store's registered callback could also be a restore listener, in which case it should be triggered along with the user specified global listener as well.Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-13590:rename InternalTopologyBuilder#topicGroups (#11704)Renamed the often confusing and opaque #topicGroups API to #subtopologyToTopicsInfoReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
MINOR: Fix reference to argument in `LogSegment.translateOffset`Changed the lowerBound argument reference in the summary comment of the translateOffset method to match the actual argument name: startingFilePosition.Author: Luke Zaparaniuk <luke.zaparaniuk@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1876 from lukezaparaniuk/patch-1,2
"MINOR: Remove unneeded error handlers in deprecated request objectsThese handlers were previously used on the broker to handle uncaught exceptions, but now the broker users the new Java request objects exclusively.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3646 from hachikuji/remove-old-request-error-handlers",4
KAFKA-5422; Handle multiple transitions to ABORTABLE_ERROR correctlyAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3285 from apurvam/KAFKA-5422-allow-multiple-transitions-to-abortable-error,0
MINOR: AdminClient consumer group domain objects should have public constructors (#5063)These constructors should be public to allow users to write test cases using them. We follow a similar pattern for the other domain objects that we expose in `AdminClient` (e.g. `TopicDescription`).Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-12170: Fix for Connect Cast SMT to correctly transform a Byte array into a string (#9950)Cast SMT transformation for bytes -> string.Without this fix, the conversion becomes ByteBuffer.toString(), which always gives this useless result:    ""java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]""With this change, the byte array is converted into a base64 string of the byte buffer content.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",4
"KAFKA-1042 logSegments(from, to) Misses first segment.I think this patch also fixes the continual timing problems we have had in log tests. The root causewas that we weren't passing through the clock instance so we were mixing instances of MockTime and SystemTime.This worked only because MockTime initializes to SystemTime.milliseconds so as long as the test took less than 1 ms it worked!",1
MINOR: Bump version to 2.2.0-SNAPSHOTAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #5744 from lindong28/bump-up-version-2.2.0,5
"KAFKA-10000: Exactly-once source tasks (#11780)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Tom Bentley <tbentley@redhat.com>",5
MINOR: Tweak upgrade note on KIP-62 to include request.timeout.msAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1960 from hachikuji/add-note-on-request-timeout,1
MINOR: Remove errant lock.unlock() call from RoundTripWorker (#6612)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
remove support for format for magic byte 0 in 0.8; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-461git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1375367 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Remove redundant default parameter values in call to LogSegment.open (#9710)Reviewers: Jun Rao <junrao@gmail.com>,2
MINOR: Remove unused IteratorTemplate (#5903)There seems to be no reason to keep this around since it is not used outsideof testing and AbstractIterator is basically the same thing.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
MINOR: Upgrade jackson-databind to 2.9.9.3 (#7125)2.9.9.1 and 2.9.9.2 include security fixes while 2.9.9.3 fixes a regressionintroduced in 2.9.9.2.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"MINOR: Document ""high watermark"" magic value for delete records requestAuthor: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4119 from ppatierno/minor-delrecords-prot",4
"MINOR: Remove unnecessary synchronized block in org.apache.kafka.streams.processor.internals.StreamTaskThe StreamTask is owned by a specific thread, so it doesn't seem necessary to synchronized the processing of the records as discussed with guozhangwang  on the dev mailing listAuthor: PierreCoquentin <pierre.coquentin@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1688 from PierreCoquentin/trunk",1
"KAFKA-3432; Cluster.update() thread-safetyReplace `update` with `withPartitions`, which returns a copy instead of mutating the instance.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1118 from ijuma/kafka-3432-cluster-update-thread-safety",5
"MINOR: Minor improvements in consumer close timeout handlingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2348 from hachikuji/minor-cleanup-for-kip-102",4
MINOR: Fix error logged if not enough alive brokers for transactions state topicAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2954 from ijuma/fix-error-message-if-transactions-topic-replication-factor-too-low,0
MINOR: Improve description of `max.poll.records` config (#10506)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-10068: add task assignment performance tests (#8892)Add tests to bound the performance of the various Streams task assignorswhen making assignments over large clusters/tasks.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-4649: Improve test coverage GlobalStateManagerImplAdd coverage for exception paths in `initialize()`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2452 from dguy/kafka-4649",5
"KAFKA-5535: Handle null values in ExtractFieldAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3559 from ewencp/kafka-5535-extract-field-null",4
"MINOR: Update doc for 3.1 (#11539)* Update main version of main documentation and add link to previous version;* Update quick start guide (links do not work yet obviously);* Add upgrade section.Reviewers: Luke Chen <showuon@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-4677: Avoid unnecessary task movement across threads during rebalanceMakes task assignment more sticky by preferring to assign tasks to clients that had previously had the task as active task. If there are no clients with the task previously active, then search for a standby. Finally falling back to the least loaded client.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2429 from dguy/kafka-4677",5
"KAFKA-2475: Make Copycat only have a Converter class instead of Serializer, Deserializer, and Converter.The Converter class now translates directly between byte[] and Copycat's dataAPI instead of requiring an intermediate runtime type like Avro's GenericRecordor Jackson's JsonNode.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #172 from ewencp/kafka-2475-unified-serializer-converter and squashes the following commits:566c52f [Ewen Cheslack-Postava] Checkstyle fixes320d0df [Ewen Cheslack-Postava] Restrict offset format.85797e7 [Ewen Cheslack-Postava] Add StringConverter for using Copycat with raw strings.698d65c [Ewen Cheslack-Postava] Move and update outdated comment about handing of types for BYTES type in Copycat.4bed051 [Ewen Cheslack-Postava] KAFKA-2475: Make Copycat only have a Converter class instead of Serializer, Deserializer, and Converter.",1
"KAFKA-9450: Follow-up; Forbid process after closed (#9083)A few cleanup and tighten screws:* When a processor is closed (due to topology-closure), we should not allow processing more records.* Let all built-in processors to extend from AbstractProcessor.* Remove duplicated override functions.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
KAFKA-13577: Replace easymock with mockito in kafka:core - part 2 (#11673)Reviewers: Tom Bentley <tbentley@redhat.com>,5
"MINOR: KIP-138 renaming of string namesAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3796 from guozhangwang/kip-138-minor-renames",5
"KAFKA-4969: Attempt to evenly distribute load of tasks (#4410)* removed round-robin approach, try to assign tasks to consumers in a more even manner, added unit test.* better interleaved task approach, updated testsReviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <mjsax@apache.org>",3
"KAFKA-9106 make metrics exposed via jmx configurable (#7674)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
Update implementation.html (#10771)Fixing the link to a cited blog. The existing link now points to a steroid website so need to pull the blog from internet archives.,2
"MINOR: skip listOffsets request for newly created changelog topics (#8662)A small hotfix to avoid an extra probing rebalance the first time an application is launched.This should particularly improve the testing experience.Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>",5
MINOR: Fix vagrant rsync exclude argumentExisting VMs will need to be re-provisioned or re-created to pick up this change.Reference docs:https://www.vagrantup.com/docs/synced-folders/rsync.htmlAuthor: Magnus Edenhill <magnus@edenhill.se>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2047 from edenhill/fix_vm_rsync_exclude,0
"KAFKA-12459; Use property testing library for raft event simulation tests (#10323)This patch changes the raft simulation tests to use jqwik, which is a property testing library. This provides two main benefits:- It simplifies the randomization of test parameters. Currently the tests use a fixed set of `Random` seeds, which means that most builds are doing redundant work. We get a bigger benefit from allowing each build to test different parameterizations.- It makes it easier to reproduce failures. Whenever a test fails, jqwik will report the random seed that failed. A developer can then modify the `@Property` annotation to use that specific seed in order to reproduce the failure.This patch also includes an optimization for `MockLog.earliestSnapshotId` which reduces the time to run the simulation tests dramatically.Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-12229: Restore original class loader in integration tests using EmbeddedConnectCluster during shutdown  (#9942)Fixes errors such as: ```java.lang.NullPointerException at org.apache.kafka.connect.mirror.MirrorSourceConnector.listTopics(MirrorSourceConnector.java:348) at org.apache.kafka.connect.mirror.MirrorSourceConnector.findSourceTopicPartitions(MirrorSourceConnector.java:192) at org.apache.kafka.connect.mirror.MirrorSourceConnectorTest.testRefreshTopicPartitionsTopicOnTargetFirst(MirrorSourceConnectorTest.java:222)```It was a difficult to debug issue due to class loading interference between the Connect worker and Mockito. Digging into the Mockito, found it's not about JUnit 5, it's because of the class loader. In Mockito, we rely on the class loader to generate the proxy instance ([source](https://github.com/mockito/mockito/blob/release/3.x/src/main/java/org/mockito/internal/creation/bytebuddy/SubclassBytecodeGenerator.java#L91)) to intercept the method call, and if the class loader is not expected, we'll generate the wrong proxy instance (with wrong class path). We set the class loader during connector start to resolve conflicting dependencies ([KIP-146](https://cwiki.apache.org/confluence/display/KAFKA/KIP-146+-+Classloading+Isolation+in+Connect)), so we should set it back to the original class loader after connector stop in tests (`EmbeddedConnectCluster` is only used in tests) for the following Mockito works as expected.So, there's an interference of integration tests with unit tests when Connect integration tests run before the MM2 unit tests, and that will cause the Mockito used in unit tests not work as expected.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",1
"KAFKA-9407: Return an immutable list from poll in SchemaSourceTask (#7939)Simple fix to return in all cases an immutable list from poll in SchemaSourceTask.Co-authored-by: David Mollitor <dmollitor@apache.org>Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <github@juma.me.uk>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-12648: Wrap all exceptions thrown to handler as StreamsException & add TaskId field (#11405)To help users distinguish which task an exception was thrown from, and which NamedTopology if it exists, we add a TaskId field to the StreamsException class. We then make sure that all exceptions thrown to the handler are wrapped as StreamsExceptions, to help the user simplify their handling code as they know they will always need to unwrap the thrown exception exactly once.Reviewers: Walker Carlson <wcarlson@confluent.io>, Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",5
"KAFKA-5853; implement WindowedKStreamAdd the `WindowedKStream` interface and implementation of methods that don't require `Materialized`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3809 from dguy/kgrouped-stream-windowed-by",5
"MINOR: Rename SslTransportLayer.State.""NOT_INITALIZED"" enum value to ""NOT_INITIALIZED""The enum ```State``` is private so it is fine to fix typo without breaking compatibility.Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8932 from chia7712/MINOR-8932",4
KAFKA-2847; Remove principal builder class from client configsAlso mark `PrincipalBuilder` as `Unstable` and  tweak docs.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #542 from ijuma/kafka-2847-remove-principal-builder-class-from-client-configs,5
"MINOR: Update Gradle to 5.4.1 and update its plugins  (#6436)Details: * gradle: 5.1.1  -->  5.4.1 * grgit: 1.9.3  -->  3.1.1 (breaking change release: artifact name is changed;also, Grgit.open' usage is slightly refactored) * gradle-versions-plugin: 0.20.0 --> 0.21.0 * shadow: 4.0.3  -->  4.0.4 * spotless-plugin-gradle: 3.17.0  --> 3.23.0 * checkstyle: 8.10 --> 8.20 * spotbugs: 3.1.8 --> 3.1.12 * jacoco: 0.8.2 --> 0.8.3",0
MINOR: Enable kraft in ApiVersionTest (#11667)This patch enables `ApiVersionsTest` to test both kraft brokers and controllers. It fixes a minor bug in which the `Envelope` request to be exposed from `ApiVersions` requests to the kraft broker. Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-6319: Quote strings stored in JSON configsThis is required for ACLs where SSL principals containspecial characters (e.g. comma) that are escaped usingbackslash. The strings need to be quoted for JSON toensure that the JSON stored in ZK is valid.Also converted `SslEndToEndAuthorizationTest` to use aprincipal with special characters to ensure that thispath is tested.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4303 from rajinisivaram/KAFKA-6319,5
"KAFKA-5073: Kafka Streams stuck rebalancing after exception thrown in rebalance listenerAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Eno Thereska, Guozhang WangCloses #2856 from mjsax/kafka-5073",5
"KAFKA-14020: Performance regression in Producer (#12365)As part of KAFKA-10888 work, there were a couple regressions introduced:A call to time.milliseconds() got moved under the queue lock, moving it back outside the lock. The call may be expensive and cause lock contention. Now the call is moved back outside of the lock.The reference to ProducerRecord was held in the batch completion callback, so it was kept alive as long as the batch was alive, which may increase the amount of memory in certain scenario and cause excessive GC work. Now the reference is reset early, so the ProducerRecord lifetime isn't bound to the batch lifetime.Tested via manually crafted benchmark, lock profile shows ~15% lock contention on the ArrayQueue lock without the fix and ~5% lock contention with the fix (which is also consistent with pre-KAFKA-10888 profile).Alloc profile shows ~10% spent in ProducerBatch.completeFutureAndFireCallbacks without the fix vs. ~0.25% with the fix (which is also consistent with pre-KAFKA-10888 profile).Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2
KAFKA-675 Allow the user to override the host that we bind to. Patch from Matan Amir<matan.amir@voxer.com> with slight changesto improve error messages for a bad host or port.,0
"KAFKA-8086: Use 1 partition for offset topic when possible (#7356)I realized some flaky tests failed at setup or calls that tries to create offset topics, and I think using one partition and one replica would be sufficient in these cases.Reviewers: Bill Bejeck <bill@confluent.io>",5
"KAFKA-10600: Connect should not add error to connector validation values for properties not in connector’s ConfigDef (#9425)Connect should not always add an error to configuration values in validation results that don't have a `ConfigKey` defined in the connector's `ConfigDef`, and any errors on such configuration values included by the connector should be counted in the total number of errors. Added more unit tests for `AbstractHerder.generateResult(...)`.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: Remove tag from metric to measure process-rate on source nodes (#8175)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
MINOR: Broker should disallow downconversion of transactional/idempotent recordsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3118 from hachikuji/disallow-transactional-idempotent-downconversion,1
"KAFKA-8897: Upgrade RocksDB to 6.19.3 (#10568)This PR upgrades RocksDB to 6.19.3. After the upgrade the Gradle build exited with code 134 due to SIGABRT signals (""Pure virtual function called!"") coming from the C++ part of RocksDB. This error was caused by RocksDB state stores not properly closed in Streams' code. This PR adds the missing closings and updates the RocksDB option adapter.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-2262; LogSegmentSize validation should be consistent; patched by Manikumar Reddy; reviewed by Jun Rao,5
create/delete ZK path for a topic in an admin tool; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-237git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1231400 13f79535-47bb-0310-9956-ffa450edef68,4
"MINOR: Fix Streams EOS system tests by adding clean-up of state dir (#7693)Recently, system tests test_rebalance_[simple|complex] failedrepeatedly with a verfication error. The cause was most probablythe missing clean-up of a state directory of one of the processors.A node is cleaned up when a service on that node is started and whena test is torn down.If the clean-up flag clean_node_enabled of a EOS Streams service isunset, the clean-up of the node is skipped.The clean-up flag of processor1 in the EOS tests should stay set beforeits first start, so that the node is cleaned before the service is started.Afterwards for the multiple restarts of processor1 the cleans-up flag shouldbe unset to re-use the local state.After the multiple restarts are done, the clean-up flag of processor1 shouldagain be set to trigger node clean-up during the test teardown.A dirty node can lead to test failures when tests from Streams EOS tests arescheduled on the same node, because the state store would not start emptysince it reads the local state that was not cleaned up.Reviewers: Matthias J. Sax <mjsax@apache.org>, Andrew Choi <andchoi@linkedin.com>, Bill Bejeck <bbejeck@gmail.com>",2
KAFKA-2632: move fetchable check ahead in handleFetchResponseAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason GustafsonCloses #295 from guozhangwang/K2632,0
"KAFKA-4801: don't verify assignment during broker up and down in testConsumptionWithBrokerFailures (#11949)In this test, we have another thread to let broker down and up, to test if consumer can still work as expected. During the broker down and up, we tried to verify the assignment is as what we expected. But the rebalance will keep triggering while broker down and up. It doesn't make sense to verify the assignment here. Remove it to make the test reliable.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
KAFKA-4403; Update KafkaBasedLog to use new endOffsets consumer APIewencp plz reviewAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2176 from baluchicken/KAFKA-4403,5
"KAFKA-12383: Get RaftClusterTest.java and other KIP-500 junit tests working (#10220)Introduce ""testkit"" package which includes KafkaClusterTestKit class for enabling integration tests of self-managed clusters. Also make use of this new integration test harness in the ClusterTestExtentions JUnit extension. Adds RaftClusterTest for basic self-managed integration test. Reviewers: Jason Gustafson <jason@confluent.io>, Colin P. McCabe <cmccabe@apache.org>Co-authored-by: Colin P. McCabe <cmccabe@apache.org>",5
KAFKA-13026: Idempotent producer (KAFKA-10619) follow-up testings (#11002)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-125 On Linux, the test can throw SocketException instead of EOFException, that is cool too.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178553 13f79535-47bb-0310-9956-ffa450edef68",1
MINOR: Cleanup redundancies in BaseRequestTest (#7735)This patch eliminates some redundancy and general messiness around the usage of `BaseRequestTest` and specifically response deserialization.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-8430: unit test to make sure null `group.id` and valid `group.instance.id` are valid combo (#6830)As title suggests, this unit test is just a double check. No need to push in 2.3Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",3
"KAFKA-9408: Use StandardCharsets.UTF-8 instead of ""UTF-8"" (#7940)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"[MINOR] fix new consumer heartbeat reschedule bugThis commit fixes a minor issue introduced in the patch for KAFKA-2123. The schedule method requires the time the task should be executed, not a delay.Author: Jason Gustafson <jason@confluent.io>Closes #79 from hachikuji/KAFKA-2123-fix and squashes the following commits:6eb7ec6 [Jason Gustafson] [Minor] fix new consumer heartbeat reschedule bug",0
KAFKA-7937: Fix Flaky Test ResetConsumerGroupOffsetTest.testResetOffsetsNotExistingGroup (#6311),3
KAFKA-2781; Only require signing artifacts when uploading archives.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #461 from ewencp/kafka-2781-no-signing-for-install,1
"KAFKA-12890; Consumer group stuck in `CompletingRebalance` (#10863)This patch introduces a new delayed operation which effectively ensures that a SyncGroup request is received from all the stable members in the groups within the rebalance timeout. The timer starts when the group transitions to the `CompletingRebalance` state. The previous mechanism based on `DelayedHeartbeat` did not work anymore because of https://github.com/apache/kafka/pull/8834 which allows heartbeats while the group is in the `CompletingRebalance`.Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
kafka-527; Compression support does numerous byte copies; patched by Yasuhiro Matsuda; reviewed by Guozhang Wang and Jun Rao,1
MINOR: add toString to Subscription classes (#10172)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
KAFKA-3368; Add documentation for old message format (#3425),2
"HOTFIX: Set version of jgit to avoid unsupported version error (#11554)A new version of JGit that is used by grgit that is used by gradlecauses the following error:org/eclipse/jgit/storage/file/FileRepositoryBuilder has been compiledby a more recent version of the Java Runtime (class file version 55.0),this version of the Java Runtime only recognizes class file versionsup to 52.0The reason is that version 6.0.0.202111291000-r of JGrit was compiledwith a newer Java version than Java 8, probably Java 11.Explicitly setting the version of JGrit in gradle to 5.12.0.202106070339-r fixesthe issue.Reviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Alexander Stohr, David Arthur <mumrah@gmail.com>",5
"KAFKA-3634; Upgrade tests for SASL authenticationAdd a test for changing SASL mechanism using rolling upgrade and a test for rolling upgrade from 0.9.0.x to 0.10.0 with SASL/GSSAPI.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ben Stopford <benstopford@gmail.com>, Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1290 from rajinisivaram/KAFKA-3634",5
"KAFKA-12336 Custom stream naming does not work while calling stream[K… (#10190)Custom stream naming does not work while calling stream[K, V](topicPattern: Pattern)Reviewers: Bill Bejeck <bbejeck@apache.org>",1
HOTFIX: fix failing StreamsMetadataStateTest tests (#11590)Followup to #11562 to fix broken tests in StreamsMetadataStateTestReviewers: Walker Carlson <wcarlson@confluent.io>,5
KAFKA-3009; Disallow star importsSummary of code changes------------------------------------1) Added a new Checkstyle rule to flag any code using star imports2) Fixed ALL existing code violations using star importsTesting-----------Local build was successfulALL JUnits ran successfully on local.ewencp - Request you to please review changes. Thank you !I state that the contribution is my original work and I license the work to the project under the project's open source license.Author: manasvigupta <manasvigupta@yahoo.co.in>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #700 from manasvigupta/KAFKA-3009,5
"MINOR: Deflake OptimizedKTableIntegrationTest (#12186)This test has been flaky due to unexpected rebalances during the test.This change fixes it by detecting an unexpected rebalance and retryingthe test logic (within a timeout).Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <guozhang@apache.org>",2
MINOR: improve JavaDoc for Streams window retention timeAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2068 from mjsax/hotfixImproveWindowRetentionTimeJavaDoc,2
"KAFKA-7001: Rename errors.allowed.max property in Connect to errors.tolerance (KIP-298)Signed-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5146 from wicknicks/KAFKA-7001",5
MINOR: Make Kafka Connect step in quickstart more Windows friendlyAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2498 from vahidhashemian/doc/connect_quickstart_update,5
KAFKA-13476: Increase resilience timestamp decoding Kafka Streams (#11535)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-7915: Don't return sensitive authentication errors to clients (#6252)Don't return error messages from `SaslException` to clients. Error messages to be returned to clients to aid debugging must be thrown as AuthenticationExceptions. This is a fix for a regression from KAFKA-7352.Reviewers: Ron Dagostino <rndgstn@gmail.com>, Ismael Juma <ismael@juma.me.uk",2
"KAFKA-5697: Use nonblocking poll in Streams (#5107)Make use of the new Consumer#poll(Duration) to avoid getting stuck in poll when the broker is unavailable.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: Fix bug in `waitUntilLeaderIsElectedOrChanged` and simplify result typeAlso disable a couple of tests that were passing incorrectly until KAFKA-3096 is fixed.The bug was for the following case:`leader.isDefined && oldLeaderOpt.isEmpty && newLeaderOpt.isDefined && newLeaderOpt.get != leader.get`We would consider it a successful election even though the new leader was not the expected leader.I also changed the result type as we never return `None` (we throw an exception instead).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3031 from ijuma/fix-wait-until-leader-is-elected,0
"KAFKA-12457; Add sentinel ID to metadata topic (#10492)KIP-516 introduces topic IDs to topics, but there is a small issue with how the KIP-500 metadata topic will interact with topic IDs. For example, https://github.com/apache/kafka/pull/9944 aims to replace topic names in the Fetch request with topic IDs. In order to get these IDs, brokers must fetch from the metadata topic. This leads to a sort of ""chicken and the egg"" problem concerning how we find out the metadata topic's topic ID. This PR adds the a special sentinel topic ID for the metadata topic, which gets around this problem.More information can be found in the [JIRA](https://issues.apache.org/jira/browse/KAFKA-12457) and in [KIP-516](https://cwiki.apache.org/confluence/display/KAFKA/KIP-516%3A+Topic+Identifiers).Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-6130; Ensure VerifiableConsumer halts when --max-messages is reachedAuthor: Tom Bentley <tbentley@redhat.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4157 from tombentley/KAFKA-6130-verifiable-consumer-max-messages,5
"MINOR: Remove incomplete gradle wrapper infrastructureSince jar files (including gradle-wrapper.jar) have tobe excluded from source releases, current gradle wrapperinfrastructure is incomplete rendering it unusable andconfusing (I expected gradlew script to work withouthaving to run default gradle task to downloadgradle-wrapper.jar).Author: Kamil Szymanski <kamil.szymanski.dev@gmail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1722 from kamilszymanski/gradlew-cleanup",4
"KAFKA-10133: MM2 readme update on config (#9215)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",5
"KAFKA-13488: Producer fails to recover if topic gets deleted midway (#11552)Allow the leader epoch to be re-assigned to the new value from the Metadata response if `oldTopicId` is not present in the cache. This is needed because `oldTopicId` is removed from the cache if the topic gets deleted but the leader epoch is not removed. Hence, metadata for the newly recreated topic won't be accepted unless we allow `oldTopicId` to be null.Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",5
MINOR: update comments in config/producer.propertiesAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4070 from omkreddy/prodcuer.config,5
"KAFKA-2421: Upgrade LZ4 to version 1.3A few notes on the added test: * I verified this test fails when changing between snappy 1.1.1.2 and 1.1.1.7 (per KAFKA-2189) * The hard coded numbers are passing before and after lzo changeAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #552 from granthenke/lz4",4
"KAFKA-13175; Optimization TopicExistsException,When a topic is marked for deletion. (#11226)After a topic is deleted, the topic is marked for deletion, create topic with the same name throw exception topic already exists. It should indicate the topic is marked for deletion.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
"MINOR: Remove `PartitionHeader` abstraction from `FetchResponse` schema (#9164)This patch removes the PartitionHeader grouping from the Fetch response. With old versions of the protocol, there was no cost for this grouping, but once we add flexible version support, then it adds an extra byte to the schema for tagged fields with little apparent benefit.Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",1
KAFKA-10828; Replacing endorsing with acknowledging for voters  (#9737)This PR replaces the terms endorsing with acknowledging for voters which have recognised the current leader.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-7347; Return not leader error for OffsetsForLeaderEpoch requests to non-replicas (#5576)The broker should return NOT_LEADER_FOR_PARTITION for OffsetsForLeaderEpoch requests against non-replicas instead of UNKNOWN_TOPIC_OR_PARTITION. This patch also fixes a minor bug in the handling of ListOffsets request using the DEBUG replica id. We should return UNKNOWN_TOPIC_OR_PARTITION if the topic doesn't exist.Reviewers: Jun Rao <junrao@gmail.com>,0
"MINOR: Add ClusterTool as specified in KIP-631 (#10047)Add ClusterTool as specified in KIP-631. It can report the current cluster ID, and also send the new RPC for removing broker registrations.Reviewers: David Arthur <mumrah@gmail.com>",4
"MINOR: Correct the ConsumerPerformance print formatCurrently, the output of `ConsumerPerformance` looks strange. The `header` format as follow:```""time, threadId, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec""```while the `body` as follow:```println(""%s, %d, %.4f, %.4f, %d, %.4f"".format(dateFormat.format(endMs), id, totalMBRead,        1000.0 * (mbRead / elapsedMs), messagesRead, ((messagesRead - lastMessagesRead) / elapsedMs) * 1000.0))```So we get the follow result:```time, data.consumeed.in.MB, MB.sec, data.consumeed.in.nMsg, nMsg.Sec09:52:00, 0, 1100.3086, 220.0177, 563358, 112649.0702```So the `header` and `body` mismatching.And also, this pr makes the functions more readable.Author: Xianyang Liu <xianyang.liu@intel.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3417 from ConeyLiu/consumertest",3
MINOR: refactor FetchResponse#toMessage to avoid creating unnecessary collections (#9818)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-5562; execute state dir cleanup on single threadUse a single `StateDirectory` per streams instance.Use threadId to determine which thread owns the lock.Only allow the owning thread to unlock.Execute cleanup on a scheduled thread in `KafkaStreams`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3516 from dguy/kafka-5562",5
KAFKA-93 | add license to missed files and remove LinkedIn copyright line per ASF guideline. Thanks to Joel Koshy for pointing it outgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156299 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: poll even when all partitions are paused. handle concurrent cleanup* We need to poll periodically even when all partitions are paused in order to respond to a possible rebalance promptly.* There is a race condition when two (or more) threads try to clean up the same state directory. One of the thread fails with FileNotFoundException. Thus the new code simply catches it and ignore.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Gwen ShapiraCloses #893 from ymatsuda/hotfix,0
trivial change to catch all throwables in ProducerSendThreadgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1211747 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Add releaseTarGz to args for building docs (#9528)Reviewers: Ismael Juma <ismael@confluent.io>,5
KAFKA-9241: Some SASL Clients not forced to re-authenticate (#7784)Brokers are supposed to force SASL clients to re-authenticate (and kill such connections in the absence of a timely and successful re-authentication) when KIP-368 SASL Re-Authentication is enabled via a positive connections.max.reauth.ms configuration value. There was a flaw in the logic that caused connections to not be killed in the absence of a timely and successful re-authentication if the client did not leverage the SaslAuthenticateRequest API (which was defined in KIP-152).Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-860 Replica fetcher thread errors out and dies during rolling bounce of cluster; reviewed by Jun Rao, Jay Kreps",0
"[KAFKA-7994] Improve Stream time accuracy for restarts and rebalances  (#6694)Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-13158: Migrate ConnectClusterStateImpl to Mockito (#12423)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",5
"KAFKA-13132; Upgrading to topic IDs in LISR requests has gaps introduced in 3.0 (part 2) (#11171)Most of [KAFKA-13132](https://issues.apache.org/jira/browse/KAFKA-13132) has been resolved, but there is one part of one case not covered.From the ticket:`2. We only assign the topic ID when we are associating the log with the partition in replicamanager for the first time`We covered the case where the log is already existing when the leader epoch is _equal_ (ie, no updates besides the topic ID), but we don't cover the update case where the leader epoch is bumped and we already have the log associated to the partition. This PR ensures we correctly assign topic ID in the makeLeaders/Followers path when the log already exists.I've also added a test for the bumped leader epoch scenario.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-9327: Document GroupMetadata metricsThis commit adds documentation on following `GroupMetadata` gauges:- `NumOffsets`- `NumGroups`- `NumGroupsPreparingRebalance`- `NumGroupsCompletingRebalance`- `NumGroupsEmpty`- `NumGroupsStable`- `NumGroupsDead`cc/ gwenshapAuthor: Lee Dongjin <dongjin@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7890 from dongjinleekr/feature/KAFKA-9327,1
"KAFKA-2419 - Fix to prevent background thread from getting created when not requiredSee here for more discussion: https://issues.apache.org/jira/browse/KAFKA-2419Basically, the fix involves adding a param to Metrics to indicate if it is capable of metric cleanup or not.Author: Aditya Auradkar <aauradka@aauradka-mn1.linkedin.biz>Reviewers: Jun Rao <junrao@gmail.com>Closes #323 from auradkar/KAFKA-2419-fix",0
"KAFKA-10792: Prevent source task shutdown from blocking herder thread (#9669)Changes the `WorkerSourceTask` class to only call `SourceTask::stop` from the task thread when the task is actually stopped (via `Source:task::close` just before `WorkerTask::run` completes), and only if an attempt has been made to start the task (which will not be the case if it was created in the paused state and then shut down before being started). This prevents `SourceTask::stop` from being indirectly invoked on the herder's thread, which can have adverse effects if the task is unable to shut down promptly.Unit tests are tweaked where necessary to account for this new logic, which covers some edge cases mentioned in PR #5020 that were unaddressed up until now.The existing integration tests for blocking connectors are expanded to also include cases for blocking source and sink tasks. Full coverage of every source/sink task method is intentionally omitted from these expanded tests in order to avoid inflating test runtime (each one adds an extra 5 seconds at minimum) and because the tests that are added here were sufficient to reproduce the bug with source task shutdown.Author: Chris Egerton <chrise@confluent.io>Reviewers: Nigel Liang <nigel@nigelliang.com>, Tom Bentley <tbentley@redhat.com>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-7766: Fail fast PR builds (#6059)Split the Gradle invocation in the jenkins.sh script into two commands sowe can fail fast for validation checks such as compile errors and checkstyleerrors.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",0
"MINOR: make Printed copy ctor protectedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3817 from dguy/printed-ctor-protected",5
"KAFKA-12864: Move KafkaEventQueue into server-common. #10787 (#10787)Since KafkaEventQueue is a generic data structure not specific to metadata, move itinto the server-common module.Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",4
"MINOR: reduce allocations in log start and recovery checkpoints (#8467)For brokers with replica counts > 4000, allocations from logsByDir becomesubstantial. logsByDir is called often by LogManager.checkpointLogRecoveryOffsetsand LogManager.checkpointLogStartOffsets. The approach used is similar to theone from the checkpointHighwatermarks change inhttps://github.com/apache/kafka/pull/6741.Are there better ways to structure out data structure to avoid creating logsByDir ondemand for each checkpoint iteration? This micro-optimization will help as is, but ifwe can avoid doing this completely it'd be better.JMH benchmark results:```Before:Benchmark                                                                      (numPartitions)  (numTopics)   Mode  Cnt        Score        Error   UnitsCheckpointBench.measureCheckpointLogStartOffsets                                             3          100  thrpt   15        2.233 ±      0.013  ops/msCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate                              3          100  thrpt   15      477.097 ±     49.731  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate.norm                         3          100  thrpt   15   246083.007 ±     33.052    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space                     3          100  thrpt   15      475.683 ±     55.569  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space.norm                3          100  thrpt   15   245474.040 ±  14968.328    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen                        3          100  thrpt   15        0.001 ±      0.001  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen.norm                   3          100  thrpt   15        0.341 ±      0.268    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.count                                   3          100  thrpt   15      129.000               countsCheckpointBench.measureCheckpointLogStartOffsets:·gc.time                                    3          100  thrpt   15       52.000                   msCheckpointBench.measureCheckpointLogStartOffsets                                             3         1000  thrpt   15        0.572 ±      0.004  ops/msCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate                              3         1000  thrpt   15     1360.240 ±    150.539  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate.norm                         3         1000  thrpt   15  2750221.257 ±    891.024    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space                     3         1000  thrpt   15     1362.908 ±    148.799  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space.norm                3         1000  thrpt   15  2756395.092 ±  44671.843    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen                        3         1000  thrpt   15        0.017 ±      0.008  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen.norm                   3         1000  thrpt   15       33.611 ±     14.401    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.count                                   3         1000  thrpt   15      273.000               countsCheckpointBench.measureCheckpointLogStartOffsets:·gc.time                                    3         1000  thrpt   15      186.000                   msCheckpointBench.measureCheckpointLogStartOffsets                                             3         2000  thrpt   15        0.266 ±      0.002  ops/msCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate                              3         2000  thrpt   15     1342.557 ±    171.260  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate.norm                         3         2000  thrpt   15  5877881.729 ±   3695.086    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space                     3         2000  thrpt   15     1343.965 ±    186.069  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space.norm                3         2000  thrpt   15  5877788.561 ± 168540.343    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen                        3         2000  thrpt   15        0.081 ±      0.043  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen.norm                   3         2000  thrpt   15      351.277 ±    167.006    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.count                                   3         2000  thrpt   15      253.000               countsCheckpointBench.measureCheckpointLogStartOffsets:·gc.time                                    3         2000  thrpt   15      231.000                   msJMH benchmarks doneAfter:CheckpointBench.measureCheckpointLogStartOffsets                                             3          100  thrpt   15        2.809 ±     0.129  ops/msCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate                              3          100  thrpt   15      211.248 ±    25.953  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate.norm                         3          100  thrpt   15    86533.838 ±  3763.989    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space                     3          100  thrpt   15      211.512 ±    38.669  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space.norm                3          100  thrpt   15    86228.552 ±  9590.781    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen                        3          100  thrpt   15       ≈ 10⁻³              MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen.norm                   3          100  thrpt   15        0.140 ±     0.111    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.count                                   3          100  thrpt   15       57.000              countsCheckpointBench.measureCheckpointLogStartOffsets:·gc.time                                    3          100  thrpt   15       25.000                  msCheckpointBench.measureCheckpointLogStartOffsets                                             3         1000  thrpt   15        1.046 ±     0.030  ops/msCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate                              3         1000  thrpt   15      524.597 ±    74.793  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate.norm                         3         1000  thrpt   15   582898.889 ± 37552.262    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space                     3         1000  thrpt   15      519.675 ±    89.754  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space.norm                3         1000  thrpt   15   576371.150 ± 55972.955    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen                        3         1000  thrpt   15        0.009 ±     0.005  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen.norm                   3         1000  thrpt   15        9.920 ±     5.375    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.count                                   3         1000  thrpt   15      111.000              countsCheckpointBench.measureCheckpointLogStartOffsets:·gc.time                                    3         1000  thrpt   15       56.000                  msCheckpointBench.measureCheckpointLogStartOffsets                                             3         2000  thrpt   15        0.617 ±     0.007  ops/msCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate                              3         2000  thrpt   15      573.061 ±    95.931  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.alloc.rate.norm                         3         2000  thrpt   15  1092098.004 ± 75140.633    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space                     3         2000  thrpt   15      572.448 ±    97.960  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Eden_Space.norm                3         2000  thrpt   15  1091290.460 ± 85946.164    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen                        3         2000  thrpt   15        0.010 ±     0.012  MB/secCheckpointBench.measureCheckpointLogStartOffsets:·gc.churn.G1_Old_Gen.norm                   3         2000  thrpt   15       19.990 ±    24.407    B/opCheckpointBench.measureCheckpointLogStartOffsets:·gc.count                                   3         2000  thrpt   15      109.000              countsCheckpointBench.measureCheckpointLogStartOffsets:·gc.time                                    3         2000  thrpt   15       67.000                  msJMH benchmarks done```For the 2000 topic, 3 partition case, we see a reduction in normalized allocations from 5877881B/op to 1284190.774B/op, a reduction of 78%.Some allocation profiles from a mid sized broker follow. I have seen worse, but theseadd up to around 3.8% on a broker that saw GC overhead in CPU time of around 30%.You could argue that this is relatively small, but it seems worthwhile for a low risk change.![image](https://user-images.githubusercontent.com/252189/79058104-33e91d80-7c1e-11ea-99c9-0cf2e3571e1f.png)![image](https://user-images.githubusercontent.com/252189/79058105-38add180-7c1e-11ea-8bfd-6e6eafb0c794.png)Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-6512: Discard references to buffers used for compression (#4570)ProducerBatch retains references to MemoryRecordsBuilder and cannot be freed until acks are received. Removing references to buffers used for compression after records are built will enable these to be garbage collected sooner, reducing the risk of OOM.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Lothsahn <Lothsahn@gmail.com>",5
"KAFKA-9523: Migrate BranchedMultiLevelRepartitionConnectedTopologyTest into a unit test (#8081)Relying on integration test to catch an algorithm bug introduces more flakiness, reduce the test into a unit test to reduce the flakiness until we upgrade Java/Scala libs.Checked the test shall fail with older version of StreamsPartitionAssignor.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
HOTFIX: typo in Streams DSL docs,2
KAFKA-9980: Fix bug where alterClientQuotas could not set default client quotas (#8658)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"MINOR: Remove unneeded client used API listsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Gwen Shapira <cshapi@gmail.com>, Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2372 from hachikuji/minor-cleanup-used-apis",4
KAFKA-2837 Follow-up: Default max block to 60 secondsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael JumaCloses #674 from guozhangwang/K2837,5
KAFKA-4318; Migrate ProducerSendTest to the new consumerAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2083 from baluchicken/KAFKA-4318,1
"KAFKA-10613: Only set leader epoch when list-offset version >= 4 (#9438)The leader epoch field is added in version 4, and the auto-generated protocol code would throw unsupported version exception if the field is set to any non-default values for version < 4. This would cause older versioned clients to never receive list-offset results.Reviewers: Boyang Chen <boyang@confluent.io>",5
"KAFKA-7833: Add missing test (#8847)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-3587; LogCleaner fails due to incorrect offset map computationRemoved the over pessimistic require and instead attempt to fill the dedup buffer. Use the (only) map until full;this may allow to process all dirty segment (optimism) or may happen in the middle of a dirt segment.In either case, do compaction using the map loaded that way.This patch was developed with edoardocomarAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1332 from mimaison/KAFKA-3587",2
KAFKA-3528: handle wakeups while rebalancing more gracefullyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1201 from hachikuji/KAFKA-3528,5
"KAFKA-10371; Partition reassignments can result in crashed ReplicaFetcherThreads (#9140)The patch https://github.com/apache/kafka/pull/8672 introduced a bug leading to crashing the replica fetcher threads. The issue is that https://github.com/apache/kafka/pull/8672 deletes the Partitions prior to stopping the replica fetchers. As the replica fetchers relies access the Partition in the ReplicaManager, they crash with a NotLeaderOrFollowerException that is not handled.This PR reverts the code to the original ordering to avoid this issue.The regression was caught and validated by our system test: `kafkatest.tests.core.reassign_partitions_test`. Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10739; Replace EpochEndOffset with automated protocol (#9630)This patch follows up https://github.com/apache/kafka/pull/9547. It refactors KafkaApis, ReplicaManager and Partition to use `OffsetForLeaderEpochResponseData.EpochEndOffset` instead of `EpochEndOffset`. In the mean time, it removes `OffsetsForLeaderEpochRequest#epochsByTopicPartition` and `OffsetsForLeaderEpochResponse#responses` and replaces their usages to use the automated protocol directly. Finally, it removes old constructors in `OffsetsForLeaderEpochResponse`. The patch relies on existing tests.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: shut down the KafkaScheduler later (#10538)Be sure to shut down the kafka scheduler thread after the LogManager, since thelatter uses the former.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-10199: Remove main consumer from store changelog reader (#12337)When store changelog reader is called by a different thread than the stream thread, it can no longer use the main consumer to get committed offsets since consumer is not thread-safe. Instead, we would remove main consumer and leverage on the existing admin client to get committed offsets.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
KAFKA-811 Fix clientId in migration tool; reviewed by Neha Narkhede,0
MINOR: Update to Gradle 2.10Some of the Improvements Include:- The Checkstyle task now produces a human friendly HTML report- Potential performance improvements- Bug FixesAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #715 from granthenke/gradle,5
MINOR: need to update system test version after version bump (#5156),3
MINOR: Propage version correctly in `FetchSnapshotRequest` constructor (#9804)Pass through the version to the super constructor in `FetchSnapshotRequest`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"KAFKA-4213; System tests for replication throttling (KIP-73)In this patch, we test `kafka-reassign-partitions` when throttling is active.This patch also fixes the following:  1. KafkaService.verify_reassign_partitions did not check whetherpartition reassignment actually completed successfully (KAFKA-4204).This patch works around those shortcomings so that we get the rightsignal from this method.  2. ProduceConsumeValidateTest.annotate_missing_messages would call`pop' on the list of missing messages, causing downstream methods to getincomplete data. We fix that in this patch as well.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ben Stopford <benstopford@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1904 from apurvam/throttling-tests",3
"MINOR: SuppressionIntegrationTest should set StreamsConfig.STATE_DIR_CONFIG (#5847)Sets StreamsConfig.STATED_DIR_CONFIG to temp directory inSuppressionIntegrationTest, to match StreamsTestUtils.This is a similar fix to #5826.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-5967; Ineffective check of negative value in CompositeReadOnlyKeyValueStore#approximateNumEntries()package name: org.apache.kafka.streams.state.internalsMinor change to approximateNumEntries() method in CompositeReadOnlyKeyValueStore class.long total = 0;   for (ReadOnlyKeyValueStore<K, V> store : stores) {          total += store.approximateNumEntries();   }return total < 0 ? Long.MAX_VALUE : total;The check for negative value seems to account for wrapping. However, wrapping can happen within the for loop. So the check should be performed inside the loop.Author: siva santhalingam <ssanthalingam@netskope.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3988 from shivsantham/trunk",1
MINOR: Remove unused hadoop versionAll dependencies on hadoop were removed with MiniKDC. This removes the left over version entry.Author: Grant Henke <granthenke@gmail.com>Reviewers: Ismael JumaCloses #1214 from granthenke/remove-hadoop,4
"MINOR: Update lz4, jetty and other minor dependency bumps (#8008)* lz4: fixes identified by oss-fuzz* jetty: fixes a few recent regressions* powermock: better support for Java 12+* zstd-jni: minor fixes* httpclient: minor fixes* spotless-plugin: minor fixes* jmh: minor fixesReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5361: Add more integration tests for Streams EOS - multi-subtopology tests - fencing test - producer fenced bug fix: Streams did not recover correctly from ProducerFencedExceptionAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3276 from mjsax/kafka-5361-add-eos-integration-tests-for-streams-api",3
MINOR: Use Math.min for StreamsPartitionAssignor#updateMinReceivedVersion method (#7954)Reviewers: Jason Gustafson <jason@confluent.io>,5
Streams Use case anchor (#4420)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-4848: Fix retryWithBackoff deadlock issueFixes related to handling of MAX_POLL_INTERVAL_MS_CONFIG during deadlock and CommitFailedException on partition revoked.Author: Sachin Mittal <sjmittal@gmail.com>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #2642 from sjmittal/trunk",1
"KAFKA-13256: Fix NPE in ConfigDef when documentation is null (#11287)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",2
KAFKA-328 Write unit test for kafka server startup and shutdown API; reviewed by Neha Narkhede,3
KAFKA-8463: Fix redundant reassignment of tasks when leader worker leaves (#6859)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-13202: KIP-768: Extend SASL/OAUTHBEARER with Support for OIDC (#11284)This task is to provide a concrete implementation of the interfaces defined in KIP-255 to allow Kafka to connect to an OAuth/OIDC identity provider for authentication and token retrieval. While KIP-255 provides an unsecured JWT example for development, this will fill in the gap and provide a production-grade implementation.The OAuth/OIDC work will allow out-of-the-box configuration by any Apache Kafka users to connect to an external identity provider service (e.g. Okta, Auth0, Azure, etc.). The code will implement the standard OAuth client credentials grant type.The proposed change is largely composed of a pair of AuthenticateCallbackHandler implementations: one to login on the client and one to validate on the broker.See the following for more detail:KIP-768KAFKA-13202Reviewers: Yi Ding <dingyi.zj@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
"MINOR: Remove deprecated KafkaStreams constructors in docs (#5118)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3715: Add granular metrics to Kafka Streams and add hierarhical logging levels to MetricsKafka Streams: add granular metrics per node and per task, also expose ability to register non latency metrics in StreamsMetricsAlso added different recording levels to Metrics.This is joint contribution from Eno Thereska and Aarti Gupta.from https://github.com/apache/kafka/pull/1362#issuecomment-218326690-------We can consider adding metrics for process / punctuate / commit rate at the granularity of each processor node in addition to the global rate mentioned above. This is very helpful in debugging.We can consider adding rate / total cumulated metrics for context.forward indicating how many records were forwarded downstream from this processor node as well. This is helpful in debugging.We can consider adding metrics for each stream partition timestamp.This is helpful in debugging.## Besides the latency metrics, we can also add throughput latency in terms of source records consumed.More discussions here https://issues.apache.org/jira/browse/KAFKA-3715, KIP-104, KIP-105Author: Eno Thereska <eno@confluent.io>Author: Aarti Gupta <aartiguptaa@gmail.com>Reviewers: Greg Fodor, Ismael Juma, Damian Guy, Guozhang WangCloses #1446 from aartigupta/trunk",1
KAFKA-12796: Removal of deprecated classes under streams-scala (#10710)Removes previously deprecated methods in older KIPsReviewers: Bruno Cadonna <cadonna@apache.org>,1
"MINOR: Fix race condition in Streams tests (#6748)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-8422; Client should send OffsetForLeaderEpoch only if broker supports latest version (#6806)In the olden days, OffsetForLeaderEpoch was exclusively an inter-broker protocol andrequired Cluster level permission. With KIP-320, clients can use this API as well andso we lowered the required permission to Topic Describe. The only way the client canbe sure that the new permissions are in use is to require version 3 of the protocolwhich was bumped for 2.3. If the broker does not support this version, we skip thevalidation and revert to the old behavior.Additionally, this patch fixes a problem with the newly added replicaId field whenparsed from older versions which did not have it. If the field was not present, thenwe used the consumer's sentinel value, but this would limit the range of visibleoffsets by the high watermark. To get around this problem, this patch adds aseparate ""debug"" sentinel similar to APIs like Fetch and ListOffsets.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-2591: Fix StreamingMetricsRemove state storage upon unclean shutdown and fix streaming metrics used for local state.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Edward Ribeiro, Yasuhiro Matsuda, Jun RaoCloses #265 from guozhangwang/K2591",1
MINOR: Closing consumerGroupService resources in SaslClientsWithInvalidCredentialsTest (#8992)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"MINOR: Fix producer timeouts in log divergence test (#7728)This test was taking more than 5 minutes because the producer writes were timing out. The problem was that broker 100 was being shutdown before broker 101, which meant that the partition was still offline after broker 100 was restarted. The producer timeouts were not detected because the produce future was not checked. After the fix, test time drops to about 15s.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-2949; Make EndToEndAuthorizationTest replicated.Author: Flavio Junqueira <fpj@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #631 from fpj/KAFKA-2949",3
HOTFIX: Temporarily ignoring this test until fixedAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1838 from enothereska/hotfix-ignore-smoke-test,3
kafka-792; Update multiple attributes in testcase_xxxx_properties.json; patched by John Fung; reviewed by Jun Rao,5
kafka-1377; transient unit test failure in LogOffsetTest; patched by Jun Rao; reviewed by Neha Narkhede,3
Add acknowledgement to the produce request; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-49git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1300435 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-554 Dynamic per-topic configuration. This patch adds a mechanism for storing per-topic configurations in zookeeper and dynamically making config changes across the cluster. Reviewed by Neha and Jun.,4
KAFKA-963 when publishing to maven repository central missing signature on everything,5
"KAFKA-12294; forward auto topic request within envelope on behalf of clients (#10142)When auto-creating topics in KIP-500, the broker will send a `CreateTopics` request to the controller. It is useful in this case to preserve the original principal from the corresponding `Metadata` request by wrapping the `CreateTopics` request in an envelope so that the controller may repeat the authorization and to improve auditability. This follows a similar pattern to how standard `CreateTopics` requests are forwarded to the controller.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-13116: Fix message_format_change_test and compatibility_test_new_broker_test failures (#11108)These failures were caused by a46b82bea9abbd08e5. Details for each test:* message_format_change_test: use IBP 2.8 so that we can write in older messageformats.* compatibility_test_new_broker_test_failures: fix down-conversion path to handleempty record batches correctly. The record scan in the old code ensured thatempty record batches were never down-converted, which hid this bug.* upgrade_test: set the IBP 2.8 when message format is < 0.11 to ensure we areactually writing with the old message format even though the test was passingwithout the change.Verified with ducker that some variants of these tests failed without these changesand passed with them. Also added a unit test for the down-conversion bug fix.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Need to have same wait as verify timeout broker upgrade downgrade (#6127)When I originally refactored the streams_upgrade_test#upgrade_downgrade_brokers test I removed the wait call which would wait for up 24 minutes for the SmokeTestDriver class to publish and verify all of its records.Since most of the tests run in two minutes or less I set the monitor_log timeout to three minutes. However, the SmokeTestDriver#verify method allows up to six minutes to consume all records before verifying the monitor_log timeout needs to be greater than 6 minutes. I've set the timeout to 8 minutes.Additionally, the steps needed to update the streams_upgrade_test should be documented as there are several components that need to get updated. So I've documented those steps here on the test as a giant comment.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
KAFKA-770 KafkaConfig properties should be verified in the constructor; reviewed by Neha Narkhede,5
"MINOR: Upgrade dependencies for Kafka 2.3 (#6665)Many patch and minor updates.Scalatest and Jetty deprecated classes that weuse. I removed usages for the former and filed KAFKA-8316 for the latter (Isuppressed the relevant deprecation warnings until the JIRA is fixed). Aspart of the scalatest fixes, I also removed `TestUtils.fail` since it duplicates`Assertions.fail`.I also fixed a few compiler warnings that have crept in since my last sweep.Updates of note:- Jetty: 9.4.14 -> 9.4.18  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.15.v20190215  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.16.v20190411  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.17.v20190418  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.17.v20190418  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.18.v20190429- zstd: 1.3.8-1 -> 1.4.0-1  * https://github.com/facebook/zstd/releases/tag/v1.4.0  * zstd's fastest strategy, 6-8% faster in most scenarios- zookeeper: 3.4.13 -> 3.4.14  * https://zookeeper.apache.org/doc/r3.4.14/releasenotes.html### Committer Checklist (excluded from commit message)- [ ] Verify design and implementation - [ ] Verify test coverage and CI build status- [ ] Verify documentation (including upgrade notes)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2
MINOR: add unsigned varint support (#7338)Support reading and writing unsigned varints.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Skip `Struct` conversion in `FetchRequest.parse` (#9740)This was missed in 6f27bb0.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-8972 (2.4 blocker): correctly release lost partitions during consumer.unsubscribe() (#7441)Inside onLeavePrepare we would look into the assignment and try to revoke the owned tasks and notify users via RebalanceListener#onPartitionsRevoked, and then clear the assignment.However, the subscription's assignment is already cleared in this.subscriptions.unsubscribe(); which means user's rebalance listener would never be triggered. In other words, from consumer client's pov nothing is owned after unsubscribe, but from the user caller's pov the partitions are not revoked yet. For callers like Kafka Streams which rely on the rebalance listener to maintain their internal state, this leads to inconsistent state management and failure cases.Before KIP-429 this issue is hidden away since every time the consumer re-joins the group later, it would still revoke everything anyways regardless of the passed-in parameters of the rebalance listener; with KIP-429 this is easier to reproduce now.Our fixes are following:• Inside unsubscribe, first do onLeavePrepare / maybeLeaveGroup and then subscription.unsubscribe. This we we are guaranteed that the streams' tasks are all closed as revoked by then.• [Optimization] If the generation is reset due to fatal error from join / hb response etc, then we know that all partitions are lost, and we should not trigger onPartitionRevoked, but instead just onPartitionsLost inside onLeavePrepare. This is because we don't want to commit for lost tracks during rebalance which is doomed to fail as we don't have any generation info.Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-7147; ReassignPartitionsCommand should be able to connect to broker over SSLAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Andras Beni <andrasbeni@cloudera.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Sriharsha Chintalapani <sriharsha@apache.org>Closes #5355 from lindong28/KAFKA-7147",2
KAFKA-5725; More failure testingAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3656 from enothereska/minor-add-more-tests,3
kafka-2039; Update Scala to 2.10.5 and 2.11.6; patched by Ismael Juma; reviewed by Jun Rao,5
"KAFKA-7712; Remove channel from Selector before propagating exception (#6023)Ensure that channel and selection keys are removed from `Selector` collections before propagating connect exceptions. They are currently cleared on the next `poll()`, but we can't ensure that callers (NetworkClient for example) wont try to connect again before the next `poll` and hence we should clear the collections before re-throwing exceptions from `connect()`.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-1653 Duplicate broker ids allowed in replica assignment; reviewed by Neha Narkhede,1
"KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter (#8829)Make sure that the Errant Record Reporter recently added in KIP-610 adheres to the  `errors.tolerance` policy.Author: Aakash Shah <ashah@confluent.io>Reviewers: Arjun Satish <arjunconfluent.io>, Randall Hauch <rhauch@gmail.com>",5
MINOR: Fix log message in AbstractFetcherThreadUse Scala string templates instead of formatAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4058 from mimaison/minor_AFT_logging,2
KAFKA-13101: Replace EasyMock and PowerMock with Mockito for RestServerTest (#11074)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-10675: Add schema name to ConnectSchema.validateValue() error message (#9541)The following error message`org.apache.kafka.connect.errors.DataException: Invalid Java object for schema type INT64: class java.lang.Long for field: ""moderate_time""`can be confusing because java.lang.Long is acceptable type for schema INT64.In fact, in this case `org.apache.kafka.connect.data.Timestamp` is used but this info is not logged.Reviewers: Randall Hauch <rhauch@gmail.com>, Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"KAFKA-2350; KafkaConsumer pause/resume APIAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael, Ashish, GuozhangCloses #100 from hachikuji/KAFKA-2350 and squashes the following commits:250e823 [Jason Gustafson] KAFKA-2350; KafkaConsumer pause/resume API",1
Bump trunk versions to 1.2-SNAPSHOT (#4505),1
"KAFKA-13619: Remove zookeeper.sync.time.ms (#11717)`zookeeper.sync.time.ms` was previously used with the old Scala consumer, whichwas removed in Apache Kafka 2.0.0. Remove the config definition from `KafkaConfig`and documentation.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
"MINOR: Change Trogdor agent's cleanup executor to a cached thread pool (#6309)It is best to use a growing thread pool for worker cleanups. This lets us ensure that we close workers as fast as possible and not get slowed down on blocking cleanups.Reviewers: Colin McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
KAFKA-1237 Follow up review suggestions on new mirror maker; reviewed by Guozhang Wang,1
KAFKA-10866: Add metadata to ConsumerRecords (#9836)Expose fetched metadata via the ConsumerRecordsobject as described in KIP-695.Reviewers: Guozhang Wang <guozhang@apache.org>,5
"MINOR: Remove unused method, redundant in interface definition and add final for object used in sychronizationguozhangwang Very minor cleanup.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1063 from Ishiihara/minor-cleanup",4
"KAFKA-13023: make ""range, cooperative-sticky"" as the default assignor in V3.0 (#10903)Set the default assignor to [""range"", ""cooperative-sticky""] to make it easier for users to switch over to cooperative rebalancing by using only a single rolling bounce.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
"KAFKA-7136: Avoid deadlocks in synchronized metrics reporters (#5341)We need to use the same lock for metric update and read to avoid NPE and concurrent modification exceptions. Sensor add/remove/update are synchronized on Sensor since they access lists and maps that are not thread-safe. Reporters are notified of metrics add/remove while holding (Sensor, Metrics) locks and reporters may synchronize on the reporter lock. Metric read may be invoked by metrics reporters while holding a reporter lock. So read/update cannot be synchronized using Sensor since that could lead to deadlock. This PR introduces a new lock in Sensor for update/read.Locking order:- Sensor#add: Sensor -> Metrics -> MetricsReporter- Metrics#removeSensor: Sensor -> Metrics -> MetricsReporter- KafkaMetric#metricValue: MetricsReporter -> Sensor#metricLock- Sensor#record: Sensor -> Sensor#metricLockReviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",4
"MINOR: Guard against NPE when throwing StreamsException on serializer mismatchAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2696 from miguno/trunk-sinknode-NPE",1
MINOR: Adding github whitelist (#8523)Reviewer: Jun Rao <junrao@gmail.com>,1
KAFKA-6334: minor typo fix in web docs,2
KAFKA-5695; Test DeleteRecordsRequest in AuthorizerIntegrationTestAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3614 from lindong28/KAFKA-5695,3
"KAFKA-2841; safe group metadata cache loading/unloadingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #530 from hachikuji/KAFKA-2841",5
"KAFKA-10618: Add UUID class, use in protocols (part of KIP-516) (#9454)In order to support topic IDs, we need to create a public UUID class. This class will be used in protocols. This PR creates the class, modifies code to use the class in the message protocol and changes the code surrounding the existing messages/json that used the old UUID class.SimpleExampleMessage was used only for testing, so all usages of UUID have been switched to the new class.SubscriptionInfoData uses UUID for processId extensively. It also utilizes java.util.UUID implementation of Comparable so that UUIDs can be ordered. This functionality was not necessary for the UUIDs used for topic IDs converted to java.util.UUID on the boundary of SubscriptionInfoData. Sorting was used only for testing, though, so this still may be changed.Also added tests for the methods of the new UUID class. The existing SimpleExampleMessage tests should be sufficient for testing the new UUID class in message protocols.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
HOTFIX: ignore reset integration testsignore reset integraion test,3
"[MINOR] Improve consumer logging on LeaveGroup (#5420)* Improve consumer logging on LeaveGroup* Add GroupCoordinator logging, and address review commentsReviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-10758: ProcessorTopology should only consider its own nodes when updating regex source topics (#9648) We should ignore any source nodes that aren't part of the ProcessorTopology's subtopology when updating its source topics after a change in the topic metadata.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Matthias J. Sax <mjsax@confluent.io>",5
"KAFKA-14089: Only check for committed seqnos after disabling exactly-once support in Connect integration test (#12429)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",3
"KAFKA-8678; Fix leave group protocol bug in throttling and error response (#7101)This is a bug fix PR to resolve errors introduced in https://github.com/apache/kafka/pull/6188. The PR fixes 2 things:1. throttle time should be set on version >= 1 instead of version >= 22. `getErrorResponse` should set throwable exception within LeaveGroupResponseDataThe patch also adds more unit tests to guarantee correctness for leave group protocol.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13605: checkpoint position in state stores (#11676)There are cases in which a state store neither has an in-memory position built up nor has it gone through the state restoration process. If a store is persistent (i.e., RocksDB), and we stop and restart Streams, we will have neither of those continuity mechanisms available.This patch:* adds a test to verify that all stores correctly recover their position after a restart* implements storage and recovery of the position for persistent stores alongside on-disk stateReviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",5
"KAFKA-10533; KafkaRaftClient should flush log after appends (#9352)This patch adds missing flush logic to `KafkaRaftClient`. The initial flushing behavior is simplistic. We guarantee that the leader will not replicate above the last flushed offset and we guarantee that the follower will not fetch data above its own flush point. More sophisticated flush behavior is proposed in KAFKA-10526.We have also extended the simulation test so that it covers flush behavior. When a node is shutdown, all unflushed data is lost. We were able to confirm that the monotonic high watermark invariant fails without the added `flush` calls.This patch also piggybacks a fix to the `TestRaftServer` implementation. The initial check-in contained a bug which caused `RequestChannel` to fail sending responses because the disabled APIs did not have metrics registered. As a result of this, it is impossible to elect leaders.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-10264; Fix Flaky Test TransactionsTest.testBumpTransactionalEpoch (#9291)The test case sends two records before killing broker. The failure is caused when both records are NOT sent in a single batch. The failure of first record can abort second batch and then produces `KafkaException` rather than `TimeoutException`. The patch removes the second record send.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Bump version to 2.1.0-SNAPSHOT (#5153),5
MINOR: Cleanup NetworkReceive constructors (#12511)There was unnecessary duplication and one of the overloadsdid not set the size field for no good reason.Reviewers: Luke Chen <showuon@gmail.com>,1
KAFKA-3273; MessageFormatter and MessageReader interfaces should be resilient to changes* Change `MessageFormat.writeTo` to take a `ConsumerRecord`* Change `MessageReader.readMessage()` to use `ProducerRecord`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #972 from ijuma/kafka-3273-message-formatter-and-reader-resilient,1
"MINOR: Fix deserialization of abortedTransactions and lastStableOffset in FetchResponseThanks to Dong Lin for finding the lastStableOffset issue.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2737 from ijuma/fix-fetch-response-lso",0
"KAFKA-12198: Migrate connect:json module to JUnit 5 (#9890)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-3010; Include error in log when ack 0I verified this by trying to produce to __consumer_offsets and the logged message looks like:[2015-12-22 10:34:40,897] INFO [KafkaApi-0] Closing connection due to error during produce request with correlation id 1 from client id console-producer with ack=0Topic and partition to exceptions: [__consumer_offsets,43] -> kafka.common.InvalidTopicException (kafka.server.KafkaApis)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #709 from ijuma/kafka-3010-include-error-in-log-when-ack-0",2
"KAFKA-12779: KIP-740, Clean up public API in TaskId and fix TaskMetadata#taskId() (#10735)As described in KIP-740, we clean up the public TaskId class and introduce new APIs to return it from TaskMetadataReviewers: Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Eliminate warnings from KafkaProducerTest (#5548)And code clean-ups in the same file.Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-5157; Options for handling corrupt data during deserializationThis is the implementation of KIP-161: https://cwiki.apache.org/confluence/display/KAFKA/KIP-161%3A+streams+deserialization+exception+handlersAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #3423 from enothereska/KAFKA-5157-deserialization-exceptions",5
MINOR: Remove deprecated valueTransformer.punctuate (#4993)Also removed the InternalValueTransformerWithKey / Supplier which is used to mock away the deprecated punctuate function.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
revisit the become leader and become follower state change operations using V3 design; patched by Yang Ye; reviewed by Neha Narkhede and Jun Rao; kafka-343git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1367619 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1147 Consumer socket timeout should be greater than fetch max wait; reviewed by Neha Narkhede and Jun Rao,5
KAFKA-8452: Compressed BufferValue review follow-up (#6940)Belatedly address a few code review comments from #6848Reviewers: Bill Bejeck <bbejeck@gmail.com>,1
KAFKA-2765: Add versions to Copycat Connector and Task interfaces and log versions when instantiating connectors and tasks.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #446 from ewencp/connector-versions,2
"KAFKA-5140: Fix reset integration testA couple of root causes of this flaky test is fixed:1. The MockTime was incorrectly used across multiple test methods within the class, as a class rule. Instead we set it on each test case; also remove the scala MockTime dependency.2. List topics may not contain the deleted topics while their ZK paths are yet to be deleted; so the delete-check-recreate pattern may fail to successfully recreate the topic at all. Change the checking to read from zk path directly instead.Another minor fix is to remove the misleading wait condition error message as the accumData is always empty.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #4095 from guozhangwang/KMinor-reset-integration-test",3
KAFKA-6055; Fix typo in KAFKA_JVM_PERFORMANCE_OPTS for WindowsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4062 from vahidhashemian/KAFKA-6055,2
MINOR: Remove unused `ByteBoundedBlockingQueue` class and `zkSessionTimeout` parameterAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2136 from ijuma/remove-unused-code,4
"KAFKA-12491: Make rocksdb an `api` dependency for `streams` (#10341)`org.rocksdb.Options` is part of Kafka Streams public api via `RocksDBConfigSetter`.Reviewers: Anna Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-7641; Introduce ""group.max.size"" config to limit group sizes (#6163)This patch introduces a new config - ""group.max.size"", which caps the maximum size any group can reach. It has a default value of Int.MAX_VALUE. Once a group is of the maximum size, subsequent JoinGroup requests receive a MAX_SIZE_REACHED error.In the case where the config is changed and a Coordinator broker with the new config loads an old group that is over the threshold, members are kicked out of the group and a rebalance is forced.Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Boyang Chen <bchen11@outlook.com>, Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Update consumer group command documentation with additionally supported options (#4462)With KIP-175 there are a number of consumer group command options that can be used to describe a consumer group.This PR updates the documentation on consumer group command to mention those options.,2
"MINOR: need to be backwards compatible with deprecated default configs until removed…s until removedAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3461 from bbejeck/MINOR_make_sure_deprecated_streams_configs_still_usable",5
MINOR: NetworkClient#disconnect should not erase connection infoNetworkClient#disconnect should not erase the connection information.  This will allow exponentialbackoff to occur.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3309 from cmccabe/disc,5
MINOR: show LogRecoveryState in MetadataShell and fix log messageShow the LeaderRecoveryState in MetadataShell.Fix a case where we were comparing a Byte type with an enum type.Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
"KAFKA-6849: add transformValues methods to KTable. (#4959)See the KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-292%3A+Add+transformValues%28%29+method+to+KTableThis PR adds the transformValues method to the KTable interface. The semantics of the call are the same as the methods of the same name on the KStream interface.Fixes KAFKA-6849Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9992: Eliminate JavaConverters in EmbeddedKafkaCluster (#8673)Fixes EmbeddedKafkaCluster.deleteTopicAndWait for use with kafka_2.13Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <vvcephei@apache.org>",5
MINOR: Update to Gradle 2.8There have been a number of improvements between the version we are currently using (2.4) and the current version (2.8):https://gradle.org/docs/2.5/release-noteshttps://gradle.org/docs/2.6/release-noteshttps://gradle.org/docs/2.7/release-noteshttp://gradle.org/docs/current/release-notesI'm particularly interested in the performance improvements.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #343 from ijuma/gradle-2.8,1
KAFKA-8212 DOCS (kafka) - Fix Maven artifacts table from cutting off text (#6576)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Fix javadoc typo in Headers (#4627),2
"MINOR - remove unused imports in package kafka.utilsAuthor: zhuchen1018 <amandazhu19620701@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Joel Koshy <jjkoshy.w@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #935 from zhuchen1018/minor-remove-unused-imports",4
KAFKA-1071; The random partition selected in DefaultEventHandler is not random across producer instances; reviewed by Neha Narkhede and Jun Rao,0
"KAFKA-4267; Quota initialization for <user, clientId> uses incorrect ZK pathAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1987 from rajinisivaram/quota-init-test",5
MINOR: add table of contentsAdded a simple table of contents for the developer section.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3760 from enothereska/minor-docs-toc,2
"KAFKA-13959: Controller should unfence Broker with busy metadata log (#12274)The reason for KAFKA-13959 is a little complex, the two keys to this problem are:KafkaRaftClient.MAX_FETCH_WAIT_MS==MetadataMaxIdleIntervalMs == 500ms. We rely on fetchPurgatory to complete a FetchRequest, in details, if FetchRequest.fetchOffset >= log.endOffset, we will wait for 500ms to send a FetchResponse. The follower needs to send one more FetchRequest to get the HW.Here are the event sequences:1. When starting the leader(active controller) LEO=m+1(m is the offset of the last record), leader HW=m(because we need more than half of the voters to reach m+1)2. Follower (standby controller) and observer (broker) send FetchRequest(fetchOffset=m)    2.1. leader receives FetchRequest, set leader HW=m and waits 500ms before send FetchResponse    2.2. leader send FetchResponse(HW=m)    3.3 broker receive FetchResponse(HW=m), set metadataOffset=m.3. Leader append NoOpRecord, LEO=m+2. leader HW=m4. Looping 1-4If we change MAX_FETCH_WAIT_MS=200 (less than half of MetadataMaxIdleIntervalMs), this problem can be solved temporarily.We plan to improve this problem in 2 ways, firstly, in this PR, we change the controller to unfence a broker when the broker's high-watermark has reached the broker registration record for that broker. Secondly, we will propagate the HWM to the replicas as quickly as possible in KAFKA-14145.Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-5111: Improve internal Task APIs of Streams Refactors Task with proper interface methods `init()`, `resume()`, `commit()`, `suspend()`, and `close()`. All other methods for task handling are internal now. This allows to simplify `StreamThread` code, avoid code duplication and allows for easier reasoning of control flow.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Damian Guy, Eno Thereska, Guozhang WangCloses #2895 from mjsax/kafka-5111-cleanup-task-code",4
"MINOR: Update jetty to 9.4.33Jetty 9.4.32 and before are affected by CVE-2020-27216. This vulnerability is fixed in Jetty 9.4.33, please see the jetty project security advisory for details: https://github.com/eclipse/jetty.project/security/advisories/GHSA-g3wg-6mcf-8jj6#advisory-comment-63053Unit tests and integration tests pass locally after the upgrade.Author: Nitesh Mor <nmor@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9556 from niteshmor/trunk",1
"KAFKA-10181: Use Envelope RPC to do redirection for (Incremental)AlterConfig, AlterClientQuota and CreateTopics (#9103)This PR adds support for forwarding of the following RPCs:AlterConfigsIncrementalAlterConfigsAlterClientQuotasCreateTopicsCo-authored-by: Jason Gustafson <jason@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-4633; Always using regex pattern subscription in StreamThread1. In StreamThread, always use subscribe(Pattern, ..) function in order to avoid sending MetadataRequest with specific topic names and cause brokers to possibly auto-create subscribed topics; the pattern is generated as ""topic-1|topic-2..|topic-n"".2. In ConsumerCoordinator, let the leader to refresh its metadata if the generated assignment contains some topics that is not contained in the subscribed topics; also in SubscriptionState, modified the verification for regex subscription to against the regex pattern instead of the matched topics since the returned assignment may contain some topics not yet created when joining the group but existed after the rebalance; also modified some unit tests in `KafkaConsumerTest` to accommodate the above changes.3. Minor cleanup: changed String[] to List<String> to avoid overloaded functions.4. Minor cleanup: enforced strong typing in SinkNodeFactory and removed unnecessary unchecked tags.5. Minor cleanup: augmented unit test error message and fixed a potential transient failure in KafkaStreamTest.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2379 from guozhangwang/K4633-regex-pattern",5
KAFKA-13294: Upgrade Netty to 4.1.68 (#11324)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-7048 NPE when creating connector (#5202)Reviewers: Robert Yokota <rayokota@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12840; Removing `compact` cleaning on a topic should abort on-going compactions (#11230)This patch ensure that on-going compaction is aborted when `compact` is removed from the `cleanup.policy` of a topic.Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-8179: do not suspend standby tasks during rebalance (#7321)Some work needs to be done in Streams before we can incorporate cooperative rebalancing. This PR lays the groundwork for it by doing some refactoring, including a behavioral change that affects eager (""normal"") rebalancing as well: will no longer suspend standbys in onPartitionsRevoked, instead we just close any that were reassigned in onPartitionsAssignedReviewers: Bruno Cadonna <bruno@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-14134: Replace EasyMock with Mockito for WorkerConnectorTest (#12472)Reviewers: Divij Vaidya <diviv@amazon.com>, Chris Egerton <fearthecellos@gmail.com>",3
MINOR: rename class `RecordTimeDefintion` to `RecordTimeDefinition` (#8939)Fix a typo for class RecordTimeDefintion to RecordTimeDefinitionReviewers: Boyang Chen <boyang@confluent.io>,5
"KAFKA-3373; MINOR: follow-up, a few val renames remainingI also slightly tweaked the wording on a couple of warnings.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1072 from ijuma/kafka-3373-follow-up",2
KAFKA-3344: Remove previous system test's leftover test-log4j.propertiesAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1024 from SinghAsDev/KAFKA-3344,5
"MINOR: onCompletion: metadata valid only if no exceptionModifies example in doc changeAuthor: ybyzek <ybyzek@users.noreply.github.com>Reviewers: Guozhang Wang, Ismael JumaCloses #1805 from ybyzek/onComplete_doc",2
KAFKA-10459: Document IQ APIs where order does not hold between stores (#9251)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Map `mkString` format updated to default java formatThis is a minor change but it helps to improve the log readability.Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2709 from Kamal15/util,2
"KAFKA-12436: Deprecate MirrorMaker v1 (KIP-720) (#10805)Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Mickael Maison <mickael.maison@gmail.com>",1
KAFKA-165 Add a cli script to use zkCli without having to download ZK.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1187983 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: replace deprecated remove with delete (#5565)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-9363; Display success message after topic creation with AdminClient (#7893)When `kafka-topics.sh` is used with the --zookeeper option, it prints a confirmation message. This patch adds the same message when --bootstrap-server is used.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-3522: Replace RecordConverter with TimestampedBytesStore (#6204)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-5804; retain duplicates in ChangeLoggingWindowBytesStore`ChangeLoggingWindowBytesStore` needs to have the same `retainDuplicates` functionality as `RocksDBWindowStore` else data could be lost upon failover/restoration.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3754 from dguy/hotfix-changelog-window-store",4
"MINOR: Use Java 11 for generating aggregated javadoc in release.py (#10399)Java 11 generates html5 pages with search support, which provides a better user experience.Fixed `get_jdk` bugs found during testing and updated `release.py` blurb to indicate thatboth JDK 8 and JDK 11 are required to perform a release.Tested by running `python2 release.py stage-docs`, which triggers the `aggregateJavadoc`path without some of the undesired (for testing) release steps.Reviewers: John Roesler <vvcephei@apache.org>",3
"MINOR: Fix typos in upgrade guide (#7005)Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2
HOTFIX: compile error in EmbeddedKafkaCluster (#8170),0
KAFKA-4982; Add listener tags to socket-server-metrics (KIP-136)Author: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3004 from edoardocomar/KAFKA-4982,2
"KAFKA-9629 Use generated protocol for Fetch API (#9008)Refactored FetchRequest and FetchResponse to use the generated message classes for serialization and deserialization. This allows us to bypass unnecessary Struct conversion in a few places. A new ""records"" type was added to the message protocol which uses BaseRecords as the field type. When sending, we can set a FileRecords instance on the message, and when receiving the message class will use MemoryRecords. Also included a few JMH benchmarks which indicate a small performance improvement for requests with high partition counts or small record sizes.Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>, David Jacot <djacot@confluent.io>, Lucas Bradstreet <lucas@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",5
KAFKA-1654 Provide a way to override server configuration from command line; reviewed by Neha Narkhede,5
"KAFKA-8052; Ensure fetch session epoch is updated before new request (#6582)Reviewers: Jason Gustafson <jason@confluent.io>, Colin Patrick McCabe <cmccabe@confluent.io>, Andrew Olson <aolson1@cerner.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"Minor: set task to null at the end of shouldWrapProducerFencedExceptionWithTaskMigragedExceptionInSuspendWhenCommitting (#5534)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-4488: UnsupportedOperationException during initialization of StandbyTaskInstead of throwing `UnsupportedOperationException` from `StandbyTask.recordCollector()` return a No-op implementation of `RecordCollector`.Refactored `RecordCollector` to have an interface and impl.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2212 from dguy/standby-task",5
"MINOR: Allow KafkaApis to be configured for Raft controller quorums (#10045)`KafkaApis` is configured differently when it is used in a broker with a Raft-based controller quorum vs. a ZooKeeper quorum.  For example, when using Raft, `ForwardingManager` is required rather than optional, and there is no `AdminManager`, `KafkaController`, or `KafkaZkClient`.  This PR introduces `MetadataSupport` to abstract the two possibilities: `ZkSupport` and `RaftSupport`.  This provides a fluent way to decide what to do based on the type of support that `KafkaApis` has been configured with.  Certain types of requests are not supported when using raft (`AlterIsrRequest`, `UpdateMetadataRequest`, etc.), and `MetadataSupport` gives us an intuitive way to identify the constraints and requirements associated with the different configurations and react accordingly.Existing tests are sufficient to detect bugs and regressions.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-6552: Use “entity_type” in description of kafka-configs.sh (#4556)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"MINOR: Handle lastFetchedEpoch/divergingEpoch in FetchSession and DelayedFetch (#9434)In 2.7, we added lastFetchedEpoch to fetch requests and divergingEpoch to fetch responses. We are not using these for truncation yet, but in order to use these for truncation with IBP 2.7 onwards in the next release, we should make sure that we handle these in all the supporting classes even in 2.7.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Remove unnecessary suppress (#10434)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"KAFKA-6422 Mirror maker will throw null pointer exception when the message value is null (#4387)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, James Cheng <jylcheng@yahoo.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4052: Allow passing properties file to ProducerPerformanceTested by running on a kerberos enabled Kafka cluster.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen Shapira, Sriharsha ChintalapaniCloses #1749 from SinghAsDev/KAFKA-4052",0
"MINOR: Fix flaky standby task test (#4767)The standby-task test failed due to standby task distribution not be exactly equal. I think this will be the case from time to time, so I've updated test to make sure the standby task assignment count is not zero.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: parameter name fix for maxScalacThreads (#12151)There's a typo in build.gradle, and cause the `maxScalacThreads` parameter doesn't work as expected",1
"KAFKA-4919: Document that stores must not be closed when Processors are closedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Eno Thereska, Matthias J. Sax, Elias Levy, Guozhang WangCloses #2725 from dguy/minor-processor-java-doc",2
"KAFKA-12396: added null check for state stores key (#10548)Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
trivial fix on coding style,0
KAFKA-10713: Stricter protocol parsing in hostnames (#9593)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
KAFKA-7922: Return authorized operations in Metadata request response (KIP-430 Part-2)-  Use automatic RPC generation in Metadata Request/Response classes-  https://cwiki.apache.org/confluence/display/KAFKA/KIP-430+-+Return+Authorized+Operations+in+Describe+ResponsesAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #6352 from omkreddy/KIP-430-METADATA,5
"KAFKA-6776: ConnectRestExtension Interfaces & Rest integration (KIP-285)This PR provides the implementation for KIP-285 and also a reference implementation for authenticating BasicAuth credentials using JAAS LoginModuleAuthor: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Arjun Satish <wicknicks@users.noreply.github.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4931 from mageshn/KIP-285",5
MINOR: Update Jackson to 2.10.0 (#7411)Guava hasn't been upgraded due to potential incompatibility with the reflectionslibrary:https://github.com/ronmamo/reflections/issues/194Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"MINOR; Test last committed record offset for Controllers (#12249)As part of KIP-835, LastCommittedRecordOffset was added to theKafkaController metric type. Make sure to test that metric.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-4591; Create Topic Policy (KIP-108)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2361 from ijuma/kafka-4591-create-topic-policy",1
KAFKA-923 Improve controller failover latency. Remove unnecessary zookeeper reads; reviewed by Jun Rao,4
"KAFKA-10005: Decouple RestoreListener from RestoreCallback (#8676)And remove bulk loading mechanism inside RocksDB.Reviewers: John Roesler <vvcephei@apache.org>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFKA-13127; Fix stray topic partition deletion for kraft (#11118)This patch fixes BrokerMetadataPublisher.findGhostReplicas (renamed to findStrayPartitions)so that it returns the stray partitions. Previously it was returning the non-stray partitions. Thiscaused all of these partitions to get deleted on startup by mistake.Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",4
"Add support for infinite endpoints for range queries (#11120)Add support to open endpoint range queries in key-value storesImplements: KIP-763Reviewers: Almog Gavra <almog@confluent.io>, Luke Chen <showuon@gmail.com>, John Roesler <vvcephei@apache.org>",5
"KAFKA-9306: The consumer must close KafkaConsumerMetrics (#7839)Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>, Shailesh Panwar <spanwar@confluent.io>",5
"KAFKA-4404; Add javadocs to document core Connect types, especially that integer types are signedAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2296 from ewencp/kafka-4404-document-connect-signed-integer-types",2
"KAFKA-3846: KIP-65: include timestamp in Connect record typeshttps://cwiki.apache.org/confluence/display/KAFKA/KIP-65%3A+Expose+timestamps+to+ConnectAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1537 from shikhar/kafka-3846",5
"KAFKA-14007: Close header converters during Connect task shutdown (#12309)The HeaderConverter interface extends Closeable, but we weren't closing them anywhere before. This change causes header converters to be closed as part of task shutdown.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Chris Egerton <fearthecellos@gmail.com>",1
MINOR: Fix documentation of compactionRemoved a duplicate line and also cleaned up some of the language around compaction guarantees.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Gwen ShapiraCloses #2089 from apurvam/fix-documentation-of-compaction and squashes the following commits:03c5bdd [Apurva Mehta] Fix line length to be consistent with the rest of the file0af1a86 [Apurva Mehta] MINOR: fix duplicate line in docs for compaction.,2
HOTFIX: fix for standby tasks using batching restoreAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3625 from bbejeck/HOTFIX_need_to_correct_stanby_task_restoration_to_use_new_restore_api,0
KAFKA-13828; Ensure reasons sent by the consumer are small (#12043)This PR reworks the reasons used in the ConsumerCoordinator to ensure that they remain reasonably short.Reviewers: Bruno Cadonna <bruno@confluent.io>,5
"KAFKA-3705 Added a foreignKeyJoin implementation for KTable. (#5527)https://issues.apache.org/jira/browse/KAFKA-3705Allows for a KTable to map its value to a given foreign key and join on another KTable keyed on that foreign key. Applies the joiner, then returns the tuples keyed on the original key. This supports updates from both sides of the join.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Jan Filipiak <Jan.Filipiak@trivago.com>, pgwhalen, Alexei Daniline",5
HOTFIX: fix PriorityQueue iteration to assign warmups in priority order (#12585)Based on a patch submitted to the confluentinc fork & then abandoned. Needed some updates and minor expansion but more or less just re-applied the changes proposed in confluentinc#697.Original PR has a very detailed justification for these changes but the tl;dr of it is that apparently the PriorityQueue's iterator does not actually guarantee to return elements in priority order.Reviewer: Luke Chen <showuon@gmail.com>,4
"KAFKA-10390; Remove ignore case option when grep process info to be more specificRemove ignore case option when grep process info to be more specific since our entry point is definitely `kafka.Kafka`.Author: Luke Chen <showuon@gmail.com>Reviewers: Gwen Shapira, Lucas BradstreetCloses #9179 from showuon/KAFKA-10390",5
Update introduction.html (#7853)Fixing small grammar issue with plural versionsReviewers: Mickael Maison <mickael.maison@gmail.com>,0
"MINOR: KafkaFutureImpl#addWaiter should be protected (#4734)KafkaFutureImpl#addWaiter should be protected, just like KafkaFuture#addWaiter.  As described in KIP-218, whenComplete is the public API, not addWaiter.",1
MINOR: remove stream simple benchmark suite (#8353)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Update Streams Scala API for addition of Grouped (#5793)While working on the documentation updates I realized the Streams Scala API needsto get updated for the addition of GroupedAdded a test for Grouped.scala ran all streams-scala tests and streams testsReviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-6138 Simplify StreamsBuilder#addGlobalStore (#4430)- implements KIP-233Author: Panuwat Anawatmongkhon <panuwat.anawatmongkhon@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA:5653: add join overloads to KTableAdd `join`, `leftJoin`, `outerJoin` overloads that use `Materialized` to `KTable`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3826 from dguy/kafka-5653",5
"MINOR: Fix log cleaner offset range log message (#8435)The upper limit offset is displayed incorrectly in the log cleaner summary message. For example:```Log cleaner thread 0 cleaned log __consumer_offsets-47 (dirty section = [358800359, 358800359])```We should be using the next dirty offset as the upper limit.Reviewers: David Arthur <mumrah@gmail.com>",1
kafka-1813; Build fails for scala 2.9.2; patched by Anatoly Fayngelerin; reviewed by Jun Rao,0
"MINOR: avoid unnecessary list iteration in ApiVersion.lastVersion (#8708)We unnecessarily iterate the versions list each time we lookuplastVersion, including in the hotpath Log.appendAsFollower.Given that allVersions is a constant, this is unnecessary.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
revert previous commit r1205659 because of wrong commit messagegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205662 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-7505: Process incoming bytes on write error to report SSL failures (#5800)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
KAFKA-2317: follow-up of KAFKA1367; reviewed by Guozhang Wang,5
"MINOR: Fix code section formatting in TROGDOR.md (#6720)Due to the lack of a blank line, a code section in TROGDOR.mdis not properly rendered. This PR fixes it.Reviewers: Jason Gustafson <jason@confluent.io>",5
trunk is the 0.8.2 snapshot,1
"Improve JavaDoc (#9594)In the JavaDoc, the implemented interface was described inaccurately.Also, the ordered list was formatted as plain text, not as html ""ol"".Reviewers: Boyang Chen <boyang@confluent.io>",5
"KAFKA-5470; Replace -XX:+DisableExplicitGC with -XX:+ExplicitGCInvokesConcurrent in kafka-run-classThis is important because Bits.reserveMemory calls System.gc() hoping to free nativememory in order to avoid throwing an OutOfMemoryException. This call is currentlya no-op due to -XX:+DisableExplicitGC.It's worth mentioning that -XX:MaxDirectMemorySize can be used to increase theamount of native memory available for allocation of direct byte buffers.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3371 from ijuma/kafka-5470-explicit-gc-invokes-concurrent",5
KAFKA-1333 follow-up; Add missing files for the coordinator folder,2
KAFKA-1057 Trim whitespaces from user specified configs; reviewed by Neha Narkhede,5
"KAFKA-7862 & KIP-345 part-one: Add static membership logic to JoinGroup protocol (#6177)This is the first diff for the implementation of JoinGroup logic for static membership. The goal of this diff contains:* Add group.instance.id to be unique identifier for consumer instances, provided by end user;Modify group coordinator to accept JoinGroupRequest with/without static membership, refactor the logic for readability and code reusability.* Add client side support for incorporating static membership changes, including new config for group.instance.id, apply stream thread client id by default, and new join group exception handling.* Increase max session timeout to 30 min for more user flexibility if they are inclined to tolerate partial unavailability than burdening rebalance.* Unit tests for each module changes, especially on the group coordinator logic. Crossing the possibilities like:6.1 Dynamic/Static member6.2 Known/Unknown member id6.3 Group stable/unstable6.4 Leader/FollowerThe rest of the 345 change will be broken down to 4 separate diffs:* Avoid kicking out members through rebalance.timeout, only do the kick out through session timeout.* Changes around LeaveGroup logic, including version bumping, broker logic, client logic, etc.* Admin client changes to add ability to batch remove static members* Deprecate group.initial.rebalance.delayReviewers: Liquan Pei <liquanpei@gmail.com>, Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Fix tests/docker/DockerfileFix tests/docker/Dockerfile to put the old Kafka distributions in thecorrect spot for tests.  Also, run_tests.sh should exit with an errorcode if image rebuilding fails, rather than silently falling back to anolder image.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2613 from cmccabe/dockerfix",2
KAFKA-1274 gradle.properties needs the variables used in the build.gradle patch by Joe Stein; Reviewed by Jun Rao,1
"KAFKA-3763; Remove deprecated APIs for 0.11.0.0This only removes deprecated methods,fields and constructors in a small number of classes.Deprecated producer configs is tracked via KAFKA-3353and the old clients and related (tools, etc.) won'tbe removed in 0.11.0.0.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2995 from ijuma/kafka-3763-remove-deprecated-0.11",4
kafka-1078; Update System Test to handle controller data returned by ZK; patched by John Fung; reviewed by Jun Rao,5
kafka-2195; Add versionId to AbstractRequest.getErrorResponse and AbstractRequest.getRequest; patched by Andrii Biletskyi; reviewed by Jun Rao,1
KAFKA-3339: Fix java docs for seekToEnd and seekToBeginning.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #1021 from SinghAsDev/KAFKA-3339,2
"KAFKA-9584: Fix Headers ConcurrentModificationException in Streams (#8181)Avoid forwarding a shared reference to the record context in punctuate calls.Note, this fix isn't airtight, since all processors triggered by a single punctuatecall will still see the same reference to the record context. It's also not a terriblyprincipled approach, since the context is still technically not defined, but thisis about the best we can do without significant refactoring. We will probablyfollow up with a more comprehensive solution, but this should avoid the issuefor most programs.Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",0
"KAFKA-7021: Reuse source based on config (#5163)This PR actually contains two changes:1. leverage on the TOPOLOGY_OPTIMIZATION config to ""adjust"" the topology internally to reuse the source topic.2. fixed a long dangling bug that whenever source topic is reused as changelog topic, write the checkpoint file for the consumed offset, this is done by union the ackedOffset from the producer, plus the consumed offset from the consumer, note we will priori ackedOffset since the same topic may show up in both (think about repartition topic), by doing this the consumed offset from source topics can be treated as checkpointed offset when reuse happens.3. added a few unit and integration tests with / wo the reusing, and make sure the restoration, standby task, and internal topic creation behaviors are all correct.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Fixing null handilg in ValueAndTimestampSerializer (#7679)Since ValueAndTimestampSerializer wraps an unknown Serializer, the output of that Serializer can be null. In which case the line.allocate(rawTimestamp.length + rawValue.length)will throw a NullPointerException.This pull request returns null instead.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Tuned timeout parameter to reduce chance of transient failureIncreased timeout in downstream consumer doing validation step. This addresses a transient failure case in mirror maker tests with mirror maker failover.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Gwen ShapiraCloses #521 from granders/minor-mm-transient-failure,0
KAFKA-143 Fixing source code files to have the Apache license header ;patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1183191 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-12408: Document omitted ReplicaManager metrics (#10258)Reviewers: Tom Bentley <tbentley@redhat.com>,2
"KAFKA-8179: Part 7, cooperative rebalancing in Streams (#7386)Key improvements with this PR:* tasks will remain available for IQ during a rebalance (but not during restore)* continue restoring and processing standby tasks during a rebalance* continue processing active tasks during rebalance until the RecordQueue is empty** only revoked tasks must suspended/closed* StreamsPartitionAssignor tries to return tasks to their previous consumers within a client* but do not try to commit, for now (pending KAFKA-7312)Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1498 Misc. producer performance enhancements. Patch from Guozhang.,5
MINOR: Remove usages of JavaConversions and fix some typos (#5115)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
KAFKA-5908; fix range query in CompositeReadOnlyWindowStoreThe `NextIteratorFunction` in `CompositeReadOnlyWindowStore` was incorrectly using the `timeFrom` as the `timeTo`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3868 from dguy/window-store-range-scan,1
"KAFKA-2802: kafka streams system testsAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #930 from ymatsuda/streams_systest",5
"KAFKA-4447; Controller resigned but it also acts as a controller for a long timeAuthor: Ismael Juma <ismael@juma.me.uk>Author: xiguantiaozhan <kafkausr@126.com>Author: tuyang <tuyang@meituan.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Onur Karaman <okaraman@linkedin.com>Closes #2191 from xiguantiaozhan/avoid_swamp_controllerLog",2
"HOTFIX: Don't check metadata unless you are creating topicDuring a broker rolling upgrade, it's likely we don't have enough brokers ready yet. If streams does not need to create a topic it shouldn't check how many brokers are up.The system test for this is in a separate PR: https://github.com/apache/kafka/pull/3411Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3418 from enothereska/hotfix-replication",0
MINOR: add timeouts to streams integration tests (#12216)Reviewers: David Arthur <mumrah@gmail.com>,3
kafka-1069; MBean kafka.cluster.Partition report wrong UnderReplicated status; patched by Jun Rao; reviewed by Neha Narkhede,0
kafka-1031; Little modification to the stop script to be able to kill the proper process; patched by Vladislav Pernin; reviewed by Jun Rao,5
"MINOR: Throw ProducerFencedException directly but with a new instance (#6717)Currently in maybeFailWithError, we always wrap the lastError as a KafkaException. For ProducerFencedException however, we should just throw the exception itself; however we throw a new instance since the previous book-kept one's call trace is not from this call, and hence could be confusing.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@conflent.io>",5
KAFKA-4903; Remove dead code in ShellAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2692 from cmccabe/KAFKA-4903,5
"KAFKA-4652: Added tests for KStreamBuilderAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2597 from bbejeck/KAFKA-4652_improve_kstream_builder_test_coverage",3
"KAFKA-7853: Refactor coordinator config (#6854)An attempt to refactor current coordinator logic.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-8415: Interface ConnectorClientConfigOverridePolicy needs to be excluded from class loading isolation (#6796)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-6790: Fix Streams processor node broken link (#4874)The page here https://kafka.apache.org/11/documentation/streams/developer-guide/memory-mgmt.html talks about processor nodes and refers to non existing links.Broken link (appears twice in the same document):https://kafka.apache.org/11/documentation/streams/concepts.html#streams-concepts-processorTo find this search for the word ""processor node"" on the page memory-management , the ones which are links are broken.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
MINOR: Pass one action per unique resource name in KafkaApis.filterAuthorized (#8432)90bbeedf52f introduced a regression resulting in passing an action per resourcename to the `Authorizer` instead of passing one per unique resource name. Refactorthe signatures of both `filterAuthorized` and `authorize` to make them easier to testand add a test for each.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
MINOR: Remove unnecessary assertDoesNotThrow (#9854)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"MINOR: Fix topology builder debug log message (#8005)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3522: Generalize Segments (#6170)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-2308: make MemoryRecords idempotent; reviewed by Guozhang Wang,1
"KAFKA-2686: Reset needsPartitionAssignment in SubscriptionState.assign()Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson, Jun RaoCloses #352 from guozhangwang/K2686",1
"KAFKA-2719; Use wildcard classpath for dependant-libsPR switches to wildcard classpath for dependant libs to restrict the length of classpath, thereby reducing command line length.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #400 from rajinisivaram/KAFKA-2719",5
KAFKA-1865 Add a flush() method to the producer.,1
KAFKA-2727: Topology partial constructionguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #411 from ymatsuda/topology_partial_construction,2
"MINOR: fix CreateTopic to return the same as DescribeTopic (#11348)Internal topic configs with default value are not included in the response of CreateTopic/DescribeTopic. However, if they are explicitly set, they will be included in the response.Reviewers: Jun Rao <junrao@gmail.com>",1
kafka-843; (addendum) Re-add the release-zip sbt target; patched by Cosmin Lehene; reviewed by Jun Rao,1
"KAFKA-6795; Added unit tests for ReplicaAlterLogDirsThreadAdded unit tests for ReplicaAlterLogDirsThread. Mostly focused on unit tests for truncating logic.Fixed  ReplicaAlterLogDirsThread.buildLeaderEpochRequest() to use future replica's latest epoch (not the latest epoch of replica it is fetching from). This follows the logic that offset for leader epoch request should be based on leader epoch of the follower (in this case it's the future local replica).Also fixed PartitionFetchState constructor that takes offset and delay. The code ignored the delay parameter and used 0 for the delay. This constructor is used only by another constructor which passes delay = 0, which luckily works.Author: Anna Povzner <anna@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #4918 from apovzner/kafka-6795",5
"KAFKA-7296; Handle coordinator loading error in TxnOffsetCommit (#5514)We should check TxnOffsetCommit responses for the COORDINATOR_LOADING_IN_PROGRESS error code and retry if we see it. Additionally, if we encounter an abortable error, we need to ensure that pending transaction offset commits are cleared.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
kafka-1529; transient unit test failure in testAutoCreateAfterDeleteTopic; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,3
MINOR: Fix typo and tweak wording in `RecordAccumulator` commentsThis was recently introduced in:https://github.com/apache/kafka/commit/1fbe445dde71df0023a978c5e54dd229d3d23e1bAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1152 from ijuma/fix-typos-in-record-accumulator,2
"MINOR: Fix small error in javadoc for persistent StoresClosed the last PR I made for this because I accidentally borked it with my other PR. Small error; I figure this is from copy-pasting the above docAuthor: Nikki Thean <nthean@etsy.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2336 from nixsticks/trunk",1
kafka-1384; Log Broker state; followup commit to add the missing new file,2
"MINOR: add IQ docs to streams documentationAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3484 from dguy/iq-doc",2
"MINOR: TopologyTestDriver should not require dummy parameters (#9477)TopologyTestDriver comes with a paper cut that it passes through aconfig requirement that application.id and bootstrap.servers must beconfigured. But these configs are not required in the context ofTopologyTestDriver specifically. This change relaxes the requirement.Reviewers: Boyang Chen <boyang@apache.org>, Matthias J. Sax <mjsax@apache.org>",1
KAFKA-12813: Remove deprecated schedule method in ProcessorContext (#10730)Removes methods deprecated via KIP-358.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
kafka-1352; Reduce logging on the server; patched by Ivan Lyutovg; reviewed by Guozhang Wang and Jun Rao,2
"KAFKA-3592: System test - configurable pathsThis patch adds logic for the following:- remove hard-coded paths to various scripts and jars in kafkatest service classes- provide a mechanism for overriding path resolution logic with a ""pluggable"" path resolver classAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1245 from granders/configurable-install-path",5
"KAFKA-8842: : Reading/Writing confused in Connect QuickStart GuideIn step 7 of the QuickStart guide, ""Writing data from the console and writing it back to the console"" should be ""Reading data from the console and writing it back to the console"".Co-authored-by: Alaa Zbair <alaa.zbair@grenoble-inp.org>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-4995; Fix remaining findbugs warnings in Kafka StreamsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Eno Thereska <eno@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2780 from cmccabe/KAFKA-4995",5
"KAFKA-4200; Fix throttle argument in kafka-reassign-partitions.shSimple jira which alters two things:1. kafka-reassign-partitions --verify prints Throttle was removed regardless of whether a throttle was applied. It should only print this if the value was actually changed.2. --verify should exception if the —throttle argument. (check generate too)To test this I extracted all validation logic into a separate method and added a test which covers the majority of combinations. The validation logic was retained as is, other than implementing (2) and adding validation to the --broker-list option which you can currently apply to any of hte main actions (where it is ignored). Requirement 1 was tested manually (as it's just println).Testing:- Build passes locally.- System test reassign_partitions_test.py also passes.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1896 from benstopford/KAFKA-4200",4
MINOR: Wakeups propagated from commitOffsets in WorkerSinkTask should be caughtAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1907 from hachikuji/catch-wakeup-worker-sink-task,1
"KAFKA-5364; ensurePartitionAdded does not handle pending partitions in abortable error stateAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3231 from hachikuji/KAFKA-5364",5
"message size not checked at the server; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-469git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1376943 13f79535-47bb-0310-9956-ffa450edef68",1
"remove unused import (#7345)Remove unused import that's slipping past checkstyle somehowReviewers: Matthias J. Sax <mjsax@apache.org>, Christopher Pettitt <cpettitt@confluent.io>",5
"KAFKA-10348: Share client channel between forwarding and auto creation manager (#10135)share forwarding channel and auto topic creation channel.Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2899: improve logging when unexpected exceptions thrown in reading local logCurrently we don't log exceptions raised when reading from the local log which makes tracking down the cause of problems a bit tricky.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Guozhang WangCloses #593 from benstopford/small-patches,0
HOTFIX: Added another broker to smoke testAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2362 from enothereska/hotfix-smoke-test-2-brokers,3
"Cleanup KTableImpl#doTransformValues (#6519)This PR is a follow-up of #6174 and #6453, which cleans up KTableImpl#doTransformValues method.Reviewers: Bill Bejeck <bbejeck@gmail.com>",4
KAFKA-979 Add jitter for time based rolling; reviewed by Neha Narkhede and Joel Koshy,1
MINOR: fix client_compatibility_features_test.py - DescribeAcls is already supported by KRaft (#10860)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-7528: Standardize on Min/Avg/Max Kafka metrics' default value - NaN (#5908)While metrics like Min, Avg and Max make sense to respective use Double.MAX_VALUE, 0.0 and Double.MIN_VALUE as default values to ease computation logic, exposing those values makes reading them a bit misleading. For instance, how would you differentiate whether your -avg metric has a value of 0 because it was given samples of 0 or no samples were fed to it?It makes sense to standardize on the output of these metrics with something that clearly denotes that no values have been recorded.Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9739: Fixes null key changing child node (#8400)For some context, when building a streams application, the optimizer keeps track of the key-changing operations and any repartition nodes that are descendants of the key-changer. During the optimization phase (if enabled), any repartition nodes are logically collapsed into one. The optimizer updates the graph by inserting the single repartition node between the key-changing node and its first child node. This graph update process is done by searching for a node that has the key-changing node as one of its direct parents, and the search starts from the repartition node, going up in the parent hierarchy.The one exception to this rule is if there is a merge node that is a descendant of the key-changing node, then during the optimization phase, the map tracking key-changers to repartition nodes is updated to have the merge node as the key. Then the optimization process updates the graph to place the single repartition node between the merge node and its first child node.The error in KAFKA-9739 occurred because there was an assumption that the repartition nodes are children of the merge node. But in the topology from KAFKA-9739, the repartition node was a parent of the merge node. So when attempting to find the first child of the merge node, nothing was found (obviously) resulting in StreamException(Found a null keyChangingChild node for..)This PR fixes this bug by first checking that all repartition nodes for optimization are children of the merge node.This PR includes a test with the topology from KAFKA-9739.Reviewers: John Roesler <john@confluent.io>",5
"MINOR: Pluggable verifiable clientsThis adds support for pluggable VerifiableConsumer and VerifiableProducers test client implementationsallowing third-party clients to be used in-place of the Java client in kafkatests.A new VerifiableClientMixin class is added and the standard Java Verifiable{Producer,Consumer}classes have been changed to use it.While third-party client drivers may be implemented with a complete class based on the Mixin, a simpleralternative which requries no kafkatest class implementation is available through the VerifiableClientApp class that uses ducktape's global param to specify the client app to use (passed to ducktape through the `--globals <json>` command line argument).Some existing kafkatest clients for reference:Go: https://github.com/confluentinc/confluent-kafka-go/tree/master/kafkatestPython: https://github.com/confluentinc/confluent-kafka-python/tree/master/confluent_kafka/kafkatestC++: https://github.com/edenhill/librdkafka/blob/0.9.2.x/examples/kafkatest_verifiable_client.cppC#/.NET: https://github.com/confluentinc/confluent-kafka-dotnet/tree/master/test/Confluent.Kafka.VerifiableClientThis PR also contains documentation for the simplex JSON-based verifiable\* client protocol.There are also some minor improvements that makes troubleshooting failing client tests easier.Author: Magnus Edenhill <magnus@edenhill.se>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2048 from edenhill/pluggable_verifiable_clients",5
KAFKA-8539; Add group.instance.id to Subscription (#6936)This PR is part of KIP-345's effort to utilize this new field for more stable topic partition assignment. We add the group instance id to the `Subscription` object to allow partition assignors to make stickier assignments. More details [here](https://cwiki.apache.org/confluence/display/KAFKA/KIP-345%3A+Introduce+static+membership+protocol+to+reduce+consumer+rebalances#KIP-345:Introducestaticmembershipprotocoltoreduceconsumerrebalances-ClientBehaviorChanges). Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Add note on IDEMPOTENT_WRITE ACL to notable changes (#12260)Update notable changes documentation to mention requiring IDEMPOTENT_WRITE permissionwhen producing messages with default/idempotent configuration and broker version lower than2.8.0.Reviewers: Ismael Juma <ismael@juma.me.uk>, Luke Chen <showuon@gmail.com>",5
"KAFKA-13053; Bump kraft frame version for incompatible changes from 2.8 (#11010)This patch bumps the default frame version for kraft records from 0 to 1. At the same time, we reset allrecords versions back to 0 and we enable flexible version support for UnregisterBrokerRecord, which wasmissed previously. Note that the frame version bump also affects the KIP-405 records since they aresharing AbstractApiMessageSerde. Since these records were not part of any previous releases, this shouldnot cause an issue.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
"KAFKA-6775: Fix the issue of without init super class's (#4859)Some anonymous classes of AbstractProcessor didn't initialize their superclass. This will not set up ProcessorContext context at AbstractProcessor.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: reduce commit time on test (#5095)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: enforce non-negative invariant for checkpointed offsets (#8297)While discussing KIP-441 we realize we don't strictly enforce that all checkpointed offset sums are positive (or 0, though there's not much point to checkingpoint a 0 offset is there)?Rather than awkwardly try handle this within every user/reader of the checkpoint file, we should just make a guarantee that all returned checkpointed offsets are positive.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-1981; Make log compaction point configurableNow uses LogSegment.largestTimestamp to determine age of segment's messages.Author: Eric Wasserman <eric.wasserman@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1794 from ewasserman/feat-1981,2
"MINOR: Log exception thrown by consumer.poll() in VerifiableConsumer (#6368)SecurityTest.test_client_ssl_endpoint_validation_failure is failing because it greps for 'SSLHandshakeException in the consumer and producer log files. With the fix for KAKFA-7773, the test uses the VerifiableConsumer instead of the ConsoleConsumer, which does not log the exception stack trace to the service log. This patch catches exceptions in the VerifiableConsumer and logs them in order to fix the test. Tested by running the test locally.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: Fix Javadoc of @throws AuthorizationException for KafkaConsumer.pollAuthor: Magnus Reftel <magnus.reftel@skatteetaten.no>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1901 from reftel/feature/poll_javadoc,2
kafka-951; Leader election rate may be reported on a non-controller; patched by Jun Rao; reviewed by Swapnil Ghike,5
"KAFKA-9955: Prevent SinkTask::close from shadowing other exceptions (#8618)* If two exceptions are thrown the `closePartitions` exception is suppressed* Add unit tests that throw exceptions in put and close to verify that  the exceptions are propagated and suppressed appropriately out of WorkerSinkTask::executeReviewers: Chris Egerton <chrise@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"MINOR: Add RandomComponentPayloadGenerator and update Trogdor documentation (#7103)Add a new RandomComponentPayloadGenerator that gives a payload based on random selection of another PayloadGenerator.  Additionally, add an example that uses a non-default PayloadGenerator configuration to TROGDOR.md.Reviewers: Colin P. McCabe <cmccabe@apache.org>",5
"KAFKA-13246: StoreQueryIntegrationTest#shouldQueryStoresAfterAddingAndRemovingStreamThread now waits for the client state to go to REBALANCING/RUNNING after adding/removing a thread and waits for state RUNNING before querying the state store. (#11334)KAFKA-13246: StoreQueryIntegrationTest#shouldQueryStoresAfterAddingAndRemovingStreamThread does not gate on stream state wellThe test now waits for the client to transition to REBALANCING/RUNNING after adding/removing a thread as well as to transition to RUNNING before querying the state store.Reviewers: singingMan <@3schwartz>, Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: upgrade pip from 20.2.2 to 21.1.1 (#10661)The following error happens on my mac m1 when building docker image for system tests.Collecting pynacl  Using cached PyNaCl-1.4.0.tar.gz (3.4 MB)  Installing build dependencies ... error  ERROR: Command errored out with exit status 1:   command: /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-k867aac0/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'setuptools>=40.8.0' wheel 'cffi>=1.4.1; python_implementation != '""'""'PyPy'""'""''       cwd: None  Complete output (14 lines):  Traceback (most recent call last):    File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main      return _run_code(code, main_globals, None,    File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code      exec(code, run_globals)    File ""/usr/local/lib/python3.8/dist-packages/pip/__main__.py"", line 23, in <module>      from pip._internal.cli.main import main as _main  # isort:skip # noqa    File ""/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py"", line 5, in <module>      import locale    File ""/usr/lib/python3.8/locale.py"", line 16, in <module>      import re    File ""/usr/lib/python3.8/re.py"", line 145, in <module>      class RegexFlag(enum.IntFlag):  AttributeError: module 'enum' has no attribute 'IntFlag'  ----------------------------------------ERROR: Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-k867aac0/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'setuptools>=40.8.0' wheel 'cffi>=1.4.1; python_implementation != '""'""'PyPy'""'""'' Check the logs for full command output.There was a related issue: pypa/pip#9689 and it is already fixed by pypa/pip#9689 (included by pip 21.1.1). I test the pip 21.1.1 and it works well on mac m1.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: Improve JavaDoc for some public classes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Mastuda <yasuhiro.mastuda@gmail.com>Closes #999 from guozhangwang/KJavaDoc,2
KAFKA-901 Kafka server can become unavailable if clients send several metadata requests; reviewed by Jun Rao,5
"MINOR: Return correct instance of SessionWindowSerde (#5546)Plus minor javadoc cleanups.Reviewers: Matthias J. Sax <matthias@confluent.io>,Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-10249: don't try to read un-checkpointed offsets of in-memory stores (#8996)Fixes an asymmetry in which we avoid writing checkpoints for non-persistent stores, but still expected to read them, resulting in a spurious TaskCorruptedException.Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",1
KAFKA-10516; Disable automatic retry of `THROTTLING_QUOTA_EXCEEDED` errors in the `kafka-topics` command (KIP-599) (#9334)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
MINOR: Fix plugin path in quickstart.html (#12252)Reviewers: Luke Chen <showuon@gmail.com>,0
"MINOR: Enable capture of full stack trace in StreamTask#process (#6310)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
kafka-2016; RollingBounceTest takes long; patched by Ted Malaska; reviewed by Jun Rao,3
"MINOR: Various small improvements to kafka.metrics.MetricsTest`testBrokerTopicMetricsUnregisteredAfterDeletingTopic` seemed completely broken,as it was creating a topic but producing/consuming to another one.Authored with mpburgAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3034 from mimaison/Fix-testBrokerTopicMetricsBytesInOut",3
"KAFKA-5241: GlobalKTable should checkpoint offsets after restoring stateEnsure checkpointable offsets for GlobalKTables are always written on close.Author: Tommy Becker <tobecker@tivo.com>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #3054 from twbecker/KAFKA-5241",1
MINOR: Document improvement (#6682)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"KAFKA-6986: Export Admin Client metrics through Stream Threads (#5210)KAFKA-6986:Export Admin Client metrics through Stream ThreadsWe already exported producer and consumer metrics through KafkaStreams class:#4998It makes sense to also export the Admin client metrics.I didn't add a separate unittest case for this. Let me know if it's needed.This is my first contribution, feel free to point out any mistakes that I did.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"MINOR: added upgrade and API changes to docsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Will Marshall, Damian Guy, Guozhang Wang, Michael G. NollCloses #2461 from mjsax/addStreamsUpdateSecton",5
KAFKA-5104: DumpLogSegments should not open index files with `rw`Add a parameter 'writable' for AbstractIndex and set its default value to true for its children classes.Author: amethystic <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2905 from amethystic/kafka-5104_DumpLogSegments_should_not_open_index_files_with_rw,2
"MINOR: Remove unneeded FIXME (#9330)A previous iteration of the Raft patch had a broken check for disconnects. We had fixed the problem, but forgotten to remove the FIXME.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
MINOR: JoinGroupRequest V0 invalid rebalance timeoutA JoinGroupRequest V0 built with the Builder hada rebalance timeout  = -1 rather than equal to session timeoutas it would have been if coming from the wire and deserializedfrom a V0 Structfix developed with mimaisonAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Rajini SivaramCloses #2936 from edoardocomar/MINOR-JoinGroupRequestV0,2
"KAFKA-5557: Using a logPrefix inside the StreamPartitionAssignorAdded logPrefix for avoiding stream thread name formatting replicated more timesAuthor: ppatierno <ppatierno@live.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3488 from ppatierno/kafka-5557",5
KAFKA-13045: Adding a test for batched offsetFetch requests with one group repeating (#11000)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-6949; alterReplicaLogDirs() should grab partition lock when accessing log of the future replicaNoSuchElementException will be thrown if ReplicaAlterDirThread replaces the current replica with future replica right before the request handler thread executes `futureReplica.log.get.dir.getParent` in the ReplicaManager.alterReplicaLogDirs(). The solution is to grab the partition lock when request handler thread attempts to check the destination log directory of the future replica.Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #5081 from lindong28/KAFKA-6949,2
KAFKA-9150; DescribeGroup uses member assignment as metadataAuthor: David Jacot <djacot@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #7658 from dajac/KAFKA-9150,5
MINOR: Update jackson databind to 2.10.5.1 (#9702)Fixes:* DOMDeserializer: setExpandEntityReferences(false) may not prevent external entityexpansion in all cases (CVE-2020-25649)Full details: https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.10#micro-patchesReviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-12902: Add unit32 type in generator (#10830)Add uint32 support in the KRPC generator.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-4630; Implement RecordTooLargeException when communicating with pre-KIP-74 brokersAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2390 from cmccabe/KAFKA-4630",5
"KAFKA-6058: Refactor consumer API result return types (#4856)Refactored the return types in consumer group APIs the following way:```Map<TopicPartition, KafkaFuture<Void>> DeleteConsumerGroupsResult#deletedGroups()Map<TopicPartition, KafkaFuture<ConsumerGroupDescription>> DescribeConsumerGroupsResult#describedGroups()KafkaFuture<Collection<ConsumerGroupListing>> ListConsumerGroupsResult#listings()KafkaFuture<Map<TopicPartition, OffsetAndMetadata>> ListConsumerGroupOffsetsResult#partitionsToOffsetAndMetadata()```* For DeleteConsumerGroupsResult and DescribeConsumerGroupsResult, for each group id we have two round-trips to get the coordinator, and then send the delete / describe request; I leave the potential optimization of batching requests for future work.* For ListConsumerGroupOffsetsResult, it is a simple single round-trip and hence the whole map is wrapped as a Future.* ListConsumerGroupsResult, it is the most tricky one: we would only know how many futures we should wait for after the first listNode returns, and hence I constructed the flattened future in the middle wrapped with the underlying map of futures; also added an iterator API to compensate the ""fail the whole future if any broker returns error"" behavior. The iterator future will throw exception on the failing brokers, while return the consumer for other succeeded brokers.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
MINOR: Remove redundant semicolons in `KafkaApis` imports (#6889)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3590; Handle not-enough-replicas errors when writing to offsets topicAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #1859 from hachikuji/KAFKA-3590",5
"MINOR: Fix stale comment in partition reassignment javadoc (#7438)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",2
"KAFKA-4501; Fix EasyMock and disable PowerMock tests under Java 9- EasyMock 3.5 supports Java 9.- Fixed issues in `testFailedSendRetryLogic` and`testCreateConnectorAlreadyExists` exposed by new EasyMockversion. The former was passing `anyObject` to`andReturn`, which doesn't make sense. This was leavingbehind a global `any` matcher, which caused a few issues inthe new version. Fixing this meant that the correlation ids hadto be updated to actually match. The latter was missing acouple of expectations that the previous version of EasyMockdidn't catch.- Removed unnecessary PowerMock dependency from 3 tests.- Disabled remaining PowerMock tests when running with Java 9until https://github.com/powermock/powermock/issues/783 isin a release.- Once we merge this PR, we can enable tests in the Java 9 buildsin Jenkins.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3845 from ijuma/kafka-4501-easymock-powermock-java-9",5
"KAFKA-4827: Correctly encode special chars while creating URI objectsSigned-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4205 from wicknicks/KAFKA-4827",5
"MINOR: Fixed log in Topology Builder. (#5477)- fix log statement in Topology Builder.- addressed some warnings shown by IntellijReviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Satish Duggana <satishd@apache.org>, Matthias J. Sax <matthias@confluent.io>",5
TRIVIAL: Remove redundant asMap utility in ConsumerProtocolAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3084 from hachikuji/trivial-remove-redundant-utility,4
"MINOR: code and JavaDoc cleanup (#7462)Reviewers: Jukka Karvanen <jukka.karvanen@jukinimi.com>, Bill Bejeck <bill@confluent.io>",5
trivial change to 0.9.0 docs to fix incorrect ssl.key.password,4
MINOR: Fix MockAdminClient to not throw IndexOutOfBoundsException when brokerId is above the known one. (#8392)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-4031; Check if buffer cleaner is null before using itA small fix to check null before using the referenceAuthor: Som Sahu <sosahu@microsoft.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1718 from soumyajit-sahu/nullCheckForDirectBufferCleaner,4
"KAFKA-13845: Add support for reading KRaft snapshots in kafka-dump-log (#12084)The kafka-dump-log command should accept files with a suffix of "".checkpoint"". It should also decode and print using JSON the snapshot header and footer control records.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
KAFKA-1510; Do full (unfiltered) offset commits when offsets storage is set to Kafka; reviewed by Joel Koshy,1
"KAFKA-4857: Replace StreamsKafkaClient with AdminClient in Kafka StreamsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4242 from mjsax/kafka-4857-admit-client",5
"KAFKA-4730: Streams does not have an in-memory windowed store (#6239)Implemented an in-memory window store allowing for range queries. A finite retention period defines how long records will be kept, ie the window of time for fetching, and the grace period defines the window within which late-arriving data may still be written to the store.Unit tests were written to test the functionality of the window store, including its insert/update/delete and fetch operations. Single-record, all records, and range fetch were tested, for both time ranges and key ranges. The logging and metrics for late-arriving (dropped)records were tested as well as the ability to restore from a changelog.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Group KafkaController, ReplicaManager metrics in documentation (#7891)Some minor edits to the docsReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2
"KAFKA-1546; Automate replica lag tuning; reviewed by Joel Koshy, NehaNarkhede, Jun Rao and Guozhang Wang",5
"HOTFIX: KAFKA-4060 and KAFKA-4476 follow upAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2418 from mjsax/kafka-4060-zk-test-follow-up",3
KAFKA-2345;  Attempt to delete a topic already marked for deletion throws ZkNodeExistsException; patched by Ashish Singh; reviewed by Sriharsha Chintalapani and Ismael Juma,4
"MINOR: Include number of members in group coordinator messages (#10273)Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-2437; Trivial follow-up,5
MINOR: Code cleanup in StreamsResetter (#9126)Reviewers: Guozhang Wang <guozhang@confluent.io>,5
"MINOR: Insure that KafkaStreams client is closed if test fails (#5618)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roessler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Eno Thereska <enother@amazon.com>",5
"KAFKA-8802: ConcurrentSkipListMap shows performance regression in cache and in-memory store (#7212)Reverts the TreeMap -> ConcurrentSkipListMap change that caused a performance regression in 2.3, and fixes the ConcurrentModificationException by copying (just) the key set to iterate overReviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
HOTFIX: Fix header in ByteArrayConverterAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Manikumar reddy O <manikumar.reddy@gmail.com>Closes #2690 from ijuma/fix-header-in-byte-array-converter,0
"Create a generic Kafka thread; patched by Yang Ye; reviewed by Jun Rao, Jay Kreps; KAFKA-56git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1375360 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-5230; Fix conversion of Class configs to handle nested classes properlyAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3044 from ewencp/kafka-5230-nested-class-recommended-values",5
KAFKA-3486: fix autocommit when partitions assigned manuallyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1169 from hachikuji/KAFKA-3486,5
"KAFKA-887 Standardize logging for partition information to [%s,%d] format; reviewed by Swapnil and Jun",5
"MINOR: always set Serde.Long on count operationsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>Closes #3943 from dguy/count-materialized",5
"KAFKA-12380 shutdown Executor in Connect's Worker when closed (#11955)When the worker is stopped, it does not shutdown this executor. This PR fixes the issue.Reviewers: Luke Chen <showuon@gmail.com>",0
"KAFKA-12318: system tests need to fetch Topic IDs via Admin Client instead of via ZooKeeper (#10286)Change the ducktape system tests to support both ZK and raft topic IDs. Clarifies thatthe IBP check applies to the ZK code path.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>",5
"KAFKA-8391; Improved the Connect integration tests to make them less flakyAdded the ability for the connector handles and task handles, which are used by the monitorable source and sink connectors used to verify the functionality of the Connect framework, to record the number of times the connector and tasks have each been started, and to allow a test to obtain a `RestartLatch` that can be used to block until the connectors and/or tasks have been restarted a specified number of types.Typically, a test will get the `ConnectorHandle` for a connector, and call the `ConnectorHandle.expectedRestarts(int)` method with the expected number of times that the connector and/or tasks will be restarted, and will hold onto the resulting `RestartLatch`. The test will then change the connector (or otherwise cause the connector to restart) one or more times as desired, and then call `RestartLatch.await(long, TimeUnit)` to block the test up to a specified duration for the connector and all tasks to be started the specified number of times.This commit also increases several of the maximum wait times used in other integration tests. It doesn’t hurt to potentially wait longer, since most test runs will not need to wait the maximum amount of time anyway. However, in the rare cases that do need that extra time, waiting a bit more is fine if we can reduce the flakiness and minimize test failures that happened to time out too early.Unit tests were added for the new `RestartLatch` and `StopAndStartCounter` utility classes. This PR only affects the tests and does not affect any runtime code or API.**This should be merged on `trunk` and backported to the `2.3.x` branch.**Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis, Arjun SatishCloses #7019 from rhauch/kafka-8391",1
"KAFKA-6289; NetworkClient should not expose failed internal ApiVersions requestsThe NetworkClient internally ApiVersion requests to each broker following connection establishment. If this request happens to fail (perhaps due to an incompatible broker), the NetworkClient includes the response in the result of poll(). Applications will generally not be expecting this response which may lead to failed assertions (or in the case of AdminClient, an obscure log message).I've added test cases which await the ApiVersion request sent by NetworkClient to be in-flight, and then disconnect the connection and verify that the response is not included from poll().Author: Jason Gustafson <jason@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4280 from hachikuji/KAFKA-6289",5
"KAFKA-4565; Separation of Internal and External traffic (KIP-103)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2354 from ijuma/kafka-4565-separation-of-internal-and-external-traffic",5
MINOR: Add KRaft broker api to protocol docs (#11786)Add KRaft broker api to protocol docs Reviewers: Luke Chen <showuon@gmail.com>,2
MINOR: Menu updates and navigation (#4405)* Menu updates and navigationReviewers: Guozhang Wang <wangguoz@gmail.com>,5
MINOR: Give a name to the coordinator heartbeat threadFollowed the same naming pattern as the producer sender thread.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason GustafsonCloses #1854 from ijuma/heartbeat-thread-name,5
"KAFKA-3281: Improve message of *-server-stop.sh when process is not runningStop scritps such as kafka-server-stop.sh log messages of kill command's error when processes aren't running.This PR changes this message to ""No kafka server to stop"".Author: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Gwen ShapiraCloses #971 from sasakitoa/stop_scripts_says_not_good_message",5
KAFKA-707 Improve error message in the producer when sending data to a partition without an active leader; reviewed by Jun Rao,5
"kafka-1952; High CPU Usage in 0.8.2 release; patched by Jun Rao; reviewed by Guozhang Wang, Ewen Cheslack-Postava and Neha Narkhede",5
"MINOR: Remove repeat creation of `ZkConfigRepository` (#11762)In `KafkaServer, `ZkConfigRepository` is just a wrapper of `zkClient`, so  we don't need to create a new one.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-5028; convert kafka controller to a single-threaded event queue modelThe goal of this ticket is to improve controller maintainability by simplifying the controller's concurrency semantics. The controller code has a lot of shared state between several threads using several concurrency primitives. This makes the code hard to reason about.This ticket proposes we convert the controller to a single-threaded event queue model. We add a new controller thread which processes events held in an event queue. Note that this does not mean we get rid of all threads used by the controller. We merely delegate all work that interacts with controller local state to this single thread. With only a single thread accessing and modifying the controller local state, we no longer need to worry about concurrent access, which means we can get rid of the various concurrency primitives used throughout the controller.Performance is expected to match existing behavior since the bulk of the existing controller work today already happens sequentially in the ZkClient’s single ZkEventThread.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2816 from onurkaraman/KAFKA-5028",2
MINOR: fix typo in FetchRequest.json (#11988)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: improve Session expiration notice (#6618)Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
kafka-989; Race condition shutting down high-level consumer results in spinning background thread; patched by Phil Hargett; reviewed by Jun Rao,1
"KAFKA-9417: New Integration Test for KIP-447 (#8000)This change mainly have 2 components:1. extend the existing transactions_test.py to also try out new sendTxnOffsets(groupMetadata) API to make sure we are not introducing any regression or compatibility issue  a. We shrink the time window to 10 seconds for the txn timeout scheduler on broker so that we could trigger expiration earlier than later2. create a completely new system test class called group_mode_transactions_test which is more complicated than the existing system test, as we are taking rebalance into consideration and using multiple partitions instead of one. For further breakdown:  a. The message count was done on partition level, instead of global as we need to visualize the per partition order throughout the test. For this sake, we extend ConsoleConsumer to print out the data partition as well to help message copier interpret the per partition data.  b. The progress count includes the time for completing the pending txn offset expiration  c. More visibility and feature improvements on TransactionMessageCopier to better work under either standalone or group mode.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-3673: Connect tests don't handle concurrent config changesAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1340 from Ishiihara/connect-test-failure,3
"KAFKA-5604: Remove the redundant TODO marker on the Streams side (#8313)The issue itself has been fixed a while ago on the producer side, so we can just remove this TODO marker now (we've removed the isZombie flag already anyways).Reviewers: John Roesler <vvcephei@apache.org>",4
"KAFKA-5036; Second part: Points 2 -> 5): Refactor caching of Latest EpochThis PR covers point (2) and point (5) from KAFKA-5036:**Commit 1:**2. Currently, we update the leader epoch in epochCache after log append in the follower but before log append in the leader. It would be more consistent to always do this after log append. This also avoids issues related to failure in log append.5. The constructor of LeaderEpochFileCache has the following:lock synchronized { ListBuffer(checkpoint.read(): _*) }But everywhere else uses a read or write lock. We should use consistent locking.This is a refactor to the way epochs are cached, replacing the code to cache the latest epoch in the LeaderEpochFileCache by reusing the cached value in Partition. There is no functional change.**Commit 2:**Adds an assert(epoch >=0) as epochs are written. Refactors tests so they never hit this assert.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2831 from benstopford/KAFKA-5036-part2-second-try",1
KAFKA-193 Add a logging helper trait and use it where logging is used. Patch from Joe Stein.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205311 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10895: Attempt to prevent JAAS config from being overwritten for basic auth filter in Connect (#9806)If a connector, converter, etc. invokes [Configuration::setConfiguration](https://docs.oracle.com/javase/8/docs/api/javax/security/auth/login/Configuration.html#setConfiguration-javax.security.auth.login.Configuration-), it will cause the Connect basic auth filter to use that JAAS config instead of the one configured at startup with the `-Djava.security.auth.login.config` JVM property. This can cause requests to the worker to succeed initially but start to be rejected after the JVM's global JAAS config is altered.To alleviate this the current PR instructs the Connect Worker to cache the JVM's global JAAS configuration at the beginning (as soon as the `BasicAuthSecurityRestExtension` class is loaded), and use that for all future authentication. Existing tests for the JAAS basic auth filter are modified to work with the new internal logic. The `testEmptyCredentialsFile` test is corrected to actually operate on an empty credentials file (instead of a non-existent credentials file, which it currently operates on). A new test is added to ensure that, even if the global JAAS config is overwritten, the basic auth filter will use the first one it could find.Reviewers: Greg Harris <gregh@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
MINOR: Add AUTO_OFFSET_RESET_CONFIG to StreamsConfig; remove TOTAL_RECORDS_TO_PROCESS from StreamsConfigand remove TOTAL_RECORDS_TO_PROCESSguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #985 from ymatsuda/config_params,5
"MINOR: update compression design doc to include lz4 protocolAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #1040 from omkreddy/MINOR-DOC",2
Minor log4j fixes for DefaultEventHandler to avoid printing ByteBufferMessageSets in error messages. This makes reading the important part of the error message very difficult,0
"KIP-476: Add new getAdmin method to KafkaClientSupplier (#7162)Reviewers: Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Use the automated protocol for the Consumer Protocol's subscriptions and assignments (#8897)This PR moves the consumer protocol to using the automated protocol instead of using plain old structs.Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Update Kafka configuration documentation to use kafka-configs.……sh, instead of deprecated kafka-topics.sh --alterAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #1772 from SinghAsDev/MinorKafkaConfigsDoc",5
"MINOR: Make JmxMixin wait for the monitored process to be listening on the JMX port before launching JmxToolAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3437 from ewencp/wait-jmx-listening",5
"KAFKA-8324: Add close() method to RocksDBConfigSetter (#6697)Following KIP-453, this PR adds a default close() method to the RocksDBConfigSetter interface and calls it when closing a store.Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"MINOR: trivial cleanups, javadoc errors, omitted StateStore tests, etc. (#8130)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3341: Improve error handling on invalid requests* Include request id when parsing of request header fails* Don't mute selector on a connection that was closed due to an error (otherwise a second exception is thrown)* Throw appropriate exception from `ApiKeys.fromId` if invalid id is passed* Fail fast in `AbstractRequest.getRequest` if we fail to handle an instance of `ApiKeys` (if this happens, it's a programmer error and the code in `getRequest` needs to be updated)I ran into the top two issues while trying to figure out why a connection from a producer to a broker was failing (and it made things harder than necessary). While fixing them, I noticed the third and fourth issues.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1017 from ijuma/kafka-3341-improve-error-handling-invalid-requests",0
"MINOR: Only add 'Data' suffix for generated request/response/header types (#8625)Currently we add ""Data"" to all generated classnames in order to avoid naming collisions with existing Request/Response objects. Generated classes for other persistent schema definitions (such as those used in `GroupCoordinator` and `TransactionCoordinator`) will not necessarily have the same problem, so it would be nice if the generated types could use the name defined in the schema directly.Reviewers: Boyang Chen <boyang@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
"MINOR: Add default serde in stream test to fix QA ERROR (#10958)We changed the default serde in Streams to be null in #10813, but forgot to add some in tests, for example TestTopicsTest and TopologyTestDriverTest.Reviewers: David Jacot <djacot@confluent.io>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-2015: Enable ConsoleConsumer to use new consumerThis extends the original patch done by GZ to provide Console access to both the new and old consumer API's. The code follows a pattern similar to that already used in ConsoleProducer.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jason Gustafson, Ismael Juma, Guozhang WangCloses #144 from benstopford/KAFKA-2015 and squashes the following commits:5058a7b [Ben Stopford] Patch for KAFKA-2015: removed unused imports6e08bf4 [Ben Stopford] Patch for KAFKA-2015: fixed formatting error739457c [Ben Stopford] Patch for KAFKA-2015: switched to blocking poll + typo + fixed to match style guide883a626 [Ben Stopford] Patch for KAFKA-2015: incorporating comments to date.0660629 [Ben Stopford] Merge remote-tracking branch 'upstream/trunk' into KAFKA-2015e102ff6 [Ben Stopford] KAFKA-2015 - ported patch from jira in and altered to match exising ConsoleProducer template",1
KAFKA-1312: Augment .gitignore. Patch from Timothy Chen.,5
"MINOR: Support ExponentialBackoff without jitter (#10455)It is useful to allow ExponentialBackoff to be configured to workwithout jitter, in order to make unit tests more repeatable.Reviewers: David Arthur <mumrah@gmail.com>",3
"MINOR: fix incorrect logging in StreamThreadFix incorrect logging when unable to create an active task. The output was: Failed to create an active task %s:It should have the taskId.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma, Eno ThereskaCloses #2109 from dguy/minor-logging",2
"KAFKA-8365; Consumer and protocol support for follower fetching (#6731)This patch includes API changes for follower fetching per [KIP-392](https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica) as well as the consumer implementation. After this patch, consumers will continue to fetch only from the leader, since the broker implementation to select an alternate read replica is not included here.Adds new `client.rack` consumer configuration property is added which allows the consumer to indicate its rack. This is just an arbitrary string to indicate some relative location, it doesn't have to actually represent a physical rack. We are keeping the naming consistent with the broker property (`broker.rack`).FetchRequest now includes `rack_id` which can optionally be specified by the consumer. FetchResponse includes an optional `preferred_read_replica` field for each partition in the response. OffsetForLeaderEpochRequest also adds new `replica_id` field which is similar to the same field in FetchRequest.When the consumer sees a `preferred_read_replica` in a fetch response, it will use the Node with that ID for the next fetch.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix DescribeLogDirs API error handling for older API versions (#12017)With KAFKA-13527 / KIP-784 we introduced a new top-level error code forthe DescribeLogDirs API for versions 3 and above. However, the changeregressed the error handling for versions less than 3 since the responseconverter fails to write the non-zero error code out (rightly) forversions lower than 3 and drops the response to the client whicheventually times out instead of receiving an empty log dirs response andprocessing that as a Cluster Auth failure.With this change, the API conditionally propagates the error code out tothe client if the request API version is 3 and above. This keeps thesemantics of the error handling the same for all versions and restoresthe behavior for older versions.See current behavior in the broker log:```bashERROR] 2022-04-08 01:22:56,406 [data-plane-kafka-request-handler-10] kafka.server.KafkaApis - [KafkaApi-0] Unexpected error handling request RequestHeader(apiKey=DESCRIBE_LOG_DIRS, apiVersion=0, clientId=sarama, correlationId=1) -- DescribeLogDirsRequestData(topics=null)org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default errorCode at version 0[ERROR] 2022-04-08 01:22:56,407 [data-plane-kafka-request-handler-10] kafka.server.KafkaRequestHandler - [Kafka Request Handler 10 on Broker 0], Exception when handling requestorg.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default errorCode at version 0```Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-13049: Name the threads used for log recovery (#11006)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Luke Chen <showuon@gmail.com>",2
"KAFKA-5698: Sort processor nodes based on its sub-tree size1. Sort processor nodes within a sub-topology by its sub-tree size: nodes with largest sizes are source nodes and hence printed earlier.2. Sort sub-topologies by ids; sort global stores by the source topic names.3. Open for discussion: start newlines for predecessor and successor.4. Minor: space between processor nodes and stores / topics; maintain `[]` for the topic names.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>Closes #3618 from guozhangwang/K5698-topology-description-sorting",2
"MINOR: Increase default `waitTime` in `waitUntilTrue` to 15 seconds5 seconds is probably enough when running tests locally, butdoesn't seem to be so for Jenkins when it is overloaded.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1589 from ijuma/increase-default-wait-time-for-wait-until-true",1
KAFKA-700 log client ip when we log each request on the broker; reviewed by Neha Narkhede,2
"KAFKA-2415; Fix transient failure in LogRecoveryTestAuthor: Jiangjie Qin <becket.qin@gmail.com>Author: Jiangjie Qin <jqin@jqin-ld1.linkedin.biz>Reviewers: Ismael Juma, Gwen ShapiraCloses #121 from becketqin/KAFKA-2415 and squashes the following commits:7a9f453 [Jiangjie Qin] Addressed Ismael's comment346103c [Jiangjie Qin] KAFKA-2415: Fix transient failure in LogRecoveryTest",3
"MINOR: Clean-up streams javadoc warnings (#9461)Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",5
add jmx beans in broker to track # bytes in consumer; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-336git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1351544 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-8569: integrate warning message under static membership (#6972)Static members never leave the group, so potentially we could log a flooding number of warning messages in the hb thread. The solution is to only log as warning when we are on dynamic membership.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-14122: Fix flaky test DynamicBrokerReconfigurationTest#testKeyStoreAlter (#12452)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"MINOR: Fix fetch session epoch comment in `FetchRequest.json` (#8802)The current ""about"" string incorrectly describes the session epoch as the partition epoch. Rename to `SessionEpoch` to make usage clearer. Also rename `MaxWait` to `MaxWaitMs` to make the time unit clear and `FetchableTopic` to `FetchTopic` for consistency with `FetchPartition`.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFAK-3522: Add TopologyTestDriver unit tests (#6179)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Missing throttle time in OffsetsForLeaderEpoch response (#5635)With KIP-320, the OffsetsForLeaderEpoch API is intended to be used by consumers to detect log truncation. Therefore the new response schema should expose a field for the throttle time like all the other APIs.Reviewers: Dong Lin <lindong28@gmail.com>",1
MINOR: putting back kstream stateful transform methodsguozhangwang* added back type safe stateful transform methods (kstream.transform() and kstream.transformValues())* changed kstream.process() to voidAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #292 from ymatsuda/transform_method,5
"KAFKA-2906: Fix Connect javadocs, restrict only to api subproject, and clean up javadoc warnings.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #599 from ewencp/kafka-2906-connect-javadocs",2
"MINOR: Add missing @Override annotation and simplify Thread declarations with lambdas (#8363)Add missing @Override annotations and use lambdas when declaring threads to suppress warnings in IDEs and improve readability. Reviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
KAFKA-4856; Synchronize registerAppInfo and unregisterAppInfoAnd make AppInfo's static fields final.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3696 from omkreddy/KAFKA-4856,5
MINOR: MemoryRecordsBuilder.sizeInBytes should consider initial positionAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3376 from hachikuji/records-builder-improvements,1
"MINOR: Drop enable.metadata.quorum config (#9934)The primary purpose of this patch is to remove the internal `enable.metadata.quorum` configuration. Instead, we rely on `process.roles` to determine if the self-managed quorum has been enabled. As a part of this, I've done the following:1. Replace the notion of ""disabled"" APIs with ""controller-only"" APIs. We previously marked some APIs which were intended only for the KIP-500 as ""disabled"" so that they would not be unintentionally exposed. For example, the Raft quorum APIs were disabled. Marking them as ""controller-only"" carries the same effect, but makes the intent that they should be only exposed by the KIP-500 controller clearer.2. Make `ForwardingManager` optional in `KafkaServer` and `KafkaApis`. Previously we used `null` if forwarding was enabled and relied on the metadata quorum check.3. Make `zookeeper.connect` an optional configuration if `process.roles` is defined.4. Update raft README to remove reference to `zookeeper.conntect`Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"Improve API docs of (flatT|t)ransform (#6365)This commit is a follow-up of pull request #5273Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2
Remove custom metrics jar and replace with latest from metrics HEAD; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-585.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1409296 13f79535-47bb-0310-9956-ffa450edef68,3
CallbackHandler.afterDequeuingExistingData is not called during event queue timeout; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-326git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1310482 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Fix broken link in security.html (#5670)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Broker down for significant amt of time system testSystem test where a broker is offline more than the configured timeouts.  In this case:- Max poll interval set to 45 secs- Retries set to 2- Request timeout set to 15 seconds- Max block ms set to 30 secondsThe broker was taken off-line for 70 seconds or more than double request timeout * num retries[passing system test results](http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2017-12-11--001.1513034559--bbejeck--KSTREAMS_1179_broker_down_for_significant_amt_of_time--6ab4802/report.html)Author: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4313 from bbejeck/KSTREAMS_1179_broker_down_for_significant_amt_of_time",5
"KAFKA-12663: Update FindCoordinator to support batch lookups (KIP-699) (#10743)This implements KIP-699: https://cwiki.apache.org/confluence/display/KAFKA/KIP-699%3A+Update+FindCoordinator+to+resolve+multiple+Coordinators+at+a+timeIt updates FindCoordinator request and response to support resolving multiple coordinators at a time. If a broker does not support the new FindCoordinator version, clients can revert to the previous behaviour and use a request for each coordinator.Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Sanjana Kaundinya <skaundinya@gmail.com>",5
MINOR: Fix error message in SnapshotWriter.java (#9862)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,0
"KAFKA-3658: Validate retention period be longer than window sizeAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Henry Cai, Ismael JumaCloses #1337 from guozhangwang/K3658",5
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunk,1
"KAFKA-3614: Consolidate duplicate code in KGroupedTableImplFeel free to review guozhangwang enothereska mjsax .Author: Michael G. Noll <michael@confluent.io>Reviewers: Matthias J. Sax, Michael G. Noll, Eno ThereskaCloses #1262 from miguno/KAFKA-3614",5
MINOR: Import classes that is used in docs to fix warnings. (#10136)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-10629: TopologyTestDriver should not require a Properties argument (#9660)Implements KIP-680.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10199: Remove tasks from state updater on revocation (#12520)Removes tasks from the state updater when the input partitions of the tasks are revoked during a rebalance.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"Add DirectoryConfigProvider to the service provider list (#11352)* Add DirectoryConfigProvider to the service provider listReviewers: Chris Egerton <chrise@confluent.io>, Tom Bentley <tbentley@redhat.com>",5
"Enable logging for tests, at a reasonable verbositypatch by cburroughs; reviewed by junrao for KAFKA-113git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1163693 13f79535-47bb-0310-9956-ffa450edef68",1
MINOR: Remove acceptor creation in network thread update code (#4742)Fix dynamic addition of network threads to only create new Processor threads and not the Acceptor.,1
"MINOR: Timeout waitForBlock in connect BlockingConnectorTest (#11595)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",3
MINOR: Avoid conflicting versions of org.apache.mina for MiniKdc deps (#5336)`mina-core` is a transitive dependency for `apacheds` and `apacheda`. It is safer to use from `apacheds` since that is the implementation.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-13397: MirrorMaker should not mirror topics ending with `.internal` (#11431)When running in dedicated mode, Connect runtimes are configured to use the `.internal` suffix for their topics. Reviewers: Mickael Maison <mickael.maison@gmail.com>, Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>",0
"KAFKA-12816 Added tiered storage related configs including remote log manager configs. (#10733)Added tiered storage related configs including remote log manager configs.Added local log retention configs to LogConfig.Added tests for the added configs.Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-5902: Added sink task metrics (KIP-196)Added Connect metrics specific to source tasks, and builds upon #3864 and #3911 that have already been merged into `trunk`, and #3959 that has yet to be merged.I'll rebase this PR when the latter is merged.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3975 from rhauch/kafka-5902",5
"MINOR: Update Scala to 2.13.8 in gradle.properties (#12273)It was updated in dependencies.gradle but this one was probably left out.Reviewers: Ismael Juma <ismael@juma.me.uk>, Andras Katona <41361962+akatona84@users.noreply.github.com>",1
"MINOR: fix failing ZooKeeper system tests (#10297)ZooKeeper-related system tests in zookeeper_security_upgrade_test.py andzookeeper_tls_test.py broke due to #10199. That patch changed the logic ofSecurityConfig.enabled_sasl_mechanisms() to only add the inter-broker SASLmechanism when the inter-broker protocol was SASL_{PLAINTEXT,SSL}. Theinter-broker protocol is left to default to PLAINTEXT for the SecurityConfiginstance associated with Zookeeper since that value doesn't apply to ZooKeeper,so the default inter-broker SASL mechanism of GSSAPI was not being added intothe set returned by enabled_sasl_mechanisms(). This is actually correct --GSSAPI shouldn't be added since inter-broker communication is a Kafka conceptand doesn't apply to ZooKeeper. GSSAPI should be added when ZooKeeper uses it,though -- which is the case in these tests. So the prior patch referred toabove uncovered a bug: we were relying on the default inter-broker SASLmechanism to signal that Kerberos was being used by ZooKeeper even though theinter-broker protocol has nothing to do with that determination in such cases.This patch explicitly includes GSSAPI in the list of enabled SASL mechanismswhen SASL is enabled for use by ZooKeeper.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"MINOR: Clean up of ConsumerCoordinator and PartitionAssignorAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1306 from Ishiihara/minor-consumer-cleanup",4
"KAFKA-6521: Use timestamped stores for KTables (#6667)Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-5247; Materialize committed offsets in offset orderWith this patch, offset commits are always materialized according to the order of the commit records in the offsets topic.Before this patch, transactional offset commits were materialized in transaction order. However, the log cleaner will always preserve the record with the greatest offset. This meant that if there was a mix of offset commits from a consumer and a transactional producer, then it we would switch from transactional order to offset order after cleaning, resulting in an inconsistent state.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3108 from apurvam/KAFKA-5247-materialize-committed-offsets-in-offset-order",1
MINOR: Initialize ConnectorConfig constructor with emptyMap and avoid instantiating a new Map (#9603)The map passed as an argument remains read-only and therefore can be initialized using Collections#emptyMap instead of being passed a new Map instance. Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
KAFKA-1496 Using batch message in sync producer only sends the first message if we use a Scala Stream as the argument; reviewed by Neha Narkhede,1
"MINOR: Check invalid bootstrap-server, alter option and config flags before checking for the required --partitions flag (#6786)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-4557; Handle Producer.send correctly in expiry callbacksWhen iterating deque for expiring record batches, delay theinvocation of the callback and deallocation until iteration iscomplete since callbacks invoked during expiry may send morerecords, modifying the deque, resulting in aConcurrentModificationException in the iterator.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2449 from rajinisivaram/KAFKA-4557",5
MINOR: Fix flaky test shouldQueryOnlyActivePartitionStoresByDefault (#9681)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
KAFKA-4728; KafkaConsumer#commitSync should copy its inputAuthor: Jan Lukavsky <jan.lukavsky@o2.cz>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2491 from je-ik/KAFKA-4728,5
"KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [part 3] (#5052)* KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [part 3]* Refactor:  - KStreamWindowReduceTest  - KTableMapKeysTest  - SessionWindowedKStreamImplTest  - TimeWindowedKStreamImplTest* Remove unnecessary @SuppressWarnings(unchecked)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-2112; make overflowWheel volatile; patched by Yasuhiro Matsuda; reviewed by Jun Rao,1
MINOR: Streams docs fixes (#9308)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
KAFKA-10835: Replace Runnable and Callable overrides with lambdas in Connect (#9867)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
"MINOR: Describe topics should describe, not deleteAuthor: dan norwood <norwood@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2952 from norwood/describe-not-delete",4
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunk,1
MINOR: Put state args in correct order named repartition test (#6114)Another system test that needs to be updated with states in the correct orderReviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-2400: Expose heartbeat interval in KafkaConsumer configurationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #116 from hachikuji/KAFKA-2400 and squashes the following commits:3c1b1dd [Jason Gustafson] KAFKA-2400; expose heartbeat interval in KafkaConsumer configuration,5
"KAFKA-3856; Cleanup Kafka Stream builder API (KIP-120)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bbejeck@gmail.com>Closes #2301 from mjsax/kafka-3856-topology-builder-API",2
"HOTFIX: Set session timeout and heartbeat interval to default to decrease flakiness (#9087)Set session timeout and heartbeat interval to default for RestoreIntegrationTestReviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12400: Upgrade jetty to fix CVE-2020-27223Here is the fix. The reason of [CVE-2020-27223](https://nvd.nist.gov/vuln/detail/CVE-2020-27223) was DOS vulnerability for Quoted Quality CSV headers and [patched in 9.4.37.v20210219](https://github.com/eclipse/jetty.project/security/advisories/GHSA-m394-8rww-3jr7).This PR updates Jetty dependency into the following version, 9.4.38.v20210224.Author: Lee Dongjin <dongjin@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #10245 from dongjinleekr/feature/KAFKA-12400",5
MINOR: Update Scala to 2.13.5 (#10169)This includes a fix from Chia-Ping that removes tupleallocations when `Map.forKeyValue` is used(https://github.com/scala/scala/pull/9425) and supportfor JDK 16.Release notes:https://github.com/scala/scala/releases/tag/v2.13.5Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
MINOR: increase timeouts for KafkaStreamsTest (#6178)Reviewer: Arjun Satish <arjun@confluent.io>,5
"MINOR: remove ignore annotations in Streams EOS integration testAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Apurva Mehta <apurva@confluent.io>Closes #3251 from guozhangwang/KMinor-remove-ignored-streams-integration-test",3
"KAFKA-5660 Don't throw TopologyBuilderException during runtime (#4645)Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Include connector name in error message (#9599)Reviewers: Randall Hauch <rhauch@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",0
KAFKA-2128 kafka.Kafka should return non-zero exit code when caught exception; reviewed by Neha,5
"KAFKA-13017: Remove excessive logging for sink task deserialization errors (#10945)[Jira](https://issues.apache.org/jira/browse/KAFKA-13017)Reverts https://github.com/apache/kafka/pull/7496, which added `ERROR`-level logging for deserialization errors in sink tasks even when connectors had logging for these errors disabled.No information is lost by this change that cannot be retained in an opt-in fashion by setting `errors.log.enable` and `errors.log.include.messages` to `true` in a connector config.Reviewers: Arjun Satish <arjun@confluent.io>, Tom Bentley <tbentley@redhat.com>",5
"MINOR: Java8 cleanup (#6598)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-6024; Move arg validation in KafkaConsumer ahead of `acquireAndEnsureOpen`  (#4617),5
MINOR: fix syntax error in upgrade_test.py (#10210)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
kafka-2043; CompressionType is passed in each RecordAccumulator append; patched by Grant Henke; reviewed by Jun Rao,4
KAFKA-3123; Ensure cleaning is resumed if truncateTo throwsAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3296 from mimaison/KAFKA-3123,1
"KAFKA-2122 Remove controller.message.queue.size Config; reviewed by Neha Narkhede, Jun Rao, Onur",5
"MINOR: Fix encoder config to make DynamicBrokerReconfigurationTest stable (#4764)DynamicBrokerReconfigurationTest currently assumes that passwords encoded with one secret will fail with an exception if decoded with another secret and configures an old.secret in setUp. This could potentially cause test failures if a password was incorrectly decoded with the wrong secret, since the test writes passwords encoded with the new secret directly to ZooKeeper. Since old.secret is only used in one test for verifying secret rotation, this config can be moved to that test to avoid transient failures.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"MINOR: Remove version in the uses pageThis is contributed by Hao Chen.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3366 from guozhangwang/KMinor-fix-streams-link-in-uses",2
"KAFKA-5566; fix unit test shouldAllowToQueryAfterThreadDiedEnsure only one thread dies, not both.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3500 from enothereska/hotfix-queryable-state",0
KAFKA-5180; Fix transient failure in ControllerIntegrationTest.testControllerMoveIncrementsControllerEpochThe tests previously ignored the fact that the controller does not atomicallycreate the /controller znode and create/increment the /controller_epoch znode.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3038 from onurkaraman/KAFKA-5180,2
kafka-1084; Validate properties for custom serializers; patched by Francois Saint-Jacquese; reviewed by Jun Rao,5
MINOR: update comment in LocalLog.replaceSegments() (#12054)Reviewers: Luke Chen <showuon@gmail.com>,2
"KAFKA-10049: Fixed FKJ bug where wrapped serdes are set incorrectly when using default StreamsConfig serdes (#8764)Bug Details:Mistakenly setting the value serde to the key serde for an internal wrapped serde in the FKJ workflow.Testing:Modified the existing test to reproduce the issue, then verified that the test passes.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",4
MINOR: remove `checksumOrNull` and `isValid` from Record (#10498)1. rewrite the checksum of DumpLogSegments2. remove checksumOrNull and isValid from RecordReviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-6530: Use actual first offset of message set when rolling log segment (#4660)Use the exact first offset of message set when rolling log segment. This is possible to do for message format V2 and beyond without any performance penalty, because we have the first offset stored in the header. This augments the fix made in KAFKA-4451 to avoid using the heuristic for V2 and beyond messages.Added unit tests to simulate cases where segment needs to roll because of overflow in index offsets. Verified that the new segment created in these cases uses the first offset, instead of the heuristic in use previously.",1
"MINOR: Eliminate unnecessary map operations in RecordAccumulator.isMuted (#7193)Avoids calling both `containsKey` and `get` from isMuted, when only a single get is necessary.Also avoid calling `remove` unless necessary. This could be a reduction of map operationsfrom 3 to 1. isMuted showed up as a hotspot in profiling when using the producer with high numbers of partitions.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-1499; Trivial follow-up (fix comments and whitespace),0
KAFKA-3864: make field.get return field's default value when neededAnd not the containing struct's default value.The contribution is my original work and that I license the work to the project under the project's open source license.ewencpAuthor: Rollulus <roelboel@xs4all.nl>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1528 from rollulus/kafka-3864,5
MINOR: Move Murmur3 to Streams,4
KAFKA-1199 Add a reduced access log level; reviewed by Guozhang Wang and Jun Rao,2
KAFKA-1178 Replica fetcher thread dies while becoming follower; reviewed by Jun Rao and Guozhang Wang,5
"KAFKA-7536: Initialize TopologyTestDriver with non-null topic (#5923)In TopologyTestDriver constructor set non-null topic; and in unit test intentionally turn on caching to verify this case.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10083: fix failed testReassignmentWithRandomSubscriptionsAndChanges tests (#8786)Minimum fix needed to stop this test failing and unblock othersCo-authored-by: Luke Chen <showuon@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-8710; Allow transactional producers to bump producer epoch [KIP-360] (#7115)This patch implements the broker-side changes for KIP-360. It adds two new fields to InitProducerId: lastEpoch and producerId. Passing these values allows the TransactionCoordinator to safely bump a producer's epoch after some failures (such as UNKNOWN_PRODUCER_ID and INVALID_PRODUCER_ID_MAPPING). When a producer calls InitProducerId after a failure, the coordinator first checks the producer ID from the request to make sure no other producer has been started using the same transactional ID. If it is safe to continue, the coordinator checks the epoch from the request; if it matches the existing epoch, the epoch is bumped and the producer can safely continue. If it matches the previous epoch, the the current epoch is returned without bumping. Otherwise, the producer is fenced.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-2554: change 0.8.3 to 0.9.0 in ApiVersion and other filesUpdated the version from 0.8.3 to 0.9.0. in ApiVersion.  Also updated in gradle.propeties.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #237 from omkreddy/KAFKA-2554",5
KAFKA-489 Add metrics collection and graphs to the system test framework; patched by Neha Narkhede; reviewed by Jun Rao and John Funggit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1378666 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-2656; Remove hardcoded default key and truststoresRemoved default hardcoded keystore and truststore in /tmp so that default JVM keystore/truststore may be used when keystore/truststore is not specified in Kafka server or client propertiesAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #312 from rajinisivaram/KAFKA-2656",5
"KAFKA-9788; Use distinct names for transaction and group load time sensors (#8784)Sensor objects are stored in the Kafka metrics registry and keyed by name. If a new sensor is created with the same name as an existing one, the existing one is returned rather than a new object being created. The partition load time sensors for the transaction and group coordinators used the same name, so data recorded to either was stored in the same object. This meant that the metrics values for both metrics were identical and consisted of the combined data. This patch changes the names to be distinct so that the data will be stored in separate Sensor objects.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-10066: TestOutputTopic should pass record headers into deserializers (#8759)Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-9885; Evict last members of a group when the maximum allowed is reached (#8525)This PR updates the algorithm which limits the number of members within a group (`group.max.size`) to fix the following two issues:1. As described in KAFKA-9885, we found out that multiple members of a group can be evicted if the leader of the consumer offset partition changes before the group is persisted. This happens because the current eviction logic always evict the first member rejoining the group.2. We also found out that dynamic members, when required to have a known member id, are not always limited. The caveat is that the current logic only considers unknown members and uses the group size, which does not include the so called pending members, to accept or reject a member. In this case, when they rejoins, they are not unknown member anymore and thus could bypass the limit. See `testDynamicMembersJoinGroupWithMaxSizeAndRequiredKnownMember` for the whole scenario.This PR changes the logic to address the above two issues and extends the tests coverage to cover all the member types.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-141 Follow up patch to fix the cpp files; patched by Lorenzo, nehanarkhede; reviewed by junrao, jjkoshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1182158 13f79535-47bb-0310-9956-ffa450edef68",1
"MINOR: updates docs for KIP-358 (#5796)Reviewers: Guozhang Wang <guozhang@confluent.io>, Jim Galasyn <jim.galasyn@confluent.io>",5
"KAFKA-6376; refactor skip metrics in Kafka Streams* unify skipped records metering* log warnings when things get skipped* tighten up metrics usage a bit### Testing strategy:Unit testing of the metrics and the logs should be sufficient.Author: John Roesler <john@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4812 from vvcephei/kip-274-streams-skip-metrics",5
KAFKA-9632; Fix MockScheduler synchronization for safe use in Log/Partition tests (#8209)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"kafka-2168; New consumer poll() can block other calls like position(), commit(), and close() indefinitely; patched by Jason Gustafson; reviewed by Jay Kreps, Ewen Cheslack-Postava, Guozhang Wang and Jun Rao",5
"KAFKA-2795: fix potential NPE in GroupMetadataManager.addGroupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Onur Karaman, Guozhang WangCloses #488 from hachikuji/KAFKA-2795",5
"MINOR: Add toString to PartitionReassignment (#7579)This patch adds a `toString()` implementation to `PartitionReassignment`. It also makes the `ListPartitionReassignmentsResult` constructor use default access, which is the standard for the admin client *Result classes.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-4645: Improve test coverage of ProcessorTopologythe toString method prints the topology, but had no tests making sure it works and/or doesn't cause exceptionsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2444 from dguy/KAFKA-4645",1
"MINOR: Set session timeout back to 10s for Streams system tests (#11236)We increased the default session timeout to 30s in KIP-735:https://cwiki.apache.org/confluence/display/KAFKA/KIP-735%3A+Increase+default+consumer+session+timeoutSince then, we are observing sporadic system test failuresdue to rebalances taking longer than the test timeout.Rather than increase the test wait times, we can just overridethe session timeout to a value more appropriate in the testingdomain.Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",3
MINOR: Temporarily disable testLogStartOffsetCheckpointIt's failing often and it seems like there are multiplereasons. PR #4238 will re-enable it.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4262 from ijuma/temporarily-disable-test-log-start-offset-checkpoint,3
"KAFKA-4013; Include exception cause in SaslServerCallbackHandlerAuthor: Bryan Baugher <bryan.baugher@cerner.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>Closes #1695 from bbaugher/KAFKA-4013",1
MINOR: Fix typo in processor api developer guide (#12203)The reference to `changlogConfig` should be `changelogConfig`.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-6057: Users forget `--execute` in the offset reset tool (#4069)Add a small warning note when the user does not use the --execute flag.,1
"KAFKA-12874; Increase default consumer session timeout to 45s (#10803)This patch increases the default consumer session timeout to 45s as documented in KIP-735: https://cwiki.apache.org/confluence/display/KAFKA/KIP-735%3A+Increase+default+consumer+session+timeout.Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Reduce the log level when the peer isn't authenticated but is using SSLThe commit here changes the log level of a log message from WARN to DEBUG.As noted in the mail discussion here https://www.mail-archive.com/devkafka.apache.org/msg56035.html,in a pretty straightforward/typical and valid setup, the broker logs getflooded with the following message:[2016-09-02 08:07:13,773] WARN SSL peer is not authenticated, returning ANONYMOUS instead (org.apache.kafka.common.network.SslTransportLayer)Author: Jaikiran Pai <jaikiran.pai@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1825 from jaikiran/ssl-log-level",2
KAFKA-1200 inconsistent log levels when consumed offset is reset patch by Dima Pekar reviewed by Joe Stein,1
KAFKA-1185 Improve leader elector module to have a resign API; reviewed by Guozhang Wang and Jun Rao,1
MINOR: Kafka Streams code samples formating unification (#10651)Code samples are now unified and correctly formatted.Samples under Streams use consistently the prism library.Reviewers: Bruno Cadonna <cadonna@apache.org>,1
"MINOR: Add missing semicolon to example jaas configurationAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4101 from omkreddy/SCRAM-DOCS",2
"KAFKA-2246; Fix incorrect config ZK path.This bug was introduced while committing KAFKA-2205. Basically, the path for topic overrides was renamed to ""topic"" from ""topics"". However, this causes existing topic config overrides to break because they will not be read from ZK anymore since the path is different.https://reviews.apache.org/r/34554/Author: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Joel KoshyCloses #152 from auradkar/2446",2
KAFKA-10519; Add missing unit test for `VotedState` (#9337)Add a simple unit test for `VotedState`. Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
KAFKA-9319: Fix generation of CA certificate for system tests. (#8106)Newer versions of Java have added checks to ensure that trust anchors are CA certificates and contain proper extensions. This PR adds Basic Constraints extension with the CA field set to true for system tests.Reviewers: ajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: Use method handles instead of reflection for creating Snappy and LZ4 streams1. Use Initialization-on-demand holder idiom that relies on JVM lazy-loading instead of explicit initialization check.2. Method handles were designed to be faster than Core Reflection, particularly if the method handle can be stored in a static final field (the JVM can then optimise the call as if it was a regular method call). Since the code is of similar complexity (and simpler if we consider the whole PR), I am treating this as a clean-up instead of a performance improvement (which would require doing benchmarks).3. Remove unused `ByteBufferReceive`.4. I removed the snappy library from the classpath and verified that `CompressionTypeTest` (which uses LZ4) still passes. This shows that the right level of laziness is achieved even if we use one of the lazily loaded compression algorithms.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2740 from ijuma/use-method-handles-for-compressed-stream-supplier",0
MINOR: Remove unnecessary options in SCRAM test jaas configAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2353 from rajinisivaram/minor-scram,5
"Fill in the 2.8 release note for Authorizer (#9865)Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-6084: Propagate JSON parsing errors in ReassignPartitionsCommand (#4090)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"KAFKA-4451; Fix OffsetIndex overflow when replicating a highly compacted topic. OffsetIndex provides checks for overflow, used when deciding to roll a LogSegmentFix OffsetIndex overflow when replicating a highly compacted topic.https://issues.apache.org/jira/browse/KAFKA-4451Author: Michael Schiff <schiff.michael@gmail.com>Author: Michael Schiff <michael.schiff@tubemogul.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2210 from michaelschiff/bug/4451",0
"KAFKA-6628: RocksDBSegmentedBytesStoreTest does not cover time window serdes (#4836)Updated RocksDBSegmentedBytesStoreTest class to include time window serdes.Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Fix KStreamKTableJoinTest and StreamTaskTest (#9357)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Fixed deserialization.exception.handler default value of config-streams (#4914)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-3328: SimpleAclAuthorizer can lose ACLs with frequent add/remov……e callsChanges the SimpleAclAuthorizer to:- Track and utilize the zookeeper version when updating zookeeper to prevent data loss in the case of stale reads and race conditions- Update local cache when modifying ACLs- Add debug loggingAuthor: Grant Henke <granthenke@gmail.com>Author: Grant Henke <granthenke@users.noreply.github.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Flavio Junqueira, Jun Rao, Ismael Juma, Gwen ShapiraCloses #1006 from granthenke/simple-authorizer-fix",0
MINOR: Remove dead codeAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4087 from ijuma/remove-dead-code,4
"KAFKA-12949; Match null when eventQueue poll hits eventTimeoutMs in `TestRaftServer` (#10883)This patch fixes a match error in `TestRaftServer` which causes the process to crash. We should match against `null` to handle the case of a timeout when polling for events.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@conflluent.io>",5
KAFKA-2819; catch NoSuchElementException in ConsoleConsumerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #516 from guozhangwang/K2819,5
"MINOR: Avoid unnecessary collection copy in MetadataCache (#6397)`map` was being used to convert `Iterable[Integer]` to `Iterable[Int`]. Thatoperation represented 11% of total CPU time measured under load for us.We also expect a positive impact on GC.Reviewers: Joel Koshy <jjkoshy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-9335: Fix StreamPartitionAssignor regression in repartition topics counts (#7904)This PR fixes the regression introduced in 2.4 from 2 refactoring PRs:#7249#7419The bug was introduced by having a logical path leading numPartitionsCandidate to be 0, which is assigned to numPartitions and later being checked by setNumPartitions. In the subsequent check we will throw illegal argument if the numPartitions is 0.This bug is both impacting new 2.4 application and upgrades to 2.4 in certain types of topology. The example in original JIRA was imported as a new integration test to guard against such regression. We also verify that without the bug fix application will still fail by running this integration test.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-7652: Restrict range of fetch/findSessions in cache (#6448)Reduce the total key space cache iterators have to search for segmented byte stores by wrapping several single-segment iterators.Summary of Benchmarking Results (# records processed as primary indicator)Session Store:Only single-key findSessions seems to benefit (~4x improvement) due to conservative scanning of potentially variable-sized keys in key-range findSessions. Could get improvement from key-range findSessions as well if we can tell when/if keys are a fixed size, or pending an efficient custom comparator API from RocksDBWindow Store:Both single and multi-key fetch saw some improvement; this depended on the size of the time-range in the fetch (in the DSL this would be window size) relative to the retention period. Performance benefits from this patch when the fetch spans multiple segments; hence the larger the time range being searched, the better this will do.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",1
MINOR: update tutorial doc to match ak-siteAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3847 from dguy/minor-doc-update,5
MINOR: Add ableegoldman and cadonna to asf whitelist (#9171)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-13281: allow #removeNamedTopology while in the CREATED state (#11810)We should be able to change the topologies while still in the CREATED state. We already allow adding them, but this should include removing them as wellReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",4
"KAFKA-3787; Preserve the message timestamp in mirror makerThe timestamp of messages consumed by mirror maker is not preserved after sending to target cluster. The correct behavior is to keep create timestamp the same in both source and target clusters.Author: Tao Xiao <xiaotao183@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1466 from xiaotao183/KAFKA-3787",1
"MINOR: Clean up group instance id handling in `GroupCoordinator` (#9958)This is a continuation of a refactor started in #9952. The logic in `GroupCoordinator` is loose and inconsistent in the handling of the `groupInstanceId`. In some cases, such as in the JoinGroup hander, we verify that the groupInstanceId from the request is mapped to the memberId precisely. In other cases, such as Heartbeat, we check the mapping, but only to validate fencing. The patch consolidates the member validation so that all handlers follow the same logic. A second problem is that many of the APIs where a `groupInstanceId` is expected use optional arguments. For example:```scaladef hasStaticMember(groupInstanceId: Option[String]): Booleandef addStaticMember(groupInstanceId: Option[String], newMemberId: String): Unit```If `groupInstanceId` is `None`, then `hasStaticMember` is guaranteed to return `false` while `addStaticMember` raises an `IllegalStateException`. So the APIs suggest a generality which is not supported and does not make sense.Finally,  the patch attempts to introduce stronger internal  invariants inside `GroupMetadata`. Currently it is possible for an inconsistent `groupInstanceId` to `memberId` mapping to exist because we expose separate APIs to modify `members` and `staticMembers`. We rely on the caller to ensure this doesn't happen.  Similarly, it is possible for a member to be in the `pendingMembers` set as well as the stable `members` map. The patch fixes this by consolidating the paths to addition and removal from these collections and adding assertions to ensure that invariants are maintained. Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-4623; Default unclean.leader.election.enabled to false (KIP-106)Author: sharad.develop <sharad.develop@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2625 from sharad-develop/KAFKA-4623,4
"MINOR: update VerifiableProducer to send keys if configured and removed StreamsRepeatingKeyProducerService (#4841)This PR does the following:* Remove the StreamsRepeatingIntegerKeyProducerService and the associated Java class* Add a parameter to VerifiableProducer.java to enable sending keys when specified* Update the corresponding Python file verifiable_producer.py to support the new parameter.Reviewers: Matthias J Sax <matthias@confluentio>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4117: Stream partitionassignro cleanup1. Create a new `ClientMetadata` to collapse `Set<String> consumerMemberIds`, `ClientState<TaskId> state`, and `HostInfo hostInfo`.2. Stop reusing `stateChangelogTopicToTaskIds` and `internalSourceTopicToTaskIds` to access the (sub-)topology's internal repartition and changelog topics for clarity; also use the source topics num.partitions to set the num.partitions for repartition topics, and clarify to NOT have cycles since otherwise the while loop will fail.3. `ensure-copartition` at the end to modify the number of partitions for repartition topics if necessary to be equal to other co-partition topics.4. Refactor `ClientState` as well and update the logic of `TaskAssignor` for clarity as well.5. Change default `clientId` from `applicationId-suffix` to `applicationId-processId` where `processId` is an UUID to avoid conflicts of clientIds that are from different JVMs, and hence conflicts in metrics.6. Enforce `assignment` partitions to have the same size, and hence 1-1 mapping to `activeTask` taskIds.7. Remove the `AssignmentSupplier` class by always construct the `partitionsByHostState` before assigning tasks to consumers within a client.8. Remove all unnecessary member variables in `StreamPartitionAssignor`.9. Some other minor fixes on unit tests, e.g. remove `test only` functions with java field reflection.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Xavier Léauté, Matthias J. Sax, Eno Thereska, Jason GustafsonCloses #2012 from guozhangwang/K4117-stream-partitionassignro-cleanup",4
MINOR: fix JavaDoc (#9217)Reviewer: John Roesler <john@confluent.io>,5
"KAFKA-6386: Use Properties instead of StreamsConfig in KafkaStreams constructorThis pull request targets https://issues.apache.org/jira/browse/KAFKA-6386The minor fix to deprecate usage of `StreamsConfig` in favor of `java.util.Properties`.I created separate public constructors using `Properties` in order to replace the old ones,and prioritize new functions in the `KafkaStreams.java` file.Since this is my first time doing open source contribution, I'm very happy to getany comment or pointer to be more professional and get better next time, thank you Guozhang guozhangwang and Liquan Ishiihara!testing strategy: existing unit test should be suffice to cover this change.Author: cs427fa16staff <bchen11@outlook.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>Closes #4354 from abbccdda/startergithub comments",5
"KAFKA-6145: KIP-441 Move tasks with caught-up destination clients right away (#8425)Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
KAFKA-3324; NullPointerException in StreamPartitionAssignorAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1001 from miguno/KAFKA-3324,5
KAFKA-10852: AlterIsr should not be throttled (#9747)Set it as a cluster action and update the handler in KafkaApis. We keep the `throttleTimeMs` fieldsince we intend to enable throttling in the future (especially relevant when we switch to thebuilt-in quorum mode).Reviewers: David Arthur <mumrah@gmail.com>,0
"KAFKA-2236; Offset request reply racing with segment rollingAuthor: William Thurston <wthurston@linkedin.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma, Guozhang WangCloses #1318 from ijuma/KAFKA-2236-offset-request-reply-segment-rolling-race",1
"KAFKA-4523; Fix crash during shutdown due to group coordinator attempting to write to a closed logShut down the group coordinator before shutting down the log manager toensure that any delayed operations are completed before the logs are closed.Author: steve <sniemitz@twitter.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2311 from steveniemitz/KAFKA-4523",5
"KAFKA-3598: Improve JavaDoc of public APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Guozhang WangCloses #1250 from mjsax/JavaDoc-publicAPI",2
KAFKA-1009 DumpLogSegments tool should return error on non-existing files; reviewed by Neha Narkhede,2
"KAFKA-10357: Add missing repartition topic validation (#10305)Reviewers: Rohan Desai <rohan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1291 Add wrapper scripts and usage information to each command.,5
MINOR: Improve shutdown sequenceAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3030 from ijuma/improve-shutdown-sequence,1
"KAFKA-10539: Convert KStreamImpl joins to new PAPI (#11356)Part of the migration to new Processor API, this PR converts KStream to KStream joins.Depends #11315Reviewers: John Roesler <vvcephei@apache.org>",1
MINOR: Refer consistently to server.properties in security docsAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3788 from omkreddy/RULE-DOC,2
"KAFKA-8449: Restart tasks on reconfiguration under incremental cooperative rebalancing (#6850)Restart task on reconfiguration under incremental cooperative rebalancing, and keep execution paths separate for config updates between eager and cooperative. Include the group generation in the log message when the worker receives its assignment.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"kafka-2226; NullPointerException in TestPurgatoryPerformance; patched by Yasuhiro Matsuda; reviewed by Onur Karaman, Guozhang Wang and Jun Rao",3
"KAFKA-4671: Fix Streams window retention policyAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2401 from mjsax/kafka-4671-window-retention-policy",5
MINOR: Add missing Alter Operation to Topic supported operations list in AclCommand- Update the AclCommandTestAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #6263 from omkreddy/aclcommand,3
KAFKA-12202 Migrate connect:mirror module to JUnit 5 (#9894)1. Replace junit 4 APIs by junit 52. Remove the dependencies of junit 4 from `EmbeddedKafkaCluster`Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"HOTFIX: Generate javadocs for all Streams packages with the exception of internalsAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Eno Thereska, Gwen ShapiraCloses #1013 from miguno/trunk-streams-javadocs-fixes",2
trival change to review unneeded error logging since an exception is already thrown to the caller,2
"MINOR: Fix typo and rephrase content in ops docs (#8581)1. fix typo: `atleast` -> `at least`2. add missing `--` from `--bootstrap-servers` argument to be consistent3. rephrase a sentence, to make it more clear:before: `LinkedIn is currently running JDK 1.8 u5 (looking to upgrade to a newer version) with the G1 collector`It will misguide the users to use JDK 1.8 u5, while the JDK 1.8 u251 is already released, which will include many important bug fixes. I did some rephrase as below:after: `At the time this is written, LinkedIn is running JDK 1.8 u5 (looking to upgrade to a newer version) with the G1 collector`Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-6802: Improved logging for missing topics during task assignment (#4891)If users don't create all topics before starting a streams application, they could get unexpected results. For example, sharing a state store between sub-topologies where one input topic is not created ahead time results in log message that that ""Partition X is not assigned to any tasks"" does not give any clues as to how this could have occurred.Also, this PR changes the log level from INFO to WARN when metadata does not have partitions for a given topic.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13559: Fix issue where responses intermittently takes 300+ ms to respond, even when the server is idle. (#12416)Ensures that SSL buffered data is processed by server immediately on the next poll when channel is unmuted after processing previous request. Poll timeout is reset to zero for this case to avoid 300ms delay in poll() if no new data arrives on the sockets.Reviewers: David Mao <dmao@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
kafka-1325; Fix inconsistent per topic log configs; patched by Manikumar Reddy; reviewed by Jun Rao,5
MINOR: Change SaslSetup workDir to be under the build folderMoves test output from the project files and allows `gradle clean` to clean up the output.Author: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #664 from granthenke/target,1
"KAFKA-7080 and KAFKA-7222: Cleanup overlapping KIP changes (#5804)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
HOTFIX: Controller topic deletion should be atomic (#10264)Topic deletions should be atomic. This fixes a build error caused by merging of both https://github.com/apache/kafka/pull/10253 and https://github.com/apache/kafka/pull/10184 at about the same time. Reviewers: David Arthur <mumrah@gmail.com>,1
"KAFKA-10774; Admin API for Describe topic using topic IDs (#9769)Reviewers: Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Satish Duggana <satishd@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-1471 Add producer unit tests for LZ4 and LZ4HC compression codecs; patched by James Oliver; reviewed by Neha Narkhede,3
KAFKA-5768; Upgrade to ducktape 0.7.1Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3721 from cmccabe/KAFKA-5768,5
"KAFKA-3045; ZkNodeChangeNotificationListener shouldn't log InterruptedException as errorAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #731 from lindong28/KAFKA-3045",0
kafka-856; Correlation id for OffsetFetch request (#2) always responds with 0; patched by Milosz Tanski; reviewed by Jun Rao,1
"MINOR: Added simple streams benchmark to system testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Geoff Anderson, Guozhang Wang, Ismael JumaCloses #1621 from enothereska/simple-benchmark-streams-system-tests",5
MINOR: Update docs wrt topic deletion being enabled by defaultAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3835 from omkreddy/update-delete-topic-doc,5
"KAFKA-9750; Fix race condition with log dir reassign completion (#8412)There is a race on receiving a LeaderAndIsr request for a replica with an active log dir reassignment. If the reassignment completes just before the LeaderAndIsr handler updates epoch information, it can lead to an illegal state error since no future log dir exists. This patch fixes the problem by ensuring that the future log dir exists when the fetcher is started. Removal cannot happen concurrently because it requires access the same partition state lock.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>Co-authored-by: Chia-Ping Tsai <chia7712@gmail.com>",1
MINOR: the broker should use metadata.log.max.record.bytes.between.snapshots (#10990)The broker should trigger a snapshot oncemetadata.log.max.record.bytes.between.snapshots has been exceeded.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13128: extract retry checker and update with retriable exception causing flaky StoreQueryIntegrationTest (#11275)Add a new case to the list of possible retriable exceptions for the flaky tests to take care of threads starting upReviewers: Leah Thomas <lthomas@confluent.io>, Anna Sophie Blee-Goldman",5
"MINOR: Murmur3 Hash with Guava dependencyPart of supporting KIP-213 ( https://cwiki.apache.org/confluence/display/KAFKA/KIP-213+Support+non-key+joining+in+KTable ). Murmur3 hash is used as a hashing mechanism in KIP-213 for the large range of uniqueness. The Murmur3 class and tests are ported directly from Apache Hive, with no alterations to the code or dependencies.Author: Adam Bellemare <adam.bellemare@wishabi.com>Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #7271 from bellemare/murmur3hash",1
"KAFKA-9235; Ensure transaction coordinator is stopped after replica deletion (#7963)During a reassignment, it can happen that the current leader of a partition is demoted and removed from the replica set at the same time. In this case, we rely on the StopReplica request in order to stop replica fetchers and to clear the group coordinator cache. This patch adds similar logic to ensure that the transaction coordinator state cache also gets cleared.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-7737; Use single path in producer for initializing the producerId (#7920)Previously the idempotent producer and transactional producer use separate logic when initializing the producerId. This patch consolidates the two paths. We also do some cleanup in `TransactionManagerTest` to eliminate brittle expectations on `Sender`.Reviewers: Bob Barrett <bob.barrett@confluent.io>, Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Annotate KafkaAdminClientTest.testAlterClientQuotas() with @TestKafkaAdminClientTest.testAlterClientQuotas() is uncalled. It is clearly intended to be a test method, but lacks `Test`.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Gwen Shapira, Brian ByrneCloses #8456 from tombentley/MINOR-annotate-test-method",3
MINOR: remove unnecessary nulllity check (#7282)Minor code enhancement: remove unnecessary check of nullity.Reviewers: Bill Bejeck <bbejeck@gmail.com>,4
MINOR: Factor `RaftManager` out of `TestRaftServer` (#9839)This patch factors out a `RaftManager` class from `TestRaftServer` which will be needed when we integrate this layer into the server. This class encapsulates the logic to build `KafkaRaftClient` as well as its IO thread. Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-4441; Monitoring incorrect during topic creation and deletionOfflinePartitionsCount PreferredReplicaImbalanceCount metrics check fortopic being deletedAdded integration test which polls the metrics while topics are beingcreated and deletedDeveloped with mimaisonAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2325 from edoardocomar/KAFKA-4441",2
"KAFKA-2330: Vagrantfile sets global configs instead of per-provider override configs; patched by Ewen Cheslack-Postava, reviewed by Geoff Anderson and Gwen Shapira",5
MINOR: Update version for doc to 2.0.0 (#5262)Reviewers: Damian Guy <damian.guy@gmail.com>,2
"KAFKA-8335; Clean empty batches when sequence numbers are reused (#6715)The log cleaner attempts to preserve the last entry for each producerId in order to ensure that sequence/epoch state is not lost. The current validation checks only the last sequence number for each producerId in order to decide whether a batch should be retained. There are two problems with this:1. Sequence numbers are not unique alone. It is the tuple of sequence number and epoch which is uniquely defined.2. The group coordinator always writes batches beginning with sequence number 0, which means there could be many batches which have the same sequence number.The complete fix for the second issue would probably add proper sequence number bookkeeping in the coordinator. For now, we have left the coordinator implementation unchanged and changed the cleaner logic to use the last offset written by a producer instead of the last sequence number. Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: MiniTrogdorCluster mutates objects from other threads (#11710)MiniTrogdorCluster spins up agents from a different thread when scheduling them, but does not use volatiles in these objects. It's not clear that the updated fields are visible.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Kvicii <Karonazaba@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: Typo fix in docs opsAuthor: Thanasis Katsadas <thanasis00@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1552 from thanasis00/trunk,1
"KAFKA-10326: Both serializer and deserializer should be able to see generated ID (#9102)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Add sentence to command line documentation of producer performance tool on how to disable throttling. (#6205),2
"MINOR: Fix file source task configs in system tests.Another fall-through of `headers.converter` and `batch.size` properties. Here in `FileStreamSourceConnector` testsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #4590 from kkonstantine/MINOR-Fix-file-source-task-config-in-system-tests",5
"KAFKA-9760: Add KIP-447 protocol change to upgrade notes (#8350)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-93 | Change and add ASF source header to follow standard ASF source header (http://www.apache.org/legal/src-headers.html).git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156232 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: complete built-in stream aggregate functionsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #787 from guozhangwang/KBuiltInAgg,1
"MINOR: Time and log producer state recovery phases (#10241)During a slow log recovery it's easy to think that loading .snapshot files is a multi-second process. Often it isn't the snapshot loading that takes most of the time, rather it's the time taken to further rebuild the producer state from segment files. This patch times both snapshot load and segment recovery phases to better indicate what is taking time.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-8298: Fix possible concurrent modification exception (#6643)When processing multiple key-changing operations during the optimization phase a ConcurrentModificationException is possible.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"KAFKA-7316: Fix Streams Scala filter recursive call #5538Due to lack of conversion to kstream Predicate, existing filter method in KTable.scala would result in StackOverflowError.This PR fixes the bug and adds testing for it.Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-4641: Add more unit test for stream thread (#4531)Before the patch, jacoco coverage test:ElementMissed InstructionsCov.Missed BranchesCov.MissedCxtyMissedLinesMissedMethodsMissedClassesTotal3,386 of 22,17784%336 of 1,63979%3501,5895264,4511037681102StreamThread 77% 76%271024829913101After the patch:ElementMissed InstructionsCov.Missed BranchesCov.MissedCxtyMissedLinesMissedMethodsMissedClassesTotal3,329 of 22,18084%329 of 1,63979%3451,5905164,4521027691102StreamThread 81% 80%231033930013201Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian@confluent.io>",5
MINOR: increase timeout values in streams tests (#5461)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-6145: Encode task positions in SubscriptionInfo (#8121)* Replace Prev/Standby task lists with a representation of the current poasition  of all tasks, where each task is encoded as the sum of the positions of all the  changelogs in that task.* Only the protocol change is implemented, not actual positions, and the  assignor is updated to translate the new protocol back to lists of Prev/Standby  tasks so that the current assignment protocol still functions without modification.Implements: KIP-441Reviewers: John Roesler <vvcephei@apache.org>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-8065: restore original input record timestamp in forward() (#6393)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-534 remove client library directorygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1390786 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-5823: Extend upgrade section for KIP-120Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Sharon Liu <sharonliu.cup@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3787 from mjsax/kafka-5823-kip120-docs",2
KAFKA-42 Cluster expansion feature; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396713 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: support retrieving cluster_id in system testsewencp would be great to cherry-pick this back into 0.11.x if possibleAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3645 from xvrl/system-test-cluster-id,5
"KAFKA-8837: KafkaMetricReporterClusterIdTest may not shutdown ZooKeeperTestHarness (#7255)- Call `assertNoNonDaemonThreads` in test method instead of tear down methodto avoid situation where parent's class tear down is not invoked.- Pass the thread prefix in tests that call `assertNoNonDaemonThreads` so that itworks correctly.- Rename `verifyNonDaemonThreadsStatus` to `assertNoNonDaemonThreads` tomake it clear that it may throw.Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-9835; Protect `FileRecords.slice` from concurrent write (#8451)A read from the end of the log interleaved with a concurrent write can result in reading data above the expected read limit. In particular, this would allow a read above the high watermark. The root of the problem is consecutive calls to `sizeInBytes` in `FileRecords.slice` which do not account for an increase in size due to a concurrent write. This patch fixes the problem by using a single call to `sizeInBytes` and caching the result.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-1134 onControllerFailover function should be synchronized with other functions; reviewed by Neha Narkhede,1
"MINOR: Use new-consumer config in MirrorMaker docMirrormaker was updated to default to the new consumer in 3db752a565071c78e4b11eaafa739844fa785b04Old consumer calls the param `auto.commit.enable`, new consumer calls it `enable.auto.commit`. So I updated the docstring to use the new consumer name for the param.Author: Jeff Widman <jeff@jeffwidman.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2393 from jeffwidman/patch-1",2
"KAFKA-10199: Separate state updater from old restore (#12583)Separates the code path for the new state updater fromthe code path of the old restoration.Ensures that with the state updater tasks are processedbefore all tasks are running.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io",5
MINOR: Upgrade Jackson to 2.9.6Upgrade strongly recommended due to security fixes forjackson-databind (same as ones in 2.7.9.4 and 2.8.11.2).Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Add a few missing entity type tags (#9828)This patch adds a few missing ""entity type"" tags to the schema definitions of `OffsetDeleteRequest`, `OffsetDeleteResponse`, and `TxnOffsetCommitRequest`. Reviewers: David Arthur <mumrah@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-7523: Add ConnectedStoreProvider to Processor API (#6824)Implements KIP-401: - Add ConnectedStoreProvider interface - let Processor/[*]Transformer[*]Suppliers extend ConnectedStoreProvider - allows to add and connect state stores to processors/transformers implicitlyReviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-5735; KIP-190: Handle client-ids consistentlyDeveloped with edoardocomarAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Edoardo Comar <ecomar@uk.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3906 from mimaison/KAFKA-5735",5
"DOC: Documentation for Throttled ReplicationAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao, Gwen ShapiraCloses #2033 from benstopford/throttling-docs",2
"KAFKA-9524: increase retention time for window and grace periods longer than one day (#10091)Reviewers: Victoria Xia <victoria.xia@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
change whitelist config for mirroring; patched by Joel; KAFKA-103git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1158969 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-405 Improve high watermark maintenance to store high watermarks for all partitions in a single .highwatermark file; patched by Neha Narkhede; reviewed by Jay Kreps and Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1365841 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Fix javadoc typos in ConsumerRebalanceListenerAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1500 from vahidhashemian/typo07/fix_javadoc_typos_consumerrebalancelistener,2
"MINOR: Fix streams Scala peek recursive call (#5566)This PR fixes the previously recursive call of Streams Scala peekReviewers: Joan Goyeau <joan@goyeau.com>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-2687: Add support for ListGroups and DescribeGroup APIsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang, Jun RaoCloses #388 from hachikuji/K2687",5
KAFKA-5049; Chroot check should be done for each ZkUtils instanceAuthor: anukin <anukin2611@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2857 from anukin/KAFKA_5049_zkroot_check,2
kafka-938; High CPU usage when more or less idle; patched by Sam Meder; reviewed by Jun Rao,5
KAFKA-12963: Add processor name to error (#11262)This PR adds the processor name to the ClassCastException exception text in process()Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
KAFKA-5481: ListOffsetResponse isn't logged in the right way with trace level enabledAdded toString() method to ListOffsetResponse for loggingAuthor: ppatierno <ppatierno@live.com>Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3383 from ppatierno/kafka-5481,5
KAFKA-3723: Cannot change size of schema cache for JSON converterAuthor: Christian Posta <christian.posta@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1401 from christian-posta/ceposta-connect-class-cast-error,0
"KAFKA-12985: Upgrade jetty to 9.4.42 (#10919)* 9.4.41 announcement: https://www.eclipse.org/lists/jetty-announce/msg00156.html* 9.4.42 announcement: https://www.eclipse.org/lists/jetty-announce/msg00158.htmlReviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
"MINOR: remove no longer needed CommitTypeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #258 from hachikuji/delete-committype",4
"KAFKA-7466: Add IncrementalAlterConfigs API (KIP-339) (#6247)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-12880: Remove deprecated `Count` and `SampledTotal` in 3.0 (#10808)They were both deprecated in Apache Kafka 2.4 and it's a straightforward changeto use the non deprecated variants.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-12305: Fix Flatten SMT for array types (#10074)Reviewers: Nigel Liang <nigel@nigelliang.com>, Tom Bentley <tbentley@redhat.com>",0
KAFKA-2999: Errors enum should be a 1 to 1 mapping of error codes and…… exceptionsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #766 from granthenke/errors-map,0
"KAFKA-2514: change default JVM options in kafka-run-class.sh.GC is set to G1 collector.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #218 from omkreddy/KAFKA-2514",1
KAFKA-12509 Tighten up StateDirectory thread locking (#10418)Modified LockAndOwner class to have Thread reference instead of just nameReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,2
KAFKA-6870 Concurrency conflicts in SampledStat (#4985)Make `KafkaMetric.measurableValue` thread-safeReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: Fix build scala 2.12 build after KAFKA-10020 (#9245)Fixes a problem in which the Serdes class in the same package asthe tests (the old one) overshadows the one we explicitly imported(the new one), but only in Scala 2.12. Since users (hopefully) don'tput their classes in our packages, they won't face the same problem.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>, John Roesler <vvcephei@apache.org>",0
KAFKA-2114 Unable to change min.insync.replicas default; reviewed by Neha,4
"KAFKA-7421: Ensure Connect's PluginClassLoader and DelegatingClassLoader are truly parallel capable and resolve deadlock occurrences (#8259)* Adds SynchronizationTest class for concurrency testing of the classloading isolation mechanism* Adds a test which deterministically reproduced a deadlock between simultaneous upward (Plugin -> Delegating) & downward (Delegating -> Plugin) class loading operations.* Makes PluginClassLoader parallel capable, resolving the above deadlock by allowing multiple threads to concurrently use the PluginClassLoader.* Makes DelegatingClassLoader parallel capable to allow parallel loading of classes from the parent loader (usually the system class loader)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Tom Bentley <tbentley@redhat.com>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Use `EasyMock.newCapture` instead of deprecated `new Capture`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira, Ewen Cheslack-PostavaCloses #149 from ijuma/fix-easy-mock-deprecations",0
"KAFKA-9924: Add RocksDB metric num-entries-active-mem-table (#9177)* Add the first RocksDB metric that exposes a RocksDB property: num-entries-active-mem-table.* Add code StreamsMetricsImpl in support of exposing RocksDB properties* unit tests and intergration testsThis commit only contains one metric to keep the PR at a reasonable size.All other RocksDB metrics described in KIP-607 will be added in other PRs.Implements: KIP-607Reviewers: Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",1
"KAFKA-3483: Restructure ducktape tests to simplify running subsets of tests… testsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1162 from granthenke/ducktape-structure",5
"KAFKA-9353; Add groupInstanceId to DescribeGroup for better visibility (#7886)Kafka-8538(#6957) has already added `group.instance.id` to `MemberDescription` but didn't print it in the describe group output, so this patch adds the logic to do so.Before the change, the describe command prints as follows:```GROUP           CONSUMER-ID                                                  HOST            CLIENT-ID               #PARTITIONS     DemoConsumer    consumer-DemoConsumer-2-89251f12-f0ae-4dc1-a118-bda49f2a6e86 /127.0.0.1      consumer-DemoConsumer-2 0               DemoConsumer    consumer-DemoConsumer-1-72221c6b-f3d9-4c68-96db-ffffa12ddf93 /127.0.0.1      consumer-DemoConsumer-1 1               ```After the change, the describe command prints as follows:```GROUP           CONSUMER-ID                                    GROUP-INSTANCE-ID HOST            CLIENT-ID                       #PARTITIONS     DemoConsumer    groupIns2-f050379c-9c0d-433c-bbe0-44de6177b60d groupIns2         /127.0.0.1      consumer-DemoConsumer-groupIns2 0               DemoConsumer    groupIns1-44805ba9-ae6f-49d3-89af-44a4b95aff8d groupIns1         /127.0.0.1      consumer-DemoConsumer-groupIns1 1                        ```If all the `GROUP-INSTANCE-ID` is null, just as the previous:```GROUP           CONSUMER-ID                                                  HOST            CLIENT-ID               #PARTITIONS     DemoConsumer    consumer-DemoConsumer-2-89251f12-f0ae-4dc1-a118-bda49f2a6e86 /127.0.0.1      consumer-DemoConsumer-2 0               DemoConsumer    consumer-DemoConsumer-1-72221c6b-f3d9-4c68-96db-ffffa12ddf93 /127.0.0.1      consumer-DemoConsumer-1 1               ```Reviewers: Alice <WheresAlice@users.noreply.github.com>, Matthias J. Sax <matthias@confluent.io>, Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10000: Zombie fencing logic (#11779)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2
obsessive compulsive tag team: Replace tabs with spacespatch by jkreps; reviewed by cburroughs for KAFKA-114git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178670 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12338; Remove unused `MetadataParser` (#10793)`MetadataParser` is a duplication of `MetadataRecordSerde` and it's not used in any code, so we can remove it. It did, however, have some useful validations which have been moved into `MetadataRecordSerde`.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: ""partition"" typos and method doc arg fix (#11298)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",0
KAFKA-9379; Fix flaky test TopicCommandWithAdminClientTest.testCreateAlterTopicWithRackAware (#7917)Waits for topic metadata to be propagated to all brokers before performing operations on the topic.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: Fix setting of ACLs and ZK shutdown in test harnessesI found both issues while investigating the issue described in PR #1425.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #1455 from ijuma/fix-integration-test-harness-and-zk-test-harness",3
KAFKA-8523 Enabling InsertField transform to be used with tombstone events (#6914)* KAFKA-8523 Avoiding raw type usage* KAFKA-8523 Gracefully handling tombstone events in InsertField SMT,1
"KAFKA-10588; Rename kafka-console-consumer CLI command line arguments for KIP-629 (#11008)This patch marks --whitelist as deprecated argument and introduce --include for kafka-console-consumer as described in KIP-629: https://cwiki.apache.org/confluence/display/KAFKA/KIP-629%3A+Use+racially+neutral+terms+in+our+codebase.Reviewers: Xavier Léauté <xavier@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-14010: AlterPartition request won't retry when receiving retriable error (#12329)When submitting the AlterIsr request, we register a future listener to handle the response. When receiving retriable error, we expected the AlterIsr request will get retried. And then, we'll re-submit the request again.However, before the future listener got called, we didn't clear the `unsentIsrUpdates`, which causes we failed to ""enqueue"" the request because we thought there's an in-flight request. We use ""try/finally"" to make sure the unsentIsrUpdates got cleared, but it happened ""after"" we retry the requestReviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",5
"KAFKA-4927: Fix KStreamsTestDriver to not throw NPE when KStream.to() sinks are useda KStream.to() sink is also a topic... so the KStreamTestDriver to fetch it when requiredAuthor: Wim Van Leuven <wim.vanleuven@bigboards.io>Author: Wim Van Leuven <wim.vanleuven@highestpoint.biz>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2716 from wimvanleuven/KAFKA-4927",1
"KAFKA-4757; NetworkClient should log request details at trace level when a request is cancelled because of disconnectionAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Onur Karaman <okaraman@linkedin.com>, Apurva Mehta <apurva.1618@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #2563 from cmccabe/KAFKA-4757",2
MINOR: greatly improve test runtime by unblocking purgatory and quota manager threads (#11653)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-6054: Code cleanup to prepare the actual fix for an upgrade path (#4630)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-3678: Removed sleep from streams integration testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1439 from enothereska/KAFKA-3678-timeouts1,3
"MINOR: log and fail on missing task in Streams (#5655)Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-4831: Extract WindowedSerde to public APIs (#3307)Now that we have augmented WindowSerde with non-arg parameters, extract it out as part of the public APIs so that users who want to I/O windowed streams can use it. This is originally introduced by @vitaly-pushkarThis PR grows out to be a much larger one, as I found a few tech debts and bugs while working on it. Here is a summary of the PR:Public API changes (I will propose a KIP after a first round of reviews):Add TimeWindowedSerializer, TimeWindowedDeserializer, SessionWindowedSerializer, SessionWindowedDeserializer into o.a.k.streams.kstream. The serializers would implemented an internal WindowedSerializer interface for the serializeBaseKey function used in 3) below.Add WindowedSerdes into o.a.k.streams.kstream. The reason to now add them into o.a.k.clients's Serdes is that it then needs dependency of streams.Add ""default.windowed.key.serde.inner"" and ""default.windowed.value.serde.inner"" into StreamsConfig, used when ""default.key.serde"" is specified to use time or session windowed serde. Note this requires the serde class, not the type class.Consolidated serde format from multiple classes, including SessionKeySerde.java for session, and WindowStoreUtils for time window, into SessionKeySchema and WindowKeySchema.Bug fix: WindowedStreamPartitioner needs to consider both time window and session window serdes.Removed RocksDBWindowBytesStore etc optimization since after KIP-182 all the serde know happens on metered store, hence this optimization is not worth.Bug fix: for time window, the serdes used for store and the serdes used for piping (source and sink node) are different: the former needs to append sequence number but not for the later.Other minor cleanups: remove unnecessary throws, etc.Authors: Guozhang Wang <wangguoz@gmail.com>, Vitaly Pushkar <vitaly.pushkar@gmail.com>Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>, Xi Hu",5
"KAFKA-13591; Fix flaky test `ControllerIntegrationTest.testTopicIdCreatedOnUpgrade` (#11666)The issue is that when `zkClient.getTopicIdsForTopics(Set(tp.topic)).get(tp.topic)` is called after the new controller is brought up, there is not guarantee that the controller has already written the topic id to the topic znode.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Update Streams quickstart to create output topic with compaction enabledAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3949 from mjsax/minor-update-streams-quickstart",5
"HOTFIX: undo renaming of public part of Subtopology API (#10713)In #10676 we renamed the internal Subtopology class that implemented the TopologyDescription.Subtopology interface. By mistake, we also renamed the interface itself, which is a public API. This wasn't really the intended point of that PR, so rather than do a retroactive KIP, let's just reverse the renaming.Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8012; Ensure partitionStates have not been removed before truncating. (#6333)This patch fixes a regression in the replica fetcher which occurs when the replica fetcher manager simultaneously calls `removeFetcherForPartitions`, removing the corresponding partitionStates, while a replica fetcher thread attempts to truncate the same partition(s) in `truncateToHighWatermark`. This causes an NPE which causes the fetcher to crash.This change simply checks that the `partitionState` is not null first. Note that a similar guard exists in `truncateToEpochEndOffsets`.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-166 Add JMX perf tool.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1188288 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: improve logging (#11584)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-2143: fix replica offset truncate to beginning during leader migration.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Gwen Shapira, Guozhang WangCloses #129 from becketqin/KAFKA-2143",1
"KAFKA-9530; Fix flaky test `testDescribeGroupWithShortInitializationTimeout` (#8154)With a short timeout, a call in KafkaAdminClient may timeout and the client might disconnect. Currently this can be exposed to the user as either a TimeoutException or a DisconnectException. To be consistent, rather than exposing the underlying retriable error, we handle both cases with a TimeoutException.Reviewers: Boyang Chen <boyang@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunkConflicts:core/src/main/scala/kafka/controller/KafkaController.scala,5
"KAFKA-3637: Added initial statesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Dan Norwood, Xavier Léauté, Damian Guy, Michael G. Noll, Matthias J. Sax, Guozhang WangCloses #2135 from enothereska/KAFKA-3637-streams-state",5
"KAFKA-1595; Remove deprecated and slower Scala JSON parserIn a test by onurkaraman involving 3066 topics and 95895 partitions,Controller initialisation time spent on JSON parsing would be reduced from37.1 seconds to 0.7 seconds by switching from the current JSON parser toJackson. See the following JIRA comment for more details:https://issues.apache.org/jira/browse/KAFKA-5328?focusedCommentId=16027086I tested that we only use Jackson methods introduced in 2.0 in the maincodebase by compiling it with the older version locally. We use aconstructor introduced in 2.4 in one test, but I didn't remove it as itseemed harmless. The reasoning for this is explained in the mailing listthread:http://search-hadoop.com/m/uyzND1FWbWw1qUbWeFinally, this PR only handles the parsing side. It would be good to use Jacksonfor serialising to JSON as well. I filed KAFKA-5631 for that.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Onur Karaman <okaraman@linkedin.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #83 from ijuma/kafka-1595-remove-deprecated-json-parser-jackson",5
"KAFKA-4575: ensure topic created before starting sink for ConnectDistributedTest.test_pause_resume_sinkOtherwise in this test the sink task goes through the pause/resume cycle with 0 assigned partitions, since the default metadata refresh interval is quite longAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2313 from shikhar/kafka-4575",5
MINOR: Publish metrics package in the javadoc (#9036)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
MINOR: Bump version to 2.5.0-SNAPSHOT (#7455),5
KAFKA-4053: remove redundant if/else statements in TopicCommandAuthor: Shuai Zhang <shuai.xyz@gmail.com>Reviewers: Gwen ShapiraCloses #1751 from sh-z/KAFKA-4053,4
"KAFKA-5704: Corrected Connect distributed startup behavior to allow older brokers to auto-create topicsWhen a Connect distributed worker starts up talking with broker versions 0.10.1.0 and later, it will use the AdminClient to look for the internal topics and attempt to create them if they are missing. Although the AdminClient was added in 0.11.0.0, the AdminClient uses APIs to create topics that existed in 0.10.1.0 and later. This feature works as expected when Connect uses a broker version 0.10.1.0 or later.However, when a Connect distributed worker starts up using a broker older than 0.10.1.0, the AdminClient is not able to find the required APIs and thus will throw an UnsupportedVersionException. Unfortunately, this exception is not caught and instead causes the Connect worker to fail even when the topics already exist.This change handles the UnsupportedVersionException by logging a debug message and doing nothing. The existing producer logic will get information about the topics, which will cause the broker to create them if they don’t exist and broker auto-creation of topics is enabled. This is the same behavior that existed prior to 0.11.0.0, and so this change restores that behavior for brokers older than 0.10.1.0.This change also adds a system test that verifies Connect works with a variety of brokers and is able to run source and sink connectors. The test verifies that Connect can read from the internal topics when the connectors are restarted.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3641 from rhauch/kafka-5704",5
kafka-1076; system tests in 0.8 are broken due to wrong log4j config; patched by Joel Koshy; reviewed by Jay Kreps and Jun Rao,5
Rebased from trunk to resolve conflicts between KAFKA-1185 and KAFKA-930,5
KAFKA-4459: Run rat checks in Jenkins scriptAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3186 from ewencp/kafka-4459-rat-jenkins,1
"KAFKA-10186; Abort transaction with pending data with TransactionAbortedException (#9280)If a transaction is aborted with no underlying exception, throw a new kind of exception - `TransactionAbortedException` todistinguish this from other fatal exceptions.This API change is documented in KIP-654: https://cwiki.apache.org/confluence/display/KAFKA/KIP-654:+Aborted+transaction+with+non-flushed+data+should+throw+a+non-fatal+exception.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-4806; Prevent double logging of ConsumerConfigThe consumer properties get logged twice since two instancesof ConsumerConfig are created during creation of KafkaConsumer.I added a constructor of ConsumerConfig accepting the booleanparameter doLog which is already passable in AbstractConfigand set it to false during the second ConsumerConfig creatingin the KafkaConsumer constructor.Author: Marco Ebert <marco_ebert@icloud.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2600 from Gacko/trunk,1
"KAFKA-13598: enable idempotence producer by default and validate the configs (#11691)In v3.0, we changed the default value for `enable.idempotence` to true, but we didn't adjust the validator and the `idempotence` enabled check method. So if a user didn't explicitly enable idempotence, this feature won't be turned on. This patch addresses the problem, cleans up associated logic, and fixes tests that broke as a result of properly applying the new default. Specifically it does the following:1. fix the `ProducerConfig#idempotenceEnabled` method, to make it correctly detect if `idempotence` is enabled or not2. remove some unnecessary config overridden and checks due to we already default `acks`, `retries` and `enable.idempotence` configs.3. move the config validator for the idempotent producer from `KafkaProducer` into `ProducerConfig`. The config validation should be the responsibility of `ProducerConfig` class.4. add an `AbstractConfig#hasKeyInOriginals` method, to avoid `originals` configs get copied and only want to check the existence of the key. 5. fix many broken tests. As mentioned, we didn't actually enable idempotence in v3.0. After this PR, there are some tests broken due to some different behavior between idempotent and non-idempotent producer.6. add additional tests to validate configuration behaviorReviewers: Kirk True <kirk@mustardgrain.com>, Ismael Juma <ismael@juma.me.uk>, Mickael Maison <mimaison@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Update JavaDoc for KTable helper interfacesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2315 from mjsax/javaDocImprovements2",2
"KAFKA-3388; Fix expiration of batches sitting in the accumulatorAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1056 from becketqin/KAFKA-3388",0
KAFKA-1089; Fix run-class and log4j for migration tool system test; reviewed by Jun Rao,3
"KAFKA-5097; Add testFetchAfterPartitionWithFetchedRecordsIsUnassignedI verified that the test would trigger an `IllegalStateException` if the`position` call was added back.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2887 from ijuma/kafka-5097-unit-test",3
"KAFKA-12648: Pt. 1 - Add NamedTopology to protocol and state directory structure (#10609)This PR includes adding the NamedTopology to the Subscription/AssignmentInfo, and to the StateDirectory so it can place NamedTopology tasks within the hierarchical structure with task directories under the NamedTopology parent dir.Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8356: add static membership info to round robin assignor (#6815)The purpose here is to leverage static membership information during round robin consumer assignment, because persistent member id could help make the assignment remain the same during rebalance.The comparison logic is changed to:1. If member A and member B both have group.instance.id, then compare their group.instance.id2. If member A has group.instance.id, while member B doesn't, then A < B3. If both member A and B don't have group.instance.id, compare their member.idIn round robin assignor, we use ephemeral member.id to sort the members in order for assignment. This semantic is not stable and could trigger unnecessary shuffle of tasks. By leveraging group.instance.id the static member assignment shall be persist when satisfying following conditions:1. number of members remain the same across generation2. static members' identities persist across generationReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3522: Add public interfaces for timestamped stores (#6175)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
HOTFIX: correct sourceNodes for kstream.through()guozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #374 from ymatsuda/fix_through_operator,0
"MINOR: Fix undefined variable in Connect testCorrects an error in the system tests:```07:55:45 [ERROR:2018-10-23 07:55:45,738]: Failed to import kafkatest.tests.connect.connect_test, which may indicate a broken test that cannot be loaded: NameError: name 'EXTERNAL_CONFIGS_FILE' is not defined```The constant is defined in the [services/connect.py](https://github.com/apache/kafka/blob/trunk/tests/kafkatest/services/connect.py#L43) file in the `ConnectServiceBase` class, but the problem is in the [tests/connect/connect_test.py](https://github.com/apache/kafka/blob/trunk/tests/kafkatest/tests/connect/connect_test.py#L50) `ConnectStandaloneFileTest`, which does *not* extend the `ConnectServiceBase class`. Suggestions welcome to be able to reuse that variable without duplicating the literal (as in this PR).System test run with this PR: https://jenkins.confluent.io/job/system-test-kafka-branch-builder/2004/If approved, this should be merged as far back as the `2.0` branch.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5832 from rhauch/fix-connect-externals-tests",3
KAFKA-12180: Implement the KIP-631 message generator changes* Implement the uint16 type* Implement MetadataRecordType and MetadataJsonConvertersReviewers: Jason Gustafson <jason@confluent.io>,5
"kafka-2252; Socket connection closing is logged, but not corresponding opening of socket; patched by Gwen Shapira; reviewed by Jun Rao",2
"KAFKA-3291; DumpLogSegment tool should also provide an option to only…… verify index sanity.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Sriharsha Chintalapani <mail@harsha.io>Closes #975 from Parth-Brahmbhatt/KAFKA-3291",1
"KAFKA-10479; Throw exception if users try to update non-reconfigurable configs of existing listeners (#9284)The previous dynamic configuration validation did not actually compare new configs to original configs as intended, so the expected exception was not thrown.Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
Changing kafka-server-stop.sh to use SIGTERM for Kafka server process termination. No reviewgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397434 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: changes to the production broker configuration docs.Author: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2519 from alexlod/production-config-docs,5
"KAFKA-9056; Inbound/outbound byte metrics should reflect incomplete sends/receives (#7551)Currently we only record completed sends and receives in the selector metrics. If there is a disconnect in the middle of the respective operation, then it is not counted. The metrics will be more accurate if we take into account partial sends and receives.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com",5
"KAFKA-4015; Change cleanup.policy config to accept a list of valid policiesChange cleanup.policy to accept a comma separated list of valid policies.Updated LogCleaner.CleanerThread to also run deletion for any topics configured with compact,delete.Ensure Log.deleteSegments only runs when delete is enabled.Additional Integration and unit tests to cover new optionAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1742 from dguy/kafka-4015",1
"KAFKA-4549; Call writeBlock before writeEndMark in KafkaLZ4BlockOutputStream.close()Author: MURAKAMI Masahiko <fossamagna2@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2265 from fossamagna/fix-lz4outputstream-close",0
KAFKA-8913: Document topic based configs & ISR settings for Streams apps (#7346)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: improve error reporting in DescribeConsumerGroupTest (#8080)Reviewers: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",3
HOTFIX: Update unit test for KIP-443,3
MINOR: Fixed clusterId reference in Metadata.update (#4360)Also fixed log message with respective error in KerberosLogin.login.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-537 Expose clientId in ConsumerConfig and fix correlation id; patched by Yang Ye; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1398893 13f79535-47bb-0310-9956-ffa450edef68,0
"MINOR: rename subscription construction function (#6954)Per discussion on #6936, some nit fixes to the Subscription initialization path.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4029: SSL support for Connect REST API (KIP-208)This PR implements the JIRA issue [KAFKA-4029: SSL support for Connect REST API](https://issues.apache.org/jira/browse/KAFKA-4029) / [KIP-208](https://cwiki.apache.org/confluence/display/KAFKA/KIP-208%3A+Add+SSL+support+to+Kafka+Connect+REST+interface).Summary of the main changes:- Jetty `HttpClient` is used as HTTP client instead of the one shipped with Java. That allows to keep the SSL configuration for Server and Client be in single place (both use the Jetty `SslContextFactory`). It also has much richer configuration than the JDK client (it is easier to configure things such as supported cipher suites etc.).- The `RestServer` class has been broker into 3 parts. `RestServer` contains the server it self. `RestClient` contains the HTTP client used for forwarding requests etc. and `SSLUtils` contain some helper classes for configuring SSL. One of the reasons for this was Findbugs complaining about the class complexity.- A new method `valuesWithPrefixAllOrNothing` has been added to `AbstractConfig` to make it easier to handle the situation that we want to use either only the prefixed SSL options or only the non-prefixed. But not mixed them.Author: Jakub Scholz <www@scholzj.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4429 from scholzj/kip-208,5
KAFKA-1692 Include client ID in new producer IO thread name; reviewed by Neha Narkhede,1
"HOTFIX: Updates on release.py before 1.0.0Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4054 from guozhangwang/KMinor-pre-1.0-release",5
"KAFKA-2946; MINOR: Follow up. Add Delete to AclCommandTestAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1730 from granthenke/test-delete",3
"KAFKA-3753: Add approximateNumEntries() method to KeyValueStore interfaceSee https://issues.apache.org/jira/browse/KAFKA-3753This contribution is my original work and I license the work to the project under the project's open source license.cc guozhangwang kichristensen ijumaAuthor: Jeff Klukas <jeff@klukas.net>Reviewers: Ismael Juma, Guozhang WangCloses #1486 from jklukas/kvstore-size",1
"KAFKA-10282; Remove Log metrics immediately when deleting logCurrently, we remove the Log metrics when asynchronous deletion of the log is triggered. However, we attempt to register the metrics immediately upon log creation. If a Log object is re-created for a partition that is pending deletion (because a topic was quickly re-created or because a partition was moved off and back onto a broker), the registration of the new metrics can happen before the asyncrhonous deletion. In this case, the metrics are removed after the second registration, leading to missing Log metrics.To fix this, this patch changes the log deletion behavior to remove the metrics when the log is first marked for deletion, rather than when the files are deleted. This removes the window in which metrics registration can occur before metrics removal. This is justifiable because the log should be logically deleted when a delete request or partition movement finishes, rather than when the files are actually removed. Tested with unit tests.Author: Bob Barrett <bob.barrett@confluent.io>Reviewers: David Jacot, Dhruvil Shah, Vikas Singh, Gwen ShapiraCloses #9054 from bob-barrett/KAFKA-10282",5
KAFKA-10199: Remove tasks from state updater on revoked and lost partitions (#12547)Removes tasks from the state updater when the input partitions of the tasks are revoked or partitions are lost during a rebalance.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
startHighWaterMarksCheckPointThread is never called; patched by Sriram Subramanian; reviewed by Jun Rao; kafka-758,5
"MINOR: update the comment for Utils.atomicMoveWithFallback (#11641)Reviewers: Luke Chen <showuon@gmail.com>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",4
KAFKA-6145: KIP-441: Add test scenarios to ensure rebalance convergence (#8475)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
KAFKA-6004; Allow authentication providers to override error messageAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4015 from rajinisivaram/KAFKA-6004-auth-exception,5
KAFKA-8473: Adjust Connect system tests for incremental cooperative rebalancing (#6872)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"MINOR: Pass absolute directory path to RocksDB.openThe method `RocksDB.open` assumes an absolute file path. If a relative path is configured, it leads to an exception like the following:```org.apache.kafka.streams.errors.ProcessorStateException: Error opening store CustomerIdToUserIdLookup at location ./tmp/rocksdb/CustomerIdToUserIdLookupat org.rocksdb.RocksDB.open(Native Method)at org.rocksdb.RocksDB.open(RocksDB.java:183)at org.apache.kafka.streams.state.internals.RocksDBStore.openDB(RocksDBStore.java:214)at org.apache.kafka.streams.state.internals.RocksDBStore.openDB(RocksDBStore.java:165)at org.apache.kafka.streams.state.internals.RocksDBStore.init(RocksDBStore.java:170)at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.init(MeteredKeyValueStore.java:85)at org.apache.kafka.test.KStreamTestDriver.<init>(KStreamTestDriver.java:64)at org.apache.kafka.test.KStreamTestDriver.<init>(KStreamTestDriver.java:50)at com.simple.estuary.transform.streaming.CartesianTransactionEnrichmentJobTest.testBuilder(CartesianTransactionEnrichmentJobTest.java:41)```Is there any risk to always fetching the absolute path as proposed here?Let me know if you think this requires a JIRA issue or a unit test. I started working on a unit test, but don't know of a great solution for writing out a file to a relative directory.This contribution is my original work and I license the work to the project under the project's open source license.Author: Jeff Klukas <jeff@klukas.net>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1481 from jklukas/rocksdb-abspath",5
"MINOR: Mention `log.message.format.version=0.10.0` in rolling upgrade sectionWe had mentioned this step in the performance impact section in the middle of a long paragraph, which made it easy to miss. I also tweaked the reason for setting `log.message.format.version` as it could be misinterpreted previously.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1514 from ijuma/tweak-upgrade-notes",5
"KAFKA-5657: Connect REST API should include the connector type when describing a connector (KIP-151)Embed the type of connector in ConnectorInfoAuthor: tedyu <yuzhihong@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3812 from tedyu/trunk",1
MINOR: Move creation of quota callback to ensure single instance (#4848)Move creation of quota callback instance out of KafkaConfig constructor to QuotaFactory.instantiate to avoid creating a callback instance for every KafkaConfig since we create temporary KafkaConfigs during dynamic config updates.Reviewers: Jun Rao <junrao@gmail.com>,5
"KAFKA-2845: new client old broker compatibilityAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #537 from granders/KAFKA-2845-new-client-old-broker-compatibility",1
"KAFKA-10166: checkpoint recycled standbys and ignore empty rocksdb base directory (#8962)Two more edge cases I found producing extra TaskcorruptedException while playing around with the failing eos-beta upgrade test (sadly these are unrelated problems, as the test still fails with these fixes in place).* Need to write the checkpoint when recycling a standby: although we do preserve the changelog offsets when recycling a task, and should therefore write the offsets when the new task is itself closed, we do NOT write the checkpoint for uninitialized tasks. So if the new task is ultimately closed before it gets out of the CREATED state, the offsets will not be written and we can get a TaskCorruptedException* We do not write the checkpoint file if the current offset map is empty; however for eos the checkpoint file is not only used for restoration but also for clean shutdown. Although skipping a dummy checkpoint file does not actually violate any correctness since we are going to re-bootstrap from the log-start-offset anyways, it throws unnecessary TaskCorruptedException which has an overhead itself.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-7037: Improve the topic command description of `--topic` optionAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5193 from vahidhashemian/KAFKA-7037,1
kafka-649; Cleanup log4j logging (extra); patched by Jun Rao; reviewed by Neha Narkhede,2
Fix DSL typo in streams docs (#12152)Reviewer: Bruno Cadonna <cadonna@apache.org>,1
Add more test cases to System Test ; patched by John Fung; reviewed by Jun Rao; KAFKA-571git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401875 13f79535-47bb-0310-9956-ffa450edef68,3
"KAFKA-13472: Correct last-committed offsets tracking for sink tasks after partial revocation (#11526)The `WorkerSinkTask.lastCommittedOffsets` field is now added to (via `Map::putAll`) after a successful offset commit, instead of being completely overwritten. In order to prevent this collection from growing indefinitely, elements are removed from it after topic partitions are revoked from the task's consumer.Two test cases are added to `WorkerSinkTaskTest`:- A basic test to verify the ""rewind for redelivery"" behavior when a task throws an exception from `SinkTask::preCommit`; surprisingly, no existing test cases appear to cover this scenario- A more sophisticated test to verify this same behavior, but with a few rounds of cooperative consumer rebalancing beforehand that expose a bug in the current logic for the `WorkerSinkTask` classThe `VerifiableSinkTask` class is also updated to only flush the requested topic partitions in its `flush` method. This is technically unrelated to the issue addressed by this PR and can be moved to a separate PR if necessary; including it here as the original context for identifying this bug was debugging failed system tests and the logic in this part of the tests was originally suspected as a cause of the test failure.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",0
"MINOR: Update docstring for ""offsets.retention.minutes"" configAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2562 from omkreddy/MINOR-DOC",2
"KAFKA-12520: Ensure log loading does not truncate producer state unless required (#10763)When we find a .swap file on startup, we typically want to rename and replace it as .log, .index, .timeindex, etc. as a way to complete any ongoing replace operations. These swap files are usually known to have been flushed to disk before the replace operation begins.One flaw in the current logic is that we recover these swap files on startup and as part of that, end up truncating the producer state and rebuild it from scratch. This is unneeded as the replace operation does not mutate the producer state by itself. It is only meant to replace the .log file along with corresponding indices. Because of this unneeded producer state rebuild operation, we have seen multi-hour startup times for clusters that have large compacted topics.This patch fixes the issue. With ext4 ordered mode, the metadata are ordered and no matter it is a clean/unclean shutdown. As a result, we rework the recovery workflow as follows.If there are any .cleaned files, we delete all .swap files with higher/equal offsets due to KAFKA-6264. We also delete the .cleaned files. If no .cleaned file, do nothing for this step.If there are any .log.swap files left after step 1, they, together with their index files, must be renamed from .cleaned and are complete (renaming from .cleaned to .swap is in reverse offset order). We rename these .log.swap files and their corresponding index files to regular files, while deleting the original files from compaction or segment split if they haven't been deleted.Do log splitting for legacy log segments with offset overflow (KAFKA-6264)If there are any other index swap files left, they must come from partial renaming from .swap files to regular files. We can simply rename them to regular files.credit: some code is copied from @dhruvilshah3 's PR: #10388Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-5124: autocommit reset earliest fixes race conditionFixes `org.apache.kafka.streams.integration.utils.IntegrationTestUtils#readKeyValues` potentially starting to `poll` for stream output after the stream finished sending the test data and hence missing it when working with `latest` offsets.Author: Armin Braun <me@obrown.io>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2921 from original-brownbear/KAFKA-5124",1
"KAFKA-4899; Fix findbugs warnings in kafka-coreAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jozef Koval <jozef.koval@protonmail.ch>, Ismael Juma <ismael@juma.me.uk>Closes #2687 from cmccabe/KAFKA-4899",5
"kafka-1302; cleanup logging in new producer; reviewed by Jay Kreps, Guozhang Wang and Neha Narkhede",1
"KAFKA-10033: Throw UnknownTopicOrPartitionException when modifying a non-existent topic's configAuthor: Brian Byrne <bbyrne@confluent.io>Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chan <boyang@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8717 from bdbyrne/KAFKA-10033",5
MINOR: Tweak detection of kafka server start-up in system testsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3834 from ijuma/tweak-system-test-regex-for-detecting-server-start-up,5
add optional mx4j support; patched by Chris Burroughs; reviewed by Jun Rao; KAFKA-78git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179501 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13879: Reconnect exponential backoff is ineffective in some cases (#12131)When a client connects to a SSL listener using PLAINTEXT security protocol, after the TCP connection is setup, the client considers the channel setup is complete. In reality the channel setup is not complete yet. The client then resets reconnect exponential backoff and issues API version request. Since the broker expects SSL handshake, the API version request will cause the connection to disconnect. Client reconnects without exponential backoff since it has been reset.This commit removes the reset of reconnect exponential backoff when sending API version request. In the good case where the channel setup is complete, reconnect exponential backoff will be reset when the node becomes ready, which is after getting the API version response. Inter-broker clients which do not send API version request and go directly to ready state continue to reset backoff before any  successful requests.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-3690: Avoid to pass null to UnmodifiableMapAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1360 from Ishiihara/avoid-to-pass-null",4
"MINOR: Eliminate redundant functions in LogTest suite (#10732)Reviewers: Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",3
"Handle ProducerFencedException on offset commit (#9479)The transaction manager does currently not handle producer fenced errors returned from a offset commit request.Adds the handling of the producer fenced errors.Reviewers: Boyang Chen <boyang@apache.org>, John Roesler <vvcephei@apache.org>",0
"KAFKA-8331: stream static membership system test (#6877)As title suggested, we boost 3 stream instances stream job with one minute session timeout, and once the group is stable, doing couple of rolling bounces for the entire cluster. Every rejoin based on restart should have no generation bump on the client side.Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",3
"MINOR: Enable ""abort previous builds"" for PRs (#12588)When a new commit is pushed to a PR, we should abort the buildand start a new one instead of queuing one build per commit.This reduces wasted resources and provides the desired feedbackfaster (since we only care about the build results for the lastcommit in the PR).Reviewers: Luke Chen <showuon@gmail.com>",5
KAFKA-4677 Follow Up: add optimization to StickyTaskAssignor for rolling rebounceDetect when a rebalance has happened due to one or more existing nodes bouncing. Keep assignment of previous active tasks the same and only assign the tasks that were not active to the new clients.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2609 from dguy/kstreams-575,1
"MINOR: add wait_for_assigned_partitions to console-consumer (#8192)what/whythe throttling_test was broken by this PR (#7785) since it depends on the consumer having partitions-assigned before starting the producerthis PR provides the ability to wait for partitions to be assigned in the console consumer before considering it started.caveatthis does not support starting up the JmxTool inside the console-consumer for custom metrics while using this wait_until_partitions_assigned flag since the code assumes one JmxTool running per node.I think a proper fix for this would be to make JmxTool its own standalone single-node servicealternativeswe could use the EndToEnd test suite which uses the verifiable producer/consumer under the hood but I found that there were more changes necessary to get this working unfortunately (specifically doesn't seem like this test suite plays nicely with the ProducerPerformanceService)Reviewers: Mathew Wong <mwong@confluent.io>, Bill Bejeck <bbejeck.com>",5
"KAFKA-5280: Protect txn metadata map with read-write lockTwo major changes plus one minor change:0. change stateLock to a read-write lock.1. Put the check of ""isCoordinator"" and ""coordinatorLoading"" together with the return of the metadata, under one read lock block, since otherwise we can get incorrect behavior if there is a change in the metadata cache after the check but before the accessing of the metadata.2. Grab the read lock right before trying to append to local txn log, and until the local append returns; this is to avoid the scenario that the epoch has actually changed when we are appending to local log (e.g. emigration followed by immigration).3. only watch on txnId instead of txnId and txnPartitionId in the txn marker purgatory, and disable reaper thread, as we can now safely clear all the delayed operations by traversing the marker queues.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson, Jun RaoCloses #3082 from guozhangwang/K5231-read-write-lock",2
KAFKA-1876; pom file for scala 2.11 should reference a specific version; patched by Jun Rao; reviewed by Joe Stein and Sriharsha Chintalapani,2
"KAFKA-7058: Comparing schema default values using Objects#deepEquals()https://issues.apache.org/jira/browse/KAFKA-7058* Summary of testing strategy: Added new unit testAuthor: Gunnar Morling <gunnar.morling@googlemail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5225 from gunnarmorling/KAFKA-7058",5
"KAFKA-13719: Fix connector restart cause duplicate tasks (#11869)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>, Chris Egerton <fearthecellos@gmail.com>Co-authored-by: Chris Egerton <fearthecellos@gmail.com>",1
"KAFKA-4381: Add per partition lag metrics to the consumerAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2329 from becketqin/KAFKA-4381",5
ByteBufferMessageSet iterator bug returning incorrect offsets after reading a compressed empty message set KAFKA-111; patched by Jun; reviewed by Nehagit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159466 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Improve close tests of caching state store (#8386)Reviewers: John Roesler <vvcephei@apache.org>, Matthias J. Sax <matthias@confluent.io>, Andrew Choi <a24choi@edu.uwaterloo.ca>",5
"MINOR: Mention KAFKA-13748 in release notes (#11994)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Bruno Cadonna <bruno@confluent.io>",5
"MINOR: Code cleanup (#4229)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian@confluent.io>, Paolo Patierno <ppatierno@live.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-5069; add controller integration testsTest the various controller protocols by observing zookeeper and broker state.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2853 from onurkaraman/KAFKA-5069",2
"KAFKA-6179: Clear min timestamp tracker upon partition queue cleanupAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4186 from guozhangwang/K6179-cleanup-timestamp-tracker-on-clear",4
trivial fix to add missing license header using .gradlew licenseFormatMain and ./gradlew licenseFormatTest; patched by Jun Rao,3
"KAFKA-2779; Close SSL socket channel on remote connection closeClose socket channel in finally block to avoid file descriptor leak when remote end closes the connectionAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #460 from rajinisivaram/KAFKA-2779",5
KAFKA-3454: add Kafka Streams web docsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen ShapiraCloses #1127 from guozhangwang/KStreamsDocs,2
KAFAK-4058: Failure in org.apache.kafka.streams.integration.ResetIntegrationTest.testReprocessingFromScratchAfterReset - fixed consumer group dead condition - disabled state store cacheAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2056 from mjsax/KAFKA-4058-instableResetToolTest,3
"MINOR: Remove duplicate definition of transactional.id.expiration.ms config (#7245)Reviewers: Bob Barrett <bob.barrett@outlook.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Delete unused code in FileStreamSourceTaskAuthor: leisore <leisore@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1433 from leisore/master",5
KAFKA-2863; Add a `close()` method to `Authorizer`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #568 from ijuma/kafka-2863-authorizer-close,1
SyncProducer connect may return failed connection on reconnect; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-226git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1215027 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6997: Exclude test-sources.jar when $INCLUDE_TEST_JARS is FALSEExclude test-sources.jar when $INCLUDE_TEST_JARS is FALSEAuthor: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Robert Yokota <rayokota@gmail.com>, Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5139 from mageshn/KAFKA-6997",5
"KAFKA-13599: Upgrade RocksDB to 6.27.3 (#11690)RocksDB v6.27.3 has been released and it is the first release to support s390x. RocksDB is currently the only dependency in gradle/dependencies.gradle without s390x support.RocksDB v6.27.3 has added some new options that require an update to streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBGenericOptionsToDbOptionsColumnFamilyOptionsAdapter.java but no other changes are needed to upgrade.I have run the unit/integration tests locally on s390x and also the :streams tests on x86_64 and they pass.Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
KAFKA-7216: Ignore unknown ResourceTypes while loading acl cache (#5673)Reviewers: Jun Rao <junrao@gmail.com>,5
"MINOR: Improve the org.apache.kafka.common.protocol code (#7344)Add UUID to the list of types documented in Type#toHtml.Type, Protocol, ArrayOf: use Type#isArray and Type#arrayElementType rather than typecasting to handle arrays.  This is cleaner.  It will also make it easier for us to add compact arrays (as specified by KIP-482) as a new array type distinct from the old array type.Add MessageUtil#byteBufferToArray, as well as a test for it.  We will need this for handling tagged fields of type ""bytes"".Schema#Visitor: we don't need a separate function overload for visiting arrays. We can just call ""visit(Type field)"".TestUUID.json: reformat the JSON file to match the others.ProtocolSerializationTest: improve the error messages on failure.  Check that each type has the name we expect it to have.Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, Vikas Singh <soondenana@users.noreply.github.com>",1
"MINOR: Remove unused ShutdownableThread class and ineffective ThreadedTest class (#12410)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Christo Lolov <christo_lolov@yahoo.com>",3
kafka-2185; Update to Gradle 2.4; patched by Ismael Juma; reviewed by Jun Rao,5
KAFKA-13875 Adjusted the output the topic describe output to include TopicID & se… (#12170)Reviewers: Luke Chen <showuon@gmail.com>,5
"KAFKA-5502; read current brokers from zookeeper upon processing broker changeDong Lin's testing of the 0.11.0 release revealed a controller-side performance regression in clusters with many brokers and many partitions when bringing up many brokers simultaneously.The regression is caused by KAFKA-5028: a Watcher receives WatchedEvent notifications from the raw ZooKeeper client EventThread. A WatchedEvent only contains the following information:- KeeperState- EventType- pathNote that it does not actually contain the current data or current set of children associated with the data/child change notification. It is up to the user to do this lookup to see the current data or set of children.ZkClient is itself a Watcher. When it receives a WatchedEvent, it puts a ZkEvent into its own queue which its own ZkEventThread processes. Users of ZkClient interact with these notifications through listeners (IZkDataListener, IZkChildListener). IZkDataListener actually expects as input the current data of the watched znode, and likewise IZkChildListener actually expects as input the current set of children of the watched znode. In order to provide this information to the listeners, the ZkEventThread, when processing the ZkEvent in its queue, looks up the information (either the current data or current set of children) simultaneously sets up the next watch, and passes the result to the listener.The regression introduced in KAFKA-5028 is the time at which we lookup the information needed for the event processing.In the past, the lookup from the ZkEventThread during ZkEvent processing would be passed into the listener which is processed immediately after. For instance in ZkClient.fireChildChangedEvents:```List<String> children = getChildren(path);listener.handleChildChange(path, children);```Now, however, there are multiple listeners that pass information looked up by the ZkEventThread into a ControllerEvent which gets processed potentially much later. For instance in BrokerChangeListener:```class BrokerChangeListener(controller: KafkaController) extends IZkChildListener with Logging {  override def handleChildChange(parentPath: String, currentChilds: java.util.List[String]): Unit = {    import JavaConverters._    controller.addToControllerEventQueue(controller.BrokerChange(currentChilds.asScala))  }}```In terms of impact, this:- increases the odds of working with stale information by the time the ControllerEvent gets processed.- can cause the cluster to take a long time to stabilize if you bring up many brokers simultaneously.In terms of how to solve it:- (short term) just ignore the ZkClient's information lookup and repeat the lookup at the start of the ControllerEvent. This is the approach taken in this ticket.- (long term) try to remove a queue. This basically means getting rid of ZkClient. This is likely the approach that will be taken in KAFKA-5501.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3413 from onurkaraman/KAFKA-5502",2
"KAFKA-3965; MirrorMaker should not commit offset when exception is thrown from producer.sendAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1915 from becketqin/KAFKA-3965",5
KAFKA-533 changes to NOTICE and LICENSE related to KAFKA-534 removing client libraries from repogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1390788 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13139: Empty response after requesting to restart a connector without the tasks results in NPE (#11132)Even after the implementation of KIP-745 it makes sense to return a response code of 204 NO CONTENT when the request is to restart the connector but not the tasks. This maintains the current behavior for this existing REST call and is also aligned with the description in the RFC: https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.2.5Reviewers: Kalpesh Patel <kpatel@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-14154; Kraft controller should return NOT_CONTROLLER if request epoch is ahead (#12514)Similar to https://github.com/apache/kafka/pull/12506. For the Kraft controller, we should return NOT_CONTROLLER if the leader/partition epoch in the request is ahead of the controller. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
kafka-927; Integrate controlled shutdown into kafka shutdown hook; patched by Sriram Subramanian; reviewed by Neha Narkhede and Jun Rao,1
"KAFKA-7758: Reuse KGroupedStream/KGroupedTable with named repartition topics (#6265)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Remove implicit return statement (#6629)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: (docs) in section, not at sectionSee https://english.stackexchange.com/questions/158981/at-this-section-vs-in-this-section and https://forum.wordreference.com/threads/at-in-within-the-section-we-can-find.374188/Author: mihbor <mbor81@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3228 from mihbor/patch-8",4
"MINOR: fix code listings security.html (#10770)Fix examples under security.html so they use the right bash icon (`>`instead of `$`) and also uses the right tool for showing code listings.Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
kafka-1364; ReplicaManagerTest hard-codes log dir; patched by Guozhang Wang; reviewed by Jun Rao,2
MINOR: fix some warnings in the brokerAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen ShapiraCloses #6942 from cmccabe/fix-scala-warnings,2
"MINOR: Upgrade Gradle to 4.8 and bug fix updates for other deps (#5148)In addition to Gradle, updated snappy, owasp-dependency-check,apache directory service api.Gradle 4.8 fixes a fatal issue when building with Java 11, butfull support is coming in 4.9 or later.",1
"KAFKA-10710; MM2 - Create herders only if source->target.enabled=true and heartbeats are disabled (#9589)By default Mirror Maker 2 creates herders for all the possible combinations even if the ""links"" are not enabled.This is because the beats are emitted from the ""opposite"" herder.If there is a replication flow from A to B and heartbeats are required, 2 herders are needed :- A->B for the MirrorSourceConnector- B->A for the MirrorHeartbeatConnectorThe MirrorHeartbeatConnector on B->A emits beats into topic heartbeats on cluster A.The MirrorSourceConnector on A->B then replicates whichever topic is configured as well as heartbeats.In cases with multiple clusters (10 and more), this leads to an incredible amount of connections, file descriptors and configuration topics created in every target clusters that are not necessary.With this code change, we will leverage the top level property ""emit.heartbeats.enabled"" which defaults to ""true"".We skip creating the A->B herder whenever A->B.emit.heartbeats.enabled=false (defaults to true) and A->B.enabled=false (defaults to false). Existing users will not see any change and if they depend on these ""opposites"" herders for their monitoring, it will still work.New users with more complex use case can change this property and fine tune their heartbeat generation.Reviewers: Ryanne Dolan <ryannedolan@gmail.com>,  Sanjana Kaundinya <skaundinya@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Fix a couple of scaladoc typosAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1440 from vahidhashemian/typo06/fix_typos_in_code_comments,2
KAFKA-13254; Fix deadlock when `AlterIsr` response returns (#11289)This patch fixes a deadlock when incrementing the high watermark after the synchronous zk ISR modification happens. The main difference is that we prevent the callback from executing while under the leader and ISR lock. The deadlock bug was introduced in https://github.com/apache/kafka/pull/11245.Reviewers: David Jacot <djacot@confluent.io>,5
"HOTFIX: Streams fix state transition stuck on rebalanceThis fixes a problem where the Kafka instance state transition gets stuck on rebalance (Thanks to dguy for pointing out). Also adjusts the test in QueryableStateIntegration test.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2252 from enothereska/hotfix_state_never_running",0
KAFKA-9881: Convert integration test to verify measurements from RocksDB to unit test (#8501)The integration test RocksDBMetricsIntegrationTest takes pretty long to complete.Most of the runtime is spent in the two tests that verify whether the RocksDBmetrics get actual measurements from RocksDB. Those tests need to wait for the threadthat collects the measurements of the RocksDB metrics to trigger the first recordingsof the metrics.This PR adds a unit test that verifies whether the Kafka Streams metrics get themeasurements from RocksDB and removes the two integration tests that verified itbefore. The verification of the creation and scheduling of the RocksDB metricsrecording trigger thread is already contained in KafkaStreamsTest and consequentlyit is not part of this PR.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-2527; System Test for Quotas in Ducktapegranders Can you take a look at this quota system test?Author: Dong Lin <lindong28@gmail.com>Reviewers: Geoff Anderson, Ewen Cheslack-PostavaCloses #275 from lindong28/KAFKA-2527",3
"KAFKA-10674: Controller API version bond with forwardable APIs (#9600)Get controller api version intersection setup for client queries. When the unsupported exception was hit in the EnvelopeResponse, close the client connection to let it rediscover the api version.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: The message of BufferExhaustedException should include pool status (#11378)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",5
"KAFKA-10199: Introduce task registry (#12549)Currently the task manager stores the tasks it manages in aninternally. We recently extracted the code to store and retrievetasks into its own class Tasks. However, the task manager createsthe Tasks object internally and during testing of the taskmanager we do not have access to it which makes testing the taskmanager quite complex.This commit externalizes the data structure that the task manageruses to store and rerieve tasks. It introduces the TasksRegistryinterface and lets the Tasks object implementing TasksRegistry.The Tasks object is passed into the task manager via itsconstructor. Passing the TasksRegistry dependency to the taskmanager from outside faciliates simpler testing of the taskmanager.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-3810: replication of internal topics should not be limited by replica.fetch.max.bytesFrom the kafka-dev mailing list discussion: [[DISCUSS] scalability limits in the coordinator](http://mail-archives.apache.org/mod_mbox/kafka-dev/201605.mbox/%3CCAMQuQBZDdtAdhcgL6h4SmTgO83UQt4s72gc03B3VFghnME3FTAmail.gmail.com%3E)There's a scalability limit on the new consumer / coordinator regarding the amount of group metadata we can fit into one message. This restricts a combination of consumer group size, topic subscription sizes, topic assignment sizes, and any remaining member metadata.Under more strenuous use cases like mirroring clusters with thousands of topics, this limitation can be reached even after applying gzip to the __consumer_offsets topic.Various options were proposed in the discussion:1. Config change: reduce the number of consumers in the group. This isn't always a realistic answer in more strenuous use cases like MirrorMaker clusters or for auditing.2. Config change: split the group into smaller groups which together will get full coverage of the topics. This gives each group member a smaller subscription.(ex: g1 has topics starting with a-m while g2 has topics starting with n-z). This would be operationally painful to manage.3. Config change: split the topics among members of the group. Again this gives each group member a smaller subscription. This would also be operationally painful to manage.4. Config change: bump up KafkaConfig.messageMaxBytes (a topic-level config) and KafkaConfig.replicaFetchMaxBytes (a broker-level config). Applying messageMaxBytes to just the __consumer_offsets topic seems relatively harmless, but bumping up the broker-level replicaFetchMaxBytes would probably need more attention.5. Config change: try different compression codecs. Based on 2 minutes of googling, it seems like lz4 and snappy are faster than gzip but have worse compression, so this probably won't help.6. Implementation change: support sending the regex over the wire instead of the fully expanded topic subscriptions. I think people said in the past that different languages have subtle differences in regex, so this doesn't play nicely with cross-language groups.7. Implementation change: maybe we can reverse the mapping? Instead of mapping from member to subscriptions, we can map a subscription to a list of members.8. Implementation change: maybe we can try to break apart the subscription and assignments from the same SyncGroupRequest into multiple records? They can still go to the same message set and get appended together. This way the limit become the segment size, which shouldn't be a problem. This can be tricky to get right because we're currently keying these messages on the group, so I think records from the same rebalance might accidentally compact one another, but my understanding of compaction isn't that great.9. Implementation change: try to apply some tricks on the assignment serialization to make it smaller.10. Config and Implementation change: bump up the __consumer_offsets topic messageMaxBytes and (from Jun Rao) fix how we deal with the case when a message is larger than the fetch size. Today, if the fetch size is smaller than the fetch size, the consumer will get stuck. Instead, we can simply return the full message if it's larger than the fetch size w/o requiring the consumer to manually adjust the fetch size.11. Config and Implementation change: same as above but only apply the special fetch logic when fetching from internal topicsThis PR provides an implementation of option 11.That being said, I'm not very happy with this approach as it essentially doesn't honor the ""replica.fetch.max.bytes"" config. Better alternatives are definitely welcome!Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1484 from onurkaraman/KAFKA-3810",5
KAFKA:212 IllegalThreadStateException in kafka mirroring;patched by nehanarkhede; reviewed by junrao and jaykrepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1208919 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-4387; KafkaConsumer should properly handle interruptsSee https://issues.apache.org/jira/browse/KAFKA-4387Author: Stig Rohde Døssing <sdo@it-minds.dk>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2110 from srdo/KAFKA-4387",5
"KAFKA-2278: JmxTool should support querying all objects when object name is omitted…ame is omittedAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Aditya Auradkar, Manikumar Reddy, Guozhang WangCloses #181 from lindong28/KAFKA-2278",1
"KAFKA-3946: Protocol guide should say that Produce request acks can o……nly be 0, 1, or -1Rephrased the documentation string for the Produce requestUpdated the acks configuration docs to state that -1, 0, and 1 are the only allowed valuesAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Gwen ShapiraCloses #1680 from mimaison/KAFKA-3946",1
"KAFKA-8179: Part 2, ConsumerCoordinator Algorithm (#6778)1. In ConsumerCoordinator, select the protocol as the common protocol from all configured assignor instances' supported protocols with the highest number.1.b. In onJoinPrepare: only call onPartitionRevoked with EAGER.1.a. In onJoinComplete: call onPartitionAssigned with EAGER; call onPartitionRevoked following onPartitionAssigned with COOPERATIVE, and then request re-join if the error indicates so.1.c. In performAssignment: update the user's assignor returned assignments by excluding all partitions that are still owned by some other members.2. I've refactored the Subscription / Assignment such that: assigned partitions, error codes, and group instance id are not-final anymore, instead they can be updated. For the last one, it is directly related to the logic of this PR but I felt it is more convienent to go with other fields.3. Testing: primarily in ConsumerCoordinatorTest, make it parameterized with protocol, and add necessary scenarios for COOPERATIVE protocol.I intentionally omitted the documentation change since there are some behavioral updates that needs to be finalized in later PRs, and hence I will also only add the docs in later PRs.Reviewers: Bill Bejeck <bbejeck@gmail.com>, Boyang Chen <boyang@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>",5
"MINOR: Fixed ConsumerRecord constructor javadocRefactoring of ConsumerRecord made in https://github.com/apache/kafka/commit/0699ff2ce60abb466cab5315977a224f1a70a4da#diff-fafe8d3a3942f3c6394927881a9389b2 left ConsumerRecord constructor javadoc inconsistent with implementation.This patch fixes ConsumerRecord constructor javadoc to be inline with implementation.Author: Stevo Slavić <sslavic@gmail.com>Reviewers: Ismael, GuozhangCloses #85 from sslavic/patch-3 and squashes the following commits:c289c4f [Stevo Slavić] MINOR: Fixed ConsumerRecord constructor javadoc",2
KAFKA-8560; The Kafka protocol generator should support common structuresAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen ShapiraCloses #6966 from cmccabe/KAFKA-8560,5
KAFKA-5075; Defer exception to the next pollOnce() if consumer's fetch position has already increasedAuthor: Dong Lin <lindong28@gmail.com>Author: Dong Lin <lindong28@users.noreply.github.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #2859 from lindong28/KAFKA-5075,1
"KAFKA-8972: Need to flush state even on unclean close (#7589)In the case of unclean close we still need to make sure all the stores are flushed before closing any.Reviewers: Matthias J. Sax <matthias@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-6204 KAFKA-7402 ProducerInterceptor should implement AutoCloseable (#11997)As part of KIP-376 we had ConsumerInterceptor implement AutoCloseablebut forgot to do the same for ProducerInterceptor. This fixes theinconsistency and also addresses KAFKA-6204 at the same time.Reviewers: John Roesler <vvcephei@apache.org>,1
KAFKA-5690; Add support to list ACLs for a given principal (KIP-357)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5633 from omkreddy/KAFKA-5690-LIST-PER-PRICIPAL,1
"KAFKA-4684: add kafka-configs.bat for Windows boxesAdd kafka-configs.bat script for Windows.Author: huxi <huxi@zhenrongbao.com>Reviewers: Guozhang Wang, Vahid HashemianCloses #2419 from amethystic/kafka4684_offer_kafkaconfigs_script",5
KAFKA-7785: move internal DefaultPartitionGrouper (#10302)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
MINOR: Change version format in release notes python codeijuma ewencpAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4171 from guozhangwang/KMinor-update-releasepy,5
KAFKA-2457; Fix how the argument is passed to `compileScala`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #159 from ijuma/kafka-2457-fix,0
"KAFKA-2821; fix deadlock in group metadata write callbackAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #519 from hachikuji/KAFKA-2821",5
"MINOR: Fix consumer/producer properties override (#9313)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",0
"MINOR: Add mock implementation of `BrokerToControllerChannelManager` (#10026)Tests involving `BrokerToControllerChannelManager` are simplified by being able to leverage `MockClient`. This patch introduces a `MockBrokerToControllerChannelManager` implementation which makes that possible.The patch updates `ForwardingManagerTest` to use `MockBrokerToControllerChannelManager`. We also add a couple additional timeout cases, which exposed a minor bug. Previously we were using the wrong `TimeoutException`, which meant that expected timeout errors were in fact translated to `UNKNOWN_SERVER_ERROR`.Reviewers: David Arthur <david.arthur@confluent.io>",5
"KAFKA-6170; KIP-220 Part 1: Add AdminClient to Streams1. Add The AdminClient into Kafka Streams, which is shared among all the threads.2. Add ADMIN_PREFIX to StreamsConfig.3. Also made a few tweaks on the metrics of the AdminClient, which is slightly different from the StreamsKafkaClient (note these changes will not be reflected in this PR but only take place when we eventually replace StreamsKafkaClient):3.1. ""clientId"" tag will be set as ""clientId-admin"": in StreamsKafkaClient it is whatever user sets, and hence could even be null.3.2. ""groupPrefix"" will be set as ""admin-client"": in StreamsKafkaClient it will be ""kafka-client"".So the metrics from `StreamsKafkaClient` to `AdminClient` would be changed from`kafka.admin.client:type=kafka-client-metrics,client-id=`to`kafka.admin.client:type=admin-client-metrics,client-id=myApp-UUID-admin`Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>Closes #4211 from guozhangwang/K6170-admin-client",5
KAFKA-12791: ConcurrentModificationException in AbstractConfig use by KafkaProducer (#10704)Recently we have noticed multiple instances where KafkaProducers have failed to constructor due to the following exception:```org.apache.kafka.common.KafkaException: Failed to construct kafka producer at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:440) at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:291) at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:318) java.base/java.lang.Thread.run(Thread.java:832) Caused by: java.util.ConcurrentModificationException at java.base/java.util.HashMap$HashIterator.nextNode(HashMap.java:1584) at java.base/java.util.HashMap$KeyIterator.next(HashMap.java:1607) at java.base/java.util.AbstractSet.removeAll(AbstractSet.java:171) at org.apache.kafka.common.config.AbstractConfig.unused(AbstractConfig.java:221) at org.apache.kafka.common.config.AbstractConfig.logUnused(AbstractConfig.java:379) at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:433) ... 9 more exception.class:org.apache.kafka.common.KafkaException exception.message:Failed to construct kafka producer```This is due to the fact that `used` below is a synchronized set. `used` is being modified while removeAll is being called. This is due to the use of RecordingMap in the Sender thread (see below). Switching to a ConcurrentHashSet avoids this issue as it support concurrent iteration.```at org.apache.kafka.clients.producer.ProducerConfig.ignore(ProducerConfig.java:569)at org.apache.kafka.common.config.AbstractConfig$RecordingMap.get(AbstractConfig.java:638)at org.apache.kafka.common.network.ChannelBuilders.createPrincipalBuilder(ChannelBuilders.java:242)at org.apache.kafka.common.network.PlaintextChannelBuilder$PlaintextAuthenticator.<init>(PlaintextChannelBuilder.java:96)at org.apache.kafka.common.network.PlaintextChannelBuilder$PlaintextAuthenticator.<init>(PlaintextChannelBuilder.java:89)at org.apache.kafka.common.network.PlaintextChannelBuilder.lambda$buildChannel$0(PlaintextChannelBuilder.java:66)at org.apache.kafka.common.network.KafkaChannel.<init>(KafkaChannel.java:174)at org.apache.kafka.common.network.KafkaChannel.<init>(KafkaChannel.java:164)at org.apache.kafka.common.network.PlaintextChannelBuilder.buildChannel(PlaintextChannelBuilder.java:79)at org.apache.kafka.common.network.PlaintextChannelBuilder.buildChannel(PlaintextChannelBuilder.java:67)at org.apache.kafka.common.network.Selector.buildAndAttachKafkaChannel(Selector.java:356)at org.apache.kafka.common.network.Selector.registerChannel(Selector.java:347)at org.apache.kafka.common.network.Selector.connect(Selector.java:274)at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:1097)at org.apache.kafka.clients.NetworkClient.access$700(NetworkClient.java:87)at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:1276)at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:1164)at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:637)at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:327)at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:242)```Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-7502: Cleanup KTable materialization logic in a single place (filter) (#6453)This PR is a follow-up of #6174, which handles doFilter / doMapValues / doTransformValues methods.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-4060 Follow-up: update docs accordinglyUpdated the docs with changes in KAFKA-4060.Author: Hojjat Jafarpour <hojjat@Hojjat-Jafarpours-MBP.local>Author: Hojjat Jafarpour <hojjat@HojjatJpoursMBP.attlocal.net>Reviewers: Ismael Juma, Matthias J. Sax, Guozhang WangCloses #2377 from hjafarpour/KAFKA-4060-docs-update",5
"KAFKA-2671: Enable starting Kafka server with a Properties objectAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Eno Thereska, Gwen ShapiraCloses #330 from SinghAsDev/KAFKA-2671",0
"KAFKA-2937; Disable the leaderIsr check if the topic is to be deleted.The check was implemented in KAFKA-340 : If we are shutting down a broker when the ISR of a partition includes only that broker, we could lose some messages that have been previously committed. For clean shutdown, we need to guarantee that there is at least 1 other broker in ISR after the broker is shut down.When we are deleting the topic, this check can be avoided.Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>Reviewers: Dong Lin <lindong28@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>Closes #729 from MayureshGharat/kafka-2937",5
"KAFKA-4420; Group StopReplicaRequests for partitions on the same broker into one StopReplicaRequestAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2148 from lindong28/KAFKA-4420",2
"KAFKA-6473: Add MockProcessorContext to public test-utils (#4736)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-9509; Fixing flakiness of MirrorConnectorsIntegrationTest.testReplication (#8048)The test case `org.apache.kafka.connect.mirror.MirrorConnectorsIntegrationTest.testReplication` has shown to be increasingly flaky recently. This PR aims to make this test more deterministic. Specifically, the flakiness was due to a timing issue between the tasks not starting up in time for the test to start running. This PR remediates that by introducing a status check after every connector is started up. These status checks include that the connector is found on the connect cluster as well as there are tasks created and up and running for that connector. These checks are introduced before the test starts running so that there is a confidence that the connectors and tasks are started up correctly before the test runs.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>",5
kafka-2119; ConsumerRecord key() and value() methods should not have throws Exception; patched by Ewen Cheslack-Postava; reviewed by Jun Rao,5
"KAFKA-2905: System test for rolling upgrade to enable ZooKeeper ACLs with SASLAuthor: flavio junqueira <fpj@apache.org>Reviewers: Ismael Juma, Geoff AndersonCloses #598 from fpj/KAFKA-2905",0
KAFKA-5771; org.apache.kafka.streams.state.internals.Segments#segments method returns incorrect results when segments were added out of orderSuggested fix for the bugAuthor: radzish <radzish@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3737 from radzish/KAFKA-5771,0
"KAFKA-12835: Topic IDs can mismatch on brokers (after interbroker protocol version update) (#10754)Upon upgrading to IBP 2.8, topic ID can end up getting reassigned which can cause errors in LeaderAndIsr handling when the partition metadata files from the previous ID are still on the broker. Topic IDs are stored in the TopicZNode. The behavior of the code before this fix is as follows:Consider we had a controller with IBP 2.8+. Each topic will be assigned topic IDs and LeaderAndIsr requests will write partition.metadata files to the brokers. If we re-elect the controller and end up with a controller with an older IBP version and we reassign partitions, the TopicZNode is overwritten and we lose the topic ID. Upon electing a 2.8+ IBP controller, we will see the TopicZNode is missing a topic ID and will generate a new one. If the broker still has the old partition metadata file, we will see an ID mismatch that causes the error.This patch changes controller logic so that we maintain the topic ID in the controller and the ZNode even when IBP < 2.8. This means that in the scenario above, reassigning partitions will not result in losing the topic ID and reassignment.Topic IDs may be lost when downgrading the code below version 2.8, but upon re-upgrading to code version 2.8+, before bumping the IBP, all partition metadata files will be deleted to prevent any errors.Reviewers:  Lucas Bradstreet <lucas@confluent.io>, David Jacot <djacot@confluent.io>",5
MINOR: fix omitted 'next.' in interactive queries documentation (#7883)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-5674; Reduce max.connections.per.ip minimum to 0 (#3610)By allowing `max.connections.per.ip` to be 0, Kafka can support IP-based filtering using `max.connections.per.ip.overrides`.",1
"MINOR: Improve Join integration test coverage, PART II1. Replaced KStreamKTableJoinIntegrationTest with the abstract based StreamTableJoinIntegrationTest. Added details on per-step verifications.2. Minor renaming on GlobalKTableIntegrationTest.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #4419 from guozhangwang/KMinor-join-integration-tests-II",3
"KAFKA-12343: Handle exceptions better in TopicAdmin, including UnsupportedVersionException (#10158)Refactored the KafkaBasedLog logic to read end offsets into a separate method to make it easier to test. Also changed the TopicAdmin.endOffsets method to throw the original UnsupportedVersionException, LeaderNotAvailableException, and TimeoutException rather than wrapping, to better conform with the consumer method and how the KafkaBasedLog retries those exceptions.Added new tests to verify various scenarios and errors.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: move connectorConfig to AbstractHerder (#6820)StandaloneHerder and DistributedHerder have identical implementations of connectorConfig (apart from one line of logging). This commit moves the common implementation of connectorConfig to AbstractHerder.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KQE-289: Replace SerDe with Serde (#11050)Right now, we have scattered uses of `SerDes` throughout the docs. These should be updated to be `Serdes`, as that's what we commonly use now.Reviewers: Boyang Chen <bchen11@outlook.com>",1
MINOR: Update design.htmlSince 0.9.0.1 Configuration parameter log.cleaner.enable is now true by default.Author: Nihed MBAREK <nihedmm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1592 from nihed/patch-1,4
MINOR: add group coordinator test coverage (#6926)Some edge cases are not currently being tested. Add more tests to cover.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-13996: log.cleaner.io.max.bytes.per.second can be changed dynamically (#12296)log.cleaner.io.max.bytes.per.second cannot be changed dynamically using bin/kafka-configs.sh. Call updateDesiredRatePerSec() of Throttler with new log.cleaner.io.max.bytes.per.second value in reconfigure() of Log Cleaner to fix the issue.Reviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>",0
KAFKA-9921: explicit handling of null values with retainDuplicates (#8626)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-7467; NoSuchElementException is raised because controlBatch is empty (#5727)This patch adds checks before reading the first record of a control batch. If the batch is empty, it is treated as having already been cleaned. In the case of LogCleaner this means it is safe to discard. In the case of ProducerStateManager it means it shouldn't cause state to be stored because the relevant transaction has already been cleaned. In the case of Fetcher, it just preempts the check for an abort. In the case of GroupMetadataManager, it doesn't process the offset as a commit. The patch also adds isControl to the output of DumpLogSegments. Changes were tested with unit tests, except the DumpLogSegments change which was tested manually.",3
KAFKA-10095: Add stricter assertion in LogCleanerManagerTest (#12004)Reviewers: Mickael Maison <mickael.maison@gmail.com>,3
"KAFKA-10636; Bypass log validation and offset assignment for writes from the raft leader (#9739)Since the Raft leader is already doing the work of assigning offsets and the leader epoch, we can skip the same logic in `Log.appendAsLeader`. This lets us avoid an unnecessary round of decompression.Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Exclude '**/*Suite.class' from test, unitTest and integrationTest (#8381)The tasks `unitTest` and `integrationTest` used to run tests don't excludethe ```**/*Suite``` so the tests included by Suite class are executed twice.For example:```11:42:25 org.apache.kafka.streams.integration.StoreQuerySuite > org.apache.kafka.streams.integration.QueryableStateIntegrationTest.shouldBeAbleToQueryMapValuesState STARTED11:42:26 11:42:26 org.apache.kafka.streams.integration.GlobalKTableIntegrationTest > shouldKStreamGlobalKTableJoin PASSED11:42:30 11:42:30 org.apache.kafka.streams.integration.StoreQuerySuite > org.apache.kafka.streams.integration.QueryableStateIntegrationTest.shouldBeAbleToQueryMapValuesState PASSED...11:48:42 org.apache.kafka.streams.integration.QueryableStateIntegrationTest > shouldBeAbleToQueryMapValuesState STARTED11:48:46 11:48:46 org.apache.kafka.streams.integration.QueryableStateIntegrationTest > shouldBeAbleToQueryMapValuesState PASSED```For consistency, move the existing exclusion for the `test` task from the`streams` project to `subprojects`.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-3652; Return error response for unsupported version of ApiVersionsRequestHandle unsupported version of ApiVersionsRequest during SASL auth as well as normal operation by returning an error response.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1310 from rajinisivaram/KAFKA-3652",5
MINOR: A few code cleanups in DynamicBrokerConfig (#12015)Reviewers: Luke Chen <showuon@gmail.com>,5
"KAFKA-2300: follow-up to clear the controller state upon resignmentI have reopened this issue because the controller isn't cleaning up the state upon an exception and the test case was legitimately failing for me every now and then. I'm proposing a change to fix this.Author: fpj <fpj@apache.org>Author: flavio junqueira <fpj@apache.org>Reviewers: Ismael Juma, Gwen Shapira, Guozhang WangCloses #212 from fpj/2300",0
MINOR: Add toString implementations to Subscription and AssignmentAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1354 from hachikuji/minor-add-missing-assignor-tostrings,1
"KAFKA-8286; Generalized Leader Election Admin RPC (KIP-460) (#6686)Implements KIP-460: https://cwiki.apache.org/confluence/display/KAFKA/KIP-460%3A+Admin+Leader+Election+RPC.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13015: Ducktape System Tests for Metadata Snapshots (#11053)This PR implements system tests in ducktape to test the ability of brokers and controllers to generateand consume snapshots and catch up with the metadata log.Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",2
MINOR: Change the log level from ERROR to DEBUG when failing to get plugin loader for connector (#7964)Reviewers: Jason Gustafson <jason@confluent.io>,5
HOTFIX: fix failed build caused by StreamThreadTest (#9691)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-2579; prevent unauthorized clients from joining groupsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #240 from hachikuji/KAFKA-2579,5
"KAFKA-9047; AdminClient group operations should respect retries and backoff (#8161)Previously, `AdminClient` group operations did not respect a `Call`'s number of configured tries and retry backoff. This could lead to tight retry loops that put a lot of pressure on the broker. This PR introduces fixes that ensures for all group operations the `AdminClient` respects the number of tries and the backoff a given `Call` has.Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10811: Correct the MirrorConnectorsIntegrationTest to correctly mask the exit procedures (#9698)Normally the `EmbeddedConnectCluster` class masks the `Exit` procedures using within the Connect worker. This normally works great when a single instance of the embedded cluster is used. However, the `MirrorConnectorsIntegrationTest` uses two `EmbeddedConnectCluster` instances, and when the first one is stopped it would reset the (static) exit procedures, and any problems during shutdown of the second embedded Connect cluster would cause the worker to shut down the JVM running the tests.Instead, the `MirrorConnectorsIntegrationTest` class should mask the `Exit` procedures and instruct the `EmbeddedConnectClusters` instances (via the existing builder method) to not mask the procedures.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-3440: Update streams javadocs- add class doc for KTable, KStream, JoinWindows- add missing return tagsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Michael G. Noll <michael@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1287 from mjsax/kafka-3440-JavaDoc",2
KAFKA-13059: Make DeleteConsumerGroupOffsetsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11019)This patch improves the error handling in `DeleteConsumerGroupOffsetsHandler`. `COORDINATOR_NOT_AVAILABLE` is not unmapped to trigger a new find coordinator request to be sent out.Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-901: Follow up minor changes,4
"KAFKA-6761: Construct Physical Plan using Graph, Reduce streams footprint part III (#5201)The specific changes in this PR from the second PR include:1. Changed the types of graph nodes to names conveying more context2. Build the entire physical plan from the graph, after StreamsBuilder.build() is called.Other changes are addressed directly as review comments on the PR.Testing consists of using all existing streams tests to validate building the physical plan with graphReviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-6560: Use single query for getters as well (#4814)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
MINOR: Use SL4J string interpolation instead of string concatenation (#5113)Also tweak logging message slightly and use Records.LOG_OVERHEAD definition.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-1233 Adding the new test file,2
Polish Javadoc for EpochState (#11897)Polish Javadoc for EpochStateReviewers: Bill Bejeck <bbejeck@apache.org>,2
"MINOR: Fix JavaDoc for StreamsConfig.PROCESSING_GUARANTEE_CONFIGThe contribution is my original work and I license the work to the project under the project's open source licence.Author: lperry <lperry@simplemachines.com.au>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3843 from leigh-perry/trunk",1
"KAFKA-3425: add missing upgrade notesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke, Ashish Singh, Ismael Juma, Guozhang WangCloses #1159 from hachikuji/KAFKA-3425",5
"KAFKA-9673: Filter and Conditional SMTs (#8699)Implemented KIP-585 to support Filter and Conditional SMTs. Added unit tests and integration tests.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
trivial 0.9.0 doc changes to AclCommand,4
"KAFKA-7831; Do not modify subscription state from background thread (#6221)Metadata may be updated from the background thread, so we need to protect access to SubscriptionState. This patch restructures the metadata handling so that we only check pattern subscriptions in the foreground. Additionally, it improves the following:1. SubscriptionState is now the source of truth for the topics that will be fetched. We had a lot of messy logic previously to try and keep the the topic set in Metadata consistent with the subscription, so this simplifies the logic.2. The metadata needs for the producer and consumer are quite different, so it made sense to separate the custom logic into separate extensions of Metadata. For example, only the producer requires topic expiration.3. We've always had an edge case in which a metadata change with an inflight request may cause us to effectively miss an expected update. This patch implements a separate version inside Metadata which is bumped when the needed topics changes.4. This patch removes the MetadataListener, which was the cause of https://issues.apache.org/jira/browse/KAFKA-7764. Reviewers: David Arthur <mumrah@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-1398 dynamic config changes are broken.,4
"KAFKA-10198: guard against recycling dirty state (#8924)We just needed to add the check in StreamTask#closeClean to closeAndRecycleState as well. I also renamed closeAndRecycleState to closeCleanAndRecycleState to drive this point home: it needs to be clean.This should be cherry-picked back to the 2.6 branchReviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>,",5
KAFKA-14062: OAuth client token refresh fails with SASL extensions (#12398)- Different objects should be considered unique even with same content to support logout- Added comments for SaslExtension re: removal of equals and hashCode- Also swapped out the use of mocks in exchange for *real* SaslExtensions so that we exercise the use of default equals() and hashCode() methods.- Updates to implement equals and hashCode and add tests in SaslExtensionsTest to confirmCo-authored-by: Purshotam Chauhan <pchauhan@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"MINOR: Fix type inference on joins and aggregates (#5019)The type inference doesn't currently work for the join functions in Scala as it doesn't know yet the types of the given KStream[K, V] or KTable[K, V].The fix here is to curry the joiner function. I personally prefer this notation but this also means it differs more from the Java API.I believe the diff with the Java API is worth in this case as it's not only solving the type inference but also fits better the Scala way of coding (ex: fold).Moreover any Scala dev will bug and spend little time on these functions trying to understand why the type inference is not working and then get frustrated to be obliged to be explicit here where it's not harmful to be inferred.Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
Missing file from KAFKA-828,2
"MINOR: Fix typo in consumer group command error (#4463)The error message lists '--reset-offset' as one of the possibleoptions, but the option is in fact called '--reset-offsets'.",1
MINOR: Fix building from subproject directoryThis patch fixes some releative paths so bulding from a subproject directory like ($rootDir/core) will not failAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Chesklack-PostavaCloses #509 from granthenke/minor,0
"KAFKA-10598: Improve IQ name and type checks (#9408)Previously, we would throw a confusing error, ""the store has migrated,""when users ask for a store that is not in the topology at all, or when thetype of the store doesn't match the QueryableStoreType parameter.Adds an up-front check that the requested store is registered and alsoa better error message when the QueryableStoreType parameterdoesn't match the store's type.Reviewers: Guozhang Wang <guozhang@apache.org>",2
"KAFKA-206 add DISCLAIMER, cleanup NOTICE file; patched by chrisburroughs;reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1203439 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-13676: Commit successfully processed tasks on error (#11791)When we hit an exception when processing tasks we should save the work we have done so far.This will only be relevant with ALOS and EOS-v1, not EOS-v2. It will actually reduce the number of duplicated record in ALOS because we will not be successfully processing tasks successfully more than once in many cases.This is currently enabled only for named topologies.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-2574: Add ducktape based ssl test for KafkaLog4jAppenderAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen Shapira, Geoff AndersonCloses #319 from SinghAsDev/KAFKA-2574",2
"MINOR: add upgrade not for group.initial.rebalance.delay.msAdd a new entry in upgrade.html for `group.initial.rebalance.delay.ms`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #3189 from dguy/relabance-delay",5
allow ReplaceField SMT to handle tombstone records (#7731)Signed-off-by: Lev Zemlyanov <lev@confluent.io>,5
"MINOR: reduce sizeInBytes for percentiles metrics (#8835)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-5913; Add hasOffset() and hasTimestamp() methods to RecordMetadataThese methods help users check for cases in which this metadata was not returned by the broker (e.g. in the case of acks=0 or a duplicate error when idempotence is enabled).Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3878 from apurvam/KAFKA-5913-add-record-metadata-not-available-exception",5
"KAFKA-13010: Retry getting tasks incase of rebalance for TaskMetadata tests (#11083)If there is a cooperative rebalance the tasks might not be assigned to a thread at all for a very short timeframe, causing this test to fail. We can just retry getting the metadata until the group has finished rebalancing and all tasks are assignedReviewers: Bruno Cadonna <cadonna@apache.org>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Josep Prat <josep.prat@aiven.io>",1
"KAFKA-8729: Change `PartitionResponse` to include all troubling records (#7612)Background:Currently, whenever a batch is dropped because ofInvalidRecordException or InvalidTimestampException, only the culprit record appears in ProduceResponse.PartitionResponse.recordErrors. However, after users try to resend that batch excluding the rejected message, the latter records are not guaranteed to be free of problems.Changes:To address this issue, I changed the function signature of validateKey, validateRecord and validateTimestamp to return a Scala's Option object. Specifically, this object will hold the reason/message the current record in iteration fails and leaves to the callers (convertAndAssignOffsetsNonCompressed, assignOffsetsNonCompressed, validateMessagesAndAssignOffsetsCompressed) to gathered all troubling records into one place. Then, all these records will be returned along with the PartitionResponse object. As a result, if a batch contains more than one record errors, users see exactly which records cause the failure. PartitionResponse.recordErrors is a list of RecordError objects introduced by #7167 which include batchIndex denoting the relative position of a record in a batch and message indicating the reason of failure.Gotchas:Things are particularly tricky when a batch has records rejected because of both InvalidRecordException and InvalidTimestampException. In this case, the InvalidTimestampException takes higher precedence. Therefore, the Error field in PartitionResponse will be encoded with INVALID_TIMESTAMP.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
MINOR: Fix typo in test log4j.propertiesAuthor: Jeff Widman <jeff@jeffwidman.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3851 from jeffwidman/patch-1,5
"MINOR: don't throw CommitFailedException during suspendTasksAndStateAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2535 from dguy/minor-commit-failed",0
MINOR: Add line break so example command is readable without scrolling (#4879),4
"KAFKA-4654: Improve test coverage for MemoryLRUCacheStoreAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2500 from bbejeck/KAFKA-4654_improve_MemroryLRUCache_test_coverage",3
"KAFKA-3356: Remove ConsumerOffsetCheckerAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3036 from mimaison/KAFKA-3356",5
KAFKA-4643; Improve test coverage of StreamsKafkaClientThe commit brings improved test coverage for StreamsKafkaClientTest.javaAuthor: Andrey Dyachkov <andrey.dyachkov@zalando.de>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3663 from adyach/kafka-4643,3
"MINOR: Code cleanup of 'clients' module (#5427)Cleanup involves:* Refactoring to use Java 8 constructs (lambdas,diamond for `empty` collection methods) and librarymethods (`computeIfAbsent`)* Simplifying code (including unnecessarily complex`equals` and `hashCode` implementations)* Removing redundant code* Fixing typosReviewers: Ryanne Dolan, Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-10583: Add documentation on the thread-safety of KafkaAdminClient (#9397)Other than a Stack Overflow comment (see https://stackoverflow.com/a/61738065) by Colin Patrick McCabe and a proposed design note on KIP-117 wiki, there is no source that verifies the thread-safety of KafkaAdminClient.This patch updates JavaDoc of KafkaAdminClient to clarify its thread-safety.Reviewers: Tom Bentley <tbentley@redhat.com>, Chia-Ping Tsai <chia7712@gmail.com>",2
"MINOR: Fix flaky test cases SocketServerTest.remoteCloseWithoutBufferedReceives and SocketServerTest.remoteCloseWithIncompleteBufferedReceive (#11861)When a socket is closed, corresponding channel should be retained only if there is complete buffered requests.Reviewers: David Jacot <djacot@confluent.io>",5
HOTFIX: remove reference to unused Assignment error code (#7645)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-8875; CreateTopic API should check topic existence before replication factor (#7298)If the topic already exists, `handleCreateTopicsRequest` should return TopicExistsException even given an invalid config (replication factor for instance).Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-9553; Improve measurement for loading groups and transactions (#8155)This patch modifies the loading time metric to account for time spent waiting for the loading time task to be scheduled.Reviewers: Jason Gustafson <jason@confluent.io>,5
kafka-832; System Test - set retry.backoff.ms=300 to all test cases; patched by John Fung; reviewed by Jun Rao,3
KAFKA-6764: Improve the whitelist command-line option for console-consumer (#5637),1
"MINOR: Check against empty replicas in AlterPartitionReassignments (#7574)Do not allow an empty replica set to be passed into the reassignment API.Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",4
KAFKA-4415; Reduce time to create and send UpdateMetadataRequestAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #2169 from lindong28/KAFKA-4415-2nd,5
"MINOR: Build modules in parallel (#9975)- According to https://docs.gradle.org/current/userguide/performance.html#parallel_execution,gradle executes builds serially by default.- With this change, the build performance is significantly better (~2x) on multi-core machinesThe time to run the following command went from 7m20s to 3m34s on one machine:`clean install assemble spotlessScalaCheck checkstyleMain checkstyleTest spotbugsMain`Reviewers: Ismael Juma <ismael@juma.me.uk>",0
KAFKA-5994; Log ClusterAuthorizationException for all ClusterAction requestsAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #5021 from omkreddy/KAFKA-5994-CLUSTER-AUTH,5
KAFKA-3421; Follow up to fix name of SourceTask method and add documentation of connector status REST APIAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1355 from ewencp/kafka-3421-follow-up,2
KAFKA-13078: Fix a bug where we were closing the RawSnapshotWriter to early (#11040)Reviewers: David Arthur <mumrah@gmail.com>,0
kafka-918; Change log.retention.hours to be log.retention.mins; patched by Alin Vasile; reviewed by Jun Rao,2
"KAFKA-13019: Add MetadataImage and MetadataDelta classes for KRaft Snapshots (#10949)Create the image/ module for storing, reading, and writing broker metadata images.Metadata images are immutable. New images are produced from existing imagesusing delta classes. Delta classes are mutable, and represent changes to a baseimage.MetadataImage objects can be converted to lists of KRaft metadata records. Thisis essentially writing a KRaft snapshot. The resulting snapshot can be readback into a MetadataDelta object. In practice, we will typically read thesnapshot, and then read a few more records to get fully up to date. After that,the MetadataDelta can be converted to a MetadataImage as usual.Sometimes, we have to load a snapshot even though we already have an existingnon-empty MetadataImage. We would do this if the broker fell too far behind andneeded to receive a snapshot to catch up. This is handled just like the normalsnapshot loading process. Anything that is not in the snapshot will be markedas deleted in the MetadataDelta once finishSnapshot() is called.In addition to being used for reading and writing snapshots, MetadataImage alsoserves as a cache for broker information in memory. A follow-up PR will replaceMetadataCache, CachedConfigRepository, and the client quotas cache with thecorresponding Image classes. TopicsDelta also replaces the ""deferredpartition"" state that the RaftReplicaManager currently implements. (That changeis also in a follow-up PR.)Reviewers: Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>",5
KAFKA-2778: Use zero loss settings by default for Connect source producers.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #459 from ewencp/kafka-2778-connect-source-zero-loss-settings,1
KAFKA-2407: Only create log directory when it will be usedAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #115 from granthenke/log-fix and squashes the following commits:de36138 [Grant Henke] Small comment fix49a8dd4 [Grant Henke] KAFKA-2407: Only create log directory when it will be used,1
KAFKA-730: Update zookeeper classpath in system_test/migration_tool_testsuite/0.7/bin/kafka-run-class.sh; reviewed by Neha Narkhede,5
KAFKA-13439: Deprecate eager rebalance protocol in kafka stream (#11490)Deprecate eager rebalancing protocol in kafka streams and log warning message when upgrade.from is set to 2.3 or lower. Also add a note in upgrade doc to prepare users for the removal of eager rebalancing supportReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
"KAFKA-8011: Fix flaky RegexSourceIntegrationTest (#8799)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-2072: Add StopReplica request/response to o.a.k.common.requestsThis PR adds StopReplica request and response as it is required by ijuma for KAFKA-2411. Migration of core module is addressed a separate PR (#141).ijuma Could you review it? gwenshap Could you take a look as well?Author: David Jacot <david.jacot@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #170 from dajac/KAFKA-2072-part-1",1
KAFKA-2667; Fix assertion depending on hash map order in KafkaBasedLogTest.testSendAndReadToEndAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #642 from hachikuji/KAFKA-2667,5
Minor fix in the broker failure test for clean shutdown of serversgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1230759 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-141; Added the ASF header to the kafka source and test files where it was missing, deleted the CONTRIBUTORS file to match the convention of other Apache projects; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179788 13f79535-47bb-0310-9956-ffa450edef68",1
MINOR: GroupCoordinator can append with group lockAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3133 from hachikuji/minor-replica-manager-append-refactor,4
KAFKA-4679: Remove unstable markers from Connect APIsewencp ignore this PR if you are already started to work on this ticket.Author: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2423 from baluchicken/KAFKA-4679(cherry picked from commit 1434b61d5d5511e5297d6ad81e2417db157986aa)Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>,5
"MINOR: Refactor admin client helpers for checking leader and ISR (#7074)Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7312: Change broker port used in testMinimumRequestTimeouts and testForceClosePort 22 is used by ssh, which causes the AdminClient to throw an OOM:> java.lang.OutOfMemoryError: Java heap space> at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)> at java.nio.ByteBuffer.allocate(ByteBuffer.java:335)> at org.apache.kafka.common.memory.MemoryPool$1.tryAllocate(MemoryPool.java:30)> at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:112)> at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:424)> at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:385)> at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:640)> at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:561)> at org.apache.kafka.common.network.Selector.poll(Selector.java:472)> at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:535)> at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1140)> at java.lang.Thread.run(Thread.java:748)>>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #6360 from omkreddy/KAFKA-7312",1
"MINOR: Fix typo in connect integration test class name (#7976)Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10283; Consolidate client-level and consumer-level assignment within ClientState (#9640)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Mx4jLoader always returns false even if mx4j is loaded & startedMx4jLoader.scala should explicitly `return true` if the class is successfully loaded and started, otherwise it will return false even if the class is loaded.Author: Edward Ribeiro <edward.ribeiro@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2295 from eribeiro/mx4jloader-bug",0
"KAFKA-6148; ClassCastException in connectors that include kafka-clients packages (#4457)Exclusion for packages that need not be loaded in isolation needs to be extended to all the `org.apache.kafka` packages (that do not belong to transforms and the other whitelisted packages). Most notably, this refers to any classes in `kafka-clients` package. Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13279: allow CreateTopicsPolicy, AlterConfigsPolicy in KRaft mode (#11310)Add support for CreateTopicsPolicy and AlterConfigsPolicy when running in KRaft mode.Reviewers: David Arthur <mumrah@gmail.com>, Niket Goel <ngoel@confluent.io>",5
"MINOR: Use `PartitionResponse.errorMessage` in exceptions in KafkaProducer (#9450)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",0
"MINOR: fix ProduceBenchWorker not to fail on final produce (#7254)When sending bad records, the Trogdor task will fail if the final record produced is bad. Instead we should catch the exception to allow the task to finish since sending bad records is a valid use case.Reviewers: Tu V. Tran <tuvtran97@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
MINOR: reduce amount of verbose printingAuthor: Eno Thereska <eno@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2764 from enothereska/minor-remove-verboseprint,4
"KIP-825: Part 1, add new RocksDBTimeOrderedWindowStore (#11802)Initial State store implementation for TimedWindow and SlidingWindow.RocksDBTimeOrderedWindowStore.java contains one RocksDBTimeOrderedSegmentedBytesStore which contains index and base schema.PrefixedWindowKeySchemas.java implements keyschema for time ordered base store and key ordered index store.Reviewers: James Hughes, Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-7338: Specify AES128 default encryption type for Kerberos tests (#5586)Java 11 enables aes128-cts-hmac-sha256-128 and aes256-cts-hmac-sha384-192 by default. These are not supported in earlier versions of Java and not supported by Apache DS libraries used by MiniKdc. To ensure that the default kerberos configuration used by Kafka integration and system tests work with all versions of Java 8 and above, configure default_tkt_enctypes and default_tgs_enctypes to use aes128-cts-hmac-sha1-96.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-5903: Added Connect metrics to the worker and distributed herder (KIP-196)Added metrics to the Connect worker and rebalancing metrics to the distributed herder.This is built on top of #3987, and I can rebase this PR once that is merged.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4011 from rhauch/kafka-5903",5
"KAFKA-13111: Re-evaluate Fetch Sessions when using topic IDs (#11331)With the changes for topic IDs, we have a different flow. When a broker receives a request, it uses a map to convert the topic ID to topic names. If the topic ID is not found in the map, we return a top level error and close the session. This decision was motivated by the difficulty to store “unresolved” partitions in the session. In earlier iterations we stored an “unresolved” partition object in the cache, but it was somewhat hard to reason about and required extra logic to try to resolve the topic ID on each incremental request and add to the session. It also required extra logic to forget the topic (either by topic ID if the topic name was never known or by topic name if it was finally resolved when we wanted to remove from the session.)One helpful simplifying factor is that we only allow one type of request (uses topic ID or does not use topic ID) in the session. That means we can rely on a session continuing to have the same information. We don’t have to worry about converting topics only known by name to topic ID for a response and we won’t need to convert topics only known by ID to name for a response.This PR introduces a change to store the ""unresolved partitions"" in the cached partition object. If a version 13+ request is sent with a topic ID that is unknown, a cached partition will be created with that fetch request data and a null topic name. On subsequent incremental requests, unresolved partitions may be resolved with the new IDs found in the metadata cache. When handling the request, getting all partitions will return a TopicIdPartition object that will be used to handle the request and build the response. Since we can rely on only one type of request (with IDs or without), the cached partitions map will have different keys depending on what fetch request version is being used. This PR involves changes both in FetchSessionHandler and FetchSession. Some major changes are outlined below.1. FetchSessionHandler: Forgetting a topic and adding a new topic with the same name -  We may have a case where there is a topic foo with ID 1 in the session. Upon a subsequent metadata update, we may have topic foo with ID 2. This means that topic foo has been deleted and recreated. When sending fetch requests version 13+ we will send a request to add foo ID 2 to the session and remove foo ID 1. Otherwise, we will fall back to the same behavior for versions 12 and below2. FetchSession: Resolving in Incremental Sessions - Incremental sessions contain two distinct sets of partitions. Partitions that are sent in the latest request that are new/updates/forgotten partitions and the partitions already in the session. If we want to resolve unknown topic IDs we will need to handle both cases.    * Partitions in the request  - These partitions are either new or updating/forgetting previous partitions in the session. The new partitions are trivial. We either have a resolved partition or create a partition that is unresolved. For the other cases, we need to be a bit more careful.         * For updated partitions we have a few cases – keep in mind, we may not programmatically know if a partition is an update:            1. partition in session is resolved, update is resolved: trivial             2. partition in session is unresolved, update is unresolved: in code, this is equivalent to the case above, so trivial as well             3. partition in session is unresolved, update is resolved: this means the partition in the session does not have a name, but the metadata cache now contains the name –  to fix this we can check if there exists a cached partition with the given ID and update it both with the partition update and with the topic name.             4. partition in session is resolved, update is unresolved: this means the partition in the session has a name, but the update was unable to be resolved (ie, the topic is deleted) – this is the odd case. We will look up the partition using the ID. We will find the old version with a name but will not replace the name. This will lead to an UNKNOWN_TOPIC_OR_PARTITION or INCONSISTENT_TOPIC_ID error which will be handled with a metadata update. Likely a future request will forget the partition, and we will be able to do so by ID.             5. Two partitions in the session have IDs, but they are different: only one topic ID should exist in the metadata at a time, so likely only one topic ID is in the fetch set. The other one should be in the toForget. We will be able to remove this partition from the session. If for some reason, we don't try to forget this partition — one of the partitions in the session will cause an inconsistent topic ID error and the metadata for this partition will be refreshed — this should result in the old ID being removed from the session. This should not happen if the FetchSessionHandler is correctly in sync.         * For the forgotten partitions we have the same cases:            1. partition in session is resolved, forgotten is resolved: trivial             2. partition in session is unresolved, forgotten is unresolved: in code, this is equivalent to the case above, so trivial as well             3. partition in session is unresolved, forgotten is resolved: this means the partition in the session does not have a name, but the metadata cache now contains the name –  to fix this we can check if there exists a cached partition with the given ID and try to forget it before we check the resolved name case.             4. partition in session is resolved, update is unresolved: this means the partition in the session has a name, but the update was unable to be resolved (ie, the topic is deleted) We will look up the partition using the ID. We will find the old version with a name and be able to delete it.             5. both partitions in the session have IDs, but they are different: This should be the same case as described above. If we somehow do not have the ID in the session, no partition will be removed. This should not happen unless the Fetch Session Handler is out of sync.     * Partitions in the session - there may be some partitions in the session already that are unresolved. We can resolve them in forEachPartition using a method that checks if the partition is unresolved and tries to resolve it using a topicName map from the request. The partition will be resolved before the function using the cached partition is applied.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Ignoring streams tests until there is fix for KAFKA-3354Per discussion with guozhangwang, `ignore` failing streams system tests until fix for KAFKA-3354 is checked in.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Guozhang WangCloses #1031 from granders/ignore-streams-systest",5
"MINOR: add the MetaLogListener, LocalLogManager, and Controller interface. (#10106)Add MetaLogListener, LocalLogManager, and related classes. Theseclasses are used by the KIP-500 controller and broker to interface with theRaft log.Also add the Controller interface. The implementation will be added in a separate PR.Reviewers: Ron Dagostino <rdagostino@confluent.io>, David Arthur <mumrah@gmail.com>",5
KAFKA-7837: Ensure offline partitions are picked up as soon as possible when shrinking ISR (#6202)Check if a partition is offline while iterating all partitions.Reviewers: Jun Rao <junrao@gmail.com>,5
KAFKA-5019; Upgrades notes for idempotent/transactional features and new message formatAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3212 from hachikuji/KAFKA-5019,5
"KAFKA-13958: Expose logdirs total/usable space via Kafka API (KIP-827) (#12248)This implements KIP-827: https://cwiki.apache.org/confluence/display/KAFKA/KIP-827%3A+Expose+logdirs+total+and+usable+space+via+Kafka+APIAdd TotalBytes and UsableBytes to DescribeLogDirsResponseAdd matching getters on LogDirDescriptionReviewers: Tom Bentley <tbentley@redhat.com>, Divij Vaidya<diviv@amazon.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Igor Soarez <soarez@apple.com>",2
MINOR: Increase default timeout for other `wait` methods in `TestUtils`They are now consistent with `waitUntilTrue`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1665 from ijuma/increase-default-wait-until-time,1
MINOR: Fix meaningless message in assertNull validation (#9965)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"MINOR: Fix malformed html in javadoc of `ScramMechanism` (#11625)Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2
"KAFKA-7223: Suppression documentation (#5787)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
improve internal topic integration test (#4437)Reviewers: Damian Guy <damian.guy@gmail.com>,3
"KAFKA-13888; Addition of Information in DescribeQuorumResponse about Voter Lag (#12206)This commit adds an Admin API handler for DescribeQuorum Request and alsoadds in two new fields LastFetchTimestamp and LastCaughtUpTimestamp tothe DescribeQuorumResponse as described by KIP-836.This commit does not implement the newly added fields. Those will beadded in a subsequent commit.Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
HOTFIX: Renamed tests to match expected suffixewencp gwenshap granders could you have a look please? Thanks.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confuent.io>Closes #1096 from enothereska/systest-hotfix-name,5
KAFKA-8025: Fix flaky RocksDB test (#8126)Reviewers: Bill Bejeck <bill@confluent.io>,5
update the quickstart link in readme (#9158)Correct the link to newly polished Kafka website.Reviewers: Boyang Chen <boyang@confluent.io>,5
KAFKA-4480: Report an error in 'kafka-configs' command if the config to be removed does not existAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2218 from vahidhashemian/KAFKA-4480,4
KAFKA-13785: [7/N][Emit final] emit final for sliding window (#12135)This is a copy PR of #12037: Implementation to emit final for sliding window agg. This is authored by lihaosky.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-4977: Fix findbugs issues in connect/runtimeAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2763 from cmccabe/KAFKA-4977",5
MINOR: Use ObjectName.quote instead of URL-encoding for JMX metric tagsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4099 from rajinisivaram/1.0(cherry picked from commit 51bb83d0dce8110b941891eddedba1fe3abdf658)Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>,5
"KAFKA-6431: Shard purgatory to mitigate lock contention (#5338)* Shard purgatory to reduce lock contention* put constant into Object, use foldLeft instead of for loop* watchersForKey -> watchersByKey* Incorporate Jun's comments: use named arguments instead of _, and removean unnecessary lockReviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Java 9/10 fixes, gradle and minor deps update (#4725)* Added dependencies so that Trogdor and Connect work with Java 9 and 10* Updated Jacoco to 0.8.1 so that it works with Java 10* Updated Gradle to 4.6* A few minor version bumps (not related to Java9/10 fixes)I tested manually that we can run ./gradlew test with Java 10after these changes. There are test failures as EasyMockand PowerMock will have to be updated to use a newerASM version. But compiling successfully and most testspassing is progress. :)I also tested manually that Trogdor can be started with Java 10.It previously failed with a ClassNotFoundError.Reviewers: Jason Gustafson <jason@confluent.io>",5
Fixed Spelling. (#5432)Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>,0
"MINOR: Upgrade compression libraries (#11303)lz4-java: 1.7.1 -> 1.8.0The most noteworthy change is the upgrade of theunderlying C library to 1.9.3. Details:* https://github.com/lz4/lz4-java/releases/tag/1.8.0* https://github.com/lz4/lz4/releases/tag/v1.9.3snappy-java: 1.1.8.1 -> 1.1.8.4The most noteworthy change is support for Apple M1.Details:* https://github.com/xerial/snappy-java/releases/tag/1.1.8.2 * https://github.com/xerial/snappy-java/releases/tag/1.1.8.3* https://github.com/xerial/snappy-java/releases/tag/1.1.8.4zstd-jni: 1.5.0-2 -> 1.5.0-4Minor fixes, details:* https://github.com/luben/zstd-jni/releases/tag/v1.5.0-3* https://github.com/luben/zstd-jni/releases/tag/v1.5.0-4Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Luke Chen <showuon@gmail.com>, Josep Prat <josep.prat@aiven.io>",5
"KAFKA-12704: Improve cache access during connector class instantiation in config validations (#10580)Concurrent requests to validate endpoint for the same connector type calls AbstractHerder::getConnector to get the cached connector instances and if the connector hasn't been cached yet then there is a race condition in the AbstractHerder::getConnector method that potentially fails to detect that an instance of the connector has already been created and, as a result, can create another instanceExisting tests are present with enough coverage so no new tests are added.Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"MINOR: fix flaky test test_standby_tasks_rebalance (#12428)* DescriptionIn this test, when third proc join, sometimes there are other rebalance scenarios such as followup joingroup request happens before syncgroup response was received by one of the proc and the previously assigned tasks for that proc is then lost during new joingroup request. This can result in standby tasks assigned as 3, 1, 2. This PR relax the expected assignment of 2, 2, 2 to a range of [1-3].* Some backgroud from Guozhang:I talked to @hao Li offline and also inspected the code a bit, and tl;dr is that I think the code logic is correct (i.e. we do not really have a bug), but we need to relax the test verification a little bit. The general idea behind the subscription info is that:When a client joins the group, its subscription will try to encode all its current assigned active and standby tasks, which would be used as prev active and standby tasks by the assignor in order to achieve some stickiness.When a client drops all its active/standby tasks due to errors, it does not actually report all empty from its subscription, instead it tries to check its local state directory (you can see that from TaskManager#getTaskOffsetSums which populates the taskOffsetSum. For active task, its offset would be “-2” a.k.a. LATEST_OFFSET, for standby task, its offset is an actual numerical number.So in this case, the proc2 which drops all its active and standby tasks, would still report all tasks that have some local state still, and since it was previously owning all six tasks (three as active, and three as standby), it would report all six as standbys, and when that happens the resulted assignment as @hao Li verified, is indeed the un-even one.So I think the actual “issue“ happens here, is when proc2 is a bit late sending the sync-group request, when the previous rebalance has already completed, and a follow-up rebalance has already triggered, in that case, the resulted un-even assignment is indeed expected. Such a scenario, though not common, is still legitimate since in practice all kinds of timing skewness across instances can happen. So I think we should just relax our verification here, i.e. just making sure that each instance has at least one standby replica at the end, not exactly evenly as “2, 2, 2”.Reviewers: Suhas Satish <ssatish@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9685: PT2, avoid unnecessary set creation in ACL matching (#8382)#8261 went a long way to solving some of the ACL performance issues. I don't thinkwe need to create sets at all for the `find` and `isEmpty` calls. ` testAuthorizer` is22% to 62% of the cost after this change:```Before:Benchmark                                (aclCount)  (resourceCount)  Mode  Cnt   Score    Error  UnitsAclAuthorizerBenchmark.testAclsIterator           5             5000  avgt   15   0.430 ±  0.004  ms/opAclAuthorizerBenchmark.testAclsIterator           5            10000  avgt   15   0.980 ±  0.007  ms/opAclAuthorizerBenchmark.testAclsIterator           5            50000  avgt   15  11.191 ±  0.032  ms/opAclAuthorizerBenchmark.testAclsIterator          10             5000  avgt   15   0.880 ±  0.007  ms/opAclAuthorizerBenchmark.testAclsIterator          10            10000  avgt   15   2.642 ±  0.029  ms/opAclAuthorizerBenchmark.testAclsIterator          10            50000  avgt   15  26.361 ±  0.242  ms/opAclAuthorizerBenchmark.testAclsIterator          15             5000  avgt   15   1.655 ±  0.024  ms/opAclAuthorizerBenchmark.testAclsIterator          15            10000  avgt   15   5.276 ±  0.041  ms/opAclAuthorizerBenchmark.testAclsIterator          15            50000  avgt   15  40.702 ±  0.574  ms/opAclAuthorizerBenchmark.testAuthorizer             5             5000  avgt   15   0.202 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            10000  avgt   15   0.233 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            50000  avgt   15   0.424 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10             5000  avgt   15   0.202 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            10000  avgt   15   0.253 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            50000  avgt   15   0.423 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15             5000  avgt   15   0.198 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            10000  avgt   15   0.242 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            50000  avgt   15   0.391 ±  0.002  ms/opJMH benchmarks doneAfter:Benchmark                                (aclCount)  (resourceCount)  Mode  Cnt   Score    Error  UnitsAclAuthorizerBenchmark.testAclsIterator           5             5000  avgt   15   0.504 ±  0.164  ms/opAclAuthorizerBenchmark.testAclsIterator           5            10000  avgt   15   1.038 ±  0.271  ms/opAclAuthorizerBenchmark.testAclsIterator           5            50000  avgt   15  11.767 ±  0.028  ms/opAclAuthorizerBenchmark.testAclsIterator          10             5000  avgt   15   0.827 ±  0.016  ms/opAclAuthorizerBenchmark.testAclsIterator          10            10000  avgt   15   2.801 ±  0.027  ms/opAclAuthorizerBenchmark.testAclsIterator          10            50000  avgt   15  26.157 ±  0.191  ms/opAclAuthorizerBenchmark.testAclsIterator          15             5000  avgt   15   1.814 ±  0.053  ms/opAclAuthorizerBenchmark.testAclsIterator          15            10000  avgt   15   5.420 ±  0.065  ms/opAclAuthorizerBenchmark.testAclsIterator          15            50000  avgt   15  41.372 ±  0.659  ms/opAclAuthorizerBenchmark.testAuthorizer             5             5000  avgt   15   0.064 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            10000  avgt   15   0.070 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            50000  avgt   15   0.240 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10             5000  avgt   15   0.055 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            10000  avgt   15   0.084 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            50000  avgt   15   0.249 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15             5000  avgt   15   0.057 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            10000  avgt   15   0.084 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            50000  avgt   15   0.243 ±  0.001  ms/op```Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"MINOR: Fix ReassignPartitionsClusterTest.testHwAfterPartitionReassignment test (#4781)Reviewers: Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-14097: Separate configuration for producer ID expiry (KIP-854) (#12501)This patch implements ""KIP-854: Separate configuration for producer ID expiry"" as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-854+Separate+configuration+for+producer+ID+expiry.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-5747; Producer snapshot loading should cover schema errorsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3688 from hachikuji/KAFKA-5747",5
"MINOR: Count fix and Type alias refactor in Streams Scala API (#4966)Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-9538; Fix flaky test `testResetOffsetsExportImportPlan` (#6561)This patch adds logic to the test case to ensure that consumer groups are in a valid state prior to attempting offset reset.Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: defineInternal for KIP-405 configs (#11293)We haven't finished implementing KIP-405, therefore we should makeKIP-405 configs as defineInternal.Reviewers: Jun Rao <junrao@gmail.com>",5
"KAFKA-13558: NioEchoServer fails to close resources (#11618)Due to resource leaks in the NioEchoServer, at times it won't startproperly to accept clients and will throw an exception in theServerSocketChannel.accept() call. Previous to this change, the errorwas not being logged. The logged error was that there were too many openfiles. Using the UnixOperatingSystemMXBean, I was able to detect thatuse of the NioEchoServer creates several FDs but does not close them.This then caused the client to never be able to connect to the server,so the waitForCondition failed intermittently.This change closes the internal Selector and the AcceptorThread'sselector so that the file descriptors are reclaimed.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-6937: In-sync replica delayed during fetch if replica throttle is exceeded (#5074)Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>, Ben Stopford <benstopford@gmail.com>",5
"KAFKA-5005: IntegrationTestUtils to override consumer configs and reuse consumer* Producer and Consumer `close` calls were not handled via `try-with-resources`* `cleanRun` unused field removed* Refactored handling of Consumer configuration in `IntegrationTestUtils` to ensure auto-committing of offsets and starting from `earliest`  * As a result reverted https://github.com/apache/kafka/pull/2921 since it's redundant nowAuthor: Armin Braun <me@obrown.io>Reviewers: Matthias J. Sax, Guozhang WangCloses #2920 from original-brownbear/cleanup-it-utils-closing",4
KAFKA-6255; Add ProduceBench to TrogdorAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4245 from cmccabe/KAFKA-6255,5
"KAFKA-5310; reset ControllerContext during resignationThis ticket is all about ControllerContext initialization and teardown. The key points are:1. we should teardown ControllerContext during resignation instead of waiting on election to fix it up. A heapdump shows that the former controller keeps pretty much all of its ControllerContext state laying around.2. we don't properly teardown/reset ControllerContext.partitionsBeingReassigned. This can cause problems when the former controller becomes re-elected as controller at a later point in time.Suppose a partition assignment is initially R0. Now suppose a reassignment R1 gets stuck during controller C0 and an admin tries to ""undo"" R1 (by deleting /admin/partitions_reassigned, deleting /controller, and submitting another reassignment specifying R0). The new controller C1 may succeed with R0. If the controller moves back to C0, it will then reattempt R1 even though that partition reassignment has been cleared from zookeeper prior to shifting the controller back to C0. This results in the actual partition reassignment in zookeeper being unexpectedly changed back to R1.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3122 from onurkaraman/KAFKA-5310",2
KAFKA-4450; Add upgrade tests for 0.10.1 and rename TRUNK to DEV_BRANCH to reduce confusionAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2457 from ewencp/kafka-4450-upgrade-tests,3
"MINOR: fix streams test-utils dependencies (#4821)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: expose commit interval config for SimpleBenchmarkExpose the streams commit interval config for different testing scenarios.Author: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3244 from bbejeck/MINOR_add_commit_config_benchmark,5
"KAFKA-6906: Fixed to commit transactions if data is produced via wall clock punctuation (#5105)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8897 Follow-up: Consolidate the global state stores (#10646)1. When register state stores, add the store to globalStateStores before calling any blocking calls that may throw errors, so that upon closing we would close the stores as well.2. Remove the other list as a local field, and call topology.globalStateStores when needed to get the list.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-5213; Mark a MemoryRecordsBuilder as full as soon as the append stream is closedAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3015 from apurvam/KAFKA-5213-illegalstateexception-in-ensureOpenForAppend",5
"KAFKA-10861; Fix race condition in flaky test `testFencingOnSendOffsets` (#9762)I wasn't able to reproduce the failure locally, but it looks like there is a race condition with the sending of the records in the first producer. The test case assumes that these records have been completed before the call to `sendOffsetsToTransaction`, but they very well might not be. It is even possible for the writes from the second producer to arrive first which would then result in the test failure that we are seeing. The solution is to force the send with `flush()`.Reviewers: Guozhang Wang <guozhang@apache.org>, Boyang Chen <boyang@confluent.io>",5
"MINOR: Test authorization of MetadataRequest with existing and non-existing topics (#5155)A bug in the original KIP-277 submission was caught during code review,but it was not detected by the tests. Fix that gap.Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",0
"KAFKA-3514, Documentations: Add out of ordering in concepts. (#5458)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
Check delete state of topic,4
"KAFKA-3617; Unit tests for SASL authenticatorUnit tests for SASL authenticator, tests for SASL/PLAIN and multiple mechanisms, authorization test for SASL/PLAINAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1273 from rajinisivaram/KAFKA-3617",5
"KAFKA-4001: Improve Kafka Streams Join Semantics (KIP-77) - fixed leftJoin -> outerJoin test bug - simplified to only use values - fixed inner KTable-KTable join - fixed left KTable-KTable join - fixed outer KTable-KTable join - fixed inner, left, and outer left KStream-KStream joins - added inner KStream-KTable join - fixed left KStream-KTable joinAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1777 from mjsax/kafka-4001-joins",5
Expose total metrics through MBeansp; patched by Pierre-Yves Ritschard; reviewed by Jun Rao; KAFKA-140git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1177798 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-4957; Request rate quotas documentationAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3069 from rajinisivaram/KAFKA-4957,5
"KAFKA-3719; Allow underscores in hostnameTechnically this does not strictly adhere to RFC-952 however it is valid for domain names, urls and uris so we should loosen the requirements a tad.Author: Ryan Pridgeon <ryan.n.pridgeon@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1856 from rnpridgeon/KAFKA-3719",1
"MINOR: upgrade to jdk8 8u202Upgrade from 171 to 202. Unpack and install directly from a cached tgz rather than going via the installer deb from webupd8. The installer is still on 8u919 while we want 202.Testing via kafka branch builder jobhttps://jenkins.confluent.io/job/system-test-kafka-branch-builder/2305/Author: Jarek Rudzinski <jarek@confluent.io>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Alex Diachenko <sansanichfb@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #6165 from jarekr/trunk-jdk8-from-tgz",1
"KAFKA-2983: Remove Scala consumers and related code (#5230)- Removed Scala consumers (`SimpleConsumer` and `ZooKeeperConsumerConnector`)and their tests.- Removed Scala request/response/message classes.- Removed any mention of new consumer or new producer in the codewith the exception of MirrorMaker where the new.consumer option wasnever deprecated so we have to keep it for now. The non-codedocumentation has not been updated either, that will be doneseparately.- Removed a number of tools that only made sense in the contextof the Scala consumers (see upgrade notes).- Updated some tools that worked with both Scala and Java consumersso that they only support the latter (see upgrade notes).- Removed `BaseConsumer` and related classes apart from `BaseRecord`which is used in `MirrorMakerMessageHandler`. The latter is a pluggableinterface so effectively public API.- Removed `ZkUtils` methods that were only used by the old consumers.- Removed `ZkUtils.registerBroker` and `ZKCheckedEphemeral` sincethe broker now uses the methods in `KafkaZkClient` and no-one elseshould be using that method.- Updated system tests so that they don't use the Scala consumers exceptfor multi-version tests.- Updated LogDirFailureTest so that the consumer offsets topic wouldcontinue to be available after all the failures. This was necessary for itto work with the Java consumer.- Some multi-version system tests had not been updated to includerecently released Kafka versions, fixed it.- Updated findBugs and checkstyle configs not to refer to deletedclasses and packages.Reviewers: Dong Lin <lindong28@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",4
kafka-1430; Purgatory redesign; patched by Guozhang Wang; reviewed by Jun Rao,5
"KAFKA-8316; Remove deprecated usage of Slf4jRequestLog, SslContextFactory (#6668)* Remove deprecated class Slf4jRequestLog: use Slf4jRequestLogWriter, CustomRequestLog instread.1. Remove '@SuppressWarnings(""deprecation"")' from RestServer#initializeResources, JsonRestServer#start.2. Remove unused JsonRestServer#httpRequest.* Fix deprecated class usage: SslContextFactory -> SslContextFactory.[Server, Client]1. Split SSLUtils#createSslContextFactory into SSLUtils#create[Server, Client]SideSslContextFactory: each method instantiates SslContextFactory.[Server, Client], respectively.2. SSLUtils#configureSslContextFactoryAuthentication is called from SSLUtils#createServerSideSslContextFactory only.3. Update SSLUtilsTest following splittion; for client-side SSL Context Factory, SslContextFactory#get[Need, Want]ClientAuth is always false. (SSLUtilsTest#testCreateClientSideSslContextFactory)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7786; Ignore OffsetsForLeaderEpoch response if epoch changed while request in flight (#6101)There is a race condition in ReplicaFetcherThread, where we can update PartitionFetchState with the new leader epoch (same leader) before handling the OffsetsForLeaderEpoch response with FENCED_LEADER_EPOCH error which causes removing partition from partitionStates, which in turn causes no fetching until the next LeaderAndIsr. This patch adds logic to ensure that the leader epoch doesn't change while an OffsetsForLeaderEpoch request is in flight (which could happen with back-to-back leader elections). If it has changed, we ignore the response.Also added toString() implementation to PartitionData, because some log messages did not show useful info which I found while investigating the above system test failure.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4351; MirrorMaker with new consumer should support comma-separated regexThis makes it consistent with MirrorMaker with the old consumer.Author: huxi <huxi@zhenrongbao.com>Author: amethystic <huxi_2b@hotmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>Closes #2072 from amethystic/kafka-4351_Regex_behavior_change_for_new_consumer",4
KAFKA-12751: Reset AlterIsr in-flight state for duplicate update requests (#10633)Reviewers: David Arthur <david.arthur@confluent.io>,5
MINOR: Use large batches in metrics test for conversion time >= 1ms (#4681),3
MINOR: Fix typo in ConsumerCoordinator commentAuthor: Jeff Widman <jeff@jeffwidman.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4032 from jeffwidman/patch-3,2
"KAFKA-4937: Batch offset fetches in the Consumerchange `consumer.position` so that it always updates any partitions that need an update. Keep track of partitions that `seekToBeginning` in `StoreChangeLogReader` and do the `consumer.position` call after all `seekToBeginning` calls.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang, Jason Gustafson, Ismael JumaCloses #2769 from dguy/kafka-4937",4
KAFKA-10180: Fix security_config caching in system tests (#8917)Reviewers: Jun Rao <junrao@gmail.com>,3
Bug in mirroring code causes mirroring to halt; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-225git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1213990 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Add build_eclipse to .gitignorebuild_eclipse is the configured output directory for eclipse when usingthe gradle eclipse plugin and should be ignoredAuthor: Christopher L. Shannon <christopher.l.shannon@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2569 from cshannon/eclipse-gitignore,1
"MINOR: Improve PlainSaslServer error message for empty tokens (#6249)Empty username or password would result in the ""expected 3 tokens""error instead of ""username not specified"" or ""password not specified"".Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: improve test READMEAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3416 from mjsax/minor-aws,5
"KAFKA-3930; Ensure ipv6 addresses are quoted properly in metrics tagsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Sriharsha Chintalapani <harsha@hortonworks.com>, Jason Gustafson <jason@confluent.io>Closes #1848 from rajinisivaram/KAFKA-3930",5
MINOR: Scala code readability improvementsAuthor: Himani Arora <1himani.arora@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2297 from himani1/refactored_code,4
KAFKA-2281: avoid unnecessary value copying if logAsString is false; reviewed by Guozhang Wang,2
"KAFKA-2555: Fix infinite recursive ensurePartitionAssignment in callback's commitSynchachikuji ewencp I found this problem when adding new consumer to mirror maker which commits offset in the rebalance callback. It is not clear to me why we are triggering rebalance for commitSync() and fetchCommittedOffset(). Can you help review to see if I miss something?Regarding commitSync, After each poll() the partitions will be either assigned to a consumer or it will be already revoked. As long as user is using internal offset map, the offset map will always be valid. i.e. the offset map will always only contain the assigned partitions when commitSync is called. Hence there is no need to trigger a rebalance in commitSync().The same guarantee also apply to fetchCommittedOffset(), isn't the only requirement is to ensure we know the coordinator?Another related issue is that today the IllegalGenerationIdException is a bit confusing. When we receive an IllegalGenerationIdException from heartbeat, we need to use that same generation Id to commit offset and the coordinator will take it. So the generation ID was not really illegal. I will file a ticket for this issue.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jason Gustafson, Guozhang WangCloses #221 from becketqin/KAFKA-2555",0
MINOR: Update security doc    Author: Luke Chen <showuon@gmail.com>    Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
Add ReplicaFetcherThread name to mbean names; kafka-726; patched by Swapnil Ghike; reviewed by Jun Rao,1
KAFKA-10056; Ensure consumer metadata contains new topics on subscription change (#8739)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Use new `Admin` interface instead of `KafkaAdminClient` class (#7232)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-3952: Consumer rebalance verifier never succeed due to type mismatchAuthor: Wan Wenli <wwl.990@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1612 from swwl1992/ticket-KAFKA-3952-fix-consumer-rebalance-verifier,0
"KAFKA-9840; Skip End Offset validation when the leader epoch is not reliable (#8486)This PR provides two fixes:1. Skip offset validation if the current leader epoch cannot be reliably determined.2. Raise an out of range error if the leader returns an undefined offset in response to the OffsetsForLeaderEpoch request.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"HOTFIX: open window segments in order, add segment id check in getSegment* During window store initialization, we have to open segments in the segment id order and update ```currentSegmentId```, otherwise cleanup won't work.* ```getSegment()``` should not create a segment and clean up old segments if the segment id is greater than ```currentSegmentId```. Segment maintenance should be driven not by query but only by data insertion.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #891 from ymatsuda/hotfix2",0
MINOR: change Streams topic-level metrics tag from 'topic-name' to 'topic' (#12310)Changes the tag name from topic-name to just topic to conform to the way this tag is named elsewhere (ie in the clients)Also:    - fixes a comment about dynamic topic routing    - fixes some indentation in MockRecordCollector    - Undoes the changes to KStreamSplitTest.scala and TestTopicsTest which are no longer necessary after this hotfixReviewers: Bruno Cadonna <cadonna@apache.org>,1
kafka-1622; project shouldn't require signing to build; patched by Ivan Lyutov; reviewed by Jun Rao,1
"KAFKA-9548 Added SPIs and public classes/interfaces introduced in KIP-405 for tiered storage feature in Kafka. (#10173)KIP-405 introduces tiered storage feature in Kafka. With this feature, Kafka cluster is configured with two tiers of storage - local and remote. The local tier is the same as the current Kafka that uses the local disks on the Kafka brokers to store the log segments. The new remote tier uses systems, such as HDFS or S3 or other cloud storages to store the completed log segments. Consumers fetch the records stored in remote storage through the brokers with the existing protocol.We introduced a few SPIs for plugging in log/index store and remote log metadata store.This involves two parts1. Storing the actual data in remote storage like HDFS, S3, or other cloud storages.2. Storing the metadata about where the remote segments are stored. The default implementation uses an internal Kafka topic.You can read KIP for more details at https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+StorageReviewers: Jun Rao <junrao@gmail.com>",5
system test testcase_0122 under replication fails due to large # of data loss; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-580git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401356 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-5965: Remove Deprecated AdminClient from Streams Resetter Tool (#4968)Removed usage of deprecated AdminClient from StreamsResetterNo additional tests are required.Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3600; Use ApiVersions to check if broker supports required api versionsAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Jason Gustafson <jason@confluent.io>, Colin P. Mccabe <cmccabe@confluent.io>, Dana Powers <dana.powers@gmail.com>, Gwen Shapira <cshapi@gmail.com>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1251 from SinghAsDev/KAFKA-3600",5
MINOR: only log first exception in RecordCollectorImpl producer callbackAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2726 from dguy/producer-send-exception,2
MINOR: Fix trace logging in ReplicaManager (#4916)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
KAFKA-13064: Make ListConsumerGroupOffsetsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11026)This patch improve the error handling in `ListConsumerGroupOffsetsHandler` and ensures that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-10407: Have KafkaLog4jAppender support `linger.ms` and `batch.size` (#9189)* KAFKA-10407: Have KafkaLog4jAppender `batch.size` and `linger.ms`https://issues.apache.org/jira/browse/KAFKA-10407Currently, KafkaLog4jAppender does not support `batch.size` or `linger.ms` which would otherwise be beneficial in some situations.",1
MINOR: Avoid nulls when deserializing Trogodor JSON (#4688),5
KAFKA-5170; KafkaAdminClientIntegrationTest should wait until metadata is propagated to all brokersAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2976 from cmccabe/KAFKA-5170,5
The ConsumerStats MBean name should include the groupid; patched by Michael Tamm; reviewed by Jun Rao; kafka-547git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1396085 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12252 and KAFKA-12262: Fix session key rotation when leadership changes (#10014)Author: Chris Egerton <chrise@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
MINOR: Remove unnecessary statement from WorkerConnector#doRun (#9653)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-12658: Include kafka-shell jar and dependencies in release tar (#10531)Verified that `./bin/kafka-metadata-shell.sh --help` on the release tarballworks as expected. It failed with a `ClassNotFoundException` before thischange.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Gwen (Chen) Shapira <cshapi@gmail.com>",4
"HOTFIX: fix streams issues* RocksDBStore.putInternal should bypass logging.* StoreChangeLogger should not call context.recordCollector() when nothing to log  * This is for standby tasks. In standby task, recordCollector() throws an exception. There should be nothing to log anyway.* fixed ConcurrentModificationException in StreamThreadguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #877 from ymatsuda/hotfix2",0
"HOTFIX: open window segments on initguozhangwangA window store should open all existing segments. This is important for segment cleanup, and it also ensures that the first fetch() call returns the hits, the values in the search range. (previously, it missed the hits in fetch() immediately after initialization).Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #886 from ymatsuda/hotfix3",0
MINOR: Remove unused local variable in SocketServer (#4669)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-6612: Added logic to prevent increasing partition counts during topic deletionThis patch adds logic in handling the PartitionModifications event, so that if the partition count is increased when a topic deletion is still in progress, the controller will restore the data of the path /brokers/topics/""topic"" to remove the added partitions.Testing done:Added a new test method to cover the bugAuthor: Lucas Wang <luwang@linkedin.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #4666 from gitlw/prevent_increasing_partition_count_during_topic_deletion",4
"KAFKA-9192: fix NPE when for converting optional json schema in structs (#7733)Author: Lev Zemlyanov <lev@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
KAFKA-776 Changing ZK format breaks some tools; reviewed by Neha Narkhede,4
"KAFKA-12265; Move the BatchAccumulator in KafkaRaftClient to LeaderState (#10480)The KafkaRaftClient has a field for the BatchAccumulator that is only used and set when it is the leader. In other cases, leader specific information was stored in LeaderState. In a recent change EpochState, which LeaderState implements, was changed to be a Closable. QuorumState makes sure to always close the previous state before transitioning to the next state. This redesign was used to move the BatchAccumulator to the LeaderState and simplify some of the handling in KafkaRaftClient.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Revert Jetty to 9.4.25 (#8183)9.4.25 renamed closeOutput to completeOutput(https://github.com/eclipse/jetty.project/commit/c5acf965067478784b54e2d241ec58fdb0b2c9fe),which is a method used by recent Jersey versions including thelatest (2.30.1). An example of the error:> java.lang.NoSuchMethodError: org.eclipse.jetty.server.Response.closeOutput()V> at org.glassfish.jersey.jetty.JettyHttpContainer$ResponseWriter.commit(JettyHttpContainer.java:326)The request still completes and hence why no test fails. We should think about howto improve the testing for this kind of problem, but I want to get the fix in before2.5 RC0.Credit to @rigelbm for finding this.Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Andrew Choi <a24choi@edu.uwaterloo.ca>",2
"KAFKA-8509; Add downgrade system test (#7724)This patch adds a basic downgrade system test. It verifies that producing and consuming continues to work before and after the downgrade.Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",1
KAFKA-3682; ArrayIndexOutOfBoundsException thrown bySkimpyOffsetMap.get() when fullLimited number of attempts to number of map slots after the internalpositionOf() goes into linear search mode.Added unit testCo-developed with mimaisonAuthor: edoardo <ecomar@uk.ibm.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1352 from edoardocomar/KAFKA-3682,2
MINOR: fix Streams docs state.dir (#5465)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"MINOR: Increase timeout for starting JMX tool (#5735)In some tests, the check monitoring the JMX tool log output doesn’t quite wait long enough before failing. Increasing the timeout from 10 to 20 seconds.",1
"MINOR: Mention ""per listener"" security overrides in listener.security.protocol.map config docAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Tom Bentley <tbentley@redhat.com>, Ismael Juma <ismael@juma.me.uk>Closes #3951 from omkreddy/KIP-103-DOCS",2
"KIP-101: Alter Replication Protocol to use Leader Epoch rather than High Watermark for TruncationThis PR replaces https://github.com/apache/kafka/pull/2743 (just raising from Confluent repo)This PR describes the addition of Partition Level Leader Epochs to messages in Kafka as a mechanism for fixing some known issues in the replication protocol. Full details can be found here:[KIP-101 Reference](https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation)*The key elements are*:- Epochs are stamped on messages as they enter the leader.- Epochs are tracked in both leader and follower in a new checkpoint file.- A new API allows followers to retrieve the leader's latest offset for a particular epoch.- The logic for truncating the log, when a replica becomes a follower, has been moved from Partition into the ReplicaFetcherThread- When partitions are added to the ReplicaFetcherThread they are added in an initialising state. Initialising partitions request leader epochs and then truncate their logs appropriately.This test provides a good overview of the workflow `EpochDrivenReplicationProtocolAcceptanceTest.shouldFollowLeaderEpochBasicWorkflow()`The corrupted log use case is covered by the test`EpochDrivenReplicationProtocolAcceptanceTest.offsetsShouldNotGoBackwards()`Remaining work: There is a do list here: https://docs.google.com/document/d/1edmMo70MfHEZH9x38OQfTWsHr7UGTvg-NOxeFhOeRew/edit?usp=sharingAuthor: Ben Stopford <benstopford@gmail.com>Author: Jun Rao <junrao@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2808 from benstopford/kip-101-v2",2
MINOR: Fix FileStreamSourceTask to create the reader around System.in when using stdin as the input source.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #251 from ewencp/minor-fix-filestream-stdin-source,2
KAFKA-12238; Implement `DescribeProducers` API from KIP-664 (#9979)Implements the `DescribeProducers` API specified by KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-5431; cleanSegments should not set length for cleanable segment filesFor a compacted topic with preallocate enabled, during log cleaning, LogCleaner.cleanSegments does not have to pre-allocate the underlying file size since we only want to store the cleaned data in the file.It's believed that this fix should also solve KAFKA-5582.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3525 from huxihx/log_compact_test",3
Bump trunk to 3.1.0-SNAPSHOT (#10981)Typical version bumps on trunk following the creation of the 3.0 release branch.Reviewer: Randall Hauch <rhauch@gmail.com>,1
MINOR: fix compilation of ReplicaManagerConcurrencyTest (#11346)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Update introduction.html (#8969),5
"KAFKA-5646; Use KafkaZkClient in DynamicConfigManager and AdminManager* Add AdminZkClient class* Use KafkaZkClient, AdminZkClient  in ConfigCommand, TopicCommand* All the existing tests should workAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #4194 from omkreddy/KAFKA-5646-ZK-ADMIN-UTILS-DYNAMIC-MANAGER",1
KAFKA-7747; Check for truncation after leader changes [KIP-320] (#6371)After the client detects a leader change we need to check the offset of the current leader for truncation. These changes were part of KIP-320: https://cwiki.apache.org/confluence/display/KAFKA/KIP-320%3A+Allow+fetchers+to+detect+and+handle+log+truncation.Reviewers: Jason Gustafson <jason@confluent.io>,5
Message size not checked at the server (patch v3); patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-469git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1378590 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: remove unimplemented SPILL_TO_DISK buffer full strategy (#10571)Remove enum for the spill-to-disk strategy since this hasn't been implemented.Reviewers: Walker Carlson <wcarlson@confluent.io>,5
"MINOR: Upgrade jetty to 9.4.27.v20200227 and jersey to 2.31 (#8859)Upgrade jetty to 9.4.27.v20200227 and jersey to 2.31Also remove the workaround used on previous versions from Connect's SSLUtils. (Reverts KAFKA-9771 - commit ee832d7d)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
"MINOR: Remove call to Exit.exit() to prevent infinite recursion in Connect integration tests (#9015)If we call org.apache.kafka.common.utils.Exit#exit(int code) with code=0, the current implementation will go into an infinite recursion and kill the VM with a stack overflow error. This happens only in integration tests because of the overrides of shutdown procedures and this commit addresses this issue by removing the redundant call to Exit#exit. Reviewers: Lucas Bradstreet <lucas@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: Clean up partition assignment logic (#7249)These are just some ""tidying up"" changes I made when I was preparing to start working on KIP-441.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Add FetchSnapshot API doc in KafkaRaftClient (#10097),2
MINOR: Add back section taken out by mistake (#9544)Reviewers: Matthias J. Sax <mjsax@apache.org>,1
"KAFKA-2601; ConsoleProducer tool shows stacktrace on invalid command parametersAuthor: GabrielNicolasAvellaneda <avellaneda.gabriel@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #269 from GabrielNicolasAvellaneda/KAFKA-2601-fix",0
"KAFKA-8209: Wrong link for KStreams DSL in core concepts doc (#6564)Reviewers Matthias J. Sax <mjsax@apache.org>, Michael Drogalis <michael.drogalis@confluent.io>, Victoria Bialas <vicky@confluent.io>",5
MINOR: add headers support in new api (#5252)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Adding See how Kafka Streams is being used section to Streams pageAuthor: manjuapu <manjula@confluent.io>Author: Manjula K <manjula@kafka-summit.org>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3914 from manjuapu/customer-logo-stream,2
"KAFKA-10261: Introduce the KIP-478 apis with adapters (#9004)Adds the new Processor and ProcessorContext interfacesas proposed in KIP-478. To integrate in a staged fashionwith the code base, adapters are included to convert backand forth between the new and old APIs.ProcessorNode is converted to the new APIs.Reviewers: Boyang Chen <boyang@confluent.io>",5
ZK consumer gets into infinite loop if a message is larger than fetch size; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-160git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1186570 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: drop dbAccessor reference on close (#6254)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-12158; Better return type of RaftClient.scheduleAppend (#10909)This patch improves the return type for `scheduleAppend` and `scheduleAtomicAppend`. Previously we were using a `Long` value and using both `null` and `Long.MaxValue` to distinguish between different error cases. In this PR, we change the return type to `long` and only return a value if the append was accepted. For the error cases, we instead throw an exception. For this purpose, the patch introduces a couple new exception types: `BufferAllocationException` and `NotLeaderException`.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3597; Query ConsoleConsumer and VerifiableProducer if they shutdown cleanlyEven if a test calls stop() on console_consumer or verifiable_producer, it is still possible that producer/consumer will not shutdown cleanly, and will be killed forcefully after a timeout. It will be useful for some tests to know whether a clean shutdown happened or not. This PR adds methods to console_consumer and verifiable_producer to query whether clean shutdown happened or not.hachikuji and/or granders Please review.Author: Anna Povzner <anna@confluent.io>Reviewers: Jason Gustafson, Geoff Anderson, Gwen ShapiraCloses #1278 from apovzner/kafka-3597",5
MINOR: Print lastTimestamp when dumping producer snapshots (#11354)The `LastTimestamp` field is useful because its value is present even when there are no data batches written by a given producerId.Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: updated configs to use one try/catch for serdesremoved `try/catch` from `keySerde` and `valueSerde` methods so only the `try\catch` blocks in `defaultKeySerde` and `defaultValueSerde` perform error handling resulting in correct error message.Author: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3568 from bbejeck/MINOR_ensure_correct_error_messages_for_configs",5
Rename client package from kafka.* to org.apache.kafka.*,2
MINOR: Fix replica_verification_tool.py to handle slight change in output formatThe string representation of TopicPartition was changed to be{topic}-{partitition} consistently in the following commit:f6f56a645bb1c5ec6810c024ba517e43bf77056cAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3890 from ijuma/fix-replica-verification-test,3
"MINOR: Add documentation for foreign-key joins (KIP-213) (#7535)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Fix static mock usage in ThreadMetricsTest (#12454)Before this PR the calls to the static methods on StreamsMetricsImpl were just calls and not a verification on the mock. This miss happened during the switch from EasyMock to Mockito.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
MINOR: Fix indentation in KafkaApis.handleOffsetFetchRequestAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4139 from vahidhashemian/minor/indentation_fix_1710,0
"MINOR: kstream/ktable counting method with default long serdesguozhangwang migunoAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Michael G. Noll, Guozhang WangCloses #1065 from ymatsuda/count_serdes",5
"MINOR: don't log config during unit tests (#5671)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5512; Awake the heartbeat thread when timetoNextHeartbeat is equal to 0Author: Stephane Roset <stephane@roset.me>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3442 from rosets/KAFKA-5512",1
MINOR: Caching layer should forward record timestamp (#5423)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
KAFKA-5014; NetworkClient.leastLoadedNode should check if channel is readyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2813 from ijuma/kafka-5014-least-loaded-node-should-check-if-channel-is-ready,5
KAFKA-10867: Improved task idling (#9840)Use the new ConsumerRecords.metadata() API to implementimproved task idling as described in KIP-695Reviewers: Guozhang Wang <guozhang@apache.org>,1
"MINOR: Add <p>/</p> to connect docs, because HTML render doesn't respect blank linesThis just adds `<p>`/`</p>` to paragraphs in Kafak Connect docs.ewencp are you a good person to review this?Author: Tom Bentley <tbentley@redhat.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4008 from tombentley/MINOR-connect-docs-paragraph",2
"MINOR: Update zookeeper to 3.5.9 (#9977)A few important fixes:* ZOOKEEPER-3829: Zookeeper refuses request after node expansion* ZOOKEEPER-3842: Rolling scale up of zookeeper cluster does not work with reconfigEnabled=false* ZOOKEEPER-3830: After add a new node, zookeeper cluster won't commit any proposal if this new node is leaderFull release notes: https://zookeeper.apache.org/doc/r3.5.9/releasenotes.htmlReviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
"KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted c…KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted comparisonThe >= should be < since we are actually able to renew if the renewTill time is later than the current ticket expiration.Author: Adam Kunicki <adam@streamsets.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #858 from kunickiaj/KAFKA-3198",1
"MINOR: Use underscore for variable initialization in Scala sources (#12534)In Scala it's standard practice to use `_` whenever you are initializing variables. In regard to implementation, for object references, `_` initialization maps to `null` so there is no change in behavior.Reviewers: Mickael Maison <mickael.maison@gmail.com>",4
"KAFKA-3935; Fix test_restart_failed_task system test for SinkTasksFix the test by using a more liberal timeout and forcing more frequent SinkTask.put() calls. Also add some logging to aid future debugging.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1663 from ewencp/kafka-3935-fix-restart-system-test",5
"MINOR: Update default for field in DeleteTopicsRequestWhen using DeleteTopicsRequest with topic IDs, the topic name field should be null. Before, the code was programmatically assigning null, but it will be easier and less error prone to simply set that as the default. Tested using the previously created `DeleteTopicsRequestTest.java` file.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: Fix windows startup scripts to use connect-log4j.properties instead of tools-log4j.properties (#10034)Co-authored-by: Scott Sugar <ssugar@proserveit.com>Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,2
MINOR: Use streaming iterator with decompression buffer when building offset map (#8494)This makes it consistent with the `filterTo` methods.,1
"Revert ""KAFKA-9705 part 1: add KIP-590 request header fields (#9144)"" (#9523)This reverts commit 21dc5231ce9c7398c7ede4dbefa2f2202e06b2d4 as we decide to use Envelope for redirection instead of initial principal.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-12195 Fix synchronization issue happening in KafkaStreams (#9887)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-4306: Shutdown distributed herder with a timeout.ResolvesKAFKA-4306: Connect workers won't shut down if brokers are not availableKAFKA-4154: Kafka Connect fails to shutdown if it has not completed startupAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2201 from kkonstantine/KAFKA-4306-Connect-workers-will-not-shut-down-if-brokers-are-not-available",1
"KAFKA-10525: Emit JSONs with new auto-generated schema (KIP-673) (#9526)This patch updates the request logger to output request and response payloads in JSON. Payloads are converted to JSON based on their auto-generated schema.Reviewers:  Lucas Bradstreet <lucas@confluent.io>, David Mao <dmao@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-5146: remove Connect dependency from Streams module (#10131)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Ismael Juma <ismael@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Remove redundant initialization of `Stats.index` (#4751),5
"KAFKA-8162: IBM JDK Class not found error when handling SASL (#6524)Attempt to load multiple IBM classes but fallback on loading the Sun class if the IBM one is not found.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",0
KAFKA-6298; Added support for location aware logger which fixes log line numbers (#4311)LogContext to have two different implementations of Logger. One will be picked based on availability of LocationAwareLogger API.Reviewers: Jason Gustafson <jason@confluent.io>,5
HOTFIX: removed extra footnote (#6996)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"MINOR: follow-up to KAFKA-2464 for renaming/cleanupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava, Jiangjie Qin, Guozhang WangCloses #354 from hachikuji/KAFKA-2464",5
KAFKA-14015: Reconfigure tasks if configs have been changed for restarted connectors in standalone mode(#12568)Reviewers: Chris Egerton <chrise@aiven.io>,4
"KAFKA-9832: extend Kafka Streams EOS system test (#8440)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Fix group_mode_transactions_test (#9538)KIP-431 (#9099) changed the format of console consumer output to `Partition:$PARTITION\t$VALUE` whereas previously the output format was `$VALUE\t$PARTITION`. This PR updates the message verifier to accommodate the updated console consumer output format.,5
"MINOR: Handle expandIsr in PartitionLockTest and ensure read threads not blocked on write (#7973)Fixed an intermittent failure in the test that was caused by a mocked instance not handling expandIsr. Also updated the test to use the offset from the batch to trigger expandIsr more often. With this change, the test may try to acquire write lock while appends are blocked on read lock, so separated out the test using write lock to make it safer.Reviewers: Jason Gustafson <jason@confluent.io>",5
kafka-1481; Stop using dashes AND underscores as separators in MBean names; patched by Vladimir Tretyakov; reviewed by Joel Koshy and Jun Rao,1
"KAFKA-2490: support new consumer in ConsumerGroupCommandAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang Wang, Jason GustafsonCloses #299 from SinghAsDev/KAFKA-2490",1
"KAFKA-12648: handle MissingSourceTopicException for named topologies (#11600)Avoid throwing a MissingSourceTopicException inside the #assign method when named topologies are used, and just remove those topologies which are missing any of their input topics from the assignment.Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",5
"KAFKA-4944; Fix an ""unread field"" findbugs warning in streams examplesAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2727 from cmccabe/KAFKA-4944",5
KAFKA-2958: Remove duplicate API key mapping functionalityAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #637 from granthenke/api-keys,1
MINOR: Update files with 3.1.0 (#11698)Reviewers: Bill Bejeck <bbejeck@apache.org>,2
"KAFKA-10257 system test kafkatest.tests.core.security_rolling_upgrade_test fails (#9021)security_rolling_upgrade_test may change the security listener and then restart Kafka servers. has_sasl and has_ssl get out-of-date due to cached _security_config. This PR offers a simple fix that we always check the changes of port mapping and then update the sasl/ssl flag.Reviewers:  Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
"KAFKA-4082; Upgrade to Gradle 3.0Also upgrade scoverage (required for compatibility) and remove usage of`useAnt` which doesn't exist in Gradle 3.0It turns out that one cannot even run `gradle` to download the project Gradle version if `useAnt` is used in the build. This is unfortunate (the SBT launcher has much saner behaviour).Release notes: https://docs.gradle.org/3.0/release-notesAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #1774 from ijuma/kafka-4082-support-gradle-3.0",1
kafka-1285; enable log4j in unit test; patched by Jun Rao; reviewed by Neha Narkhede,3
"KAFKA-6867; Corrected the typos in upgrade.html (#4970)Reviewers: Jakob Homan <jghoman@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7183: Add a trogdor test that creates many connections to brokers (#5393)Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Remove redundant `if` condition. (#5697)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-4819: Expose states for active tasks to public APISimple implementation of the feature : [KAFKA-4819](https://issues.apache.org/jira/browse/KAFKA-4819) KAFKA-4819This PR adds a new method `threadStates` to public API of `KafkaStreams` which returns all currently states of running threads and active tasks.Below is a example for a simple topology consuming from topics; test-p2 and test-p4.[{""name"":""StreamThread-1"",""state"":""RUNNING"",""activeTasks"":[{""id"":""0_0"", ""assignments"":[""test-p4-0"",""test-p2-0""], ""consumedOffsetsByPartition"":[{""topicPartition"":""test-p2-0"",""offset"":""test-p2-0""}]}, {""id"":""0_2"", ""assignments"":[""test-p4-2""], ""consumedOffsetsByPartition"":[]}]}, {""name"":""StreamThread-2"",""state"":""RUNNING"",""activeTasks"":[{""id"":""0_1"", ""assignments"":[""test-p4-1"",""test-p2-1""], ""consumedOffsetsByPartition"":[{""topicPartition"":""test-p2-1"",""offset"":""test-p2-1""}]}, {""id"":""0_3"", ""assignments"":[""test-p4-3""], ""consumedOffsetsByPartition"":[]}]}]Author: Florian Hussonnois <florian.hussonnois@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2612 from fhussonnois/KAFKA-4819",5
MINOR: Use ListOffsets request instead of SimpleConsumer in LogOffsetTest (#5227)Included a few clean-ups related to unused variables in tests.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-10895: Gracefully handle invalid JAAS configs (follow up fix) (#9987)Fixes a regression introduced by https://github.com/apache/kafka/pull/9806 in the original fix for KAFKA-10895It was discovered that if an invalid JAAS config is present on the worker, invoking Configuration::getConfiguration throws an exception. The changes from #9806 cause that exception to be thrown during plugin scanning, which causes the worker to fail even if it is not configured to use the basic auth extension at all.This follow-up handles invalid JAAS configurations more gracefully, and only throws them if the worker is actually configured to use the basic auth extension, at the time that the extension is instantiated and configured.Two unit tests are added.Reviewers: Greg Harris <gregh@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
MINOR: Log resource pattern of ACL updates at INFO level (#9578)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"KAFKA-5658; Fix AdminClient request timeout handling bug resulting in continual BrokerNotAvailableExceptionsThe AdminClient does not properly clear calls from the callsInFlight structure.Later, in an effort to clear the lingering call objects, it closes the connectionthey are associated with. This disrupts new incoming calls, which then getBrokerNotAvailableException.This patch fixes this bug by properly removing completed calls from thecallsInFlight structure. It also adds the Call#aborted flag, whichensures that we throw the right exception (TimeoutException instead ofDisconnectException) and only abort a connection once -- even if thereis a similar bug in the future which causes old Call objects to linger.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3584 from cmccabe/KAFKA-5658",5
"KAFKA-7434: Fix NPE in DeadLetterQueueReporter*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Michał Borowiecki <mbor81@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5700 from mihbor/KAFKA-7434",5
"MINOR: Fix streams broker compatibility test.Change the string in the test condition to the one that is loggedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4599 from dguy/broker-compatibility",5
update leaderAndISR in ZK conditionally; patched by Yang Ye; reviewed by Jun Rao; KAFKA-428git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377157 13f79535-47bb-0310-9956-ffa450edef68,5
KAFKA-8848; Update system tests to use new AclAuthorizer (#7374)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"MINOR: follow-up KAFKA-2730 to use two tags for broker id and fetcher id combinationAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #434 from guozhangwang/K2730-hotfix",0
"MINOR: Fix broken Javadoc on [AbstractIndex|OffsetIndex] (#5370)In the javadoc of `AbstractIndex` and `OffsetIndex`, thrown `Exception`s are not imported.",2
KAFKA-10165: Remove Percentiles from e2e metrics (#8882)* Remove problematic Percentiles measurements until the implementation is fixed* Fix leaking e2e metrics when task is closed* Fix leaking metrics when tasks are recycledReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
KAFKA-9102; Increase default zk session timeout and replica max lag [KIP-537] (#7596)This patch increases the default value of `zookeeper.session.timeout` from 6s to 18s and `replica.lag.time.max.ms` from 10s to 30s. This change was documented in KIP-537: https://cwiki.apache.org/confluence/display/KAFKA/KIP-537%3A+Increase+default+zookeeper+session+timeout.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: Close the producer batch append stream when the batch gets full to free up resourcesOf particular importance are compression buffers (64 KB for LZ4, for example).Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2796 from apurvam/idempotent-producer-close-data-stream",5
MINOR: Fix typo in documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang WangCloses #707 from vahidhashemian/typo04/fix_documentation_typos,2
"MINOR: Augment log4j to add generation number in performAssign (#7451)Since generation is private in AbstractCoordinator, I need to modify the generation() to let it return the object directly.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-9601: Stop logging raw connector config values (#8165)Author: Chris Egerton <chrise@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
KAFKA-10722: Described the types of the used state stores (#9607)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: refactored code duplicates in several files (Streams project) (#4357)* Removed code duplicate from GlobalProcessorContextImpl and ProcessorContextImpl to parent class AbstractProcessorContext* Exchanged concrete implementations with interfaces to make code more maintainable* Refactored major code duplicates in InternalTopologyBuilder* Formatted function parameters as per code reviewAdded final to code introduced in this PR* Added missing finals to putNodeGroupName functionRearranged parameters for resetTopicsPattern functionReviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",1
kafka-940; Scala match error in javaapi.Implicits; patched by Joel Koshy; reviewed by Jun Rao,0
"KAFKA-12738: track processing errors and implement constant-time task backoff (#11787)Part 1 in the initial series of error handling for named topologies.*Part 1: Track tasks with errors within a named topology & implement constant-time based task backoffPart 2: Implement exponential task backoff to account for recurring errorsPart 3: Pause/backoff all tasks within a named topology in case of a long backoff/frequent errors for any individual taskReviewers:  Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"MINOR: Use top-level error in `UpdateFeaturesRequest.getErrorResponse` (#9781)The current `getErrorResponse` sets all of the feature errors, but does not set a top-level error. It seems like the whole point of having the top-level error is so that it could be used in cases like this. This patch also updates `errorCounts` in `UpdateFeaturesResponse` so that the top-level error is included.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",0
"KAFKA-3138: 0.9.0 docs still say that log compaction doesn't work on compressed topics.Log compaction is supported on compressed topics as of 0.9.0, so update the docs to reflect that.Author: James Cheng <jylcheng@yahoo.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #807 from wushujames/KAFKA-3138",5
"KAFKA-6318: StreamsResetter should return non-zero return code on error (#4305)Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",0
"KAFKA-4034; Avoid unnecessary consumer coordinator lookupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1720 from hachikuji/KAFKA-4034",5
"KAFKA-3594; After calling MemoryRecords.close() method, hasRoomFor() method should return falseThis exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRoomFor() method. After calling MemoryRecords.close() method, hasRoomFor() method should return false.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma, Grant Henke, Guozhang WangCloses #1249 from omkreddy/KAFKA-3594",0
"KAFKA-8134: `linger.ms` must be a longReviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2
"KAFKA-6503: Parallelize plugin scanningThis is a small change to parallelize plugin scanning.  This may help in some environments where otherwise plugin scanning is slow.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4561 from rayokota/K6503-improve-plugin-scanning",1
KAFKA-8907; Return topic configs in CreateTopics response (KIP-525) (#7380)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"KAFKA-3816: Add MDC logging to Connect runtime (#5743)See https://cwiki.apache.org/confluence/display/KAFKA/KIP-449%3A+Add+connector+contexts+to+Connect+worker+logsAdded LoggingContext as a simple mechanism to set and unset Mapped Diagnostic Contexts (MDC) in the loggers to provide for each thread useful parameters that can be used within the logging configuration. MDC avoids having to modify lots of log statements, since the parameters are available to all log statements issued by the thread, no matter what class makes those calls.The design intentionally minimizes the number of changes to any existing classes, and does not use Java 8 features so it can be easily backported if desired, although per this KIP it will be applied initially only in AK 2.3 and later and must be enabled via the Log4J configuration.Reviewers: Jason Gustafson <jason@conflent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-763 follow up changes; reviewed by Neha Narkhede,4
[Emit final][4/N] add time ordered store factory (#11892)Add factory to create time ordered store supplier.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-3452 Follow-up: Optimize ByteStore ScenariosThis is a refactoring follow-up of https://github.com/apache/kafka/pull/2166. Main refactoring changes:1. Extract `InMemoryKeyValueStore` out of `InMemoryKeyValueStoreSupplier` and remove its duplicates in test package.2. Add two abstract classes `AbstractKeyValueIterator` and `AbstractKeyValueStore` to collapse common functional logics.3. Added specialized `BytesXXStore` to accommodate cases where key value types are Bytes / byte[] so that we can save calling the dummy serdes.4. Make the key type in `ThreadCache` from byte[] to Bytes, as SessionStore / WindowStore's result serialized bytes are in the form of Bytes anyways, so that we can save unnecessary `Bytes.get()` and `Bytes.wrap(bytes)`.Each of these should arguably be a separate PR and I apologize for the mess, this is because this branch was extracted from a rather large diff that has multiple refactoring mingled together and dguy and myself have already put lots of efforts to break it down to a few separate PRs, and this is the only left-over work. Such PR won't happen in the future.Ping dguy enothereska mjsax for reviewsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Jun RaoCloses #2333 from guozhangwang/K3452-followup-state-store-refactor",4
KAFKA-7518: Fix FutureRecordMetadata.get when TimeUnit is not ms (#5815)Also check for timeout before calling `nextRecordMetadata.get`. Added unit testvalidating the fix.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
KAFKA-440 Regression/system test framework; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1376147 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-3165: Fix ignored parameters in the gradle ""All"" tasksAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #835 from granthenke/all-parameters",2
"MINOR: fix ClientQuotasRequestTest (#12107)Fix ClientQuotasRequestTest.testAlterClientQuotasBadIp so that it uses actually unresolvable hostnames.The previous choices ""ip"" and ""abc-123"" are now resolvable.Reviewers: David Jacot <djacot@confluent.io>, Andrew Choi <andrew.choi@uwaterloo.ca>, Divij Vaidya <divijvaidya13@gmail.com>",5
KAFKA-8499: ensure java is in PATH for ducker system tests (#6898)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
"KAFKA-9844; Fix race condition which allows more than maximum number of members(#8454)This patch fixes a race condition in the join group request handling which sometimes results in not enforcing the maximum number of members allowed in a group. Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: log4j template should accept log_levelThe log_level parameter is used in system tests in kafka.py. However the log4j template accepted that parameter in only one place. This led to a large number of DEBUG lines printed even when the intention was to capture only INFO lines. Led to huge log files. Thanks to ijuma for noticing this.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3247 from enothereska/minor-log4j-template-fix,2
KAFKA-323 Add more parameters to the log4j appender. Patch by Jose Quinteiro.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1373067 13f79535-47bb-0310-9956-ffa450edef68,2
"MINOR: Use new consumer API timeout in test (#5217)The old timeout configs no longer take effect, as of53ca52f855e903907378188d29224b3f9cefa6cb. They are replacedby the new one.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Add missing imports to 'Hello Kafka Streams' examples (#4535)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1029 Zookeeper leader election stuck in ephemeral node retry loop; reviewed by Neha and Guozhang,1
"KAFKA-2355;  Add an unit test to validate the deletion of a partition marked as deleted; patched by Edward Ribeiro, reviewed by Ashish Singh, Ismael Juma and Grant Henke",4
MINOR: Ignore dynamic log4j log level tests (#7183)We recently introduced a bunch of flaky tests in the AdminClientIntegrationTest.These tests are failing very frequently. We should ignore the tests in order tomake the build stable until we have a fix.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
MINOR: Allow Checkpoints for consumers using static partition assignments (#9545)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
MINOR: Improve log message in `ReplicaManager.becomeLeaderOrFollower`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1789 from ijuma/improve-log-message-in-replica-manager,2
"KAFKA-5345; Close KafkaClient when streams client is closedAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3195 from rajinisivaram/KAFKA-5345",5
"KAFKA-10163; Define `controller_mutation_rate` as a Double instead of a Long (#9092)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-13412; Ensure initTransactions() safe for retry after timeout (#11452)If the user's `initTransactions` call times out, the user is expected to retry. However, the producer will continue retrying the `InitProducerId` request in the background. If it happens to return before the user retry of `initTransactions`, then the producer will raise an exception about an invalid state transition. The patch fixes the issue by tracking the pending state transition until the user has acknowledged the operation's result. In the case of `initTransactions`, even if the `InitProducerId` returns in the background and the state changes, we can still retry the `initTransactions` call to obtain the result.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: Correct MirrorMaker2 integration test configs for Connect internal topics (#8653)The replication factor for the Connect workers’ internal topics were incorrectly named and not actually used.,1
kafka-866; Recover segment does shallow iteration to fix index causing inconsistencies; patched by Sriram Subramanian; reviewed by Jun Rao,1
"MINOR: Clarify 0.10.1.0 upgrade docsThis is a minor change to fix the most glaring issues. We have another JIRA to revamp the upgrade docs.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jeff Klukas <jeff@klukas.net>, Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1971 from ijuma/kafka-4257-upgrade-docs-inconsitencies",2
"KAFKA-5692: Change PreferredReplicaLeaderElectionCommand to use Admin… (#3848)See also KIP-183.This implements the following algorithm:AdminClient sends ElectPreferredLeadersRequest.KafakApis receives ElectPreferredLeadersRequest and delegates toReplicaManager.electPreferredLeaders()ReplicaManager delegates to KafkaController.electPreferredLeaders()KafkaController adds a PreferredReplicaLeaderElection to the EventManager,ReplicaManager.electPreferredLeaders()'s callback uses thedelayedElectPreferredReplicasPurgatory to wait for the results of theelection to appear in the metadata cache. If there are no resultsbecause of errors, or because the preferred leaders are already leadingthe partitions then a response is returned immediately.In the EventManager work thread the preferred leader is elected as follows:The EventManager runs PreferredReplicaLeaderElection.process()process() calls KafkaController.onPreferredReplicaElectionWithResults()KafkaController.onPreferredReplicaElectionWithResults()calls the PartitionStateMachine.handleStateChangesWithResults() toperform the election (asynchronously the PSM will send LeaderAndIsrRequestto the new and old leaders and UpdateMetadataRequest to all brokers)then invokes the callback.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jun Rao <junrao@gmail.com>",5
"KAFKA-7439; Replace EasyMock and PowerMock with Mockito in clients moduleDevelopment of EasyMock and PowerMock has stagnated while Mockitocontinues to be actively developed. With the new Java release cadence,it's a problem to depend on libraries that do bytecode manipulationand are not actively maintained. In addition, Mockito is alsoeasier to use.While updating the tests, I attempted to go from failing test topassing test. In cases where the updated test passed on the firstattempt, I artificially broke it to ensure the test was still doing itsjob.I included a few improvements that were helpful while making thesechanges:1. Better exception if there are no nodes in `leastLoadedNodes`2. Always close the producer in `KafkaProducerTest`3. requestsInFlight producer metric should not hold a reference to`Sender`Finally, `Metadata` is no longer final so that we don't need`PowerMock` to mock it. It's an internal class, so it's OK.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5691 from ijuma/kafka-7438-mockito",5
MINOR: Pass along compression type to snapshot writer (#11556)Make sure that the compression type is passed along to the `RecordsSnapshotWriter` constructor when creating the snapshot writer using the static `createWithHeader` method.Reviewers: Jason Gustafson <jason@confluent.io>,5
Some new unit tests for ByteBufferMessageSet iterator KAFKA-108; patched by Jun; reviewed by Nehagit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159461 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Read configuration fields from ProducerConfig in example (#4601)Reading the configuration field names from ProducerConfig class and taking the key and value serializer names from class name directly instead of hardcoding.,5
"KAFKA-12484: Enable Connect's connector log contexts by default (KIP-721) (#10335)Change the `connect-log4j.properties` file to use the connector log context by default.This feature was previously defined in KIP-449, but was not enabled by default.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
KAFKA-8183: Add retries to WorkerUtils#verifyTopics (#6532)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-8785: fix request timeout by waiting for metadata cache up-to-date (#11681)The reason why this test is flaky is because we have race condition at the beginning of the test, when brokers are staring up, and the adminClient is requesting for brokers metadata. Once the adminClient only got partial metadata, the test will fail, because in these tests, brokers will be shutdown to test leader election.Fix this issue by explicitly waiting for metadata cache up-to-date in waitForReadyBrokers, and let admin client get created after waitForReadyBrokers.Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",5
KAFKA-12841: Remove an additional call of onAcknowledgement (#12064)The bug was introduced in #11689 that an additional onAcknowledgement was made using the InterceptorCallback class. This is undesirable since onSendError will attempt to call onAcknowledgement once more.Reviewers: Jun Rao <junrao@gmail.com>,0
"MINOR: Print all removed dynamic members during join complete (#8816)For better visibility on the group rebalance, we are trying to print out the evicted members inside the group coordinator during rebalance complete.Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Add documentation for KAFKA-6086 (ProductionExceptionHandler) (#4395)* Update streams documentation to describe production exception handler* Add a mention of the ProductionExceptionHandler in the upgrade guide,0
KAFKA-5108; Add support for reading PID snapshot files to DumpLogSegmentsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2922 from hachikuji/KAFKA-5108,5
"MINOR: Stop using hamcrest in system tests (#10631)We currently use hamcrest imports to check the outputs of the RelationalSmokeTest, but with the new gradle updates, the proper hamcrest imports are no longer included in the test jar.This is a bit of a workaround to remove the hamcrest usage so we can get system tests up and running again. Potential follow-up could be to update the way we create the test-jar to pull in the proper dependencies.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
MINOR:  Support listener config overrides in system tests (#6981)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: Fix ClassCastException in ConsumerGroupCommandOffset and partition are not converted from String tolong and int correctly.Running the command line with --from-file option causesthe following exception:java.lang.ClassCastException: java.lang.String cannot becast to java.lang.IntegerReason: asInstanceOf used for the conversion.Also, unit test is using --to-earliest and --from-filetogether when executing the test. This is executing--to-earliest option only and ignoring --from-fileoption. Since the preparation part is also using--to-earliest to create the file, this unit testpasses without testing --from-file option. Fixedthe unit test too.Author: Erkan Unal <eunal@cisco.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3938 from eu657/eu657-patch-1",3
KAFKA-13923; Generalize authorizer system test for kraft (#12190)Change `ZookeeperAuthorizerTest` to `AuthorizerTest` and add support for KRaft's `StandardAuthorizer` implementation.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-10487; Fetch response should return diverging epoch and end offset (#9290)This patch changes the Fetch response schema to include both the diverging epoch and its end offset rather than just the offset. This allows for more accurate truncation on the follower. This is the schema that was originally specified in KIP-595, but we altered it during the discussion.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Remove magic number and extract Pattern instance from method as class field (#4799)* Remove magic number* Extract Pattern instance from method as class field* Add @Override declareReviewers: Randall Hauch <rhauch@gmail.com>,1
KAFKA-1485 Upgrade to Zookeeper 3.4.6 patch by Gwen Shapira reviewed by Joe Stein,5
"MINOR: Switch anonymous classes to lambda expressions in tools moduleSwitch to lambda when ever possible instead of old anonymous wayin tools moduleAuthor: Srinivas Reddy <srinivas96alluri@gmail.com>Author: Srinivas Reddy <mrsrinivas@users.noreply.github.com>Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6013 from mrsrinivas/tools-switch-to-java8",5
KAFKA-647 Provide a property in System Test for no. of topics and topics string will be generated automatically; reviewed by Neha Narkhede,3
"KAFKA-10521; Skip partition watch registration when `AlterIsr` is expected (#9353)Before `AlterIsr` which was introduced in KIP-497, the controller would register watches in Zookeeper for each reassigning partition so that it could be notified immediately when the ISR was expanded and the reassignment could be completed. This notification is not needed with the latest IBP when `AlterIsr` is enabled because the controller will execute all ISR changes itself.There is one subtle detail. If we are in the middle of a roll in order to bump the IBP, then it is possible for the controller to be on the latest IBP while some of the brokers are still on the older one. In this case, the brokers on the older IBP will not send `AlterIsr`, but we can still rely on the delayed notification through the `isr_notifications` path to complete reassignments. This seems like a reasonable tradeoff since it should be a short window before the roll is completed.Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-6049: Add auto-repartitioning for cogroup (#7792)Follow up to PR #7538 (KIP-150)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Add release documentation for KIP-614 (#10051)Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: Remove legacy kafka.admin.AdminClient (#6947)It has been deprecated since 0.11.0, it was never meant as a publiclysupported API and people should use`org.apache.kafka.clients.admin.AdminClient` instead. Its presencecauses confusion and people still use them accidentally at times.`BrokerApiVersionsCommand` uses one method that is not availablein `org.apache.kafka.clients.admin.AdminClient`, we inline it for now.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
KAFKA-7772: Dynamically Adjust Log Levels in Connect (#7403)Implemented KIP-495 to expose a new `admin/loggers` endpoint for the Connect REST API that lists the current log levels and allows the caller to change log levels. Author: Arjun Satish <arjun@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"MINOR: code cleanup follow up for KAFKA-6906 (#5196)Reviewers: Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-1139 Topic data change handling callback should not call syncedRebalance directly; reviewed by Guozhang Wang and Jun Rao,4
"KAFKA-6566: Improve Connect Resource CleanupThis is a change to improve resource cleanup for sink tasks and source tasks.  Now `Task.stop()` is called from both `WorkerSinkTask.close()` and `WorkerSourceTask.close()`.It is called from `WorkerXXXTask.close()` since this method is called in the `finally` block of `WorkerTask.run()`, and Connect developers use `stop()` to clean up resources.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5020 from rayokota/K6566-improve-connect-resource-cleanup",4
"KAFKA-330 Delete topic; reviewed by Jun Rao, Guozhang Wang and Joel Koshy",4
MINOR: Improve versioning in docs when a full version is requiredAlso fix quickstart.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3501 from ijuma/introduce-full-version-variable-in-docs,2
"MINOR: add window store range query in simple benchmark (#4894)There are a couple minor additions in this PR:1. Add a new test for window store, to range query upon receiving each record.2. In the non-windowed state store case, add a get call before the put call.3. Enable caching by default to be consistent with other Join / Aggregate cases, where caching is enabled by default.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6429; LogCleanerManager.cleanableOffsets should create objects … (#4399)…for dirty non-active segments only when `log.cleaner.min.compaction.lag.ms` is greater than 0With `log.cleaner.min.compaction.lag.ms`'s default value of 0, there is no need to hold heap objects for those dirty non-active segments. This could reduce the heap size and also avoid the unnecessary monitor lock retrieval.",4
"KAFKA-4135; Consumer poll with no subscription or assignment should raise an errorWhen the consumer is not subscribed to any topic or, in the case of manual assignment, is not assigned any partition, calling `poll()` should raise an exception.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1839 from vahidhashemian/KAFKA-4135",5
"KAFKA-4492: Make the streams cache eviction policy tolerable to reentrant putsThe NamedCache wasn't correctly dealing with its re-entrant nature. This would result in the LRU becoming corrupted, and the above exception occurring during eviction. For example:Cache A: dirty key 1eviction runs on Cache ANode for key 1 gets marked as cleanEntry for key 1 gets flushed downstreamDownstream there is a processor that also refers to the table fronted by Cache ADownstream processor puts key 2 into Cache AThis triggers an eviction of key 1 again ( it is still the oldest node as hasn't been removed from the LRU)As the Node for key 1 is clean flush doesn't run and it is immediately removed from the cache.So now we have dirtyKey set with key =1, but the value doesn't exist in the cache.Downstream processor tries to put key = 1 into the cache, it fails as key =1 is in the dirtyKeySet.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2226 from dguy/cache-bug",0
"KAFKA-13892: Fix bug where multiple remove records are generated for one ACLFix a bug where multiple remove records could be generated for a single ACL. Previously, this happenedif the user submitted multiple filters to deleteAcls, and more than one matched.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7524: Recommend Scala 2.12 and use it for development (#5530)Scala 2.12 has better support for newer Java versions and includes additionalcompiler warnings that are helpful during development. In addition, Scala 2.11hasn't been supported by the Scala community for a long time, the soon to bereleased Spark 2.4.0 will finally support Scala 2.12 (this was the main reasonpreventing many from upgrading to Scala 2.12) and Scala 2.13 is at the RC stage.It's time to start recommending the Scala 2.12 build as we prepare support forScala 2.13 and start thinking about removing support for Scala 2.11.In the meantime, Jenkins will continue to build all supported Scala versions (includingScala 2.11) so the PR and trunk jobs will fail if people accidentally use methodsintroduced in Scala 2.12.Reviewers: Ewen Cheslack-Postava <me@ewencp.org>",1
"KAFKA-4055; System tests for secure quotasFix existing client-id quota test which currently don't configure quota overrides correctly. Add new tests for user and (user, client-id) quota overrides and default quotas.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1860 from rajinisivaram/KAFKA-4055",5
KAFKA-3378; Client blocks forever if SocketChannel connects instantlyThis is a different implementation to the one in #1085 by Larkin Lowrey (llowrey). The hard part here was actually finding the problem and all credit goes to llowrey.This PR also fixes our handling of `finishConnect` (we now check the return value).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun RaoCloses #1094 from ijuma/KAFKA-3378-instantly-connecting-socket-channels,5
draft patch,5
KAFKA-3117: handle metadata updates during consumer rebalanceAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1247 from hachikuji/KAFKA-3117,5
MINOR: Sync up 'kafka-run-class.bat' with 'kafka-run-class.sh'Some of the recent changes to `kafka-run-class.sh` have not been applied to `kafka-run-class.bat`.These recent changes include setting proper streams or connect classpaths. So any streams or connect use case that leverages `kafka-run-class.bat` would fail with an error like```Error: Could not find or load main class org.apache.kafka.streams.???```Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2238 from vahidhashemian/minor/sync_up_kafka-run-class.bat,1
KAFKA-2460; Fix capitalisation in SSL classesAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>Closes #355 from ijuma/kafka-2460-fix-capitalisation-in-ssl-classes,0
MINOR: Remove unused parameters in functions. (#10035)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
KAFKA-483 Improvements to the system testing framework; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1379232 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-2581: Run some existing ducktape tests with SSLParametrize console consumer sanity test, replication tests and benchmarks tests to run with both PLAINTEXT and SSL.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Geoff Anderson, Ewen Cheslack-Postava, Guozhang WangCloses #271 from rajinisivaram/KAFKA-2581",5
"KAFKA-3052; Broker properties get logged twice if acl enabledFix it by making it possible to pass the `doLog` parameter to `AbstractConfig`. As explained in the code comments, this means that we can continue to benefit from ZK default settings as specified in `KafkaConfig` without having to duplicate code.Also:* Removed unused private methods from `KafkaConfig`* Removed `case` modifier from `KafkaConfig` so that `hashCode`, `equals`and `toString` from `AbstractConfig` are used.* Made `props` a `val` and added `apply` method to `KafkaConfig` toremain binary compatible.* Call authorizer.close even if an exception is thrown during `configure`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #725 from ijuma/kafka-3052-broker-properties-get-logged-twice-if-acl-enabled",2
"KAFKA-9610: do not throw illegal state when remaining partitions are not empty (#8169)For handleRevocation, it is possible that previous onAssignment callback has cleaned up the stream tasks, which means no corresponding task could be found for given partitions. We should not throw here as this is expected behavior.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2063; Bound fetch response size (KIP-74)This PR is implementation of [KIP-74](https://cwiki.apache.org/confluence/display/KAFKA/KIP-74%3A+Add+Fetch+Response+Size+Limit+in+Bytes) which is originally motivated by [KAFKA-2063](https://issues.apache.org/jira/browse/KAFKA-2063).Author: Andrey Neporada <neporada@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1812 from nepal/kip-74",5
"Revert ""KAFKA-10469: Resolve logger levels hierarchically (#9266)""This reverts commit fda67018375ce3f6b90658e1ae9c30ab463e0240.It includes changes in the specified behavior, so a KIP must besubmitted and approved before we can make the change.",4
"KAFKA-12856: Upgrade Jackson to 2.12.3 (#10778)2.10.x is no longer supported, so we should move to 2.12 for the 3.0release.ScalaObjectMapper has been deprecated and it looks like we don'tactually need it, so remove its usage.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: Improve Streams Dev Guide content on web docsThis PR migrates content from CP Streams Dev Guide.Here is the top-level page:![image](https://user-images.githubusercontent.com/11722533/33904945-df9cf804-df31-11e7-93aa-52385961522c.png)Here is a child page:![image](https://user-images.githubusercontent.com/11722533/33904976-f2eafabe-df31-11e7-918c-fbf95db0f76b.png)See related: https://github.com/apache/kafka-site/pull/112Author: Joel Hamill <joel-hamill@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4252 from joel-hamill/20171122-migrate-cp-dev-guide,1
kafka-920; zkclient jar 0.2.0 is not compatible with 0.1.0; patched by Jun Rao; reviewed by Neha Narkhede,5
KAFKA-1740: merge offset manager into consumer coordinator; reviewed by Onur Karaman and Jason Gustafson,1
"KAFKA-5608: Add --wait option for JmxTool and use in system tests to avoid race between JmxTool and monitored servicesAuthor: Ewen Cheslack-Postava <me@ewencp.org>Author: Ewen Cheslack-Postava <ewen@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3547 from ewencp/wait-jmx-metrics",5
"MINOR: Add ApiMessageTypeGenerator (#9002)Previously, we had some code hard-coded to generate message type classesfor RPCs.  We might want to generate message type classes for otherthings as well, so make it more generic.Reviewers: Boyang Chen <boyang@confluent.io>",5
"KAFKA-7386: streams-scala should not cache serdes (#5622)Currently, scala.Serdes.String, for example, invokes Serdes.String() once and caches the result.However, the implementation of the String serde has a non-empty configure method that is variant in whether it's used as a key or value serde. So we won't get correct execution if we create one serde and use it for both keys and values.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: join test for windowed keysguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #814 from ymatsuda/windowed_key_join_test,3
"KAFKA-4722: Add application.id to StreamThread nameAdd application.id to StreamThread nameAuthor: sharad.develop <sharad.develop@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2617 from sharad-develop/KAFKA-4722",1
"MINOR: Update library dependencies (Q1 2022) (#11306)- scala 2.13: 2.13.6 -> 2.13.8  * Support Java 18 and improve Android compatibility  * https://www.scala-lang.org/news/2.13.7  * https://www.scala-lang.org/news/2.13.8- scala 2.12: 2.12.14 -> 2.12.15.   * The `-release` flag now works with Scala 2.12, backend parallelism    can be enabled via `-Ybackend-parallelism N` and string interpolation    is more efficient.  * https://www.scala-lang.org/news/2.12.5- gradle versions plugin: 0.38.0 -> 0.42.0  * Minor fixes  * https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.40.0  * https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.41.0  * https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.42.0- gradle dependency check plugin: 6.1.6 -> 6.5.3  * Minor fixes- gradle spotbugs plugin: 4.7.1 -> 5.0.5  * Fixes and minor improvements  * There were too many releases to include all the links, include the major version bump  * https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/5.0.0- gradle scoverage plugin: 5.0.0 -> 7.0.0  * Support newer Gradle versions and other improvements  * https://github.com/scoverage/gradle-scoverage/releases/tag/6.0.0  * https://github.com/scoverage/gradle-scoverage/releases/tag/6.1.0  * https://github.com/scoverage/gradle-scoverage/releases/tag/7.0.0- gradle shadow plugin: 7.0.0 -> 7.1.2  * Support gradle toolchains and security fixes  * https://github.com/johnrengelman/shadow/releases/tag/7.1.0  * https://github.com/johnrengelman/shadow/releases/tag/7.1.1  * https://github.com/johnrengelman/shadow/releases/tag/7.1.2- bcpkix: 1.66 -> 1.70  * Several improvements and fixes  * https://www.bouncycastle.org/releasenotes.html- jline: 3.12.1 -> 3.21.0  * Various fixes and improvements- jmh: 1.32 -> 1.34  * Compiler blackhole enabled by default when using Java 17 and improved    gradle incremental compilation  * https://mail.openjdk.java.net/pipermail/jmh-dev/2021-August/003355.html  * https://mail.openjdk.java.net/pipermail/jmh-dev/2021-December/003406.html- scalaLogging: 3.9.3 -> 3.9.4  * Support for Scala 3.0- jose4j: 0.7.8 -> 0.7.9  * Minor fixes- junit: 5.7.1 -> 5.8.2  * Minor improvements and fixes  * https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.8.0  * https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.8.1  * https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.8.2- jqwik: 1.5.0 -> 1.6.3  * Numerous improvements  * https://github.com/jlink/jqwik/releases/tag/1.6.0- mavenArtifact: 3.8.1 -> 3.8.4- mockito: 3.12.4 -> 4.3.1  * Removed deprecated methods, `DoNotMock` annotation and    minor fixes/improvements  * https://github.com/mockito/mockito/releases/tag/v4.0.0  * https://github.com/mockito/mockito/releases/tag/v4.1.0  * https://github.com/mockito/mockito/releases/tag/v4.2.0  * https://github.com/mockito/mockito/releases/tag/v4.3.0- scalaCollectionCompat: 2.4.4 -> 2.6.0  * Minor fixes  * https://github.com/scala/scala-collection-compat/releases/tag/v2.5.0  * https://github.com/scala/scala-collection-compat/releases/tag/v2.6.0- scalaJava8Compat: 1.0.0 -> 1.0.2  * Minor changes- scoverage: 1.4.1 -> 1.4.11  * Support for newer Scala versions- slf4j: 1.7.30 -> 1.7.32  * Minor fixes, 1.7.35 automatically uses reload4j and 1.7.33/1.7.34    cause build failures, so we stick with 1.7.32 for now.- zstd: 1.5.0-4 -> 1.5.2-1  * zstd 1.5.2  * Small refinements and performance improvements  * https://github.com/facebook/zstd/releases/tag/v1.5.1  * https://github.com/facebook/zstd/releases/tag/v1.5.2Checkstyle, spotBugs and spotless will be upgraded separately as theyeither require non trivial code changes or they have regressionsthat affect us.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",4
"KAFKA-7844: Use regular subproject for generator to fix *All targets (#6182)The presence of the buildSrc subproject is causing problems when we tryto run installAll, jarAll, and the other ""all"" targets. It's easierjust to make the generator code a regular subproject and use theJavaExec gradle task to run the code. This also makes it morestraightforward to run the generator unit tests.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>Co-authored-by: Colin P. Mccabe <cmccabe@confluent.io>Co-authored-by: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
"KAFKA-8788: Optimize client metadata handling with a large number of partitions (#7192)Credit to @lbradstreet for profiling the producer with a large number of partitions.Cache `topicMetadata`, `brokers` and `controller` in the `MetadataResponse`the first time it's needed avoid unnecessary recomputation. We were previouslycomputing`brokersMap` 4 times per partition in one code path that was invoked frommultiple places. This is a regression introduced via a42f16f980 and first releasedin 2.3.0.The `Cluster` constructor became significantly more allocation heavy due to2c44e77e2f20, first released in 2.2.0. Replaced `merge` calls with more verbose,but more efficient code. Added a test to verify that the returned collections areunmodifiable.Add `topicAuthorizedOperations` and `clusterAuthorizedOperations` to`MetadataResponse` and remove `data()` method.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Lucas Bradstreet <lucasbradstreet@gmail.com>, Colin P. McCabe <cmccabe@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Justine Olshan <jolshan@confluent.io>",5
MINOR: Update consumer javadoc for invalid operations on unassigned partitions  (#5005)Document cases where  `IllegalStateException` is raised when attempting an invalid operation on an unassigned partition. Also change `position()` to raise `IllegalStateException` when called on an unassigned partition for consistency.,4
"KAFKA-5957; Prevent second deallocate if response for aborted batch returnsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3942 from hachikuji/KAFKA-5957",5
"KAFKA-10492; Core Kafka Raft Implementation (KIP-595) (#9130)This is the core Raft implementation specified by KIP-595: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum. We have created a separate ""raft"" module where most of the logic resides. The new APIs introduced in this patch in order to support Raft election and such are disabled in the server until the integration with the controller is complete. Until then, there is a standalone server which can be used for testing the performance of the Raft implementation. See `raft/README.md` for details.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Boyang Chen <boyang@confluent.io>Co-authored-by: Boyang Chen <boyang@confluent.io>Co-authored-by: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1286: Trivial fix up: Use || instead of |.,1
"MINOR: Simplify KafkaProducerTest (#8044)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ron Dagostino <rndgstn@gmail.com>",2
"MINOR: bug fixes to ducktape servicesHere's a (mostly successful) run with these changes:http://testing.confluent.io/confluent-kafka-branch-builder-system-test-results/?prefix=2016-06-27--001.1467080884--alexlod--ducktape-fixes--ad85493/At least one of the failed tests is failing in trunk, too:http://testing.confluent.io/confluent-kafka-branch-builder-system-test-results/?prefix=2016-06-28--001.1467090978--alexlod--ducktape-fixes--ad85493/The contribution is my original work and I license the work to the project under the project's open source license.Author: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1566 from alexlod/ducktape-fixes",0
KAFKA-1723; num.partitions documented default is 1 while actual default is 2; patched by Manikumar Reddy; reviewed by Jun Rao,2
"MINOR: fix javadoc comment of TransformerHere's where it's called:https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamTransform.java#L64-L67Author: mihbor <mbor81@gmail.com>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #2884 from mihbor/patch-3",1
"HOTFIX: updated JavaDoc example for 0.9 tech-prev to 0.10Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Sriharsha Chintalapani, Ismael Juma, Guozhang WangCloses #1450 from mjsax/hotfix",0
"kafka-1074; Reassign partitions should delete the old replicas from disk; patched by Jun Rao; reviewed by Jay Kreps, Neha Narkhede and Guozhang Wang",4
MINOR: Simplify SensorAccess usageI was investigating an exception in this code and found a fewopportunities for making it clearer.I also added the `out` folder to `.gitignore` as IntelliJ sometimesuses that as the build folder.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3552 from ijuma/minor-quota-improvements,1
"KAFKA-2596: reject commits from unknown groups with positive generationsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Onur Karaman, Guozhang WangCloses #267 from hachikuji/KAFKA-2596",5
"MINOR: Make indenting in `checkstyle.xml` and `import-control.xml` consistentThey now both use 2 spaces for indents, which is what `checkstyle.xml` wasalready doing. `import.xml` had a mixture of tabs and 4 spaces previously.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #253 from ijuma/fix-xml-indents",5
"KAFKA-3865: Fix transient failure in WorkerSourceTaskTest.testSlowTaskStartAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1531 from hachikuji/KAFKA-3865",5
Deleting the ConsumerTest until the issue with the hanging test is resolved; discussed on the mailing list and got several +1s,0
"KAFKA-8233: TopologyTestDriver test input and output usability improvements (#7378)Implements KIP-470Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Fix a documentation typoAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>Closes #2674 from vahidhashemian/minor/fix_typos_1703,2
"KAFKA-8061; Handle concurrent ProducerId reset and call to Sender thread shutdown (#6388)In KAFKA-5503, we have added a check  for `running` flag in the loop inside maybeWaitForProducerId.  This is to handle concurrent call to Sender close(), while we attempt to get the ProducerId. This avoids blocking indefinitely when the producer is shutting down.This created a corner case, where Sender thread gets blocked, if we had concurrent producerId reset and call to Sender thread close. The fix here is to check the `forceClose` flag in the loop inside maybeWaitForProducerId instead of the `running` flag.Reviewers: Jason Gustafson <jason@confluent.io>",5
"Update KafkaConfig.scala (#7113)Better clarify the auto leader rebalance config documentation to reflect additional leader.imbalance.per.broker.percentage config description.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",5
"MINOR: set log4j.logger.kafka and all Config logger levels to ERROR for Streams tests (#11823)Pretty much any time we have an integration test failure that's flaky or only exposed when running on Jenkins through the PR builds, it's impossible to debug if it cannot be reproduced locally as the logs attached to the test results have truncated the entire useful part of the logs. This is due to the logs being flooded at the beginning of the test when the Kafka cluster is coming up, eating up all of the allotted characters before we even get to the actual Streams test. Setting log4j.logger.kafka to ERROR greatly improves the situation and cuts down on most of the excessive logging in my local runs. To improve things even more and have some hope of getting the part of the logs we actually need, I also set the loggers for all of the Config objects to ERROR, as these print out the value of every single config (of which there are a lot) and are not useful as we can easily figure out what the configs were if necessary by just inspecting the test locally.Reviewers:  Luke Chen <showuon@confluent.io>,  Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-10048: Possible data gap for a consumer after a failover when using MM2 (#8730)Ensure that the MM2 checkpoint mirror task replicates consumer offsets even when they arezero to avoid issues with consumers after failovers.Author: Andre Araujo <asdaraujo@gmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, Edoardo Comar <ecomar@uk.ibm.com>, heritamas",0
"KAFKA-5989; resume consumption of tasks that have state stores but no changeloggingStores where logging is disabled where never consumed as the partitions were paused, but never resumed.Author: Damian Guy <damian.guy@gmail.com>Reviewers: tedyu <yuzhihong@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4002 from dguy/restore",5
"KAFKA-9441: Cleanup Streams metrics for removed task commit latency metrics (#8356)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-6168: Connect Schema comparison is slow for large schemasRe-arrange order of comparisons in equals() to evaluate non-composite fields firstCache hash codeAuthor: tedyu <yuzhihong@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4176 from tedyu/trunk",1
"MINOR: Upgrade mockito test dependencies (#12460)## Changes- **mockito: 4.4.0 -> 4.6.1** (https://github.com/mockito/mockito/releases)Most important updates:  - Fixes https://github.com/mockito/mockito/issues/2648 : Add support for customising strictness via @mock annotation and MockSettings https://github.com/mockito/mockito/pull/2650## Why is this change needed?According to the [Mockito documentation](https://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html#when(T)) :> Although it is possible to verify a stubbed invocation, usually it's just redundant. Let's say you've stubbed foo.bar(). If your code cares what foo.bar() returns then something else breaks(often before even verify() gets executed). If your code doesn't care what get(0) returns then it should not be stubbed. While working on the [Replace EasyMock and PowerMock with Mockito for StreamsMetricsImplTest ](https://issues.apache.org/jira/browse/KAFKA-12947) I noticed that described behavior wasn't applied when you create a new `mock` like this.```java        final Metrics metrics = mock(Metrics.class);        when(metrics.metric(metricName)).thenReturn(null);        ... invoke SUT        verify(metrics).metric(metricName); // this should be redundant (according to docs)```After further investigation I figured out that described behaviour wasn't implemented until`v4.6.1`.With this change we are now able to mock objects like this:```java   Foo explicitStrictMock = mock(Foo.class, withSettings().strictness(Strictness.STRICT_STUBS));```- link to docs: [MockSettings.html#strictness](https://javadoc.io/static/org.mockito/mockito-core/4.6.1/org/mockito/quality/Strictness.html#STRICT_STUBS)It looks like I can accomplish the same thing by using the `@RunWith(MockitoJUnitRunner.StrictStubs.class)` instead of the `@RunWith(MockitoJUnitRunner.class)` so mockito dependency version update is not mandatory, but it would be nice to stay up-to-date and use the latest version (it's up to MR reviewer to decide if we are going to merge this now, or just close the MR and update mockito version later).Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-7456: Serde Inheritance in DSL (#5521)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-2804: manage changelog topics through ZK in PartitionAssignorAuthor: Guozhang Wang <wangguoz@gmail.com>Author: wangguoz@gmail.com <guozhang@Guozhang-Macbook.local>Author: Guozhang Wang <guozhang@Guozhang-Macbook.local>Reviewers: Yasuhiro MatsudaCloses #579 from guozhangwang/K2804,4
"MINOR: Log formatting for exceptions during configuration related operations (#10843)Format configuration logging during exceptions or errors. Also make sure it redacts sensitive information or unknown values.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Improvements to Record related classes (part 1)Jason recently cleaned things up significantly by consolidating the Message/Record classesinto the common Java code in the clients module. While reviewing that, I noticed a few thingsthat could be improved a little more. To make reviewing easier, there will be multiple PRs.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>Closes #2271 from ijuma/records-minor-fixes",0
MINOR: fix Scala 2.12 compile failure in ControllerApisTest (#11043)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,3
"KAFKA-1053 Kafka patch review tool that integrates JIRA and reviewboard; reviewed by Joel Koshy, Swapnil Ghike and Guozhang Wang",5
MINOR: Optimize ConnectionStressWorkerOptimize ConnectionStressWorker by avoiding creating a newChannelBuilder each time we want to open a new connection.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen ShapiraCloses #6518 from cmccabe/optimize-connection-stress-worker,1
"MINOR: Add missing option for running vagrant-up.sh with AWS to vagrant/README.mdContrary to the previous explanation, a command example invagrant/README.md lacks the option to specify the aws provider.Author: Kengo Seki <sekikn@apache.org>Reviewers: Gwen ShapiraCloses #6702 from sekikn/add-missing-option",1
"MINOR: Move request/response schemas to the corresponding object representationThis refactor achieves the following:1. Breaks up the increasingly unmanageable `Protocol` class and moves schemas closer to their actual usage.2. Removes the need for redundant field identifiers maintained separately in `Protocol` and the respective request/response objects.3. Provides a better mechanism for sharing common fields between different schemas (e.g. topics, partitions, error codes, etc.).4. Adds convenience helpers to `Struct` for common patterns (such as setting a field only if it exists).Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3813 from hachikuji/protocol-schema-refactor",4
"MINOR: Revert to ZooKeeper 3.4.10 due to ZOOKEEPER-2960 (#4678)It's a critical bug that only affects the server, but wedon't have an easy way to use 3.4.11 for the clientonly.Reviewers: Jun Rao <junrao@gmail.com>, Damian Guy <damian.guy@gmail.com>",1
"KAFKA-5932; Avoid call to fetchPrevious in FlushListenersAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3978 from bbejeck/KAFKA-5932_no_fetch_previous_when_no_old_values_returned",5
"KAFKA-10874: Fix flaky ClientQuotasRequestTest.testAlterIpQuotasRequest (#9778)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-7193: Use ZooKeeper IP address in streams tests to avoid timeouts (#5414)ZooKeeper client from version 3.4.13 doesn't handle connections to localhost very well. If ZooKeeper is started on 127.0.0.1 on a machine that has both ipv4 and ipv6 and a client is created using localhost rather than the IP address in the connection string, ZooKeeper client attempts to connect to ipv4 or ipv6 randomly with a fixed one second backoff if connection fails. Use 127.0.0.1 instead of localhost in streams tests to avoid intermittent test failures due to ZK client connection timeouts if ipv6 is chosen in consecutive address selections. Also add note to upgrade docs for 2.0.0.Reviewers: Ismael Juma <github@juma.me.uk>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-7673: Upgrade rocksdb to 5.15.10 (#5985)Reviewers: Matthias J. Sax <mjsax@apache.org>,5
"KAFKA-5505: Incremental cooperative rebalancing in Connect (KIP-415) (#6363)Added the incremental cooperative rebalancing in Connect to avoid global rebalances on all connectors and tasks with each new/changed/removed connector. This new protocol is backward compatible and will work with heterogeneous clusters that exist during a rolling upgrade, but once the clusters consist of new workers only some affected connectors and tasks will be rebalanced: connectors and tasks on existing nodes still in the cluster and not added/changed/removed will continue running while the affected connectors and tasks are rebalanced.This commit attempted to minimize the changes to the existing V0 protocol logic, though that was not entirely possible.This commit adds extensive unit and integration tests for both the old V0 protocol and the new v1 protocol. Soak testing has been performed multiple times to verify behavior while connectors and added, changed, and removed and while workers are added and removed from the cluster.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Robert Yokota <rayokota@gmail.com>, David Arthur <mumrah@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",5
MINOR: Fix a few raw type warnings in cients- Removed an unnecessary annotation- Parameterized a couple of raw typesAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1675 from mimaison/warnings,2
"KAFKA-9133; Cleaner should handle log start offset larger than active segment base offset (#7662)This was a regression in 2.3.1. In the case of a DeleteRecords call, the log start offset may be higher than the active segment base offset. The cleaner should allow for this case gracefully.Reviewers: Jun Rao <junrao@gmail.com>Co-Authored-By: Tim Van Laer <timvlaer@users.noreply.github.com>",1
"MINOR: fix compatibility-breaking bug in RequestHeader (#7479)Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-13743: Prevent topics with conflicting metrics names from being created in KRaft mode #11910In ZK mode, the topic ""foo_bar"" will conflict with ""foo.bar"" because of limitations in metricnames. We should implement this in KRaft mode.  This PR also changes TopicCommandIntegrationTest tosupport KRaft mode.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-12648: extend IQ APIs to work with named topologies (#11562)In the new NamedTopology API being worked on, state store names and their uniqueness requirement is going to be scoped only to the owning topology, rather than to the entire app. In other words, two different named topologies can have different state stores with the same name.This is going to cause problems for some of the existing IQ APIs which require only a name to resolve the underlying state store. We're now going to need to take in the topology name in addition to the state store name to be able to locate the specific store a user wants to queryReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
MINOR: Remove synchronized as the tasks are executed sequentiallyAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1441 from Ishiihara/remove-synchronized,4
Merge branch '0.8' into trunkConflicts:core/src/main/scala/kafka/log/Log.scalacore/src/test/scala/unit/kafka/admin/AdminTest.scalacore/src/test/scala/unit/kafka/log/LogTest.scalacore/src/test/scala/unit/kafka/server/LogOffsetTest.scala,5
KAFKA-13637: Use default.api.timeout.ms as default timeout value for KafkaConsumer.endOffsets (#11726)We introduced `default.api.timeout.ms` in https://github.com/apache/kafka/commit/53ca52f855e903907378188d29224b3f9cefa6cb but we missed updating `KafkaConsumer.endOffsets` which still use `request.timeout.ms`. This patch fixes this.Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Improve output format of `kafka_reassign_partitions.sh` toolThe current output for the `--generate` option looks like this```Current partition replica assignment{""version"":1,""partitions"":[{""topic"":""t1"",""partition"":0,""replicas"":[0]}]}Proposed partition reassignment configuration{""version"":1,""partitions"":[{""topic"":""t1"",""partition"":0,""replicas"":[1]}]}```This PR simply changes it to```Current partition replica assignment{""version"":1,""partitions"":[{""topic"":""t1"",""partition"":0,""replicas"":[0]}]}Proposed partition reassignment configuration{""version"":1,""partitions"":[{""topic"":""t1"",""partition"":0,""replicas"":[1]}]}```to make it more readable.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1868 from vahidhashemian/minor/improve_output_format_of_reassign_partitions",1
Hadoop Consumer goes into an infinite loop; patched by Sam William; reviewed by Richard Park; KAFKA-131git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1166424 13f79535-47bb-0310-9956-ffa450edef68,1
remove errorcode from ByteBufferMessageSet; patched by Swapnil Ghike; reviewed by Jay Kreps and Jun Rao; KAFKA-458git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383105 13f79535-47bb-0310-9956-ffa450edef68,1
Fixed README and added clearer error message. (#10133)The script `test-raft-server-start.sh` requires the config to be specified with `--config`. I've included this in the README and added an error message for this specific case.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-9439: add KafkaProducer API unit tests (#8174)Add unit tests for KafkaProducer.close(), KafkaProducer.abortTransaction(), and KafkaProducer.flush() in the KafkaProducerTest.Increase KafkaProducer test code coverage from 82% methods, 82% lines to 86% methods, 87% lines when being merged.Reviewers: Boyang Chen <boyang@confluent.io>",5
"MINOR: Update rocksDB dependency to 5.0.1Author: jozi-k <jozef.koval@protonmail.ch>Reviewers: Ismael Juma, Guozhang WangCloses #2292 from jozi-k/update-rocksdb-4.13.5",5
"KAFKA-5036; hold onto the leader lock in Partition while serving an O……ffsetForLeaderEpoch requestAuthor: Jun Rao <junrao@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ben Stopford <benstopford@gmail.com>Closes #3074 from junrao/kafka-5036",1
"MINOR: update KafkaStreams.metadataForKey(...) javadocAdd a note to `KafkaStreams.metadataForKey(String, K, Serializer<K>)` to point out that in the case of a Window Store the Serializer should still be the record key serializer and not a window serializerAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Xavier Léauté, Guozhang WangCloses #2532 from dguy/minor-docs",2
"KAFKA-3648; maxTimeToBlock in BufferPool.allocate should be enforced `maxTimeToBlock` needs to be updated in each loop iteration. Also record waitTime before throwing `TimeoutException`Author: Chen Zhu <amandazhu19620701@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1304 from zhuchen1018/KAFKA-3648",5
MINOR: Improve local variable name in UnifiedLog.maybeIncrementFirstUnstableOffset (#11253)Reviewers: Jun Rao <junrao@gmail.com>,2
MINOR: Fix typos in kafka.py (#4581),2
provides windows batch script for starting Kafka/Zookeeper; patched by Antoine Vianey; reviewed by Jun Rao; kafka-581git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1420001 13f79535-47bb-0310-9956-ffa450edef68,1
kafka-1127; kafka and zookeeper server should start in daemon mode and log to correct position; patched by Raymond Liu; reviewed by Jun Rao,2
"KAFKA-4902; Utils#delete should correctly handle I/O errors and symlinksAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2691 from cmccabe/KAFKA-4902",5
"KAFKA-2960 KAFKA-1148; Clear purgatory for partitions before becoming followerAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>, Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1018 from becketqin/KAFKA-2960",2
KAFKA-2138; Fix producer to honor retry backoff; reviewed by Joel Koshy and Guozhang Wang,1
log.truncateTo needs to handle targetOffset smaller than the lowest offset in the log ; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-463git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1386641 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Update documentation.html to refer to 2.4 (#7454),2
KAFKA-10060 GroupMetadataManager should not log if there are no offsets to expire (#8767)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-6144: IQ option to query standbys (#7962)Add a new overload of KafkaStreams#store that allows usersto query standby and restoring stores in addition to active ones.Closes: #7962Implements: KIP-535Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>Reviewed-by: John Roesler <vvcephei@apache.org>,1
"KAFKA-7223: Add late-record metrics (#5742)Add late record metrics, as specified in KIP-328Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3122; Fix memory leak in `Sender.completeBatch` on TOPIC_AUTHORIZATION_FAILEDAlso fix missing call to `sensors.record` on this error.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson, Guozhang WangCloses #791 from ijuma/fix-producer-memory-leak-on-authorization-exception",0
"KAFKA-8613: New APIs for Controlling Grace Period for Windowed Operations (#10926)Implements KIP-633.Grace-period is an important parameter and its best to make it the user's responsibility to set it expliclity. Thus, we move off to provide a default and make it a mandatory parameter when creating a window.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Bump version to 0.11.0.0-SNAPSHOTThere won't be a 0.10.3.0.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2628 from ijuma/bump-version-to-0.11.0.0-SNAPSHOT,5
MINOR: Set `replicaId` for OffsetsForLeaderEpoch from followers (#6775)Reviewers: Jason Gustafson <jason@confluent.io>,5
kafka-1797; (follow-up patch) add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Jay Kreps,1
KAFKA-1298 Controlled shutdown tool doesn't seem to work out of the box; reviewed by Neha Narkhede,1
"KAFKA-7391; Introduce close(Duration) to Producer and AdminClient instead of close(long, TimeUnit) (#5667)See KIP-367: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=89070496.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12219: Add 'synchronized' keyword to InMemoryKeyValueStore#[reverseRange, reverseAll] (#9923)Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-2637; Cipher suite setting should be configurable for SSLEnables Cipher suite setting. Code was previously reviewed by ijuma, harshach. Moving to an independent PR.Author: benstopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #301 from benstopford/cipher-switch",1
KAFKA-2726: Fix port collision between ntpdate and ntp daemongwenshap Can you take a quick look? I have verified the change allows successful `vagrant provision` even with ntp daemon already running on the vm.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Guozhang WangCloses #407 from granders/KAFKA-2726-ntp-port-collision,5
MINOR: Fix typos in docsAuthor: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Gwen ShapiraCloses #1003 from sasakitoa/Fix_typo_in_docs,2
KAFKA-1094 Configure reviewboard url in kafka-patch-review tool; reviewed by Neha Narkhede,5
"KAFKA-6511; Corrected connect list/map parsing logic (#4516)Corrected the parsing of invalid list values. A list can only be parsed if it contains elements that have a common type, and a map can only be parsed if it contains keys with a common type and values with a common type.Reviewers: Arjun Satish <arjun@confluent.io>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Enable ignored upgrade system tests - trunk (#5605)Removed ignore annotations from the upgrade tests. This PR includes the following changes for updating the upgrade tests:* Uploaded new versions 0.10.2.2, 0.11.0.3, 1.0.2, 1.1.1, and 2.0.0 (in the associated scala versions) to kafka-packages* Update versions in version.py, Dockerfile, base.sh* Added new versions to StreamsUpgradeTest.test_upgrade_downgrade_brokers including version 2.0.0* Added new versions StreamsUpgradeTest.test_simple_upgrade_downgrade test excluding version 2.0.0* Version 2.0.0 is excluded from the streams upgrade/downgrade test as StreamsConfig needs an update for the new version, requiring a KIP. Once the community votes the KIP in, a minor follow-up PR can be pushed to add the 2.0.0 version to the upgrade test.* Fixed minor bug in kafka-run-class.sh for classpath in upgrade/downgrade tests across versions.* Follow on PRs for 0.10.2x, 0.11.0x, 1.0.x, 1.1.x, and 2.0.x will be pushed soon with the same updates required for the specific version.Reviewers: Eno Thereska <eno.thereska@gmail.com>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6018: Make KafkaFuture.Future an interface (KIP-218)Changing KafkaFuture.Future and KafkaFuture.BiConsumer into an interface makesthem a functional interface.  This makes them Java 8 lambda compatible.Author: Colin P. Mccabe <cmccabe@confluent.io>Author: Steven Aerts <steven.aerts@gmail.com>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Xavier Léauté <xl+github@xvrl.net>, Tom Bentley <tbentley@redhat.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4033 from steven-aerts/KAFKA-6018",5
kafka-972; MetadataRequest returns stale list of brokers; patched by Ashish Singh; reviewed by Jun Rao,5
KAFKA-2695: limited support for nullable byte arraysAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #780 from hachikuji/KAFKA-2695,5
"KAFKA-8094: Iterating over cache with get(key) is inefficient (#6433)Use concurrent data structure for the underlying cache in NamedCache, and iterate over it with subMap instead of many calls to get()Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",1
"MINOR: Supplement the description of `Valid Values` in the documentation of `compression.type` (#11985)Because a validator is added to ProducerConfig.COMPRESSION_TYPE_CONFIG and KafkaConfig.CompressionTypeProp, the corresponding testCase is improved to verify whether the wrong value of compression.type will throw a ConfigException.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Use IntegrationTestHarness properly in BaseAdminIntegrationTest (#7705)The latter was previously hardcoding logDirCount instead of using themethod defined in the superclass since it was unnecessarily duplicatinglogic.Also tweak IntegrationTestHarness and remove unnecessary methodoverride from SaslPlainPlaintextConsumerTest.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
KAFKA-5410; Fix taskClass() method name in Connector and flush() signature in SinkTaskAuthor: ppatierno <ppatierno@live.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3269 from ppatierno/connect-doc,2
"KAFKA-13943; Make `LocalLogManager` implementation consistent with the `RaftClient` contract (#12224)Fixes two issues in the implementation of `LocalLogManager`:- As per the interface contract for `RaftClient.scheduleAtomicAppend()`, it should throw a `NotLeaderException` exception when the provided current leader epoch does not match the current epoch. However, the current `LocalLogManager`'s implementation of the API returns a LONG_MAX instead of throwing an exception. This change fixes the behaviour and makes it consistent with the interface contract.-  As per the interface contract for `RaftClient.resign(epoch)`if the parameter epoch does not match the current epoch, this call will be ignored. But in the current `LocalLogManager` implementation the leader epoch might change when the thread is waiting to acquire a lock on `shared.tryAppend()` (note that tryAppend() is a synchronized method). In such a case, if a NotALeaderException is thrown (as per code change in above), then resign should be ignored.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Tom Bentley <tbentley@redhat.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10619: Configure producer with idempotence and acks all by default (KIP-679) (#9497)This PR relies on existing tests. A subsequent PR will make additional test adjustmentsto ensure coverage of the non-default behavior is still good after this change.Reviewers: Cheng Tan <31675100+d8tltanc@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-6670: Implement a Scala wrapper library for Kafka StreamsThis PR implements a Scala wrapper library for Kafka Streams. The library is implemented as a project under streams, namely `:streams:streams-scala`. The PR contains the following:* the library implementation of the wrapper abstractions* the test suite* the changes in `build.gradle` to build the library jarThe library has been tested running the tests as follows:```$ ./gradlew -Dtest.single=StreamToTableJoinScalaIntegrationTestImplicitSerdes streams:streams-scala:test$ ./gradlew -Dtest.single=StreamToTableJoinScalaIntegrationTestImplicitSerdesWithAvro streams:streams-scala:test$ ./gradlew -Dtest.single=WordCountTest streams:streams-scala:test```Author: Debasish Ghosh <ghosh.debasish@gmail.com>Author: Sean Glover <seglo@randonom.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>, John Roesler <john@confluent.io>, Damian Guy <damian@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4756 from debasishg/scala-streams",5
"KAFKA-13651; Add audit logging to `StandardAuthorizer` (#12031)This patch adds audit support through the kafka.authorizer.logger logger to StandardAuthorizer. Itfollows the same conventions as AclAuthorizer with a similarly formatted log message. WhenlogIfAllowed is set in the Action, then the log message is at DEBUG level; otherwise, we log attrace. When logIfDenied is set, then the log message is at INFO level; otherwise, we again log atTRACE.Reviewers: Colin P. McCabe <cmccabe@apache.org>",2
MINOR: Do not start processor for bounce-at-start (#4639)Only start it after the broker has been shutdown.,5
KAFKA-5358; Consumer perf tool should count rebalance time (KIP-177)Author: huxihx <huxi_2b@hotmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3188 from huxihx/KAKFA-5358,5
"KAFKA-10355: Throw error when source topic was deleted (#9191)Before this commit, Kafka Streams would gracefully shut down the whole application when a source topic is deleted. The graceful shutdown does not give the user the possibility to react on the deletion of the source topic in the uncaught exception handler.This commit changes this behavior and throws an error when a source topic is deleted.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",5
"Minor patch, removing the .gitigore filegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180110 13f79535-47bb-0310-9956-ffa450edef68",1
Minor: remove redundant check in auto preferred leader election (#8566)This is a minor follower up PR of #8524Reviewer: Jun Rao <junrao@gmail.com>,4
"KAFKA-12590: Remove deprecated kafka.security.auth.Authorizer, SimpleAclAuthorizer and related classes in 3.0 (#10450)These were deprecated in Apache Kafka 2.4 (released in December 2019) to be replacedby `org.apache.kafka.server.authorizer.Authorizer` and `AclAuthorizer`.As part of KIP-500, we will implement a new `Authorizer` implementation that relieson a topic (potentially a KRaft topic) instead of `ZooKeeper`, so we should take the chanceto remove related tech debt in 3.0.Details on the issues affecting the old Authorizer interface can be found in the KIP:https://cwiki.apache.org/confluence/display/KAFKA/KIP-504+-+Add+new+Java+Authorizer+InterfaceReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",5
"KAFKA-6364: Second check for ensuring changelog topic not changed during restore (#4511)Added a second check for race condition where store changelog topic updated during restore, but not if a KTable changelog topic. This will be tricky to test, but I wanted to push the PR to get feedback on the approach.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-4664; Update docs/protocol.html with KIP-97 informationAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2387 from cmccabe/KAFKA-4664",5
MINOR: add helpful error message (#11139)I noticed that replace thread actions would not be logged unless the user added a log in the handler. I think it would be very useful for debugging.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
KAFKA-13062: Make DeleteConsumerGroupsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11021)This patch improve the error handling in `DeleteConsumerGroupsHandler` and ensure that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-9156: Fix LazyTimeIndex & LazyOffsetIndex concurrency (#7760)Race condition in concurrent  `get` method invocation of lazy indexes might leadto multiple `OffsetIndex`/`TimeIndex` objects being concurrently created. Whenthat happens position of `MappedByteBuffer` in `AbstractIndex` is advanced tothe last entry which in turn leads to a critical `BufferOverflowException` beingthrown whenever leader or replica tries to append a record to the segment.Moreover, `file_=` setter is seemingly also vulnerable to the race, since multiplethreads can attempt to set a new file reference as well as create newTime/OffsetIndex objects at the same time. This might lead to the discrepantFile references being held by e.g. LazyTimeIndex and its TimeIndex counterpart.This patch attempts to fix the issue by making sure that index objects areatomically constructed when loaded lazily via `get` method. Additionally, `file`reference modifications are also made atomic and thread safe.Note that the `Lazy*Index` mutation operations are executed with a lock held bythe callers, but `get` can be called without a lock (e.g. from `Log.read`).Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>, Shilin Lu, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Fix log message for transition from standby to active (#8872)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR; Refactor KafkaAdminClientTest to reduce the boilerplate code (#7842)`KafkaAdminClientTest` contains many code repetitions which could be removed. This PR removes most of the boiler plate code.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Update doc for raft state metrics (#9342)Reviewers:  Jason Gustafson <jason@confluent.io>,5
"KAFKA-5150; Reduce LZ4 decompression overhead- reuse decompression buffers in consumer Fetcher- switch lz4 input stream to operate directly on ByteBuffers- avoids performance impact of catching exceptions when reaching the end of legacy record batches- more tests with both compressible / incompressible data, multiple  blocks, and various other combinations to increase code coverage- fixes bug that would cause exception instead of invalid block size  for invalid incompressible blocks- fixes bug if incompressible flag is set on end frame block sizeOverall this improves LZ4 decompression performance by up to 40x for small batches.Most improvements are seen for batches of size 1 with messages on the order of ~100B.We see at least 2x improvements for for batch sizes of < 10 messages, containing messages < 10kBThis patch also yields 2-4x improvements on v1 small single message batches for other compression types.Full benchmark results can be found herehttps://gist.github.com/xvrl/05132e0643513df4adf842288be86efdAuthor: Xavier Léauté <xavier@confluent.io>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2967 from xvrl/kafka-5150",5
"KAFKA-6119: Bump epoch when expiring transactions in the TransactionCoordinatorA description of the problem is in the JIRA. I have added an integration test which reproduces the original scenario, and also added unit test cases.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4137 from apurvam/KAFKA-6119-bump-epoch-when-expiring-transactions",5
KAFKA-1238 Move metadata req/resp parsing into its own classes and avoid updating cluster metadata if there are no available nodes.,5
KAFKA-2626: Handle null keys and value validation properly in OffsetStorageWriter.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #345 from ewencp/kafka-2626-offset-storage-writer-null-values,1
MINOR: fix typo in ProducerConfig docAuthor: Nick Chiu <nicolas.chiu@jobcloud.ch>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4249 from nick-zh/trunk,1
"KAFKA-12701: NPE in MetadataRequest when using topic IDs (#10584)We prevent handling MetadataRequests where the topic name is null (to prevent NPE) aswell as prevent requests that set topic IDs since this functionality has not yet beenimplemented. When we do implement it  in https://github.com/apache/kafka/pull/9769,we should bump the request/response version.Added tests to ensure the error is thrown.Reviewers: dengziming <swzmdeng@163.com>, Ismael Juma <ismael@juma.me.uk>",0
MINOR: AbstractCoordinator should log with its subclass (#10149)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-2801; Process any remaining data in SSL network read buffer after handshakeProcess any remaining data in the network read buffer in `SslTransportLayer` when `read()` is invoked. On handshake completion, there could be application data ready to be processed that was read into `netReadBuffer` during handshake processing. `read()` is already invoked from `Selector` after handshake completion, but data already read into the `netReadBuffer` was not being processed. This PR adds a check for remaining data and continues with processing data if data is available.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #493 from rajinisivaram/KAFKA-2801",5
"KAFKA-12648: minor followup from Pt. 2 and some new tests (#11146)Addresses the handful of remaining feedback from Pt. 2, plus adds two new tests: one verifying a multi-topology application with a FKJ and its internal topics, another to make sure IQ works with named topologies (though note that there is a bit more work left for IQ to be fully supported, will be tackled after Pt. 3Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-5278: ConsoleConsumer should honor  `--value-deserializer`In the original implementation, console-consumer fails to honor `--value-deserializer` config.Author: amethystic <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3100 from amethystic/KAFKA-5278",5
"KAFKA-12675: improve the sticky general assignor scalability and performance (#10552)I did code refactor/optimization, keep the same algorithm in this PR.Originally, With this setting:topicCount = 50;partitionCount = 800;consumerCount = 800;We complete in 10 seconds, after my code refactor, the time down to 100~200 msWith the 1 million partitions setting:topicCount = 500;partitionCount = 2000;consumerCount = 2000;No OutOfMemory will be thrown anymore. The time will take 4~5 seconds.Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
Replace Arrays.asList with Collections.singletonList where possible (#4368)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
KAFKA-8889: Log the details about error (#7317)We need stacktrace of the error to understand the root cause and to trouble shoot the underlying problem.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-2403; Add support for commit metadata in KafkaConsumerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #119 from hachikuji/KAFKA-2403",5
"MINOR: Fix log entry in FetchSessionHandler to specify throttle correctly (#8959)Reviewers: David Jacot <djacot@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",5
trivial fix for compilation error in scala 2.9.1,0
HOTFIX: add the hyper link for storageAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3617 from guozhangwang/KHotfix-introduction-hyperlink,2
"MINOR: Account for different versions in upgrade (#6835)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <bruno@confluent.io>",5
MINOR: fix streams_broker_compatibility_test.py (#10632)The log message was changed and so the system test can't capture expected message.Reviewers: Anna Sophie Blee-Goldman ableegoldman@apache.org>,3
"HOTFIX: Close unused ColumnFamilyHandle (#6893)In RocksDBTimestampedStore#openRocksDB we try to open a db with two column families. If this succeeds but the first column family is empty (db.newIterator.seekToFirst.isValid() == false) we never actually close its ColumnFamilyHandleReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-9594: Add a separate lock to pause the follower log append while checking if the log dir could be replaced.This PR adds new lock is used to prevent the follower replica from being updated while ReplicaAlterDirThread is executing maybeReplaceCurrentWithFutureReplica() to replace follower replica with the future replica.Now doAppendRecordsToFollowerOrFutureReplica() doesn't need to hold the lock on leaderIsrUpdateLock for local replica updation and ongoing log appends on the follower will not delay the makeFollower() call.**Benchmark results for Partition.makeFollower() **Old:```Benchmark                                        Mode  Cnt     Score    Error  UnitsPartitionMakeFollowerBenchmark.testMakeFollower  avgt    15  2046.967 ? 22.842  ns/op```New:```Benchmark                                        Mode  Cnt     Score   Error  UnitsPartitionMakeFollowerBenchmark.testMakeFollower  avgt    15  1278.525 ? 5.354  ns/op```Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #8153 from omkreddy/KAFKA-9594-LAISR,3
KAFKA-12672: Added config for raft testing server (#10545)Adding a property to the `raft/config/kraft.properties` for running the rafttest server in development.For testing I ran `./bin/test-kraft-server-start.sh --config config/kraft.properties`and validated the test server started running with a throughput test.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"MINOR: Update TransactionManager to use LogContextAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3852 from hachikuji/minor-use-log-context-txn-manager",2
"MINOR: remove some specifying types in tool command (#10329)Reviewers: David Jacot <david.jacot@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",4
KAFKA-4567 - Connect Producer and Consumer ignore ssl parameters…KAFKA-4567 - Connect Producer and Consumer ignore ssl parameters configured for workerAdded brief explanation to the docs about parameter inheritance of Kafka consumers and producers from the worker config.Author: Sönke Liebau <soenke.liebau@opencore.com>Reviewers: Gwen ShapiraCloses #2511 from soenkeliebau/KAFKA-4567,5
"KAFKA-7752: Add ""/kafka-acl-extended"" zk node path to secure root paths- This commits sets ACL on /kafka-acl-extended- Extended ZkAuthorizationTest to check ACL on /kafka-acl-extended- Using zookeeper-security-migration.sh tool on a Kerberized test cluster, I verified the changes: secured and unsecured Kafka znodes and examined ACL on /kafka-acl-extended with zookeeper clientAuthor: Attila Sasvari <asasvari@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Andras Katona <41361962+akatona84@users.noreply.github.com>Closes #6072 from asasvari/KAFKA-7752",1
Creating branch for kafka-0.8.0-incubating that will include all replication related changesgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1230840 13f79535-47bb-0310-9956-ffa450edef68,4
"MINOR: Rename TopicCommandTest (#8398)Rename the test suite to later add unit tests that don't depend onZK or the AdminClient TopiCommand types.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
KAFKA-840 Post commit,5
"KAFKA-12454: Add ERROR logging on kafka-log-dirs when given brokerIds do not  exist in current kafka cluster (#10304)When non-existent brokerIds value are given, the kafka-log-dirs tool will have a timeout error:Exception in thread ""main"" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: describeLogDirsat org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45)at org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32)at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89)at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260)at kafka.admin.LogDirsCommand$.describe(LogDirsCommand.scala:50)at kafka.admin.LogDirsCommand$.main(LogDirsCommand.scala:36)at kafka.admin.LogDirsCommand.main(LogDirsCommand.scala)Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: describeLogDirsWhen the brokerId entered by the user does not exist, an error message indicating that the node is not present should be printed.Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: fix HTML (#9127)Reviewers: Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>",5
KAFKA-935: Fix shutdown tool to work with new controlled shutdown API; reviewed by Neha Narkhede,1
KAFKA-13577: Replace easymock with mockito in kafka:core - part 3 (#11674)Reviewers: Tom Bentley <tbentley@redhat.com>,5
"KAFKA-6753: Updating the OfflinePartitions count only when necessary (#5388)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>",5
"MINOR: Update dependencies for Kafka 2.2 (#6116)- Scala 2.12.7 -> 2.12.8- Gradle 5.0 -> 5.1- Jetty 9.4.12 -> 9.4.14- Rat 0.12 -> 0.13- Patch bumps for easymock, jackson, powermock- Patch bumps for gradle plugins: shadow, spotbugs, dependency-check, spotlessReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",0
"MINOR: Add api version to uncaught exception message (#7311)When we have an unhandled exception in the request handler, we print some details about the request such as the api key and payload. It is also useful to see the version of the request which is not always apparent from the request payload.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-1107 Broker unnecessarily recovers all logs when upgrading from 0.8 to 0.8.1; reviewed by Jay Kreps and Guozhang Wang,2
KAFKA-1824 ConsoleProducer - properties key.separator and parse.key no longer work; reviewed by Neha Narkhede,1
"MINOR: Update Streams docs: quickstart and conceptsAdded figures for topology and table-stream duality; added sections about aggregations; misc code fixes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Sriram SubramanianCloses #2482 from guozhangwang/KMinor-streams-docs-first-pass",4
"KAFKA-10272: Add IBM i support to ""stop"" scripts (#9023)Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
MINOR: some small style fixes to RoundRobinPartitionerAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen ShapiraCloses #7058 from cmccabe/rr-style-fixes,0
"MINOR: Refactor `MetricsIntegrationTest` (#6930)Reviewers: Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: a few web doc and javadoc fixes1. Added missing Javadocs in public interfaces.2. Added missing upgrade web docs.3. Minor improvements on exception messages.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Antony Stubbs <antony.stubbs@gmail.com>Closes #4071 from guozhangwang/KMinor-javadoc-gaps",2
"MINOR: Default GRACE with Old API should set as 24H minus window-size / inactivity-gap (#10953)In 2.8 and before, we computed the default grace period with Math.max(maintainDurationMs - sizeMs, 0); in method gracePeriodMs() in TimeWindows, SessionWindows, and JoinWindows. That means that the default grace period has never been 24 hours but 24 hours - window size. Since gracePeriodMs() is used to compute the retention time of the changelog topic for the corresponding window state store and the segments for the window state store it is important to keep the same computation for the deprecated methods. Otherwise, Streams app that run with 2.8 and before might not be compatible with Streams 3.0 because the retention time of the changelog topics created with older Streams apps will be smaller than the assumed retention time for Streams apps in 3.0. For example, with a window size of 10 hours, an old Streams app would have created a changelog topic with retention time 10 hours (window size) + 14 hours (default grace period, 24 hours - 10 hours). A 3.0 Streams app would assume a retention time of 10 hours (window size) + 24 hours (deprecated default grace period as currently specified on trunk). In the presence of failures, where a state store needs to recreated, records might get lost, because before the failure the state store of a 3.0 Streams app contained 10 hours + 24 hours of records whereas the changelog topic that was created with the old Streams app would only contain 10 hours + 14 hours of records.All this happened due to us always stating that the default grace period was 24 hours although it was not completely correct and a connected and unfortunate misunderstanding when we removed deprecated windows APIs (#10378).Co-authors: Bruno Cadonna <cadonna@apache.org>Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-12327: Remove MethodHandle usage in CompressionType (#10123)We don't really need it and it causes problems in older Android versionsand GraalVM native image usage (there are workarounds for the latter).Move the logic to separate classes that are only invoked when therelevant compression library is actually used. Place such classesin their own package and enforce via checkstyle that only theseclasses refer to compression library packages.To avoid cyclic dependencies, moved `BufferSupplier` to the `utils`package.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",4
"MINOR: Refactor SslFactory (#6674)SslFactory: split the part of SslFactory that creates SSLEngine instances into SslEngineBuilder.  When (re)configuring, we simply create a new SslEngineBuilder.  This allows us to make all the builder fields immutable.  It also simplifies the logic for reconfiguring.  Because we sometimes need to test old SslEngine instances against new ones, being able to use both the old and the new builder at once is useful.Create an enum named SslClientAuth which encodes the possible values for ssl.client.auth.  This will simplify the handling of this configuration.SslTransportLayer#maybeProcessHandshakeFailure should treat an SSLHandshakeException with a ""Received fatal alert"" message as a handshake error (and therefore an authentication error.)SslFactoryTest: add some line breaks for very long lines.ConfigCommand#main: when terminating the command due to an uncaught exception, log the exception using debug level in slf4j, in addition to printing it to stderr.  This makes it easier to debug failing junit tests, where stderr may not be kept, or may be reordered with respect to other slf4j messages.  The use of debug level is consistent with how we handle other types of exceptions in ConfigCommand#main.StateChangeLogMerger#main: spell out the full name of scala.io.Source rather than abbreviating it as io.Source.  This makes it clearer that it is part of the Scala standard library.  It also avoids compiler errors when other libraries whose groupId starts with ""io"" are used in the broker.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-12340: Fix potential resource leak in Kafka*BackingStore (#10153)These Kafka*BackingStore classes used in Connect have a recently-added deprecated constructor, which is not used within AK. However, this commit corrects a AdminClient resource leak if those deprecated constructors are used outside of AK. The fix simply ensures that the AdminClient created by the “default” supplier is always closed when the Kafka*BackingStore is stopped.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-10027: Implement read path for feature versioning system (KIP-584) (#8680)In this PR, I have implemented various classes and integration for the read path of the feature versioning system (KIP-584). The ultimate plan is that the cluster-wide finalized features information is going to be stored in ZK under the node /feature. The read path implemented in this PR is centered around reading this finalized features information from ZK, and, processing it inside the Broker.Here is a summary of what's in this PR (a lot of it is new classes):A facility is provided in the broker to declare its supported features, and advertise its supported features via its own BrokerIdZNode under a features key.A facility is provided in the broker to listen to and propagate cluster-wide finalized feature changes from ZK.When new finalized features are read from ZK, feature incompatibilities are detected by comparing against the broker's own supported features.ApiVersionsResponse is now served containing supported and finalized feature information (using the newly added tagged fields).Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",5
"MINOR: Displaying default entity name in MetadataShell (#12053)When debugging some bugs related to configs, I find we are unable to show default broker/topic entity name since the resourceName="""". Changed it to similar to how we trait default client quotas.Reviewers: Luke Chen <showuon@gmail.com>",4
KAFKA-7096 : Clear buffered data for partitions that are explicitly unassigned by userAuthor: mgharat <gharatmayuresh15@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5289 from MayureshGharat/KAFKA-7096,1
system test configs are broken; patched by John Fung; reviewed by Jun Rao; kafka-586git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1404203 13f79535-47bb-0310-9956-ffa450edef68,5
HOTFIX: Fix compilation error in ConsumerPerformance (#5127)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"MINOR: Need to get a new transformer for each get() call. can't share'em (#4435)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",1
"KAFKA-6167: Timestamp on streams directory contains a colon, which is an illegal character - change segment delimiter to . - added upgrade path - added test for old and new upgrade pathAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4210 from mjsax/kafka-6167-windows-issue",0
"KAFKA-1961 Prevent deletion of _consumer_offsets topic; reviewed by Neha Narkhede, Gwen Shapira and Jun Rao",1
"KAFKA-3421: Connect developer guide update and several fixesThis is a follow up of KAKFA-3421 to update the connect developer guide to include the configuration validation. Also includes a couple of minor fixes.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1366 from Ishiihara/connect-dev-doc",2
"KAFKA-6841: Support Prefixed ACLs (KIP-290) (#5117)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>Co-authored-by: Piyush Vijay <pvijay@apple.com>Co-authored-by: Andy Coates <big-andy-coates@users.noreply.github.com>",1
TopicCount.constructTopicCount isn't thread-safe; patched by Jun Rao; reviewed by Joel Koshy and Neha Narkhede; kafka-379git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1376598 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-3618; Handle ApiVersionsRequest before SASL authenticationServer-side implementation and tests for handling ApiVersionsRequest before SaslHandshakeRequest.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #1286 from rajinisivaram/KAFKA-3618",5
"MINOR: capture result timestamps in Kafka Streams DSL tests (#6447)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-2353; SocketServer catch exception and close connection properly; reviewed by Gwen Shapira, Ismael Juma and Guozhang Wang",5
MINOR: reformat settings.gradle to be more readable (#6621)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3854: Fix issues with new consumer's subsequent regex (pattern) subscriptionsThis patch fixes two issues:1. Subsequent regex subscriptions fail with the new consumer.2. Subsequent regex subscriptions would not immediately refresh metadata to change the subscription of the new consumer and trigger a rebalance.The final note on the JIRA stating that a later created topic that matches a consumer's subscription pattern would not be assigned to the consumer upon creation seems to be as designed. A repeat`subscribe()` to the same pattern or some wait time until the next automatic metadata refresh would handle that case.An integration test was also added to verify these issues are fixed with this PR.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1572 from vahidhashemian/KAFKA-3854",5
"KAFKA-10000: Integration tests (#11782)Implements embedded end-to-end integration tests for KIP-618, and brings together previously-decoupled logic from upstream PRs.Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Mickael Maison <mickael.maison@gmail.com>",2
"KAFKA-5117: Stop resolving externalized configs in Connect REST API[KIP-297](https://cwiki.apache.org/confluence/display/KAFKA/KIP-297%3A+Externalizing+Secrets+for+Connect+Configurations#KIP-297:ExternalizingSecretsforConnectConfigurations-PublicInterfaces) introduced the `ConfigProvider` mechanism, which was primarily intended for externalizing secrets provided in connector configurations. However, when querying the Connect REST API for the configuration of a connector or its tasks, those secrets are still exposed. The changes here prevent the Connect REST API from ever exposing resolved configurations in order to address that. rhauch has given a more thorough writeup of the thinking behind this in [KAFKA-5117](https://issues.apache.org/jira/browse/KAFKA-5117)Tested and verified manually. If these changes are approved unit tests can be added to prevent a regression.Author: Chris Egerton <chrise@confluent.io>Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com, Ewen Cheslack-Postava <ewen@confluent.io>Closes #6129 from C0urante/hide-provided-connect-configs",5
"KAFKA-6624; Prevent concurrent log flush and log deletion (#4663)KAFKA-6624; Prevent concurrent log flush and log deletionReviewers: Ted Yu <yuzhihong@gmail.com>, Jun Rao <junrao@gmail.com>",4
KAFKA-9477 Document RoundRobinAssignor as an option for partition.assignment.strategy (#8007)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"KAFKA-14133: Replace EasyMock with Mockito in streams tests (#12492)Batch 1 of the tests detailed in https://issues.apache.org/jira/browse/KAFKA-14133 which use EasyMock and need to be moved to Mockito.Reviewers: Dalibor Plavcic, Matthew de Detrich <mdedetrich@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-1432 Make num.producerThreads configurable on new MirrrorMaker; reviewed by Neha Narkhede, Jun Rao",1
"MINOR: Replace BrokerStates.scala with BrokerState.java (#10028)Replace BrokerStates.scala with BrokerState.java, to make it easier to use from Java code if needed.  This also makes it easier to go from a numeric type to an enum.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"MINOR: Fixed README examples on running specific tests.Author: GabrielNicolasAvellaneda <avellaneda.gabriel@gmail.com>Reviewers: Ismael Juma, Ewen Cheslack-PostavaCloses #268 from GabrielNicolasAvellaneda/readme-updates",5
MINOR: Bump system test version from 2.2.1 to 2.2.2 (#7765)Author: Randall Hauch <rhauch@gmail.com>Reviewer: Ismael Juma <ismael@confluent.io>,5
kafka-1533; transient unit test failure in ProducerFailureHandlingTest; reviewed by Guozhang Wang; reviewed by Jun Rao,3
MINOR: Update log level in SaslServerAuthenticator (#10270)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-3621; Add tests for ApiVersionRequest/ResponseAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1275 from SinghAsDev/KAFKA-3621,3
"KAFKA-13449: Comment optimization for parameter log.cleaner.delete.retention.ms (#11505)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Fix some copy-pasted Javadoc in StreamsConfig.javaThis contribution is my original work and I license the work to the Kafka project under the project's open source license.cc guozhangwang miguno ymatsudaAuthor: Jeff Klukas <jeff@klukas.net>Reviewers: Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #1270 from jklukas/streams-doc-fix",2
trivial 0.9.0 doc changes to fix links,2
"MINOR: allocate 2MB to offset map in connect EmbeddedKafkaCluster (#11619)EmbeddedKafkaCluster in other projects use 2MB for their offset map to reducememory consumption in test runs. Generally we allocate multiple of these offset maps,one for each broker.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-6800: Update SASL/PLAIN and SCRAM docs to use KIP-86 callbacks (#4890),1
MINOR: Bump Kafka version to 0.11.1.0-SNAPSHOTAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3095 from ijuma/bump-kafka-version,5
MINOR: Update Serdes.java (#10117)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
MINOR: Move a few more methods to AuthHelper (#9913)And move some tests to `AuthHelperTest`.Reviewers: David Arthur <mumrah@gmail.com>,3
"MINOR: Add a duplicate() method to Message classes (#8556)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2982; Mark the old Scala producer and related classes as deprecatedAlso update server tests to always use new producer.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1092 from ijuma/kafka-2982-deprecate-old-producers,1
"MINOR: trivial cleanups- Reformat header: `CustomDeserializerTest`, `ReplicaVerificationToolTest`- Remove unused constructor: `ConsumerGroupDescription`- Remove unused variables in `TimeOrderedKeyValueBufferTest#shouldRestoreV2Format`- Remove deprecated `Number` consturctor calls; use `Number#valueOf` instread.Author: Lee Dongjin <dongjin@apache.org>Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7202 from dongjinleekr/cleanup/201908",4
KAFKA-9875: Make integration tests more resilient (#8578)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-4980: testReprocessingFromScratch unit test failureWe got test error `org.apache.kafka.common.errors.TopicExistsException: Topic 'inputTopic' already exists.` in some builds. Can reproduce reliably at local machine. Root cause it async ""topic delete"" that might not be finished before topic gets re-created.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Damian Guy, Guozhang WangCloses #2757 from mjsax/minor-fix-resetintegrationtest",3
"KAFKA-13058; AlterConsumerGroupOffsetsHandler does not handle partition errors correctly. (#11016)This patch updates `AlterConsumerGroupOffsetsHandler` to handle partition errors correctly. The issue is that any partition error fails the entire future instead of being passed as an error for its corresponding partition. Reviewers: Luke Chen <showuon@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-9420; Add flexible version support for converted protocols (#7931)This patch bumps the following APIs in order to enable flexible version support:- SaslAuthenticate- SaslHandshake- CreatePartitions- DescribeDelegationToken- ExpireDelegationToken- RenewDelegationTokenThis change was documented and approved in KIP-482: https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>,5
"MINOR: improve `null` checks for headers (#9513)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Luke Chen @showuon",1
KAFKA-646 Provide aggregate stats at the high level Producer and ZookeeperConsumerConnector level; reviewed by Neha Narkhede,1
refactor the async producer; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-253git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1241754 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-10357: Add setup method to internal topics (#10317)For KIP-698, we need a way to setup internal topics without validating them. This PR adds a setup method to the InternalTopicManager for that purpose.Reviewers: Rohan Desai <rohan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Update log condition in JassContext.loadServerContext (#4566),2
"revert stream logging level back to ERROR (#10320)An accidental change of logging level for streams from #9579, correcting it.Reviewers: Bill Bejeck <bbejeck@gmail.com>",2
"MINOR: Fix KafkaConsumer.commitSync() javadoc @throws declarationsThrows IllegalArgumentException is the offset is negativeAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3780 from mimaison/commitSync_javadoc",2
MINOR: Remove compilation warnings (#7888)* Warnings   1. `kafka/core/src/test/scala/integration/kafka/server/DelayedFetchTest.scala:110: local val partition in method testReplicaNotAvailable is never used`   2. `kafka/core/src/test/scala/unit/kafka/admin/ConfigCommandTest.scala:527: local val alterResourceName in method verifyAlterBrokerConfig is never used`Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"MINOR: Fix wrong message in `bin/kafka-run-class.sh` (#4682)To build jar you need to specify `scalaVersion` instead of `scala_version`.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
kafka-1571; MetadataTest hangs; patched by Jun Rao; reviewed by Guozhang Wang,5
"KAFKA-7409; Validate message format version before creating topics or altering configs (#5651)Values for `message.format.version` and `log.message.format.version` should be verified before topic creation or config change.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8013; Avoid underflow when reading a Struct from a partially correct buffer (#6340)Protocol compatibility can be facilitated if a Struct, that has been defined as an extension of a previous Struct by adding fields at the end of the older version, can read a message of an older version by ignoring the absence of the missing new fields. Reading the missing fields should be allowed by the definition of these fields (they have to be nullable) when supported by the schema.Reviewers: David Arthur <mumrah@gmail.com>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13968: Fix 3 major bugs of KRaft snapshot generating (#12265)There are 3 bugs when a broker generates a snapshot.1. Broker should not generate snapshots until it starts publishing.    Before a broker starts publishing, BrokerMetadataListener._publisher=None, so _publisher.foreach(publish) will do nothing, so featuresDelta.metadataVersionChange().isPresent is always true, so we will generating a snapshot on every commit since we believe metadata version has changed, here are the logs, note offset 1 is a LeaderChangeMessage so there is no snapshot:[2022-06-08 13:07:43,010] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 0... (kafka.server.metadata.BrokerMetadataSnapshotter:66)[2022-06-08 13:07:43,222] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 2... (kafka.server.metadata.BrokerMetadataSnapshotter:66)[2022-06-08 13:07:43,727] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 3... (kafka.server.metadata.BrokerMetadataSnapshotter:66)[2022-06-08 13:07:44,228] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 4... (kafka.server.metadata.BrokerMetadataSnapshotter:66)2. We should compute metadataVersionChanged before _publisher.foreach(publish)    After _publisher.foreach(publish) the BrokerMetadataListener_delta is always Empty, so metadataVersionChanged is always false, this means we will never trigger snapshot generating even metadata version has changed.3. We should try to generate a snapshot when starting publishing    When we started publishing, there may be a metadata version change, so we should try to generate a snapshot before first publishing.Reviewers: Jason Gustafson <jason@confluent.io>, Divij Vaidya <diviv@amazon.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-4619: Dissallow to output records with unknown keys in TransformValuesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2346 from mjsax/kafka-4619-fixTransformValues",0
"KAFKA-7950; Update description for the ""time"" parameter for GetOffsetShellAdded additional description for the ""time"" parameter for GetOffsetShell which adds "" No offset is returned if timestamp provided is greater than recently committed record timestamp."" in the description.Author: KartikVK <karthikkalaghatgi123@gmail.com>Reviewers: huxi <huxi_2b@hotmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6357 from Kartikvk1996/kartik-branch",1
"KAFKA-6430: Add buffer for gzip streams (#4537)As described in the JIRA ticket, this can double throughput.",1
"KAFKA-6981: Move the error handling configuration properties into the ConnectorConfig and SinkConnectorConfig classes (KIP-298)Move the error handling configuration properties into the ConnectorConfig and SinkConnectorConfig classes, and refactor the tests and classes to use these new properties.Testing: Unit tests and running the connect-standalone script with a file sink connector.Author: Arjun Satish <arjun@confluent.io>Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5125 from wicknicks/KAFKA-6981",5
KAFKA-3046: Add ByteBuffer Serializer and Deserializerhttps://issues.apache.org/jira/browse/KAFKA-3046Author: Xin Wang <best.wangxin@163.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #718 from vesense/patch-3,0
"KAFKA-3799: Enable SSL endpoint validation in system testsGenerate certificates with hostname in SubjectAlternativeName and enable hostname validation.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1483 from rajinisivaram/KAFKA-3799",5
"MINOR: Log partition info when creating new request batch in controller (#6145)Due to the missing `$`, the name was being logged instead of the value.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
kafka-2271; transient unit test failure in KafkaConfigConfigDefTest.testFromPropsToProps; patched by Jason Gustafson; reviewed by Jun Rao,5
"KAFKA-10832: Fix Log to use the correct ProducerStateManager instance when updating producers (#9718)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
"KAFKA-9404: Use ArrayList instead of LinkedList in Sensor (#7936)The former is generally a better option than the latter.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-10700 - Support mutual TLS authentication for SASL_SSL listeners (KIP-684) (#10007)mTLS is enabled if listener-prefixed ssl.client.auth is configured for SASL_SSL listeners. Broker-wide ssl.client.auth is not applied to SASL_SSL listeners as before, but we now print a warning.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-10284: Group membership update due to static member rejoin should be persisted (#9270)Reviewers: Boyang Chen <boyang@apache.org>, John Roesler <vvcephei@apache.org>",5
"KAFKA-4428; Kafka does not exit if port is already boundDuring Acceptor initialization, if ""Address already in use"" error is encountered,the shutdown latch in each Processor is never counted down. Consequently,the Kafka server hangs when `Processor.shutdown` is called.Author: huxi <huxi@zhenrongbao.com>Author: amethystic <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2156 from amethystic/kafka-4428_Kafka_noexit_for_port_already_use",1
"KAFKA-724; Allow automatic socket.send.buffer from operating system in SocketServerIf socket.receive.buffer.bytes/socket.send.buffer.bytes are set to -1, use the OS defaults.Author: Joshi <rekhajoshm@gmail.com>Author: Rekha Joshi <rekhajoshm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1469 from rekhajoshm/KAFKA-724-rebased",1
"MINOR: Correct folder for package object scala (#5573)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-3616: Make kafka producers/consumers injectable for KafkaStreamsTicket: https://issues.apache.org/jira/browse/KAFKA-3616Author: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1264 from kawamuray/kafka-3616-inject-clients,0
MINOR: Add header and footer to protocol docsBecause protocol.html is going to be in its own page it needs the header and footer included.Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1043 from granthenke/protocol-docs-style,2
"KAFKA-3043: Replace request.required.acks with acks in docs.In Kafka 0.9, request.required.acks=-1 which configration of producer is replaced by acks=all,but this old config is remained in docs.Author: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Gwen ShapiraCloses #716 from sasakitoa/acks_doc",2
MINOR: Hygiene fixes in KafkaFutureImpl (#5098)Change-Id: Ia44c6c659418bbed5367645b814725365daba820,4
HOTFIX: Fix breakage in `ConsumerPerformanceTest` (#8113)Test cases in `ConsumerPerformanceTest` were failing and causing a system exit rather than throwing the expected exception following #8023. We didn't catch this because the tests were marked as skipped and not failed.Reviewers: Guozhang Wang <guozhang@confluent.io>,5
KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede and Joel Koshy,1
"KAFKA-7893; Refactor ConsumerBounceTest to reuse functionality from BaseConsumerTest (#6238)This PR should help address the flakiness in the ConsumerBounceTest#testRollingBrokerRestartsWithSmallerMaxGroupSizeConfigDisruptsBigGroup test (https://issues.apache.org/jira/browse/KAFKA-7965). I tested this locally and have verified it significantly reduces flakiness - 25/25 tests now pass. Running the test 25 times in trunk, I'd get `18/25` passes.It does so by reusing the less-flaky consumer integration testing functionality inside `BaseConsumerTest`. Most notably, the test now makes use of the `ConsumerAssignmentPoller` class  - each consumer now polls non-stop rather than the more batch-oriented polling we had in `ConsumerBounceTest#waitForRebalance()`.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix system test StreamsCooperativeRebalanceUpgradeTest.test_upgrade_to_cooperative_rebalance (#11532)Log messages were changed in the AssignorConfiguration (#11490) that arealso used for verification in system testStreamsCooperativeRebalanceUpgradeTest.test_upgrade_to_cooperative_rebalance.This commit fixes the test and adds comments to the log messagesthat point to the test that needs to be updated in case ofchanges to the log messages.Reviewers: John Roesler <vvcephei@apache.org>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Fix a variable name semantically correct.Hi all,This is my first commit to Kafka.""msec / 1000"" turns into sec, isn't it?I just have fixed a variable name.grandersAuthor: kota-uchida <kota-uchida@cybozu.co.jp>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1482 from uchan-nos/elapsed-ms",5
KAFKA-371 Refactoring of LogManager. Reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1363542 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-6284: Fixed system test for Connect REST API`topics.regex` was added in KAFKA-3073. This change fixes the test that invokes `/validate` to ensure that all the configdefs are returned as expected.Author: Mikkin <mikkin@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4279 from mikkin/KAFKA-6284",5
MINOR; Return timed out connections as a List instead of a Set (#8999)Using a Set is not necessary as the caller only cares about having the list of timed out connections/nodes.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"MINOR: clarify assertion in handleListPartitionReassignmentsRequest #11219Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>, Ron Dagostino <rndgstn@gmail.com>",2
"KAFKA-5142: Add Connect support for message headers (KIP-145)**[KIP-145](https://cwiki.apache.org/confluence/display/KAFKA/KIP-145+-+Expose+Record+Headers+in+Kafka+Connect) has been accepted, and this PR implements KIP-145 except without the SMTs.**Changed the Connect API and runtime to support message headers as described in [KIP-145](https://cwiki.apache.org/confluence/display/KAFKA/KIP-145+-+Expose+Record+Headers+in+Kafka+Connect).The new `Header` interface defines an immutable representation of a Kafka header (key-value pair) with support for the Connect value types and schemas. This interface provides methods for easily converting between many of the built-in primitive, structured, and logical data types.The new `Headers` interface defines an ordered collection of headers and is used to track all headers associated with a `ConnectRecord` (and thus `SourceRecord` and `SinkRecord`). This does allow multiple headers with the same key. The `Headers` contains methods for adding, removing, finding, and modifying headers. Convenience methods allow connectors and transforms to easily use and modify the headers for a record.A new `HeaderConverter` interface is also defined to enable the Connect runtime framework to be able to serialize and deserialize headers between the in-memory representation and Kafka’s byte[] representation. A new `SimpleHeaderConverter` implementation has been added, and this serializes to strings and deserializes by inferring the schemas (`Struct` header values are serialized without the schemas, so they can only be deserialized as `Map` instances without a schema.) The `StringConverter`, `JsonConverter`, and `ByteArrayConverter` have all been extended to also be `HeaderConverter` implementations. Each connector can be configured with a different header converter, although by default the `SimpleHeaderConverter` is used to serialize header values as strings without schemas.Unit and integration tests are added for `ConnectHeader` and `ConnectHeaders`, the two implementation classes for headers. Additional test methods are added for the methods added to the `Converter` implementations. Finally, the `ConnectRecord` object is already used heavily, so only limited tests need to be added while quite a few of the existing tests already cover the changes.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4319 from rhauch/kafka-5142-b",5
"HOTFIX: KAFKA-3160 follow-up, catch decompression errors in constructorAfter testing KAFKA-3160 a bit more, I found that the error code was not being set properly in ProduceResponse. This happened because the validation error is raised in the CompressionFactory constructor, which was not wrapped in a try / catch.ijuma junrao(This contribution is my original work and I license the work under Apache 2.0.)Author: Dana Powers <dana.powers@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1344 from dpkp/decompress_error_code",0
KAFKA-12809: Remove deprecated methods of Stores factory (#10729)Removes methods deprecated via KIP-319 and KIP-358.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
enhancements to .Net; patched by Eric Hauser; KAFKA-85git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1173797 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Fix some re-raising of exceptions in system testsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2852 from ewencp/minor-re-raise-exceptions,3
"KAFKA-10000: Use transactional producer for leader-only writes to the config topic (#11778)Implements the behavior described in KIP-618: using a transactional producer for writes to the config topic that should only be performed by the leader of the cluster.Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>",5
"KAFKA-6218: Optimize condition in if statement to reduce the number of comparisonsChanged the condition in **if** statement**(schema.name() == null || !(schema.name().equals(LOGICAL_NAME)))** whichrequires two comparisons in worst case with**(!LOGICAL_NAME.equals(schema.name()))**  which requires single comparisonin all cases and _avoids null pointer exception.![kafka_optimize_if](https://user-images.githubusercontent.com/32234013/32872271-afe0b954-ca3a-11e7-838d-6a3bc416b807.JPG)_Author: sachinbhalekar <sachinbansibhalekar@gmail.com>Author: sachinbhalekar <32234013+sachinbhalekar@users.noreply.github.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4225 from sachinbhalekar/trunk",1
"MINOR: Remove topic null check from `TopicIdPartition` and adjust constructor order (#11403)`TopicPartition` allows a null `topic` and there are cases where we havea topic id, but no topic name. Even for `TopicIdPartition`, the non nulltopic name check was only enforced in one constructor.Also adjust the constructor order to move the nullable parameter to theend, update tests and javadoc.Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
kafka-899; LeaderNotAvailableException the first time a new message for a partition is processed; patched by Jun Rao; reviewed by Neha Narkhede,1
"MINOR: Add unit test for SerDe auto-configuration (#6610)Reviewers: Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>",5
KAFKA-161 Producer using broker list does not load balance requests across multiple partitions on a broker; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1188333 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-3292; ClientQuotaManager.getOrCreateQuotaSensors() may return a null ClientSensors.throttleTimeSensorAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #977 from ijuma/kafka-3292-null-throttle-time-sensor,1
"HOTFIX: Fix unstable Streams application reset integration testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1673 from mjsax/hotfix(cherry picked from commit ad1dab9c3d3ae14746ee5d94434ef98ef4889023)Signed-off-by: Ismael Juma <ismael@juma.me.uk>",0
javaapi support for getTopoicMetaData; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-500git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387796 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR: Improve documentation for running docker system testsAdded some tips for running a single test file, test class and/or test method on the documentation landing page about testsAuthor: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3577 from ppatierno/minor-tests-doc",3
KAFKA-1823; Fix transient failure in PartitionAssignorTest; reviewed by Guozhang Wang and Neha Narkhede,3
KAFKA-10887 Migrate log4j-appender module to JUnit 5 (#9785)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
MINOR: Remove extra commas in upgrade steps documentation (#12311)Reviewers: Luke Chen <showuon@gmail.com>,2
"MINOR: update web docs and examples of Streams with Java8 syntax (#5249)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>",5
KAFKA-1621 : Standardize --messages option. Closes #58,5
trivial change to reduce default fetcher queue sizegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1242696 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: set scala version automatically based on gradle.propertiesAuthor: Andras Katona <akatona@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7953 from akatona84/kafkarunclass-auto-scala-version",1
Update expected task configs for FileStream source and sink connectors in ConnectRestApiTest (#12576)Reviewer: Chris Egerton <chrise@aiven.io>,3
"MINOR: Added more integration testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Michael G. Noll, Guozhang WangCloses #1285 from enothereska/more-integration-tests",3
"MINOR: Fix import for streams broker compatibility test to use new DEV_BRANCH constantAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2508 from ewencp/minor-streams-compatibility-trunk-dev-branch",1
"MINOR: Add unit test for internal topicsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1047 from guozhangwang/KInternal",5
KAFKA-5872; Fix transient failure in SslSelectorTest.testMuteOnOOMAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3836 from rajinisivaram/KAFKA-5872-sslselectortest-failure,5
"KAFKA-3807; Fix transient test failure caused by race on future completionAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1821 from hachikuji/KAFKA-3807",5
"KAKFA-8950: Fix KafkaConsumer Fetcher breaking on concurrent disconnect (#7511)The KafkaConsumer Fetcher can sometimes get into an invalid state where it believes that there are ongoing fetch requests, but in fact there are none. This may be caused by the heartbeat thread concurrently handling a disconnection event just after the fetcher thread submits a request which would cause the Fetcher to enter an invalid state where it believes it has ongoing requests to the disconnected node but in fact it does not. This is due to a thread safety issue in the Fetcher where it was possible for the ordering of the modifications to the nodesWithPendingFetchRequests to be incorrect - the Fetcher was adding it after the listener had already been invoked, which would mean that pending node never gets removed again.This PR addresses that thread safety issue by ensuring that the pending node is added to the nodesWithPendingFetchRequests before the listener is added to the future, ensuring the finally block is called after the node is added.Reviewers: Tom Lee, Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
kafka-1017; High number of open file handles in 0.8 producer; patched by Swapnil Ghike; reviewed by Neha Narkhede and Jun Rao,0
ConsoleConsumer throws InvalidConfigException; kafka-697; patched by Swapnil Ghike; reviewed by Jun Rao,5
"MINOR: Factor out controller node provider `BrokerToControllerChannelManager` (#10015)This patch factors out a trait to allow for other ways to provide the controller `Node` object to `BrokerToControllerChannelManager`. In KIP-500, the controller will be provided from the Raft client and not the metadata cache.Reviewers: David Arthur <david.arthur@confluent.io>",5
MINOR: Remove `zipWithIndex` to avoid tuple allocation in hot path in `LogValidator` (#9206)- improvement: +17%- garbage allocation: -12 %**Parameters**1. bufferSupplierStr = NO_CACHING1. bytes = RANDOM1. compressionType = NONE1. maxBatchSize = 5001. messageSize = 1000001. messageVersion = 2**BEFORE**```Benchmark                                                                                                  (bufferSupplierStr)  (bytes)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score       Error   UnitsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed                                        NO_CACHING   RANDOM             500         100000                 2  thrpt   15  2315566.901 ± 35760.064   ops/sUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate                         NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4004.046 ±    61.825  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate.norm                    NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1904.000 ±     0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4007.442 ±    80.422  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1905.678 ±    29.493    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.007 ±     0.001  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.003 ±     0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.count                              NO_CACHING   RANDOM             500         100000                 2  thrpt   15      516.000              countsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.time                               NO_CACHING   RANDOM             500         100000                 2  thrpt   15      491.000                  ms```**AFTER**```Benchmark                                                                                                  (bufferSupplierStr)  (bytes)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   UnitsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed                                        NO_CACHING   RANDOM             500         100000                 2  thrpt   15  2715876.329 ± 4288.625   ops/sUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate                         NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4163.501 ±    6.553  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.alloc.rate.norm                    NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1688.000 ±    0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM             500         100000                 2  thrpt   15     4164.497 ±   56.694  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM             500         100000                 2  thrpt   15     1688.397 ±   22.173    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.008 ±    0.002  MB/secUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM             500         100000                 2  thrpt   15        0.003 ±    0.001    B/opUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.count                              NO_CACHING   RANDOM             500         100000                 2  thrpt   15      536.000             countsUncompressedRecordBatchValidationBenchmark.measureAssignOffsetsNonCompressed:·gc.time                               NO_CACHING   RANDOM             500         100000                 2  thrpt   15      518.000                 ms```Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-7394; OffsetsForLeaderEpoch supports topic describe access (#5634)As part of KIP-320, allow OffsetsForLeaderEpoch requests with Topic Describe permission.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-2586; Enable SSL for inter-broker communication when SSL is enabled in testsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #252 from ijuma/kafka-2586-enable-inter-broker-ssl-in-tests,3
KAFKA-5093; Avoid loading full batch data when possible when iterating FileRecordsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3160 from hachikuji/KAFKA-5093,5
KAFKA-7367: Streams should not create state store directories unless they are needed (#5696)* KAFKA-7367: Ensure stateless topologies don't require disk access* KAFKA-7367: Streams should not create state store directories unless they are needed.* Addressed the review comments.* Addressed the review-2 comments.* Fixed FileAlreadyExistsException* Addressed the review-3 comments.* Resolved the conflicts.,5
"KAFKA-10199: Add interface for state updater (#11499)Reviewers: Andrew Eugene Choi <andrew.choi@uwaterloo.ca>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-6917; Process txn completion asynchronously to avoid deadlock (#5036)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"HOTFIX: KIP-851, rename requireStable in ListConsumerGroupOffsetsOptions",1
"KAFKA-8460: produce records with current timestamp (#9877)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-6174; Add methods in AdminClient Options classes to restore binary compatibility with 0.11From 0.11 to 1.0, we moved `DescribeClusterOptions timeoutMs(Integer timeoutMs)` fromDescribeClusterOptions to AbstractOptions (similarly for other Options classes). This cancause code compiled against 0.11.0.x to fail when it is executed with 1.0 kafka-clients jar.This patch adds back these methods to restore binary compatibility with 0.11.Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4257 from lindong28/KAFKA-6174",1
KAFKA-667 Change the .highwatermark file name.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1420356 13f79535-47bb-0310-9956-ffa450edef68,2
"MINOR: Always return partitions with diverging epochs in fetch response (#9567)Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-4002: task.open() should be invoked in case that 0 partitions is assigned to taskAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1686 from Ishiihara/open-partition,5
KAFKA-3789; Upgrade Snappy to fix snappy decompression errorsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1467 from granthenke/snappy-fix,0
"KAFKA-12958: add an invariant that notified leaders are never asked to load snapshot (#10932) Track handleSnapshot calls and make sure it is never triggered on the leader node.Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Boyang Chen <bchen11@outlook.com>",1
"KAFKA-9815; Ensure consumer always re-joins if JoinGroup fails (#8420)On metadata change for assigned topics, we trigger rebalance, revoke partitions and send JoinGroup. If metadata reverts to the original value and JoinGroup fails, we don't resend JoinGroup because we don't set `rejoinNeeded`. This PR sets `rejoinNeeded=true` when rebalance is triggered due to metadata change to ensure that we retry on failure.Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Disable SocketServerTest.closingChannelWithBufferedReceives and SocketServerTest.remoteCloseWithoutBufferedReceives (#11960)This reverts commit d706d6cac4622153973d131417e809ee57c60de0.Reviewers: Bruno Cadonna <cadonna@apache.org>,1
MINOR: update javadocs for serde (#3047)Reviewers: Matthias J. Sax <mjsax@apache.org>,2
KAFKA-2774: Rename Copycat to Kafka ConnectAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #456 from ewencp/kafka-2774-rename-copycat,2
"KAFKA-5697; Implement new consumer poll API from KIP-266 (#4855)Add the new stricter-timeout version of `poll` proposed in KIP-266.The pre-existing variant `poll(long timeout)` would block indefinitely for metadataupdates if they were needed, then it would issue a fetch and poll for `timeout` ms for new records. The initial indefinite metadata block caused applications to becomestuck when the brokers became unavailable. The existence of the timeout parametermade the indefinite block especially unintuitive.This PR adds `poll(Duration timeout)` with the semantics:1. iff a metadata update is needed:    1. send (asynchronous) metadata requests    2. poll for metadata responses (counts against timeout)        - if no response within timeout, **return an empty collection immediately**2. if there is fetch data available, **return it immediately**3. if there is no fetch request in flight, send fetch requests4. poll for fetch responses (counts against timeout)    - if no response within timeout, **return an empty collection** (leaving async fetch request for the next poll)    - if we get a response, **return the response**The old method, `poll(long timeout)` is deprecated, but we do not change its semantics, so it remains:1. iff a metadata update is needed:    1. send (asynchronous) metadata requests    2. poll for metadata responses *indefinitely until we get it*2. if there is fetch data available, **return it immediately**3. if there is no fetch request in flight, send fetch requests4. poll for fetch responses (counts against timeout)    - if no response within timeout, **return an empty collection** (leaving async fetch request for the next poll)    - if we get a response, **return the response**One notable usage is prohibited by the new `poll`: previously, you could call `poll(0)` to block for metadata updates, for example to initialize the client, supposedly without fetching records. Note, though, that this behavior is not according to any contract, and there is no guarantee that `poll(0)` won't return records the first time it's called. Therefore, it has always been unsafe to ignore the response.",5
"KAFKA-3858: Add functions to print stream topologiesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Roger Hoover, Matthias J. Sax, Guozhang WangCloses #1619 from enothereska/KAFKA-3858-print-topology",2
"MINOR: Streams tutorial refers to code in the wrong directory (#7012)The Pipe.java file should exist within the myapps package directory.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8609: Add consumer rebalance metrics (#7347)Adding the following metrics in:1. AbstractCoordinator (for both consumer and connect)* rebalance-latency-avg* rebalance-latency-max* rebalance-total* rebalance-rate-per-hour* failed-rebalance-total* failed-rebalance-rate-per-hour* last-rebalance-seconds-ago2. ConsumerCoordinator* partition-revoked-latency-avg* partition-revoked-latency-max* partition-assigned-latency-avg* partition-assigned-latency-max* partition-lost-latency-avg* partition-lost-latency-maxReviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Update documentation for internal changelog when using table(). (#6021)Updating the documentation for table operation because I believe it is incorrect.In PR #5163 the table operation stopped disabling the changelog topic by default and instead moved that optimization to a configuration that is not enabled by default. This PR updates the documentation to reflect the change in behavior and point to the new configuration for optimization.Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-3091: Broker persists generated ID even when the ID can't be used due to duplicates…updated to a new valid oneAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #763 from granthenke/id-start-failure,0
TopicConfigManager javadoc references incorrect paths; reviewed by Neha Narkhede,2
"MINOR: Set default `group.instance.id` in JoinGroupResponse to null (#6831)As we are planning to add on more supporting features for rebalancing under static membership, we need to make sure the behavior for `group.instance.id` is consistent throughout the whole stack. This patch ensures that the default value is null in the JoinGroup response.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6349: Fix concurrent modification exception in AbstractStateManager during restoreFixes a `ConcurrentModificationException` in`AbstractStateManager` that is triggered when a `StateStore` is re-initialized and there are multiple stores in the context.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, GuozhangWang <wangguoz@gmail.com>Closes #4317 from dguy/kafka-6349",5
"KAFKA-5567: Connect sink worker should commit offsets of original topic partitionsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3499 from kkonstantine/KAFKA-5567-With-transformations-that-mutate-the-topic-partition-committing-offsets-should-to-refer-to-the-original-topic-partition",1
"MINOR: ducker-ak: add down -f, avoid using a terminal in ducker testWhen using ./ducker-ak test on Jenkins, the script complains that there is no TTY.  To fix this, we should skip passing -t to docker exec.  We do not need a pseudo-TTY to run the tests.  Similarly, we should skip passing -i, since we do not need to keep stdin open.The down command should have a force option, specified as -f or --force.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",1
KAFKA-657 Change property name to offset.metadata.max.bytes for consistency.,5
KAFKA-2848; Use client SSL/SASL config utilities in Kafka Connect to avoid duplication of configs.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #539 from ewencp/kafka-2848-reuse-ssl-sasl-client-configs,5
"KAFKA-4269: Update topic subscription when regex pattern specified out of topicGroups method…d out of topicGroups method. The topicGroups method only called from StreamPartitionAssignor when KafkaStreams object  is the leader, needs to be executed for clients.Author: bbejeck <bbejeck@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2005 from bbejeck/KAFKA-4269_multiple_kstream_instances_mult_consumers_npe",5
"KAFKA-7141; Consumer group describe should include groups with no committed offsets (#5356)Currently, if a consumer group never commits offsets, ConsumerGroupCommand will not include it in the describe output even if the member assignment is valid. Instead, the tool should be able to describe the group information showing empty current_offset and LAG.Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: release.py: fix some compatibility problems.Rather than using sed, use built-in Python regular expressions to stripthe SNAPSHOT expression from the pom.xml files.  Sed has different flagson different platforms, such as Linux.  Using Python directly here ismore compatible, as well as being more efficient, and not requiring anrm command afterwards.When running release_notes.py, use the current Python interpreter.This is needed to prevent attempting to run release_notes.py withPython 3 on some systems.  release_notes.py will not (yet) work withPython 3.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Magnus Edenhill <magnus@edenhill.se>, David Arthur <mumrah@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6198 from cmccabe/release_py",5
"KAFKA-9864: Avoid expensive QuotaViolationException usage (#8477)QuotaViolationException generates an exception message via String.format in the constructoreven though the message is often not used, e.g. https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/ClientQuotaManager.scala#L258. We now override `toString` instead.It also generates an unnecessary stack trace, which is now avoided using the same pattern as in ApiException.I have also avoided use of QuotaViolationException for control flow inReplicationQuotaManager which is another hotspot that we have seen in practice.Reviewers: Gwen Shapira <gwen@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-7478: Reduce default logging verbosity in OAuthBearerLoginModule (#5738)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Xavier Léauté <xl+github@xvrl.net>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Implement ApiError#equals and hashCode (#9390)Reviewers: Mickael Maison <mickael.maison@gmail.com>,0
MINOR: fix inconsistance in LogCleaner javadoc (#4027)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-4490: Add Global Table support to Kafka StreamsAdd Global Tables to KafkaStreams. Global Tables are fully replicated once-per instance of KafkaStreams. A single thread is used to update them. They can be used to join with KStreams, KTables, and other GlobalKTables. When participating in a join a GlobalKTable is only ever used to perform a lookup, i.e., it will never cause data to be forwarded to downstream processor nodes.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2244 from dguy/global-tables",5
"KAFKA-1901; Added error handling when no file exists in .git/refs/heads.guozhangwang  added .git/refs/heads/ file existence check.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #209 from omkreddy/KAFKA-1901",2
"KAFKA-4331: Kafka Streams resetter is slow because it joins the same group for each topic  - bug-fix follow up  - Resetter fails if no intermediate topic is used because seekToEnd() commit ALL partitions to EOLAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Roger Hoover, Guozhang WangCloses #2138 from mjsax/kafka-4331-streams-resetter-bugfix",0
"KAFKA-544. Follow-up items on key-retention. Addresses misc. comments from Joel, see ticket for details. git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1413839 13f79535-47bb-0310-9956-ffa450edef68",1
MINOR: Fix log statement whose placeholders are inconsistent with arguments (#10312)1. When the 2nd argument is an exception we don't need a placeholder2. Placeholders should equal to arguments.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"MINOR: Reduce scala compilation time by 15% via scalac backend parallelism (#11739)Introduce `maxScalacThreads` and set the default to the lowest of `8`and the number of processors available to the JVM. The number `8` waspicked empirically, the sweet spot is between 6 and 10.On my desktop, `./gradlew clean core:compileScala core:compileTestScala`improved from around 60s to 51s ( with this change.While at it, we improve the build output to include more usefulinformation at the start: build id, max parallel forks, max scalathreads and max test retries.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Sean Li",3
"HOTFIX: fix broken streams testAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3493 from dguy/hotfix-test-failure",3
"KAFKA-7066 added better logging in case of Serialisation issue (#5239)Following the error message of: https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/SinkNode.java#L93Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-2026: fix logging of unsued options always showing null; reviewed by Ewen Cheslack-Postava and Jiangjie Qin,2
"KAFKA-12568: Remove deprecated APIs in KStream, KTable and Joined (#10421)This is related to KIP-307 / KIP-372 / KIP-479.Reviewers: John Roesler <vvcephei@apache.org>",4
HOTFIX: fix checkstyle issue in KAFKA-12697,0
KAFKA-944 fixing up for release pom output from publish and publish-local is not accurate,0
"KAFKA-13456; Tighten KRaft listener config checks/constraints (#11503)This patch tightens the configuration checks related to KRaft configs by adding the following constraints:* `control.plane.listener.name` is confirmed to be empty in KRaft mode whenever a config object is created as opposed to later when the broker is given the config and tries to start.* `controller.listener.names` is required to be empty for the non-KRaft (i.e. ZooKeeper) case.  A ZooKeeper-based cluster that sets this config will fail to restart until this config is removed.* There must be no advertised listeners when running just a KRaft controller (i.e. when `process.roles=controller`).  This means neither `listeners` nor `advertised.listeners` (if the latter is explicitly defined) can contain a listener that does not also appear in `controller.listener.names`.* When running a KRaft broker (i.e. when `process.roles=broker` or `process.roles=broker,controller`), advertised listeners (which was already checked to be non-empty via the check that the inter-broker listener appear there) must not include any listeners appearing in `controller.listener.names`.* When running a KRaft controller (i.e. when `process.roles=controller` or `process.roles=broker,controller`) `controller.listener.names` must be non-empty and every one must appear in `listeners`* When running just a KRaft broker (i.e. when `process.roles=broker`) `controller.listener.names` must be non-empty and none of them can appear in `listeners`.  This was indirectly checked previously, but the indirect checks did not catch all cases.* When running just a KRaft broker we log a warning if more than one entry appears in `controller.listener.names` because only the first entry is used.* We also map configured controller listener names to the `PLAINTEXT` security protocol by default provided that the security mapping is empty and no other security protocols are in use.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9615: Clean up task/producer create and close (#8213)* Consolidate task/producer management. Now, exactly one component manages  the creation and destruction of Producers, whether they are per-thread or per-task.* Add missing test coverage on TaskManagerTestReviewers: Guozhang Wang <wangguoz@gmail.com>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-13769: Explicitly route FK join results to correct partitions (#11945)Prior to this commit FK response sink routed FK results toSubscriptionResolverJoinProcessorSupplier using the primary key.There are cases, where this behavior is incorrect. For example,if KTable key serde differs from the data source serde which mighthappen without a key changing operation.Instead of determining the resolver partition by serializing the PKthis patch includes target partition in SubscriptionWrapper payloads.Default FK response-sink partitioner extracts the correct partitionfrom the value and routes the message accordingly.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3942; Change IntegrationTestUtils.purgeLocalStreamsState to use java.io.tmpdirIt was previously only deleting files/folders where the path started with /tmp. Changed it to delete from the value of the System Property `java.io.tmpdir`. Also changed the tests that were creating State dirs under /tmp to just use `TestUtils.tempDirectory(..)`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1600 from dguy/kafka-3942",3
MINOR: Remove unused fields in StreamsMetricsImpl (#7992)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-9505: Only loop over topics-to-validate in retries (#8039)Found this bug from the repeated flaky runs of system tests, it seems to be long lurking but also would only happen if there are frequent rebalances / topic creation within a short time, which is exactly the case in some of our smoke system tests.Also added a unit test.Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3857; Additional log cleaner metricsFixes KAFKA-3857Changes proposed in this pull request:An additional log cleaner metric has been added:time-since-last-run-ms: Time since the last log cleaner run, in milliseconds.  This metric would be reset to 0 every time log cleaner thread runs. If this metric keeps constantly increasing, it indicates that the log cleaner thread is not alive.If you are creating alerts around log cleaner, you could monitor this metric. A high ""time-since-last-run-ms"" value (eg: 600000) indicates that the log cleaner hasn't been running since the last 10 minutes.The code has been tested. JMX metric has been verified.Note: This pull request is a continuation of the following pull request.  PR#1593 was quite old and I had some trouble rebasing it. Decided to start a fresh PR.https://github.com/apache/kafka/pull/1593/files/927b28cf41275874945beb7377f7f36c462f27c8#diff-ca1c127eee4b3c748ae73028f6abeab8Author: Kiran Pillarisetty <pillarisetty@tivo.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2378 from kiranptivo/log_cleaner_jmx_metric",4
KAFKA-13834: add test coverage for RecordAccumulatorTest (#12092)Reviewers: Luke Chen <showuon@gmail.com>,3
"MINOR: Fix NPE handling unknown APIs in NodeApiVersions.toStringAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2561 from hachikuji/fix-npe-api-version-tostring",0
"KAFKA-2964: Split Security Rolling Upgrade Test by Client and Broker ProtocolsThe core of this PR is to ensure we evaluate enabling security in a running cluster where we have different broker and client protocols.Also in this PR are some improvements to the validation process in produce_consume_validate.py which make it easier to work out where missing messages have been lost:- Fail fast if producer or consumer stop running.- If messages go missing, check in the data files to see if the cause was data loss or the consumer missing messages.- Make it possible for the ConsoleConsumer to log both what it consumed and when it consumed it (and enable this feature in produce_consume_validate tests)Author: Ben Stopford <benstopford@gmail.com>Reviewers: Gwen Shapira, Geoff AndersonCloses #667 from benstopford/security-rolling_upgrade-additions",1
KAFKA-7834: Extend collected logs in system test services to include heap dumps* Enable heap dumps on OOM with -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<file.bin> in the major services in system tests* Collect the heap dump from the predefined location as part of the result logs for each service* Change Connect service to delete the whole root directory instead of individual expected files* Tested by running the full suite of system testsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #6158 from kkonstantine/KAFKA-7834,5
KAFKA-12648: MINOR - Add TopologyMetadata.Subtopology class for subtopology metadata (#10676)Introduce a Subtopology class to wrap the topicGroupId and namedTopology metadata.Reviewers: Walker Carlson <wcarlson@confluent.io>,5
KAFKA-3194: Validate security.inter.broker.protocol against the adver……tised.listeners protocolsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael JumaCloses #851 from granthenke/verify-protocol,5
"KAFKA-3583: Add documentation for Connect status control APIsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Roger Hoover <roger.hoover@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1358 from hachikuji/KAFKA-3583",5
MINOR: Update KRaft README.md and upgrade.html for 3.0Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"KAFKA-2990; Fix NoSuchMethodError in Pool with cast to ConcurrentMapAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #675 from hachikuji/KAFKA-2990",5
MINOR:Fix typo in the impl source (#4587)The static method KStreamImpl.createReparitionedSource() is missing a t.This PR globally fixes the typo and keeps the code indentation consistent.,2
MINOR: Add log when the consumer does not send an offset commit due to not being part of an active group (#6404)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-1334; Add the heartbeat logic to consumer coordinator; reviewed by Guozhang Wang,2
KAFKA-12257; Consumer mishandles topics deleted and recreated with the same name (#11004)Store topic ID info in consumer metadata. We will always take the topic ID from the latest metadata response and remove any topic IDs from the cache if the metadata response did not return a topic ID for the topic. The benefit of this is that it lets us detect topic recreations. This allows the client to update metadata even if the leader epoch is lower than what was seen previously.Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Remove redundant log close in `KafkaRaftClient` (#10168)This patch fixes a small shutdown bug. Current logic closes the log twice: once in `KafkaRaftClient`, and once in `RaftManager`. This can lead to errors like the following:```[2021-02-18 18:35:12,643] WARN  (kafka.utils.CoreUtils$)java.nio.channels.ClosedChannelException        at java.base/sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:150)        at java.base/sun.nio.ch.FileChannelImpl.force(FileChannelImpl.java:452)        at org.apache.kafka.common.record.FileRecords.flush(FileRecords.java:197)        at org.apache.kafka.common.record.FileRecords.close(FileRecords.java:204)        at kafka.log.LogSegment.$anonfun$close$4(LogSegment.scala:592)        at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)        at kafka.log.LogSegment.close(LogSegment.scala:592)        at kafka.log.Log.$anonfun$close$4(Log.scala:1038)        at kafka.log.Log.$anonfun$close$4$adapted(Log.scala:1038)        at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)        at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)        at scala.collection.AbstractIterable.foreach(Iterable.scala:919)        at kafka.log.Log.$anonfun$close$3(Log.scala:1038)        at kafka.log.Log.close(Log.scala:2433)        at kafka.raft.KafkaMetadataLog.close(KafkaMetadataLog.scala:295)        at kafka.raft.KafkaRaftManager.shutdown(RaftManager.scala:150)```I have tended to view `RaftManager` as owning the lifecycle of the log, so I removed the extra call to close in `KafkaRaftClient`.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",1
KAFKA-13846: Follow up PR to address review comments (#12297)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Support versions with 3 segments in _kafka_jar_versionsThe bump from 0.11.1.0-SNAPSHOT to 1.0.0-SNAPSHOT broke a coupleof system tests:* TestVerifiableProducer.test_simple_run* KafkaVersionTest.test_multi_versionAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3587 from ijuma/fix-_kafka_jar_versions,0
"KAFKA-7340: Migrate clients module to JUnit 5 (#9874)* Use the packages/classes from JUnit 5* Move description in `assert` methods to last parameter* Convert parameterized tests so that they work with JUnit 5* Remove `hamcrest`, it didn't seem to add much value* Fix `Utils.mkEntry` to have correct `equals` implementation* Add a missing `@Test` annotation in `SslSelectorTest` override* Adjust regex in `SaslAuthenticatorTest` due to small change in theassert failure string in JUnit 5Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-12756: Update ZooKeeper to v3.6.3 (#10918)Update the ZooKeeper version to v3.6.3. This requires adding dropwizardas a new dependency.Also, add Kafka v2.8.0 to the ducktape system test image.Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",3
"MINOR:Use StoreBuilder.name() for node name (#5588)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
MINOR: a single doc typo (#2969),2
MINOR; Provide static constants with lowest and highest supported versions alongside with the schema (#8916)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-3255: Added unit tests for NetworkClient.connectionDelay(Node node, long now)Author: Frank Scholten <frank@frankscholten.nl>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #941 from frankscholten/tests/cluster-connection-states",3
"KAFKA-3667; Improve Section 7.2 Encryption and Authentication using SSL to include proper hostname verification configurationBy default Kafka is configured to allow ssl communication without hostname verification. This docs has been amended to include instructions on how to set that up in the event clients would like to take a more conservative approach.Author: Ryan P <ryan.n.pridgeon@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1384 from rnpridgeon/KAFKA-3667",5
"KAFKA-10111: Make SinkTaskContext.errantRecordReporter() a default method (#8814)Connector projects may have their own mock or testing implementations of the `SinkTaskContext`, and this newly-added method should be a default method to prevent breaking those projects. Changing this to a default method that returns null also makes sense w/r/t the method semantics, since the method is already defined to return null if the reporter has not been configured.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"kafka-1410; MetadataCache cleanup; patched by Jun Rao; reviewed by Timothy Chen, Joel Koshy",4
MINOR: Remove deprecated per-partition lag metricsIt takes O(n^2) time to instantiate a mbean with n attributes which can be very slow if the number of attributes of this mbean is large. This PR removes metrics whose number of attributes can grow with the number of partitions in the cluster to fix the performance issue. These metrics have already been marked for removal in 2.0 by KIP-225.Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #5172 from lindong28/remove-deprecated-metrics,4
"MINOR: Update build and test dependencies (#9645)The spotbugs upgrade means we can re-enableRCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE and RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE.These uncovered one bug, one unnecessary null check and onefalse positive. Addressed them all, including a test for the bug.* gradle (6.7.0 -> 6.7.1): minor fixes.* gradle versions plugin (0.29.0 -> 0.36.0): minor fixes.* grgit (4.0.2 -> 4.1.0): a few small fixes and dependency bumps.* owasp dependency checker plugin (5.3.2.1 -> 6.0.3): improved dbschema, data and several fixes. * scoverage plugin (4.0.2 -> 5.0.0): support Scala 2.13.* shadow plugin (6.0.0 -> 6.1.0): require Java 8, support for Java 16.* spotbugs plugin (4.4.4 -> 4.6.0): support SARIF reporting standard.* spotbugs (4.0.6 -> 4.1.4): support for Java 16 and various fixes includingtry with resources false positive.* spotless plugin (5.1.0 -> 5.8.2): minor fixes.* test retry plugin (1.1.6 -> 1.1.9): newer gradle and java version compatibilityfixes.* mockito (3.5.7 -> 3.6.0): minor fixes.* powermock (2.0.7 -> 2.0.9): minor fixes.Release notes links:* https://docs.gradle.org/6.7.1/release-notes.html* https://github.com/spotbugs/spotbugs/blob/4.1.4/CHANGELOG.md* https://github.com/scoverage/gradle-scoverage/releases/tag/5.0.0* https://github.com/johnrengelman/shadow/releases/tag/6.1.0* https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.0* https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.0* https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.5.0* https://github.com/ben-manes/gradle-versions-plugin/releases* https://github.com/ajoberstar/grgit/releases/tag/4.1.0* https://github.com/jeremylong/DependencyCheck/blob/main/RELEASE_NOTES.md#version-603-2020-11-03* https://github.com/powermock/powermock/releases/tag/powermock-2.0.8* https://github.com/powermock/powermock/releases/tag/powermock-2.0.9* https://github.com/mockito/mockito/blob/v3.6.0/doc/release-notes/official.md* https://github.com/gradle/test-retry-gradle-plugin/releases* https://github.com/diffplug/spotless/blob/main/plugin-gradle/CHANGES.mdReviewers: Chia-Ping Tsai <chia7712@gmail.com>",4
MINOR: Correct RestServerTest formatting,3
MINOR: close producer instance in AbstractJoinIntegrationTest (#5459)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-13692: include metadata wait time in total blocked time (#11805)This patch includes metadata wait time in total blocked time. First, this patch adds a new metric for total producer time spent waiting on metadata, called metadata-wait-time-ms-total. Then, this time is included in the total blocked time computed from StreamsProducer.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-1893: Allow regex subscriptions in the new consumerAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Jason Gustafson, Guozhang Wang, Edward Ribeiro, Ismael JumaCloses #128 from SinghAsDev/KAFKA-1893",1
"KAFKA-12945: Remove port, host.name and related configs in 3.0 (#10872)They have been deprecated since 0.10.0. Full list of removes configs:* port* host.name* advertised.port* advertised.host.nameAlso adjust tests to take the removals into account. Some tests wereno longer relevant and have been removed.Finally, took the chance to:* Clean up unnecessary usage of `KafkaConfig$.MODULE$` inrelated files.* Add missing `Test` annotations to `AdvertiseBrokerTest` andmake necessary changes for the tests to pass.Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
KAFKA-589 Clean shutdown after startup connection failure; reviewed by Neha Narkhede,0
KAFKA-5817: [FOLLOW-UP] add SerializedInternalAdd `SerializedInternal` class and remove getters from `Serialized`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3825 from dguy/kafka-5817-follow-up,1
"MINOR: Some more Kafka Streams JavadocsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #853 from guozhangwang/KJavaDoc",2
"KAFKA-6101; Reconnecting to broker does not exponentially backoffAuthor: tedyu <yuzhihong@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Soenke Liebau <soenke.liebau@opencore.com>, Ismael Juma <ismael@juma.me.uk>Closes #4118 from tedyu/trunk",1
"MINOR: Reordering the props modification with configs constructionReviewers: Randall Hauch <rhauch@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: Remove obsolete variables for metric sensors (#10912)This is a clean-up that we missed for ""KIP-743: Remove config value 0.10.0-2.4 of Streams built-in metrics version config""Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-9180: Introduce BrokerMetadataCheckpointTest (#7700)While investigating KAFKA-9180, I noticed that we had nounit test coverage. It turns out that the behavior wascorrect, so we just fix the test coverage issue.Also updated .gitignore with jmh-benchmarks/generated.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
KAFKA-10199: Add RESUME in state updater (#12387)* Need to check enforceRestoreActive / transitToUpdateStandby when resuming a paused task.* Do not expose another getResumedTasks since I think its caller only need the getPausedTasks.Reviewers: Bruno Cadonna <cadonna@apache.org>,1
KAFKA-5472: Eliminated duplicate group names when validating connector resultsKafka Connect was adding duplicate group names in the response from the REST API's validation of connector configurations. This fixes the duplicates and maintains the order of the `ConfigDef` objects so that the `ConfigValue` results are in the same order.This is a blocker and should be merged to 0.11.0.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3379 from rhauch/KAFKA-5472,5
"KAFKA-9079: Fix reset logic in transactional message copierThe consumer's `committed` API does not return an entry in the response map for a requested partition if there is no committed offset. The transactional message copier, which is used in the transaction system test, did not account for this. If the first transaction attempted by the copier was randomly aborted, then we would not seek to the beginning as expected, which means we would fail to copy some of the records.This patch fixes the problem by iterating over the assignment rather than the result of `committed` when resetting offsets. It also adds enables additional logging in the transaction message copier service to make finding problems easier in the future.Author: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7653 from hachikuji/fix-transaction-system-test",5
"KAFKA-13258/13259/13260: Fix error response generation (#11288)AlterClientQuotas, DescribeProducers and FindCoordinator have issues when building error responses. This can lead to brokers returning responses without errors even when some have happened.Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Luke Chen <showuon@gmail.com>",5
MINOR: Fix left/outer join descriptions in Streams DSL reference topic (#10453)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Improve producer test BufferPoolTest#testCloseNotifyWaiters. (#7982)Makes the main thread wait for workers to be ready to test thedesired functionality before proceeding.Reviewers: Ted Yu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Preserve backwards-compatibility by renaming the AlterPartitionReassignment metric to PartitionReassignmentIn https://github.com/apache/kafka/commit/18d4e57f6e8c67ffa7937fc855707d3a03cc165a#diff-394389922df5210adf43a8b7064cc4ffL61 we unintentionally renamed the metric with the previous changes to reassignmentsAuthor: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7606 from stanislavkozlovski/minor-partition-reassignment-metric,4
HOTFIX: Set `baseOffset` correctly in `RecordAccumulator`The bug meant that the base offset was the same as the batch size instead of 0 so the broker would always recompress batches.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #2794 from ijuma/fix-records-builder-construction,0
KAFKA-4764; Upgrade notes for authentication failure handling (KIP-152)Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4013 from rajinisivaram/MINOR-upgrade-auth-failure,5
kafka-2270; incorrect package name in unit tests; patched by Proneet Verma; reviewed by Jun Rao,3
KAFKA-12464: minor code cleanup and additional logging in constrained sticky assignment (#10645)This is the follow up PR to address the remaining comments in #10509.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
extend DumpLogSegments to verify consistency btw data and index; patched by Yang Ye; reviewed by Jun Rao; KAFKA-577git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1406009 13f79535-47bb-0310-9956-ffa450edef68,5
MINOR: Fix comments in TransactionsTest (#11880)Reviewer: Luke Chen <showuon@gmail.com>,3
"KAFKA-9069: Flaky Test AdminClientIntegrationTest.testCreatePartitionshttps://issues.apache.org/jira/browse/KAFKA-9069Make `getTopicMetadata` in AdminClientIntegrationTest always read metadata from controller to get a consistent view.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: huxihx <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, José Armando García Sancio <jsancio@gmail.com>Closes #7619 from huxihx/KAFKA-9069",4
"KAFKA-12175 Migrate generator module to junit5 (#9926)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
Added quotes around the class path (#4469)The script otherwise fails when the classpath contains paths with spaces.,0
"MINOR: Request log should be enabled by debug levelAt some point, we lost the ability to output requestlogging at debug level (which is a little lessverbose than at trace level).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3595 from ijuma/fix-debug-request-log",2
kafka-17693; javadoc should only include client facing packages; patched by Jun Rao; reviewed by Neha Narkhede,2
"MINOR: Rename and change package of async ZooKeeper classes- kafka.controller.ZookeeperClient -> kafka.zookeeper.ZooKeeperClient- kafka.controller.ControllerZkUtils -> kafka.zk.KafkaZkClient- kafka.controller.ZkData -> kafka.zk.ZkData- Renamed various fields to match new names and for consistency- A few clean-ups in ZkData- Document intentAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Onur Karaman <okaraman@linkedin.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>Closes #4112 from ijuma/rename-zookeeper-client-and-move-to-zookeper-package",4
"MINOR: clarify statefulness in transform/process variations (#7668)Reviewer: Almog Gavra <almog@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3169; Limit receive buffer size for SASL packets in brokerLimit receive buffer size to avoid OOM in broker with invalid SASL packetsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #831 from rajinisivaram/KAFKA-3169",5
"Moved 'expired-window-' and 'late-' record-drop to StreamsMetricsImpl (#6355)Moved hard-coded 'expired-window-record-drop' and 'late-record-drop' to static Strings in StreamsMetricsImplReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",4
"KAFKA-7885: TopologyDescription violates equals-hashCode contract. (#6210)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-1286 Retry can block. Patch from Guozhang, reviewed by jay.",1
"KAFKA-9039: Optimize ReplicaFetcher fetch path (#7443)Improves the performance of the replica fetcher for high partition count fetch requests, where a majority of the partitions did not update between fetch requests. All benchmarks were run on an r5x.large.VanillaBenchmark (partitionCount) Mode Cnt Score Error UnitsReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 26491.825 ± 438.463 ns/opReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 153941.952 ± 4337.073 ns/opReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 339868.602 ± 4201.462 ns/opReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 2588878.448 ± 22172.482 ns/opFrom 100 to 5000 partitions the latency increase is 2588878.448 / 26491.825 = 97.Avoid gettimeofdaycalls in steady state fetch states8545888Benchmark (partitionCount) Mode Cnt Score Error UnitsReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 22685.381 ± 267.727 ns/opReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 113622.521 ± 1854.254 ns/opReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 273698.740 ± 9269.554 ns/opReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 2189223.207 ± 1706.945 ns/opFrom 100 to 5000 partitions the latency increase is 2189223.207 / 22685.381 = 97XAvoid copying partition states to maintain fetch offsets29fdd60Benchmark (partitionCount) Mode Cnt Score Error UnitsReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 17039.989 ± 609.355 ns/opReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 99371.086 ± 1833.256 ns/opReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 216071.333 ± 3714.147 ns/opReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 2035678.223 ± 5195.232 ns/opFrom 100 to 5000 partitions the latency increase is 2035678.223 / 17039.989 = 119XKeep lag alongside PartitionFetchState to avoid expensive isReplicaInSync check0e57e3eBenchmark (partitionCount) Mode Cnt Score Error UnitsReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 15131.684 ± 382.088 ns/opReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 86813.843 ± 3346.385 ns/opReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 193050.381 ± 3281.833 ns/opReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 1801488.513 ± 2756.355 ns/opFrom 100 to 5000 partitions the latency increase is 1801488.513 / 15131.684 = 119XFetch session optimizations (mostly presizing the next hashmap, and avoiding making a copy of sessionPartitions, as a deep copy is not required for the ReplicaFetcher)2614b24Benchmark (partitionCount) Mode Cnt Score Error UnitsReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 11386.203 ± 416.701 ns/opReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 60820.292 ± 3163.001 ns/opReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 146242.158 ± 1937.254 ns/opReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 1366768.926 ± 3305.712 ns/opFrom 100 to 5000 partitions the latency increase is 1366768.926 / 11386.203 = 120Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: reduce StreamThread INFO logging during low traffic (#9875)Avoid spamming the logs at the INFO level in a tight loop when there are no new records being polledReviewers: Walker Carlson <wcarlson@confluent.io>, Leah Thomas <lthomas@confluent.io>",5
"KAFKA-6435: KIP-623 Add internal topics option to streamResetter (#8923)Allow user to specify subset of internal topics to clean up with application reset toolReviewers: Boyang Chen <boyang@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Walker Carlson <wcarlson@confluent.io>",5
KAFKA-1490 remove gradlew initial setup output from source distribution patch by Ivan Lyutov reviewed by Joe Stein,1
"MINOR: Resuming Tasks should not be initialized twice (#4562)Avoids double initialization of resuming tasksRemoves race condition in StreamThreadTest plus code cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: update README with how to run code coverage on module. add reportCoverage at subProject levelAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2527 from dguy/code-coverage,3
"KAFKA-2681: Added SASL documentation… info from the wikiAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Sriharsha Chintalapani, Jun RaoCloses #401 from gwenshap/KAFKA-2681",5
MINOR: Cleanup for #11513 (#11585)Clean up some minor things that were left over from PR #11513Reviewer: John Roesler <vvcephei@apache.org>,4
"KAFKA-3396; Ensure Describe access is required to detect topic existenceReopening of https://github.com/apache/kafka/pull/1428Author: Edoardo Comar <ecomar@uk.ibm.com>Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1908 from edoardocomar/KAFKA-3396",2
KAFKA-13168: KRaft observers should not have a replica id (#11178),5
KafkaRequestHandler needs to handle exceptions; patched by Yang Ye; reviewed by Jun Rao; KAFKA-491git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1404857 13f79535-47bb-0310-9956-ffa450edef68,0
KAFKA-7768: Add version to java html urls (#6094)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
MINOR: Un-hide the tutorial buttons on web docsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3850 from guozhangwang/KMinor-unhide-button,2
MINOR: Add KIP-431 to upgrade.html file (#9514)Reviewers: Matthias J. Sax <mjsax@apache.org>,2
"KAFA-4378: Fix Scala 2.12 ""eta-expansion of zero-argument method"" warningsAuthor: Bernard Leach <leachbj@bouncycastle.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2098 from leachbj/4378-eta-expansion",2
"KAFKA-3418: add javadoc section describing consumer failure detectionAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1129 from hachikuji/KAFKA-3418",5
"KAFKA-7551: Refactor to create producer & consumer in the workerThis is minor refactoring that brings in the creation of producer and consumer to the Worker. Currently, the consumer is created in the WorkerSinkTask. This should not affect any functionality and it just makes the code structure easier to understand.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Randall Hauch <rhauch@gmail.com>, Robert Yokota <rayokota@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5842 from mageshn/KAFKA-7551",5
"MINOR: Fix version for ConnectDistributed system test, remove 0.9.0.1 compatibility test (#7023)Connect tests were using String version for KafkaService instead of the expected KafkaVersion object. This broke due to recent changes to KafkaVersion. It turns out that the tests with String version were running compatibility tests against `dev` brokers rather than the older broker versions they were expecting to run against. When version was fixed, tests using 0.9.0.1 brokers started failing since new clients are not compatible with 0.9.0.1 brokers. So this PR fixes version parameter and removes the two tests against 0.9.0.1 brokers.Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-10850: Use primitive type to replace deprecated 'new Integer' from BrokerToControllerRequestThreadTest (#9760)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
MINOR: Add a log to print acl change notification detailsThis is similar to config change logs for topic/broker. This will be useful for debugging any acl related issues.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #9841 from omkreddy/acl-change-log,4
"MINOR: deprecate TaskMetadata constructor and add KIP-740 notes to upgrade guide (#10755)Quick followup to KIP-740 to actually deprecate this constructor, and update the upgrade guide with what we changed in KIP-740. I also noticed the TaskId#parse method had been modified previously, and should be re-added to the public TaskId class. It had no tests, so now it doesReviewers: Matthias J. Sax <mjsax@confluent.io>, Luke Chen <showuon@gmail.com>",5
"MINOR: Redirect response code in Connect's RestClient to logs instead of stdoutSending the response code of an http request issued via `RestClient` in Connect to stdout seems like a unconventional choice.This PR redirects the responds code with a message in the logs at DEBUG level (usually the same level as the one that the caller of `RestClient.httpRequest` uses.This fix will also fix system tests that broke by outputting this response code to stdout.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #4591 from kkonstantine/MINOR-Redirect-response-code-in-Connect-RestClient-to-logs-instead-of-stdout",2
"MINOR: Fix AsyncProducerTest bug that hits when logging is turned up (#4450)AsyncProducerTest gets an error about an incorrect mock when the logginglevel is turned up.  Instead of usIng a mock, just create a realSyncProducerConfig object, since the object is simple to create.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: Replace Collection.toArray(new T[size]) by Collection.toArray(new T[0]) (#9750)This PR is based on the research of https://shipilev.net/blog/2016/arrays-wisdom-ancientsReviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
KAFKA-10854: fix flaky testConnectionRatePerIp test (#9752)Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: Remove inexistent parameter in doc of `LogManager#getOrCreateLog` (#10359)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-5308; TC should handle UNSUPPORTED_FOR_MESSAGE_FORMAT in WriteTxnMarker responseReturn UNSUPPORTED_MESSAGE_FORMAT in handleWriteTxnMarkers when a topic is not the correct message format.Remove any TopicPartitions that have same error from those waiting for markersAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3152 from dguy/kafka-5308",5
"MINOR: Exclude jline, netty and findbugs annotationsThese dependencies are unnecessary and they are acquiredtransitively via zkclient (jline, netty) and reflections (annotations).Ewen did the hard work in figuring out why we have unexpectedadditional dependencies since 0.9.x.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava, Guozhang Wang, Gwen ShapiraCloses #1396 from ijuma/exclude-jline-netty-deps-in-streams and squashes the following commits:3aa366f [Ismael Juma] Exclude findbugs annotations due to LGPL license2d3d714 [Ismael Juma] Use local exclusion for `jline` and `netty`482b6c0 [Ismael Juma] Exclude `jline` and `netty` dependencies in the `streams` project",1
KAFKA-8436: use automated protocol for AddOffsetsToTxn  (#7015)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"MINOR: Add reset to SnapshotRegistry and Revertable (#10891)Add reset functionality to SnapshotRegitry and Revertable, so that we canclear the current state before loading a snapshot.Reviewers: Colin P. McCabe <cmccabe@apache.org>",4
MINOR: Update jdk and maven names in Jenkinsfile (#9453),2
"KAFKA-3002; Allow uppercase letters in hostnamesMake available to specify hostname with Uppercase at broker listAuthor: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #685 from sasakitoa/hostname_uppercase",5
"MINOR: fix throttling and status in ConnectionStressWorkerEach separate thread should have its own throttle, so that it can sleepfor an appropriate amount of time when needed.ConnectionStressWorker should avoid recalculating the status aftershutting down the runnables.  Otherwise, if one runnable is slow tostop, it will skew the average down in a way that doesn't reflectreality.  This change moves the status calculation into a separateperiodic runnable that gets shut down cleanly before the other ones.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen Shapira, Stanislav KozlovskiCloses #6533 from cmccabe/fix_connection_stress_worker",0
Handle topic names with / on Kafka server; patched by Swapnil Ghike; reviewed by Jay Kreps and Jun Rao; kafka-495git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1381853 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: replace NotLeaderForPartitionException with NotLeaderOrFollowerException (#9885)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-8764: LogCleanerManager endless loop while compacting/cleaning (#7932)This fix makes the LogCleaner tolerant of gaps in the offset sequence. Previously, this could lead to endless loops of cleaning which required manual intervention. Reviewers: Jun Rao <junrao@gmail.com>, David Arthur <mumrah@gmail.com>",1
kafka-2090; Remove duplicate check to metadataFetchInProgress; patched by Tim Brook; reviewed by Ewen Cheslack-PostavaJun Rao,5
"MINOR: Set mock correctly in RocksDBMetricsRecorderTest (#11462)With a nice mock in RocksDBMetricsRecorderTest#shouldCorrectlyHandleHitRatioRecordingsWithZeroHitsAndMisses() and RocksDBMetricsRecorderTest#shouldCorrectlyHandleAvgRecordingsWithZeroSumAndCount() were green although getTickerCount() was never called. The tests were green because EasyMock returns 0 for a numerical return value by default if no expectation is specified. Thus, commenting out the expectation for getTickerCount() did not change the result of the test.This commit changes the mock to a default mock and fixes the expectation to expect getAndResetTickerCount(). Now, commenting out the expectation leads to a test failure.Reviewers: Luizfrf3 <lf.fonseca@hotmail.com>, Guozhang Wang <wangguoz@gmail.com>",0
kafka-1733; Producer.send will block indeterminately when broker is unavailable; patched by Marc Chung; reviewed by Jun Rao,5
KAFKA-12611: Fix using random payload in ProducerPerformance incorrectly (#10469)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-2680; Use IBM ConfigFile class to load jaas config if IBM JDKUse IBM ConfigFile class with IBM JDK since JavaLoginConfig provided by SUN provider is not included with IBM JDK.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Flavio Junqueira <fpj@apache.org>, Jun Rao <junrao@gmail.com>Closes #357 from rajinisivaram/KAFKA-2680",5
KAFKA-227 Broker failure system test; patched by johnfung; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1227916 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7612: Fix javac warnings and enable warnings as errors (#5900)- Use Xlint:all with 3 exclusions (filed KAFKA-7613 to remove the exclusions)- Use the same javac options when compiling tests (seems accidental thatwe didn't do this before)- Replaced several deprecated method calls with non-deprecated ones:  - `KafkaConsumer.poll(long)` and `KafkaConsumer.close(long)`  - `Class.newInstance` and `new Integer/Long` (deprecated since Java 9)  - `scala.Console` (deprecated in Scala 2.11)  - `PartitionData` taking a timestamp (one of them seemingly a bug)  - `JsonMappingException` single parameter constructor- Fix unnecessary usage of raw types in several places.- Add @SuppressWarnings for deprecations, unchecked and switch fallthrough inseveral places.- Scala clean-ups (var -> val, ETA expansion warnings, avoid reflective calls)- Use lambdas to simplify code in a few places- Add @SafeVarargs, fix varargs usage and remove unnecessary `Utils.mkList` methodReviewers: Matthias J. Sax <mjsax@apache.org>, Manikumar Reddy <manikumar.reddy@gmail.com>, Randall Hauch <rhauch@gmail.com>, Bill Bejeck <bill@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
"KAFKA-10500: Add KafkaStreams#removeStreamThread (#9695)Add the ability to remove running threadsReviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"KAFKA-2732; Add class for ZK Auth.Author: Flavio Junqueira <fpj@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>Closes #410 from fpj/KAFKA-2732",1
"Minor: add valueChangingOperation and mergeNode to StreamsGraphNode#toString (#5522)This PR adds valueChangingOperation and mergeNode to StreamsGraphNode#toStringReviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-13669; Demote empty offset commit messages for source tasks to DEBUG level (#11770)Lower the log level of a message in `WorkerSourceTask` which indicates that no messages have been produced by the task since it is spammy and causing users confusion.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-10292: Set min.insync.replicas to 1 of __consumer_offsets (#9286)The test StreamsBrokerBounceTest.test_all_brokers_bounce() fails on2.5 because in the last stage of the test there is only one brokerleft and the offset commit cannot succeed because themin.insync.replicas of __consumer_offsets is set to 2 and acks isset to all. This causes a time out and extends the closing of theKafka Streams client to beyond the duration passed to the closemethod of the client.This affects especially the 2.5 branch since there Kafka Streamscommits offsets for each task, i.e., close() needs to wait for thetimeout for each task. In 2.6 and trunk the offset commit is doneper thread, so close() does only need to wait for one time out perstream thread.I opened this PR on trunk, since the test could also becomeflaky on trunk and we want to avoid diverging system tests acrossbranches.A more complete solution would be to improve the test by defininga better success criteria.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-1456 Add LZ4 and LZ4C as a compression codec patch by James Oliver reviewed by Joe Stein,1
embedded controller; patched by Yang Ye; reviewed by Jun Rao; KAFKA-335git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350291 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-1288 add enclosing dir in release tar gz patch by Jun Rao, reviewed by Neha Narkhede",1
MINOR: Various small fixes in the configuration docs (#11402)Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-9431: Expose API in KafkaStreams to fetch all local offset lags (#7961)Add a new method to KafkaStreams to return an estimate of the lags forall partitions of all local stores.Implements: KIP-535Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>Reviewed-by: John Roesler <vvcephei@apache.org>,1
"MINOR: Typo error corrected in the KStream Javadoc.Author: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3520 from Kamal15/stream_doc",2
"KAFKA-6467; Enforce layout of dependencies within a connect plugin to be deterministic (#4459)Adds alphanumeric ordering of dependencies as they added to a Connect plugin's class loader path. This makes the layout of the dependencies consistent across systems and deployments. Dependencies should still, in principle, not include conflicts and ideally order should not matter. Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: bump release version to 3.0.0-SNAPSHOT (#10186)Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-10426: Deadlock in DistributedHerder during session key update. (#9431)DistributedHerder goes to updateConfigsWithIncrementalCooperative() synchronized method and called configBackingStore.snapshot() which take a lock on internal object in KafkaConfigBackingStore class.Meanwhile KafkaConfigBackingStore in ConsumeCallback inside synchronized block on internal object gets SESSION_KEY record and calls updateListener.onSessionKeyUpdate() which take a lock on DistributedHerder.This results to a deadlock.To avoid this, updateListener with new session key should be called outside synchronized block as it's done, for example, for updateListener.onTaskConfigUpdate(updatedTasks).Co-authored-by: Taisiia Goltseva <tado0618@netcracker.com>Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",5
"KAFKA-6743; ConsumerPerformance fails to consume all messages [KIP-281]  (#4818)This patch implements KIP-281, which adds a configurable timeout to the consumer performance tool with a default value of 10 seconds. The old timeout was hard-coded as 1 second. Additionally, this patch adds a warning message when the tool exits after a timeout rather than returning silently.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7223: internally provide full consumer record during restore (#5710)The Suppression buffer stores the full record context, not just the key and value,so its changelog/restore loop will also need to preserve this information.This change is a precondition to that, creating an option to register astate restore callback to receive the full consumer record.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13835: Fix two bugs related to dynamic broker configs in KRaft (#12063)Fix two bugs related to dynamic broker configs in KRaft. The first bug is that we are calling reloadUpdatedFilesWithoutConfigChange when a topic configuration is changed, but not when abroker configuration is changed. This is backwards. This function must be called only for broker configs, and never for topic configs or cluster configs.The second bug is that there were several configurations such as max.connections which are relatedto broker listeners, but which do not involve changing the registered listeners. We should supportthese configurations in KRaft. This PR fixes the configuration change validation to support this case.Reviewers: Jason Gustafson <jason@confluent.io>, Matthew de Detrich <mdedetrich@gmail.com>",5
"KAFKA-13173; Ensure KRaft controller handles concurrent broker expirations correctly (#11191)Prior to this patch, the controller did not accumulate ISR/leader changes correctly when multiple broker's sessions expired at the same time. This patch fixes the problem by having the controller handle one expiration at a time.Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-8410: Migrate KStream Stateless operators to new Processor API (#10381)Migrate KStream stateless operators to new Processor API.Following PRs will complete migration of KStream stateful operators and KTable.No expected functionality changes.Reviewers: John Roesler <vvcephei@apache.org>,4
KAFKA-5890; records.lag should use tags for topic and partition rather than using metric name.This is the implementation of KIP-225.It marks the previous metrics as deprecated in the documentation and adds new metrics using tags.Testing verifies that both the new and the old metric report the same value.Author: cmolter <cmolter@apple.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #4362 from lahabana/kafka-5890,1
"MINOR: Fix LogContext message format in KafkaProducerAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3854 from vahidhashemian/minor/fix_log_context_message_format",2
KAFKA-5944: Unit tests for handling SASL authentication failures in clients (#3965),0
KAFKA-12800: Configure generator to fail on trailing JSON tokens (#10717)Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-12173 Migrate streams:streams-scala module to JUnit 5 (#9858)1. replace org.junit.Assert by org.junit.jupiter.api.Assertions2. replace org.junit by org.junit.jupiter.api3. replace Before by BeforeEach4. replace After by AfterEach5. remove ExternalResource from all scala modules6. add explicit AfterClass/BeforeClass to stop/start EmbeddedKafkaClusterNoted that this PR does not migrate stream module to junit 5 so it does not introduce callback of junit 5 to deal with beforeAll/afterAll. The next PR of migrating stream module can replace explicit beforeAll/afterAll by junit 5 extension. Or we can keep the beforeAll/afterAll if it make code more readable.Reviewers: John Roesler <vvcephei@apache.org>,1
KAFKA-9065; Fix endless loop when loading group/transaction metadata (#7554)The current coordinator loading logic causes an infinite loop when there is a gap between the last record in the log and the log end offset. This is possible because of compaction if the active segment is empty. The patch fixes the problem by breaking from the loading loop when a read from the log returns no additional data.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-2593: Key value stores can use specified serializers and deserializersAdd support for the key value stores to use specified serializers and deserializers (aka, ""serdes""). Prior to this change, the stores were limited to only the default serdes specified in the topology's configuration and exposed to the processors via the ProcessorContext.Now, using InMemoryKeyValueStore and RocksDBKeyValueStore are similar: both are parameterized on the key and value types, and both have similar multiple static factory methods. The static factory methods either take explicit key and value serdes, take key and value class types so the serdes can be inferred (only for the built-in serdes for string, integer, long, and byte array types), or use the default serdes on the ProcessorContext.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Guozhang WangCloses #255 from rhauch/kafka-2593",1
"KAFKA-12407: Document Controller Health Metrics (#10257)Reviewers: Luke Chen <showuon@gmail.com>, Dong Lin <lindong28@gmail.com>",2
"MINOR: improve JavaDocs for KafkaStreams, KafkaProducer, KafkaConsumerAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4335 from mjsax/minor-improve-KafkaStreams-javadocs",2
"MINOR: Close ZooKeeperClient if waitUntilConnected fails during construction (#5411)This has always been an issue, but the recent upgrade to ZooKeeper3.4.13 means it is also an issue when an unresolvable ZKaddress is used, causing some tests to leak threads.The change in behaviour in ZK 3.4.13 is that no exception is thrownfrom the ZooKeeper constructor in case of an unresolvable address.Instead, ZooKeeper tries to re-resolve the address hoping it becomesresolvable again. We eventually throw a`ZooKeeperClientTimeoutException`, which is similar to the casewhere the the address is resolvable but ZooKeeper is notreachable.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
kafka-1721; Snappy compressor is not thread safe; patched by Ewen Cheslack-Postava; reviewed by Jun Rao,5
"MINOR: Upgrade to Gradle 4.2It includes the usual performance improvements, butthe nicest improvement for me is that the findBugsplugin no longer outputs 10000+ lines inJenkins builds:https://docs.gradle.org/4.2/release-notes.html#findbugs-plugin-does-not-render-analysis-progress-anymoreAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3923 from ijuma/gradle-4.2",5
MINOR: Fixed misleading reference to HTTPS instead of SSL support in the docAuthor: ppatierno <ppatierno@live.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3487 from ppatierno/ssl-doc-https,2
"MINOR: fix HTML markup (#8823)Reviewers: Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-4311: Multi layer cache eviction causes forwarding to incorrect ProcessorNodeGiven a topology like the one below. If a record arriving in `tableOne` causes a cache eviction, it will trigger the `leftJoin` that will do a `get` from `reducer-store`. If the key is not currently cached in `reducer-store`, but is in the backing store, it will be put into the cache, and it may also trigger an eviction. If it does trigger an eviction and the eldest entry is dirty it will flush the dirty keys. It is at this point that a ClassCastException is thrown. This occurs because the ProcessorContext is still set to the context of the `leftJoin` and the next child in the topology is `mapValues`.We need to set the correct `ProcessorNode`, on the context, in the `ForwardingCacheFlushListener` prior to calling `context.forward`. We also need to  remember to reset the `ProcessorNode` to the previous node once `context.forward` has completed.```       final KTable<String, String> one = builder.table(Serdes.String(), Serdes.String(), tableOne, tableOne);        final KTable<Long, String> two = builder.table(Serdes.Long(), Serdes.String(), tableTwo, tableTwo);        final KTable<String, Long> reduce = two.groupBy(new KeyValueMapper<Long, String, KeyValue<String, Long>>() {            Override            public KeyValue<String, Long> apply(final Long key, final String value) {                return new KeyValue<>(value, key);            }        }, Serdes.String(), Serdes.Long())                .reduce(new Reducer<Long>() {..}, new Reducer<Long>() {..}, ""reducer-store"");    one.leftJoin(reduce, new ValueJoiner<String, Long, String>() {..})        .mapValues(new ValueMapper<String, String>() {..});```Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2051 from dguy/kafka-4311",1
KAFKA-5811; Add Kibosh integration for Trogdor and DucktapeFor ducktape: add Kibosh to the testing Dockerfile.Create files_unreadable_fault_spec.py.For trogdor: create FilesUnreadableFaultSpec.java.Add a unit test of using the Kibosh service.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4195 from cmccabe/KAFKA-5811,5
"MINOR: improve stabilty of ProcessorStateManagerTest (#6240)This PR addressed the following test failure:```java.lang.AssertionError:Expected: a string starting with ""process-state-manager-test Failed to write offset checkpoint file to [""but: was ""[AdminClient clientId=adminclient-874] Connection to node -1 (localhost/127.0.0.1:8080) could not be established. Broker may not be available.""```Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-7315 DOCS update TOC internal links serdes all versions (#6875)Reviewers: Joel Hamill <joel@confluent.io>, Jim Galasyn <jim.galasyn@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-13143; Remove Metadata handling from ControllerApis (#11135)This PR removes the `METADATA` API from the Kraft controller as the controller does not yet implement the metadata fetch functionality completely.Without the change (as per the JIRA https://issues.apache.org/jira/browse/KAFKA-13143), the API would return an empty list of topics making the caller incorrectly think that there were no topics in the cluster which could be confusing. After this change the describe and list topic APIs timeout on the controller endpoint when using the `kafka-topics` CLI (which is the same behavior as create_topic).Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6145: KIP-441: Add TaskAssignor class config (#8541)* add a config to set the TaskAssignor* set the default assignor to HighAvailabilityTaskAssignor* fix broken tests (with some TODOs in the system tests)Implements: KIP-441Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
MINOR: Update docs for KIP-415 (#6958)Update docs with KIP-415 details for incremental cooperative rebalancingAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-9046: Use top-level worker configs for connector admin clients[Jira](https://issues.apache.org/jira/browse/KAFKA-9046)The changes here are meant to find a healthy compromise between the pre- and post-KIP-458 functionality of Connect workers when configuring admin clients for use with DLQs. Before KIP-458, admin clients were configured using the top-level worker configs; after KIP-458, they are configured using worker configs with a prefix of `admin.` and then optionally overridden by connector configs with a prefix of `admin.override.`. The behavior proposed here is to use, in ascending order of precedence, the top-level worker configs, worker configs prefixed with `admin.`, and connector configs prefixed with `admin.override.`; essentially, use the pre-KIP-458 behavior by default but allow it to be overridden by the post-KIP-458 behavior.Author: Chris Egerton <chrise@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Nigel Liang <nigel@nigelliang.com>Closes #7525 from C0urante/kafka-9046",5
"KAFKA-10746: Change to Warn logs when necessary to notify users (#9627)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-4689; Disable system tests for consumer hard failuresSee the JIRA for the full details. Essentially the test assertions depend on receiving reliable events from the consumer processes, but this is not generally possible in the presence of a hard failure (i.e. `kill -9`). Until we solve this problem, the hard failure scenarios will be turned off.Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2771 from hachikuji/KAFKA-4689",5
KAFKA-6447: Add Delegation Token Operations to KafkaAdminClient (KIP-249) (#4427)Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-4597; RecordMetadata should return log append time when appropriateThere is a slight change of behaviour: we now complete the `Future` returned from `send`before the callbacks are invoked. This seems OK and perhaps a little better as the `Future`can make progress sooner (as it would typically be blocked on a different thread than theI/O thread that invokes the callbacks).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2318 from ijuma/kafka-4597-record-metadata-log-append-time",5
"KAFKA-13129: replace describe topic via zk with describe users (#11115)Replace the unsupported describe topic via zk with describe users to fix the system tests.For the upgrade_test case where TLS support is not required, use list_acls instead.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"Add '?expand' query param for additional info on '/connectors'. (#6658)Per KIP-465, kept existing behavior of `/connectors` resource in the Connect's REST API, but added the ability to specify `?expand` query parameter to get list of connectors with status details on each connector. Added unit tests, and verified passing existing system tests (which use the older list form).See https://cwiki.apache.org/confluence/display/KAFKA/KIP-465%3A+Add+Consolidated+Connector+Endpoint+to+Connect+REST+API.Author: Dan Norwood <norwood@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
MINOR: Make VerifiableProducer in system tests lookup security configuration dynamically instead of at construction.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Anna PovznerCloses #1207 from ewencp/minor-dynamic-security-config-verifiable-producer,5
"MINOR: adding system tests for how streams functions with broker faiures (#4513)System test for two cases:* Starting a multi-node streams application with the broker down initially, broker starts and confirm rebalance completes and streams application still able to process records.* Multi-node streams app running, broker goes down, stop stream instance(s) confirm after broker comes back remaining streams instance(s) still function.Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5412: Using connect-console-sink/source.properties raises an exception related to ""file"" property not foundAuthor: ppatierno <ppatierno@live.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3279 from ppatierno/kafka-5412",5
"KAFKA-5205: Use default values of keySerde if it is not specified by users in CachingSessionStoreCachingSessionStore wasn't properly using the default keySerde if no Serde was supplied. I saw the below error in the logs for one of my test cases.Author: Kyle Winkelman <kyle.winkelman@optum.com>Reviewers: Damian Guy, Guozhang WangCloses #2963 from KyleWinkelman/CachingSessionStore-fix-keySerde-use",0
KAFKA-12260: Avoid hitting NPE for partitionsFor (#10017)Remove null pointer from the public partitionsFor API.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
KAFKA-8245: Fix Flaky Test DeleteConsumerGroupsTest#testDeleteCmdAllGroups (#8032)Change unit tests to make sure the consumer group is in Stable state (i.e. consumers have completed joining the group),5
"MINOR: Typo correction in server.properties (#7011)Corrected language error which was confusing.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4843: More efficient round-robin scheduler- Improves streams efficiency by more than 200K requests/second (small 100 byte requests)- Gets streams efficiency very close to pure consumer (see results in https://jenkins.confluent.io/job/system-test-kafka-branch-builder/746/console)- Maintains same fairness across tasks- Schedules all records in the queue in-between poll() calls, not just one per task.Author: Eno Thereska <eno@confluent.io>Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2643 from enothereska/minor-schedule-round-robin",5
"MINOR: Remove Utils.notNull, use Objects.requireNonNull instead (#7194)",1
MINOR: Share BrokerMetadataPublisher code for coordinators (#11525)Leader election and resignation logic for the Group Coordinator and Transaction Coordinator is thesame. Share this logic by refactoring this code into a method.Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
MINOR: Fix formatting in --new-consumer deprecation warning (#4903),2
"KAFKA-6685: Added Exception to distinguish message Key from Value during deserializing.https://issues.apache.org/jira/browse/KAFKA-6685Added Exception message in `WorkerSinkTask.convertMessages` to distinguish message Key from Value during deserialization to Kafka connect format.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Jagadesh Adireddi <adireddijagadesh@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4765 from jadireddi/KAFKA-6685---log-message-should-distinguish-key-from-value",2
MINOR: Kafka Streams updates for 2.7.0 release (#9773)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Skip sending fetches/offset lookups when awaiting the reconnect backoff (#4644)Logging can get spammy during the reconnect blackout period because any requests we send to ConsumerNetworkClient will immediately be failed when poll() returns. This patch checks for connection failures prior to sending fetches and offset lookups and skips sending to any failed nodes. Test cases added for both.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-7332; Update CORRUPT_MESSAGE exception message descriptionAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5638 from omkreddy/KAFKA-7332-COMPACTED-ERROR_MESSAGE,0
"MINOR: Fix syntax used for comment in JAAS config fileSimple fix, but important because the incorrect syntax causes the server not to start.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Guozhang WangCloses #819 from ijuma/fix-jaas-comment-syntax",0
KAFKA-5503; Idempotent producer ignores shutdown while fetching ProducerId (#5881)Check `running` in `Sender.maybeWaitForProducerId` to ensure that the producer can be closed while awaiting initialization of the producerId.Reviewers: Jason Gustafson <jason@confluent.io>,5
HOTFIX: fix NPE in changeloggerFix NPE in StoreChangeLogger caused by a record out of window retention period.guozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1124 from ymatsuda/logger_npe,2
"KAFKA-12930,KAFKA-12929: Deprecate Java 8 and Scala 2.12 (#11059)Update the readme to note the deprecation. We will also mention the deprecationin the downloads page when the release is done.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, David Jacot <djacot@confluent.io>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
MINOR: Change return type of `Schema.read` to be `Struct` instead of `Object`We always return a `Struct` from `Schema.read` and this means thatwe can remove a large number of casts.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #684 from ijuma/schema-read-should-return-struct,5
MINOR: Update Jackson to 2.9.5 (#4776),5
"KAFKA-6259: Make KafkaStreams.cleanup() clean global state directoryAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4255 from mjsax/kafka-6259-clean-global-state-diradd log4j entry",1
"KAFKA-5947; Handle authentication failure in admin client, txn producer1. Raise AuthenticationException for authentication failures in admin client2. Handle AuthenticationException as a fatal error for transactional producer3. Add comments to authentication exceptionsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>Closes #3928 from rajinisivaram/KAFKA-5947-auth-failure",5
HOTFIX: Fix checkstyle failure in KStreams by providing fully qualified class names.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1000 from ewencp/hotfix-kstreams-checkstyle-javadocs,2
MINOR: Advance system test ducktape dependency from 0.3.10 to 0.4.0Previous version of ducktape was found to have a memory leak which caused occasional failures in nightly runs.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1165 from granders/minor-advance-ducktape-to-0.4.0,5
"KAFKA-9083: Various fixes/improvements for Connect's Values class (#7593)Author: Chris Egerton <chrise@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
upgrade ZKClient to allow conditional updates in ZK; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-337git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1342487 13f79535-47bb-0310-9956-ffa450edef68,5
"replace lastOption with exists (#11605)Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-3140: Fix PatternSyntaxException and hand caused by it in Mirro…Fix PatternSyntaxException and hand caused by it in MirrorMaker on passing invalid java regex string as whitelistAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Grant Henke, Gwen ShapiraCloses #805 from SinghAsDev/KAFKA-3140",4
MINOR: make sure all generated data tests cover all versions (#10078)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-12434; Admin support for `DescribeProducers` API (#10275)This patch adds the new `Admin` API to describe producer state as described by KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.The three new APIs added by KIP-664 require different lookup and request patterns:- DescribeProducers: send to partition leaders- DescribeTransactions: send to coordinators- ListTransactions: send to all brokersOur method of handling complex workflows such as these in `KafkaAdminClient` by chaining together `Call` instances has been clumsy and error-prone at best. I have attempted to introduce a new pattern which separates the lookup stage (e.g. finding partition leaders) from the fulfillment stage (e.g. sending `DescribeProducers`). The lookup stage is implemented by `AdminApiLookupStrategy` and the fulfillment stage is implemented by `AdminApiHandler`. There is a new class `AdminApiDriver` which manages the bookkeeping for these two stages. See the corresponding javadocs for more detail. This PR provides an example of usage through `DescribeProducersHandler`, which is an implementation of `AdminApiHandler`. It relies on `PartitionLeaderStrategy` which implements `AdminApiLookupStrategy`. In addition to allowing for easier reuse of lookup strategies, this approach provides a more convenient way for testing since all of the logic is not crammed into `KafkaAdminClient`. Follow-up PRs for the rest of KIP-664 will flesh out additional lookup strategies such as for coordinator APIs.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Require final variables in Streams (#5452)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-9866: Avoid election for topics where preferred leader is not in ISR (#8524)In this commit we made sure that the auto leader election only happens after the newly starter broker is in the isr.No accompany tests are added due to the fact that:this is a change to the private method and no public facing change is madeit is hard to create tests for this change without considerable effortReviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",4
"KAFKA-384 Fix intermittent unit test failures and remove Thread.sleep statements; patched by Neha Narkhede; reviewed by Joel Koshy, Jun Rao and Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1367821 13f79535-47bb-0310-9956-ffa450edef68",4
"KAFKA-3235: Unclosed stream in AppInfoParser static blockAlways close the streamAuthor: Kim Christensen <kich@mvno.dk>Reviewers: Ismael Juma, Grant HenkeCloses #914 from kichristensen/KAFKA-3235",5
"KAFKA-690 TopicMetadataRequest throws exception when no topics are specified, reviewed by Jay Kreps and Neha Narkhede",5
MINOR: Remove types from caching stores (#6331)* MINOR: remove types from caching stores* Github comments and rebased,4
"KAFKA-5450: Increased timeout of Connect system test utilitiesIncreased the timeout from 30sec to 60sec. When running the system tests with packaged Kafka, Connect workers can take about 30seconds to start.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3344 from rhauch/KAFKA-5450",5
"Forward topic from console consumer to deserializer (#5704)Some deserializer needs the topic name to be able to correctly deserialize the payload of the message.Console consumer works great with Deserializer<String> however it calls deserializer with topic set as null.This breaks the API and the topic information is available in the ConsumerRecord.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Gardner Vickers <gardner@vickers.me>, Jun Rao <junrao@gmail.com>",5
"KAFKA-13306: Null connector config value passes validation, but fails creation (#11333)This patch adds null value check to the connector config validation, and extends unit tests to cover this functionality.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <chrise@confluent.io>, Boyang Chen <bchen11@outlook.com>, Andras Katona <akatona@cloudera.com>",5
KAFKA-5333; Remove Broker ACL resource typeAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3154 from ijuma/kafka-5333-remove-broker-acl-resource-type,4
"KAFKA-9777; Remove txn purgatory to fix race condition on txn completion (#8389)This patch addresses a locking issue with DelayTxnMarker completion. Because of the reliance on the shared read lock in TransactionStateManager and the deadlock avoidance algorithm in `DelayedOperation`, we cannot guarantee that a call to checkAndComplete will offer an opportunity to complete the job. This patch removes the reliance on this lock in two ways:1. We replace the transaction marker purgatory with a map of transaction with pending markers. We were not using purgatory expiration anyway, so this avoids the locking issue and simplifies usage.2. We were also relying on the read lock for the `DelayedProduce` completion when calling `ReplicaManager.appendRecords`. As far as I can tell, this was not necessary. The lock order is always 1) state read/write lock, 2) txn metadata locks. Since we only call `appendRecords` while holding the read lock, a deadlock does not seem possible. Reviewers: Jun Rao <junrao@gmail.com>",5
"KAFKA-4786; Wait for heartbeat thread to terminate in consumer closeAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2586 from rajinisivaram/KAFKA-4786",5
"KAFKA-9575: Mention ZooKeeper 3.5.7 upgrade*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Ron Dagostino <rdagostino@confluent.io>Reviewers: Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8139 from rondagostino/KAFKA-9575",2
KAFKA-12697: Add OfflinePartitionCount and PreferredReplicaImbalanceCount metrics to Quorum Controller (#10572)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"kafka-1432; followup patch to enable new producer in system test;  patched by Guozhang Wang; reviewed by Neha Narkhede, Jun Rao",3
"MINOR: convert some tests to KRaft (#12155)Convert EndToEndClusterIdTest, ConsumerGroupCommandTest,ListConsumerGroupTest, and LogOffsetTest to test KRaft mode.Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>",5
"MINOR: inline metrics in RecordAccumulator (#12227)Reviewers: Kvicii <Karonazaba@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Add notes for 2.6 on reassignment tool changes (#9109)Add some notable changes to the reassignment tool for the 2.6 release.Reviewers: Randall Hauch <rhauch@gmail.com>,4
"MINOR: Improvements and fixes for Trogdor payload generators. (#10621)* Changes the new Throughput Generators to track messages per windowinstead of making per-second calculations which can have rounding errors.Also, one of these had a calculation error which prompted this change inthe first place.* Fixes a couple typos.* Fixes an error where certain JSON fields were not exposed, causing theworkloads to not behave as intended.* Fixes a bug where we use wait not in a loop, which exits too quickly.* Adds additional constant payload generators.* Fixes problems with an example spec.* Fixes several off-by-one comparisons.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
KAFKA-14200: kafka-features.sh must exit with non-zero error code on error (#12586)kafka-features.sh must exit with a non-zero error code on error. We must do this in order to catchregressions like KAFKA-13990.Reviewers: David Arthur <mumrah@gmail.com>,0
kafka-1168; OfflinePartitionCount in JMX can be incorrect during controlled shutdown; patched by Jun Rao; reviewed by Swapnil Ghike,5
KAFKA-6071; Use ZookeeperClient in LogManagerAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #4089 from omkreddy/KAFKA-6071-ZK-LOGMANAGER,2
HOTFIX: changed quickstart donwload from 0.10.0.0 to 0.10.0.1Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1869 from mjsax/hotfix-doc,2
"KAFKA-8437; Await node api versions before checking if offset validation is possible (#6823)The consumer should await api version information before determining whether the broker supports offset validation. In KAFKA-8422, we skip the validation if we don't have api version information, which means we always skip validation the first time we connect to a node. This bug was detected by the failing system test `tests/client/truncation_test.py`. The test passes again with this fix.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
KAFKA-4077: Backdate system test certificates to cope with clock skewAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1810 from rajinisivaram/KAFKA-4077,5
"MINOR: Introduce `ApiKeyVersionsSource` annotation for `ParameterizedTest` (#11468)It is common in our code base to have unit tests which must be run for all the versions of a given request. Most of the time, we do so by iterating over all the versions in the test itself which is error prone.With JUnit5 and ParameterizedTest, we can now use a custom arguments source for this case, which is way more convenient. It looks likes this:```@ParameterizedTest@ApiKeyVersionsSource(apiKey = ApiKeys.ADD_PARTITIONS_TO_TXN)public void mytest(short version) {  // do smth based on version...}```This patch introduces the new annotation and updates `AddPartitionsToTxnRequestTest` test as a first example. I will migrate all the other cases in subsequent PRs.Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunk,1
"KAFKA-8213 - Fix typo in Streams Dev Guide (#6574)Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Joel Hamill <joel@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-543 Avoid sending duplicate topic names in TopicMetadataRequest. Reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396465 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR; Remove redundant version system test (#12612)This patch removes test_kafka_version.py, which contains two tests at the moment. The first test verifies we can start a 0.8.2 cluster. The second verifies we can start a cluster with one node on 0.8.2 and another on the latest. These test are covered in greater depth by upgrade_test.py and downgrade_test.py.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
MINOR: Add a note about Zstandard compression in the upgrade docsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5817 from hachikuji/add-zstandard-upgrade-notes,1
"KAFKA-6492; Fix log truncation to empty segmentThis patch ensures that truncation to an empty segment forces resizing of the index file in order to prevent premature rolling.I have added unit tests which verify that appends are permitted following truncation to an empty segment. Without the fix, this test case reproduces the failure in which the rolled segment matches the current active segment.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #4498 from hachikuji/KAFKA-6492",5
KAFKA-2815: Fix KafkaStreamingPartitionAssignorTest.testSubscriptionFails when order of elements is incorrectAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Yasuhiro MatsudaCloses #510 from granthenke/streams-test,3
"KAFKA-12330; FetchSessionCache may cause starvation for partitions when FetchResponse is full (#10318)The incremental FetchSessionCache sessions deprioritizes partitions where a response is returned. This may happen if log metadata such as log start offset, hwm, etc is returned, or if data for that partition is returned.When a fetch response fills to maxBytes, data may not be returned for partitions even if the fetch offset is lower than the fetch upper bound. However, the fetch response will still contain updates to metadata such as hwm if that metadata has changed. This can lead to degenerate behavior where a partition's hwm or log start offset is updated resulting in the next fetch being unnecessarily skipped for that partition. At first this appeared to be worse, as hwm updates occur frequently, but starvation should result in hwm movement becoming blocked, allowing a fetch to go through and then becoming unstuck. However, it'll still require one more fetch request than necessary to do so. Consumers may be affected more than replica fetchers, however they often remove partitions with fetched data from the next fetch request and this may be helping prevent starvation.Reviewers: Lucas Bradstreet <lucas@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Remove unthrown exceptions, fix typo, etc. (#10402)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
maintain HW correctly with only 1 replica in ISR; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-420git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377166 13f79535-47bb-0310-9956-ffa450edef68,2
deal with empty TopicData list in producer and fetch request; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-412git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1366244 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-9712: Catch and handle exception thrown by reflections scanner (#8289)This commit works around a bug in version v0.9.12 of the upstream `reflections` library by catching and handling the exception thrown.The reflections issue is tracked by:https://github.com/ronmamo/reflections/issues/273New unit tests were introduced to test the behavior.* KAFKA-9712: Catch and handle exception thrown by reflections scanner* Update connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/DelegatingClassLoader.javaCo-Authored-By: Konstantine Karantasis <konstantine@confluent.io>* Move result initialization back to right before it is used* Use `java.io.File` in tests* Fix checkstyleCo-authored-by: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-10044 Deprecate ConsumerConfig#addDeserializerToConfig and Prod… (#9013)deprecate ConsumerConfig#addDeserializerToConfig and ProducerConfig#addSerializerToConfig.Create internal use cases instead: appendDeserializerToConfig and appendSerializerToConfigReviewers: Boyang Chen <boyang@confluent.io>,5
"KAFKA-5549; Explain that 'client.id' is just used as a prefix within Streams- Added new String CLIENT_ID_DOC in StreamsConfig for explanationAuthor: Pranav Maniar <pranav9428@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3544 from PranavManiar/trunk",1
"KAFKA-4405; Avoid unnecessary network poll in consumer if no fetches sentAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2193 from enothereska/KAFKA-4405-prefetch",5
"KAFKA-7313; StopReplicaRequest should attempt to remove future replica for the partition only if future replica existsThis patch fixes two issues:1) Currently if a broker received StopReplicaRequest with delete=true for the same offline replica, the first StopRelicaRequest will show KafkaStorageException and the second StopRelicaRequest will show ReplicaNotAvailableException. This is because the first StopRelicaRequest will remove the mapping (tp -> ReplicaManager.OfflinePartition) from ReplicaManager.allPartitions before returning KafkaStorageException, thus the second StopRelicaRequest will not find this partition as offline.This result appears to be inconsistent. And since the replica is already offline and broker will not be able to delete file for this replica, the StopReplicaRequest should fail without making any change and broker should still remember that this replica is offline.2) Currently if broker receives StopReplicaRequest with delete=true, the broker will attempt to remove future replica for the partition, which will cause KafkaStorageException in the StopReplicaResponse if this replica does not have future replica. It is problematic to always return KafkaStorageException in the response if future replica does not exist.Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #5533 from lindong28/KAFKA-7313",0
MINOR: Remove unused import in `WordCountJob` to fix checkstyle failureAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1077 from ijuma/fix-streams-checkstyle-failure,0
MINOR: Clarify wording in server.properties commentAuthor: Jeff Widman <jeff@jeffwidman.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2851 from jeffwidman/patch-3,5
"MINOR: Fix Streams-Broker-Compatibility system test (#4594)fixes error message handling for test consumer client and KafkaStreams instanceupdates expected error messagefixes race condition in system test code and avoids starting Streams processor twiceAuthor: Matthias J. Sax <matthias@confluent.io.>Reviewer: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-10314: KafkaStorageException on reassignment when offline log directories exist (#9122)Make sure that we set the isNew field in LeaderAndIsrRequest correctly for brokersthat gets added to the replica set on reassignment.This is tested by creating a variant of ControllerIntergationTest.testPartitionReassignment()that makes one of the log directories on the target broker offline before initiating thereassignment. Without the change to the way isNew is set, this fails after a timeout. Withthe change, it succeeds.To facilitate calling causeLogDirFailure() both from ControllerIntegrationTest andLogDirFailureTest, the method was moved to TestUtils along with the other helpermethods that deals with interacting with KafkaServer instances for test cases.Reviewers: Mickael Maison <mickael.maison@gmail.com>",3
"KAFKA-9687: KIP-707: Add KafkaFuture.toCompletionStage() (#9878)* Improve the test prior to reimplementing KafkaFutureImpl using CompletableFuture.* KAFKA-9687: Reimplement KafkaFutureImpl using a CompleteableFuture* KIP-707: Add KafkaFuture.toCompletionStageReviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"MINOR: Fix unresolvable address in `testUnresolvableConnectString`Before this change, the test always failed on my MacBook Pro.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3901 from ijuma/fix-unresolvable-address-in-zookeeper-test",3
"KAFKA-6487: ChangeLoggingKeyValueBytesStore does not propagate delete (#4495)The ChangeLoggingKeyValueBytesStore used to write null to its underlying store instead of propagating the delete, which has two drawbacks:* an iterator will see null values* unbounded memory growth of the underlying in-memory keyvalue storeThe fix will just propagate the delete instead of performing put(key, null).The changes to the tests:*extra test whether the key is really gone after delete by calling the approximateEntries on the underlying store. This number is exact because we know the underlying store in the test is of type InMemoryKeyValueStore* extra test to check a delete is logged as <key, null> (the existing test would also succeed if the key is just absent)While also updating the corresponding tests of the ChangeLoggingKeyValueStore I noticed the class is nowhere used anymore so I removed it from the source code for clarity.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10340: Improve trace logging under connector based topic creation (#9149)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,1
KAFKA-5433; Close SimpleAclAuthorizer in test to close ZK clientAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3304 from rajinisivaram/KAFKA-5433,5
"KAFKA-5372; fixes to state transitionsSeveral fixes to state transition logic:- Kafka streams will now be in ERROR when all threads are DEAD or when global thread stops unexpectedly- Fixed transition logic in corner cases when thread is already dead or Kafka Streams is already closed- Fixed incorrect transition diagram in StreamThread- Unit tests to verify transitionsAlso:- re-enabled throwing an exception when an unexpected state change happens- fixed a whole bunch of EoS tests that did not start a thread- added more comments.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3432 from enothereska/KAFKA-5372-state-transitions",5
"MINOR: Document that max.block.ms affects some transaction methods (#8975)The documentation for max.block.ms said it affected only send()and partitionsFor(), but it actually also affects initTransactions(),abortTransaction() and commitTransaction(). So rework thedocumentation to cover these methods too.Reviewers: Boyang Chen <boyang@confluent.io>",5
"KAFKA-7334: Suggest changing config for state.dir in case of FileNotFoundException (#9380)Add additional warning logs and improve existing log messages for `FileNotFoundException` and if /tmp is used as state directory.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5817; Add Serialized class and overloads to KStream#groupBy and KStream#groupByKeyPart of KIP-182- Add the `Serialized` class- implement overloads of `KStream#groupByKey` and KStream#groupBy`- deprecate existing methods that have more than default argumentsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3772 from dguy/kafka-5817",5
"MINOR: Stabilize flaky smoke system tests before KIP-91This is a workaround until KIP-91 is merged. We tried increasing the timeout multiple times already but tests are still flaky.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4329 from mjsax/hotfix-system-tests",5
MINOR: Update AlterConfigsOptions Javadoc (#8958)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"KAFKA-6833; Producer should await metadata for unknown partitions (#6073)This patch changes the behavior of KafkaProducer.waitOnMetadata to wait up to max.block.ms when the partition specified in the produce request is out of the range of partitions present in the metadata. This improves the user experience in the case when partitions are added to a topic and a client attempts to produce to one of the new partitions before the metadata has propagated to the brokers. Tested with unit tests.Reviewers: Arjun Satish <arjun@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4177; Remove ThrottledReplicationRateLimit from Server ConfigThis small PR pulls ThrottledReplicationRateLimit out of KafkaConfig and puts it in a class that defines Dynamic Configs. Client configs are also placed in this class and validation added.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1864 from benstopford/KAFKA-4177",1
"KAFKA-3852: Clarify how to handle message format upgrade without killing performance…ing performanceAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1678 from gwenshap/kafka-3852",5
kafka-1673; potential java.lang.IllegalStateException in BufferPool.allocate(); patched by Jun Rao; reviewed by Jay Kreps,5
KAFKA-798 Use biased histograms instead of uniform histograms in KafkaMetricsGroup; reviewed by Neha Narkhede,1
"HOTFIX: fix KafkaStreams SmokeTestSet the NUM_STREAM_THREADS_CONFIG = 1 in SmokeTestClient as we get locking issues when we have NUM_STREAM_THREADS_CONFIG > 1 and we have Standby Tasks, i.e., replicas. This is because the Standby Tasks can be assigned to the same KafkaStreams instance as the active task, hence the directory is lockedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1861 from dguy/fix-smoketest",3
"MINOR: Fix typo in heartbeat request protocol definition (#6759)This changes the field ""generationid"" to ""generationId"" to be consistent with other uses.Reviewers: Shaobo Liu <lambda.tencent@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6104; Added unit tests for ClusterConnectionStatesAuthor: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Ted Yu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4113 from soenkeliebau/KAFKA-6104",3
"MINOR: Add ConfigRepository, use in Partition and KafkaApis (#10005)`Partition` objects are able to retrieve topic configs when creating their log, and currently they do so with an implementation of `trait TopicConfigFetcher` that uses ZooKeeper.  ZooKeeper is not available when using a Raft-based metadata log, so we need to abstract the retrieval of configs so it can work either with or without ZooKeeper.  This PR introduces `trait ConfigRepository` with `ZkConfigRepository` and `CachedConfigRepository` implementations.  `Partition` objects now use a provided `ConfigRepository` to retrieve topic configs, and we eliminate `TopicConfigFetcher` as it is no longer needed.`ReplicaManager` now contains an instance of `ConfigRepository` so it can provide it when creating `Partition` instances.`KafkaApis` needs to be able to handle describe-config requests; it currently delegates that to `ZkAdminManager`, which of course queries ZooKeeper.  To make this work with or without ZooKeeper we move the logic from `ZkAdminManager` into a new `ConfigHelper` class that goes through a `ConfigRepository` instance.  We provide `KafkaApis` with such an instance, and it creates an instance of the helper so it can use that instead of going through `ZkAdminManager`.Existing tests are sufficient to identify bugs and regressions in `Partition`, `ReplicaManager`, `KafkaApis`, and `ConfigHelper`.  The `ConfigRepository` implementations have their own unit tests.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-10289; Fix failed connect_distributed_test.py (ConnectDistributedTest.test_bounce) (#9673)In Python 3, `filter` functions return iterators rather than `list` so it can traverse only once. Hence, the following loop will only see ""empty"" and then validation fails.```python        src_messages = self.source.committed_messages() # return iterator        sink_messages = self.sink.flushed_messages()) # return iterator        for task in range(num_tasks):            # only first task can ""see"" the result. following tasks see empty result            src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]```Reference: https://portingguide.readthedocs.io/en/latest/iterators.html#new-behavior-of-map-and-filter.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6258; SSLTransportLayer should keep reading from socket until either the buffer is full or the socket has no more dataWhen consumer uses plaintext and there is remaining data in consumer's buffer, consumer.poll() will read all data available from the socket buffer to consumer buffer. However, if consumer uses ssl and there is remaining data, consumer.poll() may only read 16 KB (the size of SslTransportLayer.appReadBuffer) from socket buffer. This will reduce efficient of consumer.poll() by asking user to call more poll() to get the same amount of data.Furthermore, we observe that for users who naively sleep a constant time after each consumer.poll(), some partition will lag behind after they switch from plaintext to ssl. Here is the explanation why this can happen.Say there are 1 partition of 1MB/sec and 9 partition of 32KB/sec. Leaders of these partitions are all different and consumer is consuming these 10 partitions. Let's also assume that socket read buffer size is large enough and consume sleeps 1 sec between consumer.poll(). 1 sec is long enough for consumer to receive the FetchResponse back from broker.When consumer uses plaintext, each consumer.poll() will read all data from the socket buffer and it means 1 MB data is read from each partition.When consumer uses ssl, each consumer.poll() is likely to find that there is some data available in the memory. In this case consumer only reads 16 KB data from other sockets, particularly the socket for the broker with the large partition. Then the throughput of the large partition will be limited to 16KB/sec.Arguably user should not sleep 1 sec if its consumer is lagging behind. But on Kafka dev side it is nice to keep the previous behavior and optimize consumer.poll() to read as much data from socket as possible.Author: Dong Lin <lindong28@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>Closes #4248 from lindong28/KAFKA-6258",5
KAFKA-5439; Verify that no unexpected threads are left behind in testsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3314 from rajinisivaram/KAFKA-5439,5
MINOR: Improve ConsoleProducer options descriptions (#11564)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
KAFKA-13124: close KeyValueIterator instance in internals tests (part 1) (#11106)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-8381; Disable hostname validation when verifying inter-broker SSL (#6757)- Make endpoint validation configurable on SslEngineBuilder when creating an engine- Disable endpoint validation for engines created for inter-broker SSL validation since it is unsafe to use `localhost`- Use empty hostname in validation engine to ensure tests fail if validation is re-enabled by mistake- Add tests to verify inter-broker SSL validationReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
KAFKA-1618 Exception thrown when running console producer with no port number for the broker; reviewed by Neha Narkhede,1
"KAFKA-3266; Describe, Create and Delete ACLs Admin APIs (KIP-140)Includes server-side code, protocol and AdminClient.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2941 from cmccabe/KAFKA-3266",5
"KAFKA-10063; UnsupportedOperation when querying cleaner metrics after shutdown (#8783)Some `LogCleaner` metrics have an unsafe call to `max` over the collection of cleaner threads, which could be empty after shutdown. This leads to an `UnsupportedOperationException`. This patch fixes the problem by changing the computation to use `foldLeft`.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-3175; Topic not accessible after deletion even when delete.topic.enable is disabledRemove topics under /admin/delete_topics path in zk if deleteTopic is disabled. The topic should never be enqueued for deletion.Author: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>Closes #846 from MayureshGharat/kafka-3175",4
kafka-1297; releaseTarGz target needs signing task; trivial change to README.,4
MINOR: improve flaky Streams system testHandle TimeoutException in Producer callback and retry sending input dataAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #4244 from mjsax/improve-flaky-system-test,5
"KAFKA-10634; Adding LeaderId to voters list in LeaderChangeMessage along with granting voters (#9539)This patch ensures that the leader is included among the voters in the `LeaderChangeMessage`. It also adds an additional field for the set of granting voters, which was originally specified in KIP-595.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3403: Upgrade ZkClient to 0.8This ZkClient version adds authentication validation and a conditional delete method needed for other patchesAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #1084 from granthenke/zkclient-08",4
"KAFKA-7196; Remove heartbeat delayed operation for those removed consumers at the end of each rebalanceDuring the consumer group rebalance, when the joining group phase finishes, the heartbeat delayed operation of the consumer that fails to rejoin the group should be removed from the purgatory. Otherwise, even though the member ID of the consumer has been removed from the group, its heartbeat delayed operation is still registered in the purgatory and the heartbeat delayed operation is going to timeout and then another unnecessary rebalance is triggered because of it.Author: Lincong Li <lcli@linkedin.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5556 from Lincong/remove_heartbeat_delayedOperation",4
"KAFKA-8840: Fix bug where ClientCompatibilityFeaturesTest fails when running multiple iterations (#7260)Fix a bug where ClientCompatibilityFeaturesTest fails when running multiple iterations.Also, fix a typo in tests/docker/Dockerfile.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-10274; Consistent timeouts in transactions_test (#9026)KAFKA-10235 fixed a consistency issue with the transaction timeout and the progress timeout. Since the test case relies on transaction timeouts, we need to wait at last as long as the timeout in order to ensure progress. However, having a low transaction timeout makes the test prone to the issue identified in KAFKA-9802, in which the coordinator timed out the transaction while the producer was awaiting a Produce response.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,  Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",5
"MINOR: Enable some AdminClient integration tests (#12110)Enable KRaft in `AdminClientWithPoliciesIntegrationTes`t and `PlaintextAdminIntegrationTest`. There are some tests not enabled or not as expected yet:- testNullConfigs, see KAFKA-13863- testDescribeCluster and testMetadataRefresh, currently we don't get the real controller in KRaft mode so the test may not run as expectedThis patch also changes the exception type raised from invalid `IncrementalAlterConfig` requests with the `SUBTRACT` and `APPEND` operations. When the configuration value type is not a list, we now raise `INVALID_CONFIG` instead of `INVALID_REQUEST`.Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9854 Re-authenticating causes mismatched parse of response (#8471)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ron Dagostino <rdagostino@confluent.io>",5
"MINOR: Align the constructor of KafkaConsumer to KafkaProducer (#8605)1. Move KafkaProducer#propsToMap to Utils#propsToMap2. Apply Utils#propsToMap to constructor of KafkaConsumerReviewers: Noa Resare <noa@resare.com>, Ismael Juma <ismael@juma.me.uk>",4
"MINOR: Remove stale streams producer retry default docs. (#6844)As part of #5425 the streams default override for producer retries was removed. The documentation was not updated to reflect that change.Reviewers: Matthias J. Sax <mjsax@apache.org>, Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-9480: Fix bug that prevented to measure task-level process-rate (#8018)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Fix var typo in verifiable_consumer assertionAuthor: Magnus Edenhill <magnus@edenhill.se>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4098 from edenhill/verfcons_var_fix,0
MINOR: Add ClientQuotaMetadataManager for processing QuotaRecord  (#10101)This PR brings in the new broker metadata processor for handling QuotaRecord-s coming from the metadata log. Also included is a new cache class to allow for fast lookups of quotas on the broker for handling DescribeClientQuotaRequest.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
MINOR: Disable failing testDescribeConsumerGroupOffsets test case (#4863)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-1445 Send all partitions, regardless of how full, whenever we are sending a request to a broker. Patch from Guozhang.",5
"KAFKA-7385; Fix log cleaner behavior when only empty batches are retained (#5623)With idempotent/transactional producers, we may leave empty batches in the log during log compaction. When filtering the data, we keep track of state like `maxOffset` and `maxTimestamp` of filtered data. This patch ensures we maintain this state correctly for the case when only empty batches are left in `MemoryRecords#filterTo`. Without this patch, we did not initialize `maxOffset` in this edge case which led us to append data to the log with `maxOffset` = -1L, causing the append to fail and log cleaner to crash.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-10239: Make GroupInstanceId ignorable in DescribeGroups (#8989)* make GroupInstanceId ignorable in DescribeGroup* tests and cleanups* add throttle test coverage,3
KAFKA-683 Fix correlation id in all requests sent to kafka; reviewed by Jun Rao,0
"MINOR: prevent cleanup() from being called while Streams is still shutting down (#10666)Currently KafkaStreams#cleanUp only throw an IllegalStateException if the state is RUNNING or REBALANCING, however the application could be in the process of shutting down in which case StreamThreads may still be running. We should also throw if the state is PENDING_ERROR or PENDING_SHUTDOWNReviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-6210; IllegalArgumentException if 1.0.0 is used for inter.broker.protocol.version or log.message.format.versionAdded unit test for ApiVersion and testApiVersions fromScala to Java.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4220 from ijuma/kafka-6210-iae-if-1.0.0-inter-broker-protocol-version,5
"KAFKA-7944: Improve Suppress test coverage (#6382)* add a normal windowed suppress with short windows and a short graceperiod* improve the smoke test so that it actually verifies the intendedconditionsSee https://issues.apache.org/jira/browse/KAFKA-7944Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-6309: Improve task assignor load balance (#4624)Sorts TaskIds on first assignment evenly distributing tasks by topicGroupId should help with evening the load of work across topologies. This PR is an initial ""strawman"" approach which will be followed up (at a later date YTBD) by scoring or assigning weight to processing nodes to ensure even processing distribution.Added a new test to existing unit test.",3
kafka-811; (Delta) Fix clientId in migration tool; patched by Swapnil Ghike; reviewed by Jun Rao,0
"KAFKA-7652: Part III; Put to underlying before Flush (#6191)1. In the caching layer's flush listener call, we should always write to the underlying store, before flushing (see #4331 's point 4) for detailed explanation). When fixing 4331, it only touches on KV stores, but it turns out that we should fix for window and session store as well.2. Also apply the optimization that was in session-store already: when the new value bytes and old value bytes are all null (this is possible e.g. if there is a put(K, V) followed by a remove(K) or put(K, null) and these two operations only hit the cache), upon flushing this mean the underlying store does not have this value at all and also no intermediate value has been sent to downstream as well. We can skip both putting a null to the underlying store as well as calling the flush listener sending `null -> null` in this case.Modifies corresponding unit tests.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: Remove APIs deprecated in 0.11.0 for core and clients (#5158)Not included: old consumers and checksum methodsReviewers: Dong Lin <lindong28@gmail.com>,4
KAFKA-3526: Return string instead of object in ConfigKeyInfo and ConfigValueInfoAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1200 from Ishiihara/config-string,5
KAFKA-3510; OffsetIndex thread safety* Make all fields accessed outside of a lock `volatile`* Only allow mutation within the class* Remove unnecessary `AtomicInteger` since mutation always happens inside a lockAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1188 from ijuma/kafka-3510-offset-index-thread-safety,1
"KAFKA-10259: KIP-554 Broker-side SCRAM Config API (#9032)Implement the KIP-554 API to create, describe, and alter SCRAM user configurations via the AdminClient.  Add ducktape tests, and modify JUnit tests to test and use the new API where appropriate.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Double quote `CLASSPATH` to prevent shell glob expansion. (#8191)In the event that `CLASSPATH` does not have an ending "":"", the shellcan expand the CLASSPATH globs to be space-separated list of paths/jars,which is not how the JVM CLI accepts arguments to -cp switch. Sodouble quote the variable to prevent pattern expansion, and pass theglob pattern directly to the JVM.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-10192: Increase max time to wait for worker to start in some integration tests (#10118)Author: Luke Chen <showuon@gmail.com>Reviewers: Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
KAFKA-4409; Fix deadlock between topic event handling and shutdown in ZookeeperConsumerConnectorThe consumer can deadlock on shutdown if a topic event fires during shutdown. The shutdown acquires the rebalance lock and then the topic-event-watcher lock. The topic event watcher acquires these in the reverse order. Shutdown should not need to acquire the topic-event-watcher’s lock - all it does is unsubscribes from topic events.Author: Joel Koshy <jjkoshy@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #2129 from jjkoshy/KAFKA-4409,0
"MINOR: add Kafka Streams upgrade notes for 2.3 release (#6758)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"HOTFIX: Try to complete Send even if no bytes were written (#7622)If there are pending bytes in the transport layer, we maycomplete a send even if no bytes were recorded as written.We assume bytes are written when they are in the netWriteBuffer,but we only consider the send as completed when it's inthe socket channel buffer.This fixes a regression introduced via 0971f66ff546. The impact isthat we would sometimes throw the following exception in`MultiRecordsSend.writeTo`:```javaif (completed())    throw new KafkaException(""This operation cannot be invoked on a complete request."");```Added unit test verifying the bug fix. While in the area, I simplified one of the`SslSelectorTest` methods.Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5959; Fix NPE in Sender.canRetry when idempotence is not enabledAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: tedyu <yuzhihong@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3947 from apurvam/KAFKA-5959-npe-in-sender",5
"KAFKA-6718 / Rack aware standby task assignor (#10851)This PR is part of KIP-708 and adds rack aware standby task assignment logic.Reviewer: Bruno Cadonna <cadonna@apache.org>, Luke Chen <showuon@gmail.com>, Vladimir Sitnikov <vladimirsitnikov.apache.org>",1
"MINOR: Add verification step for Streams archetype to Jenkins build (#6431)Updates ./jenkins.sh to build stream archetype and install it in local maven cache. Afterward, archetype is used to create a new maven project and maven project is compiled for verification.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
Minor: fix compilation error in KAFKA-6254,0
"Fix the missing ApiUtils tests in streams module. (#6003)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: update docs for KIP-663, KIP-696, and KIP-671 (#9969)Co-authored-by: Bruno Cadonna <bruno@confluent.io>Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"MINOR: Use parameterized logging in StandardAuthorizer and StandardAuthorizerData (#12192)This updates StandardAuthorizer and StandardAuthorizerData to use parameterized logging per the SLF4J recommendation (see https://www.slf4j.org/faq.html). This also removes a couple if statements that explicitly check if trace is enabled, but the logger should handle not publishing the message and not constructing the String if trace is not enabled.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6978: make window retention time strict (#5218)Enforce window retention times strictly:* records for windows that are expired get dropped* queries for timestamps old enough to be expired immediately answered with nullReviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9441: Unify committing within TaskManager (#8218) - part of KIP-447 - commit all tasks at once using non-eos (and eos-beta in follow up work) - unified commit logic into TaskManager - split existing methods of Task interface in pre/post partsReviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-3748: Add consumer-property to console tools consumerijuma harshach edoardocomar Can you please review the changes.edoardocomar I have addressed your comment of extra space.Author: Bharat Viswanadham <bharatv@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1474 from bharatviswa504/Kafka-3748,5
KAFKA-6502: Update consumed offsets on corrupted records. (#11683)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-2693: Ducktape tests for SASL/PLAIN and multiple mechanismsRun a sanity test with SASL/PLAIN and a couple of replication tests with SASL/PLAIN and multiple mechanisms.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1282 from rajinisivaram/KAFKA-2693",5
HOTFIX: fix RocksDBMetricsTest (#9935)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
MINOR: bump documentation.html to 3.0,2
MINOR: Improve docs about how to provide multiple log.dir (#12119)Reviewer:  Luke Chen <showuon@gmail.com>,2
"throttle consumer timeout increase (#8188)The test_throttled_reassignment test fails because the consumer that is used to validate reassignment does not start on time to consume all messages. This does not seem like an issue with the throttling of the reassignment, since increasing the timeout allowed the test to pass multiple consecutive runs locally.This test seemed to rely on the default JmxTool for the console consumer that was removed in this commit: 179d0d7The console consumer would check to see if it had partitions assigned to it before beginning to consume. Although the test occasionally failed with the JmxTool, it began to fail much more after the removal.Error messages of failures followed the below format with varying numbers of missed messages. They are the first messages by the producer.535 acked message did not make it to the Consumer. They are: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19...plus 515 more. Total Acked: 192792, Total Consumed: 192259. We validated that the first 535 of these missing messages correctly made it into Kafka's data files. This suggests they were lost on their way to the consumer.In the scope of the test, this error suggests that the test is falling into the race condition described in produce_consume_validate.py, which has the timeout to prevent the consumer from missing initial messages.This can serve as a temporary fix until the logic of consumer startup is addressed further.Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-3505: Fix punctuate generated record metadataAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Anna Povzner <anna@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1190 from guozhangwang/K3505",5
"KAFKA-4661: Improve test coverage UsePreviousTimeOnInvalidTimestampAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3288 from jeyhunkarimov/KAFKA-4661",4
KAFKA-1910; missed follow-up changes,4
KAFKA-12717: Remove internal Connect converter properties (KIP-738) (#10854)Removed Connect Distributed worker's internal converter properties.Author: Chris Egerton <chrise@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
kafka-1940; Initial checkout and build failing; patched by Martin Lemanski; reviewed by Jun Rao,0
KAFKA-9949: Fix flaky GlobalKTableIntegrationTest (#8635)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-4622; Consumer should handle group authorization errors in offset fetchAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2384 from hachikuji/KAFKA-4622",5
"HOTFIX: fix system test race condition (#7836)In some system tests a Streams app is started and then prints a message to stdout, which the system test waits for to confirm the node has successfully been brought up. It then greps for certain log messages in a retriable loop.But waiting on the Streams app to start/print to stdout does not mean the log file has been created yet, so the grep may return an error. Although this occurs in a retriable loop it is assumed that grep will not fail, and the result is piped to wc and then blindly converted to an int in the python function, which fails since the error message is a string (throws ValueError)We should catch the ValueError and return a 0 so it can try again rather than immediately crashReviewers: Bill Bejeck <bbejeck@gmail.com>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-2344; kafka-merge-pr improvementsThe first 4 commits are adapted from changes that have been done to the Spark version and the last one is the feature that gwenshap asked for.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira <cshapi@gmail.com>Closes #90 from ijuma/kafka-2344-merge-pr-improvements and squashes the following commits:900c371 [Ismael Juma] Allow reviewers to be entered during mergeac06347 [Ismael Juma] Allow primary author to be overridden during mergeb309829 [Ismael Juma] Set JIRA resolution to ""Fixed"" instead of relying on default transition0c69a64 [Ismael Juma] Check return value of doctest.testmod()061cdce [Ismael Juma] Fix instructions on how to install the `jira-python` library",0
MINOR: Fix AdminClient.describeConfigs() of listener configs (#4747)Don't return config values from `describeConfigs` if the config type cannot be determined. Obtain config types correctly for listener configs for `describeConfigs` and password encryption.Reviewers: Jason Gustafson <jason@confluent.io>,5
"Added note to RocksDBConfigSetter (#6578)Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-5525: Streams reset tool should have same console output with or without dry-runFixed console output to be consistent with/without dry-run optionAuthor: ppatierno <ppatierno@live.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3443 from ppatierno/kafka-5525",5
"KAFKA-13266; `InitialFetchState` should be created after partition is removed from the fetchers (#11294) `ReplicationTest.test_replication_with_broker_failure` in KRaft mode sometimes fails with the following error in the log:```[2021-08-31 11:31:25,092] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Unexpected error occurred while processing data for partition __consumer_offsets-1 at offset 31727 (kafka.server.ReplicaFetcherThread)java.lang.IllegalStateException: Offset mismatch for partition __consumer_offsets-1: fetched offset = 31727, log end offset = 31728. at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:194) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$8(AbstractFetcherThread.scala:545) at scala.Option.foreach(Option.scala:437) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$7(AbstractFetcherThread.scala:533) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$7$adapted(AbstractFetcherThread.scala:532) at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62) at scala.collection.convert.JavaCollectionWrappers$JMapWrapperLike.foreachEntry(JavaCollectionWrappers.scala:359) at scala.collection.convert.JavaCollectionWrappers$JMapWrapperLike.foreachEntry$(JavaCollectionWrappers.scala:355) at scala.collection.convert.JavaCollectionWrappers$AbstractJMapWrapper.foreachEntry(JavaCollectionWrappers.scala:309) at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:532) at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:216) at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:215) at scala.Option.foreach(Option.scala:437) at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:215) at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:197) at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:99)[2021-08-31 11:31:25,093] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Partition __consumer_offsets-1 marked as failed (kafka.server.ReplicaFetcherThread)```The issue is due to a race condition in `ReplicaManager#applyLocalFollowersDelta`. The `InitialFetchState` is created and populated before the partition is removed from the fetcher threads. This means that the fetch offset of the `InitialFetchState` could be outdated when the fetcher threads are re-started because the fetcher threads could have incremented the log end offset in between.The patch fixes the issue by removing the partitions from the replica fetcher threads before creating the `InitialFetchState` for them.Reviewers: Jason Gustafson <jason@confluent.io>### Committer Checklist (excluded from commit message)- [ ] Verify design and implementation - [ ] Verify test coverage and CI build status- [ ] Verify documentation (including upgrade notes)",2
"KAFKA-2589: The default value for the ""rebalance.backoff.ms"" property is not specified correctly… is not specified correctlyAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #876 from granthenke/rebalance-doc",2
MINOR: update KStream JavaDocsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2258 from mjsax/minorKStreamJavaDoc,2
KAFKA-2314: proper MirrorMaker's message handler help message; reviewed by Guozhang Wang,0
"KAFKA-9731: Disable immediate fetch response for hw propagation if replica selector is not defined (#8607)In the case described in the JIRA, there was a 50%+ increase in the total fetch request rate in2.4.0 due to this change.I included a few additional clean-ups:* Simplify `findPreferredReadReplica` and avoid unnecessary collection copies.* Use `LongSupplier` instead of `Supplier<Long>` in `SubscriptionState` to avoid unnecessary boxing.Added a unit test to ReplicaManagerTest and cleaned up the test class a bit includingconsistent usage of Time in MockTimer and other components.Reviewers: Gwen Shapira <gwen@confluent.io>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: clarify KafkaStreams.close javadoc (#7605)Reviewers: Bill Bejeck <bill@confluent.io>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: refactor CandidateState.unrecordedVoters (#9442)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
HOTFIX: fix build compilation errorAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3981 from dguy/fix-build,0
"KAFKA-10580: Add topic ID support to Fetch request (#9944)Updated FetchRequest and FetchResponse to use topic IDs rather than topic names.Some of the complicated code is found in FetchSession and FetchSessionHandler.We need to be able to store topic IDs and maintain a cache on the broker for IDs that may not have been resolved. On incremental fetch requests, we will try to resolve them or remove them if in toForget.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",5
"KAFKA-365 change copyright in NOTICE to current year, reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1350349 13f79535-47bb-0310-9956-ffa450edef68",1
"HOTFIX: KAFKA-7097; Set create time default to -1L in VerifiableProducerReviewers: Anna Povzner <anna@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: kraft quorum configs should not be internal #11030Reviewers: David Arthur <mumrah@gmail.com>,5
MINOR: Replace unused variable with underscore (#11037)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-7790: Fix Bugs in Trogdor Task Expiration (#6103)The Trogdor Coordinator now overwrites a task's startMs to the time it received it if startMs is in the past.The Trogdor Agent now correctly expires a task after the expiry time (startMs + durationMs) passes. Previously, it would ignore startMs and expire after durationMs milliseconds of local start of the task.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",4
"kafka-12994: Migrated SlidingWindowsTest to new API (#11379)As raised in KAFKA-12994, All tests that use the old API should be either eliminated or migrated to the new API in order to remove the @SuppressWarnings(""deprecation"") annotations.This PR migrates the SlidingWindowsTest to the new API.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
"KAFKA-6647: Do note delete the lock file while holding the lock (#8267)1. Inside StateDirectory#cleanRemovedTasks, skip deleting the lock file (and hence the parent directory) until releasing the lock. And after the lock is released only go ahead and delete the parent directory if manualUserCall == true. That is, this is triggered from KafkaStreams#cleanUp and users are responsible to make sure that Streams instance is not started and hence there are no other threads trying to grab that lock.2. As a result, during scheduled cleanup the corresponding task.dir would not be empty but be left with only the lock file, so effectively we still achieve the goal of releasing disk spaces. For callers of listTaskDirectories like KIP-441 (cc @ableegoldman to take a look) I've introduced a new listNonEmptyTaskDirectories which excludes such dummy task.dirs with only the lock file left.3. Also fixed KAFKA-8999 along the way to expose the exception while traversing the directory.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
KAFKA-10557: Missing docs when describing topic configs including (#9360)Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>,5
KAFKA-1782: Follow up - add missing @Test annotations.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: GuozhangCloses #140 from ewencp/kafka-1782-followup and squashes the following commits:fe36bd1 [Ewen Cheslack-Postava] Fix missing annotation of Before and After in ControllerFailoverTest.1dcaf39 [Ewen Cheslack-Postava] KAFKA-1782: Follow up - add missing @Test annotations.,3
"MINOR: Remove unused isSticky assert out from tests only do constrainedAssign (#8788)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-8320 : fix retriable exception package for source connectors (#6675)WorkerSourceTask is catching the exception from wrong package org.apache.kafka.common.errors. It is not clear from the API standpoint as to which package the connect framework supports - the one from common or connect. The safest thing would be to support both the packages even though it's less desirable.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"kafka-1984; java producer may miss an available partition; patched by Jun Rao; reviewed by Ewen Cheslack-Postava, Jay Kreps, and Guozhang Wang",5
KAFKA-3473; More Controller Health Metrics (KIP-237)This patch adds a few metrics that are useful for monitoring controller health. See KIP-237 for more detail.Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #4392 from lindong28/KAFKA-3473,1
MINOR: set charset of Javadoc to UTF-8Currently javadoc doesn't specify charset.This pull reqeust will set this to UTF-8.Author: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1413 from sasakitoa/javadoc_garbled,2
MINOR; KafkaAdminClient#describeLogDirs should not fail all the futures when only one call fails (#8998)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
KAFKA-544 Store the key given to the producer in the message. Expose this key in the consumer. Patch reviewed by Jun.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410055 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Fix typos in javadoc and code commentsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2595 from vahidhashemian/minor/fix_typos_1702,2
MINOR: Update jackson to 2.9.9 (#6798)Important fix: https://github.com/FasterXML/jackson-databind/issues/2326Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
"KAFKA-5357: capture unexpected exception in txn marker sender thread and treat as fatal errorReplace recursion in `TransactionMarkerChannelManager#appendToLogCallback` with retryQueue. Retry the enqueued log appends each time the InterBrokerSendThread runsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #3192 from dguy/kafka-5357",1
"KAFKA-3549: Close consumers instantiated in consumer testsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1217 from granthenke/close-consumers",5
"KAFKA-8326: Introduce List Serde (#6592)Introduce List serde for primitive types or custom serdes with a serializer and a deserializer according to KIP-466Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Matthias J. Sax <mjsax@conflunet.io>, John Roesler <roesler@confluent.io>, Michael Noll <michael@confluent.io>",5
"KAFKA-12168; Move envelope request parsing out of SocketServer (#9850)Prior to this patch, envelope handling was a shared responsibility between `SocketServer` and `KafkaApis`.  The former was responsible for parsing and validation, while the latter was responsible for authorization. This patch consolidates logic in `KafkaApis` so that envelope requests follow the normal request flow.Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-2198: kafka-topics.sh exits with 0 status on failures; patched by Manikumar Reddy reviewed by Gwen Shapira,0
KAFKA-2783; Drop outdated hadoop contrib modulesAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #466 from granthenke/drop-contrib,4
MINOR: Fix invalid link to plugin.path property docs in quickstart (#12523)Reviewers: Chris Egerton <fearthecellos@gmail.com>,2
KAFKA-4349; Handle 'PreparingRebalance' and 'AwaitingSync' states in consumer group describeThe edge case where consumer group state is `PreparingRebalance` or `AwaitingSync` will be separately handled as the group assignment is not yet determined.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2070 from vahidhashemian/KAFKA-4349,5
KAFKA-3934: Start scripts enable GC by default with no way to disable…o disableAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1631 from granthenke/garbage-flag,5
"KAFKA-2668; Add a metric that records the total number of metricsonurkaraman becketqin Do you have time to review this patch? It addresses the ticket that jjkoshy filed in KAFKA-2668.Author: Dong Lin <lindong28@gmail.com>Reviewers: Onur Karaman <okaraman@linkedin.com>, Joel Koshy <jjkoshy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #328 from lindong28/KAFKA-2668",2
"MINOR: Add more info to RecordCollector error messageguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #873 from ymatsuda/hotfix",0
KAFKA-145 Kafka server mirror shutdown bug; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179466 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Reduce stream thread metrics overheadReduces overheads by avoiding re-calling time.milliseconds().Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2583 from enothereska/minor-reduce-milliseconds,5
"MINOR: Fix storage meta properties comparison (#11546)This patch adds missing `equals` and `hashCode` implements for `RawMetaProperties`. This is relied on by the storage tool for detecting when two log directories have different `meta.properties` files. Reproduce current issue:```shell$ sed -i 's|log.dirs=/tmp/kraft-combined-logs|+log.dirs=/tmp/kraft-combined-logs,/tmp/kraft-combined-logs2' ./config/kraft/server.properties$ ./bin/kafka-storage.sh format -t R19xNyxMQvqQRGlkGDi2cg -c ./config/kraft/server.propertiesFormatting /tmp/kraft-combined-logsFormatting /tmp/kraft-combined-logs2$ ./bin/kafka-storage.sh info -c ./config/kraft/server.propertiesFound log directories:  /tmp/kraft-combined-logs  /tmp/kraft-combined-logs2Found metadata: {cluster.id=R19xNyxMQvqQRGlkGDi2cg, node.id=1, version=1}Found problem:  Metadata for /tmp/kraft-combined-logs2/meta.properties was {cluster.id=R19xNyxMQvqQRGlkGDi2cg, node.id=1, version=1}, but other directories featured {cluster.id=R19xNyxMQvqQRGlkGDi2cg, node.id=1, version=1}```It's reporting that same metadata are not the same...With this fix:```shell$ ./bin/kafka-storage.sh info -c ./config/kraft/server.propertiesFound log directories:  /tmp/kraft-combined-logs  /tmp/kraft-combined-logs2Found metadata: {cluster.id=R19xNyxMQvqQRGlkGDi2cg, node.id=1, version=1}```Reviewers: Igor Soarez <soarez@apple.com>, Jason Gustafson <jason@confluent.io>",5
kafka-763 delta; Add an option to replica from the largest offset during unclean leader election; patched by Swapnil Ghike; reviewed by Jun Rao,4
KAFKA-10769 Remove JoinGroupRequest#containsValidPattern as it is dup… (#9851)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"MINOR: Update documentation for enabling optimizations (#7099)Updated docs for enabling all optimizations as of 2.3Reviewers: Victoria Bialas <vicky@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
KAFKA-9675: Fix bug that prevents RocksDB metrics to be updated (#8256)Reviewers: John Roesler <vvcephei@apache.org>,5
KAFKA-10701 First line of detailed stats from consumer-perf-test.sh incorrect (#9598),3
Adding a .0 for easier post-release support.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178988 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-5475: Connector config validation should include fields for defined transformation aliasesAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3399 from ewencp/kafka-5475-validation-transformations",5
KAFKA-5250: Do fetch down conversion after throttlingPerform down conversion after throttling to avoid retainingmessages in memory during throttling since this could resultin OOM. Also update bytesOut metrics after throttling.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3068 from rajinisivaram/KAFKA-5250,5
"MINOR: Include more detail in `ConfigDef.parseType` exception messageAuthor: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2345 from Kamal15/trunk",1
"MINOR: Refactor StreamsProducer (#8380)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Andrew Choi <a24choi@edu.uwaterloo.ca>",5
"KAFKA-8696: clean up Sum/Count/Total metrics (#7057)* Clean up one redundant and one misplaced metric* Clarify the relationship among these metrics to avoid future confusionReviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Make TopicPartitionBookkeeper and TopicPartitionEntry top level (#12097)This is the first step towards refactoring the `TransactionManager` sothat it's easier to understand and test. The high level idea is to pushdown behavior to `TopicPartitionEntry` and `TopicPartitionBookkeeper`and to encapsulate the state so that the mutations can only be done viathe appropriate methods.Inner classes have no mechanism to limit access from the outer class,which presents a challenge when mutability is widespread (like we dohere).As a first step, we make `TopicPartitionBookkeeper` and`TopicPartitionEntry` top level and rename them and a coupleof methods to make the intended usage clear and avoidredundancy.To make the review easier, we don't change anything elseexcept access changes required for the code to compile.The next PR will contain the rest of the refactoring.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-14162: Stop adding immutable maps/lists to record keys/values in HoistField and MaskField SMTs (#12502)Reviewers:  Sagar Rao <sagarmeansocean@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",1
"MINOR: fix Streams version-probing system test (#6764)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-8345 (KIP-455): Controller and KafkaApi changes (part 3/4) (#7128)Implement the revisions to the controller state machine and reassignment logic needed for KIP-455.Add the addingReplicas and removingReplicas field to the topics ZNode.Deprecate the methods initiating a reassignment via direct ZK access in KafkaZkClient.Add ControllerContextTest, and add some test cases to ReassignPartitionsClusterTest.Add a note to upgrade.html recommending not initiating reassignments during an upgrade.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",5
KAFKA-5293; Do not apply exponential backoff if users have overridden…… reconnect.backoff.msAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3174 from cmccabe/KAFKA-5293,5
BoundedByteBufferReceive hides OutOfMemoryError; patched by Chris Burroughs; reviewed by Neha Narkhede; KAFKA-204git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205663 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Update zstd and use classes with no finalizers (#10120)The updated version includes a few optimizations that benefit us:* Classes with no finalizers (opt-in) that have better GC behavior* `InputStream.skip()` implementation that uses cached buffers* Minor buffer recycler optimizations (used for OutputStream only)Full diff:https://github.com/luben/zstd-jni/compare/v1.4.8-2...v1.4.8-4Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
MINOR: Add 3.0 and 3.1 to broker and client compatibility tests (#11701)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-4302: Simplify KTableSourceKTableSource is always materialized since IQ:  - removed flag KTableSource#materialized  - removed MaterializedKTableSourceProcessorAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Guozhang WangCloses #2065 from mjsax/kafka-4302-simplify-ktablesource",5
"KAFKA-4653; Improve test coverage of RocksDBStoreAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3294 from jeyhunkarimov/KAFKA-4653",4
"KAFKA-12578: Remove deprecated security classes/methods for 3.0 (#10435)More specifically, remove deprecated:- Constants in SslConfigs- Constants in SaslConfigs- AclBinding constructor- AclBindingFilter constructor- PrincipalBuilder and DefaultPrincipalBuilder classes- ResourceFilterAlso simplify tests and code that no longer have to handle the removed `PrincipalBuilder`.These removals seem non controversial. There is a straightforward alternative. Thedeprecations happened in 1.0.0 and 2.0.0.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",4
KAFKA-3655; awaitFlushCompletion() in RecordAccumulator should always decrement flushesInProgress countAuthor: Chen Zhu <amandazhu19620701@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1315 from zhuchen1018/KAFKA-3655,5
"MINOR: MetadataShell should handle ClientQuotaRecord (#11339)MetadataShell should handle ClientQuotaRecord. Also, add MetadataNodeManagerTest.Reviewers: Colin P. McCabe <cmccabe@apache.org>",5
"KAFKA-3835; Streams is creating two ProducerRecords for each send via RecordCollectorAuthor: Jeyhun Karimov <je.karimov@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2417 from jeyhunkarimov/KAFKA-3835",4
"MINOR: Remove TLS renegotiation codeThis has been disabled since the start and sinceit's removed in TLS 1.3, there are no plans toever support it.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4034 from ijuma/remove-tls-renegotiation-support",4
"MINOR: Refer users to `kafka-storage.sh` if `meta.properties` is missing (#10279)The KIP-500 server requires users to run `kafka-storage.sh` to format log directories before the server will start. If the directory is not formatted, the error message complains about a missing `meta.properties` file. It is useful for the message to refer users to `kafka-storage.sh` directly since formatting is a new requirement.This patch also reduces the log level of a very spammy log message in `BrokerLifecycleManager`. Reviewers: Colin P. McCabe <cmccabe@apache.org>",2
MINOR: log which signals are handled on startup (#6620)Reviewers: Gwen Shapira <cshapi@gmail.com>,0
"KAFKA-6455: Session Aggregation should use window-end-time as record timestamp (#6645)For session-windows, the result record should have the window-end timestamp as record timestamp.Rebased to resolve merge conflicts. Removed unused classes TupleForwarder and ForwardingCacheFlushListener (replace with TimestampedTupleForwarder, SessionTupleForwarder, TimestampedCacheFlushListerner, and SessionCacheFlushListener)Reviewers: John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-9263 The new hw is added to incorrect log when ReplicaAlterLogDirsThread is replacing log (fix PlaintextAdminIntegrationTest.testAlterReplicaLogDirs) (#9423)Reviewers: Jun Rao <junrao@gmail.com>,5
KAFKA-2434: Remove identical topic subscription constraint for roundrobin strategy in old consumer APIAuthor: Andrew Olson <aolson1@cerner.com>Reviewers: Onur KaramanCloses #145 from noslowerdna/KAFKA-2434,4
"KAFKA-4772: Exploit #peek to implement #print() and other methodsI remove `KeyValuePrinter` and `KStreamForeach` two class, then implements them by `KStreamPeek`.So, now `KStreamPeek` can do `KeyValuePrinter` and `KStreamForeach` job.Author: jameschien <jameschien@staff.ruten.com.tw>Author: JamesChien <jedichien@users.noreply.github.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2955 from jedichien/trunk",1
"KAFKA-12519: Remove built-in Streams metrics for versions 0.10.0-2.4 (#10765)As specified in KIP-743, this PR removes the built-in metricsin Streams that are superseded by the refactoring proposed in KIP-444.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Luke Chen <showuon@gmail.com>",4
KAFKA-13769 Fix version check in SubscriptionStoreReceiveProcessorSupplier (#12535)This patch fixes another incorrect version check in the FK code and adds unit tests that would have caught this bug.Reviewers: John Roesler <vvcephei@apache.org>,0
"KAFKA-12984: make AbstractStickyAssignor resilient to invalid input, utilize generation in cooperative, and fix assignment bug (#10985)1) Bring the generation field back to the CooperativeStickyAssignor so we don't need to rely so heavily on the ConsumerCoordinator properly updating its SubscriptionState after eg falling out of the group. The plain StickyAssignor always used the generation since it had to, so we just make sure the CooperativeStickyAssignor has this tool as well2) In case of unforeseen problems or further bugs that slip past the generation field safety net, the assignor will now explicitly look out for partitions that are being claimed by multiple consumers as owned in the same generation. Such a case should never occur, but if it does, we have to invalidate this partition from the ownedPartitions of both consumers, since we can't tell who, if anyone, has the valid claim to this partition.3) Fix a subtle bug that I discovered while writing tests for the above two fixes: in the constrained algorithm, we compute the exact number of partitions each consumer should end up with, and keep track of the ""unfilled"" members who must -- or might -- require more partitions to hit their quota. The problem was that members at the minQuota were being considered as ""unfilled"" even after we had already hit the maximum number of consumers allowed to go up to the maxQuota, meaning those minQuota members could/should not accept any more partitions beyond that. I believe this was introduced in #10509, so it shouldn't be in any released versions and does not need to be backported.Reviewers: Guozhang Wang <guozhang@apache.org>, Luke Chen <showuon@gmail.com>",1
"MINOR: Remove the unused field in DelegatingClassLoaderAfter [3173](https://github.com/apache/kafka/commit/e0150a25e8), the field ""activePaths"" is not used anymore.Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4984 from chia7712/remove_unused_field_from_DelegatingClassLoader",4
"KAFKA-7778: Add KTable.suppress to Scala API (#6314)Detailed description* Adds KTable.suppress to the Scala API.* Fixed count in KGroupedStream, SessionWindowedKStream, and TimeWindowedKStream so that the value serde gets passed down to the KTable returned by the internal mapValues method.* Suppress API support for Java 1.8 + Scala 2.11Testing strategyI added unit tests covering:* Windowed KTable.count.suppress w/ Suppressed.untilTimeLimit* Windowed KTable.count.suppress w/ Suppressed.untilWindowCloses* Non-windowed KTable.count.suppress w/ Suppressed.untilTimeLimit* Session-windowed KTable.count.suppress w/ Suppressed.untilWindowClosesReviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: add :server-common test dependency to :storage (#12488)Fix a bug in the KAFKA-14124 PR where a gradle test dependency was missing.This causes missing test class exceptions.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
KAFKA-2001; Trivial commit to prevent OffsetCommitTest from hanging,3
MINOR: Fix options for old-style Admin.listConsumerGroupOffsets (#12406)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-4816; Message format changes for idempotent/transactional producer (KIP-98)Author: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2614 from hachikuji/exactly-once-message-format",5
"KAFKA-9295: increase startup timeout for flaky test in KTableKTableForeignKeyInnerJoinMultiIntegrationTest (#10635)Try to address the extreme flakiness of shouldInnerJoinMultiPartitionQueryable since the recent test cleanup. Since we need to wait for 3 streams reach RUNNING state, it makes sense to increase the waiting time to make the test more reliable.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",3
"MINOR: Remove `activeTaskCheckpointableOffsets` from `AbstractTask` (#7253)Reviewers: cpettitt-confluent <53191309+cpettitt-confluent@users.noreply.github.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2977: Transient Failure in kafka.log.LogCleanerIntegrationTest.cleanerTestMake MinCleanableDirtyRatioProp configurable(default 0.0F)in makeCleaner, thus log cleaning is always undergoing;Also removed minDirtyMessages.Author: jinxing <jinxing@fenbi.com>Author: ZoneMayor <jinxing6042@126.com>Reviewers: Ismael Juma, Guozhang WangCloses #671 from ZoneMayor/trunk-KAFKA-2977",1
KAFKA-1915: Add checkstyle for java code.,1
"MINOR: Fix typo in Log.scala: ""actually recovery"" > ""actually recover"" (#4440)",2
"KAFKA-13654: Extend KStream process with new Processor API (#11993)Updates the KStream process API to cover the use casesof both process and transform, and deprecate the KStream transform API.Implements KIP-820Reviewer: John Roesler <vvcephei@apache.org>",1
"KAFKA-7609; Add Protocol Generator for Kafka (#5893)This patch adds a framework to automatically generate the request/response classes for Kafka's protocol. The code will be updated to use the generated classes in follow-up patches. Below is a brief summary of the included components:**buildSrc/src**The message generator code is here.  This code is automatically re-run by gradle when one of the schema files changes.  The entire directory is processed at once to minimize the number of times we have to start a new JVM.  We use Jackson to translate the JSON files into Java objects.**clients/src/main/java/org/apache/kafka/common/protocol/Message.java**This is the interface implemented by all automatically generated messages.**clients/src/main/java/org/apache/kafka/common/protocol/MessageUtil.java**Some utility functions used by the generated message code.**clients/src/main/java/org/apache/kafka/common/protocol/Readable.java, Writable.java, ByteBufferAccessor.java**The generated message code uses these classes for writing to a buffer.**clients/src/main/message/README.md**This README file explains how the JSON schemas work.**clients/src/main/message/\*.json**The JSON files in this directory implement every supported version of every Kafka API.  The unit tests automatically validate that the generated schemas match the hand-written schemas in our code.  Additionally, there are some things like request and response headers that have schemas here.**clients/src/main/java/org/apache/kafka/common/utils/ImplicitLinkedHashSet.java**I added an optimization here for empty sets.  This is useful here because I want all messages to start with empty sets by default prior to being loaded with data.  This is similar to the ""empty list"" optimizations in the `java.util.ArrayList` class.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>, Bob Barrett <bob.barrett@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-749 Bug in socket server shutdown logic makes the broker hang on shutdown until it has to be killed; reviewed by Sriram and Jay Kreps,1
"KAFKA-9130; KIP-518 Allow listing consumer groups per state (#8238)Implementation of KIP-518: https://cwiki.apache.org/confluence/display/KAFKA/KIP-518%3A+Allow+listing+consumer+groups+per+state. Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",5
"KAFKA-5949; User Callback Exceptions need to be handled properly - catch user exception in user callback (TimestampExtractor, DeserializationHandler, StateRestoreListener) and wrap with StreamsExceptionAdditional cleanup: - rename globalRestoreListener to userRestoreListener - remove unnecessary interface -> collapse SourceNodeRecordDeserializer and RecordDeserializer - removed unused parameter loggingEnabled from ProcessorContext#registerAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3939 from mjsax/kafka-5949-exceptions-user-callbacks",1
"KAFKA-3692; Add quotes to variables in kafka-run-class.shAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1364 from Ishiihara/add-quote-classpath",1
MINOR: Add virtual env to Kafka system test README.mdAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Gwen ShapiraCloses #1346 from Ishiihara/add-venv,1
MINOR: Add cause to thrown exception when deleting topic in TopicCommand (#7301)Unexpected exceptions are caught during topic deletion in `TopicCommand`. The caught exception is currently lost and we raise `AdminOperationException`. This patch fixes the problem by chaining the caught exception. Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-4688; Kafka 0.10.1.1 should be available in system testsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2424 from cmccabe/KAFKA-4688",5
"MINOR: Add information to upgrade notesCredit to Gwen for some of the text.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #678 from ijuma/mirror-maker-compatibility-note",1
MINOR: Add 2.2.0 upgrade instructions (#6501)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-2597: Add to .gitignore the Eclipse IDE directoriesThe ` .metadata` and `.recommenders` keep IDE workspace state and should not be committed.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Guozhang WangCloses #259 from rhauch/kafka-2597,1
KAFKA-9392; Clarify deleteAcls javadoc and add test for create/delete timing (#7956)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
"KAFKA-8562; SaslChannelBuilder - Avoid (reverse) DNS lookup while building SslTransportLayer (#10059)This patch moves the `peerHost` helper defined in `SslChannelBuilder` into `SslFactor`. `SaslChannelBuilder` is then updated to use a new `createSslEngine` overload which relies on `peerHost` when building its `SslEngine`. The purpose is to avoid the reverse DNS in `getHostName`.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7192 Follow-up: update checkpoint to the reset beginning offset (#5430)1. When we reinitialize the state store due to no CHECKPOINT with EOS turned on, we should update the checkpoint to consumer.seekToBeginnning() / consumer.position() to avoid falling into endless iterations.2. Fixed a few other logic bugs around needsInitializing and needsRestoring.Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-7510: preventing data being leaked to logs by default (#5834)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-12536: Add Instant-based methods to ReadOnlySessionStore (#10390)Implements: KIP-666 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-666%3A+Add+Instant-based+methods+to+ReadOnlySessionStore)Reviewers: John Roesler <vvcephei@apache.org>,5
"MINOR: Make LogCleaner.shouldRetainRecord more readable (#6590)Reviewers: Bob Barrett <bob.barrett@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"Make [Config]Resource.toString() consistent with existing code (#4845)The toString() for ConfigResource was using { } instead of ( ) which is inconsistent with the existing toStrings in the code, while toString for Resource was using a mix of ( and }.",1
"MINOR: Support choosing different JVMs when running integration tests+ Add a parameter to the ducktap-ak to control the OpenJDK base image.+ Fix a few issues of using OpenJDK:11 as the base image.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Xi Yang <xi@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #6071 from yangxi/ducktape-jdk",5
"MINOR: Make info logs for KafkaConsumer a bit more verbose (#6279)When debugging KafkaConsumer production issues, it's prettyuseful to have log entries related to seeking and committedoffset retrieval enabled by default. These are currently present,but only when debug logging is enabled. Change them to `info`.Also included a minor code simplication and a slight improvementto an exception message.Reviewers: Jason Gustafson <jason@confluent.io>",5
HOTFIX: ListConsumerGroupsResult should use KafkaFuture (#4933),1
"KAFKA-9952; Remove immediate fetch completion logic on high watermark updates (#8709)For KIP-392, we added logic to make sure that high watermark changes are propagated to followers without delay in order to improve end to end latency when fetching from followers. The downside of this change is that it can increase the rate of fetch requests from followers which can have a noticeable impact on performance (see KAFKA-9731). To fix that problem, we have previously modified the code so that we only propagate high watermark changes immediately when a replica selector is used (which is not the default). However, leaving this logic around means that it is risky to enable follower fetching since it changes the follower request rate, which can have a big impact on overall broker performance. This patch disables immediate propagation of the high watermark more generally. Instead, users can use the max wait time in order to control the worst-case latency. Note that this is typically only a problem anyway for low-throughput clusters since otherwise we will always have a steady rate of high watermark updates.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Fix static mock usage in NamedCacheMetricsTest (#12322)Before this PR the call to `StreamsMetricsImpl.addAvgAndMinAndMaxToSensor()`was just a call and not a verification on the mock. This miss happenedduring the switch from EasyMock to Mockito.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-8640; Use generated classes in OffsetFetch request and response (#7062)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3716; Validate all timestamps are not negativeAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska, Ismael JumaCloses #1393 from guozhangwang/K3716-check-non-negative-timestamps",5
KAFKA-12352: Make sure all rejoin group and reset state has a reason (#10232)1. Create a reason string to be used for INFO log entry whenever we request re-join or reset generation state.2. Some minor cleanups.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
"MINOR: make flush no-op as we don't need to call flush on commit.In the event of a crash, we always restore the data from the backing changelog.  So it seems that we don't need to persist all data to disk by calling flush when committing.  Frequent flushing leads to a large number of small files for compaction increasing compaction pressure.   This PR will perform benchmarks to see if there is any performance gain in not calling `flush()` each time we commit.Author: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3211 from bbejeck/MINOR_no_flush_on_commit",5
"KAFKA-5456; Ensure producer handles old format large compressed messagesMore specifically, fix the case where a compressed V0 or V1 message islarger than the producer batch size.Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3356 from hachikuji/KAFKA-5456",5
"MINOR: increase RocksDb parallelismAuthor: Eno Thereska <eno@confluent.io>Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2663 from enothereska/minor-rocksdb-parallel",5
"KAFKA-7503: Connect integration test harnessExpose a programmatic way to bring up a Kafka and Zk cluster through Java API to facilitate integration tests for framework level changes in Kafka Connect. The Kafka classes would be similar to KafkaEmbedded in streams. The new classes would reuse the kafka.server.KafkaServer classes from :core, and provide a simple interface to bring up brokers in integration tests.Signed-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Author: Arjun Satish <wicknicks@users.noreply.github.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5516 from wicknicks/connect-integration-test",3
"MINOR: Add test demonstrating re-use of KGroupedStream with Optimizations enabled (#6050)Right now if a repartition is required and users choose to name the repartition topic for an aggregation i.e. kGroupedStream = builder.<String, String>stream(""topic"").selectKey((k, v) -> k).groupByKey(Grouped.as(""grouping"")); The resulting KGroupedStream can't be reusedwith optimizations are disabled, as Streams will attempt to create two repartiton topics with the same name.However, if optimizations are enabled then the resulting KGroupedStream can be re-usedFor example the following will work if optimizations are enabled.This PR provides a unit test proving as much.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",3
MINOR: Only update a request's local complete time in API handler if unset (#7813)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-992 followup: Fix zookeeper de-registration bug for controller and consumer; reviewed by Neha Narkhede,0
MINOR: clarify partition option behavior for console consumerConsole Consumer help doesn't say that ``--partition`` option needs ``--offset`` otherwise will consume from the end of the partition. This minor fix makes that happen.Author: Dustin Cote <dustin@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3153 from cotedm/console_consumer_help_fix,0
"KAFKA-6611: PART I, Use JMXTool in SimpleBenchmark (#4650)1. Use JmxMixin for SimpleBenchmark (will remove the self reporting in #4744), only when loading phase is false (i.e. we are in fact starting the streams app).2. Reported the full jmx reported metrics in log files, and in the returned data only return the max values: this is because we want to skip the warming up and cooling down periods that will have lower rate numbers, while max represents the actual rate at full speed.3. Incorporates two other improves to JMXTool: #1241 and #2950Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Rohan Desai <desai.p.rohan@gmail.com>",5
KAFKA-5186; Avoid expensive log scan to build producer state when upgradingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #3113 from hachikuji/KAFKA-5186,5
KAFKA-9078: Fix Connect system test after adding MM2 connector classesMM2 added a few connector classes in Connect's classpath and given that the assertion in the Connect REST system tests need to be adjusted to account for these additions.This fix makes sure that the loaded Connect plugins are a superset of the expected by the test connectors.Testing: The change is straightforward. The fix was tested with local system test runs.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7578 from kkonstantine/minor-fix-connect-test-after-mm2-classes,3
HOTFIX: Check JoinWindow boundariesguozhangwangAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1575 from mjsax/hotfix2,0
"MINOR: Initialize QuorumState lazily in RaftClient.initialize() (#9881)It is helpful to delay initialization of the `RaftClient` configuration including the voter string until after construction. This helps in integration test cases where the voter ports may not be known until sockets are bound.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6398: Return value getter based on KTable materialization statusThis is a bug fix that is composed of two parts:1. The major part is, for all operators that is generating a KTable, we should construct its value getter based on whether the KTable itself is materialized.1.a If yes, then query the materialized store directly for value getter.1.b If not, then hand over to its parents value getter (recursively) and apply the computation to return.2. The minor part is, in KStreamImpl, when joining with a table, we should connect with table's `valueGetterSupplier().storeNames()`, not the `internalStoreName()` as the latter always assume that the KTable is materialized, but that is not always true.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>Closes #4421 from guozhangwang/K6398-KTableValueGetter",1
"KAFKA-6536: Adding versions for japicmp-maven-plugin and maven-shade-plugin in quickstart (#4569)Author: Yaswanth Kumar <yash27422@gmail.com>Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-7266: Fix MetricsTest.testMetrics flakiness using compression (#5485)Increase record size and use compression for downconversion metrics test to ensure that conversion time is above 1ms to avoid transient test failures.Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Ensure `ignorable` is a boolean value (#10567)Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-5954; Correct Connect REST API system testAuthor: Randall Hauch <rhauch@gmail.com>Reviewers: tedyu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3934 from rhauch/kafka-5954",3
kafka-1384; Log Broker state; patched by Timothy Chen; reviewed by Joel Koshy and Jun Rao,2
KAFKA-5624; Add expiry check to sensor.add() methods (#4404),1
"MINOR: fixes lgtm.com warnings (#4582)fixes lgmt.com warningscleanup PrintForeachAction and PrintedAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Sebastian Bauersfeld <sebastianbauersfeld@gmx.de>, Damian Guy <damian@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Update dependencies for Kafka 2.5 (#7909)Noteworthy:* zstd decompression speed improvement of ~10%:https://github.com/facebook/zstd/releases/tag/v1.4.4* EasyMock, PowerMock and Mockito: improved support for Java 13.* Replace usage of method deprecated by Mockito.* Gradle plugins updated to versions that require Gradle 5.x, this isfine since we no longer depend on the installed Gradle version.* Fixed build not to depend on methods deprecated in Gradle 5.x(fixes KAFKA-8786).* Reflections 0.9.12 no longer depends on Guava (fixes KAFKA-3061).* Updated `OptimizedKTableIntegrationTest` to pass with new versionof Hamcrest.* Several Jetty improvements and bug fixes:   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.21.v20190926   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.22.v20191022   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.23.v20191118   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.24.v20191120   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.25.v20191220Note that I did not upgrade lz4 due to https://github.com/lz4/lz4-java/issues/156.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Co-authored-by: Ismael Juma <ismael@juma.me.uk>Co-authored-by: Aljoscha <aljoscha.poertner@posteo.de>",0
"kafka-1318; waiting for producer to stop is not reliable in system tests; patched by Jun Rao; reviewed by Guozhang Wang, Timothy Chen and Neha Narkhede",3
"MINOR: Change logging level for ignored maybeAddMetric from debug to traceAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Xavier Léauté <xavier@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2454 from guozhangwang/KMinor-trace-logging-add-metrics-twice",2
Fix deadlock between leader-finder-thread and consumer-fetcher-thread during broker failure; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-618pre-commit-status-crumb=5e65bf7a-f347-4600-b3ae-99eed1cd2a78git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410665 13f79535-47bb-0310-9956-ffa450edef68,0
KAFKA-2456 KAFKA-2472; SSL clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #342 from ijuma/kafka-2472-fix-kafka-ssl-config-warnings,5
"KAFKA-3581: add timeouts to joins in background thread servicesThis actually removes joins altogether, as well as references to self.worker_threads, which is best left as an implementation detail in BackgroundThreadService.This makes use of hachikuji 's recent ducktape patch, and updates ducktape dependency to 0.5.0.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1297 from granders/KAFKA-3581-systest-add-join-timeout",5
"MINOR: Trivial doc/ typo fixes.The change in `docs/design.html` is hard to catch in the diff -- a `tbe` is changed to `the`. All other changes show up clearly in the diff.This contribution is my original work and I license the work to the project under the project's open source license.Author: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Grant Henke, Gwen ShapiraCloses #654 from alexlod/doc-typo-fixes",2
MINOR: Fix typo in security.html (#6141)kafka-delegation-tokens.sh is the name of the script,2
"MINOR: Fix buildResponseSend test cases for envelope responses (#12185)The test cases we have in `RequestChannelTest` for `buildResponseSend` construct the envelope request incorrectly. The request is created using the envelope context, but also a reference to the wrapped envelope request object. This patch fixes `TestUtils.buildEnvelopeRequest` so that the wrapped request is built properly. It also fixes the dependence on this incorrect construction and consolidates the tests in `RequestChannelTest` to avoid duplication.Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Documentation updates for reserved.broker.max.idPeople are facing problems upgrading their clusters with configured broker IDs above 1000 due to `reserved.broker.max.id` which wasn't very well announced.This PR attempts to improve that somewhat by fixing the broker config docs and adding a note to the upgrade documentation.Author: Magnus Edenhill <magnus@edenhill.se>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #670 from edenhill/docs-reserved.broker.max.id",2
MINOR: the code generator should be able to set the java package (#7355)Reviewers: Colin P. McCabe <cmcabe@apache.org>,1
MINOR: Fixed documentation for KStream left join KStream-KTableWe are not joining in a window here.Author: Jendrik Poloczek <jendrik.poloczek@hivestreaming.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1692 from jpzk/trunk,1
"KAFKA-8653; Default rebalance timeout to session timeout for JoinGroup v0 (#7072)The rebalance timeout was added to the JoinGroup protocol in version 1. Prior to 2.3,we handled version 0 JoinGroup requests by setting the rebalance timeout to be equalto the session timeout. We lost this logic when we converted the API to use thegenerated schema definition (#6419) which uses the default value of -1. The impactof this is that the group rebalance timeout becomes 0, so rebalances finish immediatelyafter we enter the PrepareRebalance state and kick out all old members. This causesconsumer groups to enter an endless rebalance loop. This patch restores the oldbehavior.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-7177; Update 2.0 documentation to reflect changed quota behaviors by KIP-219Updated the 2.0 document for changed quota behaviors.Author: Jon Lee <jonlee@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>Closes #5384 from jonlee2/KAFKA-7177",2
"MINOR: adjust logging levels in Stream tests (#12255)Now that we've turned off logging in the brokers/zookeeper/config classes we can finally see at least some of the logs where Streams is actually doing something when trying to debug tests from a failed PR build. But I've noticed we still have some flooding of warnings from the NetworkClient and info-level junk from Metadata, so to maximize the visible useful logs we should filter out everything bu the producer/consumer client themselves (in addition to Streams) fine-grained loggingReviewers: Luke Chen <showuon@gmail.com>, Kvicii Y",2
"KAFKA-7222: Add Windows grace period (#5369)Part I of KIP-238:* add grace period to Windows* deprecate retention/maintainMs and segmentInterval from Windows* record expired records in the store with a new metric* record late record drops as a new metric instead of as a ""skipped record""Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-2600: Align Kafka Streams' interfaces with Java 8 functional interfacesA few of Kafka Stream's interfaces and classes are not as well-aligned with Java 8's functional interfaces. By making these changes, when Kafka moves to Java 8 these classes can extend standard Java 8 functional interfaces while remaining backward compatible. This will make it easier for developers to use Kafka Streams, and may allow us to eventually remove these custom interfaces and just use the standard Java 8 interfaces.The changes include:1. The 'apply' method of KStream's `Predicate` functional interface was renamed to `test` to match the method name on `java.util.function.BiPredicate`. This will allow KStream's `Predicate` to extend `BiPredicate` when Kafka moves to Java 8, and for the `KStream.filter` and `filterOut` methods to accept `BiPredicate`.2. Renamed the `ProcessorDef` and `WindowDef` interfaces to `ProcessorSupplier` and `WindowSupplier`, respectively. Also the `SlidingWindowDef` class was renamed to `SlidingWindowSupplier`, and the `MockProcessorDef` test class was renamed to `MockProcessorSupplier`. The `instance()` method in all were renamed to `get()`, so that all of these can extend/implement Java 8's `java.util.function.Supplier<T>` interface in the future with no other changes and while remaining backward compatible. Variable names that used some form of ""def"" were changed to use ""supplier"".These two sets of changes were made in separate commits.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #270 from rhauch/kafka-2600",4
MINOR: Bump version to 2.3.0-SNAPSHOT (#6226)* MINOR: Bump version to 2.3.0-SNAPSHOT* Github comment,5
MINOR: Remove redundant casting and if condition from ConnectSchema (#9959)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
MINOR: Various javadoc improvement in clients and connect (#5878)Fixed formatting issues and added links in a few classes,2
KAFKA-1723 (delta patch to fix javadoc); make the metrics name in new producer more standard; patched by Manikumar Reddy; reviewed by Jun Rao,1
KAFKA-6560: [FOLLOW-UP] don't deserialize null byte array in window store fetch (#4665)If the result of a fetch from a Window Store results in a null byte array we should return null rather than passing it to the serde to deserialize.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
KAFKA-10447: Migrate tools module to JUnit 5 (#9231)This change sets the groundwork for migrating other modules incrementally.Main changes:- Replace `junit` 4.13 with `junit-jupiter` and `junit-vintage` 5.7.0-RC1.- All modules except for `tools` depend on `junit-vintage`.- `tools` depends on `junit-jupiter`.- Convert `tools` tests to JUnit 5.- Update `PushHttpMetricsReporterTest` to use `mockito` instead of `powermock` and `easymock`(powermock doesn't seem to work well with JUnit 5 and we don't need it since mockito can mockstatic methods).- Update `mockito` to 3.5.7.- Update `TestUtils` to use JUnit 5 assertions since `tools` depends on it.Unrelated clean-ups:- Remove `unit` from package names in a few `core` tests.- Replace `try/catch/fail` with `assertThrows` in a number of places.- Tag `CoordinatorTest` as integration test.- Remove unnecessary type parameters when invoking methods and constructors.Tested with IntelliJ and gradle. Verified that the following commands work as expected:* ./gradlew tools:unitTest* ./gradlew tools:integrationTest* ./gradlew tools:test* ./gradlew core:unitTest* ./gradlew core:integrationTest* ./gradlew clients:testReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
kafka-965; merge c39d37e9dd97bf2462ffbd1a96c0b2cb05034bae from 0.8 to trunk; patched by Jun Rao; reviewed by Jay Kreps,1
"KAFKA-9267: ZkSecurityMigrator should not create /controller node[KAFKA-9267](https://issues.apache.org/jira/browse/KAFKA-9267)ZkSecurityMigrator might create a PERSISTENT /controller node with null data, it will lead to controller can't elect.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: NanerLee <nanerlee@qq.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7778 from NanerLee/fix-ZkSecurityMigrator",0
"delete (#7504)This system test was marked @Ignore around a year and a half ago pending the version probing work, but never turned on again.These days, it is made redundant by the suite of system tests in streams_upgrade_test, which cover rolling upgrades (including version probing and metadata change).Reviewers: Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-3152; kafka-acl doesn't allow space in principal name* Add quotes to `$` in shell scriptsThis is necessary for correct processing of quotes in theuser command.* Minor improvements to AclCommand messages* Use a principal with a space in `SslEndToEndAuthorizationTest`This passed without any other changes, but good avoid regressions.* Clean-up `TestSslUtils`:Remove unused methods, fix unnecessary verbosity and don't set security.protocol (it should be done at a higher-level).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.comCloses #818 from ijuma/kafka-3152-kafka-acl-space-in-principal",1
"KAFKA-6868; Fix buffer underflow and expose group state in the consumer groups API (#4980)* The consumer groups API should expose group state and coordinator information.  This information is needed by administrative tools and scripts that access consume groups.* The partition assignment will be empty when the group is rebalancing. Fix an issue where the adminclient attempted to deserialize this empty buffer.* Remove nulls from the API and make all collections immutable.* DescribeConsumerGroupsResult#all should return a result as expected, rather than Void* Fix exception text for GroupIdNotFoundException, GroupNotEmptyException. It was being filled in as ""The group id The group id does not exist was not found"" and similar.Reviewers: Attila Sasvari <asasvari@apache.org>, Andras Beni <andrasbeni@cloudera.com>, Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-9435: DescribeLogDirs automated protocol (#7972)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"KAFKA-9077: Fix reading of metrics of Streams' SimpleBenchmark (#7610)With KIP-444 the metrics definitions are refactored. Thus, Streams' SimpleBenchmark needs to be updated to correctly access the refactored metrics.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",4
"MINOR: Additional detail in description for zookeeper.connect (#5358)This setting allows specifying a chroot so we documented it.Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Katherine Farmer <kfarme3@uk.ibm.com>Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: fix @link tags in javadoc (#9939)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
MINOR: Increase produce timeout to 120 seconds (#6326)MINOR: Increase produce timeout for EmbeddedKafkaCluster to 120 secondsPrevious value was 500ms. This change gives more room to pass tests on systems with low resources running many parallel tests.Reviewers: Randall Hauch <randall@confluent.io>,5
"KAFKA-6382: Make ProducerConfig and ConsumerConfig constructors public (#4341)* KIP-234* update constructors to accept Properties and Map<String,Object>* use ProducerConfig to access BATCH_SIZE default value in Streams",5
MINOR: Update Crc32Test#testUpdate method with correct Crc32 (#10406)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
MINOR: use new method to get number of topics in DeleteTopicsRequest (#10351)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Remove deprecated callers (#5911)Callers of 1) Windows#until, 2) Windows#of, 3) Serialized are replaced when possible with the new APIs.Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>",5
System Test : Disable shallow.iterator in Mirror Maker test cases to make compression work correctly; patched by John Fung; reviewed by Jun Rao; kafka-737,1
"KAFKA-5130: Refactor transaction coordinator's in-memory cache; plus fixes on transaction metadata synchronization1. Collapsed the `ownedPartitions`, `pendingTxnMap` and the `transactionMetadataCache` into a single in-memory structure, which is a two-layered map: first keyed by the transactionTxnLog, and then valued with the current coordinatorEpoch of that map plus another map keyed by the transactional id.2. Use `transactionalId` across the modules in transactional coordinator, attach this id with the transactional marker entries.3. Use two keys: `transactionalId` and `txnLogPartitionId` in the writeMarkerPurgatory as well as passing it along with the TxnMarkerEntry, so that `TransactionMarkerRequestCompletionHandler` can use it to access the two-layered map upon getting responses.4. Use one queue per `broker-id` and `txnLogPartitionId`. Also when there is a possible update on the end point associated with the `broker-id`, update the Node without clearing the queue but relying on the requests to retry in the next round.5. Centralize the error handling callback for appending-metadata-to-log and sending-markers-to-brokers in `TransactionStateManager#appendTransactionToLog`, and `TransactionMarkerChannelManager#addTxnMarkersToSend`.6. Always update the in-memory transaction metadata AFTER the txn log has been appended and replicated, and then double check on the cache to make sure nothing has changed since log appending. The only exception is when initializing the pid for the first time, in which we will put a dummy into the cache but set its pendingState as `Empty` (so it will be valid to transit from `Empty` to `Empty`) so that it can be updated after the log append has completed.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma, Damian Guy, Jason Gustafson, Jun RaoCloses #2964 from guozhangwang/K5130-refactor-tc-inmemory-cache",4
"DOCS - clarify transactionalID and idempotent behavior (#7821)If transactional.id is set without setting enable.idempotence, the producer will set enable.idempotence to true implicitly. The docs should reflect this.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-202 Make request processing in kafka asynchronous; patched by jaykreps; reviewed by junrao and nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1230845 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Rename DecommissionBrokers to UnregisterBrokers (#10084)Rename DecommissionBrokers to UnregisterBrokers. Fix an incorrect JavaDoc commentfor the Admin API. Make sure that UNREGISTER_BROKER is marked as forwardable andnot as a controller-only API (since it can received by brokers).Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Print exception stack traces in ConsumerGroupCommand. (#5286)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"MINOR: Handle 0 futures in all()If we pass in 0 futures to an AllOfAdapter, we should complete immediatelyAuthor: dan norwood <norwood@confluent.io>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2953 from norwood/handle-all-of-0",0
"KAFKA-1054; Eliminate Scala Compilation WarningsChanges:- Suppressed compiler warnings about type erasure in matching via unboxingby Jon Riehl.- Suppressed warning caused by slight difference in input function typeby John Riehl.- Fix compiler warnings: ServerShutdownTest, DelayedJoinGroup functionsignature by Blake Smith.- Fix Scala 2.11 warnings. `Pair` has been deprecated, `try` without`catch` and `finally` is useless and initialisation order fix by IsmaelJuma.",0
KAFKA-1807 Improve accuracy of ProducerPerformance target throughput; reviewed by Neha Narkhede,1
"KAFKA-10473: Add docs on partition size-on-disk, and other log-related metrics (#9276)kafka.log,type=Log,name=Sizekafka.log,type=Log,name=NumLogSegmentskafka.log,type=Log,name=LogStartOffsetkafka.log,type=Log,name=LogEndOffsetReviewers: Guozhang Wang <wangguoz@gmail.com>",2
"MINOR: Embedded connect cluster should mask exit procedures by default (#7028)`EmbeddedConnectCluster` has the ability to mask system exits to avoid killing the jvm. It appears that the default was intended to be `true`, but is actually `false`. The `maskExitProcedures` method on `EmbeddedConnectCluster.Builder` documents the parameter as:```* @param mask if false, exit and halt procedures remain unchanged; true is the default.```Because this is not enabled by default as intended, we are seeing some build failures which exit abruptly:```17:29:11 Execution failed for task ':connect:runtime:integrationTest'.17:29:11 > Process 'Gradle Test Executor 25' finished with non-zero exit value 1```The culprit often appears to be `ExampleConnectIntegrationTest`, which indeed does not override the default value of `maskExitProcedures`.Reviewers: Ewen Cheslack-Postava <me@ewencp.org>",3
"KAFKA-6853: ZooKeeperRequestLatencyMs is incorrect (#4961)ResponseMetadata.responseTimeMs is always 0 or negative.Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: remove unused MeteredKeyValueStore (#5380)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
kafka-1378; transient unit test failure in LogRecoveryTest; patched by Jun Rao; reviewed by Neha Narkhede,3
KAFKA-1428 Ensure we close the file handle when reading the config.,5
trivial change to add byte serializer to ProducerPerformance; patched by Jun Rao,1
KAFKA-3242: minor rename / logging change to ControllerKAFKA-3242: minor rename / logging change to references to 'adding partitions' to indicate 'modifying partitions'Author: Ben Stopford <benstopford@gmail.com>Reviewers: Grant HenkeCloses #924 from benstopford/small_changes,4
MINOR: Add entityType for metadata record definitions (#10116)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
kafka-2205; Generalize TopicConfigManager to handle multiple entity configs; patched by Aditya Auradkar; reviewed Jun Rao,5
"KAFKA-6060; Add workload generation capabilities to TrogdorPreviously, Trogdor only handled ""Faults.""  Now, Trogdor can handle""Tasks"" which may be either faults, or workloads to execute in thebackground.The Agent and Coordinator have been refactored from amutexes-and-condition-variables paradigm into a message passingparadigm.  No locks are necessary, because only one thread can accessthe task state or worker state.  This makes them a lot easier to reasonabout.The MockTime class can now handle mocking deferred message passing(adding a message to an ExecutorService with a delay).  I added aMockTimeTest.MiniTrogdorCluster now starts up Agent and Coordinator classes inparalle in order to minimize junit test time.RPC messages now inherit from a common Message.java class.  This classhandles implementing serialization, equals, hashCode, etc.Remove FaultSet, since it is no longer necessary.Previously, if CoordinatorClient or AgentClient hit a networkingproblem, they would throw an exception.  They now retry several timesbefore giving up.  Additionally, the REST RPCs to the Coordinator andAgent have been changed to be idempotent.  If a response is lost, andthe request is resent, no harm will be done.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4073 from cmccabe/KAFKA-6060",5
KAFKA-2186; Follow-up to KAFKA-1650 - add selective offset commit to consumer connector API; reviewed by Joel Koshy,1
"KAFKA-2534: Fixes and unit tests for SSLTransportLayer buffer overflowUnit tests which mock buffer overflow and underflow in the SSL transport layer and fixes for the couple of issues in buffer overflow handling described in the JIRA.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>Closes #205 from rajinisivaram/KAFKA-2534",5
kafka-1462; Add new request and response formats for the new consumer and coordinator communication; patched by Jun Rao; reviewed by Guozhang Wang and Jay Kreps,1
MINOR: Update test libraries and gradle plugins for better JDK 16/17 support (#10619)Details:* spotbugs gradle plugin from 4.6.0 to 4.7.1:  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.1  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.2  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.7.0  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.7.1* spotless gradle plugin from 5.10.2 to 5.12.4:  https://github.com/diffplug/spotless/blob/gradle/5.12.4/CHANGES.md* test-retry gradle plugin from 1.2.0 to 1.2.1:  https://github.com/gradle/test-retry-gradle-plugin/releases/tag/v1.2.1* dependency check gradle plugin from 6.1.1 to 6.1.6:  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.2  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.3  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.4  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.5  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.6* versions gradle plugin from 0.36.0 to 0.38.0:https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.37.0https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.38.0* easymock from 4.2 to 4.3:  https://github.com/easymock/easymock/releases/tag/easymock-4.3* mockito from 3.6.0 to 3.9.0:https://github.com/mockito/mockito/releases (too many releases to list  them all individually)* spotbugs from 4.1.4 to 4.2.2:  https://github.com/spotbugs/spotbugs/blob/4.2.2/CHANGELOG.md  4.2.3 has a regression that causes spurious errors related to `Random`  usage.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,0
MINOR: Don't imply that ConsumerGroupCommand won't work with non-Java clientsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3564 from ewencp/minor-consumer-group-command-message,1
"KAFKA-8841; Reduce overhead of ReplicaManager.updateFollowerFetchState (#7324)This PR makes two changes to code in the ReplicaManager.updateFollowerFetchState path, which is in the hot path for follower fetches. Although calling ReplicaManager.updateFollowerFetch state is inexpensive on its own, it is called once for each partition every time a follower fetch occurs.1. updateFollowerFetchState no longer calls maybeExpandIsr when the follower is already in the ISR. This avoid repeated expansion checks. 2. Partition.maybeIncrementLeaderHW is also in the hot path for ReplicaManager.updateFollowerFetchState. Partition.maybeIncrementLeaderHW calls Partition.remoteReplicas four times each iteration, and it performs a toSet conversion. maybeIncrementLeaderHW now avoids generating any intermediate collections when updating the HWM.**Benchmark results for Partition.updateFollowerFetchState on a r5.xlarge:**Old:```  1288.633 ±(99.9%) 1.170 ns/op [Average]  (min, avg, max) = (1287.343, 1288.633, 1290.398), stdev = 1.037  CI (99.9%): [1287.463, 1289.802] (assumes normal distribution)```New (when follower fetch offset is updated):```  261.727 ±(99.9%) 0.122 ns/op [Average]  (min, avg, max) = (261.565, 261.727, 261.937), stdev = 0.114  CI (99.9%): [261.605, 261.848] (assumes normal distribution)```New (when follower fetch offset is the same):```  68.484 ±(99.9%) 0.025 ns/op [Average]  (min, avg, max) = (68.446, 68.484, 68.520), stdev = 0.023  CI (99.9%): [68.460, 68.509] (assumes normal distribution)```Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2711; SaslClientAuthenticator no longer needs KerberosNameParser in constructorAlso refactor `KerberosNameParser` and `KerberosName` to make the codeclearer and easier to use when `shortName` is not needed.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #390 from ijuma/kafka-2711,1
"KAFKA-5350: Modify unstable annotations in Streams APIAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3172 from guozhangwang/K5350-compatibility-annotations",5
KAFKA-9516; Increase timeout in testNonBlockingProducer to make it more reliable (#9181)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-8782: Close metrics in QuotaManagerTests (#7191)Since `Metrics` was constructed with `enableExpiration=false`, this wasnot a source of flakiness given the current implementation. This couldchange in the future, so good to follow the class contract.Included a few clean-ups with regards to redundant casts and type parametersas well as usage of try with resources for inline usage of `Metrics`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"MINOR: Remove gradleSetup from Jenkinsfile (#10522)We no longer need this since:1. The PR and branch jobs are configured to `clean before checkout`.2. The Gradle build outputs the gradle version on start-up.The description of `clean before checkout` is:> Clean up the workspace before every checkout by deleting all untracked files and directories, including those which are specified in .gitignore. It also resets all tracked files to their versioned state. This ensures that the workspace is in the same state as if you cloned and checked out in a brand-new empty directory, and ensures that your build is not affected by the files generated by the previous build.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
MINOR: Test for non-blocking send using max.block.ms=0 (#7370)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
MINOR: Use dynamic port in `RestServerTest` (#7079)We have seen some failures recently in `RestServerTest`. It's the usual problem with reliance on static ports. ```Caused by: java.io.IOException: Failed to bind to 0.0.0.0/0.0.0.0:8083at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:346)at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:308)at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236)at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)at org.eclipse.jetty.server.Server.doStart(Server.java:396)at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)at org.apache.kafka.connect.runtime.rest.RestServer.initializeServer(RestServer.java:178)... 56 moreCaused by: java.net.BindException: Address already in use```This patch makes the chosen port dynamic.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-2050 Avoid calling .size() on linked list.,2
"KAFKA-7824; Require member.id for initial join group request [KIP-394] (#6058)This patch implements KIP-394 as documented in https://cwiki.apache.org/confluence/display/KAFKA/KIP-394%3A+Require+member.id+for+initial+join+group+request.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-12376: Apply atomic append to the log (#10253),2
"MINOR: Update docs to say 2.2 (#6315)Update docs to say 2.2Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
MINOR: Leaves lock() outside the try block  (#9687)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"MINOR: Should cleanup the tasks after dirty close (#8433)Some tasks get closed inside HandleAssignment and did not remove from the task manager bookkeep list. The next time they would be re-closed which is illegal state.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
new consumer request format; patched by Prashanth Menon; reviewed by Jun Rao and Jay Kreps; KAFKA-240git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1243407 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9189: Use MetadataCache instead of ZK during controlled shutdown to avoid hang (#10361)This avoids hanging during shutdown if ZK is unavailable. We could change ZKcalls to get the controller id and the broker information to have a timeout, but Ithink this approach is better.The downside is that the metadata cache may be slightly out of date, but we willretry as per the controlled shutdown configuration. If this broker is partitionedaway from the Controller and is not receiving metadata updates, then we wantto shutdown asap anyway.I added a test that timed out without this change and included a couple of clean-upsin `ServerShutdownTest`:* Removed `testCleanShutdownWithDeleteTopicEnabled`, which is redundantsince delete topics is enabled by default.* Removed redundant method argumentsReviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-3896: fix transient failure in KStreamRepartitionJoinTestijuma i checked the cases where this test has failed and it seems to always be on the verification of the left join. I've ran this test plenty of times and i can't get it to fail. However in the interest of having stable builds, i've removed just the part of the test that is failing (which happens to be the last verification).Thanks,DamianAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #1549 from dguy/kafka-3896",0
kafka-1228; Socket Leak on ReplicaFetcherThread; patched by Ahmy Yulrizka; reviewed by Jun Rao,5
"KAFKA-3817: KTableRepartitionMap publish old Change first, for non-count aggregatesI affirm that the contribution is my original work and that I license the work to the project under the project's open source license.This cleans up misbehaviour that was introduce while fixing KAFKA-3817. It is impossible for a non-count aggregate to be build, when the addition happens before the removal. IMHO making sure that these details are correct is very important.This PR has local test errors. It somehow fails the ResetIntegrationTest. It doesn't quite appear to me why but it looks like this PR breaks it, especially because the error appears with the ordering of the events. Still I am unable to find where I could have broken it. Maybe not seems to fail on trunk aswell.Author: jfilipiak <Jan.Filipiak@trivago.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1705 from Kaiserchen/KAFKA-3817-preserve-order-for-aggreagators",1
MINOR: Specify keyalg RSA for SSL key generationAuthor: Sriharsha Chintalapani <harsha@hortonworks.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1416 from harshach/ssl-doc-fix,2
"KAFKA-7236: Add --under-min-isr option to describe topics command (KIP-351) (#6224)* KAFKA-7236: Add --under-min-isr option to describe topics command (KIP-351)* Minor changes to description and make test consistent with others* Fix option, and add additional test with mixed partition status* Add fully-replicated-topic to test case* Address review nits",1
"MINOR: JavaDoc improvements for new state store APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4006 from mjsax/minor-javadoc-improvments-for-stores",2
MINOR: Fix compiler error in `KafkaLog4jAppender`The branch wasn't rebased after the capitalisation fix for SSLclasses.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #368 from ijuma/fix-kafka-log4j-appender-compiler-error,2
"KAFKA-3749; fix ""BOOSTRAP_SERVERS_DOC"" typoAuthor: manuzhang <owenzhang1990@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1420 from manuzhang/KAFKA-3749",5
"KAFKA-4352: instable ResetTool integration test - increased timeout to stabilize testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Guozhang WangCloses #2082 from mjsax/kafka-4352-hotfix",0
KAFKA-3675; Add lz4 to parametrized `test_upgrade` system testAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1343 from ijuma/kafka-3675-lz4-test-upgrade,3
"KAFKA-6955: Use Java AdminClient in DeleteRecordsCommand (#5088)- Removed internal kafka.admin.AdminClient.deleteRecordsBefore since it'sno longer used.- Removed redundant tests and rewrote non redundant ones to use the JavaAdminClient.Reviewers: Viktor Somogyi <viktor.somogyi@cloudera.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"Rework on KAFKA-3968: fsync the parent directory of a segment file when the file is created (#10680)(reverted #10405). #10405 has several issues, for example:It fails to create a topic with 9000 partitions.It flushes in several unnecessary places.If multiple segments of the same partition are flushed at roughly the same time, we may end up doing multiple unnecessary flushes: the logic of handling the flush in LogSegments.scala is weird.Kafka does not call fsync() on the directory when a new log segment is created and flushed to disk.The problem is that following sequence of calls doesn't guarantee file durability:fd = open(""log"", O_RDWR | O_CREATE); // suppose open creates ""log""write(fd);fsync(fd);If the system crashes after fsync() but before the parent directory has been flushed to disk, the log file can disappear.This PR is to flush the directory when flush() is called for the first time.Did performance test which shows this PR has a minimal performance impact on Kafka clusters.Reviewers: Jun Rao <junrao@gmail.com>",5
"MINOR: Fix producer leak in `PlaintextProducerSendTest`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1471 from ijuma/fix-leaking-producers-in-plaintext-producer-send-test",3
"MINOR: equals() should check _unknownTaggedFields (#8640)_unknownTaggedFields contains tagged fields which we don't understandwith the current schema.  However, we still want to keep the data aroundfor various purposes. For example, if we are printing out a JSON form ofthe message we received, we want to include a section containing thetagged fields that couldn't be parsed. To leave these out would give anincorrect impression of what was sent over the wire.  Since the unknowntagged fields represent real data, they should be included in the fieldschecked by equals().Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>",5
MINOR: Add missing parentheses in docs/streams/tutorial.html (#7696)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-2489: add benchmark for new consumerewencpThe changes here are smaller than they look - mostly refactoring/cleanup.- ConsumerPerformanceService: added new_consumer flag, and exposed more command-line settings- benchmark.py: refactored to use `parametrize` and `matrix` - this reduced some amount of repeated code- benchmark.py: added consumer performance tests with new consumer (using `parametrize`)- benchmark.py: added more detailed test descriptions- performance.py: broke into separate filesAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Gwen ShapiraCloses #179 from granders/KAFKA-2489-benchmark-new-consumer",1
KAFKA-7938: Fix test flakiness in DeleteConsumerGroupsTest (#6312),3
"KAFKA-4965; set internal.leave.group.on.close to false in StreamsConfigSet the internal consumer config internal.leave.group.on.close in`StreamsConfig`. This is to reduce the number of rebalances we getduring bounces.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2750 from dguy/kafka-4965",1
KAFKA-10338; Support PEM format for SSL key and trust stores (KIP-651) (#9345)Adds support for SSL key and trust stores to be specified in PEM format either as files or directly as configuration values.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"KAFKA-7610; Proactively timeout new group members if rebalance is delayed (#5962)When a consumer first joins a group, it doesn't have an assigned memberId. If the rebalance is delayed for some reason, the client may disconnect after a request timeout and retry. Since the client had not received its memberId, then we do not have a way to detect the retry and expire the previously generated member id. This can lead to unbounded growth in the size of the group until the rebalance has completed.This patch fixes the problem by proactively completing all JoinGroup requests for new members after a timeout of 5 minutes. If the client is still around, we expect it to retry.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Boyang Chen <bchen11@outlook.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-3680; Enable Kafka clients to run in any classloader envConfigure default classes using class objects instead of class names, enable configurable lists of classes to be specified as class objects, add tests for different classloader configurations.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>Closes #1421 from rajinisivaram/KAFKA-3680",5
KAFKA-13237; Add ActiveBrokerCount and FencedBrokerCount metrics to the ZK controller (KIP-748) (#11273)This patch adds the `ActiveBrokerCount` and the `FencedBrokerCount` metrics to the ZK controller. Note that `FencedBrokerCount` is always set to zero in the ZK controller.Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Respect the default value of partition argument in SimpleConsumerShellThe `partition` argument is not marked as required, and has a default of `0`, according to the tool's help message. However, if `partition` is not provided the command returns with `Missing required argument ""[partition]""`. This patch is to fix the required arguments of the tool by removing `partition` from them.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1495 from vahidhashemian/minor/simple_consumer_shell_update_required_args",5
"KAFKA-8927: Deprecate PartitionGrouper interface (#7376)Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
fix for scala 2.10.1 compilation issued introduced in kafka-1117,0
MINOR: Update copyright year in the NOTICE file.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2460 from ewencp/minor-update-notice-year,5
KAFKA-5091; ReassignPartitionsCommand should protect against empty replica list assignmentReassignPartitionsCommand should protect against empty replica list assignment.Author: amethystic <huxi_2b@hotmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2904 from amethystic/kafka-5901_ReassignPartitionsCommand_protect_against_empty_replica_list,5
"MINOR: Optimize KTable-KTable join value getter supplier (#4458)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <mjsax@apache.org>",1
"MINOR: Fix partition loading checks in GroupCoordinator (#4788)In the group coordinator, we currently check whether the partition is owned before checking whether it is loading. Since loading is a prerequisite for partition ownership, it means that it is not actually possible to see the COORDINATOR_LOAD_IN_PROGRESS error. The impact is mostly harmless: while loading the group, the client may send unnecessary FindCoordinator requests to rediscover the coordinator. I've fixed the bug and restructured the code to enable testing.In the process of fixing this bug, the following improvements have been made:1. We now verify valid groupId in all request handlers.2. Currently if the coordinator is loading when a SyncGroup is received, we'll return NOT_COORDINATOR. I've changed this to return REBALANCE_IN_PROGRESS since the rebalance state will have been lost on coordinator failover. This effectively forces the consumer to rejoin the group, which seems preferable over unnecessarily rediscovering the coordinator. 3. I added a check for the COORDINATOR_LOAD_IN_PROGRESS handler in SyncGroup. Although we do not currently return this error, it seems reasonable that we might want to some day, so it seems better to get the check in now.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINOR: a small refactor for LogManage#shutdown (#9680)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
MINOR Moved tiered storage API classes from clients module to a new storage-api wmodule. (#10489)Moved tiered storage API classes from clients module to a new storage-api module.Created storage and storage-api modules. All the remote storage API classes are moved to storage-api module. All the remote storage implementation classes will be added to storage module.Reviewers: Jun Rao <junrao@gmail.com>,1
KAFKA-574 KafkaController unnecessarily reads leaderAndIsr info from ZK ; patched by Prashanth; reviewed by Jun and Nehagit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1409618 13f79535-47bb-0310-9956-ffa450edef68,5
MINOR: Add `fetchTopicMetadataFromZk` overload that takes `SecurityProtocol` parameterijumaAuthor: dan norwood <norwood@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1713 from norwood/add-security-protocol-option-for-fetch,1
"KAFKA-8584: The RPC code generator should support ByteBuffer. (#7342)The RPC code generator should support using the ByteBuffer class in addition to byte arrays. By using the ByteBuffer class, we can avoid performing a copy in many situations. Also modify TestByteBufferDataTest to test the new feature.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-6657: Add StreamsConfig prefix for different consumers (#4805)This pull request is for JIRA 6657, for KIP-276.Added unit tests for new getGlobalConsumerConfigs API and make sure existing restore consumer tests are passing.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
minor stylish fixes to raft client (#10809)Style fixes to KafkaRaftClientReviewers: Luke Chen <showuon@gmail.com>,0
"KAFKA-6696 Trogdor should support destroying tasks (#4759)Implement destroying tasks and workers.  This means erasing all record of them on the Coordinator and the Agent.Workers should be identified by unique 64-bit worker IDs, rather than by the names of the tasks they are implementing.  This ensures that when a task is destroyed and re-created with the same task ID, the old workers will be not be treated as part of the new task instance.Fix some return results from RPCs.  In some cases RPCs were returning values that were never used.  Attempting to re-create the same task ID with different arguments should fail.  Add RequestConflictException to represent HTTP error code 409 (CONFLICT) for this scenario.If only one worker in a task stops, don't stop all the other workers for that task, unless the worker that stopped had an error.Reviewers: Anna Povzner <anna@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Fix some java docs of ReplicaStateMachine (#8552)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-4062: Make --print-data-log implicit if --offsets-decoder is enabled for DumpLogSegmentsset print-data-log option when offset-decoder is set.  hachikuji we had talked about this one before, does this change look ok to you?Author: Dustin Cote <dustin@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1797 from cotedm/KAFKA-4062",5
KAFKA-6707: The default value for config of Type.LONG should be *L (#4762)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-7945: Calc refresh time correctly when token created in the past (#6288)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-3809: Auto-generate documentation for topic-level configurationijuma said that it would make sense to split out this work from KAFKA-3234, since KAFKA-3234 had both a mechanical change (generating docs) as well as a change requiring discussion (deprecating/renaming config options).jjkoshy, I hope you don't mind that I took over this work. It's been 3 months since the last activity on KAFKA-3234, so I thought it would be okay to take over.This work is essentially is the first 5-6 commits from Joel's https://github.com/apache/kafka/pull/907. However, since I'm not very experienced with git, I didn't do a direct merge/rebase, but instead largely hand-merged it. I did some minor cleanup. All credit goes to Joel, all blame goes to me. :)For reference, I attached the auto-generated configuration.html file (as a PDF, because github won't let me attache html).[configuration.pdf](https://github.com/apache/kafka/files/323901/configuration.pdf)This is my first time writing Scala, so let me know if there are any changes needed.I don't know who is the right person to review this. ijuma, can you help me redirect this to the appropriate person? Thanks.Author: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1527 from wushujames/generate_topic_docs",2
"MINOR: Remove redundant metric reset in KafkaController (#12158)The following variables in `KafkaController` are used for metrics：```    offlinePartitionCount     preferredReplicaImbalanceCount    globalTopicCount     globalPartitionCount    topicsToDeleteCount     replicasToDeleteCount     ineligibleTopicsToDeleteCount     ineligibleReplicasToDeleteCount ```When the controller goes from active to non-active, these variables will be reset to 0. Currently, this is done explicitly in in `KafkaController.onControllerResignation()` and also after every loop iteration in `KafkaController.updateMetrics()` .The first of these is redundant and can be removed. This patch fixes this and also simplifies `updateMetrics`. Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-10401; Ensure `currentStateTimeStamp` is set correctly by group coordinator (#9202)Fix the `currentStateTimeStamp` doesn't get set in `GROUP_METADATA_VALUE_SCHEMA_V3`, and did a small refactor to use the `GROUP_VALUE_SCHEMAS.size - 1` replace the default hard-coded max version number. Also add test for it.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-13546: Do not fail connector validation if default topic creation group is explicitly specified (#11615)Reviewers: Chris Egerton <fearthecellos@gmail.com>,1
KAFKA-2799: skip wakeup in the follow-up poll() call.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason GustafsonCloses #490 from guozhangwang/K2799,5
"MINOR: Include partition when logging fetch errors (#6206)This helps narrow down the specific broker they came from when debuggingACL propagation issues.Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Ismael Juma <ismael@juma.me.uk>",0
"MINOR: system test clean up (#7552)Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>,",5
KAFKA-10444: Configure PR builds via Jenkinsfile (#9238),2
"KAFKA-3412: multiple asynchronous commits causes send failuresAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1108 from hachikuji/KAFKA-3412",5
kafka-1453 (2nd follow-up); Add a channel queue jmx in Mirror Maker;  patched by Guozhang Wang; reviewed by Jun Rao,1
"MINOR: Improve group metadata unknown key version exception message (#7006)The patch clarifies the exception message for unknown key versions when loading from the group metadata topic. The patch also makes a trivial change in `KafkaAdminClient` to use `Map.computeIfAbsent`. Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Improve doc for num.x.threads configsAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2847 from edoardocomar/MINOR-server.prop.threads.comments",2
kafka-1304; unregistered mbean exception in new producer; reviewed by Jay Kreps,1
KAFKA-3674: Ensure connector target state changes propagated to workerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1341 from hachikuji/KAFKA-3674,5
trivial doc fix to add link to Quotas,2
MINOR: reduce garbage in operation and resource java conversions (#8391)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
KAFKA-12249: Add client-side Decommission Broker RPC (KIP-500) (#9996)Reviewers: Jason Gustafson <jason@confluent.io>,5
HOTFIX: Fix broken javadoc links on web docs(#4543)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-4648: Improve test coverage StreamTaskProvide test coverage for exception paths in: `schedule()`, `closeTopology()`, and `punctuate()`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2451 from dguy/kafka-4640",2
KAFKA-10570; Rename JMXReporter configs for KIP-629* rename whitelist/blacklist to include/exclude* add utility methods to translate deprecated configsAuthor: Xavier Léauté <xvrl@apache.org>Reviewers: Gwen ShapiraCloses #9367 from xvrl/kafka-10570,5
MINOR: Use mock time in DefaultStateUpdaterTest (#12344)For most tests we would need an auto-ticking mock timer to work with draining-with-timeout functions.For tests that check for never checkpoint we need no auto-ticking timer to control exactly how much time elapsed.Reviewers: Bruno Cadonna <cadonna@apache.org>,1
"KAFKA-5154: do not set rejoinNeeded in joinGroup response but in syncGroup response handlerScenario is as follows:1. Consumer subscribes to topic t1 and begins consuming2. heartbeat fails as the group is rebalancing3. ConsumerCoordinator.onJoinGroupPrepare is called   3.1 onPartitionsRevoked is called4. consumer becomes the group leader5. sends sync group request6. sync group is cancelled due to disconnection7. fetch request is sent for partitions that have previously been revokedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3181 from dguy/kafka-5154",5
"KAFKA-10460: ReplicaListValidator format checking is incomplete (#9326)Co-authored-by: akumar <akumar@cloudera.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",5
KAFKA-6568: Minor clean-ups follow-up (#4592)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-2482: Allow sink tasks to get their current assignment, as well as pause and resume topic partitions.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #249 from ewencp/kafka-2482-sink-tasks-pause-consumption",1
KAFKA-10174: Prefer --bootstrap-server for configs command in ducker tests (#8948)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
kafka-1301; system testcase_0206 fails using the new producer; patched by Jun Rao; reviewed by Jay Kreps,1
Kafka server access log does not log request details coming from a MultiProduceRequest; KAFKA-115; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160527 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-3088; Make client-id a nullable string and fix handling of invalid requests.""…ent ID- Adds  NULLABLE_STRING Type to the protocol- Changes client_id in the REQUEST_HEADER to NULLABLE_STRING with a default of """"- Fixes server handling of invalid ApiKey request and other invalid requestsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>Closes #866 from granthenke/null-clientid",0
LogManager test fails on linux; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-220git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1298426 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-7026; Sticky Assignor Partition Assignment Improvement (KIP-341) (#5291)This patch contains the implementation of KIP-341, which adds protection in the sticky assignor from consumers which are joining with a stale assignment. More details can be found in the proposal: https://cwiki.apache.org/confluence/display/KAFKA/KIP-341%3A+Update+Sticky+Assignor%27s+User+Data+Protocol.Reviewers: Steven Aerts <steven.aerts@gmail.com>, Jason Gustafson <jason@confluent.io>",5
HOTFIX: fix group coordinator edge cases around metadata storage callbackAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #451 from hachikuji/hotfix-group-coordinator,0
"KAFKA-12467: Implement QuorumController snapshot generation (#10366)Implement controller-side snapshot generation.Implement QuorumController snapshotgeneration.  Note that this PR does not handle KRaft integration, just the internal snapshot record generation and consumption logic.Reading a snapshot is relatively straightforward.  When the  QuorumControllerstarts up, it loads the most recent snapshot.  This is just a series of recordsthat we replay, plus a log offset (""snapshot epoch"") that we advance to.Writing a snapshot is more complex.  There are several components:the SnapshotWriter which persists the snapshot, the SnapshotGeneratorwhich manages writing each batch of records, and the SnapshotGeneratorManagerwhich interfaces the preceding two classes with the event queue.Controller snapshots are done incrementally.  In order to avoid blocking thecontroller thread for a long time, we pull a few record batches at a time fromour record batch iterators.  These iterators are implemented by controllermanager classes such as ReplicationControlManager, ClusterControlManager, etc.Finally, this PR adds ControllerTestUtils#deepSortRecords andControllerTestUtils#assertBatchIteratorContains, which make it easier to writeunit tests.  Since records are often constructed from unsorted data structures,it is often useful to sort them before comparing them.Reviewers: David Arthur <mumrah@gmail.com>",1
KAFKA-1948; Fix ConsumerTest.testPartitionReassignmentCallback handling issue; reviewed by Gwen Shapira,0
"MINOR: Bump version of grgit to 4.1.1 (#11561)grgit 4.1.0 caused unsupported version error during gradle builds.The reason was that grgit 4.1.0 uses always the latest JGit versioninternally. Unfortunately, the latest JGit version was compiled witha Java version later than Java 8 which caused the unsupported versionerror during gradle builds for Java 8.grgit 4.1.1 fixed this issue by upper bounding the version of JGritto a version that is still compiled with Java 8. Consequently, we canremove the hotfix we merged in commit d1e0d2b474b0bdb0b0141b6d341ce77dd331a8d4and instead bump the grgit version from 4.1.0 to 4.1.1.Reviewer: John Roesler <vvcephei@apache.org>",5
"KAFKA-2718: Prevent temp directory being reused in parallel test runsUse Files.createTempDirectory to avoid reuse, for log directories create a new temp directory as parentAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma, Guozhang WangCloses #583 from rajinisivaram/KAFKA-2718-v2",5
KAFKA-1770; clarify descriptive comments of UnknownTopicOrPartitionException; reviewed by Guozhang Wang,5
kafka-2232; make MockProducer generic; patched by Alexander Pakulov; reviewed by Jun Rao,1
"KAFKA-7149 : Reducing streams assignment data size  (#7185)* Leader instance uses dictionary encoding on the wire to send topic partitions* Topic names (most expensive component) are mapped to an integer using the dictionary* Follower instances receive the dictionary, decode topic names back* Purely an on-the-wire optimization, no in-memory structures changed* Test case added for version 5 AssignmentInfoReviewers: Guozhang Wang <wangguoz@gmail.com>",5
kafka-2164; ReplicaFetcherThread: suspicious log message on reset offset; patched by Alexey Ozeritski; reviewed by Jun Rao,1
"KAFKA-4194; Follow-up improvements/testing for ListOffsets v1 (KIP-79)Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1897 from becketqin/KAFKA-4194",5
MINOR: Fix side-effecting nullary methods warning in JsonValueTest (#5493)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-3279: Remove checks for JAAS system propertyJAAS configuration may be set using other methods and hence the check for System property doesn't  always match where the actual configuration used by Kafka is loaded from.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>, Flavio Junqueira <fpj@apache.org>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #967 from rajinisivaram/KAFKA-3279",5
"MINOR: Add attributes `processedKeys` and `processedValues` to MockProcessorSupplier (#3999)Author: Mats Julian OlsenReviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6728: Corrected the worker’s instantiation of the HeaderConverter## Summary of the problemWhen the `header.converter` is not specified in the worker config or the connector config, a bug in the `Plugins` test causes it to never instantiate the `HeaderConverter` instance, even though there is a default value.This is a problem as soon as the connector deals with headers, either in records created by a source connector or in messages on the Kafka topics consumed by a sink connector. As soon as that happens, a NPE occurs.A workaround is to explicitly set the `header.converter` configuration property, but this was added in AK 1.1 and thus means that upgrading to AK 1.1 will not be backward compatible and will require this configuration change.## The ChangesThe `Plugins.newHeaderConverter` methods were always returning null if the `header.converter` configuration value was not specified in the supplied connector or worker configuration. Thus, even though the `header.converter` property has a default, it was never being used.The fix was to only check whether a `header.converter` property was specified when the connector configuration was being used, and if no such property exists in the connector configuration to return null. Then, when the worker configuration is being used, the method simply gets the `header.converter` value (or the default if no value was explicitly set).Also, the ConnectorConfig had the same default value for the `header.converter` property as the WorkerConfig, but this resulted in very confusing log messages that implied the default header converter should be used even when the worker config specified the `header.converter` value. By removing the default, the log messages now make sense, and the Worker still properly instantiates the correct header converter.Finally, updated comments and added log messages to make it more clear which converters are being used and how they are being converted.## TestingSeveral new unit tests for `Plugins.newHeaderConverter` were added to check the various behavior. Additionally, the runtime JAR with these changes was built and inserted into an AK 1.1 installation, and a source connector was manually tested with 8 different combinations of settings for the `header.converter` configuration:1. default value1. worker configuration has `header.converter` explicitly set to the default1. worker configuration has `header.converter` set to a custom `HeaderConverter` implementation in the same plugin1. worker configuration has `header.converter` set to a custom `HeaderConverter` implementation in a _different_ plugin1. connector configuration has `header.converter` explicitly set to the default1. connector configuration has `header.converter` set to a custom `HeaderConverter` implementation in the same plugin1. connector configuration has `header.converter` set to a custom `HeaderConverter` implementation in a _different_ plugin1. worker configuration has `header.converter` explicitly set to the default, and the connector configuration has `header.converter` set to a custom `HeaderConverter` implementation in a _different_ pluginThe worker created the correct `HeaderConverter` implementation with the correct configuration in all of these tests.Finally, the default configuration was used with the aforementioned custom source connector that generated records with headers, and an S3 connector that consumes the records with headers (but didn't do anything with them). This test also passed.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4815 from rhauch/kafka-6728",5
KAFKA-5856; AdminClient.createPartitions() follow up- Improve tests and javadoc (including expected exceptions)- Return correct authorization error if no describe topicpermissionAuthor: Tom Bentley <tbentley@redhat.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3937 from tombentley/KAFKA-5856-AdminClient.createPartitions-follow-up,1
KAFKA-10141; Add more detail to log segment delete messages (#8850)It is helpful to include as much information as possible when deleting log segments. This patch introduces log messages that give more specific details as to why the log segment was deleted and the specific metadata regarding that log segment.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-10038: Supports default client.id for ConsoleConsumer, ProducerPerformance, ConsumerPerformance (#11297)Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"kafka-879; In system test, read the new leader from zookeeper instead of broker log on completion of become-leader state transition; patched by John Fung; reviewed by Jun Rao",2
"KAFKA-9202: serde in ConsoleConsumer with access to headers (#7736)The Deserializer interface has two methods, one that gives access to the headers and one that does not. ConsoleConsumer.scala only calls the latter method. It would be nice if it were to call the default method that provides header access, so that custom serde that depends on headers becomes possible.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-5068; Optionally print out metrics after running the perf testsjunrao added a config `--print.metrics` to control whether ProducerPerformance prints out metrics at the end of the test. If its okay, will add the code counterpart for consumer.Author: huxi <huxi@zhenrongbao.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #2860 from amethystic/kafka-5068_print_metrics_in_perf_tests",3
"KAFKA-5856; Add AdminClient.createPartitions() (KIP-195)The contribution is my original work and I license the work to the project under the project's open source license.This patch adds AdminClient.createPartitions() and the network protocol isuses. The broker-side algorithm is as follows:1. KafkaApis makes some initial checks on the request, then delegates to the   new AdminManager.createPartitions() method.2. AdminManager.createPartitions() performs some validation then delegates to   AdminUtils.addPartitions().Aside: I felt it was safer to add the extra validation inAdminManager.createPartitions() than in AdminUtils.addPartitions() since thelatter is used on other code paths which might fail differently with theintroduction of extra checks.3. AdminUtils.addPartitions() does its own checks and adds the partitions.4. AdminManager then uses the existing topic purgatory to wait for the   PartitionInfo available from the metadata cache to become consistent with   the new total number of partitions.The messages of exceptions thrown in AdminUtils affecting this new API havebeen made consistent with initial capital letter and terminating period.A few have been reworded for clarity.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3870 from tombentley/KAFKA-5856-AdminClient.createPartitions",1
"KAFKA-5807 - Check Connector.config() and Transformation.config() returns a valid ConfigDefLittle back story on this. Was helping a user over email. This could be much easier to debug if we assume that the connector developer might not return valid configs. For example Intellij will generate a stub that returns a null. This was the case that inspired this JIRA.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3762 from jcustenborder/KAFKA-5807",5
KAFKA-4104: Queryable state metadata is sometimes invalidIf the thread or process is not the coordinator the Cluster instance in StreamPartitionAssignor will always be null. This builds an instance of the Cluster with the metadata associated with the AssignmentAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1804 from dguy/kafka-4104,5
"KAFKA-6250: Use existing Kafka Connect internal topics without requiring ACL (#4247)When using Kafka Connect with a cluster that doesn't allow the user tocreate topics (due to ACL configuration), Connect fails when trying tocreate its internal topics even if these topics already exist. This isincorrect behavior according to the documentation, which mentions thatR/W access should be enough.This happens specifically when using Aiven Kafka, which does not permitcreation of topics via the Kafka Admin Client API.The patch ignores the returned error, similar to the behavior for olderbrokers that don't support the API.",1
KAFKA-3489; Update request metrics if a client closes a connection while the broker response is in flightI also fixed a few issues in `SocketServerTest` and included a few clean-ups.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1172 from ijuma/kafka-3489-update-request-metrics-if-client-closes,5
"KAFKA-5206: Use default aggSerde if no user-overridden is provided in RocksDBSessionStoreRocksDBSessionStore wasn't properly using the default aggSerde if no Serde was supplied.Author: Kyle Winkelman <kyle.winkelman@optum.com>Reviewers: Damian Guy, Guozhang WangCloses #2971 from KyleWinkelman/RocksDBSessionStore-fix-aggSerde-use",5
MINOR: increase request timeout for streams bounce testIncrease `REQUEST_TIMOUT_MS` to improve a flaky system test until KIP-91 mergedAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4291 from bbejeck/MINOR_increase_request_timeout_for_streams_bounce_test,3
"KAFKA-3461: Fix typos in Kafka web documentations.This PR fixes 8 typos in HTML files of `docs` module. I wrote explicitly here since Github sometimes does not highlight the corrections on long lines correctly.- docs/api.html: compatability => compatibility- docs/connect.html: simultaneoulsy => simultaneously- docs/implementation.html: LATIEST_TIME => LATEST_TIME, nPartions => nPartitions- docs/migration.html: Decomission => Decommission- docs/ops.html: stoping => stopping, ConumserGroupCommand => ConsumerGroupCommand, youre => you'reAuthor: Dongjoon Hyun <dongjoon@apache.org>Reviewers: Ismael JumaCloses #1138 from dongjoon-hyun/KAFKA-3461",2
"KAFKA-3982: Fix processing order of some of the consumer propertiesThis PR updates processing of console consumer's input properties.For both old and new consumer, the value provided for `auto.offset.reset` indirectly through `consumer.config` or `consumer.property` arguments will now take effect.For new consumer and for `key.deserializer` and `value.deserializer` properties, the precedence order is fixed to first the value directly provided as an argument, then the value provided indirectly via `consumer.property` and then `consumer.config`, and finally a default value.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1655 from vahidhashemian/KAFKA-3982",5
The FetcherRunnable busy waits on empty fetch requests; KAFKA-117; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160952 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-4547; Avoid incorrect reset of paused partitions to the committed offsetsAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2341 from vahidhashemian/KAFKA-4547,5
MINOR: inconsistent naming for the output topic in the stream documentation (#9265)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
MINOR: Fix JDK8 compatibility issue in Snappy (#9460)See https://github.com/xerial/snappy-java/releases/tag/1.1.7.7 for more details.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"KAFKA-7459: Use thread-safe Pool for RequestMetrics.requestRateInternal (#5717)As part of KAFKA-6514, the `apiVersion` tag was added to the `RequestsPerSec`metric. A thread unsafe `HashMap` was used in the implementation even thoughit can be accessed by multiple threads. Fix it by replacing it with the thread-safe`Pool`.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-8344; Fix vagrant-up.sh to work with AWS properlyFor now, `vagrant/vagrant-up.sh --aws` fails becausethe `vagrant hostmanager` command in that script lacksthe `--aws` option. This PR adds it.I ran `vagrant/vagrant-up.sh --aws` with and without`--no-parallel` option and confirmed both workedas expected.Author: Kengo Seki <sekikn@apache.org>Reviewers: Gwen ShapiraCloses #6703 from sekikn/KAFKA-8344",1
KAFKA-13982: Move WorkerConfigTransformerTest to use Mockito (#12422),1
"MINOR: add support for kafka 2.4 and 2.5 to downgrade testThe downgrade test does not currently support 2.4 and 2.5. When you enable them, it fails as a result of consumer group static membership. This PR makes the downgrade test work with all of our released versions again.Author: Lucas Bradstreet <lucas@confluent.io>Reviewers: Boyang Chen, Gwen ShapiraCloses #8518 from lbradstreet/downgrade-test-2.4-2.5",3
MINOR: Fixed broken links in the documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2010 from vahidhashemian/doc/fix_hyperlinks,2
"KAFKA-7832: Use automatic RPC generation in CreateTopics (#5972)Reviewers: Jun Rao <junrao@gmail.com>, Tom Bentley <tbentley@redhat.com>, Boyang Chen <bchen11@outlook.com>",1
kafka-1397; delete topic is not working; patched by Timothy Chen; reviewed by Neha Narkhede and Jun Rao,1
"KAFKA-8880: Add overloaded function of Consumer.committed (#7304)1. Add the overloaded functions.2. Update the code in Streams to use the batch API for better latency (this applies to both active StreamsTask for initialize the offsets, as well as the StandbyTasks for updating offset limits).3. Also update all unit test to replace the deprecated APIs.Reviewers: Christopher Pettitt <cpettitt@confluent.io>, Kamal Chandraprakash  <kamal.chandraprakash@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Remove unused code from BrokerEndPoint (#12368)Removes unused methods from `BrokerEndPoint`:* `createBrokerEndPoint(Int, String)`* `readFrom(buffer: ByteBuffer)`* `connectionString(): String`* `writeTo(buffer: ByteBuffer)`* `sizeInBytes: Int`Reviewers: dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Move `ConsoleProducerTest` to the unit test directoryIncluded a couple of clean-ups: removed unused variable and the instantiated `KafkaProducer` is now closed.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #1470 from ijuma/move-console-producer-test-to-unit-folder",3
"MINOR: more logs for empty assignment (#8397)We find that brokers may send empty assignment for some members unexpectedly, and would need more logs investigating this issue.Reviewers: John Roesler <vvcephei@apache.org>",0
"HOT_FIX: Update javadoc since imports added (#8817)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-13315: log layer exception during shutdown that caused an unclean shutdown (#11351)This also fixes KAFKA-13070.We have seen a problem caused by shutting down the scheduler before shutting down LogManager.When LogManager was closing partitions one by one, the scheduler called to delete old segments due to retention. However, the old segments could have been closed by the LogManager, which caused an exception and subsequently marked logdir as offline. As a result, the broker didn't flush the remaining partitions and didn't write the clean shutdown marker. Ultimately the broker took hours to recover the log during restart.This PR essentially reverts #10538Reviewers: Ismael Juma <ismael@juma.me.uk>, Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
MINOR: Ensure that selection key is cancelled on closeAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1368 from rajinisivaram/minor-channelclose,5
"KAFKA-13068: Rename Log to UnifiedLog (#11154)In this PR, I've renamed kafka.log.Log to kafka.log.UnifiedLog. With the advent of KIP-405, going forward the existing Log class would present a unified view of local and tiered log segments, so we rename it to UnifiedLog. The motivation for this PR is also the same as outlined in this design document: https://docs.google.com/document/d/1dQJL4MCwqQJSPmZkVmVzshFZKuFy_bCPtubav4wBfHQ/edit.This PR is a follow-up to #10280 where we had refactored the Log layer introducing a new kafka.log.LocalLog class.Note: the Log class name had to be hardcoded to ensure metrics are defined under the Log class (for backwards compatibility). Please refer to the newly introduced UnifiedLog.metricName() method.Reviewers: Cong Ding <cong@ccding.com>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2
"KAFKA-5816; add Produced class, KStream#to(topic, Produced), and KStream#through(topic, Produced)Add the `Produced` class and `KStream` overloads that use it:`KStream#to(String, Produced)``KStream#through(String, Produced)`Deprecate all other to and through methods accept the single param methods that take a topic paramAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3770 from dguy/kafka-5652-produced",5
KAFKA-3020; Ensure CheckStyle runs on all Java code- Adds CheckStyle to core and examples modules- Fixes any existing CheckStyle issuesAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #703 from granthenke/checkstyle-core,5
KAFKA-847 kafka appender layout does not work for kafka 0.7.1; reviewed by Neha Narkhede and Jun Rao,1
MINOR: Fix typo dev guide titlerelated to https://github.com/apache/kafka-site/pull/103Author: Joel Hamill <git config --global user.email>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4133 from joel-hamill/dev-guide-title,1
MINOR: Update test classes to use KafkaZkClient/AdminZkClient methods (#4353),1
"MINOR: Bump RocksDB version from 5.18.3 to 5.18.4 (#8284)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-13167; KRaft broker should send heartbeat immediately after starting controlled shutdown (#11177)Controlled shutdown in KRaft is signaled through a heartbeat request with the `shouldShutDown` flag set to true. When we begin controlled shutdown, we should immediately schedule the next heartbeat instead of waiting for the next periodic heartbeat. This allows the broker to shutdown more quickly.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
MINOR: revert back to 60s session timeout for static membership test (#11881)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
HOTFIX: special handling first ever triggered punctuateAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Anna Povzner <anna@confluent.io>Closes #1208 from guozhangwang/KPunctuate,5
KAFKA-13697; KRaft authorizer should support AclOperation.ALL (#11806)KRaft authorizer should support AclOperation.ALL correctly.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-4810: Make Kafka Connect SchemaBuilder more lax about checking that fields are unsethttps://issues.apache.org/jira/browse/KAFKA-4810> Currently SchemaBuilder is strict when checking that certain fields have not been set yet (e.g. version, name, doc). It just checks that the field is null. This is intended to protect the user from buggy code that overwrites a field with different values, but it's a bit too strict currently. In generic code for converting schemas (e.g. Converters) you will sometimes initialize a builder with these values (e.g. because you get a SchemaBuilder for a logical type, which sets name & version), but then have generic code for setting name & version from the source schema.Changed the validation method to not only check if a field is null but also to check if the new value that is being set is the same as the current value of the field.ewencpAuthor: Vitaly Pushkar <vitaly.pushkar@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2806 from vitaly-pushkar/KAFKA-4810-schema-builder-default-fields-validation",5
KAFKA-705 Shutting down brokers should not receive stop replica requests if controlled shutdown status is incomplete; reviewed by Neha Narkhede,5
"KAFKA-3024: Remove old patch review toolsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #705 from granthenke/review-tools-cleanup",4
MINOR: Log4j Improvements on Fetcher (#8629)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-5818; KafkaStreams state transitions not correct- need to check that state is CRATED at startup- some minor test cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3775 from mjsax/kafka-5818-kafkaStreams-state-transition",5
"KAFKA-6292; Improve FileLogInputStream batch position checks to avoid type overflow (#4928)Switch from sum operations to subtraction to avoid type casting in checks and type overflow during `FlieLogInputStream` work, especially in cases where property `log.segment.bytes` was set close to the `Integer.MAX_VALUE` and used as a `position` inside `nextBatch()` function.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Rephrase Javadoc summary for ConsumerRecordThe original Javadoc description for `ConsumerRecord` is slightly confusing in that it can be read in a way such that an object is a key value pair received from Kafka, but (only) consists of the metadata associated with the record. This PR makes it clearer that the metadata is _included_ with the record, and moves the comma so that the phrase ""topic name and partition number"" in the sentence is more closely associated with the phrase ""from which the record is being received"".Author: LoneRifle <LoneRifle@users.noreply.github.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2290 from LoneRifle/patch-1",5
"KAFKA-2274: verifiable consumer and integration testingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang, Geoff AndersonCloses #465 from hachikuji/KAFKA-2274",5
"KAFKA-4828: ProcessorTopologyTestDriver does not work when using throughThis resolves the following issues in the ProcessorTopologyTestDriver:- It should not create an internal changelog topic when using `through()` and `table()`- It should forward the produced record back into the topology if it is to a source topicJira ticket: https://issues.apache.org/jira/browse/KAFKA-4828The contribution is my original work and I license the work to the project under the project's open source license.Author: Hamidreza Afzali <hrafzali@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2629 from hrafzali/KAFKA-4828_ProcessorTopologyTestDriver_through",3
Add retries to release.py script (#8021),1
"MINOR: Define the term tombstone, since it's used elsewhere in the docs (#3480)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2
"KAFKA-3283; Remove beta from new consumer documentationInclude a few clean-ups (also in producer section), mention deprecation plans and reorder so that the new consumer documentation is before the old consumers.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1880 from ijuma/remove-beta-from-new-consumer-documentation",4
"KAFKA-12181; Loosen raft fetch offset validation of remote replicas (#10309)Currently the Raft leader raises an exception if there is a non-monotonic update to the fetch offset of a replica. In a situation where the replica had lost it disk state, this would prevent the replica from being able to recover. In this patch, we relax the validation to address this problem. It is worth pointing out that this validation could not be relied on to protect from data loss after a voter has lost committed state.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Boyang Chen <boyang@confluent.io>",5
KAFKA-6592: ConsoleConsumer should support WindowedSerdes (#4797)Have Console consumer support TimeWindowedDeserializer/SessionWindowedDeserializer.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-10574: Fix infinite loop in Values::parseString (#9375)Fix infinite loop in Values::parseStringAuthor: Chris Egerton <chrise@confluent.io>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-9628; Replace Produce request/response with automated protocol (#9401)This patch rewrites `ProduceRequest` and `ProduceResponse` using the generated protocols. We have also added several new benchmarks to verify no regression in performance. A summary of results is included below:### Benchmark1. loop **30** times1. calculate average#### kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput> @cluster(num_nodes=5)> @parametrize(acks=-1, topic=TOPIC_REP_THREE)- +0.3144915325 %- 28.08766667 ->  28.1715625 (mb_per_sec)> @cluster(num_nodes=5)> @matrix(acks=[1], topic=[TOPIC_REP_THREE], message_size=[100000],compression_type=[""none""], security_protocol=['PLAINTEXT'])- +4.220730323 %- 157.145 -> 163.7776667 (mb_per_sec)> @cluster(num_nodes=7)> @parametrize(acks=1, topic=TOPIC_REP_THREE, num_producers=3)- +5.996241145%- 57.64166667 -> 61.098 (mb_per_sec)> @cluster(num_nodes=5)> @parametrize(acks=1, topic=TOPIC_REP_THREE)- +0.3979572536%- 44.05833333 -> 44.23366667 (mb_per_sec)> @cluster(num_nodes=5)> @parametrize(acks=1, topic= TOPIC_REP_ONE)- +2.228235226%- 69.23266667 -> 70.77533333 (mb_per_sec)### JMH resultsIn short, most ops performance are regression since we have to convert data to protocol data. The cost is inevitable (like other request/response) before we use protocol data directly.### JMH for ProduceRequest1. construction regression:    - 281.474 -> 454.935 ns/op    - 296.000 -> 1888.000 B/op1. toErrorResponse regression:    - 41.942 -> 107.528 ns/op    - 1216.000 -> 1616.000 B/op1. toStruct improvement:    - 255.185 -> 90.728 ns/op    - 864.000 -> 304.000 B/op**BEFORE**```Benchmark                                                                        Mode  Cnt     Score    Error   UnitsProducerRequestBenchmark.constructorErrorResponse                                avgt   15    41.942 ±  0.036   ns/opProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate                 avgt   15  6409.263 ±  5.478  MB/secProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate.norm            avgt   15   296.000 ±  0.001    B/opProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space        avgt   15  6416.420 ± 76.071  MB/secProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space.norm   avgt   15   296.331 ±  3.539    B/opProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen           avgt   15     0.002 ±  0.002  MB/secProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen.norm      avgt   15    ≈ 10⁻⁴             B/opProducerRequestBenchmark.constructorErrorResponse:·gc.count                      avgt   15   698.000           countsProducerRequestBenchmark.constructorErrorResponse:·gc.time                       avgt   15   378.000               msProducerRequestBenchmark.constructorProduceRequest                               avgt   15   281.474 ±  3.286   ns/opProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate                avgt   15  3923.868 ± 46.303  MB/secProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate.norm           avgt   15  1216.000 ±  0.001    B/opProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space       avgt   15  3923.375 ± 59.568  MB/secProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space.norm  avgt   15  1215.844 ± 11.184    B/opProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen          avgt   15     0.004 ±  0.001  MB/secProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen.norm     avgt   15     0.001 ±  0.001    B/opProducerRequestBenchmark.constructorProduceRequest:·gc.count                     avgt   15   515.000           countsProducerRequestBenchmark.constructorProduceRequest:·gc.time                      avgt   15   279.000               msProducerRequestBenchmark.constructorStruct                                       avgt   15   255.185 ±  0.069   ns/opProducerRequestBenchmark.constructorStruct:·gc.alloc.rate                        avgt   15  3074.889 ±  0.823  MB/secProducerRequestBenchmark.constructorStruct:·gc.alloc.rate.norm                   avgt   15   864.000 ±  0.001    B/opProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space               avgt   15  3077.737 ± 31.537  MB/secProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm          avgt   15   864.800 ±  8.823    B/opProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                  avgt   15     0.003 ±  0.001  MB/secProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm             avgt   15     0.001 ±  0.001    B/opProducerRequestBenchmark.constructorStruct:·gc.count                             avgt   15   404.000           countsProducerRequestBenchmark.constructorStruct:·gc.time                              avgt   15   214.000               ms```**AFTER**```Benchmark                                                                        Mode  Cnt     Score    Error   UnitsProducerRequestBenchmark.constructorErrorResponse                                avgt   15   107.528 ±  0.270   ns/opProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate                 avgt   15  4864.899 ± 12.132  MB/secProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate.norm            avgt   15   576.000 ±  0.001    B/opProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space        avgt   15  4868.023 ± 61.943  MB/secProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space.norm   avgt   15   576.371 ±  7.331    B/opProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen           avgt   15     0.005 ±  0.001  MB/secProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen.norm      avgt   15     0.001 ±  0.001    B/opProducerRequestBenchmark.constructorErrorResponse:·gc.count                      avgt   15   639.000           countsProducerRequestBenchmark.constructorErrorResponse:·gc.time                       avgt   15   339.000               msProducerRequestBenchmark.constructorProduceRequest                               avgt   15   454.935 ±  0.332   ns/opProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate                avgt   15  3769.014 ±  2.767  MB/secProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate.norm           avgt   15  1888.000 ±  0.001    B/opProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space       avgt   15  3763.407 ± 31.530  MB/secProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space.norm  avgt   15  1885.190 ± 15.594    B/opProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen          avgt   15     0.004 ±  0.001  MB/secProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ±  0.001    B/opProducerRequestBenchmark.constructorProduceRequest:·gc.count                     avgt   15   494.000           countsProducerRequestBenchmark.constructorProduceRequest:·gc.time                      avgt   15   264.000               msProducerRequestBenchmark.constructorStruct                                       avgt   15    90.728 ±  0.695   ns/opProducerRequestBenchmark.constructorStruct:·gc.alloc.rate                        avgt   15  3043.140 ± 23.246  MB/secProducerRequestBenchmark.constructorStruct:·gc.alloc.rate.norm                   avgt   15   304.000 ±  0.001    B/opProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space               avgt   15  3047.251 ± 59.638  MB/secProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm          avgt   15   304.404 ±  5.034    B/opProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                  avgt   15     0.003 ±  0.001  MB/secProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm             avgt   15    ≈ 10⁻⁴             B/opProducerRequestBenchmark.constructorStruct:·gc.count                             avgt   15   400.000           countsProducerRequestBenchmark.constructorStruct:·gc.time                              avgt   15   205.000               ms```### JMH for ProduceResponse1. construction regression:    - 3.293 -> 303.226 ns/op    - 24.000 -> 1848.000 B/op1. toStruct improvement:    - 825.889 -> 311.725 ns/op    - 2208.000 -> 896.000 B/op**BEFORE**```Benchmark                                                                          Mode  Cnt     Score    Error   UnitsProducerResponseBenchmark.constructorProduceResponse                               avgt   15     3.293 ±  0.004   ns/opProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate                avgt   15  6619.731 ±  9.075  MB/secProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate.norm           avgt   15    24.000 ±  0.001    B/opProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space       avgt   15  6618.648 ±  0.153  MB/secProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space.norm  avgt   15    23.996 ±  0.033    B/opProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen          avgt   15     0.003 ±  0.002  MB/secProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen.norm     avgt   15    ≈ 10⁻⁵             B/opProducerResponseBenchmark.constructorProduceResponse:·gc.count                     avgt   15   720.000           countsProducerResponseBenchmark.constructorProduceResponse:·gc.time                      avgt   15   383.000               msProducerResponseBenchmark.constructorStruct                                        avgt   15   825.889 ±  0.638   ns/opProducerResponseBenchmark.constructorStruct:·gc.alloc.rate                         avgt   15  2428.000 ±  1.899  MB/secProducerResponseBenchmark.constructorStruct:·gc.alloc.rate.norm                    avgt   15  2208.000 ±  0.001    B/opProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space                avgt   15  2430.196 ± 55.894  MB/secProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm           avgt   15  2210.001 ± 51.009    B/opProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                   avgt   15     0.003 ±  0.001  MB/secProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm              avgt   15     0.002 ±  0.001    B/opProducerResponseBenchmark.constructorStruct:·gc.count                              avgt   15   319.000           countsProducerResponseBenchmark.constructorStruct:·gc.time                               avgt   15   166.000               ms```**AFTER**```Benchmark                                                                          Mode  Cnt     Score    Error   UnitsProducerResponseBenchmark.constructorProduceResponse                               avgt   15   303.226 ±  0.517   ns/opProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate                avgt   15  5534.940 ±  9.439  MB/secProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate.norm           avgt   15  1848.000 ±  0.001    B/opProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space       avgt   15  5534.046 ± 51.849  MB/secProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space.norm  avgt   15  1847.710 ± 18.105    B/opProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen          avgt   15     0.007 ±  0.001  MB/secProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ±  0.001    B/opProducerResponseBenchmark.constructorProduceResponse:·gc.count                     avgt   15   602.000           countsProducerResponseBenchmark.constructorProduceResponse:·gc.time                      avgt   15   318.000               msProducerResponseBenchmark.constructorStruct                                        avgt   15   311.725 ±  3.132   ns/opProducerResponseBenchmark.constructorStruct:·gc.alloc.rate                         avgt   15  2610.602 ± 25.964  MB/secProducerResponseBenchmark.constructorStruct:·gc.alloc.rate.norm                    avgt   15   896.000 ±  0.001    B/opProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space                avgt   15  2613.021 ± 42.965  MB/secProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm           avgt   15   896.824 ± 11.331    B/opProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                   avgt   15     0.003 ±  0.001  MB/secProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm              avgt   15     0.001 ±  0.001    B/opProducerResponseBenchmark.constructorStruct:·gc.count                              avgt   15   343.000           countsProducerResponseBenchmark.constructorStruct:·gc.time                               avgt   15   194.000               ms```Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6656; Config tool should return non-zero status code on failure (#4711)Prior to this patch, we caught some exceptions when executing the command, which meant that it would return with status code zero. This patch fixes this and makes the expected exit behavior explicit. Test cases have been added to verify the change.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
MINOR: Fix non-null check in the constructor of ListenerNameAuthor: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2700 from Kamal15/precondition,0
"KAFKA-5137; Controlled shutdown timeout message improvementProvide correct config details in the log message.Author: umesh chaudhary <umesh9794@gmail.com>Reviewers: Dustin Cote <dustin@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2932 from umesh9794/local",5
MINOR: Make it impossible to invoke `Request.body` without an explicit type parameterAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2579 from ijuma/safer-body,5
"KAFKA-9838; Add log concurrency test and fix minor race condition (#8476)The patch adds a new test case for validating concurrent read/write behavior in the `Log` implementation. In the process of verifying this, we found a race condition in `read`. The previous logic checks whether the start offset is equal to the end offset before collecting the high watermark. It is possible that the log is truncated in between these two conditions which could cause the high watermark to be equal to the log end offset. When this happens, `LogSegment.read` fails because it is unable to find the starting position to read from.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Allow a single struct to be a field in the protocol spec (#8413)Remove the restriction in the protocol generation code that a structurefield needs to be part of an array.Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
"MINOR: Remove redundant forwarding integration tests (#11766)There are a few integration tests for the forwarding logic which were added prior to kraft being ready for integration testing. Now that we have enabled kraft in integration tests, these tests are redundant and can be removed.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
MINOR: Cleanup in tests to avoid threads being left behindAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3146 from rajinisivaram/MINOR-test-cleanup,5
"KAFKA-10199: Further refactor task lifecycle management (#12439)1. Consolidate the task recycle procedure into a single function within the task. The current procedure now becomes: a) task.recycleStateAndConvert, at end of it the task is in closed while its stateManager is retained, and the manager type has been converted; 2) create the new task with old task's fields and the stateManager inside the creators.2. Move the task execution related metadata into the corresponding TaskExecutionMetadata class, including the task idle related metadata (e.g. successfully processed tasks); reduce the number of params needed for TaskExecutor as well as Tasks.3. Move the task execution related fields (embedded producer and consumer) and task creators out of Tasks and migrated into TaskManager. Now the Tasks is only a bookkeeping place without any task mutation logic.4. When adding tests, I realized that we should not add task to state updater right after creation, since it was not initialized yet, while state updater would validate that the task's state is already restoring / running. So I updated that logic while adding unit tests.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
KAFKA-9255: Add 'timestamp' field to 'message' entry (#7764)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
KAFKA-1282 Disconnect idle socket connection in Selector; reviewed by Neha Narkhede and Jun Rao,5
"KAFKA-10888: Sticky partition leads to uneven produce msg (#12049)The design is described in detail in KIP-794https://cwiki.apache.org/confluence/display/KAFKA/KIP-794%3A+Strictly+Uniform+Sticky+Partitioner.Implementation notes:The default partitioning logic is moved to the BuiltInPartitioner class(there is one object per topic).  The object keeps track of how manybytes are produced per-partition and once the amount exceeds batch.size,switches to the next partition (note that partition switch decision isdecoupled from batching).  The object also keeps track of probabilityweights that are based on the queue sizes (the larger the queue sizeis the less chance for the next partition to be chosen).  The queuesizes are calculated in the RecordAccumulator in the `ready` method,the method already enumerates all partitions so we just add some extralogic into the existing O(N) method.  The partition switch decision maytake O(logN), where N is the number partitions per topic, but it happensonly once per batch.size (and the logic is avoided when all queues areof equal size).  Produce bytes accounting logic is lock-free.When partitioner.availability.timeout.ms is non-0, RecordAccumulatorkeeps stats on ""node latency"" which is defined as the difference betweenthe last time the node had a batch waiting to be send and the last timethe node was ready to take a new batch.  If this difference exceedspartitioner.availability.timeout.ms we don't switch to that partitionuntil the node is ready.Reviewers: Jun Rao <junrao@gmail.com>",1
"KAFKA-12648: fix bug where thread is re-added to TopologyMetadata when shutting down (#11857)We used to call TopologyMetadata#maybeNotifyTopologyVersionWaitersAndUpdateThreadsTopologyVersion when a thread was being unregistered/shutting down, to check if any of the futures listening for topology updates had been waiting on this thread and could be completed. Prior to invoking this we make sure to remove the current thread from the TopologyMetadata's threadVersions map, but this thread is actually then re-added in the #maybeNotifyTopologyVersionWaitersAndUpdateThreadsTopologyVersion call.To fix this, we should break up this method into separate calls for each of its two distinct functions, updating the version and checking for topology update completion. When unregistering a thread, we should only invoke the latter methodReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-14144:; Compare AlterPartition LeaderAndIsr before fencing partition epoch (#12489)This PR fixes an AlterPartition regression introduced in https://github.com/apache/kafka/pull/12032When an AlterPartition request succeeds, the partition epoch gets bumped. In Zk controller mode the sender also relies on the AlterPartition response to be informed of the new partition epoch.If the sender times out the request before a response is sent, the sender will have a stale partition epoch compared to the ZK controller state and will be fenced on subsequent AlterPartition request attempts. The sender will not receive an updated partition epoch until it receives a LeaderAndIsr request for controller-initiated ISR changes.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: fix package name in integration test (#10400)Change package name of IntegrationTestUtils ,TransactionsWithMaxInFlightOneTest, ControllerContextTest and DefaultMessageFormatterTest to kafka.server since we set the package name to kafka.xxx in all other classes.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-13522: add position tracking and bounding to IQv2 (#11581)* Fill in the Position response in the IQv2 result.* Enforce PositionBound in IQv2 queries.* Update integration testing approach to leverage consistent queries.Reviewers: Patrick Stuedi <pstuedi@apache.org>, Vicky Papavasileiou <vpapavasileiou@confluent.io>, Guozhang Wang <guozhang@apache.org>",5
"KAFKA-8155: Add 2.1.1 release to system tests (#6596)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-9573: Fix VerifiableProducer and VerifiableConsumer to work with older Kafka versions (#8197)These classes are used by `upgrade_test.py` with old Kafka versions so they canonly use functionality that exists in all Kafka versions. This change fixes the testfor Kafka versions older than 0.11.0.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
KAFKA-5196; Make LogCleaner transaction-awareAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #3008 from hachikuji/KAFKA-5196,5
KAFKA-5469; Created state changelog topics not logged correctlyFixed debug logging for the created state changelog topicsAdded toString() for InternalTopicMetadata and InternalTopicConfig for above debug loggingAuthor: ppatierno <ppatierno@live.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3368 from ppatierno/kafka-5469,2
MINOR: Update consumer group describe output in the documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2409 from vahidhashemian/doc/update_consumer_group_describe_output,5
MINOR: Fix line break issue in upgrade notes (#6320)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-348 rebase branch from trunk patch by Jun Rao reviewed by Joe Steingit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1351112 13f79535-47bb-0310-9956-ffa450edef68,1
Remove redundant `containsKey` call in KafkaProducer (#8761)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-9823: Remember the sent generation for the coordinator request (#8445)For join / sync / commit / heartbeat request, we would remember the sent generation in the created handler object, and then upon getting the error code, we could check whether the sent generation still matches the current generation. If not, it means that the member has already reset its generation or has participated in a new rebalance already. This means:1. For join / sync-group request, we do not need to call reset-generation any more for illegal-generation / unknown-member. But we would still set the error since at a given time only one join/sync round-trip would be in flight, and hence we should not be participating in a new rebalance. Also for fenced instance error we still treat it as fatal since we should not be participating in a new rebalance, so this is still not expected.2. For commit request, we do not set the corresponding error for illegal-generation / unknown-member / fenced-instance but raise rebalance-in-progress. For commit-sync it would be still thrown to user, while for commit-async it would be logged and swallowed.3. For heartbeat request, we do not treat illegal-generation / unknown-member / fenced-instance errors and just consider it as succeeded since this should be a stale heartbeat which can be ignored.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Some cleanups and additional testing for KIP-88Author: Jason Gustafson <jason@confluent.io>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>Closes #2383 from hachikuji/minor-cleanup-kip-88",4
"KAFKA-4894; Fix findbugs ""default character set in use"" warningsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #2683 from cmccabe/KAFKA-4894",5
"MINOR: Tighten up locking when aborting expired transactionsThis is a followup to #4137Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #4146 from apurvam/MINOR-followups-to-bump-epoch-on-expire-patch",5
KAFKA-1560 Make arguments to jira-python API more explicit in kafka-patch-review's get_jira(); reviewed by Neha Narkhede,1
KAFKA-1818 KAFKA-1818 clean up code to more idiomatic scala usage; reviewed by Neha Narkhede and Gwen Shapira,4
"KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter (#8691)Implemented KIP-606 to add metadata context to MetricsReporter.Author: Xiaodong Du <xdu@confluent.io>Reviewers: David Arthur <mumrah@gmail.com>, Randall Hauch <rhauch@gmail.com>, Xavier Léauté <xavier@confluent.io>, Ryan Pridgeon <ryan.n.pridgeon@gmail.com>",5
"MINOR: clarify the record selection algorithm and stream-time definition (#6128)The existing javadoc for PartitionGroup is a little confusing.It's relatively important for these concepts to be clear, sincethey form the basis for stream-time in Kafka Streams.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4590; SASL/SCRAM system testsRuns sanity test and one replication test using SASL/SCRAM.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2355 from rajinisivaram/KAFKA-4590",5
MINOR: Fixes AK config typos (#7046),2
"KAFKA-14079 - Ack failed records in WorkerSourceTask when error tolerance is ALL (#12415)Make sure to ack all records where produce failed, when a connector's `errors.tolerance` config property is set to `all`. Acking is essential so that the task will continue to commit future record offsets properly and remove the records from internal tracking, preventing a memory leak.(cherry picked and slightly modified from commit 63e06aafd0cf37f8488c3830946051b3a30db2a0)Reviewers: Chris Egerton <fearthecellos@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
MINOR: Remove unused commitSync in ConsoleConsumer (#5845)Dead code is confusing.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>,5
"KAFKA-2547; Make DynamicConfigManager to use the ZkNodeChangeNotifica……tionListener introduced as part of KAFKA-2211Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Flavio Junqueira <fpj@apache.org>, Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <mail@harsha.io>Closes #679 from Parth-Brahmbhatt/KAFKA-2547 and squashes the following commits:1722c76 [Parth Brahmbhatt] Addressing review comments.376f77d [Parth Brahmbhatt] Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into KAFKA-2547a13b963 [Parth Brahmbhatt] Addressing comments from Reviewers.1007137 [Parth Brahmbhatt] KAFKA-2547: Make DynamicConfigManager to use the ZkNodeChangeNotificationListener introduced as part of KAFKA-2211",4
MINOR: Fix formatting in RelationalSmokeTest (#10639)Fixes formatting in RelationalSmokeTest.Reviewers: Leah Thomas <lthomas@confluent.io>,5
add jmx beans in broker to track # of failed requests; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-283git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1293720 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Improvements to PID snapshot managementAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2866 from hachikuji/improve-snapshot-management",1
"KAFKA-13273: Add support for Java 17 (#11296)Java 17 is at release candidate stage and it will be a LTS release onceit's out (previous LTS release was Java 11).Details:* Replace Java 16 with Java 17 in Jenkins and Readme.* Replace `--illegal-access=permit` (which was removed from Java 17)   with  `--add-opens` for the packages we require internal access to.   Filed KAFKA-13275 for updating the tests not to require `--add-opens`   (where possible).* Update `release.py` to use JDK8. and JDK 17 (instead of JDK 8 and JDK 15).* Removed all but one Streams test from `testsToExclude`. The   Connect test exclusion list remains the same.* Add notable change to upgrade.html* Upgrade to Gradle 7.2 as it's required for proper Java 17 support.* Upgrade mockito to 3.12.4 for better Java 17 support.* Adjusted `KafkaRaftClientTest` and `QuorumStateTest` not to require   private access to `jdk.internal.util.random`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"MINOR: reset state in cleanup, fixes jmx mixin flakinessewencp ijumaAuthor: Xavier Léauté <xl+github@xvrl.net>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4123 from xvrl/fix-jmx-flakiness(cherry picked from commit 91eb178e95abd71b68dd03ee25c77482087bd9bb)Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>",0
"KAFKA-13793: Add validators for configs that lack validators (#12010)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>, Chris Egerton <fearthecellos@gmail.com>, Christo Lolov <lolovc@amazon.com>, Divij Vaidya <divijvaidya13@gmail.com>",5
"MINOR: Update build.gradle and release.py to upload streams-scala_2.12 (#5368)Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",5
"Minor: Refactor methods to add metrics to sensor in `StreamsMetricsImpl` (#7161)Renames method names in StreamsMetricsImpl to make them consistent.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-330 Delete topic followup - more tests and Joel's review comments,3
KAFKA-8323: Close RocksDBStore's BloomFilter (#6672)Any RocksJava object that inherits from org.rocksdb.AbstractNativeReference must be closed explicitly in order to free up the memory of the backing C++ object. The BloomFilter extends RocksObject (which implements AbstractNativeReference) and should be also be closed in RocksDBStore#close to avoid leaking memory.Reviewers: Bill Bejeck <bbejeck@gmail.com>,5
"KAFKA-14093: Use single-worker Connect cluster when testing fenced leader recovery (#12433)Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",3
KAFKA-300 Leader election; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1303473 13f79535-47bb-0310-9956-ffa450edef68,2
KAFKA-6905: Document that Processors may be re-used by Streams (#5022)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-2721; Avoid handling duplicate LeaderAndISR requestsAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com?Closes #436 from lindong28/KAFKA-2721,5
"KAFKA-8118; Ensure ZK clients are closed in tests, fix verification (#6456)We verify that ZK clients are closed in tests since these can affect subsequent tests and that makes it hard to debug test failures. But because of changes to ZooKeeper client, we were checking the wrong thread name. The thread name used now is <creatorThreadName>-EventThread where creatorThreadName varies depending on the test. Fixed ZooKeeperTestHarness to check this format and fixed tests which were leaving ZK clients behind. Also added a test to make sure we can detect changes to the thread name when we update ZK clients in future.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
KAFKA-1997; Hopefully last follow-up fix to get messageHandlerArgs right,0
KAFKA-2121 Follow-up: minor bug fix as pointed out by Sean Lydon,0
"MINOR: Update scala default version in readme (#9260)Now, default should be 2.13.x, not 2.12.x. Update it.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Follow up for KAFKA-6761 graph should add stores for consistency (#5453)While working on 4th PR, I noticed that I had missed adding stores via the graph vs. directly via the InternalStreamsBuilder. Probably ok to do so, but we should be consistent.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"improve some logging statements (#6078)Reviewers: Matthias J. Sax <matthias@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: speed up streams integration tests... bya) merging some for startup/shutdown efficiency.b) use independent state dirs.c) remove some tests that are covered elsewhereguozhangwang ewencp - tests are running much quicker now, i.e, down to about 1 minute on my laptop (from about 2 - 3 minutes). There were some issues with state-dirs in some of the integration tests that was causing the shutdown of the streams apps to take a long time.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #1525 from dguy/integration-tests",3
"KAFKA-9770: Close underlying state store also when flush throws (#8368)When a caching state store is closed it calls its flush() method.If flush() throws an exception the underlying state store is not closed.This commit ensures that state stores underlying a wrapped state storesare closed even when preceding operations in the close method throw.Co-authored-by: John Roesler <vvcephei@apache.org>Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-7902: Replace original loginContext if SASL/OAUTHBEARER refresh login fails (#6233)Replaces original loginContext if login fails in the refresh thread to ensure that the refresh thread is left in a clean state when there are exceptions while connecting to an OAuth server. Also makes client callback handler more robust by using the token with the longest remaining time for expiry instead of throwing an exception if multiple tokens are found.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-3589: set inner serializer for ChangedSerde upon initializationAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1246 from guozhangwang/K3589",5
MINOR: equals() should compare all fields for generated classes (#8539)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-10793: move handling of FindCoordinatorFuture to fix race condition (#9671)Fixes a tricky race condition between the consumer and hb thread can lead to a failed but non-null findCoordinatorFuture, causing the AbstractCoordinator to wait endlessly on the request which it thinks is still in flight. We should move the handling of this future out of the listener callbacks and into the ensureCoordinatorReady() method where we can check the exception and clear the future all in one place.Reviewers: Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Fix potential resource leak in FileOffsetBackingStore (#4739)Reviewers: Sandor Murakozi <smurakozi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-7880:Naming worker thread by task id (#6275)KAFKA-7880: Name worker thread to include task idChange Connect's `WorkerTask` to name the thread using the `task-thread-<connectorTaskId>` pattern.Reviewers: Randall Hauch <rhauch@gmail.com>,1
auto-discovery of topics for mirroring; patched by Joel; reviewed by Jun; KAFKA-74git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156393 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-4443; Controller should send UpdateMetadataRequest prior to LeaderAndIsrRequest during failoverAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>Closes #2168 from lindong28/KAFKA-4443",0
KAFKA-999 Controlled shutdown never succeeds until the broker is killed; reviewed by Neha Narkhede,5
"MINOR: Fix incorrect expression for KTable in stream doc. (#4718)In dsi-api.html, when reading from Kafka to a KTable, the doc says ""In the case of a KStream.."" where `Kstream` here is not correct. They should be `KTable`.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-3611: Remove warnings when using reflectionsewencp granders Can you take a look? Thanks!Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1259 from Ishiihara/fix-warning,2
KAFKA-3277; Update trunk version to be 0.10.0.0-SNAPSHOTAlso update `kafka-merge-pr.py` and `tests/kafkatest/__init__.py`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #963 from ijuma/update-trunk-0.10.0.0-SNAPSHOT,5
"KAFKA-5937: Improve ProcessorStateManager exception handlingAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ted Yu <yuzhihong@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3913 from mjsax/kafka-5937-exceptions-processor-state-manager",5
"KAFKA-4932: Update docs for KIP-206 (#5769)Reviewers: Bill Bejeck <bill@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3563: Maintain MessageAndMetadata constructor compatibilityAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ashish Singh <asingh@cloudera.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1226 from granthenke/message_constructor",5
MINOR: Change the order that Connect calls `config()` and `validate()` to avoid validating if the required ConfigDef is null (#8810)Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>,5
MINOR: KIP-160 docsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3733 from guozhangwang/KMinor-kip160-docs,2
KAFKA-8531: Change default replication factor config (#10532)Implements KIP-733Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
"KAFKA-10671: improve the partition.assignment.strategy docs (#9788)Add StickyAssignor and CooperativeStickyAssignor, and also briefly introduce the RangeAssignor and RoundRobinAssignor in the docs for the partition.assignment.strategy configReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
KAFKA-1459 follow up minor patch,5
KAFKA-1179 createMessageStreams() in javaapi.ZookeeperConsumerConnector does not throw; reviewed by Neha Narkhede,1
MINOR: Upgrade RocksDB to 4.8.0Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1647 from ijuma/kafka-rocksdb-4.8,5
"MINOR: Remove sleep calls and ignore annotation from streams upgrade test (#6046)The StreamsUpgradeTest::test_upgrade_downgrade_brokers used sleep calls in the test which led to flaky test performance and as a result, we placed an @ignore annotation on the test. This PR uses log events instead of the sleep calls hence we can now remove the @ignore setting.Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-1240; Add ability to existing system tests to use the new producer client; patched by Jun Rao; reviewed by Neha Narkhede,1
"KAFKA-4539: StreamThread is not correctly creating StandbyTasksTasks that don't have any `StateStore`s wont have a `StandbyTask`, so `createStandbyTask` can return `null`. We need to check for this in `StandbyTaskCreator.createTask(...)`Also, the checkpointed offsets for `StandbyTask`s are never loaded.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2255 from dguy/kafka-4539",5
MINOR: Update year in NOTICE (#11670)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-5437; Always send a sig_kill when cleaning the message copierWhen the message copier hangs (like when there is a bug in the client), it ignores the sigterm and doesn't shut down. this leaves the cluster in an unclean state causing future tests to fail.In this patch we always send SIGKILL when cleaning the node if the process isn't already dead. This is consistent with the other services.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3308 from apurvam/KAFKA-5437-force-kill-message-copier-on-cleanup",4
KAFKA-2653: Add KStream/KTable Aggregation and KTable Join APIsping ymatsuda for reviews.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #730 from guozhangwang/K2653r,1
MINOR: Add Scalafmt to Streams Scala API (#4965)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-13587; Implement leader recovery for KIP-704 (#11733)Implementation of the protocol for starting and stopping leader recovery after an unclean leader election. This includes the management of state in the controllers (legacy and KRaft) and propagating this information to the brokers. This change doesn't implement log recovery after an unclean leader election.Protocol Changes================For the topic partition state znode, the new field ""leader_recovery_state"" was added. If the field is missing the value is assumed to be RECOVERED.ALTER_PARTITION was renamed from ALTER_ISR. The CurrentIsrVersion field was renamed to PartitionEpoch. The new field LeaderRecoveryState was added.The new field LeaderRecoverState was added to the LEADER_AND_ISR request. The inter broker protocol version is used to determine which version to send to the brokers.A new tagged field for LeaderRecoveryState was added to both the PartitionRecord and PartitionChangeRecord.Controller==========For both the KRaft and legacy controller the LeaderRecoveryState is set to RECOVERING, if the leader was elected out of the ISR, also known as unclean leader election. The controller sets the state back to RECOVERED after receiving an ALTER_PARTITION request with version 0, or with version 1 and with the LeaderRecoveryState set to RECOVERED.Both controllers preserve the leader recovery state even if the unclean leader goes offline and comes back online before an RECOVERED ALTER_PARTITION is sent.The controllers reply with INVALID_REQUEST if the ALTER_PARTITION either:    1. Attempts to increase the ISR while the partition is still RECOVERING    2. Attempts to change the leader recovery state to RECOVERING from a RECOVERED state.Topic Partition Leader======================The topic partition leader doesn't implement any log recovery in this change. The topic partition leader immediately marks the partition as RECOVERED and sends that state in the next ALTER_PARTITION request.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Refactor TopologyBuilder with ApplicationID PrefixAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1736 from guozhangwang/Kminor-topology-applicationID",2
MINOR: Add try/finally blocks to close adminclient in DelegationTokenEndToEndAuthorizationTest (#5861),3
"MINOR: In-memory stores cleanup (#6595)While going through the review of InMemorySessionStore I realized there is also some minor cleanup to be done for the other in-memory stores. This includes trivial changes such as removing unnecessary references to 'this' and moving collection initialization to the declaration. It also fixes some unsafe behavior (registering an iterator from inside its own constructor). In-memory window store iterator classes were made static and some instances of KeyValueIterator missing types were fixed across a handful of tests.Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-10014; Always try to close all channels in Selector#close (#8685)Ensure all channels get closed in `Selector.close`, even if some of them raise errors.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-221 LICENSE and NOTICE problems in Kafka 0.7; patched by jakobhoman; reviewed by junrao and nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1214904 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12655 Update Jetty: 9.4.38.v20210224 → 9.4.39.v20210325 (#10526)Reviewers: Edwin <edwinhobor@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Luke Chen, xjin-Confluent, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: Verify acls for group resource on all servers of test cluster.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #1540 from SinghAsDev/MinorAclTestCheck",3
"KAFKA-5438; Fix UnsupportedOperationException in WriteTxnMarkersRequestBefore this patch, the `partitionErrors` was an immutable map. As a result if a single producer had a marker for multiple partitions, and if there were multiple response callbacks for a single append, we would get an `UnsupportedOperationException` in the `writeTxnMarker` handler.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3313 from apurvam/KAFKA-5438-fix-unsupportedoperationexception-in-writetxnmarker",0
"MINOR: Increase Throttle lower bound assertion in throttling_testImproves the reliability of this test by decreasing the lower bound (this is to be expected as throttling  takes the first fetch to stabilise and will ""over-fetch"" for this first request)Author: Ben Stopford <benstopford@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2698 from benstopford/throttling-test-fix",3
KAFKA-6452; Add documentation for delegation token authenticationAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #4490 from omkreddy/KAFKA-6452-TOKEN-DOCS,2
"KAFKA-6307: Fix KafkaMbean leak in JmxReporter (#4307)We should remove the map entry from mbeans if it becomesempty during metric removal.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Satish Duggana <satish.duggana@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-9705 part 1: add KIP-590 request header fields (#9144)Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Jacot <david.jacot@gmail.com>",1
"MINOR: Less restrictive assertion in flaky BufferPool test (#5799)Decrease the lower bound for expected available memory, as threadscheduling entails that a variable amount of deallocation happens bythe point of assertion.Also make minor clarifications to test logic and comments.The passing rate improved from 98% to 100% locally after thesechanges (100+ runs).Reviewers: Ismael Juma <ismael@juma.me.uk>### Committer Checklist (excluded from commit message)- [ ] Verify design and implementation - [ ] Verify test coverage and CI build status- [ ] Verify documentation (including upgrade notes)",2
"MINOR: Update code to not use deprecated methods (#6434)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Colin P. McCabe <cmccabe@confluent.io>",5
"KAFKA-8474; Use HTML lists for config layout (#6870)Replace the `<table>` elements by `<ul>` so the full page width can be used for the configuration descriptions instead of only a very narrow column. I moved the other fields (Type, Default Value, etc) below each entry.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13775: CVE-2020-36518 - Upgrade jackson-databind to 2.12.6.1 (#11962)CVE-2020-36518 vulnerability affects jackson-databind (see GHSA-57j2-w4cx-62h2).Upgrading to jackson-databind version 2.12.6.1 addresses this CVE.Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Reduce logging level for controller connection failures from `error` to `warn`Before we switched from `BlockingChannel` to `NetworkClient`, we werealways reporting a successful connection due to the fact that`BlockingChannel.connect` catches and swallows all exceptions. Weare now reporting failures (which is better), but `error` seems toonoisy (as can be seen in our tests).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #280 from ijuma/reduce-connection-failure-logging-level",2
"KAFKA-12648: fix flaky #shouldAddToEmptyInitialTopologyRemoveResetOffsetsThenAddSameNamedTopologyWithRepartitioning (#11868)This test has started to become flaky at a relatively low, but consistently reproducible, rate. Upon inspection, we find this is due to IOExceptions during the #cleanUpNamedTopology call -- specifically, most often a DirectoryNotEmptyException with an ocasional FileNotFoundExceptionBasically, signs pointed to having returned from/completed the #removeNamedTopology future prematurely, and moving on to try and clear out the topology's state directory while there was a streamthread somewhere that was continuing to process/close its tasks.I believe this is due to updating the thread's topology version before we perform the actual topology update, in this case specifically the act of eg clearing out a directory. If one thread updates its version and then goes to perform the topology removal/cleanup when the second thread finishes its own topology removal, this other thread will check whether all threads are on the latest version and complete any waiting futures if so -- which means it can complete the future before the first thread has actually completed the corresponding actionReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-13899: Use INVALID_CONFIG error code consistently in AlterConfig APIs (#12162)In the AlterConfigs/IncrementalAlterConfigs zk handler, we return `INVALID_REQUEST` and `INVALID_CONFIG` inconsistently. The problem is in `LogConfig.validate`. We may either return `ConfigException` or `InvalidConfigException`. When the first of these is thrown, we catch it and convert to `INVALID_REQUEST`. If the latter is thrown, then we return `INVALID_CONFIG`. It seems more appropriate to return `INVALID_CONFIG` consistently, which is what the KRaft implementation already does this. This patch fixes this and converts a few integration tests to KRaft.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-8753; Expose controller topic deletion metrics (KIP-503) (#7156)This is the implementation for [KIP-503](https://cwiki.apache.org/confluence/display/KAFKA/KIP-503%3A+Add+metric+for+number+of+topics+marked+for+deletion)When deleting a large number of topics, the Controller can get quite bogged down. One problem with this is the lack of visibility into the progress of the Controller. We can look into the ZK path for topics marked for deletion, but in a production environment this is inconvenient. This PR adds a JMX metric `kafka.controller:type=KafkaController,name=TopicsToDeleteCount` to make it easier to see how many topics are being deleted.Reviewers: Stanislav Kozlovski <stanislav@confluent.io>, Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Do not use optional args in `ProducerStateManager` (#11734)We allowed `maxProducerIdExpirationMs` and `time` to be optional in the `ProducerStateManager` constructor. We generally frown on optional arguments since it is too easy to overlook them. In this case, it was especially dangerous because the recently added `maxTransactionTimeoutMs` argument used the same type as `maxProducerIdExpirationMs`.Reviewers: David Jacot <david.jacot@gmail.com, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-2757; Consolidate BrokerEndPoint and EndPointAuthor: zhuchen1018 <amandazhu19620701@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #911 from zhuchen1018/KAFKA-2757",5
"MINOR: Move streams-examples source files under src folderAlso remove some unused imports.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #992 from guozhangwang/KSExamples",5
"MINOR: Update jetty, jackson, gradle and jacoco (#4547)* MINOR: Update gradle, jackson and jacoco- Gradle update adds support for Java 10- Jacoco update adds support for Java 9- Jackson bug fix update adds more serializationrobustness checks* Update JettyReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6288: Broken symlink interrupts scanning of the plugin pathSubmitting a fail safe fix for rare IOExceptions on symbolic links.The fix is submitted without a test case since it does seem easy to reproduce such type of failures (just having a broken symbolic link does not reproduce the issue) and it's considered pretty low risk.If accepted, needs to be ported at least to 1.0, if not 0.11Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4481 from kkonstantine/KAFKA-6288-Broken-symlink-interrupts-scanning-the-plugin-path",5
KAFKA-2776: Fix lookup of schema conversion cache size in JsonConverter.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #458 from ewencp/kafka-2776-json-converter-cache-config-fix,5
MINOR: Tweak implementation of `FetchRequest.shuffle` and upgrade.html improvementsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1955 from ijuma/kip-74-follow-up,5
kafka-813; Minor cleanup in Controller; patched by Swapnil Ghike; reviewed by Neha Narkhede and Jun Rao,4
KAFKA-2437; Fix ZookeeperLeaderElector to handle node deletion correctly.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>Closes #189 from becketqin/KAFKA-2437,4
"MINOR: add serde configs to properly set serdes in failing StreamsStaticMembershipTest (#11093)After changing the default serde to be null, some system tests started failing. This test didn't explicitly pass in a serde and didn't set the default config so when the test was trying to setup the source node it wasn't able to find any config to use and threw a config exception. Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@confluent.io>",5
MINOR: Upgrade to gradle 6.7 (#9440)This release includes a key fix:* Zinc leaks its dependencies to user classpath (https://github.com/gradle/gradle/issues/14168)Release notes:https://docs.gradle.org/6.7/release-notes.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
MINOR: add Yahoo benchmark to nightly runsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3289 from enothereska/yahoo-benchmark,1
KAFKA-728 snappy jar missing from path in kafka-run-class.sh patch by John Fung reviewed by Joe Stein,1
"MINOR: Small enhancement to Deserializer JavadocI’ve implemented my own custom Deserializer and been using it with `KStream.reduceByKey`; I observed that `reduceByKey` was passing null to my implementation, but it wasn’t clear to me what my implementation was expected to do in this case. So this attempts to clarify it.This is my original work and I license this work to the Kafka project under Kafka’s open source license (the Apache License 2.0).Author: Avi Flax <avi@aviflax.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1503 from aviflax/patch-1(cherry picked from commit 6b1a6d9551fc44d80c7cffc0b4c21427da9d8fda)Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>",5
"KAFKA-7481; Add upgrade/downgrade notes for 2.1.xWe seemed to be missing the usual rolling upgrade instructions so I've added them and emphasized the impact for downgrades after bumping the inter-broker protocol version.Author: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #5857 from hachikuji/KAFKA-7481",5
"KAFKA-5218; New Short serializer, deserializer, serdeAuthor: Mario Molina <mmolimar@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3017 from mmolimar/KAFKA-5218",5
KAFKA-2825: Add controller failover to existing replication testsAuthor: Anna Povzner <anna@confluent.io>Reviewers: Geoff AndersonCloses #618 from apovzner/kafka_2825_01,5
"Kafka-3880: Disallow Join Window with size zeroAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Damian Guy, Eno Thereska, Guozhang WangCloses #1529 from mjsax/kafka-3880-join-windows",5
max.message.size and fetch.size defaults should be consistent; patched by Pierre-Yves Ritschard; reviewed by Jun Rao; KAFKA-247git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1232500 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-3250: release tarball is unnecessarily large due to duplicate l……ibrariesThis ensures duplicates are not copied in the distribution without rewriting all of the tar'ing logic. A larger improvement could be made to the packaging code, but that should be tracked by another jira.Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #1075 from granthenke/libs-duplicates",1
KAFKA-1515 Producer can hang during metadata updates. Patch by Guozhang.,5
"KAFKA-8104: Consumer cannot rejoin to the group after rebalancing (#7460)This PR contains the fix of race condition bug between ""consumer thread"" and ""consumer coordinator heartbeat thread"". It reproduces in many production environments.Condition for reproducing:1. Consumer thread initiates rejoin to the group because of commit timeout. Call of AbstractCoordinator#joinGroupIfNeeded which leads to sendJoinGroupRequest.2. JoinGroupResponseHandler writes to the AbstractCoordinator.this.generation new generation data and leaves the synchronized section.3. Heartbeat thread executes mabeLeaveGroup and clears generation data via resetGenerationOnLeaveGroup.4. Consumer thread executes onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment); with the cleared generation data. This leads to the corresponding exception.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Improve description of `cleanup.policy`  (#12086)Clarifies description of `cleanup.policy`, in particular for the case when both ""delete"" and ""compact"" are specified.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5610; WriteTxnMarker handler should return UNKNOWN_TOPIC_OR_PARTITION if replica is not availableBefore this patch, we would instead return the non-retriable `UNSUPPORTED_FOR_MESSAGE_FORMAT` causing markers to be lost.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3550 from apurvam/KAFKA-5610-handleWriteTxnMarker-should-handle-emigration",0
"KAFKA-2369: Add REST API for Copycat.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen Shapira, James ChengCloses #378 from ewencp/kafka-2369-copycat-rest-api",1
"MINOR: Improve log4j for per-consumer assignment (#8997)Add log4j entry summarizing the assignment (previous owned and assigned) at the consumer level.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-13461: Don't re-initialize ZK client session after auth failure if connection still alive (#11563)If JAAS configuration does not contain a Client section for ZK clients, an auth failure event is generated. If this occurs after the connection is setup in the controller, we schedule reinitialize(), which causes controller to resign. In the case where SASL is not mandatory and the connection is alive, controller maintains the current session and doesn't register its watchers, leaving it in a bad state.Reviewers: Jun Rao <junrao@gmail.com>",5
HOTFIX: missing imports and version on web docs,2
"KAFKA-9893: Configurable TCP connection timeout and improve the initial metadata fetch (KIP-601) (#8683)Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-7128; Follower has to catch up to offset within current leader epoch to join ISR (#5557)If follower is not in ISR, it has to fetch up to start offset of the current leader epoch. Otherwise we risk losing committed data. Added unit test to verify this behavior.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: fix parameter naming (#6316)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Merge remote branch 'origin/0.8' into trunk,1
MINOR: Increment ducktape dependencyPin kafka system tests to a newer version of ducktape.Ran in branch builder; only one preexisting (transient) failure:http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2016-02-01--001.1454333721--confluentinc--increment-ducktape-dependency--a40f474/report.htmlAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #852 from granders/increment-ducktape-dependency,5
"MINOR: Use debug level logging for noisy log messages in Connect (#8918)Author: Cyrus Vafadari <cyrus@confluent.io>Reviewers: Chris Egerton <chrise@confluent.io>, Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-10098: Remove unnecessary escaping in regular expression. (#8798)'<' or '>' do not need to be escaped.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Andrew Choi <andrew.choi@uwaterloo.ca>, Jakob Homan",4
KAFKA-2009 Fix two minor bugs in mirror maker.,1
"KAFKA-3661; fix NPE in o.a.k.c.c.RoundRobinAssignor when topic metadata not foundAbstractPartitionAssignor.assign has an ambiguous line in its documentation:> param partitionsPerTopic The number of partitions for each subscribed topic (may be empty for some topics)Does empty mean the topic has an entry with value zero, or that the entry is excluded from the map altogether? The current implementation in AbstractPartitionAssignor excludes the entry from partitionsPerTopic if the topic isn't in the metadata.RoundRobinAssignorTest.testOneConsumerNonexistentTopic interprets emptiness as providing the topic with a zero value.RangeAssignor interprets emptiness as excluding the entry from the map.RangeAssignorTest.testOneConsumerNonexistentTopic interprets emptiness as providing the topic with a zero value.This implementation chooses to solve the NPE by deciding to exclude topics from partitionsPerTopic when the topic is not in the metadata.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1326 from onurkaraman/KAFKA-3661",5
MINOR: Remove the extra brackets in the demo code (#9586)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
KAFKA-4837: Fix class name comparison in connector-plugins REST endpointAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2798 from kkonstantine/KAFKA-4837-Config-validation-in-Connector-plugins-need-to-compare-against-both-canonical-and-simple-class-names,5
"MINOR: Remove unused `AdminUtils.fetchTopicMetadataFromZk` methodsThese are internal methods with no tests and since we now have an `AdminClient`,we should remove them.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3299 from ijuma/remove-unused-admin-utils-methods",4
"KAFKA-13945: add bytes/records consumed and produced metrics (#12235)Implementation of KIP-846: Source/sink node metrics for Consumed/Produced throughput in StreamsAdds the following INFO topic-level metrics for the total bytes/records consumed and produced:    bytes-consumed-total    records-consumed-total    bytes-produced-total    records-produced-totalReviewers: Kvicii <Karonazaba@gmail.com>, Guozhang Wang <guozhang@apache.org>, Bruno Cadonna <cadonna@apache.org>",1
"HOTFIX: Cherrypicking state deadlock fix from 0.11Cherrypicking additional changes made as part of this PR https://github.com/apache/kafka/pull/3622, back to trunk.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3691 from enothereska/hotfix-deadlock-state",0
"KAFKA-13036: Replace EasyMock and PowerMock with Mockito for RocksDBMetricsRecorderTest (#12459)Changes:- Migrate to Mockito- Add more assertive checks using verify- Minor indentation fixesReviewers: Dalibor Plavcic <dalibor.os@proton.me>, Bruno Cadonna <cadonna@apache.org>",1
upgrade zkclient jar; #KAFKA-82git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1154064 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-9956: Authorizer APIs may be invoked more than once for a given request (#8643)* Fix describeConfigs and alterConfigs not to invoke authorizer morethan once* Add tests to KafkaApisTest to verify the fixes* Rename `filterAuthorized` to `filterByAuthorized`* Tweak `filterByAuthorized` to take resources instead of resourcenames and improve implementation* Introduce `partitionMapByAuthorized` and `partitionSeqByAuthorized`and simplify code by using it* Replace List with Seq in some AdminManager methods* Remove stray `println` in `KafkaApisTest`Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
KAFKA-4644: Improve test coverage of StreamsPartitionAssignorSome exception paths not previously covered. Extracted `ensureCopartitioning` into a static class.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2448 from dguy/KAFKA-4644,4
"fix the broken links of streams javadoc (#8789)There are some broken links of streams javadoc, for example:ReadOnlyKeyValueStoreReadOnlyWindowStoreOnly javadoc is update.Reviewers: Bill Bejeck <bbejeck@apache.org>",5
"KAFKA-4508; System test that runs client against older versions of the brokerIn reality, we’ll only test older brokers after KAFKA-4462 is fully implemented.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2263 from cmccabe/KAFKA-4508",5
KAFKA-10437: Update WordCount examples to use new PAPI (#10701)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Clarify misleading comment in WordCount exampleAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2400 from gwenshap/wordcount-comment",5
"KAFKA-13457: SocketChannel in Acceptor#accept is not closed upon IOException (#11504)This patch ensures that SocketChannel in Acceptor#accept is closed if an IOException is thrown while the socket is configured.Reviewers:  Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
KAFKA-1133 LICENSE and NOTICE files need to get into META-INF when jars are built before they're signed for publishing to maven reviewed by Joel Koshy,5
"MINOR: Update dropwizard library to 4.1.12.1 (#10982)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Luke Chen <showuon@gmail.com>",4
MINOR: apply Utils.isBlank to code base (#10124)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
MINOR: Support dynamic JAAS config for broker's LoginManager cache (#4568)Fix LoginManager caching when sasl.jaas.config is defined for broker and add unit tests.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-2944: Replaced the NPE with a nicer error and clean exit and added debug message to assist with figuring this out.…ssage to assist with figuring this out.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #993 from gwenshap/KAFKA-2944,5
"KAFKA-7799; Fix flaky test RestServerTest.testCORSEnabled (#6106)The test always fails if testOptionsDoesNotIncludeWadlOutput is executed before testCORSEnabled. It seems the problem is the use of the system property. Perhaps there is some static caching somewhere.Reviewers: Randall Hauch <rhauch@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-2981: Fix javadoc in KafkaConsumerhttps://issues.apache.org/jira/browse/KAFKA-2981Author: Xin Wang <best.wangxin@163.com>Reviewers: Guozhang WangCloses #668 from vesense/patch-2,0
"KAFKA-12964: Collect and rename snapshot files prior to async deletion. (#10896)Segment and index files are currently renamed with a .deletedsuffix prior to async deletion. This serves two purposes, toresume deletion on broker failure and also protect againstdeletion of new segments during truncation (due to deletionbeing async).We should do the same for snapshot files. While they are not subjectto issues around resuming deletion due to the stray snapshotscanning which is performed on log initialization, we can end upwith situations where truncation queues snapshots for deletion, butprior to deletion new segments with the same snapshot file name arecreated. Async deletion can then delete these new snapshots.This patch offers a two-stage snapshot deletion which first renamesand removes the segments in question from the ProducerStateManager,allowing the Log to asynchronously delete them.Credit to Kowshik Prakasam <kowshik@gmail.com> for finding this issueand creating the test demonstrating the failure.Co-authored-by: Kowshik Prakasam <kowshik@gmail.com> Address PR feedbackReviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"BUGFIX: Add missing recording of close of stand-by task (#6663)Adds recording of close of a stand-by task to the task-closed metricAdds unit tests to verify the recordingReviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",5
"KAFKA-8457; Move `Log' reference from `Replica` into `Partition` (#6841)A `Partition` object contain one or many `Replica` objects. These replicaobjects in turn can have the ""log"" if the replica corresponds to thelocal node. All the code in Partition or ReplicaManager peek intoreplica object to fetch the log if they need to operate on that. Asreplica object can represent a local replica or a remote one, thislead to a bunch of ""if-else"" code in log fetch and offset update code.NOTE: In addition to a ""log"" that is in use during normal operation, ifan alter log directory command is issued, we also create a future logobject. This object catches up with local log and then we switch the logdirectory. So temporarily a Partition can have two local logs. Beforethis change both logs are inside replica objects.This change is an attempt to untangle this relationship. In particularit moves `Log` from `Replica` into `Partition`. So a partition containsa local log to which all writes go and possibly a ""future log"" if the partition is being moved between directories. Additionally, it maintainsa list of remote replicas for offset and ""caught up time"" data that it usesfor replication protocol. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10366 & KAFKA-9649: Implement KIP-659 to allow TimeWindowedDeserializer and TimeWindowedSerde to handle window size (#9253)See KIP details and discussions here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-659%3A+Improve+TimeWindowedDeserializer+and+TimeWindowedSerde+to+handle+window+sizeDeprecates methods that allow users to skip setting a window size when one is needed. Adds a window size streams config to allow the timeWindowedDeserializer to calculate window end time.Reviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Fix comment in DistributedHerderewencpAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1243 from Ishiihara/docs,2
"MINOR: update processor topology test driverAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3828 from bbejeck/MINOR_update_processor_topology_test_driver",5
"KAFKA-2347: Add setConsumerRebalanceListener method to ZookeeperConsumerConnector java api; reviewed by Jiangjie Qin, Ismael Juma, Grant Henke and Guozhang Wang",1
MINOR: Update site docs for ASF compliance (#12494)This PR is a mirror of apache/kafka-site#433 which used placeholder images for the Kafka Streams that users need to click in order to load the iframe with the corresponding video.Reviewers: Mickael Maison <mimaison@apache.org>,1
"KAFKA-4372: Kafka Connect REST API does not handle DELETE of connector with slashes in their namesKafka Connect REST API does not handle in many places connectors with slashes in their names because it expects PathParams, this PR intends to :* Reject as bad requests API calls trying to create connectors with slashes in their names* Add support for connector with slashes in their names in the DELETE part of the API to allow users to cleanup their connectors without dropping everything.This PR adds as well the Unit Test needed for the creation part and was tested manually for the DELETE part.Author: Olivier Girardot <o.girardot@lateral-thoughts.com>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2096 from ogirardot/fix/connectors-with-slashes-cannot-be-deleted",4
MINOR: use jdk8 to build/run system tests (#4925)Debian installer packages are no longer available for Java 7.Also upgrade AMI to latest ubuntu/trusty 14 amd64 as the olderone is no longer available.Note that this only changes the JDK used to build and runthe system tests. We still have Jenkins jobs that compileand run the JUnit tests with Java 7 so that we don't usefeatures that are only available in newer Java versions.,1
KAFKA-1442 RBTools post-review is deprecated; reviewed by Neha Narkhede,1
"MINOR: Updated SASL Authentication Sequence Docs (#4724)Reworded the SASL Authentication sequence to update it to >= 1.0.0Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>, Mickael Maison <mickael.maison@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"Kafka-6693: Added consumer workload to Trogdor (#4775)Added consumer only workload to Trogdor. The topics must already be pre-populated. The spec lets the user request topic pattern and range of partitions to assign to [startPartition, endPartition].Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-7051: Improve the efficiency of ReplicaManager (#5206)Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>",1
KAFKA-3922: add constructor to AbstractStream classhttps://issues.apache.org/jira/browse/KAFKA-3922KAFKA-3922 add copy-constructor to AbstractStream classThis copy-constructor allow to access protected variables from subclasses.It should be used to extend KStreamImpl and KTableImpl classes by implementing a decorator pattern.Author: Florian Hussonnois <florian.hussonnois@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1581 from fhussonnois/KAFKA-3922,1
Minor: fix javadocs of StreamsConfig and ValueTransformerWithKey (#5157)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-9634: Add note about thread safety in the ConfigProvider interface (#8205)In Kafka Connect, a ConfigProvider instance can be used concurrently (e.g. via a PUT request to the `/connector-plugins/{connectorType}/config/validate` REST endpoint), but there is no mention of concurrent usage in the Javadocs of the ConfigProvider interface. It's worth calling out that implementations need to be thread safe.Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-8557: system tests - add support for (optional) interbroker listener with the same security protocol as client listeners (#6938)Reviewers: Brian Bushree <bbushree@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-3739: Add no-arg constructor for WindowedSerdes in StreamsAdd default constructor for library provided serdesAuthor: huxi <huxi@zhenrongbao.com>Author: amethystic <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2308 from amethystic/kafka3739_add_noarg_constructor_for_streaming_serdes,1
"HOTFIX: safely clear all active state in onPartitionsLost (#7691)After a number of last minute bugs were found stemming from the incremental closing of lost tasks in StreamsRebalanceListener#onPartitionsLost, a safer approach to this edge case seems warranted. We initially wanted to be as ""future-proof"" as possible, and avoid baking further protocol assumptions into the code that may be broken as the protocol evolves. This meant that rather than simply closing all active tasks and clearing all associated state in #onPartitionsLost(lostPartitions) we would loop through the lostPartitions/lost tasks and remove them one by one from the various data structures/assignments, then verify that everything was empty in the end. This verification in particular has caused us significant trouble, as it turns out to be nontrivial to determine what should in fact be empty, and if so whether it is also being correctly updated.Therefore, before worrying about it being ""future-proof"" it seems we should make sure it is ""present-day-proof"" and implement this callback in the safest possible way, by blindly clearing and closing all active task state. We log all the relevant state (at debug level) before clearing it, so we can at least tell from the logs whether/which emptiness checks were being violated.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Andrew Choi <andchoi@linkedin.com>",2
"KAFKA-4829: Improve log4j on Streams thread / task-levelThese are the following improvements I made:1. On stream thread level, INFO will be demonstrating `Completed xx tasks in yy ms` or `Completed rebalance with xx state in yy ms`,2. On Stream thread cache level, INFO on `Flushed xx records`.3. On Stream thread level, DEBUG on internal batched operations like `created xx tasks`, and TRACE on individual operation like `created x task`.4. Also using `isTraceEnabled` on the critical path to reduce overhead of creating `Object[]`.5. Minor cleanups in the code.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Steven Schlansker, Nicolas Fouché, Kamal C, Ismael Juma, Bill Bejeck, Eno Thereska, Matthias J. Sax, Damian GuyCloses #3354 from guozhangwang/K4829-tasks-log4j",2
"KAFKA-3872; Reduce log cleaner buffer size to 2 MBAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1533 from enothereska/KAFKA-3872-oom-integration-tests",3
KAFKA-1425; Expose metric for LogStartOffset; reviewed by Joel Koshy and Jun Rao,2
"MINOR: Log successful/failed authentications with socket information (#5856)Use `info` for failed authentications and `debug` for successful ones.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-2791; removed deprecated propertiesRemoved support for BLOCK_ON_BUFFER_FULL_CONFIG (block.on.buffer.full)Removed support for METADATA_FETCH_TIMEOUT_CONFIGRemoved support for TIMEOUT_CONFIG (aka timeout.ms)Added support for MAX_BLOCK_MS_CONFIGAdded support for REQUEST_TIMEOUT_MS_CONFIGAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #525 from benstopford/KAFKA-2791,5
Fix commit() in zk consumer for compressed messages; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-546git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1406940 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-13987: Isolate REST request timeout changes in Connect integration tests (#12291)This causes the artificial reductions in the Connect REST request timeout to be more isolated. Specifically, they now only take place in the tests that need them (instead of any tests that happen to be running after the reduction has taken place and before it has been reset), and they are only performed for the requests that are expected to time out, before being immediately reset. This should help reduce spurious test failures (especially in slow environments like Jenkins) for all Connect integration tests that interact with the REST API, not just the BlockingConnectorTest test suite.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
MINOR: Update protocol doc link in Introduction.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #1211 from SinghAsDev/MinorFixDocLink,2
KAFKA-9706: Handle null in keys or values when Flatten transformation is used (#8279)* Fixed DataException thrown when handling tombstone events with null value* Passes through original record when finding a null key when it's configured for keys or a null value when it's configured for values. * Added unit tests for schema and schemaless data,5
KAFKA-2903; FileRecords.read doesn't handle size > sizeInBytes when start is not zeroAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4158 from ijuma/kafka-2903-file-records-read-slice-size-greater,2
"KAFKA-14055; Txn markers should not be removed by matching records in the offset map (#12390)When cleaning a topic with transactional data, if the keys used in the user data happen to conflict with the keys in the transaction markers, it is possible for the markers to get removed before the corresponding data from the transaction is removed. This results in a hanging transaction or the loss of the transaction's atomicity since it would effectively get bundled into the next transaction in the log. Currently control records are excluded when building the offset map, but not when doing the cleaning. This patch fixes the problem by checking for control batches in the `shouldRetainRecord` callback.Reviewers: Jun Rao <junrao@gmail.com>",0
KAFKA-3676: system tests for connector pause/resumeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1345 from hachikuji/KAFKA-3676,5
"KAFKA-12940: Enable JDK 16 builds in Jenkins (#10702)JDK 15 no longer receives updates, so we want to switch from JDK 15 to JDK 16.However, we have a number of tests that don't yet pass with JDK 16.Instead of replacing JDK 15 with JDK 16, we have both for now and we eitherdisable (via annotations) or exclude (via gradle) the tests that don't pass withJDK 16 yet. The annotations approach is better, but it doesn't work for teststhat rely on the PowerMock JUnit 4 runner.Also add `--illegal-access=permit` when building with JDK 16 to make MiniKdcwork for now. This has been removed in JDK 17, so we'll have to figure outanother solution when we migrate to that.Relevant JIRAs for the disabled tests: KAFKA-12790, KAFKA-12941, KAFKA-12942.Moved some assertions from `testTlsDefaults` to `testUnsupportedTlsVersion`since the former claims to test the success case while the former tests the failure case.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",0
"MINOR: Updated Quickstart to mention log.dirs (#5361)The default server.properties file now contains the log.dirs setting and not log.dir anymore.Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Katherine Farmer <kfarme3@uk.ibm.com>Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Sriharsha Chintalapani <sriharsha@apache.org>",2
"MINOR: Eliminate unnecessary Topic(And)Partition allocations in Controller- Eliminated all the unnecessary allocations of `TopicPartition` and`TopicAndPartition` in the Controller. We now use the formerin the Controller (bringing it inline with the rest of the non legacycode).- Fixed missed `Listener` -> `Handler` renames for companionobjects.- More String.format -> String interpolation conversions (the formeris roughly 5 times more expensive).- Some other minor clean-ups.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Onur Karaman <okaraman@linkedin.com>, Viktor Somogyi <viktorsomogyi@gmail.com>Closes #4152 from ijuma/controller-topic-partition-and-other-clean-ups",4
"HOTFIX: Fix recent protocol breakage from KIP-345 and KIP-392 (#6780)KIP-345 and KIP-392 introduced a couple breaking changes for old versions of bumped protocols. This patch fixes them.Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Boyang Chen <bchen11@outlook.com>, Guozhang Wang <wangguoz@gmail.com>",5
trival fix to make run_sanity.sh executablegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396693 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: need to cleanup any tasks closed in TaskManager (#8463)We were hitting an IllegalStateException: There is already a changelog registered for ... in trunk-eos due to failing to call TaskManager#cleanup on unrevoekd tasks that we end up closing in handleAssignment after failing to batch commit.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"MINOR: Avoid logging connector configuration in Connect framework (#5868)Some connector configs may be sensitive, so we should avoid logging them.Reviewers: Alex Diachenko, Dustin Cote <dustin@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5806; Fix transient unit test failure in trogdor coordinator shutdownIn the coordinator, we should check that 'shutdown' is not true before going to sleep waiting for the condition.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3755 from cmccabe/KAFKA-5806",5
"KAFKA-4594; Annotate integration tests and provide gradle build targets to run subsets of testsThis uses JUnit Categories to identify integration tests. Adds 2 new build targets:`integrationTest` and `unitTest`.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska <eno@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2695 from dguy/junit-categories",3
"KAFKA-5901: Added Connect metrics specific to source tasks (KIP-196)Added Connect metrics specific to source tasks, and builds upon #3864 and #3911 that have already been merged into `trunk`.Author: Randall Hauch <rhauch@gmail.com>Reviewers: tedyu <yuzhihong@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3959 from rhauch/kafka-5901",5
"MINOR: Added scripts to automate Vagrant setup for system testsUpdated testing README accordingly.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #201 from granders/minor-vagrant-package-script",5
KAFKA-12879: Remove extra sleep (#11872),4
KAFKA-992 Double Check on Broker Registration to Avoid False NodeExist Exception; reviewed by Neha Narkhede and Swapnil Ghike,5
MINOR: follow up on Streams EOS system tests (#4593),3
"KAFKA-8964: Rename tag client-id for thread-level metrics and below (#7429)* Renamed tag client-id to thread-id for thread-level metrics and below* Corrected metrics tag keys for state store that had suffix ""-id"" instead of ""state-id""Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4866; Console consumer `print.value` property is ignoredThis property is mentioned in the quickstart.Author: huxi <huxi@zhenrongbao.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2661 from amethystic/kafka4866_consoleconsumer_ignore_printvalue,5
MINOR: Add test to ensure log metrics are removed after deletion (#7750)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Ensure in-memory metadata is removed before physical deletion of segment (#7106)Minor refactoring of the places where we delete log segments, to ensure we always remove the in-memory metadata of the segment before performing physical deletion.Reviewers: Ismael Juma <ismael@juma.me.uk>, NIkhil Bhatia <rite2nikhil@gmail.com>, Jun Rao <junrao@gmail.com>",4
MINOR: Add unit tests for PluginDesc in Connect.Related to https://github.com/apache/kafka/pull/3321Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3326 from kkonstantine/MINOR-Add-tests-for-PluginDesc,3
"KAFKA-5980: FailOnInvalidTimestamp does not log errorAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Ted Yu <yuzhihong@gmail.com>, Denis BolshakovCloses #3966 from mjsax/kafka-5980-FailOnInvalidTimestamp-does-not-log-error",2
"KAFKA-3659: Handle coordinator disconnects more gracefully in clientAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1322 from hachikuji/KAFKA-3659",5
"KAFKA-7918: Inline generic parameters Pt. I: in-memory key-value store (#6293)First PR in series to inline the generic parameters of the following bytes stores:[x] InMemoryKeyValueStore[ ] RocksDBWindowStore[ ] RocksDBSessionStore[ ] MemoryLRUCache[ ] MemoryNavigableLRUCache[ ] (awaiting merge) InMemoryWindowStoreA number of tests took advantage of the generic InMemoryKeyValueStore and had to be reworked somewhat -- this PR covers everything related to the in-memory key-value store.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
Php Client support for compression attribute; patched by AaronR; KAFKA-159git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1185774 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-5098; KafkaProducer should reject sends to invalid topics…egal char and generates InvalidTopicExceptionIf config parameter max.block.ms config parameter is set to a non-zero value,KafkaProducer.send() blocks for the max.block.ms time if topic name has illegalchar or is invalid.Wrote a unit test that verifies the appropriate exception is returned whenperforming a get on the returned future by KafkaProducer.send().Author: Ahmed Al Mehdi <aalmehdi@aalmehdi-ld1.linkedin.biz>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy@gmail.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>Closes #5247 from ahmedha/KAFKA-5098",2
Expose JMX operation to set logger level dynamically (0.8 branch); patched by Jun Rao; reviewed by Jay Kreps; KAFKA-429git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377175 13f79535-47bb-0310-9956-ffa450edef68,2
KAFKA-2773: Fixed broken vagrant provision scripts for static zk/broker clusterAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-PostavaCloses #454 from granders/KAFKA-2773-vagrant-fix,0
"Kafka-2992: Guard trace statements in the inner loop of the replica fetcherWe're seeing some GC pause issues in production, and during our investigation found that the thunks created during invocation of three trace statements guarded in this PR were responsible for ~98% of all allocations by object count and ~90% by size. While I'm not sure that this was actually the cause of our issue, it seems prudent to avoid useless allocations in a tight loop.I realize that the trace() call does its own guarding internally, however it's insufficient to prevent allocation of the thunk.This is my original work, and I license it to the Kafka project under the project's Apache license.Author: Cory Kolbeck <cory.kolbeck@urbanairship.com>Reviewers: Gwen ShapiraCloses #682 from ckolbeck/guard-trace-statements",1
KAFKA-12934: Move some controller classes to the metadata package (#10865)Move some controller classes to the metadata package so that they can beused with broker snapshots. Rename ControllerTestUtils toRecordTestUtils. Create LeaderConstants and PartitionRegistration.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-9258 Check Connect Metrics non-null in task stop (#7768)Remove nullcheck, and add integration tests for restarting a failed task.Authors: Cyrus Vafadari <cyrus@confluent.io>, Chris Egerton <chrise@confluent.io>Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-7487: DumpLogSegments misreports offset mismatches (#5756)- Compare last offset of first batch (instead of first offset) with index offset- Early exit from loop due to zero entries must happen before checking for mismatch- {TimeIndex,OffsetIndex}.entry should return absolute offset like other methods.These methods are only used by DumpLogSegments.- DumpLogSegments now calls `closeHandlers` on OffsetIndex, TimeIndexand FileRecords.- Add OffsetIndex, TimeIndex and DumpLogSegments tests- Remove unnecessary casts by using covariant returns in OffsetIndex and TimeIndex- Minor clean-ups- Fix `checkArgs` so that it does what it says only.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Sriharsha Chintalapani <sriharsha@apache.org>",0
"MINOR: KIP-307 upgrade guide docs (#7547)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-7693; Fix SequenceNumber overflow in producer (#5989)The problem is that the sequence number is an Int and should wrap around when it reaches the Int.MaxValue. The bug here is it doesn't wrap around and become negative and raises an error.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Remove unused `Json.legacyEncodeAsString` (#8726)Updated a couple of test usages not to rely on it and removedthe tests for the removed method.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
"MINOR: Fix typo in ReplicaVerificationTool outputAuthor: Andrew Otto <acotto@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #101 from ottomata/trunk and squashes the following commits:10b76f3 [Andrew Otto] MINOR - Fix typo in ReplicaVerificationTool output",2
KAFKA-3290: fix transient test failures in WorkerSourceTaskTestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #998 from hachikuji/KAFKA-3290,5
"KAFKA-12851: Fix Raft partition simulation (#11134)Instead of waiting for a high-watermark of 20 after the partition, thetest should wait for the high-watermark to reach an offset greater thanthe largest log end offset at the time of the partition. Only that offsetis guarantee to be reached as the high-watermark by the new majority.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6058: KIP-222; Add Consumer Group operations to Admin APIKIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-222+-+Add+Consumer+Group+operations+to+Admin+APIAuthor: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>Author: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Guozhang Wang <wangguoz@gmail.com>Closes #4454 from jeqo/feature/admin-client-describe-consumer-group",5
kafka-1035; Add message-send-max-retries and retry-backoff-ms options to console producer; patched by Rajasekar Elango; reviewed by Guaozhang Wang and Jun Rao,1
"MINOR: Fix minikdc cleanup in system tests (#5471)The original way of stopping the minikdc process sometimes misfires because the process arg string is very long, and `ps` is not able to find the correct process. Using the `kill_java_processes` method is more reliable for finding and killing java processes.",1
KAFKA-4129; Processor throw exception when getting channel remote address after closing the channelGet channel remote address before calling ```channel.close```Author: Tao Xiao <xiaotao183@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1826 from xiaotao183/KAFKA-4129,1
KAFKA-13221; Implement `PartitionsWithLateTransactionsCount` metric (#11725)This patch implements a new metric `PartitionsWithLateTransactionsCount` which tracks the number of partitions with late transactions in the cluster. This metric was documented in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-10003: Mark KStream.through() as deprecated and update Scala API (#8679) - part of KIP-221Co-authored-by: John Roesler <john@confluent.io>,5
"MINOR: Disable JmxTool in kafkatest console-consumer by default (#7785)Do not initialize `JmxTool` by default when running console consumer. In order to support this, we remove `has_partitions_assigned` and its only usage in an assertion inside `ProduceConsumeValidateTest`, which did not seem to contribute much to the validation.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6164; Shutdown quota managers if other components fail to startAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4181 from rajinisivaram/KAFKA-6164",5
"KAFKA-6397: Consumer should not block setting positions of unavailable partitions (#4557)Prior to this patch, the consumer always blocks in poll() if there are any partitions which are awaiting their initial positions. This behavior was inconsistent with normal fetch behavior since we allow fetching on available partitions even if one or more of the assigned partitions becomes unavailable _after_ initial offset lookup. With this patch, the consumer will do offset resets asynchronously, which allows other partitions to make progress even if the initial positions for some partitions cannot be found.I have added several new unit tests in `FetcherTest` and `KafkaConsumerTest` to verify the new behavior. One minor compatibility implication worth mentioning is apparent from the change I made in `DynamicBrokerReconfigurationTest`. Previously it was possible to assume that all partitions had a fetch position after `poll()` completed with a non-empty assignment. This assumption is no longer generally true, but you can force the positions to be updated using the `position()` API which still blocks indefinitely until a position is available.Note that this this patch also removes the logic to cache committed offsets in `SubscriptionState` since it was no longer needed (the consumer's `committed()` API always does an offset lookup anyway). In addition to avoiding the complexity of maintaining the cache, this avoids wasteful offset lookups to refresh the cache when `commitAsync()` is used.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-9297: CreateTopics API does not work with older version of the request/response (#7829)The create topic api do not work with older version of the api. It can be reproduced by trying to create a topic with kafka-topics.sh from 2.3. It timeouts.b94c7f4 has added a check which raises an exception if a field has been set to a non-default value unless the field is marked as ""ignorable"".The fields added in the version 5 of the response are always set regardless of the version used by the client. If an older version is used, an exception is thrown during the serialization because the fields have non-default values. We should either not set the fields for older versions in the api layer or mark them as ignorable. I have chosen the later in this case because it looks cleaner.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",5
Add missing metrics in 0.8; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-604,1
"HOTFIX: Fix null pointer when getting metric value in MetricsReporter (#11248)The alive stream threads metric relies on the threads field as a monitor object forits synchronized block. When the alive stream threads metric is registered it isn'tinitialised so any call to get the metric value before it is initialised will resultin a null pointer exception.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-5893; Preserve original System.out in PrintedTestAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #3893 from mjsax/kafka-5893-reset-integration-test",3
"KAFKA-8325; Remove batch from in-flight requests on MESSAGE_TOO_LARGE errors (#7176)This patch fixes a bug in the handling of MESSAGE_TOO_LARGE errors. The large batch is split, the smaller batches are re-added to the accumulator, and the batch is deallocated, but it was not removed from the list of in-flight batches. When the batch was eventually expired from the in-flight batches, the producer would try to deallocate it a second time, causing an error. This patch changes the behavior to correctly remove the batch from the list of in-flight requests.Reviewers: Luke Stephenson, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12171: Migrate streams:test-utils module to JUnit 5 (#9856)* replace `org.junit.Assert` by `org.junit.jupiter.api.Assertions`* replace `org.junit` by `org.junit.jupiter.api`* replace `org.junit.runners.Parameterized` by `org.junit.jupiter.params.ParameterizedTest`* replace `org.junit.runners.Parameterized.Parameters` by `org.junit.jupiter.params.provider.{Arguments, MethodSource}`* replace `Before` by `BeforeEach`* replace `After` by `AfterEach`Reviewers: Ismael Juma <ismael@juma.me.uk>",3
KAFKA-7859: Use automatic RPC generation in LeaveGroups (#6188)Reviewed-by: Colin P. McCabe <cmccabe@apache.org>,1
"MINOR: fix documentation versionThis will need to be double-committed.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1107 from gwenshap/fix-doc-version",2
"KAFKA-4262; Increase data volume in replication testTo prevent test from completing without throttling before config change takes effect, produce more messages in the test.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ben Stopford <benstopford@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1982 from rajinisivaram/KAFKA-4262",5
"KAFKA-2468: SIGINT during Kafka server startup can leave server deadlockedAs we handle exceptions or invalid states in Kafka server by shutting it down, there is no reason to use exit() and not halt() in shutdown itself.Author: asingh <asingh@cloudera.com>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #167 from SinghAsDev/KAFKA-2468",1
MINOR: Improve logging for alter log dirs (#6302)This patch adds several new log messages to provide more information about errors during log dir movement and to make it clear when each partition movement is finished. Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-5042: InFlightRequests#isEmpty() always returns falseAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #2823 from ijuma/kafka-5042-fix-inflight-requests-is-empty,5
"KAFKA-4300: NamedCache throws an NPE when evict is called and the cache is emptyIf evict is called on a NamedCache and the cache is empty an NPE is thrown. This was reported on the user list from a developer running 0.10.1.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2024 from dguy/cache-bug",0
"KAFKA-2478: Fix manual committing example in javadocCommitting before inserting all records into the databasemight lead to some records being lost.I've changed the example to commit only after all recordsreturned by `poll` are inserted into the database.Author: Dmitry Stratiychuk <dstratiychuk@yammer-inc.com>Reviewers: Jason Gustafson, Guozhang WangCloses #210 from shtratos/KAFKA-2478",1
"MINOR: fix flakiness in testDeleteAclsThis call to isCompletedExceptionally introduced a race conditionbecause the future might not have been completed.  assertFutureErrorchecks that the exception is present and of the correct type in anycase, so the call was not necessary.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3139 from cmccabe/fix-test-deleteacls",3
"KAFKA-5477; Lower retry backoff for first AddPartitions in transactionThis patch lowers the retry backoff when receiving a CONCURRENT_TRANSACTIONS error from an AddPartitions request. The default of 100ms would mean that back to back transactions would be 100ms long at minimum, making things to slow.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3377 from apurvam/HOTFIX-lower-retry-for-add-partitions",0
"MINOR: Fix log message when tasks directory is cleaned manually (#9262)Currently when a task directory is cleaned manually the messagefor the state dir cleaner is logged instead of the message forthe manual cleanup. This is because the code checks the elapsedtime since the last update before it checks whether the cleanupis a manual call. This commit changes the order of the checks.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-7909; Ensure timely rebalance completion after pending members rejoin or fail (#6251)Fix the following situations, where pending members (one that has a member-id, but hasn't joined the group) can cause rebalance operations to fail: - In AbstractCoordinator, a pending consumer should be allowed to leave.- A rebalance operation must successfully complete if a pending member either joins or times out.- During a rebalance operation, a pending member must be able to leave a group.Reviewers: Boyang Chen <bchen11@outlook.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Java 10 fixes so that the build passes (#4839)* Upgrade EasyMock to 3.6 which adds support for Java 10by upgrading to ASM 6.1.1.* Ensure that Jacoco is truly disabled for the `core` project.This was the original intent, since it's in Scala, but it had notbeen achieved. This is important because the Jacoco agentfails when it tries to instrument the classes compiled byscalac with Java 10.",0
KAFKA-5468: WorkerSourceTask offset commit loglevel changeschanged log level for source connector worker task when committing offsetsAuthor: Stephane Maarek <stephane@simplemachines.com.au>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3367 from simplesteph/KAFKA-5468,5
"KAFKA-5394; KafkaAdminClient#timeoutCallsInFlight does not work as ex…KAFKA-5394; Fix disconnections due to timeouts in AdminClient* Create KafkaClient#disconnect to tear down a connection anddeliver disconnects to all the requests on it.* AdminClient.java: fix mismatched braces in JavaDoc.* Make the AdminClientConfig constructor visible for testing.* KafkaAdminClient: add TimeoutProcessorFactory to make theTimeoutProcessor swappable for testing.* Make TimeoutProcessor a static class rather than an innerclass.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3250 from cmccabe/KAFKA-5394",5
"KAFKA-8181: Removed Avro topic from TOC on kafka (#6529)Removed TOC entry in Streams Developer Guide for Avro, since we have no content for thisPR on kafka-site: apache/kafka-site#195Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-4698; VerifyError in kafka/client/ClientUtils due to -target:jvm-1.7Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2434 from ijuma/kafka-4698-target-1.7-verify-error,0
"KafkaController NPE in SessionExpireListener; patched by Yang Ye; reviewed by Jun Rao, Neha Narkhede; KAFKA-464git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374467 13f79535-47bb-0310-9956-ffa450edef68",2
Partition.makeFollower() reads broker info from ZK; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-575git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403598 13f79535-47bb-0310-9956-ffa450edef68,5
KAFKA-10825 ZooKeeper ISR manager (#9713)ISR-related cleanup in ReplicaManager and Partition. Removes ISR change logic from ReplicaManager and adds a new ZkIsrManager class which adheres to a new AlterIsrManager trait. Unifies all of the ISR logic in Partition so we don't have separate code paths for ZK vs AlterIsr. Also removes PartitionStateStore,3
MINOR; alterReplicaLogDirs should not fail all the futures when only one call fails (#8985)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
"KAFKA-7063; Remove references to old producers and consumers in docs (#5240)Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: add architecture section and configure / execution for streams1. Added an architecture section.2. Added a configuration / execution sub-section to developer guide.Minor tweaks and a bunch of missing fixes from `kafka-site` repo.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Derrick Or <derrickor@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2488 from guozhangwang/KMinor-streams-docs-second-pass",4
MINOR: KAFKA-3176 follow-up to fix minor issuesCo-authored with ijuma.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1536 from vahidhashemian/minor/KAFKA-3176-Followup,0
"KAFKA-10571; Replace blackout with backoff for KIP-629This replaces code and comment occurrences as described in the KIPAuthor: Xavier Léauté <xvrl@apache.org>Reviewers: Gwen Shapira, Mickael MaisonCloses #9366 from xvrl/kafka-10571",2
"KAFKA-2439; Add MirrorMaker service class for system testsAdded MirrorMaker service and a few corresponding sanity checks, as well as necessary config template files. A few additional updates to accomodate the change in wait_until from ducktape0.2.0->0.3.0Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #148 from granders/KAFKA-2439 and squashes the following commits:c7c3ebd [Geoff Anderson] MirrorMaker now can run as multi-node service. Added kill -9 to various clean_node methods.1e806f2 [Geoff Anderson] Various cleanups per review.1b4b049 [Geoff Anderson] Added MirrorMaker service and a few corresponding sanity checks, as well as necessary config template files. A few additional updates to accomodate the change in wait_until from ducktape0.2.0->0.3.0",4
"KAFKA-12815: Preserve context for KTable.transformValues when getting value from upstream state store (#10720)Reviewers: Victoria Xia <victoria.xia@confluent.io>, John Roesler <john@confluent.io>",5
HOTFIX: fix npe in StreamsMetadataState when onChange has not been calledIf some StreamsMetadataState methods are called before the onChange method is called a NullPointerException was being thrown. Added null check for cluster in isInitialized methodAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1920 from dguy/fix-npe-streamsmetadata,5
MINOR: Detail message/batch size implications for conversion between old and new formatsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3373 from hachikuji/fetch-size-upgrade-notes,5
"Revert ""KAFKA-13542: add rebalance reason in Kafka Streams (#11804)"" (#11873)This reverts commit 2ccc834faa3fffcd5d15d2463aeef3ee6f5cea13.This reverts commit 2ccc834. We were seeing serious regressions in our state heavy benchmarks. We saw that our state heavy benchmarks were experiencing a really bad regression. The State heavy benchmarks runs with rolling bounces with 10 nodes.We regularly saw this exception:  java.lang.OutOfMemoryError: Java heap space                                                                                                                                                                                              I ran through a git bisect and found this commit. We verified that the commit right before did not have the same issues as this one did. I then reverted the problematic commit and ran the benchmarks again on this commit and did not see any more issues. We are still looking into the root cause, but for now since this isn't a critical improvement so we can remove it temporarily.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, David Jacot <djacot@confluent.io>, Ismael Juma <ismael@confluent.io>",5
"MINOR: Upgrade spotbugs and spotbugsPlugin (#8790)Upgrade spotbugsPlugin to have clear output indicating where the error is. When investigating KAFKA-10081, I found the error output of spotbugs is very poor. It doesn't even tell you where the error is and how many errors found, it will take a lot of time for the developers to find out where the error is, and then fix it.![image](https://user-images.githubusercontent.com/43372967/83590263-efc42a80-a587-11ea-95cf-e9097d9a662e.png)https://builds.apache.org/blue/organizations/jenkins/kafka-trunk-jdk8/detail/kafka-trunk-jdk8/4596/pipeline/Then, I found out there's a bug in spotbugsPlugin in V4.0.x, and got fixed in V4.2.xhttps://github.com/spotbugs/spotbugs-gradle-plugin/issues/210So, after upgrading to V4.2.x (I followed to the latest version V4.2.4), the output is like this:![image](https://user-images.githubusercontent.com/43372967/83590913-60b81200-a589-11ea-9a04-1449d693c2f2.png)So you know there's 1 error and you can also open the report file to find out the error.Upgraded to the latest bug fix release of spotbugs (4.0.3) while at it.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
KAFKA-1167 Improve the kafka-topics tool to list the topics with overridden configs; reviewed by Jun Rao,5
MINOR - Adding New York Times logo to streams pageAuthor: Manjula K <manjula@kafka-summit.org>Author: manjuapu <manjula@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3950 from manjuapu/customer-logo-stream,2
MINOR: Remove unnecessary semicolon in ResourceType (#4626),4
"KAFKA-8332: Refactor ImplicitLinkedHashSet to avoid losing ordering when converting to ScalaBecause of how conversions between Java collections and Scala collections work, ImplicitLinkedHashMultiSet objects were being treated as unordered in some contexts where they shouldn't be.  This broke JOIN_GROUP handling.  This patch renames ImplicitLinkedHashMultiSet to ImplicitLinkedHashMultCollection.  The order of Collection objects will be preserved when converting to scala.  Adding Set and List ""views"" to the Collection gives us a more elegant way of accessing that functionality when needed.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-13539: Improve propagation and processing of SSL handshake failures (#11597)When server fails SSL handshake and closes its connection, we attempt to report this to clients on a best-effort basis. When IOException is detected in the client, we may proceed to close the connection before processing all the data from the server if we have data pending to be sent to the server. Server attempts to send any data that has been already wrapped, but may not wrap again after handshake failure, so error may not be propagated to clients. However, our tests assume that clients always detect handshake failures. This commit attempts to wrap and send all data on the server-side after handshake failure and attempts to process all data on the client-side.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
trivial change to fix unit test failure introduced in kafka-2234,0
KAFKA-3044: Re-word consumer.poll behaviourhttps://issues.apache.org/jira/browse/KAFKA-3044Author: Praveen Devarao <praveendrl@in.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #751 from praveend/poll_doc_changes,4
MINOR: Code cleanup and assertion message fixes in Connect integration tests (#8750)1. Remove redundant connect#stop from test in InternalTopicsIntegrationTest since we'll do it after each test case in the @After method2. Refine the error message in topic assertions to make it better explain the errorsReviewers: Konstantine Karantasis <konstantine@confluent.io>,5
"KAFKA-5650; add StateStoreBuilder interface and implementationsPart of KIP-182- Add `StateStoreBuilder` interface and `WindowStateStoreBuilder`, `KeyValueStateStoreBuilder`, and `SessionStateStoreBuilder` implementations- Add `StoreSupplier`, `WindowBytesStoreSupplier`, `KeyValueBytesStoreSupplier`, `SessionBytesStoreSupplier` interfaces and implementations- Add new methods to `Stores` to create the newly added `StoreSupplier` and `StateStoreBuilder` implementations- Update `Topology` and `InternalTopology` to use the interfacesAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3767 from dguy/kafka-5650",5
MINOR: Fix timing issue in advertised listener update test (#5256)Wait for produce to fail before updating listener to avoid send succeeding after the listener update. Also use different topics in tests with connection failures where one is expected to fail and the other is expected to succeed.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
KAFKA-7965; Fix flaky test ConsumerBounceTestWe suspect the problem might be a race condition after broker startup where the consumer has yet to find the coordinator and rebalance. The fix here rolls all the brokers first and then waits for the expected exception.Author: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #6608 from hachikuji/KAFKA-7965,5
failed ERROR messages in LazyInitProducerTest; patched by Yang Ye; reviewed by Jun Rao; kafka-467git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374514 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-10166: always write checkpoint before closing an (initialized) task (#8926)This should address at least some of the excessive TaskCorruptedExceptions we've been seeing lately. Basically, at the moment we only commit tasks if commitNeeded is true -- this seems obvious by definition. But the problem is we do some essential cleanup in postCommit that should always be done before a task is closed:* clear the PartitionGroup* write the checkpointThe second is actually fine to skip when commitNeeded = false with ALOS, as we will have already written a checkpoint during the last commit. But for EOS, we only write the checkpoint before a close -- so even if there is no new pending data since the last commit, we have to write the current offsets. If we don't, the task will be assumed dirty and we will run into our friend the TaskCorruptedException during (re)initialization.To fix this, we should just always call prepareCommit and postCommit at the TaskManager level. Within the task, it can decide whether or not to actually do something in those methods based on commitNeeded.One subtle issue is that we still need to avoid checkpointing a task that was still in CREATED, to avoid potentially overwriting an existing checkpoint with uninitialized empty offsets. Unfortunately we always suspend a task before closing and committing, so we lose the information about whether the task as in CREATED or RUNNING/RESTORING by the time we get to the checkpoint. For this we introduce a special flag to keep track of whether a suspended task should actually be checkpointed or notReviewers: Guozhang Wang <wangguoz@gmail.com>",1
kafka-2109; Support retries in KafkaLog4jAppender; patched by Dave Beech; reviewed by Jun Rao,2
"KAFKA-10109: Fix double AdminClient creation in AclCommandAuthor: Tom Bentley <tbentley@redhat.com>Reviewers: David Jacot <djacot@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8808 from tombentley/KAFKA-10109-AclComment-multiple-AdminClients",5
"KAFKA-9230: Refactor user-customizable Streams metrics (#7762)As proposed in KIP-444, the user customizable metrics shall be refactored. The refactoring consists of:* adding methods addLatencyRateTotalSensor and addRateTotalSensor to interface StreamMetrics* implement the newly added methods in StreamsMetricsImpl* deprecate methods recordThroughput() and recordLatency() in StreamsMetricsReviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-8334 Make sure the thread which tries to complete delayed reque… (#8657)The main changes of this PR are shown below.1. replace tryLock by lock for DelayedOperation#maybeTryComplete2. complete the delayed requests without holding group lockReviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",1
kafka-823; merge 0.8 (51421fcc0111031bb77f779a6f6c00520d526a34) to trunk; patched by Jun Rao; reviewed by Jay Kreps,1
"MINOR: Tag AWS instances with Jenkins build url (#4657)This will allow us to trace leaked instances back to the job,so that we can figure out what happened and fix the leak.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
MINOR: disable zookeeper.sasl.client to avoid false error (#11469)Reviewers: Mickael Maison <mimaison@users.noreply.github.com>,1
KAFKA-7692; Fix ProducerStateManager SequenceNumber overflow (#5990)This patch fixes a few overflow issues with wrapping sequence numbers in the broker's producer state tracking. Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-240 missing producer responsegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1297593 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-6455: Extend CacheFlushListener to forward timestamp (#6147)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-9853: Improve performance of Log.fetchOffsetByTimestamp (#8474)The previous code did not use the collection produced by `takeWhile()`. It only used the length of that collection to select the next element.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-6926: Simplified some logic to eliminate some suppressions of NPath complexity checks (#5051)Modified several classes' `equals` methods and simplified a complex method toreduce the NPath complexity so they could be removed from the checkstylesuppressions that were required with the recent move to Java 8 and upgradeof Checkstyle: https://github.com/apache/kafka/pull/5046.Reviewers: Robert Yokota <rayokota@gmail.com>, Arjun Satish <arjun@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"HOTFIX: Fix broker bounce system tests (#8532)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-8890: Make SSL context/engine configuration extensible (KIP-519) (#8338),5
"MINOR: socket setup max should be 30 seconds #10306 (#10306)socket.connection.setup.timeout.max.ms should be 30 seconds.The current value of 127 seconds is longer than the default API timeoutfor AdminClient, and longer than the default request timeouts for theproducer and consumer.  We should bring these configs into line witheach other.Reviewers: Jason Gustafson <jason@confluent.io>",5
"kafka-1091; full topic list can be read from metadata cache in the broker instead of ZK; patched by Jun Rao; reviewed by Joel Koshy, Guozhang Wang, Swapnil Ghike, and Neha Narkhede",5
"KAFKA-9196; Update high watermark metadata after segment roll (#7695)When we roll a new segment, the log offset metadata tied to the high watermark mayneed to be updated. This is needed when the high watermark is equal to the log endoffset at the time of the roll. Otherwise, we risk exposing uncommitted data early.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"trivial fix to log4j.properties, which stops outputing info level message after kafka-683",5
"MINOR: Downgrade test should wait for ISR rejoin between rolls (#8495)I added a change to the upgrade test a while back that would make it wait forISR rejoin before rolls. This prevents incompatible brokers charging through abad roll and disguising a downgrade problem.We now also check for protocol errors in the broker logs.Reviewers: Boyang Chen <boyang@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Small cleanups in `AlterIsr` handling logic (#9663)A few small cleanups in `Partition` handling of `AlterIsr`:- Factor state update and log message into `sendAlterIsrRequest`- Ensure illegal state error gets raised if a retry fails to be enqueued- Always check the proposed state against the current state in `handleAlterIsrResponse`- Add `toString` implementations to `IsrState` case classesReviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-10157: Fix broken tests due to InterruptedException from FinalizedFeatureChangeListener (#8857)This PR fixes the cause of failing tests mentioned in the jira:kafka.network.DynamicConnectionQuotaTestkafka.api.CustomQuotaCallbackTestkafka.server.DynamicBrokerReconfigurationTestIssue:The call to ChangeNotificationProcessorThread.queue.take() could throw an InterruptedException. While the queue is empty and the thread is blocking on taking an item from the queue, a concurrent call to FinalizedFeatureChangeListener.close() could interrupt the thread and cause an InterruptedException to be raised from queue.take(). In such a case, it is safe to ignore the exception since the thread is being shutdown.Definitely ignoring the InterruptedException for the above reason was the intent of the code that used the ignoring clause for the same. But it seems unfortunately the ignoring clause does not ignore InterruptedException, so that doesn't work for us. To confirm this theory, I found the following code in scala.util.control.Exception.scala: https://github.com/scala/scala/blob/v2.12.0/src/library/scala/util/control/Exception.scala#L167-L176.Fix:The fix in this PR is to just not use the ignoring clause. We rely on existing mechanism in ShutdownableThread that ignores the exception during shutdown.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chan <boyang@confluent.io>, Anna Povzner <anna@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-6299; Fix AdminClient error handling when metadata changes (#4295)When AdminClient gets a NOT_CONTROLLER error, it should refresh its metadata and retry the request, rather than making the end-user deal with NotControllerException.Move AdminClient's metadata management outside of NetworkClient and into AdminMetadataManager. This will make it easier to do more sophisticated metadata management in the future, such as implementing a NodeProvider which fetches the leaders for topics.Rather than manipulating newCalls directly, the AdminClient service thread now drains it directly into pendingCalls. This minimizes the amount of locking we have to do, since pendingCalls is only accessed from the service thread.",5
KAFKA-506 Misc. follow-up cleanups from Neha's review.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397134 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-5191: Autogenerate Consumer Fetcher metricsAutogenerate docs for the Consumer Fetcher's metrics. This is a smaller subset of the original PR https://github.com/apache/kafka/pull/1202.CC ijuma benstopford hachikujiAuthor: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2993 from wushujames/fetcher_metrics_docs",2
HOTFIX: change compression codec in TransactionStateManager to UncompressedCodecChange the compression code used for the transaction log to UncompressedCoded as it fails during creation when the codec is set to NoCompressionCodec.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3022 from dguy/hotfix-tsm,0
"MINOR: Remove deprecated streams config (#4906)Removed the following: ""zookeeper.connect"", ""key.serde"", ""value.serde"", ""timestamp.extractor""Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-5077; fix GC logging arguments for Java 9Author: Xavier Léauté <xavier@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2863 from xvrl/fix-jdk9-gc-logs,2
"MINOR: Start Connect REST server in standalone mode to match distributed mode (KAFKA-7503 follow-up)Start the Rest server in the standalone mode similar to how it's done for distributed mode.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #6148 from mageshn/KAFKA-7826",5
"KAFKA-10482: Fix flaky testDynamicListenerConnectionCreationRateQuota (#9301)Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Fix documentation for KIP-585 (#9524)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
IndexOutOfBoundsException thrown by kafka.consumer.ConsumerFetcherThread; patched by Jun Rao; reviewed by Jay Kreps and Neha Narkhede; kafka-528git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1391854 13f79535-47bb-0310-9956-ffa450edef68,2
upgrade ZKClient to allow conditional updates in ZK; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-337git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1351546 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-10500: Allow resizing of StreamThread state store caches (#9572) - part of KIP-663Reviewer: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3994: Fix deadlock in Watchers by calling tryComplete without any locksAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Jun Rao, Jiangjie Qin, Guozhang WangCloses #2195 from hachikuji/KAFKA-3994-linked-queue",2
"KAFKA-8843: KIP-515: Zookeeper TLS supportSigned-off-by: Ron Dagostino <rdagostinoconfluent.io>Author: Ron Dagostino <rdagostino@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #8003 from rondagostino/KAFKA-8843",2
KAFKA-636 Make log segment delete an asynchronous background action done by the scheduler. Patch reviewed by Jun and Neha.git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1420361 13f79535-47bb-0310-9956-ffa450edef68,1
Fix windows build script - kafka-run-class.bat; patched by Mark deVilliers; reviewed by Jun Rao; kafka-751,1
MINOR: add ImplicitLinkedHashCollection#moveToEnd (#9269)Add ImplicitLinkedHashCollection#moveToEnd.Refactor ImplicitLinkedHashCollectionIterator to be a little bit morerobust against concurrent modifications to the map (which admittedlyshould not happen.)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13832: Fix flaky testAlterAssignment (#12060)In KRaft mode the metadata is not propagate in time, so we should should wait for it before make assertions.Reviewers:  Luke Chen <showuon@gmail.com>",3
"MINOR: Fix force kill of KRaft colocated controllers in system tests (#11238)I noticed that a system test using a KRaft cluster with 3 brokers but only 1 co-located controller did not force-kill the second and third broker after shutting down the first broker (the one with the controller).  The issue was a floating point rounding error.  This patch adjusts for the rounding error and also makes the logic work for an even number of controllers.  A local run of `tests/kafkatest/sanity_checks/test_bounce.py` succeeded (and I manually increased the cluster size for the 1 co-located controller case and observed the correct kill behavior: the second and third brokers were force-killed as expected).Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, David Jacot <djacot@confluent.io>",5
KAFKA-1098 Fix failing test in LogCleaner.,4
MINOR: documentation fix in StringDecoderAuthor: Dave Cromberge <davecromberge@gmail.com>Closes #124 from davecromberge/documentation-fix and squashes the following commits:7b9b1ce [Dave Cromberge] minor documentation fix to StringDecoder,0
MINOR: improve docs version numbers (#5372)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
MINOR: Fix usage of @see in IncrementalCooperativeAssignor doc comments (#12606)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
MINOR: Update rocksDB dependency to 4.11.2There are 32 failing tests on both trunk and my branch.Author: jozi-k <jozef.koval@protonmail.ch>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2036 from jozi-k/update-rocksdb-4.11.2,5
"KAFKA-2332; Add quota metrics to old producer and consumerAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #176 from lindong28/KAFKA-2332",2
"MINOR: Adds KRaft versions of most streams system tests (#12458)Migrates Streams sustem tests to either use kraft brokers or to use both kraft and zk in a testing matrix.This skips tests which use various forms of Kafka versioning since those seem to have issues with KRaft at the moment. Running these tests with KRaft will require a followup PR.Reviewers: Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",1
"KAFKA-3144; Report members with no assigned partitions in ConsumerGroupCommandThis PR makes a couple of enhancements to the `--describe` option of `ConsumerGroupCommand`:1. Listing members with no assigned partitions.2. Showing the member id along with the owner of each partition (owner is supposed to be the logical application id and all members in the same group are supposed to set the same owner).3. Printing a warning indicating whether ZooKeeper based or new consumer API based information is being reported.It also adds unit tests to verify the added functionality.Note: The third request on the corresponding JIRA (listing active offsets for empty groups of new consumers) is not implemented as part of this PR, and has been moved to its own JIRA (KAFKA-3853).Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1336 from vahidhashemian/KAFKA-3144",5
"KAFKA-13759: Disable idempotence by default in producers instantiated by Connect (#11933)With AK 3.0, idempotence was enabled by default in Kafka producers. However, if idempotence is enabled, Connect won't be able to communicate via its producers with Kafka brokers older than version 0.11. Perhaps more importantly, for brokers older than version 2.8 the IDEMPOTENT_WRITE ACL is required to be granted to the principal of the Connect worker.Therefore this commit disables producer idempotence by default to all the producers instantiated by Connect. Users can still choose to enable producer idempotence by explicitly setting the right worker and/or connector properties.The changes were tested via existing unit, integration and system tests.Reviewers: Randall Hauch <rhauch@gmail.com>",3
MINOR: Add compatibility tests for 2.3.0 (#6995)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"MINOR: Fix typo in `shouldUseJUnit5` in build.gradle (#9893)""mirorr-client"" => ""mirror-client""Reviewers: Ismael Juma <ismael@juma.me.uk",3
MINOR: log error message from Connect sink exception (#7555)Author: Narek Karapetian <narek_karapetian@epam.com>Reviewer: Randall Hauch <rhauch@gmail.com>,0
trivial change to remove unused command bin/kafka-add-partitions.sh,1
"MINOR: Fix multiple KafkaStreams.StreamStateListener being instantiatedThere should only be a single `KafkaStreams.StreamStateListener` toensure synchronization of operations on`KafkaStreams.StreamStateListener#threadState`.Author: Armin Braun <me@obrown.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2801 from original-brownbear/fix-stream-state-listener",0
"KAFKA-13194: bound cleaning by both LSO and HWM when firstUnstableOffsetMetadata is None (#11199)When the high watermark is contained in a non-active segment, we are not correctly bounding it by the hwm. This means that uncommitted records may overwrite committed data. I've separated out the bounding point tests to check the hwm case in addition to the existing active segment case.Reviewers: Jun Rao <junrao@gmail.com>",1
"KAFKA-4510: StreamThread must finish rebalance in state PENDING_SHUTDOWNAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Guozhang WangCloses #2227 from mjsax/kafka-4510-finish-rebalance-on-shutdown",5
"KAFKA-4500; Code quality improvements- Removed redundant modifiers, not needed String.format()- Removed unnecessary semicolon, additional assignment, inlined return- Using StringBuilder for consistency across codebase- Using try-with-resourcesAuthor: Rekha Joshi <rekhajoshm@gmail.com>Author: Joshi <rekhajoshm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2222 from rekhajoshm/KAFKA-4500",1
"KAFKA-7278; replaceSegments() should not call asyncDeleteSegment() for segments which have been removed from segments list (#5491)Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
kafka-1702; Messages silently Lost by producer; patched by Alexis Midon; reviewed by Jun Rao,5
"MINOR: Log project, gradle, java and scala versions at the start of the build (#10307)This is useful when debugging build issues. I also removed two printlns that are now redundant, sothis makes the build more informative and less noisy at the same time. Example output:> Starting build with version 3.0.0-SNAPSHOT using Gradle 6.8.3, Java 15 and Scala 2.13.5Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
JMX bean that reports #message/sec in consumer; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-136git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178298 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: docs typo in '--zookeeper myhost:2181--execute'this PR will fix a typo related to docs:http://kafka.apache.org/21/documentation.html#rep-throttle```bash$ bin/kafka-reassign-partitions.sh --zookeeper myhost:2181--execute --reassignment-json-file bigger-cluster.json —throttle 50000000```I think `myhost:2181` should be `localhost:2181` and followed by a `space`Author: opera443399 <pc@pcswo.com>Reviewers: Gwen ShapiraCloses #6704 from opera443399/docs-ops-typo,2
KAFKA-8519 Add trogdor action to slow down a network (#6912)This adds a new Trogdor fault spec for inducing network latency on a network device for system testing. It operates very similarly to the existing network partition spec by executing the `tc` linux utility.,1
"KAFKA-8407: Fix validation of class and list configs in connector client overrides (#6789)Because of how config values are converted into strings in the `AbstractHerder.validateClientOverrides()` method after being validated by the client override policy, an exception is thrown if the value returned by the policy isn't already parsed as the type expected by the client `ConfigDef`. The fix here involves parsing client override properties before passing them to the override policy.A unit test is added to ensure that several different types of configs are validated properly by the herder.Author: Chris Egerton <chrise@confluent.io>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
Checking in some files left from the last checkin for KAFKA-202git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1231298 13f79535-47bb-0310-9956-ffa450edef68,2
Add a shallow iterator to the ByteBufferMessageSet; patched by Yang Ye; reviewed by Jun Rao; KAFKA-277git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1293010 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-9110: Improve efficiency of disk reads when TLS is enabled (#7604)1. Avoid a buffer allocation and a buffer copy per file read.2. Ensure we flush `netWriteBuffer` successfully before reading fromdisk to avoid wasted disk reads.3. 32k reads instead of 8k reads to reduce the number of disk reads(improves efficiency for magnetic drives and reduces the number ofsystem calls).4. Update SslTransportLayer.write(ByteBuffer) to loop until the socketbuffer is full or the src buffer has no remaining bytes.5. Renamed `MappedByteBuffers` to `ByteBufferUnmapper` since it's alsoapplicable for direct byte buffers.6. Skip empty `RecordsSend`7. Some minor clean-ups for readability.I ran a simple consumer perf benchmark on a 6 partition topic (largeenough not to fit into page cache) starting from the beginning of thelog with TLS enabled on my 6 core MacBook Pro as a sanity check.This laptop has fast SSDs so it benefits less from the larger readsthan the case where magnetic disks are used. Consumer throughputwas ~260 MB/s before the changes and ~300 MB/s after(~15% improvement).Credit to @junrao  for pointing out that this code could be more efficient.Reviewers: Jun Rao <junrao@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
KAFKA-9663: Update JavaDocs to indicate `null` return values in KafkaStreams (#8228)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA2805; RecordAccumulator request timeout not enforced when all brokers are goneRemoved the check for expiring only those batches whose metadata is unavailable. Now the batches will be expired irrespective of whether the leader is available or not, as soon as it reaches the requestimeout threshold.Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>Reviewers: Jun Rao <junrao@gmail.com>Closes #503 from MayureshGharat/kafka-2805",2
KAFKA-13917: Avoid calling lookupCoordinator() in tight loop (#12180)Reviewers: Luke Chen <showuon@gmail.com>,5
MINOR: Fixed undefined method `update_guest'Author: Piotr Szwed <pszwed@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #802 from szwed/trunk,1
KAFKA-6716: Should close the `discardChannel` in MockSelector#completeSend (#4783),5
kafka-2096; Enable keepalive socket option for broker to prevent socket leak; patched by Allen Wang; reviewed by Jun Rao,0
"KAFKA-8526; Fallback to other log dirs after getOrCreateLog failure (#6969) LogManager#getOrCreateLog() selects a log dir for the new replica from _liveLogDirs, if disk failure is discovered at this point, before LogDirFailureHandler finds out, try using other log dirs before failing the operation.Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",5
HOTFIX: use the new prop object (#4888),1
MINOR: fix typo for QUORUM_FETCH_TIMEOUT_MS_DOC (#12132)Reviewers: Luke Chen <showuon@gmail.com>,2
KAFKA-631 Implement a log cleaner for Kafka. Reviewed by Neha.,4
"MINOR: Increase the amount of time available to the `test_verifiable_producer` (#9201)Increase the amount of time available to the `test_verifiable_producer` test to login and get the process name for the verifiable producer from 5 seconds to 10 seconds.We were seeing some test failures due to the assertion failing because the verifiable producer would complete before we could login, list the processes, and parse out the producer version. Previously, we were giving this operation 5 seconds to run, this PR bumps it up to 10 seconds. I verified locally that this does not flake, but even at 5 seconds I wasn't seeing any flakes. Ultimately we should find a better strategy than racing to query the producer process (as outlined in the existing comments). Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-4059; API Design section under Implementation is out of dateIt describes the old deprecated clients and it's better to justremove it.The contribution is my original work and I license the work to theproject under the project's open source license.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3385 from tombentley/KAFKA-4059,1
"KAFKA-13794: Fix comparator of inflightBatchesBySequence in TransactionsManager (round 3) (#12096)Conceptually, the ordering is defined by the producer id, producer epochand the sequence number. This set should generally only have entriesfor the same producer id and epoch, but there is one case wherewe can have conflicting `remove` calls and hence we add this asa temporary safe fix.We'll follow-up with a fix that ensures the original intended invariant.Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
KAFKA-5548: Extended validation for SchemaBuilder methods.More input validation for SchemaBuilder methods.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3474 from jcustenborder/KAFKA-5548,5
MINOR: Fix typo in sample Vagrantfile.local for AWS system testsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #565 from ewencp/fix-aws-vagrantfile-local-example,2
"trivial change to save kafka broker log to a file, in addition to console",1
"KAFKA-6905: Document that Transformers may be re-used by Streams (#5026)This is a follow-up to #5022 which added documentation to the Processorinterface. This commit adds similar documentation to Transformer andValueTransformer.Also, s/processor/transformer/ in the close() docs.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10651: read  offsets directly from checkpoint for uninitialized tasks (#9515)Read offsets directly from the checkpoint file if a task is uninitialized or closedReviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-2381: Fix concurrent modification on assigned partition while looping over it; reviewed by Jason Gustafson, Aditya Auradkar, Ewen Cheslack-Postava, Ismael Juma and Guozhang Wang",0
"KAFKA-13348: Allow Source Tasks to Handle Producer Exceptions (KIP-779) (#11382)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",0
"KAFKA-8304: Fix registration of Connect REST extensions (#6651)Fix registration of Connect REST extensions to prevent deadlocks when extensions get the list of connectors before the herder is available. Added integration test to check the behavior.Author: Chris Egerton <cegerton@oberlin.edu>Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
MINOR: Improve formatting in docs (#8611)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-7730; Limit number of active connections per listener in brokers (KIP-402)Adds a new listener config `max.connections` to limit the number of active connections on each listener. The config may be prefixed with listener prefix. This limit may be dynamically reconfigured without restarting the broker.This is one of the PRs for KIP-402 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-402%3A+Improve+fairness+in+SocketServer+processors). Note that this is currently built on top of PR #6022Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>Closes #6034 from rajinisivaram/KAFKA-7730-max-connections,5
"KAFKA-8834; Add reassignment metrics and distinguish URPs (KIP-352) (#7361)KIP-352 aims to add several new metrics in order to track reassignments much better. We will be able to measure bytes in/out rate and the count of partitions under active reassignment.We also change the semantic of the UnderReplicatedPartitions metric to cater better for reassignment. Currently it reports under-replicated partitions when during reassignment extra partitions are added as part of the process but this PR changes it so it'll always take the original replica set into account when computing the URP metrics.The newly added metrics will be: - kafka.server:type=ReplicaManager,name=ReassigningPartitions- kafka.server:type=BrokerTopicMetrics,name=ReassignmentBytesOutPerSec- kafka.server:type=BrokerTopicMetrics,name=ReassignmentBytesInPerSecThe changed URP metric:- kafka.server:type=ReplicaManager,name=UnderReplicatedPartitionsReviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13746: Attempt to fix flaky test by waiting on metadata update (#12104)Reviewers: dengziming <dengziming1993@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Update docs to point to next release add notable features for 2.7 (#9483)Reviewers: Matthias J. Sax <mjsax@apache.org>,1
"KAFKA-6126: Remove unnecessary topics created checkAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4322 from mjsax/kafka-6126-remove-topic-check-on-rebalance-2",4
"MINOR: Update docs with out-dated context.schedule(...) examples (#5924)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"Revert ""KAFKA-6383: complete shutdown for CREATED StreamThreads (#4343)""This reverts commit 47db063c310cf47e4c544196acab2abfe62977b0.",5
"MINOR: Recommend Java 11 (#9080)Java 11 has been recommended for a while, but the ops section had not been updated.Also added `-XX:+ExplicitGCInvokesConcurrent` which has been in `kafka-run-class`for a while. Finally, tweaked the text slightly to read better.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
MINOR: ProducerPerformance should work with older client jarsAuthor: Jun Rao <junrao@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2896 from junrao/minor,1
"MINOR: Add a new system test for resilience (#4560)* Rolling kill-restart Streams instances with brokers unavailable temporarily, and validate that the streams can still complete the restart processReviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Fix consumer constructor doc stringAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1568 from granthenke/consumer-doc,2
"KAFKA-9988: Suppress uncaught exceptions in log messages during Connect task shutdown (#10503)Uncaught exceptions logged during task stop were misleading because the task is already on its way of being shutdown.The suppression of exception causes a change in behavior as the caller method now calls `statusListener.onShutdown` instead of `statusListener.onFailure` which is the right behavior. A new test was added to test the right behavior for uncaught exception during shutdown and existing test was modified to test uncaught exception during normal execution.Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
MINOR: Remove some unnecessary cyclomatic complexity suppressions (#10488)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"KAFKA-4426; Add close with timeout for KafkaConsumer (KIP-102)Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2285 from rajinisivaram/KAFKA-4426",5
KAFKA-2196; Remove identical topic constraint in round-robin assignor; reviewed by Guozhang Wang,4
"MINOR: Introduce ProducerIdGenerator trait (#10009)`ProducerIdManager` is an existing class that talks to ZooKeeper directly.  We won't have ZooKeeperwhen using a Raft-based metadata quorum, so we need an abstraction for the functionality ofgenerating producer IDs.  This PR introduces `ProducerIdGenerator` for this purpose, and we passan implementation when instantiating `TransactionCoordinator` rather than letting`TransactionCoordinator.apply()` itself always create a ZooKeeper-based instance.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
KAFKA-5620: Expose the ClassCastException as the cause for the SerializationException in KafkaProducerExpose the ClassCastException as the cause for the SerializationException.Author: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3556 from jcustenborder/KAFKA-5620,1
"KAFKA-5121; Implement transaction index for KIP-98Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2910 from hachikuji/eos-txn-index",5
KAFKA-12772: Move all transaction state transition rules into their states (#10667)Co-authored-by: dengziming <dengziming@growingio.com>,4
"KAFKA-8847; Deprecate and remove usage of supporting classes in kafka.security.auth (#7966)Removes references to the old scala Acl classes from kafka.security.auth (Acl, Operation, ResourceType, Resource etc.) and replaces these with the Java API. Only the old SimpleAclAuthorizer, AuthorizerWrapper used to wrap legacy authorizer instances and tests using SimpleAclAuthorizer continue to use the old API. Deprecates the old scala API.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
KAFKA-7273 Clarification on mutability of headers passed to Converter#fromConnectData() (#7489)Author: Gunnar Morling <gunnar.morling@googlemail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-10413: Allow for even distribution of lost/new tasks when multiple Connect workers join at the same time (#9319)First issue: When more than one workers join the Connect group the incremental cooperative assignor revokes and reassigns at most average number of tasks per worker.Side-effect: This results in the additional workers joining the group stay idle and would require more future rebalances to happen to have even distribution of tasks.Fix: As part of task assignment calculation following a deployment, the reassignment of tasks are calculated by revoking all the tasks above the rounded up (ceil) average number of tasks.Second issue: When more than one worker is lost and rejoins the group at most one worker will be re assigned with the lost tasks from all the workers that left the group.Side-effect: In scenarios where more than one worker is lost and rejoins the group only one among them gets assigned all the partitions that were lost in the past. The additional workers that have joined would not get any task assigned to them until a rebalance that happens in future.Fix: As part fo lost task re assignment all the new workers that have joined the group would be considered for task assignment and would be assigned in a round robin fashion with the new tasks.Testing strategy : * System testing in a Kubernetes environment completed* New integration tests to test for balanced tasks* Updated unit tests. Co-authored-by: Rameshkrishnan Muthusamy <rameshkrishnan_muthusamy@apple.com>Co-authored-by: Randall Hauch <rhauch@gmail.com>Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"MINOR: Convert last streams join test to TTD (#7777)Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3619: File handles are leaked on .lock files of ProcessorStateManagerKafka Streams seems to hold file handles on the `.lock` files for the state dirs, resulting in an explosion of filehandles over time. Running `lsof` shows the number of open filehandles on the `.lock` file increasing rapidly over time. In a separate test project, I reproduced the issue and determined that in order for the filehandle to be relinquished the `FileChannel` instance must be properly closed. Applying this patch seems to resolve the issue in my job.Author: Greg Fodor <gfodor@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1267 from gfodor/bug/state-lock-filehandle-leak",2
"MINOR: Safer handling of requests prior to SASL authenticationThis implements two improvements for request handling prior to SASL authentication:1. Only parse request types that are allowed prior to authentication.2. Limit the maximum request size (the default is 100Mb).Author: Jason Gustafson <jason@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3558 from hachikuji/minor-restrict-presasl-request-parsing",5
"[HOT FIX] Check for null before deserializing in MeteredSessionStore  (#6575)The fetchSession() method of SessionStore searches for a (single) specific session and returns null if none are found. This is analogous to fetch(key, time) in WindowStore or get(key) in KeyValueStore. MeteredWindowStore and MeteredKeyValueStore both check for a null result before attempting to deserialize, however MeteredSessionStore just blindly deserializes and as a result NPE is thrown when we search for a record that does not exist.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Bruno Cadonna <bruno@confluent.io>",5
"MINOR: Added more basic concepts to the documentationAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Michael G. Noll, Matthias J. Sax, Guozhang WangCloses #2030 from enothereska/minor-kip63-docs",2
KAFKA-2441: SSL/TLS in official docsAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Guozhang WangCloses #406 from gwenshap/KAFKA-2441,2
"MINOR: Add version check on enable-systest-events flagRecent patch adding enable-systest-events flag without any version check breaks all uses of versioned console consumer. E.g. upgrade tests, compatibility tests etc.Added a check to only apply the flag if running 0.10.0 or greater.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1298 from granders/minor-systest-fix-versioned-console-consumer",5
MINOR: Bump system test ducktape dependency to 0.5.1Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1397 from granders/minor-increment-ducktape,5
"KAFKA-13524: Add IQv2 query handling to the caching layer (#11682)Currently, IQv2 forwards all queries to the underlying store. We add this bypass to allow handling of key queries in the cache. If a key exists in the cache, it will get answered from there.As part of this PR, we realized we need access to the position of the underlying stores. So, I added the method getPosition to the public API and ensured all state stores implement it. Only the ""leaf"" stores (Rocks*, InMemory*) have an actual position, all wrapping stores access their wrapped store's position.Reviewers: Patrick Stuedi <pstuedi@apache.org>, John Roesler <vvcephei@apache.org>",1
"KAFKA-6131; Use atomic putIfAbsent to create txn marker queuesAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4140 from rajinisivaram/KAFKA-6131-txn-concurrentmap",5
HOTFIX: Start embedded kafka in KafkaStreamsTest to avoid hangingThe KafkaStreamsTest can occasionally hang if the test doesn't run fast enough. This is due to there being no brokers available on the broker.urls provided to the StreamsConfig. The KafkaConsumer does a poll and blocks causing the test to never complete.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1693 from dguy/kafka-streams-test(cherry picked from commit ce34614a43fb1f43ef6b5660fb37f7a0598d177a)Signed-off-by: Ismael Juma <ismael@juma.me.uk>,3
"MINOR: AbstractIndex.close should unmap (#5757)Reviewers: Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>",5
MINOR: re-enable WorkerTest for java 16+ (#12557)Re-enable WorkerTest for java 16+ since we've removed powerMock in the testReviewers: Luke Chen <showuon@gmail.com>,3
MINOR: update doc for default assignor change (#11009)Update the doc and upgrade doc for default assignor change. REF: #10903Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,4
"KAFKA-6860: Fix NPE in Kafka Streams with EOS enabled (#5187)Reviewers: John Roesler <john@confluent.io>, Ko Byoung Kwon, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: jmh.sh swallows compile errors (#11870)jmh.sh runs tasks in quiet mode which swallows compiler errors. This is a pain and I frequently have to edit the shell script to see the error.Reviewers:  Ismael Juma <ismael@confluent.io>, Bill Bejeck <bbejeck@apache.org>",5
"MINOR: Correct warning about increasing capacity when insufficient nodes to assign standby tasks (#10151)We should only recommend to increase the number of KafkaStreams instances, not the number of threads, since a standby task can never be placed on the same instance as an active task regardless of the thread countReviewers: Chia-Ping Tsai <chia7712@gmail.com>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"KAFKA-8483/KAFKA-8484; Ensure safe handling of producerId resets (#6883)The idempotent producer attempts to detect spurious UNKNOWN_PRODUCER_ID errors and handle them by reassigning sequence numbers to the inflight batches. The inflight batches are tracked in a PriorityQueue. The problem is that the reassignment of sequence numbers depends on the iteration order of PriorityQueue, which does not guarantee any ordering. So this can result in sequence numbers being assigned in the wrong order.  This patch fixes the problem by using a sorted set instead of a priority queue so that the iteration order preserves the sequence order. Note that resetting sequence numbers is an exceptional case.This patch also fixes KAFKA-8484, which can cause an IllegalStateException when the producerId is reset while there are pending produce requests inflight. The solution is to ensure that sequence numbers are only reset if the producerId of a failed batch corresponds to the current producerId.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
"MINOR: replace deprecated exactly_once_beta into exactly_once_v2 (#10884)Replace deprecated exactly_once_beta with exactly_once_v2 in system tests.Follow up for #10870, found out there are still some system tests using the deprecated exactly_once_beta. This PR updates them.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Ignore test_broker_type_bounce_at_start system test (#5055)test_broker_type_bounce_at_start tries to validate that when the controller is down, the streams client will always fail trying to create the topic; with the current behavior of admin client it is actually not always true: the actual behavior depends on the admin client internals as well as when the controller becomes unavailable during the leader assign partitions phase. I'd suggest at least ignore this test for now until the admin client has more stable (personally I'd even suggest removing this test as its coverage benefits is smaller than its introduced issues to me).Also adding a few more log4j entries as a result of investigating this issue.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
kafka-1280; exclude kafka-clients jar from dependant-libs dir; patched by Jun Rao; reviewed by Neha Narkhede,5
MINOR: System test ZooKeeper upgrades (#8384)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"MINOR: improve error message for Streams testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4253 from mjsax/minor-imporve-error-message",0
KAFKA-5643: Using _DUCKTAPE_OPTIONS has no effect on executing testsAdded handling of _DUCKTAPE_OPTIONS (mainly for enabling debugging)Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3578 from ppatierno/kafka-5643,5
"KAFKA-5366; Add concurrent reads to transactions system testThis currently fails in multiple ways. One of which is most likely KAFKA-5355, where the concurrent consumer reads duplicates.During broker bounces, the concurrent consumer misses messages completely. This is another bug.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3217 from apurvam/KAFKA-5366-add-concurrent-reads-to-transactions-system-test",5
"KAFKA-5485; Streams should not suspend tasks twiceAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3390 from mjsax/kafka-5485-dont-suspend-tasks-twice",5
"KAFKA-10134: Use long poll if we do not have fetchable partitions (#8934)The intention of using poll(0) is to not block on rebalance but still return some data; however, `updateAssignmentMetadataIfNeeded` have three different logic: 1) discover coordinator if necessary, 2) join-group if necessary, 3) refresh metadata and fetch position if necessary. We only want to make 2) to be non-blocking but not others, since e.g. when the coordinator is down, then heartbeat would expire and cause the consumer to fetch with timeout 0 as well, causing unnecessarily high CPU.Since splitting this function is a rather big change to make as a last minute blocker fix for 2.6, so I made a smaller change to make updateAssignmentMetadataIfNeeded has an optional boolean flag to indicate if 2) above should wait until either expired or complete, otherwise do not wait on the join-group future and just poll with zero timer.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-12662: add unit test for ProducerPerformance (#10588)Reviewers: Luke Chen <showuon@gmail.com>, wenbingshen <oliver.shen999@gmail.com>, dengziming <dengziming1993@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-12905: Replace EasyMock and PowerMock with Mockito for NamedCacheMetricsTest (#10835)* Development of EasyMock and PowerMock has stagnated while Mockito continues to be actively developed. With the new Java cadence, it's a problem to depend on libraries that do bytecode generation and are not actively maintained. In addition, Mockito is also easier to use.KAFKA-7438Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-10070: parameterize Connect unit tests to remove code duplication (#10299)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",4
"MINOR: Add regression tests for KTable mapValues and filter (#5134)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: MockAdminClient should return InvalidReplicationFactorException if brokers.size < replicationFactor* `MockAdminClient` should behave the same way as `Admin` for `createTopics()`* Changed from throwing an `IllegalArgumentException` to `InvalidReplicationFactorException` when `brokers.size() < replicationFactor`Author: jeff kim <jeff.kim@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8617 from jeffkbkim/MockAdminClient-InvalidReplicationFactorException,5
"KAFKA-9274: Handle TimeoutException on commit (#9570)- part of KIP-572 - when KafkaStreams commits a task, a TimeoutException should not kill   the thread but `task.timeout.ms` should be triggered and the commit   should be retried in the next loopReviewer: John Roesler <john@confluent.io>",5
"MINOR: Optimize the OrderedBytes#upperRange for not all query cases (#11181)Currently in OrderedBytes#upperRange method, we'll check key bytes 1 by 1, to see if there's a byte value >= first timestamp byte value, so that we can skip the following key bytes, because we know compareTo will always return 0 or 1. However, in most cases, the first timestamp byte is always 0, more specifically the upperRange is called for both window store and session store. For former, the suffix is in timestamp, Long.MAX_VALUE and for latter the suffix is in Long.MAX_VALUE, timestamp. For Long.MAX_VALUE the first digit is not 0, for timestamp it could be 0 or not, but as long as it is up to ""now"" (i.e. Aug. 23rd) then the first byte should be 0 since the value is far smaller than what a long typed value could have. So in practice for window stores, that suffix's first byte has a large chance to be 0, and hence worth optimizing for.This PR optimizes the not all query cases by not checking the key byte 1 by 1 (because we know the unsigned integer will always be >= 0), instead, put all bytes and timestamp directly. So, we won't have byte array copy in the end either.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINoR: Replace '>' in RoundRobinAssignor.java into '&gt;' (#7073)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"MINOR: AbstractConfigTest.testClassConfigs should reset the class loa… (#10010)Reviewers: Jason Gustafson <jason@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-9767: Add logging to basic auth rest extension (#8357)Add logging to basic auth rest extension.Author: Chris Egerton <chrise@confluent.io>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: unpin ducktape dependency to always use the newest version (py3 edition) (#11884)Ensures we always have the latest published ducktape version.This way whenever we release a new one, we won't have to cherry pick a bunch of commits across a bunch of branches.",1
"MINOR: remove the indent in security docReading the security doc recently, and one thing annoys me: the long indent in front of each command, ex:![image](https://user-images.githubusercontent.com/43372967/106253151-155a1e80-6252-11eb-97f7-e8f4f60c6047.png)![image](https://user-images.githubusercontent.com/43372967/106253176-1be89600-6252-11eb-845b-b8e478534fd7.png)![image](https://user-images.githubusercontent.com/43372967/106253249-3589dd80-6252-11eb-82e1-45fe188b26d6.png)https://kafka.apache.org/documentation/#security_ssl_keyRemoving all the prefix indent in the commands. I'll create another PR to kafka-site if this change accepts. Thanks.Author: Luke Chen <showuon@gmail.com>Reviewers: Tom Bentley <tbentley@redhat.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #10002 from showuon/doc_code_indent",2
"KAFKA-10082: Fix the failed testMultiConsumerStickyAssignment (#8777)Fix the failed testMultiConsumerStickyAssignment by modifying the logic error in allSubscriptionsEqual method.We will create the consumerToOwnedPartitions to keep the set of previously owned partitions encoded in the Subscription. It's our basis to do the reassignment. In the allSubscriptionsEqual, we'll get the member generation of the subscription, and remove all previously owned partitions as invalid if the current generation is higher. However, the logic before my fix, will remove the current highest member out of the consumerToOwnedPartitions, which should be kept because it's the current higher generation member. Fix this logic error.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13495: Add reason to JoinGroupRequest (KIP-800) (#11566)This patch adds a `reason` field to the `JoinGroupRequest` as specified in KIP-800: https://cwiki.apache.org/confluence/display/KAFKA/KIP-800%3A+Add+reason+to+JoinGroupRequest+and+LeaveGroupRequest.Reviewers: loboya~ <317307889@qq.com>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
using MultiFetch in the follower; patched by Jun Rao; reviewed by Joel Koshy and Neha Narkhede; KAFKA-339git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1353086 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-8563: Remove redundant `NetworkSend.sizeDelimit()` method (#6967)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
Minor typo in KafkaConfig; reviewed by Gwen Shapira,5
KAFKA-3521: validate null keys in Streams DSL implementationsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1197 from guozhangwang/K3521,5
MINOR: Run MessageFormatChangeTest in ZK mode only (#12395)KRaft mode will not support writing messages with an older message format (2.8) since the min supported IBP is 3.0 for KRaft. Testing support for reading older message formats will be covered by https://issues.apache.org/jira/browse/KAFKA-14056.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-5429; Ignore produce response if batch was previously abortedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3300 from hachikuji/KAFKA-5429",5
"KAFKA-6321; Consolidate calls to KafkaConsumer's `beginningOffsets()` and `endOffsets()` in ConsumerGroupCommandAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ted Yu <yuzhihong@gmail.com>, Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #4344 from vahidhashemian/KAFKA-6321",1
"MINOR: log reason for fatal error in locking state dir (#7534)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: add GlobalKTable doc to streams.htmlUpdate streams.html with GlobalKTable docsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Matthias J. Sax, Guozhang WangCloses #2516 from dguy/global-tables-doc",2
KAFKA-4773; The Kafka build should run findbugsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2557 from cmccabe/KAFKA-4773,5
MINOR: Remove line for testing repartition topic name (#6488)With KIP-307 joined.name() is deprecated plus we don't need to test for repartition topic names.Reviewers: Matthias J. Sax <mjsax@apache.org>,3
MINOR: update system test readmeAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Guozhang WangCloses #487 from granders/minor-update-test-readme,5
"KAFKA-7734: Metrics tags should use LinkedHashMap to guarantee ordering (#6032)This pull request replaces HashMap with LinkedHashMap to guarantee ordering of metrics tags.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <guozhang@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>",1
"KAFKA-10173: Use SmokeTest for upgrade system tests (#8938)Replaces the previous upgrade test's trivial Streams appwith the commonly used SmokeTest, exercising many morefeatures. Also adjust the test matrix to test upgradingfrom each released version since 2.2 to the current branch.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
KAFKA-2812: improve consumer integration testsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Geoff AndersonCloses #500 from hachikuji/KAFKA-2812,5
KAFKA-1848; check consumer shutting down flag inside retry loop; reviewed by Guozhang Wang,1
"KAFKA-5136: move coordinatorEpoch from WriteTxnMarkerRequest to TxnMarkerEntryMoving the coordinatorEpoch from WriteTxnMarkerRequest to TxnMarkerEntry will generate fewer broker send requestsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #2925 from dguy/tc-write-txn-request-follow-up",1
kafka-1542 (trivail followup patch to fix NullPointerException); normal IOException in the new producer is logged as ERROR; patched by Jun Rao,0
"KAFKA-8724; Improve range checking when computing cleanable partitions (#7264)This patch contains a few improvements on the offset range handling when computing the cleanable range of offsets.1. It adds bounds checking to ensure the dirty offset cannot be larger than the log end offset. If it is, we reset to the log start offset.2. It adds a method to get the non-active segments in the log while holding the lock. This ensures that a truncation cannot lead to an invalid segment range.3. It improves exception messages in the case that an inconsistent segment range is provided so that we have more information to find the root cause.The patch also fixes a few problems in `LogCleanerManagerTest` due to unintended reuse of the underlying log directory.Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jun Rao <junrao@gmail.com>",1
MINOR: Add user overridden test logging eventsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1456 from guozhangwang/Kminor-test-logging,3
MINOR: Fix always pass unit test in MetadataRequestTest (#10033)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
MINOR: Remove some unused codes (#11935)`validateChars` and `BaseEnum` are used in old version of clients. Remove them.Reviewers: Luke Chen <showuon@gmail.com>,4
"KAFKA-4564: Add system test for pre-0.10 brokersAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2837 from mjsax/kafka-4564-fail-fast-test-stream-compatibility",3
Processor thread blocks due to infinite loop during fetch response send; patched by Sriram Subramanian; reviewed by Jun Rao; kafka-756,5
MINOR: Align the UID inside/outside container (#9652)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-5654; add materialized count, reduce, aggregate to KGroupedStreamAdd overloads of `count`, `reduce`, and `aggregate` that are `Materialized` to `KGroupedStream`.Refactor common parts between `KGroupedStream` and `WindowedKStream`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3827 from dguy/kafka-5654",5
"KAFKA-10081: remove an unused local variable to pass spotbugsMain check (#8774)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Clearer field names for ProducerIdsRecord and related classes (#11747)The current naming of the fields in `ProducerIdsRecord` is a little confusing in regard to whether the block range was inclusive or exclusive. This patch tries to improve naming to make this clearer. In the record class, instead of `ProducerIdsEnd`, we use `NextProducerId`. We have also updated related classes such as `ProducerIdsBlock.java` with similar changes.Reviewers: dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>",4
TRIVIAL: provide clearer error in describe group when group is inactiveAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #502 from hachikuji/trivial-consumer-groups-fix,0
KAFKA-1366 Multiple Unit Test failures with new producer; reviewed by Neha Narkhede,1
KAFKA-12777: Fix a potential NPE in AutoTopicCreationManagerReviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-6472 - Fix WordCount example code error (#4538)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",0
"KAFKA-5986; Streams State Restoration never completes when logging is disabledWhen logging is disabled and there are state stores the task never transitions from restoring to running. This is because we only ever check if the task has state stores and return false on initialization if it does. The check should be if we have changelog partitions, i.e., we need to restore.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, tedyu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3983 from dguy/restore-test",3
"KAFKA-14107: Upgrade Jetty version for CVE fixes (#12440)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Aaron Freeland <afreeland@gmail.com>",0
"KAFKA-5970; Use ReentrantLock for delayed operation lock to avoid blockingAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3956 from rajinisivaram/KAFKA-5970-delayedproduce-deadlock",5
"KAFKA-9298: reuse mapped stream error in joins (#8504)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-6810; Enable dynamic update of SSL truststores (#4904)Enable broker's SSL truststores to be dynamically updated using ConfigCommand in the same way as keystores are updated.,5
MINOR: Fix typos in KStream javadoc (#4550)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
kafka-1367; Broker topic metadata not kept in sync with ZooKeeper; patched by Ashish Singh; reviewed by Jun Rao,5
"KAFKA-2453: Enable new consumer in EndToEndLatencyAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Gwen Shapira, Jason GustafsonCloses #158 from benstopford/KAFKA-2453b",1
"KAFKA-9771: Port patch for inter-worker Connect SSL from Jetty 9.4.25 (#8369)For reasons outlined in https://issues.apache.org/jira/browse/KAFKA-9771we can't upgrade to a version of Jetty with the bug fixed, or downgrade to one prior to the introduction of the bug. Luckily, the actual fix is pretty straightforward and can be ported over to Connect for use until it's possible to upgrade to a version of Jetty with that bug fixed: https://github.com/eclipse/jetty.project/pull/4404/files#diff-58640db0f8f2cd84b7e653d1c1540913R2188-R2193The changes here have been verified locally; a test with multiple certificates/multiple hostnames will be submitted in a follow up. Reviewers: Jeff Huang <47870461+jeffhuang26@users.noreply.github.com>, Konstantine Karantasis <konstantine@confluent.io>",5
HOTFIX: testInitTransactionTimeout should use prepareResponse instead of respond (#8179)We have seen a flaky behavior due to using #respond instead of #prepareResponse call for the txn test.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
KAFKA-736 Add an option to the 0.8 producer to mimic 0.7 producer behavior; reviewed by Jun Rao and Sriram Subramanian,1
"MINOR: update upgrade notes with regard to KIP-149 (#4439)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>",5
"KAFKA-9633: Ensure ConfigProviders are closed (#8204)ConfigProvider extends Closeable, but were not closed in the following contexts:* AbstractConfig* WorkerConfigTransformer* WorkerThis commit ensures that ConfigProviders are close in the above contexts. It also adds MockFileConfigProvider.assertClosed()Gradle executes test classes concurrently, so MockFileConfigProvidercan't simply use a static field to hold its closure state.Instead use a protocol whereby the MockFileConfigProvider is configuredwith some unique ket identifying the test which also used when callingassertClosed().Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-13133: Replace EasyMock and PowerMock with Mockito for AbstractHerderTest (#12473)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Yash Mayya <yash.mayya@gmail.com>Co-authored-by: wycccccc <493172422@qq.com>Co-authored-by: wycccccc <43372856+wycccccc@users.noreply.github.com>",1
"MINOR: Add links to connector configs in TOC (#11794)Reviewers: Luke Chen <showuon@gmail.com>, Andrew Eugene Choi <andrew.choi@uwaterloo.ca>",5
MINOR: Stateless transformation documentationNeeds to come after https://github.com/apache/kafka/pull/3701Originally reviewed as part of #3490.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3711 from enothereska/minor-docs-stateless,2
KAFKA-3916; Check for disconnects properly before sending from the controllerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1734 from hachikuji/KAFKA-3916,5
KAFKA-3683; Add file descriptor recommendation to ops guideAdding sizing recommendations for file descriptors to the ops guide.Author: Dustin Cote <dustin@confluent.io>Author: Dustin Cote <dustin@dustins-mbp.attlocal.net>Reviewers: Gwen ShapiraCloses #1353 from cotedm/KAFKA-3683 and squashes the following commits:8120318 [Dustin Cote] Adding file descriptor sizing recommendations0908aa9 [Dustin Cote] Merge https://github.com/apache/kafka into trunk32315e4 [Dustin Cote] Merge branch 'trunk' of https://github.com/cotedm/kafka into trunk13309ed [Dustin Cote] Update links for new consumer API4dcffc1 [Dustin Cote] Update links for new consumer API,1
"MINOR: Follow-up improvements for KIP-266 (#5084)This patch contains a few follow-up improvements/cleanup for KIP-266:- Add upgrade notes- Add missing `commitSync(Duration)` API- Improve timeout messages and fix some naming inconsistencies- Various small cleanupsReviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Prohibit setting StreamsConfig commit.interval.ms to a negative value (#5809)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-5833: Reset thread interrupt state in case of InterruptedExceptionAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3841 from mjsax/kafka-5833-interrupts",5
"MINOR: Update dependencies for 0.11Worth special mention:1. Update Scala to 2.11.11 and 2.12.22. Update Gradle to 3.53. Update ZooKeeper to 3.4.104. Update reflections to 0.9.11, which:    * Switches to jsr305 annotations with a provided scope    * Updates Guava from 18 to 20    * Updates javaassist from 3.18 to 3.21There’s a separate PR for updating RocksDb, soI didn’t include that here.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2872 from ijuma/update-deps-for-0.11",5
"KAFKA-8220; Avoid kicking out static group members through rebalance timeout (#6666)To make static consumer group members more persistent, we want to avoid kicking out unjoined members through rebalance timeout. Essentially we allow static members to participate in a rebalance using their old subscription without sending a JoinGroup. The only catch is that an unjoined static member might be the current group leader, and we may need to elect a different leader.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2691: Improve handling of authorization failure during metadata refreshAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun RaoCloses #394 from hachikuji/KAFKA-2691,5
"HOTFIX: Consumer offsets not properly loaded on coordinator failoverAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2436 from hachikuji/hotfix-offset-deletion",4
MINOR: Upgrade to Jackson 2.9.7 (#5662)This contains important fixes:https://github.com/FasterXML/jackson/wiki/Jackson-Release-2.9.7Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-171 Do a single write for request sends.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205313 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10826; Ensure raft io thread respects linger timeout (#9716)When there are no pending operations, the raft IO thread can block indefinitely waiting for a network event. We rely on asynchronous wakeups in order to break the blocking wait in order to respond to a scheduled append. The current logic already does this, but only for the case when the linger time has been completed during the call to `scheduleAppend`. It is possible instead that after making one call to `scheduleAppend` to start the linger timer, the application does not do any additional appends. In this case, we still need the IO thread to wakeup when the linger timer expires. This patch fixes the problem by ensuring that the IO thread gets woken up after the first append which begins the linger timer.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-8347: Choose next record to process by timestamp (#6719)When choosing the next record to process, we should look at the head record's timestamp of each partition and choose the lowest rather than choosing the lowest of the partition's streamtime.This change effectively makes RecordQueue return the timestamp of the head record rather than its streamtime. Streamtime is removed (replaced) from RecordQueue as it was only being tracked in order to choose the next partition to poll from.Reviewers: Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",4
HOTFIX: Fix incorrect version used for group metadata versionAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #424 from hachikuji/hotfix-metadata-storage,5
"MINOR: Updating files with latest release 2.7.0 (#9772)Changes to trunk for the 2.7.0 release. Updating dependencies.gradle, Dockerfile, and vagrant/bash.shReviewers: Matthias J. Sax <mjsax@apache.org>",2
MINOR: Update LICENSE-binary (#12051)Updates the license file.Reviewer: Bill Bejeck <bbejeck@apache.org>,2
"KAFKA-10869: Gate topic IDs behind IBP 2.8 (KIP-516) (#9814)Topics processed by the controller and topics newly created will only be given topic IDs if the inter-broker protocol version on the controller is greater than 2.8. This PR also adds a kafka config to specify whether the IBP is greater or equal to 2.8. System tests have been modified to include topic ID checks for upgrade/downgrade tests. This PR also adds a new integration test file for requests/responses that are not gated by IBP (ex: metadata) Reviewers: dengziming <dengziming1993@gmail.com>, Lucas Bradstreet <lucas@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
Use zkUtils instead of zkClient in AdminUtilsAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2888 from baluchicken/KAFKA-5103,1
"KAFKA-8933; Fix NPE in DefaultMetadataUpdater after authentication failure (#7682)This patch fixes an NPE in `DefaultMetadataUpdater` due to an inconsistency in event expectations. Whenever there is an authentication failure, we were treating it as a failed update even if was from a separate connection from an inflight metadata request. This patch fixes the problem by making the `MetadataUpdater` api clearer in terms of the events that are handled.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-10134 Follow-up: Set the re-join flag in heartbeat failure (#9354)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-12980; Return empty record batch from Consumer::poll when position advances due to aborted transactions (#11046)Return empty record batch from Consumer::poll when position advances due to aborted transactions or control records. This is useful for reads to the end of a topic that contains aborted or empty transactions. If an aborted transaction is at the end of the topic, the consumer can now be expected to return from `poll` if it advances past that aborted transaction, and users can query the consumer's latest `position` for the relevant topic partitions to see if it has managed to make it past the end of the topic (or rather, what was the end of the topic when the attempt to read to the end of the topic began).Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Rework error messages in ConsumerGroupCommand (#7445)Distinguish invalid and not found groupId cases in consumer group command.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-1081 Clean up shell scripts. Removed re-run of failed command. Use exec instead of subprocess execution.,1
KAFKA-12539; Refactor KafkaRaftCllient handleVoteRequest to reduce cyclomatic complexity (#10393)1. Add `canGrantVote` to `EpochState`2. Move the if-else in `KafkaRaftCllient.handleVoteRequest` to `EpochState`3. Add unit tests for `canGrantVote`Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Skip fsync on parent directory to start Kafka on ZOS (#11793)Reviewers: Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",5
"KAFKA-4481: relax streams api type contraintsMake appropriate methods contravariant in key and value types.Author: Xavier Léauté <xavier@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2205 from xvrl/streams-contravariance",5
"KAFKA-10018: Change command line tools from /bin/sh to /bin/bash (#8692)Reviewers: Tom Bentley @tombentley, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@confluent.io>, Colin P. McCabe <cmccabe@apache.org>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: add option to rebuild source for system tests (#6656)Reviewers: Jason Gustafson <jason@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Adding a constant to denote UNKNOWN leader in LeaderAndEpoch (#11477)Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: make controller helper methods privateAuthor: Onur Karaman <okaraman@linkedin.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4198 from onurkaraman/make-controller-helper-methods-private",1
"KAFKA-6944; Add system tests testing the new throttling behavior using older clients/brokersAdded two additional test cases to quota_test.py, which run between brokers and clients with different throttling behaviors. More specifically,1. clients with new throttling behavior (i.e., post-KIP-219) and brokers with old throttling behavior (i.e., pre-KIP-219)2. clients with old throttling behavior and brokers with new throttling behaviorAuthor: Jon Lee <jonlee@linkedin.com>Author: Dong Lin <lindong28@gmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5294 from jonlee2/kafka-6944",2
"KAFKA-2974; `==` is used incorrectly in a few places in Java codeA few issues found via static analysis.Author: Edward Ribeiro <edward.ribeiro@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira, Sriharsha Chintalapani, Guozhang WangCloses #652 from ijuma/use-equals-instead-of-==",1
"MINOR: Expose window store sequence numberguozhangwang mjsax enothereskaCurrently, Kafka Streams does not have a util to get access to the sequence number added to the key of windows state store changelogs.  I'm interested in exposing it so the the contents of a changelog topic can be 1) inspected for debugging purposes and 2) saved to text file and loaded from text fileAuthor: Roger Hoover <roger.hoover@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1501 from theduderog/expose-seq-num",5
"KAFKA-12888; Add transaction tool from KIP-664 (#10814)This patch adds the transaction tool specified in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. This includes all of the logic for describing transactional state and for aborting transactions. The only thing that is left out is the `--find-hanging` implementation, which will be left for a subsequent patch.Reviewers: Boyang Chen <boyang@apache.org>, David Jacot <djacot@confluent.io>",5
"KAFKA-8804: Secure internal Connect REST endpoints (#7310)Implemented KIP-507 to secure the internal Connect REST endpoints that are only for intra-cluster communication. A new V2 of the Connect subprotocol enables this feature, where the leader generates a new session key, shares it with the other workers via the configuration topic, and workers send and validate requests to these internal endpoints using the shared key.Currently the internal `POST /connectors/<connector>/tasks` endpoint is the only one that is secured.This change adds unit tests and makes some small alterations to system tests to target the new `sessioned` Connect subprotocol. A new integration test ensures that the endpoint is actually secured (i.e., requests with missing/invalid signatures are rejected with a 400 BAD RESPONSE status).Author: Chris Egerton <chrise@confluent.io>Reviewed: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-3375; Suppress deprecated warnings where reasonable and tweak compiler settings* Fix and suppress number of unchecked warnings (except for Kafka Streams)* Add `SafeVarargs` annotation to fix warnings* Suppress unfixable deprecation warnings* Replace deprecated by non-deprecated usage where possible* Avoid reflective calls via structural types in Scala* Tweak compiler settings for scalac and javacOnce we drop Java 7 and Scala 2.10, we can tweak the compiler settings further so that they warn us about more things.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke, Gwen Shapira, Guozhang WangCloses #1042 from ijuma/kafka-3375-suppress-depreccated-tweak-compiler",1
HOTFIX: fix checkstyle in Streams system test (#7494)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"MINOR: Move FileConfigProvider to provider subpackage (#5194)This moves FileConfigProvider to the org.apache.common.config.provider package to more easily isolate provider implementations going forward.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
HOTFIX: check offset limits in streamtask when recovering KTable storeguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #947 from ymatsuda/hotfix2,0
"KAFKA-2603: Add timeout arg to ConsoleConsumer for new consumerAdded --timeout-ms argument to ConsoleConsumer that works with both old and new consumer. Also modified ducktape ConsoleConsumer service to use this arg instead of consumer.timeout.ms config that works only with the old consumer.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Aditya Auradkar, Ismael Juma, Guozhang WangCloses #274 from rajinisivaram/KAFKA-2603",5
"KAFKA-7918: Inline generic parameters Pt. III: in-memory window store (#6328)Third (and final) PR in series to inline the generic parameters of the following bytes stores:[Pt. I] InMemoryKeyValueStore[Pt. II] RocksDBWindowStore[Pt. II] RocksDBSessionStore[Pt. II] MemoryLRUCache[Pt. II] MemoryNavigableLRUCache[x] InMemoryWindowStoreReviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1164 kafka should depend on snappy 1.0.5 (instead of 1.0.4.1); reviewed by Neha Narkhede,2
"MINOR: Replace Java 14 with Java 15 in the README (#9298)We have been testing with the Java 15 release candidate for a few weeks andit has now been declared final.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, David Jacot <djacot@confluent.io>, Lee Dongjin <dongjin@apache.org>",5
MINOR: Install missing 'tc' utility - iproute2 for systemtests (#11764)Signed-off-by: Michal T <mtoth@redhat.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"KAFKA-2532; Remove Consumer reference from rebalance callbackAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava, Onur Karaman, Guozhang WangCloses #203 from hachikuji/KAFKA-2532",5
KAFKA-13497: Add trace logging to RegexRouter (#11903)This patch adds runtime logging to the RegexRouter to show exactly which topics get routed where.Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-13952 fix RetryWithToleranceOperator to respect infinite retries configuration (#12478)Reviewers: Chris Egerton <chrise@aiven.io>,5
"MINOR: Remove explicit version checks in getErrorResponse methods (#7708)This patch removes the explicit version check pattern we used in `getErrorResponse`, which is a pain to maintain (as seen by KAFKA-9200). We already check that requests have a valid version range in the `AbstractRequest` constructor.Reviewers: Andrew Choi <andrewchoi5@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Move upgraded docs from site to kafak docs (#9532)Reviewers: Matthias J. Sax <mjsax@apache.org>,2
"MINOR: Rename baseTimestamp to firstTimestamp to clarify usageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3457 from hachikuji/rename-base-timestamp",5
"KAFKA-9181; Maintain clean separation between local and group subscriptions in consumer's SubscriptionState (#7941)Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4540: Suspended tasks that are not assigned to the StreamThread need to be closed before new active and standby tasks are createdDuring `onPartitionsAssigned` first close, and remove, any suspended `StandbyTasks` that are no longer assigned to this consumer.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2266 from dguy/kafka-4540",5
"KAFKA-9784: Add OffsetFetch to group concurrency test (#8383)As title suggested, consumers would first do an OffsetFetch before starting the normal processing. It makes sense to add it to the concurrent test suite to verify whether there would be a blocking behavior.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into trunkConflicts:core/src/main/scala/kafka/controller/KafkaController.scala,5
MINOR: replace hard-coding utf-8 with StandardCharsets.UTF_8 (#10079)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-5793; Tighten up the semantics of the OutOfOrderSequenceExceptionDescription of the solution can be found here: https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Exactly+Once+-+Solving+the+problem+of+spurious+OutOfOrderSequence+errorsAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3865 from apurvam/KAFKA-5793-tighten-up-out-of-order-sequence-v2",5
KAFKA-3424: Add CORS support to Connect REST APIAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #1099 from ewencp/cors-rest-support,1
MINOR: Fix how the last broker id is computed in `TestUtils.createBrokerConfigs` (#11237)The old logic only worked when the starting brokerId was 0. Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-4148; Support ListOffsetRequest v1 and search offsets by timestamp in consumer (KIP-79)Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1852 from becketqin/KAFKA-4148",5
"KAFKA-4432; Added support to supply custom message payloads to perf-producer script.Current implementation of ProducerPerformance creates static payload. This is not very useful in testing compression or when you want to test with production/custom payloads. So, we decided to add support for providing payload file as an input to producer perf test script.We made the following changes:1. Added support to provide a payload file which can have the list of payloads that you actually want to send.2. Moved payload generation inside the send loop for cases when payload file is provided.Following are the changes to how the producer-performance is evoked:1. You must provide ""--record-size"" or ""--payload-file"" but not both. This is because, record size cannot be guaranteed when you are using custom events.  e.g. ./kafka-producer-perf-test.sh --topic test_topic --num-records 100000 --producer-props bootstrap.servers=127.0.0.1:9092 acks=0 buffer.memory=33554432 compression.type=gzip batch.size=10240 linger.ms=10 --throughput -1 --payload-file ./test_payloads --payload-delimiter ,2. Earlier ""--record-size"" was a required config, now you must provide exactly one of ""--record-size"" or ""--payload-file"". Providing both will result in an error.3. Support for an additional parameter ""--payload-delimiter"" has been added which defaults to ""\n""Author: Sandesh K <sandesh.karkera@flipkart.com>Reviewers: dan norwood <norwood@confluent.io>, Jun Rao <junrao@gmail.com>Closes #2158 from SandeshKarkera/PerfProducerChanges",4
Closes #206 . *WONT FIX* - no new release planned for 0.8.2 branch,1
MINOR: Document how to create source streams and tablesOriginally reviewed as part of https://github.com/apache/kafka/pull/3490.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3701 from enothereska/minor-docs-create-source-streams,2
"MINOR: Streams doc example should not close store (#4667)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-5701: fix flaky RocksDBStore unit test1. Remove separate thread from test failing periodically due to race condition.2. Remove anonymous `AbstractNotifyingBatchingRestoreCallback` declare as concrete inner class `RocksDBBatchingRestoreCallback` and set as package private variable.  Class is static so it has to initialize it's dependency on `RocksDBStore`Author: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3640 from bbejeck/KAFKA-5701_fix_flaky_unit_test,3
"MINOR: Don’t send the DeleteTopicsRequest for invalid topic names (#4763)The invalid topic name is already handled locally so it is unnecessary to send the DeleteTopicsRequest. This PR adds a count to MockClient for testing.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
reverting r1178669 to fix KAFKA-147 kafka integration tests fail on a fresh checkout; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179487 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1311 Add a flag to turn off delete topic until it is stable; reviewed by Joel Koshy and Guozhang Wang,4
"KAFKA-9373: Reduce shutdown time by avoiding unnecessary loading of indexes (#8346)KAFKA-7283 enabled lazy mmap on index files by initializing indiceson-demand rather than performing costly disk/memory operations whencreating all indices on broker startup. This helped reducing the startuptime of brokers. However, segment indices are still created on closingsegments, regardless of whether they need to be closed or not.This is a cleaned up version of #7900, which was submitted by @efeg. Iteliminates unnecessary disk accesses and memory map operations whiledeleting, renaming or closing offset and time indexes.In a cluster with 31 brokers, where each broker has 13K to 20K segments,@efeg and team observed up to 2 orders of magnitude faster LogManagershutdown times - i.e. dropping the LogManager shutdown time of eachbroker from 10s of seconds to 100s of milliseconds.To avoid confusion between `renameTo` and `setFile`, I replaced thelatter with the more restricted updateParentDir` (it turns out that'sall we need).Reviewers: Jun Rao <junrao@gmail.com>, Andrew Choi <a24choi@edu.uwaterloo.ca>Co-authored-by: Adem Efe Gencer <agencer@linkedin.com>Co-authored-by: Ismael Juma <ismael@juma.me.uk>",2
KAFKA-3463: change default receive buffer size for consumer to 64KAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #1140 from hachikuji/KAFKA-3463,5
KAFKA-2614; No more clients can connect after `TooManyConnectionsException` threshold (max.connections.per.ip) is reached* Call `ConnectionQuotas.decr` when calling `Selector.close` and when disconnections happen.* Expand `SocketServerTest` to test for this and to close sockets.* Refactor and clean-up `SocketServer` and `Acceptor` to make the code easier to understand.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #288 from ijuma/kafka-2614-connection-count-not-updated,5
"KAFKA-8878: Fix flaky test AssignedStreamsTasksTest#shouldCloseCleanlyWithSuspendedTaskAndEOS (#7302)The previous approach to testing KAFKA-8412 was to look at the logs anddetermine if an error occurred during close. There was no direct way todetect than an exception occurred because the exception was eaten inAssignedTasks.close. In the PR for that ticket (#7207) it wasacknowledged that this was a brittle way to test for the exception. Wenow see occasional failures because an unrelated ERROR level log entryis made while closing the task.This change eliminates the brittle log checking by rethrowing any timean exception occurs in close, even when a subsequent unclean closesucceeds. This has the potential benefit of uncovering other supressedexceptions down the road.I've verified that even with us rethrowing on closeUnclean that alltests pass.Reviewers: Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",4
"MINOR: Fix some bugs with UNREGISTER_BROKERFix some bugs in the KRaft unregisterBroker API and add a junit test.1. kafka-cluster-tool.sh unregister should fail if no broker ID is passed.2. UnregisterBrokerRequest must be marked as a KRaft broker API so that KRaft brokers can receive it.3. KafkaApis.scala must forward UNREGISTER_BROKER to the controller.Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",5
"Fixes #8198 KStreams testing docs use non-existent method pipe (#6678)Minor fix of #8198 apache/kafka-site#210Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"kafka-1171; Gradle build for Kafka; patched by David Arthur, Joe Stein, Chris Freeman and Jun Rao; reviewed by Guozhang Wang, Joel Koshy and Neha Narkhede",5
"KAFKA-2443 KAFKA-2567; Expose windowSize on Rate; - Throttle time should not return NaNThis is a followup ticket from KAFKA-2084 to improve the windowSize calculation in Quotas. I've made the following changes:1. Added a windowSize function on Rate2. Calling Rate.windowSize in ClientQuotaManager to return the exact window size to use when computing the delay time.3. Changed the window size calculation subtly. The current calculation had a bug wherein, it used the number of elapsed seconds from the ""lastWindowSeconds"" of the most recent Sample object. However, the lastWindowSeconds is the time when the sample is created.. this causes an issue because it implies that the current window elapsed time is always ""0"" when the sample is created. This is incorrect as demonstrated in a testcase I added in MetricsTest. I've fixed the calculation to count the elapsed time from the ""oldest"" sample in the set since that gives us an accurate value of the exact amount of time elapsedAuthor: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>Closes #213 from auradkar/K-2443",2
"MINOR: add log indicating the suppression time (#6260)Reviewer: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Fix generics in KStream.groupBy(...)The `KStream.groupBy(..)` calls don't change the value, only the key, so they don't need the type param `V1` as the new stream will always be of type `KStream<K1, V>`.The `Serde` in the overloaded `groupBy` should have a type param of  `V` to match the returned `KStream`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #1584 from dguy/kstream-generics",2
"TRIVIAL: Replace ""it's"" with ""its"" where appropriateNo Jira ticket created, as the Contributing Code Changes doc says it's not necessary for javadoc typo fixes.Author: Magnus Reftel <magnus.reftel@skatteetaten.no>Reviewers: Gwen ShapiraCloses #186 from magnusr/feature/its",0
"MINOR: Use explicit construction of clients in IntegrationTestHarness (#5443)Pre-initialization of clients in IntegrationTestHarness is a cause of significant confusion and has resulted in a bunch of inconsistent client creation patterns. This patch requires test cases to create needed clients explicitly and makes the creation logic more consistent.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6412 Improve synchronization in CachingKeyValueStore methodsCurrently CachingKeyValueStore methods are synchronized at method level.It seems we can use read lock for getter and write lock for put / delete methods.For getInternal(), if the underlying thread is streamThread, the getInternal() may trigger eviction. This can be handled by obtaining write lock at the beginning of the method for streamThread.The jmh patch is attached to JIRA:https://issues.apache.org/jira/secure/attachment/12905140/6412-jmh.v1.txtAuthor: tedyu <yuzhihong@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #4372 from tedyu/6412",5
"KAFKA-1097 Race condition while reassigning low throughput partition leads to incorrect ISR information in zookeeper; reviewed by Jun Rao, Guozhang Wang",5
"MINOR: Update consumer javadoc for position method (#5100)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7671: Stream-Global Table join should not reset repartition flag (#5959)This PR fixes an issue reported from a user. When we join a KStream with a GlobalKTable we should not reset the repartition flag as the stream may have previously changed its key, and the resulting stream could be used in an aggregation operation or join with another stream which may require a repartition for correct results.I've added a test which fails without the fix.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-673 The logic that controls whether to run recovery on the log is reversed. Reviewed by Neha.,2
KAFKA-2313: javadoc fix for KafkaConsumer deserialization; reviewed by Guozhang Wang,0
"KAFKA-7660: Fix child sensor memory leak (#5974)A heap dump provided by Patrik Kleindl in https://issues.apache.org/jira/browse/KAFKA-7660 identifies the childrenSensors map in Metrics as keeping references to sensors alive after they have been removed.This PR fixes it and adds a test to be sure.Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Clean up to avoid errors in dynamic broker config tests (#5486)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Improve test assertions for IQv2 (#11828)Reviewer: Bill Bejeck <bbejeck@apache.org>,3
"KAFKA-12983: reset needsJoinPrepare flag before rejoining the group (#10986)The #onJoinPrepare callback is not always invoked before a member (re)joins the group, but only once when it first enters the rebalance. This means that any updates or events that occur during the join phase can be lost in the internal state: for example, clearing the SubscriptionState (and thus the ""ownedPartitions"" that are used for cooperative rebalancing) after losing its memberId during a rebalance. We should reset the needsJoinPrepare flag inside the resetStateAndRejoin() method. Reviewers: Guozhang Wang <guozhang@apache.org>, Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-4139; Reset findCoordinatorFuture when brokers are unavailableAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma, Jason GustafsonCloses #1831 from rajinisivaram/KAFKA-4139",5
KAFKA-8942: Document RocksDB metricsAuthor: Bruno Cadonna <bruno@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #7490 from cadonna/AK8942-docs-rocksdb_metricsMinor comments,5
"KAFKA-12988 Asynchronous API support for RemoteLogMetadataManager add/update methods. (#11033)Added asynchronous API support for RemoeLogMetadataManager add/update/put methods.Implemented the changes on default topic based RemoteLogMetadataManager.Refactored the respective tests to cover the introduced asynchronous APIs.Reviewers: Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",3
"KAFKA-5756; Connect WorkerSourceTask synchronization issue on flushAuthor: oleg <oleg@nexla.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3702 from oleg-smith/KAFKA-5756",5
"KAFKA-13990: KRaft controller should return right features in ApiVersionResponse (#12294)Previously, the KRaft controller was incorrectly reporting an empty feature set inApiVersionResponse. This was preventing any multi-node clusters from being upgraded viakafka-features.sh, since they would incorrectly believe that metadata.version was not a supportedfeature. This PR adds a regression test for this bug, KRaftClusterTest.testUpdateMetadataVersion.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",5
kafka-1414; Speedup broker startup after hard reset; patched by Anton Karamanov; reviewed by Jay Kreps and Jun Rao,1
"KAFKA-7568; Return leader epoch in ListOffsets response (#5855)As part of KIP-320, the ListOffsets API should return the leader epoch of any fetched offset. We either get this epoch from the log itself for a timestamp query or from the epoch cache if we are searching the earliest or latest offset in the log. When handling queries for the latest offset, we have elected to choose the current leader epoch, which is consistent with other handling (e.g. OffsetsForTimes).Reviewers: Jun Rao <junrao@gmail.com>",1
MINOR: disable round_trip_fault_test system tests for Raft quorums (#10249)The KIP-500 early access release will not support creating a partition with a manualpartition assignment that includes a broker that is not currently online. This patch disablessystem tests for Raft-based metadata quorums where the test depends on this functionalityto pass.Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
KAFKA-8227 DOCS Fixed missing links duality of streams tables (#6625)Fixed missing links duality of streams tablesReviewers: Jim Galasyn <jim.galasyn@confluent.io> Bill Bejeck <bbejeck@gmail.com>,5
"MINOR: Comment spelling nit`CYGINW` probably should be `CYGWIN`*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Michael Gruben Trejo <mgrubentrejo@linkedin.com>Reviewers: Gwen ShapiraCloses #6523 from mgrubent/patch-1",2
"KAFKA-8179: Part 3, Add PartitionsLost API for resetGenerations and metadata/subscription change (#6884)1. Add onPartitionsLost into the RebalanceListener, which will be triggered when the consumer found that the generation is reset due to fatal errors in response handling.2. Semantical behavior change: with COOPERATIVE protocol, if the revoked / lost partitions are empty, do not trigger the corresponding callback at all. For added partitions though, even if it is empty we would still trigger the callback as a way to notify the rebalance event; with EAGER protocol, revoked / assigned callbacks are always triggered.The ordering of the callback would be the following:a. Callback onPartitionsRevoked / onPartitionsLost triggered.b. Update the assignment (both revoked and added).c. Callback onPartitionsAssigned triggered.In this way we are assured that users can still access the partitions being revoked, whereas they can also access the partitions being added.3. Semantical behavior change (KAFKA-4600): if the rebalance listener throws an exception, pass it along all the way to the consumer.poll caller, but still completes the rest of the actions. Also, the newly assigned partitions list does not gets affected with exception thrown since it is just for notifying the users.4. Semantical behavior change: the ConsumerCoordinator would not try to modify assignor's returned assignments, instead it will validate that assignments and set the error code accordingly: if there are overlaps between added / revoked partitions, it is a fatal error and would be communicated to all members to stop; if revoked is not empty, it is an error indicate re-join; otherwise, it is normal.5. Minor: with the error code removed from the Assignment, ConsumerCoordinator will request re-join if the revoked partitions list is not empty.6. Updated ConsumerCoordinatorTest accordingly. Also found a minor bug in MetadataUpdate that removed topic would still be retained with null value of num.partitions.6. Updated a few other flaky tests that are exposed due to this change.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10727; Handle Kerberos error during re-login as transient failure in clients (#9605)We use a background thread for Kerberos to perform re-login before tickets expire. The thread performs logout() followed by login(), relying on the Java library to clear and then populate credentials in Subject. This leaves a timing window where clients fail to authenticate because credentials are not available. We cannot introduce any form of locking since authentication is performed on the network thread. So this commit treats NO_CRED as a transient failure rather than a fatal authentication exception in clients.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
"MINOR: Refactor high watermark access and validation (#7055)The purpose of this patch is to restrict the paths for updating and accessing the high watermark and the last stable offset. By doing so, we can validate that these offsets always remain within the range of the log. We also ensure that we never expose `LogOffsetMetadata` unless it is fully materialized. Finally, this patch makes a few naming changes. In particular, we remove the `highWatermark_=` and `highWatermarkMetadata_=` which are both misleading and cumbersome to test.Reviewers: David Arthur <mumrah@gmail.com>",3
MINOR:  MINOR: Remove redundant error log in ChannelBuilder (#12539)Remove redundant error log in ChannelBuilderReviewers: Luke Chen <showuon@gmail.com>,2
KAFKA-8806 Reduce calls to validateOffsetsIfNeeded (#7222)Only check if positions need validation if there is new metadata. Also fix some inefficient java.util.stream code in the hot path of SubscriptionState.,0
"KAFKA-3029: Mark TopicPartition and OffsetAndMetadata as SerializablePatch for issue KAFKA-3029Given that the fix is trivial no new test case is needed. I have run the test suite using gradle (as mentioned  https://github.com/apache/kafka/blob/trunk/README.md) and suite runs clean.Author: Praveen Devarao <praveendrl@in.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Gwen Shapira <cshapi@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #711 from praveend/tp_serializable_branch",5
MINOR: Fix typo in ssl.client.auth config doc description (#8956)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
ConsumerOffsetChecker now works with hostnames (in addition to IP) in the brokers/ids zk path; KAFKA-549; patched by Bob Cotton; reviewed by Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1395809 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-10562: Properly invoke new StateStoreContext init (#9388)* all wrapping stores should pass StateStoreContext init through to the same  method on the wrapped store and not translate it to ProcessorContext init* base-level stores should handle StateStoreContext init so that callers passing  a non-InternalProcessorContext implementation will be able to initialize the store* extra tests are added to verify the desired behaviorReviewers: Guozhang Wang <guozhang@apache.org>,1
Restore .gitignoregit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180987 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10123; Fix incorrect value for AWAIT_RESET#hasPosition (#8841)## BackgroundWhen a partition subscription is initialized it has a `null` position and is in the INITIALIZING state. Depending on the consumer, it will then transition to one of the other states. Typically a consumer will either reset the offset to earliest/latest, or it will provide an offset (with or without offset metadata). For the reset case, we still have no position to act on so fetches should not occur.Recently we made changes for KAFKA-9724 (#8376) to prevent clients from entering the AWAIT_VALIDATION state when targeting older brokers. New logic to bypass offset validation as part of this change exposed this new issue.## Bug and FixIn the partition subscriptions, the AWAIT_RESET state was incorrectly reporting that it had a position. In some cases a position might actually exist (e.g., if we were resetting offsets during a fetch after a truncation), but in the initialization case no position had been set. We saw this issue in system tests where there is a race between the offset reset completing and the first fetch request being issued.Since AWAIT_RESET#hasPosition was incorrectly returning `true`, the new logic to bypass offset validation was transitioning the subscription to FETCHING (even though no position existed).The fix was simply to have AWAIT_RESET#hasPosition to return `false` which should have been the case from the start. Additionally, this fix includes some guards against NPE when reading the position from the subscription.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Don't generate unnecessary strings for debug logging in FetchSessionHandler (#7394)Profiling while benchmarking shows unnecessary calls to`responseDataToLogString` in FetchSessionHandler when logging was set toINFO level. This leads to 1.47% of the JVM CPU time going to this method.Fix it by checking if debug logging is enabled.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
MINOR: Fix documentation for updateCurrentReassignment (#7611)The function KafkaController.updateCurrentReassignment doesn't return any value. Fix the documentation to reflect that.,2
"KAFKA-13207: Skip truncation on fetch response with diverging epoch if partition removed from fetcher (#11221)AbstractFetcherThread#truncateOnFetchResponse is used with IBP 2.7 and above to truncate partitions based on diverging epoch returned in fetch responses. Truncation should only be performed for partitions that are still owned by the fetcher and this check should be done while holding partitionMapLock to ensure that any partitions removed from the fetcher thread are not truncated. Truncation will be performed by any new fetcher that owns the partition when it restarts fetching.Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Add Timer to simplify timeout bookkeeping and use it in the consumer (#5087)We currently do a lot of bookkeeping for timeouts which is both error-prone and distracting. This patch adds a new `Timer` class to simplify this logic and control unnecessary calls to system time. In particular, this helps with nested timeout operations. The consumer has been updated to use the new class.Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-9437; Make the Kafka Protocol Friendlier with L7 Proxies [KIP-559] (#7994)This PR implements the KIP-559: https://cwiki.apache.org/confluence/display/KAFKA/KIP-559%3A+Make+the+Kafka+Protocol+Friendlier+with+L7+Proxies- it adds the Protocol Type and the Protocol Name fields in JoinGroup and SyncGroup API;- it validates that the fields are provided by the client when the new version of the API is used and ensure that they are consistent. it errors out otherwise;- it validates that the fields are consistent in the client and errors out otherwise;- it adds many tests related to the API changes but also extends the testing coverage of the requests/responses themselves.- it standardises the naming in the coordinator. now, `ProtocolType` and `ProtocolName` are used across the board in the coordinator instead of having a mix of protocol type, protocol name, subprotocol, protocol, etc.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix logged timeout in KafkaProducer.close() (#4623)The log line says `ms`, but the actual value could represent adifferent time unit depending on what the user provided.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
Log flush should complete upon broker shutdown; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-126git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1175966 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10564: only process non-empty task directories when internally cleaning obsolete state stores (#9373)Avoid continuous repeated logging by not trying to clean empty task directories, which are longer fully deleted during internal cleanup as of https://issues.apache.org/jira/browse/KAFKA-6647.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-8744: Update Scala API to give names to processors (#9738)As it's only API extension to match the java API with Named object with lots of duplication, I only tested the logic once.Reviewers: Bill Bejeck <bbejeck@apache.org>",2
"KAFKA-6914; Set parent classloader of DelegatingClassLoader same as the worker's (#5720)The parent classloader of the DelegatingClassLoader and therefore the classloading scheme used by Connect does not have to be fixed to the System classloader.Setting it the same as the one that was used to load the DelegatingClassLoader class itself is more flexible and, while in most cases will result in the System classloader to be used, it will also work in othr managed environments that control classloading differently (OSGi, and others).The fix is minimal and the mainstream use is tested via system tests.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-1062 Reading topic metadata from zookeeper leads to incompatible ordering of partition list; reviewed by Neha and Guozhang,5
MINOR: Replace tbd with the actual link for out-of-ordering data (#6035)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Fix typo in system tests Dockerfile (#11740)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"KAFKA-6376: preliminary cleanup (#4872)General cleanup of Streams code, mostly resolving compiler warnings and re-formatting.The regular testing suite should be sufficient.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4593; Don't throw IllegalStateException and die on task migrationAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3948 from mjsax/kafka-4593-illegal-state-exception-in-restore",5
kafka-1646; Improve consumer read performance for Windows; patched by Honghai Chen; reviewed by Jay Kreps and Jun Rao,1
"change to standardize on [%s,%d] for partition",4
HOTFIX: fix Kafka Streams upgrade note for broker backward compatibility (#7363)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"KAFKA-13914: Add command line tool kafka-metadata-quorum.sh (#12469) Add `MetadataQuorumCommand` to describe quorum status, I'm trying to use arg4j style command format, currently, we only support one sub-command which is ""describe"" and we can specify 2 arguments which are --status and --replication.```# describe quorum statuskafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --replicationReplicaIdLogEndOffsetLagLastFetchTimeMsLastCaughtUpTimeMsStatus  0        10                  0  -1                     -1                                 Leader  1        10                  0  -1                     -1                                 Follower2        10                  0  -1                     -1                                 Followerkafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --statusClusterId:                             fMCL8kv1SWm87L_Md-I2hgLeaderId:                             3002LeaderEpoch:                      2HighWatermark:                  10MaxFollowerLag:                 0MaxFollowerLagTimeMs:   -1CurrentVoters:                    [3000,3001,3002]CurrentObservers:              [0,1,2]# specify AdminClient propertieskafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config config.properties describe --status```Reviewers: Jason Gustafson <jason@confluent.io>",5
"kafka-2248; Use Apache Rat to enforce copyright headers; patched by Ewen Cheslack-Postava; reviewed by Gwen Shapira, Joel Joshy and Jun Rao",1
MINOR: Clean up in DeleteConsumerGroupTest even if test failsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3317 from rajinisivaram/MINOR-deleteconsumergrouptest-cleanup,5
"MINOR: Only start log dir fetcher after LeaderAndIsr epoch validation (#8460)Currently a `LeaderAndIsr` request with a stale leader epoch for some partition may still result in the starting of the log dir fetcher for that partition (if the future log exists). I am not sure if this causes any correctness problem since we don't use any state from the request to start the fetcher, but it seems unnecessary to rely on this side effect.Reviewers: Jun Rao <junrao@gmail.com>",1
"KAFKA-6072; User ZookeeperClient in GroupCoordinator and TransactionCoordinatorAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ted Yu <yuzhihong@gmail.com>, Jun Rao <junrao@gmail.com>Closes #4126 from omkreddy/KAFKA-6072-ZK-IN-GRoupCoordinator",1
KAFKA-12702: Fix NPE in networkListeners from BrokerServer (#10575)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
KAFKA-1432 followup - Fixing the shutdown sequence furthermore; reviewed by Neha Narkhede,0
"KAFKA-12752: Bump Jersey deps to 2.34 due to CVE-2021-28168 (#10636)The version of the Eclipse Jersey library brought as dependences,2.31, has a known vulnerability, CVE-2021-28168 (https://github.com/advisories/GHSA-c43q-5hpj-4crv).This replaces it with 2.34, which is fully compatible with2.31, except for bugs and vulnerabilities.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",0
MINOR: Deprecate LogConfig.CompactIt actually refers to the `delete` cleanup policy.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3634 from ijuma/fix-misleading-compact-log-config,5
"KAFKA-10644; Fix VotedToUnattached test error (#9503)This patch fixes a test a test case in `QuorumStateTest`. The method name is ""testVotedToUnattachedHigherEpoch,"" but the code initialized in the unattached state instead of the voted state.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-826 Make Kafka 0.8 depend on metrics 2.2.0 instead of 3.x; reviewed by Swapnil Ghike, Neha Narkhede, Matt Christiansen, Scott Carey",1
"MINOR: Fix typo ""transation"" in AddPartitionsToTxnRequest.json (#8557)Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-7873; Always seek to beginning in KafkaBasedLog (#6203)Explicitly seek KafkaBasedLog’s consumer to the beginning of the topic partitions, rather than potentially use committed offsets (which would be unexpected) if group.id is set or rely upon `auto.offset.reset=earliest` if the group.id is null.This should not change existing behavior but should remove some potential issues introduced with KIP-287 if `group.id` is not set in the consumer configurations. Note that even if `group.id` is set, we still always want to consume from the beginning.Reviewers: Jason Gustafson <jason@confluent.io>",5
HOTFIX: fix checkstyle error of RocksDBStoreTest and flaky RocksDBTimestampedStoreTest.shouldOpenExistingStoreInRegularMode (#8515)1. Fix broken build2. Fix flaky RocksDBTimestampedStoreTest.shouldOpenExistingStoreInRegularModeReviewers: Guozhang Wang <wangguoz@gmail.com>,5
"MINOR: Remove unused code in `LeaderAndIsr`, `ApiUtils` and `TopicMetadataRequest`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2145 from ijuma/unused-code-in-leader-and-isr",1
"KAFKA-13702: Connect RestClient overrides response status code on request failure (#12320)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",0
MINOR: Fix static membership documentation link in upgrade notes (#7001)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Fix a typo in a comment in config/server.properties (#4373),5
"HOTFIX: Use a true sentinel for `UseDefaultAcls`In 67fc2a91a6, we are using an empty collection and comparing viavalue equality, so if a user passes an empty collection, they willget the default ACLs instead of no ACLs. We fix that issue here.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini SivaramCloses #2829 from ijuma/zk-utils-default-acls-improvement and squashes the following commits:0846172 [Ismael Juma] Add missing import2dc84f3 [Ismael Juma] Simplify logic in `sensitivePath`8122f27 [Ismael Juma] Use a true sentinel instead of an empty collection for `UseDefaultAcls`",1
HOTFIX: Fix Properties.putAll compiler error when compiling with Java 11 (#6140),0
"KAFKA-13672: Race condition in DynamicBrokerConfig (#11920)Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
"MINOR: Update the README.md to include a note about GRADLE_USER_HOMETrying to build the source and publish it to internal Maven repo, I ran into an issue that I explain in the mailing list discussion here https://www.mail-archive.com/devkafka.apache.org/msg56359.html.The commit here updates the README.md to make a note that the GRADLE_USER_HOME environment variable plays a role in deciding which file to add the maven configs to.Author: Jaikiran Pai <jaikiran.pai@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1837 from jaikiran/readme-update-grade-user-home",5
"KAFKA-3442; Fix FileMessageSet iterator.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1112 from becketqin/KAFKA-3442",2
"KAFKA-9176: Retry on getting local stores from KafkaStreams (#8568)This PR fixes and improves two major issues:1. When calling KafkaStreams#store we can always get an InvalidStateStoreException, and even waiting for Streams state to become RUNNING is not sufficient (this is also how OptimizedKTableIntegrationTest failed). So I wrapped all the function with a Util wrapper that captures and retries on that exception.2. While trouble-shooting this issue, I also realized a potential bug in test-util's produceKeyValuesSynchronously, which creates a new producer for each of the record to send in that batch --- i.e. if you are sending N records with a single call, within that call it will create N producers used to send one record each, which is very slow and costly.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-2519; NetworkClient.close should remove node from inFlightRequestsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #193 from ijuma/kafka-2519-network-client-close-remove-in-flight,4
"KAFKA-9525: add enforceRebalance method to Consumer API (#8087)As described in KIP-568.Waiting on acceptance of the KIP to write the tests, on the off chance something changes. But rest assured unit tests are coming ⚡️Will also kick off existing Streams system tests which leverage this new API (eg version probing, sometimes broker bounce)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-840 Controller tries to perform preferred replica election on failover before state machines have started up; reviewed by Neha Narkhede,0
KAFKA-2678; partition level lag metrics can be negativeAuthor: Dong Lin <lindong@cis.upenn.edu>Author: Dong Lin <lindong28@gmail.com>Reviewers: Guozhang WangCloses #346 from lindong28/KAFKA-2678,5
"KAFKA-9190; Close connections with expired authentication sessions (#7723)This patch fixes a bug in `SocketServer` in the expiration of connections which have not re-authenticated quickly enough. Previously these connections were left hanging, but now they are properly closed and cleaned up. This was one cause of the flaky test failures in `EndToEndAuthorizationTest.testNoDescribeProduceOrConsumeWithoutTopicDescribeAcl`.Reviewers: Jason Gustafson<jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-6145: Add unit tests for assignments of only stateless tasks (#8713)Reviewers: John Roesler <vvcephei@apache.org>,3
"KAFKA-6650: Allowing transition to OfflineReplica state for replicas without leadership info (#4825)A partially deleted topic can end up with some partitions having no leadership info.For the partially deleted topic, a new controller should be able to finish the topic deletionby transitioning the rogue partition's replicas to OfflineReplica state.This patch adds logic to transition replicas to OfflineReplica state whose partitions haveno leadership info.Added a new test method to cover the partially deleted topic case.Reviewers: Jun Rao <junrao@gmail.com>",4
Fix typo in Resource in org.apache.kafka.trogdor (#5739)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"MINOR: AdminClient metadata manager should reset state on failureIf the internal metadata request fails, we must reset the state inside `AdminClientMetadataManager` or we will be stuck indefinitely in the `UPDATE_PENDING` state and have no way to fetch new metadata.Author: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5057 from hachikuji/fix-admin-client-metadata-update-failure",5
"KAFKA-1464; Add a throttling option to the Kafka replicationThis applies to Replication Quotasbased on KIP-73 [(link)](https://cwiki.apache.org/confluence/display/KAFKA/KIP-73+Replication+Quotas) originally motivated by KAFKA-1464.System Tests Run: https://jenkins.confluent.io/job/system-test-kafka-branch-builder/544/**This first PR demonstrates the approach**.**_Overview of Change_**The guts of this change are relatively small. Throttling occurs on both leader and follower sides. A single class tracks the throttled throughput in and out of each broker (**_ReplicationQuotaManager_**).On the follower side, the Follower Throttled Rate is calculated as fetch responses arrive. Then, before the next fetch request is sent, we check to see if the quota is violated, removing throttled partitions from the request if it is. This is all encapsulated in a few lines of code in the **_ReplicaFetcherThread_**. There is existing code to handle temporal back off, if the request ends up being empty.On the leader side it's a little more complex. When a fetch request arrives in the leader, it is built, partition by partition, in **_ReplicaManager.readFromLocalLog_**. As we put each partition into the fetch response, we check if the total size fits in the current quota. If the quota is exceeded, the partition will not be added to the fetch response. Importantly, we don't increase the quota at this point, we just check to see if the bytes will fit.Now, if there aren't enough bytes to send the response immediately, which is common if we're catching up and throttled, then the request will be put in purgatory. I've added some simple code to **_DelayedFetch_** to handle throttled partitions (throttled partitions are checked against the quota, rather than the messages available in the log).When the delayed fetch completes, and exits purgatory, _**ReplicaManager.readFromLocalLog**_ will be called again. This is why _**ReplicaManager.readFromLocalLog**_ does not actually increase the quota, it just checks whether enough bytes are available for a partition.Finally, when there are enough bytes to be sent, or the delayed fetch times out, the response will be sent. Before it is sent the throttled-outbound-rate is increased, based on the size of throttled partitions being sent. This is at the end of _**KafkaApis.handleFetchRequest**_, exactly where client quotas are recorded.There is an acceptance test which asserts the whole throttling process stabilises on the desired value. This covers a number of use cases including many-to-many replication. See **_ReplicationQuotaTest_**.Note:It should be noted that this protocol can over-request. The request is built, based on the quota at time t1 (_ReplicaManager.readFromLocalLog_). The bytes in the response are recorded at time t2 (end of _KafkaApis.handleFetchRequest_), where t2 > t1. For this reason I originally included an OverRequestedRate as a JMX metric, but testing has not seen revealed any obvious issue. Over-requesting is quickly compensated by subsequent requests, stabilising close to the quota value._**Main stuff left to do:**_- The fetch size is currently unbounded. This will be addressed in KIP-74, but we need to ensure this ensures requests don’t go beyond the throttle window.- There are two failures showing up in the system tests on this branch:  StreamsSmokeTest.test_streams (which looks like it fails regularly) and OffsetValidationTest.test_broker_rolling_bounce (which I need to look into)_**Stuff left to do that could be deferred:**_- Add the extra metrics specified in the KIP.- There are no system tests.- There is no validation for the cluster size / throttle combination that could lead to ISR dropoutsAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>Closes #1776 from benstopford/rep-quotas-v2",5
"MINOR: Bump system test version from 2.2.0 to 2.2.1 (#6873)Reviewers: Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
Use uniform convention for naming properties keys; kafka-648; patched by Sriram Subramanian; reviewed by Jun Rao,1
MINOR: Capture stderr in ConsumerPerformanceService.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #331 from ewencp/minor-capture-consumer-performance-stderr,2
MINOR: add dependency analysis debugging tasksAuthor: Arvind Thirunarayanan <athirunar@confluent.io>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>Closes #7694 from arvindth/ath-debugdeps-task,0
"MINOR: Update zstd to 1.4.5 (#8766)It improves decompression speed:>For x64 cpus, expect a speed bump of at least +5%, and up to +10% in favorable cases.>ARM cpus receive more benefit, with speed improvements ranging from +15% vicinity,>and up to +50% for certain SoCs and scenarios (ARM‘s situation is more complex due>to larger differences in SoC designs).See https://github.com/facebook/zstd/releases/tag/v1.4.5 for more details.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
"MINOR: Generate deprecated warning for static default quota configThe default client-id bandwidth quota config properties have been marked deprecated in the doc, but a warning may be useful before the property is removed in a future release.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3315 from rajinisivaram/MINOR-deprecate-staticquota",5
KAFKA-1910 Follow-up again; fix ListOffsetResponse handling for the expected error codes,0
HOTFIX: fix StreamTask.close()guozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #586 from ymatsuda/fix_streamtask_close,0
"KAFKA-7240: -total metrics in Streams are incorrect (#5467)Changes:1. Add org.apache.kafka.streams.processor.internals.metrics.CumulativeCount analogous to Count, but not a SampledStat2. Use CumulativeCount for -total metrics in streams instead of CountTesting strategy:Add a test in StreamsMetricsImplTest which fails on old, incorrect behaviorThe contribution is my original work and I license the work to the project under the project's open source license.Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
MINOR: Delete redudant tmp file (#11446)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
MINOR: docs should point to latest version (#5132)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"MINOR: use StoreBuilder in KStreamImpl rather than StateStoreSupplierAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3892 from dguy/cleanup-state-stores",4
KAFKA-13515: Fix KRaft config validation issues (#11577)Require that topics exist before topic configurations can be created for them.Merge the code from ConfigurationControlManager#checkConfigResource intoControllerConfigurationValidator to avoid duplication.Add KRaft support to DynamicConfigChangeTest.Split out tests in DynamicConfigChangeTest that don't require a cluster intoDynamicConfigChangeUnitTest to save test time.Reviewers: David Arthur <mumrah@gmail.com>,3
"KAFKA-14001: Migrate streams module to JUnit 5 - Part 1 (#12285)This pull request addresses https://issues.apache.org/jira/browse/KAFKA-14001. It is the first of a series of pull requests which address the move of Kafka Streams tests from JUnit 4 to JUnit 5.Reviewers: Divij Vaidya <diviv@amazon.com>, Bruno Cadonna <cadonna@apache.org>",1
HOTFIX: use ConsumedInternal in StreamsBuilder,1
KAFKA-13255: Use config.properties.exclude when mirroring topics (#11401)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"KAFKA-8736: Streams performance improvement, use isEmpty() rather than size() == 0 (#7164)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Increase maximum value of log.retention.size; patched by Elben Shira; reviewed by Jun Rao; KAFKA-285git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1294441 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13443: Kafka broker exits when OAuth enabled and certain configuration not specified (#11484)The sasl.oauthbearer.jwks.endpoint.retry.backoff.ms and sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms configuration options were added to the SaslConfig class but their default values were not added to KafkaConfig. As a result, when the OAuth validation feature is enabled in the broker and those two configuration values aren't explicitly provided by the user, the broker exits. This patch fixes the issue by defining them in the KafkaConfig class.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: Fix command examples in kafka-reassign-partitions.sh docs (#7583)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13214; Consumer should not reset state after retriable error in rebalance (#11231)Currently the consumer will reset state after any retriable error during a rebalance. This includes coordinator disconnects as well as coordinator changes. The impact of this is that rebalances get delayed since they will be blocked until the session timeout of the old memberId expires. The patch here fixes the problem by not resetting the member state after a retriable error.Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1443 Add delete topic option to topic commands; reviewed by Neha Narkhede,4
"KAFKA-3613: Consolidate TumblingWindows and HoppingWindows into TimeWindowsThis PR includes the same code as https://github.com/apache/kafka/pull/1261 but is rebased on latest trunk.Author: Michael G. Noll <michael@confluent.io>Reviewers: Matthias J. Sax, Guozhang WangCloses #1277 from miguno/KAFKA-3613-v2",5
"KAFKA-10455: Ensure that probing rebalances always occur (#9383)Add dummy data to subscriptionUserData to make sure thatit is different each time a member rejoins.Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>, John Roesler <vvcephei@apache.org>",1
"KAFKA-3728; EndToEndAuthorizationTest offsets_topic misconfiguredSet OffsetsTopicReplicationFactorProp to 3 like MinInSyncReplicasProp  Else a consumer was able to consume via assign but not via subscribe, so the testProduceAndConsume is now duplicated to check both pathsAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1425 from edoardocomar/KAFKA-3728",2
"KAFKA-3669; Add secondary constructor for KafkaConfig with a default value for doLog…value for doLogAuthor: Mark Grover <mark@apache.org>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1334 from markgrover/kafka-3669-trunk",1
MINOR: Convert Stream-StreamJoin Integration Test to TTD (#7752)Convert StreamStreamJoinIntegrationTest to TTD for more stable testing.Reviewers: Matthias J. Sax <mjsax@apache.org>,3
"MINOR: additional check to follower fetch handling  (#4433)add check to KafkaApis, add unit test specific to follower fetchdeveloped with @mimaisonReviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Make some constructors in admin package publicAdd a public create API that takes a Properties instance.Make the constructors for TopicDescription, TopicListingand TopicPartitionInfo public to enable AdminClientusers to write better tests.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3070 from cmccabe/publicapi",5
MINOR: Small fixes in docs/upgrade.html (#12239)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-12161; Support raft observers with optional id (#9871)We would like to be able to use `KafkaRaftClient` for tooling/debugging use cases. For this, we need the localId to be optional so that the client can be used more like a consumer. This is already supported in the `Fetch` protocol by setting `replicaId=-1`, which the Raft implementation checks for. We just need to alter `QuorumState` so that the `localId` is optional. The main benefit of doing this is that it saves tools the need to generate an arbitrary id (which might cause conflicts given limited Int32 space) and it lets the leader avoid any local state for these observers (such as `ReplicaState` inside `LeaderState`).Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>",5
KAFKA-12697: Add Global Topic and Partition count metrics to the Quorum Controller (#10679)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-5726; KafkaConsumer.subscribe() overload that takes just Pattern- changed the interface & implementations- updated tests to use the new method where applicableAuthor: Attila Kreiner <attila@kreiner.hu>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3669 from attilakreiner/KAFKA-5726",5
"MINOR: Move quickstart under streamsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3494 from enothereska/minor-quickstart-docsrename section name and bold font for section names",2
"KAFKA-3725; Update documentation with regards to XFSI've updated the ops documentation with information on using the XFS filesystem, based on LinkedIn's testing (and subsequent switch from EXT4).I've also added some information to clarify the potential risk to the suggested EXT4 options (again, based on my experience with a multiple broker failure situation).Author: Todd Palino <tpalino@linkedin.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Dana Powers <dana.powers@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1605 from toddpalino/trunk",1
MINOR: Add missing `@Override` to `KStreamImpl.through`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1216 from ijuma/add-missing-override-to-through,1
"KAFKA-10458; Updating controller quota does not work since Token Bucket (#9272)This PR fixes two issues that have been introduced by #9114.- When the metric was switched from Rate to TokenBucket in the ControllerMutationQuotaManager, the metrics were mixed up. That broke the quota update path.- When a quota is updated, the ClientQuotaManager updates the MetricConfig of the KafkaMetric. That update was not reflected into the Sensor so the Sensor was still using the MetricConfig that it has been created with.Reviewers: Anna Povzner <anna@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-2896; Added system test for partition re-assignmentPartition re-assignment tests with and without broker failure.Author: Anna Povzner <anna@confluent.io>Reviewers: Ben Stopford <ben@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Geoff Anderson <geoff@confluent.io>Closes #655 from apovzner/kafka_2896",5
"KAFKA-6391 ensure topics are created with correct partitions BEFORE building the… (#4347)* ensure topics are created with correct partitions BEFORE building the metadata for our stream tasks* Added a test case. The test should fail with the old logic, because:While stream-partition-assignor-test-KSTREAM-MAP-0000000001-repartition is created correctly with four partitions, the StreamPartitionAssignor will only assign three tasks to the topic. Test passes with the new logic.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>",2
kafka-649; patch v5; Cleanup log4j logging; patched by Guozhang Wang; reviewed by Jun Rao,2
"MINOR: Add connector configs to site-docsIn AK's documentation, the config props for connectors are not listed (https://kafka.apache.org/documentation/#connectconfigs). This PR adds these sink and source connector configs to the html site-docs.Signed-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5469 from wicknicks/add-connector-configs-to-docs",5
MINOR: clarify variables for skipping idempotent source updates (#9316)Reviewers: Guozhang Wang <guozhang@apache.org>,5
KAFKA-12323: Set timestamp in record context when punctuate (#10170)We need to preserve the timestamp when punctuating so that downstream operators would retain it via context.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-1485 Upgrade to Zookeeper 3.4.6 and create shim for ZKCLI so system tests can run patch by Gwen Shapira reviewed by Joe Stein and Jun Rao,1
"KAFKA-4205; KafkaApis: fix NPE caused by conversion to arrayNPE was caused by `log.logSegments.toArray` resulting in array containing `null` values. The exact reason still remains somewhat a mystery to me, but it seems that the culprit is `JavaConverters` in combination with concurrent data structure access.Here's a simple code example to prove that:```scalaimport java.util.concurrent.ConcurrentSkipListMap// Same as `JavaConversions`, but allows explicit conversions via `asScala`/`asJava` methods.import scala.collection.JavaConverters._case object Valueval m = new ConcurrentSkipListMap[Int, Value.type]new Thread { override def run() = { while (true) m.put(9000, Value) } }.start()new Thread { override def run() = { while (true) m.remove(9000) } }.start()new Thread { override def run() = { while (true) { println(m.values.asScala.toArray.headOption) } } }.start()```Running the example will occasionally print `Some(null)` indicating that there's something shady going on during `toArray` conversion.`null`s magically disappear by making the following change:```diff- println(m.values.asScala.toArray.headOption)+ println(m.values.asScala.toSeq.headOption)```Author: Anton Karamanov <ataraxer@yandex-team.ru>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2204 from ataraxer/KAFKA-4205",4
MINOR: fixes a few error logging formatsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>Closes #1919 from guozhangwang/minor-error-message-fixes,0
"MINOR: Add BrokerMetadataListener (#10111)This adds BrokerMetadataListener which is responsible for processing metadata records received by the broker when running in Raft mode.This also moves some classes that were added to the wrong folder in trunkReviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>",5
"MINOR: catch InvalidStateStoreException in QueryableStateIntegrationTestA couple of the tests may transiently fail in QueryableStateIntegrationTest as they are not catching InvalidStateStoreException. This exception is expected during rebalance.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1840 from dguy/minor-fix",0
"MINOR: Update Streams IQ JavaDocs to not point to a deprecated method (#8271)Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-5128; Check inter broker version in transactional methodsAdd check in `KafkaApis` that the inter broker protocol version is at least `KAFKA_0_11_0_IV0`, i.e., supporting transactionsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3103 from dguy/kafka-5128",5
"KAFKA-10800; Enhance the test for validation when the state machine creates a snapshot (#10593)This patch adds additional test cases covering the validations done when snapshots are created by the state machine.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3402; Restore behaviour of MetadataCache.getTopicMetadata when unsupported security protocol is receivedAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson, Grant HenkeCloses #1073 from ijuma/kafka-3402-restore-get-topic-metadata-behaviour",5
MINOR: Fix typos in documentationAnd improve readability by adding proper punctuations.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2002 from vahidhashemian/doc/fix_typos,2
"MINOR: Avoid intermediate strings when parsing/decoding ZK JSONAlso:- Fix bug in result type of `createSequentialPersistentPath`- Remove duplicated code from `ReplicationUtils`- Move `propagateIsrChanges` from `ReplicationUtils` to `KafkaZkClient`- Add tests- Minor clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Ted Yu <yuzhihong@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #4261 from ijuma/zk-data-improvements",5
"MINOR: Make data in FetchSnapshotRequest and FetchSnapshotRespponse private (#9820)Reviewers: José Armando García Sancio <jsancio@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-12365; Disable APIs not supported by KIP-500 broker/controller (#10194)This patch updates request `listeners` tags to be in line with what the KIP-500 broker/controller support today. We will re-enable these APIs as needed once we have added the support.I have also updated `ControllerApis` to use `ApiVersionManager` and simplified the envelope handling logic.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
"KAFKA-5417; Fix Selector's handling of some failures during prepareIf prepare throws an exception in the same poll when the connectionis established, the channel id should be in `disconnected`, butnot in `connected`.Author: dongeforever <dongeforever@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3282 from dongeforever/KAFKA-5417",0
MINOR: Fix flaky testClientDisconnectionUpdatesRequestMetrics() (#11987)Reviewers: David Jacot <djacot@confluent.io>,5
Make backoff time during consumer rebalance configurable; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-234git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1227417 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13212: add support infinite query for session store (#11234)Add support for infinite range query for SessionStore.Reviewers: Patrick Stuedi <pstuedi@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-6005; Reject JoinGroup request from first member with empty protocol type/protocol listAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3957 from omkreddy/JOIN-GROUP-EMPTY-PROTOCOL,5
"KAFKA-12738: address minor followup and consolidate integration tests of PR #11787 (#11812)This PR addresses the remaining nits from the final review of #11787It also deletes two integration test classes which had only one test in them, and moves the tests to another test class file to save on the time to bring up an entire embedded kafka cluster just for a single runReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-9751: Forward CreateTopicsRequest for FindCoordinator/Metadata when topic creation is needed (#9579)Consolidate auto topic creation logic to either forward a CreateTopicRequest or handling the creation directly as AutoTopicCreationManager, when handling FindCoordinator/Metadata request.Co-authored-by: Jason Gustafson <jason@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: fix message protocol help text for ElectPreferredLeadersResult (#6479)Reviewers: Jun Rao <junrao@gmail.com>,0
"KAFKA-8671: NullPointerException occurs if topic associated with GlobalKTable changes (#7437)Reviewers: Matthias J. Sax <matthias@confluent.io>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-8820: kafka-reassign-partitions.sh should support the KIP-455 API (#8244)Rewrite ReassignPartitionsCommand to use the KIP-455 API when possible, ratherthan direct communication with ZooKeeper.  Direct ZK access is still supported,but deprecated, as described in KIP-455.As specified in KIP-455, the tool has several new flags.  --cancel stopsan assignment which is in progress.  --preserve-throttle causes the--verify and --cancel commands to leave the throttles alone.--additional allows users to execute another partition assignment evenif there is already one in progress.  Finally, --show displays all ofthe current partition reassignments.Reorganize the reassignment code and tests somewhat to rely more on unittesting using the MockAdminClient and less on integration testing.  Eachintegration test where we bring up a cluster seems to take about 5 seconds, soit's good when we can get similar coverage from unit tests.  To enable this,MockAdminClient now supports incrementalAlterConfigs, alterReplicaLogDirs,describeReplicaLogDirs, and some other APIs.  MockAdminClient is also nowthread-safe, to match the real AdminClient implementation.In DeleteTopicTest, use the KIP-455 API rather than invoking the reassignmentcommand.",1
"KAFKA-9364: Fix misleading consumer logs on throttling (#7894)When the consumer's fetch request is throttled by the KIP-219 mechanism,it receives an empty fetch response.  The consumer should not log thisas an error.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: fixes on streams upgrade test (#5754)1. In test_upgrade_downgrade_brokers, allow duplicates to happen.2. In test_version_probing_upgrade, grep the generation numbers from brokers at the end, and check if they can ever be synchronized.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-4073; MirrorMaker should handle messages without timestamp correctlyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1773 from ijuma/kafka-4073-mirror-maker-timestamps,1
"TRIVIAL: fix JavaDocs formatting (#10134)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-5361: Add EOS integration tests for Streams APIAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3193 from mjsax/kafka-5361-add-eos-integration-tests-for-streams-api",3
"KAFKA-6461 TableTableJoinIntegrationTest is unstable if caching is enabled (#4451)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",0
MINOR: Close create topics policy during shutdown and more testsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2443 from ijuma/close-create-topics-policy-during-shutdown,1
"KAFKA-7811: Avoid unnecessary lock acquire when KafkaConsumer commits offsets (#6119)Avoid unnecessary lock acquire when KafkaConsumer commits offsets.Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: reduce commit interval and cache size for integration testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2789 from mjsax/minor-improve-integration-test",3
kafka-1424; transient unit test failure in testSendWithDeadBroker; patched by Jun Rao; reviewed by Timothy Chen,5
"KAFKA-12837; Process entire batch reader in the `BrokerMetadataListener` commit handler (#10902)We should process the entire batch in `BrokerMetadataListener` and make sure that `hasNext` is called before calling `next` on the iterator. The previous code worked because the raft client kept track of the position in the iterator, but it caused NoSuchElementException to be raised when the reader was empty (as might be the case with control records).Reviewers: Jason Gustafson <jason@confluent.io>",5
kafka-1531; zookeeper.connection.timeout.ms is set to 10000000 in configuration file in Kafka tarball; patched by Manikumar Reddy; reviewed by Jun Rao,2
"MINOR: fix error in quota_test.py system testsquota_test.py tests are failing with below error.```23:24:42 [INFO:2020-10-24 17:54:42,366]: RunnerClient: kafkatest.tests.client.quota_test.QuotaTest.test_quota.quota_type=user.override_quota=False: FAIL: not enough arguments for format string23:24:42 Traceback (most recent call last):23:24:42   File ""/home/jenkins/workspace/system-test-kafka-branch-builder/kafka/venv/lib/python3.6/site-packages/ducktape-0.8.0-py3.6.egg/ducktape/tests/runner_client.py"", line 134, in run23:24:42     data = self.run_test()23:24:42   File ""/home/jenkins/workspace/system-test-kafka-branch-builder/kafka/venv/lib/python3.6/site-packages/ducktape-0.8.0-py3.6.egg/ducktape/tests/runner_client.py"", line 192, in run_test23:24:42     return self.test_context.function(self.test)23:24:42   File ""/home/jenkins/workspace/system-test-kafka-branch-builder/kafka/venv/lib/python3.6/site-packages/ducktape-0.8.0-py3.6.egg/ducktape/mark/_mark.py"", line 429, in wrapper23:24:42     return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)23:24:42   File ""/home/jenkins/workspace/system-test-kafka-branch-builder/kafka/tests/kafkatest/tests/client/quota_test.py"", line 141, in test_quota23:24:42     self.quota_config = QuotaConfig(quota_type, override_quota, self.kafka)23:24:42   File ""/home/jenkins/workspace/system-test-kafka-branch-builder/kafka/tests/kafkatest/tests/client/quota_test.py"", line 60, in __init__23:24:42     self.configure_quota(kafka, self.producer_quota, self.consumer_quota, ['users', None])23:24:42   File ""/home/jenkins/workspace/system-test-kafka-branch-builder/kafka/tests/kafkatest/tests/client/quota_test.py"", line 83, in configure_quota23:24:42     (kafka.kafka_configs_cmd_with_optional_security_settings(node, force_use_zk_conection), producer_byte_rate, consumer_byte_rate)23:24:42 TypeError: not enough arguments for format string23:24:42```ran thee tests locally.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: David Jacot <djacot@confluent.io>, Ron Dagostino <rndgstn@gmail.com>Closes #9496 from omkreddy/quota-tests",3
"[KAFKA-9826] Handle an unaligned first dirty offset during log cleaning. (#8469)In KAFKA-9826, a log whose first dirty offset was past the start of the active segment and past the last cleaned point resulted in an endless cycle of picking the segment to clean and discarding it. Though this didn't interfere with cleaning other log segments, it kept the log cleaner thread continuously busy (potentially wasting CPU and impacting other running threads) and filled the logs with lots of extraneous messages.This was determined to be because the active segment was getting mistakenly picked for cleaning, and because the logSegments code handles (start == end) cases only for (start, end) on a segment boundary: the intent is to return a null list, but if they're not on a segment boundary, the routine returns that segment.This fix has two parts:It changes logSegments to handle start==end by returning an empty List always.It changes the definition of calculateCleanableBytes to not consider anything past the UncleanableOffset; previously, it would potentially shift the UncleanableOffset to match the firstDirtyOffset even if the firstDirtyOffset was past the firstUncleanableOffset. This has no real effect now in the context of the fix for (1) but it makes the code read more like the model that the code is attempting to follow.These changes require modifications to a few test cases that handled this particular test case; they were introduced in the context of KAFKA-8764. Those situations are now handled elsewhere in code, but the tests themselves allowed a DirtyOffset in the active segment, and expected an active segment to be selected for cleaning.Reviewer: Jun Rao <junrao@gmail.com>",4
"KAFKA-7981; Add fetcher and log cleaner thread count metrics (#6514)This patch adds metrics for failed threads as documented in KIP-434: https://cwiki.apache.org/confluence/display/KAFKA/KIP-434%3A+Add+Replica+Fetcher+and+Log+Cleaner+Count+Metrics.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-722 Fix the classpath in kafka-run-class.sh; reviewed by Neha Narkhede,1
"MINOR: Introduce 2.5-IV0 IBP (#8010)As the feature freeze approaches, we should support `2.5` as the inter.broker.protocol.version value. There are no new APIs so far, so `2.5` is effectively equivalent to `2.4`.",1
"MINOR: ConsoleConsumer should not always exit when Consumer::poll returns an empty record batch (#11718)With https://github.com/apache/kafka/commit/ddb6959c6272d2039ed8c9f595634c3c9573f85e, `Consumer::poll` will return an empty record batch when position advances due to aborted transactions or control records. This makes the `ConsoleConsumer` exists because it assumes that `poll` returns due to the timeout being reached. This patch fixes this by explicitly tracking the timeout.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Move a few methods from the `ZKUtils` class to the companion objectThey don't require access to `ZkClient`.Also include a few obvious clean-ups in `ZKUtils`:* Remove redundant rethrows and braces* Use named arguments for booleansAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira <cshapi@gmail.com>Closes #1775 from ijuma/move-some-zk-utils-methods-to-companion-object,4
"KAFKA-10211: Add DirectoryConfigProvider (#9136)See KIP-632: https://cwiki.apache.org/confluence/display/KAFKA/KIP-632%3A+Add+DirectoryConfigProviderReviewers: Mickael Maison <mickael.maison@gmail.com>, David Jacot <david.jacot@gmail.com>",5
KAFKA-5737; KafkaAdminClient thread should be daemonAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3674 from cmccabe/KAFKA-5737,5
MINOR: Improve the description of principal under different mechanisms of sasl (#11947)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"KAFKA-2477: Fix a race condition between log append and fetch that causes OffsetOutOfRangeException.Tried two fixes. I prefer the second approach because it saves an additional offset search.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #204 from becketqin/KAFKA-2477",1
KAFKA-9966: add internal assignment listener to stabilize eos-beta upgrade test (#8648)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-5730; Consumer should invoke async commit callback before sync commit returnsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>Closes #3666 from hachikuji/KAFKA-5730",5
"MINOR: Fixed compiler warnings in LogManagerTest (#6897)Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5233; KIP-138: Change punctuate semanticsImplementation for KIP-138: Change punctuate semanticsAuthor: Michal Borowiecki <michal.borowiecki@openbet.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3055 from mihbor/KIP-138",5
kafka-1140; Move the decoding logic from ConsumerIterator.makeNext to next; patched by Guozhang Wang; reviewed by Jun Rao,1
KAFKA-4395; Break static initialization order dependency between KafkaConfig and LogconfigFixes static initialization order dependency between KafkaConfig and LogConfig. jjkoshy please take a look.Author: Sumant Tambe <sutambe@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2120 from sutambe/logconfig-static-init,5
"MINOR: fix Quota's equal() functionIt compares upper bound with itself.Author: Edward Ribeiro <edward.ribeiro@gmail.com>Reviewers: Aditya Auradkar, Ismael Juma, Guozhang WangCloses #182 from eribeiro/equals-bug",0
KAFKA-1997; Follow-up to add the shutdown hook before starting the consumers; reviewed by Guozhang Wang,1
"KAFKA-7101: Consider session store for windowed store default configs (#5298)1. extend isWindowStore to consider session store as well.2. extend the existing unit test accordingly.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5463; Controller incorrectly logs rack information when new brokers are addedBefore:```pri=TRACE t=Controller-1-to-broker-0-send-thread at=logger Controller 1 epoch 1 received response {error_code=0} for a request sent to broker <ip>:<port> (id: 0 rack: null)```After:```pri=TRACE t=Controller-1-to-broker-0-send-thread at=logger Controller 1 epoch 1 received response {error_code=0} for a request sent to broker <ip>:<port> (id: 0 rack: us-east-1d)```Author: Jeff Chao <jeffchao@me.com>Reviewers: Onur Karaman <okaraman@linkedin.com>, Ismael Juma <ismael@juma.me.uk>Closes #3358 from jeffchao/fix-controller-rack-aware-logging",2
KAFKA-1446 Consumer metrics for rebalance; reviewed by Neha Narkhede and Joel Koshy,5
"MINOR: Update release script with new remote, better error handling, correct mvn deploy profileAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <github@juma.me.uk>Closes #4528 from ewencp/update-release-script",5
kafka-1418; transient unit test failure in ProducerFailureHandlingTest; patched by Jun Rao; reviewed by Guozhang Wang and Joel Koshy,3
"KAFKA-3832; Kafka Connect's JSON Converter never outputs a null value (#6027)When using the Connect `JsonConverter`, it's impossible to produce tombstone messages, thus impacting the compaction of the topic. This patch allows the converter with and without schemas to output a NULL byte value in order to have a proper tombstone message. When it's regarding to get this data into a connect record, the approach is the same as when the payload looks like `""{ ""schema"": null, ""payload"": null }""`, this way the sink connectors can maintain their functionality and reduces the BCC.Reviewers: Gunnar Morling <gunnar.morling@googlemail.com>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7353: Connect logs 'this' for anonymous inner classesReplace 'this' reference in anonymous inner class logs to out class's 'this'Author: Kevin Lafferty <kevin.lafferty@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Arjun Satish <arjun@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5583 from kevin-laff/connect_logging",2
HOTFIX: Fix verbose logging in ControllerChannelManager.brokerReadyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1786 from hachikuji/hotfix-ctrlchannelmgr-verbose-logging,2
KAFKA-3014: fix integer overflow problem in leastLoadedNodeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #696 from hachikuji/KAFKA-3014,5
"MINOR: Fix tracing in KafkaApis.handle()requestObj() returns null for the o.a.k.c.requests objects so use header() for these.Once all the requests will have been replaced by o.a.k.c.requests objects, we should be able to clean that up, but in the meantime it's useful to trace both.Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1435 from mimaison/kafkaapis_trace",1
"KAFKA-3084: Topic existence checks in topic commands (create, alter, delete)…delete)Author: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #744 from granthenke/exists-checks",5
"KAFKA-10669: Make CurrentLeaderEpoch field ignorable and set MaxNumOffsets field default to 1Couple of failures observed after KAFKA-9627: Replace ListOffset request/response with automated protocol (https://github.com/apache/kafka/pull/8295)1. Latest consumer fails to consume from 0.10.0.1 brokers. Below system tests are failingkafkatest.tests.client.client_compatibility_features_test.ClientCompatibilityFeaturesTestkafkatest.tests.client.client_compatibility_produce_consume_test.ClientCompatibilityProduceConsumeTestSolution: Current default value for MaxNumOffsets is 0. because to this brokers are not returning offsets for v0 request. Set default value for MaxNumOffsets field to 1.  This is similar to previous [approach](https://github.com/apache/kafka/blob/2.6/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java#L204)2. In some scenarios, latest consumer fails with below error when connecting to a Kafka cluster which consists of newer and older (<=2.0) Kafka brokers`org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default currentLeaderEpoch at version 3`Solution: After #8295, consumer can set non-default CurrentLeaderEpoch value for v3 and below requests. One solution is to make CurrentLeaderEpoch ignorable.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: David Jacot <djacot@confluent.io>Closes #9540 from omkreddy/fix-listoffsets",0
KAFKA-513 Add state change log to Kafka brokers; reviewed by Neha Narkhede,2
MINOR: add units to metrics descriptions + test fix post KAFKA-13229 (#11286)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
KAFKA-176 Fix existing perf tools; patched by nehanarkhede; reviewed by junrao and jaykrepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205525 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Rename Throttling config variables to match config nameThrottledLeaderReplicationRate* => LeaderReplicationThrottledRate*ThrottledFollowerReplicationRate* => FollowerReplicationThrottledRate* LeaderThrottledReplicasList* => LeaderReplicationThrottledReplicas*FollowerThrottledReplicasList* => FollowerReplicationThrottledReplicas*Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1951 from benstopford/rename-ThrottledLeaderReplicationRateProp,5
KAFKA-13636: Fix for the group coordinator issue where the offsets are deleted for unstable groups (#11742)This patch ensures that the committed offsets are not expired while the group is rebalancing. The issue is that we can't rely on the subscribed topics if the group is not stable.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-13391: don't fsync directory on Windows OS (#11426)Reviewers: Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",5
"Minor: replace .kafka with .log in implementation documentation (#12401)replace .kafka with .log in implementation documentationReviewers: Luke Chen <showuon@gmail.com>, Liam Clarke-Hutchinson <liam@steelsky.co.nz>",2
KAFKA-4172; Ensure fetch responses contain the requested partitionsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1857 from hachikuji/KAFKA-4172,5
KAFKA-1577; Swallow errors from connection-quotas in closing sockets on shutdown; reviewed by Joel Koshy,0
"KAFKA-3314: Add CDDL license to LICENSE and NOTICE fileAuthor: Jun Rao <junrao@gmail.com>Reviewers: Guozhang Wang, Ismael Juma, Gwen ShapiraCloses #997 from junrao/kafka-3314",2
"MINOR: KAFKA-7112: Only resume restoration if state is still PARTITIONS_ASSIGNED after poll (#5306)Before KIP-266, consumer.poll(0) would call updateAssignmentMetadataIfNeeded(Long.MAX_VALUE), which makes sure that the rebalance is definitely completed, i.e. both onPartitionRevoked and onPartitionAssigned called within this poll(0). After KIP-266, however, it is possible that only onPartitionRevoked will be called if timeout is elapsed. And hence we need to double check that state is still PARTITIONS_ASSIGNED after the consumer.poll(duration) call.Reviewers: Ted Yu <yuzhihong@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3849; Add explanation on why polling every second in MirrorMaker is requiredAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Jason Gustafson <jason@confluent.io>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1515 from SinghAsDev/KAFKA-3849",5
Exception java.util.NoSuchElementException: None.get appears inconsistently; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-370git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1352980 13f79535-47bb-0310-9956-ffa450edef68,1
trivial fix to print key properly in DumpLogSegments,2
MINOR: close state store in CachingSessionStoreTestclose the sessions store in `After` to release rocksdb resources.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2430 from dguy/minor-close-sesion-store,5
KAFKA-13377: Close `Stream` to avoid resource leak (#11397)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"HOTFIX: Added check for metadata unavailableAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1887 from enothereska/hotfix-metadata-unavailable",5
"MINOR. Replace Utils::readFileAsString method to read file as stream (#7208)The current Utils::readFileAsString method creates a FileChannel andmemory maps file and copies its content to a String and returns it. Butthat means that we need to know the size of the file in advance. Thisprecludes us from reading files whose size is not known in advance, i.e.any file opened with flag S_IFIFO.This change updates the method to use stream to read the content of the file.It has couple of practical advantages:Allows bash process substitution to pass in strings as file. So we cansay `./bin/kafka-reassign-partitions.sh --reassignment-json-file <(echo""reassignment json"")When adding systest for commands that take file, we don't have tocreate real physical file. Instead we can just dump the content of thefile on the command line.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
MINOR: improve QueryableStateIntegrationTest (#5987)Fix test Comparators plus Java8 cleanupReviewers: Guozhang Wang <wangguoz@gmail.com>,4
MINOR: Support auto-incrementing offsets in MemoryRecordsBuilderAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2282 from hachikuji/builder-autoincrement-offsets,1
KAFKA-1885 Upgrade junit dependency in core to 4.6 version to allow running individual test methods via gradle command line; reviewed by Neha Narkhede,3
"KAFKA-6296; Increase jitter to fix transient failure in NetworkClientTest.testConnectionDelayDisconnectedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ted Yu <yuzhihong@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4285 from hachikuji/KAFKA-6296",5
kafka-1555; provide strong consistency with reasonable availability; patched by Gwen Shapira; reviewed by Joel Koshy and Jun Rao,1
"MINOR: add upgrade section for 1.0.01. Add upgrade section for 1.0.0, including Streams API changes section.2. Add metrics name changes section.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3687 from guozhangwang/KMinor-metrics-upgrade-guide",4
KAFKA-2756: Use request version Id instead of latest version Id to parse the corresponding response.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang WangCloses #438 from guozhangwang/K2756,3
HOTFIX: Re-inserted SimpleBenchmark output for system testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1744 from enothereska/hotfix-ducktape-marker,0
"MINOR: Add test brokers to list as they are created to ensure cleanupAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3471 from rajinisivaram/MINOR-shutdown-brokers",5
"KAFKA-3761; Remove BrokerState ""RunningAsController""The reasons to remove it are:1. It's currently broken.  The purpose of the [JIRA](https://issues.apache.org/jira/browse/KAFKA-3761) was to report that the RunningAsController state gets overwritten back to ""RunningAsBroker"".2. It's not a useful state.  a. If clients want to use this metric to know whether a broker is ready to receive requests or not, they do not care whether or not the broker is the controller  b. there is already a separate boolean property, KafkaController.isActive which contains this information.Author: Roger Hoover <roger.hoover@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1437 from theduderog/KAFKA-3761-broker-state",5
trivial change to add some logging info in DefaultEventHandlergit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350046 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-5236; Increase the block/buffer size when compressing with Snappy or GzipWe had originally increased Snappy’s block size as part of KAFKA-3704. However,we had some issues with excessive memory usage in the producer and we revertedit in 7c6ee8d5e.After more investigation, we fixed the underlying reason why memory usage seemedto grow much more than expected via KAFKA-3747 (included in 0.10.0.1).In 0.10.2, we changed the broker to use the same classes as the producer and thebroker’s block size for Snappy was changed from 32 KB to 1KB. As reported inKAFKA-5236, the on disk size is, in some cases, 50% larger when the data is compressedwith 1 KB instead of 32 KB as the block size.As discussed in KAFKA-3704, it may be worth making this configurable and/or allocatethe compression buffers from the producer pool. However, for 0.11.0.0, I think thesimplest thing to do is to default to 32 KB for Snappy (the default if no block sizeis provided).I also increased the Gzip buffer size. 1 KB is too small and the default is smallerstill (512 bytes). 8 KB (which is the default buffer size for BufferedOutputStream)seemed like a reasonable default.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3205 from ijuma/kafka-5236-snappy-block-size",5
"KAFKA-7697: Process DelayedFetch without holding leaderIsrUpdateLock (#5999)Delayed fetch operations acquire leaderIsrUpdate read lock of one or more Partitions from the fetch request when attempting to complete the fetch operation. While appending new records, complete fetch requests after releasing leaderIsrUpdate of the Partition to which records were appended to avoid deadlocks in request handler threads.Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-10736 Convert transaction coordinator metadata schemas to use g… (#9611)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Replace some Java 7 style code with Java 8 style (#7623)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
KAFKA-1038; fetch response should use empty messageset instead of null when handling errors; patched by Jun Rao; reviewed by Neha Narkhede,0
"MINOR: prune the metadata upgrade test matrix (#8971)Most of the values in the metadata upgrade test matrix are just testingthe upgrade/downgrade path between two previous releases. This isunnecessary. We run the tests for all supported branches, so what weshould test is the up-/down-gradability of released versions with respectto the current branch.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-12449: Remove deprecated WindowStore#put (#10293)Removes `WindowStore#put(K,V)` that was deprecated via KIP-474.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-12898; Owned partitions in the subscription must be sorted (#10878)The group coordinator compares the provided subscription with the store subscription based on their bytes representation. So if the subscribed partitions are not in the same order, the group coordinator would consider that they are different and rebalance the group. This patch ensures that the topics and the owned partitions are sorted.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
KAFKA-10199: Implement adding active tasks to the state updater (#12128)This PR adds the default implementation of the state updater. The implementation only implements adding active tasks to the state updater.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"MINOR; DescribeUserScramCredentialsRequest API should handle request with users equals to `null` (#9504)DescribeUserScramCredentialsRequest states that all users are described when Users is empty or null. null is not handled at the moment and throws an NPE.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
"HOTFIX: Include RocksDB dependency in release tarballsWithout this change `./gradlew releaseTarGz` (and its variants) will not include the RocksDB jar, which is required for Kafka Streams, in Kafka's `libs/` folder.  The impact is that any Streams job will fail when it runs against a broker that was installed via a release tarball.guozhangwang junrao : please review.Author: Michael G. Noll <michael@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #1007 from miguno/trunk-rocksdb-fixes",5
"KAFKA-4662: adding test coverage for addSource methods with AutoOffsetReset…tResetAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2464 from bbejeck/KAFKA-4662_improve_topology_builder_test_coverage",3
KAFKA-1668 Print an error if you try to alter a topic that doesn't exist.,1
KAFKA-10628: remove all the unnecessary parameters from the tests which are using TopologyTestDriver (#9507)1. remove unneeded javadoc content.2. Replace containsKey/setProperty with putIfAbsent3. refactor the constructor of TopologyTestDriverTestReviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
KAFKA-12417: streams copyDependentLibs should not copy testRuntime configuration jars (#10466)This also fixes a Gradle deprecation that unblocks the upgrade to Gradle 7.0.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
KAFKA-5623: ducktape kafka service: do not assume Service contains num_nodes…m_nodesAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3557 from cmccabe/KAFKA-5623,5
"MINOR: Catch JsonMappingException subclass (#3821)Handle InvalidTypeIdException as NOT_IMPLEMENTED and add unit tests for all exceptions.Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Replace ACL_AUTHORIZER attribute with ZK_ACL_AUTHORIZER (#12247)Replace ACL_AUTHORIZER attribute with ZK_ACL_AUTHORIZER in system tests. Required after the changes merged with https://github.com/apache/kafka/pull/12190.Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-2879: Make MiniKDC test service slightly more genericAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-PostavaCloses #578 from gwenshap/KAFKA-2879,3
"MINOR: Fix typo in KTable javadoc*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Dmitry Minkovsky <dminkovsky@gmail.com>Reviewers: Joel Hamill <joel-hamill@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>Closes #4483 from dminkovsky/fix-javadoc-typogithub comments",2
HOTFIX: fix unit tests for KAFKA-5136,3
kafka-2012; Broker should automatically handle corrupt index files;  patched by Manikumar Reddy; reviewed by Jun Rao,2
"MINOR: Add HostedPartition.Deferred state in ReplicaManager (#10003)Brokers receive metadata from the Raft metadata quorum very differently than they do fromZooKeeper today, and this has implications for ReplicaManager.  In particular, when a brokerreads the metadata log it may not arrive at the ultimate state for a partition until it reads multiplemessages.  In normal operation the multiple messages associated with a state change will allappear in a single batch, so they can and will be coalesced and applied together.  There arecircumstances where messages associated with partition state changes will appear acrossmultiple batches and we will be forced to coalesce these multiple batches together.  Thecircumstances when this occurs are as follows:- When the broker restarts it must ""catch up"" on the metadata log, and it is likely that thebroker will see multiple partition state changes for a single partition across differentbatches while it is catching up.  For example, it will see the `TopicRecord` and the`PartitionRecords` for the topic creation, and then it will see any `IsrChangeRecords`that may have been recorded since the creation.  The broker does not know the state ofthe topic partitions until it reads and coalesces all the messages.- The broker will have to ""catch up"" on the metadata log if it becomes fenced and thenregains its lease and resumes communication with the metadata quorum.- A fenced broker may ultimately have to perform a ""soft restart"" if it was fenced for solong that the point at which it needs to resume fetching the metadata log has beensubsumed into a metadata snapshot and is no longer independently fetchable.  A softrestart will entail some kind of metadata reset based on the latest available snapshotplus a catchup phase to fetch after the snapshot end point.The first case -- during startup -- occurs before clients are able to connect to the broker.Clients are able to connect to the broker in the second case.  It is unclear if clients will beable to to connect to the broker during a soft restart (the third case).We need a way to defer the application of topic partition metadata in all of the above cases,and while we are deferring the application of the metadata the broker will not service clientsfor the affected partitions.As a side note, it is arguable if the broker should be able to service clients while catching upor not.  The decision to not service clients has no impact in the startup case -- clients can'tconnect yet at that point anyway.  In the third case it is not yet clear what we are going to do,but being unable to service clients while performing a soft reset seems reasonable.  In thesecond case it is most likely true that we will catch up quickly; it would be unusual toreestablish communication with the metadata quorum such that we gain a new lease andbegin to catch up only to lose our lease again.So we need a way to defer the application of partition metadata and make those partitionsunavailable while deferring state changes.  This PR adds a new internal partition state toReplicaManager to accomplish this.  Currently the available partition states are simple`Online`, `Offline` (meaning a log dir failure) and `None` (meaning we don't know about it). We add a new `Deferred` state.  We also rename a couple of methods that refer to""nonOffline"" partitions to instead refer to ""online"" partitions.**The new `Deferred` state never happens when using ZooKeeper for metadata storage.**Partitions can only enter the `Deferred` state when using a KIP-500 Raft metadata quorumand one of the above 3 cases occurs.  The testing strategy is therefore to leverage existingtests to confirm that there is no functionality change in the ZooKeeper case.  We will addthe logic for deferring/applying/reacting to deferred partition state in separate PRs sincethat code will never be invoked in the ZooKeeper world.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-1491; Always read coordinator information in consumer metadata response; reviewed by Neha Narkhede.,5
kafka-1473; transient unit test failure in testRequestHandlingDuringDeleteTopic;  patched by Guozhang Wang; reviewed by Jun Rao,3
"MINOR: Do not print log4j for memberId required (#9667)For MemberIdRequiredException, we would not print the exception at INFO with a full exception message since it may introduce more confusion that clearance.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>",5
"KAFKA-6145: KIP-441: fix flaky shouldEnforceRebalance test in StreamThreadTest (#8452)Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-6966: Extend TopologyDescription to better represent Source and (#5284)Implements KIP-321Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
Trivial commit - warn on consumer fetch request errors.,0
"KAFKA-4525; Kafka should not require SSL truststore passwordAuthor: Grant Henke <ghenke@cloudera.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2246 from granthenke/truststore-password",4
"MINOR: add test for repartition/source-topic/changelog optimization (#9668)If topology optimization is enabled, KafkaStreams does not create store changelog topics but re-uses source input topics if possible. However, this optimization should not be applied to internal repartition topics, because those are actively purged.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
MINOR: Fix broken link in quickstart.html (#10161)Update the old anchor #intro_topic to #intro_concepts_and_termsReviewers: Mickael Maison <mickael.maison@gmail.com>,5
KAFKA-10199: Expose tasks in state updater (#12312)This PR exposes the tasks managed by the state updater. The state updater manages all tasks that were added to the state updater and that have not yet been removed from it by draining one of the output queues.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
Consumer needs a pluggable decoder; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-3git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1176671 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-992 follow up. Fix broken unit test,3
"KAFKA-5172: Fix fetchPrevious to find the correct sessionChange fetchPrevious to use findSessions with the proper key and timestamps rather than using fetch.Author: Kyle Winkelman <kyle.winkelman@optum.com>Reviewers: Damian Guy, Guozhang WangCloses #2972 from KyleWinkelman/CachingSessionStore-fetchPrevious",1
"Time based log segment rollout; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-475git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1377093 13f79535-47bb-0310-9956-ffa450edef68",1
"MINOR: Fix static mock usage in StateStoreMetricsTest (#12325)Before this PR the calls to the static methods onStreamsMetricsImpl were just calls and not a verificationon the mock. This miss happened during the switch fromEasyMock to Mockito.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-10308: Fix flaky core/round_trip_fault_test.py (#9079)Creating a topic may fail (due to timeout) in running system tests. However, `RoundTripWorker` does not ignore `TopicExistsException` which makes `round_trip_fault_test.py` be a flaky one.More specifically, a network exception can cause the `CreateTopics` request to reach Kafka but Trogdor retry itand hit a `TopicAlreadyExists` exception on the retry, failing the test.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"MINOR: Eliminate PID terminology from non test codeProducer id is used instead.Also refactored TransactionLog schema code to followour naming convention and to have better structure.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3041 from ijuma/eliminate-pid-terminology",2
"MINOR: Fix gradle error writing test stdout (#8133)Adds a couple of extra checks to the test-output-capturing logic in our gradle build.Previously, we were seeing a lot of error logs while attempting to write output for atest whose output file hadn't been initialized.Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>",5
KAFKA-13270: Set JUTE_MAXBUFFER to 4 MB by default (#11295)We restore the 3.4.x/3.5.x behavior unless the caller has set the property (note that ZKConfigauto configures itself if certain system properties have been set).I added a unit test that fails without the change and passes with it.I also refactored the code to streamline the way we handle parameters passed toKafkaZkClient and ZooKeeperClient. See https://github.com/apache/zookeeper/pull/1129 for the details on why the behaviorchanged in 3.6.0.Credit to @rondagostino for finding and reporting this issue.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-10126:Add a warning message for ConsumerPerformance (#8845)ConsumerPerformance has not implemented options numThreadsOpt and numFetchersOpt as so far.This patch adds a warning message when used these options according to comments fromhttps://issues.apache.org/jira/browse/KAFKA-10126 . Once these two options are implemented,this warning message should be removed.Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
MINOR: Remove redundant code from ReplicaManagerTest#testFetchMessagesWhenNotFollowerForOnePartition (#10501)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"MINOR: Remove deprecated Metric.value() method usage (#5626)Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, John Roesler <john@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: remove unnecessary semicolon from Agent.java and AgentClient.java (#9625)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"MINOR: improve exception message for incompatible Serdes to actual key/value data typesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Guozhang WangCloses #2118 from mjsax/hotfixImproveSerdeTypeMissmatchError",0
MINOR: Update ducktape version to 0.5.3Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2220 from ewencp/update-ducktape,5
"KAFKA-13151; Disallow policy configs in KRaft since they are not yet supported (#11145)The configs `alter.config.policy.class.name` and `create.topic.policy.class.name` are not yet supported by KRaft. KRaft servers should fail startup if any of these are configured.Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12177: apply log start offset retention before time and size based retention (#10216)Log start offset retention is the cheapest retention to evaluate and does not require access to maxTimestamp fields for segments, nor segment sizes. In addition, it may unblock other types of retention such as time based retention. Without this change retention is not idempotent. It's possible for one deleteOldSegments call to delete segments due to log start offset retention, and a follow up call to delete due to time based retention, even if the time has not changed.Reviewers: Jun Rao <junrao@gmail.com>",4
KAFKA-10188: Prevent SinkTask::preCommit from being called after SinkTask::stop (#8910),5
"KAFKA-9652: Fix throttle metric in RequestChannel and request log due to KIP-219 (#8567)After KIP-219, responses are sent immediately and we rely on a combinationof clients and muting of the channel to throttle. The result of this is thatwe need to track `apiThrottleTimeMs` as an explicit value instead ofinferring it. On the other hand,  we no longer need`apiRemoteCompleteTimeNanos`.Extend `BaseQuotaTest` to verify that throttle time in the request channelmetrics are being set. Given the nature of the throttling numbers, the testis not particularly precise.I included a few clean-ups:* Pass KafkaMetric to QuotaViolationException so that the caller doesn'thave to retrieve it from the metrics registry.* Inline Supplier in SocketServer (use SAM).* Reduce redundant `time.milliseconds` and `time.nanoseconds`calls.* Use monotonic clock in ThrottledChannel and simplify `compareTo` method.* Simplify `TimerTaskList.compareTo`.* Consolidate the number of places where we update `apiLocalCompleteTimeNanos`and `responseCompleteTimeNanos`.* Added `toString` to ByteBufferSend` and `MultiRecordsSend`.* Restrict access to methods in `QuotaTestClients` to expose only what we needto.Reviewers: Jun Rao <junrao@gmail.com>",3
Updating trunk versions after cutting branch for 2.7,1
"Trogdor's ProducerBench does not fail if topics exists (#4673)Added configs to ProducerBenchSpec:topicPrefix: name of topics will be of format topicPrefix + topic index. If not provided, default is ""produceBenchTopic"".partitionsPerTopic: number of partitions per topic. If not provided, default is 1.replicationFactor: replication factor per topic. If not provided, default is 3.The behavior of producer bench is changed such that if some or all topics already exist (with topic names = topicPrefix + topic index), and they have the same number of partitions as requested, the worker uses those topics and does not fail. The producer bench fails if one or more existing topics has number of partitions that is different from expected number of partitions.Added unit test for WorkerUtils -- for existing methods and new methods.Fixed bug in MockAdminClient, where createTopics() would over-write existing topic's replication factor and number of partitions while correctly completing the appropriate futures exceptionally with TopicExistsException.Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Added to .gitignore Kafka server logs directoryWhen running Kafka server from sources, logs directory gets created in root of repository, and kafka server logs end up there. Currently that directory is not ignored by git.This change adds root logs directory to .gitignore so that Kafka server logs are ignored and do not get tracked by git.Author: Stevo Slavić <sslavic@gmail.com>Reviewers: Ismael JumaCloses #94 from sslavic/patch-7 and squashes the following commits:c7b62a7 [Stevo Slavić] MINOR: Added to .gitignore Kafka server logs",2
MINOR: Add provider name of SSLContext to debug log. (#7407),2
"MINOR: Rename brokers to replicas in the reassignment API (#7570)Reviewers: Jason Gustafson <jason@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Vikas Singh <vikas@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
KAFKA-787 Simple Consumer connecting to Broker that is not the Leader generates wrong error; reviewed by Jun Rao,0
kafka-2266; Client Selector can drop idle connections without notifying NetworkClient; patched by Jason Gustafson; reviewed by Jun Rao,1
KAFKA-8106: Skipping ByteBuffer allocation of key / value / headers in logValidator (#6785)* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.* github comments* use batch.skipKeyValueIterator* cleanups* no need to skip kv for uncompressed iterator* checkstyle fixes* fix findbugs* adding unit tests* reuse decompression buffer; and using streaming iterator* checkstyle* add unit tests* remove reusing buffer supplier* fix unit tests* add unit tests* use streaming iterator* minor refactoring* rename* github comments* github comments* reuse buffer at DefaultRecord caller* some further optimization* major refactoring* further refactoring* update comment* github comments* minor fix* add jmh benchmarks* update jmh* github comments* minor fix* github comments,0
MONOR: Remove redudant LocalLogManager (#10325)Remove an unused copy of LocalLogManager (a test class) that endedup in the main code directory.Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
KAFKA-642 Fixes to protocol. Patch reviewed by Neha and Joel.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1417734 13f79535-47bb-0310-9956-ffa450edef68,0
kafka-server-start.sh ignores JMX_PORT; patched by Mathias Herberts; reviewed by Jun Rao; KAFKA-144git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178434 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-6606; Ensure consumer awaits auto-commit interval after sending… (#4641)We need to reset the auto-commit deadline after sending the offset commit request so that we do not resend it while the request is still inflight. Added unit tests ensuring this behavior and proper backoff in the case of a failure.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"MINOR: doc changes for KIP-372 (#5790)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-6166: Streams configuration requires consumer. and producer. in order to be read (#4434)* Implement method to get custom properties* Add custom properties to getConsumerConfigs and getProducerConfigs* Add testsReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Provide link to ZooKeeper within QuickstartAuthor: Kevin Sweeney <restlessdesign@users.noreply.github.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3372 from restlessdesign/patch-1,1
MINOR: Fix flaky assertion in ControllerIntegrationTest (#5829)`ControllerIntegrationTest#waitUntilControllerEpoch` sometimes fails with the following error:```java.util.NoSuchElementException: None.getat scala.None$.get(Option.scala:347)at scala.None$.get(Option.scala:345)at kafka.controller.ControllerIntegrationTest$$anonfun$waitUntilControllerEpoch$1.apply$mcZ$sp(ControllerIntegrationTest.scala:312)at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:779)at kafka.controller.ControllerIntegrationTest.waitUntilControllerEpoch(ControllerIntegrationTest.scala:312)at kafka.controller.ControllerIntegrationTest.testEmptyCluster(ControllerIntegrationTest.scala:51)```We should retry until the value is defined or it times out.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: Free sends in MultiSend as they complete (#4574)Currently we hold onto all Records references in a multi-partition fetch response until the full response has completed. This can be a problem when the records have been down-converted since they will be occupying a (potentially large) chunk of memory. This patch changes the behavior in MultiSend so that once a Send is completed, we no longer keep a reference to it, which will allow the Records objects to be freed sooner.I have added a simple unit test to verify that sends are removed as the MultiSend progresses.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
MINOR: fix bootstrap-server typo in ReassignPartitionsCommand (#5941),2
"KAFKA-10286: Connect system tests should wait for workers to join group (#9040)Currently, the system tests `connect_distributed_test` and `connect_rest_test` only wait for the REST api to come up.The startup of the worker includes an asynchronous process for joining the worker group and syncing with other workers.There are some situations in which this sync takes an unusually long time, and the test continues without all workers up.This leads to flakey test failures, as worker joins are not given sufficient time to timeout and retry without waiting explicitly.This changes the `ConnectDistributedTest` to wait for the Joined group message to be printed to the logs before continuing with tests. I've activated this behavior by default, as it's a superset of the checks that were performed by default before.This log message is present in every version of DistributedHerder that I could find, in slightly different forms, but always with `Joined group` at the beginning of the log message. This change should be safe to backport to any branch.Signed-off-by: Greg Harris <gregh@confluent.io>Author: Greg Harris <gregh@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
MINOR: Rename stream partition assignor to streams partition assignor (#4621)This is a straight-forward change that make the name of the partition assignor to be aligned with Streams.Reviewers: Matthias J. Sax <mjsax@apache.org>,1
"KAFKA-10192: Wait for REST API to become available before testing blocked connectors (#8928)The `testBlockInConnectorStop` test is failing semi-frequently on Jenkins. It's difficult to verify the cause without complete logs and I'm unable to reproduce locally, but I suspect the cause may be that the Connect worker hasn't completed startup yet by the time the test begins and so the initial REST request to create a connector times out with a 500 error. This isn't an issue for normal tests but we artificially reduce the REST request timeout for these tests as some requests are meant to exhaust that timeout.The changes here use a small hack to verify that the worker has started and is ready to handle all types of REST requests before tests start by querying the REST API for a non-existent connector. Reviewers: Boyang Chan <boyang@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",5
"KAFKA-5295: Allow source connectors to specify topic-specific settings for new topics (KIP-158) (#8722)Kafka Connect workers have been able to create Connect's internal topics using the new admin client for some time now (see KAFKA-4667 for details). However, tasks of source connectors are still relying upon the broker to auto-create topics with default config settings if they don't exist, or expect these topics to exist before the connector is deployed, if their configuration needs to be specialized. With the implementation of KIP-158 here, if `topic.creation.enable=true`, Kafka Connect will supply the source tasks of connectors that are configured to create topics with an admin client that will allow them to create new topics on-the-fly before writing the first source records to a new topic. Additionally, each source connector has the opportunity to customize the topic-specific settings of these new topics by defining groups of topic configurations. This feature is tested here via unit tests (old tests that have been adjusted and new ones) as well as integration tests.Reviewers: Randall Hauch <rhauch@gmail.com>",3
KAFKA-6405: Fix incorrect comment in MetadataUpdater (#4361)* Fix incorrect comment in MetadataUpdater* Fix comment for handleCompletedMetadataResponse,5
"KAFKA-9667: Connect JSON serde strip trailing zeros (#8230)This change turns on exact decimal processing in JSON Converter for deserializing decimals, meaning trailing zeros are maintained. Serialization was already using the decimal scale to output the right value, so this change means a value of `1.2300` can now be serialized to JSON and deserialized back to Connect without any loss of information.Author: Andy Coates <big-andy-coates@users.noreply.github.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Almog Gavra <almog@confluent.io>",5
"MINOR: Check for null timestamp rather than value in hashcodeAuthor: Andrew Stevenson <andrew@datamountaineer.com>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2055 from andrewstevenson/kafka-4334",5
"KAFKA-13649: Implement early.start.listeners and fix StandardAuthorizer loading (#11969)Since the StandardAuthorizer relies on the metadata log to store its ACLs, we need to be sure thatwe have the latest metadata before allowing the authorizer to be used. However, if the authorizeris not usable for controllers in the cluster, the latest metadata cannot be fetched, becauseinter-node communication cannot occur. In the initial commit which introduced StandardAuthorizer,we punted on the loading issue by allowing the authorizer to be used immediately. This commit fixesthat by implementing early.start.listeners as specified in KIP-801. This will allow in superusersimmediately, but throw the new AuthorizerNotReadyException if non-superusers try to use theauthorizer before StandardAuthorizer#completeInitialLoad is called.For the broker, we call StandardAuthorizer#completeInitialLoad immediately after metadata catch-upis complete, right before unfencing. For the controller, we callStandardAuthorizer#completeInitialLoad when the node has caught up to the high water mark of thecluster metadata partition.This PR refactors the SocketServer so that it creates the configured acceptors and processors inits constructor, rather than requiring a call to SocketServer#startup A new function,SocketServer#enableRequestProcessing, then starts the threads and begins listening on theconfigured ports. enableRequestProcessing uses an async model: we will start the acceptor andprocessors associated with an endpoint as soon as that endpoint's authorizer future is completed.Also fix a bug where the controller and listener were sharing an Authorizer when in co-locatedmode, which was not intended.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Upgrade ducktape to 0.7.8 (#8879)Newer version of ducktape that updates some dependencies and adds some features. You can see that diff here:https://github.com/confluentinc/ducktape/compare/v0.7.7...v0.7.8Reviewer: Konstantine Karantasis <konstantine@confluent.io>,5
"KAFKA-10439: Connect's Values to parse BigInteger as Decimal with zero scale. (#9320)The `org.apache.kafka.connect.data.Values#parse` method parses integers, which are larger than `Long.MAX_VALUE` as `double` with `Schema.FLOAT64_SCHEMA`.That means we are losing precision for these larger integers.For example:`SchemaAndValue schemaAndValue = Values.parseString(""9223372036854775808"");`returns:`SchemaAndValue{schema=Schema{FLOAT64}, value=9.223372036854776E18}`Also, this method parses values that can be parsed as `FLOAT32` to `FLOAT64`.This PR changes parsing logic, to use `FLOAT32`/`FLOAT64` for numbers that don't have fraction part(`decimal.scale()!=0`) only, and use an arbitrary-precision `org.apache.kafka.connect.data.Decimal` otherwise.Also, it updates the method to parse numbers, that can be represented as `float` to `FLOAT64`.Added unit tests, that cover parsing `BigInteger`, `Byte`, `Short`, `Integer`, `Long`, `Float`, `Double` types.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",3
KAFKA-2622: Add Time logical type for Copycat.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #285 from ewencp/kafka-2622-time-logical-type,2
kafka-791; Fix validation bugs in System Test; patched by John Fung; reviewed by Jun Rao,3
KAFKA-8147: Add changelog topic configuration to KTable suppress (#8029)Implements: KIP-446Reviewers: John Roesler <vvcephei@apache.org>,5
"kafka-1619; perf dir can be removed; patched by Jun Rao; reviewed by Guozhang Wang, Neha Narkhede and Stevo Slavic",4
"KAFKA-2667: Fix transient error in KafkaBasedLogTest.The test required a specific sequence of events for each Consumer.poll() call,but the MockConsumer.waitForPollThen() method could not guarantee that,resulting in race conditions. Add support for scheduling sequences of eventseven when running in multi-threaded environments.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #333 from ewencp/kafka-2667-kafka-based-log-transient-error",2
MINOR: Add ineligible replica reason to log message (#12328)It's useful if the message about ineligible replicas explains the reason the replica is ineligible.Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-5727: Add Streams quickstart tutorial as an archetype project0. Minor fixes on the existing examples to merge all on a single input topic; also do not use `common.utils.Exit` as it is for internal usage only.1. Add the archetype project for the quickstart. Steps to try it out:  a. `mvn install` on the quickstart directory.  b. `mvn archetype:generate \-DarchetypeGroupId=org.apache.kafka \-DarchetypeArtifactId=streams-quickstart-java \-DarchetypeVersion=1.0.0-SNAPSHOT \-DgroupId=streams-quickstart \-DartifactId=streams-quickstart \-Dversion=0.1 \-Dpackage=StreamsQuickstart \-DinteractiveMode=false` at any directory to create the project.  c. build the streams jar with version `1.0.0-SNAPSHOT` to local maven repository with `./gradlew installAll`; `cd streams-quickstart; mvn clean package`  d. create the input / output topics, start the console producer and consumer.  e. start the program: `mvn exec:java -Dexec.mainClass=StreamsQuickstart.Pipe/LineSplit/WordCount`.  f. type data on console producer and observe data on console consumer.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Eno Thereska <eno.thereska@gmail.com>Closes #3630 from guozhangwang/KMinor-streams-quickstart-tutorial",5
"KAFKA-10340: Proactively close producer when cancelling source tasks (#10016)Close the producer in `WorkerSourceTask` when the latter is cancelled. If the broker do not autocreate the topic, and the connector is not configured to create topics written by the source connector, then the `WorkerSourceTask` main thread will block forever until the topic is created, and will not stop if cancelled or scheduled for shutdown by the worker.Expanded an existing unit test for the WorkerSourceTask class to ensure that the producer is closed when the task is abandoned, and added a new integration test that guarantees that tasks are still shut down even when their producers are trying to write to topics that do not exist.Author: Chris Egerton <chrise@confluent.io>Reviewed: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
kafka-994; High level consumer doesn't throw an exception when the message it is trying to fetch exceeds the configured fetch size; patched by Sam Meder; reviewed by Jay Kreps and Jun Rao,5
MINOR: Update release versions for upgrade tests with 3.2.0 release (#12143)Updates release versions in files that are used for upgrade test with the 3.2.0 release version.  Reviewer: David Jacot <djacot@confluent.io>,5
"KAFKA-6253: Improve sink connector topic regex validationKAFKA-3073 added topic regex support for sink connectors. The addition requires that you only specify one of topics or topics.regex settings. This is being validated in one place, but not during submission of connectors. This PR adds validation at `AbstractHerder.validateConnectorConfig` and `WorkerConnector.initialize`.This adds a test of the new behavior to `AbstractHerderTest`.Author: Jeff Klukas <jeff@klukas.net>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4251 from jklukas/connect-topics-validation",5
"KAFKA-10847: Delete Time-ordered duplicated records using deleteRange() internally (#10537)This PR changes the TimeOrderedKeySchema composite key from time-seq-key -> time-key-seq to allow deletion of duplicated time-key records using the RocksDB deleteRange API. It also removes all duplicates when put(key, null) is called. Currently, the put(key, null) was a no-op, which was causing problems because there was no way to delete any keys when duplicates are allowed.The RocksDB deleteRange(keyFrom, keyTo) deletes a range of keys from keyFrom (inclusive) to keyTo (exclusive). To make keyTo inclusive, I incremented the end key by one when calling the RocksDBAccessor.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-6455: Update integration tests to verify result timestamps (#6751)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-6958: Allow to name operation using parameter classes (#6410)This is the 2nd PR for the KIP-307Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: Update kafka-topics.sh line command tool upgrade notes with removed option (#10806)Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>Co-authored-by: shenwenbing <shenwenbing@qianxin.com>",4
"KAFKA-5694; Add AlterReplicaDirRequest and DescribeReplicaDirRequest (KIP-113 part-1)Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Colin P. Mccabe <cmccabe@confluent.io>Closes #3621 from lindong28/KAFKA-5694",5
KAFKA-7366: Make topic configs segment.bytes and segment.ms to take effect immediately (#5728)Reviewers: Ismael Juma <ismael@juma.me.uk> and Jun Rao <junrao@gmail.com>,5
MINOR: remove the group id from a restore consumerguozhangwangA restore consumer does not belong to a consumer group.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #543 from ymatsuda/no_group_for_restore_consumer,5
"KAFKA-10321: fix infinite blocking for global stream thread startup (#9095)The start() function for global stream thread only checks whether the thread is not running, as it needs to block until it finishes the initialization. This PR fixes this behavior by adding a check whether the thread is already in error state as well.Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",0
"KAFKA-4603: Disallow abbreviations in OptionParser constructorKAFKA-4603 the command parsed errorUsing ""new OptionParser"" might result in parse errorChange all the OptionParser constructor in Kafka into ""new OptionParser(false)""Author: xinlihua <xin.lihua1@zte.com.cn>Author: unknown <00067310@A23338408.zte.intra>Author: auroraxlh <xin.lihua1@zte.com.cn>Author: xin <xin.lihua1@zte.com.cn>Reviewers: Damian Guy, Guozhang WangCloses #2349 from auroraxlh/fix_OptionParser_bug",0
"KAFKA-9666; Don't increase producer epoch when trying to fence if the log append fails (#8239)When fencing producers, we currently blindly bump the epoch by 1 and write an abort marker to the transaction log. If the log is unavailable (for example, because the number of in-sync replicas is less than min.in.sync.replicas), we will roll back the attempted write of the abort marker, but still increment the epoch in the transaction metadata cache. During periods of prolonged log unavailability, producer retires of InitProducerId calls can cause the epoch to be increased to the point of exhaustion, at which point further InitProducerId calls fail because the producer can no longer be fenced. With this patch, we track whenever we have failed to write the bumped epoch, and when that has happened, we don't bump the epoch any further when attempting to fence. This is safe because the in-memory epoch is still causes old producers to be fenced.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: Exclude Committer Checklist section from commit messageIt seems like it's sufficient to be able to refer to it in the PR.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4202 from ijuma/exclude-committer-checklist-when-merging,5
"KAFKA-10500: Allow people to add new StreamThread at runtime (#9615)Part of KIP-663.Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-12284: increase request timeout to make tests reliable (#10547)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"KAFKA-9883: Add better error message when REST API forwards a request and leader is not known (#8536)When the Connect worker forwards a REST API request to the leader, it might get back a `RequestTargetException` that suggests the worker should forward the request to a different worker. This can happen when the leader changes, and the worker that receives the original request forwards the request to the worker that it thinks is the current leader, but that worker is not the current leader. In this case. In most cases, the worker that received the forwarded request includes the URL of the current leader, but it is possible (albeit rare) that the worker doesn’t know the current leader and will include a null leader URL in the resulting `RequestTargetException`.When this rare case happens, the user gets a null pointer exception in their response and the NPE is logged. Instead, the worker should catch this condition and provide a more useful error message that is similar to other existing error messages that might occur.Added a unit test that verifies this corner case is caught and this particular NPE does not occur.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-6809: Count inbound connections in the connection-creation metric (#5301)Previously, the connection-creation metric only accounted for opened connections from the broker. This change extends it to account for received connections.",4
MINOR: Fix typo in ReplicaManagerTest (#12178)Reviewer: Luke Chen <showuon@gmail.com>,3
MINOR: Small cleanups in connect:runtime (#11756)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3802; log mtimes reset on broker restart / shutdownThere seems to be a bug in the JDK that on some versions the mtime ofthe file is modified on FileChannel.truncate() even if the javadoc states`If the given size is greater than or equal to the file's current size then the file is not modified.`.This causes problems with log retention, as all the files then look likethey contain recent data to Kafka. Therefore this is only done if the channel size is different to the target size.Author: Moritz Siuts <m.siuts@emetriq.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1497 from msiuts/KAFKA-3802-log_mtimes_reset_on_broker_shutdown",2
"MINOR: Increase timeouts to 30 seconds (#6852)The ResetIntegrationTest has experienced several failures and it seems the current timeout of 10 seconds may not be enough timeReviewers: Matthias J. Sax <mjsax@apache.org>, Boyang Chen <boyang@confluent.io>",5
"MINOR: log 2min processing summary of StreamThread loop (#9941)Remove all INFO-level logging from the main StreamThread loop in favor of a summary with a 2min intervalReviewers: Walker Carlson <carlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-12593: Fix Apache License headers (#10452)* Standardize license headers in scala, python, and gradle files.* Relocate copyright attribution to the NOTICE.* Add a license header check to `spotless` for scala files.Reviewers: Ewen Cheslack-Postava <ewencp@apache.org>, Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org",2
"broker should exit if hitting exceptions durin startup; patched by Jun Rao; reviewed by Sriram Subramanian, Swapnil Ghike and Neha Narkhede; kafka-768",5
KAFKA-1075; Consumer will not rebalance upon topic partition change; reviewed by Neha Narkhede and Jun Rao,4
"HOTFIX: Compilation error in CommandLineUtils (#6131)This was broken by #6084. The syntax works with Scala 2.12, but not 2.11.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>",1
MINOR: Remove unnecessary semicolon in NetworkClient (#9853)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-4105: Queryable state testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #1806 from enothereska/queryable-state-tests",3
HOTFIX: temp fix for ktable look upguozhangwangTemporarily disabled state store access checking.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #864 from ymatsuda/fix_table_lookup,0
"KAFKA-2373: Add Kafka-backed offset storage for Copycat.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen Shapira, James ChengCloses #202 from ewencp/kafka-2373-copycat-distributed-offset",1
"MINOR: Fix FetchRequest.getErrorResponse for version 1Author: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1091 from granthenke/fetch-error",0
"KAFKA-5031; Validate count of records and headers for new message formathttps://issues.apache.org/jira/browse/KAFKA-5031Implements additional check for `DefaultRecordBatch` that compares number of records declared in the header with actual number of records. Similarly for headers.Author: gosubpl <github@gosub.pl>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3156 from gosubpl/KAFKA-5031",5
MINOR: Security doc fixesSimple fixes that have tripped users.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #745 from ijuma/security-doc-improvements,2
"KIP-145: Add SMTs, HeaderFrom, DropHeaders and InsertHeader (#9549)These SMTs were originally specified in KIP-145 but never implementedat the time.HeaderTo is not included since its original specification doesn't deal withthe fact that there can be >1 header with the same name, but a field can onlyhave a single value (which could be an array, but not if the headers forthe given name had different schemas).Reviewers: Chris Egerton <chrise@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",5
MINOR: Use string interpolation in FinalizedFeatureCache (#9602)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-13807: Fix incrementalAlterConfig and refactor some things (#12033)Ensure that we can set log.flush.interval.ms at the broker or cluster level viaIncrementalAlterConfigs. This was broken by KAFKA-13749, which added log.flush.interval.ms as thesecond synonym rather than the first. Add a regression test to DynamicConfigChangeTest.Create ControllerRequestContext and pass it to every controller API. This gives us a uniform way topass through information like the deadline (if there is one) and the Kafka principal which ismaking the request (in the future we will want to log this information).In ControllerApis, enforce a timeout for broker heartbeat requests which is equal to the heartbeatrequest interval, to avoid heartbeats piling up on the controller queue. This should have been donepreviously, but we overlooked it.Add a builder for ClusterControlManager and ReplicationControlManager to avoid the need to dealwith a lot of churn (especially in test code) whenever a new constructor parameter gets added forone of these.In ControllerConfigurationValidator, create a separate function for when we just want to validatethat a ConfigResource is a valid target for DescribeConfigs. Previously we had been re-using thevalidation code for IncrementalAlterConfigs, but this was messy.Split out the replica placement code into a separate package and reorganize it a bit.Reviewers: David Arthur <mumrah@gmail.com",5
MINOR: Fix EventQueueProcessingTimeMs metric #11668Make sure that the event queue processing time histogram gets updatedand add tests that verify that the update methods modify the correcthistogram.Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
"MINOR: Adjust `testClientDisconnectionUpdatesRequestMetrics` to also test small response case (#7754)Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Andrew Choi <andchoi@linkedin.com>",2
"KAFKA-9570: Define SSL configs in all worker config classes, not just distributed (#8135)Define SSL configs in all worker config classes, not just distributedAuthor: Chris Egerton <chrise@confluent.io>Reviewers: Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-5936; KafkaProducer.close should throw InterruptExceptionAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3912 from mjsax/kafka-5936-producer-close",5
"KAFKA-6120: RecordCollector should not retry sendingAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4148 from mjsax/kafka-6120-recordCollector",5
"KAFKA-1018 tidy up the pom, 0.8.0 release, build the test jars now too",3
"MINOR: Remove unused params in `ZkConfigManager` (#11763)Remove `changeExpirationMs` and `time` in `ZkConfigManager`, since these two parameters are not used.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: fix streams tutorial (#12251)Reviewers: Luke Chen <showuon@gmail.com>,0
"KAFKA-9490: Fix generics for Grouped (#8028)Reviewers: Andrew Choi <andchoi@linkedin.com>, John Roesler <john@confluent.io>",5
"MINOR: Doc changes for KIP-324 (#5788)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-2945; CreateTopic - protocol and server side implementationAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1489 from granthenke/create-wire-new,1
KAFKA-2663; Trivial follow-up to edit comments,2
KAFKA-6328: Sort node groups considering global stores in InternalTopologyBuilder#makeNodeGroupsAuthor: RichardYuSTUG <yohan.richard.yu2@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4339 from ConcurrencyPractitioner/kafka-6238Minor edits on description,2
MINOR: Ensure streaming iterator is closed by FetcherAuthor: Jason Gustafson <jason@confluent.io>Author: Ismael Juma <github@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2762 from hachikuji/ensure-decompression-stream-closed,5
"KAFKA-9605; Do not attempt to abort batches when txn manager is in fatal error (#8177)We detected a bug in soak where the producer batches shall be failed in sender loop before the produce response callback. This shall trigger an illegal state exception on the producer batch as it is already aborted. The impact is not severe since sender is on its own thread but should be fixed to avoid unnecessary critical exception.Reviewers: Bob Barrett <bob.barrett@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-4431; Make consumer heartbeat thread a daemon threadAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2234 from rajinisivaram/KAFKA-4431,5
KAFKA-4924: Fix Kafka Connect API findbugs warningsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2715 from cmccabe/KAFKA-4924,5
"KAFKA-2752: Add VerifiableSource/Sink connectors and rolling bounce Copycat system tests.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ben Stopford, Geoff Anderson, Guozhang WangCloses #432 from ewencp/kafka-2752-copycat-clean-bounce-test",3
KAFKA-14147: Prevent deferredTaskUpdates map from growing monotonically in KafkaConfigBackingStore (#12490)Reviewers: Chris Egerton <fearthecellos@gmail.com>,5
migration tool from 0.7 to 0.8; patched by Yang Ye; reviewed by Jun Rao; kafka-327git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1389460 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-2247; Merge kafka.utils.Time and kafka.common.utils.TimeAlso:* Make all implementations of `Time` thread-safe as they are accessed from multiple threads in some cases.* Change default implementation of `MockTime` to use two separate variables for `nanoTime` and `currentTimeMillis` as they have different `origins`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Jason Gustafson <jason@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #2095 from ijuma/kafka-2247-consolidate-time-interfaces",5
MINOR: Move connect.start() to try catch blockAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1347 from Ishiihara/connect-standalone,5
"KAFKA-10694; Implement zero copy for FetchSnapshot (#9819)This patch adds zero-copy support for the `FetchSnapshot` API. Unlike the normal `Fetch` API, records are not assumed to be offset-aligned in `FetchSnapshot` responses. Hence this patch introduces a new `UnalignedRecords` type which allows us to use most of the existing logic to support zero-copy while preserving type safety in the snapshot APIs.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5253: Fixed TopologyTestDriver to handle streams created with patterns (#4793)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Adjust test params pursuant to KAFKA-4514. (#5777)PR #2267 Introduced support for Zstandard compression. The relevant test expects values for `num_nodes` and `num_producers` based on the (now-incremented) count of compression types.Passed the affected, previously-failing test:`ducker-ak test tests/kafkatest/tests/client/compression_test.py`Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-5755; KafkaProducer should be refactored to use LogContextWith LogContext, each producer log item is automatically prefixed with client id and transactional id.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3703 from huxihx/KAFKA-5755",5
kafka-1642; [Java New Producer Kafka Trunk] CPU Usage Spike to 100% when network connection is lost; patched by Ewen Cheslack-Postava; reviewed by Guozhang Wang and Jun Rao,1
kafka-2174; Wrong TopicMetadata deserialization; patched by Alexey Ozeritskiy; reviewed by Jun Rao,5
HOTFIX: Checkstyle import fixAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>Closes #261 from ijuma/checkstyle-import-fix,2
KAFKA-5752; Update index files correctly during async deletetimeIndex and txnIndex were not being updated previously.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3700 from omkreddy/KAFKA-5752,5
KAFKA-13804: Output the reason why broker exit unexpectedly during startup (#12028)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"HOTFIX: ambiguity issue calling putAll() in scala compilation against JAVA 9The cause for compilation error in JDK 9.0 was an ambiguity issue in scalac:```both method putAll in class Properties of type (x$1: java.util.Map[_, _])Unitand  method putAll in class Hashtable of type (x$1: java.util.Map[_ <: Object, _ <: Object])Unitmatch argument types (java.util.Properties)      newProps.putAll(props)```Author: RichardYuSTUG <yohan.richard.yu2@gmail.com>Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4482 from ConcurrencyPractitioner/trunk",1
"MINOR: Warning instead of error if TGT cannot be renewed beyond the next expiry dateAuthor: Sriharsha Chintalapani <harsha@hortonworks.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1510 from harshach/KerberosLogin-Log",2
"KAFKA-4831: add documentation for KIP-265 (#4686)Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>",5
KAFKA-7833: Add Global/StateStore name conflict check (#8825)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Retry setting aligned time until set (#4893)In the AbstractResetIntegrationTest we can have a transient error when setting the time for the test where the new time is less than the original time, for those cases we should catch the exception and re-try setting the time once versus letting the test fail.For testing, ran the entire streams test suite.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-3451: Add basic HTML coverage report generation to gradleAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ismael Juma, Ewen Cheslack-PostavaCloses #1121 from granthenke/coverage",3
"KAFKA-12278; Ensure exposed api versions are consistent within listener (#10666)Previously all APIs were accessible on every listener exposed by the broker, butwith KIP-500, that is no longer true.  We now have more complex requirements forAPI accessibility.For example, the KIP-500 controller exposes some APIs which are not exposed bybrokers, such as BrokerHeartbeatRequest, and does not expose most client APIs,such as JoinGroupRequest, etc.  Similarly, the KIP-500 broker does not implementsome APIs that the ZK-based broker does, such as LeaderAndIsrRequest andUpdateFeaturesRequest.All of this means that we need more sophistication in how we expose APIs andkeep them consistent with the ApiVersions API. Up until now, we have beenworking around this using the controllerOnly flag inside ApiKeys, but this isnot rich enough to support all of the cases listed above.  This PR introduces anew ""listeners"" field to the request schema definitions.  This field is an arrayof strings which indicate the listener types in which the API should be exposed.We currently support ""zkBroker"", ""broker"", and ""controller"".  (""broker""indicates the KIP-500 broker, whereas zkBroker indicates the old broker).This PR also creates ApiVersionManager to encapsulate the creation of theApiVersionsResponse based on the listener type.  Additionally, it modifiesSocketServer to check the listener type of received requests before forwardingthem to the request handler.Finally, this PR also fixes a bug in the handling of the ApiVersionsResponseprior to authentication. Previously a static response was sent, which means thatchanges to features would not get reflected. This also meant that the logic toensure that only the intersection of version ranges supported by the controllerwould get exposed did not work. I think this is important because some clientsrely on the initial pre-authenticated ApiVersions response rather than doing asecond round after authentication as the Java client does.One final cleanup note: I have removed the expectation that envelope requestsare only allowed on ""privileged"" listeners.  This made sense initially becausewe expected to use forwarding before the KIP-500 controller was available. Thatis not the case anymore and we expect the Envelope API to only be exposed on thecontroller listener. I have nevertheless preserved the existing workarounds toallow verification of the forwarding behavior in integration testing.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",3
MINOR: Update `./gradlew allDepInsight` example in README (#11125)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
MINOR: Update docs to reflect the ZK 3.5.5 upgrade (#7149)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"KAFKA-2930: Update references to ZooKeeper in the docs.Author: Flavio Junqueira <fpj@apache.org>Reviewers: Ismael Juma, Gwen ShapiraCloses #615 from fpj/KAFKA-2930",2
"KAFKA-3464: Add system tests for Connect with Kafka security enabledAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma, Gwen ShapiraCloses #1141 from ewencp/kafka-3464-connect-security-system-tests",5
MINOR: Substitute assertEquals(null) with assertNull (#9852)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-13785: [8/N][emit final] time-ordered session store (#12127)Time ordered session store implementation. I introduced AbstractRocksDBTimeOrderedSegmentedBytesStore to make it generic for RocksDBTimeOrderedSessionSegmentedBytesStore and RocksDBTimeOrderedSegmentedBytesStore.A few minor follow-up changes:1. Avoid extra byte array allocation for fixed upper/lower range serialization.2. Rename some class names to be more consistent.Authored-by: Hao Li <1127478+lihaosky@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com.com>, John Roesler <vvcephei@apache.org>",1
"Updating docs for streams app reset tool (#4401)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: report streams benchmarks separately (#5275)Specify each benchmark as a separate test so that we can see the results reported independently.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
KAFKA-91 zkclient does not show up in pom;patched by cburroughs;reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1195253 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-816 Reduce noise in Kafka server logs due to NotLeaderForPartitionException; reviewed by Jun Rao,2
Include controllerId in all requests sent by controller; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-793,5
"KAFKA-9677: Fix consumer fetch with small consume bandwidth quotas (#8290)When we changed quota communication with KIP-219, fetch requests get throttled by returning empty response with the delay in throttle_time_ms and Kafka consumer retries again after the delay. With default configs, the maximum fetch size could be as big as 50MB (or 10MB per partition). The default broker config (1-second window, 10 full windows of tracked bandwidth/thread utilization usage) means that < 5MB/s consumer quota (per broker) may block consumers from being able to fetch any data.This PR ensures that consumers cannot get blocked by quota by capping fetchMaxBytes in KafkaApis.handleFetchRequest() to quota window * consume bandwidth quota. In the example of default configs (10-second quota window) and 1MB/s consumer bandwidth quota, fetchMaxBytes would be capped to 10MB.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
Correct exception message in DistributedHerder (#7995)Author: Ted Yu <yuzhihong@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,5
KAFKA-5212; Consumer ListOffsets request can starve group heartbeatsAuthor: Richard Yu <richardyu@Richards-Air.attlocal.net>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4110 from ConcurrencyPractitioner/trunk,1
"KAFKA-4996; Fix findBugs warning in getOrCreateSegmentThe code was correct since the method is only called fromone thread, but the change is worthwhile anyway.Author: Amit Daga <adaga@adobe.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2966 from amitdaga/findbugs-streams-multithread",5
"KAFKA-4660; Improve test coverage KafkaStreamsdguy , mjsax Please review the PR and let me know your comments.Author: umesh chaudhary <umesh9794@gmail.com>Reviewers: Bill Bejeck, Matthias J. Sax, Guozhang WangCloses #3099 from umesh9794/mylocal",3
"KAFKA-2562: update kafka scripts to use new tools/codeUpdated  kafka-producer-perf-test.sh to use org.apache.kafka.clients.tools.ProducerPerformance.Updated build.gradle to add kafka-tools-0.9.0.0-SNAPSHOT.jar to kafka/libs  folder.Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #242 from omkreddy/KAFKA-2562",1
Merging commits 1230840:1239902 from trunkgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1239937 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-5579: check for nullAuthor: Jeremy Custenborder <jcustenborder@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3517 from jcustenborder/KAFKA-5579",5
"KAFKA-13219: BrokerState metric not working for KRaft clusters (#11239)The BrokerState metric always has a value of 0, for NOT_RUNNING, in KRaftclusters. This patch fixes it and adds a test.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-5269; Retry on unknown topic/partition error in transactional requestsWe should retry AddPartitionsToTxnRequest and TxnOffsetCommitRequest when receiving an UNKNOWN_TOPIC_OR_PARTITION error.As described in the JIRA: It turns out that the `UNKNOWN_TOPIC_OR_PARTITION` is returned from the request handler in KafkaAPis for the AddPartitionsToTxn and the TxnOffsetCommitRequest when the broker's metadata doesn't contain one or more partitions in the request. This can happen for instance when the broker is bounced and has not received the cluster metadata yet.We should retry in these cases, as this is the model followed by the consumer when committing offsets, and by the producer with a ProduceRequest.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3094 from apurvam/KAFKA-5269-handle-unknown-topic-partition-in-transaction-manager",0
"KAFKA-3191: Improve offset committing JavaDoc in KafkaConsumerAdded an example clarifying the correct way to use explicit offsets with commitSync().Author: Adam Kunicki <adam@streamsets.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #850 from kunickiaj/KAFKA-3191",5
"KAFKA-1714: Fix gradle wrapper bootstrapping (#6031)Given we need to follow the Apache rule of not checkingany binaries into the source code, Kafka has always hada bit of a tricky Gradle bootstrap.Using ./gradlew as users expect doesn’t work and alocal and compatible version of Gradle was required togenerate the wrapper first.This patch changes the behavior of the wrapper task toinstead generate a gradlew script that can bootstrap thejar itself. Additionally it adds a license, removes the batscript, and handles retries.The documentation in the readme was also updated.Going forward patches that upgrade gradle should run`gradle wrapper` before checking in the change.With this change users using ./gradlew can be sure theyare always building with the correct version of Gradle.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk",1
"MINOR: Add Kafka Streams API / upgrade notesAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1321 from guozhangwang/KStreamsJavaDoc",2
MINOR: Fix partition numbering from 0 to P-1 instead of P in docs (#8572)Small typo fixReviewers: Konstantine Karantasis <konstantine@confluent.io>,5
kafka-807; LineMessageReader doesn't correctly parse the key separator; patched by Dragos Manolescu; reviewed by Jun Rao,5
"MONIR: Check for NULL in case of version probing (#7275)In case of version probing we would skip the logic for setting cluster / assigned tasks; since these values are initialized as null they are vulnerable to NPE when code changes.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-5184 KAFKA-5173; Various improvements to SASL tests1. Call `closeSasl` in `MultipleListenersWithSameSecurityProtocolBaseTest`2. Refactor the code to make it easier to reason about3. Add an assert that may possibly help us narrow down how KAFKA-5184can happen (it seems impossible).4. Remove SaslTestHarness to make it easier to reason about setUpand tearDown methods.5. Fix *AdminClientIntegrationTest to have a single `tearDown`6. Remove a *ReplicaFetcherTest and *TopicMetadataTest secure variants.They are redundant from a security perspective given the consumer andproducer tests.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3010 from ijuma/kafka-5184-kafka-5173-sasl-issues,0
KAFKA-12879: Addendum to reduce flakiness of tests (#11871)This is an addendum to the KAFKA-12879 (#11797) to fix some tests that are somewhat flaky when a build machine is heavily loaded (when the timeouts are too small).- Add an if check to void sleep(0)- Increase timeout in the tests,3
MINOR: Fix QueryResult Javadocs (#12404)Fixes the QueryResult javadocs.Reviewer: Bruno Cadonna <cadonna@apache.org>,1
KAFKA-10209: Fix connect_rest_test.py after the introduction of new connector configs (#8944)There are two new configs introduced by 371f14c3c12d2e341ac96bd52393b43a10acfa84 and 1c4eb1a5757df611735cfac9b709e0d80d0da4b3 so we have to update the expected configs in the connect_rest_test.py system test too.Reviewer: Konstantine Karantasis <konstantine@confluent.io>,5
"KAFKA-8874: Add consumer metrics to observe user poll behavior (KIP-517)https://cwiki.apache.org/confluence/display/KAFKA/KIP-517%3A+Add+consumer+metrics+to+observe+user+poll+behaviorAuthor: Kevin Lu <kelu@paypal.com>Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jason Gustafson <jason@confluent.io>Closes #7395 from KevinLiLu/KIP517-KAFKA8874",5
"HOTFIX: Fix two test failures in JDK11 (#8063)1. StoreChangelogReaderTest.shouldRequestCommittedOffsetsAndHandleTimeoutException[1] This is due to stricter ternary operator type casting2. KStreamImplTest.shouldSupportTriggerMaterializedWithKTableFromKStreamThis is added recently where String typed values for <String, Integer>, in J8 it is allowed but in J11 it is not allowed.Reviewers: John Roesler <john@confluent.io>",5
"MINOR: replace test ""expected"" parameter by assertThrows (#9520)This PR includes following changes.1. @Test(expected = Exception.class) is replaced by assertThrows2. remove reference to org.scalatest.Assertions3. change the magic code from 1 to 2 for testAppendAtInvalidOffset to test ZSTD4. rename testMaybeAddPartitionToTransactionXXXX to testNotReadyForSendXXX5. increase maxBlockMs from 1s to 3s to avoid unexpected timeout from TransactionsTest#testTimeoutReviewers: Ismael Juma <ismael@confluent.io>",5
KAFKA-2202: fix consumerTimeoutMs computation on ConsumerPerformance; reviewed by Guozhang Wang,0
"MINOR: Update Scala to 2.13.3 (#8931)I had to fix several compiler errors due to deprecation of auto application of `()`. A relatedXlint config (`-Xlint:nullary-override`) is no longer valid in 2.13, so we now only enable itfor 2.12. The compiler flagged two new inliner warnings that required suppression andthe semantics of `&` in `@nowarn` annotations changed, requiring a small change inone of the warning suppressions.I also removed the deprecation of a number of methods in `KafkaZkClient` asthey should not have been deprecated in the first place since `KafkaZkClient` is aninternal class and we still use these methods in the Controller and so on. Thisbecame visible because the Scala compiler now respects Java's `@Deprecated`annotation.Finally, I included a few minor clean-ups (eg using `toBuffer` instead `toList`) when fixingthe compilation warnings.Noteworthy bug fixes in Scala 2.13.3:* Fix 2.13-only bug in Java collection converters that caused some operations to perform an extra pass* Fix 2.13.2 performance regression in Vector: restore special cases for small operands in appendedAll and prependedAll* Increase laziness of #:: for LazyList* Fixes related to annotation parsing of @Deprecated from Java sources in mixed compilationFull release notes:https://github.com/scala/scala/releases/tag/v2.13.3Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",0
"KAFKA-5353; baseTimestamp should always have a create timestampThis makes the case where we build the records from scratch consistentwith the case where update the batch header ""in place"". Thanks toedenhill who found the issue while testing librdkafka.The reason our tests don’t catch this is that we rely on the maxTimestampto compute the record level timestamps if log append time is used.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3177 from ijuma/set-base-sequence-for-log-append-time",2
"KAFKA-5700; Producer should not drop header information when splitting batchesProducer should not drop header information when splitting batches.  This PR also corrects a minor typo in Sender.java, where `spitting and retrying` should be `splitting and retrying`.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin <becket.qin@gmail.com>Closes #3620 from huxihx/KAFKA-5700",1
MINOR: web docs fixes on message header (#5381)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Fetch only from leader should be respected in purgatory (#7650)In #7361, we inadvertently reverted a change to enforce leader only fetching for old versions of the protocol. This patch fixes the problem and adds a new test case to cover fetches which hit purgatory.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, David Arthur <mumrah@gmail.com>",3
"KAFKA-6677: Fixed StreamsConfig producer's max-in-flight allowed when EOS enabled. (#4868)Reviewers: Matthias J Sax <matthias@confluentio>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-5411: AdminClient javadoc and documentation improvements- Show AdminClient configs in the docs.- Update Javadoc config so that public classes exposed bythe AdminClient are included.- Version and table of contents fixes.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Colin Mccabe, Gwen ShapiraCloses #3271 from ijuma/kafka-5411-admin-client-javadoc-configs",5
"KAFKA-10223; Use NOT_LEADER_OR_FOLLOWER instead of non-retriable REPLICA_NOT_AVAILABLE for consumers (#8979)Brokers currently return NOT_LEADER_FOR_PARTITION to producers and REPLICA_NOT_AVAILABLE to consumers if a replica is not available on the broker during reassignments. Non-Java clients treat REPLICA_NOT_AVAILABLE as a non-retriable exception, Java consumers handle this error by explicitly matching the error code even though it is not an InvalidMetadataException. This PR renames NOT_LEADER_FOR_PARTITION to NOT_LEADER_OR_FOLLOWER and uses the same error for producers and consumers. This is compatible with both Java and non-Java clients since all clients handle this error code (6) as retriable exception. The PR also makes ReplicaNotAvailableException a subclass of InvalidMetadataException.    - ALTER_REPLICA_LOG_DIRS continues to return REPLICA_NOT_AVAILABLE. Retained this for compatibility since this request never returned NOT_LEADER_FOR_PARTITION earlier.    -  MetadataRequest version 0 also returns REPLICA_NOT_AVAILABLE as topic-level error code for compatibility. Newer versions filter these out and return Errors.NONE, so didn't change this.   - Partition responses in MetadataRequest return REPLICA_NOT_AVAILABLE to indicate that one of the replicas is not available. Did not change this since NOT_LEADER_FOR_PARTITION is not suitable in this case.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Bob Barrett <bob.barrett@confluent.io>",5
MINOR: Suppress DescribeConfigs Denied log during CreateTopics (#7971)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"KAFKA-3352: Avoid DNS reverse lookupsBy using `getHostString` (introduced in Java 7) instead of `getHostName`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson, Grant HenkeCloses #1030 from ijuma/kafka-3352-avoid-dns-reverse-look-ups",1
MINOR: Start the broker-to-controller channel for request forwarding (#10340)Also use different log prefixes for the different channels,0
"Reverting KAFKA-510, to be reapplied after addressing review comments and after KAFKA-42 is checked ingit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396704 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-13262: Remove final from `MockConsumer.close()` and delegate implementation (#11307)I added the final via 2f3600198722 to catch overriding mistakessince the implementation was moved from the deprecated andoverloaded `close` with two parameters to the no-arg`close`.I didn't realize then that `MockConsumer` is a publicAPI (seems like a bit of a mistake since we tweak theimplementation and sometimes adds methods without a KIP).Given that this is a public API, I have also moved the implementationof `close` to the one arg overload. This makes it easier for asubclass to have specific overriding behavior depending on thetimeout.Reviewers: David Jacot <djacot@confluent.io>",5
HOTFIX: Fix spotsbug failure in Kafka examples (#8051)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-1416; Unify sendMessages in TestUtils; reviewed by Guozhang Wang,3
"KAFKA-12948: Remove node from ClusterConnectionStates.connectingNodes when node is removed (#10882)NetworkClient.poll() throws IllegalStateException when checking isConnectionSetupTimeout if all nodes in ClusterConnectionStates.connectingNodes aren't present in ClusterConnectionStates.nodeState. This commit ensures that when we remove a node from nodeState, we also remove from connectingNodes.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-2633; Default logging from tools to StderrAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #296 from granthenke/tools-log4j,2
"KAFKA-5003; StreamThread should catch InvalidTopicExceptionWe should catch `InvalidTopicException` and not just`NoOffsetForPartitionException`. Also, we need to step throughall partitions that might be affected and reset those.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2747 from mjsax/minor-fix-reset",0
"KAFKA-3905: Handling null/empty topics and collections, patterns when subscription with list of topics or with patterns, and with assignments.- Added validity checks for input parameters on subscribe, assign to avoid NPE, and provide an argument exception instead- Updated behavior for subscription with null collection to be same as when subscription with emptyList.i.e., unsubscribes.- Added tests on subscription, assignAuthor: Rekha Joshi <rekhajoshm@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1601 from rekhajoshm/KAFKA-3905-1",5
"KAFKA-10086: Integration test for ensuring warmups are effective (#8818)Add an integration test for the task assignor.* ensure we see proper scale-out behavior with warmups* ensure in-memory stores are properly recycled and not restored through the scale-out processFix two bugs revealed by the test:Bug 1: we can't remove active tasks in the cooperative algorithm, because this causes their state to get discarded (definitely for in-memory stores, and maybe for persistent ones, depending on the state cleaner). Instead, we convert them to standbys so they can keep warm.Bug 2: tasks with only in-memory stores weren't reporting their offset positionsReviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
MINOR: Improve producer Javadoc about send with acks = 0 (#11882)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"KAFKA-6388; Recover from rolling an empty segment that already exists (#5986)There were several reported incidents where the log is rolled to a new segment with the same base offset as an active segment, causing KafkaException: Trying to roll a new log segment for topic partition X-N with start offset M while it already exists. In the cases we have seen, this happens to an empty log segment where there is long idle time before the next append and somehow we get to a state where offsetIndex.isFull() returns true due to _maxEntries == 0. This PR recovers from this state by deleting and recreating the segment and all of its associated index files.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6749: Fixed TopologyTestDriver to process stream processing guarantee as exactly once (#4912)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>",5
KAFKA-2716: Make Kafka core not depend on log4j-appenderAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael JumaCloses #405 from SinghAsDev/KAFKA-2716,2
"KAFKA-7736; Consolidate Map usages in TransactionManager (#6270)Refactors the various maps used in TransactionManager into one map to simplify bookkeeping of inflight batches, offsets and sequence numbers.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: update docs with regard to improved resilience of Kafka Streams (#4380)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Joel Hamill, Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Always apply the java-library gradle plugin (#10394)As @chia7712 found, we currently apply the `java` plugin indirectly via `rat.gradle`if the `.git` folder exists (https://github.com/apache/kafka/blob/7071ded2a61448da21c149fa1d85b3999b0d2f73/gradle/rat.gradle#L101).This led to inconsistent behavior if the `.git` directory was not present. Withthis change, the `java-library` plugin (which has slightly more features thanthe `java` plugin) is always applied.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <vvcephei@apache.org>",4
"KAFKA-1131 copy license and notice to the release files, reviewed by David Arthur",2
"KAFKA-8426; Fix for keeping the ConfigProvider configs consistent with KIP-297 (#6750)According to KIP-297 a parameter is passed to ConfigProvider with syntax ""config.providers.{name}.param.{param-name}"". Currently AbstractConfig allows parameters of the format ""config.providers.{name}.{param-name}"". With this fix AbstractConfig will be consistent with KIP-297 syntax.Reviewers: Robert Yokota <rayokota@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-12214: Generated code does not include UUID or struct fields in its toString output (#9914)Reviewers: Justine Olshan <jolshan@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-1046 New files,2
KAFKA-7540; Retry coordinator lookup to fix transient failure in ConsumerBounceTest (#6235)Add logic in ConsumerBounceTest to check the error code in FindCoordinator responses and retry if needed. This should help with transient failures or at least get us closer to the actual problem.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"KAFKA-12253: Add tests that cover all of the cases for ReplicatedLog's validateOffsetAndEpoch (#10276)Improves test coverage of `validateOffsetAndEpoch`. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5996; JsonConverter generates Mismatching schema DataException (#4523)JsonConverter should use object equality rather than reference equality in `convertToJson`.Reviewers: Bartlomiej Tartanus <bartektartanus@gmail.com>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Remove unnecessary store info from TopologyBuilderThis PR is extracted from https://github.com/apache/kafka/pull/2333 as an incremental fix to ease the reviewing:1. Removed `storeToProcessorNodeMap` from ProcessorTopology since it was previously used to set the context current record, and can now be replaced with the dirty entry in the named cache.2. Replaced `sourceStoreToSourceTopic` from ProcessorTopology with `storeToChangelogTopic` map, which includes the corresponding changelog topic name for all stores that are changelog enabled.3. Modified `ProcessorStateManager` to rely on `sourceStoreToSourceTopic` when retrieving the changelog topic; this makes the second parameter `loggingEnabled` in `register` not needed any more, and we can deprecate the old API with a new one.4. Also fixed a minor issue in `KStreamBuilder`: if the storeName is not provided in the `table(..)` function, do not create the underlying materialized store. Modified the unit tests to cover this case.5. Fixed a bunch of other unit tests failures that are exposed by this refactoring, in which we are not setting the applicationId correctly when constructing the mocking processor topology.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Ewen Cheslack-PostavaCloses #2338 from guozhangwang/KMinor-refactor-state-to-changelogtopic",4
"KAFKA-133 publish kafka to maven - patch by Maxime Brugidou with updates for depen by Otis Gospodnetic, reviewed by Joe Stein",5
MINOR: Fix typo in version 2.4.1 of kafka folder in Dockerfile (#8393),2
make time-based reconnect starting at a random time; patched by Yang Ye; reviewed by Jun Rao; KAFKA-268git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1291490 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: fixed javadoc typo in KafkaProducer.partitionsForAuthor: Jean-Philippe Daigle <jdaigle@tripadvisor.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2592 from jpdaigle/minor_typo_fix,2
"MINOR: Fix NPE when Connect offset contains non-primitive typeWhen storing a non-primitive type in a Connect offset, the following NullPointerException will occur:```07:18:23.702 [pool-3-thread-1] ERROR o.a.k.c.storage.OffsetStorageWriter - CRITICAL: Failed to serialize offset data, making it impossible to commit offsets under namespace tenant-db-bootstrap-source. This likely won't recover unless the unserializable partition or offset information is overwritten.07:18:23.702 [pool-3-thread-1] ERROR o.a.k.c.storage.OffsetStorageWriter - Cause of serialization failure:java.lang.NullPointerException: nullat org.apache.kafka.connect.storage.OffsetUtils.validateFormat(OffsetUtils.java:51)at org.apache.kafka.connect.storage.OffsetStorageWriter.doFlush(OffsetStorageWriter.java:143)at org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets(WorkerSourceTask.java:319)... snip ...```The attached patch fixes the specific case where OffsetUtils.validateFormat is attempting to provide a useful error message, but fails to because the schemaType method could return null.This contribution is my original work and I license the work to the project under the project's open source license.Author: Mathieu Fenniak <mathieu.fenniak@replicon.com>Reviewers: Gwen ShapiraCloses #2087 from mfenniak/fix-npr-with-clearer-error-message",0
"KAFKA-4897; Add pause method to ShutdownableThread (#4393) - Use newly added pause method in LogCleaner and ControllerChannelManager classes - Remove LogCleaner, Cleaner exclusions from findbugs-exclude.xmlReviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
MINOR: Renable SocketServerTest.closingChannelWithBufferedReceives and SocketServerTest.remoteCloseWithoutBufferedReceives (#11927)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-5746; Return 0.0 from Metric.value() instead of throwing exceptionThis is less likely to break custom metric reporters and since the methodis deprecated, people will be warned about this potential issue.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Xavier Léauté <xavier@confluent.io>Closes #3996 from ijuma/avoid-exception-in-measurable-value",5
MINOR: remove redundant null check when testing specified type (#10314)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-4093; Cluster Id (KIP-78)This PR implements  KIP-78:Cluster Identifiers [(link)](https://cwiki.apache.org/confluence/display/KAFKA/KIP-78%3A+Cluster+Id#KIP-78:ClusterId-Overview) and includes the following changes:1. Changes to broker code- generate cluster id and store it in Zookeeper- update protocol to add cluster id to metadata request and response- add ClusterResourceListener interface, ClusterResource class and ClusterMetadataListeners utility class- send ClusterResource events to the metric reporters2. Changes to client code- update Cluster and Metadata code to support cluster id- update clients for sending ClusterResource events to interceptors, (de)serializers and metric reporters3. Integration tests for interceptors, (de)serializers and metric reporters for clients and for protocol changes and metric reporters for broker.4. System tests for upgrading from previous versions.Author: Sumit Arrawatia <sumit.arrawatia@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1830 from arrawatia/kip-78",3
"MINOR: fix Scala 2.13 build error introduced in #8083 (#8301)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Brian Byrne <bbyrne@confluent.io>",5
"KAFKA-12577; Remove deprecated `ConfigEntry` constructor for 3.0 (#10436)ConfigEntry's public constructor was deprecated in 1.1.0. This patch removes it in AK 3.0.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
"KAFKA-6190: Use consumer.position() instead of record.offset() to advance in GlobalKTable restoration to avoid transactional control messagesCalculate offset using consumer.position() in GlobalStateManagerImp#restoreStateAuthor: Alex Good <alexjsgood@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4197 from alexjg/0.11.0(cherry picked from commit 1321d89484a9a0657620b20c08ce96ee43d8a691)Signed-off-by: Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Remove dependence on __consumer_offsets in AdminClient listConsumerGroupsAvoid dependence on the internal __consumer_offsets topic to handle `listConsumerGroups()` since it unnecessarily requires users to have Describe access on an internal topic. Instead we query each broker independently. For most clusters, this amounts to the same thing since the default number of partitions for __consumer_offsets is 50. This also provides better encapsulation since it avoids exposing the use of __consumer_offsets, which gives us more flexibility in the future.Author: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5007 from hachikuji/remove-admin-use-of-offsets-topic",4
KAFKA-8121; Shutdown ZK client expiry handler earlier during close (#6462)Shutdown session expiry thread prior to closing ZooKeeper client to ensure that new clients are not created by the expiry thread and left active when returning from ZooKeeperClient.close().Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-2813; selector doesn't close socket connection on non-IOExceptionsPatched Selector.poll() to close the connection on any exception.Author: Jun Rao <junrao@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Gwen Shapira <cshapi@gmail.com>Closes #501 from junrao/KAFKA-2813",5
KAFKA-13063: Make DescribeConsumerGroupsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11022)This patch improve the error handling in `DescribeConsumerGroupsHandler` and ensure that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Add ignorable field check to `toStruct` and fix usage (#7710)If a field is not marked as ignorable, we should raise an exception if it has been set to a non-default value. This check already exists in `Message.write`, so this patch adds it to `Message.toStruct`. Additionally, we fix several fields which should have been marked ignorable and we fix some related test assertions.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>, Colin Patrick McCabe <cmccabe@apache.org>",3
"KAFKA-12581: Remove deprecated `Admin.electPreferredLeaders` (#10440)`Admin.electLeaders` is the replacement since the deprecation in Apache Kafka 2.4.0.The methods were originally introduced in Apache Kafka 2.2.0, so they were onlynon deprecated for two releases.Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-3272: Add debugging options to kafka-run-class.sh so we can easily run remote debugging…able remote debugging to Kafka tools scriptsAuthor: Christian Posta <christian.posta@gmail.com>Reviewers: Grant Henke, Gwen ShapiraCloses #955 from christian-posta/ceposta-enable-jvm-debugging-opts",0
"MINOR: remove unused code from InternalTopicManagerRemove isValidCleanupPolicy and related fields as they are never used.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1888 from dguy/minor-remove-unused",4
"MINOR: Improve javadocs for offset retention (#12552)Our docs for offset retention has been outdated and hence needs to be updated. Also I think it's better to indicate how we handle offsets when delete-topics and delete-groups.Reviewers: Victoria Xia <victoria.f.xia281@gmail.com>, Luke Chen <showuon@gmail.com>",4
"KAFKA-3912: Query local state storesguozhangwang enothereska please reviewAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Michael G. Noll, Guozhang WangCloses #1565 from dguy/kafka-3912",5
"KAFKA-10545: Create topic IDs and propagate to brokers (#9626)This change propagates topic ids to brokers in LeaderAndIsr Request. It also removes the topic name from the LeaderAndIsr Response, reorganizes the response to be sorted by topic, and includes the topic ID.In addition, the topic ID is persisted to each replica in Log as well as in a file on disk. This file is read on startup and if the topic ID exists, it will be reloaded.Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>, Nikhil Bhatia <rite2nikhil@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-7471: Multiple Consumer Group Management Feature (#5726)* Describe/Delete/Reset offsets on multiple consumer groups at a time (including each group by repeating `--group` parameter)* Describe/Delete/Reset offsets on ALL consumer groups at a time (add new `--all-groups` option similar to `--all-topics`)* Reset plan CSV file generation reworked: structure updated to support multiple consumer groups and make sure that CSV file generation is done properly since there are no restrictions on consumer group names and symbols like commas and quotes are allowed.* Extending data output table format by adding `GROUP` column for all `--describe` queries,1
HOTFIX: Fix infinite loop in AbstractIndex.indexSlotRangeFor (#7702)Fixes regression from #5378 which causing an infinite loop in `binarySearch`.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: Improve performance of checkpointHighWatermarks, patch 1/2 (#6741)This PR works to improve high watermark checkpointing performance.`ReplicaManager.checkpointHighWatermarks()` was found to be a major contributor to GC pressure, especially on Kafka clusters with high partition counts and low throughput.Added a JMH benchmark for `checkpointHighWatermarks` which establishes aperformance baseline. The parameterized benchmark was run with 100, 1000 and2000 topics. Modified `ReplicaManager.checkpointHighWatermarks()` to avoid extra copies and cachedthe Log parent directory Sting to avoid frequent allocations when calculating`File.getParent()`.A few clean-ups:* Changed all usages of Log.dir.getParent to Log.parentDir and Log.dir.getParentFile toLog.parentDirFile.* Only expose public accessor for `Log.dir` (consistent with `Log.parentDir`)* Removed unused parameters in `Partition.makeLeader`, `Partition.makeFollower` and `Partition.createLogIfNotExists`.Benchmark results:| Topic Count | Ops/ms | MB/sec allocated ||-------------|---------|------------------|| 100               | + 51%    |  - 91% || 1000             | + 143% |  - 49% || 2000            | + 149% |   - 50% |Reviewers: Lucas Bradstreet <lucas@confluent.io>. Ismael Juma <ismael@juma.me.uk>Co-authored-by: Gardner Vickers <gardner@vickers.me>Co-authored-by: Ismael Juma <ismael@juma.me.uk>",5
MINOR: Update comment on verifyTaskGenerationAndOwnership method in DistributedHerderReviewers: Chris Egerton <fearthecellos@gmail.com>,5
"KAFKA-6768; Transactional producer may hang in close with pending requests (#4842)This patch fixes an edge case in producer shutdown which prevents `close()` from completing due to a pending request which will never be sent due to shutdown initiation. I have added a test case which reproduces the scenario.Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Use sha512 instead of sha2 suffix in release artifactsAs per Apache guidelines:http://www.apache.org/dev/release-distribution#sigs-and-sumsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3844 from ijuma/fix-sha512-naming,0
"KAFKA-12976; Remove UNSUPPORTED_VERSION error from delete topics call (#10923)Removed the condition to throw the error. Now we return UNKNOWN_TOPIC_ID which allows clients to retry instead of failing. Updated the test for IBP < 2.8 that tries to delete topics using ID.Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4010: add ConfigDef toEnrichedRst() for additional fields in outputfollowup on https://github.com/apache/kafka/pull/1696cc rekhajoshmAuthor: Shikhar Bhushan <shikhar@confluent.io>Author: Joshi <rekhajoshm@gmail.com>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1964 from shikhar/kafka-4010",5
"KAFKA-353 Tie producer-side ack with high watermark and progress of replicas; patched by Joel Koshy; reviewed by Jun Rao, Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1355578 13f79535-47bb-0310-9956-ffa450edef68",2
KAFKA-8265: Fix override config name to match KIP-458. (#6776)Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-9921: disable caching on stores configured to retain duplicates (#8564)These two options are essentially incompatible, as caching will do nothing to reduce downstream traffic and writes when it has to allow non-unique keys (skipping records where the value is also the same is a separate issue, see KIP-557). But enabling caching on a store that's configured to retain duplicates is actually more than just ineffective, and currently causes incorrect results.We should just log a warning and disable caching whenever a store is retaining duplicates to avoid introducing a regression. Maybe when 3.0 comes around we should consider throwing an exception instead to alert the user more aggressively.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",5
"MINOR: Ensure compile and runtime classpaths have consistent versions (#9921)Ensure that runtime-only dependencies don't cause a different version to be used.More specifically:> The relationship is directed, which means that if the runtimeClasspath configurationhas to be resolved, Gradle will first resolve the compileClasspath and then ""inject"" theresult of resolution as strict constraints into the runtimeClasspath.For more details, see:https://docs.gradle.org/6.8/userguide/resolution_strategy_tuning.html#sec:configuration_consistencyReviewers: Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-9630; Replace OffsetsForLeaderEpoch request/response with automated protocol (#9547)This PR migrates the OffsetsForLeaderEpoch request/response to the automated protocol. It also refactors the OffsetsForLeaderEpochClient to use directly the internal structs generated by the automated protocol. It relies on the existing tests.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Propagate LogContext to channel builders and SASL authenticator (#7867)The log context is useful when debugging applications which have multiple clients. This patch propagates the context to the channel builders and the SASL authenticator.Reviewers: Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
KAFKA-9607: Do not clear partition queues during close (#8168)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-2826: Make Kafka Connect ducktape services easier to extend.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #522 from ewencp/kafka-2826-extensible-connect-services,1
"MINOR: Verify mocks in all WorkerTest tests and don't unnecessarily mockStatic the Plugins classAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3319 from ewencp/minor-worker-test-cleanup",3
kafka-1799; (add missing test file) ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG doesn't work; patched by Manikumar Reddy; reviewed by Jun Rao,1
KAFKA-2186; Follow-up to KAFKA-1650 - add selective offset commit toconsumer connector API; reviewed by Joel Koshy,1
KAFKA-5544; The LastStableOffsetLag metric should be removed when partition is deletedAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3463 from lindong28/KAFKA-5544,4
"KAFKA-3559: Recycle old tasks when possibleAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2032 from enothereska/KAFKA-3559-onPartitionAssigned",5
KAFKA-9656; Return COORDINATOR_NOT_AVAILABLE for older producer clients (#8253)The `TxnOffsetCommit` API suffers from a bug affecting older client versions which treat `COORDINATOR_LOAD_IN_PROGRESS` errors as fatal. This PR changes the handling on the broker to instead return `COORDINATOR_NOT_AVAILABLE` in this case so that clients won't crash upon doing txn commit. Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-3133: Add putIfAbsent function to KeyValueStoreguozhangwangAuthor: Kim Christensen <kich@mvno.dk>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #912 from kichristensen/KAFKA-3133",1
MINOR: Upstream QuotaConfigsThis PR moves static property definitions for user client quotas into anew class called QuotaConfigs in the clients module under theo.a.k.common.config.internals package. This is needed to support theclient quotas work in the quorum based controller.Reviewers: Colin McCabe <cmccabe@apache.org>,1
"KAFKA-10716: persist UUID in state directory for stable processId across restarts (#9978)To stabilize the task assignment across restarts of the JVM we need some way to persist the process-specific UUID. We can just write it to a file in the state directory, and initialize it from there or create a new one if no prior UUID exists.Reviewers: Walker Carlson <wcarlson@confluent.io>, Leah Thomas <lthomas@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Fix unnecessary metadata fetch before group assignment (#8095)The recent increase in the flakiness of one of the offset reset tests (KAFKA-9538) traces back to https://github.com/apache/kafka/pull/7941. After investigation, we found that following this patch, the consumer was sending an additional metadata request prior to performing the group assignment. This slight timing difference was enough to trigger the test failures. The problem turned out to be due to a bug in `SubscriptionState.groupSubscribe`, which no longer counted the local subscription when determining if there were new topics to fetch metadata for. Hence the extra metadata update. This patch restores the old logic.Without the fix, we saw 30-50% test failures locally. With it, I could no longer reproduce the failure. However, #6561 is probably still needed to improve the resilience of this test.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
Update Gradle to 6.4.1 (#8678)This fixes critical bugs in Gradle 6.4:* Regression: Different daemons are used between IDE and CLI builds for the same project* Regression: Main-Class attribute always added to jar manifest when using application plugin* Fix potential NPE if code is executed concurrentlyMore details: https://github.com/gradle/gradle/releases/tag/v6.4.1Reviewers: Manikumar Reddy <manikumar@confluent.io>,5
"KAFKA-7912: Support concurrent access in InMemoryKeyValueStore (#6336)Previously the InMemoryKeyValue store would throw a ConcurrentModificationException if the store was modified beneath an open iterator. The TreeMap implementation was swapped with a ConcurrentSkipListMap for similar performance while supporting concurrent access.Added one test to AbstractKeyValueStoreTest, no existing tests caught this.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13264: fix inMemoryWindowStore backward fetch not in reversed order (#11292)When introducing backward iterator for WindowStroe in #9138, we forgot to make ""each segment"" in reverse order (i.e. in descendingMap) in InMemoryWindowStore. Fix it and add integration tests for it.Currently, in Window store, we store records in [segments -> [records] ].For example:window size = 500,input records:key: ""a"", value: ""aa"", timestamp: 0 ==> will be in [0, 500] windowkey: ""b"", value: ""bb"", timestamp: 10 ==> will be in [0, 500] windowkey: ""c"", value: ""cc"", timestamp: 510 ==> will be in [500, 1000] windowSo, internally, the ""a"" and ""b"" will be in the same segment, and ""c"" in another segments.segments: [0 /* window start */, records], [500, records].And the records for window start 0 will be ""a"" and ""b"".the records for window start 500 will be ""c"".Before this change, we did have a reverse iterator for segments, but not in ""records"". So, when doing backwardFetchAll, we'll have the records returned in order: ""c"", ""a"", ""b"", which should be ""c"", ""b"", ""a"" obviously.Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <wangguoz@gmail.com>",4
MINOR; Remove unused AdminZkClient in MetadataSupport (#11785)Remove unused AdminZkClient in MetadataSupportReviewers: Luke Chen <showuon@gmail.com>,5
KAFKA-731 use a variable for the ivy2 path in kafka-run-class.sh patch by Joe Stein reviewed by Neha Narkhede,1
"KAFKA-13778: Fetch from follower should never run the preferred read replica selection (#11965)The current preferred read replica selection logic relies on `partition.leaderReplicaIdOpt` to determine if the selection must be run. The issue is that `partition.leaderReplicaIdOpt` is defined for both the leader and the followers thus the logic is ran all the time. The impact is not too bad as the leader is selected most of the time when the logic is ran by the follower and the leader is filtered out. However there are cases where the selection on a follower could redirect the consumer to another follower under certain rare conditions. For instance with the `RackAwareReplicaSelector `, the follower must have stale replica states from a previous leadership and must have other followers in the same rack for instance. Other implementation of the selection logic could be more impacted.This patch ensures that the preferred read replica selection is only ran by the leader.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: clean up unneeded `@SuppressWarnings` (#10855)Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2
"MINOR: Remove redudant test files and close LogSegment after test (#10592)Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-10263: Do not assign standby for revoking stateless tasks (#9005)Also piggy-back a small fix to use TreeMap other than HashMap to preserve iteration ordering.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"HOTFIX: Set session interval back to 10s for StreamsCooperativeRebalanceUpgradeTest (#11103)This test is hitting pretty frequent timeouts after bouncing a node and waiting for it to come back and fully rejoin the group. It seems to now take 45s for the initial JoinGroup to succeed, which I suspect is due to the new default session.interval.ms (which was recently changed to 45s). Let's try fixing this config to the old value of 10s and see if that helps it rejoin in time.Reviewer: Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Use Java 8 lambdas in KStreamImplTest (#6430)Just a minor cleanup to use Java 8 lambdas vs anonymous classes in this test.I ran all tests in the streams test suiteReviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",3
KAFKA-6576: Configurable Quota Management (KIP-257) (#4699)Enable quota calculation to be customized using a configurable callback. See KIP-257 for details.Reviewers: Jun Rao <junrao@gmail.com>,5
Bump version to 0.10.3.0-SNAPSHOT,5
MINOR: Added changes in 0.10.2.1Author: Eno Thereska <eno@confluent.io>Reviewers: Gwen ShapiraCloses #2824 from enothereska/minor-docs-0.10.2.1(cherry picked from commit 5a68fa7e4e1315801c3128f95deedc0b2221ffaa)Signed-off-by: Gwen Shapira <cshapi@gmail.com>,2
"MINOR: Fix javadoc errors in `RaftClient` (#10901)This patch fixes a few minor javadoc issues in the `RaftClient` interface.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-9307; Make transaction metadata loading resilient to previous errors (#7840)Allow transaction metadata to be reloaded, even if it already exists as of a previous epoch. This helps with cases where a previous become-follower transition failed to unload corresponding metadata.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Producer performance tool should use the new blocking async producer instead of the sleep timeout hack; KAFKA-118; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160947 13f79535-47bb-0310-9956-ffa450edef68,1
kafka-1616; Purgatory Size and Num.Delayed.Request metrics are incorrect; patched by Guozhang Wang; reviewed by Jun Rao,5
"KAFKA-6311: Expose Kafka cluster ID in Connect REST API (KIP-238) (#4314)Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-14114: Add Metadata Error Related MetricsThis PR adds in 3 metrics as described in KIP-859: kafka.server:type=broker-metadata-metrics,name=metadata-load-error-count kafka.server:type=broker-metadata-metrics,name=metadata-apply-error-count kafka.controller:type=KafkaController,name=MetadataErrorCountThese metrics are incremented by fault handlers when the appropriate fault happens. Broker-sideload errors happen in BrokerMetadataListener. Broker-side apply errors happen in theBrokerMetadataPublisher. The metric on the controller is incremented when the standby controller(not active) encounters a metadata error.In BrokerMetadataPublisher, try to limit the damage caused by an exception by introducing morecatch blocks. The only fatal failures here are those that happen during initialization, when weinitialize the manager objects (these would also be fatal in ZK mode).In BrokerMetadataListener, try to improve the logging of faults, especially ones that happen whenreplaying a snapshot. Try to limit the damage caused by an exception.Replace MetadataFaultHandler with LoggingFaultHandler, which is more flexible and takes a Runnableargument. Add LoggingFaultHandlerTest.Make QuorumControllerMetricsTest stricter. Fix a bug where we weren't cleaning up some metrics fromthe yammer registry on close in QuorumControllerMetrics.Co-author: Colin P. McCabe <cmccabe@apache.org>",1
kafka-1574; unit tests can hang on socketserver shutdown; patched by Jun Rao; reviewed by Jay Kreps and Guozhang Wang,3
MINOR: Update `TransactionalMessageCopier` to use the latest transaction pattern (#11265)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Remove `TargetVoters` from `DescribeQuorum` (#9376)This field is leftover from the early days of the KIP when it covered reassignment. The API is not exposed yet, so there is no harm updating the first version.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-9492; Ignore record errors in ProduceResponse for older versions (#8030)Fixes NPE in brokers when processing record errors in produce response for older versions.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4800: Streams State transition ASCII diagrams need fixing and polishingadded \<pre> tags to not break javadoc display of the ASCII diagrams.see broken ascii here:https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/KafkaStreams.State.htmlfix can be checked with gradle :streams:javadoc and then checking streams/build/docs/javadoc/org/apache/kafka/streams/KafkaStreams.State.htmlI also fixed the diagram in StreamThread.java however currently no javadoc is generated for that one (since it's internal)enothereska please have a lookAuthor: Clemens Valiente <clemens.valiente@trivago.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2621 from cvaliente/KAFKA-4800-ASCII-diagrams",2
KAFKA-3245: config for changelog replication factorguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #948 from ymatsuda/changelog_topic_replication,4
"KAFKA-957; MirrorMaker needs to preserve ordering for keyed messages from source cluster; patched by Guozhang Wang, reviewed by Joel Koshy",1
MINOR: use relative counts for restores (#11176)Use a relative count from using 0 for totalNumbRestores to prevent flakiness.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
MINOR: cleanup for postProcessAndValidateIdempotenceConfigs method (#12069)Reviewers: Luke Chen <showuon@gmail.com>,5
"MINOR: Enable testUpdateFeaturesWithForwarding (#12059)This test was removed in #11667 since UpdateFeatures is not properly handled in KRaft mode, now we can bring it back since UpdateFeatures is properly handled after #12036.Reviewers: Luke Chen <showuon@gmail.com>",0
MINOR: Remove unused LeaderAndIsrResponse.partitions() since it has been replaced with partitionErrors() (#10127)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Add System test for standby task-rebalancing (#4554)Author: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"kafka-1392; all TestUtiles.waitUntilTrue() should throw an exception if the return value is false; patched by Jun Rao; reviewed by Guozhang Wang, Neha Narkhede and Joel Koshy",3
"KAFKA-7738; Track leader epochs in client Metadata (#6045)Track the last seen partition epoch in the Metadata class. When handling metadata updates, check that the partition info being received is for the last seen epoch or a newer one. This prevents stale metadata from being loaded into the client.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-2852; Updating the Authorizer CLI to use a consistent way to specify a list of values for a config options.…ecify a list of values for a config options.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #545 from Parth-Brahmbhatt/KAFKA-2852,5
Minor: code enhancment (#6999)Reviewers: Bill Bejeck <bbejeck@gmail.com>,5
"KAFKA-2058: Fix ProducerTest.testSendWithDeadBroker transient failureIt turns that waitUntilMetadataIsPropagated is not enough;in ""onBrokerStartup"", methods below will send send both LeaderAndIsrRequest and UpdateMetadataRequest to KafkaApis:    replicaStateMachine.handleStateChanges(allReplicasOnNewBrokers, OnlineReplica)    partitionStateMachine.triggerOnlinePartitionStateChange()The two kinds of request are handled seperately and we are not sure about the order;If UpdateMetadataRequest is handled first, metadataCache of kafkaApis will be updated, thus TestUtils.waitUntilMetadataIsPropagated will be satisfied, and consumer can(will) start fetching data;But if the LeaderAndIsrRequest is not handled at this moment, ""becomeLeaderOrFollower"" cannot be called , thus structures like ""leaderReplicaOpt"" cannot be updated, which leads to failure of consumer's fetching data;To fix above, consumer should start fetching data after partition's leaderReplica is refreshed, not just the leader is elected;So added ""TestUtils.waitUntilLeaderIsKnown(servers, topic, 0)""Author: ZoneMayor <jinxing6042@126.com>Author: jinxing <jinxing@fenbi.com>Reviewers: Ismael Juma, Guozhang WangCloses #689 from ZoneMayor/trunk-KAFKA-2058",1
"KAFKA-12486: Enforce Rebalance when a TaskCorruptedException is throw… (#11076)This PR aims to utilize HighAvailabilityTaskAssignor to avoid downtime on corrupted tasks. The idea is that, when we hit TaskCorruptedException on an active task, a rebalance is triggered after we've wiped out the corrupted state stores. This will allow the assignor to temporarily redirect this task to another client who can resume work on the task while the original owner works on restoring the state from scratch.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
KAFKA-1783; Add missing slash in documentation for consumer's ZK path; reviewed by Guozhang Wang,2
kafka-1271; controller logs exceptions during ZK session expiration; patched by Jun Rao; reviewed by Guozhang Wang and Jay kreps,2
"KAFKA-12650: fix NPE in InternalTopicManagerTest (#10529)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen (@showuon), Bruno Cadonna <bruno@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
Use getMetadata Api in ZookeeperConsumerConnector; patched by Yang Ye; reviewed by Jun Rao; KAFKA-473git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1390798 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-3202: System test that changes message version on the flybecketqin apovzner please have a look. becketqin the test fails when the producer and consumer are 0.9.x and the message format changes on the fly.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ewen Cheslack-Postava, Ismael Juma, Gwen ShapiraCloses #1070 from enothereska/kafka-3202-format-change-fly",4
"KAFKA-4725; Stop leaking messages in produce request body when requests are delayedThis change is in response to [KAFKA-4725](https://issues.apache.org/jira/browse/KAFKA-4725).When a produce request is received, if the user/client is exceeding their produce quota, the response will be delayed until the quota is refilled appropriately.Unfortunately, the request body is still referenced in the callback which in turn leaks the messages contained within the request.This change allows the `KafkaApis` method to take ownership of the request body from the `RequestChannel.Request` object.I am not sure whether this breaks other invariants which are assumed within other parts of Kafka.Author: Tim Carey-Smith <tim@spork.in>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2496 from halorgium/fix-throttled-response-leak",0
HOTFIX: Use the correct serde classesAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #991 from guozhangwang/KSerde,1
"MINOR: fix typo ""intervall"" to ""interval"" (#5435)Co-authored-by: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
"KAFKA-12955: Fix LogLoader to pass materialized view of segments for deletion (#10888)Within LogLoader.removeAndDeleteSegmentsAsync(), we should force materialization of the segmentsToDelete iterable, to make sure the results of the iteration remain valid and deterministic. We should also pass only the materialized view to the logic that deletes the segments, as otherwise we could end up deleting the wrong segments.Reviewers: Jun Rao <junrao@gmail.com>",0
AsyncProducerStats is not a singleton; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-207git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205659 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12344 Support SlidingWindows in the Scala API (#10519)Support SlidingWindows in the Scala APIReviewers: Leah Thomas <lthomas@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
change ProducerShell to use high level producer; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-195git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1198849 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Update usage of deprecated API (#6146)Reviewers: Guozhang Wang <guozhang@confluent.io>, Ismael Juma <ismael@confluent.io>, Jorge Quilcate Otoya <quilcate.jorge@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: A bunch of clean-ups related to usage of unused variablesThere should be only one cases where these clean-ups have a functional impact: replaced repeated identical logs with a single log for the stale controller epoch case.The rest should just make the code easier to read and make it a bit less wasteful. I did this exercise because unused variables sometimes mask bugs.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1985 from ijuma/remove-unused,4
KAFKA-3299: Ensure that reading config log on rebalance doesn't hang the herderAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #981 from gwenshap/KAFKA-3299,5
"KAFKA-5494; Enable idempotence with max.in.flight.requests.per.connection > 1Here we introduce client and broker changes to support multiple inflight requests while still guaranteeing idempotence. Two major problems to be solved:1. Sequence number management on the client when there are request failures. When a batch fails,  future inflight batches will also fail with `OutOfOrderSequenceException`. This must be handled on the client with intelligent sequence reassignment. We must also deal with the fatal failure of some batch: the future batches must get different sequence numbers when the come back.2. On the broker, when we have multiple inflights, we can get duplicates of multiple old batches. With this patch, we retain the record metadata for 5 older batches.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3743 from apurvam/KAFKA-5494-increase-max-in-flight-for-idempotent-producer",1
"KAFKA-2594: Add InMemoryLRUCacheStore as a preliminary method for bounding in-memory storesAdded a new `KeyValueStore` implementation called `InMemoryLRUCacheStore` that keeps a maximum number of entries in-memory, and as the size exceeds the capacity the least-recently used entry is removed from the store and the backing topic. Also added unit tests for this new store and the existing `InMemoryKeyValueStore` and `RocksDBKeyValueStore` implementations. A new `KeyValueStoreTestDriver` class simplifies all of the other tests, and can be used by other libraries to help test their own custom implementations.This PR depends upon [KAFKA-2593](https://issues.apache.org/jira/browse/KAFKA-2593) and its PR at https://github.com/apache/kafka/pull/255. Once that PR is merged, I can rebase this PR if desired.Two issues were uncovered when creating these new unit tests, and both are also addressed as separate (small) commits in this PR:* The `RocksDBKeyValueStore` initialization was not creating the file system directory if missing.* `MeteredKeyValueStore` was casting to `ProcessorContextImpl` to access the `RecordCollector`, which prevent using `MeteredKeyValueStore` implementations in tests where something other than `ProcessorContextImpl` was used. The fix was to introduce a `RecordCollector.Supplier` interface to define this `recordCollector()` method, and change `ProcessorContextImpl` and `MockProcessorContext` to both implement this interface. Now, `MeteredKeyValueStore` can cast to the new interface to access the record collector rather than to a single concrete implementation, making it possible to use any and all current stores inside unit tests.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Edward Ribeiro, Guozhang WangCloses #256 from rhauch/kafka-2594",3
KAFKA-2830; Change default fix version to 0.9.1.0 in kafka-merge-pr.pyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #523 from ijuma/kafka-2830-fix-version-0.9.1.0,0
MINOR: Fix menu ordering in streams docshttps://issues.apache.org/jira/browse/KAFKA-6419Related: https://github.com/apache/kafka-site/pull/115Author: Joel Hamill <joel-hamill@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4390 from joel-hamill/fix-streams-menu-order,0
"KAFKA-4745; Remove unnecessary flush in KafkaLZ4BlockOutputStream.close()Remove unnecessary 'flush', the underlying stream should handle it on close.Author: Will Droste <william.droste@arris.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2528 from wdroste/trunk",1
"KAFKA-2411; remove usage of blocking channelAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Gwen Shapira <cshapi@gmail.com>Closes #151 from ijuma/kafka-2411-remove-usage-of-blocking-channel",4
"KAFKA-3219: Fix long topic name validationThis fixes an issue with long topic names by considering, during topicvalidation, the '-' and the partition id that is appended to the logfolder created for each topic partition.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen Shapira, Grant HenkeCloses #898 from vahidhashemian/KAFKA-3219",1
Fix compile issue from last commit. Oops. :-(,0
kafka-server-stop.sh doesn't stop broker; reviewed by Neha Narkhede,5
"KAFKA-12258; Add support for splitting appending records (#10063)1. Type `BatchAccumulator`. Add support for appending records into one or more batches.2. Type `RaftClient`. Rename `scheduleAppend` to `scheduleAtomicAppend`.3. Type `RaftClient`. Add a new method `scheduleAppend` which appends records to the log using as many batches as necessary.4. Increase the batch size from 1MB to 8MB.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix indentation for several doc pages (#10766)Fixes the indentation of the code listings for:api.htmlconfiguration.htmldesign.htmlimplementation.htmltoc.htmlThese changes consist of whitespaces added or removed for consistency. It also contains a couple of fixes on unbalanced html tags.Reviewers: Luke Chen <showuon@gmail.com>, Bill Bejeck <bbejeck@apache.org>",0
KAFKA-683 Fix correlation id in all requests sent to kafka; reviewed by Jun Rao,0
"KAFKA-1112; broker can not start itself after kafka is killed with -9; patched by Jay Kreps and Jun Rao; reviewed by Jay Kreps, Neha Narkhede and Guozhang Wang",5
"MINOR: Fix typos in config properties in MM2 test (#8561)Fixed typos in two MM2 configs that define the replication factor for internal Connect topics.Only a single test was affected. Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
MINOR: Increase consumer init timeout in throttling testThe throttling system test sometimes fail because it takes longer than the current 10 second time out for partitions to get assigned to the consumer.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2567 from apurvam/increase-timeout-for-partitions-assigned,1
KAFKA-9533: Fix JavaDocs of KStream.transformValues (#8298)Reviewers: Bill Bejeck <bill@confluent.io>,5
"MINOR: Upgrade RocksDB to 5.13.4 (#5309)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-4583; Fix KafkaConsumerTest.testGracefulClose transient failureAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2309 from rajinisivaram/KAFKA-4583,5
"MINOR: comment apikey types in generated switch (#8201)As a developer, it would be convenient if the generated{request,response}HeaderVersion case statements in ApiMessageType.javaincluded a comment to remind me which type each of them is so I don'tneed to manually cross-reference the newer/rarer ones.Also include commented lines for the two special cases aroundApiVersionsResponse and ControllerShutdownRequest which are hardcoded inthe ApiMessageTypeGenerator.java and not covered by the message formatjson files.Before:```java    public short requestHeaderVersion(short _version) {        switch (apiKey) {            case 0:                return (short) 1;            case 1:                return (short) 1;            case 2:                return (short) 1;            case 3:                if (_version >= 9) {                    return (short) 2;                } else {                    return (short) 1;                }            // ...etc```After:```java    public short requestHeaderVersion(short _version) {        switch (apiKey) {            case 0: // Produce                return (short) 1;            case 1: // Fetch                return (short) 1;            case 2: // ListOffset                return (short) 1;            case 3: // Metadata                if (_version >= 9) {                    return (short) 2;                } else {                    return (short) 1;                }            // ...etc```Signed-off-by: Dominic Evans <dominic.evans@uk.ibm.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>",5
MINOR: improve JavaDocs for TimestampExtractor interfaceAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3264 from mjsax/minor-javadocs-timestamp-extractor,4
"KAFKA-6118: Fix transient failure testTwoConsumersWithDifferentSaslCredentialsIt's rare, but it can happen that the initial FindCoordinator request returns before the first Metadata request. Both authorization errors are fine for this test case.Author: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4287 from hachikuji/KAFKA-6118",5
"KAFKA-12440; ClusterId validation for Vote, BeginQuorum, EndQuorum and FetchSnapshot (#10289)Previously we implemented ClusterId validation for the Fetch API in the Raft implementation. This patch adds ClusterId validation to the remaining Raft RPCs. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Add debug logs for StreamThread (#9267)Add debug logs to see when Streams calls poll, process, commit, etc.Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@apache.org>",5
"MINOR: add unit test for KGroupedTable.countAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Michael G. Noll <michael@confluent.io>Closes #1255 from dguy/kgroupedtable-count-test",3
"MINOR: WorkerUtils#abort: fix bug in abort logic (#6516)doneFuture is supposed to be completed with an empty string (meaning success) or a non-empty string which is the error message.  Currently, due to exception.getMessage sometimes returning null or an empty string, this is not working correctly.  This patch fixes that.Reviewers: David Arthur <mumrah@gmail.com>",0
"KAFKA-6761: Part 1 of 3; Graph nodes (#4923)This PR supersedes PR #4654 as it was growing too large. All comments in that PR should be addressed here.I will attempt to break the PRs for the topology optimization effort into 3 PRs total and will follow this general plan:1. This PR only adds the graph nodes and graph. The graph nodes will hold the information used to make calls to the InternalTopologyBuilder when using the DSL. Graph nodes are stored in the StreamsTopologyGraph until the final topology needs building then the graph is traversed and optimizations are made at that point. There are no tests in this PR relying on the follow-up PR to use all current streams tests, which should suffice.2. PR 2 will intercept all DSL calls and build the graph. The InternalStreamsBuilder uses the graph to provide the required info to the InternalTopologyBuilder and build a topology. The condition of satisfaction for this PR is that all current unit, integration and system tests pass using the graph.3. PR 3 adds some optimizations mainly automatically repartitioning for operations that may modify a key and have child operations that would normally create a separate repartition topic, saving possible unnecessary repartition topics. For example the following topology:```KStream<String, String> mappedStreamOther = inputStream.map(new KeyValueMapper<String, String, KeyValue<? extends String, ? extends String>>() {            @Override            public KeyValue<? extends String, ? extends String> apply(String key, String value) {                return KeyValue.pair(key.substring(0, 3), value);            }        });        mappedStreamOther.groupByKey().windowedBy(TimeWindows.of(5000)).count().toStream().to(""count-one-out"");        mappedStreamOther.groupByKey().windowedBy(TimeWindows.of(10000)).count().toStream().to(""count-two-out"");        mappedStreamOther.groupByKey().windowedBy(TimeWindows.of(15000)).count().toStream().to(""count-three-out"");```would create 3 repartion topics, but after applying an optimization strategy, only one is created.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Convert `ReassignPartitionsIntegrationTest` to KRaft (#12258)Updates relevant tests in `ReassignPartitionsIntegrationTest` for KRaft. We skip JBOD tests since it is not supported and we skip `AlterPartition` upgrade tests since they are not relevant.Reviewers: Kvicii <Karonazaba@gmail.com>, David Arthur <mumrah@gmail.com>",3
MINOR: disable test_produce_bench_transactions for Raft metadata quorum (#10222)Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
"MINOR: Remove Deprecated Scala Procedure Syntax (#7214)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",4
"KAFKA-7157: Fix handling of nulls in TimestampConverter (#7070)Fix handling of nulls in TimestampConverter.Authors: Valeria Vasylieva <valeria.vasylieva@gmail.com>, Robert Yokota <rayokota@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
some more changes,4
KAFKA-5059 Follow-up: Remove broken locking and fix handleAddPartitionsremove broken locking. fix handleAddPartitions after complete commit/abortrespond with CONCURRENT_TRANSACTIONS in initPidAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2934 from dguy/follow-up-tc-work,1
MINOR: Add a release script that helps generate release candidates.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #2795 from ewencp/release-script and squashes the following commits:f1d0590 [Ewen Cheslack-Postava] Don't expose promotion to the user since it is not implemented yet.1a6947a [Ewen Cheslack-Postava] Handle cleanup if there's a failure during generation of release notes.fa58401 [Ewen Cheslack-Postava] Fix hard-coded uses of trunk639bcca [Ewen Cheslack-Postava] Try to cleanup after most failures.a3a7245 [Ewen Cheslack-Postava] Fix SCRIPT_DIR to be an absolute path so git clones against the REPO work when it is also your cwdde54c97 [Ewen Cheslack-Postava] Load/save preferences in a .release-settings.json file so you don't have to keep entering the same info repeatedlyb559a61 [Ewen Cheslack-Postava] Check that the user doesn't have any oustanding diffs before starting the rest of the scriptff0b330 [Ewen Cheslack-Postava] Store original starting branch to switch back to instead of using a default.b793562 [Ewen Cheslack-Postava] Use 2.12 instead of specific Scala version so we use the default 2.12 version.382b7f9 [Ewen Cheslack-Postava] MINOR: Add a release script that helps generate release candidates.,5
"KAFKA-12657: Increase timeouts in Connect integration tests (#12191)As an initial step to address the notoriously flaky BlockingConnectorTest test suite, we can try increasing test timeouts.This approach may not be sufficient, and even if it is, it's still suboptimal. Although it may address flakiness on Jenkins, it will make genuine failures harder to detect when testing local changes. Additionally, if the workload on Jenkins continues to increase, we'll probably have to bump these timeouts in the future again at some point.Potential next steps, for this PR and beyond:    Stop leaking threads that block during test runs    Instead of artificially reducing the REST request timeout at the beginning of every test, reduce it selectively right before issuing a REST request that is expected to time out, and then immediately reset it.    Eliminate artificial reduction of the REST request timeout entirely, as it may be negatively impacting other Connect integration tests that are being run concurrently.    Test repeatedly on Jenkins, ideally at least 50 times    Gather information on the number of CPU cores available to each Jenkins node and the distribution of how many threads are allocated over a given time period (maybe a day?); this is especially relevant since local testing indicates that these tests all do much better when parallelism is reduced, which shouldn't be too surprising considering that each Connect integration test spins up separate threads for at least one Zookeeper node, one Kafka broker, one Connect worker, and usually at least one connector and one task.I'd like to test these changes as a first step before investigating any of the above (except maybe items 1 and 2, which should be fairly straightforward). To trigger new runs I plan on pushing empty commits or, if those do not trigger new Jenkins runs, dummy commits. If this is objectionable let me know and hopefully we can find a suitable alternative.Reviewers: Kvicii <Karonazaba@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
KAFKA-2121; Close internnal modules upon client shutdown; reviewed by Ewen Cheslack-Postava and Guozhang Wang,5
"KAFKA-13585; Fix flaky test `ReplicaManagerTest.testReplicaAlterLogDirsWithAndWithoutIds` (#11665)The issue was quite subtile. It was due to a race for the `partitionMapLock` lock. `assertFetcherHasTopicId` would only succeed if it can acquire it before `processFetchRequest`. This PR refactors the test in order to make it more stable.Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>,",5
"KAFKA-2576; ConsumerPerformance hangs when SSL enabled for Multi-Partition TopicWe now write to the channel with an empty buffer whenthere are pending bytes remaining and all data has beensent.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>Closes #236 from ijuma/kafka-2576-ssl-multi-partition-topic-hang",1
"KAFKA-10648: Add Prefix Scan support to State Stores (#9508)Add prefix scan support to State stores. Currently, only RocksDB and InMemory key value stores are being supported.Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7211; MM should handle TimeoutException in commitSyncWith KIP-266 introduced, MirrorMaker should handle TimeoutException thrown in commitSync(). Besides, MM should only commit offsets for existsing topics.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5492 from huxihx/KAFKA-7211",1
"KAFKA-3197; Fix producer sending records out of orderThis patch reuse max.in.flight.request.per.connection. When it equals to one, we take it as user wants order protection. The current approach is make sure there is only one batch per partition on the fly.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Jason Gustafson <jason@confluent.io>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>, Jun Rao <junrao@gmail.com>Closes #857 from becketqin/KAFKA-3197",5
"KAFKA-5378; Return LSO in FetchResponse plus some metricsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3248 from hachikuji/KAFKA-5378",5
KAFKA-5443; Consumer should use last offset from batch to set next fetch offsetAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3331 from hachikuji/KAFKA-5443,5
"KAFKA-12156: Document single threaded response handling in Admin client (#9842)If users block the response handling thread in one call waiting for the resultof a second ""nested"" call then the client effectively hangs because the 2ndcall's response will never be processed.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"MINOR: don't assign standby tasks with no logged state (#8147)Right now the task assignor just blindly assigns N standby tasks per active task (where N = num.standbys) and attempts to distribute them evenly across all instances/threads. But only standby tasks that are stateful, and whose stores are changelog-enabled, will ever actually be created.This can result in a less-balanced assignment, and should be cleaned up in particular before implementing KIP-441 to remove the noise of ghost standbys.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Consolidate Topic classesDuring the 0.11.0.0 cycle, a Java version of the classwas introduced so that Streams could use it. Given thatit includes the bulk of the functionality of the Scalaversion of the class, it makes sense to consolidate them.While doing this, I noticed that one of the tests forthe Java class (`shouldThrowOnInvalidTopicNames`) wasbroken as it only checked if the first topic name inthe list was invalid.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3046 from ijuma/consolidate-topic-classes",5
MINOR: Fix quota violation exception messageAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1508 from rajinisivaram/MINOR-quota-exception,5
kafka-1671; uploaded archives are missing for Scala version 2.11; patched by Ivan Lyutov; reviewed by Jun Rao,5
MINOR: Use functional patterns in PartitionStates (#6089)* MINOR: Use functional patterns in PartitionStates* Can't use fluent consumers yet in scala 2.11,1
MINOR: Add a newline to a Javadoc sample in KafkaConsumerThis PR simply adds a newline to a Javadoc sample in `KafkaConsumer` to flush the outputs.Author: Johnny Lim <izeye@naver.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1390 from izeye/patch-1,5
"MINOR: system test spelling/pydoc/dead code fixes (#10604)Reviewers: Kamal Chandraprakash <kamal@nmsworks.co.in>, Chia-Ping Tsai <chia7712@gmail.com>",1
"MINOR: Further reduce runtime for metrics integration tests (#8514)1. In both RocksDBMetrics and Metrics integration tests, we do not need to wait for consumer to consume records from output topics since the sensors / metrics are registered upon task creation.2. Merged the two test cases of RocksDB with one app that creates two state stores (non-segmented and segmented).With these two changes, local runtime of these two tests reduced from 2min+ and 3min+ to under a minute.Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-10074: Improve performance of `matchingAcls` (#8769)This PR reduces allocations by using a plain old `foreach` in`matchingAcls` and improves `AclSeqs.find` to only search the innercollections that are required to find a match (instead of searching allof them).A recent change (90bbeedf52) in `matchingAcls` to remove `filterKeys` infavor of filtering inside `flatMap` caused a performance regression incases where there are large number of topics, prefix ACLs andTreeMap.from/to filtering is ineffective. In such cases, we rely onstring comparisons to exclude entries from the ACL cache that are notrelevant.This issue is not present in any release yet, so we should include thesimple fix in the 2.6 branch.The original benchmark did not show a performance difference, so Iadjusted the benchmark to stress the relevant code more. Morespecifically, `aclCacheSnapshot.from(...).to(...)` returns nearly 20000entries where each map value contains 1000 AclEntries. Out of the 200kAclEntries, only 1050 are retained due to the `startsWith` filtering.This is the case where the implementation in master is leastefficient when compared to the previous version and the version in thisPR.The adjusted benchmark results for testAuthorizer are 4.532ms formaster, 2.903ms for the previous version and 2.877ms for this PR.Normalized allocation rate was 593 KB/op for master, 597 KB/op for theprevious version and 101 KB/s for this PR. Full results follow:master with adjusted benchmark:```Benchmark                                                                 (aclCount)  (resourceCount)  Mode  Cnt          Score          Error   UnitsAclAuthorizerBenchmark.testAclsIterator                                           50           200000  avgt    5        680.805 ±       44.318   ms/opAclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate                            50           200000  avgt    5        549.879 ±       36.259  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate.norm                       50           200000  avgt    5  411457042.000 ±     4805.461    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space                   50           200000  avgt    5        331.110 ±       95.821  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space.norm              50           200000  avgt    5  247799480.320 ± 72877192.319    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space               50           200000  avgt    5          0.891 ±        3.183  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space.norm          50           200000  avgt    5     667593.387 ±  2369888.357    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.count                                 50           200000  avgt    5         28.000                 countsAclAuthorizerBenchmark.testAclsIterator:·gc.time                                  50           200000  avgt    5       3458.000                     msAclAuthorizerBenchmark.testAuthorizer                                             50           200000  avgt    5          4.532 ±        0.546   ms/opAclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate                              50           200000  avgt    5        119.036 ±       14.261  MB/secAclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate.norm                         50           200000  avgt    5     593524.310 ±       22.452    B/opAclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space                     50           200000  avgt    5        117.091 ±     1008.188  MB/secAclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space.norm                50           200000  avgt    5     598574.303 ±  5153905.271    B/opAclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Survivor_Space                 50           200000  avgt    5          0.034 ±        0.291  MB/secAclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Survivor_Space.norm            50           200000  avgt    5        173.001 ±     1489.593    B/opAclAuthorizerBenchmark.testAuthorizer:·gc.count                                   50           200000  avgt    5          1.000                 countsAclAuthorizerBenchmark.testAuthorizer:·gc.time                                    50           200000  avgt    5         13.000                     ms```master with filterKeys like 90bbeedf52 and adjusted benchmark:```Benchmark                                                                 (aclCount)  (resourceCount)  Mode  Cnt          Score          Error   UnitsAclAuthorizerBenchmark.testAclsIterator                                           50           200000  avgt    5        729.163 ±       20.842   ms/opAclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate                            50           200000  avgt    5        513.005 ±       13.966  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate.norm                       50           200000  avgt    5  411459778.400 ±     3178.045    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space                   50           200000  avgt    5        307.041 ±       94.544  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space.norm              50           200000  avgt    5  246385400.686 ± 82294899.881    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space               50           200000  avgt    5          1.571 ±        2.590  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space.norm          50           200000  avgt    5    1258291.200 ±  2063669.849    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.count                                 50           200000  avgt    5         33.000                 countsAclAuthorizerBenchmark.testAclsIterator:·gc.time                                  50           200000  avgt    5       3266.000                     msAclAuthorizerBenchmark.testAuthorizer                                             50           200000  avgt    5          2.903 ±        0.175   ms/opAclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate                              50           200000  avgt    5        187.088 ±       11.301  MB/secAclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate.norm                         50           200000  avgt    5     597962.743 ±       14.237    B/opAclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space                     50           200000  avgt    5        118.602 ±     1021.202  MB/secAclAuthorizerBenchmark.testAuthorizer:·gc.churn.G1_Eden_Space.norm                50           200000  avgt    5     383359.632 ±  3300842.044    B/opAclAuthorizerBenchmark.testAuthorizer:·gc.count                                   50           200000  avgt    5          1.000                 countsAclAuthorizerBenchmark.testAuthorizer:·gc.time                                    50           200000  avgt    5         14.000                     ms```This PR with adjusted benchmark:```Benchmark                                                                 (aclCount)  (resourceCount)  Mode  Cnt          Score          Error   UnitsAclAuthorizerBenchmark.testAclsIterator                                           50           200000  avgt    5        706.774 ±       32.353   ms/opAclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate                            50           200000  avgt    5        529.879 ±       25.416  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.alloc.rate.norm                       50           200000  avgt    5  411458751.497 ±     4424.187    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space                   50           200000  avgt    5        310.559 ±      112.310  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Eden_Space.norm              50           200000  avgt    5  241364219.611 ± 97317733.967    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Old_Gen                      50           200000  avgt    5          0.690 ±        5.937  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Old_Gen.norm                 50           200000  avgt    5     531278.507 ±  4574468.166    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space               50           200000  avgt    5          2.550 ±       17.243  MB/secAclAuthorizerBenchmark.testAclsIterator:·gc.churn.G1_Survivor_Space.norm          50           200000  avgt    5    1969325.592 ± 13278191.648    B/opAclAuthorizerBenchmark.testAclsIterator:·gc.count                                 50           200000  avgt    5         32.000                 countsAclAuthorizerBenchmark.testAclsIterator:·gc.time                                  50           200000  avgt    5       3489.000                     msAclAuthorizerBenchmark.testAuthorizer                                             50           200000  avgt    5          2.877 ±        0.530   ms/opAclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate                              50           200000  avgt    5         31.963 ±        5.912  MB/secAclAuthorizerBenchmark.testAuthorizer:·gc.alloc.rate.norm                         50           200000  avgt    5     101057.225 ±        9.468    B/opAclAuthorizerBenchmark.testAuthorizer:·gc.count                                   50           200000  avgt    5            ≈ 0                 counts```Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-8700: Flaky Test QueryableStateIntegrationTest#queryOnRebalance (#7548)This is not guaranteed to actually fix queryOnRebalance, since thefailure could never be reproduced locally. I did not bump timeoutsbecause it looks like that has been done in the past for this testwithout success. Instead this change makes the following improvements:It waits for the application to be in a RUNNING state beforeproceeding with the test.It waits for the remaining instance to return to RUNNING statewithin a timeout after rebalance. I observed once that we were able todo the KV queries but the instance was still in REBALANCING, so thisshould reduce some opportunity for flakiness.The meat of this change: we now iterate over all keys in one shot(vs. one at a time with a timeout) and collect various failures, all ofwhich are reported at the end. This should help us to narrow down thecause of flakiness if it shows up again.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Fix null exception in coordinator log (#10250)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-5753; ShellTest.testRunProgramWithErrorReturn fails on macOSAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3706 from ijuma/fix-shell-test-mac,3
"MINOR: Clean up streams metric sensors (#9696)Reviewers: Bruno Cadonna <bruno@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-498: Controller has race conditions and synchronization bugs; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1382988 13f79535-47bb-0310-9956-ffa450edef68,0
trivial typo fix; patched by Moritz Schwörer; reviewed by Jun Rao,0
"KAFKA-10167: use the admin client to read end-offset (#8876)Since admin client allows use to use flexible offset-spec, we can always set to use read-uncommitted regardless of the EOS config.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1580; disallow non-admin clients to produce to internal (e.g. offsets) topics; reviewed by Joel Koshy,1
"HOTFIX: Fix compile error in TopicAdminTest (#8866)Commit 9a4f00f78bf37041006ae8b6432d194f603ac6cc changed the constructor of DescribeConfigsResponse.The build failed with the following error: ```/home/chia7712/kafka/connect/runtime/src/test/java/org/apache/kafka/connect/util/TopicAdminTest.java:582: error: incompatible types: int cannot be converted to Struct        return new DescribeConfigsResponse(1000, configs);                                           ^Note: Some messages have been simplified; recompile with -Xdiags:verbose to get full output1 error```Reviewers: Boyang Chan <boyang@confluent.io>, Tom Bentley <tbentley@redhat.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-10050: kafka_log4j_appender.py fixed for JDK11 (#8731)kafka_log4j_appender.py was broken on JDK11 by befd80b38.`fix_opts_for_new_jvm` requires `node.version` to be set, weadd the relevant code to the test.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
"KAFKA-12724: Add 2.8.0 to system tests and streams upgrade tests. (#10602)Also adjusted the acceptable recovery lag to stabilize Streams tests.Reviewers: Justine Olshan <jolshan@confluent.io>, Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",5
MINOR: Javadoc for ExtendedSerializer and ExtendedDeserializerAnd add warning about usage.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3330 from ijuma/extended-serializer-javadoc,2
trivial doc change for building customized user name,1
"KAFKA-3490; Multiple version support for ducktape performance testsAuthor: Ismael Juma <ismael@juma.me.uk>Author: Geoff Anderson <geoff@confluent.io>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1173 from ijuma/kafka-3490-multiple-version-support-perf-tests",3
KAFKA-8417: Remove redundant network definition --net=host when starting testing docker containers (#6797)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"KAFKA-6742: TopologyTestDriver error when dealing with stores from GlobalKTableguozhangwangWhile TopologyTestDriver works well with stores created from KTable it does not with stores from GlobalKTable.Moreover, for my testing purposes but I think it can be useful to others, I need to get access to the MockProducer inside TopologyTestDriver.I have added 4 new tests to TopologyTestDriverTest, two for stores from KTable and two for stores from GlobalKTable.While I was changing the TopologyTestDriver I've also make it implement java.io.Closeable.Author: Valentino Proietti <valentino.proietti@kydea.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4823 from Vale68/KAFKA-6742minor renaming",5
"MINOR: Fix doc - `FileMessageSet` was replaced by `FileRecords` (#4852)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Fix typo in LeaderEpochFileCacheTest (#9203)Reviewers: David Jacot,3
"MINOR: change Streams integration test log levels (#9024)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-8060: The Kafka protocol generator should allow null defaultsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6387 from cmccabe/KAFKA-8060,5
KAFKA-4161: KIP-89: Allow sink connectors to decouple flush and offset commitAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2139 from shikhar/kafka-4161-deux,5
"KAFKA-5670: (KIP-120) Add Topology and deprecate TopologyBuilderAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3590 from mjsax/kafka-3856-replace-topology-builder-by-topology",2
"KAFKA-13149; Fix NPE when handling malformed record data in produce requests (#11080)Raise `InvalidRecordException` from `DefaultRecordBatch.readFrom` instead of returning null if there are not enough bytes remaining to read the record. This ensures that the broker can raise a useful exception for malformed record batches.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-14104; Add CRC validation when iterating over Metadata Log Records (#12457)This commit adds a check to ensure the RecordBatch CRC is valid wheniterating over a Batch of Records using the RecordsIterator. TheRecordsIterator is used by both Snapshot reads and Log Records reads inKraft. The check can be turned off by a class parameter and is on by default.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,1
"KAFKA-7813: JmxTool throws NPE when --object-name is omittedhttps://issues.apache.org/jira/browse/KAFKA-7813Running the JMX tool without --object-name parameter, results in a NullPointerException.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: huxihx <huxi_2b@hotmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #6139 from huxihx/KAFKA-7813",5
"MINOR: Correct KStream documentation (#6552)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: close iterator on doc exampleThe iterator interface usage has some examples missing explicit close operation after usage. We should remind the user to do so because un-closed iterator will leave the underlying file descriptor open, thus eating up memory.guozhangwang IshiiharaAuthor: Boyang Chen <bychen@pinterest.com>Author: Boyang Chen <bchen11@outlook.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3714 from abbccdda/add_iterator_close_on_docminor fixes",0
"KAFKA-12787; Integrate controller snapshoting with raft client (#10786)Directly use `RaftClient.Listener`, `SnapshotWriter` and `SnapshotReader` in the quorum controller.1. Allow `RaftClient` users to create snapshots by specifying the last committed offset and last committed epoch. These values are validated against the log and leader epoch cache.2. Remove duplicate classes in the metadata module for writing and reading snapshots.3. Changed the logic for comparing snapshots. The old logic was assuming a certain batch grouping. This didn't match the implementation of the snapshot writer. The snapshot writer is free to merge batches before writing them.4. Improve `LocalLogManager` to keep track of multiple snapshots.5. Improve the documentation and API for the snapshot classes to highlight the distinction between the offset of batches in the snapshot vs the offset of batches in the log. These two offsets are independent of one another. `SnapshotWriter` and `SnapshotReader` expose a method called `lastOffsetFromLog` which represents the last inclusive offset from the log that is represented in the snapshot.Reviewers: dengziming <swzmdeng@163.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7549; Old ProduceRequest with zstd compression does not return error to client (#5925)Older versions of the Produce API should return an error if zstd is used. This validation existed, but it was done during request parsing, which means that instead of returning an error code, the broker disconnected. This patch fixes the issue by moving the validation outside of the parsing logic. It also fixes several other record validations which had the same problem.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: remove explicit passing of AdminClient into StreamsPartitionAssignor (#9384)Currently, we pass multiple object reference (AdminClient,TaskManager, and a few more) into StreamsPartitionAssignor. Furthermore, we (miss)use TaskManager#mainConsumer() to get access to the main consumer (we need to do this, to avoid a cyclic dependency).This PR unifies how object references are passed into a single ReferenceContainer class to - not ""miss use"" the TaskManager as reference container - unify how object references are passesNote: we need to use a reference container to avoid cyclic dependencies, instead of using a config for each passed reference individually.Reviewers: John Roesler <john@confluent.io>",5
"getOffset Api should return different latest offset to non-follower and follower consumers. Also, implement a batched version of the getOffset Api. patched by Joel Koshy; reviewed by Jun Rao; KAFKA-501git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1391168 13f79535-47bb-0310-9956-ffa450edef68",1
"KAFKA-6269: KTable restore fails after rebalance (#4300)* Return offset of next record of records left after restore completed* Changed check for restoring partition to remove the ""+1"" in the guard conditionMatthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",4
kafka-891; NullPointerException in ConsoleConsumer; patched by Colin B.; reviewed by Neha Narkhede and Jun Rao,5
"KAFKA-8062: Do not remore StateListener when shutting down stream thread (#6468)In a previous commit #6091, we've fixed a couple of edge cases and hence do not need to remove state listener anymore (before that we removed the state listener intentionally to avoid some race conditions, which has been gone for now).Reviewers: Matthias J. Sax <mjsax@apache.org>,   Bill Bejeck <bbejeck@gmail.com>",4
"MINOR: Factor out common response parsing logic (#9617)This patch factors out some common parsing logic from `NetworkClient.parseResponse` and `AbstractResponse.parseResponse`. As a result of this refactor, we are now verifying the correlationId in forwarded requests. This patch also adds a test case to verify handling in this case.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>",5
"Part 1 of KIP-511: Collect and Expose Client's Name and Version in the Brokers #7381Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, David Arthur <mumrah@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2
KAFKA-4147; Fix transient failure in ConsumerCoordinatorTest.testAutoCommitDynamicAssignmentAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1841 from hachikuji/KAFKA-4147,5
"KAFKA-7597: Add transaction support to ProduceBenchWorker (#5885)KAFKA-7597: Add configurable transaction support to ProduceBenchWorker.  In order to get support for serializing Optional<> types to JSON, add a new library: jackson-datatype-jdk8. Once Jackson 3 comes out, this library will not be needed.Reviewers: Colin McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-1326 Refactor Sender to support consumer.,1
"MINOR: Fix trace/debug logs in RequestChannelAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #192 from SinghAsDev/KAFKA-2461-2",2
"KAFKA-10384: Separate converters from generated messages (#9194)For the generated message code, put the JSON conversion functionalityin a separate JsonConverter class.Make MessageDataGenerator simply another generator class, alongside thenew JsonConverterGenerator class.  Move some of the utility functionsfrom MessageDataGenerator into FieldSpec and other places, so that theycan be used by other generator classes.Use argparse4j to support a better command-line for the generator.Reviewers: David Arthur <mumrah@gmail.com>",1
"KAFKA-7443: OffsetOutOfRangeException in restoring state store from changelog topic when start offset of local checkpoint is smaller than that of changelog topic (#5946)Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-263 Enhance single host broker failure test to have 2 topics with uneven distribution on the source brokers; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1241528 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-2660; Correct cleanableRatio calculationonurkaraman Could you have a look? This is the patch I discussed with you.Author: Dong Lin <lindong28@gmail.com>Author: Dong Lin <lindong@cis.upenn.edu>Reviewers: Onur Karaman <okaraman@linkedin.com>, Joel Koshy <jjkoshy@gmail.com>, Jun Rao <junrao@gmail.com>Closes #316 from lindong28/KAFKA-2660",2
KAFKA-12541; Extend ListOffset to fetch offset with max timestamp (KIP-734) (#10760)This patch implements KIP-734 as described in https://cwiki.apache.org/confluence/display/KAFKA/KIP-734%3A+Improve+AdminClient.listOffsets+to+return+timestamp+and+offset+for+the+record+with+the+largest+timestamp.Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: rename @returns to @return (#9808)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"HOT_FIX: Change flag so plain RocksDB instance returned (#6297)This PR fixes the issue found in the soak testing cluster regarding using RocksDBTimestampedStore when a regular RocksDB store should have been used.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>, John Roesler <john@confluent.io>",5
MINOR: Fix typo in WordCountProcessorDemo`bin-kafka-console-producer.sh` should be `bin/kafka-console-producer.sh`.Author: Will Marshall <wcm214@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2410 from wmarshall484/typo-fix,2
KAFKA-1142 Patch review tool should take diff with origin from last divergent point; reviewed by Neha Narkhede,5
Minor fix to add description of usage of MIT license in the LICENSE filegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1208924 13f79535-47bb-0310-9956-ffa450edef68,1
ProducerSendThread calls ListBuffer.size a whole bunch. That is a O(n) operation; patched by David Arthur; reviewed by Jun Rao; kafka-456git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1394164 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: Fix checkstyle error caused by #5781,1
KAFKA-6052; Fix WriteTxnMarkers request retry issue in InterBrokerSendThread (#4705)This resolves the issue found when running the brokers on Windows which prevents the coordinator from sending WriteTxnMarkers requests to complete a transaction.,1
"KAFKA-5765; Move merge() from StreamsBuilder to KStreamThis is the polished version.1. The old merge() method in StreamsBuilder has been removed,2. The merge() method in KStreamBuilder was changed so that it would use the single variable argumentrather than several variable arguments in the KStreamImpl implementation3. The merge() method in KStream has been declared as final and tests have been added to test correctness.Author: Richard Yu <richardyu@Richards-Air.attlocal.net>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3916 from ConcurrencyPractitioner/trunk",1
KAFKA-4227; Shutdown AdminManager when KafkaServer is shutdownTerminate topic purgatory thread in AdminManager during server shutdown to avoid threads being left around in unit tests.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1927 from rajinisivaram/KAFKA-4227,5
SyncProducer should log host and port if can't connect; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-214git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1207642 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-5290; Docs need clarification on meaning of 'committed' to the logbased on conversations with vahidhashemian rajinisivaram apurvamThe docs didn't make clear that what gets committed and what gets not may depend on the producer acks.Author: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3035 from edoardocomar/DOC-clarification-on-committed",2
MINOR: Fixed a few warning in core and connects (#6545)- var -> val- unused imports- Javadoc fixReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"Add system test coverage for group coordinator migration (#9588)This newly added system test is to verify that with the fix in #9270 , the member.id update caused by static member rejoin would be persisted correctly.Reviewers: Boyang Chen <boyang@confluent.io>",5
MINOR: Make 'Topic-Level Configs' a doc section for easier accessAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3415 from vahidhashemian/doc/make_topic_config_a_section,5
MINOR: Remove unused loggerAuthor: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3365 from Kamal15/logger,2
"KAFKA-12429: Added serdes for the default implementation of RLMM based on an internal topic as storage. (#10271)KAFKA-12429: Added serdes for the default implementation of RLMM based on an internal topic as storage. This topic will receive events of RemoteLogSegmentMetadata, RemoteLogSegmentUpdate, and RemotePartitionDeleteMetadata. These events are serialized into Kafka protocol message format.Added tests for all the event types for that topic.This is part of the tiered storaqe implementation KIP-405.Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
MINOR: Enable console logs in Connect tests (#6745)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
KAFKA-13689: printing unused and unknown logs separately (#11800)Differentiate between unused and unknown configs during log output.Reviewer: Luke Chen <showuon@gmail.com>,2
MINOR: Fix category in doap_Kafka.rdf (#11423)Reviewers: Mickael Maison <mickael.maison@gmail.com>,0
"KAFKA-8634: Update ZooKeeper to 3.5.5 (#6802)ZooKeeper 3.5.5 is the first stable release in the 3.5.x series. The key new featurein is TLS support, but there are a few more noteworthy features:* Dynamic reconfiguration* Local sessions* New node types: Container, TTL* Ability to remove watchers* Multi-threaded commit processor* Upgraded to Netty 4.1See the release notes for more detail:https://zookeeper.apache.org/doc/r3.5.5/releasenotes.htmlIn addition to the version bump, we:* Add `commons-cli` dependency as it's required by `ZooKeeperMain`, but specified as`provided` in their pom.* Remove unnecessary `ZooKeeperMainWrapper`, the bug it worked around was fixedupstream a long time ago.* Ignore non zero exit in one system test invocation of `ZooKeeperMain`.`ZooKeeperMainWrapper` always returned `0` and `ZooKeeperService.query` relieson that for correct behavior.Reviewers: Jason Gustafson <jason@confluent.io>",5
Minor checkin to fix replication system test and jmx toolgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1370941 13f79535-47bb-0310-9956-ffa450edef68,3
"KAFKA-12474: Handle failure to write new session keys gracefully (#10396)If a distributed worker fails to write (or read back) a new session key to/from the config topic, it dies. This fix softens the blow a bit by instead restarting the herder tick loop anew and forcing a read to the end of the config topic until the worker is able to successfully read to the end.At this point, if the worker was able to successfully write a new session key in its first attempt, it will have read that key back from the config topic and will not write a new key during the next tick iteration. If it was not able to write that key at all, it will try again to write a new key (if it is still the leader).Verified with new unit tests for both cases (failure to write, failure to read back after write).Author: Chris Egerton <chrise@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Upgrade to Gradle 7.5 (#12413)Highlights:* The default Scala Zinc version was updated from 1.3.5 to 1.6.1* Multiple Checkstyle tasks may now run in parallel within a project* Support for Java 18* Much more responsive continuous builds on Windows and macOS* Improved diagnostics for dependency resolutionSome of our tests require java.util and java.lang modules to be open,so do it explicitly given the following Gradle bug fix:> When running on Java 9+, Gradle no longer opens the java.base/java.util> and java.base/java.lang JDK modules for all Test tasks. In some cases,> this would cause code to pass during testing but fail at runtime.Release notes: https://docs.gradle.org/7.5/release-notes.htmlReviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>, Luke Chen <showuon@gmail.com>",2
"4385Author: RichardYuSTUG <yohan.richard.yu2@gmail.com>Author: Prasanna Gautam <prasannagautam@gmail.com>Author: Dong Lin <lindong28@gmail.com>Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4385 from ConcurrencyPractitioner/doc-kafka-4499",2
"KAKFA-9612: Add an option to kafka-configs.sh to add configs from a prop file (KIP-574)Add an option to kafka-configs.sh `--add-config-file` that adds the configs from a properties file.Testing: Added new tests to ConfigCommandTest.scalaAuthor: Aneel Nazareth <aneel@confluent.io>Reviewers: David Jacot <djacot@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8184 from WanderingStar/KAFKA-9612",5
"KAFKA-3784: TimeWindows#windowsFor calculation is incorrect- Fixed the logic calculating the windows that are affected by a new …event in the case of hopping windows and a small overlap.- Added a unit test that tests for the issueAuthor: Tom Rybak <trybak@gmail.com>Reviewers: Michael G. Noll, Matthias J. Sax, Guozhang WangCloses #1462 from trybak/bugfix/KAFKA-3784-TimeWindows#windowsFor-false-positives",0
"KAFKA-13454: Avoid duplicate config logging at startup (#11496)Kafka has duplicate configuration information log information printing during startup, repeated information printing will bring confusion to users.It is better to add log information before and after repeating the configuration information.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Remove redundant try block in LogCleaner (#5776)Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",4
MINOR: Changed javadoc on KafkaConsumer#endOffsets (#3470),1
"KAFKA-13217: Reconsider skipping the LeaveGroup on close() or add an overload that does so (#12035)This is for KIP-812:* added leaveGroup on a new close function in kafka stream* added logic to resolve future returned by remove member call in close method* added max check on remainingTime value in close functionReviewers: David Jacot <david.jacot@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-9719: Streams with EOS-beta should fail fast for older brokers (#8367)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-6432: Make index lookup more cache friendly (#5346) KAFKA-6432: Make index lookup more cache friendlyFor each topic-partition, Kafka broker maintains two indices: one for message offset, one for message timestamp. By default, a new index entry is appended to each index for every 4KB messages. The lookup of the indices is a simple binary search. The indices are mmaped files, and cached by Linux page cache.Both consumer fetch and follower fetch have to do an offset lookup, before accessing the actual message data. The simple binary search algorithm used for looking up the index is not cache friendly, and may cause page faults even on high QPS topic-partitions.In a normal Kafka broker, all the follower fetch requests, and most consumer fetch requests should only look up the last few entries of the index. We can make the index lookup more cache friendly, by searching in the last one or two pages of the index first. Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>,  Ismael Juma <github@juma.me.uk>, Sriharsha Chintalapani <sriharsha@apache.org>",1
MINOR: fix linking errors in javadoc (#8198)This improvement fixes several linking errors to classes and methods from within javadocs. Related to #8291Reviewers: Konstantine Karantasis <konstantine@confluent.io>,5
"KAFKA-5111: Code cleanup and improved log4j on StreamThread and Task - mainly moving methods - also improved loggingAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2917 from mjsax/kafka-5111-code-cleanup-follow-up",4
"KAFKA-6546: Use LISTENER_NOT_FOUND_ON_LEADER error for missing listener (#5189)For metadata request version 6 and above, use a different error code to indicate missing listener on leader broker to enable diagnosis of listener configuration issues.Reviewers: Ismael Juma <ismael@juma.me.uk>",0
KAFKA-7513: Fix timing issue in SaslAuthenticatorFailureDelayTest (#5805)Reduce tick interval of the mock timer and avoid large timer increments to avoid hitting idle expiry on the client-side before delayed close is processed by the server. Also reduce poll interval in the server to make the test complete faster (since delayed close is only processed when poll returns).Reviewers: Ismael Juma <ismael@juma.me.uk>,3
MINOR: Fix some spelling corrections in comments (#6507)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
KAFKA-1241 Better error message for underflow on read of struct.,0
"MINOR: Fix Raft broker restart issue when offset partitions are deferred #10155A Raft-based broker is unable to restart if the broker defers partitionmetadata changes for a __consumer_offsets topic-partition. The issue isthat GroupMetadataManager is asked to removeGroupsForPartition() uponthe broker becoming a follower, but in order for that code to functionit requires that the manager's scheduler be started. There are multiplepossible solutions here since removeGroupsForPartition() is a no-op atthis point in the broker startup cycle (nothing has been loaded, sothere is nothing to unload). We could just not invoke the callback. Butit seems more reasonable to not special-case this and instead startReplicaManager and the coordinators just before applying the deferredpartitions states.We also mark deferred partitions for which we are a follower as beingonline a bit earlier to avoid NotLeaderOrFollowerException that wasbeing thrown upon restart. Fixing this issue exposed the above issueregarding the scheduler not being started.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",0
KAFKA-12615: Fix `Selector.clear()` javadoc typo (#10477)The second `clearCompletedSends()` reference should be `clearCompletedReceives()`.Reviewers: Ismael Juma <ismael@juma.me.uk>Co-authored-by: Zhao Haiyuan <zhaohaiyuan@mobike.com>,2
"Revert ""KAFKA-4345; Run decktape test for each pull request""This reverts commit e035fc039598127e88f31739458f705290b1fdba for thefollowing reasons:1. License files are missing causing local builds to fail during therat task (rat is not being run in Jenkins for some reason, filedKAFKA-4459 for that)2. It renames a number of system test files when there's a betterway to achieve the goal of running a subset of system tests to stayunder the Travis limit.3. It adds the gradle wrapper binary even though this was removedintentionally a while back.A new PR will be submitted for KAFKA-4345 without the undesiredchanges.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2187 from ijuma/kafka-4345-revert",4
"KAFKA-8345: KIP-455: Admin API changes (Part 2) (#7120)Add the AlterPartitionReassignments and ListPartitionReassignments APIs.  Also remove an unused methodlength suppression for KafkaAdminClient.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",1
"KAFKA-13852: Kafka Acl documentation bug for wildcard '*' (#12090)The wildcard * in command without wrapped by single quote will be replaced into the file name under the current folder by bash. So we need to wrap with single quote. Update the doc and command option description.Reviewers: dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>",2
"KAFKA-4716: send create topics to controller in internaltopicmanagerThis PR fixes a blocker issue, where the streams client code cannot talk to the controller. It also enables a system test that was previously failing.This PR is for trunk only. A separate PR with just the fix (but not the tests) will be created for 0.10.2.Author: Eno Thereska <eno@confluent.io>Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Ismael Juma, Matthias J. Sax, Guozhang WangCloses #2522 from enothereska/KAFKA-4716-metadata",5
Log errors for unrecognized config options; patched by Jun Rao; reviewed by Jay Kreps; KAFKA-181git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377220 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-9388: Refactor integration tests to always use different application ids (#8530)When debugging KAFKA-9388, I found the reason that the second test method test takes much longer (10s) than the previous one (~500ms) is because they used the same app.id. When the previous clients are shutdown, they would not send leave-group and hence we are still depending on the session timeout (10s) for the members to be removed out of the group.When the second test is triggered, they will join the same group because of the same application id, and the prepare-rebalance phase would would for the full rebalance timeout before it kicks out the previous members.Setting different application ids could resolve such issues for integration tests --- I did a quick search and found some other integration tests have the same issue. And after this PR my local unit test runtime reduced from about 14min to 7min.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <john@confluent.io>",5
"MINOR: SuppressScenarioTest should set StreamsConfig.STATE_DIR_CONFIG (#5826)Set `StreamsConfig.STATED_DIR_CONFIG` in `SuppressScenarioTest`, aswith `StreamsTestUtils`. I have deliberately avoided using `StreamsTestUtils` asthis test sets bogus config parameters, but still fails if the default`STATE_DIR_CONFIG` does not exist.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, John Roesler <john@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: enhance streams system testguozhangwang* add table aggregate to the system test* actually create change log partition replicaAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #966 from ymatsuda/enh_systest,5
"MINOR: Reduce allocations in requests via buffer caching (#9229)Use a caching `BufferSupplier` per request handler thread so thatdecompression buffers are cached if supported by the underlying`CompressionType`. This achieves a similar outcome as #9220, butwith less contention.We introduce a `RequestLocal` class to make it easier to introducenew request scoped stateful instances (one example we discussedpreviously was an `ActionQueue` that could be used to avoidsome of the complex group coordinator locking).This is a small win for zstd (no synchronization or soft references) anda more significant win for lz4. In particular, it reduces allocationssignificantly when the number of partitions is high. The decompressionbuffer size is typically 64 KB, so a produce request with 1000 partitionsresults in 64 MB of allocations even if each produce batch is small (likely,when there are so many partitions).I did a quick producer perf local test with 5000 partitions, 1 KB recordsize,1 broker, lz4 and ~0.5 for the producer compression rate metric:Before this change:> 20000000 records sent, 346314.349535 records/sec (330.27 MB/sec),148.33 ms avg latency, 2267.00 ms max latency, 115 ms 50th, 383 ms 95th, 777 ms 99th, 1514 ms 99.9th.After this change:> 20000000 records sent, 431956.113259 records/sec (411.95 MB/sec),117.79 ms avg latency, 1219.00 ms max latency, 99 ms 50th, 295 ms 95th, 440 ms 99th, 662 ms 99.9th.That's a 25% throughput improvement and p999 latency was reduced tounder half (in this test).Default arguments will be removed in a subsequent PR.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",4
"KAFKA-2604; Remove `completeAll` and improve timeout passed to `Selector.poll` from `NetworkClient.poll`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Guozhang WangCloses #272 from ijuma/kafka-2640-remove-complete-all-poll-timeout",4
KAFKA-5134; Replace zkClient.getChildren method with zkUtils.getChildrenAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3097 from baluchicken/KAFKA-5134-2,1
MINOR: Fix typo in KafkaConsumer javadoc (#4422),2
"KAFKA-12677: Return not_controller error in envelope response itself in KRaft mode (#10794)In Kafka Raft mode, the flow sending request from client to controller is like this:1. client send request to a random controller (ex: A-controller)2. A-controller will forward the request to active controller (ex: B-controller) to handle the request3. After active B-controller completed the request, the A-controller will receive the response, and do a check:  3.1. if the response has ""disconnected"" or ""NOT_CONTROLLER"" error, which means the cached active controller is changed. So, clear the cached active controller, and wait for next retry to get the updated active controller from `controllerNodeProvider`  3.2. else, complete the request and respond back to clientIn this bug, we have 2 issues existed:1. ""NOT_CONTROLLER"" exception won't be correctly send back to the requester, instead, `UNKNOWN_SERVER_ERROR` will be returned. The reason is the `NotControllerException` is wrapped by a `CompletionException` when the `Future` completeExceptionally. And the `CompletionException` will not match any Errors we defined, so the `UNKNOWN_SERVER_ERROR` will be returned. Even if we don't want the `NotControllerException` return back to client, we need to know it to do some check.fix 1: unwrap the `CompletionException` before encoding the exception to error.2. Even if we fixed 1st bug, we still haven't fixed this issue. After the 1st bug fixed, the client can successfully get `NotControllerException` now, and keep retrying... until timeout. So, why won't it meet the flow `3.1` mentioned above, since it has `NotControllerException`? The reason is, we wrapped the original request with `EnvelopeRequest` and forwarded to active controller. So, after the active controller completed the request, responded with `NotControllerException`, and then, wrapped into an `EnvelopeResponse` **with no error**, and then send the `EnvelopeResponse` back. That is, in the flow `3.1`, we only got ""no error"" from `EnvelopeResponse`, not the `NotControllerException` inside.fix 2: Make the envelope response return `NotControllerException` if the controller response has `NotControllerException`. So that we can catch the `NotControllerException` on envelopeResponse to update the active controller.Reviewers: wenbingshen <oliver.shen999@gmail.com>, Ismael Juma <ismael@juma.me.uk>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-905 Logs can have same offsets causing recovery failure; reviewed by Jun, Neha and Jay",0
MINOR: Remove log warning for RocksDB 6+ upgrade (#10911)Reviewers: Boyang Chen <boyang@apache.org>,5
"MINOR: Fixes version lookup exception.Given a schema with 2 versions (0 and 1), if you pass in a version of `2` you will get an `OutOfBoundsException` instead of an `IllegalArgumentException`.This fixes the problem by changing the check from `>` to `>=`, which will now return true in the given scenario.Author: Micah Zoltu <micah@zoltu.net>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #748 from Zoltu/patch-1",5
MINOR: Fix race condition on shutdown of verifiable producerWe've seen `ReplicaVerificationToolTest.test_replica_lags` fail occasionally due to errors such as the following:```RemoteCommandError: ubuntuworker7: Command 'kill -15 2896' returned non-zero exit status 1. Remote error message: bash: line 0: kill: (2896) - No such process```The problem seems to be a shutdown race condition when using `max_messages` with the producer. The process may already be gone which will cause the signal to fail.Author: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #6906 from hachikuji/fix-failing-replicat-verification-test,3
MINOR: Remove duplicate jfreechart definition in dependencies.gradle (#5185)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-8315: fix the JoinWindows retention deprecation doc (#6664)Fix a javadoc mistake introduced in https://github.com/apache/kafka/pull/5911/files#diff-35e3523474fa277a63e36a3fe9e22af8.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3006: standardize KafkaConsumer API to use CollectionAuthor: Pierre-Yves Ritschard <pyr@spootnik.org>Reviewers: Jason Gustafson, Gwen ShapiraCloses #1098 from hachikuji/KAFKA-3006",1
MINOR: correct the doc of transaction.timeout.ms (#8901)Reference the correct transaction timeout error class in the config documentation.Reviewers: Boyang Chen <boyang@confluent.io>,5
"KAFKA-5873; add materialized overloads to StreamsBuilderAdd overloads for `table` and `globalTable` that use `Materialized`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3837 from dguy/kafka-5873",5
"Remove duplicate code which is invoked twice (#5039)Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",4
"KAFKA-6398: fix KTable.filter that does not include its parent's queryable storename1. Include the parent's queryable store name in KTable.filter if this operator is not materialized.2. Augment InternalTopologyBuilder checking on null processor / store names from the enum.3. Unit test.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>Closes #4384 from guozhangwang/K6398-topology-builder-exception",2
kafka-969; Need to prevent failure of rebalance when there are no brokers available when consumer comes up; patched by Sriram Subramanian; reviewed by Joel Koshy and Jun Rao,0
"MINOR: Add unit tests to the ReassignPartitionsCommandAdds a bunch of tests to unit tests to the assignment command.Moves the Rack aware test into its own class as it makes use of ZooKeeperTestHarness and slows everything else down.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1950 from benstopford/os-rebalance-extra-unit-testing",3
KAFKA-1042 follow up compilation fix; reviewed by Neha Narkhede,0
MigrationTool should disable shallow iteration in the 0.7 consumer; patched by Yang Ye; reviewed by Jun Rao; KAFKA-613git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410662 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-2372: Add Kafka-backed storage of Copycat configs.This also adds some other needed infrastructure for distributed Copycat, mostimportantly the DistributedHerder, and refactors some code for handlingKafka-backed logs into KafkaBasedLog since this is shared betweeen offset andconfig storage.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen Shapira, James ChengCloses #241 from ewencp/kafka-2372-copycat-distributed-config",5
"KAFKA-6871: KStreams Scala API: incorrect Javadocs and misleading parameter name (#4971)Reviewer: Matthias J. Sax <matthias@confluent.io>, Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Fix DistributedHerderTest after adding reason to maybeLeaveGroup (#6982)Mocking of WorkerCoordinator was not precise after adding an argument (reason) to AbstractCoordinator#maybeLeaveGroup in KAFKA-8569:Unit test case for DistributedHerderTest is now precise with respect to the expected argument and succeedsReviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Update jacoco to 0.8.7 for JDK 16 support (#10654)Details:* https://github.com/jacoco/jacoco/releases/tag/v0.8.6* https://github.com/jacoco/jacoco/releases/tag/v0.8.7Ran `./gradlew clients:reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false`successfully with Java 15 (see https://github.com/gradle/gradle/issues/15730 andhttps://github.com/scoverage/gradle-scoverage/issues/150 for the reason why `-Dorg.gradle.parallel=false` is required).Also updated `README.md` to include `-Dorg.gradle.parallel=false` alongside `reportCoverage`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"HOTFIX: Fix unit tests that failed when executed from IDE (#7707)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-2735: BrokerEndPoint should support uppercase hostnames.Added support for uppercase hostnames in BrokerEndPoint. Added unit testto cover this scenario.Author: jholoman <jeff.holoman@gmail.com>Reviewers: Grant Henke, Guozhang WangCloses #415 from jholoman/KAFKA-2735",3
MINOR: remove obsolete warning in StreamsResetter (#4749)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"KAFKA-7242: Reverse xform configs before saving (KIP-297)During actions such as a reconfiguration, the task configs are obtainedvia `Worker.connectorTaskConfigs` and then subsequently saved into aninstance of `ClusterConfigState`.  The values of the properties that are savedare post-transformation (of variable references) when they should bepre-transformation.  This is to avoid secrets appearing in plaintext inthe `connect-configs` topic, for example.The fix is to change the 2 clients of `Worker.connectorTaskConfigs` toperform a reverse transformation (values converted back into variablereferences) before saving them into an instance of `ClusterConfigState`.The 2 places where the save is performed are`DistributedHerder.reconfigureConnector` and`StandaloneHerder.updateConnectorTasks`.The way that the reverse transformation works is by using the""raw"" connector config (with variable references still intact) from`ClusterConfigState` to convert config values back into variablereferences for those keys that are common between the task configand the connector config.There are 2 additional small changes that only affect `StandaloneHerder`:1) `ClusterConfigState.allTasksConfigs` has been changed to perform atransformation (resolution) on all variable references.  This isnecessary because the result of this method is compared directly to`Worker.connectorTaskConfigs`, which also has variable referencesresolved.2) `StandaloneHerder.startConnector` has been changed to match`DistributedHerder.startConnector`.  This is to fix an issue whereduring `StandaloneHerder.restartConnector`, the post-transformedconnector config would be saved back into `ClusterConfigState`.I also performed an analysis of all other code paths where configs aresaved back into `ClusterConfigState` and did not find any otherissues.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5475 from rayokota/KAFKA-7242-reverse-xform-props",5
KAFKA-10815 EosTestDriver#verifyAllTransactionFinished should break loop if all partitions are verified (#9706)Reviewers: Matthias J. Sax <mjsax@apache.org>,4
"KAFKA-2334; Guard against non-monotonic offsets in the client (#5991)After a recent leader election, the leaders high-water mark might lag behind the offset at the beginning of the new epoch (as well as the previous leader's HW). This can lead to offsets going backwards from a client perspective, which is confusing and leads to strange behavior in some clients.This change causes Partition#fetchOffsetForTimestamp to throw an exception to indicate the offsets are not yet available from the leader. For new clients, a new OFFSET_NOT_AVAILABLE error is added. For existing clients, a LEADER_NOT_AVAILABLE is thrown.This is an implementation of [KIP-207](https://cwiki.apache.org/confluence/display/KAFKA/KIP-207%3A+Offsets+returned+by+ListOffsetsResponse+should+be+monotonically+increasing+even+during+a+partition+leader+change).Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6073; Use ZookeeperClient in KafkaApisI kept zkUtils for the call to AdminUtils.createTopic(). AdminUtils can be done in another PR.Is there a reason why we use TopicAndPartition instead of TopicPartition in KafkaControllerZkUtils ?Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #4111 from mimaison/KAFKA-6073",1
produce/fetch remote time metric not set correctly when num.acks = 1; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-584git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1402250 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Replace test usages of ClientUtils.fetchTopicMetadata with BaseRequestTest (#5216)For tests that are not testing the old consumers functionality. As part of this,consolidate `TopicMetadataTest` into `MetadataRequestTest`. Finally,remove `ProducerBounceTest` which has no tests left in it.Reviewers: Jason Gustafson <jason@confluent.io>",5
Fix Documentation for cleanup.policy is out of date (#6181),5
"MINOR: Refactor `kafka.cluster.Replica` (#12081)This patch refactors kafka.cluster.Replica, it usages and tests. This is part of the work in KAFKA-13790.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-257 Hadoop producer should use software load balancer; patched by Sam Shah; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1241249 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR Removed unused ConfigProvider from raft resources module. (#10829)Reviewers: Jun Rao <junrao@gmail.com>,5
"KAFKA-5086: Update topic expiry time in Metadata every time the topic metadata is requestedUpdate topic expiry time after every metadata update to handle max.block.ms greater than 5 minutesAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>Closes #2869 from lindong28/KAFKA-5086",5
KAFKA-5418; ZkUtils.getAllPartitions() may fail if a topic is marked for deletionSkip topics that don't have any partitions in zkUtils.getAllPartitions()Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3295 from mimaison/KAFKA-5418,1
"KAFKA-4923: Add Exactly-Once Semantics to StreamsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Apurva Metha, Ismael Juma, Damian Guy, Eno Thereska, Guozhang WangCloses #2945 from mjsax/kafka-4923-add-eos-to-streams",1
MINOR: Ensure sensor names are unique in Kafka Streams (#5009)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"KAFKA-7709: Fix ConcurrentModificationException when retrieving expired inflight batches on multiple partitions. (#6005)Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3929: Add prefix for underlying clients configs in StreamConfigAdd prefixes for consumer and producer configs to StreamsConfig, but be backward compatible.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1649 from dguy/kafka-3929",5
KAFKA-13809: Propagate full connector configuration to tasks in FileStream connectors (#12450)Reviewers: Chris Egerton <fearthecellos@gmail.com>,2
kafka-2033; Small typo in documentation; patched by Pierre-Yves Ritschard; reviewed by Jun Rao,2
KAFKA-3926: Fix transient test failure in RegexSourceIntegrationTest…Tasks call versus simply asserting createStreamTasks method called.Author: bbejeck <bbejeck@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1590 from bbejeck/KAFKA-3926-transient-failures-regex-source-integration-test,3
"KAFKA-14167; Completion exceptions should not be translated directly to error codes (#12518)There are a few cases in `ControllerApis` where we may see an `ApiException` wrapped as a `CompletionException`. This can happen in `QuorumController.allocateProducerIds` where the returned future is the result of calling `thenApply` on the future passed to the controller. The danger when this happens is that the `CompletionException` gets passed to `Errors.forException`, which translates it to an `UNKNOWN_SERVER_ERROR`. At a minimum, I found that the `AllocateProducerIds` and `UpdateFeatures` APIs were affected by this bug, but it is difficult to root out all cases. Interestingly, `DeleteTopics` is not affected by this bug as I originally suspected. This is because we have logic in `ApiError.fromThrowable` to check for both `CompletionException` and `ExecutionException` and to pull out the underlying cause. This patch duplicates this logic from `ApiError.fromThrowable` into `Errors.forException` to be sure that we handle all cases where exceptions are converted to error codes.Reviewers: David Arthur <mumrah@gmail.com>",0
"MINOR: Update zstd-jni to 1.4.8-2 (#9957)* The latest version zstd-jni doesn't use `RecyclingBufferPool` by default, so wepass it via the relevant constructors to maintain the behavior before thischange.* zstd-jni fixes an issue when using Alpine, see https://github.com/luben/zstd-jni/issues/157.* zstd 1.4.7 includes several months of improvements across many axis,from performance to various fixes. Details: https://github.com/facebook/zstd/releases/tag/v1.4.7* zstd 1.4.8 is a hotfix release, details: https://github.com/facebook/zstd/releases/tag/v1.4.8Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",0
"MINOR: Fix TestDowngrade.test_upgrade_and_downgrade (#12027)The second validation does not verify the second bounce because the verified producer and the verified consumer are stopped in `self.run_validation`. This means that the second `run_validation` just spit out the same information as the first one. Instead, we should just run the validation at the end.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Verify stopReplica if broker epoch not stale (#12040)Verify that ReplicaManager.stopReplica is called if the stop replicarequest doesn't result in a stale broker epoch error.Reviewers: Mickael Maison <mimaison@users.noreply.github.com>,1
"MINOR: Restore and global consumers should never have group.instance.id (#8322)And hence restore / global consumers should never expect FencedInstanceIdException.When such exception is thrown, it means there's another instance with the same instance.id taken over, and hence we should treat it as fatal and let this instance to close out instead of handling as task-migrated.Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Remove unused parameter in `checkIfPartitionReassignmentSucceeded` and clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1635 from ijuma/remove-unused-parameter-in-check-if-partition-reassignment-succeeded and squashes the following commits:f9ed930 [Ismael Juma] Code style improvements in `ReassignPartitionsCommand`66c7541 [Ismael Juma] Fix comment in `KafkaController.onPartitionReassignment`85288f3 [Ismael Juma] Remove unused parameter from `checkIfPartitionReassignmentSucceeded`,2
"KAFKA-5642; Use async ZookeeperClient in ControllerKafka today uses ZkClient, a wrapper client around the raw Zookeeper client. This library only exposes synchronous apis to the user. Synchronous apis mean we must wait an entire round trip before doing the next operation.This becomes problematic with partition-heavy clusters, as we find the controller spending a significant amount of time just sending many sequential reads and writes to zookeeper at the per-partition granularity. This especially becomes an issue during:- controller failover, where the newly elected controller effectively reads all zookeeper state.- broker failures and controlled shutdown. The controller tries to elect a new leader for partitions previously led by the broker. The controller also removes the broker from isr on partitions for which the broker was a follower. These all incur partition-granular reads and writes to zookeeper.As a first step in addressing these issues, we built a low-level wrapper client called ZookeeperClient in KAFKA-5501 that encourages pipelined, asynchronous apis.This patch converts the controller to use the async ZookeeperClient to improve controller failover, broker failure handling, and controlled shutdown times.Some notable changes made in this patch:- All ControllerEvents now defer access to zookeeper at processing time instead of enqueue time as was intended with the single-threaded event queue model patch from KAFKA-5028. This results in a fresh view of the zookeeper state by the time we process the event. This reverts the hacks from KAFKA-5502 and KAFKA-5879.- We refactored PartitionStateMachine and ReplicaStateMachine to process multiple partitions and replicas in batch rather than one-at-a-time so that we can send a batch of requests over to ZookeeperClient to pipeline.- We've decouple ZookeeperClient handler registration from watcher registration. Previously, these two were coupled, which meant handler registrations actually sent out a request to the zookeeper ensemble to do the actual watcher registration. In KafkaController.onControllerFailover, we register partition modification handlers (thereby registering watchers) and additionally lookup the partition assignments for every topic in the cluster. We can shave a bit of time off failover if we merge these two operations. We can do this by decoupling ZookeeperClient handler registration from watcher registration. This means ZookeeperClient's registration apis have been changed so that they are purely in-memory operations, and they only take effect when the client sends ExistsRequest, GetDataRequest, or GetChildrenRequest.- We've simplified the logic for updating LeaderAndIsr such that if we get a BADVERSION error code, the controller will now just retry in the next round by reading the new state and trying the update again. This simplifies logic when updating the partition leader epoch, removing replicas from isr, and electing leaders for partitions.- We've implemented KAFKA-5083: always leave the last surviving member of the ISR in ZK. This means that if people re-disabled unclean leader election, we can still try to elect the leader from the last in-sync replica.- ZookeeperClient's handlers have been changed so that their methods default to no-ops for convenience.- All znode paths and definitions for znode encoding and decoding have been consolidated as static methods in ZkData.scala.- The partition leader election algorithms have been refactored as pure functions so that they can be easily unit tested.- PartitionStateMachine and ReplicaStateMachine now have unit tests.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3765 from onurkaraman/KAFKA-5642",2
"MINOR: Small cleanups in integration.kafka tests (#12480)Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <christo_lolov@yahoo.com>",3
"KAFKA-5275; AdminClient API consistencyAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3339 from ijuma/kafka-5275-admin-client-api-consistency",5
MINOR: Fix doc typos and grammarThis is contributed by mihbor on various doc fixes including:https://github.com/apache/kafka/pull/3224https://github.com/apache/kafka/pull/3226https://github.com/apache/kafka/pull/3229Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3746 from guozhangwang/KMinor-doc-typos,2
"KAFKA-10212: Describing a topic with the TopicCommand fails if unauthorised to use ListPartitionReassignments APISince https://issues.apache.org/jira/browse/KAFKA-8834, describing topics with the TopicCommand requires privileges to use ListPartitionReassignments or fails to describe the topics with the following error:> Error while executing topic command : Cluster authorization failed.This is a quite hard restriction has most of the secure clusters do not authorize non admin members to access ListPartitionReassignments.This patch catches the `ClusterAuthorizationException` exception and gracefully fails back. We already do this when the API is not available so it remains consistent.Author: David Jacot <djacot@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8947 from dajac/KAFKA-10212",5
KAFKA-5895: Gradle 3.0+ is needed on the build (#3861)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
HOTFIX: remove sub-module 'kafka' (#5238)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"KAFKA-10748: Add IP connection rate throttling metric (KIP-612) (#9685)This PR adds the IP throttling metric as described in KIP-612.Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",5
"KAFKA-4507; Clients should support older brokers (KIP-97)The client should send older versions of requests to the broker if necessary.Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2264 from cmccabe/KAFKA-4507",5
"KAFKA-7793: Improve the Trogdor command line. (#6133)* Allow the Trogdor agent to be started in ""exec mode"", where it simplyruns a single task and exits after it is complete.* For AgentClient and CoordinatorClient, allow the user to pass the pathto a file containing JSON, instead of specifying the JSON object in thecommand-line text itself.  This means that we can get rid of the bashscripts whose only function was to load task specs into a bash stringand run a Trogdor command.* Print dates and times in a human-readable way, rather than as numbersof milliseconds.* When listing tasks or workers, output human-readable tables ofinformation.* Allow the user to filter on task ID name, task ID pattern, or taskstate.* Support a --json flag to provide raw JSON output if desired.Reviewed-by: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",5
"KAFKA-9105; Add back truncateHead method to ProducerStateManager (#7599)The truncateHead method was removed from ProducerStateManager by github.com/apache/kafka/commit/c49775b. This meant that snapshots were no longer removed when the log start offset increased, even though the intent of that change was to remove snapshots but preserve the in-memory mapping. This patch adds the required functionality back.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-5663; Pass non-null logDirFailureChannel to Log.applyAlso:- Improve logging- Remove dangerous default arguments in Log.apply- Improve naming of methods and fields in LogDirFailureChannel- Some clean-upsAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3594 from lindong28/KAFKA-5663",5
"MINOR: Fixed 3 inner classes without instance reference to be static* Turned 3 inner classes that weren't static but could be into `static` ones.* Turned one `public` inner class that wasn't used publicly into a `private`.Trivial but imo worthwhile to explicitly keep visibility and ""staticness"" correct in syntax (if only to be nice to the GC) :)Author: Armin Braun <me@obrown.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2574 from original-brownbear/cleanup-inner-nonstatic",4
"MINOR: simplify state transition for Kafka Streams and stream threads1. StreamThread: prevent `PARTITIONS_REVOKED` to transit to itself in `setState` by returning false. And only execute the task suspension logic when `setState(PARTITIONS_REVOKED)` returns true in `onPartitionsRevoked`.2. StreamThread: minor, renaming `shutdown` to `completeShutdown`, and `close` to `shutdown`, `stillRunning` to `isRunning`, `isInitialized` to `isRunningAndNotRebalancing`.3. GlobalStreamThread: tighten the transition a bit in `setState`. Force transiting to `PENDING_SHUTDOWN` and `DEAD` when initialization failed.4. GlobalStreamThread: minor, add logPrefix to StateConsumer. Also removing its state change listener when closing the thread.5. KafkaStreams: because of 1) above we can now prevent its `REBALANCING` to `REBALANCING`.6. KafkaStreams: prevent `CREATED` to ever go to `REBALANCING` first to force it transit to `RUNNING` when starting. Also prevent `CREATED` to go to `ERROR`.7. KafkaStreams: collapse `validateStartOnce` and `checkFirstTimeClosing ` into `setState`.8. KafkaStreams: in `close` and `start`, only execute the logic when `setState` succeeds.Author: Guozhang Wang <wangguoz@gmail.com>Author: Damian Guy <damian.guy@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #3713 from guozhangwang/KMinor-set-state",1
KAFKA-3063; LogRecoveryTest causes JVM to exit occasionallyRemove deletion of tmp file in `OffsetCheckpoint`'s constructor. This delete causes unintuitive behaviour like `LogRecoveryTest` causing a `System.exit` because the test creates an instance of `OffsetCheckpoint` in order to call `read()` on it (while unexpectedly deleting a file being written by another instance of `OffsetCheckpoint`).Also:* Improve error-handling in `OffsetCheckpoint`* Also include minor performance improvements in `read()`* Minor clean-ups to `ReplicaManager` and `LogRecoveryTest`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #759 from ijuma/kafka-3063-log-recovery-test-exits-jvm,3
KAFKA-3644; Use Boolean protocol type for StopReplicaRequest delete_p……artitionsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1296 from granthenke/stop-boolean,4
KAFKA-8033; Wait for NoOffsetForPartitionException in testFetchInvalidOffset (#9184)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-6354: Update KStream JavaDoc using new State Store API (#4456)Updates KStream JavaDoc and web page documentations using new State Store APIAuthor: Yu Liu <yu.liu003@gmail.com>Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-6394; Add a check to prevent misconfiguration of advertised listeners (#4897)Do not allow server startup if one of its configured advertised listeners has already been registered by another broker.,5
"MINOR: fix record collector to stick with streams partitioner behavior if it is specifiedIf `partition==null` and `partitioner!=null` we should not fall back to default partitioner (as we do before the patch if `producer.partitionsFor(...)` returns empty list. Falling back to default partitioner might corrupt hash partitioning.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Damian Guy, Guozhang WangCloses #2868 from mjsax/minor-fix-RecordCollector",0
KAFKA-4711: fix docs on unclean.leader.election.enable default,4
"KAFKA-9768: Fix handling of rest.advertised.listener config (#8360)The rest.advertised.listener config is currently broken as setting it to http when listeners are configured for both https and http will cause the framework to choose whichever of the two listeners is listed first. The changes here attempt to fix this by checking not only that ServerConnector::getName begins with the specified protocol, but also that that protocol is immediately followed by an underscore, which the framework uses as a delimiter between the protocol and the remainder of the connector name.An existing unit test for the RestServer::advertisedUrl method has been expanded to include a case that fails with the framework in its current state and passes with the changes in this commit. * KAFKA-9768: Fix handling of rest.advertised.listener config* KAFKA-9768: Add comments on server connector names* KAFKA-9768: Update RestServerTest commentCo-authored-by: Randall Hauch <rhauch@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Andrew Choi <andchoi@linkedin.com>",2
"KAFKA-10162; Use Token Bucket algorithm for controller mutation quota (KIP-599, Part III) (#9114)Based on the discussion in #9072, I have put together an alternative way. This one does the following:Instead of changing the implementation of the Rate to behave like a Token Bucket, it actually use two different metrics: the regular Rate and a new Token Bucket. The latter is used to enforce the quota.The Token Bucket algorithm uses the rate of the quota as the refill rate for the credits and compute the burst based on the number of samples and their length (# samples * sample length * quota).The Token Bucket algorithm used can go under zero in order to handle unlimited burst (e.g. create topic with a number of partitions higher than the burst). Throttling kicks in when the number of credits is under zero.The throttle time is computed as credits under zero / refill rate (or quota).Only the controller mutation uses it for now.The remaining number of credits in the bucket is exposed with the tokens metrics per user/clientId.Reviewers: Anna Povzner <anna@confluent.io>, Jun Rao <junrao@gmail.com>",5
"System Test : Leader Failure Log Segment Checksum Mismatched When request-num-acks is 1; patched by Jun Rao; reviewed by John Fung, Joel Koshy and Neha Narkhede; KAFKA-573git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1399934 13f79535-47bb-0310-9956-ffa450edef68",2
Minor log4j fix in the producer,0
"KAFKA-10147 MockAdminClient#describeConfigs(Collection<ConfigResource>) is unable to handle broker resource (#8853)Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Boyang Chen <boyang@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-10602: Make RetryWithToleranceOperator thread safe (#9422)ErrantRecordReporter uses a RetryWithToleranceOperator instance, which is necessarily stateful, having a ProcessingContext of which there's supposed to be one per task. That ProcessingContext is used by both RetryWithToleranceOperator.executeFailed() and execute(), so it's not enough to just synchronize executeFailed().So make all public methods of RetryWithToleranceOperator synchronized so that RetryWithToleranceOperator is now threadsafe.Tested with the addition of a multithreaded test case that fails consistently if the methods are not properly synchronized. Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",0
kafka-259; Give better error message when trying to run shell scripts without having built/downloaded the jars yet; patched by Ashwanth Fernando; reviewed by Jun Rao,1
"KAFKA-7992: Introduce start-time-ms metric (#6318)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
KAFKA-1254 remove vestigial sbt patch by Joe Stein; reviewed by Jun Rao,4
HOTFIX: Temporary suspension of 2 testsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2199 from enothereska/hotfix-streams-test-reset-ignore,3
"KAFKA-5894; add the notion of max inflight requests to async ZooKeeperClientZooKeeperClient is a zookeeper client that encourages pipelined requests to zookeeper. We want to add the notion of max inflight requests to the client for several reasons:1. to bound memory overhead associated with async requests on the client.2. to not overwhelm the zookeeper ensemble with a burst of requests.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ted Yu <yuzhihong@gmail.com>, Jun Rao <junrao@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #3860 from onurkaraman/KAFKA-5894",2
"KAFKA-7103: Use bulkloading for RocksDBSegmentedBytesStore during init (#5276)This PR uses bulk loading for recovering RocksDBWindowStore, same as RocksDBStore. Reviewers: Boyang Chen <bchen11@outlook.com>, Shawn Nguyen <shnguyen@pinterest.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-551 Remove the concept of immutable log segments--now all indexes and message sets are mutable. This allows truncating old segments. Review by Jun and Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396102 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10277: Allow null keys with non-null mappedKey in KStreamKGlobalTable join (#9186)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6446; KafkaProducer initTransactions() should timeout after max.block.ms (#4563)Currently the `initTransactions()` API blocks indefinitely if the broker cannot be reached. This patch changes the behavior to raise a `TimeoutException` after waiting for `max.block.ms`. Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-4261: Provide debug option in vagrant-up.shAuthor: fpj <fpj@apache.org>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1981 from fpj/vagrant-debug-option,0
"KAFKA-10624: For FeatureZNodeStatus, use sealed trait instead of Enumeration (#9561)This is a follow-up to initial KIP-584 development. In this PR, I've switched the FeatureZNodeStatus enum to be a sealed trait. In Scala, we prefer sealed traits over Enumeration since the former gives you exhaustiveness checking. With Scala enumeration, you don't get a warning if you add a new value that is not handled in a given pattern match.Reviewers: Jun Rao <junrao@gmail.com>",0
"MINOR: Remove unused parameters, exceptions, comments, etc. (#11472)* Remove redundant toString call & unused value in LogCleanerParameterizedIntegrationTest* Remove unthrown exceptions in FileRawSnapshotTest* Remove unused parameters in DumpLogSegmentsTest.scala* Remove redundant parameter to FetchDataInfo()* Remove redundant toString call in EndToEndLatency* Remove unused parameters in DumpLogSegments* Remove unused toString call in AbstractLogCleanerIntegrationTest* Remove unused parameter in LogCleanerTest#appendTransactionalAsLeader* Remove redundant 'val's from ClientQuotaManagerTest.UserClient.* Remove redundant parameters in EdgeCaseRequestTest* Remove redundant Int.MaxValue from DumpLogSegments.dumpTimeIndex parameters.* Remove '// 9) static client-id quota' from DefaultQuotaCallback#quotaMetricTags; static client-id quota was removed in 3.0.0.* Remove redundant parameters to DumpLogSegments#[dumpLog, dumpTimeIndex].Reviewers: Mickael Maison <mickael.maison@gmail.com>",2
"MINOR: Increase throughput for VerifiableProducer in test (#6060)Previous PR #6043 reduced throughput for VerifiableProducer in base class, but the streams_standby_replica_test needs higher throughput for consumer to complete verification in 60 secondsUpdate system test and kicked off branch builder with 25 repeats https://jenkins.confluent.io/job/system-test-kafka-branch-builder/2201/Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7072: clean up segments only after they expire (#5253)Significant refactor of Segments to use stream-time as the basis of segment expiration.Previously Segments assumed that the current record time was representative of stream time.In the event of a ""future"" event (one whose record time is greater than the stream time), thiswould inappropriately drop live segments. Now, Segments will provision the new segmentto house the future event and drop old segments only after they expire.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10839; improve consumer group coordinator unavailable message (#9729)When a consumer encounters an issue that triggers marking it to mark coordinator as unknown, the error message it prints does not give much context about the error that triggered it. This change includes the response error that triggered the transition or any other cause if not triggered by an error code in a response.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: reuse toConfigObject(Map) to generate Config (#8889)Author: Chia-Ping Tsai <chia7712@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, David Jacot <david.jacot@gmail.com>",5
KAFKA-13060: Replace EasyMock and PowerMock with Mockito in WorkerGroupMemberTest.java (#12484)This PR is created on top of #10904 and includes commits from original author for attribution. ## Testing1. `./gradlew connect:runtime:unitTest --tests WorkerGroupMemberTest` is successful.2. Verified that test is run as part of `./gradlew connect:runtime:unitTest` (see report in the PR)Reviewers: Ismael Juma <ismael@juma.me.uk>Co-authored-by: Chun-Hao Tang <tang7526@gmail.com>,3
"KAFKA-4340; Change default message.timestamp.difference.max.ms to the same as log.retention.msAuthor: Jiangjie Qin <becket.qin@gmail.com>Author: Jiangjie (Becket) Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2071 from becketqin/KAFKA-4340",5
"KAFKA-3602; Rename RecordAccumulator dequeFor() and fix usageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ashish Singh <asingh@cloudera.com>, Ismael Juma <ismael@juma.me.uk>Closes #1254 from hachikuji/KAFKA-3602",5
"KAFKA-2720: expire group metadata when all offsets have expiredAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei, Onur Karaman, Guozhang WangCloses #1427 from hachikuji/KAFKA-2720",5
MINOR: Kafka Streams Scala API cleanup (#7852)Reviewers: Bill Bejeck <bill@confluent.io>,5
KAFKA-7247: Update a link to Apache BookKeeper project (#5460) Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>,2
KAFKA-9842; Add test case for OffsetsForLeaderEpoch grouping in Fetcher (#8457)This is a follow-up to #8077. The bug exposed a testing gap in how we group partitions. This patch adds a test case which reproduces the reported problem.Reviewers: David Arthur <mumrah@gmail.com>,0
"KAFKA-5864; ReplicaFetcherThread should not die due to replica in offline log directoryAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3820 from lindong28/KAFKA-5864",2
KAFKA-13966 Prepend bootstrap metadata to controller queue (#12269)Also fixes flaky QuorumControllerTest#testInvalidBootstrapMetadataReviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-7703; position() may return a wrong offset after seekToEnd (#6407)When poll is called which resets the offsets to the beginning, followed by a seekToEnd and a position, it could happen that the ""reset to earliest"" call in poll overrides the ""reset to latest"" initiated by seekToEnd in a very delicate way: 1. both request has been issued and returned to the client side (listOffsetResponse has happened)2. in Fetcher.resetOffsetIfNeeded(TopicPartition, Long, OffsetData) the thread scheduler could prefer the heartbeat thread with the ""reset to earliest"" call, overriding the offset to the earliest and setting the SubscriptionState with that position.3. The thread scheduler continues execution of the thread (application thread) with the ""reset to latest"" call and discards it as the ""reset to earliest"" already set the position - the wrong one.4. The blocking position call returns with the earliest offset instead of the latest, despite it wasn't expected.The fix makes SubscriptionState synchronized so that we can verify that the reset is expected while holding the lock. Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-2293; Fix incorrect format specification in Partition.scala; reviewed by Joel Koshy,0
KAFKA-640 kafka.common.InvalidClientIdException in broker log4j messages; patched by Swapnil; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415765 13f79535-47bb-0310-9956-ffa450edef68,2
MINOR: fix scalaVersion variable in templateData.jsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3790 from dguy/fix-js-tempate,0
Transient failure in ProducerTest; patched by Jun Rao; reviewed by Neha Narkhede; kafka-471git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1381858 13f79535-47bb-0310-9956-ffa450edef68,3
KAFKA-1398 Dynamic config follow-on-comments.,5
"MINOR: Fix some streams web doc nits (#4411)Reviewers: Derrick Or <derrickor@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2
Leaner DelayedItem; reviewed by Neha Narkhede and Joel Koshy,2
"HOTFIX: RocksDBStore must clear dirty flags after flushguozhangwangWithout clearing the dirty flags, RocksDBStore will perform flush for every new record. This bug made the store performance painfully slower.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1163 from ymatsuda/clear_dirty_flag",5
"KAFKA-9887 fix failed task or connector count on startup failure (#8844)Moved the responsibility for recording task and connector startup and failure metrics from the invocation codeinto the status listener. The reason behind this is that the WorkerTasks (and subclasses) were either not propagating exceptions upwards, or were unable to do so easily because they were running on completely different threads.Also split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make surethe Data Abstraction Count checkStyle rule was not violated.Author: Michael Carter <michael.carter@instaclustr.com>Reviewers: Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Re-implement NewPartitionReassignment#of() (#7592)Re-implement NewPartitionReassignment#of.  It now takes a list rather than a variable-length list of arguments.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Vikas Singh <vikas@confluent.io>",5
"MINOR: Small cleanups in TopicCommand describe handling (#7136)This patch contains a few small cleanups to make topic describe logic a little clearer. It also fixes a minor inconsistency in the output between the --zookeeper and --bootstrap-server behavior when the leader is unknown. Previously we printed -1 when --zookeeper was used, and now we print ""none."" The patch consolidates the output logic for describing topics and partitions in order to avoid inconsistencies like this in the future.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-925 Add a partition key that overrides the message's stored key. Patch reviewed by Joel.,1
MINOR: Make asJsonSchema() and asConnectSchema() methods publicWant to use these methods in an external project.Author: Chris Egerton <fearthecellos@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2610 from C0urante/public-json-schema-conversion,5
"KAFKA-13823 Feature flag changes from KIP-778 (#12036)This PR includes the changes to feature flags that were outlined in KIP-778.  Specifically, itchanges UpdateFeatures and FeatureLevelRecord to remove the maximum version level. It also addsdry-run to the RPC so the controller can actually attempt the upgrade (rather than the client). Itintroduces an upgrade type enum, which supersedes the allowDowngrade boolean. BecauseFeatureLevelRecord was unused previously, we do not need to introduce a new version.The kafka-features.sh tool was overhauled in KIP-778 and now includes the describe, upgrade,downgrade, and disable sub-commands.  Refer to[KIP-778](https://cwiki.apache.org/confluence/display/KAFKA/KIP-778%3A+KRaft+Upgrades) for moredetails on the new command structure.Reviewers: Colin P. McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",1
"KAFKA-12441: remove deprecated method StreamsBuilder#addGlobalStore (#10284)The method StreamsBuilder#addGlobalStore was simplified via KIP-233 in 1.1.0 release. This PR removes the old and deprecated overload.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"HOTFIX: timeout issue in removeStreamThread() (#10321)Timeout is a duration not a point in time.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"KAFKA-14095: Improve handling of sync offset failures in MirrorMaker (#12432)We should not treat UNKNOWN_MEMBER_ID as an unexpected error in the Admin client. In MirrorMaker, check the result of committing offsets and log an useful error message in case that failed with UNKNOWN_MEMBER_ID.Reviewers: Chris Egerton <fearthecellos@gmail.com>",0
kafka-1208; Update system test still to use kafka-topics instead of kafka-create-topics shell; patched by Guozhang Wang; reviewed by Jun Rao,1
KAFKA-7606: Remove deprecated options from StreamsResetter (#10411)Remove deprecated --zookeeper and --execute flagsReviewers: Matthias J. Sax <mjsax@confluent.io>,5
"KAFKA-10255: Fix flaky testOneWayReplicationWithAutoOffsetSync test (#9029)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ning Zhang",3
"MINOR: Refactor RequestResponseTest (#11393)- Ensure we test all requests and responses- Code cleanupsReviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>",4
"MINOR: Clarify doc on consumption of topicsIn doc it stays:_""Our topic is divided into a set of totally ordered partitions, each of which is consumed by one consumer at any given time.""_And consumer is described as:_""We'll call **processes** that subscribe to topics and process the feed of published messages **consumers**.""_Which might lead to a wrong conclusion - that each partition can be read by one process at any given time.I think this statements misses information about **consumer groups**, so i propose:_""Our topic is divided into a set of totally ordered partitions, each of which is consumed by exactly one consumer (from each subscribed consumer groups) at any given time""_This contribution is my original work and I license the work to the project under the project's open source license.Author: pilo <jakub.pilimon@4finance.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1900 from pilloPl/minor/doc-fix",2
"KAFKA-3406; Update CommonClientConfigs.RETRY_BACKOFF_MS_DOC doc stringAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>Closes #1230 from omkreddy/KAFKA-3406",1
"KAFKA-4115: Increasing the heap settings for Connect scriptsSigned-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4213 from wicknicks/KAFKA-4115",5
"KAFKA-10319: Skip unknown offsets when computing sum of changelog offsets (#9066) (#9097)In PR #8962 we introduced a sentinel UNKNOWN_OFFSET to mark unknown offsets in checkpoint files. The sentinel was set to -2 which is the same value used for the sentinel LATEST_OFFSET that is used in subscriptions to signal that state stores have been used by an active task. Unfortunately, we missed to skip UNKNOWN_OFFSET when we compute the sum of the changelog offsets.If a task had only one state store and it did not restore anything before the next rebalance, the stream thread wrote -2 (i.e., UNKNOWN_OFFSET) into the subscription as sum of the changelog offsets. During assignment, the leader interpreted the -2 as if the stream run the task as active although it might have run it as standby. This misinterpretation of the sentinel value resulted in unexpected task assignments.Ports: KAFKA-10287 / #9066Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <vvcephei@apache.org>, Matthias J. Sax <mjsax@apache.org>",5
"MINOR: Restore scanning for super types of Connect plugins (#4584)Enabling scans for super types in reflections is required in order to discover Connect plugins.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13750; Client Compatability KafkaTest uses invalid idempotency configs (#11909)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
HOTFIX: disabled application-reset-tool integration testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1785 from mjsax/disableTest,3
KAFKA-13123: close KeyValueIterator instances in example code and tests (#11105)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
kafka-1758; corrupt recovery file prevents startup; patched by Manikumar Reddy; reviewed by Neha Narkhede and Jun Rao,2
MINOR: Save failed test output to build output directoryAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>Closes #6234 from ewencp/test-logs,3
"KAFKA-8069; Fix early expiration of offsets due to invalid loading of expire timestamp (#6401)After the 2.1 release, if the broker hasn't been upgrade to the latest inter-broker protocol version, the committed offsets stored in the __consumer_offset topic will get cleaned up way earlier than it should be when the offsets are loaded back from the __consumer_offset topic in GroupCoordinator, which will happen during leadership transition or after broker bounce. This patch fixes the bug by setting expireTimestamp to None if it is the default value after loading v1 offset records from __consumer_offsets.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: remove useless repeated method call in KafkaApiTest (#9988)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
"KAFKA-8418: Wait until REST resources are loaded when starting a Connect Worker. (#6840)Author: Alex Diachenko <sansanichfb@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Improve Trogdor client logging. (#4675)AgentClient and CoordinatorClient should have the option of logging failures to custom log4j objects.  There should also be builders for these objects, to make them easier to extend in the future.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-12375: don't reuse thread.id until a thread has fully shut down (#10215)Always grab a new thread.id and verify that a thread has fully shut down to DEAD before removing from the `threads` list and making that id available againReviewers: Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",5
"KAFKA-3492; Secure quotas for authenticated usersImplementation and tests for secure quotas at <user> and <user, client-id> levels as described in KIP-55. Also adds dynamic default quotas for <client-id>, <user> and <user-client-id>. For each client connection, the most specific quota matching the connection is used, with user quota taking precedence over client-id quota.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1753 from rajinisivaram/KAFKA-3492",5
MINOR: Increase `zkConnectionTimeout` and timeout in `testReachableServer`We had a number of failures recently due to these timeouts being too low. It's a particular problem if multiple forks are used while running the tests.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1889 from ijuma/increase-zk-timeout-in-tests,3
KAFKA-10449: Add some important parameter desc in connect-distributed.properties (#9235)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
KAFKA-12329; kafka-reassign-partitions command should give a better error message when a topic does not exist (#10141)This patch updates `kafka-reassign-partitions` to provide a meaningful error message to the user when a topic does not exist.Reviewers:  Chia-Ping Tsai <chia7712@gmail.com>,1
MINOR: Bump latest 2.6 version to 2.6.2 (#10582)Bump the version for system tests to 2.6.2,3
MINOR: Fix class comparison in `AlterConfigPolicy.RequestMetadata.equals()` (#11900)This patch fixes a bug in the `AlterConfigPolicy.RequestMetadata.equals` method where we were not comparing the class correctly.Co-authored-by: David Jacot <djacot@confluent.io>Reviewers: David Jacot <djacot@confluent.io>,5
"High watermark recovered incorrrectly from file; kafka-681; patched by Jun Rao; reviewed by Joel Koshy, Neha Narkhede and John Fung",2
"MINOR: fix non-deterministic streams-scala tests (#5792)Stop using current system time by default, as it introduces non-determinism.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Remove redundant volatile write in RecordHeadersThe JMH benchmark included shows that the redundantvolatile write causes the constructor of `ProducerRecord`to take more than 50% longer:ProducerRecordBenchmark.constructorBenchmark  avgt   15  24.136 ± 1.458  ns/op (before)ProducerRecordBenchmark.constructorBenchmark  avgt   15  14.904 ± 0.231  ns/op (after)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3233 from ijuma/remove-volatile-write-in-records-header-constructor,4
"MINOR: Update rocksDb memory management doc (#11528)In the RocksDb memory management doc, we mentioned in the footnote that there's a rocksdb bug caused the strict_capacity_limit boolean parameter in the LRUCache constructor can't be set to true. However, the bug is already fixed in 6.11.4, and we're using 6.22 now, so the note can be removed.Reviewer: Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-9863: replace the deprecated --zookeeper options in the documentation (#8482)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
"MINOR: Return null in key mapping of committed (#7659)To be consistent with other grouping APIs, and also modified callers accordingly.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-6825: Make StreamsConfig#DEFAULT_PRODUCTION_EXCEPTION_HANDLER_CLASS_CONFIG public (#4929)Reviewers: Matthias J Sax <matthias@confluentio>,5
"KAFKA-8981 Add rate limiting to NetworkDegradeSpec (#7446)* Add rate limiting to tc* Feedback from PR* Add a sanity test for tc* Add iperf to vagrant scripts* Dynamically determine the network interface* Add some temp code for testing on AWS* Temp: use hostname instead of external IP* Temp: more AWS debugging* More AWS WIP* More AWS temp* Lower latency some* AWS wip* Trying this again now that ping should work* Add cluster decorator to tests* Fix broken import* Fix device name* Fix decorator arg* Remove errant import* Increase timeouts* Fix tbf command, relax assertion on latency test* Fix log line* Final bit of cleanup* Newline* Revert Trogdor retry count* PR feedback* More PR feedback* Feedback from PR* Remove unused argument",1
"MINOR: Remove unnecessary call to `super` in `MetricConfig` constructor (#7975)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-3500: Handle null keys and values in KafkaOffsetBackingStore.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma, Jason Gustafson, Gwen ShapiraCloses #1662 from ewencp/kafka-3500-kafka-offset-backing-store-null",1
KAFKA-12341: Ensure consistent versions for javassist (#10191)And update to 3.27.0-GA.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"MINOR: Add unit tests for StreamsRebalanceListener (#9258)Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
javaapi ZookeeperConsumerConnectorTest duplicates many tests in the scala version; patched by Jun Rao; reviewed by Kay Kreps; KAFKA-210git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205535 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-4528: Fix failure in ProducerTest.testAsyncSendCanCorrectlyFailWithTimeoutI was able to reproduce the failure in less than 10 runs before the change. With the change,the test passed 70 times consecutively.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #2298 from ijuma/kafka-4528-fix-test-async-send-timeout",3
"MINOR: Update authorizer start-up check to handle end point with ephemeral portAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #7350 from omkreddy/checkstartup",5
"KAFKA-9668: Iterating over KafkaStreams.getAllMetadata() results in ConcurrentModificationException (#8233)`KafkaStreams.getAllMetadata()` returns `StreamsMetadataState.getAllMetadata()`. All the latter methods is `synchronized` it returns a reference to internal mutable state.  Not only does this break encapsulation, but it means any thread iterating over the returned collection when the metadata gets rebuilt will encounter a `ConcurrentModificationException`.This change: * switches from clearing and rebuild `allMetadata` when `onChange` is called to building a new list and swapping this in. This is thread safe and has the benefit that the returned list is not empty during a rebuild: you either get the old or the new list. * removes synchronisation from `getAllMetadata` and `getLocalMetadata`. These are returning member variables. Synchronisation adds nothing. * changes `getAllMetadata` to wrap its return value in an unmodifiable wrapper to avoid breaking encapsulation. * changes the getters in `StreamsMetadata` to wrap their return values in unmodifiable wrapper to avoid breaking encapsulation.Co-authored-by: Andy Coates <big-andy-coates@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-9089; Reassignment should be resilient to unexpected errors (#7562)The purpose of this patch is to make the reassignment algorithm simpler and more resilient to unexpected errors. Specifically, it has the following improvements:1. Remove `ReassignedPartitionContext`. We no longer need to track the previous reassignment through the context and we now use the assignment state as the single source of truth for the target replicas in a reassignment.2. Remove the intermediate assignment state when overriding a previous reassignment. Instead, an overriding reassignment directly updates the assignment state and shuts down any unneeded replicas. Reassignments are _always_ persisted in Zookeeper before being updated in the controller context.3. To fix race conditions with concurrent submissions, reassignment completion for a partition always checks for a zk partition reassignment to be removed. This means the controller no longer needs to track the source of the reassignment.4. Api reassignments explicitly remove reassignment state from zk prior to beginning the new reassignment. This fixes an inconsistency in precedence. Upon controller failover, zookeeper reassignments always take precedence over any active reassignment. So if we do not have the logic to remove the zk reassignment when an api reassignment is triggered, then we can revert to the older zk reassignment.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",4
"MINOR: Several fixes and improvements for FeatureControlManager (#12207)This PR fixes a bug where FeatureControlManager#replay(FeatureLevelRecord) was throwing anexception if not all controllers in the quorum supported the feature being applied. While we dowant to validate this, it needs to be validated earlier, before the record is committed to the log.Once the record has been committed to the log it should always be applied if the current controllersupports it.Fix another bug where removing a feature was not supported once it had been configured. Note thatbecause we reserve feature level 0 for ""feature not enabled"", we don't need to useOptional<VersionRange>; we can just return a range of 0-0 when the feature is not supported.Allow the metadata version to be downgraded when UpgradeType.UNSAFE_DOWNGRADE has been set.Previously we were unconditionally denying this even when this was set.Add a builder for FeatureControlManager, so that we can easily add new parameters to theconstructor in the future. This will also be useful for creating FeatureControlManagers that areinitialized to a specific MetadataVersion.Get rid of RemoveFeatureLevelRecord, since it's easier to just issue a FeatureLevelRecord withthe level set to 0.Set metadata.max.idle.interval.ms to 0 in RaftClusterSnapshotTest for more predictability.Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",3
"MINOR: Increase smoke test production time (#11190)We've seen a few failures recently due to the driver finishingthe production of data and verifying the results before thewhole cluster is even running.Reviewers: Leah Thomas <lthomas@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-4841; NetworkClient should only consider a connection to have failed after attempt to connectAlso fix a potential reordering bug and include a few clean-ups.Author: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2641 from lindong28/KAFKA-4820-followup",5
"MINOR: Remove ZK dependency for coordinator topics' partition counts (#10008)The group coordinator and the transaction state manager query ZooKeeper to retrieve the partition count for the topics they manager. Since ZooKeeperwon't be available when the broker is using a Raft-based metadata quorum,this PR changes the startup function to provide an accessor function instead.This will allow the ZK-based broker to continue using ZK, while the kip-500broker will query the metadata provided by the metadata log.Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <david.arthur@confluent.io>Co-authored-by: Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [part 2] (#4986)* KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [part 2]* Refactor:  -KTableFilterTest.java  -KTableImplTest.java  -KTableMapValuesTest.java  -KTableSourceTest.java* Add access to task, processorTopology, and globalTopology in TopologyTestDriver via TopologyTestDriverWrapper* Remove unnecessary constructor in TopologyTestDriver* Change how TopologyTestDriverWrapper#getProcessorContext sets the current nodeReviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Fix typo in docs (#7158)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-9355: Fix bug that removed RocksDB metrics after failure in EOS (#7996)* Added init() method to RocksDBMetricsRecorder* Added call to init() of RocksDBMetricsRecorder to init() of RocksDB store* Added call to init() of RocksDBMetricsRecorder to openExisting() of segmented state stores* Adapted unit tests* Added integration test that reproduces the situation in which the bug occurredReviewers: Guozhang Wang <wangguoz@gmail.com>,0
"KAFKA-6774; Improve the default group id behavior in KafkaConsumer (KIP-289) (#5877)Improve the default group id behavior by:* changing the default consumer group to null, where no offset commit or fetch, or group management operations are allowed* deprecating the use of empty (`""""`) consumer group on the clientReviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-5491; Enable transactions in ProducerPerformance ToolWith this patch, the `ProducePerfomance` tool can create transactions of differing durations.This patch was used to to collect the initial set of benchmarks for transaction performance, documented here: https://docs.google.com/spreadsheets/d/1dHY6M7qCiX-NFvsgvaE0YoVdNq26uA8608XIh_DUpI4/edit#gid=282787170Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jun Rao <junrao@gmail.com>Closes #3400 from apurvam/MINOR-add-transaction-size-to-producre-perf",1
"MINOR: Correctly mark some tests as integration tests (#12223)Also fix package name of `ListOffsetsIntegrationTest`.Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-2351; Catch all exceptions in socket server's acceptor; reviewed by Grant Henke, Joel Koshy, Jiangjie Qin, Jun Rao",5
MINOR: Update reverse lookup test to work when ipv6 not enabled (#5797)Update `ClientUtilsTest.testParseAndValidateAddressesWithReverseLookup` test to work in environments where ipv6 is not enabled and `InetAddress.getAllByName` doesn't return ipv6 addresses.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-5446: Annoying braces showed on log.error using streamsFixed log.error usage with annoying bracesAuthor: ppatierno <ppatierno@live.com>Author: Paolo Patierno <ppatierno@live.com>Reviewers: Xavier Léauté, Guozhang WangCloses #3338 from ppatierno/log-error",2
kafka-1371; Ignore build output dirs; patched by Stevo Slavic; reviewed by Jun Rao,5
"KAFKA-5597: Autogenerate producer sender metricsSubtask of https://issues.apache.org/jira/browse/KAFKA-3480The changes are very similar to what was done for the consumer in https://issues.apache.org/jira/browse/KAFKA-5191 (pull request https://github.com/apache/kafka/pull/2993)Author: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3535 from wushujames/producer_sender_metrics_docsFix one minor naming bug",0
MINOR: StreamThread performance optimizationguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #680 from ymatsuda/perf,5
MINOR: stateful docs for aggregatesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3730 from enothereska/minor-docs-aggregates,2
"KAFKA-10564: fix flaky test (#9466)Minor update to fix flaky state directory test by advancing the MockTime.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, A. Sophie Blee-Goldman <ableegoldman@apache.org>",3
"MINOR: Raft max batch size needs to propagate to log config (#10256)This patch ensures that the constant max batch size defined in `KafkaRaftClient` is propagated to the constructed log configuration in `KafkaMetadataLog`. We also ensure that the fetch max size is set consistently with appropriate testing. Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",3
"KAFKA-9756: Process more than one record of one task at a time (#8358)1. Within a single while loop, process the tasks in AAABBBCCC instead of ABCABCABC. This also helps the follow-up PR to time the per-task processing ratio to record less time, hence less overhead.2. Add thread-level process / punctuate / poll / commit ratio metrics.3. Fixed a few issues discovered (inline commented).Reviewers: John Roesler <vvcephei@apache.org>",0
[MINOR] Update upgrade documentation for 3.2 (#12055)Reviewer: Bruno Cadonna <cadonna@apache.org>,1
KAFKA-10502: Use Threadlocal.remote to avoid leak on TimestampRouter (#9304)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-9381: Fix publishing valid scaladoc for streams-scala (#9486)Reviewers: Ismael Juma <ismael@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
"KAFKA-9796; Ensure broker shutdown is not stuck when Acceptor is waiting on connection queue (#8448)This commit reworks the SocketServer to always start the acceptor threads after the processor threads and to always stop the acceptor threads before the processor threads. It ensures that the acceptor shutdown is not blocked waiting on the processors to be fully shutdown by decoupling the shutdown signal and the awaiting. It also ensure that the processor threads drain its newConnection queue to unblock acceptors that may be waiting. However, the acceptors still bind during the startup, only the processing of new connections and requests is further delayed.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Demystify rebalance schedule log (#12582)Reviewers: Bruno Cadonna <cadonna@apache.org>, Bill Bejeck <bbejeck@apache.org>",1
Add constructor for message which takes both byte array offset and length; patched by Graham Sanderson; reviewed by Jun Rao; KAFKA-393git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1378264 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-642 Missed message magic version on last checkin.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418423 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-6312; Document --reset-offsets option for consumer group tool (#4527)KIP-122 added the ability for kafka-consumer-groups.sh to reset/change consumer offsets, at a fine grained level. This patch adds documentation for this feature.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Update docs about ZooKeeper upgrade issue from 3.4.X to 3.5.6ZK upgrade from 3.4.X to 3.5.6 fails with ""java.io.IOException: No snapshot found"" if there are no snapshot files. This was discussed in https://issues.apache.org/jira/browse/ZOOKEEPER-3056Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #7625 from omkreddy/zk-upgrade",0
"MINOR: add null check for aggregate and reduce operatorsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda, Gwen ShapiraCloses #1175 from guozhangwang/KSNullPointerException",1
KAFKA-10712; Update release scripts to Python3 (#11538)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
KAFKA-928 new topics may not be processed after ZK session expiration in controller; reviewed by Jun Rao,1
"KAFKA-6145: Add balanced assignment algorithm (#8334)This algorithm assigns tasks to clients and tries to- balance the distribution of the  partitions of the  same input topic over stream threads and clients,  i.e., data parallel workload balance- balance the distribution of work over stream threads.The algorithm does not take into account potentially existing stateson the client.The assignment is considered balanced when the difference inassigned tasks between the stream thread with the most tasks andthe stream thread with the least tasks does not exceed a givenbalance factor.The algorithm prioritizes balance over stream threadshigher than balance over clients.Reviewers: John Roesler <vvcephei@apache.org>",1
"HOTFIX: disable flaky system testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3497 from mjsax/disable-flaky-system-tests",5
Corrupted request shuts down the broker; patched by Jun Rao; reviewed by Jay Kreps and Neha Narkhede; KAFKA-261git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1239740 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-3225: Method commit() of class SourceTask never invoked1. Added a test case to prove commit() on SourceTask was not being called.2. Added commitSourceTask() which logs potential exceptions.3. Added after call to finishSuccessfulFlush().Author: Jeremy Custenborder <jeremy@scarcemedia.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #909 from jcustenborder/KAFKA-3225,5
"MINOR: Use KafkaConsumer in GetOffsetShell (#5220)This does the minimal amount of work so that the toolrelies on public non-deprecated APIs (i.e. it no longerrelies on Scala clients code).Additional improvements (not included here) havebeen proposed via KIP-308.There are a few other PRs that touch this class withoverlapping goals:- https://github.com/apache/kafka/pull/2891- https://github.com/apache/kafka/pull/3051- https://github.com/apache/kafka/pull/3320One of them remains relevant in the context of KIP-308, butthe others have been superseded. I included the authors ofthe 3 PRs as co-authors.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Co-authored-by: Arseniy Tashoyan <tashoyan@gmail.com>Co-authored-by: Vahid Hashemian <vahidhashemian@us.ibm.com>Co-authored-by: Mohammed Amine GARMESCo-authored-by: Ismael Juma <ismael@juma.me.uk>",5
KAFKA-3650: Fix vagrant download URLAuthor: Roger Hoover <roger.hoover@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1308 from theduderog/fix_vagrant_dl,0
"KAFKA-4183; Corrected Kafka Connect's JSON Converter to properly convert from null to logical valuesThe `JsonConverter` class has `LogicalTypeConverter` implementations for Date, Time, Timestamp, and Decimal, but these implementations fail when the input literal value (deserialized from the message) is null.Test cases were added to check for these cases, and these failed before the `LogicalTypeConverter` implementations were fixed to consider whether the schema has a default value or is optional, similarly to how the `JsonToConnectTypeConverter` implementations do this. Once the fixes were made, the new tests pass.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #1867 from rhauch/kafka-4183",5
"KAFKA-13525: Implement KeyQuery in Streams IQv2 (#11582)Implement the KeyQuery as proposed in KIP-796Reviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <guozhang@apache.org>",5
"KAFKA-7567; Clean up internal metadata usage for consistency and extensibility (#5813)This patch makes two improvements to internal metadata handling logic and testing:1. It reduce dependence on the public object `Cluster` for internal metadata propagation since it is not easy to evolve. As an example, we need to propagate leader epochs from the metadata response to `Metadata`, but it is not straightforward to do this without exposing it in `PartitionInfo` since that is what `Cluster` uses internally. By doing this change, we are able to remove some redundant `Cluster` building logic. 2. We want to make the metadata handling in `MockClient` simpler and more consistent. Currently we have mix of metadata update mechanisms which are internally inconsistent with each other and do not match the implementation in `NetworkClient`.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
kafka-1232; make TopicCommand more consistent; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,1
"KAFKA-12455: Fix OffsetValidationTest.test_broker_rolling_bounce failure with Raft (#10322)This test was failing when used with a Raft-based metadata quorum but succeeding with aZooKeeper-based quorum. This patch increases the consumers' session timeouts to 30 seconds,which fixes the Raft case and also eliminates flakiness that has historically existed in theZookeeper case.This patch also fixes a minor logging bug in RaftReplicaManager.endMetadataChangeDeferral() thatwas discovered during the debugging of this issue, and it adds an extra logging statement in RaftReplicaManager.handleMetadataRecords() when a single metadata batch is applied to mirrorthe same logging statement that occurs when deferred metadata changes are applied.In the Raft system test case the consumer was sometimes receiving a METADATA response with just1 alive broker, and then when that broker rolled the consumer wouldn't know about any alive nodes.It would have to wait until the broker returned before it could reconnect, and by that time the groupcoordinator on the second broker would have timed-out the client and initiated a group rebalance. Thetest explicitly checks that no rebalances occur, so the test would fail. It turns out that the reason whythe ZooKeeper configuration wasn't seeing rebalances was just plain luck. The brokers' metadatacaches in the ZooKeeper configuration show 1 alive broker even more frequently than the Raftconfiguration does. If we tweak the metadata.max.age.ms value on the consumers we can easilyget the ZooKeeper test to fail, and in fact this system test has historically been flaky for theZooKeeper configuration. We can get the test to pass by setting session.timeout.ms=30000 (whichis longer than the roll time of any broker), or we can increase the broker count so that the clientnever sees a METADATA response with just a single alive broker and therefore never loses contactwith the cluster for an extended period of time. We have plenty of system tests with 3+ brokers, sowe choose to keep this test with 2 brokers and increase the session timeout.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: small code optimizations in streamsguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1176 from ymatsuda/optimize,5
kafka-1157; Clean up Per-topic Configuration from Kafka properties; patched by Guozhang Wang; reviewed by Jun Rao,5
"KAFKA-7428: ConnectionStressSpec: add ""action"", allow multiple clients (#5668)",1
MINOR: Upgrade Gradle to 3.2.1 and Scala to 2.12.1There were a couple of important issues fixed in Gradle 3.2.1:* [GRADLE-3582] - Gradle wrapper fails to escape arguments with nested quotes* [GRADLE-3583] - Newlines in JAVA_OPTS breaks application plugin shell script in Gradle 3.2And a lot of important issues fixed in Scala 2.12.1:* http://www.scala-lang.org/news/2.12.1Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>Closes #2216 from ijuma/gradle-3.2.1-and-scala-2.12.1,1
"KAFKA-4042: Contain connector & task start/stop failures within the WorkerInvoke the statusListener.onFailure() callback on start failures so that the statusBackingStore is updated. This involved a fix to the putSafe() functionality which prevented any update that was not preceded by a (non-safe) put() from completing, so here when a connector or task is transitioning directly to FAILED.Worker start methods can still throw if the same connector name or task ID is already registered with the worker, as this condition should not happen.Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1778 from shikhar/distherder-stayup-take4",5
MINOR: Move `RequestChannel.Response` creation logic into `RequestChannel` (#9912)This patch moves some common response creation logic from `RequestHandlerHelper` and into `RequestChannel`. This refactor has the following benefits:- It allows us to get rid of some logic that was previously duplicated in both `RequestHandlerHelper` and `TestRaftRequestHandler`. - It ensures that we do not need to rely on the caller to ensure that `updateErrorMetrics` gets called since this is handled internally in `RequestChannel`.- It provides better encapsulation of the quota workflow which relies on custom `Response` objects. Previously it was quite confusing for `KafkaApis` to handle this directly through the `sendResponse` API.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"MINOR: Add unit tests to verify setting of serdes in timestamped key-value store (#6825)Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",1
"HOTFIX: Replace JDK download and fix missing argument in Vagrant provisioning scriptAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3121 from ewencp/hotfix-vagrant-provisioning",0
KAFKA-4244; Fix formatting issues in documentationAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1966 from gwenshap/KAFKA-4244,5
"KAFKA-6967: TopologyTestDriver does not allow pre-populating state stores that have change logging (#5096)Reviewers: Guozhang Wang <guozhang@confluent.io>, James Cheng <jylcheng@yahoo.com>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
partition state machine log4j change,4
KAFKA-124 Console consumer does not stop consuming if the program reading from standard out dies. Check for errors on the output stream and exit if no one is listening.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1163911 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Fix state transition diagram for stream threads (#9153)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9184: Redundant task creation and periodic rebalances after zombie Connect worker rejoins the group (#7771)Check connectivity with broker coordinator in intervals and stop tasks if coordinator is unreachable by setting `assignmentSnapshot` to null and resetting rebalance delay when there are no lost tasks. And, because we're now sometimes setting `assignmentSnapshot` to null and reading it from other methods and thread, made this member volatile and used local references to ensure consistent reads.Adapted existing unit tests to verify additional debug calls, added more specific log messages to `DistributedHerder`, and added a new integration test that verifies the behavior when the brokers are stopped and restarted only after the workers lose their heartbeats with the broker coordinator.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
KAFKA-5277; Sticky Assignor should not cache previous assignment (KIP-54 follow-up)... plus some minor cleanupAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3092 from vahidhashemian/KAFKA-5277,5
MINOR: Port fix to other StoreQueryIntegrationTests (#11153)Port the fix from #11129 to the other store-query tests.Reviewers: John Roesler <vvcephei@apache.org>,3
KAFKA-1544 Log cleaner takes a long time to shut down. Patch from Manikumar Reddy.,4
"KAFKA-6175; AbstractIndex should cache index file to avoid unnecessary disk access during resize()This patch also adds the a test for test the log deletion after close.Author: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4179 from lindong28/KAFKA-6175",4
KAFKA-6476: Documentation for dynamic broker configuration (#4558)Docs for dynamic broker configuration (KIP-226),5
MINOR: simplify implementation of ConsumerGroupOperationContext.hasCo… (#9449)Reviewers: David Jacot <djacot@confluent.io>,5
MINOR: add missing space to errro message when setting uint16 (#10274)Reviewers: David Arthur <mumrah@gmail.com>,1
"KAFKA-5322; Add `OPERATION_NOT_ATTEMPTED` error code to resolve AddPartitionsToTxn inconsistencyIn the `AddPartitionsToTxn` request handling, if even one partition fails authorization checks, the entire request is essentially failed. However, the `AddPartitionsToTxnResponse` today will only contain the error codes for the topics which failed authorization. It will have no error code for the topics which succeeded, making it inconsistent with other APIs.This patch adds a new error code `OPERATION_NOT_ATTEMPTED` which is returned for the successful partitions to indicate that they were not added to the transaction.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3204 from apurvam/KAFKA-5322-add-operation-not-attempted-for-add-partitions",1
"KAFKA-8355: add static membership to range assignor (#7014)The purpose of this PR is to add static membership support for range assignor. More details for the motivation in here.Similar to round robin assignor, if we are capable of persisting member identity across generations, we will reach a much more stable assignment.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-10040; Make computing the PreferredReplicaImbalanceCount metric more efficient (#8724)This PR changes the way `PreferredReplicaImbalanceCount` is computed. It moves from re-computing after the processing of each event in the controller, which requires a full pass over all partitions, to incrementally maintaining the count as assignments and leaders are changing.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-374 Move off the default java crc implementation to the crc code borrowed from Hadoop. Patch reviewed by Joe.,4
"KAFKA-2857; MINOR: Follow up toMINOR: Fix ResetIntegrationTest test failuresKAFKA-2857 follow-up.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2636 from vahidhashemian/minor/kafka-2857-followup",5
"KAFKA-8398: Prevent NPE in `forceUnmap` (#8983)Without this change, we would catch the NPE and log it.This was misleading and could cause excessive logvolume.The NPE can happen after `AlterReplicaLogDirs` completessuccessfully and when unmapping older regions. Examplestacktrace:```text[2019-05-20 14:08:13,999] ERROR Error unmapping index /tmp/kafka-logs/test-0.567a0d8ff88b45ab95794020d0b2e66f-delete/00000000000000000000.index (kafka.log.OffsetIndex)java.lang.NullPointerExceptionat org.apache.kafka.common.utils.MappedByteBuffers.unmap(MappedByteBuffers.java:73)at kafka.log.AbstractIndex.forceUnmap(AbstractIndex.scala:318)at kafka.log.AbstractIndex.safeForceUnmap(AbstractIndex.scala:308)at kafka.log.AbstractIndex.$anonfun$closeHandler$1(AbstractIndex.scala:257)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)at kafka.log.AbstractIndex.closeHandler(AbstractIndex.scala:257)at kafka.log.AbstractIndex.deleteIfExists(AbstractIndex.scala:226)at kafka.log.LogSegment.$anonfun$deleteIfExists$6(LogSegment.scala:597)at kafka.log.LogSegment.delete$1(LogSegment.scala:585)at kafka.log.LogSegment.$anonfun$deleteIfExists$5(LogSegment.scala:597)at kafka.utils.CoreUtils$.$anonfun$tryAll$1(CoreUtils.scala:115)at kafka.utils.CoreUtils$.$anonfun$tryAll$1$adapted(CoreUtils.scala:114)at scala.collection.immutable.List.foreach(List.scala:392)at kafka.utils.CoreUtils$.tryAll(CoreUtils.scala:114)at kafka.log.LogSegment.deleteIfExists(LogSegment.scala:599)at kafka.log.Log.$anonfun$delete$3(Log.scala:1762)at kafka.log.Log.$anonfun$delete$3$adapted(Log.scala:1762)at scala.collection.Iterator.foreach(Iterator.scala:941)at scala.collection.Iterator.foreach$(Iterator.scala:941)at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)at scala.collection.IterableLike.foreach(IterableLike.scala:74)at scala.collection.IterableLike.foreach$(IterableLike.scala:73)at scala.collection.AbstractIterable.foreach(Iterable.scala:56)at kafka.log.Log.$anonfun$delete$2(Log.scala:1762)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at kafka.log.Log.maybeHandleIOException(Log.scala:2013)at kafka.log.Log.delete(Log.scala:1759)at kafka.log.LogManager.deleteLogs(LogManager.scala:761)at kafka.log.LogManager.$anonfun$deleteLogs$6(LogManager.scala:775)at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)```Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Co-authored-by: Jaikiran Pai <jaikiran.pai@gmail.com>",1
KAFKA-10300 fix flaky core/group_mode_transactions_test.py (#9059)the root cause is same to #9026 so I copy the approach of #9026 to resolve core/group_mode_transactions_test.pyReviewers: Jun Rao <junrao@gmail.com>,3
"KAFKA-4925: delay initial rebalance of consumer groupAdd new broker config, `group.initial.rebalance.delay.ms`, with a default of 3 seconds.When a consumer creates a new group, set the group's state to InitialRebalance and delay the rebalance until `min(group.initial.rebalance.delay.ms, rebalanceTimeout)`. As other members join the group further delay the rebalance by `min(group.initial.rebalance.delay.ms, remainingRebalanceTimeout)`. Once `rebalanceTimeout` is hit or no new members join the group within the delay, complete the rebalance.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #2758 from dguy/kafka-4925",1
MINOR: Fix connect development guide.Fix some trivial misses.ewencpAuthor: uchan-nos <uchan0@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1496 from uchan-nos/docfix-connect,2
KAFKA-10138: Prefer --bootstrap-server for reassign_partitions command in ducktape tests (#8898)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
"MINOR: Updating files with release 2.6.1 (#9844)Reviewers: Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2
MINOR: revise assertions in AbstractConfigTest (#9180)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
revert streams/src/main/java/org/apache/kafka/streams/processor/ConsumerRecordTimestampExtractor.java,4
"KAFKA-14204: QuorumController must correctly handle overly large batches (#12595)Originally, the QuorumController did not try to limit the number of records in a batch that it sentto the Raft layer.  This caused two problems. Firstly, we were not correctly handling the exceptionthat was thrown by the Raft layer when a batch of records was too large to apply atomically. Thishappened because the Raft layer threw an exception which was a subclass of ApiException. Secondly,by letting the Raft layer split non-atomic batches, we were not able to create snapshots at each ofthe splits. This led to O(N) behavior during controller failovers.This PR fixes both of these issues by limiting the number of records in a batch. Atomic batchesthat are too large will fail with a RuntimeException which will cause the active controller tobecome inactive and revert to the last committed state. Non-atomic batches will be split intomultiple batches with a fixed number of records in each.Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",0
KAFKA-720 Migration tool halts silently; reviewed by Neha Narkhede,5
"MINOR: Log append validation improvements- Consistent validation across different code paths in LogValidator- Validate baseOffset for message format V2- Flesh out LogValidatorTest to check producerId, baseSequence, producerEpoch and partitionLeaderEpoch.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #2802 from ijuma/validate-base-offset",5
KAFKA-2707: make KStream processor names deterministicguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #408 from ymatsuda/kstream_processor_name,5
"MINOR: Clean up AlterIsrManager code (#11832)Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-8784: remove default close for RocksDBConfigSetter (#10416)Remove the default close implementation for RocksDBConfigSetter to avoid accidental memory leaks via C++ backed objects which are constructed but not closed by the userReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
"KAFKA-7326: KStream.print() should flush on each line for PrintStream (#5579)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",5
"KAFKA-3765; Kafka Code style correctionsRemoved explicit returns, not needed parentheses, corrected variables, removed unused importsUsing isEmpty/nonEmpty  instead of size check, using head, flatmap instead of map-flattenAuthor: Joshi <rekhajoshm@gmail.com>Author: Rekha Joshi <rekhajoshm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1442 from rekhajoshm/KAFKA-3765",1
"HOTFIX: RequestContext constructor change (#9559)Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-3227; Conservative update of Kafka dependenciesPatch version bumps for bouncy castle, minikdc, snappy, slf4j, scalatest and powermock. Notable fixes:* Snappy: fixes a resource leak* Bouncy castle: security fixesAlso update Gradle to 2.11 (where the notable change is improved IDE integration) and the grgit build dependency.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #903 from ijuma/kafka-3227-conservative-update-of-kafka-deps",5
MINOR: Fix expected output in Streams quickstartInclude the topic config `segment.bytes`.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #6945 from vahidhashemian/minor/update_streams_quickstart_doc,5
"MINOR: Remove redundant inheritance from FilteringJmxReporter #onMetricRemoved (#10303)Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: Align KTableAgg and KTableReduce (#6712)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Jeff Kim <kimkb2011@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR KAFKA-7406: Follow up and address final comments (#5730)Reviewers: John Roesler <john@confluent.io>, Matthias J Sax <matthias@confluent.io>",5
"KAFKA-4271: Fix the server start script for Windows 32-bit OSWithout this fix the new consumer fails to run on a 32-bit Windows OS.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson, Guozhang WangCloses #2189 from vahidhashemian/KAFKA-4271",1
"KAFKA-2587; Increasing timeout for the test verification.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>Closes #260 from Parth-Brahmbhatt/KAFKA-2587",1
"KAFKA-2598; Adding integration test for the authorizer at API level. ……Some bug fixes that I encountered while running the tests.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #300 from Parth-Brahmbhatt/KAFKA-2598",5
MINOR: remove TransactionCoordinatorIntegrationTest`TransactionCoordinatorIntegrationTest` is not covering anything that isn't already covered by the more complete `TransactionsTest`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3128 from dguy/minor-remove-test,3
KAFKA-3075; Fix ClassCastException in `ZookeeperConsumerConnector.commitOffsets`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #833 from ijuma/kafka-3075-javaapi-consumer-class-cast-exception,1
kafka-843; Re-add the release-zip sbt target; patched by Cosmin Lehene; reviewed by Jun Rao,1
MINOR: Update release versions for upgrade tests with 3.1.1 release (#12156)Updates release versions in files that are used for upgrade test with the 3.1.1 release version.Reviewers: Bruno Cadonna <bruno@confluent.io>,5
Consumer rebalance fails if no leader available for a partition and stops all fetchers; patched by Maxime Brugidou; reviewed by Jun Rao; kafka-693,0
KAFKA-6883: Add toUpperCase support to sasl.kerberos.principal.to.local rule (KIP-309)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #7375 from omkreddy/KAFKA-6883-KerberosShortNamer,5
"KAFKA-3625: add docs for Kafka Streams test-utils (follow up) (#4493)Adds web page docs for KIP-247Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, Joel Hamill <joel@confluent.io>, Damian Guy <damian@confluent.io>",5
KAFKA-1641; Reset first dirty offset for compaction to earliest offsetif the checkpointed offset is invalid; reviewed by Joel Koshy,1
"MINOR: Add 'task container' class to KafkaStreams TaskManager (#9835)Kafka Streams' TaskManager is a central class that grew quite big. ThisPR breaks out a new 'task container' class to descope what TaskManagerdoes. In follow up PRs, we plan to move more methods from TaskManagerto the new 'Tasks.java' class and also improve task-type type safety.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-2648: enforce non-empty group-ids in join-group requestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #362 from hachikuji/KAFKA-2648,5
KAFKA-164 Fix up configuration with more docs.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1188024 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: refactor topic check to make sure all topics exist by name vs doing a topic count (#6271)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Remove references to version 1.2 in docs (#5386),2
KAFKA-10658 ErrantRecordReporter.report always return completed futur… (#9525)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,5
"KAFKA-5127; Replace pattern matching with foreach where the case None is ignoredAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2919 from baluchicken/KAFKA-5127",5
"KAFKA-4514; Add Codec for ZStandard Compression (#2267)This patch adds support for zstandard compression to Kafka as documented in KIP-110: https://cwiki.apache.org/confluence/display/KAFKA/KIP-110%3A+Add+Codec+for+ZStandard+Compression. Reviewers: Ivan Babrou <ibobrik@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2928; system test: fix version sanity checksFixed version sanity checks by updated kafkatest version to match kafka versionAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #656 from granders/KAFKA-2928-fix-version-sanity-checks,0
"KAFKA-8410: Part 1: processor context bounds (#8414)Add type bounds to the ProcessorContext, which bounds the types that can be forwarded to child nodes.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
KAFKA-6755: Allow literal value for MaskField SMT (#6284)Implemented KIP-437 by adding a new optional configuration property for the `MaskField` transformation that allows users to define a replacement literal for specific fields in matching records.Author: Valeria Vasylieva <valeria.vasylieva@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,1
"KAFKA-12631; Implement `resign` API in `KafkaRaftClient` (#10913)This patch adds an implementation of the `resign()` API which allows the controller to proactively resign leadership in case it encounters an unrecoverable situation. There was not a lot to do here because we already supported a `Resigned` state to facilitate graceful shutdown.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, David Arthur <mumrah@gmail.com>",1
"KAFKA-6946; Keep the session id for incremental fetch when fetch responses are throttledCurrently, a throttled fetch response is returned with INVALID_SESSION_ID, which causes dropping the current fetch session if incremental fetch is in progress. This patch fixes this by returning the correct session id.Author: Jon Lee <jonlee@linkedin.com>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Dong Lin <lindong28@gmail.com>Closes #5164 from jonlee2/KAFKA-6946",2
KAFKA-3066: Demo Examples for Kafka StreamsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #797 from guozhangwang/K3066,5
"MINOR: Remove FanoutIntegrationTest.javaThis test has been completely subsumed by the coverage of reset integration test, and hence can be removed.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #4184 from guozhangwang/KMinor-remove-fanout-integration",4
KAFKA-2761: enable whitelist regex subscription for new consumer in ConsoleConsumer#412 is a pre-req.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang WangCloses #445 from SinghAsDev/KAFKA-2761,1
"MINOR: Update docs for new version1. Update the Streams hello world examples with the new API.2. Update the version references in various places.3. Update version templates to 1.1.x.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>, Derrick Or <derrickor@gmail.com>Closes #4169 from guozhangwang/KMINOR-streams-docs",2
"MINOR: Remove unwanted regexReplace on tests/kafkatest/__init__.pyAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>Closes #8072 from omkreddy/release-script",5
"KAFKA-8351; Cleaner should handle transactions spanning multiple segments (#6722)When cleaning transactional data, we need to keep track of which transactions still have data associated with them so that we do not remove the markers. We had logic to do this, but the state was not being carried over when beginning cleaning for a new set of segments. This could cause the cleaner to incorrectly believe a transaction marker was no longer needed. The fix here carries the transactional state between groups of segments to be cleaned.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Fix error in design docsAuthor: dasl <dasl-@users.noreply.github.com>Reviewers: Gwen ShapiraCloses #2357 from dasl-/trunk,1
"KAFKA-9507; AdminClient should check for missing committed offsets (#8057)Addresses exception being thrown by `AdminClient` when `listConsumerGroupOffsets` returns a negative offset. A negative offset indicates the absence of a committed offset for a requested partition, and should result in a null in the returned offset map.Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: Handle task migrated inside corruption path (#8667)Reviewers: John Roesler <vvcephei@apache.org>,0
KAFKA-785 Resolve bugs in PreferredReplicaLeaderElection admin tool; reviewed by Swapnil Ghike and Neha Narkhede,0
KAFKA-7098; Improve accuracy of throttling by avoiding under-estimating actual rate in ThrottlerAuthor: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5350 from hzxa21/KAFKA-7098,1
kafka-1926; Replace kafka.utils.Utils with o.a.k.common.utils.Utils; patched by Tong Li; reviewed by Jun Rao,5
"MINOR: Only log overridden topic configs during topic creation (#10828)It's quite verbose to include all configs for every partition loaded/created.Also make sure to redact sensitive and unknown config values.Unit test included.Reviewers: David Jacot <djacot@confluent.io>, Kowshik Prakasam <kprakasam@confluent.io>, Luke Chen <showuon@gmail.com>",5
"MINOR: Check null keys in KTableSourceAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Matthias J. SaxCloses #1521 from guozhangwang/Kminor-check-nullkey-ktable-source",2
"MINOR: code cleanup (#6053)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Support long maxMessages in Trogdor consume/produce bench workers (#5957)Reivewers: Colin McCabe <cmccabe@apache.org>,1
KAFKA 222 Mavenize contrib;patched by nehanarkhede; reviewed jakobhoman and junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1211616 13f79535-47bb-0310-9956-ffa450edef68,1
commit offset before consumer shutdown KAFKA-84; rename util.StringSerializer to ZKStringSerializer to avoid confusion with producer.StringSerializergit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1154719 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Update Connect error message to point to the correct config validation REST endpoint (#7991)When incorrect connector configuration is detected, the returned exception message suggests to check the connector's configuration against the `{connectorType}/config/validate` endpoint. Changing the error message to refer to the exact REST endpoint which is `/connector-plugins/{connectorType}/config/validate` This aligns the exception message with the documentation at: https://kafka.apache.org/documentation/#connect_rest Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
"MINOR: Upgrade jetty to 9.4.30.v20200611 (#8893)Recently, commit 492306a updated both jetty to version 9.4.27.v20200227 and jersey to version 2.31However in the latest versions of jetty, the renaming of the method `Response#closeOutput` to `Response#completeOutput` has been reverted, with the latest version using again `Response#closeOutput`. Jersey has not released a recent version in which `Response#closeOutput` is called directly. In its currently latest version (2.31) `Response#closeOutput` will be called if `Response#completeOutput` throws a `NoSuchMethodError` exception. Given that, this version combination is compatible. Jersey should be upgraded once a new version that uses `Response#closeOutput` directly is out.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: Remove unnecessary OptionParser#accepts method call from PreferredReplicaLeaderElectionCommand (#6710)Reviewers: Jason Gustafson <jason@confluent.io>,5
HOTFIX: Avoid ambiguity error of Properties#putAll in Java 11 and scala 2.12 (#8599)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
"KAFKA-9747: Creating connect reconfiguration URL safely (#11174)* URL wasn't urlencoded when forwarded reconfiguration to leader connect worker* handling previously swallowed errors in connect RestClientReviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Co-authored-by: Andras Katona  <akatona@cloudera.com>Co-authored-by: Daniel Urban <durban@cloudera.com>",0
KAFKA 218 Upgrade to zookeeper 3.3.4; patched by pyritschard; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1229784 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: remove unused scala files from core module (#9296)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Lee Dongjin <dongjin@apache.org>",2
kafka-1433; transient unit test failure in ZookeeperConsumerConnectorTest; patched by Jun Rao; reviewed by Guozhang Wang,3
"KAFKA-9393: DeleteRecords may cause extreme lock contention for large partition directories (#7929)This PR avoids a performance issue with DeleteRecords when a partition directory contains high numbers of files. Previously, DeleteRecords would iterate the partition directory searching for producer state snapshot files. With this change, the iteration is removed in favor of keeping a 1:1 mapping between producer state snapshot file and segment file. A segment files corresponding producer state snapshot file is now deleted when the segment file is deleted.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
"MINOR: WorkerUtils#topicDescriptions must unwrap exceptions properly (#6937)Reviewers: Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",1
"KAFKA-4704; Coordinator cache loading fails if groupId is reused for offset storage after group is removedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2455 from hachikuji/KAFKA-4704",5
"KAFKA-13418: Support key updates with TLS 1.3 (#11966)Key updates with TLS 1.3 trigger code paths similar to renegotiation with TLS 1.2.Update the read/write paths not to throw an exception in this case (kept the exceptionin the `handshake` method).With the default configuration, key updates happen after 2^37 bytes are encrypted.There is a security property to adjust this configuration, but the change has to bedone before it is used for the first time and it cannot be changed after that. As such,it is best done via a system test (filed KAFKA-13779).To validate the change, I wrote a unit test that forces key updates and manually rana producer workload that produced more than 2^37 bytes. Both cases failed withoutthese changes and pass with them.Note that Shylaja Kokoori attached a patch with the SslTransportLayer fix and henceincluded them as a co-author of this change.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Co-authored-by: Shylaja Kokoori",5
"KAFKA-9025: Add a option for path existence check in ZkSecurityMigratorhttps://issues.apache.org/jira/browse/KAFKA-9025If a chroot is configured, ZkSecurityMigrator should prompt a confirm to user to ensure whether chroot is specified correctly.Author: huxihx <huxi_2b@hotmail.com>Author: huxi <huxi_2b@hotmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7618 from huxihx/KAFKA-9025",1
"KAFKA-3055; Fix JsonConverter mangling the Schema in ConnectAuthor: ksenji <ksenji@ebay.com>Reviewers: Dong Lin <lindong28@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #722 from ksenji/trunk",1
MINOR: fix integer overflow in simple benchmark MB/sec calculationAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2523 from dguy/minor-streams-bench,0
"KAFKA-5182: Reduce rebalance timeouts in request quota testReduce rebalance and session timeouts for join requests to trigger throttling in the request quota test.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>Closes #3057 from rajinisivaram/KAFKA-5182-quotatest",5
"KAFKA-4544: Add system tests for delegation token based authenticationThis change adds some basic system tests for delegation token based authentication:- basic delegation token creation- producing with a delegation token- consuming with a delegation token- expiring a delegation token- producing with an expired delegation tokenNew files:- delegation_tokens.py: a wrapper around kafka-delegation-tokens.sh  - executed in container where a secure Broker is running (taking advantage of automatic cleanup)- delegation_tokens_test.py: basic test to validate the lifecycle of a delegation tokenChanges were made in the following file to extend their functionality:- config_property was updated to be able to configure Kafka brokers with delegation token related settings- jaas.conf template because a broker needs to support multiple login modules when delegation tokens are used- consule-consumer and verifiable_producer to override KAFKA_OPTS (to specify custom jaas.conf) and the client properties (to authenticate with delegation token).Author: Attila Sasvari <asasvari@apache.org>Reviewers: Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Andras Katona <41361962+akatona84@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5660 from asasvari/KAFKA-4544",1
"MINOR: Extend RocksDB section of Memory Management Docs (#6793)Now that we can configure RocksDB to bound the total memory we should include docs describing how, as well as touching on some possible options that should be considered when taking advantage of this feature.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jim Galasyn <jim.galasyn@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
HOTFIX: remove redundant check for QueryableStateIntegrationTest,3
MINOR: Update MirrorMaker docs to remove multiple --consumer.config optionsSee:- https://issues.apache.org/jira/browse/KAFKA-1650- https://mail-archives.apache.org/mod_mbox/kafka-users/201512.mbox/%3CCAHwHRrUeTq_-EHXiUXdrbgHcRt-0E_t0+5kOYaF9Qy4aNVqYkAmail.gmail.com%3EAuthor: Andrew Otto <acotto@gmail.com>Reviewers: Gwen ShapiraCloses #1654 from ottomata/mirror-maker-doc-fix,2
"KAFKA-8446: Kafka Streams restoration crashes with NPE when the record value is null (#6842)When the restored record value is null, we are in danger of NPE during restoration phase.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10757: Fix compilation failure in StreamThreadTest (#9636)Add missing `null` to `TaskManager` constructor.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-2068; KAFKA-2069; Replace OffsetCommit and OffsetFetch Request/……Response with o.a.k.c.requests equivalentAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael JumaCloses #927 from granthenke/offset-refactor,4
KAFKA-12210; AdminClient should use DescribeCluster API when available (KIP-700) (#9905)This PR updates the AdminClient to use the DescribeCluster API when available. The clients fails back to the Metadata API otherwise.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-4996: Fix findbugs multithreaded correctness warnings for streams (#8929)Fix findbugs multithreaded correctness warnings for streams, updated variables to be threadsafeReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: Only send delete request if there are offsets in map (#7256)Currently on commit streams will attempt to delete offsets from repartition topics. However, if a topology does not have any repartition topics, then the recordsToDelete map will be empty.This PR adds a check that the recordsToDelete is not empty before executing the AdminClient#deleteRecords() method.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
System Test - Update all testcase_xxxx_properties.json for properties keys uniform naming convention; kafka-688; patched by Jun Rao; reviewed by Jun Rao,5
"KafkaController.RequestSendThread can throw exception on broker socket; patched by Yang Ye; reviewed by Jun Rao; KAFKA-459, KAFKA-460git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1373448 13f79535-47bb-0310-9956-ffa450edef68",2
KAFKA-1449; Use CRC32C for checksum of V2 message formatI manually tested that Crc32CTest and AbstractChecksums pass with JDK 9. I also verified that `Java9ChecksumFactory` is used in that case.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2739 from ijuma/kafka-1449-crc32c,5
MINOR: Reorder modifiers and Replace Map.get with Map.computeIfAbsent (#9991)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-13905: Fix failing ServerShutdownTest.testCleanShutdownAfterFailedStartupDueToCorruptLogs (#12165)Reviewers: Jason Gustafson <jason@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-8729, pt 1: Add 4 new metrics to keep track of various types of invalid record rejections (#7142)Right now we only have very generic FailedProduceRequestsPerSec and FailedFetchRequestsPerSec metrics that mark whenever a record is failed on the broker side. To improve the debugging UX, I added 4 new metrics in BrokerTopicStats to log various scenarios when an InvalidRecordException is thrown when LogValidator fails to validate a record:-- NoKeyCompactedTopicRecordsPerSec: counter of failures by compacted records with no key-- InvalidMagicNumberRecordsPerSec: counter of failures by records with invalid magic number-- InvalidMessageCrcRecordsPerSec: counter of failures by records with crc corruption-- NonIncreasingOffsetRecordsPerSec: counter of failures by records with invalid offsetReviewers: Robert Yokota <rayokota@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-1805; ProducerRecord should implement equals and hashCode; reviewed by Guozhang Wang,5
"KAFKA-2212: Authorizer CLI implementation.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #230 from Parth-Brahmbhatt/KAFKA-2212",5
KAFKA-5644; Fix Reset Consumer Group Offset tool to handle minute component of TimeZoneAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3626 from omkreddy/KAFKA-5644,5
KAFKA-13261: Add support for custom partitioners in foreign key joins (#11368)Implements KIP-775.Co-authored-by: Tomas Forsman <tomas-forsman@users.noreply.github.com>,1
trivial fix for kafka-producer-perf-test.shgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1245779 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Cleanup scala warnings (#7335)This patch removes a few warnings: mainly unused imports or vars.Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Update jmh for async profiler 2.0 support (#10800)Async profiler 2.0 outputs html5 flame graph filesand supports simultaneous collection of cpu,allocation and lock profiles in jfr format.Updated the readme to include an example of thelatter and verified that the Readme commandswork with async profiler 2.0.Release notes:* 1.28: https://mail.openjdk.java.net/pipermail/jmh-dev/2021-March/003171.html* 1.29: https://mail.openjdk.java.net/pipermail/jmh-dev/2021-March/003218.html* 1.30: https://mail.openjdk.java.net/pipermail/jmh-dev/2021-May/003237.html* 1.31: https://mail.openjdk.java.net/pipermail/jmh-dev/2021-May/003286.html* 1.32: https://mail.openjdk.java.net/pipermail/jmh-dev/2021-May/003307.htmlReviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-12235: Fix a bug where describeConfigs does not work on 2+ config keys (#9990)Fix a bug where if more than one configuration key is supplied, describeConfigs fails to return any results at all.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
"MINOR: add hint for setting an uncaught exception handler to JavaDocsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4104 from mjsax/minor-uncaught-exception-handler",0
"MINOR: Replication system tests should cover compressed pathAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2745 from hachikuji/add-replication-testcase-for-compression",3
"KAFKA-3488; Avoid failing of unsent requests in consumer where possibleFail unsent requests only when returning from KafkaConsumer.poll().Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1183 from rajinisivaram/KAFKA-3488",5
"KAFKA-4163: NPE in StreamsMetadataState during re-balance operationsDuring rebalance operations the Cluster object gets set to Cluster.empty(). This can result in NPEs when doing certain operation on StreamsMetadataState. This should throw a StreamsException if the Cluster is empty as it is not yet (re-)initializedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1845 from dguy/streams-meta-hotfix",0
"Kafka 9626: Improve ACLAuthorizer.acls() performanceThis PR avoids creation of unnecessary sets in AclAuthorizer.acls() method implementation.Perf results:**Old**```Benchmark                                (aclCount)  (resourceCount)  Mode  Cnt    Score   Error  UnitsAclAuthorizerBenchmark.testAclsIterator           5             5000  avgt   15    5.821 ? 0.309  ms/opAclAuthorizerBenchmark.testAclsIterator           5            10000  avgt   15   15.303 ? 0.107  ms/opAclAuthorizerBenchmark.testAclsIterator           5            50000  avgt   15   74.976 ? 0.543  ms/opAclAuthorizerBenchmark.testAclsIterator          10             5000  avgt   15   15.366 ? 0.184  ms/opAclAuthorizerBenchmark.testAclsIterator          10            10000  avgt   15   29.899 ? 0.129  ms/opAclAuthorizerBenchmark.testAclsIterator          10            50000  avgt   15  167.301 ? 1.723  ms/opAclAuthorizerBenchmark.testAclsIterator          15             5000  avgt   15   21.980 ? 0.114  ms/opAclAuthorizerBenchmark.testAclsIterator          15            10000  avgt   15   44.385 ? 0.255  ms/opAclAuthorizerBenchmark.testAclsIterator          15            50000  avgt   15  241.919 ? 3.955  ms/op```**New**```Benchmark                                (aclCount)  (resourceCount)  Mode  Cnt   Score   Error  UnitsAclAuthorizerBenchmark.testAclsIterator           5             5000  avgt   15   0.666 ? 0.004  ms/opAclAuthorizerBenchmark.testAclsIterator           5            10000  avgt   15   1.427 ? 0.015  ms/opAclAuthorizerBenchmark.testAclsIterator           5            50000  avgt   15  21.410 ? 0.225  ms/opAclAuthorizerBenchmark.testAclsIterator          10             5000  avgt   15   1.230 ? 0.018  ms/opAclAuthorizerBenchmark.testAclsIterator          10            10000  avgt   15   4.303 ? 0.744  ms/opAclAuthorizerBenchmark.testAclsIterator          10            50000  avgt   15  36.724 ? 0.409  ms/opAclAuthorizerBenchmark.testAclsIterator          15             5000  avgt   15   2.433 ? 0.379  ms/opAclAuthorizerBenchmark.testAclsIterator          15            10000  avgt   15   9.818 ? 0.214  ms/opAclAuthorizerBenchmark.testAclsIterator          15            50000  avgt   15  52.886 ? 0.525  ms/op```Author: Manikumar Reddy <manikumar.reddy@gmail.com>Author: Lucas Bradstreet <lucas@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Lucas Bradstreet <lucas@confluent.io>Closes #8199 from omkreddy/KAFKA-9626",5
"KAFKA-10584:IndexSearchType should use sealed trait instead of Enumeration (#9399)https://issues.apache.org/jira/browse/KAFKA-10584In Scala, we prefer sealed traits over Enumeration since the former gives you exhaustiveness checking. With Scala Enumeration, you don't get a warning if you add a new value that is not handled in a given pattern match.",0
"KAFKA-6462: fix unstable ResetIntegrationTest (#4446)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>",3
"KAFKA-6451: Simplifying KStreamReduce and KStreamAggregate[KAFKA-6451](https://issues.apache.org/jira/browse/KAFKA-6451)Simplified KStreamReduce and KStreamAggregate.Updated comments in KStreamAggregate.Author: Tanvi Jaywant <tanvijaywant@Tanvis-Air.home>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>Closes #4477 from tanvijaywant31/KAFKA-6451",5
"KAFKA-9859 / kafka-streams-application-reset tool doesn't take into account topics generated by KTable foreign key join operation (#8671)This PR fixes kafka-streams-application-reset tool. Before, kafka-streams-application-reset tool wasn't taking into account topics generated by KTable foreign key join operation.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Add --help to DumpLogSegmentsAuthor: Tom Bentley <tbentley@redhat.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3351 from tombentley/help,2
"KAFKA-10199: Commit the restoration progress within StateUpdater (#12279)During restoring, we should always commit a.k.a. write checkpoint file regardless of EOS or ALOS, since if there's a failure we would just over-restore them upon recovery so no EOS violations happened.Also when we complete restore or remove task, we should enforce a checkpoint as well; for failing cases though, we should not write a new one.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
KAFKA-5507; Check if classpath is empty in kafka-run-class.shAuthor: Evgeny Veretennikov <evg.veretennikov@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3421 from evis/kafka-run-class-check-classpath,1
MINOR: added spacing in streams doc in section 9.2Author: Kaufman Ng <kaufman@confluent.io>Reviewers: Guozhang WangCloses #1454 from coughman/trunk,1
merge from 0.8 and resolve conflicts,5
KAFKA-1281 add the new producer to existing tools; reviewed by Jun Rao and Guozhang Wang,1
"KAFKA-7043: Modified plugin isolation whitelist with recently added converters (KIP-305)Several recently-added converters are included in the plugin isolation whitelist, similarly to the `StringConverter`. This is a change in the implementation, and does not affect the approved KIP. Several unit tests were added to verify they are being loaded in isolation, again similarly to `StringConverter`.These changes should be applied only to `trunk` and `2.0`, since these converters were added as part of KIP-305 for AK 2.0.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5198 from rhauch/kafka-7043",5
"KAFKA-9950: Construct new ConfigDef for MirrorTaskConfig before defining new properties (#8608)`MirrorTaskConfig` class mutates the `ConfigDef` by defining additional properties, which leads to a potential `ConcurrentModificationException` during worker configuration validation and unintended inclusion of those new properties in the `ConfigDef` for the connectors which in turn is then visible via the REST API's `/connectors/{name}/config/validate` endpoint.The fix here is a one-liner that just creates a copy of the `ConfigDef` before defining new properties.Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
KAFKA-1896; Record size function should check if value is null; reviewed by Guozhang Wang,1
"KAFKA-8943: Move SecurityProviderCreator to org.apache.kafka.common.security.auth package (#7564)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Bump latest 3.0 version to 3.0.1 (#11885)Reviewers: Matthias J. Sax <mjsax@apache.org>,3
"KAFKA-6015; Fix NPE in RecordAccumulator after ProducerId resetIt is possible for batches with sequence numbers to be in the `deque` while at the same time the in flight batches in the `TransactionManager` are removed due to a producerId reset.In this case, when the batches in the `deque` are drained, we will get a `NullPointerException` in the background thread due to this line:```javaif (first.hasSequence() && first.baseSequence() != transactionManager.nextBatchBySequence(first.topicPartition).baseSequence())```Particularly, `transactionManager.nextBatchBySequence` will return null, because there no inflight batches being tracked.In this patch, we simply allow the batches in the `deque` to be drained if there are no in flight batches being tracked in the TransactionManager. If they succeed, well and good. If the responses come back with an error, the batces will be ultimately failed in the producer with an `OutOfOrderSequenceException` when the response comes back.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4022 from apurvam/KAFKA-6015-npe-in-record-accumulator",5
MINOR: Improve document of MirrorMakerAuthor: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Gwen ShapiraCloses #717 from sasakitoa/mirrorMaker_doc,2
KAFKA-7482: LeaderAndIsrRequest should be sent to the shutting down broker (#5745)Reviewers: Dong Lin <lindong28@gmail.com>,5
"MINOR: correct the error message of validating uint32 (#10193)Reviewers: Tom Bentley <tbentley@redhat.com>, David Jacot <djacot@confluent.io>",5
MINOR: remove the init method from SerdesguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #834 from ymatsuda/remove_init_from_Serdes,5
"MINOR: Update Scala to 2.12.7, lz4-java to 1.5 and othersHighlights:* 10% compilation speed improvement in Scala 2.12.7:https://www.scala-lang.org/news/2.12.7* 10% better decompression speed in lz4 1.8.2 (lz4-java 1.5.0includes lz4 1.8.3):https://github.com/lz4/lz4-java/blob/master/CHANGES.md#150https://github.com/lz4/lz4/releasesAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5715 from ijuma/scala-2.12.7-and-other-updates",5
"KAFKA-13161; Update replica partition state and replica fetcher state on follower update (#11189)When processing the topics delta, make sure that the replica manager partition state and replica fetcher state matches the information included in the topic delta. Also ensure that delayed operations are processed after the follower state change has been made since that is what allows them to be completed.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Add missing `+` in LogSegment.toString (#7408)The closing `)` was previously being discarded.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"MINOR: Clean up imports and unused variables (#5171)Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-5486: org.apache.kafka logging should go to server.logThe current config sends org.apache.kafka and any unspecified logger tostdout. They should go to `server.log` instead.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3402 from ijuma/kafka-5486-org.apache.kafka-logging-server.log,2
"KAFKA-13582: TestVerifiableProducer.test_multiple_kraft_security_protocols fails (#11664)KRaft brokers always use the first controller listener, so if there is not also a colocated KRaft controller on the node be sure to only publish one controller listener in `controller.listener.names` even when the inter-controller listener name differs.  System tests were failing due to unnecessarily publishing a second entry in `controller.listener.names` for a broker-only config and not also publishing a mapping for it in `listener.security.protocol.map`.  Removing the unnecessary entry in `controller.listener.names` solves the problem.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-10543: Convert KTable joins to new PAPI (#11412)* Migrate KTable joins to new Processor API.* Migrate missing KTableProcessorSupplier implementations.* Replace KTableProcessorSupplier with new Processor API implementation.Reviewers: John Roesler <vvcephei@apache.org>,1
MINOR: Improve verification in flaky testPartitionReassignmentDuringDeleteTopic (#6460)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-143 Check and make sure that all source code distributed by the project is covered by one or more approved licenses; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1182023 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: Close ZooKeeper clients in a couple of testsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3039 from rajinisivaram/MINOR-close-zkclient,5
"KAFKA-14024: Consumer keeps Commit offset in onJoinPrepare in Cooperative rebalance (#12349)In KAFKA-13310, we tried to fix a issue that consumer#poll(duration) will be returned after the provided duration. It's because if rebalance needed, we'll try to commit current offset first before rebalance synchronously. And if the offset committing takes too long, the consumer#poll will spend more time than provided duration. To fix that, we change commit sync with commit async before rebalance (i.e. onPrepareJoin).However, in this ticket, we found the async commit will keep sending a new commit request during each Consumer#poll, because the offset commit never completes in time. The impact is that the existing consumer will be kicked out of the group after rebalance timeout without joining the group. That is, suppose we have consumer A in group G, and now consumer B joined the group, after the rebalance, only consumer B in the group.Besides, there's also another bug found during fixing this bug. Before KAFKA-13310, we commitOffset sync with rebalanceTimeout, which will retry when retriable error until timeout. After KAFKA-13310, we thought we have retry, but we'll retry after partitions revoking. That is, even though the retried offset commit successfully, it still causes some partitions offsets un-committed, and after rebalance, other consumers will consume overlapping records.Reviewers: RivenSun <riven.sun@zoom.us>, Luke Chen <showuon@gmail.com>",1
"KAFKA-12944: Assume message format version is 3.0 when inter-broker protocol is 3.0 or higher (KIP-724) (#11036)Also:* Deprecate `log.message.format.version` and `message.format.version`.* Log broker warning if the deprecated config values are ignored due tothe inter-broker protocol version.* Log warning if `message.format.version` is set via `ConfigCommand`.* Always down-convert if fetch version is v3 or lower.* Add tests to verify new message format version based on theinter-broker protocol version.* Adjust existing tests that create topics with an older message format tohave the inter-broker protocol set to 2.8.* Add upgrade note.Note that the log compaction change to always write new segments withrecord format v2 if the IBP is 3.0 or higher will be done as part ofKAFKA-13093 (with Kafka 3.1 as the target release version).Reviewers: David Jacot <djacot@confluent.io>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9556; Fix two issues with KIP-558 and expand testing coverage (#8085)Correct the Connect worker logic to properly disable the new topic status (KIP-558) feature when `topic.tracking.enable=false`, and fix automatic topic status reset after a connector is deleted.Also adds new `ConnectorTopicsIntegrationTest` and expanded unit tests.Reviewers: Randall Hauch <rhauch@gmail.com>",3
"MINOR: Fix concurrency bug in MetadataCache and Metadata request when listeners inconsistent (#4374)- Add missing locking/volatile in MetadataCache.aliveEndPoint- Fix topic metadata not to throw BrokerNotAvailableExceptionwhen listeners are inconsistent. Add test verifying the fix. Aspart of this fix, renamed Broker methods to follow Mapconvention where the `get` version returns `Option`.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-12979; Implement command to find hanging transactions (#10974)This patch implements the `find-hanging` command described in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions#KIP664:Providetoolingtodetectandaborthangingtransactions-FindingHangingTransactions.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
revert commit to KAFKA-343 due to unit test failuresgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1367811 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-4265; Run replication quotas test with producer acks=1Test expects all records to be published successfully, which cannot be guaranteed with acks=0 since failures are not retried.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ben Stopford <benstopford@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1991 from rajinisivaram/KAFKA-4265",5
"KAFKA-1647; Create replicas on follower transition even if leader isunavailable, otherwise replication offset checkpoints (high water marks)can be lost on hard kills and restarts; reviewed by Joel Koshy, NehaNarkhede, Jun Rao and Guozhang Wang",1
KAFKA-1515 Fix a bug that could result in blocking for a long period of time in the producer. Patch from Guozhang Wang.,0
"MINOR: Code quality improvements to Config classes- Minor Javadoc fixes- Used final modifier if possible- Unnecessary type casts removed- Other minor clean-upsAuthor: Kamal C <kamal.chandraprakash@gmail.com>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2578 from Kamal15/config",5
"KAFKA-12537: fix application shutdown corner case with only one thread (#10387)When in EOS the run loop terminates on that thread before the shutdown can be called. This is a problem for EOS single thread applications using the application shutdown feature.I changed it so in all cases with a single thread, the dying thread will spin up a new thread to communicate the shutdown and terminate the dying thread. Also @ableegoldman refactored the catch blocks in runloop.Co-authored-by: A. Sophie Blee-Goldman <ableegoldman@gmail.com>Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
MINOR: Dependency updates for Scala libraries for improved Scala 3.0 support (#10783)Release notes:* Scala 2.12.14: https://github.com/scala/scala/releases/tag/v2.12.14* Scala Logging: https://github.com/lightbend/scala-logging/releases/tag/v3.9.3* Scala Collection Compat:  *  https://github.com/scala/scala-collection-compat/releases/tag/v2.3.1  * https://github.com/scala/scala-collection-compat/releases/tag/v2.3.2  * https://github.com/scala/scala-collection-compat/releases/tag/v2.4.0  * https://github.com/scala/scala-collection-compat/releases/tag/v2.4.1  * https://github.com/scala/scala-collection-compat/releases/tag/v2.4.2  * https://github.com/scala/scala-collection-compat/releases/tag/v2.4.3  * https://github.com/scala/scala-collection-compat/releases/tag/v2.4.4* Scala Java8 Compat:  * https://github.com/scala/scala-java8-compat/releases/tag/v1.0.0-RC1  * https://github.com/scala/scala-java8-compat/releases/tag/v1.0.0Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"MINOR: update JavaDoc for simple helper interfaces of KStream and KTable operatorsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2321 from mjsax/javaDocImprovements3",2
"MINOR: Avoid WARN log message when re-init from checkpoint skipped (#8873)The warning appears because the skipped offsets are not removed from the checkpoint. However, there is nothing to warn about, because the offset found there corresponding state stores and they were skipped.A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-5792; Fix Transient failure in KafkaAdminClientTest.testHandleTimeoutAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3822 from cmccabe/KAFKA-5792,5
"MINOR update comments and docs to be gender-neutralWhile this is not technically part of KIP-629, I believe this makes our codebase more inclusive as well.cc gwenshapAuthor: Xavier Léauté <xvrl@apache.org>Reviewers: Gwen ShapiraCloses #9398 from xvrl/neutral-term",1
MINOR: Use LATEST_1_1 instead of V_1_1_0 in quota_test (#5636)The goal is to only test against the latest bug fix release for each release branch.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"MINOR: Fixes javadoc of Windows, fixes typo in parameter name of KGroupedTableAuthor: Michael G. Noll <michael@confluent.io>Reviewers: Damian Guy, Ismael Juma, Guozhang WangCloses #1823 from miguno/trunk-windowed-javadocs",2
KAFKA-4613: Follow-up to fix JavaDocsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2468 from mjsax/kafka-4613-null-keys-follow-up,5
"KAFKA-8179: Part I, Bump up consumer protocol to v2 (#6528)1. Add new fields of subscription / assignment and bump up consumer protocol to v2.2. Update tests to make sure old versioned protocol can be successfully deserialized, and new versioned protocol can be deserialized by old byte code.Reviewers: Boyang Chen <boyang@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-6242: Dynamic resize of various broker thread pools (#4471)Dynamic resize of broker thread pools as described in KIP-226:  - num.network.threads  - num.io.threads  - num.replica.fetchers  - num.recovery.threads.per.data.dir  - background.threadsReviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Use max retries for consumer group tests to avoid flakiness (#7186)This patch updates ConsumerGroupCommandTest.scala to use the maximum possible number of AdminClient retries. The test runs will still be bounded by the request timeout. This address flakiness in tests such as testResetOffsetsNotExistingGroup and testResetOffsetsExistingTopic, which was caused by group coordinators being intermittently unavailable. Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
kafka-1462 (followup patch); Add new request and response formats for the new consumer and coordinator communication; patched by Jun Rao; reviewed by Jay Kreps,1
"MINOR: Standardise ""variable-length"" vs ""variable length"" (#7720)Both were used in the same sentence, which isn't necessarily clear.Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
MINOR: Fix bad logging substitution in `AbstractCoordinator` (#9757)Missed this in #9729. The substitution in `markCoordinatorUnknown` does not work because the argument is not provided as a parameter.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-3660: Log exception message in ControllerBrokerRequestBatchAuthor: Flavio Junqueira <fpj@apache.org>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1325 from fpj/KAFKA-3660",5
MINOR: Fix grammar in error message for InvalidRecordException (#8465)* Fix error message for InvalidRecordException* Update clients/src/main/java/org/apache/kafka/common/protocol/Errors.javaCo-authored-by: Konstantine Karantasis <konstantine@confluent.io>,5
KAFKA-1997; Refactor MirrorMaker based on KIP-3; reviewed by Joel Koshy and Guozhang Wang,1
"KAFKA-5876: KIP-216 Part 3, Apply StreamsNotStartedException for Interactive Queries (#10597)KIP-216 Part 3: Throw StreamsNotStartedException if KafkaStreams state is CREATEDReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
"KAFKA-2817; Check if socketChannel is connected in `SslTransportLayer.close`This avoids spurious log warning messages. Also tweak log messageif wrapResult.getStatus != CLOSED.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>Closes #511 from ijuma/kafka-2817-unconnected-ssl-transport-layer-close",5
KAFKA-6025: small fix for streams tutorialAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4053 from bbejeck/KAFKA_6025_fix_streams_tutorial,0
MINOR: Remove redundant semicolon (#10358),4
"MINOR: MyProcessor doc example should implement, not extend `Processor`Author: Michael G. Noll <michael@confluent.io>Reviewers: Eno Thereska, Guozhang WangCloses #2723 from miguno/trunk-streams-docs-typo-fix",2
MINOR: fix error message in TestRaftServer.scala (#9812)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"KAFKA-13880: Remove DefaultPartitioner from StreamPartitioner (#12304)There are some considerata embedded in this seemingly straight-forward PR that I'd like to explain here. The StreamPartitioner is used to send records to three types of topics:1) repartition topics, where key should never be null.2) changelog topics, where key should never be null.3) sink topics, where only non-windowed key could be null and windowed key should still never be null.Also, the StreamPartitioner is used as part of the IQ to determine which host contains a certain key, as determined by the case 2) above.This PR's main goal is to remove the deprecated producer's default partitioner, while with those things in mind such that:We want to make sure for not-null keys, the default murmur2 hash behavior of the streams' partitioner stays consistent with producer's new built-in partitioner.For null-keys (which is only possible for non-window default stream partition, and is never used for IQ), we would fix the issue that we may never rotate to a new partitioner by setting the partition as null hence relying on the newly introduced built-in partitioner.Reviewers: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>, Matthias J. Sax <matthias@confluent.io>",5
"kafka-1982; change kafka.examples.Producer to use the new java producer; patched by Ashish Singh; reviewed by Gwen Shapira, Mayuresh Gharat and Jun Rao",1
"KAFKA-8455: Add VoidSerde to Serdes (#7485)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-13557: Remove swapResult from the public API (#11617)Follow-on from #11582 .Removes a public API method in favor of an internal utility method.Reviewer: Matthias J. Sax <mjsax@apache.org>,4
"KAFKA-6455: KStream-KStream join should set max timestamp for result record (#6565)Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: log4j improvements on assigned tasks and store changelog readerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Xavier Léauté <xavier@confluent.io>, Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #4031 from guozhangwang/KMinor-assigned-task-log4j",2
"HOTFIX: Fix HerderRequest.compareTo()With KAFKA-3008 (#1788), the implementation does not respect the contract that 'sgn(x.compareTo(y)) == -sgn(y.compareTo(x))'This fix addresses the hang with JDK8 in DistributedHerderTest.compareTo()Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2232 from shikhar/herderreq-compareto",5
Embedded consumer doesn't shut down if the server can't start; patched by Jun Rao; reviewed by Neha Narkhede and Jay Kreps; KAFKA-197git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1213546 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10509: Added throttle connection accept rate metric (KIP-612) (#9317)This commit adds metric to track throttle time of connection accept rate (when hitting connection attempt rate quota), which is a part of KIP-612. Also does 2 fixes:  - Ensures that per-listener connection quotas are configured on broker startup (from static broker config, if one is set).  - Reduces quota values used in testDynamicListenerConnectionCreationRateQuota test, and the duration of verifyConnectionRate (that creates connections and verifies rate). We observed once that this test exhausted ephemeral port count. I reduced quotas used in this test by half, since this does not change the correctness of the test, while it also reduces the number of connections made by this test.Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-9688: kafka-topic.sh should show KIP-455 adding and removing replicas (#8332)Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
MINOR: improve JavaDocs for ReadOnlySessionStore (#11759)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"KAFKA-9703; Free up compression buffer after splitting a large batchMethod split takes up too many resources and mightcause outOfMemory error when the bigBatch is huge.Call closeForRecordAppends() to free up resourceslike compression buffers.Change-Id: Iac6519fcc2e432330b8af2d9f68a8d4d4a07646bSigned-off-by: Jiamei Xie <jiamei.xiearm.com>*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Jiamei Xie <jiamei.xie@arm.com>Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #8286 from jiameixie/outOfMemory",4
"KAFKA-12803: Support reassigning partitions when in KRaft mode (#10753)Support the KIP-455 reassignment API when in KRaft mode. Reassignmentswhich merely rearrange partitions complete immediately. Those that onlyremove a partition complete immediately if the ISR would be non-emptyafter the specified removals. Reassignments that add one or morepartitions follow the KIP-455 pattern of adding all the adding replicasto the replica set, and then waiting for the ISR to include all the newpartitions before completing. Changes to the partition sets areaccomplished via PartitionChangeRecord.Reviewers: Jun Rao <junrao@gmail.com>",4
MINOR: Make documentation follow latest templateMake the latest version of our docs follow the latest site template structure.Author: Derrick Or <derrickor@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2003 from derrickdoo/docs-updates,5
"KAFKA-4114: Allow different offset reset strategiesmjsaxHere's my first pass at finer grained auto offset reset strategies.I've left TODO comments about whether we want to consider adding this to `KGroupedTable.aggregate` and `KStreamImpl` when re-partitioning a source.Author: bbejeck <bbejeck@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #2007 from bbejeck/KAFKA-4114_allow_different_offset_reset_strategies",1
"KAFKA-3806: Increase offsets retention default to 7 days (KIP-186) (#4648)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8191: Add pluggability of KeyManager to generate the broker Private Keys and CertificatesReviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Ismael Juma <ismael@juma.me.uk>",1
MINOR: Fix broken docs linkAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #676 from granthenke/doc-link,2
KAFKA-5101; Remove unused zkClient parameter in incrementControllerEpochAuthor: Balint Molnar <balintmolnar91@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2886 from baluchicken/KAFKA-5101,2
KAFKA-6238; Fix 1.0.0 upgrade instructions relating to the message format versionThe upgrade instructions concerning the message format versions did not accountfor upgrades from versions prior to 0.11.0.x.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4256 from hachikuji/KAFKA-6328,5
Replace numerical compression codes in config with something human readable; KAFKA-363; patched by David Arthur; reviewed by Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1393731 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-7655 Metadata spamming requests from Kafka Streams under some circumstances, potential DOS (#5929)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-3460: Remove old 0.7 KafkaMigrationToolAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1136 from granthenke/remove-07-migration,4
"KAFKA-6082; Fence zookeeper updates with controller epoch zkVersionThis PR aims to enforce that the controller can only update zookeeper states after checking the controller epoch zkVersion. The check and zookeeper state updates are wrapped in the zookeeper multi() operations to ensure that they are done atomically. This PR is necessary to resolve issues related to multiple controllers (i.e. old controller updates zookeeper states before resignation, which is possible during controller failover based on the single threaded event queue model we have)This PR includes the following changes:- Add MultiOp request and response in ZookeeperClient- Ensure all zookeeper updates done by controller are protected by checking the current controller epoch zkVersion- Modify test cases in KafkaZkClientTest to test mismatch controller epoch zkVersionTests Done:- Unit tests (with updated tests to test mismatch controller epoch zkVersion)- Existing integration testsAuthor: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Dong Lin <lindong28@gmail.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>Closes #5101 from hzxa21/KAFKA-6082",3
MINOR: some javadocs for kstream public apiguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #844 from ymatsuda/javadoc,2
MINOR: Update possible errors in OffsetFetchResponseNote: None of the use cases for offset fetch would lead to a `TOPIC_AUTHORIZATION_FAILED` error (fetching offset of an unauthorized partition would return an `UNKNOWN_TOPIC_OR_PARTITION` error). That is why it is being removed from the `PARTITION_ERRORS` list.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2653 from vahidhashemian/minor/update_possible_errors_in_offset_fetch_response,5
ApiUtils#writeShortString uses String length instead of byte length; kafka-680; patched by David Arthur; reviewed by Jun Rao,1
"KAFKA-4642: Improve test coverage of ProcessorStateManagerMost of the exception paths weren't covered. Now they are.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2442 from dguy/KAFKA-4642",3
KAFKA-9620: Do not throw in the middle of consumer user callbacks (#8187)One way of fixing it forward.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"MINOR: Make ReplicaManager, LogManager, KafkaApis easier to construct (#11320)The ReplicaManager, LogManager, and KafkaApis class all have manyconstructor parameters. It is often difficult to add or remove aparameter, since there are so many locations that need to be updated. Inorder to address this problem, we should use named parameters whenconstructing these objects from Scala code. This will make it easy toadd new optional parameters without modifying many test cases.  It willalso make it easier to read git diffs and PRs, since the parameters willhave names next to them. Since Java does not support named paramters,this PR adds several Builder classes which can be used to achieve thesame effect.ReplicaManager also had a secondary constructor, which this PR removes.The function of the secondary constructor was just to provide somedefault parameters for the main constructor. However, it is simpler justto actually use default parameters.Reviewers: David Arthur <mumrah@gmail.com>",2
"KAFKA-3384: Conform to POSIX kill usageI believe this addresses KAFKA-3384.The POSIX kill manpage is at http://pubs.opengroup.org/onlinepubs/9699919799/utilities/kill.htmlAuthor: Matt McClure <mlm@aya.yale.edu>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1148 from matthewlmcclure/KAFKA-3384",5
KAFKA-7829; Javadoc should show that AdminClient.alterReplicaLogDirs() is supported in Kafka 1.1.0 or later (#6157)Reviewers: Jun Rao <junrao@gmail.com>,1
"KAFKA-7916: Unify store wrapping code for clarity (#6255)Refactor internal store wrapping for improved maintainability.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Bump latest 2.8 version to 2.8.1 (#11341)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
kafka-1503; all partitions are using same broker as their leader after broker is down;  patched by Jianwen Wang; reviewed by Guozhang Wang and Jun Rao,1
"MINOR: Remove ARM/PowerPC builds from Jenkinsfile (#12380)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
"KAFKA-10885 Refactor MemoryRecordsBuilderTest/MemoryRecordsTest to avoid a lot of… (#9906)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
"MINOR: Follow-up Streams doc changes to break into sub-pagesAlso fixed a bunch of broken links (details can be found in https://github.com/apache/kafka-site/commit/34f8ecea0db15523ce4b81e6b6bc4c5c2fabd603)Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3473 from guozhangwang/KMinor-streams-doc-breakdown",4
"MINOR: Remove throttling logic from RecordAccumulator (#7195)This is redundant since `Sender` and `NetworkClient` handle throttling. It'salso confusing since the `RecordAccumulator` logic only applies when`max.in.flight.requests.per.connection=1`.In `Sender.sendProducerData`, the following code handles throttling:```javawhile (iter.hasNext()) {    Node node = iter.next();    if (!this.client.ready(node, now)) {        iter.remove();        notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));    }}```Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: Standardised benchmark params for consumer and streamsThere were some minor differences in the basic consumer config and streams config that are now rectified. In addition, in AWS environments the socket size makes a big difference to performance and I've tuned it up accordingly. I've also increased the number of records now that perf is higher.Author: Eno Thereska <eno@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2634 from enothereska/minor-standardize-params",2
"KAFKA-13785: [6/N][Emit final] Copy: Emit final for TimeWindowedKStreamImpl (#12100)This is a copy PR of #11896, authored by @lihaosky (Hao Li): Initial implementation to emit final for TimeWindowedKStreamImpl. This PR is on top of #12030 Author: Hao LiReviewers: John Roesler <vvcephei@apache.org>",5
kafka-825; KafkaController.isActive() needs to be synchronized; patched by Jun Rao; reviewed by Neha Narkhede,5
"KAFKA-5595; Ensure client connection ids are not reused too quicklyWhen there are broker delays that cause a response to take longerthan `connections.max.idle.ms`, connections may be closed by thebroker (as well as by the client) before the response is processed.If the port is reused, broker may send the outstanding response toa new connection with the reused port. The new connection will endup with correlation id mismatch, requiring process restart. Thisis also a security exposure since clients receive responseintended for the wrong connection.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3530 from rajinisivaram/KAFKA-5595",5
ConsoleProducer does not have the queue-size option; kafka-684; patched by Maxime Brugidou; reviewed by Jun Rao,5
"HOTFIX: null check keys of ProducerRecord when computing sizeInBytes (#12288)Minor followup to #12235 that adds a null check on the record key in the new ClientUtils#producerRecordSizeInBytes utility method, as there are valid cases in which we might be sending records with null keys to the Producer, such as a simple builder.stream(""non-keyed-input-topic"").filter(...).to(""output-topic"")Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-12865 : Fix doc error in Admin.describeAcls API (#10790)Reviewers: Lee Dongjin <dongjin@apache.org>, Manikumar Reddy <manikumar.reddy@gmail.com>",0
KAFKA-521 Missing files on last commit.git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1416254 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-6244; Dynamic update of log cleaner configuration (#4465),5
"MINOR Updated transaction index as optional in LogSegmentData. (#10848)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
MINOR: JavaDoc improvements for RangeAssignor (#4079),1
"KAFKA-10606: Disable auto topic creation for fetch-all-topic-metadata request (#9435)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: some public JavaDoc cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2332 from mjsax/javaDocImprovements5",2
KAFKA-5384: Enable topic deletion by defaulthttps://cwiki.apache.org/confluence/display/KAFKA/KIP-162+-+Enable+topic+deletion+by+defaultAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ismael JumaCloses #3241 from gwenshap/KAFKA-5384,5
"MINOR: demote ""Committing task offsets"" log to DEBUG (#9489)Demote ""committing offsets"" log message to DEBUG and promote/add summarizing INFO level logs in the main StreamThread loopReviewers: Boyang Chen <boyang@confluent.io>, Walker Carlson <wcarlson@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-9832: Extend Streams system tests for EOS-beta (#8443)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-504 Catching the wrong exception in the test for snappy compression, added check for SnappyException too. Trivial fix, no review.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396178 13f79535-47bb-0310-9956-ffa450edef68",0
"KAFKA-9491; Increment high watermark after full log truncation (#8037)When a follower's fetch offset is behind the leader's log start offset, thefollower will do a full log truncation. When it does so, it must update bothits log start offset and high watermark. The previous code did the former,but not the latter. Failure to update the high watermark in this case can leadto out of range errors if the follower becomes leader before getting the latesthigh watermark from the previous leader. The out of range errors occur whenwe attempt to resolve the log position of the high watermark in DelayedFetchin order to determine if a fetch is satisfied.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-3845: KIP-75: Add per-connector convertersAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Shikhar Bhushan, Gwen ShapiraCloses #1721 from ewencp/kafka-3845-per-connector-converters",1
KAFKA-3937; Kafka Clients Leak Native Memory For Longer Than Needed With Compressed Messagesijuma - Making the change against trunk based on your suggestions to have the stream closing handled in the private RecordIterator constructor which I understand is only to be used only if the block of message(s) are compressed.Author: William Yu <wyu@unified.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1760 from wiyu/compressor_memory_leak_in_fetcher,1
"KAFKA-13834: fix drain batch starving issue (#12066)In drainBatchesForOneNode method, there's possibility causing some partitions in a node will never get picked. Fix this issue by maintaining a drainIndex for each node.Reviewers: Luke Chen <showuon@gmail.com>, RivenSun <91005273+RivenSun2@users.noreply.github.com>",1
KAFKA-1836 metadata.fetch.timeout.ms set to zero blocks forever; reviewed by Neha Narkhede and Ewen Cheslack-Postava,1
"MINOR: Improve GlobalKTable docs (#5996)Reviewers: Jim Galasyn, Michael G. Noll, John Roesler, Bill Bejeck, Guozhang Wang",2
"KAFKA-7225: Pretransform validated propsIf a property requires validation, it should be pretransformed if it is a variable reference, in order to have a value that will properly pass the validation.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5445 from rayokota/KAFKA-7225-pretransform-validated-props",5
"MINOR: Improve docs by adding ToC links to MonitoringMy top 2 reasons for visiting the Kafka docs are to:- View configurations- View metricsThis PR aims to improve the user experience for viewing metrics:- Add href links to the `Monitoring` section of the Table of Contents so users do not need to scroll or Ctrl/Cmd-F to find specific metric details (Monitoring section has grown large as more component & metrics are added)Author: lu.kevin@berkeley.edu <kelu@paypal.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5511 from KevinLiLu/feature/minor-improve-docs",2
"KAFKA-8861 Fix flaky RegexSourceIntegrationTest.testMultipleConsumersCanReadFromPartitionedTopic (#7281)similar to https://issues.apache.org/jira/browse/KAFKA-8011 and https://issues.apache.org/jira/browse/KAFKA-8026Reviewers:  Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",0
"KAFKA-12892: Use dedicated root in ZK ACL test (#10821)Having the `testChrootExistsAndRootIsLocked` test in a separate `ZookeeperTestHarness` isn't enough to prevent the ACL changes to the ZK root from affecting other integration tests. So instead, let's use a dedicated znode for this test. It still works because `makeSurePersistentPathExists` uses `createRecursive`, which will recurse and act the same for the root or a given znode. Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"MINOR: Stop logging 404s at ERROR level in ConnectCatches valid 404 exceptions, triggered by any HTTP request to a nonexistent path on the Connect REST API, higher in the code to not to log an ERROR log which can be seen as a false alarmReviewers: Chris Egerton <fearthecellos@gmail.com>",2
MINOR: streams javadoc correctionsAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Gwen ShapiraCloses #1019 from omkreddy/JAVADOC,2
"KAFKA-7537: Avoid sending full UpdateMetadataRequest to existing brokers in the cluster on broker changes to reduce controller memory footprint (#5869)This PR avoids sending out full UpdateMetadataReuqest in the following scenarios:1. On broker startup, send out full UpdateMetadataRequest to newly added brokers and only send out UpdateMetadataReuqest with empty partition states to existing brokers.2. On broker failure, if it doesn't require leader election, only include the states of partitions that are hosted by the dead broker(s) in the UpdateMetadataReuqest instead of including all partition states.This PR also introduces a minor optimization in the MetadataCache update to avoid copying the previous partition states upon receiving UpdateMetadataRequest with no partition states.Reviewers: Jun Rao <junrao@gmail.com>",5
"KAFKA-8731: InMemorySessionStore throws NullPointerException on startup (#7132)Reviewers:  Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2
KAFKA-2869; Host used by Authorizer should be IP address not hostname/IPAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #567 from ijuma/kafka-2869-host-used-by-authorizer-should-be-ip,1
kafka-1618 (followup); Exception thrown when running console producer with no port number for the broker; patched by Balaji Seshadri; reviewed by Jun Rao,1
MINOR: fix system tests sending ACLs through ZooKeeper (#9458)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: make Sensor#add idempotent (#4853)This change makes adding a metric to a sensor idempotent.That is, if the metric is already added to the sensor, the methodreturns with success.The current behavior is that any attempt to register a second metricwith the same name is an error.Testing strategy: There is a new unit test covering this behaviorReviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-9494; Include additional metadata information in DescribeConfig response (KIP-569) (#8723)Adds documentation and type of ConfigEntry in version 3 of DescribeConfigsResponseReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-9946; Partition deletion event should only be sent if deletion was requested in the StopReplica request (#8609)This patch fixes a regression in the `StopReplica` response handling. We should only send the event on receiving the `StopReplica` response if we had requested deletion in the request.Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9972: Only commit tasks with valid states (#8632)We spotted a case in the soak test where a standby task could be in CREATED state during commit, which causes an illegal state exception. To prevent this from happening, the solution is to always enforce a state check.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-1227 New producer!,1
"kafka-1409; oversized messages can slow down the brokers; patched by Guozhang Wang; reviewed by Neha Narkhede, Jun Rao",5
"KAFKA-7779; Avoid unnecessary loop iteration in leastLoadedNode (#6081)In NetworkClient.leastLoadedNode, we invoke `isReady` to  check if an established connection exists for the given node. `isReady` checks whether metadata needs to be updated also which wants to make metadata request first priority. However, if the to-be-sent request is metadata request, then we do not have to check this otherwise the loop in `leastLoadedNode` will do a complete iteration until the final node is selected. Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix javadoc warning in StreamsMetric (#8314)Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@apache.org>",2
KAFKA-2714: Added integration tests for exceptional cases in fetchingAuthor: Anna Povzner <anna@confluent.io>Reviewers: Jason GustafsonCloses #393 from apovzner/cpkafka-84,5
"KAFKA-5152: perform state restoration in poll loopIn onPartitionsAssigned:release all locks for non-assigned suspended tasks.resume any suspended tasks.Create new tasks, but don't attempt to take the state lock.Pause partitions for any new tasks.set the state to PARTITIONS_ASSIGNEDIn StreamThread#runLooppollif state is PARTITIONS_ASSIGNED2.1 attempt to initialize any new tasks, i.e, take out the state locks and init state stores2.2 restore some data for changelogs, i.e., poll once on the restore consumer and return the partitions that have been fully restored2.3 update tasks with restored partitions and move any that have completed restoration to running2.4 resume consumption for any tasks where all partitions have been restored.2.5 if all active tasks are running, transition to RUNNING and assign standby partitions to the restoreConsumer.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3675 from dguy/kafka-5152",5
MINOR: Improve TransactionIndex.sanityCheck() messageAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3446 from ijuma/improve-transaction-index-exception-sanity-check,1
KAFKA-2713: Run task start and stop methods in worker threads so they execute in parallel and cannot block the herder thread.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #443 from ewencp/kafka-2713-task-start-stop-threaded,1
make # of consumer rebalance retries configurable; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-213git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1207645 13f79535-47bb-0310-9956-ffa450edef68,1
"kafka-1395; fix unit tests in AutoOffsetResetTest; patched by Guozhang Wang; reviewed by Neha Narkhede, Jun Rao",3
"KAFKA-7828: Add ExternalCommandWorker to Trogdor (#6219)Allow the Trogdor agent to execute external commands. The agent communicates with the external commands via stdin, stdout, and stderr.Based on a patch by Xi Yang <xi@confluent.io>Reviewers: David Arthur <mumrah@gmail.com>",5
KAFKA-7168: Treat connection close during SSL handshake as retriable (#5371)SSL `close_notify` from broker connection close was processed as a handshake failure in clients while unwrapping the message if a handshake is in progress. Updated to handle this as a retriable IOException rather than a non-retriable SslAuthenticationException to avoid authentication exceptions in clients during rolling restart of brokers.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"MINOR: Add missing unit tests for Mirror Connect (#10192)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",3
"remove unnecessary semicolon (#9207)Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@apache.com>",5
"KAFKA-7231; Ensure NetworkClient uses overridden request timeout (#5444)Fixed incorrect use of default timeout instead of the argument explicitly passed to `newClientRequest`.Reviewers: Ron Dagostino <rndgstn@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2
"MINOR: Improve streams config parametersAdjust ""importance level"" and add explanation to the docs.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2855 from mjsax/minor-improve-streams-config-parameters",5
"KAFKA-3514: Part II, Choose tasks with data on all partitions to process (#5398)1. In each iteration, decide if a task is processable if all of its partitions contains data, so it can decide which record to process next.1.a Add one exception that, if the task indeed have data on some but not all of its partitions, we only consider as not processable for some finite round of iterations.1.b Add a task-level metric to record whenever we are forced to process a task that is only ""partially data available"", since it may leads to non-determinism.2. Break the main loop on put-raw-data and process-them. Since now not all data put into the queue would be processed completely within a single iteration.3. NOTE that within an iteration, if a task has exhausted one of its queue it will still be processed, since we only update processable list once in each iteration, I'm improving on this on the follow-up part III PR.4. Found and fixed a bug in metrics recording: the taskName and sensorName parameters were exchanged.5. Optimized task stream time computation again since our current partition stream time reasoning has been simplified.6. Added unit tests.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Bill Bejeck <bbejeck@gmail.com>",1
MINOR: change KStream processor namesguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #587 from ymatsuda/kstream_processor_names,5
"KAFKA-4019; Update log cleaner to handle max message size of topicsGrow read and write buffers of cleaner up to the maximum message size of the log being cleaned if the topic has larger max message size than the default config of the broker.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1758 from rajinisivaram/KAFKA-4019",5
KAFKA-5031; Follow-up with small cleanups/improvementsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3363 from hachikuji/KAFKA-5031-FOLLOWUP,5
KAFKA-177 Remove the clojure clients until correctly implemented and refactored; patched by nehanarkhede; reviewd by jefferydamickgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1195249 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Remove unused abstract function in test class (#5888)The function `setup_producer_and_consumer` is unused in the system testframework, which incorrectly suggests subclasses should implementit. It is not required or even referenced by the framework, sothe requirement should be removed.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Add test that verifies fix for KAFKA-3047Also clean-up `LogTest` a little.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #1071 from ijuma/kafka-3047-explicit-offset-assignment-corrupt-log-test,3
MINOR: Clean up for TransactionManager and RecordAccumulator (#11979)Reviewers: Luke Chen <showuon@gmail.com>,4
"KAFKA-4359: Remove commit interval in integration tests for testing caching effectsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2124 from enothereska/KAFKA-4359-intergration-tests-commit1",3
KAFKA-12248; Add BrokerHeartbeat/BrokerRegistration RPCs for KIP-500 (#9994)This patch adds the schemas and request/response objects for the `BrokerHeartbeat` and `BrokerRegistration` APIs that were added as part of KIP-631. These APIs are only exposed by the KIP-500 controller and not advertised by the broker.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Control plane listener tests should not use static port (#7033)We recently saw a few failing tests recently due to the static reliance on port 5000. For example:```org.apache.kafka.common.KafkaException: Socket server failed to bind to localhost:5000: Address already in use.at kafka.network.Acceptor.openServerSocket(SocketServer.scala:605)at kafka.network.Acceptor.<init>(SocketServer.scala:481)at kafka.network.SocketServer.createAcceptor(SocketServer.scala:253)at kafka.network.SocketServer.$anonfun$createControlPlaneAcceptorAndProcessor$1(SocketServer.scala:234)at kafka.network.SocketServer.$anonfun$createControlPlaneAcceptorAndProcessor$1$adapted(SocketServer.scala:232)at scala.Option.foreach(Option.scala:438)at kafka.network.SocketServer.createControlPlaneAcceptorAndProcessor(SocketServer.scala:232)at kafka.network.SocketServer.startup(SocketServer.scala:119)at kafka.network.SocketServerTest.withTestableServer(SocketServerTest.scala:1139)at kafka.network.SocketServerTest.testControlPlaneRequest(SocketServerTest.scala:198)```This patch fixes the failing tests to dynamically select the port.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
kafka-2323; Simplify ScalaTest dependency versions; patched by Ismael Juma; reviewed by Jun Rao,3
"KAFKA-5776; Add the Trogdor fault injection daemonAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3699 from cmccabe/trogdor-review",5
"KAFKA-3741; allow users to specify default topic configs for internal topicsAllow users to specify default topic configs for streams internal topics by supplying properties from `TopicConfig` with a prefix.Supplied defaults are used when creating the internal topics. They are overridden by the configs supplied along with the `InternalTopicConfig`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3459 from dguy/kafka-3741",5
MINOR: Streams web doc table fix (#4942),0
"KAFKA-7131: Update release script to generate announcement email textAuthor: Bibin Sebastian <bisebastian@DELC02QP51SG8WN.sea.corp.expecn.com>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Matthias J. Sax <mjsax@apache.org>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5572 from bibinss/release_mail",5
kafka-1517; Messages is a required argument to Producer Performance Test; patched by Daniel Compton; reviewed by Jun Rao,3
MINOR: Fix timestampDelta type in doc (#8870)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
KAFKA-9661: Propagate includeSynonyms option to AdminClient in ConfigCommand (#8229),5
"KAFKA-7866; Ensure no duplicate offsets after txn index append failure (#6570)This patch fixes a bug in the append logic which can cause duplicate offsets to be appended to the log when the append to the transaction index fails. Rather than incrementing the log end offset after the index append, we do it immediately after the records are written to the log. If the index append later fails, we do two things:1) We ensure that the last stable offset cannot advance. This guarantees that the aborted data will not be returned to the user until the transaction index contains the corresponding entry.2) We skip updating the end offset of the producer state. When recovering the log, we will have to reprocess the log and write the index entries.Reviewers: Jun Rao <junrao@gmail.com>",2
"MINOR: Move the resetting from revoked to the thread loop (#7243)Move the error code resetting logic from the onPartitionsRevoked callback into the streamthread directly after we've decided to rejoin the group, since onPartitionsRevoked are not guaranteed to be triggered.Ran system tests on the originally failed StreamsUpgradeTest 10 times and passed.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-9644: Handle non-existent configs in incrementalAlterConfigs APPEND/SUBTRACTProblem----The `incrementalAlterConfigs` API supports OpType.APPEND and OpType.SUBTRACT for configuration properties of LIST type. If an APPEND or SUBTRACT OpType is submitted for a config property which currently has no value, then the operation fails with a NullPointerException on the broker side (conveyed as an ""unknown server error"" to the client).This is because the alter code does a `getProperty` of the existing configuration valuewith no concern as to whether or not the property actually exists.This change handles the case of existing null properties.Testing-----This change includes 2 test cases in the unit test that demonstrate the issue for OpType.SUBTRACT and OpType.APPEND.Author: Steve Rodrigues <srodrigues@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Bob Barrett <bob.barrett@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #8216 from steverod/steverod.kafka-9644",5
"MINOR: Avoid FileInputStream/FileOutputStream (#5281)They rely on finalizers (before Java 11), which createunnecessary GC load. The alternatives are as easy touse and don't have this issue.Also use FileChannel directly instead of retrievingit from RandomAccessFile whenever possiblesince the indirection is unnecessary.Finally, add a few try/finally blocks.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
kafka-2235; LogCleaner offset map overflow; patched by Ivan Simoneko; reviewed by Jun Rao,1
MINOR: Upgrade gradle to 7.5.1 and bump other build/test dependencies (#12495)Gradle 7.5.1:* Important bug fixes including https://github.com/gradle/gradle/issues/21400* Release notes: https://docs.gradle.org/7.5.1/release-notes.htmlJUnit 5.9.0* Support for open test reporting and configurable thread mode for @Timeout* Release notes: https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.9.0test-retry-gradle-plugin 1.4.0* Support for Gradle 7.6 and minor fixes* Release notes:  * https://github.com/gradle/test-retry-gradle-plugin/releases/tag/v1.3.2  * https://github.com/gradle/test-retry-gradle-plugin/releases/tag/v1.4.0spotbugs-gradle-plugin* Minor fixes* Release notes:  * https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/5.0.7  * https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/5.0.8  * https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/5.0.9 dependency-check-gradle-plugin* Minor improvements and false positive fixes* Release notes:  * https://github.com/jeremylong/DependencyCheck/releases/tag/v7.0.4  * https://github.com/jeremylong/DependencyCheck/releases/tag/v7.1.0rat-gradle-plugin* Minor fixes* Diff: https://github.com/eskatos/creadur-rat-gradle/compare/v0.7.0...v0.7.1Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
KAFKA-7962: Avoid NPE for StickyAssignor (#6308)* KAFKA-7962: StickyAssignor: throws NullPointerException during assignments if topic is deletedhttps://issues.apache.org/jira/browse/KAFKA-7962Consumer using StickyAssignor throws NullPointerException if a subscribed topic was removed.* addressed vahidhashemian's comments* lower NPath Complexity* added a unit test,3
MINOR: fixing streams test-util compilation errors in Eclipse (#4631)Author: Edoardo Comar <ecomar@uk.ibm.com>Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-664 RequestPurgatory should clean up satisfied requests from watchers map. Also, simplify the purge logic - purge based on an incoming request interval.",2
KAFKA-1362; Publish sources and javadoc jars; (also removed Scala 2.8.2-specific actions). Reviewed by Jun Rao and Joe Stein,4
KAFKA-5742; Fix incorrect method name follow-upAuthor: Xavier Léauté <xl+github@xvrl.net>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3818 from xvrl/fix-startswith,0
"KAFKA-13385: In the KRPC request header, translate null clientID to empty (#11385)Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-9287; Fix unneeded delay before failing pending transaction commit (#7799)It is possible for the user to call `commitTransaction` before a pending `AddPartitionsToTxn` call has returned. If the `AddPartitionsToTxn` call returns an abortable error, we need to cancel any pending batches in the accumulator and we need to fail the pending commit. The problem in this case is that `Sender.runOnce`, after failing the batches, enters `NetworkClient.poll` before it has a chance to cancel the commit. Since there are no pending requests at this time, this will block unnecessarily and prevent completion of the doomed commit. This patch fixes the problem by returning from `runOnce` if any batches have been aborted, which allows the commit to also fail without the delay.Note that this was the cause of the delay executing `AuthorizerIntegrationTest.testTransactionalProducerTopicAuthorizationExceptionInCommit` compared to other tests in this class. After fixing the bug, the delay is gone and the test time is similar to other test cases in the class.Reviewers:  Guozhang Wang <wangguoz@gmail.com>",3
"MINOR: Update JavaDoc of KStream interfaceAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2153 from mjsax/javaDocKStreams",2
"KAFKA-5047: NullPointerException while using GlobalKTable in KafkaStreamsSkip null keys when initializing GlobalKTables. This is inline with what happens during normal processing.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2834 from dguy/kafka-5047",5
"KAFKA-6637; Avoid divide by zero error with segment.ms set to zero (#4698)Require a minimum value of 1 for `segment.ms` to avoid division by zero when computing random jitter.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Avoid trace logging computation in `checkEnoughReplicasReachOffset``numAcks` is only used in the `trace` logging statement so it should be a `def` instead of a `val`. Also took the chance to improve the code and documentation a little.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1449 from ijuma/minor-avoid-trace-logging-computation-in-partition",2
MINOR:fixed typo and removed outdated varilable name (#7402)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
ruby kafka gem is not functional; patched by Pierre-Yves Ritschard; KAFKA-135git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1175972 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-6663: Doc for `GlobalKTable` should be corrected. (#4723)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Format AdminUtils::assignReplicasToBrokers java documentation (#7173)The assignReplicasToBrokers method has helpful but a large unformattedjavadoc comment that results in a big blob in generated html. Thischange formats the comment so that generated javadoc is nice.Reviewers: Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8289: Fix Session Expiration and Suppression (#6654)Fix two problems in Streams:* Session windows expired prematurely (off-by-one error), since the window end is inclusive, unlike other windows* Suppress duration for sessions incorrectly waited only the grace period, but session windows aren't closed until gracePeriod + sessionGapUpdate the tests accordinglyReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3625: Add public test utils for Kafka Streams (#4402)* KAFKA-3625: Add public test utils for Kafka Streams - add new artifact test-utils - add TopologyTestDriver - add MockTime, TestRecord, add TestRecordFactoryReviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-9907: Switch default build to Scala 2.13 (#8537)Scala 2.13.2 introduces support for suppressing warnings,which makes it possible to enable fatal warnings. This isuseful enough from a development perspective to justifythis change.In addition, Scala 2.13.2 also has a Vector implementationwith significant performance improvements and encodingof String matches to switches.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
MINOR: KAFKA-3361 follow upAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1037 from granthenke/protocol-minor,5
"KAFKA 6673: Implemented missing override equals method (#4745)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-7742; Fixed removing hmac entry for a token being removed from DelegationTokenCacheAuthor: Satish Duggana <satishd@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6037 from satishd/KAFKA-7742,4
"MINOR: Ensure consumers are closed in DynamicBrokerReconfigurationTest (#5750)In `ConsumerBuilder.build`, if `awaitInitialPositions` raises an exception, the consumer will not be closed properly. We should add the consumer instance to the `consumers` collection immediately after construction.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-8747; Add atomic counter to fix flaky testEventQueueTime test (#7320)This patch adds an atomic counter in the test to ensure we have processed all the events before we assert the metrics. There was a race condition with the previous assertion, which asserted that the event queue is empty before checking the metrics.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-13446: Remove JWT access token from logs (#11489)The OAuth code logs the access token on both the client and the server, potentially exposing service account details. Remove all logging entries to prevent this from leaking.Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
KAFKA-2957: Fix typos in Kafka documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #641 from vahidhashemian/KAFKA-2957(cherry picked from commit 1f98b0315c92cf8c89f07241485fa6db8b496fdc)Signed-off-by: Gwen Shapira <cshapi@gmail.com>,5
"MINOR: Make kafka-streams-test-utils dependencies work with releases tarballshttps://github.com/apache/kafka/pull/4760 unintentionally included extra raw class files in the release tarballs by making the .class file output (instead of the jar) for a streams a dependency of the streams-test-utils. This fixes that issue by instead breaking the circular dependency by using a `compileOnly`/`provided` dependency on those sources and also including the dependency as a test dependency.I verified by using `gradlew clean installAll releaseTarGzAll`, then checking that the release tarball doesn't have the extraneous files and the installed pom file has the expected dependencies. The dependency on kafka-streams is now in the `test` scope, but that should be fine since a streams application would only use this dependency if it already had a dependency on streams in `compile` (or in weird edge cases the user could handle specifying the right dependencies). This actually seems to even be an improvement over the previous situation where the actual dependency was not expressed in the pom at all (since the dependency was on the sourceSet output rather than the actual project).Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@users.noreply.github.com>Closes #4816 from ewencp/fix-streams-dependencies",0
"MINOR: fix incorrect exception message in KafkaProducerWhile playing with client got the next exception:```javajava.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0...1].```It's obviously incorrect, so I've fixed it.Author: Igor Stepanov <igor.stepanov@keystonett.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1210 from stepio/trunk",1
MINOR: Fix Transient test failure SslTransportLayerTest.testNetworkThreadTimeRecorded (#5597),3
"KAFKA-6529: Stop file descriptor leak when client disconnects with staged receives (#4517)If an exception is encountered while sending data to a client connection, that connection is disconnected. If there are staged receives for that connection, they are tracked to process those records. However, if the exception was encountered during processing a `RequestChannel.Request`, the `KafkaChannel` for that connection is muted and won't be processed.Disable processing of outstanding staged receives if a send fails. This stops the leak of the memory for pending requests and the file descriptor of the TCP socket.Test that a channel is closed when an exception is raised while writing to a socket that has been closed by the client. Since sending a response requires acks != 0, allow specifying the required acks for test requests in SocketServerTest.scala.Author: Graham Campbell <graham.campbell@salesforce.com>Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Ted Yu <yuzhihong@gmail.com>",5
KAFKA-7106: remove deprecated Windows APIs (#10378)1. Remove all deprecated APIs in KIP-328.2. Remove deprecated APIs in Windows in KIP-358.Reviewers: John Roesler <vvcephei@apache.org>,4
KAFKA-3121: Remove aggregatorSupplier and add Reduce functionsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MatsudaCloses #795 from guozhangwang/K3121s1,1
"KAFKA-6747 Check whether there is in-flight transaction before aborting transaction (#4826)As Frederic reported on mailing list under the subject ""kafka-streams Invalid transition attempted from state READY to state ABORTING_TRANSACTION"", producer#abortTransaction should only be called when transactionInFlight is true.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
kafka-1644; Inherit FetchResponse from RequestOrResponse; patched by Anton Karamanov; reviewed by Jun Rao,5
"KAFKA-9274: Fix commit-TimeoutException handling for EOS (#9800)If EOS is enabled and the TX commit fails with a timeout,we should not process more messages (what is ok for non-EOS)because we don't really know the status of the TX.If the commit was indeed successful, we won't have an open TXcan calling send() would fail with an fatal error.Instead, we should retry the (idempotent) commit of the TX,and start a new TX afterwards.Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-13767; Fetch from consumers should return immediately when preferred read replica is defined by the leader (#11942)When a replica selector is configured, the partition leader computes a preferred read replica for any fetch from the consumers. When the preferred read replica is not the leader, the leader returns the preferred read replica with `FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY)` to the `ReplicaManager`. This causes the fetch to go into in the fetch purgatory because the exit conditions are not met. In turns out that the delayed fetch is not completed until the timeout is reached because the delayed fetch ignores partition with an unknown offset (-1). If the fetch contains only one partition, the fetch is unnecessarily delayed by the timeout time (500ms by default) to only inform the consumer that it has to read from a follower.This patch fixes the issue by completing the fetch request immediately when a preferred read replica is defined.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Create ChannelBuilder for each connection in ConnectionStressWorker workload- Currently we create single channel builder and reuse it in ConnectStressor workload.  This will fail when testing with secure connections, as we close channel builder after first connection.  This PR creates  ChannelBuilder for each test connection.- Also increase to connect ready wait timeout to 500ms.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #8937 from omkreddy/Connect",5
"KAFKA-13288; Include internal topics when searching hanging transactions (#11319)This patch ensures that internal topics are included when searching for hanging transactions with the `--broker-id` argument in `kafka-transactions.sh`.Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-7496: Handle invalid filters gracefully in KafkaAdminClient#describeAcls  (#5774),0
MINOR: Add a replication system test which simulates a slow replica (#11395)This patch adds a new system test which exercises the shrining/expansion process of the partition leader. It does so by introducing a network partition which isolates a broker from the other brokers in the cluster but not from KRaft Controller/ZK.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-12442: Upgrade ZSTD JNI from 1.4.8-4 to 1.4.9-1 (#10285)Since the new features are not used, you may right. However, I believe the benefits are three-fold.- There exists ZSTD side bug-fixes at ZSTD 1.4.9.- There exists ZSTD JNI side memory optimization improvements at ZSTD JNI 1.4.8-5 ~ 1.4.8-7. (This includes some incompatible changes and recovery. So, 1.4.9 is more human-readable stable version number.).- I hope this will reduce the chance of future potential version conflict issues across Apache projects. It's important when some downstream project starts to use new feature.   - Apache Spark 3.2.0 will use ZSTD 1.4.9. (https://github.com/apache/spark/commit/ba7e525a114cba01735ba94dc6d3a55dc372a2fc)   - Apache Parquet 1.12.0 will use ZSTD 1.4.9 (https://github.com/apache/parquet-mr/commit/66ac28ce232c586626f53b72110276ea45ec5fa2)   - Apache Avro 1.10.3 will use ZSTD 1.4.9 (https://github.com/apache/avro/commit/806667cb2b18e45d16fff25514c17a0272db2b2d)Reviewers: Lee Dongjin <dongjin@apache.org>, Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",5
MINOR: Wait for tasks to terminate to avoid exception in test teardownAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3483 from rajinisivaram/MINOR-consumerbounce-test,5
"KAFKA-7308: Fix rat and checkstyle config for Java 11 support (#5529)Relative paths in Gradle break when the Gradle daemon is usedunless user.dir can be changed while the process is running.Java 11 disallows this, so we use project paths instead.Verified that rat and checkstyle work with Java 11 after thesechanges.Reviewers: Dong Lin <lindong28@gmail.com>",4
"KAFKA-12500: fix memory leak in thread cache (#10355)Need to exclude threads in PENDING_SHUTDOWN from the num live threads computation used to compute the new cache size per thread. Also adds some logging to help follow what's happening when a thread is added/removed/replaced.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Walker Carlson <wcarlson@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-1046 Added support for Scala 2.10 builds while maintaining compatibility with 2.8.x; reviewed by Neha and Jun,5
KAFKA-13316; Enable KRaft mode in CreateTopics tests (#11655)This PR follows #11629 to enable `CreateTopicsRequestWithForwardingTest` and `CreateTopicsRequestWithPolicyTest` in KRaft mode.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-7997: Use automatic RPC generation in SaslAuthenticateAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6324 from mimaison/sasl-authenticate,1
KAFKA-2538: Fixing a compilation error in trunk.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Guozhang WangCloses #208 from Parth-Brahmbhatt/KAFKA-2538,1
KAFKA-449: Leader election testgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1384854 13f79535-47bb-0310-9956-ffa450edef68,3
"KAFKA-8425: Fix for correctly handling immutable maps (KIP-421 bug) (#6795)Since the originals map passed to AbstractConfig constructor may be immutable, avoid updating this map while resolving indirect config variables. Instead a new ResolvingMap instance is now used to store resolved configs.Reviewers: Randall Hauch <rhauch@gmail.com>, Boyang Chen <bchen11@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"Initial checkin of Kafka to Apache SVN. This corresponds to https://github.com/kafka-dev/kafka/commit/709afe4ec75489bc00a44335de8821fa726bb97e except that git specific files have been removed and code has been put into trunk/branches/site/etc. This is just a copy of master, branches and history are not being converted since we can't find a good tool for it.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1152970 13f79535-47bb-0310-9956-ffa450edef68",1
MINOR: Fix metric collection NPE during shutdownCollecting socket server metrics during shutdown may throw NullPointerExceptionAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2221 from xvrl/fix-metrics-npe-on-shutdown,0
"KAFKA-7140; Remove deprecated poll usages (#5319)Reviewers: Matthias J. Sax <mjsax@apache.org>, Jason Gustafson <jason@confluent.io>",5
MINOR: make sure all dir jobs are completed (#9728)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-13507: GlobalProcessor ignores user specified names (#11573)Use the name specified via consumed parameter in InternalStreamsBuilder#addGlobalStore method for initializing the source name and processor name. If not specified, the names are generated.Reviewers: Luke Chen <showuon@gmail.com>, Bill Bejeck <bbejeck@apache.org>",5
"KAFKA-10763: Fix incomplete cooperative rebalances preventing connector/task revocations (#9765)When two cooperative rebalances take place soon after one another, a prior rebalance may not complete before the next rebalance is started.Under Eager rebalancing, no tasks would have been started, so the subsequent onRevoked call is intentionally skipped whenever rebalanceResolved was false.Under Incremental Cooperative rebalancing, the same logic causes the DistributedHerder to skip stopping all of the connector/task revocations which occur in the second rebalance.The DistributedHerder still removes the revoked connectors/tasks from its assignment, so that the DistributedHerder and Worker have different knowledge of running connectors/tasks.This causes the connector/task instances that would have been stopped to disappear from the rebalance protocol, and left running until their workers are halted, or they fail.Connectors/Tasks which were then reassigned to other workers by the rebalance protocol would be duplicated, and run concurrently with zombie connectors/tasks.Connectors/Tasks which were reassigned back to the same worker would encounter exceptions in Worker, indicating that the connector/task existed and was already running.* Added test for revoking and then reassigning a connector under normal circumstances* Added test for revoking and then reassigning a connector following an incomplete cooperative rebalance* Changed expectRebalance to make assignment fields mutable before passing them into the DistributedHerder* Only skip revocation for the Eager protocol, and never skip revocation for incremental cooperative protocolsReviewers: Konstantine Karantasis <k.karantasis@gmail.com>",4
"MINOR: add missing TimeoutException to Producer.send JavaDocs (#10495)Reviewers: Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
MINOR: Rename InitPidRequest/InitPidResponse to InitProducerIdRequest/InitProducerIdResponseAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2997 from hachikuji/minor-rename-initpid,5
"MINOR: Refactor AdminClient ListConsumerGroups API (#4884)The current Iterator-based ListConsumerGroups API is synchronous.  The API should be asynchronous to fit in with the other AdminClient APIs.  Also fix some error handling corner cases.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10357: Add validation method for internal topics (#10266)For KIP-698, we need a way to validate internal topics before we create them. This PR adds a validation method to the InternalTopicManager for that purpose.Reviewers: Rohan Desai <rohan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-8254: Pass Changelog as Topic in Suppress Serdes (#6602)Reviewers:  Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10205: Documentation and handling of non deterministic Topologies (#9064)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-12233: Align the length passed to FileChannel by `FileRecords.writeTo` (#9970)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-10817; Add clusterId validation to raft Fetch handling (#10129)This patch adds clusterId validation in the `Fetch` API as documented in KIP-595. A new error code `INCONSISTENT_CLUSTER_ID` is returned if the request clusterId does not match the value on the server. If no clusterId is provided, the request is treated as valid.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-10740; Replace OffsetsForLeaderEpochRequest.PartitionData with automated protocol (#9689)This patch follows up https://github.com/apache/kafka/pull/9547. It refactors AbstractFetcherThread and its descendants to use `OffsetForLeaderEpochRequestData.OffsetForLeaderPartition` instead of `OffsetsForLeaderEpochRequest.PartitionData`. The patch relies on existing tests.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6844: Call shutdown on GlobalStreamThread after all StreamThreads have stopped (#4950)Moved the shutdown of GlobalStreamThread to after all StreamThread instances have stopped.There can be a race condition where shut down is called on a StreamThread then shut down is called on a GlobalStreamThread, but if StreamThread is delayed in shutting down, the GlobalStreamThread can shutdown first.If the StreamThread tries to access a GlobalStateStore before closing the user can get an exception stating ""..Store xxx is currently closed ""Tested by running all current streams tests.Reviewers: Ted Yu <yuzhihong@gmail.com>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: just remove leader on trunk like we did on 2.3 (#7447)Small follow-up to trunk PR #7423While debugging the 2.3 VP PR we realized we should remove the leader-tracking from the VP system test altogether. We'd already merged the corresponding trunk PR so I made a quick new PR for trunk (also fixes a missed version bump in one of the log messages)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
MINOR: Fix incorrect references to the max transaction timeout config (#4664),5
MINOR: Include additional detail in fetch error message (#6036)This patch adds additional information in the log message after a fetch failure to make debugging easier.Reviewers: David Arthur <mumrah@gmail.com>,0
"KAFKA-7250: switch scala transform to TransformSupplier (#5481)#5468 introduced a breaking API change that was actually avoidable. This PR re-introduces the old API as deprecated and alters the API introduced by #5468 to be consistent with the other methodsalso, fixed misc syntax problems",0
extend DumpLogSegments to verify consistency btw data and index; patched by Yang Ye; reviewed by Neha Narkhede and Jun Rao; KAFKA-577git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403553 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR: Fixed ""snasphot"" naming issue (#11203)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"Remove duplicate common.message.* from clients:test jar file (#12407)When consuming both `kafka-client:3.0.1` and `kafka-client:3.0.1:test`through maven a hygene tool was detecting multiple instances of the sameclass loaded into the classpath.Verified this change by building locally with a before and after build with`./gradlew clients:publishToMavenLocal`, then used beyond compare toverify the contents.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
KAFKA-3782: Ensure heartbeat thread restarted after rebalance woken upAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #1898 from hachikuji/KAFKA-3782,5
"MINOR: Rename remaining `zkVersion` to `partitionEpoch` in `PartitionTest` (#12147)Reviewers:  Kvicii <42023367+Kvicii@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
A tool to GET Zookeeper partition-offset and output to files; patched by John Fung; reviewed by Jun Rao; KAFKA-254git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1291535 13f79535-47bb-0310-9956-ffa450edef68,1
Some arguments are always set to default in ProducerPerformance; patched by John Fung; committed by Jun Rao; kafka-710,1
KAFKA-10437: Implement new PAPI support for test-utils (#9396)Implements KIP-478 for the test-utils module:* adds mocks of the new ProcessorContext and StateStoreContext* adds tests that all stores and store builders are usable with the new mock* adds tests that the new Processor api is usable with the new mock* updates the demonstration Processor to the new apiReviewers: Guozhang Wang <guozhang@apache.org>,1
"KAFKA-12684: Fix noop set is incorrectly replaced with succeeded set from LeaderElectionCommand (#10558)Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"MINOR: fix Bash shebang on vagrant/ scriptsAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1567 from shikhar/vagrant-scripts-shebang",5
KAFKA-9650: include human readable units in ms and bytes configs (#8222)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"MINOR: ConsoleConsumer - Fix number of processed messages countkafka-console-consumer.sh is showing an incorrect number ofmessages processed, counting one more message than the actualnumber of processed messages.Author: Luciano Afranllie <luafran@gmail.com>Reviewers: Guozhang WangCloses #617 from luafran/console-consumer-number-of-processed-messages",0
"MINOR: Allow creation of statestore without logging enabled or explicit source topicguozhangwangAuthor: dan norwood <norwood@confluent.io>Reviewers: Eno Thereska, Damian Guy, Guozhang WangCloses #1828 from norwood/manual-store",5
KAFKA-8210: Fix link for streams table duality (#6573)Reviewers: Victoria Bialas <vicky@confluent.io>,5
kafka-2234; Partition reassignment of a nonexistent topic prevents future reassignments; patched by Manikumar Reddy; reviewed by Jun Rao,5
trivial change to add kafka doap project file,2
"fix rows (#7837)Minor followup to #7825, should be cherry-picked to 2.4Reviewers: Bill Bejeck <bbejeck@gmail.com>",0
KAFKA-1068 OfflinePartitionCount metrics may be incorrect after the controller failover; reviewed by Neha Narkhede and Guozhang Wang,0
KAFKA-2304 Supported enabling JMX in Kafka Vagrantfile patch by Stevo Slavic reviewed by Ewen Cheslack-Postava,2
"KAFKA-7142: fix joinGroup performance issues (#5354)Summary:1. Revert GroupMetadata.members to private2. Add back a wrongly removed comment3. In GroupMetadata.remove(), update supportedProtocols and awaitingJoinCallbackMembers, only when the remove succeededReviewers: Jason Gustafson <jason@confluent.io>,  Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <sriharsha@apache.org>",5
"KAFKA-9659: Add more log4j when updating static member mappings (#8269)Reviewers: Matthias J. Sax <matthias@confluent.io>, Boyang Chen <boyang@confluent.io>, Rohan <desai.p.rohan@gmail.com>",5
KAFKA-1488; new metrics for measuring the ratio when the new producer is block for space allocation; patched by Jun Rao; reviewed by Guozhang Wang and Joel Koshy,1
KAFKA-1884; Add logging upon metadata response errors; reviewed by Guozhang Wang,0
"KAFKA-3121: Refactor KStream Aggregate to be Lambda-able.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #839 from guozhangwang/K3121s2",5
"KAFKA-10199: Cleanup TaskManager and Task interfaces (#12397)In order to integrate with the state updater, we would need to refactor the TaskManager and Task interfaces. This PR achieved the following purposes:    Separate active and standby tasks in the Tasks placeholder, plus adding pendingActiveTasks and pendingStandbyTasks into Tasks. The exposed active/standby tasks from the Tasks set would only be mutated by a single thread, and the pending tasks hold for those tasks that are assigned but cannot be actively managed yet. For now they include two scenarios: a) tasks from unknown sub-topologies and hence cannot be initialized, b) tasks that are pending for being recycled from active to standby and vice versa. Note case b) would be added in a follow-up PR.    Extract any logic that mutates a task out of the Tasks / TaskCreators. Tasks should only be a place for maintaining the set of tasks, but not for manipulations of a task; and TaskCreators should only be used for creating the tasks, but not for anything else. These logic are all migrated into TaskManger.    While doing 2) I noticed we have a couple of minor issues in the code where we duplicate the closing logics, so I also cleaned them up in the following way:    a) When closing a task, we first trigger the corresponding closeClean/Dirty function; then we remove the task from Tasks bookkeeping, and for active task we also remove its task producer if EOS-V1 is used.    b) For closing dirty, we swallow the exception from close call and the remove task producer call; for closing clean, we store the thrown exception from either close call or the remove task producer, and then rethrow at the end of the caller. The difference though is that, for the exception from close call we need to retry close it dirty; for the exception from the remove task producer we do not need to re-close it dirty.Reviewer: Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Streams Update for KIP-330 / KIP-356 (#5794)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Fix flaky testIdleConnection() test (#11996)The test expects that the connection becomes idle before the mock time is moved forward, but the processor thread runs concurrently and may run some activity on the connection after the mock time is moved forward, thus the connection never expires.The solution is to wait until the message is received on the socket, and only then wait until the connection is unmuted (it's not enough to wait for unmuted without waiting for message being received on the socket, because the channel might have not been muted yet).Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: fix cleanup phase for KStreamWindowAggregateTestfixes:```java.nio.file.NoSuchFileException: /tmp/test7863510415433793941/topic2-Canonized/topic2-Canonized-197001010000/000015.sstat sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:97)at java.nio.file.Files.readAttributes(Files.java:1686)at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:105)at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:199)at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:199)at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:199)at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:69)at java.nio.file.Files.walkFileTree(Files.java:2602)at java.nio.file.Files.walkFileTree(Files.java:2635)at org.apache.kafka.common.utils.Utils.delete(Utils.java:555)at org.apache.kafka.streams.kstream.internals.KStreamWindowAggregateTest.testJoin(KStreamWindowAggregateTest.java:320)```Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Jun Rao <junrao@gmail.com>Closes #2778 from mjsax/minor-fix-kstreamWindowAggregateTest",3
"MINOR: improve MinTimestampTrackerTest and fix NPE when null element removedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2611 from dguy/testing",3
"KAFKA-5556; Fix IllegalStateException in KafkaConsumer.commitSync due to missing future completion checkThis PR makes `commitOffsetsSync` method check whether future is completed after client's poll or not.Author: umesh chaudhary <umesh9794@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3489 from umesh9794/KAFKA-5556",5
"KAFKA-2366; Initial patch for CopycatThis is an initial patch implementing the basics of Copycat for KIP-26.The intent here is to start a review of the key pieces of the core API and get a reasonably functional, baseline, non-distributed implementation of Copycat in place to get things rolling. The current patch has a number of known issues that need to be addressed before a final version:* Some build-related issues. Specifically, requires some locally-installed dependencies (see below), ignores checkstyle for the runtime data library because it's lifted from Avro currently and likely won't last in its current form, and some Gradle task dependencies aren't quite right because I haven't gotten rid of the dependency on `core` (which should now be an easy patch since new consumer groups are in a much better state).* This patch currently depends on some Confluent trunk code because I prototyped with our Avro serializers w/ schema-registry support. We need to figure out what we want to provide as an example built-in set of serializers. Unlike core Kafka where we could ignore the issue, providing only ByteArray or String serializers, this is pretty central to how Copycat works.* This patch uses a hacked up version of Avro as its runtime data format. Not sure if we want to go through the entire API discussion just to get some basic code committed, so I filed KAFKA-2367 to handle that separately. The core connector APIs and the runtime data APIs are entirely orthogonal.* This patch needs some updates to get aligned with recent new consumer changes (specifically, I'm aware of the ConcurrentModificationException issue on exit). More generally, the new consumer is in flux but Copycat depends on it, so there are likely to be some negative interactions.* The layout feels a bit awkward to me right now because I ported it from a Maven layout. We don't have nearly the same level of granularity in Kafka currently (core and clients, plus the mostly ignored examples, log4j-appender, and a couple of contribs). We might want to reorganize, although keeping data+api separate from runtime and connector plugins is useful for minimizing dependencies.* There are a variety of other things (e.g., I'm not happy with the exception hierarchy/how they are currently handled, TopicPartition doesn't really need to be duplicated unless we want Copycat entirely isolated from the Kafka APIs, etc), but I expect those we'll cover in the review.Before commenting on the patch, it's probably worth reviewing https://issues.apache.org/jira/browse/KAFKA-2365 and https://issues.apache.org/jira/browse/KAFKA-2366 to get an idea of what I had in mind for a) what we ultimately want with all the Copycat patches and b) what we aim to cover in this initial patch. My hope is that we can use a WIP patch (after the current obvious deficiencies are addressed) while recognizing that we want to make iterative progress with a bunch of subsequent PRs.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma, Gwen ShapiraCloses #99 from ewencp/copycat and squashes the following commits:a3a47a6 [Ewen Cheslack-Postava] Simplify Copycat exceptions, make them a subclass of KafkaException.8c108b0 [Ewen Cheslack-Postava] Rename Coordinator to Herder to avoid confusion with the consumer coordinator.7bf8075 [Ewen Cheslack-Postava] Make Copycat CLI speific to standalone mode, clean up some config and get rid of config storage in standalone mode.656a003 [Ewen Cheslack-Postava] Clarify and expand the explanation of the Copycat Coordinator interface.c0e5fdc [Ewen Cheslack-Postava] Merge remote-tracking branch 'origin/trunk' into copycat0fa7a36 [Ewen Cheslack-Postava] Mark Copycat classes as unstable and reduce visibility of some classes where possible.d55d31e [Ewen Cheslack-Postava] Reorganize Copycat code to put it all under one top-level directory.b29cb2c [Ewen Cheslack-Postava] Merge remote-tracking branch 'origin/trunk' into copycatd713a21 [Ewen Cheslack-Postava] Address Gwen's review comments.6787a85 [Ewen Cheslack-Postava] Make Converter generic to match serializers since some serialization formats do not require a base class of Object; update many other classes to have generic key and value class type parameters to match this change.b194c73 [Ewen Cheslack-Postava] Split Copycat converter option into two options for key and value.0b5a1a0 [Ewen Cheslack-Postava] Normalize naming to use partition for both source and Kafka, adjusting naming in CopycatRecord classes to clearly differentiate.e345142 [Ewen Cheslack-Postava] Remove Copycat reflection utils, use existing Utils and ConfigDef functionality from clients package.be5c387 [Ewen Cheslack-Postava] Minor cleanup122423e [Ewen Cheslack-Postava] Style cleanup6ba87de [Ewen Cheslack-Postava] Remove most of the Avro-based mock runtime data API, only preserving enough schema functionality to support basic primitive types for an initial patch.4674d13 [Ewen Cheslack-Postava] Address review comments, clean up some code styling.25b5739 [Ewen Cheslack-Postava] Fix sink task offset commit concurrency issue by moving it to the worker thread and waking up the consumer to ensure it exits promptly.0aefe21 [Ewen Cheslack-Postava] Add log4j settings for Copycat.220e42d [Ewen Cheslack-Postava] Replace Avro serializer with JSON serializer.1243a7c [Ewen Cheslack-Postava] Merge remote-tracking branch 'origin/trunk' into copycat5a618c6 [Ewen Cheslack-Postava] Remove offset serializers, instead reusing the existing serializers and removing schema projection support.e849e10 [Ewen Cheslack-Postava] Remove duplicated TopicPartition implementation.dec1379 [Ewen Cheslack-Postava] Switch to using new consumer coordinator instead of manually assigning partitions. Remove dependency of copycat-runtime on core.4a9b4f3 [Ewen Cheslack-Postava] Add some helpful Copycat-specific build and test targets that cover all Copycat packages.31cd1ca [Ewen Cheslack-Postava] Add CLI tools for Copycat.e14942c [Ewen Cheslack-Postava] Add Copycat file connector.0233456 [Ewen Cheslack-Postava] Add copycat-avro and copycat-runtime11981d2 [Ewen Cheslack-Postava] Add copycat-data and copycat-api",5
KAFKA 158 Support for compression in go clients; patched by jeffregydamick; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1189773 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Combine repeated top-level error test in AlterIsrManagerTest (#9649)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",3
"KAFKA-5380: Fix transient failure in KafkaConsumerTest, close consumers1. Fix ordering of metadata update request for regex subscription to avoid timing issue when heartbeat thread updates metadata2. Override metadata cluster in MockClient for `KafkaConsumer#testChangingRegexSubscription` to avoid timing issues during update3. Close consumer in all KafkaConsumer tests since they leave behind heartbeat threads.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3238 from rajinisivaram/KAFKA-5380",5
"KAFKA-5960; Fix regression in produce version selection on old brokersAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3944 from hachikuji/KAFKA-5960",5
"KAFKA 8311: better handle timeout exception on Stream thread (#6662)The goals for this small diff are:1. Give user guidance if they want to relax commit timeout threshold2. Indicate the code path where timeout exception was caughtReviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3338: Add print and writeAsText to KStream/KTable in Kafka Streams    Addresses comments from previous PR [#1187]    Changed print and writeAsText method return signature to void    Flush System.out on close    Changed IllegalStateException to TopologyBuilderException    Updated MockProcessorContext.topic method to return a String    Renamed KStreamPrinter to KeyValuePrinter    Updated the printing of null keys to 'null' to match ConsoleConsumer    Updated JavaDoc stating need to override toStringAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Dan Norwood, Guozhang WangCloses #1209 from bbejeck/KAFKA-3338_Adding_print/writeAsText_to_Streams_DSL",1
KAFKA-9557: correct thread process-rate sensor to measure throughput (#8112)Correct the process-rate (and total) sensor to measure throughput (and total record processing count).Reviewers: Guozhang Wang <guozhang@confluent.io>,5
MINOR: Fix redundant static modifier for enum (#11282)Reviewers: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: ik.lim <iksh192@gmail.com>,0
"KAFKA-6878: NPE when querying global state store not in READY state (#4978)Check whether cache is null before retrieving from cache.Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-8868: Generate SubscriptionInfo protocol message (#7248)Rather than maintain hand coded protocol serialization code, Streams could use the same code-generation framework as Clients/Core.There isn't a perfect match, since the code generation framework includes an assumption that you're generating ""protocol messages"", rather than just arbitrary blobs, but I think it's close enough to justify using it, and improving it over time.Using the code generation allows us to drop a lot of detail-oriented, brittle, and hard-to-maintain serialization logic in favor of a schema spec.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"[KAFKA-13848] Clients remain connected after SASL re-authentication f… (#12179)Clients remain connected and able to produce or consume despite an expired OAUTHBEARER token.Root cause seems to be SaslServerAuthenticator#calcCompletionTimesAndReturnSessionLifetimeMs failing to set ReauthInfo#sessionExpirationTimeNanos when tokens have already expired (when session life time goes negative), in turn causing KafkaChannel#serverAuthenticationSessionExpired returning false and finally SocketServer not closing the channel.The issue is observed with OAUTHBEARER but seems to have a wider impact on SASL re-authentication.Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Sam Barker <sbarker@redhat.com>",0
"HOTFIX: fix a few typos on streams quickstartAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3510 from guozhangwang/KHotfix-streams-quickstart",0
"KAFKA-7652: Part II; Add single-point query for SessionStore and use for flushing / getter (#6161)#2972 tried to fix a bug about flushing operation, but it was not complete, since findSessions(key, earliestEnd, latestStart) does not guarantee to only return a single entry since its semantics are to return any sessions whose end > earliestEnd and whose start < latestStart.I've tried various ways to fix it completely and I ended up having to add a single-point query to the public ReadOnlySessionStore API for the exact needed semantics. It is used for flushing to read the old values (otherwise the wrong old values will be sent downstreams, hence it is a correctness issue) and also for getting the value for value-getters (it is for perf only).",1
"KAFKA-7169: Custom SASL extensions for OAuthBearer authentication mechanism (KIP-342) (#5379)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-8507; Unify connection name flag for command line tool [KIP-499] (#8023)This change updates ConsoleProducer, ConsumerPerformance, VerifiableProducer, and VerifiableConsumer classes to add and prefer the --bootstrap-server flag for defining the connection point of the Kafka cluster. This change is part of KIP-499: https://cwiki.apache.org/confluence/display/KAFKA/KIP-499+-+Unify+connection+name+flag+for+command+line+tool.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>,  Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4756; The auto-generated broker id should be passed to MetricRe……porter.configureAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2540 from cmccabe/KAFKA-4756",5
"MINOR: Add vagrant up wrapper for simple parallel bringup on awsThe main impediment to bringing up aws machines in parallel using vagrant was the interaction between `vagrant-hostmanager` and `vagrant-aws`. If you disable hostmanager during the `up` phase, and run it after the cluster is up, parallel bringup is possible. The only caveat is that machines must be brought up in small-ish batches to prevent rate limit errors from AWS since `vagrant-aws` doesn't seem to have mechanisms toThis PR:- disables `vagrant-hostmanager` during bringup- adds a wrapper script to make it convenient to bring machines up in batches on awsAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #982 from granders/vagrant-disable-hostmanager",5
MINOR; Remove end html tag from upgrade (#12605)The </html> tag doesn't have a matching <html> tag. Those tags are added bythe server side include and are not needed in docs/upgrade.htmlReviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-3902: Optimize KTable.filter in Streams DSL to avoid forwarding if both old and new values are nullThe contribution is my original work and that I license the work to the project under the project's open source license.Contributors: Guozhang Wang, Phil DeromeguozhangwangAdded checkEmpty to validate processor does nothing  and added a inhibit check for filter to fix issue.Author: Philippe Derome <phderome@gmail.com>Author: Phil Derome <phderome@gmail.com>Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1556 from phderome/DEROME-3902",0
KAFKA-9293; Fix NPE in DumpLogSegments offsets parser and display tombstone keys (#7820)Fixes an NPE when UserData in a member's subscription is null and adds similar checks for transaction log parser. Also modifies the output logic so that we show the keys of tombstones for both group and transaction metadata. Reviewers: David Arthur <mumrah@gmail.com>,5
"KAFKA-4254; Update producer's metadata before failing on non-existent partitionsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1995 from kkonstantine/KAFKA-4254-Update-producers-metadata-before-failing-on-non-existent-partition",5
KAFKA-4552; README.md has org.gradle.project.maxParallelForms instead of maxParallelForksAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2270 from cmccabe/KAFKA-4552,5
KAFKA-2338; Warn on max.message.bytes change- Both TopicCommand and ConfigCommand warn if message.max.bytes increases- Log failures on the broker if replication gets stuck due to an oversized message- Added blocking call to warning.Author: benstopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #322 from benstopford/CPKAFKA-61,2
KAFKA-8822; Consolidate `PartitionRecords` and `CompletedFetch` types in Fetcher (#7228)The `CompletedFetch` and `PartitionRecords` types are somewhat redundant. This PR consolidates the two types.Reviewers: Jason Gustafson <jason@confluent.io>,5
Should close filter in RocksDBStoreTest as well (#6676)Forgot to also close the filter in RocksDBStoreTest in time.Reviewers: Bill Bejeck <bbejeck@gmail.com>,5
"MINOR: add suppress warnings annotations in Streams API - fixes examples with regard to new API - fixes `Topology#addGlobalStore` parametersAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #4003 from mjsax/minor-deprecated",5
"KAFKA-1387: Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of timeThis is a patch to get around the problem discussed in the KAFKA-1387 jira. The tests are not passing in my box when I run them all, but they do pass when I run them individually, which indicates that there is something leaking from a test to the next. I still need to work this out and also work on further testing this. I wanted to open this PR now so that it can start getting reviewed.Author: flavio junqueira <fpj@apache.org>Author: fpj <fpj@apache.org>Author: Flavio Junqueira <fpj@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #178 from fpj/1387",1
KAFKA-1373; Set first dirty (uncompacted) offset to first offset of thelog if no checkpoint exists. Reviewed by Neha Narkhede and Timothy Chen.,2
"KAFKA-12200: Migrate connect:file module to JUnit 5 (#9917)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
"MINOR: Fix a typos in commentsAuthor: ouyangliduo <ouyangliduo@360.cn>Reviewers: Gwen Shapira, Lin DongCloses #701 from oyld/typos_fix",2
"KAFKA-8428: Always require a single batch with un- / compressed messages (#6816)I think it's better just to make single-batch as a universal requirement for all versions for compressed messages, and for V2 and beyond uncompressed messages as well.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Improve exception message that gets thrown for non-existent groupAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang WangCloses #471 from SinghAsDev/ExceptionMessage,1
"MINOR: Using enums for auto.offset.reset configuration (#12077)Using enums instead of Strings for auto.offset.reset configurationReviewers: Divij Vaidya <divijvaidya13@gmail.com>, Luke Chen <showuon@gmail.com",5
"KAFKA-8580: Compute RocksDB metrics (#7263)A metric recorder runs in it own thread and regularly records RocksDB metrics fromRocksDB's statistics. For segmented state stores the metrics are aggregated over thesegments.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-14051: Create metrics reporters in KRaft remote controllers (#12396)KRaft remote controllers do not yet support dynamic reconfiguration (https://issues.apache.org/jira/browse/KAFKA-14057). Until we implement that, in the meantime we see that the instantiation of the configured metric reporters is actually performed as part of the wiring for dynamic reconfiguration. Since that wiring does not exist yet for KRaft remote controllers, this patch refactors out the instantiation of the metric reporters from the reconfiguration of them and adjusts the controller startup sequence to explicitly instantiate the reporters if the controller is a remote one.Reviewers: Colin P. McCabe <cmccabe@apache.org>",5
MINOR: fix flaky StreamsUpgradeTestIntegrationTest (#7974)Make the test resilient to rebalance timing.Reviewed-by: Guozhang Wang <wangguoz@gmail.com>,3
HOTFIX: move restoreConsumer.assign() to shutdownTasksAndStaterestoreConsumer.assign(..) in removeStandbyTasks was logging an (ignorable) exception due to the restoreConsumer being closed. Moved the restoreConsumer.assign(..) to shutdownTasksAndState as this is done prior to the closing of consumers.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1986 from dguy/hotfix-assign,0
"MINOR: Fix race condition in Streams EOS system testWe should start the process only within the `with` block, otherwise the bytes parameter would cause a race condition that result in false alarms of system test failures.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>Closes #4348 from guozhangwang/KMinor-fix-eos-test",3
MINOR: Remove unnecessary semi-colonsAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2326 from mimaison/minor-fixes,0
"KAFKA-3157: Mirror maker doesn't commit offset with low trafficMirror maker doesn't commit offset with new consumer enabled when data volume is low. This is caused by infinite loop in ```receive()``` which would never jump out of loop if no data comingAuthor: Tao Xiao <xiaotao183@gmail.com>Reviewers: Ismael Juma, Jason GustafsonCloses #821 from xiaotao183/KAFKA-3157",5
KAFKA-9143: Log task reconfiguration error only when it happened (#7648)This commit makes `DistributedHerder` log that some error has happened during task reconfiguration only when it actually has happened.Author: Ivan Yurchenko <ivan0yurchenko@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,5
"KAFKA-12952: Remove deprecated LogConfig.Compact (#10451)Deprecated since 1.0.0 for misleading name. Not a public API technically,but we were conservative originally.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: Remove unnecessary batch iteration in FileRecords.downConvertAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4192 from ijuma/avoid-unnecessary-batch-iteration-in-down-convert,5
"MINOR: ensure original use of prop_file in verifiable producerThis PR: https://github.com/apache/kafka/pull/958 fixed the use of prop_file in the situation when we have multiple producers (before, every producer will add to the config). However, it assumes that self.prop_file is initially """". This is correct for all existing tests, but it precludes us from extending verifiable producer and adding more properties to the producer config (same as console consumer).This is a small PR to change the behavior to the original, but also make verifiable producer use prop_file method to be consistent with console consumer.Also few more fixes to verifiable producer came up during the review:-- fixed each_produced_at_least() method-- more straightforward use of compression typesgranders please review.Author: Anna Povzner <anna@confluent.io>Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1192 from apovzner/fix_verifiable_producer",0
"MINOR: Fix flaky test case for compact/delete topics (#6975)We recently observed a transient failure of this test case:```java.lang.AssertionError: Contents of the map shouldn't change expected:<Map(0 -> (340,340), 5 -> (345,345), 10 -> (350,350), 14 -> (354,354), 1 -> (341,341), 6 -> (346,346), 9 -> (349,349), 13 -> (353,353), 2 -> (342,342), 17 -> (357,357), 12 -> (352,352), 7 -> (347,347), 3 -> (343,343), 18 -> (358,358), 16 -> (356,356), 11 -> (351,351), 8 -> (348,348), 19 -> (359,359), 4 -> (344,344), 15 -> (355,355))> but was:<Map(0 -> (340,340), 5 -> (345,345), 10 -> (350,350), 14 -> (354,354), 1 -> (341,341), 6 -> (346,346), 97 -> (297,297), 9 -> (349,349), 96 -> (296,296), 13 -> (353,353), 2 -> (342,342), 17 -> (357,357), 12 -> (352,352), 7 -> (347,347), 98 -> (298,298), 3 -> (343,343), 18 -> (358,358), 95 -> (295,295), 16 -> (356,356), 11 -> (351,351), 99 -> (299,299), 8 -> (348,348), 19 -> (359,359), 4 -> (344,344), 15 -> (355,355))>```The presence of old keys implies that not all old segments had been deleted. We believe the retention check (which runs asynchronously) is executing after the last modified time of all but one of the segments has been changed. This leaves one old segment behind which ultimately causes the above assertion error.The fix here is to improve the wait condition.Rather than waiting for the number of segments to be 1, we wait for the log start offset to reach the end offset.Reviewers: David Arthur <mumrah@gmail.com>",1
KAFKA-2775: Move exceptions into API package for Kafka Connect.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #457 from ewencp/kafka-2775-exceptions-in-api-package,4
KAFKA-1257 Only send metadata requests to nodes with no in-flight requests.,5
"KAFKA-5671 Followup: Remove reflections in unit test classes1. Remove rest deprecation warnings in streams:jar.2. Consolidate all unit test classes' reflections to access internal topology builder from packages other than `o.a.k.streams`. We need to refactor the hierarchies of StreamTask, StreamThread and KafkaStreams to remove these hacky reflections.3. Minor fixes such as reference path, etc.4. Minor edits on web docs for the describe function under developer-guide.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>Closes #3603 from guozhangwang/K5671-followup-comments",5
"KAFKA-9848: Avoid triggering scheduled rebalance delay when task assignment fails but Connect workers remain in the group (#8805)In the first version of the incremental cooperative protocol, in the presence of a failed sync request by the leader, the assignor was designed to treat the unapplied assignments as lost and trigger a rebalance delay. This commit applies optimizations in these cases to avoid the unnecessary activation of the rebalancing delay. First, if the worker that loses the sync group request or response is the leader, then it detects this failure by checking the what is the expected generation when it performs task assignments. If it's not the expected one, it resets its view of the previous assignment because it wasn't successfully applied and it doesn't represent a correct state. Furthermore, if the worker that has missed the assignment sync is an ordinary worker, then the leader is able to detect that there are lost assignments and instead of triggering a rebalance delay among the same members of the group, it treats the lost tasks as new tasks and reassigns them immediately. If the lost assignment included revocations that were not applied, the leader reapplies these revocations again. Existing unit tests and integration tests are adapted to test the proposed optimizations. Reviewers: Randall Hauch <rhauch@gmail.com>",3
MINOR: JavaDoc markup cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2462 from mjsax/javaDocImprovements9,2
"KAFKA-8363: Fix parsing bug for config providers (#6726)Author: Chris Egerton <cegerton@oberlin.edu>Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",1
KAFKA-6785: Add Trogdor documentation (#4862),2
"KAFKA-6622; Fix performance issue loading consumer offsets (#4661)`batch.baseOffset` is an expensive operation (even says so in its javadoc), and yet was called for every single record in a batch when loading offsets. This means that for N records in a gzipped batch, the entire batch will be unzipped N times. The fix is to compute and cache the base offset once as we decompress and process the batch.Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Add missing generics and surpress warning annotations (#4518)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Send kraft raft/controller logs to controller log in systests (#12222)Currently the only place we see controller/raft logging in system tests is `server-start-stdout-stderr.log` where they are mixed with all other logs. It is more convenient to send them to `controller.log` as we do for zk tests.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, David Jacot <djacot@confluent.io>",5
HOTFIX: remove deprecated calls,4
"KAFKA-6659: Improve error message if state store is not found (#4732)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-14124: improve quorum controller fault handling (#12447)Before trying to commit a batch of records to the __cluster_metadata log, the active controllershould try to apply them to its current in-memory state. If this application process fails, theactive controller process should exit, allowing another node to take leadership. This will preventmost bad metadata records from ending up in the log and help to surface errors during testing.Similarly, if the active controller attempts to renounce leadership, and the renunciation processitself fails, the process should exit. This will help avoid bugs where the active controllercontinues in an undefined state.In contrast, standby controllers that experience metadata application errors should continue on, inorder to avoid a scenario where a bad record brings down the whole controller cluster.  Theintended effect of these changes is to make it harder to commit a bad record to the metadata log,but to continue to ride out the bad record as well as possible if such a record does get committed.This PR introduces the FaultHandler interface to implement these concepts. In junit tests, we use aFaultHandler implementation which does not exit the process. This allows us to avoid terminatingthe gradle test runner, which would be very disruptive. It also allows us to ensure that the testsurfaces these exceptions, which we previously were not doing (the mock fault handler stores theexception).In addition to the above, this PR fixes a bug where RaftClient#resign was not being called from therenounce() function. This bug could have resulted in the raft layer not being informed of an activecontroller resigning.Reviewers: David Arthur <mumrah@gmail.com>",5
"KAFKA-7918: Inline generic parameters Pt. II: RocksDB Bytes Store and Memory LRU Caches (#6327)Second PR in series to inline the generic parameters of the following bytes storesReviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2
"MINOR: FileConfigProvider#get should keep failure exception (#11130)Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: clean up window store interface to avoid confusion (#5359)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Improve FK Join docs and optimize null-fk case (#7536)Fix the formatting and wording of the foreign-key join javadocOptimize handling of null extracted foreign keysReviewers: Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"MINOR: Fix generic type of ProcessorParameters (#5741)In unrelated recent work, I noticed some warnings about the missing type parameters on ProcessorParameters.While investigating it, it seems like there was a bug in the creation of repartition topics.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-10017: disable flaky EosBetaUpgradeIntegrationTest to stabilize build (#8732)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
KAFKA-13528: KRaft RegisterBroker should validate that the cluster ID matches (#11593)The KRaft controller should validate that the clusterID matches before allowing a broker to register inthe cluster.Reviewers: José Armando García Sancio <jsancio@gmail.com>,1
"KAFKA-12368: Added inmemory implementations for RemoteStorageManager and RemoteLogMetadataManager. (#10218)KAFKA-12368: Added inmemory implementations for RemoteStorageManager and RemoteLogMetadataManager.Added inmemory implementation for RemoteStorageManager and RemoteLogMetadataManager. A major part of inmemory RLMM will be used in the default RLMM implementation which will be based on topic storage. These will be used in unit tests for tiered storage.Added tests for both the implementations and their supported classes.This is part of tiered storage implementation, KIP-405.Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-1986; Request failure rate should not include invalid message size and offset out of range; reviewed by Joel Koshy,1
KAFKA-9821: consolidate Streams rebalance triggering mechanisms (#8596)Persist followup rebalance in assignment and consolidate rebalance triggering mechanismsReviewers: John Roesler <vvcephei@apache.org>,5
"KAFKA-13553: Add PAPI Window and Session store tests for IQv2 (#11650)During some recent reviews, @mjsax pointed out that StateStore layersare constructed differently the stores are added via the PAPI vs. the DSL.This PR adds PAPI construction for Window and Session stores to theIQv2StoreIntegrationTest so that we can ensure IQv2 works on everypossible state store.Reviewer: Guozhang Wang <guozhang@apache.org>",1
"KAFKA-13100: Create KRaft controller snapshot during promotion (#11084)The leader assumes that there is always an in-memory snapshot at the lastcommitted offset. This means that the controller needs to generate an in-memorysnapshot when getting promoted from inactive to active.  This PR adds thatcode. This fixes a bug where sometimes we would try to look for that in-memorysnapshot and not find it.The controller always starts inactive, and there is no requirement that thereexists an in-memory snapshot at the last committed offset when the controlleris inactive. Therefore we can remove the initial snapshot at offset -1.We should also optimize when a snapshot is cancelled or completes, by deletingall in-memory snapshots less that the last committed offset.SnapshotRegistry's createSnapshot should allow the creating of a snapshot ifthe last snapshot's offset is the given offset. This allows for simpler clientcode. Finally, this PR renames createSnapshot to getOrCreateSnapshot.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
"MINOR: Send latest LeaderAndIsr version (#7351)KIP-455 (18d4e57f6e8c67ffa7937fc855707d3a03cc165a) bumped the LeaderAndIsr version to 3 but did not change the Controller code to actually send the new version. The ControllerChannelManagerTest had a bug which made it assert wrongly, hence why it did not catch it. This patch fixes said test.Because the new fields in LeaderAndIsr are not used yet, the gap was not caught by integration tests either.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-6115: TaskManager should be type aware - remove type specific methods from Task interface - add generics to preserve task type - add sub classes for different task typesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4129 from mjsax/kafka-6115-taskManager-should-be-type-aware",5
KAFKA-13117: migrate TupleForwarder and CacheFlushListener to new Record API (#11481)* Migrate TupleForwarder and CacheFlushListener to new Processor API* Update the affected ProcessorsReviewers: John Roesler <vvcephei@apache.org>,5
"KAFKA-2367; Add Copycat runtime data API.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen Shapira, Jay KrepsCloses #163 from ewencp/kafka-2367-copycat-runtime-data-api",5
MINOR: make Send and Receive work with TransferableChannel rather than Gat… (#9516)This PR introduces a new interface 'TransferableChannel' to replace GatheringByteChannel to avoid casting in write path. `TransferableChannel ` extends GatheringByteChannel with the minimal set of methods required by the Send interface. Supporting TLS and efficient zero copy transfers are the main reasons for the additional methods.Co-authored-by: Ismael Juma <ismael@juma.me.uk>Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: Restore `SslConsumerTest` which was accidentally deleted in client-side assignment commitProbably happened while resolving conflicts, commit: 86eb74d9236c586af5889fe79f4b9e066c9c2af3Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason GustafsonCloses #350 from ijuma/restore-ssl-consumer-test",3
MINOR: Updated StreamTableJoinIntegrationTest to use TTD (#7722)Convert StreamTableJoinIntegrationTest to use the ToplogyTestDriver to eliminate flakiness and speed up the build.Reviewers: John Roesler <john@confluent.io>,5
"MINOR: Add log identifier/prefix printing in Log layer static functions (#10742)When #10478 was merged, we accidentally lost the identifier/prefix string that we used to previously log to stderr from some of the functions in the Log class. In this PR, I have reinstated the identifier/prefix logging in these functions, so that the debuggability is restored.Reviewers: Luke Chen <showuon@gmail.com>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",0
"KAFKA-3740: Enable configuration of RocksDBStoresAdd new config StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG to enable advancedRocksDB users to override default RocksDB configurationAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Roger Hoover, Dan Norwood, Eno Thereska, Guozhang WangCloses #1640 from dguy/kafka-3740-listener",5
"KAFKA-12939: After migrating processors, search the codebase for missed migrations (#11534)Migrated internal usages that had previously been marked with TODO suppressions.Reviewer: John Roesler<vvcephei@apache.org>",2
"KAFKA-9891: add integration tests for EOS and StandbyTask (#8890)Ports the test from #8886 to trunk -- this should be merged to 2.6 branch.One open question. In 2.6 and trunk we rely on the active tasks to wipe out the store if it crashes. However, assume there is a hard JVM crash and we don't call closeDirty() the store would not be wiped out. Thus, I am wondering, if we would need to fix this (for both active and standby tasks) and do a check on startup if a local store must be wiped out?The current test passes, as we do a proper cleanup after the exception is thrown.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
HOTFIX: log4j-appender not getting builtAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #395 from SinghAsDev/HOTFIX-Log4jAppender,2
"KAFKA-10656: Log the feature flags received by the client (#9552)print out the feature flags received at DEBUG level, as well as the other version information.Example log line:[2020-11-03 17:47:17,076] DEBUG Node 0 has finalizedFeaturesEpoch: 42, finalizedFeatures: [FinalizedFeatureKey(name='feature_1', maxVersionLevel=2, minVersionLevel=1), FinalizedFeatureKey(name='feature_2', maxVersionLevel=4, minVersionLevel=3)], supportedFeatures: [SupportedFeatureKey(name='feature_1', minVersion=1, maxVersion=2), SupportedFeatureKey(name='feature_2', minVersion=3, maxVersion=4)] (org.apache.kafka.clients.NetworkClient:926)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-8770: KIP-557: Drop idempotent KTable source updates (#8254)Drops idempotent updates from KTable source operators.Specifically, drop updates in which the value is unchanged,and the timestamp is the same or larger.Implements: KIP-557Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
KAFKA-1187 Controller should retry connecting to brokers to send state change requests; reviewed by Jun Rao and Guozhang Wang,4
"MINOR: Remove duplicated test cases in MetadataVersionTest (#12116)These tests belongs to ApiVersionsResponseTest, and accidentally copied them to MetadataVersionTest when working on #12072.Reviewer: Luke Chen <showuon@gmail.com>",1
"MINOR: Fix failing test case in TransactionLogTest (#7895)This patch fixes a brittle expectation on the `toString` implementation coming from `Set`. This was failing on jenkins with the following error:```java.lang.AssertionError: expected:<Some(producerId:1334,producerEpoch:0,state=Ongoing,partitions=Set(topic-0),txnLastUpdateTimestamp=0,txnTimeoutMs=1000)> but was:<Some(producerId:1334,producerEpoch:0,state=Ongoing,partitions=HashSet(topic-0),txnLastUpdateTimestamp=0,txnTimeoutMs=1000)>```Instead we convert the collection to a string directly.Reviewers: Boyang Chen <boyang@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-10432; LeaderEpochCache is incorrectly recovered for leader epoch 0 (#9219)The leader epoch cache is incorrectly recovered for epoch 0 as theassignment is skipped when epoch == 0. This check was likely intended toprevent negative epochs from being applied or there was an assumptionthat epochs started at 1.A test has been added to LogSegmentTest to show the LogSegmentrecovery path works for the epoch cache. This was a test gap as none of the recover calls supply a leader epoch cache to recover.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: add spotlessScalaCheck to jenkins job (#5473)Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>,5
Changing version to 0.10.1.0-SNAPSHOT,4
"KAFKA-3651; Remove the condition variable waiting on memory availability in Bufferpool when a TimeoutException is thrownWhenever the BufferPool throws a ""Failed to allocate memory within the configured max blocking time"" exception, it should also remove the condition object from the waiters dequeAuthor: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Chen Zhu <amandazhu19620701@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1314 from MayureshGharat/kafka-3651",4
KAFKA-8098: Fix Flaky Test testConsumerGroups- The flaky failure is caused by the fact that the main thread sometimes issues DescribeConsumerGroup request before the consumer assignment takes effect. Added a latch to make sure such situation is not going to happen.Author: huxihx <huxi_2b@hotmail.com>Author: huxi <huxi_2b@hotmail.com>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6441 from huxihx/KAFKA-8098,1
"KAFKA-5132: abort long running transactionsAbort any ongoing transactions that haven't been touched for longer than the transaction timeoutAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Jason Gustafson, Apurva Mehta, Ismael Juma, Guozhang WangCloses #2957 from dguy/kafka-5132",1
"kafka-2099; BrokerEndPoint file, methods and object names should match; patched by Gwen Shapira; reviewed by Sriharsha Chintalapani and Jun Rao",2
KAFKA-10199: Implement adding standby tasks to the state updater (#12200)This PR adds adding of standby tasks to the default implementation of the state updater.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-1468 Misc. improvements from benchmarking.,1
KAFKA-12321 the comparison function for uuid type should be 'equals' rather than '==' (#10098)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
MINOR: BrokerMetadataSnapshotter must avoid exceeding batch size (#12486)BrokerMetadataSnapshotter should split up record lists that exceed the batch size.Reviewers: David Arthur <mumrah@gmail.com>,5
"MINOR: Remove unused MessageWriter and CompressionFactoryAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2543 from hachikuji/remove-message-writer",4
KAFKA-8241; Handle configs without truststore for broker keystore update (#6585)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
KAFKA-13689: optimize the log output of logUnused method (#11940)Optimize the log output of logUnused method.Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"MINOR: lower logging severity for offset resetWhen resetting the first dirty offset to the log start offset, we currently log an ERROR which makes users think the log cleaner has a problem and maybe has exited.  We should log a WARN instead to avoid alarming the users.Author: Dustin Cote <dustin@confluent.io>Reviewers: Gwen ShapiraCloses #1691 from cotedm/minorlogcleanerlogging",4
KAFKA-13588: consolidate `changelogFor` methods to simplify the generation of internal topic names (#11703)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
"MINOR: reload4j build dependency fixes (#12144)* Replace `log4j` with `reload4j` in `copyDependantLibs`. Since we have  some projects that have an explicit `reload4j` dependency, it  was included in the final release release tar - i.e. it was effectively  a workaround for this bug.* Exclude `log4j` and `slf4j-log4j12` transitive dependencies for  `streams:upgrade-system-tests`. Versions 0100 and 0101  had a transitive dependency to `log4j` and `slf4j-log4j12` via  `zkclient` and `zookeeper`. This avoids classpath conflicts that lead  to [NoSuchFieldError](https://github.com/qos-ch/reload4j/issues/41) in  system tests.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-5843; Mx4jLoader.maybeLoad should only be executed if kafka_mx4jenable is set to trueAuthor: Dong Lin <lindong28@gmail.com>Author: Ralph WeiresReviewers: Ismael Juma <ismael@juma.me.uk>Closes #3797 from lindong28/KAFKA-5843,1
MINOR: Fix red herring when ConnectDistributedTest.test_bounce fails. (#6838)Author: Alex Diachenko <sansanichfb@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,0
"KAFKA-13126: guard against overflow when computing `joinGroupTimeoutMs` (#11111)Setting the max.poll.interval.ms to MAX_VALUE causes overflow when computing the joinGroupTimeoutMs and results in the JoinGroup timeout being set to the request.timeout.ms instead, which is much lower.This can easily make consumers drop out of the group, since they must rejoin now within 30s (by default) yet have no obligation to almost ever call poll() given the high max.poll.interval.ms, especially when each record takes a long time to process or the `max.poll.records` is also very large. We just need to check for overflow and fix it to Integer.MAX_VALUE when it occurs.Reviewers: Luke Chen <showuon@gmail.com>, John Roesler <vvcephei@apache.org>",0
"MINOR: commit method doesn't exists for Consumer, but `commitSync` does. (#9585)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-368 use the pig core jar from maven instead of distributing it patch by Joe Stein reviewed by Jun Rao and Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1352146 13f79535-47bb-0310-9956-ffa450edef68,1
"Revert ""MINOR: make flush no-op as we don't need to call flush on commit.""This reverts commit 90b2a2bf664e4e40d4cd1b46c72732c5edb97cf9.",5
"MINOR: Tiny optimization to avoid mapping twice on the results.As pointed out by granthenke in #196, error can be wrapped in JShort directly to avoid second map.Author: David Jacot <david.jacot@gmail.com>Reviewers: Grant Henke, Gwen ShapiraCloses #714 from dajac/wrap-jshort",0
"KAFKA-13233 Log zkVersion in more places (#11266)When debugging issues with partition state, it's very useful to know the zkVersion that was written. This patch adds the zkVersion of LeaderAndIsr in a few more places.",1
KAFKA-12271 Immutable container classes to support new MetadataCache (#10018)Three new classes are added to support the upcoming changes to MetadataCacherequired for handling Raft metadata records.Reviewers: Jason Gustafson <jason@confluent.io>Co-authored-by: David Arthur <mumrah@gmail.com>,5
"KAFKA-9194: Update documentation for replica.fetch.min.bytes configLooks it is a typo, the actual key supposed to be this #replicaFetchWaitMaxTimeMs(replica.fetch.wait.max.ms) instead of that the docs have this #replicaMaxWaitTimeMsAuthor: sbellapu <sbellapu@visa.com>Author: sbellapu <satishbabumsc@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8877 from satishbellapu/trunk",1
"KAFKA-9409: Supplement immutability of ClusterConfigState class in Connect (#7942)The class claims to be immutable, but there are some mutable features of this class.Increase the immutability of it and add a little cleanup:* Pre-initialize size of ArrayList* Remove superfluous syntax* Use ArrayList instead of LinkedList since the list is created onceReviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-8730; Add API to delete consumer offsets (KIP-496) (#7276)This adds an administrative API to delete consumer offsets of a group as well as extends the mechanism to expire offsets of consumer groups.It makes the group coordinator aware of the set of topics a consumer group (protocol type == 'consumer') is actively subscribed to, allowing offsets of topics which are not actively subscribed to by the group to be either expired or administratively deleted. The expiration rules remain the same.For the other groups (non-consumer), the API allows to delete offsets when the group is empty and the expiration remains the same.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-6568; Log cleaner should check partition state before removal from inProgress map  (#4580)The log cleaner should not naively remove the partition from in progress map without checking the partition state. This may cause the other thread calling `LogCleanerManager.abortAndPauseCleaning()` to hang indefinitely.,5
"KAFKA-5655; materialized count, aggregate, reduce to KGroupedTableAdd overloads of `count`, `aggregate`, `reduce` using `Materialized` to `KGroupedTable`deprecate other overloadsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3829 from dguy/kafka-5655",5
"KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson, Ismael Juma, Joel Koshy, Jun Rao, and Edward Ribeiro",1
kafka-1198; NullPointerException in describe topic; patched by Guozhang Wang; reviewed by Jun Rao,5
"MINOR: Fix bugs in KafkaStreams.close()Initially proposed by ijuma in https://github.com/apache/kafka/pull/1362#issuecomment-218293662mjsax commented:> StreamThread.close() should be extended to call metrics.close() (the class need a private member to reference the Metrics object, too)The `Metrics` instance is created in the `KafkaStreams` constructor and shared between all threads, so closing it within the threads doesn't seem like the right approach. This PR calls `Metrics.close()` in `KafkaStreams.close()` instead.cc guozhangwangAuthor: Jeff Klukas <jeff@klukas.net>Reviewers: Ismael Juma, Guozhang WangCloses #1379 from jklukas/close-streams-metrics",1
"KAFKA-7584: StreamsConfig throws ClassCastException if max.in.flight.request.per.connect is specified as String (#5874)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9352: Use 'roundrobin' to assign topic-partitions to mirroring tasks (#7880)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",1
KAFKA-924. Specify console consumer properties via a single --property command line parameter; reviewed by Neha Narkhede,2
"MINOR: A few cleanups for DescribeQuorum APIs (#12548)A few small cleanups in the `DescribeQuorum` API and handling logic:- Change field types in `QuorumInfo`:  - `leaderId`: `Integer` -> `int`  - `leaderEpoch`: `Integer` -> `long` (to allow for type expansion in the future)  - `highWatermark`: `Long` -> `long`- Use field names `lastFetchTimestamp` and `lastCaughtUpTimestamp` consistently- Move construction of `DescribeQuorumResponseData.PartitionData` into `LeaderState`- Consolidate fetch time/offset update logic into `LeaderState.ReplicaState.updateFollowerState`Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-12691: Add case where task can be considered idling (#10565)Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
"KAFAK-3522: add API to create timestamped stores (#6601)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Upgrade build and test dependencies (#11984)* gradle: 7.3.3 -> 7.4.2  Configuration cache improvements and several other improvements.  https://docs.gradle.org/7.4.2/release-notes.html* dependencycheck gradle plugin: 6.5.3 -> 7.0.3  Minor fixes.* spotbugs gradle plugin: 5.0.5 -> 5.0.6  Minor fixes.  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/5.0.6* jmh: 1.34 -> 1.35  Fixes and profiler improvements.  https://mail.openjdk.java.net/pipermail/jmh-dev/2022-March/003422.html* jqwik: 1.6.3 -> 1.6.5  Various tweaks and some breaking changes that don't seem to affect us.  https://github.com/jlink/jqwik/releases/tag/1.6.4  https://github.com/jlink/jqwik/releases/tag/1.6.5* mockito: 4.3.1 -> 4.4.0  Add feature to verify static methods calls in order and minor fixes/improvements.  https://github.com/mockito/mockito/releases/tag/v4.4.0Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
KAFKA-533 changes to NOTICE and LICENSE related to KAFKA-534 removing client libraries from repogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1390790 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-7261: Record 1.0 for total metric when Count stat is used for rate (#5484)Reviewers: Jun Rao <junrao@gmail.com>, John Roesler <john@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-2820: Remove log threshold on appender in tools-log4j.propertiesRemoved a config in tools-log4j.properties which prevented certain service classes from logging at TRACE level.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #556 from granders/KAFKA-2820-systest-tool-loglevel",5
"Upgrade RocksDB from 6.27.3 to 6.29.4.1 (#11967)RocksDB 6.27.3 does not run on arm64 M1 Macs which would prevent people on this platform to run Kafka Streams. Thus, this PR upgrades RocksDB to 6.29.4.1 which contains the following fix to allow to run RocksDB on arm64 M1 Macs:facebook/rocksdb#7720The source compatibility report between 6.27.3 and 6.29.4.1 (attached to the ticket) reports a couple of incompatibilities. However, the incompatibilities do not seem to affect Kafka Streams' backwards compatibility.    The changes to class RocksDB only apply when inheriting from RocksDB. RocksDB is not exposed to users in Streams.    The changes to class WriteBatch and class WriteBatchInterface also only apply with inheritance. Both classes are not exposed to users in Streams.    -The change to enum SanityLevel seem also not to apply to Streams since SanityLevel is only used in ConfigOptions which is only used to load options from files and properties objects. Loading options from files or properties is not exposed to users in Streams.Reviewers: Bill Bejeck <bbejeck@apache.org>, Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org>",1
"MINOR: correctly parse version OffsetCommitResponse version < 3KAFKA-7903: automatically generate OffsetCommitRequest (#6583) introduced a change that cause consumer breakage when OffsetCommitResponse versions < 3 are parsed, as they do not include a throttle_time_ms field. This PR fixes the parsing by supplying the correct version to the OffsetCommitResponse constructor in AbstractResponse.parseResponse.I have tested this change against many of the compatibility system tests, and it has fixed all the failures that I have tested thus far.Author: Lucas Bradstreet <lucas@confluent.io>Reviewers: Gwen Shapira, Boyang ChenCloses #6698 from lbradstreet/offset-commit-response-throttle-field",1
"MINOR: Reuse decompression buffers in log cleanerFollow-up to KAFKA-5150, reuse decompression buffers in the log cleaner thread.Author: Xavier Léauté <xavier@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3180 from xvrl/logcleaner-decompression-buffers",4
KAFKA-2002: Mx4JLoader doesn't disable when kafka_mx4jenable=false.,0
"KAFKA-13769: Add tests for ForeignJoinSubscriptionProcessorSupplier (#12437)Reviewers: Adam Bellemare <adam.bellemare@gmail.com>, John Roesler <vvcephei@apache.org>",3
"KAFKA-510 Broker needs to know replication factor per partition; patched by Yang Ye; reviewed by Neha Narkhede, Jun Rao and Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397372 13f79535-47bb-0310-9956-ffa450edef68",2
"KAFKA-4930: Enforce set of legal characters for connector names (KIP-212)…to check for empty connector name and illegal characters in connector name. This also fixes  KAFKA-4938 by removing the check for slashes in connector name from ConnectorsResource.Author: Ewen Cheslack-Postava <me@ewencp.org>Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2755 from soenkeliebau/KAFKA-4930",5
"KAFKA-9729: avoid readLock in authorizer ACL lookupsA write lock is currently taken out whenever an ACL update is triggered. This update requires a round trip to ZK to get the ACLs for the resource (https://github.com/apache/kafka/pull/7882/files#diff-852b9cb2ceb2b85ec25b422f72c42620R489). This round trip to ZK can block any ACL lookups, which will block any requests and that require authorization, and their corresponding handler threads. This PR attempts to avoid these read locks by snapshotting the aclCache which is a threadsafe scala immutable.TreeMap.Author: Lucas Bradstreet <lucas@confluent.io>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.ukCloses #7882 from lbradstreet/acl-read-lock",5
"HOTFIX / KAFKA-14130: Reduce RackAwarenesssTest to unit Test (#12476)While working on KAFKA-13877, I feel it's an overkill to introduce the whole test class as an integration test, since all we need is to just test the assignor itself which could be a unit test. Running this suite with 9+ instances takes long time and is still vulnerable to all kinds of timing based flakiness. A better choice is to reduce it as a unit test, similar to HighAvailabilityStreamsPartitionAssignorTest that just test the behavior of the assignor itself, rather than creating many instances hence depend on various timing bombs to not explode.Since we mock everything, there's no flakiness anymore. Plus we greatly reduced the test runtime (on my local machine, the old integration takes about 35 secs to run the whole suite, while the new one take 20ms on average).Reviewers: Divij Vaidya <diviv@amazon.com>, Dalibor Plavcic",1
KAFKA-150 Make the error message for duplicate node ids in zk more self-explanatory.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1188255 13f79535-47bb-0310-9956-ffa450edef68,1
MINOR: add docs for KIP-354 KAFKA-7321 (#6724)MINOR: update documentation for the log cleaner max compaction lag feature (KIP-354) implemented in KAFKA-7321Author: Xiongqi Wu <xiowu@linkedin.com>Reviewer: Joel Koshy <jjkoshy@gmail.com>,2
MINOR: Update raft/README.md and minor RaftConfig tweaks (#9484)* Replace quorum.bootstrap.servers and quorum.bootstrap.voters withquorum.voters.* Remove seemingly unused `verbose` config.* Use constant to avoid unnecessary repeated concatenation.Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Remove redundant conditional judgments in Selector.clear() (#12048)Condition 'sendFailed' is always 'false' when reached.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"MINOR: Use generated InitProducerId RPC (#6538)This patch updates the InitProducerId request API to use the generated sources. It also fixes a small bug in the DescribeAclsRequest class where we were using the wrong api key.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Colin McCabe <cmccabe@apache.org>",0
MINOR: Fix inconsistency in StopReplica/LeaderAndIsr error countsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4147 from hachikuji/fix-error-inconsistencies,0
KAFKA-2860: better handling of auto commit errorsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #553 from hachikuji/KAFKA-2860,5
KAFKA-3654: Config validation should validate both common and connector specific configurationsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1313 from Ishiihara/config-short-circuit,5
"KAFKA-6214: enable use of in-memory store for standby tasksRemove the flag in `ProcessorStateManager` that checks if a store is persistent when registering it as a standby task.Updated the smoke test to use an in-memory store.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #4239 from dguy/kafka-6214",5
KAFKA-7561: Increase stop_timeout_sec to make ConsoleConsumerTest pass (#5853)Looks like the increased delay happens when connecting to the docker container.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-8384; Leader election command integration tests (#6880)This patch adds test cases for the leader election command added in KIP-460.Reviewers: Vikas Singh, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Store metrics scope, total metrics (#5290)1. Rename metrics scope of rocksDB window and session stores; also modify the store metrics accordingly with guidance on its correlations to metricsScope.2. Add the missing total metrics for per-thread, per-task, per-node and per-store sensors.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6256: fix flaky test KStreamKTableJoinIntegrationTest.shouldCountClicksPerRegionWithNonZeroByteCacheIncrease commit interval to make it less likely that we flush the cache in-between.To make it fool-proof, only compare the ""final"" result records if cache is enabled.Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4364 from mjsax/kafka-6256-flaky-kstream-ktable-join-with-caching-test",3
KAFKA-1611 Improve system test configuration; reviewed by Neha Narkhede and Guozhang Wang,5
"MINOR: Add timer for update limit offsets (#8047)Instead of always try to update committed offset limits as long as there are buffered records for standby tasks, we leverage on the commit interval to reduce our consumer.committed frequency.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <john@confluent.io>",5
KAFKA-12808: Remove Deprecated Methods under StreamsMetrics (#10724)Removal of methods already deprecated since 2.5.Adapt test to use the new alternative method.Reviewers: Bruno Cadonna <cadonna@apache.org>,1
HOTFIX: fix failed ControllerChannelManagerTest#testUpdateMetadataRequestSent (#9768)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-12394; Return `TOPIC_AUTHORIZATION_FAILED` in delete topic response if no describe permission (#10223)We now accept topicIds in the `DeleteTopic` request. If the client principal does not have `Describe` permission, then we return `TOPIC_AUTHORIZATION_FAILED`. This is justified because the topicId is not considered sensitive. However, in this case, we should not return the name of the topic in the response since we do consider it sensitive.Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>, Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-7317: Use collections subscription for main consumer to reduce metadata (#7969)Also addresses KAFKA-8821Note that we still have to fall back to using pattern subscription if the user has added any regex-based source nodes to the topology. Includes some minor cleanup on the sideReviewers: Bill Bejeck <bbejeck@gmail.com>,4
Require values in Utils.getTopic* methods to be positive; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-481git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1377213 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Use `firstTimestamp` instead of `baseTimestamp` in docs (#8584)In the docs, the `baseTimestamp` term is used when `firstTimestamp` is defined in the on-disk format and implementation.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: fix generics in Windows.segments and Windows.until`Windows.segments(...)` and `Windows.until(...)` currently aren't returning the `Window` with its type param `W`. This causes the generic type to be lost and therefore methods using this can't infer the correct return types.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #1587 from dguy/windows-generics",5
"KAFKA-5488: Add type-safe split() operator (#9107)Implements KIP-418, that deprecated the `branch()` operator in favor of the newly added and type-safe `split()` operator.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-99 Enforce a max request size in socket server to avoid running out of memory with very large requests.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159837 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-10200: Fix testability of PAPI with windowed stores (#8927)It's currently not possible to unit-test custom processors that use windowed stores,because the provided windowed store implementations cast the context toInternalProcessorContext.This change adds a public API example using windowed stores, and fixes thecasts internally that would make that example fail previously.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-6121: Restore and global consumer should not use auto.offset.reset- set auto.offset.reste to ""none"" for restore and global consumer- handle InvalidOffsetException for restore and global consumer- add corresponding tests- some minor cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com, Bill Bejeck <bill@confluent.io>, GuozhangWang <wangguoz@gmail.com>Closes #4215 from mjsax/kafka-6121-restore-global-consumer-handle-reset",0
"KAFKA-12648: fix IllegalStateException in ClientState after removing topologies (#11591)Fix for one of the causes of failure in the NamedTopologyIntegrationTest: org.apache.kafka.streams.errors.StreamsException: java.lang.IllegalStateException: Must initialize prevActiveTasks from ownedPartitions before initializing remaining tasks.This exception could occur if a member sent in a subscription where all of its ownedPartitions were from a named topology that is no longer recognized by the group leader, eg because it was just removed from the client. We should filter each ClientState based on the current topology only so the assignor only processes the partitions/tasks it can identify. The member with the out-of-date tasks will eventually clean them up when the #removeNamedTopology API is invoked on themReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-12357: Do not inline methods from the scala package by default (#10174)As mentioned in #9548, users currently use the kafka jar (`core` module)for integration testing and the current inlining behavior causesproblems when the user's classpath contains a different Scala versionthan the one that was used for compilation (e.g. 2.13.4 versus 2.13.3).An example error:`java.lang.NoClassDefFoundError: scala/math/Ordering$$anon$7`We now disable inlining of the `scala` package by default, but make iteasy to enable it for those who so desire (a good option if you canensure the scala library version matches the one used for compilation).While at it, we make it possible to disable scala compiler optimizations(`none`) or to use only method local optimizations (`method`). This canbe useful if optimizing for compilation time during development.Verified behavior by running gradlew with `--debug` and checking theoutput after `[zinc] The Scala compiler is invoked with:`Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",0
"KAFKA-9483: Add Scala KStream#toTable to the Streams DSL (#8024)Part of KIP-523Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
MINOR: Include quota related interfaces to javadocs (#5325),2
"KAFKA-3176: Add partition/offset options to the new consumerWith this pull request the new console consumer can be provided with optional --partition and --offset arguments so only messages from a particular partition and starting from a particular offset are consumed.The following rules are also implemented to avoid invalid combinations of arguments:- If --partition or --offset is provided --new-consumer has to be provided too.- If --partition is provided --topic has to be provided too.- If --offset is provided --partition has to be provided too.- --offset and --from-beginning cannot be used at the same time.This patch is co-authored with rajinisivaram.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #922 from vahidhashemian/KAFKA-3176",5
MINOR: Pass `-release 8` to scalac and upgrade to Gradle 6.4 (#8538)The version of Zinc included with Gradle 6.4 includes a fix for the blockerthat was preventing us from passing `-release 8` to scalac.Release notes for Gradle 6.4:https://docs.gradle.org/6.4/release-notes.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"MINOR: AbstractRequestResponse should be an interface (#7513)AbstractRequestResponse should be an interface, since it has no concrete elements or implementation.  Move AbstractRequestResponse#serialize to RequestUtils#serialize and make it package-private, since it doesn't need to be public.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-8488: Reduce logging-related string allocation in FetchSessionHandlerReviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-5844; add groupBy(selector, serialized) to Ktableadd `KTable#groupBy(KeyValueMapper, Serialized)` and deprecate the overload with `Serde` paramsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>Closes #3802 from dguy/kip-182-ktable-groupby",5
kafka-801; Fix MessagesInPerSec mbean to count uncompressed message rate; patched by Jun Rao; reviewed by Neha Narkhede,0
"MINOR: Remove unused GroupState.state fieldThis field doesn't seem to be used and the value for`AwaitingSync` seems to be wrong (it seems like itshould have been `2` instead of `5`).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3572 from ijuma/remove-unused-group-state-field",4
MINOR: Small refactorings in admin group handlers (#11079)Small refactoring to make the code uniform across the newly introduced admin group handlers.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-642 Remove the response version and baseline all versions/magic bytes etc to 0.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418181 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-3025; Added timetamp to Message and use relative offset.See KIP-31 and KIP-32 for details.A few notes on the patch:1. This patch implements KIP-31 and KIP-32. The patch includes features in both KAFKA-3025,  KAFKA-3026 and KAFKA-30362. All unit tests passed.3. The unit tests were run with new and old message format.4. When message format conversion occurs during consumption, the consumer will not be able to detect the message size too large situation. I did not try to fix this because the situation seems rare and only happen during migration phase.Author: Jiangjie Qin <becket.qin@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Author: Jiangjie (Becket) Qin <becket.qin@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Anna Povzner <anna@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #764 from becketqin/KAFKA-3025",5
MINOR: Fix ProcessorContext JavaDocs and stream-time computation (#8603)Reviewer: John Roesler <john@confluent.io>,5
"KAFKA-4901; Make ProduceRequest thread-safeIf request logging is enabled, `ProduceRequest` can be accessedand mutated concurrently from a network thread (which calls`toString`) and a request handler thread (which calls`clearPartitionRecords()`).That can lead to a `ConcurrentModificationException` when iteratingthe `partitionRecords` map.The underlying thread-safety issue has existed since the serverstarted using the Java implementation of ProduceRequest in 0.10.0.However, we were incorrectly not clearing the underlying struct until0.10.2, so `toString` itself was thread-safe until that change. In 0.10.2,`toString` is no longer thread-safe and we could potentially see a`NullPointerException` given the right set of interleavings between`toString` and `clearPartitionRecords` although we haven't seen thathappen yet.In trunk, we changed the requests to have a `toStruct` methodinstead of creating a struct in the constructor and `toString` wasno longer printing the contents of the `Struct`. This accidentallyfixed the race condition, but it meant that request logging was lessuseful.A couple of days ago, `AbstractRequest.toString` was changed toprint the contents of the request by calling `toStruct().toString()`and reintroduced the race condition. The impact is more visiblebecause we iterate over a `HashMap`, which proactivelychecks for concurrent modification (unlike arrays).We will need a separate PR for 0.10.2.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>Closes #2689 from ijuma/produce-request-thread-safety",2
MINOR: Replace if/else with match in KafkaZkClient#getPartitionAssignmentForTopics (#11669)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: Fix common struct `JsonConverter` and `Schema` generation (#9279)This patch fixes a couple problems with the use of the `StructRegistry`. First, it fixes registration so that it is consistently based on the typename of the struct. Previously structs were registered under the field name which meant that fields which referred to common structs resulted in multiple entries. Second, the patch fixes `SchemaGenerator` so that common structs are considered first.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
"MINOR: fix typos and incorrect docsAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Matthias J. Sax, Guozhang WangCloses #2112 from xvrl/minor-doc-fixes",2
MINOR: Disable KafkaAdminClientTest.testHandleTimeoutThis test is super flaky in the PR builder. https://issues.apache.org/jira/browse/KAFKA-5792 tracks the fix.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3877 from apurvam/MINOR-disable-adminclient-timeout-test,3
"MINOR: Update test to wait for final value to reduce flakiness updated test method for multiple keys (#5517)Updated two integration tests to use IntegrationTestUtils#waitUntilFinalKeyValueRecordsReceived to eliminate flaky test results.Also, I updated IntegrationTestUtils#waitUntilFinalKeyValueRecordsReceived method to support having results with the same key present with different values.For testing, I ran the current suite of streams tests.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5487; upgrade and downgrade streams app system test-Tests for rolling upgrades for a streams app (keeping broker config fixed)-Tests for rolling upgrades of brokers (keeping streams app config fixed)Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3411 from enothereska/KAFKA-5487-upgrade-test-streams",3
"KAFKA-4720: Add a KStream#peek(ForeachAction<K, V>) in DSLhttps://issues.apache.org/jira/browse/KAFKA-4720Peek is a handy method to have to insert diagnostics that do not affect the stream itself, but some external state such as logging or metrics collection.Author: Steven Schlansker <sschlansker@opentable.com>Reviewers: Damian Guy, Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2493 from stevenschlansker/kafka-4720-peek",2
"MINOR: fix docs typo (#5827)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-4891; kafka.request.logger TRACE regressionBoth the headers and requests have regressed to just show object ids instead of their contents from their underlying structs. I'm guessing this regression came from commit [fc1cfe475e8ae8458d8ddf119ce18d0c64653a70](https://github.com/apache/kafka/commit/fc1cfe475e8ae8458d8ddf119ce18d0c64653a70)Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #2678 from onurkaraman/KAFKA-4891,2
MINOR: Upgrade netty to 4.1.73.Final (#11706)Changelog: https://github.com/netty/netty/issues?q=is%3Aclosed+milestone%3A4.1.73.FinalReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
KAFKA-8190; Don't update keystore modification time during validation (#6539)Ensure that modification time is checked against the file used to create the SSLContext that is in-use so that SSLContext is updated whenever file is modified and a config update request is received.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"KAFKA-9169: fix standby checkpoint initialization (#7681)Instead of caching the checkpoint map during StandbyTaskinitialization, use the latest checkpoints (which would havebeen updated during suspend).Reviewers: Bill Bejeck <bill@confluent.io>",5
kafka-959; DefaultEventHandler can send more produce requests than necesary; patched by Guozhanh Wang; reviewed by Jun Rao,0
"KAFKA-6146; minimize the number of triggers enqueuing PreferredReplicaLeaderElection eventsWe currently enqueue a PreferredReplicaLeaderElection controller event in PreferredReplicaElectionHandler's handleCreation, handleDeletion, and handleDataChange. We can just enqueue the event upon znode creation and after preferred replica leader election completes. The processing of this latter enqueue will register the exist watch on PreferredReplicaElectionZNode and perform any pending preferred replica leader election that may have occurred between completion and registration.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4189 from onurkaraman/KAFKA-6146",2
"KAFKA-6378: For KStream-GlobalKTable joins let null KeyValueMapper results indicate no match (#4494)Reviewers: Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5325; Avoid and handle exceptions for Kerberos re-loginIf producer creates a connection during Kerberos re-login (after logout,before login), there are no principals in the subject and`SaslClientAuthenticator.configure` may throw an exception while tryingto determine the principal. A socket channel is created and its keyregistered with the selector, but the `RuntimeException` thrown leavesthe key registered with the selector without adding the channel to thechannel list. This results in an infinite loop of `NullPointerExceptions`.The PR applies two fixes:1. Convert the `RuntimeException` to a meaningful `KafkaException`2. Handle any exception in `buildChannel`, cleanup and throw `IOException`.Retries will take care of re-connections.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3208 from rajinisivaram/KAFKA-5325",5
MINOR: Add missing licenses and update versions in LICENSE-binary for 3.0 (#11232)One new dependency was missing a license entry ([jline](https://github.com/jline/jline3))The rest of the changes correspond to updated package versions. No functional changes in the code Reviewers: Randall Hauch <rhauch@gmail.com>,4
"MINOR: Fix newly added client side timeout tests in `KafkaAdminClientTest` (#10398)This patch fixes a race condition between the background thread calling `ready` and the call to `MockTime.sleep` in the test. If the call to `sleep` happens first, then the test hangs. I fixed it by giving `MockClient` a way to listen to `ready` calls. This combined with a latch fixes the race. This patch also fixes a similar race condition in `testClientSideTimeoutAfterFailureToReceiveResponse`. After the disconnect, there is a race between the background thread sending the retry request and the foreground sleeping for the needed backoff delay.Reviewers: Guozhang Wang <wangguoz@gmail.com>, David Arthur <mumrah@gmail.com>",1
"KAFKA-6526: Enable unclean leader election without controller change (#4920)Enable dynamic update of default unclean leader election config of brokers. A new controller event has been added to process unclean leader election when the config is enabled dynamically.Reviewers: Dong Lin <lindong28@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",0
KAFKA-569 Split up utils package and do some cleanup. Patch reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397765 13f79535-47bb-0310-9956-ffa450edef68,4
"fix: make sliding window works without grace period (#kafka-13739) (#11928)Fix upperbound for sliding window, making it compatible with no grace period (kafka-13739)Added unit test for early sliding window and ""normal"" sliding window for both events within one time difference (small input) and above window time difference (large input).Fixing this window interval may slightly change stream behavior but probability to happen is extremely slow and may not have a huge impact on the result given.Reviewers Leah Thomas <lthomas@confluent.io>, Bill Bejeck <bbejeck@apache.org>",5
KAFKA-2684; Add force option to topic / config command so they can be called programaticallyTiny change to add a force option to the topic and config commands so they can be called programatically without requiring user input.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #351 from benstopford/CPKAFKA-61B,1
KAFKA-1008 Lock around unmap on windows.,5
KAFKA-6489; Fetcher.retrieveOffsetsByTimes() should batch the metadata fetch.Currently if users call KafkaConsumer.offsetsForTimes() with a large set of partitions. The consumer will add one topic at a time for the metadata refresh. We should add all the topics to the metadata topics and just do one metadata refresh instead.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4478 from becketqin/KAFKA-6849,5
"MINOR: fix incorrect GC log size with JDK9+ (#8800)Author: Xavier Léauté <xavier@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
"KAFKA-9801: Still trigger rebalance when static member joins in CompletingRebalance phase (#8405)Fix the direct cause of the observed issue on the client side: when heartbeat getting errors and resetting generation, we only need to set it to UNJOINED when it was not already in REBALANCING; otherwise, the join-group handler would throw the retriable UnjoinedGroupException to force the consumer to re-send join group unnecessarily.Fix the root cause of the issue on the broker side: we should still trigger rebalance when static member joins in CompletingRebalance phase; otherwise the member.ids would be changed when the assignment is received from the leader, hence causing the new member.id's assignment to be empty.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-5746; Document new broker metrics added for health checksAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4026 from rajinisivaram/MINOR-KIP-188-metrics-docs,5
"KAFKA-695 Broker shuts down due to attempt to read a closed index file;reviewed by Neha Narkhede, Jay Kreps",2
Minor: added description for lag in consumer group commandAuthor: Kaufman Ng <kaufman@confluent.io>Reviewers: Gwen ShapiraCloses #1320 from coughman/trunk,1
"KAFKA-9849: Fix issue with worker.unsync.backoff.ms creating zombie workers when incremental cooperative rebalancing is used (#8827)When Incremental Cooperative Rebalancing is enabled and a worker fails to read to the end of the config topic, it needs to voluntarily revoke its locally running tasks on time, before these tasks get assigned to another worker, creating a situation where redundant tasks are running in the Connect cluster. Additionally, instead of using the delay `worker.unsync.backoff.ms` that was defined for the eager rebalancing protocol and has a long default value (which coincidentally is equal to the default value of the rebalance delay of the incremental cooperative protocol), the worker should quickly attempt to re-read the config topic and backoff for a fraction of the rebalance delay. After this fix, the worker will retry for a maximum time of 5 times before it revokes its running assignment and for a cumulative delay less than the configured `scheduled.rebalance.max.delay.ms`.Unit tests are added to cover the backoff logic with incremental cooperative rebalancing. Reviewers: Randall Hauch <rhauch@gmail.com>",2
"MINOR: Initialize BrokerTopicMetrics with no topic tag greedily (#7198)This patch fixes the quota system test whose JMX tool relies on the existenceof these metrics.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Nikhil Bhatia <nikhil@confluent.io>, Tu V. Tran <tuvtran97@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: update Kafka Streams standby task config (#11404)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Antony Stubbs <antony@confluent.io>, James Galasyn <jim.galasyn@confluent.io>",5
KAFKA-2798: Use prefixedd configurations for Kafka Connect producer and consumer settings so they do not conflict with the distributed herder's settings.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #486 from ewencp/kafka-2798-conflicting-herder-producer-consumer-configs,5
"MINOR: Add description of how consumer wakeup acts if no threads are awakenedI think the Javadoc should describe what happens if wakeup is called and no other thread is currently blocking. This may be important in some cases, e.g. trying to shut down a poll thread, followed by manually committing offsets.Author: Stig Rohde Døssing <sdo@it-minds.dk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2093 from srdo/minor-expand-wakeup-javadoc",2
"KAFKA-13276: Prefer KafkaFuture in admin Result constructors (#11301)Avoid using the non-public API KafkaFutureImpl in the Admin client's `*Result` class constructors.This is particularly problematic for `DescribeConsumerGroupsResult` which currently has apublic constructor.  For the other classes the rationale is simply consistency with the majority ofthe `*Result` classes.Reviewers: Ismael Juma <ismael@juma.me.uk, David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
trivial change: revert incorrect change to ssl.key.password,4
"KAFKA-9919: Add logging to KafkaBasedLog::readToLogEnd (#8554)Simple logging additions at TRACE level that should help when the worker can't get caught up to the end of an internal topic.Reviewers: Gwen Shapira <cshapi@gmail.com>, Aakash Shah <ashah@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
KAFKA-3920: Add Schema source connector to Kafka ConnectAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1574 from Ishiihara/schema-source,5
"KAFKA-5182; Close txn coordinator threads during broker shutdownShutdown delayed delete purgatory thread, transaction marker purgatory thread andsend thread in `TransactionMarkerChannelManager` during broker shutdown.Made `InterBrokerSendThread` interruptible so that it is shutdown.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3014 from rajinisivaram/KAFKA-5182",5
"MINOR: Do not falsely log that partitions are being reassigned on controller startup (#7431)Previously we would log the following on each controller startup:```[2019-09-13 22:40:10,272] INFO [Controller id=2] DEPRECATED: Partitions being reassigned through ZooKeeper: Map()```This patch only logs the message if the map is non-empty.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: set batch-size option into batch.size config in consoleProducer (#11855)Reviewers: Luke Chen <showuon@gmail.com>,5
"KAFKA-7019; Make reading metadata lock-free by maintaining an atomically-updated read snapshotAuthor: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <github@juma.me.uk>, Dong Lin <lindong28@gmail.com>Closes #5221 from radai-rosenblatt/metadata-adventures",5
"KAFKA-541 Move to metrics csv reporter for system tests; patched by Yang Ye; reviewed by Neha, Jun and Joelgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401138 13f79535-47bb-0310-9956-ffa450edef68",3
KAFKA-43 Move leader to preferred replica; patched by Neha Narkhede; reviewed by Joel Koshy and Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397747 13f79535-47bb-0310-9956-ffa450edef68,4
"KAFKA-7097 VerifiableProducer does not work properly with --message-create-time argument (#5292)Currently create time is interpreted as integer.This PR makes the tool accept long values.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-2931: add system test for consumer rolling upgradesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #619 from hachikuji/KAFKA-2931",5
MINOR; Fix UpdateMetadataRequestTest.testVersionLogic's assertions (#9462)UpdateMetadataRequestTest.testVersionLogic's assertions must verify the deserialized request instead of the original one.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
KAFKA-2504: Stop logging WARN when client disconnectsAuthor: jholoman <jeff.holoman@gmail.com>Reviewers: Gwen ShapiraCloses #211 from jholoman/KAFKA-2504,2
"KAFKA-2571; KafkaLog4jAppender dies while specifying acks configAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #231 from SinghAsDev/KAFKA-2571",5
"KAFKA-7798: Expose embedded clientIds (#6107)Reviewers: Damian Guy <damian@confluent.io>, John Roesler <john@confluent.io>, Boyang Chen <bchen11@outlook.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Use service loader for ConfigProvider impls (KIP-297)This is a small change to use the Java ServiceLoader to load ConfigProvider plugins.  It uses code added by mageshn for Connect Rest Extensions.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5141 from rayokota/service-loader-for-config-plugins",5
"KAFKA-13421; Reenable `testRollingBrokerRestartsWithSmallerMaxGroupSizeConfigDisruptsBigGroup` (#11485)This test was disabled in https://github.com/apache/kafka/commit/af8100b94fda4a27511797233e9845078ae8a69f. The reason the test was failing is that it assumes that the reference to `servers` can be mutated directly. The implementation in `IntegrationTestHarness` is intended to allow this by returning a mutable buffer, but the implementation actually returns a copy of the underlying collection. This caused the test case to create multiple `KafkaServer` instances instead of one as intended because it was modifying the copy. This led to the broker registration failure.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-8066; Always close the sensors in Selector.close() (#6402)When shutting down the ReplicaFetcher thread, we may fail to unregister sensors in selector.close(). When that happened, we will fail to start up the ReplicaFetcherThread with the same fetch id again because of the IllegalArgumentException in sensor registration. This issue will cause constant URPs in the cluster because the ReplicaFetchterThread is gone.This patch addresses this issue by introducing a try-finally block in selector.close() so that we will always unregister the sensors in shutting down ReplicaFetcherThreads.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix code example reference to SchemaBuilder call in Connect's documentation (#3029)Simple doc fix in a code snippet in connect.htmlCo-authored-by: Scott Ferguson <smferguson@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-6456; JavaDoc clarification for Connect SourceTask#poll() (#4432)Making clear that implementations of poll() shouldn't block indefinitely in order to allow the task instance to transition to PAUSED state.Reviewers:  Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Fix order of compression algorithms in upgrade noteAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>Closes #1373 from ijuma/fix-producer-buffer-size-upgrade-note",0
KAFKA-13963: Clarified TopologyDescription JavaDoc for Processors API forward() calls (#12293)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-3896: Fix KStream-KStream leftJoin in RepartitionIntegrationTestThe issue of transiently having duplicates is due to the bad design of the left join itself: in order to ignore the partial joined results such as `A:null`, it lets the producer to potentially send twice to source stream one and rely on all the following conditions to be true in order to pass the test:1. `receiveMessages` happen to have fetched all the produced results and have committed offsets.2. streams app happen to have completed sending all result data.3. consumer used in `receiveMessages` will complete getting all messages in a single poll().If any of the above is not true, the test fails.Fixed this test to add a filter right after left join to filter out partial joined results. Minor cleanup on integration test utils.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Ewen Cheslack-PostavaCloses #2485 from guozhangwang/K3896-duplicate-join-results",3
"MINOR: Fix Vagrant setup script for use on FedoraI tested and verified that `vagrant --version | egrep -o ""\d+\.\d+\.\d+""` works on Mac but failed on RedHad 6.4, while `vagrant --version | egrep -o ""[0-9]\.[0-9]\.[0-9]""` works on both OS.Author: Dong Lin <lindong28@gmail.com>Reviewers: Geoff Anderson, Guozhang WangCloses #246 from lindong28/Vagrant-setup-on-Fedora",1
"KAFKA-5931; deprecate KTable#through and KTable#toAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3903 from dguy/deprectate-to-through",5
"KAFKA-4157; Transient system test failure in replica_verification_test.test_replica_lags…t.test_replica_lagsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ashish Singh <asingh@cloudera.com>, Ismael Juma <ismael@juma.me.uk>Closes #1849 from granthenke/replica-verification-fix",0
"KAFKA-6074; Use ZookeeperClient in ReplicaManager and PartitionReplaced ZkUtils with KafkaZkClient in ReplicaManager and Partition.Relying on existing tests.Author: tedyu <yuzhihong@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4254 from tedyu/trunk",1
"MINOR: Use log start offset as high watermark if current value is out of range (#4722)Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Add ability to wait for all instances in an application to be RUNNING (#7500)Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-6363: Use MockAdminClient for any unit tests that depend on AdminClient (#4371)* Implement MockAdminClient.deleteTopics* Use MockAdminClient instead of MockKafkaAdminClientEnv in StreamsResetterTest* Rename MockKafkaAdminClientEnv to AdminClientUnitTestEnv* Use MockAdminClient instead of MockKafkaAdminClientEnv in TopicAdminTest* Rename KafkaAdminClient to AdminClientUnitTestEnv in KafkaAdminClientTest.java* Migrate StreamThreadTest to MockAdminClient* Fix style errors* Address review comments* Fix MockAdminClient callReviewers: Matthias J. Sax <matthias@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-2272; listeners endpoint parsing fails if the hostname has capital letter; patched by Sriharsha Chintalapani; reviewed by Jun Rao,0
MINOR: Replaced unnecessary map and getOrElse with existsAuthor: himani1 <1himani.arora@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2035 from himani1/code_refactored,4
MINOR: Improve logging around initial log loading (#8970)Users often get confused after an unclean shutdown when log recovery takes a long time. This patch attempts to make the logging clearer and provide a simple indication of loading progress.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-2683: ensure wakeup exceptions raised to userAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava, Guozhang WangCloses #366 from hachikuji/KAFKA-2683",5
close TopologyTestDriver to release resources (#11143)Close TopologyTestDriver to release resourcesReviewers: Bill Bejeck <bbejeck@apache.org>,3
KAFKA-4956: Verify client-side throttle time metrics in quota testAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3190 from rajinisivaram/KAFKA-4956-unittest,5
MINOR: Improved configuration formatting in documentation (#5532)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-6261; Fix exception thrown by request logging if acks=0Only expect responseAsString to be set if request logging isenabled _and_ responseSend is defined.Also fixed a couple of issues that would manifest themselvesif trace logging is enabled:- `MemoryRecords.toString` should not throw exception if data is corrupted- Generate `responseString` correctly if unsupported api versions request isreceived.Unit tests were added for every issue fixed. Also changedSocketServerTest to run with trace logging enabled asrequest logging breakage has been a common issue.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4250 from ijuma/fix-issues-when-trace-logging-is-enabled,2
"MINOR: move NoOpSnapshotWriter to main (#10496)Move NoOpSnapshotWriter and NoOpSnapshotWriterBuilder out of the testdirectory and into the main directory, until we implement the KRaftintegration.Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
KAFKA-13888; Implement `LastFetchTimestamp` and  in `LastCaughtUpTimestamp` for DescribeQuorumResponse [KIP-836] (#12508)This commit implements the newly added fields `LastFetchTimestamp` and `LastCaughtUpTimestamp` for KIP-836: https://cwiki.apache.org/confluence/display/KAFKA/KIP-836:+Addition+of+Information+in+DescribeQuorumResponse+about+Voter+Lag.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-858 High watermark values can be overwritten during controlled shutdown; reviewed by Jun Rao,5
MINOR: reuse pseudo-topic in FKJoin (#8296)Reuse the same pseudo-topic for serializing the LHS value in the foreign-key join resolver aswe originally used to serialize it before sending the subscription request.Reviewers: Boyang Chen <boyang@confluent.io>,5
closes pr #206. *WONT FIX* - no new release planned for 0.8.2 branch,1
"MINOR: Fix javadoc typos in KStream#processinterface for `Processor` in comments incorrectly had `transform` rather than `process`.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Ismael Juma <ismael@juma.me.uk>Closes #2396 from dguy/minor-javadoc",2
Consumer doesn't receive all data; patched by Jun Rao; reviewed by John Fung; KAFKA-372git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1354094 13f79535-47bb-0310-9956-ffa450edef68,5
"MINOR: Improve the help doc of consumer group commandClarify the consumer group command help message around `zookeeper`, `bootstrap-server`, and `new-consumer` options.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2046 from vahidhashemian/minor/improve_consumer_group_command_doc",2
KAFKA-4098: NetworkClient should not intercept user metdata requests on disconnectAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1798 from hachikuji/KAFKA-4098,5
"KAFKA-13730: OAuth access token validation fails if it does not contain the ""sub"" claim (#11886)Removes the requirement of presence of sub claim in JWT access tokens, when clients authenticate via OAuth.This does not interfere with OAuth specifications and is to ensure wider compatibility with OAuth providers.Unit test added.Reviewers:  Kirk True <ktrue@confluent.io>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",5
"MINOR: MessageUtil: remove some deadcode (#9931)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",4
MINOR: remove unused imports in Streams system tests (#7468)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-7477: Improve Streams close timeout semantics (#5747)Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-12619; Raft leader should expose hw only after committing LeaderChange (#10481)KIP-595 describes an extra condition on commitment here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum#KIP595:ARaftProtocolfortheMetadataQuorum-Fetch. In order to ensure that a newly elected leader's committed entries cannot get lost, it must commit one record from its own epoch. This guarantees that its latest entry is larger (in terms of epoch/offset) than any previously written record which ensures that any future leader must also include it. This is the purpose of the `LeaderChange` record which is written to the log as soon as the leader gets elected.Although we had this check implemented, it was off by one. We only ensured that replication reached the epoch start offset, which does not reflect the appended `LeaderChange` record. This patch fixes the check and clarifies the point of the check. The rest of the patch is just fixing up test cases.Reviewers: dengziming <swzmdeng@163.com>, Guozhang Wang <wangguoz@gmail.com>",3
Fix wrong property mentioned in doc; Author: Praveen K Palaniswamy <yourspraveen@gmail.com>,2
"MINOR: Update dependencies for 1.0.0 releaseNotable updates:1. Gradle 4.1 includes a number of performance andCLI improvements as well as initial Java 9 support.2. Scala 2.12.3 has substantial compilation timeimprovements.3. lz4-java 1.4 allows us to remove a workaround inKafkaLZ4BlockInputStream (not done in this PR).4. snappy-java 1.1.4 improved performance of compression (5%)and decompression (20%). There was a slight increase in thecompressed size in one of our tests.Not updated:1. PowerMock due to a couple of regressions. I investigated one of themand filed https://github.com/powermock/powermock/issues/828.2. Jackson, which will be done via #3631.3. Rocksdb, which will be done via #3519.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3619 from ijuma/update-deps-for-1.0.0",5
"MINOR: (re)add equals/hashCode to *Windows (#5510)Andy Coates <big-andy-coates@users.noreply.github.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4817; Add idempotent producer semanticsThis is from the KIP-98 proposal.The main points of discussion surround the correctness logic, particularly the Log class where incoming entries are validated and duplicates are dropped, and also the producer error handling to ensure that the semantics are sound from the users point of view.There is some subtlety in the idempotent producer semantics. This patch only guarantees idempotent production upto the point where an error has to be returned to the user. Once we hit a such a non-recoverable error, we can no longer guarantee message ordering nor idempotence without additional logic at the application level.In particular, if an application wants guaranteed message order without duplicates, then it needs to do the following in the error callback:1. Close the producer so that no queued batches are sent. This is important for guaranteeing ordering.2. Read the tail of the log to inspect the last message committed. This is important for avoiding duplicates.Author: Apurva Mehta <apurva@confluent.io>Author: hachikuji <jason@confluent.io>Author: Apurva Mehta <apurva.1618@gmail.com>Author: Guozhang Wang <wangguoz@gmail.com>Author: fpj <fpj@apache.org>Author: Jason Gustafson <jason@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2735 from apurvam/exactly-once-idempotent-producer",5
"MINOR: Reconcile differences in .bat & .sh start scriptsA few minor fixes to reconcile differences between the windows and unix versions of the kafka/zookeeper start scripts that were causing cross-platform inconsistencies during deployment.- Resolve differences in CLASSPATH setup between .bat and .sh start scripts- .bat start scripts honor externally provided KAFKA_HEAP_OPTS and KAFKA_LOG4J_OPTS consistent with .sh- .bat start scripts configure log4j similar to .shAuthor: Matt Fluet <matt.fluet@appian.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #908 from fluetm/scripts-patch",5
"HOTFIX: fix broken trunk due to conflicting and overlapping commits (#12074)Reviewers: Victoria Xia <victoria.xia@confluent.io>, David Arthur <mumrah@gmail.com>",5
KAFKA-5020; Update message format in implementation docsAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3360 from apurvam/KAFKA-5020-message-format-docs-update,5
"KAFKA-4724: Clean up of state directories can possibly remove stores that are about to be used by another threadDelay the cleanup of state directories that are not locked and not owned by the current thread such that we only remove the directory if its last modified is < now - cleanupDelayMs.This also helps to avoid a race between threads on the same instance, where during rebalance, one thread releases the lock on the state directory, and before another thread can take the lock, the cleanup runs and removes the data.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2486 from dguy/KAFKA-4724",5
"KAFKA-10692: Add delegation.token.secret.key, deprecate ...master.key (#9623)Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
"KAFKA-2507 KAFKA-2959; Remove legacy ControlledShutdown request/response objectsThis patch replaces the legacy ControlledShutdown objects in `kafka.api` with the alternatives in `org.apache.kafka.common.requests`. Since this was the last API that needed updating, we have also dropped the reference in `RequestChannel.Request` to the legacy object type.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3612 from hachikuji/remove-old-controlled-shutdown-objects",4
"MINOR: enable KRaft mode in CreateTopicsRequestTest (#11629)Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>",5
"MINOR: clean up unused checkstyle suppressions for Streams (#8861)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Expose ReplicaManager gaugesThere are several gauges in core that are registered but cannot be accessed programmatically. For example, gauges ""LeaderCount"", ""PartitionCount"", ""UnderReplicatedParittions"" are all registered in ReplicaManager.scala but there is no way to access them programmatically if one has access to the kafka.server object. Other metrics,  such as isrExpandRate (also in ReplicaManager.scala) can be accessed. The solution here is trivial, add a var <variable name> in front of newGauge, as shown belowval partitionCount newGauge(     ""PartitionCount"",     new Gauge[Int] {       def value = allPartitions.size     })Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #364 from enothereska/gauges",1
KAFKA-802 Flush message interval is based on compressed message count; reviewed by Jun Rao,5
MINOR: Fix FetchSessionBenchmark (#11501)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-7875: Add KStream.flatTransformValues (#6424)Adds flatTrasformValues methods in KStreamAdds processor supplier and processor for flatTransformValuesImproves API documentation of transformValuesReviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-9218: MirrorMaker 2 can fail to create topics (#7745)When the scheduled refreshTopicPartitions runs, check existing topics inboth source and target clusters in order to compute topic partitions tobe created on target.If a temporary failure to create the target topic is encountered (e.g.insufficient number of brokers), on the next refresh the target topiccreation will be re-attempted.Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Mickael Maison <mickael.maison@uk.ibm.com>Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
reverting previous commit for KAFKA-296 because patch didn't apply cleanlygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1300801 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: remove FetchResponse.AbortedTransaction and redundant construc… (#9758)1. rename INVALID_HIGHWATERMARK to INVALID_HIGH_WATERMARK2. replace FetchResponse.AbortedTransaction by FetchResponseData.AbortedTransaction3. remove redundant constructors from FetchResponse.PartitionData4. rename recordSet to records5. add helpers ""recordsOrFail"" and ""recordsSize"" to FetchResponse to process record castingReviewers: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-2618; Disable SSL renegotiation for 0.9.0.0Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>Closes #339 from ijuma/kafka-2618-disable-renegotiation",5
"MINOR: Build and code sample updates for Kafka Streams DSL for Scala (#4949)Several build and documentation updates were required after the merge of KAFKA-6670: Implement a Scala wrapper library for Kafka Streams.Encode Scala major version into streams-scala artifacts.To differentiate versions of the kafka-streams-scala artifact across Scala major versions it's required to encode the version into the artifact name before its published to a maven repository. This is accomplished by following a similar release process as kafka core, which encodes the Scala major version and then runs the build for each major version of Scala supported. This is considered standard practice when releasing Scala libraries, but is not handled for us automatically with the basic Scala for Gradle support.After this change you can generate and install the kafka-streams-scala artifact into the local maven repository:$ ./gradlew -PscalaVersion=2.11 install$ ./gradlew -PscalaVersion=2.12 installReviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",4
"KAFKA-8594: Add version 2.3 to Streams system tests (#7131)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"TRIVIAL: Fix type inconsistencies, unthrown exceptions, etc (#10678)Reviewers: Ismael Juma <ismael@juma.me.uk>, Bruno Cadonna <cadonna@apache.org>",1
"MINOR: Improve Log layer segment iteration logic and few other areas (#10684)In Log.collectAbortedTransactions() I've restored a previously used logic, such that it would handle the case where the starting segment could be null. This was the case previously, but the PR #10401 accidentally changed the behavior causing the code to assume that the starting segment won't be null.In Log.rebuildProducerState() I've removed usage of the allSegments local variable. The logic looks a bit simpler after I removed it.I've introduced a new LogSegments.higherSegments() API. This is now used to make the logic a bit more readable in Log. collectAbortedTransactions() and Log.deletableSegments() APIs.I've removed the unnecessary use of java.lang.Long in LogSegments class' segments map definition.I've converted a few LogSegments API from public to private, as they need not be public.Reviewers: Ismael Juma <ismael@juma.me.uk>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",2
"KAFKA-13785: [10/N][emit final] more unit test for session store and disable cache for emit final sliding window (#12370)1. Added more unit test for RocksDBTimeOrderedSessionStore and RocksDBTimeOrderedSessionSegmentedBytesStore2. Disable cache for sliding window if emit strategy is ON_WINDOW_CLOSEReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12250; Add metadata record serde for KIP-631 (#9998)This patch adds a `RecordSerde` implementation for the metadata record format expected by KIP-631. Reviewers: Colin McCabe <cmccabe@apache.org>, Ismael Juma <mlists@juma.me.uk>",5
MINOR: temporarily ignore system test until I can fix it (#5283),0
MINOR: Add upgrade note about TLSv1 and TLSv1.1 being disabled in 2.5.0 (#8128)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
"KAFKA-7399: KIP-366, Make FunctionConversions deprecated (#5562)Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-10193: Add preemption for controller events that have callbacksJIRA: https://issues.apache.org/jira/browse/KAFKA-10193* add `preempt(): Unit` method for all `ControllerEvent` so that all events (and future events) must implement it* for events that have callbacks, move the preemption from individual methods to `preempt()`* add preemption for `ApiPartitionReassignment` and `ListPartitionReassignments`* add integration tests:1. test whether `preempt()` is called when controller shuts down2. test whether the events with callbacks have the correct error response (`NOT_CONTROLLER`)* explicit typing for `ControllerEvent` methodsAuthor: jeff kim <jeff.kim@confluent.io>Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,Stanislav Kozlovski <stanislav@confluent.io>, David Arthur <mumrah@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9050 from jeffkbkim/KAFKA-10193-controller-events-add-preemption",1
MINOR: move some client methods to new ClientUtils (#8328)* move to new ClientUtils* checkstyle* fix KafkaStreamsTest* checkstyle again,3
"HOTFIX: Persistent store in ProcessorStateManagerTestymatsuda junrao Could you take a quick look? The current unit test is failing on this.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma, Jun RaoCloses #276 from guozhangwang/HF-ProcessorStateManager",0
"KAFKA-3639; Configure default serdes upon constructionAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1311 from guozhangwang/K3639",5
"MINOR: StreamThread standbyTask comment typolog info typos. should be standby task, not active task.Author: zqhxuyuan <qihuang.zheng@fraudmetrix.cn>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #3362 from zqhxuyuan/trunk",1
"KAFKA-5229: Reflections logs excessive warnings when scanning classpathschanged the reflections log level to ERROR.And tested it, now the warning logs are not shown up during the start of Kafka connect.ewencp could you please review the changes.Author: Bharat Viswanadham <bharatv@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3072 from bharatviswa504/KAFKA-5229",5
"MINOR: A few small group coordinator cleanups (#9952)A few small cleanups in `GroupCoordinator` and related classes:- Remove redundant `groupId` field from `MemberMetadata`- Remove redundant `isStaticMember` field from `MemberMetadata`- Fix broken log message in `GroupMetadata.loadGroup` and apply it to all loaded members- Remove ancient TODOs and no-op methods from `GroupCoordinator`- Move removal of static members into `GroupMetadata.remove`Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-2613; Make maxParallelForks configurable via Gradle config so it can be turned down on shared build infrastructure.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma, Sriharsha ChintalapaniCloses #293 from ewencp/kafka-2613-user-configurable-max-forks",5
MINOR: Add last modified time and deletion horizon to clear log message (#7357)It's useful to know when the cleaner runs what the last modified timeof the segment and the deletion horizon is. The current log messageonly allows you to infer that one is greater than the other.Reviewers: Jun Rao <junrao@gmail.com>,5
kafka-2113; TestPurgatoryPerformance does not compile using IBM JDK; patched by Rajini Sivaram; reviewed by Yasuhiro Matsuda and Jun Rao,5
"KAFKA-7396: Materialized, Serialized, Joined, Consumed and Produced with implicit Serdes (#5551)We want to make sure that we always have a serde for all Materialized, Serialized, Joined, Consumed and Produced.For that we can make use of the implicit parameters in Scala.KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-365%3A+Materialized%2C+Serialized%2C+Joined%2C+Consumed+and+Produced+with+implicit+SerdeReviewers: John Roesler <vvcephei@users.noreply.github.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>",5
"KAFKA-1888: rolling upgrade testewencp gwenshapThis needs some refactoring to avoid the duplicated code between replication test and upgrade test, but in shape for initial feedback.I'm interested in feedback on the added `KafkaConfig` class and `kafka_props` file. This addition makes it:- easier to attach different configs to different nodes (e.g. during broker upgrade process)- easier to reason about the configuration of a particular nodeNotes:- in the default values in the KafkaConfig class, I removed many properties which were in kafka.properties before. This is because most of those properties were set to what is already the default value.- when running non-trunk VerifiableProducer, I append the trunk tools jar to the classpath, and run it with the non-trunk kafka-run-class.sh scriptAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Dong Lin, Ewen Cheslack-PostavaCloses #229 from granders/KAFKA-1888-upgrade-test",3
Fixing KAFKA-10094 (#8797),0
KAFKA-9423: Refine layout of configuration options on website and make individual settings directly linkable (#7955)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"MINOR: Start using Response and replace IOException in EmbeddedConnectCluster for failures (#8055)Changed `EmbeddedConnectCluster` to add utility methods that return `Response`, throw `ConnectException` instead of `IOException` for failures, and deprecate the old methods that returned primitive types rather than `Response`. Also introduce common assertions for embedded clusters under `EmbeddedConnectClusterAssertions`.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-1925; Fix coordinator broker id stuck with INT_MIN; reviewed by Jay Kreps,0
MINOR: update the memberMetadata#toString output (#10166)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-12482 Remove deprecated rest.host.name and rest.port configs (#10841)Remove the `rest.host.name` and `rest.port` Connect worker configs that were deprecated in KIP-208 and AK 1.1.Author: Kalpesh Patel <kalpeshpatel.india@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, wenbingshen <oliver.shen999@gmail.com>",5
"MINOR: KafkaBroker.brokerState should be volatile instead of AtomicReference (#10080)We don't need or use the additional functionality provided byAtomicReference.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",1
"MINOR: Fix race condition in KafkaConsumer closeWe intended to make `KafkaConsumer.close()` idempotent,but due to the fact that the `closed` variable ischecked without a lock prior to beginning close logic,it is possible for two or more threads to see`closed=false` and attempt to close.Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3426 from hachikuji/minor-fix-consumer-idempotent-close",0
"MINOR: Fix bug introduced by adding batch.size without default in FileStreamSourceConnector (#4579)https://github.com/apache/kafka/pull/4356 added `batch.size` config property to `FileStreamSourceConnector` but the property was added as required without a default in config definition (`ConfigDef`). This results in validation error during connector startup. Unit tests were added for both `FileStreamSourceConnector` and `FileStreamSinkConnector` to avoid such issues in the future.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6950: Delay response to failed client authentication to prevent potential DoS issues (KIP-306) (#5082)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5638; Improve the Required ACL of ListGroups API (KIP-231) (#5352)Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Remove redundant SuppressIntegrationTests (#5896)The removed tests have counterparts covered by SuppressScenarioTest using the TopologyTestDriver.This will speed up the build and improve stability in the CPU-constrained Jenkins environment.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
trivial doc changes,4
trivial change to javadoc for makeLeaders(); patched by Lantao Jin,1
"KAFKA-7799; Use httpcomponents-client in RestServerTest.The test `org.apache.kafka.connect.runtime.rest.RestServerTest#testCORSEnabled` assumes Jersey client can send restricted HTTP headers(`Origin`).Jersey client uses `sun.net.www.protocol.http.HttpURLConnection`.`sun.net.www.protocol.http.HttpURLConnection` drops restricted headers(`Host`, `Keep-Alive`, `Origin`, etc) based on static property `allowRestrictedHeaders`.This property is initialized in a static block by reading Java system property `sun.net.http.allowRestrictedHeaders`.So, if classloader loads `HttpURLConnection` before we set `sun.net.http.allowRestrictedHeaders=true`, then all subsequent changes of this system property won't take any effect(which happens if `org.apache.kafka.connect.integration.ExampleConnectIntegrationTest` is executed before `RestServerTest`).To prevent this, we have to either make sure we set `sun.net.http.allowRestrictedHeaders=true` as early as possible or do not rely on this system property at all.This PR adds test dependency on `httpcomponents-client` which doesn't depend on `sun.net.http.allowRestrictedHeaders` system property. Thus none of existing tests should interfere with `RestServerTest`.Author: Alex Diachenko <sansanichfb@gmail.com>Reviewers: Randall Hauch, Konstantine Karantasis, Gwen ShapiraCloses #6236 from avocader/KAFKA-7799",3
Improve logging in the consumer for epoch updates (#6879),5
"KAFKA-10360: Allow disabling JMX Reporter (KIP-830) (#12046)This implements KIP-830: https://cwiki.apache.org/confluence/display/KAFKA/KIP-830%3A+Allow+disabling+JMX+ReporterIt adds a new configuration `auto.include.jmx.reporter` that can be set to false to disable the JMX Reporter. This configuration is deprecated and will be removed in the next major version.Reviewers: Tom Bentley <tbentley@redhat.com>, Christo Lolov <christo_lolov@yahoo.com>",4
KAFKA-13374: Update doc to mention read from leader/followers (#11408)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"KAFKA-6718: Update SubscriptionInfoData with clientTags (#10802)adds ClientTags to SubscriptionInfoDataReviewer: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-4379: Remove caching of dirty and removed keys from StoreChangeLoggerThe `StoreChangeLogger` currently keeps a cache of dirty and removed keys and will batch the changelog records such that we don't send a record for each update. However, with KIP-63 this is unnecessary as the batching and de-duping is done by the caching layer. Further, the `StoreChangeLogger` relies on `context.timestamp()` which is likely to be incorrect when caching is enabledAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2103 from dguy/store-change-logger",4
"KAFKA-12648: fix #add/removeNamedTopology blocking behavior when app is in CREATED (#11813)Currently the #add/removeNamedTopology APIs behave a little wonky when the application is still in CREATED. Since adding and removing topologies runs some validation steps there is valid reason to want to add or remove a topology on a dummy app that you don't plan to start, or a real app that you haven't started yet. But to actually check the results of the validation you need to call get() on the future, so we need to make sure that get() won't block forever in the case of no failure -- as is currently the caseReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"MINOR: Use time constant algorithms when comparing passwords or keys (#10978)Author: Randall Hauch <rhauch@gmail.com>Reviewers: Manikumar Reddy <manikumar@confluent.io>, Rajini Sivaram <rajinisivaram@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ijuma@apache.org>",5
KAFKA-12267; Implement `DescribeTransactions` API (#10183)This patch implements the `DescribeTransactions` API as documented in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. This is only the server-side implementation and does not contain the `Admin` API.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
MINOR: reduce verbosity of cache flushesThis log message tends to be extremely verbose when state stores are being restoredAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2412 from xvrl/reduce-verbosity,5
KAFKA-4166; Fix transient MM failure caused by slow old consumer shutdownAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2279 from hachikuji/KAFKA-4166,5
MINOR: Exclude junit 3 transitive dependency from jfreechart (#9928)This was causing IntelliJ to choose the Vintage runner when running `core` testswhich would then fail during the discovery phase.Verified that `core` tests work in IntelliJ again after this change.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
MINOR: Implement toString() in config validator classes (#5401),5
"KAFKA-3742: (FIX) Can't run bin/connect-*.sh with -daemon flag## ProblemCurrent connect scripts (`connect-distributed.sh`, `connect-standalone.sh`) do not support `-daemon` flag even if users specify the flagsince `kafka-run-class.sh` requires that the`-daemon` flag should precede other arguments (e.g. class name)## SolutionDo the same thing like in `kafka-server-start.sh`- Parse a command- Add `-daemon` to `$EXTRA_ARGS` if existsAuthor: 1ambda <1amb4a@gmail.com>Reviewers: Gwen ShapiraCloses #1717 from 1ambda/KAFKA-3742-connect-running-as-daemon",1
"KAFKA-6993: Fix defective documentations for KStream/KTable methods (#5136)* KAFKA-6993: Fix defective documentations for KStream/KTable methods1. Fix the documentation of following methods, e.g., making more detailed description for the overloaded methods:- KStream#join- KStream#leftJoin- KStream#outerJoin- KTable#filter- KTable#filterNot- KTable#mapValues- KTable#transformValues- KTable#join- KTable#leftJoin- KTable#outerJoin2. (trivial) with possible new type -> with possibly new type.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
MINOR: Replace unused variables by underscore (#5003)And remove one unused expression.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"MINOR: update JavaDocs for Kafka Streams DSL helpers - also deprecate ZK config for StreamsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #2459 from mjsax/javaDocImprovements8",2
"KAFKA-9474: Adds 'float64' to the RPC protocol types (#8012)Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-4209; Reduce run time for quota integration testsRun quota tests which expect throttling only until the first produce/consume request is throttled.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1902 from rajinisivaram/KAFKA-4209,5
"KAFKA-5922: Add SessionWindowedKStreamAdd `SessionWindowedKStream` and implementation. Deprecate existing `SessionWindow` `aggregate` methods on `KGroupedStream`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3902 from dguy/kafka-5922",5
"KAFKA-5371; Increase request timeout for producer used by testReachableServer500ms is low for a shared Jenkins environment.Also removed the try/catch blocks that simply obscuredthe underlying error.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3225 from ijuma/kafka-5371-flaky-testReachableServer",3
"KAFKA-6863 Kafka clients should try to use multiple DNS resolved IP (#4987)Implementation of KIP-302: Based on the new client configuration `client.dns.lookup`, a NetworkClient can use InetAddress.getAllByName to find all IPs and iterate over them when they fail to connect. Only uses either IPv4 or IPv6 addresses similar to the default mode.Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-13071; Deprecate support for changing acls through the authorizer (#11502)This patch marks the following arguments as deprecated in kafka-acls.sh as documented in [KIP-604](https://cwiki.apache.org/confluence/display/KAFKA/KIP-604%3A+Remove+ZooKeeper+Flags+from+the+Administrative+Tools): --authorizer, --authorizer-properties, and --zk-tls-config-file.Reviewers: David Jacot <djacot@confluent.io>",5
MINOR: cleanTest ought to remove output of unitTest task and integrat… (#10585)The command used by our private CI is ./gradlew cleanTest xxx:test. It does not re-run test when we use unitTest and integrationTest to replace test. The root cause is that we don't offer test output (unitTest and integrationTest) to cleanTest task and so it does not delete related test output.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-9198; Complete purgatory operations on receiving StopReplica (#7701)Force completion of delayed operations when receiving a StopReplica request. In the case of a partition reassignment, we cannot rely on receiving a LeaderAndIsr request in order to complete these operations because the leader may no longer be a replica. Previously when this happened, the delayed operations were left to eventually timeout. Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>Co-Authored-By: Kun Du <kidkun@users.noreply.github.com>",1
KAFKA-301 Implement broker startup procedure; patched by Neha Narkhede; reviewed by Jun Rao and Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1329509 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-3325: Out of date instructions in quickstart guideAdjust the listeners property rather than the port.  Following the original instructions would result in all of the brokers being started with the same listeners setting, and so fail to work.Author: Duncan Sands <baldrick@free.fr>Reviewers: Ismael Juma, Gwen ShapiraCloses #1002 from CunningBaldrick/quickstart",1
"KAFKA-12259: Use raw config to infer the connector type when returning a connector status response (#10040)Problem: when calling the connect status endpoint, a 500 error is returned, e.g.```{  ""error_code"": 500,  ""message"": ""Could not read properties from file /tmp/somefile.properties""}```when any of the connectors has an exception from the config provider. This is because the `AbstractHerder` is trying to use the resolved config to infer the type of the connector. However, only the `connector.class` is needed from the config to infer if a specific connector is of source or sink type. The endpoint should still return the status of the connector instead of a 500 error.This change uses the raw config from the config backing store to retrieve the connector class to avoid any variable resolution.Unit tests have been updated to reflect this change.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",4
kafka-1353;report capacity used by request thread pool and network thread pool; patched by Guozhang Wang; reviewed by Jun Rao,1
MINOR: Disable transactional/idempotent system tests for Raft quorums (#10224),3
"MINOR: Adjust logic of conditions to set number of partitions in step zero of assignment. (#7419)A minor change in logic to account for repartition topics where we might not have the num partitions yet in the metadata.Ran all existing tests plus all streams system tests.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"KAFKA-4791: unable to add state store with regex matched topicsFix for adding state stores with regex defined sourcesAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #2618 from bbejeck/KAFKA-4791_unable_to_add_statestore_regex_topics",3
KAFKA-9138: Add system test for relational joins (#7664)Add a system test to verify the new foreign-key join introduced in KIP-213Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-698 Avoid advancing the log end offset until the append has actually happened since reads may be happening in the meantime.,1
"KAFKA-7548; KafkaConsumer should not discard fetched data for paused partitions (#6988)This is an updated implementation of #5844 by @MayureshGharat (with Mayuresh's permission). As described in the original ticket:> Today when we call KafkaConsumer.poll(), it will fetch data from Kafka asynchronously and is put in to a local buffer (completedFetches).>> If now we pause some TopicPartitions and call KafkaConsumer.poll(), we might throw away any buffered data that we might have in the local buffer for these TopicPartitions. Generally, if an application is calling pause on some TopicPartitions, it is likely to resume those TopicPartitions in near future, which would require KafkaConsumer to re-issue a fetch for the same data that it had buffered earlier for these TopicPartitions. This is a wasted effort from the application's point of view.This patch fixes the problem by retaining the paused data in the completed fetches queue, essentially moving it to the back on each call to `fetchedRecords`. Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-8248; Ensure time updated before sending transactional request (#6613)This patch fixes a bug in the sending of transactional requests. We need to call `KafkaClient.send` with an updated current time. Failing to do so can result in an `IllegalStateExcepton` which leaves the producer effectively dead since the in-flight correlation id has been set, but no request has been sent. To avoid the same problem in the future, we update the in flight correlationId only after sending the request.Reviewers: Matthias J. Sax <matthias@confluent.io>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-3997; log partition name on truncationAuthor: Alexey Ozeritsky <aozeritsky@yandex-team.ru>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1724 from resetius/KAFKA-3997,1
"HOTFIX: fix potentially hanging test shouldAddStateStoreToRegexDefinedSource…dSourceAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2783 from bbejeck/HOTFIX_potentially_hanging_test_in_RegexSourceIntegrationTest",3
"MINOR: Add docs for StreamJoined changes (#9951)Add docs for KIP-689.Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-4012; Added #toString() to KerberosShortNamerAuthor: Bryan Baugher <bryan.baugher@cerner.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1694 from bbaugher/KAFKA-4012,1
"KAFKA-7755; Look up client host name since DNS entry may have changed (#6049)Lookup client host name after every full iteration through the addresses returned.Reviewers: Loïc Monney <loicmonney@github.com>, Edoardo Comar <ecomar@uk.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-9704: Fix the issue z/OS won't let us resize file when mmap. (#8224)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
MINOR: Set min isr to avoid race condition in ReplicationBytesIn initialisationAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3033 from ijuma/fix-transient-test-failure-in-test-broker-topic-metrics-bytes-in-out,3
KAFKA-3019: Add an exceptionName method to ErrorsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #754 from granthenke/exception-name,5
"KAFKA-4532: StateStores can be connected to the wrong source topic resulting in incorrect metadata returned from Interactive QueriesWhen building a topology with tables and StateStores, the StateStores are mapped to the source topic names. This map is retrieved via TopologyBuilder.stateStoreNameToSourceTopics() and is used in Interactive Queries to find the source topics and partitions when resolving the partitions that particular keys will be in.There is an issue where by this mapping for a table that is originally created with builder.table(""topic"", ""table"");, and then is subsequently used in a join, is changed to the internal repartition topic. This is because the mapping is updated during the call to topology.connectProcessorAndStateStores(..).In the case that the stateStoreNameToSourceTopics Map already has a value for the state store name it should not update the Map.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2250 from dguy/kafka-4532",5
Tool to watch consumer offsets and lag; patched by Joel Joshy; reviewed by Jun Rao; KAFKA-127git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1167405 13f79535-47bb-0310-9956-ffa450edef68,1
kafka-1801; Remove non-functional variable definition in log4j.properties; patched by Raman Gupta; reviewed by Jun Rao,2
"KAFKA-10262: Ensure that creating task directory is thread safe (#9010)Reviewers: A. Sophie Blee-Goldman <sohpie@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-6826 avoid range scans when forwarding values during aggregation (#4927)Reviewers: Matthias J Sax <matthias@confluentio>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-6145: KIP-441: Fix assignor config passthough (#8716)Also fixes a system test by configuring the HATA to perform a one-shot balanced assignmentReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>",5
"KAFKA-9818: improve error message to debug test (#8423)Reviewers: A. Sophie Blee Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-129 ZK-based producer can throw an unexpceted exception when sending a message; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178997 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12289: Adding test cases for prefix scan in InMemoryKeyValueStore (#10052)Co-authored-by: Bruno Cadonna <bruno@confluent.io>Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Follow-up minor improvements/cleanup for KAFKA-3396Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1946 from hachikuji/followup-for-kafka-3396,5
MINOR: Add upgrade notes for KAFKA-2358Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3200 from guozhangwang/KMinor-KAFKA-2358-upgrade-notes,1
KAFKA-2807: Move ThroughputThrottler back to tools jar to fix upgrade tests.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #499 from ewencp/kafka-2807-relocate-throughput-throttler,3
"KAFKA-8429; Handle offset change when OffsetForLeaderEpoch inflight (#6811)It is possible for the offset of a partition to be changed while we are in the middle of validation. If the OffsetForLeaderEpoch request is in-flight and the offset changes, we need to redo the validation after it returns. We had a check for this situation previously, but it was only checking if the current leader epoch had changed. This patch fixes this and moves the validation in `SubscriptionState` where it can be protected with a lock.Additionally, this patch adds test cases for the SubscriptionState validation API. We fix a small bug handling broker downgrades. Basically we should skip validation if the latest metadata does not include leader epoch information.Reviewers: David Arthur <mumrah@gmail.com>",5
KAFKA-5764; Add toLowerCase support to sasl.kerberos.principal.to.local rule (KIP-203)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3800 from omkreddy/KAFKA-5764-REGEX,5
"MINOR: Not enough replica exception should never happen for delete recordsWhen reviewing https://github.com/apache/kafka/pull/4132, I felt that NOT_ENOUGH_REPLICAS should never happen actually. Hence proposing to remove it from the listed error code as well in the broker-side capture clause.Testing added in 4132 should have been sufficient.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>Closes #4208 from guozhangwang/KMinor-delete-records-error-code",4
KAFKA-2298; Client Selector can drop connections on InvalidReceiveException without notifying NetworkClient; reviewed by Jason Gustafson and Joel Koshy,1
KAFKA-10199: Remove tasks from state updater on partition lost (#12521)Removes tasks from the state updater when the input partitions of the tasks are lost during a rebalance.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-3747; Close `RecordBatch.records` when append to batch failsWith this change, `test_producer_throughput` with message_size=10000, compression_type=snappy and a snappy buffer size of 32k can be executed in a heap of 192m in a local environment (768m is needed without this change).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1418 from ijuma/kafka-3747-close-record-batch-when-append-fails",0
KAFKA-668 Store jmx port in broker zk string - controlled shutdown admin tool should not require controller JMX url/port to be supplied. Reviewed by Jun Rao.,1
MINOR: Fix javadoc for `PartitionInfo.leader()`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #789 from ijuma/fix-partition-info-leader-doc,5
KAFKA-2024 Log compaction can generate unindexable segments.,2
"KAFKA-7301: Fix streams Scala join ambiguous overload (#5502)Join in the Scala streams API is currently unusable in 2.0.0 as reported by @mowczare:#5019 (comment)This due to an overload of it with the same signature in the first curried parameter.See compiler issue that didn't catch it: https://issues.scala-lang.org/browse/SI-2628Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-3522: Interactive Queries must return timestamped stores (#6661)Reviewers: John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",5
Upgrade ZooKeeper to 3.4.12 and Scala to 2.12.6 (#4940)Reviewers: Jun Rao <junrao@gmail.com>,5
"KAFKA-14129: KRaft must check manual assignments for createTopics are contiguous (#12467)KRaft should validate that manual assignments given to createTopics are contiguous. In other words,they must start with partition 0, and progress through 1, 2, 3, etc. ZK mode does this, but KRaftmode previously did not. Also fix a null pointer exception when the placement for partition 0was not specified.Convert over AddPartitionsTest to use KRaft. This PR converts all of the test except for some ofthe placement logic tests, which will need to be redone for KRaft mode in a future change.Fix null pointer exception in KRaftMetadataCache#getPartitionInfo.  Specifically, we should notassume that the partition will be found in the hash map. This is another case where we had""Some(x)"" but it should be ""Option(x).""Fix a potential null pointer exception in BrokerServer#state.Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9098: When users name repartition topic, use the name for the repartition filter, source and sink node. (#7598)When users specify a name for a repartition topic, we should use the same name for the repartition filter, source, and sink nodes. With the addition of KIP-307 if users go to the effort of naming every node in the topology having processor nodes with generated names is inconsistent behavior.Updated tests in the streams test suite.Reviewers: John Roesler <john@confluent.io>, Christopher Pettitt <cpettitt@confluent.io>",5
"MINOR: Fix Scala 2.13 compiler warnings (#8390)Once Scala 2.13.2 is officially released, I will submit a follow up PRthat enables `-Xfatal-warnings` with the necessary warningexclusions. Compiler warning exclusions were only introduced in 2.13.2and hence why we have to wait for that. I used a snapshot build totest it in the meantime.Changes:* Remove Deprecated annotation from internal request classes* Class.newInstance is deprecated in favor ofClass.getConstructor().newInstance* Replace deprecated JavaConversions with CollectionConverters* Remove unused kafka.cluster.Cluster* Don't use Map and Set methods deprecated in 2.13:    - collection.Map +, ++, -, --, mapValues, filterKeys, retain    - collection.Set +, ++, -, --* Add scala-collection-compat dependency to streams-scala andupdate version to 2.1.4.* Replace usages of deprecated Either.get and Either.right* Replace usage of deprecated Integer(String) constructor* `import scala.language.implicitConversions` is not needed in Scala 2.13* Replace usage of deprecated `toIterator`, `Traversable`, `seq`,`reverseMap`, `hasDefiniteSize`* Replace usage of deprecated alterConfigs with incrementalAlterConfigswhere possible* Fix implicit widening conversions from Long/Int to Double/Float* Avoid implicit conversions to String* Eliminate usage of deprecated procedure syntax* Remove `println`in `LogValidatorTest` instead of fixing the compilerwarning since tests should not `println`.* Eliminate implicit conversion from Array to Seq* Remove unnecessary usage of 3 argument assertEquals* Replace `toStream` with `iterator`* Do not use deprecated SaslConfigs.DEFAULT_SASL_ENABLED_MECHANISMS* Replace StringBuilder.newBuilder with new StringBuilder* Rename AclBuffers to AclSeqs and remove usage of `filterKeys`* More consistent usage of Set/Map in Controller classes: this also fixesdeprecated warnings with Scala 2.13* Add spotBugs exclusion for inliner artifact in KafkaApis with Scala 2.12.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",0
"MINOR: Fix consumer and producer to actually support metrics recording levelAlso add tests and a few clean-ups.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2937 from ijuma/metrics-recording-level-producer",5
"MINOR: Revert incompatible behavior change to consumer reset tool (#4611)This patch reverts the removal of the --execute option in the offset reset tool and the change to the default behavior when no options were present. For consistency, this patch adds the --execute flag to the streams reset tool, but keeps its current default behavior. A note has been added to both of these commands to warn the user that future default behavior will be to prompt before acting.Test cases were not actually validating that offsets were committed when the --execute option was present, so I have fixed that and added basic assertions for the dry-run behavior. I also removed some duplicated test boilerplate.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-9274: Add timeout handling for state restore and StandbyTasks (#9368)* Part of KIP-572* If a TimeoutException happens during restore of active tasks, or updating standby tasks, we need to trigger task.timeout.ms timeout.Reviewers: John Roesler <john@confluent.io>",5
KAFKA-922 System Test - set retry.backoff.ms=300 to testcase_0119; reviewed by Neha Narkhede,3
"KAFKA-2273; Sticky partition assignment strategy (KIP-54)This PR implements a new partition assignment strategy called ""sticky"", and it's purpose is to balance partitions across consumers in a way that minimizes moving partitions around, or, in other words, preserves existing partition assignments as much as possible.This patch is co-authored with rajinisivaram and edoardocomar.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1020 from vahidhashemian/KAFKA-2273",5
"KAFKA-5063: Fix flaky o.a.k.streams.integration.ResetIntegrationTestAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2931 from mjsax/kafka-5140-flaky-reset-integration-test",3
KAFKA-3037: Test number of alive brokers known after single node cluster startup…ter startupAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #875 from granthenke/self-aware,5
"KAFKA-6605: Fix NPE in Flatten when optional Struct is null (#5705)Correct the Flatten SMT to properly handle null key or value `Struct` instances.Author: Michal Borowiecki <michal.borowiecki@openbet.com>Reviewers: Arjun Satish <arjun@confluent.io>, Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
KAFKA-13833: Remove the min_version_level from the finalized version range written to ZooKeeper (#12062)Reviewers: David Arthur <mumrah@gmail.com>,4
"KAFKA-9573: Fix JVM options to run early versions of Kafka on the latest JVMs (#8138)Startup scripts for the early version of Kafka contain removed JVM options like `-XX:+PrintGCDateStamps` or `-XX:UseParNewGC`. When system tests run on JVM that doesn't support these options we should set upenvironment variables with correct options.Reviewers: Guozhang Wang <guozhang@confluent.io>, Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk",5
"KAFKA-5746; Add new metrics to support health checks (KIP-188)Adds new metrics to support health checks:1. Error rates for each request type, per-error code2. Request size and temporary memory size3. Message conversion rate and time4. Successful and failed authentication rates5. ZooKeeper latency and status6. Client versionAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3705 from rajinisivaram/KAFKA-5746-new-metrics",5
"KAFKA-3985; Transient system test failure ZooKeeperSecurityUpgradeTest.test_zk_security_upgrade.security_protocolAuthor: Flavio Junqueira <fpj@apache.org>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1973 from fpj/KAFKA-3985",5
"KAFKA-12637: Remove deprecated PartitionAssignor interface (#10512)Remove PartitionAssignor and related classes, update docs and move unit testReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",3
"KAFKA-9753: Add active tasks process ratio (#8370)Measure the percentage ratio the stream thread spent on processing each task among all assigned active tasks (KIP-444). Also add unit tests to cover the added metrics in this PR and the previous #8358. Also trying to fix the flaky test reported in KAFKA-5842Co-authored-by: John Roesler <vvcephei@apache.org>Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
KAFKA-13930: Add 3.2.0 to core upgrade and compatibility system tests (#12210)Apache Kafka 3.2.0 was recently released. Now we needto test upgrades and compatibility with 3.2 in core system tests.Reviewer: Jason Gustafson <jason@confluent.io>,5
"KAFKA-990 Fix ReassignPartitionCommand and improve usability; reviewed by Neha, Jun, Joel and Guozhang",1
KAFKA-3475; Introduce our own `MiniKdc`This also fixes KAFKA-3453 and KAFKA-2866.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1155 from ijuma/kafka-3475-introduce-our-minikdc,5
"KAFKA-7023: Move prepareForBulkLoad() call after customized RocksDBConfigSetter (#5166)*Summaryoptions.prepareForBulkLoad() and then use the configs from the customized customized RocksDBConfigSetter. This may overwrite the configs set in prepareBulkLoad call. The fix is to move prepareBulkLoad call after applying configs customized RocksDBConfigSetter.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-3996; ByteBufferMessageSet.writeTo() should be non-blockingAlso:* Introduce a blocking variant to be used by `FileMessageSet.append`* Add tests* Minor clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1669 from ijuma/kafka-3996-byte-buffer-message-set-write-to-non-blocking,1
"KAFKA-5516: Formatting verifiable producer/consumer output in a similar fashionAuthor: ppatierno <ppatierno@live.com>Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3434 from ppatierno/verifiable-consumer-producer",5
enable shallow iterator in ByteBufferMessageSet to allow mirroing data without decompression; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-315git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1310595 13f79535-47bb-0310-9956-ffa450edef68,1
"Revert ""KAFKA-992 follow up: Fix the zookeeper de-registration issue for controller and consumer; reviewed by Neha Narkhede""This reverts commit 81c49bbdae5e490f9d5dc7b042ee60e617fbb22b.",4
"KAFKA-13877: Fix flakiness in RackAwarenessIntegrationTest (#12468)In the current test, we check for tag distribution immediately after everyone is on the running state, however due to the fact of the follow-up rebalances, ""everyone is now in running state"" does not mean that the cluster is now stable. In fact, a follow-up rebalance may occur, upon which the local thread metadata would return empty which would cause the distribution verifier to fail.Reviewers: Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>",0
"MINOR: Fix message count for sliding windows test (#9248)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
MINOR: Remove duplicate properties encode in KafkaZkClient#setOrCreateEntityConfigs (#8636)The properties are encoded multiple times by `setOrCreateEntityConfigs`.Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"KAFKA-5762; Refactor AdminClient to use LogContext- client id is part of the log context, so removed ad-hoc usages- Fixed an issue where the response was not printed correctly,use `toString(version)` instead of `toString()`- Capitalized all log statements for consistency- Fixed a number of double spaces after periodAuthor: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3741 from Kamal15/kafka-5762",0
KAFKA-12406 Integrate client quotas with KRaft broker (#10254),5
KAFKA-9515: Upgrade ZooKeeper to 3.5.7 (#8125)A couple of critical fixes:ZOOKEEPER-3644: Data loss after upgrading standalone ZK server 3.4.14 to 3.5.6 with snapshot.trust.empty=trueZOOKEEPER-3701: Split brain on log disk full (3.5) Full release notes:https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310801&version=12346098Reviewers: Bill Bejeck <bbejeck@gmail.com>,0
"KAFKA-4916: test streams with brokers failingSeveral fixes for handling broker failures:- default replication value for internal topics is now 3 in test itself (not in streams code, that will require a KIP.- streams producer waits for acks from all replicas in test itself (not in streams code, that will require a KIP.- backoff time for streams client to try again after a failure to contact controller.- fix bug related to state store locks (this helps in multi-threaded scenarios)- fix related to catching exceptions property for network errors.- system test for all the aboveAuthor: Eno Thereska <eno@confluent.io>Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2719 from enothereska/KAFKA-4916-broker-bounce-test",3
"MINOR: Fix StreamsOptimizedTest (#9911)We have seen recent system test timeouts associated with this test.Analysis revealed an excessive amount of time spent searchingfor test conditions in the logs.This change addresses the issue by dropping some unnecessarychecks and using a more efficient log search mechanism.Reviewers: Bill Bejeck <bbejeck@apache.org>, Guozhang Wang <guozhang@apache.org>",2
"MINOR: Fix failing upgrade test by supporting both security.inter.broker.protocol and inter.broker.listener.name depending on kafka version (#7000)Reviewers: Brian Bushree <bbushree@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"HOTFIX: Init stream-stream left/outer join emit interval correctly (#11055)Follow up to #10917The fix from #10917 intended to reduce the emit frequency to save the creation cost of RocksDB iterators. However, we incorrectly initialized the ""timer"" with timestamp zero, and thus, the timer was always in the past and we did try to emit left/outer join result too often.This PR fixes the initialization of the emit interval timer to current wall-clock time to effectively 'enable' the fix from #10917.Reviewers: Sergio Peña <sergio@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-1650; avoid data loss when mirror maker shutdown uncleanly; reviewed by Guozhang Wang,4
"KAFKA-8869: Remove task configs for deleted connectors from config snapshot (#8444)Currently, if a connector is deleted, its task configurations will remain in the config snapshot tracked by the KafkaConfigBackingStore. This causes issues with incremental cooperative rebalancing, which utilizes that config snapshot to determine which connectors and tasks need to be assigned across the cluster. Specifically, it first checks to see which connectors are present in the config snapshot, and then, for each of those connectors, queries the snapshot for that connector's task configs.The lifecycle of a connector is for its configuration to be written to the config topic, that write to be picked up by the workers in the cluster and trigger a rebalance, the connector to be assigned to and started by a worker, task configs to be generated by the connector and then written to the config topic, that write to be picked up by the workers in the cluster and trigger a second rebalance, and finally, the tasks to be assigned to and started by workers across the cluster.There is a brief period in between the first time the connector is started and when the second rebalance has completed during which those stale task configs from a previously-deleted version of the connector will be used by the framework to start tasks for that connector. This fix aims to eliminate that window by preemptively clearing the task configs from the config snapshot for a connector whenever it has been deleted.An existing unit test is modified to verify this behavior, and should provide sufficient guarantees that the bug has been fixed.Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-8736: Track size in InMemoryKeyValueStore (#7177)InMemoryKeyValueStore uses ConcurrentSkipListMap#size which takes linear time as it iterates over the entire map. We should just track size ourselves for approximateNumEntriesReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",1
"KAFKA-3812: fix state store directory locking in Kafka StreamsMove all state directory creation/locking/unlocking/cleaning to a single class. Don't release the channel until the lock is released. Refactor code to make use of new classAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Ismael Juma, Guozhang WangCloses #1628 from dguy/kafka-3812",1
MINOR: Fix the format string supplied to CustomRequestLogger (#11359)Fix the format string supplied to CustomRequestLogger. It was previously missing thebrackets required to delineate the unit of time being recorded.See https://www.eclipse.org/jetty/javadoc/jetty-9/org/eclipse/jetty/server/CustomRequestLog.htmlReviewers: Ismael Juma <ismael@juma.me.uk>,2
"MINOR: Suppress ProducerConfig warning in MirrorMakerThough MirrorMaker uses the `producer.type` value of theproducer properties, ProducerConfig show the warning:`The configuration 'producer.type' was supplied butisn't a known config.`Author: Shun Takebayashi <shun@takebayashi.asia>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2676 from takebayashi/suppress-mirrormaker-warning",2
KAFKA-1512 Add per-ip connection limits.,1
"KAFKA-13249: Always update changelog offsets before writing the checkpoint file (#11283)When using EOS checkpointed offsets are not updated to the latest offsets from the changelog because the maybeWriteCheckpoint method is only ever called when commitNeeded=false. This change will force the update if enforceCheckpoint=true .I have also added a test which verifies that both the state store and the checkpoint file are completely up to date with the changelog after the app has shutdown.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <wangguoz@gmail.com>",4
KAFKA-7027: Add overloaded build method to StreamsBuilder (#5437)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-4044; log actual socket send/receive buffer size after connecting in SelectorAuthor: Manikumar Reddy O <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #1750 from omkreddy/KAFKA-4044-LOG,2
"KAFKA-14078; Do leader/epoch validation in Fetch before checking for valid replica (#12411)After the fix for https://github.com/apache/kafka/pull/12150, if a follower receives a request from another replica, it will return UNKNOWN_LEADER_EPOCH even if the leader epoch matches. We need to do epoch leader/epoch validation first before we check whether we have a valid replica.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-8038 - Fix timing issue in SslTransportLayerTest.testCloseSsl (#6377)Ensure that server-side channel is ready before it is muted in the test.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-9422: Track the set of topics a connector is using (KIP-558) (#8017)This feature corresponds to KIP-558 and extends how the internal status topic (set via `status.storage.topic` distributed worker config) is used to include information that allows Kafka Connect to keep track which topics a connector is using.The set of topics a connector is actively using, is exposed via a new endpoint that is added to the REST API of Connect workers.* A `GET /connectors/{name}/topics` request will return the set of topics that have been recorded as active since a connector started or since the set of topics was reset for this connector.An additional endpoints allows users to reset the set of active topics for a connector via the second endpoint that this feature is adding:* A `PUT /connectors/{name}/topics/reset` request clears the set of active topics. An operator may enable or disable this feature by setting `topic.tracking.enable` (true by default).The `topic.tracking.enable` worker config property (true by default) allows an operator to enable/disable the entire feature. Or if the feature is enabled, the `topic.tracking.allow.reset` worker config property (true by default) allows an operator to control whether reset requests submitted to the Connect REST API are allowed.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
KAFKA-3104: add windowed aggregation to KStreamAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro MastudaCloses #781 from guozhangwang/K3104,1
"MINOR: Fix typo in LogCleanerTest (#10984)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
KAFKA-5668; fetch across stores in CompositeReadOnlyWindowStore & CompositeReadOnlySessionStoreFix range queries in `CompositeReadOnlyWindowStore` and `CompositeReadOnlySessionStore` to fetch across all stores (was previously just looking in the first store)Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3685 from dguy/kafka-5668,0
KAFKA-12209: Add the timeline data structures for the KIP-631 controller (#9901)Reviewers: Jun Rao <junrao@gmail.com>,5
KAFKA-2168: minor follow-up patch; reviewed by Guozhang Wang,5
"MINOR: add versioning to request and response headers (#7372)Add a version number to request and response headers.  The headerversion is determined by the first two 16 bit fields read (API key andAPI version).  For now, ControlledShutdown v0 has header version 0, andall other requests have v1.  Once KIP-482 is implemented, there will bea v2 of the header which supports tagged fields.",1
"KAFKA-12867: Fix ConsumeBenchWorker exit behavior for maxMessages config (#10797)The trogdor ConsumeBenchWorker allows several consumption tasks to be run in parallel, the number is configurable using the threadsPerWorker config. If one of the consumption tasks completes executing successfully due to maxMessages being consumed, then, the consumption task prematurely notifies the doneFuture causing the entire ConsumeBenchWorker to halt. This becomes a problem when more than 1 consumption task is running in parallel, because the successful completion of 1 of the tasks shuts down the entire worker while the other tasks are still running. When the worker is shut down, it kills all the active consumption tasks, though they have not consumed maxMessages yet. This commit defers notification of the doneFuture to the CloseStatusUpdater thread, which is already responsible for tracking the status of the tasks and updating their status when all of the tasks complete.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Update docs for KIP-229 (#4499)This PR includes:* Minor fix to command line output message* Relevant documentation update,5
KAFKA-2935: Remove vestigial WorkerConfig.CLUSTER_CONFIGAuthor: shikhar <shikhar@schmizz.net>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1404 from shikhar/kafka-2935,5
"MINOR: Clean up ThreadCacheTest (#6485)Minor clean up ofThreadCacheTestReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",3
MINOR: ignore wakeups when committing offsets on consumer closeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #306 from hachikuji/handle-wakeup-in-consumer-close,0
MINOR: Add KafkaServerStartable constructor overload for compatibilityWe added the `reporters` parameter as part of KIP-74: Cluster Id.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #1878 from ijuma/add-kafka-startable-overload-for-compat,1
"KAFKA-4355: Skip topics that have no partitionsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2133 from enothereska/KAFKA-4355-topic-not-found",5
"MINOR: improve KafkaStreams replication factor documentation (#9829)Reviewers: Jason Gustafson <jason@confluent.io>, Jim Galasyn <jim.galasyn@confluent.io>",5
"KAFKA-10021: Changed Kafka backing stores to use shared admin client to get end offsets and create topics (#9780)The existing `Kafka*BackingStore` classes used by Connect all use `KafkaBasedLog`, which needs to frequently get the end offsets for the internal topic to know whether they are caught up. `KafkaBasedLog` uses its consumer to get the end offsets and to consume the records from the topic.However, the Connect internal topics are often written very infrequently. This means that when the `KafkaBasedLog` used in the `Kafka*BackingStore` classes is already caught up and its last consumer poll is waiting for new records to appear, the call to the consumer to fetch end offsets will block until the consumer returns after a new record is written (unlikely) or the consumer’s `fetch.max.wait.ms` setting (defaults to 500ms) ends and the consumer returns no more records. IOW, the call to `KafkaBasedLog.readToEnd()` may block for some period of time even though it’s already caught up to the end.Instead, we want the `KafkaBasedLog.readToEnd()` to always return quickly when the log is already caught up. The best way to do this is to have the `KafkaBackingStore` use the admin client (rather than the consumer) to fetch end offsets for the internal topic. The consumer and the admin API both use the same `ListOffset` broker API, so the functionality is ultimately the same but we don't have to block for any ongoing consumer activity.Each Connect distributed runtime includes three instances of the `Kafka*BackingStore` classes, which means we have three instances of `KafkaBasedLog`. We don't want three instances of the admin client, and should have all three instances of the `KafkaBasedLog` share a single admin client instance. In fact, each `Kafka*BackingStore` instance currently creates, uses and closes an admin client instance when it checks and initializes that store's internal topic. If we change `Kafka*BackingStores` to share one admin client instance, we can change that initialization logic to also reuse the supplied admin client instance.The final challenge is that `KafkaBasedLog` has been used by projects outside of Apache Kafka. While `KafkaBasedLog` is definitely not in the public API for Connect, we can make these changes in ways that are backward compatible: create new constructors and deprecate the old constructors. Connect can be changed to only use the new constructors, and this will give time for any downstream users to make changes.These changes are implemented as follows:1. Add a `KafkaBasedLog` constructor to accept in its parameters a supplier from which it can get an admin instance, and deprecate the old constructor. We need a supplier rather than just passing an instance because `KafkaBasedLog` is instantiated before Connect starts up, so we need to create the admin instance only when needed. At the same time, we'll change the existing init function parameter from a no-arg function to accept an admin instance as an argument, allowing that init function to reuse the shared admin instance used by the `KafkaBasedLog`. Note: if no admin supplier is provided (in deprecated constructor that is no longer used in AK), the consumer is still used to get latest offsets.2. Add to the `Kafka*BackingStore` classes a new constructor with the same parameters but with an admin supplier, and deprecate the old constructor. When the classes instantiate its `KafkaBasedLog` instance, it would pass the admin supplier and pass an init function that takes an admin instance.3. Create a new `SharedTopicAdmin` that lazily creates the `TopicAdmin` (and underlying Admin client) when required, and closes the admin objects when the `SharedTopicAdmin` is closed.4. Modify the existing `TopicAdmin` (used only in Connect) to encapsulate the logic of fetching end offsets using the admin client, simplifying the logic in `KafkaBasedLog` mentioned in #1 above. Doing this also makes it easier to test that logic.5. Change `ConnectDistributed` to create a `SharedTopicAdmin` instance (that is `AutoCloseable`) before creating the `Kafka*BackingStore` instances, passing the `SharedTopicAdmin` (which is an admin supplier) to all three `Kafka*BackingStore objects`, and finally always closing the `SharedTopicAdmin` upon termination. (Shutdown of the worker occurs outside of the `ConnectDistributed` code, so modify `DistributedHerder` to take in its constructor additional `AutoCloseable` objects that should be closed when the herder is closed, and then modify `ConnectDistributed` to pass the `SharedTopicAdmin` as one of those `AutoCloseable` instances.)6. Change `MirrorMaker` similarly to `ConnectDistributed`.7. Change existing unit tests to no longer use deprecated constructors.8. Add unit tests for new functionality.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
"KAFKA-10024: Add dynamic configuration and enforce quota for per-IP connection rate limits (KIP-612, part 2) (#9386)This PR implements the part of KIP-612 for adding IP throttling enforcement, and a ZK entity for configuring dynamic IP throttles.Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",5
"MINOR: Retain public constructors of classes from public API (#6455)TopicDescription and ConsumerGroupDescription in org.apache.kafka.clients.admin. are part of the public API, so we should retain the existing public constructor. Changed the new constructor with authorized operations to be package-private to avoid maintaining more public constructors since we only expect admin client to use this.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
"KAFKA-7462: Make token optional for OAuthBearerLoginModule (#5733)OAuthBearerLoginModule is used both on the server-side and client-side (similar to login modules for other mechanisms). OAUTHBEARER tokens are client credentials used only on the client-side to authenticate with servers, but the current implementation requires tokens to be provided on the server-side even if OAUTHBEARER is not used for inter-broker communication. This commit makes tokens optional for server-side login context to allow brokers to be configured without a token when OAUTHBEARER is not used for inter-broker communication.Reviewers: Ron Dagostino <rndgstn@gmail.com>, Jun Rao <junrao@gmail.com>",2
"KAFKA-5772 Improve Util classes (#3370)Utils with static methods should not be instantiated, hence marking the classes `final` and adding a `private` constructor.Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-5611; AbstractCoordinator should handle wakeup raised from onJoinCompleteAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3571 from hachikuji/KAFKA-5611,5
"KAFKA-7430: Improve Transformer interface JavaDoc (#5675)This PR improves the JavaDoc of the transformer interface. Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-5777; Add ducktape integration for TrogdorAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3726 from cmccabe/KAFKA-5777,5
"KAFKA-2509: Replace LeaderAndIsr{Request,Response} with o.a.k.c reque……sts equivalentAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #647 from granthenke/isr-request",5
kafka-1202; optimize ZK access in KafkaController; also incorporating fixes in kafka-1020; patched by Jun Rao and Guozhang Wang; reviewed by Neha Narkhede and Joel Koshy,0
Improve second replica assignment; patched by Jun Rao; reviewed by Guozhang Wang; kafka-762,1
"KAFKA-2440; Use `NetworkClient` instead of `SimpleConsumer` to fetch data from replicaAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Jun Rao <junrao@gmail.com>Closes #194 from ijuma/kafka-2440-use-network-client-in-fetcher",1
MINOR: Some minor improvements to TxnOffsetCommit handlingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3040 from hachikuji/txn-offset-commit-cleanups,4
"KAFKA-10199: Add PAUSE in state updater (#12386)* Add pause action to task-updater.* When removing a task, also check in the paused tasks in addition to removed tasks.* Also I realized we do not check if tasks with the same id are added, so I add that check in this PR as well.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
kafka-763; Add an option to replica from the largest offset during unclean leader election; patched by Swapnil Ghike; reviewed by Jun Rao,4
"KAFKA-2276; KIP-25 initial patchInitial patch for KIP-25Note that to install ducktape, do *not* use pip to install ducktape. Instead:```$ git clone gitgithub.com:confluentinc/ducktape.git$ cd ducktape$ python setup.py install```Author: Geoff Anderson <geoff@confluent.io>Author: Geoff <granders@gmail.com>Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen, Gwen, Jun, GuozhangCloses #70 from granders/KAFKA-2276 and squashes the following commits:a62fb6c [Geoff Anderson] fixed checkstyle errorsa70f0f8 [Geoff Anderson] Merged in upstream trunk.8b62019 [Geoff Anderson] Merged in upstream trunk.47b7b64 [Geoff Anderson] Created separate tools jar so that the clients package does not pull in dependencies on the Jackson JSON tools or argparse4j.a9e6a14 [Geoff Anderson] Merged in upstream changesd18db7b [Geoff Anderson] fixed :rat errors (needed to add licenses)321fdf8 [Geoff Anderson] Ignore tests/ and vagrant/ directories when running rat build task795fc75 [Geoff Anderson] Merged in changes from upstream trunk.1d93f06 [Geoff Anderson] Updated provisioning to use java 7 in light of KAFKA-23162ea4e29 [Geoff Anderson] Tweaked README, changed default log collection behavior on VerifiableProducer0eb6fdc [Geoff Anderson] Merged in system-tests69dd7be [Geoff Anderson] Merged in trunk4034dd6 [Geoff Anderson] Merged in upstream trunkede6450 [Geoff] Merge pull request #4 from confluentinc/move_muckrake7751545 [Geoff Anderson] Corrected license headerse6d532f [Geoff Anderson] java 7 -> java 68c61e2d [Geoff Anderson] Reverted jdk back to 6f14c507 [Geoff Anderson] Removed mode = ""test"" from Vagrantfile and Vagrantfile.local examples. Updated testing README to clarify aws setup.98b7253 [Geoff Anderson] Updated consumer tests to pre-populate kafka logse6a41f1 [Geoff Anderson] removed stray printlnb15b24f [Geoff Anderson] leftover KafkaBenchmark in super call0f75187 [Geoff Anderson] Rmoved stray allow_fail. kafka_benchmark_test -> benchmark_testf469f84 [Geoff Anderson] Tweaked readme, added example Vagrantfile.local3d73857 [Geoff Anderson] Merged downstream changes42dcdb1 [Geoff Anderson] Tweaked behavior of stop_node, clean_node to generally fail fast7f7c3e0 [Geoff Anderson] Updated setup.py for kafkatestc60125c [Geoff Anderson] TestEndToEndLatency -> EndToEndLatency4f476fe [Geoff Anderson] Moved aws scripts to vagrant directory5af88fc [Geoff Anderson] Updated README to include aws quickstarte5edf03 [Geoff Anderson] Updated example aws Vagrantfile.local96533c3 [Geoff] Update aws-access-keys-commands25a413d [Geoff] Update aws-example-Vagrantfile.local884b20e [Geoff Anderson] Moved a bunch of files to kafkatest directoryfc7c81c [Geoff Anderson] added setup.py632be12 [Geoff] Merge pull request #3 from confluentinc/verbose-client51a94fd [Geoff Anderson] Use argparse4j instead of joptsimple. ThroughputThrottler now has more intuitive behavior when targetThroughput is 0.a80a428 [Geoff Anderson] Added shell program for VerifiableProducer.d586fb0 [Geoff Anderson] Updated comments to reflect that throttler is not message-specific6842ed1 [Geoff Anderson] left out a file from last commit1228eef [Geoff Anderson] Renamed throttler9100417 [Geoff Anderson] Updated command-line options for VerifiableProducer. Extracted throughput logic to make it reusable.0a5de8e [Geoff Anderson] Fixed checkstyle errors. Changed name to VerifiableProducer. Added synchronization for thread safety on println statements.475423b [Geoff Anderson] Convert class to string before adding to json object.bc009f2 [Geoff Anderson] Got rid of VerboseProducer in core (moved to clients)c0526fe [Geoff Anderson] Updates per review comments.8b4b1f2 [Geoff Anderson] Minor updates to VerboseProducer2777712 [Geoff Anderson] Added some metadata to producer output.da94b8c [Geoff Anderson] Added number of messages option.07cd1c6 [Geoff Anderson] Added simple producer which prints status of produced messages to stdout.a278988 [Geoff Anderson] fixed typosf1914c3 [Liquan Pei] Merge pull request #2 from confluentinc/system_tests81e4156 [Liquan Pei] Bootstrap Kafka system tests",3
init a list with only one element with singleton function to enhance perf (#9208)Reviewers: Bill Bejeck <bbejeck@apache.org>,1
"MINOR: upgrade system test should check for ISR rejoin on each roll (#7827)The upgrade system test correctly rolls by upgrading the broker and leaving the IBP, and then rolling again with the latest IBP version.Unfortunately, this is not sufficient to pick up many problems in our IBPgating as we charge through the rolls and after the second roll all ofthe brokers will rejoin the ISR and the test will be treated as asuccess.This test adds two new checks:1. We wait for the ISR to stabilize for all partitions. This is bestpractice during rolls, and is enough to tell us if a broker hasn'trejoined after each roll.2. We check the broker logs for some common protocol errors. This is afail safe as it's possible for the test to be successful even if someprotocols are incompatible and the ISR is rejoined.Reviewers: Nikhil Bhatia <nikhil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
MINOR: Remove unnecessary conditional in KafkaAdminClient to fix checkstyle (#5058),0
"KAFKA-8340, KAFKA-8819: Use PluginClassLoader while statically initializing plugins (#7315)Added plugin isolation unit tests for various scenarios, with a `TestPlugins` class that compiles and builds multiple test plugins without them being on the classpath and verifies that the Plugins and DelegatingClassLoader behave properly. These initially failed for several cases, but now pass since the issues have been fixed.KAFKA-8340 and KAFKA-8819 are closely related, and this fix corrects the problems reported in both issues.Author: Greg Harris <gregh@confluent.io>Reviewers: Chris Egerton <chrise@confluent.io>, Magesh Nandakumar <mageshn@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Correct KafkaProducer Javadoc spelling of property 'max.in.flight.requests.per.connection'Currently, in branches _trunk_, _0.11.0_, and _1.0_ the property **max.in.flight.requests.per.connection** is incorrectly misspelled as _max.inflight.requests.per.connection_harshach ijuma guozhangwang can you please review. Thank you.Author: Hugo Louro <hmclouro@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4094 from hmcl/trunk_MINOR_Doc_InflightProp",5
KAFKA-13080: Direct fetch snapshot request to kraft controller (#11041)Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"KAFKA-9820: validateMessagesAndAssignOffsetsCompressed allocates unused iterator (#8422)https://github.com/apache/kafka/commit/3e9d1c1411c5268de382f9dfcc95bdf66d0063a0 introduced skipKeyValueIterator(s) which were intended to be used, but in this case were created but were not used in offset validation.A subset of the benchmark results follow. Looks like a 20% improvement in validation performance and a 40% reduction in garbage allocation for 1-2 batch sizes.**# Parameters: (bufferSupplierStr = NO_CACHING, bytes = RANDOM, compressionType = LZ4, maxBatchSize = 1, messageSize = 1000, messageVersion = 2)**Before:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":  64851.837 ±(99.9%) 944.248 ops/s [Average]                (min, avg, max) = (64505.317, 64851.837, 65114.359), stdev = 245.218  CI (99.9%): [63907.589, 65796.084] (assumes normal distribution)                                                                                                    ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":  164088.003 ±(99.9%) 0.004 B/op [Average]                                                                                   (min, avg, max) = (164088.001, 164088.003, 164088.004), stdev = 0.001  CI (99.9%): [164087.998, 164088.007] (assumes normal distribution)After:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":                                        78910.273 ±(99.9%) 707.024 ops/s [Average]                                                                                 (min, avg, max) = (78785.486, 78910.273, 79234.007), stdev = 183.612                                                       CI (99.9%): [78203.249, 79617.297] (assumes normal distribution)                                       ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":                                                                                                                                     96440.002 ±(99.9%) 0.001 B/op [Average]                                                                                    (min, avg, max) = (96440.002, 96440.002, 96440.002), stdev = 0.001                                                         CI (99.9%): [96440.002, 96440.003] (assumes normal distribution)    **# Parameters: (bufferSupplierStr = NO_CACHING, bytes = RANDOM, compressionType = LZ4, maxBatchSize = 2, messageSize = 1000, messageVersion = 2)**Before:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":                                        64815.364 ±(99.9%) 639.309 ops/s [Average]                                                                                 (min, avg, max) = (64594.545, 64815.364, 64983.305), stdev = 166.026                                                                                                                                                                                  CI (99.9%): [64176.056, 65454.673] (assumes normal distribution)                                                                                                                                                                                                                                                 ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":          163944.003 ±(99.9%) 0.001 B/op [Average]                                                                                   (min, avg, max) = (163944.002, 163944.003, 163944.003), stdev = 0.001                                                      CI (99.9%): [163944.002, 163944.004] (assumes normal distribution)                                     After:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":  77075.096 ±(99.9%) 201.092 ops/s [Average]                (min, avg, max) = (77021.537, 77075.096, 77129.693), stdev = 52.223  CI (99.9%): [76874.003, 77276.188] (assumes normal distribution)                                                                                                    ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":  96504.002 ±(99.9%) 0.003 B/op [Average]                                                                                    (min, avg, max) = (96504.001, 96504.002, 96504.003), stdev = 0.001  CI (99.9%): [96503.999, 96504.005] (assumes normal distribution)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
merge from 0.8 and resolve conflict in Log,2
KAFKA-10847: Add internal flag to disable KAFKA-10847 fix (#10612)Adds an internal flag that can be used to disable the fixes in KAFKA-10847. It defaults to true if the flag is not set or has an invalid boolean value.The flag is named __enable.kstreams.outer.join.spurious.results.fix__. This flag is considered internal only. It is a temporary flag that will be used to help users to disable the join fixes while they do a transition from the previous semantics of left/outer joins. The flag may be removed in future releases.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
MINOR: fix record time in test shouldWipeOutStandbyStateDirectoryIfCheckpointIsMissing (#9948)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Small cleanups in connect/mirror (#12113)Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <divijvaidya13@gmail.com>",4
HOTFIX: Fix optional import in ConsumerCoordinator (#6953)This was caused by back-to-back merging of #6854 (which removed the Optional import) and #6936 (which needed the import).Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-1911; Async delete topic - contributed by Mayuresh Gharat <gharatmayuresh15@gmail.com> and Sumant Tambe <sutambe@yahoo.com>The last patch submitted by MayureshGharat (back in Dec 15) has been rebased to the latest trunk. I took care of a couple of test failures (MetricsTest) along the way. jjkoshy , granders , avianey , you may be interested in this PR.Author: Sumant Tambe <sutambe@yahoo.com>Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>Author: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Joel Koshy <jjkoshy.w@gmail.com>Closes #1664 from sutambe/async-delete-topic",4
Create topic support (revisit based on v3 design); patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-329git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1351188 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13414: Replace Powermock/EasyMock by Mockito in connect.storage (#11450)I've skipped the following classes as they use powermock to stub/access private and static fields/methods:- KafkaConfigBackingStoreTest- KafkaOffsetBackingStoreTestThose will require some refactoring and will be updated in a separate PR.Reviewers: Tom Bentley <tbentley@redhat.com>, dengziming <dengziming1993@gmail.com>",5
"MINOR: guard against calls to exit in QuorumTestHarness tests (#11457)Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Sherzod Mamadaliev <mamadaliev@yahoo.com>Closes #11457 from cmccabe/guard_against_exit",1
"KAFKA-8941: Add RocksDB Metrics that Could not be Added due to RocksD… (#11441)This PR adds some RocksDB metrics that could not be added in KIP-471 due to RocksDB version. The new metrics are extracted using Histogram data provided by RocksDB API, and the old ones were extracted using Tickers. The new metrics added are memtable-flush-time-(avg|min|max) and compaction-time-(avg|min|max).Reviewer: Bruno Cadonnna <cadonna@apache.org>",1
KAFKA-12648: fill in javadocs for the StreamsException class with new guarantees (#11436)Minor followup to #11405 / KIP-783 to write down the new guarantees we're providing about the meaning of a StreamsException in the javadocs of that classReviewers: Bruno Cadonna <cadonna@apache.org>,1
"KAFKA-3080: Fix ConsoleConsumerTest by checking version when service is startedThe MessageFormatter being used was only introduced as of 0.9.0.0. The Kafkaversion in some tests is changed dynamically, sometimes from trunk back to anearlier version, so this option must be set based on the version used when theservice is started, not when it is created.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Geoff Anderson, Ismael Juma, Grant HenkeCloses #770 from ewencp/kafka-3080-system-test-console-consumer-version-failure",5
KAFKA-12683: Remove deprecated UsePreviousTimeOnInvalidTimestamp (#10557)Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
"KAFKA-7431: Clean up connect unit tests[KAFKA-7431](https://issues.apache.org/jira/browse/KAFKA-7431)Changes made to improve the code readability: - Removed `throws Exception` from the place where there won't be an exception - Removed type arguments where those can be inferred explicitly by compiler - Rewritten Anonymous classes to Java 8 with lambdasAuthor: Srinivas Reddy <mrsrinivas@users.noreply.github.com>Author: Srinivas Reddy <srinivas96alluri@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ryanne Dolan <ryannedolan@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5681 from mrsrinivas/cleanup-connect-uts",5
"HOTFIX: for flaky Streams EOS integration testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3273 from mjsax/hotfix-flaky-stream-eos-test",3
"KAFKA-10028: Minor fixes to describeFeatures and updateFeatures apis (#9393)In this PR, I have addressed the review comments from @chia7712 in #9001 which were provided after #9001 was merged. The changes are made mainly to KafkaAdminClient:Improve error message in updateFeatures api when feature name is empty.Propagate top-level error message in updateFeatures api.Add an empty-parameter variety for describeFeatures api.Minor documentation updates to @param and @return to make these resemble other apis.Reviewers: Chia-Ping Tsai chia7712@gmail.com, Jun Rao junrao@gmail.com",1
KAFKA-532 Multiple controllers can co-exist during soft failures; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1411010 13f79535-47bb-0310-9956-ffa450edef68,0
MINOR: Update Scala to 2.13.6 (#10711)This includes TASTy Reader support for Scala 3.0.0. This makes it easierfor Kafka libraries to be used in Scala 3.0 projectsRelease notes: https://github.com/scala/scala/releases/tag/v2.13.6Reviewers: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-9320: Enable TLSv1.3 by default (KIP-573) (#8695)1. Enables `TLSv1.3` by default with Java 11 or newer.2. Add unit tests that cover the various TLSv1.2 and TLSv1.3 combinations.3. Extend `benchmark_test.py` and `replication_test.py` to run with 'TLSv1.2'or 'TLSv1.3'.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
KAFKA-2316: Drop java 1.6 support; patched by Sriharsha Chintalapani reviewed by Ismael Juma and Gwen Shapira,1
KAFKA-13430: Remove broker-wide quota properties from the documentation (#11463)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-9716; Clarify meaning of compression rate metrics (#8664)There is some confusion over the compression rate metrics, as the meaning of the value isn't clearly stated in the metric description. In this case, it was assumed that a higher compression rate value meant better compression. This PR clarifies the meaning of the value, to prevent misunderstandings.Reviewers: Jason Gustafson <jason@confluent.io>",5
MINOR: Check null in SmokeTestDriver to avoid NPEAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #1611 from guozhangwang/Kminor-check-null-smokedriver,3
KAFKA-8559: Allocate ArrayList with correct size in PartitionStates (#6964)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
"MINOR: Fix issue in `AsyncProducerTest` where it expects the `port` config to be setThis test fails locally when I run it, but somehow Jenkins builds are passed. Not clear how.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2073 from ijuma/async-producer-test-port-config",5
KAFKA-1087 Empty topic list causes consumer to fetch metadata of all topics; reviewed by Guozhang Wang and Neha Narkhede,5
"KAFKA-6205: initialize topology after state stores restoration completedInitialize topology after state store restoration.Although IMHO updating some of the existing tests demonstrates the correct order of operations, I'll probably add an integration test, but I wanted to get this PR in for feedback on the approach.Author: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>Closes #4415 from bbejeck/KAFKA-6205_restore_state_stores_before_initializing_topologyminor log4j edits",2
KAFKA-13889: Fix AclsDelta handling of REMOVE_ACCESS_CONTROL_ENTRY_RECORD (#12160)AclsDelta stores the pending deletion in the changes Map. This could override a creation that might have just happened. This is an issue because in BrokerMetadataPublisher this results in us making a removeAcl call which finally results in StandardAuthorizerData trying to remove an ACL that doesn't exist which throws an exception. If the ACCESS_CONTROL_ENTRY_RECORD event never got processed by BrokerMetadataPublisher then the ACL wont be in the Map yet.The fix here is to remove the entry from the changes Map if the ACL doesnt exist in the image yet.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,1
KAFKA-3665: Enable TLS hostname verification by default (KIP-294) (#4956)Make HTTPS the default ssl.endpoint.identification.algorithm.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
MINOR: Serialize the real isolationLevel in FetchRequestAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2961 from apurvam/MINOR-serialize-isolation-level-in-fetch-request,5
"KAFKA-13410; Add a --release-version flag for storage-tool (#12245)This patch removes the --metadata-version and adds a --release-version to the kafka-storage tool. This change is not a breaking change since we are removing --metadata-version which was introduced on May 18, but it has not been released yet.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>",1
"KAFKA-10062: Add a methods to retrieve the current timestamps as known by the Streams app (#9744)Implements KIP-622.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-13780: Generate OpenAPI file for Connect REST API (#12067)New gradle task `connect:runtime:genConnectOpenAPIDocs` that generates `connect_rest.yaml` under `docs/generated`.This task is executed when `siteDocsTar` runs.,1
Added script for bin/kafka-consumer-groups.sh that was mistakenly dropped from the original patch for KAFKA-1476,4
KAFKA-13763: Improve unit testing coverage and flexibility for IncrementalCooperativeAssignor (#11974)Reviewers: Mickael Maison <mickael.maison@gmail.com>,3
"KAFKA-3343; Use NoTimestamp in GroupMetadataManager when message v0 i……s used.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1023 from becketqin/KAFKA-3343",1
"MINOR: Pin pip to 9.0.3 as 10 is not compatible with with system pip (#4937)If not pinned, the following error will happen:Traceback (most recent call last):  File ""/usr/bin/pip"", line 9, in <module>    from pip import mainImportError: cannot import name mainReviewers: Guozhang Wang <wangguoz@gmail.com>",2
KAFKA-7540: commit offset sync before close (#11898)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
"KAFKA-10463: Install `git` explicitly in Dockerfile (#9257)`openjdk:8` includes `git` by default, but `openjdk:11` does not. Install `git` explicitly to make it easier totest with newer openjdk versions.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
MINOR: Modify unnecessary access specifiers (#9861)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"KAFKA-3108: custom StreamParitioner for Windowed keyguozhangwangWhen ```WindowedSerializer``` is specified in ```to(...)``` or ```through(...)``` for a key, we use ```WindowedStreamPartitioner```.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #779 from ymatsuda/partitioner",5
HOTFIX: Remove duplicate entry from ApiVersionAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #2818 from ijuma/fix-api-version,0
HOTFIX: Fix invalid long format conversion in request logger messageAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3318 from hachikuji/hotfix-request-metric-udpate,0
"MINOR: Add reason to log message when incrementing the log start offset (#8701)Sometimes logging leaves us guessing at the cause of an increment to the log start offset. Since this results in deletion of user data, we should provide the reason explicitly.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-6590; Fix bug in aggregation of consumer fetch bytes and counts metrics (#4278)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Ensure a single version of scala-library is used (#9155)This patch ensures we use a force resolution strategy for the scala-library dependency.I've tested this locally and saw a difference in the output.With the change (using 2.4 and the jackson library 2.10.5):```./core/build/dependant-libs-2.12.10/scala-java8-compat_2.12-0.9.0.jar./core/build/dependant-libs-2.12.10/scala-collection-compat_2.12-2.1.2.jar./core/build/dependant-libs-2.12.10/scala-reflect-2.12.10.jar./core/build/dependant-libs-2.12.10/scala-logging_2.12-3.9.2.jar./core/build/dependant-libs-2.12.10/scala-library-2.12.10.jar```Without (using 2.4 and the jackson library 2.10.5):``` find . -name 'scala*.jar'./core/build/dependant-libs-2.12.10/scala-java8-compat_2.12-0.9.0.jar./core/build/dependant-libs-2.12.10/scala-collection-compat_2.12-2.1.2.jar./core/build/dependant-libs-2.12.10/scala-reflect-2.12.10.jar./core/build/dependant-libs-2.12.10/scala-logging_2.12-3.9.2.jar./core/build/dependant-libs-2.12.10/scala-library-2.12.12.jar```Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"MINOR: Fix --enable-autocommit flag in verifiable consumer (#7743)The --enable-autocommit argument is a flag. It does not take a parameter. This was broken in #7724.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",2
"MINOR: Refactor tag key for store level metrics (#7257)The tag key for store level metrics specified in StreamsMetricsImplis unified with the tag keys on thread and task level.Reviewers: Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-2643: Run mirror maker ducktape tests with SSL and SASLRun tests with SSL, SASL_PLAINTEXT and SASL_SSL. Same security protocol is used for source and target Kafka.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Geoff Andreson, Ben StopfordCloses #559 from rajinisivaram/KAFKA-2643",5
KAFKA-9405: Use Map.computeIfAbsent where applicable (#7937)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"KAFKA-3522: Add RocksDBTimestampedSegmentedBytesStore (#6186)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-5365; Fix regression in compressed message iteration affecting magic v0 and v1Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3203 from hachikuji/KAFKA-5365,5
"KAFKA-3134: Fix missing value.deserializer error during KafkaConsumer initialization… initializationAuthor: Yifan Ying <yying@fitbit.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #803 from happymap/KAFKA-3134",5
Kafka has become a TLPgit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1414576 13f79535-47bb-0310-9956-ffa450edef68,2
"KAFKA-3192: Add unwindowed aggregations for KStream; and make all example code executableAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda, Michael G. Noll, Jun RaoCloses #870 from guozhangwang/K3192",1
MINOR: Fix error message in KafkaConfig validation (#4417),5
"KAFKA-6145: Add constrained balanced assignment algorithm (#8262)Adds a currently unused component of the new Streams assignment algorithm.Implements: KIP-441Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"HOTFIX: StateDirectoryTest should use Set instead of List (#8305)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-3163; Add time based index to Kafka.This patch is for KIP-33.https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+indexAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>, Liquan Pei <liquanpei@gmail.com>Closes #1215 from becketqin/KAFKA-3163",5
"MINOR: add additional shutdown log info (#9124)As title, additional logging added to detect the shutdown progress for Kafka server.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-7286; Avoid getting stuck loading large metadata records (#5500)If a group metadata record size is higher than offsets.load.buffer.size, loading offsets and group metadata from __consumer_offsets would hang forever. This was due to the buffer being too small to fit any message bigger than the maximum configuration. This patch grows the buffer as needed so the large records will fit and the loading can move on.A similar change was made to the logic for state loading in the transactioncoordinator.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, lambdaliu <lambdaliu@users.noreply.github.com>, Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13041: Enable connecting VS Code remote debugger (#10915)The changes in this PR enable connecting VS Code's remote debugger to a system test running locally with ducker-ak.Changes include:- added zip_safe=False to setup.py - this enables installing kafkatest module together with source code when running `python setup.py  develop/install`.- install [debugpy](https://github.com/microsoft/debugpy) on ducker nodes- expose 5678 (default debugpy port) on ducker01 node - ducker01 is the one that actually executes tests, so that's where you'd connect to.- added `-d|--debug` option to `ducker-ak test` command - if used, tests will run via `python3.7 -m debugpy` command, which would listen on 5678 and pause until debugger is connected.- changed the logic of the `ducker-ak test` command so that ducktape args are collected separately after `--` - otherwise any argument we add to the `test` command in the future might potentiallyshadow a similar ducktape argument. - we don't really check that `ducktape_args` are args while `test_name_args` are actual test names, so the difference between the two is minimal actually - most importantly we do check that `test_name_args` is not empty, but we are ok if `ducktape_args` is.Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
MINOR: Reenable streams smoke testI ran it 3 times and it works again.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2257 from enothereska/minor-reenable-smoke-test,3
KAFKA-12630: Remove deprecated KafkaClientSupplier#getAdminClient in Streams (#10502)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
MINOR: code cleanup for `VOut` inconsistent naming (#8907)Consistently using VOut instead of Vout for Streams group API.Reviewers: Boyang Chen <boyang@confluent.io>,5
"KAFKA-6010; Relax record conversion time test to avoid build failureFor record conversion tests, check time >=0 since conversion times may be too small to be measured accurately. Since default value is -1, the test is still useful. Also increase message size in SslTransportLayerTest#testNetworkThreadTimeRecorded to avoid failures when processing time is too small.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4018 from rajinisivaram/KAFKA-6010-MemoryRecordsBuilderTest",5
"KAFKA-6585: Consolidate duplicated logic on reset tools (#9255)Reviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Matthias J. Sax <matthias@confluent.io>",5
consumer sometimes don't release partition ownership properly in ZK during rebalance; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-286git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1294302 13f79535-47bb-0310-9956-ffa450edef68,1
PreferredReplicaLeaderElectionCommand has command line error; patched by Jun Rao; reviewed by Maxime Brugidou; kafka-743,0
KAFKA-4051: Use nanosecond clock for timers in brokerUse System.nanoseconds instead of System.currentTimeMillis in broker timer tasks to cope with changes to wall-clock time.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Gwen ShapiraCloses #1768 from rajinisivaram/KAFKA-4051,5
MINOR: AdminClient should respect retry backoffAdminClient should backoff when retrying a Call. Fixed and added a unit testAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5077 from hachikuji/admin-client-retry-backoff,1
"KAFKA-4402: make the KafkaProducer true round robin per topicAuthor: yaojuncn <yaojuncn@users.noreply.github.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Konstantin <konstantin@tubemogul.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2128 from yaojuncn/KAFKA-4402-client-producer-round-robin-fix",0
"KAFKA-7502: Cleanup KTable materialization logic in a single place (doMapValues) (#6520)* Move materialization logic from TableProcessorNode to KTableImpl1. TableProcessorNode: remove materializedInternal, use storeBuilder instead.2. Instantiate StoreBuilder in KTableImpl#[doFilter, doMapValues, doTransformValues], instead of TableProcessorNode#init.* Cleanup KTableImpl#doMapValues* 1. Add TableProcessorNode(String, ProcessorParameters, StoreBuilder). 2. Reformat+trivial changes on TableProcessorNode.java.",4
"MINOR: fix NamedCache metrics in Streams (#4917)* Fixes a bug in which all NamedCache instances in a process sharedone parent metric.* Also fixes a bug which incorrectly computed the per-cache metric tag(which was undetected due to the former bug).* Drop the StreamsMetricsConventions#xLevelSensorName conventionin favor of StreamsMetricsImpl#xLevelSensor to allow StreamsMetricsImplto track thread- and cache-level metrics, so that they may be cleanly declaredfrom anywhere but still unloaded at the appropriate time. This was necessaryright now so that the NamedCache could register a thread-level parent sensorto be unloaded when the thread, not the cache, is closed.* The above changes made it mostly unnecessary for the StreamsMetricsImpl toexpose a reference to the underlying Metrics registry, so I did a little extra workto remove that reference, including removing inconsistently-used and unnecessarycalls to Metrics#close() in the tests.The existing tests should be sufficient to verify this change.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Adding example to SMT documentationAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2721 from gwenshap/improve_smt_docs,2
"KAFKA-4235; Fix race condition in Sender.initiateClose that may cause missed callbacksAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1939 from becketqin/KAFKA-4235",5
KAFKA-1863; Add docs for possible thrown exception in Callback; reviewed by Jiangjie Qin,2
"HOTFIX: move rebalanceInProgress check to skip commit during handleCorrupted (#10444)Minor followup to #10407 -- we need to extract the rebalanceInProgress check down into the commitAndFillInConsumedOffsetsAndMetadataPerTaskMap method which is invoked during handleCorrupted, otherwise we may attempt to commit during a a rebalance which will failReviewers: Matthias J. Sax <mjsax@confluent.io>",5
"KAFKA-8934: Introduce instance-level metrics for streams applications (#7416)1. Moves StreamsMetricsImpl from StreamThread to KafkaStreams2. Adds instance-level metrics as specified in KIP-444, i.e.:-- version-- commit-id-- application-id-- topology-description-- stateReviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-2105; Check for null in KafkaProducer.partitionsForAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3697 from omkreddy/KAFKA-2105,5
"KAFKA-13113; Support unregistering Raft listeners (#11109)This patch adds support for unregistering listeners to `RaftClient`. Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13782; Ensure correct partition added to txn after abort on full batch (#11995)Fixes a regression introduced in https://github.com/apache/kafka/pull/11452. Following [KIP-480](https://cwiki.apache.org/confluence/display/KAFKA/KIP-480%3A+Sticky+Partitioner), the `Partitioner` will receive a callback when a batch has been completed so that it can choose another partition. Because of this, we have to wait until the batch has been successfully appended to the accumulator before adding the partition in `TransactionManager.maybeAddPartition`. This is still safe because the `Sender` cannot dequeue a batch from the accumulator until it has been added to the transaction successfully.Reviewers: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>, David Jacot <djacot@confluent.io>,  Tom Bentley <tbentley@redhat.com>",5
KAFKA-12561: Fix flaky kafka.server.RaftClusterTest.testCreateClusterAndCreateListDeleteTopic (#10410)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
KAFKA-588 Fix bug in OffsetIndex.truncateTo. Reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403859 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Improved display names for parameterized KRaft and ZK tests (#11957)This patch adds display names for KRaft and ZK tests. Without this, it becomes hard to understand in Jenkins test reports which test failed. With this addition, it becomes more clear which method in the test suite fails.Reviewers: Colin P. McCabe <cmccabe@apache.org>",0
"KAFKA-7564: Expose single task details in Trogdor (#5852)This commit adds a new ""/coordinator/tasks/{taskId}"" endpoint which fetches details for a single task.",1
"MINOR: Fix a few blocking calls in PlaintextConsumerTest (#5859)We've been seeing some hanging builds recently (see KAFKA-7553). Consistently the culprit seems to be a test case in PlaintextConsumerTest. This patch doesn't fix the underlying issue, but it eliminates a few places where these test cases could block:1. It replaces several calls to the deprecated `poll(long)` which can block indefinitely in the worst case in order to join the group with `poll(Duration)` which respects the timeout.2. It also fixes a consume utility in `TestUtils` which can block for a long time depending on the number of records that are expected to be consumed.Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin Patrick McCabe <colin@cmccabe.xyz>",3
MINOR: Remove `InvalidReceiveException` catch in `SocketServer``Selector.poll` no longer throws it.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #506 from ijuma/poll-no-longer-throws-invalid-receive-exception,4
MINOR: Doc of 'retries' config should mention max.in.flight.requests.per.connection to avoid confusionAuthor: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1607 from kawamuray/MINOR-retries-doc,2
"KAFKA-13721: asymetric join-winodws should not emit spurious left/outer join results (#11875)Reviewers:  Sergio Peña <sergio@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-9176: Do not update limit offset if we are in RESTORE_ACTIVE mode (#8235)Previously we may be updating the standby's limit offset as committed offsets to those source changelogs, and then inside the inner method we check if the state is in RESTORE_ACTIVE or not, which is a bug.We should, instead, just check on the caller that we can skip restoring if:1. we are in RESTORE_ACTIVE mode.2. there're no source changelog partitions.3. those partitions do not have any buffered records.Also updated the unit test for this coverage.Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-5263: Avoid tight polling loop in consumer with no ready nodesFor consumers with manual partition assignment, await metadata when there are no ready nodes to avoid busy polling.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3124 from rajinisivaram/KAFKA-5263",5
KAFKA-7989: RequestQuotaTest should wait for quota config change before running tests (#6482)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
KAFKA-13865: Fix ResponseSendTimeMs metric in RequestChannel is removed twice (#12111)Fix ResponseSendTimeMs metric in RequestChannel is removed twiceReviewers: Luke Chen <showuon@gmail.com>,4
"KAKFA-10619: Idempotent producer will get authorized once it has a WRITE access to at least one topic (KIP-679) (#9485)Includes:- New API to authorize by resource type- Default implementation for the method that supports super users and ACLs- Optimized implementation in AclAuthorizer that supports ACLs, super users and allow.everyone.if.no.acl.found- Benchmarks and tests- InitProducerIdRequest authorized for Cluster:IdempotentWrite or WRITE to any topic, ProduceRequest authorized only for topic even if idempotentReviewers: Lucas Bradstreet <lucas@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-6362; Async auto-commit should discover coordinator if it is unknown (#4326)Currently `maybeAutoCommitOffsetsAsync` does not try to find the coordinator if it is unknown. As a result, asynchronous auto-commits will fail indefinitely. This patch changes the behavior to add coordinator discovery to the async auto-commit path.",1
KAFKA-4375; Reset interrupt state in a few places where InterruptedException is caughtSee https://issues.apache.org/jira/browse/KAFKA-4375Author: Stig Rohde Døssing <sdo@it-minds.dk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2100 from srdo/KAFKA-4375,5
KAFKA-13929: Replace legacy File.createNewFile() with NIO.2 Files.createFile() (#12197)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
KAFKA-3681; Connect doc formattingAuthor: Kaufman Ng <kaufman@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1351 from coughman/KAFKA-3681-connect-doc-formatting,2
"MINOR: KafkaApis#handleOffsetDeleteRequest does not group result correctly (#8485)`KafkaApis#handleOffsetDeleteRequest` does not build the response correctly because `topics.add` is not in the correct loop. Fortunately, due to how the response is processed by the admin client, it works but sends redundant information on the wire.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: increase timeout for unstable KTableSourceTopicRestartIntegrationTest (#4445)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-3448; Support zone index in IPv6 regexWhen an address is written textually, the zone index is appended to the address, separated by a percent sign (%). The actual syntax of zone indices depends on the operating system.Author: Som Sahu <sosahu@microsoft.com>Author: Soumyajit Sahu <soumyajit-sahu@users.noreply.github.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1305 from soumyajit-sahu/fixIPV6RegexPattern_trunk",0
KAFKA-3395: prefix job id to internal topic namesguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1062 from ymatsuda/k3395,5
"KAFKA-4973; Fix transient failure of AdminClientTest.testDeleteRecordsWithExceptionAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2760 from lindong28/KAFKA-4973",3
"[MINOR] allow additional JVM args in KafkaService (#7297)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Vikas Singh <vikas@confluent.io>",5
KAFKA-10404; Use higher poll timeout to avoid rebalance in testCoordinatorFailover (#9183)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
Merge remote branch 'origin/0.8' into trunk,1
KAFKA-5837; Set defaults for ReassignPartitionsCommand correctlyAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #3792 from rajinisivaram/KAFKA-5837,5
Reverting KAFKA-42 since it accidentally contained changes to metrics package. Didn't catch it due to a stale sbt cache. It is better to redo the patch and then commitgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396726 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-4584: Fail the 'kafka-configs' command if the config to be removed does not existAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2300 from vahidhashemian/KAFKA-4584,4
"MINOR: Streams integration tests should not call exit (#9067)- replace System.exit with Exit.exit in all relevant classes- forbid use of System.exit in all relevant classes and add exceptions for othersCo-authored-by: John Roesler <vvcephei@apache.org>Co-authored-by: Matthias J. Sax <matthias@confluent.io>Reviewers: Lucas Bradstreet <lucas@confluent.io>, Ismael Juma <ismael@confluent.io>",5
"KAFKA-8215: Upgrade Rocks to v5.18.3 (#6743)This upgrade exposes a number of new options, including the WriteBufferManager which -- along with existing TableConfig options -- allows users to limit the total memory used by RocksDB across instances. This can alleviate some cascading OOM potential when, for example, a large number of stateful tasks are suddenly migrated to the same host.The RocksDB docs guarantee backwards format compatibility across versionsReviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>,",2
MINOR: Remove version check when setting reason for `Join/LeaveGroupRequest` in `RequestResponseTest` (#11680)This patch ensures that the `Reason` field can be set for all versions (ignorable field).Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Standby task commit needed when offsets updated (#8146)This is a minor fix of a regression introduced in the refactoring PR: in current trunk standbyTask#commitNeeded always return false, which would cause standby tasks to never be committed until closed. To go back to the old behavior we would return true when new data has been applied and offsets being updated.Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-2973; Fix leak of child sensors on removeAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira, Guozhang WangCloses #650 from ijuma/kafka-2973-fix-leak-child-sensors-on-remove",4
KAFKA-1374; Log cleaner should be able to handle compressed messages; reviewed by Guozhang Wang,0
"MINOR: MetadataShell should handle ProducerIdsRecord (#11603)MetadataShell should be able to display contents from `ProducerIdsRecord`.Reviewers: Mickael Maison <mickael.maison@gmail.com>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8456: Stabilize flaky StoreUpgradeIntegrationTest (#6941)Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
MINOR: return unmodifiableMap for PartitionStates.partitionStateMap. (#7637)Makes the map returned by partitionStateMap unmodifiable to prevent mutation.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
MINOR: Remove remnants of hadoop clients from kafka-run-class.shAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #799 from granthenke/hadoop-contrib,1
"MINOR: cleanup apache license in python filesijumaAs discussed in https://github.com/apache/kafka/pull/1645, this patch removes an extraneous line from several __init__.py files, and a few others as wellAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1659 from granders/minor-cleanup-init-files",5
use propertyExists to test if both broker.list and zk.connect are present; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-290git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1294959 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13099; Transactional expiration should account for max batch size (#11098)When expiring transactionalIds, we group the tombstones together into batches. Currently there is no limit on the size of these batches, which can lead to `MESSAGE_TOO_LARGE` errors when a bunch of transactionalIds need to be expired at the same time. This patch fixes the problem by ensuring that the batch size respects the configured limit. Any transactionalIds which are eligible for expiration and cannot be fit into the batch are postponed until the next periodic check.Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
kafka-1383; transient unit test failure in SocketServerTest; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,3
MINOR: Bump documentation version to 2.1The documentation version of 2.1.0 RC1 is still at 2.0. Updated it to 2.1.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5916 from vahidhashemian/minor/update_version_in_documentation_for_2.1.0,5
MINOR: replace kafka-preferred-replica-election.sh with kafka-leader-election.sh (#11954)Reviewers: Luke Chen <showuon@gmail.com>,5
KAFKA-992 follow up: Fix the zookeeper de-registration issue for controller and consumer; reviewed by Neha Narkhede,0
"KAFKA-5360; Down-converted uncompressed batches should respect fetch offsetMore specifically, V2 messages are always batched (whether compressed or not) whileV0/V1 are only batched if they are compressed.Clients like librdkafka expect to receive messages from the fetch offset when dealing with uncompressed V0/V1 messages. When converting from V2 to V0/1, we were returning all themessages in the V2 batch.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3191 from ijuma/kafka-5360-down-converted-uncompressed-respect-offset",1
KAFKA-10565: Only print console producer prompt with a tty (#9644)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
MINOR: Small cleanups/refactoring in kafka.controller- Updated logging to use string interpolation- Minor refactors- Fixed a few typosAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4231 from mimaison/controller_refactor,4
KAFKA-2518: Update NOTICE fileAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Guozhang WangCloses #404 from gwenshap/KAFKA-2518,2
MINOR: Update Gradle to 5.1.1 (#6160)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"KAFKA-4708; Fix transient failure in BrokerApiVersionsCommandTest.checkBrokerApiVersionCommandOutputAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2489 from cmccabe/KAFKA-4708",5
"KAFKA-7605; Retry async commit failures in integration test cases to fix flaky tests (#5890)We are seeing some timeouts in tests which depend on the awaitCommitCallback (e.g.SaslMultiMechanismConsumerTest.testCoordinatorFailover). After some investigation,we found that it is caused by a disconnect when attempting the async commit.To fix the problem, we have added simple retry logic to the test utility.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",3
"MINOR: avoid autoboxing in FetchRequest.PartitionData.equalsFetchRequest.PartitionData.equals unnecessarily uses Object.equals generating a lot of allocations due to boxing, even though primitives are being compared. This is shown in the allocation profile below. Note that the CPU overhead is negligble.￼![image](https://user-images.githubusercontent.com/252189/79079019-46686300-7cc1-11ea-9bc9-44fd17bae888.png)Author: Lucas Bradstreet <lucasbradstreet@gmail.com>Reviewers: Chia-Ping Tsai, Gwen ShapiraCloses #8473 from lbradstreet/avoid-boxing-partition-data-equals",5
HOTFIX: set correct numIterations in shouldAllowConcurrentAccesses,1
"KAFKA-8240: Fix NPE in Source.equals() (#6589)Reviewers: John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
MINOR: Fix few documentation errors in streams quickstartPlus a minor enhancementAuthor: glikson <glikson@il.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1571 from glikson/patch-1,0
MINOR: Don't publish javadocs for raft module (#9336)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13234; Transaction system test should clear URPs after broker restarts (#11267)Clearing under-replicated-partitions helps ensure that partitions do not become unavailable longer than necessary as brokers are rolled. This prevents flakiness due to transaction timeouts.Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",3
KAFKA-10185: Restoration info logging (#8896)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"KAFKA-12686 AlterIsr and LeaderAndIsr race condition (#10561)Remove the clearPending method from AlterIsrManagerReviewers: Colin P. Mccabe <cmccabe@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5340; Batch splitting should preserve magic and transactional flagAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3162 from hachikuji/KAFKA-5340",5
MINOR: Stop logging raw record contents above TRACE level in WorkerSourceTask (#10630)Reviewers: Tom Bentley <tbentley@redhat.com>,1
"KAFKA-2706: make state stores first class citizens in the processor topology* Added StateStoreSupplier* StateStore  * Added init(ProcessorContext context) method* TopologyBuilder  * Added addStateStore(StateStoreSupplier supplier, String... processNames)  * Added connectProessorAndStateStores(String processorName, String... stateStoreNames)    * This is for the case processors are not created when a store is added to the topology. (used by KStream)* KStream  * add stateStoreNames to process(), transform(), transformValues().* Refactored existing state stores to implement StateStoreSupplierguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #387 from ymatsuda/state_store_supplier",5
"KAFKA-2557: separate REBALANCE_IN_PROGRESS and ILLEGAL_GENERATION error codesAuthor: Onur Karaman <okaraman@linkedin.com>Reviewers: Jiangjie Qin, Jason Gustafson, Guozhang WangCloses #222 from onurkaraman/KAFKA-2557",2
KAFKA-13801: Kafka server does not respect MetricsReporter contract for dynamically configured reporters (#11998)MetricsReporter.contextChange contract states the method should always be called first before MetricsReporter.init is called. This is done correctly for reporters enabled by default (e.g. JmxReporter) but not for metrics reporters configured dynamically.This fixes the call ordering for dynamically configured metrics reporter and updates tests to enforce ordering.Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Rat should ignore generated directories (#7729)For some reason, PR builds are failing due to the `rat` licensecheck even though it should ignore files included in `.gitignore`.Reviewers: Jason Gustafson <jason@confluent.io>",5
"KAFKA-8471: Replace control requests/responses with automated protocol (#7353)Replaced UpdateMetadata{Request, Response}, LeaderAndIsr{Request, Response}and StopReplica{Request, Response} with the automated protocol classes.Updated the JSON schema for the 3 request types to be more consistent andless strict (if needed to avoid duplication).The general approach is to avoid generating new collections in the requestclasses. Normalization happens in the constructor to make this possible. Buildersstill have to group by topic to maintain the external ungrouped view.Introduced new tests for LeaderAndIsrRequest and UpdateMetadataRequest toverify that the new logic is correct.A few other clean-ups/fixes in code that was touched due to these changes:* KAFKA-8956: Refactor DelayedCreatePartitions#updateWaiting to avoid modifyingcollection in foreach.* Avoid unnecessary allocation for state change trace logging if trace logging is not enabled* Use `toBuffer` instead of `toList`, `toIndexedSeq` or `toSeq` as it generally performsbetter and it matches the performance characteristics of `java.util.ArrayList`. This isparticularly important when passing such instances to Java code.* Minor refactoring for clarity and readability.* Removed usage of deprecated `/:`, unused imports and unnecessary `var`s.* Include exception in `AdminClientIntegrationTest` failure message.* Move StopReplicaRequest verification in `AuthorizerIntegrationTest` to the endto match the comment.Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",3
kafka-846; AbstractFetcherThread should do shallow instead of deep iteration; patched by Jun Rao; reviewed by Neha Narkhede,1
KAFKA-5379 follow up: reduce redundant mock processor contextAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>Closes #3757 from guozhangwang/K5379-follow-up,5
"MINOR: Streams upgrade guide section for newly merged KIPs (#6108)Reviewers: Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-8412: Fix nullpointer exception thrown on flushing before closing producers (#7207)Prior to this change an NPE is raised when calling AssignedTasks.closeunder the following conditions:1. EOS is enabled2. The task was in a suspended stateThe cause for the NPE is that when a clean close is requested for aStreamTask the StreamTask tries to commit. However, in the suspendedstate there is no producer so ultimately an NPE is thrown for thecontained RecordCollector in flush.The fix put forth in this commit is to have AssignedTasks callcloseSuspended when it knows the underlying StreamTask is suspended.Note also that this test is quite involved. I could have just testedthat AssignedTasks calls closeSuspended when appropriate, but that istesting, IMO, a detail of the implementation and doesn't actually verifywe reproduced the original problem as it was described. I feel much moreconfident that we are reproducing the behavior - and we can test exactlythe conditions that lead to it - when testing across AssignedTasks andStreamTask. I believe this is an additional support for the argument ofeventually consolidating the state split across classes.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5194; Include only client traffic in BytesOutPerSec metric (KIP-153)Also added 2 new metrics to account for incoming/outgoing traffic due to internal replication- ReplicationBytesInPerSec- ReplicationBytesOutPerSecAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3003 from mimaison/KAFKA-5194",1
KAFKA-424. Fix command line usage description. Patch from Tommie.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1373056 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-13425:  Optimization of KafkaConsumer#pause semantics (#11460)* 1. Enhance the annotation of KafkaConsumer#pause(...) method2. Add log output when clearing the paused mark of topicPartitions.Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Use Kafka artifact compiled with Scala 2.11 in quickstart.htmlAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #505 from ijuma/scala-2.11-in-quickstart,1
"MINOR: Fix BNF output for protocol arrays conataining primitives in docsBefore this patch arrays containing primitive types were not output:```Metadata Request (Version: 0) => [topics]```After this patch the type is listed:```Metadata Request (Version: 0) => [topics]      topics => STRING```Author: Grant Henke <granthenke@gmail.com>Reviewers: Ashish Singh, Gwen ShapiraCloses #1174 from granthenke/protocol-arrays",5
"Changed for updatedTasks, avoids stopping and starting of unnecessary tasks (#7097)Corrected the `KafkaConfigBackingStore` logic to notify of only the changed tasks, rather than all tasks. This was not noticed before because Connect always stopped and restarted all tasks during a rebalanced, but since 2.3 the incremental rebalance logic exposed this bug.Author: Luying Liu <lyliu@lyliu-mac.freewheelmedia.net>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"KAFKA-6376: Document skipped records metrics changes (#4922)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: RegisterBroker should use an atomic append (#11700)The batch of records that registers a new broker should be committed atomically. This doesn't matterright now, because we only create a single record to register the broker. But if we create multiplerecords in the future, this could matter. In order to avoid confusion, this should useControllerResult#atomicOf.Reviewers: David Arthur <mumrah@gmail.com>",1
KAFKA-2001; Trivial commit to fix OffsetCommitTest,3
MINOR: Fix integer overflow in LRUCacheBenchmark (#7270)The jmh LRUCacheBenchmark will exhibit an int overflow when run on a fast machine:```java.lang.ArrayIndexOutOfBoundsException: Index -3648 out of bounds for length 10000at org.apache.kafka.jmh.cache.LRUCacheBenchmark.testCachePerformance(LRUCacheBenchmark.java:70)at org.apache.kafka.jmh.cache.generated.LRUCacheBenchmark_testCachePerformance_jmhTest.testCachePerformance_thrpt_jmhStub(LRUCacheBenchmark_testCachePerformance_jmhTest.java:119)at org.apache.kafka.jmh.cache.generated.LRUCacheBenchmark_testCachePerformance_jmhTest.testCachePerformance_Throughput(LRUCacheBenchmark_testCachePerformance_jmhTest.java:83)```Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Extend mirror maker test to include interceptorsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2081 from kkonstantine/MINOR-Extend-mirror-maker-test-to-include-interceptors,3
"MINOR: fix comments on deleteTopics method (#10966)Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
"KAFKA-8450: Using KeyValueTimeStamp in MockProcessor (#6933)This PR is to use KeyValueTimeStamp Object in MockProcessor Test file instead of String and change all the dependency files with broken test cases.Reviewers: Kamal Chandraprakash, Matthias J. Sax <mjsax@apache.org>,  Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-4534: StreamPartitionAssignor only ever updates the partitionsByHostState and metadataWithInternalTopics on first assignmentpartitionsByHostState and metadataWithInternalTopics need to be updated on each call to onAssignment() otherwise they contain invalid/stale metadata.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2256 from dguy/4534",5
KAFKA-545 Add some log performance tests.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410088 13f79535-47bb-0310-9956-ffa450edef68,3
"MINOR: update the branch(split) doc and java doc and tests (#11195)Reviewers: Ivan Ponomarev <iponomarev@mail.ru>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Validate inner message compression attributeAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #976 from ijuma/validate-inner-message-compression-attribute,5
"MINOR: Improve ReplicationQuotasTest#shouldThrottleOldSegments resiliency (#5849)I've seen this test fail with```java.lang.AssertionError: Throttled replication of 6352ms should be < 6000ms```A contributing factor is that it starts counting the time it took for replicationbefore the replication itself has started. `createServer()` initializes ZK andother systems before it starts up the replication thread.I ran the test 25 times locally both ways.Average `throttledTook` before the change: 5341.75Mean `throttledTook` after the change: 5256.92Note that those are the results from `./gradlew core:test --tests kafka.server.ReplicationQuotasTest.shouldThrottleOldSegments`. I've noticed that ifI run the whole test class `ReplicationQuotasTest`, the `throttledTook` is close~4100.Reviewers: Ismael Juma <ismael@juma.me.uk>",3
KAFKA-3373; add 'log' prefix to configurations in KIP-31/32Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Gwen ShapiraCloses #1049 from becketqin/KAFKA-3373,5
"KAFKA-12435: Fix javadoc errors (#10392)There were errors while generating javadoc for the streams:test-utils modulebecause the included TopologyTestDriver imported some excluded classes.This fixes the errors by inlining the previously excluded packages.Reviewers: Chia-Ping Tsai <chia7712@apache.org>, Ismael Juma <ijuma@apache.org>",5
"KAFKA-8768: DeleteRecords request/response automated protocol (#7957)Also add version 2 to make use of flexible versions, per KIP-482.Reviewers: Mickael Maison <mickael.maison@gmail.com>",1
"KAFKA-3479: Add new consumer metrics documentationadded new consumer metrics sectionrefactored common metrics into new sectionupdated TOCAuthor: Kaufman Ng <kaufman@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1361 from coughman/KAFKA-3479-consumer-metrics-doc",2
KAFKA-7190: KIP-443; Remove streams overrides on repartition topics (#6511)* remove streams overrides on segment.ms and segment.index.bytes* kip comments,4
"KAFKA-7672: Restoring tasks need to be closed upon task suspension (#6113)* In activeTasks.suspend, we should also close all restoring tasks as well. Closing restoring tasks would not require `task.close` as in `closeNonRunningTasks `, since the topology is not initialized yet, instead only state stores are initialized. So we only need to call `task.closeStateManager`.* Also add @linyli001 's fix.* Unit tests updated accordingly.Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",5
"KAFKA-3936: Validate parameters as early as possibleAdded non null checks to parameters supplied via the DSL and `TopologyBuilder`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Edward Ribeiro <edward.ribeiro@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #1711 from dguy/kafka-3936",2
"KAFKA-4099; Fix the potential frequent log rollingAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1809 from becketqin/KAFKA-4099",2
"KAFKA-12185: fix ConcurrentModificationException in newly added Tasks container class (#9940)Reviewers: Guozhang Wang <guozhand@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-9852: Change the max duration that calls to the buffer pool can block from 2000ms to 10ms to reduce overall test runtime (#8464)Adjusted one assert condition on a testcase as the success was dependanton thread runtimes and the much lower tolerances due to the reduced timebroke this test.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-6634: Delay starting new transaction in task.initializeTopology (#4684)As titled, not starting new transaction since during restoration producer would have not activity and hence may cause txn expiration. Also delay starting new txn in resuming until initializing topology.Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>",5
MINOR: avoid closing over both pre & post-transform record in WorkerSourceTaskFollowup to #2299 for KAFKA-3209Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2365 from shikhar/2299-followup,5
"KAFKA-5565: Add a broker metric specifying the number of consumer group rebalances in progress…up rebalances in progressAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3506 from cmccabe/KAFKA-5565",5
"Fix perf regression on LISR requests by asynchronously flushing the partition.metadata file (#11056)After noticing increased LISR times, we discovered a lot of time was spent synchronously flushing the partition metadata file. This PR changes the code so we asynchronously flush the files.We ensure files are flushed before appending, renaming or closing the log to ensure we have the partition metadata information on disk. Three new tests have been added to address these cases.Reviewers:  Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",5
KAFKA-9727: cleanup the state store for standby task dirty close and check null for changelogs (#8307)This PR fixes three things:* the state should be closed when standby task is restoring as well* the EOS standby task should also wipe out state under dirty close* the changelog reader should check for null as wellReviewers: Guozhang Wang <wangguoz@gmail.com>,4
"KAFKA-7454: Use lazy allocation for SslTransportLayer buffers and null them on close (#5713)Lazy allocation helps when there are a large number of connectionsthat have been accepted, but where no data has been received fromthe clients. Each buffer is often around 16k (max TLS record size).Nulling the buffers should not make a difference in the currentimplementation since we release the reference to the channeland transport layer after we close them, but it's a good practiceto release medium/large buffers after `close` is called.Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"KAFKA-7204: Avoid clearing records for paused partitions on poll of MockConsumer (#7505)The previous version of MockConsumer does not allow the clients to test consecutive calls to poll while consuming only from a partial set of partitions due to the fact that it clears all the records after each call. This change makes MockConsumer clearing the records only for the partitions that are not paused (whose records are actually returned by the poll). The remaining paused partitions will retain the records.Unit test added accordingly.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-3896: Fix KStreamRepartitionJoinTestThe root cause of this issue is that in InternalTopicManager we are creating topics one-at-a-time, and for this test, there are 31 topics to be created, as a result it is possible that the consumer could time out during the assignment in rebalance, and the next leader has to do the same again because of ""makeReady"" calls are one-at-a-time.This patch batches the topics into a single create request and also use the StreamsKafkaClient directly to fetch metadata for validating the created topics. Also optimized a bunch of inefficient code in InternalTopicManager and StreamsKafkaClient.Minor cleanup: make the exception message more informative in integration tests.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Jason GustafsonCloses #2405 from guozhangwang/K3896-fix-kstream-repartition-join-test",3
KAFKA-7896; Add sasl.jaas.config/sasl.mechanism props to the log4j kafka appenderThis patch adds 2 props to the log4j kafka appender that get put directlyinto the sasl properties passed to the producer:    - ClientJaasConf: This property sets sasl.jaas.config    - SaslMechanim: This property sets sasl.mechanismAuthor: Rohan Desai <desai.p.rohan@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6216 from rodesai/add-kafka-appender-security-props,1
"MINOR: improve security docs for Kafka Streams (#4532)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Joel Hamill <joel@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Fix upgrade.mode references (#5645)Reviewers: John Roesler <john@confluent.io>, Andrew Choi <andrew.choi@uwaterloo.ca>, Chia-Ping Tsai <chia7712@gmail.com>",5
MINOR: fix formatting,0
"KAFKA-3502: KStreamTestDriver needs to be closed after the test caseFound a few recently added unit tests did not close KStreamTestDriver after the test itself is closed; this can cause RocksDB virtual function called if the contained topology has some persistent store since they will be initialized but not closed in time.MINOR fix: found that when closing KStreamTestDriver, we need to first flushing all stores before closing any of them; this is triggered from the `KTableKTableLeftJoin.shouldNotThrowIllegalStateExceptionWhenMultiCacheEvictions`.MINOR fix: in CachingXXXStore, the `name` field is actually used as the cache's namespace, not really the store name or its corresponding topic name. Fixed it by renaming it to `cacheName` and use `this.name()` elsewhere which will call the underlying store's name.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava, Eno Thereska, Damian GuyCloses #2432 from guozhangwang/K3502-kstream-builder-test",3
MINOR: Fix `GroupCoordinator.onGroupLoaded` log (#11434)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
KAFKA-1812 Allow IpV6 in configuration with parseCsvMap patch by Jeff Holoman reviewed by Gwen Shapira and Joe Stein,5
KAFKA-4809: docker/run_tests.sh should set up /opt/kafka-dev to be the source directory…0.x and not 0.8Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2602 from cmccabe/KAFKA-4809,5
KAFKA-9586: Fix errored json filename in ops documentationThis PR is the counterpart of apache/kafka-site#253.cc/ omkreddyAuthor: Lee Dongjin <dongjin@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8149 from dongjinleekr/feature/KAFKA-9586,2
"KAFKA-5259; TransactionalId auth implies ProducerId authAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>Closes #3075 from hachikuji/KAFKA-5259-FIXED",0
"MINOR: Improve Sensor recording efficiency (#8593)1. Added a recordInternal function to let all other public functions trigger, so that shouldRecord would only be checked once.2. In Streams, pass along the current wall-clock time inside InternalProcessorContext when process / punctuate which can be passed in to the record function to reduce the calling frequency of SystemTime.milliseconds().Reviewers: John Roesler <vvcephei@apache.org>",5
"KAFKA-8058: Fix ConnectClusterStateImpl.connectors() method (#6384)Fixed the ConnectClusterStateImpl.connectors() method and throw an exception on timeout. Added unit test.Author: Chris Egerton <chrise@confluent.io>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Robert Yokota <rayokota@gmail.com>, Arjun Satish <wicknicks@users.noreply.github.com>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #6384 from C0urante:kafka-8058",5
KAFKA-615 fsync asynchronous from log roll. Patch reviewed by Jun and Sriram.,2
KAFKA-3316: Add REST API for listing connector pluginsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1090 from Ishiihara/kafka-3316,5
MINOR: Don't process sasl.kerberos.principal.to.local.rules on client-side (#8362)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"MINOR: KAFKA-2371 follow-up, DistributedHerder should wakeup WorkerGroupMember after assignment to ensure work is started immediatelyAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #360 from ewencp/minor-kafka-2371-follow-up-wakeup-after-rebalance",1
MINOR: Close ZKDatabase in EmbeddedZookeeper (#6237)And remove redundant call. Closing ZKDatabase is necessary to allow the datadirectory to be deleted when running on Windows.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
Merge remote branch 'origin/0.8' into trunk,1
Minor change: Deleting the doc for kafka.producer.Producer's constructor. It is causing NoSuchElementException causing jenkins build to failgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1364001 13f79535-47bb-0310-9956-ffa450edef68,0
MINOR: Fix zookeeper-security-migration documentation exampleIncorrect option in examplehttps://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/admin/ZkSecurityMigrator.scala#L71Author: Ryan P <ryan.n.pridgeon@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2714 from rnpridgeon/patch-1,1
"KAFKA-9581: Remove rebalance exception withholding (#8145)The rebalance exception withholding is no longer necessary as we have better mechanism for catching and wrapping these exceptions. Throw them directly should be fine and simplify our current error handling.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-9020: Streams sub-topologies should be sorted by sink -> source relationship (#7495)Subtopologies are currently ordered alphabetically by source node, which prior to KIP-307 happened to always result in the ""correct"" (ie topological) order. Now that users may name their nodes anything they want, we must explicitly order them so that upstream node groups/subtopologies come first and the downstream ones come after.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2
MINOR: Log transaction metadata state transitions plus a few cleanupsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3081 from hachikuji/minor-add-txn-transition-logging,2
KAFKA-5495; Update docs to use `kafka-consumer-groups.sh` for checking consumer offsetsAnd remove the deprecated `ConsumerOffsetChecker` example.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3405 from vahidhashemian/KAFKA-5495,5
"KAFKA-5987: Maintain order of metric tags in generated documentationThe `MetricNameTemplate` is changed to used a `LinkedHashSet` to maintain the same order of the tags that are passed in. This tag order is then maintained when `Metrics.toHtmlTable` generates the MBean names for each of the metrics.The `SenderMetricsRegistry` and `FetcherMetricsRegistry` both contain templates used in the producer and consumer, respectively, and these were changed to use a `LinkedHashSet` to maintain the order of the tags.Before this change, the generated HTML documentation might use MBean names like the following and order them:```kafka.connect:type=sink-task-metrics,connector={connector},partition={partition},task={task},topic={topic}kafka.connect:type=sink-task-metrics,connector={connector},task={task}```However, after this change, the documentation would use the following order:```kafka.connect:type=sink-task-metrics,connector={connector},task={task}kafka.connect:type=sink-task-metrics,connector={connector},task={task},topic={topic},partition={partition}```This is more readable as the code that is creating the templates has control over the order of the tags.Note that JMX MBean names use ObjectName that does not maintain order of the properties (tags), so this change should have no impact on the actual JMX MBean names used in the metrics.cc wushujamesAuthor: Randall Hauch <rhauch@gmail.com>Reviewers: James Cheng <jylcheng@yahoo.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3985 from rhauch/kafka-5987",5
KAFKA 244 Improve log4j appender to use kafka.producer.Producer; patched by vtkstef; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1231276 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Mention that -1 disables retention by time (#4881)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Updating files with release 2.7.1 (#10660)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,  Matthias J. Sax <mjsax@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2
MINOR: Fix typo in mapper parameter of flatMapValuesThe parameter is already called `mapper` in the KStreamImpl class. I think it was probably named `processor` here because it was copy/pasted from some other signature. This sees trivial enough to not require a jira as per the contribution guidelines.Author: Andy Chambers <andy.chambers@fundingcircle.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3888 from cddr/fix-kstream-flatMapValues-signature,0
"MINOR: PartitionReassignmentHandler should only generate event when znode is createdWe only need to generate the event when the znode is created or deleted.In the former case, we start the reassignment while in the latter were-register the watcher (necessary for the Controller to detect futurereassignments).During Controller failover, we restart the reassignment without generatingan event so it's not affected by this change.Also use the Controller cache (`ControllerContext.partitionsBeingReassigned`)in `removePartitionFromReassignedPartitions` instead of reloading thedata from ZooKeeper.Overall, we would previously load the reassignment data from ZooKeeper twiceper completed partition whereas now as don't do it at all. As an example,say there were 30k partitions being reassigned, these changes save theallocation of 900 million `TopicAndPartition` and `Seq[Int]` (replicas)instances (could easily amount to 20-40 GB depending on the topic namelength). This matters most in cases where the partitions being reassigneddon't have much data allowing the reassignment to complete reasonablyfast for many of the partitions.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Onur Karaman <okaraman@linkedin.com>Closes #4143 from ijuma/partition-reassignment-ignore-handle-deletion-and-data-change",5
kafka-1717; remove netty dependency through ZK 3.4.x; patched by Jun Rao; reviewed by Sriharsha Chintalapani and Neha Narkhede,4
"KAFKA-12875: Change Log layer segment map mutations to avoid absence of active segment (#11950)Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-5112; Update compatibility system tests to include 0.10.2.1Also update message format tests now that we have a third messageformat.Finally, set group.initial.rebalance.delay.ms=100.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2701 from ijuma/update-upgrade-tests-for-0.11",5
bump to 2.9 development version,5
"MINOR: Add Processing Guarantees to Streams docsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3345 from guozhangwang/KMinor-streams-eos-docs",2
"MINOR: Switch order of sections on tumbling and hopping windows in streams doc. Tumbling windows are defined as ""special case of hopping time windows"" - but hopping windows currently only explained later in the docs. (#8505)Currently, tumbling windows are defined as ""a special case of hopping time windows"" in the streams docs, but hopping windows are only explained in a subsequent section.I think it would make sense to switch the order of these paragraphs around. To me this also makes more sense semantically.TestingBuilt the site and checked that everything looks ok and html is valid (or at least didn't contain any new warnings that were caused by this change).Reviewers: Bill Bejeck <bbejeck@apache.org>",4
"KAFKA-12866: Avoid root access to Zookeeper (#10795)The broker shouldn't assume create access to the chroot. There aredeployement scenarios where the chroot is already created is the onlyznode which the broker can access.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",5
Adding a file missed while committing KAFKA-2345,2
KAFKA-1660; Add API to the producer to support close with a timeout; reviewed by Joel Koshy and Jay Kreps.,1
"KAFKA-8659: fix SetSchemaMetadata failing on null value and schema (#7082)Make SetSchemaMetadata SMT ignore records with null value and valueSchema or key and keySchema.The transform has been unit tested for handling null values gracefully while still providing the necessary validation for non-null values.Reviewers: Konstantine Karantasis<konstantine@confluent.io>, Bill Bejeck <bbejeck@apache.org>",5
MINOR: Clean up of SourceTaskOffsetCommiterAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1170 from Ishiihara/minor-cleanup,4
"KAFKA-5767; Kafka server should halt if IBP < 1.0.0 and there is log directory failureAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #3718 from lindong28/KAFKA-5767",0
KAFKA-12165: Include org.apache.kafka.common.quota in javadoc (#9846)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-3704; Revert ""Remove hard-coded block size in KafkaProducer""This is not an exact revert as the code changed a bit since theoriginal commit. We also include a note in `upgrade.html`.The original commit is 1182d61deb23b5cd86cbe462471f7df583a796e1.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira, Guozhang WangCloses #1391 from ijuma/kafka-3704-revert and squashes the following commits:7891b67 [Ismael Juma] Tweak upgrade note based on Gwen's feedback1673cd0 [Ismael Juma] Revert ""KAFKA-3704: Remove hard-coded block size in KafkaProducer""",4
"KAFKA-5600; Fix group loading regression causing stale metadata/offset cachethe while loop was too big and need to be closed earlierto see the fix, ignore whitespace since most of it is indentationthis bug was introduced by commit5bd06f1d542e6b588a1d402d059bc24690017d32Author: Jan Burkhardt <jan.burkhardt@just.social>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #3538 from bjrke/trunk",1
"KAFKA-5738; Add cumulative count for rate metrics (KIP-187)Implementation of https://cwiki.apache.org/confluence/display/KAFKA/KIP-187+-+Add+cumulative+count+metric+for+all+Kafka+rate+metricsAlso made locking in Sensor for `CompoundStat` consistent with simple `Stat`, avoiding locking the whole sensor.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3686 from rajinisivaram/KAFKA-5738",5
"MINOR: Fix Kafka Streams JavaDocs with regard to new StreamJoined class (#7627)Reviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-13088: Replace EasyMock with Mockito for ForwardingDisabledProcessorContextTest (#11051)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
MINOR: re-enable EosBetaUpgradeIntegrationTest (#8953)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"MINOR: Use CRC32 from standard library and remove custom implementation (#11736)We only use it in the legacy record formats (V0 and V1) and the CRC32implementation in the standard library has received various performanceimprovements over the years(https://bugs.openjdk.java.net/browse/JDK-8245512 is a recent example).Also worth noting that record formats V0 and V1 have been deprecatedsince Apache Kafka 3.0.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Kvicii <Karonazaba@gmail.com>",0
"KAFKA-4362; Consumer can fail after reassignment of the offsets topic partitionAuthor: MayureshGharat <gharatmayuresh15@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #2116 from MayureshGharat/KAFKA-4362",5
KAFKA-5354; MirrorMaker not preserving headersHeaders are only preserved if the new consumer isused since the old consumer does not supportthem.Add test case to verify the fix and to avoid regression.Author: Michael Andre Pearce <Michael.Andre.Pearce@me.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3322 from michaelandrepearce/KAFKA-5354,0
KAFKA-995 Ensure that replica fetch size is > max message size on server.,5
"MINOR: make methods introduced in KAFKA-4490 consistent with KIP-100and remove some unnecessary SuppressWarnings annotationsAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #2363 from xvrl/kip-100-followup",5
"KAFKA-9274: Gracefully handle timeout exception (#8060)1. Delay the initialization (producer.initTxn) from construction to maybeInitialize; if it times out we just swallow and retry in the next iteration.2. If completeRestoration (consumer.committed) times out, just swallow and retry in the next iteration.3. For other calls (producer.partitionsFor, producer.commitTxn, consumer.commit), treat the timeout exception as fatal.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
KAFKA-2502; Documentation for quotasFollowed the approach specified here: https://issues.apache.org/jira/browse/KAFKA-2502I also made a minor fix to ConfigCommand to expose the right options on add-config.Author: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Gwen ShapiraCloses #381 from auradkar/K-2502,2
"KAFKA-3068: Remove retry with nodesEverSeenewencp ijuma if this looks good please merge when you can. Thanks.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #823 from enothereska/kafka-3068-alt",5
KAFKA-2401: Fix transient failure in ProducerSendTest.testCloseWithZeroTimeoutFromSenderThreadAuthor: Jiangjie Qin <becket.qin@gmail.com>Reviewers: GuozhangCloses #113 from becketqin/KAFKA-2401 and squashes the following commits:7d4223d [Jiangjie Qin] KAFKA-2401: fix transient failure in ProducerSendTest.testCloseWithZeroTimeoutFromSenderThread,3
KAFKA-9928: Fix flaky GlobalKTableEOSIntegrationTest (#8600)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
"MINOR: Factor out some common group/transactional fields in request objectsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: tedyu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4047 from hachikuji/factor-out-some-common-fields",5
trivial change to increase default offset commit interval to reduce ZK load,1
Remove the html end tag from upgrade.html,4
MINOR: Fix missing word in LogLoader logged warning (#11150)Reviewers: David Arthur <mumrah@gmail.com>,2
"MINOR: Simplify the create partition metadata type. (#7930)Changed `CreatePartitionMetadata` to not include partition assignmentinformation since this is not needed to generate a`CreatePartitionResponse` message.Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Implement ConfigEntry.toString()Author: Paolo Patierno <ppatierno@live.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3551 from ppatierno/admin_config_entry",5
"KAFKA-13900 Support Java 9 direct ByteBuffer Checksum methods (#12163)Some numbers with JDK 11.Before:```Benchmark                 (bytes)  (direct)  (readonly)  (seed)   Mode  Cnt   Score    Error   UnitsCrc32CBenchmark.checksum      128     false       false      42  thrpt   20  26.730 ±  0.410  ops/usCrc32CBenchmark.checksum      128      true       false      42  thrpt   20   1.781 ±  0.007  ops/usCrc32CBenchmark.checksum     1024     false       false      42  thrpt   20   6.553 ±  0.053  ops/usCrc32CBenchmark.checksum     1024      true       false      42  thrpt   20   0.223 ±  0.001  ops/usCrc32CBenchmark.checksum     4096     false       false      42  thrpt   20   4.054 ±  0.015  ops/usCrc32CBenchmark.checksum     4096      true       false      42  thrpt   20   0.056 ±  0.001  ops/us```And this PR:```Benchmark                 (bytes)  (direct)  (readonly)  (seed)   Mode  Cnt   Score   Error   UnitsCrc32CBenchmark.checksum      128     false       false      42  thrpt   20  26.922 ± 0.065  ops/usCrc32CBenchmark.checksum      128      true       false      42  thrpt   20  24.656 ± 0.620  ops/usCrc32CBenchmark.checksum     1024     false       false      42  thrpt   20   6.548 ± 0.025  ops/usCrc32CBenchmark.checksum     1024      true       false      42  thrpt   20   6.432 ± 0.136  ops/usCrc32CBenchmark.checksum     4096     false       false      42  thrpt   20   4.031 ± 0.022  ops/usCrc32CBenchmark.checksum     4096      true       false      42  thrpt   20   4.004 ± 0.016  ops/us```The purpose of the PR is to makes heap and direct ByteBuffer able to perform the same (especiallynot read-only), without affecting the existing heap ByteBuffer performance.Reviewers: Ismael Juma <ismael@juma.me.uk>, Divij Vaidya <diviv@amazon.com>",1
KAFKA-7253; The returned connector type is always null when creating connector (#5470)The null map returned from the current snapshot causes the null type in response. The connector class name can be taken from the config of request instead since we require the config should contain the connector class name.Reviewers: Jason Gustafson <jason@confluent.io>,5
"HOTFIX: ClassCastException in request loggingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ewen Cheslack-Postava <me@ewencp.org>Closes #2566 from hachikuji/hotfix-request-logging",2
"KAFKA-12992; Make kraft configuration properties public (#10971)This patch makes the following KRaft configurations public:- `process.roles`- `node.id`- `initial.broker.registration.timeout.ms`- `broker.heartbeat.interval.ms`- `broker.session.timeout.ms`- `metadata.log.dir`- `controller.listener.names`- `sasl.mechanism.controller.protocol`Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-9741: Update ConsumerGroupMetadata before calling onPartitionsRevoked() (#8325)If partitions are revoked, an application may want to commit the current offsets.Using transactions, committing offsets would be done via the producer passing in the current ConsumerGroupMetadata. If the metadata is not updates before the callback, the call to commitTransaction(...) fails as and old generationId would be used.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
MINOR: Update documentation.html to refer to 2.5 (#8744),2
"KAFKA-9274: Add timeout handling for `StreamPartitioner` (#9997) Part of KIP-572: When a custom `StreamPartitioner` is used, we need to get the number of partitions of output topics from the producer. This `partitionFor(topic)` call may through a `TimeoutException` that we now handle gracefully.Reviewers: John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
KAFKA-9758: Doc changes for KIP-523 and KIP-527 (#8343)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-4709：Error message from Struct.validate() should include the name of the offending field.https://issues.apache.org/jira/browse/KAFKA-4709Author: Aegeaner <xihuke@gmail.com>Reviewers: Dong Lin, Guozhang WangCloses #2521 from Aegeaner/KAFKA-4709",0
MINOR: Adds entity-specific flags to ConfigCommand per KIP-543. (#7667)Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
"KAFKA-10614: Ensure group state (un)load is executed in the right order (#9441)Co-authored-by: Jason Gustafson<jason@confluent.io>Reviewers: Jason Gustafson<jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-13498: track position in remaining state stores (#11541)Reviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, John Roesler<vvcephei@apache.org>",5
"KAFKA-9743: Catch commit offset exception to eventually close dirty tasks (#8327)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Upgrade Netty and Jackson versions for CVE fixes [KAFKA-14044] (#12376)Reviewers: Luke Chen <showuon@gmail.com>,0
"KAFKA-13466: delete unused config batch.size in kafka-console-producer.sh (#11517)delete unused config batch.size in kafka-console-producer.shReviewer: Andrew Eugene Choi <andrew.choi@uwaterloo.ca>, Luke Chen <showuon@gmail.com>,",5
"MINOR: Fix flaky test TopicCommandIntegrationTest.testDescribeAtMinIsrPartitions(String).quorum=kraft (#12189)Flaky test as failed in CI https://ci-builds.apache.org/blue/organizations/jenkins/Kafka%2Fkafka-pr/detail/PR-12184/1/tests/The test fails because it does not wait for metadata to be propagated across brokers before killing a broker which may lead to it getting stale information. Note that a similar test was done in #12104 for a different test.Reviewers: Kvicii Y, Ziming Deng, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-13786: Add a note in`control.plane.listener.name` doc (#11978)Add a note in `control.plane.listener.name` doc to mention the value can't be identical with `inter.broker.listener.name`.Reviewers: Luke Chen <showuon@gmail.com>,2
MINOR: Temporarily remove the apiVersions API for 0.11Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3324 from cmccabe/removeApiVersions,4
"KAFKA-7164; Follower should truncate after every missed leader epoch change (#5436)Currently, we skip the steps to make a replica a follower if the leader does not change, including truncating the follower log if necessary. This can cause problems if the follower has missed one or more leader updates. Change the logic to only skip the steps if the new epoch is the same or one greater than the old epoch. Tested with unit tests that verify the behavior of `Partition` and that show log truncation when the follower's log is ahead of the leader's, the follower has missed an epoch update, and the follower receives a `LeaderAndIsrRequest` making it a follower.Reviewers: Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>",5
"HOTFIX: failing to close this iterator causes leaks in rocksdbguozhangwang dguyAuthor: dan norwood <norwood@confluent.io>Reviewers: Damian Guy, Michael G. Noll, Guozhang WangCloses #2122 from norwood/close-call",5
"MINOR: Fix test name typo in StoresTest (#8006)Reviewers: Ron Dagostino <rdagostinoconfluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-8447: New Metric to Measure Number of Tasks on a Connector (#6843)Implemented KIP-475 to add new metrics for each worker to expose the number of current tasks per connector and per status.Author: Cyrus Vafadari <cyrus@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>, Boyang Chen <Boyang Chen <boyang@confluent.io>",5
KAFKA-6724; ConsumerPerformance should not always reset to earliest offsets (#4787)Remove the explicit `seekToBeginning` on startup and instead rely on the consumer's auto offset reset strategy to set the initial position.,5
kafka-649; Cleanup log4j logging; patched by Jun Rao; reviewed by Jay Kreps,2
Trivial commit - explicitly exclude build/** from rat check,5
"KAFKA-8601: Implement KIP-480: Sticky Partitioning for keyless records (#6997)Implement KIP-480, which specifies that the default partitioner should use a ""sticky"" partitioning strategy for records that have a null key.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Lucas Bradstreet <lucasbradstreet@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>, Kamal Chandraprakash  <kamal.chandraprakash@gmail.com>",1
KAFKA-6051; Close the ReplicaFetcherBlockingSend earlier on shutdownRearranged the testAddPartitionDuringDeleteTopic() test to keep thelikelyhood of the race condition.Author: Maytee Chinavanichkit <maytee.chinavanichkit@linecorp.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #4056 from mayt/KAFKA-6051,3
"KAFKA-12379: Allow configuring the location of the offset-syncs topic with MirrorMaker2 (#10221)This commit implements KIP-716. It introduces a new setting `offset-syncs.topic.location` that allows specifying where the offset-syncs topic is created.Reviewers: Tom Bentley <tbentley@redhat.com>, Edoardo Comar <ecomar@uk.ibm.com>",1
"KAFKA-13512: Avoid duplicating maps in ZkMetadataCache topic accessorsReviewers: Colin P. McCabe <cmccabe@apache.org>, Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
"[KAFKA-7379] [streams] send.buffer.bytes should be allowed to set -1 in KafkaStreams (#5643)What changes were proposed in this pull request?atLeast(0) in StreamsConfig, ProducerConfig and ConsumerConfig were replaced by SEND_BUFFER_LOWER_BOUND and RECEIVE_BUFFER_LOWER_BOUND from CommonClientConfigs.How was this patch tested?Three unit tests were added to KafkaStreamsTestReviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
MINOR: Remove an unnecessary character from broker's startup logAuthor: Kengo Seki <sekikn@apache.org>Reviewers: Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6628 from sekikn/remove-unnecessary-character,4
KAFKA-8410: KTableProcessor migration groundwork (#10744)* Lay the groundwork for migrating KTable Processors to the new PAPI.* Migrate the KTableFilter processor to prove that the groundwork works.This is an effort to help break up #10507 into multiple PRs.Reviewers: Boyang Chen <boyang@apache.org>,4
"MINOR: Fix transient failure in SelectorTest.testCloseConnectionInClosingState`SelectorTest.testCloseConnectionInClosingState` creates a channel with some staging receives and moves time forward to expire the channel. To ensure that the channel will be expired on the next poll, the channel must be muted to avoid expiry time being updated if more data is available for read.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3823 from rajinisivaram/MINOR-SelectorTest-closingChannel",5
"MINOR: Fix `testResolveDnsLookup` by using a mocked dns resolver (#11091)This focuses on the currently failing test, #9315 is a more complete fixthat we should also review and merge.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Include isolationLevel in toString of FetchRequestAuthor: Jacek Laskowski <jacek@japila.pl>Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #4038 from jaceklaskowski/KAFKA-4818-isolationLevel",5
"KAFKA-9123 Test a large number of replicas (#7621)Two tests using 50k replicas on 8 brokers:* Do a rolling restart with clean shutdown, delete topics* Run produce bench and consumer bench on a subset of topicsReviewed-By: David Jacot <djacot@confluent.io>, Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-2934; Offset storage file configuration in Connect standalone mode is not included in StandaloneConfigAdded offsetBackingStore config to StandaloneConfig and DistributedConfig;Added config for offset.storage.topic and config.storage.topic into DistributedConfig;Author: jinxing <jinxing@fenbi.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #734 from ZoneMayor/trunk-KAFKA-2934",1
"KAFKA-8392: Fix old metrics leakage by brokers that have no leadership over any partition for a topic (#6977)* Added removeOldLeaderMetrics in BrokerTopicStats to remove MessagesInPerSec, BytesInPerSec, BytesOutPerSec for any broker that is no longer a leader of any partition for a particular topic* Modified ReplicaManager to remove the metrics of any topic that the current broker has no leadership (meaning the broker either becomes a follower for all of the partitions in that topic or stops being a replica)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>",4
HOTFIX: Hotfix streams smoke testAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2149 from enothereska/hotfix-streams-smoke-test,3
"MINOR: Add 2.1 version metadata upgrade (#6111)Updated the test_metadata_upgrade test. To enable using the 2.1 version I needed to add config change to the StreamsUpgradeTestJobRunnerService to ensure the ductape passes proper args when starting the StreamsUpgradeTestFor testing, I ran the test_metadata_upgrade test and all versions now pass http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2019-01-09--001.1547049873--bbejeck--MINOR_add_2_1_version_metadata_upgrade--a450c68/report.htmlReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Small cleanups in the AclAuthorizer (#11921)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
"MINOR: Streams input topic corrected (#6513)Though out the tutorial, the name of the input topic that was created is `streams-plaintext-input`. However, this was mistaken at some point in the tutorial and changed to `streams-wordcount-input`.This patch is to adjust that. Thanks.Reviewers: Guozhang Wang <wangguoz@gmail.com>",4
"KAFKA-5852: Add filter, filterNot, mapValues and Materialized to KTableAdd overloads of `filter`, `filterNot`, `mapValues` that take `Materialized` as a param to `KTable`. Deprecate overloads using `storeName` and `storeSupplier`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3807 from dguy/ktable-filter-map",5
MINOR: Reduce log level to Trace for fetch offset downgrade (#8093)Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-391 Refactor fetch/producer requests to use maps instead of several arrays; patched by Joel Koshy; reviewed by Jun Rao.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1386806 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-13469: Block for in-flight record delivery before end-of-life source task offset commit (#11524)Although committing source task offsets without blocking on the delivery of all in-flight records is beneficial most of the time, it can lead to duplicate record delivery if there are in-flight records at the time of the task's end-of-life offset commit.A best-effort attempt is made here to wait for any such in-flight records to be delivered before proceeding with the end-of-life offset commit for source tasks. Connect will block for up to offset.flush.timeout.ms milliseconds before calculating the latest committable offsets for the task and flushing those to the persistent offset store.Author: Chris Egerton <chrise@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"KAFKA-8803: Remove timestamp check in completeTransitionTo (#8278)In prepareAddPartitions the txnStartTimestamp could be updated as updateTimestamp, which is assumed to be always larger then the original startTimestamp. However, due to ntp time shift the timer may go backwards and hence the newStartTimestamp be smaller than the original one. Then later in completeTransitionTo the time check would fail with an IllegalStateException, and the txn would not transit to Ongoing.An indirect result of this, is that this txn would NEVER be expired anymore because only Ongoing ones would be checked for expiration.We should do the same as in #3286 to remove this check.Also added test coverage for both KAFKA-5415 and KAFKA-8803.Reviewers: Jason Gustafson<jason@confluent.io>",5
"KAFKA-7657: Fixing thread state change to instance state change (#6018)While looking into KAFKA-7657, I found there are a few loopholes in this logic:1. We kept a map of thread-name to thread-state and a global-thread state at the KafkaStreams instance-level, in addition to the instance state itself. stateLock is used when accessing the instance state, however when we are in the thread state change callback, we are accessing both the thread-states as well as the instance state at the same time in the callers of setState without a lock, which is vulnerable to concurrent multi-stream threads. The fix is a) introduce a threadStatesLock in addition to the stateLock, which should always be grabbed to modify the thread-states map before the stateLock for modifying the instance level; and we also defer the checking of the instance-level state inside the setState call.2. When transiting to state.RUNNING, we check if all threads are either in RUNNING or DEAD state, this is because some threads maybe dead at the rebalance period but we should still proceed to RUNNING if the rest of threads are still transiting to RUNNING.Added unit test for 2) above. Also simplified another test as a nit change.Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>",1
KAFKA-4276: Add REST configuration in connector propertiesAddition of REST configuration in connect-distributed.properties config filegwenshap ewencp - Please review.Author: Akhilesh Naidu <akhilesh_naidu@persistent.com>Reviewers: Gwen ShapiraCloses #2505 from akhilesh1194/JIRA_KAFKA-4276,2
"MINOR: Use `Record` instead of `ByteBufferMessageSet` in `ProduceRequestTest`We want to phase out `ByteBufferMessageSet` eventually, so new code should favour `Record` where possible.Also use a fixed timestamp in `testCorruptLz4ProduceRequest` to ensure thatthe checksum is always the same.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson, Guozhang WangCloses #1357 from ijuma/produce-request-test-improvement",3
"MINOR: fix consumer group failure message typo (#6962)Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: Add NullPayloadGenerator to Trogdor (#4844),1
"KAFKA-5202: Handle topic deletion while trying to send txn markersHere is the sketch of this proposal:1. When it is time to send the txn markers, only look for the leader node of the partition once instead of retrying, and if that information is not available, it means the partition is highly likely been removed since it was in the cache before. In this case, we just remove the partition from the metadata object and skip putting into the corresponding queue, and if all partitions' leader broker are non-available, complete this delayed operation to proceed to write the complete txn log entry.2. If the leader id is unknown from the cache but the corresponding node object with the listener name is not available, it means that the leader is likely unavailable right now. Put it into a separate queue and let sender thread retry fetching its metadata again each time upon draining the queue.One caveat of this approach is the delete-and-recreate case, and the argument is that since all the messages are deleted anyways when deleting the topic-partition, it does not matter whether the markers are on the log partitions or not.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3130 from guozhangwang/K5202-handle-topic-deletion",4
"KAFKA-9074: Correct Connect’s `Values.parseString` to properly parse a time and timestamp literal (#7568)* KAFKA-9074: Correct Connect’s `Values.parseString` to properly parse a time and timestamp literalTime and timestamp literal strings contain a `:` character, but the internal parser used in the `Values.parseString(String)` method tokenizes on the colon character to tokenize and parse map entries. The colon could be escaped, but then the backslash character used to escape the colon is not removed and the parser fails to match the literal as a time or timestamp value.This fix corrects the parsing logic to properly parse timestamp and time literal strings whose colon characters are either escaped or unescaped. Additional unit tests were added to first verify the incorrect behavior and then to validate the correction.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Chris Egerton <chrise@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Jason Gustafson <jason@confluent.io>",5
MINOR: Partition is under reassignment when adding and removing (#8364)A partition is under reassignment if the either the set of addingreplicas or set removing replicas is non-empty.Fix the test assertion such that it prints stdout on failure.Reviewers: Ismael Juma <ismael@juma.me.uk>,0
"KAFKA-6813: Remove deprecated APIs in KIP-182, Part III (#4991)1. Remove TopologyBuilder, TopologyBuilderException, KStreamBuilder,2. Completed the leftover work of https://issues.apache.org/jira/browse/KAFKA-5660, when we remove TopologyBuilderException.3. Added MockStoreBuilder to replace MockStateStoreSupplier, remove all XXStoreSupplier except StateStoreSupplier as it is still referenced in the logical streams graph.4. Minor: rename KStreamsFineGrainedAutoResetIntegrationTest.java to FineGrainedAutoResetIntegrationTest.java.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Reduce required occurrance from 100 to 10 (#5048)Due to #4644 the consumer connector logs will be much more clean with fewer ""broker may not be available"" entries. We need to reduce the required frequency from 100 to a smaller number.I've thought about reducing to just 1, but it may still be transient (i.e. even if broker is starting up you may see a few entries) so I reduced it to 10.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: add retry to state dir lockingThere is a possibility that the state directory locking fails when another stream thread is taking long to close all tasks. Simple retries should alleviate the problem.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #899 from ymatsuda/minor2,5
KAFKA-12203 Migrate connect:mirror-client module to JUnit 5 (#9889)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-6367: StateRestoreListener use actual last restored offset for restored batch (#4507)Author: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
kafka-1453 (follow-up); Add a channel queue jmx in Mirror Maker;  patched by Guozhang Wang; reviewed by Jun Rao,1
"KAFKA-9567: Docs, system tests for ZooKeeper 3.5.7These changes depend on [KIP-515: Enable ZK client to use the new TLS supported authentication](https://cwiki.apache.org/confluence/display/KAFKA/KIP-515%3A+Enable+ZK+client+to+use+the+new+TLS+supported+authentication), which was only added to 2.5.0. The upgrade to ZooKeeper 3.5.7 was merged to both 2.5.0 and 2.4.1 via https://issues.apache.org/jira/browse/KAFKA-9515, but this change must only be merged to 2.5.0 (it will break the system tests if merged to 2.4.1).Author: Ron Dagostino <rdagostino@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Andrew Choi <li_andchoi@microsoft.com>Closes #8132 from rondagostino/KAFKA-9567",2
MINOR: add java 8/scala 2.12 deprecation info in doc (#12261)Reviewers: Ismael Juma <mlists@juma.me.uk>,2
"KAFKA-7804: Update docs for topic-command related KIP-377This PR adds a upgrade notes and changes examples to use the bootstrap-server.Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Reviewers: Srinivas <srinivas96alluri@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6118 from viktorsomogyi/topiccommand-adminclient-doc",2
"KAFKA-9561: Update task input partitions after rebalance (#8221)Co-authored-by: Vyacheslav Stepanenko <vstepanenko@aligntech.com>Co-authored-by: Guozhang Wang <wangguoz@gmail.com>Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: add MacOS requirement to Streams docs*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill BejeckCloses #6490 from mjsax/minor-streams-docs-rocksdb",5
"MINOR: Enable topic deletion in the KIP-500 controller (#10184)This patch enables delete topic support for the new KIP-500 controller. Also fixes the following:- Fix a bug where feature level records were not correctly replayed.- Fix a bug in TimelineHashMap#remove where the wrong type was being returned.Reviewers: Jason Gustafson <jason@confluent.io>, Justine Olshan <jolshan@confluent.io>, Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>Co-authored-by: Jason Gustafson <jason@confluent.io>",5
KAFKA-534 remove client library directorygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1390784 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-7485: Wait for truststore update request to complete in test (#5791)Reviewers: Jason Gustafson <jason@confluent.io>,5
"MINOR: Update copyright year in NOTICEAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4529 from ewencp/update-NOTICE-year",5
"MINOR: Upstream ApisUtils from kip-500 (#9715)In the [KIP-500 development branch](https://github.com/confluentinc/kafka/tree/kip-500),we have a separate ControllerApis that shares a lot of functionality with KafkaApis. Weintroduced a utility class ApisUtils to pull out the common code. Some things were movedto RequestChannel as well.We'd like to upstream this work now so we don't continue to diverge (since KafkaApis isa frequently modified class). There should be no logical changes in this PR, only shufflingcode around.Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jose Sancio <jsancio@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",1
KAFKA-1890 Fix bug preventing Mirror Maker from successful rebalance; reviewed by Gwen Shapira and Neha Narkhede,1
KAFKA-1253 Compression in the new producer: follow up patch to push new files,2
"[MINOR] Improve docs for Global Store operations (#6803)A lot of confusion seems to have arisen from the StreamBuilder#addGlobalStore(...ProcessorSupplier) method. Users have assumed they can safely use this to transform records before populating their global state store; unfortunately this results in corrupted data as on restore the records are read directly from the source topic changelog, bypassing their custom processor.We should probably provide a means to do this at some point but for the time being we should clarify the proper use of #addGlobalStore as it currently functionsReviewers:  Matthias J. Sax <mjsax@apache.org>, Bruno Cadonna <bruno@confluent.io>",5
"MINOR: Increase the Kafka shutdown timeout to 120 (#11183)The streams static membership test has failed several times due to hitting the Kafka shutdown timeout, but the logs were showing that the shutdown did actually succeed after the 60 second timeout.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Walker Carlson <wcarlson@confluent.io>",5
"KAFKA-10540: Migrate KStream aggregate operations (#11315)As part of the migration of KStream/KTable operations to the newProcessor API https://issues.apache.org/jira/browse/KAFKA-8410,this PR includes the migration of KStream aggregate/reduce operations.Reviewers: John Roesler <vvcephei@apache.org>",0
MINOR: Update the javadoc in GroupMetadataManager.scala (#9241)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTo……picMetadata()Author: Grant Henke <granthenke@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #117 from granthenke/invalid-topic and squashes the following commits:0abda5f [Grant Henke] KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTopicMetadata(),5
MINOR: Fix typo (#4426)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-8860: Let SslPrincipalMapper split SSL principal mapping rulesAuthor: teebee <tb@teebee.de>Reviewers: Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #7140 from teebee/teebee/ssl-principal-mapping-rules-handling,5
"KAFKA-6499: Do not write offset checkpoint file with empty offset map (#4492)* In Checkpoint.write(), if the offset map passed in is empty, skip the writing of the file which would only contain version number and the empty size. From the reading pov, it is the same as no file existed.* Add related unit tests.* Minor fixes on log4j messages.Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-6252; Close the metric group to clean up any existing metricsWe are closing the metricGroups created in a Worker, Source task and Sink task before populating them with new metrics. This helps in cases where an Exception is thrown when previously created groups were not cleaned up correctly.Signed-off-by: Arjun Satish <arjunconfluent.io>Author: Arjun Satish <arjun@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4397 from wicknicks/KAFKA-6252",5
"MINOR: StreamsPartitionAssignor should log the individual members of each client (#10996)Log the specific StreamThreads participating in the rebalance for each client in the Streams applicationReviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: Added a couple of unit tests for KStreamPrint node when values are bytesWith current tests, the deserialization inside the KStreamPrint node processor which happens when key and/or values are byte[] isn't tested. This PR fixes that.Author: Paolo Patierno <ppatierno@live.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bbejeck@gmail.com>Closes #3611 from ppatierno/minor-kstream-print-test",3
kafka-931; make zookeeper.connect a required property; patched by Jun Rao; reviewed by Neha Narkhede,5
MINOR: remove duplicate code of serializing auto-generated data (#10128)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
KAFKA-5368: Fix skipped record metrics to use rate of sum instead of rate of countThis resolved the issue with Kafka Streams skipped records sensor reporting wrong values.Jira ticket: https://issues.apache.org/jira/browse/KAFKA-5368The contribution is my original work and I license the work to the project under the project's open source license.Author: Hamidreza Afzali <hrafzali@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3206 from hrafzali/KAFKA-5368_skipped-records-sensor-bug,0
single_host_multi_brokers system test fails on laptop; patched by John Fung; reviewed by Jun Rao; kafka-413git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1366085 13f79535-47bb-0310-9956-ffa450edef68,0
"KAFKA-2924: support offsets topic in DumpLogSegmentsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #622 from hachikuji/KAFKA-2924",5
"HOTFIX: Modify system test config to reduce time to stable task assignment. (#11090)Currently, we verify the startup of a Streams client by checking the transitionfrom REBALANCING to RUNNING and if the client processed some recordsin the EOS system test. However, if the Streams client onlyhas standby tasks assigned as it can happen if the client is catching up by using warm-up replicas, the client will never processrecords within the timeout of the startup verification. Hence, the test will fail although everything is fine. This commit fixes this by reducingthe time to the next probing rebalance and by increasing the number of max warm-up replicas. In such a way, the catch up of the client and the following processing of records should still be within the startup verification timeout of the client.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
KAFKA-3580; Improve error logging in ReplicaFetchThreadAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1237 from omkreddy/KAFKA-3580,2
"KAFKA-3911: KTable source materializationAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #1638 from enothereska/KAFKA-3911-ktable-materialization",2
KAFKA-4100: Ensure 'fields' and 'fieldsByName' are not null for Struct schemasAuthor: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1800 from shikhar/kafka-4100,5
"KAFKA-12575: Eliminate Log.isLogDirOffline boolean attribute (#10430)This PR is a precursor to the recovery logic refactor work (KAFKA-12553).I have made a change to eliminate Log.isLogDirOffline attribute. This boolean also comes in the way of refactoring the recovery logic. This attribute was added in #9676. But it is redundant and can be eliminated in favor of looking up LogDirFailureChannel to check if the logDir is offline. The performance/latency implication of such a ConcurrentHashMap lookup inside LogDirFailureChannel should be very low given that ConcurrentHashMap reads are usually lock free.Tests:Relying on existing unit/integration tests.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-8637: WriteBatch objects leak off-heap memory (#7050)Should be cherry-picked back to 2.3 (picked from 2.2 to 2.1 in 7077 )Reviewers: pkleindl <44436474+pkleindl@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: Update authorization primitives in security.html (#7509)Since 2.3, there are 5 new APIs: ElectPreferredLeaders, IncrementalAlterConfigs, AlterPartitionReassignments, DescribePartitionReassignments and OffsetDeleteReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",4
"KAFKA-12648: fix #getMinThreadVersion and include IOException + topologyName in StreamsException when topology dir cleanup fails (#11867)Quick fix to make sure we log the actual source of the failure both in the actual log message as well as the StreamsException that we bubble up to the user's exception handler, and also to report the offending topology by filling in the StreamsException's taskId field.Also prevents a NoSuchElementException from being thrown when trying to compute the minimum topology version across all threads when the last thread is being unregistered during shutdown.Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
"MINOR: Upgrade rocksdb to 5.14.2 (#5343)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-3959: enforce offsets.topic.replication.factor upon __consumer_offsets auto topic creation (KIP-115)Kafka brokers have a config called ""offsets.topic.replication.factor"" that specify the replication factor for the ""__consumer_offsets"" topic. The problem is that this config isn't being enforced. If an attempt to create the internal topic is made when there are fewer brokers than ""offsets.topic.replication.factor"", the topic ends up getting created anyway with the current number of live brokers. The current behavior is pretty surprising when you have clients or tooling running as the cluster is getting setup. Even if your cluster ends up being huge, you'll find out much later that __consumer_offsets was setup with no replication.The cluster not meeting the ""offsets.topic.replication.factor"" requirement on the internal topic is another way of saying the cluster isn't fully setup yet.The right behavior should be for ""offsets.topic.replication.factor"" to be enforced. Topic creation of the internal topic should fail with GROUP_COORDINATOR_NOT_AVAILABLE until the ""offsets.topic.replication.factor"" requirement is met. This closely resembles the behavior of regular topic creation when the requested replication factor exceeds the current size of the cluster, as the request fails with error INVALID_REPLICATION_FACTOR.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2177 from onurkaraman/KAFKA-3959",5
"KAFKA-7395; Add fencing to replication protocol (KIP-320) (#5661)This patch contains the broker-side support for the fencing improvements from KIP-320. This includes the leader epoch validation in the ListOffsets, OffsetsForLeaderEpoch, and Fetch APIs as well as the changes needed in the fetcher threads to maintain and use the current leader epoch. The client changes from KIP-320 will be left for a follow-up.One notable change worth mentioning is that we now require the read lock in `Partition` in order to read from the log or to query offsets. This is necessary to ensure the safety of the leader epoch validation. Additionally, we forward all leader epoch changes to the replica fetcher thread and go through the truncation phase. This is needed to ensure the fetcher always has the latest epoch and to guarantee that we cannot miss needed truncation if we missed an epoch change.Reviewers: Jun Rao <junrao@gmail.com>",4
"KAFKA-10199: Bookkeep tasks during assignment for use with state updater (#12442)Bookkeeps tasks to be recycled, closed, and updated during handling of the assignment. The bookkeeping is needed for integrating the state updater.These change is hidden behind internal config STATE_UPDATER_ENABLED. If the config is false Streams should not use the state updater and behave as usual.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-5985; update javadoc regarding closing iteratorsAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Michael G. Noll <michael@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3994 from bbejeck/KAFKA-5985_document_need_to_close_iterators",2
MINOR: Remove unused compressionType parameter from TestUtils.produceMessages (#5569)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-8179: add public ConsumerPartitionAssignor interface (#7108)Main changes of this PR:* Deprecate old consumer.internal.PartitionAssignor and add public consumer.ConsumerPartitionAssignor with all OOTB assignors migrated to new interface* Refactor assignor's assignment/subscription related classes for easier to evolve API* Removed version number from classes as it is only needed for serialization/deserialization* Other previously-discussed cleanup included in this PR:* Remove Assignment.error added in pt 1* Remove ConsumerCoordinator#adjustAssignment added in pt 2Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4175: Can't have StandbyTasks in KafkaStreams where NUM_STREAM_THREADS_CONFIG > 1standby tasks should be assigned per consumer not per processAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1862 from dguy/kafka-4175",5
KAFKA-8158: Add EntityType for Kafka RPC fields (#6503)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-7538: Reduce lock contention for Partition ISR lock (#5866)Check for ISR updates using ISR read lock and acquire ISR write lock only if ISR needs to be updated. This avoids lock contention between request handler threads processing log appends on the leader holding the ISR read lock and request handler threads processing replica fetch requests that check/update ISR.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-1236 Fix various breakages in the perf tests. Make the producer test use either the old or the new producer.,1
MINOR: Fix NPE from addingReplicas and removingReplicas (#10992)Fix NPE from addingReplicas and removingReplicas. Make addingReplicas and removingReplicas in PartitionRecord non-nullable as described in KIP-746.Reviewers: Colin P. McCabe <cmccabe@apache.org>,4
kafka-827; improve list topic output format; patched by Jun Rao; reviewed by Neha Narkhede,1
KAFKA-4591; Create Topic Policy follow-up1. Added javadoc to public classes2. Removed `s` from config name for consistency with interface name3. The policy interface now implements Configurable and AutoCloseable as per the KIP4. Use `null` instead of `-1` in `RequestMetadata`5. Perform all broker validation before invoking the policy6. Add testsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2388 from ijuma/create-topic-policy-docs-and-config-name-change,5
MINOR: Consolidate FinalizedFeatureCache into MetadataCache (#12214)Reviewers: Colin P. McCabe <cmccabe@apache.org>,5
KAFKA-2089: Fix transient MetadataTest failure; reviewed by Jiangjie Qin and Guozhang Wang,0
"KAFKA-9974: Fix flaky test by removing unneeded asserts (#8646)The tests failed at assertThat(listener.startOffset, is(equalTo(0L)));. It looks like that it did a restore before the assert. But we should expect the restore sometimes happen to resume the failed tasks by itself. It should not cause the test failure under this situation.On the other hands, the original tests added the assertThat(listener.startOffset, is(equalTo(0L))); is because in the end of the test, we'll also test the startOffset value. But in the newer version of the test, we don't really care about the startOffset or totalNumRestored value. All we want to test in this test is:Assert that the current value in store reflects all messages being processedSo, removing the assert can avoid flaky test failure, and also be able to test what the test case want to test.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Remove unnecessary assertion from ConnectHeader (#9452)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
"MINOR: Update introduction page in Kafka documentation Although APIs section in Kafka documentation lists 5 core APIs (https://kafka.apache.org/documentation/#api), introduction page in Kafka documentation lists 4 of them. I've added the missing list element to fix this incoherence.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",0
MINOR: Fix error response handler for controlled shutdown v0Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3627 from hachikuji/minor-fix-controlled-shutdown-error-response,0
"KAFKA-9657: Throw upon offset fetch unsupported stable flag protocol  (#8265)This PR tries to add an internal flag to throw if we hit an unexpected protocol version for offset fetch. It could be used together with EOS_BETA flag so that if server side downgrades unexpectedly, we shall fail the application ASAP.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: A few logging improvements in the broker (#6773)Reviewers: Boyang Chen <bchen11@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-12909: add missing tests (#10893)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
"KAFKA-6287; Consumer group command should list simple consumer groups (#4407)With this patch, simple consumer groups which only use Kafka for offset storage will be viewable using the `--list` option in consumer-groups.sh. In addition, this patch fixes a bug in the offset loading logic which caused us to lose the protocol type of empty groups on coordinator failover. I also did some cleanup of the various consumer group command test cases.For testing, I have added new integration tests which cover listing and describing simple consumer groups. I also added unit tests to cover loading empty groups with assertions on the protocol type.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
KAFKA-14111 Fix sensitive dynamic broker configs in KRaft (#12455)Enable some of the dynamic broker reconfiguration tests in KRaft mode,3
"KAFKA-4259; Dynamic JAAS configuration for Kafka clients (KIP-85)Implementation of KIP-85: https://cwiki.apache.org/confluence/display/KAFKA/KIP-85%3A+Dynamic+JAAS+configuration+for+Kafka+clientsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1979 from rajinisivaram/KAFKA-4259",5
"MINOR: fix race condition in KafkaStreamsTest (#6185)Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Bug in serialize and collate logic in the DefaultEventHandler KAFKA-107; patched by Neha; reviewed by Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159452 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-12508: Disable KIP-557 (#10397)A major issue has been raised that this implementation ofemit-on-change is vulnerable to a number of data-loss bugsin the presence of recovery with dirty state under at-least-oncesemantics. This should be fixed in the future when we implementa way to avoid or clean up the dirty state under at-least-once,at which point it will be safe to re-introduce KIP-557 andcomplete it.Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",4
"KAFKA-8294; Batch StopReplica requests when possible and improve test coverage (#6642)The main problem we are trying to solve here is the batching of StopReplica requests and the lack of test coverage for `ControllerChannelManager`. Addressing the first problem was straightforward, but the second problem required quite a bit of work because of the dependence on `KafkaController` for all of the events. It seemed to make sense to separate the events from the processing of events so that we could remove this dependence and improve testability. With the refactoring, I was able to add test cases covering most of the logic in `ControllerChannelManager` including the generation of requests and the expected response handling logic. Note that I have not actually changed any of the event handling logic in `KafkaController`.While refactoring this logic, I found that the event queue time metric was not being correctly computed. The problem is that many of the controller events were singleton objects which inherited the `enqueueTimeMs` field from the `ControllerEvent` trait. This would never get updated, so queue time would be skewed.Reviewers: Jun Rao <junrao@gmail.com>",5
"MINOR: call super.close() when closing RocksDB options (#9498)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: fix transient QueryableStateIntegration test failureThe verification in verifyGreaterOrEqual was incorrect. It was failing when a new key was found.Set the TimeWindow to a large value so all windowed results fall in a single windowAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1833 from dguy/minor-test-fix,3
"KAFKA-4184; Intermittent failures in ReplicationQuotasTest.shouldBootstrapTwoBrokersWithFollowerThrottleBuild is unstable, so it's hard to validate this change. Of the various builds up until 11am BST the test ran twice and passed twice.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1873 from benstopford/KAFKA-4184",4
"KAFKA-4260; Disallow non-routable address in advertised.listenersAs described in the JIRA ticket, when `listeners=PLAINTEXT://0.0.0.0:9092`(note the 0.0.0.0 ""bind all interfaces"" IP address) and`advertised.listeners` is not specified it defaults to `listeners`,but it makes no sense to advertise 0.0.0.0 as it's not a routable IPaddress.This patch checks for a 0.0.0.0 host in `advertised.listeners`(whether via default or not) and fails with a meaningful error if it'sfound.This contribution is my original work and I license the work to theproject under the project's open source license.Author: Tom Bentley <tbentley@redhat.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3382 from tombentley/advertised.listeners",1
KAFKA-6166: Update javadoc for streams config (#4489)This PR piggy-back a few different javadoc changes:* KIP-220: add admin client prefix.* Clarify on user customized configs.,5
Address code review feedbacks,5
"KAFKA-13851: Add integration tests for DeleteRecords API (#12087)Reviewers: Luke Chen <showuon@gmail.com>, dengziming <dengziming1993@gmail.com>",4
"KAFKA-3427: broker can return incorrect version of fetch response when the broker hits an unknown exceptionAuthor: Jun Rao <junrao@gmail.com>Reviewers: Ismael Juma, Becket QinCloses #1101 from junrao/kafka-3427",5
"KAFKA-9519: Deprecate the --zookeeper flag in ConfigCommand (#8056)Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rndgstn@gmail.com>",2
KAFKA-2788; Allow specifying principals with comman in ACL CLI.Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #489 from Parth-Brahmbhatt/KAFKA-2788,1
MINOR: Use TopicPartition in ConsumerGroupCommand instead of TopicAndPartition where possible (#4333)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-4024; Override client metadata backoff on topic changes and avoid unnecessary connectionsFixes a bug that inappropriately applies backoff as interval between metadata updates even though the current one is outdated.Author: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #1707 from kawamuray/KAFKA-4024-metadata-backoff",5
KAFKA-527; Use in-place decompression enabled inner iterator to replace old decompress function; reviewed by Joel Koshy and Jun Rao,1
KAFKA-3704: Remove hard-coded block size in KafkaProducerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael JumaCloses #1371 from guozhangwang/K3565-remove-compression-blocksize,4
"MINOR: update streams.html with KStream API changesmjsax guozhangwangAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #1534 from dguy/update-streams-doc",5
"KAFKA-9527: fix NPE when using time-based argument for Stream Resetter Tool (#10042)Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: cleaner resume log message is misleadingWhen the LogManager resumes cleaning it states that compaction is resumed, however the topic in question is not necessarily a compacted one.Author: Lucas Bradstreet <lucas@confluent.io>Reviewers: Gwen Shapira, Chia-Ping TsaiCloses #8466 from lbradstreet/bad-cleaning-message",4
KAFKA-5327: ConsoleConsumer should manually commit offsets for records that are returned in receive()KAFKA-5327: ConsoleConsumer should manually commit offsets for those records it really consumed. Currently it leaves this job to the automatic offset commit scheme where some unread messages will be passed if `--max-messages` is set.Author: amethystic <huxi_2b@hotmail.com>Author: huxi <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3148 from amethystic/KAFKA-5327_ConsoleConsumer_distable_autocommit,1
"KAFKA-6635; Producer close awaits pending transactions (#5971)Currently close() only awaits completion of pending produce requests. If there is a transaction ongoing, it may be dropped. For example, if one thread is calling commitTransaction() and another calls close(), then the commit may never happen even if the caller is willing to wait for it (by using a long timeout). What's more, the thread blocking in commitTransaction() will be stuck since the result will not be completed once the producer has shutdown. This patch ensures that 1) completing transactions are awaited, 2) ongoing transactions are aborted, and 3) pending callbacks are completed before close() returns.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: improve error message for Serde type miss match (#6801)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>",5
KAFKA-8886; Make Authorizer create/delete API asynchronous (#7316)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,4
KAFKA-2723: new consumer exception cleanupAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #441 from hachikuji/K2723,5
MINOR: enable KRaft in MinIsrConfigTest (#11635)Reviewers: José Armando García Sancio <jsancio@gmail.com>,5
Implement clean shutdown in replication; patched by Joel Koshy; reviewed by Jun Rao and Neha Narkhede; KAFKA-340git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1402395 13f79535-47bb-0310-9956-ffa450edef68,4
"MINOR: Remove copyDependantTestLibs from jar dependencies_copyDependantTestLibs_ was added temporarily as a dependency of _jar_ task to enable SASL system tests to be run with MiniKdc without changing the automated system test runs which run _gradlew clean jar_. Since the build target _systemTestLibs_ is already in Kafka build.gradle, the Confluent automated test runs can now run _gradlew clean systemTestLibs_ instead. This PR provides the final change to remove _copyDependantTestLibs_ from the _jar_ task. This should be committed only after the Confluent automated sytem test build script is updated, to avoid breaking any builds.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #430 from rajinisivaram/minor-systemtestlibs",5
MINOR: doc changes for QueueTimeMs JMX metrics.Author: Alex Loddengaard <alexloddengaard@gmail.com>Reviewers: Gwen ShapiraCloses #1706 from alexlod/doc-queuetimems-jmx,2
"KAFKA-5490; Skip empty record batches in the consumerThe actual fix for KAFKA-5490 is inhttps://github.com/apache/kafka/pull/3406.This is just the consumer change that will allow the cleanerto use empty record batches without breaking 0.11.0.0consumers (assuming that KAFKA-5490 does not make the cut).This is a safe change even if we decide to go with a different optionfor KAFKA-5490 and I'd like to include it in RC2.Author: Jason Gustafson <jason@confluent.io>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3408 from ijuma/kafka-5490-consumer-should-skip-empty-batches",5
KAFKA-13769 Fix version check in SubscriptionJoinForeignProcessorSupplier (#12420)This commit changes the version check from != to > as the process methodworks correctly on both version 1 and 2. != incorrectly throws on v1records.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Add compatibility tests for 2.4.0 (#7838)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-9251; Describing a non consumer group with the Admin API hangs forever (#7763)If a non-consumer group is specified in `describeConsumerGroup`, the future will hang indefinitely because the future callback is never completed. This patch fixes the problem by completing the future exceptionally with an `IllegalArgumentException`.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-12789: Remove Stale comments for meta response handling logic (#10700)Correct empty meta response comment, since it is no longer related only to brokers associating with the query topic.Reviewers: Boyang Chen <boyang@confluent.io>",5
MINOR: Fix link to old doc in quickstart (#12129)In Kafka's quickstart a link points to the 2.5 Kafka Streams demo.This PR fixes this link.,2
"KAFKA-8595: Support deserialization of JSON decimals encoded in NUMERIC  (#7354)Implemented KIP-481 by adding support for deserializing Connect DECIMAL values encoded in JSON as numbers, in addition to raw byte array (base64) format used previously.Author: Almog Gavra <almog@confluent.io>Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"MINOR: Doc changes for KIP-312 (#5789)Documentation changes for adding overloaded StreamsBuilder(java.util.Properties props) method in KIP-312Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-1305. Controller can hang on controlled shutdown with auto leader balance enabled; reviewed by Neha Narkhede and Jun Rao,0
"MINOR: Remove unused maxProducerIdExpirationMs parameter in Log constructor (#10723)Reviewers: Satish Duggana <satishd@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2
HOTFIX: add missing upgrade docs,2
"MINOR: correct package of LinuxIoMetricsCollector (#9271)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Lee Dongjin <dongjin@apache.org>",2
"MINOR: fix inaccurate RecordBatchIterationBenchmark.measureValidation benchmark (#8428)KAFKA-9820 (https://github.com/apache/kafka/pull/8422) added a benchmark of LogValidator.validateMessagesAndAssignOffsetsCompressed. Unfortunately it instantiated BrokerTopicStats within the benchmark itself, and it is expensive. The fixed benchmark does not change the outcome of the improvement in KAFKA-9820, and actually increases the magnitude of the improvement in percentage terms.```Updated benchmark before KAFKA-9820:Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt       Score      Error   UnitsRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15  164173.236 ± 2927.701   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate                         NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15   20440.980 ±  364.411  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15  137120.002 ±    0.002    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15   20708.378 ±  372.041  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15  138913.935 ±  398.960    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15       0.547 ±    0.107  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15       3.664 ±    0.689    B/opRecordBatchIterationBenchmark.measureValidation:·gc.count                              NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15    2713.000             countsRecordBatchIterationBenchmark.measureValidation:·gc.time                               NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15    1398.000                 msRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15  164305.533 ± 5143.457   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate                         NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15   20490.828 ±  641.408  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15  137328.002 ±    0.002    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15   20767.922 ±  648.843  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15  139185.616 ±  325.790    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15       0.681 ±    0.053  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15       4.560 ±    0.292    B/opRecordBatchIterationBenchmark.measureValidation:·gc.count                              NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15    3101.000             countsRecordBatchIterationBenchmark.measureValidation:·gc.time                               NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15    1538.000                 msRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15  169572.635 ±  595.613   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate                         NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15   21129.934 ±   74.618  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15  137216.002 ±    0.002    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15   21410.416 ±   70.458  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15  139037.806 ±  309.278    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15       0.312 ±    0.420  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15       2.026 ±    2.725    B/opRecordBatchIterationBenchmark.measureValidation:·gc.count                              NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15    3398.000             countsRecordBatchIterationBenchmark.measureValidation:·gc.time                               NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15    1701.000                 msJMH benchmarks doneUpdated benchmark after KAFKA-9820:Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (maxBatchSize)  (messageSize)  (messageVersion)   Mode  Cnt       Score     Error   UnitsRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15  322678.586 ± 254.126   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate                         NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15   20376.474 ±  15.326  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15   69544.001 ±   0.001    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15   20485.394 ±  44.087  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15   69915.744 ± 143.372    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15       0.027 ±   0.002  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15       0.091 ±   0.008    B/opRecordBatchIterationBenchmark.measureValidation:·gc.count                              NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15    3652.000            countsRecordBatchIterationBenchmark.measureValidation:·gc.time                               NO_CACHING   RANDOM                LZ4               1           1000                 2  thrpt   15    1773.000                msRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15  321332.070 ± 869.841   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate                         NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15   20303.259 ±  55.609  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15   69600.001 ±   0.001    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15   20394.052 ±  72.842  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15   69911.238 ± 160.177    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15       0.028 ±   0.003  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15       0.096 ±   0.010    B/opRecordBatchIterationBenchmark.measureValidation:·gc.count                              NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15    3637.000            countsRecordBatchIterationBenchmark.measureValidation:·gc.time                               NO_CACHING   RANDOM                LZ4               2           1000                 2  thrpt   15    1790.000                msRecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15  315490.355 ± 271.921   ops/sRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate                         NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15   19943.166 ±  21.235  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15   69640.001 ±   0.001    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space                NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15   20020.263 ±  43.144  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Eden_Space.norm           NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15   69909.228 ± 136.413    B/opRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen                   NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15       0.026 ±   0.002  MB/secRecordBatchIterationBenchmark.measureValidation:·gc.churn.G1_Old_Gen.norm              NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15       0.090 ±   0.008    B/opRecordBatchIterationBenchmark.measureValidation:·gc.count                              NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15    3571.000            countsRecordBatchIterationBenchmark.measureValidation:·gc.time                               NO_CACHING   RANDOM                LZ4              10           1000                 2  thrpt   15    1764.000                ms```Reviewers: Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Fixed introduction doc - wrong streams api linkAuthor: Jakub Dziworski <jakub.dziworski@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1996 from JakubDziworski/doc_fix_streams_link",2
KAFKA-773 kafka.integration.PrimitiveApiTest fails intermittently; reviewed by Neha Narkhede,0
"KAFKA-13614: Don't apply leader replication quota to consumer fetches (#11714)In the fetch path, we check shouldLeaderThrottle regardless of whether the read is coming from a consumer or follower broker. This results in replication quota being applied to consumer fetches. This patch ensures that it is only applied to followers.Reviewers: David Jacot <djacot@confluent.io>",5
kafka-1798; ConfigDef.parseType() should throw exception on invalid boolean value; patched by dokovan; reviewed by Jun Rao,5
"MINOR: Web docs for KIP-2201. added functions for KafkaStreams and KafkaClientSupplier.2. added prefix for admin client in StreamsConfig.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Matthias J. Sax <matthias@confluent.io>Closes #4338 from guozhangwang/K6150-doc-changes",4
MINOR: Improve assert in testCreateTopicsResponseMetadataAndConfig (#7484)It's much easier to debug when one can see the config names than onecan only see a number.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
kafka-1123; Broker IPv6 addresses parsed incorrectly; patched by Krzysztof Szafrański; reviewed by Jun Rao,1
"KAFKA-3561: Auto create through topic for KStream aggregation and joinguozhangwang enothereska mjsax migunoIf you get a chance can you please take a look at this. I've done the repartitioning in the join, but it results in 2 internal topics for each join. This seems like overkill as sometimes we wouldn't need to repartition at all, others just 1 topic, and then sometimes both, but I'm not sure how we can know that.I'd also need to implement something similar for leftJoin, but again, i'd like to see if i'm heading down the right path or if anyone has any other bright ideas.For reference - https://github.com/apache/kafka/pull/1453 - the previous PRThanks for taking the time and looking forward to getting some welcome advice :-)Author: Damian Guy <damian.guy@gmail.com>Author: Damian Guy <damian@continuum.local>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1472 from dguy/KAFKA-3561",1
MINOR: Fix transient failure in PreferredReplicaLeaderElectionCommandTest (#6908)We have seen this failing recently due to the follower error:```java.util.NoSuchElementException: None.getat scala.None$.get(Option.scala:366)at scala.None$.get(Option.scala:364)at kafka.admin.PreferredReplicaLeaderElectionCommandTest.getLeader(PreferredReplicaLeaderElectionCommandTest.scala:101)at kafka.admin.PreferredReplicaLeaderElectionCommandTest.testNoopElection(PreferredReplicaLeaderElectionCommandTest.scala:240)```We need to wait for the leader to be available.Reviewers: David Arthur <mumrah@gmail.com>,3
"KAFKA-12247: add timeout and static group rebalance to remove thread (#9984)Add timeout to remove thread, and trigger thread to explicitly leave the group even in case of static membershipReviewers: Bruno Cadonna <bruno@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"KAFKA-13862; Support Append/Subtract multiple config values in KRaft mode (#12108)We can append/subtract multiple config values in kraft mode using the `IncrementalAlterConfig` RPC. For example: append/subtract topic config ""cleanup.policy"" with value=""delete,compact"" will end up treating ""delete,compact"" as a value not 2 values. This patch fixes the problem. Additionally, it update the zk logic to correctly handle duplicate additions.Reviewers: Akhilesh Chaganti <akhileshchg@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Remove redundant allows in import-control.xml (#10339)1. Remove org.apache.log4j from allowed import list of shell, trogdor subpackage; they uses slf4j, not log4.2. Remove org.slf4j from allowed import list of clients, server subpackage: org.slf4j is allowed globally.3. Remove org.apache.log4j from streams subpackage's allowed import listReviewers: David Jacot <david.jacot@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2
MINOR: Doc updates for Kafka 3.0.1 (#11906)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-2979: Enable authorizer and ACLs in ducktape testsPatch by fpj and benstopford.Author: flavio junqueira <fpj@apache.org>Author: Flavio Junqueira <fpj@apache.org>Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ben Stopford <benstopford@gmail.com>, Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #683 from fpj/KAFKA-2979",5
KAFKA-8503; Add default api timeout to AdminClient (KIP-533) (#8011)This PR implements `default.api.timeout.ms` as documented by KIP-533. This is a rebased version of #6913 with some additional test cases and small cleanups.Reviewers: David Arthur <mumrah@gmail.com>Co-authored-by: huxi <huxi_2b@hotmail.com>,4
Move AddPartitions into TopicCommand,1
KAFKA-9432: automated protocol for DescribeConfigs (#8312)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
MINOR: Catch NoRecordsException in testCommaSeparatedRegex() test (#5944)This test sometimes fails with```kafka.tools.MirrorMaker$NoRecordsExceptionat kafka.tools.MirrorMaker$ConsumerWrapper.receive(MirrorMaker.scala:483)at kafka.tools.MirrorMakerIntegrationTest$$anonfun$testCommaSeparatedRegex$1.apply$mcZ$sp(MirrorMakerIntegrationTest.scala:92)at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:738)```The test should catch `NoRecordsException` instead of `TimeoutException`.Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"KAFKA-2492; Upgraded zkclient dependency from 0.5 to 0.6Author: Stevo Slavic <sslavic@gmail.com>Reviewers: Ismael Juma, Ewen Cheslack-Postava, Flavio JunqueiraCloses #184 from sslavic/feature/KAFKA-2492",5
KAFKA-2245; Add response tests for consumer coordinator; reviewed by Joel Koshy,3
"KAFKA-9798: Send one round synchronously before starting the async producer (#8565)Comparing all other test cases, the shouldAllowConcurrentAccesses starts an async producer sending records throughout the test other than just synchronously sent and acked a few records before we start the streams application. Right after the streams app is started, we check that at least one record is sent to the output topic (i.e. completed processing). However since only this test starts the producer async and did not wait for it to complete, it is possible that the async producer gets too longer to produce some records and causing it to fail.To follow what other tests did, I let this test to first send one round of records synchronously before starting the async producing.Also encountered some new scala warnings that I fixed along with this PR.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
MINOR: Adding deprecated KTable methods to docs from KIP-114Author: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3215 from bbejeck/kip114-doc,2
"KAFKA-5587; Remove channel only after staged receives are deliveredWhen idle connections are closed, ensure that channels with stagedreceives are retained in `closingChannels` until all staged receivesare completed. Also ensure that only one staged receive is completedin each poll, even when channels are closed.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3526 from rajinisivaram/KAFKA-5587",5
KAFKA-9288: Do not allow the same object to be inserted multiple times into ImplicitLinkedHashCollection (#7809)Reviewers: Jason Gustafson <jason@confluent.io>,5
merge from 0.8 and resolve conflicts,5
KAFKA-4776; Implement graceful handling for improperly formed compressed message setsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jiangjie Qin <becket.qin@gmail.com>Closes #2572 from hachikuji/KAFKA-4776,5
"KAFKA-4208; Add record headers upgrade docUpdate upgrade.htmlRaising this now, as KIP-118 is pulled from release as such submitting this without java 8 changes.As per remaining review comment from https://github.com/apache/kafka/pull/2772, updating the upgrade notes.Author: Michael André Pearce <michael.andre.pearce@me.com>Author: Michael Andre Pearce <Michael.Andre.Pearce@me.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2991 from michaelandrepearce/KIP-82",5
"[MINOR] Consolidate in-memory/rocksdb unit tests for window & session store (#6677)Consolidated the unit tests by having {RocksDB/InMemory}{Window/Session}StoreTest extend {Window/Session}BytesStoreTest. Besides some implementation-specific tests (eg involving segment maintenance) all tests were moved to the abstract XXXBytesStoreTest class. The test coverage now is a superset of the original test coverage for each store type.The only difference made to existing tests (besides moving them) was to switch from list-based equality comparison to set based, in order to reflect that the stores make no guarantees regarding the ordering of records returned from a range fetch.There are some implementation-specific tests that were left in the corresponding test class. The RocksDBWindowStoreTest, for example, had several tests pertaining to segments and/or the underlying filesystem. Another key difference is that the in-memory versions should delete expired records aggressively, while the RocksDB versions should only remove entirely expired segments.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12153; Update producer state before updating start/end offsets after truncation (#9838)When we truncate the log, the first unstable offset might become valid. On the other hand, the logic in `updateHighWatermarkMetadata` assumes that the first stable offset remains at a valid position. Since this method can be reached through either `updateLogStartOffset` or `updateLogEndOffset` in the truncation paths, we need to ensure that the first unstable offset first reflects the truncated state.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",1
"MINOR: cleanup Kafka Streams exception classesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Guozhang WangCloses #2314 from mjsax/javaDocImprovements",2
"KAFKA-12718: SessionWindows are closed too early (#10824)Session windows should not be close directly when ""window end"" time is reached, but ""window close"" time should be ""window-end + gap + grace-period"".Reviewer: Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-2698: Add paused() method to o.a.k.c.c.ConsumerAuthor: Tom Lee <github@tomlee.co>Reviewers: Onur Karaman <okaraman@linkedin.com>, Jiangjie Qin <jiangjie@linkedin.com>, Grant Henke <ghenke@cloudera.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #962 from hachikuji/KAFKA-2698",5
"MINOR: Improve TopologyTestDriver JavaDocs (#8619)Reviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@apache.org>",5
"KAFKA-9984 Should fail the subscription when pattern is empty (#8665)Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-4377; remove deprecated scala.collection.JavaConversions callsJavaConversions are deprecated in 2.12 in favour of JavaConverters.Author: Bernard Leach <leachbj@bouncycastle.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2101 from leachbj/4377-java-converters,4
MINOR: Fix Embedded ConfigDef Validator toString issue (#6339)`ConfigDef.embeddedValidator` should return an Anonymous Object instead of lambda so that we can have a useful `toString()` for methods such as `toRst`.Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-1499; Broker-side compression configuration; reviewed by Joel Koshy,5
"MINOR: enforce setting listeners in CREATE state.Author: Bill Bejeck <bill@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #3569 from bbejeck/MINOR_enforce_adding_listeners_only_created_state",1
MINOR: Move common out of range handling into AbstractFetcherThread (#5608)This patch removes the duplication of the out of range handling between `ReplicaFetcherThread` and `ReplicaAlterLogDirsThread` and attempts to expose a cleaner API for extension. It also adds a mock implementation to facilitate testing and several new test cases.Reviewers: Jun Rao <junrao@gmail.com>,3
"KAFKA-10585: Kafka Streams should clean up the state store directory from cleanup (#9414)1. Update StateDirectory#clean  - Delete application's statestore directory in cleanup process if it is empty.2. Add Tests  - StateDirectoryTest#shouldDeleteAppDirWhenCleanUpIfEmpty: asserting the empty application directory is deleted with StateDirectory#clean.  - StateDirectoryTest#shouldNotDeleteAppDirWhenCleanUpIfNotEmpty: asserting the non-empty application directory is not deleted with StateDirectory#clean and appropriate log message is generated.  - Add Integration test: StateDirectoryIntegrationTest3. Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <guozhang@apache.org>",4
"Adapt docs about metrics of Streams according to KIP-444 (#8171)Adapts the docs about metrics of Streams according to https://cwiki.apache.org/confluence/display/KAFKA/KIP-444%253A+Augment+metrics+for+Kafka+StreamsReviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12914: StreamSourceNode should return `null` topic name for pattern subscription (#10846)Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-4379; Follow-up to avoid sending to changelog while restoring InMemoryLRUCache1. Added a flag to indicate if it is restoring or not in the LRU Store; since we only have a restore callback we have to set it each time applying the change.2. Fixed the corresponding unit test, plus some minor cleaning up.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2908 from guozhangwang/K4379-remove-listener",4
"KAFKA-10494: Eager handling of sending old values (#9415)Nodes that are materialized should not forward requests to `enableSendingOldValues` to parent nodes, as they themselves can handle fulfilling this request. However, some instances of `KTableProcessorSupplier` were still forwarding requests to parent nodes, which was causing unnecessary materialization of table sources.The following instances of `KTableProcessorSupplier` have been updated to not forward `enableSendingOldValues` to parent nodes if they themselves are materialized and can handle sending old values downstream: * `KTableFilter` * `KTableMapValues` * `KTableTransformValues`Other instances of `KTableProcessorSupplier` have not be modified for reasons given below: * `KTableSuppressProcessorSupplier`: though it has a `storeName` field, it didn't seem right for this to handle sending old values itself. Its only job is to suppress output. * `KTableKTableAbstractJoin`: doesn't have a store name, i.e. it is never materialized, so can't handle the call itself. * `KTableKTableJoinMerger`: table-table joins already have materialized sources, which are sending old values. It would be an unnecessary performance hit to have this class do a lookup to retrieve the old value from its store. * `KTableReduce`: is always materialized and already handling the call without forwarding * `KTableAggregate`: is always materialized and already handling the call without forwardingReviewer: Matthias J. Sax <matthias@confluent.io>",5
KAFKA-499 Refactor controller; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387270 13f79535-47bb-0310-9956-ffa450edef68,4
MINOR: remove streams-smoke-test.shguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1125 from ymatsuda/remove_smoketest_shell_script,3
"MINOR: Fix JMX serialization by reverting lazy computation of JMX attributes (#5114)This reverts commit c9ec292135f26d1d70a (#5011). Thatcommit introduces an anonymous inner class which retains areference to the non-serializable outer class `KafkaMbean`breaking Serialization. This means that reading JMX metricsvia JConsole or JmxTool no longer works since RMI relieson Java Serialization.Reviewers: Jason Gustafson <jason@confluent.io>, Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
MINOR: Improve doc string in PartitionGrouperAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>Closes #1550 from guozhangwang/Kminor-grouppartitioner-javadoc,2
MINOR: Remove unused method parameter in `SimpleAclAuthorizer`Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3147 from vahidhashemian/minor/remove_unsed_method_parameter_simpleaclauthorizer,4
"MINOR: Fix kraft timeout in LogOffsetTest (#12262)Fixes the timeouts we have been seeing in `LogOffsetTest` when KRaft is enabled. The problem is the dependence on `MockTime`. In the KRaft broker, we need a steadily advancing clock for events in `KafkaEventQueue` to get executed. In the case of the timeouts, the broker was stuck with the next heartbeat event in the queue. We depended on the execution of this event in order to send the next heartbeat and complete the `initialCatchUpFuture` and finish broker startup. This caused the test to get stuck during initialization, which is probably why the `@Timeout` wasn't working. The patch fixes the problem by using system time instead because there was not a strong dependence on `MockTime`.Reviewers: David Arthur <mumrah@gmail.com>",1
"KAFKA-5998: fix checkpointableOffsets handling (#7030)fix checkpoint file warning by filtering checkpointable offsets per taskclean up state manager hierarchy to prevent similar bugsReviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"KAFKA-9308: Reworded the ssl part of the security documentation  (#8009)Reworded the ssl part of the security documentation to fix various issues (mainly as noted by this jira, the problem that SAN extension values are not copied to certificates) and add some recommendations.Reviewers: Mickael Maison <mickael.maison@gmail.com>",5
"KAFKA-3155; Avoid long overflow in RecordBatch#maybeExpire`Long.MaxValue` for the linger overflows in `RecordBatch#maybeExpire` when added tothe current timestamp.Then causes an error to be set for the batch by `Sender` (not happening every time sinceit depends on the timing of `Sender`):That error then causes a call to `ProduceRequestResult#done` on the batch, which thenmakes the check for ""not done"" fail.Author: Armin Braun <me@obrown.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2639 from original-brownbear/KAFKA-3155",0
"KAFKA-2084; Add per-client-id byte-rate metrics and quota manager; reviewed by Joel Koshy, Dong Lin, Jun Rao and Edward Ribeiro",1
more info in DumpLogSegments; KAFKA-122 ; patched by Jun; reviewed by Nehagit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1161664 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Improve test of log messages for dropped records (#10920)Reviewers: Luke Chen <showuon@gmail.com>,  Boyang Chen <boyang@apache.org>",4
KAFKA-844 System Test - Mirror Maker cases enhancements; reviewed by Neha Narkhede,1
MINOR: Log at INFO level in Benchmark testsAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Gwen ShapiraCloses #569 from granders/minor-reduce-benchmark-logs,2
MINOR: change default TX timeout only if EOS is enabled (#9618)Reviewer: Boyang Chen <boyang@confluent.io>,5
"KAFKA-9845: Warn users about using config providers with plugin.path property (#8455)* KAFKA-9845: Fix plugin.path when config provider is used* Revert ""KAFKA-9845: Fix plugin.path when config provider is used""This reverts commit 96caaa9a4934bcef78d7b145d18aa1718cb10009.* KAFKA-9845: Emit ERROR-level log message when config provider is used for plugin.path property* KAFKA-9845: Demote log message level from ERROR to WARNCo-Authored-By: Nigel Liang <nigel@nigelliang.com>* KAFKA-94845: Fix failing unit tests* KAFKA-9845: Add warning message to docstring for plugin.path config* KAFKA-9845: Apply suggestions from code reviewCo-authored-by: Randall Hauch <rhauch@gmail.com>Co-authored-by: Nigel Liang <nigel@nigelliang.com>Co-authored-by: Randall Hauch <rhauch@gmail.com>",5
MINOR: Move processor response queue into Processor (#4542)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-7068: Handle null config values during transform (KIP-297)Fix NPE when processing null config values during transform.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5241 from rayokota/KIP-297-null-config-values",5
"KAFKA-9383: Expose consumer group metadata (#7906)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-10000: Add new metrics for source task transactions (#11772)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"Adding reverse iterator usage for sliding windows processing (extending KIP-450) (#9239)Add a backwardFetch call to the window store for sliding windowprocessing. While the implementation works with the forward callto the window store, using backwardFetch allows for the iteratorto be closed earlier, making implementation more efficient.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"KAFKA-13939: Only track dirty keys if logging is enabled. (#12263)InMemoryTimeOrderedKeyValueBuffer keeps a Set of keys that have been seen in order to log them for durability. This set is never used nor cleared if logging is not enabled. Having it be populated creates a memory leak. This change stops populating the set if logging is not enabled.Reviewers: Divij Vaidya <diviv@amazon.com>, Kvicii <42023367+Kvicii@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
"MINOR: make Consumed copy ctor protectedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3816 from dguy/consumed-ctor",5
KAFKA-9985: Sink connector may exhaust broker when writing in DLQ (#8663)* Validate topic name against DQL topic in Sink connector config* Adding parseTopicsList method* Suppress warning* KAFKA-9985: Minor changes to improve readability of exception messagesCo-authored-by: Randall Hauch <rhauch@gmail.com>,1
MINOR: Implement `toString` in some Validator instancesThis is used in the generated config table. Also fix a coupleof typos in the process.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3451 from ijuma/fix-doc-typos,2
"KAFKA-2880: consumer should handle disconnect/timeout for metadata requestsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #581 from hachikuji/KAFKA-2880",5
"KAFKA-9924: Add docs for RocksDB properties-based metrics (#9895)Document the new properties-based metrics for RocksDBReviewers: Leah Thomas <lthomas@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
"MINOR: Clean up of ProducerConfig documentation, including correction for block.on.buffer.fulldefault value is ""false"" and not ""true""See: https://stackoverflow.com/questions/35578519/kafka-block-on-buffer-full-default-valueand https://github.com/apache/kafka/blob/d5b43b19bb06e9cdc606312c8bcf87ed267daf44/clients/src/main/java/org/apache/kafka/clients/producer/ProducerConfig.java#L232Author: mjsax <mjsax@apache.org>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #954 from mjsax/hotfix-docu",2
"MINOR; Small optimizations in `ReplicaManager#becomeLeaderOrFollower` (#11225)This patch refactors `ReplicaManager#becomeLeaderOrFollower` to avoid having to re-iterate over all the partitions to determine which ones should become leaders and which ones should become followers.The patch also refactors how partitions are marked as offline when the log can't be created. Before the patch, we were iterating over all the partitions in the request or in the delta to mark them as offline is the log was not present. Now, we mark them as failed directly if the log can not be created.Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",5
ConsoleProducer does not exit correctly; kafka-701; patched by Maxime Brugidou; reviewed by Jun Rao,5
commit the remaining changes,4
"MINOR: Clarify usage of stateful processor node (#5740)In recent PRs, we have been confused about the proper usage ofStatefulProcessorNode (#5731 , #5737 )This change disambiguates it.Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: add missing parameter `processing.guaratees` to Streams docs (#5023)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-7369; Handle retriable errors in AdminClient list groups API (#5595)We should retry when possible if ListGroups fails due to a retriable error (e.g. coordinator loading).Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>,  Guozhang Wang <wangguoz@gmail.com>",0
Avoid creating a new topic by the consumer; patched by Taylor Gautier; reviewed by Jun Rao; KAFKA-101git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1204764 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-4263: Fix flaky test QueryableStateIntegrationTest.concurrentAccessAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4342 from mjsax/kafka-4263-concurrentAccess",5
"KAFKA-5283; Handle producer epoch/sequence overflow- Producer sequence numbers should wrap around- Generate a new producerId if the producer epoch would overflowAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3183 from hachikuji/KAFKA-5283",5
MINOR: Fix typo in Kafka config docs (#12268)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-12625: Fix the NOTICE file (#10693)Adds new NOTICE-binary file and packages it in the binary release,2
MINOR: Remove unused constructor param from ProcessorStateManagerRemove applicationId parameter as it is no longer used.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2385 from dguy/minor-remove-unused-param,4
KAFKA-8932; Add tag for CreateTopicsResponse.TopicConfigErrorCode (KIP-525) (#7464)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
"MINOR: Disabled flaky DynamicBrokerReconfigurationTest.testAddRemoveSslListener until fixed (#4924)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
trival fix to remove reference of sbt in README,4
"MINOR: remove unnecessary timeout for admin request (#8738)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Fix broken link to record format in protocol docs (#5526)Co-authored-by: Mickael Maison <mickael.maison@gmail.com>Co-authored-by: Gantigmaa Selenge  <tina.selenge@gmail.com>Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jason Gustafson <jason@confluent.io>",5
"MINOR: fixing typos in docsThis commit contains minor grammatical fixes.  Some of the changes are just removing rogue commas, which can be hard to see in the diff.This contribution is my original work and I license the work to the project under the project's open source license.Author: Samuel Julius Hecht <samjhecht@gmail.com>Reviewers: Gwen ShapiraCloses #721 from samjhecht/minor-docs-edits",2
"KAFKA-10778; Fence appends after write failure (#9676)This patch improves append fencing after an IO error. Previously there was a window between the time of an IO error and the time the log is taken offline in which additional appends can be attempted. This is due to the asynchronous propagation of the IO error. This patch tightens the fencing so that no additional appends will be accepted after a previous append failed with an IO error.Reviewers: Guozhang Wang <guozhang@apache.org>, Jason Gustafson <jason@confluent.io>",5
MINOR: Add UUID type to Kafka API code generation (#7291)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-8461: Wait for follower to join the ISR in testUncleanLeaderElectionDisabled TestAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>Closes #6887 from omkreddy/unclean-leader",4
"KAFKA-5303, KAFKA-5305: Improve logging when fetches fail in ReplicaFetcherThreadAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3115 from ijuma/kafka-5305-missing-log-info-replica-fetcher",5
MINOR: Connect hangs on startup failureAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #902 from hachikuji/hotfix-connect-startup,0
"KAFKA-6935: Add config for allowing optional optimization (#5071)Adding configuration to StreamsConfig allowing for making topology optimization optional.Added unit tests are verifying default values, setting correct value and failure on invalid values.Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-8219: add doc changes for static membership release (#6790)* add doc changes for static membership release* address comments* address comments for a separate page* address Matthias' comment,1
kafka-1578; Controller should de-register all listeners upon designation; patched by Guozhang Wang; reviewed by Jun Rao,5
KAFKA-211 Fix LICENSE file to include MIT and SCALA license; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205116 13f79535-47bb-0310-9956-ffa450edef68,1
"MINOR: Lower producer throughput in flaky upgrade system testWe see the upgrade test failing from time to time. I looked into it and found that the root cause is basically that the test throughput can be too high for the 0.9 producer to make progress. Eventually it reaches a point where it has a huge backlog of timed out requests in the accumulator which all have to be expired. We see a long run of messages like this in the output:```{""exception"":""class org.apache.kafka.common.errors.TimeoutException"",""time_ms"":1559907386132,""name"":""producer_send_error"",""topic"":""test_topic"",""message"":""Batch Expired"",""class"":""class org.apache.kafka.tools.VerifiableProducer"",""value"":""335160"",""key"":null}{""exception"":""class org.apache.kafka.common.errors.TimeoutException"",""time_ms"":1559907386132,""name"":""producer_send_error"",""topic"":""test_topic"",""message"":""Batch Expired"",""class"":""class org.apache.kafka.tools.VerifiableProducer"",""value"":""335163"",""key"":null}{""exception"":""class org.apache.kafka.common.errors.TimeoutException"",""time_ms"":1559907386133,""name"":""producer_send_error"",""topic"":""test_topic"",""message"":""Batch Expired"",""class"":""class org.apache.kafka.tools.VerifiableProducer"",""value"":""335166"",""key"":null}{""exception"":""class org.apache.kafka.common.errors.TimeoutException"",""time_ms"":1559907386133,""name"":""producer_send_error"",""topic"":""test_topic"",""message"":""Batch Expired"",""class"":""class org.apache.kafka.tools.VerifiableProducer"",""value"":""335169"",""key"":null}```This can continue for a long time (I have observed up to 1 min) and prevents the producer from successfully writing any new data. While it is busy expiring the batches, no data is getting delivered to the consumer, which causes it to eventually raise a timeout.```kafka.consumer.ConsumerTimeoutExceptionat kafka.consumer.NewShinyConsumer.receive(BaseConsumer.scala:50)at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:109)at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:69)at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:47)at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)```The fix here is to reduce the throughput, which seems reasonable since the purpose of the test is to verify the upgrade, which does not demand heavy load. Note that I investigated several failing instances of this test going back to 1.0 and saw a similar pattern, so there does not appear to be a regression.Author: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #6907 from hachikuji/lower-throughput-for-upgrade-test",3
KAFKA-12613: Fix inconsistent validation logic between KafkaConfig and LogConfig (#10472)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
"KAFKA-6751; Support dynamic configuration of max.connections.per.ip/max.connections.per.ip.overrides configs (KIP-308) (#5334)KIP-308 implementation. See https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=85474993.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: kafkatest add manifestThis patch makes it possible to publish kafkatest (system test package) to pypi and use it as a library in other projects by:- including necessary static resources with the package- renaming the version to conform w/PEP 440, since python packaging tools reject the current version nameAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #173 from granders/minor-kafkatest-add-manifest",3
"KAFKA-2017: Persist Group Metadata and Assignment before RespondingAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Onur Karaman, Jason Gustafson, Jun RaoCloses #386 from guozhangwang/K2017",5
"KAFKA-6560: Add docs for KIP-261 (#4685)Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-4948; Wait for offset commit in test to fix transient failure`DescribeConsumerGroupTest#testDescribeExistingGroupWithNoMembersWithNewConsumer` shuts down the consumer executor thread and then checks that the assignments returned by `describeGroup` contain the consume group with no members. But if the executor thread is shut down before any offsets are committed, the assignments returned by `describeGroup` doesn't contain the group at all. This PR waits for an offset commit by waiting for the group to appear in `describeGroup` assignments prior to shutting down the executor.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3246 from rajinisivaram/KAFKA-4948",5
"KAFKA-4826: Fix some findbugs warnings in Kafka StreamsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Matthias J. Sax, Guozhang WangCloses #2623 from cmccabe/KAFKA-4826",5
KAFKA-1960; .gitignore does not exclude test generated files and folders; reviewed by Joel Koshy and Gwen Shapira,2
"KAFKA-9032: Bypass serdes for tombstones (#7518)In a KTable context, null record values have a special ""tombstone"" significance. We should always bypass the serdes for such tombstones, since otherwise the serde could violate Streams' table semantics.Added test coverage for this case and fixed the code accordingly.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-5174: Have at least 2 threads for compaction and flushing in RocksDBThis fix needs to be backported to 0.10.2 as well.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Ismael Juma, Guozhang WangCloses #2982 from enothereska/KAFKA-5174-1-core",0
MINOR: Add authorizer.class.name to the security section in documentation (#4310),2
"MINOR: ducktape should start brokers in parallel and support co-located kraftThis patch adds a sanity-check bounce system test for the case where we have 3co-located KRaft controllers and fixes the system test code so that this casewill pass by starting brokers in parallel by default instead of serially. Wenow also send SIGKILL to any running KRaft broker or controller nodes for theco-located case when a majority of co-located controllers have been stopped --otherwise they do not shutdown, and we spin for the 60 second timeout. Finally,this patch adds the ability to specify that certain brokers should not bestarted when starting the cluster, and then we can start those nodes at a latertime via the add_broker() method call; this is going to be helpful for KRaftsnapshot system testing.We were not testing the 3 co-located KRaft controller case previously, and itwould not pass because the first Kafka node would never be considered started.We were starting the Kafka nodes serially, and we decide that a node hassuccessfully started when it logs a particular message. This message is notlogged until the broker has identified the controller (i.e. the leader of theKRaft quorum). There cannot be a leader until a majority of the KRaft quorumhas started, so with 3 co-located controllers the first node could never beconsidered ""started"" by the system test.Reviewers: Colin P. McCabe <cmccabe@apache.org>",3
"MINOR: fix Connect system test runs with JDK 10+ (#12202)When running our Connect system tests with JDK 10+, we hit the error     AttributeError: 'ClusterNode' object has no attribute 'version'because util.py attempts to check the version variable for non-Kafka service objects.Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",1
KAFKA-6049: Add non-windowed Cogroup operator (KIP-150) (#7538)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"MINOR: Refactor partition lag metric for cleaner encapsulationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2416 from hachikuji/refactor-partition-lag-cleanup",4
"KAFKA-8643; Bring back public MemberDescription constructor (#7060)This patch fixes a compatibility breaking `MemberDescription` constructor change in #6957. It also updates `equals` and `hashCode` for the new `groupInstanceId` field that was added in the same patch.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-4647: Improve test coverage of GlobalStreamThreadAdd a test to ensure a `StreamsException` is thrown when an exception other than `StreamsException` is caughtAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2450 from dguy/KAFKA-4647",3
"MINOR: Remove line with addAll since collection passed into constructor call. (#7807)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>",5
kafka-1567; Metric memory leaking after closing the clients; patched by Jiangjie Qin; reviewed by Guozhang Wang and Jun Rao,5
HOTFIX: fix build error (#10796)Fix compile error in scala tests.The compile error is:```[Error] /home/jenkins/jenkins-agent/workspace/Kafka_kafka-pr_PR-9229/core/src/test/scala/unit/kafka/server/metadata/BrokerMetadataListenerTest.scala:97: polymorphic expression cannot be instantiated to expected type;[2021-05-29T02:34:50.308Z]  found   : [T]()T[2021-05-29T02:34:50.308Z]  required: kafka.server.RequestLocal```This error happens only in scala 2.12Reviewers: Bruno Cadonna <cadonna@apache.org>,1
KAFKA-1086 Improve GetOffsetShell to find metadata automatically; reviewed by Jun Rao and Joel Koshy,5
"KAFKA-9254; Overridden topic configs are reset after dynamic default change (#7870)Currently, when a dynamic change is made to the broker-level default log configuration, existing log configs will be recreated with an empty overridden configs. In such case, when updating dynamic broker configs a second round, the topic-level configs are lost. This can cause unexpected data loss, for example, if the cleanup policy changes from ""compact"" to ""delete.""Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Enable deep-iteration to print data in DumpLogSegments (#4396)Enable deep-iteration option when print-data-log is enabled in DumpLogSegments. Otherwise data is not printed.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-4614; Forcefully unmap mmap of OffsetIndex to prevent long GC pauseIssue: https://issues.apache.org/jira/browse/KAFKA-4614Fixes the problem that the broker threads suffered by long GC pause.When GC thread collects mmap objects which were created for index files, it unmaps memory mapping so kernel turns to delete a file physically. This work may transparently read file's metadata from physical disk if it's not available on cache.This seems to happen typically when we're using G1GC, due to it's strategy to left a garbage for a long time if other objects in the same region are still alive.See the link for the details.Author: Yuto Kawamura <kawamuray.dadada@gmail.com>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>,Closes #2352 from kawamuray/KAFKA-4614-force-munmap-for-index",1
"KAFKA-5147; Add missing synchronization to TransactionManagerThe basic idea is that exactly three collections, ie. `pendingRequests`, `newPartitionsToBeAddedToTransaction`, and `partitionsInTransaction` are accessed from the context of application threads. The first two are modified from the application threads, and the last is read from those threads.So to make the `TransactionManager` truly thread safe, we have to ensure that all accesses to these three members are done in a synchronized block. I inspected the code, and I believe this patch puts the synchronization in all the correct places.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3132 from apurvam/KAFKA-5147-transaction-manager-synchronization-fixes",0
MINOR; Small refactor in `GroupMetadata` (#10236)Reviewers: Jason Gustafson <jason@confluent.io>,5
KAFKA-10079: improve thread-level stickiness (#8775)Uses a similar (but slightly different) algorithm as in KAFKA-9987 to produce a maximally sticky -- and perfectly balanced -- assignment of tasks to threads within a single client. This is important for in-memory stores which get wiped out when transferred between threads.Reviewers: John Roesler <vvcephei@apache.org>,1
"KAFKA-7117: Support AdminClient API in AclCommand (KIP-332) (#5463)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",1
"fix compile error for example (#6526)Reviewers: Prashant Sabnekar, Bill Bejeck <bbejeck@gmail.com>",0
KAFKA-4023: Add thread id and task id for logging prefix in StreamsAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1803 from bbejeck/KAFKA-4023_add_thread_id_prefix_for_logging,2
"KAFKA-8024; Fix `UtilsTest` failure under non-english locales (#6351)The two digit formatting we use in `Utils.formatBytes` depends on the english locale. If run from a different locale (e.g. German), the test case fails. This patch uses english explicitly.Reviewers: Lee Dongjin <dongjin@apache.org>, Jason Gustafson <jason@confluent.io>",5
KAFKA-4783: Add ByteArrayConverter (KIP-128)Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2599 from ewencp/kafka-4783-byte-array-converter,1
"KAFKA-3794: added stream / table names as prefix to print / writeAsText…int to the console.Author: bbejeck <bbejeck@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #1577 from bbejeck/KAFKA-3794-add-prefix-to-print-functions",0
"MINOR: Add PayloadGenerator to Trogdor (#4640)It generates the producer payload (key and value) and makes sure that the values arepopulated to target a realistic compression rate (0.3 - 0.4) if compression is used.The generated payload is deterministic and can be replayed from a given position.For now, all generated values are constant size, and key types can be configuredto be either null or 8 bytes.Added messageSize parameter to producer spec, that specifies producedkey + message size.",2
MINOR: Fix ConcurrentModificationException in TransactionManager (#4608),0
MINOR: fix typo in TimeIndex (#9834)fix typos in TimeIndexCo-authored-by: wenbingshen <oliver.shen999@gmail.com>Reviewers: Boyang Chen <boyang@confluent.io>,5
KAFKA-1485 Upgrade to Zookeeper 3.4.6 missing file,2
"MINOR: Move off deprecated APIs in StreamsResetter (#11075)Reviewers: Luke Chen <showuon@gmail.com>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-8928: Logged producer config does not always match actual configured values (#7466)Some logged producer configs(clientId, acks, retries) might not be reflected the actual values.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-7055: Update InternalTopologyBuilder to throw TopologyException if a processor or sink is added with no upstream node attached (#5215)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
KAFKA-13694: Log more specific information when the verification record fails on brokers. (#11830)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
"MINOR: Fix for the location of the trogdor.sh executable file in the documentation. (#5040)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Ismael Juma <ismael@juma.me.uk>",2
"MINOR: Restructure ConsistencyVectorIntegrationTest (#11848)Reviewers: YEONCHEOL JANG <@YeonCheolGit>, Matthias J. Sax <mjsax@apache.org>",3
MINOR: Renamed a few record definition files with the existing convention. (#11414)Reviewers: Jun Rao <junrao@gmail.com>,2
kafka-1642; (followup patch) [Java New Producer Kafka Trunk] CPU Usage Spike to 100% when network connection is lost; patched by Ewen Cheslack-Postava; patched by Ewen Cheslack-Postava; reviewed by Jun Rao,1
"KAFKA-365 change copyright in NOTICE to current year, reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350349 13f79535-47bb-0310-9956-ffa450edef68",4
"KAFKA-4283: records deleted from CachingKeyValueStore still appear in range and all queriesRecords that are deleted/removed from the CachingKeyValueStore shouldn't appear in range and all queries.Modified the iterator such that it skips over the deleted records.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Matthias J. Sax, Guozhang WangCloses #2001 from dguy/kafka-4283",4
"KAFKA-6569: Move OffsetIndex/TimeIndex logger to companion object  (#4586)We identified that we spend a lot of time in the creation of Logger instanceswhen creating OffsetIndex/TimeIndex due to the Logging mixin.When the broker is bootstrapping it's just doing this in a tight loop, so thetime adds up.This patch moves the logger to the companion objects of OffsetIndex,TimeIndex and AbstractIndex resolving this issue.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Co-authored-by: Kyle Ambroff <kyle@ambroff.com>Co-authored-by: Ismael Juma <ismael@juma.me.uk>",0
"KAFKA-5540: Deprecate internal converter configs (KIP-174)Implementation of [KIP-174](https://cwiki.apache.org/confluence/display/KAFKA/KIP-174+-+Deprecate+and+remove+internal+converter+configs+in+WorkerConfig)Configuration properties 'internal.key.converter' and 'internal.value.converter'are deprecated, and default to org.apache.kafka.connect.json.JsonConverter.Warnings are logged if values are specified for either, or if properties thatappear to configure instances of internal converters (i.e., ones prefixed witheither 'internal.key.converter.' or 'internal.value.converter.') are given.The property 'schemas.enable' is also defaulted to false for internalJsonConverter instances (both for keys and values) if it isn't specified.Documentation and code have also been updated with deprecation notices andannotations, respectively.Unit tests have been updated in `PluginsTest` to account for the new defaults for `schemas.enable` for internal key/value converters, and to ensure that (for the time being), internal key/value converters are still configurable despite being deprecated.Author: Chris Egerton <chrise@confluent.io>Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4693 from C0urante/kafka-5540",5
"MINOR: fix failing Streams system tests (#5928)Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-2428: Add sanity check in KafkaConsumer for the timeoutsAdd sanity test in kafkaConsumer for the timeouts. This is a followup ticket for Kafka-2120.Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>Reviewers: Dong Lin, Ismael Juma, Guozhang WangCloses #282 from MayureshGharat/Kafka-2428",2
"KAFKA-10102: update ProcessorTopology instead of rebuilding it (#8803)Reviewers: Boyang Chen  <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: Improve handling of channel close exceptionPropagate IOException in SslTransportLayer channel.close to be consistent with PlaintextTransportLayer,  close authenticator on channel close even if transport layer close fails.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1370 from rajinisivaram/minor-channelclose2",5
MINOR: Make assignment expectation explicit in testConsumptionWithBrokerFailuresAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2930 from hachikuji/bouncetest-assert-assignment,3
MINOR: Use https instead of http in links (#6477)Verified that the https links work.I didn't update the license header in this PR since that touchesso many files. Will file a separate one for that.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,2
"KAFKA-7185: Allow empty resource name when matching ACLs (#5400)Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"MINOR: fix grammatical errors in DataException messageWas just reading kafka source code, my favourite Friday afternoon activity, when I found these small grammatical errors in some `DataException` messages.Could someone please review? ewencp dguyAuthor: Laurier Mantel <laurier.mantel@shopify.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1551 from LaurierMantel/maps-typos",2
"KAFKA-3411: Streams: stop using ""job"" terminology, rename job.id to application.idguozhangwang ymatsuda : please review.Author: Michael G. Noll <michael@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1081 from miguno/KAFKA-3411",5
KAFKA-5341; Add UnderMinIsrPartitionCount and per-partition UnderMinIsr metrics (KIP-164)Author: Dong Lin <lindong28@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3583 from lindong28/KAFKA-5341,5
"MINOR: Use `hiResClockMs` in `testRequestExpiry` to fix transient test failureWe recently switched `SystemTimer` to use `hiResClockMs` (based on `nanoTime`), but wewere still using `System.currentTimeMillis` in the test. That would sometimes meanthat we would measure elapsed time as lower than expected.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>Closes #1890 from ijuma/fix-test-request-satisfaction-transient-failure",3
KAFKA-5619; Deprecate --new-consumer option in all toolsAdded deprecation and warning message when the --new-consumeroption is used with the ConsumerGroupCommand andthe ConsumerPerformance tools.Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3555 from ppatierno/kafka-5619,1
"KAFKA-12648: avoid modifying state until NamedTopology has passed validation (#11750)Previously we were only verifying the new query could be added after we had already inserted it into the TopologyMetadata, so we need to move the validation upfront.Also adds a test case for this and improves handling of NPE in case of future or undiscovered bugs.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
"KAFKA-12208: Rename AdminManager to ZkAdminManager (#9900)Rename AdminManager to ZkAdminManager to emphasize the fact that it is not used by the KIP-500 code paths.Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
"KAFKA-5634; Do not allow segment deletion beyond high watermarkThis patch changes the segment deletion behavior to take the high watermark of the partition into account. In particular, segments containing offsets equal to or larger than the high watermark are no longer eligible for deletion. This is needed to ensure that the log start offset reported in fetch responses does not get ahead of the high watermark.Impact: segment deletion may be delayed compared to existing behavior since the broker must await advancement of the high watermark. For topics with heavy load, this may make the active segment effectively ineligible for deletion since the high watermark may never catch up to the log end offset.Author: Jason Gustafson <jason@confluent.io>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3575 from hachikuji/KAFKA-5634",5
kafka-2290; OffsetIndex should open RandomAccessFile consistently; patched by Chris Black; reviewed by Jun Rao,2
MINOR; Update upgrade documentation for 3.3 (#12550),2
"KAFKA-3264; Deprecate the old Scala consumer (KIP-109)Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>This patch had conflicts when merged, resolved byCommitter: Ismael Juma <ismael@juma.me.uk>Closes #2328 from vahidhashemian/KAFKA-3264",0
"MINOR: Fix log4j entry in RepartitionTopics (#11958)I noticed two issues in the log4j entry:1. It's formatted as ""{}...{}"" + param1, param2; effectively it is one param only, and the printed line is effectively mis-aligned: we always print Subtopology [sourceTopics set] was missing source topics {}2. Even fix 1) is not enough, since topologyName may be null. On the other hand I think the original goal is not to print the topology name but the sub-topology id since it's within the per-sub-topology loop.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
MINOR: Exclude PULL_REQUEST_TEMPLATE.md from rat checksAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4201 from ijuma/exclude-pull-request-template-from-rat,5
"KAFKA-4081; KafkaConsumer should not allow negative offsets to be committedAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1827 from mimaison/KAFKA-4081",5
"MINOR: Rejoin split ssl principal mapping rules (#6099)* Join ssl principal mapping rules correctly before evaluating.Java properties splits the configuration array on commas, and that leads to rules containing commas being split before being evaluated. This commit adds a code change to re-join those strings into full rules before evaluating them. The function assumes every rule is either DEFAULT or begins with the prefix RULE:",0
"KAFKA-13553: add PAPI KV store tests for IQv2 (#11624)During some recent reviews, @mjsax pointed out that StateStore layersare constructed differently the stores are added via the PAPI vs. the DSL.This PR adds KeyValueStore PAPI construction to theIQv2StoreIntegrationTest so that we can ensure IQv2 works on everypossible state store.Reviewers: Patrick Stuedi <pstuedi@apache.org>, Guozhang Wang <guozhang@apache.org>",1
"KAFKA-6627: Prevent config default values overriding ones specified through --producer-property on command line. (#6084)* KAFKA-6627: Prevent config default values overriding ones specified through --producer-property on command line.In Console{Producer,Consumer}, extraProducerProps (options specified in--producer-property) is applied first, then overriden unconditionally,even if the value is not specified explicitly (and default value isused). This patch fixes it so that it doesn't override the existingvalue set by --producer-property if it is not explicitly specified.The contribution is my original work and I license the work to theproject under the project's open source license.Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>",1
MINOR: fix typo in `AbstractIndex.scala` (#9745)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
MINOR: add UPGRADE_FROM to config docs (#7825)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
KAFKA-851 Broken handling of leader and isr request leads to incorrect high watermark checkpoint file; reviewed by Jun Rao and Swapnil Ghike,2
MINOR: Ensure timestamp type is provided when up-converting messagesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2483 from hachikuji/minor-upconvert-timestamp-safety,5
"KAFKA-9329; KafkaController::replicasAreValid should return error message (#7865)The `KafkaController::replicasAreValid` method currently returns aboolean indicating if replicas are valid or not. But the failurecondition loses any context on why replicas are not valid. This changeupdates the metod to return the error conition if validation fails. Thisallows caller to report the error to the client.The change also renames the `replicasAreValid` method to`validateReplicas` to reflect updated semantics.Reviewers: Sean Li <seanli-rallyhealth@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-14177: Correctly support older kraft versions without FeatureLevelRecord (#12513)The main changes here are ensuring that we always have a metadata.version record in the log, making˘sure that the bootstrap file can be used for records other than the metadata.version record (forexample, we will want to put SCRAM initialization records there), and fixing some bugs.If no feature level record is in the log and the IBP is less than 3.3IV0, then we assume the minimum KRaftversion for all records in the log.Fix some issues related to initializing new clusters. If there are no records in the log at all,then insert the bootstrap records in a single batch. If there are records, but no metadata version,process the existing records as though they were metadata.version 3.3IV0 and then append a metadataversion record setting version 3.3IV0.  Previously, we were not clearly distinguishing between thecase where the metadata log was empty, and the case where we just needed to add a metadata.versionrecord.Refactor BootstrapMetadata into an immutable class which contains a 3-tuple of metadata version,record list, and source. The source field is used to log where the bootstrap metadata was obtainedfrom. This could be a bootstrap file, the static configuration, or just the software defaults.Move the logic for reading and writing bootstrap files into BootstrapDirectory.java.Add LogReplayTracker, which tracks whether the log is empty.Fix a bug in FeatureControlManager where it was possible to use a ""downgrade"" operation totransition to a newer version. Do not store whether we have seen a metadata version or not inFeatureControlManager, since that is now handled by LogReplayTracker.Introduce BatchFileReader, which is a simple way of reading a file containing batches of snapshotsthat does not require spawning a thread. Rename SnapshotFileWriter to BatchFileWriter to beconsistent, and to reflect the fact that bootstrap files aren't snapshots.QuorumController#processBrokerHeartbeat: add an explanatory comment.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-2764: Change use of Properties in Copycat to Maps.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen Shapira, Guozhang WangCloses #444 from ewencp/kafka-2764-maps-not-properties",1
"MINOR: Ensure consumer calls poll() if requests are outstandingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Onur Karaman <okaraman@linkedin.com>, Ismael Juma <ismael@juma.me.uk>Closes #2596 from hachikuji/ensure-poll-with-inflight-requests",5
KAFKA-9855 - return cached Structs for Schemas with no fields (#8472)At the time of this writing there are 6 schemas in kafka APIs with no fields - 3versions each of LIST_GROUPS and API_VERSIONS.When reading instances of these schemas off the wire there's little point inreturning a unique Struct object (or a unique values array inside that Struct)since there is no payload.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-4180; Support clients with different authentication credentials in the same JVMChanged caching in LoginManager to allow one LoginManager per clientJAAS configuration.Added test to End2EndAuthorization for SASL Plain and GSSAPI with twoconsumers with different credentials.Developed with mimaison.Author: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2293 from edoardocomar/KAFKA-4180d",2
KAFKA-13455: Add steps to run Kafka Connect to quickstart (#11500)Signed-off-by: Katherine Stanley <11195226+katheris@users.noreply.github.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"KAFKA-13057; Add KRaft ""broker"" to several RPC's listeners (#11012)This patch fixes a few request listener specs. We were missing ""broker"" for many APIs which are now implemented in KRaft and there were a couple cases where we had unnecessarily exposed a controller-only API on the broker. Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-8354; Replace Sync group request/response with automated protocol (#6729)Update SyncGroup API to use the generated protocol classes.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-4588: Wait for topics to be created in QueryableStateIntegrationTest.shouldNotMakeStoreAvailableUntilAllStoresAvailableAfter debugging this i can see the times that it fails there is a race between when the topic is actually created/ready on the broker and when the assignment happens. When it fails `StreamPartitionAssignor.assign(..)` gets called with a `Cluster` with no topics. Hence the test hangs as no tasks get assigned. To fix this I added a `waitForTopics` method to `EmbeddedKafkaCluster`. This will wait until the topics have been created.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2371 from dguy/integration-test-fix",3
KAFKA-3318: clean up consumer logging and error messagesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael JumaCloses #1036 from hachikuji/KAFKA-3318,5
"MINOR: Increase `awaitCommits` timeout in ExampleConnectIntegrationTest (#7061)The transient failures are usually caused by a timeout in `awaitCommits`. This patch increases the timeout from 15s to 30s.Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Matthias J. Sax <mjsax@apache.org>",5
MINOR: revise error message from TransactionalRequestResult#await (#9843)Reviewers: Gwen Shapira <cshapi@gmail.com>,0
KAFKA-13204: assignor name conflict check (#11217)Add the partition assignor name conflicting check to avoid the wrong assignor being used. Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
MINOR: remove DelayedOperations.checkAndCompleteFetch (#9278)Reviewers: Jun Rao <junrao@gmail.com>,4
"MINOR: fix html generation syntax errors (#12094)The html document generation has some errors in it, specifically related to protocols. The two issues identified and resolved are:* Missing </tbody> closing tags added* Invalid usage of a <p> tag as a wrapper element for <table> elements. Changed the <p> tag to be a <div>.Tested by running ./gradlew siteDocsTar and observing that the output was properly formed.Reviewers: Guozhang Wang <wangguoz@gmail.com>",2
MINOR: Fix some compiler warnings (#4726),2
"KAFKA-6241; Enable dynamic updates of broker SSL keystore (#4263)Enable dynamic broker configuration (see KIP-226 for details). Includes - Base implementation to allow specific broker configs and custom configs to be dynamically updated - Extend DescribeConfigsRequest/Response to return all synonym configs and their sources in the order of precedence - Extend AdminClient to alter dynamic broker configs - Dynamic update of SSL keystoresReviewers: Ted Yu <yuzhihong@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6789; Handle retriable group errors in AdminClient API (#5578)This patch adds support to retry all group operations after COORDINATOR_LOAD_IN_PROGRESS and COORDINATOR_NOT_AVAILABLE in AdminClient group operations. Previously we only had logic to retry after FindCoordinator failures.Reviewers: Yishun Guan <gyishun@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-1490 remove gradlew initial setup output from source distribution patch by Ivan Lyutov reviewed by Joe Stein,1
"KAFKA-14140: Ensure an offline or in-controlled-shutdown replica is not eligible to join ISR in ZK mode (#12487)This patch prevents offline or in-controller-shutdown replicas from being added back to the ISR and therefore to become leaders in ZK mode. This is an extra line of defense to ensure that it never happens. This is a continuation of the work done in KIP-841.Reviewers: David Mao <dmao@confluent.io>, Jason Gustafson <jason@confluent.io>, Jun Rao <jun@confluent.io>, David Jacot <djacot@confluent.io>",5
KAFKA-7288; Fix check in SelectorTest to wait for no buffered bytes (#6415)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
MINOR: Replace for with foreach loop in common moduleAuthor: Prabhat Kashyap <prabhat.kashyap@knoldus.in>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2530 from PKOfficial/refactored-code,4
MINOR: Avoid coarse lock in Pool#getAndMaybePut (#5258)Use `ConcurrentHashMap#computeIfAbsent` which relies onper key locks.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
MINOR: Add comment for round robin partitioner with different subscriptionsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1475 from Ishiihara/roundrobin-comment,5
"KAFKA-7420: Global store surrounded by read only implementation (#5865)Reviewers: Matthias J. Sax <matthias@confluent.io>, Kamal Chandraprakash (@kamalcph), Bill Bejeck <bill@confluent.io>",5
"MINOR: Ensure consumer logging has clientId/groupId contextThis patch ensures that the consumer groupId and clientId are available in all log messages which makes debugging much easier when a single application has multiple consumer instances. To make this easier, I've added a new `LogContext` object which builds a log prefix similar to the broker-side `kafka.utils.Logging` mixin. Additionally this patch changes the log level for a couple minor cases:- Consumer wakeup events are now logged at DEBUG instead of TRACE- Heartbeat enabling/disabling is now logged at DEBUG instead of TRACEAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3676 from hachikuji/log-consumer-wakeups",2
"migrate remaining RPCs (#9558)This PR follows up 0814e4f to migrate the remaining RPCs which need forwarding, including:CreateAcls/DeleteAcls/CreateDelegationToken/RenewDelegationToken/ExpireDelegationToken/AlterPartitionReassignment/CreatePartition/DeleteTopics/UpdateFeatures/ScramReviewers: David Arthur <mumrah@gmail.com>",5
KAFKA-5501; introduce async ZookeeperClientAuthor: Onur Karaman <okaraman@linkedin.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3427 from onurkaraman/KAFKA-5501,2
MINOR: Changed visibility of methods in ClusterConnectionStates to privateThe methods resetReconnectBackoff and updateReconnectBackoff in ClusterConnectionStates both take an instance of a private inner class as parameter and thus cannot be called from outside the class anyway.Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4114 from soenkeliebau/MINOR_private,2
MINOR: Pass materialized to the inner KTable instance (#11888)Reviewers: Luke Chen <showuon@gmail.com>,4
"KAFKA-5225; StreamsResetter doesn't allow custom Consumer propertiesAuthor: Matthias J. Sax <matthias@confluent.io>Author: Bharat Viswanadham <bharatv@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>Closes #3970 from mjsax/kafka-5225-streams-resetter-properties",1
"KAFKA-4626; Add KafkaConsumer#close change to upgrade notesAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2366 from rajinisivaram/KAFKA-4626",5
"KAFKA-10033: Throw UnknownTopicOrPartitionException if altering configs of non-existing topicFixes KAFKA-10033.Replace AdminOperationException with UnknownTopicOrPartitionException if topic does not exist when validating topic configs in AdminZkClient.Author: gnkoshelev <gnkoshelev@gmail.com>Author: Gregory <gnkoshelev@gmail.com>Reviewers: Brian Byrne <bbyrne@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #8715 from gnkoshelev/KAFKA-10033",5
"KAFKA-9179; Fix flaky test due to race condition when fetching reassignment state (#7786)This patch fixes a race condition on reassignment completion. The previous code fetched metadata first and then fetched the reassignment state. It is possible in between those times for the reassignment to complete, which leads to spurious URPs being reported. The fix here is to change the order of these checks and to explicitly check for reassignment completion. Note this patch fixes the flaky test `TopicCommandWithAdminClientTest.testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress`.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
"KAFKA-8007: Avoid copying on fetch in InMemoryWindowStore (#6335)Rewrote the InMemoryWindowStore implementation by moving the work of a fetch to the iterator, and cleaned up the iterators as well.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",4
"MINOR: code cleanup (#6056)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
MINOR: initialize Serdes with ProcessorContextguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #589 from ymatsuda/init_serdes_with_procctx,5
"KAFKA-3311; Prepare internal source topics before calling partition grouperAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Yasuhiro Matsuda <yasuhiro.matsuda@gmail.com>, Jun Rao <junrao@gmail.com>Closes #990 from guozhangwang/K3311",5
KAFKA-1824 - fix ConsoleProducer so parse.key and key.separator will work again; reviewed by Neha Narkhede,1
KAFKA-4596; Throttled reassignment should support partial JSON fileFixes a logic error in the Reassignment process which throws an exceptionif you don't rebalance all partitions.Author: Ben Stopford <benstopford@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2399 from benstopford/KAFKA-4596,0
"MINOR: Adjust Streams parameter hint on TimeoutException (#6280)KIP-91 was included in Kafka 2.1.0, so we should mention`delivery.timeout.ms` in the hint as it's the config thatusers would want to change in most cases.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Small improvements to KafkaProducer javadocs (#11467)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"MINOR:Replace duplicated code with common function in utils (#6819)Reviewers: Ivan Yurchenko <ivanyu@aiven.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-7243: Add unit integration tests to validate metrics in Kafka Streams (#6080)The goal of this task is to implement an integration test for the kafka stream metrics.We have to check 2 things:1. After streams application are started, all metrics from different levels (thread, task, processor, store, cache) are correctly created and displaying recorded values.2. When streams application are shutdown, all metrics are correctly de-registered and removed.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: fix some bugs in ControllerApis.scala (#10505)Fix some cases where ControllerApis was blocking on the controllerthread.  This should not be necessary, since the controller thread canjust interface directly with the network threads.Fix some cases where ControllerApis wasn't doing authorizationcorrectly.  Since the previous release of KRaft did not supportauthorizers, this bug is not as severe as it could have been, but itstill needs to be fixed.  Add authorization unit tests for each API.Add support for the deprecated ALTER_CONFIGS API in ControllerApis.  Itwas already supported in QuorumController, but wasn't exposedpreviously.Fix how we validate duplicate config resources and unknown configresource types in ControllerApis.  Duplicates should yield anINVALID_REQUEST error, and unknown resource types should give an errorwith the corresponding numerical resource type and UNSUPPORTED_VERSION.Fix some redaction code in RequestChannel that was throwing an exceptionwhen duplicate config resources were present in the request.Fix a comment in ControllerApis#deleteTopics that no longer reflectswhat the code is doing when we don't have ""describe"" permission.Add function stubs for the KIP-455 reassignment APIs in ControllerApisand QuorumController.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",1
"MINOR: Add InterfaceStability.Unstable annotations to some Kafka Streams public APIsAlso improves Java docs for the Streams high-level DSL.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma, Michael G. NollCloses #1097 from guozhangwang/KNewJavaDoc",2
"MINOR: Stream metrics documentationAuthor: Eno Thereska <eno@confluent.io>Reviewers: Matthias J. Sax, Guozhang WangCloses #2542 from enothereska/minor-streams-metrics",5
"KAFKA-6323: punctuate with WALL_CLOCK_TIME triggered immediately (#4301)This PR avoids unnecessary punctuation calls if punctuations are missed due to large time advances. It also aligns punctuation schedules to the epoch.Author: Frederic ArnoReviewers: Michal Borowiecki <michal.borowiecki@openbet.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
"MINOR: fix quotes for consistent rendering“ as opposed to "" don't render consistently across browsers. On current Kafka website they render correctly in Firefox but not Chrome (â€œrunsâ€) - charset issue?Author: Michal Borowiecki <michal.borowiecki@openbet.com>Author: mihbor <mbor81@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3227 from mihbor/patch-7",0
KAFKA-350 Enable message replication in the presence of failures; patched by Neha Narkhede; reviewed by Jun Rao and Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1365199 13f79535-47bb-0310-9956-ffa450edef68,0
Kafka-6792: Fix wrong pointer in the link for stream dsl (#4876)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
MINOR: Add missing DESCRIBE_QUORUM ApiKey in AbstractRequest.parseRequest (#9537)Reviewers: David Jacot <djacot@confluent.io>,5
KAFKA-1634; Bump up Offset Commit Request to v2 to add global retention and remove per-partition commit timestamp; reviewed by Joel Koshy and Jun Rao,4
KAFKA-8470: State change logs should not be in TRACE level (#8320)1. Defaults state-change log level to INFO.2. INFO level state-change log includes  (a) request level logging with just partition counts; (b) the leader/isr changes per partition in the controller and in the broker (reduced to mostly just 1 logging per partition).Reviewers: Jun Rao <junrao@gmail.com>,2
"KAFKA-10611: Merge log error to avoid double error (#9407)When using an error tracking system, two error log messages result into two different alerts.It's best to group the logs and have one error with all the information.For example when using with Sentry, this double line of log.error will create 2 different Issues. One can merge the issues but it will be simpler to have a single error log line.Signed-off-by: Benoit Maggi <benoit.maggi@gmail.com>Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Konstantine Karantasis <k.karantasis@gmail.com>",2
"KAFKA-4990; Request/response classes for transactions (KIP-98)Author: Matthias J. Sax <matthias@confluent.io>Author: Guozhang Wang <wangguoz@gmail.com>Author: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2799 from mjsax/kafka-4990-add-api-stub-config-parameters-request-types",5
"MINOR: Remove unintentional tilde character from kafka-run-class.bat scriptIt seems a tipo was made on a avariable for the log dir with commit 81e789ae3dc6ea8369db181c5aef440491d74f19. Then Windows tries to access by default the /log directory which of cause not exists.klesta490 Is it ok so? Or was the tilde ~ intentional?To test:On Windows with the a fresh downloaded Kafka, adapt the properties:* dataDir in config/zookeeper.properties with what you want, windows-compatible* log.dirs in config/server.properties with what you want, windows-compatibleand executes:bin\windows\zookeeper-server-start.bat config\zookeeper.propertiesAuthor: u214578 <florian.hof@sbb.ch>Reviewers: Vladimír Kleštinec <klestinec@gmail.com>, Vahid Hashemian <vahid.hashemian@gmail.com>Closes #5837 from florianhof/feature/fix_windows_log_param",2
log.append() should halt on IOException; patched by Jun Rao; reviewed by Jay Kreps; KAFKA-540git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1393906 13f79535-47bb-0310-9956-ffa450edef68,2
Fixing incorrect JavaDoc for METRICS_RECORDING_LEVEL_CONFIG keyReviewers: Sriharsha Chintalapani <sriharsha@apache.org>,5
MINOR: Fixed comment to refer to UpdateMetadataPartitionState rather than UpdateMetadataTopicState. (#9447)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-6998: Disable Caching when max.cache.bytes are zero. (#5488)1) As titled, add a rewriteTopology that 1) sets application id, 2) maybe disable caching, 3) adjust for source KTable. This optimization can hence be applied for both DSL or PAPI generated Topology.2) Defer the building of globalStateStores in rewriteTopology so that we can also disable caching. But we still need to build the state stores before InternalTopologyBuilder.build() since we should only build global stores once for all threads.3) Added withCachingDisabled to StoreBuilder, it is a public API change.4) [Optional] Fixed unit test config setting functionalities, and set the necessary config to shorten the unit test latency (now it reduces from 5min to 3.5min on my laptop).Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Ted Yu <yuzhihong@gmail.com>",5
"MINOR: Document that Connect topics should use compactionUpdate documentation for Kafka Connect distributed’s config.storage.topic, offset.storage.topic, and status.storage.topic configuration values to indicate that all three should refer to compacted topics.Author: Mathieu Fenniak <mathieu.fenniak@replicon.com>Reviewers: Jason GustafsonCloses #1832 from mfenniak/kafka-connect-topic-docs",2
KAFKA-8011: Fix for race condition causing concurrent modification exception (#6338)In the RegexSourceIntegrationTest#testRegexMatchesTopicsAWhenCreated() and RegexSourceIntegrationTest#testRegexMatchesTopicsAWhenDeleted() a race condition exists where the ConsumerRebalanceListener in the test modifies the list of subscribed topics when the condition for the test success is comparing the same array instance against expected values.This PR should fix this race condition by using a CopyOnWriteArrayList which guarantees safe traversal of the list even when a concurrent modification is happening.Reviewers: Guozhang Wang <wangguoz@gmail.com>,1
KAFKA-767 Message Size check should be done after assigning the offsets; reviewed by Neha Narkhede and Jun Rao,1
KAFKA-508 split out partiondata from fetchresponse and producerrequestgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1394587 13f79535-47bb-0310-9956-ffa450edef68,5
"KAFKA-3160; Fix LZ4 FramingThis contribution is my original work and I license the work under Apache 2.0.Author: Dana Powers <dana.powers@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1212 from dpkp/KAFKA-3160",1
"MINOR: Use `testRuntimeOnly` instead of `testRuntime` in storage modules (#10524)`testRuntime` is deprecated in Gradle 6.x and has been removed in Gradle 7.0.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Satish Duggana <satishd@apache.org>",4
"MINOR: Default to 5 partitions of the __consumer_offsets topic in Streams integration tests (#7331)Given that the tests do not create clusters larger than 3, we do not gain much by creating 50 partitions for that topic. Reducing it should slightly increase test startup and shutdown speed.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",3
"KAFKA-7054; Kafka describe command should throw topic doesn't exist exception**User Interface Improvement :** If topic doesn't exist then Kafka describe command should throw topic doesn't exist exception, like alter and delete commandsAuthor: Manohar Vanam <manohar.crazy09@gmail.com>Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Jason Gustafson <jason@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>Closes #5211 from ManoharVanam/KAFKA-7054",5
"KAFKA-12226: Commit source task offsets without blocking on batch delivery (#11323)Replaces the current logic for committing source offsets, which is batch-based and blocks until the entirety of the current batch is fully written to and acknowledged by the broker, with a new non-blocking approach that commits source offsets for source records that have been ""fully written"" by the producer. The new logic consider a record fully written only if that source record and all records before it with the same source partition have all been written to Kafka and acknowledged.This new logic uses a deque for every source partition that a source task produces records for. Each element in that deque is a SubmittedRecord with a flag to track whether the producer has ack'd the delivery of that source record to Kafka. Periodically, the worker (on the same thread that polls the source task for records and transforms, converts, and dispatches them to the producer) polls acknowledged elements from the beginning of each of these deques and collects the latest offsets from these elements, storing them in a snapshot that is then committed on the separate source task offset thread.The behavior of the `offset.flush.timeout.ms property` is retained, but essentially now only applies to the actual writing of offset data to the internal offsets topic (if running in distributed mode) or the offsets file (if running in standalone mode). No time is spent during `WorkerSourceTask::commitOffsets` waiting on the acknowledgment of records by the producer.This behavior also does not change how the records are dispatched to the producer nor how the producer sends or batches those records.It's possible that memory exhaustion may occur if, for example, a single Kafka partition is offline for an extended period. In cases like this, the collection of deques in the SubmittedRecords class may continue to grow indefinitely until the partition comes back online and the SubmittedRecords in those deques that targeted the formerly-offline Kafka partition are acknowledged and can be removed. Although this may be suboptimal, it is no worse than the existing behavior of the framework in these cases.Author: Chris Egerton <chrise@confluent.io>Reviewed: Randall Hauch <rhauch@gmail.com>",5
"KAFKA-7283: Enable lazy mmap on index files and skip sanity check for segments below recovery point (#5498)Per the KIP-263 discussion, we think we can improve broker restart time by avoiding performing costly disk operations when sanity checking index files for segments below recovery point on broker startup.This PR includes the following changes:1. Mmap the index file and populate fields of the index file on-demand rather than performing costly disk operations when creating the index object on broker startup.2. Skip sanity checks on the time index and offset index of segments.      1. For segment with offset below the flushed point (recovery point), these segments are safely flushed so we don't need to sanity check the index files. if there are indeed data corruption on disk, given that we don't sanity check the segment file, sanity checking only the indexes adds little benefit.   2. For segment with offset above the flushed point (recovery point), we will recover these segments in `recoveryLog()` (Log.scala) in any case so sanity checking the index files for these segments is redundant.We did experiments on a cluster with 15 brokers, each of which has ~3k segments (and there are 31.8k partitions with RF=3 which are evenly distributed across brokers; total bytes-in-rate is around 400 MBps). The results show that rolling bounce time reduces from 135 minutes to 55 minutes.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2
Add license header in suppressions.xml (#11753)Add license header in suppressions.xml Reviewers: Luke Chen <showuon@gmail.com>,5
MINOR: Change order of Property Check To Avoid NPE (#5528)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Bump version to 2.4.0-SNAPSHOT (#6774)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-8352 : Fix Connect System test failure 404 Not Found (#6713)Corrects the system tests to check for either a 404 or a 409 error and sleeping until the Connect REST API becomes available. This corrects a previous change to how REST extensions are initialized (#6651), which added the ability of Connect throwing a 404 if the resources are not yet started. The integration tests were already looking for 409.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>",3
KAFKA-2422: Allow copycat connector plugins to be aliased to simpler names…namesAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #687 from gwenshap/KAFKA-2422,5
"MINOR: Fix typo in Utils#toPositive (#9943)Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2
Trivial: update javadoc comment for KAFKA-1355,2
"KAFKA-7400: Compacted topic segments that precede the log start offse… (#5646)* KAFKA-7400: Compacted topic segments that precede the log start offset are not cleaned upCurrently we don't delete any log segments if the cleanup policy doesn't include delete. This patch changes the behavior to delete log segments that fully precede the log start offset even when deletion is not enabled. Tested with unit tests to verify that LogManager.cleanupLogs now cleans logs with cleanup.policy=compact and that Log.deleteOldSegments deletes segments that preced the start offset regardless of the cleanup policy.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",5
"HOTFIX: Fix equality semantics of KeyValueFixes wrong KeyValue equals logic when keys not equal but values equal.Original hotfix PR at https://github.com/apache/kafka/pull/1293 (/cc enothereska)Please review: ewencp ijuma guozhangwangAuthor: Eno Thereska <eno.thereska@gmail.com>Author: Michael G. Noll <michael@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1294 from miguno/KeyValue-equality-hotfix",0
"HOTFIX: Fix lgtm.com alerts (dead code and out-of-bounds error) (#4388)This fixes two alerts flagged on lgtm.com for Apache Kafka.This dead code alert where InvalidTypeIdException indirectly extends JsonMappingException. The flagged condition with the type test appears after the type test for the latter and thus makes its body dead. I opted to change the order of the tests. Please let me know if this is the intended behavior.The second commit addresses this out-of-bounds alert.More alerts can be found here. Note that my colleague Aditya Sharad addressed some of those in the now outdated #2939.Reviewers: Matthias J. Sax <matthias@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-5711: batch restore should handle deletesAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #3644 from bbejeck/KAFKA-5711_bulk_restore_should_handle_deletes",4
MINOR: log when controller begins processing logdir failure event (#6153)Reviewers: Jun Rao <junrao@gmail.com>,0
kafka-1797; (missed parametric in a few files) add the serializer/deserializer api to the new java client; patched by Jun Rao,1
"KAFKA-12716; Add `Admin` API to abort transactions (#10599)This patch adds the Admin API to abort transactions from KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. The `WriteTxnMarker` API needs to be sent to partition leaders, so we are able to reuse `PartitionLeaderStrategy`, which was introduced when support for `DescribeProducers` was added.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-9434: automated protocol for alterReplicaLogDirs (#8311)Reviewers: David Jacot <djacot@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",5
"KAFKA-13280: Avoid O(N) behavior in KRaftMetadataCache#topicNamesToIds (#11311)Avoid O(N) behavior in KRaftMetadataCache#topicNamesToIds andKRaftMetadataCache#topicIdsToNames by returning a map subclass thatexposes the TopicsImage data structures without copying them.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"MINOR: Add timeout to LogOffsetTest (#12213)Reviewers: Kvicii <Karonazaba@gmail.com>, David Arthur <mumrah@gmail.com>",3
KAFKA-7429: Enable key/truststore update with same filename/password (#5699),4
KAFKA-12620 Allocate producer ids on the controller (#10504)Introduce new AllocateProducerIds RPC and IBP 3.0-IV0 as part of KIP-730.This change adds a new AllocateProducerIds RPC which is used by the broker to request a block of producer IDs from the controller. The new IBP added will determine if the broker should talk directly to ZooKeeper (IBP < 3.0) or it if should use the new RPC to talk to the controller (IBP >= 3.0).Per-broker property overrides for ClusterTests were also added (in order to test mixed IBPs in a cluster)Reviewers: Colin P. McCabe <cmccabe@apache.org>,3
"MINOR: replace `late` with `out-of-order` in JavaDocs and docs (#7274)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-4427: Skip topic groups with no tasksAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2171 from enothereska/KAFKA-4427-topicgroups-with-no-tasks",5
"KAFKA-3562; Handle topic deletion during a sendFix timing window in producer by holding onto cluster object while processing send requests so that changes to cluster during metadata refresh don't cause NPE if a topic is deleted.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1478 from rajinisivaram/KAFKA-3562",5
MINOR: log connect reconfiguration error only if there was an errorAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #871 from gwenshap/fix-cc-log,2
"KAFKA-10106: log time taken to handle LeaderAndIsr request (#8807)Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-6345; Keep a separate count of in-flight requests to avoid ConcurrentModificationException.This keeps a separate count of the number of in flight requests so that sensor threads will not need to deal with ConcurrentModfiicationException.This would probably still be correct with volatile rather than AtomicInteger, but FindBugs flags the use of volatile as the count is incremented and decremented.Author: Sean McCauliff <smccauliff@linkedin.com>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>Closes #4460 from smccauliff/KAFKA-6345",2
KAFKA-8091; Remove unsafe produce from dynamic listener update test (#6443)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
MINOR: Allow Serdes subclasses to access WrapperSerdeThis PR loosens access restrictions on `WrapperSerde` to `protected` so that users can define a `Serdes` subclass that provides additional custom serde members following the same pattern as the parent class.This is my own work and is compatible with Kafka's license.Author: Jeff Klukas <jeff@klukas.net>Reviewers: Guozhang WangCloses #1382 from jklukas/expose-wrapperserde,1
"KAFKA-6973: Validate topic config message.timestamp.type (#5106)Specifying an invalid config (i.e. something other than `CreateTime` or`LogAppendTime`) via `TopicCommand` would previously cause thebroker to fail on start-up.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",0
MINOR: Updated KafkaZkClient.pathExists() to use ExistsRequestrather than using GetDataRequestAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4217 from mimaison/pathExists,5
"MINOR: fix NPE in iqv2 (#11702)There is a brief window between when the store is registered and whenit is initialized when it might handle a query, but there is no context.We treat this condition just like a store that hasn't caught up to thedesired position yet.Reviewers: Guozhang Wang <guozhang@apache.org>, Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org>, Patrick Stuedi <pstuedi@apache.org>",0
MINOR; Synchronize access to snapshots' TreeMap (#12464)Read and write access to the TreeMap in snapshots needs to be synchronized.Reviewers: David Arthur <mumrah@gmail.com>,5
"MINOR: improve EmbeddedKafkaCluster test utility for deleting topicsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck, Damian Guy, Eno Thereska, Guozhang WangCloses #3104 from mjsax/minor-improve-embedded-kafka-cluster",1
KAFKA-2913: missing partition check when removing groups from cacheAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #605 from hachikuji/KAFKA-2913,5
KAFKA-10386; Fix flexible version support for `records` type (#9163)This patch fixes the generated serde logic for the 'records' type so that it uses the compact byte array representation consistently when flexible versions are enabled.Reviewers: David Arthur <mumrah@gmail.com>,0
"MINOR: add session windows doc to streams.htmlAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Matthias J. Sax, Guozhang WangCloses #2547 from dguy/session-window-doc",2
"MINOR - fix typo in index corruption warning messageAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #606 from lindong28/minor-fix-typo",2
update version in quickstart to current,5
"MINOR: Replace string literal with constant in RequestChannel (#12134)Replace the ""RequestsPerSec"" literal value with the pre-existing constant `RequestsPerSec`.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-3085; BrokerChangeListener computes inconsistent live/dead broker list.Follow up PR as per comments in the ticket.junrao It should be correct now as `curBrokers` included only live brokers and live/dead brokers are computed based on it. Could you take a look when you have time?Author: David Jacot <david.jacot@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #756 from dajac/KAFKA-3085,4
KAFKA-3632; remove fetcher metrics on shutdown and leader migrationAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1312 from hachikuji/KAFKA-3632,5
Add auto leader rebalance support,1
"KAFKA-1289 Misc. nitpicks in log cleaner for new 0.8.1 features patch by Jay Kreps, reviewed by Sriram Subramanian and Jun Rao",1
KAFKA-3435: Remove `Unstable` annotation from new Java ConsumerAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #1113 from granthenke/remove-unstable,4
MINOR: add default-replication-factor to MockAdminClient (#11648)Reviewers: Bill Bejeck <bill@confluent.io>,5
"MINOR: clean up some remaining locking stuff in StateDirectory (#10608)Minor followup to #10342 that I noticed while working on the NamedTopology stuff. Cleans up a few things:We no longer need locking for the global state directory either, since it's contained within the top-level state directory lock. Definitely less critical than the task directory locking, since it's less vulnerable to IOExceptions given that it's just locked and unlocked once during the application lifetime, but nice to have nonethelessClears out misc. usages of the LOCK_FILE_NAME that no longer apply. This has the awesome side effect of finally being able to actually delete obsolete task directories, whereas previously we had to leave behind the empty directory due to a ridiculous Windows bug (though I'm sure they would claim ""it's not a bug it's a feature"" 😉 )Lazily delete old-and-now-unused lock files in the StateDirectory#taskDirIsEmpty method to clean up the state directory for applications that upgraded from an older version that still used task lockingReviewers: Walker Carlson <wcarlson@confluent.io>",5
"MINOR: Put states in proper order, increase timeout for starting (#6105)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-6246; Dynamic update of listeners and security configs (#4488)Dynamic update of listeners as described in KIP-226. This includes:  - Addition of new listeners with listener-prefixed security configs  - Removal of existing listeners  - Password encryption  - sasl.jaas.config property for broker's JAAS config prefixed with listener and mechanism name,0
KAFKA-146 testUnreachableServer sporadically fails; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179043 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-4039; Fix deadlock during shutdown due to log truncation not allowedAuthor: Maysam Yabandeh <myabandeh@dropbox.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #2474 from ijuma/kafka-4039-deadlock-during-shutdown,4
"KAFKA-6611, PART II: Improve Streams SimpleBenchmark (#4854)SimpleBenchmark:1.a Do not rely on manual num.records / bytes collection on atomic integers.1.b Rely on config files for num.threads, bootstrap.servers, etc.1.c Add parameters for key skewness and value size.1.d Refactor the tests for loading phase, adding tumbling-windowed count.1.e For consumer / consumeproduce, collect metrics on consumer instead.1.f Force stop the test after 3 minutes, this is based on empirical numbers of 10M records.Other tests: use config for kafka bootstrap servers.streams_simple_benchmark.py: only use scale 1 for system test, remove yahoo from benchmark tests.Note that the JMX based metrics is more accurate than the manually collected metrics. Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: refactor SelectingIterator by scala iterator (#9755)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"MINOR: Fix a few compiler warnings (#6767)Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-9831: increase max.poll.interval.ms to avoid unexpected rebalance (#10301)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-9261; Client should handle unavailable leader metadata (#7770)The client caches metadata fetched from Metadata requests. Previously, each metadata response overwrote all of the metadata from the previous one, so we could rely on the expectation that the broker only returned the leaderId for a partition if it had connection information available. This behavior changed with KIP-320 since having the leader epoch allows the client to filter out partition metadata which is known to be stale. However, because of this, we can no longer rely on the request-level guarantee of leader availability. There is no mechanism similar to the leader epoch to track the staleness of broker metadata, so we still overwrite all of the broker metadata from each response, which means that the partition metadata can get out of sync with the broker metadata in the client's cache. Hence it is no longer safe to validate inside the `Cluster` constructor that each leader has an associated `Node`Fixing this issue was unfortunately not straightforward because the cache was built to maintain references to broker metadata through the `Node` object at the partition level. In order to keep the state consistent, each `Node` reference would need to be updated based on the new broker metadata. Instead of doing that, this patch changes the cache so that it is structured more closely with the Metadata response schema. Broker node information is maintained at the top level in a single collection and cached partition metadata only references the id of the broker. To accommodate this, we have removed `PartitionInfoAndEpoch` and we have altered `MetadataResponse.PartitionMetadata` to eliminate its `Node` references.Note that one of the side benefits of the refactor here is that we virtually eliminate one of the hotspots in Metadata request handling in `MetadataCache.getEndpoints` (which was renamed to `maybeFilterAliveReplicas`). The only reason this was expensive was because we had to build a new collection for the `Node` representations of each of the replica lists. This information was doomed to just get discarded on serialization, so the whole effort was wasteful. Now, we work with the lower level id lists and no copy of the replicas is needed (at least for all versions other than 0).Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",5
KAFKA-12620 Allocate Producer IDs in KRaft controller (#10752)This is part 2 of KIP-730. Part 1 was in #10504.This PR adds QuorumController support for handling AllocateProducerIDs requestsand managing the state of the latest producer ID block in the controller by committingthis state to the metadata log.Reviewers: Colin P. McCabe <cmccabe@apache.org>,2
"MINOR: fix ClusterControlManager log message (#11358)Fix a ClusterControlManager log message that should have distinguished betweennewly registered and re-registered brokers, but did not due to a bug.Reviewers: Ismael Juma <ismael@juma.me.uk>, José Armando García Sancio <jsancio@gmail.com>",0
kafka-1493; Use a well-documented LZ4 compression format and remove redundant LZ4HC option; patched by James Oliver; reviewed by Jun Rao,4
MINOR: Allow topics with `null` leader on MockAdminClient createTopic. (#8345)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
MINOR: Add maybeThrow method to ZooKeeperClient AsyncResponse* Add maybeThrow method to AsyncResponse* Update KafkaZkClient to use newly introduced maybeThrow* Change AsyncResponse from trait to abstract class formore readable stacktraces (there's no benefit in using atrait here)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4266 from omkreddy/KAFKAZKCLEINT_EXCEPTION_CLEANUP,4
"KAFKA-9410; Make groupId Optional in KafkaConsumer (#7943)Reviewers: Ron Dagostino <rndgstn@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-8765: Remove interface annotations in Streams API (#7174)Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
KAFKA-1382 follow up patch; reviewed by Neha Narkhede,5
"KAFKA-10500: Add failed-stream-threads metric for adding + removing stream threads (#9614)Part of KIP-663.Reviewer: Bruno Cadonna <bruno@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
KAFKA-1747 TestcaseEnv improperly shares state between instances; reviewed by Neha Narkhede,3
"MINOR: Fix transient failure in SocketServerTest.testConnectionIdReuseTwo requests sent together may not always trigger a staged receive since the requests may not be received in a single poll and the channel is muted when receives are complete. Hence attempt to stage multiple times until a receive is staged to make the test more stable.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>Closes #3712 from rajinisivaram/MINOR-connectionidreuse-test",5
"KAFKA-5520: KIP-171; Extend Consumer Group Reset Offset for Stream ApplicationKIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-171+-+Extend+Consumer+Group+Reset+Offset+for+Stream+ApplicationMerge changes from KIP-198Ref: https://github.com/apache/kafka/pull/3831Author: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Author: Matthias J. Sax <matthias@confluent.io>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Author: Guozhang Wang <wangguoz@gmail.com>Author: Apurva Mehta <apurva@confluent.io>Author: Rajini Sivaram <rajinisivaram@googlemail.com>Author: Jason Gustafson <jason@confluent.io>Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Author: Bill Bejeck <bill@confluent.io>Author: Dong Lin <lindong28@gmail.com>Author: Soenke Liebau <soenke.liebau@opencore.com>Author: Colin P. Mccabe <cmccabe@confluent.io>Author: Damian Guy <damian.guy@gmail.com>Author: Xavier Léauté <xl+github@xvrl.net>Author: Maytee Chinavanichkit <maytee.chinavanichkit@linecorp.com>Author: Joel Hamill <git config --global user.email>Author: Paolo Patierno <ppatierno@live.com>Author: siva santhalingam <siva.santhalingam@gmail.com>Author: Tommy Becker <tobecker@tivo.com>Author: Mickael Maison <mickael.maison@gmail.com>Author: Onur Karaman <okaraman@linkedin.com>Author: tedyu <yuzhihong@gmail.com>Author: Xin Li <Xin.Li@trivago.com>Author: Magnus Edenhill <magnus@edenhill.se>Author: Manjula K <manjula@kafka-summit.org>Author: Hugo Louro <hmclouro@gmail.com>Author: Jeff Widman <jeff@jeffwidman.com>Author: bartdevylder <bartdevylder@gmail.com>Author: Ewen Cheslack-Postava <me@ewencp.org>Author: Jacek Laskowski <jacek@japila.pl>Author: Tom Bentley <tbentley@redhat.com>Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4159 from jeqo/feature/kip-171",5
"MINOR: Update Trogdor StringExpander regex to handle an epilogue (#6123)Update the Trogdor StringExpander regex to handle an epilogue.  Previously the regex would use a lazy quantifier at the end, which meant it would not catch anything after the range expression.  Add a unit test.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",3
Actually run the delete topic command in kafka.py (#7776)Reviewed-By: Jason Gustafson <jason@confluent.io>,5
KAFKA-10090 Misleading warnings: The configuration was supplied but i… (#8826)Reviewers: Jun Rao <junrao@gmail.com>,5
MINOR: Pass RecordingLevel to MetricConfig in the brokerThis is a KIP-104/105 follow-up. Thanks to ijuma for pointing out.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2350 from enothereska/minor-broker-level-config,5
KAFKA-2288; Follow-up to KAFKA-2249 - reduce logging and testing; Reviewd by Jun Rao,3
"MINOR: fix JavaDocs warnings - add some missing annotations for deprecated methodsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #4005 from mjsax/minor-fix-javadoc-warnings",2
KAFKA-7352; Allow SASL Connections to Periodically Re-Authenticate (KIP-368) (#5582)KIP-368 implementation to enable periodic re-authentication of SASL clients. Also adds a broker configuration option to terminate client connections that do not re-authenticate within the configured interval.,5
"MINOR: Fix one flaky test in MetricsTest and improve checks for another* Fix flakiness of `testBrokerTopicMetricsUnregisteredAfterDeletingTopic` by notconsuming messages. Filed KAFKA-5238 to track the issue that metrics for a deletedtopic may be re-created if there are fetch requests in the purgatory.* Check the log size in `testBrokerTopicMetricsBytesInOut` before attempting to readthe `replicationBytesIn` metric. This helps understand where things have gone wrongif if the metric has not increased (i.e. if it was an issue replicating or with the metric).* Only remove the replication bytes in/out if the metrics are defined. This should notaffect the behaviour due to the tags, but it makes the code clearer. We've seen somecases in Jenkins when the metric does not exist and it's still unclear how that canhappen.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3042 from ijuma/more-informative-assertion-for-flaky-metrics-test",5
"KAFKA-9929: Support reverse iterator on KeyValueStore (#9137)Add new methods to KeyValueStore interfaces to support reverse iteration.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
"MINOR: Use correct connectionId in SocketServer log messageAlso add connection id to KafkaChannel exception messageAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3529 from rajinisivaram/MINOR-log-connection-id",5
Update description of num.partitions config in sample server properties - issue reported by Vaibhav Puranik,0
KAFKA-5118: Improve message for Kafka failed startup with non-Kafka data in data.dirsExplicitly throwing clear exceptions when starting up a Kafka with some non-Kafka data in data.dirs.Author: amethystic <huxi_2b@hotmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2907 from amethystic/kafka-5118_improve_msg__for_failed_startup_with_nonKafka_data,5
MINOR: Fix javadoc at org.apache.kafka.clients.producer.KafkaProducer.InterceptorCallback#onCompletion (#7337)Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
MINOR: code cleanup for inconsistent naming (#8871)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"KAFKA-8070: Increase consumer startup timeout in system tests (#6405)For consumers using SSL, this timeout includes the time to create and copy keystores and truststores and sometime it takes longer than 10s to complete the security setup before starting the consumer process.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: Adding LINE corp logo to streams pageAuthor: Manjula K <manjula@kafka-summit.org>Author: manjuapu <manjula@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3940 from manjuapu/customer-logo-stream,2
MINOR: More graceful handling of buffers that are too small in Record's `isValid` and `ensureValid`Also add tests and make `Crc32.update` perform the same argument checks as`java.util.zip.CRC32`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1672 from ijuma/record-is-valid-should-be-more-robust,5
"KAFKA-9566: Improve DeserializationExceptionHandler JavaDocs (#9837)Reviewers: John Roesler <john@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",5
KAFKA-12728: Upgrade gradle to 7.0.2 and shadow to 7.0.0 (#10606)Details:* gradle upgrade: 6.8.3 -> 7.0.2  https://github.com/gradle/gradle/releases/tag/v7.0.0  https://github.com/gradle/gradle/releases/tag/v7.0.1  https://github.com/gradle/gradle/releases/tag/v7.0.2* 'distributionSha256Sum' gradle property is included into 'gradle-wrapper.properties' file* gradle shadow plugin upgrade: 6.1.0 -> 7.0.0  https://github.com/johnrengelman/shadow/releases/tag/7.0.0* Remaining configurations obsoleted in Gradle 6 (and removed in Gradle 7) are replaced:  `compile` -> `implementation`  `testCompile` -> `testImplementation`Reviewers: Ismael Juma <ismael@juma.me.uk>,3
MINOR: Update junit to 5.7.0 (#9282)The final release is now out:https://junit.org/junit5/docs/5.7.0/release-notes/index.htmlReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"KAFKA-8003; Fix flaky testFencingOnTransactionExpirationWe see this failure from time to time:```java.lang.AssertionError: expected:<1> but was:<0>at org.junit.Assert.fail(Assert.java:89)at org.junit.Assert.failNotEquals(Assert.java:835)at org.junit.Assert.assertEquals(Assert.java:647)at org.junit.Assert.assertEquals(Assert.java:633)at kafka.api.TransactionsTest.testFencingOnTransactionExpiration(TransactionsTest.scala:512)```The cause is probably that we are using `consumeRecordsFor` which has no expectation on the number of records to fetch and a timeout of just 1s. This patch changes the code to use `consumeRecords` and the default 15s timeout.Note we have also fixed a bug in the test case itself, which was using the wrong topic for the second write, which meant it could never have failed in the anticipated way anyway.Author: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #6905 from hachikuji/fix-flaky-transaction-test",3
KAFKA-6694: The Trogdor Coordinator should support filtering task responses (#4741),1
"KAFKA-5899: Added Connect metrics for connectors (KIP-196)This PR is the first of several subtasks for [KAFKA-2376](https://issues.apache.org/jira/browse/KAFKA-2376) to add metrics to Connect worker processes. See that issue and [KIP-196 for details](https://cwiki.apache.org/confluence/display/KAFKA/KIP-196%3A+Add+metrics+to+Kafka+Connect+framework).This PR adds metrics for each connector using Kafka’s existing `Metrics` framework. This is the first of several changes to add several groups of metrics, this change starts by adding a very simple `ConnectMetrics` object that is owned by each worker and that makes it easy to define multiple groups of metrics, called `ConnectMetricGroup` objects. Each metric group maps to a JMX MBean, and each metric within the group maps to an MBean attribute.Future PRs will build upon this simple pattern to add metrics for source and sink tasks, workers, and worker rebalances.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewencp@confluent.io>Closes #3864 from rhauch/kafka-5899",5
"KAFKA-4839; Throw NoOffsetForPartitionException from poll once for all TopicPartitions affectedSigned-off-by: radai-rosenblatt <radai.rosenblattgmail.com>Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2637 from radai-rosenblatt/KAFKA-4839",5
"KAFKA-7689; Add AlterConsumerGroup/List Offsets to AdminClient [KIP-396] (#7296)This patch implements new AdminClient APIs to list offsets and alter consumer group offsets as documented in KIP-396: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=97551484.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Documentation improvements* Fix typo in api.html* Mark security features as beta quality (similar to new consumer). Is there better wording?* Improve wording and clarify things in a number of places* Improve layout of `pre` blocks (tested locally, which doesn't seem to use the same stylesheets as the deployed version)* Use producer.config in console-producer.sh command* Improve SASL documentation structureAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao, Magnus Edenhill, Gwen ShapiraCloses #550 from ijuma/documentation-improvements",2
"KAFKA-12709; Add Admin API for `ListTransactions` (#10616)This patch adds `Admin` support for the `listTransactions` API, which was added by [KIP-664](https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions). Similar to `listConsumerGroups`, the new `listTransactions` API is intended to be sent to all brokers. Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: doc changes for KIP-1381. Core concepts (added the stream time definition), upgrade guide and developer guide.2. Related Java docs changes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3732 from guozhangwang/KMinor-kip138-docs",2
"KAFKA-8014: Extend Connect integration tests to add and remove workers dynamically (#6342)Extend Connect's integration test framework to add or remove workers to EmbeddedConnectCluster, and choosing whether to fail the test on ungraceful service shutdown. Also added more JavaDoc and other minor improvements. Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>Closes #6342 from kkonstantine/KAFKA-8014",5
Bug in the collate logic of the DefaultEventHandler dispatches empty list of messages using the producer KAFKA-110; patched by Neha; reviewed by Jungit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159465 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-8856: Add Streams config for backward-compatible metrics (#7279)Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
KAFKA-13141; Skip follower fetch offset update in leader if diverging epoch is present (#11136)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: Fix wrong commentsAuthor: Yukun Guo <gyk.net@gmail.com>Reviewers: Gwen ShapiraCloses #1198 from gyk/fix-comment,0
KAFKA-7687; Print batch level information in DumpLogSegments when deep iterating (#5976)DumpLogSegments should print batch level information when deep-iteration is specified.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-12598: ConfigCommand should only support communication via ZooKeeper for a reduced set of cases (#10811)Checked the documentation, we must use `--zookeeper` option in 3 places (alter and describe):1. user configs where the config is a SCRAM mechanism name (i.e. a SCRAM credential for a user)2. update broker configs for a particular broker when that broker is down3. broker default configs when all brokers are downReference:1. [config SCRAM Credentials](https://kafka.apache.org/documentation/#security_sasl_scram_credentials)2. [Update config before broker started](https://kafka.apache.org/documentation/#dynamicbrokerconfigs)So, after this PR, we only support `--zookeeper` on `users` and `brokers` entity. Add some argument parse rules and tests. Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-4103: Fix regression in DumpLogSegments offsets decoderAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1807 from hachikuji/KAFKA-4103",5
"KAFKA-2984: KTable should send old values when requiredguozhangwangAt DAG level, `KTable<K,V>` sends (key, (new value, old value)) to down stream.  This is done by wrapping the new value and the old value in an instance of `Change<V>` class and sending it as a ""value"" part of the stream. The old value is omitted (set to null) by default for optimization. When any downstream processor needs to use the old value, the framework should enable it (see `KTableImpl.enableSendingOldValues()` and implementations of `KTableProcessorSupplier.enableSensingOldValues()`).NOTE: This is meant to be used by aggregation. But, if there is a use case like a SQL database trigger, we can add a new KTable method to expose this.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #672 from ymatsuda/trigger",5
KAFKA-1755; trivial follow-up to fix comment in CleanerTest,3
MINOR: Add `KafkaAdminClient.getListOffsetsCalls` benchmark (#10955)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Fix kafka-run-class for Java 10 (#4895)We need to match to the end of the line to make it work with Java 10 as explained in the expanded comment.Tested manually for all supported versions:```shellecho $(.../jdk1.8.0_152.jdk/Contents/Home/bin/java -version 2>&1 | sed -E -n 's/.* version ""([0-9]*).*$/\1/p')1echo $(.../jdk-9.0.4.jdk/Contents/Home/bin/java -version 2>&1 | sed -E -n 's/.* version ""([0-9]*).*$/\1/p')9echo $(.../jdk-10.jdk/Contents/Home/bin/java -version 2>&1 | sed -E -n 's/.* version ""([0-9]*).*$/\1/p')10echo $(.../jdk-10.0.1.jdk/Contents/Home/bin/java -version 2>&1 | sed -E -n 's/.* version ""([0-9]*).*$/\1/p')10```",1
"HOTFIX: Poll with zero milliseconds during restoration phase1. After the poll call, re-check if the state has been changed or not; if yes, initialize the tasks again.2. Minor log4j improvements.Author: Guozhang Wang <wangguoz@gmail.com>Author: Damian Guy <damian.guy@gmail.com>Author: Jason Gustafson <jason@confluent.io>Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>Closes #4096 from guozhangwang/KHotfix-restore-only",0
"MINOR: move non-management methods from TaskManager to Task Executor (#11738)Basic refactoring with no logical changes to lay the groundwork & facilitate reviews for error handling work.This PR just moves all methods that go beyond the management of tasks into a new TaskExecutor class, such as processing, committing, and punctuating. This breaks up the ever-growing TaskManager class so it can focus on the tracking and updating of the tasks themselves, while the TaskExecutor can focus on the actual processing. In addition to cleaning up this code this should make it easier to test this part of the code.Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
KAFKA-9648: Add configuration to adjust listen backlog size for Acceptor (KIP-764) (#11422)This patch implements KIP-764 as described in https://cwiki.apache.org/confluence/display/KAFKA/KIP-764%3A+Configurable+backlog+size+for+creating+Acceptor.Reviewers: David Jacot <djacot@confluent.io>,5
Address flakiness of CustomQuotaCallbackTest#testCustomQuotaCallback (#6330),3
MINOR: Protocol schema refactor follow-up- Use constants in a few places that were missed- Remove ProtoUtils by moving its methods to Schema- Merge SchemaVisitor and SchemaVisitorAdapter- Change SchemaVisitor package.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3895 from ijuma/protocol-schema-refactor-follow-ups,4
MINOR: Fix testUniqueErrorCodes unit test failureError code collision due to incorrect mergeconflict resolution after 2 PRs were merged inquick succession.Author: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3931 from wushujames/KAFKA-5856.buildfix,0
MINOR: Add note about num.standby.replicas (#5271)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-5248; Remove unused/unneeded retention time in TxnOffsetCommitRequestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3058 from hachikuji/KAFKA-5248",5
MINOR: Fix deprecation warnings in SlidingWindowedCogroupedKStreamImplTest (#10703)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-1060 Break-down sendTime into responseQueueTime and the real sendTime; reviewed by Neha Narkhede and Jun Rao,4
"MINOR: Follow-up from KAFKA-2720 with comment/style fixesAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1513 from hachikuji/followup-for-kafka-2720",5
MINOR: Fix document header/footer linksBased on:  https://github.com/apache/kafka-site/pull/27I recommend also merging into 10.1.0.0 branch to avoid mishaps when re-publishing docs.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2077 from gwenshap/protocol_doc_fix,2
"KAFKA-3698; Update the message format section.Author: Jiangjie Qin <becket.qin@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1375 from becketqin/KAFKA-3698",5
