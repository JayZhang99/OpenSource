commit_msg,labels
[FLINK-5427] [docs] Fix code example in event_timestamps_watermarks.mdThis closes #3082,0
[FLINK-18776][avro] Avoid hardcoded scala versionThis closes #13032.,2
[FLINK-15102][datastream/api] Add continuousSource() methods to the StreamExecutionEvironment.The patch also adds a new SourceEventType of NoMoreSplitsEvent to allow the SourceReaderBase to exit after all the work is done.,1
[FLINK-14014] Bump maven-shade-plugin to 3.2.1Bumps maven-shade-plugin to 3.2.1 as version below 3.1.0 could not workwell with ASM 6.0(MSHADE-258) which is dependent by Beam,1
kafka-899; LeaderNotAvailableException the first time a new message for a partition is processed; patched by Jun Rao; reviewed by Neha Narkhede,1
修改页面git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@795 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Add unit test for ExtensionLoader,3
"Remove unsafe getFieldFast() method from Tuple, because it turned out to be not faster than the switch-based getField() method.",1
[FLINK-7281] Make quickstart versions depend on project versions,1
[FLINK-11843] Remove old DispatcherRunnerImpl and DispatcherRunnerFactoryImpl,1
[hotfix][yarn] Remove unused internal options in YarnConfigOptionsInternal,5
[FLINK-12472][yarn] Support setting attemptFailuresValidityInterval of jobs on YarnThis closes #8400.,0
KAFKA-1539 Fsync offset checkpoint file after writing.,2
[FLINK-1622][java-api][scala-api] add a GroupCombine operatorThe GroupCombine operator acts like a the optional combine step in theGroupReduceFunction. It is more general because it combines from aninput to an arbitrary output type. Combining is performed on thepartitions with as much data in memory as possible. This may lead topartial results.The operator can be used to pre-combine elements into an intermediateoutput format before applying a proper groupReduce to produce the finaloutput format.* make Combine and FlatCombine generic by adding an output type* add documentation* Reuse GroupReduceCombineDriver and SynchronousChainedCombineDriver for GroupCombine operator** make them more generic by specifying input and output type** implement AllCombineDriver* add Java tests* add Scala testThis closes #466,3
3.0 migration applications (#7102),5
"KAFKA-6608; Add timeout parameter to blocking consumer calls [KIP-266] (#5014)This patch implements the consumer timeout APIs from KIP-266 (everything except `poll()`, which was done separately).Reviewers:  John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[FLINK-29030][core] Add constant for generic type doc reference,2
[FLINK-17339][examples] Update examples due to default planner changing.,4
KAFKA-9499; Improve deletion process by batching more aggressively (#8053)This PR speeds up the deletion process by doing the following:- Batch whenever possible to minimize the number of requests sent out to other brokers;- Refactor `onPartitionDeletion` to remove the usage of `allLiveReplicas`.Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-21435][table] Use a dedicated SQL expression in Table APIThis closes #14986.,1
[hotfix][table] Switched from PatternSelectFunction to PatternProcessFunction,1
Removed buggy clean-up optimization,4
Added main to Sopremo server,1
"KAFKA-3741; allow users to specify default topic configs for internal topicsAllow users to specify default topic configs for streams internal topics by supplying properties from `TopicConfig` with a prefix.Supplied defaults are used when creating the internal topics. They are overridden by the configs supplied along with the `InternalTopicConfig`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3459 from dguy/kafka-3741",5
"[hotfix][datastream, core] Move StreamTransformation to flink-core",2
Adapted ITCases for contracts to new datamodel,5
Add tupleType() method to CsvReader that allows to read directly into subclasses of Tuple,1
[FLINK-21926][doc] Add docs for fine-grained resource managementThis closes #16561,2
[FLINK-2419] [hotfix] addSink now uses transform + remove double checkpoint commit at head operator,1
[FLINK-10419] Added IT test to check declineCheckpoint invocation,3
"MINOR: Stop logging 404s at ERROR level in ConnectCatches valid 404 exceptions, triggered by any HTTP request to a nonexistent path on the Connect REST API, higher in the code to not to log an ERROR log which can be seen as a false alarmReviewers: Chris Egerton <fearthecellos@gmail.com>",2
[streaming] Minor fixes,0
[hotfix] Exclude spider.log file from jekyll,2
"[FLINK-6945] Fix TaskCancelAsyncProducerConsumerITCase by removing race conditionThe TaskCacnelAsyncProducerConsumerITCase#testCancelAsyncProducerAndConsumer test casesometimes failed with a NPE because of a race condition. The problem was that someinvokables set static fields which are checked in the main thread. Since we checkedthe wrong field, the one for the consumer, after making sure that the produceris running, this could lead to a race condition if the consumer wasn't running yet.This closes #4139.",1
KAFKA-13123: close KeyValueIterator instances in example code and tests (#11105)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[Bugfix] Resolve the issues about the demos using DubboBootstrap (#5314)* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5309 : [ISSURE] The beans of Dubbo's Config can't be found on the ReferenceBean's initialization* Polish apache/dubbo#5312 : Resolve the demos' issues of zookeeper and nacos* Polish apache/dubbo#5313 : [Migration] migrate the code in common module from cloud-native branch to master,1
[FLINK-28621] Enable Date/Time&Optional support for all mappers,1
KAFKA-7288; Fix check in SelectorTest to wait for no buffered bytes (#6415)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"MINOR: Update README to specify Gradle 4.6 as the minimum required version (#5606)#5602 uses `annotationProcessor`, which was introduced in Gradle 4.6.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
"[FLINK-1005] By default, new objects are created for each element in group operations",1
[hotfix][table-api-java] Make DataTypeFactory configurable for CatalogManager,2
[FLINK-6434] [tests] Harden and speed up SlotPoolRpcTest,3
"MINOR: Disable JmxTool in kafkatest console-consumer by default (#7785)Do not initialize `JmxTool` by default when running console consumer. In order to support this, we remove `has_partitions_assigned` and its only usage in an assertion inside `ProduceConsumeValidateTest`, which did not seem to contribute much to the validation.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix] [docs] Fix flink-s3-fs-* README entry for the service file,2
"KAFKA-4930: Enforce set of legal characters for connector names (KIP-212)…to check for empty connector name and illegal characters in connector name. This also fixes  KAFKA-4938 by removing the check for slashes in connector name from ConnectorsResource.Author: Ewen Cheslack-Postava <me@ewencp.org>Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Gwen Shapira <cshapi@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2755 from soenkeliebau/KAFKA-4930",5
"KAFKA-7353: Connect logs 'this' for anonymous inner classesReplace 'this' reference in anonymous inner class logs to out class's 'this'Author: Kevin Lafferty <kevin.lafferty@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Arjun Satish <arjun@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5583 from kevin-laff/connect_logging",2
DUBBO-323 增加toString方法git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1487 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-1997][table] Add <> and != for un-equal in expressions,1
"KAFKA-5376; Ensure aborted transactions are propagated in DelayedFetchAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3239 from hachikuji/KAFKA-5376",5
[streaming] Created StreamComponentFactory for the common methods of StreamSource and StreamTask,1
"KAFKA-4357; Fix consumer group describe output when there is no active member (old consumer)Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jason Gustafson <jason@confluent.io>Closes #2075 from vahidhashemian/KAFKA-4357",5
[FLINK-13632] Port StreamElementSerializer test to TypeSerializerUpgradeTestBase,3
"[hotfix][build][sql] Remove slf4j/log4j dependenciesThe SQL client does not require explicit slf4j/log4j dependencies.slf4j-api is already defined in the root pom, whereas the log4j-related dependencies are just not necessary since the distribution provides them.",1
[FLINK-2318] Union can be used as BroadcastVariableThis closes #1390,1
"[FLINK-2332] [runtime] Adds leader session IDs and registration session IDs to JobManager and TaskManager messages.Refactors Flink's actor traits to support stackable traitsRefactored Flink's actors to use a factory method to generate messagesReplaced ActorRef with InstanceGateway in Task, RuntimeEnvironment and ExecutionGraphAdd commentsAdd test cases for registration session ID and leader session IDAdds IT case to check that a CancelMessage with the wrong leader session ID is discardedCorrected order of visibility and abstract modifiers. Removed lazy log member from FlinkActor. Made RequiresLeaderSessionID a Java interface.This closes #917.",1
merge 2.7 metadata annotations definition to 3.0 (#8305)Co-authored-by: kalman03 <kalman03@qq.com>,5
DUBBO-371 zookeeper注册中心改为使用zkclient实现git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1689 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-10199: Cleanup TaskManager and Task interfaces (#12397)In order to integrate with the state updater, we would need to refactor the TaskManager and Task interfaces. This PR achieved the following purposes:    Separate active and standby tasks in the Tasks placeholder, plus adding pendingActiveTasks and pendingStandbyTasks into Tasks. The exposed active/standby tasks from the Tasks set would only be mutated by a single thread, and the pending tasks hold for those tasks that are assigned but cannot be actively managed yet. For now they include two scenarios: a) tasks from unknown sub-topologies and hence cannot be initialized, b) tasks that are pending for being recycled from active to standby and vice versa. Note case b) would be added in a follow-up PR.    Extract any logic that mutates a task out of the Tasks / TaskCreators. Tasks should only be a place for maintaining the set of tasks, but not for manipulations of a task; and TaskCreators should only be used for creating the tasks, but not for anything else. These logic are all migrated into TaskManger.    While doing 2) I noticed we have a couple of minor issues in the code where we duplicate the closing logics, so I also cleaned them up in the following way:    a) When closing a task, we first trigger the corresponding closeClean/Dirty function; then we remove the task from Tasks bookkeeping, and for active task we also remove its task producer if EOS-V1 is used.    b) For closing dirty, we swallow the exception from close call and the remove task producer call; for closing clean, we store the thrown exception from either close call or the remove task producer, and then rethrow at the end of the caller. The difference though is that, for the exception from close call we need to retry close it dirty; for the exception from the remove task producer we do not need to re-close it dirty.Reviewer: Bruno Cadonna <cadonna@apache.org>",1
[FLINK-15156] Warn user if System.exit() is called in user codeThis closes #14499,1
DUBBO-252 @Adaptive支持getMethodParametergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1140 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Improved computation of initial checkpoint state,5
DUBBO-110 统一startup和shutdown脚本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@503 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[3.0] Fix validation exception (#9620)* [3.0] Fix validation exception* fix ut,0
fix  cache Class avoid PermGen space OOM in dubbo3.0 (#7386)* fix #6742 cache Class avoid PermGen space OOM* optimization cache Class avoid PermGen space OOM* optimization cache Class avoid PermGen space OOM* Optimize Proxy WeakReference to SoftReference,0
Refactored and Reorganized sopremo-common,4
[FLINK-19756][table-planner] Rename BatchExecMultipleInputNode/StreamExecMultipleInputNode to BatchExecMultipleInput/StreamExecMultipleInput,2
[FLINK-4185] Reflecting rename from Tachyon to Alluxio.This closes #2222,2
Minor fix: Turning on TCP NODELAY in the Simple Consumer. This fix has a significant impact on single fetch request performance from a latency standpointgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1339944 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-12963] [state-processor] Add savepoint writer for bootstrapping new savepoints,1
[FLINK-12372] [runtime] implement ExecutionSlotAllocatorThis closes #8486.,1
[FLINK-17523] Add call expression with a class of UDF as a parameter,2
"[docs] Add ""Iterator Data Sink"" section to DataStream guide.This closes #1487",5
UT： refer metadata service (#8761)* add ut for refer metadata service* fix mockito* fix* fix* fix,0
[docs] Group monitoring/debugging docs,2
[FLINK-21255] Add tests for WaitingForResources stateThis closes #14852,3
[FLINK-7320] [futures] Replace Flink's futures with Java 8's CompletableFuture in SchedulerAddress PR commentsThis closes #4435.,1
KAFKA-2957: Fix typos in Kafka documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Gwen ShapiraCloses #641 from vahidhashemian/KAFKA-2957(cherry picked from commit 1f98b0315c92cf8c89f07241485fa6db8b496fdc)Signed-off-by: Gwen Shapira <cshapi@gmail.com>,5
KAFKA-14015: Reconfigure tasks if configs have been changed for restarted connectors in standalone mode(#12568)Reviewers: Chris Egerton <chrise@aiven.io>,4
"[FLINK-6952, FLINK-6985] [docs] Fix Javadocs linksThis is a follow up to e7c887c and 0287758. For snapshot versionswe need to differntiate between title version and javadocs version.In addition, this removes an unneded config variable and updatesthe release scripts.",5
[FLINK-2057] [FLINK-2058] [core] Fix hadoop input split class loading and remove IOReadableWritable from InputSplits,4
[FLINK-8833] [sql-client] Create a SQL Client JSON format fat-jarThis closes #5700.,5
DUBBO-344 Logger自动搜索slf4j和jclgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1572 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-8592; Fix for resolving variables for dynamic config as per KIP-421. (#7031)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Stanislav Kozlovski <familyguyuser192@windowslive.com>",1
[FLINK-7875] [flip6] Start StaticFileServerHandler with random tmp dirThis closes #4861.,2
[streaming] StreamComponentHelper refactor to Generics,4
[hotfix] [scala-cep] Remove unnecessary testing dependency,3
MINOR: Replace EasyMock with Mockito in connect:basic-auth-extension (#11321)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
Constructor fix in sort-merger testcase.,3
"KAFKA-4860; Allow spaces in paths on windowsWhen we install kafka on path with spaces, batch files were failing, this PR is trying to fix this issue.Author: Vladimír Kleštinec <klestinec@gmail.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>Closes #2649 from klesta490/trunk",1
KAFKA-3259 KAFKA-3253; KIP-31/KIP-32 Follow-upThis PR includes a number of clean-ups:* Code style* Documentation wording improvements* Efficiency improvementsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #943 from ijuma/kafka-3259-kip-31-32-clean-ups,4
first pull request (#3396),5
[FLINK-7037] Remove scala suffic from flink-examples moduleThis closes  #4221.,2
[FLINK-21406][parquet] Rename ParquetAvroWriters to AvroParquetWriters,2
"MINOR: Remove throwing exception if not found from describe topics (#6112)We recently improved the handling of the InternalTopicManager retries with #6085. The AdminClient will throw an InvalidTopicException if the topic is not found. We need to ignore that exception as when calling AdminClient#describe we may not have had a chance to create the topic yet, especially with the case of internal topicsI've created a new test asserting that when an InvalidTopicException is thrown when the topic is not found we continue on.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-4586; Add purgeDataBefore() API (KIP-107)Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin <becket.qin@gmail.com>Closes #2476 from lindong28/KAFKA-4586",5
[hotfix] [streaming] Remove some unused internal classes,1
[FLINK-15592][hive] Add black list for Hive built-in functionscloses #10894.,1
removed old typica library,4
[FLINK-1466] Add support for complex types in Flink tuples for HCatInputFormats.This closes #411,2
[FLINK-12902][hadoop] Remove flink-shaded-yarn-tests,3
[streaming] Copy default state values for partitioned states,5
"KAFKA-6015; Fix NPE in RecordAccumulator after ProducerId resetIt is possible for batches with sequence numbers to be in the `deque` while at the same time the in flight batches in the `TransactionManager` are removed due to a producerId reset.In this case, when the batches in the `deque` are drained, we will get a `NullPointerException` in the background thread due to this line:```javaif (first.hasSequence() && first.baseSequence() != transactionManager.nextBatchBySequence(first.topicPartition).baseSequence())```Particularly, `transactionManager.nextBatchBySequence` will return null, because there no inflight batches being tracked.In this patch, we simply allow the batches in the `deque` to be drained if there are no in flight batches being tracked in the TransactionManager. If they succeed, well and good. If the responses come back with an error, the batces will be ultimately failed in the producer with an `OutOfOrderSequenceException` when the response comes back.Author: Apurva Mehta <apurva@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4022 from apurvam/KAFKA-6015-npe-in-record-accumulator",5
"[FLINK-11634][docs] Translate ""State Backends"" page into Chinese (#16522)this fix #16522",0
MINOR: Fix ProcessorContext JavaDocs and stream-time computation (#8603)Reviewer: John Roesler <john@confluent.io>,5
Cancel availability check for NopServiceDiscovery (#10271)Signed-off-by: crazyhzm <crazyhzm@gmail.com>,5
[FLINK-1201] [gelly] reverse and graph input methods,2
"MINOR: Document ""high watermark"" magic value for delete records requestAuthor: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4119 from ppatierno/minor-delrecords-prot",4
"[FLINK-4800] Introduce the TimestampedFileInputSplit for Continuous File ProcessingThis commit mainly introduces the TimestampedFileInputSplit,which extends the class FileInputSplit and also contains:i) the modification time of the file it belongs to and also, andii) when checkpointing, the point the reader is currently reading    from in the split the reader.This will be useful for rescaling. With this addition, theContinuousFileMonitoringFunction sends TimestampedFileInputSplitto the Readers, and the Readers' state now contain onlyTimestampedFileInputSplit.In addition, it refactors the code of the ContinuousFileMonitoringFunctionand that of the ContinuousFileReaderOperator along with the relatedtests.This closes #2618.",3
"[hotfix][task] Interrupt source legacy thread on failure.If a legacy source task fails outside of the legacy thread, the legacy threadblocks proper cancellation (completion future never completed).",5
fix UTs,0
Worked on getFileStatus method for S3 file system,5
"[3.0] Improve startup processing of api usage, auto start module (#9083)* Improve startup processing of api usage, auto start module* Improve ReferenceConfig ref checking* Fix MetadataServiceExporter* Fix NPE of attribute map* Replace checkStarted/checkStarting with checkState of ApplicationDeployer* Fix testMultiModuleDeployAndReload* improve deploy state notify and checking* Fix check state lock* Fix start future NPE of ApplicationDeployer* Add async export/refer tests* Avoid internal module wait itself* Improve deploy locks* Ensure complete start future when handle state event was throw an exception",0
[FLINK-16981][tests] Add global PowerMock exclusions,1
Fixed bug that sink tasks did not use the correct degree of parallelism to decide whether to create the target directory.,1
[FLINK-1201] [gelly] added label propagation in library,1
"KAFKA-13649: Implement early.start.listeners and fix StandardAuthorizer loading (#11969)Since the StandardAuthorizer relies on the metadata log to store its ACLs, we need to be sure thatwe have the latest metadata before allowing the authorizer to be used. However, if the authorizeris not usable for controllers in the cluster, the latest metadata cannot be fetched, becauseinter-node communication cannot occur. In the initial commit which introduced StandardAuthorizer,we punted on the loading issue by allowing the authorizer to be used immediately. This commit fixesthat by implementing early.start.listeners as specified in KIP-801. This will allow in superusersimmediately, but throw the new AuthorizerNotReadyException if non-superusers try to use theauthorizer before StandardAuthorizer#completeInitialLoad is called.For the broker, we call StandardAuthorizer#completeInitialLoad immediately after metadata catch-upis complete, right before unfencing. For the controller, we callStandardAuthorizer#completeInitialLoad when the node has caught up to the high water mark of thecluster metadata partition.This PR refactors the SocketServer so that it creates the configured acceptors and processors inits constructor, rather than requiring a call to SocketServer#startup A new function,SocketServer#enableRequestProcessing, then starts the threads and begins listening on theconfigured ports. enableRequestProcessing uses an async model: we will start the acceptor andprocessors associated with an endpoint as soon as that endpoint's authorizer future is completed.Also fix a bug where the controller and listener were sharing an Authorizer when in co-locatedmode, which was not intended.Reviewers: Jason Gustafson <jason@confluent.io>",5
init a list with only one element with singleton function to enhance perf (#9208)Reviewers: Bill Bejeck <bbejeck@apache.org>,1
KAFKA-7606: Remove deprecated options from StreamsResetter (#10411)Remove deprecated --zookeeper and --execute flagsReviewers: Matthias J. Sax <mjsax@confluent.io>,5
[FLINK-10353][kafka] Support change of transactional semantics in Kafka Producer with existing stateThis closes #7010.,4
[FLINK-3150] Make YARN container invocation configurableThis closes #3056,5
[FLINK-22021][table-planner-blink] Fix INTERVAL types conversion in RexNodeExtractorThis closes #15424,4
Add WordCount example with anonymous classes (for discussion),1
[FLINK-16744][task] Implement channel state reading and writing for unaligned checkpoints,2
[FLINK-3595] [runtime] Eagerly destroy buffer pools on cancellingThis closes #1780.,1
[streaming] Added TypeInfo to DataStream,5
KAFKA-13786: Add a note in`control.plane.listener.name` doc (#11978)Add a note in `control.plane.listener.name` doc to mention the value can't be identical with `inter.broker.listener.name`.Reviewers: Luke Chen <showuon@gmail.com>,2
[FLINK-5457] [docs] Add stub for Async I/O docs,2
[FLINK-13955][runtime] use mailbox execution model in ContinuousFileReaderOperator.Motivation: allow to avoid explicit synchronization and eventually to remove StreamTask.getCheckpointLock().ContinuousFileReaderOperator was changed significantly to avoidthe currently necessary thread and extra synchronization between blocking and non-blocking code(e.g.  format.reachedEnd and nextRecord)Performance is lower by ~15% because of the overhead of enqueueing and processing each mail (instead of just loop).,1
Fixed estimates for DataSource,5
[FLINK-23064][connector-hbase] Make connector options PublicEvolving,1
[FLINK-16044][doc] Extract libraries documentation to a top-level section,2
[hotfix][test] Add TestingRetrievableStateStorageHelper which is settable with exception,1
Remove usage of classes in Junit 4,3
[FLINK-20651] Update .editorconfig to match google-java-format,5
"[FLINK-15248][FileSystems] Allow FileUtils#compressDirectory to process relative directories.FileUtils#compressDirectory behaves buggy when processing relative directory path. If the path of target directory is a relative path, the relative path inside the target zip file can not be constructed correctly. Convert the relative path to absolute path before compressing it.",2
KAFKA-4991; Resolve findbugs warnings in KerberosLogin (#4394),2
[hotfix] Removed foul language. This closes #18722[hotfix] Removed foul language. This closes #18722,4
"MINOR: catch InvalidStateStoreException in QueryableStateIntegrationTestA couple of the tests may transiently fail in QueryableStateIntegrationTest as they are not catching InvalidStateStoreException. This exception is expected during rebalance.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1840 from dguy/minor-fix",0
kafka-1699; autoRebalanceScheduler.shutdown() causes deadlock while controller shutting down; patched by Sriharsha Chintalapani; reviewed by Jun Rao,1
[hotfix] Refactor the setup function of KubernetesTestBase,3
[FLINK-1110] Implement collection-based execution for coGroup,2
Finalizer Guardian先不Destroy对象 DUBBO-483 ReferceConfig添加Finalizer Guardian,5
"KAFKA-9500: Fix FK Join Topology (#8015)Corrects a flaw leading to an exception while building topologies that include both:* A foreign-key join with the result not explicitly materialized* An operation after the join that requires source materializationAlso corrects a flaw in TopologyTestDriver leading to output records being enqueued in the wrong order under some (presumably rare) circumstances.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-10625] [docs] Polishing MATCH_RECOGNIZE document,2
[FLINK-9990] [table] Add regex_extract function in TableAPI and SQLThis closes #6448.,1
[FLINK-4239] Set Default Allowed Lateness to Zero and Make Triggers Non-PurgingThis closes #2278.,1
KAFKA-9855 - return cached Structs for Schemas with no fields (#8472)At the time of this writing there are 6 schemas in kafka APIs with no fields - 3versions each of LIST_GROUPS and API_VERSIONS.When reading instances of these schemas off the wire there's little point inreturning a unique Struct object (or a unique values array inside that Struct)since there is no payload.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
[FLINK-21401] Make DispatcherTest.testWaitingForJobMasterLeadership independent of Scheduler implementationBy letting the DispatcherTest.testWaitingForJobMasterLeadership use the TestingJobManagerRunnerFactory we can abstract thistest from the implementation details of the Scheduler and when it shows which JobStatus.,3
kafka-1799; (add missing test file) ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG doesn't work; patched by Manikumar Reddy; reviewed by Jun Rao,1
[FLINK-28663][runtime] Allow multiple downstream consumer job vertices sharing the same intermediate dataset at scheduler sideThis closes #20350.,5
"fix compile error for example (#6526)Reviewers: Prashant Sabnekar, Bill Bejeck <bbejeck@gmail.com>",0
[FLINK-14381][table-planner-blink] Remove getPartitionFieldNames in PartitionableTableSource and PartitionableTableSinkThis closes #9909,1
[streaming] StreamSource and Task updated to support connection level partitioning,1
"KAFKA-4476: Kafka Streams gets stuck if metadata is missing - break loop in StreamPartitionAssigner.assign() in case partition metadata is missing - fit state transition issue (follow up to KAFKA-3637: Add method that checks if streams are initialised) - some test improvementsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Eno Thereska, Ismael Juma, Guozhang WangCloses #2209 from mjsax/kafka-4476-stuck-on-missing-metadata",5
"KAFKA-3160; Fix LZ4 FramingThis contribution is my original work and I license the work under Apache 2.0.Author: Dana Powers <dana.powers@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1212 from dpkp/KAFKA-3160",1
- fixed bug #63,0
[FLINK-14216][table] introduce temp system functions and temp functions to FunctionCatalogadapt existing APIs to the introduction of temporary system and temp functions according to FLIP-57.This closes #9822.,1
[hotfix] Stopping the StreamTask#systemTimerService explicitly after the invoke,5
"KAFKA-10885 Refactor MemoryRecordsBuilderTest/MemoryRecordsTest to avoid a lot of… (#9906)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",3
修改测试依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@103 1a56cb94-b969-4eaa-88fa-be21384802f2,1
SopremoTestPlanTest -> trying to find bug in 2 testcases,3
[FLINK-9088] [nifi-connector] Bump nifi-site-to-site-client to 1.6.0This closes #5891,2
[FLINK-25080][tests] Move tests to flink-core,2
"[3.0] allocate invokers space at initial time of AbstractDirectory, fix ConnectivityValidationTest (#9211)* allocate space for invokers and validInvokers to avoid NPE* extract operations of invokers and validInvokers* remove useless import* reset validInvokersInitialized at destroy()* add invokersInitialized for refreshInvoker* optimize codes* use local reference to avoid NPE* optimize codes* set empty instead of clearing at destroyInvokers()* remove useless lock* add lock for validInvoker* return unmodifiableList for getInvokers and getValidInvokers* return clone object to avoid being modified* fix ut* optimize code* refresh validInvokers at setInvokers* wait new task finished at checkConnectivity()* retrieve checkConnectivity and fix ConnectivityValidationTest* retrieve checkConnectivity* optimize setInvokers()",1
Mocked local channels acquire buffers in a blocked fashion now,5
"[FLINK-2994] [client] Report error cause when jobs switch to failing.For jobs that do not switch to FAILED, but rather RESTARTING, this now prints the error causeas well. Also minor improvement to exception printing in CliFrontend.",1
"KAFKA-4060: Remove zk client dependency in kafka streamsdguy guozhangwang This is a new PR for KAFKA-4060.Author: Hojjat Jafarpour <hojjat@Hojjat-Jafarpours-MBP.local>Author: Hojjat Jafarpour <hojjat@HojjatJpoursMBP.attlocal.net>Reviewers: Damian Guy, Matthias J. Sax, Isamel Juma, Guozhang WangCloses #1884 from hjafarpour/KAFKA-4060-Remove-ZkClient-dependency-in-Kafka-Streams-new",4
MINOR: Correct RestServerTest formatting,3
[flink-yarn-tests] Add check for exceptions in the flink logs.,2
重构checkDuplicate,5
"KAFKA-7778: Add KTable.suppress to Scala API (#6314)Detailed description* Adds KTable.suppress to the Scala API.* Fixed count in KGroupedStream, SessionWindowedKStream, and TimeWindowedKStream so that the value serde gets passed down to the KTable returned by the internal mapValues method.* Suppress API support for Java 1.8 + Scala 2.11Testing strategyI added unit tests covering:* Windowed KTable.count.suppress w/ Suppressed.untilTimeLimit* Windowed KTable.count.suppress w/ Suppressed.untilWindowCloses* Non-windowed KTable.count.suppress w/ Suppressed.untilTimeLimit* Session-windowed KTable.count.suppress w/ Suppressed.untilWindowClosesReviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-9372] [elasticsearch] Typo on Elasticsearch website linkThis closes #6018.,2
[FLINK-20315][doc] Optimize the compaction document to warn users about backpressureThis closes #14285,1
[hotfix][runtime] Remove executionCanceled() and executionFailed() from ExecutionVertexThis closes #8369.,0
KAFKA-3447; partitionState in UpdateMetadataRequest not logged properly state-change logAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1117 from ijuma/kafka-3447-metadata-cache-logging,5
Reworked input formats and source/sink tasks to be - more generic - support non-file inputs - allow user defined splits - allow user defined statistics gathering,1
[FLINK-21525] Move scheduler benchmarks to FlinkFix the compilation errors due to FLINK-21401,2
[hotfix] Enable memory manager with zero memory or zero pages,0
MINOR: Fix typo in test log4j.propertiesAuthor: Jeff Widman <jeff@jeffwidman.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3851 from jeffwidman/patch-1,5
[hotfix] Let AbstractEventTimeWindowCheckpointingITCase shutdown ZooKeeper after MiniCluster,5
[FLINK-6281] [jdbc] Add JDBCAppendTableSink.This closes #3712.,5
"[FLINK-16076][docs-zh] Translate ""Queryable State"" page into ChineseThis closes #12139.",1
[FLINK-21565][table-planner] Support more integer types in TIMESTAMPADDThis closes #17793,1
[FLINK-19449][table-planner] LEAD/LAG cannot work correctly in streaming modeThis closes #15747,1
[FLINK-10453][travis] Move hdp 2.4 tests to cron jobs,3
[hotfix][sql-gateway] Use camelCase for REST request/response body fields in session related APIs.,1
[FLINK-24387][table-planner] Remove code generation dependency on actual JSON node,5
GovWild,5
KAFKA-3704: Remove hard-coded block size in KafkaProducerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael JumaCloses #1371 from guozhangwang/K3565-remove-compression-blocksize,4
[FLINK-28556][refactor] Extract header fields of Buffer into a BufferHeader class for blocking shuffle file IOThis closes #20328.,2
Fixed #255,0
[FLINK-5571] [table] add open and close methods for UserDefinedFunctionThis closes #3176.,1
enable tcp no delay for netty 3 server (#1746)(cherry picked from commit 430fb4c),0
[FLINK-12823][datastream] Add ShuffleMode property to PartitionTransformationThis also wires the property all the way through to the JobGraph.,5
[Dubbo-3231]keep TagRouter consistent with 2.6.x (#3233)* keep TagRouter consistent with 2.6.x* refactor filterUsingStaticTag using lambda in tagRouter,1
[FLINK-8312][table] Fix ScalarFunction varargs length exceed 254This closes #5206,1
[runtime tests] Fix buggy recover a task manager failure integration test case[runtime tests] Fix TaskManagerFailsITCase and TaskManagerFailsWithSlotSharingITCase,0
"KAFKA-12803: Support reassigning partitions when in KRaft mode (#10753)Support the KIP-455 reassignment API when in KRaft mode. Reassignmentswhich merely rearrange partitions complete immediately. Those that onlyremove a partition complete immediately if the ISR would be non-emptyafter the specified removals. Reassignments that add one or morepartitions follow the KIP-455 pattern of adding all the adding replicasto the replica set, and then waiting for the ISR to include all the newpartitions before completing. Changes to the partition sets areaccomplished via PartitionChangeRecord.Reviewers: Jun Rao <junrao@gmail.com>",4
[FLINK-28140][python][docs] Improve the documentation by adding Python examples in several pagesThis closes #20290.,1
"MINOR update comments and docs to be gender-neutralWhile this is not technically part of KIP-629, I believe this makes our codebase more inclusive as well.cc gwenshapAuthor: Xavier Léauté <xvrl@apache.org>Reviewers: Gwen ShapiraCloses #9398 from xvrl/neutral-term",1
[FLINK-13728][docs] Fix wrong closing tag order in sidenavThis closes #9439,0
"KAFKA-2508; Replace UpdateMetadata{Request,Response} with o.a.k.c.req……uests equivalentAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <mail@harsha.io>Closes #896 from granthenke/update-metadata and squashes the following commits:2eb5d59 [Grant Henke] Address reviews497258d [Grant Henke] KAFKA-2508: Replace UpdateMetadata{Request,Response} with o.a.k.c.requests equivalent",5
"MINOR: Remove topic null check from `TopicIdPartition` and adjust constructor order (#11403)`TopicPartition` allows a null `topic` and there are cases where we havea topic id, but no topic name. Even for `TopicIdPartition`, the non nulltopic name check was only enforced in one constructor.Also adjust the constructor order to move the nullable parameter to theend, update tests and javadoc.Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
[hotfix][RAT] Add generated avro java codes to RAT exclusion listThis closes #6256.,1
[FLINK-4000] [RabbitMQ] Style cleanups in MessageAcknowledgingSourceBase,4
[hotfix][docs] Adjust playground docs to Flink 1.11 output,2
[FLINK-6893] [table] Add BIN function to Table API and fix bugs,0
[FLINK-9938][state] Clean up full snapshot from expired state with TTLThis closes #6460.,4
"MINOR: optimize performAssignment to skip unnecessary check (#11218)Found this while reading the code. We did a ""a little heavy"" check each time after performing assignment, which is to compare the ""assigned topics"" set and the ""subscribed topics"" set, to see if there's any topics not existed in another set. Also, the ""assigned topics"" set is created by traversing all the assigned partitions, which will be a little heavy if partition numbers are large.However, as the comments described, it's a safe-guard for user-customized assignor, which might do assignment that we don't expected. In most cases, user will just use the in-product assignor, which guarantee that we only assign the topics from subscribed topics. Therefore, no need this check for in-product assignors.In this PR, I added an ""in-product assignor names"" list, and we'll in consumerCoordinator check if the assignor is one of in-product assignors, to decide if we need to do the additional check. Also add test for it.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
DUBBO-627 fix bug,0
[FLINK-13128][hive] make HiveGenericUDAF expose accumulator type in order to create its corresponding AggregateFunctionDefinition,5
Config api unit test (#1758)* unit test for ApplicationConfig* fix typo* unit test for ArgumentConfig* unit test for ConsumerConfig* unit test for MethodConfig* unit test for ModuleConfig* unit test for MonitorConfig* unit test for ProtocolConfig* unit test for ApplicationConfig* fix typo* unit test for ArgumentConfig* unit test for ConsumerConfig* unit test for MethodConfig* unit test for ModuleConfig* unit test for MonitorConfig* unit test for ProtocolConfig* unit test for ProviderConfig* make test stable,3
"[FLINK-17748][table] Remove registration of TableSource/TableSink in table envThe old TableSource/TableSink interface will be replaced by FLIP-95 in the future, thuswe choose a more lightweight solution to move the registration from TableEnvironementto TableEnvironmentInternal, keep these methods from users but still avaliable to ourcodebase.After FLIP-95 is done, we should continue to improve table factory and related descriptor APIto make it easy and intuitive for users to register user defined table (source & sink).This closes #12076",1
[FLINK-19760] Sink API: Make the `GlobalCommitter` not extend the `Committer`This patch decouples the `GlobalCommitter` from the `Committer`interface in the new Sink API.This closes #13888.,1
[hotfix] Add checkstyle suppressions for StateBackendTestBaseThe commits after this one move consolidated tests to this file whichbreaks the 3000 lines limit.,4
DUBBO-204 注册中心路由功能迁移到客户端git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1344 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-15090][tests] Move streaming env tests to flink-tests+ GetOperatorUniqueIDTest+ RemoteStreamEnvironmentTest+ ReinterpretDataStreamAsKeyedStreamITCase+ LocalStreamEnvironmentITCase,5
[hotfix][core] Added snapshot for TestListCompositeSerializer,3
[FLINK-4258] fix potential NPE in SavepointCoordinator,0
fix CsvOutputFormatTest (and re-introduced a flag for constructor-based instantiation,3
[FLINK-7026] [asm] Introduce flink-shaded-asm-5This closes #4494.,2
[FLINK-11741] [core] Remove TypeSerializerSingleton's ensureCompatibility implementation,4
[FLINK-3216] [FLINK-3217] [cep] Adds CEP operator for pattern recognitionImplements NFA using the SharedBufferImplements NFACompiler to compile a Pattern into a NFAAdd CEP operatorMakes NFA and SharedBuffer serializableAdd serializability support to SharedBuffer and NFAAdd keyed cep pattern operatorAdds CEP documentationAdds online documentation for the CEP libraryCopies sequence events before giving them to the UDFFix correct scala type suffixesThis closes #1557.,0
[FLINK-7683][state backends] Introduce iterator for keys in KeyedStateBackend.This closes #4722.,2
"KAFKA-10667: add timeout for forwarding requests (#9564)add total timeout for forwarding, including the underlying broker-to-controller channel timeout setting.Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-7538: Reduce lock contention for Partition ISR lock (#5866)Check for ISR updates using ISR read lock and acquire ISR write lock only if ISR needs to be updated. This avoids lock contention between request handler threads processing log appends on the leader holding the ISR read lock and request handler threads processing replica fetch requests that check/update ISR.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"KAFKA-2599: Fix Metadata.getClusterForCurrentTopics throws NPE…h null checkingAuthor: Edward Ribeiro <edward.ribeiro@gmail.com>Reviewers: Ismael Juma, Guozhang WangCloses #262 from eribeiro/KAFKA-2599",5
[FLINK-21369][docs] Document Checkpoint StorageThis closes #14932,1
"KAFKA-8391; Temporarily ignore flaky Connect rebalance integration testsI've spent quite a bit of time on trying to discover the root cause, with no luck so far. I have been able to reproduce it locally by running the following 100 times:```./gradlew connect:runtime:clean connect:runtime:test --tests org.apache.kafka.connect.integration.RebalanceSourceConnectorsIntegrationTest```The `testReconfigConnector` test failed 28% of the time and the others failed 0%. This issue and KAFKA-8661 suggest that `testDeleteConnector` and `testStartTwoConnectors` are also flaky, though I've not seen those tests fail locally.Because this flakiness is causing issues for the rest of the project, I'm going to temporarily ignore several of the flaky ITs while I continue to investigate:* `RebalanceSourceConnectorsIntegrationTest.testReconfigConnector`* `RebalanceSourceConnectorsIntegrationTest.testDeleteConnector`* `RebalanceSourceConnectorsIntegrationTest.testStartTwoConnectors`**This should be backported to the `2.3` branch, which is when these integration tests were first added.**Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ismael JumaCloses #7237 from rhauch/kafka-8391-temporary",1
"KAFKA-10559: Not letting TimeoutException shutdown the app during internal topic validation (#9432)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Fixed bug in web-client.,0
[FLINK-13656][table-planner-blink] Update plan change because of collapsed IS NOT DISTINCT FROMThis was introduced by CALCITE-3174.,1
"KAFKA-4829: Improve log4j on Streams thread / task-levelThese are the following improvements I made:1. On stream thread level, INFO will be demonstrating `Completed xx tasks in yy ms` or `Completed rebalance with xx state in yy ms`,2. On Stream thread cache level, INFO on `Flushed xx records`.3. On Stream thread level, DEBUG on internal batched operations like `created xx tasks`, and TRACE on individual operation like `created x task`.4. Also using `isTraceEnabled` on the critical path to reduce overhead of creating `Object[]`.5. Minor cleanups in the code.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Steven Schlansker, Nicolas Fouché, Kamal C, Ismael Juma, Bill Bejeck, Eno Thereska, Matthias J. Sax, Damian GuyCloses #3354 from guozhangwang/K4829-tasks-log4j",2
[FLINK-9588][cep] Reused context with same computation state calculateThis cloes #6168,1
[FLINK-6641] [ha] Don't let the ClusterClient clean up HA services data when being shut downThe ClusterClient should not call HighAvailabilityServices#closeAndCleanupAllData when being shut down.The reason is that this call will delete all HA data needed for a future recovery. Only the JobManagershould be allowed to decide when to discard HA data or not.,5
Add test example for rest,3
Fixed bug that classloading fails in configuration with null class loader.,5
Added unit and integration tests for join,3
"[FLINK-22502][checkpointing] Don't tolerate checkpoint retrieval failures on recoveryIgnoring such failures and running with an incompleteset of checkpoints can lead to consistency violation.Instead, transient failures should be mitigated byautomatic job restart.",0
Improved javadoc and renamed name of test class,3
"[FLINK-23225][doc-zh] Fixed some translation mismatches in the ""flink-architecture"" page (#16363)",2
"Revert ""[FLINK-23427][chinese-translation] Translate the page of ""Blocking Shuffle"" into Chinese""This reverts commit b296cb4849efb05ac94da7b5e95b7e5afa3d8e14.",4
[hotfix][filesystem] Fix the typo in InProgressFileWriterThis closes #18438,2
"MINOR: Replace string literal with constant in RequestChannel (#12134)Replace the ""RequestsPerSec"" literal value with the pre-existing constant `RequestsPerSec`.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix][docs] Fix Scala example for MiniCluster testThis closes #17949,3
"[FLINK-4360] [tm] Implement TM -> JM registration logicUpon requesting a slot for a new job, the TaskManager registers this job at theJobLeaderService. The job leader service is responsible to monitor job leader changesfor all registered jobs. In case of a new job leader, the service will try to establisha connection to the new job leader. Upon establishing the connection the task manageris informed about it. The task manager will then offer all allocated but not yet activeslots to the new job leader.Implement JobLeaderServiceThe JobLeaderService is responsible for establishing a connection to the JM leader of a givenjob.Disable TaskExecutorTest#testRejectAllocationRequestsForOutOfSyncSlotsAdd simple task submission testAdd job leader detection test caseAdd task slot acceptance testFix RpcCompletenessTestAdd commentsThis closes #2640.",3
[hotfix][testutil] Return Optional in MetricListener getters,1
[FLINK-8265] Missing jackson dependency for flink-mesos,2
Add service level `serialization` config,5
MINOR: Traverse plugin path recursively in Connect (KIP-146)Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3173 from kkonstantine/MINOR-Traverse-plugin-path-recursively-in-Connect,5
"[FLINK-1954] [FLINK-1636] [runtime] Improve partition not found error handlingProblem: cancelling of tasks sometimes leads to misleading error messages about""not found partitions"". This is an artifact of task cancelling. If a task(consumer) consumes data from another remote task (producer), its sends apartition request over the network. If the producer fails concurrently with thisrequest, the request returns with a PartitioNotFoundException to the consumer.If this error message is received *before* the consumer is cancelled (as aresult of the failing producer), you see the misleading error being attributedto the consumer. This makes it hard to trace the root cause of the problem (thefailing producer).Solution: when a consumer receives a remote PartitionNotFoundException, it asksthe central job manager whether the producer is still running or has failed.If the producer is still running, the partition request is send again (using anexponential back off). If the following requests fail again, the consumer failswith a PartitionNotFoundException.If the producer has failed, the consumer is cancelled.If the producer is not running and has not failed, there is a bug either in theconsumer task setup (e.g. requesting a non-existing result) or in the networkstack (e.g. unsafe publication of produced results), in which case the error isattributed to the consumer.---The new Akka messages introduced with this change are only exchanged in errorcases and don't affect normal operation.Normal operation (not affected by this change):- TM1=>TM2: request result- TM2=>TM1: resultError case:- TM1=>TM2: request result- TM2=>TM1: PartitionNotFoundException- TM1=>JM: check partition state- JM=>TM1: retrigger request -OR- cancel consumerThis closes #705.",0
[hotfix][tests] Rename ContainsCauseMatcher,1
Improved robustness of task manager profiling,1
"Merge pull request #1040, refactor: replace some deprecated methods related with jedis.",4
remove discoveryManager,4
[FLINK-1671] [jobmanager] Rename JobManager's ExecutionMode to JobManagerModeThis is done to avoid name conflicts with the overloaded type name ExecutionMode.,5
"[FLINK-4150] [runtime] Don't clean up BlobStore on BlobServer shut downThe `BlobServer` acts as a local cache for uploaded BLOBs. The life-cycle ofeach BLOB is bound to the life-cycle of the `BlobServer`. If the BlobServershuts down (on JobManager shut down), all local files will be removed.With HA, BLOBs are persisted to another file system (e.g. HDFS) via the`BlobStore` in order to have BLOBs available after a JobManager failure (orshut down). These BLOBs are only allowed to be removed when the job thatrequires them enters a globally terminal state (`FINISHED`, `CANCELLED`,`FAILED`).This commit removes the `BlobStore` clean up call from the `BlobServer`shutdown. The `BlobStore` files will only be cleaned up via the`BlobLibraryCacheManager`'s' clean up task (periodically or onBlobLibraryCacheManager shutdown). This means that there is a chance thatBLOBs will linger around after the job has terminated, if the job managerfails before the clean up.This closes #2256.",4
[FLINK-1201] [gelly] changed ConstantFields to ForwardedFieldsThis closes #335,4
"Merge pull request #348, AtomicPositiveInteger less memory used & provides better perf.",1
"KAFKA-10390; Remove ignore case option when grep process info to be more specificRemove ignore case option when grep process info to be more specific since our entry point is definitely `kafka.Kafka`.Author: Luke Chen <showuon@gmail.com>Reviewers: Gwen Shapira, Lucas BradstreetCloses #9179 from showuon/KAFKA-10390",5
[FLINK-11677] Remove ResourceManagerRunnerThis closes #7699.,1
[FLINK-4940] Add broadcast state to the OperatorStateBackend.,1
"[hotfix][build] Remove shade-plugin configuration from flink-yarn-testsThe relocations are a no-op since no dependencies are bundled, nor are any classes that are relocated referenced in this module.The dependency-reduced-pom.xml is not used by anyone, since we neither deploy or nor any other module depends on it.As such the shade-plugin configuration is not necessary here.",5
[Refactor] Dubbo Spring based on Alibaba spring-context-support (#5324)* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5309 : [ISSURE] The beans of Dubbo's Config can't be found on the ReferenceBean's initialization* Polish apache/dubbo#5312 : Resolve the demos' issues of zookeeper and nacos* Polish apache/dubbo#5313 : [Migration] migrate the code in common module from cloud-native branch to master* Polish apache/dubbo#5316 : [Refactor] Replace @EnableDubboConfigBinding Using spring-context-support* Polish apache/dubbo#5317 : [Refactor] Refactor ReferenceAnnotationBeanPostProcessor using Alibaba spring-context-suuport API* Polish apache/dubbo#5321 : Remove BeanFactoryUtils* Polish apache/dubbo#5321 : Remove AnnotatedBeanDefinitionRegistryUtils* Polish apache/dubbo#5321 : Remove AnnotationUtils* Polish apache/dubbo#5321 : Remove ClassUtils* Polish apache/dubbo#5321 : Remove BeanRegistrar* Polish apache/dubbo#5321 : Remove ObjectUtils* Polish apache/dubbo#5321 : Remove PropertySourcesUtils,5
[FLINK-16676][python][test] Fix ValidationPipelineTest.test_pipeline_from_invalid_json failure in Azure,0
[FLINK-3355] [rocksdb backend] Allow passing options to the RocksDB backend.This also cleans up the generics in the RocksDB state classes.This closes #1608,5
[FLINK-26281][connectors/elasticsearch] Remove unused 'connection.max-retry-timeout' optionThis closes #19202.,1
[FLINK-16222][metrics][prometheus] Add plugin e2e test,3
[hotfix] [misc] Fix some typosThis closes #5204,2
Support for ibm J9  (#10033)* support for ibm J9* format code,1
"[FLINK-25744] Support native savepointsWe introduce a savepoint type flag both to the CLI and REST API thatcontrols the binary format of the savepoint to take. Native savepointsare taken in the state backend specific binary format. They can befaster to take and restore from, but they do not support e.g. changingthe state backend.This commit does not support RocksDB incremental savepoints yet. Whenincremental savepoints are configured, native savepoints will fail.",0
[FLINK-6084][Cassandra] Promote transitive dependenciesThis closes #3556,2
[FLINK-19324][yarn] Match requested and allocated containers with priority rather than resources.This closes #13592.,2
[FLINK-20379][connector/common] Add a method of getUserCodeClassLoader() method to the SourceReaderContext.,1
[FLINK-4556] [distributed runtime] Make Queryable State Key-Group AwareThis closes #2523,1
[FLINK-11757][tests] Add 1.8 to MigrationVersion,1
kafka-1414; Speedup broker startup after hard reset; patched by Anton Karamanov; reviewed by Jay Kreps and Jun Rao,1
"[FLINK-8162] [kinesis] Move shard metric gauges registration to KinesisDataFetcherThis commit refactors the registration of shard metric gauges to theKinesisDataFetcher, instead of being handled by the ShardConsumer.Overall, this achieves better separation of concerns.This commit also consolidates all metrics related constant strings to aseparate KinesisConsumerMetricConstants class, with comments that themetric names should not be touched to maintain backwards compatibilityfor the consumer's shipped metrics.",5
"KAFKA-7180; Fixing the flaky test testHWCheckpointWithFailuresSingleLogSegmentBy waiting until server1 has joined the ISR before shutting down server2Rerun the test method many times after the code change, and there is no flakiness any more.Author: Lucas Wang <luwang@linkedin.com>Reviewers: Mayuresh Gharat <gharatmayuresh15@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5387 from gitlw/fixing_flacky_logrecevorytest",3
[FLINK-25194] Implement an API for duplicating artefacts,2
Added missing methods to DelegatingConfig.,5
[ISSUES #10249]Fix the problem of repeatedly creating registry in AbstractRegistryFactory#getRegistry #10249 (#10252)Co-authored-by: xuhao <hao2.xu@ly.com>,1
"KAFKA-9634: Add note about thread safety in the ConfigProvider interface (#8205)In Kafka Connect, a ConfigProvider instance can be used concurrently (e.g. via a PUT request to the `/connector-plugins/{connectorType}/config/validate` REST endpoint), but there is no mention of concurrent usage in the Javadocs of the ConfigProvider interface. It's worth calling out that implementations need to be thread safe.Reviewers: Konstantine Karantasis <konstantine@confluent.io>",5
"[hotfix] Remove explicit YarnClusterDescriptor.zookeeperNamespaceThe YarnClusterDescriptor.zookeeperNamespace has been replaced by the configuration whichis deployed together with the Yarn cluster. Hence, it is no longer needed.",1
[hotfix] [runtime] Minor code cleanup in SlotPool,4
KAFKA-10572 mirror-maker config changes for KIP-629 (#9429)Author: Xavier Léauté <xavier@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
[FLINK-15782][connectors/jdbc] refactor JDBC sink testsChanges:1. extract DbMetadata to allow to use different databases2. extract test fixture from the base class3. use inheritance only for @Before/@After behaviour,1
remote dubbo-all javadoc plugin (#2307)* remote dubbo-all javadoc plugin* add license to test source* disable checkstyle and rat plugin,3
[FLINK-7675] [metrics] LatestCompletedCheckpointExternalPathGauge should check if external path is existThis closes #4709.,3
[hotfix] Extend MockEnvironment to provide better testing tools,3
[FLINK-23839][kafka] Improve warnings on InvalidTxnState-/ProducerFencedException,2
[scala] Self-contained build for scala examplesThis closes #199.,5
"[FLINK-2555] Properly pass security credentials in the Hadoop Input/Output format wrappersThis is needed because the Hadoop IF/OF's are using Hadoop's FileSystem stack, which is usingthe security credentials passed in the JobConf / Job class in the getSplits() method.Note that access to secured Hadoop 1.x using Hadoop IF/OF's is not possible with this change.This limitation is due to missing methods in the old APIs.- Add some comments & change dependency scope to test",3
KAFKA-7972: Use automatic RPC generation in SaslHandshakeAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #6301 from mimaison/sasl-handshake,1
[FLINK-12763][runtime] Yarn/MesosResourceManager set SlotManager to fail unfulfillable requests on started.,0
[hofix] Improve failure message of shuffle memory sanity check,0
kafka-server-stop.sh doesn't stop broker; reviewed by Neha Narkhede,5
"KAFKA-9294: Add tests for Named parameter (#7874)Part 1 -- tests for stateless KStream operators onlyReviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-17385][jdbc][postgres] Handled problem of numeric with 0 precisioncloses #11914,0
MINOR: Clarify impact of num.replica.fetchers (#12153)The documentation for `num.replica.fetchers` should emphasize the fact that the count applies to each source broker individually. Also mention the tradeoff.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-6145: Set HighAvailabilityTaskAssignor as default in streams_upgrade_test.py (#8613)Generalize the verification in the upgrade test so that itdoes not rely on the task assignor's behavior.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
[FLINK-24781][table-planner] Added CastRule#canFail and make sure ScalarOperatorGens wraps the cast invocation in a try-catchSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
KAFKA-642 Fixes to protocol. Patch reviewed by Neha and Joel.git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1417734 13f79535-47bb-0310-9956-ffa450edef68,0
[FLINK-16075][docs-zh] modification based on klion26's review,2
"[FLINK-29047][k8s] Shade fabric8 kubernetes dependency with org.apache.flink.shaded prefix in flink-kubernetesFor supporting stepDecorators SPI(pluginable decorators), we propose to package the implementation class and associated dependencies into a plugin jar.So we need to load the said dependencies from parent class loader, as the most part / all of plugin decorators depend on the fabric8 kubernetes dependency,such as replies on the kubernetes models/client from fabric8.So we need to shade all the said classes in flink-kubernetes and flink-dist.",2
KAFKA-7561: Increase stop_timeout_sec to make ConsoleConsumerTest pass (#5853)Looks like the increased delay happens when connecting to the docker container.Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"KAFKA-7072: clean up segments only after they expire (#5253)Significant refactor of Segments to use stream-time as the basis of segment expiration.Previously Segments assumed that the current record time was representative of stream time.In the event of a ""future"" event (one whose record time is greater than the stream time), thiswould inappropriately drop live segments. Now, Segments will provision the new segmentto house the future event and drop old segments only after they expire.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[hotfix][table-planner] Propagate AssertionError in BuiltInFunctionTestBase,5
MINOR: log connect reconfiguration error only if there was an errorAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #871 from gwenshap/fix-cc-log,2
[FLINK-15558][Connector] Bump Elasticsearch version from 7.3.2 to 7.5.1 for es7 connector,2
Adapted Hash Function Test and included HashJoin probing for spilled partitions.,3
[hotfix][runtime] Adding back the missing blacklisting information when refining SotProfile in allocateCoLocatedMultiTaskSlot,2
[FLINK-4380] Remove KeyGroupAssigner in favor of static method/Have default max. parallelism at 128,4
[FLINK-18117][e2e] Dynamically allocate port causing test instabilities (#13894),3
[FLINK-11719] Make SchedulerNG in JobMaster finalSince the JobMaster is now a PermanentlyFencedRpcEndpoint we no longerneed to make the scheduler resettable.,1
Delete UT in dubbo-test module,3
"MINOR: Rename remaining `zkVersion` to `partitionEpoch` in `PartitionTest` (#12147)Reviewers:  Kvicii <42023367+Kvicii@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-6761: Reduce streams footprint part IV add optimization (#5451)This PR adds the optimization of eliminating multiple repartition topics when the KStream resulting from a key-changing operation executes other methods using the new key and reduces the repartition topics to one.Note that this PR leaves in place the optimization for re-using a source topic as a changelog topic for source KTable instances. I'll have another follow-up PR to move the source topic optimization to a method within InternalStreamsBuilder so it can be performed in the same area of the code.Additionally, the current value of StreamsConfig.OPTIMIZE is all and we'll need to have another KIP to change the value to 2.1.An integration test RepartitionOptimizingIntegrationTest which asserts the same results for an optimized topology with one repartition topic as the un-optimized version with four repartition topics.Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-12717][python] Remove script pyflink-gateway-server.sh which has been replaced with pyflink_gateway_server.pyThis closes #12125.,2
[hotfix] [runtime] Remove obsolete Exception from JobLeaderIdService signature,4
Merge pull request #62 from rmetzger/gith_input_format_bugMinor bugfix for TextInputFormat + Testcase,3
Merge branch 'sewen'Conflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/plan/PactConnection.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/MatchTask.java,5
[FLINK-26480][python] Support window_all in Python DataStream APIThis closes #19758.,5
"[FLINK-14704] Remove unused SynchronousSavepointLatchAfter FLINK-12482, SynchronousSavepointLatch has been useless and should be removed.This closes #10154 .",4
[hotfix][table-common] Improve terminology for data types in formats,5
[hotfix] Split the final checkpoint related tests to a separate test class.This is necessary since the StreamTaskTest is too big and has exceed thelimitation of file size configured in checkstyle plugin.,5
[FLINK-3272] [Gelly] Generic value in Connected Components* Updated scather-gather and GSA implementation * tests* updated documentationThis closes #1785,2
Update version to 1.13-SNAPSHOT,5
"[FLINK-19392] Detect runtime execution mode based on boundedness of sourcesThis option, when exposed to the user, it will allow to specifythe mode in which the pipeline is going to be executed, asdescribed in FLIP-134.This closes #13502.",1
[FLINK-12891][hive] remove hadoop/hive writable from boundaries of Hive functions and FlinkThis PR removes hadoop/hive writable from boundaries of Hive functions and Flink because Flink only deals with java objects rather than hadoop/hive writables. Data is passed from Flink to Hive functions and from Hive functions back to Flink will always be simple java objects.This closes #8813.,2
"[FLINK-5608] [webfrontend] Cancel button stays visible in narrow windows- Most importantly, the Cancel and Stop buttons have been changed tofloat right, and will only wrap downward if pushed out by the job name- Also combined the job name and job id into a single horizontalelement, reducing the overall horizontal space taken by the mainnavbar components in the job view, making the main navbar componentsless likely to wrap downward and be overlapped by the secondary navbar.- Moved global job status counts to be right-most so it wraps beforethe job-specific information, and it's now hidden on medium width(992px - 1900px) to save horizontal space- Compiled code has been rebuilt",5
MINOR: fix number of nodes used in test_compatible_brokers_eos_v2_enabled (#12211)Reviewers: David Jacot <djacot@confluent.io>,5
"MINOR: Avoiding attempt to connect to Zookeeper on closing consumer for deleting random group.id with the new oneWith the new consumer the ""/consumers"" path on Zookeeper isn't filled by consumer info. On closing the new consumer, there is some code that is useless to execute for trying to connect to Zookeeper (but the URL is null).Author: ppatierno <ppatierno@live.com>Author: Paolo Patierno <ppatierno@live.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3301 from ppatierno/old-consumer-delete-groupid",4
[3.0] Fix dubbo-bom (#7914)* [3.0] Fix dubbo-bom (#7913)* Fix (#7913),0
[FLINK-15758][MemManager] Remove KeyedBudgetManager and use AtomicLong,1
adjust dubbo protobuf stub generator,5
[FLINK-21401] Make DispatcherTest.testNonBlockingJobSubmission independent of underlying schedulerMake DispatcherTest.testNonBlockingJobSubmission independent of underlying scheduler by using theBlockingJobManagerRunnerFactory and blocking the creation of the JobManagerRunner.,1
[FLINK-14735][scheduler] Improve scheduling of all-to-all partitions with ALL input constraint for legacy schedulerThis closes #10278,1
"KAFKA-10436: Implement KIP-478 Topology changes (#9221)Convert Topology#addProcessor and #addGlobalStoreAlso, convert some of the internals in support of addProcessorReviewers: Bill Bejeck <bbejeck@apache.org>",1
MINOR: Bump Kafka version to 0.11.1.0-SNAPSHOTAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3095 from ijuma/bump-kafka-version,5
"[FLINK-5999] [resMgnr] Move JobLeaderIdService shut down into ResourceManagerRunnerThe JobLeaderIdService is being created by the ResourceManagerRunner and then given to aResourceManager. Before the ResourceManager stopped the service before being stoppeditself. This could lead to a concurrent modification exception by a state changing actionexecuted by the actor thread. In order to avoid this concurrent modification, the service'sshut down is now being executed after the ResourceManager has been shut down.This closes #3526.",4
[hotfix] Factor ExecutionGraph creation out into ExecutionGraphFactoryUsing the ExecutionGraphFactory for creating and restoring an ExecutionGraph allowsto share the functionality between the DefaultScheduler and the AdaptiveScheduler.,1
KAFKA-1883 Fix NullPointerException in RequestSendThread; reviewed by Neha Narkhede,0
[FLINK-1324] [runtime] Trailing data is cached before the local input strategies are closed.,5
[FLINK-1969] [runtime] Remove deprecated profiler code,2
Reduce minimum memory threshold for sorter,5
Added Method STubs to PactRecord,1
"KAFKA-9016; Warn when log dir stopped serving replicasAuthor: uttpal <kumar.uttpal@oyorooms.com>Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #7563 from uttpal/KAFKA-9016",2
[FLINK-4322] [checkpointing] Add and fix tests for unified Checkpoint/Savepoint CoordinatorThis closes #2366,3
"KAFKA-6854; Handle batches deleted during log cleaning of logs with txns (#4962)Log cleaner grows buffers when result.messagesRead is zero. This contains the number of filtered messages read from source which can be zero when transactions are used because batches may be discarded. Log cleaner incorrectly assumes that messages were not read because the buffer was too small and attempts to double the buffer size unnecessarily, failing with an exception if the buffer is already max.message.bytes. Additional check for discarded batches has been added to avoid growing buffers when batches are discarded.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
Disable tests because operators are not implemented yet,1
[FLINK-2974] Add periodic offset committer for Kafka when checkpointing is disabledThis closes #1341,1
[hotfix] Remove unused static methods from LocalExecutor,1
[FLINK-16019][runtime] fix ContinuousFileReaderOperator error handling,0
[FLINK-14130][client] Shift down Logger from ClusterClient to RestClusterClient,2
[FLINK-29017][docs] Replace all links to github master with shortcode,2
Minor: Missing LicenseAuthor: Sriharsha Chintalapani <harsha@hortonworks.com>Reviewers: Gwen ShapiraCloses #524 from harshach/missing-license,1
"Revert ""[FLINK-10911][scala-shell] Enable flink-scala-shell with Scala 2.12""This reverts commit b7ce6119158346504e0ddd8d0f110859304eacbd.Our per-push CI does not cover Scala 2.12 so we didn't notice thatScalaShellITCase does not actually pass.",4
"KAFKA-4331: Kafka Streams resetter is slow because it joins the same group for each topic  - bug-fix follow up  - Resetter fails if no intermediate topic is used because seekToEnd() commit ALL partitions to EOLAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Roger Hoover, Guozhang WangCloses #2138 from mjsax/kafka-4331-streams-resetter-bugfix",0
[FLINK-1201] [gelly] added description in GraphMetrics example,1
"KAFKA-5350: Modify unstable annotations in Streams APIAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3172 from guozhangwang/K5350-compatibility-annotations",5
"[FLINK-3088] [serialization] Fix copy method of TypeSerializer which use KryoSome TypeSerializer, WritableSerializer, ValueSerializer, and AvroSerializer, andcomparators, WritableComparator and ValueComparator, use Kryo to copy records.In case where the Kryo serializer cannot copy the record, the copy method fails.This is however not necessary, because one can copy the element by serializingthe record to a byte array and deserializing it from this array. This PR addsthis behaviour to the respective classes.Adds KryoUtils tool with copy method to avoid code duplicationThis closes #1415.Adds comments to KryoUtils functions",1
KAFKA-6185; Remove channels from explictlyMutedChannels set when closedThis memory leak could eventually lead to an OutOfMemoryError. Thiswas particularly likely in case of down conversions as the leakedchannels would hold on to the record batch (which is only loadedinto the heap in case of down conversions).Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4193 from rajinisivaram/KAFKA-6185-oom,5
"KAFKA-9716; Clarify meaning of compression rate metrics (#8664)There is some confusion over the compression rate metrics, as the meaning of the value isn't clearly stated in the metric description. In this case, it was assumed that a higher compression rate value meant better compression. This PR clarifies the meaning of the value, to prevent misunderstandings.Reviewers: Jason Gustafson <jason@confluent.io>",5
[streaming] Add a clean in WindowedDataStream,5
"KAFKA-5702; extract refactor StreamThreadExtracted `TaskManager` to handle all task related activities.Make `StandbyTaskCreator`, `TaskCreator`, and `RebalanceListener` static classes so they must define their dependencies and can be testing independently of `StreamThread`Added interfaces between `StreamPartitionAssignor` & `StreamThread` to reduce coupling.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Eno Thereska <eno.thereska@gmail.com>Closes #3624 from dguy/stream-thread-refactor",4
"- added local strategies for self match: SORT_SELF_NESTEDLOOPS, SELF_NESTEDLOOPS- extended JSONGenerator to handle new local strategies- extended JobGraphGenerator to handle new local strategies",1
Fixes problem with ambiguity of Hadoop hostnames,0
[FLINK-8011][dist] Set flink-python to providedThis closes #4973.,1
[FLINK-15072][client] Move printing stringified JobExecutionResult to ContextEnv,4
[FLINK-25817] Unify logic between TaskExecutor.requestSlot and TaskExecutor.tryLoadLocalAllocationSnapshotsThis commit unifies the logic between TaskExecutor.requestSlot and TaskExecutor.tryLoadLocalAllocationSnapshots.This helps to reduce maintaince costs since both method use the same logic.This closes #18237.,2
commit the remaining changes,4
[FLINK-2976] [runtime] Add StateStore<T>,3
"KAFKA-5236; Increase the block/buffer size when compressing with Snappy or GzipWe had originally increased Snappy’s block size as part of KAFKA-3704. However,we had some issues with excessive memory usage in the producer and we revertedit in 7c6ee8d5e.After more investigation, we fixed the underlying reason why memory usage seemedto grow much more than expected via KAFKA-3747 (included in 0.10.0.1).In 0.10.2, we changed the broker to use the same classes as the producer and thebroker’s block size for Snappy was changed from 32 KB to 1KB. As reported inKAFKA-5236, the on disk size is, in some cases, 50% larger when the data is compressedwith 1 KB instead of 32 KB as the block size.As discussed in KAFKA-3704, it may be worth making this configurable and/or allocatethe compression buffers from the producer pool. However, for 0.11.0.0, I think thesimplest thing to do is to default to 32 KB for Snappy (the default if no block sizeis provided).I also increased the Gzip buffer size. 1 KB is too small and the default is smallerstill (512 bytes). 8 KB (which is the default buffer size for BufferedOutputStream)seemed like a reasonable default.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3205 from ijuma/kafka-5236-snappy-block-size",5
[FLINK-10964][sql-client] SQL Client throws exception when paging through finished batch queryThis closes #7265.,5
"[FLINK-2936] Fix ClassCastException for Event-Time sourceBefore, would throw a ClassCastException when emitting watermarks withtimestamp/watermark multiplexing disabled.",0
[FLINK-20835][coordination] Introduce TaskManagerTracker to track TaskManager's resource and slot status,2
[FLINK-6711] Activate strict checkstyle for flink-connector-twitter,2
KAFKA-6145: KIP-441: avoid unnecessary movement of standbys (#8436)Reviewers: John Roesler <vvcephei@apache.org>,5
[FLINK-9839][tests] Add support for SSL to e2e-testsThis closes #6327.,3
"KAFKA-6126: Remove unnecessary topics created checkAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4322 from mjsax/kafka-6126-remove-topic-check-on-rebalance-2",4
Igonre .patch file.,2
[FLINK-2388] forward message to archivist in case accumulators can't be found- return AccumulatorsNotFound in case the archive cannot find them eitherThis closes #930.,2
"KAFKA-9971: Error Reporting in Sink Connectors (KIP-610) (#8720)Implementation for KIP-610: https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors based on which sink connectors can now report errors at the final stages of the stream that exports records to the sink system. This PR adds the `ErrantRecordReporter` interface as well as its implementation - `WorkerErrantRecordReporter`. The `WorkerErrantRecordReporter` is created in `Worker` and brought up through `WorkerSinkTask` to `WorkerSinkTaskContext`. An integration test and unit tests have been added.Reviewers: Lev Zemlyanov <lev@confluent.io>, Greg Harris <gregh@confluent.io>, Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",5
[hotfix][table-common] Relax literal casting check in AdaptedCallContext,0
unit test for etcd serviceDiscovery,3
"MINOR: Double quote `CLASSPATH` to prevent shell glob expansion. (#8191)In the event that `CLASSPATH` does not have an ending "":"", the shellcan expand the CLASSPATH globs to be space-separated list of paths/jars,which is not how the JVM CLI accepts arguments to -cp switch. Sodouble quote the variable to prevent pattern expansion, and pass theglob pattern directly to the JVM.Reviewers: Ismael Juma <ismael@juma.me.uk>",4
"[FLINK-4296] Fixes failure reporting of consumer task scheduling when producer has already finishedThis PR changes the failure behaviour such that the consumer task is failed instead of theproducer task. The latter is problematic, since a finsihed producer task will simply swallowscheduling exception originating from scheduling the consumer task.This closes #2321.",1
"[FLINK-9712][docs,table] Document processing time Temporal Table Joins",2
[hotfix][task] Add task name to BufferDebloater logging,2
Fixed file output configuration and logging for various test cases.,3
[FLINK-1943] [gelly] Added GSA compiler and translation testsThis closes #916,3
Implemented listener mechanism for checkpoint state changes,4
"MINOR: Clean up partition assignment logic (#7249)These are just some ""tidying up"" changes I made when I was preparing to start working on KIP-441.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
Fix typo (#3839),2
[streaming] cellinfo and wordcount update for cluster testing,3
buildCuratorFramework method add zk digest acl support when use zk instance discovery (#10247),1
[FLINK-1793] [streaming] Fix file source isRunning check for proper cancelling,1
[3.0] Add Router Snapshot Print Support (#9517)* [3.0] Add Router Snapshot* [3.0] Add ut* [3.0] Add RouterSnapshotFilter* [3.0] Add recent log* opt,2
Fixed #222 error with running indices,1
[hotfix] Add missing import AkkaOptions to MiniClusterConfiguration,5
"KAFKA-14201; Consumer should not send group instance ID if committing with empty member ID (#12599)The consumer group instance ID is used to support a notion of ""static"" consumer groups. The idea is to be able to identify the same group instance across restarts so that a rebalance is not needed. However, if the user sets `group.instance.id` in the consumer configuration, but uses ""simple"" assignment with `assign()`, then the instance ID nevertheless is sent in the OffsetCommit request to the coordinator. This may result in a surprising UNKNOWN_MEMBER_ID error.This PR fixes the issue on the client side by not setting the group instance id if the member id is empty (no generation).Reviewers: Jason Gustafson <jason@confluent.io>",5
[FLINK-6660] [docs] Expand the connectors overview pageThis closes #3964.,1
[FLINK-23513][docs] Fix docs due to new CSV connector,1
[FLINK-1823] Remove linq from Table API documentation,2
KAFKA-10306: GlobalThread should fail on InvalidOffsetException (#9075)* KAFKA-10306: GlobalThread should fail on InvalidOffsetException* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.javaCo-authored-by: John Roesler <vvcephei@users.noreply.github.com>,1
[core] move AbstractID from runtime to core,1
[hotfix][docs] Fix some ScalaDocs in ExecutionEnvironment.scalaThis closes #12064,2
[FLINK-10069] [docs] Update SSL docs to reflect internal vs. external communicationThis closes #6507.,2
[FLINK-3165] [py] Windows OS supportThis closes #1454,1
[FLINK-14692][table] Support rename/alter table in TableEnvironment for both flink/blink plannerThis closes #10410,2
[FLINK-22052][python] Add set_default_savepoint_directory to PyFlinkThis closes #15441,2
[hotfix] Extract utils of CheckpointCoordinatorTest into a separate utils class and correct codestyle,3
[FLINK-1670] [streaming] Cleanup for DataStream collectMoved corresponding test to flink-contribRemoved unnecessary printCloses #581,4
[hotfix][tests] Close Kafka AdminClients to prevent resource leaks,3
Add unit test for MetadataReportInstance and AbstractServiceNameMapping (#8846),5
"【Unit Test】FailbackRegistry Test: recover method (#2591)* FailbackRegistry Test: recover method* fix the type error, and use CountDownLatch await method to fix the unstable problom* trigger the travis ci test retry* trigger the code static check again",1
[refactor][tests] Remove unnecessary wrapping with ConsumableNotifyingResultPartitionWriterDecorator,4
"KAFKA-6622; Fix performance issue loading consumer offsets (#4661)`batch.baseOffset` is an expensive operation (even says so in its javadoc), and yet was called for every single record in a batch when loading offsets. This means that for N records in a gzipped batch, the entire batch will be unzipped N times. The fix is to compute and cache the base offset once as we decompress and process the batch.Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
KAFKA 244 Improve log4j appender to use kafka.producer.Producer; patched by vtkstef; reviewed by nehanarkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1231276 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix][git] Add 'flink-python/.idea/' to .gitignore file,2
[FLINK-23722][fs] Downgrade shaded hadoop to 3.2.2 to avoid HADOOP-17771.,2
"Revert ""[FLINK-6122] Add Travis build status to README""This reverts commit 486f7249cb36a34af928c771b5d59052ebed9154.Removed after the ""[DISCUSS] TravisCI status on GitHub Page"" discussion onthe mailing list.This closes #3577.",4
[hotfix][metrics] Rename constant IS_BACKPRESSURE to IS_BACK_PRESSURE,0
FIxed bug in default deserializer.,0
[streaming] WordCount Refactor,4
"MINOR: Doc changes for KIP-312 (#5789)Documentation changes for adding overloaded StreamsBuilder(java.util.Properties props) method in KIP-312Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Use uniform convention for naming properties keys; kafka-648; patched by Sriram Subramanian; reviewed by Jun Rao,1
HOTFIX: add missing upgrade docs,2
[FLINK-8399] [runtime] use independent configurations for the different timeouts in slot managerThis closes #5271.,5
"[FLINK-7499][io] also let AsynchronousBufferFileWriter#writeBlock() recycle the buffer in case of failuresThis fixes a double-recycle in SpillableSubpartitionView and also makes surethat even if adding the (asynchronous) write operation fails, the buffer isproperly freed in code that did not perform this cleanup. It avoids codeduplication of this cleanup and it is also more consistent to take overresponsibility of the given buffer even if an exception is thrown.[FLINK-7499][io] complete the idiom of ResultSubpartition#add() taking over ownership of the bufferThe buffer will now always be released once and at the right time and the callermust not worry about the buffer release if a called function threw an exception.This closes #4581.",1
[FLINK-23556][tests] Make SQLClientSchemaRegistryITCase more stable (#16952),1
修复创建AdaptiveExtensionClass时方法异常签名问题,1
"[FLINK-15794][Kubernetes] Generate the Kubernetes default image versionThe default image used by Kubernetes is 'flink:latest' which causes version compatibility problemsif the latest it not exactly the same as what you are using.The commit derives the default value from the actual Flink and Scala version,which the running Flink was built with (i.e. no longer latest).The latest tag is used only for snapshot versions until we have snapshot builds for docker images.This closes #11245.",2
[FLINK-18697][table-api] Add the missing test scope to the flink-streaming-java_2.11:test-jar dependencyThis closes #12977,3
[FLINK-16480][AZP] fix log upload condition,2
[FLINK-11073] [core] Replace EitherSerializerSnapshot with new JavaEitherSerializerSnapshot,1
[FLINK-28212][hive-dialect] Fix IndexOutOfBoundsException when over window SELECT doesn't contain all fields of inputThis closes #20060,0
"KAFKA-2411; remove usage of blocking channelAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Gwen Shapira <cshapi@gmail.com>Closes #151 from ijuma/kafka-2411-remove-usage-of-blocking-channel",4
[FLINK-3580] [table] Add current time point functionsThis closes #2441.,1
[hotfix] Add countWindow and countWindowAll shortcut,1
[hotfix][examples-table] Update registerDataSet to createTemporaryView,1
first compensations possible,5
"[FLINK-4202] Add restarting time JM metricThis PR adds a JM metric which shows the time it took to restart a job. The time ismeasured between entering the JobStatus.RESTARTING and reaching the JobStatus.RUNNINGstate. During this time, the restarting time is continuously updated. The metric onlyshows the time for the last restart attempt. The metric is published in the job metricgroup under the name of ""restartingTime"".This closes #2271.",5
prevent chained tasks in the iteration tail for now.,5
[FLINK-1170] address pull request review commentsThis closes #158,1
"[FLINK-20458][docs-zh] Translate ""Getting Started"" page of Table SQLThis closes #14437",1
[FLINK-20723][tests] Allow retries to be defined per class,1
MINOR; Remove unused AdminZkClient in MetadataSupport (#11785)Remove unused AdminZkClient in MetadataSupportReviewers: Luke Chen <showuon@gmail.com>,5
[hotfix][table] Replace constructor of expressions with util calls,0
[FLINK-20078][coordination] Factor out an ExecutionGraph factory method for DefaultExecutionTopology,2
[FLINK-16339][metrics][datadog] Log configuration,5
[FLINK-28134][runtime] Rework TaskDeploymentDescriptorFactory to accept an execution to deployThis helps to decouple the task deployment from ExecutionVertex#getCurrentExecutionAttempt().,1
"fix #2533, set timeout to 3000 (#2552)* fix #2533, set timeout to 3000* change timeout",4
[FLINK-28629][sql-gateway][hive] Allow to getCatalogs in the HiveServer2 EndpointThis closes #20334,2
[FLINK-16619][coordination] Log reception of slot reports only once,2
MINOR: Port fix to other StoreQueryIntegrationTests (#11153)Port the fix from #11129 to the other store-query tests.Reviewers: John Roesler <vvcephei@apache.org>,3
[FLINK-4749] [streaming api] Remove redundant processing time timer sets from window operator,1
"KAFKA-13727; Preserve txn markers after partial segment cleaning (#11891)It is possible to clean a segment partially if the offset map is filled before reaching the end of the segment. The highest offset that is reached becomes the new dirty offset after the cleaning completes. The data above this offset is nevertheless copied over to the new partially cleaned segment. Hence we need to ensure that the transaction index reflects aborted transactions from both the cleaned and uncleaned portion of the segment. Prior to this patch, this was not the case. We only collected the aborted transactions from the cleaned portion, which means that the reconstructed index could be incomplete. This can cause the aborted data to become effectively committed. It can also cause the deletion of the abort marker before the corresponding data has been removed (i.e. the aborted transaction becomes hanging).Reviewers: Jun Rao <junrao@gmail.com>",4
[hotfix][connector/kafka] Reduce the offset commit logging verbosity from INFO to DEBUG.,0
"KAFKA-3098: ""partition.assignment.strategy"" appears twice in documentationAuthor: David Jacot <david.jacot@gmail.com>Reviewers: Gwen ShapiraCloses #774 from dajac/KAFKA-3098",2
[FLINK-9513][state] Implement TTL state wrappers factory and serializer for value with TTLThis closes #6196.This closes #5799. (forgotten),2
"[FLINK-13123] [rest] align terminology of ""stop"" endpoint with cli",2
[tests] Fix missing task parallelism in JobManagerITCase bipartite job support test,3
[FLINK-17593] Update BucketStateSerializerTest for v2,3
KAFKA-13689: printing unused and unknown logs separately (#11800)Differentiate between unused and unknown configs during log output.Reviewer: Luke Chen <showuon@gmail.com>,2
MINOR: KAFKA-3176 follow-up to fix minor issuesCo-authored with ijuma.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1536 from vahidhashemian/minor/KAFKA-3176-Followup,0
"KAFKA-2977: Transient Failure in kafka.log.LogCleanerIntegrationTest.cleanerTestMake MinCleanableDirtyRatioProp configurable(default 0.0F)in makeCleaner, thus log cleaning is always undergoing;Also removed minDirtyMessages.Author: jinxing <jinxing@fenbi.com>Author: ZoneMayor <jinxing6042@126.com>Reviewers: Ismael Juma, Guozhang WangCloses #671 from ZoneMayor/trunk-KAFKA-2977",1
KAFKA-3674: Ensure connector target state changes propagated to workerAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1341 from hachikuji/KAFKA-3674,5
"KAFKA-10426: Deadlock in DistributedHerder during session key update. (#9431)DistributedHerder goes to updateConfigsWithIncrementalCooperative() synchronized method and called configBackingStore.snapshot() which take a lock on internal object in KafkaConfigBackingStore class.Meanwhile KafkaConfigBackingStore in ConsumeCallback inside synchronized block on internal object gets SESSION_KEY record and calls updateListener.onSessionKeyUpdate() which take a lock on DistributedHerder.This results to a deadlock.To avoid this, updateListener with new session key should be called outside synchronized block as it's done, for example, for updateListener.onTaskConfigUpdate(updatedTasks).Co-authored-by: Taisiia Goltseva <tado0618@netcracker.com>Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",5
[FLINK-18011] Make WatermarkStrategy/WatermarkStrategies more ergonomicThis removes WatermarkStrategies and instead moves the convenienceentrypoint methods for strategies directly to WatermarmStrategy.WatermarkStrategy is now also itself the builder for more complexstrategies instead of WatermarkStrategies.,1
[hotfix] [core] Add tests for Futures applying multiple functions,1
[FLINK-2716] [gelly] [apis] New checksum method on DataSet and GraphThis closes #1462,5
[hotfix][python] Fix typo in BeamDataStreamPythonFunctionRunnerThis closes #15581.,5
[FLINK-28631][sql-gateway][hive] Support to GetFunctions in the HiveServer2EndpointThis closes #20479,1
"MINOR: Code cleanup in StreamsResetter (#5891)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Remove redundant CRC validation for non-compressed records in older message formatsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2881 from hachikuji/fix-redundant-crc-check,0
修改pom依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@456 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-17357][table-planner-blink] add DROP catalog DDLThis closes #12197,2
设置目录属性 排除不需要提交的文件git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1636 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"Merge with Warneke, excluded IO Manager Perfomance Tests from Integration tests",3
[FLINK-22117] Reduce the logs if not all tasks are RUNNING when checkpointing,1
Fixed WebLogAnalysis example to work with the new datamodel,5
[FLINK-23616][python] Support to chain the Python DataStream operators as much as possibleThis closes #16777.,1
DUBBO-140 修改API的对称性git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@675 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Merge branch 'staging_datamodel' of https://stratosphere.eu/stage1 into new_datamodel,5
"[FLINK-27199][Connector/Pulsar] Pulsar 2.10.0 deprecated the queue length, add new memory-based options.",1
[FLINK-23471][checkpoint] Try best to ensure all operators and state manager handle the checkpoint complete notification,0
KAFKA-921; Expose max lag and min fetch rate mbeans for consumers and replica fetchers; reviewed by Jun Rao.,5
#1067: I18N effort for dubbo code base - dubbo-rpc (part7),5
[hotfix][tests] TestingPhysicalSlot rejects payload if one is already assigned,3
"[FLINK-16000] Move ""Project Build Setup"" to ""Getting Started"" in documentationWe also add redirects.",1
[FLINK-26851][metrics] Migrate reporter options to proper ConfigOptions,5
[FLINK-4230] [DataStreamAPI] PR feedback on Session Windowing ITCase,5
DUBBO-581 codec encode后检查数据是否超过payload的限制,5
[FLINK-24441][source] Block SourceOperator when watermarks are out of alignment,1
[FLINK-1325] [Java API] Minor cleanups on the ClosureCleaner,4
[3.0] Reduce array creation when routing (#9219)* [3.0] Reduce array creation when routing* fix ut* fix ut,0
[FLINK-25329][runtime] Use cache in memory graph store and support memory graph store in session clusterThis closes #18360.,1
set reference bean definition target type (#5710)Co-authored-by: quzijing <quzijing@oppo.com>,1
DUBBO-54 增加一个JVM多个group测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@956 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-9799][state] Generalize and unify state meta infosThis closes #6308.,5
[FLINK-23720][table] Migrate ModuleFactory to the new stack- [table] Migrate HiveModule- [table] Migrate CoreModule- [table] Add a module factory helper- [table] Remove ModuleDescriptor(Validator)- [sql-client] Remove unsued test module- [table] Move deprecated logic into FactoryUtil for easier removal- [table] Make LOAD MODULE summary string more SQL-likeThis closes #16781.,1
[FLINK-27990][table-planner] Parquet format supports reporting statisticsThis closes #20008,1
Bump version to 1.1-SNAPSHOT,5
"[FLINK-9427] Fix registration and request slot race condition in TaskExecutorThis commit fixes a race condition between the TaskExecutor and the ResourceManager. Before,it could happen that the ResourceManager sends requestSlots message before the TaskExecutorregistration was completed. Due to this, the TaskExecutor did not have all information it neededto accept task submissions.The problem was that the TaskExecutor sent the SlotReport at registration time. Due to this, the SlotManager could already assign these slots to pending slot requests. With this commit, theregistration protocol changes such that the TaskExecutor first registers at the ResourceManagerand only after completing this step, it will announce the available slots to the SlotManager.This closes #6067.",4
Merge branch 'webinterface_autoupdate_newrelease-pr' of https://github.com/markus-h/stratosphere into webfix,0
[FLINK-28140][python][docs] Improve the documentation connector pages and metrics pagesThis closes #20385.,2
[FLINK-12115][fs] Add NOTICE file for flink-azure-fs-hadoopThis closes #8537.This closes #8117.,2
"KAFKA-13469: Block for in-flight record delivery before end-of-life source task offset commit (#11524)Although committing source task offsets without blocking on the delivery of all in-flight records is beneficial most of the time, it can lead to duplicate record delivery if there are in-flight records at the time of the task's end-of-life offset commit.A best-effort attempt is made here to wait for any such in-flight records to be delivered before proceeding with the end-of-life offset commit for source tasks. Connect will block for up to offset.flush.timeout.ms milliseconds before calculating the latest committable offsets for the task and flushing those to the persistent offset store.Author: Chris Egerton <chrise@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
[FLINK-14008][release] Generate binary licensing during release,2
[FLINK-10581] Increased the threshold for memory verification in YarnConfigurationITCase.testFlinkContainerMemory,5
[FLINK-11657][hadoop] Remove redundant test path in WordCountMapreduceITCase,3
"[FLINK-21606] Fail TaskExecutor hard if the ResourceManager rejects its registration.The ResourceManager rejects the connection attempt of a TaskExecutor if the TaskExecutor is notknown to the ResourceManager. In this case, we don't wait for the max registration timeout butinstead fail hard and fast.This closes #15105.",0
修改日志输出git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@535 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][yarn] Remove duplicated adding ship files in yarn-tests,3
[hotfix][network] Remove optional class field from LocalBufferPool,4
DUBBO-364 支持provider嵌套service标签git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1648 1a56cb94-b969-4eaa-88fa-be21384802f2,1
update test case already destory: DUBBO-2git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@139 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fixed problem in replay thread,0
[FLINK-2330] [streaming] Make FromElementsFunction checkpointable,1
MINOR: Add log when the consumer does not send an offset commit due to not being part of an active group (#6404)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-1794] [test-utils] Adds test base for scala tests and adapts existing flink-ml tests[FLINK-1794] [test-utils] Adds scala docs to FlinkTestBaseThis closes #540.,3
MINOR: Remove unused local variable in SocketServer (#4669)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"[FLINK-19123] Don't override execute()/executeAsync() in TestStreamEnvironmentInstead, we use a custom PipelineExecutorServiceLoader to inject aMiniClusterExecutor. This requires that we directly use MiniClusterinstead of the JobExecutor interface in the test environments because weneed to use asynchronous job submission. The alternative would be toextend the JobExecutor interface to allow async job submission.We have to fix OrcFileSystemITCase to actually wait for the job thatfills the test table to finish because now the async execution methodreturns too fast.",1
"MINOR: Remove unused GroupState.state fieldThis field doesn't seem to be used and the value for`AwaitingSync` seems to be wrong (it seems like itshould have been `2` instead of `5`).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3572 from ijuma/remove-unused-group-state-field",4
[FLINK-23460] Use a global feature flag in the CheckpointCoordinator,1
[FLINK-11776][coordination] Refactor to simplify the process of scheduleOrUpdateConsumersThis closes #7856.,5
[FLINK-3593][tableAPI] Fix failing DistinctITCase,0
[FLINK-18992][table-api-java] Fix Table API renameColumns JavaDocsThis closes #13257.,2
Fixed bug in equals method of SingleInstanceProfilingEvent,0
DUBBO-54 重构，添加单元测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1174 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-20102][docs][hbase] Update connectors index for HBase connectorThis closes #14059,5
[FLINK-23434][table-planner] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg functionThis closes #16539,1
DUBBO-222 从Dubbo1.0的代码中迁移带权重轮循逻辑到2.0git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1204 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-19385] Request partitions for each inputGate independently,2
"[FLINK-4387][QS] don't wait and process requests at Netty servers after shutdown requestThere is a race condition on an assertion in Netty's event loop that may causetests to fail when finished early.This was fixed in 4.0.33.Final, see https://github.com/netty/netty/issues/4357.This closes #5606.",0
[FLINK-11362][tests] Clean up TaskExecutorTest# testTaskManagerServicesShutdown* Use IOManagerAsync(String) constructor* Simplify TaskExecutorTest#testTaskManagerServicesShutdown() asserts* Explicitly create MemoryManager instance for assertions* Remove superfluous NetworkEnvironmentConfiguration instance* Rename test testTaskManagerServicesShutdown to testShouldShutDownTaskManagerServicesInPostStop* Move heartbeatServices declaration/definition closer to first usage,5
[FLINK-3025] [kafka consumer] Bump transitive ZkClient dependency to 0.7 for bugfixesThis closes #1365,0
[FLINK-23944][connector/pulsar] Enable PulsarSourceITCase.testTaskManagerFailure after test framework was fixed.This closes #17201,0
"KAFKA-4015; Change cleanup.policy config to accept a list of valid policiesChange cleanup.policy to accept a comma separated list of valid policies.Updated LogCleaner.CleanerThread to also run deletion for any topics configured with compact,delete.Ensure Log.deleteSegments only runs when delete is enabled.Additional Integration and unit tests to cover new optionAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #1742 from dguy/kafka-4015",1
[FLINK-15648][k8s] Support to configure limit for CPU and memoryThis closes #17098.,5
[FLINK-23909][connector-jdbc][scala-shell][yarn] Remove redundant variables and improve some style format in coding.This closes #16931.,1
KAFKA-3290: fix transient test failures in WorkerSourceTaskTestAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #998 from hachikuji/KAFKA-3290,5
[FLINK-2640] [yarn] integrate off-heap configurationThis closes #1132,5
"Merge pull request #1375, remove unnecessary boxing.Fixes #1245",0
[FLINK-7739][kafka-tests] Shutdown NetworkFailureProxyThis closes #4749.,0
Removes Google collections from the build dependencies,4
[hotfix] [docs] Add config docs about checkpoint stats,2
[FLINK-16170][elasticsearch] Fix SearchTemplateRequest ClassNotFoundException when using flink-sql-connector-elasticsearch7 We shouldn't `exclude org.elasticsearch:elasticsearch-geo` and `org.elasticsearch.plugin:lang-mustache-client` when shading.This closes #11396,2
DUBBO-527 Remoting的异常不应显示服务名,5
[FLINK-3559] [dist] Don't print INFO if no active processThis closes #1751.,5
"KAFKA-9000: fix flaky FK join test by using TTD (#7517)Migrate this integration test to use TopologyTestDriver instead of running 3 Streams instances.Dropped one test that was attempting to produce specific interleavings. If anything, these should be verified deterministically by unit testing.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
- added SkewRecordCount job,1
"[FLINK-12564][network] Remove ResultPartitionWriter#getBufferProvider()* [FLINK-12564][network] Refactor the method of getBufferProvider to getBufferBuilder in ResultPartitionWriterResultPartitionWriter#getBufferProvider seems not very general for all the writer implementations. The key point is to request a BufferBuilderfrom the BufferProvider, so this method is refactored into getBufferBuilder directly. Then the internal components of ResultPartitionWriter instancewould not be exposed to outside.* [fixup] Remove getBufferProvider from ResultPartition",1
"[FLINK-4628] [core] Provide user class loader during input split assignmentIn analogy to the configure() method, this also sets a context classloader during input split assignment.This closes #2505",1
"KAFKA-7128; Follower has to catch up to offset within current leader epoch to join ISR (#5557)If follower is not in ISR, it has to fetch up to start offset of the current leader epoch. Otherwise we risk losing committed data. Added unit test to verify this behavior.Reviewers: Jason Gustafson <jason@confluent.io>",5
Change to thread-safe date processing class (#9936)* Change to thread-safe date processing class* restore package order,5
Functions can now implement ResultTypeQueryable to supply TypeInformation manually.,5
"[FLINK-11358][tests] Port LeaderChangeStateCleanupTest to new code baseThis commit pots the LeaderChangeStateCleanupTest to the new code base. The newtests test that revoking and granting of the leadership to the Dispatcher and theJobMaster will leave the system in a clean state.Moreover, this commit adds TaskExecutorTest#testDisconnectFromJobMasterWhenNewLeader whichensures that the TaskExecutor sends a disconnect message to the JobMaster if it is notifiedabout a leader change.Additionally, we test via DispatcherTest#testJobSuspensionWhenDispatcherLosesLeadership thata job is failed if the Dispatcher loses leadership.This closes #7567.",0
"KAFKA-7335; Store clusterId locally to ensure broker joins the right cluster (#7189)This patch stores `clusterId` in the `meta.properties` file. During startup, the broker checks that it joins the correct cluster and fails fast otherwise.The `meta.properties' is versioned. I have decided to not bump the version because 1) the clusterId is null anyway if not present in the file; and 2) bumping it means that rolling back to a previous version won't work.I have refactored the way the metadata is read and written as it was strongly coupled with the brokerId bits. Now, the metadata is read independently during the startup and used to 1) check the clusterId and 2) get or generate the brokerId (as before).Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-15802][table] Bring input/output types of table functions closerRefactors the code generation around table functions such that return data typeand argument data type are read from the function at the same location insteadof reading each in a separate code generator. This adds an additional runtimecollector that is only responsible for result conversion.,1
"MINOR: Use self-managed mode instead of KIP-500 and nozk (#10362)KIP-500 is not particularly descriptive. I also tweaked the readme text a bit.Tested that the readme for self-managed still works after these changes.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-13558: NioEchoServer fails to close resources (#11618)Due to resource leaks in the NioEchoServer, at times it won't startproperly to accept clients and will throw an exception in theServerSocketChannel.accept() call. Previous to this change, the errorwas not being logged. The logged error was that there were too many openfiles. Using the UnixOperatingSystemMXBean, I was able to detect thatuse of the NioEchoServer creates several FDs but does not close them.This then caused the client to never be able to connect to the server,so the waitForCondition failed intermittently.This change closes the internal Selector and the AcceptorThread'sselector so that the file descriptors are reclaimed.Reviewers: Ismael Juma <ismael@juma.me.uk>",2
[FLINK-10455][Kafka Tx] Close transactional producers in case of failure and termination (#6989)This commit addresses the problem of potential leak of resources associated with unclosed Kafka transactional producers in case of commitment failure or task shutdown.1. always close producer even if commit fails in TwoPhaseCommitSinkFunction#notifyCheckpointComplete2. close pending transactions in close method of Kafka Flink function in case of task shutdown3. continue trying to commit other transactions in TwoPhaseCommitSinkFunction#notifyCheckpointComplete if any of them failed,0
"KAFKA-2667: Fix transient error in KafkaBasedLogTest.The test required a specific sequence of events for each Consumer.poll() call,but the MockConsumer.waitForPollThen() method could not guarantee that,resulting in race conditions. Add support for scheduling sequences of eventseven when running in multi-threaded environments.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #333 from ewencp/kafka-2667-kafka-based-log-transient-error",2
[hotfix][tests] fix codestyle issues in ResultPartitionBuilder,0
"Dubbo cloud native (#4958)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4807 : Add sort implementation* Refactor* Refactor* Polish apache/dubbo#4845 : [Feature] Enhance the Event-Publishing feature to original ServiceDiscovery* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Polish apache/dubbo#4854 : [Feature] MetadataService supports the Dubbo protocol under auto-increased port* Polish apache/dubbo#4857 : [Enhancement] Sync the Metadata storage type into ApplicationConfig* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4873 : [Feature] Add a conditional EventListener into Event Module* Polish apache/dubbo#4875 : [Feature] Refactor ServiceInstancesChangedListener* Remove the cycle dependencies* Remove the cycle dependencies* Polish apache/dubbo#4903 : [Feature] Set source into the BeanDefinition of Dubbo Config* Polish apache/dubbo#4902 : [Feature] Dubbo Cloud Native to Spring XML scenario* Polish apache/dubbo#4713 : Initial the new module and dependencies* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4910 : [Feature] To suppoort DubboLifecycleComponentApplicationListener in Spring XML scenario* Polish apache/dubbo#4713 : Add Service discovery implementation for Eureka #4713* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4920 : [Refactor] Extract the common implementation for URLs' revision* Refactor* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Remove useless classes* Bugfix & Refactor ServiceDiscoveryRegistry* Polish apache/dubbo#4937 : The calculation of Revision should add the parameters of URL* Polish apache/dubbo#4940 : NacosDynamicConfiguration supports getConfigKeys method* Polish apache/dubbo#4942 : Dubbo Cloud Native supports multiple protcols* Polish apache/dubbo#4944 : [Feature] Simplify The metadata of URL for MetadataService* Polish apache/dubbo#4947 : [Feature] Dubbo Cloud-Native supports the REST call to Non-Dubbo* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/metadata/ServiceInstanceMetadataUtils.java* Refactor* Update JavaDoc",2
"[FLINK-1801] [FLINK-1465] Network environment can start prior to TaskManager in ""disassociated"" mode.NetworkEnvironment allocates heavy network buffer pool on startup and supportsmultiple associations / disassociations with the TaskManager actor.Fix negative memory report by replacing overflowing ints with longs.",0
[FLINK-4545] [network] (followup) Replace awk lshift by multiplication'lshift(...)' is not defined by default in some commonly used awk versions.,1
[FLINK-14091][coordination] Allow updates to connection state when ZKCheckpointIDCounter reconnects to ZK,5
"[FLINK-20949][table-planner-blink] Introduce StreamPhysicalLegacySink, and make StreamExecLegacySink only extended from ExecNodeThis closes #14637",1
[FLINK-5620] Fix unstable ContinuousFileProcessingTest,3
add compatible com.alibaba.xxx.RpcInvocation (#5167),1
MINOR: remove unneeded comments to avoid misleading message (#11122)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
[FLINK-15919][core][mem] MemoryManager shouldn't allow releasing more memory than reservedThis closes #11025.,1
- fix #90- set jvm heap space fix to 512MB for pact-tests unit and integration tests- a separate JVM is forked for each test case in pact-tests integration tests,3
[3.0] ignore non-dubbo nacos services (#8573),5
"KAFKA-10618: Add UUID class, use in protocols (part of KIP-516) (#9454)In order to support topic IDs, we need to create a public UUID class. This class will be used in protocols. This PR creates the class, modifies code to use the class in the message protocol and changes the code surrounding the existing messages/json that used the old UUID class.SimpleExampleMessage was used only for testing, so all usages of UUID have been switched to the new class.SubscriptionInfoData uses UUID for processId extensively. It also utilizes java.util.UUID implementation of Comparable so that UUIDs can be ordered. This functionality was not necessary for the UUIDs used for topic IDs converted to java.util.UUID on the boundary of SubscriptionInfoData. Sorting was used only for testing, though, so this still may be changed.Also added tests for the methods of the new UUID class. The existing SimpleExampleMessage tests should be sufficient for testing the new UUID class in message protocols.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
Fix nacos registry memory leak (#9261)* fix nacos registry memory leak* reduce the creation of EventListener* reduce the creation of EventListener,1
fix destroyAll called twice. (#5819)fix #5813,0
MINOR: use relative counts for restores (#11176)Use a relative count from using 0 for totalNumbRestores to prevent flakiness.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,1
[FLINK-2950] [ml] [docs] Fix markdown rendering problem in SVM documentation  - Remove unnecessary indentation of table  - Fix wrong `strong` end tag  - Simplify lambda expression in map operationThis closes #1312,0
"[FLINK-6261] [table] Support TUMBLE, HOP, SESSION group window functions for SQL queries on batch tables.- Drop support for group window translation of ""GROUP BY FLOOR/CEIL"".This closes #3675.",1
"MINOR: Fix javadoc typos in KStream#processinterface for `Processor` in comments incorrectly had `transform` rather than `process`.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Michael G. Noll, Ismael Juma <ismael@juma.me.uk>Closes #2396 from dguy/minor-javadoc",2
[FLINK-9310] [security] Update standard cipher suites for secure modeThis sets the cipher suits accepted by default to those recommended inIETF RFC 7525 : https://tools.ietf.org/html/rfc7525This closes #5965,5
"KAFKA-8305; Support default partitions & replication factor in AdminClient#createTopic (KIP-464) (#6728)This commit makes three changes:- Adds a constructor for NewTopic(String, Optional<Integer>, Optional<Short>)which allows users to specify Optional.empty() for numPartitions orreplicationFactor in order to use the broker default.- Changes AdminManager to accept -1 as valid options for replicationfactor and numPartitions (resolving to broker defaults).- Makes --partitions and --replication-factor optional arguments when creatingtopics using kafka-topics.sh.- Adds a dependency on scalaJava8Compat library to make it simpler toconvert Scala Option to Java OptionalReviewers: Ismael Juma <ismael@juma.me.uk>, Ryanne Dolan <ryannedolan@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Bump admin client retries for creating repartition topics (#6063)The topology optimization test was getting intermittent failures because of failures to create repartition topics on startup. This PR Increased admin client retriesI kicked off the system test with 25 repeats, all passed http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2018-12-21--001.1545436859--bbejeck--MINOR_flaky_optimization_test_create_repartition_fails--6cd55e2/report.htmlReviewers: Guozhang Wang <wangguoz@gmail.com>",5
fix examples in GitHub readme page to 0.5 version usage,0
[Dubbo-5592] simplify code for getExtensionLoader method (#5593),1
[FLINK-17639] Document which FileSystems are supported by the StreamingFileSinkThis closes #12737.,2
KAFKA-1233 Adding the new test file,2
[FLINK-1706] Spilling BarrierBuffer added + basic tests,3
Added HeaderlessChannelReaderViewFixed HashJoin for recursive spilling,0
KAFKA-3066: Demo Examples for Kafka StreamsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #797 from guozhangwang/K3066,5
[FLINK-11126][YARN][security] Filter out AMRMToken in the TaskManager credentialsThis closes #7895.,2
[FLINK-25783][docs-zh] Translate azure_table_storage.md page into Chinese.This closes #18766.,2
"KAFKA-7215: Improve LogCleaner Error Handling (#5439)The thread no longer dies. When encountering an unexpected error, it marks the partition as ""uncleanable"" which means it will not try to clean its logs in subsequent runs.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",5
Refactor README.,4
[Feature] Using the ID of Dubbo Config as the alias of Bean  (#5094)* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring* Polish /apache/dubbo#4674 & /apache/dubbo#4470* Polish /apache/dubbo#5093 : Revert the previous commit* Polish apache/dubbo#5093 : [Feature] Dubbo Services generate the metadata of REST services,5
"finished parser, but not working for all cases",1
[FLINK-22463][table-planner-blink] Fix IllegalArgumentException in WindowAttachedWindowingStrategy when two phase is enabled for distinct aggThis closes #15759,0
"MINOR: Fix partition loading checks in GroupCoordinator (#4788)In the group coordinator, we currently check whether the partition is owned before checking whether it is loading. Since loading is a prerequisite for partition ownership, it means that it is not actually possible to see the COORDINATOR_LOAD_IN_PROGRESS error. The impact is mostly harmless: while loading the group, the client may send unnecessary FindCoordinator requests to rediscover the coordinator. I've fixed the bug and restructured the code to enable testing.In the process of fixing this bug, the following improvements have been made:1. We now verify valid groupId in all request handlers.2. Currently if the coordinator is loading when a SyncGroup is received, we'll return NOT_COORDINATOR. I've changed this to return REBALANCE_IN_PROGRESS since the rebalance state will have been lost on coordinator failover. This effectively forces the consumer to rejoin the group, which seems preferable over unnecessarily rediscovering the coordinator. 3. I added a check for the COORDINATOR_LOAD_IN_PROGRESS handler in SyncGroup. Although we do not currently return this error, it seems reasonable that we might want to some day, so it seems better to get the check in now.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
[gelly] renamed IncrementalSSSPExample -> IncrementalSSSP to match the new examples naming scheme,1
MINOR: Update dependencies for Kafka 2.4 (part 2) (#7333)Upgrade to Gradle 5.6.2 as a step towards Gradle 6.0 (necessaryfor Java 13 support).https://docs.gradle.org/5.5.1/release-notes.htmlhttps://docs.gradle.org/5.6.2/release-notes.htmlThe other updates are mostly bug fixes:* Scala 2.13.1: https://github.com/scala/scala/releases/tag/v2.13.1* Scala 2.12.10: https://github.com/scala/scala/releases/tag/v2.12.10* Jetty 9.4.20: https://www.eclipse.org/lists/jetty-announce/msg00133.html* SLF4J 1.7.28: adds Automatic-Module-Name in MANIFEST.MF* Bouncy castle 1.63: https://www.bouncycastle.org/releasenotes.html* zstd 1.4.3: https://github.com/facebook/zstd/releases/tag/v1.4.3Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
[FLINK-11767] In PojoSerializerUpgradeTest also check against Flink 1.8,2
add dubbo-addmin,1
"[FLINK-11088] Allow YARN to discover pre-installed keytab filesThis is to change how keytab files are discovered,    * remove hard-coded keytab filenames    * extended YARNSessionFIFOITCase to accommodate different types of security setting test cases regenerate configuration documentations",2
add twitter follow (#3104)* add twitter follow,1
[FLINK-26221][prometheus] Migrate tests to JUnit5,3
[hotfix][docs] Fix few typos in the java docsThis closes #9671.,2
"[hotfix] [core] Subclass serializer cache in PojoSerializer should be a MapIn this case, there is no specific need to let that cache bespecifically a HashMap. Changing this to the generic Map does not breakcontracts with how the PojoSerializer works. It also doesn't breakcompatibility w.r.t. Java serialization of the PojoSerializer.",4
[FLINK-3048] [tests] Increase stability of DataSinkTaskTest,5
"MINOR: Add docs for StreamJoined changes (#9951)Add docs for KIP-689.Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-6471] [checkpoint] Fix RocksDBStateBackendTest#testCancelRunningSnapshot failing sporadically,0
Support protocol config for reference annotation (#1675),5
[FLINK-20654][tests] Add a time-limit to the induced backpressure.Also increase checkpointing interval with parallelism to avoid overloading I/O during recovery (slowing down checkpointing after recovery).,1
[FLINK-8667] Expose key in KeyedBroadcastProcessFunction#onTimer()This closes #5500.,5
[FLINK-4827] [docs] Fix scala Streaming Table exampleThis closes #2632.,0
[FLINK-15695][docs] Remove outdated background sections from configuration docs,2
KAFKA-1515 Producer can hang during metadata updates. Patch by Guozhang.,5
[FLINK-19445][hbase] Fix guava version conflict in Hbase 1.4 testCloses #13503,3
"MINOR: Fix code section formatting in TROGDOR.md (#6720)Due to the lack of a blank line, a code section in TROGDOR.mdis not properly rendered. This PR fixes it.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: Only include transactional id in LogContext if it's setAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3910 from ijuma/transactional-id-should-be-optional-in-log-context",2
[FLINK-4179] [table] Additional TPCHQuery3Table example improvements,1
Fixed Nephele Visualization job selection not working on Mac OS X[ci skip],1
[FLINK-12325][metrics] Add counter/gauge tests for StatsD,3
[FLINK-20456][docs] Make dynamic tables sound less 'academic',1
Minor cleanup for Warnings,2
[hotfix] Remove a supportsAsynchronousSnapshots method used in tests only,3
[FLINK-10402] Port AbstractTaskManagerProcessFailureRecoveryTest to new code baseThis closes #6750.,1
[FLINK-10358] fix NPE when running flink-kinesis connector against dynamodb streamsThis closes #6708.,5
[hotfix][network] Remove the deduplication for CancelPartitionRequest.To avoid the memory leak in the record map for deduplication.,4
Clean hash join shutdown on cancel case.,4
MINOR: Fix config name and remove hard coded values (#12564)Fix config name and remove hard coded valuesReviewers: Luke Chen <showuon@gmail.com>,4
[FLINK-22093][coordination][tests] Harden ThreadInfoSampleServiceTest,5
"KAFKA-13412; Ensure initTransactions() safe for retry after timeout (#11452)If the user's `initTransactions` call times out, the user is expected to retry. However, the producer will continue retrying the `InitProducerId` request in the background. If it happens to return before the user retry of `initTransactions`, then the producer will raise an exception about an invalid state transition. The patch fixes the issue by tracking the pending state transition until the user has acknowledged the operation's result. In the case of `initTransactions`, even if the `InitProducerId` returns in the background and the state changes, we can still retry the `initTransactions` call to obtain the result.Reviewers: David Jacot <djacot@confluent.io>",5
"HOTFIX: don't try to remove uninitialized changelogs from assignment & don't prematurely mark task closed (#8140)This fixes two issues which together caused the soak to crash/some test to fail occasionally.What happened was: In the main StreamThread loop we initialized a new task in TaskManager#checkForCompletedRestoration which includes registering, but not initializing, its changelogs. We then complete the loop and call poll, which resulted in a rebalance that revoked the newly-initialized task. In TaskManager#handleAssignment we then closed the task cleanly and go to remove the changelogs from the StoreChangelogReader only to get an IllegalStateException because the changelog partitions were not in the restore consumer's assignment (due to being uninitialized).This by itself should^ be a recoverable error, as we catch exceptions here and retry closing the task as unclean. Of course the task actually was successfully closed (clean) so we now get an unexpected exception Illegal state CLOSED while closing active taskThe fix(es) I'd propose are:1. Keep the restore consumer's assignment in sync with the registered changelogs, ie the set ChangelogReader#changelogs but pause them until they are initialized edit: since the consumer does still perform some actions (gg fetches) on paused partitions, we should avoid adding uninitialized changelogs to the restore consumer's assignment. Instead, we should just skip them when removing.2. Move the StoreChangelogReader#remove call to before the task.closeClean so that the task is only marked as closed if everything was successful. We should do so regardless, as we should (attempt to) remove the changelogs even if the clean close failed and we must do unclean.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[hotfix][runtime] Move generating PendingTaskManagerId to inside PendingTaskManager.,4
[hotfix][table-common] Disable cast from binary to date/timeDon't allow to cast from `BINARY`/`VARBINARY`/`BYTES` to any of`DATE`/`TIME`/`TIMESTAMP`/`TIMESTAMP_LTZ` in verification stage.,5
"KAFKA-4937: Batch offset fetches in the Consumerchange `consumer.position` so that it always updates any partitions that need an update. Keep track of partitions that `seekToBeginning` in `StoreChangeLogReader` and do the `consumer.position` call after all `seekToBeginning` calls.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang, Jason Gustafson, Ismael JumaCloses #2769 from dguy/kafka-4937",4
MINOR: Fix MockAdminClient to not throw IndexOutOfBoundsException when brokerId is above the known one. (#8392)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
[hotfix] Add shortcuts for getting jvm heap / direct memory size.,1
KAFKA-4728; KafkaConsumer#commitSync should copy its inputAuthor: Jan Lukavsky <jan.lukavsky@o2.cz>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2491 from je-ik/KAFKA-4728,5
[FLINK-10938][e2e] Add e2e test for natively running flink session cluster on kubernetesThis closes #10602.,3
[FLINK-17017][runtime] Allow to set whether a physical slot payload will occupy the slot indefinitely,5
[hotfix][e2e] harden elasticsearch test,3
[FLINK-21132][runtime][tests] Stop with savepoint shouldn't end input,3
DUBBO-253git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1224 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-5712] [config] update several deprecated configuration optionsThis closes #3267.,5
- updated contract tests- moved pact program tests- fixed tpch-3 program test- fixed LocalFSProvider,1
[hotfix] Establish strict one to one mapping between primary and secondary key in DualKeyLinkedMapThis commit corrects the contract of the DualKeyLinkedMap which states that there can exactly be one entry with a given primary or secondary key and that there is a strict one-to-one relationship between the keys.,1
[FLINK-8370][REST] Port AggregatingMetricsHandler to flip6This closes #5805.,0
[FLINK-15638][release][python] Change version of pyflink to the release version when creating release branch,1
[FLINK-8620] Enable shipping custom files to BlobStore and accessing them through DistributedCacheThis closes #5580,2
[FLINK-17967][docs] Fix Chinese documentation build is brokenThis closes 12414,2
DUBBO-188 增加mock=false测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1187 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-22232][network] More logging of network stack.,1
Fix javadocs in CsvReader,2
"MINOR: Clean up imports and unused variables (#5171)Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
[hotfix] Fix some typos in comments,2
[FLINK-5124] [table] Support more temporal arithmeticThis closes #2851.,1
"KAFKA-13456; Tighten KRaft listener config checks/constraints (#11503)This patch tightens the configuration checks related to KRaft configs by adding the following constraints:* `control.plane.listener.name` is confirmed to be empty in KRaft mode whenever a config object is created as opposed to later when the broker is given the config and tries to start.* `controller.listener.names` is required to be empty for the non-KRaft (i.e. ZooKeeper) case.  A ZooKeeper-based cluster that sets this config will fail to restart until this config is removed.* There must be no advertised listeners when running just a KRaft controller (i.e. when `process.roles=controller`).  This means neither `listeners` nor `advertised.listeners` (if the latter is explicitly defined) can contain a listener that does not also appear in `controller.listener.names`.* When running a KRaft broker (i.e. when `process.roles=broker` or `process.roles=broker,controller`), advertised listeners (which was already checked to be non-empty via the check that the inter-broker listener appear there) must not include any listeners appearing in `controller.listener.names`.* When running a KRaft controller (i.e. when `process.roles=controller` or `process.roles=broker,controller`) `controller.listener.names` must be non-empty and every one must appear in `listeners`* When running just a KRaft broker (i.e. when `process.roles=broker`) `controller.listener.names` must be non-empty and none of them can appear in `listeners`.  This was indirectly checked previously, but the indirect checks did not catch all cases.* When running just a KRaft broker we log a warning if more than one entry appears in `controller.listener.names` because only the first entry is used.* We also map configured controller listener names to the `PLAINTEXT` security protocol by default provided that the security mapping is empty and no other security protocols are in use.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"[FLINK-11636][docs-zh] Translate ""State Schema Evolution"" page into ChineseThis closes #8319",1
FileInputFormat.acceptFile() to filter out files and directories while creating input splits (like _log or _SUCCESS),2
Removed old code,4
"implemented LazyArrayNode,changed return type of IArrayNode>>toArray from Object[] to IJsonNode[],refactored LazyObjectNode>>getOtherField() so less type-casts are needed",1
[FLINK-27902][network] Add ConsumingConstraint and releaseBy in ResultPartitionType to decoupling scheduling and partition release.,1
KAFKA-1910; Refactor new consumer and fixed a bunch of corner cases / unit tests; reviewed by Onur Karaman and Jay Kreps,3
MINOR: Fix wrong commentsAuthor: Yukun Guo <gyk.net@gmail.com>Reviewers: Gwen ShapiraCloses #1198 from gyk/fix-comment,0
"Merge pull request #2070, fix a bug which make isDone method infinite-loop.",5
"[FLINK-3674] Add an interface for Time aware User FunctionsThis moves the event-time/processing-time trigger code fromWindowOperator behind a well defined interface that can be used byoperators (and user functions).InternalTimerService is the new interface that has the samefunctionality that WindowOperator used to have. TimerService is the userfacing interface that does not allow dealing with namespaces/payloadsand also does not allow deleting timers. There is a defaultimplementation in HeapInternalTimerService that can checkpoint timers toa stream and also restore from a stream. Right now, this is managed inAbstractStreamOperator and operators can ask for anInternalTimerService.This also adds tests for HeapInternalTimerService.This adds two new user functions: - TimelyFlatMapFunction: an extension of FlatMapFunction that also   allows querying time and setting timers - TimelyCoFlatMapFunction: the same, but for CoFlatMapFunctionThere are two new StreamOperator implementations for these that use theInternalTimerService interface.This also adds tests for the two new operators.This also adds the new interface KeyContext that is used forsetting/querying the current key context for state and timers. Timersare always scoped to a key, for now.Also, this moves the handling of watermarks for both one-input andtwo-input operators to AbstractStreamOperators so that we have a centralground-truth.",1
add toString for RocksDbWindowBytesStoreSupplier (#8952)Add toString() to RocksDbWindowBytesStoreSupplier to amend the logging gap.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
[hotfix] Make TestingSlotManager#setFailUnfulfillableRequestConsumer non-nullable,3
增加README说明git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@709 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"Follow up to KAFKA-695:Broker shuts down due to attempt to read a closed index file, reviewed by Neha and Jay",2
"[FLINK-15577][table-planner-blink] Add different windows tests to blink plannerThe Blink planner doesn't seem to be subject to the bug described inFLINK-15577. For safety, we also add the tests to ensure no regressionis possible that would introduce the issue in the Blink planner.",2
[FLINK-3818] Remove Guava dependency from flink-gelly-examplesThis closes #1936,2
service discovery demo,5
[hotfix][benchmarks] Add network stack benchmarks for LocalInputChannels,1
Require values in Utils.getTopic* methods to be positive (0.8 branch); patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-481git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377214 13f79535-47bb-0310-9956-ffa450edef68,1
[3.0]Fix security problem (#7779),0
[FLINK-8773] [flip6] Make JobManagerRunner shut down non blockingThe Dispatcher no longer shuts down the JobManagerRunner in a blocking fashion.Instead it registers the termination futures and calls the shut down of theJobManagerSharedServices once all JobManagerRunners have terminated.This closes #5575.,1
[FLINK-28634][json] Deprecate JsonNodeDeserializationSchemaSubsumed by more general 'JsonDeserializationSchema'.,5
"KAFKA-12482 Remove deprecated rest.host.name and rest.port configs (#10841)Remove the `rest.host.name` and `rest.port` Connect worker configs that were deprecated in KIP-208 and AK 1.1.Author: Kalpesh Patel <kalpeshpatel.india@gmail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, wenbingshen <oliver.shen999@gmail.com>",5
[FLINK-3611] [docs] Correct link in CONTRIBUTING.mdThis closes #1786,2
[FLINK-9511] Implement state TTL configurationThis closes #6277.,5
"MINOR: Provide better messages when waiting for a condition in test (#7488)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[hotfix][table] Remove deprecated AggregateFunction.requiresOver(),1
[FLINK-2445] Improve HadoopOutputFormatTestsThis closes #1628,3
[hotfix] Fix parameter name KeyedCoProcessOperator constructor,1
"Kafka-3880: Disallow Join Window with size zeroAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Michael G. Noll, Damian Guy, Eno Thereska, Guozhang WangCloses #1529 from mjsax/kafka-3880-join-windows",5
[FLINK-14786][configuration] Add configure method to ExecutionConfigThis closes #10217,5
"KAFKA-8595: Support deserialization of JSON decimals encoded in NUMERIC  (#7354)Implemented KIP-481 by adding support for deserializing Connect DECIMAL values encoded in JSON as numbers, in addition to raw byte array (base64) format used previously.Author: Almog Gavra <almog@confluent.io>Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
"[FLINK-20436][table-planner-blink] Simplify ExecNode: Remove ""Planner"" type parameter & Remove the default implementation into ExecNodeBase",4
Added tests for project operator,1
"[minor,docs] Clarify *final results* in DataStream execution mode docs",2
"[FLINK-20705][table-planner-blink] Introduce StreamPhysicalValues, and make StreamExecValues only extended from ExecNodeThis closes #14454",1
"MINOR: Fix consumer/producer properties override (#9313)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",0
[FLINK-8857][hbase] Remove redundant execute() call in hbase exampleThis closes #5633.,4
"KAFKA-8941: Add RocksDB Metrics that Could not be Added due to RocksD… (#11441)This PR adds some RocksDB metrics that could not be added in KIP-471 due to RocksDB version. The new metrics are extracted using Histogram data provided by RocksDB API, and the old ones were extracted using Tickers. The new metrics added are memtable-flush-time-(avg|min|max) and compaction-time-(avg|min|max).Reviewer: Bruno Cadonnna <cadonna@apache.org>",1
MINOR: Upstream QuotaConfigsThis PR moves static property definitions for user client quotas into anew class called QuotaConfigs in the clients module under theo.a.k.common.config.internals package. This is needed to support theclient quotas work in the quorum based controller.Reviewers: Colin McCabe <cmccabe@apache.org>,1
[FLINK-8821] [table] Fix non-terminating decimal errorThis closes #5608.,0
[FLINK-10102][docs] Fix docs for EXECUTION_FAILOVER_STRATEGY,0
MINOR: Verify stopReplica if broker epoch not stale (#12040)Verify that ReplicaManager.stopReplica is called if the stop replicarequest doesn't result in a stale broker epoch error.Reviewers: Mickael Maison <mimaison@users.noreply.github.com>,1
MINOR: Remove errant lock.unlock() call from RoundTripWorker (#6612)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"Fixes #8198 KStreams testing docs use non-existent method pipe (#6678)Minor fix of #8198 apache/kafka-site#210Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
Release resource after use in ConfigParserTest (#3127)Release resource after use in ConfigParserTest,5
[core] cleanup & tests for FileInputFormatfollowup of f2891ab857e00bc70eb025bb430f46f4f58355a5This closes #732.,2
[FLINK-22766][connector/kafka] Report offsets and Kafka consumer metrics in Flink metric group,2
[FLINK-8038] [table] Clear maps and support cardinality,1
Updated Readme.,5
"MINOR: Add pull request templateAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4174 from ijuma/pull-request-template",5
"Extended notice that the project uses Apache Code, to be compliant with Apache Guidelines.",1
"[3.0] fix #10035 ,n DubboService.java loadbalance does not have a correct default value (#10036)change DubboService#loadbalance() default ClusterRules.EMPTY;  to loadbalance() default LoadbalanceRules.EMPTY;",5
[FLINK-23040][table-common] Consider ConfigOption fallback keys of formats in FactoryUtilThis closes #16226.,5
[hotfix][tests] Always respond to task cancellation requestsThe previous cancel setup doesn't make sense if you aren't aware that one of the tests forces a restart.We now immediately respond to any task cancellation request instead.,1
"KAFKA-5660 Don't throw TopologyBuilderException during runtime (#4645)Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-18209] Replace slave with worker in docker cluster test scripts,3
[FLINK-10987] Add LICENSE & NOTICE files for flink-runtime-web,2
[FLINK-22462][connectors / jdbc] Fix XA connection leak,0
[FLINK-12611][table-planner-blink] Make time indicator nullable in blinkThis closes #8530,2
Some bug fixes,0
"MINOR: Add a new system test for resilience (#4560)* Rolling kill-restart Streams instances with brokers unavailable temporarily, and validate that the streams can still complete the restart processReviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-1676] Rework ExecutionConfig.enableForceKryo()This closes #473,5
[FLINK-16197][hive] Failed to query partitioned table when partition folder is removedThis closes #11175,4
"KAFKA-9274: handle TimeoutException on task reset (#10000)Part of KIP-572: We move the offset reset for the internal ""main consumer"" when we revive a corrupted task, from the ""task cleanup"" code path, to the ""task init"" code path. For this case, we have already logic in place to handle TimeoutException that might be thrown by consumer#committed() method call.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",5
Shorten the life cycle of TimeoutTask to avoid frequent gc. (#4040),5
"MINOR: Update jetty, jackson, gradle and jacoco (#4547)* MINOR: Update gradle, jackson and jacoco- Gradle update adds support for Java 10- Jacoco update adds support for Java 9- Jackson bug fix update adds more serializationrobustness checks* Update JettyReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-28446][runtime] Expose more information in PartitionDescriptor to support more optimized Shuffle ServiceThis closes #20200.,1
[FLINK-21715][table-api] Support implicit cast conversion between TIMESTAMP and TIMESTAMP_LTZThis closes #15363,1
[Dubbo-3347] Update package name in README file  fix#3347 (#3362),0
MINOR: LogCleaner.validateReconfiguration fixes (#4770)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
[hotfix][table][docs] Fix link,2
"[FLINK-18906][task] Expose InputProcessorUtil#createCheckpointBarrierHandlerThis will be useful in a next commit, where MultipleInputStreamTask will needto have an access to the CheckpointBarrierHandler",0
[FLINK-15999][doc] Add TODOs to state concepts section,2
Added rule rewriter for cleansing expression,4
[FLINK-23080][datastream] Introduce SinkFunction#finish() method.,5
Add 2.0.7git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@8 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-22477][tests] Replace SlotPoolImpl usage with DeclarativeSlotPoolBridge in DefaultSchedulerBatchSchedulingTest,3
"KAFKA-13553: Add PAPI Window and Session store tests for IQv2 (#11650)During some recent reviews, @mjsax pointed out that StateStore layersare constructed differently the stores are added via the PAPI vs. the DSL.This PR adds PAPI construction for Window and Session stores to theIQv2StoreIntegrationTest so that we can ensure IQv2 works on everypossible state store.Reviewer: Guozhang Wang <guozhang@apache.org>",1
Add :authority and :scheme to triple headers (#7156),1
"[FLINK-11826][tests] Harden Kafka09ITCase#testRateLimitedConsumerKafka tests seem to have the problem that writing to a newly created topiccan fail. In order to harden the test against this problem, we set thenumber of Kafka retries to 3.This closes #7900.",1
"MINOR: checkstyle version upgrade: 8.20 -> 8.36.2 (#10656)Details:* Release notes: https://checkstyle.org/releasenotes.html#Release_8.36.2* Checkstyle version 8.42 should be skipped (lots of false positives, see here: https://github.com/checkstyle/checkstyle/issues/9957)* More recent Checkstyle versions (i.e. 8.37 and above) are imposing more strict indentationrules.",0
"KAFKA-3216: ""Modifying topics"" section incorrectly says you can't change replication factor.Correct the text that said that you can't change the replication factor of a topic.Author: James Cheng <jylcheng@yahoo.com>Reviewers: Ismael JumaCloses #881 from wushujames/KAFKA-3216",4
"KAFKA-12369; Implement `ListTransactions` API (#10206)This patch implements the `ListTransactions` API as documented in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.Reviewers: Tom Bentley <tbentley@redhat.com>, Chia-Ping Tsai <chia7712@gmail.com>",5
[hotfix] Fix test instability in AbstractTaskManagerProcessFailureRecoveryTest,3
[hotfix][tests] Report failure with error level instead of debug,0
[FLINK-13225][hive] Fix getAccumulatorType of HiveGenericUDAF,1
[FLINK-21979][runtime] Cleanup completed checkpoint store after dispatcher cleans up HA services.This closes #16535.,4
"[FLINK-8589][runtime] Add polling method to InputGateThis is a preparation for changes in data notifications, which will not bethat strict as they are now.",5
[hotfix][runtime] Add convenience TestingLogicalSlot constructor,3
Add convenience method to set local environments to overwrite files by default.,2
[hotfix] [streaming] Handle rich functions properly in aligned time windows,1
[streaming] Moved tuple copying to StreamCollector2,4
[FLINK-25238][table-runtime] Fix ArrayDataSerializer#copy for customized types,5
[hotfix][docs] Improve the description of JDBC docs (#17661),2
[FLINK-26779][rest] OperationKey implements Serializable,2
[hotfix][table-planner] Remove unnused Quarter case classThe API for this was already changed in FLINK-6846.,2
[hotfix][network] Improve error message in ChannelStateWriterImpl,0
MINOR: Clarify how to fix conversion issues when plain JSON data is used with schemas.enable=trueAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2041 from ewencp/clarify-json-converter-failure,5
[hotfix] Use properly shaded guava version,1
"KAFKA-9433: Use automated protocol for AlterConfigs request and response (#8315)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Boyang Chen <boyang@confluent.io>",5
[hotfix] [tests] Remove unused enum from StateBackendTestBase,3
"KAFKA-5470; Replace -XX:+DisableExplicitGC with -XX:+ExplicitGCInvokesConcurrent in kafka-run-classThis is important because Bits.reserveMemory calls System.gc() hoping to free nativememory in order to avoid throwing an OutOfMemoryException. This call is currentlya no-op due to -XX:+DisableExplicitGC.It's worth mentioning that -XX:MaxDirectMemorySize can be used to increase theamount of native memory available for allocation of direct byte buffers.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Apurva Mehta <apurva@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3371 from ijuma/kafka-5470-explicit-gc-invokes-concurrent",5
"MINOR: Introduce ProducerIdGenerator trait (#10009)`ProducerIdManager` is an existing class that talks to ZooKeeper directly.  We won't have ZooKeeperwhen using a Raft-based metadata quorum, so we need an abstraction for the functionality ofgenerating producer IDs.  This PR introduces `ProducerIdGenerator` for this purpose, and we passan implementation when instantiating `TransactionCoordinator` rather than letting`TransactionCoordinator.apply()` itself always create a ZooKeeper-based instance.Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",1
"[FLINK-5772] [elasticsearch] Allow Elasticsearch 1.x tests to rerun on failureThis is allowed because Elasticsearch 1.x has a potential deadlock whencreating indices. Since this flakiness rarely happens, this commitallows rerunning the Elasticsearch 1.x tests to try to mitigate thisproblem instead of just failing them.This closes #3410.",0
KAFKA-12331: Use LEO for the base offset of LeaderChangeMessage batch (#10138)The `KafkaMetadataLog` implementation of `ReplicatedLog` validates that batches appended using `appendAsLeader` and `appendAsFollower` have an offset that matches the LEO. This is enforced by `KafkaRaftClient` and `BatchAccumulator`. When creating control batches for the `LeaderChangeMessage` the default base offset of `0` was being used instead of using the LEO. This is fixed by:1. Changing the implementation for `MockLog` to validate against this and throw an `RuntimeException` if this invariant is violated.2. Always create a batch for `LeaderChangeMessage` with an offset equal to the LEO.Reviewers: Jason Gustafson <jason@confluent.io>,5
[3.0] Reduce object creation when getting extensions (#9218)* [3.0] Reduce object creation when getting extensions* fix ut,0
Adjusted job graph generator to new job graph classes,1
HOTFIX: fix build error (#10796)Fix compile error in scala tests.The compile error is:```[Error] /home/jenkins/jenkins-agent/workspace/Kafka_kafka-pr_PR-9229/core/src/test/scala/unit/kafka/server/metadata/BrokerMetadataListenerTest.scala:97: polymorphic expression cannot be instantiated to expected type;[2021-05-29T02:34:50.308Z]  found   : [T]()T[2021-05-29T02:34:50.308Z]  required: kafka.server.RequestLocal```This error happens only in scala 2.12Reviewers: Bruno Cadonna <cadonna@apache.org>,1
"KAFKA-5990: Enable generation of metrics docs for Connect (KIP-196)A new mechanism was added recently to the Metrics framework to make it easier to generate the documentation. It uses a registry with a MetricsNameTemplate for each metric, and then those templates are used when creating the actual metrics. The metrics framework provides utilities that can generate the HTML documentation from the registry of templates.This change moves the recently-added Connect metrics over to use these templates and to then generate the metric documentation for Connect.This PR is based upon #3975 and can be rebased once that has been merged.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3987 from rhauch/kafka-5990",5
[FLINK-17295][runtime] Rework MetricGroup methods to ensure param consistency,2
[FLINK-5447] [table] Sync documentation of built-in functions for Table API with SQLThis closes #3126.,1
[FLINK-2400] [tests] Improve error message on unexpected TaskTest message,3
Merge branch 'score' into streamingConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/jobmanager/JobManager.java,5
[DUBBO-3137]: step3 - start to use RpcConstants (#4038)* constants step3 rpc* remove useless import* remove useless import* remove useless import* remove useless import,2
Fixed overrestrictive null-pointer check in Ordering.,0
[FLINK-19223][connectors] Simplify Availability Future Model in Base ConnectorThis implements a model closer to the AvailabilityListener and AvailabilityHelper in the flink-runtime.This closes #13385,2
KAFKA-1250 Add logging to new producer.,1
Fixed race in TackManager's checking for failed tasks.,0
[hotfix][rest][tests] Replace HandlerBlocker with BlockerSync,0
"[FLINK-20654][network] Fix ChannelStatePersister#checkForBarrier.This commit also checks if #startPersisting called correctly.Note that a few test cases in UnalignedControllerTest already fail with this new check, such that no new tests are needed.",3
- extended DefaultMemoryManagerTest,3
[FLINK-22052][python] Add new checkpoint storage classes to PyFlink,2
[FLINK-8735] Add new StatefulJobSavepointMigrationITCaseThis new test does not pretend to use legacy state but now instead usesthe more modern operator state varieties.The binary savepoints for this were generated on the release-1.4 branch.,1
[docs] Add production readiness checklistThis closes #3259.,1
[contrib] Remove redundant LICENSE file in 'flink-contrib/docker-flink',2
"KAFKA-3597; Query ConsoleConsumer and VerifiableProducer if they shutdown cleanlyEven if a test calls stop() on console_consumer or verifiable_producer, it is still possible that producer/consumer will not shutdown cleanly, and will be killed forcefully after a timeout. It will be useful for some tests to know whether a clean shutdown happened or not. This PR adds methods to console_consumer and verifiable_producer to query whether clean shutdown happened or not.hachikuji and/or granders Please review.Author: Anna Povzner <anna@confluent.io>Reviewers: Jason Gustafson, Geoff Anderson, Gwen ShapiraCloses #1278 from apovzner/kafka-3597",5
[FLINK-2784] Remove deprecated configuration keys and updated documentationThis closes #1244,2
"MINOR: clean up node and store sensors (#5450)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"[FLINK-12946][docs-zh] Translate ""Apache NiFi Connector"" page into ChineseThis closes #8838",1
Some refactoring in OptimizerNode,4
"KAFKA-5230; Fix conversion of Class configs to handle nested classes properlyAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3044 from ewencp/kafka-5230-nested-class-recommended-values",5
[FLINK-28778][SQL/API] Bulk fetch of table and column statistics for given partitionsThis closes #20501Co-authored-by: Jing Ge <gejing@gmail.com>,2
add netty channel connected and disconnected log. (#5171),2
[hotfix][table] Deduplicate RelTimeInidicatoConverter logic,2
KAFKA-4957; Request rate quotas documentationAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3069 from rajinisivaram/KAFKA-4957,5
Fatal error during KafkaServerStable startup when hard-failed broker is re-started; patched by Swapnil Ghike; reviewed by Jun Rao and Jay Kreps; kafka-757,0
Fixed formatting,0
[FLINK-1077] Fix unstable test CliFrontendPackageProgramTest,3
"Revert ""[hotfix] [cassandra] Fix CassandraSinkBase serialization issue""This reverts commit 5fa389014a3ce40534703c8a5731c8a9a955058a.",4
[hotfix] fix table walkthrough due to removing TableSource & TableSink registration,4
[hotfix][tests] Let PhysicalSlotProviderImplWithSpreadOutStrategyTest extend TestLogger,3
[FLINK-9330] [runtime] Add periodic logging of SlotPool statusOnly happens if log level for the SlotPool is set to DEBUG,0
[FLINK-3156] Fix NPE in KafkaConsumer when reading from SOME empty topics/partitions,0
[FLINK-4731] Fix HeapKeyedStateBackend Scale-InAdds additional tests in RescalingITCase for scale-inThis closes #2584.,3
[FLINK-9266] [kinesis] Updates Kinesis connector to use newer version of kcl to limit describe streams callsThis closes #5932.,1
[hotfix] Correct checkstyle violations in RestartStrategies,0
added sortmerger cache to latest code-base,3
[FLINK-6580] Sync default heap sizes from code with config fileThis closes #3900,2
[FLINK-12683] Provide task manager location information for checkpoint coordinator specific log messages,2
[streaming] Repository change to dms.sztaki.hu/maven-public,4
"KAFKA-5864; ReplicaFetcherThread should not die due to replica in offline log directoryAuthor: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #3820 from lindong28/KAFKA-5864",2
[refactor] Use tabs in checkstyle.xml to conform to our other XML files,2
[FLINK-24099][docs] Refer to nightlies.apache.org,2
MINOR: LogLoader: Add log identifier at few missing areas (#10819)Reviewers: Jun Rao <junrao@gmail.com>,2
[FLINK-27255] [flink-avro] flink-avro does not support ser/de of large avro schema (#19645)Co-authored-by: Haizhou Zhao <haizhou_zhao@apple.com>,1
[FLINK-2425] [FLINK-2426] [runtime] Add an unmodifiable config and provide access to task manager configuration and hostname inside RuntimeEnvironment,1
[FLINK-6909] [types] Add tests for Lombok POJOsThis closes #6033.,3
Merge branch 'version02' into checkpointingConflicts:pact/pact-clients/src/main/java/eu/stratosphere/pact/testing/MockTaskManager.java,5
"[FLINK-24189] Extract BufferDebloatConfigurationExtract a BufferDebloatConfiguration which reads and validates optionsfrom a general purpose Configuration. This way we do not need to passaround the entire task configuration, but just a concise set ofnecessary options.",1
"[FLINK-12839][dist] package flink-shaded-netty-tcnative-dynamic into opt/Please note that there is also a static version of netty-tcnative but wecurrently do not distribute it due to licensing issues. Once openSSL completesits switch to Apache License v2, we can provide this as well and maybe evenmake that one default (by putting it into lib/). Since there are to many thingswhich may go wrong with the dynamically-linked library (based on the system yourun on), we provide this only in opt/.",1
[FLINK-954] Improved WebClient  - display temp_mode at edge  - simplified function loadJsonToDagre(data);  - removed small grey borders below colored borders  - mirrored node into iteration if the origin is outside to draw an edge  - added zoom buttons in planVisualizer.htmlThis closes #82,1
"MINOR: Improve PartitionState logging and remove duplication of codeCurrently, logs involving PartitionState are not very helpful.```Broker 449 cached leader info org.apache.kafka.common.requests.UpdateMetadataRequest$PartitionState3285d64a for partition <topic>-<partition> in response to UpdateMetadata request sent by controller 356 epoch 138 with correlation id 0TRACE state.change.logger: Broker 449 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState66d6a8eb correlation id 3 from controller 356 epoch 138 for partition [<topic>,<partition>]```Author: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1609 from SinghAsDev/partitionState",4
[FLINK-14630] Add test utility to create YarnClusterDescriptor with Logging,2
[FLINK-1694] [gelly] fixed typo and a small code simplificationThis closes #547,2
KAFKA-12633: Remove deprecated APIs in TopologyTestDriver (#10508)As well as related test classes.Reviewers: John Roesler <vvcephei@apache.org>,3
[FLINK-21463][table-api] Support to parse 'RESET key' command,1
KAFKA-1925; Fix coordinator broker id stuck with INT_MIN; reviewed by Jay Kreps,0
[streaming] Minor streaming code cleanupsCloses #873,4
[streaming] Fixed error logging in streaming tasks.,2
MINOR: enable KRaft in MetadataRequestTest (#11637)Reviewers: David Arthur <mumrah@gmail.com>,5
DUBBO-259 pojoutil基本类型转换失败 回滚修改在string Utils中增加number的判断方法git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1190 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Menu updates and navigation (#4405)* Menu updates and navigationReviewers: Guozhang Wang <wangguoz@gmail.com>,5
Merge branch 'hpi'Conflicts:nephele/nephele-common/src/test/java/eu/stratosphere/nephele/io/channels/serialization/SerializationTestType.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/ElementaryOperator.javasopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/testing/SopremoTestPlan.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/Annotator.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/Clustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/Point.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/SimpleClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/initial/InitialClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/initial/SequentialClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/json/ClusterNodes.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/ClusterDisassemble.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/MainClustering.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/PointMapper.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/main/RepresentationUpdate.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/PointSelection.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/PostProcess.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/RepresentationSelection.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/RepresentationSwitch.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/postprocessing/Split.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/tree/ClusterTree.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/ClusterToTreePreparation.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/TreeAssembler.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/TreeCreator.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/json/AnnotatorNodes.javasopremo/sopremo-sdaa11/src/main/java/eu/stratosphere/sopremo/sdaa11/util/JsonUtil2.javasopremo/sopremo-sdaa11/src/main/java/temp/GeneratePoints.javasopremo/sopremo-sdaa11/src/test/java/eu/stratosphere/sopremo/sdaa11/clustering/ClusteringTest.javasopremo/sopremo-sdaa11/src/test/java/eu/stratosphere/sopremo/sdaa11/clustering/InitialClusteringAndTreeCreationTest.javasopremo/sopremo-sdaa11/src/test/java/eu/stratosphere/sopremo/sdaa11/clustering/treecreation/TreeAssemblerTest.java,5
KAFKA-6418; AdminClient should handle empty or null topic names better (#4470),1
"kafka-2104; testDuplicateListeners() has a typo; patched by Gwen Shapira; reviewed by Sriharsha Chintalapani, Onur Karaman and Jun Rao",2
[hotfix][tests] Remove Kafka testFailOnDeploy test,3
Added static utility serialization and deserialization methods to PactString for custom data types.,5
[hotfix][java] Add missing space to error messageThis closes #4944.,1
[distributed runtime] Notify about error when handing in channel,0
[FLINK-25414][metrics] Document maxSoft/HardBackPressureTime and soft/hardBackPressureTimeMsPerSecond metrics,5
[FLINK-1985] [streaming] Add ExecutionConfig serialization for streaming jobsThis closes #682,5
Removed csv converter hack,4
[FLINK-3474]: Enable partial aggregate in Table API-- add new Aggregate interface which support partial aggregate-- implement SUM/COUNT/AVG/MIN/MAX aggregate functions implementation-- sorted-based runtime supportthis closes #1746,1
"KAFKA-10018: Change command line tools from /bin/sh to /bin/bash (#8692)Reviewers: Tom Bentley @tombentley, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@confluent.io>, Colin P. McCabe <cmccabe@apache.org>, Matthias J. Sax <matthias@confluent.io>",5
Merge branch 'merge-3.x'# Conflicts:#dubbo-common/src/main/java/org/apache/dubbo/common/URL.java#dubbo-common/src/main/java/org/apache/dubbo/rpc/model/ServiceMetadata.java#dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/command/impl/Offline.java#dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/command/impl/Online.java#dubbo-plugin/dubbo-qos/src/test/java/org/apache/dubbo/qos/command/impl/LsTest.java#dubbo-plugin/dubbo-qos/src/test/java/org/apache/dubbo/qos/command/impl/OfflineTest.java#dubbo-plugin/dubbo-qos/src/test/java/org/apache/dubbo/qos/command/impl/OnlineTest.java#dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/RpcInvocation.java#dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/GenericImplFilter.java,5
[hotfix] Introduce TaskSlotUtils for tests,3
MISC: change project description(include quick start),4
"[FLINK-2814] [optimizer] DualInputPlanNode cannot be cast to SingleInputPlanNodeWorksetIterationNode#instantiate loops over all solution and work setcandidates. Since the solution set reference is modified in place whenthe predecessor node can be used in its place, swith this variable tothe inner loop.This closes #3563",1
"KAFKA-9287; Fix unneeded delay before failing pending transaction commit (#7799)It is possible for the user to call `commitTransaction` before a pending `AddPartitionsToTxn` call has returned. If the `AddPartitionsToTxn` call returns an abortable error, we need to cancel any pending batches in the accumulator and we need to fail the pending commit. The problem in this case is that `Sender.runOnce`, after failing the batches, enters `NetworkClient.poll` before it has a chance to cancel the commit. Since there are no pending requests at this time, this will block unnecessarily and prevent completion of the doomed commit. This patch fixes the problem by returning from `runOnce` if any batches have been aborted, which allows the commit to also fail without the delay.Note that this was the cause of the delay executing `AuthorizerIntegrationTest.testTransactionalProducerTopicAuthorizationExceptionInCommit` compared to other tests in this class. After fixing the bug, the delay is gone and the test time is similar to other test cases in the class.Reviewers:  Guozhang Wang <wangguoz@gmail.com>",3
[hotfix] Revert annotation to Internal on DataStreamQueryOperation,5
[hotfix][test] Deduplicate test case between SourceStreamTask and SourceOperatorStreamTask,1
DUBBO-71 Graceful shutdown-半关闭状态判断条件写反了git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@340 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-28195][python] Fix the build wheelsThis closes #20085.,0
[FLINK-17124][python] Fix PyFlink Job runs into infinite loop if Python UDF imports job code which is not enclosed in a `if name == 'main'` statementThis closes #11719.,2
[hotfix][tests] Add ManuallyTriggeredScheduledExecutorService#triggerAllNonPeriodicTasks,1
[FLINK-15025][python][build] Include resource directory in jar,2
Scala triangle enumeration examples behave like their Java counterparts,5
[FLINK-12961][datastream] Add internal StreamExecutionEnvironment.execute(StreamGraph),1
"KAFKA-3403: Upgrade ZkClient to 0.8This ZkClient version adds authentication validation and a conditional delete method needed for other patchesAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma, Gwen ShapiraCloses #1084 from granthenke/zkclient-08",4
"[FLINK-17537][jdbc] Refactor flink-jdbc connector structure(1) Use Jdbc instead of JDBC.(2) Move interfaces and classes to org.apache.flink.connector.jdbc.(3) Keep ancient JDBCOutputFormat, JDBCInputFormat and ParameterValuesProvider in old package.(4) Add tests/ITCase for ancient Classes and new classes.(5) rename flink-jdbc module to flink-connector-jdbc.(6) update docs.This closes #12036",2
Adjust deb package to new names and scripts,1
"Revert ""[hotfix][table-planner] Raw to Binary can fail if the user type ser/de fails""This reverts commit cbfca3afae5d33f9137ae97eb4f4c27ea0d82919.The method is not used anywhere but causes compilation errors.",0
"KAFKA-4603: Fixed the argument of shell in doc    KAFKA-4603 the argument of shell in doc wrong and command parsed error    In ""7.6.2 Migrating clusters"" of document security.html, the argument ""--zookeeper.connection"" of shell ""zookeeper-security-migrat.sh""   is wrong  and the using of OptionParser is not correct    This patch corrected the doc and changed the OptionParser constructorAuthor: auroraxlh <xin.lihua1@zte.com.cn>Reviewers: Xi Hu <huxi_2b@hotmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #2322 from auroraxlh/my-issue",0
"Added sopremo operators & tests for selection, projection, aggregation, and joins",3
[hotfix] Fix head --lines usage in test scripts--lines does not work on macOS but -n works.,1
MINOR: Remove magic number and extract Pattern instance from method as class field (#4799)* Remove magic number* Extract Pattern instance from method as class field* Add @Override declareReviewers: Randall Hauch <rhauch@gmail.com>,1
KAFKA-1253 Compression in the new producer: follow up patch to push new files,2
made ComparativeExpressionTest to a parametrisized Test to include more TestCases,3
MINOR: Fix support for custom commit ids in the build (#12014)This regressed in ca375d8004c1 due to a typo. We need testsfor our builds. :)I verified that passing the commitId via `-PcommitId=123`works correctly.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"Removed some old, outdated code",5
[FLINK-28429][python] Upgrade the version of grpcio-toolsThis closes #20685.,2
[FLINK-9287][kafka] Ensure threads count do not grow in FlinkKafkaProducer011This closes #5952.,2
"MINOR: Convert last streams join test to TTD (#7777)Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"MINOR: Add check for empty topics iterator in ReplicaVerificationTool.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Guozhang Wang, Gwen ShapiraCloses #1167 from SinghAsDev/minorFixRelicaLagTool",0
[FLINK-20342][docs] Move Plugins above File Systems,5
[hotfix] Fix wrong unit (secs vs msecs) in TaskManager logging statement.,2
MINOR: remove unused import in TopicIdWithOldInterBrokerProtocolTest (#10037)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1375 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-6193; Only delete reassign_partitions znode after reassignment is complete- Ensure that `partitionsBeingReassigned` is fully populated before`removePartitionFromReassignedPartitions` is invoked. This isnecessary to avoid premature deletion of the `reassign_partitions`znode.- Modify and add tests to verify the fixes.- Add documentation.- Use `info` log message if assignedReplicas == newReplicas andremove control flow based on exceptions.- General logging improvements.- Simplify `initializePartitionAssignment` by relying on logic alreadypresent in `maybeTriggerPartitionReassignment`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>Closes #4283 from ijuma/kafka-6193-flaky-shouldPerformMultipleReassignmentOperationsOverVariousTopics",2
Update japicmp configuration for 1.15.0,5
[FLINK-1514] [gelly] Simplified GatherUdf; added forwarded fields annotations,1
[FLINK-22835][tests] Assert latency tracking on delegated backend,3
"[FLINK-11334] Fix EnumSerializer.equals()Before, it wasn't comparing the ordering of enum values, i.e. themapping of indices to enum values.",0
"[FLINK-19779][avro] Remove the ""record_"" field name prefix for Avro format deserializationNever modify and prefix the field name, instead, we now use the {rowName}_{fieldName}as the nested row type name because Avro schema does not allow same name row typewith different schema.",1
[FLINK-6012] [table] Support SQL WindowStart and WindowEnd functions.This closes #3693.,1
MINOR: change task initialization logging levelsIn `AssignedTasks` log at debug all task ids that are yet to be initialized.In `StreamsTask` log at trace when the task is initialized.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3905 from dguy/minor-task-init-logging,5
Increased idle time until TCP connection is closed to 10 sec.,1
"[FLINK-8746] [flip6] Allow rescaling of partially running jobsThis commit enables the rescaling of Flink jobs which are currently not fullydeployed. In such a case, Flink will use the last internal rescaling savepoint.If there is no such savepoint, then it will use the provided savepoint when thejob was submitted. In case that there is no savepoint at all, then it will restartthe job with vanilla state.This closes #5560.",1
add issues template (#9036),0
[FLINK-4847] Let RpcEndpoint.start/shutDown throw exceptionsAllowing the RpcEndpoint.start/shutDown to throw exceptions will help to let rpc endpointsto quickly fail without having to use a callback like the FatalErrorHandler.This closes #2651.,0
Update version to 1.17-SNAPSHOT,5
"[FLINK-17159] Use testcontainers for Elasticsearch ITCasesThis should harden the tests because we now use random ports for the ESnodes. I have a suspicion that we had clashes before, which were causingtest instability.Additionally, this allows us to get rid of quite some of our own codefor setting up an ES environment. Once we drop ES5 we can additionallydrop ElasticsearchResource and EmbeddedElasticsearchNodeEnvironment.",4
[FLINK-17678][hbase] Add flink-sql-connector-hbase module to provide uber jar for HBase connectorThis closes #12687,1
[FLINK-7739] [tests] Remove unnecessary FlinkMiniCluster#awaitTermination calls,5
fix NetUtils.isPreferIPV6Address bug (#5238),0
修改版本号为2.1.1git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1269 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Improve shutdown sequenceAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #3030 from ijuma/improve-shutdown-sequence,1
[Dubbo] Refactoring to remove duplicate methods and feature envy. (#5506),4
Simplified state model of file buffer manager,2
Add links to README.md,2
[tests] Improve debuggability of ProcessReapingTests,3
"KAFKA-5549; Explain that 'client.id' is just used as a prefix within Streams- Added new String CLIENT_ID_DOC in StreamsConfig for explanationAuthor: Pranav Maniar <pranav9428@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3544 from PranavManiar/trunk",1
"KAFKA-13155; Fix concurrent modification in consumer shutdown (#11164)The `TransactionalMessageCopier` tool, which is used in system tests attempts to close the consumer as part of a shutdown hook. Although the access is synchronized, there is no guarantee that the consumer has finished polling when shutdown is invoked. The patch fixes the problem by call `wakeup()` from the shutdown hook and pushing the call to `close()` to the main thread.Reviewers: David Jacot <djacot@confluent.io>",5
"[FLINK-1201] [gelly] Added Push-Gather-Apply, mapVertices, subgraph, outDegreesAdded:mapVertices + Testsubgraph (Unfinished)outDegreesPush-Gather-Apply Neighborhood ModelJunit DependencyEverything is untested as we are blocked on graph creation",1
[hotfix] [core] Remove environment checks for Java 6,4
[FLINK-14857][runtime/task] deprecate StreamTask.getCheckpointLock method (#10252),1
remove the duplicate superclass of TagRouter and ConditionRouter (#2885)Remove the class ConditionRouter and TagRouter implement duplicate superclass Comparable,4
[docs] Fixes jekyll's config to bind to localhost,5
[FLINK-22974][dist] Add execution checkpointing related configs in flink-conf.yaml.,5
[FLINK-26036] Don't execute TaskExecutor.freeSlotInternal if not runningThis commit prevents the execution of TaskExecutor.freeSlotInternal if theTaskExecutor is shutting down. This will preserve the slot allocation informationwhen shutting down.This closes #18711.,5
"MINOR: Change logging level for ignored maybeAddMetric from debug to traceAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Xavier Léauté <xavier@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2454 from guozhangwang/KMinor-trace-logging-add-metrics-twice",2
[documentation] modified gh_link to support naming,1
Re added accidentally lost WordCountArrayTuples example.,1
MINOR: Extend mirror maker test to include interceptorsAuthor: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2081 from kkonstantine/MINOR-Extend-mirror-maker-test-to-include-interceptors,3
[hotfix][table-planner-blink] Store last watermark in state to emit on recovery for EventTimeProcessOperator,1
"KAFKA-8289: Fix Session Expiration and Suppression (#6654)Fix two problems in Streams:* Session windows expired prematurely (off-by-one error), since the window end is inclusive, unlike other windows* Suppress duration for sessions incorrectly waited only the grace period, but session windows aren't closed until gracePeriod + sessionGapUpdate the tests accordinglyReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
MINOR: Set MaxInlineLevel to 15 (#7811)OpenJDK has changed the default from 9 to15 in JDK 14:https://bugs.openjdk.java.net/browse/JDK-8234863https://mail.openjdk.java.net/pipermail/hotspot-compiler-dev/2019-December/036332.htmlScala applications tend to see the biggestbenefit (one of the Scala benchmarks improvedby 3x).Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
[FLINK-20267][runtime] The JaasModule didn't support symbolic links. This is fixed now.Tests were added to verify the change.This closes #14171.,4
[streaming] connectors logging and error handling fixed,0
[hotfix] Remove ScalaTestingUtils,3
[hotfix][tests] Update junit4 to junit5 in endpoint related test case,3
Fixed TLS using scheme HTTP when using TRI protocol (#8497)* Fixed TLS using scheme HTTP when using TRI protocol* change ssl config to channel attr* Reuse scheme variable & Set attr only if ssl enabled,0
[FLINK-24270][checkpoint] Refactor the tests related to the VertexFinishedStateChecker.This closes #18196.,5
"[FLINK-25830][docs]Typo mistake in ""Metric Report page"" of the documentationThis closes #18713.",2
MINOR: Upgrade to Scala 2.12.13 (#9981)Reviewers: Ismael Juma <ismael@juma.me.uk>,5
[hotfix][table-planner][tests] Remove unnecessary `throws Exception`,4
[FLINK-13634] Add compression format for use with StreamingFileSink,2
[FLINK-1619] [FLINK-1620] Grouped sliding prereducers added for Time and CountCloses #465,1
"[FLINK-22424][network] Prevent releasing PipelinedSubpartition while Task can still write to itThis bug was happening when a downstream tasks were failing over or being cancelled. If allof the downstream tasks released subpartition views, underlying memory segments/buffers couldhave been recycled, while upstream task was still writting some records.The problem is fixed by adding the writer (result partition) itself as one more referencecounted user of the result partition",1
[FLINK-19286][runtime] Replace java streams on critical paths with normal for-loop,2
"MINOR: Adds KRaft versions of most streams system tests (#12458)Migrates Streams sustem tests to either use kraft brokers or to use both kraft and zk in a testing matrix.This skips tests which use various forms of Kafka versioning since those seem to have issues with KRaft at the moment. Running these tests with KRaft will require a followup PR.Reviewers: Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",1
[scala] Introduces trait type to TypeAnalyzer which avoids compiler warnings due to misclassification as a pojo type,2
Small fix to get test to run under windows,1
[FLINK-4012] [docs] Fix link to Iterations in Basic Concepts page,2
[FLINK-20534] Add Flink 1.12 MigrationVersionThis closes #14956.,2
[hotfix][docs] Correct method name in KeyedStateReaderFunction exampleThis closes #9520,1
[FLINK-22169][sql-client] Improve CliTableauResultView when printing batch results (#15603),1
[FLINK-14543][table] Support partition for temporary table,1
MINOR: Fix QueryResult Javadocs (#12404)Fixes the QueryResult javadocs.Reviewer: Bruno Cadonna <cadonna@apache.org>,1
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1430 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-15684][docs] Add taskmanager.memory.flink.size to common optionsThis closes #10916,2
[FLINK-2080] Document how to use Flink with sbtCloses #787,2
Reactivated GlobalSortingITCase,5
[3.0] Seperate RpcContext to client and server (#7556),5
[FLINK-17822][MemMan] Use private Reference.tryHandlePending|waitForReferenceProcessing to trigger GC cleanerThis closes #12270.,4
documented interfaces of serialization package,2
"[FLINK-28122][docs-zh] Translate ""Overview"" and ""Project Configuration"" in ""User-defined Sources & Sinks"" page into Chinese",1
[FLINK-11265][docs] AvroSinkWriter → AvroKeyValueSinkWriter,2
[FLINK-23967][tests] Remove Scala references in OneInputStreamTaskTest,3
"[hotfix] [build] Fix broken project references to 'flink-shaded-curator-recipes'.The project 'flink-shaded-curator-recipes' was renamed to 'flink-shaded-curator',but some references were not properly updated. This fixes the remaining references.",5
Fix typo (#3293),2
[hotfix][tests] Add 60s timeout to UnalingCheckpointITCase,1
"[FLINK-4836] [cluster management] Add flink mini cluster (part 1)This implements  - mini cluster configuration  - startup / shutdown of common services (rpc, ha)  - startup / shutdown of JobManager and Dispatcher",5
[FLINK-19959][table-planner-blink] Multiple input creation algorithm now considers related inputs when deducing input priorities,1
"[FLINK-4154] [core] Correction of murmur hash breaks backwards compatibilityRevert ""[FLINK-3623] [runtime] Adjust MurmurHash Algorithm""This reverts commit 641a0d436c9b7a34ff33ceb370cf29962cac4dee.This closes #2223",4
[FLINK-19178][core] Extend Transformation for various managed memory use cases.,1
[FLINK-28152][sql-gateway][hive] Support GetOperationStatus and GetResultSetMetadata for HiveServer2Endpoint,5
KAFKA-4038; Transient failure in DeleteTopicsRequestTest.testErrorDeleteTopicRequestsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1737 from granthenke/transient-delete,4
更新parent的版本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1933 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: remove unused log field from KStreamTransformValuesProcessorremove unused log field from KStreamTransformValuesProcessorAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2717 from dguy/remove-unused-log-para,4
"KAFKA-10199: Add PAUSE in state updater (#12386)* Add pause action to task-updater.* When removing a task, also check in the paused tasks in addition to removed tasks.* Also I realized we do not check if tasks with the same id are added, so I add that check in this PR as well.Reviewers: Bruno Cadonna <cadonna@apache.org>",1
"KAFKA-13835: Fix two bugs related to dynamic broker configs in KRaft (#12063)Fix two bugs related to dynamic broker configs in KRaft. The first bug is that we are calling reloadUpdatedFilesWithoutConfigChange when a topic configuration is changed, but not when abroker configuration is changed. This is backwards. This function must be called only for broker configs, and never for topic configs or cluster configs.The second bug is that there were several configurations such as max.connections which are relatedto broker listeners, but which do not involve changing the registered listeners. We should supportthese configurations in KRaft. This PR fixes the configuration change validation to support this case.Reviewers: Jason Gustafson <jason@confluent.io>, Matthew de Detrich <mdedetrich@gmail.com>",5
improve performance (#9931),1
[FLINK-24912][state-processor-api] Update documentation for DataStream based APICo-authored-by: Jun Qin <11677043+qinjunjerry@users.noreply.github.com>This closes #18170,1
KAFKA-8611: Refactor KStreamRepartitionIntegrationTest (#8470)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
Added file missing from last commit,2
Introduced hybrid event model,5
"KAFKA-13015: Ducktape System Tests for Metadata Snapshots (#11053)This PR implements system tests in ducktape to test the ability of brokers and controllers to generateand consume snapshots and catch up with the metadata log.Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",2
"MINOR: implement BrokerRegistrationChangeRecord (#12195)Implement BrokerRegistrationChangeRecord as specified in KIP-746. This is a more flexible record than thesingle-purpose Fence / Unfence records.Reviewers: José Armando García Sancio <jsancio@gmail.com>, dengziming <dengziming1993@gmail.com>",4
system test configs are broken; patched by John Fung; reviewed by Jun Rao; kafka-586git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1404203 13f79535-47bb-0310-9956-ffa450edef68,5
"[FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput.The demultiplexing works in two dimensions for the following cases.* Subtasks of the current operator have been collapsed in a round-robin fashion.* The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly relevant to keyed exchanges).In both cases, records from multiple old channels are received over one new physical channel, which need to demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).For performance reasons, the virtual demultiplexing logic is implemented separately from StreamTaskNetworkInput, such that on after recovery, the network input is replaced with the non-recovery counter-part in all StreamInputProcessors.",1
fix probe extensions (#9643),0
reverting previous commit for KAFKA-296 because patch didn't apply cleanlygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1300801 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix][python][tests] Refactor the test cases in DataStreamTests to reduce the number of itcases,5
[FLINK-11316][tests] Refactor ClassLoaderUtilsTests#createValidJar(File)This closes #7486.,3
"[FLINK-6353] Fix legacy user-state restore from 1.2State that was checkpointed using Checkpointed (on a user function)could be restored using CheckpointedRestoring when the savepoint wasdone on Flink 1.2. The reason was an overzealous check inAbstractUdfStreamOperator that only restores from ""legacy"" operatorstate using CheckpointedRestoring when the stream is a Migration stream.This removes that check but we still need to make sure to read away thebyte that indicates whether there is legacy state, which is written whenwe're restoring from a Flink 1.1 savepoint.After this fix, the procedure for a user to migrate a user function awayfrom the Checkpointed interface is this: - Perform savepoint with user function still implementing Checkpointed,   shutdown job - Change user function to implement CheckpointedRestoring - Restore from previous savepoint, user function has to somehow move   the state that is restored using CheckpointedRestoring to another   type of state, .e.g operator state, using the OperatorStateStore. - Perform another savepoint, shutdown job - Remove CheckpointedRestoring interface from user function - Restore from the second savepoint - Done.If the CheckpointedRestoring interface is not removed as prescribed inthe last steps then a future restore of a new savepoint will failbecause Flink will try to read legacy operator state that is not thereanymore.  The above steps also apply to Flink 1.3, when a user want's tomove away from the Checkpointed interface.",4
[FLINK-4928] [yarn] Implement FLIP-6 YARN Application Master Runner,1
"KAFKA-8803: Remove timestamp check in completeTransitionTo (#8278)In prepareAddPartitions the txnStartTimestamp could be updated as updateTimestamp, which is assumed to be always larger then the original startTimestamp. However, due to ntp time shift the timer may go backwards and hence the newStartTimestamp be smaller than the original one. Then later in completeTransitionTo the time check would fail with an IllegalStateException, and the txn would not transit to Ongoing.An indirect result of this, is that this txn would NEVER be expired anymore because only Ongoing ones would be checked for expiration.We should do the same as in #3286 to remove this check.Also added test coverage for both KAFKA-5415 and KAFKA-8803.Reviewers: Jason Gustafson<jason@confluent.io>",5
"KAFKA-12579: Remove various deprecated clients classes/methods for 3.0 (#10438)* Remove `ExtendedSerializer` and `ExtendedDeserializer`, deprecated since 2.1.The extra functionality was also made available in `Serializer` and `Deserializer`.* Remove `close(long, TimeUnit)` from the producer, consumer and admin client,deprecated since 2.0 for the consumer and 2.2 for the rest. The replacement is `close(Duration)`.* Remove `ConsumerConfig.addDeserializerToConfig` and `ProducerConfig.addSerializerToConfig`,deprecated since 2.7 with no replacement. These methods were not intended to be public APIand are likely not used much (if at all).* Remove `NoOffsetForPartitionException.partition()`, deprecated since 0.11. `partitions()`should be used instead.* Remove `MessageFormatter.init(Properties)`, deprecated since 2.7. The `configure(Map)`method should be used instead.* Remove `kafka.common.MessageFormatter`, deprecated since 2.7.`org.apache.kafka.common.MessageFormatter` should be used instead.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
[FLINK-1372] [runtime] Adds EnvironmentInformation.logEnvironmentInfo method calls to JobManager's and TaskManager's main methods.This closes #329.,5
[FLINK-26780][tests] Force RPC serialization,1
[FLINK-10912][rocksdb] Configurable RocksDBStateBackend optionsThis closes #7586.,5
KAFKA-765 Corrupted messages in produce request could shutdown the broker; reviewed by Jun Rao and Sriram Subramanian,5
"KAFKA-13056; Do not rely on broker for snapshots if controller is co-resident (#11013)When a node is serving as both broker and controller, we should only rely on the controller to write new snapshots.Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",1
"KAFKA-7433; Introduce broker options in TopicCommand to use AdminClient (KIP-377)The PR adds --bootstrap-server and --admin.config options to TopicCommand and implements an alternative, AdminClient based way of topic management.As testing I've duplicated the existing tests and made them working with the AdminClient options.Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>Reviewers: Andras Katona <41361962+akatona84@users.noreply.github.com>, Sandor Murakozi <smurakozi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #5683 from viktorsomogyi/topiccommand-adminclient",5
[FLINK-17869][task][checkpointing] Abort writing of channel state by RPCnotification,2
"KAFKA-9974: Fix flaky test by removing unneeded asserts (#8646)The tests failed at assertThat(listener.startOffset, is(equalTo(0L)));. It looks like that it did a restore before the assert. But we should expect the restore sometimes happen to resume the failed tasks by itself. It should not cause the test failure under this situation.On the other hands, the original tests added the assertThat(listener.startOffset, is(equalTo(0L))); is because in the end of the test, we'll also test the startOffset value. But in the newer version of the test, we don't really care about the startOffset or totalNumRestored value. All we want to test in this test is:Assert that the current value in store reflects all messages being processedSo, removing the assert can avoid flaky test failure, and also be able to test what the test case want to test.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-25445] No need to create local recovery dirs when disabled local-recovery in TaskExecutorLocalStateStoresManager,3
[hotfix] Replace deprecated Assert.assertThat in LocalInputPreferredSlotSharingStrategyTest,3
"MINOR: ducker-ak: add down -f, avoid using a terminal in ducker testWhen using ./ducker-ak test on Jenkins, the script complains that there is no TTY.  To fix this, we should skip passing -t to docker exec.  We do not need a pseudo-TTY to run the tests.  Similarly, we should skip passing -i, since we do not need to keep stdin open.The down command should have a force option, specified as -f or --force.Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",1
KAFKA-7352; Allow SASL Connections to Periodically Re-Authenticate (KIP-368) (#5582)KIP-368 implementation to enable periodic re-authentication of SASL clients. Also adds a broker configuration option to terminate client connections that do not re-authenticate within the configured interval.,5
DUBBO-245 将Invocation的getUrl改成getInvokergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1113 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-25249][connector/kafka] Reimplement KafkaTestEnvironment with KafkaContainer,3
[FLINK-17586][python] Use the real StreamExecutionEnvironment contained in DummyStreamExecutionEnvironment when translating the Python UDF physical nodes to operators. (#12048),1
[hotfix][runtime] Adds write method for consistency reasons,1
The FetcherRunnable busy waits on empty fetch requests; KAFKA-117; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160952 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-18765][python] Support map() and flat_map() for Python DataStream API. (#13066),5
[FLINK-23143][state/changelog] Support state migration for ChangelogStateBackend,4
Merge branch 'merge-3.x' into master-merged-performance-2.7# Conflicts:#dubbo-dependencies-bom/pom.xml#dubbo-dependencies/dubbo-dependencies-zookeeper/pom.xml#pom.xml,5
[FLINK-16935][table-planner-blink] Enable or delete most of the ignored test cases in blink planner.This closes #11874,2
Optimize code in ServiceConfig.doExportUrlsFor1Protocol. (#8262)Co-authored-by: Annoyer <247221925@qq.com>,5
Added grouping operator of DAP algorithm.,1
[FLINK-27924][python][docs] Include pulsar in the list of supported connectors in DataStream (#19887),5
[FLINK-17096][core] Simple performance improvements in WatermarkOutputMultiplexer,1
"KAFKA-8225 & KIP-345 part-2: fencing static member instances with conflicting group.instance.id (#6650)For static members join/rejoin, we encode the current timestamp in the new member.id. The format looks like group.instance.id-timestamp.During consumer/broker interaction logic (Join, Sync, Heartbeat, Commit), we shall check the whether group.instance.id is known on group. If yes, we shall match the member.id stored on static membership map with the request member.id. If mismatching, this indicates a conflict consumer has used same group.instance.id, and it will receive a fatal exception to shut down.Right now the only missing part is the system test. Will work on it offline while getting the major logic changes reviewed.Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-24480][table-planner] Do not discard exception in testThis closes #17469,3
[3.0-Triple] Fix missing response and duplicate trailers (#9140)* Fix missing response and duplicate trailers* Some minor fix,0
Fixed flaw in unit test for GateDeploymentDescriptor class,3
[FLINK-18010][runtime] Expand HistoryServer logging,2
[FLINK-2357] [web dashboard] Add subtasks to vertex display,1
KAFKA-13557: Remove swapResult from the public API (#11617)Follow-on from #11582 .Removes a public API method in favor of an internal utility method.Reviewer: Matthias J. Sax <mjsax@apache.org>,4
"KAFKA-5329; Fix order of replica list in metadata cacheAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jun Rao <junrao@gmail.com>Closes #3257 from ijuma/kafka-5329-fix-order-of-replica-list-in-metadata-cache",5
"[FLINK-5940] [checkpoint] Harden ZooKeeperCompletedCheckpointStore.recover methodThe ZooKeeperCompletedCheckpointStore only tries to recover the latest completedcheckpoint even though it might have read older checkpoint state handles fromZooKeeper. In order to deal with corrupted state handles, this commit changes thebehaviour such that the completed checkpoint store adds all read retrievablestate handles from ZooKeeper and upon request of the latest checkpoint it willreturn the latest completed checkpoint which could be retrieved from the statehandles. Broken state handles are removed from the completed checkpoint store andZooKeeper.This closes 3446.",4
[hotfix][tests] Expose full heartbeat payload,3
MINOR: Update consumer group describe output in the documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2409 from vahidhashemian/doc/update_consumer_group_describe_output,5
[FLINK-22335][runtime][config] Increase default resource wait timeout for the adaptive scheduler.This closes #15657,1
[FLINK-2324] [streaming] Partitioned state checkpointing rework + test update,5
[FLINK-4450] [storm compat] Update storm version to 1.0This closes #3037,5
[hotfix][task] Rename isStoppingBySyncSavepoint to ignoreEndOfInput,0
[FLINK-26042][python][doc] Raise exception when python version does not meet requirements.This closes #18894.,1
Fix stub proxy does not work cause of ProxyFactory.getProxy change (#5838)fix #5836,0
"[FLINK-23812][rocksdb] support configuring RocksDB logging (#16848)This allows further tuning RocksDB's info logger with the following three new parameters:- `state.backend.rocksdb.log.max-file-size` sets the max info log file size- `state.backend.rocksdb.log.file-num` configures the number of info log files to keep- `state.backend.rocksdb.log.dir` sets the directory of the info log files, e.g. to put these logs onto a (separate) volume that may not be local and is retained after container shutdown for debugging purposes",0
"KAFKA-4786; Wait for heartbeat thread to terminate in consumer closeAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>Closes #2586 from rajinisivaram/KAFKA-4786",5
[FLINK-18176][document] Add supplement for file system connector documentThis closes #12522,2
Added diagnostic trace for input split opener timeout.,1
[hotfix][docs] Fix typos in  Scala Table-DataStream API docs,2
[FLINK-17977][core] Silence type extractor warnings for built-in Row,2
"[FLINK-25992][Runtime/Coordination, Tests] For stability, wait until the latest restored checkpoint is not null to avoid race condition",3
"[FLINK-21403][tests] Adjust MiniClusterITCaseReduce the number of slots for the test to 0, and set RESOURCE_WAIT_TIMEOUT to let the test pass with the adaptive scheduler.",4
KAFKA-776 Changing ZK format breaks some tools; reviewed by Neha Narkhede,4
[FLINK-17728] [sql-client] sql client supports parser statements via sql parserThis closes #12188,1
Fix bug where a non-iterative data set is not fully consumed.,1
[hotfix][table] Removed unnecessary casts in ApiExpressionUtils,4
[FLINK-16967][metrics][slf4j] Add Slf4jReporterFactory,1
"KAFKA-2706: make state stores first class citizens in the processor topology* Added StateStoreSupplier* StateStore  * Added init(ProcessorContext context) method* TopologyBuilder  * Added addStateStore(StateStoreSupplier supplier, String... processNames)  * Added connectProessorAndStateStores(String processorName, String... stateStoreNames)    * This is for the case processors are not created when a store is added to the topology. (used by KStream)* KStream  * add stateStoreNames to process(), transform(), transformValues().* Refactored existing state stores to implement StateStoreSupplierguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #387 from ymatsuda/state_store_supplier",5
"[FLINK-14818][benchmark] Fix InputGate setup logic of StreamNetworkBenchmarkEnvironmentBefore this change, in network benchmark (for example 1000 channels benchmark with 4 record writers) StreamNetworkBenchmarkEnvironment#createInputGate was creating 1000 input gates with 4 input channels each, which doesn't make much sense. This commit is changing that to a single receiver with 4 input gates and each with 1000 channels.It is achieved by providing testing implementations of InputChannels, which are using channel index for requesting subpartitions from ResultPartition, instead of subpartition index. Thanks to that, we can map a single ResultPartition with N subpartitions, to a single instance of InputGate with N channels.The change also influences the benchmark results, overall, the performance goes down a bit because of the decrease of floating buffers and the followings are benchmark results before and after this change:------------------------------------------------------------------Before----------------------------------------------------------------------Benchmark                                                                     (channelsFlushTimeout)   Mode  Cnt      Score      Error   UnitsDataSkewStreamNetworkThroughputBenchmarkExecutor.networkSkewedThroughput                         N/A  thrpt   30  17079.534 ±  830.532  ops/msStreamNetworkBroadcastThroughputBenchmarkExecutor.networkBroadcastThroughput                     N/A  thrpt   30    599.664 ±   13.325  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                 100,100ms  thrpt   30  45629.898 ± 1623.455  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                             100,100ms,SSL  thrpt   30   9817.421 ±  216.075  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                  1000,1ms  thrpt   30  25442.152 ±  968.340  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                1000,100ms  thrpt   30  27944.285 ±  518.106  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                            1000,100ms,SSL  thrpt   30   7820.549 ±  895.862  ops/msStreamNetworkLatencyBenchmarkExecutor.networkLatency1to1                                         N/A   avgt   30     13.184 ±    0.093   ms/op------------------------------------------------------------------After-----------------------------------------------------------------------Benchmark                                                                     (channelsFlushTimeout)   Mode  Cnt      Score      Error   UnitsDataSkewStreamNetworkThroughputBenchmarkExecutor.networkSkewedThroughput                         N/A  thrpt   30  17345.574 ±  370.647  ops/msStreamNetworkBroadcastThroughputBenchmarkExecutor.networkBroadcastThroughput                     N/A  thrpt   30    608.881 ±   12.054  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                 100,100ms  thrpt   30  41732.518 ± 1109.436  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                             100,100ms,SSL  thrpt   30   9689.525 ±  202.895  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                  1000,1ms  thrpt   30  24106.705 ± 2952.364  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                                1000,100ms  thrpt   30  27509.665 ± 3246.965  ops/msStreamNetworkThroughputBenchmarkExecutor.networkThroughput                            1000,100ms,SSL  thrpt   30   7691.287 ±  927.775  ops/msStreamNetworkLatencyBenchmarkExecutor.networkLatency1to1                                         N/A   avgt   30     12.758 ±    0.147   ms/op",1
[FLINK-24586][table-planner] JSON_VALUE should return STRING instead of VARCHAR(2000)This closes #19014.,5
[hotfix] Allow leader assignment to TestingLeaderElectionService if it has not been started,3
KAFKA-1257 Only send metadata requests to nodes with no in-flight requests.,5
"KIP-421: Support for resolving externalized secrets in AbstractConfig (#6467)Updated AbstractConfig to be able to resolve variables in config values when the configuration includes config provider properties.Author: Tejal Adsul <tejal@confluent.io>Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
KAFKA-6144: IQ option to query standbys (#7962)Add a new overload of KafkaStreams#store that allows usersto query standby and restoring stores in addition to active ones.Closes: #7962Implements: KIP-535Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>Reviewed-by: John Roesler <vvcephei@apache.org>,1
Added first version of Scala example jobs for triangle enumeration,1
[FLINK-25036][runtime] Introduce vertex wise scheduling strategyThis closes #18126.,2
MINOR: Ensure a single version of scala-library is used (#9155)This patch ensures we use a force resolution strategy for the scala-library dependency.I've tested this locally and saw a difference in the output.With the change (using 2.4 and the jackson library 2.10.5):```./core/build/dependant-libs-2.12.10/scala-java8-compat_2.12-0.9.0.jar./core/build/dependant-libs-2.12.10/scala-collection-compat_2.12-2.1.2.jar./core/build/dependant-libs-2.12.10/scala-reflect-2.12.10.jar./core/build/dependant-libs-2.12.10/scala-logging_2.12-3.9.2.jar./core/build/dependant-libs-2.12.10/scala-library-2.12.10.jar```Without (using 2.4 and the jackson library 2.10.5):``` find . -name 'scala*.jar'./core/build/dependant-libs-2.12.10/scala-java8-compat_2.12-0.9.0.jar./core/build/dependant-libs-2.12.10/scala-collection-compat_2.12-2.1.2.jar./core/build/dependant-libs-2.12.10/scala-reflect-2.12.10.jar./core/build/dependant-libs-2.12.10/scala-logging_2.12-3.9.2.jar./core/build/dependant-libs-2.12.10/scala-library-2.12.12.jar```Reviewers: Ismael Juma <ismael@juma.me.uk>,2
[FLINK-10149][mesos] Don't allocate extra mesos port for TM unless configured to do so.This closes #7203.,5
KAFKA-5822; Consistent log formatting of topic partitionsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3778 from hachikuji/KAFKA-5822,5
"KAFKA-13852: Kafka Acl documentation bug for wildcard '*' (#12090)The wildcard * in command without wrapped by single quote will be replaced into the file name under the current folder by bash. So we need to wrap with single quote. Update the doc and command option description.Reviewers: dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>",2
修改配置空指针git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@144 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-22312][yarn][test] Fix test instabilities due to expected heartbeat exceptions in logThis closes #16127,2
Minor consistency fix in the pom files.,2
"KAFKA-7584: StreamsConfig throws ClassCastException if max.in.flight.request.per.connect is specified as String (#5874)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-5493] Fix String formats in FlinkDistributionOverlay and TaskThis closes #3010.,2
[streaming] comments on examples,5
Simplify code with Lambda (#4834)Simplify code with Lambda,5
[hotfix][tests] Consolidate the instantiation of the RocksDBKEyesStateBackendBuilder for tests in a utility class.,3
[hotfix][tests] Remove unnecessary temp directory handlingRemove the use of a non-needed temp directory and relies on JUnit tool rather than manual cleanup.,4
[FLINK-13774][table-planner-blink] Supports decimal with different precision for IF PlannerExpression,1
"KAFKA-10768 Make ByteBufferInputStream.read(byte[], int, int) to follow the contract (#9761)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-13858; Kraft should not shutdown metadata listener until controller shutdown is finished (#12187)When the kraft broker begins controlled shutdown, it immediately disables the metadata listener. This means that metadata changes as part of the controlled shutdown do not get sent to the respective components. For partitions that the broker is follower of, that is what we want. It prevents the follower from being able to rejoin the ISR while still shutting down. But for partitions that the broker is leading, it means the leader will remain active until controlled shutdown finishes and the socket server is stopped. That delay can be as much as 5 seconds and probably even worse.This PR revises the controlled shutdown procedure as follow:* The broker signals to the replica manager that it is about to start the controlled shutdown.* The broker requests a controlled shutdown to the controller.* The controller moves leaders off from the broker, removes the broker from any ISR that it is a member of, and writes those changes to the metadata log.* When the broker receives a partition metadata change, it looks if it is in the ISR. If it is, it updates the partition as usual. If it is not or if there is no leader defined--as would be the case if the broker was the last member of the ISR--it stops the fetcher/replica. This basically stops all the partitions for which the broker was part of their ISR.When the broker is a replica of a partition but it is not in the ISR, the controller does not do anything. The leader epoch is not bumped. In this particular case, the follower will continue to run until the replica manager shuts down. In this time, the replica could become in-sync and the leader could try to bring it back to the ISR. This remaining issue will be addressed separately.Reviewers: Jason Gustafson <jason@confluent.io>",5
[FLINK-9916] Add FROM_BASE64 function for table/sql APIThis closes #6397.,1
"KAFKA-13940; Return NOT_LEADER_OR_FOLLOWER if DescribeQuorum sent to non-leader (#12517)Currently the server will return `INVALID_REQUEST` if a `DescribeQuorum` request is sent to a node that is not the current leader. In addition to being inconsistent with all of the other leader APIs in the raft layer, this error is treated as fatal by both the forwarding manager and the admin client. Instead, we should return `NOT_LEADER_OR_FOLLOWER` as we do with the other APIs. This error is retriable and we can rely on the admin client to retry it after seeing this error.Reviewers: David Jacot <djacot@confluent.io>",5
[hotfix] Fix checkstyle violations in TaskExecutorPartitionLifecycleTest,3
[FLINK-15999][doc] Add reference to windowing and ProcessFunction doc in event_time.mdAlso fix section formatting.,0
[hotfix] Add null checks in StateAssignmentOperation,1
- fixed PactProgram constructor (bug reported by Thomas Bodner),0
"KAFKA-5431; cleanSegments should not set length for cleanable segment filesFor a compacted topic with preallocate enabled, during log cleaning, LogCleaner.cleanSegments does not have to pre-allocate the underlying file size since we only want to store the cleaned data in the file.It's believed that this fix should also solve KAFKA-5582.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #3525 from huxihx/log_compact_test",3
MINOR: Add maybeThrow method to ZooKeeperClient AsyncResponse* Add maybeThrow method to AsyncResponse* Update KafkaZkClient to use newly introduced maybeThrow* Change AsyncResponse from trait to abstract class formore readable stacktraces (there's no benefit in using atrait here)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4266 from omkreddy/KAFKAZKCLEINT_EXCEPTION_CLEANUP,4
[FLINK-20437][table-planner-blink] Move the utility methods in ExecNode into ExecNodeUtil,4
[FLINK-14901] Throw Error in MemoryUtils if there is problem with using system classes over reflection,5
HOTFIX: Added another broker to smoke testAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2362 from enothereska/hotfix-smoke-test-2-brokers,3
[hotfix] [tests] Add a lightweight test for classloading in the Kryo Serializer,3
"KAFKA-4033; Revise partition assignment semantics on consumer subscription changes (KIP-70)This PR changes topic subscription semantics so a change in subscription does not immediately cause a rebalance.Instead, the next poll or the next scheduled metadata refresh will update the assigned partitions.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Jason GustafsonCloses #1726 from vahidhashemian/KAFKA-4033",5
[hotfix][hive] resolve bad merge in HiveTableSinkTestResolve bad merge between #8965 and #8987 though they passed CI separately.,4
[FLINK-12814][sql-client] Support a traditional and scrolling view of result (tableau format)This closes #11273,1
[FLINK-15233][kafka] Improve Kafka connector properties to make append update-mode as defaultThis closes #10584,5
[FLINK-12234][hive] Support view related operations in HiveCatalogThis PR supports view related operations in HiveCatalog and creates HiveCatalogView.This closes #8434.,2
[docs] Update README and internals (scheduling) for graduation and fix broken links,2
KAFKA-1009 DumpLogSegments tool should return error on non-existing files; reviewed by Neha Narkhede,2
[FLINK-4245] JMXReporter exposes all defined variablesThis closes #2418.,2
[Dubbo-#1362] cache provider always lru cache (#1396)* #1362修复#1362修复* #1362修复#1362修复* #1362修复#1362修复* 修改bug修改bug* 修改bug修改bug* 添加cache的测试用例添加cache的测试用例,0
wrong event setting (#3043)* wrong event setting* modify event seeting* modify,1
[hotfix] Fix type in ProcessFunction documentation,2
[FLINK-10877] Cleanup flink-connector-kafka pom fileRemove duplicate flink-connector-kafka-base test dependencies and exclusions.,3
MINOR: Update TupleForwarder comment (#4414)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
[FLINK-2808] [streaming] Refactor and extend state backend abstraction,4
[hotfix][table-common] Introduce forceNullable as a type strategy,1
[FLINK-4835] [cluster management] Add embedded version of the high-availability servicesThis includes the addition of the EmbeddedLeaderServiceand a clean shutdown hook for all high availability services.,1
"[FLINK-2769] [runtime-web] Add configurable job manager address to HTTP requestsThis was removed in 3b8b4f0f8c0600dc851d676ce1bd7f5ab81cb64f. Theissue was fixed by this, but it disabled local testing as well.This change re-introduces the variable and sets it to the emptystring by default. This way, we can still use the proxy server forlocal testing.This closes #1449",3
[FLINK-14960][e2e] Fix failed dependency shading test of table modules,3
Provider输出日志便于排错 DUBBO-146 调用的返回值在Provider端序列化失败，Provider端也没有异常输出，Consumer端超时出错git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@714 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Upgrade gradle plugins and test libraries for Java 14 support (#8519)Also:* Remove deprecated `=` in resolutionStrategy.* Replace `AES/GCM/PKCS5Padding` with `AES/GCM/NoPadding`in `PasswordEncoderTest`. The former is invalid and JDK 14 rejects it,see https://bugs.openjdk.java.net/browse/JDK-8229043.With these changes, the build works with Java 14 and Scala 2.12. Thesame will apply to Scala 2.13 when Scala 2.13.2 is released (shouldhappen within 1-2 weeks).Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
Added guava dependency to nephele job and taskmanager startup scripts,1
[FLINK-17005][docs-zh] Translate the CREATE TABLE ... LIKE syntax documentation to ChineseThis closes #12313,1
[FLINK-2906] Remove Record APIThis closes #1403,4
DUBBO-365 ValidationFilter在generic调用时会出错git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1681 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-16357][checkpointing] Only global failure/restores reset the coordinator state.The failure handling results are now flagged with whether the failure was a global failureor a task failure. Based on that, the Scheduler invokes different restore methods on theCheckpointCoordinator.",0
"KAFKA-12648: fix IllegalStateException in ClientState after removing topologies (#11591)Fix for one of the causes of failure in the NamedTopologyIntegrationTest: org.apache.kafka.streams.errors.StreamsException: java.lang.IllegalStateException: Must initialize prevActiveTasks from ownedPartitions before initializing remaining tasks.This exception could occur if a member sent in a subscription where all of its ownedPartitions were from a named topology that is no longer recognized by the group leader, eg because it was just removed from the client. We should filter each ClientState based on the current topology only so the assignor only processes the partitions/tasks it can identify. The member with the out-of-date tasks will eventually clean them up when the #removeNamedTopology API is invoked on themReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
Continued multicast implementation,5
add logback container,2
Added test for multilevel hash function,1
MINOR: Improve instructions for running system tests with dockerAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3649 from enothereska/minor-docker-docs,2
[FLINK-23473][runtime] Do not create transaction in TwoPhaseCommitSinkFunction after finish (#16768),5
"KAFKA-9770: Close underlying state store also when flush throws (#8368)When a caching state store is closed it calls its flush() method.If flush() throws an exception the underlying state store is not closed.This commit ensures that state stores underlying a wrapped state storesare closed even when preceding operations in the close method throw.Co-authored-by: John Roesler <vvcephei@apache.org>Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",5
[docs] fix broken links in FAQ,2
[FLINK-13266][table-runtime-blink] remove Order class from table-runtime-blink,2
"Merge pull request #1843, support implicit delivery of attachments from provider to consumer.Fixes #889, #1466, #1834, #1466, #1524",0
"KAFKA-9756: Process more than one record of one task at a time (#8358)1. Within a single while loop, process the tasks in AAABBBCCC instead of ABCABCABC. This also helps the follow-up PR to time the per-task processing ratio to record less time, hence less overhead.2. Add thread-level process / punctuate / poll / commit ratio metrics.3. Fixed a few issues discovered (inline commented).Reviewers: John Roesler <vvcephei@apache.org>",0
[FLINK-9546] Fix checking of heartbeatTimeoutIntervalMs in HeartbeatMonitorThis closes #6135.,0
fix #8244 getServiceKey throw npe. (#8265),1
[FLINK-3225] Implemented optimization of Table API queries via Calcite- added logical Flink nodes and translation rules- added stubs for DataSet translation rules- ported DataSetNodes to Scala- reactivated tests and added expected NotImplementedError,0
Fixed bug in checkpoint removal method,4
[FLINK-7568] Add note about 'key' parameter to window doc,2
[FLINK-28771][runtime] Assign speculative execution attempt with correct CREATED timestampThis closes #20411.,1
[FLINK-5508] [mesos] Introduce ZooKeeperUtilityFactory to create ZooKeeper utility classesThis commit adds utility classes to abstract the CuratorFramework dependency from ZooKeeperutility classes away. That way it is possible for modules outside of flink-runtime to usethese utility classes without facing the problem of a relocated curator dependency.Address PR commentsThis closes #3157.,1
[FLINK-5941] Integrate Archiver pattern into handlersThis closes #3444.,0
[hotfix][checkpointing] Log checkpoint ID from notification,2
"KAFKA-2660; Correct cleanableRatio calculationonurkaraman Could you have a look? This is the patch I discussed with you.Author: Dong Lin <lindong28@gmail.com>Author: Dong Lin <lindong@cis.upenn.edu>Reviewers: Onur Karaman <okaraman@linkedin.com>, Joel Koshy <jjkoshy@gmail.com>, Jun Rao <junrao@gmail.com>Closes #316 from lindong28/KAFKA-2660",2
"[FLIN-20342][docs] Split up jobmanager_high_availability.md into ha/index.md, ha/kubernets_ha.md and ha/zookeeper_ha.md",2
"[FLINK-22613][tests] Fix FlinkKinesisITCase.testStopWithSavepoint.The test relies on a few elements remaining pending after stop-with-savepoint, however that can only be guaranteed heuristically: We cannot block task thread or else the respective savepoint will not succeed but we also cannot add infinite input as it's an IT test against Kinesis. Here, the fix is to add much more elements to Kinesis stream. An optimized sendMessage on the test client ensures timely setup.",1
[FLINK-1354] Made test graph for TransitiveClosureITCase smallerThis closes #285,3
"MINOR: Handle segment splitting edge cases and fix recovery bug  (#5169)This patch fixes the following issues in the log splitting logic added to address KAFKA-6264:1. We were not handling the case when all messages in the segment overflowed the index. In this case, there is only one resulting segment following the split.2. There was an off-by-one error in the recovery logic when completing a swap operation which caused an unintended segment deletion.Additionally, this patch factors out of `splitOverflowedSegment` a method to write to a segment using from with an instance of `FileRecords`. This allows for future reuse and isolated testing.Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",5
[FLINK-9707] Support concurrent directory creations in LocalFileSystemSupport concurrent directory creations by accepting directories which have beencreated by a different thread/process in LocalFileSystem#mkdirs.This closes #6243.,5
[hotfix] Remove unused code in JarActionHandler,0
"[FLINK-18391][docs-zh] Translate ""Avro Format"" page into ChineseThis closes #12796",1
[FLINK-20022][docs] Move statebackend tradeoffs out of checklistThis closes #13960.,4
"[FLINK-8656] [flip6] Add modify CLI command to rescale Flink jobsJobs can now be rescaled by calling flink modify <JOB_ID> -p <PARALLELISM>.Internally, the CliFrontend will send the corresponding REST call and pollfor status updates.This closes #5487.",5
修改javadoc插件git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@818 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-4899; Fix findbugs warnings in kafka-coreAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Jozef Koval <jozef.koval@protonmail.ch>, Ismael Juma <ismael@juma.me.uk>Closes #2687 from cmccabe/KAFKA-4899",5
DUBBO-170支持直接配置return值进行Mockgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@809 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fixes broken code highlighting in documentation,2
[FLINK-5928] [checkpoints] Add CheckpointCoordinatorExternalizedCheckpointsTestProblem: there were only unit tests for the checkpoint instances availablethat don't test the behaviour of the checkpoint coordinator with respectto externalized checkpoints.This closes #3424,3
[hotfix] Add deprecation message to old Key interface,1
"KAFKA-4901; Make ProduceRequest thread-safeIf request logging is enabled, `ProduceRequest` can be accessedand mutated concurrently from a network thread (which calls`toString`) and a request handler thread (which calls`clearPartitionRecords()`).That can lead to a `ConcurrentModificationException` when iteratingthe `partitionRecords` map.The underlying thread-safety issue has existed since the serverstarted using the Java implementation of ProduceRequest in 0.10.0.However, we were incorrectly not clearing the underlying struct until0.10.2, so `toString` itself was thread-safe until that change. In 0.10.2,`toString` is no longer thread-safe and we could potentially see a`NullPointerException` given the right set of interleavings between`toString` and `clearPartitionRecords` although we haven't seen thathappen yet.In trunk, we changed the requests to have a `toStruct` methodinstead of creating a struct in the constructor and `toString` wasno longer printing the contents of the `Struct`. This accidentallyfixed the race condition, but it meant that request logging was lessuseful.A couple of days ago, `AbstractRequest.toString` was changed toprint the contents of the request by calling `toStruct().toString()`and reintroduced the race condition. The impact is more visiblebecause we iterate over a `HashMap`, which proactivelychecks for concurrent modification (unlike arrays).We will need a separate PR for 0.10.2.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>Closes #2689 from ijuma/produce-request-thread-safety",2
[hotfix] [RocksDB backend] Minor cleanups to constructors and comments in RocksDBStateBackend,5
[FLINK-3330] [ml] Fix SparseVector support in GradientDescentThe GradientDescent implementation did not work with sparse input databecause it requires the gradient to be dense. This patch makes sure thatthe gradient sum is always dense.This closes #1587.,1
[FLINK-7514][tests] fix BackPressureStatsTrackerITCase releasing buffers twiceThis closes #4591.,0
Hessian2 whitelist (#6378)fixes #6364,0
[FLINK-19491][avro] Support large schema in AvroSerializerSnapshot,1
"Merge pull request #1391, fix typo of method name in qos module.",2
[FLINK-18671][docs] Update upgrade compatibility table for 1.11.0,5
"MINOR: Update dependencies for 1.0.0 releaseNotable updates:1. Gradle 4.1 includes a number of performance andCLI improvements as well as initial Java 9 support.2. Scala 2.12.3 has substantial compilation timeimprovements.3. lz4-java 1.4 allows us to remove a workaround inKafkaLZ4BlockInputStream (not done in this PR).4. snappy-java 1.1.4 improved performance of compression (5%)and decompression (20%). There was a slight increase in thecompressed size in one of our tests.Not updated:1. PowerMock due to a couple of regressions. I investigated one of themand filed https://github.com/powermock/powermock/issues/828.2. Jackson, which will be done via #3631.3. Rocksdb, which will be done via #3519.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3619 from ijuma/update-deps-for-1.0.0",5
"Rename POMs, scripts, quickstarts and other minor renames",5
[FLINK-24155][documentation] Sync Chinese version of documentation to configure CheckpointFailureManager (#17173),0
[FLINK-3761] Refactor RocksDB Backend/Make Key-Group AwareThis change makes the RocksDB backend key-group aware by building on thechanges in the previous commit.,4
[hotfix][doc] fix the usage example of datagen connector docThis closes #14060,2
[hotfix] Let TaskExecutorOperatorEventHandlingTest extend TestLogger,3
[FLINK-21134] Rename EXECUTION_MODE to INTERNAL_CLUSTER_EXECUTION_MODE,2
[Dubbo-5468] fix duplicate code in CacheableRouterFactory (#5565),0
[hotfix][test] Improve error message in ValidatingCheckpointHandler,5
"[FLINK-5672] [scripts] Add special cases for a local setup in cluster start/stop scriptsThis way, if all slaves refer to ""localhost"", we do not require ssh at all.This closes #3298",1
[hotfix][docs] Add glossary entry for 'Table program',1
[FLINK-8004][metrics][docs] Fix usage examplesThis closes #4965.,0
"KAFKA-3522: Add RocksDBTimestampedStore (#6149)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"[FLINK-13725][docs] use sassc for faster doc generationJekyll requires sass but can optionally also use a C-based implementationprovided by sassc. Although we do not use sass directly, there may be someindirect use inside jekyll. It doesn't seem to hurt to upgrade here.This closes #9443",1
"[hotfix][runtime] Remove unused check for the ResourceSpec of SlotSharingGroup in calculation manage memory fractionAs the resource requirement will be set to the ResourceProfile of SlotSharingGroup, the calculation of manage memory fractionshould be aligned.",2
"MINOR: add upgrade note for KIP-336Author: Viktor Somogyi <viktorsomogyi@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Andras Katona <41361962+akatona84@users.noreply.github.com>, Dong Lin <lindong28@gmail.com>Closes #5685 from viktorsomogyi/upgrade-notes-for-serializer-consolidation",5
[scala api] Minor code cleanup for compiler warnings,2
[FLINK-22070][python] Support FileSink in PyFlink DataStream APIThis closes #15455.,5
MINOR: Fix quickstart in docsReverting some of the recent changes to quickstart doc. Further explanation is provided inline.Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2539 from vahidhashemian/doc/fix_quickstart_issues,2
"KAFKA-12365; Disable APIs not supported by KIP-500 broker/controller (#10194)This patch updates request `listeners` tags to be in line with what the KIP-500 broker/controller support today. We will re-enable these APIs as needed once we have added the support.I have also updated `ControllerApis` to use `ApiVersionManager` and simplified the envelope handling logic.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
[FLINK-13440] Add test for FLINK-12858,2
- Added UnitTests and IntegrationTests for PACT Tasks,3
"MINOR: make Consumed copy ctor protectedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3816 from dguy/consumed-ctor",5
[FLINK-4452] [metrics] TaskManager network buffer gaugesAdds gauges for the number of total and available TaskManager networkmemory segments.This closes #2408,1
[FLINK-5608] [webfrontend] Rebuild web frontendThis closes #3189.,2
Added small introductory text about stratosphere to the readme.,1
[FLINK-25269][tests] Migrate AbstractHandlerTest to JUnit5,3
[FLINK-16753][checkpointing] Use CheckpointException to wrap exceptions thrown from AsyncCheckpointRunnableThis closes #11509.,1
"fix #2560, use target/test-classes as the basedir (#2563)",3
[hotfix][runtime] Fix unstable TaskManagerCheckInSlotManagerTest#testTaskManagerIsNotReleasedInCaseOfConcurrentAllocation,3
Corrected code style of OutgoingConnection.java,5
[FLINK-21867][webui] Expose concurrent exceptions,2
[hotfix] [tests] Fix JavaProgramTestBase to reset MiniClusterResource#TestEnvironment,5
[FLINK-23021] Check for illegal job graph modifications with finishedoperatorsIf we restore from a checkpoint with finished vertices there are certaingraph modifications that are not supported. Usesrs can not add a runningoperator followed by a finished one. We throw an exception if weidentify such case.Moreover so far we do not support vertices with part of the chainfinished. This might happen if the chainning changes before the restore.We throw an exception in that case as well.,4
DUBBO-399 开源memcached协议git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1810 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][runtime] Cleanup NoResourceAvailableExceptionRemove unused methods and fix checkstyle violations.,0
"MINOR: adding system tests for how streams functions with broker faiures (#4513)System test for two cases:* Starting a multi-node streams application with the broker down initially, broker starts and confirm rebalance completes and streams application still able to process records.* Multi-node streams app running, broker goes down, stop stream instance(s) confirm after broker comes back remaining streams instance(s) still function.Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[hotfix] Minor refactoring of OperationsOnFreedSegmentTest,3
[hotfix][tests] Make NoOpCheckpointResponder top level classMake NoOpCheckpointResponder a top level class so that it can be used by other tests as well.,3
[hotfix][test] Deduplicate code in BarrierBufferTestBase,3
"[streaming] fromCollection, fromElements test",3
修改版本号为2.1.0git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1261 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-13501][doc] Fixes a few issues in documentation for Hive integrationThis closes #9437.,2
"MINOR: improve license header check by providing head file instead of (prefix) header regexAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2303 from mjsax/licenseHeader",5
[FLINK-18840][table-api] Add StreamStatementSet.attachAsDataStream()This closes #16816.,5
[FLINK-3296] Remove 'flushing' behavior of the OutputFormat support of the DataStream APIThis closes #1563,5
"Fixed #1226, enhance netty support for rest protocol",1
[FLINK-16437][runtime] Pass SlotManagerConfiguration into SlotManagerImpl.,5
Fixed deserialization problems with the plugin ID,0
"TRIVIAL: Updated testing readmeMinor update to point to testing tutorial, and install the correct version of vagrant-hostmanagerAuthor: Geoff Anderson <geoff@confluent.io>Reviewers: Gwen ShapiraCloses #187 from granders/minor-testing-readme-update",5
"KAFKA-12648: extend IQ APIs to work with named topologies (#11562)In the new NamedTopology API being worked on, state store names and their uniqueness requirement is going to be scoped only to the owning topology, rather than to the entire app. In other words, two different named topologies can have different state stores with the same name.This is going to cause problems for some of the existing IQ APIs which require only a name to resolve the underlying state store. We're now going to need to take in the topology name in addition to the state store name to be able to locate the specific store a user wants to queryReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
[FLINK-14723][table-planner-blink] Java(Scala)DataStreamQueryOperation should remember the registered object pathJava(Scala)DataStreamQueryOperation represent a registered DataStream from `registerDataStream` methodor a unregistered DataStream from `fromDataStream`. However the name under which the DataStreamis registered is missing when converting a Java(Scala)DataStreamQueryOperation to a RelNode.So add a `qualifiedName` member field in it to remember the original name.,1
Merge pull request #161 from aljoscha/serializer-fixesSerializer fixes,0
"[FLINK-8605] [rest] Enable job cancellation from the web UIIn order to support the job cancellation from the web UI, including when usingYarn, we have to register the JobTerminationHandler under /jobs/:jobid/yarn-canceland /jobs/:jobid/yarn-stop. This is just a temporary fix until we can sendarbitrary REST verbs through the Yarn proxy.This closes #5430.",0
hopefully fix bug with version detection using maven for yarn deployment to sonatype,1
"KAFKA-9892; Producer state snapshot should be forced to disk (#9621)FileChannel.close() does not guarantee modified buffer would be written on the file system. We are changing  it with force() semantics to enforce file buffer and metadata written to filesystem (FileChannel.force(true) updates buffer and metadata).Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-3714] Rename getCleanupTimeForWindow to cleanupTime in WindowOperator,1
Merge branch 'stratosphere'Conflicts:pom.xml,5
[FLINK-18628][table-common] Fix error message for overloaded function with same parameter namesThis closes #12928.,2
Fixing typos in the javadocs.,2
[hotfix][docs] Merge the two Flink POJO definitions to make the definition uniform.,5
[FLINK-7017] Remove netty usages in flink-testsThis closes #4196.,3
upgrade slf4j & logback & fastjson,5
DUBBO-371 NoNodeException检测git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1749 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-19414][connector-file] Introduce forEachRemaining util for BulkFormat.Reader,5
Reduce context switching cost by optimizing thread model on consumer side. (#4131),5
#1056 I18N effort for dubbo code base: dubbo-common,5
"[FLINK-19448][connector base] Explicitly check for un-expected condition that would leave an inconsistent stateThis condition should never happen, but if it ever happened, it would leave the source in an idle state waiting formore input data, rather than shutting down.",5
[FLINK-12098][table-planner-blink] Add support for generating optimized logical plan for simple group aggregate on stream (#8110),2
Add netty4 dependency to 'dubbo-maven/pom.xml',5
KAFKA-12283: disable flaky testMultipleWorkersRejoining to stabilize build (#10408)Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
KAFKA-12492: Fix the formatting of example RocksDBConfigSetter (#10486)Fix the formatting of example RocksDBConfigSetter due to the un-arranged spaces within <pre> tag.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,5
"KAFKA-8861 Fix flaky RegexSourceIntegrationTest.testMultipleConsumersCanReadFromPartitionedTopic (#7281)similar to https://issues.apache.org/jira/browse/KAFKA-8011 and https://issues.apache.org/jira/browse/KAFKA-8026Reviewers:  Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",0
[FLINK-24163][test] Increase the checkpoint timeout for PartiallyFinishedSourcesITCaseThis closes #17170.,5
[FLINK-22877][table] Remove BatchTableEnvironment and related classes,4
[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration (#13434),5
[FLINK-21178][Runtime/Checkpointing] Task failure should trigger master hook's reset() (#14890),1
Implemented optimizer plan post pass for workset iterations.,1
MINOR: Fix how the last broker id is computed in `TestUtils.createBrokerConfigs` (#11237)The old logic only worked when the starting brokerId was 0. Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-13934][rest] Throw RestHandlerException instead of sending inline response,0
Changed to snapshot version; added maven repository for deployment,1
[FLINK-5160] Fix SecurityContextTest#testCreateInsecureHadoopContext on WindowsThis closes #2888.,3
[FLINK-15728][jdbc] Introduce FieldNamedPreparedStatement to support fields are bound multiple times in update statementThis closes #12882,5
kafka-2205; Generalize TopicConfigManager to handle multiple entity configs; patched by Aditya Auradkar; reviewed Jun Rao,5
[FLINK-15792][k8s] Update logging section in native Kubernetes documentThis closes #12240,2
update change list,4
Fixed bugs in ClusterManager and the corresponding unit test,3
Fixed bug in computation of the initial active channel set,1
[jobmanager] Fix indentation,0
[docs] small fix to the description of the checkpointing mechanism,0
"[FLINK-20888][runtime] Close outputs in OperatorChain.OperatorChain creates the outputs and owns them, so that it should also close them. Specific operators should not close the outputs.Also, ChainingOutput should never close the chained operator; it's not owning the operator.",1
"[FLINK-11834] [table-planner-blink] Introduce flink logical relational nodes (#7910)* [FLINK-11834] [table-planner-blink] Introduce flink logical relational nodesThis commit includes most flink logical relational nodes, the rest will be introduced by other commit.* add FlinkLogicalTableFunctionScan* add FlinkLogicalTableSourceScan* move RankRange into Rank.scala file",2
polish #5421,1
[FLINK-5998] Un-fat Hadoop from Flink fat jar.This closes #3604,2
"[hotfix][runtime/task] remove MailboxExecutor#executeFirst and enqueue MailboxProcessor ""control"" mails directly in itThe only use of MailboxExecutor#executeFirst is in MailboxProcessor to send control messages to itself.These control messages don't require any special handling like synchronization with task state changing actions.",4
[FLINK-24880][python] Fix PeriodicThread to handle properly for negative wait timeout valueThis closes #18292.,0
[FLINK-12815] [table-planner-blink] TableImpl supports QueryOperation in blink planner,2
"[hotfix][runtime,test] Deduplicate the common codes in RecordWriterTest (#7989)Extract a common method in tests for easy reuse and maintenance",1
[FLINK-24770] Remove error from JobStatusListenerThe error is not currently used anywhere and makes it harder to add more uses of the interface.,1
Fixed bug in JobManager shutdown method,0
[FLINK-20064][docs] Fix the broken linksThis closes #14009.,2
Add Logger Disabled Option (#8885),2
Adjusted interfaces for secondary sort to Orderings.,5
"Refactor ConfigManager (#4804)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager",5
[FLINK-3940] [table] Add support for ORDER BY OFFSET FETCHThis closes #2282.,1
"KAFKA-7250: switch scala transform to TransformSupplier (#5481)#5468 introduced a breaking API change that was actually avoidable. This PR re-introduces the old API as deprecated and alters the API introduced by #5468 to be consistent with the other methodsalso, fixed misc syntax problems",0
[FLINK-16190][e2e] Migrate tests to FlinkResource,2
MINOR: Use MessageDigest equals when comparing signature (#10898),1
"[FLINK-18390][docs-zh] Translate ""JSON Format"" page into ChineseThis closes #12733",1
[FLINK-2961] [table] Add support for basic type Date in Table APIFix nullCheck enabledFix testTableConfig introducedImprovements and bug fixingThis closes #1322.,0
"KAFKA-3086: Remove unused method in MirrorMaker.Author: Jakub Nowak <jakub.nowak94@interia.pl>Reviewers: Ismael Juma, Gwen Shapira, Grant Henke, Guozhang WangCloses #758 from Mszak/kafka-3086",1
[hotfix] [checkpointing] Fix error message in SavepointLoaderThe message referred to parallelism although max parallelism ischecked.,0
[FLINK-9234] [table] Fix missing dependencies for external catalogsThis closes #5897.,2
[FLINK-5294] Test accumulating aligned window op restore from 1.1,3
[FLINK-9636][network] fix inconsistency with interrupted buffer pollingThis closes #6238.,0
"[FLINK-23209] Introduce HeartbeatListener.notifyTargetUnreachableWith this commit Flink's HeartbeatServices listen to the result of the heartbeat rpcs.If a rpc fails with RecipientUnreachableException, then it will fail the heartbeat andcall HeartbeatListener.notifyTargetUnreachable. All Flink components (ResourceManager,JobMaster and TaskExecutor) will treat this signal similar to a heartbeat timeout. Thismeans that connection failures on the TCP layer will now speed up the detection of lostcomponents.",0
"KAFKA-9346: Consumer back-off logic when fetching pending offsets (#7878)Let consumer back-off and retry offset fetch when the specific offset topic has pending commits.The major change lies in the broker side offset fetch logic, where a request configured with flag WaitTransaction to true will be required to back-off when some pending transactional commit is ongoing. This prevents any ongoing transaction being modified by third party, thus guaranteeing the correctness with input partition writer shuffling.Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10583: Add documentation on the thread-safety of KafkaAdminClient (#9397)Other than a Stack Overflow comment (see https://stackoverflow.com/a/61738065) by Colin Patrick McCabe and a proposed design note on KIP-117 wiki, there is no source that verifies the thread-safety of KafkaAdminClient.This patch updates JavaDoc of KafkaAdminClient to clarify its thread-safety.Reviewers: Tom Bentley <tbentley@redhat.com>, Chia-Ping Tsai <chia7712@gmail.com>",2
Use maven CI friendly versions: revision. (#3851),1
"KAFKA-10282; Remove Log metrics immediately when deleting logCurrently, we remove the Log metrics when asynchronous deletion of the log is triggered. However, we attempt to register the metrics immediately upon log creation. If a Log object is re-created for a partition that is pending deletion (because a topic was quickly re-created or because a partition was moved off and back onto a broker), the registration of the new metrics can happen before the asyncrhonous deletion. In this case, the metrics are removed after the second registration, leading to missing Log metrics.To fix this, this patch changes the log deletion behavior to remove the metrics when the log is first marked for deletion, rather than when the files are deleted. This removes the window in which metrics registration can occur before metrics removal. This is justifiable because the log should be logically deleted when a delete request or partition movement finishes, rather than when the files are actually removed. Tested with unit tests.Author: Bob Barrett <bob.barrett@confluent.io>Reviewers: David Jacot, Dhruvil Shah, Vikas Singh, Gwen ShapiraCloses #9054 from bob-barrett/KAFKA-10282",5
DUBBO-320 ActiveLimitFilter没有实时获取并发数git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1481 1a56cb94-b969-4eaa-88fa-be21384802f2,1
pull request#131: 修复当value == null &&　entry.getValue() ＝= null 时语句if(value == null && entry.getValue() != null || !value.equals(entry.getValue())) 报NullPointerException,1
testcode 修改waring times 判断，集成测试环境cpu高的情况下，有可能重连此数受影响git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@569 1a56cb94-b969-4eaa-88fa-be21384802f2,1
DUBBO-970 修改Registry客户端支持category分类数据git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1513 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-10821] E2E now uses externalized checkpointThis commit fixes the test_resume_externalized_checkpoints.sh script,by providing the path to the externalized checkpoint taken.",1
MINOR: MemoryRecordsBuilder.sizeInBytes should consider initial positionAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3376 from hachikuji/records-builder-improvements,1
[hotfix] Refactor HeartbeatManagerTest to remove SimpleTestingHeartbeatListener,3
[ml] Fixes implicit issue with BreezeVectorConverter,0
trunk is the 0.8.2 snapshot,1
"MINOR: add architecture section and configure / execution for streams1. Added an architecture section.2. Added a configuration / execution sub-section to developer guide.Minor tweaks and a bunch of missing fixes from `kafka-site` repo.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Derrick Or <derrickor@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2488 from guozhangwang/KMinor-streams-docs-second-pass",4
[hotfix][tests] Don't set process variable to nullPrevents the output from being written in case of failure,0
[FLINK-11017][table] Throw exception if constant with YEAR TO MONTH resolution was used for group windowsThis closes #7200.,1
MINOR: update Streams upgrade notes with removed APIs (#10420)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
MINOR: remove redundant null check when testing specified type (#10314)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"[FLINK-11306][jdcs] Bump derby from 10.10.1.1 to 10.14.2.0Derby has two CVE's:https://ossindex.sonatype.org/vuln/b01781a6-31db-4dbc-b091-d683aaeb98e6https://ossindex.sonatype.org/vuln/bbe6594a-c255-41a7-a397-d762d1aa8b00Although it is only a test dependency, updating would be nice.",5
KAFKA-1720; Renamed Delayed Operations after KAFKA-1583; reviewed by Gwen Shapira and Joel Koshy,5
[FLINK-10340] Add Cosh math function supported in Table API and SQL,1
[FLINK-16877][table-runtime] SingleDirectoryWriter should not produce file when no input recordThis closes #11572,2
Fix simple error in local execution memory estimation,0
"MINOR: Update Gradle to 5.4.1 and update its plugins  (#6436)Details: * gradle: 5.1.1  -->  5.4.1 * grgit: 1.9.3  -->  3.1.1 (breaking change release: artifact name is changed;also, Grgit.open' usage is slightly refactored) * gradle-versions-plugin: 0.20.0 --> 0.21.0 * shadow: 4.0.3  -->  4.0.4 * spotless-plugin-gradle: 3.17.0  --> 3.23.0 * checkstyle: 8.10 --> 8.20 * spotbugs: 3.1.8 --> 3.1.12 * jacoco: 0.8.2 --> 0.8.3",0
[FLINK-6675] Activate strict checkstyle for flink-annotationsThis closes #3970.,2
MINOR: Javadoc formatting for MetricsContext (#11419)The Javadoc for MetricsContext wasn't correctly formatted for nice/readable HTML output.Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
[FLINK-7996] [table] Add support for (left.time = right.time) predicates to window join.This closes #4977.,1
[hotfix] Added missing documentation in StateTransformationFunction,1
[hotfix][tests] Don't test emit from Operator.close()The contract was refined in FLINK-22972 (FLIP-147).,2
[FLINK-26210][pulsar][tests] Add jaxb-api to e2e test,3
修改zookeeper实现git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@71 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-22895][docs] Fix example typo in ""Table Concepts & Common API"" pageThis closes #16087",1
MINOR: Add ClientQuotaMetadataManager for processing QuotaRecord  (#10101)This PR brings in the new broker metadata processor for handling QuotaRecord-s coming from the metadata log. Also included is a new cache class to allow for fast lookups of quotas on the broker for handling DescribeClientQuotaRequest.Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
MINOR: add Yahoo benchmark to nightly runsAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3289 from enothereska/yahoo-benchmark,1
[FLINK-10508] Remove JobManagerITCaseThe session timeout test cases are obsolete with the Flip-6 code base.The savepoint failure message handling should be covered by tests inSavepointITCase.This closes #6834.,3
[FLINK-3837] [table] Create FLOOR/CEIL functionThis closes #1943,1
[FLINK-21976] Remove Flink ML related examples from flink-examplesThis closes #15405.,2
trivial change to clarify comments in KAFKA-4229,4
[FLINK-1181] Fix IOReadableWritable checks in RPC serviceThis closes #167,0
[FLINK-23929][python] Operator with multiple outputs should not be chained with one of the outputsThis closes #16948.,1
[hotfix] Let KubernetesSharedWatcher only require an ExecutorThis commit changes the KubernetesSharedWatcher to only require an Executor insteadof an ExecutorService.,1
upgrade curator version,5
[FLINK-9623][runtime] Move zipping logic out of blobserviceThis closes #6187.,2
"KAFKA-7536: Initialize TopologyTestDriver with non-null topic (#5923)In TopologyTestDriver constructor set non-null topic; and in unit test intentionally turn on caching to verify this case.Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[hotfix][runtime] DefaultExecutionSlotAllocator checks for duplicated slot allocationThis ensures that a restarted vertex is in a correct state to request a slot.It also ensures that DefaultExecutionSlotAllocator will not drop the referenceof an existing pending slot request.,4
[FLINK-4836] [cluster management] Start ResourceManager and TaskManager services in MiniCluster,5
[FLINK-6597] [table] Clean up unused imports.This closes #3920.,2
[hotfix] [runtime] Migrate NetworkEnvironmentConfiguration to Java,5
Rebuild web-frontend,5
[hotfix] [mesos] Delete unused class FlinkMesosSessionCli.,2
"MINOR: Update dependencies for Kafka 2.5 (#7909)Noteworthy:* zstd decompression speed improvement of ~10%:https://github.com/facebook/zstd/releases/tag/v1.4.4* EasyMock, PowerMock and Mockito: improved support for Java 13.* Replace usage of method deprecated by Mockito.* Gradle plugins updated to versions that require Gradle 5.x, this isfine since we no longer depend on the installed Gradle version.* Fixed build not to depend on methods deprecated in Gradle 5.x(fixes KAFKA-8786).* Reflections 0.9.12 no longer depends on Guava (fixes KAFKA-3061).* Updated `OptimizedKTableIntegrationTest` to pass with new versionof Hamcrest.* Several Jetty improvements and bug fixes:   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.21.v20190926   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.22.v20191022   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.23.v20191118   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.24.v20191120   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.25.v20191220Note that I did not upgrade lz4 due to https://github.com/lz4/lz4-java/issues/156.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Co-authored-by: Ismael Juma <ismael@juma.me.uk>Co-authored-by: Aljoscha <aljoscha.poertner@posteo.de>",0
"MINOR: Remove outdated comment in Connect's WorkerCoordinator (#9805)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"MINOR: Count fix and Type alias refactor in Streams Scala API (#4966)Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-14381][table-planner] Remove dynamic partition shuffle support in legacy planner,1
Fix various serialization warnings.,2
refactor: Optimize Extension annotation import (#9515),2
"[3.0] Check duplicated ReferenceConfig/ServiceConfig by unique service name (#8198)* Check duplicated ReferenceConfig/ServiceConfig by unique servie name, improve adding large numbers of references/services* fix tests* Create reference proxy without ReferenceConfigCache in ReferenceBean",5
"Apollo config center optimization, use 'dubbo.properties' as default namespace for properties. (#5105)",1
[refactor] Factor common testing code out of FileSinkITBaseWe want to reuse this code for the new FileSink migration test as well.,3
[FLINK-22252][docs][config] Fix backticks rendering,0
[scripts] Fix job manager heap size configuration key,5
[FLINK-2381] Stringify cause of ProducerFailedExceptions,0
[hotfix] [streaming] Tasks print subtask in log statements,2
Implemented queue for pending actions inside the task manager component of the Nephele streaming plugin,2
Prevent RPC service from blocking on exceptions during task cleanup on canceling.,4
[docs] Document difference between 'stop' and 'cancel',2
[FLINK-10114] Add ORC BulkWriter support for StreamingFileSinkThis closes #11474.,2
[FLINK-3604][tableAPI] Enable and fix ignored tests.This closes #1782.,3
[hotfix] Abort restore when the procedure failed through with a closed CloseableRegistryThis prevents that exceptions from cancellation through the CloseableRegistry will result inunnecessary recovery attemps with alternative state.,1
[hotfix][tests] AsyncWaitOperatorTest refactoring: move common test harness creation to a dedicated method,1
"[hotfix] [docs] Fix description of ""following"" for Table API over windows.This closes #4161.",0
introduced JsonNodeWrapper for serialization,5
check if path is null,5
[FLINK-23654][runtime] Splitting IO and future threadpools and adding advanced configurations[FLINK-23654] Use fixed thread pool for JobManagerSharedServices.ioExecutor[FLINK-23654] Update keys of JobManagerOptions.JOB_MANAGER_FUTURE_POOL_SIZE and .JOB_MANAGER_IO_POOL_SIZEThe new key name for JobManagerOptions.JOB_MANAGER_FUTURE_POOL_SIZE is jobmanager.future-pool.size andJobManagerOptions.JOB_MANAGER_IO_POOL_SIZE is jobmanager.io-pool.size.This closes #16946.,1
[hotfix][ci] Return tools/ci/docs.sh,2
KAFKA-5920; Handle SSL handshake failures as authentication exceptions1. Propagate `SSLException` as `SslAuthenticationException` to enable clients to report these and avoid retries2. Updates to `SslTransportLayer` to process bytes received even if end-of-stream3. Some tidy up of authentication handling4. Report exceptions in SaslClientAuthenticator as AuthenticationExceptionsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3918 from rajinisivaram/KAFKA-5920-SSL-handshake-failure,5
"Fixed log levels, code cleanups and restore the thread interruption states for JobManager and TaskManager",4
[FLINK-9508][docs] Fix spelling/punctuation errorsThis closes #6112.,0
[FLINK-19681][checkpointing] Timeout aligned checkpoints based on checkpointStartDelay,2
[FLINK-24765][tests] Use DockerImageVersions to reference Kafka docker image,2
"[FLINK-20737][table-planner-blink] Introduce StreamPhysicalIncrementalGroupAggregate, and make StreamExecIncrementalGroupAggregate only extended from ExecNodeThis closes #14478",1
KAFKA-1807 Improve accuracy of ProducerPerformance target throughput; reviewed by Neha Narkhede,1
KAFKA-5418; ZkUtils.getAllPartitions() may fail if a topic is marked for deletionSkip topics that don't have any partitions in zkUtils.getAllPartitions()Author: Mickael Maison <mickael.maison@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3295 from mimaison/KAFKA-5418,1
[FLINK-5282] Fix closing streams on exception in SavepointV0Serializer,0
[hotfix] fix mobile layout on documentation,2
optimize array code style (#4031)Signed-off-by: jimin.jm <slievrly@163.com>,5
Fixed Runtime Bugs for new DataModel Runtime,1
[FLINK-4824] [client] CliFrontend shows misleading error messageWhen a command-line program is run but no Flink job is executed themessage to the user is now displayed without the stacktrace.When a Flink program throws ProgramParametrizationException theoptional message is printed to stderr without a stacktrace.This closes #2662,2
"[FLINK-20706][table-planner-blink] Introduce StreamPhysicalUnion, and make StreamExecUnion only extended from ExecNodeThis closes #14455",1
[hotfix][docs] Fix minor typo,2
"MINOR: Streams Update for KIP-330 / KIP-356 (#5794)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-15646][kubernetes] Make kubernetes context configurableThis closes #10956 .,5
[FLINK-15390][orc] List/Map/Struct types support for vectorized orc readerThis closes #15939,1
[FLINK-13811][python] Support converting flink Table to pandas DataFrameThis closes #12148.,5
[FLINK-24058][coordination] Use ExecutorUtils#gracefulShutdown,1
Corrected typo in checkpointing annotations,2
[FLINK-18683][table-common] Support @DataTypeHint for table/aggregate function output typesAllows to use @DataTypeHint(...) as a synonym @FunctionHint(output = @DataTypeHint(...)) fortable and imperative aggregate functions.This closes #13149.,1
[FLINK-14478][python] Optimize current python test cases to reduce test time.This closes #9991.,3
[FLINK-16437][runtime] Compute pending slot profiles inside SlotManager when allocating resource.This means also check unfulfillable slot profiles inside SlotManager.,2
fixed test failure,0
[FLINK-21302][table-planner-blink] Fix NPE when use row_number() in overAggThis closes #14880,1
[FLINK-16303][rest] Enable retrieval of custom JobManager log filesThis closes #11542.,2
"MINOR: Reset timer when all the buffer is drained and empty (#7573)For scenarios where the incoming traffic of all input partitions are small, there's a pitfall that the enforced processing timer is not reset after we have enforce processed ALL records. The fix itself is pretty simple: we just reset the timer when there's no buffered records.Reviewers: Javier Holguera <javier.holguera@gmail.com>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-17307] Add collector to deserialize in RMQ,1
[hotfix][util] Fix Precondition#checkNotNull annotations.,0
[FLINK-9853] [table] Add HEX support for Table API & SQLThis closes #6337.,1
KAFKA-1582; System Test should wait for producer to finish; reviewed by Joel Koshy and Guozhang Wang,5
[refactor] [tests] Refactor CliFrontend mocking into utility class,4
[FLINK-8736][network] fix memory segment offsets for slices of slices being wrongThis closes #5551.,0
MINOR: cleanup policy doc update (#6692)Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
Several fixes to JNI code and Makefiles,2
[FLINK-27287][tests] Migrate tests to MiniClusterResource,5
"MINOR: Fix a few compiler warnings (#6767)Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-13761][scala] Deprecate Scala SplitStreamDeprecate Scala SplitStream which has been superseded by side outputs.This closes #9474.,2
[hotfix][docs]fix kafka datastream connector mistake,5
"KAFKA-5088: some spelling error in code commentfix some spelling errorsAuthor: xinlihua <xin.lihua1@zte.com.cn>Reviewers: Matthias J. Sax, Guozhang WangCloses #2871 from auroraxlh/fix_spellingerror",0
KAFKA-2714: Added integration tests for exceptional cases in fetchingAuthor: Anna Povzner <anna@confluent.io>Reviewers: Jason GustafsonCloses #393 from apovzner/cpkafka-84,5
[hotfix] Fix race condition in JobMaster#requestJobDetailsDo not directly access executionGraph in another thread because it might bealtered.,1
MINOR: rename class `RecordTimeDefintion` to `RecordTimeDefinition` (#8939)Fix a typo for class RecordTimeDefintion to RecordTimeDefinitionReviewers: Boyang Chen <boyang@confluent.io>,5
[FLINK-4033] Polish up Kinesis connector documentationIncludes:1. Scala examples for consumer and producer2. Add information about AWS Kinesis service usage3. Add Kinesis connecter to the fault tolerance guarantees table4. Minor typo fix in Kafka documentationThis closes #2181,2
Fix typo in Resource in org.apache.kafka.trogdor (#5739)Reviewers: Ismael Juma <ismael@juma.me.uk>,2
"[FLINK-13819][coordination] Introduce isRunning state for RpcEndpointTo better reflect the lifecycle of RpcEndpoint, we suggest to introduce its running state.We can use the non-running state e.g. to make decision about how to react on APIcalls if it is already known that the RpcEndpoint is terminating.",1
MemoryManager changes to page memory manager.,4
[streaming] License fix,0
[FLINK-4895] Drop Hadoop1 support and remove related build infrastructureThis closes #2850,5
[FLINK-1065] [streaming] Explicitly adding commons-math dependency,1
standardizing json values stored in ZK; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-755,5
register metadata config on ConfigManager,5
[FLINK-2895] Duplicate immutable object creationOperators defer object creation when object reuse is disabled.This closes #1288,1
Fixed and extended tests for global ordering.,3
[FLINK-16525][task] Increment subtask id by 1 to display subtask name,2
[FLINK-14199] [runtime] Mailbox explicitly requires a description to ease debugging,0
"[FLINK-7547] Make AsyncFunction.scala extends FunctionBefore, the Scala AsyncFunction was not Serializable. Function isderived from Serializable.",1
DUBBO-91 修改启动脚本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@396 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-11952][3/4] Integrate plugin mechanism with FileSystem,5
拆分模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@51 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][table-planner-blink] Reuse data structure converters whenever possible,5
DUBBO-282 将连接报警检查的时间间隔从默认5分钟改为15分钟。此参数的作用是在设定时间内，重连失败不报警。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1289 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][docs] Fix typo,2
[hotfix] Remove StandaloneMiniCluster from ScalaShellITCase,5
"[FLINK-15670][connector] Kafka Shuffle API PartKafkaShuffle provides a transparent Kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.",1
DUBBO-152 增加注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@736 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Refactored envelope forwarding API,4
[FLINK-11741] [runtime] WritableSerializer's ensureCompatibility method should have been removed,4
[FLINK-18639][scripts] Print raw output from BashJavaUtils in case of execution failure.This closes #12933.,0
trival fix to make hash code positive; patched by Joel Koshy; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1177516 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-12979][formats] Allow empty line delimiter for CsvRowSerializationSchemaThis closes #9529.,1
"MINOR: Clarification in producer config documentationAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>Reviewers: Dana Powers, Gwen ShapiraCloses #1732 from vahidhashemian/minor/clarify_producer_config_documentation",5
[hotfix] Update task heap/offheap config option descriptions for preciseness.,5
[FLINK-8634] [rest] Introduce job rescaling REST handlerAdd rescaling REST handler as a sub class of theAbstractAsynchronousOperationHandlers.This closes #5451.,0
修改Demo配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1219 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[Tools] Minor fixes in release script- Introduced required RELEASE_BRANCH environment variable- Some hardcoded binary calls (gpg, sha512sum, md5sum) have been  replaced by environment variables (GPG, SHASUM, MD5SUM) and added  """" argument for 'sed -i' calls for compatability with OS X- Removed unused environment variables- Directly call ssh/scp instead of going through sshpass",4
[FLINK-28996][datadog] Move parameter parsing into factory,2
MINOR: improve docs version numbers (#5372)Reviewer: Guozhang Wang <guozhang@confluent.io>,5
DUBBO-100 method oninvoke在spring解析器中没有做解析，此功能失效git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@431 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-145 Kafka server mirror shutdown bug; patched by nehanarkhede; reviewed by junraogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179466 13f79535-47bb-0310-9956-ffa450edef68,1
Dependencies Upgrade (#8351)* Dependencies Upgrade* fix ut* update nacos version* remove eclipse-collections dependency* fix compile error* revert 401c56e6* exclude guava* fix test compile,3
[FLINK-6642] Return -1 in EnvInfo#getOpenFileHandlesLimitThis closes #3956.,5
[streaming] StreamRecord created,1
修改surefire forkmode为oncegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1850 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-12737][table-api][table-planner] Port TemporalTableFunctionImpl to java-api module,1
[hotfix][python][tests] Split the test cases of connectors & formats into separate files,2
"KAFKA-13854 Refactor ApiVersion to MetadataVersion (#12072)Refactoring ApiVersion to MetadataVersion to support both old IBP versioning and new KRaft versioning (feature flags)for KIP-778.IBP versions are now encoded as enum constants and explicitly prefixed w/ IBP_ instead of KAFKA_, and having aLegacyApiVersion vs DefaultApiVersion was not necessary and replaced with appropriate parsing rules for extractingthe correct shortVersions/versions.Co-authored-by: David Arthur <mumrah@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",4
[FLINK-26604][doc] add more information for Avro records support and clean up redundant content of bounded and unbounded data.- mvn dependency- using namespace in schema for reflect records[FLINK-26604][doc] bug fix,0
Added constants for true and false to PactBoolean[ci skip],1
"MINOR: improve Streams error message (#5975)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-19170][table] fix parameter naming error (#13361),0
Removed superfluous class,4
[FLINK-1230] Add documentation and an example for collection-based executionThis closes #195,2
[hotfix] [core] Add comments for class loading config options in CoreOptions,5
[FLINK-28466][tests] Bump assertj to 3.23.1,3
添加注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@226 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-13799: Improve documentation for Kafka zero-copy (#12052)Improve documentation for Kafka zero-copy. Kafka combines pagecache and zero-copy to greatly improve message consumption efficiency. But zero-copy only works in PlaintextTransportLayer.Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
[FLINK-21136] Adjust timeouts for reactive modeThis closes #15159,2
调整 pom 的 relativePathgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1553 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-1682] Ported optimizer unit tests from Record API to Java APIThis closes #627,3
Add first files for system internals documentation[ci skip],2
Added unit test for #141,3
Added contract util for generic contract manipulation,1
"[FLINK-2611][yarn] do not fail application in shutdown hookThe application status is set to failed for jobs which did not completesuccessfully. If the client shuts down the YARN cluster, theapplications should be reported as SUCCESSFUL.",0
"KAFKA-8474; Use HTML lists for config layout (#6870)Replace the `<table>` elements by `<ul>` so the full page width can be used for the configuration descriptions instead of only a very narrow column. I moved the other fields (Type, Default Value, etc) below each entry.Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",5
KAFKA-2117; Use the correct metadata field for reading offset struct; reviewed by Jun Rao and Jiangjie Qin,1
"[FLINK-21155][tests] Fix FileSourceTextLinesITCaseThe problem of the test case was that it is reusing the MiniCluster. Moreover, it kills for everyTaskManager failure the TaskManager at the index 0. Since this is only possible once, all precedingTaskManager failure test will succeed because not TaskManager is killed.This commit fixes the problem by not reusing the MiniCluster across multiple tests.This closes #14855.",3
[hotfix][table-common] Enrich the output type of InputTypeValidators#getExpectedSignature.,5
[FLINK-4639] [table] Introduce CalciteConfig to make Calcite features more pluggable.This closes #2521This closes #1617 // closing PR after discussion,1
[FLINK-27878][datastream] Add Retry Support For Async I/O In DataStream APIThis closes #19983.,5
[hotfix][tests] Do not hide original exception in SuccessAfterNetworkBuffersFailureITCase,0
[FLINK-16330][AZP] Enable tests requiring S3 credentialsThis closes #11332,1
[FLINK-14826][tests] Increase number of restarts in BucketingSinkTestProgramThis closes #10266.,3
[hotfix][tests] Remove redundant null check,4
"KAFKA-8345: KIP-455 Protocol changes (part 1) (#7114)Add a new exception, NoReassignmentInProgressException.  Modify LeaderAndIsrRequest to include the AddingRepicas and RemovingReplicas fields.  Add the ListPartitionReassignments and AlterPartitionReassignments RPCs.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",1
[FLINK-16200][table-planner] Refactor CustomizedConvertRuleThis closes #16691.,4
"KAFKA-13916; Fenced replicas should not be allowed to join the ISR in KRaft (KIP-841, Part 2) (#12181)This path implements [KIP-841](https://cwiki.apache.org/confluence/display/KAFKA/KIP-841%3A+Fenced+replicas+should+not+be+allowed+to+join+the+ISR+in+KRaft). Specifically, it implements the following:* It introduces INELIGIBLE_REPLICA and NEW_LEADER_ELECTED error codes.* The KRaft controller validates the new ISR provided in the AlterPartition request and rejects the call if any replica in the new ISR is not eligible to join the the ISR - e.g. when fenced or shutting down. The leader reverts to the last committed ISR when its request is rejected due to this.* The partition leader also verifies that a replica is eligible before trying to add it back to the ISR. If it is not eligible, the ISR expansion is not triggered at all.* Updates the AlterPartition API to use topic ids. Updates the AlterPartition manger to handle topic names/ids. Updates the ZK controller and the KRaft controller to handle topic names/ids depending on the version of the request used.Reviewers: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-11884][table] DistinctTableOperation & FilterTableOperation construction &transformation to RelNodes,2
[FLINK-18428][API/DataStream] Rename StreamExecutionEnvironment#continuousSource() to StreamExecutionEnvironment#source().This closes #12766,5
[FLINK-13977] Let HighAvailabilityServices implementations implement getClusterRestEndpointLeaderElectionServiceInstead of implementing HighAvailabilityServices#getWebMonitorLeaderElectionService allHighAvailabilityServices implementation now implement getClusterRestEndpointLeaderElectionService.This closes #9631.,1
[FLINK-3169] Move Record Type Utils from flink-java to flink-runtime/test,3
[hotfix][table] Rename TableAggFunctionCallVisitor to TableAggFunctionCallResolver for class name more meaningful.This closes #9281,0
[FLINK-1502] [core] Add basic metric system,5
KAFKA-2744: Commit source task offsets after task is completely stoppedAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #423 from ewencp/commit-source-offsets-after-work-thread-exits,1
[FLINK-22760][Connectors/Hive] Fix issue of HiveParser::setCurrentTimestamp fails with hive-3.1.2This closes #15995,0
Implemented lazy task deployment,5
Version bumped to 0.10-SNAPSHOTCloses #851,5
KAFKA-1281 add the new producer to existing tools; reviewed by Jun Rao and Guozhang Wang,1
[FLINK-21229][avro-confluent-registry] Add Confluent schema registry SSL support,1
[hotfix][docs] Fix config doc structure,2
[FLINK-19677][runtime] Make JobManager lazily resolve hostname of TaskManager and provide an option to turn off reverse resolution entirely[FLINK-19677][runtime][tests] Added test casesMore test case and formattingMinor changes after reviewRe-generated docsImprovements after reviewRemove spacesThis closes #13706.,4
[FLINK-11547][flink-connector-kinesis] Fix JsonMappingException in DynamoDBStreamsSchema,5
[FLINK-11884][table] SortTableOperation construction &transformation to RelNodes,2
[FLINK-8204] [tests] Harden JobManagerLeaderSessionIDITCaseReplace wait on lock with OneShotLatch to resolve race condition between taskstart up and unblocking of invokable.,0
[FLINK-25892][hbase1.4][test] add ArchUnit tests for test code,3
"[FLINK-12146][network] Remove unregisterTask from NetworkEnvironment to simplify the interface of ShuffleService NetworkEnvironment#unregisterTask is used for closing partition/gate and releasing partition from ResultPartitionManager. partition/gate close could be done in task which already maintains the arrays of them.Further we could release partition from ResultPartitionManager inside ResultPartition via introducing ResultPartition#fail(Throwable).To do so, the NetworkEnvironment#unregisterTask could be totally replaced to remove. The benefit is simplifying the method of NetworkEnvironment which would be regarded as default ShuffleService implementation.",1
[FLINK-7674] Fix NullPointerException in ContinuousFileMonitoringFunction#closeThis closes #4711.,2
[FLINK-12821][table-planner][cep] Fix the bug that fix time quantifier can not be the last element of a pattern,0
"[FLINK-1301] Added Apache license headers to Markdown, HTML, SVG, Python files.Made exceptions for license check plugin more fine-granular.This closes #250",2
[3.0] Fix Service Discovery related concurrency issue (#9642),0
[hotfix] [py] Code cleanup - SerializationUtils,4
checkout .travis.yml from origin/master,5
Fixed RegexTokenizer,0
修改Maingit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@460 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[streaming] addon packages rename to connector,1
Fixed bug in multicast manager,0
- fixed in-cache sort path bug (missed sentinel)- found potential memory leak,0
[FLINK-28936][sql-gateway] Fix REST endpoint can not serialize uncompacted LogicalType (#20617),2
KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede,1
[FLINK-13723][docs] Use liquid-c for faster doc generationJekyll requires liquid and only optionally uses liquid-c if available. Thelatter uses natively-compiled code and reduces generation time by ~5% for me.This closes #9441,1
[FLINK-9210][metrics] Only call Gauge#getValue once during serialization,1
MINOR: Update Jetty to 9.4.11 (#5377),5
Implemented envelope consumption tracker to guarantee replay of envelopes in the correct order,5
KAFKA-8381; Disable hostname validation when verifying inter-broker SSL (#6757)- Make endpoint validation configurable on SslEngineBuilder when creating an engine- Disable endpoint validation for engines created for inter-broker SSL validation since it is unsafe to use `localhost`- Use empty hostname in validation engine to ensure tests fail if validation is re-enabled by mistake- Add tests to verify inter-broker SSL validationReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
[hotfix][runtime] Remove ExecutionSlotAllocator#stop() which is never used in production,1
"KAFKA-3614: Consolidate duplicate code in KGroupedTableImplFeel free to review guozhangwang enothereska mjsax .Author: Michael G. Noll <michael@confluent.io>Reviewers: Matthias J. Sax, Michael G. Noll, Eno ThereskaCloses #1262 from miguno/KAFKA-3614",5
"KAFKA-6913: Add Connect converters and header converters for short, integer, long, float, and double (KIP-305)*[KIP-305](https://cwiki.apache.org/confluence/display/KAFKA/KIP-305%3A+Add+Connect+primitive+number+converters) has been approved.*Added converters and header converters for the primitive number types for which Kafka already had serializers and deserializers. All extend a common base class, `NumberConverter`, that encapsulates most of the shared functionality. Unit tests were added to check the basic functionality.These classes are not used by any other Connect code, and must be explicitly used in Connect workers and connectors.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Arjun Satish <wicknicks@users.noreply.github.com>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5034 from rhauch/kafka-6913",5
[FLINK-8860][flip6] stop SlotManager spamming logs for every TM heartbeat at log level 'info'This closes #5637.,5
"[FLINK-20389][tests] Fix UnalignedCheckpointITCase to work with unassigned splits.The test currently assumed that when induced failures happen, splits have been assigned to readers, which works fine for the planned snapshot-failure-recovery sequence.However, when unexpected failures happen, this assumption does not necessarily hold resulting in failures that may impede investigations.The test would still fail as the number of failures would be different from the expected numbers of failures, but investigation can focus on the unexpected failure then.",0
"KAFKA-14154; Kraft controller should return NOT_CONTROLLER if request epoch is ahead (#12514)Similar to https://github.com/apache/kafka/pull/12506. For the Kraft controller, we should return NOT_CONTROLLER if the leader/partition epoch in the request is ahead of the controller. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",1
"KAFKA-12716; Add `Admin` API to abort transactions (#10599)This patch adds the Admin API to abort transactions from KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. The `WriteTxnMarker` API needs to be sent to partition leaders, so we are able to reuse `PartitionLeaderStrategy`, which was introduced when support for `DescribeProducers` was added.Reviewers: David Jacot <djacot@confluent.io>",5
KAFKA-1597 New metrics: ResponseQueueSize and BeingSentResponses; reviewed by Neha Narkhede and Jun Rao,1
"[FLINK-16656] Introduce the DispatcherBootstrapThis new interface generalizes how a Dispatcher can be initialized. Beforethis, a Dispatcher would always be initialized with a list of recovered jobs(that could be empty). With this generalization we can add other ways ofinitializing the jobs/state of a Dispatcher, which we will use in the follow-upcommits that add an application-mode dispatcher bootstrap.",1
[FLINK-24360] Drop Scala Shell,4
Need to enhance DecodeableRpcResult error message (#3995)Fixes #3994,0
Fix Concurrent issue when creating SPIs' Adaptive class (#8998)* Fix Concurrent issue when creating SPIs' Adaptive class* Fix ut,0
"[FLINK-25575][streaming] Scope batch exchanges in PartitionTransformation to batch mode.This change allows DataStream internally to insert fail-over regions into the operator graph that are only used in batch mode. For streaming mode, these exchanges are reset to UNDEFINED and set during StreamGraph construction.Co-authored-by: Arvid Heise <arvid@ververica.com>",1
[hotfix] Let JobMasterStopWithSavepointITCase.ExceptionOnCallbackStreamTask implement finishTask to finishIn order to properly finish ExceptionOnCallbackStreamTask the Task needs to implement finishTask.,5
"[streaming] deleted obsolete examples, renamed addFileSource -> readTextFile to match batch api",2
Improved clean-up behavior for compression,4
"KAFKA-3715: Add granular metrics to Kafka Streams and add hierarhical logging levels to MetricsKafka Streams: add granular metrics per node and per task, also expose ability to register non latency metrics in StreamsMetricsAlso added different recording levels to Metrics.This is joint contribution from Eno Thereska and Aarti Gupta.from https://github.com/apache/kafka/pull/1362#issuecomment-218326690-------We can consider adding metrics for process / punctuate / commit rate at the granularity of each processor node in addition to the global rate mentioned above. This is very helpful in debugging.We can consider adding rate / total cumulated metrics for context.forward indicating how many records were forwarded downstream from this processor node as well. This is helpful in debugging.We can consider adding metrics for each stream partition timestamp.This is helpful in debugging.## Besides the latency metrics, we can also add throughput latency in terms of source records consumed.More discussions here https://issues.apache.org/jira/browse/KAFKA-3715, KIP-104, KIP-105Author: Eno Thereska <eno@confluent.io>Author: Aarti Gupta <aartiguptaa@gmail.com>Reviewers: Greg Fodor, Ismael Juma, Damian Guy, Guozhang WangCloses #1446 from aartigupta/trunk",1
- fixed bug in TextInputFormat (input size estimation),0
[FLINK-16133][docs-zh] Translate /ops/filesystems/azure.zh.mdThis closes #11232,5
"MINOR: Use explicit type in AclCommandInference sometimes fails for this case.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #885 from ijuma/use-explicit-type-in-acl-command",1
"HOTFIX: Use a true sentinel for `UseDefaultAcls`In 67fc2a91a6, we are using an empty collection and comparing viavalue equality, so if a user passes an empty collection, they willget the default ACLs instead of no ACLs. We fix that issue here.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini SivaramCloses #2829 from ijuma/zk-utils-default-acls-improvement and squashes the following commits:0846172 [Ismael Juma] Add missing import2dc84f3 [Ismael Juma] Simplify logic in `sensitivePath`8122f27 [Ismael Juma] Use a true sentinel instead of an empty collection for `UseDefaultAcls`",1
[FLINK-17977][runtime] Log outdated TaskExecutor registration on DEBUG,0
Fix RpcContext duplicated override (#8842)* Fix RpcContext duplicated override* Fix import,2
Worked on new checkpointing implementation,1
Implemented streaming tag and integrated it,5
[FLINK-18685] Make MiniClusterJobClient#getAccumulators non-blockingThis closes #14558,5
code format (#2554),5
Fixed problem with undetected missing envelopes in RuntimeInputChannelContext,1
[FLINK-15793][k8s] Replace kubernetes-entry.sh with unified docker-entrypoint.sh,2
[streaming] [api-breaking] Consolidate DataStream method namesTo better match the names of the DataSet API the following renamings were made:- DataStream.merge -> DataStream.union- DataStream.distribute -> DataStream.rebalance- DataStream.partitionBy -> DataStream.partitionByHashCloses #743,5
[hotfix] Fix the generic parameter declaration of ParquetAvroStreamingFileSinkITCase,2
"MINOR: Remove o.a.kafka.common.utils.Base64 and IS_JAVA8_COMPATIBLEWe no longer need them since we now require Java 8.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Andras Beni <andrasbeni@cloudera.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Dong Lin <lindong28@gmail.com>Closes #5049 from ijuma/remove-base64",4
[hotfix] Fix RocksDB resource handling in RocksKeyGroupsRocksSingleStateIteratorTest,3
"MINOR: rename wrong topic id variable name and description (#10598)Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",0
[hotfix] Introduce constants MemorySize#ZERO and MemorySize#MAX_VALUE.,0
"KAFKA-5704: Corrected Connect distributed startup behavior to allow older brokers to auto-create topicsWhen a Connect distributed worker starts up talking with broker versions 0.10.1.0 and later, it will use the AdminClient to look for the internal topics and attempt to create them if they are missing. Although the AdminClient was added in 0.11.0.0, the AdminClient uses APIs to create topics that existed in 0.10.1.0 and later. This feature works as expected when Connect uses a broker version 0.10.1.0 or later.However, when a Connect distributed worker starts up using a broker older than 0.10.1.0, the AdminClient is not able to find the required APIs and thus will throw an UnsupportedVersionException. Unfortunately, this exception is not caught and instead causes the Connect worker to fail even when the topics already exist.This change handles the UnsupportedVersionException by logging a debug message and doing nothing. The existing producer logic will get information about the topics, which will cause the broker to create them if they don’t exist and broker auto-creation of topics is enabled. This is the same behavior that existed prior to 0.11.0.0, and so this change restores that behavior for brokers older than 0.10.1.0.This change also adds a system test that verifies Connect works with a variety of brokers and is able to run source and sink connectors. The test verifies that Connect can read from the internal topics when the connectors are restarted.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3641 from rhauch/kafka-5704",5
DUBBO-77 增加ExceptionFilter测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@348 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-10585: Kafka Streams should clean up the state store directory from cleanup (#9414)1. Update StateDirectory#clean  - Delete application's statestore directory in cleanup process if it is empty.2. Add Tests  - StateDirectoryTest#shouldDeleteAppDirWhenCleanUpIfEmpty: asserting the empty application directory is deleted with StateDirectory#clean.  - StateDirectoryTest#shouldNotDeleteAppDirWhenCleanUpIfNotEmpty: asserting the non-empty application directory is not deleted with StateDirectory#clean and appropriate log message is generated.  - Add Integration test: StateDirectoryIntegrationTest3. Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <guozhang@apache.org>",4
Avoid blocking on FrameworkModel during destroying (#9189),1
[FLINK-21772][metrics][slf4j] Remove flink-runtime dependency,2
[FLINK-16946] Update user documentation for job manager memory modelThis closes #11947.,2
"KAFKA-6967: TopologyTestDriver does not allow pre-populating state stores that have change logging (#5096)Reviewers: Guozhang Wang <guozhang@confluent.io>, James Cheng <jylcheng@yahoo.com>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
[FLINK-28586][runtime] Let SourceCoordinator context know whether `supportsConcurrentExecutionAttempts`,1
Forward fit new config API to plans in pact-tests,3
[FLINK-11935][table-planner-blink] Fix unixDateCeil in blink planner since CALCITE-3199 is not fixed in avatica-1.15.0This closes #10208,0
[FLINK-14461][configuration] Remove unused sessionTimeout from JobGraphThis closes #9942.,1
[FLINK-6819] Activate checkstyle for runtime/leaderretrievalThis closes #4053.,1
HOTFIX: fix checkstyle issue in KAFKA-12697,0
[FLINK-24168][table-planner] Update MATCH_ROWTIME function which could receive 0 argument or 1 argumentThis closes #17205,1
Polish README.,1
Fix aggregation testsFix error message for unsupported averaging data type,5
[FLINK-8061][QS] Remove trailing * in QSClient javadocs.,2
"MINOR: Update lz4-java to 1.6.0 for 12-18% decompression improvement (#6735)lz4-java 1.6.0 relies on lz4 1.9.1, which includes significantdecompression performance improvements first released as partof 1.9.0:Version | v1.8.3 | v1.9.0 | Improvementenwik8 | 4090 MB/s | 4560 MB/s | +12%calgary.tar | 4320 MB/s | 4860 MB/s | +13%silesia.tar | 4210 MB/s | 4970 MB/s | +18%See https://github.com/lz4/lz4/releases/tag/v1.9.0 for moredetails.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
[FLINK-3876] improve documentation of Scala Shell- restructure sections- improve readability,1
"KAFKA-5154: do not set rejoinNeeded in joinGroup response but in syncGroup response handlerScenario is as follows:1. Consumer subscribes to topic t1 and begins consuming2. heartbeat fails as the group is rebalancing3. ConsumerCoordinator.onJoinGroupPrepare is called   3.1 onPartitionsRevoked is called4. consumer becomes the group leader5. sends sync group request6. sync group is cancelled due to disconnection7. fetch request is sent for partitions that have previously been revokedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3181 from dguy/kafka-5154",5
"[FLINK-15552][table] Use thread context classloader to find factories in TableFactoryServiceThis fixes the problem that `--library` and `--jar` doesn't work for DDL in SQL CLI, because the user's classloader is not passed to the TableFactoryService. A long-term solution is not to use the context-classloader which is tracked by FLINK-15635.This closes #10874",2
"KAFKA-7142: fix joinGroup performance issues (#5354)Summary:1. Revert GroupMetadata.members to private2. Add back a wrongly removed comment3. In GroupMetadata.remove(), update supportedProtocols and awaitingJoinCallbackMembers, only when the remove succeededReviewers: Jason Gustafson <jason@confluent.io>,  Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <sriharsha@apache.org>",5
[hotfix][test] Add support for EndOfData in tests,3
Code clean up,4
[hotfix] Adds fail to DispatcherTest,3
"KAFKA-2515: Handle oversized messages properly in new consumerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Dong Lin, Jun RaoCloses #318 from guozhangwang/K2515",1
"KAFKA-12951: restore must terminate for tx global topic (#10894)Reviewers: Guozhang Wang <guozhang@confluent.io>, Luke Chen <showuon@gmail.com>, Gasparina Damien <d.gasparina@gmail.com>",5
[hotfix] Include Hadoop version into EnvironmentInformation,5
[hotfix][state/changelog] Introduce StateChangelogHandleReaderInverse control when reading StateChangelogHandles to avoidembedding logic into handles and make the reader creation explicit andsymmetric to writer.The reader is now obtained from StateChangelogWriterFactory which isrenamed in a subsequent commit.,4
[FLINK-23513][e2e] Remove legacy factory check in test_sql_client.shThis closes #16638.,3
[FLINK-19662][container][runtime][kubernetes][mesos][yarn] Moved ClusterEntrypointUtils into ClusterEntrypoint package.,1
[FLINK-16641][network] (Part#1) Introduce a new network message BacklogAnnouncement which can bring the upstream buffer backlog to the downstream,2
[hotfix] [core] Fix checkstyle for 'flink-core' : 'org.apache.flink.util',2
[hotfix][doc] Include config option TaskManagerOptions#MANAGED_MEMORY_CONSUMER_WEIGHTS into docs.,2
[hotfix][hive][test] enhance HiveCatalog IT case with 'alter table' and 'drop table' statements,4
"MINOR: Improve doc for num.x.threads configsAuthor: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #2847 from edoardocomar/MINOR-server.prop.threads.comments",2
[FLINK-19748] Skip key groups that don't have a defined stream offset,1
[FLINK-18947][python] Support partition_custom() for Python DataStream API. (#13155),5
"fix issue 6504, and polish some code (#6505)",1
[streaming] StreamCollector2 added to streamcomponenthelper with fix,0
DUBBO-204 修改本地条件路由git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1569 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-5541: Streams should not re-throw if suspending/closing tasks failsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4037 from mjsax/kafka-5541-dont-rethrow-on-suspend-or-close-2",5
Removes deprecated assignment of file names for file channels,2
[FLINK-2711] [tests] Increase timeout for TaskManager tests upon partition lookups,3
[FLINK_21972][table-planner-blink] check whether TemporalTableSourceSpec can be serialized or notThis closes #15370,2
[FLINK-10788][tests] Update ContinuousFileProcessingMigrationTest for 1.7,3
"[FLINK-28078][tests] Mitigate likelihood to run into test stability issues caused by CURATOR-645CURATOR-645 covers a bug in the LeaderLatch implementation that causes a race condition if a child node, participating in the leader election, is removed too fast. This results in a different code branch being executed which triggers a reset of the LeaderLatch instead of re-collecting the children to determine the next leader.The issue occurs because LeaderLatch#checkLeadership is not executed transactionally, i.e. retrieving the children and setting up the watcher for the predecessor is not done atomically. This leads to the race condition where a children (the previous leader's node) is removed before setting up the watcher which results in an invalid handling of the situation using reset.Adding some sleep here (simulating the leader actually doing something) will reduce the risk of falling into the race condition because it will give the concurrently running LeaderLatch instances more time to set up the watchers properly.This is only meant as a temporary solution until CURATOR-645 is resolved and the curator dependency on the Flink side is upgraded.",2
添加简单Cache Util实现 DUBBO-475 ReferenceConfig支持按group+interface+version缓存,5
KAFKA-892 Change request log to include request completion not handling; reviewed by Joel Koshy,2
[Typo] Typo fixes in code comments.This closes #352,0
[FLINK-14512][table] Introduce listPartitionsByFilter to CatalogThis closes #10325,2
[FLINK-8635] [rest] Register rescaling handlers at web endpointThis closes #5454.,0
[FLINK-20909][table-planner-blink] Fix mini-batch interval inference doesn't work well with event-time deduplicateThis closes #14610Co-authored-by: zhangjing14 <zhangjing14@kuaishou.com>,1
[streaming] LogUtils updated,5
"KAFKA-7976; Update config before notifying controller of unclean leader update (#6426)When unclean leader election is enabled dynamically on brokers, we notify controller of the update before updating KafkaConfig. When processing this event, controller's decision to elect unclean leaders is based on the current KafkaConfig, so there is a small timing window when the controller may not elect unclean leader because KafkaConfig of the server was not yet updated. The commit fixes this timing window by using the existing BrokerReconfigurable interface used by other classes which rely on the current value of KafkaConfig.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",5
[FLINK-8475][config][docs] Integrate FS optionsThis closes #5459.,5
[FLINK-8548] [examples] Add state machine exampleThis adds an example of using a state machine for pattern validation.The example illustrates the use of state and the kafka connector.This closes #5401,1
"MINOR: Fix some bugs with UNREGISTER_BROKERFix some bugs in the KRaft unregisterBroker API and add a junit test.1. kafka-cluster-tool.sh unregister should fail if no broker ID is passed.2. UnregisterBrokerRequest must be marked as a KRaft broker API so that KRaft brokers can receive it.3. KafkaApis.scala must forward UNREGISTER_BROKER to the controller.Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: remove NewTopic#NO_PARTITIONS and NewTopic#NO_REPLICATION_FACTOR as they are duplicate to CreateTopicsRequest#NO_NUM_PARTITIONS and CreateTopicsRequest#NO_REPLICATION_FACTOR (#9077)Consolidate constant values of NO_PARTITIONS and NO_REPLICATION_FACTOR as stated in the title.Reviewers: Boyang Chen <boyang@confluent.io>,5
Minor changes to logging in job manager,2
"KAFKA-13029; Set appropriate fields for FindCoordinatorRequest based on version (#10965)KIP-699 added support for batching in FindCoordinatorRequest using a new protocol that changes the wire format for both batched and unbatched requests. Clients were updated to try the new format first and switch irreversibly to the old format if the new format is not supported on one broker. During rolling upgrade (or a downgrade), it is possible that a broker doesn't support new format at some point while other brokers do at a later point. Clients end up in a bad state until restarted since they use new version with old format. This PR changes FindCoordinatorRequest to set data based on actual version when a single group is used. This is always the case for consumer coordinator and transaction manager. For admin API, we still switch to unbatched mode on failure, but the data is set based on actual version, so we never fail even if brokers are upgraded/downgraded.Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",5
[FLINK-16608][python] Remove the method which derives the LogicalType from the Arrow ValueVector,2
[FLINK-14870][runtime] Drop the nullable assumption of slot sharing group in ScheduledUnit and remove the consequently unused methods in SchedulerImpl,1
Add shutdown method to LocalDistributedExecutor and remove failing CustomDataTypeTest=> the removed test functionality will be included in an upcoming test by @aljoscha,3
[FLINK-23005][coordination] Introduce CompressedSerializedValue,2
[FLINK-27763][kinesis][tests] Remove netty bundling&relocation,4
"MINOR: Factor out some common group/transactional fields in request objectsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: tedyu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4047 from hachikuji/factor-out-some-common-fields",5
"[FLINK-7515][network] allow actual 0-length content in NettyMessage#allocateBuffer()Previously, length ""0"" meant ""unknown content length"" but there are cases wherethe actual length is 0 and so we use -1 for tagging the special case now.[FLINK-7515][network] address PR commentsThis closes #4592.",1
[FLINK-2662] [optimizer] Fix computation of global properties of union operator.- Fixes invalid shipping strategy between consecutive unions.This closes #2848.,0
[FLINK-11353][tests] Port JobManagerHAJobGraphRecoveryITCase to new code baseRemoved testClientNonDetachedListeningBehaviour because the test was only relevant forthe JobClientActor. Moved testJobPersistencyWhenJobManagerShutdown toDispatcherHATest#testPersistedJobGraphWhenDispatcherIsShutDown.This closes #7526.,3
"MINOR: Refactor the MetadataCache interface (#10887)Remove getNonExistingTopics, which was not necessary. MetadataCachealready lets callers check for the existence of topics by callingMetadataCache#contains.Add MetadataCache#getAliveBrokerNode and getAliveBrokerNodes. Thissimplifies the calling code, which always wants a Node.Fix a case where we were calling getAliveBrokers and filtering by id,rather than simply calling getAliveBroker(id) and making use of the hashmap.Reviewers: Jason Gustafson <jason@confluent.io>, Jose Sancio <jsancio@gmail.com>",5
"[FLINK-8421] [DataStream, tests] Add WindowOperator migration test for Kryo-serialized window keys",3
"[FLINK-10508] Port Savepoint relevant tests1. ""JobManagerITCase.The JobManager actor must handle trigger savepoint response for non-existing job"" -> SavepointITCase#testTriggerSavepointForNonExistingJob2. ""JobManagerITCase.The JobManager actor must handle trigger savepoint response for job with disabled checkpointing"" -> SavepointITCase#testTriggerSavepointWithCheckpointingDisabled3. ""JobManagerITCase.The JobManager actor must handle trigger savepoint response after succeeded savepoint future"": removed.mechanism guarded by SavepointITCase and other savepoint tests; no need to check message since FLIP-6 is not directly based on Akka.",3
KAFKA-9714; Eliminate unused reference to IBP in `TransactionStateManager` (#8293)Reviewers: Jason Gustafson <jason@confluent.io>,5
MINOR: docs typo in '--zookeeper myhost:2181--execute'this PR will fix a typo related to docs:http://kafka.apache.org/21/documentation.html#rep-throttle```bash$ bin/kafka-reassign-partitions.sh --zookeeper myhost:2181--execute --reassignment-json-file bigger-cluster.json —throttle 50000000```I think `myhost:2181` should be `localhost:2181` and followed by a `space`Author: opera443399 <pc@pcswo.com>Reviewers: Gwen ShapiraCloses #6704 from opera443399/docs-ops-typo,2
[FLINK-5962] [runtime-web] [tests] Replace deprecated usage og JsonNode#getValueAsTextThis closes #3679,5
[FLINK-16360][orc] Flink STRING data type should map to ORC STRING type (#11277)Hive 2.0 ORC not support schema evolution from STRING to VARCHAR.We need produce STRING in ORC for VarcharType(MAX_LENGHT) in Flink.,2
"KAFKA-9850 Move KStream#repartition operator validation during Topolo… (#8550)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-10247] Start metrics ActorSystem under metrics,5
[hotfix][connectors/jdbc] Rename JdbcDynamicOutputFormatBuilder to JdbcOutputFormatBuilder,5
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1388 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-22082][table-planner-blink] Nested projection push down doesn't work for composite types, such as row(array(row))This closes #15493",1
"KAFKA-4772: Exploit #peek to implement #print() and other methodsI remove `KeyValuePrinter` and `KStreamForeach` two class, then implements them by `KStreamPeek`.So, now `KStreamPeek` can do `KeyValuePrinter` and `KStreamForeach` job.Author: jameschien <jameschien@staff.ruten.com.tw>Author: JamesChien <jedichien@users.noreply.github.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2955 from jedichien/trunk",1
[FLINK-13286][table-api] Port RowtimeValidator and SchemaValidator to api-java-bridgeThis closes #9168,1
DUBBO-241 修改方法名git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1164 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-2023] [scala] Improve type analysis - Exclude static fields in Scala Pojo analysis - Recognize Java Tuples - Clean up legacy code(And also make one of the field type retrieval methods nicer)This closes #669,1
"Merge pull request #1672, improve LICENSE and NOTICE according to ASF policy.",1
[hotfix][docs] Add warning to K8s docs about LoadBalancer exposed type,5
[FLINK-7583] [REST] Use static constant for CONTENT_TYPE headerThis closes #4646.,1
KAFKA-8410: Migrate KStream Stateless operators to new Processor API (#10381)Migrate KStream stateless operators to new Processor API.Following PRs will complete migration of KStream stateful operators and KTable.No expected functionality changes.Reviewers: John Roesler <vvcephei@apache.org>,4
[FLINK-5421] Deduplicate code in StateHandle Iterators,0
Convert TimeoutException when invoke timeout (#8906),5
[FLINK-27567][aws][tests] Migrate connector-aws-kinesis-streams to JUnit5,3
HOTFIX: remove reference to unused Assignment error code (#7645)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
[FLINK-17599][docs] Add documents for EXPLAIN statement,2
"MINOR: fix Scala compiler warning (#6417)Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",2
[FLINK-1282] [docs] Make Flink logo link back to frontpageThis closes #237.,1
[hotfix][DataStream API] Fix checkstyle issues and JavaDocs in CheckpointListener.,2
[FLINK-15169][runtime] Hand task failures to ExecutionGraph so that the vertex state and failure cause are properly setProperly setting failure cause to Execution is needed to exhibit the taskfailure in WebUI.This closes #10541.,0
MINOR: Update jacoco to 0.8.7 for JDK 16 support (#10654)Details:* https://github.com/jacoco/jacoco/releases/tag/v0.8.6* https://github.com/jacoco/jacoco/releases/tag/v0.8.7Ran `./gradlew clients:reportCoverage -PenableTestCoverage=true -Dorg.gradle.parallel=false`successfully with Java 15 (see https://github.com/gradle/gradle/issues/15730 andhttps://github.com/scoverage/gradle-scoverage/issues/150 for the reason why `-Dorg.gradle.parallel=false` is required).Also updated `README.md` to include `-Dorg.gradle.parallel=false` alongside `reportCoverage`.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
[FLINK-12844][table-planner-blink] Use default conversion class LocalDate/LocalTime/LocalDateTime for DateType/TimeType/TimestampTypeThis closes #8762,5
MINOR: Simplify controller election utilities (#6944)This patch simplifies the controller election API. We were passing `LeaderIsrAndControllerEpoch` into the election utilities even though we just needed `LeaderAndIsr`. We also remove some unneeded collection copies `doElectLeaderForPartitions`.Reviewers: Ismael Juma <ismael@juma.me.uk>,4
[hotfix] Replace HighAvailabilityOptions#HA_ZOOKEEPER_NAMESPACE with HA_CLUSTER_ID,0
[FLINK-22593][tests] Waiting for all tasks running before triggering savepoint in SavepointITCase,1
[FLINK-14135][orc] Introduce OrcSplitReader to refactor orc input format,4
"[FLINK-11171] Avoid concurrent usage of StateSnapshotTransformerTest non concurrent access of StateSnapshotTransformerRefactor out testNonConcurrentSnapshotTransformerAccess to separte StateSnapshotTransformerTestuse element serializer from new meta info, duplicate it in rocksdb transformer factory, test concurrent access for element serializerThis closes #7320.",3
[hotfix] [tests] Stabilize AsyncCallsTest by ensuring delayed messages are not executed before their time,3
[FLINK-8719] Add module description for flink-contrib to clarify its purposeThis closes #5537.,1
[FLINK-21363][docs] Fix baseurl in documentationThis closes #14926,2
"MINOR: equals() should check _unknownTaggedFields (#8640)_unknownTaggedFields contains tagged fields which we don't understandwith the current schema.  However, we still want to keep the data aroundfor various purposes. For example, if we are printing out a JSON form ofthe message we received, we want to include a section containing thetagged fields that couldn't be parsed. To leave these out would give anincorrect impression of what was sent over the wire.  Since the unknowntagged fields represent real data, they should be included in the fieldschecked by equals().Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>",5
MINOR: Fix ThrottledReplicaListValidator doc error. (#6537)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,0
MINOR: Reinstate info-level log for dynamic update of SSL keystores (#6925)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,5
Some new unit tests for ByteBufferMessageSet iterator KAFKA-108; patched by Jun; reviewed by Nehagit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159461 13f79535-47bb-0310-9956-ffa450edef68,1
HOTFIX: fix checkstyle error of RocksDBStoreTest and flaky RocksDBTimestampedStoreTest.shouldOpenExistingStoreInRegularMode (#8515)1. Fix broken build2. Fix flaky RocksDBTimestampedStoreTest.shouldOpenExistingStoreInRegularModeReviewers: Guozhang Wang <wangguoz@gmail.com>,5
KAFKA-6065; Latency metric for KafkaZkClientMeasures the latency of each request.Updated existing `ZkUtils` test to use `KafkaZkClient`instead.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #4265 from ijuma/kafka-6065-async-zk-metrics,1
More generated Tuples up to 25.,5
"KAFKA-10764: Add support for returning topic IDs on create, supplying topic IDs for delete (#9684)Updated CreateTopicResponse, DeleteTopicsRequest/Response and added some new AdminClient methods and classes. Now the newly created topic ID will be returned in CreateTopicsResult and found in TopicAndMetadataConfig, and topics can be deleted by supplying topic IDs through deleteTopicsWithIds which will return DeleteTopicsWithIdsResult.Reviewers: dengziming <dengziming1993@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Remove redundant semicolons in `KafkaApis` imports (#6889)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-9692] [kinesis] Adaptive reads from KinesisThis closes #6300,2
[FLINK-9784] Fix inconsistent use of 'static' in AsyncIOExample.javaThis closes #6298.,1
Added README,1
"[hotfix] Move util to WebFrontedITCaseThis util is a bit questionable, so we're moving it to reduce exposure.",4
MINOR; Refactor KafkaAdminClientTest to reduce the boilerplate code (#7842)`KafkaAdminClientTest` contains many code repetitions which could be removed. This PR removes most of the boiler plate code.Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-1892] [tez] Bump Tez dependency to 0.6.1 from 0.6.0 to include tez bugfixes,0
[docs] correct yarn command-line example,2
Unify all job vertices to one type (rather than dedicated input/output types),5
[FLINK-24280] Initialize base locations for checkpoints lazily in thefirst checkpointIn FLINK-23180 we changed the initialization of base path locations toonly be called if periodic checkpoints are enabled. It worked becauseperiodic checkpoints were the only kind of checkpoints. Now we areintroducing manually triggered checkpoints which can be triggered by auser even if periodic checkpoints are disabled. That's why we need topossibly initialize the base locations on the first checkpoint that istriggered manually.,5
- adapted Pact task tests to new minimum memory requirements,1
[hotfix][javadocs] Fix typos and errors,0
"KAFKA-9308: Reworded the ssl part of the security documentation  (#8009)Reworded the ssl part of the security documentation to fix various issues (mainly as noted by this jira, the problem that SAN extension values are not copied to certificates) and add some recommendations.Reviewers: Mickael Maison <mickael.maison@gmail.com>",5
修改默认检查服务错误的问题 (#281)框架默认会检查服务是否存在，ReferenceConfig 中check 时null时则是true，而注解中的默认值为false，导致向spring解析时，对ReferenceBean 的check值没有给值，默认为处理为true，导致标签check功能失效,5
"[FLINK-15991][docs-zh] Translate the ""Set up Task Executor Memory"" page into Chinese.This closes #11401",1
[FLINK-27046][tests] Migrate avro/json schema registry to JUnit 5,3
[FLINK-5456] [docs] Add stub for types of state and state interfaces,1
MINOR: Fix typo (thread -> threads) in MirrorMaker (#10130)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
"KAFKA-4916: test streams with brokers failingSeveral fixes for handling broker failures:- default replication value for internal topics is now 3 in test itself (not in streams code, that will require a KIP.- streams producer waits for acks from all replicas in test itself (not in streams code, that will require a KIP.- backoff time for streams client to try again after a failure to contact controller.- fix bug related to state store locks (this helps in multi-threaded scenarios)- fix related to catching exceptions property for network errors.- system test for all the aboveAuthor: Eno Thereska <eno@confluent.io>Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2719 from enothereska/KAFKA-4916-broker-bounce-test",3
[hotfix][table-planner] Improve exception message for ContextResolvedTable serde,0
[streaming] JobGraphBuilder minor refactor,4
[FLINK-23309][python] Optimize the finish bundle logic to make the Python UDF results could be processed in a pipeline manner during finishBundleThis closes #16467.,5
[FLINK-5294] Make WindowOperator backwards compatible with 1.1 snapshots,1
"[FLINK-23906][tests] Increase the default akka.ask.timeout for the MiniCluster to 5 minutesThis commit sets the akka.ask.timeout, if not explicitly configured, to 5 minutes when usingthe MiniCluster. The idea behind this change is to harden all our tests that rely on the MiniClusterand run into TimeoutExceptions on our slow CI infrastructure.This closes #16921.",5
"KAFKA-9820: validateMessagesAndAssignOffsetsCompressed allocates unused iterator (#8422)https://github.com/apache/kafka/commit/3e9d1c1411c5268de382f9dfcc95bdf66d0063a0 introduced skipKeyValueIterator(s) which were intended to be used, but in this case were created but were not used in offset validation.A subset of the benchmark results follow. Looks like a 20% improvement in validation performance and a 40% reduction in garbage allocation for 1-2 batch sizes.**# Parameters: (bufferSupplierStr = NO_CACHING, bytes = RANDOM, compressionType = LZ4, maxBatchSize = 1, messageSize = 1000, messageVersion = 2)**Before:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":  64851.837 ±(99.9%) 944.248 ops/s [Average]                (min, avg, max) = (64505.317, 64851.837, 65114.359), stdev = 245.218  CI (99.9%): [63907.589, 65796.084] (assumes normal distribution)                                                                                                    ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":  164088.003 ±(99.9%) 0.004 B/op [Average]                                                                                   (min, avg, max) = (164088.001, 164088.003, 164088.004), stdev = 0.001  CI (99.9%): [164087.998, 164088.007] (assumes normal distribution)After:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":                                        78910.273 ±(99.9%) 707.024 ops/s [Average]                                                                                 (min, avg, max) = (78785.486, 78910.273, 79234.007), stdev = 183.612                                                       CI (99.9%): [78203.249, 79617.297] (assumes normal distribution)                                       ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":                                                                                                                                     96440.002 ±(99.9%) 0.001 B/op [Average]                                                                                    (min, avg, max) = (96440.002, 96440.002, 96440.002), stdev = 0.001                                                         CI (99.9%): [96440.002, 96440.003] (assumes normal distribution)    **# Parameters: (bufferSupplierStr = NO_CACHING, bytes = RANDOM, compressionType = LZ4, maxBatchSize = 2, messageSize = 1000, messageVersion = 2)**Before:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":                                        64815.364 ±(99.9%) 639.309 ops/s [Average]                                                                                 (min, avg, max) = (64594.545, 64815.364, 64983.305), stdev = 166.026                                                                                                                                                                                  CI (99.9%): [64176.056, 65454.673] (assumes normal distribution)                                                                                                                                                                                                                                                 ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":          163944.003 ±(99.9%) 0.001 B/op [Average]                                                                                   (min, avg, max) = (163944.002, 163944.003, 163944.003), stdev = 0.001                                                      CI (99.9%): [163944.002, 163944.004] (assumes normal distribution)                                     After:Result ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation"":  77075.096 ±(99.9%) 201.092 ops/s [Average]                (min, avg, max) = (77021.537, 77075.096, 77129.693), stdev = 52.223  CI (99.9%): [76874.003, 77276.188] (assumes normal distribution)                                                                                                    ""org.apache.kafka.jmh.record.RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm"":  96504.002 ±(99.9%) 0.003 B/op [Average]                                                                                    (min, avg, max) = (96504.001, 96504.002, 96504.003), stdev = 0.001  CI (99.9%): [96503.999, 96504.005] (assumes normal distribution)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
Minor performance improvement for transfer envelope queue,1
[hotfix] Rename PriorityQueueStateType.ROCKS into PriorityQueueStateType.ROCKSDB,5
[FLINK-25161][build] Update japicmp jaxb-impl dependency for Java 11+,5
[FLINK-8928] [QS] Improve server binding error message.,0
简化Spring占位符配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@804 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-3469] [docs] Improve documentation for grouping keysThis closes #1858.,2
"KAFKA-7134: KafkaLog4jAppender exception handling with ignoreExceptions (#5415)Reviewers: Andras Beni <andrasbeni@cloudera.com>, Sandor Murakozi <smurakozi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
Port streaming package to new JobGraph API and adjust all runtime-level tests,3
Merge branch 'master' of github.com:AHeise/ozone into AHeise-masterConflicts:.travis.ymlnephele/nephele-clustermanager/pom.xmlnephele/nephele-common/pom.xmlnephele/nephele-compression-bzip2/pom.xmlnephele/nephele-compression-lzma/pom.xmlnephele/nephele-compression-snappy/pom.xmlnephele/nephele-compression-zlib/pom.xmlnephele/nephele-examples/pom.xmlnephele/nephele-hdfs/pom.xmlnephele/nephele-management/pom.xmlnephele/nephele-profiling/pom.xmlnephele/nephele-queuescheduler/pom.xmlnephele/nephele-s3/pom.xmlnephele/nephele-server/pom.xmlnephele/nephele-visualization/pom.xmlnephele/pom.xmlpact/pact-array-datamodel/pom.xmlpact/pact-clients/pom.xmlpact/pact-common/pom.xmlpact/pact-compiler-tests/pom.xmlpact/pact-compiler/pom.xmlpact/pact-examples/pom.xmlpact/pact-runtime/pom.xmlpact/pact-tests/pom.xmlpact/pom.xmlstratosphere-dist/pom.xml,5
[FLINK-12975][table-planner-blink] UserDefinedFunctionUtils should distinguish overload any parameters methodsThis closes #8869,2
[FLINK-1883] [gelly] Connected Components exampleThis is a squash of the following commits:[FLINK-1883][gelly] Added Min Vertex Id Propagation library and example[FLINK-1883][gelly] Renamed algorithm to Connected Components[FLINK-1883][gelly] Made the CC library method match Spargel[FLINK-1883][gelly] Polished the CC with Randomised Edges testCloses #596,3
[streaming] Merged conflicts,5
polish 2.7.3 change list,4
"KAFKA-4724: Clean up of state directories can possibly remove stores that are about to be used by another threadDelay the cleanup of state directories that are not locked and not owned by the current thread such that we only remove the directory if its last modified is < now - cleanupDelayMs.This also helps to avoid a race between threads on the same instance, where during rebalance, one thread releases the lock on the state directory, and before another thread can take the lock, the cleanup runs and removes the data.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2486 from dguy/KAFKA-4724",5
[hotfix][core] Fix migration version comparision for 1.10,0
KAFKA-13546: Do not fail connector validation if default topic creation group is explicitly specified (#11615)Reviewers: Chris Egerton <fearthecellos@gmail.com>,1
[FLINK-2262][utils] rename method for default integer value in ParameterTool,2
"KAFKA-4684: add kafka-configs.bat for Windows boxesAdd kafka-configs.bat script for Windows.Author: huxi <huxi@zhenrongbao.com>Reviewers: Guozhang Wang, Vahid HashemianCloses #2419 from amethystic/kafka4684_offer_kafkaconfigs_script",5
[FLINK-20836][runtime] Pass total resource and default slot resource in registering TaskManager to SlotManagerThis closes #14561,4
DUBBO-121 增加@Parameter(append = true)测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@563 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Primitive type arrays have dedicated serializers now.,5
[FLINK-18989][task] Read channel state sequentiallyNon-sequential state reader and the associated code will be removed insubsequent commits.,4
Merge branch '2.7.0-release' into ConfigCenter-optimization,5
fix java8 compilation issue,0
[FLINK-1523] [gelly] Added Vertex Centric Configuration TestsThis commit squashes the following:Pratially addressed inline commentsAdded test for removal of a non-SP-edge,4
"MINOR: Fix sensor removal assertion in `MetricTest.testRemoveInactiveMetrics` (#11755)The test case `MetricTest.testRemoveInactiveMetrics` attempts to test removal of inactive sensors, but one of the assertions is checking the wrong sensor name (""test.s1"" instead of ""test.s2""). The patch fixes the assertion to use the right sensor name.Reviewers: Jason Gustafson <jason@confluent.io>Co-authored-by: zhonghou3 <zhonghou3@jd.com>",5
"HOTFIX: Correct ordering of input buffer and enforced processing sensors (#12363)1. As titled, fix the right constructor param ordering.2. Also added a few more loglines.Reviewers: Matthias J. Sax <matthias@confluent.io>, Sagar Rao <sagarmeansocean@gmail.com>, Hao Li <1127478+lihaosky@users.noreply.github.com>",1
[hotfix] [build] Force delete corrupt jar files from cache,2
"KAFKA-6733: Printing additional ConsumerRecord fields in DefaultMessageFormatter (#9099)Implementation of KIP-431 - Support of printing additional ConsumerRecord fields in DefaultMessageFormatterhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-431%3A+Support+of+printing+additional+ConsumerRecord+fields+in+DefaultMessageFormatterReviewers: David Jacot <djacot@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
KAFKA-7937: Fix Flaky Test ResetConsumerGroupOffsetTest.testResetOffsetsNotExistingGroup (#6311),3
[FLINK-24800][runtime] Changed the assert condition for checking buffer timeout disabling test,3
MINOR: Improve code style in FenceProducersHandler (#12208)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-2012] [gelly] Changed addVertices to operate on vertices onlyThis closes #678,1
[FLINK-25754][elsaticsearch] Remove unused private class,1
MINOR: remove dangling quickstart-*.html (#9721)Reviewers: Guozhang Wang <guozhang@confluent.io>,5
KAFKA-2457; Fix how the argument is passed to `compileScala`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #159 from ijuma/kafka-2457-fix,0
[FLINK-14584][python] Support ArrayType,1
"[FLINK-14014][python][table-common] Adds basic classes PythonFunction, PythonEnv, PythonFunctionInfoIntroduces basic classes such as PythonEnv, PythonFunction, PythonFunctionInfointo flink-table-common which hold the information such as the Python executionenvironment, the serialized Python functions, etc. These classes are located inflink-table-common because they will be used by the added RelNode which will beintroduced later.",1
[FLINK-8912][WebUI] Update error handling for flip6This closes #5907.,0
[FLINK-1047] Fixes main class for start-local.bat,0
"KAFKA-6567: Remove KStreamWindowReducer (#5922)This pull request removes the final reference to KStreamWindowReducer and replaces it with KStreamWindowAggregateSigned-off-by: Samuel Hawker sam.b.hawker@gmail.comcontribution is my original work and that I license the work to the project under the project's open source license.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-9808] [state backends] Migrate state when necessary in state backends,2
"[FLINK-14338][table-planner-blink] Plan verify changes from DIGEST to EXPLAIN* Because of CALCITE-3713, the project names was removed from plan DIGEST, thus, the DIGEST plan has less info that EXPLAIN, we switch to EXPLAIN for plan verification;* The CALC window fields name was also changes with CALCITE-3713, which is acceptable because the old name was also un-readable, the new name was based on field index, not bad.",1
[FLINK-26036] Only respond to TaskExecutor.freeSlot when runningThis commit changes the TaskExecutor to only respond to freeSlot when running.This avoids that during the shut down of a TaskExecutor a JobMaster free slotcall will delete the slot allocation snapshot. The JobMaster will send theserpcs because the TaskExecutor disconnects from it. It is important to keep theslot allocation snapshot in order to be able to recover this information whenrestarting the process.This closes #18684.,5
Update README.md,2
[hotfix] Add --host and --executionMode config option to ClusterEntrypointThis is necessary to support the command line syntax used by the multi masterstandalone start-up scripts.,1
[hotfix][task] Refactor the class name AvailabilityListener to AvailabilityProvider,1
[FLINK-23528][connectors/kinesis] Reenable FlinkKinesisITCase and rewrite stopWithSavepoint.,2
MINOR: Replace TopicAndPartition with TopicPartition in `Log` and `ReplicaManager`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2268 from ijuma/topicpartition-vs-topicandpartition,5
unify registry_cluster key,1
Improve the route logic.,2
[FLINK-22396][hbase] Remove unnecessary entries from shaded plugin configuration,5
[FLINK-16113][table-planner-blink] ExpressionReducer shouldn't escape the reduced string value (#11108),2
"[FLINK-19927][coordination] Enable ExecutionStateUpdateListener state updates in EG independent from legacy schedulingThe state updates for ExecutionStateUpdateListener in ExecutionGraph#notifyExecutionChange are not done at the momentbecause ExecutionGraph#notifyExecutionChange is currently enabled only for legacy scheduling.This prevents from stopping deployment tracking for execution state TM/JM reconciliation, hence it leads to memory leaks.The state update handling is supposed to be done only in SchedulerNG (DefaultScheduler), not in legacy code of ExecutionGraph.However, this generally requires more refactoring for execution deployment tracking and reconciliation.Hence, this commit just enables ExecutionStateUpdateListener state updates in ExecutionGraph#notifyExecutionChange for SchedulerNG as a quick fix,before we refactor the execution deployment tracking and reconciliation.JobMasterExecutionDeploymentReconciliationTest#testExecutionDeploymentReconciliation is also extended with the checkthat ExecutionStateUpdateListener is called and the execution deployment tracking is stopped.The commit also refactors tests in JobMasterExecutionDeploymentReconciliationTest and introduces TestingExecutionDeploymentTrackerWrapper to facilitate ExecutionDeploymentTracker call checks.This closes #13908.",3
[FLINK-16661][cli] Fix log configuration forwarding for yarn application mode,5
"[FLINK-16317][operators] Refactor AbstractStreamOperatorTest classThis deduplicates code a little bit, fixes not closing issue and makes it ready for future extension that comes in next commit.",1
[FLINK-12812] [runtime] (follow-up) Consolidate profile/memory configuration logic in ResourceManagers.,2
[hotfix][metrics] keep the non-null assumption and implement tests properlyPrevious commit in e908b62ab3 caused a regression leading to unit test failures.,0
[streaming] Updated CellInfo and BasicTopology examples,2
DUBBO-431 zookeeper注册中心增加curator集成git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1966 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][runtime] Minor clean-up in ThreasholdMeter.,4
"KAFKA-4590; SASL/SCRAM system testsRuns sanity test and one replication test using SASL/SCRAM.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2355 from rajinisivaram/KAFKA-4590",5
"[FLINK-8431] Allow to specify # GPUs for TaskManager in Mesos[FLINK-8431] Upgrade Fenzo dependency to 0.10.1[FLINK-8431] Simplify scalar aggregation[FLINK-8431] Offer::getScalarValues need not contain entries for cpus, mem, disk, and network[FLINK-8431] Floor # gpus to make sure whole numbersThis closes #5307.",1
[hotfix] Remove asm dependency from root pom,4
[FLINK-24006][tests] Stop mailbox processor before asserting the idleness when new mails arriveThis commits ensure that the MailboxExecutorImplTest#testIsIdle actuallyensure the wanted behaviour of FLINK-19109 that after the mailboxprocessor is stopped it is still possible to consume control messages(not idle).,2
[FLINK-15272][table-planner-blink] Improve exception message when insert partition with values (#10591),1
DUBBO-216 暂将dubbo-transaction移到sandboxgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@971 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fixed typo in EventCollector to correctly remove failed jobs from recentJobs list,0
加速测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@116 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: AdminClient consumer group domain objects should have public constructors (#5063)These constructors should be public to allow users to write test cases using them. We follow a similar pattern for the other domain objects that we expose in `AdminClient` (e.g. `TopicDescription`).Reviewers: Ismael Juma <ismael@juma.me.uk>,1
[hotfix][mesos] Fix the access modifiers in LaunchableMesosWorker,1
[FLINK-1560] [streaming] Streaming example ITCases cleanupThis closes #519,4
[hotfix][travis] Fix log4j configuration path,5
[hotifx][table] Improve documentation around table configThis closes #9369.,5
kafka-2033; Small typo in documentation; patched by Pierre-Yves Ritschard; reviewed by Jun Rao,2
"MINOR: SaslChannelBuilder should be idempotentAfter we call `release`, we should null out the reference sothat we neither use it or release it a second time.This should fix the following exception that has been reported:```text[2017-06-23 03:24:02,485] ERROR stream-thread [...] Failed to close consumer:  (org.apache.kafka.streams.processor.internals.StreamThread:1054)org.apache.kafka.common.KafkaException: Failed to close kafka consumer        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1623)        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1573)        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1549)        at org.apache.kafka.streams.processor.internals.StreamThread.shutdown(StreamThread.java:1052)        at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:538)Caused by: java.lang.IllegalStateException: release called on LoginManager with refCount == 0        at org.apache.kafka.common.security.authenticator.LoginManager.release(LoginManager.java:106)        at org.apache.kafka.common.network.SaslChannelBuilder.close(SaslChannelBuilder.java:125)        at org.apache.kafka.common.network.Selector.close(Selector.java:257)        at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:505)        at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.close(ConsumerNetworkClient.java:439)        at org.apache.kafka.clients.ClientUtils.closeQuietly(ClientUtils.java:71)        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1613)```It's worth noting that it's not clear how `SaslChannelBuilder.close()` is called more thanonce and it would be good to understand that as well.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3422 from ijuma/sasl-channel-builder-idempotent",5
[streaming] Updated RemoteStreamEnvironment,3
[FLINK-22562][docs-zh] Translate recent updates to backpressure docs (#15866),2
"[FLINK-20857][table-planner-blink] Introduce BatchPhysicalSortWindowAggregate & BatchPhysicalLocalSortWindowAggregate, and make BatchExecSortWindowAggregate only extended from ExecNodeThis closes #14574",1
"KAFKA-2557: separate REBALANCE_IN_PROGRESS and ILLEGAL_GENERATION error codesAuthor: Onur Karaman <okaraman@linkedin.com>Reviewers: Jiangjie Qin, Jason Gustafson, Guozhang WangCloses #222 from onurkaraman/KAFKA-2557",2
"[FLINK-12015] Fix TaskManagerRunnerTest instabilityBefore, the was a race condition between the termination future inTaskManagerRunner completing and the asynchronous shutdown part here:https://github.com/apache/flink/blob/70107c4647ecac3df9b2b8c7920e7cb99ad550f1/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java#L258The test would go out of the block that was waiting on the future butthe shutdown code that is executed after the future completes isexecuted asynchronously, so is not guaranteed to have run at that point.This also refactors the code a bit to make it more obvious what ishappening and removes the SecurityManagerContext because it wasobscuring the problem.This was analyzed by Igal and me, and mostly fixed by Igal.",0
Post-Merge fix of MockEnvironment,0
KAFKA-8126: Flaky Test org.apache.kafka.connect.runtime.WorkerTest.testAddRemoveTask (#6475)Changed the WorkerTest to use a mock Executor.Author: Attila Doroszlai <adoroszlai@apache.org>Reviewer: Randall Hauch <rhauch@gmail.com>,1
[FLINK-14806][table-runtime-blink] Add get and set interface for SqlTimestamp to BaseRow and VectorizedColumnBatchThis closes #10212,1
[hotfix][table-planner] Improved error messages in ExpressionTestBaseSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
Added first set of built-in aggregation functions for the new Java API.,1
[FLINK-11693] Deprecate old constructors in modern KafkaProducer,2
MINOR: Fix javadoc typo in Headers (#4627),2
Fixed some bugs related to writing checkpoints to a distributed file system,5
"Remove old TestBase, rename TestBase2 -> RecordAPITestBase",3
[hotfix][metrics][tests] Cleanup test,3
修改pom依赖git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@458 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-24596][core] Introduce SerializableFunction and unify usages,1
"KAFKA-5353; baseTimestamp should always have a create timestampThis makes the case where we build the records from scratch consistentwith the case where update the batch header ""in place"". Thanks toedenhill who found the issue while testing librdkafka.The reason our tests don’t catch this is that we rely on the maxTimestampto compute the record level timestamps if log append time is used.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3177 from ijuma/set-base-sequence-for-log-append-time",2
Delete repeat code (#9917),4
[streaming] [scala] ITCases for streaming scala examples,5
[FLINK-27143][docs][tests] Migrate flink-docs to JUnit 5,3
[hotfix][docs] Mention maven dependency for RocksDB state backendThis closes #5293.,5
[FLINK-6924] [table] Add Table API log() function.This closes #5638.,1
[FLINK-23054][table] Add SinkUpsertMaterialize before upsert sink to resolve change log disorderThis closes #16239,2
[hotfix] Remove code duplication in HighAvailabilityServicesUtilsIntroduce HighAvailabilityServicesUtils#loadCustomHighAvailabilityServicesFactory toremove duplicated code in createCustomHAServices and createCustomClientHAServices.,1
[FLINK-10329] Fail ZooKeeperSubmittedJobGraphStore#removeJobGraph if job cannot be removedFail properly with an exception if we cannot remove the JobGraph in ZooKeeperSubmittedJobGraphStore#removeJobGraph. This is necessary in order to notify callers about the unsuccessful attempt.,4
"KAFKA-9686: MockConsumer#endOffsets should be idempotent (#8255)Fixed issue with MockConsumer#updateEndOffsets where the input offsets were appended to existing ones instead of overwriting them. Since there's no use for adding to existing end offsets currently, MockConsumer#updateEndOffsets is simplified and MockConsumer#getEndOffset is removed after changing the value type of the member field map 'endOffsets' to Long in MockConsumerDetails in: https://issues.apache.org/jira/browse/KAFKA-9686The following flaky is fixed by this PR1. KafkaBasedLogTest.testSendAndReadToEndReviewers: Jason Gustafson <jason@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",5
[FLINK-7767] [file system sinks] Avoid loading Hadoop conf dynamically at runtime,1
Some simplifications to the PiEstimation example,5
"MINOR: Subscribe/assign calls should be logged at info level (#6299)Since we are logging offset resets and such at info level, it makes sense to use the same level for subscriptions and assignments.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
MINOR: remove streams config params from producer/consumer configsRemoving streams' specific config params from producer/consumer configs to reduce warning messages.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #906 from ymatsuda/clean_config,5
Optimize deleting file (#9907)* Optimize deleting file* Add to print lockFile name,2
kafka-1418; transient unit test failure in ProducerFailureHandlingTest; patched by Jun Rao; reviewed by Guozhang Wang and Joel Koshy,3
[FLINK-8213][metrics] Improve fallback behaviorsThis closes #8213.,1
[FLINK-13434][e2e] Change the test_resume_savepoint to use stop-with-savepoint.,1
[hotfix] Fix the version number in NOTICE and pom in table-planner-blink,2
[FLINK-21847][table] Support DESC as an abbreviation of the DESCRIBE statementThis closes #15285,1
[hotfix][hive] make hive-metastore dependency scope to 'provided' as pre-requisite to support multiple hive versionsThis closes #8560.,1
[FLINK-19908][table-planner-blink] FlinkLogicalTableSourceScan and CommonPhysicalTableSourceScan should respect source reuse config option,5
[streaming] Automerge error + License fix,0
[FLINK-20835][coordination] Add fine-grained resource management feature toggle,1
MINOR: fix RocksDBStore range searchThe range is inclusive according to KeyValueStore's java doc.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #883 from ymatsuda/minor,5
"* fixed some bugs (endless recursion in latency path construction, some NPEs)* added some toString() functions",1
"KAFKA-13008: Try to refresh end offset when partitionLag returns empty (#11057)1. When listOffset result is retrieved inside Fetcher, check if the partitions are part of the subscriptions of the consumer; if yes update the corresponding LSO or HW based on the isolation level.2. When partitionLag cannot return result since the log end offset (LSO/HW) is not known, send an async list offset which would be completed by other calls polling (also the hb thread may complete it as well), and hope the next partitionLag would get the result.3. Keep track of list-offset request sent at the subscription state level so that frequent currentLag calls would not cause excessive list-offset requests.Then on the streams side, the first partitionLag would still return empty, but soon enough the subsequent partitionLag should return data and we would not wait for the fetch response to update fetched state.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, John Roesler <vvcephei@apache.org>",5
[FLINK-25398] Show complete stacktrace when requesting thread dumpThis closes #18158.,2
[FLINK-25707] Forbid transitions from CREATED -> DEPLOYING,1
[FLINK-15912][table] Support create table source/sink by context in hive connector,1
Optimize CompletableFuture get (#8223),1
[FLINK-12226][docs] Update CLI docs for SUSPEND/TERMINATE.,2
[FLINK-7712][flip6] Implement JarDeleteHandlerThis closes #5529.,4
"KAFKA-7313; StopReplicaRequest should attempt to remove future replica for the partition only if future replica existsThis patch fixes two issues:1) Currently if a broker received StopReplicaRequest with delete=true for the same offline replica, the first StopRelicaRequest will show KafkaStorageException and the second StopRelicaRequest will show ReplicaNotAvailableException. This is because the first StopRelicaRequest will remove the mapping (tp -> ReplicaManager.OfflinePartition) from ReplicaManager.allPartitions before returning KafkaStorageException, thus the second StopRelicaRequest will not find this partition as offline.This result appears to be inconsistent. And since the replica is already offline and broker will not be able to delete file for this replica, the StopReplicaRequest should fail without making any change and broker should still remember that this replica is offline.2) Currently if broker receives StopReplicaRequest with delete=true, the broker will attempt to remove future replica for the partition, which will cause KafkaStorageException in the StopReplicaResponse if this replica does not have future replica. It is problematic to always return KafkaStorageException in the response if future replica does not exist.Author: Dong Lin <lindong28@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>Closes #5533 from lindong28/KAFKA-7313",0
"kafka-1307; potential socket leak in new producer and clean up; reviewed by Jay Kreps, Guozhang Wang and Neha Narkhede",4
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1416 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-23400][python] Support to decode a single record for the Python coderThis closes #16508.,1
[FLINK-16413][hive] Reduce hive source parallelism when limit push downThis closes #11405,2
schedule metadata retry at fixed delay,0
"[FLINK-17760][runtime, tests] Add test to verify that vertices are properly restarted on slot allocation failures",0
"MINOR: Validate the KRaft controllerListener config on startup (#11070)Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",5
[FLINK-4053] Add tests for RMQ sink and check connection for nullThis closes #2128,3
[FLINK-16456][e2e] Increase memory off heap of 'Heavy deployment end-to-end test'Increasing from default / calculated 134217728b to 200m.,3
[FLINK-6691][checkstyle] Add separate block for scala imports,2
DUBBO-340 检测 client 为 2.0.7 及以上版本才开启心跳git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1597 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix] [docs] Fix typo in best_practicesThis closes #7594.,2
"[FLINK-21928][clients] JobManager failover should succeed, when trying to resubmit already terminated job in application mode.[FLINK-21928][clients] Tolerate missing job result for already terminated jobs after JM failover in application mode.",0
"[FLINK-11449][table] Uncouple table expressions from CalciteThis commit uncouples table expressions from Calcite by switchingthe API to a new, simplified basic expression stack.Major changes:- Rename CommonExpression to Expression- Rework the function catalog to work with the newly introduced function definitions- Rework the Scala implicits and Java expression parser to return the new expression stack- Introduce an expression bridge on the edges of the API to convert to the old expression stack as a temporary solution until the old expression stack becomes obsolete- Cleanup of main API interfaces (i.e. Table.scala and expressionDsl.scala)- Ensure that SPI classes such as FilterableTableSource and TimestampExtractor still workThis closes #7664.This closes #7967.",1
[FLINK-23213][python] Move class SimpleStateRequestHandler into a separate file,2
Added support for Apache Tez as an execution environmentThis closes #189,1
[FLINK-7862] No longer send inidividual TaskManager information in an arrayFix failing WebFrontendITCase,0
[FLINK-8539] [checkpointing] (part 2) Modify all tests to use CompletedCheckpointStorageLocation.,1
[FLINK-10282][rest] Separate REST and Dispatcher RPC thread pools,2
[hotfix][docs] Fix Liquid Exception in documentationThis closes #12626,2
"MINOR: Clarify log deletion configuration options in server.propertiesI spent a bit of time tracking down why files were being deleted before they reached log.retention.hours of age. It turns out that the time and size log retention schemes function independently, and not as the original comment ""The minimum age of a log file to be eligible for deletion"" might indicate to a new user.Author: Mark Rose <markrose@markrose.ca>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #28 from MarkRose/fix_misleading_configuration_file_for_trunk",5
"KAFKA-6296; Increase jitter to fix transient failure in NetworkClientTest.testConnectionDelayDisconnectedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ted Yu <yuzhihong@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #4285 from hachikuji/KAFKA-6296",5
[FLINK-23066][table-api-java] Introduce TableEnvironment#from(TableDescriptor)This closes #16287.,2
[FLINK-17869][task][checkpointing] Ignore out of order checkpoints in SubtaskCheckpointCoordinatorCheck (by task thread) whether the current checkpoint was already aborted in the following scenario:1. on checkpoint barrier ThreadSafeUnaligner sends a mail to start checkpointing (netty thread)2. on cancellation marker CheckpointBarrierUnaligner aborts it (task thread)3. task thread processes a mail to start checkpointing,1
"MINOR: Upgrade to Scala 2.13.4 (#9643)Scala 2.13.4 restores default global `ExecutionContext` to 2.12 behavior(to fix a perf regression in some use cases) and improves pattern matching(especially exhaustiveness checking). Most of the changes are relatedto the latter as I have enabled the newly introduced `-Xlint:strict-unsealed-patmat`.More details on the code changes:* Don't swallow exception in `ReassignPartitionsCommand.topicDescriptionFutureToState`.* `RequestChannel.Response` should be `sealed`.* Introduce sealed ClientQuotaManager.BaseUserEntity to avoid false positiveexhaustiveness warning.* Handle a number of cases where pattern matches were not exhaustive:either by marking them with @unchecked or by adding a catch-all clause.* Workaround scalac bug related to exhaustiveness warnings in ZooKeeperClient* Remove warning suppression annotations related to the optimizer that are nolonger needed in ConsumerGroupCommand and AclAuthorizer.* Use `forKeyValue` in `AclAuthorizer.acls` as the scala bug preventing us fromusing it seems to be fixed.* Also update scalaCollectionCompat to 2.3.0, which includes minor improvements.Full release notes:* https://github.com/scala/scala/releases/tag/v2.13.4* https://github.com/scala/scala-collection-compat/releases/tag/v2.3.0Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
"KAFKA-10357: Extract setup of changelog from Streams partition assignor (#10163)To implement the explicit user initialization of Kafka Streams asdescribed in KIP-698, we first need to extract the code for thesetup of the changelog topics from the Streams partition assignorso that it can also be called outside of a rebalance.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",5
"[FLINK-25816][state] Remove checkpoint abortion notification of notify backendThe notification currently causes an exception and adds complexity.It's also not necessary, unlikely to be delivered (because of thedifference in checkpoint/materialization intervals) and unlikely to beutilized (it will arrive only after the nested snapshot has completedand most likely do the same GC as in completion notification).",1
MINOR: Update KTable JavaDocAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #2438 from mjsax/ktableJavaDocs,2
Started to integrate new RPC service,1
DOCS-3625: Add section to config topic: parameters controlled by Kafka Streams (#8268)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
"[FLINK-28748][docs-zh] Translate ""SELECT DISTINCT"" page into Chinese. This closes #20395* [FLINK-28748][docs-zh] Translate ""SELECT DISTINCT"" page into Chinese.",2
[FLINK-12929] Pass TypeInformation in addSourceCo-authored-by: Georg Rollinger <georg.rollinger@posteo.net>,1
"[FLINK-21028][task] Do not interrupt the source thread on stop with savepointCurrently stop with savepoint relies on the EndOfPartitionEvents propagation and performsclean shutdown after the stop with savepoint (which can produce some records to process afterthe savepoint while stopping). If we interrupt source thread, we might leave the newtork stackin an inconsitent state. So, if we want to relay on the clean shutdown, we can not interruptthe source thread.",4
Bump mina-core from 1.1.7 to 2.1.5 in /dubbo-dependencies-bom (#9899)Bumps [mina-core](https://github.com/apache/mina) from 1.1.7 to 2.1.5.- [Release notes](https://github.com/apache/mina/releases)- [Commits](https://github.com/apache/mina/compare/1.1.7...2.1.5)---updated-dependencies:- dependency-name: org.apache.mina:mina-core  dependency-type: direct:production...Signed-off-by: dependabot[bot] <support@github.com>Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>,1
FLINK-3022: Broken link 'Working With State' in Fault Tolerance Section of Stream Programming Guide,1
[hotfix] [streaming] Fix race in stream tasks when canceling tasks early.,0
[FLINK-15355][s3]Plugins now use multi-release mechanism to ship jaxb for Java 9+.,1
"MINOR: fix the way total consumed is calculated for verifiable consumer (#9143)Reviewers: Ron Dagostino <rdagostino@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
trivial change to print out last offset in DumpLogSegmentsgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179500 13f79535-47bb-0310-9956-ffa450edef68,1
"[FLINK-5040] [taskmanager] Adjust partition request backoffsThe back offs were hard coded before, which would have made itimpossible to react to any potential problems with them.This closes #2784.",0
[FLINK-20359][k8s] Added Owner Reference to Job Manager in native kubernetesThis closes #14591,3
"[FLINK-9912][JM] Release TaskExecutors if they have no slots registered at SlotPoolThis commit extends the SlotPools behaviour when failing an allocation by sending a notificationmessage to the TaskExecutor about the freed slot. Moreover, it checks whether the affectedTaskExecutor has more slots registered or not. In the latter case, the TaskExecutor's connectionwill be eagerly closed.This closes #6394.",0
"KAFKA-9290: Update IQ related JavaDocs (#8114)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Name escaping for jobmanager webfrontend,5
KAFKA-773 kafka.integration.PrimitiveApiTest fails intermittently; reviewed by Neha Narkhede,0
[FLINK-19716][Kinesis][EFO] Unable to use Assume Role with EFO record publisherThis closes #13689.,1
[FLINK-28797][hive] HiveSource enables vector reading for complex data type with parquet format,5
Added strict binary logarithm computation to math utils,2
[FLINK-16986][coordination][refactor] Change executor in OperatorCoordinatorSchedulerTestThis prepares the test to be ready to run with proper main-thread-execution in theOperatorCoordinators.,1
[streaming] MapFunction support added,1
[FLINK-21714][table] Use TIMESTAMP_LTZ as return type for function PROCTIME()This closes #15280,1
[streaming] incremental machine learning skeleton added,1
修改测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@414 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-12184][hs] HistoryServerArchiveFetcher incompatible with old versionThis closes #8313.,2
"KAFKA-5272; Policy for Alter Configs (KIP-133)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3210 from ijuma/kafka-5272-improve-validation-for-describe-alter-configs",5
Implemented custom read logic in StreamingInputGate,2
"MINOR: Remove deprecated KafkaStreams constructors in docs (#5118)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
MINOR: Fix homophone typo in Design documentationNoticed that there was a small typo in section 4.1 of the Design documentation on the [website](https://kafka.apache.org/documentation.html#majordesignelements) ('new' vs. 'knew'). This patch corrects that.Author: Chris Pinola <chris@pinola.co>Reviewers: Guozhang WangCloses #391 from chrnola/minor/design-doc-typo,2
[FLINK-8395][network] add a read-only sliced ByteBuf implementation based on NetworkBufferThis closes #5288.,1
[hotfix] [tests] Check for s3a and s3 schemes in a unit testThis avoid duplicating the very expensive and time consuming execution of theS3 file system integration tests.The scheme is an artifact purely of the factory with no need to test it inan integration test of the actual file system.,5
"KAFKA-8785: fix request timeout by waiting for metadata cache up-to-date (#11681)The reason why this test is flaky is because we have race condition at the beginning of the test, when brokers are staring up, and the adminClient is requesting for brokers metadata. Once the adminClient only got partial metadata, the test will fail, because in these tests, brokers will be shutdown to test leader election.Fix this issue by explicitly waiting for metadata cache up-to-date in waitForReadyBrokers, and let admin client get created after waitForReadyBrokers.Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",5
remove sleep in test (#12525)Remove spurious sleep in ConsumerCoordinatorTestReviewers: Ismael Juma <mlists@juma.me.uk>,3
- replaced constant value by already defined final static field in SpillingResettableIteratorTest,3
multicast注册中心增加unicast=false开关git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@629 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-21433][runtime] Pass number of slots as dynamic properties to TMs.This closes #15128,4
"[FLINK-4431] [core] Introduce a ""VisibleForTesting"" annotation.This annotation documents methods/fields that are not private because tests need them,but should not be called by any non-testing code.This closes #2390",3
"[FLINK-18071][coordination] (part 5) Communication from Coordinators to Tasks happens through gateways that are scoped to a single execution attempt.That way the events have a well specified target, no matter how much the actual sending is delayed due to raceconditions.This also un-ignores the CoordinatorEventsExactlyOnceITCase that now runs stable with this fix.",0
[hotfix][hbase] Add missed ITCase in hbase2 connector,1
[FLINK-12777][network] Extract CheckpointBarrierAligner from BarrierBuffer,4
[FLINK-2600] Enable test rerun for Elasticsearch TestsThis also bumps surefire/failsafe version to 2.8.1,0
"KAFKA-9068: Fix javadoc of Stores.{persistent,inMemory}SessionStore (#7908)Reviewer: Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-4929: Transformation Key/Value type references should be to class name(), not canonicalName()Changing getCanonicalName() references to getName() so that docs update with ""$"" instead of ""."".  Also added a connect-plugin-discovery.sh CLI to list all of the transformations available.Author: Bruce Szalwinski <bruce.szalwinski@cdk.com>Reviewers: Gwen ShapiraCloses #2720 from bruce-szalwinski/transforms and squashes the following commits:ec3b5b9 [Bruce Szalwinski] remove connect-plugin-discovery.  will submit in a different PReba0af7 [Bruce Szalwinski] Key / Value transformations are static nested classes and so are referenced using OuterClass$Key and OuterClass$Value.",1
Go back to 2.6.2-SNAPSHOT to prepare for the next release.,5
Initial checkin.,5
[refactor] Extract logCheckpointInfo,5
[FLINK-5348] [core] Add support for custom field names to RowTypeInfo.This closes #3020,5
In-memory sort operational with normal-key-sort.,5
[hotfix][runtime] Pipelined partition consumers should not be scheduled in LazyFromSourcesSchedulingStrategy#onExecutionStateChangeThe pipelined partition consumers should be already scheduled inLazyFromSourcesSchedulingStrategy#onPartitionConsumable.,4
[hotfix] Expose AllocationID as string through TaskInfo,5
[streaming] Added FlatMapInvokable,1
[FLINK-17654] Make Clock interfaces in flink-core PublicEvolving,2
[hotfix][tests] Split DataStreamAllroundTestJobFactory#setupEnvironment into smaller methods,5
[FLINK-3176] Improve documentation for window applyThis closes #1488,2
MINOR: follow up on Streams EOS system tests (#4593),3
[hotfix] [kafka] Cleanup star / unused imports in all Flink Kafka tests,3
DUBBO-377 ExceptionFilter不过滤java标准包中的异常类型git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1718 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-7113] Make ClusterDescriptor independent of cluster sizeThe deploySession method now is given a ClusterSpecification which specifies thesize of the cluster which it is supposed to deploy.Remove 2 line breaks, unnecessary parameters for YarnTestBase#Runner, add builder for ClusterSpecificationThis closes #4271.",1
MINOR: remove unused code from MessageTest (#9961)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
"[FLINK-3400] Move RocksDB Copy Utils to flink-streaming-javaThey are not specific to RocksDB, just utilities for copying localfolders to/from HDFS. Moving them to flink-streaming-java means thatthey are always in the classpath of the TaskManager, not only in theuser-code jar when using RocksDB. If they are only in the user-code jarthe external process runner cannot find the class files, leading toClassNotFoundExceptions.",2
[FLINK-9532] Flink Overview of Jobs Documentation IncorrectThis closes #6125.,2
Add LinearRegression example (Java API),1
[FLINK-6023] fix process function doc examplesThis closes #3510.,2
Update README.md,2
[streaming] Fix LICENSE file for streaming project. Minor merge fixes.This closes #72,0
"[FLINK-14971][checkpointing] Remove coordinator-wide lock of CheckpointCoordinatorSince all non-IO operations are executed in main thread, thecoordinator-wide lock could be avoided now.",4
[hotfix] [docs] Fix tEnv in tableApi docsThis closes #7254.,2
DUBBO-187 Directory增加注释AbstarctClusterInvoker 增加mockSelect方法git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1107 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-3858: Add functions to print stream topologiesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Roger Hoover, Matthias J. Sax, Guozhang WangCloses #1619 from enothereska/KAFKA-3858-print-topology",2
"[FLINK-5247] [streaming api] Fix checks for allowed lateness in windowed streamsAlso, fix outdated documentation.",2
"MINOR: Move off deprecated APIs in StreamsResetter (#11075)Reviewers: Luke Chen <showuon@gmail.com>, Bill Bejeck <bill@confluent.io>",5
[FLINK-13617] Update FlinkKafkaProducer011MigrationTest to restore from 1.9 savepointThis closes #9592.,3
[FLINK-2547] [web dashboard] Updated web dashboard after request/response changes,4
[FLINK-14343][coordination] Remove uncompleted YARNHighAvailabilityServiceThis closes #9852.,4
"[FLINK-6197] [cep] Add support for iterative conditions.So far, the where clause only supported simple FilterFunctionconditions. With this, we add support for conditions where anevent is accepted not only based on its own properties, e.g.name, as it was before, but also based on some statisticcomputed over previously accepted events in the pattern, e.g.if the price is higher than the average of the prices of thepreviously accepted events.",1
[FLINK-2170] [connectors] Add OrcRowInputFormat and OrcTableSource.This closes #4670.,1
[3.0] fix destroy IllegalStateException and doOverrideIfNecessary NPE (#8768)* fix destroy IllegalState and doOverrideIfNecessary potential NPE* add ut and fix NPE* add UT* fix ut,0
"KAFKA-4654: Improve test coverage for MemoryLRUCacheStoreAuthor: bbejeck <bbejeck@gmail.com>Reviewers: Damian Guy, Guozhang WangCloses #2500 from bbejeck/KAFKA-4654_improve_MemroryLRUCache_test_coverage",3
DUBBO-21 增加UrlUtils单元测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@164 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-1808] [streaming] Send barrier requests only when the execution graph is runningCloses #551,1
[FLINK-13523][table-planner-blink] Refactor DIVIDE function to keep it compatible with old plannerThe behavior of DIVIDE function in blink planner always return double/decimal type which is not standard.,2
"MINOR: consume from outputTopic in EosIntegrationTest.runSimpleCopyTestPreviously, the code mistakenly consumed from inputTopic, whichworked, but didn't actually verify that the messages were correctlycopied from inputTopic to outputTopic.Author: Joel Dice <jdice@mersive.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3522 from dicej/trunk",1
KAFKA-1062 Reading topic metadata from zookeeper leads to incompatible ordering of partition list; reviewed by Neha and Guozhang,5
[FLINK-1482] Add shutdown hooks to delete blob storage directories,4
[FLINK-14433][DataStream] Move generated Jaas conf file from /tmp directory to Job specific directory,2
[FLINK-27219][sql-client] Print exception stack when get errorsThis closes #19796.,0
Add unit test for BitList (#8415)* Add unit test for BitList* FIX UT,0
[FLINK-1640] Remove tailing slash from paths. Add tests for Path and FileOutputFormat.This closes #453,2
[hotfix][test] Do not hide original exception in the SourceStreamTaskTest,3
[FLINK-27042][metrics] Fix instability of StreamTaskTest#testMailboxMetricsSchedulingRemove assertion for latency measurement from StreamTaskTest#testMailboxMetricsScheduling as itcauses instability and is already covered in StreamTaskTest#testMailboxMetricsMeasurement.,3
[FLINK-21321][Runtime/StateBackends] Add ITCases for rescaling from checkpoint,1
"HOTFIX: KIP-851, rename requireStable in ListConsumerGroupOffsetsOptions",1
"KAFKA-4831: add documentation for KIP-265 (#4686)Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>",5
[FLINK-4852] Remove Non-Multiplexing StreamRecordSerializerThis also renames MultiplexingStreamRecordSerializer toStreamElementSerializer.,4
[FLINK-27233][licence] Remove the unused licence entries from Elasticsearch7 connector,1
[FLINK-20097][checkpointing] Fix race conditions in ChannelStatePersister,0
Added instance awareness in the compiler.,1
[FLINK-12353][tools] Collect japicmp output under tools/japicmp-output,2
"Remove ConfigManager operations in sub Configs, leave it to DubboBootstrap",5
[FLINK-2994] minor correction for newlines,1
[FLINK-15245][hive] Fix hive table source cannot write data to another hadoop clusterThis closes #10568,5
MINOR: Include request header in exception when correlation of request/response failsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1793 from ijuma/include-request-header-if-request-correlation-fails,0
[FLINK-20860][core] Update valid names for TaskManagerOptions#MANAGED_MEMORY_CONSUMER_WEIGHTS.This closes #14576,5
[FLINK-18695][network] Force netty to use direct buffers instead of heap buffers,1
"KAFKA-9309: Add the ability to translate Message classes to and from JSON (#7844)Reviewers: David Arthur <mumrah@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",5
[hotfix][docs] Fix the inaccessible huawei cloud  link.,2
[FLINK-6447] [docs] Update aws/emr docsThis closes #3828,2
Cleaning and commenting I/O Manager + Hashjoin incremental progress.,4
Improved robustness of spilling queue implementation,1
KAFKA-2437; Trivial follow-up,5
[FLINK-4179] [table] Update TPCHQuery3Table exampleThis closes #2232.,5
[hotfix][docs] clarify RocksDB thread options applicability per operator/TM,1
[FLINK-28951][table-planner] Make header with one line commentsThis closes #20568.,1
[FLINK-22368] Deque channel after releasing on EndOfPartition...and don't enqueue the channel if it received EndOfPartitionpreviously.Leaving a released channel enqueued may lead toCancelTaskException which can prevent EndOfPartitionEventpropagation and the job being stuck.,2
fix: custom registry port (#9298),1
[hotfix][javadocs] Fix class reference,0
[FLINK-20668][table-planner-blink] Introduce translateToExecNode method for FlinkPhysicalRelThis closes #14417,2
[hotfix] [docs] Fix UDTF join description in SQL docs.,2
[FLINK-16740][orc] Orc logicalTypeToOrcType fails to create decimal type with precision < 10This closes #11492,1
[FLINK-17970] Rename cluster.io-executor.pool-size config option into cluster.io-pool.sizeShortens the cluster.io-pool.size config option and updates the description of it.,5
Add GenericTypeComparator,1
[FLINK-22011][table-planner-blink] Use BIGINT instead of TIMESTAMP(3) for slice end column of local window aggregateThis closes #15439,1
MINOR: Improve doc string in PartitionGrouperAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>Closes #1550 from guozhangwang/Kminor-grouppartitioner-javadoc,2
MINOR: Update consumer javadoc for invalid operations on unassigned partitions  (#5005)Document cases where  `IllegalStateException` is raised when attempting an invalid operation on an unassigned partition. Also change `position()` to raise `IllegalStateException` when called on an unassigned partition for consistency.,4
Bump doc version to 0.7-incubating,2
Fixed close bug for broadcast channels,0
"HOTFIX: Missing streams jar in releaseObservation: when doing ""gradlew releaseTarGz"" the streams jar was not included in the tarball. Adding a line to include it. ijuma guozhangwang could you please review. Thanks.Author: Eno Thereska <eno.thereska@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #984 from enothereska/trunk",1
etcd3 integration test api (#3887)* etcd config center integrate test* clean code,4
[hotfix] remove Guava dependency from flink-mesos,2
[hotfix][travis] Remove unnecessary faraday installation,4
Fix metadata equals and instance listener (#8275),5
Fixed project path,0
MINOR: ConnectionStressWorker: add missing executor shutdown (#6558),1
[FLINK-16996][table] Refactor planner and runtime to use new data structuresThis closes #11925,5
[FLINK-19837][DataStream] Don't emit intermediate watermarks from watermark operators in BATCH execution modeThis closes #13853,1
TPCH Q 9 again,5
KAFKA-3684: SinkConnectorConfig does not return topics in config validation.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1356 from Ishiihara/bug-fix-validate,5
"MINOR: Update gradlew.bat as per latest gradle releaseWhen invoking `gradle` on a recent version, it updates `gradlew.bat` to fix a typo. It's an annoyance at development time as it causes a diff on whatever branch one is working on.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1034 from ijuma/update-gradlew.bat",5
[FLINK-2357] [web dashboard] Timeline for running tasks,1
[FLINK-9599][rest] RestClient supports FileUploadsThis closes #6189.,2
[hotfix][tests] Move containsCause to FlinkMatchers,2
"KAFKA-2571; KafkaLog4jAppender dies while specifying acks configAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ewen Cheslack-Postava, Gwen ShapiraCloses #231 from SinghAsDev/KAFKA-2571",5
DUBBO-155 将root节点延迟到register时创建，避免启动时在ZookeeperRegistry构造函数出现异常，并吃掉zookeeper.exists()异常，返回false，避免在if条件中抛出异常，改由create()抛出异常。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@727 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Forward fitted changes to Sopremo Packages.,4
[FLINK-21497][coordination] Only complete leader future with valid leader,2
DUBBO-970 修改lookupgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1602 1a56cb94-b969-4eaa-88fa-be21384802f2,1
set EXTENSION_LOADERS/EXTENSION_INSTANCE default size to 64 (#5812),1
[FLINK-21869][table-planner-blink] Support StreamExecTemporalSort json serialization/deserializationThis closes #15284,5
[FLINK-4638] [core] Fix exception message for MemorySegmentThis closes #2515,0
"MINOR: Define the term tombstone, since it's used elsewhere in the docs (#3480)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2
[FLINK-3051] [streaming] Add mechanisms to control the maximum number of concurrent checkpointsThis closes #1408,1
[hotfix][doc] add missing tag in catalogs.zh.md,2
[hotfix] [docs] Minor improvements to the 'building form source' guide.,1
[Typo] Delete DiscardingOuputFormatThis closes #343,4
Adapted code in combining unilateral sort-merger and associated test case.,3
[hotfix] Introduce ExecutionGraphHandler to factor out ExecutionGraph logic from the SchedulerBase,2
[FLINK-19986] Skip license check for scala 2.12 profile,2
[hotfix] [gelly] Reduce maximum number of generator blocksThe default maximum akka transfer size is 10 MB. This commit reduces thenumber of generator blocks from 2^20 to 2^15 which removes the limit ongraph size. The original limit of one millions blocks was intended tofuture-proof scalability.This is a temporary fix as graph generation will be reworked in FLINK-3997.,2
"Revert ""[FLINK-21796] Temporarily disable SQLClientKafkaITCase""This reverts commit 18a9f02fa2c34c36ea29b9f607b88668cf04194d.",4
[FLINK-6893] [table] Add BIN function supportThis closes #4128.,1
[FLINK-7811] Fix japicmp exclusion patternIt seems \$ doesn't work but $$ does. I noticed this when changingDataStream.scala.,5
[FLINK-26185] Update Elasticsearch7SinkExample to use new unified Sink interface,1
[FLINK-19656][metrics] Automatically replace delimiter characters in identifier and logical scope,2
[hotfix][build] Remove disabled checkstyle rules,4
[FLINK-24781][table-planner] Add string parsing methods to BinaryStringDataUtil and add from string cast rulesSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix] Remove exception suppression from Dispatcher#stopDispatcherServices,4
[FLINK-14727][hive][doc] update doc of supported Hive versionsthis closes #10165.,1
[FLINK-23186][docs] improve installation pageThis closes #16414,1
Added test case for PactNull datatype,5
[hotfix][runtime] Refactor ResourceManager#onTaskManagerRegistration argument type.,4
"KAFKA-10702; Skip bookkeeping of empty transactions (#9632)Compacted topics can accumulate a large number of empty transaction markers as the data from the transactions gets cleaned. For each transaction, there is some bookkeeping that leaders and followers must do to keep the transaction index up to date. The cost of this overhead can degrade performance when a replica needs to catch up if the log has mostly empty or small transactions. This patch improves the cost by skipping over empty transactions since these will have no effect on the last stable offset and do not need to be reflected in the transaction index.Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",5
"KAFKA-2984: KTable should send old values when requiredguozhangwangAt DAG level, `KTable<K,V>` sends (key, (new value, old value)) to down stream.  This is done by wrapping the new value and the old value in an instance of `Change<V>` class and sending it as a ""value"" part of the stream. The old value is omitted (set to null) by default for optimization. When any downstream processor needs to use the old value, the framework should enable it (see `KTableImpl.enableSendingOldValues()` and implementations of `KTableProcessorSupplier.enableSensingOldValues()`).NOTE: This is meant to be used by aggregation. But, if there is a use case like a SQL database trigger, we can add a new KTable method to expose this.Author: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #672 from ymatsuda/trigger",5
[FLINK-22136][e2e] Odd parallelism for resume_externalized_checkpoints was added to run-nightly-tests.sh.,3
More graceful failing/errors/logging when canceling in early job stages,2
[FLINK-7030] Build with scala-2.11 by defaultThis closes #4209.,2
[FLINK-24245][python] Fix the problem caused by multiple jobs sharing the loopback mode address stored in the environment variable in PyFlinkThis closes #17239.,2
[hotfix][table] Make use of VarCharType.STRING_TYPEReplace occurrences of `new VarCharType(MAX_LENGTH()` with new constant`VarCharType.STRING_TYPE`.,2
[hotfix][runtime] Replace Arrays.asList() with Collections.singletonList(),0
[hotfix][table-planner] Clean up serde classes,4
[FLINK-5448] [checkpoints] Fix typo in StateAssignmentOperation ExceptionThis closes #3097,2
[FLINK-16152][doc-zh] Translate dev/datastream/operators/overview.md into ChineseThis closes #16889.,1
MINOR: Fix typo and tweak wording in `RecordAccumulator` commentsThis was recently introduced in:https://github.com/apache/kafka/commit/1fbe445dde71df0023a978c5e54dd229d3d23e1bAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>Closes #1152 from ijuma/fix-typos-in-record-accumulator,2
"KAFKA-4526; Disable throttling test until it can be fixed correctly.At present, the test is fragile in the sense that the console consumerhas to start and be initialized before the verifiable producer beginsproducing in the produce-consume-validate loop.If this doesn't happen, the consumer will miss messages at the head ofthe log and the test will fail.At present, the consumer is considered inited once it has a PID. This isa weak assumption. The plan is to poll appropriate metrics (likepartition assignment), and use those as a proxy for consumerinitialization. That work will be tracked in a separate ticket. For now,we will disable the tests so that we can get the builds healthy again.Author: Apurva Mehta <apurva.1618@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2278 from apurvam/KAFKA-4526-throttling-test-failures",3
"KAFKA-12265; Move the BatchAccumulator in KafkaRaftClient to LeaderState (#10480)The KafkaRaftClient has a field for the BatchAccumulator that is only used and set when it is the leader. In other cases, leader specific information was stored in LeaderState. In a recent change EpochState, which LeaderState implements, was changed to be a Closable. QuorumState makes sure to always close the previous state before transitioning to the next state. This redesign was used to move the BatchAccumulator to the LeaderState and simplify some of the handling in KafkaRaftClient.Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-21300][docs][table] Update function module related documentation (#15230),2
[FLINK-20756][python] Fix the bug that it doesn't support field access of expression containing Python UDF in the condition of CalcThis closes #14492.,5
[FLINK-18721][yarn] Introduce YarnResourceManagerDriver,2
"KAFKA-10729; Bump remaining RPC's to use tagged fields. (#9601)As a follow-up from [KIP-482](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields), this PR bumps the version for severalRPC's to enable tagged fields via the flexible versioning mechanism.Additionally, a new IBP version `KAFKA_2_8_IV0` is introduced toallow replication to take advantage of these new RPC versions forOffsetForLeaderEpoch and ListOffset.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
[hotfix] [kafka connector] Replace funky loop with simple division in FixedPartitioner,0
Update implementation.html (#10771)Fixing the link to a cited blog. The existing link now points to a steroid website so need to pull the blog from internet archives.,2
Reduced NIO timed waiting interval to 10 ms,5
[hotfix] Use Flink's FileUtils in BlobUtils to have proper exception handling,2
[hotfix] [tests] Remove unnecessary stack trace printing in StreamTaskTest,3
"[FLINK-17782] Add array,map,row types support for parquet row writerThis closes #17542",1
"KAKFA-13699: new ProcessorContext is missing methods (#11877)We added `currentSystemTimeMs()` and `currentStreamTimeMs()` to the`ProcessorContext` via KIP-622, but forgot to add both to the new`api.ProcessorContext`.Reviewers: Ricardo Brasil <anribrasil@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-13323; Fixed variable name in KafkaConsumer (#11558)Fixes a misspelled variable name in `KafkaConsumer`: `cachedSubscriptionHashAllFetchPositions` -> `cachedSubscriptionHasAllFetchPositions`.Reviewers: Kvicii <Karonazaba@gmail.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Remove `activeTaskCheckpointableOffsets` from `AbstractTask` (#7253)Reviewers: cpettitt-confluent <53191309+cpettitt-confluent@users.noreply.github.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-6261; Fix exception thrown by request logging if acks=0Only expect responseAsString to be set if request logging isenabled _and_ responseSend is defined.Also fixed a couple of issues that would manifest themselvesif trace logging is enabled:- `MemoryRecords.toString` should not throw exception if data is corrupted- Generate `responseString` correctly if unsupported api versions request isreceived.Unit tests were added for every issue fixed. Also changedSocketServerTest to run with trace logging enabled asrequest logging breakage has been a common issue.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4250 from ijuma/fix-issues-when-trace-logging-is-enabled,2
"[FLINK-14992] Extend test coverage of JobListenerITCaseThis changes the test to use a MiniClusterResource to be more efficient.This adds test coverage for the executeAsync() methods.This verifies that we call the job listeners from the main executionthread, which is important for some frameworks such as Zeppelin support.",1
[FLINK-11601] Remove legacy JobManagerGatewayThis closes #7741.,4
Improved code quality,1
add apiVersion to override url,1
Add Count and Delta  WindowPolicy,1
"[FLINK-6177] Add support for ""Distributed Cache"" in streaming applicationsThis closes #3741.",1
"KAFKA-7853: Refactor coordinator config (#6854)An attempt to refactor current coordinator logic.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-4089][yarn] fix null check in Yarn client,0
TRIVIAL: Fix misc. numerical issues in histogram.,0
[FLINK-22667][docs] Add missing slash,1
[FLINK-8804][build] Bump flink-shaded-jackson version to 3.0This closes #5596.,2
KAFKA-10188: Prevent SinkTask::preCommit from being called after SinkTask::stop (#8910),5
[FLINK-17407] Forward extended resource request to YARN.,2
[FLINK-10987] Add license notices for flink-filesystems,5
"MINOR: Add more info to RecordCollector error messageguozhangwangAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #873 from ymatsuda/hotfix",0
[streaming] Pojo wordcount example added to streaming,1
"KAFKA-12305: Fix Flatten SMT for array types (#10074)Reviewers: Nigel Liang <nigel@nigelliang.com>, Tom Bentley <tbentley@redhat.com>",0
avoid repeat init of dynamicconfiguration,5
"MINOR: Store metrics scope, total metrics (#5290)1. Rename metrics scope of rocksDB window and session stores; also modify the store metrics accordingly with guidance on its correlations to metricsScope.2. Add the missing total metrics for per-thread, per-task, per-node and per-store sensors.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-8489][ES] Prevent side-effects when modifying user-configThis closes #5378.This closes #4847.This closes #5305.This closes #5208.This closes #2192.This closes #2422.This closes #3478.,5
add visual-studio-code ignore (#6221) (#6287)(cherry picked from commit 83afabeda133a4cac2e4e0a55c8b4d69b2b9f4aa)Co-authored-by: oaoit <oaoist@gmail.com>,1
[hotfix] [tests] Update log4j-test.propertiesBrings the logging definition in sync with other projects.Updates the classname for the suppressed logger in Netty to account for the newshading model introduced in Flink 1.4.,2
"KAFKA-10727; Handle Kerberos error during re-login as transient failure in clients (#9605)We use a background thread for Kerberos to perform re-login before tickets expire. The thread performs logout() followed by login(), relying on the Java library to clear and then populate credentials in Subject. This leaves a timing window where clients fail to authenticate because credentials are not available. We cannot introduce any form of locking since authentication is performed on the network thread. So this commit treats NO_CRED as a transient failure rather than a fatal authentication exception in clients.Reviewers: Ron Dagostino <rdagostino@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
- fixed PactRecord.updateBinaryRepresentation for tailing null fields- added test case,3
[FLINK-13624][Tests] Update StatefulJobWBroadcastStateMigrationITCase to restore from 1.9 savepointThis closes #9626.,5
"MINOR: Fix comment in FinalizedFeatureChangeListener.initOrThrow (#9562)Fixed the param doc in FinalizedFeatureChangeListener.initOrThrow method. The parameter waitOnceForCacheUpdateMs is expected to be > 0, but the doc was incorrect.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
[FLINK-2019] Use a properly instantiated Kryo in the GenericTypeComparatorThis closes #679,1
#1067: I18N effort for dubbo code base - dubbo-rpc (part1),5
[hotfix][kafka][es] Add missing @PublicEvolving annotation on Kafka and Elasticsearch descriptor class,1
[hotfix][tests][connector/kafka] Disable KafkaSink metric tests until FLINK-26126 has been fixed,0
[FLINK-11476] [SQL/TABLE] Create CatalogManager to manage multiple catalogs and encapsulate Calcite schema,2
[FLINK-20752][coordination] Properly respect max-failures-per-interval,0
[hotfix] [webfrontend] Rebuild,0
fix method name typo: convertMethodConfig2AsyncInfo,5
"[hotfix][runtime] Smaller cleanup of Mailbox and ensuring state changingoperation may only occur through the mailbox thread, such that statechecks do not any kind of synchronizations.",4
[FLINK-25391][connector-kafka] Forward catalog table options,2
"[FLINK-29096][table] Add test for json_value, which json path has blank characters.This closes #20675",5
[FLINK-5745] [network] Set uncaught exception handler for Netty threadsThis sets a JVM-terminating handler that logs errors from uncaught exceptionsand terminates the process so that critical exceptions are not accidentallylost and leave the system running in an inconsistent state.This closes #3293.,1
Improved logging,2
[hotfix][test] Remove unused waitUntilJobInitializationFinished of TestUtilsThis closes #19114.,3
"KAFKA-13672: Race condition in DynamicBrokerConfig (#11920)Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",5
Minor renaming of compiler hint,5
MINOR: fix Scala 2.12 compile failure in ControllerApisTest (#11043)Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>,3
"[hotfix] [FLINK-3679] Improve Javadocs of DeserializationSchemasJavadocs of the `deserialize(...)` method should inform that returningnull from the method is allowed, if the message cannot be deserialized.",1
[hotfix][runtime] Remove legacy NoOpIOManager class,4
- added missing Apache Headers,1
[hotfix][docs] Fix typo,2
polish code,1
Introduced unknown receiver events to signalize delivery failures to the sender,0
[hotfix][coordination] Add execution state to RestartPipelinedRegionFailoverStrategyTest,3
Added implementation for S3 input streams plus tests and javadoc improvements,1
[FLINK-9674][tests] Replace hard-coded sleeps in QS E2E testThis closes #6216.This closes #6025.This closes #5297.This closes #6211.This closes #5899.This closes #5888.This closes #5901.,3
Added negative tests for TestPlan,3
[FLINK-13905][checkpointing] Unify all error handlings of checkpoint failureThere are so many similar entrances for error handling of checkpoint failure.So here unified these methods into abortPendingCheckpoint(s).,0
[hotfix] Fix Table API doc typo,2
MINOR: Move `Os` class to utils package and rename it to OperatingSystemThe `common` package is public and this class isinternal.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2759 from ijuma/move-os-to-utils,4
"MINOR: Optimize KTable-KTable join value getter supplier (#4458)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <mjsax@apache.org>",1
"KAFKA-10153: Error Reporting in Connect Documentation (#8858)Added a section about error reporting in Connect documentation, and another about how to safely use the new errant record reporter in SinkTask implementations.Author: Aakash Shah <ashah@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"KAFKA-5922: Add SessionWindowedKStreamAdd `SessionWindowedKStream` and implementation. Deprecate existing `SessionWindow` `aggregate` methods on `KGroupedStream`Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3902 from dguy/kafka-5922",5
[FLINK-10983][queryable state] Increase port range for NonHAQueryableStateFsBackendITCaseThis closes #7159,1
"[FLINK-3701] enable reuse of ExecutionConfigDepending on the context, the ExecutionConfig's type fields may eitherbe deserialized using a custom class loader or the default classloader. It may be explicitly serialized for the Task or shipped insidethe PojoSerializer where it is serialized or directly passed in localmode. An ExecutionConfig may be reused and thus its fields can't be setto null after it has been shipped once.The entire ExecutionConfig is now serialized upon setting it on theJobGraph. It is not passed through the JobGraph's constructor but setexplicitly on the JobGraph. If no ExecutionConfig has been set, thedefault is used. Unlike before, no code may modify the ExecutionConfigafter it has been set on the JobGraph.This closes #1913",1
"MINOR: Fix LogDirFailureTest flakeEnsure that `TestUtils.waitUntilTrue(..)` is blocked on both send completed and a new leader being assignedAuthor: Gardner Vickers <gardner@vickers.me>Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Dong Lin <lindong28@gmail.com>Closes #5695 from gardnervickers/log-dir-failure-test-fix",3
[FLINK-5830] [distributed coordination] Handle OutOfMemory and fatal errors during process async message in akka rpc actorThis closes #3360,0
"KAFKA-13986; Brokers should include node.id in fetches to metadata quorum (#12498)Currently we do not set the replicaId in fetches from brokers to the metadata quorum. It is useful to do so since that allows us to debug replication using the `DescribeQuorum` API.Reviewers: dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"revert stream logging level back to ERROR (#10320)An accidental change of logging level for streams from #9579, correcting it.Reviewers: Bill Bejeck <bbejeck@gmail.com>",2
[FLINK-8409] [kafka] Fix offset committing race condition in KafkaConsumerThreadThis closes #5329.,1
[FLINK-5933] Allow Evictor for merging windows,1
修改demogit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1745 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[minor] Remove empty check in ConfigUtils#encodeCollectionToConfig(),5
KAFKA-7785: move internal DefaultPartitionGrouper (#10302)Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
[FLINK-23914][connector/testing-framework] Add INFO log to track running stage of connector testing framework,1
[FLINK-26206][runtime-web] add service layer abstraction and refactor config service,5
"fix telnet trace times is always 1 (#3038)* fix telnet trace times is always 1* use StringUtils determine if the string is empty* Fix 3105 , make invoke command with Json string parameter without ""class"" key* Fix 3105 ，Keep the class key to support overloaded methods* optimize InvokerTelnetHandlerTest",3
MINOR: Update consumer group command documentation with additionally supported options (#4462)With KIP-175 there are a number of consumer group command options that can be used to describe a consumer group.This PR updates the documentation on consumer group command to mention those options.,2
"KAFKA-6534: Enforce a rebalance in the next poll call when encounter task migration (#4544)The fix is in two folds:For tasks that's closed in closeZombieTask, their corresponding partitions are still in runningByPartition so those closed tasks may still be returned in activeTasks and standbyTasks. Adding guards on the returned tasks and if they are closed notify the thread to trigger rebalance immediately.When triggering a rebalance, un-subscribe and re-subscribe immediately to make sure we are not dependent on the background heartbeat thread timing.Some minor changes on log4j. More specifically, I moved the log entry of closeZombieTask to its callers with more context information and the action going to take.I can re-produce the issue with EosIntegrationTest may hand-code the heartbeat thread to GC, and confirmed this patch fixed the issue. Unfortunately this test cannot be added to AK since currently we do not have ways to manipulate the heartbeat thread in unit tests.Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"[FLINK-28623][network] Optimize the use of off-heap memory by blocking and hybrid shuffle readerCurrently, each FileReader (PartitionFileReader or HsSubpartitionFileReaderImpl) will internally allocate a headerBuffer with the size of 8B. Besides, PartitionFileReader also has a 12B indexEntryBuf. Because FileReader is of subpartition granularity, if the parallelism becomes very big, and there are many slots on each TM, the memory occupation will even reach the MB level. In fact, all FileReaders of the same ResultPartition read data in a single thread, so we only need to allocate one headerBuffer for each ResultPartition to optimize it.This closes #20333.",5
Added normalized key direction inversion to normalized key sorter.,1
'continue' statement is unnecessary as the last statement in a loop (#3046)'continue' statement is unnecessary as the last statement in a loop,5
"[FLINK-5426] [ml] Clean up the Flink Machine Learning libraryRemoved duplicate tests, inproved scaladoc and naming, removed typo's in scaladoc, introduced and improved use of constants, improved test-case naming.This closes #3081.",3
DUBBO-505 客户端路由的条件没有匹配消费者地址，而误匹配了注册中心地址,5
"Updated DEPENDENCIES, NOTICE and LICENSE files.",2
[FLINK-11861][tests] Fix JobMasterTriggerSavepointIT not executedThis closes #7943.,0
KAFKA-3209: KIP-66: more single message transformsRenames `HoistToStruct` SMT to `HoistField`.Adds the following SMTs:`ExtractField``MaskField``RegexRouter``ReplaceField``SetSchemaMetadata``ValueToKey`Adds HTML doc generation and updates to `connect.html`.Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2374 from shikhar/more-smt,5
Fixed Window Size Bug in Partial Sorter.,0
[FLINK-20525][python] Fix StreamArrowPythonGroupWindowAggregateFunctionOperator incorrect handling of rowtime and proctime fieldsThis closes #14327.,1
[FLINK-19417][python] Fix the implementation of StreamTableEnvironment.from_data_streamThis closes #13491.,5
[FLINK-16186][es][tests] Reduce connect timeout to 5 seconds,3
DUBBO-402 开源http协议支持timeout和client属性配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1979 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-10549][tests] Remove Legacy* tests,3
[FLINK-20534] Add Flink 1.12 MigrationVersion,2
[hotfix] [docs] Fix Java typo in dataset transformations docThis closes #4300,2
[FLINK-28720][hive][connectors] Add Hive partition when flink has no data to write (#20394),5
[FLINK-6034] [checkpoints] Introduce KeyedStateHandle abstraction for the snapshots in keyed streams,0
"KAFKA-6101; Reconnecting to broker does not exponentially backoffAuthor: tedyu <yuzhihong@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Soenke Liebau <soenke.liebau@opencore.com>, Ismael Juma <ismael@juma.me.uk>Closes #4118 from tedyu/trunk",1
"[FLINK-17552][network] Do not cache InputChannels in UnionInputGateThis is a simple fix for a bug on the master branch that is not visible currently in anyway, but which is causingan inconsistent state with UnionInputGate if underlying channels are updated inside SingleInputGate",5
Merge pull request #596 from yuyijq:refactoroverridenotify这里每个服务export的时候都会订阅一个OverrideListener，那么configurators节点发生变动的时候，每个服务的OverrideListener都会触发，那每个服务的OverrideListener去修改自己就好了，为什么要把bounds里全拿出来呢？还增加了出bug的几率,5
[FLINK-10406][tests] Port JobManagerTest#testSavepointRestoreSettingsPort JobManagerTest#testSavepointRestoreSettings to JobMasterTest#testRestoringModifiedJobFromSavepoint.,3
Removed compiler error check in PactConnection#setShipStrategy,1
"MINOR: add useConfiguredPartitioner and skipFlush options for ProduceBenchAdd a ""useConfiguredPartitioner"" boolean to specify testing with the configured partitioner, rather than overriding the partitioner in the test.Add a ""skipFlush"" boolean to specify skipping the flush operation when producing.  This is helpful when testing some scenarios where linger.ms is greater than 0.Reviewers: Colin P. McCabe <cmccabe@apache.org>",3
[FLINK-22464][runtime][tests] Disable a test failing with AdaptiveScheduler tracked in FLINK-22464,2
[FLINK-8055][QS] Deduplicate logging messages about QS start.,2
"Merge pull request #3062, code review around RouterFactory.* code review around RouterFactory* update javadoc for Router* clean up RouterChain* refactor, typo correct around ConfigParser* correct logic* reformat logging message, and remove useless import* remove enabled status from AbstractRouter* remove isEnabled()* refactor TagRouter",4
[hotfix] Simplify SlotSharingManagerTest by introducing factory method,3
[FLINK-8425][network] fix SpilledSubpartitionView not protected against concurrent release callsThis closes #5314.,0
[FLINK-10139][tests] Update compatibility tests for 1.6,3
Remove custom.md.,4
[FLINK-12078][network] Abstract TaskEventPublisher interface for simplifying NetworkEnvironment,1
[hotfix] Simplify logic which duplicates TaskExecutorResourceUtils#deriveManagedMemoryAbsoluteOrWithFraction and calls it again,2
"[FLINK-8119] [flip6] Wire correct Flip6 components in Flip6YarnClusterDescriptorLet the Flip6YarnClusterDescriptor create a RestClusterClient as ClusterClient.Moreover, this commit makes the YarnResourceManager register under the REST portat Yarn.This closes #5234.",1
"[FLINK-8769][flip6] do not print error causing exceptions without debuggingIn DispatcherRestEndpoint and TaskExecutor, there were two places where withouterrors (running a job inside an IDE) exceptions were logged. While for debuggingthey may be useful, for normal operation it is enough to print the messagesthemselves, especially since some more details were already logged before.This closes #5611.",2
[FLINK-4214] [web dashboard] Properly increment the exceptions counterThis closes #2242,2
修改demogit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1617 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[streaming] Added MockCoInvokable, replaced environments with it in CoFunction tests",3
Merge branch 'dima'Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/services/memorymanager/spi/DefaultMemorySegment.javapact/pact-runtime/pom.xmlpom.xml,5
[hotfix][metrics] Harden JMXAvailability test,3
[hotfix][yarn] Extract some common codes of TaskManagerRunner to public methods and simplify YarnTaskExecutorRunner,1
- Split up ResettableIterator interface- Fixed multi input bug for CrossTask,0
[FLINK-23562][CI] Update CI JDK to 1.8.0_292,5
Add Pregelsphere,1
[hotfix][Javadoc] Make first sentence in JobSubmissionException Javadoc end with period,2
"Revert ""[FLINK-23984][python][tests] Temporary disable the PyFlink end to end tests due to Python 3.7 was removed from debian""This reverts commit 3555741a12ba9fb65e8db9f731a131ab39d1cfe8",5
"[FLINK-18222][e2e] Stabilize Avro Confluent Schema Registry nightly testThe test was unstable because the broker tried to connect to ZK before ZK was running.With this change, we wait for ZK to be running before proceeding.This closes #13248",1
"[FLINK-21778][network] Use heap memory instead of direct memory as index entry cache for sort-merge shuffleCurrently, the sort-merge shuffle implementation uses a piece of direct memory as index entry cache for acceleration. This patch switches to heap memory instead to reduce the consumption of direct memory which can further reduce the possibility of OutOfMemoryError. Heap memory is better because the default direct memory size of Flink is only 128M which is quite small.",2
"MINOR: fix parameter naming (#6316)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Added generic versions of contracts.,1
[hotfix][typo]Fix typo in RelationalQueryCompilerTest and TpcdsTestProgramThis closes #11841,3
KAFKA-683 Fix correlation id in all requests sent to kafka; reviewed by Jun Rao,0
KAFKA-9831: increase max.poll.interval.ms to avoid unexpected rebalance (#10301)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[FLINK-7111] [scala-shell] Disable external jar testThis closes #4288.,3
Continued to work on integration of new RPC service,1
[hotfix] Improved logging for task local recovery,2
[FLINK-24307][docs] Cleanup Scala examples,4
[FLINK-18906][hotfix] Fix JavaDoc for in InputProcessorUtil,2
[FLINK-3201] Add operator state to make change backwards compatible,4
[FLINK-1638] [streaming] Seperated AbstractRecordReader for streaming and batch,2
enhancement: extract duplicated method calls to variable (#3482)extract duplicated method calls to variable,4
先注释掉服务提供方的Listenergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1483 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-22863][runtime] Fix ArrayIndexOutOfBoundsException when building rescale edges in EdgeManagerBuildUtilThis closes #16071,0
[FLINK-11545] [container] Parse job ID in StandaloneJobClusterConfigurationParserFactory[pr-review] Make getJobId static[pr-review] Add expected format and example to error messageFix checkstyleDon't wrap JobID.fromHexString error message in StandaloneJobClusterConfigurationParserFactory[pr-review] Add test for short options,3
[FLINK-20805][table][build] Apply spotless formatting,2
[docs] fix typos in Basic Concepts documentationCloses #1730,2
"MINOR: Increase the amount of time available to the `test_verifiable_producer` (#9201)Increase the amount of time available to the `test_verifiable_producer` test to login and get the process name for the verifiable producer from 5 seconds to 10 seconds.We were seeing some test failures due to the assertion failing because the verifiable producer would complete before we could login, list the processes, and parse out the producer version. Previously, we were giving this operation 5 seconds to run, this PR bumps it up to 10 seconds. I verified locally that this does not flake, but even at 5 seconds I wasn't seeing any flakes. Ultimately we should find a better strategy than racing to query the producer process (as outlined in the existing comments). Reviewers: Jason Gustafson <jason@confluent.io>",5
[hotfix] [tests] Let BucketingSink extend TestLogger,3
[hotfix] Properly declare ComplexIntegrationTest as an Integration Test Case,3
[FLINK-22651][python][table-planner-blink] Support StreamExecPythonGroupAggregate json serialization/deserializationThis closes #15928.,5
[hotfix][test] Drop mockito usage from BarrierTrackerTest,3
[streaming] Adjust pom.xml to match new repo,1
[FLINK-17017][runtime] Introduce BulkSlotProvider which allocates physical slots in bulks,1
[FLINK-5109] [webfrontend] Fix invalid content-encodingThis closes #2898,0
DUBBO-556 心跳日志过多。由INFO改成DEBUG,5
Fix MetadataInfo Module (#8818),5
Address review comments,1
[FLINK-27767][sql-gateway] Introduce Endpoint API and utils (#19849),2
"KAFKA-5290; Docs need clarification on meaning of 'committed' to the logbased on conversations with vahidhashemian rajinisivaram apurvamThe docs didn't make clear that what gets committed and what gets not may depend on the producer acks.Author: Edoardo Comar <ecomar@uk.ibm.com>Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #3035 from edoardocomar/DOC-clarification-on-committed",2
[FLINK-20235][hive][parquet] Parquet lack additional dependencies after bumpingThis closes #14189,1
- replaced HDFS's API classes by Nephele's API,5
[FLINK-19026][network] Removing unnecessary priority flag on output side.The priority information is fully incorporated in Buffer.DataType now.,5
[FLINK-24804][FLINK-25505] Upgrade oshi-core to version 6.1.5,2
KAFKA-12892: Disable testChrootExistsAndRootIsLocked (#10820)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
[FLINK-8597] Add examples for Connected Streams with Broadcast State.This closes #5425.,1
MINOR: remove stream simple benchmark suite (#8353)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Add back section taken out by mistake (#9544)Reviewers: Matthias J. Sax <mjsax@apache.org>,1
new pull,1
[hotfix] Fix checkstyle violations in MessageSerializationTest,3
Fixed data race problem in FileInputFormat.,2
[FLINK-16302][rest] Enable retrieval of custom TaskManager log filesAdd log list handler which lists all files in TaskManager log directory. Enableretrieval of custom TaskManager log files by name.This closes #11250.,2
[FLINK-1218] Replace new Integer with Integer.valueOf in testsThis closes #183.,3
"KAFKA-13071; Deprecate support for changing acls through the authorizer (#11502)This patch marks the following arguments as deprecated in kafka-acls.sh as documented in [KIP-604](https://cwiki.apache.org/confluence/display/KAFKA/KIP-604%3A+Remove+ZooKeeper+Flags+from+the+Administrative+Tools): --authorizer, --authorizer-properties, and --zk-tls-config-file.Reviewers: David Jacot <djacot@confluent.io>",5
"KAFKA-9274: Add timeout handling for `StreamPartitioner` (#9997) Part of KIP-572: When a custom `StreamPartitioner` is used, we need to get the number of partitions of output topics from the producer. This `partitionFor(topic)` call may through a `TimeoutException` that we now handle gracefully.Reviewers: John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",5
make UTs work,1
[FLINK-6861][metrics] Use OperatorID in metric systemThis closes #4849.,5
修改版本为2.1.0-SNAPSHOTgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@811 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Added code to trigger chaining event,5
"Fix NepheleJobGraphGenerator bug with iterationsWhen traversing it is not checked whether iterations where alreadyvisited, this led to a bug when you used the output of an iterationtwice.",1
[streaming] Introduced extractor interface to enable flexible handling of arbitrary input data types.,5
"[FLINK-5390] [yarn] Fix for proper closing input and output streams, in case of errorsThis closes #3045",0
[hotfix] Improve performance of GenericArraySerializer.copy(),1
[FLINK_13475][hive] Reduce dependency on third-party maven repositoriesThis closes #9337,2
[FLINK-10493] [scala] Rename SpecificCaseClassSerializer to ScalaCaseClassSerializerThis closes #7658.,2
[FLINK-13718][hbase] Disable tests on Java 11,3
Merge branch 'warneke_v2' into pact v2 branchConflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/checkpointing/CheckpointDecisionCoordinator.java,5
"KAFKA-4486: Don't commit offsets on exceptionAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Matthias J. Sax, Damian Guy, Guozhang WangCloses #2225 from enothereska/KAFKA-4486-exception-commit",1
KAFKA-3014: fix integer overflow problem in leastLoadedNodeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang WangCloses #696 from hachikuji/KAFKA-3014,5
"KAFKA-6635; Producer close awaits pending transactions (#5971)Currently close() only awaits completion of pending produce requests. If there is a transaction ongoing, it may be dropped. For example, if one thread is calling commitTransaction() and another calls close(), then the commit may never happen even if the caller is willing to wait for it (by using a long timeout). What's more, the thread blocking in commitTransaction() will be stuck since the result will not be completed once the producer has shutdown. This patch ensures that 1) completing transactions are awaited, 2) ongoing transactions are aborted, and 3) pending callbacks are completed before close() returns.Reviewers: Jason Gustafson <jason@confluent.io>",5
"MINOR: code and JavaDoc cleanup (#7462)Reviewers: Jukka Karvanen <jukka.karvanen@jukinimi.com>, Bill Bejeck <bill@confluent.io>",5
"MINOR: Clean up of ConsumerCoordinator and PartitionAssignorAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1306 from Ishiihara/minor-consumer-cleanup",4
"MINOR: Updated configuration docs with RocksDBConfigSetter#close (#6784)The old docs here used a now deprecated method to set the block cache size. In switching over to the new one we would now need to construct a Cache object and therefore also need to close it, so this is a good opportunity to demonstrate the RocksDBConfigSetter#close method that will need to be implemented by users.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
[streaming] WordCount updated,5
[hotfix][runtime] Code clean-ups in ActiveResourceManagerFactory.,4
Disable also local environment in client submission settings.,1
Merge branch 'andrehacker-hadoop-maven-profiles',2
[FLINK-10187] [table] Fix LogicalUnnestRule after upgrading to Calcite 1.17.* LogicalUnnestRule needs to match correlate->...->project->uncollect* Remove SqlToRelConverter which was copied from Calcite to workaround CALCITE-2440.This closes #6592.,1
"KAFKA-2948; Remove unused topics from producer metadata setIf no messages are sent to a topic during the last refresh interval or if UNKNOWN_TOPIC_OR_PARTITION error is received, remove the topic from the metadata list. Topics are added to the list on the next attempt to send a message to the topic.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Author: rsivaram <rsivaram@uk.ibm.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #645 from rajinisivaram/KAFKA-2948",5
"KAFKA-7223: Suppression Buffer Metrics (#5795)Add the final batch of metrics from KIP-328Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
fixed package statementpackage statement was not updated after class movementalso added a missing importAuthor: mjsax <mjsax@informatik.hu-berlin.de>Closes #437 from mjsax/bug_fix_package_statement and squashes the following commits:1470b0f [mjsax] fixed package statement,0
DUBBO-274 提供一个选项所有的Provider都不做Export操作（不需要修改配置）git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1325 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fix duplicate ssl init (#9959),5
"[FLINK-14338][table-planner][table-planner-blink] Update all kinds of left plan changes* Some join order changes for blink-planner due to the rule fire sequence changes, see https://github.com/apache/calcite/commit/35caa059a762094c7df0b30e9b51358a19b48ac2, they are still correct* The Correlate row count estimation has been fixed from a always 1 to join like estimation, thus, if the inputs of Join is a Correlate, the join algorithm would very probably changes, i.e. batch.sql.SubplanReuseTest* Due to CALCITE-3729, the filter condition was pushed down for some Join cases: batch.sql.join.JoinReorderTest* Due to CALCITE-2450 RexNode normalization, the predicates sequence of some test changes: logical.subquery.FlinkRewriteSubQueryRuleTest* The Decimal modulus precision inference has been fixed: planner.expressions.DecimalTypeTest",3
Changed triangle enumeration scala jobs to scala class instead of object,4
"KAFKA-3870: Expose state store names in DSLAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy, Matthias J. Sax, Michael G. Noll, Guozhang WangCloses #1526 from enothereska/expose-names-dsl",5
"[FLINK-19521] Support dynamic properties on DefaultCLIThis allows specifying arbitrary configuration options using the""-Dfoo=bar"" syntax. Before, this was only possible when using theGenericCLI or YARN cli.",1
Adjusted examples packaging to only create jars for fully self-contained examples.,1
Open UT on travis,5
[FLINK-4601] [java] Check for empty string properlyThis closes #2483.,2
[FLINK-19891][table-planner-blink] ScalarOperatorGens should generate a not-null type for IS NULL and IS NOT NULLThis closes #13851,1
[FLINK-10051][tests][sql] Add missing dependencies for sql client E2E test,3
MINOR: fix system tests sending ACLs through ZooKeeper (#9458)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"MINOR: distinguish between missing source topics and internal assignment errors (#9446)Introduce an ASSIGNMENT_ERROR code to distinguish from INCOMPLETE_SOURCE_TOPIC_METADATA and shut down all members in case of an unexpected exception during task assignment.Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <vvcephei@apache.org>",5
[FLINK-6313] [runtime] Fix typos; log exception in QSClient for ActorSystem shutdown failureThis closes #3728.,0
[FLINK-2436] [streaming] Make ByteStreamStateHandles more robustCloses #958,3
[FLINK-5788] [docs] Improve documentation of FileSystem and specify the data persistence contract.This closes #3301,5
DUBBO-204 修改应用名常量git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1737 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix] [checkpoints] Remove unused and obsolete start()/stop() methods on CheckpointRecoveryFactory,1
"[FLINK-6330] [docs] Add basic Docker, K8s docsThis closes #3751",2
MINOR: Tweak upgrade note on KIP-62 to include request.timeout.msAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1960 from hachikuji/add-note-on-request-timeout,1
[FLINK-24665][s3] Update Presto Hadoop dependency to v2.7.4-9,5
"KAKFA-10619: Idempotent producer will get authorized once it has a WRITE access to at least one topic (KIP-679) (#9485)Includes:- New API to authorize by resource type- Default implementation for the method that supports super users and ACLs- Optimized implementation in AclAuthorizer that supports ACLs, super users and allow.everyone.if.no.acl.found- Benchmarks and tests- InitProducerIdRequest authorized for Cluster:IdempotentWrite or WRITE to any topic, ProduceRequest authorized only for topic even if idempotentReviewers: Lucas Bradstreet <lucas@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-17258][sql][test] Fix AggregateITCase.testPruneUselessAggCall missing sortedThe result of this query doesn't guarantee any ordering. This brakes with enabled unaligned checkpoints.,0
[FLINK-11833] [State Backends] Cleanup unnecessary createKeyedStateBackend methods in StateBackendThis closes #7909.,1
"KAFKA-6174; Add methods in AdminClient Options classes to restore binary compatibility with 0.11From 0.11 to 1.0, we moved `DescribeClusterOptions timeoutMs(Integer timeoutMs)` fromDescribeClusterOptions to AbstractOptions (similarly for other Options classes). This cancause code compiled against 0.11.0.x to fail when it is executed with 1.0 kafka-clients jar.This patch adds back these methods to restore binary compatibility with 0.11.Author: Dong Lin <lindong28@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4257 from lindong28/KAFKA-6174",1
delete SerialDetector,4
MINOR: Fix flaky test shouldQueryOnlyActivePartitionStoresByDefault (#9681)Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"KAFKA-6627: Prevent config default values overriding ones specified through --producer-property on command line. (#6084)* KAFKA-6627: Prevent config default values overriding ones specified through --producer-property on command line.In Console{Producer,Consumer}, extraProducerProps (options specified in--producer-property) is applied first, then overriden unconditionally,even if the value is not specified explicitly (and default value isused). This patch fixes it so that it doesn't override the existingvalue set by --producer-property if it is not explicitly specified.The contribution is my original work and I license the work to theproject under the project's open source license.Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>",1
[FLINK-8397] [cassandra] Add CassandraRowOutputFormat.This closes #5272.,1
"KAFKA-12983: reset needsJoinPrepare flag before rejoining the group (#10986)The #onJoinPrepare callback is not always invoked before a member (re)joins the group, but only once when it first enters the rebalance. This means that any updates or events that occur during the join phase can be lost in the internal state: for example, clearing the SubscriptionState (and thus the ""ownedPartitions"" that are used for cooperative rebalancing) after losing its memberId during a rebalance. We should reset the needsJoinPrepare flag inside the resetStateAndRejoin() method. Reviewers: Guozhang Wang <guozhang@apache.org>, Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",5
[hotfix][docs] Fix code tabs for state backend migration,0
optimize : update README.md DubboSamples url (#5605),2
Enhance error message in BucketingSinkFaultToleranceITCaseWe add this with the hope of finding clues about FLINK-9920.,2
MINOR: Update test libraries and gradle plugins for better JDK 16/17 support (#10619)Details:* spotbugs gradle plugin from 4.6.0 to 4.7.1:  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.1  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.2  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.7.0  https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.7.1* spotless gradle plugin from 5.10.2 to 5.12.4:  https://github.com/diffplug/spotless/blob/gradle/5.12.4/CHANGES.md* test-retry gradle plugin from 1.2.0 to 1.2.1:  https://github.com/gradle/test-retry-gradle-plugin/releases/tag/v1.2.1* dependency check gradle plugin from 6.1.1 to 6.1.6:  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.2  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.3  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.4  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.5  https://github.com/jeremylong/DependencyCheck/releases/tag/v6.1.6* versions gradle plugin from 0.36.0 to 0.38.0:https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.37.0https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.38.0* easymock from 4.2 to 4.3:  https://github.com/easymock/easymock/releases/tag/easymock-4.3* mockito from 3.6.0 to 3.9.0:https://github.com/mockito/mockito/releases (too many releases to list  them all individually)* spotbugs from 4.1.4 to 4.2.2:  https://github.com/spotbugs/spotbugs/blob/4.2.2/CHANGELOG.md  4.2.3 has a regression that causes spurious errors related to `Random`  usage.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,0
"MINOR: replace `late` with `out-of-order` in JavaDocs and docs (#7274)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",5
Paths in windows scripts enclosed in double quotes,5
"#1597: CacheFilter,when value is null,it will throw NPE(if use ehcache for jcache),why not check null here (#1828)",1
[FLINK-14627][tests] Refactor ExecutionGraph creation in tests as TestingExecutionGraphBuilderThis closes #10100 .,3
[FLINK-19180][state backends] Make rocksdb state backend respect managed memory fraction.This closes #13500.,5
[hotfix] Remove unused methods from MiniCluster,5
[FLINK-19465][runtime / statebackends] Add CheckpointStorage interface and loader,1
[FLINK-5771] [core] Fix multi-char delimiter detection in DelimitedInputFormat.- Add a test case to validate correct delimiter detection.- Remove a couple of try-catch blocks from existing tests.This closes #3316.,3
KAFKA-8889: Log the details about error (#7317)We need stacktrace of the error to understand the root cause and to trouble shoot the underlying problem.Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
[hotfix]: Fix broken javaDoc inline link.,2
"KAKFA-3599: Move WindowStoreUtils to package ""internals""Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Ismael Juma, Michael G. Noll, Guozhang WangCloses #1266 from mjsax/kafka-3599-minorCodeCleanup",4
"KAFKA-5037 Follow-up: move Scala test to Java (#5399)Reviewers: Ted Yu <yuzhihong@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-22250][sql-parser] Add missing 'createSystemFunctionOnlySupportTemporary' entry in ParserResource.properties (#15582),1
Redirected output of input split assigner from stdout to standard logging,2
[FLINK-18534][kafka][table] Fix unstable KafkaTableITCase.testKafkaDebeziumChangelogSource This closes #12858,3
"KAFKA-10706; Ensure leader epoch cache is cleaned after truncation to end offset (#9633)This patch fixes a liveness bug which prevents follower truncation from completing after a leader election. If there are consecutive leader elections without writing any data entries, then the leader and follower may have conflicting epoch entries at the end of the log.The problem is the shortcut return in `Log.truncateTo` when the truncation offset is larger than or equal to the end offset, which prevents the conflicting entries from being resolved. Here we change this case to ensure `LeaderEpochFileCache.truncateFromEnd` is still called.Reviewers: Jun Rao <junrao@gmail.com>",2
[FLINK-6495] Migrate Akka configuration optionsThis closes #3935.,5
[FLINK-22744][table] Update and simplify EnvironmentSettings,1
[streaming] performance tracker update,5
[FLINK-28602][state/changelog] Close stream of StateChangeFsUploader normally while enabling compression,0
"KAFKA-10547; Add TopicId in MetadataResponse (#9622)Includes:- Bump the version of MetadataRequest and MetadataResponse, add topicId in MetadataResponse- Alter describeTopic in AdminClientTopicService and ZookeeperTopicService- TopicMetadata is cached in MetadataCache, so we need to add topicId to MetadataCache- MetadataCache is updated by UpdateMetadataRequest, bump the version of UpdateMetadataReq and UpdateMetadataResp, add topicId in UpdateMetadataReq.Reviewers: Justine Olshan <jolshan@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
MINOR: Streams docs fixes (#9308)Reviewers: Guozhang Wang <wangguoz@gmail.com>,0
performance tuning: getMethodparameter refactor (#4244),4
[FLINK-1450] Added fold operator for the Streaming API,1
[hotfix][table] Fix the comments of Operation,0
[FLINK-7327] [futures] Replace Flink's future with Java 8's CompletableFuture in StreamRecordQueueEntryThis closes #4442.,1
KAFKA-3187: Make kafka-acls.sh help messages more generic.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #892 from SinghAsDev/KAFKA-3187,1
"KAFKA-6970: All standard state stores guarded with read only wrapper (#6016)Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
KAFKA-12700: override toString method to show correct value in doc (#10574)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
[FLINK-9962] allow users to specify TimeZone in DateTimeBucketerThis closes #6492.,5
[FLINK-5892] Enable 1.2 keyed state testThis closes #3842.,3
"[FLINK-12812] [runtime] (follow-up) Test refers to slot profile computed in ResourceManager.This helps catch a previous bug in which the test re-computed the managed memory, passing a test valuein MEGABYTES. The original call in the ResourceManager passed a value in BYTES.",4
[FLINK-7993][kafka] Sync curator shading patternsThis closes #4953.,2
[FLINK-1638] [streaming] At-Least once monitoring semantics added and bug fixesFault Tolerance monitor suicide on ExecutionGraph terminal stateForwarding messages to StreamCheckpointCoordinator,0
[FLINK-13101][datastream] Introduce blockingConnectionsBetweenChains property of StreamGraph,5
[FLINK-16608][python] Support BooleanType in vectorized Python UDF,1
- remove AggregateReduceFunctionsRule copy in Flink repo.- incoporate calcite change in DATETIME_PLUS operator.- fix unittests.- fix SqlToRelConverter in Flink repo.,2
KAFKA-10199: Expose tasks in state updater (#12312)This PR exposes the tasks managed by the state updater. The state updater manages all tasks that were added to the state updater and that have not yet been removed from it by draining one of the output queues.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
[FLINK-5188] [table] [connectors] [core] Adjust imports and method calls to new Row type.- Port RowCsvInputFormat to Java and move it to flink-core.This closes #3003.,2
"[FLINK-23371][streaming-java] Allow disabling progressive watermarks for SourceFunctionIt might be a rare use case but since SourceFunction is still widely used, it ensurescorrectness and consistency with the FLIP-27 stack when used in a DynamicTableSource.",1
Fix the managed memory planning after patch 9ce6293075d1a2326df8a2e99c032445a555b28b,0
"KAFKA-3584; Fix synchronization issue between deleteOldSegments() and delete() methodsThis PR is to fix synchronization issue between deleteOldSegments() and delete() method calls. log.deleteOldSegments() call throws NullPointerException after log.delete() method call.cc ijuma junraoAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1367 from omkreddy/KAFKA-3584",4
remove useless imports,2
[FLINK-24725][python] Update Cython to the latest versionThis closes #17644.,3
[hotfix] Rework GlobFilePathFilterTest to be based on AssertJ & JUnit5,3
KAFKA-5949; Follow-up after latest KIP-161 changes - compare KAFKA-5958Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3986 from mjsax/kafka-5949-exceptions-user-callbacks-KIP-161-follow-up,1
"KAFKA-12247: add timeout and static group rebalance to remove thread (#9984)Add timeout to remove thread, and trigger thread to explicitly leave the group even in case of static membershipReviewers: Bruno Cadonna <bruno@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
MINOR: Use dynamic port in `RestServerTest` (#7079)We have seen some failures recently in `RestServerTest`. It's the usual problem with reliance on static ports. ```Caused by: java.io.IOException: Failed to bind to 0.0.0.0/0.0.0.0:8083at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:346)at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:308)at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236)at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)at org.eclipse.jetty.server.Server.doStart(Server.java:396)at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)at org.apache.kafka.connect.runtime.rest.RestServer.initializeServer(RestServer.java:178)... 56 moreCaused by: java.net.BindException: Address already in use```This patch makes the chosen port dynamic.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
[hotfix] Avoid redundant slot release operations,0
"HOTFIX: Fix lgtm.com alerts (dead code and out-of-bounds error) (#4388)This fixes two alerts flagged on lgtm.com for Apache Kafka.This dead code alert where InvalidTypeIdException indirectly extends JsonMappingException. The flagged condition with the type test appears after the type test for the latter and thus makes its body dead. I opted to change the order of the tests. Please let me know if this is the intended behavior.The second commit addresses this out-of-bounds alert.More alerts can be found here. Note that my colleague Aditya Sharad addressed some of those in the now outdated #2939.Reviewers: Matthias J. Sax <matthias@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-2454] [buikd] Update Travis to drop JDK6 for tests,3
"Revert ""MINOR: make flush no-op as we don't need to call flush on commit.""This reverts commit 90b2a2bf664e4e40d4cd1b46c72732c5edb97cf9.",5
[FLINK-20342][docs] Change Cluster & Deployment into Resource Providers,1
"MINOR: MessageUtil: remove some deadcode (#9931)Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",4
[hotfix] [docs] Add missing licenses to programming guide redirects.This closes #1545,1
[hotfix] Fix typo in comments of MemorySegmentThis closes #7744.,2
"KAFKA-10199: Remove tasks from state updater on shutdown (#12562)The state updater removes its updating and paused task on shutdown.The removed tasks are added to the output queue for removed tasks.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",5
[FLINK-8368] [rest] Simplify SubtaskExecutionAttemptDetailsHandlerTest#testHandleRequest,3
[FLINK-3244] [runtime] Add debug log messages to SavepointCoordinator,2
[FLINK-1902] Show jobmanager address/port in configuration,5
[hotfix][tests] Extract SubmittedJobGraphStore implementation from JobManagerHARecoveryTest,3
KAFKA-7412: clarify the doc for producer callback (#5798)The metadata in the callback is not null with non-null exception.Reviewers: Jun Rao <junrao@gmail.com>,5
[FLINK-3200] Fix Triggers by introducing clear() method to clean up state/triggers,4
[FLINK-13504][table] Fixed shading issues in table modules.Properly include the flink-sql-parser into flink-planner* modules shadedjars. Removed the flink-sql-parser module from flink-table-uber* jars asit is already included in the flink-planner* modules.This closes #9313.,2
[FLINK-9313] [security] (part 3) Activate mutual authentication for RPC/akka,2
Updated java 8 package to match flink-examples standardsRenamed org.apache.flink.example package to org.apache.flink.examplesDefault data is provided from flink-java examples,2
DUBBO-213 增加dubbo-examples模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@952 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"When use delay to export service, catch the exception and log it. (#8584)* when use delay to export service, catch the exception and log it.* format file* enhance log info.",5
"MINOR: Documentation updates for reserved.broker.max.idPeople are facing problems upgrading their clusters with configured broker IDs above 1000 due to `reserved.broker.max.id` which wasn't very well announced.This PR attempts to improve that somewhat by fixing the broker config docs and adding a note to the upgrade documentation.Author: Magnus Edenhill <magnus@edenhill.se>Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #670 from edenhill/docs-reserved.broker.max.id",2
[hotfix] Let HistoryServerStaticFileServerHandlerTest extend TestLogger,3
[DUBBO-2991][WIP]Enhance the java doc of dubbo-cluster (#2991) (#4424)* Replace RpcStatus to count (#2984)* Create constants for 'hash.names' and 'hash.arguments' (#3744)* Add javadoc in RandomLoadBalance* Improve Javadoc of RandomLoadBalance,5
KAFKA-1729; Add constructor to javaapi to allow constructing explicitly versioned offset commit requests; reviewed by Jun Rao,1
[FLINK-5404] [docs] Consolidate and update AWS setupThis closes #3054.,1
[FLINK-7918] Run AbstractTestBase tests on Flip-6 MiniClusterThis closes #5095.,5
[FLINK-11153][travis] Remove flink-java tests Java 9 exclusion,3
"KAFKA-2822: DescribeConsumerGroup now returns empty list for non-existent group.…tent group, it used to throw IllegalArgumentExceptionAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Jason Gustafson, Guozhang WangCloses #515 from SinghAsDev/KAFKA-2822",1
update erlang link (#4100),2
MINOR: Make it impossible to invoke `Request.body` without an explicit type parameterAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2579 from ijuma/safer-body,5
MINOR: AdminClient should respect retry backoffAdminClient should backoff when retrying a Call. Fixed and added a unit testAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5077 from hachikuji/admin-client-retry-backoff,1
[FLINK-21936][checkpoint] Fail early if attempting to rescale pointwise connection.,0
"[FLINK-9703] Allow TM ports to be exposed through MesosMaintain a deterministic port ordering, so we can have expectations on which endpoint is behind which port index.This closes #6288.",5
[hotfix] Correct log statements in YarnResourceManager,2
"Fix create_release_branch.sh to accomodate Hadoop VersionsBefore, this would not correctly change version tags that have a versionprefix or suffix, like the shaded Hadoop modules.",0
"[FLINK-2976] [core, runtime, streaming-java] Add ApplicationID to ExecutionGraph",1
[3.0] Fix import check (#9615),2
[FLINK-24813][table-planner] Improve ImplicitTypeConversionITCaseThis closes #17771,1
Added union operator and refactored,4
[FLINK-24038] Introduce HighAvailabilityOptions.USE_OLD_HA_SERVICES as safety hatch,1
"KAFKA-13832: Fix flaky testAlterAssignment (#12060)In KRaft mode the metadata is not propagate in time, so we should should wait for it before make assertions.Reviewers:  Luke Chen <showuon@gmail.com>",3
"MINOR: Log unexpected exceptions in Connect REST calls that generate 500s at a higher log levelThe ConnectExceptionMapper was originally intended to handle ConnectException errors for some expected cases where we just want to always convert them to a certain response and the ExceptionMapper was the easiest way to do that uniformly across the API. However, in the case that it's not an expected subclass, we should log the information at the error level so the user can track down the cause of the error.This is only an initial improvement. We should probably also add a more general ExceptionMapper to handle other exceptions we may not have caught and converted to ConnectException.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #4227 from ewencp/better-connect-error-logging",2
[streaming] CoGroupedWindowReduceInvokable refactor[streaming] Grouped window reduce bugfix,0
"KAFKA-7242: Reverse xform configs before saving (KIP-297)During actions such as a reconfiguration, the task configs are obtainedvia `Worker.connectorTaskConfigs` and then subsequently saved into aninstance of `ClusterConfigState`.  The values of the properties that are savedare post-transformation (of variable references) when they should bepre-transformation.  This is to avoid secrets appearing in plaintext inthe `connect-configs` topic, for example.The fix is to change the 2 clients of `Worker.connectorTaskConfigs` toperform a reverse transformation (values converted back into variablereferences) before saving them into an instance of `ClusterConfigState`.The 2 places where the save is performed are`DistributedHerder.reconfigureConnector` and`StandaloneHerder.updateConnectorTasks`.The way that the reverse transformation works is by using the""raw"" connector config (with variable references still intact) from`ClusterConfigState` to convert config values back into variablereferences for those keys that are common between the task configand the connector config.There are 2 additional small changes that only affect `StandaloneHerder`:1) `ClusterConfigState.allTasksConfigs` has been changed to perform atransformation (resolution) on all variable references.  This isnecessary because the result of this method is compared directly to`Worker.connectorTaskConfigs`, which also has variable referencesresolved.2) `StandaloneHerder.startConnector` has been changed to match`DistributedHerder.startConnector`.  This is to fix an issue whereduring `StandaloneHerder.restartConnector`, the post-transformedconnector config would be saved back into `ClusterConfigState`.I also performed an analysis of all other code paths where configs aresaved back into `ClusterConfigState` and did not find any otherissues.Author: Robert Yokota <rayokota@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #5475 from rayokota/KAFKA-7242-reverse-xform-props",5
[FLINK-11678] Change RestfulGateway#requestJob return type to CompletableFuture<ArchivedExecutionGraph>,4
[FLINK-18635][docs] Fix typo on website,2
[FLINK-26460][table-planner] Fix Unsupported type when convertTypeToSpec: MAPThis closes #18967,1
HOTFIX: fix broken WorkerSourceTask testAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #859 from hachikuji/hotfix-worker-source-test,3
Initial commit,5
[FLINK-1922] [runtime] Fixes NPE when TM receives a null input splitThis closes #631,0
"[FLINK-8338] [flip6] Make CustomCommandLines non static in CliFrontendThis commit changes how CustomCommandLines are registered at the CliFrontend.Henceforth, the CliFrontend is initialized with the set of CustomCommandLinesinstead of registering them statically. This improves maintainability andtestability.This closes #5224.",3
[FLINK-14199] [runtime] Improving the performance of named mails by adding overloaded submission methods to MailboxExecutor.java that do not create a new array for empty arguments.,1
[FLINK-3413] [streaming] Make implicit conversions from Java DataStream to Scala DataStream explicitThis also clean up a lot of JavaDocs in various Scala DataStream API classes.,5
"KAFKA-5979; Use single AtomicCounter to generate internal namesAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>Closes #3979 from mjsax/kafka-5979-kip-120-regression",5
"[FLINK-5747] [distributed coordination] Eager scheduling allocates slots and deploys tasks in bulkThat way, strictly topological deployment can be guaranteed.Also, many quick deploy/not-enough-resources/fail/recover cycles can beavoided in the cases where resources need some time to appear.This closes #3295",0
"HOTFIX: Remove from restoringByPartition once restored (#7631)Minor follow up to #7608: For some reason the AssignedStreamTasks#updateRestored method only updates the restoring and restoredPartitions data structures, but there is a third map holding restored tasks & partitions: restoringByPartitionsAlso improves the TaskManager#closeLostTasks logging, by separating by case and logging the specific failure before throwing.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",0
"[FLINK-20001] Don't use setAllVerticesInSameSlotSharingGroupByDefault in StreamGraphGeneratorI think the default of having all vertices in the same slot sharinggroup should be good for both BATCH and STREAMING right now. We canreconsider actually setting this flag in the future.Background information: this is a special setting that was introducedfor the Table API Blink runner/planner, which does special things withslot sharing (or lack thereof) and is more aware of memory requirementsand such. For general DataStream/DataSet programs changing the settingdoesn't make sense.",1
save url attributes on initialization (#9467),5
KAFKA-569 Split up utils package and do some cleanup. Patch reviewed by Neha.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397765 13f79535-47bb-0310-9956-ffa450edef68,4
[FLINK-21439][runtime] Move FailureResult into separate class,0
Added scala docs to actor messages.,2
[hotfix] fix shaded reference,0
[hotfix] [gelly] Update test graph generationIn tests RMat graphs are now created by calling a function with thedesired scale and edge factor. Also updated the documentation forgenerating test graphs using Gelly examples.,1
KAFKA-9881: Convert integration test to verify measurements from RocksDB to unit test (#8501)The integration test RocksDBMetricsIntegrationTest takes pretty long to complete.Most of the runtime is spent in the two tests that verify whether the RocksDBmetrics get actual measurements from RocksDB. Those tests need to wait for the threadthat collects the measurements of the RocksDB metrics to trigger the first recordingsof the metrics.This PR adds a unit test that verifies whether the Kafka Streams metrics get themeasurements from RocksDB and removes the two integration tests that verified itbefore. The verification of the creation and scheduling of the RocksDB metricsrecording trigger thread is already contained in KafkaStreamsTest and consequentlyit is not part of this PR.Reviewers: Guozhang Wang <wangguoz@gmail.com>,3
"[FLINK-14331][runtime] Reset vertices before asking the scheduling strategy to restart themWithout this change, the LazyFromSourcesSchedulingStrategy will fail to restarttasks. This is because the LazyFromSourcesSchedulingStrategy only schedulesvertices in CREATED state.",1
[FLINK-27908] HsSubpartitionView should calculate backlog no less than true value.This closes #20445,2
[FLINK-16996][table-runtime-blink] Remove legacy data formats (BaseRow)This closes #11925,5
"[FLINK-19579] Add the SideOutputTransformation translatorWith the addition of the TransformationTranslator frameworkin FLINK-19485, we can now pull the translation logic outof the StreamGraphGenerator and put it into dedicated translators.This commit does so for the SideOutputTransformation.This closes #13649",2
Limit the times of registry retry. (#2946)The default value is 3.,1
[FLINK-23054][table] TemporalJoinRewrite should based on upsert key,2
"KAFKA-8147: Update upgrade notes for KIP-446 (#8965)Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",5
[hotfix][cep] Added test event builder,3
"MINOR: Update jetty to 9.4.33Jetty 9.4.32 and before are affected by CVE-2020-27216. This vulnerability is fixed in Jetty 9.4.33, please see the jetty project security advisory for details: https://github.com/eclipse/jetty.project/security/advisories/GHSA-g3wg-6mcf-8jj6#advisory-comment-63053Unit tests and integration tests pass locally after the upgrade.Author: Nitesh Mor <nmor@confluent.io>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #9556 from niteshmor/trunk",1
"MINOR: MiniTrogdorCluster mutates objects from other threads (#11710)MiniTrogdorCluster spins up agents from a different thread when scheduling them, but does not use volatiles in these objects. It's not clear that the updated fields are visible.Reviewers: Colin P. McCabe <cmccabe@apache.org>, Kvicii <Karonazaba@gmail.com>, David Jacot <djacot@confluent.io>",5
"Merge pull request #3527 Bricks-Man/incubator-dubbo, fix accidentally check exchanger in setDispatcherfixes #3518",0
[FLINK-14195] Add Streaming File Sink s3 end-to-end test back for java 11.,3
KAFKA-1866 LogStartOffset gauge throws exceptions after log.delete(); reviewed by Neha Narkhede,4
"[FLINK-9313] [security] (part 1) Instantiate all SSLSocket and SSLServerSocket through factories.This removes hostname verification from SSL client sockets.With client authentication, this is no longer needed and it is not compatible withvarious container environments.",4
[hotfix] [gelly] Improve graph generator documentation,2
[hotifx][tests] Remove dead code in TaskExecutorTest,3
MINOR: Fix typo in system tests Dockerfile (#11740)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
[FLINK-5852] Move handler JSON generation code into static methodsThis closes #3365.,5
Merge pull request #9989 from wangxlong/hotifx-annotation-NonWindowLeftRightJoinWithNonEquiPredicates[hotfix][docs] Delete useless annotation in NonWindowLeftRightJoinWithNonEquiPredicates,1
[FLINK-11843] Rename DispatcherLeaderProcess#getConfirmLeaderSessionFuture into getLeaderAddressFuture,1
optimize generic invoke (#4076)only effective for hessian2 serialization scenario.,5
kafka-1462; Add new request and response formats for the new consumer and coordinator communication; patched by Jun Rao; reviewed by Guozhang Wang and Jay Kreps,1
[FLINK-3817] Remove unused guava dependency from RocksDb backendThis closes #1934,5
Fixed Stratosphere Website link (relative relative to absolute link)[ci skip],2
[FLINK-25851][cassandra][tests] Inject dynamic table name into Pojos,3
[FLINK-20963][python] Update examples to use the latest recommended API (#14673),3
[streaming] Changed time based windowing policies to make lower boundary excluded and upper boundary included in the windows and adjusted policy test cases respectively.,3
[hotfix][runtime] Refactoring: remove ProcessingTimeService::shutdownAndAwaitPending method,4
[hotfix][metrics][docs] Remove redundant <th> from metric table,4
[hotfix] Bump japicmp reference version to Flink 1.5.0,2
"[FLINK-3085] [runtime] Initialize state backends as part of ""invoke()""",5
JobManager now considers profiling dependencies of plugins,2
DUBBO-970 修改测试用例git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1548 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-3486: fix autocommit when partitions assigned manuallyAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1169 from hachikuji/KAFKA-3486,5
[FLINK-5216] [checkpoints] 'Min Time Between Checkpoints' references timestamp after checkpoint,2
generate urls directly for non-dubbo service instances.,2
[hotfix] Shade avro in sql-avro jars,0
MINOR: add equals()/hashCode() for Produced/Consumed (#4979)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
[hotfix][docs] Cleanup grammar in python table walkthrough,4
Added user-defined data distribution to TeraSort,5
[FLINK-14766][coordination] Remove volatile keyword in executiongraph packageThis closes #10207 .,1
[FLINK-24565][avro] Port avro file format factory to BulkReaderFormatFactoryThis closes #17520,2
[hotfix] regenerate rest-docs to latest code,3
Add *.log exclude pattern for source-release assembly,2
"MINOR: Correctly mark some tests as integration tests (#12223)Also fix package name of `ListOffsetsIntegrationTest`.Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[tests] Flix flakey SimpleRecoveryITCase,3
DUBBO-138 修改WebService依赖包git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1982 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-12648: fill in javadocs for the StreamsException class with new guarantees (#11436)Minor followup to #11405 / KIP-783 to write down the new guarantees we're providing about the meaning of a StreamsException in the javadocs of that classReviewers: Bruno Cadonna <cadonna@apache.org>,1
"KAFKA-6102; Consolidate MockTime implementations between connect and clientsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #4105 from cmccabe/KAFKA-6102",5
[FLINK-23093] Limit default io pool size to 4 for Mini Cluster.This closes #16274.,5
MINOR: Fix JavaDoc of OffsetIndex#append (#11744)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
remove unnecessary null check  before instance of (#4321)Signed-off-by: jimin.jm <slievrly@163.com>,4
"KAFKA-2844; Separate keytabs for sasl testsUse a different keytab for server and client in SASL testsAlso:* Improve approach used to build the JAAS files programmatically* Delete stale `kafka_jaas.conf` file* Move `FourLetterWords` to its own file, add `Zk` prefix and clean-up its usageAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Harsha Chintalapani, Gwen ShapiraCloses #533 from ijuma/separate-keytabs-for-sasl-tests",3
[hotfix][runtime] Minor format cleanup in OperatorCoordinatorHolder,1
[FLINK-9374] [kinesis] Enable FlinkKinesisProducer backpressuringThis closes #9374.,2
#2748: Provider should disable mock configuration (#2749),5
"KAFKA-1961 Prevent deletion of _consumer_offsets topic; reviewed by Neha Narkhede, Gwen Shapira and Jun Rao",1
Update fastjson to 1.2.83 (#10099)Security issue: Update fastjson to 1.2.83,5
splitted ArraySchema/LazyArrayNode up to head and tail types,5
[hotfix][io] remove duplicate code between SynchronousBufferFileReader and BufferReadRequest,2
MINOR: Log error when storing assignment fails (#12526)Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-13149; Fix NPE when handling malformed record data in produce requests (#11080)Raise `InvalidRecordException` from `DefaultRecordBatch.readFrom` instead of returning null if there are not enough bytes remaining to read the record. This ensures that the broker can raise a useful exception for malformed record batches.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
Update several documentation links (#2354),2
#1682: Enhance the test coverage part-4 (#1862),3
"MINOR: Fix flaky TestUtils functions (#4743)TestUtils#produceMessages should always close the KafkaProducer, evenwhen there is an exception.  Otherwise, the test will leak threads whenthere is an error.TestUtils#createNewProducer should create a producer with arequestTimeoutMs of 30 seconds by default, not around 10 seconds.This should avoid tests that flake when the load on Jenkins climbs.Fix two cases where a very short timeout of 2 seconds was getting set.Reviewers: Ismael Juma <ismael@juma.me.uk>",1
remove reference destroy guardian (#5863)fix #5855,0
[hotfix] [dist] Add notice about memory pre-allocation to default 'flink-conf.yaml',5
[FLINK-17893][sql-client] SQL CLI should print the root cause if the statement is invalidThis closes #12355,1
[hotfix][doc][hive] add doc on what hive dependencies to put in /lib dir,2
DUBBO-444 修复RpcInvocation的attachments问题,5
[FLINK-18301][e2e] Backup kafka logs on failure,0
MINOR: Update Scala to 2.13.5 (#10169)This includes a fix from Chia-Ping that removes tupleallocations when `Map.forKeyValue` is used(https://github.com/scala/scala/pull/9425) and supportfor JDK 16.Release notes:https://github.com/scala/scala/releases/tag/v2.13.5Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,1
[FLINK-14788][documentation] Generated documentation for ExecutionCheckpointingOptionsThis closes #10222,2
Added support for broadcast variables to the optimizer IR structures.,1
Compatibility to OpenJDK 1.7.0,5
[FLINK-2381] [Storm Compatibility] Failing Test: WrapperSetupHelperTest,3
[FLINK-5163] Port the MessageAcknowledgingSourceBase to the new state abstractions.,1
[FLINK-20337] Add ITCase for migrating from StreamingFileSink to FileSink,2
MINOR: Add build_eclipse to .gitignorebuild_eclipse is the configured output directory for eclipse when usingthe gradle eclipse plugin and should be ignoredAuthor: Christopher L. Shannon <christopher.l.shannon@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2569 from cshannon/eclipse-gitignore,1
[hotfix][hbase][legal] Remove invalid NOTICE entries,4
[FLINK-10569][tests] Replace various Scheduler usages,3
Moved query related sopremo implementation to this package,4
[FLINK-22452][docs] list the configuration methods of FlinkKafkaProducer and add ProducerFencedException in Troubleshooting,1
"MINOR: Factor out common response parsing logic (#9617)This patch factors out some common parsing logic from `NetworkClient.parseResponse` and `AbstractResponse.parseResponse`. As a result of this refactor, we are now verifying the correlationId in forwarded requests. This patch also adds a test case to verify handling in this case.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>",5
Minor changes in Java POJO WordCount example,4
[FLINK-9899] Add more ShardConsumer metricsThis closes #6409.,1
MINOR: Remove uncommitted code (#6919),4
[hotfix][tests] Reformat default flink configuration map,5
"[FLINK-26146] Add tests of flink version upgrades to cover native snapshotsTurned SavepointMigrationTestBase into SnapshotMigrationTestBase that supports testing canconicalsavepoints, native savepoints, and checkpoints; and adapted sub classes accordingly.",3
[hotfix][javadocs] Fix typo,2
[streaming] IncrementalLearning skeleton updated,5
"[FLINK-8984][network] Drop taskmanager.exactly-once.blocking.data.enabled config optionPreviously there were twe options:taskmanager.network.credit-based-flow-control.enabledandtaskmanager.exactly-once.blocking.data.enabledIf we disabled first one, but keept default value for the second one deadlocks will occur.By dropping taskmanager.exactly-once.blocking.data.enabled we can always use: - blocking BarrierBuffer for credit based flow control - spilling BarrierBuffer for non credit based flow control.This closes #5708.",2
KAFKA-3063; LogRecoveryTest causes JVM to exit occasionallyRemove deletion of tmp file in `OffsetCheckpoint`'s constructor. This delete causes unintuitive behaviour like `LogRecoveryTest` causing a `System.exit` because the test creates an instance of `OffsetCheckpoint` in order to call `read()` on it (while unexpectedly deleting a file being written by another instance of `OffsetCheckpoint`).Also:* Improve error-handling in `OffsetCheckpoint`* Also include minor performance improvements in `read()`* Minor clean-ups to `ReplicaManager` and `LogRecoveryTest`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #759 from ijuma/kafka-3063-log-recovery-test-exits-jvm,3
[FLINK-20006] Fix the unstable FileSinkITCase,2
"KAFKA-1113 log.cleanup.interval.mins property should be renamed; Trivial patch, no review",5
Merge branch 'streaming_test' into streamingConflicts:nephele/nephele-streaming/src/main/java/eu/stratosphere/nephele/streaming/StreamingJobManagerPlugin.java,5
KAFKA-2295; Support dynamically loaded classes from context class loaderRebased code..Author: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Guozhang WangCloses #314 from omkreddy/KAFKA-2295,1
kafka-2241; AbstractFetcherThread.shutdown() should not block on ReadableByteChannel.read(buffer); patched by Dong Lin; reviewed by Jun Rao,5
"Revert ""[FLINK-16864][metrics] Add IdleTime metric for task""This reverts commit 18787230ea0bb3b502a8002b9f4f0fa0afb85f63.",4
[FLINK-22912][python] Support state ttl in Python DataStream APIThis closes #16667.,5
Improved java doc,2
[hotfix] Update create_binary_release.sh to newer Hadoop versionsThis brings it in line with the monolithic create_release_files.sh.,2
Merge branch 'michael'Conflicts:sopremo/sopremo-common/src/main/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNode.javasopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/serialization/LazyTailArrayNodeTest.java,5
[FLINK-28776][table-planner] RowTimeMiniBatchAssginerOperator doesn't need separate chain with upstream operator (#20417),1
"KAFKA-9383: Expose consumer group metadata (#7906)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-1679] deprecate old parallelism config entryold config parameter can still be usedOLDparallelization.degree.defaultNEWparallelism.default,1
[FLINK-8266] Add network memory to ResourceProfile for input/output memory of a taskThis closes #5170.,2
[FLINK-12817][docs] Fix imports in Processing function example,1
Fixed #204,0
"MINOR: Redirect response code in Connect's RestClient to logs instead of stdoutSending the response code of an http request issued via `RestClient` in Connect to stdout seems like a unconventional choice.This PR redirects the responds code with a message in the logs at DEBUG level (usually the same level as the one that the caller of `RestClient.httpRequest` uses.This fix will also fix system tests that broke by outputting this response code to stdout.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Randall Hauch <rhauch@gmail.com>, Damian Guy <damian.guy@gmail.com>Closes #4591 from kkonstantine/MINOR-Redirect-response-code-in-Connect-RestClient-to-logs-instead-of-stdout",2
"[FLINK-4581] [table] Fix Table API throwing ""No suitable driver found for jdbc:calcite""This closes #2506This closes #1491 // closing stale PRThis closes #997  // closing stale PR",5
"[FLINK-25365][python] Remove remaining references to planner from Python- Move DataViewSpec, ListViewSpec and MapViewSpec out of DataViewUtils and inside table-runtime- Move PythonInputFormatTableSource from PythonTableUtils and convert to Java- Converted PythonTableUtils to Java and moved to flink-python- Refactor PythonBridgeUtils to remove usage of calcite classes- Remove runtime dependency on flink-table-plannerThis closes #18156.",2
[FLINK-27185][connector] Convert connector-kinesis module to assertjCo-authored-by: slinkydeveloper <francescoguard@gmail.com>,2
KAFKA-5184 KAFKA-5173; Various improvements to SASL tests1. Call `closeSasl` in `MultipleListenersWithSameSecurityProtocolBaseTest`2. Refactor the code to make it easier to reason about3. Add an assert that may possibly help us narrow down how KAFKA-5184can happen (it seems impossible).4. Remove SaslTestHarness to make it easier to reason about setUpand tearDown methods.5. Fix *AdminClientIntegrationTest to have a single `tearDown`6. Remove a *ReplicaFetcherTest and *TopicMetadataTest secure variants.They are redundant from a security perspective given the consumer andproducer tests.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3010 from ijuma/kafka-5184-kafka-5173-sasl-issues,0
Added hooks for task manager plugins,1
"KAFKA-690 TopicMetadataRequest throws exception when no topics are specified, reviewed by Jay Kreps and Neha Narkhede",5
[hotfix][tests] Avoid mock NetworkEnvironment in tests,3
[FLINK-28201][ci] Generalize utils around dependency plugin,2
[FLINK-1201] [gelly] Added mapEdges,1
"MINOR: Make data in FetchSnapshotRequest and FetchSnapshotRespponse private (#9820)Reviewers: José Armando García Sancio <jsancio@gmail.com>, David Jacot <djacot@confluent.io>",5
KAFKA-1233 Integration test for the new producer; reviewed by Jay Kreps and Neha Narkhede,1
[FLINK-18515][Kinesis] Adding FanOutRecordPublisher for Kinesis EFO supportThis closes #13189.,1
[FLINK-17818] Fix argument check of CsvReader.pojoType(),0
"KAFKA-4645: Improve test coverage of ProcessorTopologythe toString method prints the topology, but had no tests making sure it works and/or doesn't cause exceptionsAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2444 from dguy/KAFKA-4645",1
[FLINK-21151] Pass whole resources instead of fields in RocksFullSnapshotStrategyWe also move the fillMetaData() method and hide it in the resources.,5
[hotfix] [tests] Let SlotCountExceedingParallelismTest use the TestLogger,3
[FLINK-12780][hive] use Flink's LogicalTypeRoot for type comparison in HiveTypeUtilThis PR changes type comparisons in HiveTypeUtil to use LogicalTypeRoot of Flink's DataType.This closes #8662.,5
fix 4892 (#4893),0
"[FLINK-25257][TE] Let TaskExecutor use TaskExecutorBlobService interface instead of concrete BlobCacheService implementationThis commit decouples the TaskExecutor from the BlobCacheService implementation by introducing a TaskExecutorBlobServiceinterface that abstracts the concrete implementation details away. Due to this change we also introduced a JobPermanentBlobServiceto decoupled the TaskExecutor from relying on the PermanentBlobCache implementation. Moreover, this commit introduces aNoOpTaskExecutorBlobService that simplifies testing.This closes #18081.",3
[FLINK-21934][table] Add new StreamTableEnvironment.toDataStreamThis closes #15457.,5
"KAFKA-3140: Fix PatternSyntaxException and hand caused by it in Mirro…Fix PatternSyntaxException and hand caused by it in MirrorMaker on passing invalid java regex string as whitelistAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Grant Henke, Gwen ShapiraCloses #805 from SinghAsDev/KAFKA-3140",4
Merge #689 from qinliujie:feat/threadDumpnew feature: dump thread stack to file when threadpool exhausted,2
"DUBBO-13 对class.forname增加cache,将所有ClassLoader相关方法设为privategit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@261 1a56cb94-b969-4eaa-88fa-be21384802f2",1
[hotfix][tests] Consolidate matching logic,2
HOTFIX: use ConsumedInternal in StreamsBuilder,1
"[hotfix] Migrate PartitionFileWriteReadTest, SortMergeResultPartitionReadSchedulerTest, SortMergeSubpartitionReaderTest to Junit5 and AssertJThis closes #20333.",3
[3.0] Fix isConsumerSide not work in sub invoke (#9740)Fix #9666,0
[FLINK-10687] [table] Move TableSchema to flink-table-common,2
[FLINK-4204] [gelly] Clean up gelly-examplesMoves drivers into separate package. Adds default main class to printusage listing included classes. Includes documentation for runningGelly examples.This closes #2670,1
"[FLINK-17766] Use checkpoint lock instead of fine-grained locking in Kafka AbstractFetcherBefore, we were locking on the partition state object itself to preventconcurrent access (and to make sure that changes are visible acrossthreads). However, after recent changes we hold the checkpoint lock foremitting the whole ""bundle"" of records from Kafka. We can now also justuse the checkpoint lock in the periodic emitter callback and then don'tneed the fine-grained locking on the state for record emission.",1
"[FLINK-5666] [tests] Add blob server clean up testsPreviously, deleting in HA mode was only tested with a local file system.This verifies that the delete still works on HDFS.This closes #3222.",1
[FLINK-24325][tests] Update Elasticsearch CI tests,3
[hotfix][docs] Use Hugo highlighting for danger and info sectionsThis commit uses Hugo's highlighting to emphasize danger and info sections in the cli.md.,5
MINOR: Modify unnecessary access specifiers (#9861)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
[FLINK-9702] Improvement in (de)serialization of keys and values for RocksDB stateThis closes #7288.Co-authored-by: Stefan Richter <s.richter@data-artisans.com>Co-authored-by: klion26 <qcx978132955@gmail.com>,5
"Finished Hash Join, Adopted Match Task Iterators, ensured SortMatch will stay in-memory for N:M, if possible, cleaned iterator interfaces.",4
removed System.out.println statements from unit tests.,3
[FLINK-15467][task] Wait for sourceTaskThread to finish before exiting from invoke,5
[FLINK-6176] [scripts] [yarn] [mesos] Add JARs to CLASSPATH deterministicallySorts files read from Flink's lib directory and places the distributionJAR to the end of the CLASSPATH.This closes #3632,2
"KAFKA-5959; Fix NPE in Sender.canRetry when idempotence is not enabledAuthor: Apurva Mehta <apurva@confluent.io>Reviewers: tedyu <yuzhihong@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #3947 from apurvam/KAFKA-5959-npe-in-sender",5
[FLINK-15113][config] add fs.azure.account.key to list of sensitive configs,5
remove a redundant '>' (#2467),4
"KAFKA-7010: Rename ResourceNameType to PatternType (#5205)The initial PR for KIP-290 #5117 added a new `ResourceNameType`, which was initially a field on `Resource` and `ResourceFilter`. However, follow on PRs have now moved the name type fields to new `ResourcePattern` and `ResourcePatternFilter` classes. This means the old name is no longer valid and may be confusing. The PR looks to rename the class to a more intuitive `resource.PatternType`.@cmccabe also requested that the current `ANY` value for this class be renamed to avoid confusion. `PatternType.ANY` currently causes `ResourcePatternFilter` to bring back all ACLs that would affect the supplied resource, i.e. it brings back literal, wildcard ACLs, and also does pattern matching to work out which prefix acls would affect the resource.  This is very different from the behaviour of `ResourceType.ANY`, which just means the filter ignores the type of resources.  `ANY` is to be renamed to `MATCH` to disambiguate it from other `ANY` filter types. A new `ANY` will be added that works in the same way as others, i.e. it will cause the filter to ignore the pattern type, (but won't do any pattern matching).Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",1
add test cases for injvm rpc protocol (#2041),3
[FLINK-22745][zk] Trim starting slashes when creating a namespaced CuratorFramework facadeThis commit trims starting slashes from the namespace used to instantiate the CuratorFramework facadein ZooKeeperUtilityFactory because namespaces must not start with slashes.This closes #15988.,1
[FLINK-16745][k8s] Start Kubernetes JM with FLIP-116 JVM memory argsThis closes #11675.,2
"[hotfix] [storm compatibility] Deactivate tests for split stream field grouping, which do not work in teh runtime and are now caught earlier",1
"[FLINK-17664][table] Introduce print, blackhole connector in tableThis closes #12126",2
Remove obsolete collection execution example.Correct remote collector format example.,4
[FLINK-19114][python] Introduce Expression class for Python Table APIThis closes #13278.,2
"[FLINK-17823][network] Resolve the race condition while releasing RemoteInputChannelRemoteInputChannel#releaseAllResources might be called by canceler thread. Meanwhile, the task thread can also call RemoteInputChannel#getNextBuffer.There probably cause two potential problems:1. Task thread might get null buffer after canceler thread already released all the buffers, then it might cause misleading NPE in getNextBuffer.2. Task thread and canceler thread might pull the same buffer concurrently, which causes unexpected exception when the same buffer is recycled twice.The solution is to properly synchronize the buffer queue in release method to avoid the same buffer pulled by both canceler thread and task thread.And in getNextBuffer method, we add some explicit checks to avoid misleading NPE and hint some valid exceptions.",1
[Dubbo-4861] WIP: fix stackoverflow of protostuff and other errors (#4862)* fix stackoverflow of protostuff and other errors* revert,4
[FLINK-22604][table-runtime-blink] Fix NPE on bundle close when task failover after a failed task openThis closes #15863,0
[FLINK-20429][kafka] Using proper watermark interval in KafkaTableITCase#testKafkaTemporalJoinChangelog testThis closes #14267,3
[FLINK-5884] [table] Integrate time indicators for Table API & SQL. Continued,2
[FLINK-17632][yarn] Always build the packaged program in the cluster for application mode,2
[FLINK-27376][table] Support current_database built-in function (#19218),1
[hotfix] remove unused code in RemoteStreamEnvironment.executeRemotely(),3
KAFKA-3864: make field.get return field's default value when neededAnd not the containing struct's default value.The contribution is my original work and that I license the work to the project under the project's open source license.ewencpAuthor: Rollulus <roelboel@xs4all.nl>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1528 from rollulus/kafka-3864,5
"[FLINK-1520] [gelly] add types methods and make formatting changes to the graph csv readerThis squashes the following commits:[FLINK-1520] [gelly] add named types methods for reading a Graph from CSV input,with and without vertex/edge values. Change the examples and the tests accordingly.[FLINK-1520] [gelly] corrections in Javadocs; updated documentationThis closes #1149",2
[FLINK-26387][connector/kafka] Use multi-broker kafka cluster in broker failure testsThis closes #18965.,3
KAFKA-8880: Docs on upgrade-guide (#7385)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[FLINK-8432] Add support for openstack's swift filesystemThis closes #5296.,5
"[FLINK-23896][streaming] Implement retrying for failed committables for Sinks.In batch mode and add stop-with-savepoint with drain, the CommitRetryer will wait indefinitively in a close loop to avoid data loss.Otherwise, it will retry every second until all commits succeed.",1
Reformatting PartitionTask,5
MINOR: Rename InitPidRequest/InitPidResponse to InitProducerIdRequest/InitProducerIdResponseAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2997 from hachikuji/minor-rename-initpid,5
remove StdErrLog from JettyHttpServer (#9052)* remove StdErrLog from JettyHttpServer (#8108)* add jetty logger adapter for JettyHttpServer(#8108)* add license* add unit test* change to English description,4
"[FLINK-16008][python][table-planner][table-planner-blink] Add rules to transpose the join condition as a Calc on top of the Python Correlate node (#11299)Since currently we don't support joining a Python UDTF with conditions,add a rule to transpose the condition as a Calc on top of the Python Correlate node.",1
Fix of JVM 6 related bug and enhancement of 2 other corner cases.,0
KAFKA-12862: Update Scala fmt library and apply fixes (#10784)Updates the scala fmt to the latest stable version.Applies all the style fixes (all source code changes are done by scala fmt).Removes setting about dangling parentheses as `true` is already thedefault.Reviewer: John Roesler <john@confluent.io>,5
Remove resources from swt visualization,4
[FLINK-10679] [core] Let TypeSerializerSnapshot.resolveSchemaCompatibility be the entry point for all compatibility checks,1
[FLINK-25159][tests] Fix rule usage,0
fix useless null check in ServiceConfig (#5580),5
[hotfix] Remove and deprecate memory preallocation in MemoryManager,4
[streaming] WordCount updated for cluster testing,3
[FLINK-27267][contrib] Migrate tests to JUnit5,3
"[FLINK-926] Add shallow copy, deep equality, and hashCode to Tuple classesThis closes #17.",1
[FLINK-3793][docs] re-organize table API and SQL docsThis closes #1955,2
[FLINK-1638] [streaming] Vertex level fault tolerance and state monitor,2
[FLINK-16220][json] Fix cast exception in JsonRowSerializationSchema when serializing null fieldsThis closes #11180,5
[FLINK-7934] [table] Clean up and add more EXTRACT tests,3
[FLINK-1964] Reimplement TwitterSourceThis closes #1796This closes #666,2
[scala] Make getType public in Scala DataSet,5
MINOR: Remove redundant volatile write in RecordHeadersThe JMH benchmark included shows that the redundantvolatile write causes the constructor of `ProducerRecord`to take more than 50% longer:ProducerRecordBenchmark.constructorBenchmark  avgt   15  24.136 ± 1.458  ns/op (before)ProducerRecordBenchmark.constructorBenchmark  avgt   15  14.904 ± 0.231  ns/op (after)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #3233 from ijuma/remove-volatile-write-in-records-header-constructor,4
[FLINK-24897][yarn] Make usrlib work for YARN application and per-jobThe $FLINK_HOME/usrlib will be shipped automatically and included into the system classpath when running a per-job/application cluster. This behavior can be controlled with the yarn.classpath.include-user-jar parameter.This closes #18531.,2
Merge branch 'warneke'Conflicts:nephele/nephele-server/src/main/java/eu/stratosphere/nephele/taskmanager/bytebuffered/OutgoingConnectionThread.javasolved by taking warneke's version.,5
MINOR: Correct spelling errors in KafkaRaftClient (#12061)Correct spelling errors in KafkaRaftClientReviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,1
KAFKA-440 Regression/system test framework; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1376147 13f79535-47bb-0310-9956-ffa450edef68,1
"[FLINK-11726][network] Refactor the creations of ResultPartition and SingleInputGate into NetworkEnvironmentAt the moment ResultPartition and SingleInputGate are created in Task. Based on new pluggable ShuffleManager, they should be created via ShuffleService#createResultPartitionWriter/InputGate.The NetworkEnvironment would be refactored into NetworkShuffleService future. So we could migrate the process of creating ResultPartition and SingleInputGate into current NetworkEnvironment. The metrics registration of network and buffers can also be done along with the creations.",1
[FLINK-29211][hive][legal] Update 2.3.9 NOTICE,5
Such logic already exists in findAnnotationName (#1750),2
"MINOR: Remove repeat creation of `ZkConfigRepository` (#11762)In `KafkaServer, `ZkConfigRepository` is just a wrapper of `zkClient`, so  we don't need to create a new one.Reviewers: Jason Gustafson <jason@confluent.io>",5
fix compile error (#8008),0
Improve robustness of task manager test,3
[FLINK-26280][table-planner] Add 'table.exec.legacy-transformation-uids' to support old transformation uid generation behaviourThis closes #18879.,1
[FLINK-22495][docs] Add Reactive Mode section to K8s,1
MINOR: Fix unrelated types comparison in MetadataRequestTest (#8195)The type of `leaderId` was changed to `Optional` in a recent change.Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"KAFKA-10286: Connect system tests should wait for workers to join group (#9040)Currently, the system tests `connect_distributed_test` and `connect_rest_test` only wait for the REST api to come up.The startup of the worker includes an asynchronous process for joining the worker group and syncing with other workers.There are some situations in which this sync takes an unusually long time, and the test continues without all workers up.This leads to flakey test failures, as worker joins are not given sufficient time to timeout and retry without waiting explicitly.This changes the `ConnectDistributedTest` to wait for the Joined group message to be printed to the logs before continuing with tests. I've activated this behavior by default, as it's a superset of the checks that were performed by default before.This log message is present in every version of DistributedHerder that I could find, in slightly different forms, but always with `Joined group` at the beginning of the log message. This change should be safe to backport to any branch.Signed-off-by: Greg Harris <gregh@confluent.io>Author: Greg Harris <gregh@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>",5
"MINOR: Add 2.1 version metadata upgrade (#6111)Updated the test_metadata_upgrade test. To enable using the 2.1 version I needed to add config change to the StreamsUpgradeTestJobRunnerService to ensure the ductape passes proper args when starting the StreamsUpgradeTestFor testing, I ran the test_metadata_upgrade test and all versions now pass http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2019-01-09--001.1547049873--bbejeck--MINOR_add_2_1_version_metadata_upgrade--a450c68/report.htmlReviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
Reworked WebLogAnalysis to new RecordInputFormat,1
"[FLINK-21356][state/changelog] Implement checkpointing using changelogBoth materialized and non-materialized state are checkpointed.But materialization and recovery from changelog will be implemented in subsequent commits.For now,- changelog grows indefinitely (not truncated)- state changes are not applied on recovery, tests fail with incorrect results",0
TRIVIAL: add @throws ConsumerWakeupException in KafkaConsumerAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen ShapiraCloses #311 from guozhangwang/wakeupComments,1
HOTFIX: fix for standby tasks using batching restoreAuthor: Bill Bejeck <bill@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3625 from bbejeck/HOTFIX_need_to_correct_stanby_task_restoration_to_use_new_restore_api,0
Ensured proper setup of logging framework in system integration tests.,3
[hotfix] [docs] Fix error in docs for zipping elements.This closes #3280.,2
"KAFKA-13280: Avoid O(N) behavior in KRaftMetadataCache#topicNamesToIds (#11311)Avoid O(N) behavior in KRaftMetadataCache#topicNamesToIds andKRaftMetadataCache#topicIdsToNames by returning a map subclass thatexposes the TopicsImage data structures without copying them.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-19542][k8s] Introduce data structures and interface for KubernetesLeaderElector,5
[FLINK-5698] [table] Add NestedFieldsProjectableTableSource interface.This closes #3269.,1
"[3.0] Nacos, add switch and disable consumer side registration by default (#9827)",1
"[hotfix] [core] Make sure Dropwizard reporters do not block operator creation/teardown while reportingThe ""report()"" method used to hold the same lock that was needed to create and shutdown metrics.Holding that lock too long could delay operator creation and teardown.This also removes the no longer needed dependency on dropwizard in flink-core.",2
[FLINK-6988][kafka] Add flink-connector-kafka-0.11 with exactly-once semantic,2
"KAFKA-6146; minimize the number of triggers enqueuing PreferredReplicaLeaderElection eventsWe currently enqueue a PreferredReplicaLeaderElection controller event in PreferredReplicaElectionHandler's handleCreation, handleDeletion, and handleDataChange. We can just enqueue the event upon znode creation and after preferred replica leader election completes. The processing of this latter enqueue will register the exist watch on PreferredReplicaElectionZNode and perform any pending preferred replica leader election that may have occurred between completion and registration.Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #4189 from onurkaraman/KAFKA-6146",2
"[FLINK-5670] Properly clean up local RocksDB directoriesWe have to change the instance path to not include too many nesteddirectories, otherwise the Keyed backend cannot properly clean up thewhole directory hierarchy.",4
[FLINK-16921][e2e] Print more information for debugging when Kubernetes e2e tests failed,0
"KAFKA-2851 Using random file names for local kdc files to avoid conflicts.I originally tried to solve the problem by using tempfile, and creating and using scp() utility method that created a random local temp file every time it was called. However, it required passing miniKdc object to SecurityConfig setup_node which looked very invasive, since many tests use this method. Here is the PR for that, which I think we will close: https://github.com/apache/kafka/pull/609This change is the least invasive change to solve conflicts between multiple tests jobs.Author: Anna Povzner <anna@confluent.io>Reviewers: Geoff AndersonCloses #610 from apovzner/kafka_2851_01",5
Added DefaultInputSplitAssigner as default fallback for GenericInputSplit.,1
KAFKA-3786: Let ConfigDef filter property key value pairsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1465 from guozhangwang/K3786-config-parsing,5
[tests] Simple code format in CountCollectITCase and suppresses sysout output for test.,3
DUBBO-438 修改单元测试,5
[FLINK-3375] [kafka connector] Add per-Kafka-partition watermark generation to the FlinkKafkaConsumerThis closes #1839,2
Add TupleSerializer tests.,3
[FLINK-10779][tests] Update Java / Scala StatefulJobSavepointMigrationITCase for 1.7,5
[streaming] Deleted StreamOperator,1
[FLINK-8362][elasticsearch] shade all dependencies,2
[FLINK-14246][runtime] Annotate MiniClusterITCase with AlsoRunWithSchedulerNG and fix broken testsThe tests broke because the error messages of NoResourceAvailableExceptions fromLegacyScheduler and DefaultScheduler are different.,0
[hotfix] Fix maven-javadoc-plugin configurationBecause we're now using Java 8 we have to disable linting also when notusing the (now-removed) jdk8 profile or the release profile.Because of this problem snapshot deployments were not working.,1
[hotfix][travis] Exclude all jars from cacheJar caching is not required since they are rebuilt in the test profiles anyway.,2
[hotfix][yarn] Rename YarnTaskExecutorRunner#run to #runTaskManagerSecurely,1
[FLINK-21885] Fixed minor typo within batch execution criteria,2
optimize some code styles (#4260)* optimize some code stylesSigned-off-by: jimin.jm <slievrly@163.com>* optimize some code stylesSigned-off-by: jimin.jm <slievrly@163.com>,5
"[FLINK-4289] Unset -x flag for .java filesSome source files had the -x flag set:Before this change:```$ find . -perm +111 -type f | grep ""\.java""./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/places/Attributes.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/places/BoundingBox.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/places/Places.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/Contributors.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/Coordinates.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/CurrentUserRetweet.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Entities.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/HashTags.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Media.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Size.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/Symbol.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/URL.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/entities/UserMention.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/tweet/Tweet.java./flink-contrib/flink-tweet-inputformat/src/main/java/org/apache/flink/contrib/tweetinputformat/model/User/Users.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/Graph.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/ApplyFunction.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/GatherFunction.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/GatherSumApplyIteration.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/Neighbor.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/gsa/SumFunction.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/GSAConnectedComponents.java./flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/GSASingleSourceShortestPaths.java./flink-libraries/flink-gelly-examples/src/main/java/org/apache/flink/graph/examples/GSASingleSourceShortestPaths.java./flink-libraries/flink-gelly-examples/src/test/java/org/apache/flink/graph/test/GatherSumApplyITCase.java./flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java```After this change:```$ find . -perm +111 -type f | grep ""\.java""```",4
"MINOR: Improve usage of LogCaptureAppender (#8508)Reviewers: Ismael Juma <ismael@confluent.io>, John Roesler <john@confluent.io>",5
"KAFKA-6238; Fix inter-broker protocol message format compatibility checkThis patch fixes a bug in the validation of the inter-broker protocol and the message format version. We should allow the configured message format api version to be greater than the inter-broker protocol api version as long as the actual message format versions are equal. For example, if the message format version is set to 1.0, it is fine for the inter-broker protocol version to be 0.11.0 because they both use message format v2.I have added a unit test which checks compatibility for all combinations of the message format version and the inter-broker protocol version.Author: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4583 from hachikuji/KAFKA-6328-REOPENED",5
[streaming] Added performance test data copying script,5
Added delta page rank example.,1
[FLINK-13807][tests] Use UTF-8 charset in TestBaseUtils.getResultReader,3
[FLINK-25186][table-common] Fix ServiceLoaderUtil#load to work with Java 11This closes #18020.,1
[FLINK-14454][tests] Re-enable SavepointSerializers.setFailWhenLegacyStateDetected after testsThis closes #9944,3
[FLINK-14255][hive] Integrate hive with parquet and orc format to streaming file sinkThis closes #12206,2
"[FLINK-7248] [kafka, tests] Remove invalid checkRestoredNullCheckpointWhenFetcherNotReady testThis test is an invalid remnant from recent major Kafka consumerrefactorings. The actual behaviour is covered bycheckRestoredCheckpointWhenFetcherNotReady. When the fetcher is not yetready and exposed and a checkpoint happens, we fallback to using anyrestored state as the checkpoint.This closes #4387.",1
[hotfix][pulsar] Disable tests,3
"KAFKA-13661; Consistent permissions in KRaft for CreatePartitions API (#11745)In #11649, we fixed one permission inconsistency between kraft and zk authorization for the `CreatePartitions` request. Previously kraft was requiring `CREATE` permission on the `Topic` resource when it should have required `ALTER`. A second inconsistency is that kraft was also allowing `CREATE` on the `Cluster` resource, which is not supported in zk clusters and was not documented in KIP-195: https://cwiki.apache.org/confluence/display/KAFKA/KIP-195%3A+AdminClient.createPartitions. This patch fixes this inconsistency and adds additional test coverage for both cases.Reviewers: José Armando García Sancio <jsancio@gmail.com>",3
[FLINK-18720][k8s] Enable pod creation interval for KubernetesResourceManagerDriver.,1
[hotfix][table-common] Fix LogicalType to DataType conversion for DistinctType,5
[FLINK-22773][coordination] Introduce DefaultLogicalEdge,2
"MINOR: Add Streams landing pageContent and assets for the updated Streams API landing pageAuthor: Derrick Or <derrickor@gmail.com>Reviewers: Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3540 from derrickdoo/streams-landing-page",5
[FLINK-2323] [api-breaking] Rename OperatorState interface methods to value() and update(..)Closes #890,5
[FLINK-25810][connector/kinesis] Renaming e2e test module for kinesis data streams.,5
- fixed NullPointerException bug in shutdown of TempTask,0
HOTFIX: fix table-table outer join and left join. more testsguozhangwang* fixed bugs in table-table outer/left joins* added more testsAuthor: Yasuhiro Matsuda <yasuhiro@confluent.io>Reviewers: Guozhang WangCloses #653 from ymatsuda/join_tests,3
KAFKA-8168; Add a generated ApiMessageType classAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Gwen ShapiraCloses #6510 from cmccabe/KAFKA-8168,5
[hotfix][test] Reduce test timeout to a reasonable value,3
"KAFKA-3406; Update CommonClientConfigs.RETRY_BACKOFF_MS_DOC doc stringAuthor: Manikumar reddy O <manikumar.reddy@gmail.com>Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>Closes #1230 from omkreddy/KAFKA-3406",1
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1403 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-7058: Comparing schema default values using Objects#deepEquals()https://issues.apache.org/jira/browse/KAFKA-7058* Summary of testing strategy: Added new unit testAuthor: Gunnar Morling <gunnar.morling@googlemail.com>Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #5225 from gunnarmorling/KAFKA-7058",5
[FLINK-4355] [cluster management] Add tests for the TaskManager -> ResourceManager registration.This closes #2395.,3
Support for BC Variables in Iterations.,1
Increased allowed cancelling time in PACT cancelling tests necessary due to slight changes in Nephele's event delivery order,4
[scripts] Fixes path for taskmanager.sh in the start-cluster.sh script,0
"KAFKA-6849: add transformValues methods to KTable. (#4959)See the KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-292%3A+Add+transformValues%28%29+method+to+KTableThis PR adds the transformValues method to the KTable interface. The semantics of the call are the same as the methods of the same name on the KStream interface.Fixes KAFKA-6849Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-23947] Improve logging of granting/revoking leadership in DefaultDispatcherRunnerThis commit logs on info level when the DefaultDispatcherRunner was granted or revoked its leadership.This closes #17033.,1
"[FLINK-7878] [api] make resource type extendible in ResourceSpecSummary:Now, flink only support user define CPU and MEM,but some user need to specify the GPU, FPGA and so on resources.So it need to make the resouce type extendible in the ResourceSpec.Add a extend field for new resources.Test Plan: UnitTestReviewers: haitao.wDifferential Revision: https://aone.alibaba-inc.com/code/D327427make Resource abstract and add GPUResource FPGAResourceThis closes #4911.Add a resource spec builder and remove FPGAResource",4
[FLINK-5073] Use Executor to run ZooKeeper callbacks in ZooKeeperStateHandleStoreUse dedicated Executor to run ZooKeeper callbacks in ZooKeeperStateHandleStore insteadof running it in the ZooKeeper client's thread. The callback can be blocking because itdiscards state which might entail deleting files from disk.Introduce dedicated Executor for blocking io operationsThis closes #2815.,2
[FLINK-23991][yarn] Specifying yarn.staging-dir fail when staging scheme is different from default fs schemeCloses #16994,0
MINOR: Fix typo in MirrorMaker v2 documentation (#10433)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
[FLINK-7404] [table] Generate code for non-equi join conditions only.This closes #4507.,2
[hotfix][build] Move jaxb copy into executionThis allows us to specify multiple executions that copy different file sets without having to worry what side-effects it may have.,1
[FLINK-2883] [docs] Add documentation to forbid key-modifying ReduceFunctionThis closes #3256,1
[FLINK-19341][table] Update all API related methods to FLIP-107This updates all API related classes to support the concept of ametadata column. It considers all location until planner level.- Updates TableColumn to a hierarchy of 3 column types.- Updates TableSchemaUtils and all related locations that rely oncomputed column but have to deal with metadata column as well now.This closes #13480.This updates all API related classes to support the concept of ametadata column. It considers all location until planner level.,5
"[FLINK-23064][table-runtime-blink] Expose options for ""raw"" format as PublicEvolving",2
[FLINK-16371][fs-connector] Add ITCaseThis closes #11307.,1
[refactor] Move Source Reader Test Utils classes from 'flink-core' test jar to 'flink-connector-test-utils',3
"MINOR: Fix typo in connect integration test class name (#7976)Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-13891: reset generation when syncgroup failed with REBALANCE_IN_PROGRESS (#12140)Reviewers: Luke Chen <showuon@gmail.com>,0
Split between source distribution license/notice and binary distribution license/notice.Add a DEPENDENCIES file to list all maven dependencies with licenses and notices.[ci skip],2
"Termination Criterion and PageRank for the new Java APIOptimization of SimplePagerank, setting of a correct serializer for the termination criterion, empty implementation of combiners for cogroup",1
[hotfix][docs]  Fix some typos in state_processor_api docs (#11033),2
[hotfix] Clean up CliFrontend after removing web client,4
修改simple注册中心git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@587 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Refactor return value (#4810)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-21801][table-api] Use new schema in Table and TableResultReplaces Table(Result).getSchema with Table(Result).getResolvedSchemaThis closes #15266.,0
[FLINK-5482] [tests] Dedup code in QueryableStateITCase,3
[FLINK-2863] [kafka connector] Kafka connector propagates async producer exceptions,2
"[hotfix][kafka,test] Handle shutdownCluster even if it wasn't initializedPreviously null pointer exception thrown from @AfterClass shutdown call could hideoriginal underlying issue if there was a failure that prevented kafkaServer from being constructed",0
"HOTFIX: fix flaky StateDirectoryTest.shouldReturnEmptyArrayIfListFilesReturnsNull (#8310)StateDirectoryTest.shouldReturnEmptyArrayIfListFilesReturnsNull always moves the stage dir to /tmp/state-renamed so it always fails if there is already a folder (for example, the stuff leaved by previous test).Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-10616: Always call prepare-commit before suspending for active tasks (#9464)Today for active tasks we the following active task suspension:1. closeAndRevive in handleTaskCorruption.2. closeClean in assignor#onAssignment.3. closeClean in shutdown.4. closeDirty in assignor#onAssignment.5. closeDirty in listener#onPartitionsLost.6. closeDirty in shutdown.7. suspend in listener#onPartitionsRevoked.Among those, 1/4/5/6 do not call prepareCommit which would stateManager#flushCache and may cause illegal state manager. This PR would require a prepareCommit triggered before suspend.Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",1
[hotfix][python] Remove nosiy warnings,2
[FLINK-4441] Make RocksDB backend return null on empty state + add test for all backendsCloses #2399,3
[FLINK-9838][logging] Don't log slot request failures on the ResourceManagerThis closes #6373.,0
[FLINK-11323] [tests] Adjust serializer tests to respect new COMPATIBLE_WITH_RECONFIGURED_SERIALIZER optionAdjust serializer tests to use the reconfigured serializer if suchserializer was provided.,1
[FLINK-21606] Fail hard if the ResourceManager rejects a JobMaster registration,0
KAFKA-13785: [7/N][Emit final] emit final for sliding window (#12135)This is a copy PR of #12037: Implementation to emit final for sliding window agg. This is authored by lihaosky.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"[FLINK-14912][Table] register, drop, and alter catalog functions from DDL via catalogthis closes #10450.",2
kafka-937; ConsumerFetcherThread can deadlock; patched by Jun Rao; reviewed by Joel Koshy,5
[FLINK-21214][kafka/IT] Add retry rule for FlinkKafkaProducerITCase,2
"[FLINK-9686] [kinesis] Allow creating AWS credentials by assuming a roleConfig example:```aws.credentials.provider: ASSUME_ROLEaws.credentials.provider.role.arn: <arn>aws.credentials.provider.role.sessionName: session-nameaws.credentials.provider.role.provider: AUTO```[FLINK-9686] [kinesis] Housekeeping: Use early return instead of variable assignment and break[FLINK-9686] [kinesis] Add dependency on aws-java-sdk-stsImplicitly (via `Class.forName`) used by `STSProfileCredentialsServiceProvider`.Due to shading, it is not possible to treat this as a ""provided"" dependency, asMaven rewrites the class name with the shaded one, which would force clients toprovide aws-java-sdk-sts shaded in the same way.[FLINK-9686] [kinesis] Mention new config option in docs[FLINK-9686] [kinesis] Use `STSAssumeRoleSessionCredentialsProvider` instead[FLINK-9686] [kinesis] Add constants for new config optionsThis closes #6221.",5
TRIVIAL: Fix spelling of log messageAuthor: Magnus Reftel <magnus.reftel@skatteetaten.no>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2335 from reftel/feature/triggering,5
Disable merging of Iteration Aux TasksThis will become obsolete once we have buffer oriented execution.Disable it for now because it is causing a bug: FLINK-1087,2
[FLINK-14009][build] Ignore license file check for Scala version different than 2.11This closes #9651.,2
KAFKA-8091; Remove unsafe produce from dynamic listener update test (#6443)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
[FLINK-19681][checkpointing] Switch controller before processing the first barrierIf a checkpoint announcement was processed and then UC-barrier arrives(from the upstream) then it should be processed by the UC controller.,2
[FLINK-6080] Unclosed ObjectOutputStream in NFA#serialize(),2
"MINOR: Mx4jLoader always returns false even if mx4j is loaded & startedMx4jLoader.scala should explicitly `return true` if the class is successfully loaded and started, otherwise it will return false even if the class is loaded.Author: Edward Ribeiro <edward.ribeiro@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #2295 from eribeiro/mx4jloader-bug",0
"MINOR: guard against calls to exit in QuorumTestHarness tests (#11457)Author: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Sherzod Mamadaliev <mamadaliev@yahoo.com>Closes #11457 from cmccabe/guard_against_exit",1
[FLINK-16245][table] Close user classloader,1
[hotfix] Fix testing log level in flink-runtime,2
[FLINK-9885] [elasticsearch] Major cleanup to finalize Elasticsearch 6.x connectorThis closes #6391.,4
Initial work on job status web interface part 2,1
[hotfix] [table] Show deserialization error cause,1
DUBBO-169 扩展点的set方法不是扩展点时忽略set操作，不要报错git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@827 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][release] Update the compatibility table for the release 1.14 and 1.15This closes #19144.,5
KAFKA-6233: Removed unnecessary null check in StringSerializerRemoved unnecessary null checkif (encodingValue != null && encodingValue instanceof String)null instanceof String returns false hence replaced the check withif (encodingValue instanceof String)Author: Sagar Chavan <sagar.chavan3172@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #4232 from sagarchavan3172/trunk,1
[FLINK-13632] Port ListSerializer upgrade test to TypeSerializerUpgradeTestBase,3
[FLINK-19246][table-planner] Fix TableSourceITCase.testStreamScanParallelism fails on AzureThis closes #13407,0
[FLINK-1473] Make abstract methods public in SplittableIterator,1
"MINOR: clean up unused checkstyle suppressions for Streams (#8861)Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"KAFKA-12648: fix NPE due to race condtion between resetting offsets and removing a topology (#11847)While debugging the flaky NamedTopologyIntegrationTest. shouldRemoveOneNamedTopologyWhileAnotherContinuesProcessing test, I did discover one real bug. The problem was that we update the TopologyMetadata's builders map (with the known topologies) inside the #removeNamedTopology call directly, whereas the StreamThread may not yet have reached the poll() in the loop and in case of an offset reset, we get an NP.eI changed the NPE to just log a warning for now, going forward I think we should try to tackle some tech debt by keeping the processing tasks and the TopologyMetadata in syncAlso includes a quick fix on the side where we were re-adding the topology waiter/KafkaFuture for a thread being shut downReviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
Fix a typo: warped,2
[FLINK-12359][metrics][tests] Harden SystemResourcesMetricsITCase,5
"KAFKA-3394; allow null offset metadata in commit APIAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Jun Rao <junrao@gmail.com>Closes #1064 from hachikuji/KAFKA-3394",5
[FLINK-2419] Add test for sinks after keyBy and groupByCloses #947,3
[hotfix] Fixes to flink-annotations JavaDocs,2
"[FLINK-6803] [tests] Fully enable PojoSerializerUpgradeTests for all state backendsWith the fixes for the PojoSerializer in, this commit fully enables alltests for upgrading the PojoSerializer for all state backends, whichotherwise could not pass before.This closes #4044.",4
[FLINK-25123][table-planner] Remove redundant info for the ExecNode's descriptionThis closes #18127,5
DUBBO-253 Spring配置解析时，标签的id号没有注入到Bean中，导致-D参数按id覆盖失效git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1150 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-1265] Fix user classloader bug for registerInputOutput() method,0
[FLINK-12968][table-common] Add a utility for logical type castsThis closes #8874.,2
[FLINK-24399][table-common] Add DataType#toInternalSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
"[FLINK-9386] Embed netty routerThis commit replaces netty-router dependency with our own version of it, which issimplified and adds guarantees about order of matching router patterns.This is a prerequisite for FLINK-3952. netty-router 1.10 is incompatible withNetty 4.1, while netty-router 2.2.0 brakes a compatibility in a way that wewere unable to use it.This closes #6031.",1
Add flag for unmanaged solution set to spargel,1
bump up fastjson's version,5
Fix ASM library version conflict.,5
KAFKA-3621; Add tests for ApiVersionRequest/ResponseAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1275 from SinghAsDev/KAFKA-3621,3
[hotfix][tests] Fix checkstyle violations in AkkaRpcServiceTest,3
"KAFKA-4289; moved short-lived loggers to companion objectsSigned-off-by: radai-rosenblatt <radai.rosenblattgmail.com>Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Onur Karaman <okaraman@linkedin.com>, Joel Koshy <jjkoshy.w@gmail.com>Closes #2006 from radai-rosenblatt/omgsrsly",2
[FLINK-13159] Fix the NPE when PojoSerializer restored,0
"KAFKA-8698: Fix typo in ListOffsetResponse v0 protocol field nameAuthor: asutosh936 <asutosh.pandya@hotmail.com>Reviewers: Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Vahid Hashemian <vahid.hashemian@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #7141 from asutosh936/KAFKA-8698",5
[FLINK-3786] [core] [api-extending] Add BigDecimal and BigInteger as Basic typesThis closes #1928.,1
"KAFKA-3282; Change tools to use new consumer if zookeeper is not specifiedAuthor: Arun Mahadevan <aiyer@hortonworks.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1376 from arunmahadevan/cons-consumer-fix",0
DUBBO-583 集成 hsf 的路由,5
[FLINK-22708][config] Propagate savepoint settings from StreamExecutionEnvironment to StreamGraph,1
[FLINK-20808][build] Remove redundant checkstyle rules,4
"MINOR: Remove unused abstract function in test class (#5888)The function `setup_producer_and_consumer` is unused in the system testframework, which incorrectly suggests subclasses should implementit. It is not required or even referenced by the framework, sothe requirement should be removed.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-21774][sql-client] Display all the SHOW command result in tableau formatThis closes #15213,2
[FLINK-18705][debezium] Fix Debezium-JSON throws NPE when tombstone message is receivedJust skip the tombstone messagesThis closes #13019,5
[FLINK-11463][tests] Add utilities- FactoryUtils for simplified ServiceLoader access- TestUtils for simplified resource jar access- ParameterProperty for defining parameters- OperatingSystemRestriction to restrict tests to operating systems,5
[FLINK-2722] Use InetAddress.getLocalHost() as first approach when detecting the TMs own ip/hostnameThis closes #1159,1
[FLINK-27766][sql-gateway] Introduce the basic components for the SqlGatewayService,2
metadata report status,5
[hotfix] [checkpoints] Remove incorrect 'Serializable' from StateBackendFactory,4
[FLINK-21794][metrics] Support retrieving slot details via rest apiThis closes #15249,1
[FLINK-17263][table-planner-blink] Replace RepeatFamilyOperandTypeChecker with CompositeOperandTypeChecker in plannerThis closes #11819,2
Cleaned up execution graph unit tests,3
[FLINK-10001][docs] Add documentation for job cluster deployment on Docker and K8s[FLINK-10001][docs] Add documentation for job cluster deployment on K8sThis closes #6561.,2
[FLINK-13375][table] Improve config names in ExecutionConfigOptions and OptimizerConfigOptionsThis closes #9203,5
[FLINK-10131][network] improve logging around subpartitions- add task name- add subpartition indexThis closes #6547.,1
Continued to work on channel refactoring,4
"KAFKA-4565; Separation of Internal and External traffic (KIP-103)Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #2354 from ijuma/kafka-4565-separation-of-internal-and-external-traffic",5
fix rule ip support,1
[docs] fix typos in quickstart and CEP docsThis closes #1663,2
KAFKA-10497 Convert group coordinator metadata schemas to use generat… (#9318)Reviewers: David Jacot <djacot@confluent.io>,5
"KAFKA-4749; Fix join-time-max and sync-time-max MeasurableStat typeGroupCoordinatorMetrics currently sets up join-time-max and sync-time-max incorrectly as a ""new Avg()"" MeasurableStat instead of ""new Max()""Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2520 from onurkaraman/KAFKA-4749",5
修改Monitor多线程测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1238 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fixed bug in selfmatch task after adapting to new datamodel,5
[FLINK-17593] Turn BucketStateSerializerTest into an upgrade testWe need this for future changes to the serialization format.,4
FLINK-3115: Update ElasticSearch connector to 2.xThis closes #1792,5
correct distribution name,5
[FLINK-24088][streaming] Log FlinkJobNotFoundException in debug instead of warn level in CollectResultFetcher for a cleaner logThis closes #17093,2
Polish apache/dubbo#6296 : Adding the new methods into MetadataReport to manipulate the exported URLs for service introspection (#6299),5
KAFKA-923 Improve controller failover latency. Remove unnecessary zookeeper reads; reviewed by Jun Rao,4
"[FLINK-7224] [kafka, docs] Fix incorrect Javadoc / docs regarding Kafka partition metadata queryingSince Flink 1.3, partition metadata is no longer queried on the clientside. This commit corrects the statements of this legacy behaviour inthe Javadocs and documentation.This closes #4310.",2
[FLINK-16690][tests] Refactor StreamTaskTest to reuse TestTaskBuilder and MockStreamTaskBuilderThis closes #11459,3
"[FLINK-15991][docs-zh] Translate the index of ""Memory Configuration"" into Chinese.This closes #11401",5
[FLINK-23912][coordination] Ignore repeated empty requirements declarations,1
[hotfix][test] Adjust suppressWarnings,2
"[FLINK-14246][runtime] Annotate TaskExecutorITCase with AlsoRunWithSchedulerNG and fix broken testsThe test testJobRecoveryWithFailingTaskExecutor was to fail because terminatingone TM will cause 2 tasks to fail, leading to 2 failure recoveries when usingDefaultScheduler. And the restart strategy limited max failure count to 1.",0
KAFKA-2089: Fix transient MetadataTest failure; reviewed by Jiangjie Qin and Guozhang Wang,0
"KAFKA-2666: Docs: Automatically generate documentation from config classes…the way we always planned toAuthor: Gwen Shapira <cshapi@gmail.com>Reviewers: Jun Rao, Guozhang WangCloses #382 from gwenshap/KAFKA-2666",5
[FLINK-19533][checkpoint] Introduce builder for OperatorSubtaskState.The builder will make it easier to add more fields to OperatorSubtaskState in future commits.,1
"[FLINK-3275] [py] Support for DataSet.setParallelism()-parallelism is stored Value object within the OperationInfo, so it can be passed as a reference to multiple operations (in cases where a set is internally executed as multiple operations)-setParallelism is called for every DataSet with either a user-set value or env.getParallelism-added a DataSink set, providing access to name() and setParallelism() for sinks",1
[FLINK-4207] WindowOperator becomes very slow with allowed lateness,1
Remove deprecation warning suppressions,2
"[FLINK-13145][runtime, tests] Enable fine grained failover in E2E HA data set test- Introduce new test job (DataSetFineGrainedRecoveryTestProgram), which waits  for an  external file to be created before finishing.- Introduce killing of TMs to HA data set test.- Reduce JM kills to 2.- Reduce heartbeat interval and timeout to speed up TM loss detection.This closes #9060.",3
[FLINK-19108][table] Stop expanding the identifiers with scope aliased by the system with 'EXPR$' prefixThis closes #13293,0
[scala-shell] [docs] Fixes wrong scala shell command in online documentation,2
KAFKA-3117: handle metadata updates during consumer rebalanceAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1247 from hachikuji/KAFKA-3117,5
Missing file from last commit,2
[FLINK-23680][streaming] Wait until all expected threads would be triggered in testOpenCloseAndTimestamps (#16797),3
KAFKA-2121; Fix Closeable backward-compatibility; reviewed by Guozhang Wang,0
[FLINK-9141][datastream] Fail early when using both split and side-outputsThis closes #5836.This closes #5479.This closes #4893.This closes #4809.This closes #4621.This closes #3915.,1
[FLINK-9181] [docs] [sql-client] Add documentation for the SQL ClientThis closes #5913.,2
testcase:修复 HeaderExchangeClient/HeaderExchangeServer 单元测试错误,4
"KAFKA-5856; AdminClient.createPartitions() follow-up (KIP-195)- Remove DelayedCreatePartitions to reduce code duplication- Avoid unnecessary ZK calls (call it once per request insteadof once per topic, if possible)- Simplify code- A few minor clean-upsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Tom Bentley <tbentley@redhat.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3930 from ijuma/kafka-5856-admin-client-creation-partitions",1
DUBBO-485 owner配置允许填写多个负责人,5
[FLINK-14656][table-planner-blink] blink planner should also fetch catalog statistics for permanent table (#10119),2
"MINOR: Improve performance of checkpointHighWatermarks, patch 1/2 (#6741)This PR works to improve high watermark checkpointing performance.`ReplicaManager.checkpointHighWatermarks()` was found to be a major contributor to GC pressure, especially on Kafka clusters with high partition counts and low throughput.Added a JMH benchmark for `checkpointHighWatermarks` which establishes aperformance baseline. The parameterized benchmark was run with 100, 1000 and2000 topics. Modified `ReplicaManager.checkpointHighWatermarks()` to avoid extra copies and cachedthe Log parent directory Sting to avoid frequent allocations when calculating`File.getParent()`.A few clean-ups:* Changed all usages of Log.dir.getParent to Log.parentDir and Log.dir.getParentFile toLog.parentDirFile.* Only expose public accessor for `Log.dir` (consistent with `Log.parentDir`)* Removed unused parameters in `Partition.makeLeader`, `Partition.makeFollower` and `Partition.createLogIfNotExists`.Benchmark results:| Topic Count | Ops/ms | MB/sec allocated ||-------------|---------|------------------|| 100               | + 51%    |  - 91% || 1000             | + 143% |  - 49% || 2000            | + 149% |   - 50% |Reviewers: Lucas Bradstreet <lucas@confluent.io>. Ismael Juma <ismael@juma.me.uk>Co-authored-by: Gardner Vickers <gardner@vickers.me>Co-authored-by: Ismael Juma <ismael@juma.me.uk>",5
[hotfix][runtime] Fix checkstyle violations in RestartStrategyFactory,0
"KAFKA-13883: Implement NoOpRecord and metadata metrics (#12183)Implement NoOpRecord as described in KIP-835. This is controlled by the newmetadata.max.idle.interval.ms configuration.The KRaft controller schedules an event to write NoOpRecord to the metadata log if the metadataversion supports this feature. This event is scheduled at the interval defined inmetadata.max.idle.interval.ms. Brokers and controllers were improved to ignore the NoOpRecord whenreplaying the metadata log.This PR also addsffour new metrics to the KafkaController metric group, as described KIP-835.Finally, there are some small fixes to leader recovery. This PR fixes a bug where metadata version3.3-IV1 was not marked as changing the metadata. It also changes the ReplicaControlManager toaccept a metadata version supplier to determine if the leader recovery state is supported.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
[hotfix][runtime] rename ContinuousFileReaderOperator.TRANSITIONS to VALID_TRANSITIONS,2
"[FLINK-13529][table-planner-blink] Remove the second parameter of FIRST_VALUE and LAST_VALUEAccording to ANSI-SQL, FIRST_VALUE and LAST_VALUE are ordered set function which require the within group clause to specify an order instead of pass the order field as a parameter.This closes #9316",2
Remove unused import from OutboundEnvelopeEncoderTest,3
[hotfix] Remove Nonnull annotations from DispatcherFactory and sub classes,4
kafka-1461; Replica fetcher thread does not implement any back-off behavior; patched by Sriharsha Chintalapani; reviewed by Jun Rao,5
[FLINK-18039] Ensure the source events are sent via the coordinator thread.,2
[FLINK-21256] Add Executing state for declarative scheduler,1
"KAFKA-5900: Add task metrics common to both sink and source tasksAdded metrics that are common to both sink and source tasks.Marked as ""**WIP**"" since this PR is built upon #3864, and will need to be rebased once that has been merged into `trunk`. However, I would still appreciate initial reviews since this PR is largely additive.Author: Randall Hauch <rhauch@gmail.com>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #3911 from rhauch/kafka-5900",5
"HOTFIX: Fix bug in readToLogEnd in KafkaBasedLog.Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2211 from kkonstantine/HOTFIX-Correctly-read-to-end-of-offsets-log-in-Connect-KafkaBasedLog",2
[FLINK-24728][table-runtime] Close output stream in batch SQL file sinkThis closes #17638,2
[FLINK-26251][akka] Migrate test to JUnit5,3
[FLINK-20522][table] Add built-in IFNULL functionThis closes #14378.,1
[FLINK-16068][table-planner-blink] Fix DDL fails when both computed column and keyword-escaped column exist (#11101),0
MANIFEST.MF configuration,5
[hotfix][flink-avro] Use local actual schema variable (#17305),1
"Parameters zkSessionTimeOutMs and zkConnectionTimeoutMs are reversed in SimpleAclAuthorizerAlso use named parameters in KafkaServer for clarity (even though it was correct previously).Author: Matt <wangm92@163.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1646 from wangzzu/wangzzu",2
"MINOR: Gracefully handle non-assigned case in fetcher metric (#7383)Minor tweak to gracefully handle a possible IllegalStateException while checking a metric value.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",5
fixed: PactRecord allocating too few memory when writing UTF encoded strings,0
MINOR: remove DelayedOperations.checkAndCompleteFetch (#9278)Reviewers: Jun Rao <junrao@gmail.com>,4
"Dubbo cloud native (#4817)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components",1
修改测试配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1453 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-28161][sql-gateway]Introduce the session related API for REST endpointThis closes #20418,2
[hotfix][network] Removed unused method in LocalInputChannel,1
Remove usage of classes in Junit 4,3
[FLINK-1172] [docs] Fix broken links in documentationThis closes #206,2
[FLINK-7755] [table] Fix NULL handling in batch joins.- Fixes also [FLINK-5498] Add support for non-equi join and local predicates to outer joinsThis closes #4858.This closes #3379 (stale PR for FLINK-5498).,2
kafka-1076; system tests in 0.8 are broken due to wrong log4j config; patched by Joel Koshy; reviewed by Jay Kreps and Jun Rao,5
[FLINK-19624][table-planner-blink] Update deadlock break-up algorithm to cover more cases (#13692),4
"MINOR: fix NamedCache metrics in Streams (#4917)* Fixes a bug in which all NamedCache instances in a process sharedone parent metric.* Also fixes a bug which incorrectly computed the per-cache metric tag(which was undetected due to the former bug).* Drop the StreamsMetricsConventions#xLevelSensorName conventionin favor of StreamsMetricsImpl#xLevelSensor to allow StreamsMetricsImplto track thread- and cache-level metrics, so that they may be cleanly declaredfrom anywhere but still unloaded at the appropriate time. This was necessaryright now so that the NamedCache could register a thread-level parent sensorto be unloaded when the thread, not the cache, is closed.* The above changes made it mostly unnecessary for the StreamsMetricsImpl toexpose a reference to the underlying Metrics registry, so I did a little extra workto remove that reference, including removing inconsistently-used and unnecessarycalls to Metrics#close() in the tests.The existing tests should be sufficient to verify this change.Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[hotfix] Fix the missing comma in create_snapshot_branch.sh,1
修改错误的testcasegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1519 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-2523] [taskmanager] Increase interrupt timeout in TaskManager task.,1
- generalized NepheleReaderIterator- added IteratorNepheleReader,1
[FLINK-22577][tests] Harden KubernetesLeaderElectionAndRetrievalITCaseThis commit introduces closing logic to the TestingLeaderElectionEventHandler which wouldotherwise forward calls after the KubernetesLeaderElectionDriver is closed.This closes #15849.,3
[FLINK-16222][runtime] Introduce PluginManager to ReporterSetup,1
"KAFKA-7697: Process DelayedFetch without holding leaderIsrUpdateLock (#5999)Delayed fetch operations acquire leaderIsrUpdate read lock of one or more Partitions from the fetch request when attempting to complete the fetch operation. While appending new records, complete fetch requests after releasing leaderIsrUpdate of the Partition to which records were appended to avoid deadlocks in request handler threads.Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",5
MINOR: Kafka Streams updates for 2.7.0 release (#9773)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
KAFKA-1472; Add the compression ratio metrics in the new producer; patched by Dong Lin; reviewed by Guozhang Wang and Jun Rao,1
MINOR: Fix documentation for KIP-585 (#9524)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
[hotfix] Fix checkstyle violations in EvictingBoundedList,0
"[FLINK-26843][table-planner] Replace `TableConfig` with `ReadableConfig`Replace `TableConfig` with `ReadableConfig` where possible, to cleanupthe usages, and make sure that `TableConfig` is only used where it'sabsolutely necessary, because of the extra functionality it provides.",1
[hotfix][docs] Update Yarn setup documentation with Flip-6,2
"MINOR: bump version in kraft readme (#11596)Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Jacot <djacot@confluent.io>",5
KAFKA-12879: Remove extra sleep (#11872),4
[FLINK-7603] [table] Support WITHIN clause in MATCH_RECOGNIZEIntroduces support for WITHIN clause in MATCH_RECOGNIZE thatallows adding a time constraint for a pattern. It reuses thewithin function of Pattern in the CEP library. The behavioris such that the difference between first row in a match andlast row in a match must be smaller than the given period. TheWITHIN clause accepts only a constant millisecond interval value.,1
Fix method sigs that may not pass original check (#9417),4
MINOR: Fix `GroupCoordinator.onGroupLoaded` log (#11434)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
"KAFKA-6145: Pt 2. Include offset sums in subscription (#8246)KIP-441 Pt. 2: Compute sum of offsets across all stores/changelogs in a task and include them in the subscription.Previously each thread would just encode every task on disk, but we now need to read the changelog file which is unsafe to do without a lock on the task directory. So, each thread now encodes only its assigned active and standby tasks, and ignores any already-locked tasks.In some cases there may be unowned and unlocked tasks on disk that were reassigned to another instance and haven't been cleaned up yet by the background thread. Each StreamThread makes a weak effort to lock any such task directories it finds, and if successful is then responsible for computing and reporting that task's offset sum (based on reading the checkpoint file)This PR therefore also addresses two orthogonal issues:1. Prevent background cleaner thread from deleting unowned stores during a rebalance2. Deduplicate standby tasks in subscription: each thread used to include every (non-active) task found on disk in its ""standby task"" set, which meant every active, standby, and unowned task was encoded by every thread.Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",5
[hotfix][connectors/kafka] Correctly check required configs in KafkaSourceBuilder,5
"Rework the Taskmanager to a slot based model and remove legacy cloud codeSquashed commit of the following:  - Post merge cleanup  - Renamed fractionMemory into memoryFraction.  - Removed Local and QueueScheduler and replaced it instead with an unified DefaultScheduler.  - Removed Local and ClusterManager and inserted instead an unified DefaultInstanceManager.  - Removed connection IDs from execution edges  - Removed InstanceType, InstanceRequestMap, InstanceTypeDescription, InstanceTypeDescriptionTypeFactory, PendingRequestsMap  - Fixed problems with test cases.  - introduced simple slot system for scheduling.  - Removed subtasks per instance  - Added registerTaskManager to the JobManager RPC calls. RegisterTaskManager is called only once where the hardware description information is sent.Add: Merging cloudmodel remove with new network stack",1
Remove usage of classes in Junit 4,3
"follow up for pr#4339, remove the space (#4591)",4
"[FLINK-14399] Implement reservation of memory chunks in MemoryManagerMemoryManager allocates paged segments from the provided memory pools of different types (on-/off-heap).Additionally, it can manage reservation and release of arbitrarily sized chunks of memory from the same memory poolsrespecting their overall limit. The way, how the memory is allocated, used and freed, is then up to the memory user.MemoryManager is just a book-keeping and limit checking component.",1
[FLINK-4963] [gelly] Tabulate edge direction for directed VertexMetricsThe current implementation simply counts edges. We can do one better andtabulate unidirectional (u:v but no v:u) and bidirectional edges (u:vand v:u).This is effectively the 'dyadic census'.This commit also makes edge metrics distinct from vertex metrics.Previously EdgeMetrics has always been a superset of VertexMetrics.This closes #2725,1
Improved log message in EC2 cloud manager,2
[FLINK-6229] [py] Rework setup of PythonPlanBinder- make file/argument split more readable- pass on Paths where applicable instead of recreating them every time- rename PPB#clearPath to more appropriate deleteIfExists- simplify PPB#copyFile- simplify PPB#startPython- use UUID#randomUUID() instead of Random.nextInt()- remove several invalid exception declarations,4
[hotfix] Segregate TaskSlotPayload interface from Task for TaskSlot and TaskSlotTable,0
unit test for ServiceConfig (#1780)* unit test for RegistryConfigTest* unit test for ServiceConfig* ignore com.alibaba.dubbo.config.ServiceConfigTest.testUnexport to make unit test stable,3
"MINOR: Update authorizer start-up check to handle end point with ephemeral portAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>Closes #7350 from omkreddy/checkstartup",5
DUBBO-487 修复异步调用参数,5
[FLINK-23204] Provide StateBackends access to MailboxExecutor (#16531)There are several places in ChangelogStateBackend that need execute actions from the task thread- DFS writer: collect so far uploaded changes; handle upload results after completion- ChangelogKeyedStateBackend: checkpointing to combine state handles upon upload completion by writer- ChangelogKeyedStateBackend: materialization take a snapshot (sync phase) and handle results of the async phaseThis PR provides access to mailbox executor to simply threading model (avoid using lock).,1
trivial fix to authorization CLI table,0
DUBBO-520 ExtensionLoader的getExtension名字转入true不应返回缺省扩展,1
correct grammar issue,0
[FLINK-17899][runtime] Integrate FLIP-126 Watermarks with FLIP-27 Sources,2
Fix error with invalid config values for degree of parallelism.,5
"KAFKA-6360: Clear RocksDB Segments when store is closedNow that we support re-initializing state stores, we need to clear the segments when the store is closed so that they can be re-opened.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>Closes #4324 from dguy/kafka-6360",5
[FLINK-22939][azure] Generalize JDK switch,2
[hotfix][task] Remove unncessary SuppressWarnings from StreamOneInputProcessor,2
"[FLINK-2226][YARN] fail application on failed single-job cluster jobFailing jobs executed in the YARN cluster mode leave the applicationcontainer in the ""SUCCEEDED"" final state. While for long-running FlinkYARN clusters where multiple jobs are run, this is fine, for single jobsit is appropriate to mark the application as failed.This closes #838.",0
[FLINK-6941] [table] Validate that start and end window properties are not accessed on over windows.This closes #4137.,5
[Dubbo-3106]Make getRegistered return unmodifiable collection. #3106 (#3425)* make getRegistered return unmodifiable collection. #3106* fix ci failure,0
[FLINK-4993] Remove Unused Import in TriggerResult,2
[FLINK-11142][docs] Point out fields can be projected out for Position-based MappingThis closes #7352,2
"change ""try"" to ""try resource"" in  IOUtils.java (#5586)",1
[FLINK-1443] Added support for replicated data sources.Introduced new PartitioningProperty for any distribution (random partitioning or full replication).,5
[FLINK-15375][core] Introduce MemorySize#toHumanReadableString.,2
[FLINK-8698] [flip6] Use Flip6LocalStreamEnvironment instead of LocalStreamEnvironment,1
Add test for reduce operator translation,1
[hotfix][table-api-java] Missing @Test annotation in TableEnvironmentTest,3
"[FLINK-16943][python] Support to set the configuration option ""pipeline.jars"" in PyFlink (#11768)",2
fix reference cache (#7412),0
[hotfix][runtime-tests] Deduplicate CollectingResultPartitionWriters classes,3
[hotfix][docs][kafka] Fix code formatting,0
"MINOR: Change type of StreamsConfig.BOOTSTRAP_SERVERS_CONFIG to ListThis is an improved version of https://github.com/apache/kafka/pull/1374, where we include a unit test./cc ijuma and guozhangwangAuthor: Guozhang Wang <wangguoz@gmail.com>Author: Michael G. Noll <michael@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1377 from miguno/streamsconfig-multiple-bootstrap-servers",5
[docs] Add separate AWS setup page,1
[FLINK-14371][tests] Annotate EventTimeWindowCheckpointingITCase with AlsoRunWithSchedulerNG category,1
Fix combiner for group reduce.,0
MINOR: Read configuration fields from ProducerConfig in example (#4601)Reading the configuration field names from ProducerConfig class and taking the key and value serializer names from class name directly instead of hardcoding.,5
[FLINK-19205][core] Add access to configuration and hostname in the SourceReaderContext,5
"MINOR: Typo in documentation of topic config removalAuthor: Ján Koščo <3k.stanley@gmail.com>Reviewers: Ismael Juma, Grant Henke, Guozhang WangCloses #768 from s7anley/trunk",1
Server close时输出日志，与Start的日志对应git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@985 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-7349] [travis] Only execute checkstyle in misc profileThis closes #4460.,2
[FLINK-17374][travis] Remove tools/travis directory,4
[FLINK-16467][core] Fix MemorySizeTest#testToHumanReadableString failure due to different string formats in different locales.,0
"HOTFIX: Persistent store in ProcessorStateManagerTestymatsuda junrao Could you take a quick look? The current unit test is failing on this.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ismael Juma, Jun RaoCloses #276 from guozhangwang/HF-ProcessorStateManager",0
[FLINK-20765][table-planner] Fix ScalarOperatorGens doesn't set proper nullability for result type of generated expressionsThis closes #19851,1
"[FLINK-20513][table-planner-blink] Introduce StreamPhysicalExchange, and make StreamExecExchange only extended from ExecNodeThis closes #14384",4
[hotfix] Update README.md building prerequisitesThis closes #5924,3
KAFKA-2859: Fix deadlock in WorkerSourceTask.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #554 from ewencp/kafka-2859-deadlock-worker-source-task,1
[FLINK-5389] [tests] Increate ask timeout in JobSubmitTest,3
[FLINK-28990][table-planner] Fix BatchPhysicalDynamicFilteringDataCollector with empty output typeThis closes #20594,5
[FLINK-21426][docs] adds English details to jdbc sink connectorThis closes #14975,5
"[FLINK-3260] [runtime] Enforce terminal state of ExecutionsThis commit fixes the problem that Executions could leave their terminal stateFINISHED to transition to FAILED. Such a transition will be propagated to theExecutionGraph where it entails JobStatus changes. Since the Execution alreadyreached a terminal state, it should not again affect the ExecutionGraph. Thiscan lead to an inconsistent state in case of a restart where the old Executionsget disassociated from the ExecutionGraph.This closes #1613",1
"[FLINK-27050][runtime] Removes default RpcSystem instanceHaving a default RpcSystem in TestingDispatcher.Buildercaused threads being spawned without cleanup. Instead, weshould rely on the RpcSystem instance provided by the test.",3
[hotfix] Fix typo in JobManager,2
"MINOR: Fix logged timeout in KafkaProducer.close() (#4623)The log line says `ms`, but the actual value could represent adifferent time unit depending on what the user provided.Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-4664] [webUI] Show uploaded-jars descending by upload timeThis closes #4664.,2
"MINOR: improve MinTimestampTrackerTest and fix NPE when null element removedAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Guozhang WangCloses #2611 from dguy/testing",3
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1446 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Fix testPublishConfigCas exec fail (#7664)* fix testPublishConfigCas exec fail* fix AbstractInterfaceBuilderTest.build test case.* disable testGetResource,3
KAFKA-10000: Utils methods for overriding user-supplied properties and dealing with Enum types (#11774)Reviewers: Mickael Maison <mickael.maison@gmail.com>,1
"MINOR: Clarify meaning of end offset in consumer javadocs (#4885)Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
"[FLINK-17135][python][tests] Fix the test testPandasFunctionMixedWithGeneralPythonFunction to make it more stableThere are two caches in RelDataTypeFactoryImpl: KEY2TYPE_CACHE andDATATYPE_CACHE. KEY2TYPE_CACHE caches the mapping of Key(consists offield names and field types, etc) to RelDataType and can be used for thecanonization of row types. DATATYPE_CACHE caches the RelDataType instances.PythonCalcSplitRule will split a Calc RelNode which contains bothnon-vectorized Python UDF and vectorized Python UDF into two Calc RelNodes.For the test case testPandasFunctionMixedWithGeneralPythonFunction,the output type of the bottom Calc consists of two fields (f0: INTEGER, f1: INTEGER),let's call it row_type_0. This row type is already available in the cache(generated by other test cases, held in variable KEY2TYPE_CACHE) and so it will hit thecache when constructing this row type for the bottle Calc. However, during debugging, Ifound that the INTEGER type referenced by row_type_0 is already cleanedup from the cache DATATYPE_CACHE. Then when constructing the RexProgramfor the top Calc, it creates another INTEGER type and failure happens.To work around this problem, we adjust the test case a bit to make theoutput row type of the bottom Calc consisting of three fields instead oftwo fields to make the cache hit fail.",0
[FLINK-25436] Let BlobServer automtically expire recovered transient blobsThis commit enables the BlobServer to automatically register expiration timeoutsfor recovered transient blobs. This makes sure that orphaned transient blobs getcleaned up eventually.,4
"KAFKA-5697: Use nonblocking poll in Streams (#5107)Make use of the new Consumer#poll(Duration) to avoid getting stuck in poll when the broker is unavailable.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[ml] [docs] Fixes broken back links,2
"[FLINK-9331] [mesos] Let MesosResourceManager request new tasks for failed onesIn order to avoid the problem of not fulfilling allocation requests when a Mesostasks dies before it could register at the RM, this commit restarts all failedMesos tasks. The downside is that in some cases where the JM notices the failureof a TM and would fail the job, we request tasks which are not directly needed.This closes #5986.",0
"Added hash and equals methode in CoerceExpression, added testcases for CoerceExpression, added new testcase for NumberCastingExpression",3
[FLINK-14870][runtime] Ensure JobVertex slot sharing group to be non-null when created from a StreamNode,1
[FLINK-18907][test] Refactor MockSourceReaderMake the synchronisation around availability easier to understand.,1
Minor dependencies cleanup:  - Move sling JSON dependency to streaming connectors (prev streaming core)  - Exclude YARN API from transitive mapreduce-core dependencies we use the dependency    only for .mapred and .mapreduce interfaces  - Remove some unnecessary dependencies (junit in java8)  - Manage Kryo dependency  - Cleanup minor POM warnings.,2
[hotfix] Make 'force-shading' deployable,1
[docs] Broken links in Hive documentationThis closes #9435.,2
[FLINK-20968][table-planner-blink] Remove legacy exec nodesThis closes #14733,4
[FLINK-20903] Pass JobStatusListener to SchedulerBase,4
[FLINK-11382][docs] Update documentation,2
DUBBO-305 消费者地址注册失败不抛错，在后台重试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1466 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-14338][sql-parser] Bump sql parser Calcite dependency to 1.22.0* Add Junit5 supports for tests* Move classes under package calcite.sql to flink.sql.parser.type* Remove ExtendedSqlBasicTypeNameSpec, use SqlAlienSystemTypeNameSpec instead* In Parser.tdd, re-organize the imports order to alphabetical order, remove the useless tailing commas, extends nonReservedKeywordsToAdd* Fix the JavaCC compile warnings",2
[streaming] WordCount update for testing,3
"KAFKA-9159: The caller of sendListOffsetRequest need to handle retriable InvalidMetadata (#7665)Loop call Consumer.endOffsets Throw TimeoutException: Failed to get offsets by times in 30000ms after a leader change.Reviewers: Steven Lu, Guozhang Wang <wangguoz@gmail.com>",4
[FLINK-15904][connectors/kafka] Use explicit Serializer for KafkaConsumer unionOffsetStates,1
Extend ConnectedComponentsITCase instead of code duplication for SpargelConnectedComponentsITCase,2
"KAFKA-7259; Remove deprecated ZKUtils usage from ZkSecurityMigrator- Remove ZKUtils usage from various testsAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Ismael Juma <ismael@juma.me.uk>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>Closes #5480 from omkreddy/zkutils",3
"[FLINK-6448][web] Rename ""Free Memory"" field to ""JVM Heap Size""",2
"MINOR: improve error message for Streams testAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4253 from mjsax/minor-imporve-error-message",0
add config module back and remove bootstrap module,4
"[FLINK-12993][runtime] Refactor forceReleaseOnConsumption to JM conceptThe forceReleaseOnConsumption option/flag is now only evaluated on the JobMaster side and transparent to task managers,",1
- extended optimzer nodes with input schema check,5
[FLINK-11413][metrics] Fix reporter filtering on JDK 9,0
KAFKA-12991; Fix unsafe access to `AbstractCoordinator.state` (#10879)This patch fixes the unsynchronized accesses to `AbstractCoordinator.state`.Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,0
[FLINK-13051][runtime] Drop the non-selectable StreamTask and InputProcessor,4
修改profilegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@2048 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[3.0] ServiceAnnotationBeanPostProcessor should be changed to ServiceClassPostProcessor (#7836),4
[FLINK-26421][python] Remove TableConfig from StreamTableEnvironment#createFollowing: 57742b85095147711070c566069244c40ed8e77c remove the`TableConfig` from `StreamTableEnviroment#create()` and allowconfiguration only via `EnviromentSettings.with_configuration()`.,5
[FLINK-11373] Don't cut of error message in CliFrontend,0
"[hotfix] Suppress emitting non-causal exceptions from closed checkpointing threadThis avoids that an exception that is caused by closing a running snapshot is reported.With this we avoid that users get confused by their logs or that this exception could bereported before its actual cause, thus hiding the real cause in logs.",2
MINOR: Small refactorings in admin group handlers (#11079)Small refactoring to make the code uniform across the newly introduced admin group handlers.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>,5
"KAFKA-5098; KafkaProducer should reject sends to invalid topics…egal char and generates InvalidTopicExceptionIf config parameter max.block.ms config parameter is set to a non-zero value,KafkaProducer.send() blocks for the max.block.ms time if topic name has illegalchar or is invalid.Wrote a unit test that verifies the appropriate exception is returned whenperforming a get on the returned future by KafkaProducer.send().Author: Ahmed Al Mehdi <aalmehdi@aalmehdi-ld1.linkedin.biz>Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy@gmail.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>Closes #5247 from ahmedha/KAFKA-5098",2
"[FLINK-4155] [kafka] Move partition list fetching  to open() for Kafka producersThe fetched partition list from Kafka in open() is sorted by partition idso that subtasks will have the same list across failures. To compensate the originaluse of the KafkaProducer instantiation in the constructor to eagerlyensure that required producer configs are provided, we check that at leastthe bootstrap servers are set.This change also includes refactoring of AtLeastOnceProducerTest for a morecomplete suite of tests on FlinkKafkaProducerBase.This closes #2681.",2
HOTFIX: delete removed WindowedStore.put() method (#10517)Reviewers: Boyang Chen <boyang@confluent.io>,5
"[FLINK-16135][core] Unify the TemporaryClassLoaderContext and AutoContextClassLoaderThese two classes did teh same thing, this commit unifies the use to a consolidated instance.This closes #11120",5
[FLINK-7516][memory] do not allow copies into a read-only ByteBuffer[FLINK-7516][memory] address PR commentsThis closes #4593.,1
Merge branch 'michael'Conflicts:sopremo/sopremo-cleansing/src/main/java/eu/stratosphere/sopremo/cleansing/transitiveClosure/TransitiveClosure.java,5
[Dubbo -fix annotation bug] Fix @Reference bug (#2649)It's fine.,0
"KAFKA-10669: Make CurrentLeaderEpoch field ignorable and set MaxNumOffsets field default to 1Couple of failures observed after KAFKA-9627: Replace ListOffset request/response with automated protocol (https://github.com/apache/kafka/pull/8295)1. Latest consumer fails to consume from 0.10.0.1 brokers. Below system tests are failingkafkatest.tests.client.client_compatibility_features_test.ClientCompatibilityFeaturesTestkafkatest.tests.client.client_compatibility_produce_consume_test.ClientCompatibilityProduceConsumeTestSolution: Current default value for MaxNumOffsets is 0. because to this brokers are not returning offsets for v0 request. Set default value for MaxNumOffsets field to 1.  This is similar to previous [approach](https://github.com/apache/kafka/blob/2.6/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java#L204)2. In some scenarios, latest consumer fails with below error when connecting to a Kafka cluster which consists of newer and older (<=2.0) Kafka brokers`org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default currentLeaderEpoch at version 3`Solution: After #8295, consumer can set non-default CurrentLeaderEpoch value for v3 and below requests. One solution is to make CurrentLeaderEpoch ignorable.Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: David Jacot <djacot@confluent.io>Closes #9540 from omkreddy/fix-listoffsets",0
"KAFKA-10319: Skip unknown offsets when computing sum of changelog offsets (#9066) (#9097)In PR #8962 we introduced a sentinel UNKNOWN_OFFSET to mark unknown offsets in checkpoint files. The sentinel was set to -2 which is the same value used for the sentinel LATEST_OFFSET that is used in subscriptions to signal that state stores have been used by an active task. Unfortunately, we missed to skip UNKNOWN_OFFSET when we compute the sum of the changelog offsets.If a task had only one state store and it did not restore anything before the next rebalance, the stream thread wrote -2 (i.e., UNKNOWN_OFFSET) into the subscription as sum of the changelog offsets. During assignment, the leader interpreted the -2 as if the stream run the task as active although it might have run it as standby. This misinterpretation of the sentinel value resulted in unexpected task assignments.Ports: KAFKA-10287 / #9066Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <vvcephei@apache.org>, Matthias J. Sax <mjsax@apache.org>",5
"[FLINK-20856][table-planner-blink] Introduce StreamPhysicalPythonGroupWindowAggregate, and make StreamExecPythonGroupWindowAggregate only extended from ExecNodeThis closes #14569",1
[FLINK-2003] [docs] Added instructions for encrypted filesystemsThis closes #1100,5
[FLINK-2642] [table] Scala Table API crashes when executing word count exampleThis closes #1209.,2
[release] Upgrade current version to 1.15 for TypeSerializerSnapshotMigrationITCase and create snapshots,1
[FLINK-16821][e2e] Use constant minikube version instead of latest,3
[FLINK-12784][metrics] Support retention policy for InfluxDB metrics reporter,5
[hotfix][table-planner-blink] Fix statistics extraction for temporary tablesA temporary table can be registered in a catalog that does not exist. In the DatabaseCalciteSchema table statistics logic was not accounting for that.,2
[FLINK-23569][docs] Fix typo,2
"KAFKA-7773; Add end to end system test relying on verifiable consumer (#6070)This commit creates an EndToEndTest base class which relies on the verifiable consumer. This will ultimately replace ProduceConsumeValidateTest which depends on the console consumer. The advantage is that the verifiable consumer exposes more information to use for validation. It also allows for a nicer shutdown pattern. Rather than relying on the console consumer idle timeout, which requires a minimum wait time, we can halt consumption after we have reached the last acked offsets. This should be more reliable and faster. The downside is that the verifiable consumer only works with the new consumer, so we cannot yet convert the upgrade tests. This commit converts only the replication tests and a flaky security test to use EndToEndTest.",3
[hotfix] [py] Code cleanup - StreamPrinter- implements Runnable instead of extending Thread- use AtomicRefence<String> instead of StringBuilder- remove redundant wrapInException argument,4
Merging commits 1230840:1239902 from trunkgit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1239937 13f79535-47bb-0310-9956-ffa450edef68,1
fix convertMethodConfig2AsyncInfo spelling error (#4563),0
fix travis cov (#2337),0
"KAFKA-8792; Default ZK configuration to disable AdminServerKafka ships with default ZK configuration. With the upgrade to ZK 3.5, our defaults include running ZK's AdminServer on port 8080. This is an unfortunate default as it tends to cause conflicts.I suggest we default to disable ZK's AdminServer in the default ZK configs that we ship. Users who want to use AdminServer can enable it and set the port to something that works for them. Realistically, in most production environments, a different ZK server will be used anyway. So this is mostly to save new users who are trying Kafka on their own machine from running into accidental and frustrating port conflicts.Author: Gwen Shapira <gwen@confluent.io>Reviewers: Ismael JumaCloses #7203 from gwenshap/zk_disable_adminserver",5
DUBBO-454 支持字节流泛化调用,5
DUBBO-188 fix force:throw失效git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1186 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-11696][checkpoint] Avoid to send mkdir requests to DFS from task side (#7942)Previously, not only checkpoint coordinator but also tasks would always send those mkdir requests out when initialization. This would actually put a lot of pressure to master of distributed file system.This commit avoids to call file system's mkdir when creating CheckpointStorage, but call it only once by the CheckpointCoordinator.",1
"Speed up ""getOptimizedPlan"" by not starting the local embedded runtime.",1
"KAFKA-3043: Replace request.required.acks with acks in docs.In Kafka 0.9, request.required.acks=-1 which configration of producer is replaced by acks=all,but this old config is remained in docs.Author: Sasaki Toru <sasakitoa@nttdata.co.jp>Reviewers: Gwen ShapiraCloses #716 from sasakitoa/acks_doc",2
"KAFKA-12474: Handle failure to write new session keys gracefully (#10396)If a distributed worker fails to write (or read back) a new session key to/from the config topic, it dies. This fix softens the blow a bit by instead restarting the herder tick loop anew and forcing a read to the end of the config topic until the worker is able to successfully read to the end.At this point, if the worker was able to successfully write a new session key in its first attempt, it will have read that key back from the config topic and will not write a new key during the next tick iteration. If it was not able to write that key at all, it will try again to write a new key (if it is still the leader).Verified with new unit tests for both cases (failure to write, failure to read back after write).Author: Chris Egerton <chrise@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
[FLINK-9806][docs] Add canonical linkThis closes #6396.,2
[FLINK-19462][checkpointing] Report aborted checkpoint statsThis change introduces a new RPC from TM to JM.Existing one can't be used because it:a) confirms the checkpointb) requires task state snapshotThe call is issued after cancelling task state-persistingfutures upon receiving abortion notification. This waymore precise metrics are available (compared to reportingfrom AsyncCheckpointRunnable after cancellation).,1
[FLINK-13632] Add Flink 1.11 snapshots for TypeSerializer upgrade testsTheses snapshots were created on the release-1.11 branch by un-@IgnoringTypeSerializerUpgradeTestBase.generateTestSetupFiles() and running testson each subclass individually.,3
[FLINK-15650][python][doc] Improve the udfs documentation of the Python API,2
A tool to GET Zookeeper partition-offset and output to files; patched by John Fung; reviewed by Jun Rao; KAFKA-254git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1291535 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1028 per topic configuration of preference for consistency over availability; reviewed by Neha Narkhede and Jay Kreps,5
use default revision N/A,1
[hotfix][doc] remove obsolete catalog.md in favor of new catalogs.md,2
Fixes multi-registry subscription loadbalance strategy does not work properly. (#5686)* refactor directory to make cluster and invoker load balance work* add weight property in dubbo.xsd* distinguish usage of getUrl and getConsumerUrl* fix directory related UT* fix ut,0
[hotfix][datadog] Remove outdated comments,5
Changed IO manager to allow block writers.,1
[FLINK-13266][table] Port function-related descriptors to flink-table-commonFileSystem/OldCsv/RowtimeValidator/SchemaValidator will be ported in other commits,5
Extract DubboSpringInitializer and support customize initialization (#8495),5
MINOR: Some minor improvements to TxnOffsetCommit handlingAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3040 from hachikuji/txn-offset-commit-cleanups,4
[FLINK-11755] [core] Removed no longer used class TypeDeserializer,1
[hotfix] [tests] Clean up lots of warnings,2
[hotfix] Add methods defined in the gateway to the ResourceManager and TaskExecutor,1
[FLINK-7044] [qs] Allow to specify namespace and descriptor in query.,1
Finished implementation of optimized broadcast in output gate,5
[hotfix][coordination] Fix error message,0
MINOR: disable flaky Streams EOS integration testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #3272 from mjsax/minor-disable-eos-tests,3
fix UT,0
FLINK-1722][datastream] Enable the InitializeOnMaster and FinalizeOnMaster interfaces on datastream,5
[FLINK-1210] Improve error message in delta iterations when the next workset does not depend on the workset,1
[quickstart] fix links to documentation,2
"MINOR: Update release script with new remote, better error handling, correct mvn deploy profileAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <github@juma.me.uk>Closes #4528 from ewencp/update-release-script",5
[hotfix][table] Replace TableConfig constructor with getDefault(),1
[hotfix][docs][s3] Clarify wording of S3 Filesystem supportThis closes #12043,1
"MINOR: Added a couple of unit tests for KStreamPrint node when values are bytesWith current tests, the deserialization inside the KStreamPrint node processor which happens when key and/or values are byte[] isn't tested. This PR fixes that.Author: Paolo Patierno <ppatierno@live.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bbejeck@gmail.com>Closes #3611 from ppatierno/minor-kstream-print-test",3
[hotfix][tests] Fix capital variable names in ExecutionGraphRestartTest,3
"KAFKA-7483: Allow streams to pass headers through Serializer. (#5751)Satish Duggana <sduggana@hortonworks.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-10010] Mark BaseAlignedWindowAssigner as deprecatedAnd also remove SlidingAlignedProcessingTimeWindows,4
Fixed bug. stub.open() was not called for COMBININGSORT local strategy.,5
[FLINK-1110] Implement collection-based execution for bulk iterations,2
Updated year in about dialog,2
[scala] Fix Formatting in Examples and add ITCasesAlso actually use termination criterion in TransitivelClosureNaiveJava example.Add ConnectedComponentsITCase for Scala ExampleAlso fix some formatting in the example codeAdd WebLogAnalysisITCase for Scala ExampleSome minor reformatting of example code and scaladoc.Add ITCases for TriangleEnumeration Scala ExamplesAlso fix some formatting and make TriangleEnumerationOpt Scala produce thesame output as the Java version.Add PageRankITCase for Scala ExampleAlso fix formatting in PageRank Scala Example.Fix formatting in EnumTriangles Scala ExamplesRemove Old/Deprecated Scala Examples and ITCasesFix formatting in EnumTrianglesBasic.scalaFix formatting in LinearRegression Scala ExampleRemove old Scala LineRank Code and RelQuery Example[scala] Fix typo in scaladoc in GroupedDataSet[scala] Fix Scaladoc of Join and CoGroup OperationWas still referring to the type of join/coGroup function that returns anOption.Fix tab vs. spaces in flink-scala and flink-scala-examples,2
[FLINK-11758] Update ContinuousFileProcessingMigrationTest for 1.8,3
"KAFKA-1714: Fix gradle wrapper bootstrapping (#6031)Given we need to follow the Apache rule of not checkingany binaries into the source code, Kafka has always hada bit of a tricky Gradle bootstrap.Using ./gradlew as users expect doesn’t work and alocal and compatible version of Gradle was required togenerate the wrapper first.This patch changes the behavior of the wrapper task toinstead generate a gradlew script that can bootstrap thejar itself. Additionally it adds a license, removes the batscript, and handles retries.The documentation in the readme was also updated.Going forward patches that upgrade gradle should run`gradle wrapper` before checking in the change.With this change users using ./gradlew can be sure theyare always building with the correct version of Gradle.Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk",1
"KAFKA-2275: Add ListTopics() API to the Java consumer; reviewed by Jason Gustafson, Edward Ribeiro and Guozhang Wang",1
[FLINK-12077][table-runtime-blink] Introduce HashJoinOperator and LongHashJoinGenerator to blink runtime (#8093),1
[hotfix][build][python][tests] Remove Scala suffix,0
"[FLINK-15999][doc] Remove ""operator state"" from concepts sectionWe move it to the development section and mention that it is a specialtype of state that is normally not needed in user programs.",1
[hotfix][tests][runtime] Extract utilities for creating InputChannels,1
[hotfix] Improve logging and thread characteristics for 'EmbeddedNonHaServices',2
[hotfix] [tests] Speed up StreamCheckpointNotifierITCase,3
KAFKA-545 Add some log performance tests.git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410088 13f79535-47bb-0310-9956-ffa450edef68,3
[FLINK-23369][connector-kafka] Use enums for optionsThis closes #16482.,1
方法名重构,5
Fixed #85,0
[hotfix][tests] Fix Files.walk resource leak,2
DUBBO-354 API方式指定方法调用为异步git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1642 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-15327][runtime] No warning of InterruptedException during cancel.InterruptedException are previously only handled when wrapped inWrappingRuntimeException. This patch looks through the whole exceptionchain.,1
KAFKA-12257; Consumer mishandles topics deleted and recreated with the same name (#11004)Store topic ID info in consumer metadata. We will always take the topic ID from the latest metadata response and remove any topic IDs from the cache if the metadata response did not return a topic ID for the topic. The benefit of this is that it lets us detect topic recreations. This allows the client to update metadata even if the leader epoch is lower than what was seen previously.Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-19357][fs-connector] Introduce FileLifeCycleListener to BucketsThis closes #13697,2
[FLINK-4773] [metrics] [refactor] Introduce OperatorIOMetricGroup,1
refactor packagegit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1407 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-776 Changing ZK format breaks some tools; reviewed by Neha Narkhede,4
KAFKA-12772: Move all transaction state transition rules into their states (#10667)Co-authored-by: dengziming <dengziming@growingio.com>,4
[hotfix][connector/test] Make MockSplitEnumeratorContext implement AutoClosable and shutdown executors at closing,1
KAFKA-8452: Compressed BufferValue review follow-up (#6940)Belatedly address a few code review comments from #6848Reviewers: Bill Bejeck <bbejeck@gmail.com>,1
[FLINK-7393] [kinesis] Move unit tests of KinesisConfigUtil from FlinkKinesisConsumerTest to KinesisConfigUtilTestThis closes #4708.,5
[FLINK-18289][Checkpoint] Ensure notifyCheckpointAborted interface work in UDF operator,1
"KAFKA-9051: Prematurely complete source offset read requests for stopped tasks (#7532)Prematurely complete source offset read requests for stopped tasks, and added unit tests.Author: Chris Egerton <chrise@confluent.io>Reviewers: Arjun Satish <arjun@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Jinxin Liu <liukrimhim@gmail.com>, Randall Hauch <rhauch@gmail.com>",5
[FLINK-19467][runtime / state backends] Implement HashMapStateBackend and EmbeddedRocksDBStateBackend,5
修改启动脚本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@482 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-9956: Authorizer APIs may be invoked more than once for a given request (#8643)* Fix describeConfigs and alterConfigs not to invoke authorizer morethan once* Add tests to KafkaApisTest to verify the fixes* Rename `filterAuthorized` to `filterByAuthorized`* Tweak `filterByAuthorized` to take resources instead of resourcenames and improve implementation* Introduce `partitionMapByAuthorized` and `partitionSeqByAuthorized`and simplify code by using it* Replace List with Seq in some AdminManager methods* Remove stray `println` in `KafkaApisTest`Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"KAFKA-13207: Skip truncation on fetch response with diverging epoch if partition removed from fetcher (#11221)AbstractFetcherThread#truncateOnFetchResponse is used with IBP 2.7 and above to truncate partitions based on diverging epoch returned in fetch responses. Truncation should only be performed for partitions that are still owned by the fetcher and this check should be done while holding partitionMapLock to ensure that any partitions removed from the fetcher thread are not truncated. Truncation will be performed by any new fetcher that owns the partition when it restarts fetching.Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[FLINK-5497] [tests] Remove duplicated tests for hash tablesThis closes #3089,3
[streaming] JobGraphBuilder refactor,4
"KAFKA-10674: Controller API version bond with forwardable APIs (#9600)Get controller api version intersection setup for client queries. When the unsupported exception was hit in the EnvelopeResponse, close the client connection to let it rediscover the api version.Reviewers: Jason Gustafson <jason@confluent.io>",5
KAFKA-1499; Broker-side compression configuration; reviewed by Joel Koshy,5
[FLINK-25235][runtime] Re-enable ZooKeeper test with multi-component leader election (see FLINK-24038)The TestingMiniCluster had to be adapted a bit to make this work.The new multi-component leader election assumes that there's asingle leader election instance available per JobManager that isclosed as soon as the JobManager is shut down. The TestingMiniClusterused a single leader election that's shared between multipleJobManagers and closed after all these JMs are shutdown.The new implementation creates an individualHighAvailabilityServices instance per JM and closes this instance assoon as the JM shuts down to revoke the leadership and enable otherJMs to pick the leadership up again.,0
"MINOR: code cleanup (#6053)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Guozhang Wang <guozhang@confluent.io>",5
"MINOR: Delete unused DeleteTopicsWithIdsResult (#10957)Reviewers: Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",5
Fix 3.0 use triple can not return real exception (#8458)* Fix use triple can't return real exception in java (#8363)* Fix use triple can't return real exception in java (#8363)- add common exception structure for multi-language* Remove exception serialization and ignore when decode/encode failed* Add exceptionUtils license and remove useless pom config* Remove unused constant* Serialize exception only in wrapper mode* Format code* Ignore google rpc classesCo-authored-by: guohao <guohaoice@gmail.com>,1
[hotfix][kinesis] Eliminate compliler warnings and apply simple inspection-based automated cleanups,4
[FLINK-5293] Make Kafka consumer backwards compatible with 1.1 snapshots,1
[FLINK-11524][tests] Print failure cause if job failed,0
KAFKA-12697: Add Global Topic and Partition count metrics to the Quorum Controller (#10679)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"[FLINK-9575][tests] Simplify DispatcherTest#testBlobsAreRemovedOnlyIfJobIsRemovedProperlyMove DispatcherTest#testBlobsAreRemovedOnlyIfJobIsRemovedProperly into DispatcherResourceCleanupTestand split it up into a success and failure case.Moreover, this commit changes the logic of blob cleanup to also cleanup locally in case of a removalfailure of a job from a SubmittedJobGraphStore.",4
[FLINK-29196][python] Update flink-python NOTICEThis closes #20758.,2
Standardized code (#4211),5
[FLINK-4082] Add Setting for enabling/disabling LargeRecordHandlerBy default this is set to disabled because there are known issues whenusers specify a custom TypeInformation.,5
[FLINK-18500][table] Make the legacy planner exception more clear when resolving computed columns types for schema,1
"[FLINK-5197] [jm] Ignore outdated JobStatusChanged messagesOutdated JobStatusChanged messages no longer trigger a RemoveJob message but arelogged and ignored. This has the advantage, that an outdated JobStatusChanged messagecannot interfere with a recovered job which can have the same job id.",4
[FLINK-22290][checkpointing] Use duration for alignment timeout.,1
"MINOR: Add mock implementation of `BrokerToControllerChannelManager` (#10026)Tests involving `BrokerToControllerChannelManager` are simplified by being able to leverage `MockClient`. This patch introduces a `MockBrokerToControllerChannelManager` implementation which makes that possible.The patch updates `ForwardingManagerTest` to use `MockBrokerToControllerChannelManager`. We also add a couple additional timeout cases, which exposed a minor bug. Previously we were using the wrong `TimeoutException`, which meant that expected timeout errors were in fact translated to `UNKNOWN_SERVER_ERROR`.Reviewers: David Arthur <david.arthur@confluent.io>",5
[FLINK-23034][runtime] Added compatibility for ExecutionState in HistoryServer,1
[FLINK-2536] [streaming] Add a re-connect attempty to socket sinkThis closes #1030,1
#1046 The comments translation of registry-registry module (#1051),1
[docs] Fix broken links in documentation,2
[FLINK-24586][table] SQL functions should return STRING instead of VARCHAR(2000)This closes #17691.,1
[hotfix] Fix checkstyle violation in TestingResourceManagerGateway,3
"[FLINK-10281] [table] Fix string literal escaping throughout Table & SQL APIThis commit fixes the string literal escaping of the Table & SQL API. Properescaping of quotes was not possible in the past for Table API. SQL and SQL Clientwere not standard compliant.Due to FLINK-8301 backslashes were considered in SQL literals, however, theyshould only be used in SQL `U&'\1234'` literals. For the Table API, the newlogic relies on the Java/Scala escaping and uses duplicate quotes for escapingthe quotes in expression strings. For SQL, we rely on unicode string literalswith or without the UESCAPE clause. The SQL Client was using backslashes forescaping new lines. For the SQL Client, we allow unescaped new lines anduse ';' for statement finalization; similar to other SQL clients.This closes #6671.",1
"KAFKA-5816; add Produced class, KStream#to(topic, Produced), and KStream#through(topic, Produced)Add the `Produced` class and `KStream` overloads that use it:`KStream#to(String, Produced)``KStream#through(String, Produced)`Deprecate all other to and through methods accept the single param methods that take a topic paramAuthor: Damian Guy <damian.guy@gmail.com>Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3770 from dguy/kafka-5652-produced",5
[FLINK-4936] [gelly] Operator names for Gelly inputsProvide descriptive operator names for Graph and GraphCsvReader.Condense multiple type conversion maps into a single mapper.Reuse objects in operations wrapping user-defined-functions.This closes #2832,1
[FLINK-18237][fs-connector] Exception when reading filesystem partitioned table with stream modeThis closes #12576,5
"[FLINK-17659] Rework WatermarkStrategy, add Suppliers for TimestampAssigner/WatermarkGeneratorWe add Suppliers for both TimestampAssigner and WatermarkGenerator toallow them to not be Serializable and add API methods for using them inWatermarkStrategies.This makes the WatermarkStrategy the one-stop thing when it comes totimestamps/watermarks. This makes it possible, for example, to easilygenerate code from the Table API.The WatermarkStrategy has a default RecordTimestampAssigner, which meansthat in most cases users don't need to specify a TimestampAssigner butwill use the timestamps provided by the source. Only aWatermarkGenerator is required in most cases.We also will use this for compatibility with the oldassigners/extractors in the KafkaConsumer. In the old model, bothtimestamp assigner and watermark extractor where in one and the sameobject and extracting a timestamp updates the state of the assigner. TheKafkaConsumer will de-serialize a new extractor for each partition,meaning we have to keep the new-model assigner and wm generator in oneand the same object. (The wrapping WatermarkStrategy for the oldassigners returns the same object for both TimestampAssigner andWatermarkGenerator)",4
修改PojoUtils空指针git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@624 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][scala-shell] fix location of classes according to package nameJavadoc was throwing an error because it expected the class files to beorganized in hierarchical directories.,2
[FLINK-7005] [table] Optimization steps are missing for nested registered tablesThis closes #4186.,2
[FLINK-23599] Remove JobVertex#connectIdInput and its related unit testsThis closes #16686.,3
Update OverrideServiceImpl.javafix the bug: cant enable override,0
"KAFKA-13968: Fix 3 major bugs of KRaft snapshot generating (#12265)There are 3 bugs when a broker generates a snapshot.1. Broker should not generate snapshots until it starts publishing.    Before a broker starts publishing, BrokerMetadataListener._publisher=None, so _publisher.foreach(publish) will do nothing, so featuresDelta.metadataVersionChange().isPresent is always true, so we will generating a snapshot on every commit since we believe metadata version has changed, here are the logs, note offset 1 is a LeaderChangeMessage so there is no snapshot:[2022-06-08 13:07:43,010] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 0... (kafka.server.metadata.BrokerMetadataSnapshotter:66)[2022-06-08 13:07:43,222] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 2... (kafka.server.metadata.BrokerMetadataSnapshotter:66)[2022-06-08 13:07:43,727] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 3... (kafka.server.metadata.BrokerMetadataSnapshotter:66)[2022-06-08 13:07:44,228] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 4... (kafka.server.metadata.BrokerMetadataSnapshotter:66)2. We should compute metadataVersionChanged before _publisher.foreach(publish)    After _publisher.foreach(publish) the BrokerMetadataListener_delta is always Empty, so metadataVersionChanged is always false, this means we will never trigger snapshot generating even metadata version has changed.3. We should try to generate a snapshot when starting publishing    When we started publishing, there may be a metadata version change, so we should try to generate a snapshot before first publishing.Reviewers: Jason Gustafson <jason@confluent.io>, Divij Vaidya <diviv@amazon.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",1
"[FLINK-22566][test] Adds log extraction for the worker nodesWe struggled to get the logs of the node manager which made it hard toinvestigate FLINK-22566 where there was a lag between setting up the YARNcontainers and starting the TaskExecutor. Hopefully, the nodemanager logslocated on the worker nodes will help next time to investigate something likethat.",1
[streaming] Critical bugfix for streaming keyselectors,0
[FLINK-12709][runtime] Implement RestartBackoffTimeStrategyFactoryLoader which also respects legacy restart strategy configsThis closes #8912.,5
Added test for property propagation through UnionNode,5
"DUBBO-242 配置解析支持""-""分隔的属性，自动转为驼峰命名的settergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1158 1a56cb94-b969-4eaa-88fa-be21384802f2",1
"KAFKA-8102: Add an interval-based Trogdor transaction generator (#6444)This patch adds a TimeIntervalTransactionsGenerator class which enables the Trogdor ProduceBench worker to commit transactions based on a configurable millisecond time interval.Also, we now handle 409 create task responses in the coordinator command-line client by printing a more informative messageReviewers: Colin P. McCabe <cmccabe@apache.org>",5
[hotfix] Make SlotPoolBuilder a top level class,1
[FLINK-21139][runtime] Fix unstable ThresholdMeterTestThis closes 14823,3
kafka-937; fix bug exposed in ConsumerOffsetChecker; patched by Jun Rao; reviewed by Alexey Ozeritskiy,1
Fix inefficient use of keySet iterator instead of entrySet iterator (#3508)Fix inefficient use of keySet iterator instead of entrySet iterator,1
[FLINK-4460] Add side outputs for ProcessFunction,1
Change parent pom back to oss in this version,4
[hotfix][python] Fix typo of lint-python (#19769),2
[FLINK-3679] [kafka] Allow Kafka consumer to skip corrupted messages,1
"[FLINK-15250][docs] Update ""Connect to External Systems"" page to list the required formats in connectors definition sectionThis closes #10585",5
Added cardinality annotations to clustering operators.,1
"[Dubbo-3764]Merge dubbo rpc xmlrpc (#3764) (#3775)* Create constants for 'hash.names' and 'hash.arguments' (#3744)* Merge dubbo-rpc-xmlrpc (#3764)* Removing .gitignore* Rename package name* Add Apache License* Rename groupID name and url* Update dubbo-rpc-xmlrpc version and add as a dependency in dubbo-all* Replace package for ""org.apache.dubbo.xml"" and rename ""com.alibaba.*"" to ""org.apache.dubbo""* Fix the name of artifactID* Remove unused files and add dubbo-rpc-xml as a module in dubbo-rpc* Remove authors and delete files that are duplicate in the main repo have one* Fix the name of package and remove unnecessary space* Remove unnecessary space* Remove authors* Fix imports and remove authors from pom* Update groupID and the name of package* Remove unused tags* Add dubbo-rpc-xml as a dependency on dubbo-bom* Fix package names* Call JettyHttpBinder from remoting module to avoid duplicated files* Fix unit tests and upgrade to JUnit 5* Call JettyHttpBinder from remoting module to avoid duplicated files* Add external dependencies on dubbo-dependencies-bom",1
[FLINK-5209] [webfrontend] Fix TaskManager metricsFixes a capitalization incompatibility when providing memory metrics tothe webfrontend. Numeric metrics now returned as numbers in the JSONAPI. Non-byte numbers now localized in the webfrontend.This closes #2902,5
fix comments,0
[FLINK-7379] [qs] Remove HighAvailabilityServices from QS client constructor.,4
[FLINK-2656] Fix behavior of FlinkKafkaConsumer for out of range offsetsThis closes #1117,1
[FLINK-14803][metrics][influx] Support consistency level,1
[FLINK-23005][coordination] Cache compressed serialized value of ShuffleDescriptorsThis closes #16314.,2
[FLINK-11688][checkstyle] Enforce whitespace around TYPE_EXTENSION_AND,1
Added JDBC Input Formant and tests.,3
MINOR: Update docs to point to next release add notable features for 2.7 (#9483)Reviewers: Matthias J. Sax <mjsax@apache.org>,1
[hotfix] [table] Include commons-lang3 in flink-table artifact JAR.,2
[FLINK-2785] [gelly] implement fromCsvReader for gelly-scala; add tests and docsThis closes #1205,2
[FLINK-15834] Set up nightly builds in Azure,1
[FLINK-13088][table-api] Support lazy query transformation & execution on TableEnvironment,1
[FLINK-1338] [docs] Remove incubator footer from docs,2
[3.0] Fix concurrent modification in Invocation attribute (#9805)* [3.0] Fix concurrent modification in Invocation attribute* convert to Collections.synchronizedMap(new HashMap<>()),1
[FLINK-5631] [yarn] Support downloading additional jars from non-HDFS paths.This closes #3202,1
"[FLINK-2819] Add Windowed Join/CoGroup Operator Based on Tagged UnionRight now, this does everything in memory, so the JVM will blow if datafor one key becomes too large.",5
"MINOR: Update documentation and DumpLogSegments tool for addition of `deleteHorizonMs` in batch format (#11694)This PR updates the documentation and tooling to match https://github.com/apache/kafka/pull/10914, which added support for encoding `deleteHorizonMs` in the record batch schema. The changes include adding the new attribute and updating field names. We have also updated stale references to the old `FirstTimestamp` field in the code and comments. Finally, In the `DumpLogSegments` tool, when record batch information is printed, it will also include the value of `deleteHorizonMs` is (e.g. `OptionalLong.empty` or `OptionalLong[123456]`).Reviewers: Vincent Jiang <84371940+vincent81jiang@users.noreply.github.com>, Kvicii <42023367+Kvicii@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
Fixed minor bug in task manager logging,2
Close all ports after tests finish (#2906),5
Merge branch '3.0.1-release' into apache-3.0# Conflicts:#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/reference/javaconfig/JavaConfigReferenceBeanTest.java#dubbo-config/dubbo-config-spring/src/test/java/org/apache/dubbo/config/spring/schema/GenericServiceTest.java#dubbo-config/dubbo-config-spring/src/test/resources/META-INF/spring/dubbo-generic-consumer.xml,5
[FLINK-12388][docs] Update the production readiness checklistThis closes #8330,5
[FLINK-23868][Client] JobExecutionResult printed event if suppressSysout is enabledThis closes #16891 .,0
"Merge pull request #2049, upgrade netty4 to the latest release and make it the default option for transporter.",1
[FLINK-7645] [docs][metrics] Add system-metrics subsections to ToCThis closes #4693.,5
Fix bug in topological sort,2
"KAFKA-3162: Added producer and consumer interceptorsThis is the most of the KIP-42: Producer and consumer interceptor. (Except exposing CRC and record sizes to the interceptor, which is coming as a separate PR; tracked by KAFKA-3196).This PR includes:1. Add ProducerInterceptor interface and call its callbacks from appropriate places in Kafka Producer.2. Add ConsumerInterceptor interface and call its callbacks from appropriate places in Kafka Consumer.3. Add unit tests for interceptor changes4. Add integration test for both mutable consumer and producer interceptors.Author: Anna Povzner <anna@confluent.io>Reviewers: Jason Gustavson, Ismael Juma, Gwen ShapiraCloses #854 from apovzner/kip42",5
New config format,5
Added hooks for plugins in the job manager,1
[FLINK-17495][metrics] Add support for configuring additional variables,1
[FLINK-16587][checkpointing] Provide the method for getting unconsumed buffer from RecordDeserializer.,1
Modified to lower camel case (#2945),5
[FLINK-14104][build] Pin jackson version to 2.10.1,2
[FLINK-13029][table-planner] Ported GROUP BY expression to new type system,5
[FLINK-22288][connectors / jdbc] Remove unnecessary argument in JdbcSink,5
"HOTFIX: timeout issue in removeStreamThread() (#10321)Timeout is a duration not a point in time.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
Added two more integration tests for the fault tolerance features,3
Introduced group state to reduce computational complexity on execution state changes,4
[FLINK-26071][table] Add various improvements to plan compilation- Now Planner#compilePlan fails if the plan cannot be serialized.- Add CompiledPlan#explain and toString implementation.- Invoking Planner#loadPlan will fail on Batch planner.This closes #18701.,0
"KAFKA-12593: Fix Apache License headers (#10452)* Standardize license headers in scala, python, and gradle files.* Relocate copyright attribution to the NOTICE.* Add a license header check to `spotless` for scala files.Reviewers: Ewen Cheslack-Postava <ewencp@apache.org>, Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org",2
[FLINK-15758][MemManager] Remove MemoryManager#AllocationRequest,4
Use empty protocol for nacos registry when address list is empty. (#4349)fixes #4294.,0
[hotfix] Resolve compiler warnings in AkkaRpcService,2
MINOR: JavaDoc markup cleanupAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2462 from mjsax/javaDocImprovements9,2
Added event subscription / publication methods to mutable reader interface and implementations.,1
KAFKA-8106: Skipping ByteBuffer allocation of key / value / headers in logValidator (#6785)* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.* github comments* use batch.skipKeyValueIterator* cleanups* no need to skip kv for uncompressed iterator* checkstyle fixes* fix findbugs* adding unit tests* reuse decompression buffer; and using streaming iterator* checkstyle* add unit tests* remove reusing buffer supplier* fix unit tests* add unit tests* use streaming iterator* minor refactoring* rename* github comments* github comments* reuse buffer at DefaultRecord caller* some further optimization* major refactoring* further refactoring* update comment* github comments* minor fix* add jmh benchmarks* update jmh* github comments* minor fix* github comments,0
- Smaller modifications to the PACT examples,5
[FLINK-7058] Fix scala-2.10 dependenciesThis closes #4240.,0
"MINOR: Update to Gradle 6.8.1 (#9953)A number of regressions were fixed (see ""Fixed issues"" section):https://docs.gradle.org/6.8.1/release-notes.htmlReviewers: Chia-Ping Tsai <chia7712@gmail.com>",2
[FLINK-16210] Extend the Flink Architecture section with more information about Flink Master components and application execution,2
"[FLINK-3948] Protect RocksDB cleanup by cleanup lockBefore, it could happen that an asynchronous checkpoint was going onwhen trying to do cleanup. Now we protect cleanup and asynchronouscheckpointing by a lock.",4
[FLINK-18731][table-planner-blink] Fix monotonicity logic of UUID functionThis closes #12998,1
Replace ServiceLoader with Dubbo ExtensionLoader,5
"KAFKA-10601; Add support for append linger to Raft implementation (#9418)The patch adds `quorum.append.linger.ms` behavior to the raft implementation. This gives users a powerful knob to tune the impact of fsync.  When an append is accepted from the state machine, it is held in an accumulator (similar to the producer) until the configured linger time is exceeded. This allows the implementation to amortize fsync overhead at the expense of some write latency.The patch also improves our methodology for testing performance. Up to now, we have relied on the producer performance test, but it is difficult to simulate expected controller loads because producer performance is limited by other factors such as the number of producer clients and head-of-line blocking. Instead, this patch adds a workload generator which runs on the leader after election.Finally, this patch brings us nearer to the write semantics expected by the KIP-500 controller. It makes the following changes:- Introduce `RecordSerde<T>` interface which abstracts the underlying log implementation from `RaftClient`. The generic type is carried over to `RaftClient<T>` and is exposed through the read/write APIs.- `RaftClient.append` is changed to `RaftClient.scheduleAppend` and returns the last offset of the expected log append.- `RaftClient.scheduleAppend` accepts a list of records and ensures that the full set are included in a single batch.- Introduce `RaftClient.Listener` with a single `handleCommit` API which will eventually replace `RaftClient.read` in order to surface committed data to the controller state machine. Currently `handleCommit` is only used for records appended by the leader.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",1
[FLINK-10411] Rename ClusterComponent into DispatcherResourceManagerComponent,2
[FLINK-5720] Deprecate DataStream#fold()This closes #3816.,5
[FLINK-3220] Remove javax.servlet exclusions from hadoop2 fat jar to fix Flink on HDP,2
"MINOR: Re-use counter in mocking of LogSegment.size (#12021)When migrating from Easymock to Mockito, the mockito implemetnationdidn't have the same semantic as the Easymock implementation.Without this fix the mocking of LogSegment.size() always returns 0 becausea new AtomicInteger was getting created for each invocation ofLogSegment.size()Reviewers: Mickael Maison <mimaison@users.noreply.github.com>",1
"[FLINK-19022] Fail DispatcherResourceManagerComponent fatally if ResourceManager terminates unexpectedlyAn unexpected termination of the ResourceManager indicates an invalid state. Hence, theDispatcherResourceManagerComponent should react to it by calling the FatalErrorHandler.",0
Enabled checkpoints by default,0
Remove unused code.,1
[FLINK-11518] [table] Add partition related catalog APIs and implement them in GenericInMemoryCatalogThis closes #8222,2
"[FLINK-10585][tests] Explicitly bind testing RestServerEndpoint on loopback addressIf we do not bind on a loopback address, the wildcard address will be chosen.The downside of that is it can happen that the server will be only available viaeither IPv4 or IPv6 (but not both). This can happen, for example, if anotherapplication chose to bind on the same (random) port but only using the IPv4stack. In this case, the bind operation in the RestServerEndpoint will onlysucceed for IPv6 and silently fail for IPv4.",0
[FLINK-16316][operators] Move inner CountingClass class out from AbstractStreamOperator,1
"Merge pull request #1820, improve graceful shutdown.",1
"KAFKA-10004: ConfigCommand fails to find default broker configs without ZK (#8675)Reviewers: Brian Byrne <bbyrne@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",5
[FLINK-13440] Report reason when failing job due to checkpoint failure.,0
[FLINK-10765][test] Include s3p schema in S3 testThis closes #7032.,3
[FLINK-26421][python] Add warnings to deprecated methods in EnvironmentSettings,1
MINOR: update doc for default assignor change (#11009)Update the doc and upgrade doc for default assignor change. REF: #10903Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>,4
more refactoring...,4
[FLINK-23512][checkpoint] Store whether a subtask is finished in the checkpoint,5
"multiple registries, services only register to default registry. (#4420)fixes #4412",0
Partition.makeFollower() reads broker info from ZK; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-575git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403598 13f79535-47bb-0310-9956-ffa450edef68,5
fix UT,0
"[FLINK-18546] Upgrade to Kafka Schema Registry Client 5.5.2The commit changes the packaging of flink-avro-confluent-registry module. We do no longer ship a fat-jar. Instead users should build the fat-jar themselves. It is because the upgraded version of registry client accesses fields from Avro of Jackson types. Because of the fact we can either bundle and shade both Avro and Jackson, or not shade Jackson. I decided it will be best not to ship a fat-jar and leave that decision to users.On the other hand for the sql-client it is better to provide fat-jars, however because of 1. I added a separate flink-sql-avro-confluent-registry module that builds a fat-jar (including Avro, and shaded jackson).",5
optimize some code of URLItemCache (#9835)Co-authored-by: 呈铭 <beck.wcm@antgroup.com>,5
Embedded consumer doesn't shut down if the server can't start; patched by Jun Rao; reviewed by Neha Narkhede and Jay Kreps; KAFKA-197git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1213546 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-6094] [table] Implement stream-stream proctime non-window inner joinThis closes #4471.,2
"[FLINK-25026] UnalignedCheckpointRescaleITCase.shouldRescaleUnalignedCheckpoint fails on AZPTests that extend from UnalignedCheckpointTestBase create a lot ofMiniClusters. E.g. the rescale it case creates 72 tests * 2 clusters(pre & post rescale). Direct buffers allocated by netty are freed duringthe GC.At the same time Flink uses PooledBufferAllocator, where we return usedbuffers earlier and we do not need to wait for GC to kick in. The ideato make the test more stable is to reuse a single NettyBufferPool forall clusters that are started in those tests. That way we can reusebuffers that were previously allocated and we do not need to wait untilthey are freed.Lastly as a note. This should not be an issue in production setups, aswe do not start multiple shuffle environments in a single JVM process(TM).",1
[FLINK-11884][table] CatalogTableOperation construction &transformation to RelNodes,2
[FLINK-24500][table] Move SqlDateTimeUtils to table-common as DateTimeUtilsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>This closes #17454.,2
[hotfix][runtime] Fix typo in static factory method,2
Changed signature of computeSplits method,4
add service notification log,2
Fixed CachingList#clear,0
[FLINK-6904] [cep] Support for quantifier range to CEP's pattern APIThis closes #4121,1
"performance tuning, fix cache registry url creation bug (#6914)",0
Merged #928 manually: fix curator null path bug,0
[FLINK-20885][canal-json] Fix deserialization exception when using 'canal-json.table.include' to filter binlogs of multiple tablesThis closes #14631,2
"MINOR: Add a duplicate() method to Message classes (#8556)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",5
KAFKA-3666; Update links for new consumer APIPull request to update the consumer API links in the docs.Author: Dustin Cote <dustin@dustins-mbp.attlocal.net>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1331 from cotedm/KAFKA-3666,2
[FLINK-21390] Rename DeclarativeScheduler to AdaptiveSchedulerNote that this commit also changes the system property to enable the adaptive schedulerfrom flink.tests.enable-declarative-scheduler to flink.tests.enable-adaptive-scheduler.This closes #14970.,3
Added TriangleEnumeration examples for reworked Scala API.,1
修改状态信息git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@808 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Fix javadoc for `PartitionInfo.leader()`Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Guozhang WangCloses #789 from ijuma/fix-partition-info-leader-doc,5
DUBBO-343 还原提供方订阅override信息git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1695 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][docs] reintroduce build_docs.sh scriptThis closes #15008,2
[fix] Rename method in BroadcastStream,0
"KAFKA-3310; Fix for NPEs observed when throttling clients.The fix basically ensures that the throttleTimeSensor is non-null before handing off to record the metric value. We also record the throttle time to 0 so that we don't recreate the sensor always.Author: Aditya Auradkar <aauradkar@linkedin.com>Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>Closes #989 from auradkar/KAFKA-3310",2
"[FLINK-10411] Introduce DispatcherResourceManagerComponentFactoryThis commit introduces the DispatcherResourceManagerComponentFactory which is usedto create a DispatcherResourceManagerComponent. That way, it is possible to eagerlyinitialize all fields of the DispatcherResourceManagerComponent making it possibleto make all fields final and remove the lock.This closes #6743.",4
"[FLINK-9603] Fix part counter loop in BucketingSink to account for part suffix.1. all logic, that is responsible for path assembly moved into method;2. test logic of part file indexing, when in-progress/ pending/ final   part files already exists in bucket;3. test the same logic, when part file has suffixThis closes #6176.",0
[FLINK-2761] [scala-shell] Prevent creation of new environment in Scala ShellThis closes #1180,1
[hotfix] Add a wildcard type in heap state backend related classes,1
[FLINK-4943] Fix typo ConfigConstants JavaDocs: YYARN -> YARNThis closes #2704.,2
[FLINK-28000][runtime][security] Throw exception when principal is set in the configuration without keytab,5
[FLINK-10512][rest][docs] Remove legacy docs,2
[FLINK-22471][table-runtime-blink] Remove repetition of default values,4
[hotfix][connectors] Every connector now shades the flink-connector-base in its uber jarSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[FLINK-5467] Avoid legacy state for CheckpointedRestoring operatorsThis closes #3102.,1
[FLINK-8146][py] Properly close ZipInputStreamThis closes #5349.,2
KAFKA-7030; Add configuration to disable message down-conversion (KIP-283) (#5192)Add support for the topic-level `message.downconversion.enable` config as part of KIP-283.,5
"Merge pull request #834, ignore system file",2
MINOR: the broker should use metadata.log.max.record.bytes.between.snapshots (#10990)The broker should trigger a snapshot oncemetadata.log.max.record.bytes.between.snapshots has been exceeded.Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-13338][table] Make SQL dialect configurableThis closes #9212.,5
"KAFKA-3692; Add quotes to variables in kafka-run-class.shAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1364 from Ishiihara/add-quote-classpath",1
"[hotfix] Rename SchedulerNG.getTerminationFuture into getJobTerminationFutureThis is a preparational step to better distinguish the job termination future fromthe Scheduler termination future. Moreover, the return type was changed toCompletableFuture<JobStatus> to be more expressive.",4
[FLINK-17506][state-processor-api] Use proper RocksDB configurations in KeyedStateInputFormat,5
[FLINK-12679][sql-client] Support 'default-database' config for catalog entries in SQL CLI yaml file,2
DUBBO-234 监控中心负责清理redis脏数据git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1243 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][tests] Add file sshd-run.The file that was previously missing is needed to build the docker images usedfor running the Jepsen tests locally.,3
[FLINK-2528] [tests] Increase robustness and error reporting of MatchTaskTest,3
"KAFKA-9058: Lift queriable and materialized restrictions on FK Join (#7541)Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
- Allow dependencies to retain guava- Clean dependencies in flink-streaming connectors,2
"[Dubbo-1687]Add unit tests for dubbo-filter-validation module (#1736)* Add unit tests for dubbo-filter-validation module* add more jaxb api libs for testing with jdk9, because it does't contain them by default any more",1
[FLINK-25807][rest][docs] Deduplicate fields that only differ by naming convention,2
KAFKA-4483; Fix NPE in `Log` constructor if log level is INFO or finerAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2207 from ijuma/kafka-4483-npe-in-log-constructor,2
"KAFKA-4923: Modify compatibility test for Exaclty-Once Semantics in Streams - add broker compatibility system testsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2974 from mjsax/kafka-4923-add-eos-to-streams-add-broker-check-and-system-test",5
KAFKA-6052; Fix WriteTxnMarkers request retry issue in InterBrokerSendThread (#4705)This resolves the issue found when running the brokers on Windows which prevents the coordinator from sending WriteTxnMarkers requests to complete a transaction.,1
"[FLINK-8324] [kafka, metrics] Add new offsets metrics that can be scoped by topic and partition",1
[minor] Simplify PlanExecutor.execute() signature,5
增加toUrl()方法，方便测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1635 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-21231][sql-client] Support ""SHOW VIEWS"" in SQL clientThis closes #14840",1
[FLINK-24859][doc][formats] Make new formats name coherent,1
[FLINK-17602][docs] Corrected method name in dev/stream/broadcast_state document,2
Fixed javadoc,2
[FLINK-14101][jdbc-connector] Support SQLServer dialect in the jdbc connector.This closes #20235.,5
[FLINK-7739] [kafka connector] Fix test instabilities  - Set shorter heartbeats intervals. Default pause value of 60seconds is    too large (tests would timeout before akka react)  - Exclude netty dependency from zookeeper. Zookeeper was pulling in    conflicting Netty version. Conflict was extremly subtle - TaskManager in    Kafka tests was deadlocking in some rare corner cases.This closes #4775,3
[FLINK-27162][runtime] Trigger non-periodic checkpoint in 'timer' threadThis closes #19864.,2
[hotfix] [table] Update documentation about limitations,2
KAFKA-5462: Add configuration to build custom SSL principal name (KIP-371)Author: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>Closes #5684 from omkreddy/KAFKA-5462-SSL-Name,5
[FLINK-11716] Add new config option for TaskManager automatic address binding[FLINK-11716] Add unit test to new config option[FLINK-11716] TaskManager: introduce new (default) automatic ip address bindingThis closes #7795.,1
[FLINK-13376][datastream] ContinuousFileReaderOperator should respect semantics of BoundedOneInput,2
KAFKA-8442; Include ISR in Metadata response even if there is no leader (#6836)Currently the Metadata response returns an empty ISR if there is no active leader. The behavior is inconsistent since other fields such as the replica list and offline replicas are included. This patch changes the behavior to return the current known ISR. This fixes a problem with the topic describe command which fails to report ISR when a leader is offline.Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-16177][checkpointing] Integrate OperatorCoordinator fully with checkpointing.  - This adds verious tests for OperatorCoordinator checkpointing  - The checkpoint coordinator also restores state to the OperatorCoordinator,1
"KAFKA-3250: release tarball is unnecessarily large due to duplicate l……ibrariesThis ensures duplicates are not copied in the distribution without rewriting all of the tar'ing logic. A larger improvement could be made to the packaging code, but that should be tracked by another jira.Author: Grant Henke <granthenke@gmail.com>Reviewers: Gwen Shapira, Ismael JumaCloses #1075 from granthenke/libs-duplicates",1
[FLINK-1433] Add HADOOP_CLASSPATH to start scriptsThis closes #337,1
[FLINK-20307][doc] Strength the document about temporal table join syntax,2
"2.7.6 REST Metadata (#5738)* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring* Polish /apache/dubbo#4674 & /apache/dubbo#4470* Polish /apache/dubbo#5093 : Revert the previous commit* Polish apache/dubbo#5093 : [Feature] Dubbo Services generate the metadata of REST services* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5306 : [Migration] Upgrade the @since tags in Javadoc migration cloud native to master* Polish apache/dubbo#5309 : [ISSURE] The beans of Dubbo's Config can't be found on the ReferenceBean's initialization* Polish apache/dubbo#5312 : Resolve the demos' issues of zookeeper and nacos* Polish apache/dubbo#5313 : [Migration] migrate the code in common module from cloud-native branch to master* Polish apache/dubbo#5316 : [Refactor] Replace @EnableDubboConfigBinding Using spring-context-support* Polish apache/dubbo#5317 : [Refactor] Refactor ReferenceAnnotationBeanPostProcessor using Alibaba spring-context-suuport API* Polish apache/dubbo#5321 : Remove BeanFactoryUtils* Polish apache/dubbo#5321 : Remove AnnotatedBeanDefinitionRegistryUtils* Polish apache/dubbo#5321 : Remove AnnotationUtils* Polish apache/dubbo#5321 : Remove ClassUtils* Polish apache/dubbo#5321 : Remove BeanRegistrar* Polish apache/dubbo#5321 : Remove ObjectUtils* Polish apache/dubbo#5321 : Remove PropertySourcesUtils* Polish apache/dubbo#5325 : [Migration] To migrate dubbo-metadata-api from cloud-native branch* Polish apache/dubbo#5326 : [Migration] To migrate dubbo-metadata-processor from cloud-native branch* Polish apache/dubbo#5329 : [Feature] To add the default metadata into ServiceInstance* Polish apache/dubbo#5339 : [Refactor] Refactor the DynamicConfiguration interface* Polish bugfix* Fixes test cases* Merge remote-tracking branch 'upstream/master' into cloud-native-2.7.5# Conflicts:#dubbo-configcenter/dubbo-configcenter-zookeeper/src/test/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfigurationTest.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/DynamicConfigurationServiceNameMappingTest.java* Merge remote-tracking branch 'upstream/master' into cloud-native-2.7.5# Conflicts:#dubbo-configcenter/dubbo-configcenter-zookeeper/src/test/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfigurationTest.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/DynamicConfigurationServiceNameMappingTest.java* Polish /apache/dubbo#5721 : [Enhancement] Setting the default IDs for Dubbo's Config Beans* Polish /apache/dubbo#5729 : [Optimization] To remove EnableDubboConfigBinding and EnableDubboConfigBindings* Polish /apache/dubbo#5594 : [Feature] Add the resolver of ServiceRestMetadata based on Java Reflection* Polish /apache/dubbo#5736 : [Feature] Introducing Conversion features* Polish /apache/dubbo#5737 : [Feature] Introducing ""dubbo-metadata-processor"" module* Polish /apache/dubbo#5594 : Change the Metadata implementation* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases* Polish /apache/dubbo#5594 : Fixed test cases",3
Add semantic properties to spargel plan.,1
kafka-1698; Validator.ensureValid() only validates default config value; patched by Ewen Cheslack-Postava; reviewed by Jun Rao,5
"[FLINK-14314][runtime] Remove SharedSlotOversubscribedException handlingNow that a physical slot resources should always fulfill all possible children slots allocated in it.Therefore, slot oversubscribing only happens when there is a bug.Hence, there is no need to do partial releasing on oversubscribing or do retrying allocation for unfulfilled children slots.A simple sanity check is kept though.",1
[FLINK-4161] [build] Add Quickstart exclusion for flink-dist dependenciesThis closes #2309,2
[FLINK-8919] [table] Add KeyedProcessFunctionWithCleanupState.This closes #5680.,4
[hotfix][runtime] Rename XXXSubPartitionBufferBuilderXXX to XXXUnicastBufferBuilderXXX,0
[hotfix][rpc] Add proper error reporting to AkkaRpcActor#handleControlMessage,0
"KAFKA-10588; Rename kafka-console-consumer CLI command line arguments for KIP-629 (#11008)This patch marks --whitelist as deprecated argument and introduce --include for kafka-console-consumer as described in KIP-629: https://cwiki.apache.org/confluence/display/KAFKA/KIP-629%3A+Use+racially+neutral+terms+in+our+codebase.Reviewers: Xavier Léauté <xavier@confluent.io>, David Jacot <djacot@confluent.io>",5
[FLINK-4526][yarn] remove redundant proxy messagesThis closes #2437,4
Registry cannot work under k8s API server using SSL (#8039),1
[FLINK-16182][table-api] Remove check against null types as a result of an input type inference when deriving output type based on surrounding info.,5
[FLINK-14310][runtime] Get ExecutionVertexID from ExecutionVertex rather than creating new instances,1
DUBBO-112 在decodeResponse的时候，把相关联的request从future中取出传进来，通过request拿到returnType。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@504 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-16874] Respect the dynamic options when calculating memory options in taskmanager.shThis closes #11577.,2
[FLINK-6903] [runtime] Activate checkstyle for runtime/akkaThis closes #4114,1
"[FLINK-14230][datastream] Remove the BoundedOneInput implementation of AsyncWaitOperator and ContinuousFileReaderOperatorAfter ""endInput"" of the downstream operator on the chain is invoked correctly, we revertthe changes of PR#9298 and PR#9221.",4
Redesign Scheduler part 2,5
[FLINK-11048] Ability to programmatically execute streaming pipeline with savepoint restoreThis closes #7249.,2
[FLINK-2189] [runtime] Fix various issues in hash table  - check for memory availability before probing  - correctly compute memory required for recursive build fast path  - remove all temp files properly,2
branch switch,5
"KAFKA-2680; Use IBM ConfigFile class to load jaas config if IBM JDKUse IBM ConfigFile class with IBM JDK since JavaLoginConfig provided by SUN provider is not included with IBM JDK.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Flavio Junqueira <fpj@apache.org>, Jun Rao <junrao@gmail.com>Closes #357 from rajinisivaram/KAFKA-2680",5
Rename MetadataReportFactory SPI config files,2
"[FLINK-19981][core][table] Add name-based field mode for RowThis adds a name-based field mode to the Row class. A row canoperate in 3 different modes: name-based, position-based, ora hybrid of both when leaving the Flink runtime. It simplifiesthe handling of large rows (possibly with hundreds of fields)and will make it easier to switch between DataStream API andTable API.See the documentation of the Row class for more information.This closes #14420.",5
"Fix race condition leading to erroneous ""NoResourceAvailableException"".",0
MINOR: Fix documentation for updateCurrentReassignment (#7611)The function KafkaController.updateCurrentReassignment doesn't return any value. Fix the documentation to reflect that.,2
[FLINK-22545][hotfix][coordination] Extend logging (temporarily) to debug test instability,3
[FLINK-12460][docs] Replace taskmanager.tmp.dirs with io.tmp.dirs in documentation,2
Increased coverage of sopremo.common.base,3
[FLINK-15179] Make Kubernetes Session CLI use the ExecutorCLI,1
[FLINK-19605][table-runtime-blink] Implement cumulative windowing for window aggregate operatorThis closes #13650,1
"MINOR: improve error message for Serde type miss match (#6801)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>",5
[FLINK-10704][end-to-end] Fix sql client end to end test failure,0
"MINOR: Rename `AlterIsrManager` to `AlterPartitionManager` (#12089)Since we have changed the `AlterIsr` API to `AlterPartition`, it makes sense to rename `AlterIsrManager` as well and some of the associated classes.Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",5
"MINOR: Remove unsupported rsync and ssh commands from release.py (#11309)ssh and rsync access has been removed from home.apache.org.Removing the commands from release.py and replacing them with a note to make sure they are manually uploaded with an sftp client instead.Reviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
[hotfix] Treat taskManager's rpc address and location separately,1
KAFKA-775 Very long error message on the producer during produce requests failures; skipped review since patch is minor log4j change,4
Baiji 269  team 9 add unit test (#2261)* issues #2177* issues #217 modifed,0
"KAFKA-2929: Migrate duplicate error mapping functionalityDeprecates ErrorMapping.scala in core in favor or Errors.java in common.Duplicated exceptions in core are deprecated as well, to ensure the mapping is correct.Author: Grant Henke <granthenke@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #616 from granthenke/error-mapping",0
DUBBO-485 owner配置允许填写多个负责人,5
[hotfix][tests] Add NoOpJobFailCall singleton,0
"KAFKA-9113: Extract clients from tasks to record collectors (#7833)This is part1 of a series of PRs for task management cleanup:1. Primarily cleanup MockRecordCollectors: remove unnecessary anonymous inheritance but just consolidate on the NoOpRecordCollector -> renamed to MockRecordCollector. Most relevant changes are unit tests that would be relying on this MockRecordCollector.2. Let StandbyContextImpl#recordCollector() to return null instead of returning a no-op collector, since in standby tasks we should ALWAYS bypass the logging logic and only use the inner store for restoreBatch. Returning null helps us to realize this assertion failed as NPE as early as possible whereas a no-op collector just hides the bug.Reviewers: Guozhang Wang <wangguoz@gmail.com>",0
[FLINK-17616][tests] Temporarily increase akka.ask.timeout in TPC-DS e2e testThis closes #12082.,3
use the latest version as the default dependency.,3
KAFKA-139 cross-compile multiple Scala versions and upgrade to SBT 0.12.1 patch by Derek Chen-Becker reviewed by Joe Stein,5
[FLINK-24189] Perform buffer debloating per single gateThis commit moves calculating throughput as well debloating buffers tothe gate level. It should help with situations when there is asignificant difference in gates throughput.,4
[refactor] Rename StreamConfig.setTypeSerializersIn() to setupNetworkInputs()Because that's what it does.,1
"[FLINK-7728] [DataStream] Flush max watermark across all inputs once all become idlePrior to this commit, once all inputs of the StatusWatermarkValvebecomes idle, we only emit the StreamStatus.IDLE marker, and checknothing else. This makes the watermark advancement behaviourinconsistent in the case that all inputs become idle depending on theorder that they become idle.This commit fixes this by ""flushing"" the max watermark across allchannels once all inputs become idle. At a high-level, what this meansfor downstream operators is that all inputs have become idle and willtemporariliy cease to advance their watermarks, so they can safelyadvance their event time to whatever the largest watermark is.",1
Generified binary and sequential i/o formats,5
"[hotfix][tests] Merge DefaultSchedulerBuilder and AdaptiveBatchSchedulerBuilderThe extending AdaptiveBatchSchedulerBuilder is in a good shape, which requires hack logics to create AdaptiveBatchScheduler. Merging them can make it simpler to create different schedulers.",1
[streaming] Multiple iteration 1,5
[hotfix][network] Simplify UnionInputGate#isFinished,5
Cleaning and commenting I/O Manager + Hashjoin incremental progress.,4
[hotfix] Add JobGraphStoreFactory,4
[hotfix] Let ResourceProfileTest extend TestLogger,3
[FLINK-23418][e2e] Increase the timeout to make kubernetes application ha test more stableThis closes #16602.,3
[hotfix] Fail unacknowledged checkpoints before trying to restart the failed tasks,0
[FLINK-12347][build][sql] Add scala suffix,0
[FLINK-10880] Add release notes warning to not use Flink's failover strategy,0
[FLINK-3254] [dataSet] Adding functionality to support the CombineFunction contract.This closes #1568,1
"MINOR: Vagrant AWS overrideable EC2 instance name prefixewencpThis small change allows users to use Vagrantfile.local to specify a custom prefix for names of ec2 instances brought up with vagrant.This makes management of multiple aws test clusters a little easier since individual clusters can be assigned different name prefixes.if `ec2_instance_name_prefix` is not specified in `Vagrantfile.local`, behavior will be exactly the same as before this change.Testing:- aws: I verified worker nodes, broker nodes, zk nodes with and without the prefix override. Behavior is as expected- locally: I verified that bringing up worker nodes, broker nodes, zk nodes on a local machine is not impacted by this change.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #801 from granders/minor-vagrant-aws-overrideable-prefix",0
[FLINK-25156][table-planner] Support distinct type in CastRulesThis closes #18030.,1
[FLINK-5171] [runtime] fix wrong use of Preconditions.checkState in TaskManagerRunnerThis closes #2880.,1
[FLINK-5825] [webui] Rebuild web frontend,2
修改pomgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1080 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-9377] [core] (part 6) Introduce TypeSerializerSnapshot for a smoother upgrade pathThis commit deprecates TypeSerializerConfigSnapshot, and introduces aTypeSerializerSnapshot interface which will eventually be the newreplacement.The now-deprecated TypeSerializerConfigSnapshot differentiates in thatwhen being written, it wil still write along with it the priorserializer and return that when attempting to restore the priorserializer. Implementations which are upgraded to directly implement thenew TypeSerializerSnapshot interface are strictly required to implementthe restoreSerializer() method. Therefore, once upgraded, the priorserializer is no longer written.",1
"KAFKA-4468: Correctly calculate the window end timestamp after read from state storesI have decided to use the following approach to fixing this bug:1) Since the Window Size in WindowedDeserializer was originally unknown, I have initializeda field _windowSize_ and created a constructor to allow it to be instantiated2) The default size for __windowSize__ is _Long.MAX_VALUE_. If that is the case, then thedeserialize method will return an Unlimited Window, or else will return Timed one.3) Temperature Demo was modified to demonstrate how to use this new constructor, giventhat the window size is known.Author: Richard Yu <richardyu@Richards-Air.attlocal.net>Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3745 from ConcurrencyPractitioner/trunk",1
[hotfix][test] Remove unused class in StreamTaskTest,3
"MINOR: Improve FK Join docs and optimize null-fk case (#7536)Fix the formatting and wording of the foreign-key join javadocOptimize handling of null extracted foreign keysReviewers: Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
[streaming] WordCount Refactor,4
[hotfix][core][test] Prioritize configurations over system properties for enabling fine-grained resource management.,0
[FLINK-24190][runtime] Forbid to split the first record in the buffer if it physically fit it.,2
kafka-1567; Metric memory leaking after closing the clients; patched by Jiangjie Qin; reviewed by Guozhang Wang and Jun Rao,5
removed 'null' as target from evaluate-calls inside an evaluate-method,1
"MINOR: Close the producer batch append stream when the batch gets full to free up resourcesOf particular importance are compression buffers (64 KB for LZ4, for example).Author: Apurva Mehta <apurva@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2796 from apurvam/idempotent-producer-close-data-stream",5
"Merge pull request #1868, add test for rpc modules.fixes #1697",0
修改测试配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1447 1a56cb94-b969-4eaa-88fa-be21384802f2,1
MINOR: Fix a startup NPE in BrokerServer (#10989)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
"MINOR: cleanup some state store code (#5656)Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
Code adjustment and optimization of config-api/common module (#9329)* Code adjustment and optimization of config-api/common module* Remove unused import* Remove unused imports* Update AbstractConfig.java,5
[FLINK-12254][table] Update value literals to new type system,5
TPCH Q10,5
"KAFKA-9992: Eliminate JavaConverters in EmbeddedKafkaCluster (#8673)Fixes EmbeddedKafkaCluster.deleteTopicAndWait for use with kafka_2.13Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <vvcephei@apache.org>",5
reformat code,5
[hotfix][docs][metrics] Fix Threads.Count metric referenceThis closes #5213.,0
"KAFKA-13345: Use ""delete"" cleanup policy for windowed stores if duplicates are enabled (#11380)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>",5
"KAFKA-3985; Transient system test failure ZooKeeperSecurityUpgradeTest.test_zk_security_upgrade.security_protocolAuthor: Flavio Junqueira <fpj@apache.org>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #1973 from fpj/KAFKA-3985",5
[FLINK-12650][docs] Redirect Users to Documentation Homepage if Requested Resource Does Not Exist,2
"KAFKA-6462: fix unstable ResetIntegrationTest (#4446)Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>",3
[FLINK-11334] Fix EnumSerializerSnapshotMigrationTest to check reconfiguration,5
"[FLINK-2561] [gelly] add gelly-scala examples: vertex-centric SSSP, GSA SSSPand how to use a library method (connected components).This closes #1211",1
KAFKA-2767; Upgrade ZkClient version to 0.7Author: Flavio Junqueira <fpj@apache.org>Reviewers: Jun Rao <junrao@gmail.com>Closes #449 from fpj/KAFKA-2767,2
[3.0-Triple] Support triple server stream (#8542)* Support triple server stream* Fix prvodier NPE,0
"MINOR: Remove extraneous code in LocalLogManager (#12168)Reviewers: Kvicii <Karonazaba@gmail.com>, dengziming <dengziming1993@gmail.com>, Divij Vaidya <divijvaidya13@gmail.com>",2
[hotfix] Use UTC when converting to/from SqlTimestamp and TimestampStringThis closes #11694,1
"[FLINK-7489] Remove startJobExecution and suspendExecution from JobMasterGatewayThe job lifecycle methods should not be exposed as RPCs. Therefore, this commitremoves them from the JobMasterGateway definition.This closes #4573.",5
[CI] add source and javadoc jar to snapshot,2
"KAFKA-12380 shutdown Executor in Connect's Worker when closed (#11955)When the worker is stopped, it does not shutdown this executor. This PR fixes the issue.Reviewers: Luke Chen <showuon@gmail.com>",0
[FLINK-24820][docs] Wrong description in documentation for IS DISTINCT FROM,2
"KAFKA-14010: AlterPartition request won't retry when receiving retriable error (#12329)When submitting the AlterIsr request, we register a future listener to handle the response. When receiving retriable error, we expected the AlterIsr request will get retried. And then, we'll re-submit the request again.However, before the future listener got called, we didn't clear the `unsentIsrUpdates`, which causes we failed to ""enqueue"" the request because we thought there's an in-flight request. We use ""try/finally"" to make sure the unsentIsrUpdates got cleared, but it happened ""after"" we retry the requestReviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",5
[FLINK-10916][streaming] Include duplicated user-specified uid in error message,0
"[FLINK-1084] Fix broken links in ""How to add an operator""",1
[FLINK-3665] [dataSet] Add support for sort orders in range partitioning.This closes #1848,1
[hotfix][build] remove duplicate scalatest dependency,3
javaapi support for getTopoicMetaData; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-500git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387796 13f79535-47bb-0310-9956-ffa450edef68,5
MINOR: Fix line break issue in upgrade notes (#6320)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
[FLINK-22889][tests] Configure MySQL lock wait timeout in JdbcExactlyOnceSinkE2eTestThis makes it clear whether waiting lock is the reason of timeoutof task cancellation or snapshot.,1
[FLINK-21673][state/heap] Add extension points to snapshot reading/writing,1
"KAFKA-10607: Consistent behaviour for response errorCounts() (#9433)Reviewers: Lee Dongjin <dongjin@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",0
[FLINK-17515][yarn] Move YARN staging functionality to a separate classThis closes #11991.,1
[FLINK-4446] Remove Flume connector (now in Bahir),4
"MINOR: Fix flaky testIdleConnection() test (#11996)The test expects that the connection becomes idle before the mock time is moved forward, but the processor thread runs concurrently and may run some activity on the connection after the mock time is moved forward, thus the connection never expires.The solution is to wait until the message is received on the socket, and only then wait until the connection is unmuted (it's not enough to wait for unmuted without waiting for message being received on the socket, because the channel might have not been muted yet).Reviewers: David Jacot <djacot@confluent.io>",5
[FLINK-4443] [rpc] Add support for rpc gateway and rpc endpoint inheritanceThis commit extends the RpcCompletenessTest such that it can now check for inheritedremote procedure calls. All methods defined at the RpcGateway are considered native.This means that they need no RpcEndpoint counterpart because they are implemented bythe RpcGateway implementation.This closes #2401.update commentsremove native method annotationadd line break,4
Added test utility classes for plugable types.,3
[FLINK-16581][table-planner-blink] Support state ttl for Mini-Batch deduplication using StateTtlConfigThis closes #11482,5
[FLINK-3321] TupleSerializer.getLength() can return fixed-length sizeThis closes #1654.,0
"MINOR: Fix internal topic manager tests (#11574)When the unit tests of the internal topic manager testare executed on a slow machine (like sometimes in automatic builds)they sometimes fail with a timeout exception instead of the expectedexception. To fix this behavior, this commit replaces the use ofsystem time with mock time.Reviewer: John Roesler <vvcephei@apache.org>",5
"[FLINK-19027][test][network] Set exclusive and floating buffers in UnalignedCheckpointITCase.This commit will amend the original build instability, but future commit will still ensure that a job will not livelock with a tight memory configuration.",5
"[FLINK-9701] [state] (follow up) Use StateTtlConfiguration.DISABLED instead of null, make it Serializable and addconvenience methods to its builderThis closes #6331.",1
[streaming] 0.6 build fix,0
[FLINK-20284][python] Port Grpc SharedResourceHolder class to flink-python moduleThis closes #14217.,2
"KAFKA-2527; System Test for Quotas in Ducktapegranders Can you take a look at this quota system test?Author: Dong Lin <lindong28@gmail.com>Reviewers: Geoff Anderson, Ewen Cheslack-PostavaCloses #275 from lindong28/KAFKA-2527",3
[hotfix][runtime] Rename StreamTask's performDefaultAction method to processInput,0
[FLINK-5883] [core] Re-adding the Exception-thrown code for ListKeyGroupedIterator when the iterator is requested the second timeThis closes #3392,2
First implementation of a general Schema. Extended the signature of Schema>>jsonToRecord with an EvaluationContext; added simple testcases for GeneralSchema,3
[FLINK-25519][Connectors] Promote StreamExecutionEnvironment#fromSource() from @Experimental to @PublicEvolving,2
"KAFKA-4335: Add batch.size to FileStreamSource connector to prevent OOMWhen the source file of `FileStreamSource` is a large file, `FileStreamSourceTask.poll()` will result in OOM. This pull request added `batch.size` parameter which can restrict the poll size.*More detailed description of your change,if necessary. The PR title and PR message becomethe squashed commit message, so use a separatecomment to ping reviewers.**Summary of testing strategy (including rationale)for the feature or bug fix. Unit and/or integrationtests are expected for any behaviour change andsystem tests should be considered for larger changes.*Author: Study <ph.study@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #4356 from phstudy/KAFKA-4335",5
[FLINK-8957][tests] Port JMXJobManagerMetricTest to flip6This closes #5720.,3
"Fixed bug in PactConnection, Reengineered BlockResettableIterator for correct shutdown.",1
"[FLINK-21790][network] Shuffle data directories to make directory selection of different TaskManagers fairerCurrently, different TaskManagers select data directory in the same order and if there are multiple disk, some disks may stores more data than others which is bad for performance. A simple improvement is that each TaskManager shuffles the given data directories randomly and select the data directory in different order.This closes #18456.",5
Fix telnet can not find method with enum type (#2803),0
Add route part,1
"KAFKA-3479: Add new consumer metrics documentationadded new consumer metrics sectionrefactored common metrics into new sectionupdated TOCAuthor: Kaufman Ng <kaufman@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1361 from coughman/KAFKA-3479-consumer-metrics-doc",2
[hotfix][docs][table] Fix docs for SHA1,2
"[FLINK-14926][state-backend-rocksdb] (follow-up) Replace OptionsFactory for RocksDBOptionsFactoryOptionsFactory was breaking existing implementations by adding a method to the interface without default method.To solve this, we keep OptionsFactory but replace it in the RocksDB State Backend with the RocksDBOptionsFactory which hasthe evolved signature. The OptionsFactory is still accepted and wrapped into a RocksDBOptionsFactory, for compatibility.",5
[hotfix] Enable standalone HA mode by choosing HA port range,0
Fixed #124,0
[FLINK-1201] [gelly] Expose the full Vertex and Edge object in filter functionsExpose the full Vertex and Edge object in filter functions to allow filteringby key value:- subgraph()- filterOnVertices()- filterOnEdges()fixes #56,0
修改页面git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@399 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Refactor project structure using maven,1
move getKey from RedisServiceStore to AbstractServiceStore;  modify demo consumer url,1
[FLINK-17047][runtime] Remove the producerId param from SchedulingStrategy#onPartitionConsumable(…)It’s redundancy since we can also retrieve it from the partition.,2
"KAFKA-10847: Set StreamsConfig on InternalTopologyDriver before writing topology (#10640)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Explain the separate  upgrade paths for consumer groups and Streams (#7516)Document the upgrade path for the consumer and for Streams (note that they differ significantly).Needs to be cherry-picked to 2.4Reviewers: Guozhang Wang <wangguoz@gmail.com>,2
"MINOR: reduce impact of trace logging in replica hot path (#8468)The impact of trace logging is normally small, on the order of 40ns per getEffectiveLevel check, however this adds up with trace is called multiple times per partition in the replica fetch hot path.This PR removes some trace logs that are not very useful and reduces cases where the level is checked over and over for one fetch request.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",1
KAFKA-698 Avoid advancing the log end offset until the append has actually happened since reads may be happening in the meantime.,1
"[FLINK-10596][cep, docs] Added description of TimeContext to docs",2
Qos heart (#3170)* qos heart question fix #3165* modify* judge if it's a IdleStateEvent* add UT* modify,1
[hotfix] [log] Log proper user defined state backend in StreamTask,1
"[FLINK-21667][runtime] Move RM leader election to ResourceManagerService.This means each ResourceManager only serves one leadership session. When leadership is revoked and re-granted, a new ResourceManager will be created.This closes #15524",1
"[FLINK-3002] Add Either type, EitherTypeInfo, and EitherSerializer to the Java APIThis closes #1371",5
[hotfix][build] Enable incremental compilation,0
[FLINK-4997] [streaming] Add ProcessWindowFunction to Scala API,1
MINOR: Remove dead codeAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4087 from ijuma/remove-dead-code,4
"[FLINK-18801][docs][python] Add a ""10 minutes to Table API"" document under the ""Python API"" -> ""User Guide"" -> ""Table API"" section.This closes #13273.",1
[hotfix] [quickstarts] Fix block comments in program stubs.,0
[hotfix][docs][kafka] Corrected idleness attribute nameThis closes #16451,2
"[FLINK-10508] Port ""The JobManager actor must handle jobs when not enough slots"" to MiniClusterITCase#testHandleJobsWhenNotEnoughSlot",5
Small cleanup to truncate some lines that are too long for easy read of the code.,1
[FLINK-11029] [docs] Fixed incorrect parameter in Working with state docThis closes #7198.,2
[FLINK-7598][travis] fix ineffective shaded artifacts checksThis fixes the netty check and makes all of them more robust against failures ofthe executed commands counting the number of dependencies.This closes #4653.,0
[streaming] [docs] Updated streaming guide for new state interfaces,1
"KAFKA-12738: track processing errors and implement constant-time task backoff (#11787)Part 1 in the initial series of error handling for named topologies.*Part 1: Track tasks with errors within a named topology & implement constant-time based task backoffPart 2: Implement exponential task backoff to account for recurring errorsPart 3: Pause/backoff all tasks within a named topology in case of a long backoff/frequent errors for any individual taskReviewers:  Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",5
[FLINK-19119][python][docs] Update the documentation to use Expression instead of strings in the Python Table APIThis closes #13348.,1
"MINOR: Tighten FileRecords size checks to prevent overflow (#5332)Add some additional size validation to prevent overflows when using `FileRecords`. Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",5
"[FLINK-6926] [table] Add support for MD5, SHA1 and SHA256This closes #4810.",1
[hotfix][task] Rename SourceStreamTask.isFinished to wasStoppedExternally,5
[FLINK-20669][python][legal] Add the jzlib LICENSE file in flink-python moduleThis closes #14418.,2
Decreased NIO sleep time from 500 to 50 ms,5
[docs] Fix documentation for building Flink with Scala 2.11 or 2.10This closes #1260,2
[FLINK-20342][docs] Move ops/deployment/Overview to ops/Overview,4
KAFKA-2782: Fix KafkaBasedLogTest assertion and move it to the main test thread.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Gwen ShapiraCloses #463 from ewencp/kafka-2782-fix-kafka-based-log-test-assertion,3
[FLINK-17555][python] Remove duplicate FileSystem object in descriptors (#12023),5
[FLINK-6411] [flip-6] Remove job removal from RunningJobsRegistry in YarnFlinkApplicationMasterRunner.shutdownThe YarnFlinkApplicationMasterRunner should not be concerned with removing jobs fromthe RunningJobsRegistry. This is the responsibility of the JobManagerRunner.This PR removes the job removal from the RunningJobRegistry from theYarnFlinkApplicationMasterRunner.shutdown method.This closes #3797.,2
Changed logic of cancelling thread to join with executing thread.,2
"extract 2 methods: (#3453)isSetter: test if a method is a settergetSetterProperty: get property for setter, for instance setVersionreturn ""version""",1
add final modifier for lock in FrameworkModel (#10281),1
DUBBO-249 增加特定配置名称过滤git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1147 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-2208; add consumer side error handling upon coordinator failure; reviewed by Onur Karaman,0
[FLINK-9557] [formats] Parse 'integer' type as BigDecimalThis closes #6153.,2
MINOR: add dependency analysis debugging tasksAuthor: Arvind Thirunarayanan <athirunar@confluent.io>Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>Closes #7694 from arvindth/ath-debugdeps-task,0
KAFKA-7216: Ignore unknown ResourceTypes while loading acl cache (#5673)Reviewers: Jun Rao <junrao@gmail.com>,5
"KAFKA-12939: After migrating processors, search the codebase for missed migrations (#11534)Migrated internal usages that had previously been marked with TODO suppressions.Reviewer: John Roesler<vvcephei@apache.org>",2
Fix time unit problem in UT,0
"KAFKA-3705 Added a foreignKeyJoin implementation for KTable. (#5527)https://issues.apache.org/jira/browse/KAFKA-3705Allows for a KTable to map its value to a given foreign key and join on another KTable keyed on that foreign key. Applies the joiner, then returns the tuples keyed on the original key. This supports updates from both sides of the join.Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Jan Filipiak <Jan.Filipiak@trivago.com>, pgwhalen, Alexei Daniline",5
[docs] Add back pressure monitoring page,1
"[FLINK-3994] [ml, tests] Fix flaky KNN integration testsThis closes #2056.",3
[FLINK-12763][runtime] Introduce a start-up period to standalone cluster that after this period StandaloneResourceManager set SlotManager to fail unfulfillable requests.,0
Adjusted pom.xml for test dependencies to latest documentation,2
[FLINK-12959][table-planner-blink] Implement BatchExecHashJoin translateToPlanInternalThis closes #8854,2
"fix #9341, ignore OverlappingFileLockException (#9358)",2
"Revert ""[FLINK-19850] Add e2e tests for the new FileSink in streaming mode""This reverts commit dfd2a55065e228b973f9e2343b6252ca308e5398.",4
[FLINK-7599][docs] Updated MATCH_RECOGNIZE documentation with aggregations,2
Fixed bug in FailingJobITCase,0
"Revert ""[hotfix][docs] Temporarily disable liveserve""This reverts commit f802e16b06b0c3a3682af7f9017f9c0a69e5d4de.",4
[FLINK-22697][examples-table] Remove WordCountTable example,4
KAFKA-13088: Replace EasyMock with Mockito for ForwardingDisabledProcessorContextTest (#11051)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
set reg status to true after reExport,1
[FLINK-7304] [scripts] Simplify taskmanager GC configurationThis closes #4427.,5
DUBBO-259 pojoutil基本类型转换失败git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1188 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-12270: Handle race condition when Connect tasks attempt to create topics (#10032)When a source connector is configured to create missing topics has multiple tasks that generate records for the same topic, it is possible that multiple tasks may simultaneously describe the topic, find it does not exist, and attempt to create the task. One of those create topic requests will succeed, and the other concurrent tasks will receive the response from the topic admin as having not created the task and will fail unnecessarily.This change corrects the logic by moving the `TopicAdmin` logic to create a topic to a new `createOrFindTopics(…)` method that returns the set of created topic names and the set of existing topic names. This allows the existing `createTopics(…)` and `createTopic(…)` methods to retain the same behavior, but also allows the `WorkerSourceTask` to know from its single call to this new method whether the topic was created or was found to exist.This adds one unit test and modifies several unit tests in `WorkerSourceTaskWithTopicCreationTest` that use mocks to verify the behavior, and modifies several existing unit tests for `TopicAdminTest` to ensure the logic of the new method is as expected.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
DUBBO-132 bytecode包的Wrapper的反射方法调用，提供方没有重载的方法时，当提供多余的参数时，多余参数会被忽略（应该报错）git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@720 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][test] Disable Google PubSub Emulator e2e test on aarch64This closes #12111,3
"[FLINK-12639] [docs] add ""getting started"" section to documentation to expand in FLIP-42",2
KAFKA-2461; request logger no longer logs extra information in debug modeAuthor: asingh <asingh@cloudera.com>Reviewers: Gwen ShapiraCloses #169 from SinghAsDev/KAFKA-2461,0
[FLINK-24704][table-runtime] Fix exception when the input record loses monotonicity on the sort key field of UpdatableTopNFunctionThis closes #17605,5
"MINOR: Relax Unsupported Version check on BrokerCompatibilityTest (#5170)In BrokerCompatibilityTest.java, when older versioned broker is used (0.10.1, 0.10.2), LIST_OFFSET is not supported as well. Hence in the verification phase, there is a possibility that consumer hit the UnsupportedVersionException earlier than Streams actually hits it:org.apache.kafka.common.errors.UnsupportedVersionException: The broker does not support LIST_OFFSETS with version in range [2,3]. The supported range is [0,1].While the test is waiting fororg.apache.kafka.common.errors.UnsupportedVersionException: Cannot create a v0 FindCoordinator request because we require features supported only in 1 or later.Both are valid errors to expect (the former is from consumer while the latter is from producer of the streams app).Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
[FLINK-24763][parquet] Ignore unstable ParquetFileSystemITCase.testLimitableBulkFormatThis closes #17923,5
KAFKA-2324; Update to Scala 2.11.7Author: Ismael Juma <ismael@juma.me.uk>Closes #82 from ijuma/kafka-2324 and squashes the following commits:d71bf5c [Ismael Juma] KAFKA-2324; Update to Scala 2.11.7,5
[FLINK-12861][coordination] Remove legacy ListeningBehaviour,4
Fix metadata report configuration error (#3183)* fix prefix* Missing '@Override' annotation,0
[FLINK-21116][tests] Harden DefaultDispatcherRunnerITCase#leaderChange_withBlockingJobManagerTermination_doesNotAffectNewLeader.This closes #16695.,4
made lower and upper bound configurable,5
[3.0] Improve resource cleaning (#9129),4
"Demo, remove version",4
[FLINK-1981] add support for GZIP files* register decompression algorithms with file extensions for extensibility* fit deflate decompression into this scheme* add support for GZIP files* test support for deflate and GZIP files with the CsvInputFormat* replace Apache Commons' Validate with Guava's Preconditions* add documentation on reading compressed filesThis closes #762.,2
[hotfix][table] Improve signature of Executor,1
[release] Upgrade current version to 1.15 for FlinkKafkaProducerMigrationTest and create snapshots,1
[hotfix] Add a waitUntil() method to the CommonTestUtils.,3
[FLINK-24275][rest] Idempotent job cancellation,2
"KAFKA-5520: KIP-171; Extend Consumer Group Reset Offset for Stream ApplicationKIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-171+-+Extend+Consumer+Group+Reset+Offset+for+Stream+ApplicationMerge changes from KIP-198Ref: https://github.com/apache/kafka/pull/3831Author: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>Author: Ismael Juma <ismael@juma.me.uk>Author: Matthias J. Sax <matthias@confluent.io>Author: Manikumar Reddy <manikumar.reddy@gmail.com>Author: Guozhang Wang <wangguoz@gmail.com>Author: Apurva Mehta <apurva@confluent.io>Author: Rajini Sivaram <rajinisivaram@googlemail.com>Author: Jason Gustafson <jason@confluent.io>Author: Vahid Hashemian <vahidhashemian@us.ibm.com>Author: Bill Bejeck <bill@confluent.io>Author: Dong Lin <lindong28@gmail.com>Author: Soenke Liebau <soenke.liebau@opencore.com>Author: Colin P. Mccabe <cmccabe@confluent.io>Author: Damian Guy <damian.guy@gmail.com>Author: Xavier Léauté <xl+github@xvrl.net>Author: Maytee Chinavanichkit <maytee.chinavanichkit@linecorp.com>Author: Joel Hamill <git config --global user.email>Author: Paolo Patierno <ppatierno@live.com>Author: siva santhalingam <siva.santhalingam@gmail.com>Author: Tommy Becker <tobecker@tivo.com>Author: Mickael Maison <mickael.maison@gmail.com>Author: Onur Karaman <okaraman@linkedin.com>Author: tedyu <yuzhihong@gmail.com>Author: Xin Li <Xin.Li@trivago.com>Author: Magnus Edenhill <magnus@edenhill.se>Author: Manjula K <manjula@kafka-summit.org>Author: Hugo Louro <hmclouro@gmail.com>Author: Jeff Widman <jeff@jeffwidman.com>Author: bartdevylder <bartdevylder@gmail.com>Author: Ewen Cheslack-Postava <me@ewencp.org>Author: Jacek Laskowski <jacek@japila.pl>Author: Tom Bentley <tbentley@redhat.com>Author: Konstantine Karantasis <konstantine@confluent.io>Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4159 from jeqo/feature/kip-171",5
[FLINK-7811] Update scalatest to 3.0.0 for Scala 2.12 supportOur previous dependency was too old.,1
customize instance metadata.,5
[FLINK-200137][python] Handle the timestamp of elements properly in Python DataStream APIThis closes #14068.,5
[hotfix][docs] Fix missing period package declarationThis closes #5077.,0
[hotfix] Move SchedulerBase specific queryable state logic into KvStateHandler to make it reusable,1
Adjust the scope of the spi extension (#8600)* change test spi scope* change test spi scope,3
[FLINK-19064][hbase] HBaseRowDataInputFormat is leaking resourcesThis closes #13275,5
"KAFKA-7354; Fix IdlePercent and NetworkProcessorAvgIdlePercent metricCurrently, MBean `kafka.network:type=Processor,name=IdlePercent,networkProcessor=*` and `afka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent` could be greater than 1. However, these two values represent a percentage which should not exceed 1.Author: huxihx <huxi_2b@hotmail.com>Reviewers: Dong Lin <lindong28@gmail.com>Closes #5584 from huxihx/KAFKA-7354",1
MINOR: Log4j Improvements on Fetcher (#8629)Reviewers: Jason Gustafson <jason@confluent.io>,5
[FLINK-11483][tests] Simplify StreamOperatorSnapshotRestoreTest with ParameterizedThis closes #7612.,2
[FLINK-4745] [table] Convert KafkaTableSource test to unit testsThis closes #2603.,3
[FLINK-25545][flink-clients][JUnit5 Migration] Module: flink-clients.This closes #18928.Co-authored-by: Ryan Skraba <ryan@skraba.com>,2
Fixed PactNull Serialization.,0
[streaming] Integrated the policy based windowing into DataStream and introduced WindowedDataStream to handle windowing helper.,0
[FLINK-1560] [streaming] Added ITCases to streaming examples,1
[hotfix][hive] Use TableUtils.collectToList(Table) in TableEnvHiveConnectorTest,3
"MINOR: refactor Log to get rid of ""return"" in nested anonymous function (#9162)Scala uses NonLocalReturnException to implement the control flow of returning from a nested anonymous function. That is anti-pattern so we should avoid using it in the hot methods.Reviewers: Ismael Juma <ismael@confluent.io>",5
"KAFKA-13266; `InitialFetchState` should be created after partition is removed from the fetchers (#11294) `ReplicationTest.test_replication_with_broker_failure` in KRaft mode sometimes fails with the following error in the log:```[2021-08-31 11:31:25,092] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Unexpected error occurred while processing data for partition __consumer_offsets-1 at offset 31727 (kafka.server.ReplicaFetcherThread)java.lang.IllegalStateException: Offset mismatch for partition __consumer_offsets-1: fetched offset = 31727, log end offset = 31728. at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:194) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$8(AbstractFetcherThread.scala:545) at scala.Option.foreach(Option.scala:437) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$7(AbstractFetcherThread.scala:533) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$7$adapted(AbstractFetcherThread.scala:532) at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62) at scala.collection.convert.JavaCollectionWrappers$JMapWrapperLike.foreachEntry(JavaCollectionWrappers.scala:359) at scala.collection.convert.JavaCollectionWrappers$JMapWrapperLike.foreachEntry$(JavaCollectionWrappers.scala:355) at scala.collection.convert.JavaCollectionWrappers$AbstractJMapWrapper.foreachEntry(JavaCollectionWrappers.scala:309) at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:532) at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:216) at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:215) at scala.Option.foreach(Option.scala:437) at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:215) at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:197) at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:99)[2021-08-31 11:31:25,093] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Partition __consumer_offsets-1 marked as failed (kafka.server.ReplicaFetcherThread)```The issue is due to a race condition in `ReplicaManager#applyLocalFollowersDelta`. The `InitialFetchState` is created and populated before the partition is removed from the fetcher threads. This means that the fetch offset of the `InitialFetchState` could be outdated when the fetcher threads are re-started because the fetcher threads could have incremented the log end offset in between.The patch fixes the issue by removing the partitions from the replica fetcher threads before creating the `InitialFetchState` for them.Reviewers: Jason Gustafson <jason@confluent.io>### Committer Checklist (excluded from commit message)- [ ] Verify design and implementation - [ ] Verify test coverage and CI build status- [ ] Verify documentation (including upgrade notes)",2
[FLINK-24353][scripts] Respect dynamic configurations when calculating memory sizes.This closes #17335,5
[hotfix][docs] Add the missing datastream_execution_mode.zh.md,5
Upgrade webx version to fix dubbo-admin incompatible problem when running with jdk1.8,1
[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse.This closes #11353.,1
[FLINK-18493] Make Yarn staging directory for Flink application configurableThis closes #13014.,5
[FLINK-17958][core] Fix MathUtils#divideRoundUp bug for handling zero / negative values.This closes #12357.,0
[FLINK-8165] ParameterTool serialization fixCloses #5096,0
[FLINK-23363][table-code-splitter] Java code splitter now supports functions with return statements,1
"Adding reverse iterator usage for sliding windows processing (extending KIP-450) (#9239)Add a backwardFetch call to the window store for sliding windowprocessing. While the implementation works with the forward callto the window store, using backwardFetch allows for the iteratorto be closed earlier, making implementation more efficient.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",5
[FLINK-23111][runtime-web] Bump angular's and ng-zorro's version to 8,2
Temporary fix: Adapt dop for union from descendant,0
[FLINK-10934][client] Make flink run-application could support local schema,1
"MINOR: Fix comment about AbstractFetcherThread.handlePartitionsWithError (#7205)Reviewers: Stanislav Kozlovski<stanislav_kozlovski@outlook.com>, William Hammond<william.t.hammond@gmail.com>, Chia-Ping Tsai<chia7712@gmail.com>",0
[FLINK-10690][tests] Fix Files.list resource leaks,2
[FLINK-7456][network] Implement Netty sender incoming pipeline for credit-basedThis closes #4552.,2
[FLINK-21448] Add randomization of state changelog config,5
"[optimization]RestProtocol opt, share client pool among services and avoid potential memory leak. (#10023)* rest protocol client share* rest protocol optimization* reference count support* check and clear",1
[FLINK-24773][kafka] Fail job if unhandled exception occurs during committingUnhandled exceptions during committing usually imply that data is lost.We should not only log and continue processing but fail the job to givethe user the choice what should be done.,1
Minor changes in RemoteExecutor.java and LocalExecutor.java. Removed obsolete null-value check in the finally clauses in LocalExecutor.java. Returning proper exit code in RemoteExecutor.java.,1
[FLINK-17810][doc] Add document for K8s application modeThis closes #12245,2
DUBBO-275 简化本地服务，自动短路 改为scope的方式git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1637 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Replace some Java 7 style code with Java 8 style (#7623)Reviewers: Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",5
modify some typos (#3257)* modify some typos* fix some other addionalParameterKeys and paramter typos,2
[hotfix][avro] Add comments to explain why projection pushdown works for avro bulk formatThis closes #18717,1
[hotfix][tests] Make NoOpPartitionProducerStateChecker a public reusable test implementation.,3
Fixed erroneous cluster mode instantiation.,0
[hotfix][docs] fix broken SVG figure and include license this time,0
"MINOR: Move `RaftRequestHandler` to `tools` package (#9377)To avoid confusion since it is only used by `TestRaftServer`, this PR moves `RaftRequestHandler` to the `tools` package and renames it to `TestRaftRequestHandler`.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
[FLINK-23990][runtime-web] Replace custom monaco editor with nz-code-editor,2
[FLINK-10541][tests] Removed unused legacy methods in TestBaseUtils,3
MINOR: Fix re-raise of python error in system testsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2099 from ewencp/fix-python-reraise,0
[FLINK-27556][state] Inline state handle id generation...  to avoid unnecessary overhead when it's not used.,1
没有此问题 DUBBO-542 Cache、Validation功能，在Reference配置值不会无效，只有Method配置的值才生效URL获得true，统一缺省值的字面量default,5
"KAFKA-13418: Support key updates with TLS 1.3 (#11966)Key updates with TLS 1.3 trigger code paths similar to renegotiation with TLS 1.2.Update the read/write paths not to throw an exception in this case (kept the exceptionin the `handshake` method).With the default configuration, key updates happen after 2^37 bytes are encrypted.There is a security property to adjust this configuration, but the change has to bedone before it is used for the first time and it cannot be changed after that. As such,it is best done via a system test (filed KAFKA-13779).To validate the change, I wrote a unit test that forces key updates and manually rana producer workload that produced more than 2^37 bytes. Both cases failed withoutthese changes and pass with them.Note that Shylaja Kokoori attached a patch with the SslTransportLayer fix and henceincluded them as a co-author of this change.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Co-authored-by: Shylaja Kokoori",5
"[FLINK-14967][table] Add a utility for creating data types via reflectionThis implements the data type extractor mentioned in FLIP-65. It is similar toFlink's core type information extractor but also adds a lot of SQL specific featuresand improves the overall user experience. In particular, it allows to annotatetypes, fields, and classes for parameterizing the extraction process. It is unifiedacross Java and Scala.This closes #10342.",4
KAFKA-10017: fix uncaucht-exception handling in EosBetaUpgradeIntegrationTest (#9733)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
Add acknowledgement to the produce request; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-49git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1300435 13f79535-47bb-0310-9956-ffa450edef68,1
[FLINK-22773][coordination] Make DefaultLogicalTopology inherit from LogicalTopology,2
[FLINK-23808][checkpoint] Bypass operators when advanceToEndOfEventTime for both legacy and new source tasksThis closes #16861.,1
"[FLINK-2219] [webfrontend] Fix IllegalArgumentException and decrease log level- Pressing the state button in the job history view (like SCHEDULED, FINISHED)  sends a ""null"" (String) as group vertex ID, which results in an  IllegalArgumentException. Fixed by check and early return.- The JM log is flooded by INFO-level messages when no GlobalJobParameters are  set (common case). Fixed by decreasing the log level of these message to  DEBUG.",0
[hotfix] [docs] Tidy up documentation. Fix some non-idiomatic usage of return in scala code.This closes #1531,0
[FLINK-7765][build] Enable dependency convergence by defaultDisable it in most modules.,0
"KAFKA-6512: Discard references to buffers used for compression (#4570)ProducerBatch retains references to MemoryRecordsBuilder and cannot be freed until acks are received. Removing references to buffers used for compression after records are built will enable these to be garbage collected sooner, reducing the risk of OOM.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Lothsahn <Lothsahn@gmail.com>",5
[3.0] Add some log when failed to get return types (#9618),1
Removed final modifier from FileBufferManager class,2
[FLINK-14065] Log metric name when the metric fails on registration/unregistrationThis closes #9680.,0
[FLINK-898] Clean up distribution default config,5
further work on clustering,1
[FLINK-19958] Add IOException to all I/O related Sink API signatures,1
[FLINK-15100][connector/common] Add abstract implementation for SourceReader (FLIP-27).,1
KAFKA-1333 follow-up; Add missing files for the coordinator folder,2
"KAFKA-8558:  Add StreamJoined config object to join (#7285)Reviewer: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-9147] [metrics] Include shaded Prometheus dependencies in jar  The Prometheus metrics reporter does not include the shaded Prometheus dependencies in its jar. This commit changes this.This closes #5828.,4
"KAFKA-5928; Avoid redundant requests to zookeeper when reassign topic partitionAuthor: uncleGen <hustyugm@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>Closes #3894 from uncleGen/KAFKA-5928",5
- added compiler hints to WebLogAnalysis PACT example job,2
[hotfix] [rpc] Add more logging for endpoint shutdown,2
"KAFKA-13943; Make `LocalLogManager` implementation consistent with the `RaftClient` contract (#12224)Fixes two issues in the implementation of `LocalLogManager`:- As per the interface contract for `RaftClient.scheduleAtomicAppend()`, it should throw a `NotLeaderException` exception when the provided current leader epoch does not match the current epoch. However, the current `LocalLogManager`'s implementation of the API returns a LONG_MAX instead of throwing an exception. This change fixes the behaviour and makes it consistent with the interface contract.-  As per the interface contract for `RaftClient.resign(epoch)`if the parameter epoch does not match the current epoch, this call will be ignored. But in the current `LocalLogManager` implementation the leader epoch might change when the thread is waiting to acquire a lock on `shared.tryAppend()` (note that tryAppend() is a synchronized method). In such a case, if a NotALeaderException is thrown (as per code change in above), then resign should be ignored.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Tom Bentley <tbentley@redhat.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-5876: Apply UnknownStateStoreException for Interactive Queries (#9821)KIP-216: IQ should throw different exceptions for different errors, Part 2Reviewers: Matthias J. Sax <mjsax@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@confluent.io>",5
[hotfix][table-planner] Disable IntervalJoinITCase.testRowTimeInnerJoinWithEquiTimeAttrs until FLINK-24443 is fixed,0
[FLINK-6724] Include class name in UDFUtils#checkForInstantiation exceptionsThis closes #3995.,2
[3.0] Save interface class in ReferenceConfig (#9569),5
[hotfix] Some Java 7 cleanups in InstantiationUtil,4
[hotfix][docs] Improve HBase and JDBC connector documentation,2
[FLINK-18253][doc][avro] Add filesystem option documentation for AvroThis closes #12599,2
kafka-1529; transient unit test failure in testAutoCreateAfterDeleteTopic; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,3
[hotfix][table-common] Reformat BuiltInFunctionDefinitions,5
[hotfix] [docs] Add double quotes to Kafka version YAML examplesThis closes #6639.,1
MINOR: Tweak detection of kafka server start-up in system testsAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3834 from ijuma/tweak-system-test-regex-for-detecting-server-start-up,5
[FLINK-2011] [runtime] Improve error message when user-defined serialization logic is erroneous,2
[hotfix] [docs] Update documentation about joins,2
[hotfix] Avoid redundant state access in TemporalProcessTimeJoin.,0
[FLINK-15064][table-planner-blink] Remove XmlOutput util class in blink planner since Calcite has fixed the issueThis closes #15911,0
Improved robustness of default configuration,5
[FLINK-16718][tests] Fix ByteBuf leak in KvStateServerHandlerTestThis closes #11453.,3
KAFKA-9734: Fix IllegalState in Streams transit to standby (#8319)Consolidate ChangelogReader state management inside of StreamThread to avoid having to reason about all execution paths in both StreamThread and TaskManager.Reviewers: Guozhang Wang <wangguoz@gmail.com>,4
[hotfix][python]Fix the install failure of pyflink used previous version of python 2.7 (#9016)Fix for python 2.7.10.,0
[FLINK-1110] Add execution on collections for flatMap,1
"KAFKA-10164; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part II, Admin Changes) (#8968)Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-23416][runtime] Don't log NoResourceAvailableException stacktraceThis closes #16523.,2
[hotfix][runtime] Cleanup IOManager code,4
"KAFKA-12324: Upgrade jetty to fix CVE-2020-27218Here is the fix. The reason of [CVE-2020-27218](https://nvd.nist.gov/vuln/detail/CVE-2020-27218) was [Incorrect recycling of `HttpInput`](https://bugs.eclipse.org/bugs/show_bug.cgi?id=568892) and [patched in 9.4.35.v20201120](https://github.com/eclipse/jetty.project/security/advisories/GHSA-86wm-rrjm-8wh8).This PR updates Jetty dependency into the following version, 9.4.36.v20210114.Author: Lee Dongjin <dongjin@apache.org>Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>Closes #10177 from dongjinleekr/feature/KAFKA-12324",5
[hotfix][docs] Fix broken table that describes 'numberOfRestarts' metric,0
[FLINK-16834] Add flink-clients to flink-quickstarts pomsFlink quickstarts' poms need to include flink-clients as a dependency because it isno longer transitively pulled into the project.,1
"fix #10078, Use synchronizedMap to avoid ConcurrentModificationException (#10139)",1
[FLINK-22714][table-planner-blink] Simplify window TVF to a simple window assigner if successornode is WindowRank or WindowJoinThis closes #16025,2
[FLINK-7518][network] pass our own NetworkBuffer to nettyThis is using a composite buffer to assemble header+content and avoids anunnecessary buffer copy from our (Network)Buffer class backed by a MemorySegmentto Netty's ByteBuf class.This closes #4615.,1
[hotfix][task] Fix the code formatting in StreamTask,0
[streaming] wordcount cluster settings updated,5
[hotfix] Add BiFunctionWithException#unchecked to convert into BiFunction,1
[FLINK-1201] [gelly] removed 2-arg Edge constructor,4
[FLINK-16203][table] Support JSON_OBJECTThis closes #17186,5
[FLINK-8131] Update to Kafka 0.11.0.2,5
"[FLINK-13653][sql-client] ResultStore should avoid using RowTypeInfo when creating a resultFix the issue that types with parameters, e.g. decimal, cannot be accessed via SQL client.This closes #9432.",2
[FLINK-6824] Activate checkstyle for runtime/eventThis closes #4056.,1
Add Unit Test for org.apache.dubbo.registry.support.AbstractRegistry,1
DUBBO-218 测试对空属性也要检查-D参数git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1047 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Added ReduceITCase for Java API reduce operator,1
[hotfix][travis] Reduce depth for walkthrough module detectionIf the module was built beforehand a pom.xml would be detected in the target directory.,1
"[FLINK-10406] (Part 7) testResourceManagerConnectiontestResourceManagerConnection is not applicable to FLIP-6 new code base,FLIP-6 has its own reconnect logic between JM and RM and the mechanismshould be guarded byJobMasterTest#testReconnectionAfterDisconnectJobMasterTest#testResourceManagerConnectionAfterRegainingLeadershipJobMasterTest#testCloseUnestablishedResourceManagerConnection",5
"[FLINK-21610][tests] Harden ProcessFailureCancelingITCaseThe cancellation of the job may fail if the job termination finishes so quickly that the job has been cleaned up before the cancellation has been processed.The cancellation is unnecessary anyway because the TM failure causes the job to fail and we explicitly forbid restarts.As such we can just remove the cancel call.Furthermore, the conditions for when to kill the TM were not correct, as they did not ensure the job was actually deployed.",4
"KAFKA-6813: Remove deprecated APIs in KIP-182, Part III (#4991)1. Remove TopologyBuilder, TopologyBuilderException, KStreamBuilder,2. Completed the leftover work of https://issues.apache.org/jira/browse/KAFKA-5660, when we remove TopologyBuilderException.3. Added MockStoreBuilder to replace MockStateStoreSupplier, remove all XXStoreSupplier except StateStoreSupplier as it is still referenced in the logical streams graph.4. Minor: rename KStreamsFineGrainedAutoResetIntegrationTest.java to FineGrainedAutoResetIntegrationTest.java.Reviewers: Matthias J. Sax <matthias@confluent.io>",5
[FLINK-11899][parquet] Introduce parquet ColumnarRow split readerThis closes #10922,2
[hotfix] Make ExecutionGraphTestUtils#createSimpleTestGraph return DefaultExecutionGraph,3
[FLINK-4539] [runtime] Reuse functionality for Physical Memory size in 'Hardware' and 'EnvironmentInformation'.,5
[FLINK-1287] LocalizableSplitAssigner prefers splits with less degrees of freedomThis closes #258,2
[hotfix] [docs] Update checkstyle version in documentationThis closes #5061,2
删掉不再使用的常量git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1873 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][travis] Hide maven download progress,0
READMEgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@880 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][state] Improve memory-friendliness of state assignment by allocating collections with correct sizes or improved size estimates where possible,1
[release][docs] Clean up 1.14 release notesThis closes #17392,3
[FLINK-24560][build][yarn] Copy example jars in pre-integration-test phasejars don't exist before packaging phase,3
[hotfix][table-planner] Unify the JSON test utilities,3
Moved WebInfoServer and WebInterfaceServer resources into resource folders of respective projects. Jetty uses the jar as base directory.,1
[FLINK-3224] [DataStream] Call setInputType() on output formats that implement InputTypeConfigurableThis closes #1497,5
"KAFKA-9614: Not initialize topology twice in StreamTask (#8173)We only initialize topology when transiting from restoring -> running.Also tighten some unit tests for this fix:a. restoring -> suspended should just write checkpoint file without committing.b. suspended -> restoring should not need any inner updates.c. restoring -> running should always try to fetch committed offsets, and forward timeout exceptions.Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>",5
add gpg signing plugin for protobuf compiler,1
Finished I/O operations of failure patterns manager,0
Add shutdown command for telnet (#3280)* telnet add shutdown command* refactor rename shutDown to shutdown* remove unregister  in doDestroy* unregister the ShutdownHook when the shutdown command invoked,1
"MINOR: Fix flaky ConsumerTopicCreationTest (#6727)`ConsumerTopicCreationTest` relied on `KafkaConsumer#poll` to send a `MetadataRequest` within 100ms to verify if a topic is auto created or not. This is brittle and does not guarantee if the request made it to the broker or was processed successfully. This PR fixes the flaky test by adding another topic; we wait until we consume a previously produced record to this topic. This ensures MetadataRequest was processed and we could then check if the topic we're interested in was created or not.Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",5
Improve service exported logic (#8160),2
add AddressListener into RegistryDirectory,1
[FLINK-5810] [flip-6] Use single timeout task for SlotManager,1
[FLINK-18966][python] Support key_by() on ConnectedStreams for Python DataStream API (#13153),5
"MINOR: Improve PlainSaslServer error message for empty tokens (#6249)Empty username or password would result in the ""expected 3 tokens""error instead of ""username not specified"" or ""password not specified"".Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
[hotfix] Fix typo in TestableKinesisDataFetcherThis closes #5178,5
DUBBO-489 修改出错页面,5
"[streaming] Introduced grouped windowing invokable, added required cloneable policy interfaces, and adjusted existing windowing invokable to make it usable together with the new grouped windowing invokable.",1
[FLINK-1434] [FLINK-1401] Streaming support added for webclientCloses #334,1
"[FLINK-19317] Update docs for new stream time characteristic defaultI remove most usages where EventTime is set and remove copy that talksabout the default.In general, we should discourage using the stream time characteristic asmuch as possible.",1
[FLINK-27902][network] Introduce canBePipelinedConsumed to replace some previous isPipelined calls that actually judge whether the downstream can consume data when upstream is not finish.,5
KAFKA-654 Irrecoverable error while trying to roll a segment that already exists; patched by Neha Narkhede; reviewed by Jay Krepsgit-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1419627 13f79535-47bb-0310-9956-ffa450edef68,1
修改测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1012 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-9672: Leader with ISR as a superset of replicas (#9631)It is possible for the the controller to send LeaderAndIsr requests withan ISR that contains ids not in the replica set. This is used duringreassignment so that the partition leader doesn't add replicas back tothe ISR. This is needed because the controller updates ZK and thereplicas through two rounds:1. The first round of ZK updates and LeaderAndIsr requests shrinks the ISR.2. The second round of ZK updates and LeaderAndIsr requests shrinks the replicaset.This could be avoided by doing 1. and 2. in one round. Unfortunately thecurrent controller implementation makes that non-trivial.This commit changes the leader to allow the state where the ISR containsids that are not in the replica set and to remove such ids from the ISRif required.Reviewers: Jun Rao <junrao@gmail.com>,1
[FLINK-17543][Azure] Add timestamp to log name to allow multiple uploads per module,1
[FLINK-1478] [jobmanager] Scheduler support for external location constraints,1
fix: disable testcase of ConfigTest#testReferGenericExport (#8580),5
#1067: I18N effort for dubbo code base - dubbo-rpc (part6),5
"KAFKA-8371: Remove dependence on ReplicaManager from Partition (#6705)This patch attempts to simplify the interaction between Partition and the various components from `ReplicaManager`. This is primarily to make unit testing easier. I have also tried to eliminate the OfflinePartition sentinel which has always been unsafe.Reviewers: Boyang Chen <bchen11@outlook.com>, David Arthur <mumrah@gmail.com>",3
[FLINK-11947] Fix exposure leak of NestedSerializerSnapshotsDelegate,0
Minor modification to generation of random filenames,2
"KAFKA-9685: PT2, avoid unnecessary set creation in ACL matching (#8382)#8261 went a long way to solving some of the ACL performance issues. I don't thinkwe need to create sets at all for the `find` and `isEmpty` calls. ` testAuthorizer` is22% to 62% of the cost after this change:```Before:Benchmark                                (aclCount)  (resourceCount)  Mode  Cnt   Score    Error  UnitsAclAuthorizerBenchmark.testAclsIterator           5             5000  avgt   15   0.430 ±  0.004  ms/opAclAuthorizerBenchmark.testAclsIterator           5            10000  avgt   15   0.980 ±  0.007  ms/opAclAuthorizerBenchmark.testAclsIterator           5            50000  avgt   15  11.191 ±  0.032  ms/opAclAuthorizerBenchmark.testAclsIterator          10             5000  avgt   15   0.880 ±  0.007  ms/opAclAuthorizerBenchmark.testAclsIterator          10            10000  avgt   15   2.642 ±  0.029  ms/opAclAuthorizerBenchmark.testAclsIterator          10            50000  avgt   15  26.361 ±  0.242  ms/opAclAuthorizerBenchmark.testAclsIterator          15             5000  avgt   15   1.655 ±  0.024  ms/opAclAuthorizerBenchmark.testAclsIterator          15            10000  avgt   15   5.276 ±  0.041  ms/opAclAuthorizerBenchmark.testAclsIterator          15            50000  avgt   15  40.702 ±  0.574  ms/opAclAuthorizerBenchmark.testAuthorizer             5             5000  avgt   15   0.202 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            10000  avgt   15   0.233 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            50000  avgt   15   0.424 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10             5000  avgt   15   0.202 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            10000  avgt   15   0.253 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            50000  avgt   15   0.423 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15             5000  avgt   15   0.198 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            10000  avgt   15   0.242 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            50000  avgt   15   0.391 ±  0.002  ms/opJMH benchmarks doneAfter:Benchmark                                (aclCount)  (resourceCount)  Mode  Cnt   Score    Error  UnitsAclAuthorizerBenchmark.testAclsIterator           5             5000  avgt   15   0.504 ±  0.164  ms/opAclAuthorizerBenchmark.testAclsIterator           5            10000  avgt   15   1.038 ±  0.271  ms/opAclAuthorizerBenchmark.testAclsIterator           5            50000  avgt   15  11.767 ±  0.028  ms/opAclAuthorizerBenchmark.testAclsIterator          10             5000  avgt   15   0.827 ±  0.016  ms/opAclAuthorizerBenchmark.testAclsIterator          10            10000  avgt   15   2.801 ±  0.027  ms/opAclAuthorizerBenchmark.testAclsIterator          10            50000  avgt   15  26.157 ±  0.191  ms/opAclAuthorizerBenchmark.testAclsIterator          15             5000  avgt   15   1.814 ±  0.053  ms/opAclAuthorizerBenchmark.testAclsIterator          15            10000  avgt   15   5.420 ±  0.065  ms/opAclAuthorizerBenchmark.testAclsIterator          15            50000  avgt   15  41.372 ±  0.659  ms/opAclAuthorizerBenchmark.testAuthorizer             5             5000  avgt   15   0.064 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            10000  avgt   15   0.070 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer             5            50000  avgt   15   0.240 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10             5000  avgt   15   0.055 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            10000  avgt   15   0.084 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            10            50000  avgt   15   0.249 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15             5000  avgt   15   0.057 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            10000  avgt   15   0.084 ±  0.001  ms/opAclAuthorizerBenchmark.testAuthorizer            15            50000  avgt   15   0.243 ±  0.001  ms/op```Reviewers: Ismael Juma <ismael@juma.me.uk>",3
拆分模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@52 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-24121][flink-python] There are spelling mistakes in the notes.This closes #17110,2
"if the registry type is zookeeper, use the address as default configcenter address.",1
[FLINK-7178] [metrics] Do not create separate shaded jarsThis closes #4326.,1
MINOR: More graceful handling of buffers that are too small in Record's `isValid` and `ensureValid`Also add tests and make `Crc32.update` perform the same argument checks as`java.util.zip.CRC32`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Gwen ShapiraCloses #1672 from ijuma/record-is-valid-should-be-more-robust,5
"MINOR: KafkaService should print node hostname on failureAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #3715 from cmccabe/kafka_service_print_node_hostname_on_failure",0
"KAFKA-5218; New Short serializer, deserializer, serdeAuthor: Mario Molina <mmolimar@gmail.com>Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3017 from mmolimar/KAFKA-5218",5
Fix the comment of ServiceInstance (#8674),0
MINOR: stateful docs for aggregatesAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #3730 from enothereska/minor-docs-aggregates,2
"- replaced compiler hint ""Selectivity"" by ""AvgRecordsEmittedPerStubCall""- adapted size estimations to new compiler hint- adapted JSONGenerator to new compiler hint- Adapted examples to new compiler hint",1
"Revert ""KAFKA-5098; ProducerRecord should validate the topic name""We need to verify that this doesn't cause a performance regression,so reverting until that is done.This reverts commit 941e2177c0cf57eff818192258300d256971a11e.",4
[hotfix] HsMemoryDataManager spillAsync's callback should assertNoException.,3
[hotfix][checkpointing] Double check if local state directory exists to avoid problem with concurrent directory creation.,1
- fixed bug in SelfMatchTaskTest- improved SelfMatchTask with value buffer,1
[FLINK-26645][Connector/pulsar] Support subscribe only one topic partition.,1
[FLINK-10845] [table] Support multiple different DISTINCT aggregates for batchThis closes #7079.,1
[FLINK-6695] Activate strict checkstyle for flink-streaming-contribThis closes #4004.,2
[FLINK-20333][python] Fix the issue that metaspace OOM will be thrown after submitting PyFlink UDF jobs multiple times to the standalone clusterThis closes #14205.,2
"[FLINK-5749] [build] Unset HADOOP_HOME and HADOOP_CONF_DIR variables for testsThis unsets the HADOOP_HOME and HADOOP_CONF_DIR envirobment variables for tests, to avoidthat the tests pick those variable up from build servers and produce unexpected testresults.This closes #3288",3
[FLINK-7189] Activate checkstyle flink-java/utilsThis closes #4336.,2
[FLINK-15497][table-planner-blink] Reduce outputs when rank number is not required in Retractable TopN (#10823),1
[FLINK-5496] [mesos] Relocate Mesos Protobuf dependency to avoid version conflictsOnly relocate Mesos Protobuf dependency in flink-mesos. This avoids problems with Mesosbecause Flink pulls in Protobuf 2.5.0 via Flakka.This closes #3156.,2
[hotfix] [build] Include flink-gelly-examples in opt/Adds the flink-gelly-examples jar to the opt/ directory of the binaryrelease artifacts. The examples jar is referenced in the online documentation.Corrects the file paths in the Gelly quickstart documentation.,2
"KAFKA-7097 VerifiableProducer does not work properly with --message-create-time argument (#5292)Currently create time is interpreted as integer.This PR makes the tool accept long values.Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",1
[FLINK-28095][oss] Replace commons-io IOUtils dependency,2
"[FLINK-20468][minicluster] Enable leadership control in MiniCluster to test JM failoverCurrently, there is no easy way to test how JM failover (revoke and grant leadership)affects other features with the MiniCluster and its testing resource rule.The custom HA services can be provided to the TestingMiniCluster but there is no simple HA servicesto support revoking and granting leadership with a valid in-memory checkpoint store.Providing a way to enable such embedded HA services for the MiniCluster out of the box allows to implement IT cases similar to E2E tests.This closes #14301.",3
[FLINK-14907] [filesystems] Add EnvironmentVariableKeyProvider for Azure Blob StorageAlso updates the documentation on credential configuration for ABSThis closes #10376,5
KAFKA-1087 Empty topic list causes consumer to fetch metadata of all topics; reviewed by Guozhang Wang and Neha Narkhede,5
DUBBO-384 ValidationFilter在有@Size标注时出错git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1740 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-14059][core] Introduce option allVerticesInSameSlotSharingGroupByDefault in ExecutionConfig,5
MINOR: regression test for task assignor config (#8743)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>,5
"HOTFIX: undo renaming of public part of Subtopology API (#10713)In #10676 we renamed the internal Subtopology class that implemented the TopologyDescription.Subtopology interface. By mistake, we also renamed the interface itself, which is a public API. This wasn't really the intended point of that PR, so rather than do a retroactive KIP, let's just reverse the renaming.Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[hotfix] [security] Reduce logging verbosity for SSLUtils,2
[FLINK-2288] [runtime] Cleanups and comments for ZooKeeper based initialization,5
[hotfix][tests] Remove redundant setup statement in OperatorCoordinatorSchedulerTestThis is accidental leftover from some refactoring.,4
[hotfix] Fix javadoc reference,2
"MINOR: fix comment in TimingWheel (#11480)Co-authored-by: jiangyuan04 <jiangyuan04@baidu.com>Reviewers: Luke Chen <showuon@gmail.com>, Jun Rao <junrao@gmail.com>",0
[FLINK-14843][e2e] Harden bucketing sink e2e test,3
"MINOR: Cache Node's hashCode to improve the producer's performance  (#4350)`Node` is immutable so this is safe.With 100 brokers, 150 topics and 350 partitions, `HashSet.contains` in `RecordAccumulator.ready` took about 40% of the application time. Itis caused by re-calculating a hash code of a leader (Node instance) forevery batch entry. Caching the hashCode reduced the time of`HashSet.contains` in `RecordAccumulator.ready` to ~2%. Themeasurements were taken with Flight Recorder.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ted Yu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>",5
[FLINK-7876] Properly start and shutdown MetricRegistry by ClusterEntrypointSuppress MetricRegistry#shutdown exceptions if the metric query service actor's actor system has already beenshut down.Address PR commentsPull out TaskManagerMetricGroup instantiation from TaskManagerServices,1
"MINOR: Don't register signal handlers if running on WindowsThe following happens on Windows for `HUP`:[2017-10-11 21:45:11,642] FATAL  (kafka.Kafka$)java.lang.IllegalArgumentException: Unknown signal: HUP        at sun.misc.Signal.<init>(Unknown Source)        at kafka.Kafka$.registerHandler$1(Kafka.scala:67)        at kafka.Kafka$.registerLoggingSignalHandler(Kafka.scala:73)        at kafka.Kafka$.main(Kafka.scala:82)        at kafka.Kafka.main(Kafka.scala)I thought it was safer not to register them at all since the additionallogging is a nice to have and we haven't tested it on Windows.Also changed map to be concurrent and removed strayprintStackTrace in test.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Damian Guy <damian.guy@gmail.com>Closes #4066 from ijuma/dont-register-signal-handler-windows",0
[FLINK-11311][datastream] Fix StreamSource implements StreamOperator interface multiple timesThis closes #7492.,1
[FLINK-7568] Add note about start/end timestamps in window doc,2
[streaming] Test added for iteration sink-source CoLocation + non-chained windowing,1
[FLINK-17339][misc] Update tests due to default planner changing.,4
[FLINK-2996] Introduce configuration parameter for BlobServer portThis closes #1394,2
[FLINK-15107][sql client] Fix sql cli can not execute statement with lower 'inert into'This closes #10469,0
[FLINK-24005][coordination] Only return fulfilled requirements for reserved slots,1
[FLINK-18820] Emit MAX_WATERMARK at the end in SourceOperatorStarting from this commit we emit a MAX_WATERMARK when all records areproduced in SourceOperator or a stop with savepoint was triggered.This closes #13073,1
[hotfix] [streaming] Fix instantiation of state backends from state backend factory.,0
[FLINK-14673][hive] Shouldn't expect HMS client to throw NoSuchObjectException for non-existing functionAlways to check MetaException when getting function with HMS client.This closes #10133.,1
[FLINK-11855] Fix race condition in EmbeddedLeaderService#GrantLeadershipCallFix the race condition between executing EmbeddedLeaderService#GrantLeadershipCalland a concurrent shutdown of the leader service by making GrantLeadershipCall notaccessing mutable state outside of a lock.This closes #7935.,1
[hotfix] Remove unnecessary generics from DispatcherResourceManagerComponent,4
"[FLINK-24409][kafka] Fix collection of KafkaSourceReaderMetrics for topics containing periodsInternally, Kafka translates the periods in topic names to underscore.This led to that Flink could not collect the metrics and logged awarning. With this commit we also translate the topic name before tryingto collect the metrics.",1
HOTFIX: decrease session timeout in flaky NamedTopologyIntegrationTest (#11259)Decrease session timeout back to 10s to improve test flakinessReviewers: Walker Carlson <wcarlson@confluent.io>,5
[FLINK-24875][ci] Move e2e job definition into separate template,5
[hotfix][table-runtime-blink] Query converters for internal data structures,5
"[FLINK-23312][ci] speed up compilation for e2e testsThe ""compile"" builder already applies all checks so we can use -Dfast here;also, the web UI is not actually needed in the E2E tests.",3
[FLINK-22627][runtime] Remove unused slot request protocolThis closes #15899.,1
[FLINK-15803][table] Support DataViews in FLIP-65 aggregate functionsThis enables support for ListView and MapView in FLIP-65 aggregatefunctions. There are two major differences to the previous design:1. We use the internal serialization format for checkpoints/savepointsof data views. Data structure converters are used at the edges whichmeans that we support all data types and conversion classes.2. The data types of data views are expressed in a declarative way. Wedon't instantiate the accumulators anymore. Instead users can useannotations or override getTypeInference.Old aggregate functions are still supported when usingTableEnvironment.registerFunction.This closes #13054.,1
[FLINK-21274] Block main thread when running the TaskManagerRunnerIn order to ensure that the TaskManager properly shuts down we need to letthe main thread block on the execution of the TaskManager. This will ensurethat there is always a non-daemon thread as long as the TaskManager runs.This closes #14906.,1
Fix merge does not work. (#5848)* fix merge does not work,1
[hotfix][table-common] Fix invalid class to data type conversion,5
Rename onReponse in ClusterInterceptor to onMessage (#5528),5
"[3.0] Kubernetes Client dependency upgrade (#7603)* upgrade fabric version, use http protocol in ut instead",1
[FLINK-16418][hive] Hide hive version to avoid user confuse (#11304),5
Merge branch 'warneke_v2' into datamodel,5
[dubbo-1689]: Enhance the test coverage part-10 : dubbo-plugin module (#1949)* reformat the code style*     #1689: Enhance the test coverage part-10 : dubbo-plugin module* fix unit test failure,0
[hotfix] Fix restart strategy class loading by using not lower cased class name,1
[FLINK-14951][tests] Harden the thread safety of State TTL backend tests,3
Fixed Bug in adopted Test Input Formats,3
[streaming] StreamRecord copy updated,5
KAFKA-722 Fix the classpath in kafka-run-class.sh; reviewed by Neha Narkhede,1
"MINOR: fix documentation versionThis will need to be double-committed.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1107 from gwenshap/fix-doc-version",2
[FLINK-12335][table-runtime-blink] Improvement the code and performance of class SegmentsUtilThis closes #8278,1
DUBBO-118 client reconnect 发布过程中reconnect会报太多的错误，导致生产环境报警。git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@528 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Pipeline breakers are placed correctly direct after iterations if needed.,4
Modified recovery logic to also handle node failures,0
"MINOR: Mention that -1 disables retention by time (#4881)Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
[FLINK-26011][sequence-file][test] add ArchUnit tests for the test code,3
[FLINK-26357][avro-parquet] make AvroParquetRecordFormat package private and update javadoc.,2
more cleanup,4
[hotfix][hadoop] Minor code cleanups in HadoopFileStatus,2
[FLINK-4693] [table] Add session group-windows for batch tablesThis closes #3150.,1
"[FLINK-25199][network] Make sure StreamEdges are uniquePreviously, if there was a node that was self-unioned with itself,it was creating a situation with two identical StreamEdges. Bothwith the same partitioning, from the same source node to the sametarget node.This was causing issues when constructing output collectors andpicking the correct RecordWriters, as StreamTask was not able touniquely identify given StreamEdge and was assigning the sameRecordWriter to both of the edges. As a result all stream elementswere sent twice through the same RecordWriter. It was actually prettyharmless apart of calculating the combined watermark downstream,since all watermarks were always comming just from one singleedge/inputgate, and the unused edges were always stuck withmin watermark.As a solution we are making sure that StreamEdges are uniqueby introducing a uniqueId field, incremented for every pairof StreamEdges connecting the same node.",1
[FLINK-23678][kafka] Temporarily ignore KafkaSinkITCase.testWriteRecordsToKafkaWithExactlyOnceGuarantee.,3
[FLINK-12924][table] Add basic type inference logicThis closes #8865.,2
"KAFKA-3627: consumer fails to execute delayed tasks in poll when records are availableAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Liquan Pei <liquanpei@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #1295 from hachikuji/KAFKA-3627",5
Merge branch 'master' of https://stratosphere.eu/stage1 into stagingConflicts:pact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.java,5
[hotfix] Use currentPoolSize in releaseMemory expression instead of numBuffers,1
"[hotfix][build][e2e] Invert Java 11 activation conditionIf we are not running on Java 11, then tests failing on Java 11 should still be run. Conversely, these tests should be excluded on Java 11.",3
"KAFKA-9056; Inbound/outbound byte metrics should reflect incomplete sends/receives (#7551)Currently we only record completed sends and receives in the selector metrics. If there is a disconnect in the middle of the respective operation, then it is not counted. The metrics will be more accurate if we take into account partial sends and receives.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com",5
Fixed builder pattern port,0
"MINOR: Clean up ThreadCacheTest (#6485)Minor clean up ofThreadCacheTestReviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",3
"KAFKA-9083: Various fixes/improvements for Connect's Values class (#7593)Author: Chris Egerton <chrise@confluent.io>Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",5
kafka-1870; Cannot commit with simpleConsumer on Zookeeper only with Java API; patched by Jun Rao; reviewed by Jeol Koshy and Sriharsha Chintalapani,5
[hotfix] Fix failing Table API test and checkstyle violation,3
[FLINK-12747][docs] Getting Started - Table Api Walkthrough,1
[streaming] StreamConfig now uses InstantiationUtils for serialization,1
"[FLINK-12428][docs-zh] Translate the ""Event Time"" page into ChineseThis closes #12442",1
[FLINK-1077] Improved error message if test failsThis closes #120,0
[FLINK-4253] [config] Rename 'recovery.mode' key to 'high-availability',5
KAFKA-5742: support ZK chroot in system testsAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #3677 from xvrl/support-zk-chroot-in-tests,3
[hotfix] Fix typos in MemorySegment java docs,2
[FLINK-13386][web]: Fix operators/tasks metrics sort,1
"[FLINK-21326] Introduce EdgeManager, ConsumerVertexGroup and ConsumedPartitionGroup",2
"KAFKA-14204: QuorumController must correctly handle overly large batches (#12595)Originally, the QuorumController did not try to limit the number of records in a batch that it sentto the Raft layer.  This caused two problems. Firstly, we were not correctly handling the exceptionthat was thrown by the Raft layer when a batch of records was too large to apply atomically. Thishappened because the Raft layer threw an exception which was a subclass of ApiException. Secondly,by letting the Raft layer split non-atomic batches, we were not able to create snapshots at each ofthe splits. This led to O(N) behavior during controller failovers.This PR fixes both of these issues by limiting the number of records in a batch. Atomic batchesthat are too large will fail with a RuntimeException which will cause the active controller tobecome inactive and revert to the last committed state. Non-atomic batches will be split intomultiple batches with a fixed number of records in each.Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",0
[hotfix][tests] replace DiscardingRecycler with FreeingBufferRecycler,3
[FLINK-18699][table-api-scala] Allow selecting fields without string interpolation in ScalaThis closes #12978.,1
Adopted runtime tests and partly runtime classes to new data model,5
"KAFKA-5176; AdminClient: add controller and clusterId methods to DescribeClusterResultsAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: dan norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2977 from cmccabe/KAFKA-5176",5
[FLINK-13017] [docs] Do not mount local $HOME into docs docker environmentThis closes #8917,2
[FLINK-25228][table-test-utils] Introduce flink-table-test-utilsThis closes #18255.,3
[3.0 Triple] Support native stub generator (#9822)Support native stub generator,1
"MINOR: Mark RocksDBStoreTest as integration test (#7412)shouldNotThrowExceptionOnRestoreWhenThereIsPreExistingRocksDbFiles takes1m30s, which is too long for a unit test.`RocksDBTimestampedStoreTest` inherits from `RocksDBStoreTest` and it'simplicitly considered an integration test too.Reviewers: Guozhang Wang <guozhang@confluent.io>",5
[FLINK-7266] [core] Prevent attempt for parent directory deletion for object storesThis closes #4397,4
[FLINK-8668] Document how to set HADOOP_CLASSPATH for Flink,2
[FLINK-7934] [table] Upgrade to Calcite 1.15This closes #5355.,2
Add some unit tests for remoting module (#9043)* Add unit test for remoting module* FIX* Add unit test & fix check style* Update ChannelHandlersTest.java* Update RequestTest.java* Update PortUnificationExchangerTest.java* Update RequestTest.java* Add some unit tests for remoting module* Add license,1
"[FLINK-21246] Fail fast if a failure occurs when triggering a checkpointon a TaskPrior to the change we did not check if the request finished successfully. If it did not, we wereleaving the checkpoint to fail due to a subsequent checkpoint. Since the Tasks can now finish it may be a more common situation that weend up with a failed checkpoint triggering. We should fail thecheckpoint fast if we realize we failed to trigger some tasks.This closes #16493",0
KAFKA-3665: Enable TLS hostname verification by default (KIP-294) (#4956)Make HTTPS the default ssl.endpoint.identification.algorithm.Reviewers: Ismael Juma <ismael@juma.me.uk>,1
[FLINK-6416] Fix divide-by-zero in InputGateMetrics,0
put consumer url into URL attribute,5
[FLINK-20342][docs] Move monitoring/metrics.md to ops/metrics.md,4
"KAFKA-3352: Avoid DNS reverse lookupsBy using `getHostString` (introduced in Java 7) instead of `getHostName`.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson, Grant HenkeCloses #1030 from ijuma/kafka-3352-avoid-dns-reverse-look-ups",1
"[FLINK-26961][connectors][filesystems][formats] Update Jackson Databind and Annotations to 2.13.2.2, Jackson Dataformat to 2.13.2, Jackson Core to 2.13.2 and Jackson-BOM to 2.13.2.20220328. This closes #19303",5
KAFKA-7747; Check for truncation after leader changes [KIP-320] (#6371)After the client detects a leader change we need to check the offset of the current leader for truncation. These changes were part of KIP-320: https://cwiki.apache.org/confluence/display/KAFKA/KIP-320%3A+Allow+fetchers+to+detect+and+handle+log+truncation.Reviewers: Jason Gustafson <jason@confluent.io>,5
[hotfix][metrics][docs] Add type for numLateRecordsDropped metricThis closes #4964.,4
[FLINK-5894] [docs] Fix misleading HA docsThis closes #3401.,2
[hotfix] Simplify AkkaRpcService.connectInternal by relying on Akka APIs,0
[minor] Remove outdated components(.zh).md,5
DUBBO-395 修改SimpleMonitor不能显示数据的问题git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1795 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-3520: Add system tests for REST APIs of list connector plugins and config validationewen granders Ready for review.Author: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1195 from Ishiihara/system-test,5
"Move some SPI extensions to apache/dubbo-spi-extensions, add sub package modules  (#6157)",1
[Dubbo-#2177] Improve and Add Unit Test for org.apache.dubbo.registry.support.AbstractRegistry #2177 Team2 (#2284)* Fix format problem of AbstractRegistryTest* Improve existing tests and add multi thread tests,3
"MINOR: improve security docs for Kafka Streams (#4532)Author: Matthias J. Sax <matthias@confluent.io>Reviewers: Bill Bejeck <bill@confluent.io>, Joel Hamill <joel@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-8290: Close producer for zombie task (#6636)When we close a task and EOS is enabled we should always close the producer regardless if the task is in a zombie state (the broker fenced the producer) or not.I've added tests that fail without this change.Reviewers: Matthias J. Sax <mjsax@apache.org>, Jason Gustafson <jason@confluent.io>",5
optimize collection judgment method in ConfigParser.java (#5584),5
[hotfix] [tests] Make S3 config key forwarding a proper unit testThis avoids unnecessary and expensive connections to S3 just to validate whether configkeys of various formats are forwarded.,5
KAFKA-1997; Follow-up to add the shutdown hook before starting the consumers; reviewed by Guozhang Wang,1
Merge branch 'master' into cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-common/src/main/java/org/apache/dubbo/common/config/configcenter/DynamicConfiguration.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata-report/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata-report/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java,5
[FLINK-11702][table-planner-blink] Introduce a new blink table type system: InternalType.This closes #7817.,5
[FLINK-8216] [kinesis] Unify test utils in flink-connector-kinesisThis closes #5130.,2
"KAFKA-3933; Always fully read deepIteratorAvoids leaking native memory and hence crashing brokers on bootup due torunning out of memory.Seeeing as `messageFormat > 0` always reads the full compressed messageset and is the default going forwards, we can use that behaviour toalways close the compressor when calling `deepIterator`Author: Tom Crayford <tcrayford@googlemail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #1660 from tcrayford/dont_leak_native_memory_round_2",1
HOTFIX: remove unimplemented SPILL_TO_DISK buffer full strategy (#10571)Remove enum for the spill-to-disk strategy since this hasn't been implemented.Reviewers: Walker Carlson <wcarlson@confluent.io>,5
[FLINK-11884][table] Skeleton for transforming operations to RelNodes,2
[FLINK-21815][table-planner-blink] Support json serialization/deserialization for StreamExecUnionThis closes #15233,5
[FLINK-13087][table] Add group window Aggregate operator to Table APIThis closes #8979,1
[FLINK-1803] [streaming] returns(..) method added to Stream operatorsThis closes #556,1
"MINOR: PartitionReassignmentHandler should only generate event when znode is createdWe only need to generate the event when the znode is created or deleted.In the former case, we start the reassignment while in the latter were-register the watcher (necessary for the Controller to detect futurereassignments).During Controller failover, we restart the reassignment without generatingan event so it's not affected by this change.Also use the Controller cache (`ControllerContext.partitionsBeingReassigned`)in `removePartitionFromReassignedPartitions` instead of reloading thedata from ZooKeeper.Overall, we would previously load the reassignment data from ZooKeeper twiceper completed partition whereas now as don't do it at all. As an example,say there were 30k partitions being reassigned, these changes save theallocation of 900 million `TopicAndPartition` and `Seq[Int]` (replicas)instances (could easily amount to 20-40 GB depending on the topic namelength). This matters most in cases where the partitions being reassigneddon't have much data allowing the reassignment to complete reasonablyfast for many of the partitions.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jun Rao <junrao@gmail.com>, Onur Karaman <okaraman@linkedin.com>Closes #4143 from ijuma/partition-reassignment-ignore-handle-deletion-and-data-change",5
[hotfix] Clean up AbstractID and make it immutable.This removes the IOReadableWritable interface from AbstractID which is no longer used with IDs.,1
[FLINK-26849][metrics] Deduplicate metric (un)registration logic,2
[hotfix][runtime] Check managed memory fraction range when setting it into StreamConfig,5
[FLINK_22662][yarn][test] Add logs for YARNHighAvailabilityITCaseThis closes #16197,1
"KAFKA-5876: KIP-216 Part 3, Apply StreamsNotStartedException for Interactive Queries (#10597)KIP-216 Part 3: Throw StreamsNotStartedException if KafkaStreams state is CREATEDReviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",1
[hotfix] [tests] Cleanup and lambda-ify StreamOperatorChainingTest,5
"[FLINK-12964][sql client] add commented-out defaults to sql client yaml file to make it easier for users to adoptThis PR adds commented-out defaults for catalogs to sql client yaml file, to make it easier for users to adopt. This is done similar to how existing defaults of tables and functions is written.This closes #8862.",1
[FLINK-3234] [dataSet] Add KeySelector support to sortPartition operation.This closes #1585,1
[FLINK-25044][pulsar][test]: fix the messsageId overflow when set to latest,3
[FLINK-23813][connectors/jdbc] Update delete executor in TableJdbcUpsertOutputFormat... so that it is properly initializated after reconnection,5
[hotfix][e2e] Add retries for downloading Kafka distribution,1
[FLINK-2981] [docs] update requirements in docs/README* added libraries and versionsThis closes #1335.,1
Fix ReferenceCountManagedChannel#incrementAndGetCount return type (#7838),1
MINOR: Simplify the timeout logic to handle  protocol in Connect distributed system tests (#7806),3
[FLINK-26049][checkpoint] Adding CheckpointStatsTracker logic without pending checkpoint,2
MINOR: Increase zk connection timeout in tests for client created in `KafkaServer`We had already made this change to the client created in `ZooKeeperTestHarness`.I last saw this failure when `SaslPlaintextTopicMetadataTest.testAliveBrokerListWithNoTopics`was executed in Jenkins.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2066 from ijuma/increase-zk-timeout-in-kafka-server,1
make sure compatible Router works fine,1
[FLINK-8317][flip6] Implement savepoints in RestClusterClientAllow triggering of savepoints through RestfulGateway. Implement REST handlersto trigger and query the status of savepoints. Implementsavepoint command in RestClusterClient.[FLINK-8317][flip6] Rename field QueueStatus#statusId to id[FLINK-8317][flip6] Simplify initialization of RpcUtils#INF_TIMEOUT[FLINK-8317][flip6] Add missing fail() to test in SavepointHandlersTest[FLINK-8317][flip6] Add TestLogger to unit tests[FLINK-8317][flip6] Replace anonymous with lambda[FLINK-8317][flip6] Extract string constants to variables in RestClusterClientTest[FLINK-8317][flip6] Move method RestClusterClient#waitForResource[FLINK-8317][flip6] Do not wait if resource is already completed[FLINK-8317][flip6] Only return savepoint location from triggerSavepointOnly return the savepoint's location from RestfulGateway#triggerSavepoint. Fixmistakes in Javadoc. Rename occurrences of checkpoint to savepoint inSavepointHandlers class.[FLINK-8317][flip6] Declare SavepointHandlers#defaultSavepointDir finalThis closes #5223.,0
[FLINK-2909] [gelly] Graph GeneratorsInitial set of scale-free graph generators:- Complete graph- Cycle graph- Empty graph- Grid graph- Hypercube graph- Path graph- RMat graph- Singleton edge graph- Star graphThis closes #1807,1
"MINOR: Fixed introduction doc - wrong streams api linkAuthor: Jakub Dziworski <jakub.dziworski@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>Closes #1996 from JakubDziworski/doc_fix_streams_link",2
[FLINK-2953] fix chaining of sortPartition() calls in Scala DataSet API- Added tests for Scala DataSet sortPartitionThis closes #1317.,5
"MINOR: Insure that KafkaStreams client is closed if test fails (#5618)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roessler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Eno Thereska <enother@amazon.com>",5
KAFKA-12813: Remove deprecated schedule method in ProcessorContext (#10730)Removes methods deprecated via KIP-358.Reviewers: Matthias J. Sax <matthias@confluent.io>,5
Added toString() methods to configuration and task classed to ease debugging.,0
[FLINK-19657][yarn][tests] Whitelist common error in logs,2
[hotfix] [taskmanager] Add chain failure cause to exception when updating task execution state on JobManager,5
kafka-2109; Support retries in KafkaLog4jAppender; patched by Dave Beech; reviewed by Jun Rao,2
[FLINK-23454][runtime] NewBufferSize migrated from long to int for bufferSize because the bufferSize is always int.,1
DUBBO-211 增加Validation扩展点git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1169 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-25817] Let TaskExecutorLocalStateStoresManager only deleted owned local state directoriesThis commit makes sure that the TaskExecutorLocalStateStoresManager only deletes local state directorieson shutdown if they are owned by it. If the local state is stored under the working directory, then it isborrowed and, thus, won't be deleted when the TaskExecutorLocalStateStoresManager shuts down.",3
Deactive sorting tests for data sink,5
"Dubbo cloud native (#4929)* Polish apache/dubbo#4542 : [Enhancement] Adapt the Java standard Event/Listener mechanism* Polish apache/dubbo#4541 : [Feature] Add local File System DynamicConfigurationFactory‘s extension* Polish apache#4541 : Bugfix* Polish apache/dubbo#4541 : Optimization* Polish apache/dubbo#4541 : Add the compatibility for PollingWatchService on the some platforms* Polish apache/dubbo#4541 : Add delay publish without ThreadPoolExecutor* Polish apache/dubbo#4541 : Refactor the extension name* Polish apache/dubbo#4541 : Add remove ops* Polish apache/dubbo#4541 : Add testable constructor* Polish apache/dubbo#4541 : Add getConfigGroups method* Polish apache/dubbo#4610 : [Refactor] Refactor the bootstrap module* Polish apache/dubbo#4541 : Fix the nulling URL issue* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : [Refactor] Refactor ConfigManager* Polish apache/dubbo#4622 : Support multiple configcenters* Polish apache/dubbo#4671 : ServiceNameMapping will not map the group, version and protocol* update referenceCount log (#4683)Add comments to support multiple shared connections* Polish /apache/dubbo#4687 : Remove the duplicated test code in dubbo-config-spring (#4688)* #4685  修改代码if判断false问题 if (hasException == false)修改成if (!hasException) (#4695)* Fixed Service annotation method parameters are not in effect (#4598)* keep demo simple, and switch to use zookeeper as registry center (#4705)* keep demo simple, and switch to use zookeeper as registry center* remove comment* @Reference auto-wires the instance of generic interface #4594 (#4677)* try to shorten maven output to make travis build pass (#4710)* use CountDownLatch to check zk registry if establish connection (#4589)* Minor change* Rename the extension name of WritableMetadataService* Polish apache/dubbo#4759 : [Refactor] Change the signature of methods of MetadataService #4759* Merge remote-tracking branch 'upstream/master' into dubbo-cloud-native# Conflicts:#dubbo-all/pom.xml#dubbo-bom/pom.xml#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractInterfaceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ApplicationConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ConfigCenterConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ReferenceConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/RegistryConfig.java#dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java#dubbo-config/dubbo-config-api/src/test/java/org/apache/dubbo/config/ReferenceConfigTest.java#dubbo-configcenter/dubbo-configcenter-api/src/main/java/org/apache/dubbo/configcenter/DynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-api/src/test/java/org/apache/dubbo/configcenter/mock/MockDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-consul/src/main/java/org/apache/dubbo/configcenter/consul/ConsulDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-etcd/src/test/java/org/apache/dubbo/configcenter/support/etcd/EtcdDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-nacos/src/main/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfiguration.java#dubbo-configcenter/dubbo-configcenter-nacos/src/test/java/org/apache/dubbo/configcenter/support/nacos/NacosDynamicConfigurationTest.java#dubbo-configcenter/dubbo-configcenter-zookeeper/src/main/java/org/apache/dubbo/configcenter/support/zookeeper/ZookeeperDynamicConfiguration.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/definition/model/MethodDefinition.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifier.java#dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java#dubbo-metadata/dubbo-metadata-api/src/test/java/org/apache/dubbo/metadata/report/identifier/MetadataIdentifierTest.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/main/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilder.java#dubbo-metadata/dubbo-metadata-definition-protobuf/src/test/java/org/apache/dubbo/metadata/definition/protobuf/ProtobufTypeBuilderTest.java#dubbo-metadata/pom.xml#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/integration/AbstractConfiguratorListener.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistry.java#dubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/NacosRegistryFactory.java#dubbo-rpc/dubbo-rpc-xml/src/main/java/org/apache/dubbo/xml/rpc/protocol/xmlrpc/XmlRpcProtocol.java* Polish apache/dubbo#3984 : Add the implementation of Page<ServiceInstance> getInstances(String serviceName, int offset, int pageSize, boolean healthyOnly)* Code merge* Fix the cases* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-bootstrap/src/test/java/org/apache/dubbo/bootstrap/DubboServiceProviderBootstrap.java#dubbo-metadata/dubbo-metadata-definition-protobuf/pom.xml#dubbo-registry/dubbo-registry-api/src/test/java/org/apache/dubbo/registry/support/ServiceOrientedRegistryTest.java#dubbo-registry/dubbo-registry-consul/src/main/java/org/apache/dubbo/registry/consul/ConsulServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-etcd3/src/main/java/org/apache/dubbo/registry/etcd/EtcdServiceDiscovery.java* Refactor ConfigManager* Refactor ConfigManager* Resolve the issues on ConfigManager* Refactor and add test-cases for ConfigManager* Polish apache/dubbo#4774 : [Feature] Dubbo Cloud Native - To Support in Spring* Polish apache/dubbo#4808 : [Feature] Add the registered/unregistered event mechanism ShutdownHook* Polish apache/dubbo#4807 : [Feature] Add the callback mechanism ShutdownHook #4807* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4815 : [Feature] Add the ServiceLoader for Dubbo's services or components* Polish apache/dubbo#4813 : [Feature] add Prioritized implementation for ServiceInstanceCustomizer* Polish apache/dubbo#4807 : Add sort implementation* Refactor* Refactor* Polish apache/dubbo#4845 : [Feature] Enhance the Event-Publishing feature to original ServiceDiscovery* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Merge remote-tracking branch 'upstream/cloud-native' into dubbo-cloud-native# Conflicts:#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/DefaultServiceDiscoveryFactory.java#dubbo-registry/dubbo-registry-api/src/main/java/org/apache/dubbo/registry/client/ServiceDiscoveryRegistry.java* Polish apache/dubbo#4854 : [Feature] MetadataService supports the Dubbo protocol under auto-increased port* Polish apache/dubbo#4857 : [Enhancement] Sync the Metadata storage type into ApplicationConfig* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4868 : [Enhancement] Refactor ConfigChangeEvent* Polish apache/dubbo#4873 : [Feature] Add a conditional EventListener into Event Module* Polish apache/dubbo#4875 : [Feature] Refactor ServiceInstancesChangedListener* Remove the cycle dependencies* Remove the cycle dependencies* Polish apache/dubbo#4903 : [Feature] Set source into the BeanDefinition of Dubbo Config* Polish apache/dubbo#4902 : [Feature] Dubbo Cloud Native to Spring XML scenario* Polish apache/dubbo#4713 : Initial the new module and dependencies* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4690 : AnnotatedBeanDefinitionRegistryUtils#registerBeans can't remove the duplicated bean definitions* Polish apache/dubbo#4910 : [Feature] To suppoort DubboLifecycleComponentApplicationListener in Spring XML scenario* Polish apache/dubbo#4713 : Add Service discovery implementation for Eureka #4713* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4713 : Add Service registration and discovery implementation for Eureka* Polish apache/dubbo#4920 : [Refactor] Extract the common implementation for URLs' revision* Refactor* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Polish apache/dubbo#4925 : ServiceDiscovery limits only one ServiceInstancesChangedListener each service* Remove useless classes",1
[FLINK-25528][state-processor-api] state processor api do not support increment checkpointonly support savepoint but support switching savepoint format.,1
MINOR - Increase the number of Trogdor Histogram buckets to 10000 (#8627)Reviewers: Colin P. McCabe <cmccabe@apache.org>,1
"KAFKA-2397: add leave group request to force coordinator trigger rebalanceLet's say every consumer in a group has session timeout s. Currently, if a consumer leaves the group, the worst case time to stabilize the group is 2s (s to detect the consumer failure + s for the rebalance window). If a consumer instead can declare they are leaving the group, the worst case time to stabilize the group would just be the s associated with the rebalance window.This is a low priority optimization!Author: Onur Karaman <okaraman@linkedin.com>Reviewers: Jason Gustafson, Guozhang WangCloses #103 from onurkaraman/leave-group",2
MINOR: remove old producer in config sections to align with APIsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Gwen ShapiraCloses #468 from guozhangwang/WikiUpdate,5
kafka-989; Race condition shutting down high-level consumer results in spinning background thread; patched by Phil Hargett; reviewed by Jun Rao,1
"KAFKA-10705: Make state stores not readable by others (#9583)Change permissions on the folders for the state store so they're no readable or writable by ""others"", but still accessible by owner and group members.Reviewers: Bruno Cadonna <bruno@confluent.io>,  Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
Extended comments in nephele config file.,2
[FLINK-11084][datastream] Forbid using two consecutive split transformationsThis closes #7258,1
[FLINK-12608][runtime] Add getVertexOrThrow and getResultPartitionOrThrow to SchedulingTopologyThis closes #8603.,2
Fixed shutdown problem in job client,0
[Hotfix] Fix typos.,2
[FLINK-13905][checkpointing] Separate checkpoint triggering into severalasynchronous stages.,2
simply telnet command enabled check logic (#3316)* simply telnet command enabled check,0
fix issue-2948:spring boot external config invalid (#2950),5
"MINOR: Missing punctuation marks in quickstart (#5755)Minor fix for missing punctuation marks in the quickstart.Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",5
"Removed static split assignment, prepared code for lazy split assignment",4
"KAFKA-8256; Replace Heartbeat request/response with automated protocol (#6691)Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",5
[3.0-Triple] Support reflection api (#10168)* Add proto* Update compiler* Add v1Alpha for compatibility* Abstract builtin service export* Try add get fd by name* get service by symbol now works* Add type* Support extension* Ignore reflection code scan* Remove v1,4
[hotfix][doc] Document union list metadata gotchaThis closes #11475.,5
[FLINK-15537][table-planner-blink] Fix code generation to use BinaryRow instead of GenericRow for distinct keysCode generation should use BinaryRow instead of GenericRow for distinct keys to have a consistent behavior of equals and hashcode. Because the distinct key will be deseraizlied as BinaryRow from state when job recovery. This closes #10815,1
[FLINK-8565][tests] Ensure locationBytes.length > 0This closes #5417.,3
[refactor] Consolidate code for 'ManuallyTriggeredScheduledExecutor' between test-utils and runtime tests.,3
[FLINK-24583][connectors/elasticsearch] Improve teststability by blocking until all records have been acknowledged by Elasticsearch,3
"KAFKA-6446; KafkaProducer initTransactions() should timeout after max.block.ms (#4563)Currently the `initTransactions()` API blocks indefinitely if the broker cannot be reached. This patch changes the behavior to raise a `TimeoutException` after waiting for `max.block.ms`. Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>",5
[hotfix] Correct the description of security.kerberos.krb5-conf.path,5
"KAFKA-10482: Fix flaky testDynamicListenerConnectionCreationRateQuota (#9301)Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"KAFKA-10021: Changed Kafka backing stores to use shared admin client to get end offsets and create topics (#9780)The existing `Kafka*BackingStore` classes used by Connect all use `KafkaBasedLog`, which needs to frequently get the end offsets for the internal topic to know whether they are caught up. `KafkaBasedLog` uses its consumer to get the end offsets and to consume the records from the topic.However, the Connect internal topics are often written very infrequently. This means that when the `KafkaBasedLog` used in the `Kafka*BackingStore` classes is already caught up and its last consumer poll is waiting for new records to appear, the call to the consumer to fetch end offsets will block until the consumer returns after a new record is written (unlikely) or the consumer’s `fetch.max.wait.ms` setting (defaults to 500ms) ends and the consumer returns no more records. IOW, the call to `KafkaBasedLog.readToEnd()` may block for some period of time even though it’s already caught up to the end.Instead, we want the `KafkaBasedLog.readToEnd()` to always return quickly when the log is already caught up. The best way to do this is to have the `KafkaBackingStore` use the admin client (rather than the consumer) to fetch end offsets for the internal topic. The consumer and the admin API both use the same `ListOffset` broker API, so the functionality is ultimately the same but we don't have to block for any ongoing consumer activity.Each Connect distributed runtime includes three instances of the `Kafka*BackingStore` classes, which means we have three instances of `KafkaBasedLog`. We don't want three instances of the admin client, and should have all three instances of the `KafkaBasedLog` share a single admin client instance. In fact, each `Kafka*BackingStore` instance currently creates, uses and closes an admin client instance when it checks and initializes that store's internal topic. If we change `Kafka*BackingStores` to share one admin client instance, we can change that initialization logic to also reuse the supplied admin client instance.The final challenge is that `KafkaBasedLog` has been used by projects outside of Apache Kafka. While `KafkaBasedLog` is definitely not in the public API for Connect, we can make these changes in ways that are backward compatible: create new constructors and deprecate the old constructors. Connect can be changed to only use the new constructors, and this will give time for any downstream users to make changes.These changes are implemented as follows:1. Add a `KafkaBasedLog` constructor to accept in its parameters a supplier from which it can get an admin instance, and deprecate the old constructor. We need a supplier rather than just passing an instance because `KafkaBasedLog` is instantiated before Connect starts up, so we need to create the admin instance only when needed. At the same time, we'll change the existing init function parameter from a no-arg function to accept an admin instance as an argument, allowing that init function to reuse the shared admin instance used by the `KafkaBasedLog`. Note: if no admin supplier is provided (in deprecated constructor that is no longer used in AK), the consumer is still used to get latest offsets.2. Add to the `Kafka*BackingStore` classes a new constructor with the same parameters but with an admin supplier, and deprecate the old constructor. When the classes instantiate its `KafkaBasedLog` instance, it would pass the admin supplier and pass an init function that takes an admin instance.3. Create a new `SharedTopicAdmin` that lazily creates the `TopicAdmin` (and underlying Admin client) when required, and closes the admin objects when the `SharedTopicAdmin` is closed.4. Modify the existing `TopicAdmin` (used only in Connect) to encapsulate the logic of fetching end offsets using the admin client, simplifying the logic in `KafkaBasedLog` mentioned in #1 above. Doing this also makes it easier to test that logic.5. Change `ConnectDistributed` to create a `SharedTopicAdmin` instance (that is `AutoCloseable`) before creating the `Kafka*BackingStore` instances, passing the `SharedTopicAdmin` (which is an admin supplier) to all three `Kafka*BackingStore objects`, and finally always closing the `SharedTopicAdmin` upon termination. (Shutdown of the worker occurs outside of the `ConnectDistributed` code, so modify `DistributedHerder` to take in its constructor additional `AutoCloseable` objects that should be closed when the herder is closed, and then modify `ConnectDistributed` to pass the `SharedTopicAdmin` as one of those `AutoCloseable` instances.)6. Change `MirrorMaker` similarly to `ConnectDistributed`.7. Change existing unit tests to no longer use deprecated constructors.8. Add unit tests for new functionality.Author: Randall Hauch <rhauch@gmail.com>Reviewer: Konstantine Karantasis <konstantine@confluent.io>",5
fix the bug when use protobuf-json (#4634)Fix #4632,0
kafka-1453 (follow-up); Add a channel queue jmx in Mirror Maker;  patched by Guozhang Wang; reviewed by Jun Rao,1
"MINOR: Preserve the assignment order from the LeaderAndIsr request (#7010)Leaders should make changes to the assignment and the ISR at the same time as part of processing the LeaderAndIsr requests. The leader should also preserve the order of assignment mainly for consistency with the Controller's code and data representation.Reviewers: Vikas Singh, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",5
还原修改： DUBBO-64 去掉commons-dubbo模块中JSON实现，使用FastJsongit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@265 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-14851] Remove getJobSubmissionResult from JobClient,1
"MINOR: Add missing @Test annotation to MetadataTest#testMetadataMerge (#8141)Reviewers: Brian Byrne <bbyrne@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"[FLINK-14464] Introduce the AbstractUserClassPathJobGraphRetrieverThis abstract class is for the JobGraphRetriever, which wants touse the user's classpath.",1
[FLINK-3956] Make FileInputFormats independent from ConfigurationParameters of some input formats that was only possible to beset through the Configuration object now have setter methodsthat allow the user to do so.Values set by the setters cannot be reset by the configurationobject.,5
Distinguish zookeeper module from zookeeper-curator5 (#9528)Use lower version zookeeper and curator dependencies by default.,1
KAFKA-1312: Augment .gitignore. Patch from Timothy Chen.,5
[hotfix][coordination] Refactor Builder for TestingSchedulingExecutionVertex in tests,3
KAFKA-9944: Added supporting customized HTTP response headers for Kafka Connect. (#8620)Added support for customizing the HTTP response headers for Kafka Connect as described in KIP-577.Author: Jeff Huang <jeff.huang@confluent.io>Reviewer: Randall Hauch <rhauch@gmail.com>,5
[FLINK-6562] [table] Support implicit table references for nested fields in SQL.This closes #3879.,1
[FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism.The descriptors will be used during unspilling and in the StreamTaskNetworkInput to create virtual channels.,1
[hotfix][docs] Update docs Readme to mention Hugo extended version.,2
"MINOR: refactor ControllerApis#createTopics (#10465)Refactor ControllerApis#createTopics to be easier to unit test.  Addunit tests for various invalid request and permission denied scenarios.In ControllerApisTest, statically import all the Errors enums.Implement MockController#createTopics.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",1
[FLINK-24706][rpc] Forward deserialization errors to returned future,0
[FLINK-22319][table][sql-client] Support RESET table option for ALTER TABLE statementThis closes #15949,1
MINOR: Remove the extra brackets in the demo code (#9586)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
KAFKA-728 snappy jar missing from path in kafka-run-class.sh patch by John Fung reviewed by Joe Stein,1
[FLINK-23402][streaming-java] Fix minor code issues around 'shuffle mode',0
[FLINK-21177][runtime] Add pending resources to ClusterResourceStatisticsProvider.,1
[hotfix][tests][coordination] Move idle task manager release tests into a separate suite,3
"MINOR: Clarify config names for EOS versions 1 and 2 (#9670)Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
[FLINK-12198][jdbc] Add support for setting auto-commit mode of JDBCInputFormat DB connection.This closes #8186.,5
[FLINK-2200] [build system] Deploy Flink 2.11 with every build (nightly)This closes #885,2
[FLINK-26536][python] Fix RemoteKeyedStateBackend#merge_namespaces to handle properly for the timerserviceThis closes #19008.,0
[hotfix] [tests] Remove leftover sysout logging from AccumulatingAlignedProcessingTimeWindowOperatorTest,3
[hotfix][kubernetes] Correct exception typoThis closes #6677.,2
[FLINK-26543][python] Fix the issue that exceptions generated during startup are lost in Python loopback modeThis closes #19013.,0
"[hotfix][runtime, tests] Fix typos in parameter namesRename parameter of SimpleAckingTaskManagerGateway#setSubmitConsumer() frompredicate to submitConsumer.Rename parameter of SimpleAckingTaskManagerGateway#setCancelConsumer() frompredicate to cancelConsumer.",1
MINOR: Fix missing copyright in config file added in KAFKA-2640.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Guozhang WangCloses #377 from ewencp/minor-jaas-config-copyright,5
remove hard code about port in URLBuilderTest and ProtocolConfigTest (#8252)Co-authored-by: xuhuijing <huijingxu@Ctrip.com>,5
修改README版本git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1996 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Add api version to uncaught exception message (#7311)When we have an unhandled exception in the request handler, we print some details about the request such as the api key and payload. It is also useful to see the version of the request which is not always apparent from the request payload.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
[FLINK-26842][python] Remove scala-bridge dependency,4
"MINOR: Upgrade to Gradle 4.2It includes the usual performance improvements, butthe nicest improvement for me is that the findBugsplugin no longer outputs 10000+ lines inJenkins builds:https://docs.gradle.org/4.2/release-notes.html#findbugs-plugin-does-not-render-analysis-progress-anymoreAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3923 from ijuma/gradle-4.2",5
[FLINK-19539][jmx] Synchronize accesses to port,2
"[FLINK-12187] Bug fixes, Use BufferedWriter in a loop instead of FileWriter",2
[hotfix][metrics] Allow QueryParameter converters to throw ConversionExceptions,2
- fixed CrossTaskExternalITCase to actually go to disk,0
[FLINK-15684][docs] Regenerate documentation,2
"MINOR: factor state checks into descriptive methods and clarify javadocs (#11123)Just a bit of minor cleanup that (a) does some prepwork for another PR I'm working on, (b) updates the javadocs & exception messages to report a more useful error to the user and describe what they actually need to do, and (c) hopefully makes these state checks more future-proof by defining methods for each kind of check in one place that can be easily updated instead of tracking down every individual check.Reviewers: Walker Carlson <wcarlson@confluent.io>, Luke Chen <showuon@gmail.com>",5
"[FLINK-5808] Add proper checks in setParallelism()/setMaxParallelism()Before, there where some checks inStreamExecutionEnvironment.set(Max)Parallelism() but a user wouldcircumvent these if using the ExecutionConfig directly. Now, all checksare moved to the ExecutionConfig.",5
[hotfix][state-backend-rocksdb] Some minor style cleanups in RocksDBResourceContainer  - Make visibility consistent package private (was mix of package private and public)  - remove unused method  - Adjust line spacing between fields  - Add some JavaDocs  - Make final (not designed for inheritance)  - Nullable annotations,1
[FLINK-17012][streaming] Implemented the restore method in StreamTaskfixup,0
"[FLINK-8609] [flip6] Enable Flip-6 job mode in CliFrontendThis commit allows to deploy detached job mode clusters via theCliFrontend. In order to do that, it first extracts the JobGraphfrom the PackagedProgram and then uses the ClusterDescriptor todeploy the job mode cluster.This closes #5432.",1
[FLINK-23567][hive] Fix CNFE when creating hive table with locationThis closes #16665,1
MINOR: remove duplicate code of serializing auto-generated data (#9964)Reviewers: David Jacot <djacot@confluent.io>,5
[FLINK-23534] Fix flink-dstl-dfs version used in changelog statebackend,4
"[Dubbo-5813]prevent destroyAll method of DubboShutdownHook being invoked twice when using Spring (#5814)* fix issue 5813, prevent destroyAll method of DubboShutdownHook being invoke twice when using Spring* fix issue 5813",0
"KAFKA-6648; Fetcher.getTopicMetadata() should return all partitions for each requested topicCurrently Fetcher.getTopicMetadata() will not include offline partitions. ThusKafkaConsumer.partitionsFor(topic) will not return all partitions of a topic ifthere if any partition of the topic is offline. This causes problem if usertries to query the total number of partitions of the given topic.Author: radai-rosenblatt <radai.rosenblatt@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4679 from radai-rosenblatt/partition_shenanigans",5
"KAFKA-10700 - Support mutual TLS authentication for SASL_SSL listeners (KIP-684) (#10007)mTLS is enabled if listener-prefixed ssl.client.auth is configured for SASL_SSL listeners. Broker-wide ssl.client.auth is not applied to SASL_SSL listeners as before, but we now print a warning.Reviewers: David Jacot <djacot@confluent.io>",5
"MINOR: Fix state transition diagram for stream threads (#9153)Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[FLINK-6788] Remove unsused GenericFlatTypePostPass/AbstractSchema classesThis closes #4118.,4
[FLINK-13483] Retry delete when checking path existence in AbstractHadoopFileSystemITTestThis closes #11516.,5
生成类名换成$符git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1511 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"KAFKA-5735; KIP-190: Handle client-ids consistentlyDeveloped with edoardocomarAuthor: Mickael Maison <mickael.maison@gmail.com>Reviewers: Edoardo Comar <ecomar@uk.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3906 from mimaison/KAFKA-5735",5
[FLINK-17988][checkpointing] Discard only unique channel state delegatesThe underlying state handles of channel state handles can be the same.Discard should only iterate over unique underlying handles.,0
[FLINK-19741] Let timer service skip reading raw keyed state if it isn't the writerThis closes #13761.,2
"KAFKA-4761; Fix producer regression handling small or zero batch sizeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>Closes #2545 from hachikuji/KAFKA-4761",5
Implemented execution state update for ReplayTask,5
[FLINK-1925] [runtime] Splits the processing of the SubmitTask message into two phases:  1. TDD reception with eager acknowledgement and  2. TDD instantiation with a subsequent state update message.This closes #622,5
[FLINK-9867] Add release notes file for Flink 1.7,2
"MINOR: Remove Utils.notNull, use Objects.requireNonNull instead (#7194)",1
[FLINK-8744][docs] Add CommonOption annotationThis closes #5843.,1
[FLINK-9464] Remove version and scope from flink-test-utils-junit dependency in flink-statebackend-rocksdb pom.xml,5
"KAFKA-9760: Add KIP-447 protocol change to upgrade notes (#8350)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[hotfix][runtime] Extract SharedStateRegistry interface,1
[FLINK-13024][table] integrate FunctionCatalog with CatalogManagerThis PR integrates FunctionCatalog with Catalog APIs.This closes #8920.,2
[FLINK-24763][fs-connector] LimitableReader should swallow exception when reached limitThis closes #17792,1
[FLINK-18721][yarn] Introduce TestingRegisterApplicationMasterResponse,3
"KAFKA-13710: bring the InvalidTimestampException back for record error (#11853)Reviewers: Guozhang Wang <guozhang@confluent.io>, Ricardo Brasil <anribrasil@gmail.com>",5
Replaced dummy split assignment code with final input split manager,5
[FLINK-24182][task] Unify exception preProcessing logic,2
add checkstyle to project,1
"[FLINK-14291][runtime, tests] Add test coverage to DefaultScheduler- Remove SubmissionTrackingTaskManagerGateway, and introduce  TestExecutionVertexOperationsDecorator to track task deployments.- Introduce DefaultExecutionSlotAllocatorFactory- Introduce TestExecutionSlotAllocatorThis closes #9872.",3
MINOR: add timeouts to streams integration tests (#12216)Reviewers: David Arthur <mumrah@gmail.com>,3
[FLINK-3017] [Docu] Fix broken 'Slots' link on Streaming Guide.This closes #1357,2
[FLINK-12233][hive] Support table related operations in HiveCatalogThis PR introduced HiveCatalogTable and implemented table related catalog APIs in HiveCatalog.This closes #8353.,2
[hotfix][runtime] Add missing '@Override' annotations in Result Partition classes,1
[hotfix] [docs] Fix typo in Elasticsearch example,2
[FLINK-17308] Add regular cleanup task for ExecutionGraphCacheThe WebMonitorEndpoint now schedules are regular cleanup task whichruns every 2 * WebOptions.REFRESH_INTERVAL and tries to clean upexpired ExecutionGraphCache entries. This ensures that we will removeunused entries.This closes #11879.,4
[FLINK-24772][docs] Add documentation for individual window table-valued function (#17885),1
[FLINK-28373][network] Read a full buffer of data per file IO read request for sort-shuffleThis closes #20457.,2
"Merge pull request #1242, remove redundant null check.fixes #1231",0
[hotfix][test] Removes unused jobId parameter,2
MINOR: fix the wrong/missing anchor in docs caused link error (#10413)Reviewers: Matthias J. Sax <matthias@confluent.io>,5
"[FLINK-5046] [tdd] Preserialize TaskDeploymentDescriptor informationIn order to speed up the serialization of the TaskDeploymentDescriptor we can pre serializeall information which stays the same for all TaskDeploymentDescriptors. The information whichis static for a TDD is the job related information contained in the ExecutionGraph and theoperator/task related information stored in the ExecutionJobVertex.In order to pre serialize this information, this PR introduces the JobInformation classand the TaskInformration class which are stored in serialized form in the ExecutionGraphand the ExecutionJobVertex, respectively.This closes #2779.",5
Fix clustermanager test.,3
Merge pull request #576 from qinliujie/masterfix:修复优雅关机的时候，client 关闭的时候没有加超时时间,0
further commenting,5
MINOR: Fix link to old doc in quickstart (#12129)In Kafka's quickstart a link points to the 2.5 Kafka Streams demo.This PR fixes this link.,2
"[FLINK-14872][runtime] Temporary fix for potential deadlock problem when tasks read from blocking ResultPartitions. (#10472)This commit implements a temporary fix for the potential deadlock problem reported in FLINK-14872. The problem itself is not solved completely, however the possibility of deadlock is largely reduced. We leave the proper fix of this problem to the future version.",0
[FLINK-16194][k8s] Introduce Factories that chain the decorators together to construct all the client/cluster-side Kubernetes resources,1
"KAFKA-13914: Add command line tool kafka-metadata-quorum.sh (#12469) Add `MetadataQuorumCommand` to describe quorum status, I'm trying to use arg4j style command format, currently, we only support one sub-command which is ""describe"" and we can specify 2 arguments which are --status and --replication.```# describe quorum statuskafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --replicationReplicaIdLogEndOffsetLagLastFetchTimeMsLastCaughtUpTimeMsStatus  0        10                  0  -1                     -1                                 Leader  1        10                  0  -1                     -1                                 Follower2        10                  0  -1                     -1                                 Followerkafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --statusClusterId:                             fMCL8kv1SWm87L_Md-I2hgLeaderId:                             3002LeaderEpoch:                      2HighWatermark:                  10MaxFollowerLag:                 0MaxFollowerLagTimeMs:   -1CurrentVoters:                    [3000,3001,3002]CurrentObservers:              [0,1,2]# specify AdminClient propertieskafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config config.properties describe --status```Reviewers: Jason Gustafson <jason@confluent.io>",5
[streaming] StringRecord to Record migrate,5
"[core] Use consistent equality check in Value typesThis closes #849, #850.",1
"[FLINK-7728] [DataStream] Make StatusWatermarkValve unit tests more fine-grainedPreviously, the unit tests in StatusWatermarkValveTest were toocluttered and testing too many behaviours in a single test. This makesit hard to have a good overview of what test cases are covered.This commit is a rework of the previous tests, making them morefine-grained so that the scope of each test is small enough. Allpreviously tested behaviours are still covered.",3
[hotfix][tests] Remove TestingMemoryArchivist,3
KAFKA-13669; Demote empty offset commit messages for source tasks to DEBUG level (#11770)Lower the log level of a message in `WorkerSourceTask` which indicates that no messages have been produced by the task since it is spammy and causing users confusion.Reviewers: Jason Gustafson <jason@confluent.io>,5
see last commit,5
Changed Singleton annotation to more flexible DegreeOfParallelism annotation. Avoiding test plan DOP synchronization for explicitly set DOPs.,1
"KAFKA-6650: Allowing transition to OfflineReplica state for replicas without leadership info (#4825)A partially deleted topic can end up with some partitions having no leadership info.For the partially deleted topic, a new controller should be able to finish the topic deletionby transitioning the rogue partition's replicas to OfflineReplica state.This patch adds logic to transition replicas to OfflineReplica state whose partitions haveno leadership info.Added a new test method to cover the partially deleted topic case.Reviewers: Jun Rao <junrao@gmail.com>",4
[hotfix][network] Introduce ResultPartitionFactory,0
"[FLINK-22819][yarn] Remove 'yarn.am.liveness-monitor.expiry-interval-ms' override for tests.This is an interval between AM container allocation and actually running RM Client inside this container,which can take longer in resource limited environment such as CI. If heartbeats between AM and RM don'twork and a test relies on this, then it will fail a bit later because the default value is 5 minutes.This closes #16413.",1
KAFKA-10085: correctly compute lag for optimized source changelogs (#8787)Split out the optimized source changelogs and fetch the committed offsets rather than the end offset for task lag computationReviewers: John Roesler <vvcephei@apache.org>,1
[FLINK-13968][travis] Check correctness of binary licensing,2
[FLINK-15741][docs][TTL] Fix TTL docs after enabling RocksDB compaction filter by default,5
Bump up version to 1.1.0-SNAPSHOT,5
- fixed pact-test/pom.xml- removed unused imports in contract tests- updated TestBase.java,3
KAFKA-9663: Update JavaDocs to indicate `null` return values in KafkaStreams (#8228)Reviewer: Matthias J. Sax <matthias@confluent.io>,5
MINOR: Change topic-exists log for CreateTopics from INFO to DEBUG (#7666)Reviewers: Ismael Juma <ismael@juma.me.uk>,0
修改注释git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@134 1a56cb94-b969-4eaa-88fa-be21384802f2,1
DUBBO-365 加强Validation测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1735 1a56cb94-b969-4eaa-88fa-be21384802f2,1
Rebuild web-dashboard,5
[FLINK-3748] [table] Add CASE function to Table APIThis closes #1893.,1
KAFKA-8150: Fix bugs in handling null arrays in generated RPC code (#6489)ToString functions must not get a NullPointException.  read() functionsmust properly translate a negative array length to a null field.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,1
[FLINK-7137] [table] Rework nullability handling,1
[FLINK-1716] [ml] Adds CoCoA algorithm[ml] Adds web documentation and code comments to CoCoA[ml] Adds commentsThis closes #545.,1
[FLINK-24980] Introduce numBytesProduced counter into ResultPartition to record the size of result partition.This closes #17905.,2
"MINOR: clean up window store interface to avoid confusion (#5359)Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",5
add unit test,3
[FLINK-15198][Config][Mesos] Remove deprecated option 'mesos.resourcemanager.tasks.mem'The option was deprecated in 1.10 in favour of `taskmanager.memory.process.size`.This closes #10890.,4
"KAFKA-1432 Make num.producerThreads configurable on new MirrrorMaker; reviewed by Neha Narkhede, Jun Rao",1
"[FLINK-18377] Rename ""Flink Master"" back to JobManager in documentation",2
[hotfix] [REST] Extend empty request/parameters support[hotfix] [REST] Fix error message if empty request does not conform to RequestBody spec[hotfix] [REST] Add special handling for plain-text responsesThis closes #4730.,1
MINOR: Remove unnecessary assertion from ConnectHeader (#9452)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,3
[FLINK-2288] [docs] Add docs for HA/ZooKeeper setupThis closes #886,1
"[FLINK-1297] add accumulator called OperatorStatsAccumulator..capable of tracking min, max and estimates for count distinct andheavy hitters.The count distinct algorithms are Linear Counting and HyperLogLog, bothfrom an imported library from clearspring.The heavy hitters algorithms are Lossy counting (Manku et.al 2002) andone based on Count Min Sketch (Cormode 2005).The heavy hitters algorithms are implemented in the statistics packagein the flink-operator-stats submodule of flink-contrib.Include tests verifying if merged skecthes have the same guarantees aslocal sketches.Added conditional to every collect variable, to make stats moreconfigurable. Made print operator stats more informative. Addedarguments to yarn pom to enable buildingImplemented deep cloning for class OperatorStatistics. Added additionaltests in OperatorStatsAccumulatorTest to check if the accumulator workswhen only one statistic is being tracked, rather than all.This closes #605.",1
Adapted interesting properties generation for UnionNode,5
[hotfix] Make field JobMaster#resourceManagerLeaderRetriever final,1
[FLINK-18997][python] Rename parameter name type_info to result_type for DataStream.flat_map(),5
[hotfix][table-planner-blink] Use PEEK_FIELDS_NO_EXPAND semantics for structured types,1
KAFKA-3019: Add an exceptionName method to ErrorsAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #754 from granthenke/exception-name,5
"[streaming] Added CoBatchReduceInvokable, CoWindowReduceInvokable, CoGroupedBatchReduceInvokable, CoGroupedWindowReduceInvokable",5
KAFKA-10712; Update release scripts to Python3 (#11538)Reviewers: Mickael Maison <mickael.maison@gmail.com>,5
[FLINK-26166][runtime-web] Add auto newline detection to prettier formatter,1
override url in directory,5
"Union implementation for new java api, with simple UnionIT testcase",3
[FLINK-9355][checkpointing] Simplify configuration of local recovery to a simple on/off switchThis closes #6006.,5
[hotfix] Create JarUtils with common jar file tools,2
[FLINK-3241] Fix Scala 2.11 build by moving some flink-table classes into the right directory,2
KAFKA-925 Add a partition key that overrides the message's stored key. Patch reviewed by Joel.,1
Introduced new checkpoint state undecided,1
[hotfix] Fix raw types warning.,2
trivial fix for stylecheck error on Jenkins,0
Ignore version 1.0.0 (#9674),5
Removed unfinished checkpointing features for OS release,5
"KAFKA-4516: When a CachingStateStore is closed it should clear its associated NamedCacheClear and remove the NamedCache from the ThreadCache when a CachingKeyValueStore or CachingWindowStore is closed.Validate that the store is open when doing any queries or writes to Caching State Stores.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #2235 from dguy/kafka-4516",5
Ran a clean-up on sopremo-sdaa11.,4
[FLINK-8977] [e2e] Allow configuring restart strategy for general purpose DataStream job,5
[FLINK-24418][table-planner] Add support for casting RAW to BINARYImplement casting from generic RAW type into BINARY/VARBINARY/BYTESThis closes #17450.,3
Fix NPE when parse migration rule error happen (#8280),0
生成类名换成$符git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1510 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-10596][cep] Introduced PatternProcessFunction,1
"[FLINK-13226][connector/kafka] Fix deadlock between producer closure and transaction commit in the universal Kafka connector.This patch fixes a race condition between the checkpointing thread and main thread.The sequence causing the deadlock is the following:    1. In FlinkKafkaProducer, the main thread encounters a problem and closes all the producer       to start failover.    2. The previous checkpoint has completed, so the checkpointing thread grabs the checkpoint       lock and tries to commit the transaction on the producer that has been closed in step 1.       This commit will never succeed due to KAFKA-6635. So the checkpoint thread blocks forever.    3. In StreamTask, the main thread will eventually try to release all the record writer.       To do that, it attempts to grab the checkpoint lock which is hold by checkpoint thread in       step 2 and will never be released. So the main thread also blocks forever.KAFKA-6635 has been fixed in Kafka 2.3.0. But Flink 1.9 does not rely on that yet, So we are justgoing to fix on the Flink side first. The solution is to make sure that in FlinkKafkaProducer anyoperation relying on the underlying sender thread to finish throws an exception if the produceris closed.",5
"KAFKA-8730; Add API to delete consumer offsets (KIP-496) (#7276)This adds an administrative API to delete consumer offsets of a group as well as extends the mechanism to expire offsets of consumer groups.It makes the group coordinator aware of the set of topics a consumer group (protocol type == 'consumer') is actively subscribed to, allowing offsets of topics which are not actively subscribed to by the group to be either expired or administratively deleted. The expiration rules remain the same.For the other groups (non-consumer), the API allows to delete offsets when the group is empty and the expiration remains the same.Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",5
"KAFKA-10332: Update MM2 refreshTopicPartitions() logic (#9343)Trigger task reconfiguration when:- topic-partitions are created or deleted on source cluster- topic-partitions are missing on target clusterAuthors: Mickael Maison <mickael.maison@gmail.com>, Edoardo Comar <ecomar@uk.ibm.com>Reviewer: Randall Hauch <rhauch@gmail.com>",1
Fixes startup problem with bash 4.1 in cluster mode,0
[hotfix][table-runtime] Fix ArrayDataSerializer null fields writingSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
remove chinese comments,4
[FLINK-13287][table-planner] Support STREAM_RECORD_TIMESTAMP call in table planner,1
[FLINK-11011][E2E][JM] Log error messages about null CheckpointCoordinator only if job is running (#7216),1
"MINOR: Send kraft raft/controller logs to controller log in systests (#12222)Currently the only place we see controller/raft logging in system tests is `server-start-stdout-stderr.log` where they are mixed with all other logs. It is more convenient to send them to `controller.log` as we do for zk tests.Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, David Jacot <djacot@confluent.io>",5
[FLINK-28932][Table/SQL] Remove use of deprecated method,1
[FLINK-10094][tests] Always backup config before running test,3
[FLINK-18018][dist] Bundle GPU plugin in plugins/ directory,2
[FLINK-7522] Add termination future to ClusterEntrypointThe termination future is completed when the ClusterEntrypoint shuts down. Thisallows for easier testing.This closes #4589.,3
"KAFKA-8557: system tests - add support for (optional) interbroker listener with the same security protocol as client listeners (#6938)Reviewers: Brian Bushree <bbushree@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",5
"[FLINK-21085] Allows taking snapshot with closed operators if enabled checkpoints after tasks finishedSince the StreamTask would waiting till the downstream tasks have finishedprocessing all the pending records, during this period the checkpointhas to be taken with closed operators. In the future PR we woulddeal with this case by also reporting the status of operator finished.In this PR we would first not decline checkpoint in this scenarioso that we could add tests.",3
[FLINK-8084][build] Remove unnecessary japicmp pom entriesThis closes #5020.,4
"[FLINK-17514] Fail fatally if the TaskCancelerWatchDog encounters exception in run methodIf the TaskCancelerWatchDog encounters an exception in the run method, then we can no longerguarantee that it will do its job. Hence, it is best to fail fatally by letting the exceptionbubble up so that it is handled by the uncaught exception handler.",0
"Refactored PactModule, added SopremoModule and shared base class",1
"KAFKA-4553; Improve round robin assignment in Connect to avoid uneven distributions of connectors and tasksAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>Closes #2272 from ewencp/kafka-4553-better-connect-round-robin",1
"[hotfix] Clean up structure and comments in 'FileSystem'This commit aims to improve the readability of the FileSystem class.The commit does not introduce new/different code, but introduces sections in the class, moves nestedclasses and methods between these sections.The commit also improves comments for the class and nested classes.",1
Make sure instance and meta registered to remote when interface delay publish enabled. (#6868),0
Merge branch major changes from warneke into memmanager branchConflicts:pact/pact-runtime/src/test/java/eu/stratosphere/pact/runtime/task/util/OutputEmitterTest.java,5
"KAFKA-8992; Redefine RemoveMembersFromGroup interface on AdminClient  (#7478)This PR fixes the inconsistency involved in the `removeMembersFromGroup` admin API calls:1. Fail the `all()` request when there is sub level error (either partition or member)2. Change getMembers() to members()3. Hide the actual Errors from user4. Do not expose generated MemberIdentity type5. Use more consistent naming for Options and Result typesReviewers: Guozhang Wang <wangguoz@gmail.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",5
Made ExecutionExceptionHandler in TestPlans static to make the code more robust against resource leakage,1
"KAFKA-13167; KRaft broker should send heartbeat immediately after starting controlled shutdown (#11177)Controlled shutdown in KRaft is signaled through a heartbeat request with the `shouldShutDown` flag set to true. When we begin controlled shutdown, we should immediately schedule the next heartbeat instead of waiting for the next periodic heartbeat. This allows the broker to shutdown more quickly.Reviewers: Colin P. McCabe <cmccabe@apache.org>",1
remove useless if check of max value of Integer (#4886),1
[FLINK-24397][connectors/hbase] Remove TableSchema usage from Hbase table connector,4
[FLINK-27140][coordination] Write job result in ioExecutor,2
[FLINK-22988][tests] Port TestingUtils to java,3
"KAFKA-5522; ListOffsets should bound timestamp search by LSO in read_committedAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #3456 from hachikuji/KAFKA-5522",5
"KAFKA-2140 follow up, checking in newly renamed file ConsumerRebalanceFailedException",0
Finished implementation of channel throughput measurements,5
[hotfix] Remove obsolete .gitattributes fileThis contained entries about bat scripts and vendored files from the old web UI.Both are not part of Flink any more.,2
MINOR: Fix red herring when ConnectDistributedTest.test_bounce fails. (#6838)Author: Alex Diachenko <sansanichfb@gmail.com>Reviewer: Randall Hauch <rhauch@gmail.com>,0
[FLINK-12592][python] Add `--force` for python install.This closes #8525,1
"MINOR: gradle wrapper should handle directories with spacesIf attempting to build the project from a directory with spaces in its name and gradle-wrapper.jar is missing, the script will fail to download a new one because the ""if"" condition will break because $APP_HOME will resolve to multiple strings. Protecting $APP_HOME with quotes fixes the issue. Tested by deleting gradle.wrapper and trying to build.Author: Gwen Shapira <cshapi@gmail.com>Reviewers: Chia-Ping TsaiCloses #9813 from gwenshap/fix_gradlew",0
更新版本为 2.5.0-SNAPSHOT,5
[3.0] Fix flaky tests caused by java getDeclaredAnnotations() (#9240)* Fixed 2 flaky tests* Fixing flaky tests using hashmapCo-authored-by: Yu <gey2@fa21-cs527-042.cs.illinois.edu>,1
[FLINK-4660] Allow CoProcessFunction on non-keyed ConnectedStreamsIntroduce new CoProcessOperator for this. Rename the pre-existingCoProcessOperator to KeyedCoProcessOperator.,1
[FLINK-22889][tests] Log InnoDB details in JdbcExactlyOnceSinkE2eTest to ease debugging,0
[FLINK-4741] Proper shutdown the ServerBootstrap WebRuntimeMonitorThis closes #2862.,1
"MINOR: Fix incorrect pattern matching on `version` in `CheckpointFile`Also add test and refactor things a little to make testing easier.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>Closes #2822 from ijuma/hotfix-checkpoint-file",2
[FLINK-26929][table-runtime] Introduce adaptive hash join strategy for batch hash join (#20365),2
KAFKA-13637: Use default.api.timeout.ms as default timeout value for KafkaConsumer.endOffsets (#11726)We introduced `default.api.timeout.ms` in https://github.com/apache/kafka/commit/53ca52f855e903907378188d29224b3f9cefa6cb but we missed updating `KafkaConsumer.endOffsets` which still use `request.timeout.ms`. This patch fixes this.Reviewers: David Jacot <djacot@confluent.io>,5
enhance comments (#2735),5
[FLINK-11843] Forward shut down future from Dispatcher through to the DispatcherRunnerImplNG,1
[Flink-21910][resourcemanager] fix the check that whether JobLeaderIdService has been statedThis closes #15228.,0
Removed working directory for queue manager's test configuration,5
[hotfix][state] Add error message to precondition in HeapPriorityQueueSet,1
[FLINK-25385][table-planner] Regenerate plansThis closes #18858.,2
refactor the interface and import jaket source,2
DUBBO-176在反序列化void方法返回值时时不要传入void.classgit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@829 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Log exception thrown by consumer.poll() in VerifiableConsumer (#6368)SecurityTest.test_client_ssl_endpoint_validation_failure is failing because it greps for 'SSLHandshakeException in the consumer and producer log files. With the fix for KAKFA-7773, the test uses the VerifiableConsumer instead of the ConsoleConsumer, which does not log the exception stack trace to the service log. This patch catches exceptions in the VerifiableConsumer and logs them in order to fix the test. Tested by running the test locally.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
[FLINK-23001][build] Re-enable Scala suffix check for avro-glue-registry moduleThis closes #16247,1
[FLINK-1455] [runtime] Improve robustness of external sorting test errors,0
Hash Join bucket array structure,5
[FLINK-671] Python API,2
"KAFKA-12459; Use property testing library for raft event simulation tests (#10323)This patch changes the raft simulation tests to use jqwik, which is a property testing library. This provides two main benefits:- It simplifies the randomization of test parameters. Currently the tests use a fixed set of `Random` seeds, which means that most builds are doing redundant work. We get a bigger benefit from allowing each build to test different parameterizations.- It makes it easier to reproduce failures. Whenever a test fails, jqwik will report the random seed that failed. A developer can then modify the `@Property` annotation to use that specific seed in order to reproduce the failure.This patch also includes an optimization for `MockLog.earliestSnapshotId` which reduces the time to run the simulation tests dramatically.Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, David Jacot <djacot@confluent.io>",5
"KIP-476: Add new getAdmin method to KafkaClientSupplier (#7162)Reviewers: Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[doc] [hotfix] Fix Gelly readCsvFile example,2
Add go implementation link.,2
[FLINK-18721][yarn] Introduce TaskExecutorProcessSpecContainerResourceAdapter,2
KAFKA-12321 the comparison function for uuid type should be 'equals' rather than '==' (#10098)Reviewers: Ismael Juma <ismael@juma.me.uk>,1
"[FLINK-3761] Refactor State Backends/Make Keyed State Key-Group AwareThe biggest change in this is that functionality that used to be inAbstractStateBackend is now moved to CheckpointStreamFactory andKeyedStateBackend. The former is responsible for providing streams thatcan be used to checkpoint data while the latter is responsible forkeeping keyed state. A keyed backend can checkpoint the state that itkeeps by using a CheckpointStreamFactory.This also refactors how asynchronous keyed state snapshots work. Theyare not implemented using a Future/RunnableFuture.Also, this changes the keyed state backends to be key-group aware and tosnapshot the state in key-groups with an index for restoring.",4
修改版本为2.0.9git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@650 1a56cb94-b969-4eaa-88fa-be21384802f2,1
add serviceStoreService test and modify the code,3
[hotfix][docs] fix typo in SQL functionsThis closes #16390,1
Added missing files,2
[FLINK-20456][docs] Simplify streaming joins,2
[hotfix][travis] Fix directory references,0
"[hotfix][task] Throw MailboxClosedException if TaskMailbox is closing instead of IllegalStateExceptionThis will allow to handle this particular exception, instead of catching IllegalStateException",0
[hotifx] Remove unused constructor of StreamingJobGraphGenerator,1
"[hotfix][runtime] Fix backwards compatibility of NettyShuffleEnvironmentOptions#NETWORK_NUM_BUFFERS.The legacy NettyShuffleEnvironmentOptions#NETWORK_NUM_BUFFERS should be used to decide shuffle memory size, when:- NettyShuffleEnvironmentOptions#NETWORK_NUM_BUFFERS is explicitly configured, and- None of TaskManagerOptions#SHUFFLE_MEMORY_MIN/MAX/FRACTION is configured.This was not respected when deriving internal memory sizes from total flink memory size in TaskExecutorResourceUtils.",2
"[hotfix][coordination] Wire ZooKeeperJobGraphStore to the new interfaceWe introduce three specific composition implementations for ZooKeeper, ZooKeeperJobGraphStoreWatcher, ZooKeeperJobGraphStoreEventHandler, ZooKeeperJobGraphStoreUtil.* ZooKeeperJobGraphStoreWatcher is a watcher on JobGraphStore. It could monitor all the changes on the job graph store and notify the DefaultJobGraphStore via JobGraphStore.JobGraphListener.* ZooKeeperJobGraphStoreUtil is a utility class which could convert a ZooKeeper path to JobId, or vice versa.",4
"[FLINK-4184] [metrics] Replace invalid characters in ScheduledDropwizardReporterThe GraphiteReporter and GangliaReporter report metric names which can contain invalidcharacters. These characters include quotes and dots. In order to properly report metricsto these systems, the afore-mentioned characters have to be replaced in metric names.The PR also removes quotes from the garbage collector metric name.The PR sets the default value for TTL in the GangliaReporter to 1, because -1 causes thereporter to fail.Introduce CharacterFilter to filter invalid characters from the metric name outThe character filter is applied to all components of the fully qualified metric name.The ScheduledDropwizardReporter and AbstractReporter implement this interface to generatecompatible metric names.Correct AbstractMetricGroup.getMetricIdentifier; Add test cases to check that reporters filter out invalid charactersThis closes #2220.",3
"MINOR: Fix potential resource leak in FileOffsetBackingStore (#4739)Reviewers: Sandor Murakozi <smurakozi@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix] Remove dead code in TypeExtractor,4
[hotfix][doc]Fixed the problem that the Windows document Window Assigners and Window Functions of the master branch could not jump correctly.,1
去掉compatible的filtergit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@529 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-15754][docs] Remove config options table.exec.resource.*memory from docs,2
DUBBO-430 dubbo的注解扫描和现有框架冲突git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1965 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"MINOR: Allow creation of statestore without logging enabled or explicit source topicguozhangwangAuthor: dan norwood <norwood@confluent.io>Reviewers: Eno Thereska, Damian Guy, Guozhang WangCloses #1828 from norwood/manual-store",5
[streaming] flatmaptest refactored,4
[hotfix][build] Remove unused flink-test-utils dependencies,3
"DUBBO-244 支持Spring的p:foo=""bar""自定义参数git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1124 1a56cb94-b969-4eaa-88fa-be21384802f2",1
Transformed JobManagerTest into an integration test,3
[FLINK-26444][python] Align the WindowAssigners with the Java DataStream APIThis closes #18957.,5
MINOR: Factor `RaftManager` out of `TestRaftServer` (#9839)This patch factors out a `RaftManager` class from `TestRaftServer` which will be needed when we integrate this layer into the server. This class encapsulates the logic to build `KafkaRaftClient` as well as its IO thread. Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,2
"KAFKA-4372: Kafka Connect REST API does not handle DELETE of connector with slashes in their namesKafka Connect REST API does not handle in many places connectors with slashes in their names because it expects PathParams, this PR intends to :* Reject as bad requests API calls trying to create connectors with slashes in their names* Add support for connector with slashes in their names in the DELETE part of the API to allow users to cleanup their connectors without dropping everything.This PR adds as well the Unit Test needed for the creation part and was tested manually for the DELETE part.Author: Olivier Girardot <o.girardot@lateral-thoughts.com>Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #2096 from ogirardot/fix/connectors-with-slashes-cannot-be-deleted",4
Move PageRankITCase to proper package,4
"KAFKA-13273: Add support for Java 17 (#11296)Java 17 is at release candidate stage and it will be a LTS release onceit's out (previous LTS release was Java 11).Details:* Replace Java 16 with Java 17 in Jenkins and Readme.* Replace `--illegal-access=permit` (which was removed from Java 17)   with  `--add-opens` for the packages we require internal access to.   Filed KAFKA-13275 for updating the tests not to require `--add-opens`   (where possible).* Update `release.py` to use JDK8. and JDK 17 (instead of JDK 8 and JDK 15).* Removed all but one Streams test from `testsToExclude`. The   Connect test exclusion list remains the same.* Add notable change to upgrade.html* Upgrade to Gradle 7.2 as it's required for proper Java 17 support.* Upgrade mockito to 3.12.4 for better Java 17 support.* Adjusted `KafkaRaftClientTest` and `QuorumStateTest` not to require   private access to `jdk.internal.util.random`.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",1
[FLINK-1501] Add metrics library for monitoring TaskManagersThis closes #421,1
Implemented UTF8 string encoding/decoding,5
调整DataSource缺省实现，保证线程可见性 DUBBO-122 Provider的线程池监控支持,1
[hotfix][security] Remove never thrown exception in method signature,4
HOTFIX: Fix optional import in ConsumerCoordinator (#6953)This was caused by back-to-back merging of #6854 (which removed the Optional import) and #6936 (which needed the import).Reviewers: Jason Gustafson <jason@confluent.io>,5
[streaming] partitioner performance improvements,1
[FLINK-2040] [runtime] Tolerate out-of-order CANCELING and CANCELED messages.,1
KAFKA-9704: Fix the issue z/OS won't let us resize file when mmap. (#8224)Reviewers: Mickael Maison <mickael.maison@gmail.com>,2
[FLINK-19554][connector/testing-framework] Basic abstractions of connector testing framework,1
[hotfix][core] Fix typos in ReadableConfig,5
[FLINK-3402] Refactor Common Parts of Stream/Batch Documentation,2
[FLINK-14135][orc] Introduce OrcColumnarRowSplitReader to orc,2
[hotfix][table-planner] Add ExpressionCodeGeneratorCastRule extracting generateExpression from AbstractExpressionCodeGeneratorCastRuleSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
MINOR: Update Scala to 2.13.6 (#10711)This includes TASTy Reader support for Scala 3.0.0. This makes it easierfor Kafka libraries to be used in Scala 3.0 projectsRelease notes: https://github.com/scala/scala/releases/tag/v2.13.6Reviewers: Ismael Juma <ismael@juma.me.uk>,1
[FLINK-18545][table] Specify job name by `pipeline.name` for sql job,2
Fixed cancellation of pacts in testing framework,1
[FLINK-19625][table-planner] Introduce multi-input exec node (#13671),2
[FLINK-8961][tests] Port JobRetrievalITCase to flip6This closes #5730.,3
[docs] Minor addition to the cluster execution docs.This closes #1018,2
"[FLINK-6801] [core] Allow deserialized PojoSerializer to have removed fieldsPrior to this commit, deserializing the PojoSerializer would fail whenwe encounter a missing field that existed in the POJO type before. It isactually perfectly fine to have a missing field; the deserializedPojoSerializer should simply skip reading the removed field's previouslyserialized values, i.e. much like how Java Object Serialization works.This commit relaxes the deserialization of the PojoSerializer, so that anull will be used as a placeholder value to indicate a removed fieldthat previously existed. De-/serialization and copying methods on thePojoSerializer will respect null Fields and simply skip them.",4
"MINOR: Add Streams system test for broker backwards compatibilityAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2403 from mjsax/addStreamsClientCompatibilityTest",3
"KAFKA-10634; Adding LeaderId to voters list in LeaderChangeMessage along with granting voters (#9539)This patch ensures that the leader is included among the voters in the `LeaderChangeMessage`. It also adds an additional field for the set of granting voters, which was originally specified in KIP-595.Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
"MINOR: Java 9/10 fixes, gradle and minor deps update (#4725)* Added dependencies so that Trogdor and Connect work with Java 9 and 10* Updated Jacoco to 0.8.1 so that it works with Java 10* Updated Gradle to 4.6* A few minor version bumps (not related to Java9/10 fixes)I tested manually that we can run ./gradlew test with Java 10after these changes. There are test failures as EasyMockand PowerMock will have to be updated to use a newerASM version. But compiling successfully and most testspassing is progress. :)I also tested manually that Trogdor can be started with Java 10.It previously failed with a ClassNotFoundError.Reviewers: Jason Gustafson <jason@confluent.io>",5
如果没有配置Cache File跳过Save操作git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1625 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-17002] Disallow CREATE TABLE ... LIKE in legacy plannerThis closes #11981,1
"[FLINK-3713] [clients, runtime] Use user code class loader when disposing savepointDisposing savepoints via the JobManager fails for state handles or descriptors,which contain user classes (for example custom folding state or RocksDB handles).With this change, the user can provide the job JAR when disposing a savepoint inorder to use the user code class loader of that job. The JAR is optional, hencenot breaking the CLI API.This closes #2083.",4
"KAFKA-8461: Wait for follower to join the ISR in testUncleanLeaderElectionDisabled TestAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>Closes #6887 from omkreddy/unclean-leader",4
Separate Streams documentation and setup docs with easy to set variables- Seperate Streams documentation out to a standalone page.- Setup templates to use handlebars.js- Create template variables to swap in frequently updated values like version number from a single file templateData.jsAuthor: Derrick Or <derrickor@gmail.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2245 from derrickdoo/docTemplates,2
[FLINK-3666] Remove all remaining Nephele references,5
[hotfix][table-planner] add test cases for AND and OR,3
[FLINK-5890] [gelly] GatherSumApply broken when object reuse enabledGatherSumApplyIteration uses reduce and join for which extra care mustbe taken when object reuse is enabled. Adds a check for objects returnedby the user to prevent system objects from being overwritten.This closes #3402,5
KAFKA-9457; Fix flaky test org.apache.kafka.common.network.SelectorTest.testGracefulClose (#7989)Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,3
"[FLINK-20310][doc] Add documentation for Debezium, Canal, Raw support for Filesystem connectorThis closes #14191",5
[FLINK-21377][coordination][tests] Refactor JobMasterQueryableStateTest,3
MINOR: Fixed undefined method `update_guest'Author: Piotr Szwed <pszwed@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #802 from szwed/trunk,1
"[FLINK-14282] Simplify DispatcherResourceManagerComponent hierarchyRemove unnecessary subclasses of AbstractDispatcherResourceManagerComponentand rename this class into DefaultDispatcherResourceManagerComponent. Moreover,this commit removes the unnecessary generics from the DispatcherRunnerFactoryto further simplify the code base.This closes #9809.",1
[FLINK-11463][tests] Always run in a fresh copy of the distribution,1
"KAFKA-13542: Add rebalance reason in Kafka Streams (#12018)Reviewers: Bruno Cadonna <bruno@confluent.io>, David Jacot <djacot@confluent.io>",5
[FLINK-11545] [container] Add docs for job-id argument,2
[FLINK-28315][runtime-web] introduce aggregate stats in tables of the subtasks and taskmanagersThis closes #20260,2
KAFKA-483 Improvements to the system testing framework; patched by John Fung; reviewed by Neha Narkhedegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1379232 13f79535-47bb-0310-9956-ffa450edef68,1
"KAFKA-4123: Queryable State returning null for key before all stores in instance have been initializedMark the store as open after the DB has been restored from the changelog.Only add the store to the map in ProcessorStateManager post restore.Make RocksDBWindowStore.Segment override openDB(..) as it needs to mark the Segment as open.Throw InvalidStateStoreException if any stores in a KafkaStreams instance are not available.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Eno Thereska, Guozhang WangCloses #1824 from dguy/kafka-4123",3
[FLINK-20793][core] Fix the NamesTest and JarSubmissionITCase due to code style refactorThis closes #14514.,4
Improved efficiency of AbstractID class,1
"MINOR: Update zstd, easymock, powermock, zkclient and build plugins (#5846)EasyMock 4.0.x includes a change that relies on the caller for inferringthe return type of mock creator methods. Updated a number of Scalatests for compilation and execution to succeed.The versions of EasyMock and PowerMock in this PR include full supportfor Java 11.Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",1
[FLINK-6847] [FLINK-6813] [table] Add support for TIMESTAMPDIFF in Table API & SQLThis closes #6282.,1
[streaming] Deleted obsolete parts of the connected stream api,4
"KAFKA-9701 (fix): Only check protocol name when generation is valid (#8324)This bug was incurred by #7994 with a too-strong consistency check. It is because a reset generation operation could be called in between the joinGroupRequest -> joinGroupResponse -> SyncGroupRequest -> SyncGroupResponse sequence of events, if user calls unsubscribe in the middle of consumer#poll().Proper fix is to avoid the protocol name check when the generation is invalid.Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-12584; Remove deprecated `Sum` and `Total` classes (#10511)`Sum` and `Total` classes were deprecated and replaced by `WindowedSum` and `CumulativeSum` in 2.4. This patch removes them for 3.0.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",4
KAFKA-928 new topics may not be processed after ZK session expiration in controller; reviewed by Jun Rao,1
[FLINK-11770] Update FlinkKinesisConsumerMigrationTest for 1.8,3
[FLINK-26532][metrics][test] using the numRecordsSend counter to get the correct metric,1
修改注册中心URL添加应用名信息git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@577 1a56cb94-b969-4eaa-88fa-be21384802f2,1
rename log file from alibaba to custom-access (#2057),2
"MINOR: Cleanup threads in integration tests (#5269)Leftover threads doing network I/O can interfere with subsequent tests. Add missing shutdown in tests and include admin client in the check for leftover threads.Reviewers: Anna Povzner <anna@confluent.io>, Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy O <manikumar.reddy@gmail.com>",5
"MINOR: improve logging of tasks on shutdown (#7597)Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
"[FLINK-6365] [kinesis] Adapt default values of the Kinesis connectorThe previous GET_SHARDS_MAX and GET_SHARDS_INTERVAL_MILLIS did not workwell with AWS's service limitations, leading to poor Kinesis connectorperformace if used directly out-of-the-box. This commit adapats them tofollow the default values used by the AWS SDK.This closes #4375.",1
"KAFKA-10000: Add all public-facing config properties (#11775)Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Andrew Eugene Choi <andrew.choi@uwaterloo.ca>",5
[hotfix][docs] Fix missing double quotes in catalog docscloses #11008,2
[FLINK-13323][table-runtime-blink] Add tests for complex data formats,5
Warning to indicate that in-place-sorter is not spilling ready.,2
"[FLINK-4851] [rm] Introduce FatalErrorHandler and MetricRegistry to RMThis PR introduces a FatalErrorHandler and the MetricRegistry to the RM. The FatalErrorHandler is used to handle fatal errors. Additionally, the PR adds the MetricRegistry to the RM which can be usedto register metrics.Apart from these changes the PR restructures the code of the RM a little bit and fixes someblocking operations.The PR also moves the TestingFatalErrorHandler into the util package of flink-runtime test. Thatit is usable across multiple tests.Introduce ResourceManagerRunner to handle errors in the ResourceManagerThis closes #2655.",0
[FLINK-5811] [tests] Harden YarnClusterDescriptorTestAdd fail call after method which is supposed to fail. Remove stack trace printingto stdout.This closes #3326.,4
[FLINK-10569][runtime] Remove Instance usage in ExecutionVertexCancelTest,3
"[FLINK-14859][runtime] Remove wrong checkStateA slot that is assigned to an execution may be unreleased even if a deploymentis outdated. However, this is safe, because the execution is responsible forreleasing the slot.This closes #10351.",1
Fixed logging in avro tets case,2
More modifications to RPC protocols,5
[FLINK-22014][ha] Make sure that AbstractHaServices delete first the HA data before deleting blobs on closeAndCleanupAllDataThe AbstractHaServices should always first delete the HA data (pointers to jobs and checkpoints) before deleting the referencedobjects such as blobs. That way we ensure that we don't leave the system in an invalid state if the process stops abruptly becauseeither all the data is still available or the pointers have been cleared and Flink only leaves some orphaned blobs. The casewhere the pointers are still there but not the blobs will no longer be possible with this fix.This closes #15468.,0
[FLINK-16966][metrics][infuxdb] Add InfluxDBReporterFactory,5
[FLINK-14821][tests] Enable E2E test to pass with new DefaultSchedulerEnable test_queryable_state_restart_tm ('Queryable state (rocksdb) with TMrestart') to pass with new DefaultScheduler.This closes #10226.,1
[FLINK-20272][table-runtime-blink] Fix wrong result for TopN when removing records out of TopNThis closes #14173,4
[FLINK-23097][tests] Harden test_queryable_state_restart_tm.shThis commit hardens the test_queryable_state_restart_tm.sh e2e test by only writing thecount value of state entries on notifyCheckpointComplete. Before we have written out uncommittedinformation out that led to test failures.This closes #16910.,0
[FLINK-2991] Adjust RocksDB Folding State to latest RocksDBStateBackend,5
[FLINK-7249] [build] Bump java.version property to 1.8This closes #4398.,5
[hotfix] [core] Fix typo in variable nameThis closes #3002,2
Added convenience class to check a set of task class properties,1
MINOR: KStream JavaDoc fixAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2284 from mjsax/javaDoc,2
[FLINK-8475][config][docs] Integrate HeartbeatManager optionsThis closes #5507.,5
"[FLINK-1201] [gelly] Reverted to using Tuples, added tests.",3
Add unit test for VirtualServiceRule (#8428)* Add unit test for VirtualServiceRule* FIX UT,0
[hotfix][tests] Make SchedulerTestingUtils constructor private,3
[FLINK-2277] [scala api] Add flag to set delta iteration solution set to unmanagedThis closes #1005,1
[hotfix][tests] Use TestUtils#copyDirectory,3
"MINOR: Make LogCleaner.shouldRetainRecord more readable (#6590)Reviewers: Bob Barrett <bob.barrett@outlook.com>, Jason Gustafson <jason@confluent.io>",5
[yarn] fix debug string displayed for failed applicationsThis closes #2745.,0
[FLINK-12075] Update flink-conf.yaml to not specify rest.port per defaultThis commits updates the flink-conf.yaml to contain the new rest options and commentsout the rest.port per default.,1
Fix destroy notify order (#8873),0
[hotfix][Javadoc] Fix typo in ConversionException,2
"KAFKA-6739; Ignore headers when down-converting from V2 to V0/V1 (#4813)Ignore headers when down-converting to V0/V1 since they are not supported. Added a test-case to verify down-conversion sanity in presence of headers.Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",5
replace Random with ThreadLocalRandom (#2433),5
refactor publish-interface key,4
Fixed project path,0
Merge branch 'datamodel' into staging_datamodel,5
[FLINK-22236][docs] Document opt-in behavior of FlameGraph[review] add @alpinegizmo suggestionsCo-authored-by: David Anderson <david@alpinegizmo.com>linktmptmp,2
[FLINK-15457][yarn] Remove outdated TODOThe referenced config option no longer exists.,5
spi配置多个tag解析错误问题 (#4346)fixes #4344,0
KAFKA-533 changes to NOTICE and LICENSE related to KAFKA-534 removing client libraries from repogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1390788 13f79535-47bb-0310-9956-ffa450edef68,1
KAFKA-1634; Bump up Offset Commit Request to v2 to add global retention and remove per-partition commit timestamp; reviewed by Joel Koshy and Jun Rao,4
[FLINK-11067][table-common] port AmbiguousTableFactoryException and NoMatchingTableFactoryException from api-java to table-common,2
[FLINK-12227][runtime] Add interfaces for SchedulingTopologyThe SchedulingTopology contains the information which is provided to theSchedulingStrategy in order to decide which execution vertices should bescheduled next.,1
[FLINK-5980] [core] Expose max-parallelism value in RuntimeContext.This closes #3487,1
[hotfix][table-common] Add utility method for checking if a type is a composite type,1
[FLINK-4232] Make sure ./bin/flink returns correct pidThis closes #2268,2
[FLINK-25659][table-planner] Enable flaky LogicalRelDataTypeConverterTest with debug information,5
"[FLINK-5763][state backends] (follow-up) Rework MetaData Serializers and externalPointer passingThis fix has several goals:(1) Change the pointer / path resolution parsing from a static variable to a parameter that is passed.The serializers are singleton instances and currently assume to be usable in a multi-threaded manner.The static variables prevent this, usng the context object parameter restores this behavior.(2) Lower level serialization methods should not expose themselves directly to the tests.This methods makes (almost) all lower level serialization methods instance methods and package-private.Static access methods are gathered in one place, as a workaround for tests that require accesd tothose lower level methods (even through they should not).(3) With more unified access to the methods from tests, we can now make prevent that tests need tobe aware of the the context object or external pointer parameter.(4) Minor cosmetic cleanups around method grouping.",4
[FLINK-17577][table-common] SinkFormat#createSinkFormat should use DynamicTableSink.Context as parameterThis closes #12039,2
[FLINK-17428][table-planner-blink] supports projection push down on the new DynamicTableSourceThis closes #12145,1
[FLINK-25548][table] Migrate sq-parser tests to JUnit5,3
[FLINK-12709][runtime] Add NoRestartBackoffTimeStrategy which suppresses all task restarts,1
"Minor: Fixed ConsumerOffset#path (#5060)consumer offset path in zookeeper should be /consumers/${group}/offsets/${topic}/${partition} instead of /consumers/${group}/offset/${topic}/${partition}. Added `s` to the word `offset`.Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>",1
[3.0] Refactor MetricsConfig (#8785)* refactor metrics config and add empty prometheus implementation* Fix attribute name,0
fix compilation issue cause of merge conflict,5
[FLINK-23498][table] Introduce a full planner configurationThis is an MVP version of a layered configuration of Executor and Table API.This closes #16626.,5
"[FLINK-13517][docs][hive] Restructure Hive Catalog documentationHive documentation is currently spread across a number of pages and fragmented. In particular:- An example was added to getting-started/examples, however, this section is being removed- There is a dedicated page on hive integration but also a lot of hive specific information is on the catalog pageThis closes #9308.",1
KAFKA-1943; MessageSizeTooLarge and MessageSetSizeTooLarge should not be counted toward broker-side producer failure rate,0
[FLINK-14260] Port DispatcherResourceCleanupTest to use TestingJobManagerRunnerFactoryNG,3
"[hotfix][checkpointing] Convert some CheckpointStatsTracker state to argumentsThis is a preparatory step for FLINK-19462.CheckpointStatsTracker is created with a fixed set of vertices.At time of checkpoint creation this set can be different.As checkpoint already carries the vertices there is no need to storethem as state.Besides that, changing the type from List<ExecutionJobVertex>to Map<JobVertexID, Integer> simplifies writing the tests.",3
Moved compilation logic from pact program to client.,2
"[FLINK-24977][connectors/kafka] Replace ConfigOption lookup in Map<String, String> object with proper lookup in Configuration object",5
MINOR: Make release notes script check resolutions to avoid spurious inclusion of non-fix 'fixes' in release notes.Author: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2174 from ewencp/release-notes-resolution-filters,0
bugfix: ReferenceConfig 潜在的并发问题(#594)修复可能潜在的并发创建 client 的问题,1
Added simple and sopremo packages,1
"KAFKA-4259; Dynamic JAAS configuration for Kafka clients (KIP-85)Implementation of KIP-85: https://cwiki.apache.org/confluence/display/KAFKA/KIP-85%3A+Dynamic+JAAS+configuration+for+Kafka+clientsAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1979 from rajinisivaram/KAFKA-4259",5
"[FLINK-23259][docs] Fix the link for page ""docs/dev/datastream/operators/overview"" (#16381)",5
[FLINK-20492][runtime] SourceOperator.dispose() should close the source reader.,1
fix problem when creating router chain for StaticDirectory (consume multi groups),1
[hotfix][network] Incomplete cleanup of buffer pools does no longer leak other resources.,4
[FLINK-9892][tests] Disable local recovery in Jepsen tests.This closes #6369.,3
MINOR: Changed visibility of methods in ClusterConnectionStates to privateThe methods resetReconnectBackoff and updateReconnectBackoff in ClusterConnectionStates both take an instance of a private inner class as parameter and thus cannot be called from outside the class anyway.Author: Soenke Liebau <soenke.liebau@opencore.com>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #4114 from soenkeliebau/MINOR_private,2
[FLINK-16316][operators] Implement new AbstractStreamOperatorV2 as a replacement for AbstractStreamOperatorThe new base class for operators tries to address couple of limitations in the AbstractStreamOperator like:- lack of support for multiple inputs- setup(...) method,1
"KAFKA-8747; Add atomic counter to fix flaky testEventQueueTime test (#7320)This patch adds an atomic counter in the test to ensure we have processed all the events before we assert the metrics. There was a race condition with the previous assertion, which asserted that the event queue is empty before checking the metrics.Reviewers: Jason Gustafson <jason@confluent.io>",5
[FLINK-13818][web] Check whether web submission are enabled,0
[FLINK-7939] [table] Fix Table conversion of DataStream of AtomicType.This closes #4917.,5
MINOR: reduce amount of verbose printingAuthor: Eno Thereska <eno@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #2764 from enothereska/minor-remove-verboseprint,4
[FLINK-18420][tests] Disable failed test SQLClientHBaseITCase in java 11This closes #12760,3
[FLINK-24433][Tests][Buildsystem] Remove additional pre-installed packages to clean up more diskspace before starting the E2E tests. Also removing the line that removes `^ghc-8.*` since that doesn't exist anymore on the machines.,4
[FLINK-10987] Add LICENSE & NOTICE files for flink-shaded-hadoop2-uber,2
KAFKA-10893 Increase target_messages_per_sec of ReplicaScaleTest to reduce the run time (#9797)Reviewers: David Arthur <mumrah@gmail.com>,1
修改monitor配置加载buggit-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@245 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-3445: Validate TASKS_MAX_CONFIG's lower boundCurrently the property TASKS_MAX_CONFIG is not validated against nonsensical values such as 0. This patch leverages the Range.atLeast() method to ensure value is at least 1.Author: Ryan P <Ryan.N.Pridgeon@Gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1132 from rnpridgeon/KAFKA-3445,5
[FLINK-10149][mesos] Simplify assertions in LaunchableMesosWorkerTestUse Set equality to simplify test assertions.Change type of field LaunchableMesosWorker#TM_PORT_KEYS to Set<String>.,1
Added compiler test for kmeans single step.Various examples cleaned up.,4
"KAFKA-10199: Bookkeep tasks during assignment for use with state updater (#12442)Bookkeeps tasks to be recycled, closed, and updated during handling of the assignment. The bookkeeping is needed for integrating the state updater.These change is hidden behind internal config STATE_UPDATER_ENABLED. If the config is false Streams should not use the state updater and behave as usual.Reviewers: Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-14024: Consumer keeps Commit offset in onJoinPrepare in Cooperative rebalance (#12349)In KAFKA-13310, we tried to fix a issue that consumer#poll(duration) will be returned after the provided duration. It's because if rebalance needed, we'll try to commit current offset first before rebalance synchronously. And if the offset committing takes too long, the consumer#poll will spend more time than provided duration. To fix that, we change commit sync with commit async before rebalance (i.e. onPrepareJoin).However, in this ticket, we found the async commit will keep sending a new commit request during each Consumer#poll, because the offset commit never completes in time. The impact is that the existing consumer will be kicked out of the group after rebalance timeout without joining the group. That is, suppose we have consumer A in group G, and now consumer B joined the group, after the rebalance, only consumer B in the group.Besides, there's also another bug found during fixing this bug. Before KAFKA-13310, we commitOffset sync with rebalanceTimeout, which will retry when retriable error until timeout. After KAFKA-13310, we thought we have retry, but we'll retry after partitions revoking. That is, even though the retried offset commit successfully, it still causes some partitions offsets un-committed, and after rebalance, other consumers will consume overlapping records.Reviewers: RivenSun <riven.sun@zoom.us>, Luke Chen <showuon@gmail.com>",1
ConsumerOffsetChecker now works with hostnames (in addition to IP) in the brokers/ids zk path; KAFKA-549; patched by Bob Cotton; reviewed by Joel Koshygit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1395809 13f79535-47bb-0310-9956-ffa450edef68,1
[hotfix][checkpoint] Adding testlogger to all checkpoint tests.,3
修改injvm测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@187 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-19739][table-runtime] Fix compile exception for window aggregate in batch jobsThis closes #16591,0
Fixed GovWild use case,1
Implemented and tested intra source RL,3
MINOR: Fix typo in processor api developer guide (#12203)The reference to `changlogConfig` should be `changelogConfig`.Reviewers: Jason Gustafson <jason@confluent.io>,5
"KAFKA-1854 Allow JIRA username and password to be prompted in the absence of a jira.ini file, during patch submission; reviewed by Neha Narkhede",2
[hotfix] [core] Fix TypeSerializerUtils#snapshotBackwardsCompatible method signature,0
Fix race condition in ExecutionGraph which made the job finish before all vertices have called the finalizeOnMaster method.,5
[FLINK-11201] Update release notes to contain changes for SBT projectsSBT projects which use the MiniClusterResource now have to explicitly add a test-jardependency on flink-runtime. The reason for this is that we moved the MiniClusterResourceto flink-runtime and sbt does not properly pull in transitive test-jar dependencies.,3
[3.0] Remove parse placeholder in beanName logic (#8368),2
"MINOR: Disable Travis PR builds (#10038)Kafka is consuming over 50% of all our Travis executors according to Apache Infra, so let's disable it for now.Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",5
[FLINK-15174][security] Added certificate pinning for SSL mutual authThis helps to make sure only a single certificate can be used when certificates are issued by public CA.,0
"[FLINK-21996][refactor] Unify exception handling for Operator Coordinator Events sent to not-running tasksSending an event to a not-running task sometimes throws an exception directly from the method (if the event is immediately sent)and sometimes completes the resulting future with an exception (for example if the event had to be enqueued until after checkpointbarrier injection to preserve exactly-once sematics).This changes the code to always report those exceptions through the result future and never through direct exception throwing,to simplify and unify the way this can be handled by the calling code.",0
[FLINK-17594][filesystem] Support Hadoop path-based part-file writerThis closes #12224,2
KAFKA-651 Add system tests for auto create topic; reviewed by Neha Narkhede,1
"KAFKA-7980 - Fix timing issue in SocketServerTest.testConnectionRateLimit (#6391)Test currently checks that there were at least 5 polls when 5 connections are established with connectionQueueSize=1. But we could be doing the check just after the 5th connection before the 5th poll, so updated the check to verify that there were at least 4 polls.Reviewers: Ismael Juma <ismael@juma.me.uk>",5
[FLINK-11485] [core] Refactor multiple nested serializer compatibility resolution logic to CompositeTypeSerializerUtilThis commit refactors the logic of resolving overall compatibilityresults across multiple nested serializers of a composite serializer outof the CompositeTypeSerializerSnapshot class.This allows us to reuse this functionality when implementing thecompatibility check for the PojoSerializerSnapshot,1
[hotfix][docs] Specify that json format works for append only streamsSigned-off-by: slinkydeveloper <francescoguard@gmail.com>,2
[hotfix] [docs] Fix link to docker-compose.ymlThis closes #3887,5
"KAFKA-12211: don't change perm for base/state dir when no persistent store (#9904) If a user doesn't have Persistent Stores, we won't create base dir and state dir and should not try to set permissions on them.Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",5
[FLINK-16164][build] Disable maven-site-plugin,2
KAFKA-7730; Limit number of active connections per listener in brokers (KIP-402)Adds a new listener config `max.connections` to limit the number of active connections on each listener. The config may be prefixed with listener prefix. This limit may be dynamically reconfigured without restarting the broker.This is one of the PRs for KIP-402 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-402%3A+Improve+fairness+in+SocketServer+processors). Note that this is currently built on top of PR #6022Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Gwen Shapira <cshapi@gmail.com>Closes #6034 from rajinisivaram/KAFKA-7730-max-connections,5
KAFKA-9355: Fix bug that removed RocksDB metrics after failure in EOS (#7996)* Added init() method to RocksDBMetricsRecorder* Added call to init() of RocksDBMetricsRecorder to init() of RocksDB store* Added call to init() of RocksDBMetricsRecorder to openExisting() of segmented state stores* Adapted unit tests* Added integration test that reproduces the situation in which the bug occurredReviewers: Guozhang Wang <wangguoz@gmail.com>,0
Merge pull request #779 from chickenlj:xml_config Adjust some config properties,5
添加replaceExtension方法 DUBBO-512 ExtensionLoader支持编程方式添加扩展,5
[FLINK-20905][K8s] Format the description of 'kubernetes.container.image' optionThis closes #14597,2
[FLINK-3136] Fix shaded imports in ClosureCleaner.scala,4
[hotfix] Fix flink-sql-parquet NOTICE fileRemove unused dependency org.apache.commons:commons-compress:1.20 from NOTICE fileThis closes #12811.,2
"[FLINK-26403][datastream] Fixes the endOfInput logic of sink writer and committer.SinkWriterOperator should emit all the pending committables on endOfInput,and CommitterOperator should commit all committables when the final checkpointis completed or on endOfInput if there's no final checkpoint.This closes #18938.",1
"[FLINK-17794][tests] Tear down installed software in reverse orderTear down installed software in reverse order in Jepsen tests. Thismitigates the issue that sometimes YARN's NodeManager directories cannotbe removed using 'rm -rf' because Flink processes keep running andgenerate files after the YARN NodeManager is shut down. rm -r removesfiles recursively but if files are created in the backgroundconcurrently, the command can still fail with a non-zero exit code.This closes #12249.",0
manual merge for SpillingResettableIteratorTest,3
[FLINK-14117][docs-zh] Translate changes on index page to Chinese (#9815),4
"MINOR: refactored code duplicates in several files (Streams project) (#4357)* Removed code duplicate from GlobalProcessorContextImpl and ProcessorContextImpl to parent class AbstractProcessorContext* Exchanged concrete implementations with interfaces to make code more maintainable* Refactored major code duplicates in InternalTopologyBuilder* Formatted function parameters as per code reviewAdded final to code introduced in this PR* Added missing finals to putNodeGroupName functionRearranged parameters for resetTopicsPattern functionReviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",1
[hotfix][tests] Harden tests using CommonTestUtils.waitUntilConditionIncrease the retry interval for TaskExecutorITCase and ZooKeeperLeaderElectionITCasesince they take so long that the low retry interval won't have a big effect apartfrom a higher CPU load.,1
[build] merge transitive notice files to shaded noticesThis closes #837.,2
[hotfix][network] Move queuedBuffered and currentBuffered fields to BufferStorageThis makes BufferStorage contract more complete. Now it takes care of the whole processof storing and returning the data with simpler interface (single #rollOver methodvs two different as it was before).,5
"MINOR: Start Connect REST server in standalone mode to match distributed mode (KAFKA-7503 follow-up)Start the Rest server in the standalone mode similar to how it's done for distributed mode.Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>Reviewers: Arjun Satish <arjun@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #6148 from mageshn/KAFKA-7826",5
[hotfix][streaming] Update new calculated buffer size value only if the announcement doesn't fail,0
use revision in pom.xml (#3980),5
"[hotfix][table-runtime Improve performance of UpdatableRowDataUse a `BitSet` instead of `boolean[]` to use less memory and speed upresetting all fields to ""not-updated"" when setting a new delegate row.",1
"[FLINK-2272] [ml] Removed roadmap and vision from docs, added link to them in the wiki.This closes #864.",2
[hotfix][e2e] Refactor yarn kerberos test: use retry_times to start hadoop cluster,1
Added key columns for new datamodel contracts.,5
"[FLINK-3500] [test] Fix possible instability in ExecutionGraphRestartTestAfter restart of the execution graph, the test driver waits for thegraph to assign the new executions in a loop. If switchToRunning()is called multiple times in this loop, the job is canceled. Thiscould happen, if one execution had its resource assigned and calledswitchToRunning(), but the other didn't. In this case, the completeloop was retried and switchToRunning() was called again.This closes #1708.",1
"[FLINK-10174] [table] Define UTF-8 charset for HEX, TO_BASE64, FROM_BASE64This closes #6579.",1
[FLINK-25995][table-planner] Make implicit assumption of SQL local hash explicitThis closes #18707,1
"[FLINK-17783][orc] Add array,map,row types support for orc row writerThis closes #15746",1
"[FLINK-6180] [rpc] Remove TestingSerialRpcServiceThe TestingSerialRpcService produces thread interleavings which are not happeningwhen being executed with a proper RpcService implementation. Due to this the testcases can fail or succeed wrongly. In order to avoid this problem, this commitremoves the TestingSerialRpcService and adapts all existing tests which used itbefore.Remove TestingSerialRpcService from MesosResourceManagerTestRemove TestingSerialRpcService from ResourceManagerJobMasterTestRemove TestingSerialRpcService from ResourceManagerTaskExecutorTestRemove TestingSerialRpcService from ResourceManagerTestRemove SerialTestingRpcService from JobMasterTestRemove TestingSerialRpcService from TaskExecutorITCaseRemove TestingSerialRpcService from TaskExecutorTestRemove TestingSerialRpcService from SlotPoolTestDelete TestingSerialRpcServiceThis closes #4516.",3
[FLINK-13994][docs-zh] Translate 'Getting Started' overview page into Chinese (#9649),1
[FLINK-3467] [runtime] Remove superfluous objects from DataSourceTask.invokeThis closes #1691,5
MINOR: Fix typos in code commentsThis patch fixes all occurances of two consecutive 'the's in the code comments.Author: Ishita Mandhan (imandhaus.ibm.com)Author: Ishita Mandhan <imandha@us.ibm.com>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1240 from imandhan/typofixes,2
[FLINK-15523][conf] Revert removal of Public fields,4
"KAFKA-13388; Kafka Producer nodes stuck in CHECKING_API_VERSIONS (#11671)At the moment, the `NetworkClient` will remain stuck in the `CHECKING_API_VERSIONS` state forever if the `Channel` does not become ready. To prevent this from happening, this patch changes the logic to transition to the `CHECKING_API_VERSIONS` only when the `ApiVersionsRequest` is queued to be sent out. With this, the connection will timeout if the `Channel` does not become ready within the connection setup timeout. Once the `ApiVersionsRequest` is queued up, the request timeout takes over.Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",5
[FLINK-25848][connectors/kinesis] KDS Sink failing fast when bad credentials are provided.,1
[FLINK-14594][runtime] Change ResourceProfile to use CPUResource for cpu cores,1
KAFKA-2579; prevent unauthorized clients from joining groupsAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Gwen ShapiraCloses #240 from hachikuji/KAFKA-2579,5
DUBBO-253 添加单元测试，测试系统属性覆盖 dubbo.properties 的配置git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1222 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-11436] [avro] Manually Java-deserialize AvroSerializer for backwards compatibilityDuring the release of Flink 1.7, the value of serialVersionUID was uptick to 2L (was 1L before)And although the AvroSerializer (along with it's snapshot class) were migrated to the new serializationabstraction (hence free from Java serialization), there were composite serializers that were not migratedand were serialized with Java serialization.This commit manually Java-Deserializes the AvroSerializer to support backwards compatability.This closes #7580.",1
[FLINK-6439] Fix close OutputStream && InputStream in OperatorSnapshotUtilThis closes #3904.,1
Added taggable record type,1
[FLINK-7309] [table] Fix NullPointerException when selecting null fields.This closes #4479.,0
[FLINK-1451] [streaming] Parallel file source fix + minor windowing fix,0
[FLINK-25454][runtime] Pause and resume time for throughput calculator only from one thread.,1
[hotfix] Add missing import,2
"MINOR: Update Streams docs: quickstart and conceptsAdded figures for topology and table-stream duality; added sections about aggregations; misc code fixes.Author: Guozhang Wang <wangguoz@gmail.com>Reviewers: Damian Guy, Sriram SubramanianCloses #2482 from guozhangwang/KMinor-streams-docs-first-pass",4
[release] Upgrade current version to 1.15 for StatefulJobSavepointMigrationITCase and create snapshots,1
[FLINK-11334] Allow setting a compatibility matcher in TypeSerializerSnapshotMigrationTestBase,3
"[hotfix] Remove the unnecessary suppressing logger for kubernetes informerIn FLINK-22802, the fabric8 Kubernetes client has been upgraded to 5.5.0, the verbose log level has been changed to Debug, so we don't need to suppress it manually.This closes #16661.",0
删除空模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1661 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-14939][e2e] Set distDir property,5
[FLINK-14535][table-planner-blink] Fix cast exception when count distinct on decimal fieldsThe conversion class of DecimalType of distinct key should be Decimal instead of BigDecimal.This closes #10001,0
[FLINK-26407][end-to-end-tests] Increase timeouts for MetricsAvailabilityITCase.,1
"[hotfix] Replace check state condition in Execution#tryAssignResource with if checkInstead of risking an IllegalStateException it is better to check that thetaskManagerLocationFuture has not been completed yet. If, then we also rejectthe assignment of the LogicalSlot to the Execution. That way, we don't riskthat we don't release the slot in case of an exception inExecution#allocateAndAssignSlotForExecution.",2
Merge branch 'stage1'Resolved Conflicts:pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/DataSinkContract.javapact/pact-compiler/src/main/java/eu/stratosphere/pact/compiler/jobgen/JobGraphGenerator.javapact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/DataSinkTask.java,5
[hotfix] Make the StreamGraphGenerator use Transformation.getInputs()This will uniformize partially most of the transform*() methodsin the StreamGraphGenerator.,1
[FLINK-20456][docs] Simplify temporal table definition,5
[FLINK-14326][table-planner-blink] Support to generate and apply watermark assigner in translateToPlan,1
changes TaskManager methods to IORadWritable parameters,2
KAFKA-2138; Fix producer to honor retry backoff; reviewed by Joel Koshy and Guozhang Wang,1
[FLINK-14353][table] Enable fork reuse for tests,3
"MINOR: Add select changes from 3rd KIP-307 PR for incrementing name index counter (#6754)When users provide a name for operation via the Streams DSL, we need to increment the counter used for auto-generated names to make sure any operators downstream of a named operator still produce a compatible name.This PR is a subset of #6411 by @fhussonnois. We need to merge this PR now because it covers cases when users name repartition topics or state stores.Updated tests to reflect the counter produces expected number even when the user provides a name.Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",5
[FLINK-25791][table-planner] Add Parser to the SerdeContext,1
[FLINK-6880] [runtime] Activate checkstyle for runtime/iterativeThis closes #4098.,1
[streaming] Incremental OLS update,5
[FLINK-22055][runtime] Fix RpcEndpoint MainThreadExecutor schedules callables with potential wrong time unit.This closes #15411,0
"KAFKA-8346; Improve replica fetcher behavior for handling partition failure [KIP-461] (#6716)The replica fetcher thread is terminated in case a partition crashes which leads to under replication. This behavior can be improved by dropping the failed partition. The thread can continue monitoring the rest of the partitions. If all partitions of a thread have failed, the thread would be shut down. This is documented in KIP-461: https://cwiki.apache.org/confluence/display/KAFKA/KIP-461+-+Improve+Replica+Fetcher+behavior+at+handling+partition+failure.Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",5
[hotfix] [docs] Fix typos in MATCH_RECOGNIZE docsThis closes #7194.,2
[FLINK-7190] [java] Activate checkstyle flink-java/*This closes #4343.,2
[FLINK-11295][conf] Rename configuration options of queryable-state from query.x to queryable-state.xChange-Id: Idb561da3982de07e77a05ffef9ad227094f527b0,5
KAFKA-5829; Only delete producer snapshots before the recovery pointAuthor: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #4023 from ijuma/kafka-5829-avoid-reading-older-segments-on-hard-shutdown,5
日志加强 DUBBO-88 Remoting模块中Client重连失败抛出的异常不能判定关联的服务git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@451 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-17307] Add collector to deserialize in PubSub,1
[FLINK-26095][metrics] Respect bind-host for MQS actor system,5
[hotfix][docs] Fix broken links to table functionsthis closes #10244.,1
Remove space after comma for TupleXX.toString()It is better to save some bytes when writing the output. Users can always overwrite to `toString()` if they want.Author: Robert Metzger <rmetzger@apache.org>Closes #118 from rmetzger/benchFixes and squashes the following commits:cb8a251 [Robert Metzger] Remove space after comma for TupleXX.toString(),4
[DUBBO-3137]: step4 - remove MonitorConstants (#4069)* [DUBBO-3137]: step4 - remove MonitorConstants* remove unused import,2
- inverted StubAnnotation UpdateSet to ConstantSet,1
[FLINK-15067][table-api] Add utility method to TableConfig that adds a new job parameter,2
[FLINK-20084][table-planner-blink] Fix NPE when generating watermark for null rowtime after watermark push downThis closes #14029,0
"[FLINK-20852][metrics] Drop BackPressureSampleService in favour of backPressuredTimeMsPerSecond metricBackPressureSampleService is no longer needed and furthermore it should be less accurate comparedto the backPressuredTime metric. This is because sampling used to work by checking Task#isBackPressuredmethod, which in some cases can return true, with task that should be back pressured, but tasks(especially flatMap operators) can sometimes ignore back pressure status and keep spining forlimited amount of time. Because of that for flatMap operators, like WindowOperator,BackPressureSampleService could return too high back pressured ratios.Further more this allows us to greatly simplify JobVertexBackPressureHandler and to removethe no longer needed BackPressureStatsTracker and BackPressureRequestCoordinator components.",4
[FLINK-1209] [compiler] Improve error messages when forgetting to close an iteration,1
[hotfix][python] Remove the redundant 'python setup.py install' from tox.iniThis close #8947,5
Improved code style,1
[FLINK-4285] [docs] Update the setup quickstart guide with the new SocketWindowWordCount example,1
添加UT DUBBO-543 URL在addParameter时，如果没有修改则返回this,2
[FLINK-11089] Log filecache directory removed messagesThis closes #7257.,4
"[FLINK-18907][hotfix] Replace old processIf/WhileAvailable with processSingleStepThe new versions have a bit different semantc. They process data/keep processing data,as long something was processed, instead of relaying on input/output availability.The biggest difference is, that processSingleStep can process mailbox actionseven if input is not available.",5
delay the display of job history with 8 sec instead of using a high network overhead method,1
"[FLINK-7372] [JobGraph] Remove ActorGateway from JobGraphThe JobGraph has an unncessary dependency on the ActorGateway via itsJobGraph#uploadUserJars method. In order to get rid of this dependencyfor future Flip-6 changes, this commit retrieves the BlobServer'saddress beforehand and directly passes it to this method.This closes #4483.",4
KAFKA-1755; trivial follow-up to fix comment in CleanerTest,3
[FLINK-8284][metrics][docs] Expand port description for JMX reporter,2
[FLINK-5160] SecurityUtils use OperatingSystem.getCurrentOperatingSystem()This closes #3066.,5
Modified unit test after having removed dead code,4
Fix ProxyHolder class modifier (#10302),0
[FLINK-19512] Introduce the new sink APIThis is the new Transactional Sink API described in FLIP-143.This closes #13576.,1
"[FLINK-16744][task] Send channel state handles to JM1. add channel state writer to SubtaskCheckpointCoordinator2. add handles to the reported snapshot3. cache checkpoint locations to prevent multiple streamsper checkpoint. With unaligned checkpoints, checkpointcan be initiated from several places which can result(without cache) in multiple streams/files for a singlecheckpoint",2
"[FLINK-21535][tests] Improved the detection of the attempt number in UnalignedCheckpointITCase.Attempt number was inferred from the times a specific source reader was created. However, there was a race condition between the induced failure in FailureMapper#initializeState and the creation of the source reader. If the failure was induced first, no restart was detected and thus the test never finishes.The solution is now to track the restarts of all source tasks through Enumerator#addSplitsBack, which is called on recovery. Additionally, instead of just tracking only one specific source operator, all operators are now tracked and the results are consolidated when all readers are initialized.",5
[FLINK-15494][table-planner-blink] Fix incorrect time field index in LogicalWindowAggregateRuleBaseThis closes #10784,2
[FLINK-24690][runtime] Changed the calculation of reaching buffer debloat threshold into more expected way,4
[FLINK-8531] [checkpoints] (part 8) Add tests for the FsCheckpointStorage and MemoryBackendCheckpointStorage.,3
Merge branch 'fhueske'Conflicts:pact/pact-runtime/src/main/java/eu/stratosphere/pact/runtime/task/ReduceTask.java,5
MINOR: Update log condition in JassContext.loadServerContext (#4566),2
We need to change the version to SNAPSHOT to satisfy release:prepare,4
"[FLINK-11106][tests] Port YarnTaskManagerRunnerFactoryTest to new code baseThe test YarnTaskManagerRunnerFactoryTest#testKerberosKeytabConfiguration is now covered byYarnTaskExecutorRunnerTest#testKerberosKeytabConfiguration. In order to test the behaviour,the YarnTaskExecutorRunner was slightly refactored to make it testable.",3
[FLINK-2006] [runtime] Fix testing TaskManager task status request to stabilize tests.,3
"MINOR: code cleanup (#6055)Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
[FLINK-24470][streaming] Added EMA calculation for buffer size inside BufferDebloater,1
[FLINK-20366][table-planner-blink] ColumnIntervalUtil#getColumnIntervalWithFilter should consider constant predicate,1
[FLINK-10740][docs] Add documentation for FLIP-27 sourcesThis closes #12492,2
[FLINK-10717] [core] Introduce SimpleSerializerSnapshot as replacement for ParameterlessTypeSerializerConfig,5
"MINOR: Refactor replica log dir fetching for improved logging (#6313)In order to debug problems with log directory reassignments, it is helpful to know when the fetcher thread begins moving a particular partition. This patch refactors the fetch logic so that we stick to a selected partition as long as it is available and log a message when a different partition is selected.Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>",2
"[FLINK-11334] Don't use IntSerializer in EnumValueSerializerUsing an IntSerialize technically makes EnumValueSerializer a compositeserializer, which it doesn't have to be. This decouplesEnumValueSerializer from any future changes to IntSerializer.",4
Fixed #273,0
"KAFKA-7864; validate partitions are 0-based (#6246)Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jun Rao <junrao@gmail.com>",5
some more tests for interface and implementation of arraynode,3
"[FLINK-18662][task] Calculate alignmentDurationNanos for unaligned checkpoints and CheckpointBarrierTrackerThis is modifing the alignmentDurationNanos metric for the CheckpointBarrierTracker. Previously it wasalways 0, now it's defined as the duration between processing first and the last checkpoint barrier.",2
[FLINK-13891][build] Increment flink-shaded version,2
[FLINK-10893] [tests] Export S3 credentials properly for test scripts,3
[FLINK-21505] Factor snapshot resource creation out of RocksFullSnapshotStrategyThis will allow us to create snapshot resources for a savepoint withoutusing a snapshot strategy.,1
[FLINK-19539][jmx][tests] Shutdown JMXService after tests,3
"KAFKA-13841: Fix a case where we were unable to place on fenced brokers in KRaft mode (#12075)This PR fixes a case where we were unable to place on fenced brokers In KRaft mode. Specifically,if we had a broker registration in the metadata log, but no associated heartbeat, previously theHeartbeatManager would not track the fenced broker. This PR fixes this by adding this logic to themetadata log replay path in ClusterControlManager.Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2
"KAFKA-13231; `TransactionalMessageCopier.start_node` should wait until the process if fully started (#11264)This patch ensures that the transaction message copier is fully started in `start_node`. Without this, it is possible that `stop_node` is called before the process is started which results in not stopping it at all.Reviewers: Jason Gustafson <jason@confluent.io>",5
DUBBO-109 demo放到trunk管理，与trunk同发布git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@480 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[hotfix][runtime] Fix the logger of BlocklistDeclarativeSlotPool,2
[FLINK-14260] Port ZooKeeperHaDispatcherTest to use TestingJobManagerRunnerFactoryNG,3
"KAFKA-3077: Enable KafkaLog4jAppender to work with SASL enabled brokersAuthor: Ashish Singh <asingh@cloudera.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>Closes #740 from SinghAsDev/KAFKA-3077",5
[hotfix] Remove unused imports from MetricOptions,2
[FLINK-26118][connectors/common] Add support for AsyncSink to downscale with state. AsyncSinkWriter can be restored from multiple BufferedRequestState,1
"KAFKA-10571; Replace blackout with backoff for KIP-629This replaces code and comment occurrences as described in the KIPAuthor: Xavier Léauté <xvrl@apache.org>Reviewers: Gwen Shapira, Mickael MaisonCloses #9366 from xvrl/kafka-10571",2
[FLINK-5637] Avoid warning while parsing YAML configuration files,2
"Fix the missing ApiUtils tests in streams module. (#6003)Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",5
"KAFKA-2644; Run relevant ducktape tests with SASL_PLAINTEXT and SASL_SSLRun sanity check, replication tests and benchmarks with SASL/Kerberos using MiniKdc.Author: Rajini Sivaram <rajinisivaram@googlemail.com>Reviewers: Geoff Anderson <geoff@confluent.io>, Jun Rao <junrao@gmail.com>Closes #358 from rajinisivaram/KAFKA-2644",5
[FLINK-1112] Add KeySelector group sorting on KeySelector groupingThis closes #209,1
[strom-compat] Added Storm API compatibility classes,1
"[FLINK-3727] Add support for embedded streaming SQL (projection, filter, union)- add methods to register DataStreams- add sql translation method in StreamTableEnvironment- add a custom rule to convert to streamable table- add docs for streaming table and sqlThis closes #1917",2
[hotfix] [tests] Minor style fix in FlinkTestBase,3
"KAFKA-12155: Metadata log and snapshot cleaning #10864This PR includes changes to KafkaRaftClient and KafkaMetadataLog to support periodiccleaning of old log segments and snapshots.Four new public config keys are introduced: metadata.log.segment.bytes,metadata.log.segment.ms, metadata.max.retention.bytes, andmetadata.max.retention.ms.These are used to configure the log layer as well as the snapshot cleaning logic. Snapshotand log cleaning is performed based on two criteria: total metadata log + snapshot size(metadata.max.retention.bytes), and max age of a snapshot (metadata.max.retention.ms).Since we have a requirement that the log start offset must always align with a snapshot,we perform the cleaning on snapshots first and then clean what logs we can.The cleaning algorithm follows:1. Delete the oldest snapshot.2. Advance the log start offset to the new oldest snapshot.3. Request that the log layer clean any segments prior to the new log start offset4. Repeat this until the retention size or time is no longer violated, or only a singlesnapshot remains.The cleaning process is triggered every 60 seconds from the KafkaRaftClient pollingthread.Reviewers: José Armando García Sancio <jsancio@gmail.com>, dengziming <dengziming1993@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",4
[FLINK-26118][connectors/common] Setting defaults in test to reduce test complexity,3
[FLINK-5518] [hadoopCompat] Add null check to HadoopInputFormatBase.close().This closes #3133This closes #243 // closing stale PR,1
[hotfix][docs] Fix typosThis closes #5827.,2
add license headers,1
[FLINK-11648] Remove MemoryArchivistThis closes #7733.,4
[hotfix] Replace deprecated Assert.assertThat,3
[FLINK-3541] [Kafka Connector] Clean up workaround in FlinkKafkaConsumer09This closes #1846,2
override equals of Config,5
broker failure system test broken on replication branch; patched by John Fung; reviewed by Joel Koshy and Jun Rao; KAFKA-306git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1359813 13f79535-47bb-0310-9956-ffa450edef68,3
[FLINK-22496][tests] Harden ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHookHardens the ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook by increasing the timeout from 3s to 10s.,1
"KAFKA-10017: fix flaky EosBetaUpgradeIntegrationTest (#8963)The current failures we're seeing with this test are due to faulty assumptions that it makes and not any real bug in eos-beta (at least, from what I've seen so far).The test relies on tightly controlling the commits, which it does by setting the commit interval to MAX_VALUE and manually requesting commits on the context. In two phases, the test assumes that any pending data will be committed after a rebalance. But we actually take care to avoid unnecessary commits -- with eos-alpha, we only commit tasks that are revoked while in eos-beta we must commit all tasks if any are revoked, but only if the revoked tasks themselves need a commit.The failure we see occurs when we try to verify the committed data after a second client is started and the group rebalances. The already-running client has to give up two tasks to the newly started client, but those tasks may not need to be committed in which case none of the tasks would be. So we still have an open transaction on the partitions where we try to read committed data.Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
KAFKA-4248; Consumer should rematch regex immediately in subscribeAuthor: Jason Gustafson <jason@confluent.io>Reviewers: Guozhang Wang <wangguoz@gmail.com>Closes #1954 from hachikuji/rematch-regex-on-subscribe,5
[FLINK-22563][docs] Add migration guide for new StateBackend interfacesCo-authored-by: Nico Kruber <nico.kruber@gmail.com>This closes #15831,1
[FLINK-28147][Python] Update httplib2 to at least 0.19.0 to address CVE-2021-21240,1
"KAFKA-3763; Remove deprecated APIs for 0.11.0.0This only removes deprecated methods,fields and constructors in a small number of classes.Deprecated producer configs is tracked via KAFKA-3353and the old clients and related (tools, etc.) won'tbe removed in 0.11.0.0.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2995 from ijuma/kafka-3763-remove-deprecated-0.11",4
KAFKA-499 Refactor controller; patched by Neha Narkhede; reviewed by Jun Raogit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387270 13f79535-47bb-0310-9956-ffa450edef68,4
增加MethodValidated注解的测试用例  及对MethodValidated使用场景和用法的说明注释 (#784)* 增加MethodValidated注解的测试用例  及对MethodValidated使用场景和用法的说明注释* 将需要检查的分组维护到List<Class<?>> groups中，包括当前接口类及Default.class两个默认的分组* 修改接口级别为jdk1.6; 按javadoc规范修改注释,2
[hotfix][kubernetes] Remove the unnecessary clean up codes for Kubernetes embedded jobThe ${OUTPUT_VOLUME} is under ${TEST_DATA_DIR}. And ${TEST_DATA_DIR} will be cleaned up automatically when the e2e test finished. See test-runner-common.sh#cleanup.,3
Fixed classloader delegation of task conf,5
[FLINK-11480][hive] Create HiveTableFactory that creates TableSource/Sink from a Hive tableThis PR creates HiveTableFactory that creates TableSource/Sink from a Hive tableThis closes #8785.,1
[streaming] update internal state abstraction,5
[FLINK-7791] [Client] Move LIST logic into ClusterClient,2
KAFKA-12450: Remove deprecated methods from ReadOnlyWindowStore (#10294)Implement first part of https://cwiki.apache.org/confluence/display/KAFKA/KIP-667%3A+Remove+deprecated+methods+from+ReadOnlyWindowStore.Reviewers: Guozhang Wang <wangguoz@gmail.com>,5
"KAFKA-4490: Add Global Table support to Kafka StreamsAdd Global Tables to KafkaStreams. Global Tables are fully replicated once-per instance of KafkaStreams. A single thread is used to update them. They can be used to join with KStreams, KTables, and other GlobalKTables. When participating in a join a GlobalKTable is only ever used to perform a lookup, i.e., it will never cause data to be forwarded to downstream processor nodes.Author: Damian Guy <damian.guy@gmail.com>Reviewers: Matthias J. Sax, Eno Thereska, Guozhang WangCloses #2244 from dguy/global-tables",5
[FLINK-18072][hbase] Fix HBaseLookupFunction can not work with new internal data structure RowDataThis closes #12594,5
repackage ServiceConfigBase and ReferenceConfigBase,5
Fixed startup scripts to include extended hadoop dependencies in the classpath.,0
Add binary release module 'distribution',1
"[FLINK-20145][network] Double-check if gate still has priority buffer when enqueuing in UnionInputGate.Since notification is not atomic in respect to gate enqueuing, priority event already polled by task thread when netty enqueues the gate.",2
[hotfix] Correct comment references to flink-yarn-tests,3
"[FLINK-19251][connectors] Avoid confusing queue handling in ""SplitReader.handleSplitsChanges()""This removes the queue (and repeated queue passing logic) and simly passes a list of split changesdirectly and once, for the fetcher to handle.This closes #13400",0
fix #2134 upgrade httpcore to 4.4.6 (#2319),0
Add ClassLoader Binding for ScopeModel (#8766)* Add ClassLoader Binding for ScopeModel* Fix UT* Fix UT* Fix UT* Fix API* Fix UT* remove ExtensionLoader reload* Fix cl* Fix cl* Fix NPE* Fix override method,0
"MINOR: enforce non-negative invariant for checkpointed offsets (#8297)While discussing KIP-441 we realize we don't strictly enforce that all checkpointed offset sums are positive (or 0, though there's not much point to checkingpoint a 0 offset is there)?Rather than awkwardly try handle this within every user/reader of the checkpoint file, we should just make a guarantee that all returned checkpointed offsets are positive.Reviewers: Guozhang Wang <wangguoz@gmail.com>",1
Fixed simple typos,2
[FLINK-13351][table-blink-planner] Clean up duplicate case clause for ROW in FlinkTypeFactory.toLogicalTypeThis closes #9196,2
"MINOR: Assume unclean shutdown for metadata log (#10363)Currently the metadata log assumes successful shutdown and skips recovery. For now, we prefer to err on the safe side and assume instead that the replica was shutdown uncleanly so that we can force full recovery. This is justified in the short term because:1. Snapshots are not fully implemented for the metadata log2. The replicas (controllers and brokers) need to read the entire metadata log to load it into memory.In other words, we need to read through the metadata log once on startup anyway. A long-term fix will be provided in https://issues.apache.org/jira/browse/KAFKA-12504.Reviewers: Jason Gustafson <jason@confluent.io>",5
"I18N code, change to apache license, and remove author info",5
"KAFKA-6058: Refactor consumer API result return types (#4856)Refactored the return types in consumer group APIs the following way:```Map<TopicPartition, KafkaFuture<Void>> DeleteConsumerGroupsResult#deletedGroups()Map<TopicPartition, KafkaFuture<ConsumerGroupDescription>> DescribeConsumerGroupsResult#describedGroups()KafkaFuture<Collection<ConsumerGroupListing>> ListConsumerGroupsResult#listings()KafkaFuture<Map<TopicPartition, OffsetAndMetadata>> ListConsumerGroupOffsetsResult#partitionsToOffsetAndMetadata()```* For DeleteConsumerGroupsResult and DescribeConsumerGroupsResult, for each group id we have two round-trips to get the coordinator, and then send the delete / describe request; I leave the potential optimization of batching requests for future work.* For ListConsumerGroupOffsetsResult, it is a simple single round-trip and hence the whole map is wrapped as a Future.* ListConsumerGroupsResult, it is the most tricky one: we would only know how many futures we should wait for after the first listNode returns, and hence I constructed the flattened future in the middle wrapped with the underlying map of futures; also added an iterator API to compensate the ""fail the whole future if any broker returns error"" behavior. The iterator future will throw exception on the failing brokers, while return the consumer for other succeeded brokers.Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",5
Introduced enumeration for Nephele's possible execution modes,5
DUBBO-339 修改日志测试类git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1879 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-6515; Adding toString() method to o.a.k.connect.data.Field (#4509),5
[FLINK-12351][DataStream] Fix AsyncWaitOperator to deep copy StreamElement when object reuse is enabled #8321 (#8321),0
Fixed #149,0
Keep parameters in registry url.,1
"KAFKA-4501; Fix EasyMock and disable PowerMock tests under Java 9- EasyMock 3.5 supports Java 9.- Fixed issues in `testFailedSendRetryLogic` and`testCreateConnectorAlreadyExists` exposed by new EasyMockversion. The former was passing `anyObject` to`andReturn`, which doesn't make sense. This was leavingbehind a global `any` matcher, which caused a few issues inthe new version. Fixing this meant that the correlation ids hadto be updated to actually match. The latter was missing acouple of expectations that the previous version of EasyMockdidn't catch.- Removed unnecessary PowerMock dependency from 3 tests.- Disabled remaining PowerMock tests when running with Java 9until https://github.com/powermock/powermock/issues/783 isin a release.- Once we merge this PR, we can enable tests in the Java 9 buildsin Jenkins.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3845 from ijuma/kafka-4501-easymock-powermock-java-9",5
[FLINK-3367] Add PublicEvolving and Internal annotations to flink-streaming-java and flink-streaming-scalaThis closes #1606,2
[config] Remove unused config constants,5
"MINOR: Rolling bounce upgrade fixed broker system test (#4690)Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
modify dubbo configuration key,5
[hotfix] [tests] Remove redundant rebalance in SuccessAfterNetworkBuffersFailureITCaseThis closes #5916,0
"[FLINK-15763][Runtime] Running TM checks only necessary resource cofig, set to default for local executionFLIP-49 (FLINK-13980) calculates memory setup to start TM process. Atm, we reuse this logic to get necessary resource configuration options in running TM, although we do not need the full TaskExecutorResourceSpec which can be renamed to TaskExecutorProcessSpec.In case of local execution in mini cluster, the TM process is started outside of Flink framework and nothing is pre-calculated. It means that any configured process or Flink memory size can make no sense and can be ignored then to make things simpler and more explicit. Also the result of FLIP-49 calculation can contradict to the default values and other derived FLIP-49 memory components are not used by TM internally anyways. If some necessary options are not set, we can set them to reasonable defaults. The configuration options required for running TM, which are expected to be calculated and set before its start, are the following (with defaults for local execution):- cpu cores (potentially for FLIP-56, FLINK-14187, default: Double.MAX_VALUE- task heap memory (potentially for FLIP-56, FLINK-14187, default: MemorySize.MAX_VALUE)- task off-heap memory (potentially for FLIP-56, FLINK-14187, default: MemorySize.MAX_VALUE)- network memory (default: 64Mb)- managed memory (default: 128Mb)Additionally, we refactor TM runner to not reuse current FLIP-49 computation but just check that the necessary options are set and create TaskExecutorResourceSpec which contains only them.This closes #10946.",1
DUBBO-489 dubbo-admin开源,5
"[FLINK-20018] Allow escaping in 'pipeline.cached-files' and 'pipeline.default-kryo-serializers'This commit enables escaping in options that expect a map ofstring-string entries. It lets users pass options such as e.g.pipeline.cached-files=name:file1,path:'oss://bucket/file1'",2
[FLINK-22927][python] Fix the bug of JobStatusThis closes #16146.,0
"[FLINK-17520] [test] Simplify CompositeTypeSerializerSnapshotTestThe unit tests in CompositeTypeSerializerSnapshotTest were previouslyover-engineered w.r.t. how to mock the result of a compatibility check.It was doing string equals checks, whereas it is simple enough to justlet the new serializer wrap a mock compat result and just return thatfor the compatibility checks.",1
"MINOR: Fix typo in `shouldUseJUnit5` in build.gradle (#9893)""mirorr-client"" => ""mirror-client""Reviewers: Ismael Juma <ismael@juma.me.uk",3
KAFKA-1953; KAFKA-1962; Disambiguate purgatory metrics; restore delayed request metrics; reviewed by Guozhang Wang,5
MINOR: refactor SelectingIterator by scala iterator (#9755)Reviewers: Ismael Juma <ismael@juma.me.uk>,4
"Merge pull request #2018, fix redis auth problem for RedisProtocol.Fixes #2017",0
Fix MetadataService connections leak (#8555),5
KAFKA-7485: Wait for truststore update request to complete in test (#5791)Reviewers: Jason Gustafson <jason@confluent.io>,5
[hotfix][tests] Document flink-jepsen correctness model,2
[FLINK-26629][runtime] fix bug in code comment of SubtaskStateMapper.RANGE,0
[FLINK-1201] [gelly] changed mapEdges to also return a Graph,4
[FLINK-23498][streaming-java] Expose an easier StreamExecutionEnvironment.configure(),5
[FLINK-19689][yarn][test] Fix TaskExecutorProcessSpecContainerResourcePriorityAdapterTest failure for Hadoop 2.10+.This closes #13673.,0
MINOR: some code cleanups in the controller,4
KAFKA-3125: Add Kafka Streams ExceptionsAuthor: Guozhang Wang <wangguoz@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #809 from guozhangwang/K3125,5
cloudmgr fix (still experimental),0
[runtime] Quick fix for error with unsupported ship strategy,1
MINOR: Optimize the matches method of AccessControlEntryFilter (#11768)* MINOR: Make the getters in match method in AccessControlEntryFilter consistencyReviewers: Luke Chen <showuon@gmail.com>,1
[FLINK-2763] [runtime] Fix hash table spilling partition selection.,0
[FLINK-18864][python] Support key_by() operation for Python DataStream API. (#13097),5
[3.0] Fix Zone Aware Filter not work (#9680),1
[FLINK-21180][python] Move the state module from 'pyflink.common' to 'pyflink.datastream'This closes #14788.,5
[FLINK-14405][runtime] Update ResourceSpec to align with FLIP-49 resource types,5
added csv test resource,3
"KAFKA-4216; Control Leader & Follower Throttled Replicas SeparatelySplits the throttled replica configuration (the list of which replicas should be throttled for each topic) into two. One for the leader throttle, one for the follower throttle.So: quota.replication.throttled.replicas=>quota.leader.replication.throttled.replicas & quota.follower.replication.throttled.replicasAuthor: Ben Stopford <benstopford@gmail.com>Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>Closes #1906 from benstopford/KAFKA-4216-seperate-leader-and-follower-throttled-replica-lists",5
[FLINK-28213][runtime] StreamExecutionEnvironment configure method support override pipeline.jars optionThis closes #20057.,1
PactProgram and PlanWithJar create proper user code class loaders.,1
[FLINK-7041] Deserialize StateBackend from JobCheckpointingSettings with user classloaderThis closes #4232.,1
[FLINK-20318][kafka] Fix cast question for properies() method in kafka ConnectorDescriptorThis closes #15250,0
[FLINK-17867][hive][test] Add hdfs dependency to hive-3.1.1 testThis closes #12318,3
MINOR: Exclude Committer Checklist section from commit messageIt seems like it's sufficient to be able to refer to it in the PR.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #4202 from ijuma/exclude-committer-checklist-when-merging,5
optimize ConfigManager,5
[FLINK-14851] Re-enabled the -sae flag.,0
Use special Configuration for Configs (#4522),5
"MINOR: more log4j entry on elect / resignation of coordinators (#9416)When a coordinator module is being elected / resigned, our log entry is usually associated with a background scheduler on loading / unloading entries and hence it is unclear at the exact time when the election or resignation happens, and we have to then compare with the KafkaAPI's log entry for leaderAndISR / StopReplica to infer the actual time. I think add a couple new log entries indicating the exact time when it happens is helpful.Reviewers: Boyang Chen <boyang@confluent.io>, Lee Dongjin <dongjin@apache.org>, Bruno Cadonna <bruno@confluent.io>",5
[FLINK-4410] [runtime] Rework checkpoint stats tracking,1
[hotfix][runtime] Close SlotPool in main threadOtherwise main thread check violation can happen if the SlotPool#close() triggers SlotPool#releaseSlot().,0
[streaming] Discretizer sharing added with further window optimzations for better chaining,5
"KAFKA-3076; BrokerChangeListener should log the brokers in orderAuthor: Konrad <konkalita@gmail.com>Author: konradkalita <konkalita@gmail.com>Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>Closes #749 from konradkalita/kafka-3076",2
DUBBO-125 改进日志输出git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@613 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-14422][runtime] Added metrics for total memory, available memory, used memory and number of used memory segments.",1
[FLINK-22518][docs-zh] Translate the documents of High Availability into Chinese(#16084) (#16084)This fix #16084.,0
[FLINK-22477][tests] Remove TestingSlotPoolImpl from PhysicalSlotProviderResource,1
删除空模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1653 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-20650][k8s] Remove ""native-k8s"" command and add bash wrapper for JobManager and TaskManager container argsThe ""native-k8s"" command has been deprecated. Flink should use the pass-through mode. Note that Flink needs to add a ""bash -c"" wrapper so that the environment variables could be expanded when executing in the ""docker-entrypoint.sh"".The corresponding PR in flink-docker is https://github.com/apache/flink-docker/pull/49.This closes #14419",2
[hotfix][docs] fix spelling,0
"[FLINK-9004][tests] Implement Jepsen tests to test job availability.Use the Jepsen framework (https://github.com/jepsen-io/jepsen) to implementtests that verify Flink's HA capabilities under real-world faults, such assudden TaskManager/JobManager termination, HDFS NameNode unavailability, networkpartitions, etc. The Flink cluster under test is automatically deployed on YARN(session & job mode) and Mesos.Provide Dockerfiles for local test development.This closes #6240.",3
MINOR: Remove redundant casting and if condition from ConnectSchema (#9959)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,4
"[FLINK-28753][table-planner] Improve FilterIntoJoinRule which could push some predicates to another sideFor the above filter of inner/left/right join or the join condition of inner join, the predicate which field references are all from one side join condition can be pushed into another join sideThis closes #20432",1
[hotfix][table-common] Add missing getter to TimeType,1
[hotfix][tests] Remove unnecessary component,4
[FLINK-23004][yarn] Fix misleading logThis closes #16169,2
Polish apache/dubbo#6152 (#6154),1
[FLINK-13869][table-planner-blink][hive] Fix Hive functions can not work in blink planner streaming mode (#10013),2
[hotfix] [tests] Fix CassandraConnectorITCase on Java 7 profiles,2
[hotfix][network] Fix the comments error in NettyMessage,0
[FLINK-18720][k8s] Introduce KubernetesResourceManagerDriver.,2
testfile,3
[hotfix][doc] Remove redundant punctuation for External Resources page.,4
[FLINK-17375] Adopt nightly python wheels jobs to refactored ci scripts,4
[FLINK-5058] [scala-shell] Set correct value for TaskManager memory parameter.This closes #2799.,2
[FLINK-25845][table] Add COMPILE PLAN and COMPILE AND EXECUTE PLANThis closes #18648.,1
KAFKA-5792; Fix Transient failure in KafkaAdminClientTest.testHandleTimeoutAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #3822 from cmccabe/KAFKA-5792,5
made JSON plan output more detailed.,5
"Revert ""[FLINK-17593][fs-connector] Support arbitrary recovery mechanism for PartFileWriter""This reverts commit 339f5d84d0b7e9fe64534ea4e2adf7e35dee8398.I'm reverting these three related commits because it is important tohave confidence in our testing and to clearly separate the addition ofthe Bucket State upgrade test from changing the serializer.",4
[docs] fixed a few typos in internal_general_arch.mdThis closes #602,2
[FLINK-27244][hive] Improve documentation of reading partition with subdirectories for Hive tables,2
[FLINK-21070][table-runtime-blink] Fix invalid reuse of generated codeCompileUtils reuses code based on only the class name. This could be error-proneas code that is slightly different would be ignored. The wrong behavior wasvisible during code generation of structured types.This closes #14720.,0
test,3
[FLINK-18552][tests] Update migration tests of FlinkKafkaConsumerBaseMigrationTest to cover migration till release-1.11,3
[FLINK-25252][kafka] Enabling Kafka tests on Java 11,3
[FLINK-17655] Remove assignTimestamps from documentationThis was deprecated and now removed.,4
trivial change to reduce default fetcher queue sizegit-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1242696 13f79535-47bb-0310-9956-ffa450edef68,1
"[FLINK-16633][AZP] Fix builds without s3 credentialsProblem: Builds on Azure where failing if S3 credentails were not provided, because the syntax in the pipeline definition was incorrect.Solution: Use a way to access secret variables that leads to an empty value (instead of the variable name). Also, extend the check in the unit tests to ""variable empty"" instead of just ""variable not set"".",1
[hotfix][docs-zh] Delete redundant English content in Chinese documents.,2
[FLINK-16587][checkpointing] Implement CheckpointBarrierUnaligner to trigger checkpoint when receiving the first barrier.CheckpointBarrierUnaligner will receive more sophisticated strategies to trigger a checkpoint with later tasks of FLINK-14551.,2
KAFKA-8034: Use automatic RPC generation in DeleteTopicsReviewers: Colin P. McCabe <cmccabe@apache.org>,4
[hotfix][test] Minor clean-ups in DemultiplexingRecordDeserializerTest.,3
"MINOR: Add RaftReplicaManager (#10069)This adds the logic to apply partition metadata when consuming from the Raft-basedmetadata log.RaftReplicaManager extends ReplicaManager for now to minimize changes to existingcode for the 2.8 release. We will likely adjust this hierarchy at a later time (e.g. introducinga trait and adding a helper to refactor common code). For now, we expose the necessaryfields and methods in ReplicaManager by changing their scope from private to protected,and we refactor out a couple of pieces of logic that are shared between the twoimplementation (stopping replicas and adding log dir fetchers).Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2
"MINOR: Adding a constant to denote UNKNOWN leader in LeaderAndEpoch (#11477)Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",5
Added some missing operator annotations and constructors. Added two point test files.,2
"[FLINK-14314][runtime] Introduce physical slot ResourceProfile in SlotProfilephysicalSlotResourceProfile can be used for allocating a physical slot for the task slot. If the task is not in a shared slot, it is the task resource profile. Otherwise it is the slot sharing group resource profile.The existing ResourceProfile in SlotProfile is renamed as taskResourceProfile for logical slot allocation.",2
[FLINK-8725] Reverted backward compatibility with <=1.5This closes #5960,4
[FLINK-1392] Add Kryo serializer for ProtobufConflicts:flink-java/pom.xmlflink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/KryoSerializer.java,5
[FLINK-11701][table-runtime-blink] Introduce an abstract set of data formatsThis closes #7816,5
"KAFKA-6775: Fix the issue of without init super class's (#4859)Some anonymous classes of AbstractProcessor didn't initialize their superclass. This will not set up ProcessorContext context at AbstractProcessor.Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",1
Adapted JobGraphGenerator to explicit UnionNode in optimized plan,5
Fixed function call tests,3
[hotfix][docs] Fix the link-tags of 'Side Outputs' page of 'DataStream API' (#13087),5
[FLINK-12878][travis] Move flink-table-planner-blink & flink-table-runtime-blink to separate profileThis closes #8772,2
"KAFKA-5157; Options for handling corrupt data during deserializationThis is the implementation of KIP-161: https://cwiki.apache.org/confluence/display/KAFKA/KIP-161%3A+streams+deserialization+exception+handlersAuthor: Eno Thereska <eno.thereska@gmail.com>Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>Closes #3423 from enothereska/KAFKA-5157-deserialization-exceptions",5
KAFKA-4861; GroupMetadataManager record is rejected if broker configured with LogAppendTimeThe record should be created with CreateTime (like in the producer). The conversion toLogAppendTime happens automatically (if necessary).Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Jason Gustafson <jason@confluent.io>Closes #2657 from ijuma/kafka-4861-log-append-time-breaks-group-data-manager,5
[hotfix] Fix SimpleStringSchema serialization issue,0
fix #9026 (#9027)Co-authored-by: luguilin <luguilin@longfor.com>,0
"[FLINK-3626] [py] Add zipWithIndex()This closes #2136Create a task_id message in PythonStreamer that is passed throughto the underlying process and included in the RuntimeContext, whereit is accessible to the user and to functions.",1
KAFKA-1199 Add a reduced access log level; reviewed by Guozhang Wang and Jun Rao,2
Added PactBoolean type.,1
"KAFKA-10614: Ensure group state (un)load is executed in the right order (#9441)Co-authored-by: Jason Gustafson<jason@confluent.io>Reviewers: Jason Gustafson<jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
Refactored input/output gates,4
[FLINK-26847][python] Ensure command line option '-py' works in YARN application modeThis closes #19227.,1
[FLINK-16652][orc] BytesColumnVector should init buffer in Hive 3.xThis closes #11485,5
[3.0] Pre-allocate map size in Directory (#9222),5
[FLINK-21104][network] Do not enqueue released channels into the input gate.,2
Fix the problem that some key values of MetadataReportConfig cannot be obtained (#9429),5
[FLINK-10839][serializer] Fix implementation of PojoSerializer.duplicate() w.r.t. subclass serializer,0
restarting from pact-runtime,1
[FLINK-2037] Provide flink-python.jar in lib/This closes #691,2
[FLINK-11762] Update WindowOperatorMigrationTest for 1.8,3
[FLINK-25712][connectors/testing-framework] Merge flink-connector-testing module to flink-connector-test-utils moduleThis closes #18437.,3
[FLINK-13567][e2e] Retry kafka/registry start,1
put default version&group from provider and consumer into service metadata. (#6111)* put default version&group from provider and consumer into service metadata.,5
[FLINK-13347][table-planner] should handle SEMI/ANTI JoinRelType in switch caseThis closes #9227.,1
Missing file from KAFKA-828,2
[FLINK-17977][runtime] Log leader grant/revocation to shutdown JobManager on DEBUG,0
[runtime] Remove old redundant classes  - StringRecord -> StringValue  - IntegerRecord -> IntValue  - FileRecord -> obsolete,2
[FLINK-3580] [table] Add OVERLAPS functionThis closes #2468.,1
change protoc compiler version to SNAPSHOT,4
[hotfix][coordination] Guard assumption in AdaptiveScheduler.Restarting,0
"KAFKA-8457; Move `Log' reference from `Replica` into `Partition` (#6841)A `Partition` object contain one or many `Replica` objects. These replicaobjects in turn can have the ""log"" if the replica corresponds to thelocal node. All the code in Partition or ReplicaManager peek intoreplica object to fetch the log if they need to operate on that. Asreplica object can represent a local replica or a remote one, thislead to a bunch of ""if-else"" code in log fetch and offset update code.NOTE: In addition to a ""log"" that is in use during normal operation, ifan alter log directory command is issued, we also create a future logobject. This object catches up with local log and then we switch the logdirectory. So temporarily a Partition can have two local logs. Beforethis change both logs are inside replica objects.This change is an attempt to untangle this relationship. In particularit moves `Log` from `Replica` into `Partition`. So a partition containsa local log to which all writes go and possibly a ""future log"" if the partition is being moved between directories. Additionally, it maintainsa list of remote replicas for offset and ""caught up time"" data that it usesfor replication protocol. Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",5
[FLINK-19148][docs] Fix crashed table in Flink Table API & SQL docsThis closes #13338,2
[hotfix][tests] Refactor MapR FS Tests,3
[FLINK-11329] [DataStream] Migrate StreamElementSerializer to use new compatibility API,1
"MINOR: correctly parse version OffsetCommitResponse version < 3KAFKA-7903: automatically generate OffsetCommitRequest (#6583) introduced a change that cause consumer breakage when OffsetCommitResponse versions < 3 are parsed, as they do not include a throttle_time_ms field. This PR fixes the parsing by supplying the correct version to the OffsetCommitResponse constructor in AbstractResponse.parseResponse.I have tested this change against many of the compatibility system tests, and it has fixed all the failures that I have tested thus far.Author: Lucas Bradstreet <lucas@confluent.io>Reviewers: Gwen Shapira, Boyang ChenCloses #6698 from lbradstreet/offset-commit-response-throttle-field",1
[FLINK-20906][legal] Update copyright year to 2021 for NOTICE files.This closes #14598,2
[hotfix][json][tests] Fix location of services directory,0
kafka-1609; New producer metadata response handling should only exclude a PartitionInfo when its error is LEADER_NOT_AVAILABLE; patched by Dong Lin; reviewed by Jun Rao,0
[FLINK-18945][python] Support CoFlatMap for Python DataStream API (#13152),5
[FLINK-18084] Rename the ExecutorCLI to GenericCLI according to docs,2
Fixed bug in new ObjectSerializer,1
MINOR: Fix some re-raising of exceptions in system testsAuthor: Ewen Cheslack-Postava <me@ewencp.org>Reviewers: Ismael Juma <ismael@juma.me.uk>Closes #2852 from ewencp/minor-re-raise-exceptions,3
[FLINK-8675] Add non-blocking shut down method to RestServerEndpointMake shut down method of RestServerEndpoint non blocking.This closes #5511.,1
[hotfix][python] Ignore PythonTableFunctionOperatorTest temporarily,3
Fix javadoc for Adaptive.value() (#3867),2
[FLINK-4291] [metrics] Add log entry for scheduled reportersThis closes #2318,1
[hotfix] improvements to savepoint docs (#18909)* [hotfix] [docs] remove unneccessary mentions to old Flink version in Savepoints docs* [hotfix] misc improvements and simplifications to savepoint docs,2
"[hotfix][config] Remove CheckpointConfig#enableUnalignedCheckpoints without parameters.CheckpointConfig#enableUnalignedCheckpoints(boolean) makes it explicit and also is more future-proof. When unaligned checkpoints become the default, this method will be mostly useless and we would need to add a #disableUnalignedCheckpoints() for consistency.",1
DUBBO-366 修改工程结构，折叠子模块git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1668 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-19180][runtime] Decalare managed memory use cases for transformations with state backends.,1
[FLINK-25867][docs-zh] translate ChangelogBackend documentation to chinese,2
DUBBO-175解决本机IP出错导致Log的递归调用git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@817 1a56cb94-b969-4eaa-88fa-be21384802f2,1
[FLINK-20981][coordination] Allow initializing jobs to be suspended,5
[FLINK-21852][table] Introduce NullAwareGetters to BinaryRowDataThis closes #15257,5
"KAFKA-4944; Fix an ""unread field"" findbugs warning in streams examplesAuthor: Colin P. Mccabe <cmccabe@confluent.io>Reviewers: Michael G. Noll <michael@confluent.io>, Ismael Juma <ismael@juma.me.uk>Closes #2727 from cmccabe/KAFKA-4944",5
"[FLINK-10247] Introduce port range option for Flink's metrics query serviceIn order to make the port used for Flink's internal metrics query service configurable,this commits adds the metrics.internal.query-service.port config option. This optionspecifies a port range from which the metric query service picks a free one to bind to.Per default, a random port is picked.This closes #6759.",5
DUBBO-394 增加黑白名单日志git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@1869 1a56cb94-b969-4eaa-88fa-be21384802f2,1
KAFKA-13101: Replace EasyMock and PowerMock with Mockito for RestServerTest (#11074)Reviewers: Ismael Juma <ismael@juma.me.uk>,3
[3.0-Triple] fix tri TheadPool is default (#10019),0
[hotfix] Fix checkstyle violations in ExecutionGraphSuspendTest,3
[FLINK-6884] [table] Improve confused exception information.This closes #4100,5
"[FLINK-23308] Optimize checks if SourceContext is closedThis commit tries to optimize checks on the hot path for closedSourceContext. It removes unnecessary duplicated calls ofcheckNotClosed.There is no certainty it fixes the problem, however we want to runbenchmarks for a couple of days and see how it affects the performance.",1
[FLINK-17872][doc] Add document for writing Avro files with StreamingFileSinkThis closes #12321,2
"KAFKA-8398: Prevent NPE in `forceUnmap` (#8983)Without this change, we would catch the NPE and log it.This was misleading and could cause excessive logvolume.The NPE can happen after `AlterReplicaLogDirs` completessuccessfully and when unmapping older regions. Examplestacktrace:```text[2019-05-20 14:08:13,999] ERROR Error unmapping index /tmp/kafka-logs/test-0.567a0d8ff88b45ab95794020d0b2e66f-delete/00000000000000000000.index (kafka.log.OffsetIndex)java.lang.NullPointerExceptionat org.apache.kafka.common.utils.MappedByteBuffers.unmap(MappedByteBuffers.java:73)at kafka.log.AbstractIndex.forceUnmap(AbstractIndex.scala:318)at kafka.log.AbstractIndex.safeForceUnmap(AbstractIndex.scala:308)at kafka.log.AbstractIndex.$anonfun$closeHandler$1(AbstractIndex.scala:257)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)at kafka.log.AbstractIndex.closeHandler(AbstractIndex.scala:257)at kafka.log.AbstractIndex.deleteIfExists(AbstractIndex.scala:226)at kafka.log.LogSegment.$anonfun$deleteIfExists$6(LogSegment.scala:597)at kafka.log.LogSegment.delete$1(LogSegment.scala:585)at kafka.log.LogSegment.$anonfun$deleteIfExists$5(LogSegment.scala:597)at kafka.utils.CoreUtils$.$anonfun$tryAll$1(CoreUtils.scala:115)at kafka.utils.CoreUtils$.$anonfun$tryAll$1$adapted(CoreUtils.scala:114)at scala.collection.immutable.List.foreach(List.scala:392)at kafka.utils.CoreUtils$.tryAll(CoreUtils.scala:114)at kafka.log.LogSegment.deleteIfExists(LogSegment.scala:599)at kafka.log.Log.$anonfun$delete$3(Log.scala:1762)at kafka.log.Log.$anonfun$delete$3$adapted(Log.scala:1762)at scala.collection.Iterator.foreach(Iterator.scala:941)at scala.collection.Iterator.foreach$(Iterator.scala:941)at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)at scala.collection.IterableLike.foreach(IterableLike.scala:74)at scala.collection.IterableLike.foreach$(IterableLike.scala:73)at scala.collection.AbstractIterable.foreach(Iterable.scala:56)at kafka.log.Log.$anonfun$delete$2(Log.scala:1762)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at kafka.log.Log.maybeHandleIOException(Log.scala:2013)at kafka.log.Log.delete(Log.scala:1759)at kafka.log.LogManager.deleteLogs(LogManager.scala:761)at kafka.log.LogManager.$anonfun$deleteLogs$6(LogManager.scala:775)at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)```Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>Co-authored-by: Jaikiran Pai <jaikiran.pai@gmail.com>",1
[FLINK-20966][table-planner-blink] Rename BatchExecIntermediateTableScan to BatchPhysicalIntermediateTableScanThis closes #14638,2
MINOR: ListPartitionReassignmentsResponse should not be entirely failed when a topic-partition does not exist  (#7486)Reviewers: Colin P. McCabe <cmccabe@apache.org>,0
[FLINK-17461][formats][json] Support JSON serialization and deseriazation schema for RowData typeThis closes #11944,5
[FLINK-9526][e2e] Fix unstable BucketingSink end-to-end test,3
[FLINK-4862] fix Timer register in ContinuousEventTimeTriggerThis closes #2671,1
Renaming and minor cleanup of TPCH Q3 example,4
"[FLINK-14344][checkpointing] MasterHooks class supports asynchronous triggeringThis commits add supports for asynchronous triggering `MasterHooks`.As for now, they are still being fired synchronously by the `CheckpointCoordinator`.",1
MINOR: Print the cached broker epoch (#11005)When the broker epochs do not match make sure to print both broker epochs.,1
"[FLINK-15047][runtime] Fix format of setting managed memory size in ActiveResourceManagerFactory.This fixes YarnDistributedCacheITCase#testPerJobModeWithDistributedCache.The test case failed because value of dynamic properties in generated task executor starting command contains space, which blocks parsing of the subsequent properties.",1
[hotfix][e2e] Output and collect the logs for Kubernetes IT cases,2
[FLINK-2740] Adding flink-connector-nifi module with NiFiSource and NiFiSinkThis closes #1198,2
[FLINK-14947] Introduce LocalExecutor and make LocalEnvironment use it,1
[FLINK-1866] [streaming] StreamConfig key bugfix,0
[FLINK-14129][hive] HiveTableSource should implement ProjectableTableSourceImplement ProjectableTableSource for HiveTableSource.This closes #9721.,2
Add ReplicaFetcherThread name to mbean names; kafka-726; patched by Swapnil Ghike; reviewed by Jun Rao,1
[FLINK-10687] [table] Move format factories to flink-table-common,2
[FLINK-23507] Use IP address of a kubernetes node when constructing node port connection string for the REST gateway.This closes #16720.,1
[FLINK-9292] [core] Remove TypeInfoParser (part 2)This changes #5970,4
[FLINK-4292] [batch connectors] Fix setup of HCatalog project by adding Scala SDK dependency,1
Add logback-test.xml to java8-tests and logback.xml to java-examples,5
"[FLINK-6519] Integrate BlobStore in lifecycle management of HighAvailabilityServicesThe HighAvailabilityService creates a single BlobStoreService instance which isshared by all BlobServer and BlobCache instances. The BlobStoreService's lifecycleis exclusively managed by the HighAvailabilityServices. This means that theBlobStore's content is only cleaned up if the HighAvailabilityService's HA datais cleaned up. Having this single point of control, makes it easier to decide whento discard HA data (e.g. in case of a successful job execution) and when to retainthe data (e.g. for recovery).Close and cleanup all data of BlobStore in HighAvailabilityServicesUse HighAvailabilityServices to create BlobStoreIntroduce BlobStoreService interface to hide close and closeAndCleanupAllData methodsThis closes #3864.",5
"Added Grouping unit test, extended Reduce integration test, added JavaDocs to ReduceFunction",1
"KAFKA-12193: Re-resolve IPs after a client disconnects (#9902)This patch changes the NetworkClient behavior to resolve the target node's hostname after disconnecting from an established connection, rather than waiting until the previously-resolved addresses are exhausted. This is to handle the scenario when the node's IP addresses have changed during the lifetime of the connection, and means that the client does not have to try to connect to invalid IP addresses until it has tried each address.Reviewers: Mickael Maison <mickael.maison@gmail.com>, Satish Duggana <satishd@apache.org>, David Jacot <djacot@confluent.io>",5
KAFKA-3316: Add REST API for listing connector pluginsAuthor: Liquan Pei <liquanpei@gmail.com>Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>Closes #1090 from Ishiihara/kafka-3316,5
[hotfix] Simplify TaskExecutorTest to avoid Mockito,3
[FLINK-9955][kubernetes] Add Kubernetes ClusterDescriptor to support deploying session clusterThis closes #9973 .,1
"[FLINK-6768] [core] More efficient field serializer lookups in PojoSerializerSnapshotIn the PojoSerializerSnapshot#resolveSchemaCompatibility method we callfor each field the findField(...) method in the PojoSerializer, whichperforms a linear scan of the array of fields. This effectively hasO(n^2) complexity.This is improved by this commit by building an index in theresolveSchemaCompatibility method for faster field serializer lookups.",0
"[FLINK-11249][kafka] Fix migration from FlinkKafkaProducer0.11 to universalAdd backward compatibile classes to the universal FlinkKafkaProducer, so that it can restore from 0.11 checkpoints.",2
[FLINK-1430] [streaming] Scala API completeness for streamingCloses #753,2
[FLINK-14018][python] Package cloudpickle in flink for ease of use for Flink Python usersThis closes #9766.,1
"[FLINK-7778] [build] Shade ZooKeeper dependency (followups)  - Rename the 'flink-shaded-curator-recipes' module to 'flink-shaded-curator',    because it actually contains more curator code than just the recipes.  - Move the exception handling logic of 'ZooKeeperAccess' directly into the    ZooKeeperStateHandleStore",0
MINOR: Move common out of range handling into AbstractFetcherThread (#5608)This patch removes the duplication of the out of range handling between `ReplicaFetcherThread` and `ReplicaAlterLogDirsThread` and attempts to expose a cleaner API for extension. It also adds a mock implementation to facilitate testing and several new test cases.Reviewers: Jun Rao <junrao@gmail.com>,3
"KAFKA-3522: Add internal RecordConverter interface (#6150)Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",5
"KAFKA-13457: SocketChannel in Acceptor#accept is not closed upon IOException (#11504)This patch ensures that SocketChannel in Acceptor#accept is closed if an IOException is thrown while the socket is configured.Reviewers:  Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",5
MINOR: Fix broken link in quickstart.html (#10161)Update the old anchor #intro_topic to #intro_concepts_and_termsReviewers: Mickael Maison <mickael.maison@gmail.com>,5
"[FLINK-2850] Limit the types of jobs which can run in detached modeThis disallows the following types of interactive programs in detachedmode:1. More than one call to execute2. Accessing job execution results likeaccumulators, net runtime, etc. This effectively disables eagerexecution functions such as count, print, collect, etc. too",1
"HOTFIX: move rebalanceInProgress check to skip commit during handleCorrupted (#10444)Minor followup to #10407 -- we need to extract the rebalanceInProgress check down into the commitAndFillInConsumedOffsetsAndMetadataPerTaskMap method which is invoked during handleCorrupted, otherwise we may attempt to commit during a a rebalance which will failReviewers: Matthias J. Sax <mjsax@confluent.io>",5
[hotfix][k8s] Fix k8s ha service doc.This closes #14416.,2
[FLINK-19914][table-planner] fix TemporalJoinITCase.testEventTimeTemporalJoinChangelogUsingBeforeTime is instable,5
DUBBO-499 解决服务暴露多次问题。,5
"use maven CI friendly versions: revision, cherry-pick to 3.x. (#3852)* use maven CI friendly versions: revision* add back mis-deleted files* bump version to 3.0.0-SNAPSHOT",2
[FLINK-4103] [table] Modify CsvTableSource to implement StreamTableSourceThis closes #2162.,2
[hotfix] Fix checkstyle violations in ScheduledUnit,0
[hotfix][docs] Fixed typo in metrics.md,2
CsvFormat configurable via regular parameters.CsvFormat generic (independent of PactRecord)Additional parsers.Examples partially ported to configuration via parameters (rather than confog strings).,5
[FLINK-21743] Document limitation of JdbcXaSinkFunction for MySQL support,1
[hotfix][table-common] Align explicit casting with Calcite's SqlTypeCoercionRule,0
"MINOR: Always specify the keystore type in system testsAlso throw an exception if a null keystore type is seenin `SecurityStore`. This should never happen.The default keystore type has changed in Java 9 (http://openjdk.java.net/jeps/229), so we need tobe explicit to have consistent behaviour acrossJava versions.Author: Ismael Juma <ismael@juma.me.uk>Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>Closes #3808 from ijuma/set-jks-explicitly-in-system-tests",5
KAFKA-13952 fix RetryWithToleranceOperator to respect infinite retries configuration (#12478)Reviewers: Chris Egerton <chrise@aiven.io>,5
"MINOR: make methods introduced in KAFKA-4490 consistent with KIP-100and remove some unnecessary SuppressWarnings annotationsAuthor: Xavier Léauté <xavier@confluent.io>Reviewers: Ismael Juma, Guozhang WangCloses #2363 from xvrl/kip-100-followup",5
[hotfix][tests] Move getMostRecentCompletedCheckpoint to TestUtils,3
[FLINK-21998][hive] Add more hive code,1
[FLINK-13192][hive] Add tests for different Hive table formatsThis closes #9264,3
[FLINK-2658] fieldsGrouping for multiple output streams fails - added SplitStreamTypeKeySelector and JUnit testsThis closes #1122,3
[streaming] wordcountlocal updatet for tuple,5
"[FLINK-24609][akka][build] Use same Scala properties as root pomMaven does not properly resolve dependencyManagement entries if the parent/child module declare one for the same dependency with different properties being used in the artifactId.Hence we unfortunately need to use the same property names, which should however not cause issues in the future (if say, a 2.13 profile is introduced), because the properties defined in the child take precedence.",1
[hotfix][tests] Discard state snapshot iff not null,3
DumpLogSegment offset verification is incorrect for compressed messages (second fix); patched by Yang Ye; reviewed by Jun Rao; KAFKA-614git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415004 13f79535-47bb-0310-9956-ffa450edef68,0
[FLINK-23517][build] Add error messages for bannedDependencies rules,0
"MINOR: Rename `ZkVersion` to `PartitionEpoch` (#12071)This patch does some initial cleanups in the context of KAFKA-13790. Mainly, it renames `ZkVersion` field to `PartitionEpoch` in the `LeaderAndIsrRequest`, the `LeaderAndIsr` and the `Partition`.Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>",5
[hotfix][docs] Align the documentation of checkpoint directory to the actual implementation,2
[FLINK-20654][docs] Adding unaligned checkpoint warning to release notes/docs.,2
[FLINK-24635][examples] Fix deprecations in Twitter example,0
"[FLINK-3929] conditionally skip RollingSinkSecuredITCase- for now, we skip this test class until Hadoop version 3.x.x.",3
"KAFKA-12802 Added a file based cache for consumed remote log metadata for each partition to avoid consuming again incase of broker restarts. (#11058)Added snapshots for consumed remote log metadata for each partition to avoid consuming again in case of broker restarts. These snapshots are stored in the respective topic partition log directories.Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",5
"MINOR: Add system configuration to zk security exception messages (#7280)This patch ensures that relevant system configurations are included in exception messages when zk security validation fails.Reviewers: Vikas Singh <soondenana@users.noreply.github.com>,  José Armando García Sancio <jsancio@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",1
KAFKA-3091: Broker persists generated ID even when the ID can't be used due to duplicates…updated to a new valid oneAuthor: Grant Henke <granthenke@gmail.com>Reviewers: Gwen ShapiraCloses #763 from granthenke/id-start-failure,0
Rename BufferAvailabilityRegistration constants and add initial LocalBufferPoolTest,3
initial clean up,4
[hotfix] [docs] Minor cleanup in filesystem docs,2
"KAFKA-5063: Fix flaky o.a.k.streams.integration.ResetIntegrationTestAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Damian Guy, Eno Thereska, Guozhang WangCloses #2931 from mjsax/kafka-5140-flaky-reset-integration-test",3
"MINOR: Time and log producer state recovery phases (#10241)During a slow log recovery it's easy to think that loading .snapshot files is a multi-second process. Often it isn't the snapshot loading that takes most of the time, rather it's the time taken to further rebuild the producer state from segment files. This patch times both snapshot load and segment recovery phases to better indicate what is taking time.Reviewers: David Jacot <djacot@confluent.io>",5
[hotfix] [table] Simplify time attribute handling for joins,0
[hotfix][docs] Change mailing list link in quickstart to flink-userPreviously it was pointing to flink-dev,2
[FLINK-12507][table-runtime-blink] Fix AsyncLookupJoin doesn't close all generated ResultFuturesThis closes #8436,0
"MINOR: Ignoring streams tests until there is fix for KAFKA-3354Per discussion with guozhangwang, `ignore` failing streams system tests until fix for KAFKA-3354 is checked in.Author: Geoff Anderson <geoff@confluent.io>Reviewers: Guozhang WangCloses #1031 from granders/ignore-streams-systest",5
Several issues with cluster,0
"MINOR: Update rocksDB dependency to 5.0.1Author: jozi-k <jozef.koval@protonmail.ch>Reviewers: Ismael Juma, Guozhang WangCloses #2292 from jozi-k/update-rocksdb-4.13.5",5
MINOR: Remove incorrect code in metadata module build (#9897)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
"[FLINK-9823] Add Kubernetes deployment ymlsThe Kubernetes files contain a job-cluster service specification, a job specificationfor the StandaloneJobClusterEntryPoint and a deployment for TaskManagers.This closes #6320.",1
"KAFKA-8179: Part 4, add CooperativeStickyAssignor (#7130)Splits the existing StickyAssignor logic into an AbstractStickyAssignor class, which is extended by the existing (eager) StickyAssignor and by the new CooperativeStickyAssignor which supports incremental cooperative rebalancing.There is no actual change to the logic -- most methods from StickyAssignor were moved to AbstractStickyAssignor to be shared with CooperativeStickyAssignor, and the abstract MemberData memberData(Subscription) method converts the Subscription to the embedded list of owned partitions for each assignor.The ""generation"" logic is left in, however this is always Optional.empty() for the CooperativeStickyAssignor as onPartitionsLost should always be called when a generation is missed.Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
"KAFKA-4052: Allow passing properties file to ProducerPerformanceTested by running on a kerberos enabled Kafka cluster.Author: Ashish Singh <asingh@cloudera.com>Reviewers: Gwen Shapira, Sriharsha ChintalapaniCloses #1749 from SinghAsDev/KAFKA-4052",0
[hotfix] Add FutureUtils.forwardAsyncFutureUtils.forwardAsync forwards the source value to the target future usingthe provided executor.,1
[FLINK-28977] NullPointerException in HybridSourceSplitEnumerator.close (#20587),2
"KAFKA-544. Follow-up items on key-retention. Addresses misc. comments from Joel, see ticket for details. git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1413839 13f79535-47bb-0310-9956-ffa450edef68",1
[FLINK-13378][table-planner-blink] Fix SINGLE_VALUE is not correctly supported in blink plannerThis closes #9208,2
[FLINK-15739] Fix TypeSerializerUpgradeTestBase on Java 12The problem was that some of the relocated classes inPojoSerializerUpgradeTest have enums in them. Java 12 introduced theEnumDesc class and enums will have an inner subclass of this definedthat does not have a ClassLoader. We now filter out classes that don'thave a classloader in the ClassRelocator because these classes don'thave bytecode that we could relocate.,1
"MINOR: Add System test for standby task-rebalancing (#4554)Author: Bill Bejeck <bill@confluent.io>Reviewers: Damian Guy <damian@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",5
Fixed error in QueueSchedulerTest,3
[FLINK-25128][table-planner] Fix usage of avatica core DateTimeUtils class,5
KAFKA-4070: implement Connect Struct.toString()Author: Shikhar Bhushan <shikhar@confluent.io>Reviewers: Gwen ShapiraCloses #1790 from shikhar/add-struct-tostring,1
"KAFKA-9784: Add OffsetFetch to group concurrency test (#8383)As title suggested, consumers would first do an OffsetFetch before starting the normal processing. It makes sense to add it to the concurrent test suite to verify whether there would be a blocking behavior.Reviewers: Guozhang Wang <wangguoz@gmail.com>",3
[FLINK-28913][hive] Fix failed to open HiveCatalog when it's for hive3 (#20573),2
Removed unused legacy class.,1
[hotfix] Let TaskExecutorTest.testReleaseInactiveSlots use TaskExecutorGateway,1
[FLINK-2619] [tests] Fix for some unexecuted Scala testsThis closes #1103,3
Fix NPE in MetadataInfo (#8131),5
加速测试git-svn-id: http://code.alibabatech.com/svn/dubbo/trunk@119 1a56cb94-b969-4eaa-88fa-be21384802f2,1
"[FLINK-15355][plugins] Added parent first patterns for plugins.Certain parent first entries do not work well with unrelocated pluginsand custom hadoop bundling. By using a reduced list that only consistsof SPI level interfaces and logging frameworks, plugins work withoutrelocations.",1
[FLINK-24765][kafka] Bump Kafka version to 2.8By bumping the kafka version to the latest 2.x release we include thelatest patches of Kafka which should harden our tests.,3
MINOR: Using primitive data types for loop index (#9705)Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,5
Removed array datamodel and Scala Grabbag,5
[FLINK-8811] [flip6] Implement MiniClusterClient#cancel,5
[FLINK-22298][table-planner-blink] The ExecNode's id should always start from 1 in the json plan testsThis closes #15639,3
[FLINK-6201] [py] [dist] move python example files from resources to the examplesThis closes #3628.,2
Refactor ChannelBufferStreamTest.testAll to improve the test experience (#10244),3
"[FLINK-1201] [gelly] refactored methods for Graph creation- constructors are now private- create() methods have been renamed and refactored to fromDataSet()- fromCollection() methods have been refactored- overall consistency in creating new Graph objects, using the constructor now in all placesfixes #53",0
[FLINK-16019][runtime][test] Implement test coverage for FLINK-16019 bug,0
[FLINK-16057][task] Optimize TaskMailbox state retrievalDon't lock in TaskMailboxImpl.getState for task thread.This makes ContinuousFileReaderOperator about 29% faster.,2
[hotfix] [network] Minor code cleanup in NettyTestUtil,3
KAFKA-10090 Misleading warnings: The configuration was supplied but i… (#8826)Reviewers: Jun Rao <junrao@gmail.com>,5
[FLINK-5343] [table] Add support to overwrite files with CsvTableSink.This closes #3011.,2
[FLINK-15239][table-planner-blink] Fix CompileUtils:#COMPILED_CACHE leaks class loaders (#10620),0
[hotfix] Fix checkstyle violations in ZooKeeperCheckpointIDCounter,0
[FLINK-15629] Unify DefaultSchedulerBatchSchedulingTest with BatchSchedulingTestBaseThis closes #10883.,3
KAFKA-1094 Configure reviewboard url in kafka-patch-review tool; reviewed by Neha Narkhede,5
Fix State Router Throw Exception when Address is Empty (#8951),1
Extended plugin interfaces,2
fix the key name to hide the accessKeyId and secretAccessKey (#5878)Co-authored-by: 郑泽超 <zhengzechao@qiyi.com>,0
"MINOR: Improve EOS related config docsAuthor: Matthias J. Sax <matthias@confluent.io>Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>Closes #4284 from mjsax/minor-improve-eos-docs",2
[hotfix] Add notice about using FLINK_CONF_DIR in Yarn Setup,1
fix referOrDestroyCallbackService.referOrDestroyCallbackService to Camel-case fix issues  #2973 (#2979),0
service discovery demos,5
[FLINK-11511][tests] Remove legacy class JobAttachmentClientActorThis closes #7637.,4
"KAFKA-13419: Only reset generation ID when ILLEGAL_GENERATION error (#11451)Updated: This PR will reset generation ID when ILLEGAL_GENERATION error since the member ID is still valid.=====resetStateAndRejoin when REBALANCE_IN_PROGRESS error in sync group, to avoid out-of-date ownedPartition== JIRA description ==In KAFKA-13406, we found there's user got stuck when in rebalancing with cooperative sticky assignor. The reason is the ""ownedPartition"" is out-of-date, and it failed the cooperative assignment validation.Investigate deeper, I found the root cause is we didn't reset generation and state after sync group fail. In KAFKA-12983, we fixed the issue that the onJoinPrepare is not called in resetStateAndRejoin method. And it causes the ownedPartition not get cleared. But there's another case that the ownedPartition will be out-of-date. Here's the example:consumer A joined and synced group successfully with generation 1New rebalance started with generation 2, consumer A joined successfully, but somehow, consumer A doesn't send out sync group immediatelyother consumer completed sync group successfully in generation 2, except consumer A.After consumer A send out sync group, the new rebalance start, with generation 3. So consumer A got REBALANCE_IN_PROGRESS error with sync group responseWhen receiving REBALANCE_IN_PROGRESS, we re-join the group, with generation 3, with the assignment (ownedPartition) in generation 1.So, now, we have out-of-date ownedPartition sent, with unexpected results happenedWe might want to do resetStateAndRejoin when RebalanceInProgressException errors happend in sync group. Because when we got sync group error, it means, join group passed, and other consumers (and the leader) might already completed this round of rebalance. The assignment distribution this consumer have is already out-of-date.Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",5
[hotfix][e2e] Refactor docker embedded job test: use pushd/popd instead of cd,1
New Datamodel API adoptions for compilation.,5
Added new unit test for ticket #212,3
[FLINK-1316] [web client] Fix plan display for nodes referenced from multiple closures.,0
[FLINK-7811] Fix TestingJobManagerLike for Scala 2.12,3
[FLINK-21685][k8s] Use dedicated thread pool for Kubernetes client IO operationsThis closes #15385.,1
"Adds join projection, comments for join classes, removes unsupported methods for join.",1
[FLINK-18247][table-planner-blink] Fix unstable test: TableITCase.testCollectWithCloseThis closes #12595,3
"MINOR: Fix typo in javadoc of `flatMapValues`Author: Michael G. Noll <michael@confluent.io>Reviewers: Damian Guy, Matthias J. Sax, Guozhang WangCloses #2607 from miguno/trunk-flatMapValues-docstring",2
